{
  "title": "Python. К вершинам мастерства [2022] Лусиану Рамальо",
  "chapters": [
    {
      "name": "Глава 1. Модель данных в языке Python 32",
      "content": "--- Страница 32 ---\nколлекции; доступ к атрибутам; итерирование (включая асинхронное итерирование с помощью async for); перегрузку операторов; вызов функций и методов; представление и форматирование строк; асинхронное программирование с использованием await ; создание и уничтожение объектов; управляемые контексты (т. е. блоки with и async with ). Магические и dunder-методы На жаргоне специальные методы называют магическими, но как мы в разговоре произносим имя конкретного метода, напри- мер __getitem__ ? Выражение «dunder-getitem» я услышал от авто- ра и преподавателя Стива Холдена. «Dunder» – это сокращенная форма «двойной подчерк до и после». Поэтому специальные ме- тоды называются также dunder-методами. В главе «Лексический анализ» Справочного руководства по Python имеется предупреж - дение: «Любое использование имен вида __*__ в любом контек - сте, отличающееся от явно документированного, может привес- ти к ошибке без какого-либо предупреждения». чтО нОвОг О в этОй главе В этой главе немного отличий от первого издания, потому что она представ- ляет собой введение в модель данных в Python, которая давно стабилизирова- лась. Перечислим наиболее существенные изменения: в таблицы в разделе «Сводка специальных методов» добавлены мето- ды, поддерживающие асинхронное программирование и другие новые средства; на рис. 1.2 показано использование специальных методов API коллек - ций, включая абстрактный базовый класс collections.abc.Collection , по- явившийся в версии Python 3.6. Кроме того, здесь и далее я использую синтаксис f-строк, введенный в Python 3.6, который проще читать и зачастую удобнее, чем прежние способы форматирования: метод str.format() и оператор %. Использовать нотацию my_fmt.format() все еще необходимо, ког- да my_fmt определено не там, где выполняется операция форма- тирования. Например, если my_fmt состоит из нескольких строчек и определено в виде константы или читается из конфигураци- онного файла либо из базы данных. Тут по-другому не сделаешь, но такие ситуации встречаются нечасто. кОлОда карт на python Следующий пример очень прост, однако демонстрирует выгоды от реализации двух специальных методов: __getitem__ и __len__. Колода карт на Python  33\n--- Страница 33 ---\nПример 1.1. Колода как последовательность карт import collections Card = collections.namedtuple('Card', ['rank', 'suit']) class FrenchDeck: ranks = [str(n) for n in range(2, 11)] + list('JQKA') suits = 'spades diamonds clubs hearts'.split() def __init__(self): self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks] def __len__(self): return len(self._cards) def __getitem__(self, position): return self._cards[position] Прежде всего отметим использование collections.namedtuple для конструиро- вания простого класса, представляющего одну карту. Мы используем класс namedtuple для построения классов, содержащих только атрибуты и никаких методов, как, например, запись базы данных. В данном примере мы восполь- зовались им для создания простого представления игральной карты, что про- демонстрировано в следующем сеансе оболочки: >>> beer_card = Card('7', 'diamonds') >>> beer_card Card(rank='7', suit='diamonds') Но изюминка примера – класс FrenchDeck . Совсем короткий, он таит в себе немало интересного. Во-первых, как и для любой стандартной коллекции в Python, для колоды можно вызвать функцию len(), которая вернет количест - во карт в ней: >>> deck = FrenchDeck() >>> len(deck) 52 Получить карту из колоды, например первую или последнюю, просто благо- даря методу __getitem__ : >>> deck[0] Card(rank='2', suit='spades') >>> deck[-1] Card(rank='A', suit='hearts') Нужно ли создавать метод для выбора случайной карты? Необязательно. В Python уже есть функция выборки случайного элемента последовательности: random.choice . Достаточно вызвать ее для экземпляра колоды: >>> from random import choice >>> choice(deck) Card(rank='3', suit='hearts') >>> choice(deck) Card(rank='K', suit='spades')34  Модель данных в языке Python\n--- Страница 34 ---\n>>> choice(deck) Card(rank='2', suit='clubs') Мы только что видели два преимущества использования специальных мето- дов для работы с моделью данных. Пользователям нашего класса нет нужды запоминать нестандартные име- на методов для выполнения стандартных операций («Как мне получить количество элементов? То ли .size(), то ли .length(), то ли еще как-то»). Проще воспользоваться богатством стандартной библиотеки Python (на- пример, функцией random.choice ), чем изобретать велосипед. Но это еще не все. Поскольку метод __getitem__ делегирует выполнение оператору [] объекта self._cards , колода автоматически поддерживает срезы. Вот как можно посмот- реть три верхние карты в неперетасованной колоде, а затем выбрать только тузы, начав с элемента, имеющего индекс 12, и пропуская по 13 карт: >>> deck[:3] [Card(rank='2', suit='spades'), Card(rank='3', suit='spades'), Card(rank='4', suit='spades')] >>> deck[12::13] [Card(rank='A', suit='spades'), Card(rank='A', suit='diamonds'), Card(rank='A', suit='clubs'), Card(rank='A', suit='hearts')] Стоило нам реализовать специальный метод __getitem__ , как колода стала до- пускать итерирование: >>> for card in deck: # doctest: +ELLIPSIS print(card) Card(rank='2', suit='spades') Card(rank='3', suit='spades') Card(rank='4', suit='spades') Итерировать можно и в обратном порядке: >>> for card in reversed(deck): # doctest: +ELLIPSIS print(card) Card(rank='A', suit='hearts') Card(rank='K', suit='hearts') Card(rank='Q', suit='hearts') Многоточие в тестах Всюду, где возможно, листинги сеансов оболочки извлекались из doctest-скриптов, чтобы гарантировать точность. Если вы- вод слишком длинный, то опущенная часть помечается много- точием, как в последней строке показанного выше кода. В та- ких случаях мы используем директиву # doctest: +ELLIPSIS , чтобы тест завершился успешно. Если вы будете вводить эти примеры в интерактивной оболочке, можете вообще опускать директивы doctest. Итерирование часто подразумевается неявно. Если в коллекции отсутству - ет метод __contains__ , то оператор in производит последовательный просмотр. Колода карт на Python  35\n--- Страница 35 ---\nКонкретный пример – в классе FrenchDeck оператор in работает, потому что этот класс итерируемый. Проверим: >>> Card('Q', 'hearts') in deck True >>> Card('7', 'beasts') in deck False А как насчет сортировки? Обычно карты ранжируются по достоинству (тузы – самые старшие), а затем по масти в порядке пики (старшая масть), чер- ви, бубны и трефы (младшая масть). Приведенная ниже функция ранжирует карты, следуя этому правилу: 0 означает двойку треф, а 51 – туз пик. suit_values = dict(spades=3, hearts=2, diamonds=1, clubs=0) def spades_high(card): rank_value = FrenchDeck.ranks.index(card.rank) return rank_value * len(suit_values) + suit_values[card.suit] С помощью функции spades_high мы теперь можем расположить колоду в по- рядке возрастания: >>> for card in sorted(deck, key=spades_high): # doctest: +ELLIPSIS print(card) Card(rank='2', suit='clubs') Card(rank='2', suit='diamonds') Card(rank='2', suit='hearts') (46 карт опущено) Card(rank='A', suit='diamonds') Card(rank='A', suit='hearts') Card(rank='A', suit='spades') Хотя класс FrenchDeck неявно наследует object, его функциональность не на- следуется, а является следствием использования модели данных и компози- ции. Вследствие реализации специальных методов __len__ и __getitem__ класс FrenchDeck ведет себя как стандартная последовательность и позволяет исполь- зовать базовые средства языка (например, итерирование и получение среза), а также функции reversed и sorted. Благодаря композиции реализации методов __len__ и __getitem__ могут перепоручать работу объекту self._cards класса list. А как насчет тасования? В текущей реализации объект класса FrenchDeck нельзя перетасо- вать, потому что он неизменяемый: ни карты, ни их позиции не- возможно изменить, не нарушая инкапсуляцию (т. е. манипули- руя атрибутом _cards непосредственно). В главе 13 мы исправим это, добавив однострочный метод __setitem__ . как иСпО льзуют Ся Специальные метОды Говоря о специальных методах, нужно все время помнить, что они предназна- чены для вызова интерпретатором, а не вами. Вы пишете не my_object.__len__() , а len(my_object) , и если my_object – экземпляр определенного пользователем клас - са, то Python вызовет реализованный вами метод экземпляра __len__. 36  Модель данных в языке Python\n--- Страница 36 ---\nОднако для встроенных классов, например list, str, bytearray, или расшире- ний типа массивов NumPy интерпретатор поступает проще. Коллекции пере- менного размера, написанные на C, включают структуру1 PyVarObject , в которой имеется поле ob_size, содержащее число элементов в коллекции. Поэтому если my_object – экземпляр одного из таких встроенных типов, то len(my_object) воз- вращает значение поля ob_size, что гораздо быстрее, чем вызов метода. Как правило, специальный метод вызывается неявно. Например, предложе- ние for i in x: подразумевает вызов функции iter(x), которая, в свою очередь, может вызывать метод x.__iter__() , если он реализован, или использовать x.__ getitem__() , как в примере класса FrenchDeck . Обычно в вашей программе не должно быть много прямых обращений к специальным методам. Если вы не пользуетесь метапрограммированием, то чаще будете реализовывать специальные методы, чем явно вызывать их. Единственный специальный метод, который регулярно вызывается из поль- зовательского кода напрямую, – __init__, он служит для инициализации супер- класса из вашей реализации __init__. Если необходимо обратиться к специальному методу, то обычно лучше вы- звать соответствующую встроенную функцию (например, len, iter, str и т. д.). Она вызывает нужный специальный метод и нередко предоставляет допол- нительный сервис. К тому же для встроенных типов это быстрее, чем вызов метода. См. раздел «Использование iter совместно с вызываемым объектом» главы 17. В следующих разделах мы рассмотрим некоторые из наиболее важных при- менений специальных методов: эмуляция числовых типов; строковое представление объектов; булево значение объекта; реализация коллекций. Эмуляция числовых типов Несколько специальных методов позволяют объектам иметь операторы, на- пример +. Подробно мы рассмотрим этот вопрос в главе 16, а пока проиллюст - рируем использование таких методов на еще одном простом примере. Мы реализуем класс для представления двумерных векторов, обычных ев- клидовых векторов, применяемых в математике и физике (рис. 1.1). Для представления двумерных векторов можно использовать встроенный класс complex, но наш класс допускает обобщение на n-мерные векторы. Мы займемся этим в главе 17. 1 В языке C структура – это тип записи с именованными полями. Как используются специальные методы  37\n--- Страница 37 ---\nVector(4,5) Vector(2,4) Vector(2,1)y x Рис. 1.1. Пример сложения двумерных векторов: Vector(2, 4) + Vector(2, 1) = Vector(4, 5) Для начала спроектируем API класса, написав имитацию сеанса оболочки, которая впоследствии станет тестом. В следующем фрагменте тестируется сло- жение векторов, изображенное на рис. 1.1. >>> v1 = Vector(2, 4) >>> v2 = Vector(2, 1) >>> v1 + v2 Vector(4, 5) Отметим, что оператор + порождает результат типа Vector, который отобра- жается в оболочке интуитивно понятным образом. Встроенная функция abs возвращает абсолютную величину вещественного числа – целого или с плавающей точкой – и модуль числа типа complex, поэто- му для единообразия наш API также использует функцию abs для вычисления модуля вектора: >>> v = Vector(3, 4) >>> abs(v) 5.0 Мы можем еще реализовать оператор *, выполняющий умножение на ска- ляр (т. е. умножение вектора на число, в результате которого получается новый вектор с тем же направлением и умноженным на данное число модулем): >>> v * 3 Vector(9, 12) >>> abs(v * 3) 15.0 В примере 1.2 приведен класс Vector, реализующий описанные операции с помощью специальных методов __repr__, __abs__, __add__ и __mul__.38  Модель данных в языке Python\n--- Страница 38 ---\nПример 1.2. Простой класс двумерного вектора «»» vector2d.py: упрощенный класс, демонстрирующий некоторые специальные методы. Упрощен из дидактических соображений. Классу не хватает правильной обработки ошибок, особенно в методах ``__add__`` and ``__mul__``. Далее в книге этот пример будет существенно расширен. Сложение:: >>> v1 = Vector(2, 4) >>> v2 = Vector(2, 1) >>> v1 + v2 Vector(4, 5) Абсолютная величина:: >>> v = Vector(3, 4) >>> abs(v) 5.0 Умножение на скаляр:: >>> v * 3 Vector(9, 12) >>> abs(v * 3) 15.0 \"\"\" import math class Vector: def __init__(self, x=0, y=0): self.x = x self.y = y def __repr__(self): return f'Vector({self.x!r}, {self.y!r})' def __abs__(self): return math.hypot(self.x, self.y) def __bool__(self): return bool(abs(self)) def __add__(self, other): x = self.x + other.x y = self.y + other.y return Vector(x, y) def __mul__(self, scalar): return Vector(self.x * scalar, self.y * scalar) Мы реализовали пять специальных методов, помимо хорошо знакомого __init__. Отметим, что ни один из них не вызывается напрямую внутри само- Как используются специальные методы  39\n--- Страница 39 ---\nго класса или при типичном использовании класса, показанном в листингах сеансов оболочки. Как уже было сказано, чаще всего специальные методы вы- зывает интерпретатор Python. В примере 1.2 реализовано два оператора: + и *, чтобы продемонстрировать использование методов __add__ и __mul__. В обоих случаях метод создает и воз- вращает новый экземпляр класса Vector, не модифицируя ни один операнд – аргументы self и other только читаются. Именно такого поведения ожидают от инфиксных операторов: создавать новые объекты, не трогая операндов. Мы еще вернемся к этому вопросу в главе 16. Реализация в примере 1.2 позволяет умножать Vector на число, но не число на Vector. Это нарушает свойство коммутативности операции умножения на скаляр. В главе 16 мы исправим данный недостаток, реализовав специальный метод __rmul__. В следующих разделах мы обсудим другие специальные методы класса Vector. Строковое представление Специальный метод __repr__ вызывается встроенной функцией repr для полу - чения строкового представления объекта. Если бы мы не реализовали метод __repr__, то объект класса Vector был бы представлен в оболочке строкой вида <Vector object at 0x10e100070> . Интерактивная оболочка и отладчик вызывают функцию repr, передавая ей результат вычисления выражения. То же самое происходит при обработке спецификатора %r в случае классического форматирования с помощью опера- тора % и при обработке поля преобразования !r в новом синтаксисе форматной строки (https://docs.python.org/3.10/library/string.html#format-string-syntax), приме- няемом в f-строках в методе str.format . Отметим, что в f-строке в нашей реализации метода __repr__ мы использо- вали !r для получения стандартного представления отображаемых атрибутов. Это разумный подход, потому что в нем отчетливо проявляется существенное различие между Vector(1, 2) и Vector('1', '2') – второй вариант в контексте этого примера не заработал бы, потому что аргументами конструктора должны быть числа, а не объекты str. Строка, возвращаемая методом __repr__, должна быть однозначно определе- на и по возможности соответствовать коду, необходимому для восстановления объекта. Именно поэтому мы выбрали представление, напоминающее вызов конструктора класса (например, Vector(3, 4) ). В отличие от __repr__, метод __str__ вызывается конструктором str() и неявно используется в функции print. Он должен возвращать строку, пригодную для показа пользователям. Иногда строка, возвращенная методом __repr__, уже пригодна для показа пользователям, тогда нет нужды писать метод __str__, т. к. реализация, уна- следованная от класса object, вызывает __repr__, если нет альтернативы. При- мер 5.2 – один из немногих в этой книге, где используется пользовательский метод __str__. 40  Модель данных в языке Python\n--- Страница 40 ---\nПрограммисты, имеющие опыт работы с языками, где имеется метод toString, по привычке реализуют метод __str__, а не __repr__. Если вы реализуете только один из этих двух методов, то пусть это будет __repr__. На сайте Stack Overflow был задан вопрос «What is the difference between __str__ and __repr__ in Python» (https://stackoverflow.com/ questions/1436703/what-is-the-difference-between-str-and-repr), ответ на который содержит прекрасные разъяснения Алекса Мартелли и Мартина Питерса. Булево значение пользовательского типа Хотя в Python есть тип bool, интерпретатор принимает любой объект в булевом контексте, например в условии if, в управляющем выражении цикла while или в качестве операнда операторов and, or и not. Чтобы определить, является ли вы- ражение истинным или ложным, применяется функция bool(x), которая возвра- щает True или False. По умолчанию любой экземпляр пользовательского класса считается истин- ным, но положение меняется, если реализован хотя бы один из методов __bool__ или __len__. Функция bool(x), по существу, вызывает x.__bool__() и использует полученный результат. Если метод __bool__ не реализован, то Python пытается вызвать x.__len__() и при получении нуля функция bool возвращает False. В про- тивном случае bool возвращает True. Наша реализация __bool__ концептуально проста: метод возвращает False, если модуль вектора равен 0, и True в противном случае. Для преобразования модуля в булеву величину мы вызываем bool(abs(self)) , поскольку ожидается, что метод __bool__ возвращает булево значение. Вне метода __bool__ редко воз- никает надобность вызывать bool() явно, потому что любой объект можно ис- пользовать в булевом контексте. Обратите внимание на то, как специальный метод __bool__ обеспечивает со- гласованность пользовательских объектов с правилами проверки значения ис- тинности, определенными в главе «Встроенные типы» документации по стан- дартной библиотеке Python (http://docs.python.org/3/library/stdtypes.html#truth). Можно было бы написать более быструю реализацию метода Vector.__bool__ : def __bool__(self): return bool(self.x or self.y) Она сложнее воспринимается, зато позволяет избежать обращений к abs и __abs__, возведения в квадрат и извлечения корня. Явное преобразование в тип bool необходимо, потому что метод __bool__ должен возвращать булево значение, а оператор or возвращает один из двух операндов: результат вычисления x or y равен x, если x истинно, иначе равен y вне зависимости от его значения. API коллекций На рис. 1.2 описаны интерфейсы основных типов коллекций, поддерживае- мых языком. Все классы на этой диаграмме являются абстрактными базо- Как используются специальные методы  41\n--- Страница 41 ---\nвыми классами, ABC. Такие классы и модуль collections.abc рассматриваются в главе 13. Цель этого краткого раздела – дать общее представление о самых важных интерфейсах коллекций в Python и показать, как они строятся с по- мощью специальных методов. * Появилось в Python 3.6 Рис. 1.2. UML-диаграмма классов, иллюс трирующая наиболее важные типы коллекций. Методы, имена которых набраны курсивом, абстрактные, поэтому должны быть реализованы в конкретных подклассах, например list и dict. У остальных методов имеются конкретные реализации, которые подклассы могут унаследовать У каждого из ABC в верхнем ряду есть всего один специальный метод. Аб- страктный базовый класс Collection (появился в версии Python 3.6) унифицирует все три основных интерфейса, который должна реализовать любая коллекция: Iterable для поддержки for, распаковки и других видов итерирования; Sized для поддержки встроенной функции len; Container для поддержки оператора in. Python не требует, чтобы конкретные классы наследовали какому-то из этих ABC. Любой класс, реализующий метод __len__, удовлетворяет требованиям ин- терфейса Sized. Перечислим три важнейшие специализации Collection : Sequence, формализует интерфейс встроенных классов, в частности list и str; Mapping, реализован классами dict, collections.defaultdict и др.; Set, интерфейс встроенных типов set и frozenset.42  Модель данных в языке Python\n--- Страница 42 ---\nТолько Sequence реализует интерфейс Reversible , потому что последовательно- сти поддерживают произвольное упорядочение элементов, тогда как отобра- жения и множества таким свойством не обладают. Начиная с версии Python 3.7 тип dict официально считается «упорядоченным», но это лишь означает, что порядок вставки ключей сохраняется. Переупорядочить ключи словаря dict так, как вам хочется, невозможно. Все специальные методы ABC Set предназначены для реализации инфикс - ных операторов. Например, выражение a & b вычисляет пересечение множеств a и b и реализовано специальным методом __and__. В следующих двух главах мы подробно рассмотрим стандартные библиотеч- ные последовательности, отображения и множества. А пока перейдем к основным категориям специальных методов, определен- ным в модели данных Python. СвОдка Специальных метОдОв В главе «Модель данных» (http://docs.python.org/3/reference/datamodel.html) спра- вочного руководства по языку Python перечислено более 80 специальных ме- тодов. Больше половины из них используются для реализации операторов: арифметических, поразрядных и сравнения. Следующие таблицы дают пред- ставление о том, что имеется в нашем распоряжении. В табл. 1.1 показаны имена специальных методов, за исключением тех, что используются для реализации инфиксных операторов и базовых математиче- ских функций, например abs. Большинство этих методов будут рассмотрены на протяжении книги, в т. ч. недавние добавления: асинхронные специальные методы, в частности __anext__ (добавлен в Python 3.5), и точка подключения для настройки класса __init_subclass__ (добавлен в Python 3.6). Таблица 1.1. Имена специальных методов (операторы не включены) Категория Имена методов Представление в виде строк и байтов__repr__, __str__, __format__, __bytes__, __fspath__ Преобразование в число __bool__, __complex__, __int__, __float__, __hash__, __index__ Эмуляция коллекций __len__, __getitem__, __setitem__, __delitem__, __con - tains__ Итерирование __iter__, __aiter__, __next__, __anext__, __reversed__ Выполнение объектов, допуска- ющих вызов, или сопрограмм__call__, __await__ Управление контекстом __enter__, __exit__, __aenter__, __aexit__ Создание и уничтожение объ- ектов__new__, __init__, __del__ Сводка специальных методов  43\n--- Страница 43 ---\nКатегория Имена методов Управление атрибутами __getattr__, __getattribute__, __setattr__, __delat - tr__, __dir__ Дескрипторы атрибутов __get__, __set__, __delete__, __set_name__ Абстрактные базовые классы __instancecheck__, __subclasscheck__ Метапрограммирование классов __prepare__, _init_subclass__, __class_getitem__, __ mro_entries__ Инфиксные и числовые операторы поддерживаются специальными метода- ми, перечисленными в табл. 1.2. В версии Python 3.5 были добавлены методы __matmul__ , __rmatmul__ и __imatmul__ для поддержки @ в роли инфиксного оператора умножения матриц (см. главу 16). Таблица 1.2. Имена специальных методов для операторов Категория операторов Символы Имена методов Унарные числовые опе- раторы- + abs() __neg__ __pos__ __abs__ Операторы сравнения < <= == !- > >= __lt__ __le__ __eq__ __ne__ __gt__ __ge__ Арифметические опера- торы+ - * / // % @ divmod() round() ** pow()__add__ __sub__ __mul__ __truediv__ __floordiv__ __mod__ __matmul__ __ divmod__ __round__ __pow__ Инверсные арифметиче- ские операторы(арифметические опера- торы с переставленными операндами)__radd__ __rsub__ __rmul__ __ rtruediv__ __rfloordiv__ __rmod__ __rmatmul__ __rdivmod__ __rpow__ Арифметические опера- торы составного присва- ивания+= -= *= /= //= %= @= **=__iadd__ __isub__ __imul__ __itrue - div____ifloordiv__ __imod__ __imat - mul__ __ipow__ Поразрядные операторы & | ^ << >> ~ __and__ __or__ __xor__ __lshift__ __rshift__ __invert__ Инверсные поразрядные операторы(поразрядные операто- ры с переставленными операндами)__rand__ __ror__ __rxor__ __ rlshift__ __rrshift__ Поразрядные операторы составного присваивания&= |= ^= <<= >>= __iand__ __ior__ __ixor__ __il - shift__ __irshift__ Python вызывает инверсный специальный метод от имени второ- го операнда, если нельзя использовать соответственный специ- альный метод от имени первого операнда. Операторы составного присваивания – сокращенный способ вызвать инфиксный опера- тор с последующим присваиванием переменной, например a += b. В главе 16 инверсные операторы и составное присваивание рас- сматриваются подробнее. Окончание табл. 1.144  Модель данных в языке Python\n--- Страница 44 ---\nпОчему len – не метОд Я задавал этот вопрос разработчику ядра Раймонду Хэттингеру в 2013 году, смысл его ответа содержится в цитате из «Дзен Python»: «практичность важ- нее чистоты» (https://www.python.org/doc/humor/#thezen-of-python). В разделе «Как используются специальные методы» выше я писал, что функция len(x) работа- ет очень быстро, если x – объект встроенного типа. Для встроенных объектов интерпретатор CPython вообще не вызывает никаких методов: длина просто читается из поля C-структуры. Получение количества элементов в коллекции – распространенная операция, которая должна работать эффективно для таких разных типов, как str, list, memoryview и т. п. Иначе говоря, len не вызывается как метод, потому что играет особую роль в мо- дели данных Python, равно как и abs. Но благодаря специальному методу __len__ можно заставить функцию len работать и для пользовательских объектов. Это разум ный компромисс между желанием обеспечить как эффективность встроен- ных объектов, так и согласованность языка. Вот еще цитата из «Дзен Python»: «осо- бые случаи не настолько особые, чтобы из-за них нарушать правила». Если рассматривать abs и len как унарные операторы, то, возмож - но, вы простите их сходство с функциями, а не с вызовами мето- да, чего следовало бы ожидать от ОО-языка. На самом деле в язы- ке ABC – непосредственном предшественнике Python, в котором впервые были реализованы многие его средства, – существовал оператор #, эквивалентный len (следовало писать #s). При исполь- зовании в качестве инфиксного оператора – x#s – он подсчитывал количество вхождений x и s; в Python для этого нужно вызвать s.count(x) , где s – произвольная последовательность. резюме Благодаря реализации специальных методов пользовательские объекты могут вести себя как встроенные типы. Это позволяет добиться выразительного сти- ля кодирования, который сообщество считает «питоническим». Важное требование к объекту Python – обеспечить полезные строковые представления себя: одно – для отладки и протоколирования, другое – для по- каза пользователям. Именно для этой цели предназначены специальные ме- тоды __repr__ и __str__. Эмуляция последовательностей, продемонстрированная на примере класса FrenchDeck , – одно из самых распространенных применений специальных ме- тодов. Устройство большинства типов последовательностей – тема главы 2, а реализация собственных последовательностей будет рассмотрена в главе 12 в контексте создания многомерного обобщения класса Vector. Благодаря перегрузке операторов Python предлагает богатый набор число- вых типов, от встроенных до decimal.Decimal и fractions.Fraction , причем все они поддерживают инфиксные арифметические операторы. Библиотека анализа данных NumPy поддерживает инфиксные операторы для матриц и тензоров. Реализация операторов, в том числе инверсных и составного присваивания, будет продемонстрирована в главе 16 в процессе расширения класса Vector. Использование и реализация большинства других специальных методов, вхо- дящих в состав модели данных Python, рассматривается в разных частях книги. Резюме  45\n--- Страница 45 ---\nдОпО лнительная литература Глава «Модель данных» (http://docs.python.org/3/reference/datamodel.html) справоч- ного руководства по языку Python – канонический источник информации по теме этой главы и значительной части изложенного в книге материала. В книге Alex Martelli, Anna Ravenscroft, Steve Holden «Python in a Nutshell», тре- тье издание (O’Reilly), прекрасно объясняется модель данных. Данное ими опи- сание механизма доступа к атрибутам – самое полное из всех, что я видел, если не считать самого исходного кода CPython на C. Мартелли также очень активен на сайте Stack Overflow, ему принадлежат более 6200 ответов. С его профилем можно ознакомиться по адресу http://stackoverflow.com/users/95810/alex-martelli. Дэвид Бизли написал две книги, в которых подробно описывается модель данных в контексте Python 3: «Python Essential Reference», издание 4 (Addison- Wesley Professional), и «Python Cookbook»1, издание 3 (O’Reilly), в соавторстве с Брайаном Л. Джонсом. В книге Gregor Kiczales, Jim des Rivieres, Daniel G. Bobrow «The Art of the Meta- object Protocol» (MIT Press) объясняется протокол метаобъектов, одним из при- меров которого является модель данных в Python. Поговорим Модель данных или объектная модель? То, что в документации по Python называется «моделью данных», большин- ство авторов назвали бы «объектной моделью Python». В книгах Alex Martelli, Anna Ravenscroft, Steve Holden «Python in a Nutshell», издание 3, и David Beazley «Python Essential Reference», издание 4, – лучших книгах по «модели данных Python» – употребляется термин «объектная модель». В Википедии самое первое определение модели данных (http://en.wikipedia.org/wiki/Object_model) звучит так: «Общие свойства объектов в конкретном языке программирова- ния». Именно в этом и заключается смысл «модели данных Python». В этой книге я употребляю термин «модель данных», потому что его предпочитают авторы документации и потому что так называется глава в справочном руко- водстве по языку Python (https://docs.python.org/3/reference/datamodel.html), име- ющая прямое касательство к нашему обсуждению. Магические методы В словаре «The Original Hacker’s Dictionary» (https://www.dourish.com/goodies/ jargon.html) термин магический определяется как «еще не объясненный или слишком сложный для объяснения» или как «не раскрываемый публично ме- ханизм, позволяющий делать то, что иначе было бы невозможно». В сообществе Ruby эквиваленты специальных методов называют магиче- скими. Многие пользователи из сообщества Python также восприняли этот термин. Лично я считаю, что специальные методы – прямая противополож - ность магии. В этом отношении языки Python и Ruby одинаковы: тот и другой предоставляют развитый протокол метаобъектов, отнюдь не магический, но позволяющий пользователям применять те же средства, что доступны разра- 1 Бизли Д., Джонс Б. К. Python. Книга рецептов. М.: ДМК Пресс, 2019 // https://dmkpress. com/catalog/computer/programming/python/978-5-97060-751-0/46  Модель данных в языке Python\n--- Страница 46 ---\nботчикам ядра, которые пишут интерпретаторы этих языков. Сравним это с Go. В этом языке у некоторых объектов есть действительно ма- гические возможности, т. е. такие, которые невозможно имитировать в поль- зовательских типах. Например, массивы, строки и отображения в Go под- держивают использование квадратных скобок для доступа к элементам: a[i]. Но не существует способа приспособить нотацию [] к новым, определенным пользователем типам. Хуже того, в Go нет ни понятия интерфейса итерируе- мости, ни объекта итератора на пользовательском уровне, поэтому синтак - сическая конструкция for/range ограничена поддержкой пяти «магических» встроенных типов, в т. ч. массивов, строк и отображений. Быть может, в будущем проектировщики Go расширят протокол метаобъек - тов. А пока в нем куда больше ограничений, чем в Python и Ruby. Метаобъекты «The Art of the Metaobject Protocol» (AMOP) – моя любимая книга по ком- пьютерам. Но и отбросив в сторону субъективизм, термин «протокол мета- объектов» полезен для размышления о модели данных в Python и о похожих средствах в других языках. Слово «метаобъект» относится к объектам, являю- щимся структурными элементами самого языка. А «протокол» в этом контек - сте – синоним слова «интерфейс». Таким образом, протокол метаобъектов – это причудливый синоним «объектной модели»: API для доступа к базовым конструкциям языка. Развитый протокол метаобъектов позволяет расширять язык для поддержки новых парадигм программирования. Грегор Кикзалес, первый автор книги AMOP, впоследствии стал первопроходцем аспектно-ориентированного про- граммирования и первоначальным автором AspectJ, расширения Java для реа лизации этой парадигмы. В динамическом языке типа Python реализо- вать аспектно-ориентированное программирование гораздо проще, и суще- ствует несколько каркасов, в которых это сделано. Самым известным из них является каркас zope.interface ( http://docs.zope.org/zope.interface/), на базе которо- го построена система управления контентом Plone (https://plone.org/). Дополнительная литература  47",
      "debug": {
        "start_page": 32,
        "end_page": 46
      }
    },
    {
      "name": "Глава 2. Массив последовательностей 48",
      "content": "--- Страница 47 --- (продолжение)\nГлава 2 Массив последовательностей Как вы, наверное, заметили, некоторые из упомянутых операций одина- ково работают для текстов, списков и таблиц. Для текстов, списков и таб- лиц имеется обобщенное название «ряд» […]. Команда FOR также едино- образно применяется ко всем рядам. – Leo Geurts, Lambert Meertens, Steven Pembertonm, «ABC Programmer’s Handbook»1 До создания Python Гвидо принимал участие в разработке языка ABC. Это был растянувшийся на 10 лет исследовательский проект по проектированию среды программирования для начинающих. В ABC первоначально появились многие идеи, которые мы теперь считаем «питоническими»: обобщенные операции с последовательностями, встроенные типы кортежа и отображения, структу - рирование кода с помощью отступов, строгая типизация без объявления пере- менных и др. Не случайно Python так дружелюбен к пользователю. Python унаследовал от ABC единообразную обработку последовательностей. Строки, списки, последовательности байтов, массивы, элементы XML, резуль- таты выборки из базы данных – все они имеют общий набор операций, вклю- чающий итерирование, получение среза, сортировку и конкатенацию. Зная о различных последовательностях, имеющихся в Python, вы не стане- те изобретать велосипед, а наличие общего интерфейса побуждает создавать API, которые согласованы с существующими и будущими типами последова- тельностей. Материал этой главы в основном относится к последовательностям вообще: от знакомых списков list до типов str и bytes, появившихся в Python 3. Здесь же будет рассмотрена специфика списков, кортежей, массивов и очередей, од- нако обсуждение строк Unicode и последовательностей байтов мы отложим до главы 4. Кроме того, здесь мы рассматриваем только готовые типы последо- вательностей, а о том, как создавать свои собственные, поговорим в главе 12. В этой главе будут рассмотрены следующие темы: списковые включения и основы генераторных выражений; использование кортежей как записей и как неизменяемых списков; распаковка последовательностей и последовательности-образцы; чтение и запись срезов; специализированные типы последовательностей, в частности массивы и очереди. 1 Leo Geurts, Lambert Meertens, Steven Pemberton «ABC Programmer’s Handbook», стр. 8 (Bosko Books).\nГлава 2 Массив последовательностей Как вы, наверное, заметили, некоторые из упомянутых операций одина- ково работают для текстов, списков и таблиц. Для текстов, списков и таб- лиц имеется обобщенное название «ряд» […]. Команда FOR также едино- образно применяется ко всем рядам. – Leo Geurts, Lambert Meertens, Steven Pembertonm, «ABC Programmer’s Handbook»1 До создания Python Гвидо принимал участие в разработке языка ABC. Это был растянувшийся на 10 лет исследовательский проект по проектированию среды программирования для начинающих. В ABC первоначально появились многие идеи, которые мы теперь считаем «питоническими»: обобщенные операции с последовательностями, встроенные типы кортежа и отображения, структу - рирование кода с помощью отступов, строгая типизация без объявления пере- менных и др. Не случайно Python так дружелюбен к пользователю. Python унаследовал от ABC единообразную обработку последовательностей. Строки, списки, последовательности байтов, массивы, элементы XML, резуль- таты выборки из базы данных – все они имеют общий набор операций, вклю- чающий итерирование, получение среза, сортировку и конкатенацию. Зная о различных последовательностях, имеющихся в Python, вы не стане- те изобретать велосипед, а наличие общего интерфейса побуждает создавать API, которые согласованы с существующими и будущими типами последова- тельностей. Материал этой главы в основном относится к последовательностям вообще: от знакомых списков list до типов str и bytes, появившихся в Python 3. Здесь же будет рассмотрена специфика списков, кортежей, массивов и очередей, од- нако обсуждение строк Unicode и последовательностей байтов мы отложим до главы 4. Кроме того, здесь мы рассматриваем только готовые типы последо- вательностей, а о том, как создавать свои собственные, поговорим в главе 12. В этой главе будут рассмотрены следующие темы: списковые включения и основы генераторных выражений; использование кортежей как записей и как неизменяемых списков; распаковка последовательностей и последовательности-образцы; чтение и запись срезов; специализированные типы последовательностей, в частности массивы и очереди. 1 Leo Geurts, Lambert Meertens, Steven Pemberton «ABC Programmer’s Handbook», стр. 8 (Bosko Books).\n--- Страница 48 ---\nчтО нОвОг О в этОй главе Самое важное новшество в этой главе – раздел «Сопоставление с последо- вательностями-образцами». Это первое знакомство с новым механизмом сопоставления с образцами, появившимся в Python 3.10, на страницах дан- ной книги. Другие изменения – не столько новшества, сколько улучшения первого из- дания: новая диаграмма и описание внутреннего механизма последовательно- стей, в котором противопоставляются контейнеры и плоские последова- тельности; краткое сравнение характеристик производительности и потребления памяти классов list и tuple ; подводные камни, связанные с изменяемыми элементами, и как их об- наружить в случае необходимости. Я перенес рассмотрение именованных кортежей в раздел «Классические именованные кортежи» главы 5, где они сравниваются с typing.NamedTuple и @dataclass . Чтобы расчистить место для нового материала и не увеличивать объем книги сверх разумного, раздел «Средства работы с упо- рядоченными последовательностями в модуле bisect», присут - ствовавший в первом издании, теперь оформлен в виде статьи на сопроводительном сайте fluentpython.com. ОБщие Сведения О вСтрОенных пОСледОвательнОС тях Стандартная библиотека предлагает богатый выбор типов последовательно- стей, реализованных на C: Контейнерные последовательности Позволяют хранить элементы разных типов, в т. ч. вложенные контейнеры. Примерами могут служить list, tuple и collections.deque . Плоские последовательности Позволяют хранить элементы только одного типа. Примерами могут слу- жить str, bytes и array.array . В контейнерных последовательностях хранятся ссылки на объекты любого типа, тогда как в плоских последовательностях – сами значения прямо в па- мяти, занятой последовательностью, а не как отдельные объекты Python. См. рис. 2.1. Общие сведения о встроенных последовательностях  49\n--- Страница 49 ---\narray('d', [9.46,2.08. 4.29]) (9.46, 'cat', [2.08. 4.29]) 9.46 9.462.084.29 'cat' 2.08 4.29 Рис. 2.1. Упрощенные диаграммы размещения кортежа и массива в памяти (тот и другой содержат три элемента). Закрашенные ячейки представляют заголовок объекта Python в па- мяти – пропорции не соблюдены. В кортеже хранится массив ссылок на элементы. Каждый элемент – отдельный объект Python, быть может, содержащий ссылки на другие объекты, скажем список из двух элементов. Напротив, массив в Python – это единственный объект, в котором хранится C-массив трех чисел типа double Поэтому плоские последовательности компактнее, но могут содержать только значения примитивных машинных типов, например байты, целые чис- ла и числа с плавающей точкой. Каждый объект Python, находящийся в памяти, имеет заголовок с метаданными. У простейшего объекта, float, имеется поле зна- чения и два поля метаданных: ob_refcnt : счетчик ссылок на объект; ob_type: указатель на тип объекта; ob_fval: число типа double (в смысле C), в котором хранится значение с плавающей точкой. В 64-разрядной сборке Python каждое из этих полей занимает 8 байт. Потому-то массив float гораздо компактнее, чем кортеж float: массив – это один объект, хранящий сами значения с пла- вающей точкой, а кортеж состоит из нескольких объектов: сам кортеж и все содержащиеся в нем объекты типа float. Последовательности можно также классифицировать по признаку изменя- емости: Изменяемые последовательности Например, list, bytearray, array.array и collections.deque . Неизменяемые последовательности Например, tuple, str и bytes. На рис. 2.2 показано, что изменяемые последовательности наследуют от не- изменяемых все методы и реализуют несколько дополнительных. Встроенные 50  Массив последовательностей\n--- Страница 50 ---\nконкретные типы последовательностей не являются подклассами показанных на рисунке абстрактных базовых классов (ABC) Sequence и MutableSequence . На са- мом деле они являются виртуальными подклассами, зарегистрированными в этих ABC, как мы увидим в главе 13. Будучи виртуальными подклассами, tuple и list проходят следующие тесты: >>> from collections import abc >>> issubclass(tuple, abc.Sequence) True >>> issubclass(list, abc.MutableSequence) True * Появилось в Python 3.6 Рис. 2.2. Упрощенная UML-диаграмма нескольких классов из модуля collections.abc суперклассы показаны слева, стрелки ведут от подклассов к суперклассам, курсивом набраны имена абстрактных классов и абстрактных методов) Помнить об этих общих характеристиках – изменяемый и неизменяемый, контейнерная и плоская последовательность – полезно для экстраполяции знаний об одних последовательностях на другие. Самый фундаментальный тип последовательности – список list, изменяе- мый контейнер. Не сомневаюсь, что вы уверенно владеете списками, поэтому перейдем прямо к списковому включению (list comprehension), эффективно- му способу построения списков, который недостаточно широко используется из-за незнакомого синтаксиса. Овладение механизмом спискового включения открывает двери к генераторным выражениям, которые – среди прочего – мо- гут порождать элементы для заполнения последовательностей любого типа. То и другое обсуждается в следующем разделе. СпиСк ОвОе включение и генерат Орные выражения Чтобы быстро построить последовательность, можно воспользоваться списко- вым включением (если конечная последовательность – список) или генера- торным выражением (для всех прочих типов последовательностей). Если вы не пользуетесь этими средствами в повседневной работе, клянусь, вы упускае- те возможность писать код, который одновременно является и более быстрым, и более удобочитаемым. Если сомневаетесь насчет «большей удобочитаемости», читайте дальше. Я попробую вас убедить. Списковое включение и генераторные выражения  51\n--- Страница 51 ---\nМногие программисты для краткости называют списковое включение listcomp, а генераторное выражение – genexp. Я тоже иногда буду употреблять эти слова. Списковое включение и удобочитаемость Вот вам тест: какой код кажется более понятным – в примере 2.1 или 2.2? Пример 2.1. Построить список кодовых позиций Unicode по строке >>> symbols = '$¢£¥€¤' >>> codes = [] >>> for symbol in symbols: codes.append(ord(symbol)) >>> codes [36, 162, 163, 165, 8364, 164] Пример 2.2. Построить список кодовых позиций Unicode по строке с применением listcomp >>> symbols = '$¢£¥€¤' >>> codes = [ord(symbol) for symbol in symbols] >>> codes [36, 162, 163, 165, 8364, 164] Всякий, кто хоть немного знаком с Python, сможет прочитать пример 2.1. Но после того, как я узнал о списковом включении, пример 2.2 стал казаться мне более удобочитаемым, потому что намерение программиста в нем выра- жено отчетливее. Цикл for можно использовать с самыми разными целями: просмотр последо- вательности для подсчета или выборки элементов, вычисление агрегатов (сум- мы, среднего) и т. д. Так, код в примере 2.1 строит список. А у спискового включе- ния только одна задача – построить новый список, ничего другого оно не умеет. Разумеется, списковое включение можно использовать и во вред, так что код станет абсолютно непонятным. Я встречал код на Python, в котором listcomp’ы применялись просто для повторения блока кода ради его побочного эффекта. Если вы ничего не собираетесь делать с порожденным списком, то не поль- зуйтесь этой конструкцией. Кроме того, не переусердствуйте: если списковое включение занимает больше двух строчек, то, быть может, лучше разбить его на части или переписать в виде старого доброго цикла for. Действуйте по си- туации: в Python, как и в любом естественном языке, не существует твердых и однозначных правил для написания ясного текста. Замечание о синтаксисе В программе на Python переход на другую строку внутри пар скобок [], {} и () игнорируется. Поэтому при построении много- строчных списков, списковых включений, генераторных выра- жений, словарей и прочего можно обходиться без косой черты \\ для экранирования символа новой строки, которая к тому же не работает, если после нее случайно поставлен пробел. Кроме того, если эти пары ограничителей используются для определе- 52  Массив последовательностей\n--- Страница 52 ---\nния литерала с последовательности элементов, перечисленных через запятую, то завершающая запятая игнорируется. Напри- мер, при записи многострочного спискового литерала будет муд- ро поставить после последнего элемента запятую, чтобы потом было проще добавить в конец списка дополнительные элементы и не загромождать лишними строками дельты двух файлов. Локальная область видимости внутри включений и генераторных выражений В Python 3.1 у списковых включений, генераторных выражений, а также у род- ственных им словарных и множественных включений имеется локальная область видимости для хранения переменных, которым присвоено значение в части for. Однако переменные, которым присвоено значение в операторе :=, остают - ся доступными и после возврата из включения или выражения – в отличие от локальных переменных, определенных в функции. В документе PEP 572 «Assignment Expressions» (https://peps.python.org/pep-0572/) область видимости оператора := определена как объемлющая функция, если только соответству - ющая переменная не является частью объявления global или nonlocal1. >>> x = 'ABC' >>> codes = [ord(x) for x in x] >>> x  'ABC' >>> codes [65, 66, 67] >>> codes = [last := ord(c) for c in x] >>> last  67 >>> c  Traceback (most recent call last): File \"<stdin>\", line 1, in <module> NameError: name 'c' is not defined  Значение x не перезаписано: оно по-прежнему привязано к 'ABC'.  last осталось таким, как прежде.  c пропала, она существовала только внутри listcomp. Списковое включение строит список из последовательности или любого другого итерируемого типа путем фильтрации и трансформации элементов. То же самое можно было бы сделать с помощью встроенных функций filter и map, но, как мы увидим ниже, удобочитаемость при этом пострадает. Сравнение спискового включения с map и filter Списковое включение может делать все, что умеют функции map и filter, без до- полнительных выкрутасов, связанных с использованием лямбда-выражений. Взгляните на пример 2.3. 1 Спасибо читательнице Тине Лапин, указавшей на этот момент. Списковое включение и генераторные выражения  53\n--- Страница 53 ---\nПример 2.3. Один и тот же список, построенный с помощью listcomp и композиции map и filter >>> beyond_ascii = [ord(s) for s in symbols if ord(s) > 127] >>> beyond_ascii [162, 163, 165, 8364, 164] >>> beyond_ascii = list(filter(lambda c: c > 127, map(ord, symbols))) >>> beyond_ascii [162, 163, 165, 8364, 164] Раньше я думал, что композиция map и filter быстрее эквивалентного списко- вого включения, но Алекс Мартелли показал, что это не так, по крайней мере в примере выше. В репозитории кода для этой книги имеется скрипт (https:// github.com/fluentpython/example-code-2e/blob/master/02-array-seq/listcomp_speed.py) 02-array-seq/listcomp_speed.py для сравнения времени работы listcomp и filter/map. В главе 7 я еще вернусь к функциям map и filter. А пока займемся использова- нием спискового включения для вычисления декартова произведения: списка, содержащего все кортежи, включающие по одному элементу из каждого спис- ка-сомножителя. Декартовы произведения С помощью спискового включения можно сгенерировать список элементов декартова произведения двух и более итерируемых объектов. Декартово про- изведение – это множество кортежей, включающих по одному элементу из каждого объекта-сомножителя. Длина результирующего списка равна произ- ведению длин входных объектов. См. рис. 2.3. Рис. 2.3. Декартово произведение пос ледовательности трех достоинств карт и последова- тельности четырех мастей дает последовательность, состоящую из двенадцати пар Пусть, например, требуется построить список футболок, доступных в двух цветах и трех размерах. В примере 2.4 показано, как это сделать с помощью listcomp. Результирующий список содержит шесть элементов.54  Массив последовательностей\n--- Страница 54 ---\nПример 2.4. Построение декартова произведения с помощью спискового включения >>> colors = ['black', 'white'] >>> sizes = ['S', 'M', 'L'] >>> tshirts = [(color, size) for color in colors for size in sizes]  >>> tshirts [('black', 'S'), ('black', 'M'), ('black', 'L'), ('white', 'S'), ('white', 'M'), ('white', 'L')] >>> for color in colors:  for size in sizes: print((color, size)) ('black', 'S') ('black', 'M') ('black', 'L') ('white', 'S') ('white', 'M') ('white', 'L') >>> tshirts = [(color, size) for size in sizes  for color in colors] >>> tshirts [('black', 'S'), ('white', 'S'), ('black', 'M'), ('white', 'M'), ('black', 'L'), ('white', 'L')]  Генерирует список кортежей, упорядоченный сначала по цвету, а затем по размеру.  Обратите внимание, что результирующий список упорядочен так, как если бы циклы for были вложены именно в том порядке, в котором указаны в списковом включении.  Чтобы расположить элементы сначала по размеру, а затем по цвету, нужно просто поменять местами предложения for; после переноса второго предло- жения for на другую строку стало понятнее, как будет упорядочен результат. В примере 1.1 (глава 1) показанное ниже выражение использовалось для инициализации колоды карт списком, состоящим из 52 карт четырех мастей по 13 карт в каждой: self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks] Списковые включения умеют делать всего одну вещь: строить списки. Для порождения последовательностей других типов придется обратиться к гене- раторным выражениям. В следующем разделе кратко описывается примене- ние генераторных выражений для построения последовательностей, отлич- ных от списков. Генераторные выражения Инициализацию кортежей, массивов и других последовательностей тоже мож - но начать с использования спискового включения, но genexp экономит па- мять, т. к. отдает элементы по одному, применяя протокол итератора, вместо того чтобы сразу строить целиком список для передачи другому конструктору. Синтаксически генераторное выражение выглядит так же, как списковое включение, только заключается не в квадратные скобки, а в круглые. Списковое включение и генераторные выражения  55\n--- Страница 55 ---\nНиже приведены простые примеры использования генераторных выраже- ний для построения кортежа и массива. Пример 2.5. Инициализация кортежа и массива с помощью генераторного выражения >>> symbols = '$¢£¥€¤' >>> tuple(ord(symbol) for symbol in symbols)  (36, 162, 163, 165, 8364, 164) >>> import array >>> array.array('I', (ord(symbol) for symbol in symbols))  array('I', [36, 162, 163, 165, 8364, 164])  Если генераторное выражение – единственный аргумент функции, то дуб- лировать круглые скобки необязательно.  Конструктор массива принимает два аргумента, поэтому скобки вокруг ге- нераторного выражения обязательны. Первый аргумент конструктора array определяет тип хранения чисел в массиве, мы вернемся к этому вопросу в разделе «Массивы» ниже. В примере 2.6 генераторное выражение используется для порождения де- картова произведения и последующей распечатки ассортимента футболок двух цветов и трех размеров. В отличие от примера 2.4, этот список футболок ни в какой момент не находится в памяти: генераторное выражение отдает циклу for по одному элементу. Если бы списки, являющиеся сомножителями декарто- ва произведения, содержали по 1000 элементов, то применение генераторно- го выражения позволило бы сэкономить память за счет отказа от построения спис ка из миллиона элементов с единственной целью его обхода в цикле for. Пример 2.6. Порождение декартова произведения генераторным выражением >>> colors = ['black', 'white'] >>> sizes = ['S', 'M', 'L'] >>> for tshirt in (f'{c} {s}' for c in colors for s in sizes):  print(tshirt) black S black M black L white S white M white L  Генераторное выражение отдает по одному элементу за раз; список, содер- жащий все шесть вариаций футболки, не создается. В главе 17 подробно объясняется, как работают генераторы. Здесь же мы только хотели показать использование генератор- ных выражений для инициализации последовательностей, от- личных от списков, а также для вывода последовательности, не хранящейся целиком в памяти. Перейдем теперь к следующему фундаментальному типу последовательно- стей в Python: кортежу. 56  Массив последовательностей\n--- Страница 56 ---\nкОртеж – не прОСтО неизменяемый СпиСОк В некоторых учебниках Python начального уровня кортежи описываются как «неизменяемые списки», но это описание неполно. У кортежей две функции: использование в качестве неизменяемых списков и в качестве записей с не- именованными полями. Второе применение иногда незаслуженно игнориру - ется, поэтому начнем с него. Кортежи как записи В кортеже хранится запись: каждый элемент кортежа содержит данные одного поля, а его позиция определяет семантику поля. Если рассматривать кортеж только как неизменяемый список, то количество и порядок элементов могут быть важны или не важны в зависимости от кон- текста. Но если считать кортеж набором полей, то количество элементов часто фиксировано, а порядок всегда важен. В примере 2.7 показано использование кортежей в качестве записей. От- метим, что во всех случаях переупорядочение кортежа уничтожило бы ин- формацию, потому что семантика каждого элемента данных определяется его позицией. Пример 2.7. Кортежи как записи >>> lax_coordinates = (33.9425, -118.408056)  >>> city, year, pop, chg, area = ('Tokyo', 2003, 32_450, 0.66, 8014)  >>> traveler_ids = [('USA', '31195855'), ('BRA', 'CE342567'),  ('ESP', 'XDA205856')] >>> for passport in sorted(traveler_ids):  print('%s/%s' % passport)  BRA/CE342567 ESP/XDA205856 USA/31195855 >>> for country, _ in traveler_ids:  print(country) USA BRA ESP  Широта и долгота международного аэропорта Лос-Анджелеса.  Данные о Токио: название, год, численность населения (в миллионах чело- век), динамика численности населения (в процентах), площадь (в км2).  Список кортежей вида ( код_страны, номер_паспорта ).  При обходе списка с каждым кортежем связывается переменная passport.  Оператор форматирования % понимает кортежи и трактует каждый эле- мент как отдельное поле.  Цикл for знает, как извлекать элементы кортежа по отдельности, это назы- вается «распаковкой». В данном случае второй элемент нас не интересует, поэтому он присваивается фиктивной переменной _. Кортеж – не просто неизменяемый список  57\n--- Страница 57 ---\nВообще говоря, использование _ в качестве фиктивной пере- менной – не более чем удобство. Это вполне допустимое имя переменной, пусть и странное. Однако в предложении match/case символ _ является метасимволом, который соответствует любо- му значению, но не привязан ни к какому. См. раздел «Сопостав- ление с последовательностью-образцом». А на консоли Python результат только что выполненной команды присваивается пе- ременной _, если только он не равен None. Мы часто рассматриваем записи как структуры данных с именованными поля- ми. В главе 5 показаны два способа создания кортежей с именованными полями. Но зачастую нет необходимости создавать класс только для того, чтобы по- именовать поля, особенно если мы применяем распаковку и не используем индексы для доступа к полям. В примере 2.7 мы в одном предложении при- своили кортеж ('Tokyo', 2003, 32450, 0.66, 8014) совокупности переменных city, year, pop, chg, area. Затем оператор % присвоил каждый элемент кортежа passport соответствующему спецификатору в форматной строке, переданной функции print. То и другое – примеры распаковки кортежа. Термин распаковка кортежа питонисты употребляют часто, но все большее распространение получает термин распаковка итери- руемого объекта, как, например, в заголовке документа PEP 3132 «Extended Iterable Unpacking» (https://peps.python.org/pep-3132/). В разделе «Распаковка последовательностей и итерируемых объектов» сказано гораздо больше о распаковке не только корте- жей, но и вообще последовательностей и итерируемых объектов. Теперь перейдем к рассмотрению класса tuple как неизменяемого варианта класса list. Кортежи как неизменяемые списки Интерпретатор Python и стандартная библиотека широко используют кортежи в роли неизменяемых списков, и вам стоит последовать их примеру. У такого использования есть два важных преимущества: Ясность Видя в коде кортеж, мы точно знаем, что его длина никогда не изменится. Производительность Кортеж потребляет меньше памяти, чем список той же длины, и позволяет интерпретатору Python выполнить некоторые оптимизации. Однако не забывайте, что неизменность кортежа относится только к храня- щимся в нем ссылкам – их нельзя ни удалить, ни изменить. Но если какая-то ссылка указывает на изменяемый объект и этот объект будет изменен, то зна- чение кортежа изменится. В следующем фрагменте иллюстрируется, что при этом происходит. Первоначально два кортежа, a и b, равны, и на рис. 2.4 пока- зано размещение кортежа b в памяти. 58  Массив последовательностей\n--- Страница 58 ---\n10 'alpha' 1 2(10, 'alpha', [1,2])tuple int int intlist str Рис. 2.4. Само содержимое кортежа неизменно, но это лишь означает, что хранящиеся в кортеже ссылки всегда указывают на одни и те же объекты. Однако если какой-то из этих объектов изменяемый, например является списком, то его содержимое может измениться Когда последний элемент b изменяется, b и a становятся различны: >>> a = (10, 'alpha', [1, 2]) >>> b = (10, 'alpha', [1, 2]) >>> a == b True >>> b[-1].append(99) >>> a == b False >>> b (10, 'alpha', [1, 2, 99]) Кортежи с изменяемыми элементами могут быть источником ошибок. В разделе «Что можно хешировать» мы увидим, что объект допускает хеширо- вание только тогда, когда его значение никогда не изменяется. Нехешируемый кортеж не может быть ни ключом словаря dict, ни элементом множества set. Если вы хотите явно узнать, является ли значение кортежа (или вообще лю- бого объекта) фиксированным, можете воспользоваться встроенной функцией hash для создания функции fixed вида: >>> def fixed(o): try: hash(o) except TypeError: return False return True >>> tf = (10, 'alpha', (1, 2)) >>> tm = (10, 'alpha', [1, 2]) >>> fixed(tf) True >>> fixed(tm) False Кортеж – не просто неизменяемый список  59\n--- Страница 59 ---\nМы еще вернемся к этому вопросу в разделе «Относительная неизменяе- мость кортежей». Несмотря на этот подвох, кортежи широко используются в качестве неиз- меняемых списков. Их преимущества в части производительности объяснил разработчик ядра Python Раймонд Хэттингер, отвечая на следующий вопрос, заданный на сайте StackOverflow: «Правда ли, что в Python кортежи эффек - тивнее списков?» (https://stackoverflow.com/questions/68630/are-tuples-more-efficient- than-lists-in-python/22140115#22140115). Вот краткое изложение его ответа. Чтобы вычислить кортежный литерал, компилятор Python генерирует байт- код для константы типа кортежа, состоящий из одной операции, а для спис- кового литерала сгенерированный байт-код сначала помещает каждый элемент в стек данных в виде отдельной константы, а затем строит список. Имея кортеж t, вызов tuple(t) просто возвращает ссылку на тот же t. Никакого копирования не производится. Напротив, если дан список l, то конструктор list(l) должен создать новую копию l. Благодаря фиксированной длине для экземпляра tuple выделяется ровно столько памяти, сколько необходимо. С другой стороны, для экземпля- ров list память выделяется с запасом, чтобы амортизировать стоимость последующих добавлений в список. Ссылки на элементы кортежа хранятся в массиве, находящемся в са- мой структуре кортежа, тогда как в случае списка хранится указатель на массив ссылок, размещенный где-то в другом месте. Косвенность необ- ходима, потому что когда список перестает помещаться в выделенной памяти, Python должен перераспределить память для массива ссылок, добавив места. Дополнительный уровень косвенности снижает эффек - тивность процессорных кешей. Сравнение методов кортежа и списка При использовании типа tuple в качестве неизменяемого варианта типа list полезно знать, насколько они похожи. Из табл. 2.1 видно, что tuple поддержи- вает все методы list, не связанные с добавлением или удалением элементов, за одним исключением – у кортежа нет метода __reversed__ . Но это просто опти- мизация; вызов reversed(my_tuple) работает и без него. Таблица 2.1. Методы и атрибуты списка и кортежа (для краткости методы, унаследованные от object, опущены) list tuple s.__add__(s2) ●●s + s2 – конкатенация s.__iadd__(s2) ● s += s2 – конкатенация на месте s.append(e) ● Добавление элемента в конец списка s.clear() ● Удаление всех элементов s.__contains__(e) ●●e входит в s s.copy() ● Поверхностная копия списка s.count(e) ●● Подсчет числа вхождений элемента60  Массив последовательностей\n--- Страница 60 ---\nlist tuple s.__delitem__(p) ● Удаление элемента в позиции p s.extend(it) ● Добавление в конец списка элементов из ите- рируемого объекта it s.__getitem__(p) ●●s[p] – получение элемента в указанной пози- ции s.__getnewargs__() ● Для поддержки оптимизированной сериализа- ции с помощью pickle s.index(e) ●● Поиск позиции первого вхождения e s.insert(p, e) ● Вставка элемента e перед элементом в позиции p s.__iter__() ●● Получение итератора s.__len__() ●●len(s) – количество элементов s.__mul__(n) ●●s * n – кратная конкатенация s.__imul__(n) ● s *= n – кратная конкатенация на месте s.__rmul__(n) ●●n * s – инверсная кратная конкатенацияa s.pop([p]) ● Удалить и вернуть последний элемент или эле- мент в позиции p, если она задана s.remove(e) ● Удалить первое вхождение элемента e, задан- ного своим значением s.reverse() ● Изменить порядок элементов на противополож - ный на месте s.__reversed__() ● Получить итератор для перебора элементов от конца к началу s.__setitem__(p, e) ● s[p] = e – поместить e в позицию p вместо на- ходящегося там элементаb s.sort([key], [reverse]) ● Отсортировать элементы на месте с факульта- тивными аргументами key и reverse a Инверсные операторы рассматриваются в главе 16. b Также используется для перезаписывания последовательности. См. раздел «Присваива- ние срезам». Теперь перейдем к важной для идиоматического программирования на Python теме: распаковке кортежа, списка и итерируемого объекта. раСпак Овка пОСледОвательнОС тей и итерируемых ОБъект Ов Распаковка важна, потому что позволяет избежать ненужного и чреватого ошибками использования индексов для извлечения элементов из последова- тельностей. Кроме того, распаковка работает, когда источником данных явля- ется любой итерируемый объект, включая итераторы, которые вообще не под-Окончание табл. 2.1 Распаковка последовательностей и итерируемых объектов  61\n--- Страница 61 ---\nдерживают индексной нотации ([]). Единственное требование – итерируемый объект должен отдавать лишь один элемент на каждую переменную на при- нимающей стороне, если только не используется звездочка (*) для получения всех лишних элементов (см. раздел «Использование * для выборки лишних элементов»). Самая очевидная форма распаковки кортежа – параллельное присваивание, т. е. присваивание элементов итерируемого объекта кортежу переменных, как показано в следующем примере: >>> lax_coordinates = (33.9425, -118.408056) >>> latitude, longitude = lax_coordinates # распаковка >>> latitude 33.9425 >>> longitude -118.408056 Элегантное применение распаковки кортежа – обмен значений двух пере- менных без создания временной переменной: >>> b, a = a, b Другой пример – звездочка перед аргументом при вызове функции: >>> divmod(20, 8) (2, 4) >>> t = (20, 8) >>> divmod(*t) (2, 4) >>> quotient, remainder = divmod(*t) >>> quotient, remainder (2, 4) Здесь также показано еще одно применение распаковки кортежа: возврат нескольких значений из функции способом, удобным вызывающей програм- ме. Например, функция os.path.split() строит кортеж (path, last_part) из пути в файловой системе: >>> import os >>> _, filename = os.path.split('/home/luciano/.ssh/id_rsa.pub') >>> filename 'id_rsa.pub' Еще один способ извлечь только некоторые элементы распаковываемого кортежа – воспользоваться символом *, как описано ниже. Использование * для выборки лишних элементов Определение параметров функции с помощью конструкции *args, позволяю- щей получить произвольные дополнительные аргументы, – классическая воз- можность Python. В Python 3 эта идея была распространена на параллельное присваивание: >>> a, b, *rest = range(5) >>> a, b, rest (0, 1, [2, 3, 4]) >>> a, b, *rest = range(3)62  Массив последовательностей\n--- Страница 62 ---\n>>> a, b, rest (0, 1, [2]) >>> a, b, *rest = range(2) >>> a, b, rest (0, 1, []) В этом контексте префикс * можно поставить только перед одной перемен- ной, которая, впрочем, может занимать любую позицию: >>> a, *body, c, d = range(5) >>> a, body, c, d (0, [1, 2], 3, 4) >>> *head, b, c, d = range(5) >>> head, b, c, d ([0, 1], 2, 3, 4) Распаковка с помощью * в вызовах функций и литеральных последовательностях В документе PEP 448 «Additional Unpacking Generalizations» (https://peps.python. org/pep-0448/) предложен более гибкий синтаксис распаковки итерируемого объекта, который лучше всего описан в главе «Что нового в Python 3.5» офи- циальной документации (https://docs.python.org/3/whatsnew/3.5.html#pep-0448- additional-unpacking-generalizations). В вызовах функций можно использовать * несколько раз: >>> def fun(a, b, c, d, *rest): return a, b, c, d, rest >>> fun(*[1, 2], 3, *range(4, 7)) (1, 2, 3, 4, (5, 6)) Символ * можно также использовать при определении литералов типа list, tuple и set, как показано в следующих примерах, взятых из официальной до- кументации: >>> *range(4), 4 (0, 1, 2, 3, 4) >>> [*range(4), 4] [0, 1, 2, 3, 4] >>> {*range(4), 4, *(5, 6, 7)} {0, 1, 2, 3, 4, 5, 6, 7} В PEP 448 введен аналогичный синтаксис для оператора **, с которым мы познакомимся в разделе «Распаковка отображений». Наконец, очень полезным свойством распаковки кортежа является возмож - ность работы с вложенными структурами. Распаковка вложенных объектов Объект, в который распаковывается выражение, может содержать вложенные объекты, например (a, b, (c, d)) , и Python правильно заполнит их, если значе- ние имеет такую же структуру вложенности. В примере 2.8 показана распаков- ка вложенного объекта в действии. Распаковка последовательностей и итерируемых объектов  63\n--- Страница 63 ---\nПример 2.8. Распаковка вложенных кортежей для доступа к долготе metro_areas = [ ('Tokyo', 'JP', 36.933, (35.689722, 139.691667)),  ('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889)), ('Mexico City', 'MX', 20.142, (19.433333, -99.133333)), ('New York-Newark', 'US', 20.104, (40.808611, -74.020386)), ('São Paulo', 'BR', 19.649, (-23.547778, -46.635833)), ] def main(): print(f'{\"\":15} | {\"latitude\":>9} | {\"longitude\":>9}') for name, _, _, (lat, lon) in metro_areas:  if lon <= 0:  print(f'{name:15} | {lat:9.4f} | {lon:9.4f}') if __name__ == '__main__': main()  Каждый кортеж содержит четыре поля, причем последнее – пара координат.  Присваивая последнее поле кортежу, мы распаковываем координаты.  Условие if longitude <= 0: отбирает только мегаполисы в Западном полушарии. Вот что печатает эта программа: | lat. | long. Mexico City | 19.4333 | -99.1333 New York-Newark | 40.8086 | -74.0204 Sao Paulo | -23.5478 | -46.6358 Распаковку можно производить и в список, но это редко имеет смысл. Вот единственный известный мне пример, когда такая операция полезна: если за- прос к базе данных возвращает ровно одну запись (например, когда в SQL-коде присутствует фраза LIMIT 1), то можно произвести распаковку и одновременно убедиться, что действительно возвращена одна запись: >>> [record] = query_returning_single_row() Если запись содержит только одно поле, то его можно получить сразу: >>> [[field]] = query_returning_single_row_with_single_field() Оба предложения можно было бы записать с помощью кортежей, но не забы- вайте об одной синтаксической тонкости: при записи одноэлементных корте- жей нужно добавлять в конце запятую. Поэтому в первом случае в левой части присваивания нужно написать (record,), а во втором – ((field,),) . В обоих случаях отсутствие запятой приводит к ошибке, о которой ничего не сообщается1. Теперь займемся сопоставлением с образцом – операцией, которая поддер- живает еще более мощные способы распаковки последовательностей. СОпОС тавление С пОСледОвательнОС тями-ОБразцами Самая заметная новая возможность в Python 3.10 – предложение match/case для сопоставления с образцом, описанное в документе PEP 634 «Structural Pattern Matching: Specification» (https://peps.python.org/pep-0634/). 1 Спасибо рецензенту Леонардо Рохаэлю за этот пример.64  Массив последовательностей\n--- Страница 64 ---\nРазработчик ядра Python Кэрол Уиллинг написал прекрас - ное введение в механизм сопоставления с образцом в разделе «Структурное сопоставление с образцом» главы «Что нового в Python 3.10» (https://docs.python.org/3.10/whatsnew/3.10.html) офи- циальной документации. Возможно, вам захочется прочитать этот краткий обзор. Я же решил разбить тему сопоставления с образцом на части и поместить их в разные главы в зависи- мости от типа образца: «Сопоставление с отображением-об- разцом» и «Сопоставление с экземпляром класса – образцом». Развернутый пример приведен в разделе «Сопоставление с об- разцом в lis.py: пример». Ниже приведен первый пример предложения match/case . Допустим, что мы проектируем робота, который принимает команды в виде последовательно- стей слов и чисел, например BEEPER 440 3 . Разбив команду на части и разобрав числа, мы должны получить сообщение вида ['BEEPER', 440, 3] . Для обработки таких сообщений можно воспользоваться показанным ниже методом. Пример 2.9. Метод из гипотетического класса Robot def handle_command(self, message): match message:  case ['BEEPER', frequency, times]:  self.beep(times, frequency) case ['NECK', angle]:  self.rotate_neck(angle) case ['LED', ident, intensity]:  self.leds[ident].set_brightness(ident, intensity) case ['LED', ident, red, green, blue]:  self.leds[ident].set_color(ident, red, green, blue) case _:  raise InvalidCommand(message)  Выражение после ключевого слова match называется субъектом. Это данные, которые Python попытается сопоставить с образцами в ветвях case.  С этим образцом сопоставляется любой субъект, являющийся последова- тельностью из трех элементов. Первый элемент должен быть равен 'BEEPER'. Второй и третий могут быть любыми, они связываются с переменными frequency и times именно в таком порядке.  С этим образцом сопоставляется любой субъект, содержащий два элемен- та, причем первый должен быть равен 'NECK'.  С этим образцом сопоставляется субъект, содержащий три элемента, пер- вым из которых должен быть 'LED'. Если число элементов не совпадает, то Python переходит к следующей ветви case.  Еще одна последовательность-образец, начинающаяся с 'LED', но теперь со- держащая пять элементов, включая константу 'LED'.  Это ветвь case по умолчанию. С ней сопоставляется любой субъект, для ко- торого не нашлось подходящего образца. Переменная _ специальная, как мы увидим ниже. Сопоставление с последовательностями-образцами  65\n--- Страница 65 ---\nНа первый взгляд, конструкция match/case похожа на предложение switch/ case в языке C – но это только на первый взгляд1. Основное улучшение match по сравнению с switch – деструктуризация, т. е. более развитая форма распаковки. Деструктуризация – новое слово в словаре Python, но оно часто встречается в документации по языкам, поддерживающим сопоставление с образцом, на- пример Scala и Elixir. Для начала в примере 2.10 показана часть примера 2.8, переписанная с ис- пользованием match/case . Пример 2.10. Деструктуризация вложенных кортежей (необходима версия Python ≥ 3.10) metro_areas = [ ('Tokyo', 'JP', 36.933, (35.689722, 139.691667)), ('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889)), ('Mexico City', 'MX', 20.142, (19.433333, -99.133333)), ('New York-Newark', 'US', 20.104, (40.808611, -74.020386)), ('São Paulo', 'BR', 19.649, (-23.547778, -46.635833)), ] def main(): print(f'{\"\":15} | {\"latitude\":>9} | {\"longitude\":>9}') for record in metro_areas: match record:  case [name, _, _, (lat, lon)] if lon <= 0:  print(f'{name:15} | {lat: 9.4f} | {lon: 9.4f}')  Субъектом в этом предложении match является record, т. е. каждый из корте- жей в списке metro_areas .  Ветвь case состоит из двух частей: образец и необязательное охранное усло- вие, начинающееся ключевым словом if. В общем случае сопоставление с последовательностью-образцом считается успешным, если: 1) субъект является последовательностью и; 2) субъект и образец содержат одинаковое число элементов и; 3) все соответственные элементы, включая вложенные, совпадают. Например, образец [name, _, _, (lat, lon)] в примере 2.10 сопоставляется с по- следовательностью из четырех элементов, последним элементом которой яв- ляется последовательность из двух элементов. Последовательности-образцы могут быть кортежами, списками или лю- бой комбинацией вложенных кортежей и списков, на синтаксисе это никак не сказывается: квадратные и круглые скобки в последовательности-образце означают одно и то же. Я записал образец в виде списка с вложенным 2-корте- жем, просто чтобы избежать повторения квадратных или круглых скобок, как в примере 2.10. 1 На мой взгляд, последовательность блоков if/elif/elif/ /else является достойной заменой switch/case . Она исключает такие проблемы, как случайное проваливание (https://en.wikipedia.org/wiki/Switch_statement#Fallthrough) и висячие ветви else (https:// en.wikipedia.org/wiki/Dangling_else), которые проектировщики некоторых языков не- критически скопировали из C, – через много лет было признано, что они являются источником бесчисленных ошибок.66  Массив последовательностей\n--- Страница 66 ---\nПоследовательность-образец может сопоставляться с большинством реаль- ных или виртуальных подклассов класса collections.abc.Sequence , за исключением лишь классов str, bytes и bytearray. Экземпляры классов str, bytes и bytearray не считаются после- довательностями в контексте match/case . Субъект match, принад- лежащий одному из этих типов, трактуется как «атомарное» значение – точно так же, как целое число 987 считается одним значением, а не последовательностью цифр. Обращение с этими типами как с последовательностями могло бы стать причиной ошибок из-за непреднамеренного совпадения. Если вы хотите рассматривать объект одного из этих типов как субъект последо- вательности, то преобразуйте его тип во фразе match. Например, так мы поступили с tuple(phone) в следующем фрагменте: match tuple(phone): case ['1', *rest]: # Северная Америка и страны Карибского бассейна case ['2', *rest]: # Африка и некоторые другие территории case ['3' | '4', *rest]: # Европа С последовательностями-образцами совместимы следующие типы из стан- дартной библиотеки: list memoryview array.array tuple range collections.deque В отличие от распаковки, образцы не деструктурируют итерируемые объек - ты, не являющиеся последовательностями (например, итераторы). Символ _ в образцах имеет специальный смысл: он сопоставляется с одним любым элементом в этой позиции, но никогда не связывается со значением сопоставленного элемента. Кроме того, _ – единственная переменная, которая может встречаться в образце более одного раза. Любую часть образца можно связать с переменной с помощью ключевого слова as: case [name, _, _, (lat, lon) as coord]: Субъект ['Shanghai', 'CN', 24.9, (31.1, 121.3)] сопоставляется с этим образцом, и при этом устанавливаются следующие переменные: Переменная Установленное значение name 'Shanghai' lat 31.1 lon 121.3 coord (31.1, 121.3) Образцы можно сделать более специфичными, добавив информацию о типе. Например, показанный ниже образец сопоставляется с последовательностью с такой же структурой вложенности, как в предыдущем примере, но первый Сопоставление с последовательностями-образцами  67\n--- Страница 67 ---\nэлемент должен быть экземпляром типа str и оба элемента 2-кортежа должны иметь тип float: case [str(name), _, _, (float(lat), float(lon))]: Выражения str(name) и float(lat) выглядят как вызовы кон- структоров, как было бы, если бы мы хотели преобразовать name и lat соответственно в типы str и float. Но в контексте образца эта синтаксическая конструкция производит проверку типа во время выполнения: образец сопоставится с 4-элементной по- следовательностью, в которой элемент 0 должен иметь тип str, а элемент 3 должен быть парой чисел типа float. Кроме того, str в позиции 0 будет связана с переменной name, а два числа типа float в позиции 3 – с переменными lat и lon соответственно. Та- ким образом, хотя str(name) заимствует синтаксис конструктора, в контексте образца семантика совершенно другая. Использова- ние произвольных классов в образцах рассматривается в разде- ле «Сопоставление с экземплярами классов – образцами». С другой стороны, если мы хотим произвести сопоставление произвольной последовательности-субъекта, начинающейся с str и заканчивающейся вло- женной последовательностью из двух float, то можем написать: case [str(name), *_, (float(lat), float(lon))]: Здесь *_ сопоставляется с любым числом элементов без привязки их к пере- менной. Если вместо *_ использовать *extra, то с переменной extra будет связан список list, содержащий 0 или более элементов. Необязательное охранное условие, начинающееся со слова if, вычисляется только в случае успешного сопоставления с образцом. При этом в условии мож - но ссылаться на переменные, встречающиеся в образце, как в примере 2.10: match record: case [name, _, _, (lat, lon)] if lon <= 0: print(f'{name:15} | {lat: 9.4f} | {lon: 9.4f}') Вложенный блок, содержащий предложение print, выполняется, только если сопоставление было успешным и охранное условие похоже на истину. Деструктуризация с помощью образцов настолько выразитель- на, что иногда даже наличие единственной ветви case может сделать код проще. Гвидо ван Россум собрал коллекцию приме- ров case/match , один из которых назвал «Очень глубокий итери- руемый объект и сравнение типа с выделением» (https://github. com/gvanrossum/ patma/blob/3ece6444ef70122876fd9f0099eb9490a2d 630df/EXAMPLES.md#case-6-a-very-deep-iterable-and-type-match-with- extraction). Нельзя сказать, что пример 2.10 чем-то лучше примера 2.8. Это просто два разных способа сделать одно и то же. В следующем примере мы покажем, как сопоставление с образцом позволяет писать более ясный, лаконичный и эф- фективный код. 68  Массив последовательностей\n--- Страница 68 ---\nСопоставление с последовательностями-образцами в интерпретаторе Питер Норвиг из Стэнфордского университета написал программу lis.py, ин- терпретатор подмножества диалекта Scheme языка программирования Lisp. Она состоит всего из 132 строк красивого и прекрасно читаемого кода на Python. Я взял код Норвига, распространяемый по лицензии MIT, и перенес его на Python 3.10, чтобы продемонстрировать сопоставление с образцом. В этом разделе мы сравним ключевую часть кода Норвига – ту, в которой использует - ся if/elif и распаковка, – с вариантом на основе match/case . Две главные функции в lis.py – parse и evaluate 1. Анализатор принимает вы- ражение Scheme со скобками и возвращает списки Python. Приведем два при- мера: >>> parse('(gcd 18 45)') ['gcd', 18, 45] >>> parse(''' (define double (lambda (n) (* n 2))) ''') ['define', 'double', ['lambda', ['n'], ['*', 'n', 2]]] Вычислитель принимает такого рода списки и выполняет их. В первом при- мере вызывается функция gcd с аргументами 18 и 45. Она вычисляет наиболь- ший общий делитель аргументов: 9. Во втором примере определена функция double с параметром n. Ее телом является выражение (* n 2). Результат вызова этой функции в Scheme – значение последнего выражения в ее теле. Нас здесь больше всего интересует деструктуризация последовательностей, поэтому я не стану вдаваться в действия вычислителя. Подробнее о работе lis. py можно прочитать в разделе «Сопоставление с образцом в lis.py: пример». В примере 2.11 показан слегка модифицированный вычислитель Норвига, в ко- тором я оставил только код для демонстрации последовательностей-образцов. Пример 2.11. Сопоставление с образцами без match/case def evaluate(exp: Expression, env: Environment) -> Any: \"Evaluate an expression in an environment.\" if isinstance(exp, Symbol): # ссылка на переменную return env[exp] # несколько строк опущено elif exp[0] == 'quote': # (quote exp) (_, x) = exp return x elif exp[ 0] == 'if': # (if test conseq alt) (_, test, consequence, alternative) = exp if evaluate(test, env): return evaluate(consequence, env) else: return evaluate(alternative, env) 1 Последняя называется eval в коде Норвига; я переименовал ее, чтобы избежать пута- ницы со встроенной в Python eval. Сопоставление с последовательностями-образцами  69\n--- Страница 69 ---\nelif exp[0] == 'lambda': # (lambda (parm…) body…) (_, parms, *body) = exp return Procedure(parms, body, env) elif exp[0] == 'define': (_, name, value_exp) = exp env[name] = evaluate(value_exp, env) # последующие строки опущены Обратите внимание, что в каждой ветви elif проверяется первый элемент списка, а затем список распаковывается и первый элемент игнорируется. Столь активное использование распаковки наводит на мысль, что Норвиг – большой поклонник сопоставления с образцом, но этот код был написан для Python 2 (хотя работает и с любой версией Python 3). Воспользовавшись предложением match/case в Python ≥ 3.10, мы сможем пе- реписать evaluate, как показано в примере 2.12. Пример 2.12. Сопоставление с образцом с применением match/case (необходима версия Python ≥ 3.10) def evaluate(exp: Expression, env: Environment) -> Any: \"Evaluate an expression in an environment.\" match exp: # несколько строк опущено case ['quote', x]:  return x case ['if', test, consequence, alternative]:  if evaluate(test, env): return evaluate(consequence, env) else: return evaluate(alternative, env) case ['lambda', [*parms], *body] if body:  return Procedure(parms, body, env) case ['define', Symbol() as name, value_exp]:  env[name] = evaluate(value_exp, env) # еще несколько строк опущено case _:  raise SyntaxError(lispstr(exp))  Сопоставляется, если субъект – двухэлементная последовательность, начи- нающаяся с 'quote'.  Сопоставляется, если субъект – четырехэлементная последовательность, начинающаяся с 'if'.  Сопоставляется, если субъект – последовательность из трех или более элемен- тов, начинающаяся с 'lambda'. Охранное условие гарантирует, что body не пусто.  Сопоставляется, если субъект – трехэлементная последовательность, начи- нающаяся с 'define'.  Рекомендуется всегда включать перехватывающую ветвь case. В данном случае если exp не сопоставляется ни с одним образцом, значит, выражение построено неправильно, и я возбуждаю исключение SyntaxError . Если бы перехватывающей ветви не было, то предложение ничего не сдела- ло бы, когда субъект не сопоставляется ни с одной ветвью case, т. е. имела бы место ошибка без каких бы то ни было сообщений.70  Массив последовательностей\n--- Страница 70 ---\nНорвиг сознательно опустил проверку ошибок в lis.py, чтобы сделать код понятнее. Сопоставление с образцом позволяет добавить больше проверок, сохранив удобочитаемость. Например, в образце 'define' оригинальный код не проверяет, что name является экземпляром класса Symbol, потому что это по- требовало бы включения блока if, вызова isinstance и дополнительного кода. Пример 2.12 короче и безопаснее, чем пример 2.11. Альтернативные образцы для лямбда-выражений В языке Scheme имеется синтаксическая конструкция lambda, в ней использует - ся соглашение о том, что суффикс … означает, что элемент может встречаться нуль или более раз: (lambda (parms…) body1 body2…) Простой образец для сопоставления с 'lambda' мог бы выглядеть так: case ['lambda', parms, *body] if body: Однако с ним сопоставляется любое значение в позиции parms, в частности первое 'x' в следующем недопустимом субъекте: ['lambda', 'x', ['*', 'x', 2]] В Scheme во вложенном списке после ключевого слова lambda находятся име- на формальных параметров функции, и это должен быть именно список, даже если он содержит всего один элемент. Список может быть и пустым, если функ - ция не имеет параметров, как random.random() в Python. В примере 2.12 я сделал образец 'lambda' более безопасным, воспользовав- шись вложенной последовательностью-образцом: case ['lambda', [*parms], *body] if body: return Procedure(parms, body, env) В каждой последовательности-образце * может встречаться только один раз. Здесь же мы имеем две последовательности: внешнюю и внутреннюю. Добавление символов [*] вокруг parms сделало образец более похожим на синтаксическую конструкцию Scheme, которую он призван обрабатывать, так что мы получаем дополнительную проверку правильности структуры. Сокращенный синтаксис для определения функции В Scheme имеется альтернативная синтаксическая конструкция define для соз- дания именованной функции без использования вложенного lambda, а именно: (define (name parm…) body1 body2…) За ключевым словом define должен следовать список, содержащий имя name новой функции и нуль или более имен параметров. После этого списка распо- лагается тело функции, содержащее одно или несколько выражений. Добавив в match следующие две строки, мы обработаем этот случай: case ['define', [Symbol() as name, *parms], *body] if body: env[name] = Procedure(parms, body, env) Я бы поместил эту ветвь case после другой ветви, сопоставляющей с define в примере 2.12. В данном случае порядок расположения двух ветвей неважен, Сопоставление с последовательностями-образцами  71\n--- Страница 71 ---\nпотому что никакой субъект не может сопоставляться сразу с обоими образ- цами. Действительно, в первоначальной ветви define второй элемент должен иметь тип Symbol, а в ветви для определения функции он должен быть последо- вательностью, начинающейся с Symbol. А теперь подумайте, сколько кода пришлось бы добавить, чтобы поддержать вторую синтаксическую конструкцию, включающую define, не прибегая к сопо- ставлению с образцом (пример 2.11). Предложение match делает куда больше, чем switch в C-подобных языках. Сопоставление с образцом – пример декларативного программирования: мы описываем, «что» хотим сопоставить, а не «как» это сделать. Форма кода повторяет форму данных, как видно из табл. 2.2. Таблица 2.2. Некоторые синтаксические конструкции Scheme и соответствующие им образцы Конструкция Scheme Последовательность-образец (quote exp) ['quote', exp] (if test conseq alt) ['if', test, conseq, alt] (lambda (parms…) body1 body2…) ['lambda', [*parms], *body] if body (define name exp) ['define', Symbol() as name, exp] (define (name parms…) body1 body2…) ['define', [Symbol() as name, *parms], *body] if body Надеюсь, эта переработка функции evaluate в коде Норвига с применением сопоставления с образцом убедила вас в том, что предложение match/case может сделать ваш код более понятным и безопасным. Мы еще вернемся к программе lis.py в разделе «Сопоставление с образцом в lis.py: пример», где рассмотрим полный код match/ case в функции evaluate. Если хотите больше узнать о программе Норвига lis.py, прочитайте его замечательную статью «How to Write a (Lisp) Interpreter (in Python))» (https://norvig.com/lispy.html). На этом завершается наше первое знакомство с распаковкой, деструктури- зацией и сопоставлением с последовательностями-образцами. Другие типы образцов будут рассмотрены в последующих главах. Каждый пишущий на Python программист знает о синтаксисе вырезания частей последовательности – s[a:b]. А мы сейчас рассмотрим менее известные факты об операции получения среза. пОлучение Среза Общей особенностью классов list, tuple, str и прочих типов последователь- ностей в Python является поддержка операций среза, которые обладают куда большими возможностями, чем многие думают. В этом разделе мы опишем использование дополнительных форм срезки. А о том, как реализовать их в пользовательских классах, поговорим в главе 12, не отступая от общей установки – в этой части рассматривать готовые классы, а в части III – создание новых. 72  Массив последовательностей\n--- Страница 72 ---\nПочему в срезы и диапазоны не включается последний элемент Принятое в Python соглашение не включать последний элемент в срезы и диа- пазоны соответствует индексации с нуля, принятой в Python, C и многих дру- гих языках. Приведем несколько полезных следствий из этого соглашения. Легко понять, какова длина среза или диапазона, если задана только ко- нечная позиция: и range(3), и my_list[:3] содержат три элемента. Легко вычислить длину среза или диапазона, если заданы начальная и конечная позиции, достаточно вычислить их разность stop - start . Легко разбить последовательность на две непересекающиеся части по любому индексу x: нужно просто взять my_list[:x] и my_list[x:] . Например: >>> l = [10, 20, 30, 40, 50, 60] >>> l[:2] # split at 2 [10, 20] >>> l[2:] [30, 40, 50, 60] >>> l[:3] # split at 3 [10, 20, 30] >>> l[3:] [40, 50, 60] Но самые убедительные аргументы в пользу этого соглашения изложил гол- ландский ученый, специализирующийся в информатике, Эдсгер Вибе Дейк - стра (см. последний пункт в списке дополнительной литературы). Теперь познакомимся ближе с тем, как Python интерпретирует нотацию среза. Объекты среза Хотя это не секрет, все же напомним, что в выражении s[a:b:c] задается шаг c, что позволяет вырезать элементы не подряд. Шаг может быть отрицательным, тогда элементы вырезаются от конца к началу. Поясним на примерах: >>> s = 'bicycle' >>> s[::3] 'bye' >>> s[::-1] 'elcycib' >>> s[::-2] 'eccb' Еще один пример был приведен в главе 1, где мы использовали выражение deck[12::13] для выборки всех тузов из неперетасованной колоды: >>> deck[12::13] [Card(rank='A', suit='spades'), Card(rank='A', suit='diamonds'), Card(rank='A', suit='clubs'), Card(rank='A', suit='hearts')] Нотация a:b:c допустима только внутри квадратных скобок, когда использу - ется в качестве оператора индексирования и порождает объект среза slice(a, b, c). В разделе «Как работает срезка» главы 12 мы увидим, что для вычисления выражения seq[start:stop:step] Python вызывает метод seq.__getitem__(slice(start, stop, step)) . Даже если вы никогда не будете сами реализовывать типы после- Получение среза  73\n--- Страница 73 ---\nдовательностей, знать об объектах среза полезно, потому что это позволяет присваивать срезам имена – по аналогии с именами диапазонов ячеек в элект- ронных таблицах. Пусть требуется разобрать плоский файл данных, например накладную, по- казанную в примере 2.13. Вместо того чтобы загромождать код «зашитыми» диапазонами, мы можем поименовать их. Посмотрим, насколько понятным становится при этом цикл for в конце примера. Пример 2.13. Строки из файла накладной >>> invoice = \"\"\" 0 6 40 52 55 1909 Pimoroni PiBrella $17.50 3 $52.50 1489 6mm Tactile Switch x20 $4.95 2 $9.90 1510 Panavise Jr. - PV-201 $28.00 1 $28.00 1601 PiTFT Mini Kit 320x240 $34.95 1 $34.95 \"\"\" >>> SKU = slice(0, 6) >>> DESCRIPTION = slice(6, 40) >>> UNIT_PRICE = slice(40, 52) >>> QUANTITY = slice(52, 55) >>> ITEM_TOTAL = slice(55, None) >>> line_items = invoice.split('\\n')[2:] >>> for item in line_items: print(item[UNIT_PRICE], item[DESCRIPTION]) $17.50 Pimoroni PiBrella $4.95 6mm Tactile Switch x20 $28.00 Panavise Jr. - PV-201 $34.95 PiTFT Mini Kit 320x240 Мы еще вернемся к объектам slice, когда дойдем до создания собственных коллекций в разделе «Vector, попытка № 2: последовательность, допускающая срезку» главы 12. А пока отметим, что с точки зрения пользователя у операции срезки есть ряд дополнительных возможностей, в частности многомерные срезы и нотация многоточия (…). Читайте дальше. Многомерные срезы и многоточие Оператор [] может принимать несколько индексов или срезов, разделенных за- пятыми. Специальные методы __getitem__ и __setitem__ , на которых основан опе- ратор [], просто принимают индексы, заданные в выражении a[i, j], в виде кор- тежа. Иначе говоря, для вычисления a[i, j] Python вызывает a.__getitem__((i, j)) . Это используется, например, во внешнем пакете NumPy, где для получения одного элемента двумерного массива numpy.ndarray применяется нотация a[i, j], а для получения двумерного среза – нотация a[m:n, k:l] . В примере 2.22 ниже будет продемонстрировано использование этой нотации. За исключением memoryview , в Python встроены только одномерные типы по- следовательностей, поэтому они поддерживают лишь один индекс или срез, а не кортеж1. 1 В разделе «Представления памяти» будет показано, что специально сконструирован- ные представления памяти могут иметь более одного измерения.74  Массив последовательностей\n--- Страница 74 ---\nМноготочие – записывается в виде трех отдельных точек, а не одного символа … (Unicode U+2026) – распознается анализатором Python как лексема. Это псев- доним объекта Ellipsis, единственного экземпляра класса ellipsis1. А раз так, то многоточие можно передавать в качестве аргумента функциям и использовать в качестве части спецификации среза, например f(a, , z) или a[i: ]. В NumPy … используется для сокращенного задания среза многомерного массива; напри- мер, если x – четырехмерный массив, то x[i, ] – то же самое, что x[i, :, :, :,] . Дополнительные сведения по этому вопросу можно найти в «Кратком введении в NumPy» (https://numpy.org/doc/stable/user/quickstart.html#indexing-slicing-and-iterating). На момент написания этой книги мне не было известно о применении объ- екта Ellipsis или многомерных индексов в стандартной библиотеке Python. Если найдете, дайте мне знать. Эти синтаксические средства существуют для поддержки пользовательских типов и таких расширений, как NumPy. Срезы полезны не только для выборки частей последовательности; они по- зволяют также модифицировать изменяемые последовательности на месте, т. е. не перестраивая с нуля. Присваивание срезу Изменяемую последовательность можно расширять, схлопывать и иными способами модифицировать на месте, применяя нотацию среза в левой части оператора присваивания или в качестве аргумента оператора del. Следующие примеры дают представление о возможностях этой нотации: >>> l = list(range(10)) >>> l [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] >>> l[2:5] = [20, 30] >>> l [0, 1, 20, 30, 5, 6, 7, 8, 9] >>> del l[5:7] >>> l [0, 1, 20, 30, 5, 8, 9] >>> l[3::2] = [11, 22] >>> l [0, 1, 20, 11, 5, 22, 9] 6 7 >>> l[2:5] = 100  Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: can only assign an iterable >>> l[2:5] = [100] >>> l [0, 1, 100, 22, 9]  Когда в левой части присваивания стоит срез, в правой должен находиться итерируемый объект, даже если он содержит всего один элемент. 1 Нет, я ничего не перепутал: имя класса ellipsis записывается строчными буквами, а его экземпляр – встроенный объект Ellipsis. Точно так же обстоит дело с классом bool и его экземплярами True и False. Получение среза  75\n--- Страница 75 ---\nВсе знают, что конкатенация – распространенная операция для последова- тельностей любого типа. В учебниках Python для начинающих объясняется, как использовать для этой цели операторы + и *, однако в их работе есть кое- какие тонкие детали, которые мы сейчас и обсудим. иСпОльзОвание + и * для пОСледОвательнОС тей Пишущие на Python программисты ожидают от последовательностей поддерж - ки операторов + и *. Обычно оба операнда + должны быть последовательностями одного типа, причем ни один из них не модифицируется, а создается новая по- следовательность того же типа, которая и является результатом конкатенации. Для конкатенации нескольких экземпляров одной последовательности ее мож - но умножить на целое число. При этом также создается новая последовательность: >>> l = [1, 2, 3] >>> l * 5 [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3] >>> 5 * 'abcd' 'abcdabcdabcdabcdabcd' Операторы + и * всегда создают новый объект и никогда не изменяют свои операнды. Остерегайтесь выражений вида a * n, где a – последователь- ность, содержащая изменяемые элементы, потому что резуль- тат может оказаться неожиданным. Например, при попытке инициа лизировать список списков my_list = [[]] * 3 получится список, содержащий три ссылки на один и тот же внутренний список, хотя вы, скорее всего, хотели не этого. В следующем разделе мы рассмотрим ловушки, которые подстерегают нас при попытке использовать * для инициализации списка списков. Построение списка списков Иногда требуется создать список, содержащий несколько вложенных списков, например чтобы распределить студентов по группам или представить клетки на игровой доске. Лучше всего это делать с помощью спискового включения, как показано в примере 2.14. Пример 2.14. Список, содержащий три списка длины 3, может представлять поле для игры в крестики и нолики >>> board = [['_'] * 3 for i in range(3)]  >>> board [['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']] >>> board[1][2] = 'X'  >>> board [['_', '_', '_'], ['_', '_', 'X'], ['_', '_', '_']]  Создать список из трех списков по три элемента в каждом. Взглянуть на его структуру.  Поместить крестик в строку 1, столбец 2 и проверить, что получилось. Соблазнительный, но ошибочный короткий путь показан в примере 2.15. 76  Массив последовательностей\n--- Страница 76 ---\nПример 2.15. Список, содержащий три ссылки на один и тот же список, бесполезен >>> weird_board = [['_'] * 3] * 3  >>> weird_board [['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']] >>> weird_board[1][2] = 'O'  >>> weird_board [['_', '_', 'O'], ['_', '_', 'O'], ['_', '_', 'O']]  Внешний список содержит три ссылки на один и тот же внутренний спи- сок. Пока не сделано никаких изменений, все кажется нормальным.  Поместив нолик в строку 1, столбец 2, мы обнаруживаем, что все строки ссылаются на один и тот же объект. Проблема в том, что код в примере 2.15, по существу, ведет себя так же, как следующий код: row = ['_'] * 3 board = [] for i in range(3): board.append(row)   Один и тот же объект row трижды добавляется в список board. C другой стороны, списковое включение из примера 2.14 эквивалентно та- кому коду: >>> board = [] >>> for i in range(3): row = ['_'] * 3  board.append(row) >>> board [['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']] >>> board[2][0] = 'X' >>> board  [['_', '_', '_'], ['_', '_', '_'], ['X', '_', '_']]  На каждой итерации строится новый список row, который добавляется в ко- нец списка board.  Как и положено, изменилась только строка 2. Если проблема или ее решение, представленные в этом разде- ле, вам не вполне понятны, не огорчайтесь. Глава 6 специально написана для того, чтобы прояснить механизм работы ссылок и изменяемых объектов, а также связанные с ним подводные камни. До сих пор мы говорили о простых операторах + и * в применении к по- следовательностям, но существуют также операторы += и *=, которые работают совершенно по-разному в зависимости от того, изменяема конечная последо- вательность или нет. Эти различия объяснены в следующем разделе. Использование + и * для последовательностей  77\n--- Страница 77 ---\nСОСтавнОе приСваивание пОСледОвательнОС тей Поведение операторов составного присваивания += и *= существенно зависит от типа первого операнда. Для простоты мы рассмотрим составное сложение (+=), но все сказанное равным образом относится также к оператору *= и другим операторам составного присваивания. За оператором += стоит специальный метод __iadd__ (аббревиатура «in-place addition» – сложение на месте). Но если метод __iadd__ не реализован, то Python вызывает метод __add__. Рассмотрим следующее простое выражение: >>> a += b Если объект a реализует метод __iadd__, то он и будет вызван. В случае из- меняемых последовательностей (например, list, bytearray, array.array ) a будет изменен на месте (результат получается такой же, как при вызове a.extend(b) ). Если же a не реализует __iadd__, то выражение a += b вычисляется так же, как a = a + b, т. е. сначала вычисляется a + b и получившийся в результате новый объект связывается с переменной a. Иными словами, идентификатор объек - та a остается тем же самым или становится другим в зависимости от наличия метода __iadd__. Вообще говоря, если последовательность изменяемая, то можно ожидать, что метод __iadd__ реализован и оператор += выполняет сложение на месте. В случае неизменяемых последовательностей такое, очевидно, невозможно. Сказанное об операторе += применимо также к оператору *=, который реа- лизован с помощью метода __imul__. Специальные методы __iadd__ и __imul__ об- суждаются в главе 16. Ниже демонстрируется применение оператора *= к из- меняемой и неизменяемой последовательностям: >>> l = [1, 2, 3] >>> id(l) 4311953800  >>> l *= 2 >>> l [1, 2, 3, 1, 2, 3] >>> id(l) 4311953800  >>> t = (1, 2, 3) >>> id(t) 4312681568  >>> t *= 2 >>> id(t) 4301348296   Идентификатор исходного списка.  После умножения список – тот же самый объект, в который добавлены но- вые элементы.  Идентификатор исходного кортежа.  В результате умножения создан новый кортеж. Кратная конкатенация неизменяемых последовательностей выполняется неэффективно, потому что вместо добавления новых элементов интерпрета-78  Массив последовательностей\n--- Страница 78 ---\nтор вынужден копировать всю конечную последовательность, чтобы создать новую с добавленными элементами1. Мы рассмотрели типичные случаи использования оператора +=. А в следу - ющем разделе обсудим интригующий случай, показывающий, что в действи- тельности означает «неизменяемость» в контексте кортежей. Головоломка: присваивание A += Попробуйте, не прибегая к оболочке, ответить на вопрос: что получится в ре- зультате вычисления двух выражений в примере 2.162? Пример 2.16. Загадка >>> t = (1, 2, [30, 40]) >>> t[2] += [50, 60] Что произойдет в результате? Какой ответ кажется вам правильным? 1. t принимает значение (1, 2, [30, 40, 50, 60]) . 3. Возбуждается исключение TypeError с сообщением о том, что объект 'tuple' не поддерживает присваивание. 3. Ни то, ни другое. 4. И то, и другое. Я был почти уверен, что правильный ответ b, но на самом деле правилен ответ d: «И то, и другое»! В примере 2.17 показано, как этот код выполняется в оболочке для версии Python 3.93. Пример 2.17. Неожиданный результат: элемент t2 изменился и возбуждено исключе- ние >>> t = (1, 2, [30, 40]) >>> t[2] += [50, 60] Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: 'tuple' object does not support item assignment >>> t (1, 2, [30, 40, 50, 60]) Сайт Online Python Tutor (http://www.pythontutor.com/) – прекрасный инстру - мент для наглядной демонстрации работы Python. На рис. 2.5 приведены два снимка экрана, демонстрирующих начальное и конечное состояния кортежа t после выполнения кода из примера 2.17. 1 Тип str – исключение из этого правила. Поскольку построение строки с помощью оператора += в цикле – весьма распространенная операция, в CPython этот случай оп- тимизирован. Экземпляры str создаются с запасом памяти, чтобы при конкатенации не приходилось каждый раз копировать всю строку. 2 Спасибо Леонардо Рохаэлю и Сезару Каваками, которые предложили эту задачу на Бразильской конференции по языку Python 2013 года. 3 Один читатель указал, что операцию из этого примера можно без ошибок выполнить с помощью выражения t[2].extend([50,60]) . Я это знаю, но цель примера – обсудить странное поведение оператора +=. Составное присваивание последовательностей  79\n--- Страница 79 ---\nРис. 2.5. Начальное и конечное состояния кортежа в задаче о присваивании (диаграммы сгенерированы на сайте Online Python Tutor) Изучение байт-кода, который Python генерирует для выражения s[a] += b (пример 2.18), показывает, что происходит на самом деле. Пример 2.18. Байт-код вычисления выражения s[a] += b >>> dis.dis('s[a] += b') 1 0 LOAD_NAME 0 (s) 3 LOAD_NAME 1 (a) 6 DUP_TOP_TWO 7 BINARY_SUBSCR  8 LOAD_NAME 2 (b) 11 INPLACE_ADD  12 ROT_THREE 13 STORE_SUBSCR  14 LOAD_CONST 0 (None) 17 RETURN_VALUE  Поместить значение s[a] на вершину стека ( TOS).  Выполнить TOS += b. Эта операция завершается успешно, если TOS ссылается на изменяемый объект (в примере 2.17 это список).  Выполнить присваивание s[a] = TOS . Эта операция завершается неудачно, если s – неизменяемый объект (в примере 2.17 это кортеж t). Это патологический случай – за 20 лет, что я пишу на Python, я ни разу не слышал, чтобы кто-то нарвался на такое поведение на практике. Но из этого примера я вынес три урока. Не стоит помещать изменяемые элементы в кортежи. Составное присваивание – не атомарная операция; мы только что виде- ли, как она возбуждает исключение, проделав часть работы. Изучить байт-код не так уж трудно, и часто это помогает понять, что происходит под капотом.80  Массив последовательностей\n--- Страница 80 ---\nПознакомившись с тонкостями использования операторов + и * для конка- тенации, сменим тему и обратимся еще к одной важной операции с последо- вательностями: сортировке. метОд list.sort и вСтрОенная функция sorted Метод list.sort сортирует список на месте, т. е. не создавая копию. Он возвра- щает None, напоминая, что изменяет объект-приемник1, а не создает новый список. Это важное соглашение в Python API: функции и методы, изменяющие объект на месте, должны возвращать None, давая вызывающей стороне понять, что изменился сам объект в противовес созданию нового. Аналогичное пове- дение демонстрирует, к примеру, функция random.shuffle , которая перетасовыва- ет изменяемую последовательность s на месте и возвращает None. У соглашения о возврате None в случае обновления на месте есть недостаток: такие методы невозможно соединить в це- почку. Напротив, методы, возвращающие новые объекты (например, все методы класса str), можно сцеплять, получая тем самым «текучий» интерфейс. Дополнительные сведения по этому вопросу см. в статье Википедии «Fluent interface» (http://en.wikipedia.org/wiki/Fluent_interface). C другой стороны, встроенная функция sorted создает и возвращает новый список. На самом деле она принимает любой итерируемый объект в качест- ве аргумента, в том числе неизменяемые последовательности и генераторы (см. главу 147). Но независимо от типа исходного итерируемого объекта sorted всегда возвращает новый список. И метод list.sort, и функция sorted принимают два необязательных имено- ванных аргумента: reverse Если True, то элементы возвращаются в порядке убывания (т. е. инвертиру - ется сравнение элементов). По умолчанию False. key Функция с одним аргументом, которая вызывается для каждого элемента и возвращает его ключ сортировки. Например, если при сортировке списка строк задать key=str.lower , то строки будут сортироваться без учета регистра, а если key=len, то по длине в символах. По умолчанию подразумевается тож- дественная функция (т. е. сравниваются сами элементы). Необязательный именованный параметр key можно также ис- пользовать совместно с встроенными функциями min() и max() и другими функциями из стандартной библиотеки (например, itertools.groupby() или heapq.nlargest() ). 1 Приемником называется объект, от имени которого вызывается метод, т. е. объект, связанный с переменной self в теле метода. Метод list.sort и встроенная функция sorted  81\n--- Страница 81 ---\nПримеры ниже иллюстрируют применение этих функций и именованных аргументов. Они также демонстрируют, что алгоритм сортировки в Python устойчивый (т. е. сохраняет относительный порядок элементов, признанных равными)1: >>> fruits = ['grape', 'raspberry', 'apple', 'banana'] >>> sorted(fruits) ['apple', 'banana', 'grape', 'raspberry']  >>> fruits ['grape', 'raspberry', 'apple', 'banana']  >>> sorted(fruits, reverse=True) ['raspberry', 'grape', 'banana', 'apple']  >>> sorted(fruits, key=len) ['grape', 'apple', 'banana', 'raspberry']  >>> sorted(fruits, key=len, reverse=True) ['raspberry', 'banana', 'grape', 'apple']  >>> fruits ['grape', 'raspberry', 'apple', 'banana']  >>> fruits.sort()  >>> fruits ['apple', 'banana', 'grape', 'raspberry']   Порождает новый список строк, отсортированный в алфавитном порядке2.  Инспекция исходного списка показывает, что он не изменился.  Это сортировка в обратном алфавитном порядке.  Новый список строк, отсортированный уже по длине. Поскольку алгоритм сортировки устойчивый, строки «grape» и «apple», обе длины 5, остались в том же порядке.  Здесь строки отсортированы в порядке убывания длины. Результат не яв- ляется инверсией предыдущего, потому что в силу устойчивости сорти- ровки «grape» по-прежнему оказывается раньше «apple».  До сих пор порядок исходного списка fruits не изменился.  Этот метод сортирует список на месте и возвращает None (оболочка не по- казывает это значение).  Теперь массив fruits отсортирован. По умолчанию строки в Python сортируются лексикографиче- ски по кодам символов. Это означает, что заглавные буквы в ко- дировке ASCII предшествуют строчным, а порядок сортировки не-ASCII символов вряд ли будет сколько-нибудь разумным. В разделе «Сортировка текста в кодировке Unicode» главы 4 рас- сматривается вопрос о том, как сортировать текст в порядке, ко- торый представляется человеку естественным. В отсортированной последовательности поиск производится очень эффек - тивно. Стандартный алгоритм двоичного поиска уже имеется в модуле bisect из стандартной библиотеки Python. Этот модуль включает также вспомогатель- 1 Основной алгоритм сортировки в Python называется в честь автора, Тима Петерса. Детали алгоритма Timsort обсуждаются во врезке «Поговорим» в конце этой главы. 2 Слова в этом примере отсортированы по алфавиту, потому что содержат только строчные буквы в кодировке ASCII. См. предупреждение после примера. 82  Массив последовательностей\n--- Страница 82 ---\nную функцию bisect.insort , которая гарантирует, что отсортированная последо- вательность такой и останется после вставки новых элементов. Иллюстриро- ванное введение в модуль bisect имеется в статье «Managing Ordered Sequences with Bisect» (https://www.fluentpython.com/extra/ordered-sequences-with-bisect/) на со- проводительном сайте fluentpython.com. Многое из описанного до сих пор относится к любым последовательностям, а не только к списками или кортежам. Программисты на Python иногда чрез- мерно увлекаются типом list просто потому, что он очень удобен, – знаю, сам грешен. Например, при работе со списками чисел лучше использовать масси- вы. Остаток этой главы посвящен альтернативам спискам и кортежам. кОгда СпиСОк не пОдхОдит Тип list гибкий и простой в использовании, но не всегда оптимален. Напри- мер, если требуется сохранить 10 миллионов чисел с плавающей точкой, то тип array будет гораздо эффективнее, поскольку в нем хранятся не полные объекты float, а только упакованные байты, представляющие их машинные значения, – как в массиве в языке C. С другой стороны, если вы часто добавляете и удаляе- те элементы из того или другого конца списка, стоит вспомнить о типе deque (двусторонняя очередь) – более эффективной структуре данных FIFO1. Если в программе много проверок на вхождение (например, item in my_collection ), то, возможно, в качестве типа my_collection сто- ит взять set, особенно если количество элементов велико. Мно- жества оптимизированы для быстрой проверки вхождения. Од- нако они не упорядочены и потому не являются последователь- ностями. Мы будем рассматривать множества в главе 3. Массивы Если список содержит только числа, то тип array.array эффективнее, чем list: он поддерживает все операции над изменяемыми последовательностями (вклю- чая .pop, .insert и .extend), а также дополнительные методы для быстрой загруз- ки и сохранения, например .frombytes и .tofile. Массив Python занимает столько же памяти, сколько массив C. Как показано на рис. 2.1, в массиве значений типа float хранятся не полноценные экземпляры этого типа, а только упакованные байты, представляющие их машинные значе- ния, – как в массиве double в языке C. При создании экземпляра array задается код типа – буква, определяющая, какой тип C использовать для хранения элементов. Например, код типа b соответствует типу C signed char , описывающему це- лые числа от –128 до 127. Если создать массив array('b') , то каждый элемент будет храниться в одном байте и интерпретироваться как целое число. Если последовательность чисел велика, то это позволяет сэкономить много памяти. А Python не даст записать в массив число, не соответствующее заданному типу. В примере 2.19 демонстрируется создание, сохранение и загрузка массива, содержащего 10 миллионов случайных чисел с плавающей точкой. 1 First in, first out (первым пришел, первым ушел) – поведение очереди, подразумева- емое по умолчанию. Когда список не подходит  83\n--- Страница 83 ---\nПример 2.19. Создание, сохранение и загрузка большого массива чисел с плавающей точкой >>> from array import array  >>> from random import random >>> floats = array('d', (random() for i in range(10**7)))  >>> floats[-1]  0.07802343889111107 >>> fp = open('floats.bin', 'wb') >>> floats.tofile(fp)  >>> fp.close() >>> floats2 = array('d')  >>> fp = open('floats.bin', 'rb') >>> floats2.fromfile(fp, 10**7)  >>> fp.close() >>> floats2[-1]  0.07802343889111107 >>> floats2 == floats  True  Импортировать тип array.  Создать массив чисел с плавающей точкой двойной точности (код типа 'd') из любого итерируемого объекта – в данном случае генераторного выра- жения.  Прочитать последнее число в массиве.  Сохранить массив в двоичном файле.  Создать пустой массив чисел с плавающей точкой двойной точности.  Прочитать 10 миллионов чисел из двоичного файла.  Прочитать последнее число в массиве.  Проверить, что содержимое обоих массивов совпадает. Как видим, пользоваться методами array.tofile и array.fromfile легко. Выпол- нив этот пример, вы убедитесь, что и работают они очень быстро. Несложный эксперимент показывает, что для загрузки методом array.fromfile 10 миллионов чисел с плавающей точкой двойной точности из двоичного файла, созданного методом array.tofile , требуется примерно 0,1 с. Это почти в 60 раз быстрее чте- ния из текстового файла, когда требуется разбирать каждую строку встроенной функцией float. Метод array.tofile работает примерно в 7 раз быстрее, чем запись чисел с плавающей точкой в текстовый файл по одному на строку. Кроме того, размер двоичного файла с 10 миллионами чисел двойной точности составляет 80 000 000 байт (по 8 байт на число, с нулевыми накладными расходами), а тек - стового файла с теми же данными – 181 515 739 байт. Для частных случаев числовых массивов, представляющих такие двоичные данные, как растровые изображения, в Python имеются типы bytes и bytearray, которые мы обсудим в главе 4. Завершим этот раздел о массивах таблицей 2.3, в которой сравниваются свойства типов list и array.array .84  Массив последовательностей\n--- Страница 84 ---\nТаблица 2.3. Методы и атрибуты типов list и array (нерекомендуемые методы массива, а также унаследованные от object, для краткости опущены) list array s.__add__(s2) ●●s + s2 – конкатенация s.__iadd__(s2) ●●s += s2 – конкатенация на месте s.append(e) ●● Добавление элемента в конец списка s.byteswap() ● Перестановка всех байтов в массиве с целью из- менения машинной архитектуры s.clear() ● Удаление всех элементов s.__contains__(e) ●●e входит в s s.copy() ● Поверхностная копия списка s.__copy__() ● Поддержка метода copy.copy s.count(e) ●● Подсчет числа вхождений элемента s.__deepcopy__() ● Оптимизированная поддержка метода copy.deepcopy s.__delitem__(p) ●● Удаление элемента в позиции p s.extend(it) ●● Добавление в конец списка элементов из итериру- емого объекта it s.frombytes(b) ● Добавление в конец элементов из последователь- ности байтов, интерпретируемых как упакованные машинные слова s.fromfile(f, n) ● Добавление в конец n элементов из двоичного файла f, интерпретируемых как упакованные ма- шинные слова s.fromlist(l) ● Добавление в конец элементов из списка; если хотя бы один возбуждает исключение TypeError , то не добавляется ничего s.__getitem__(p) ●●s[p] – получение элемента в указанной позиции s.index(e) ●● Поиск позиции первого вхождения e s.insert(p, e) ● Вставка элемента e перед элементом в позиции p s.itemsize ● Размер каждого элемента массива в байтах s.__iter__() ●● Получение итератора s.__len__() ●●len(s) – количество элементов s.__mul__(n) ●●s * n – кратная конкатенация s.__imul__(n) ● s *= n – кратная конкатенация на месте s.__rmul__(n) ●●n * s – инверсная кратная конкатенацияa s.pop([p]) ●● Удалить и вернуть последний элемент или элемент в позиции p, если она задана s.remove(e) ●● Удалить первое вхождение элемента e, заданного своим значением s.reverse() ●● Изменить порядок элементов на противоположный на месте Когда список не подходит  85\n--- Страница 85 ---\nlist array s.__reversed__() ●● Получить итератор для перебора элементов от конца к началу s.__setitem__(p, e) ●●s[p] = e – поместить e в позицию p вместо находя- щегося там элемента s.sort([key], [reverse]) ● Отсортировать элементы на месте с факультативны- ми аргументами key и reverse s.tobytes() ● Сохранение элементов как упакованных машинных слов в объекте типа bytes s.tofile(f) ● Сохранение элементов как упакованных машинных слов в двоичном файле f s.tolist() ● Сохранение элементов в виде числовых объектов в объекте list s.typecode ● Односимвольная строка, описывающая C-тип эле- ментов a Инверсные операторы рассматриваются в главе 16. В версии Python 3.10 у типа array нет метода сортировки на мес- те, аналогичного list.sort() . Чтобы отсортировать массив, вос- пользуйтесь встроенной функцией sorted, которая перестраива- ет массив: a = array.array(a.typecode, sorted(a)) Чтобы поддерживать массив в отсортированном состоянии при вставке элементов, пользуйтесь функцией bisect.insort . Если вы часто работаете с массивами и ничего не знаете о типе memoryview , то много теряете в жизни. Читайте следующий раздел. Представления областей памяти Встроенный класс memoryview – это тип последовательности в общей памяти, который позволяет работать со срезами массивов, ничего не копируя. Он по- явился под влиянием библиотеки NumPy (которую мы обсудим ниже в разделе «NumPy»). Трэвис Олифант (Travis Oliphant), основной автор NumPy, на вопрос «Когда использовать memoryview?» (https://stackoverflow.com/questions/4845418/ when-should-a-memoryview-be-used/) отвечает так: По существу, memoryview – это обобщенная структура массива NumPy, встроенная в сам язык Python (но без математических операций). Она позволяет разделять память между структурами данных (например, изо- бражениями в библиотеке PIL, базами данных SQLlite, массивами NumPy и т. д.) без копирования. Для больших наборов данных это очень важно. С применением нотации, аналогичной той, что используется в модуле array, метод memoryview.cast позволяет изменить способ чтения и записи нескольких байтов в виде блоков, не перемещая ни одного бита. Метод memoryview.cast воз- вращает другой объект memoryview , занимающий то же самое место в памяти. Окончание табл. 2.386  Массив последовательностей\n--- Страница 86 ---\nВ примере 2.20 показано, как создать различные представления одного и того же массива 6 байт, чтобы его можно было рассматривать как матри- цу 2×3 или 3×2. Пример 2.20. Обращение с 6 байтами в памяти как с представлениями матриц 1×6, 2×3 или 3×2 >>> from array import array >>> octets = array('B', range(6))  >>> m1 = memoryview(octets)  >>> m1.tolist() [0, 1, 2, 3, 4, 5] >>> m2 = m1.cast('B', [2, 3])  >>> m2.tolist() [[0, 1, 2], [3, 4, 5]] >>> m3 = m1.cast('B', [3, 2])  >>> m3.tolist() [[0, 1], [2, 3], [4, 5]] >>> m2[1,1] = 22  >>> m3[1,1] = 33  >>> octets  array('B', [0, 1, 2, 33, 22, 51])  Построить массив из шести байт (код типа 'B').  Построить по этому массиву memoryview , а затем экспортировать его как спи- сок.  Построить новое memoryview по предыдущему, но с 2 строками и 3 столбцами.  Еще одно memoryview , на этот раз с 3 строками и 2 столбцами.  Перезаписать байт в строке 1, столбце 1 представления m2 значением 22.  Перезаписать байт в строке 1, столбце 1 представления m3 значением 33.  Отобразить исходный массив, доказав тем самым, что octets, m1, m2 и m3 ис- пользовали одну и ту же память. Впечатляющую мощь memoryview можно использовать и во вред. В примере 2.21 показано, как изменить один байт в массиве 16-разрядных целых чисел. Пример 2.21. Изменение значения элемента массива путем манипуляции одним из его байтов >>> numbers = array.array('h', [-2, -1, 0, 1, 2]) >>> memv = memoryview(numbers)  >>> len(memv) 5 >>> memv[0]  -2 >>> memv_oct = memv.cast('B')  >>> memv_oct.tolist()  [254, 255, 255, 255, 0, 0, 1, 0, 2, 0] >>> memv_oct[5] = 4  >>> numbers array('h', [-2, -1, 1024, 1, 2])   Построить объект memoryview по массиву пяти целых чисел типа short signed (код типа 'h'). Когда список не подходит  87\n--- Страница 87 ---\n memv видит те же самые 5 элементов массива.  Создать объект memv_oct, приведя элементы memv к коду типа ‘B’ (unsigned char ).  Экспортировать элементы memv_oct в виде списка для инспекции.  Присвоить значение 4 байту со смещением 5.  Обратите внимание, как изменились числа: двухбайтовое число, в кото- ром старший байт равен 4, равно 1024. Пример инспекции memoryview с помощью пакета struct можно найти на сайте fluentpython.com в статье «Parsing binary records with struct» (https://www.fluentpython.com/extra/parsing-binary-struct/). А пока отметим, что для нетривиальных численных расчетов с применени- ем массивов следует использовать библиотеки NumPy. Рассмотрим их прямо сейчас. NumPy В этой книге я стараюсь ограничиваться тем, что уже есть в стандартной биб- лиотеке Python, и показывать, как извлечь из этого максимум пользы. Но биб- лиотека NumPy – это такое чудо, что заслуживает небольшого отступления. Именно чрезвычайно хорошо развитым операциям с массивами и матри- цами в NumPy язык Python обязан признанием со стороны ученых, занимаю- щихся вычислительными приложениями. В NumPy реализованы типы много- мерных однородных массивов и матриц, в которых можно хранить не только числа, но и определенные пользователем записи. При этом предоставляются эффективные поэлементные операции. Библиотека SciPy, написанная поверх NumPy, предлагает многочисленные вычислительные алгоритмы, относящиеся к линейной алгебре, численному анализу и математической статистике. SciPy работает быстро и надежно, по- тому что в ее основе лежит широко используемый код на C и Fortran из ре- позитория Netlib Repository (http://www.netlib.org). Иными словами, SciPy дает ученым лучшее из обоих миров: интерактивную оболочку и высокоуровневые API, присущие Python, и оптимизированные функции обработки числовой ин- формации промышленного качества, написанные на C и Fortran. В качестве очень простой демонстрации в примере 2.22 показаны некото- рые операции с двумерными массивами в NumPy. Пример 2.22. Простые операции со строками и столбцами из модуля numpy.ndarray >>> import numpy as np  >>> a = np.arange(12)  >>> a array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) >>> type(a) <class 'numpy.ndarray'> >>> a.shape  (12,) >>> a.shape = 3, 4  >>> a 88  Массив последовательностей\n--- Страница 88 ---\narray([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) >>> a[2]  array([ 8, 9, 10, 11]) >>> a[2, 1]  9 >>> a[:, 1]  array([1, 5, 9]) >>> a.transpose()  array([[ 0, 4, 8], [ 1, 5, 9], [ 2, 6, 10], [ 3, 7, 11]])  Импортировать NumPy, предварительно установив (этот пакет не входит в стандартную библиотеку Python).  Построить и распечатать массив numpy.ndarray , содержащий целые числа от 0 до 11.  Распечатать размерности массива: это одномерный массив с 12 элемента- ми.  Изменить форму массива, добавив еще одно измерение, затем распечатать результат.  Получить строку с индексом 2.  Получить элемент с индексами 2, 1.  Получить столбец с индексом 1.  Создать новый массив, транспонировав исходный (т. е. переставив места- ми строки и столбцы). NumPy также поддерживает загрузку, сохранение и применение операций сразу ко всем элементам массива numpy.ndarray : >>> import numpy >>> floats = numpy.loadtxt('floats-10M-lines.txt')  >>> floats[-3:]  array([ 3016362.69195522, 535281.10514262, 4566560.44373946]) >>> floats *= .5  >>> floats[-3:] array([ 1508181.34597761, 267640.55257131, 2283280.22186973]) >>> from time import perf_counter as pc  >>> t0 = pc(); floats /= 3; pc() - t0  0.03690556302899495 >>> numpy.save('floats-10M', floats)  >>> floats2 = numpy.load('floats-10M.npy', 'r+')  >>> floats2 *= 6 >>> floats2[-3:]  memmap([ 3016362.69195522, 535281.10514262, 4566560.44373946])  Загрузить 10 миллионов чисел с плавающей точкой из текстового файла.  С помощью нотации получения среза распечатать последние три числа.  Умножить каждый элемент массива floats на 0.5 и снова распечатать по- следние три элемента. Когда список не подходит  89\n--- Страница 89 ---\n Импортировать таймер высокого разрешения (включен в стандартную биб лиотеку начиная с версии Python 3.3).  Разделить каждый элемент на 3; для 10 миллионов чисел с плавающей точ- кой это заняло менее 40 миллисекунд.  Сохранить массив в двоичном файле с расширением .npy.  Загрузить данные в виде спроецированного на память файла в другой мас- сив; это позволяет эффективно обрабатывать срезы массива, хотя он и не находится целиком в памяти.  Умножить все элементы на 6 и распечатать последние три. Этот код приведен, только чтобы разжечь ваш аппетит. NumPy и SciPy – потрясающие библиотеки, лежащие в основе не менее заме- чательных библиотек для анализа данных, в т. ч. Pandas (http://pandas.pydata.org), которая предоставляет эффективные типы массивов для хранения нечисловых данных, а также функции импорта-экспорта, совместимые с различными форма- тами (например, CSV, XLS, дамп SQL, HDF5 и т. д.), и scikit-learn (https://scikit-learn. org/stable/), которая сейчас является самым широко распространенным набором инструментов для машинного обучения. Большинство функций в библиотеках NumPy и SciPy написаны на C или C++ и могут задействовать все доступные про- цессорные ядра, т. к. освобождают глобальную блокировку интерпретатора (GIL), присутствующую в Python. Проект Dask (https://dask.org/) также поддерживает рас- пределение обработки с помощью NumPy, Pandas и scikit-learn между машина- ми, образующими кластер. Эти пакеты заслуживают отдельной книги, правда, не этой. Однако любой обзор последовательностей в Python был бы неполным без упоминания о массивах NumPy, хотя бы беглого. Познакомившись с плоскими последовательностями – стандартными мас- сивами и массивами NumPy, – обратимся к совершенно другой альтернативе старого доброго списка list: очередям. Двусторонние и другие очереди Методы .append и .pop позволяют использовать список list как стек или очередь (если вызывать только .append и .pop(0), то получится дисциплина обслуживания LIFO). Однако вставка и удаление элемента из левого конца списка (с индек - сом 0) обходятся дорого, потому что приходится сдвигать весь список. Класс collections.deque – это потокобезопасная двусторонняя очередь, пред- назначенная для быстрой вставки и удаления из любого конца. Эта структу - ра удобна и для хранения списка «последних виденных элементов» и прочего в том же духе, т. к. deque можно сделать ограниченной (при создании задать максимальную длину). Тогда по заполнении deque добавление новых элементов приводит к удалению элементов с другого конца. В примере 2.23 показаны ти- пичные операции со структурой deque. Пример 2.23. Работа с очередью >>> from collections import deque >>> dq = deque(range(10), maxlen=10)  >>> dq deque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], maxlen=10) >>> dq.rotate(3) 90  Массив последовательностей\n--- Страница 90 ---\n>>> dq deque([7, 8, 9, 0, 1, 2, 3, 4, 5, 6], maxlen=10) >>> dq.rotate(-4) >>> dq deque([1, 2, 3, 4, 5, 6, 7, 8, 9, 0], maxlen=10) >>> dq.appendleft(-1)  >>> dq deque([-1, 1, 2, 3, 4, 5, 6, 7, 8, 9], maxlen=10) >>> dq.extend([11, 22, 33])  >>> dq deque([3, 4, 5, 6, 7, 8, 9, 11, 22, 33], maxlen=10) >>> dq.extendleft([10, 20, 30, 40])  >>> dq deque([40, 30, 20, 10, 3, 4, 5, 6, 7, 8], maxlen=10)  Необязательный аргумент maxlen задает максимальное число элементов в этом экземпляре deque, при этом устанавливается допускающий только чтение атрибут экземпляра maxlen.  В результате циклического сдвига с n > 0 элементы удаляются с правого конца и добавляются с левого; при n < 0 удаление производится с левого конца, а добавление – с правого.  При добавлении элемента в заполненную очередь (len(d) == d.maxlen ) про- исходит удаление с другого конца; обратите внимание, что в следующей строке элемент 0 отсутствует.  При добавлении трех элементов справа удаляются три элемента слева: –1, 1 и 2.  Отметим, что функция extendleft(iter) добавляет последовательные эле- менты из объекта iter в левый конец очереди, т. е. в итоге элементы будут размещены в порядке, противоположном исходному. В табл. 2.5 сравниваются методы классов list и deque (унаследованные от object не показаны). Отметим, что deque реализует большинство методов list и добавляет несколь- ко новых, связанных с ее назначением, например popleft и rotate. Но существует и скрытая неэффективность: удаление элементов из середины deque произво- дится медленно. Эта структура данных оптимизирована для добавления и уда- ления элементов только с любого конца. Операции append и popleft атомарны, поэтому deque можно безопасно исполь- зовать как FIFO-очередь в многопоточных приложениях без явных блокировок. Таблица 2.4. Методы, реализованные в классах list и deque (унаследованные от object для краткости опущены) list deque s.__add__(s2) ● s + s2 – конкатенация s.__iadd__(s2) ●●s += s2 – конкатенация на месте s.append(e) ●● Добавление элемента справа (после последнего) s.appendleft(e) ● Добавление элемента слева (перед первым) Когда список не подходит  91\n--- Страница 91 ---\nlist deque s.clear() ●● Удаление всех элементов s.__contains__(e) ● e входит в s s.copy() ● Поверхностная копия списка s.__copy__() ● Поддержка copy.copy (поверхностная копия) s.count(e) ●● Подсчет числа вхождений элемента s.__delitem__(p) ●● Удаление элемента в позиции p s.extend(i) ●● Добавление элементов из итерируемого объекта it справа s.extendleft(i) ● Добавление элементов из итерируемого объекта it слева s.__getitem__(p) ●●s[p] – получение элемента в указанной позиции s.index(e) ● Поиск позиции первого вхождения e s.insert(p, e) ● Вставка элемента e перед элементом в позиции p s.__iter__() ●● Получение итератора s.__len__() ●●len(s) – количество элементов s.__mul__(n) ● s * n – кратная конкатенация s.__imul__(n) ● s *= n – кратная конкатенация на месте s.__rmul__(n) ●●n * s – инверсная кратная конкатенацияa s.pop() ●● Удалить и вернуть последний элементb s.popleft() ● Удалить и вернуть первый элемент s.remove(e) ●● Удалить первое вхождение элемента e, заданно- го своим значением s.reverse() ●● Изменить порядок элементов на противополож - ный на месте s.__reversed__() ●● Получить итератор для перебора элементов от конца к началу s.rotate(n) ● Переместить n элементов из одного конца в другой s.__setitem__(p, e) ●●s[p] = e – поместить e в позицию p вместо на- ходящегося там элемента s.sort([key], [reverse]) ● Отсортировать элементы на месте с факультатив- ными аргументами key и reverse a Инверсные операторы рассматриваются в главе 16. b Вызов a_list.pop(p) позволяет удалить элемент в позиции p, но класс deque его не поддерживает. Помимо deque, в стандартной библиотеке Python есть пакеты, реализующие другие виды очередей. queueОкончание табл. 2.492  Массив последовательностей\n--- Страница 92 ---\nСодержит синхронизированные (т. е. потокобезопасные) классы Queue, LifoQueue и PriorityQueue . Они используются для безопасной коммуникации между потоками. Все три очереди можно сделать ограниченными, передав конструктору аргумент maxsize, больший 0. Однако, в отличие от deque, в слу - чае переполнения элементы не удаляются из очереди, чтобы освободить место, а блокируется вставка новых элементов, т. е. программа ждет, пока какой-нибудь другой поток удалит элемент из очереди. Это полезно для ограничения общего числа работающих потоков. multiprocessing Реализует собственную неограниченную очередь SimpleQueue и ограничен- ную очередь Queue, очень похожие на аналоги в пакете queue, но предназна- ченные для межпроцессного взаимодействия. Чтобы упростить управле- ние задачами, имеется также специализированный класс multiprocessing. JoinableQueue . asyncio Предоставляет классы Queue, LifoQueue, PriorityQueue и JoinableQueue , API которых построен по образцу классов из модулей queue и multiprocessing , но адаптиро- ван для управления задачами в асинхронных программах. heapq В отличие от трех предыдущих модулей, heapq не содержит класса очере- ди, а предоставляет функции, в частности heappush и heappop, которые дают возможность работать с изменяемой последовательностью как с очередью с приоритетами, реализованной в виде пирамиды. На этом мы завершаем обзор альтернатив типу list и изучение типов после- довательностей в целом – за исключением особенностей типа str и двоичных последовательностей, которым посвящена отдельная глава 4. резюме Свободное владение типами последовательностей из стандартной библиоте- ки – обязательное условие написания краткого, эффективного и идиоматич- ного кода на Python. Последовательности Python часто классифицируются как изменяемые или неизменяемые, но полезно иметь в виду и другую классификацию: плоские и контейнерные последовательности. Первые более компактные, быстрые и простые в использовании, но в них можно хранить только атомарные дан- ные, т. е. числа, символы и байты. Контейнерные последовательности облада- ют большей гибкостью, но могут стать источником сюрпризов при хранении в них изменяемых объектов, поэтому при использовании их для размещения иерархических структур данных следует проявлять осторожность. К сожалению, в Python нет по-настоящему неизменяемой последователь- ности контейнерного типа: даже в «неизменяемых» кортежах значения могут быть изменены, если представляют собой изменяемые объекты, например списки или объекты, определенные пользователем. Списковые включения и генераторные выражения – эффективный способ создания и инициализации последовательностей. Если вы еще не освоили эти Резюме  93\n--- Страница 93 ---\nконструкции, потратьте какое-то время на изучение базовых способов их при- менения. Это нетрудно и очень скоро воздастся сторицей. У кортежей в Python двоякая роль: записи с неименованными полями и не- изменяемые списки. Используя кортеж в качестве неизменяемого списка, помните, что значение кортежа будет фиксировано, только если все его эле- менты также неизменяемы. Вызов функции hash(t) для кортежа – простой спо- соб убедиться в том, что его значение никогда не изменится. Если t содержит изменяемые элементы, то будет возбуждено исключение TypeError. Когда кортеж используется как запись, операция его распаковки – самый безопасный и понятный способ получить отдельные поля. Конструкция * работает не только с кортежами, но также со списками и итерируемыми объектами во многих контекстах. Некоторые способы ее применения по- явились в Python 3.5 и описаны в документе PEP 448 «Additional Unpacking Generalizations» (https://peps.python.org/pep-0448/). В Python 3.10 добавлен меха- низм сопоставления с образцом match/case , поддерживающий более развитые средства распаковки, называемые деструктуризацией. Получение среза последовательности – одна из самых замечательных син- таксических конструкций Python, причем многие даже не знают всех ее воз- можностей. Многомерные срезы и нотация многоточия (…), нашедшие при- менение в NumPy, могут поддерживаться и другими пользовательскими по- следовательностями. Присваивание срезу – очень выразительный способ мо- дификации изменяемых последовательностей. Кратная конкатенация (seq * n) – удобный механизм и при должной осторож - ности может применяться для инициализации списка списков, содержащих изменяемые элементы. Операции составного присваивания += и *= ведут себя по-разному для изменяемых и неизменяемых последовательностей. В послед- нем случае они по необходимости создают новую последовательность. Но если конечная последовательность изменяемая, то обычно она модифицируется на месте, хотя и не всегда, т. к. это зависит от того, как последовательность реа- лизована. Метод sort и встроенная функция sorted просты в использовании и облада- ют большой гибкостью благодаря необязательному аргументу key, который представляет собой функцию для вычисления критерия сортировки. Кстати, в качест ве key могут выступать и встроенные функции min и max. Помимо списков и кортежей, в стандартной библиотеке Python имеется класс array.array . И хотя пакеты NumPy и SciPy не входят в стандартную библио- теку, настоятельно рекомендуется хотя бы бегло познакомиться с ними любо- му, кто занимается численным анализом больших наборов данных. В конце главы мы рассмотрели практичный потокобезопасный класс collections.deque , сравнили его API с API класса list (табл. 2.4) и кратко упомяну - ли другие реализации очереди, имеющиеся в стандартной библиотеке. дОпО лнительная литература В главе 1 «Структуры данных» книги David Beazley, Brian K. Jones «Python Cookbook», 3-е издание (O’Reilly), имеется много рецептов, посвященных по-94  Массив последовательностей\n--- Страница 94 ---\nследовате льностям, в том числе рецепт 1.11 «Именованные срезы», из которо- го я позаимствовал присваивание срезов переменным для повышения удобо- читаемости кода (пример 2.13). Второе издание книги «Python Cookbook» охватывает версию Python 2.4, но значительная часть приведенного в ней кода работает и в Python 3, а многие рецепты в главах 5 и 6 относятся к последовательностям. Книгу редактировали Алекс Мартелли, Анна Мартелли Равенскрофт и Дэвид Эшер, свой вклад в нее внесли также десятки других питонистов. Третье издание было переписано с нуля и в большей степени ориентировано на семантику языка – особенно на изменения, появившиеся в Python 3, – тогда как предыдущие издания посвя- щены в основном прагматике (т. е. способам применения языка для решения практических задач). И хотя кое-какой код из второго издания уже нельзя счи- тать наилучшим подходом, я все же полагаю, что полезно иметь под рукой оба издания «Python Cookbook». В официальном документе о сортировке в Python «Sorting HOW TO» (http:// docs.python.org/3/howto/sorting.html) приведено несколько примеров продвину - того применения sorted и list.sort. Документ PEP 3132 «Extended Iterable Unpacking» (http://python.org/dev/peps/pep- 3132/) – канонический источник сведений об использовании новой конструкции *extra в правой части параллельного присваивания. Если вам интересна исто- рия развития Python, то загляните в обсуждение проблемы «Missing *-unpacking generalizations» (http://bugs.python.org/issue2292), где предлагается еще более общее использование нотации распаковки итерируемых объектов. Документ PEP 448 «Additional Unpacking Generalizations» (https://www.python.org/dev/peps/pep-0448/) появился в результате этого обсуждения. Как я говорил в разделе «Сравнение с последовательностью-образцом», написанный Кэролом Уиллингом раздел «Структурное сопоставление с об- разцом» (https://docs.python.org/3.10/whatsnew/3.10.html) главы «Что нового в Python 3.10» официальной документации – прекрасное введение в этот но- вый механизм, занимающее где-то 1400 слов (меньше 5 страниц в PDF-файле, который Firefox строит по HTML-коду). Документ PEP 636 «Structural Pattern Matching: Tutorial» (https://peps.python.org/pep-0636/) тоже неплох, но длиннее. Однако в нем имеется приложение A «Краткое введение» (https://peps.python. org/pep-0636/#appendix-a-quick-intro). Оно короче введения Уиллинга, потому что не содержит общих рассуждений на тему, почему сопоставление с образ- цом – это хорошо. Если вам нужны еще аргументы, чтобы убедить себя или других в пользе сопоставления с образцом, почитайте 22-страничный доку - мент PEP 635 «Structural Pattern Matching: Motivation and Rationale» (https:// peps.python.org/pep-0635/). Статья в блоге Эли Бендерского «Less Copies in Python with the Buffer Protocol and memoryviews» (https://eli.thegreenplace.net/2011/11/28/less-copies-in-python- with-the-buffer-protocol-and-memoryviews/) содержит краткое пособие по исполь- зованию memoryview . На рынке есть немало книг, посвященных NumPy, и в названиях некоторых из них слово «NumPy» отсутствует. Одна из них – книга Jake VanderPlas «Python Data Science Handbook» (https://jakevdp.github.io/PythonDataScienceHandbook/), вы- Дополнительная литература  95\n--- Страница 95 ---\nложенная в открытый доступ, другая – Wes McKinney «Python for Data Analysis» (https://www.oreilly.com/library/view/python-for-data/9781491957653/)1. «NumPy – это о векторизации». Так начинается находящаяся в открытом до- ступе книга Nicolas P. Rougier «From Python to NumPy» (https://www.labri.fr/perso/ nrougier/from-python-to-numpy/). Векторизованные операции применяют мате- матические функции ко всем элементам массива без необходимости писать явный цикл на Python. Они могут работать параллельно, пользуясь специаль- ными командами современных процессоров, и либо задействовать несколь- ко ядер, либо делегировать работу графическому процессору – в зависимости от библиотеки. Первый же пример в книге Руже демонстрирует ускорение в 500 раз после рефакторинга идиоматического класса на Python, пользующе- гося генератором, в компактную и эффективную функцию, вызывающую две векторные функции из библиотеки NumPy. Если хотите научиться использовать класс deque (и другие коллекции), позна- комьтесь с примерами и практическими рецептами в главе «Контейнерные типы данных» (https://docs.python.org/3/library/collections.html) документации по Python. Лучшие аргументы в поддержку исключения последнего элемента диапазона и среза привел сам Эдсгер В. Дейкстра в короткой заметке под названием «Why Numbering Should Start at Zero» (https://www.cs.utexas.edu/users/EWD/ transcriptions/ EWD08xx/EWD831.html). Тема этой заметки – математическая нотация, но она от- носится и к Python, потому что профессор Дейкстра строго и с юмором объясняет, почему последовательность 2, 3, …, 12 следует описывать только условием 2 ≤ i < 13. Все прочие разумные соглашения опровергаются, как и мысль о том, чтобы позво- лить пользователю самому выбирать соглашение. Название заметки наводит на мысль об индексировании с нуля, но на самом деле речь в ней идет о том, почему 'ABCDE'[1:3] должно означать 'BC', а не 'BCD', и почему диапазон 2, 3, …, 12 следует записывать в виде range(2, 13) . Кстати, заметка рукописная, но вполне разборчивая. Почерк Дейкстры настолько четкий, что кто-то даже создал на его основе шрифт (https://www.fonts101.com/fonts/view/Uncategorized/34398/Dijkstra). Поговорим О природе кортежей В 2012 году я презентовал плакат, касающийся языка ABC на конференции PyCon US. До создания Python Гвидо работал над интерпретатором языка ABC, поэтому пришел посмотреть на мой плакат. По ходу дела мы поговорили о со- ставных объектах в ABC, которые, безусловно, являются предшественника- ми кортежей Python. Составные объекты также поддерживают параллельное присваивание и используются в качестве составных ключей словарей (в ABC они называются таблицами). Однако составные объекты не являются после- довательностями. Они не допускают итерирования, к отдельному полю объ- екта нельзя обратиться по индексу, а уж тем более получить срез. Составной объект можно либо обрабатывать целиком, либо выделить поля с помощью параллельного присваивания – вот и всё. 1 Уэс Маккини. Python и анализ данных. 2-е изд. ДМК Пресс, 2020 // https://dmkpress.com/ catalog/computer/programming/python/978-5-97060-590-5/96  Массив последовательностей\n--- Страница 96 ---\nЯ сказал Гвидо, что в силу этих ограничений основная цель составных объек - тов совершенно ясна: это просто записи с неименованными полями. И вот что он ответил: «То, что кортежи ведут себя как последовательности, – просто хак». Это иллюстрация прагматического подхода, благодаря которому Python ока- зался настолько удачнее и успешнее ABC. С точки зрения разработчика языка, заставить кортежи вести себя как последовательности почти ничего не стоит. В результате основное использование кортежей как записей не столь очевид- но, но мы получили неизменяемые списки – пусть даже имя типа не такое говорящее, как frozenlist . Плоские и контейнерные последовательности Чтобы подчеркнуть различие между моделями памяти в последовательностях разных типов, я воспользовался терминами контейнерная и плоская последо- вательность. Слово «контейнер» употребляется в документации по модели данных (https://docs.python.org/3/reference/datamodel.html#objects-values-and-types): Некоторые объекты содержат ссылки на другие объекты, они называ- ются контейнерами. Я остановился на термине «контейнерная последовательность» для большей точности, потому что в Python есть контейнеры, не являющиеся последова- тельностями, например dict и set. Контейнерные последовательности могут быть вложенными, поскольку могут содержать объекты любого типа, в том числе своего собственного. С другой стороны, плоские последовательности не могут быть вложенными, потому что в них разрешено хранить только простые атомарные типы, на- пример целые, числа с плавающей точкой или символы. Я выбрал термин плоская последовательность, потому что нуждался в чем-то, противоположном «контейнерной последовательности». Несмотря на цитированное выше употребление слова «контейнеры» в офи- циальной документации, в модуле collections.abc имеется класс с именем Container. В этом ABC есть всего один метод, __contains__ , – специальный метод, поддерживающий оператор in. Это означает, что строки и массивы, не явля- ющиеся контейнерами в традиционном смысле, являются тем не менее вир- туальными подклассами Container, потому что реализуют метод __contains__ . Это лишний раз подтверждает, что люди часто используют одно и то же сло- во в разных смыслах. В этой книге я пишу «контейнер» (container) строчны- ми буквами, имея в виду «объект, содержащий ссылки на другие объекты», и Container с заглавной буквы и моноширинным шрифтом, когда хочу сослать- ся на класс collections.abc.Container . Смешанные списки В учебниках Python для начинающих подчеркивается, что списки могут со- держать объекты разных типов, но на практике такая возможность не слиш- ком полезна: ведь мы помещаем элементы в список, чтобы впоследствии их обработать, а это значит, что все элементы должны поддерживать общий набор операций (т. е. должны «крякать», даже если не родились утками). На- пример, в Python 3 невозможно отсортировать список, если его элементы не сравнимы: Дополнительная литература  97\n--- Страница 97 ---\n>>> l = [28, 14, '28', 5, '9', '1', 0, 6, '23', 19] >>> sorted(l) Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: unorderable types: str() < int() В отличие от списков, кортежи часто содержат элементы разных типов. И это естественно: если каждый элемент кортежа – поле, то поля могут иметь раз- личные типы. Аргумент key – истинный бриллиант Факультативный аргумент key метода list.sort и функций sorted, max и min – от- личная идея. В других языках вы должны передавать функцию сравнения с дву - мя аргументами, как, например, ныне не рекомендуемая функция cmp(a, b) в Python 2. Но использовать key и проще, и эффективнее. Проще – потому что нужно определить функцию всего с одним аргументом, которая извлекает или вычисляет критерий, с помощью которого сортируются объекты; это легче, чем написать функцию с двумя аргументами, возвращающую –1, 0 или 1. А эф- фективнее – потому что функция key вызывается только один раз для каждого элемента, тогда как функция сравнения с двумя аргументами – всякий раз, как алгоритму сортировки необходимо сравнить два элемента. Разумеется, Python тоже должен сравнивать ключи во время сортировки, но это сравнение произво- дится в оптимизированном коде на C, а не в написанной вами функции Python. Кстати, аргумент key даже позволяет сортировать списки, содержащие числа и похожие на числа строки. Нужно только решить, как интерпретировать все объекты: как целые числа или как строки: >>> l = [28, 14, '28', 5, '9', '1', 0, 6, '23', 19] >>> sorted(l, key=int) [0, '1', 5, 6, '9', 14, 19, '23', 28, '28'] >>> sorted(l, key=str) [0, '1', 14, 19, '23', 28, '28', 5, 6, '9'] Oracle, Google и таинственный Timbot В функции sorted и методе list.sort используется адаптивный алгоритм Timsort, который переключается с сортировки вставками на сортировку слия- нием в зависимости от того, как упорядочены данные. Это эффективно, пото- му что в реальных данных часто встречаются уже отсортированные участки. На эту тему есть статья в Википедии (http://en.wikipedia.org/wiki/Timsort). Алгоритм Timsort впервые был реализован в CPython в 2002 году. Начиная с 2009 года Timsort используется также для сортировки массивов в стандартном компиляторе Java и в Android, этот факт стал широко известен, потому что корпо- рация Oracle использовала относящийся к Timsort код как доказательство нару - шения Google прав интеллектуальной собственности компании Sun. См., напри- мер, постановление судьи Уильяма Олсапа, вынесенное в 2012 году (http://www. groklaw.net/pdf3/OraGoogle-1202.pdf). В 2021 году Верховный суд США постановил, что использование компанией Google кода Java следует считать правомерным. Алгоритм Timsort изобрел Тим Питерс, один из разработчиков ядра Python, настолько плодовитый, что его считали даже искусственным интеллектом – Timbot. Об этой конспирологической теории можно прочитать на страничке Python Humor (https://www.python.org/doc/humor/#id9). Тим – также автор «Дзен Python»: import this .98  Массив последовательностей",
      "debug": {
        "start_page": 47,
        "end_page": 97
      }
    },
    {
      "name": "Глава 3. Словари и множества 99",
      "content": "--- Страница 98 --- (продолжение)\nГлава 3 Словари и множества Python – по сути своей словари, обернутые тоннами синтаксического сахара. – Лало Мартинс, один из первых цифровых номадов и питонистов Мы используем словари во всех своих программах на Python. Если не напря- мую в коде, то косвенно, потому что тип dict – фундаментальная часть реали- зации Python. Атрибуты классов и экземпляров, пространства имен модулей, именованные аргументы функции – вот лишь некоторые фундаментальные конструкции, в которых используются словари. Встроенные типы, объекты и функции хранятся в словаре __builtins__.__dict__ . В силу своей важности словари в Python высокооптимизированы. В основе высокопроизводительных словарей лежат хеш-таблицы. Хеш-таблицы лежат и в основе других встроенных типов: set и frozenset. Они предлагают более развитые API и наборы операторов, чем множества, встре- чающиеся в других популярных языках. В частности, множества в Python реа- лизуют все основные теоретико-множественные операции: объединение, пе- ресечение, проверку на подмножество и т. д. С их помощью мы можем выра- жать алгоритмы более декларативным способом, избегая вложенных циклов и условий. Вот краткое содержание этой главы: современные синтаксические конструкции для построения и работы со словарями dict и отображениями, включая улучшенную распаковку и со- поставление с образцом; часто используемые методы типов отображений; специальная обработка отсутствия ключа; различные вариации типа dict в стандартной библиотеке; типы set и frozenset ; как устройство хеш-таблиц отражается на поведении множеств и словарей. чтО нОвОг О в этОй главе Большинство изменений во втором издании связаны с новыми возможностями, относящимися к типам отображений. В разделе «Современный синтаксис словарей» рассматривается улуч- шенный синтаксис распаковки и различные способы объединения ото- бражения, включая операторы | и |=, поддерживаемые классом dict, на- чиная с версии Python 3.9.\nГлава 3 Словари и множества Python – по сути своей словари, обернутые тоннами синтаксического сахара. – Лало Мартинс, один из первых цифровых номадов и питонистов Мы используем словари во всех своих программах на Python. Если не напря- мую в коде, то косвенно, потому что тип dict – фундаментальная часть реали- зации Python. Атрибуты классов и экземпляров, пространства имен модулей, именованные аргументы функции – вот лишь некоторые фундаментальные конструкции, в которых используются словари. Встроенные типы, объекты и функции хранятся в словаре __builtins__.__dict__ . В силу своей важности словари в Python высокооптимизированы. В основе высокопроизводительных словарей лежат хеш-таблицы. Хеш-таблицы лежат и в основе других встроенных типов: set и frozenset. Они предлагают более развитые API и наборы операторов, чем множества, встре- чающиеся в других популярных языках. В частности, множества в Python реа- лизуют все основные теоретико-множественные операции: объединение, пе- ресечение, проверку на подмножество и т. д. С их помощью мы можем выра- жать алгоритмы более декларативным способом, избегая вложенных циклов и условий. Вот краткое содержание этой главы: современные синтаксические конструкции для построения и работы со словарями dict и отображениями, включая улучшенную распаковку и со- поставление с образцом; часто используемые методы типов отображений; специальная обработка отсутствия ключа; различные вариации типа dict в стандартной библиотеке; типы set и frozenset ; как устройство хеш-таблиц отражается на поведении множеств и словарей. чтО нОвОг О в этОй главе Большинство изменений во втором издании связаны с новыми возможностями, относящимися к типам отображений. В разделе «Современный синтаксис словарей» рассматривается улуч- шенный синтаксис распаковки и различные способы объединения ото- бражения, включая операторы | и |=, поддерживаемые классом dict, на- чиная с версии Python 3.9.\n--- Страница 99 ---\nВ разделе «Сопоставление с отображениями-образцами» иллюстриру - ется использование отображений совместно с match/case , появившееся в версии Python 3.10. Раздел «collections.OrderedDict» теперь посвящен небольшим, но все еще сохраняющимся различиям между dict и OrderedDict – с учетом того, что начиная с версии Python 3.6 ключи в dict хранятся в порядке вставки. Добавлены новые разделы об объектах представлений, возвращаемых атрибутами dict.keys, dict.items и dict.values : «Представления словарей» и «Теоретико-множественные операции над представлениями слова- рей». В основе реализации dict и set по-прежнему лежат хеш-таблицы, но в код dict внесено две важные оптимизации, позволяющие сэкономить память и со- хранить порядок вставки ключей. В разделах «Практические последствия внут реннего устройства класса dict» и «Практические последствия внутрен- него устройства класса set» сведено то, что нужно знать для их эффективного использования. Добавив более 200 страниц во второе издание, я переместил раз- дел «Внутреннее устройство множеств и словарей» на сопрово- дительный сайт fluentpython.com. Дополненная и исправленная 18-страничная статья включает пояснения и диаграммы, касаю- щиеся следующих вопросов: алгоритм и структуры данных хеш-таблиц, начиная с более прос- того для понимания использования в классе set; оптимизация памяти, обеспечивающая сохранение порядка встав- ки ключей в экземпляры dict (начиная с Python 3.6); обеспечивающее разделение ключей размещение в памяти слова- рей, в которых хранятся атрибуты экземпляра – атрибут __dict__ определенных пользователем объектов (оптимизация, реализо- ванная в Python 3.3). СОвременный Синтак СиС СлОварей В следующих разделах описываются средства построения, распаковки и обра- ботки отображений. Некоторые из них присутствуют в языке давно, но, воз- можно, будут новыми для вас. Для других необходима версия Python 3.9 (на- пример, для оператора |) или 3.10 (для match/case ). Но начнем с описания самых старых и самых лучших средств. Словарные включения Начиная с версии Python 2.7 синтаксис списковых выключений и генератор- ных выражений расширен на словарные включения (а также на множествен- ные включения, о которых речь ниже). Словарное включение (dictcomp) строит объект dict, порождая пары key:value из произвольного итерируемого объекта. В примере 3.1 демонстрируется применение словарного включения для по- строения двух словарей из одного и того же списка кортежей. 100  Словари и множества\n--- Страница 100 ---\nПример 3.1. Примеры словарных включений >>> dial_codes = [  (880, 'Bangladesh'), (55, 'Brazil'), (86, 'China'), (91, 'India'), (62, 'Indonesia'), (81, 'Japan'), (234, 'Nigeria'), (92, 'Pakistan'), (7, �Russia'), (1, 'United States'), ] >>> country_dial = {country: code for code, country in dial_codes}  >>> country_dial {'Bangladesh': 880, 'Brazil': 55, 'China': 86, 'India': 91, 'Indonesia': 62, 'Japan': 81, 'Nigeria': 234, 'Pakistan': 92, 'Russia': 7, 'United States': 1} >>> {code: country.upper()  for country, code in sorted(country_dial.items()) if code < 70} {55: 'BRAZIL', 62: 'INDONESIA', 7: 'RUSSIA', 1: UNITED STATES'}  Итерируемый объект dial_codes , содержащий список пар ключ-значение, можно напрямую передать конструктору dict, но…  … мы инвертируем пары: ключом является country, а значением – code.  Сортируем country_dial по названию страны, снова инвертируем пары, пре- образуем значения в верхний регистр и оставляем только элементы, для которых code < 70. Если вы уже освоили списковые включения, то словарные естественно ста- нут следующим шагом. Если нет, то тем больше причин поскорее заняться этим – ведь синтаксис списковых включений теперь обобщен. Распаковка отображений Документ PEP 448 «Additional Unpacking Generalizations» (https://peps.python.org/ pep-0448/) ввел два дополнения в поддержку распаковки отображений сверх того, что было в Python 3.5. Во-первых, оператор ** можно применять более чем к одному аргумен- ту вызванной функции. Это допустимо, когда все ключи являются строками и среди аргументов нет повторяющихся ключей (т. к. дубликаты именованных аргументов запрещены). >>> def dump(**kwargs): return kwargs >>> dump(**{'x': 1}, y=2, **{'z': 3}) {'x': 1, 'y': 2, 'z': 3} Во-вторых, оператор ** можно использовать внутри словарного литерала – и тоже несколько раз: >>> {'a': 0, **{'x': 1}, 'y': 2, **{'z': 3, 'x': 4}} {'a': 0, 'x': 4, 'y': 2, 'z': 3} Современный синтаксис словарей  101\n--- Страница 101 ---\nВ этом случае повторяющиеся ключи разрешены. Последующее вхождение ключа перезаписывает предыдущее (как в случае значения x в примере выше). Такой синтаксис можно использовать и для объединения отображений, но есть и другие способы. Читайте дальше. Объединение отображений оператором | В Python 3.9 поддерживаются операторы | и |= для объединения отображений. Это и понятно, потому что они же используются и для объединения множеств. Оператор | создает новое отображение: >>> d1 = {'a': 1, 'b': 3} >>> d2 = {'a': 2, 'b': 4, 'c': 6} >>> d1 | d2 {'a': 2, 'b': 4, 'c': 6} Обычно тип нового отображения совпадает с типом левого операнда, d1 в примере выше, но может совпадать и с типом правого, если в операции участ вуют определенные пользователем типы. При этом действуют правила перегрузки операторов, которые мы будем рассматривать в главе 16. Для модификации уже имеющегося отображения на месте служит оператор |=. Продолжим предыдущий пример – содержимое d1 изменилось, хотя пере- менная осталась той же: >>> d1 {'a': 1, 'b': 3} >>> d1 |= d2 >>> d1 {'a': 2, 'b': 4, 'c': 6} Если необходимо поддерживать работоспособность кода в вер- сии Python 3.8 или более ранней, то в разделе «Motivation» до- кумента PEP 584 «Add Union Operators To dict» (https://peps.python. org/pep-0584/#motivation) вы найдете хороший обзор других спо- собов объединения отображений. Теперь посмотрим, как к отображениям применяется сопоставление с об- разцом. СОпОС тавление С ОтОБражением -ОБразц Ом Предложение match/case поддерживает субъекты, являющиеся отображения- ми. Отображения-образцы выглядят как литералы типа dict, но могут сопо- ставляться с экземплярами любого реального или виртуального подкласса collections.abc.Mapping1. 1 Виртуальным называется подкласс, зарегистрированный методом .register() аб- страктного базового класса (см. раздел «Виртуальный подкласс ABC» главы 13). Типы, реализованные с помощью Python/C API, также допустимы, если установлен специ- альный бит признака. См. Py_TPFLAGS_MAPPING (https://docs.python.org/3.10/c-api/ typeobj.html#Py_TPFLAGS_MAPPING). 102  Словари и множества\n--- Страница 102 ---\nВ главе 2 мы занимались только последовательностями-образцами, но раз- ные типы образцов можно комбинировать и вкладывать. Благодаря деструк - туризации сопоставление с образцом является мощным средством обработки записей, состоящих из вложенных отображений и последовательностей. Это часто бывает полезно при чтении из JSON API и баз данных с полуструктури- рованными схемами, например MongoDB, EdgeDB или PostgreSQL. См. при- мер 3.2. Из простых аннотаций типов в функции get_creators следует, что функ - ция принимает dict и возвращает list. Пример 3.2. creator.py: get_creators() выделяет имена авторов из записей о произве- дениях def get_creators(record: dict) -> list: match record: case {'type': 'book', 'api': 2, 'authors': [*names]}:  return names case {'type': 'book', 'api': 1, 'author': name}:  return [name] case {'type': 'book'}:  raise ValueError(f\"Invalid 'book' record: {record!r}\") case {'type': 'movie', 'director': name}:  return [name] case _:  raise ValueError(f'Invalid record: {record! r}')  Сопоставить с любым отображением, в котором 'type': 'book', 'api' : 2 , а клю - чу 'authors' соответствует последовательность. Вернуть элементы последова- тельности в виде нового списка.  Сопоставить с любым отображением, в котором 'type': 'book', 'api' : 1 , а клю - чу 'author' соответствует произвольный объект. Вернуть этот объект в виде элемента списка.  Любое другое отображение, в котором 'type': 'book' , недопустимо, возбу - дить исключение ValueError .  Сопоставить с любым отображением, в котором 'type': 'movie' , а ключу 'director' соответствует одиночный объект. Вернуть этот объект в виде эле- мента списка.  Любой другой субъект недопустим, возбудить исключение ValueError . В примере 3.2 продемонстрированы полезные приемы обработки слабо- структурированных данных, в частности записей в формате JSON: включить поле, описывающее вид записи (например, 'type': 'movie' ); включить поле, идентифицирующее версию схемы (например, 'api': 2'), чтобы в будущем можно было модифицировать открытый API; предусмотреть ветви case для обработки недопустимых записей (напри- мер, 'book'), а также перехватывающую ветвь. Теперь посмотрим, как функция get_creators обрабатывает некоторые тесты. Сопоставление с отображением-образцом  103\n--- Страница 103 ---\n>>> b1 = dict(api=1, author='Douglas Hofstadter', type='book', title='Gödel, Escher, Bach') >>> get_creators(b1) ['Douglas Hofstadter'] >>> from collections import OrderedDict >>> b2 = OrderedDict(api=2, type='book', title='Python in a Nutshell', authors='Martelli Ravenscroft Holden'.split()) >>> get_creators(b2) ['Martelli', 'Ravenscroft', 'Holden'] >>> get_creators({'type': 'book', 'pages': 770}) Traceback (most recent call last): ValueError: Invalid 'book' record: {'type': 'book', 'pages': 770} >>> get_creators('Spam, spam, spam') Traceback (most recent call last): ValueError: Invalid record: 'Spam, spam, spam' Заметим, что порядок ключей в образцах не играет роли, даже если субъект имеет тип OrderedDict , как в случае b2. В отличие от последовательностей-образцов, сопоставление с отображения- ми-образцами считается успешным даже в случае частичного совпадения. В тестах субъекты b1 и b2 включают ключ 'title', отсутствующий в образце 'book', и тем не менее сопоставление успешно. Использовать аргумент **extra для сопоставления с лишними парами ключ- значение необязательно, но если вы хотите собрать их в словарь, то можете ука- зать одну переменную с префиксом **. Она должна быть последней в образце, а конструкция **_ запрещена ввиду своей избыточности. Вот простой пример: >>> food = dict(category='ice cream', flavor='vanilla', cost=199) >>> match food: case {'category': 'ice cream', **details}: print(f'Ice cream details: {details}') Ice cream details: {'flavor': 'vanilla', 'cost': 199} В разделе «Автоматическая обработка отсутствующих ключей» ниже мы бу- дем рассматривать тип defaultdict и другие отображения, для которых поиск ключа с помощью метода __getitem__ (т. е. d[key]) всегда завершается успешно, потому что отсутствующие элементы создаются динамически. В контексте сопоставления с образцом сопоставление считается успешным, только если в субъекте уже присутствовали необходимые ключи до выполнения match. Автоматическая обработка отсутствующих ключей не активи- руется, потому что механизм сопоставления с образцом всегда вызывает метод d.get(key, sentinel) , где sentinel по умолчанию является специальным маркером, который не может встретить- ся в пользовательских данных. Разобравшись с синтаксисом и структурой, перейдем к изучению API ото- бражений. 104  Словари и множества\n--- Страница 104 ---\nСтандартный Api типОв ОтОБражений Модуль collections.abc содержит абстрактные базовые классы Mapping и MutableMapping , формализующие интерфейсы типа dict и родственных ему. См. рис. 3.1. Основная ценность ABC – документирование и формализация минималь- ного интерфейса отображений, а также использование в тестах с помощью функции isinstance в тех программах, которые должны поддерживать произ- вольные отображения: >>> my_dict = {} >>> isinstance(my_dict, abc.Mapping) True >>> isinstance(my_dict, abc.MutableMapping) True Использовать isinstance совместно с ABC зачастую лучше, чем проверять, принадлежит ли аргумент функции конкретному типу dict, потому что так можно использовать и другие типы отображений. Мы подробно обсудим э тот вопрос в главе 13. Рис. 3.1. Упрощенная UML-диаграмма класса MutableMapping и его суперклассов из моду- ля collections.abc (стрелки ведут от подклассов к суперклассам, курсивом набраны имена абстрактных классов и абстрактных методов) Чтобы реализовать свое отображение, проще расширить класс collections. UserDict или обернуть dict с помощью композиции, чем создавать подклас - сы этих ABC. Класс collections.UserDict и все конкретные классы отображений в стандартной библиотеке инкапсулируют базовый словарь dict, который, в свою очередь, основан на хеш-таблице. Поэтому у всех них есть общее огра- ничение: ключи должны быть хешируемыми (к значениям это требование не относится). В следующем разделе объясняется, что это означает. Что значит «хешируемый»? Вот часть определения хешируемости, взятая из глоссария Python (https:// docs.python.org/3/glossary.html#term-hashable): Объект называется хешируемым, если имеет хеш-код, который не изме- няется на протяжении всего времени его жизни (у него должен быть ме- тод __hash__() ), и допускает сравнение с другими объектами (у него дол- Стандартный API типов отображений  105\n--- Страница 105 ---\nжен быть метод __eq__()). Если в результате сравнения хешируемых объ- ектов оказывается, что они равны, то и их хеш-коды должны быть равны1. Все числовые типы и плоские неизменяемые типы str и bytes являются хе- шируемыми. Объект типа frozenset всегда хешируемый, потому что его элемен- ты должны быть хешируемыми по определению. Объект типа tuple является хешируемым только тогда, которые хешируемы все его элементы. Взгляните на кортежи tt, tl и tf: >>> tt = (1, 2, (30, 40)) >>> hash(tt) 8027212646858338501 >>> tl = (1, 2, [30, 40]) >>> hash(tl) Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: unhashable type: 'list' >>> tf = (1, 2, frozenset([30, 40])) >>> hash(tf) -4118419923444501110 Хеш-код объекта может зависеть от версии Python, машинной архитектуры и начального значения, включенного в процесс вычисления хешей из сообра- жений безопасности2. Хеш-код корректно реализованного объекта является гарантированно постоянным только в рамках одного процесса. Любой пользовательский тип является хешируемым по определению, пото- му что его хеш-значение равно id(), а метод __eq__(), унаследованный от клас - са object, просто сравнивает идентификаторы объектов. Если объект реализует пользовательский метод __eq__(), учитывающий внутреннее состояние, то он будет хешируемым, только если его метод __hash__() всегда возвращает один и тот же хеш-код. На практике это требование означает, что методы __eq__() и __hash__() должны принимать во внимание только те атрибуты экземпляра, которые не изменяются на протяжении всей жизни объекта. Теперь обсудим API наиболее употребительных типов отображений в Python: dict, defaultdict и OrderedDict . Обзор наиболее употребительных методов отображений Базовый API отображений очень хорошо развит. В табл. 3.1 показаны мето- ды, реализованные в классе dict и двух его самых полезных разновидностях: defaultdict и OrderedDict (тот и другой определены в модуле collections ). 1 В глоссарии Python (https://docs.python.org/3/glossary.html#term-hashable) употребляется термин «хеш-значение», а не «хеш-код». Я предпочитаю «хеш-код», потому что это понятие часто встречается в контексте отображений, элементы которых состоят из ключей и значений, и, следовательно, одновременное употребление терминов «хеш- значение» и «значение» могло бы привести к путанице. В этой книге используется только «хеш-код». 2 О проблемах безопасности и принятых решениях см. документ PEP 456 «Secure and interchangeable hash algorithm» (https://peps.python.org/pep-0456/).106  Словари и множества\n--- Страница 106 ---\nТаблица 3.1. Методы типов отображений types dict, collections.defaultdict и collections. OrderedDict (для краткости методы, унаследованные от object, опущены); необязательные аргументы заключены в квадратные скобки dict defaultdict OrderedDict d.clear() ● ● ● Удаление всех элементов d.__contains__(k) ● ● ● k входит в d d.copy() ● ● ● Поверхностная копия d.__copy__() ● Поддержка copy.copy d.default_factory ● Вызываемый объект, к которому обращается метод __missing__ в случае отсутствия значенияa s.__delitem__(p) ● ● ● del d[k] – удаление элемента с ключом k d.fromkeys(itm [initial])● ● ● Новое отображение, ключи ко- торого поставляет итерируемый объект, и с необязательным на- чальным значением (по умолча- нию None) d.get(k, [default]) ● ● ● Получить элемент с ключом k, а если такой ключ отсутствует, вернуть default или None d.__getitem__(k) ● ● ● d[k] – получить элемент с ключом k d.items() ● ● ● Получить представление эле- ментов – множество пары (key, value) d.__iter__() ● ● ● Получение итератора по ключам d.keys() ● ● ● Получить представление ключей d.__len__() ● ● ● len(d) – количество элементов d.__missing__(k) ● Вызывается, когда __getitem__ не может найти элемент d.move_to_end(k, [last])● Переместить ключ k в первую или последнюю позицию ( last по умолчанию равно True) d.__or__(other) ● ● ● Поддерживает операцию d1 | d2 , создающую объединение d1 и d2 (Python ≥ 3.9) d.__ior__(other) ● ● ● Поддерживает операцию d1 |= d2, добавляющую в d1 содержи- мое d2 (Python ≥ 3.9) d.pop(k, [default]) ● ● ● Удалить и вернуть значение с клю- чом k, а если такой ключ отсутству- ет, вернуть default или None d.popitem() ● ● ● Удалить и вернуть произвольный элемент (key, value)b Стандартный API типов отображений  107\n--- Страница 107 ---\ndict defaultdict OrderedDict d.__reversed__() ● ● ● Получить итератор для перебора ключей от последнего к первому вставленному d.__ror__(other) ● ● ● Поддерживает операцию other | d – оператор инверсного объеди- нения (Python ≥ 3.9)c d.setdefault(k, [default])● ● ● Если k принадлежит d, вернуть d[k], иначе положить d[k] = default и вернуть это значение d.__setitem__(k, v) ● ● ● d[k] = v – поместить v в элемент с ключом k d.update(m, [**kargs])● ● ● Обновить d элементами из ото- бражения или итерируемого объекта, возвращающего пары (key, value) d.values() ● ● ● Получить представление значений a default_factory – не мет од, а атрибут – вызываемый объект, задаваемый пользователем при создании объекта defaultdict . b Метод OrderedDict.popitem() удаляет первый вставленный элемент (дисциплина FIFO); если необязательный аргумент last равен True, то удаляет последний вставленный эле- мент (дисциплина LIFO). с Инверсные операторы обсуждаются в главе 16. То, как метод d.update(m) трактует свой первый аргумент m, – яркий пример утиной типизации (duck typing): сначала проверяется, есть ли у m метод keys, и если да, то предполагается, что это отображение. В противном случае update() производит обход m в предположении, что элементами являются пары (key, value). Конструкторы большинства отображений в Python применяют логику метода update(), а значит, отображение можно инициализировать как другим отображением, так и произвольным итерируемым объектом, порождающим пары (key, value) . Метод setdefault – тонкая штучка. Нужен он не всегда, но, когда нужен, позволяет существенно ускорить работу, избегая излишних операций поиска ключа. В сле- дующем разделе на практическом примере объясняется, как им пользоваться. Вставка и обновление изменяемых значений В полном соответствии с философией быстрого отказа доступ к словарю dict с помощью конструкции d[k] возбуждает исключение, если ключ k отсутствует. Любой питонист знает об альтернативной конструкции d.get(k, default) , кото - рая применяется вместо d[k], если иметь значение по умолчанию удобнее, чем обрабатывать исключение KeyError. Однако если нужно обновить изменяемое значение, то есть способ лучше. Рассмотрим скрипт для индексирования текста, порождающий отображе- ние, в котором ключом является слово, а значением – список позиций, в кото- рых это слово встречается (см. пример 3.3).Окончание табл. 3.1108  Словари и множества\n--- Страница 108 ---\nПример 3.3. Частичный результат работы скрипта 3.4 применительно к обработке текста «Дзен Python»; в каждой строке показано слово и список его вхождений, представленных парами (номер_строки, номер-столбца) $ python3 index0.py zen.txt a [(19, 48), (20, 53)] Although [(11, 1), (16, 1), (18, 1)] ambiguity [(14, 16)] and [(15, 23)] are [(21, 12)] aren [(10, 15)] at [(16, 38)] bad [(19, 50)] be [(15, 14), (16, 27), (20, 50)] beats [(11, 23)] Beautiful [(3, 1)] better [(3, 14), (4, 13), (5, 11), (6, 12), (7, 9), (8, 11), (17, 8), (18, 25)] В примере 3.4 показан неоптимальный скрипт, демонстрирующий одну си- туацию, когда dict.get – не лучший способ обработки отсутствия ключа. Он ос - нован на примере Алекса Мартелли1. Пример 3.4. index0.py: применение метода dict.get для выборки и обновления списка вхождений слова в индекс (в примере 3.4 показано лучшее решение) \"\"\"Строит индекс, отображающий слово на список его вхождений\"\"\" import re import sys WORD_RE = re.compile(r'\\w+') index = {} with open(sys.argv[1], encoding='utf-8') as fp: for line_no, line in enumerate(fp, 1): for match in WORD_RE.finditer(line): word = match.group() column_no = match.start() + 1 location = (line_no, column_no) # некрасиво; написано только для демонстрации идеи occurrences = index.get(word, [])  occurrences.append(location)  index[word] = occurrences  # напечатать в алфавитном порядке for word in sorted(index, key=str.upper):  print(word, index[word])  Получить список вхождений слова word или [], если оно не найдено.  Добавить новое вхождение в occurrences .  Поместить модифицированный список occurrences в словарь dict; при этом производится второй поиск в индексе. 1 Оригинальный скрипт представлен на слайде 41 презентации Мартелли «Учим Python заново» (http://www.aleax.it/Python/accu04_Relearn_Python_alex.pdf). Его скрипт де- монстрирует использование dict.setdefault , показанное в примере 3.5. Стандартный API типов отображений  109\n--- Страница 109 ---\n При задании аргумента key функции sorted мы не вызываем str.upper, а толь- ко передаем ссылку на этот метод, чтобы sorted могла нормализовать слова перед сортировкой1. Три строчки, относящиеся к обработке occurrences в примере 3.4, можно за- менить одной, воспользовавшись методом dict.setdefault . Пример 3.5 ближе к оригинальному коду Алекса Мартелли. Пример 3.5. index.py: применение метода dict.setdefault для выборки и обновления списка вхождений слова в индекс; в отличие от примера 3.4, понадобилась только одна строчка «»»Строит индекс, отображающий слово на список его вхождений»»» import re import sys WORD_RE = re.compile(r'\\w+') index = {} with open(sys.argv[1], encoding='utf-8') as fp: for line_no, line in enumerate(fp, 1): for match in WORD_RE.finditer(line): word = match.group() column_no = match.start() + 1 location = (line_no, column_no) index.setdefault(word, []).append(location)  # напечатать в алфавитном порядке for word in sorted(index, key=str.upper): print(word, index[word])  Получить список вхождений слова word или установить его равным [], если слово не найдено; setdefault возвращает значение, поэтому список можно обновить без повторного поиска. Иными словами, строка… my_dict.setdefault(key, []).append(new_value) … дает такой же результат, как … if key not in my_dict: my_dict[key] = [] my_dict[key].append(new_value) … с тем отличием, что во втором фрагменте производится по меньшей мере два поиска ключа (три, если ключ не найден), тогда как setdefault довольствует - ся единственным поиском. Смежный вопрос – обработка отсутствия ключа при любом поиске (а не только при вставке) – тема следующего раздела. 1 Здесь мы видим пример использования метода в качестве полноправной функции, подробнее эта тема обсуждается в главе 7.110  Словари и множества\n--- Страница 110 ---\nавтОматичеСкая ОБраБО тка ОтСутСтвующих ключей Иногда удобно, чтобы отображение возвращало некоторое специальное значе- ние, если искомый ключ отсутствует. К решению данной задачи есть два под- хода: первый – использовать класс defaultdict вместо dict, второй – создать под- класс dict или любого другого типа отображения и добавить метод __missing__ . Ниже рассматриваются оба способа. defaultdict: еще один подход к обработке отсутствия ключа Экземпляр класса collections.defaultdict создает элементы, имеющие значение по умолчанию, динамически, если при использовании конструкции d[k] ключ не был найден. В примере 3.6 предлагается еще одно элегантное решение за- дачи индексирования текста из примера 3.5. Работает это следующим образом: при конструировании объекта defaultdict задается вызываемый объект, который порождает значение по умолчанию всякий раз, как методу __getitem__ передается ключ, отсутствующий в словаре. Например, пусть defaultdict создан как dd = defaultdict(list) . Тогда если ключ 'new-key' отсутствует в dd, то при вычислении выражения dd['new-key'] выполня- ются следующие действия: 1. Вызвать list() для создания нового списка. 2. Вставить список в dd в качестве значения ключа 'new-key'. 3. Вернуть ссылку на этот список. Вызываемый объект, порождающий значения по умолчанию, хранится в атрибуте экземпляра default_factory . Пример 3.6. index_default.py: использование экземпляра defaultdict вместо метода setdefault \"\"\"Строит индекс, отображающий слово на список его вхождений\"\"\" import collections import re import sys WORD_RE = re.compile(r'\\w+') index = collections.defaultdict(list)  with open(sys.argv[1], encoding='utf-8') as fp: for line_no, line in enumerate(fp, 1): for match in WORD_RE.finditer(line): word = match.group() column_no = match.start() + 1 location = (line_no, column_no) index[word].append(location)  # напечатать в алфавитном порядке for word in sorted(index, key=str.upper): print(word, index[word])  Создать defaultdict , задав в качестве default_factory конструктор list.  Если слова word еще нет в index, то вызывается функция default_factory , кото - Автоматическая обработка отсутствующих ключей  111\n--- Страница 111 ---\nрая порождает отсутствующее значение – в данном случае пустой список. Это значение присваивается index[word] и возвращается, так что операция .append(location) всегда завершается успешно. Если атрибут default_factory не задан, то в случае отсутствия ключа, как обыч- но, возбуждается исключение KeyError. Атрибут default_factory объекта defaultdict вызывается только для того, чтобы предоставить значение по умолчанию при об- ращении к методу __getitem__ и только к нему. Например, если dd – объект класса defaultdict и k – отсутствующий ключ, то при вычислении выражения dd[k] происходит обращение к default_ factory для создания значения по умолчанию, а вызов dd.get(k) все равно возвращает None и k in dd равно False. А почему defaultdict обращается к default_factory ? Всему виной специальный метод __missing__ . Его мы и обсудим далее. Метод __missing__ В основе механизма обработки отсутствия ключей в отображениях лежит ме- тод, которому как нельзя лучше подходит имя __missing__ . Он не определен в ба- зовом классе dict, но dict знает о нем: если создать подкласс dict и реализовать в нем метод __missing__ , то стандартный метод dict.__getitem__ будет обращаться к нему всякий раз, как не найдет ключ, – вместо того чтобы возбуждать исклю- чение KeyError. Допустим, нам нужно отображение, в котором ключ перед поиском преоб- разуется в тип str. Конкретный пример дает библиотека работы с устройства- ми для IoT1, в которой программируемая плата с контактами ввода-вывода общего назначения (например, Raspberry Pi или Arduino) представлена объ- ектом класса Board с атрибутом my_board.pins , который является отображением идентификаторов физических контактов на программные объекты контактов. Идентификатор физического контакта может задаваться числом или строкой вида \"A0\" либо \"P9_12\". Для единообразия желательно, чтобы все ключи board.pins были строками, но хорошо бы, чтобы и обращение вида my_arduino.pin[13] тоже работало, тогда начинающие не будут впадать в ступор, желая зажечь светоди- од, подключенный к контакту 13 на плате Arduino. В примере 3.7 показано, как такое отображение могло бы быть реализовано. Пример 3.7. При поиске по нестроковому ключу объект StrKeyDict0 преобразует его в тип str в случае отсутствия Tests for item retrieval using `d[key]` notation:: >>> d = StrKeyDict0([('2', 'two'), ('4', 'four')]) >>> d['2'] 'two' >>> d[4] 'four' 1 Одна из таких библиотек – Pingo.io ( https://github.com/pingo-io/pingo-py), развитие кото- рой прекращено. 112  Словари и множества\n--- Страница 112 ---\n>>> d[1] Traceback (most recent call last): KeyError: '1' Tests for item retrieval using `d.get(key)` notation:: >>> d.get('2') 'two' >>> d.get(4) 'four' >>> d.get(1, 'N/A') 'N/A' Tests for the `in` operator:: >>> 2 in d True >>> 1 in d False В примере 3.8 реализован класс StrKeyDict0 , для которого все приведенные выше тесты проходят. Более правильный способ реализовать тип пользовательского отображения – унаследовать классу collections.UserDict , а не dict (мы так и поступим в примере 3.9). Здесь мы создали подкласс dict просто для демонстрации того, что метод __missing__ под- держивается встроенным методом dict.__getitem__ . Пример 3.8. Класс StrKeyDict0 преобразует нестроковые ключи в тип str во время по- иска (см. тесты в примере 3.7) class StrKeyDict0(dict):  def __missing__(self, key):  if isinstance(key, str): raise KeyError(key) return self[str(key)]  def get(self, key, default=None): try: return self[key]  except KeyError: return default  def __contains__(self, key): return key in self.keys() or str(key) in self.keys()   StrKeyDict0 наследует dict.  Проверить, принадлежит ли ключ key типу str. Если да и при этом отсут - ствует в словаре, возбудить исключение KeyError.  Преобразовать key в str и искать.  Метод get делегирует свою работу методу __getitem__ благодаря нотации self[key]; это приводит в действие наш метод __missing__ . Автоматическая обработка отсутствующих ключей  113\n--- Страница 113 ---\n Если возникло исключение KeyError, значит, метод __missing__ уже завершил- ся с ошибкой, поэтому вернуть default.  Искать сначала по немодицированному ключу (экземпляр может содер- жать нестроковые ключи), а затем по строке str, построенной по ключу. Задайтесь вопросом, зачем в реализации __missing__ необходима проверка isinstance(key, str) . Без этой проверки наш метод __missing__ работал бы для любого ключа k – не важно, принадлежит он типу str или нет, – если только str(k) порождает существующий ключ. Но если ключ str(k) не существует, то возникла бы бес- конечная рекурсия. В последней строке вычисление self[str(key)] привело бы к вызову __getitem__ с параметром, равным строковому представлению ключа, а это, в свою очередь, – снова к вызову __missing__ . Метод __contains__ в этом примере также необходим для обеспечения согла- сованного поведения, потому что его вызывает операция k in d, однако реа- лизация данного метода, унаследованная от dict, не обращается к __missing__ в случае отсутствия ключа. В нашей реализации __contains__ есть тонкий нюанс: мы не проверяем наличие ключа принятым в Python способом – k in my_dict – потому что конструкция str(key) in self привела бы к рекурсивному вызову __contains__ . Чтобы избежать этого, мы явно ищем ключ в self.keys() . Поиск вида k in my_dict.keys() эффективен в Python 3 даже для очень боль- ших отображений, потому что dict.keys() возвращает представление, похожее на множество, как мы увидим в разделе «Теоретико-множественные операции над представлениями словарей» ниже. Однако не забывайте, что k in my_dict делает то же самое, причем быстрее, потому что не нужно искать среди атри- бутов метод .keys(). У меня была причина использовать self.keys() в методе __contains__ в приме- ре 3.8. Проверка наличия немодифицированного ключа – key in self.keys() – не- обходима для корректности, потому что класс StrKeyDict0 не гарантирует, что все ключи словаря обязательно имеют тип str. Наша цель состоит только в том, чтобы сделать поиск более дружелюбным, а не навязывать пользователю типы. Определенные пользователем классы, производные от ото- бражений из стандартной библиотеки, могут использовать или не использовать метод __missing__ в качестве запасного вари- анта в собственной реализации __getitem__ , get или __contains__ . Мы обсудим это в следующем разделе. Несогласованное использование __missing__ в стандартной библиотеке Рассмотрим следующие сценарии и то, как в них обрабатывается поиск отсут - ствующего ключа. Подкласс dict Подкласс dict, в котором реализован только метод __missing__ и никаких дру- гих. В этом случае __missing__ может вызываться лишь при использовании конструкции d[k], которая обращается к методу __getitem__ , унаследованно- му от dict. 114  Словари и множества\n--- Страница 114 ---\nПодкласс collections.UserDict Подкласс UserDict, в котором реализован только метод __missing__ и никаких других. В этом случае метод get, унаследованный от UserDict, вызывает __ getitem__. Это значит, что __missing__ может вызываться для обработки поиска с помощью конструкций d[k] или d.get(k). Подкласс abc.Mapping с простейшим __getitem__ Минимальный подкласс abc.Mapping , в котором реализован метод __missing__ и необходимые абстрактные методы, в т. ч. имеется реализация __getitem__ , не обращающаяся к __missing__ . В таком классе метод __missing__ никогда не вызывается. Подкласс abc.Mapping с __getitem__ , вызывающим __missing__ Минимальный подкласс abc.Mapping , в котором реализован метод __missing__ и необходимые абстрактные методы, в т. ч. имеется реализация __getitem__ , обращающаяся к __missing__ . В таком классе метод __missing__ вызывается, когда поиск производится с помощью конструкций d[k], d.get(k) и k in d. В скрипте missing.py (https://github.com/fluentpython/example-code-2e/blob/ master/03-dict-set/missing.py) в репозитории кода приведены демонстрации всех описанных выше сценариев. Во всех четырех сценариях предполагаются минимальные реализации. Если ваш подкласс реализует методы __getitem__ , get и __contains__ , то использо- вать в них __missing__ или нет, зависит от конкретных потребностей. Цель этого раздела – показать, что при создании подклассов стандартных библиотечных отображений, в которых предполагается использовать __missing__ , необходима осторожность, потому что базовые классы по умолчанию поддерживают раз- ные поведения. Не забывайте, что поведение методов setdefault и update тоже зависит от по- иска ключа. И наконец, в зависимости от логики реализации __missing__ в сво- ем классе вы, возможно, должны будете реализовать специальную логику в __setitem__ , чтобы избежать несогласованного или неожиданного поведения. Пример такого рода мы встретим в разделе «Создание подкласса UserDict вмес то dict». До сих пор мы рассматривали типы отображений dict и defaultdict , но в стан- дартной библиотеке имеются и другие реализации отображения. Обсудим их. вариации на тему dict В этом разделе мы дадим обзор типов отображений, включенных в модуль стандартной библиотеки collections (помимо рассмотренного выше defaultdict ): collections.OrderedDict Поскольку начиная с версии Python 3.6 встроенный словарь dict также хранит ключи упорядоченными, использовать OrderedDict имеет смысл главным обра- зом для поддержания обратной совместимости с предыдущими версиями. Тем не менее в документации приводится несколько оставшихся различий между Вариации на тему dict  115\n--- Страница 115 ---\ndict и OrderedDict , которые я повторю здесь, перечислив в порядке, отвечающем частоте использования в повседневной практике. Оператор равенства в классе OrderedDict проверяет, что порядок следова- ния ключей одинаков. Метод popitem() в классе OrderedDict имеет другую сигнатуру. Он принимает необязательный аргумент, указывающий, какой элемент извлечь. В классе OrderedDict имеется метод move_to_end() , который эффективно пе- реходит к последнему элементу в словаре. При проектировании обычного dict на первое место ставилась высокая эффективность операций отображения, а отслеживание порядка вставки было вторичным. При проектировании OrderedDict на первое место ставилась высокая эф- фективность операций переупорядочения, а эффективность использо- вания памяти, скорость итерирования и производительность операций обновления были вторичны. Алгоритмически OrderedDict справляется с частыми операциями переупо- рядочения лучше, чем dict. Поэтому он подходит для отслеживания не- давних операций доступа (например, в LRU-кеше). collections.ChainMap Хранит список отображений, так что их можно просматривать как единое це- лое. Поиск производится в каждом отображении в порядке их перечисления в конструкторе и завершается успешно, если ключ найден хотя бы в одном. Например: >>> d1 = dict(a=1, b=3) >>> d2 = dict(a=2, b=4, c=6) >>> from collections import ChainMap >>> chain = ChainMap(d1, d2) >>> chain['a'] 1 >>> chain['c'] 6 Экземпляр ChainMap не копирует входные отображения, а хранит ссылки на них. Все модификации и вставки ChainMap применяются только к первому из входных отображений. Продолжим предыдущий пример: >>> chain['c'] = -1 >>> d1 {'a': 1, 'b': 3, 'c': -1} >>> d2 {'a': 2, 'b': 4, 'c': 6} ChainMap полезен при реализации интерпретаторов языков с вложенными областями видимости, когда каждая область видимости представлена отдель- ным отображением, в направлении от самого внутреннего к самому внеш- нему. В разделе «Объекты ChainMap» документации по модулю collections (https://docs.python.org/3/library/collections.html#collections.ChainMap) есть несколь- ко примеров использования ChainMap, включая и следующий фрагмент, иллюст- рирующий базовые правила поиска имен переменных в Python:116  Словари и множества\n--- Страница 116 ---\nimport builtins pylookup = ChainMap(locals(), globals(), vars(builtins)) В примере 18.14 показано, как подкласс ChainMap применяется в интерпрета- торе подмножества языка Scheme. collections.Counter Отображение, в котором с каждым ключом ассоциирован счетчик. Обновление существующего ключа увеличивает его счетчик. Этот класс можно использовать для подсчета количества хешируемых объектов или в качестве мультимножества (обсуждается ниже в данном разделе). В классе Counter реализованы операторы + и - для объединения серий и другие полезные методы, например most_common([n]) , который возвращает упорядоченный список кортежей, содержащий n самых часто встречающихся элементов вместе с их счетчиками; документацию см. по адресу https://docs.python.org/3/library/collections.html#collections.Counter. Ниже демон- стрируется применение Counter для подсчета числа различных букв в слове: >>> ct = collections.Counter('abracadabra') >>> ct Counter({'a': 5, 'b': 2, 'r': 2, 'c': 1, 'd': 1}) >>> ct.update('aaaaazzz') >>> ct Counter({'a': 10, 'z': 3, 'b': 2, 'r': 2, 'c': 1, 'd': 1}) >>> ct.most_common(3) [('a', 10), ('z', 3), ('b', 2)] Обратите внимание, что оба ключа 'b' и 'r' делят третье место, но ct.most_ common(3) показывает только три счетчика. Чтобы воспользоваться классом collections.Counter как мультимножеством, представьте, что каждый ключ – элемент множества, а счетчик – количество вхождений этого элемента в множество. shelve.Shelf Модуль shelve из стандартной библиотеки предоставляет постоянное хранили- ще для отображения строковых ключей на объекты Python, сериализованные в двоичном формате pickle. Название shelve (полка) – намек на то, что банки с соленьями (pickle) хранятся на полках. Функция уровня модуля shelve.open возвращает экземпляр shelve.Shelf – прос- тую базу ключей и значений, поддерживаемую модулем dbm и обладающую сле- дующими свойствами: shelve.Shelf является подклассом abc.MutableMapping , т. е. предоставляет ос- новные методы, ожидаемые от типа отображения; кроме того, shelve.Shelf предоставляет еще несколько методов для управ- ления вводом-выводом, например sync и close ; экземпляр Shelf является контекстным менеджером, поэтому его можно включать в блок with, гарантирующий закрытие после использования; ключи и значения сохраняются при каждом присваивании нового зна- чения ключу. Ключи должны быть строками; значения должны быть объектами, которые модуль pickle умеет сериа- лизовывать. Вариации на тему dict  117\n--- Страница 117 ---\nВ документации по модулям shelve (https://docs.python.org/3/library/shelve.html), dbm (https://docs.python.org/3/library/ dbm.html) и pickle (https://docs.python.org/3/ library/pickle.html) приведены дополнительные сведения и описаны некоторые подводные камни. Модуль pickle легко использовать в простых случаях, но у него есть несколько недостатков. Прочитайте статью Нэда Бэтчел- дера «Pickle’s nine flaws» (https://nedbatchelder.com/blog/202006/ pickles_nine_flaws.html), прежде чем принимать любое решение, подразумевающее использование pickle. Кстати, Нэд упоминает и о других форматах сериализации, на которые стоит обратить внимание. Классы OrderedDict , ChainMap, Counter и Shelf готовы к использованию, но при же- лании их поведение можно модифицировать, создав подклассы. С другой сто- роны, UserDict – базовый класс, специально предназначенный для расширения. Создание подкласса UserDict вместо dict Рекомендуется создавать новый тип отображения путем расширения клас - са collections.UserDict , а не dict. Мы убедимся в этом, попытавшись расширить класс StrKeyDict0 из примера 3.8, так чтобы любой ключ, добавляемый в ото- бражение, сохранялся в виде строки str. Основная причина, по которой предпочтительнее наследовать классу UserDict, а не dict, заключается в том, что в реализации dict некоторые углы сре- заны, что вынуждает нас переопределять методы, которые можно без всяких проблем унаследовать от UserDict1. Отметим, что UserDict не наследует dict, а пользуется композицией: хранит в атрибуте data экземпляр dict, где и находятся сами элементы. Это позволяет избежать нежелательной рекурсии при кодировании таких специальных мето- дов, как __setitem__ , и упрощает код __contains__ по сравнению с тем, что показан в примере 3.8. Благодаря UserDict класс StrKeyDict (пример 3.9) получился короче, чем StrKeyDict0 (пример 3.8), но умеет при этом больше: он хранит все ключи в виде str, обходя тем самым неприятные сюрпризы, возможные, если при создании или обновле- нии экземпляра были добавлены данные с нестроковыми ключами. Пример 3.9. StrKeyDict всегда преобразует нестроковые ключи в тип str – при вставке, об- новлении и поиске import collections class StrKeyDict(collections.UserDict):  def __missing__(self, key):  if isinstance(key, str): raise KeyError(key) return self[str(key)] 1 Точное описание проблем, сопряженных с наследованием dict и другим встроенным классам, см. в разделе «Сложности наследования встроенным типам» главы 14. 118  Словари и множества\n--- Страница 118 ---\ndef __contains__(self, key): return str(key) in self.data  def __setitem__(self, key, item): self.data[str(key)] = item   StrKeyDict расширяет UserDict.  Метод __missing__ точно такой же, как в примере 3.8.  Метод __contains__ проще: можно предполагать, что все хранимые ключи имеют тип str, так что можно искать ключ в самом словаре self.data, а не вызывать self.keys() , как в классе StrKeyDict0 .  Метод __setitem__ преобразует любой ключ в тип str. Этот метод проще пере- определить, если можно делегировать работу атрибуту self.data. Поскольку UserDict – подкласс MutableMapping , остальные методы, благодаря ко- торым StrKeyDict является полноценным отображением, наследуются от UserDict, MutableMapping или Mapping. В двух последних есть несколько полезных конкрет - ных методов, хотя они и являются абстрактными базовыми классами (ABC). Стоит отметить следующие методы. MutableMapping.update Этот метод можно вызывать напрямую, но им также пользуется метод __init__ для инициализации экземпляра другими отображениями, итерируемыми объектами, порождающими пары (key, value) , и именованными аргументами. Поскольку для добавления элементов он использует конструкцию self[key] = value, то в конечном итоге будет вызвана наша реализация __setitem__ . Mapping.get В классе StrKeyDict0 (пример 3.8) мы вынуждены были самостоятель- но написать метод get, чтобы получаемые результаты были согласованы с __getitem__ , но в примере 3.9 мы унаследовали Mapping.get , который реали- зован в точности так, как StrKeyDict0.get (см. исходный код Python (https:// github.com/python/cpython/blob/0bbf30e2b910bc9c5899134ae9d73a8df968da35/ Lib/_collections_abc.py#L813)). Уже написав класс StrKeyDict , я обнаружил, что Антуан Питру (Antoine Pitrou) опубликовал документ PEP 455 «Adding a key- transforming dictionary to collections» (https://www.python.org/dev/ peps/pep-0455/) и исправление, дополняющее модуль collections классом TransformDict . Он более общий, чем StrKeyDict , и сохра- няет ключи в том виде, в котором они переданы, прежде чем применить к ним преобразование. Предложение PEP 455 было отвергнуто в мае 2015 года – см. возражение Раймонда Хэттин- гера (https://mail.python.org/pipermail/python-dev/2015-May/140003. html). Чтобы поэкспериментировать с классом TransformDict , я «выдернул» заплату Питру из проблемы 18986 (https://github. com/fluentpython/example-code-2e) в отдельный модуль (03-dictset/ transformdict.py) в репозитории кода к этой книге (https://github. com/fluentpython/example-code-2e)). Вариации на тему dict  119\n--- Страница 119 ---\nМы знаем, что существует несколько неизменяемых типов последователь- ностей, а как насчет неизменяемого словаря? В стандартной библиотеке тако- го не имеется, но выход есть. Читайте дальше. неизменяемые ОтОБражения Все типы отображений в стандартной библиотеке изменяемые, но иногда нуж- но гарантировать, что пользователь не сможет по ошибке модифицировать отображение. Конкретный пример снова дает проект Pingo, который я уже опи- сывал в разделе «Метод __missing__ » выше: отображение board.pins представляет физические контакты GPIO на плате. Поэтому было бы желательно предотвра- тить непреднамеренное изменение board.pins , потому что нельзя же изменять оборудование с помощью программы, т. е. любая такая модификация оказа- лась бы не согласованной с физическим устройством. Модуль types содержит класс-обертку MappingProxyType , который получает ото- бражение и возвращает объект mappingproxy , допускающий только чтение, но при этом являющийся динамическим представлением исходного отображения. Это означает, что любые изменения исходного отображения будут видны и в mappingproxy , но через него такие изменения сделать нельзя. Демонстрация при- ведена в примере 3.10. Пример 3.10. Класс MappingProxyType строит по словарю объект mappingproxy , допускаю- щий только чтение >>> d = {1: 'A'} >>> d_proxy = MappingProxyType(d) >>> d_proxy mappingproxy({1: 'A'}) >>> d_proxy[1]  'A' >>> d_proxy[2] = 'x'  Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: 'mappingproxy' object does not support item assignment >>> d[2] = 'B' >>> d_proxy  mappingproxy({1: 'A', 2: 'B'}) >>> d_proxy[2] 'B' >>>  Элементы d можно видеть через d_proxy.  Произвести изменения через d_proxy невозможно.  Представление d_proxy динамическое: любое изменение сразу же отражается. Вот как этим можно воспользоваться на практике в случае программирова- ния оборудования: конструктор конкретного подкласса Board инициализирует закрытое отображение объектами, представляющими контакты, и раскрыва- ет его клиентам API с помощью открытого атрибута .pins, реализованного как mappingproxy . Таким образом, клиент не сможет по ошибке добавлять, удалять и изменять контакты.120  Словари и множества\n--- Страница 120 ---\nДалее мы рассмотрим представления, которые позволяют очень эффектив- но производить операции с dict без необходимости копировать данные. предСтавления СлОваря Такие методы dict, как .keys(), .values() и .items(), возвращают экземпляры клас - сов dict_keys, dict_values и dict_items соответственно. Эти представления слова- ря – проекции внутренних структур данных, используемых в реализации dict, допускающие только чтение. Они обходятся без накладных расходов, прису - щих эквивалентным методам в Python 2, которые возвращали списки, дубли- рующие данные, уже хранящиеся в словаре. Кроме того, они заменяют старые методы, возвращавшие итераторы. В примере 3.11 показаны некоторые простые операции, поддерживаемые всеми представлениями словарей. Пример 3.11. Метод .values() возвращает представление значений в dict >>> d = dict(a=10, b=20, c=30) >>> values = d.values() >>> values dict_values([10, 20, 30])  >>> len(values)  3 >>> list(values)  [10, 20, 30] >>> reversed(values)  <dict_reversevalueiterator object at 0x10e9e7310> >>> values[0]  Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: 'dict_values' object is not subscriptable  Метод repr объекта представления показывает его содержимое.  Можно запросить длину представления len.  Представления допускают итерирование, поэтому из них легко создавать списки.  Представления реализуют метод __reversed__ , возвращающий пользователь- ский итератор.  Для получения отдельного элемента представления нельзя использовать оператор []. Объект представления – это динамический прокси-объект. Если исходный словарь изменился, то изменения сразу же становятся видны через имеющее- ся представление. Продолжим пример 3.11. >>> d['z'] = 99 >>> d {'a': 10, 'b': 20, 'c': 30, 'z': 99} >>> values dict_values([10, 20, 30, 99]) Классы dict_keys, dict_values и dict_items внутренние: они недоступны через __builtins__ или какой-либо модуль из стандартной библиотеки. Даже получив Представления словаря  121\n--- Страница 121 ---\nссылку на любой из них, вы не сможете воспользоваться ей в коде на Python, чтобы создать новое представление. >>> values_class = type({}.values()) >>> v = values_class() Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: cannot create 'dict_values' instances Класс dict_values – простейшее из представлений словарей: он реализует только специальные методы __len__, __iter__ и __reversed__ . Классы dict_keys и dict_ items дополнительно реализуют несколько методов множества – почти столько же, сколько класс frozenset. После того как мы рассмотрим множества, мы еще вернемся к классам dict_keys и dict_items в разделе «Теоретико-множественные операции над представлениями словарей». А теперь, вооруженные знаниями о внутренней реализации dict, сформули- руем некоторые правила и дадим рекомендации. практичеСкие пОСледСтвия внутреннег О уСтрОйСтва клаССа dict Реализация класса Python dict на основе хеш-таблиц очень эффективна, но важно понимать, какие последствия вытекают из такого проектного решения. Ключи должны быть хешируемыми объектами. Они должны правильно реализовывать методы __hash__ и __eq__, как описано в разделе «Что зна- чит “хешируемый”?». Доступ к элементу по ключу производится очень быстро. Словарь может содержать миллионы ключей, но Python для нахождения ключа нужно только вычислить хеш-код ключа и получить по нему смещение отно- сительно начала хеш-таблицы; возможно, еще придется выполнить не- сколько попыток, чтобы добраться до нужной записи. Порядок ключей сохраняется, это побочный эффект более компактного размещения словаря в памяти, реализованного в CPython 3.6 и ставшего официальной особенностью языка в версии 3.7. Несмотря на новое компактное размещение, словарям внутренне при- сущи большие накладные расходы на хранение в памяти. Самой ком- пактной внутренней структурой данных для контейнера был бы массив указателей на элементы1. По сравнению с этим хеш-таблица должна хра- нить больше данных на каждую запись, причем хотя бы треть записей должна оставаться незаполненной, чтобы интерпретатор мог работать эффективно. Для экономии памяти избегайте создания атрибутов экземпляров вне метода __init__. Последний совет насчет атрибутов экземпляров следует из того, что по умол- чанию Python хранит атрибуты экземпляров в специальном атрибуте __dict__, который представляет собой словарь, являющийся принадлежностью эк- 1 Именно так данные хранятся в кортежах.122  Словари и множества\n--- Страница 122 ---\nземпляра1. С тех пор как в версии Python 3.3 было реализовано предложение PEP 412 «Key-Sharing Dictionary» (https://peps.python.org/pep-0412/), экземпляры класса могут разделять общую хеш-таблицу, хранящуюся в самом классе. На эту общую хеш-таблицу ссылаются атрибуты __dict__ каждого нового экземпляра, имеющего такие же имена атрибутов, что и первый экземпляр этого клас - са, возвращенный __init__. Тогда __dict__ в каждом экземпляре может хранить только собственные значения атрибутов в виде простого массива указателей. Добавление атрибута экземпляра после возврата из __init__ заставляет Python создать новую хеш-таблицу для хранения __dict__ только одного этого экзем- пляра (такое поведение подразумевалось по умолчанию для всех экземпляров до версии Python 3.3). Согласно PEP 412, эта оптимизация сокращает потребле- ние памяти в объектно-ориентированных программах на 10–20 %. Детали компактного размещения в памяти и оптимизаций, связанных с раз- делением ключей, довольно сложны. Дополнительные сведения можно найти в статье «Internals of sets and dicts» (https://www.fluentpython.com/extra/internals-of- sets-and-dicts/) на сайте fluentpython.com. Теперь перейдем к множествам. теОрия мнО жеС тв Множества – сравнительно недавнее добавление к Python, которое использу - ется недостаточно широко. Тип set и его неизменяемый вариант frozenset впер- вые появились в виде модуля в Python 2.3, а в Python 2.6 были «повышены» до встроенных типов. В этой книге словом «множество» обозначается как set, так и frozenset . Множество – это набор уникальных объектов. Поэтому один из основных способов его использования – устранение дубликатов: >>> l = ['spam', 'spam', 'eggs', 'spam', 'bacon', 'eggs'] >>> set(l) {'eggs', 'spam', 'bacon'} >>> list(set(l)) ['eggs', 'spam', 'bacon'] Если вы хотите устранить дубликаты, сохранив при этом поря- док первого вхождения каждого элемента, можете воспользо- ваться простым словарем dict: >>> dict .fromkeys(l) .keys() dict_keys(['spam', 'eggs', 'bacon']) >>> list(dict .fromkeys(l) .keys()) ['spam', 'eggs', 'bacon'] 1 Если только в классе нет атрибута __slots__ , назначение которого объясняется в раз- деле «Экономия памяти с помощью __slots__» ниже. Теория множеств  123\n--- Страница 123 ---\nЭлементы множества должны быть хешируемыми. Сам тип set хешируемым не является, поэтому объекты set не могут вложенными. Но тип frozenset хеши- руемый, поэтому элементами set могут быть объекты типа frozenset. Помимо гарантии уникальности, типы множества предоставляют набор тео ретико-множественных операций, в частности инфиксные операции: если a и b – множества, то a | b – их объединение, a & b – пересечение, а a - b – раз- ность. Умелое пользование теоретико-множественными операциями помога- ет уменьшить как объем, так и время работы Python-программ и одновремен- но сделать код более удобным для восприятия и осмысления – за счет устране- ния циклов и условных конструкций. Пусть, например, у нас есть большой набор почтовых адресов (haystack, стог) и меньший набор адресов (needles, иголок), а наша задача – подсчитать, сколько раз элементы needles встречаются в haystack. Благодаря операции пе- ресечения множеств (оператор &) для ее решения достаточно одной строки (пример 3.12). Пример 3.12. Подсчет количества вхождений needles в haystack, оба объекта имеют тип set found = len(needles & haystack) Без оператора пересечения эту программу пришлось бы написать, как по- казано в примере 3.13. Пример 3.13. Подсчет количества вхождений needles в haystack (результат тот же, что в примере 3.10) found = 0 for n in needles: if n in haystack: found += 1 Программа из примера 3.12 работает чуть быстрее, чем из примера 3.13. С другой стороны, пример 3.13 работает для любых итерируемых объектов needles и haystack, тогда как в примере 3.12 требуется, чтобы оба были множест - вами. Впрочем, если исходные объекты множествами не были, то их легко можно построить на лету, как показано в примере 3.14. Пример 3.14. Подсчет количества вхождений needles в haystack; этот код работает для любых итерируемых типов found = len(set(needles) & set(haystack)) # или по-другому: found = len(set(needles).intersection(haystack)) Разумеется, построение множеств в примере 3.14 обходится не бесплатно, но если needles или haystack уже является множеством, то варианты, показанные в примере 3.14, могут оказаться дешевле кода из примера 3.13. Любой из показанных выше примеров тратит на поиск 1000 «иголок» в «сто- ге» haystack, состоящем из 10 000 000 элементов, чуть больше 0.3 миллисекунды, т. е. по 0.3 микросекунды на одну «иголку». Помимо чрезвычайно быстрой проверки вхождения (благодаря механизму хеш-таблиц), встроенные типы set и frozenset предоставляют богатый набор 124  Словари и множества\n--- Страница 124 ---\nопераций для создания новых множеств или – в случае set – модификации су- ществующих. Ниже мы обсудим эти операции, но сначала сделаем одно заме- чание о синтаксисе. Литеральные множества Синтаксис литералов типа set – {1}, {1, 2} и т. д. – выглядит в точности как мате- матическая нотация, за одним важным исключением: не существует литераль- ного обозначения пустого множества, в таком случае приходится писать set(). Синтаксический подвох Не забывайте: для создания пустого множества set следует ис- пользовать конструктор без аргументов: set(). Написав {}, вы, как и в прошлых версиях, создадите пустой словарь dict. В Python 3 для представления множеств строками используется нотация { } во всех случаях, кроме пустого множества: >>> s = {1} >>> type(s) <class 'set'> >>> s {1} >>> s.pop() 1 >>> s set() Литеральный синтаксис множеств вида {1, 2, 3} быстрее и понятнее, чем вызов конструктора (например, set([1, 2, 3]) ). При этом вторая форма медлен- нее, потому что для вычисления такого выражения Python должен найти класс set по имени, чтобы получить его конструктор, затем построить список и, на- конец, передать этот список конструктору. А при обработке литерала {1, 2, 3} Python исполняет специализированный байт-код BUILD_SET1. Не существует специального синтаксиса для литералов, представляющих frozenset, – их приходится создавать с помощью конструктора. И стандартное строковое представление в Python 3 выглядит как вызов конструктора frozenset. Ниже показан пример в сеансе оболочки: >>> frozenset(range(10)) frozenset({0, 1, 2, 3, 4, 5, 6, 7, 8, 9}) И раз уж мы заговорили о синтаксисе, то отметим, что хорошо знакомый синтаксис спискового включения был приспособлен и для построения мно- жеств. 1 Это, возможно, интересно, но не так уж важно. Ускорение достигается, только когда литеральное множество вычисляется, а это происходит не более одного раза в каж - дом процессе Python – при первоначальной компиляции модуля. Особо любозна- тельные могут импортировать функцию dis из модуля dis и с ее помощью дизас - семблировать байт-код создания литерального множества, например dis('{1}') , и вызова конструктора set – dis('set([1])') . Теория множеств  125\n--- Страница 125 ---\nМножественное включение Множественное включение (setcomp) было добавлено еще в версии Python 2.7 наряду со словарным включением, рассмотренным выше. См. пример 3.15. Пример 3.15. Построение множества символов Latin-1, в Unicode-названии которых встре- чается слово «SIGN» >>> from unicodedata import name  >>> {chr(i) for i in range(32, 256) if 'SIGN' in name(chr(i),'')}  {'§', '=', '¢', '#', '¤', '<', '¥', 'μ', '×', '$', '¶', ' ￡', '©', '°', '+', '÷', '±', '>', ' ￡', '®', '%'}  Импортировать функцию name из unicodedata для получения названий симво- лов.  Построить множество символов с кодами от 32 до 255, в названиях которых встречается слово «SIGN» Порядок вывода символов будет разным в разных процессах Python из-за случайного начального значения при создании хеша (см. раздел «Что такое “хешируемый”?». Но оставим в стороне вопросы синтаксиса и перейдем к поведению множеств. практичеСкие пОСледСтвия внутреннег О уСтрОйСтва клаССа set Типы set и frozenset реализованы с помощью хеш-таблиц. Отсюда вытекает ряд следствий. Элементы множества должны быть хешируемыми объектами. Ключи должны быть хешируемыми объектами. Они должны правильно реали- зовывать методы __hash__ и __eq__, как описано в разделе «Что значит “хе- шируемый”?». Проверка на членство производится очень эффективно. Множество мо- жет содержать миллионы элементов, но для нахождения элемента нуж- но только вычислить его хеш-код и получить по нему смещение отно- сительно начала хеш-таблицы; возможно, еще придется выполнить не- сколько попыток, чтобы добраться до нужного элемента или убедиться, что его не существует. Множествам присущи большие накладные расходы на хранение в памя- ти по сравнению с низкоуровневым массивом указателей на элементы, что было бы компактнее, но резко замедлило бы поиск, если число эле- ментов в множестве сколько-нибудь велико. Порядок элементов зависит от порядка вставки, но опираться на эту за- висимость не рекомендуется, т. к. это ненадежно. Если два элемента раз- личны, но имеют одинаковый хеш-код, то их взаимное расположение зависит от того, какой элемент был добавлен первым. Добавление элементов в множество может изменить порядок уже при- сутствующих в нем элементов. Это связано с тем, что эффективность ал- горитма падает, когда хеш-таблица заполнена на две трети или более, 126  Словари и множества\n--- Страница 126 ---\nпоэтому Python приходится увеличивать размер таблицы по мере ее рос та, что влечет за собой перемещение в памяти. Когда такое происхо- дит, элементы вставляются заново, и их относительный порядок может измениться. Дополнительные сведения можно найти в статье «Internals of sets and dicts» (https://www.fluentpython.com/extra/internals-of-sets-and-dicts/) на сайте fluentpython.com. Теперь рассмотрим богатый ассортимент операций над множествами. Операции над множествами На рис. 3.2 приведена сводка методов, которые имеются у изменяемых и не- изменяемых множеств. Многие из них – специальные методы, поддерживаю- щие перегрузку операторов. В табл. 3.2 показаны математические операции над множествами, которым соответствуют какие-то операторы или методы в Python. Отметим, что некоторые операторы и методы изменяют конечное множество на месте (например, &=, difference_update и т. д.). Таким операциям нет места в идеальном мире математических множеств, и в классе frozenset они не реализованы. Инфиксные операторы, приведенные в табл. 3.2, требуют, чтобы оба операнда были множествами, но все остальные методы принимают в качестве аргументов один или несколько итерируемых объектов. Например, чтобы создать объединение четырех коллекций a, b, c, d, можно написать a.union(b, c, d) , где a должно иметь тип set и b, c и d могут быть итерируемыми объектами любого типа, порождающе- го хешируемые элементы. Если требуется создать новое множество, являющееся объединением четырех итерируемых объектов, то вместо модификации существующего множества можно написать {*a, *b, *c, *d} . Это предложено в документе PEP 448 «Additional Unpacking Generalizations» (https://peps.python.org/pep-0448/) и реали- зовано начиная с версии Python 3.5. Рис. 3.2. UML-диаграмма класса MutableSet и его суперклассов из модуля collections.abc (курсивом набраны имена абстрактных классов и абстрактных методов, инверсные опера- торные методы для краткости опущены) Практические последствия внутреннего устройства класса set  127\n--- Страница 127 ---\nТаблица 3.2. Математические операции над множествами: эти методы либо порождают новое множество, либо модифицируют конечное множество на месте (если оно изменяемое) Мат. символОператор PythonМетод Описание S ∩ Z s & z s.__and__(z) Пересечение s и z s.intersection(it,…) Пересечение s и всех множеств, построенных из итерируемых объектов it и т. д. s &= z s.__iand__(z) Замена s пересечением s и z s.intersection_update(it,…) Замена s пересечением s и всех множеств, построенных из ите- рируемых объектов it и т. д. S ∪ Z s | z s.__or__(z) Объединение s и z z | s z.__ror__(s) Инверсный оператор | s.union(it,…) Объединение s и всех множеств, построенных из итерируемых объектов it и т. д. s |= z s.__ior__(z) Замена s объединением s и z s.update(it,…) Замена s объединением s и всех множеств, построенных из ите- рируемых объектов it и т. д. S \\ Z s - z s.__sub__(z) Относительное дополнение или разность s и z z - s z.__rsub__(s) Инверсный оператор - s.difference(it,…) Разность между s и всеми множествами, построенными из итерируемых объектов it и т. д. s -= z s.__isub__(z) Замена s разностью между s и z s.difference_update(it,…) Замена s разностью между s и всеми множествами, построен- ными из итерируемых объектов it и т. д. s.symmetric_difference(it) Дополнение s & set(it) S Δ Z s ^ z s.__xor__(z) Симметрическая разность (до- полнение пересечения s & z) z ^ s z.__rxor__(s) Инверсный оператор ^ s.symmetric_difference_ update(it,…)Замена s симметрической разностью между s и всеми множествами, построенными из итерируемых объектов it и т. д. s ^= z s.__ixor__(z) Замена s симметрической раз- ностью между s и z В табл. 3.3 перечислены теоретико-множественные предикаты: методы и операторы, которые возвращают True или False.128  Словари и множества\n--- Страница 128 ---\nТаблица 3.3. Операторы сравнения множеств и методы, возвращающие булево значение Мат. символОператор PythonМетод Описание S ∩ Z = ∅ s.isdisjoint(z) s и z дизъюнктны (т. е. не пересекаются) e ∈ Z e in s s.__contains__(e) e является элементом s S ⊆ Z s <= z s.__le__(z) s является подмножеством z s.issubset(it) s является подмножеством множества z, по- строенного из итерируемого объекта it S ⊂ Z s < z s.__lt__(z) s является собственным подмножеством z S ⊇ Z s >= z s.__ge__(z) s является надмножеством z s.issuperset(it) s является надмножеством множества z, по- строенного из итерируемого объекта it S ⊃ Z s > z s.__gt__(z) s является собственным надмножеством z Помимо теоретико-множественных операторов и методов, типы мно- жеств реализуют и другие методы, полезные на практике. Они сведены в табл. 3.4. Таблица 3.4. Дополнительные методы множеств set frozenset s.add(e) ● Добавить элемент e в s s.clear() ● Удалить все элементы из s s.copy() ● ● Поверхностная копия s s.discard(e) ● Удалить элемент e из s, если он там присутствует s.__iter__() ● ● Получить итератор для обхода s s.__len__() ● ●len(s) s.pop() ● Удалить и вернуть элемент s, возбудив исключение KeyError , если s пусто s.remove(e) ● Удалить элемент e из s, возбудив исключение KeyError , если e отсутствует в s На этом мы завершаем обзор множеств и их возможностей. Теперь, как и было обещано в разделе «Представления словарей», убедимся, что два типа представления словарей ведут себя очень похоже на frozenset. теОретик О-мнО жеС твенные Операции над пред Ставлениями СлОварей В табл. 3.5 показано, что объекты представлений, возвращаемые методами .keys() и .items() объекта dic, удивительно похожи на frozenset. Теоретико-множественные операции над представлениями словарей  129\n--- Страница 129 ---\nТаблица 3.4. Дополнительные методы множеств frozenset dict_keys dict_ itemsОписание s.__and__(z) ● ● ●s & z (пересечение s и z) s.__rand__(z) ● ● ● Инверсный оператор & s.__contains_ _()● ● ●e является элементом s s.copy() ● Поверхностная копия s s.difference(it,…) ● Разность между s и итерируемы- ми объектами it и т. д. s.intersection(it,…) ● Пересечение s и итерируемых объектов it и т. д. s.isdisjoint(z) ● ● ●s и z дизъюнктны (т. е. не имеют общих элементов) s.issubset(it) ● s является подмножеством итерируемого объекта it s.issuperset(it) ● s является надмножеством ите- рируемого объекта it s.__iter__() ● ● ● Получить итератор для обхода s s.__len__() ● ● ●len(s) s.__or__(z) s | z (объединение s и z) s.__ror__(z) ● ● ● Инверсный оператор | s.__reversed_ _()● ● Получить итератор для обхода s в обратном порядке s.__rsub__(z) ● ● ● Инверсный оператор - s.__sub__(z) ● ● ●s – z (разность s и z) s.symmetric_ difference(it)● Дополнение s & set(it) s.union(it,…) ● Объединение s и итерируемых объектов it и т. д. s.__xor__(z) ● ● ●s ^ z (симметрическая разность s & z) s.__rxor__(z) ● ● ● Инверсный оператор ^ В частности, dict_keys и dict_items реализуют специальные методы для под- держки операторов над множествами & (пересечение), | (объединение), - (раз- ность) и ^ (симметрическая разность). Например, с помощью & легко получить ключи, встречающиеся в двух сло- варях: >>> d1 = dict(a=1, b=2, c=3, d=4) >>> d2 = dict(b=20, d=40, e=50) >>> d1.keys() & d2.keys() {'b', 'd'}130  Словари и множества\n--- Страница 130 ---\nОтметим, что оператор & возвращает значение типа set. Более того, операто- ры над множествами в представлениях словарей совместимы с экземплярами set. Убедимся в этом: >>> s = {'a', 'e', 'i'} >>> d1.keys() & s {'a'} >>> d1.keys() | s {'a', 'c', 'b', 'd', 'i', 'e'} Представление dict_items работает как множество, только если все значения в словаре допускают хеширование. Попытка при- менить операцию над множествами к представлению dict_ items с нехешируемыми значениями приводит к исключению TypeError: unhashable type 'T' , где T – тип недопустимого значения. С другой стороны, представление dict_keys всегда можно ис- пользовать как множество, потому что все ключи словаря явля- ются хешируемыми по определению. Применение операторов множества к представлениям позволяет отказаться от многочисленных циклов и условных предложений при исследовании содер- жимого словарей. Заставьте эффективную реализацию Python, написанную на C, работать для вас! На этом мы можем подвести итоги. резюме Словари – краеугольный камень Python. С годами знакомый синтаксис литера- лов {k1: v1, k2: v2} пополнился поддержкой распаковки с помощью оператора **, сопоставлением с образцом и словарным включением. Помимо базового класса dict, в стандартной библиотеке имеются удобные, го- товые к применению специализированные отображения, например defaultdict , OrderedDict , ChainMap и Counter, все они определены в модуле collections . После внед- рения новой реализации dict класс OrderedDict уже не так полезен, как прежде, но остается в стандартной библиотеке ради обратной совместимости; к тому же он обладает рядом свойств, отсутствующих у dict, в частности принимает во вни- мание порядок ключей в сравнениях словарей на равенство ==. Также в модуле collections находится предназначенный для расширения класс UserDict. Два весьма полезных метода, имеющихся в большинстве отображений, – setdefault и update. Метод setdefault используется для модификации элементов, содержащих изменяемые значения, например в словаре значений типа list, чтобы избежать повторных операций поиска того же ключа. Метод update об- легчает массовую вставку или перезапись элементов, когда новые элементы берутся из другого отображения, из итерируемого объекта, порождающего пары (key, value) , или из именованных аргументов. Конструкторы отображе- ний также пользуются методом update, что позволяет инициализировать ото- бражение другим отображением, итерируемым объектом или именованными аргументами. Начиная с версии Python 3.9 мы также можем использовать опе- ратор |= для модификации отображения и оператор | для создания нового ото- бражения из объединения двух существующих. Резюме  131\n--- Страница 131 ---\nВ API отображений имеется метод __missing__ , который позволяет опреде- лить, что должно происходить в случае отсутствия ключа при использовании синтаксической конструкции d[k], которая вызывает метод __getitem__ . Модуль collections.abc содержит абстрактные базовые классы Mapping и MutableMapping для справки и контроля типов. Класс MappingProxyType из моду - ля types позволяет создавать неизменяемый фасад для отображения, которое требуется защитить от непреднамеренного изменения. Существуют также аб- страктные базовые классы Set и MutableSet . Представления словарей стали замечательным приобретением в Python 3, поскольку позволили исключить дополнительный расход памяти при исполь- зовании методов .keys(), .values() и .items(), которые в Python 2 строили списки, дублирующие данные, уже присутствовавшие в экземпляре dict. Кроме того, классы dict_keys и dict_items поддерживают наиболее полезные операторы и ме- тоды класса frozenset. дОпО лнительная литература В разделе документации по стандартной библиотеке Python «collections – кон- тейнерные типы данных» (https://docs.python.org/3/library/collections.html) есть примеры и практические рецепты использования различных типов отображе- ний. Исходный код модуля Lib/collections/init.py станет отличным справочным пособием для всех, кто захочет написать новый тип отображения или разо- браться в логике работы существующих. В главе 1 книги David Beazley, Brian K. Jones «Python Cookbook», 3-е издание (O’Reilly), имеется 20 полезных и по- учительных примеров работы со структурами данных – в большинстве из них изобретательно используется словарь dict. Грег Гандербергер выступает за то, чтобы и дальше использовать класс collections. OrderedDict на том основании, что «явное лучше неявного», а также ради обратной совместимости и потому что некоторые инструменты и би- блиотеки предполагают, что порядок ключей в dict несуществен. См. его статью «Python Dictionaries Are Now Ordered. Keep Using OrderedDict» (http:// gandenberger.org/2018/03/10/ordered-dicts-vs-ordereddict/). Документ PEP 3106 «Revamping dict.keys(), .values() and .items()» (https://peps. python.org/pep-3106/) – то место, где Гвидо ван Россум впервые описал представ- ления словарей для Python 3. В реферате он написал, что идея навеяна коллек - циями в Java. PyPy (https://www.pypy.org/) стал первым интерпретатором Python, в кото- ром было реализовано предложение Раймонда Хэттингера по поводу ком- пактных словарей. Авторы рассказали об этом в статье «Faster, more memory efficient and more ordered dictionaries on PyPy» (https://morepypy.blogspot. com/2015/01/faster-more-memory-efficient-and-more.html), признав, что похожее раз- мещение в памяти использовалось в PHP 7 и было описано в статье «PHP’s new hashtable implementation» (https://www.npopov.com/2014/12/22/PHPs-new-hashtable- implementation.html). Всегда приятно, когда авторы ссылаются на достижения своих предшественников. На конференции PyCon 2017 Брэндон Родес провел презентацию «The Dictionary Even Mightier» (https://www.youtube.com/watch?v=66P5FMkWoVU), 132  Словари и множества\n--- Страница 132 ---\nпродолжение его классической анимированной презентации «The Mighty Dictionary» (https://pyvideo.org/pycon-us-2010/the-mighty-dictionary-55.html), вклю- чавшей анимированные коллизии в хеше! Еще одно современное, но более глубокое видео, посвященное внутреннему устройству словарей в Python, – «Modern Dictionaries» (https://www.youtube.com/watch?v=p33CVV29OG8) Раймонда Хэттингера, где он рассказывает, что после первой неудачной попытки «впа- рить» компактные словари разработчикам ядра CPython он обратился к коман- де PyPy, те приняли его идею, она вызвала интерес, и в конечном итоге Инада Наоки включил ее в CPython 3.6 (https://docs.python.org/3/whatsnew/3.6.html#new- dict-implementation). Полную информацию можно почерпнуть из пространного комментария к файлу Objects/dictobject.c ( https://github.com/python/cpython/blob/ cf7eaa4617295747ee5646 c4e2b7e7a16d7c64ab/Objects/dictobject.c) в коде CPython и в техническом документе Objects/dictnotes.txt ( https://github.com/python/cpython/ blob/cf7eaa4617295747ee5646c 4e2b7e7a16d7c64ab/Objects/dictnotes.txt). Аргументация в пользу добавления множеств в язык приведена в документе PEP 218 «Adding a Built-In Set Object Type» (https://www.python.org/dev/peps/pep-0218/). Когда этот документ был одобрен, для множеств еще не была принята какая- то специальная литеральная нотация. Литеральные множества появились в Python 3, а затем были внедрены и в версию Python 2.7 наряду со словарны- ми и множественными включениями. На конференции PyCon 2019 я провел презентацию «Set Practice: learning from Python’s set types» (https://speakerdeck. com/ramalho/python-set-practice-at-pycon), в которой описал случаи использования множеств в реальных программах, рассмотрел структуру их API и реализацию uintset (https://github.com/ramalho/uintset) – класса множества целых чисел с ис - пользованием битового вектора вместо хеш-таблицы, идея которого была навеяна примером из главы 6 замечательной книги Alan Donovan and Brian Kernighan «The Go Programming Language» (издательство Addison-Wesley)1. В журнале Spectrum (), издаваемом IEEE, напечатан рассказ о Хансе Пете- ре Луне, плодовитом изобретателе, который запатентовал колоду перфокарт для выбора рецептов коктейлей в зависимости от доступных ингредиентов, а также ряд других изобретений, в том числе … хеш-таблицы! См. статью «Hans Peter Luhn and the Birth of the Hashing Algorithm» (https://spectrum.ieee.org/hans- peter-luhn-and-the-birth-of-the-hashing-algorithm). Поговорим Синтаксический сахар Мой друг Джеральдо Коэн как-то заметил, что Python – «простой и коррект - ный язык». Ревнители чистоты языков программирования часто отметают синтаксис как нечто несущественное. Синтаксический сахар вызывает рак точек с запятой. – Алан Перлис 1 Алан Донован, Брайан У. Керниган. Язык программирования Go. Диалектика-Вильямс, 2020. Дополнительная литература  133\n--- Страница 133 ---\nСинтаксис – это пользовательский интерфейс языка программирования, по- этому на практике он очень важен. До того как я открыл для себя Python, я писал веб-приложения на Perl, PHP и JavaScript. Мне очень нравился литеральный синтаксис отображений в этих языках, которого так не хватало в Java и C. Хороший синтаксис литеральных отображений упрощает конфигурирование, реализации на основе таблиц и хранение данных для создания прототипов и тестирования. Это тот урок, который извлекли проектировщики Go из ана- лиза динамических языков. Отсутствие такого синтаксиса для выражения структурированных данных в самом коде вынудило сообщество Java принять многословный и чрезмерно сложный язык XML в качестве формата данных. Формат JSON был предложен как «обезжиренная альтернатива XML» (http:// www.json.org/fatfree.html) и добился ошеломительного успеха, заменив XML во многих контекстах. Благодаря краткому синтаксису списков и словарей он от- лично подходит на роль формата для обмена данными. PHP и Ruby позаимствовали синтаксис хеша из Perl, где для ассоциации клю- чей и значений применяется оператор =>. JavaScript последовал по стопам Python и использует для этой цели знак :. Зачем использовать два символа, когда для удобочитаемости хватает и одного? Истоки JSON следует искать в JavaScript, но так получилось, что это почти точ- ное подмножество синтаксиса Python. JSON совместим с Python во всем, кро- ме написания значений true, false и null. Армин Ронахер в своем твите (https://fpy.li/3-33) пишет, что ему понравилось «подправить» глобальное пространство имен Python, добавив совместимые с JSON псевдонимы для символов Python True, False и None, так что теперь он может копировать JSON прямо на консоль. Вот как выглядит его идея: >>> true, false, null = True, False, None >>> fruit = { \"type\": \"banana\", \"avg_weight\": 123.2, \"edible_peel\": false, \"species\": [\"acuminata\", \"balbisiana\", \"paradisiaca\"], \"issues\": null, } >>> fruit {'type': 'banana', 'avg_weight': 123.2, 'edible_peel': False, 'species': ['acuminata', 'balbisiana', 'paradisiaca'], 'issues': None} Синтаксис, которым ныне все пользуются для обмена данными, – это синтак - сис словаря и списка в Python. Теперь у нас есть изящный синтаксис, который к тому же сохраняет порядок вставки. Просто и корректно.134  Словари и множества",
      "debug": {
        "start_page": 98,
        "end_page": 133
      }
    },
    {
      "name": "Глава 4. Unicode-текст и байты 135",
      "content": "--- Страница 134 --- (продолжение)\nГлава 4 Unicode-текст и байты Человек работает с текстом, компьютер – с байтами. – Эстер Нэм и Трэвис Фишер, «Кодировка символов и Unicode в Python»1 В Python 3 появилось четкое различие между строками текста, предназначен- ными для человека, и последовательностями байтов. Неявное преобразование последовательности байтов в Unicode-текст ушло в прошлое. В этой главе речь пойдет о Unicode-строках, двоичных последовательностях и кодировках для преобразования одного в другое. Так ли важно глубоко разбираться в Unicode? Ответ на этот вопрос зави- сит от того, в какой области вы программируете на Python. Но, так или иначе, от различий между типами str и byte никуда не деться. А в качестве премии за потраченные усилия вы узнаете, что специализированные типы двоичных по- следовательностей обладают возможностями, которых нет у «универсального» типа str в Python 2. В этой главе мы рассмотрим следующие вопросы: символы, кодовые позиции и байтовые представления; уникальные особенности двоичных последовательностей: bytes, bytearray и memoryview ; кодировки для полного Unicode и унаследованных наборов символов; как предотвращать и обрабатывать ошибки кодировки; рекомендации по работе с текстовыми файлами; кодировка по умолчанию и стандартные проблемы ввода-вывода; безопасное сравнение Unicode-текстов с нормализацией; служебные функции для нормализации, сворачивания регистра и явно- го удаления диакритических знаков; правильная сортировка Unicode-текстов с помощью модуля locale и биб- лиотеки pyuca; символьные метаданные в базе данных Unicode; двухрежимные API для работы с типами str и bytes. 1 Слайд 12 выступления на конференции PyCon 2014 «Character Encoding and Unicode in Python» (слайды – https://www.slideshare.net/fischertrav/character-encoding-unicode-how- to-with-dignity-33352863, видео – https://pyvideo.org/pycon-us-2014/character-encoding-and- unicode-in-python.html).\nГлава 4 Unicode-текст и байты Человек работает с текстом, компьютер – с байтами. – Эстер Нэм и Трэвис Фишер, «Кодировка символов и Unicode в Python»1 В Python 3 появилось четкое различие между строками текста, предназначен- ными для человека, и последовательностями байтов. Неявное преобразование последовательности байтов в Unicode-текст ушло в прошлое. В этой главе речь пойдет о Unicode-строках, двоичных последовательностях и кодировках для преобразования одного в другое. Так ли важно глубоко разбираться в Unicode? Ответ на этот вопрос зави- сит от того, в какой области вы программируете на Python. Но, так или иначе, от различий между типами str и byte никуда не деться. А в качестве премии за потраченные усилия вы узнаете, что специализированные типы двоичных по- следовательностей обладают возможностями, которых нет у «универсального» типа str в Python 2. В этой главе мы рассмотрим следующие вопросы: символы, кодовые позиции и байтовые представления; уникальные особенности двоичных последовательностей: bytes, bytearray и memoryview ; кодировки для полного Unicode и унаследованных наборов символов; как предотвращать и обрабатывать ошибки кодировки; рекомендации по работе с текстовыми файлами; кодировка по умолчанию и стандартные проблемы ввода-вывода; безопасное сравнение Unicode-текстов с нормализацией; служебные функции для нормализации, сворачивания регистра и явно- го удаления диакритических знаков; правильная сортировка Unicode-текстов с помощью модуля locale и биб- лиотеки pyuca; символьные метаданные в базе данных Unicode; двухрежимные API для работы с типами str и bytes. 1 Слайд 12 выступления на конференции PyCon 2014 «Character Encoding and Unicode in Python» (слайды – https://www.slideshare.net/fischertrav/character-encoding-unicode-how- to-with-dignity-33352863, видео – https://pyvideo.org/pycon-us-2014/character-encoding-and- unicode-in-python.html).\n--- Страница 135 ---\nчтО нОвОг О в этОй главе Поддержка Unicode в Python 3 достаточно полная и стабильная, поэтому самое заметное добавление – раздел «Поиск символов по имени», в котором описана утилита для поиска в базе данных Unicode – отличный способ искать цифры в кружочках и улыбающихся котят прямо из командной строки. Заслуживает также упоминания небольшое изменение в поддержке Unicode в Windows, которая стала лучше и проще начиная с версии Python 3.6, в чем у нас будет случай убедиться в разделе «Остерегайтесь кодировок по умолчанию». Начнем с не особенно новых, но фундаментальных понятий: символов, кодовых позиций и байтов. Для второго издания я расширил раздел, посвященный модулю struct, и опубликовал его в виде статьи «Parsing binary records with struct» (https://www.fluentpython.com/extra/parsing-binary-struct/) на сопроводительном сайте fluentpython.com. Там же вы найдете статью «Building Multi-character Emojis» (https://www.fluentpython.com/extra/multi-character-emojis/), в которой описано, как создавать эмодзи с изображением флагов стран, людей с разным цветом кожи и значки из различных семейств путем комбинирования символов Unicode. О СимвО лах, и не тОлькО Концепция «строки» достаточно проста: строка – это последовательность сим- волов. Проблема – в определении понятия «символ». В 2021 году под «символом» мы понимаем символ Unicode, и это лучшее определение на сегодняшний момент. Поэтому отдельными элементами объ- екта типа str в Python 3 являются символы Unicode (точно так же обстоит дело с элементами объекта unicode в Python 2), – а не просто байты, из которых со- стоят объекты str в Python 2. Стандарт Unicode явно разделяет идентификатор символа и конкретное байтовое представление. Идентификатор символа – его кодовая позиция – это число от 0 до 1 114 111 (по основанию 10), которое в стандарте Unicode записывается шестнадца- теричными цифрами (в количестве от 4 до 6) с префиксом «U+». Например, кодовая позиция буквы A равна U+0041, знака евро – U+20AC, музыкального символа скрипичного ключа – U+1D11E. В версии Unicode 13.0.0 (используемой в Python 3.10.0b4) конкретные символы сопоставлены примерно 13 % допусти- мых кодовых позиций. Какими именно байтами представляется символ, зависит от используе- мой кодировки. Кодировкой называется алгоритм преобразования кодовых позиций в последовательности байтов и наоборот. Кодовая позиция буквы A (U+0041) кодируется одним байтом \\x41 в кодировке UTF-8 и двумя байтами \\x41\\x00 в кодировке UTF-16LE. Другой пример: знак евро (U+20AC) преобразу - ется в три байта в UTF-8 – \\xe2\\x82\\xac , но в UTF-16LE кодируется двумя байта- ми – \\xac\\x20. 136  Unicode-текст и байты\n--- Страница 136 ---\nПреобразование из кодовых позиций в байты называется кодированием, пре- образование из байтов в кодовые позиции – декодированием. См. пример 4.1. Пример 4.1. Кодирование и декодирование >>> s = 'café' >>> len(s)  4 >>> b = s.encode('utf8')  >>> b b'caf\\xc3\\xa9'  >>> len(b)  5 >>> b.decode('utf8')  'café'  Строка 'café' состоит из четырех символов Unicode.  Преобразуем str в bytes, пользуясь кодировкой UTF-8.  Литералы типа bytes начинаются префиксом b.  Объект b типа bytes состоит из пяти байт (кодовая позиция, соответствую- щая «é», в UTF-8 кодируется двумя байтами).  Преобразуем bytes обратно в str, пользуясь кодировкой UTF-8. Если вы никак не можете запомнить, когда употреблять .decode() , а когда – .encode() , представьте, что последовательности байтов – это загадочный дамп памяти машины, а объекты Unicode str – «человеческий» текст. Тогда декодирование bytes в str призвано получить понятный человеку текст, а кодирование str в bytes – получить представление, пригодное для хранения или передачи. Тип str в Python 3 – это, по существу, не что иное, как переименованный тип unicode из Python 2. Но вот тип bytes в Python 3 – не просто старый тип str, и с ним тесно связан тип bytearray. Поэтому имеет смысл сначала разобраться с типами двоичных последовательностей, а уж потом переходить к вопросам кодирования и декодирования. вСе, чтО нужнО знать О Байтах Новые типы двоичных последовательностей во многих отношениях похожи на тип str в Python 2. Главное, что нужно знать, – это то, что существуют два основных встроенных типа двоичных последовательностей: неизменяемый тип bytes, появившийся в Python 3, и изменяемый тип bytearray, добавленный в Python 2.61. В документации по Python иногда используется общий термин «байтовая строка» (byte string) для обозначения и bytes, и bytearray. Я стараюсь не употреблять этот создающий путаницу термин. Каждый элемент bytes или bytearray – целое число от 0 до 255, а не односим- вольная строка, как в типе str в Python 2 str. Однако срез двоичной последова- тельности всегда является двоичной последовательностью того же типа, даже если это срез длины 1. См. пример 4.2. 1 В Python 2.6 и 2.7 был также тип bytes, но теперь это просто псевдоним типа str. Все, что нужно знать о байтах  137\n--- Страница 137 ---\nПример 4.2. Пятибайт овая последовательность в виде bytes и bytearray >>> cafe = bytes('café', encoding='utf_8')  >>> cafe 2 b'caf\\xc3\\xa9' >>> cafe[0]  99 >>> cafe[:1]  b'c' >>> cafe_arr = bytearray(cafe) >>> cafe_arr  bytearray(b'caf\\xc3\\xa9') >>> cafe_arr[-1:]  bytearray(b'\\xa9')  bytes можно получить из str, если известна кодировка.  Каждый элемент – целое число в диапазоне range(256) .  Срезы bytes также имеют тип bytes, даже если срез состоит из одного байта.  Для типа bytearray не существует литерального синтаксиса: в оболочке объ- екты этого типа представляются в виде конструктора bytearray() , аргумен- том которого является литерал типа bytes.  Срез bytesarray также имеет тип bytesarray . Тот факт, что my_bytes[0] возвращает int, а my_bytes[:1] – по- следовательность объектов bytes длины 1, вызывает удивле- ние только потому, что мы привыкли, что для типа Python str имеет место равенство s[0] == s[:1] . Для всех остальных типов последовательностей один элемент – не то же самое, что срез длины 1. Хотя двоичные последовательности – на самом деле последовательности целых чисел, в их литеральной нотации отражен тот факт, что часто они вклю- чают ASCII-текст. Поэтому применяются различные способы отображения, за- висящие от значения каждого байта. Для байтов с десятичными кодами от 32 до 126 – от пробела до ~ – выво- дится сам символ ASCII. Для байтов, соответствующих символам табуляции, новой строки, возвра- та каретки и \\, выводятся управляющие последовательности \\t, \\n, \\r и \\\\. Если в последовательности байтов встречаются оба ограничителя ' и «, то вся последовательность заключается в одиночные кавычки ', а все сим- волы ' внутри нее экранируются, т. е. записываются в виде \\'1. Для всех остальных байтов выводится шестнадцатеричное представле- ние (например, нулевой байт представляется последовательностью \\x00). Именно поэтому в примере 4.2 мы видим представление b'caf\\xc3\\xa9' : пер- вые три байта b'caf' принадлежат диапазону символов ASCII с графическим начертанием, последний – нет. 1 Любопытный факт: символ ASCII «одиночная кавычка», который в Python по умол- чанию используется как ограничитель строки, в стандарте Unicode называется APOSTROPHE. А настоящие одиночные кавычки асимметричны: левая имеет код U+2018, а правая – U+2019. 138  Unicode-текст и байты\n--- Страница 138 ---\nОба типа, bytes и bytearray, поддерживают все методы типа str, кроме тех, что относятся к форматированию (format, format_map ), и еще нескольких, прямо зависящих от особенностей Unicode, в том числе casefold, isdecimal, isidentifier , isnumeric, isprintable и encode. Это означает, что при работе с двоичными последо- вательностями мы можем пользоваться знакомыми методами строк, напри- мер endswith, replace, strip, translate, upper и десятками других, только аргументы должны иметь тип bytes, а не str. К двоичным последовательностям приме- нимы и функции для работы с регулярными выражениями из модуля re, если регулярное выражение откомпилировано из двоичной последовательности, а не из str. Начиная с версии Python 3.5 оператор % снова работает с двоичны- ми последовательностями1. Для двоичных последовательностей существует метод класса, отсутствую- щий в типе str: fromhex, который строит последовательность, разбирая пары шестнадцатеричных цифр, которые могут быть разделены пробелами, хотя это и необязательно. >>> bytes.fromhex('31 4B CE A9') b'1K\\xce\\xa9' Другие способы построения объектов bytes и bytearray связаны с вызовом различных конструкторов: с именованными аргументами str и encoding ; с итерируемым объектом, порождающим элементы со значениями от 0 до 255; с объектом, который реализует протокол буфера (например, bytes, bytearray, memoryview , array.array ), при этом байты копируются из исходного объекта во вновь созданную двоичную последовательность. До версии Python 3.5 можно было также вызывать конструкторы bytes и bytearray , передавая одное целое число, чтобы создать двоичную последовательность такого размера, инициализиро- ванную нулевыми байтами. Эта сигнатура была объявлена не- рекомендуемой в Python 3.5 и исключена в Python 3.6. См. до- кумент PEP 467 «Minor API improvements for binary sequences» (https://www.python.org/dev/peps/pep-0467/). Построение двоичной последовательности из буфероподобного объекта – это низкоуровневая операция, которая может потребовать приведения типов. См. пример 4.3. Пример 4.3. Инициализация байтов данными, хранящимися в массиве >>> import array >>> numbers = array.array('h', [-2, -1, 0, 1, 2])  >>> octets = bytes(numbers)  >>> octets b'\\xfe\\xff\\xff\\xff\\x00\\x00\\x01\\x00\\x02\\x00'   Код типа 'h' означает создание массива коротких целых (16-разрядных). 1 Он не работал в версиях Python с 3.0 до 3.4, что причиняло много страданий разработ - чикам, имеющим дело с двоичными данными. Возврат к прошлому документирован в PEP 461 «Adding % formatting to bytes and bytearray» (https://peps.python.org/pep-0461/). Все, что нужно знать о байтах  139\n--- Страница 139 ---\n В объекте octets хранится копия байтов, из которых составлены числа в мас - сиве numbers.  Это десять байт, представляющих пять коротких целых. Создание объекта bytes или bytearray из буфероподобного источника всегда сопровождается копированием байтов. Напротив, объекты типа memoryview по- зволяют разным двоичным структурам данных использовать одну и ту же об- ласть памяти, как мы видели в разделе «Представления областей памяти». После этого краткого введения в типы двоичных последовательностей в Python рассмотрим их преобразования в строки и обратно. БазОвые кОдир Овщики и декОдир Овщики В дистрибутиве Python имеется свыше 100 кодеков (кодировщик-декодиров- щик) для преобразования текста в байты и обратно. У каждого кодека есть имя, например 'utf_8', а часто еще и синонимы, например 'utf8', 'utf-8' и 'U8'. Имя можно передать в качестве аргумента encoding таким функциям, как open(), str. encode(), bytes.decode() и т. д. В примере 4.4 показан один и тот же текст, закоди- рованный как три разные последовательности байтов. Пример 4.4. Строка «El Niño», закодированная тремя кодеками, дает совершенно разные последовательности байтов >>> for codec in ['latin_1', 'utf_8', 'utf_16']: print(codec, 'El Niño'.encode(codec), sep='\\t') latin_1 b'El Ni\\xf1o' utf_8 b'El Ni\\xc3\\xb1o' utf_16 b'\\xff\\xfeE\\x00l\\x00 \\x00N\\x00i\\x00\\xf1\\x00o\\x00' На рис. 4.1 показано, какие байты различные кодеки генерируют для неко- торых символов: от буквы «A» до символа скрипичного ключа. Отметим, что последние три кодировки многобайтовые, переменной длины. Рис. 4.1. Двенадцать символов, их кодовые позиции и байтовые представления (в 16-рич- ном виде) в семи разных кодировках (звездочка означает, что в данной кодировке этот символ непредставим)140  Unicode-текст и байты\n--- Страница 140 ---\nЗвездочки на рис. 4.1 ясно показывают, что некоторые кодировки, в част - ности ASCII и даже многобайтовая кодировка GB2312, не способны пред- ставить все символы Unicode. Однако кодировки семейства UTF спроекти- рованы так, чтобы была возможность представить любую кодовую позицию Unicode. Кодировки на рис. 4.1 образуют достаточно репрезентативную выборку. latin1 , или iso8859_1 Важна, потому что лежит в основе других кодировок, в частности cp1252, и са - мого Unicode (отметим, что значения байтов latin1 повторяются в столбце cp1252 и даже в самих кодовых позициях). cp1252 Надмножество latin1, разработанное Microsoft. Добавлены некоторые по- лезные символы, например фигурные кавычки и знак евро €. В некоторых приложениях для Windows эта кодировка называется «ANSI», хотя никакой стандарт ANSI по этому поводу не принимался. cp437 Оригинальный набор символов для IBM PC, содержащий символы псевдо- графики. Несовместим с кодировкой latin1, которая появилась позже. gb2312 Унаследованный стандарт кодирования упрощенных китайских иерогли- фов, используемый в континентальном Китае; одна из нескольких широко распространенных многобайтовых кодировок для азиатских языков. utf-8 Самая употребительная 8-разрядная кодировка в вебе. По состоянию на июль 2021 года в исследовании W3Techs «Usage statstics of character encodings for websites» (https://w3techs.com/technologies/overview/character_encoding) ут- верждается, что на 97 % сайтов используется кодировка UTF-8. В первом из- дании книги приводилась цифра на сентябрь 2014 года: 81.4 %. utf-16le Одна из форм 16-разрядной схемы кодирования UTF-16; все кодировки се- мейства UTF-16 поддерживают кодовые позиции с номерами, большими U+FFFF, с помощью управляющих последовательностей, называемых «сур- рогатными парами». UTF-16 заменила первоначальную 16-разрядную кодировку в Unicode 1.0 – UCS-2 – еще в 1996 году. UCS-2 все еще развернута во многих системах, но поддерживает только кодовые позиции с номерами до U+FFFF. По состоянию на 2021 год более 57 % рас- пределенных кодовых позиций имеют номера больше U+10000, сюда относятся и столь популярные эмодзи. Завершив обзор распространенных кодировок, перейдем к проблемам, воз- никающим в процессе кодирования и декодирования. Базовые кодировщики и декодировщики  141\n--- Страница 141 ---\nпрОБлемы кОдир Ования и декОдир Ования Существует общее исключение UnicodeError , но возникающая ошибка почти всегда более специфична: либо UnicodeEncodeError (в случае преобразования str в двоичную последовательность), либо UnicodeDecodeError (в случае чтения двоичной последовательности в str). При загрузке модулей Python может также возникать исключение SyntaxError в случае неожиданной кодировки исходного кода. В следующих разделах мы расскажем, как обрабатывать та- кие ошибки. Первое, на что нужно обращать внимание, получив ошиб- ку Unicode, – точный тип исключения. Это UnicodeEncodeError , UnicodeDecodeError или какая-то другая ошибка (например, SyntaxError ), свидетельствующая об ошибке кодирования? Это главное, что нужно знать для решения проблемы. Обработка UnicodeEncodeError В большинстве кодеков, не входящих в семейство UTF, представлено только небольшое подмножество символов Unicode. Если в ходе преобразования тек- ста в байты оказывается, что символ отсутствует в конечной кодировке, то воз- буждается исключение UnicodeEncodeError , если только методу или функции ко- дировки не передан аргумент errors, обеспечивающий специальную обработку. Поведение обработчиков ошибок демонстрируется в примере 4.5. Пример 4.5. Кодирование текста в байты: успешное завершение и обработка ошибок >>> city = 'São Paulo' >>> city.encode('utf_8')  b'S\\xc3\\xa3o Paulo' >>> city.encode('utf_16') b'\\xff\\xfeS\\x00\\xe3\\x00o\\x00 \\x00P\\x00a\\x00u\\x00l\\x00o\\x00' >>> city.encode('iso8859_1')  b'S\\xe3o Paulo' >>> city.encode('cp437')  Traceback (most recent call last): File \"<stdin>\", line 1, in <module> File \"/ /lib/python3.4/encodings/cp437.py\", line 12, in encode return codecs.charmap_encode(input,errors,encoding_map) UnicodeEncodeError: 'charmap' codec can't encode character '\\xe3' in position 1: character maps to <undefined> >>> city.encode('cp437', errors='ignore')  b'So Paulo' >>> city.encode('cp437', errors='replace')  b'S?o Paulo' >>> city.encode('cp437', errors='xmlcharrefreplace')  b'S&#227;o Paulo'  Кодировки 'utf_?' справляются с любой строкой str.  'iso8859_1' также работает для строки 'São Paulo' .  'cp437' не может закодировать букву 'ã' («a» с тильдой). Обработчик ошибок по умолчанию – 'strict' – возбуждает исключение UnicodeEncodeError . 142  Unicode-текст и байты\n--- Страница 142 ---\n Обработчик error='ignore' молча пропускает некодируемые символы, обыч- но это не слишком удачная идея.  Обработчик error='replace' заменяет некодируемые символы знаком '?'; данные теряются, но пользователь хотя бы знает, что какая-то часть ин- формации утрачена.  'xmlcharrefreplace' заменяет некодируемые символы XML-компонентом. Если вы не можете использовать UTF, а потеря данных недопустима, то это единственный вариант. Механизм обработки ошибок в модуле codecs расширяемый. Можно зарегистрировать дополнительные значения аргумента errors, передав строку и функцию обработки ошибок функции codecs.register_error . См. документацию по codecs.register_error (https://docs.python.org/3/library/codecs.html#codecs.register_error). ASCII – общее подмножество всех известных мне кодировок, поэтому лю- бая кодировка должна работать, если текст состоит только из ASCII-символов. В Python 3.7 добавлен (https://docs.python.org/3/library/ stdtypes.html#str.isascii), новый булев метод str.isascii() , который проверяет, что Unicode-текст на 100 % состоит из ASCII-символов. Если это так, то его можно представить в виде байтов в любой кодировке, не опасаясь исключения UnicodeEncodeError . Обработка UnicodeDecodeError Не каждый байт содержит допустимый символ ASCII, и не каждая последова- тельность байтов является допустимой в кодировке UTF-8 или UTF-16. Если при декодировании двоичной последовательности встретится неожиданный байт, то возникнет исключение UnicodeDecodeError . С другой стороны, многие унаследованные 8-разрядные кодировки, напри- мер 'cp1252', 'iso8859_1' и 'koi8_r', могут декодировать произвольный поток бай- тов, в т. ч. случайный шум, без ошибок. Поэтому если ваша программа оши- бется в предположении о том, какая 8-разрядная кодировка используется, то будет молча декодировать мусор. В русской традиции «мусорные» символы называются «кро- козябрами», а в англоязычной «гремлинами», или «mojibake» (文字化け – по-японски «трансформированный текст»). В примере 4.6 показано, как неправильно выбранный кодек может порож - дать крокозябры или исключение UnicodeDecodeError . Пример 4.6. Декодирование строки в байты: успешное завершение и обработка ошибок >>> octets = b'Montr\\xe9al'  >>> octets.decode('cp1252')  'Montréal' >>> octets.decode('iso8859_7')  'Montrιal' >>> octets.decode('koi8_r')  Проблемы кодирования и декодирования  143\n--- Страница 143 ---\n'MontrИal' >>> octets.decode('utf_8')  Traceback (most recent call last): File \"<stdin>\", line 1, in <module> UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 5: invalid continuation byte >>> octets.decode('utf_8', errors='replace'  'Montr�al'  Эти байты являются символами строки «Montréal» в кодировке latin1 ; '\\ xe9' – байт, соответствующий букве «é».  Декодирование с помощью кодировки 'cp1252' (Windows 1252) работает, по- тому что она является собственным надмножеством latin1.  Кодировка ISO-8859-7 предназначена для греческого языка, поэтому байт '\\xe9' интерпретируется неправильно, но исключение не возбуждается.  KOI8-R – кодировка для русского языка. Теперь '\\xe9' интерпретируется как русская буква «И».  Кодек 'utf_8' обнаруживает октеты, не являющиеся допустимой после- довательностью байтов в кодировке UTF-8, и возбуждает исключение UnicodeDecodeError .  При использовании обработчика ошибок 'replace' байт \\xe9 заменяется сим- волом «�» (кодовая позиция U+FFFD), официальным ЗАМЕНЯЮЩИМ СИМ- ВОЛОМ в Unicode, который служит для представления неизвестных симво- лов. Исключение SyntaxError при загрузке модулей с неожиданной кодировкой UTF-8 – подразумеваемая по умолчанию кодировка исходного кода в Python 3 так же, как ASCII была кодировкой по умолчанию в Python 2. При попытке за- грузить py-модуль, содержащий данные не в кодировке UTF-8 и не имеющий объявления кодировки, будет выдано сообщение вида: SyntaxError: Non-UTF-8 code starting with '\\xe1' in file ola.py on line 1, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details Поскольку в системах GNU/Linux и OS X практически повсеместно разверну - та кодировка UTF-8, такая ошибка наиболее вероятна при открытии py-файла, созданного в Windows в кодировке cp1252. Отметим, что она происходит даже в Python для Windows, потому что в Python 3 по умолчанию на всех платфор- мах подразумевается кодировка UTF-8. Чтобы исправить ошибку, добавьте в начало файла магический коммента- рий, как показано в примере 4.8. Пример 4-7. ola.py: «Hello, World!» по-португальски # coding: cp1252 print('Olá, Mundo!')144  Unicode-текст и байты\n--- Страница 144 ---\nТеперь, когда исходный код на Python 3 не ограничивается од- ной лишь кодировкой ASCII и по умолчанию подразумевается замечательная UTF-8, самое правильное «лечение» для исходно- го кода в унаследованной кодировке типа 'cp1252' – преобразо- вать в UTF-8 и не заморачиваться комментариями coding. Если ваш редактор не поддерживает UTF-8, пора его поменять. Предположим, что имеется некий текстовый файл, все равно, исходный код или стихотворение, но вы не знаете, в какой кодировке он записан. Как опре- делить истинную кодировку? Ответ см. в следующем разделе. Как определить кодировку последовательности байтов Как узнать, в какой кодировке записана последовательность байтов? Короткий ответ: никак. Кто-то должен вам сообщить. В некоторых коммуникационных протоколах и файловых форматах, напри- мер HTTP и XML, предусмотрены заголовки, в которых явно указывается, как за- кодировано содержимое. Можно быть уверенным, что поток байтов представлен не в кодировке ASCII, если он содержит значения, большие 127, а сам способ по- строения UTF-8 и UTF-16 исключает определенные последовательности байтов. Предложение Лео о том, как распознать кодировку UTF-8 (Следующие несколько абзацев составляют содержание комментария техни- ческого рецензента Леонардо Рохаэля к черновой редакции этой книги.) Кодировка UTF-8 спроектирована так, что случайная последовательность байтов или даже неслучайная, но представленная в кодировке, отличной от UTF-8, почти наверняка не будет декодирована как мусор в UTF-8, а приведет к исключению UnicodeDecodeError . Причина в том, что в управляющих последовательностях UTF-8 никогда не используются ASCII-символы и в эти последовательности встроены би- товые паттерны, из-за которых очень трудно по ошибке принять случайные данные за корректный код в UTF-8. Поэтому если вам удается декодировать несколько байтов с кодами, больши- ми 127, как UTF-8, то с большой вероятностью это UTF-8 и есть. Имея дело с бразильскими онлайновыми службами, некоторые из которых надстроены над унаследованными серверными продуктами, я, случалось, вы- нужден был реализовывать следующую стратегию декодирования: попытать- ся декодировать как UTF-8, а исключение UnicodeDecodeError рассматривать как указание на кодировку cp1252. Некрасиво, но эффективно. Однако известно, что в естественных языках есть свои правила и ограничения. Поэтому есть допустить, что поток байтов – это простой текст на естественном языке, то его кодировку можно попытаться определить с помощью различных эв- ристических правил и статистики. Например, если часто встречается байт b'\\x00', Проблемы кодирования и декодирования  145\n--- Страница 145 ---\nто это, скорее всего, 16- или 32-разрядная кодировка, но не 8-разрядная схема, потому что нулевые байты в открытом тексте – очевидная ошибка. Если неред- ко встречается последовательность b'\\x20\\x00' , то это, наверное, символ пробела (U+0020) в кодировке UTF-16LE, а не малоизвестный символ U+2000 EN QUAD. Именно так и работает пакет Chardet – универсальный детектор кодиров- ки символов ( https://pypi.python.org/pypi/chardet), – который пытается распознать одну из 30 поддерживаемых кодировок. Chardet – написанная на Python биб- лиотека, которую вы можете включить в свою программу, а кроме нее, пакет содержит также командную утилиту chardetect . Вот что она сообщает о файле с исходным кодом к данной главе: $ chardetect 04-text-byte.asciidoc 04-text-byte.asciidoc: utf-8 with confidence 0.99 Хотя в самих двоичных последовательностях закодированного текста обыч- но нет явных указаний на кодировку, в некоторых UTF-форматах в начале файла может находиться маркер порядка байтов. Это объясняется в следую- щем разделе. BOM: полезный крокозябр Возможно, вы заметили, что в примере 4.4 в начале последовательности в ко- дировке UTF-16 находились два дополнительных байта. Приведем их еще раз: >>> u16 = 'El Niño'.encode('utf_16') >>> u16 b'\\xff\\xfeE\\x00l\\x00 \\x00N\\x00i\\x00\\xf1\\x00o\\x00' Речь идет о байтах b'\\xff\\xfe' . Это BOM – byte-order mark (маркер порядка байтов). В данном случае он говорит, что порядок байтов прямой, т. е. приня- тый в процессоре Intel, на котором производилось кодирование. На машине с прямым порядком байтов для каждой кодовой позиции пер- вым идет младший байт: буква 'E' с кодовой позицией U+0045 (десятичное 69) представлена в позициях со смещением 2 и 3 от начала последовательности числами 69 и 0: >>> list(u16) [255, 254, 69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111, 0] На машине с обратным порядком байтов кодировка была бы противополож - ной; буква 'E' была бы закодирована числами 0 и 69. Во избежание недоразумений в начало текстовых файлов в кодировке UTF-16 добавляется специальный невидимый символ НЕРАЗРЫВНЫЙ ПРОБЕЛ НУЛЕВОЙ ШИРИНЫ (U+FEFF). В системе с прямым порядком байтов он кодируется байтами b'\\xff\\xfe' (десятичные 255, 254). Поскольку символ в кодовой позиции U+FFFE не существует – это задумано специально, – последовательность байтов b'\\xff\\xfe' должна означать НЕРАЗРЫВНЫЙ ПРОБЕЛ НУЛЕВОЙ ШИРИНЫ в кодировке с пря- мым порядком, поэтому кодек знает, каким должен быть порядок байтов. Существует вариант кодировки UTF-16 – UTF-16LE – специально предназна- ченный для систем с прямым порядком байтов, а также его аналог для систем с обратным порядком – UTF-16BE. В случае их использования маркер BOM не добавляется:146  Unicode-текст и байты\n--- Страница 146 ---\n>>> u16le = 'El Niño'.encode('utf_16le') >>> list(u16le) [69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111, 0] >>> u16be = 'El Niño'.encode('utf_16be') >>> list(u16be) [0, 69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111] Предполагается, что BOM, если он присутствует, будет отфильтрован ко- деком UTF-16, так что останется только сам текст файла без НЕРАЗРЫВНОГО ПРОБЕЛА НУЛЕВОЙ ШИРИНЫ. Стандарт гласит, что для файла в кодировке UTF-16 без маркера BOM следует предполагать кодировку UTF-16BE (с обрат - ным порядком байтов). Однако в архитектуре Intel x86 порядок байтов пря- мой, поэтому на практике в изобилии встречаются файлы в кодировке UTF-16 с прямым порядком байтов без BOM. Проблема порядка байтов возникает только для кодировок, в которых символы кодируются словами, состоящими из нескольких байтов, например UTF-16 и UTF- 32. Существенное достоинство UTF-8 заключается в том, что эта кодировка порож - дает одни и те же последовательности байтов вне зависимости от машинной ар- хитектуры, поэтому BOM не нужен. Тем не менее некоторые приложения Windows (и прежде всего Блокнот) добавляют BOM и в файлы в кодировке UTF-8, а для Excel наличие BOM означает, что файл записан в UTF-8, иначе предполагается, что для его кодирования использовалась кодовая страница Windows. Схема кодировки UTF-8 с BOM в Python называется кодеком UTF-8-SIG. Символ U+FEFF в UTF-8-SIG кодируется последовательностью из трех байт b'\\xef\\xbb\\xbf' . Поэтому файл, начи- нающийся такими байтами, скорее всего, закодирован в UTF-8 и содержит BOM. Замечание Калеба по поводу UTF-8-SIG Калеб Хэттинг – один из технических рецензентов – предлагает всегда использовать кодек UTF-8-SIG при чтении файлов в ко- дировке UTF-8. Это безвредно, потому что UTF-8-SIG правиль- но читает файлы с BOM и без BOM и не возвращает сам сим- вол BOM. При записи файлов я рекомендую использовать UTF-8 ради интероперабельности. Например, Python-скрипт можно сделать исполняемым в системах Unix, добавив в начало ком- ментарий #!/usr/bin/env python3 . Первые два байта должны быть равны b'#!', иначе этот прием работать не будет, но наличие BOM нарушает соглашение. Если одним из требований являет - ся возможность экспорта данных для приложений, ожидающих BOM, используйте UTF-8-SIG, но помните, что написано в до- кументации по кодекам Python (https://docs.python.org/3/library/ codecs.html#encodings-and-unicode): «В UTF-8 использование BOM не рекомендуется, и в общем случае его следует избегать». Перейдем теперь к обработке текстовых файлов в Python 3. ОБраБО тка текСтОвых файлОв На практике обрабатывать текстовые файлы лучше всего, применяя «сэндвич Unicode» (рис. 4.2)1. Это означает, что тип bytes следует декодировать в str на как 1 Впервые словосочетание «сэндвич Unicode» встретилось мне в замечательном вы- ступлении Нэда Бэтчелдера «Pragmatic Unicode» на конференции US PyCon 2012 (http://nedbatchelder.com/text/unipain/unipain.html). Обработка текстовых файлов  147\n--- Страница 147 ---\nможно более ранних стадиях ввода (например, при открытии файла для чтения). «Котлета» в сэндвиче – это бизнес-логика вашей программы, внутри которой об- рабатываются только объекты str. Никогда не следует производить кодирование или декодирование в середине обработки. На этапе вывода объекты str кодиру - ются в bytes как можно позже. Именно так работает большинство веб-каркасов, так что их пользователям редко приходится иметь дело с типом bytes. Например, в Django представления должны выводить строки str, а Django сам позаботится о кодировании ответа в bytes, применяя по умолчанию кодировку UTF-8. Python 3 облегчает следование этой рекомендации, потому что встроенная функция open производит необходимое декодирование при чтении и кодиро- вание при записи файлов в текстовом режиме, т. е. от метода my_file.read() мы получаем объекты str и их же передаем методу my_file.write(text) . Таким образом, работать с текстовыми файлами просто. Но, всегда полага- ясь на кодировку по умолчанию, вы можете горько пожалеть. Сэндвич Unicode декодировать байты при вводе, обрабатывать только текст, кодировать текст при выводе Рис. 4.2. Сэндвич Unicode – рекомендуемый способ обработки текста Взгляните на сеанс оболочки в примере 4.8. Сможете найти ошибку? Пример 4.8. Проблема платформенно-зависимой кодировки (выполнив этот код на своей машине, вы, возможно, наткнетесь на проблему, а возможно, и нет) >>> open('cafe.txt', 'w', encoding='utf_8').write('café') 4 >>> open('cafe.txt').read() 'cafÃ©' Ошибка заключается в том, что я задал кодировку UTF-8 при записи в файл, но забыл сделать это при чтении, поэтому Python предположил, что использу - ется системная кодировка по умолчанию – Windows 1252, – и декодировал два последних байта в файле как символы 'Á©' вместо 'é'. Я выполнял пример 4.8 на машине под управлением Windows 10 (сборка 18363) с 64-разрядным Python 3.8.1. Те же самые предложения в последних версиях GNU/Linux и Mac OS X работают без ошибок, потому что в них по умол- чанию предполагается кодировка UTF-8, и это создает ложное впечатление, будто все хорошо. Если бы мы опустили аргумент encoding при открытии файла для записи, то была бы использована местная кодировка по умолчанию, и мы правильно прочитали бы файл в той же самой кодировке. Но тогда этот скрипт генерировал бы файлы с разным байтовым содержимым на разных платфор-148  Unicode-текст и байты\n--- Страница 148 ---\nмах и даже при различных настройках локали на одной и той же платформе, и мы получили бы проблему совместимости. Код, который должен работать на разных машинах или в раз- ных ситуациях, не должен зависеть от кодировки по умолчанию. Всегда явно задавайте аргумент encoding= при открытии тексто- вых файлов, потому что умолчания могут зависеть от машины и даже меняться на одной и той же машине. В примере 4.8 есть любопытная деталь: функция write в первом предложе- нии говорит, что было записано четыре символа, а в следующей строке чита- ется пять символов. В примере 4.9, где приведен расширенный вариант при- мера 4.8, объясняется этот и другие курьезы. Пример 4.10. Более пристальное изучение запуска примера 4.9 в Windows вскрывает ошиб- ку и показывает, как ее исправить >>> fp  <_io.TextIOWrapper name='cafe.txt' mode='w' encoding='utf_8'> >>> fp.write('café')  4 >>> fp.close() >>> import os >>> os.stat('cafe.txt').st_size  5 >>> fp2 = open('cafe.txt') >>> fp2  <_io.TextIOWrapper name='cafe.txt' mode='r' encoding='cp1252'> >>> fp2.encoding  'cp1252' >>> fp2.read()  'cafÃ©' >>> fp3 = open('cafe.txt', encoding='utf_8')  >>> fp3 <_io.TextIOWrapper name='cafe.txt' mode='r' encoding='utf_8'> >>> fp3.read()  'café' >>> fp4 = open('cafe.txt', 'rb')  >>> fp4  <_io.BufferedReader name='cafe.txt'> >>> fp4.read() ⓫ b'caf\\xc3\\xa9'  По умолчанию open открывает файл в текстовом режиме и возвращает объ- ект TextIOWrapper .  Метод write объекта TextIOWrapper возвращает количество записанных симво- лов Unicode.  Функция os.stat сообщает, что файл содержит 5 байт; в кодировке UTF-8 буква 'é' представлена двумя байтами: 0xc3 и 0xa9.  В результате открытия текстового файла без явного указания кодировки возвращается объект TextIOWrapper , в котором установлена кодировка, взятая из локали.  В объекте TextIOWrapper имеется атрибут encoding, который можно опросить, в данном случае он равен cp1252. Обработка текстовых файлов  149\n--- Страница 149 ---\n В кодировке Windows cp1252 байт 0xc3 соответствует символу «Ã» (A с тиль- дой), а 0xa9 – знаку копирайта.  Открытие того же файла с указанием правильной кодировки.  Ожидаемый результат: те же самые четыре символа Unicode 'café'.  При задании флага 'rb' файл открывается в двоичном режиме.  Возвращенный объект имеет тип BufferedReader , а не TextIOWrapper . ⓫ Чтение возвращает те байты, которые ожидаются. Не открывайте текстовые файлы в двоичном режиме, если не со- бираетесь анализировать содержимое файла на предмет опреде- ления кодировки, да и в этом случае лучше пользоваться библио- текой Chardet, а не изобретать велосипед (см. раздел «Как опре- делить кодировку последовательности байтов» выше). В обычной программе двоичный режим следует использовать только для открытия двоичных файлов, например растровых изображений. Проблема, встретившаяся нам в примере 4.9, возникла из-за неверного предположения о кодировке по умолчанию при открытии текстового файла. Как показано в следующем разделе, существует несколько источников таких умолчаний. Остерегайтесь кодировок по умолчанию На установку кодировки по умолчанию в Python влияет несколько параметров. См. скрипт default_encodings.py в примере 4.10. Пример 4.10. Исследование кодировок по умолчанию import locale import sys expressions = \"\"\" locale.getpreferredencoding() type(my_file) my_file.encoding sys.stdout.isatty() sys.stdout.encoding sys.stdin.isatty() sys.stdin.encoding sys.stderr.isatty() sys.stderr.encoding sys.getdefaultencoding() sys.getfilesystemencoding() \"\"\" my_file = open('dummy', 'w') for expression in expressions.split(): value = eval(expression) print(f'{expression:>30} -> {value!r}') Этот скрипт выводит одно и то же в GNU/Linux (Ubuntu 14.04 – 19.10) и macOS (10.9–10.14), показывая, что в данных системах всюду используется кодировка UTF-8: 150  Unicode-текст и байты\n--- Страница 150 ---\n$ python3 default_encodings.py locale.getpreferredencoding() -> 'UTF-8' type(my_file) -> <class '_io.TextIOWrapper'> my_file.encoding -> 'UTF-8' sys.stdout.isatty() -> True sys.stdout.encoding -> 'utf-8' sys.stdin.isatty() -> True sys.stdin.encoding -> 'utf-8' sys.stderr.isatty() -> True sys.stderr.encoding -> 'utf-8' sys.getdefaultencoding() -> 'utf-8' sys.getfilesystemencoding() -> 'utf-8' Однако в Windows выводится нечто совершенно иное (см. пример 4.11). Пример 4.11. Кодировки по умолчанию в оболочке Windows 10 PowerShell (cmd.exe дает такой же результат) > chcp  Active code page: 437 > python default_encodings.py  locale.getpreferredencoding() -> 'cp1252'  type(my_file) -> <class '_io.TextIOWrapper'> my_file.encoding -> 'cp1252'  sys.stdout.isatty() -> True  sys.stdout.encoding -> 'utf-8'  sys.stdin.isatty() -> True sys.stdin.encoding -> 'utf-8' sys.stderr.isatty() -> True sys.stderr.encoding -> 'utf-8' sys.getdefaultencoding() -> 'utf-8' sys.getfilesystemencoding() -> 'utf-8'  chcp показываетактивную кодовую страницу для консоли: 437.  При запуске default_encodings.py с выводом на консоль.  locale.getpreferredencoding() – самый важный параметр.  Для текстовых файлов по умолчанию используется locale.getpreferredencoding() .  Вывод производится на консоль, поэтому sys.stdout.isatty() равно True.  Но sys.stdout.encoding не такая же, как кодовая страница для консоли, печата- емая chcp! Поддержка Unicode в самой Windows и в Python для Windows улучшилась за время, прошедшее с выхода первого издания. В Windows 7 с версией Python 3.4 скрипт 4.11 сообщал о четырех разных кодировках. Кодировки для stdout, stdin и stderr совпадали с активной кодовой страницей, напечатанной командой chcp, теперь же во всех этих случаях используется utf-8 – благодаря предложе- нию из документа PEP 528 «Change Windows console encoding to UTF-8» (https:// peps.python.org/pep-0528/), реализованному в Python 3.6, и поддержке Unicode в PowerShell и в cmd.exe (начиная со сборки Windows 1809, вышедшей в октябре 2018 года)1. Странно, что chcp и sys.stdout.encoding печатают разные кодировки, когда stdout связан с консолью, но хорошо уже то, что мы наконец-то можем пе- 1 Источник: «Windows Command-Line: Unicode and UTF-8 Output Text Buffer» (https:// devblogs.microsoft.com/commandline/windows-command-line-unicode-and-utf-8-output-text-buffer/). Обработка текстовых файлов  151\n--- Страница 151 ---\nчатать Unicode-строки, не вызывая ошибок кодировки в Windows, – если толь- ко пользователь не перенаправит выход в файл, как мы вскоре увидим. Это не значит, что все ваши любимые эмодзи будут видны на консоли; все зависит от шрифта, которым пользуется консоль. Еще одно изменение, описанное в документе PEP 529 «Change Windows filesystem encoding to UTF-8» (https://peps.python.org/pep-0529/) и также реализо- ванное в Python 3.6, изменило кодировку файловой системы (используемую для представления имен каталогов и файлов) с Microsoft MBCS на UTF-8. Однако если перенаправить вывод примера 4.10 в файл: Z:\\>python default_encodings.py > encodings.log то sys.stdout.isatty() становится равным False и sys.stdout.encoding устанавливает - ся путем обращения к locale.getpreferredencoding() , т. е. 'cp1252' на данной машине. Но sys.stdin.encoding и sys.stderr.encoding остаются равными utf-8. В примере 4.12 я использую управляющую последовательность '\\N{}' для литералов Unicode, при этом внутри скобок записывает - ся официальное название символа. Это довольно многословно, но зато явно и безопасно: Python возбуждает исключение SyntaxError , если указанное имя не существует – гораздо лучше, чем записы- вать шестнадцатеричное число, которое может оказаться невер- ным, но узнаете вы об этом гораздо позже. Да и, скорее всего, вы все равно написали бы комментарий, объясняющий назначение кодов, так что с пространностью \\N{} легко смириться. Это означает, что скрипт, подобный приведенному в примере 4.12, работает при выводе на консоль, но может ломаться при перенаправлении вывода в файл. Пример 4.12. stdout_check.py import sys from unicodedata import name print(sys.version) print() print('sys.stdout.isatty():', sys.stdout.isatty()) print('sys.stdout.encoding:', sys.stdout.encoding) print() test_chars = [ '\\N{HORIZONTAL ELLIPSIS}', # есть в cp1252, нет в cp437 '\\N{INFINITY}', # есть в cp437, нет в cp1252 '\\N{CIRCLED NUMBER FORTY TWO}', # нет ни в cp437, ни в cp1252 ] for char in test_chars: print(f'Trying to output {name(char)}:') print(char) Пример 4.12 выводит результат sys.stdout.isatty() , значение sys.stdout.encoding и следующие три символа: '…' HORIZONTAL ELLIPSIS – есть в кодировке CP 1252, но не в CP 437; '∞' INFINITY – есть в кодировке CP 437, но не в CP 1252; '42' CIRCLED NUMBER FORTY TWO – нет ни в cp437, ни в cp1252. 152  Unicode-текст и байты\n--- Страница 152 ---\nПри запуске stdout_check.py в PowerShell или cmd.exe он работал, как показано на рис. 4.3. Рис. 4.3. Выполнение stdout_check.py в PowerShell Хотя chcp сообщает, что активна кодовая страница 437, кодировка sys.stdout. encoding равна UTF-8, поэтому символы HORIZONTAL ELLIPSIS и INFINITY выводятся правильно. Символ CIRCLED NUMBER FORTY TWO заменен прямоугольником, но ошиб- ки не возникло. Вероятно, символ-то допустимый, но в консольном шрифте нет соответствующего ему глифа. Однако после перенаправления вывода stdout_check.py в файл я получил кар- тину, показанную на рис. 4.4. Рис. 4.4. Выполнение stdout_check.py в PowerShell с перенаправлением вывода Первая из показанных на рис. 4.4 проблем – ошибка UnicodeEncodeError , в кото - рой упомянут символ '\\u221e'. Она возникла, потому что кодировка sys.stdout. encoding равна 'cp1252', а в этой кодовой странице нет символа INFINITY. Прочитав файл out.txt командой type или открыв его в редакторе, например VS Code или Sublime Text, мы увидим, что вместо символа HORIZONTAL ELLIPSIS присутствует символ 'à' (LATIN SMALL LETTER A WITH GRAVE ). Оказывается, что значе- Обработка текстовых файлов  153\n--- Страница 153 ---\nние байта 0x85 в кодировке CP 1252 означает '…', а в кодировке CP 437 – сим- вол 'à'. Так что, похоже, активная кодовая страница играет роль – ни разумной, ни полезной ее не назовешь, но частично она объясняет проблемы с Unicode. Для описанных экспериментов я пользовался ноутбуком, скон- фигурированным для рынка США с установленной ОС Windows 10 OEM. В версиях Windows, локализованных для других стран, кодировка может быть настроена иначе. Например, в Бразилии на консоли Windows по умолчанию используется кодовая стра- ница 850, а не 437. Подводя итоги этой приводящей в исступление ситуации с кодировками по умолчанию, в последний раз рассмотрим различные кодировки, встречающие- ся в примере 4.11. Если опустить аргумент encoding при открытии файла, то умолчание опре- деляется методом locale.getpreferredencoding() ('cp1252' в примере 4.11). До версии Python 3.6 кодировка sys.stdout/stdin/stderr определялась пере- менной окружения PYTHONIOENCODING (https://docs.python.org/3/using/cmdline. html#envvar-PYTHONIOENCODING). Теперь она игнорируется, если только значением переменной PYTHONLEGACYWINDOWSSTDIO (https://docs.python.org/3/ using/cmdline.html#envvar-PYTHONLEGACYWINDOWSSTDIO) не является не- пустая строка, а если является, то кодировка стандартного ввода-вы- вода равна UTF-8, когда поток связан с консолью, но совпадает с locale. getpreferredencoding() , когда поток перенаправлен на файл. Функция sys.getdefaultencoding() используется самим интерпретатором Python для неявных преобразований двоичных данных в строку и об- ратно. Изменение этого параметра не поддерживается. Функция sys.getfilesystemencoding() применяется для кодирования и декодиро- вания имен файлов (но не их содержимого). Она вызывается, когда open() получает имя файла в виде строки str; если же имя файла задано аргументом типа bytes, то оно передается API операционной системы без изменения. В GNU/Linux и macOS все эти кодировки по умолчанию совпа- дают с UTF-8, и такое положение существует уже несколько лет, поэтому подсистема ввода-вывода обрабатывает все символы Unicode. В Windows не только используются различные коди- ровки в одной и той же системе, но обычно это еще и кодовые страницы, например 'cp850' или 'cp1252', которые поддержи- вают только ASCII и еще 127 символов, отличающихся в разных кодировках. Поэтому у пользователей Windows гораздо больше шансов столкнуться с ошибками кодирования при малейшей небрежности. Подводя итоги, можно сказать, что самым важным из всех относящихся к кодировкам параметров является значение, возвращаемое методом locale. getpreferredencoding() : оно подразумевается по умолчанию при открытии тексто- вых файлов и при вводе-выводе на sys.stdout/stdin/stderr , если поток перена- правлен в файл. Однако в документации (https://docs.python.org/3/library/ locale. html#locale.getpreferredencoding) мы читаем: 154  Unicode-текст и байты\n--- Страница 154 ---\nlocale.getpreferredencoding(do_setlocale=True) Вернуть кодировку, используемую для текстовых данных, в соответствии с предпочтениями пользователя. Предпочтения задаются по-разному в разных системах и не всегда доступны из программы, поэтому данная функция возвращает только предположительное значение […]. Таким образом, лучшее, что можно посоветовать в части кодировок по умолчанию: не полагайтесь на них. Если вы будете поступать, как рекомендует сэндвич Unicode, и всегда явно указывать кодировку, то избежите множества неприятностей. К сожалению, проблемы работы с Unicode не заканчиваются, даже если вы правильно пре- образуете bytes в str. В следующих двух разделах рассматриваются темы, кото- рые не вызывают ни малейших трудностей в краю ASCII, но становятся весь- ма сложными на планете Unicode: нормализация текста (т. е. приведение его к единому представлению для сравнения) и сортировка. нОрмализация unicode для надежнОг О Сравнения Сравнение строк осложняется тем, что в Unicode есть модифицирующие сим- волы: диакритические и другие знаки, присоединяемые к предыдущему сим- волу, так что при печати оба символа выглядят как единое целое. Например, слово «café» можно составить двумя способами, из четырех или из пяти кодовых позиций, хотя результат будет выглядеть одинаково: >>> s1 = 'café' >>> s2 = 'cafe\\N{COMBINING ACUTE ACCENT}' >>> s1, s2 ('café', 'café') >>> len(s1), len(s2) (4, 5) >>> s1 == s2 False Кодовая позиция U+0301 называется COMBINING ACUTE ACCENT (МОДИ- ФИЦИРУЮЩИЙ АКУТ). Если она следует за «e», то результат отображается как «é». В стандарте Unicode последовательности вида 'é' и 'e\\u0301' называют - ся «каноническими эквивалентами» и предполагается, что приложения будут считать их одинаковыми. Но Python видит две разные последовательности ко- довых позиций и одинаковыми их не считает. Решение состоит в том, чтобы использовать функцию unicodedata.normalize . Первым аргументом функции передается одна из четырех строк: 'NFC', 'NFD', 'NFKC' или 'NFKD'. Сначала рассмотрим первые две. Форма нормализации C (NFC) производит композицию двух кодовых по- зиций с целью получения самой короткой эквивалентной строки, а форма нормализации D (NFD) производит декомпозицию, т. е. разложение составно- го символа на базовый и модифицирующие. В результате выполнения обеих нормализаций сравнение работает, как и ожидается: >>> from unicodedata import normalize Нормализация Unicode для надежного сравнения  155\n--- Страница 155 ---\n>>> s1 = 'café' >>> s2 = 'cafe\\N{COMBINING ACUTE ACCENT}' >>> len(s1), len(s2) (4, 5) >>> len(normalize('NFC', s1)), len(normalize('NFC', s2)) (4, 4) >>> len(normalize('NFD', s1)), len(normalize('NFD', s2)) (5, 5) >>> normalize('NFC', s1) == normalize('NFC', s2) True Драйверы клавиатуры обычно генерируют составные символы, поэтому набранный пользователем текст по умолчанию оказывается в формате NFC. Но для пущей уверенности лучше прогнать строки через normalize('NFC', user_ text) перед сохранением. Форма нормализации NFC рекомендуется также кон- сорциумом W3C в документе «Character Model for the World Wide Web: String Matching and Searching (http://www.w3.org/TR/charmod-norm/). Некоторые одиночные символы форма NFC преобразует в другие одиноч- ные символы. Символ ома, единицы электрического сопротивления, Ω преоб- разуется в греческую букву омега в верхнем регистре. Визуально они ничем не отличаются, но при сравнении не совпадают, поэтому во избежание сюр- призов необходимо производить нормализацию: >>> from unicodedata import normalize, name >>> ohm = '\\u2126' >>> name(ohm) 'OHM SIGN' >>> ohm_c = normalize('NFC', ohm) >>> name(ohm_c) 'GREEK CAPITAL LETTER OMEGA' >>> ohm == ohm_c False >>> normalize('NFC', ohm) == normalize('NFC', ohm_c) True В акронимах двух других форм нормализации – NFKC и NFKD – буква K оз- начает «compatibility» (совместимость). Это более строгие формы нормализа- ции, затрагивающие так называемые «символы совместимости». Хотя одна из целей Unicode – определить единственную «каноническую» кодовую позицию для каждого символа, некоторые символы встречаются несколько раз ради совместимости с предшествующими стандартами. Например, знак «микро», MICRO SIGN , 'μ' (U+00B5) был добавлен в Unicode для поддержки обратимого пре- образования в latin1, хотя тот же самый символ является также частью гре- ческого алфавита, где ему соответствует кодовая позиция U+03BC (GREEK SMALL LETTER MU, СТРОЧНАЯ ГРЕЧЕСКАЯ БУКВА МЮ ). Поэтому знак «микро» считается «символом совместимости». В формах NFKC и NFKD каждый символ совместимости заменяется «совмес- тимой декомпозицией» из одного или более символов, которая считается «предпочтительным» представлением, даже если при этом возникает потеря форматирования – в идеале форматирование должно быть функцией внешней разметки, а не частью Unicode. Например, совместимой декомпозицией дро- би «одна вторая» '½' (U+00BD) является последовательность трех символов '1/2', 156  Unicode-текст и байты\n--- Страница 156 ---\nа совместимой декомпозицией знака «микро» 'μ' (U+00B5) – строчная буква мю 'μ' (U+03BC)1. Вот как NFKC работает на практике: >>> from unicodedata import normalize, name >>> half = '\\N{VULGAR FRACTION ONE HALF}' >>> print(half) ½ >>> normalize('NFKC', half) '1⁄2' >>> for char in normalize('NFKC', half): print(char, name(char), sep='\\t') 1 DIGIT ONE ⁄ FRACTION SLASH 2 DIGIT TWO >>> four_squared = '4²' >>> normalize('NFKC', four_squared) '42' >>> micro = 'μ' >>> micro_kc = normalize('NFKC', micro) >>> micro, micro_kc ('μ', 'μ') >>> ord(micro), ord(micro_kc) (181, 956) >>> name(micro), name(micro_kc) ('MICRO SIGN', 'GREEK SMALL LETTER MU') В то время как '1⁄2' – разумная замена для '½', а знак «микро» действитель- но совпадает со строчной греческой буквой мю, преобразование '42' в '42' из- меняет смысл. Приложение могло бы сохранить '42' как '4<sup>2</sup>' , но функ - ция normalize ничего не знает о форматировании. Поэтому формы NFKC и NFKD могут терять или искажать информацию, но в то же время дают удобное про- межуточное представление для поиска и индексирования. К сожалению, в Unicode все всегда сложнее, чем кажется. Для символа VULGAR FRACTION ONE HALF (ПРОСТАЯ Дробь Одна Вторая ) форма нормализации NFKC порождает символы 1 и 2, соединенные символом FRACTION SLASH (ДРОБНАЯ ЧЕРТА ), а не SOLIDUS (КОСАЯ ЧЕРТА ) – знакомым символом с десятичным кодом ASCII 47. Поэтому по- иск последовательности трех символов ASCII '1/2' не найдет нормализованной последовательности Unicode. Формы нормализации NFKC и NFKD следует применять с осто- рожностью и только в особых случаях, например для поиска и индексирования, а не для постоянного хранения текста, по- скольку выполняемые ими преобразования могут приводить к потере данных. Для подготовки текста к поиску или индексированию полезна еще одна опе- рация: сворачивание регистра. Это и есть тема следующего раздела. 1 Любопытно, что знак «микро» считается символом совместимости, а знак «ом» нет. В результате NFC не трогает знак «микро», но изменяет знак «ом» на заглавную букву омега, тогда как NFKC и NFKD заменяют и «ом», и «микро» символами греческого алфавита. Нормализация Unicode для надежного сравнения  157\n--- Страница 157 ---\nСворачивание регистра Сворачивание регистра – это, по существу, перевод всего текста в нижний регистр с некоторыми дополнительными преобразованиями. Для этой цели предназначен метод str.casefold() . Если строка s содержит только символы из набора latin1, то s.casefold() дает такой же результат, как s.lower(), с двумя исключениями: знак «микро» 'μ' за- меняется строчной греческой буквой мю (в большинстве шрифтов они выгля- дят одинаково), а немецкая «эсцет» преобразуется в «ss »: >>> micro = 'μ' >>> name(micro) 'MICRO SIGN' >>> micro_cf = micro.casefold() >>> name(micro_cf) 'GREEK SMALL LETTER MU' >>> micro, micro_cf ('μ', 'μ') >>> eszett = 'ß' >>> name(eszett) 'LATIN SMALL LETTER SHARP S' >>> eszett_cf = eszett.casefold() Существует 300 кодовых позиций, для которых str.casefold() и str.lower() дают различные результаты. Как все связанное с Unicode, сворачивание регистра – сложная лингвисти- ческая проблема со множеством особых случаев, но разработчики ядра Python приложили максимум усилий, чтобы предложить решение, устраивающее большинство пользователей. В следующих двух разделах мы применим знания о нормализации к разра- ботке служебных функций. Служебные функции для сравнения нормализованного текста Как мы видели, формы нормализации NFC и NFD безопасны и позволяют до- статочно осмысленно сравнивать Unicode-строки. Для большинства приложе- ний NFC – наилучшая нормализованная форма. Для сравнения строк без учета регистра предназначен метод str.casefold() . Если вы работаете с текстами на многих языках, рекомендуем включить в свой арсенал функции наподобие nfc_equal и fold_equal , показанные в приме- ре 4.13. Пример 4.13. normeq.py: сравнение нормализованных Unicode-строк «»» Служебные функции для сравнения нормализованных Unicode-строк. Использование нормальной формы C, с учетом регистра: >>> s1 = 'cafe' >>> s2 = 'cafe\\u0301' >>> s1 == s2158  Unicode-текст и байты\n--- Страница 158 ---\nFalse >>> nfc_equal(s1, s2) True >>> nfc_equal('A', 'a') False Использование нормальной формы C, со сворачиванием регистра: >>> s3 = 'Strase' >>> s4 = 'strasse' >>> s3 == s4 False >>> nfc_equal(s3, s4) False >>> fold_equal(s3, s4) True >>> fold_equal(s1, s2) True >>> fold_equal('A', 'a') True «»» from unicodedata import normalize def nfc_equal(str1, str2): return normalize('NFC', str1) == normalize('NFC', str2) def fold_equal(str1, str2): return (normalize('NFC', str1).casefold() == normalize('NFC', str2).casefold()) Помимо нормализации и сворачивания регистра (то и другое – части стан- дарта Unicode), иногда бывают полезны более глубокие преобразования, на- пример 'café' в 'cafe'. В следующем разделе мы покажем, когда это необходи- мо и как делается. Экстремальная «нормализация»: удаление диакритических знаков Секретный рецепт поиска Google скрывает много разных хитростей, одна из них – полное игнорирование диакритических знаков (акцентов, седилей и т. д.), по крайней мере в некоторых контекстах. Удаление диакритических знаков, строго говоря, не является нормализацией, потому что зачастую при этом меняется смысл слов и поиск может находить не то, что нужно. Но жизнь есть жизнь: многие ленятся ставить диакритические знаки или не знают, как это нужно делать, да и правила правописания время от времени меняются. Игнорирование диакритики помогает справиться с этими проблемами. Но даже если оставить поиск в стороне, удаление диакритических знаков делает URL-адреса более удобочитаемыми, по крайней мере в языках на осно- ве латиницы. Взгляните на URL статьи Википедии о городе Сан-Паулу: http://en.wikipedia.org/wiki/S%C3%A3o_Paulo Нормализация Unicode для надежного сравнения  159\n--- Страница 159 ---\nЧасть %C3%A3 – результат URL-кодирования представления буквы «ã» (a с тиль- дой) в кодировке UTF-8. Показанный ниже URL гораздо понятнее, пусть даже правописание в нем хромает: http://en.wikipedia.org/wiki/Sao_Paulo Для удаления всех диакритических знаков из str можно воспользоваться функцией из примера 4.14. Пример 4.14. Функция для удаления всех модифицирующих символов (модуль sanitize.py) import unicodedata import string def shave_marks(txt): \"\"\"Remove all diacritic marks\"\"\" norm_txt = unicodedata.normalize('NFD', txt)  shaved = ''.join(c for c in norm_txt if not unicodedata.combining(c))  return unicodedata.normalize('NFC'shaved)   Разложить все символы на базовые и модифицирующие.  Найти все модифицирующие символы.  Произвести обратную композицию. В примере 4.15 демонстрируются два применения функции shave_marks . Пример 4.15. Два применения функции shave_marks из примера 4.14 >>> order = '\"Herr Voß: • ½ cup of OEtker™ caffè latte • bowl of açaí.\"' >>> shave_marks(order) '\"Herr Voß: • ½ cup of OEtker™ caffe latte • bowl of acai.\"'  >>> Greek = 'Ζέφυρος, Zéfiro' >>> shave_marks(Greek) 'Ζεφυρος, Zefiro   Заменены только буквы «è», «ç» и «ί».  Заменены буквы «έ» и «é». Функция shave_marks работает правильно, но, быть может, чрезмерно усерд- ствует. Часто диакритические знаки удаляются только для того, чтобы пере- вести текст из кодировки Latin в чистый ASCII, но shave_marks изменяет также и нелатинские символы, например греческие буквы, которые – что с акцен- тами, что без – никогда не превратятся в ASCII. Поэтому имеет смысл проана- лизировать каждый базовый символ и удалять присоединенные знаки, только если он является буквой из набора символов Latin. Именно это делает функция из примера 4.16. Пример 4.16. Функция удаления модифицирующих знаков только для символов из набора Latin (предложения импорта опущены, поскольку это часть модуля sanitize.py из примера 4.14) def shave_marks_latin(txt): \"\"\"Удалить все диакритические знаки для базовых символов набора Latin\"\"\" norm_txt = unicodedata.normalize('NFD', txt)  latin_base = False preserve = []160  Unicode-текст и байты\n--- Страница 160 ---\nfor c in norm_txt: if unicodedata.combining(c) and latin_base:  continue # игнорировать диакритические знаки # для базовых символов набора Latin preserve.append(c)  # если это не модифицирующий символ, значит, новый базовый if not unicodedata.combining(c):  latin_base = c in string.ascii_letters shaved = '' .join(preserve) return unicodedata.normalize('NFC'shaved)   Разложить все символы на базовые и модифицирующие.  Пропустить модифицирующие символы, если базовый из набора Latin.  В противном случае сохранить текущий символ.  Распознать новый базовый символ и определить, принадлежит ли он на- бору Latin.  Произвести обратную композицию. Еще более радикальный шаг – заменить часто встречающиеся в западных текстах символы (например, фигурные кавычки, длинные тире, маркеры спис- ков и т. д.) эквивалентными символами из набора ASCII. Этим занимается функция asciize из примера 4.17. Пример 4.17. Преобразование некоторых западных типографических символов в ASCII (этот код также входит составной частью в модуль sanitize.py из примера 4.14) single_map = str.maketrans(\"\"\"‚ƒ„ˆ‹''\"\"•––˜›\"\"\",  \"\"\"'f\"^<''\"\"---~>\"\"\") multi_map = str.maketrans({  '€': 'EUR', '…': ' ', 'Æ': 'AE', 'æ': 'ae', 'OE': 'OE', 'oe': 'oe', '™': '(TM)', '‰': '<per mille>', '†': '**', '‡': '***', }) multi_map.update(single_map)  def dewinize(txt): \"\"\"Заменить символы Win1252 символами или последовательностями символов ASCII \"\"\" return txt.translate(multi_map)  def asciize(txt): no_marks = shave_marks_latin(dewinize(txt))  no_marks = no_marks.replace('ß', 'ss')  return unicodedata.normalize(NFK C',nomarks)   Построить таблицу соответствия для замены одного символа другим.  Построить таблицу соответствия для замены символа строкой символов.  Объединить таблицы соответствия. Нормализация Unicode для надежного сравнения  161\n--- Страница 161 ---\n Функция dewinize не изменяет символы из наборов ASCII и latin1, а затрагива- ет только добавления к latin1, включенные Microsoft в набор cp1252.  Применить dewinize и удалить диакритические знаки.  Заменить эсцет на «ss» (мы не пользуемся сворачиванием регистра, потому что хотим сохранить исходный регистр).  Применить нормализацию NFKC для композиции символов с их кодовыми позициями совместимости. В примере 4.18 показана функция asciize в действии. Пример 4.18. Два применения функции asciize из примера 4.17 >>> order = '\"Herr Voß: • ½ cup of OEtker™ caffè latte • bowl of açaí.\"' >>> dewinize(order) '\"Herr Voß: - ½ cup of OEtker(TM) caffè latte - bowl of açaí.\"'  >>> asciize(order) '\"Herr Voss: - 1⁄2 cup of OEtker(TM) caffe latte - bowl of acai.\"'   dewinize заменяет фигурные кавычки, маркеры списка и знак торговой мар- ки ™.  asciize вызывает dewinize, затем удаляет диакритические знаки и заменяет 'ß'. В разных языках правила удаления диакритических знаков раз- личны. Например, немцы заменяют 'ü' на 'ue'. Наша функция asciize не настолько рафинирована, поэтому может статься, что к вашему языку она не применима. Впрочем, для португальского работает отлично. Итак, функции из модуля sanitize.py не ограничиваются стандартной нормали- зацией, а подвергают текст серьезной хирургической операции, которая вполне может изменить его смысл. Лишь обладая знаниями о целевом языке, потенци- альных пользователях и способах использования преобразованного текста, мож - но решить, стоит ли заходить так далеко. А кому все это знать, как не вам? На этом мы подводим черту под обсуждением нормализации Unicode- текстов. Далее нам предстоит заняться проблемой сортировки. СОртир Овка unicode -текСтОв Python сортирует последовательности любого типа, сравнивая элементы один за другим. Для строк это означает сравнение кодовых позиций. Увы, результат получится никуда не годным, если только вы не ограничиваетесь символами ASCII. Рассмотрим сортировку списка фруктов, произрастающих в Бразилии. >>> fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola'] >>> sorted(fruits) ['acerola', 'atemoia', 'açaí', 'caju', 'cajá'] Правила сортировка зависят от локали, но в португальском и многих других языках, основанных на латинице, акценты и седили редко учитываются при 162  Unicode-текст и байты\n--- Страница 162 ---\nсортировке1. Поэтому «cajá» сортируется так же, как «caja» и, следовательно, предшествует «caju». Отсортированный список fruits должен выглядеть так: ['açaí', 'acerola', 'atemoia', 'cajá', 'caju'] Стандартный способ сортировки не-ASCII текстов в Python – функция locale. strxfrm, которая, как написано в документации по модулю locale (https://docs. python.org/3/library/locale.html?highlight=strxfrm#locale.strxfrm), «преобразует стро- ку, так чтобы ее можно было использовать в сравнениях с учетом локали». Чтобы можно было воспользоваться функцией locale.strxfrm , необходимо сна- чала установить локаль, отвечающую нуждам приложения, и надеяться, что ОС ее поддерживает. В системах на базе GNU/Linux (Ubuntu 14.04) при выборе ло- кали pt_BR нужный результат дает последовательность команд в примере 4.19. Пример 4.19. locale_sort.py: использование функции locale.strxfrm в качестве ключа сортировки import locale my_locale = locale.setlocale(locale.LC_COLLATE, 'pt_BR.UTF-8') print(my_locale) fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola'] sorted_fruits = sorted(fruits, key=locale.strxfrm) print(sorted_fruits) При выполнении примера 4.19 в GNU/Linux (Ubuntu 19.10) с установленной локалью pt_BR.UTF-8 я получил правильный результат: 'pt_BR.UTF-8' ['açaí', 'acerola', 'atemoia', 'cajá', 'caju'] Таким образом, до использования locale.strxfrm в качестве значения парамет- ра key необходимо вызвать setlocale(LC_COLLATE, «ваша_локаль») . Однако есть несколько подводных камней. Поскольку установка локали – глобальное действие, вызывать setlocale в биб лиотеке не рекомендуется. Приложение или каркас должны установить локаль в начале работы процесса и затем уже не менять. Локаль должна быть установлена в ОС, иначе вызов setlocale возбуждает исключение locale.Error: unsupported locale setting . Необходимо точно знать, как пишется имя локали. Локаль должна быть правильно реализована производителем ОС. С Ubuntu 14.04 мне повезло, а с macOS 10.14 – нет. В macOS обращение setlocale(LC_COLLATE, 'pt_BR.UTF-8') честно возвращало строку 'pt_BR.UTF-8' . Однако вызов sorted(fruits, key=locale.strxfrm) давал тот же неправильный результат, что и sorted(fruits) . Я пробовал также локали fr_FR, es_ES и de_DE в macOS, но ни разу locale.strxfrm не отработала, как положено2. 1 Диакритические знаки оказывают влияние на сортировку в тех редких случаях, когда слова только ими и отличаются, в подобном случае слово с диакритическим знаком следует за словом без такового. 2 Я не смог найти решение, но другие тоже жаловались на эту проблему. Алекс Мартел- ли, один из технических рецензентов, не сталкивался с ошибкой при использовании setlocale и locale.strxfrm на своем macOS 10.9. Короче говоря, как повезет. Сортировка Unicode-текстов  163\n--- Страница 163 ---\nТаким образом, содержащееся в стандартной библиотеке решение для ин- тернационализированной сортировки работает, но лучше всего поддержано в GNU/Linux (или в Windows, если вы специалист по этой ОС). Но даже в этом случае оно зависит от настройки локали, что может вызвать неприятности при развертывании. По счастью, существует более простое решение: библиотека pyuca, доступ- ная на сайте PyPI. Сортировка с помощью алгоритма упорядочивания Unicode Джеймсу Тауберу (James Tauber), автору многих проектов для Django, должно быть, надоела эта путаница, и он написал модуль PyUCA (https:// pypi.python.org/pypi/pyuca/), реализацию алгоритма упорядочивания Unicode (Unicode Collation Algorithm – UCA) на чистом Python. В примере 4.20 по- казано, как просто его использовать. Пример 4.20. Использование метода pyuca.Collator.sort_key >>> import pyuca >>> coll = pyuca.Collator() >>> fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola'] >>> sorted_fruits = sorted(fruits, key=coll.sort_key) >>> sorted_fruits ['açaí', 'acerola', 'atemoia', 'cajá', 'caju'] Метод удобный и работает правильно в системах GNU/Linux, macOS и Windows, по крайней мере на моей маленькой выборке. Библиотека pyuca не обращает внимания на локаль. Если требуется изме- нить порядок сортировки, укажите путь к своей таблице упорядочения при вызове конструктора Collator() . Оригинальная библиотека пользуется файлом allkeys.txt (https://github.com/jtauber/pyuca), включенным в дистрибутив. Это прос то копия стандартной таблицы элементов упорядочения Unicode (http:// www.unicode.org/Public/UCA/6.3.0/allkeys.txt) с сайта Unicode.org. PYICU: рекомендация Миро касательно сортировки в UNICODE (Технический рецензент Мирослав Седивы – полиглот и эксперт по Unicode. Вот что он написал по поводу pyuca.) В pyuca имеется один алгоритм сортировки, который не учи- тывает порядок сортировки в конкретных языках. Например, в немецком буква Ä расположена между A и B, а в шведском она идет после Z. Обратите внимание на расширение PyICU (https://pypi.org/project/PyICU/), которое работает как локаль, но без изменения локали процесса. Оно также необходимо, если требуется изменить регистр iİ/ıI в турецком языке. Расшире- ние PyICU необходимо компилировать, поэтому в некоторых системах установить его сложнее, чем библиотеку pyuca, напи- санную на чистом Python. Кстати говоря, таблица упорядочения – лишь одна из многих составных ча- стей базы данных Unicode, о которой мы поговорим в следующем разделе. 164  Unicode-текст и байты\n--- Страница 164 ---\nБаза данных unicode В стандарте Unicode приведена целая база данных – в виде многочисленных структурированных текстовых файлов, – которая включает не только со- поставление имен символов кодовым позициям, но также метаданные от- дельных символов и информацию о связях между ними. Например, в базе данных Unicode указано, имеет ли символ графическое начертание, является ли он буквой, десятичной цифрой или еще каким-то числовым символом. На основе этой информации работают методы isidentifier , isprintable , isdecimal и isnumeric класса str. Метод str.casefold также пользуется информацией из базы данных Unicode. Функция unicodedata.category(char) возвращает двухбуквенную категорию символа из базы данных Unicode. Методы класса str более высокого уровня использовать проще. Например, label. isalpha() возвращает True, если все символы label принадлежат одной из следующих категорий: Lm, Lt, Lu, Ll или Lo. О том, что оз- начают эти коды, см. раздел «General Category» в статье из англо- язычной части Википедии «Unicode character property» (https:// en.wikipedia.org/wiki/Unicode_character_property). Поиск символов по имени В модуле unicodedata имеются функции, возвращающие метаданные символов, в т. ч. unicodedata.name() , которая возвращает официальное название символа по стандарту. На рис. 4.5 показана эта функция в действии1. Рис. 4.5. Исследование unicodedata.name() на консоли Python Функцию name() можно использовать в приложениях, позволяющих ис- кать символы по имени. На рис. 4.6 показан результат работы командного скрипта cf.py, который принимает в качестве аргументов одно или несколь- ко слов и выводит символы Unicode, в официальных названиях которых встречаются эти слова. Полный исходный код скрипта cf.py приведен в при- мере 4.21. 1 Это картинка, а не листинг, потому что цифровые инструменты подготовки к печати, применяемые в издательстве O’Reilly, плохо поддерживают эмодзи. База данных Unicode  165\n--- Страница 165 ---\nРис. 4.6. Использование скрипта cf.py для поиска улыбающихся котят Поддержка эмодзи сильно зависит от операционной системы и приложения. В последние годы лучшую поддержку эмодзи на терминалах предлагает macOS, за ней следуют современные гра- фические терминалы GNU/Linux. В Windows cmd.exe и PowerShell теперь поддерживают вывод Unicode, но в январе 2020 года, ког- да я пишу эти строки, они еще не отображали эмодзи, по край- ней мере не «из коробки». Технический рецензент Леонардо Рохаэль говорил мне о новом терминале Windows с открытым исходным кодом от Microsoft, который, возможно, предлагает улучшенную поддержку Unicode, чем старые консоли Microsoft. Но у меня не было времени попробовать его. В примере 4.21 обратите внимание на предложение if в функции find. В нем используется метод .issubset() для быстрой проверки того, встречаются ли все слова, перечисленные в множестве query, в списке слов, построенном по имени символа. Благодаря развитому API работы с множествами нам не нужно писать вложенный цикл for и еще одно предложение if для реализации этой проверки. Пример 4.21. cf.py: утилита для поиска символов #!/usr/bin/env python3 import sys import unicodedata START, END = ord(' '), sys.maxunicode + 1  def find(*query_words, start=START, end=END):  query = {w.upper() for w in query_words}  for code in range(start, end): char = chr(code)  name = unicodedata.name(char, None)  if name and query.issubset(name.split()):  print(f'U+{code:04X}\\t{char}\\t{name}')  def main(words): if words: find(*words) else: print('Please provide words to find.') if __name__ == '__main__': main(sys .a rgv[ 1:]  Задать умолчания для просматриваемого диапазона кодовых позиций.  find принимает аргумент query_words и необязательные чисто именованные аргументы, чтобы ограничить диапазон поиска и упростить тестирование. 166  Unicode-текст и байты\n--- Страница 166 ---\n Преобразовать query_words в множество строк в верхнем регистре.  Получить символ Unicode, соответствующий code.  Получить имя символа или None, если кодовой позиции не назначен никакой символ.  Если имя существует, разбить его на список слов, а затем проверить, что множество query является подмножеством этого списка.  Напечатать строку, содержащую кодовую позицию в формате U+9999, сам символ и его имя. В модуле unicodedata есть и другие интересные функции. Далее мы рассмот- рим несколько функций для получения информации о символах, связанных с числами. Символы, связанные с числами В модуле unicodedata имеются функции, которые проверяют, представляет ли символ Unicode число, и если да, то возвращают его значение, интересное человеку, а не просто номер кодовой позиции. В примере 4.22 показано ис- пользование функций unicodedata.name() и unicodedata.numeric() , а также методов .isdecimal() и .isnumeric() класса str. Пример 4.22. Демонстрация работы с метаданными числовых символов в базе данных Unicode (числовые маркеры описывают отдельные столбцы распечатки) import unicodedata import re re_digit = re.compile(r'\\d') sample = '1\\xbc\\xb2\\u0969\\u136b\\u216b\\u2466\\u2480\\u3285' for char in sample: print(f'U+{ord(char):04x}',  char.center(6),  're_dig' if re_digit.match(char) else '-',  'isdig' if char.isdigit() else '-',  'isnum' if char.isnumeric() else '-',  f'{unicodedata.numeric(char):5.2f}',  unicodedata.name(char),  sep='\\t')  Кодовая позиция в формате U+0000.  Символ, центрированный в поле длины 6.  Вывести re_dig, если символ соответствует регулярному выражению r'\\d'.  Вывести isdig, если char.isdigit() равно True.  Вывести isnum, если char.isnumeric() равно True.  Числовое значение в поле шириной 5 с двумя десятичными знаками после запятой.  Имя символа Unicode. В результате выполнения этого скрипта получается распечатка, показанная на рис. 4.7 (при условии что шрифт терминала содержит все эти глифы). База данных Unicode  167\n--- Страница 167 ---\nРис. 4.7. Числовые символы и их метаданные в терминале macOS; re_dig означает, что сим- вол соответствует регулярному выражению r'\\d' Шестая колонка на рис. 4.7 содержит результат вызова unicodedata.numeric(char) для символа. Эта функция говорит о том, что Unicode знает числовые значения символов, представляющих числа. Так что если вы собираетесь написать про- грамму для электронной таблицы, поддерживающей тамильские или римские цифры, вперед и с песней! По рис. 4.7 видно, что регулярному выражению r'\\d' соответствует цифра «1» и цифра 3 письменности Деванагари, но не некоторые другие символы, которые функция isdigit считает цифрами. Модуль re знает о Unicode мень- ше, чем должен бы. Новый модуль regex, доступный на сайте PyPI, имеет целью полностью заменить re и поддерживает Unicode лучше1. Мы вернемся к моду - лю re в следующем разделе. В этой главе мы пользовались несколькими функциями из модуля unicodedata , но на самом деле их гораздо больше. См. описание модуля unicodedata в докумен- тации по стандартной библиотеке (https://docs.python.org/3/library/unicodedata.html). Далее мы кратко познакомимся с двухрежимным API, предоставляющим функции, которые принимают в качестве аргументов str и bytes и работают по-разному в зависимости от типа. двухрежимный Api В стандартной библиотеке есть функции, которые принимают в качестве аргу - ментов значения типа str или bytes и ведут себя по-разному в зависимости от типа. Примеры имеются в модулях re и os. str и bytes в регулярных выражениях Если при построении регулярного выражения был задан аргумент типа bytes, то образцам вида \\d или \\w будут соответствовать только ASCII-символы. На- оборот, если был задан аргумент типа str, то этим образцам будут соответ - ствовать цифры и буквы в смысле Unicode, а не только ASCII. В примере 4.23 и на рис. 4.8 показано сопоставление букв, ASCII-цифр, надстрочных индексов и тамильских цифр с образцами типа str и bytes. 1 Хотя цифры он распознавал ничуть не лучше модуля re.168  Unicode-текст и байты\n--- Страница 168 ---\nПример 4.23. ramanujan.py: сравнение поведения простых регулярных выражений с аргументами типа str и bytes import re re_numbers_str = re.compile(r'\\d+')  re_words_str = re.compile(r'\\w+') re_numbers_bytes = re.compile(rb'\\d+')  re_words_bytes = re.compile(rb'\\w+') text_str = (\"Ramanujan saw \\u0be7\\u0bed\\u0be8\\u0bef\"  \" as 1729 = 1³ + 12³ = 9³ + 10³.\")  text_bytes = text_str.encode('utf_8')  print(f'Text\\n {text_str!r}') print('Numbers') print(' str :', re_numbers_str.findall(text_str))  print(' bytes:', re_numbers_bytes.findall(text_bytes))  print('Words') print(' str :', re_words_str.findall(text_str))  print(' bytes:', re_words_bytes.findall(text_bytes))   Первые два регулярных выражения типа str.  Последние два регулярных выражения типа bytes.  Текст Unicode, в котором производится поиск, содержит тамильские цифры числа 1729 (логическая строка продолжается до правой закрывающей скобки).  Эта строка конкатенируется с предыдущей на этапе компиляции (см. раздел 2.4.2 «Конкатенация строковых литералов» справочного руко- водства (https://docs.python.org/3/reference/ lexical_analysis.html#string-literal- concatenation) по языку Python).  Для поиска с помощью регулярного выражения типа bytes необходима строка типа bytes.  Образец r'\\d+' типа str сопоставляется с тамильскими цифрами и цифрами ASCII.  Образец rb'\\d+' типа bytes сопоставляется только с цифрами ASCII.  Образец r'\\w+' типа str сопоставляется с буквами, надстрочными индекса- ми, тамильскими цифрами и цифрами ASCII.  Образец rb'\\w+' типа str сопоставляется только с ASCII-байтами букв и цифр. Рис. 4.8. Результат выполнения скрипта ramanujan.py из примера 4.23 Двухрежимный API  169\n--- Страница 169 ---\nЭто тривиальный пример, призванный подчеркнуть одну мысль: в регуляр- ных выражениях можно употреблять как str, так и bytes, но во втором случае байты, не принадлежащие диапазону ASCII, не считаются ни цифрами, ни символами, являющимися частью слова. Для регулярных выражений типа str существует флаг re.ASCII, при задании ко- торого \\w, \\W, \\b, \\B, \\d, \\D, \\s и \\S производят сопоставление только с байтами ASCII. Подробнее см. документацию по модулю re (https://docs.python.org/3/library/re.html). Еще один важный двухрежимный модуль – это os. str и bytes в функциях из модуля os Ядро GNU/Linux ничего не знает о Unicode, поэтому на практике можно встре- тить имена файлов, представляющие собой последовательности байтов, ко- торые не являются допустимыми ни в какой разумной кодировке и которые нельзя декодировать в тип str. Особенно чувствительны к этой проблеме фай- ловые серверы, имеющие клиентов для разных ОС. Чтобы обойти эту проблему, все функции из модуля os, принимающие име- на файлов или пути, могут работать с аргументами типа str или bytes. Если такая функция вызывается с аргументом типа str, то он автоматически преоб- разуется кодеком, определяемым функцией sys.getfilesystemencoding() , а ответ ОС декодируется тем же кодеком. Почти всегда это именно то, что нужно, и согла- суется с сэндвичем Unicode. Но если приходится иметь дело с именами, которые так обрабатывать нель- зя (или исправлять такие имена), то можно передавать функциям из модуля os аргументы типа bytes, и при этом они возвращают значения типа bytes. Это по- зволяет работать с любыми именами файлов и путями, сколько бы в них ни было крокозябров. См. пример 4.24. Пример 4.24. Функция listdir с аргументами типа str и bytes и ее результаты >>> os.listdir('.')  ['abc.txt', 'digits-of-π.txt'] >>> os.listdir(b'.')  [b'abc.txt', b'digits-of-\\xcf\\x80.txt']  Второе имя файла равно «digits-of-π.txt» (с греческой буквой «пи»).  Если аргумент имеет тип bytes, то listdir возвращает имена файлов как бай- ты: b'\\xcf\\x80' – представление греческой буквы «пи» в кодировке UTF-8. Чтобы помочь обрабатывать последовательности типа str или bytes, состав- ляющие имена файлов или пути, модуль os предоставляет специальные функ - ции кодирования и декодирования os.fsencode(name_or_path) и os.fsdecode(name_ or_path). Обе функции принимают аргумент типа str либо bytes или, начиная с Python 3.6, объект, реализующий интерфейс os.PathLike . Unicode – глубокая кроличья нора. Пора заканчивать рассказ о типах str и bytes. резюме Мы начали эту главу с опровержения утверждения 1 символ == 1 байт . В мире, перешедшем на Unicode, необходимо разделять понятия текстовой строки 170  Unicode-текст и байты\n--- Страница 170 ---\nи двоичной последовательности, которой такая строка представлена в файле. И Python 3 поддерживает подобное разделение. После краткого обзора двоичных типов последовательностей – bytes, bytearray и memoryview – мы перешли к кодированию и декодированию, привели репре- зентативную выборку кодеков и объяснили, как предотвратить или обработать печально известные ошибки UnicodeEncodeError , UnicodeDecodeError и SyntaxError , вы- званные неправильным кодированием исходного файла Python. Далее мы рассмотрели теорию и практику распознавания кодировки в от - сутствие метаданных; теоретически это невозможно, но на практике пакет Chardet неплохо справляется с этой задачей для многих популярных кодиро- вок. Мы сказали о том, что маркеры порядка байтов – единственная инфор- мация о кодировке, присутствующая в файлах с кодировкой UTF-16 и UTF-32, иногда также UTF-8. В следующем разделе мы продемонстрировали открытие текстовых файлов. В этой несложной задаче есть один подвох: именованный аргумент encoding= не- обязателен, хотя должен бы быть таковым. Если кодировка не задана, то получа- ется программа, которая генерирует «простой текст», несовместимый с разными платформами из-за несовпадения кодировок по умолчанию. Затем мы расска- зали о различных параметрах, которые интерпретатор Python использует в ка- честве источников умолчаний: locale.getpreferredencoding() , sys.getfilesystemencoding() , sys.getdefaultencoding() , а также о кодировках стандартных потоков ввода-вывода (например, sys.stdout.encoding ). Печальным фактом для пользователей Windows является то, что эти параметры зачастую имеют разные значения на одной и той же машине, причем эти значения несовместимы между собой. Напротив, пользователи GNU/Linux и macOS обитают в счастливом мире, где практически повсюду по умолчанию используется кодировка UTF-8. В Unicode некоторые символы можно представить несколькими способа- ми, поэтому перед сравнением необходимо выполнить нормализацию. Мы не только объяснили, что такое нормализация и сворачивание регистра, но и привели несколько служебных функций, которые вы можете приспособить к своим нуждам, и среди них функцию, которая полностью удаляет все акцен- ты. Далее мы видели, как правильно сортировать текст Unicode с применением стандартного модуля locale (у которого есть некоторые недостатки) или аль- тернативного ему внешнего пакета pyuca, не зависящего от головоломных на- строек локали. Мы воспользовались базой данных Unicode для написания командной ути- литы поиска символов по имени – благодаря мощным средствам Python она уместилась всего в 28 строках кода. Мы кратко рассмотрели другие метадан- ные Unicode и двухрежимный API, позволяющий вызывать некоторые функ - ции с аргументами типа str или bytes, получая при этом разные результаты. дОпО лнительная литература Хочу отметить выдающееся выступление Нэда Бэтчелдера на конференции PyCon US 2012 года «Pragmatic Unicode – or – How Do I Stop the Pain?» (http:// nedbatchelder.com/text/unipain.html). Нэд оказался настолько профессионален, что выложил полную запись доклада со всеми слайдами и видео. Дополнительная литература  171\n--- Страница 171 ---\nНа конференции PyCon 2014 Эстер Нэм и Трэвис Фишер выступили с ве- ликолепным докладом «Character encoding and Unicode in Python: How to (╯°□°)╯ ┻━┻ with dignity» (слайды имеются по адресу https://www. slideshare.net/fischertrav/character-encoding-unicode-how-to-with-dignity-33352863, видео – по адресу https://pyvideo.org/pycon-us-2014/character-encoding-and-unicode- in-python.html), из которого я взял эпиграф к данной главе «Человек работает с текстом, компьютер – с байтами». Леннарт Регебро – один из технических рецензентов книги – представил свою «полезную мысленную модель Unicode» в короткой статье «Unconfusing Unicode: What Is Unicode?» (https://regebro.wordpress.com/2011/03/23/unconfusing- unicode-what-is-unicode/). Unicode – сложный стандарт, поэтому мысленная мо- дель Леннарта – действительно полезная отправная точка. В официальном документе «Unicode HOWTO» (https://docs.python.org/3/howto/ unicode.html) в документации по Python эта тема рассматривается с разных точек зрения: от удачного исторического введения до деталей синтаксиса, кодеков, ре- гулярных выражений, имен файлов и рекомендаций по написанию кода ввода- вывода с учетом Unicode (сэндвич Unicode). В каждом разделе имеются ссылки на дополнительную информацию. В главе 4 «Строки» (http://www.diveintopython3. net/strings.html) замечательной книги Mark Pilgrim «Dive into Python 3» (http:// www.diveintopython3.net) также имеется отличное введение в поддержку Unicode в Python 3. В главе 15 той же книги (https://finderiko.com/python-book) описан пере- нос библиотеки Chardet с Python 2 на Python 3 – ценный пример, учитывая, что переход от старого типа str к новому типу bytes стал причиной большинства не- приятностей, связанных с миграцией, а это – как раз основная тема библиотеки, призванной распознавать кодировки. Для тех, кто знает Python 2, но незнаком с Python 3, в статье Гвидо ван Россу - ма «What’s New in Python 3.0» (https://docs.python.org/3.0/whatsnew/3.0.html#text-vs- data-instead-of-unicode-vs-8-bit) перечислено 15 основных отличий со множест - вом ссылок. Гвидо начинает с прямого заявления: «Все, что, как вам казалось, вы знали о двоичных данных и Unicode, изменилось». Армен Ронашер (Armin Ronacher) опубликовал в своем блоге статью «The Updated Guide to Unicode on Python» (https://lucumr.pocoo.org/2013/7/2/the-updated-guide-to-unicode/), в которой акцентирует внимание на некоторых подводных камнях Unicode в Python 3 (Армен – не большой поклонник Python 3). В главе 2 книги David Beazley, Brian K. Jones «Python Cookbook», 3-е изда- ние (O’Reilly), приведено несколько рецептов, относящихся к нормализации в Unicode, очистке текста и выполнению текстовых операций над последова- тельностями байтов. В главе 5, посвященной файлам и вводу-выводу, имеет - ся рецепт 5.17 «Запись байтов в текстовый файл», где показано, что за любым текстовым файлом стоит двоичный поток, к которому при желании можно получить доступ напрямую. Далее в рецепте 6.11 «Чтение и запись двоичных массивов структур» показано применение модуля struct. В блоге Ника Кофлина (Nick Coghlan) «Python Notes» есть две статьи, имею- щие непосредственное отношение к этой главе: «Python 3 and ASCII Compatible Binary Protocols» (http://python-notes.curiousefficiency.org/en/latest/) и «Processing Text Files in Python 3» (http://python-notes.curiousefficiency.org/en/latest/python3/ text_ file_processing.html). Настоятельно рекомендую.172  Unicode-текст и байты\n--- Страница 172 ---\nСписок кодировок, поддерживаемых Python, приведен в разделе «Стандарт - ные кодировки» (https://docs.python.org/3/library/codecs.html#standard-encodings) документации по модулю codecs. О том, как получить доступ к этому списку из программы, см. скрипт /Tools/unicode/listcodecs.py ( https://github.com/python/ cpython/blob/0bbf30e2b910bc9c5899134ae9d73a8df968da35/Tools/unicode/listcodecs. py), входящий в состав дистрибутива CPython. Книги Jukka K. Korpela «Unicode Explained» (https://www.oreilly.com/library/view/ unicode-explained/059610121X/) (O’Reilly) и Richard Gillam «Unicode Demystified» (Addison-Wesley) не связаны с Python, но очень помогли мне в изучении кон- цепций Unicode. Книга Виктора Стиннера (Victor Stinner) «Programming with Unicode» (http://unicodebook.readthedocs.org/index.html) – бесплатное произведе- ние, опубликованное самим автором (распространяется по лицензии Creative Commons BY-SA); в ней рассматривается как сам стандарт Unicode, так и ин- струментальные средства и API для основных операционных систем и не- скольких языков программирования, включая Python. На страницах сайта W3C «Case Folding: An Introduction» (http://www.w3.org/ International/wiki/Case_folding) и «Character Model for the World Wide Web: String Matching and Searching» (http://www.w3.org/TR/charmod-norm/) рассматривается кон- цепция нормализации; первый документ написан в форме введения для начина- ющих, а второй – рабочий проект, изложенный сухим языком стандарта – в том же стиле, что «Unicode Standard Annex #15 – Unicode Normalization Forms» (http:// unicode.org/reports/tr15/). Документ «Frequently Asked Questions / Normalization» (http://www.unicode.org/faq/normalization.html) на сайте Unicode.org (http://www.unicode. org/) проще для восприятия, равно как и NFC FAQ (http://www.macchiato.com/unicode/ nfc-faq) Марка Дэвиса – автора нескольких алгоритмов Unicode и президента кон- сорциума Unicode Consortium на момент работы над этой книгой. В 2016 году Музей современного искусства в Нью-Йорке добавил в свою коллекцию оригинальные эмодзи (https://stories.moma.org/the-original-emoji-set- has-been-added-to-the-museum-of-modern-arts-collection-c6060e141f61) – 176 эмодзи, разработанных дизайнером Шигетака Курита в 1999 году для NTT DOCOMO, японского мобильного оператора. Углубляясь в историю еще дальше, отметим, что Эмодзипедиа ( https://blog.emojipedia.org/) опубликовала статью «Поправки к истории первого набора эмодзи» (https://blog.emojipedia.org/correcting-the-record- on-the-first-emoji-set/), в которой честь создания самого раннего из известных наборов эмодзи приписывается японскому банку SoftBank, который размес- тил его в сотовых телефонах в 1997 году. Набор SoftBank является источником 90 эмодзи, находящихся ныне в Unicode, включая U+1F4A9 (PILE OF POO , КАКАШКА). Сайт Мэтью Ротенберга emojitracker.com – динамическая панель, на которой в режиме реального времени показываются счетчики использования эмодзи в Твиттере. Когда я пишу эти слова, самым популярным был эмодзи FACE WITH TEARS OF JOY (ЛИЦО СО СЛЕЗАМИ РАДОСТИ ) (U+1F602), он встречался 3 313 667 315 раз. Поговорим Не-ASCII имена в исходном коде: стоит ли их использовать? В Python 3 разрешается использовать в исходном коде идентификаторы в ко- дировке, отличной от ASCII: Дополнительная литература  173\n--- Страница 173 ---\n>>> ação = 'PBR' # ação = frwbz >>> ε = 10**-6 # ε = epsilon Некоторым эта идея не нравится. Чаще всего в пользу использования только ASCII-идентификаторов приводят тот довод, что так всем будет проще читать и редактировать код. Но тут упущена одна деталь: вы хотите, чтобы ваш ис- ходный код был доступен для чтения и редактирования целевой аудитории, а это вовсе необязательно «все». Если код принадлежит интернациональной корпорации или является открытым, и вы хотите, чтобы дополнять его мог- ли люди во всего света, то идентификаторы определенно стоит писать по- английски, и тогда вам нужна только кодировка ASCII. Но если вы преподаете в Бразилии, то студентам будет проще читать код, в котором имена переменных и функций написаны по-португальски и при- том без орфографических ошибок. И у них не будет проблем с вводом седилей и акцентированных гласных, поскольку они работают с местной клавиатурой. Поскольку теперь Python понимает Unicode-имена, а UTF-8 – кодировка ис- ходного кода по умолчанию, то я не вижу никакого смысла писать португаль- ские идентификаторы без диакритических знаков, как мы делали в Python 2 по необходимости, – если, конечно, вы не собираетесь запускать свой код и в Python 2 тоже. Если имена все равно португальские, то отбрасывание диакри- тических знаков не сделает код понятнее ни для кого. Это моя личная точка зрения – человека, говорящего на бразильском диалек - те португальского языка, – но полагаю, что она применима и к другим куль- турам и регионам: выберите естественный язык, который наиболее понятен потенциальным читателям кода, и набирайте его символы правильно. Что такое «простой текст»? Для любого, кто в повседневной работе имеет дело с неанглоязычными тек- стами, «простой текст» не ассоциируется с «ASCII». В глоссарии Unicode (http:// www.unicode.org/glossary/#plain_text) простой текст определяется так: Закодированный для компьютера текст, который включает только после- довательность кодовых позиций из некоторого стандарта – без какой-ли- бо форматной или структурной информации. Начинается это определение очень хорошо, но с частью после тире я не согла- сен. HTML – прекрасный пример простого текста, содержащего форматную и структурную информацию. Но это все же простой текст, потому что каждый байт в таком файле представляет некий текстовый символ, обычно в коди- ровке UTF-8. В файле нет байтов, несущих нетекстовую нагрузку, как, ска- жем, в файлах типа PNG или XLS, где большинство байтов – это упакованные двоичные значения, представляющие либо цвета в формате RGB, либо числа с плавающей точкой. В простом тексте число было бы представлено в виде последовательности цифр. Я пишу эту книгу в формате простого текста, который, по иронии судьбы, на- зывается AsciiDoc (http://www.methods.co.nz/asciidoc/) и является частью велико- лепного инструментария, входящего в комплект платформы книгоиздания Atlas компании O’Reilly (https://atlas.oreilly.com/). Исходные файлы в формате AsciiDoc – это простой текст, но в кодировке UTF-8, а не ASCII. В противном случае писать эту главу было бы крайне затруднительно. Несмотря на свое название, AsciiDoc – отличная вещь.174  Unicode-текст и байты\n--- Страница 174 ---\nВселенная Unicode постоянно расширяется, и на ее границах не всегда есть подходящие инструменты. Не все нужные мне символы присутствовали в шрифтах, которыми набрана эта книга. Именно поэтому я был вынужден использовать изображения, а не листинги в некоторых примерах из этой гла- вы. С другой стороны, на терминалах в Ubuntu и macOS большинство симво- лов Unicode прекрасно отображаются – включая и японские символы, состав- ляющие слово «mojibake»: 文字化け. Как кодовые позиции представлены в памяти? В официальном руководстве по Python старательно обходится вопрос о том, как кодовые позиции строки str хранятся в памяти. В конце концов, это дей- ствительно деталь реализации. Теоретически это не имеет значения: каким бы ни было внутреннее представление, каждая строка при выводе должна перекодироваться в объект типа bytes. В Python 3 объект str хранится в памяти как последовательность кодовых по- зиций с фиксированным количеством байтов на одну позицию, чтобы обес- печить прямой доступ к любому символу или срезу. Начиная с версии Python 3.3 интерпретатор, создавая объект str, проверяет, из каких символов он состоит, и выбирает наиболее экономичное размеще- ние в памяти данного объекта. Если имеются только символы из диапазона latin1, то каждая кодовая позиция str будет представлена всего одним бай- том. В противном случае для представления кодовой позиции может понадо- биться 2 или 4 байта – все зависит от str. Это упрощенное изложение, детали см. в документе PEP 393 «Flexible String Representation» (https://www.python.org/ dev/peps/pep-0393/). Гибкое представление строки похоже на представление типа int в Python 3: если целое число умещается в машинном слове, то оно и хранится как одно машинное слово. В противном случае интерпретатор переходит на представ- ление переменной длины, как для типа long в Python 2. Приятно видеть, как распространяются хорошие идеи. Однако мы всегда можем рассчитывать на Армена Ронахера, когда нужно найти проблемы в Python 3. Он объяснил мне, почему на практике эта идея не так уж хороша: берется единственный символ RAT (U+1F400), в результате чего текст, который без этого состоял бы только из символов ASCII, разбухает и превращается в массив – пожиратель памяти, в котором на каждый сим- вол отведено четыре байта, тогда как для всех символов, кроме RAT, хватило бы и одного. Кроме того, из-за многочисленных способов комбинирования символов в Unicode умение быстро извлекать произвольный символ по но- меру позиции переоценено, а попытка извлекать произвольные участки из Unicode-текста в лучшем случае наивна, а зачастую и вредна, поскольку по- рождает крокозябры. По мере распространения эмодзи эти проблемы будут только нарастать. Дополнительная литература  175",
      "debug": {
        "start_page": 134,
        "end_page": 174
      }
    },
    {
      "name": "Глава 5. Построители классов данных 176",
      "content": "--- Страница 175 --- (продолжение)\nГлава 5 Построители классов данных Классы данных – как дети. В начале пути они прелестны, но чтобы участ- вовать во взрослой жизни, должны брать на себя ответственность. – Мартин Фаулер и Кент Бек1 Python предлагает несколько способов построить простой класс, являющийся просто набором полей, почти или даже совсем без дополнительной функцио- нальности. Этот паттерн называется «классом данных», а dataclasses – один из пакетов, поддерживающих его. В этой главе рассматриваются три разных по- строителя классов, которые можно использовать, чтобы сократить время на- писания классов данных. collections.namedtuple Самый простой способ, доступен начиная с версии Python 2.6. typing.NamedTuple Альтернатива, требующая заданий аннотаций типов для полей. Существу - ет начиная с версии Python 3.5, а синтаксическая конструкция class была добавлена в версии 3.6. @dataclasses.dataclass Декоратор класса, допускающий бóльшую гибкость настройки, чем преды- дущие альтернативы. Но вместе с богатством параметров приходит и до- полнительная сложность. Существует начиная с версии Python 3.7. Рассмотрев все эти построители, мы обсудим, почему «класс данных» счи- тается запашком в коде, т. е. паттерном, который может быть симптомом не- удачного объектно-ориентированного дизайна. Может показаться, что typing.TypedDict – еще один построитель классов данных. В нем используется похожий синтаксис, да и в документации по модулю typing для Python 3.9 его описание идет сразу после typing.NamedTuple . Однако TypedDict не строит конкретные классы, для которых можно было бы создать экземпляры. Это всего лишь синтаксис для написания аннотаций типов параметров функций и пере- менных. Такие аннотации принимают отображения, использу - емые в качестве записей, ключами которых являются имена по- лей. Мы будем рассматривать их в главе 15 «TypedDict». 1 Из книги «Refactoring», первое издание, глава 3, раздел «Bad Smells in Code, Data Class», стр. 87 (Addison-Wesley).\nГлава 5 Построители классов данных Классы данных – как дети. В начале пути они прелестны, но чтобы участ- вовать во взрослой жизни, должны брать на себя ответственность. – Мартин Фаулер и Кент Бек1 Python предлагает несколько способов построить простой класс, являющийся просто набором полей, почти или даже совсем без дополнительной функцио- нальности. Этот паттерн называется «классом данных», а dataclasses – один из пакетов, поддерживающих его. В этой главе рассматриваются три разных по- строителя классов, которые можно использовать, чтобы сократить время на- писания классов данных. collections.namedtuple Самый простой способ, доступен начиная с версии Python 2.6. typing.NamedTuple Альтернатива, требующая заданий аннотаций типов для полей. Существу - ет начиная с версии Python 3.5, а синтаксическая конструкция class была добавлена в версии 3.6. @dataclasses.dataclass Декоратор класса, допускающий бóльшую гибкость настройки, чем преды- дущие альтернативы. Но вместе с богатством параметров приходит и до- полнительная сложность. Существует начиная с версии Python 3.7. Рассмотрев все эти построители, мы обсудим, почему «класс данных» счи- тается запашком в коде, т. е. паттерном, который может быть симптомом не- удачного объектно-ориентированного дизайна. Может показаться, что typing.TypedDict – еще один построитель классов данных. В нем используется похожий синтаксис, да и в документации по модулю typing для Python 3.9 его описание идет сразу после typing.NamedTuple . Однако TypedDict не строит конкретные классы, для которых можно было бы создать экземпляры. Это всего лишь синтаксис для написания аннотаций типов параметров функций и пере- менных. Такие аннотации принимают отображения, использу - емые в качестве записей, ключами которых являются имена по- лей. Мы будем рассматривать их в главе 15 «TypedDict». 1 Из книги «Refactoring», первое издание, глава 3, раздел «Bad Smells in Code, Data Class», стр. 87 (Addison-Wesley).\n--- Страница 176 ---\nчтО нОвОг О в этОй главе В первом издании этой главы вообще не было. Раздел «Классические имено- ванные кортежи» входил в главу 2, но все остальное написано заново. Мы начнем с общего обзора всех трех построителей классов. ОБзОр пОСтрОителей клаССОв данных Рассмотрим простой класс для представления географических координат (пример 5.1). Пример 5.1. class/coordinates.py class Coordinate: def __init__(self, lat, lon): self.lat = lat self.lon = lon Класс Coordinate хранит в своих атрибутах широту и долготу. Написание сте- реотипного кода __init__ очень быстро надоедает, особенно если в классе атри- бутов не два, а больше: каждый придется упомянуть три раза! И к тому же та- кой стереотипный код не дает нам того, чего мы ожидаем от объекта Python: >>> from coordinates import Coordinate >>> moscow = Coordinate(55.76, 37.62) >>> moscow <coordinates.Coordinate object at 0x107142f10>  >>> location = Coordinate(55.76, 37.62) >>> location == moscow  False >>> (location.lat, location.lon) == (moscow.lat, moscow.lon)  True  Метод __repr__, унаследованный от object, не особенно полезен.  Оператор == вообще бессмысленный; метод __repr__, унаследованный от object, сравнивает идентификаторы объектов.  Для сравнения двух координат необходимо явно сравнить обе пары атрибутов. Построители классов данных, рассматриваемые в этой главе, автоматически предоставляют необходимые методы __init__, __repr__ и __eq__, а также другие полезные средства. Ни один из обсуждаемых ниже построителей классов не опи- рается на наследование. Построители collections.namedtuple и typing.NamedTuple строят классы, являющиеся подклассами tuple. А @dataclass – вообще декоратор класса, который никак не влияет на иерархию классов. Все они пользуются различны- ми средствами метапрограммирования для внедрения методов и атрибутов данных в создаваемый класс. Ниже показано поведение класса Coordinate , построенного с помощью namedtuple – фабричной функции, которая строит подкласс tuple с заданными нами именем и полями: Обзор построителей классов данных  177\n--- Страница 177 ---\n>>> from collections import namedtuple >>> Coordinate = namedtuple('Coordinate', 'lat lon') >>> issubclass(Coordinate, tuple) True >>> moscow = Coordinate(55.756, 37.617) >>> moscow Coordinate(lat=55.756, lon=37.617)  >>> moscow == Coordinate(lat=55.756, lon=37.617)  True  Полезный метод __repr__.  Осмысленный метод __eq__. Появившийся позже класс typing.NamedTuple предлагает такую же функцио- нальность и дополнительно аннотации типа для каждого поля: >>> import typing >>> Coordinate = typing.NamedTuple('Coordinate', [('lat', float), ('lon', float)]) >>> issubclass(Coordinate, tuple) True >>> typing.get_type_hints(Coordinate) {'lat': <class 'float'>, 'lon': <class 'float'>} Типизированный именованный кортеж можно построить так же, задав поля в виде именованных аргументов: Coordinate = typing.NamedTuple('Coordinate', lat=float, lon=float) Этот код проще читать, а кроме того, он позволяет задать ото- бражение полей на типы в виде **fields_and_types . Начиная с версии Python 3.6 typing.NamedTuple можно также использовать в предложении class, а аннотации типов записывать, как предлагается в доку - менте PEP 526 «Syntax for Variable Annotations» (https://peps.python.org/pep-0526/). Это гораздо проще читается и позволяет легко переопределять методы или до- бавлять новые. В примере 5.2 показан тот же класс Coordinate с двумя атрибута- ми float и методом __str__, который отображает координаты в формате 55.8°N, 37.6°E. Пример 5.2. typing_namedtuple/coordinates.py from typing import NamedTuple class Coordinate(NamedTuple): lat: float lon: float def __str__(self): ns = 'N' if self.lat >= 0 else 'S' we = 'E' if self.lon >= 0 else 'W' return f'{abs(self.lat):.1f}°{ns}, {abs(self.lon):.1f}°{we}' 178  Построители классов данных\n--- Страница 178 ---\nХотя NamedTuple выглядит в предложении class как суперкласс, на самом деле это не так. В классе typing.NamedTuple используется про- двинутая функциональность метакласса1, позволяющая настро- ить создание пользовательского класса. В этом легко убедиться: >>> issubclass(Coordinate, typing .NamedTuple) False >>> issubclass(Coordinate, tuple) True В методе __init__, сгенерированном с помощью typing.NamedTuple , поля встре- чаются в том же порядке, в каком они перечислены в предложении class. Как и typing.NamedTuple , декоратор dataclass поддерживает синтаксис объявле- ния атрибутов экземпляра, описанный в документе PEP 526. Декоратор чита- ет аннотации переменных и автоматически генерирует методы вашего клас - са. Для сравнения взгляните на эквивалентный класс Coordinate , написанный с применением декоратора dataclass (пример 5.3). Пример 5.3. dataclass/coordinates.py from dataclasses import dataclass @dataclass(frozen=True) class Coordinate: lat: float lon: float def __str__(self): ns = 'N' if self.lat >= 0 else 'S' we = 'E' if self.lon >= 0 else 'W' return f'{abs(self.lat):.1f}°{ns}, {abs(self.lon):.1f}°{we}' Отметим, что тела классов в примерах 5.2 и 5.3 одинаковы – разница только в самом предложении class. Декоратор @dataclass не опирается ни на наследова- ние, ни на метакласс, поэтому не препятствует любому использованию вами этих механизмов2. Класс Coordinate в примере 5.3 – подкласс object. Основные возможности У различных построителей классов данных много общих черт, сведенных в табл. 5.1. Таблица 5.1. Сравнение избранных возможностей всех трех построителей классов данных (x означает экземпляр класса данных) namedtuple NamedTuple dataclass Изменяемые экземп- лярыНет Нет Да Синтаксис предло- жения classНет Да Да 1 Метаклассы – одна из тем главы 24 «Метапрограммирование классов». 2 Декораторы классов рассматриваются в главе 24 «Метапрограммирование классов» наряду с метаклассами. То и другое – способы настройки поведения классов, недо- стижимые с помощью наследования. Обзор построителей классов данных  179\n--- Страница 179 ---\nnamedtuple NamedTuple dataclass Конструирование dictx._asdict() x._asdict() dataclasses.asdict(x) Получение имен полейx._fields x._fields [f.name for f in dataclasses.fields(x)] Получение значений по умолчаниюx._field_defaults x._field_defaults [f.default for f in dataclasses.fields(x)] Получение типов полейНе применимо x.__annotations__ x.__annotations__ Новый экземпляр с изменениямиx._replace(…) x._replace(…) dataclasses.replace(x, …) Новый класс во вре- мя выполненияnamedtuple(…) NamedTuple(…) dataclasses.make_ dataclass(…) У классов, построенных с помощью typing.NamedTuple и @dataclass , имеется атрибут __annotations__ , в котором хранятся аннотации типов полей. Однако читать __annotations__ напрямую не реко- мендуется. Лучше получать эту информацию от метода inspect. get_annotations(MyClass) (добавлен в Python 3.10) или typing.get_ type_hints(MyClass) (Python 3.5–3.9). Дело в том, что эти функции предоставляют дополнительные возможности, в частности раз- решение опережающих ссылок в аннотациях типов. Мы вернем- ся к этому вопросу гораздо позже, в разделе «Проблемы аннота- ций на этапе выполнения» главы 15. А теперь обсудим эти основные возможности. Изменяемые экземпляры Ключевое различие между этими построителями классов – тот факт, что collections.namedtuple и typing.NamedTuple строят подклассы tuple, поэтому экземп- ляры оказываются неизменяемыми. По умолчанию @dataclass порождает из- меняемые классы. Но декоратор принимает именованный аргумент frozen, показанный в примере 5.3. Если frozen=True , то класс возбудит исключение при попытке присвоить какому-либо полю значение после инициализации экземпляра. Синтаксис предложения class Только typing.NamedTuple и dataclass поддерживают регулярный синтаксис пред- ложения class, что упрощает добавление методов и строк документации в соз- даваемый класс. Конструирование dict Оба варианта на основе именованных кортежей предоставляют метод эк- земпляра (._asdict) для конструирования объекта dict по полям экземпля- ра класса данных. Модуль dataclasses содержит функцию для этой цели: dataclasses.asdict . Окончания табл. 5.1180  Построители классов данных\n--- Страница 180 ---\nПолучение имен полей и значений по умолчанию Все три построителя классов позволяют получать имена полей и заданных для них значений по умолчанию. В классах, производных от именованного кор- тежа, эти метаданные хранятся в атрибутах ._fields и ._fields_defaults . От класса с декоратором dataclass те же метаданные можно получить с помощью функ - ции fields из модуля dataclasses . Она возвращает кортеж объектов Field, имеющих несколько атрибутов, в т. ч. name и default. Получение типов полей В классах, определенных с помощью typing.NamedTuple и @dataclass , имеется атри- бут __annotations__ , содержащий отображение имен полей на их типы. Как уже было сказано, рекомендуется использовать функцию typing.get_type_hints , а не читать этот атрибут непосредственно. Новый экземпляр с изменениями Если дан именованный кортеж x, то вызов x._replace(**kwargs) возвращает новый экземпляр, в котором значения некоторых атрибутов изменены в соответ - ствии с переданными именованными аргументами. Функция уровня модуля dataclasses.replace(x, **kwargs) делает то же самое для экземпляра класса с деко- ратором dataclass. Новый класс во время выполнения Хотя синтаксис предложения class более понятен, он предполагает статиче- ское создание. Иногда требуется создавать классы данных динамически, во время выполнения. Для этого можно использовать синтаксис вызова функции collections.namedtuple , поддерживаемый также классом typing.NamedTuple . В модуле dataclasses для той же цели имеется функция make_dataclass . После этого обзора основных возможностей построителей классов данных рассмотрим каждый из них подробно и начнем с простейшего. клаССичеСкие именОванные кОртежи Функция collections.namedtuple – это фабрика, порождающая подклассы tuple, до- полненные возможностью задавать имена полей, имя класса и информатив- ный метод __repr__. Классы, построенные с помощью namedtuple , можно исполь- зовать всюду, где нужны кортежи, и на самом деле многие функции из стан- дартной библиотеки Python, которые служат для возврата кортежей, теперь для удобства возвращают именованные кортежи; на пользовательский код это никак не влияет. Экземпляры класса, построенного с помощью namedtuple , потреб- ляют ровно столько памяти, сколько кортежи, потому что имена полей хранятся в определении класса. В примере 5.4 показано, как можно было бы определить кортеж для хране- ния информации о городе. Классические именованные кортежи  181\n--- Страница 181 ---\nПример 5.4. Определение и использование именованного кортежа >>> from collections import namedtuple >>> City = namedtuple('City', 'name country population coordinates')  >>> tokyo = City('Tokyo', 'JP', 36.933, (35.689722, 139.691667))  >>> tokyo City(name='Tokyo', country='JP', population=36.933, coordinates=(35.689722, 139.691667)) >>> tokyo.population  36.933 >>> tokyo.coordinates (35.689722, 139.691667) >>> tokyo[1] 'JP'  Для создания именованного кортежа нужно задать два параметра: имя класса и список имен полей; последний может быть любым итерируемым объектом, содержащим строки, или одной строкой, в которой имена пере- числены через запятую.  Данные передаются конструктору в виде позиционных аргументов (тогда как конструктор кортежа принимает единственный итерируемый объект).  К полям можно обращаться по имени или по номеру позиции. Будучи подклассом tuple, City наследует полезные методы, в частности __eq__ и специальные методы, поддерживающие операторы сравнения, включая __lt__, что позволяет сортировать списки экземпляров City. Именованный кортеж предлагает несколько атрибутов и методов в допол- нение к унаследованным от кортежа. В примере 5.5 показаны наиболее по- лезные: атрибут класса _fields, метод класса _make(iterable) и метод экземпляра _asdict(). Пример 5.5. Атрибуты и методы именованного кортежа (продолжение предыдущего при- мера) >>> City._fields  ('name', 'country', 'population', 'location') >>> Coordinate = namedtuple('Coordinate', 'lat lon') >>> delhi_data = ('Delhi NCR', 'IN', 21.935, Coordinate(28.613889, 77.208889)) >>> delhi = City._make(delhi_data)  >>> delhi._asdict()  {'name': 'Delhi NCR', 'country': 'IN', 'population': 21.935, 'location': Coordinate(lat=28.613889, lon=77.208889)} >>> import json >>> json.dumps(delhi._asdict())  '{\"name\": \"Delhi NCR\", \"country\": \"IN\", \"population\": 21.935, \"location\": LatLong(lat=28.613889, long=77.208889) >>>  _fields – кортеж, содержащий имена полей данного класса.  _make() строит объект City из итерируемого объекта; конструктор City(*delhi_ data) делает то же самое.  ._asdict() возвращает объект dict, построенный по именованному кортежу.  ._asdict() полезен для сериализации данных в формате JSON.182  Построители классов данных\n--- Страница 182 ---\nДо версии Python 3.7 включительно метод _asdict возвращал OrderedDict . Начиная с версии Python 3.8 он возвращает прос- той dict, и это хорошо, потому что теперь мы знаем, что поря- док вставки ключей сохраняется. Если вам обязательно нужен OrderedDict , то документация по _asdict рекомендует надстроить его над результатом: OrderedDict(x._asdict()) . Начиная с версии Python 3.7 namedtuple принимает чисто именованный аргу - мент defaults, предоставляющий итерируемый объект, содержащий N значений по умолчанию для каждого из N самых правых полей класса. В примере 5.6 по- казано, как определить именованный кортеж Coordinate со значением по умол- чанию для поля reference. Пример 5.6. Атрибуты и методы именованного кортежа (продолжение примера 5.5) >>> Coordinate = namedtuple('Coordinate', 'lat lon reference', defaults=['WGS84']) >>> Coordinate(0, 0) Coordinate(lat=0, lon=0, reference='WGS84') >>> Coordinate._field_defaults {'reference': 'WGS84'} В абзаце «Синтаксис предложения class» выше я упомянул, что проще ко- дировать методы, используя синтаксис класса, который поддерживается клас - сом typing.NamedTuple и декоратором @dataclass . В класс, созданный с помощью namedtuple , тоже можно добавить методы, но это хак. Если хаки вас не интересу - ют, можете пропустить следующую врезку. Вставка метода в класс, созданный с помощью namedtuple Вспомните, как мы строили класс Card в примере 1.1 главы 1: Card = collections .namedtuple('Card', ['rank', 'suit']) Затем я написал функцию spades_high для сортировки. Было бы хорошо ин- капсулировать ее логику в методе класса Card, но чтобы добавить spades_high в Card, не пользуясь возможностями предложения class, нужно прибегнуть к хаку: определить функцию, а затем присвоить ее атрибуту класса. В при- мере 5.7 показано, как это делается. Пример 5.7. frenchdeck.doctest: добавление атрибута класса и метода в Card, имено- ванный кортеж из примера «Колода карт на Python» >>> Card.suit_values = dict(spades=3, hearts=2, diamonds=1, clubs=0)  >>> def spades_high(card):  rank_value = FrenchDeck.ranks.index(card.rank) suit_value = card.suit_values[card.suit] return rank_value * len(card.suit_values) + suit_value >>> Card.overall_rank = spades_high  >>> lowest_card = Card('2', 'clubs') >>> highest_card = Card('A', 'spades') >>> lowest_card.overall_rank()  Классические именованные кортежи  183\n--- Страница 183 ---\n0 >>> highest_card.overall_rank() 51  Присоединить атрибут класса, содержащий достоинства для каждой масти.  Функция spades_high станет методом; первый аргумент необязательно на- зывать self. Ему все равно будет присвоена ссылка на объект, от имени ко- торого вызывался метод.  Присоединить функцию к классу Card как метод с именем overall_rank .  Работает! Для удобочитаемости и удобства сопровождения в будущем гораздо лучше помещать методы внутрь предложения class. Но и об этом приеме полезно знать – может пригодиться1. Это было небольшое отступление для демонстрации мощи динамического языка. Теперь перейдем к рассмотрению варианта typing.NamedTuple . типизир Ованные именОванные кОртежи Класс Coordinate с полем, имеющим значение по умолчанию, из примера 5.6 можно написать, воспользовавшись классом typing.NamedTuple , как показано в примере 5.8. Пример 5.8. typing_namedtuple/coordinates2.py from typing import NamedTuple class Coordinate(NamedTuple): lat: float  lon: float reference: str ='WGS84'   Каждое поле экземпляра должно быть аннотировано типом.  Поле экземпляра reference аннотировано типом и значением по умолчанию. Классы, построенные с помощью typing.NamedTuple , не имеют методов, помимо тех, что генерирует collections.namedtuple , а также унаследованных от tuple. Един- ственное различие – присутствие атрибута класса __annotations__ , который ин- терпретатор Python игнорирует во время выполнения. Поскольку основной отличительной особенностью typing.NamedTuple являют - ся аннотации типов, кратко рассмотрим их, прежде чем вернуться к изучению построителей классов данных. 1 Если вы знакомы с Ruby, то знаете, что внедрение методов – хорошо известный при- ем среди рубистов, однако отношение к нему неоднозначное. В Python он не так широко распространен, поскольку неприменим к встроенным типам: str, list и т. д. Я считаю это ограничение Python благословением.184  Построители классов данных\n--- Страница 184 ---\nкратк Ое введение в аннО тации типОв Аннотации типов – это способ объявить ожидаемые типы аргументов и воз- вращаемого значения функции, переменных и атрибутов. Первое, что нужно знать об аннотациях типов, – то, что ни компилятор байт- кода, ни интерпретатор Python их никак не контролируют. Это очень краткое введение в аннотации типов, его единствен- ная цель – чтобы вы поняли синтаксис и семантику аннотаций, используемых в объявлениях с применением typing.NamedTuple и @dataclass . Мы будем рассматривать аннотации типов для сигнатур функций в главе 8, а более сложные аннотации в гла- ве 15. Здесь же будут показаны в основном аннотации, в которых участ вуют простые встроенные типы, например str, int и float, но, откровенно говоря, именно ими чаще всего аннотируют поля классов данных. Никаких последствий во время выполнения Аннотации типов в Python правильнее всего рассматривать как «документа- цию, которая может быть проверена IDE и программами проверки типов». Дело в том, что аннотации типов не оказывают никакого влияния на поведе- ние Python-программ во время выполнения. Взгляните на пример 5.9. Пример 5.9. Python не проверяет аннотации типов во время выполнения >>> import typing >>> class Coordinate(typing.NamedTuple): lat: float lon: float >>> trash = Coordinate('Ni!', None) >>> print(trash) Coordinate(lat='Ni!', lon=None)   Я предупреждал: никаких проверок во время выполнения! Если вы оформите код из примера 5.9 в виде модуля Python, то при вы- полнении он выведет бессмысленные координаты, не выдав ни ошибки, ни предуп реждения: $ python3 nocheck_demo.py Coordinate(lat='Ni!', lon=None) Аннотации типов предназначены прежде всего для сторонних программ проверки типов, например Mypy (https://mypy.readthedocs.io/en/stable/) или ин- тегрированной среды разработки PyCharm (https://www.jetbrains.com/pycharm/) со встроенной проверкой типов. Это инструменты статического анализа: они проверяют «покоящийся» исходный код, а не код в процессе выполнения. Чтобы увидеть эффект от аннотаций типов, нужно применить какой-нибудь из этих инструментов к своему коду. Например, вот что говорит Mypy о преды- дущем примере: Краткое введение в аннотации типов  185\n--- Страница 185 ---\n$ mypy nocheck_demo.py nocheck_demo.py:8: error: Argument 1 to \"Coordinate\" has incompatible type \"str\"; expected \"float\" nocheck_demo.py:8: error: Argument 2 to \"Coordinate\" has incompatible type \"None\"; expected \"float\" Видя определение Coordinate , Mypy понимает, что оба аргумента конструк - тора должны иметь тип float, но при создании trash заданы аргументы типа str и None1. Теперь поговорим о синтаксисе и семантике аннотаций типов. Синтаксис аннотаций переменных И typing.NamedTuple , и @dataclass пользуются синтаксисом аннотаций переменных, определенным в документе PEP 526 (https://peps.python.org/pep-0526/). Ниже приведено краткое введение в этот синтаксис в контексте определения атри- бутов в предложениях class. Базовый синтаксис аннотации переменной имеет вид: var_name: some_type В разделе «Допустимые аннотации типов» документа PEP 484 (https:// peps.python.org/pep-0484/#acceptable-type-hints) объясняется, что такое допус- тимые типы, но в контексте определения класса данных наиболее полез- ными, скорее всего, будут следующие типы: конкретный класс, например str или FrenchDeck ; параметризованный тип коллекции, например list[int], tuple[str, float] и т. д.; typing.Optional , например Optional[str] , для объявления поля, которое мо- жет принимать значения типа str или None. Переменную можно также инициализировать значением. В объявлении с помощью typing.NamedTuple или @dataclass это значение станет значением соот - ветствующего атрибута по умолчанию, если для него не задан аргумент при вызове конструктора: var_name: some_type = a_value Семантика аннотаций переменных В разделе «Никаких последствий во время выполнения» мы видели, что анно- тации типов никак не влияют на происходящее на этапе выполнения. Но на этапе импорта, когда модель загружается, Python читает их и строит словарь __annotations__ , который typing.NamedTuple и @dataclass затем используют для допол- нения класса. Начнем это исследование с простого класса в примере 5.10, чтобы впослед- ствии можно было увидеть, что добавляют typing.NamedTuple и @dataclass . 1 В контексте аннотаций типов None – не синглтон типа NoneType, а псевдоним самого типа NoneType. Если задуматься, то это выглядит странно, но согласуется с нашей ин- туицией и заставляет функцию возвращать аннотации, которые проще читать в час- то встречающемся случае функций, возвращающих None. 186  Построители классов данных\n--- Страница 186 ---\nПример 5.10. meaning/demo_plain.py: простой класс с аннотациями типов class DemoPlainClass: a: int  b: float = 1.1  c = 'spam'   Для поля a заводится запись в __annotations__ , но больше оно никак не ис - пользуется: атрибут с именем a в классе не создается.  Поле b сохраняется в аннотациях и, кроме того, становится атрибутом клас - са со значением 1.1.  c – это самый обычный атрибут класса, а не аннотация. Все это можно проверить на консоли: сначала прочитаем атрибут __annotations__ класса DemoPlainClass , а затем попытаемся получить его атрибуты a, b и c: >>> from demo_plain import DemoPlainClass >>> DemoPlainClass.__annotations__ {'a': <class 'int'>, 'b': <class 'float'>} >>> DemoPlainClass.a Traceback (most recent call last): File \"<stdin>\", line 1, in <module> AttributeError: type object 'DemoPlainClass' has no attribute 'a' >>> DemoPlainClass.b 1.1 >>> DemoPlainClass.c 'spam' Отметим, что интерпретатор создает специальный атрибут __annotations__ , чтобы запомнить аннотации типов, встречающиеся в исходном коде, – даже в обычном классе. От поля a остается только аннотация. Оно не становится атрибутом клас - са, потому что с ним не связано никакое значение1. Поля b и c сохраняются в качест ве атрибутов класса, потому что с ними связаны значения. Ни один из этих трех атрибутов не присутствует в новом экземпляре класса DemoPlainClass . Если создать объект o = DemoPlainClass() , то o.a возбуждает исключе- ние AttributeError , тогда как o.b и o.c извлекают атрибуты класса со значениями 1.1 и 'spam' – обычное поведение объекта в Python. Инспекция typing.NamedTuple Теперь исследуем класс, построенный с помощью typing.NamedTuple (пример 5.11) с теми же атрибутами и аннотациями, что в DemoPlainClass из примера 5.10. Пример 5.11. meaning/demo_nt.py: класс, построенный с помощью typing.NamedTuple import typing class DemoNTClass(typing.NamedTuple): a: int  b: float = 1.1  c = 'spam'  1 В Python нет понятия undefined, одной из самых глупых ошибок, допущенных при проектировании JavaScript. Спасибо, Гвидо! Краткое введение в аннотации типов  187\n--- Страница 187 ---\n Для поля a заводится аннотация и атрибут экземпляра.  Для поля b также заводится аннотация, и оно также становится атрибутом экземпляра со значением по умолчанию 1.1.  c – самый обычный атрибут класса, никакая аннотация на него не ссылается. Инспекция DemoNTClass дает такие результаты: >>> from demo_nt import DemoNTClass >>> DemoNTClass.__annotations__ {'a': <class 'int'>, 'b': <class 'float'>} >>> DemoNTClass.a <_collections._tuplegetter object at 0x101f0f940> >>> DemoNTClass.b <_collections._tuplegetter object at 0x101f0f8b0> >>> DemoNTClass.c 'spam' Здесь для a и b аннотации такие же, как в примере 5.10. Но typing.NamedTuple создает атрибуты класса a и b. Атрибут c – обычный атрибут класса со значени- ем 'spam'. Атрибуты класса a и b являются дескрипторами; этот продвинутый меха- низм рассматривается в главе 23. Пока считайте, что это некий аналог методов чтения свойств (getter), который не нуждается в явном операторе вызова (), чтобы получить атрибут экземпляра. На практике это означает, что a и b будут работать как атрибуты экземпляра, допускающие только чтение, и это имеет смысл, если вспомнить, что экземпляры DemoNTClass – просто наделенные до- полнительными возможностями кортежи, а кортежи неизменяемы. DemoNTClass получает также строку документации: >>> DemoNTClass.__doc__ 'DemoNTClass(a, b)' Исследуем экземпляр DemoNTClass : >>> nt = DemoNTClass(8) >>> nt.a 8 >>> nt.b 1.1 >>> nt.c 'spam' Чтобы сконструировать nt, мы должны передать DemoNTClass как минимум ар- гумент a. Конструктор принимает также аргумент b, но у него есть значение по умолчанию 1.1, поэтому он необязателен. У объекта nt имеются атрибуты a и b, как и следовало ожидать; атрибута c у него нет, но Python берет его из класса, как обычно. Попытавшись присвоить значения атрибутам nt.a, nt.b, nt.c или даже nt.z, мы получим исключения AttributeError с несколько различающимися сообщениями об ошибках. Попробуйте сами и поразмыслите об этих сообщениях. Инспектирование класса с декоратором dataclass Теперь обратимся к примеру 5.12.188  Построители классов данных\n--- Страница 188 ---\nПример 5.12. meaning/demo_dc.py: класс с декоратором @dataclass from dataclasses import dataclass @dataclass class DemoDataClass: a: int  b: float = 1.1  c = 'spam'   Для поля a заводится аннотация, оно также становится атрибутом экземп- ляра, управляемым дескриптором.  Для поля b также заводится аннотация, и оно также становится атрибутом экземпляра с дескриптором и значением по умолчанию 1.1.  c – самый обычный атрибут класса, никакая аннотация на него не ссылается. Теперь посмотрим на атрибуты __annotations__ , __doc__ и a, b, c класса DemoDataClass : >>> from demo_dc import DemoDataClass >>> DemoDataClass.__annotations__ {'a': <class 'int'>, 'b': <class 'float'>} >>> DemoDataClass.__doc__ 'DemoDataClass(a: int, b: float = 1.1)' >>> DemoDataClass.a Traceback (most recent call last): File \"<stdin>\", line 1, in <module> AttributeError: type object 'DemoDataClass' has no attribute 'a' >>> DemoDataClass.b 1.1 >>> DemoDataClass.c 'spam' Атрибуты __annotations__ и __doc__ не таят никаких сюрпризов. Но атрибута с именем a в классе DemoDataClass нет – в отличие от DemoNTClass из примера 5.11, в котором имеется дескриптор для получения a из экземпляров в виде атри- бутов, допускающих только чтение (таинственный атрибут <_collections._ tuplegetter> ). Все объясняется тем, что атрибут a существует лишь в экземплярах DemoDataClass . Это будет открытый атрибут, который можно читать и записывать, если только класс не заморожен. С другой стороны, b и c являются атрибутами класса, причем b хранит значение по умолчанию для атрибута экземпляра b, а c – просто атрибут класса, который не будет связан с экземплярами. Полюбопытствуем, как выглядит экземпляр DemoDataClass : >>> dc = DemoDataClass(9) >>> dc.a 9 >>> dc.b 1.1 >>> dc.c 'spam' И снова a и b – атрибуты экземпляра, а c – атрибут класса, который мы полу - чаем через экземпляр. Как уже отмечалось, экземпляры DemoDataClass изменяемы – и никакой про- верки типов на этапе выполнения не производится. Краткое введение в аннотации типов  189\n--- Страница 189 ---\n>>> dc.a = 10 >>> dc.b = 'oops' Можно даже выполнить еще более глупые присваивания: >>> dc.c = 'whatever' >>> dc.z = 'secret stash' Теперь у экземпляра dc есть атрибут c, но присваивание ему не изменяет атрибут класса c. И можно добавить новый атрибут z. Это обычное поведение Python: у регулярных экземпляров могут быть собственные атрибуты, отсут - ствующие в классе1. еще О @dAtAclAss До сих пор мы видели только простые примеры использования @dataclass . Этот декоратор принимает несколько именованных аргументов. Вот его сигнатура: @dataclass(*, init=True, repr=True, eq=True, order=False, unsafe_hash=False, frozen=False) Символ * в первой позиции означает, что остальные параметры чисто име- нованные. Они описаны в табл. 5.2. Таблица 5.2. Именованные параметры, принимаемые декоратором @dataclass Параметр Семантика Значение по умолча- ниюПримечания init Сгенерировать __init__True Игнорируется, если __init__ реализован пользо- вателем repr Сгенерировать __repr__True Игнорируется, если __repr__ реализован пользо- вателем order Сгенерировать __lt__ , __le__ , __gt__ , __ge__False Если True, то возбуждает исключение, если eq=False или любой из подлежащих определению методов сравнения уже определен или унаследован unsafe_hash Сгенерировать __hash__False Сложная семантика и несколько подвохов; см. до- кументацию по dataclass (https://docs.python.org/3/ library/dataclasses.html#dataclasses.dataclass) frozen Делать экзем- пляры «неизме- няемыми»False Экземпляры будут в разумной степени защищены от случайного изменения, но не являются неизме- няемыми в полном смысле словаa a @dataclass эмулирует неизменяемость, генерируя методы __setattr__ и __delattr__ , кото - рые возбуждают исключение dataclass.FrozenInstanceError – подкласс AttributeError , – когда пользователь пытается изменить или удалить поле. Значения по умолчанию выбраны, исходя из полезности в типичных случа- ях. Изменять на противоположные, скорее всего, понадобится только значе- ния по умолчанию следующих аргументов: 1 Задание атрибута после __init__ сводит на нет оптимизацию памяти __dict__, свя- занную с разделением ключей (см. раздел «Практические последствия внутреннего устройства класса dict» главы 3).190  Построители классов данных\n--- Страница 190 ---\nfrozen=True Защищает экземпляры класса от непреднамеренного изменения. order=True Позволяет сортировать экземпляры класса данных. Учитывая динамическую природу объектов в Python, настырному про- граммисту не составит труда обойти защиту, предоставляемую аргументом frozen=True . Но такие трюки легко заметить во время рецензирования кода. Если оба аргумента, eq и frozen, равны True, то @dataclass порождает подходя- щий метод __hash__, так что экземпляры будут допускать хеширование. В сгене- рированном методе __hash__ будут использоваться данные из всех полей, кроме явно исключенных с помощью опции поля, которую мы рассмотрим в разделе «Опции полей» ниже. Если frozen=False (по умолчанию), то @dataclass установит атрибут __hash__ равным None, сигнализируя о том, что экземпляры не хешируе- мые, и тем самым отменив метод __hash__, унаследованный от суперкласса. В документе PEP 557 «Data Classes» об аргументе unsafe_hash сказано следующее: Хотя это и не рекомендуется, вы можете заставить класс данных создать метод __hash__, задав аргумент unsafe_hash=True . Такое бывает необходимо, если ваш класс логически неизменяемый, но тем не менее может быть изменен. Это очень специальный случай, нуждающийся в тщательном обдумывании. И это все, что я имею сказать о unsafe_hash . Если вам кажется, что без этой воз- можности не обойтись, почитайте документацию по dataclasses.dataclass (https:// docs.python.org/3/library/dataclasses.html#dataclasses.dataclass). Дальнейшая настройка сгенерированного класса данных производится на уровне полей. Опции полей С самой главной опцией поля мы уже знакомы: предоставлять (или не предо- ставлять) значение по умолчанию с аннотацией типа. Объявленные нами поля экземпляра становятся параметрами сгенерированного метода __init__. Python не позволяет задавать параметр без значения по умолчанию, если до него был задан хотя бы один параметр, имеющий значение по умолчанию. Поэтому если объявлено поле со значением по умолчанию, то и все последующие поля тоже должны иметь значения по умолчанию. Изменяемые значения по умолчанию – место, где начинающие програм- мисты на Python часто допускают ошибки. В определениях функций изме- няемое значение по умолчанию легко запортить, когда при каком-то одном обращении функция изменяет его, после чего изменяется поведение во всех последующих обращениях. Эту проблему мы будем рассматривать в разделе «Значения по умолчанию изменяемого типа: неудачная мысль» главы 6. Атри- буты классов часто используются как значения атрибутов по умолчанию для экземпляров, в т. ч. в классах данных. А декоратор @dataclass использует зна- чения по умолчанию в аннотациях типов, чтобы сгенерировать параметры со значениями по умолчанию для __init__. Для предотвращения ошибок @dataclass отвергает определение класса в примере 5.13. Еще о @dataclass  191\n--- Страница 191 ---\nПример 5.13. dataclass/club_wrong.py: э тот класс возбуждает исключение ValueError @dataclass class ClubMember: name: str guests: list = [] Попытавшись загрузить модуль с таким классом ClubMember , мы получим: $ python3 club_wrong.py Traceback (most recent call last): File \"club_wrong.py\", line 4, in <module> class ClubMember: несколько строк опущено ValueError: mutable default <class 'list'> for field guests is not allowed: use default_factory Сообщение в ValueError объясняет, в чем проблема, и предлагает решение: использовать default_factory . В примере 5.14 показано, как исправить класс ClubMember . Пример 5.14. dataclass/club.py: это определение ClubMember работает from dataclasses import dataclass, field @dataclass class ClubMember: name: str guests: list = field(default_factory=list) В поле guests в примере 5.14 мы вместо литерального списка задаем значе- ние по умолчанию путем вызова функции dataclasses.field с параметром default_ factory=list . Параметр default_factory позволяет указать функцию, класс или еще какой-то вызываемый объект, который будет вызываться без аргументов для построе- ния значения по умолчанию при каждом создании экземпляра класса данных. При таком подходе у каждого экземпляра ClubMember будет собственный список list, а не один list на всех, что редко является желаемым поведением и обычно свидетельствует об ошибке. Хорошо, что @dataclass отвергает определения классов со списком в качестве значения поля по умолчанию. Однако следует иметь в виду, что это частичное решение, применимое только к list, dict и set. Про другие изменяемые значения, использованные в качестве значений по умолчанию, @dataclass ничего не говорит. Вы сами должны понимать суть проблемы и пользоваться фабри- кой, когда нужно задать изменяемое значение по умолчанию. Покопавшись в документации по модулю dataclasses (https://docs.python.org/3/ library/dataclasses.html), вы наткнетесь на определение поля типа list с новым синтаксисом, показанным в примере 5.15. Пример 5.15. dataclass/club_generic.py: это определение ClubMember более точное from dataclasses import dataclass, field @dataclass 192  Построители классов данных\n--- Страница 192 ---\nclass ClubMember: name: str guests: list[str] = field(default_factory=list)   list[str] означает «список объектов типа str». Новый синтаксис list[str] – это параметризованный обобщенный тип: на- чиная с версии Python 3.9 встроенный тип list допускает задание типа элемен- тов списка в квадратных скобках. До Python 3.9 встроенные коллекции не поддерживали нотацию обобщенного типа. В качестве временного обходного решения в модуле typing имеются соответствующие типы коллекций. Если в версии Python 3.8 или более ранней вам нужен был тип пара- метризованного списка, то следовало импортировать тип List из typing и пользоваться им: List[str] . Дополнительные сведе- ния на эту тему см. во врезке «Поддержка унаследованных типов и нерекомендуемые типы коллекций» в главе 8. Обобщенные типы мы будем рассматривать в главе 8. А пока заметим, что оба примера, 5.14 и 5.15, правильны и программа проверки типов Mypy не ру - гается ни на одно из этих определений класса. Разница в том, что guests: list означает, что guests может быть списком объ- ектов любого типа, а guests: list[str] говорит, что guests должно быть списком строк. Это позволяет программе проверки типов находить некоторые ошибки в коде, пытающемся поместить недопустимые элементы в список или прочи- тать то, чего в списке не может быть. default_factory – пожалуй, самая часто используемая опция функции field, но есть и другие. Все они перечислены в табл. 5.3. Таблица 5.3. Именованные аргументы, принимаемые функцией field Опция Семантика Значение по умолчанию default Значение поля по умолчанию _MISSING_TYPEa default_factory Функция без параметров, порождающая значение по умолчанию_MISSING_TYPE init Включить поле в состав параметров __init__ True repr Включить поле в __repr__ True compare Использовать поле в методах сравнения __eq__ , __lt__ и т. д.True hash Включить поле в вычисление __hash__ Noneb metadata Отображение, содержащее пользовательские данные; игнорируется @dataclassNone a dataclass._MISSING_TYPE – это специальное значение, означающее, что опция не задана. Существует для того, чтобы можно было задать None в качестве фактического значения по умолчанию, как часто бывает. b Опция hash=None означает, что поле будет использоваться при вычислении __hash__ , только если compare=True . Еще о @dataclass  193\n--- Страница 193 ---\nОпция default существует, потому что обращение к field заменяет значение по умолчанию в аннотации поля. Если мы хотим создать поле athlete со значением по умолчанию False, но не включать это поле в метод __repr__, то должны будем написать такое определение: @dataclass class ClubMember: name: str guests: list = field(default_factory=list) athlete: bool = field(default=False, repr=False) Постинициализация Метод __init__, генерируемый декоратором @dataclass, принимает только передан- ные аргументы и присваивает их (или их значения по умолчанию в случае отсут - ствия) атрибутам экземпляра, которые являются полями экземпляра. Но иногда инициализировать экземпляр недостаточно. В таком случае можно предоставить метод __post_init__ . Если он существует, то @dataclass добавляет в сгенерированный метод __init__ обращение к __post_init__ в качестве последнего шага. Типичные сценарии использования __post_init__ – проверка и вычисление значений полей на основе других полей. Мы изучим простые примеры при- менения __post_init__ по обеим причинам. Сначала рассмотрим ожидаемое поведение подкласса HackerClubMember класса ClubMember , поведение которого описывается тестами в примере 5.16. Пример 5.16. dataclass/hackerclub.py: тесты для HackerClubMember «»» ``HackerClubMember`` объект принимает необязательный аргумент ``handle``:: >>> anna = HackerClubMember('Anna Ravenscroft', handle='AnnaRaven') >>> anna HackerClubMember(name='Anna Ravenscroft', guests=[], handle='AnnaRaven') Если ``handle`` опущен, то берется первая часть имени члена:: >>> leo = HackerClubMember('Leo Rochael') >>> leo HackerClubMember(name='Leo Rochael', guests=[], handle='Leo') Члены должны иметь уникальный описатель. Следующий объект ``leo2`` не будет создан потому, что его описатель ``handle`` был бы равен 'Leo', но этот описатель уже сопоставлен ``leo``:: >>> leo2 = HackerClubMember('Leo DaVinci') Traceback (most recent call last): ValueError: handle 'Leo' already exists. Чтобы исправить эту ошибку, ``leo2`` необходимо создать с явным описателем:: >>> leo2 = HackerClubMember('Leo Dainci', handle='Neo') >>> leo2 HackerClubMember(name='Leo DaVinci', guests=[], handle='Neo') \"\"\"194  Построители классов данных\n--- Страница 194 ---\nЗаметим, что задавать handle следует в виде именованного аргумента, пото- му что HackerClubMember наследует name и guests от ClubMember и добавляет поле handle. Сгенерированная строка документации для HackerClubMember показывает поря- док полей при вызове конструктора: >>> HackerClubMember.__doc__ \"HackerClubMember(name: str, guests: list = <factory>, handle: str = '')\" Здесь <factory> – короткий способ сказать, что некоторый вызываемый объ- ект порождает значение по умолчанию для guests (в нашем случае фабрика – это класс list). Мораль: чтобы задать handle, но не задавать guests, мы должны передать handle в качестве именованного аргумента. В разделе «Наследование» документации по модулю dataclasses (https:// docs.python.org/3/library/dataclasses.html#inheritance) объясняется, как вычисля- ется порядок полей при наличии нескольких уровней наследования. В главе 14 мы будем говорить о неправильном использовании наследования, особенно когда суперклассы не являются аб- страктными. Создавать иерархию классов обычно не рекомен- дуется, но тут это сослужило нам добрую службу, позволив со- кратить пример 5.17 и сосредоточиться на объявлении поля handle и проверке в методе __post_init__ . В примере 5.17 показана реализация. Пример 5.17. dataclass/hackerclub.py: код класса HackerClubMember from dataclasses import dataclass from club import ClubMember @dataclass class HackerClubMember(ClubMember):  all_handles = set()  handle: str = ''  def __post_init__(self): cls = self.__class__  if self.handle == '':  self.handle = self.name.split()[0] if self.handle in cls.all_handles:  msg = f'handle {self.handle!r} already exists.' raise ValueError(msg) cls.all_handles.add(self.handle)   HackerClubMember расширяет ClubMember .  all_handles – атрибут класса.  handle – поле экземпляра, имеющее тип str и по умолчанию равное пустой строке; это делает его факультативным.  Получить класс экземпляра.  Если self.handle – пустая строка, положить ее равной первой части name.  Если self.handle уже присутствует в cls.all_handles , возбудить исключение ValueError .  Добавить новый handle в cls.all_handles . Еще о @dataclass  195\n--- Страница 195 ---\nПример 5.17 работает, как и ожидается, но программа статической проверки типов с ним не справится. Далее мы объясним, почему и как это исправить. Типизированные атрибуты класса Если проверить пример 5.17 с помощью Mypy, то мы получим сообщение об ошибке: $ mypy hackerclub.py hackerclub.py:37: error: Need type annotation for «all_handles» (hint: «all_handles: Set[<type>] = ») Found 1 error in 1 file (checked 1 source file) К сожалению, решение, предлагаемое Mypy (когда я писал этот раздел, те- кущей версией была 0.910), бесполезно в контексте применения @dataclass . Во-первых, предлагается использовать Set, но я работаю с Python 3.9, поэтому могу применить set – и избежать импорта класса Set из модуля typing. Но важнее другое – если добавить аннотацию вида set[…] к all_handles , то @dataclass увидит ее и сделает all_handles атрибутом экземпляра. К чему это приводит, мы видели в разделе «Инспектирование класса с декоратором dataclass» выше. Обходной путь, описанный в документе PEP 526 «Syntax for Variable Annotations» (https://peps.python.org/pep-0526/#class-and-instance-variable-annotations), никак не назовешь элегантным. Чтобы завести переменную класса с аннотацией типа, мы должны использовать псевдотип typing.ClassVar , в котором применяет - ся нотация обобщенных типов [], дабы задать тип переменной и одновременно объявить ее атрибутом класса. Чтобы удовлетворить программу проверки типов и декоратор @dataclass , предлагается объявить all_handles в примере 5.17 следующим образом: all_handles: ClassVar[set[str]] = set() Вот что означает эта аннотация типа: all_handles – атрибут типа set-of-str , для которого значением по умолча- нию является пустое множество. Чтобы закодировать эту аннотацию, мы должны импортировать ClassVar из модуля typing. Декоратору @dataclass безразличны типы в аннотациях, за исключением двух случаев. Один из них такой: если тип атрибута равен ClassVar, то для него не ге- нерируется поле экземпляра. Второй случай, когда тип поля имеет значение для @dataclass , – объявление пе- ременных только для инициализации. Мы рассмотрим его в следующем разделе. Инициализируемые переменные, не являющиеся полями Иногда возникает необходимость передать __init__ аргументы, не являющие- ся полями экземпляра. В документации по dataclasses (https://docs.python.org/3/ library/dataclasses.html#init-only-variables) они называются переменными только для инициализации. Для объявления такого аргумента модуль dataclasses предо- ставляет псевдотип InitVar, в котором используется тот же синтаксис, что и в typing.ClassVar . В документации приведен пример – класс данных, в котором 196  Построители классов данных\n--- Страница 196 ---\nимеется поле, инициализируемое из базы данных, поэтому конструктору не- обходимо передать объект базы данных. В примере 5.18 показан код, иллюстрирующий использование переменных только для инициализации. Пример 5.18. Пример из документации по модулю dataclasses @dataclass class C: i: int j: int = None database: InitVar[DatabaseType] = None def __post_init__(self, database): if self.j is None and database is not None: self.j = database.lookup('j') c = C(10, database=my_database) Обратите внимание, как объявлен атрибут database. InitVar не дает декоратору @dataclass обращаться с database как с обычным полем. Он не будет создавать для него атрибут экземпляра, а функция dataclasses.fields не включит его в список полей. Однако database станет одним из аргументов, принимаемых сгенериро- ванным __init__, и будет передаваться методу __post_init__ . Если вы будете пи- сать этот метод, то должны добавить соответствующий аргумент в его сигнату - ру, как показано в примере 5.18. В этом довольно пространном обзоре декоратора @dataclass мы остановились на наиболее полезных средствах. Некоторые из них уже были упомянуты в предыду - щих разделах, например «Основные возможности», где параллельно рассматри- вались все три построителя классов данных. Полное изложение смотрите в доку - ментации по dataclasses и в документе PEP 526 «Syntax for Variable Annotations». В следующем разделе я представлю более длинный пример использования @dataclass . Пример использования @dataclass: запись о ресурсе из дублинского ядра Часто классы, построенные с помощью @dataclass , включают больше полей, чем во встречавшихся до сих пор коротеньких примерах. Дублинское ядро (https:// www.dublincore.org/specifications/dublin-core/) дает материал для более представи- тельного примера использования @dataclass . Схема дублинского ядра – это небольшой набор словарных терминов, ко- торые можно использовать для описания цифровых ресурсов (видео, изо- бражений, веб-страниц и т. д.), а также физических ресурсов: книг, ком- пакт-дисков и предметов искусства1. – Дублинское ядро в Википедии В стандарте определено 15 факультативных полей, в классе Resource из при- мера 5.19 используются восемь из них. 1 Источник: статья о дублинском ядре в Википедии (https://en.wikipedia.org/wiki/Dublin_Core). Еще о @dataclass  197\n--- Страница 197 ---\nПример 5.19. dataclass/resource.py: код класса Resource, основанного на схеме дублин- ского ядра from dataclasses import dataclass, field from typing import Optional from enum import Enum, auto from datetime import date class ResourceType(Enum):  BOOK = auto() EBOOK = auto() VIDEO = auto() @dataclass class Resource: \"\"\" Описание мультимедийного ресурса.\"\"\" identifier: str  title: str = '<untitled>'  creators: list[str] = field(default_factory=list) date: Optional[date] = None  type: ResourceType = ResourceType.BOOK  description: str = '' language: str = '' subjects: list[str] = field(default_factory=list)  Это перечисление Enum содержит допустимые значения поля Resource.type .  identifier – единственное обязательное поле.  title – первое поле со значением по умолчанию. Это значит, что все после- дующие поля тоже должны иметь значения по умолчанию.  Значение date может быть экземпляром datetime.date или None.  Для поля type значением по умолчанию является ResourceType.BOOK . В примере 5.20 приведен тест, показывающий, как запись типа Resource долж - на использоваться в коде. Пример 5.20. Тест класса Resource >>> description = 'Improving the design of existing code' >>> book = Resource('978-0-13-475759-9', 'Refactoring, 2nd Edition', ['Martin Fowler', 'Kent Beck'], date(2018, 11, 19), ResourceType.BOOK, description, 'EN', ['computer programming', 'OOP']) >>> book # doctest: +NORMALIZE_WHITESPACE Resource(identifier='978-0-13-475759-9', title='Refactoring, 2nd Edition', creators=['Martin Fowler', 'Kent Beck'], date=datetime.date(2018, 11, 19), type=<ResourceType.BOOK: 1>, description='Improving the design of existing code', language='EN', subjects=['computer programming', 'OOP']) Метод __repr__, сгенерированный @dataclass , годится, но можно сделать пред- ставление более удобочитаемым. Вот какого формата мы ждем от repr(book) : >>> book # doctest: +NORMALIZE_WHITESPACE Resource( identifier = '978-0-13-475759-9',198  Построители классов данных\n--- Страница 198 ---\ntitle = 'Refactoring, 2nd Edition', creators = ['Martin Fowler', 'Kent Beck'], date = datetime.date(2018, 11, 19), type = <ResourceType.BOOK: 1>, description = 'Improving the design of existing code', language = 'EN', subjects = ['computer programming', 'OOP'], ) В примере 5.21 приведен код __repr__, порождающий такой формат. Здесь ис- пользуется функция dataclass.fields , которая возвращает имена всех полей клас - са данных. Пример 5.21. dataclass/resource_repr.py: код метода __repr__, реализованного в классе Resource из примера 5.19 def __repr__(self): cls = self.__class__ cls_name = cls.__name__ indent = ' ' * 4 res = [f'{cls_name}(']  for f in fields(cls):  value = getattr(self, f.name)  res.append(f'{indent}{f.name} = {value!r},')  res.append(')')  return '\\n'.join(res)   Начать список res для построения выходной строки. Включить имя класса и открывающую скобку.  Для каждого поля f класса …  … получить именованный атрибут из экземпляра.  Дописать в конец начинающуюся отступом строку, содержащую имя поля и repr(value) , – именно это делает !r.  Дописать закрывающую скобку.  Построить по res многострочную строку и вернуть ее. Этим примером мы завершаем знакомство с построителями классов дан- ных в Python. Классы данных удобны, но если использовать их неумеренно, проект может пострадать. В следующем разделе объясняется, в чем проблема. клаСС данных как признак кОда С душк Ом Не важно, пишете вы код класса данных самостоятельно или пользуетесь од- ним из описанных выше построителей классов, необходимо понимать, что само его наличие может быть индикатором проблемы в дизайне. Во втором издании книги «Рефакторинг»1 Мартин Фаулер и Кент Бек пред- ставили каталог примеров «дурно пахнущего кода» – паттернов, которые ука- зывают на необходимость рефакторинга. Раздел, озаглавленный «Класс дан- ных», начинается так: 1 М. Фаулер, К. Бек. Рефакторинг. Диалектика-Вильямс, 2019. Класс данных как признак кода с душком  199\n--- Страница 199 ---\nЭто классы, в которых имеются поля, методы чтения и записи этих по- лей и больше ничего. Такие классы – тупые хранители данных, и зачастую другие классы манипулируют ими, вникая в слишком большое число де- талей. На персональном сайте Фаулера имеется статья «Code Smell» (https:// martinfowler.com/bliki/CodeSmell.html), проясняющая эту точку зрения. Она имеет непосредственное отношение к нашему обсуждению, потому что класс данных используется как один из примеров кода с душком и даются рекомендации, что с этим делать. Приведу полный текст статьи1. Код с душком Мартин Фаулер Код с душком (code smell) – это видимый признак, который обычно соответ - ствует более глубокой проблеме в системе. Термин предложил Кент Бек, по- могавший мне при написании книги «Рефакторинг» (https://martinfowler.com/ books/refactoring.html). Данное выше краткое определение содержит два тонких момента. Во-первых, душок, по определению, – нечто такое, что легко обнаружить, или унюхать, как я с недавних пор стал это называть. Длинный метод – прекрасный при- мер; стоит мне увидеть, что в методе на Java больше дюжины строк, как нос тут же начинается чесаться. Второй момент – душок необязательно является верным признаком пробле- мы. Иногда длинный метод – это нормально. Нужно заглянуть глубже и по- нять, действительно ли проблема существует, – запахи сами по себе не плохи, они являются индикатором проблемы, а не самой проблемой. Самые лучшие запахи – те, что легко обнаружить, и, как правило, они сви- детельствуют о по-настоящему интересных проблемах. Классы данных (со- держащие только данные и никакого поведения) могут служить отличным примером. Мы смотрим на них и задаемся вопросом, какого поведения здесь не хватает. А потом приступаем к рефакторингу, чтобы перенести нужное поведение в класс. Часто простые вопросы и начальный рефакторинг могут стать важным шагом на пути превращения анемичных объектов в нечто, за- служивающее называться классом. У кода с душком есть полезная черта – его может выявить даже неопытный человек, не имеющий достаточно знаний, чтобы понять, существует ли ре- альная проблема и как ее исправить. Я слышал о руководителях группы, ко- торые выбирали «душок недели» и просили коллег поискать код с таким душ- ком и представить его на рассмотрение старших членов группы. Разбираться с одним душком за раз – отличный способ постепенно обучать членов группы навыкам хорошего программирования. Основная идея объектно-ориентированного программирования – собрать данные и поведение в одной единице кода: классе. Если класс широко исполь- зуется, но не имеет собственного поведения, то может статься, что код, рабо- тающий с его экземплярами, разбросан (и даже дублируется) по разным мето- 1 Мне повезло работать вместе с Мартином Фаулером в компании Thoughtworks, так что на получение разрешения ушло всего 20 минут.200  Построители классов данных\n--- Страница 200 ---\nдам и функциям. А это неизбежно ведет к трудностям на этапе сопровождения. Поэтому рефакторинг, предлагаемый Фаулером в отношении классов данных, призван вернуть ему положенные обязанности. С учетом сказанного все же имеется два типичных сценария, когда имеет смысл завести класс данных, обделенный поведением. Класс данных как временная конструкция В этом случае класс данных является начальной упрощенной реализацией не- которого класса, необходимой, чтобы приступить к работе над новым проектом или модулем. Со временем класс получит собственные методы и перестанет по- лагаться на методы других классов для работы со своими экземплярами. Это можно сравнить со строительными лесами – они временные, а в конечном итоге класс, возможно, перестанет зависеть от построителя, с которого все начиналось. Кроме того, Python нередко используется для быстрого решения задачи и экспериментов, и тогда можно оставить временную конструкцию навсегда. Класс данных как промежуточное представление Класс данных может быть полезен и для построения записей, которые впо- следствии экспортируются в формате JSON или еще каком-то формате обмена данными, либо для хранения только что импортированных данных, пересе- кающих какие-то границы внутри системы. Все построители классов данных в Python предоставляют метод или функцию для преобразования экземпляра в простой словарь dict. Кроме того, всегда можно вызвать конструктор, передав ему словарь именованных аргументов, расширяемый с помощью оператора **. Такой словарь очень близок к записи в формате JSON. В этом случае к экземплярам класса данных следует относиться как к неиз- меняемым объектам; даже если поля изменяемые, все равно не следует изме- нять их, пока они пребывают в такой промежуточной форме. Если вы не после- дуете этому совету, то потеряете главное преимущество от размещения данных и поведения в одном месте. Если при импорте или экспорте необходимо изме- нять значения, то следует реализовать собственные методы построителя, не ис - пользуя ни предлагаемые методы типа «as dict», ни стандартные конструкторы. Теперь сменим тему и посмотрим, как писать образцы, с которыми можно сопоставлять экземпляры произвольных классов, а не только последователь- ности и отображения, о которых мы говорили в разделах «Сопоставление с по- следовательностями-образцами» и «Сопоставление с отображениями-образ- цами» главы 3. СОпОС тавление С экземплярами клаССОв – ОБразцами Классы-образцы предназначены для сопоставления с экземплярами классов по типу и факультативно по атрибутам. Субъектом класса-образца может быть экземпляр любого класса, а не только класса данных1. 1 Я поместил этот материал сюда, потому что это первая из глав, где речь идет о пользо- вательских классах, и подумал, что тема сопоставления с классами-образцами настоль- ко важна, что не стоит откладывать ее до второй части книги. Я руководствуюсь следу - ющим принципом: важнее знать, как использовать классы, чем как их определять. Сопоставление с экземплярами классов – образцами  201\n--- Страница 201 ---\nСуществует три вида классов-образцов: простой, именованный и позици- онный. Мы рассмотрим их в этом порядке. Простые классы-образцы В разделе «Сопоставление с последовательностями-образцами» мы уже виде- ли, как простые классы-образцы используются в качестве подобразцов: case [str(name), _, _, (float(lat), float(lon))]: С этим образцом сопоставляется четырехэлементная последовательность, в которой первый элемент должен быть экземпляром класса str, а последний – 2-кортежем, содержащим два экземпляра float. Синтаксически классы-образцы выглядят как вызов конструктора. Ниже показан класс-образец, с которым сопоставляются значения float без свя- зывания с переменной (в теле case можно при необходимости ссылаться на x напрямую): match x: case float(): do_something_with(x) Но следующий пример, скорее всего, содержит ошибку: match x: case float: # ОПАСНО!!! do_something_with(x) В этом примере case float: сопоставляется с любым субъектом, потому что Python рассматривает float как переменную, которая затем связывается с субъ- ектом. Синтаксис простого образца float(x) – специальный случай, применимый толь- ко к девяти получившим особое благословение встроенным типам, перечис - ленным в конце раздела «Class Patterns» (https://peps.python.org/pep-0634/#class- patterns) документа PEP 634 «Structural Pattern Matching: Specification»: bytes dict float frozenset int list set str tuple В этих классах переменная, которая выглядит как аргумент конструкто- ра, например x в float(x), связывается со всем экземпляром субъекта или его частью, которая сопоставляется с подобразцом, как продемонстрировано в рассмотренном ранее примере сопоставления с последовательностью-об- разцом: case [str(name), _, _, (float(lat), float(lon))]: Если класс не является одним из этих привилегированных встроенных клас - сов, то похожие на аргумент переменные представляют образцы, с которыми должны сопоставляться атрибуты экземпляра класса. Именованные классы-образцы Чтобы понять, как используются именованные классы-образцы, рассмотрим следующий класс City и пять его экземпляров в примере 5.22.202  Построители классов данных\n--- Страница 202 ---\nПример 5.22. Класс City и несколько его экземпляров import typing class City(typing.NamedTuple): continent: str name: str country: str cities = [ City('Asia', 'Tokyo', 'JP'), City('Asia', 'Delhi', 'IN'), City('North America', 'Mexico City', 'MX'), City('North America', 'New York', 'US'), City('South America', 'São Paulo', 'BR'), ] При таких определениях следующая функция вернет список азиатских го- родов: def match_asian_cities(): results = [] for city in cities: match city: case City(continent='Asia'): results.append(city) return results С образцом City(continent='Asia') сопоставляется любой экземпляр City, в ко - тором значение атрибута continent равно 'Asia', вне зависимости от значений других атрибутов. Чтобы собрать в коллекцию значения атрибута country, можно было бы на- писать: def match_asian_countries(): results = [] for city in cities: match city: case City(continent='Asia', country=cc): results.append(cc) return results С образцом City(continent='Asia', country=cc) сопоставляются те же азиатские города, что и раньше, но теперь переменная cc связана с атрибутом country каж- дого экземпляра. Это работает и тогда, когда переменная-образец тоже назы- вается country: match city: case City(continent='Asia', country=country): results.append(country) Именованные классы-образцы прекрасно воспринимаются на глаз и рабо- тают с любым классом, имеющим открытые атрибуты экземпляра. Но они не- сколько многословны. Позиционные классы-образцы в некоторых случаях более удобны, но тре- буют явной поддержки со стороны класса субъекта, как будет показано ниже. Сопоставление с экземплярами классов – образцами  203\n--- Страница 203 ---\nПозиционные классы-образцы При тех же определениях, что в примере 5.22, следующая функция вернет спи- сок азиатских городов, только сопоставление производится с позиционным классом-образцом: def match_asian_cities_pos(): results = [] for city in cities: match city: case City('Asia'): results.append(city) return results С образцом City('Asia') сопоставляется любой экземпляр City, в котором пер- вый атрибут равен 'Asia', вне зависимости от значений других атрибутов. Чтобы собрать в коллекцию значения атрибута country, можно было бы на- писать: def match_asian_countries_pos(): results = [] for city in cities: match city: case City('Asia', _, country): results.append(country) return results С образцом City('Asia', _, country) сопоставляются те же города, что и раньше, но теперь переменная country связана с третьим атрибутом экземпляра. Я сказал «первый атрибут», «третий атрибут», но что это в действительности означает? Класс City или любой другой класс может работать с позиционными образ- цами, только если в нем присутствует специальный атрибут класса с именем __match_args__ , который автоматически создают построители классов, рассмат- риваемые в этой главе. Вот как выглядит атрибут __match_args__ в классе City: >>> City.__match_args__ ('continent', 'name', 'country') Как видите, __match_args__ объявляет имена атрибутов в том порядке, в кото- ром они будут использоваться в позиционных образцах. В разделе «Поддержка сопоставления с позиционными образцами» главы 11 мы напишем код, в котором атрибут класса __match_args__ создается без участия построителя классов. Можно сочетать именованные и позиционные аргументы в од- ном образце. Можно включать в __match_args__ не все атрибуты экземпляра. Поэтому иногда мы просто вынуждены использо- вать в образце именованные аргументы в дополнение к пози- ционным. Пришло время подводить итоги. 204  Построители классов данных\n--- Страница 204 ---\nрезюме Основной темой этой главы были построители классов данных collections. namedtuple , typing.NamedTuple и dataclasses.dataclass . Мы видели, что каждый из них генерирует классы данных по описаниям, предоставленным в виде аргумен- тов фабричной функции, или по предложениям class с аннотациями типов в последних двух случаях. В частности, оба варианта на основе именованных кортежей порождают подклассы tuple, добавляя лишь возможность обращаться к полям по имени и предоставление атрибута класса _fields, в котором имена полей перечисляются в виде кортежа строк. Затем мы сравнили основные возможности всех трех построителей классов, в частности как извлекать данные экземпляра в виде словаря, как получать имена полей и их значения по умолчанию и как создавать новый экземпляр из существующего. Это стало предлогом для первого знакомства с аннотациями типов, особен- но с теми, что применяются для аннотирования атрибутов в предложении class с использованием нотации, предложенной в документе PEP 526 «Syntax for Variable Annotations» (https://peps.python.org/pep-0526/) и впервые реализован- ной в версии Python 3.6. Быть может, самый удивительный аспект аннотаций типов вообще – тот факт, что они не оказывают никакого влияния на этапе выполнения. Python остается динамическим языком. Чтобы воспользоваться преимуществами информации о типах для обнаружения ошибок путем ста- тического анализа исходного кода, необходимы внешние инструменты, на- пример Mypy. После краткого обзора синтаксиса, описанного в PEP 526, мы перешли к изучению аннотаций в обычном классе и в классах, построенных с помощью typing.NamedTuple и @dataclass . Затем рассмотрели наиболее востребованные средства декоратора @dataclass и опцию default_factory функции dataclasses.field . Мы также уделили внимание аннотациям специальных псевдотипов typing.ClassVar и dataclasses.InitVar , кото - рые важны в контексте классов данных. Изложение основного предмета гла- вы завершилось примером на основе схемы дублинского ядра, что позволило проиллюстрировать использование dataclasses.fields для перебора атрибутов эк- земпляра Resource в пользовательском методе __repr__. Далее мы предостерегли от возможного злоупотребления классами данных, нарушающего принцип объектно-ориентированного программирования: данные и работающие с ними функции должны находиться в одном и том же классе. Классы, не содержащие никакой логики, могут быть признаком того, что логика помещена не туда, где должна быть. В последнем разделе мы видели, как сопоставление с образцом работает, когда субъект является экземпляром произвольного класса, а не только класса, порожденного рассмотренными в этой главе построителями. дОпО лнительная литература Стандартная документация Python по построителям классов данных написана очень хорошо и содержит немало небольших примеров. Дополнительная литература  205\n--- Страница 205 ---\nВ частности, что касается декоратора @dataclass, в документацию по модулю dataclasses (https://docs.python.org/3/library/dataclasses.html) скопирована бóльшая часть документа PEP 557 «Data Classes» (https://peps.python.org/pep-0557/). Но в этом документе имеется несколько весьма информативных разделов, которые не были скопированы, в т. ч. «Why not just use namedtuple?» (Почему бы просто не использовать именованный кортеж), «Why not just use typing.NamedTuple?» (Почему бы просто не использовать typing.NamedTuple) и «Rationale» (Обосно- вание). Последний заканчивается таким вопросом и ответом на него: Когда не стоит использовать классы данных? Требуется совместимость API с кортежами или словарями. Требуется про- верка типов, выходящая за рамки документов PEP 484 и 526, либо провер- ка или преобразование значений. – Eric V. Smith, PEP 557 «Rationale» На сайте RealPython.com Гейр Арне Ньелле (Geir Arne Hjelle) написал очень полное «Пособие по классам данных в Python 3.7» (https://realpython.com/python- data-classes/). На конференции PyCon US 2018 Раймонд Хэттингер провел презентацию «Dataclasses: The code generator to end all code generators» (https://www.youtube. com/watch?v=T-TwcmT6Rcw). Если говорить о дополнительных возможностях и продвинутой функцио- нальности, включая проверку, то несколькими годами ранее dataclasses появил- ся проект attrs (https://www.attrs.org/en/stable/) под руководством Хинека Шлава- ка, который обещает «вернуть радость написания классов, освободив автора от рутины реализации объектных протоколов (они же dunder-методы)». Эрик В. Смит, автор документа PEP 557, признает влияние проекта attrs на дизайн декоратора @dataclass . Возможно, это относится и к самому важному решению Смита относительно API: использовать для решения задачи декоратор класса вместо базового класса и (или) метакласса. Глиф (Glyph), основатель проекта Twisted, написал великолепное введение в attrs в статье «The One Python Library Everyone Needs» (https://glyph.twistedmatrix. com/2016/08/attrs.html). Документация по проекту attrs содержит обсуждение альтернатив (https://www.attrs.org/en/stable/why.html). Автор книг, преподаватель и одержимый ученый-компьютерщик Дэйв Бизли написал cluegen ( https://github.com/dabeaz/cluegen), еще один генератор классов дан- ных. Если вы слушали какие-нибудь презентации Дэйва, то знаете, что он боль- шой и убежденный мастер метапрограммирования на Python. Поэтому для меня источником вдохновения стали изложенные в файле README.md мысли о кон- кретном сценарии, который побудил его написать альтернативу имеющемуся в Python декоратору @dataclass, и его философия предоставления подхода к реше- нию задачи в противоположность инструменту: поначалу может показаться, что использовать инструмент быстрее, но подход обладает большей гибкостью и мо- жет доставить вас настолько далеко, насколько вы расположены идти. Что касается отношения к классу данных как к коду с душком, то лучший из известных мне источников – второе издание книги Мартина Фаулера «Рефак - торинг». В этом последнем издании отсутствует цитата, вынесенная в эпиграф к этой главе: «Классы данных – как дети…», но в остальном это лучшее издание 206  Построители классов данных\n--- Страница 206 ---\nсамой знаменитой книги Фаулера, особенно для питонистов, поскольку при- меры написаны на современном JavaScript, который ближе к Python, чем Java – язык, использованный в первом издании. На сайте Refactoring Guru также имеется описание душка, распространяемо- го кодом классов данных (https://refactoring.guru/smells/data-class). Поговорим В глоссарии на сайте The Jargon File статья «Guido» (https://web.archive.org/web/ 20190204130328/http://catb.org/esr/jargon/html/G/Guido.html) посвящена Гвидо ван Россуму. Среди прочего в ней есть такие слова: Есть поверье, что самым важным атрибутом Гвидо, если не считать само- го Python, является его машина времени, которой, говорят, он обладает, потому что снова и снова на запросы пользователей о новых возможно- стях следует ответ «А я как раз вчера вечерком это реализовал…». Очень долго в синтаксисе Python не было одной важной части – быстрого и стандартного способа создавать атрибуты экземпляров в классе. Во многих объектно-ориентированных языках такая возможность была. Вот часть опре- деления класса Point в Smalltalk: Object subclass: #Point instanceVariableNames: 'x y' classVariableNames: '' package: 'Kernel-BasicObjects' Во второй строке перечисляются имена атрибутов экземпляра x и y. Если бы это были атрибуты класса, то они находились бы в третьей строке. Python всегда предлагал простой способ объявления атрибутов класса, име- ющих начальное значение. Но атрибуты экземпляра встречаются куда чаще, и программисты были вынуждены заглядывать в метод __init__, чтобы найти их, постоянно опасаясь, нет ли еще каких-то атрибутов, определенных в другом месте класса или даже внешними функциями или методами других классов. А теперь у нас есть @dataclass , ура! Но вместе с ним пришли новые проблемы. Во-первых, если используется @dataclass , то аннотации типов перестают быть факультативными. Последние семь лет, с момента выхода документа PEP 484 «Type Hints» (https://peps.python.org/pep-0484/), нам обещали, что аннотации всегда будут необязательными. А теперь мы имеем важное новое средство языка, которое без них работать не может. Если вам не нравится весь этот уклон в сторону статической типизации, то можете вместо этого пользовать- ся attrs (https://www.attrs.org/en/stable/). Во-вторых, синтаксис, предлагаемый в PEP 526 для аннотирования атрибутов класса и экземпляра, выворачивает наизнанку установившееся соглашение о предложениях class: все, что объявлено на верхнем уровне блока class, явля- ется атрибутом класса (методы – тоже атрибуты класса). А в PEP 526 и @dataclass всякий атрибут, объявленный на верхнем уровне с аннотацией типа, стано- вится атрибутом экземпляра: @dataclass class Spam: repeat: int # атрибут экземпляра Дополнительная литература  207\n--- Страница 207 ---\nВо фрагменте ниже repeat – тоже атрибут экземпляра: @dataclass class Spam: repeat: int = 99 # атрибут экземпляра Но если аннотаций типов нет, то мы внезапно возвращаемся в старые добрые времена, когда объявления, находящиеся на верхнем уровне класса, принад- лежали самому классу, а не его экземплярам: @dataclass class Spam: repeat = 99 # атрибут класса! Наконец, если мы хотим аннотировать атрибут класса типом, то не можем ис- пользовать регулярные типы, потому что тогда получим атрибут экземпляра. И приходится прибегать к аннотации псевдотипа ClassVar: @dataclass class Spam: repeat: ClassVar[int] = 99 # ррррр! Здесь мы имеем исключение из исключения из правила. По мне – так в выс - шей степени антипитонично. Я не принимал участия в обсуждениях, закончившихся появлением докумен- тов PEP 526 и PEP 557 «Data Classes» (https://peps.python.org/pep-0557/), но хо- тел бы видеть другой синтаксис, а именно: @dataclass class HackerClubMember: .name: str  .guests: list = field(default_factory=list) .handle: str = '' all_handles = set()   Атрибуты экземпляра должны быть объявлены с префиксом  Любое имя атрибута без префикса . считается атрибутом класса (как всегда и было). Для реализации этого предложения пришлось бы изменить грамматику язы- ка. Мне такой синтаксис кажется вполне понятным, и не возникает никаких исключений из исключений. Хотелось бы мне одолжить машину времени Гвидо, чтобы вернуться в 2017 год и продать эту идею команде разработчиков ядра.208  Построители классов данных",
      "debug": {
        "start_page": 175,
        "end_page": 207
      }
    },
    {
      "name": "Глава 6. Ссылки на объекты, изменяемость и повторное использование 209",
      "content": "--- Страница 208 --- (продолжение)\nГлава 6 Ссылки на объекты, изменяемость и повторное использование – Ты загрустила? – огорчился Рыцарь. – Давай я спою тебе в утешение песню. […] Заглавие этой песни называется «ПУГОВКИ ДЛЯ СЮРТУКОВ». – Вы хотите сказать – песня так называется? – спросила Алиса, стараясь заинтересоваться песней. – Нет, ты не понимаешь, – ответил нетерпеливо Рыцарь. – Это ЗАГЛАВИЕ так называется. А песня называется «ДРЕВНИЙ СТАРИЧОК». – Льюис Кэрролл, «Алиса в Зазеркалье» Алиса и Рыцарь задают тон тому, о чем пойдет речь в этой главе. Ее тема – раз- личие между объектами и их именами. Имя – это не объект, а совершенно от- дельная вещь. Мы начнем главу с метафоры переменных в Python: переменные – это эти- кетки, а не ящик. Если ссылочные переменные – для вас давно не новость, то все равно аналогия может пригодиться, когда понадобится объяснить кому- нибудь, что такое псевдонимы. Затем мы обсудим понятия идентичности объектов, значений и псевдони- мов. Обнаружится удивительная особенность кортежей: сами они неизменяе- мы, но их значения могут изменяться. Это подведет нас к вопросу о глубоком и поверхностном копировании. Следующая тема – параметры-ссылки и пара- метры-функции: проблемы значения изменяемого параметра по умолчанию и безопасной обработки изменяемых аргументов, которые клиенты передают нашим функциям. Последние разделы главы посвящены сборке мусора, команде del и избран- ным фокусам, которые Python проделывает с неизменяемыми объектами. Это довольно сухая глава, но рассматриваемые в ней проблемы являются источником многих тонких ошибок в реальных Python-программах.\nГлава 6 Ссылки на объекты, изменяемость и повторное использование – Ты загрустила? – огорчился Рыцарь. – Давай я спою тебе в утешение песню. […] Заглавие этой песни называется «ПУГОВКИ ДЛЯ СЮРТУКОВ». – Вы хотите сказать – песня так называется? – спросила Алиса, стараясь заинтересоваться песней. – Нет, ты не понимаешь, – ответил нетерпеливо Рыцарь. – Это ЗАГЛАВИЕ так называется. А песня называется «ДРЕВНИЙ СТАРИЧОК». – Льюис Кэрролл, «Алиса в Зазеркалье» Алиса и Рыцарь задают тон тому, о чем пойдет речь в этой главе. Ее тема – раз- личие между объектами и их именами. Имя – это не объект, а совершенно от- дельная вещь. Мы начнем главу с метафоры переменных в Python: переменные – это эти- кетки, а не ящик. Если ссылочные переменные – для вас давно не новость, то все равно аналогия может пригодиться, когда понадобится объяснить кому- нибудь, что такое псевдонимы. Затем мы обсудим понятия идентичности объектов, значений и псевдони- мов. Обнаружится удивительная особенность кортежей: сами они неизменяе- мы, но их значения могут изменяться. Это подведет нас к вопросу о глубоком и поверхностном копировании. Следующая тема – параметры-ссылки и пара- метры-функции: проблемы значения изменяемого параметра по умолчанию и безопасной обработки изменяемых аргументов, которые клиенты передают нашим функциям. Последние разделы главы посвящены сборке мусора, команде del и избран- ным фокусам, которые Python проделывает с неизменяемыми объектами. Это довольно сухая глава, но рассматриваемые в ней проблемы являются источником многих тонких ошибок в реальных Python-программах.\n--- Страница 209 ---\nчтО нОвОг О в этОй главе Рассматриваемые в этой главе механизмы фундаментальные и стабильные. Достойных специального упоминания изменений в новом издании нет. В конец раздела «Выбор между == и is» я добавил пример использования is для проверки на совпадение с охранным объектом и предупреждение о ненад- лежащем употреблении оператора is. Раньше эта глава находилась в части IV, но я решил перенести ее порань- ше, потому что она выглядит более уместно в качестве завершения части II «Структуры данных», чем в качестве открывающей тему «Объектно-ориенти- рованные идиомы». Раздел «Слабые ссылки» из первого издания книги теперь вы- ложен в качестве статьи на сайте fluentpython.com ( https://www. fluentpython.com/extra/weak-references/). Для начала забудем, что переменная – что-то вроде ящика, в котором хра- нятся данные. переменные – не ящики В 1997 году я прослушал летний курс по Java в МТИ. Профессор, Линн Андреа Стейн1, отметила, что стандартная метафора «переменные – это ящики» ведет к непониманию ссылочных переменных в объектно-ориентированных язы- ках. Переменные в Python похожи на ссылочные переменные в Java, поэтому лучше представлять их как этикетки, приклеенные к объектам. Следующий пример и рисунок помогут понять, почему. В примере 6.1 показано простое взаимодействие, которое невозможно объяс - нить с помощью метафоры переменных как ящиков. На рис. 6.1 наглядно пред- ставлено, почему метафора ящика не годится для Python, тогда как метафора этикетки правильно описывает, как в действительности работают переменные. Пример 6.1. В переменных a и b хранятся ссылки на один и тот же список, а не копии списка >>> b = a  >>> a.append(4)  >>> b  [1, 2, 3, 4]   Создать список [1, 2, 3] и связать с ним переменную a  Связать переменную b с тем же значением, на которое ссылается a.  Изменить список, на который ссылается a, добавив в конец еще один элемент.  Можно наблюдать, как это отразилось на переменной b. Если считать b ящиком, в котором хранилась копия списка [1, 2, 3] из ящика a, то такое поведение бессмысленно. 1 Линн Андреа Стейн – удостоенная наград преподаватель информатики, в настоящее вре- мя работает в инженерном колледже Олин (https://www.olin.edu/bios/lynn-andrea-stein). 210  Ссылки на объекты, изменяемость и повторное использование\n--- Страница 210 ---\nРис. 6.1. Если представлять себе переменные как ящики, то невозможно понять, как рабо- тает присваивание в Python; правильнее считать, что переменные – нечто вроде этикеток, – тогда объяснить пример 6.1 становится проще Таким образом, предложение b = a не копирует содержимое ящика a в ящик b, а наклеивает метку b на объект, уже имеющий метку a. Профессор Стейн также очень аккуратно употребляла слова, говоря о при- сваивании. Например, рассказывая об объекте seesaw (качели) в програм- ме моделирования, она всегда говорила «переменная s присвоена объекту seesaw», а не «объект seesaw присвоен переменной s». Имея дело со ссылочны- ми переменными, правильнее говорить, что переменная присвоена объекту, а не наоборот. Ведь объект-то создается раньше присваивания. Пример 6.2 до- казывает, что правая часть присваивания вычисляется раньше. Поскольку употребление глагола «присваивать» (assign) неоднозначно, по- лезной альтернативой является глагол «связывать» (bind): в Python предложе- ние присваивания x = … связывает имя x с объектом, находящимся в правой части. И этот объект должен существовать до того, как с ним связывается имя, что доказывает пример 6.2. Пример 6.2. Переменные связываются с объектами только после создания объектов >>> class Gizmo: def __init__(self): print(f'Gizmo id: {id(self)}') >>> x = Gizmo() Gizmo id: 4301489152  >>> y = Gizmo() * 10  Gizmo id: 4301489432  Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: unsupported operand type(s) for *: 'Gizmo' and 'int' >>> >>> dir()  ['Gizmo', '__builtins__', '__doc__', '__loader__', '__name__', '__package__', '__spec__', 'x']  Вывод Gizmo id: – побочный эффект создания объекта Gizmo.  Умножение объекта Gizmo приводит к исключению.  Это доказывает, что второй объект Gizmo все-таки был создан еще до по- пытки выполнить умножение.  Но переменная y так и не была создана, потому что исключение произо- шло тогда, когда вычислялась правая часть. Переменные – не ящики  211\n--- Страница 211 ---\nДля правильного понимания присваивания в Python всегда сна- чала читайте правую часть, ту, где объект создается или извле- кается. Уже после этого переменная в левой части связывается с объектом – как приклеенная к нему этикетка. А о ящиках за- будьте. Поскольку переменные – это просто этикетки, ничто не мешает наклеить на объект несколько этикеток. В этом случае образуются псевдонимы. О них и по- говорим в следующем разделе. тОждеС твеннОС ть, равенС твО и пСевд Онимы Льюис Кэрролл, литературный псевдоним профессора Чарльза Лутвиджа Додж сона, – не равен проф. Доджсону; это одно и то же лицо. В примере 6.3 эта идея выражена на языке Python. Пример 6.3. Переменные charles и lewis ссылаются на один и тот же объект >>> charles = {'name': 'Charles L. Dodgson', 'born': 1832} >>> lewis = charles  >>> lewis is charles True >>> id(charles), id(lewis)  (4300473992, 4300473992) >>> lewis['balance'] = 950  >>> charles {'name': 'Charles L. Dodgson', 'balance': 950, 'born': 1832}  lewis – псевдоним charles.  Это подтверждают оператор is и функция id.  Добавление элемента в хеш lewis дает тот же результат, что и добавление в хеш charles. Предположим, однако, что некий самозванец – назовем его д-р Александр Педаченко – заявляет, что он и есть Чарльз Л. Доджсон, родившийся в 1832 году. Возможно, он предъявляет такие же документы, но д-р Педаченко и проф. Додж сон – разные лица. Такая ситуация изображена на рис. 6.2. Рис. 6.2. charles и lewis связаны с одним и тем же объектом, alex – с другим объектом, име- ющим точно такое же содержимое В примере 6.4 реализован и протестирован объект alex, изображенный на рис. 6.2. 212  Ссылки на объекты, изменяемость и повторное использование\n--- Страница 212 ---\nПример 6.4. alex и charles равны, но alex не совпадает с charles >>> alex = {'name': 'Charles L. Dodgson', 'born': 1832, 'balance': 950}  >>> alex == charles  True >>> alex is not charles  True  Переменная alex ссылается на объект, являющийся точной копией объекта, присвоенного переменной charles.  При сравнении объекты оказываются равны, поскольку так реализован ме- тод __eq__ в классе dict.  Но это разные объекты. В Python отрицательное сравнение на тождество записывается в виде a is not b . В примере 6.3 иллюстрируются псевдонимы. В этом коде lewis и charles – псев- донимы: две переменные, связанные с одним и тем же объектом. С другой сто- роны, alex не является псевдонимом charles: эти переменные связаны с разными объектами. Объекты, связанные с переменными alex и charles, имеют одно и то же значение – то, что сравнивает оператор ==, – но идентификаторы у них разные. В разделе 3.1 «Объекты, значения и типы» справочного руководства по язы- ку Python (https://docs.python.org/3/reference/datamodel.html#objects-values-and-types) написано: У каждого объекта есть идентификатор, тип и значение. Идентификатор объекта после создания не изменяется, можете считать, что это адрес объек - та в памяти. Оператор is сравнивает идентификаторы двух объектов; функ - ция id() возвращает целое число, представляющее идентификатор объекта. Истинный смысл идентификатора объекта зависит от реализации. В CPython функция id() возвращает адрес объекта в памяти, но в другом интерпретаторе это может быть что-то совсем иное. Главное – гарантируется, что идентифика- тор является уникальной числовой этикеткой и не изменяется в течение всего времени жизни объекта. На практике мы редко пользуемся функцией id(). Проверка на тождество чаще производится с помощью оператора is, который сравнивает идентифи- каторы объектов, поэтому нам вызывать id() явно нет необходимости. Далее мы обсудим различия между операторами is и ==. Технический рецензент Леонардо Рохаэль чаще всего употреб- ляет id() во время отладки, когда метод repr() возвращает оди- наковые представления объектов, но необходимо понять, явля- ются ли две ссылки псевдонимами или ведут на разные объек - ты. Если ссылки встречаются в разных контекстах – например, в разных кадрах стека, – то использование оператора is может не дать желаемого результата. Выбор между == и is Оператор == сравнивает значения объектов (хранящиеся в них данные), а опе- ратор is – их идентификаторы. При программировании нас обычно интересуют значения, а не идентифи- каторы, поэтому == встречается в Python-программах чаще, чем is. Тождественность, равенство и псевдонимы  213\n--- Страница 213 ---\nОднако при сравнении переменной с объектом-одиночкой (синглтоном) имеет смысл использовать is. Самый типичный случай – проверка того, что переменная связана с объектом None. Вот как это рекомендуется делать: x is None А вот как правильно записывать отрицание этого условия: x is not None None – самый распространенный синглтон, с которым мы сравниваем с помо- щью is. Охранные объекты – еще один пример такого рода синглтонов. Ниже показан один из способов создания охранного объекта и сравнения с ним: END_OF_DATA = object() # много строчек def traverse( ): # еще строчки if node is END_OF_DATA: return # и т. д . Оператор is работает быстрее, чем ==, потому что его невозможно перегру - зить, так что интерпретатору не приходится искать и вызывать специальные методы для его вычисления, а само вычисление сводится к сравнению двух це- лых чисел. Напротив, a == b – это синтаксический сахар поверх вызова метода a.__eq__(b) . Метод __eq__, унаследованный от object, сравнивает идентификаторы объектов, поэтому дает тот же результат, что is. Но в большинстве встроенных типов метод __eq__ переопределен в соответствии с семантикой типа, т. е. с уче- том значений других атрибутов. Для установления равенства может потребо- ваться большой объем обработки, например сравнение больших коллекций или глубоко вложенных структур. Обычно равенство объектов интересует нас больше, чем тождест- венность. Сравнение с None – единственный распространенный случай употребления оператора is. В большинстве других ситу - аций, с которыми я сталкивался в процессе технического рецен- зирования кода, is употребляется не к месту. Если не уверены, пишите ==. Обычно это именно то, что нужно, да и для сравнения с None тоже работает, правда, не так быстро. Завершая обсуждение тождественности и равенства, мы покажем, что знаме- нитый своей неизменяемостью тип tuple вовсе не такой несгибаемый, как кажется. Относительная неизменяемость кортежей Кортежи, как и большинство коллекций в Python – списки, словари, множест - ва и т. д., – хранят ссылки на объекты1. Если элементы, на которые указывают ссылки, изменяемы, то их можно модифицировать, хотя сам кортеж остается неизменяемым. Иными словами, говоря о неизменяемости кортежа, мы име- 1 С другой стороны, плоские последовательности, например str, bytes и array.array , содер- жат не ссылки, а сами данные – символы, байты и числа – в непрерывной области памяти. 214  Ссылки на объекты, изменяемость и повторное использование\n--- Страница 214 ---\nем в виду физическое содержимое структуры данных tuple (т. е. хранящиеся в ней ссылки), но не объекты, на которые эти ссылки указывают. В примере 6.5 иллюстрируется ситуация, когда значение кортежа изменя- ется в результате модификации изменяемого объекта, на который указывает ссылка. Но что никогда не может измениться, так это идентификаторы эле- ментов, хранящихся в кортеже. Пример 6.5. Кортежи t1 и t2 первоначально равны, но после модификации изменяемо- го объекта, хранящегося в t1, они перестают быть равными >>> t1 = (1, 2, [30, 40])  >>> t2 = (1, 2, [30, 40])  >>> t1 == t2  True >>> id(t1[-1])  4302515784 >>> t1[-1].append(99)  >>> t1 (1, 2, [30, 40, 99]) >>> id(t1[-1])  4302515784 >>> t1 == t2  False  t1 неизменяемый, но t1[-1] изменяемый.  Построить кортеж t2, элементы которого равны элементам t1.  Хотя t1 и t2 – разные объекты, они, как и следовало ожидать, равны.  Вывести идентификатор списка в элементе t1[-1].  Модифицировать t1[-1] на месте.  Идентификатор объекта t1[-1] не изменился, изменилось лишь его значение. t1 и t2 теперь не равны. Эта относительная неизменяемость объясняет загадку в разделе «Голово- ломка: присваивание A +=» главы 2. По этой же причине некоторые кортежи не являются хешируемыми, как мы видели во врезке «Что значит “хешируе- мый”»? в главе 2. Различие между равенством и тождественностью проявляется и при копи- ровании объекта. Копия – это объект, равный исходному, но с другим иденти- фикатором. Однако если объект содержит другие объекты, то следует ли при копировании дублировать также внутренние объекты или можно оставить их разделяемыми? Единственно правильного ответа на этот вопрос не существу - ет. Читайте дальше. пО умО лчанию кОпир Ование пОверхнОС тнОе Простейший способ скопировать список (как и большинство встроенных из- меняемых коллекций) – воспользоваться встроенным конструктором самого типа, например: >>> l1 = [3, [55, 44], (7, 8, 9)] >>> l2 = list(l1)  По умолчанию копирование поверхностное  215\n--- Страница 215 ---\n>>> l2 [3, [55, 44], (7, 8, 9)] >>> l2 == l1  True >>> l2 is l1  False  list(l1) создает копию l1.  Копии равны…  … но ссылаются на разные объекты. Для списков и других изменяемых последовательностей присваивание l2 = l1[:] также создает копию. Однако при использовании конструктора и оператора [:] создается поверхност- ная копия (т. е. дублируется только самый внешний контейнер, который заполняет - ся ссылками на те же элементы, что хранятся в исходном контейнере). Это эконо- мит память и не создает проблем, если все элементы неизменяемые. Однако при наличии изменяемых элементов можно столкнуться с неприятными сюрпризами. В примере 6.6 мы создаем поверхностную копию списка, который содержит другой список и кортеж, а затем производим изменения и смотрим, как они отразились на объектах, на которые указывают ссылки. Если ваш компьютер подключен к сети, рекомендую понаблю- дать за интерактивной анимацией примера 6.6 на сайте Online Python Tutor (http://www.pythontutor.com/). Во время работы над этой главой прямая ссылка на пример, подготовленный для pythontutor.com, работала ненадежно, но сам инструмент заме- чательный, поэтому время, потраченное на копирование кода на сайт, будет потрачено не зря. Пример 6.6. Создание поверхностной копии списка, содержащего другой список; скопируй- те этот код на сайт Online Python Tutor, чтобы увидеть его анимацию l1 = [3, [66, 55, 44], (7, 8, 9)] l2 = list(l1)  l1.append(100)  l1[1].remove(55)  print('l1:', l1) print('l2:', l2) l2[1] += [33, 22]  l2[2] += (10, 11)  print('l1:', l1) print('l2:', l2)  l2 – поверхностная копия l1. Это состояние изображено на рис. 6.3.  Добавление 100 в l1 не отражается на l2.  Здесь мы удаляем 55 из внутреннего списка l1[1]. Это отражается на l2, по- тому что объект l2[1] связан с тем же списком, что l1[1].  Для изменяемого объекта, в частности списка, на который ссылается l2[1], оператор += изменяет список на месте. Это изменение отражается на l1[1], т. к. это псевдоним l2[1].  Для кортежа оператор += создает новый кортеж и перепривязывает к нему переменную l2[2]. Это то же самое, что присваивание l2[2] = l2[2] + (10, 11) . 216  Ссылки на объекты, изменяемость и повторное использование\n--- Страница 216 ---\nОтметим, что кортежи в последней позиции списков l1 и l2 уже не являют - ся одним и тем же объектом. См. рис. 6.4. Рис. 6.3. Состояние программы сразу после присваивания l2 = list(l1) в примере 6.6. l1 и l2 ссылаются на разные списки, но эти списки разделяют ссылки на один и тот же объект внутрен- него списка [66, 55, 44] и кортеж (7, 8, 9) (рисунок построен сайтом Online Python Tutor) Результат работы примера 6.6 показан в примере 6.7, а конечное состояние объектов – на рис. 6.4. Пример 6.7. Результат работы примера 6.6 l1: [3, [66, 44], (7, 8, 9), 100] l2: [3, [66, 44], (7, 8, 9)] l1: [3, [66, 44, 33, 22], (7, 8, 9), 100] l2: [3, [66, 44, 33, 22], (7, 8, 9, 10, 11)] Рис. 6.4. Конечное состояние l1 и l2: они по-прежнему разделяют ссылки на один и тот же объект списка, который теперь содержит [66, 44, 33, 22] , но в результате операции l2[2] += (10, 11) был создан новый кортеж (7, 8, 9, 10, 11) , не связанный с кортежем (7, 8, 9 ), на который ссылается элемент l1[2] (рисунок построен сайтом Online Python Tutor) По умолчанию копирование поверхностное  217\n--- Страница 217 ---\nТеперь должно быть понятно, что создать поверхностную копию легко, но это не всегда то, что нам нужно. В следующем разделе мы обсудим создание глубоких копий. Глубокое и поверхностное копирование произвольных объектов Не всегда поверхностное копирование является проблемой, но иногда требу - ется получить глубокую копию (когда копия не разделяет с оригиналом ссылки на внутренние объекты). В модуле copy имеются функции deepcopy и copy, которые возвращают соответственно глубокие и поверхностные копии произвольных объектов. Для иллюстрации работы copy() и deepcopy() в примере 6.8 определен простой класс Bus, представляющий школьный автобус, который по ходу маршрута под- бирает и высаживает пассажиров. Пример 6.8. Автобус подбирает и высаживает пассажиров class Bus: def __init__(self, passengers=None): if passengers is None: self.passengers = [] else: self.passengers = list(passengers) def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name) Далее в интерактивном примере 6.9 мы создадим объект класса Bus (bus1) и два его клона: поверхностную копию (bus2) и глубокую копию ( bus3) – и понаб- людаем за тем, что происходит, когда bus1 высаживает школьника. Пример 6.9. Сравнение copy и deepcopy >>> import copy >>> bus1 = Bus(['Alice', 'Bill', 'Claire', 'David']) >>> bus2 = copy.copy(bus1) >>> bus3 = copy.deepcopy(bus1) >>> id(bus1), id(bus2), id(bus3) (4301498296, 4301499416, 4301499752)  >>> bus1.drop('Bill') >>> bus2.passengers ['Alice', 'Claire', 'David']  >>> id(bus1.passengers), id(bus2.passengers), id(bus3.passengers) (4302658568, 4302658568, 4302657800)  >>> bus3.passengers ['Alice', 'Bill', 'Claire', 'David']   Используя copy и deepcopy, мы создаем три разных объекта Bus.  После высадки 'Bill' из автобуса bus1 он исчезает и из bus2.218  Ссылки на объекты, изменяемость и повторное использование\n--- Страница 218 ---\n Инспекция атрибута passengers показывает, что bus1 и bus2 разделяют один и тот же объект списка, т. к. bus2 – поверхностная копия bus1.  bus3 – глубокая копия bus1, поэтому ее атрибут passengers ссылается на другой список. Отметим, что в общем случае создание глубокой копии – дело не простое. Между объектами могут существовать циклические ссылки, из-за которых наивный алгоритм попадет в бесконечный цикл. Для корректной обработки циклических ссылок функция deepcopy запоминает, какие объекты она уже ко- пировала. Это продемонстрировано в примере 6.10. Пример 6.10. Циклические ссылки: b ссылается на a, а затем добавляется в конец a; тем не менее deepcopy справляется с копированием a >>> a = [10, 20] >>> b = [a, 30] >>> a.append(b) >>> a [10, 20, [[ ], 30]] >>> from copy import deepcopy >>> c = deepcopy(a) >>> c [10, 20, [[ ], 30]] Кроме того, в некоторых случаях глубокое копирование может оказать- ся слишком глубоким. Например, объекты могут ссылаться на внешние ресурсы или на синглтоны, которые копировать не следует. Поведением функций copy и deepcopy можно управлять, реализовав специальные методы __copy__() и __deepcopy__() , как описано в документации по модулю copy (http:// docs.python.org/3/library/copy.html). Разделение ссылок на объекты посредством псевдонимов объясняет также механизм передачи параметров в Python и решает проблему использования изменяемых типов для параметров по умолчанию. Эти вопросы мы рассмот- рим далее. параметры функций как ССылки Единственный способ передачи параметров в Python – вызов по соиспользова- нию (call by sharing). Он применяется в большинстве объектно-ориентирован- ных языков, в том числе JavaScript, Ruby, и Java (это относится к ссылочным типам Java, параметры примитивных типов передаются по значению). Вызов по соиспользованию означает, что каждый формальный параметр функции получает копию ссылки на фактический аргумент. Иначе говоря, внутри функ - ции параметры становятся псевдонимами фактических аргументов. В результате функция получает возможность модифицировать любой из- меняемый объект, переданный в качестве параметра, но не может заменить объект другим, не тождественным ему. В примере 6.11 показана простая функция, применяющая оператор += к одному из своих параметров. Резуль- тат зависит от того, что передано в качестве фактического аргумента: число, список или кортеж. Параметры функций как ссылки  219\n--- Страница 219 ---\nПример 6.11. Функция может модифицировать любой переданный ей изменяемый объект >>> def f(a, b): a += b return a >>> x = 1 >>> y = 2 >>> f(x, y) 3 >>> x, y  (1, 2) >>> a = [1, 2] >>> b = [3, 4] >>> f(a, b) [1, 2, 3, 4] >>> a, b  ([1, 2, 3, 4], [3, 4]) >>> t = (10, 20) >>> u = (30, 40) >>> f(t, u)  (10, 20, 30, 40) >>> t, u ((10, 20), (30, 40))  Число x не изменилось.  Список a изменился.  Кортеж t не изменился. С параметрами функций связан также еще один вопрос: что бывает, когда значение по умолчанию имеет изменяемый тип? Значения по умолчанию изменяемого типа: неудачная мысль Необязательные параметры, имеющие значения по умолчанию, – замечатель- ная возможность, которую можно использовать в определениях функций для обеспечения обратной совместимости API. Однако не следует использовать в качестве значений по умолчанию изменяемые объекты. Для иллюстрации возникающей проблемы мы в примере 6.12 взяли класс Bus из примера 6.8 и изменили в нем метод __init__, получив новый класс HauntedBus . Но решили поумничать и вместо значения по умолчанию passengers=None задали passengers=[] , избавившись тем самым от предложения if в предыдущем вари- анте __init__. Такое «умничанье» приводит к беде. Пример 6.12. Простой класс, иллюстрирующий опасности изменяемых значений по умол- чанию class HauntedBus: \"\"\"Автобус, облюбованный пассажирами-призраками\"\"\" def __init__(self, passengers=[]):  self.passengers = passengers  def pick(self, name): self.passengers.append(name) 220  Ссылки на объекты, изменяемость и повторное использование\n--- Страница 220 ---\ndef drop(self, name): self.passengers.remove(name)  Если аргумент passengers не передан, то этот параметр связывается с объек - том списка по умолчанию, который первоначально пуст.  В результате этого присваивания self.passengers становится псевдонимом passengers , который сам является псевдонимом списка по умолчанию, если аргумент passengers не передан.  Применяя методы .remove() и .append() к self.passengers , мы на самом деле из- меняем список по умолчанию, который является атрибутом объекта-функ - ции. В примере 6.13 показано потустороннее поведение объекта HauntedBus . Пример 6.13. Автобусы, облюбованные пассажирами-призраками >>> bus1 = HauntedBus(['Alice', 'Bill'])  >>> bus1.passengers ['Alice', 'Bill'] >>> bus1.pick('Charlie') >>> bus1.drop('Alice') >>> bus1.passengers  ['Bill', 'Charlie'] >>> bus2 = HauntedBus()  >>> bus2.pick('Carrie') >>> bus2.passengers ['Carrie'] >>> bus3 = HauntedBus()  >>> bus3.passengers ['Carrie'] >>> bus3.pick('Dave') >>> bus2.passengers  ['Carrie', 'Dave'] >>> bus2.passengers is bus3.passengers  True >>> bus1.passengers  ['Bill', 'Charlie']  Вначале bus1 содержит список из двух пассажиров.  Пока все хорошо: bus1 не таит никаких сюрпризов.  bus2 вначале пуст, поэтому атрибуту self.passengers присвоен пустой список по умолчанию.  bus3 также вначале пуст, self.passengers – снова список по умолчанию.  Список по умолчанию уже не пуст!  Теперь Dave, севший в автобус bus3, оказался и в bus2.  Проблема: bus2.passengers и bus3.passengers ссылаются на один и тот же список.  Но bus1.passengers – другой список. Проблема в том, что все экземпляры HauntedBus, конструктору которых не был явно передан список пассажиров, разделяют один и тот же список по умолчанию. Это тонкая ошибка. Из примера 6.13 видно, что когда объект HauntedBus ини- циализируется списком пассажиров, он работает правильно. Странности на- чинаются, когда HauntedBus вначале пуст, потому что в этом случае self.passengers Параметры функций как ссылки  221\n--- Страница 221 ---\nоказывается псевдонимом значения по умолчанию для параметра passengers . Беда в том, что любое значение по умолчанию вычисляется в момент опре- деления функции, т. е. обычно на этапе загрузки модуля, после чего значения по умолчанию становятся атрибутами объекта-функции. Так что если значе- ние по умолчанию – изменяемый объект и вы его изменили, то изменение отразит ся и на всех последующих вызовах функции. Если после выполнения кода из примера 6.13 проинспектировать объект HauntedBus.__init__ , то мы обнаружим школьников-призраков в его атрибуте __ defaults__ : >>> dir(HauntedBus.__init__) # doctest: +ELLIPSIS ['__annotations__', '__call__', , '__defaults__', ] >>> HauntedBus.__init__.__defaults__ (['Carrie', 'Dave'],) Наконец, можно убедиться, что bus2.passengers – псевдоним первого элемента атрибута HauntedBus.__init__.__defaults__ : >>> HauntedBus.__init__.__defaults__[0] is bus2.passengers True Описанная проблема и есть причина того, почему для параметров, прини- мающих изменяемые значения, часто по умолчанию задается значение None. В примере 6.8 __init__ проверяет, верно ли, что аргумент passengers совпадает с None, и, если это так, присваивает атрибуту self.passengers вновь созданный пус- той список. Если passengers не совпадает с None, то правильное решение заклю- чается в том, чтобы связать копию этого атрибута с self.passengers . В следующем разделе объясняется, почему следует предпочесть копирование аргумента. Защитное программирование при наличии изменяемых параметров При написании функции, принимающей изменяемый параметр, нужно тща- тельно обдумать, ожидает ли вызывающая сторона, что переданный аргумент может быть изменен. Например, если функция принимает словарь и должна модифицировать его в процессе обработки, должен ли этот побочный эффект быть виден вне самой функции? Ответ зависит от контекста. Так или иначе, необходимо согласовать предположения автора функции и вызывающей программы. Приведем еще один, последний, пример автобуса – класс TwilightBus , который нарушает ожидания, разделяя список пассажиров со своими клиентами. Преж- де чем переходить к реализации, посмотрите, как работает класс TwilightBus с точки зрения его клиента. Пример 6.14. Пассажиры, вышедшие из автобуса TwilightBus , бесследно исчезают >>> basketball_team = ['Sue', 'Tina', 'Maya', 'Diana', 'Pat']  >>> bus = TwilightBus(basketball_team)  >>> bus.drop('Tina')  >>> bus.drop('Pat') >>> basketball_team ['Sue', 'Maya', 'Diana'] 222  Ссылки на объекты, изменяемость и повторное использование\n--- Страница 222 ---\n В списке basketball_team пять школьников.  TwilightBus везет всю баскетбольную команду.  Из автобуса bus вышел сначала один школьник, за ним второй.  Вышедшие пассажиры исчезли из баскетбольной команды! Класс TwilightBus нарушает «принцип наименьшего удивления»1 – одну из ре- комендаций по проектированию интерфейсов. Поистине удивительно, что стоит школьнику выйти из автобуса, как он исчезает из состава баскетбольной команды. В примере 6.15 приведена реализация класса TwilightBus и объяснена причи- на проблемы. Пример 6.15. Простой класс, иллюстрирующий опасности, которыми чревато изменение по- лученных аргументов class TwilightBus: \"\"\"Автобус, из которого бесследно исчезают пассажиры\"\"\" def __init__(self, passengers=None): if passengers is None: self.passengers = []  else: self.passengers = passengers  def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name)   Здесь мы честно создаем пустой список, когда passengers совпадает с None.  Но в результате этого присваивания self.passengers становится псевдонимом параметра passengers , который сам является псевдонимом фактического ар- гумента, переданного методу __init__ (т. е. basketball_team в примере 6.14).  Применяя методы .remove() и .append() к self.passengers , мы в действительно- сти изменяем исходный список, переданный конструктору в качестве аргу - мента. Проблема здесь в том, что в объекте bus создается псевдоним списка, передан- ного конструктору. А надо бы хранить собственный список пассажиров. Исправить ошибку просто: в методе __init__ атрибут self.passengers следует инициализировать копией параметра passengers, если тот задан, как и было сделано в примере 6.8. def __init__(self, passengers=None): if passengers is None: self.passengers = [] else: self.passengers = list(passengers)   Создать копию списка passengers или преобразовать его в тип list, если пара- метр имеет другой тип. 1 См. статью «Principle of least astonishment» (https://en.wikipedia.org/wiki/Principle_of_ least_astonishment) в англоязычной части Википедии. Параметры функций как ссылки  223\n--- Страница 223 ---\nВот теперь внутренние операции со списком пассажиров никак не влияют на аргумент, переданный конструктору автобуса. Заодно это решение оказы- вается и более гибким: аргумент, переданный в качестве параметра passengers , может быть кортежем или любым другим итерируемым объектом, например множеством или даже результатом запроса к базе данных, поскольку кон- структор класса list принимает любой итерируемый объект. Так как мы сами создали список, с которым будем работать, то гарантируется, что он поддер- живает операции .remove() и .append(), используемые в методах .pick() и .drop(). Если метод специально не предназначен для изменения объ- екта, полученного в качестве аргумента, то следует дважды по- думать, перед тем как создавать псевдоним аргумента, просто присваивая его атрибуту экземпляра в своем классе. Если со- мневаетесь, делайте копию. Клиенты обычно будут только рады. Конечно, создание копии обходится не бесплатно: потребляется процессорное время и память. Однако API, вызывающий тонкие ошибки, – обычно куда большая проблема, чем небольшое за- медление или немного повышенное потребление ресурсов. Теперь поговорим об одном из самых плохо понимаемых предложений Python: del. del и СБОрка муСОра Объекты никогда не уничтожаются явно, однако, оказавшись недоступ- ными, они могут стать жертвой сборщика мусора. – «Модель данных», глава справочного руководства по языку Python Первая странность del – то, что это не функция, а предложение языка. Мы пи- шем del x, а не del(x), хотя вторая форма тоже работает, но только потому, что в Python выражения x и (x) обычно означают одно и то же. Вторая странность – то, что предложение del удаляет ссылки, а не объекты. Сборщик мусора в Python может удалить объект из памяти в качестве побоч- ного результата del, если это была последняя ссылка на объект. Связывание переменной с другим объектом также может обнулить количество ссылок на объект, что приведет к его уничтожению. >>> a = [1, 2]  >>> b = a  >>> del a  >>> b  [1, 2] >>> b = [3]   Создать объект [1, 2] и связать с ним a.  Связать b с тем же самым объектом [1, 2].  Удалить ссылку a.  Объект [1, 2] остался на месте, потому что b по-прежнему указывает на него.  Если связать b с другим объектом, то последняя оставшаяся ссылка на [1, 2] будет удалена. Теперь сборщик мусора может удалить сам объект. 224  Ссылки на объекты, изменяемость и повторное использование\n--- Страница 224 ---\nСуществует специальный метод __del__, но он не приводит к уничтожению экземпляра, и вы не должны вызывать его са- мостоятельно. Метод __del__ вызывается интерпретатором Python непосредственно перед уничтожением объекта, давая ему возможность освободить внешние ресурсы. Вам редко придется реализовывать метод __del__ в своем коде, но тем не менее некоторые начинающие программисты тратят время на его написание безо всяких на то причин. Правильно напи- сать метод __del__ довольно сложно. Он документирован в гла- ве «Модель данных» справочного руководства по языку Python (https://docs.python.org/3/reference/datamodel.html# object.__del__). В CPython основной алгоритм сборки мусора основан на подсчете ссылок. В каждом объекте хранится счетчик указывающих на него ссылок – refcount. Как только этот счетчик обратится в нуль, объект сразу же уничтожается: CPython вызывает метод __del__ объекта (если он определен), а затем освобож - дает выделенную ему память. В CPython 2.0 был добавлен алгоритм сборки мусора, основанный на поколениях, который обнаруживает группы объектов, ссылающихся друг на друга и образующих замкнутую группу. Такие объекты могут оказаться недостижимыми, хотя в каждом из них счетчик ссылок боль- ше нуля. В других реализациях Python применяются более сложные сборщики мусора, не опирающиеся на подсчет ссылок, а это означает, что метод __del__ может вызываться не сразу после того, как на объект не осталось ссылок. См. статью A. Jesse Jiryu Davis «PyPy, Garbage Collection, and a Deadlock» (https:// emptysqua.re/blog/pypy-garbage-collection-and-a-deadlock/), в которой обсуждается правильное и неправильное использование метода __del__. Для демонстрации завершения жизни объекта в примере 6.16 используется функция weakref.finalize , которая регистрирует функцию обратного вызова, вы- зываемую перед уничтожением объекта. Пример 6.16. Наблюдение за гибелью объекта, на который не осталось ссылок >>> import weakref >>> s1 = {1, 2, 3} >>> s2 = s1  >>> def bye():  print(' like tears in the rain.') >>> ender = weakref.finalize(s1, bye)  >>> ender.alive  True >>> del s1 >>> ender.alive  True >>> s2 = 'spam'  like tears in the rain. >>> ender.alive False  s1 и s2 – псевдонимы, ссылающиеся на одно и то же множество {1, 2, 3}.  Эта функция не должна быть связанным методом уничтожаемого объекта, иначе она будет хранить ссылку на него. del и сборка мусора  225\n--- Страница 225 ---\n Регистрируем обратный вызов bye объекта, на который ссылается s1.  Атрибут .alive равен True, перед тем как вызвана функция, зарегистрирован- ная finalize.  Как было сказано, del удаляет не объект, а только ссылку на него.  После перепривязки последней ссылки, s2, объект {1, 2, 3} оказывается не- доступен. Он уничтожается, вызывается функция bye, и атрибут ender.alive становится равен False. Смысл примера 6.16 – ясно показать, что предложение del не удаляет объ- екты, хотя объекты могут быть удалены из-за того, что после выполнения del оказываются недоступны. Быть может, вам не понятно, почему в примере 6.16 был уничтожен объект {1, 2, 3}. Ведь ссылка s1 была передана функции finalize, которая должна была бы удержать ее, чтобы следить за объектом и вызвать функцию обратного вызова. Это работает, потому что finalize удерживает слабую ссылку на объект {1, 2, 3}. Слабые ссылки на объект не увеличивают счетчик ссылок. Таким образом, сла- бая ссылка не препятствует уничтожению объекта ссылки сборщиком мусора. Слабые ссылки полезны для кеширования, поскольку мы не хотим, чтобы кеши- рованный объект оставался жив только потому, что на него ссылается сам кеш. Слабые ссылки – очень специальная тема. Поэтому я решил опус- тить посвященный им раздел во втором издании. Но вы може- те найти его на сайте fluentpython.com в статье «Weak References» (https://www.fluentpython.com/extra/weak-references/). как python хитрит С неизменяемыми ОБъектами Вы можете спокойно пропустить этот раздел. В нем обсуждаются некоторые детали реализации, которые пользователям Python не особенно интересны и могут быть неприменимы к другим реализациям Python и даже к будущим версиям CPython. Тем не менее, экспериментируя с псевдонимами и копированием, иногда можно наткнуться на следы этих трюков, поэтому мне показалось, что о них стоит сказать пару слов. Я удивился, узнав, что для кортежа t конструкция t[:] не создает копию, а воз- вращает ссылку на сам объект. Ссылку на исходный кортеж мы получаем так- же, написав tuple(t)1. Это доказывает пример 6.17. Пример 6.17. Кортеж, инициализированный другим кортежем, в точности совпадает с ис - ходным >>> t1 = (1, 2, 3) >>> t2 = tuple(t1) >>> t2 is t1  True >>> t3 = t1[:] 1 Это поведение четко документировано. Набрав help(tuple) в оболочке Python, чита- ем: «Если аргумент является кортежем, то возвращается исходный объект». А я-то, садясь за написание этой книги, думал, что знаю о кортежах все. 226  Ссылки на объекты, изменяемость и повторное использование\n--- Страница 226 ---\n>>> t3 is t1  True  t1 и t2 связаны с одним и тем же объектом.  И t3 тоже. Такое же поведение свойственно экземплярам классов str, bytes и frozenset. Отметим, что frozenset – не последовательность, поэтому, когда fs является объектом frozenset, конструкция fs[:] не работает. Но fs.copy() дает точно та- кой же эффект: обманывает нас и возвращает ссылку на тот же объект, а вовсе не на его копию. См. пример 6.181. Пример 6.18. Строковые литералы могут создавать разделяемые объекты >>> t1 = (1, 2, 3) >>> t3 = (1, 2, 3)  >>> t3 is t1  False >>> s1 = 'ABC' >>> s2 = 'ABC'  >>> s2 is s1  True  Создание нового кортежа с нуля.  t1 и t3 равны, но не тождественны.  Создание второй строки str с нуля.  Сюрприз: s1 и s2 ссылаются на один и тот же объект str! Разделение строковых литералов – это техника оптимизации, называемая интернированием. В CPython тот же прием используется для небольших целых чисел, чтобы избежать ненужного дублирования «популярных» чисел, напри- мер 0, 1, –1 и т. д. Отметим, что CPython не интернирует все строки и целые числа подряд, а критерии, которыми он руководствуется, остаются недокумен- тированной деталью реализации. Никогда не полагайтесь на интернирование объектов str и int! Для сравнения на равенство используйте только оператор ==, а не is. Интернирование предназначено исключительно для внутренних нужд интерпретатора. Трюки, обсуждаемые в этом разделе, в том числе поведение метода frozenset. copy(), – это «ложь во спасение»: они экономят память и ускоряют работу ин- терпретатора. Не думайте о них, никаких хлопот они не доставят, потому что относятся только к неизменяемым объектам. Пожалуй, наилучшее примене- ние этим мелочам – пари со знакомыми питонистами2. 1 Невинную ложь – тот факт, что метод copy ничего не копирует, – можно объяснить совместимостью интерфейсов: при этом класс frozenset оказывается лучше совмес- тим с set. Как бы то ни было, конечному пользователю безразлично, являются два идентичных неизменяемых объекта одним и тем же объектом или разными. 2 Жестокое использование этой информации – задать вопрос кандидату на собеседо- вании или включить его в экзамен на получение сертификата. Есть множество более важных и полезных вещей, позволяющих судить о знании Python. Как Python хитрит с неизменяемыми объектами  227\n--- Страница 227 ---\nрезюме У каждого объекта в Python есть идентификатор, тип и значение. И только зна- чение объекта может изменяться со временем1. Если две переменные ссылаются на неизменяемые объекты, имеющие рав- ные значения (a == b принимает значение True), то на практике редко бывает важно, ссылаются они на копии или являются псевдонимами, – за одним ис- ключением. Это исключение составляют неизменяемые коллекции, например кортежи и объекты frozenset: если неизменяемая коллекция содержит ссылки на изменяемые объекты, то ее значение может измениться при изменении значения одного из ее элементов. На практике такая ситуация встречается нечасто. Но идентификаторы объектов, хранящихся в неизменяемой коллек - ции, не изменяются ни при каких обстоятельствах. Классу frozenset эта проб- лема не свойственна, потому что в нем могут храниться только хешируемые элементы, а значение хешируемого объекта, по определению, никогда не из- меняется. Из того, что в переменных хранятся ссылки, вытекает ряд практических следствий. Простое присваивание не создает копий. Составное присваивание (операторы +=, *= и т. п.) создает новый объект, если переменная в левой части связана с неизменяемым объектом, а из- меняемый объект может быть модифицирован на месте. Присваивание нового значения существующей переменной не изменя- ет объект, с которым она была связана ранее. Это называется перепри- вязкой: переменная просто связывается с другим объектом. Если в этой переменной хранилась последняя ссылка на предыдущий объект, то этот объект убирается в мусор. Параметры функций передаются как псевдонимы, т. е. функция может модифицировать любой изменяемый объект, переданный ей в качестве аргумента. Этому невозможно воспрепятствовать, разве что создать ло- кальную копию или использовать неизменяемые объекты (т. е. переда- вать кортеж вместо списка). Использовать изменяемые объекты в качестве значений параметров функции по умолчанию опасно, потому что если изменить параметр на месте, то изменится значение по умолчанию, и это скажется на всех по- следующих вызовах функции с параметром по умолчанию. В CPython объект уничтожается, как только число ссылок на него станет равно нулю. Объекты также могут уничтожаться, если образуют группу с цик- лическими ссылками друг на друга, и ни на один объект группы нет других – внешних – ссылок. В некоторых ситуациях полезно иметь ссылку, которая сама по себе не удер- живает объект «в мире живых». Примером может служить класс, желающий отслеживать все свои экземпляры. Это можно сделать с помощью слабых ссы- 1 На самом деле тип объекта тоже можно изменить, просто присвоив другой класс его атрибуту __class__ , но это неприкрытое зло, и я жалею, что написал эту сноску.228  Ссылки на объекты, изменяемость и повторное использование\n--- Страница 228 ---\nлок – низкоуровневого механизма, на базе которого построены более полез- ные коллекции WeakValueDictionary , WeakKeyDictionary , WeakSet и функция finalize – все из модуля weakref. Дополнительные сведения по этому вопросу см. в статье «Weak References» (https://www.fluentpython.com/extra/weak-references/). дОпО лнительная литература Глава «Модель данных» (https://docs.python.org/3/reference/datamodel.html) спра- вочного руководства по языку Python начинается с объяснения того, что такое идентификаторы и значения объектов. Уэсли Чан, автор серии книг Core Python, показал на конференции EuroPython 2011 презентацию «Understanding Python’s Memory Model, Mutability, and Methods» (https://www.youtube.com/watch?v=HHFCFJSPWrI&feature=youtu.be), в кото- рой затрагиваются не только темы этой главы, но и использование специаль- ных методов. Дуг Хеллманн написал статьи «copy – Duplicate Objects» (http://pymotw.com/2/copy/) и «weakref – Garbage-Collectable References to Objects» (http://pymotw.com/2/weakref/), где рассматриваются некоторые из обсуждавшихся в этой главе вопросов. Дополнительные сведения об основанном на поколениях сборщике мусо- ра можно найти в документации по модулю gc (https://docs.python.org/3/library/ gc.html), которая начинается фразой: «Этот модуль предоставляет интерфейс к факультативному сборщику мусора». Слово «факультативный» в этом кон- тексте может вызвать удивление, но в главе «Модель данных» (https://docs. python.org/3/reference/datamodel.html) также утверждается: Реализации разрешено откладывать сборку мусора и даже не произво- дить ее вовсе; как именно реализована сборка мусора – вопрос качества реализации, главное условие – чтобы не уничтожался ни один объект, ко- торый все еще достижим. Пабло Галиндо представил развернутое описание сборщика мусора в Python в разделе «Design of CPython’s Garbage Collector» (https://devguide.python.org/ garbage_collector/) руководства по Python для разработчиков, ориентированное на новых и опытных соразработчиков CPython. В версии CPython 3 сборщик мусора усовершенствован в части обработ - ки объектов с методом __del__, это описано в документе PEP 442 «Safe object finalization» (https://peps.python.org/pep-0442/). В Википедии имеется статья об интернировании строк (https://en.wikipedia. org/wiki/String_interning), в которой описывается применение этой техники в разных языках, включая Python. В Википедии также имеется статья о песне Льюиса Кэрролла «Haddocks’ Eyes» (Пуговки для сюртуков) (https://en.wikipedia.org/wiki/Haddocks%27_Eyes), ко- торую я вынес в эпиграф к этой главе. Редакторы Википедии пишут, что эти стихи использовались в работах по логике и философии, «чтобы прояснить символический статус понятия имени: имя – это идентифицирующий маркер, который можно связать с чем угодно, в т. ч. с другим именем, и тем самым ор- ганизовать различные уровни представления в виде символов». Дополнительная литература  229\n--- Страница 229 ---\nПоговорим Равное отношение ко всем объектам Прежде чем открыть для себя Python, я изучал Java. Оператор == в Java всегда оставлял у меня чувство неудовлетворенности. Программист обычно инте- ресуется равенством, а не тождественностью, но для объектов (в отличие от примитивных типов) оператор == сравнивает ссылки, а не значения объектов. Даже такую базовую вещь, как сравнение строк, Java заставляет делать с при- менением метода .equals. Но и в этом случае есть подвох: если при вычис - лении выражения a.equals(b) окажется, что a равно null, то возникнет исклю- чение из-за нулевого указателя. Проектировщики Java сочли необходимым переопределить для строк оператор +, так почему же не пошли дальше и не переопределили также оператор ==? В Python это сделано правильно. Оператор == сравнивает значения объектов, а оператор is – ссылки. И поскольку в Python имеется механизм перегрузки опе- раторов, то == разумно работает для всех объектов из стандартной библиотеки, включая None, каковой является обычным объектом, в отличие от null в Java. И разумеется, можно определить метод __eq__ в собственных классах, само- стоятельно решив, что должен означать для них оператор ==. Если метод __eq__ не переопределен, то он наследуется от object и сравнивает идентификаторы объектов, так что все объекты пользовательского класса по умолчанию счита- ются различными. Вот такие вещи побудили меня перейти с Java на Python, после того как в один прекрасный день в сентябре 1998 года я прочел «Учебное пособие по Python». Изменяемость Эта глава была бы излишней, если бы все объекты в Python были неизменяе- мы. Когда имеешь дело с неизменяемым объектом, не важно, хранятся ли в переменных сами объекты или ссылки на разделяемые объекты. Если a == b истинно и ни тот, ни другой объект не может измениться, то они вполне могут быть одним и тем же объектом. Вот поэтому интернирование строк и безопасно. Тождественность объектов становится важна, только если объ- екты изменяемы. В «чистом» функциональном программировании все данные неизменяемы: при добавлении элемента в коллекцию создается новая коллекция. Напри- мер, Elixir – практичный функциональный язык, в котором все встроенные типы, включая списки, неизменяемы. Но Python – не функциональный язык программирования и уж тем более не чистый. Экземпляры пользовательских классов в Python по умолчанию изменяемы – как и в большинстве объектно-ориентированных языков. Если требуется создавать неизменяемые объекты, то следует проявлять особую осторожность. Каждый атрибут такого объекта тоже должен быть неизме- няемым, иначе получится нечто, аналогичное кортежу: хотя с точки зрения идентификаторов объектов кортеж неизменяемый, его значение может из- мениться, если в нем хранятся изменяемые объекты. Изменяемые объекты – также основная причина, из-за которой так трудно написать корректную многопоточную программу: если потоки изменяют230  Ссылки на объекты, изменяемость и повторное использование\n--- Страница 230 ---\nобъекты, не заботясь о синхронизации, то данные будут повреждены. С другой стороны, если синхронизации слишком много, возникают взаимоблокировки. Язык и платформа Erlang (включающая и Elixir) проектировались, чтобы обес- печить максимально долгое непрерывное функционирование в сильно конку - рентных распределенных приложениях, например телекоммуникационных коммутаторах. Естественно, что по умолчанию данные в них неизменяемые. Уничтожение объектов и сборка мусора В Python нет механизма прямого уничтожения объекта, и это не упущение, а великое благо: если бы можно было уничтожить объект в любой момент, что стало бы с указывающими на него сильными ссылками? В CPython сборка мусора основана главным образом на механизме подсчета ссылок; он легко реализуется, но ведет к утечке памяти при наличии цикли- ческих ссылок. Поэтому в версии 2.0 (октябрь 2000) был реализован сборщик мусора на основе поколений, который умеет уничтожать группы объектов, связанных только циклическими ссылками и недостижимых извне. Но подсчет ссылок по-прежнему остается основным механизмом и приводит к немедленному уничтожению объектов, на которые не осталось ссылок. Это означает, что в CPython – по крайней мере, сейчас – безопасно такое пред- ложение: open('test.txt', 'wt', encoding='utf-8').write('1, 2, 3') Этот код безопасен, потому что счетчик ссылок на объект файла окажется ра- вен нулю после возврата из метода write, и Python немедленно закроет файл, перед тем как уничтожить объект, представляющий его в памяти. Однако в Jython или IronPython эта строка небезопасна, т. к. они пользуются более сложными сборщиками мусора в объемлющей среде выполнения (Java VM и .NET CLR соответственно), которые не опираются на подсчет ссылок и могут отложить уничтожение объекта и закрытие файла на неопределенное время. Поэтому в любом случае и, в частности, в CPython рекомендуется явно за- крывать файл, а самый надежный способ сделать это – воспользоваться пред- ложением with, которое гарантирует закрытие файла, даже если, пока он был открыт, произошло исключение. С использованием with показанный выше фрагмент можно записать так: with open('test.txt', 'wt', encoding='utf-8') as fp: fp.write('1, 2, 3') Если вас заинтересовала тема сборщиков мусора, можете почитать статью То- маса Перла «Python Garbage Collector Implementations: CPython, PyPy and GaS» (https://thp.io/2012/python-gc/python_gc_final_2012-01-22.pdf), из которой я узнал о безопасности open().write() в CPython. Передача параметров: вызов по соиспользованию Популярным объяснением механизма передачи параметров в Python является фраза: «Параметры передаются по значению, но значениями являются ссыл- ки». Нельзя сказать, что это неверно, но вводит в заблуждение, потому что в бо- лее старых языках наиболее употребительные способы передачи параметров – по значению (функция получает копию аргумента) и по ссылке (функция по- лучает указатель на аргумент). В Python функция получает копии аргументов, Дополнительная литература  231\n--- Страница 231 ---\nно аргументы всегда являются ссылками. Поэтому значение объекта, на ко- торый указывает ссылка, может измениться, если объект изменяемый, но его идентификатор – никогда. Кроме того, поскольку функция получает копию ссылки, переданной в аргументе, перепривязка не видна за пределами функ - ции. Я позаимствовал термин вызов по соиспользованию, прочитав материал на эту тему в книге Michael L. Scott «Programming Language Pragmatics», издание 3 (Morgan Kaufmann), особенно раздел 8.3.1 «Способы передачи параметров».232  Ссылки на объекты, изменяемость и повторное использование\n--- Страница 232 ---\nЧасть II Функции как объекты",
      "debug": {
        "start_page": 208,
        "end_page": 232
      }
    },
    {
      "name": "Глава 7. Функции как полноправные объекты 234",
      "content": "--- Страница 233 --- (продолжение)\nГлава 7 Функции как полноправные объекты Я никогда не считал, что на Python оказали заметное влияние функцио- нальные языки, что бы кто об этом ни говорил или ни думал. Я был значи- тельно лучше знаком с императивными языками типа C и Algol 68 и, хотя сделал функции полноправными объектами, никогда не рассматривал Python как язык функционального программирования. – Гвидо ван Россум, пожизненный великодушный диктатор Python1 Функции в Python – полноправные объекты. Теоретики языков программиро- вания определяют «полноправный объект» как элемент программы, обладаю- щий следующими свойствами: может быть создан во время выполнения; может быть присвоен переменной или полю структуры данных; может быть передан функции в качестве аргумента; может быть возвращен функцией в качестве результата. Целые числа, строки и словари – все это тоже примеры полноправных объектов в Python, так что ничего необычного тут нет. Реализация функций как полноправных объектов – необходимое свойство функциональных язы- ков, например Clojure, Elixir и Haskell. Однако полноправные функции на- столько полезны, что вошли и в другие популярные языки, в т. ч. JavaScript, Go и Java (начиная с JDK 8), ни один из которых не называет себя «функцио- нальным». В этой главе, да и в части III в целом мы будем изучать практические послед- ствия обращения с функциями как с объектами. Термин «полноправные функции» широко используется как со- кращение фразы «функции как полноправные объекты». Он не совсем точен, потому что наводит на мысль о некоей «элите» среди функций. В Python все функции полноправные. 1 «Origins of Python’s Functional Features» (http://python-history.blogspot.com/2009/04/ origins-of-pythons-functional-features.html), из блога Гвидо «История Python».\nГлава 7 Функции как полноправные объекты Я никогда не считал, что на Python оказали заметное влияние функцио- нальные языки, что бы кто об этом ни говорил или ни думал. Я был значи- тельно лучше знаком с императивными языками типа C и Algol 68 и, хотя сделал функции полноправными объектами, никогда не рассматривал Python как язык функционального программирования. – Гвидо ван Россум, пожизненный великодушный диктатор Python1 Функции в Python – полноправные объекты. Теоретики языков программиро- вания определяют «полноправный объект» как элемент программы, обладаю- щий следующими свойствами: может быть создан во время выполнения; может быть присвоен переменной или полю структуры данных; может быть передан функции в качестве аргумента; может быть возвращен функцией в качестве результата. Целые числа, строки и словари – все это тоже примеры полноправных объектов в Python, так что ничего необычного тут нет. Реализация функций как полноправных объектов – необходимое свойство функциональных язы- ков, например Clojure, Elixir и Haskell. Однако полноправные функции на- столько полезны, что вошли и в другие популярные языки, в т. ч. JavaScript, Go и Java (начиная с JDK 8), ни один из которых не называет себя «функцио- нальным». В этой главе, да и в части III в целом мы будем изучать практические послед- ствия обращения с функциями как с объектами. Термин «полноправные функции» широко используется как со- кращение фразы «функции как полноправные объекты». Он не совсем точен, потому что наводит на мысль о некоей «элите» среди функций. В Python все функции полноправные. 1 «Origins of Python’s Functional Features» (http://python-history.blogspot.com/2009/04/ origins-of-pythons-functional-features.html), из блога Гвидо «История Python».\n--- Страница 234 ---\nчтО нОвОг О в этОй главе Раздел «Девять видов вызываемых объектов» в первом издании назывался «Семь видов вызываемых объектов». Новыми являются платформенные со- программы и асинхронные генераторы, добавленные в версиях Python 3.5 и 3.6 соответственно. Те и другие рассматриваются в главе 21, но для полноты картины упомянуты здесь вместе с другими вызываемыми объектами. «Чисто позиционные параметры» – новый раздел, посвященный средству, добавленному в Python 3.8. Я перенес обсуждение доступа к аннотациям функций во время выполне- ния в раздел «Чтение аннотаций типов во время выполнения» главы 15. Ког- да я работал над первым изданием, документ PEP 484 «Type Hints» (https:// peps.python.org/pep-0484/) еще находился на этапе рассмотрения, и аннотации использовались разными людьми по-разному. Начиная с версии Python 3.5 аннотации должны соответствовать документу PEP 484. Поэтому лучше всего поместить этот материал туда, где обсуждаются аннотации типов. В первом издании книги были разделы об интроспекции объек - тов-функций, которые я счел слишком низкоуровневыми и от - влекающими внимание от основного предмета данной главы. Я объединил все эти разделы в статью «Introspection of Function Parameters» и поместил ее на сайт fluentpython.com ( https://www. fluentpython.com/extra/function-introspection/). Теперь поговорим о том, почему функции в Python являются полноправны- ми объектами. ОБращение С функцией как С ОБъект Ом В сеансе оболочки в примере 7.1 показано, что функции в Python – объекты. Мы создаем функцию, вызываем ее, читаем ее атрибут __doc__ и проверяем, что сам объект-функция является экземпляром класса function. Пример 7.1. Создаем и тестируем функцию, затем читаем ее атрибут __doc__ и опра- шиваем тип >>> def factorial(n):  \"\"\"возвращает n!\"\"\" return 1 if n < 2 else n * factorial(n – 1) >>> factorial(42) 1405006117752879898543142606244511569936384000000000 >>> factorial.__doc__  'returns n!' >>> type(factorial)  <class 'function'>  Это сеанс оболочки, т. е. мы создаем функцию «во время выполнения».  __doc__ – один из атрибутов объектов-функций.  factorial – экземпляр класса function. Обращение с функцией как с объектом  235\n--- Страница 235 ---\nАтрибут __doc__ служит для генерации текста справки по объекту. В интер- активной оболочке Python команда help(factorial) выводит информацию, по- казанную на рис. 7.1. Рис. 7.1. Справка по функции factorial . Текст берется из атрибута __doc__ объекта-функции Из примера 7.2 видна «полноправность» объекта-функции. Мы можем при- своить функцию переменной fact и вызвать ее по имени. Можем передать функцию factorial в виде аргумента функции map. Функция map возвращает ите- рируемый объект, каждый элемент которого – результат применения первого аргумента (функции) к последовательным элементам второго аргумента (ите- рируемого объекта), в данном случае range(10). Пример 7.2. Использование функции под другим именем и передача функции в качестве аргумента >>> fact = factorial >>> fact <function factorial at 0x > >>> fact(5) 120 >>> map(factorial, range(11)) <map object at 0x > >>> list(map(factorial, range(11))) [1, 1, 2, 6, 24, 120, 720, 5040, 40320, 362880, 3628800] Полноправность функций открывает возможности для программирования в функциональном стиле. Один из отличительных признаков функционально- го программирования (https://en.wikipedia.org/wiki/Functional_programming) – ис- пользование функций высшего порядка. функции выСшег О пОрядка Функцией высшего порядка называется функция, которая принимает функцию в качестве аргумента или возвращает в качестве значения. Примером может служить функция map из примера 7.2. Другой пример – встроенная функция sorted: ее необязательный аргумент key позволяет задать функцию, которая применяется к каждому сортируемому элементу, как было показано в разделе «Метод list.sort и встроенная функция sorted» главы 2. Например, чтобы отсор- тировать список слов по длине, достаточно передать функцию len в качестве аргумента key, как в примере 7.3.236  Функции как полноправные объекты\n--- Страница 236 ---\nПример 7.3. Сортировка списка слов по длине >>> fruits = ['strawberry', 'fig', 'apple', 'cherry', 'raspberry', 'banana'] >>> sorted(fruits, key=len) ['fig', 'apple', 'cherry', 'banana', 'raspberry', 'strawberry'] >>> В роли ключа может выступать любая функция с одним аргументом. Напри- мер, для создания словаря рифм полезно отсортировать слова в обратном по- рядке букв. Обратите внимание, что в примере 7.4 сами слова не изменяются, но поскольку они отсортированы в обратном порядке букв, то все ягоды (berry) оказались рядом. Пример 7.4. Сортировка списка слов в обратном порядке букв >>> def reverse(word): return word[::-1] >>> reverse('testing') 'gnitset' >>> sorted(fruits, key=reverse) ['banana', 'apple', 'fig', 'raspberry', 'strawberry', 'cherry'] >>> В функциональной парадигме программирования хорошо известны следу - ющие функции высшего порядка: map, filter, reduce, apply. Функция apply была объ- явлена нерекомендуемой в версии Python 2.3 и исключена из Python 3, пото- му что в ней отпала необходимость. Чтобы вызвать функцию с динамическим набором аргументов, достаточно написать fn(*args, **keywords) вместо apply(fn, args, kwargs) . Функции map, filter и reduce пока никуда не делись, но, как показано в следую- щем разделе, в большинстве случаев им есть лучшие альтернативы. Современные альтернативы функциям map, filter и reduce В функциональных языках программирования обычно имеются функции выс- шего порядка map, filter и reduce (иногда под другими именами). Функции map и filter по-прежнему встроены в Python 3, но с появлением списковых включе- ний и генераторных выражений потеряли былую значимость. Как списковое включение, так и генераторное выражение могут сделать то же, что комбина- ция map и filter, только код будет выглядеть понятнее. Взгляните на пример 7.5. Пример 7.5. Списки факториалов, порожденные функциями map и filter, а также альтер- натива в виде спискового включения >>> list(map(factorial, range(6)))  [1, 1, 2, 6, 24, 120] >>> [factorial(n) for n in range(6)]  [1, 1, 2, 6, 24, 120] >>> list(map(factorial, filter(lambda n: n % 2, range(6))))  [1, 6, 120] >>> [factorial(n) for n in range(6) if n % 2]  [1, 6, 120] >>> Функции высшего порядка  237\n--- Страница 237 ---\n Построить список факториалов от 0! до 5!.  Та же операция с помощью спискового включения.  Список факториалов нечетных чисел до 5!, построенный с использованием map и filter.  Списковое включение делает то же самое, заменяя map и filter и делая не- нужным лямбда-выражение. В Python 3 функции map и filter возвращают генераторы – вариант итерато- ра – поэтому безо всяких проблем могут быть заменены генераторным выра- жением (в Python 2 эти функции возвращали списки, поэтому их ближайшим аналогом было списковое включение). Функция reduce, которая в Python 3 была встроенной, теперь «понижена в звании» и перенесена в модуль functools. В той ситуации, где она чаще всего применялась, а именно для суммирования, удобнее встроенная функция sum, включенная в версию Python 2.3 в 2003 году. Она дает большой выигрыш в пла- не удобочитаемости и производительности (см. пример 7.6). Пример 7.6. Суммирование целых чисел до 99 с помощью reduce и sum >>> from functools import reduce  >>> from operator import add  >>> reduce(add, range(100))  4950 >>> sum(range(100))  4950 >>>  Начиная с версии Python 3.0 функция reduce больше не является встроенной.  Импортировать модуль add, чтобы не создавать функцию для сложения двух чисел.  Вычислить сумму целых чисел, не больших 99.  Решение той же задачи с помощью функции sum; импортировать reduce и add больше не нужно. Общая идея функций sum и reduce – применить некую операцию к каждому элементу последовательности с аккумулированием результатов и тем самым свести (редуцировать) последователь- ность значений к одному. Редуцирующими являются также встроенные функции all и any: all(iterable) Возвращает True, если каждый элемент объекта iterable «похож на истин- ный»; all([]) возвращает True. any(iterable) Возвращает True, если хотя бы один элемент объекта iterable «похож на ис- тинный»; all([]) возвращает False. Более полное объяснение reduce я приведу в разделе «Vector, попытка № 4: хеширование и ускорение оператора ==» главы 12, где будет подходящий кон- 238  Функции как полноправные объекты\n--- Страница 238 ---\nтекст для использования этой функции. А в разделе «Функции редуцирования итерируемого объекта» главы 17, где основной темой обсуждения будут итери- руемые объекты, мы подведем итоги. Иногда для передачи функциям высшего порядка удобно создать неболь- шую одноразовую функцию. Для этого и предназначены анонимные функции. анОнимные функции Ключевое слово lambda служит для создания анонимной функции внутри вы- ражения Python. Однако в силу простоты синтаксиса тело лямбда-функции может быть толь- ко чистым выражением. Иными словами, тело lambda не может содержать дру- гих предложений Python, таких как while, try и т. д. Присваивание оператором = – тоже предложение, поэтому внутри lambda его быть не может. Можно исполь- зовать новый синтаксис выражения присваивания :=, но если вы испытываете в этом необходимость, то, наверное, ваше лямбда-выражение слишком слож - ное и читать его будет трудно, поэтому лучше преобразовать его в обычную функцию, начинающуюся с def. Особенно удобны анонимные функции в списке аргументов функции выс- шего порядка. Так, в примере 7.7 код построения словаря рифм из примера 7.4 переписан с помощью lambda, без определения функции reverse. Пример 7.7. Сортировка списка слов в обратном порядке букв с помощью lambda >>> fruits = ['strawberry', 'fig', 'apple', 'cherry', 'raspberry', 'banana'] >>> sorted(fruits, key=lambda word: word[::-1]) ['banana', 'apple', 'fig', 'raspberry', 'strawberry', 'cherry'] >>> Помимо задания аргументов функций высшего порядка, анонимные функ - ции редко используются в Python. Из-за синтаксических ограничений нетри- виальные лямбда-выражения либо не работают, либо оказываются малопо- нятны. Если lambda читается с трудом, то настоятельно рекомендую последовать совету Фредрика Лундха. Рецепт рефакторинга лямбда-выражений Лундха Если вы не можете понять какой-то фрагмент кода из-за использования в нем lambda, последуйте совету Фредрика Лундха: 1. Напишите комментарий, объясняющий, что делает lambda. 2. Внимательно изучите этот комментарий и придумайте имя, в котором за- ключалась бы суть изложенного в нем. 3. Преобразуйте lambda в предложение def, указав придуманное вами имя. 4. Удалите комментарий. Эти шаги взяты из документа «Functional Programming HOWTO» (http:// docs.python.org/3/howto/functional.html), который должен прочитать каждый. Анонимные функции  239\n--- Страница 239 ---\nКонструкция lambda – не более чем синтаксический сахар: лямбда-выражение создает объект-функцию точно так же, как предложение def. Это лишь один из нескольких видов вызываемых объектов в Python. В следующем разделе рас- смотрены все. девять вид Ов вызываемых ОБъект Ов Оператор вызова () можно применять не только к функциям. Чтобы понять, является ли объект вызываемым, воспользуйтесь встроенной функцией callable() . В документации по модели данных Python для версии 3.9 перечисле- но девять вызываемых типов. Пользовательские функции Создаются с помощью предложения def или лямбда-выражений. Встроенные функции Функции, написанные на языке C (в случае CPython), например len или time.strftime . Встроенные методы Методы, написанные на C, например dict.get. Методы Функции, определенные в теле класса. Классы При вызове класс выполняет свой метод __new__, чтобы создать экземпляр, затем вызывает метод __init__ для его инициализации и, наконец, возвра- щает экземпляр вызывающей программе. Поскольку в Python нет операто- ра new, вызов класса аналогичен вызову функции1. Экземпляры классов Если в классе определен метод __call__, то его экземпляры можно вызывать как функции – это тема следующего раздела. Генераторные функции Функции или методы, в теле которых используется ключевое слово yield. При вызове генераторная функция возвращает объект-генератор. Платформенные сопрограммы Функции или методы, определенные с помощью async def. При вызове они возвращают объект сопрограммы. Добавлены в Python 3.5. Асинхронные генераторные функции Функции или методы, определенные с помощью async def, в теле которых используется ключевое слово yield. При вызове генераторная функция воз- вращает асинхронный генератор с async for. Добавлены в Python 3.6. 1 Обычно при вызове класса создается экземпляр именно этого класса, но такое пове- дение можно изменить, переопределив метод __new__. Соответствующий пример будет приведен в разделе «Гибкое создание объектов с помощью метода __new__» главы 22.240  Функции как полноправные объекты\n--- Страница 240 ---\nГенераторы, платформенные сопрограммы и асинхронные генераторные функции отличаются от других вызываемых объектов тем, что возвращаемые ими значения являются не данными приложения, а объектами, которые нуж- даются в последующей обработке, в процессе которой отдают данные прило- жению или выполняют полезную работу. Генераторные функции возвращают итераторы. Им посвящена глава 17. Платформенные сопрограммы и асинхрон- ные генераторные функции возвращают объекты, которые работают только в сочетании с каким-нибудь каркасом асинхронного программирования, на- пример asyncio. Они рассматриваются в главе 21. Учитывая разнообразие вызываемых типов в Python, самый безопас ный способ узнать, является ли объект вызываемым, – воспользоваться встроенной функцией callable() : >>> abs, str, 'Ni!' (<built-in function abs>, <class 'str'>, 'Ni!') >>> [callable(obj) for obj in (abs, str, 'Ni!')] [True, True, False] Теперь займемся созданием экземпляров классов, ведущих себя как вызы- ваемые объекты. пОльзОватель Ские вызываемые типы Мало того что в Python функции являются настоящими объектами, так еще и любой объект можно заставить вести себя как функция. Для этого нужно лишь реализовать метод экземпляра __call__. В примере 7.8 реализован класс BingoCage. Экземпляр этого класса строится из любого итерируемого объекта и хранит внутри себя список элементов в слу - чайном порядке. При вызове экземпляра из списка удаляется один элемент1. Пример 7.8. bingocall.py: экземпляр BingoCage делает всего одну вещь: выбирает эле- менты из перемешанного списка import random class BingoCage: def __init__(self, items): self._items = list(items)  random.shuffle(self._items)  def pick(self):  try: return self._items.pop() except IndexError: raise LookupError('pick from empty BingoCage')  def __call__(self):  return self.pick() 1 Зачем создавать класс BingoCage , если уже есть функция random.choice ? Дело в том, что функция choice может вернуть один и тот же элемент несколько раз, поскольку вы- бранный элемент не удаляется из коллекции. Вызов BingoCage никогда не возвращает дубликатов, если, конечно, все значения в коллекции уникальные. Пользовательские вызываемые типы  241\n--- Страница 241 ---\n Метод __init__ принимает произвольный итерируемый объект; создание локальной копии предотвращает изменение списка, переданного в качест- ве аргумента.  Метод shuffle гарантированно работает, потому что self._items – объект типа list.  Основной метод.  Возбудить исключение со специальным сообщением, если список self._ items пуст.  Позволяет писать просто bingo() вместо bingo.pick() . Ниже приведена простая демонстрация этого кода. Обратите внимание, что объект bingo можно вызывать как функцию, и встроенная функция callable() распознает его как вызываемый объект: >>> bingo = BingoCage(range(3)) >>> bingo.pick() 1 >>> bingo() 0 >>> callable(bingo) True Класс, в котором реализован метод __call__, – простой способ создать по- хожий на функцию объект, обладающий внутренним состоянием, которое должно сохраняться между вызовами, как, например, остающиеся элементы в BingoCage. Еще один хороший пример – декоратор. Декоратор должен быть вы- зываемым объектом, и иногда удобно иметь возможность «запоминать» что- то между вызовами декоратора (например, в случае кеширования результатов длительных вычислений для последующего использования) или разбить слож - ную реализацию на несколько методов. Функциональный подход к созданию функций, имеющих внутреннее состоя- ние, дают замыкания. Замыкания, как и декораторы, рассматриваются в главе 9. Теперь исследуем развитый синтаксис, предлагаемый Python для объявле- ния формальных параметров функции и передачи в них фактических аргу - ментов. От пОзициОнных к чиСтО именОванным параметрам Одна из самых замечательных особенностей функций в Python – чрезвычайно гибкий механизм обработки параметров, дополненный в Python 3 чисто име- нованными аргументами. С этой темой тесно связано использование * и ** для распаковки итерируемых объектов и отображений в отдельные аргументы при вызове функции. Чтобы понять, как это выглядит на практике, взгляните на код в примере 7.9 и результат его выполнения в примере 7.10. Пример 7.9. Функция tag генерирует HTML; чисто именованный аргумент class_ служит для передачи атрибута «class». Это обходное решение необходимо, потому что в Python class – зарезервированное слово def tag(name, *content, class_=None, **attrs): \"\"\"Сгенерировать один или несколько HTML-тегов\"\"\"242  Функции как полноправные объекты\n--- Страница 242 ---\nif class_ is not None: attrs['class'] = class_ attr_pairs = (f' {attr}=\"{value}\"' for attr, value in sorted(attrs.items())) attr_str = ''.join(attr_pairs) if content: elements = (f'<{name}{attr_str}>{c}</{name}>' for c in content) return '\\n'.join(elements) else: return f'<{name}{attr_str} />' Функцию tag можно вызывать различными способами, как показано в при- мере 7.10. Пример 7.10. Некоторые из многочисленных способов вызвать функцию tag из при- мера 7.9 >>> tag('br')  '<br />' >>> tag('p', 'hello')  '<p>hello</p>' >>> print(tag('p', 'hello', 'world')) <p>hello</p> <p>world</p> >>> tag('p', 'hello', id=33)  '<p id=\"33\">hello</p>' >>> print(tag('p', 'hello', 'world', class_='sidebar'))  <p class=\"sidebar\">hello</p> <p class=\"sidebar\">world</p> >>> tag(content='testing', name=\"img\")  '<img content=\"testing\" />' >>> my_tag = {'name': 'img', 'title': 'Sunset Boulevard', 'src': 'sunset.jpg', 'class': 'framed'} >>> tag(**my_tag)  '<img class=\"framed\" src=\"sunset.jpg\" title=\"Sunset Boulevard\"/>  При задании одного позиционного аргумента порождает пустой тег с та- ким именем.  Любое число аргументов после первого поглощается конструкцией *content и помещается в кортеж.  Именованные аргументы, которые не перечислены явно в сигнатуре функ - ции tag, поглощаются конструкцией **attrs и помещаются в словарь.  Параметр class можно передать только с помощью именованного аргумента.  Первый позиционный аргумент тоже можно передать как именованный.  Если словарю my_tag предшествуют две звездочки **, то все его элементы пере- даются как отдельные аргументы, затем некоторые связываются c именован- ными параметрами, а остальные поглощаются конструкцией **attrs. В этом случае в словаре аргументов может присутствовать ключ 'class', потому что это строка, так что конфликта с зарезервированным словом class нет. Чисто именованные аргументы – возможность, появившаяся в Python 3. В примере 7.9 параметр class_ может быть передан только как именованный От позиционных к чисто именованным параметрам  243\n--- Страница 243 ---\nаргумент – он никогда не поглощается неименованными позиционными ар- гументами. Чтобы задать чисто именованные аргументы в определении функ - ции, указывайте их после аргумента с префиксом *. Если вы вообще не хотите поддерживать позиционные аргументы, оставив тем не менее возможность, задавать чисто именованные, включите в сигнатуру звездочку * саму по себе: >>> def f(a, *, b): return a, b >>> f(1, b=2) (1, 2) >>> f(1, 2) Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: f() takes 1 positional argument but 2 were given Отметим, что у чисто именованных аргументов может и не быть значения по умолчанию, они могут быть обязательными, как b в предыдущем примере. Чисто позиционные параметры Начиная с версии Python 3.8 в сигнатурах пользовательских функций можно задавать чисто позиционные параметры. Такая возможность всегда существо- вала для встроенных функций, например divmod(a, b) , которую можно вызывать только с позиционными параметрами, но не в виде divmod(a=10, b=4) . Чтобы определить функцию, требующую чисто позиционных параметров, используйте символ / в списке параметров. Следующий пример из раздела документации «What’s New In Python 3.8» (https://docs.python.org/3/whatsnew/3.8.html#positional-only-parameters) показывает, как эмулировать встроенную функцию divmod: def divmod(a, b, /): return (a // b, a % b) Все аргументы слева от / чисто позиционные. После / можно задавать и дру - гие аргументы, они будут работать, как обычно. Наличие / в списке параметров считается синтаксической ошиб- кой в версии Python 3.7 и более ранних. Например, рассмотрим функцию tag из примера 7.9. Если мы хотим, чтобы параметр name был чисто позиционным, то можем добавить после него / в сиг - натуре функции. def tag(name, /, *content, class_=None, **attrs): Другие примеры чисто позиционных параметров можно найти в разделе документации «What’s New In Python 3.8» и в документе PEP 570 (https://peps. python.org/pep-0570/). Разобравшись с гибкими средствами объявления аргументов, мы посвятим оставшуюся часть главы рассмотрению наиболее полезных пакетов, включен- 244  Функции как полноправные объекты\n--- Страница 244 ---\nных в стандартную библиотеку ради поддержки функционального стиля про- граммирования. пакеты для функциОнальнОг О прОграммир Ования Хотя Гвидо ясно дал понять, что Python не задумывался как язык функциональ- ного программирования, в нем тем не менее можно применять функциональ- ный стиль кодирования – благодаря полноправным функциям, сопоставлению с образцом и таким пакетам, как operator и functools, которые мы рассмот рим в следующих двух разделах. Модуль operator В функциональном программировании часто бывает удобно использовать арифметический оператор как функцию. Пусть, например, требуется перемно- жить последовательность чисел для нерекурсивного вычисления факториа- ла. Для суммирования можно воспользоваться функцией sum, но аналогичной функции для умножения не существует. Можно было бы применить функцию reduce, как было показано в разделе «Современные альтернативы функциям map, filter и reduce» выше, но для этого необходима функция умножения двух элементов последовательности. В примере 7.11 показано, как решить эту за- дачу с помощью lambda. Пример 7.11. Вычисление факториала с помощью reduce и анонимной функции from functools import reduce def factorial(n): return reduce(lambda a, b: a*b, range(1, n+1)) Чтобы избавить нас от необходимости писать тривиальные анонимные функции вида lambda a, b: a*b , модуль operator предоставляет функции, экви- валентные многим арифметическим операторам. С его помощью пример 7.11 можно переписать следующим образом. Пример 7.12. Вычисление факториала с помощью reduce и operator.mul from functools import reduce from operator import mul def factorial(n): return reduce(mul, range(1, n+1)) Модуль operator включает также функции для выборки элементов из после- довательностей и чтения атрибутов объектов: itemgetter и attrgetter строят спе- циализированные функции для выполнения этих действий. В примере 7.13 показано типичное применение itemgetter : сортировка спис- ка кортежей по значению одного поля. В этом примере печатаются города, отсортированные по коду страны (поле 1). По существу, itemgetter(1) создает функцию, которая получает коллекцию и возвращает элемент с индексом 1. Это проще писать и читать, чем выражение lambda fields: fields[1] , которое делает то же самое. Пакеты для функционального программирования  245\n--- Страница 245 ---\nПример 7.13. Результат применения itemgetter для сортировки списка кортежей (дан- ные взяты из примера 2.8) >>> metro_data = [ ('Tokyo', 'JP', 36.933, (35.689722, 139.691667)), ('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889)), ('Mexico City', 'MX', 20.142, (19.433333, -99.133333)), ('New York-Newark', 'US', 20.104, (40.808611, -74.020386)), ('São Paulo', 'BR', 19.649, (-23.547778, -46.635833)), ] >>> >>> from operator import itemgetter >>> for city in sorted(metro_data, key=itemgetter(1)): print(city) ('São Paulo', 'BR', 19.649, (-23.547778, -46.635833)) ('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889)) ('Tokyo', 'JP', 36.933, (35.689722, 139.691667)) ('Mexico City', 'MX', 20.142, (19.433333, -99.133333)) ('New York-Newark', 'US', 20.104, (40.808611, -74.020386)) Если передать функции itemgetter несколько индексов, то она построит функ - цию, которая возвращает кортеж, содержащий выбранные значения. Это по- лезно, когда нужно сортировать по нескольким ключам. >>> for city in metro_data: print(cc_name(city)) ('JP', 'Tokyo') ('IN', 'Delhi NCR') ('MX', 'Mexico City') ('US', 'New York-Newark') ('BR', 'São Paulo') >>> Поскольку itemgetter пользуется оператором [], то поддерживает не только последовательности, но и отображения, да и вообще любой класс, в котором реализован метод __getitem__ . Близким родственником itemgetter является функция attrgetter , которая соз- дает функции для извлечения атрибутов объекта по имени. Если передать attrgetter несколько имен атрибутов, то она также создаст функцию, возвра- щающую кортеж значений. Кроме того, если имя аргумента содержит точки, то attrgetter обойдет вложенные объекты для извлечения атрибута. Описанные возможности продемонстрированы в примере 7.14. Сеанс оболочки получился довольно длинным, потому что нам пришлось построить вложенную структу - ру для демонстрации обработки имен атрибутов с точкой. Пример 7.14. Применение attrgetter для обработки ранее определенного списка име- нованных кортежей metro_data (тот же список, что в примере 7.13) >>> LatLon = namedtuple('LatLon', 'lat lon')  >>> Metropolis = namedtuple('Metropolis', 'name cc pop coord')  >>> metro_areas = [Metropolis(name, cc, pop, LatLon(lat, lon))  for name, cc, pop, (lat, lon) in metro_data] >>> metro_areas[0] Metropolis(name='Tokyo', cc='JP', pop=36.933,246  Функции как полноправные объекты\n--- Страница 246 ---\ncoord=LatLon(lat=35.689722, lon=139.691667)) >>> metro_areas[0].coord.lat  35.689722 >>> from operator import attrgetter >>> name_lat = attrgetter('name', 'coord.lat')  >>> >>> for city in sorted(metro_areas, key=attrgetter('coord.lat')):  print(name_lat(city))  ('São Paulo', -23.547778) ('Mexico City', 19.433333) ('Delhi NCR', 28.613889) ('Tokyo', 35.689722) ('New York-Newark', 40.808611)  Определить именованный кортеж LatLon.  Определить также Metropolis .  Построить список metro_areas , содержащий экземпляры Metropolis ; обратите внимание на распаковку именованного кортежа для извлечения (lat, lon) и использование этих данных для построения объекта LatLon, являющегося значением атрибута coord объекта Metropolis .  Получить широту из элемента metro_areas[0] .  Определить attrgetter для выборки атрибута name и вложенного атрибута coord.lat.  Снова использовать attrgetter для сортировки списка городов по широте.  Использовать определенный выше attrgetter для показа только названия и широты города. Ниже приведен неполный список функций в модуле operator (имена, начи- нающиеся знаком подчеркивания, опущены, потому что такие функции со- держат детали реализации): >>> [name for name in dir(operator) if not name.startswith('_')] ['abs', 'add', 'and_', 'attrgetter', 'concat', 'contains', 'countOf', 'delitem', 'eq', 'floordiv', 'ge', 'getitem', 'gt', 'iadd', 'iand', 'iconcat', 'ifloordiv', 'ilshift', 'imatmul', 'imod', 'imul', 'index', 'indexOf', 'inv', 'invert', 'ior', 'ipow', 'irshift', 'is_', 'is_not', 'isub', 'itemgetter', 'itruediv', 'ixor', 'le', 'length_hint', 'lshift', 'lt', 'matmul', 'methodcaller', 'mod', 'mul', 'ne', 'neg', 'not_', 'or_', 'pos', 'pow', 'rshift', 'setitem', 'sub', 'truediv', 'truth', 'xor'] Назначение большинства из этих 54 функций очевидно. Функции, имена которых начинаются с i и далее содержат имя оператора, например iadd, iand и т. д., соответствуют составным операторам присваивания: +=, &= и т. д. Они изменяют свой первый аргумент на месте, если это изменяемый объект; в про- тивном случае функция работает так же, как аналогичная без префикса i: прос- то возвращает результат операции. Из прочих функций мы рассмотрим только methodcaller . Она похожа на attrgetter и itemgetter в том смысле, что на лету создает функцию. Эта функция вызывает метод по имени для объекта, переданного в качестве аргумента (пример 7.15). Пакеты для функционального программирования  247\n--- Страница 247 ---\nПример 7.15. Демонстрация methodcaller : во втором тесте показано связывание допол- нительных аргументов >>> from operator import methodcaller >>> s = 'The time has come' >>> upcase = methodcaller('upper') >>> upcase(s) 'THE TIME HAS COME' >>> hyphenate = methodcaller('replace', ' ', '-') >>> hyphenate(s) 'The-time-has-come' Первый тест в примере 7.15 просто показывает, как работает функция methodcaller , но вообще-то если нужно использовать метод str.upper как функ - цию, то можно просто вызвать его от имени класса str, передав строку в качест- ве аргумента: >>> str.upper(s) 'THE TIME HAS COME' Второй тест показывает, что methodcaller позволяет также фиксировать не- которые аргументы – так же, как функция functools.partial . Это и будет нашей следующей темой. Фиксация аргументов с помощью functools.partial В модуле functools собраны некоторые функции высшего порядка. Мы видели функцию reduce в разделе «Современные альтернативы функциям map, filter и reduce» выше. Еще одна функция – partial: получив на входе вызываемый объект, она порождает новый вызываемый объект, в котором некоторые ар- гументы исходного объекта связаны с заранее определенными значениями. Это полезно для адаптации функции, принимающей один или несколько ар- гументов, к API, требующему обратного вызова функции с меньшим числом аргументов. Тривиальная демонстрация приведена в примере 7.16. Пример 7.16. Использование partial позволяет вызывать функцию с двумя аргумента- ми там, где требуется вызываемый объект с одним аргументом >>> from operator import mul >>> from functools import partial >>> triple = partial(mul, 3)  >>> triple(7)  21 >>> list(map(triple, range(1, 10)))  [3, 6, 9, 12, 15, 18, 21, 24, 27]  Создать новую функцию triple из mul, связав первый аргумент со значением 3.  Протестировать ее.  Использовать triple совместно с map; mul в этом примере не смогла бы рабо- тать с map. Более полезный пример относится к функции unicode.normalize , с которой мы встречались в разделе «Нормализация Unicode для правильного сравнения» главы 4. Для многих языков перед сравнением или сохранением строки реко- мендуется нормализовывать с помощью вызова unicode.normalize('NFC', s) . Если 248  Функции как полноправные объекты\n--- Страница 248 ---\nэто приходится делать часто, то удобно завести функцию nfc, как показано в примере 7.17. Пример 7.17. Построение вспомогательной функции нормализации Unicode-строк с помощью partial >>> nfc = functools.partial(unicodedata.normalize, 'NFC') >>> s1 = 'café' >>> s2 = 'cafe\\u0301' >>> s1, s2 ('café', 'café') >>> s1 == s2 False >>> nfc(s1) == nfc(s2) True Функция partial принимает в первом аргументе вызываемый объект, а за ним – произвольное число позиционных и именованных аргументов, подле- жащих связыванию. В примере 7.18 демонстрируется использование partial совместно с функ - цией tag из примера 7.9 для фиксации одного позиционного и одного имено- ванного аргумента. Пример 7.18. Применение partial к функции tag из примера 7.9 >>> from tagger import tag >>> tag <function tag at 0x10206d1e0>  >>> from functools import partial >>> picture = partial(tag, 'img', class_='pic-frame')  >>> picture(src='wumpus.jpeg') '<img class=\"pic-frame\" src=\"wumpus.jpeg\" />'  >>> picture functools.partial(<function tag at 0x10206d1e0>, 'img', class_='pic-frame')  >>> picture.func  <function tag at 0x10206d1e0> >>> picture.args ('img',) >>> picture.keywords {'cls': 'pic-frame'}  Импортировать функцию tag из примера 7.9 и показать ее идентификатор.  Создать функцию picture из tag, зафиксировав значение первого позицион- ного аргумента – 'img' и значение именованного параметра class_ – 'pic-frame'.  Функция picture работает, как и ожидалось.  partial() возвращает объект functools.partial1.  У объекта functools.partial есть атрибуты, дающие доступ к исходной функ - ции и фиксированным аргументам. 1 Из исходного кода (https://github.com/python/cpython/blob/0bbf30e2b910bc9c5899134ae9d 73a8df968 da35/Lib/functools.py#L341) в скрипте functools.py становится ясно, что класс functools.partial реализован на C и используется по умолчанию. Если он недоступен, то начиная с версии Python 3.4 в модуле functools имеется реализация partial на чис- том Python. Пакеты для функционального программирования  249\n--- Страница 249 ---\nФункция functools.partialmethod делает то же, что partial, но предназначена для работы с методами. Модуль functools включает также функции высшего порядка, рассчитанные на использование в качестве декораторов, в частности cache и singledispatch. Мы рассмотрим их в главе 9, где также обсуждается, как реализовать пользова- тельские декораторы. резюме Целью этой главы было исследование функций как полноправных объектов Python. Идея в том, что функции можно присваивать переменным, передавать другим функциям, сохранять в структурах данных, а также получать атрибуты функций, что позволяет каркасам и инструментальным средствам принимать те или иные решения. Функции высшего порядка, основа функционального программирования, час то используются в программах на Python. Встроенные функции sorted, min, max и functools.partial – примеры распространенных функций высшего порядка. Функ - ции map, filter и reduce употребляются реже, чем в былые времена, – благодаря спис- ковому включению (и аналогичным конструкциям, например генераторным вы- ражениям) и наличию встроенных редуцирующих функций типа sum, all и any. Начиная с версии Python 3.6 в языке имеется девять видов вызываемых объектов: от простых функций, создаваемых с помощью lambda, до экземпля- ров классов, в которых реализован метод __call__. Генераторы и сопрограммы также являются вызываемыми объектами, хотя и совсем не похожими на дру- гие. Все вызываемые объекты распознаются встроенной функцией callable() . Любой вызываемый объект поддерживает общий развитый синтаксис объяв- ления формальных параметров, в том числе чисто именованные параметры, чисто позиционные параметры и аннотации. Наконец, мы рассмотрели несколько функций из модуля operator и функцию functools.partial , которая упрощает функциональное программирование за счет уменьшения потребности в синтаксисе лямбда-выражений. дОпО лнительная литература В следующих двух главах мы продолжим изучение программирования с помо- щью объектов-функций. Глава 8 посвящена аннотациям типов в параметрах и возвращаемых значениях функций. Тема главы 9 – декораторы, специаль- ный вид функций высшего порядка, и механизм замыкания, благодаря кото- рому декораторы и работают. В главе 10 показано, как полноправные функции упрощают некоторые классические паттерны объектно-ориентированного программирования. В разделе 3.2 «Иерархия стандартных типов» справочного руководства по язы- ку Python (https://docs.python.org/3/reference/datamodel.html#the-standard-type-hierarchy) описаны все девять вызываемых типов, а также остальные встроенные типы. Глава 7 книги David Beazley, Brian K. Jones «Python Cookbook», 3-е издание (O’Reilly), отлично дополняет эту и девятую главу, поскольку к объяснению тех же концепций подходит по-другому.250  Функции как полноправные объекты\n--- Страница 250 ---\nЕсли вас интересуют причины, по которым в язык были включены чисто именованные аргументы, а также примеры их использования, обратитесь к документу PEP 3102 «Keyword-Only Arguments» (https://www.python.org/dev/ peps/pep-3102/). Отличное введение в функциональное программирование на Python – со- ставленный А. М. Кухлингом документ «Python Functional Programming HOWTO» (http://docs.python.org/3/howto/functional.html). Но в основном он посвящен исполь- зованию итераторов и генераторов, которые рассматриваются в главе 17. На заданный на сайте StackOverflow вопрос «Зачем нужна функция functools.partial в Python» (https://stackoverflow.com/questions/3252228/python-why- is-functools-partial-necessary) в высшей степени информативный ответ дал Алекс Мартелли, соавтор классической книги «Python in a Nutshell» (O’Reilly). Размышляя над вопросом, является ли Python функциональным языком, я создал одну из своих любимых презентаций, «Beyond Paradigms», которую представлял на конференциях PyCaribbean, PyBay и PyConDE. См. слайды (https://speakerdeck.com/ramalho/beyond-paradigms-berlin-edition) и видео (https:// www.youtube.com/watch?v=bF3a2VYXxa0) с презентации в Берлине, где я повстре- чался с Мирославом Седивым и Юргеном Гмахом, которые вошли в число тех- нических рецензентов этой книги. Поговорим Является ли Python функциональным языком? Где-то в 2000 году я проходил обучение на курсах компании Zope Corporation в США, когда в аудиторию заглянул Гвидо ван Россум (он не преподавал). В последовавшей серии вопросов и ответов кто-то спросил, какие функции Python заимствовал из других языков. Гвидо ответил: «Все, что есть хорошего в Python, украдено из других языков». Шрирам Кришнамурти (Shriram Krishnamurthi), профессор информатики в Брауновском университете, начинает свою статью «Teaching Programming Languages in a Post-Linnaean Age» (http://cs.brown.edu/~sk/Publications/Papers/ Published/sk-teach-pl-post-linnaean/) такими словами: «Парадигмы» языков программирования – отжившее и никому не нужное наследие ушедшего века. Проектировщики современных языков не обращают на них никакого внимания, так почему же на учебных курсах мы так рабски им привержены? В той же статье упоминается и Python: Что еще сказать о таких языках, как Python, Ruby или Perl? У их про- ектировщиков не было терпения изучать красоты линнеевских иерар- хий; они брали те функциональные возможности, которые считали нужными, творя смеси, не поддающиеся никакой классификации. Кришнамурти предлагает не пытаться классифицировать языки, следуя зара- нее выбранной таксономии, а рассматривать их как агрегаты функциональных возможностей. Его идеи вдохновили меня на создание презентации «Beyond Paradigms», упомянутой в конце раздела «Дополнительная литература». Дополнительная литература  251\n--- Страница 251 ---\nИ хотя Гвидо не ставил такой цели, включение в Python полноправных функ - ций распахнуло двери функциональному программированию. В сообщении «Origins of Python’s Functional Features» Гвидо пишет, что именно функции map, filter и reduce стали поводом для реализации в Python лямбда-выражений (http://python-history.blogspot.com/2009/04/origins-of-pythons-functional-features.html ). Все эти средства предложил для включения в Python 1.0 Амрит Прем (Amrit Prem) в 1994 году, согласно файлу Misc/HISTORY по адресу http://hg.python.org/ cpython/file/ default/Misc/HISTORY в дереве исходного кода CPython. Такие функции, как lambda, map, filter и reduce, впервые появились в Lisp, первом функциональном языке программирования. Однако в Lisp не налагаются огра- ничения на то, что можно делать внутри lambda, потому что в Lisp любая кон- струкция является выражением. В Python принят синтаксис, основанный на предложениях; выражения в нем не могут содержать предложения, а многие языковые конструкции являются предложениями – в том числе блок try/catch, которого мне особенно не хватает в лямбда-выражениях. Такова цена, которую приходится платить за в высшей степени удобочитаемый синтаксис1. У языка Lisp много сильных сторон, но удобочитаемость не из их числа. По иронии судьбы, заимствование синтаксиса спискового включения из дру- гого функционального языка, Haskell, заметно сократило потребность в map и filter, да, кстати, и в lambda. Помимо ограничений синтаксиса анонимных функций, основным препят - ствием для более широкого принятия идиом функционального программи- рования в Python является отсутствие устранения хвостовой рекурсии – опти- мизации, которая уменьшает потребление памяти функцией, выполняющей рекурсивный вызов в конце своего тела. В другом сообщении, «Tail Recursion Elimination» (http://neopythonic.blogspot.com/2009/04/tail-recursion-elimination.html), Гвидо приводит несколько причин, по которым такая оптимизация плохо под- ходит для Python. Это сообщение весьма интересно технической аргумента- цией, но еще более тем, что первые три – самые важные – причины касаются удобства пользования. Тот факт, что использование, изучение и преподавание Python доставляет массу удовольствия, – не случайность. Гвидо специально стремился к этому. Итак: Python по своему замыслу не является функциональным языком – что бы под этим ни понимать. Python лишь заимствует кое-какие удачные идеи из функциональных языков. Проблема анонимных функций Помимо синтаксических ограничений, связанных со спецификой Python, у анонимных функций есть серьезный недостаток в любом языке: отсутствие имени. И это лишь наполовину шутка. Трассировку стека проще читать, если у функций есть имена. Анонимные функции удобны, когда нужно сре- зать угол, программисты любят их писать, но иногда слишком увлекают - ся – особенно если язык и среда поощряют глубокую вложенность аноним- ных функций, как, скажем, JavaScript в среде Node.js. Большое количество вложенных анонимных функций усложняет отладку и обработку ошибок. 1 Еще есть проблема потери отступов при копировании кода в веб-форумы, но это я отвлекся.252  Функции как полноправные объекты\n--- Страница 252 ---\nАсинхронное программирование в Python более структурировано, быть может, потому что ограничения лямбда-выражений препятствуют злоупо- треблениям и заставляют искать более явные подходы. Обещания, будущие и отложенные объекты – концепции, используемые в API асинхронного про- граммирования. Наряду с сопрограммами они открывают выход из так на- зываемого «ада обратных вызовов». Обещаю рассказать подробнее об асин- хронном программировании в будущем, но эту тему отложу до главы 21. Дополнительная литература  253",
      "debug": {
        "start_page": 233,
        "end_page": 252
      }
    },
    {
      "name": "Глава 8. Аннотации типов в функциях 254",
      "content": "--- Страница 253 --- (продолжение)\nГлава 8 Аннотации типов в функциях Следует также подчеркнуть, что Python останется динамически типи- зированным языком, и у авторов нет ни малейшего желания когда- нибудь делать аннотации типов обязательными, пусть даже в силу соглашения. – Гвидо ван Россум, Юкка Лехтосало и Лукаш Ланга, PEP 484 «Type Hints»1 Аннотации типов – самое большое изменение в истории Python после унифи- кации типов и классов (https://www.python.org/download/releases/2.2.3/descrintro/) в Python 2.2 в 2001 году. Однако аннотации типов устраивают не всех пользо- вателей Python, поэтому они должны быть факультативными. В документе PEP 484 «Type Hints» (https://peps.python.org/pep-0484/) описаны синтаксис и семантика явных объявлений типов в аргументах функций, воз- вращаемых значениях и переменных. Цель – помочь инструментам разработ - ки искать ошибки в кодовых базах на Python с помощью статического анализа, т. е. не выполняя тестов кода. Основными выгодоприобретателями являются профессиональные про- граммисты, пользующиеся интегрированными средами разработки (IDE) и системами непрерывной интеграции (CI). Анализ преимуществ и недостат - ков, доказывающий привлекательность аннотаций типов для этой группы, распространяется не на всех пользователей Python. Круг пользователей Python гораздо шире. Он включает, в частности, науч- ных работников, трейдеров, журналистов, художников, производителей, ана- литиков и студентов многих специальностей. Для большинства из них плата за изучение аннотаций типов, скорее всего, окажется несоразмерно высокой, если только они уже незнакомы с каким-нибудь языком, имеющим статиче- ские типы, механизм создания подтипов и обобщенные типы. А преимущест - ва для многих из них окажутся не столь ощутимыми, учитывая характер их работы с Python, а также меньший размер кодовой базы и команды – зачастую «команда» состоит из одного человека. Динамическая типизация Python, под- разумеваемая по умолчанию, проще и выразительнее, когда нужно написать код для исследования данных и идей, как то бывает в науке о данных, приме- нении компьютеров для творчества и обучения. Эта глава посвящена аннотациям типов в сигнатурах функций, а в главе 15 мы изучим аннотации типов в контексте классов, а также другие средства, имеющиеся в модуле typing. 1 PEP 484 – Type Hints, «Rationale and Goals»; сохранено выделение оригинала.\nГлава 8 Аннотации типов в функциях Следует также подчеркнуть, что Python останется динамически типи- зированным языком, и у авторов нет ни малейшего желания когда- нибудь делать аннотации типов обязательными, пусть даже в силу соглашения. – Гвидо ван Россум, Юкка Лехтосало и Лукаш Ланга, PEP 484 «Type Hints»1 Аннотации типов – самое большое изменение в истории Python после унифи- кации типов и классов (https://www.python.org/download/releases/2.2.3/descrintro/) в Python 2.2 в 2001 году. Однако аннотации типов устраивают не всех пользо- вателей Python, поэтому они должны быть факультативными. В документе PEP 484 «Type Hints» (https://peps.python.org/pep-0484/) описаны синтаксис и семантика явных объявлений типов в аргументах функций, воз- вращаемых значениях и переменных. Цель – помочь инструментам разработ - ки искать ошибки в кодовых базах на Python с помощью статического анализа, т. е. не выполняя тестов кода. Основными выгодоприобретателями являются профессиональные про- граммисты, пользующиеся интегрированными средами разработки (IDE) и системами непрерывной интеграции (CI). Анализ преимуществ и недостат - ков, доказывающий привлекательность аннотаций типов для этой группы, распространяется не на всех пользователей Python. Круг пользователей Python гораздо шире. Он включает, в частности, науч- ных работников, трейдеров, журналистов, художников, производителей, ана- литиков и студентов многих специальностей. Для большинства из них плата за изучение аннотаций типов, скорее всего, окажется несоразмерно высокой, если только они уже незнакомы с каким-нибудь языком, имеющим статиче- ские типы, механизм создания подтипов и обобщенные типы. А преимущест - ва для многих из них окажутся не столь ощутимыми, учитывая характер их работы с Python, а также меньший размер кодовой базы и команды – зачастую «команда» состоит из одного человека. Динамическая типизация Python, под- разумеваемая по умолчанию, проще и выразительнее, когда нужно написать код для исследования данных и идей, как то бывает в науке о данных, приме- нении компьютеров для творчества и обучения. Эта глава посвящена аннотациям типов в сигнатурах функций, а в главе 15 мы изучим аннотации типов в контексте классов, а также другие средства, имеющиеся в модуле typing. 1 PEP 484 – Type Hints, «Rationale and Goals»; сохранено выделение оригинала.\n--- Страница 254 ---\nВ этой главе будут рассмотрены следующие вопросы: практическое введение в постепенную типизацию на примере Mypy; дополнительные возможности утиной и номинальной типизации; обзор основных категорий типов, которые могут встречаться в аннота- циях (это примерно 60 % главы); аннотации типов с переменным числом параметров ( *args, **kwargs); ограничения и недостатки аннотаций типов и статической типизации. чтО нОвОг О в этОй главе Вся эта глава новая. Аннотации типов появились в версии Python 3.5 уже после того, как я закончил работу над первым изданием книги. С учетом ограничений статической системы типов лучшее, что мог предло- жить документ PEP 484, – внедрение системы постепенной типизации. Начнем с определения того, что этот термин означает. О пОСтепеннОй типизации В документе PEP 484 описано включение системы постепенных типов в Python. Из других языков с системой постепенных типов назовем TypeScript от Microsoft, Dart (язык Flutter SDK, созданный Google) и Hack (диалект PHP, поддерживаемый виртуальной машиной HHVM от Facebook). Сама программа проверки типов Mypy начиналась как язык: постепенно типизированный диалект Python со своим соб- ственным интерпретатором. Гвидо ван Россум убедил создателя Mypy, Юкку Лех- тосало, превратить его в инструмент для проверки аннотированного Python-кода. Система постепенной типизации обладает следующими характеристиками. Является факультативной По умолчанию средство проверки типов не должно выдавать предупреж - дений для кода без аннотаций типов. Вместо этого оно должно предпола- гать тип Any, если не может определить тип объекта. Тип Any считается со- вместимым с любым другим. Не обнаруживает ошибки типизации во время выполнения Аннотации типов используются средствами проверки типов, линтерами и IDE для выдачи предупреждений. Они не препятствуют ни передаче не- согласованных значений функциям, ни присваиванию их переменным во время выполнения. Не увеличивает производительность Аннотации типов предоставляют сведения, которые теоретически могли бы открыть возможность оптимизаций сгенерированного байт-кода, но по состоянию на июль 2021 года такие оптимизации не реализованы ни в од- ной из известных мне сред выполнения Python1. 1 JIT-компилятор, например имеющийся в PyPy, располагает куда более полными дан- ными, чем аннотации типов: он наблюдает за Python-программой во время ее вы- полнения, видит, какие конкретно типы она использует, и генерирует оптимизиро- ванный машинный код именно для этих типов. О постепенной типизации  255\n--- Страница 255 ---\nСамая важная для пользователей особенность постепенной типизации – тот факт, что аннотации всегда факультативны. При использовании статической системы типов большинство ограничений на типы выразить легко, многие неудобно, некоторые трудно, а совсем немно- гие невозможно1. Мы без труда сможем написать прекрасный код на Python, с хорошим тестовым покрытием, но при этом не сумеем добавить аннотации типов, которые удовлетворили бы средство проверки. Ничего страшного – прос- то опустите проблематичные аннотации типов и пускайте в эксплуатацию! Аннотации типов факультативны на всех уровнях: можно встретить целые пакеты без единой аннотации, можно подавить проверку типов при импорте такого пакета в модуль, где аннотации используются, и можно добавить спе- циальные комментарии, заставляющие средство проверки типов игнориро- вать конкретные строки кода. Стремление к стопроцентному покрытию аннотациями типов означает, что вы применяете аннотирование без ясной цели, просто ради красивых показателей. К тому же это будет мешать команде добиться максимума от мощи и гибкости Python. Код без аннотаций типов должен без колебаний приниматься, если аннотации сделали бы API менее удобным для пользователя или без нужды усложнили бы реализацию. пОСтепенная типизация на практике Посмотрим, как постепенная типизация работает на практике. Начнем с прос- той функции и будем постепенно добавлять в нее аннотации типов, под руко- водством Mypy. Существует несколько программ проверки типов для Python, со- вместимых с PEP 484, в т. ч. Google pytype (https://github.com/google/ pytype), Microsoft Pyright (https://github.com/Microsoft/pyright), Facebook Pyre (https://pyre-check.org/) – и это помимо средств, встроенных в IDE типа PyCharm. Я выбрал для примеров Mypy ( https://mypy. readthedocs.io/en/stable/), потому что она самая известная. Но для каких-то проектов или команд другая программа может оказать- ся более подходящей. К примеру, Pytype проектировалась так, что может работать с кодовыми базами без аннотаций типов и тем не менее давать полезные советы. Она более снисходительна, чем Mypy, и умеет сама генерировать аннотации для вашего кода. Мы будем аннотировать функцию show_count , которая возвращает строку, со- держащую счетчик и слово в единственном или множественном числе в зави- симости от значения счетчика: >>> show_count(99, 'bird') '99 birds' 1 Например, по состоянию на июль 2021 года рекурсивные типы не поддержива- лись – см. проблему #182, зарегистрированную для модуля typing: «Define a JSON type» (https://github.com/python/typing/issues/182), и проблему #731 для Mypy «Support recursive types» (https://github.com/python/mypy/issues/731). 256  Аннотации типов в функциях\n--- Страница 256 ---\n>>> show_count(1, 'bird') '1 bird' >>> show_count(0, 'bird') 'no birds' В примере 8.1 приведен исходный код show_count без аннотаций. Пример 8.1. Функция show_count из модуля messages.py без аннотаций типов def show_count(count, word): if count == 1: return f'1 {word}' count_str = str(count) if count else 'no' return f'{count_str} {word}s' Начинаем работать с Mypy Чтобы приступить к проверке типов, я применил команду mypy к модулю messages.py: …/no_hints/ $ pip install mypy [много сообщений опущено ] …/no_hints/ $ mypy messages.py Success: no issues found in 1 source file Mypy с параметрами по умолчанию не нашла никаких ошибок в примере 8.1. Я пользуюсь версией Mypy 0.910, последней по состоянию на июль 2021 года. Во «Введении» к Mypy есть предупреждение, что «офи- циально это бета-версия. Возможны изменения, нарушающие об- ратную совместимость». Mypy выдала как минимум одно сообще- ние, отличающееся от того, которые я получал в апреле 2020 года, когда писал эту главу. Не исключено, что когда вы будете ее чи- тать, результаты будут отличаться от представленных здесь. Если в сигнатуре функции нет аннотаций, то Mypy по умолчанию игнориру - ет ее, если не была сконфигурирована иначе. В примере 8.2 приведены автономные тесты, рассчитанные на pytest. Пример 8.2. Файл messages_test.py без аннотаций типов from pytest import mark from messages import show_count @mark.parametrize('qty, expected', [ (1, '1 part'), (2, '2 parts'), ]) def test_show_count(qty, expected): got = show_count(qty, 'part') assert got == expected def test_show_count_zero(): got = show_count(0, 'part') assert got == 'no parts' Постепенная типизация на практике  257\n--- Страница 257 ---\nТеперь под чутким руководством Mypy добавим аннотации типов. А теперь построже Параметр командной строки --disallow-untyped-defs заставляет Mypy помечать все определения функций, в которых нет аннотаций типов для всех парамет- ров и возвращаемого значения. Задав --disallow-untyped-defs для тестового файла, мы получим три сообщения об ошибках и одно примечание: …/no_hints/ $ mypy --disallow-untyped-defs messages_test.py messages.py:14: error: Function is missing a type annotation messages_test.py:10: error: Function is missing a type annotation messages_test.py:15: error: Function is missing a return type annotation messages_test.py:15: note: Use \"-> None\" if function does not return a value Found 3 errors in 2 files (checked 1 source file) Начиная добавлять постепенную типизацию, я предпочитаю задавать дру- гой параметр: --disallow-incomplete-defs . Сначала он не говорит ничего: …/no_hints/ $ mypy --disallow-incomplete-defs messages_test.py Success: no issues found in 1 source file Теперь попробую аннотировать в show_count только возвращаемое значение: def show_count(count, word) -> str: Этого достаточно, чтобы Mypy обратила на функцию внимание. Та же ко- манда, что и выше, примененная для проверки messages_test.py, побудит Mypy снова взглянуть на messages.py: …/no_hints/ $ mypy --disallow-incomplete-defs messages_test.py messages.py:14: error: Function is missing a type annotation for one or more arguments Found 1 error in 1 file (checked 1 source file) Теперь я могу постепенно добавлять аннотации типов к одной функции за другой, не получая предупреждений для еще не аннотированных функций. Вот как выглядит полностью аннотированная сигнатура, удовлетворяющая Mypy: def show_count(count: int, word: str) -> str: Вместо того чтобы задавать параметры типа --disallow-incomplete- defs в командной строке, можно сохранить те, которыми вы поль- зуетесь особенно часто, в конфигурационном файле Mypy. Пара- метры могут задаваться глобально или на уровне модуля. Вот как может выглядеть простой файл mypy.ini в начале работы: [mypy] python_version = 3.9 warn_unused_configs = True disallow_incomplete_defs = True Значение параметра по умолчанию Функция show_count в примере 8.1 работает только с правильными именами существительными. Если множественное число образуется не добавлением 258  Аннотации типов в функциях\n--- Страница 258 ---\nбуквы 's', то мы должны дать пользователю возможность самому указать форму множественного числа, например: >>> show_count(3, 'mouse', 'mice') '3 mice' Давайте займемся «разработкой через типы». Сначала добавим тест, в кото- ром используется этот третий аргумент. Не забудем добавить аннотацию воз- вращаемого значения в тестовой функции, иначе Mypy не станет ее проверять. def test_irregular() -> None: got = show_count(2, 'child', 'children') assert got == '2 children' Mypy обнаруживает ошибку: …/hints_2/ $ mypy messages_test.py messages_test.py:22: error: Too many arguments for \"show_count\" Found 1 error in 1 file (checked 1 source file) Теперь изменим show_count , добавив необязательный параметр plural, как по- казано в примере 8.3. Пример 8.3. Функция show_count из модуля hints_2/messages.py с факультативным па- раметром def show_count(count: int, singular: str, plural: str = '') -> str: if count == 1: return f'1 {singular}' count_str = str(count) if count else 'no' if not plural: plural = singular + 's' return f'{count_str} {plural}' Теперь Mypy говорит «Success» – все хорошо. В коде ниже есть опечатка, которую Python не замечает. Сможете найти ее? def hex2rgb(color=str) -> tuple[int, int, int]: Сообщение об ошибке, выдаваемое Mypy, не сильно помогает: colors.py:24: error: Function is missing a type annotation for one or more arguments Аннотация типа для аргумента color должна иметь вид color: str. Я написал color=str , а это вообще не аннотация. Такая запись означает, что color по умолчанию имеет значение str. По моему опыту, это довольно типичная ошибка, которую легко проглядеть, особенно в сложных аннотациях типов. Следующие рекомендации считаются признаками хорошего стиля в анно- тациях типов: между именем параметра и : не должно быть пробелов, после : должен быть один пробел; по обе стороны от знака =, предшествующего значению по умолчанию, должно быть по одному пробелу. Постепенная типизация на практике  259\n--- Страница 259 ---\nС другой стороны, в документе PEP 8 говорится, что вокруг = не должно быть пробелов, если для этого конкретного параметра нет аннотации типа. Стиль кодирования: используйте flake8 и blue Вместо того чтобы запоминать всякие глупые правила, пользуйтесь инструмента- ми типа flake8 (https://pypi.org/project/flake8/) и blue ( https://pypi.org/project/blue/). flake8 в числе прочего сообщает о недочетах, связанных со стилем кодирования, а blue переписывает исходный код в соответствии с правилами (большинством из них), встроенными в средство форматирования кода black (https://pypi.org/project/black/). Если цель – навязать «стандартный» стиль кодирования, то blue лучше, чем black, потому что следует присущей Python рекомендации использовать по умолчанию одиночные кавычки, а двойные – как альтернативу: >>> \"I prefer single quotes\" 'I prefer single quotes' Предпочтение одиночным кавычкам встроено в функцию repr() и в другие места CPython. Модуль doctest (https://docs.python.org/3/library/doctest.html) зави- сит от использования одиночных кавычек в repr(). Одним из авторов blue является Барри Уорсоу (https://wefearchange.org/2020/11/ steeringcouncil.rst.html), соавтор PEP 8, разработчик ядра Python с 1994 года и член Руководящего совета Python с 2019 года по настоящее время (июль 2021 года). Выбирая одиночные кавычки по умолчанию, мы оказываемся в очень хорошей компании. Если вам позарез необходимо использовать black, то задавайте параметр black -S. Тогда кавычки в коде не будут изменены. None в качестве значения по умолчанию В примере 8.3 параметр plural аннотирован типом str, а значение по умолча- нию равно '', так что конфликта типов не возникает. Мне нравится это решение, но в других контекстах лучше использовать по умолчанию None. Если факультативный параметр имеет изменяемый тип, то None – единственно разумное значение по умолчанию, как было показано в раз- деле «Значения по умолчанию изменяемого типа: неудачная мысль» главы 6. Чтобы значением по умолчанию параметра plural было None, сигнатура долж - на выглядеть так: from typing import Optional def show_count(count: int, singular: str, plural: Optional[str] = None) -> str: Расшифруем: Optional[str] означает, что plural может иметь тип str или None; необходимо явно задать значение по умолчанию = None. Если параметру plural не сопоставлено значение по умолчанию, то среда вы- полнения Python будет рассматривать его как обязательный. Помните: на эта- пе выполнения аннотации типов игнорируются.260  Аннотации типов в функциях\n--- Страница 260 ---\nОтметим, что мы должны импортировать Optional из модуля typing. При им- портировании типов рекомендуется использовать синтаксис from typing import X , чтобы уменьшить длину сигнатур функций. Optional – не самое лучшее имя, потому что наличие аннотации не делает параметр факультативным. Чтобы параметр стал фа- культативным, ему нужно назначить значение по умолчанию. Optional[str] просто означает, что тип параметра может быть str или NoneType. В языках Haskell и Elm похожий тип называется Maybe. Теперь, составив первое представление о постепенной типизации, рассмот- рим, что концепция типа означает на практике. типы Определяют Ся тем, какие Операции Они пОддерживают В литературе есть много определений понятия типа. Здесь мы предпола- гаем, что тип – это множество значений и набор функций, применимых к этим значениям. – PEP 483 «The Theory of Type Hints» На практике полезнее рассматривать набор операций как определяющую ха- рактеристику типа1. Например, с точки зрения применимых операций, каковы допустимые типы x в следующей функции? def double(x): return x * 2 Параметр x может быть числовым (int, complex, Fraction, numpy.uint32 и т. д.), но может быть также последовательностью (str, tuple, list, array), N-мерным мас- сивом numpy.array или любым другим типом, который реализует или наследует метод __mul__, принимающий аргумент типа int. Однако рассмотрим следующую аннотированную функцию double. Не обра- щайте внимания на отсутствие типа возвращаемого значения, давайте сосре- доточимся на типе параметра: from collections import abc def double(x: abc.Sequence): return x * 2 Средство проверки типа отвергнет этот код. Если вы скажете Mypy, что x имеет тип abc.Sequence, то она пометит выражение x * 2 как ошибку, потому 1 В Python нет синтаксиса для управления множеством допустимых значений типа, если не считать типов Enum. Например, с помощью аннотаций типов невозможно определить тип Quantity как множество целых чисел от 1 до 1000 или тип AirportCode как трехбуквенную аббревиатуру. NumPy предлагает типы uint8, int16 и другие ма- шинно-ориентированные числовые типы, но в стандартной библиотеке Python есть только типы с очень небольшим числом значений (NoneType, bool) или очень большим множеством значений ( float, int, str, все кортежи и т. д.). Типы определяются тем, какие операции они поддерживают  261\n--- Страница 261 ---\nчто абстрактный базовый тип Sequence (https://docs.python.org/3/library/ collections. abc.html#collections-abstract-base-classes) не реализует и не наследует метод __mul__. Во время выполнения этот код будет работать с конкретными последователь- ностями, такими как str, tuple, list, array и т. д., а также с числами, потому на эта- пе выполнения аннотации типов игнорируются. Но для средства проверки ти- пов важно лишь то, что объявлено явно, а в классе abc.Sequence метода __mul__ нет. Потому-то этот раздел и называется «Типы определяются тем, какие опе- рации они поддерживают». Среда выполнения Python примет любой объект в качестве аргумента x для обоих вариантов функции double. Вычисление x * 2 может закончиться успешно или возбудить исключение TypeError, если опера- ция не поддерживается x. С другой стороны, Mypy, проанализировав анноти- рованный код double, сообщит, что выражение x * 2 недопустимо, потому что для объявленного типа x: abc.Sequence операция не поддерживается. В системе постепенной типизации сталкиваются два разных взгляда на типы: Утиная типизация Этот взгляд принят в Smalltalk – первопроходческом объектно-ориентиро- ванном языке, а также в Python, JavaScript и Ruby. У объектов есть типы, но переменные (в т. ч. параметры) не типизированы. На практике не важно, каков объявленный тип объекта, важно лишь, какие операции он факти- чески поддерживает. Если я могу вызвать метод birdie.quack() , то в данном контексте birdie является уткой. По определению, утиная типизация всту - пает в действие только на этапе выполнения, когда предпринимается по- пытка выполнить какую-то операцию объекта. Это более гибкий подход, чем номинальная типизация, но расплачиваться за гибкость приходится большим числом ошибок на этапе выполнения1. Номинальная типизация Этот взгляд принят в C++, Java и C# и поддерживается в Python с аннотация- ми. У объектов и переменных есть типы. Но объекты существуют только во время выполнения, а средство проверки типов имеет дело лишь с ис - ходным кодом, в котором переменные (в т. ч. параметры) аннотированы типами. Если Duck – подкласс Bird, то экземпляр типа Duck можно присво- ить параметру, аннотированному как birdie: Bird . Но в теле функции сред- ство проверки типов считает вызов birdie.quack() недопустимым, потому что birdie номинально принадлежит типу Bird, а в этом классе нет метода .quack(). Не важно, что фактический аргумент на этапе выполнения будет иметь тип Duck, потому что номинальная типизация проверяется статиче- ски. Средство проверки не выполняет никакую часть программы, а только читает исходный код. Это более строгий подход, чем утиная типизация, но зато он позволяет отлавливать некоторые ошибки на более ранних стадиях конвейера сборки, иногда даже в процессе ввода кода в IDE. 1 Утиная типизация – неявная форма структурной типизации, которая в Python ≥ 3.8 поддерживается также благодаря добавлению typing.Protocol . Эта тема обсуждается ниже в данной главе – в разделе «Статические протоколы», а затем более подробно в главе 13.262  Аннотации типов в функциях\n--- Страница 262 ---\nПример 8.4 – незамысловатая иллюстрация противопоставления утиной и номинальной типизаций, а также статической проверки типов и поведения на этапе выполнения1. Пример 8.4. birds.py class Bird: pass class Duck(Bird):  def quack(self): print('Quack!') def alert(birdie):  birdie.quack() def alert_duck(birdie: Duck) -> None:  birdie.quack() def alert_bird(birdie: Bird) -> None:  birdie.quack()  Duck – подкласс Bird.  alert не имеет аннотаций типов, поэтому средство проверки типов ее игно- рирует.  alert_duck принимает один аргумент типа Duck.  alert_bird принимает один аргумент типа Bird. Проверка birds.py с помощью Mypy вскрывает проблему: …/birds/ $ mypy birds.py birds.py:16: error: \"Bird\" has no attribute \"quack\" Found 1 error in 1 file (checked 1 source file) Проанализировав только исходный код, Mypy увидела, что в alert_bird есть ошибка: в аннотации параметр birdie объявлен как имеющий тип Bird, но в теле функции вызывается birdie.quack() , хотя в классе Bird нет такого метода. Теперь попробуем воспользоваться модулем birds в файле daffy.py (при- мер 8.5). Пример 8.5. daffy.py from birds import * daffy = Duck() alert(daffy)  alert_duck(daffy)  alert_bird(daffy)   Допустимый вызов, потому что для alert нет аннотаций типов.  Допустимый вызов, потому что alert_duck принимает аргумент типа Duck, а daffy как раз и имеет тип Duck. 1 Наследованием часто злоупотребляют, и его применение трудно оправдать в при- мерах одновременно простых и реалистичных, поэтому примите данный пример с животными как элементарную иллюстрацию подтипов. Типы определяются тем, какие операции они поддерживают  263\n--- Страница 263 ---\n Допустимый вызов, потому что alert_bird принимает аргумент типа Bird, а тип daffy, Duck, является подклассом Bird. Применение Mypy к daffy.py выдает ту же ошибку по поводу вызова quack в функции alert_bird , определенной в файле birds.py: …/birds/ $ mypy daffy.py birds.py:16: error: \"Bird\" has no attribute \"quack\" Found 1 error in 1 file (checked 1 source file) Но Mypy видит проблему не в самом файле daffy.py: все три вызова функций не вызывают возражений. Запустив скрипт daffy.py, мы получим: …/birds/ $ python3 daffy.py Quack! Quack! Quack! Все работает! Пригодность утиной типизации подтверждена! На этапе выполнения Python не обращает внимания на объявленные типы. Он пользуется только утиной типизацией. Mypy сочла функцию alert_bird оши- бочной, но ее вызов для daffy работает правильно. У многих питонистов это поначалу вызывает удивление: средство статической проверки типов иногда находит ошибки там, где, как мы знаем, все работает нормально. Однако если по прошествии нескольких месяцев вас попросят расширить этот глупейший пример, то, возможно, вы скажете Mypy спасибо. Взгляните на модуль woody.py, в котором также используется birds (пример 8.6). Пример 8.6. woody.py from birds import * woody = Bird() alert(woody) alert_duck(woody) alert_bird(woody) При проверке woody.py Mypy обнаруживает две ошибки: …/birds/ $ mypy woody.py birds.py:16: error: \"Bird\" has no attribute \"quack\" woody.py:5: error: Argument 1 to \"alert_duck\" has incompatible type \"Bird\"; expected \"Duck\" Found 2 errors in 2 files (checked 1 source file) Первая ошибка находится в файле birds.py: вызов birdie.quack() в функции alert_bird, это мы уже видели. Вторая ошибка находится в файле woody.py: woody – экземпляр Bird, поэтому вызов alert_duck(woody) недопустим, т. е. эта функция тре- бует аргумента типа Duck. Каждая утка Duck является птицей Bird, но не каждая птица Bird является уткой Duck. На этапе выполнения оба вызова в woody.py приведут к ошибке. Последова- тельность ошибок хорошо видна в консольном сеансе в примере 8.7.264  Аннотации типов в функциях\n--- Страница 264 ---\nПример 8.7. Ошибки во время выполнения и чем могла бы помочь Mypy >>> from birds import * >>> woody = Bird() >>> alert(woody)  Traceback (most recent call last): AttributeError: 'Bird' object has no attribute 'quack' >>> >>> alert_duck(woody)  Traceback (most recent call last): AttributeError: 'Bird' object has no attribute 'quack' >>> >>> alert_bird(woody)  Traceback (most recent call last): AttributeError: 'Bird' object has no attribute 'quack'  Mypy не смогла обнаружить эту ошибку, потому что для alert нет аннотаций типов.  Mypy сообщила об ошибке: Argument 1 to \"alert_duck\" has incompatible type \"Bird\"; expected \"Duck\" .  Mypy, начиная с примера 8.4, талдычит нам о том, что функция alert_bird написана неправильно: «Bird» has no attribute»quack» . Этот небольшой эксперимент показывает, что к работе с утиной типиза- цией проще приступить и она обладает большей гибкостью, но возможность, что неподдерживаемые операции приведут к ошибке во время выполнения, остается. Номинальная типизация обнаруживает ошибки до начала выпол- нения, но иногда отвергает код, который работал бы правильно – как вызов alert_bird(daffy) в примере 8.5. Даже если иногда это работает, функция alert_bird названа неудачно: в ее теле требуется объект, который поддерживает метод .quack(), а Bird его не поддерживает. В этом нехитром примере все функции занимали одну строку. Но в реальной программе они могут быть длиннее, могут передавать аргумент birdie другим функциям, а место создания аргумента birdie может отстоять от места вызова на много функций, поэтому трудно понять, что именно привело к ошибке во время выполнения. Средство проверки типов предотвращает многие ошибки такого рода на этапе выполнения. Ценность аннотаций типов сомнительна в таких крохотных примерах, которые могут поместиться в книге. Но становится более очевидной по мере увеличения размера кодовой базы. Именно поэтому компании, владеющие миллионами строк кода на Python, например Dropbox, Google и Facebook, инвестирова- ли в команды и инструменты. Их цель – поддержать внедрение аннотаций типов во всей компании и проверять типы в значи- тельной и постоянно растущей части кодовой базы в конвейере непрерывной интеграции. В этом разделе мы исследовали взаимосвязь типов и операций при ути- ной и номинальной типизациях, начав с простой функции double(), которую Типы определяются тем, какие операции они поддерживают  265\n--- Страница 265 ---\nне снабдили никакими аннотациями типов. Теперь поговорим о наиболее важных типах, используемых для аннотирования функций. Мы покажем хо- роший способ добавить аннотации типов к double(), когда дойдем до раздела «Статические протоколы». Но прежде познакомимся с дополнительными фун- даментальными типами. типы, приг Одные для иСпО льзОвания в аннО тациях Практически любой тип Python можно использовать в аннотациях типов, но есть кое-какие ограничения и рекомендации. Кроме того, модуль typing ввел в обраще- ние специальные конструкции, семантика которых иногда вызывает удивление. В этом разделе рассматриваются все основные типы, которые можно ис- пользовать в аннотациях: typing.Any ; простые типы и классы; typing.Optional и typing.Union ; коллекции общего вида, включая кортежи и отображения; абстрактные базовые классы; обобщенные итерируемые объекты; параметризованные обобщенные типы и TypeVar ; typing.Protocol – ключ к статической утиной типизации; typing.Callable ; typing.NoReturn – красноречивое завершение этого перечня. Мы рассмотрим все эти типы по очереди, начав со странного типа, который кажется бесполезным, но на самом деле крайне важен. Тип Any Краеугольным камнем системы постепенной типизации является тип Any, или динамический тип. Когда средство проверки типов видит нетипизированную функцию вида def double(x): return x * 2 оно предполагает, что: def double(x: Any) -> Any: return x * 2 Это означает, что аргумент x и возвращаемое значение могут быть любого типа, необязательно одного и того же. Считается, что тип Any поддерживает лю- бую операцию. Сравним типы Any и object. Рассмотрим такую сигнатуру: def double(x: object) -> object: Эта функция также принимает аргументы любого типа, потому что любой тип является подтипом object. Однако средство проверки типов такую функцию отвергает: def double(x: object) -> object: return x * 2266  Аннотации типов в функциях\n--- Страница 266 ---\nПроблема в том, что object не поддерживает операцию __mul__. Вот что сооб- щает Mypy: …/birds/ $ mypy double_object.py double_object.py:2: error: Unsupported operand types for * (\"object\" and \"int\") Found 1 error in 1 file (checked 1 source file) Чем более общим является тип, тем уже его интерфейс, т. е. тем меньше операций он поддерживает. Класс object реализует меньше операций, чем abc. Sequence, тот – меньше операций, чем abc.MutableSequence , а этот, в свою очередь, меньше операций, чем list. Но Any – необычный тип, который располагается и в самом верху, и в самом низу иерархии типов. Это одновременно и самый общий тип, т. е. аргумент n: Any принимает значения любого типа, и самый специализированный, т. е. под- держивает любую операцию. По крайней мере, именно так средство проверки типов воспринимает Any. Разумеется, никакой тип не может поддерживать все возможные операции, по- этому использование Any лишает средство проверки типов возможности выполнить свою основную миссию: обнаруживать потенциально некорректные операции до того, как программа аварийно завершится с исключением во время выполнения. «Является подтипом» и «совместим с» Традиционная объектно-ориентированная номинальная система типов опи- рается на отношение «является подтипом». Если дан класс T1 и подкласс T2, то T2 является подтипом T1. Рассмотрим такой код: class T1: class T2(T1): def f1(p: T1) -> None: o2 = T2() f1(o2) # OK Вызов f1(o2) – пример применения принципа подстановки Лисков (Liskov Substitution Principle – LSP). Барабара Лисков1 на самом деле определяла от- ношение «является подтипом» в терминах поддерживаемых операций: если объект типа T2 можно подставить вместо объекта типа T1 и программа будет вести себя корректно, то T2 является подтипом T1. Если продолжить предыдущий пример, то следующий код является наруше- нием LSP: def f2(p: T2) -> None: o1 = T1() f2(o1) # ошибка типизации 1 Профессор MIT, проектировщик языков программирования, лауреат премии Тью- ринга. Википедия: Barbara Liskov (https://en.wikipedia.org/wiki/Barbara_Liskov). Типы, пригодные для использования в аннотациях  267\n--- Страница 267 ---\nС точки зрения поддерживаемых операций, это вполне разумно: будучи подклассом, T2 наследует и должен поддерживать все операции T1. Поэтому экземпляр T2 можно использовать всюду, где ожидается экземпляр T1. Но об- ратное неверно: T2 может реализовывать дополнительные методы, поэтому может статься, что T1 допустимо использовать не во всех местах, где ожида- ется T2. Такое внимание к поддерживаемым операциям отражено в названии подтипизация по поведению (https://en.wikipedia.org/wiki/Behavioral_subtyping), ко- торое также используется в качестве синонима LSP. В системе постепенной типизации есть еще одно отношение: «совместим с», которое применимо везде, где применимо отношение «является подти- пом», но имеет дополнительные правила, касающиеся Any, а именно: 1. Если даны тип T1 и подтип T2, то T2 совместим с T1 (подстановка Лисков). 2. Любой тип совместим с Any: в качестве аргумента, объявленного с типом Any, можно передать объект любого типа. 3. Any совместим с любым типом: объект типа Any можно передать в качест- ве аргумента, объявленного с любым типом. Для показанных выше определений объектов o1 и o2 ниже приведены при- меры допустимого кода, иллюстрирующие правила 2 и 3: def f3(p: Any) -> None: o0 = object() o1 = T1() o2 = T2() f3(o0) # f3(o1) # все хорошо: правило 2 f3(o2) # def f4(): # неявный возвращаемый тип: `Any` o4 = f4() # выведенный тип: `Any` f1(o4) # f2(o4) # все хорошо: правило 3 f3(o4) # В любой системе постепенной типизации необходим универсальный тип наподобие Any. Слова «вывести» в контексте анализа типов – наукообразный синоним слова «угадать». Современные программы проверки типов в Python и других языках не требуют наличия аннотаций типов всюду, потому что могут вывести тип многих выражений. Например, если я напишу x = len(s) * 10 , то программе провер- ки типов не нужно видеть явное локальное объявление, чтобы понять, что x имеет тип int, при условии что она может найти аннотации типов для встроенной функции len. Теперь можно перейти к изучению остальных типов, используемых в анно- тациях. 268  Аннотации типов в функциях\n--- Страница 268 ---\nПростые типы и классы Простые типы, такие как int, float, str и bytes, можно использовать в аннотаци- ях типов напрямую. Конкретные классы из стандартной библиотеки, внешних пакетов или определенные пользователем – FrenchDeck , Vector2d или Duck – тоже можно использовать в аннотациях. В аннотациях типов могут быть полезны и абстрактные базовые классы. Мы вернемся к ним при изучении типов коллекций и в разделе «Абстрактные базовые классы» ниже. Для классов отношение «совместим с» определяется как «является подклас - сом»: подкласс совместим со всеми своими суперклассами. Однако «практичность важнее чистоты», поэтому существует важное ис- ключение, которое составляет предмет следующей врезки. INT совместим с COMPLEX Номинально не существует отношения подтипа между встроен- ными типами int, float и complex: все они являются прямыми под- классами object. Но в документе PEP 484 декларировано (https:// peps.python.org/pep-0484/#the-numeric-tower), что тип int совместим с float, а float совместим с complex. Это имеет смысл на практике: int реализует все операции, которые реализует float, плюс до- полнительные: &, |, << и т. д. Итог: int совместим с complex. Если i = 3, то i.real равно 3, а i.imag равно 0. Типы Optional и Union В разделе «None в качестве значения по умолчанию» мы встречались со спе- циальным типом Optional. Он решает проблему использования None в качестве значения по умолчанию, как в следующем примере из того же раздела: from typing import Optional def show_count(count: int, singular: str, plural: Optional[str] = None) -> str: Конструкция Optional[str] фактически является сокращенной записью Union[str, None] , которая означает, что типом plural может быть str или None. Улучшенный синтаксис Optional и Union в Python 3.10 Начиная с версии Python 3.10 мы можем писать str | bytes вместо Union[str, bytes] . Это короче и не нужно импортировать Optional и Union из модуля typing. Сравните старый и новый синтаксисы аннотаций типов для параметра plural функции show_count : plural: Optional[str] = None # до plural: str | None = None # после Оператор | можно также применять в сочетании с isinstance и issubclass для построения второго аргумента: isinstance(x, int | str) . Дополнительные сведения см. в документе PEP 604 «Complementary syntax for Union[]» (https://peps.python.org/pep-0604/). Сигнатура встроенной функции ord – простой пример Union: она принимает str или bytes и возвращает int1: 1 Точнее, ord принимает только объект типа str или bytes, для которого len(s) == 1 . Но в настоящее время система типов не позволяет выразить такое ограничение. Типы, пригодные для использования в аннотациях  269\n--- Страница 269 ---\ndef ord(c: Union[str, bytes]) -> int: Ниже приведен пример функции, которая принимает str, но может вернуть str или float: from typing import Union def parse_token(token: str) -> Union[str, float]: try: return float(token) except ValueError: return token По возможности избегайте создания функций, возвращающих типы Union, поскольку они возлагают дополнительную ответственность на пользователя – он должен проверять тип возвращенного значения во время выполнения, что- бы знать, что с ним делать. Но функция parse_token выше – разумный пример использования в контексте простого вычислителя выражений. В разделе «Двухрежимный API» главы 4 мы видели функции, которые принимают аргументы типа str или bytes, но возвра- щают str, если аргумент имел тип str, и bytes, если он имел тип bytes. В таких случаях тип возвращаемого значения определяет - ся типом входа, поэтому Union – не совсем подходящее решение. Чтобы правильно аннотировать подобные функции, нам нужна переменная-тип (см. раздел «Параметризованные обобщенные типы и TypeVar») или перегрузка – как будет показано в разделе «Перегруженные сигнатуры». Union[] требует по меньшей мере двух типов. Вложенные типы Union дают та- кой же эффект, как линеаризованный Union. То есть аннотация типа Union[A, B, Union[C, D, E]] – то же самое, что Union[A, B, C, D, E] Union полезнее в сочетании с типами, не совместимыми между собой. На- пример, Union[int, float] избыточно, потому что int совместим с float. Если просто воспользоваться float для аннотирования параметра, то значения типа int тоже будут считаться допустимыми. Обобщенные коллекции Большинство коллекций в Python гетерогенны. Например, в список list можно поместить значения произвольных типов, необязательно одинаковых. Но на практике это не очень полезно: помещая элементы в коллекцию, мы, скорее всего, хотим впоследствии производить над ними какие-то операции, и обыч- но это означает, что у всех элементов должен быть хотя бы один общий метод1. 1 В языке ABC, оказавшем наибольшее влияние на начальный проект Python, списки могли содержать значения только одного типа, а именно того, которому принадле- жал первый помещенный в список элемент. 270  Аннотации типов в функциях\n--- Страница 270 ---\nПри объявлении обобщенных типов можно указывать тип элементов, кото- рые они могут обрабатывать. Например, list можно параметризовать, ограничив типы содержащихся в списке элементов, как показано в примере 8.8. Пример 8.8. Функция tokenize с аннотациями типов для Python ≥ 3.9 def tokenize(text: str) -> list[str]: return text.upper().split() В версиях Python ≥ 3.9 это означает, что tokenize возвращает список list, в ко - тором каждый элемент имеет тип str. Аннотации stuff: list и stuff: list[Any] означают одно и то же: stuff может быть списком объектов любого типа. В версиях Python 3.8 и более ранних концепция та же, но кода нужно написать больше – см. врезку «Поддержка унаследован- ных типов и нерекомендуемые типы коллекций» ниже. В документе PEP 585 «Type Hinting Generics In Standard Collections» (https:// peps.python.org/pep-0585/#implementation) перечислены коллекции из стандарт - ной библиотеки, принимающие аннотации обобщенных типов. В следующем списке приведены только те коллекции, которые принимают простейшую ан- нотацию вида container[item] : list collections.deque abc.Sequence abc.MutableSequence set abc.Container abc.Set abc.MutableSet frozenset abc.Collection Типы кортежа и отображения поддерживают и более сложные аннотации типов, как будет показано в соответствующих разделах. В версии Python 3.10 нет хорошего способа аннотировать array.array , который принимал бы во внимание аргумент конструктора typecode, определяющий, ка- кие числа хранятся в массиве: целые или с плавающей точкой. Еще более труд- ная проблема – как проверить диапазон целочисленных типов, чтобы во время выполнения предотвратить исключение OverflowError при добавлении элементов в массивы. Например, array с typecode='B' может хранить только значения типа int от 0 до 255. В настоящее время статическая система типов в Python не умеет справляться с этой задачей. Поддержка унаследованных типов и нерекомендуемые типы коллекций (Если вы работаете только с версией Python 3.9 или более поздней, можете пропустить этот материал.) В Python 3.7 и 3.8 необходимо импортировать модуль __future__ , чтобы но- тация [] работала со встроенными коллекциями, в частности list (см. при- мер 8.9). Типы, пригодные для использования в аннотациях  271\n--- Страница 271 ---\nПример 8.9. Функция tokenize с аннотациями типов в Python ≥ 3.7 from __future__ import annotations def tokenize(text: str) -> list[str]: return text.upper().split() Импорт __future__ не работает с версией Python 3.6 и более ранними. В примере 8.10 показано, как аннотировать функцию tokenize способом, рабо- тающим с Python ≥ 3.5. Пример 8.10. Функция tokenize с аннотациями типов в Python ≥ 3.5 from typing import List def tokenize(text: str) -> List[str]: return text.upper().split() Чтобы с чего-то начать поддержку аннотаций обобщенных типов, авторы PEP 484 создали десятки обобщенных типов в модуле typing. В табл. 8.1 показаны некоторые из них. Полный список см. в документации (https:// docs.python.org/3/library/ typing.html). Таблица 8.1. Некоторые типы коллекций и соответствующие им аннотации типов Коллекция Соответствующая аннотация типа list typing.List set typing.Set frozenset typing.FrozenSet collections.deque typing.Deque collections.abc.MutableSequence typing.MutableSequence collections.abc.Sequence typing.Sequence collections.abc.Set typing.AbstractSet collections.abc.MutableSet typing.MutableSet Документом PEP 585 «Type Hinting Generics In Standard Collections» (https:// peps.python.org/pep-0585/) был начат многолетний процесс улучшения аннота- ций обобщенного типа с точки зрения удобства пользования. Он состоял из четырех шагов. 1. Включить в Python 3.7 предложение from __future__ import annotations , чтобы стандартные библиотечные классы можно было использовать как обоб- щенные с помощью нотации list[str]. 2. Сделать это поведение подразумеваемым по умолчанию в Python 3.9: те- перь list[str] работает без импорта future. 3. Объявить нерекомендуемыми избыточные обобщенные типы из модуля typing1. Предупреждения о нерекомендуемости не будут выдаваться ин- терпретатором Python, потому что средства проверки типов должны по- 1 Я и сам внес вклад в документацию по модулю typing – добавил десятки предупреж - дений о нерекомендуемости, когда под чутким руководством Гвидо ван Россума раз- бивал раздел «Содержимое модуля» на подразделы.272  Аннотации типов в функциях\n--- Страница 272 ---\nмечать нерекомендуемые типы, когда проверяемая программа рассчитана на версию Python 3.9 или более новую. 4. Удалить избыточные обобщенные типы из первой же версии Python, вы- пущенной спустя пять лет после выхода Python 3.9. При нынешнем темпе выхода версий это будет версия Python 3.14 или Python Pi. Теперь посмотрим, как включать в аннотации обобщенные типы. Типы кортежей Существует три способа аннотировать тип кортежа: кортежи как записи; кортежи как записи с именованными полями; кортежи как неизменяемые последовательности. Кортежи как записи Если кортеж используется как запись, то возьмите встроенный тип tuple и объ - явите типы полей в квадратных скобках []. Например, если мы хотим принимать кортежи, содержащие название горо- да, численность населения в нем и страну: ('Shanghai', 24.28, 'China') , то аннота- ция типа должна выглядеть так: tuple[str, float, str] . Рассмотрим функцию, которая принимает географические координаты и возвращает объект Geohash (https://en.wikipedia.org/wiki/Geohash), используе- мый следующим образом: >>> shanghai = 31.2304, 121.4737 >>> geohash(shanghai) 'wtw3sjq6q' В примере 8.11 показано, как функция geohash определяется с использовани- ем пакета geolib из архива PyPI. Пример 8.11. coordinates.py с функцией geohash from geolib import geohash as gh # type: ignore  PRECISION = 9 def geohash(lat_lon: tuple[float, float]) -> str:  return gh.encode(*lat_lon, PRECSION)  Эта команда не дает Mypy ругаться на то, что в пакете geolib нет аннотаций типов.  Параметр lat_lon аннотирован типом tuple с двумя полями типа float. Для версий Python < 3.9 импортируйте и используйте typing.Tuple в аннотациях типов. Такая практика не рекомендуется, но оста- нется в стандартной библиотеке по крайней мере до 2024 года. Типы, пригодные для использования в аннотациях  273\n--- Страница 273 ---\nКортежи как записи с аннотированными полями Чтобы использовать в аннотациях кортеж, содержащий много полей, или конкретные типы кортежей, которые встречаются во многих местах кода, я настоя тельно рекомендую взять тип typing.NamedTuple , описанный в главе 5. В примере 8.12 показан вариант примера 8.11 с NamedTuple . Пример 8.12. coordinates_named.py с NamedTupleCoordinates и функцией geohash from typing import NamedTuple from geolib import geohash as gh # type: ignore PRECISION = 9 class Coordinate(NamedTuple): lat: float lon: float def geohash(lat_lon: Coordinate) -> str: return gh.encode(*lat_lon, PRECISION) Как было объяснено в разделе «Обзор построителей классов данных» главы 5, класс typing.NamedTuple является фабрикой подклассов tuple, так что тип Coordinate совместим с tuple[float, float] , но обратное неверно – ведь у Coordinate есть допол- нительные методы, добавленные NamedTuple , например ._asdict() , и могут быть также определенные пользователем методы. На практике это означает, что можно безопасно передать экземпляр Coordinate функции display, определенной следующим образом: def display(lat_lon: tuple[float, float]) -> str: lat, lon = lat_lon ns = 'N' if lat >= 0 else 'S' ew = 'E' if lon >= 0 else 'W' return f'{abs(lat):0.1f}°{ns}, {abs(lon):0.1f}°{ew}' Кортежи как неизменяемые последовательности Чтобы включить в аннотацию кортеж неопределенной длины, используемый как неизменяемый список, необходимо задать один тип, за которым следуют запятая и многоточие (это лексема Python, составленная из трех точек, а не символ Unicode U+2026 – HORIZONTAL ELLIPSIS ). Например, tuple[int, ] – кортеж, состоящий из элементов типа int. Многоточие означает, что допустимо любое число элементов >= 1. Не сущест - вует способа задать поля разных типов в кортежах произвольной длины. Аннотации stuff: tuple[Any, ] и stuff: tuple означают одно и то же: stuff яв- ляется кортежем неопределенной длины, содержащим объекты любого типа. В примере ниже функция columnize преобразует последовательность в табли- цу, строки которой представляют собой список кортежей неопределенной дли- ны. Это полезно, когда нужно отобразить элементы по столбцам: >>> animals = 'drake fawn heron ibex koala lynx tahr xerus yak zapus'.split() >>> table = columnize(animals) >>> table274  Аннотации типов в функциях\n--- Страница 274 ---\n[('drake', 'koala', 'yak'), ('fawn', 'lynx', 'zapus'), ('heron', 'tahr'), ('ibex', 'xerus')] >>> for row in table: print(''.join(f'{word:10}' for word in row)) drake koala yak fawn lynx zapus heron tahr ibex xerus В примере 8.13 показана реализация columnize. Обратите внимание на тип возвращаемого значения: list[tuple[str, ]] Пример 8.13. columnize.py возвращает список кортежей строк from collections.abc import Sequence def columnize( sequence: Sequence[str], num_columns: int = 0 ) -> list[tuple[str, ]]: if num_columns == 0: num_columns = round(len(sequence) ** 0.5) num_rows, reminder = divmod(len(sequence), num_columns) num_rows += bool(reminder) return [tuple(sequence[i::num_rows]) for i in range(num_rows)] Обобщенные отображения Обобщенные отображения – это аннотированные типы вида MappingType[KeyType,ValueType] . Встроенный тип dict и типы отображений в модулях collections и collections.abc следуют соглашению, принятому в Python ≥ 3.9. В бо- лее ранних версиях необходимо использовать класс typing.Dict и другие типы отображений из модуля typing, как описано во врезке «Поддержка унаследован- ных типов и нерекомендуемые типы коллекций» выше. Пример 8.14 – практическая демонстрация использования функции, возвра- щающей инвертированный индекс (https://en.wikipedia.org/wiki/ Inverted_index) для поиска символов Unicode по имени – вариация на тему примера 4.21, лучше приспособленная для серверного кода, который мы будем изучать в главе 21. Получив начальный и конечный коды символов Unicode, name_index возвра- щает словарь dict[str, set[str]] , который содержит инвертированный индекс, отображающий слово во множество символов, в названии которых это слово встречается. Например, после индексирования ASCII-символов от 32 до 64 слов 'SIGN' и 'DIGIT' будут соответствовать показанные ниже множества символов. Показано также, как найти символ с именем 'DIGIT EIGHT' : >>> index = name_index(32, 65) >>> index['SIGN'] {'$', '>', '=', '+', '<', '%', '#'} >>> index['DIGIT'] {'8', '5', '6', '2', '3', '0', '1', '4', '7', '9'} >>> index['DIGIT'] & index['EIGHT'] {'8'} Типы, пригодные для использования в аннотациях  275\n--- Страница 275 ---\nВ примере 8.14 приведен исходный код файла charindex.py, содержащего функцию name_index . Помимо аннотации типа dict[], в этом примере демонстри- руются еще три средства, которые до сих пор нам не встречались. Пример 8.14. charindex.py import sys import re import unicodedata from collections.abc import Iterator RE_WORD = re.compile(r'\\w+') STOP_CODE = sys.maxunicode + 1 def tokenize(text: str) -> Iterator[str]:  \"\"\"вернуть итерируемый объект, содержащий слова в верхнем регистре\"\"\" for match in RE_WORD.finditer(text): yield match.group().upper() def name_index(start: int = 32, end: int = STOP_CODE) -> dict[str, set[str]]: index: dict[str, set[str]] = {}  for char in (chr(i) for i in range(start, end)): if name := unicodedata.name(char, ''):  for word in tokenize(name): index.setdefault(word, set()).add(char) return index  tokenize – генераторная функция. Генераторам посвящена глава 17.  Локальная переменная index аннотирована. Не будь этой аннотации, Mypy со- общила бы: Need type annotation for 'index' (hint: «index: dict[<type>, <type>] = ») .  Я воспользовался оператором := в условии if. Он присваивает результат вызова unicodedata.name() переменной name и выражению в целом. Результат '' интерпретируется как ложь и index не изменяется1. Когда dict выступает в роли записи, принято делать все ключи объектами типа str, а тип значения может зависеть от ключа. Этот вопрос рассматривается в разделе «TypedDict» главы 15. Абстрактные базовые классы Будь консервативен, когда передаешь, будь либерален, когда принимаешь. – Закон Постела, или принцип надежности В табл. 8.1 перечислено несколько абстрактных классов из модуля collections. abc. В идеале функция должна принимать аргументы этих абстрактных типов (или их эквивалентов из модуля typing в версиях младше Python 3.9), а не кон- кретные типы. Это дает больше гибкости вызывающей стороне. 1 Я использую оператор := в нескольких примерах, когда это имеет смысл, но не рас - смат риваю его в данной книге. Технические детали см. в документе PEP 572 «Assignment Expressions» (https://peps.python.org/pep-0572/). 276  Аннотации типов в функциях\n--- Страница 276 ---\nРассмотрим следующую сигнатуру функции: from collections.abc import Mapping def name2hex(name: str, color_map: Mapping[str, int]) -> str: Использование abc.Mapping позволяет вызывающей стороне передать экзем- пляр dict, defaultdict , ChainMap, подкласса UserDict или любого другого типа, являю- щегося подтипом Mapping. С другой стороны, рассмотрим сигнатуру: def name2hex(name: str, color_map: dict[str, int]) -> str: Теперь color_map должно быть объектом типа dict или одного из его подтипов, например defaultDict или OrderedDict . Но подкласс collections.UserDict не пройдет проверку типа, хотя это и рекомендованный способ создавать пользователь- ские отображения, как мы видели в разделе «Создание подкласса UserDict вмес- то dict» главы 3. Mypy отвергнет экземпляр класса UserDict или производного от него, потому что UserDict не является подклассом dict; они находятся на одном уровне иерархии наследования – оба являются подклассами abc.MutableMapping1. Таким образом, в общем случае в аннотациях типов параметров лучше ис- пользовать abc.Mapping или abc.MutableMapping , а не dict (или typing.Dict в унаследо- ванном коде). Если функции name2hex не нужно изменять переданное color_map, то самой точной аннотацией типа color_map будет abc.Mapping . Тогда вызывающей стороне не нужно будет предоставлять объект, реализующий методы setdefault , pop и update, которые являются частью интерфейса MutableMapping , но не Mapping. Это вполне согласуется со второй частью закона Постела: «будь либерален, когда принимаешь». Закон Постела также рекомендует быть консервативным при передаче. Зна- чением функции всегда является конкретный объект, поэтому в аннотации для возвращаемого значения должен быть указан конкретный тип, как в при- мере из раздела «Обобщенные коллекции», где используется list[str]: def tokenize(text: str) -> list[str]: return text.upper().split() В разделе документации, посвященном typing.List (https://docs.python.org/3/ library/typing.html#typing.List), говорится: Обобщенная версия list. Полезна для аннотирования типов возвращае- мых значений. Для аннотирования аргументов лучше использовать аб- страктные типы коллекций, например Sequence или Iterable. Аналогичный комментарий имеется в разделах, посвященных typing.Dict (https://docs.python.org/3/library/typing.html#typing.Dict) и typing.Set (https://docs. python.org/3/ library/typing.html#typing.Set). Напомним, что начиная с Python 3.9 большинство ABC из модуля collections. abc и другие конкретные классы из модуля collections , а также встроенные 1 На самом деле dict – это виртуальный подкласс abc.MutableMapping . Концеп- ция виртуального подкласса объясняется в главе 13. Пока достаточно знать, что issubclass(dict,abc.MutableMapping) равно True, несмотря на то что dict написан на C и не наследует ничему из модуля abc.MutableMapping , а только object. Типы, пригодные для использования в аннотациях  277\n--- Страница 277 ---\nколлекции поддерживают нотацию аннотаций обобщенных классов вида collections.deque[str] . Соответствующие коллекции из модуля typing нужны толь- ко для поддержки кода, написанного для версии Python 3.8 или более ранней. Полный список классов, ставших обобщенными, приведен в разделе «Реали- зация» (https://peps.python.org/pep-0585/#implementation) документа PEP 585 «Type Hinting Generics In Standard Collections». И, завершая обсуждение ABC в аннотациях типов, хотелось бы сказать не- сколько слов об ABC из пакета numbers. Падение числовой башни Пакет numbers определяет так называемую числовую башню, описанную в доку - менте PEP 3141 «A Type Hierarchy for Numbers» (https://peps.python.org/pep-3141/). Башня представляет собой линейную иерархию ABC, наверху которой нахо- дится тип Number: Number Complex Real Rational Integral Эти ABC прекрасно работают для проверки типов во время выполнения, но не поддерживаются для статической проверки типов. В разделе «Число- вая башня» (https://peps.python.org/pep-0484/#the-numeric-tower) документа PEP 484 ABC из пакета numbers отвергаются и постулируется, что встроенные типы complex, float и int должны считаться специальными случаями, как объясняется во врезке «INT совместим с COMPLEX». Мы вернемся к этому вопросу в разделе «ABC из пакета numbers и числовые протоколы» главы 13, посвященном сравнению протоколов и ABC. На практике, если требуется аннотировать числовые алгоритмы для стати- ческой проверки типов, у нас есть несколько вариантов. 1. Использовать один из конкретных типов int, float или complex, как реко- мендуется в документе PEP 488. 2. Объявить тип объединения, например Union[float, Decimal, Fraction] . 3. Чтобы не зашивать в код конкретные типы, использовать числовые про- токолы, например SupportsFloat , рассматриваемые в разделе «Статические протоколы, допускающие проверку во время выполнения» главы 13. Раздел «Статические протоколы» ниже в этой главе – необходимое предва- рительное условие для понимания того, что такое числовые протоколы. А пока обратимся к одному из самых полезных ABC для аннотаций типов: Iterable. Тип Iterable В документации по типу typing.List , которую я недавно цитировал, рекомен- дуется использовать типы Sequence и Iterable для аннотирования параметров функций. Пример аргумента типа Iterable встречается в функции math.fsum из стандартной библиотеки: def fsum(__seq: Iterable[float]) -> float:278  Аннотации типов в функциях\n--- Страница 278 ---\nФайлы-заглушки и проект T ypeshed В версии Python 3.10 в стандартной библиотеке нет аннотаций типов, но Mypy, PyCharm и другие программы могут найти не- обходимые аннотации в проекте Typeshed (https://github.com/ python/typeshed) в виде файлов-заглушек – специальных исходных файлов с расширением .pyi, содержащих аннотированные сиг- натуры функций и методов без реализации – очень похоже на заголовочные файлы в C. Сигнатура функции math.fsum находится в файле /stdlib/2and3/ math.pyi. Начальные пробелы в имени __seq – соглашение о чисто позиционных параметрах, рекомендуемое в документе PEP 484 (мы объясним его в разделе «Аннотирование чисто позицион- ных и вариадических параметров» ниже). Пример 8.15 – еще один пример использования параметра типа Iterable, ко- торый порождает элементы, имеющие тип tuple[str, str] . Вот как используется эта функция: >>> l33t = [('a', '4'), ('e', '3'), ('i', '1'), ('o', '0')] >>> text = 'mad skilled noob powned leet' >>> from replacer import zip_replace >>> zip_replace(text, l33t) 'm4d sk1ll3d n00b p0wn3d l33t' А ниже показана ее реализация. Пример 8.15. replacer.py from collections.abc import Iterable FromTo = tuple[str, str]  def zip_replace(text: str, changes: Iterable[FromTo]) -> str:  for from_, to in changes: text = text.replace(from_, to) return text  FromTo – псевдоним типа: я присвоил FromTo тип tuple[str, str] , чтобы сигнату - ру zip_replace было проще читать.  changes должен иметь тип Iterable[FromTo] ; это то же самое, что Iterable[tuple[str, str]], но короче и легче воспринимается. Явные псевдонимы типов в Python 3.10 В документе PEP 613 «Explicit Type Aliases» (https://peps.python.org/ pep-0613/) введен специальный тип TypeAlias, идея которого в том, чтобы сделать создаваемые псевдонимы типов хорошо видимыми и упростить для них проверку типов. Начиная с версии Python 3.10 это рекомендуемый способ создания псевдонимов типов: from typing import TypeAlias FromTo: TypeAlias = tuple[str, str] Типы, пригодные для использования в аннотациях  279\n--- Страница 279 ---\nabc.Iterable и abc.Sequence И math.fsum, и replacer.zip_replace должны обойти все аргументы, порождаемые Iterable, чтобы вернуть результат. Учитывая, что бывают бесконечные итери- руемые объекты, например генератор itertools.cycle , эти функции могли бы потребить всю память, что приведет к аварийному завершению процесса. Несмотря на эту потенциальную опасность, в современном Python довольно часто встречаются функции, которые принимают на входе Iterable даже тогда, когда для получения результата необходимо обработать его целиком. Это дает вызывающей стороне возможность поставлять входные данные с помощью генератора, а не строить последовательность заранее. Если количество вход- ных элементов велико, то так можно сэкономить много памяти. С другой стороны, функция columnize из примера 8.13 принимает параметр Sequence, а не Iterable, потому что ей нужно знать длину последовательности len(), чтобы заранее вычислить количество строк. Как и Sequence, объект Iterable лучше использовать в качестве типа парамет- ра. В качестве типа возвращаемого значения он не позволяет составить пред- ставление о том, что же будет на выходе. Функция должна более ясно говорить о том, какой конкретный тип она возвращает. С Iterable тесно связан тип Iterator, используемый в качестве возвращаемого значения в примере 8.14. Мы вернемся к нему в главе 17, посвященной генера- торам и классическим итераторам. Параметризованные обобщенные типы и T ypeVar Параметризованный обобщенный тип – это обобщенный тип, записанный в виде list[T], где T – переменная-тип, которая будет связана с конкретным типом при каждом использовании. Это позволяет использовать переменную- тип в типе результата. В примере 8.16 определена функция sample, которая принимает два аргумен- та: последовательность элементов типа T и int. Она возвращает список list эле- ментов того же типа T, случайно выбранных из первого аргумента. Пример 8.16. sample.py from collections.abc import Sequence from random import shuffle from typing import TypeVar T = TypeVar('T') def sample(population: Sequence[T], size: int) -> list[T]: if size < 1: raise ValueError('size must be >= 1') result = list(population) shuffle(result) return result[:size] Ниже приведено два примера, показывающих, почему я использовал в sample переменную-тип: если при вызове функции передается кортеж типа tuple[int, ] , кото - рый совместим с Sequence[int] , то параметр-тип равен int, т. е. возвращае- мое значение будет иметь тип list[int] ;280  Аннотации типов в функциях\n--- Страница 280 ---\nесли при вызове функции передается строка str, которая совместима с Sequence[str] , то параметр-тип равен str, т. е. возвращаемое значение бу- дет иметь тип list[str]. Зачем нужен класс T ypeVar? Авторы документа PEP 484 хотели ввести аннотации типов, до- бавив модуль typing и больше не изменяя в языке ничего. С по- мощью хитроумного метапрограммирования они могли бы за- ставить оператор [] работать с классами наподобие Sequence[T] . Но имя переменной T в квадратных скобках должно быть где-то определено, иначе в интерпретатор Python пришлось бы вно- сить глубокие изменения для поддержки нотации обобщенных типов как специального случая употребления []. Поэтому по- надобился конструктор typing.TypeVar : чтобы ввести имя пере- менной в текущее пространство имен. В языках типа Java, C# и TypeScript заранее объявлять имя переменной-типа не нужно, поэтому в них нет эквивалента класса TypeVar. Еще один пример дает функция statistics.mode из стандартной библиотеки, которая возвращает самую часто встречающуюся точку в последовательности. Вот пример ее использования из документации (https://docs.python.org/3/ library/statistics.html#statistics.mode): >>> mode([1, 1, 2, 3, 3, 3, 3, 4]) 3 Без использования TypeVar функция mode могла бы иметь сигнатуру, показан- ную в примере 8.17. Пример 8.17. mode_float.py: функция mode, применимая к float и его подтипам1 from collections import Counter from collections.abc import Iterable def mode(data: Iterable[float]) -> float: pairs = Counter(data).most_common(1) if len(pairs) == 0: raise ValueError('no mode for empty data') return pairs[0][0] Чаще всего mode применяется к значениям типа int или float, но в Python есть и другие числовые типы, и желательно, чтобы возвращалось значение того же типа, который указан во входном объекте Iterable. Мы можем улучшить сигна- туру, воспользовавшись классом TypeVar. Начнем с простой, но неправильной параметризованной сигнатуры: from collections.abc import Iterable from typing import TypeVar T = TypeVar('T') def mode(data: Iterable[T]) -> T: 1 Здесь реализация проще, чем в модуле statistics из стандартной библиотеки Python. Типы, пригодные для использования в аннотациях  281\n--- Страница 281 ---\nПри первом вхождении в сигнатуру параметр-тип T может быть любым. Но при втором вхождении он будет означать тот же тип, что при первом. Поэтому любой итерируемый объект совместим с Iterable[T] , в т. ч. итери- руемые объекты нехешируемых типов, которые не может обработать тип collections.Counter . Необходимо ограничить типы, которые можно присваивать T. В следующих двух разделах мы рассмотрим два способа это сделать. Ограниченный TypeVar Тип TypeVar принимает дополнительные позиционные аргументы, ограничива- ющие параметр-тип. Улучшить сигнатуру mode, так чтобы она принимала опре- деленные числовые типы, можно следующим образом: from collections.abc import Iterable from decimal import Decimal from fractions import Fraction from typing import TypeVar NumberT = TypeVar('NumberT', float, Decimal, Fraction) def mode(data: Iterable[NumberT]) -> NumberT: Уже лучше, именно такой была сигнатура mode в файле-заглушке statistics.pyi (https://github.com/python/typeshed/blob/e1e99245bb46223928eba68d4fc74962240ba 5b4/stdlib/3/statistics.pyi) 25 мая 2020 года. Однако в документацию по функции statistics.mode (https://docs.python.org/3/ library/statistics.html#statistics.mode) включен такой пример: >>> mode([\"red\", \"blue\", \"blue\", \"red\", \"green\", \"red\", \"red\"]) 'red' В спешке мы могли бы просто добавить str в определение NumberT: NumberT = TypeVar('NumberT', float, Decimal, Fraction, str) Это, конечно, работает, но теперь название типа NumberT совершенно не от - ражает его сущности, ведь он принимает str. Однако важнее даже не это, а то, что мы не можем добавлять типы всякий раз, как оказывается, что mode должна с ними работать. Есть способ лучше – нужно только воспользоваться другой возможностью TypeVar. Связанный TypeVar Взглянув на тело функции mode из примера 8.17, мы увидим, что для ранжиро- вания используется класс Counter. Этот класс основан на словаре dict, поэтому тип каждого элемента, порождаемого итерируемым объектом, должен допус- кать хеширование. На первый взгляд, должна работать следующая сигнатура: from collections.abc import Iterable, Hashable def mode(data: Iterable[Hashable]) -> Hashable: Теперь проблема в том, что тип возвращаемого элемента Hashable: ABC, реа- лизующий только метод __hash__. Поэтому средство проверки типов не позво-282  Аннотации типов в функциях\n--- Страница 282 ---\nлит нам сделать с возвращаемым значением ничего, кроме применения мето- да hash(). Не очень полезно. Решение дает еще одна возможность TypeVar: необязательный именованный параметр bound. Он задает верхнюю границу допустимых типов. В примере 8.18 мы имеем bound=Hashable , это означает, что параметр-тип может быть Hashable или любым его подтипом1. Пример 8.18. mode_hashable.py: то же, что пример 8.17, но с более гибкой сигнатурой from collections import Counter from collections.abc import Iterable, Hashable from typing import TypeVar HashableT = TypeVar('HashableT', bound=Hashable) def mode(data: Iterable[HashableT]) -> HashableT: pairs = Counter(data).most_common(1) if len(pairs) == 0: raise ValueError('no mode for empty data') return pairs[0][0] Подведем итоги: ограниченной переменной-типу будет назначен один из типов, пере- численных в объявлении TypeVar ; связанной переменной-типу будет назначен выведенный тип выраже- ния – при условии что выведенный тип совместим с границей, объяв- ленной в именованном аргументе bound= типа TypeVar. Не очень хорошо, что именованный аргумент для объявления граничного TypeVar называется bound=, потому что глагол «to bind» (связывать) обычно означает задание значения перемен- ной, это действие в ссылочной семантике Python лучше всего описать как связывание имени со значением. Путаницы было бы меньше, если бы этот аргумент назывался boundary= . У конструктора typing.TypeVar есть и другие факультативные параметры – covariant и contravariant , – которые мы будем обсуждать в разделе «Вариантность» главы 15. Закончим это введение в тип TypeVar описанием переменной AnyStr. Предопределенная переменная-тип AnyStr В модуль typing включена переменная-тип AnyStr, определенная следующим об- разом: AnyStr = TypeVar('AnyStr', bytes, str) Она используется во многих функциях, принимающих bytes или str и воз- вращающих значение заданного типа. А теперь перейдем к typing.Protocol , новой возможности, которая появилась в версии Python 3.8 и поддерживает использование аннотаций типов более ор- ганичным для Python способом. 1 Я отправил это решение в typeshed, и именно так аннотирована функция mode в файле statistics.pyi по состоянию на 26 мая 2020 года. Типы, пригодные для использования в аннотациях  283\n--- Страница 283 ---\nСтатические протоколы В объектно-ориентированном программировании концеп- ция «протокола» как неформального интерфейса восходит еще к Smalltalk и являлась неотъемлемой частью Python с самого на- чала. Однако в контексте аннотаций типов протокол – это под- класс typing.Protocol , определяющий интерфейс, который может верифицировать средство проверки типов. Оба вида протоколов рассматриваются в главе 13. Это лишь краткое введение в кон- тексте аннотаций функций. Тип Protocol в том виде, в каком он представлен в документе PEP 544 «Protocols: Structural subtyping (static duck typing)» (https://peps.python.org/pep-0544/), похож на интерфейсы в языке Go: тип протокола определяется заданием одного или нескольких методов, а средство проверки типов проверяет, что эти методы реа- лизованы всюду, где требуется данный тип протокола. В Python определение протокола записывается в виде подкласса typing. Protocol. Однако классы, реализующие протокол, не обязаны наследовать, регист рировать или объявлять какую-то связь с классом, который определяет протокол. На средство проверки типов возлагается обязанность найти имею- щиеся типы протоколов и гарантировать их правильное использование. Приведем пример задачи, которую можно решить с помощью Protocol и TypeVar. Предположим, что требуется создать функцию top(it, n) , которая воз- вращает n наибольших элементов из итерируемого объекта it: >>> top([4, 1, 5, 2, 6, 7, 3], 3) [7, 6, 5] >>> l = 'mango pear apple kiwi banana'.split() >>> top(l, 3) ['pear', 'mango', 'kiwi'] >>> >>> l2 = [(len(s), s) for s in l] >>> l2 [(5, 'mango'), (4, 'pear'), (5, 'apple'), (4, 'kiwi'), (6, 'banana')] >>> top(l2, 3) [(6, 'banana'), (5, 'mango'), (5, 'apple')] Параметризованная обобщенная функция top могла бы выглядеть, как по- казано в примере 8.19. Пример 8.19. Функция top с неопределенным параметром типом T def top(series: Iterable[T], length: int) -> list[T]: ordered = sorted(series, reverse=True) return ordered[:length] Вопрос в том, как ограничить T. Это не может быть Any или object, потому что series должен работать с функцией sorted. Встроенная функция sorted на самом деле принимает Iterable[Any] , но это только потому, что факультативный пара- метр key принимает функцию, которая вычисляет произвольный ключ сорти- ровки по каждому элементу. А что будет, если передать sorted список простых объектов, но не задавать аргумент key? Попробуем: 284  Аннотации типов в функциях\n--- Страница 284 ---\n>>> l = [object() for _ in range(4)] >>> l [<object object at 0x10fc2fca0>, <object object at 0x10fc2fbb0>, <object object at 0x10fc2fbc0>, <object object at 0x10fc2fbd0>] >>> sorted(l) Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: '<' not supported between instances of 'object' and 'object' Сообщение об ошибке говорит, что sorted применяет оператор < к элементам итерируемого объекта. И это все, что надо? Поставим еще один эксперимент1: >>> class Spam: def __init__(self, n): self.n = n def __lt__(self, other): return self.n < other.n def __repr__(self): return f'Spam({self.n})' >>> l = [Spam(n) for n in range(5, 0, -1)] >>> l [Spam(5), Spam(4), Spam(3), Spam(2), Spam(1)] >>> sorted(l) [Spam(1), Spam(2), Spam(3), Spam(4), Spam(5)] Подтверждено: я могу сортировать список объектов Spam, потому что в классе Spam реализован специальный метод __lt__, поддерживающий оператор <. Таким образом, параметр-тип T в примере 8.19 должен быть ограничен ти- пами, реализующими __lt__. В примере 8.18 нам был нужен параметр-тип, реа- лизующий метод __hash__, чтобы можно было использовать typing.Hashable как верхнюю границу типов. Но на этот раз ни в typing, ни в abc подходящего типа нет, так что придется его создать. В примере 8.20 показан новый тип SupportsLessThan , являющийся протоколом. Пример 8.20. comparable.py: определение типа протокола SupportsLessThan from typing import Protocol, Any class SupportsLessThan(Protocol):  def __lt__(self, other: Any) -> bool:   Протокол является подклассом typing.Protocol .  В теле протокола имеется одно или несколько определений методов, со- держащих вместо тела многоточие Тип T совместим с протоколом P, если T реализует все методы, определенные в P с такими же сигнатурами. Имея SupportsLessThan , мы теперь можем определить работоспособную версию функции top. Пример 8.21. top.py: определение функции top с помощью TypeVar с bound=SupportsLessThan from collections.abc import Iterable from typing import TypeVar 1 Как чудесно все-таки открыть интерактивную консоль и, опираясь на утиную типи- зацию, исследовать разные языковые средства. Мне очень не хватает этой возмож - ности при работе с языками, которые ее не поддерживают. Типы, пригодные для использования в аннотациях  285\n--- Страница 285 ---\nfrom comparable import SupportsLessThan LT = TypeVar('LT', bound=SupportsLessThan) def top(series: Iterable[LT], length: int) -> list[LT]: ordered = sorted(series, reverse=True) return ordered[:length] Протестируем top. В примере 8.22 показана часть комплекта тестов для pytest. Сначала мы пытаемся вызвать top, передав генераторное выражение, которое отдает tuple[int, str] , а затем – передав список object. Во втором случае мы ожи- даем получить исключение TypeError. Пример 8.22. top_test.py: часть комплекта тестов для top from collections.abc import Iterator from typing import TYPE_CHECKING  import pytest from top import top # несколько строк опущено def test_top_tuples() -> None: fruit = 'mango pear apple kiwi banana'.split() series: Iterator[tuple[int, str]] = (  (len(s), s) for s in fruit) length = 3 expected = [(6, 'banana'), (5, 'mango'), (5, 'apple')] result = top(series, length) if TYPE_CHECKING:  reveal_type(series)  reveal_type(expected) reveal_type(result) assert result == expected # намеренно допущена ошибка типизации def test_top_objects_error() -> None: series = [object() for _ in range(4)] if TYPE_CHECKING: reveal_type(series) with pytest.raises(TypeError) as excinfo: top(series, 3)  assert \"'<' not supported\" in str(excinfo .value)  Константа typing.TYPE_CHECKING во время выполнения всегда равна False, но средства проверки типов во время работы притворяются, что она равна True.  Явное объявление типа для переменной series, чтобы было проще читать вывод Mypy1.  Это условие if запрещает выполнять следующие три строки во время про- гона теста. 1 Без этой аннотации типа Mypy вывела бы для series тип Generator[Tuple[builtins.int, builtins.str*], None, None] – длинный, но совместимый с Iterator[tuple[int, str] .286  Аннотации типов в функциях\n--- Страница 286 ---\n reveal_type() нельзя вызывать во время выполнения, потому что это не обыч- ная функция, а отладочное средство Mypy – потому-то оно ниоткуда не им- портируется. Mypy будет печатать по одному отладочному сообщению для каждого вызова псевдофункции reveal_type() , показывая, какой тип аргу - мента она вывела.  Эту строку Mypy пометит как ошибочную. Показанные выше тесты проходят, но они прошли бы в любом случае – с ан- нотациями типов в top.py или без оных. Интереснее другое: если я проверю этот тестовый файл с помощью Mypy, то увижу, что TypeVar работает в полном соответствии с ожиданиями. См. вывод mypy в примере 8.23. В версии Mypy 0.910 (июль 2021) reveal_type иногда показывает не в точности те типы, что я объявил, а совместимые с ними. Напри- мер, я использовал не typing.Iterator , а abc.Iterator . Не обращайте внимания на эту деталь. Вывод Mypy все равно полезен. В ходе его обсуждения я сделаю вид, что эта проблема Mypy уже решена. Пример 8.23. Вывод mypy top_test.py …/comparable/ $ mypy top_test.py top_test.py:32: note: Revealed type is \"typing.Iterator[Tuple[builtins.int, builtins.str]]\"  top_test.py:33: note: Revealed type is \"builtins.list[Tuple[builtins.int, builtins.str]]\" top_test.py:34: note: Revealed type is \"builtins.list[Tuple[builtins.int, builtins.str]]\"  top_test.py:41: note: Revealed type is \"builtins.list[builtins.object*]\"  top_test.py:43: error: Value of type variable \"LT\" of \"top\" cannot be \"object\"  Found 1 error in 1 file (checked 1 source file)  В функции test_top_tuples reveal_type(series) показывает, что это Iterator[tuple[int, str]] – тот тип, который я явно объявил.  reveal_type(result) подтверждает, что тип, возвращенный после вызо- ва top, – именно то, что я хотел: с учетом типа series результат имеет тип list[tuple[int, str]] .  В функции test_top_objects_error reveal_type(series) показывает, что это list[object*] . Mypy выводит * после любого выведенного типа: я не анноти- ровал тип series в этом тесте.  Mypy обнаруживает ошибку, которую этот тест намеренно хотел вызвать: типом элемента итерируемого объекта не может быть object (элемент дол- жен иметь тип SupportsLessThan ). Главное преимущество типа протокола перед ABC – то, что для совместимо- сти с типом протокола не нужно никакого специального объявления. Это по- зволяет создавать протоколы с использованием уже существующих типов или типов, реализованных в коде, который мы не контролируем. Мне не нужно на- следовать или регистрировать типы str, tuple, float, set и другие, чтобы исполь- зовать их там, где ожидается параметр типа SupportsLessThan . Они должны только реализовывать метод __lt__. А средство проверки все равно справится со своей Типы, пригодные для использования в аннотациях  287\n--- Страница 287 ---\nработой, потому что SupportsLessThan явно определен как Protocol – в противопо- ложность неявным протоколам, свойственным утиной типизации, которые не видны средству проверки типов. В документе PEP 544 «Protocols: Structural subtyping (static duck typing)» (https://peps.python.org/pep-0544/) был представлен специальный класс Protocol. В примере 8.21 демонстрируется, почему это средство называется статическая утиная типизация: решение аннотировать параметр series функции top было продиктовано следующим соображением: «Номинальный тип series не игра- ет роли, лишь бы он реализовывал метод __lt__». Утиная типизация в Python всегда позволяла сказать это неявно, оставив средства статической проверки типов ни с чем. Средство проверки не может прочитать исходный код CPython, написанный на C, или выполнить эксперименты на консоли, дабы понять, что функция sorted требует лишь, чтобы элементы поддерживали оператор <. Теперь же мы можем сделать утиную типизацию явной для программ ста- тической проверки типов. Вот почему имеет смысл говорить, что typing.Protocol дает нам статическую утиную типизацию1. Это не все, что можно сказать о классе typing.Protocol . Мы вернемся к нему в части IV, где в главе 13 сравниваются структурная типизация, утиная типиза- ция и ABC – еще один подход к формализации протоколов. Кроме того, в раз- деле «Перегруженные сигнатуры» главы 15 объясняется, как объявлять пере- груженные сигнатуры функций с помощью декоратора @typing.overload , и приво- дится расширенный пример использования typing.Protocol и граничного TypeVar. typing.Protocol открывает возможность для аннотирования функции double, представленной в разделе «Типы определяют - ся тем, какие операции они поддерживают» выше, без потери функциональности. Ключ к этому – определение протокольного класса с методом __mul__. Предлагаю вам эту задачу в качестве упражнения. Решение будет приведено в разделе «Типизиро- ванная функция double» главы 13. Тип Callable Чтобы можно было аннотировать параметры обратного вызова или вызывае- мые объекты, возвращаемые функциями высшего порядка, модуль collections. abc предоставляет тип Callable, доступный также в модуле typing для тех, кто еще не перешел на Python 3.9. Тип Callable параметризован следующим образом: Callable[[ParamType1, ParamType2], ReturnType] Список параметров – [ParamType1, ParamType2] – может содержать нуль или бо- лее типов. Ниже приведен пример в контексте функции repl, входящей в простой интер активный интерпретатор, который мы разработаем в разделе «Сопо- ставление с образцом в lis.py: пример»2. 1 Я не знаю, кто придумал термин статическая утиная типизация, но он приобрел по- пулярность с распространением языка Go, в котором семантика интерфейсов больше походит на протоколы Python, чем на номинальные интерфейсы Java. 2 REPL означает Read-Eval-Print-Loop (цикл чтения-вычисления-печати), такой цикл лежит в основе интерактивных интерпретаторов. 288  Аннотации типов в функциях\n--- Страница 288 ---\ndef repl(input_fn: Callable[[Any], str] = input]) -> None: При нормальном использовании функция repl пользуется встроенной в Python функцией input для чтения выражений, введенных пользователем. Од- нако для автоматизированного тестирования или интеграции с другими источ- никами ввода repl принимает факультативный параметр input_fn: объект типа Callable с такими же типами параметра и возвращаемого значения, что у input. Встроенная функция input имеет следующую сигнатуру в typeshed: def input(__prompt: Any = ) -> str: Сигнатура input совместима с таким аннотированным Callable: Callable[[Any], str] Не существует синтаксической конструкции, позволяющей аннотировать типы факультативных или именованных аргументов. В документации (https:// docs.python.org/3/library/typing.html#typing.Callable) по typing.Callable сказано: «та- кие типы функций редко используются в качестве типов обратных вызовов». Если вам нужна аннотация типа для функции с гибкой сигнатурой, замените весь список параметров многоточием: Callable[ , ReturnType] Такое взаимодействие обобщенных параметров-типов с иерархией типов приводит к новой концепции: вариантности. Вариантность в типах Callable Представьте себе систему управления температурой с простой функцией update, показанной в примере 8.24. Функция update вызывает функцию probe, чтобы полу - чить текущую температуру, а затем функцию display, чтобы показать температу - ру пользователю. Обе функции, probe и display, передаются update в качестве аргу - ментов из педагогических соображений. Цель примера – сравнить две аннота- ции Callable: одну с типом возвращаемого значения, другую с типом параметра. Пример 8.24. Иллюстрация вариантности from collections.abc import Callable def update(  probe: Callable[[], float],  display: Callable[[float], None]  ) -> None: temperature = probe() # здесь может быть какой-то код управления display(temperature) def probe_ok() -> int:  return 42 def display_wrong(temperature: int) -> None:  print(hex(temperature)) update(probe_ok, display_wrong) # ошибка типизации  Типы, пригодные для использования в аннотациях  289\n--- Страница 289 ---\ndef display_ok(temperature: complex) -> None:  print(temperature) update(probe_ok, display_ok) # OK   update принимает два вызываемых объекта в качестве аргументов.  Вызываемый объект probe не принимает аргументов и возвращает float.  Объект display принимает аргумент типа float и возвращает None.  Функция probe_ok совместима с Callable[[], float] , потому что возврат int не вызывает ошибки в коде, который ожидает float.  Функция display_wrong несовместима с Callable[[float], None] , потому что нет гарантии, что функция, ожидающая int, сможет обработать float; например, функция Python hex принимает int, но отвергает float.  Mypy считает эту строку ошибочной, потому что display_wrong несовместима с аннотацией типа параметра display в update.  display_ok совместима с Callable[[float], None] , потому что функция, принима- ющая complex, сможет обработать и float.  Эта строка не вызывает возражений у Mypy. Подведем итоги. Ничто не мешает передать функцию обратного вызова, кото- рая возвращает int, когда программа ожидает получить функцию, возвращающую float, потому что значение типа int всегда можно использовать, когда ожидается float. Формально мы говорим, что Callable[[], int] является подтипом Callable[[], float], – так как int является подтипом float. Это означает, что тип Callable ковари- антен относительно возвращаемого значения, потому что направление отно- шения является подтипом между типами int и float такое же, как между типами Callable, в которых они являются типами возвращаемого значения. С другой стороны, ошибкой будет передача функции обратного вызова, ко- торая принимает аргумент типа int, когда требуется, чтобы функция могла об- рабатывать float. Формально Callable[[int], None] не является подтипом Callable[[float], None] . Хотя int является подтипом float, в параметризованном типе Callable направ- ление отношения противоположно: Callable[[float], None] является подтипом Callable[[int], None] . Поэтому мы говорим, что тип Callable контравариантен от- носительно объявленных типов параметров. В разделе «Вариантность» главы 15 эта тема рассматривается более подроб- но с примерами инвариантных, ковариантных и контравариантных типов. Пока что имейте в виду, что большинство параметризованных обобщенных типов инвариантны, поэтому проще. Например, если я объявлю scores: list[float] , то буду точно знать, что можно присвоить scores. Я не смогу присвоить этой переменной объект, объявленный как list[int] или list[complex] : объект list[int] недопустим, потому что он может хранить значения типа float, которые моя программа могла бы по- местить в scores ; объект list[complex] недопустим, потому что моя програм- ма может захотеть отсортировать scores для нахождения медианы, но тип complex не предоставляет метода __lt__, по- этому список list[complex] не сортируется. 290  Аннотации типов в функциях\n--- Страница 290 ---\nТеперь рассмотрим последний специальный тип в этой главе. Тип NoReturn Этот специальный тип используется только для аннотирования типов воз- вращаемых значений функций, которые вообще не возвращают управления. Обычно они существуют, чтобы возбуждать исключение. В стандартной биб- лиотеке десятки таких функций. Например, функция sys.exit() возбуждает исключение SystemExit , чтобы за- вершить процесс Python. Ее сигнатура в typeshed имеет вид: def exit(__status: object = ) -> NoReturn: Параметр __status чисто позиционный и имеет значение по умолчанию. В фай- лах-заглушках не указываются значения по умолчанию, вместо них использу - ется __status имеет тип object, а это значит, что он может принимать и значе- ние None, поэтому было бы избыточно аннотировать его как Optional[object] . В примере 24.6 главы 24 тип NoReturn используется в методе __flag_unknown_attrs , который выводит полное и понятное пользователю сообщение об ошибке, а затем возбуждает исключение AttributeError . Последний раздел этой главы эпического размера посвящен позиционным и вариадическим параметрам. аннО тирОвание чиСтО пОзициОнных и вариадичеСких параметр Ов Вспомним функцию tag из примера 7.9. Последний раз мы видели ее сигнатуру в разделе «Чисто позиционные параметры». def tag(name, /, *content, class_=None, **attrs): Ниже показана полностью аннотированная функция tag, записанная в не- скольких строках – обычное соглашение для длинных сигнатур. Разбиение на строки такое, как в форматере blue (https://pypi.org/project/blue/): from typing import Optional def tag( name: str, /, *content: str, class_: Optional[str] = None, **attrs: str, ) -> str: Обратите внимание на аннотацию типа *content: str для произвольных пози- ционных параметров; это означает, что все такие аргументы должны иметь str. Локальная переменная content в теле функции будет иметь тип tuple[str, ] . Произвольные именованные аргументы в этом примере аннотированы типом **attrs: str , поэтому аргумент attrs внутри функции будет иметь тип dict[str, str] . Если бы аннотация имела вид **attrs: float , то аргумент attrs имел бы тип dict[str, float] . Аннотирование чисто позиционных и вариадических параметров  291\n--- Страница 291 ---\nЕсли параметр attrs должен принимать значения разных типов, то следует использовать Union[] или Any: **attrs: Any . Нотация / для чисто позиционных параметров появилась в версии Python 3.8. В Python 3.7 и более ранних версиях она приводит к синтаксической ошибке. В до- кументе PEP 484 предлагается соглашение (https://peps.python.org/pep-0484/#id38): имя любого чисто позиционного параметра начинать с двух знаков подчеркива- ния. Снова приведем сигнатуру tag, на этот раз занимающую две строчки и следу - ющую соглашению PEP 484: from typing import Optional def tag(__name: str, *content: str, class_: Optional[str] = None, **attrs: str) -> str: Mypy понимает оба способа объявления чисто позиционных параметров и следит за их соблюдением. В заключение этой главы кратко рассмотрим ограничения аннотаций типов и статической системы типов, которую они поддерживают. неСОвершенная типизация и СтрОгОе теСтирОвание Лица, отвечающие за сопровождение больших корпоративных кодовых баз, го- ворят, что многие ошибки проще обнаружить и исправить с помощью программ статической проверки типов, чем если бы они были найдены только после запус- ка системы в эксплуатацию. Однако следует отметить, что в известных мне ком- паниях автоматизированное тестирование стало стандартной практикой и полу - чило широкое распространение задолго до внедрения статической типизации. Даже в тех контекстах, где статическая типизация наиболее полезна, на нее нельзя полагаться как на единственный критерий правильности. Вполне мож - но столкнуться с: Ложноположительными результатами Инструмент сообщает об ошибке, когда ее нет. Ложноотрицательными результатами Инструмент не сообщает об ошибке в заведомо неправильном коде. Кроме того, требуя проверять типы всего на свете, мы утрачиваем часть вы- разительности Python: некоторые удобные возможности нельзя проверить статически, напри- мер распаковку аргументов вида config(**settings) ; программы проверки типов в общем случае плохо поддерживают или вообще не понимают таких продвинутых возможностей, как свойства, дескрипторы, метаклассы и метапрограммирование; программы проверки типов не поспевают за выходом новых версий Python, отвергают код, содержащий новые возможности, или даже «па- дают» – и иногда это продолжается больше года. Самые простые ограничения на данные невозможно выразить в системе типов. Например, аннотации типов не могут гарантировать, что «величина должна быть целым числом > 0» или что «метка должна быть строкой длиной 292  Аннотации типов в функциях\n--- Страница 292 ---\nот 6 до 12 символов ASCII». Вообще, аннотации слабо помогают отлавливать ошибки в прикладной логике. С учетом всех этих подводных камней аннотации типов не могут считаться оплотом качества программного обеспечения, а требовать их задания во всех случаях без исключения значило бы усугубить их недостатки. Рассматривайте программы статической проверки типов как один из ин- струментов в современном конвейере непрерывной интеграции (CI) наряду с исполнителями тестов, линтерами и т. д. Цель конвейера CI – уменьшить ко- личество программных ошибок, а автоматизированные тесты находят многие ошибки, выходящие за рамки возможного для аннотаций типов. Любой код, который можно написать на Python, можно на Python и протестировать – с ан- нотациями типов или без них. Заголовок и заключение этого раздела были навеяны ста- тьей Брюса Эккеля «Строгая типизация и строгое тести- рование» (https://docs.google.com/document/d/1aXs1tpwzPjW9 MdsG5dI7clNFyYayFBkcXwRDo-qvbIk/preview), опубликованной также в антологии «The Best Software Writing I» (https://www.oreilly.com/ library/view/the-best-software/ 9781590595008/) под редакцией Джо- эля Спольски (издательство Apress). Брюс – фанат Python и ав- тор книг о C++, Java, Scala и Kotlin. В этой статье он рассказывает о том, что был горячим сторонником статической типизации, пока не изучил Python, и заключает следующими словами: «Если для программы на Python имеются адекватные автономные тес- ты, то она может быть не менее надежной, чем программы на C++, Java или C# с адекватным набором автономных тестов (хотя на Python тесты писать быстрее)». На этом мы пока завершаем рассмотрение аннотаций типов в Python. Они также являются главной темой главы 15, где рассматриваются обобщенные классы, вариантность, перегруженные сигнатуры, приведение типов и т. д. А до тех пор аннотации типов будут время от времени появляться в примерах кода. резюме Мы начали с краткого введения в концепцию постепенной типизации, а затем перешли к практическим вопросам. Трудно понять, как постепенная типиза- ция работает, не имея инструмента, который читает аннотации типов, поэто- му мы разработали аннотированную функцию, руководствуясь сообщениями об ошибках, выдаваемыми Mypy. Возвращаясь к идее постепенной типизации, мы выяснили, что она являет - ся гибридом традиционной утиной типизации в Python и номинальной типи- зации, более знакомой пишущим на Java, C++ и других статически типизиро- ванных языках. Большая часть главы была посвящена представлению основных групп ти- пов, используемых в аннотациях. Многие из рассмотренных типов тесно свя- заны со знакомыми нам типами объектов в Python: коллекциями, кортежами и вызываемыми объектами, но дополнены поддержкой нотации обобщения вида Sequence[float] . Многие из этих типов являются временными суррогатами, Резюме  293\n--- Страница 293 ---\nреализованными в модуле typing до того, как стандартные типы были измене- ны с целью поддержки обобщенных типов в Python 3.9. Некоторые типы являются специальными. Типы Any, Optional, Union и NoReturn не имеют никакого отношения к фактическим объектам в памяти, а существу - ют только в абстрактной сфере системы типов. Мы изучили параметризованные обобщенные типы и переменные-типы, которые повышают гибкость аннотаций типов, не жертвуя типобезопасностью. Параметризованные обобщенные типы становятся еще более выразитель- ными при использовании протоколов. Тип Protocol появился только в версии Python 3.8 и пока еще не получил широкого распространения, но его важность невозможно переоценить. Protocol открывает возможность для статической утиной типизации, мосту между ядром Python, основанным на утиной типи- зации, и номинальной типизацией, позволяющей средствам статической про- верки типов отлавливать ошибки. По ходу изучения этих типов мы экспериментировали с программой Mypy, чтобы понаблюдать за ошибками типизации и тем, какие типы выводит Mypy, – с помощью магической функции reveal_type() . Последний раздел был посвящен аннотированию чисто позиционных и ва- риадических параметров. Аннотации типов – сложный и развивающийся предмет. По счастью, это фа- культативное средство. Давайте позаботимся о том, чтобы Python оставался доступным широчайшей аудитории, и не будем молиться, чтобы весь код на Python был снабжен аннотациями типов, – а я встречал публичные проповеди, произносимые поборниками типизации. Наш почетный BDFL1 возглавил проникновение аннотаций типов в Python, поэтому будет справедливо завершить эту главу его словами: Мне была бы не по нраву версия Python, в которой я был бы морально обязан всюду добавлять аннотации типов. Я действительно думаю, что у аннотаций типов есть свое место, но также полно случаев, когда их ис- пользование неуместно, поэтому хорошо, что у нас есть выбор2. – Гвидо ван Россум дОпО лнительная литература Бернат Габор написал в своем замечательном посте «The state of type hints in Python» (https://bernat.tech/posts/the-state-of-type-hints-in-python/): Аннотации типов следовало бы использовать всюду, где имеет смысл пи- сать автономные тесты. Я сам большой поклонник тестирования, но при этом часто занимаюсь ис- следовательским кодированием. Во время экспериментов тесты и аннотации типов не особенно полезны. Они только тормозят работу. 1 «Benevolent Dictator For Life» (пожизненный великодушный диктатор). См. статью Гви- до ван Россума «Origin of BDFL» (https://www.artima.com/weblogs/viewpost.jsp?thread=235725). 2 Из видео на YouTube «Type Hints» (https://www.youtube.com/watch?v=YFexUDjHO6w) Гвидо ван Россума (март 2015). Цитата начинается в 13'40''. Я ее немного отредактировал.294  Аннотации типов в функциях\n--- Страница 294 ---\nПост Габора – одно из лучших известных мне введений в аннотации ти- пов в Python наряду со статьей Гейра Арне Хьелле «Python Type Checking (Guide)» (https://realpython.com/python-type-checking/). Текст Клаудио Йолови- ца «Hypermodern Python Chapter 4: Typing» (https://cjolowicz.github.io/posts/ hypermodern-python-04-typing/) – более краткое введение, в котором рассматри- вается также проверка типов во время выполнения. Если вам нужно более глубокое изложение, то наиболее авторитетным ис- точником является документация по Mypy (https://mypy.readthedocs.io/en/stable/ index.html). Она представляет ценность независимо от того, каким средством проверки типов вы пользуетесь, потому что включает пособие и справочные материалы о типизации в Python вообще, а не только в самой программе Mypy. Там же вы найдете удобные шпаргалки (https://mypy.readthedocs.io/en/stable/ cheat_sheet_py3.html) и очень полезную страницу на тему типичных проблем и их решений (https://mypy.readthedocs.io/en/stable/common_issues.html). Документация по модулю typing (https://docs.python.org/3/library/typing.html) – неплохой краткий справочник, но деталей там не слишком много. Документ PEP 483 «The Theory of Type Hints» (https://peps.python.org/pep-0483/) включает глубокое объяснение вариантности, причем тип Callable используется для ил- люстрации контравариантности. Бесспорным авторитетом являются доку - менты PEP, относящиеся к типизации. Их уже набралось больше 20. Предпо- лагаемая аудитория PEP – разработчики ядра Python и Руководящий совет по Python, поэтому предполагаются обширные предварительные знания, и, ко- нечно, это не легкое чтение. Как уже было сказано, в главе 15 рассматриваются дополнительные вопросы типизации, там же, в разделе «Дополнительная литература», имеются другие ссылки, в т. ч. табл. 15.1, в которой перечислены PEP, относящиеся к типиза- ции, – как утвержденные, так и находящиеся в процессе обсуждения (по со- стоянию на конец 2021 года). Сайт «Awesome Python Typing» (https://github.com/typeddjango/awesome-python- typing) – ценное собрание ссылок на инструменты и справочные материалы. Поговорим Просто езжай Забудьте про ультралегкие неудобные велосипеды, блестящие майки, грубые ботинки, с трудом помещающиеся на крохотные педали, на- матывание бесконечных миль. А просто езжайте, как бывало в дет - стве, – садитесь на велосипед и получайте чистую радость от катания. – Грант Петерсен «Просто езжай: радикально практичное руковод- ство по катанию на велосипеде» (Workman Publishing) Если кодирование – не ваша профессия, а лишь полезный инструмент, при- меняемый в профессиональных занятиях, или нечто такое, что вы изучаете ради удовольствия, то, пожалуй, аннотации типов нужны вам не больше, чем жесткие ботинки и металлические набойки большинству велосипедистов. Просто кодируйте. Дополнительная литература  295\n--- Страница 295 ---\nКогнитивный эффект типизации Меня беспокоит, какое влияние оказывают аннотации типов на стиль коди- рования на Python. Я согласен, что пользователи большинства API выигрывают от наличия аннотаций типов. Но Python привлекал меня – среди многих других при- чин – тем, что предоставляет чрезвычайно мощные функции, способные заменить целые API, и, более того, мы сами можем писать такие функции. Рассмотрим встроенную функцию max(). Она мощная, но понять ее легко. Однако, как будет показано в разделе «Перегрузка max», чтобы ее правиль- но аннотировать, нужно 14 строчек аннотаций типов, и это не считая typing. Protocol и нескольких определений TypeVar, необходимых для поддержки этих аннотаций. Я боюсь, что если библиотеки будут строго требовать аннотирования типов, то программисты раз и навсегда зарекутся писать такие функции. Согласно англоязычной Википедии, «лингвистическая относительность» (https://en.wikipedia.org/wiki/Linguistic_relativity) – она же гипотеза Сепира–Уорфа – это «принцип, провозглашающий, что структура языка оказывает влияние на восприятие мира людьми, говорящими на нем». Далее Википедия объясняет: сильная версия говорит, что язык определяет мышление и что лингвисти- ческие категории ограничивают и определяют когнитивные категории; слабая версия говорит, что лингвистические категории и их использова- ние лишь влияют на мышление и принимаемые решения. В общем и целом лингвисты соглашаются, что сильная версия ложна, но су- ществуют эмпирические свидетельства в поддержку слабой версии. Мне неизвестны конкретные исследования в отношении языков программи- рования, но мой опыт показывает, что они сильно влияют на подход к проб- леме. Первым языком, на котором я работал профессионально, был Applesoft BASIC – еще во времена 8-разрядных компьютеров. BASIC не поддерживал рекурсию непосредственно – приходилось самостоятельно раскручивать стек вызовов. Поэтому я никогда не рассматривал рекурсивные алгоритмы и структуры данных. Я знал, что на некотором концептуальном уровне такие вещи существовали, но они не входили в мой инструментарий. Несколько десятков лет спустя, начиная осваивать Elixir, я получал наслаж - дение от рекурсивного решения задач и даже злоупотреблял рекурсией – пока не обнаружил, что многие мои решения были бы проще, если бы я ис - пользовал уже готовые функции из модулей Elixir Enum и Stream. Я узнал, что в идиоматическом коде прикладного уровня на Elixir рекурсивные вызовы редко бывают необходимы, зато перечисления и потоки реализуют рекур- сию под капотом. Гипотеза лингвистической относительности могла бы объяснить широко рас- пространенную (хотя и не доказанную) идею о том, что изучение разных язы- ков программирования делает из вас лучшего программиста, особенно ког- да языки поддерживают различные парадигмы программирования. Знание Elixir позволило мне применять функциональные паттерны при программи- ровании на Python или Go. А теперь вернемся на грешную землю.296  Аннотации типов в функциях\n--- Страница 296 ---\nПакет requests, вероятно, имел бы совершенно другой API, если бы Кеннет Рейц решил сам (или ему велел бы начальник) аннотировать все функции. Он ставил себе целью написать API, которым было бы легко пользоваться, который был бы мощным и вместе с тем гибким. В этом он преуспел, и па- кет requests снискал огромную популярность – в мае 2020 года он занимал четвертое место в статистике PyPI (https://pypistats.org/top) с числом скачива- ний 2,6 миллиона в день. Первое место занимает пакет urllib3, от которого requests зависит. В 2017 году люди, отвечающие за сопровождение requests, решили (https:// github.com/psf/requests/issues/3855) не тратить время на написание аннотаций типов. Один из них, Кори Бенфилд, в почтовом сообщении писал: Я думаю, что библиотеки с питоническим API в меньшей степени нуждаются в этой системе типов, потому что ценность ее для них ми- нимальна. В этом сообщении Бенфилд привел доведенный до абсурда пример попыт - ки определения типа для именованного аргумента files функции requests. request() (https://docs.python-requests.org/en/master/api/#requests.request): Optional[ Union[ Mapping[ basestring, Union[ Tuple[basestring, Optional[Union[basestring, file]]], Tuple[basestring, Optional[Union[basestring, file]], Optional[basestring]], Tuple[basestring, Optional[Union[basestring, file]], Optional[basestring], Optional[Headers]] ] ], Iterable[ Tuple[ basestring, Union[ Tuple[basestring, Optional[Union[basestring, file]]], Tuple[basestring, Optional[Union[basestring, file]], Optional[basestring]], Tuple[basestring, Optional[Union[basestring, file]], Optional[basestring], Optional[Headers]] ] ] ] ] При этом еще предполагается следующее определение: Headers = Union[ Mapping[basestring, basestring], Iterable[Tuple[basestring, basestring]], ] Дополнительная литература  297\n--- Страница 297 ---\nКак вы думаете, достигла бы библиотека requests такого успеха, если бы сопро- вождающие настаивали на 100-процентном покрытии аннотациями типов? SQLAlchemy – еще один важный пакет, который плохо уживается с аннотациями. Своим успехом эти библиотеки обязаны тем, что на всю катушку используют динамическую природу Python. У аннотаций типов есть достоинства, но есть и цена. Во-первых, нужно потратить усилия, чтобы понять, как работает система типов. Но это одноразовые затраты. А есть еще и постоянные, которые придется нести всегда. Настаивая на вставке аннотаций везде и всюду, мы теряем часть выразитель- ности Python. Такие замечательные средства, как распаковка аргументов – например, config(**settings ), – выходят за пределы возможностей программ проверки типов. Если вы хотите подвергнуть вызов вида config(**settings ) проверке типов, то должны будете выписать каждый аргумент. Это наводит меня на воспомина- ния о Turbo Pascal, на котором я писал 35 лет назад. Библиотеки, в которых используется метапрограммирование, трудно или даже невозможно анотировать. Конечно, метапрограммирование можно упо- требить во вред, но одновременно это вещь, благодаря которой со многими Python-пакетами так приятно работать. Если в крупных компаниях использование аннотаций типов станет непре- рекаемым требованием, не допускающим исключений, то держу пари, что вскоре люди начнут использовать кодогенераторы, чтобы уменьшить объем стереотипного кода, – типичная практика в менее динамичных языках. В некоторых проектах и контекстах аннотации типов просто не имеют смыс - ла. И даже в тех контекстах, где в большинстве случаев смысл есть, бывают ис- ключения. Любая разумная политика использования аннотаций типов долж - на допускать исключения. Алан Кэй, лауреат премии Тьюринга, один из пионеров объектно-ориентиро- ванного программирования, писал: Некоторые относятся к системе типов с религиозным рвением. Мне как математику идея систем типов нравится, но никто еще не придумал си- стему с достаточно широким охватом1. Спасибо Гвидо за факультативную типизацию. Давайте будем использовать ее так, как она задумана, и не пытаться аннотировать все вокруг в строгом со- ответствии со стилем кодирования, напоминающим Java 1.5. Пригодность утиной типизации Утиная типизация отвечает моему складу ума, а статическая утиная типи- зация – удачный компромисс, допускающий статическую проверку типов, не жертвуя гибкостью, которая в некоторых системах номинальной типиза- ции возможна лишь ценой сильного усложнения – если вообще возможна. До выхода PEP 544 вся идея аннотаций типов казалась мне в высшей степе- ни чуждой Python. Я был очень рад, когда увидел, как typing.Protocol вписался в Python. Это внесло некоторое равновесие. 1 Источник: «Интервью с Аланом Кэем» (https://queue.acm.org/detail.cfm?id=1039523). 298  Аннотации типов в функциях\n--- Страница 298 ---\nОбобщенные или конкретные? С точки зрения Python, использование термина «обобщенный» в системе ти- пов вывернуто наизнанку. Обычно, говоря «обобщенный» (generic), имеют в виду «применимый к целому классу или группе» либо «без торговой марки»1. Сравним list и list[str]. Первый список является обобщенным: он принимает любой объект. Второй список конкретный: он принимает только str. Однако в Java этот термин имеет смысл. До выхода Java 1.5 все коллекции в Java (кроме магического array) были «конкретными»: они могли хранить только ссылки на Object, поэтому для использования элементов, извлекаемых из коллекции, приходилось приводить тип. В Java 1.5 коллекции получили па- раметры-типы и стали «обобщенными». 1 В этом смысле вместо «обобщенный» в русском языке употребляется слово «джене- рик». – Прим. перев. Дополнительная литература  299",
      "debug": {
        "start_page": 253,
        "end_page": 298
      }
    },
    {
      "name": "Глава 9. Декораторы и замыкания 300",
      "content": "--- Страница 299 --- (продолжение)\nГлава 9 Декораторы и замыкания Многие были недовольны выбором названия «декоратор» для этого сред- ства. И главная причина – несогласованность с использованием термина в книге «Банды четырех»1. Название декоратор, пожалуй, в большей сте- пени связано с употреблением в области разработки компиляторов – об- ход и аннотирование синтаксического дерева. – PEP 318 «Decorators for Functions and Methods» Декораторы функций дают возможность «помечать» функции в исходном коде, тем или иным способом дополняя их поведение. Это мощное средство, но для овладения им нужно понимать, что такое замыкание – то, что мы полу - чаем, когда функция захватывает переменную, определенную вне ее тела. Одно из самых плохо понимаемых зарезервированных слов в Python – nonlocal, оно появилось в версии Python 3.0. Программист на Python может без- бедно существовать, и не используя его, если будет строго придерживаться объектно-ориентированной диеты, основанной на классах. Но если вы захо- тите реализовать собственные декораторы функций, то должны досконально разбираться в замыканиях, а тогда потребность в слове nonlocal становится очевидной. Помимо применения при реализации декораторов, замыкания важны так- же для эффективного асинхронного программирования без обратных вызовов и для кодирования в функциональном стиле там, где это имеет смысл. Конечная цель этой главы – точно объяснить, как работают декораторы – от простейших регистрационных до более сложных параметризованных. Но преж де нам предстоит рассмотреть следующие вопросы: как интерпретатор Python разбирает синтаксис декораторов; как Python решает, является ли переменная локальной; зачем нужны замыкания и как они работают; какие проблемы решает ключевое слово nonlocal. Заложив этот фундамент, мы сможем перейти непосредственно к декораторам: реализация корректно ведущего себя декоратора; мощные декораторы в стандартной библиотеке: @cache, @lru_cache и @singledispatch ; реализация параметризованного декоратора. 1 Вышедшая в1995 году книга «Design Patterns» за авторством так называемой «банды четырех» (Gamma et al., Addison-Wesley).\nГлава 9 Декораторы и замыкания Многие были недовольны выбором названия «декоратор» для этого сред- ства. И главная причина – несогласованность с использованием термина в книге «Банды четырех»1. Название декоратор, пожалуй, в большей сте- пени связано с употреблением в области разработки компиляторов – об- ход и аннотирование синтаксического дерева. – PEP 318 «Decorators for Functions and Methods» Декораторы функций дают возможность «помечать» функции в исходном коде, тем или иным способом дополняя их поведение. Это мощное средство, но для овладения им нужно понимать, что такое замыкание – то, что мы полу - чаем, когда функция захватывает переменную, определенную вне ее тела. Одно из самых плохо понимаемых зарезервированных слов в Python – nonlocal, оно появилось в версии Python 3.0. Программист на Python может без- бедно существовать, и не используя его, если будет строго придерживаться объектно-ориентированной диеты, основанной на классах. Но если вы захо- тите реализовать собственные декораторы функций, то должны досконально разбираться в замыканиях, а тогда потребность в слове nonlocal становится очевидной. Помимо применения при реализации декораторов, замыкания важны так- же для эффективного асинхронного программирования без обратных вызовов и для кодирования в функциональном стиле там, где это имеет смысл. Конечная цель этой главы – точно объяснить, как работают декораторы – от простейших регистрационных до более сложных параметризованных. Но преж де нам предстоит рассмотреть следующие вопросы: как интерпретатор Python разбирает синтаксис декораторов; как Python решает, является ли переменная локальной; зачем нужны замыкания и как они работают; какие проблемы решает ключевое слово nonlocal. Заложив этот фундамент, мы сможем перейти непосредственно к декораторам: реализация корректно ведущего себя декоратора; мощные декораторы в стандартной библиотеке: @cache, @lru_cache и @singledispatch ; реализация параметризованного декоратора. 1 Вышедшая в1995 году книга «Design Patterns» за авторством так называемой «банды четырех» (Gamma et al., Addison-Wesley).\n--- Страница 300 ---\nчтО нОвОг О в этОй главе Кеширующий декоратор functools.cache – новое средство в Python 3.9 – проще традиционного functools.lru_cache , поэтому я представляю его первым. А вто- рой, включая его упрощенную форму, появившуюся в Python 3.8, рассматрива- ется в разделе «Использование lru_cache». Раздел «Обобщенные функции с одиночной диспетчеризацией» был расши- рен, и теперь в нем используются аннотации типов – рекомендуемый способ использования functools.singledispatch начиная с Python 3.7. Раздел «Параметризованные декораторы» теперь включает пример 9.27, в котором декоратор реализован в виде класса. Я перенес главу 10 «Реализация паттернов проектирования с помощью полноправных функций» в конец части II, чтобы сделать последовательность изложения более логичной. Раздел «Паттерн Стратегия, дополненный декора- тором» теперь находится в этой главе вместе с другими вариантами паттерна Стратегия, основанными на использовании вызываемых объектов. Начнем с самых базовых понятий, относящихся к декораторам, а затем об- ратимся к остальным перечисленным выше темам. кратк Ое введение в декОрат Оры Декоратор – это вызываемый объект, который принимает другую функцию в качестве аргумента (декорируемую функцию). Декоратор может производить какие-то операции с функцией и возвра- щает либо ее саму, либо другую заменяющую ее функцию или вызываемый объект1. Иначе говоря, в предположении, что существует декоратор с именем decorate, следующий код: @decorate def target(): print('running target()') эквивалентен такому: def target(): print('running target()') target = decorate(target) Конечный результат одинаков: в конце обоих фрагментов имя target связано с функцией target, которую вернул вызов decorate(target) . Это может быть функ - ция, которая изначально называлась target, или какая-то другая. Чтобы убедиться, что декорируемая функция действительно заменена, рас- смотрим сеанс оболочки в примере 9.1. 1 Если в предыдущем предложении заменить слово «функция» словом «класс», то по- лучится краткое описание того, что делает декоратор класса. Декораторы классов рассматриваются в главе 24. Краткое введение в декораторы  301\n--- Страница 301 ---\nПример 9.1. Декоратор обычно заменяет одну функцию другой >>> def deco(func): def inner(): print('running inner()') return inner  >>> @deco def target():  print('running target()') >>> target()  running inner() 2 >>> target  <function deco.<locals>.inner at 0x10063b598>  deco возвращает свой внутренний объект-функцию inner.  target декорирована deco.  При вызове декорированной функции target на самом деле выполняется inner.  Инспекция показывает, что target теперь ссылается на inner. Строго говоря, декораторы – не более чем синтаксический сахар. Как мы ви- дели, всегда можно просто вызвать декоратор как обычный вызываемый объект, передав ему функцию. Иногда это действительно удобно, особенно для метапро- граммирования – изменения поведения программы в процессе ее выполнения. Следующие три факта – главное, что нужно знать о декораторах: декоратор – это функция или другой вызываемый объект; декоратор может заменить декорируемую функцию другой; декораторы выполняются сразу после загрузки модуля. Теперь сосредоточим внимание на последнем моменте. кОгда python выпО лняет декОрат Оры Главное свойство декораторов – то, что они выполняются сразу после опреде- ления декорируемой функции. Обычно на этапе импорта (т. е. когда Python загружает модуль). Рассмотрим скрипт registration.py в примере 9.2. Пример 9.2. Модуль registration.py registry = []  def register(func):  print(f'running register({func})')  registry.append(func)  return func  @register  def f1(): print('running f1()') @register302  Декораторы и замыкания\n--- Страница 302 ---\ndef f2(): print('running f2()') def f3():  print('running f3()') def main():  print('running main()') print('registry ->', registry) f1() f2() f3() if __name__ == '__main__': main()   В registry хранятся ссылки на функции, декорированные @register.  register принимает функцию в качестве аргумента.  Показать, какая функция декорируется, – для демонстрации.  Включить func в registry.  Вернуть func: мы должны вернуть функцию, в данном случае возвращается та же функция, что была передана на входе.  f1 и f2 декорированы @register.  f3 не декорирована.  main распечатывает registry, затем вызывает f1(), f2() и f3().  main() вызывается только тогда, когда registration.py запускается как скрипт. Будучи запущена как скрипт, программа registration.py выводит следующие строки: $ python3 registration.py running register(<function f1 at 0x100631bf8>) running register(<function f2 at 0x100631c80>) running main() registry -> [<function f1 at 0x100631bf8>, <function f2 at 0x100631c80>] running f1() running f2() running f3() Отметим, что register выполняется (дважды) до любой другой функции в мо- дуле. При вызове register получает в качестве аргумента декорируемый объ- ект-функцию, например <function f1 at 0x100631bf8> . После загрузки модуля в registry оказываются ссылки на две декорирован- ные функции: f1 и f2. Они, как и функция f3, выполняются только при явном вызове из main. Если registration.py импортируется (а не запускается как скрипт), то вывод выглядит так: >>> import registration running register(<function f1 at 0x10063b1e0>) running register(<function f2 at 0x10063b268>) Если сейчас заглянуть в registry, то мы увидим: Когда Python выполняет декораторы  303\n--- Страница 303 ---\n>>> registration.registry [<function f1 at 0x10063b1e0>, <function f2 at 0x10063b268>] Основная цель примера 9.2 – подчеркнуть, что декораторы функций выпол- няются сразу после импорта модуля, но сами декорируемые функции – только в результате явного вызова. В этом проявляется различие между этапом им- порта и этапом выполнения в Python. региС трациОнные декОрат Оры По сравнению с типичным применением декораторов в реальных програм- мах, пример 9.2 необычен в двух отношениях. Функция-декоратор определена в том же модуле, что и декорируемые функции. Настоящий декоратор обычно определяется в одном модуле и применяется к функциям из других модулей. Декоратор register возвращает ту же функцию, что была передана в качест ве аргумента. На практике декоратор обычно определяет вну- треннюю функцию и возвращает именно ее. Хотя декоратор register из примера 9.2 возвращает декорированную функ - цию без изменения, эта техника не бесполезна. Подобные декораторы исполь- зуются во многих веб-каркасах, написанных на Python, с целью добавления функций в некий центральный реестр, например для отображения образцов URL на функции, генерирующие HTTP-ответы. Такие регистрационные деко- раторы могут изменять декорируемую функцию, но это необязательно. Мы увидим, как применяется регистрационный декоратор, в разделе «Пат - терн Стратегия, дополненный декоратором» главы 10. Большинство декораторов все же изменяют декорируемую функцию. Обыч- но для этого определяется некая внутренняя функция, которая заменяет де- корируемую. Код, в котором используются внутренние функции, неизбежно опирается на замыкания. Чтобы понять, что такое замыкания, нам придется отступить назад и тщательно разобраться с тем, как в Python работают области видимости переменных. правила видимОС ти переменных В примере 9.3 мы определяем и тестируем функцию, которая читает две пе- ременные: локальную переменную a, определенную как параметр функции, и переменную b, которая внутри функции вообще не определена. Пример 9.3. Функция, читающая локальную и глобальную переменные >>> def f1(a): print(a) print(b) >>> f1(3) 3 Traceback (most recent call last): File \"<stdin>\", line 1, in <module> File \"<stdin>\", line 3, in f1 NameError: global name 'b' is not defined304  Декораторы и замыкания\n--- Страница 304 ---\nОшибка не должна вызывать удивления. Но если продолжить пример 9.3 и присвоить значение глобальной переменной b, а затем вызвать f1, то все за- работает: >>> b = 6 >>> f1(3) 3 6 А теперь рассмотрим пример, который, возможно, вас удивит. Взгляните на функцию f2 в примере 9.4. Первые две строчки в ней такие же, как в f1 из примера 9.3, но затем мы присваиваем значение переменной b. Однако функция завершается с ошибкой на втором предложении print, до при- сваивания. Пример 9.4. Переменная b локальна, потому что ей присваивается значение в теле функции >>> b = 6 >>> def f2(a): print(a) print(b) b = 9 >>> f2(3) 3 Traceback (most recent call last): File \"<stdin>\", line 1, in <module> File \"<stdin>\", line 3, in f2 UnboundLocalError: local variable 'b' referenced before assignment Отметим, что число 3 все же напечатано, следовательно, предложение print(a) было выполнено. Но вот до print(b) дело так и не дошло. Впервые увидев этот пример, я очень удивился, так как думал, что 6 будет напечатано – ведь существует глобальная переменная b, а присваивание локальной b произво- дится уже после print(b). Однако же, компилируя тело этой функции, Python решает, что b – локаль- ная переменная, т. к. ей присваивается значение внутри функции. Сгенериро- ванный байт-код отражает это решение и пытается выбрать b из локального контекста. Позже, во время вызова f2(3), тело f2 успешно находит и печатает локальную переменную a, но при попытке получить значение локальной пере- менной b обнаруживает, что b не связана. Это не ошибка, а осознанный выбор: Python не заставляет нас объявлять переменные, но предполагает, что всякая переменная, которой присваивается значение в теле функции, локальна. Это гораздо лучше поведения JavaScript, который тоже не требует объявлять переменные, но если вы забудете объявить переменную локальной (с помощью зарезервированного слова var), то можете случайно затереть одноименную глобальную переменную. Если нам нужно, чтобы интерпретатор считал переменную b глобальной, несмотря на присваивание внутри функции, то придется добавить объявле- ние global: Правила видимости переменных  305\n--- Страница 305 ---\n>>> b = 6 >>> def f3(a): global b print(a) print(b) b = 9 >>> f3(3) 3 6 >>> b 9 В примерах выше имеется две области видимости: Глобальная область видимости модуля Образована именами, которым присвоены значения, не объявленные ни в одном блоке класса или функции. Локальная область видимости функции f3 Образована именами, которым присвоены значения как параметрам или непосредственно в теле функции. Существует еще одна область видимости, из которой могут происходить пе- ременные. Она называется нелокальной и является фундаментальной для за- мыканий; мы познакомимся с ней чуть ниже. После этого краткого знакомства с принципом работы областей видимости в Python мы можем приступить к замыканиям. А вниманию тех, кому интерес - но посмотреть, чем отличается байт-код функций из примеров 9.3 и 9.4, пред- лагается следующая врезка. Сравнение байт-кода Модуль dis позволяет без труда дизассемблировать байт-код функций Python. В примерах 9.5 и 9.6 показан байт-код функций f1 и f2 из примеров 9.3 и 9.4. Пример 9.5. Дизассемблированная функция f1 из примера 9.3 >>> from dis import dis >>> dis(f1) 2 0 LOAD_GLOBAL 0 (print)  3 LOAD_FAST 0 (a)  6 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 9 POP_TOP 3 10 LOAD_GLOBAL 0 (print) 13 LOAD_GLOBAL 1 (b)  16 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 19 POP_TOP 20 LOAD_CONST 0 (None) 23 RETURN VALUE  Загрузить глобальное имя print.  Загрузить локальное имя a.  Загрузить глобальное имя b.306  Декораторы и замыкания\n--- Страница 306 ---\nА теперь сравните с байт-кодом функции f2 в примере 9.6. Пример 9.6. Дизассемблированная функция f1 из примера 9.4 >>> dis(f2) 2 0 LOAD_GLOBAL 0 (print) 3 LOAD_FAST 0 (a) 6 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 9 POP_TOP 3 10 LOAD_GLOBAL 0 (print) 13 LOAD_FAST 1 (b)  16 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 19 POP_TOP 4 20 LOAD_CONST 1 (9) 23 STORE_FAST 1 (b) 26 LOAD_CONST 0 (None) 29 RETURN_VALUE  Загрузить локальное имя b. Как видим, компилятор считает b локальной переменной, даже если присваивание b встречается позже, поскольку природа переменной – локальная она или нет – не должна приводить к изменению тела функции. Виртуальная машина CPython, которая исполняет байт-код, – это стековая машина, т. е. операции LOAD и POP относятся к стеку. Дальнейшее описание ко- дов операций Python выходит за рамки этой книги, но они документированы в разделе, посвященном модулю dis: «Дизассемблер байт-кода Python» (http:// docs.python.org/3/library/dis.html). замыкания В блогосфере замыкания иногда путают с анонимными функциями. Причина тому историческая: определение функций внутри функций кажется делом не- обычным до тех пор, пока мы не начинаем пользоваться анонимными функ - циями. А замыкания вступают в игру только при наличии вложенных функ - ций. Поэтому многие изучают обе концепции одновременно. На самом деле замыкание – это функция, назовем ее f, с расширенной об- ластью видимости, которая охватывает переменные, на которые есть ссылки в теле f, но которые не являются ни глобальными, ни локальными переменны- ми f. Такие переменные должны происходить из локальной области видимо- сти внешней функции, объемлющей f. Не имеет значения, является функция анонимной или нет; важно лишь, что она может обращаться к неглобальным переменным, определенным вне ее тела. Эту идею довольно трудно переварить, поэтому лучше продемонстрировать ее на примере. Рассмотрим функцию avg, которая вычисляет среднее продолжающегося ряда чисел, например среднюю цену закрытия биржевого товара за всю исто- рию торгов. Каждый день ряд пополняется новой ценой, а при вычислении среднего учитываются все прежние цены. Замыкания  307\n--- Страница 307 ---\nЕсли начать с чистого листа, то функцию avg можно было бы использовать следующим образом: >>> avg(10) 10.0 >>> avg(11) 10.5 >>> avg(12) 11.0 Откуда берется avg и где она хранит предыдущие значения? Для начала покажем реализацию, основанную на классах. Пример 9.7. average_oo.py: класс для вычисления накопительного среднего class Averager(): def __init__(self): self.series = [] def __call__(self, new_value): self.series.append(new_value) total = sum(self.series) return total / len(self.series) Класс Averager создает вызываемые объекты: >>> avg = Averager() >>> avg(10) 10.0 >>> avg(11) 10.5 >>> avg(12) 11.0 А теперь покажем функциональную реализацию с использованием функ - ции высшего порядка make_averager . Пример 9.8. average.py: функция высшего порядка для вычисления накопительного средне- го def make_averager(): series = [] def averager(new_value): series.append(new_value) total = sum(series) return total / len(series) return averager При обращении к make_averager возвращается объект-функция averager. При каждом вызове averager добавляет переданный аргумент в конец списка series и вычисляет текущее среднее, как показано в примере 9.9.308  Декораторы и замыкания\n--- Страница 308 ---\nПример 9.9. Тестирование функции из примера 9.8 >>> avg = make_averager() >>> avg(10) 10.0 >>> avg(11) 10.5 >>> avg(15) 12.0 Обратите внимание на сходство обоих примеров: мы обращаемся к Averager() или к make_averager() , чтобы получить вызываемый объект avg, который обновля- ет временной ряд и вычисляет текущее среднее. В примере 9.7 avg – экземпляр Averager, а в примере 9.8 – внутренняя функция averager. И в том, и в другом случае мы просто вызываем avg(n), чтобы добавить n в ряд и вычислить новое среднее. Совершенно ясно, где хранит историю объект avg класса Averager: в атрибуте экземпляра self.series . Но где находит series функция avg из второго примера? Обратите внимание, что series – локальная переменная make_averager , потому что инициализация series = [] производится в теле этой функции. Но к момен- ту вызова avg(10) функция make_averager уже вернула управление, и ее локальная область видимости уничтожена. Внутри averager series является свободной переменной. Этот технический тер- мин означает, что переменная не связана в локальной области видимости. См. рис. 9.1. замыканиеdef make_averager(): series = [] def averager(new_value): series.append(new_value) total = sum(series) return total/len(series) return averagerсвободная переменная Рис. 9.1. Замыкание averager расширяет область видимости функции, включая в нее при- вязку свободной переменной series Инспекция возвращенного объекта averager показывает, что Python хранит имена локальных и свободных переменных в атрибуте __code__, который пред- ставляет собой откомпилированное тело функции. Это показано в примере 9.10. Пример 9.10. Инспекция функции, созданной функцией make_averager из примера 9.8 >>> avg.__code__.co_varnames ('new_value', 'total') >>> avg.__code__.co_freevars ('series',) Значение переменной series хранится в атрибуте __closure__ возвращенной функции avg. Каждому элементу avg.__closure__ соответствует имя в avg.__code__. co_freevars . Эти элементы называются ячейками (cells), и у каждого из них есть Замыкания  309\n--- Страница 309 ---\nатрибут cell_contents , где можно найти само значение. Эти атрибуты демон- стрируются в примере 9.11. Пример 9.11. Продолжение примера 9.9 >>> avg.__code__.co_freevars ('series',) >>> avg.__closure__ (<cell at 0x107a44f78: list object at 0x107a91a48>,) >>> avg.__closure__[0].cell_contents [10, 11, 12] Резюмируем: замыкание – это функция, которая запоминает привязки сво- бодных переменных, существовавшие на момент определения функции, так что их можно использовать впоследствии при вызове функции, когда область видимости, в которой она была определена, уже не существует. Отметим, что единственная ситуация, когда функции может понадобиться доступ к внешним неглобальным переменным, – это когда она вложена в дру - гую функцию и эти переменные являются частью локальной области видимо- сти внешней функции. ОБъявление nonloc Al Приведенная выше реализация функции make_averager неэффективна. В при- мере 9.8 мы храним все значения во временном ряде и вычисляем их сум- му при каждом вызове averager. Лучше было бы хранить предыдущую сумму и количество элементов, тогда, зная эти два числа, можно вычислить новое среднее. Реализация в примере 9.12 некорректна и приведена только в педагогиче- ских целях. Сможете ли вы найти ошибку? Пример 9.12. Неправильная функция высшего порядка для вычисления накопительного среднего без хранения всей истории def make_averager(): count = 0 total = 0 def averager(new_value): count += 1 total += new_value return total / count return averager При попытке выполнить этот код получится вот что: >>> avg = make_averager() >>> avg(10) Traceback (most recent call last): UnboundLocalError: local variable 'count' referenced before assignment >>>310  Декораторы и замыкания\n--- Страница 310 ---\nПроблема в том, что предложение count += 1 означает то же самое, что count = count + 1 , где count – число или любой неизменяемый тип. То есть мы по сути дела присваиваем count значение в теле averager, делая ее тем самым локальной переменной. То же относится к переменной total. В примере 9.8 этой проблемы не было, потому что мы ничего не присваива- ли переменной series; мы лишь вызывали series.append и передавали ее функци- ям sum и len. То есть воспользовались тем, что список – изменяемый тип. Однако переменные неизменяемых типов – числа, строки, кортежи и т. д. – разрешается только читать, но не изменять. Если попытаться перепривязать такую переменную, как в случае count = count + 1 , то мы неявно создадим ло- кальную переменную count. Она уже не является свободной и потому не запо- минается в замыкании. Чтобы обойти эту проблему, в Python 3 было добавлено объявление nonlocal. Оно позволяет пометить переменную как свободную, даже если ей присваи- вается новое значение внутри функции. В таком случае изменяется привязка, хранящаяся в замыкании. Корректная реализация функции make_averager пока- зана в примере 9.13. Пример 9.13. Вычисление накопительного среднего без хранения всей истории (ис- правленный вариант с nonlocal) def make_averager(): count = 0 total = 0 def averager(new_value): nonlocal count, total count += 1 total += new_value return total / count return averager Поняв, как используется nonlocal, суммируем все, что мы знаем о поиске пе- ременных в Python. Логика поиска переменных Встретив определение функции, компилятор байт-кода Python определяет, как найти встречающуюся в ней переменную x, руководствуясь следующими правилами1: если имеется объявление global x, то x берется из него и присваивается глобальной переменной x уровня модуля2; если имеется объявление nonlocal x , то x берется из него и присваивается локальной переменной x в ближайшей объемлющей функции, в которой x определена; если x – параметр или ей присвоено значение в теле функции, то x – ло- кальная переменная; 1 Благодарю технического рецензента Леонардо Рохаэля, который предложил эту сводку. 2 В Python нет области видимости уровня программы, только уровня модуля. Объявление nonlocal  311\n--- Страница 311 ---\nесли на x имеется ссылка, но значение ей не присвоено и параметром она тоже не является, то:  x ищется в локальных областях видимости тел объемлющих функ - ций (нелокальных областях видимости);  если она не найдена в объемлющих областях видимости, то читает - ся из глобальной области видимости модуля;  если она не найдена и в глобальной области видимости, то читается из __builtins__.__dict__ . Теперь, познакомившись с замыканиями в Python, мы можем продемон- стрировать эффективную реализацию декораторов с помощью вложенных функций. реализация прОСтОгО декОрат Ора В примере 9.14 показан декоратор, который хронометрирует каждый вызов декорируемой функции и печатает затраченное время, переданные аргумен- ты и результат. Пример 9.14. Простой декоратор для вывода времени выполнения функции import time def clock(func): def clocked(*args):  t0 = time.perf_counter() result = func(*args)  elapsed = time.perf_counter() - t0 name = func.__name__ arg_str = ', '.join(repr(arg) for arg in args) print(f'[{elapsed:0.8f}s] {name}({arg_str}) -> {result!r}') return result  return clocked  Определить внутреннюю функцию clocked, принимающую произвольное число позиционных аргументов.  Эта функция работает только потому, что замыкание clocked включает сво- бодную переменную func.  Вернуть внутреннюю функцию взамен декорируемой. В примере 9.15 демонстрируется использование декоратора clock. Пример 9.15. Использование декоратора clock import time from clockdeco0 import clock @clock def snooze(seconds): time.sleep(seconds) @clock def factorial(n): return 1 if n < 2 else n*factorial(n-1)312  Декораторы и замыкания\n--- Страница 312 ---\nif __name__ == '__main__': print('*' * 40, 'Calling snooze(.123)') snooze(.123) print('*' * 40, 'Calling factorial(6)') print('6! =', factorial(6)) Вот что выводит этот код: $ python3 clockdeco_demo.py **************************************** Calling snooze(.123) [0.12363791s] snooze(0.123) -> None **************************************** Calling factorial(6) [0.00000095s] factorial(1) -> 1 [0.00002408s] factorial(2) -> 2 [0.00003934s] factorial(3) -> 6 [0.00005221s] factorial(4) -> 24 [0.00006390s] factorial(5) -> 120 [0.00008297s] factorial(6) -> 720 6! = 720 Как это работает Напомним, что код @clock def factorial(n): return 1 if n < 2 else n*factorial(n-1) на самом деле эквивалентен следующему: def factorial(n): return 1 if n < 2 else n*factorial(n-1) factorial = clock(factorial) То есть в обоих случаях декоратор clock получает функцию factorial в качест- ве аргумента func (см. пример 9.14). Затем он создает и возвращает функ - цию clocked, которую интерпретатор Python за кулисами связывает с именем factorial. На самом деле если импортировать модуль clockdeco_demo и вывести атрибут __name__ функции factorial, то мы увидим: >>> import clockdeco_demo >>> clockdeco_demo.factorial.__name__ 'clocked' >>> Таким образом, factorial действительно хранит ссылку на функцию clocked. Начиная с этого момента при каждом вызове factorial(n) выполняется clocked(n) . А делает clocked вот что: 1. Запоминает начальный момент времени t0. 2. Вызывает исходную функцию factorial и сохраняет результат. 3. Вычисляет, сколько прошло времени. 4. Форматирует и печатает собранные данные. 5. Возвращает результат, сохраненный на шаге 2. Это типичное поведение декоратора: заменить декорируемую функцию но- вой, которая принимает те же самые аргументы и (как правило) возвращает то, Реализация простого декоратора  313\n--- Страница 313 ---\nчто должна была бы вернуть декорируемая функция, но при этом произвести какие-то дополнительные действия. В книге Гамма и др. «Паттерны проектирования» краткое опи- сание паттерна Декоратор начинается словами: «Динамически добавляет объекту новые обязанности». Декораторы функций отвечают этому описанию. Но на уровне реализации декорато- ры в Python имеют мало общего с классическим Декоратором, описанным в оригинальной книге. Ниже, во врезке «Погово- рим», я еще вернусь к этой теме. Декоратор clock, реализованный в примере 9.14, имеет ряд недостатков: он не поддерживает именованные аргументы и маскирует атрибуты __name__ и __doc__ декорированной функции. В примере 9.16 используется декоратор functools.wraps , который копирует необходимые атрибуты из func в clocked. К тому же в этой новой версии правильно обрабатываются именованные ар- гументы. Пример 9.16. clockdeco.py: улучшенный декоратор clock import time import functools def clock(func): @functools.wraps(func) def clocked(*args, **kwargs): t0 = time.perf_counter() result = func(*args, **kwargs) elapsed = time.perf_counter() - t0 name = func.__name__ arg_lst = [repr(arg) for arg in args] arg_lst.extend(f'{k}={v!r}' for k, v in kwargs.items()) arg_str = ', '.join(arg_lst) print(f'[{elapsed:0.8f}s] {name}({arg_str}) -> {result!r}') return result return clocked Декоратор functools.wraps – лишь один из нескольких готовых декораторов в стандартной библиотеке. В следующем разделе мы рассмотрим самый впе- чатляющий декоратор в модуле functools: cache. декОрат Оры в СтандартнОй БиБлиО теке В Python есть три встроенные функции, предназначенные для декорирования методов: property, classmethod и staticmethod . Функцию property мы обсудим в раз- деле «Использование свойств для контроля атрибутов» главы 22, а остальные – в разделе «Декораторы classmethod и staticmethod» главы 11. В примере 9.16 мы видели еще один важный декоратор – functools.wraps , вспо- могательное средство для построения корректных декораторов. Некоторые из наиболее интересных декораторов в стандартной библиотеке – cache, lru_cache и singledispatch – определены в модуле functools. Их мы далее и рассмотрим. 314  Декораторы и замыкания\n--- Страница 314 ---\nЗапоминание с помощью functools.cache Декоратор functools.lru_cache реализует запоминание1 (memoization): прием оп- тимизации, смысл которого заключается в сохранении результатов предыду - щих дорогостоящих вызовов функции, что позволяет избежать повторного вычисления с теми же аргументами, что и раньше. Декоратор functools.cache был добавлен в версии Python 3.9. Если вы хотите выполнить приведенные ниже примеры в Python 3.8, замените @cache на @lru_cache . В более ранних версиях Python нужно вызывать декоратор, записывая @lru_cache() , как объясня- ется в разделе «Использование lru_cache ». Продемонстрируем применение cache на примере медленной рекурсивной функции вычисления n-го числа Фибоначчи. Пример 9.17. Очень накладный рекурсивный способ вычисления n-го числа Фибоначчи from clockdeco import clock @clock def fibonacci(n): if n < 2: return n return fibonacci(n - 2) + fibonacci(n - 1) if __name__ == '__main__': print(fibonacci(6)) Вот результат работы fibo_demo.py. Все строки, кроме последней, выведены декоратором clock: $ python3 fibo_demo.py [0.00000095s] fibonacci(0) -> 0 [0.00000095s] fibonacci(1) -> 1 [0.00007892s] fibonacci(2) -> 1 [0.00000095s] fibonacci(1) -> 1 [0.00000095s] fibonacci(0) -> 0 [0.00000095s] fibonacci(1) -> 1 [0.00003815s] fibonacci(2) -> 1 [0.00007391s] fibonacci(3) -> 2 [0.00018883s] fibonacci(4) -> 3 [0.00000000s] fibonacci(1) -> 1 [0.00000095s] fibonacci(0) -> 0 [0.00000119s] fibonacci(1) -> 1 [0.00004911s] fibonacci(2) -> 1 [0.00009704s] fibonacci(3) -> 2 [0.00000000s] fibonacci(0) -> 0 [0.00000000s] fibonacci(1) -> 1 [0.00002694s] fibonacci(2) -> 1 [0.00000095s] fibonacci(1) -> 1 [0.00000095s] fibonacci(0) -> 0 1 Уточним: в слове memoization ( https://en.wikipedia.org/wiki/Memoization) нет опечатки. В информатике этот термин хоть и отдаленно связан с «memorization» (сохранение в памяти), но означают они не одно и то же. Декораторы в стандартной библиотеке  315\n--- Страница 315 ---\n[0.00000095s] fibonacci(1) -> 1 [0.00005102s] fibonacci(2) -> 1 [0.00008917s] fibonacci(3) -> 2 [0.00015593s] fibonacci(4) -> 3 [0.00029993s] fibonacci(5) -> 5 [0.00052810s] fibonacci(6) -> 8 8 Непроизводительные затраты бросаются в глаза: fibonacci(1) вызывается во- семь раз, fibonacci(2) – пять раз и т. д. Но если добавить две строчки, чтобы за- действовать cache, то производительность резко возрастет. Пример 9.18. Более быстрая реализация с использованием кеширования import functools from clockdeco import clock @functools.cache  @clock  def fibonacci(n): if n < 2: return n return fibonacci(n - 2) + fibonacci(n - 1) if __name__ == '__main__': print(fibonacci(6))  Эта строка работает в версии Python 3.9 и более поздних. Альтернативы для более ранних версий Python описаны в разделе «Использование lru_ cache».  Это пример композиции декораторов: @cache() применяется к функции, возвращенной декоратором @clock. Композиция декораторов Чтобы понять, в чем смысл композиции декораторов, вспомни- те, что @ – синтаксический сахар для применения декорирую- щей функции к функции, которая находится под ней. Если де- кораторов несколько, то они ведут себя как вложенные вызовы функций. Запись @alpha @beta def my_fn(): семантически эквивалентна следующей: my_fn = alpha(beta(my_fn)) Иными словами, сначала применяется декоратор beta, а возвра- щенная им функция передается декоратору alpha. Благодаря использованию декоратора cache функция fibonacci вызывается все- го один раз для каждого значения n: 316  Декораторы и замыкания\n--- Страница 316 ---\n$ python3 fibo_demo_lru.py [0.00000119s] fibonacci(0) -> 0 [0.00000119s] fibonacci(1) -> 1 [0.00010800s] fibonacci(2) -> 1 [0.00000787s] fibonacci(3) -> 2 [0.00016093s] fibonacci(4) -> 3 [0.00001216s] fibonacci(5) -> 5 [0.00025296s] fibonacci(6) -> 8 В другом тесте для вычисления fibonacci(30) программа из примера 9.18 выпол- нила 31 вызов за 0,00017 с, тогда как программа без кеширования из приме- ра 9.17 обращалась к функции fibonacci(1) 832 040 раз, а всего выполнида 2 692 537 вызовов и затратила на это 12,09 с на ноутбуке с процессором Intel Core i7. Все аргументы, принимаемые декорированной функцией, должны быть хе- шируемыми, потому что cache пользуется словарем dict для хранения резуль- татов, а его ключи образованы из позиционных и именованных аргументов, переданных при вызовах. Но @cache умеет не только исправлять плохо написанные рекурсивные алго- ритмы, во всем блеске он проявляется, когда нужно получать информацию от удаленных API. functools.cache может занять всю имеющуюся память, если в кеше очень много элементов. Я считаю, что ее стоит исполь- зовать только в командных скриптах, работающих недолго. Для долгоживущих процессов я рекомендую декоратор functools. lru_cache с подходящим параметром maxsize, о котором речь пой- дет в следующем разделе. Использование lru_cache Декоратор functools.cache на самом деле является простой оберткой вокруг по- явившейся раньше функции functools.lru_cache , более гибкой и совместимой с Python 3.8 и более ранними версиями. Основное преимущество @lru_cache в том, что объем потребляемой памяти можно ограничить с помощью параметра maxsize, для которого по умолчанию подразумевается довольно консервативное значение 128, т. е. в любой момент времени в кеше может быть не более 128 элементов. Акроним LRU расшифровывается как «Least Recently Used» (последний ис- пользованный); это означает, что элементы, к которым давно не было обраще- ний, вытесняются, чтобы освободить место для новых. Начиная с Python 3.8 lru_cache можно применять двумя способами. Вот как выглядит тот, что проще: @lru_cache def costly_function(a, b): Другой способ существует еще со времен версии Python 3.2 и выглядит как вызов функции со скобками (): @lru_cache() def costly_function(a, b): Декораторы в стандартной библиотеке  317\n--- Страница 317 ---\nВ обоих случаях используются параметры по умолчанию, а именно: maxsize=128 Задает максимальное число элементов в кеше. После заполнения кеша эле- мент, который дольше других не использовался, вытесняется, и его место за- нимает новый элемент. Для достижения оптимальной производительности maxsize должен быть степенью 2. Если maxsize=None , то логика LRU отключается, поэтому кеш работает быстрее, но элементы никогда не вытесняются, что мо- жет привести к перерасходу памяти. Это именно то, что делает @functools.cache . typed=False Определяет, следует ли хранить элементы разного типа раздельно. Напри- мер, в конфигурации по умолчанию элементы типа float и integer, признан- ные равными, хранятся лишь один раз, т. е. вызовы f(1) и f(1.0) приведут к помещению в кеш только одного элемента. Если typed=True , то такие вы- зовы приведут к созданию двух разных элементов кеша. Ниже приведен пример вызова @lru_cache со значениями параметров, отли- чающимися от умалчиваемых: @lru_cache(maxsize=2**20, typed=True) def costly_function(a, b): А теперь изучим еще один мощный декоратор, functools.singledispatch . Обобщенные функции с одиночной диспетчеризацией Пусть требуется написать инструмент для отладки веб-приложений. Мы хо- тим, чтобы он умел генерировать HTML-представления объектов Python раз- ного типа. Можно было бы начать с такой функции: import html def htmlize(obj): content = html.escape(repr(obj)) return f'<pre>{content}</pre>' Она будет работать для любого типа Python, но нам хотелось бы, чтобы для некоторых типов генерировались специальные представления. Вот несколько примеров. str Заменять внутренние символы новой строки строкой '<br>\\n' и использо- вать теги <p> вместо <pre>. int Показывать число в десятичном и шестнадцатеричном виде (bool – специ- альный случай). list Выводить HTML-список, в котором каждый элемент отформатирован в со- ответствии со своим типом.318  Декораторы и замыкания\n--- Страница 318 ---\nfloat и Decimal Выводить значение, как обычно, а также в виде дроби (почему бы и нет?). Желательное поведение показано в примере 9.19. Пример 9.19. Функция htmlize() генерирует HTML-представление объектов разных типов >>> htmlize({1, 2, 3})  '<pre>{1, 2, 3}</pre>' >>> htmlize(abs) '<pre>&lt;built-in function abs&gt;</pre>' >>> htmlize('Heimlich & Co.\\n- a game')  '<p>Heimlich &amp; Co.<br/>\\n- a game</p>' >>> htmlize(42)  '<pre>42 (0x2a)</pre>' >>> print(htmlize(['alpha', 66, {3, 2, 1}]))  <ul> <li><p>alpha</p></li> <li><pre>66 (0x42)</pre></li> <li><pre>{1, 2, 3}</pre></li> </ul> >>> htmlize(True)  '<pre>True</pre>' >>> htmlize(fractions.Fraction(2, 3))  '<pre>2/3</pre>' >>> htmlize(2/3)  '<pre>0.6666666666666666 (2/3)</pre>' >>> htmlize(decimal.Decimal('0.02380952')) '<pre>0.02380952 (1/42)</pre>  Оригинальная функция зарегистрирована для object, поэтому обрабатыва- ет все типы аргументов, для которых не нашлось другой реализации.  Объекты типа str также HTML-экранируются, но помещаются между тега- ми <p> и </p> и перед каждым '.\\n' вставляется <br/>.  Число типа int показывается в десятичном и шестнадцатеричном виде между тегами <pre> и </pre>.  Каждый элемент списка форматируется в соответствии со своим типом, а вся последовательность оформляется как HTML-список.  Хотя bool – подтип int, он обрабатывается специальным образом.  Показывать Fraction как обыкновенную дробь.  Показывать float и Decimal в виде приближенной обыкновенной дроби. Функция singledispatch Поскольку в Python нет механизма перегрузки методов, как в Java, мы не мо- жем создать варианты htmlize с разными сигнатурами для каждого типа дан- ных, который желательно обрабатывать специальным образом. Возможное ре- шение состоит в том, чтобы преобразовать htmlize в функцию диспетчеризации, содержащую предложение if с несколькими ветвями elif, в каждой из которых вызывается некая специализированная функция: htmlize_str , htmlize_int и т. д. Но такое решение не поддается расширению пользователями модуля и слиш- ком неуклюже: со временем диспетчер htmlize чрезмерно разрастется, а связь между ним и специализированными функциями станет недопустимо тесной. Декораторы в стандартной библиотеке  319\n--- Страница 319 ---\nДекоратор functools.singledispatch позволяет каждому модулю вносить свой вклад в общее решение, так что пользователь легко может добавить специали- зированную функцию, даже не имея возможности изменять класс. Обычная функция, декорированная @singledispatch , становится точкой входа для обоб- щенной функции: группы функций, выполняющих одну и ту же логическую операцию по-разному в зависимости от типа первого аргумента. Именно это и называется одиночной диспетчеризацией. Если бы для выбора конкретных функций использовалось больше аргументов, то мы имели бы множественную диспетчеризацию. В примере 9.20 показано, как это делается. Декоратор functools.singledispatch существует, начиная с версии Python 3.4, но поддерживает аннотации типов, только начиная с версии Python 3.7. Последние две функции в примере 9.20 ил- люстрируют синтаксис, который работает во всех версиях, начи- ная с Python 3.4. Пример 9.20. Декоратор singledispatch создает функцию @htmlize.register для объеди- нения нескольких функций в одну обобщенную from functools import singledispatch from collections import abc import fractions import decimal import html import numbers @singledispatch  def htmlize(obj: object) -> str: content = html.escape(repr(obj)) return f'<pre>{content}</pre>' @htmlize.register  def _(text: str) -> str:  content = html.escape(text).replace('\\n', '<br/>\\n') return f'<p>{content}</p>' @htmlize.register  def _(seq: abc.Sequence) -> str: inner = '</li>\\n<li>'.join(htmlize(item) for item in seq) return '<ul>\\n<li>' + inner + '</li>\\n</ul>' @htmlize.register  def _(n: numbers.Integral) -> str: return f'<pre>{n} (0x{n:x})</pre>' @htmlize.register  def _(n: bool) -> str: return f'<pre>{n}</pre>' @htmlize.register(fractions.Fraction)  def _(x) -> str: frac = fractions.Fraction(x) return f'<pre>{frac.numerator}/{frac.denominator}</pre>' @htmlize.register(decimal.Decimal)  320  Декораторы и замыкания\n--- Страница 320 ---\n@htmlize.register(float) def _(x) -> str: frac = fractions.Fraction(x).limit_denominator() return f'<pre>{x} ({frac.numerator}/{frac.denominator})</pre>'  @singledispatch помечает базовую функцию, которая обрабатывает тип object.  Каждая специализированная функция снабжается декоратором @«base». register.  Тип первого аргумента, переданного во время выполнения, определяет, когда будет использоваться это конкретное определение функции. Имена специализированных функций несущественны, и это подчеркнуто выбо- ром _ в качестве имени1.  Для каждого типа, нуждающегося в специальной обработке, регистрирует - ся новая функция с подходящей аннотацией типа в первом параметре.  Абстрактные базовые классы numbers полезны в сочетании с singledispatch2.  bool является подтипом numbers.Integral , но singledispatch ищет реализацию с самым специфичным подходящим типом независимо от порядка появ- ления в программе.  Если вы не хотите или не можете добавить аннотации типов в декориро- ванную функцию, то можете передать тип декоратору @«base».register . Этот синтаксис работает начиная с версии Python 3.4.  Декоратор @«base».register возвращает недекорированную функцию, поэто- му можно компоновать их, чтобы зарегистрировать два или более типов для одной и той же реализации3. Если есть возможность, регистрируйте специализированные функции для обработки ABC (абстрактных классов), например numbers.Integral или abc. MutableSequence , а не конкретных реализаций, например int или list. Это позво- лит программе поддержать более широкий спектр совместимых типов. Напри- мер, расширение Python может предоставлять альтернативы типу int с фикси- рованной длиной в битах в качестве подклассов numbers.Integral4. Использование ABC или typing.Protocol в сочетании с @singledispatch позволит программе поддержать существующие или будущие классы, являющиеся настоящими или виртуальными подкласса- ми этих ABC или реализующие указанный протокол. Применение ABC и концепция виртуального подкласса – темы главы 13. 1 К сожалению, Mypy 0.770 ругается, когда видит несколько функций с одинаковым именем. 2 Несмотря на предупреждение в разделе «Падение числовой башни» главы 8, число- вые ABC не объявлены нерекомендуемыми, и их можно найти в коде Python 3. 3 Быть может, когда-нибудь мы сможем выразить это с помощью одного непараметри- зованного декоратора @htmlize.register и аннотации типа, в которой используется Union, но когда я попытался это сделать, Python возбудил исключение с сообщением о том, что Union – не класс. Так что хотя описанный в PEP 484 синтаксис поддержива- ется декоратором @singledispatch , с семантикой еще не все в порядке. 4 Например, NumPy реализует несколько машинно-ориентированных типов целых и с плавающей точкой (https://numpy.org/doc/stable/user/basics.types.html). Декораторы в стандартной библиотеке  321\n--- Страница 321 ---\nЗамечательное свойство механизма singledispatch состоит в том, что специа- лизированные функции можно зарегистрировать в любом месте системы, в любом модуле. Если впоследствии вы добавите модуль, содержащий новый пользовательский тип, то сможете без труда написать новую специализиро- ванную функцию для обработки этого типа. А также реализовать функции об- работки для классов, которые вы не писали и не можете изменить. Декоратор singledispatch – продуманное дополнение к стандартной библиоте- ке, его возможности шире, чем описано выше. Документ PEP 443 «Single-dispatch generic functions» (https://www.python.org/dev/peps/pep-0443/) – хорошее справочное руководство, но в нем не упоминаются аннотации типов, добавленные позже. Документация по модулю functools доработана и более актуальна, в частности со- держит несколько примеров в разделе, посвященном singledispatch . Декоратор @singledispatch задуман не для того, чтобы перенести в Python перегрузку методов в духе Java. Один класс с несколь- кими перегруженными вариантами метода лучше одной функ - ции с длинной цепочкой предложений if/elif/elif/elif . Но оба решения грешат тем, что поручают слишком много обязанно- стей одной единице программы – классу или функции. Преиму - щество @singledispath – в поддержке модульного расширения: каждый модуль может зарегистрировать специализированную функцию для того типа, который поддерживает. На практике вы вряд ли стали бы помещать все реализации обобщенных функ - ций в один модуль, как в примере 9.20. Мы видели несколько декораторов, принимающих аргументы, например @ lru_cache() и htmlize.register(float) в примере 9.20. В следующем разделе описано, как создавать декораторы с параметрами. параметризОванные декОрат Оры Разбирая декоратор, встретившийся в исходном коде, Python берет декориру - емую функцию и передает ее в качестве первого аргумента функции-декора- тору. А как сделать, чтобы декоратор принимал и другие аргументы? Ответ та- ков: написать фабрику декораторов, которая принимает эти аргументы и воз- вращает декоратор, который затем применяется к декорируемой функции. Непонятно? Естественно. Начнем с примера, основанного на простейшем из рассмотренных до сих пор декораторов: register (см. пример 9.21). Пример 9.21. Сокращенный модуль registration.py из примера 9.2, повторен для удобства registry = [] def register(func): print(f'running register({func})') registry.append(func) return func @register def f1(): print('running f1()') print('running main()') 322  Декораторы и замыкания\n--- Страница 322 ---\nprint('registry ->', registry) f1() Параметризованный регистрационный декоратор Чтобы функцию регистрации, вызываемую декоратором register, можно было активировать и деактивировать, мы снабдим ее необязательным параметром active: если он равен False, то декорируемая функция не регистрируется. В при- мере 9.22 показано, как это делается. Концептуально новая функция register – не декоратор, а фабрика декораторов. Будучи вызвана, она возвращает насто- ящий декоратор, который применяется к декорируемой функции. Пример 9.22. Чтобы новый декоратор register мог принимать параметры, его следует вызывать как функцию registry = set()  def register(active=True): def decorate(func):  print('running register'  f'(active={active})->decorate({func})') if active:  registry.add(func) else: registry.discard(func)  return func  return decorate  @register(active=False)  def f1(): print('running f1()') @register()  def f2(): print('running f2()') def f3(): print('running f3()')  Теперь registry имеет тип set, чтобы ускорить добавление и удаление функций.  Функция register принимает необязательный именованный аргумент.  Собственно декоратором является внутренняя функция decorate, она при- нимает в качестве аргумента функцию.  Регистрируем func, только если аргумент active (определенный в замыка- нии) равен True.  Если не active и функция func присутствует в registry, удаляем ее.  Поскольку decorate – декоратор, он должен возвращать функцию.  Функция register – наша фабрика декораторов, поэтому она возвращает decorate.  Фабрику @register следует вызывать как функцию, передавая ей нужные па- раметры.  Даже если параметров нет, register все равно нужно вызывать как функ - цию – @register(), – чтобы она вернула настоящий декоратор decorate. Параметризованные декораторы  323\n--- Страница 323 ---\nИдея в том, что функция register() возвращает декоратор decorate, который затем применяется к декорируемой функции. Код из примера 9.22 находится в модуле registration_param.py. Если его им- портировать, получится вот что: >>> import registration_param running register(active=False)->decorate(<function f1 at 0x10063c1e0>) running register(active=True)->decorate(<function f2 at 0x10063c268>) >>> registration_param.registry [<function f2 at 0x10063c268>] Заметим, что в registry присутствует только функция f2, а функция f1 туда не попала, т. к. фабрике декораторов register был передан аргумент active=False , поэтому метод decorate, примененный к f1, не добавил ее в registry. Если бы мы использовали register как обычную функцию без символа @, то для декорирования функции f, т. е. для добавления ее в registry, нужно было бы написать register()(f) , а чтобы не добавлять f в реестр (или удалить отту - да) – register(active=False)(f) . В примере 9.23 показано, как добавлять функции в реестр registry и удалять из него. Пример 9.23. Использование модуля registration_param из примера 9.22 running register(active=False)->decorate(<function f1 at 0x10073c1e0>) running register(active=True)->decorate(<function f2 at 0x10073c268>) >>> registry  {<function f2 at 0x10073c268>} >>> register()(f3)  running register(active=True)->decorate(<function f3 at 0x10073c158>) <function f3 at 0x10073c158> >>> registry  {<function f3 at 0x10073c158>, <function f2 at 0x10073c268>} >>> register(active=False)(f2)  running register(active=False)->decorate(<function f2 at 0x10073c268>) <function f2 at 0x10073c268> >>> registry  {<function f3 at 0x10073c158>}  После импортирования модуля f2 оказывается в registry.  Выражение register() возвращает декоратор decorate, который затем приме- няется к f3.  В предыдущей строке функция f3 была добавлена в registry.  Этот вызов удаляет f2 из registry.  Убедиться, что f3 осталась в registry. Механизм работы параметризованных декораторов довольно сложен; рас- смотренный выше пример проще, чем в большинстве случаев. Параметри- зованные декораторы обычно заменяют декорируемую функцию, а в их кон- структорах необходим еще один уровень вложенности. В экскурсию по такой пирамиде функций мы отправимся в следующем разделе. Параметризованный декоратор clock В этом разделе мы вернемся к декоратору clock и добавим возможность пере- давать ему строку, управляющую форматом вывода. См. пример 9.24.324  Декораторы и замыкания\n--- Страница 324 ---\nДля простоты код в примере 9.24 основан на первоначальной реа лизации clock в примере 9.14, а не на улучшенной реали- зации из примера 9.16, в которой использовался декоратор @ functools.wraps , добавляющий еще один слой. Пример 9.24. Модуль clockdeco_param.py : параметризованный декоратор clock import time DEFAULT_FMT = '[{elapsed:0.8f}s] {name}({args}) -> {result}' def clock(fmt=DEFAULT_FMT):  def decorate(func):  def clocked(*_args):  t0 = time.perf_counter() _result = func(*_args)  elapsed = time.perf_counter() - t0 name = func.__name__ args = ', '.join(repr(arg) for arg in _args)  result = repr(_result)  print(fmt.format(**locals()))  return _result  return clocked  return decorate  if __name__ == '__main__': @clock() ⓫ def snooze(seconds): time.sleep(seconds) for i in range(3): snooze(.123)  Теперь clock – наша фабрика параметризованных декораторов.  decorate – это собственно декоратор.  clocked обертывает декорированную функцию.  _result – результат, возвращенный декорированной функцией.  В _args хранятся фактические аргументы clocked, тогда как args – отображае- мая строка.  result – строковое представление _result, предназначенное для отображения.  Использование **locals() позволяет ссылаться в fmt на любую локальную переменную clocked1. 1 Технический рецензент Мирослав Седивы заметил: «Это также означает, что лин- теры будут сообщать о неиспользуемых переменных, потому что они, как правило, игнорируют locals()». Да, это еще один пример того, как инструменты статическо- го анализа отваживают от использования тех динамических средств, из-за которых Python так привлекателен для меня и еще множества программистов. Чтобы удов- летворить линтер, я мог бы записать каждую локальную переменную дважды при вызове: fmt.format(elapsed=elapsed, name=name, args=args, result=result) . Но не буду. Если вы пользуетесь инструментами статического анализа, то важно знать, когда их следует игнорировать. Параметризованные декораторы  325\n--- Страница 325 ---\n clocked заменяет декорированную функцию, поэтому должна возвращать то, что вернула бы эта функция в отсутствие декоратора.  decorate возвращает clocked.  clock возвращает decorate. ⓫ В этом тесте clock() вызывается без аргументов, поэтому декоратор будет использовать форматную строку по умолчанию. При выполнении программы из примера 9.24 печатается следующее: $ python3 clockdeco_param.py [0.12412500s] snooze(0.123) -> None [0.12411904s] snooze(0.123) -> None [0.12410498s] snooze(0.123) -> None Для демонстрации новой функциональности в примерах 9.25 и 9.26 показа- ны еще два модуля, в которых используется clockdeco_param , а также результаты их выполнения. Пример 9.25. clockdeco_param_demo1.py import time from clockdeco_param import clock @clock('{name}: {elapsed}s') def snooze(seconds): time.sleep(seconds) for i in range(3): snooze(.123) Результат выполнения примера 9.25: $ python3 clockdeco_param_demo1.py snooze: 0.12414693832397461s snooze: 0.1241159439086914s snooze: 0.12412118911743164s Пример 9.26. clockdeco_param_demo2.py import time from clockdeco_param import clock @clock('{name}({args}) dt={elapsed:0.3f}s') def snooze(seconds): time.sleep(seconds) for i in range(3): snooze(.123) Результат выполнения примера 9.26: $ python3 clockdeco_param_demo2.py snooze(0.123) dt=0.124s snooze(0.123) dt=0.124s snooze(0.123) dt=0.124s326  Декораторы и замыкания\n--- Страница 326 ---\nЛеннарт Регебро – один из рецензентов первого издания этой книги – считает, что декораторы лучше писать как классы, реа- лизующие метод __call__, а не как функции (как в примерах из этой главы). Согласен, что для нетривиальных декораторов такой подход разумнее. Но функции проще, когда требуется объяснить основную идею этого механизма. См. раздел «Дополнительная литература», а в особенности блог Грэхема Дамплтона и модуль wrapt, если хотите узнать, как пишутся реальные декораторы. В следующем разделе показан пример декоратора, написанного в стиле, ре- комендуемом Регебро и Дамплтоном. Декоратор clock на основе класса Напоследок в примере 9.27 приведена реализация параметризованного деко- ратора clock в виде класса с методом __call__. Сравните примеры 9.24 и 9.27. Какой вам больше нравится? Пример 9.27. Модуль clockdeco_cls.py: параметризованный декоратор clock, реализо- ванный в виде класса import time DEFAULT_FMT = '[{elapsed:0.8f}s] {name}({args}) -> {result}' class clock:  def __init__(self, fmt=DEFAULT_FMT):  self.fmt = fmt def __call__(self, func):  def clocked(*_args): t0 = time.perf_counter() _result = func(*_args)  elapsed = time.perf_counter() - t0 name = func.__name__ args = ', '.join(repr(arg) for arg in _args) result = repr(_result) print(self.fmt.format(**locals())) return _result return clocked  Теперь фабрикой параметризованных декораторов является не внешняя функция clock, а класс clock. Я решил писать его имя со строчной буквы c, чтобы было понятно, что эту реализацию можно подставить вместо при- веденной в примере 9.24.  Аргумент, переданный clock(my_format) , присваивается параметру fmt. Кон- структор класса возвращает экземпляр clock, а my_format сохраняется в self.fmt.  Наличие метода __call__ делает clock вызываемым объектом. При вызове этот объект заменяет декорированную функцию на clocked.  clocked обертывает декорированную функцию. На этом мы завершаем изучение декораторов функций. С декораторами классов мы познакомимся в главе 24. Параметризованные декораторы  327\n--- Страница 327 ---\nрезюме В этой главе мы рассматривали трудный материал, но я старался сделать путе- шествие по возможности комфортабельным, хотя дорога была ухабистой. Ведь мы, по существу, вступили на территорию метапрограммирования. Мы начали с простого декоратора @register без внутренней функции и закон- чили параметризованным декоратором @clock() с двумя уровнями вложенных функций. Регистрационные декораторы, хотя и простые по существу, находят реальные применения в развитых каркасах на Python. Мы воспользуемся идеей регистра- ции в одной из реализаций паттерна проектирования Стратегия в главе 10. Для понимания механизма работы декораторов понадобилось разобраться в различиях между этапом импорта и этапом выполнения, в областях действия переменных, в замыканиях и в новом объявлении nonlocal. Свободное владение замыканиями и объявлением nonlocal важно не только при написании декора- торов, но и при разработке событийно-ориентированных программ с графи- ческим интерфейсом, для асинхронного ввода-вывода с обратными вызовами, а также для применения функционального стиля программирования, когда это имеет смысл. Параметризованные декораторы почти всегда содержат по меньшей мере две вложенные функции, а иногда и больше, если мы хотим использовать @functools. wraps для создания декоратора, который лучше поддерживает некоторые про- двинутые возможности. Одну такую возможность – композицию декораторов – мы рассмотрели в примере 9.18. Для более сложных декораторов реализация в виде класса может оказаться проще для чтения и сопровождения. В качестве примеров параметризованных декораторов в стандартной биб- лиотеке мы рассмотрели два впечатляющих декоратора из модуля functools: @cache и @singledispatch . дОпО лнительная литература В рецепте 26 из книги Brett Slatkin «Effective Python» https://effectivepython.com/, 2-е издание (Addison-Wesley), рассматриваются передовые практики напи- сания декораторов функций и всегда рекомендуется использовать functools. wraps. Мы видели это в примере 9.161. Грэхем Дамплтон опубликовал в своем блоге (https://github.com/ GrahamDumpleton/wrapt/blob/develop/blog/README.md) серию статей о способах реализации корректно работающих декораторов, и первая из них называется «How You Implemented Your Python Decorator is Wrong» (Ваш способ реализа- ции декоратора в Python неправильный) (https://github.com/GrahamDumpleton/ wrapt/blob/develop/blog/01-how-you-implemented-your-python-decorator-is-wrong.md). Его обширный опыт в этой области аккуратно инкапсулирован в модуль wrapt (http://wrapt.readthedocs.org/en/latest/), написанный с целью упростить реализа- цию декораторов и динамических функций-оберток, которые поддерживают 1 Я хотел сделать код как можно более простым, поэтому не во всех примерах следовал прекрасному совету Слаткина.328  Декораторы и замыкания\n--- Страница 328 ---\nинтроспекцию и корректно ведут себя, если еще раз подвергаются декориро- ванию, а также в случае применения к методам и использования в качестве дескрипторов. Дескрипторы – тема главы 23. В главе 9 «Метапрограммирование» книги David Beazley, Brian K. Jones «Python Cookbook», 3-е издание (O’Reilly), есть несколько рецептов – от элемен- тарных декораторов до очень сложных, в том числе такого, который можно вы- зывать либо как обычный декоратор, либо как фабрику декораторов, напри- мер @clock или @clock(). Это рецепт 9.6 «Определение декоратора, принимающе- го необязательный аргумент». Мишель Симионато написал пакет, имеющий целью «облегчить среднему программисту использование декораторов и популяризировать декораторы путем демонстрации различных нетривиальных примеров». На сайте PyPI па- кет доступен под названием decorator (https://pypi.python.org/pypi/decorator). Вики-страница Python Decorator Library (https://wiki.python.org/moin/ PythonDecoratorLibrary), созданная, когда декораторы только появились в Python, содержит десятки примеров. Поскольку странице уже много лет, некоторые приемы устарели, но она по-прежнему остается источником новых идей. В коротенькой статье «Closures in Python» (http://effbot.org/zone/closure.htm) в блоге Фредрика Лундха объясняется терминология замыканий. В документе PEP 3104 «Access to Names in Outer Scopes» (http://www.python.org/ dev/peps/pep-3104/) доступно описано объявление nonlocal, позволяющее пере- привязывать имена, не являющиеся ни локальными, ни глобальными. Здесь же имеется отличный обзор подходов к этой задаче в других динамических языках (Perl, Ruby, JavaScript и т. д.), а также обсуждение плюсов и минусов раз- личных проектных решений, возможных в Python. Документ PEP 227 «Statically Nested Scopes» (http://www.python.org/dev/peps/ pep-0227/) более теоретического характера содержит введение в механизм лек- сических областей видимости, который появился как факультативное сред- ство в Python 2.1 и стал стандартным в Python 2.2. Здесь же дается обоснование и варианты реализации замыканий в Python. В документе PEP 443 (http://www.python.org/dev/peps/pep-0443/) приводится обоснование и детальное описание создания обобщенных функций с помощью одиночной диспетчеризации. В старой (март 2005 года) статье в блоге Гвидо ван Россума «Five-Minute Multimethods in Python» (Мультиметоды в Python за пять минут) (http://www.artima.com/weblogs/viewpost.jsp?thread=101605) подробно рассматривается реализация обобщенных функций (или мультиметодов) с по- мощью декораторов. Код Гвидо поддерживает множественную диспетчериза- цию (т. е. диспетчеризацию на основе нескольких позиционных аргументов). Этот код интересен прежде всего с педагогической точки зрения. Современная готовая к работе реализация обобщенных функций с множественной диспет - черизацией имеется в библиотеке Reg (http://reg.readthedocs.org/en/latest/) Мар- тина Фаассена, автора моделеориентированного и поддерживающего REST веб-каркаса Morepath (http://morepath.readthedocs.org/en/latest/). Дополнительная литература  329\n--- Страница 329 ---\nПоговорим Сравнение динамической и лексической областей действия Проектировщик любого языка с полноправными функциями сталкивается со следующей проблемой: будучи полноправными объектами, функции опре- делены в некоторой области видимости, но могут вызываться из других об- ластей видимости. Вопрос: как вычислять свободные переменные? Самое простое, что сразу приходит в голову: «динамическая область видимости». Это означает, что при вычислении свободных переменных просматривается окружение, в котором функция вызывается. Если бы в Python были динамические области видимости, но не было замыка- ний, то функцию avg – аналогичную той, что приведена в примере 9.8, – мож - но было бы написать так: >>> ### это не настоящий сеанс оболочки Python! ### >>> avg = make_averager() >>> series = [] >>> avg(10) 10.0 >>> avg(11)  10.5 >>> avg(12) 11.0 >>> series = [1]  >>> avg(5) 3.0  Перед тем как использовать avg, мы должны сами определить список series = [] , поскольку averager (внутри make_averager ) ссылается на список по этому имени.  За кулисами series используется для хранения усредняемых значений.  При выполнении присваивания series = [1] предыдущий список затирает - ся. Это может произойти случайно, если одновременно вычисляются два независимых средних. Функции должны быть черными ящиками, их реализация должна быть скры- та от пользователя. Но если в функции имеются динамические переменные, то при использовании динамических областей видимости программист обя- зан знать внутреннее устройство функции, чтобы правильно настроить ее окружение. После многих лет борьбы с языком подготовки документов LaTeX я наткнулся на великолепную книгу George Grätzer «Practical LaTeX» (Springer), из которой узнал, что для переменных LaTeX используется динамическая об- ласть видимости. Вот почему они вызывали у меня такие трудности! В Emacs Lisp также используется динамическая область видимости, по крайней мере по умолчанию. Краткое пояснение см. в разделе «Динамическое связыва- ние» (https://www.gnu.org/software/emacs/manual/html_node/elisp/Dynamic-Binding.html) руководства по Emacs Lisp. Динамическую область видимости проще реализовать, и, наверное, именно поэтому Джон Маккарти выбрал такой путь при создании Lisp, первого язы- ка, в котором появились полноправные функции. Статья Пола Грэхема «The 330  Декораторы и замыкания\n--- Страница 330 ---\nRoots of Lisp» (http://www.paulgraham.com/rootsoflisp.html) содержит доступное объяснение оригинальной статьи Маккарти о языке Lisp «Recursive Functions of Symbolic Expressions and Their Computation by Machine, Part I» (Рекурсив- ные функции символических выражений и их вычисление машиной, часть I) (http://bit.ly/mccarthy_recursive). Работа Маккарти – такой же шедевр, как Девя- тая симфония Бетховена. Пол Грэхем перевел ее для всех нас – с языка мате- матики на английский, а затем на язык кода. Из комментария Пола Грэхема также видно, что динамические области види- мости далеко не тривиальны. Приведем цитату из его статьи: Красноречивым свидетельством того, какими опасностями чреваты динамические области видимости, является тот факт, что даже самый первый пример функции высшего порядка в Lisp не работал – именно из-за них. Быть может, в 1960 году Маккарти не вполне сознавал по- следствия использования динамических областей видимости. Как бы то ни было, они оставались в реализациях Lisp на удивление долго – пока Сассмен и Стил не разработали язык Scheme в 1975 году. Лекси- ческие области видимости не слишком усложняют определение eval, но могут затруднить написание компиляторов. Сегодня лексическая область видимости считается нормой: свободные пере- менные вычисляются в том окружении, в котором функция определена. Лек- сические области видимости усложняют реализацию языков с полноправ- ными функциями, потому что зависят от поддержки замыканий. С другой стороны, исходный код с лексическими областями видимости проще читать. В большинстве языков, придуманных после Algol, имеются лексические об- ласти видимости. Заметное исключение – JavaScript, в котором специаль- ная переменная this вызывает недоразумения, потому что может иметь как лексическую, так и динамическую область видимости в зависимости от того, как написан код (https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/ Operators/this). В течение многих лет лямбда-выражения в Python не поддерживали замы- кания, что снискало им дурную славу среди адептов функционального про- граммирования в блогосфере. Это было исправлено в версии Python 2.2 (де- кабрь 2001), но у блогосферы долгая память. С тех пор к конструкции lambda есть только одна претензия: синтаксические ограничения. Декораторы в Python и паттерн проектирования Декоратор Декораторы функций в Python согласуются с общим описанием паттерна Декоратор в книге Гамма и др. «Паттерны проектирования»: «Динамически добавляет объекту новые обязанности. Является гибкой альтернативой по- рождению подклассов с целью расширения функциональности». На уровне реализации декораторы в Python не имеют ничего общего с классическим паттерном Декоратор, но какую-то аналогию провести можно. В паттерне проектирования Decorator и Component – абстрактные классы. Эк- земпляр конкретного декоратора обертывает экземпляр конкретного ком- понента, чтобы расширить его поведение. Приведем цитату из «Паттернов проектирования»: Дополнительная литература  331\n--- Страница 331 ---\nДекоратор следует интерфейсу декорируемого объекта, поэтому его присутствие прозрачно для клиентов компонента. Декоратор пере- адресует запросы внутреннему компоненту, но может выполнять и до- полнительные действия (например, рисовать рамку) до или после пере- адресации. Поскольку декораторы прозрачны, они могут вкладываться друг в друга, добавляя тем самым любое число новых обязанностей. В Python декоратор играет роль конкретного подкласса Decorator, а внутренняя функция, которую он возвращает, является экземпляром декоратора. Возвра- щенная функция обертывает декорируемую функцию, которая может быть уподоблена компоненту в паттерне проектирования. Возвращенная функция прозрачна, потому что согласуется с интерфейсом компонента, ведь она при- нимает те же самые аргументы. Она переадресует вызов компоненту и может выполнять дополнительные действия до или после переадресации. Мы мо- жем переформулировать последнее предложение из приведенной цитаты следующим образом: «Поскольку декораторы прозрачны, они могут вклады- ваться друг в друга, добавляя тем самым любое число новых видов поведе- ния». Именно это свойство открывает возможность композиции декораторов. Я вовсе не предлагаю использовать декораторы для реализации паттерна Деко- ратор в программах на Python. Хотя в некоторых специфических ситуациях это возможно, в общем случае паттерн Декоратор лучше реализовать с помощью классов, представляющих сам Декоратор и обертываемые им компоненты.332  Декораторы и замыкания",
      "debug": {
        "start_page": 299,
        "end_page": 331
      }
    },
    {
      "name": "Глава 10. Реализация паттернов проектирования с помощью полноправных функций 333",
      "content": "--- Страница 332 --- (продолжение)\nГлава 10 Реализация паттернов проектирования с помощью полноправных функций Соответствием паттернам качество не измеряется. – Ральф Джонсон, один из авторов классической книги «Паттерны проектирования»1 В программной инженерии паттерном проектирования ( https://en.wikipedia.org/ wiki/Software_design_pattern) называется общий рецепт решения типичной задачи проектирования. Для чтения этой главы знакомство с паттернами проектиро- вания необязательно. Я буду объяснять паттерны, встречающиеся в примерах. Применение паттернов проектирования было популяризировано в зна- менательной книге Erich Gamma, Richard Helm, Ralph Johnson, John Vlissides «Design Patterns: Elements of Reusable Object-Oriented Software» (Addison- Wesley), авторы которой получили шутливое прозвище «Банда четырех». Книга представляет собой каталог 23 паттернов и описывает структурную организа- цию классов с примерами на C++, хотя предполагается, что они будут полезны и в других объектно-ориентированных языках. Хотя паттерны проектирования от языка не зависят, это не значит, что лю- бой паттерн применим к любому языку. Например, в главе 17 мы покажем, что эмулировать рецепт паттерна Итератор в Python не имеет смысла, потому что он встроен в сам язык и готов к использованию в форме генераторов, кото- рым классы вообще не нужны, а кода требуется меньше, чем в классическом рецепте. Авторы книги «Паттерны проектирования» признают во введении, что при- менимость паттернов зависит от реализации языка: Выбор языка программирования важен, поскольку он определяет точку зрения. В наших паттернах подразумевается использование возможно- стей Smalltalk и C++, и от этого выбора зависит, что реализовать легко, а что – трудно. Если бы мы имели в виду процедурные языки, то включили бы паттерны «Наследование», «Инкапсуляция» и «Полиморфизм». Неко- 1 Со слайда к докладу «Root Cause Analysis of Some Faults in Design Patterns», прочитан- ному Ральфом Джонсоном на IME/CCSL, университет Сан-Паулу, 15 ноября 2014.\nГлава 10 Реализация паттернов проектирования с помощью полноправных функций Соответствием паттернам качество не измеряется. – Ральф Джонсон, один из авторов классической книги «Паттерны проектирования»1 В программной инженерии паттерном проектирования ( https://en.wikipedia.org/ wiki/Software_design_pattern) называется общий рецепт решения типичной задачи проектирования. Для чтения этой главы знакомство с паттернами проектиро- вания необязательно. Я буду объяснять паттерны, встречающиеся в примерах. Применение паттернов проектирования было популяризировано в зна- менательной книге Erich Gamma, Richard Helm, Ralph Johnson, John Vlissides «Design Patterns: Elements of Reusable Object-Oriented Software» (Addison- Wesley), авторы которой получили шутливое прозвище «Банда четырех». Книга представляет собой каталог 23 паттернов и описывает структурную организа- цию классов с примерами на C++, хотя предполагается, что они будут полезны и в других объектно-ориентированных языках. Хотя паттерны проектирования от языка не зависят, это не значит, что лю- бой паттерн применим к любому языку. Например, в главе 17 мы покажем, что эмулировать рецепт паттерна Итератор в Python не имеет смысла, потому что он встроен в сам язык и готов к использованию в форме генераторов, кото- рым классы вообще не нужны, а кода требуется меньше, чем в классическом рецепте. Авторы книги «Паттерны проектирования» признают во введении, что при- менимость паттернов зависит от реализации языка: Выбор языка программирования важен, поскольку он определяет точку зрения. В наших паттернах подразумевается использование возможно- стей Smalltalk и C++, и от этого выбора зависит, что реализовать легко, а что – трудно. Если бы мы имели в виду процедурные языки, то включили бы паттерны «Наследование», «Инкапсуляция» и «Полиморфизм». Неко- 1 Со слайда к докладу «Root Cause Analysis of Some Faults in Design Patterns», прочитан- ному Ральфом Джонсоном на IME/CCSL, университет Сан-Паулу, 15 ноября 2014.\n--- Страница 333 ---\nторые из наших паттернов напрямую поддерживаются менее распростра- ненными языками. Так, в языке CLOS есть мультиметоды, которые делают ненужным паттерн «Посетитель»1. В презентации 1996 года «Design Patterns in Dynamic Languages» (http:// norvig.com/design-patterns/) Петер Норвиг утверждает, что 16 из 23 паттернов, описанных в оригинальной книге «Паттерны проектирования», в динами- ческих языках «либо не видны, либо более просты» (слайд 9). Он говорил о языках Lisp и Dylan, но аналогичные динамические средства существуют и в Python. В частности, в контексте языков с полноправными функциями Норвиг предлагает переосмыслить паттерны Стратегия, Команда, Шаблон- ный метод и Посетитель. Цель этой главы – показать, что в некоторых случаях функции могут про- делать ту же работу, что и классы, а код при этом получается проще и коро- че. Мы переработаем паттерн Стратегия с помощью объектов-функций, убрав много стереотипного кода, и обсудим аналогичный подход к упрощению пат- терна Команда. чтО нОвОг О в этОй главе Я перенес эту главу в конец части III, чтобы можно было применить регистраци- онный декоратор, описанный в разделе «Паттерн Стратегия, дополненный де- коратором», а также использовать в примерах аннотации типов. Большинство встречающихся в этой главе аннотаций несложны, но код с ними читать проще. практичеСкий пример : перераБО тка паттерна Стратегия Стратегия – прекрасный пример паттерна проектирования, который в Python можно упростить путем использования функций как полноправных объектов. В следующем разделе мы опишем и реализуем Стратегию, сохраняя верность «классической» структуре, описанной в «Паттернах проектирования». Если вы знакомы с классическим паттерном, то можете сразу перейти к разделу «Функ - ционально-ориентированная Стратегия», где код будет переработан, в резуль- тате чего его объем существенно уменьшится. Классическая Стратегия На UML-диаграмме классов (рис. 10.1) изображены взаимоотношения классов, участвующих в паттерне Стратегия. В книге «Паттерны проектирования» паттерн Стратегия описывается следу - ющим образом: Определить семейство алгоритмов, инкапсулировать каждый из них и сделать их взаимозаменяемыми. Стратегия позволяет заменять алго- ритм независимо от использующих его клиентов. 1 Эрих Гамма, Ричард Хелм, Ральф Джонсон, Джон Влиссидес. Приемы объектно-ориен- тированного проектирования. Паттерны проектирования. Питер, 2001.334  Реализация паттернов проектирования с помощью полноправных функций\n--- Страница 334 ---\nстратегияконтекст конкретные стратегии Рис. 10.1. UML-диаграмма классов для обработки скидок по заказам, реализованных в со- ответствии с паттерном Стратегия Наглядный пример применения паттерна Стратегия к коммерческой зада- че – вычисление скидок на заказы в соответствии с характеристиками заказ- чика или результатами анализа заказанных позиций. Рассмотрим интернет-магазин со следующими правилами формирования скидок: заказчику, имеющему не менее 1000 баллов лояльности, предоставляется глобальная скидка 5 % на весь заказ; на позиции, заказанные в количестве не менее 20 единиц в одном заказе, предоставляется скидка 10 %; на заказы, содержащие не менее 10 различных позиций, предоставляется глобальная скидка 7 %. Для простоты предположим, что к каждому заказу может быть применена только одна скидка. UML-диаграмма классов для паттерна Стратегия показана на рис. 10.1. Ее участниками являются: Контекст Предоставляет службу, делегируя часть вычислений взаимозаменяемым компонентам, реализующим различные алгоритмы. В примере интернет- магазина контекстом является класс Order, который конфигурируется для применения поощрительной скидки по одному из нескольких алгоритмов. Стратегия Интерфейс, общий для всех компонентов, реализующих различные алго- ритмы. В нашем примере эту роль играет абстрактный класс Promotion. Практический пример: переработка паттерна Стратегия  335\n--- Страница 335 ---\nКонкретная стратегия Один из конкретных подклассов Стратегии. В нашем случае реализованы три конкретные стратегии: FidelityPromo , BulkPromo и LargeOrderPromo . Код в примере 10.1 следует изображенной на рис. 10.1 схеме. Как описано в «Паттернах проектирования», конкретная стратегия выбирается клиентом класса контекста. В нашем примере система, перед тем как создать объект за- каза, должна каким-то образом выбрать стратегию предоставления скидки и передать ее конструктору класса Order. Вопрос о выборе стратегии не являет - ся предметом данного паттерна. Пример 10.1. Реализация класса Order с помощью взаимозаменяемых стратегий предостав- ления скидки from abc import ABC, abstractmethod from collections.abc import Sequence from decimal import Decimal from typing import NamedTuple, Optional class Customer(NamedTuple): name: str fidelity: int class LineItem(NamedTuple): product: str quantity: int price: Decimal def total(self) -> Decimal: return self.price * self.quantity class Order(NamedTuple): # контекст customer: Customer cart: Sequence[LineItem] promotion: Optional['Promotion'] = None def total(self) -> Decimal: totals = (item.total() for item in self.cart) return sum(totals, start=Decimal(0)) def due(self) -> Decimal: if self.promotion is None: discount = Decimal(0) else: discount = self.promotion.discount(self) return self.total() - discount def __repr__(self): return f'<Order total: {self.total():.2f} due: {self.due():.2f}>' class Promotion(ABC): # Стратегия: абстрактный базовый класс @abstractmethod def discount(self, order: Order) -> Decimal: \"\"\"Вернуть скидку в виде положительной суммы в долларах\"\"\"336  Реализация паттернов проектирования с помощью полноправных функций\n--- Страница 336 ---\nclass FidelityPromo(Promotion): # первая конкретная стратегия \"\"\"5%-ная скидка для заказчиков, имеющих не менее 1000 баллов лояльности\"\"\" def discount(self, order: Order) -> Decimal: rate = Decimal('0.05') if order.customer.fidelity >= 1000: return order.total() * rate return Decimal(0) class BulkItemPromo(Promotion): # вторая конкретная стратегия «»»10%-ная скидка для каждой позиции LineItem, в которой заказано не менее 20 единиц»»» def discount(self, order: Order) -> Decimal: discount = Decimal(0) for item in order.cart: if item.quantity >= 20: discount += item.total() * Decimal('0.1') return discount class LargeOrderPromo(Promotion): # третья конкретная стратегия \"\"\"7%-ная скидка для заказов, включающих не менее 10 различных позиций\"\"\" def discount(self, order: Order) -> Decimal: distinct_items = {item.product for item in order.cart} if len(distinct_items) >= 10: return order.total() * Decimal('0.07') return Decimal(0) Отметим, что в примере 10.1 я сделал Promotion абстрактным базовым клас - сом (ABC), чтобы можно было использовать декоратор @abstractmethod и тем са- мым прояснить структуру паттерна. В примере 10.2 показаны тесты, которые проверяют работу модуля, реали- зующего описанные выше правила. Пример 10.2. Пример использования класса Order с различными стратегиями скидок >>> joe = Customer('John Doe', 0)  >>> ann = Customer('Ann Smith', 1100) >>> cart = (LineItem('banana', 4, Decimal('.5')),  LineItem('apple', 10, Decimal('1.5')), LineItem('watermelon', 5, Decimal(5))) >>> Order(joe, cart, FidelityPromo())  <Order total: 42.00 due: 42.00> >>> Order(ann, cart, FidelityPromo())  <Order total: 42.00 due: 39.90> >>> banana_cart = (LineItem('banana', 30, Decimal('.5')),  LineItem('apple', 10, Decimal('1.5'))) >>> Order(joe, banana_cart, BulkItemPromo())  <Order total: 30.00 due: 28.50> >>> long_cart = tuple(LineItem(str(sku), 1, Decimal(1))  for sku in range(10)) >>> Order(joe, long_cart, LargeOrderPromo())  <Order total: 10.00 due: 9.30> >>> Order(joe, cart, LargeOrderPromo()) <Order total: 42.00 due: 42.00> Практический пример: переработка паттерна Стратегия  337\n--- Страница 337 ---\n Два заказчика: у joe 0 баллов лояльности, у ann – 1100.  Одна корзина покупок с тремя позициями.  Класс FidelityPromo не дает joe никаких скидок.  ann получает скидку 5 %, поскольку имеет не менее 1000 баллов лояльности.  В корзине banana_cart находится 30 бананов и 10 яблок.  Класс BulkItemPromo дает joe скидку $1.50 на бананы.  В заказе long_order имеется 10 различных позиций стоимостью $1.00 каждая.  joe получает скидку 7 % на весь заказ благодаря классу LargerOrderPromo . Пример 10.1 работает без нареканий, но ту же функциональность можно реализовать в Python гораздо короче, воспользовавшись функциями как объ- ектами. функциОнальнО -Ориентир Ованная Стратегия Каждая конкретная стратегия в примере 10.1 – это класс с одним методом discount. К тому же объекты стратегии не имеют состояния (атрибутов экзем- пляра). Мы могли бы сказать, что они сильно напоминают функции, и были бы правы. В примере 10.3 код из примера 10.1 переработан – конкретные стра- тегии заменены простыми функциями, а абстрактный класс Promo исключен вовсе. В класс Order пришлось внести совсем немного изменений1. Пример 10.3. Класс Order, в котором стратегии предоставления скидок реализованы в виде функций from collections.abc import Sequence from dataclasses import dataclass from decimal import Decimal from typing import Optional, Callable, NamedTuple class Customer(NamedTuple): name: str fidelity: int class LineItem(NamedTuple): product: str quantity: int price: Decimal def total(self): return self.price * self.quantity @dataclass(frozen=True) class Order: # контекст 1 Я был вынужден переделать класс Order, добавив декоратор @dataclass из-за ошибки в Mypy. Можете не обращать внимания на эту деталь, потому что класс работает и с NamedTuple , как в примере 10.1. Если Order является NamedTuple , то Mypy 0.910 «падает» при проверке аннотации типа для promotion . Я пытался добавить # type ignore в эту конкретную строку, но Mypy все равно падает. Ту же самую аннотацию типа Mypy об- рабатывает правильно, если Order снабжен декоратором @dataclass . Проблема #9397 остается нерешенной по состоянию на 19 июля 2021 года. Надеюсь, что она будет решена к моменту, когда вы будете это читать.338  Реализация паттернов проектирования с помощью полноправных функций\n--- Страница 338 ---\ncustomer: Customer cart: Sequence[LineItem] promotion: Optional[Callable[['Order'], Decimal]] = None  def total(self) -> Decimal: totals = (item.total() for item in self.cart) return sum(totals, start=Decimal(0)) def due(self) -> Decimal: if self.promotion is None: discount = Decimal(0) else: discount = self.promotion(self)  return self.total() - discount def __repr__(self): return f'<Order total: {self.total():.2f} due: {self.due():.2f}>'  def fidelity_promo(order: Order) -> Decimal:  \"\"\"5%-ная скидка для заказчиков, имеющих не менее 1000 баллов лояльности\"\"\" if order.customer.fidelity >= 1000: return order.total() * Decimal('0.05') return Decimal(0) def bulk_item_promo(order: Order) -> Decimal: \"\"\"10%-ная скидка для каждой позиции LineItem, в которой заказано не менее 20 единиц»»» discount = Decimal(0) for item in order.cart: if item.quantity >= 20: discount += item.total() * Decimal('0.1') return discount def large_order_promo(order: Order) -> Decimal: \"\"\"7%-ная скидка для заказов, включающих не менее 10 различных позиций\"\"\" distinct_items = {item.product for item in order.cart} if len(distinct_items) >= 10: return order.total() * Decimal('0.07') return Decimal(0)  Эта аннотация типов означает, что promotion может быть равно None или вызыва- емому объекту, который принимает аргумент типа Order и возвращает Decimal.  Для вычисления скидки просто вызываем функцию self.promotion() .  Абстрактного класса больше нет.  Каждая стратегия является функцией. Почему self.promotion(self)? В классе Order переменная promotion не является методом. Это атрибут класса, по стечению обстоятельств оказавшийся вызы- ваемым объектом. Чтобы его вызвать, мы должны предоставить экземпляр Order – в данном случае self. Поэтому self и встреча- ется в этом выражении дважды. Функционально-ориентированная стратегия  339\n--- Страница 339 ---\nВ разделе «Методы являются дескрипторами» главы 23 мы объ- ясним механизм автоматического связывания методов с экзем- плярами. Но к promotion он неприменим, потому что это не метод. Код в примере 10.3 короче, чем в примере 10.1. Пользоваться новым классом Order также несколько проще, как показано в тестах ниже. Пример 10.4. Пример использования класса Order, в котором стратегии скидки реали- зованы в виде функций >>> joe = Customer('John Doe', 0)  >>> ann = Customer('Ann Smith', 1100) >>> cart = [LineItem('banana', 4, Decimal('.5')), LineItem('apple', 10, Decimal('1.5')), LineItem('watermelon', 5, Decimal(5))] >>> Order(joe, cart, fidelity_promo)  <Order total: 42.00 due: 42.00> >>> Order(ann, cart, fidelity_promo) <Order total: 42.00 due: 39.90> >>> banana_cart = [LineItem('banana', 30, Decimal('.5')), LineItem('apple', 10, Decimal('1.5'))] >>> Order(joe, banana_cart, bulk_item_promo)  <Order total: 30.00 due: 28.50> >>> long_cart = [LineItem(str(item_code), 1, Decimal(1)) for item_code in range(10)] >>> Order(joe, long_cart, large_order_promo) <Order total: 10.00 due: 9.30> >>> Order(joe, cart, large_order_promo) <Order total: 42.00 due: 42.00>  Те же тестовые фикстуры, что в примере 10.1.  Для применения стратегии скидки к объекту Order нужно просто передать функцию скидки в качестве аргумента.  Здесь и в следующем тесте используются разные функции скидки. По поводу выносок в примере 10.4: нет необходимости создавать новый объект скидки для каждого заказа – функции и так готовы к применению. Интересно, что авторы «Паттернов проектирования» замечают: «в большин- стве случаев объекты-стратегии подходят как приспособленцы»1. В другой части книги паттерн Приспособленец определяется так: «Приспособленец – это раз- деляемый объект, который можно использовать одновременно в нескольких контекстах»2. Разделение рекомендуется для того, чтобы сэкономить на стоимо- сти создания экземпляров конкретных стратегий, которые многократно приме- няются в каждом новом контексте – в нашем примере к каждому объекту Order. Поэтому в целях преодоления недостатка паттерна Стратегия – высоких наклад- ных расходов во время выполнения – авторы рекомендуют применять еще один паттерн. И тем самым увеличиваются объем и сложность сопровождения кода. В более сложном случае, когда у конкретных стратегий имеется внутреннее состояние, может оказаться необходимым как-то комбинировать части пат- тернов Стратегия и Приспособленец. Но часто у конкретных стратегий нет 1 «Паттерны проектирования», стр. 309. 2 Там же, стр. 192.340  Реализация паттернов проектирования с помощью полноправных функций\n--- Страница 340 ---\nвнут реннего состояния, они имеют дело только с данными из контекста. И тог - да ничто не мешает использовать обычные функции вместо написания клас - сов с единственным методом, которые реализуют интерфейс, объявленный еще в одном классе. Функция обходится дешевле экземпляра пользователь- ского класса, и отпадает надобность в паттерне Приспособленец, потому что каждая функция-стратегия создается только один раз – когда Python компи- лирует модуль. Обычная функция как раз и является «разделяемым объектом, который можно использовать одновременно в нескольких контекстах». Теперь, когда мы знаем, как реализовать паттерн Стратегия, перед нами от- крываются и другие возможности. Допустим, мы хотим создать «метастрате- гию», которая выбирает наилучшую скидку для данного объекта Order. В сле- дующих разделах мы продолжим переработку и покажем различные подходы к реализации этого требования, используя функции и модули как объекты. Выбор наилучшей стратегии: простой подход Используя тех же заказчиков и корзины покупок, что в примере 10.4, мы до- бавим еще три теста. Пример 10.5. Функция best_promo применяет все стратегии и возвращает наибольшую скидку >>> Order(joe, long_cart, best_promo)  <Order total: 10.00 due: 9.30> >>> Order(joe, banana_cart, best_promo)  <Order total: 30.00 due: 28.50> >>> Order(ann, cart, best_promo)  <Order total: 42.00 due: 39.90>  Для покупателя joe функция best_promo выбрала стратегию larger_order_promo .  Здесь joe получил скидку от bulk_item_promo за заказ большого числа бананов.  Несмотря на очень простую корзину, best_promo дала лояльному покупателю ann скидку согласно стратегии fidelity_promo . Реализация best_promo очень проста и показана в примере 10.6. Пример 10.6. best_promo находит максимальную скидку, перебирая все функции promos = [fidelity_promo, bulk_item_promo, large_order_promo]  def best_promo(order: Order) -> Decimal:  \"\"\"Вычислить наибольшую скидку\"\"\" return max(promo(order) for promo in promos)   promos: список стратегий, реализованных в виде функций.  best_promo получает объект Order в качестве аргумента, как и другие функции *_promo.  С помощью генераторного выражения мы применяем к order каждую функ - цию из списка promos и возвращаем максимальную вычисленную скидку. Код в примере 10.6 работает бесхитростно: promos – это список функций. Сжившись с идеей о том, что функции – полноправные объекты, вы будете вос- принимать и структуры, содержащие функции, как нечто естественное. Функционально-ориентированная стратегия  341\n--- Страница 341 ---\nПример 10.6 работает, и читать код легко, но все же в нем есть некоторое дублирование, которое может приводить к тонкой ошибке: чтобы добавить новую стратегию скидки, нужно написать функцию и не забыть добавить ее в список promos, иначе новая стратегия будет работать, если явно передать ее в качестве аргумента Order, но best_promotion ее рассматривать не будет. Ниже описано два решения этой проблемы. Читайте дальше. Поиск стратегий в модуле Модули в Python также являются полноправными объектами, и в стандарт - ной библиотеке есть несколько функций для работы с ними. В документации встроенная функция globals описана следующим образом: globals() Возвращает словарь, представляющий текущую таблицу глобальных сим- волов. Это всегда словарь текущего модуля (внутри функции или метода это тот модуль, где данная функция или метод определены, а не модуль, из которого они вызваны). В примере 10.7 показан не вполне честный способ использования globals, по- зволяющий best_promo автоматически находить все доступные функции *_promo. Пример 10.7. Список promos строится путем просмотра глобального пространства имен модуля from decimal import Decimal from strategy import Order from strategy import ( fidelity_promo, bulk_item_promo, large_order_promo  ) promos = [promo for name, promo in globals().items()  if name.endswith('_promo') and  name != 'best_promo'  ] def best_promo(order: Order) -> Decimal:  \"\"\"Вычислить наибольшую скидку\"\"\" return max(promo(order) for promo i n promos)  Импортировать функции скидок, чтобы они были доступны в глобальном пространстве имен1.  Перебрать все имена в словаре, возвращенном функцией globals().  Оставить только имена с суффиксом _promo.  Отфильтровать саму функцию best_promo, чтобы не было бесконечной рекурсии.  Сама функция best_promo не изменилась. Другой способ собрать вместе все стратегии скидки – создать отдельный мо- дуль и поместить в него все функции-стратегии, кроме best_promo . 1 flake8 и VS Code ругаются, что эти имена импортированы, но не используются. По определению, инструменты статического анализа не способны понять динамиче- скую структуру Python. Если тупо следовать каждому их совету, то мы начнем писать угрюмый и многословный код а-ля Java с синтаксисом Python.342  Реализация паттернов проектирования с помощью полноправных функций\n--- Страница 342 ---\nПример 10.8 отличается только тем, что список функций-стратегий строит - ся путем просмотра специального модуля promotions . Отметим, что для работы этого кода необходимо импортировать модуль promotions , а также модуль inspect, в котором находятся высокоуровневые функции интроспекции. Пример 10.8. Список promos строится путем интроспекции нового модуля promotions from decimal import Decimal import inspect from strategy import Order import promotions promos = [func for _, func in inspect.getmembers(promotions, inspect.isfunction)] def best_promo(order: Order) -> Decimal: \"\"\"Вычислить наибольшую скидку\"\"\" return max(promo(order) for promo in promos) Функция inspect.getmembers возвращает атрибуты объекта – в данном случае модуля promotions – возможно, отфильтрованные предикатом (булевой функци- ей). Мы пользуемся предикатом inspect.isfunction , чтобы получить только име- ющиеся в модуле функции. Код в примере 10.8 работает независимо от имен функций, важно лишь, что- бы модуль promotions содержал только функции вычисления скидки для пере- данного заказа. Конечно, это некое неявное предположение: если кто-нибудь включит в модуль promotions функцию с другой сигнатурой, то при попытке при- менить ее к заказу функция best_promo завершится с ошибкой. Можно было бы отбирать функции более строго, например анализируя их аргументы. Но цель примера 10.8 – не предложить полное решение, а показать один из возможных путей использования интроспекции модуля. Есть и более явный подход к динамическому отбору функций вычисления скидки – воспользоваться декоратором. Этому посвящен следующий раздел. паттерн Стратегия , дОпО лненный декОрат ОрОм Напомним, что в примере 10.6 мы столкнулись с проблемой повторения имен функций в определениях и в списке promos, который используется функцией best_promo для вычисления максимально возможной скидки. Такое повторение плохо тем, что программист может добавить новую функцию-стратегию, за- быв включить ее в список promos, и тогда best_promo молча проигнорирует новую стратегию, а в системе появится тонкая ошибка. В примере 10.9 эта проблема решается с помощью регистрационного декоратора. Пример 10.9. Список promos заполняется декоратором promotion Promotion = Callable[[Order], Decimal] promos: list[Promotion] = []  def promotion(promo: Promotion) -> Promotion:  Паттерн Стратегия, дополненный декоратором  343\n--- Страница 343 ---\npromos.append(promo) return promo def best_promo(order: Order) -> Decimal: \"\"\"Вычислить наибольшую скидку\"\"\" return max(promo(order) for promo in promos)  @promotion  def fidelity(order: Order) -> Decimal: \"\"\"5%-ная скидка для заказчиков, имеющих не менее 1000 баллов лояльности\"\"\" if order.customer.fidelity >= 1000: return order.total() * Decimal('0.05') return Decimal(0) @promotion def bulk_item(order: Order) -> Decimal: \"\"\"10%-ная скидка для каждой позиции LineItem, в которой заказано не менее 20 единиц»»» discount = Decimal(0) for item in order.cart: if item.quantity >= 20: discount += item.total() * Decimal('0.1') return discount @promotion def large_order(order: Order) -> Decimal: \"\"\"7%-ная скидка для заказов, включающих не менее 10 различных позиций\"\"\" distinct_items = {item.product for item in order.cart} if len(distinct_items) >= 10: return order.total() * Decimal('0.07') return Decimal( 0)  Список promos глобален на уровне модуля и вначале пуст.  Регистрационный декоратор promotion возвращает функцию promo_func без изменения, но добавляет ее в список promos.  Функция best_promo не изменяется, поскольку зависит только от списка promos.  Все функции, декорированные @promotion , добавлены в promos. По сравнению с другими решениями, представленными выше, у этого есть несколько преимуществ. Функции, реализующие стратегии вычисления скидки, не обязаны иметь специальные имена – суффикс _promo не нужен. Декоратор @promotion ясно описывает назначение декорируемой функции и без труда позволяет временно отменить предоставление ссылки: до- статочно закомментировать декоратор. Стратегии скидки можно определить в других модулях, в любом месте системы; главное – чтобы к ним применялся декоратор @promotion. В следующем разделе мы обсудим паттерн Команда, который часто реали- зуют с помощью классов с единственным методом, хотя достаточно и обычной функции.344  Реализация паттернов проектирования с помощью полноправных функций\n--- Страница 344 ---\nпаттерн кОманда Команда – еще один паттерн проектирования, который можно упростить с по- мощью передачи функций в качестве аргументов. На рис. 10.2 показана диа- грамма классов для этого паттерна. клиент инициатор команда получателиконкретные команды Рис. 10.2. UML-диаграмма классов для управляемого меню текстового редактора, реализо- ванного с применением паттерна Команда. У каждой команды может быть свой получатель: объект, выполняющий действие. Для команды PasteCommand получателем является Document , а для OpenCommand – приложение Цель Команды – разорвать связь между объектом, инициировавшим опера- цию (Инициатором), и объектом, который ее реализует (Получателем). В при- мере из «Паттернов проектирования» инициаторами являются пункты меню в графическом редакторе, а получателями – редактируемый документ или само приложение. Идея в том, чтобы поместить между инициатором и получателем объект Command, который реализует интерфейс с единственным методом execute, вызы- вающим какой-то метод Получателя для выполнения желаемой операции. Та- ким образом, Инициатор ничего не знает об интерфейсе Получателя, так что, написав подклассы Command, можно адаптировать различных получателей. Ини- циатор конфигурируется конкретной командой и вызывает ее метод execute. Отметим, что на рис. 10.2 показан, в частности, класс MacroCommand , который мо- жет хранить последовательность команд; его метод execute() вызывает одно- именный метод каждой хранимой команды. Авторы «Паттернов проектирования» пишут: «Команды – объектно-ори- ентированная замена обратным вызовам». Вопрос: а нужна ли нам объектно- ориентированная замена обратным вызовам? Иногда да, а иногда и нет. Вместо того чтобы передавать Инициатору объект Command, мы можем пере- дать ему обычную функцию. И вызывать Инициатор будет не метод command. execute(), а просто функцию command(). Класс MacroCommand можно реализовать с по- Паттерн Команда  345\n--- Страница 345 ---\nмощью класса, в котором реализован специальный метод __call__. Тогда экзем- пляры MacroCommand будут вызываемыми объектами, содержащими список функ - ций для последующего вызова (см. пример 10.10). Пример 10.10. В каждом объекте MacroCommand хранится внутренний список команд class MacroCommand: \"\"\"Команда, выполняющая список команд\"\"\" def __init__(self, commands): self.commands = list(commands)  def __call__(self): for command in self.commands:  command()  Построение списка, инициализированного аргументом commands, гарантиру - ет, что это итерируемый объект, и сохраняет локальную копию ссылок на команды в каждом экземпляре MacroCommand .  При вызове экземпляра MacroCommand последовательно вызываются все ко- манды из списка self.commands . Для менее тривиальных применений паттерна Команда – например, для поддержки операции отмены – простой функции обратного вызова может не хватить. Но даже в этом случае Python предлагает две альтернативы, заслу - живающие внимания. Вызываемый объект наподобие MacroCommand из примера 10.10 может хра- нить произвольное состояние и предоставлять другие методы в допол- нение к __call__. Для запоминания внутреннего состояния функции между ее вызовами можно воспользоваться замыканием. На этом мы завершаем переосмысление паттерна Команда, навеянное при- менением полноправных функций. На верхнем уровне этот подход близок к использованному в паттерне Стратегия: заменить вызываемыми объектами экземпляры класса-участника, реализующего интерфейс с единственным ме- тодом. Ведь любой вызываемый объект в Python и так реализует интерфейс с единственным методом, а именно методом __call__. резюме Как отметил Петер Норвиг спустя два года после выхода классической книги «Паттерны проектирования»: «16 из 23 паттернов в языках Lisp и Dylan имеют существенно более простую реализацию, чем в C++, по крайней мере в некото- рых ситуациях» (слайд 9 из презентации Норвига «Паттерны проектирования в динамических языках» (http://www.norvig.com/design-patterns/index.htm)). Python обладает некоторыми динамическими средствами, имеющимися в языках Lisp и Dylan, в частности полноправными функциями, которым в основном и по- священа эта часть книги. В том же выступлении на праздновании 20-й годовщины выхода «Паттер- нов проектирования», цитата из которого послужила эпиграфом к этой главе, 346  Реализация паттернов проектирования с помощью полноправных функций\n--- Страница 346 ---\nРальф Джонсон говорил, что одной из неудач книги стало «чрезмерно большое внимание к паттернам как конечным точкам, а не шагам проектирования»1. В этой главе мы взяли в качестве отправной точки паттерн Стратегия и по- казали, как упростить его работоспособную реализацию путем использования полноправных функций. Во многих случаях функции или вызываемые объекты оказываются более естественным способом реализации обратных вызовов в Python, чем раб- ское следование описаниям паттернов Стратегия или Команда, приведенным в книге «Паттерны проектирования». Переработка Стратегии и обсуждение Команды – примеры более общей ситуации: если встречается паттерн или API, который нуждается в компоненте с единственным методом, и этот метод име- ет такое общее название, как «execute», «run» или «doIt», то такой паттерн или API часто проще реализовать с помощью полноправных функций или иных вызываемых объектов. При этом объем стереотипного кода уменьшается. дОпО лнительная литература В рецепте 8.21 «Реализация паттерна Посетитель» из книги David Beazley, Brian K. Jones «Python Cookbook», 3-е издание (O’Reilly), предложена элегантная реали- зация паттерна Посетитель, в которой класс NodeVisitor обращается с методами, как с полноправными объектами. По паттернам проектирования выбор литературы для программиста на Python не так широк, как для других языков. Книга Gennadiy Zlobin «Learning Python Design Patterns» (Packt) – единствен- ная целиком посвященная паттернам в Python. Но она очень короткая (100 стра- ниц), и в ней рассмотрены только восемь из 23 оригинальных паттернов. Книга Tarek Ziade «Expert Python Programming» (Packt) – одна из лучших на рынке для программистов на Python среднего уровня, а в последней главе «Useful Design Patterns» описаны семь классических паттернов с точки зрения Python. Алекс Мартелли несколько раз выступал с докладами на тему паттернов проектирования в Python. В сети опубликована видеозапись его презентации на конференции EuroPython 2011 (https://pyvideo.org/europython-2011/python- design-patterns.html), а на его личном сайте также выложен набор слайдов (http:// www.aleax.it/gdd_pydp.pdf). В разные годы мне встречались наборы слайдов раз- ной комплектности и видео разной продолжительности, так что имеет смысл поискать повнимательнее, указав в запросе имя автора и слова «Python Design Patterns». В издательстве мне сказали, что Мартелли пишет книгу на эту тему. Я обязательно куплю ее, когда она выйдет. Существует много книг по паттернам проектирования в контексте Java, из них я хотел бы выделить книгу Eric Freeman, Bert Bates, Kathy Sierra, Elisabeth Robson «Head First Design Patterns», 2-е издание (O’Reilly). В ней объясняются 16 из 23 классических паттернов. Если вам нравится неформальный стиль се- рии «Head First» и требуется введение в эту тему, то это как раз то, что надо. Книга ориентирована на Java, но во втором издании отражено добавление 1 Из доклада «Root Cause Analysis of Some Faults in Design Patterns», прочитанного Джонсоном на IME-USP 15 ноября 2014 года. Дополнительная литература  347\n--- Страница 347 ---\nполноправных функций в Java, так что некоторые примеры стали ближе к коду, который мы пишем на Python. Тем, кого интересует свежий взгляд на паттерны с точки зрения динамиче- ского языка с динамической типизацией и полноправными функциями, стоит прочитать книгу Russ Olsen «Design Patterns in Ruby» (Addison-Wesley); многие мысли применимы также к Python. Несмотря на многочисленные синтаксиче- ские различия, на семантическом уровне Python и Ruby ближе друг к другу, чем к Java или C++. В презентации «In Design Patterns in Dynamic Languages» (http://norvig.com/ design-patterns/) (слайды) Петер Норвиг показывает, как с помощью полноправ- ных функций (и других динамических средств) сделать некоторые классиче- ские паттерны более простыми или вообще ненужными. За одно только введение к оригинальной книге Гамма и др. «Паттерны проектирования» можно было бы заплатить цену всей книги – это не просто каталог 23 паттернов, от очень важных до редко встречающихся. Введение – первоисточник часто цитируемых принципов проектирования: «Ставьте во главу угла интерфейс, а не реализацию» и «Предпочитайте композицию, а не наследование классов». Применять паттерны к проектированию впервые предложил архитектор Кристофер Александер с соавторами в книге «A Pattern Language» (Oxford University Press). Идея Александера заключалась в том, чтобы создать стандарт - ный словарь, который даст возможность разным коллективам обмениваться типичными решениями при проектировании зданий. М. Дж. Доминус создал завораживающий набор слайдов «‘Design Patterns’ Aren’t», и Postscript-текст к ним, в котором доказывает, что оригинальное видение паттернов Алексан- дером более значительно, больше соответствует человеческой природе и при- менимо также к программной инженерии. Поговорим В языке Python есть полноправные функции и полноправные типы – сред- ства, которые, согласно Норвигу, могут оказать влияние на 10 из 23 паттернов (слайд 10 из презентации «Design Patterns in Dynamic Languages» по адресу http://norvig.com/design-patterns/). В главе 9 мы видели, что в Python есть также обобщенные функции (раздел «Одиночная диспетчеризация и обобщенные функции»), похожие на мультиметоды из языка CLOS, которые в книге Гамма и др. названы более простым способом реализации классического паттерна Посетитель. Со своей стороны Норвиг утверждает, что мультиметоды упро- щают паттерн Построитель (слайд 10). Адаптация паттернов к языку про- граммирования – не точная наука. На учебных курсах в разных уголках мира паттерны проектирования часто преподают на примерах из Java. Я не раз слышал от студентов, будто их заверя- ли в том, что оригинальные паттерны полезны в любом языке. Как оказалось, 23 «классических» паттерна из книги Гамма и др. прекрасно ложатся на «клас - сический» Java, хотя первоначально излагались в основном в контексте C++ (в книге очень немного примеров для Smalltalk). Но это не значит, что каждый паттерн одинаково хорошо применим в любом языке. Авторы в самом начале348  Реализация паттернов проектирования с помощью полноправных функций\n--- Страница 348 ---\nкниги явно говорят, что «некоторые из наших паттернов напрямую поддержи- ваются менее распространенными объектно-ориентированными языками» (также еще раз прочитайте эпиграф к этой главе). Библиография на тему паттернов проектирования в Python крайне скромна по сравнению с Java, C++ или Ruby. В разделе «Дополнительная литература» я упомянул книгу Gennadiy Zlobin «Learning Python Design Patterns», опубли- кованную только в ноябре 2013 года. А вот книга Russ Olsen «Design Patterns in Ruby» вышла еще в 2007 году и насчитывает 384 страницы – на 284 больше, чем работа Злобина. Но будем надеяться, что с ростом популярности Python в академических кру- гах о паттернах проектирования в этом языке станут писать больше. Кроме того, в Java 8 появились ссылки на методы и анонимные функции – средства, которых ждали очень давно, – и есть надежда, что это стимулирует поиск но- вых подходов к паттернам в Java. В общем, надо признать, что языки разви- ваются, а вместе с ними и наши представления о том, как применять класси- ческие паттерны проектирования. Зов (call) предков Когда мы все вместе вносили в книгу последние исправления, технический рецензент Леонардо Рохаэль сделал удивительное открытие. Если у функций есть метод __call__, а методы сами являются вызываемыми объектами, то, возможно, у метода __call__ тоже есть метод __call__? Не знаю, будет ли его открытие полезным, но факт остается фактом: >>> def turtle(): return 'eggs' >>> turtle() 'eggs' >>> turtle.__call__() 'eggs' >>> turtle.__call__.__call__() 'eggs' >>> turtle.__call__.__call__.__call__() 'eggs' >>> turtle.__call__.__call__.__call__.__call__() 'eggs' >>> turtle.__call__.__call__.__call__.__call__.__call__() 'eggs' >>> turtle.__call__.__call__.__call__.__call__.__call__.__call__() 'eggs' >>> turtle.__call__.__call__.__call__.__call__.__call__.__call__.__call__() 'eggs' Черепахи – и нет им конца! (https://en.wikipedia.org/wiki/Turtles_all_the_way_down.) Дополнительная литература  349\n--- Страница 350 ---\nЧасть III Классы и протоколы",
      "debug": {
        "start_page": 332,
        "end_page": 350
      }
    },
    {
      "name": "Глава 11. Объект в духе Python 352",
      "content": "--- Страница 351 --- (продолжение)\nГлава 11 Объект в духе Python Чтобы библиотека или каркас были питоническими, нужно сделать так, чтобы программист на Python мог максимально легко и естественно по- нять, как решать задачу. – Мартин Фаассен, автор каркасов на Python и JavsScript1 Благодаря модели данных в Python пользовательские типы могут вести себя так же естественно, как встроенные. И это достигается безо всякого наследо- вания, в духе утиной типизации: достаточно просто реализовать методы, не- обходимые для того, чтобы объект вел себя ожидаемым образом. В предыдущих главах мы рассказали о структуре и поведении многих встро- енных объектов. А теперь займемся созданием собственных классов, которые ведут себя как настоящие объекты в Python. Вам не обязательно, да и не следу - ет, реализовывать в своих прикладных классах столько специальных методов, сколько в примерах из этой главы. Но если вы пишете библиотеку или каркас, то программисты, которые будут пользоваться вашими классами, ожидают от них такого же поведения, как от классов, предоставляемых самими Python. От- вечать таким ожиданиям и значит соблюдать «дух Python». Эта глава начинается с места, где закончилась глава 1, – мы покажем, как реализовать несколько специальных методов, которые обычно встречаются в объектах Python разных типов. В этой главе мы узнаем, как: поддержать встроенные функции, которые порождают альтернативные представления объекта ( repr(), bytes() и другие); реализовать альтернативный конструктор в виде метода класса; расширить мини-язык, используемый во встроенной функции format() и в методе str.format() ; предоставить доступ к атрибутам только для чтения; сделать объект хешируемым, чтобы он мог быть элементом множества и ключом словаря; сэкономить память за счет использования __slots__. Все это мы сделаем по мере разработки простого типа двумерного евклидова вектора Vector2d. Этот код ляжет в основу класса N -мерного вектора в главе 12. По ходу дела мы дважды прервемся, чтобы обсудить два концептуально важных вопроса: 1 Из статьи в блоге Фаассена «What is Pythonic?» (https://blog.startifact.com/posts/older/ what-is-pythonic.html).\nГлава 11 Объект в духе Python Чтобы библиотека или каркас были питоническими, нужно сделать так, чтобы программист на Python мог максимально легко и естественно по- нять, как решать задачу. – Мартин Фаассен, автор каркасов на Python и JavsScript1 Благодаря модели данных в Python пользовательские типы могут вести себя так же естественно, как встроенные. И это достигается безо всякого наследо- вания, в духе утиной типизации: достаточно просто реализовать методы, не- обходимые для того, чтобы объект вел себя ожидаемым образом. В предыдущих главах мы рассказали о структуре и поведении многих встро- енных объектов. А теперь займемся созданием собственных классов, которые ведут себя как настоящие объекты в Python. Вам не обязательно, да и не следу - ет, реализовывать в своих прикладных классах столько специальных методов, сколько в примерах из этой главы. Но если вы пишете библиотеку или каркас, то программисты, которые будут пользоваться вашими классами, ожидают от них такого же поведения, как от классов, предоставляемых самими Python. От- вечать таким ожиданиям и значит соблюдать «дух Python». Эта глава начинается с места, где закончилась глава 1, – мы покажем, как реализовать несколько специальных методов, которые обычно встречаются в объектах Python разных типов. В этой главе мы узнаем, как: поддержать встроенные функции, которые порождают альтернативные представления объекта ( repr(), bytes() и другие); реализовать альтернативный конструктор в виде метода класса; расширить мини-язык, используемый во встроенной функции format() и в методе str.format() ; предоставить доступ к атрибутам только для чтения; сделать объект хешируемым, чтобы он мог быть элементом множества и ключом словаря; сэкономить память за счет использования __slots__. Все это мы сделаем по мере разработки простого типа двумерного евклидова вектора Vector2d. Этот код ляжет в основу класса N -мерного вектора в главе 12. По ходу дела мы дважды прервемся, чтобы обсудить два концептуально важных вопроса: 1 Из статьи в блоге Фаассена «What is Pythonic?» (https://blog.startifact.com/posts/older/ what-is-pythonic.html).\n--- Страница 352 ---\nкак и когда использовать декораторы @classmethod и @staticmethod ; закрытые и защищенные атрибуты в Python: использование, соглаше- ния и ограничения. чтО нОвОг О в этОй главе Я заменил эпиграф и добавил несколько слов во второй абзац, посвященный вопросу о том, что такое «дух Python». В первом издании этот вопрос обсуж - дался в самом конце главы. Раздел «Форматирование при выводе» дополнен материалом об f-строках, появившихся в версии Python 3.6. Это небольшое изменение, поскольку f-строки поддерживают тот же самый мини-язык форматирования, что встро- енная функция format() и метод str.format() , поэтому все ранее написанные ме- тоды __format__ будут работать и с f-строками. Больше в главе почти ничего не изменилось – специальные методы в основ- ном те же самые, что в Python 3.0, а основные идеи заложены еще в Python 2.2. Начнем с методов представления объекта. предСтавления ОБъекта В любом объектно-ориентированном языке есть по меньшей мере один стан- дартный способ получить строковое представление произвольного объекта. В Python таких способов два: repr() Вернуть строку, представляющую объект в виде, удобном для разработчи- ка. Это то, что мы видим, когда объект отображается на консоли Python или в отладчике. str() Вернуть строку, представляющую объект в виде, удобном для пользователя. Это то, что печатает функция print(). Как мы знаем из главы 1, для поддержки функций repr() и str() необходимо реализовать специальные методы __repr__ и __str__. Существует еще два специальных метода для поддержки альтернативных представлений объектов: __bytes__ и __format__ . Метод __bytes__ аналогичен __ str__: он вызывается функцией bytes(), чтобы получить представление объекта в виде последовательности байтов. А метод __format__ вызывается f-строками, встроенной функцией format() и методом str.format() для получения строкового представления объектов с помощью специальных форматных кодов. В следу - ющем разделе мы рассмотрим метод __bytes__ , а вслед за ним метод __format__ . Если раньше вы программировали на Python 2, то имейте в виду, что в Python 3 методы __repr__, __str__ и __format__ всегда долж - ны возвращать Unicode-строки (типа str). И лишь метод __bytes__ должен возвращать последовательность байтов (типа bytes). Представления объекта  353\n--- Страница 353 ---\nи СнОва клаСС вект Ора Для демонстрации различных методов, генерирующих представления объек - тов, мы воспользуемся классом Vector2d, аналогичным рассмотренному в гла- ве 1. В этом и следующих разделах мы будем постепенно наращивать его функ - циональность. В примере 11.1 показано базовое поведение, ожидаемое от объ- екта Vector2d. Пример 11.1. У экземпляров Vector2d есть несколько представлений >>> v1 = Vector2d(3, 4) >>> print(v1.x, v1.y)  3.0 4.0 >>> x, y = v1  >>> x, y (3.0, 4.0)  >>> v1 Vector2d(3.0, 4.0) >>> v1_clone = eval(repr(v1))  >>> v1 == v1_clone  True >>> print(v1)  (3.0, 4.0) >>> octets = bytes(v1)  >>> octets b'd\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x08@\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x10@' >>> abs(v1)  5.0 >>> bool(v1), bool(Vector2d(0, 0))  (True,False)  К компонентам Vector2d можно обращаться напрямую, как к атрибутам (ме- тодов чтения нет).  Объект Vector2d можно распаковать в кортеж переменных.  repr для объекта Vector2d имитирует исходный код конструирования экзем- пляра.  Использование eval показывает, что результат repr для Vector2d – точное представление вызова конструктора1.  Vector2d поддерживает сравнение с помощью ==; это полезно для тестирования.  print вызывает функцию str, которая для Vector2d порождает упорядоченную пару.  bytes пользуется методом __bytes__ для получения двоичного представления.  abs вызывает метод __abs__, чтобы вернуть модуль вектора.  bool пользуется методом __bool__, чтобы вернуть False для объекта Vector2d ну- левой длины, и True в противном случае. Реализация класса Vector2d из примера 11.1 находится в файле vector2d_v0.py (пример 11.2). Код основан на примере 1.2, только методы для операций + и * 1 Я использовал для клонирования объект eval, просто чтобы проиллюстрировать по- ведение repr; на практике клонировать объект проще и безопаснее с помощью функ - ции copy.copy .354  Объект в духе Python\n--- Страница 354 ---\nбудут реализованы в главе 16. Мы также добавим метод для оператора ==, по- скольку он полезен для тестирования. В данный момент в Vector2d имеется не- сколько специальных методов для поддержки операций, которые питонист ожидает от хорошо спроектированного объекта. Пример 11.2. vector2d_v0.py: пока что реализованы только специальные методы from array import array import math class Vector2d: typecode = 'd'  def __init__(self, x, y): self.x = float(x)  self.y = float(y) def __iter__(self): return (i for i in (self.x, self.y))  def __repr__(self): class_name = type(self).__name__ return '{}({!r}, {!r})'.format(class_name, *self)  def __str__(self): return str(tuple(self))  def __bytes__(self): return (bytes([ord(self.typecode)]) +  bytes(array(self.typecode, self)))  def __eq__(self, other): return tuple(self) == tuple(other)  def __abs__(self): return math.hypot(self.x, self.y)  def __bool__(self): return bool(abs(self))   typecode – это атрибут класса, которым мы воспользуемся, когда будем пре- образовывать экземпляры Vector2d в последовательности байтов и наоборот.  Преобразование x и y в тип float в методе __init__ позволяет на ранней ста- дии обнаруживать ошибки, это полезно в случае, когда конструктор Vector2d вызывается с неподходящими аргументами.  Наличие метода __iter__ делает Vector2d итерируемым; именно благодаря ему работает распаковка (например, x, y = my_vector ). Мы реализуем его прос то с помощью генераторного выражения, которое отдает компоненты поочередно1. 1 Эту строку можно было бы записать и в виде yield self.x; yield.self.y . У меня еще найдется что сказать по поводу специального метода __iter__, генераторных выра- жений и ключевого слова yield в главе 17. И снова класс вектора  355\n--- Страница 355 ---\n Метод __repr__ строит строку, интерполируя компоненты с помощью син- таксиса {!r} для получения их представления, возвращаемого функцией repr; поскольку Vector2d – итерируемый объект, *self поставляет компоненты x и y функции format.  Из итерируемого объекта Vector2d легко построить кортеж для отображения в виде упорядоченной пары.  Для генерации объекта типа bytes мы преобразуем typecode в bytes и конкате- нируем …  … с объектом bytes, полученным преобразованием массива, который по- строен путем обхода экземпляра.  Для быстрого сравнения всех компонентов мы строим кортежи из операн- дов. Это работает, когда операнды являются экземплярами класса Vector2d, но не без проблем. См. предупреждение ниже.  Модулем вектора называется длина гипотенузы прямоугольного треуголь- ника с катетами x и y.  Метод __bool__ вызывает abs(self) для вычисления модуля, а затем преоб- разует полученное значение в тип bool, так что 0.0 преобразуется в False, а любое число, отличное от нуля, – в True. Метод __eq__ в примере 11.2 работает для операндов типа Vector2d, но возвращает True и в случае, когда экземпляр Vector2d сравнивается с другими итерируемыми объектами, содержащи- ми точно такие же числовые значения (например, Vector(3, 4) == [3, 4]). Считать ли это ошибкой, зависит от точки зрения. Мы от - ложим дальнейшее обсуждение этого вопроса до главы 16, где рассматривается перегрузка операторов. У нас имеется довольно полный набор базовых методов, но одного, очевид- но, не хватает: восстановления объекта Vector2d из двоичного представления, порожденного функцией bytes(). альтернативный кОнСтрукт Ор Поскольку мы можем экспортировать Vector2d в виде последовательности бай- тов, хотелось бы иметь метод, который производит обратную операцию – конструирование Vector2d из двоичной последовательности. Заглянув в стан- дартную библиотеку в поисках источника вдохновения, мы обнаружим, что в классе array.array есть метод класса .frombytes , который нас вполне устраива- ет – мы видели его применение в разделе «Массивы» главы 2. Позаимствуем как имя, так и функциональность при написании метода класса Vector2d в фай- ле vector2d_v1.py (пример 11.3). Пример 11.3. Часть файла vector2d_v1.py: здесь показан только метод класса frombytes , добавленный в определение Vector2d из файла vector2d_v0.py (пример 11.2) @classmethod  def frombytes(cls, octets):  typecode = chr(octets[0])  memv = memoryview(octets[1:]).cast(typecode)  return cls(*memv)  356  Объект в духе Python\n--- Страница 356 ---\n Метод класса снабжен декоратором classmethod .  Аргумент self отсутствует; вместо него в аргументе cls передается сам класс.  Прочитать typecode из первого байта.  Создать объект memoryview из двоичной последовательности октетов и при- вести его к типу typecode1.  Распаковывать memoryview , образовавшийся в результате приведения типа, и получить пару аргументов, необходимых конструктору. Поскольку мы только что воспользовались декоратором classmethod , весьма специфичным для Python, будет уместно сказать о нем несколько слов. декОрат Оры clAssmethod и stAticmethod Декоратор classmethod не упоминается в пособии по Python, равно как и декора- тор staticmethod . Те, кто изучал объектно-ориентированное программирование на примере Java, наверное, недоумевают, зачем в Python два декоратора, а не какой-нибудь один из них. Начнем с classmethod . Его использование показано в примере 11.3: опреде- лить метод на уровне класса, а не отдельного экземпляра. Декоратор classmethod изменяет способ вызова метода таким образом, что в качестве первого аргу - мента передается сам класс, а не экземпляр. Типичное применение – альтер- нативные конструкторы, подобные frombytes из примера 11.3. Обратите внима- ние, как в последней строке метод frombytes использует аргумент cls, вызывая его для создания нового экземпляра: cls(*memv) . Напротив, декоратор staticmethod изменяет метод так, что он не получает в первом аргументе ничего специального. По существу, статический метод – это просто обычная функция, определенная в теле класса, а не на уровне моду - ля. В примере 11.4 сравнивается работа classmethod и staticmethod . Пример 11.4. Сравнение декораторов classmethod и staticmethod >>> class Demo: @classmethod def klassmeth(*args):  return args @staticmethod def statmeth(*args): return args  >>> Demo.klassmeth()  (<class '__main__.Demo'>,) >>> Demo.klassmeth('spam') (<class '__main__.Demo'>, 'spam') >>> Demo.statmeth()  () >>> Demo.statmeth('spam') ('spam',)  klassmeth просто возвращает все позиционные аргументы.  statmeth делает то же самое. 1 Краткое введение в memoryview , где, в частности, описывается метод .cast, см. в раз- деле «Представления памяти» главы 2. Декораторы classmethod и staticmethod  357\n--- Страница 357 ---\n Вне зависимости от способа вызова Demo.klassmeth получает класс Demo в качест ве первого аргумента.  Demo.statmeth ведет себя как обычная функция. Декоратор classmethod , очевидно, полезен, но мне очень редко встречались хорошие примеры употребления staticmethod . Быть может, функция тесно связана с классом, хотя и не залезает в его «потроха», так что лучше разместить ее код поблизости. Но даже если так, размещение функции сразу до или после класса в том же модуле – это достаточно близко для любых практических целей1. Узнав, для чего применяется декоратор classmethod (и почему staticmethod не очень полезен), вернемся к вопросу о представлении объекта и посмотрим, как поддерживается форматирование вывода. фОрматир Ование при вывО де Встроенная функция format() и метод str.format() делегируют форматирование конкретному типу, вызывая его метод .__format__(format_spec) . Аргумент format_ spec – это спецификатор формата, который либо: является вторым аргументом при вызове format(my_obj, format_spec) , либо равен тому, что находится после двоеточия в поле подстановки, обозна- чаемом скобками {} внутри f-строки или fmt при вызове str.format() . Например: >>> brl = 1 / 4.82 # курс бразильского реала к доллару США >>> brl 0.20746887966804978 >>> format(brl, '0.4f')  '0.2075' >>> '1 BRL = {rate:0.2f} USD'.format(rate=brl)  '1 BRL = 0.21 USD' >>> f'1 USD = {1 / brl:0.2f} BRL'  '1 USD = 4.82 BRL'  Спецификатор формата '0.4f'.  Спецификатор формата '0.2f'. Подстрока 'rate' в поле подстановки назы- вается именем поля. Она не связана со спецификатором формата, а опре- деляет, какой аргумент метода .format() попадает в это поле подстановки.  Снова спецификатор '0.2f'. Выражение 1 / brl не является его частью. Код, помеченный вторым маркером, – демонстрация важного момента: в форматной строке, например, '{0.mass:5.3e}' мы видим две совершенно раз- ные нотации. Часть '0.mass' слева от двоеточия – это имя поля подстановки field_name, а часть '5.3e' после двоеточия – спецификатор формата. Нотация, 1 Леонардо Рохаэль, один из технических рецензентов книги, не согласен с моим скеп- тическим отношением к декоратору staticmethod и рекомендует прочитать статью в «The Definitive Guide on How to Use Static, Class or Abstract Methods in Python» (https:// julien.danjou.info/guide-python-static-class-abstract-methods/) в блоге Жюльена Данжу, где приводятся контраргументы. Статья Данжу очень интересна, рекомендую ее. Но ее оказалось недостаточно, чтобы я изменил свое мнение о staticmethod . Решать вам. 358  Объект в духе Python\n--- Страница 358 ---\nприменяемая в спецификаторе формата, называется также мини-языком специ фикации формата (https://docs.python.org/3/library/string.html#formatspec). Если вы раньше не встречались с f-строками, format() и str. format(), то хочу сказать, что мой опыт преподавания показывает, что лучше сначала изучить функцию format(), в которой исполь- зуется только мини-язык спецификации формата. Освоив его, прочитайте разделы документации «Литералы форматной стро- ки» (https://docs.python.org/3/reference/lexical_analysis.html#f-strings) и «Синтаксис форматной строки» (https://docs.python.org/3/library/ string.html#format-string-syntax), чтобы разобраться с нотацией поля подстановки {:}, используемой в f-строках и методе str.format() (включая флаги преобразования !s, !r и !a). F-строки не отменя- ют метод str.format() : как правило, f-строки решают задачу, но иногда лучше задать форматную строку где-то в другом месте, а не там, где она используется для вывода. Для нескольких встроенных типов в мини-языке спецификации формата предусмотрены специальные коды представления. Например, для типа int поддерживаются (среди прочих) коды b и x, обозначающие соответственно ос- нование 2 и 16, а для типа float – код f для вывода значения с фиксированной точкой и % для вывода в виде процента: >>> format(42, 'b') '101010' >>> format(2 / 3, '.1%') '66.7%' Мини-язык спецификации формата расширяемый, потому что каждый класс может интерпретировать аргумент format_spec , как ему вздумается. На- пример, классы из модуля datetime пользуются одними и теми же форматными кодами в функции strftime() и в своих методах __format__ . Вот несколько приме- ров применения встроенной функции format() и метода str.format() : >>> from datetime import datetime >>> now = datetime.now() >>> format(now, '%H:%M:%S') '18:49:05' >>> \"It's now {:%I:%M %p}\".format(now) \"It's now 06:49 PM\" Если в классе не реализован метод __format__ , то используется метод, уна- следованный от object, который возвращает значение str(my_object) . Поскольку в классе Vector2d есть метод __str__, это работает следующим образом: >>> v1 = Vector2d(3, 4) >>> format(v1) '(3.0, 4.0)' Но если передать спецификатор формата, то object.__format__ возбудит ис- ключение TypeError: >>> format(v1, '.3f') Traceback (most recent call last): TypeError: non-empty format string passed to object.__format__ Форматирование при выводе  359\n--- Страница 359 ---\nИсправим это, реализовав собственный мини-язык форматирования. Для начала предположим, что спецификатор формата, заданный пользователем, служит для форматирования каждой компоненты float вектора. Вот какой ре- зультат мы хотим получить: >>> v1 = Vector2d(3, 4) >>> format(v1) '(3.0, 4.0)' >>> format(v1, '.2f') '(3.00, 4.00)' >>> format(v1, '.3e') '(3.000e+00, 4.000e+00)' В примере 11.5 реализован метод __format__ , дающий именно такой результат. Пример 11.5. Метод Vector2d.format , попытка № 1 # в классе Vector2d def __format__(self, fmt_spec=''): components = (format(c, fmt_spec) for c in self)  return '({}, {})'.format(*components)   Использовать встроенную функцию format, чтобы применить fmt_spec к каж - дой компоненте вектора и построить итерируемый объект, порождающий отформатированные строки.  Подставить отформатированные строки в шаблон '(x, y)'. Теперь добавим в наш мини-язык специальный форматный код: если спецификатор формата заканчивается буквой 'p', то будем отображать век- тор в полярных координатах: <r, θ>, где r – модуль, а θ – угол в радианах. Остаток спецификатора формата (все, что предшествует 'p') используется, как и раньше. При выборе буквы для специального форматного кода я стремил- ся избегать совпадения с кодами для других типов. В мини-язы- ке спецификации формата (https://docs.python.org/3/library/string. html#formatspec) для целых чисел используются коды 'bcdoxXn' , для чисел с плавающей точкой – 'eEfFgGn%' , а для строк – 's'. Поэтому для полярных координат я взял код 'p'. Поскольку каждый класс интерпретирует коды независимо от остальных, использование одной и той же буквы в разных классах не является ошибкой, но может вызвать недоумение у пользователей. Для вычисления полярных координат у нас уже есть метод __abs__, возвраща- ющий модуль, а для получения угла напишем простой метод angle, в котором используется функция math.atan2() . Вот его код: # в классе Vector2d def angle(self): return math.atan2(self.y, self.x) Теперь мы можем обобщить метод __format__ для вывода представления в по- лярных координатах. 360  Объект в духе Python\n--- Страница 360 ---\nПример 11.6. Метод Vector2d.format , попытка № 2 – теперь и в полярных координатах def __format__(self, fmt_spec=''): if fmt_spec.endswith('p'):  fmt_spec = fmt_spec[:-1]  coords = (abs(self), self.angle())  outer_fmt = '<{}, {}>'  else: coords = self  outer_fmt = '({}, {})'  components = (format(c, fmt_spec) for c in coords)  return outer_fmt.format(*components)   Формат заканчивается буквой 'p': полярные координаты.  Удалить суффикс 'p' из fmt_spec.  Построить кортеж полярных координат: (magnitude, angle) .  Сконфигурировать внешний формат, используя угловые скобки.  Иначе использовать компоненты x, y вектора self для представления в пря- моугольных координатах.  Сконфигурировать внешний формат, используя круглые скобки.  Породить итерируемый объект, компонентами которого являются отфор- матированные строки.  Подставить строки во внешний формат. Ниже показаны результаты, полученные с помощью кода из примера 11.6. >>> format(Vector2d(1, 1), 'p') '<1.4142135623730951, 0.7853981633974483>' >>> format(Vector2d(1, 1), '.3ep') '<1.414e+00, 7.854e-01>' >>> format(Vector2d(1, 1), '0.5fp') '<1.41421, 0.78540>' Как видно из этого раздела, совсем несложно расширить мини-язык специ- фикации формата для поддержки пользовательских типов. Теперь перейдем к вопросу, не относящемуся к видимому представлению: мы сделаем класс Vector2d хешируемым, чтобы можно было создавать множест - ва векторов и использовать векторы в качестве ключей словаря. хешируемый клаСС Vector 2d До сих пор экземпляры класса Vector2d не были хешируемыми, поэтому мы не могли поместить их в множество: >>> hash(v1) Traceback (most recent call last): TypeError: unhashable type: 'Vector2d' >>> set([v1]) Traceback (most recent call last): TypeError: unhashable type: 'Vector2d' Чтобы класс Vector2d был хешируемым, мы должны реализовать метод __hash__ (необходим еще метод __eq__, но он у нас уже есть). Нужно также, чтобы векто- Хешируемый класс Vector2d  361\n--- Страница 361 ---\nры были неизменяемыми, как было сказано во врезке «Что значит “хешируе- мый”?» в главе 3. Пока ничто не мешает любому пользователю написать v1.x = 7, т. к. нигде в коде не говорится, что изменение Vector2d запрещено. Вот какое поведение мы хотим получить: >>> v1.x, v1.y (3.0, 4.0) >>> v1.x = 7 Traceback (most recent call last): AttributeError: can't set attribute Мы добьемся этого, сделав компоненты x и y свойствами, доступными толь- ко для чтения. Пример 11.7. vector2d_v3.py: показаны только изменения, необходимые, чтобы сделать класс Vector2d неизменяемым, полный листинг см. в примере 11.11 class Vector2d: typecode = 'd' def __init__(self, x, y): self.__x = float(x)  self.__y = float(y) @property  def x(self):  return self.__x  @property  def y(self): return self.__y def __iter__(self): return (i for i in (self.x, self.y))  # остальные методы: такие же, как в предыдущем варианте Vector2d  Использовать ровно два начальных подчерка (и нуль или один конечный), чтобы сделать атрибут закрытым1.  Декоратор @property помечает метод чтения свойства.  Метод чтения назван так же, как соответствующее открытое свойство: x.  Просто вернуть self.__x.  Повторяем то же самое для свойства y.  Все методы, которые просто читают компоненты x и y, не изменяются, только теперь self.x и self.y означает чтение открытых свойств, а не закры- тых атрибутов. Поэтому оставшаяся часть класса не показана. 1 Плюсы и минусы закрытых атрибутов – тема раздела «Закрытые и защищенные атрибуты в Python» ниже в этой главе.362  Объект в духе Python\n--- Страница 362 ---\nVector.x и Vector.y – примеры свойств, доступных только для чтения. Свойства, доступные для чтения и записи, рассматрива- ются в главе 22, где мы детально изучим декоратор @property . Теперь, когда векторы стали неизменяемыми, мы можем реализовать метод __hash__. Он должен возвращать int и в идеале учитывать хеши объектов-атрибу - тов, которые используются также в методе __eq__, потому что у равных объектов хеши также должны быть одинаковы. В документации по специальному методу __hash__ (https://docs.python.org/3/reference/datamodel.html) рекомендуется вычислять хеш кортежа покомпонентно, так мы и поступим (см. пример 11.8). Пример 11.8. vector2d_v3.py: реализация хеширования # в классе Vector2d: def __hash__(self): return hash((self.x, self.y)) После добавления метода __hash__ мы получили хешируемые векторы: >>> v1 = Vector2d(3, 4) >>> v2 = Vector2d(3.1, 4.2) >>> hash(v1), hash(v2) (1079245023883434373, 1994163070182233067) >>> {v1, v2} {Vector2d(3.1, 4.2), Vector2d(3.0, 4.0)} Строго говоря, для создания хешируемого типа необязатель- но вводить свойства или как-то иначе защищать атрибуты экземпляра от изменения. Требуется только корректно реа- лизовать методы __hash__ и __eq__. Но значение хешируемого объекта никогда не должно изменяться, так что представился отличный повод поговорить о свойствах, доступных только для чтения. Если вы собираетесь создать тип с разумным скалярным числовым значе- нием, то имеет смысл реализовать также методы __int__ и __float__, которые вызываются из конструкторов int() и float(), используемых в некоторых кон- текстах для приведения типов. Существует также метод __complex__ , поддер- живающий встроенный конструктор complex(). Быть может, в классе Vector2d и стоило бы реализовать метод __complex__ , но это я оставляю вам в качестве упражнения. пОддержка пОзициОннОг О СОпОС тавления С ОБразц Ом До сих пор экземпляры Vector2d были совместимы с именованными классами- образцами, которые рассматривались в разделе «Именованные классы-образ- цы» главы 5. В примере 11.9 все эти именованные образцы работают в полном соответ - ствии с ожиданиями. Поддержка позиционного сопоставления с образцом  363\n--- Страница 363 ---\nПример 11.9. Именованные образцы для субъектов типа Vector2d – требуется версия Python 3.10 def keyword_pattern_demo(v: Vector2d) -> None: match v: case Vector2d(x=0, y=0): print(f'{v!r} is null') case Vector2d(x=0): print(f'{v!r} is vertical') case Vector2d(y=0): print(f'{v!r} is horizontal') case Vector2d(x=x, y=y) if x==y: print(f'{v!r} is diagonal') case _: print(f'{v!r} is awesome') Однако при попытке использовать позиционный образец: case Vector2d(_, 0): print(f'{v!r} is horizontal') мы получаем: TypeError: Vector2d() accepts 0 positional sub-patterns (1 given) Чтобы заставить Vector2d работать с позиционными образцами, необходимо добавить атрибут класса __match_args__ , перечислив в нем атрибуты экземпляра в том порядке, в каком они будут использоваться при позиционном сравнении с образцом: class Vector2d: __match_args__ = ('x', 'y') # и т. д. Теперь мы можем сэкономить несколько нажатий клавиш при написании образцов, которые сопоставляются с субъектами Vector2d, как показано в при- мере 11.10. Пример 11.10. Позиционные образцы для субъектов типа Vector2d – требуется версия Python 3.10 def positional_pattern_demo(v: Vector2d) -> None: match v: case Vector2d(0, 0): print(f'{v!r} is null') case Vector2d(0): print(f'{v!r} is vertical') case Vector2d(_, 0): print(f'{v!r} is horizontal') case Vector2d(x, y) if x==y: print(f'{v!r} is diagonal') case _: print(f'{v!r} is awesome') Атрибут класса __match_args__ не обязан включать все открытые атрибуты эк- земпляра. В частности, если у метода __init__ имеются обязательные и факуль- тативные аргументы, которые присваиваются атрибутам экземпляра, то, воз-364  Объект в духе Python\n--- Страница 364 ---\nможно, будет разумно перечислить в __match_args__ обязательные аргументы, но опустить факультативные. Теперь сделаем шаг назад и окинем взглядом все, что мы написали в классе Vector2d. пОлный кОд клаССа Vector 2d, верСия 3 По ходу работы над классом Vector2d мы показывали только фрагменты кода, а в примере 11.11 представлен полный код vector2d_v3.py со всеми тестами, ко- торые я писал, пока разрабатывал его. Пример 11.11. vector2d_v3.py: полный код «»» Класс двумерного вектора >>> v1 = Vector2d(3, 4) >>> print(v1.x, v1.y) 3.0 4.0 >>> x, y = v1 >>> x, y (3.0, 4.0) >>> v1 Vector2d(3.0, 4.0) >>> v1_clone = eval(repr(v1)) >>> v1 == v1_clone True >>> print(v1) (3.0, 4.0) >>> octets = bytes(v1) >>> octets b'd\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x08@\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x 00\\\\x10@' >>> abs(v1) 5.0 >>> bool(v1), bool(Vector2d(0, 0)) (True, False) Тест метода класса ``.frombytes()``: >>> v1_clone = Vector2d.frombytes(bytes(v1)) >>> v1_clone Vector2d(3.0, 4.0) >>> v1 == v1_clone True Тесты ``format()`` с декартовыми координатами: >>> format(v1) '(3.0, 4.0)' >>> format(v1, '.2f') '(3.00, 4.00)' Полный код класса Vector2d, версия 3  365\n--- Страница 365 ---\n>>> format(v1, '.3e') '(3.000e+00, 4.000e+00)' Тесты метода ``angle``:: >>> Vector2d(0, 0).angle() 0.0 >>> Vector2d(1, 0).angle() 0.0 >>> epsilon = 10**-8 >>> abs(Vector2d(0, 1).angle() - math.pi/2) < epsilon True >>> abs(Vector2d(1, 1).angle() - math.pi/4) < epsilon True Тесты ``format()`` с полярными координатами: >>> format(Vector2d(1, 1), 'p') # doctest:+ELLIPSIS '<1.414213 , 0.785398 >' >>> format(Vector2d(1, 1), '.3ep') '<1.414e+00, 7.854e-01>' >>> format(Vector2d(1, 1), '0.5fp') '<1.41421, 0.78540>' Тесты свойств `x` и `y`, доступных только для чтения: >>> v1.x, v1.y (3.0, 4.0) >>> v1.x = 123 Traceback (most recent call last): AttributeError: can't set attribute 'x' Тесты хеширования: >>> v1 = Vector2d(3, 4) >>> v2 = Vector2d(3.1, 4.2) >>> len({v1, v2}) 2 \"\"\" from array import array import math class Vector2d: __match_args__ = ('x', 'y') typecode = 'd' def __init__(self, x, y): self.__x = float(x) self.__y = float(y)366  Объект в духе Python\n--- Страница 366 ---\n@property def x(self): return self.__x @property def y(self): return self.__y def __iter__(self): return (i for i in (self.x, self.y)) def __repr__(self): class_name = type(self).__name__ return '{}({!r}, {!r})'.format(class_name, *self) def __str__(self): return str(tuple(self)) def __bytes__(self): return (bytes([ord(self.typecode)]) + bytes(array(self.typecode, self))) def __eq__(self, other): return tuple(self) == tuple(other) def __hash__(self): return hash((self.x, self.y)) def __abs__(self): return math.hypot(self.x, self.y) def __bool__(self): return bool(abs(self)) def angle(self): return math.atan2(self.y, self.x) def __format__(self, fmt_spec=''): if fmt_spec.endswith('p'): fmt_spec = fmt_spec[:-1] coords = (abs(self), self.angle()) outer_fmt = '<{}, {}>' else: coords = self outer_fmt = '({}, {})' components = (format(c, fmt_spec) for c in coords) return outer_fmt.format(*components) @classmethod def frombytes(cls, octets): typecode = chr(octets[0]) memv = memoryview(octets[1:]).cast(typecode) return cls(*memv) Подведем итоги. В этом и предыдущем разделах мы видели некоторые спе- циальные методы, которые должен иметь полноценный объект. Полный код класса Vector2d, версия 3  367\n--- Страница 367 ---\nРеализовывать эти специальные методы следует, только если приложение в них нуждается. Пользователям наплевать, соот - ветствует ваш объект «духу Python» или нет. С другой стороны, если ваши классы являются частью библиоте- ки, предназначенной для других программистов, то вы не знае- те, что они будут делать с вашими объектами, так что лучше, если они будут отвечать духу Python. Представленный в примере 11.11 класс Vector2d – написанный в педагоги- ческих целях код, изобилующий специальными методами, относящимися к представлению объекта, а не образец для создания любого пользователь- ского класса. В следующем разделе мы отвлечемся от класса Vector2d и обсудим дизайн и недостатки механизма закрытых атрибутов в Python – двойное подчеркива- ние в начале имени self.__x. закрытые и «защищенные » атриБуты в python В Python не существует способа создать закрытые переменные, как с помощью модификатора private в Java. Мы имеем лишь простой механизм, предотвраща- ющий случайную модификацию «закрытого» атрибута в подклассе. Рассмотрим такую ситуацию: кто-то написал класс Dog, где используется внутренний атрибут экземпляра mood, который автор не хотел раскрывать кли- ентам. Нам нужно написать подкласс Dog – Beagle. Если мы создадим свой атри- бут экземпляра mood, не подозревая о конфликте имен, то затрем атрибут mood, используемый в методах, унаследованных от Dog. Отлаживать такую ошибку непросто. Чтобы предотвратить это, мы можем назвать атрибут __mood (с двумя началь- ными подчерками и, возможно, одним – не более – конечным подчерком). Тог- да Python сохранит имя в словаре экземпляра __dict__, добавив в начало один подчерк и имя класса, т. е. в классе Dog атрибут __mood будет называться _Dog__ mood, а в классе Beagle – _Beagle__mood . Эта особенность языка имеет прелестное название – декорирование имен (name mangling). В примере 11.12 показано, как это выглядит в классе Vector2d из примера 11.7. Пример 11.12. Имена закрытых атрибутов «декорируются» добавлением префикса _ и име- ни класса >>> v1 = Vector2d(3, 4) >>> v1.__dict__ {'_Vector2d__y': 4.0, '_Vector2d__x': 3.0} >>> v1._Vector2d__x 3.0 Декорирование имен служит скорее предохранительной мерой, а не сред- ством обеспечения безопасности; идея в том, чтобы предотвратить случайный доступ, а не намеренное желание причинить зло (на рис. 11.1 изображено еще одно предохранительное устройство). Любой программист, знающий, как устроено декорированное имя, может на- прямую прочитать закрытый атрибут, как показано в последней строке при- 368  Объект в духе Python\n--- Страница 368 ---\nмера 11.12, – и это полезно для отладки и сериализации. Можно также присво- ить значение закрытому компоненту Vector2d, просто написав v1._Vector__x = 7 . Но если вы так сделаете в производственном коде, то жаловаться на то, что про- грамма перестала работать, будет некому. Декорирование имен нравится далеко не всем питонистам, как и непри- глядные имена вида self.__x. Некоторые предпочитают вместо этого добавлять одиночный подчерк, чтобы «защитить» атрибуты соглашением (например, self._x). Критики автоматического декорирования имен с двумя начальны- ми подчерками говорят, что проблему случайного затирания атрибутов сле- дует решать с помощью соглашений об именовании. Ян Байкинг, автор pip, virtualenv и других проектов, пишет: Ни в коем случае не используйте два подчерка в начале. Это приватно до безобразия. Если конфликт имен представляет проблему, применяйте яв- ное декорирование (например, _MyThing_blahblah). По сути дела, это то же самое, что два подчерка, только делает прозрачным то, что два подчерка скрывают1. Рис. 11.1. Крышка рубильника – это предохранительное устройство, не гарантирующее безопас ность, она предотвращает случайное, а не злонамеренное включение Одиночный начальный подчерк в именах атрибутов не означает ничего особенного для интерпретатора Python, но в среде программистов, пишущих на этом языке, бытует соглашение о том, что не надо обращаться к таким атри- бутам извне самого класса2. Нетрудно уважать право на приватность объекта, который помечает свои атрибуты одиночным знаком _, равно как и соблюдать соглашение о том, что переменные с именами, состоящими только из заглав- ных букв ( ALL_CAPS), должны считаться константами. 1 Из «Руководства по стилю программирования в Paste» (http://pythonpaste.org/StyleGuide.html). 2 В модулях одиночный подчерк в начале имени верхнего уровня имеет специальный смысл: если написать from mymod import * , то имена с префиксом _ не будут импортиро- ваться из mymod. Но ничто не мешает явно написать from mymod import _privatefunc . Это объясняется в «Учебном пособии по Python» в разделе 6.1 «Еще о модулях» (https:// docs.python.org/3/tutorial/modules.html#more-on-modules). Закрытые и «защищенные» атрибуты в Python  369\n--- Страница 369 ---\nАтрибуты с одиночным подчерком в начале в некоторых уголках документации Python называются «защищенными»1. Практика «защиты» атрибутов соглашени- ем вида self._x широко распространена, но название «защищенный» не столь употребительно. Некоторые даже называют такие атрибуты «закрытыми». Подведем итог: компоненты класса Vector2d «закрыты», а экземпляры Vector2d «неизменяемы». Устрашающие кавычки поставлены, потому что на самом деле не существует способа сделать их по-настоящему закрытыми и неизменяемыми2. Но вернемся к классу Vector2d. В последнем разделе мы рассмотрим специ- альный атрибут (не метод) __slots__, который влияет на внутреннее хранение данных в объекте, что может заметно сократить потребление памяти, но почти не сказывается на открытом интерфейсе класса. экОнОмия памяти С пОмОщью атриБута клаССа __slots__ По умолчанию Python хранит атрибуты экземпляра в словаре __dict__, принад- лежащем самому экземпляру. В разделе «Практические последствия механиз- ма работы dict» главы 3 мы видели, что со словарями сопряжены значительные накладные расходы – даже при всех упомянутых там оптимизациях. Но если определить атрибут класса __slots__, в котором хранится последовательность имен атрибутов, то Python будет использовать альтернативную модель хра- нения для атрибутов экземпляра: атрибуты с именами, представленными в __ slots__, хранятся в скрытом массиве ссылок, потребляющем намного меньше памяти, чем dict. Посмотрим, как это работает на простых примерах. Пример 11.13. Класс Pixel использует __slots__ >>> class Pixel: __slots__ = ('x', 'y')  >>> p = Pixel()  >>> p.__dict__  Traceback (most recent call last): AttributeError: 'Pixel' object has no attribute '__dict__' >>> p.x = 10  >>> p.y = 20  >>> p.color = 'red' Traceback (most recent call last): AttributeError: 'Pixel' object has no attribute 'color'  __slots__ должен присутствовать в момент создания класса; добавление или изменение впоследствии не оказывает никакого эффекта. Имена атрибу - тов могут храниться в кортеже или в списке, но лично я предпочитаю кор- теж, чтобы сразу было понятно, что изменять его нет никакого смысла. 1 Один такой пример – документация по модулю gettext (https://docs.python.org/3/library/ gettext.html# gettext.NullTranslations). 2 Если такое состояние дел вас угнетает и вызывает желание сделать Python больше похожим в этом отношении на Java, не читайте мои высказывания по поводу отно- сительности возможностей модификатора private в Java во врезке «Поговорим».370  Объект в духе Python\n--- Страница 370 ---\n Создать экземпляр Pixel, потому что мы хотим видеть, как __slots__ влияет на экземпляры.  Первый эффект: у экземпляров Pixel нет атрибута __dict__.  Установить атрибуты p.x и p.y как обычно.  Второй эффект: попытка установить атрибут, отсутствующий в __slots__, приводит к исключению AttributeError . Пока все хорошо. А теперь давайте создадим подкласс Pixel в примере 11.14, чтобы увидеть сторону __slots__, противоречащую интуиции. Пример 11.14. Класс OpenPixel является подклассом Pixel >>> class OpenPixel(Pixel):  pass >>> op = OpenPixel() >>> op.__dict__  {} >>> op.x = 8  >>> op.__dict__  {} >>> op.x  8 >>> op.color = 'green'  >>> op.__dict__  {'color': 'green'}  OpenPixel не объявляет собственных атрибутов.  Сюрприз: у экземпляров OpenPixel есть атрибут __dict__.  Если установить атрибут x (присутствующий в атрибуте __slots__ базового класса Pixel) …  … то он не появляется в атрибуте __dict__ экземпляра …  … но сохраняется в скрытом массиве ссылок в этом экземпляре.  Если установить атрибут, отсутствующий в __slots__ …  … то он сохраняется в атрибуте __dict__ экземпляра. Пример 11.14 показывает, что эффект __slots__ лишь частично наследуется подклассом. Чтобы гарантировать отсутствие __dict__ в подклассе, необходимо еще раз объявить в нем __slots__. Если объявить __slots__ = () (пустой кортеж), то у экземпляров подклас - са не будет __dict__ и они будут принимать только атрибуты, перечисленные в атрибуте __slots__ базового класса. Если вы хотите, чтобы в подклассе не было дополнительных атрибутов, то перечислите имена тех, что вас интересуют, в __slots__, как показано в приме- ре 11.15. Пример 11.15. ColorPixel , еще один подкласс Pixel >>> class ColorPixel(Pixel): __slots__ = ('color',)  >>> cp = ColorPixel() >>> cp.__dict__  Traceback (most recent call last): Экономия памяти с помощью атрибута класса __slots__  371\n--- Страница 371 ---\nAttributeError: 'ColorPixel' object has no attribute '__dict__' >>> cp.x = 2 >>> cp.color = 'blue'  >>> cp.flavor = 'banana' Traceback (most recent call last): AttributeError: 'ColorPixel' object has no attribute 'flavor'  Атрибуты __slots__ суперклассов добавляются в __slots__ текущего класса. Не забывайте, что кортежи с одним элементом должны заканчиваться за- пятой.  Экземпляры ColorPixel не имеют атрибута __dict__.  Мы можем установить только атрибуты, объявленные в __slots__ этого клас - са и его суперклассов, и больше никакие. Можно и «память сэкономить, и косточкой не подавиться»: если добавить имя '__dict__' в список __slots__, то все атрибуты, перечисленные в __slots__, бу- дут храниться в массиве ссылок, принадлежащем экземпляру, но при этом раз- решено динамически создавать новые атрибуты, которые хранятся в словаре __dict__, как обычно. Это обязательно, если вы хотите пользоваться декорато- ром @cached_property (рассматривается в разделе «Шаг 5: кеширование свойств с помощью functools» главы 22). Разумеется, помещение '__dict__' в атрибут __slots__ может свести на нет все преимущества последнего, но это зависит от количества статических и динамиче- ских атрибутов и того, как они используются. Бездумная оптимизация еще хуже преждевременной: вы увеличиваете сложность, а взамен не получаете ничего. Существует еще один специальный атрибут экземпляра, который имеет смысл сохранить: __weakref__ необходим, чтобы объект поддерживал слабые ссылки (см. раздел «Слабые ссылки» главы 6). По умолчанию этот атрибут при- сутствует в экземплярах всех пользовательских классов. Однако если в классе определен атрибут __slots__, а вам нужно, чтобы его экземпляры могли быть объектами слабых ссылок, то '__weakref__' необходимо явно включить в список имен атрибутов в __slots__. Теперь посмотрим, какое влияние оказывает атрибут __slots__ на класс Vector2d. Простое измерение экономии, достигаемой за счет __slot__ В примере 11.16 показана реализация __slots__ в классе Vector2d. Пример 11.16. vector2d_v3_slots.py: по сравнению с версией Vector2d добавился только атрибут __slots__ class Vector2d: __match_args__ = ('x', 'y')  __slots__ = ('__x', '__y')  typecode = 'd' # методы такие же, как в предыдущей версии  В __match_args__ перечислены открытые атрибуты для позиционного сопо- ставления с образцом.372  Объект в духе Python\n--- Страница 372 ---\n Напротив, в __slots__ перечислены имена атрибутов экземпляра, которые в данном случае являются закрытыми. Чтобы измерить экономию памяти, я написал скрипт mem_test.py. Он при- нимает имя модуля, содержащего вариант класса Vector2d, и с помощью списко- вого включения строит список с 10 000 000 экземпляров Vector2d. При первом прогоне (пример 11.17) я взял класс vector2d_v3.Vector2d (из примера 11.7), а при втором – версию класса с атрибутом __slots__ из примера 11.16. Пример 11.17. mem_test.py создает 10 миллионов экземпляров класса Vector2d из ука- занного при запуске модуля $ time python3 mem_test.py vector2d_v3 Selected Vector2d type: vector2d_v3.Vector2d Creating 10,000,000 Vector2d instances Initial RAM usage: 6,983,680 Final RAM usage: 1,666,535,424 real 0m11.990s user 0m10.861s sys 0m0.978s $ time python3 mem_test.py vector2d_v3_slots Selected Vector2d type: vector2d_v3_slots.Vector2d Creating 10,000,000 Vector2d instances Initial RAM usage: 6,995,968 Final RAM usage: 577,839,104 real 0m8.381s user 0m8.006s sys 0m0.352s Как видно из примера 11.17, потребление памяти составляет 1,55 ГиБ при ис- пользовании в каждом из 10 миллионов экземпляров Vector2d словаря __dict__, но снижается до 551 МиБ, если используется атрибут __slots__. К тому же версия с __slots__ еще и быстрее. Скрипт mem_test.py просто загружает модуль, измеряет потребление памяти и красиво выводит результаты. Его код можно найти по адре- су https://github.com/fluentpython/example-code-2e/blob/master/11-pythonic-obj/mem_test.py. При работе с миллионами объектов, содержащих числовые дан- ные, следует использовать массивы NumPy (см. раздел «NumPy» главы 2), которые не только эффективно расходуют память, но и располагают оптимизированными функциями, в том числе применяемыми к массиву в целом. Я проектировал класс Vector2d только для того, чтобы было на чем обсуждать специальные ме- тоды, т. к. стараюсь по возможности избегать бессмысленных примеров с foo и bar. Проблемы при использовании __slots__ Атрибут __slots__ при правильном использовании может дать значительную экономию памяти, но есть несколько подводных камней. Не забывайте заново объявлять __slots__ в каждом подклассе, потому что унаследованный атрибут интерпретатор игнорирует. Экономия памяти с помощью атрибута класса __slots__  373\n--- Страница 373 ---\nЭкземпляры класса могут иметь только атрибуты, явно перечисленные в __slots__, если в него не включено также имя '__dict__' (однако при этом вся экономия памяти может быть сведена на нет). Для классов, где используется __slots__, нельзя употреблять декоратор @cached_property , если только в __slots__ явно не включено имя '__dict__' . Экземпляры класса не могут быть объектами слабых ссылок, если не включить в __slots__ имя '__weakref__' . Последняя тема этой главы – переопределение атрибутов класса в экзем- плярах и подклассах. переОпределение атриБут Ов клаССа Отличительной особенностью Python является использование атрибутов клас - са в качестве значений по умолчанию для атрибутов экземпляра. В классе Vector2d имеется атрибут класса typecode. Он дважды используется в методе __ bytes__, но там мы осознанно писали self.typecode . Поскольку экземпляры класса Vector2d создаются без собственного атрибута typecode, значение self.typecode по умолчанию берется из атрибута класса Vector2d.typecode . Но если мы упоминаем в коде имя несуществующего атрибута, то создается новый атрибут экземпляра, например typecode, а одноименный атрибут класса остается без изменения. Однако начиная с этого момента всякий раз, как код, работающий с этим экземпляром, видит self.typecode , читается атрибут typecode экземпляра, т. е. атрибут класса с тем же именем маскируется. Это открывает возможность настроить отдельный экземпляр, изменив в нем typecode. По умолчанию Vector2d.typecode равен 'd', т. е. при экспорте в тип bytes каждая компонента вектора представляется 8-байтовым числом с плавающей точкой двойной точности. Если же перед экспортом присвоить атрибуту typecode кон- кретного экземпляра Vector2d значение 'f', то каждая компонента будет экс- портироваться в виде 4-байтового числа с плавающей точкой одинарной точ- ности. См. пример 11.18. Поскольку мы обсуждаем динамическое добавление атрибута, то в примере 11.18 используется реализация Vector2d без __slots__, показанная в примере 11.11. Пример 11.18. Настройка экземпляра путем установки атрибута typecode, первоначаль- но унаследованного от класса >>> from vector2d_v3 import Vector2d >>> v1 = Vector2d(1.1, 2.2) >>> dumpd = bytes(v1) >>> dumpd b'd\\x9a\\x99\\x99\\x99\\x99\\x99\\xf1?\\x9a\\x99\\x99\\x99\\x99\\x99\\x01@' >>> len(dumpd)  17 >>> v1.typecode = 'f'  >>> dumpf = bytes(v1) >>> dumpf 374  Объект в духе Python\n--- Страница 374 ---\nb'f\\xcd\\xcc\\x8c?\\xcd\\xcc\\x0c@' >>> len(dumpf)  9 >>> Vector2d.typecode  'd'  Подразумеваемое по умолчанию представление bytes имеет длину 17 байт.  Присвоить typecode значение 'f' в экземпляре v1.  Теперь длина представления в виде bytes составляет 9 байт.  Vector2d.typecode не изменился; атрибут typecode равен 'f' только в экземпляре v1. Теперь должно быть понятно, почему при экспорте объекта Vector2d в фор- мате bytes результирующее представление начинается с typecode: мы хотели поддержать различные форматы экспорта. Если вы хотите изменить сам атрибут класса, то должны присвоить ему зна- чение напрямую, а не через экземпляр. Чтобы изменить значение typecode по умолчанию, распространяющееся на все экземпляры (не имеющие собствен- ного атрибута typecode), нужно написать: >>> Vector2d.typecode = 'f' Однако существует идиоматический способ добиться более постоянного эффекта и явно выразить смысл изменения. Поскольку атрибуты класса от- крыты и наследуются подклассами, то принято настраивать атрибут класса в подклассе. В основанных на классах представлениях Django эта техника применяется сплошь и рядом. Она демонстрируется в примере 11.19. Пример 11.19. ShortVector2d – подкласс Vector2d, единственное отличие которого – пере- определение атрибута typecode по умолчанию >>> from vector2d_v3 import Vector2d >>> class ShortVector2d(Vector2d):  typecode = 'f' >>> sv = ShortVector2d(1/11, 1/27)  >>> sv ShortVector2d(0.09090909090909091, 0.037037037037037035)  >>> len(bytes(sv))  9  Создать ShortVector2d как подкласс Vector2d только для того, чтобы переопре- делить атрибут класса typecode.  Создать экземпляр ShortVector2d – объект sv.  Инспектировать представление sv.  Проверить, что экспортировано 9 байт, а не 17, как раньше. Этот пример также объясняет, почему я не стал «зашивать» значение class_ name в код Vecto2d.__repr__ , а получаю его в виде type(self).__name__ : # в классе Vector2d: def __repr__(self): class_name = type(self).__name__ return '{}({!r}, {!r})'.format(class_name, *self) Переопределение атрибутов класса  375\n--- Страница 375 ---\nЕсли бы я зашил class_name , то подклассы Vector2d и, в частности, ShortVector2d должны были бы переопределять метод __repr__ только для того, чтобы изме- нить class_name . А, получая имя от функции type, примененной к экземпляру, я сделал __repr__ безопасным относительно наследования. На этом завершается рассмотрение реализации простого класса, который ведет себя, как положено в Python, пользуясь средствами, предоставляемыми моделью данных: предлагает различные представления объекта, реализует специализированный код форматирования, раскрывает атрибуты, доступные только для чтения, и поддерживает метод hash() для интеграции со множества- ми и отображениями. резюме Целью этой главы была демонстрация специальных методов и соглашений в процессе разработки класса Python, который ведет себя ожидаемо. Можно ли сказать, что реализация в файле vector2d_v3.py (пример 11.11) лучше соответствует духу Python, чем та, что находится в файле vector2d_v0.py (пример 11.2)? Конечно, в классе Vector2d из файла vector2d_v3.py задействовано больше механизмов Python. Но какую версию считать более идиоматичной, зависит от контекста использования. В «Дзен Python» Тима Питера сказано: Простое лучше, чем сложное. Объект должен быть настолько простым, насколько возможно при соблюде- нии требований, – а не выставкой языковых средств. Если код является частью приложения, то следует поставить во главу угла то, что необходимо для под- держки конечных пользователей, – и не больше. Если код входит в библиотеку, предназначенную другим программистам, то будет разумно реализовать спе- циальные методы, поддерживающие виды поведения, ожидаемые питониста- ми. Например, метод __eq__, возможно, не нужен с точки зрения бизнес-требо- ваний, но его наличие облегчает тестирование класса. Развивая код Vector2d, я ставил себе целью предложить контекст для обсуж - дения специальных методов и соглашений о кодировании. В примерах из этой главы продемонстрировано несколько специальных методов, с которыми мы впервые встретились в табл. 1.1: методы строкового и байтового представления: __repr__, __str__, __format__ и __bytes__ ; методы преобразования объекта в число: __abs__, __bool__, __hash__ ; оператор __eq__ для тестирования преобразования в bytes и поддержки хеширования (наряду с методом __hash__). Обеспечивая поддержку преобразования в bytes, мы заодно реализовали альтернативный конструктор Vector2d.frombytes() и попутно получили пред- лог для обсуждения декораторов @classmethod (очень полезного) и @staticmethod (не столь полезного, поскольку функции уровня модуля проще). Идея метода frombytes позаимствована у его тезки из класса array.array . Мы видели, что мини-язык спецификации формата (https://docs.python.org/3/ library/string.html#formatspec) можно расширить путем реализации метода __ format__, который осуществляет несложный разбор строки format_spec , передавае-376  Объект в духе Python\n--- Страница 376 ---\nмой встроенной функции format(obj, format_spec) или включенной в поле подста- новки '{:«format_spec»} ' в f-строках или строках, используемых в методе str.format. Прежде чем сделать экземпляры класса Vector2d хешируемыми, мы постара- лись обеспечить их неизменяемость или, по крайней мере, предотвратить слу- чайное изменение. Для этого мы сделали атрибуты x и y закрытыми и предо- ставили к ним доступ через свойства, доступные только для чтения. Затем реа- лизовали метод __hash__, применяя рекомендуемую технику: объединить хеши атрибутов экземпляра с помощью оператора ИСКЛЮЧАЮЩЕЕ ИЛИ. Далее мы обсудили экономию памяти, достигаемую с помощью атрибута __slots__ в классе Vector2d, и опасности, подстерегающие на этом пути. Поскольку с использованием __slots__ сопряжены некоторые сложности, делать это имеет смысл только при работе с очень большим количеством экземпляров – поряд- ка миллионов, а не тысяч. В таких случаях часто лучше прибегнуть к библиоте- ке pandas (https://pandas.pydata.org/). И напоследок мы обсудили вопрос о переопределении атрибута класса при доступе через экземпляры (например, self.typecode ). Для этого мы сначала соз- дали атрибут конкретного экземпляра, а затем породили подкласс и пере- определили в нем атрибут на уровне класса. В этой главе я не раз отмечал, что проектные решения, принимаемые при раз- работке примеров, были основаны на изучении API стандартных объектов Python. Если бы меня попросили свести содержание главы к одной фразе, я бы сказал: Создавая объекты в духе Python, наблюдайте за поведением настоящих объектов Python. – Старинная китайская пословица дОпО лнительная литература В этой главе рассмотрено несколько специальных методов модели данных, по- этому естественно, что ссылки в основном те же, что в главе 1, где был дан общий обзор той же темы. Для удобства я повторю несколько предыдущих ре- комендаций и добавлю ряд новых: Глава «Модель данных» справочного руководства по языку Python (https://docs. python.org/3/reference/datamodel.html) Большинство использованных в этой главе методов документирова- ны в разделе 3.3.1 «Простая настройка» (https://docs.python.org/3/reference/ datamodel.html#basic-customization). Alex Martelli, Anna Ravenscroft, Steve Holden «Python in a Nutshell», 3-е издание (O’Reilly) Глубоко рассмотрены специальные методы. David Beazley, Brian K. Jones «Python Cookbook», 3-е издание В многочисленных рецептах демонстрируются современные подходы к кодированию. Особый интерес представляет глава 8 «Классы и объек - ты», в которой приведено несколько решений, относящихся к тематике этой главы. Дополнительная литература  377\n--- Страница 377 ---\nDavid Beazley «Python Essential Reference», 4-е издание Подробно рассматривается модель данных, правда, только в контексте Python 2.6 и Python 3.0 (в четвертом издании). Фундаментальные концепции те же самые, а большинство API модели данных не изменилось со времен Python 2.2, когда были унифицированы встроенные типы и пользователь- ские классы. В 2015 году, когда я закончил работу над первым изданием этой книги, Хи- нек Шлавак (Hynek Schlawack) приступил к разработке пакета attrs. Приведу цитату из документации по attrs: attrs – Python-пакет, который вернет радость от написания классов, освободив вас от рутины реализации объектных протоколов (они же dunder-методы). Я упоминал attrs как более мощную альтернативу @dataclass в разделе «До- полнительная литература» главы 5. Построители классов данных, описанные в главе 5, равно как и пакет attrs, автоматически наделяют ваши классы не- сколькими специальными методами. Но умение кодировать эти специальные методы самостоятельно все равно полезно, поскольку позволяет понять, как эти пакеты работают, решить, действительно ли они вам нужны, и – при не- обходимости – переопределить сгенерированные ими методы. В этой главе мы рассмотрели все специальные методы, относящиеся к пред- ставлению объектов, кроме __index__ и __fspath__ . Метод __index__ мы обсудим в разделе «Метод __getitem__ с учетом срезов» главы 12. О методе __fspath__ я го - ворить не буду. Интересующиеся могут прочитать о нем в документе PEP 519 «Adding a file system path protocol» (https://peps.python.org/pep-0519/). Впервые необходимость различных строковых представлений объекта была осознана в языке Smalltalk. В статье 1996 года «How to Display an Object as a String: printString and displayString» (http://esug.org/data/HistoricalDocuments/ TheSmalltalkReport/ST07/04wo.pdf) Бобби Вулф обсуждает реализацию методов printString и displayString в этом языке. Из этой статьи я позаимствовал выраже- ния «в виде, удобном для разработчика» и «в виде, удобном для пользователя» для описания методов repr() и str() в разделе «Представления объекта» выше. Поговорим Свойства позволяют снизить начальные затраты В первых версиях класса Vector2d атрибуты x и y были открытыми, как и все атрибуты класса и экземпляра по умолчанию. Естественно, пользователям вектора необходим доступ к его компонентам. И хотя наши векторы являют - ся итерируемыми объектами и могут быть распакованы в пару переменных, желательно также иметь возможность писать my_vector.x и my_vector.y для пря- мого доступа к компонентам по отдельности. Осознав необходимость воспрепятствовать случайному изменению атрибу - тов x и y, мы реализовали свойства, но больше нигде – ни в коде, ни в откры- том интерфейсе класса Vector2d – менять ничего не пришлось, что доказывают тесты. Мы по-прежнему можем обращаться к компонентам с помощью нота- ции my_vector.x и my_vector.y .378  Объект в духе Python\n--- Страница 378 ---\nЭто доказывает, что начинать разработку класса всегда надо с простейшего варианта, оставив атрибуты открытыми, а когда (и если) мы впоследствии захотим усилить контроль доступа с помощью методов чтения и установки, это можно будет сделать, реализовав свойства и ничего не меняя в уже на- писанном коде работы с компонентами объекта по именам (например, x и y), которые первоначально были просто открытыми атрибутами. Такой подход прямо противоположен пропагандируемому в Java: там про- граммист не может начать с простых атрибутов, а впоследствии, если пона- добится, перейти на свойства, потому что таковых в языке попросту не су - ществует. Поэтому написание методов чтения и установки считается нормой в Java – даже если эти методы не делают ничего полезного, – так как при пере- ходе от открытых атрибутов к акцессорам весь ранее написанный код пере- станет работать. Кроме того, как пишут Мартелли, Равенскрофт и Холден в третьем издании книги «Python in a Nutshell», набирать всюду обращения к методам чтения и установки как-то тупо. Приходится писать: >>> my_object.set_foo(my_object.get_foo() + 1) вместо куда более краткого: >>> my_object.foo += 1 Уорд Каннингэм, изобретатель вики и основоположник экстремального про- граммирования, рекомендует задавать себе вопрос: «Как написать самый простой код, который будет это делать?» Идея в том, чтобы сосредоточить все внимание на цели1. Реализация акцессоров с самого начала только отвлекает от цели. В Python мы можем просто использовать открытые атрибуты, зная, что при необходимости сумеем в любой момент заменить их свойствами. Закрытые атрибуты – защита и безопасность Perl не одержим идеей навязать закрытость во что бы то ни стало. Он пред- почитает, чтобы вы не входили в дом, потому что вас туда не приглашали, а не потому, что там стоит пулемет. – Ларри Уолл, создатель Perl Во многих отношениях Python и Perl – полные противоположности, но в во- просе о закрытости объектов Ларри и Гвидо, похоже, едины. За годы преподавания Python многочисленным программистам на Java я по- нял, что многие чрезмерно уповают на гарантии закрытости, предоставля- емые Java. Но на самом деле модификаторы private и protected в Java защи- щают только от непреднамеренных случайностей. Защитить от злого умысла они могут, лишь если приложение развернуто с диспетчером безопасности (https://docs.oracle.com/javase/ tutorial/essential/environment/security.html), а такое редко встречается на практике, даже в корпоративной среде. Для доказательства этого положения я обычно привожу следующий класс Java. 1 См. «Simplest Thing that Could Possibly Work: A Conversation with Ward Cunningham, Part V» (http://www.artima.com/intv/simplest3.html). Дополнительная литература  379\n--- Страница 379 ---\nПример 11.20. Confidential.java: класс Java с закрытым полем secret public class Confidential { private String secret = \"\"; public Confidential(String text) { this.secret = text.toUpperCase(); } } Здесь я сохраняю текст в поле secret, предварительно преобразовав его в верх - ний регистр, чтобы значение этого поля гарантированно было записано за- главными буквами. Собственно демонстрация заключается в выполнении скрипта expose.py ин- терпретатором Jython. Этот скрипт применяет интроспекцию (в терминоло- гии Java – «отражение»), чтобы получить значение закрытого поля. Код по- казан в примере 11.21. Пример 11.21. expose.py: Jython-код для чтения содержимого закрытого поля другого класса #!/usr/bin/env jython # Примечание: Jython остается на уровне Python 2.7 по состоянию на конец 2020 года import Confidential message = Confidential('top secret text') secret_field = Confidential .getDeclaredField('secret') secret_field .setAccessible(True) # замок взломан! print 'message.secret =' , secret_field.get(message) Выполнив пример 11.21, получим: $ jython expose.py message.secret = TOP SECRET TEXT Строка 'TOP SECRET TEXT' прочитана из закрытого поля secret класса Confidential . Никакой черной магии тут нет: скрипт expose.py применяет API отражения Java, чтобы получить ссылку на закрытое поле с именем 'secret', а затем вы- зывает метод 'secret_field.setAccessible(True)' , чтобы сделать его доступным для чтения. Разумеется, то же самое можно сделать и в коде на Java (только придется написать в три раза больше строк, см. файл Expose.java в репозито- рии кода к этой книге по адресу https://github.com/fluentpython/example-code). Решающий вызов .setAccessible(True) завершится с ошибкой, только если скрипт Jython или главная программа Java (например, Expose.class ) работает под управлением диспетчера безопасности SecurityManager. Но на практике Java-приложения редко развертываются таким образом – за исключением Java-апплетов, если вам удастся найти поддерживающий их браузер. Мой вывод: в Java модификаторы контроля доступа тоже обеспечивают лишь защиту, но не безопасность, по крайней мере на практике. Поэтому расслабь- тесь и получайте удовольствие от могущества, которым наделяет вас Python. Но применяйте его ответственно.380  Объект в духе Python",
      "debug": {
        "start_page": 351,
        "end_page": 379
      }
    },
    {
      "name": "Глава 12. Специальные методы для последовательностей 381",
      "content": "--- Страница 380 --- (продолжение)\nГлава 12 Специальные методы для последовательностей Не проверяйте, утка ли это; проверяйте, что оно крякает, как утка, ходит, как утка, и т. д. и т. п. – в зависимости от того, какая часть поведения утки важна в ваших языковых игрищах (comp.lang.python, 26 июля 2000). – Алекс Мартелли В этой главе мы напишем класс Vector для представления многомерного век- тора – заметный шаг вперед по сравнению с классом двумерного вектора Vector2d из главы 11. Класс Vector будет вести себя как стандартная плоская не- изменяемая последовательность в Python. Ее элементами будут числа с пла- вающей точкой, и окончательная версия будет поддерживать следующие воз- можности: базовый протокол последовательности: методы __len__ и __getitem__ ; безопасное представление экземпляров со многими элементами; поддержка операции среза, в результате которой получается новый эк- земпляр Vector ; хеширование агрегата с учетом значений всех содержащихся в нем эле- ментов; расширение языка форматирования. Мы также реализуем доступ к динамическим атрибутам с помощью метода __getattr__ – как замену доступных только для чтения свойств в классе Vector2d, – хотя для типов последовательностей такая функциональность нетипична. Демонстрация кода будет прерываться обсуждением самой идеи протоко- ла как неформального интерфейса. Мы поговорим о связи между протокола- ми и утиной типизацией, а также о ее практических следствиях для создания пользовательских типов. чтО нОвОг О в этОй главе Никаких существенных изменений в этой главе нет. В конец раздела «Прото- колы и утиная типизация» добавлен совет, содержащий краткое обсуждение класса typing.Protocol . В разделе «Метод __getitem__ с учетом срезов» реализация __getitem__ в при- мере 12.6 сделана более краткой и надежной, чем в первом издании, благодаря\nГлава 12 Специальные методы для последовательностей Не проверяйте, утка ли это; проверяйте, что оно крякает, как утка, ходит, как утка, и т. д. и т. п. – в зависимости от того, какая часть поведения утки важна в ваших языковых игрищах (comp.lang.python, 26 июля 2000). – Алекс Мартелли В этой главе мы напишем класс Vector для представления многомерного век- тора – заметный шаг вперед по сравнению с классом двумерного вектора Vector2d из главы 11. Класс Vector будет вести себя как стандартная плоская не- изменяемая последовательность в Python. Ее элементами будут числа с пла- вающей точкой, и окончательная версия будет поддерживать следующие воз- можности: базовый протокол последовательности: методы __len__ и __getitem__ ; безопасное представление экземпляров со многими элементами; поддержка операции среза, в результате которой получается новый эк- земпляр Vector ; хеширование агрегата с учетом значений всех содержащихся в нем эле- ментов; расширение языка форматирования. Мы также реализуем доступ к динамическим атрибутам с помощью метода __getattr__ – как замену доступных только для чтения свойств в классе Vector2d, – хотя для типов последовательностей такая функциональность нетипична. Демонстрация кода будет прерываться обсуждением самой идеи протоко- ла как неформального интерфейса. Мы поговорим о связи между протокола- ми и утиной типизацией, а также о ее практических следствиях для создания пользовательских типов. чтО нОвОг О в этОй главе Никаких существенных изменений в этой главе нет. В конец раздела «Прото- колы и утиная типизация» добавлен совет, содержащий краткое обсуждение класса typing.Protocol . В разделе «Метод __getitem__ с учетом срезов» реализация __getitem__ в при- мере 12.6 сделана более краткой и надежной, чем в первом издании, благодаря\n--- Страница 381 ---\nутиной типизации и методу operator.index . Это изменение внесено в последую- щие реализации класса Vector в данной главе и в главе 16. Итак, начнем. Vector : пОльзОватель Ский тип пОСледОвательнОС ти При реализации класса Vector мы будем пользоваться не наследованием, а ком - позицией. Компоненты вектора будут храниться в массиве array чисел с плава- ющей точкой, и мы напишем методы, необходимые для того, чтобы Vector вел себя как неизменяемая плоская последовательность. Но перед тем как приступать к методам последовательностей, разработа- ем базовую реализацию класса Vector, которая будет совместима с написанным ранее классом Vector2d – за исключением случаев, где говорить о совместимо- сти не имеет смысла. Где применяются векторы размерности выше 3 Кому нужен вектор с 1000 измерений? Подсказка: не 3D-дизайнерам! Тем не менее n-мерные векторы (с большим значением n) широко используются в информационном поиске, где документы и тексты запросов представляют - ся в виде векторов, по одному измерению на каждое слово. Это называется векторной моделью (http://en.wikipedia.org/wiki/Vector_space_model). В векторной модели в качестве основной меры релевантности используется коэффици- ент Отиаи (косинус угла между вектором запроса и вектором документа). При уменьшении угла его косинус стремится к максимальному значению 1, а вмес те с ним и релевантность документа запросу. Однако в этой главе класс Vector приведен только в педагогических целях, так что математики почти не будет. У нас более узкая задача – продемонстриро- вать специальные методы Python в контексте последовательностей. Для выполнения серьезных математических операций над векторами по- надобятся библиотеки NumPy и SciPy. В пакете gemsim (https://pypi.python.org/ pypi/gensim) Радима Рехурека реализована векторная модель для обработки естественных языков и информационного поиска с использованием NumPy и SciPy. Vector , пОпытка № 1: СОвмеС тимОС ть С Vector 2d Первая версия Vector должна быть по возможности совместима с классом Vector2d. Однако же конструктор Vector мы не станем делать совместимым. Можно было бы добиться работоспособности выражений Vector(3, 4) и Vector(3, 4, 5) , разрешив задавать произвольное число аргументов с помощью конструкции *args в методе __init__, но обычно конструктор последовательности принимает данные в виде итерируемого объекта – как все встроенные типы последова- тельностей. В примере 12.1 показано несколько способов создания объектов класса Vector.382  Специальные методы для последовательностей\n--- Страница 382 ---\nПример 12.1. Тесты методов Vector.__init__ и Vector.__repr__ Vector([3.1, 4.2]) >>> Vector((3, 4, 5)) Vector([3.0, 4.0, 5.0]) >>> Vector(range(10)) Vector([0.0, 1.0, 2.0, 3.0, 4.0, ]) Помимо сигнатуры конструктора, я включил тесты, которые проходили для Vector2d (например, Vector2d(3, 4) ). Они должны проходить и для Vector и давать такие же результаты. Если у вектора больше шести компонент, то вместо окончания строки, порожденной методом repr(), выводится , как в по- следней строчке примера 10.1. Это существенно для любого типа коллекции, в котором может быть много элементов, потому что repr применяется для отладки (и вряд ли вам понравится, когда один объект занимает тысячи строк на консоли или в журнале). Для создания укороченных представлений используйте модуль reprlib, как в примере 12.2. В версии Python 2.7 модуль reprlib назывался repr. В примере 12.2 приведена реализация первой версии класса Vector (она ос- нована на коде из примеров 11.2 и 11.3). Пример 12.2. vector_v1.py: основана на vector2d_v1.py from array import array import reprlib import math class Vector: typecode = 'd' def __init__(self, components): self._components = array(self.typecode, components)  def __iter__(self): return iter(self._components)  def __repr__(self): components = reprlib.repr(self._components)  components = components[components.find('['):-1]  return f'Vector({components})' def __str__(self): return str(tuple(self)) def __bytes__(self): return (bytes([ord(self.typecode)]) + bytes(self._components))  def __eq__(self, other): return tuple(self) == tuple(other) def __abs__(self): Vector, попытка № 1: совместимость с Vector2d  383\n--- Страница 383 ---\nreturn math.hypot(*self)  def __bool__(self): return bool(abs(self)) @classmethod def frombytes(cls, octets): typecode = chr(octets[0]) memv = memoryview(octets[1:]).cast(typecode) return cls(memv)   В «защищенном» атрибуте экземпляра self._components хранится массив array компонента Vector.  Чтобы было возможно итерирование, возвращаем итератор, построенный по self._components1.  Использовать reprlib.repr() для получения представления self._components ограниченной длины (например, array('d', [0.0, 1.0, 2.0, 3.0, 4.0, ]) ).  Удалить префикс array('d' и закрывающую скобку ), перед тем как подста- вить строку в вызов конструктора Vector.  Построить объект bytes из self._components .  Начиная с версии Python 3.8 метод math.hypot принимает N-мерные точки. Раньше я пользовался следующим выражением: math.sqrt(sum(x * x for x in self)).  Единственное отличие от написанного ранее метода frombytes – последняя строка: мы передаем объект memoryview напрямую конструктору, не распако- вывая его с помощью *, как раньше. То, как я использовал функцию reprlib.repr , заслуживает пояснения. Эта функция порождает безопасное представление длинной или рекурсивной структуры путем ограничения длины выходной строки с заменой отброшен- ного окончания многоточием ' '. Я хотел, чтобы repr-представление Vector имело вид Vector([3.0, 4.0, 5.0]) , а не Vector(array('d', [3.0, 4.0, 5.0])) , потому что присутствие array внутри Vector – деталь реализации. Поскольку оба вызова конструктора возвращают одинаковые объекты Vector, я предпочел более прос- той синтаксис с использованием аргумента типа list. При написании метода __repr__ я мог бы вывести упрощенное отображение components с помощью такого выражения: reprlib.repr(list(self._components)) . Но это было бы расточительно, поскольку пришлось бы копировать каждый элемент self._components в list только для того, чтобы использовать list repr. Вместо этого я решил применить reprlib.repr непосредственно к массиву self._components , а за - тем отбросить все символы, оказавшиеся вне квадратных скобок []. Для этого и предназначена вторая строка метода __repr__ в примере 12.2. Поскольку метод repr() вызывается во время отладки, он никог - да не должен возбуждать исключение. Если в __repr__ происхо- дит какая-то ошибка, вы должны обработать ее сами и сделать все возможное, чтобы показать пользователю нечто разумное, позволяющее идентифицировать получателя ( self). 1 Функция iter() рассматривается в главе 17 наряду с методом __ iter__. 384  Специальные методы для последовательностей\n--- Страница 384 ---\nОтметим, что методы __str__, __eq__ и __bool__ остались такими же, как в клас - се Vector2d, а в методе frombytes изменился только один символ (удален символ * в последней строке). Это воздаяние за то, что класс Vector2d изначально был сделан итерируемым. Кстати, я мог бы сделать Vector подклассом Vector2d, но не стал по двум при- чинам. Во-первых, при наличии несовместимых конструкторов создавать подклассы не рекомендуется. Эту трудность можно было бы обойти за счет хитроумной обработки параметров в __init__, но есть и вторая, более важная причина: я хочу, чтобы Vector был не зависящим от других классов примером реализации протокола последовательности. Этим мы и займемся далее, пред- варительно обсудив сам термин протокол. прОтОкОлы и утиная типизация Еще в главе 1 мы видели, что для создания полнофункционального типа после- довательности в Python необязательно наследовать какому-то специальному классу; нужно лишь реализовать методы, удовлетворяющие протоколу после- довательности. Но что это за протокол такой? В объектно-ориентированном программировании протоколом называ- ется неформальный интерфейс, определенный только в документации, но не в коде. Например, протокол последовательности в Python подразумевает только наличие методов __len__ и __getitem__ . Любой класс Spam, в котором есть такие методы со стандартной сигнатурой и семантикой, можно использовать всюду, где ожидается последовательность. Является Spam подклассом какого-то другого класса или нет, роли не играет. Мы видели это в примере 1.1, который воспроизведен ниже. Пример 12.3. Код из примера 1.1, воспроизведенный здесь для удобства import collections Card = collections.namedtuple('Card', ['rank', 'suit']) class FrenchDeck: ranks = [str(n) for n in range(2, 11)] + list('JQKA') suits = 'spades diamonds clubs hearts'.split() def __init__(self): self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks] def __len__(self): return len(self._cards) def __getitem__(self, position): return self ._cards[position] В классе FrenchDeck из примера 12.3 применяются разнообразные средства Python, потому что он реализует протокол последовательности, хотя нигде в коде об этом явно не сказано. Любому опытному программисту на Python достаточно одного взгляда на код, что понять, что это именно класс последо- Протоколы и утиная типизация  385\n--- Страница 385 ---\nвательности, несмотря на то что он является подклассом object. Мы говорим, что он является последовательностью, потому что ведет себя как последова- тельность, а только это и важно. Такой подход получил название «утиная типизация», и именно о нем идет речь в высказывании Алекса Мартелли, взятом в качестве эпиграфа к этой главе. Поскольку протокол – неформальное понятие, которое не подкреплено средствами языка, мы зачастую можем реализовать лишь часть протокола, если точно знаем, в каком контексте будет использоваться класс. Например, для поддержки итерирования нужен только метод __getitem__ , а без метода __ len__ можно обойтись. Следуя документу PEP 544 «Protocols: Structural subtyping (static duck typing)» (https://peps.python.org/pep-0544/), Python 3.8 поддер- живает классы протоколов: конструкции из модуля typing, кото - рые мы изучали в разделе «Статические протоколы» главы 8. Это новое употребление слова «протокол» в Python имеет родствен- ную, но все же отличающуюся семантику. В тех случаях, когда их необходимо различать, я буду писать статический протокол, имея в виду протоколы, формализованные классами протоко- лов, и динамический протокол, имея в виду традиционное по- нятие. Ключевое различие заключается в том, что реализации статических протоколов должны предоставлять все методы, определенные в классе протокола. Дополнительные сведения см. в разделе «Два вида протоколов» главы 13. Далее мы реализуем протокол последовательности в классе Vector, поначалу без надлежащей поддержки операции среза, но позже добавим и ее. Vector , пОпытка № 2: пОСледОвательнОС ть, дОпуСкающая Срез В примере класса FrenchDeck мы видели, что поддержать протокол последова- тельности очень просто, если можно делегировать работу атрибуту объекта, который является последовательностью, в нашем случае таким атрибутом бу- дет массив self._components . Для начала нас вполне устроят такие однострочные методы __len__ и __getitem__ : class Vector: # много строк опущено # def __len__(self): return len(self._components) def __getitem__(self, index): return self._components[index] После этих добавлений все показанные ниже операции работают: >>> v1 = Vector([3, 4, 5]) >>> len(v1) 3 386  Специальные методы для последовательностей\n--- Страница 386 ---\n>>> v1[0], v1[-1] (3.0, 5.0) >>> v7 = Vector(range(7)) >>> v7[1:4] array('d', [1.0, 2.0, 3.0]) Как видите, даже срезы поддерживаются – но не очень хорошо. Было бы луч- ше, если бы срез вектора также был экземпляром класса Vector, а не массивом. В старом классе FrenchDeck была такая же проблема: срез оказывался объектом класса list. Но в случае Vector мы утрачиваем значительную часть функцио- нальности, если операция среза возвращает простой массив. Рассмотрим встроенные типы последовательностей: для каждого из них операция среза порождает объект того же, а не какого-то другого типа. Если мы хотим, чтобы срезы Vector тоже были объектами класса Vector, то не долж - ны делегировать получение среза классу array. В методе __getitem__ мы должны про- анализировать полученные аргументы и выполнить подходящее действие. Теперь посмотрим, как Python преобразует конструкцию my_seq[1:3] в аргу - менты вызова my_seq.__getitem__( ) . Как работает срезка Код заменяет тысячу слов, поэтому обратимся к примеру 12.4. Пример 12.4. Изучение поведения __getitem__ и срезов def __getitem__(self, index): return index  >>> s = MySeq() >>> s[1]  1 >>> s[1:4]  slice(1, 4, None) >>> s[1:4:2]  slice(1, 4, 2) >>> s[1:4:2, 9]  (slice(1, 4, 2), 9) >>> s[1:4:2, 7:9]  (slice(1, 4, 2), slice(7,9,None))  Здесь __getitem__ просто возвращает то, что ему передали.  Один индекс, ничего нового.  Нотация 1:4 преобразуется в slice(1, 4, None) .  slice(1, 4, 2) означает: начать с 1, закончить на 4, с шагом 2.  Сюрприз: при наличии запятых внутри [] метод __getitem получает кортеж.  Этот кортеж может даже содержать несколько объектов среза. Теперь приглядимся внимательнее к самому классу slice. Пример 12.5. Инспекция атрибутов класса slice >>> slice  <class 'slice'> >>> dir(slice)  Vector, попытка № 2: последовательность, допускающая срез  387\n--- Страница 387 ---\n['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'indices', 'start', 'step', 'stop']  slice – встроенный тип (мы это уже поняли в разделе «Объекты среза» гла- вы 2).  Инспекция slice показывает наличие атрибутов start, stop и step, а также метода indices. В примере 12.5 вызов dir(slice) показывает наличие метода indices – весьма интересного, хотя и малоизвестного. Вот что говорит о нем справка – help(slice. indices): S.indices(len) -> (start, stop, stride) В предположении, что длина последовательности равна len, вычисляет индексы start и stop, а также длину stride расширенного среза, представленного объектом S. Индексы, выходящие за границы, приводятся к границам так же, как при обработке обычных срезов. Иначе говоря, метод indices раскрывает нетривиальную логику, применяе- мую во встроенных последовательностях для корректной обработки отсут - ствующих или отрицательных индексов и срезов, длина которых превышает длину конечной последовательности. Этот метод возвращает «нормализован- ные» кортежи, содержащие неотрицательные целые числа start, stop и stride, скорректированные так, чтобы не выходить за границы последовательности заданной длины. Ниже приведено два примера для последовательности длины 5, например 'ABCDE': >>> slice(None, 10, 2).indices(5)  (0, 5, 2) >>> slice(-3, None, None).indices(5)  (2, 5, 1)  'ABCDE'[:10:2] – то же самое, что 'ABCDE'[0:5:2] .  'ABCDE'[-3] – то же самое, что 'ABCDE'[2:5:1] . В классе Vector нам не нужен метод slice.indices() , потому что, получив в аргу - менте срез, мы делегируем его обработку массиву _components . Но если опереться на средства, предоставляемые внутренней последовательностью, не получает - ся, то этот метод может сэкономить уйму времени. Теперь, разобравшись, как обрабатывать срезы, рассмотрим улучшенную реализацию метода Vector.__getitem__ . Метод __getitem__ с учетом срезов В примере 12.6 приведено два метода, необходимых для того, чтобы класс Vector вел себя как последовательность: __len__ и __getitem__ (последний теперь правильно обрабатывает срезы).388  Специальные методы для последовательностей\n--- Страница 388 ---\nПример 12.6. Часть файла vector_v2.py: в класс Vector из файла vector_v1.py (при- мер 12.2) добавлены методы __len__ и __getitem__ : def __len__(self): return len(self._components) def __getitem__(self, key): if isinstance(key, slice):  cls = type(self)  return cls(self._components[key])  index = operator.index(key)  return self._components[index]   Если аргумент key принадлежит типу slice…  … то получить класс экземпляра (т. е. Vector) и …  … вызвать класс для построения нового экземпляра Vector по срезу массива _components .  Если можно получить index по key…  … то просто вернуть один конкретный элемент из _components . Функция operator.index() вызывает специальный метод __index__. И функция, и специальный метод определены в документе PEP 357 «Allowing Any Object to be Used for Slicing» (https://peps.python.org/pep-0357/), в котором Трэвис Олифант предложил разрешить использование в качестве индексов и срезов любого из многочисленных типов целых в NumPy. Основное различие между operator. index() и int() заключается в том, что первый предназначен для этой конкрет - ной цели. Например, int(3.14) возвращает 3, а operator.index(3.14) возбуждает ис- ключение TypeError, потому что float не может использоваться в качестве индекса. Злоупотребление функцией isinstance иногда является призна- ком неудачного объектно-ориентированного проектирования, но применение ее для обработки срезов в __getitem__ оправдано. В первом издании я также применял функцию isinstance , что- бы проверить, является ли key целым числом. Использование operator.index позволяет обойтись без этой проверки и возбу - дить исключение TypeError с очень информативным сообщени- ем, если из key нельзя получить index. См. последнее сообщение об ошибке в примере 12.7. После добавления кода из примера 12.6 в класс Vector поведение операции среза исправилось, что доказывает пример 12.7. Пример 12.7. Тесты улучшенного метода Vector.__getitem__ из примера 12.6 >>> v7 = Vector(range(7)) >>> v7[-1]  6.0 >>> v7[1:4]  Vector([1.0, 2.0, 3.0]) >>> v7[-1:]  Vector([6.0]) >>> v7[1,2]  Traceback (most recent call last): TypeError: 'tuple' object cannot be interpreted as an integer Vector, попытка № 2: последовательность, допускающая срез  389\n--- Страница 389 ---\n Если индекс – целое число, то извлекается ровно одна компонента типа float.  Если задан индекс типа slice, то создается новый объект Vector.  Если длина среза len == 1, то все равно создается новый объект Vector.  Класс Vector не поддерживает многомерное индексирование, поэтому при задании кортежа индексов или срезов возбуждается исключение. Vector , пОпытка № 3: дОСтуп к динамичеСким атриБутам При переходе от класса Vector2d к Vector мы потеряли возможность обращаться к компонентам вектора по имени, например v.x, v.y. Теперь мы имеем дело с векторами, имеющими сколь угодно много компонент. Тем не менее иногда удобно обращаться к нескольким первым компонентам по именам, состоя- щим из одной буквы, например x, y, z вместо v[0], v[1] и v[2]. Ниже показан альтернативный синтаксис для чтения первых четырех ком- понент вектора, который мы хотели бы поддержать: >>> v = Vector(range(10)) >>> v.x 0.0 >>> v.y, v.z, v.t (1.0, 2.0, 3.0) В классе Vector2d мы предоставляли доступ для чтения компонент x и y с по- мощью декоратора @property (пример 11.7). Мы могли бы завести и в Vector че- тыре свойства, но это утомительно. Специальный метод __getattr__ позволяет сделать это по-другому и лучше. Метод __getattr__ вызывается интерпретатором, если поиск атрибута завер- шается неудачно. Иначе говоря, анализируя выражение my_obj.x, Python прове- ряет, есть ли у объекта my_obj атрибут с именем x; если нет, поиск повторяется в классе (my_obj.__class__ ), а затем вверх по иерархии наследования1. Если атрибут x все равно не найден, то вызывается метод __getattr__ , определенный в классе my_obj, причем ему передается self и имя атрибута в виде строки (например, 'x'). В примере 12.8 приведен код метода __getattr__ . Он проверяет, является ли искомый атрибут одной из букв xyzt, и если да, то возвращает соответствую- щую компоненту вектора. Пример 12.8. Часть файла vector_v3.py: в класс Vector из файла vector_v2.py добавлен метод __getattr__ __match_args__ = ('x', 'y', 'z', 't')  def __getattr__(self, name): cls = type(self)  try: pos = cls.__match_args__.index(name)  except ValueError:  pos = -1 1 На самом деле поиск атрибутов устроен сложнее. Технические детали мы обсудим в части V, а пока достаточно и этого упрощенного объяснения.390  Специальные методы для последовательностей\n--- Страница 390 ---\nif 0 <= pos < len(self._components):  return self._components[pos] msg = f'{cls.__name__!r} object has no attribute {name!r}'  raise AttributeError (msg)  Инициализировать __match_args__ , чтобы можно было применить сопостав- ление с образцом к динамическим атрибутам, поддерживаемым __getattr__1.  Получить класс Vector для последующего использования.  Попытаться получить позицию name в __match_args__ .  Вызов .index(name) возбуждает исключение ValueError , если name не найдено; положить pos равным –1 (я предпочел бы использовать здесь метод вроде str.find, но в классе tuple он не реализован).  Если pos не выходит за пределы кортежа, вернуть соответствующий элемент.  Если мы дошли до этого места, возбудить исключение AttributeError со стан- дартным сообщением об ошибке. Реализовать метод __getattr__ просто, но в данном случае недостаточно. Рас- смотрим странное взаимодействие в примере 12.9. Пример 12.9. Неправильное поведение: присваивание v.x не приводит к ошибке, но результат получается несогласованным >>> v = Vector(range(5)) >>> v Vector([0.0, 1.0, 2.0, 3.0, 4.0]) >>> v.x  0.0 >>> v.x = 10  >>> v.x  3 10 >>> v Vector([0.0, 1.0, 2.0, 3.0, 4.0])   Доступ к элементу v[0] по имени v.x.  Присвоить v.x новое значение. При этом должно бы возникнуть исключе- ние.  Чтение v.x показывает новое значение: 10.  Однако компоненты вектора не изменились. Сможете объяснить, что здесь происходит? И главное – почему чтение v.x возвращает 10, если это значение не хранится в массиве компонент? Если сходу не понятно, прочитайте еще раз, как работает метод __getattr__ (перед при- мером 12.8). Это тонкий момент, но от него зависит многое из того, с чем мы встретимся далее в этой книге. Поразмыслив над этой проблемой, можете читать дальше – мы объясним, что же случилось. 1 Хотя __match_args__ введен для поддержки сопоставления с образцами в Python 3.10, установка этого атрибута безвредна и в предшествующих версиях Python. В первом издании книги я назвал его shortcut_names . А новое имя позволяет сделать два дела сра- зу: поддержать позиционные образцы в ветвях case и хранить имена динамических атрибутов, поддерживаемые специальной логикой в методах __getattr__ и __setattr__ . Vector, попытка № 3: доступ к динамическим атрибутам  391\n--- Страница 391 ---\nНесогласованность в примере 12.9 возникла из-за способа работы __getattr__ : Python вызывает этот метод только в том случае, когда у объекта нет атрибута с указанным именем. Однако же после присваивания v.x = 10 у объекта v по- явился атрибут x, поэтому __getattr__ больше не вызывается для доступа к v.x: интерпретатор просто вернет значение 10, связанное с v.x. С другой стороны, в нашей реализации __getattr__ игнорируются все атрибуты экземпляра, кроме self._components , откуда читаются значения «виртуальных атрибутов», перечис - ленных в __match_args__ . Чтобы избежать рассогласования, мы должны изменить логику установки атрибутов в классе Vector. Напомним, что в последних вариантах класса Vector2d в главе 11 попытка присвоить значение атрибутам экземпляра .x или .y приводила к исключению AttributeError . В классе Vector мы хотим возбуждать такое же исключение при любой попытке присвоить значение атрибуту, имя которого состоит из одной строчной буквы, – просто во избежание недоразумений. Для этого реализуем метод __setattr__ , как показано в примере 12.10. Пример 12.10. Часть файла vector_v3.py: метод __setattr__ в классе Vector def __setattr__(self, name, value): cls = type(self) if len(name) == 1:  if name in cls.__match_args__:  error = 'readonly attribute {attr_name!r}' elif name.islower():  error = \"can't set attributes 'a' to 'z' in {cls_name!r}\" else: error = ''  if error:  msg = error.format(cls_name=cls.__name__, attr_name=name) raise AttributeError(msg) super().__setattr__(name,value)   Специальная обработка односимвольных имен атрибутов.  Если имя совпадает с одним из перечисленных в __match_args__ , задать один текст сообщения об ошибке.  Если имя – строчная буква, задать другой текст сообщения – обо всех одно- буквенных именах.  В противном случае оставить сообщение об ошибке пустым.  Если сообщение об ошибке не пусто, возбудить исключение.  Случай по умолчанию: вызвать метод __setattr__ суперкласса для получения стандартного поведения. Функция super() – быстрый способ обратиться к методам су- перкласса. Она необходима в динамических языках, поддер- живающих множественное наследование, к числу которых от- носится и Python. Используется для делегирования некоторого действия в подклассе подходящему методу суперкласса, как в примере 12.10. Мы еще вернемся к функции super в разделе «Множественное наследование и порядок разрешения мето- дов» главы 14. 392  Специальные методы для последовательностей\n--- Страница 392 ---\nРешая, какое сообщение об ошибке вернуть в исключении AttributeError , я преж- де всего сверился с поведением встроенного типа complex, поскольку он неизменя- емый и имеет два атрибута: real и imag. Попытка изменить любой из них приводит к исключению AttributeError с сообщением «can't set attribute» . С другой стороны, попытка изменить доступный только для чтения атрибут, который защищен, как в разделе «Хешируемый класс Vector2d» главы 11, кончается сообщением «readonly attribute». Выбирая значение строки error в методе __setattr__ , я руководствовался обоими образцами, но уточнил, какие именно атрибуты запрещены. Отметим, что мы не запрещаем установку всех вообще атрибутов, а только таких, имя которых состоит из одной строчной буквы, – чтобы избежать пута- ницы с доступными только для чтения атрибутами x, y, z и t. Мы знаем, что объявление атрибута __slots__ на уровне класса предотвращает создание новых атрибутов экземпляров, поэтому может возникнуть искушение воспользоваться этой возможно- стью и не реализовывать метод __setattr__ . Но из-за различных подводных камней, которые обсуждались в разделе «Проблемы при использовании __slots__» главы 11, не рекомендуется объявлять __slots__ только ради запрета создавать новые атрибуты экзем- пляра. Этот механизм предназначен исключительно для экономии памяти, да и то лишь в случае, когда с этим возникают проблемы. Но пусть мы и отказались от записи в компоненты Vector, все равно из этого примера можно вынести важный урок: часто вместе с методом __getattr__ при- ходится писать и метод __setattr__ , чтобы избежать несогласованного поведе- ния объекта. Если бы мы решили допустить изменение компонент, то могли бы реали- зовать метод __setitem__ , чтобы можно было писать v[0] = 1.1 , и (или) метод __ setattr__, чтобы работала конструкция v.x = 1.1. Но сам класс Vector должен оставаться неизменяемым, потому что в следующем разделе мы собираемся сделать его хешируемым. Vector , пОпытка № 4: хешир Ование и уСкОрение Операт Ора == И снова нам предстоит реализовать метод __hash__. В сочетании с уже имею- щимся методом __eq__ это сделает экземпляры класса Vector хешируемыми. Метод __hash__ в классе Vector2d (пример 11.8) вычислял хеш кортежа с двумя элементами: self.x и self.y. Теперь же элементов может быть тысячи, поэтому построение кортежа обошлось бы слишком дорого. Вместо этого я применю оператор ^ (ИСКЛЮЧАЮЩЕЕ ИЛИ) к хешам всех компонент, например v[0] ^ v[1] ^ v[2] . Тут нам на помощь придет функция functools.reduce . Выше я говорил, что функция reduce уже не так популярна, как в былые времена1, но для вычис - ления хеша всех компонент она подходит идеально. На рис. 12.1 представлена общая идея функции reduce. 1 Функции sum, any и all покрывают большинство типичных применений reduce. См. об- суждение в разделе «Современные замены map, filter и reduce» главы 7. Vector, попытка № 4: хеширование и ускорение оператора ==  393\n--- Страница 393 ---\nreduce Рис. 12.1. Редуцирующие функции – reduce , sum, any, all – порождают единственное значе- ние-агрегат из последовательности или произвольного конечного итерируемого объекта До сих пор мы видели, что функцию functools.reduce() можно заменить функ - цией sum(), а теперь объясним, как же она все-таки работает. Идея в том, чтобы редуцировать последовательность значений в единственное значение. Пер- вый аргумент reduce() – функция с двумя аргументами, а второй – итериру - емый объект. Допустим, что имеется функция с двумя аргументами fn и спи- сок lst. Если написать reduce(fn, lst) , то fn сначала применяется к первым двум элементам – fn(lst[0], lst[1]) , – и в результате получится первый результат r1. Затем fn применяется к r1 и следующему элементу – fn(r1, lst[2]) ; так мы полу - чаем второй результат r2. Потом вызов fn(r2, lst[3]) порождает r3 … и так далее до последнего элемента, после чего возвращается окончательный результат rN. Вот как можно было бы применить reduce для вычисления 5! (факториал 5): >>> 2 * 3 * 4 * 5 # ожидаемый результат: 5! == 120 120 >>> import functools >>> functools.reduce(lambda a,b: a*b, range(1, 6)) 120 Но вернемся к проблеме хеширования. В примере 12.11 показано, как мож - но было бы вычислить результат многократного применения ^ тремя способа- ми: один – с помощью цикла for и два – с помощью reduce. Пример 12.11. Три способа вычислить результат применения оператора ИСКЛЮЧАЮЩЕЕ ИЛИ к целым числам от 0 до 5 >>> n = 0 >>> for i in range(1, 6):  n ^= i >>> n 1 >>> import functools >>> functools.reduce(lambda a, b: a^b, range(6))  1 >>> import operator >>> functools.reduce(operator.xor, range(6))  1  Агрегирование в цикле for в накопительную переменную.  functools.reduce с анонимной функцией.  functools.reduce с заменой специально написанного лямбда-выражения функцией operator.xor .394  Специальные методы для последовательностей\n--- Страница 394 ---\nИз представленных вариантов мне больше всего нравится последний, а на втором месте стоит цикл for. А вам как кажется? В разделе «Модуль operator» главы 7 мы видели, что модуль operator пре- доставляет функциональность всех инфиксных операторов Python в форме функций, снижая потребность в лямбда-выражениях. Чтобы написать метод Vector.__hash__ в том стиле, который я предпочитаю, необходимо импортировать модули functools и operator. Изменения показаны в примере 12.12. Пример 12.12. Часть файла vector_v4.py: в класс Vector из файла vector_v3.py добавлены два предложения импорта и метод __hash__ from array import array import reprlib import math import functools  import operator  class Vector: typecode = 'd' # много строк опущено def __eq__(self, other):  return tuple(self) == tuple(other) def __hash__(self): hashes = (hash(x) for x in self._components)  return functools.reduce(operator.xor, hashes, 0)  # последующие строки опущены  Импортировать functools для использования reduce.  Импортировать operator для использования xor.  Метод __eq__ не изменился; я привел его только потому, что методы __eq__ и __hash__ принято располагать в исходном коде рядом, т. к. они дополняют друг друга.  Создать генераторное выражение для отложенного вычисления хеша каж- дой компоненты.  Подать выражение hashes на вход reduce вместе с функцией xor – для вычис - ления итогового хеш-значения; третий аргумент, равный 0, – инициализатор (см. предупреждение ниже). При использовании reduce рекомендуется задавать третий аргу - мент, reduce(function, iterable, initializer) , чтобы предотвра- тить появление исключения TypeError: reduce() of empty sequence with no initial value (отличное сообщение: описывается проб- лема и способ исправления). Значение initializer возвращает - ся, если последовательность пуста, а кроме того, используется в качестве первого аргумента в цикле редукции, поэтому оно должно быть нейтральным элементом относительно выполняе- мой операции. Так, для операций +, |, ^ initializer должен быть равен 0, а для *, & – 1. Vector, попытка № 4: хеширование и ускорение оператора ==  395\n--- Страница 395 ---\nМетод __hash__ в примере 11.12 – отличный пример техники map-reduce (рис. 12.2). reducemap Рис. 12.2. Map-reduce: применить функцию к каждому элементу для генерации новой по- следовательности (map), затем вычислить агрегат (reduce) На шаге отображения (map) порождается один хеш для каждого компонен- та, а на шаге редукции (reduce) все хеши агрегируются с помощью оператора xor. Если использовать функцию map вместо генераторного выражения, то шаг отображения станет даже более наглядным: def __hash__(self): hashes = map(hash, self._components) return functools.reduce(operator.xor, hashes) Решение на основе map не так эффективно в Python 2, где функция map строит список, содержащий результаты. Однако в Python 3 map откладывает вычисления: она порождает гене- ратор, который отдает результаты по требованию, экономя тем самым память, – точно так же, как генераторное выражение в методе __hash__ из примера 12.8. Раз уж мы заговорили о редуцирующих функциях, то почему бы не заме- нить нашу написанную на скорую руку реализацию оператора __eq__ другой, которая и работать будет быстрее, и памяти потреблять меньше, по крайней мере для больших векторов. В примере 11.2 приведена такая лаконичная реа- лизация __eq__: def __eq__(self, other): return tuple(self) == tuple(other) Она работает для Vector2d и для Vector – и даже считает, что Vector([1, 2]) ра- вен (1, 2); это может оказаться проблемой, однако пока закроем на нее глаза1. Но для векторов с тысячами компонент эта реализация крайне неэффектив- на. Она строит два кортежа, полностью копируя оба операнда, только для того, чтобы воспользоваться оператором __eq__ из типа tuple. Такая экономия уси- лий вполне оправдана для класса Vector2d (всего с двумя компонентами), но 1 К вопросу о разумности равенства Vector([1, 2]) == (1, 2) мы серьезно подойдем в разделе «Основы перегрузки операторов» главы 16. 396  Специальные методы для последовательностей\n--- Страница 396 ---\nне для многомерных векторов. Более эффективный способ сравнения объекта Vector с другим объектом Vector или с итерируемым объектом показан в при- мере 12.13. Пример 12.13. Метод Vector.eq , в котором используется функция zip в цикле for для более эффективного сравнения def __eq__(self, other): if len(self) != len(other):  return False for a, b in zip(self, other):  if a != b:  return False return True   Если длины объектов различны, то они не равны.  Функция zip порождает генератор кортежей, содержащих соответственные элементы каждого переданного ей итерируемого объекта. Если вы с ней незнакомы, см. врезку «Удивительная функция zip» ниже. Сравнение длин в предложении  необходимо, потому что zip без предупреждения пере- стает порождать значения, как только хотя бы один входной аргумент ока- зывается исчерпанным.  Как только встречаются две различные компоненты, выходим и возвраща- ем False.  В противном случае объекты равны. Свое название функция zip получила от застежки-молнии (zipper), принцип работы которой основан на зацеплении зу- бьев, расположенных с двух сторон, – наглядная аналогия того, что происходит при обращении к zip(left, right) . Никакого от- ношения к формату сжатия файлов это название не имеет. Код из примера 12.13 эффективен, но функция all может вычислить тот же агрегат, что и цикл for, всего в одной строчке: если все сравнения соответ - ственных компонент операндов возвращают True, то и результат равен True. Как только какое-нибудь сравнение возвращает False, так all сразу возвра- щает False. В примере 12.14 показано, как выглядит метод __eq__, в котором используется all. Пример 12.14. Оператор Vector.eq с использованием zip и all: логика та же, что в при- мере 12.13 def __eq__(self, other): return len(self) == len(other) and all(a == b for a, b in zip(self, other)) Отметим, что сначала проверяется равенство длин операндов, потому что zip остановится по исчерпании более короткого операнда. Реализацию из примера 12.14 мы включили в файл vector_v4.py. Vector, попытка № 4: хеширование и ускорение оператора ==  397\n--- Страница 397 ---\nУдивительная функция zip Наличие цикла for, в котором можно обойти элементы коллекции без воз- ни с индексной переменной, – отличное дело, и многие ошибки так можно предотвратить, только для этого нужны специальные служебные функции. Одна из них – встроенная функция zip, позволяющая параллельно обходить два и более итерируемых объекта: она возвращает кортежи, которые можно распаковать в переменные, – по одной для каждого входного объекта. См. пример 12.15. Пример 12.15. Встроенная функция zip за работой >>> zip(range(3), 'ABC')  <zip object at 0x10063ae48> >>> list(zip(range(3), 'ABC'))  [(0, 'A'), (1, 'B'), (2, 'C')] >>> list(zip(range(3), 'ABC', [0.0, 1.1, 2.2, 3.3]))  [(0, 'A', 0.0), (1, 'B', 1.1), (2, 'C', 2.2)] >>> from itertools import zip_longest  >>> list(zip_longest(range(3), 'ABC', [0.0, 1.1, 2.2, 3.3], fillvalue=-1)) [(0, 'A', 0.0), (1, 'B', 1.1), (2, 'C', 2.2), (-1, -1, 3.3)]  zip возвращает генератор, который порождает кортежи по запросу.  Здесь мы строим из генератора список list просто для отображения; обыч- но генератор обходят в цикле.  zip останавливается, не выдавая предупреждения, как только один из ите- рируемых объектов оказывается исчерпанным.  Функция itertools.zip_longest ведет себя иначе: она подставляет вместо от- сутствующих значений необязательный аргумент fillvalue (по умолчанию None), поэтому генерирует кортежи, пока не окажется исчерпанным самый длинный итерируемый объект. Новый параметр zip() в Python 3.10 В первом издании книги я писал, что поведение zip – остановка без предупреждения по исчерпании самого короткого итерируемого объекта – кажется мне неожиданным, а для API это не есть хорошо. Молчаливое игнорирование части входных данных может при- водить к тонким ошибкам. Вместо этого zip должна была бы воз- буждать исключение ValueError , если не все итерируемые объекты имеют одинаковую длину, что и имеет место при распаковке ите- рируемого объекта в кортеж переменных разной длины, – в полном соответствии с принципом быстрого отказа, принятым в Python. В документе PEP 618 «Add Optional Length-Checking To zip» (https:// peps.python.org/pep-0618/) предложено добавить в zip факультатив- ный аргумент strict, при наличии которого она ведет себя именно таким образом. Предложение реализовано в Python 3.10. Функцию zip можно также использовать для транспонирования матрицы, представленной в виде вложенных итерируемых объектов. Например: 398  Специальные методы для последовательностей\n--- Страница 398 ---\n>>> a = [(1, 2, 3), (4, 5, 6)] >>> list(zip(*a)) [(1, 4), (2, 5), (3, 6)] >>> b = [(1, 2), (3, 4), (5, 6)] >>> list(zip(*b)) [(1, 3, 5), (2, 4, 6)] Если вы хотите до конца разобраться, как работает zip, потратьте некоторое время на анализ этих примеров. Встроенная функция enumerate – еще одна генераторная функция, которую часто используют в циклах for, чтобы избежать явной работы с индексными перемен- ными. Если вы незнакомы с enumerate, обязательно прочитайте раздел документа- ции «Встроенные функции» (https://docs.python.org/3/library/functions.html#enumerate). Функции zip, enumerate и другие генераторные функции из стандартной библио- теки рассматриваются в разделе «Генераторные функции в стандартной библио- теке» главы 17. И в завершение этой главы перенесем метод __format__ из класса Vector2d в класс Vector. Vector , пОпытка № 5: фОрматир Ование Метод __format__ класса Vector будет похож на одноименный метод из класса Vector2d, но вместо специального представления в полярных координатах мы будем использовать так называемые «гиперсферические» координаты (на- звание связано с тем, что в пространствах размерности 4 и выше сферы на- зываются гиперсферами)1. Соответственно, специальный суффикс форматной строки 'p' мы заменим на 'h'. В разделе «Форматированное отображение» главы 11 мы виде- ли, что при расширении мини-языка спецификации формата (https://docs.python.org/3/library/string.html#formatspec) лучше не ис - пользовать форматные коды, предназначенные для встроенных типов. В частности, в нашем расширенном мини-языке коды 'eEfFgGn%' используются в своем изначальном смысле, поэтому их-то точно нельзя переопределять. Для форматирования целых чисел служат коды 'bcdoxXn' , а для строк – код 's'. Для вывода объекта Vector2d в полярных координатах я выбрал код 'p', а для гиперсферических координат возьму код 'h'. Например, для объекта Vector в четырехмерном пространстве (len(v) == 4 ) код 'h' порождает представление вида <r, Φ₁, Φ₂, Φ₃> , где r – модуль вектора (abs(v)), а Φ1, Φ2, Φ3 – угловые координаты. 1 На сайте Wolfram Mathworld (http://mathworld.wolfram.com/Hypersphere.html) имеется статья о гиперсферах; в Википедии запрос по слову «hypersphere» переадресуется на статью «n-sphere» (http://en.wikipedia.org/wiki/Nsphere). Vector, попытка № 5: форматирование  399\n--- Страница 399 ---\nНиже приведены примеры вывода 4-мерного вектора в сферических коор- динатах, взятые из тестов в файле vector_v5.py (см. пример 12.16): >>> format(Vector([-1, -1, -1, -1]), 'h') '<2.0, 2.0943951023931957, 2.186276035465284, 3.9269908169872414>' >>> format(Vector([2, 2, 2, 2]), '.3eh') '<4.000e+00, 1.047e+00, 9.553e-01, 7.854e-01>' >>> format(Vector([0, 1, 0, 0]), '0.5fh') '<1.00000, 1.57080, 0.00000, 0.00000>' Прежде чем вносить мелкие изменения в метод __format__ , мы должны на- писать два вспомогательных метода: angle(n) будет вычислять одну из угловых координат (например, Φ1), а angles() – возвращать итерируемый объект, содер- жащий все угловые координаты. Не стану останавливаться здесь на математи- ческой теории, интересующиеся читатели могут найти формулы преобразо- вания из декартовых координат в сферические в статье из Википедии (http:// en.wikipedia.org/wiki/N-sphere). В примере 12.16 приведен полный код из файла vector_v5.py, в который во- шло все, что мы сделали, начиная с раздела «Vector, попытка № 1: совмести- мость с Vector2d», включая форматирование. Пример 12.16. vector_v5.py: тесты и окончательный код класса Vector; выноски описы- вают добавления, необходимые для поддержки метода __format__ «»» Многомерный класс ``Vector``, попытка 5 A ``Vector`` is built from an iterable of numbers:: >>> Vector([3.1, 4.2]) Vector([3.1, 4.2]) >>> Vector((3, 4, 5)) Vector([3.0, 4.0, 5.0]) >>> Vector(range(10)) Vector([0.0, 1.0, 2.0, 3.0, 4.0, ]) Tests with two dimensions (same results as ``vector2d_v1.py``):: >>> v1 = Vector([3, 4]) >>> x, y = v1 >>> x, y (3.0, 4.0) >>> v1 Vector([3.0, 4.0]) >>> v1_clone = eval(repr(v1)) >>> v1 == v1_clone True >>> print(v1) (3.0, 4.0) >>> octets = bytes(v1) >>> octets b'd\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x08@\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x10@'400  Специальные методы для последовательностей\n--- Страница 400 ---\n>>> abs(v1) 5.0 >>> bool(v1), bool(Vector([0, 0])) (True, False) Test of ``.frombytes()`` class method: >>> v1_clone = Vector.frombytes(bytes(v1)) >>> v1_clone Vector([3.0, 4.0]) >>> v1 == v1_clone True Tests with three dimensions:: >>> v1 = Vector([3, 4, 5]) >>> x, y, z = v1 >>> x, y, z (3.0, 4.0, 5.0) >>> v1 Vector([3.0, 4.0, 5.0]) >>> v1_clone = eval(repr(v1)) >>> v1 == v1_clone True >>> print(v1) (3.0, 4.0, 5.0) >>> abs(v1) # doctest:+ELLIPSIS 7.071067811 >>> bool(v1), bool(Vector([0, 0, 0])) (True, False) Tests with many dimensions:: >>> v7 = Vector(range(7)) >>> v7 Vector([0.0, 1.0, 2.0, 3.0, 4.0, ]) >>> abs(v7) # doctest:+ELLIPSIS 9.53939201 Test of ``.__bytes__`` and ``.frombytes()`` methods:: >>> v1 = Vector([3, 4, 5]) >>> v1_clone = Vector.frombytes(bytes(v1)) >>> v1_clone Vector([3.0, 4.0, 5.0]) >>> v1 == v1_clone True Tests of sequence behavior:: >>> v1 = Vector([3, 4, 5]) Vector, попытка № 5: форматирование  401\n--- Страница 401 ---\n>>> len(v1) 3 >>> v1[0], v1[len(v1)-1], v1[-1] (3.0, 5.0, 5.0) Test of slicing:: >>> v7 = Vector(range(7)) >>> v7[-1] 6.0 >>> v7[1:4] Vector([1.0, 2.0, 3.0]) >>> v7[-1:] Vector([6.0]) >>> v7[1,2] Traceback (most recent call last): TypeError: 'tuple' object cannot be interpreted as an integer Tests of dynamic attribute access:: >>> v7 = Vector(range(10)) >>> v7.x 0.0 >>> v7.y, v7.z, v7.t (1.0, 2.0, 3.0) Dynamic attribute lookup failures:: >>> v7.k Traceback (most recent call last): AttributeError: 'Vector' object has no attribute 'k' >>> v3 = Vector(range(3)) >>> v3.t Traceback (most recent call last): AttributeError: 'Vector' object has no attribute 't' >>> v3.spam Traceback (most recent call last): AttributeError: 'Vector' object has no attribute 'spam' Tests of hashing:: >>> v1 = Vector([3, 4]) >>> v2 = Vector([3.1, 4.2]) >>> v3 = Vector([3, 4, 5]) >>> v6 = Vector(range(6)) >>> hash(v1), hash(v3), hash(v6) (7, 2, 1)402  Специальные методы для последовательностей\n--- Страница 402 ---\nMost hash values of non-integers vary from a 32-bit to 64-bit CPython build:: >>> import sys >>> hash(v2) == (384307168202284039 if sys.maxsize > 2**32 else 357915986) True Tests of ``format()`` with Cartesian coordinates in 2D:: >>> v1 = Vector([3, 4]) >>> format(v1) '(3.0, 4.0)' >>> format(v1, '.2f') '(3.00, 4.00)' >>> format(v1, '.3e') '(3.000e+00, 4.000e+00)' Tests of ``format()`` with Cartesian coordinates in 3D and 7D:: >>> v3 = Vector([3, 4, 5]) >>> format(v3) '(3.0, 4.0, 5.0)' >>> format(Vector(range(7))) '(0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0)' Tests of ``format()`` with spherical coordinates in 2D, 3D and 4D:: >>> format(Vector([1, 1]), 'h') # doctest:+ELLIPSIS '<1.414213 , 0.785398 >' >>> format(Vector([1, 1]), '.3eh') '<1.414e+00, 7.854e-01>' >>> format(Vector([1, 1]), '0.5fh') '<1.41421, 0.78540>' >>> format(Vector([1, 1, 1]), 'h') # doctest:+ELLIPSIS '<1.73205 , 0.95531 , 0.78539 >' >>> format(Vector([2, 2, 2]), '.3eh') '<3.464e+00, 9.553e-01, 7.854e-01>' >>> format(Vector([0, 0, 0]), '0.5fh') '<0.00000, 0.00000, 0.00000>' >>> format(Vector([-1, -1, -1, -1]), 'h') # doctest:+ELLIPSIS '<2.0, 2.09439 , 2.18627 , 3.92699 >' >>> format(Vector([2, 2, 2, 2]), '.3eh') '<4.000e+00, 1.047e+00, 9.553e-01, 7.854e-01>' >>> format(Vector([0, 1, 0, 0]), '0.5fh') '<1.00000, 1.57080, 0.00000, 0.00000>' «»» from array import array import reprlib import math import functools import operator import itertools  class Vector: typecode = 'd' Vector, попытка № 5: форматирование  403\n--- Страница 403 ---\ndef __init__(self, components): self._components = array(self.typecode, components) def __iter__(self): return iter(self._components) def __repr__(self): components = reprlib.repr(self._components) components = components[components.find('['):-1] return f'Vector({components})' def __str__(self): return str(tuple(self)) def __bytes__(self): return (bytes([ord(self.typecode)]) + bytes(self._components)) def __eq__(self, other): return (len(self) == len(other) and all(a == b for a, b in zip(self, other))) def __hash__(self): hashes = (hash(x) for x in self) return functools.reduce(operator.xor, hashes, 0) def __abs__(self): return math.hypot(*self) def __bool__(self): return bool(abs(self)) def __len__(self): return len(self._components) def __getitem__(self, key): if isinstance(key, slice): cls = type(self) return cls(self._components[key]) index = operator.index(key) return self._components[index] __match_args__ = ('x', 'y', 'z', 't') def __getattr__(self, name): cls = type(self) try: pos = cls.__match_args__.index(name) except ValueError: pos = -1 if 0 <= pos < len(self._components): return self._components[pos] msg = f'{cls.__name__!r} object has no attribute {name!r}' raise AttributeError(msg)404  Специальные методы для последовательностей\n--- Страница 404 ---\ndef angle(self, n):  r = math.hypot(*self[n:]) a = math.atan2(r, self[n-1]) if (n == len(self) - 1) and (self[-1] < 0): return math.pi * 2 - a else: return a def angles(self):  return (self.angle(n) for n in range(1, len(self))) def __format__(self, fmt_spec=''): if fmt_spec.endswith('h'): # гиперсферические координаты fmt_spec = fmt_spec[:-1] coords = itertools.chain([abs(self)], self.angles())  outer_fmt = '<{}>'  else: coords = self outer_fmt = '({})'  components = (format(c, fmt_spec) for c in coords)  return outer_fmt.format(', '.join(components))  @classmethod def frombytes(cls, octets): typecode = chr(octets[0]) memv = memoryview(octets[1:]).cast(typecode) return cls(memv)  Импортировать itertools, чтобы можно было воспользоваться функцией chain в методе __format__ .  Вычислить одну из угловых координат по формулам, взятым из статьи об N-сфере (http://en.wikipedia.org/wiki/N-sphere).  Создать генераторное выражение для вычисления всех угловых координат по запросу.  Использовать itertools.chain для порождения генераторного выражения, которое перебирает модуль и угловые координаты вектора.  Сконфигурировать отображение сферических координат в угловых скобках.  Сконфигурировать отображение декартовых координат в круглых скобках.  Создать генераторное выражение для форматирования координат по запросу.  Подставить отформатированные компоненты, разделенные запятыми, в угловые или круглые скобки. Мы вовсю пользуемся генераторными выражениями в методах __format__ , angle и angles, но наша цель здесь – просто написать метод __format__ , чтобы класс Vector не уступал в полноте реали- зации классу Vector2d. При рассмотрении генераторов в главе 14 мы воспользуемся в качестве примера кодом из класса Vector, и тогда все хитрости будут подробно объяснены. Итак, все задачи, которые мы ставили перед собой в этой главе, решены. В главе 16 мы пополним класс Vector инфиксными операторами, но пока хо- тели лишь изучить, как писать специальные методы, полезные в различных классах коллекций. Vector, попытка № 5: форматирование  405\n--- Страница 405 ---\nрезюме Класс Vector из этой главы был задуман совместимым с классом Vector2d во всем, кроме использования другой сигнатуры конструктора, – теперь он принимает один итерируемый объект, как конструкторы встроенных типов последова- тельностей. Чтобы класс Vector вел себя так же, как последовательность, ока- залось достаточно реализовать методы __getitem__ и __len__, и этот факт подвиг нас на обсуждение протоколов – неформальных интерфейсов в языках с ути- ной типизацией. Далее мы разобрались, как на самом деле работает конструкция my_seq[a:b:c] , для чего создали объект slice(a, b, c) и передали его методу __getitem__ . Воору - жившись этими знаниями, мы переделали класс Vector, так чтобы операция получения среза выполнялась для него корректно, т. е. возвращала экземпляр типа Vector, как и положено последовательности в Python. Нашим следующим шагом было обеспечение доступа для чтения к несколь- ким первым компонентам объекта Vector по именам, т. е. с помощью нотации my_vec.x. Для этого мы реализовали метод __getattr__ . При этом у пользователя могло возникнуть искушение присвоить значение таким компонентам, напи- сав my_vec.x = 7 , однако это приводило к ошибке. Мы исправили ошибку, реали- зовав еще и метод __setattr__ , запрещающий присваивать значения атрибутам с однобуквенными именами. Очень часто бывает, что методы __getattr__ и __ setattr__ необходимо реализовывать совместно во избежание несогласованно- го поведения. Реализация метода __hash__ предоставила нам отличную возможность вос- пользоваться функцией functools.reduce , поскольку необходимо было приме- нить оператор ^ к хешам всех компонент Vector, чтобы создать агрегированное хеш-значение объекта Vector в целом. Применив функцию reduce в методе __ hash__, мы затем воспользовались встроенной функцией all для создания более эффективной версии метода __eq__. И последним усовершенствованием класса Vector стала новая реализация метода __format__ из класса Vector2d, поддерживающая гиперсферические коор- динаты в дополнение к декартовым. Тут нам понадобились кое-какие мате- матические формулы и несколько генераторов, но все это детали реализации (к генераторам мы еще вернемся в главе 17). В последнем разделе нашей це- лью было поддержать специальный формат и тем самым выполнить данное ранее обещание, что класс Vector сможет делать все, что умел Vector2d, и кое-что сверх того. Как и в главе 11, мы часто оглядывались на поведение стандартных объек - тов Python, стремясь имитировать его, чтобы класс Vector соответствовал духу Python. В главе 16 мы реализуем в классе Vector несколько инфиксных операторов. Математика будет куда проще, чем в методе angle(), зато изучение работы ин- фиксных операторов в Python станет отличным уроком по объектно-ориенти- рованному проектированию. Однако прежде чем заняться перегрузкой опера- торов, мы на время отвлечемся от разработки отдельного класса и посмотрим, как можно организовать несколько классов с помощью интерфейсов и насле- дования. Это темы глав 13 и 14.406  Специальные методы для последовательностей\n--- Страница 406 ---\nдОпО лнительная литература Большинство специальных методов, рассмотренных при разработке класса Vector, встречаются и в классе Vector2d из главы 11, поэтому актуальны все биб- лиографические ссылки, приведенные в предыдущей главе. Мощную функцию высшего порядка reduce называют также fold, accumulate, aggregate, compress и inject. Дополнительные сведения можно найти в статье из Википедии «Fold (higher-order function)» (http://en.wikipedia.org/wiki/Fold_(higher- order_function)), где описаны применения этой функции с упором на функцио- нальное программирование с рекурсивными структурами данных. В этой ста- тье имеется также таблица, в которой перечислены похожие функции в десят - ках языков программирования. В документе «What’s New in Python 2.5» (https://docs.python.org/2.5/whatsnew/ pep-357.html) имеется короткое объяснение метода __index__, предназначенно- го для поддержки методов __getitem__ , как было показано в разделе «Метод __ getitem__ с учетом срезов». В документе PEP 357 «Allowing Any Object to be Used for Slicing» (https://peps.python.org/pep-0357/) обосновывается его необходимость с точки зрения разработчика C-расширения, Трэвиса Олифанта, основного ав- тора NumPy. Благодаря многочисленным вкладам Олифанта Python вышел на первое место среди языков программирования для научной работы, а затем и на лидирующие позиции в области приложений машинного обучения. Поговорим Протоколы как неформальные интерфейсы Протоколы – не изобретение Python. Авторы языка Smalltalk, пустившие в оборот также выражение «объектно-ориентированный», использовали сло- во «протокол» как синоним того, что сейчас называется интерфейсом. В не- которых средах программирования на Smalltalk программистам разрешалось помечать группу методов как протокол, но только в целях документирования и навигации – сам язык эту концепцию не поддерживал. Поэтому я полагаю, что «неформальный интерфейс» – разумное краткое объяснение существа «протокола» в выступлении перед аудиторией, больше знакомой с формаль- ными (и поддержанными компилятором) интерфейсами. Протоколы естественно возникают в любом языке с динамической типиза- цией, когда контроль типов производится во время выполнения, потому что в объявлениях переменных и сигнатур методов нет никакой статической ин- формации о типе. Ruby – еще один важный объектно-ориентированный язык, в котором имеется динамическая типизация и используются протоколы. В документации по Python протокол можно узнать по выражениям типа «объ- ект, похожий на файл». Это сокращение фразы «нечто, что ведет себя в доста- точной степени похоже на файл благодаря реализации тех частей интерфейса файла, которые существенны в данном контексте». Кто-то решит, что реализация лишь части протокола – признак небрежного программирования, но у такого подхода есть преимущество – простота. В раз- деле 3.3 главы «Модель данных» (https://docs.python.org/3/reference/datamodel. html# special-method-names) читаем такую рекомендацию: Дополнительная литература  407\n--- Страница 407 ---\nПри реализации класса, имитирующего встроенный тип, важно не за- ходить слишком далеко, а ограничиться лишь тем, что имеет смысл для моделируемого объекта. Например, для некоторых последова- тельностей вполне достаточно извлечения отдельных элементов, тог- да как получение среза бессмысленно. Если мы можем обойтись без кодирования ненужных методов только для того, чтобы удовлетворить требованиям какого-то перенасыщенного функцио- нальностью контракта, а компилятор при этом не будет ругаться, то становит - ся проще следовать принципу KISS1 (http://en.wikipedia.org/wiki/KISS_principle). С другой стороны, если мы пользуемся средством проверки типов для вери- фикации реализаций протоколов, то необходимо более строгое определение протокола. Именно такое определение и предлагает класс typing.Protocol . Мы еще вернемся к протоколам и интерфейсам в главе 13, которая в основ- ном этой теме и посвящена. Истоки утиной типизации Я полагаю, что популяризации термина «duck typing» (утиная типизация) боль- ше других способствовало сообщество Ruby, обращавшееся с проповедью к по- клонникам Java. Но это выражение встречалось в обсуждениях Python еще до того, как Ruby и Python стали «популярными». Согласно Википедии, один из первых примеров аналогии с уткой в объектно-ориентированном программи- ровании – сообщение в списке рассылки Python, отправленное Алексом Мар- телли 26 июля 2000 года и касавшееся полиморфизма (с заголовком Re: Type checking in python?) (https://mail.python.org/pipermail/python-list/2000-July/046184. html). Именно из него взята цитата, ставшая эпиграфом к данной главе. Если вам любопытны литературные корни термина «утиная типизация», а также приме- нения этой объектно-ориентированной концепции во многих языках, почитай- те статью Википедии «Duck typing» (http://en.wikipedia.org/wiki/Duck_typing). Безопасный __format__ повышенного удобства При реализации метода __format__ мы не принимали никаких мер предосторож - ности на случай экземпляров Vector с очень большим числом компонент, хотя в методе __repr__ применили для этой цели библиотеку reprlib. Обоснованием служит тот факт, что функция repr() предназначена для отладки и протоколи- рования, поэтому любой ценой должна вывести хоть какое-то полезное пред- ставление, тогда как __format__ предназначен для конечного пользователя, кото- рый, вероятно, хочет видеть вектор целиком. Если вы полагаете, что это опасно, то можете продолжить расширение мини-языка спецификации формата. Я бы сделал это так: по умолчанию для любого форматированного вектора выводится разумное, хотя и ограниченное количество компонент, скажем 30. Если элементов больше, то поведение по умолчанию может быть аналогично тому, что делает reprlib: отбросить дополнительные компоненты, заменив их многоточием. Но если спецификатор формата заканчивается специальным кодом *, означающим «все», то ограничения на размер не действуют. Таким образом, пользователь, который не знает о проблеме очень длинного пред- ставления, не станет жертвой случайности. Однако если ограничение начина- ет мешать, то наличие должно натолкнуть пользователя на мысль поискать в документации, где он узнает о коде форматирования *. 1 Кeep it simple, stupid – Будь проще, глупышка. – Прим. перев.408  Специальные методы для последовательностей\n--- Страница 408 ---\nКак вычислить сумму в духе Python Не существует однозначного ответа на вопрос «Что соответствует духу Python?», как и ответа на вопрос «Что такое красота?». Я часто говорю, что это означает «идиоматичный Python», однако такой ответ не вполне годится, по- тому что слово «идиоматичный» для меня и для вас может означать разные вещи. Но одно я знаю точно: «идиоматичность» не означает, что нужно ис- пользовать средства языка, спрятанные в самых потаенных закоулках. В списке рассылки Python (https://mail.python.org/mailman/listinfo/python-list) есть ветка, датированная апрелем 2003, под названием «Pythonic Way to Sum n-th List Element?» (https://mail.python.org/pipermail/python-list/2003-April/218568.html). Она примыкает к обсуждению функции reduce в этой главе. Начавший ее Гай Миддлтон просил улучшить следующее решение, оговорив- шись, что ему не нравятся лямбда-выражения1: >>> my_list = [[1, 2, 3], [40, 50, 60], [9, 8, 7]] >>> import functools >>> functools.reduce(lambda a, b: a+b, [sub[1] for sub in my_list]) 60 В этом коде идиом хватает: lambda, reduce и списковое включение. Наверное, он занял бы последнее место на конкурсе популярности, потому что равно оскорбляет чувства тех, кто ненавидит lambda, и тех, кто презирает списковое включение, – а это чуть ли не вся публика. Если вы собираетесь использовать lambda, то, пожалуй, нет причин прибегать к списковому включению, разве что для фильтрации, но здесь у нас не тот случай. Вот мое решение, которое должно понравиться любителям lambda: >>> functools.reduce(lambda a, b: a + b[1], my_list, 0) 60 Я не участвовал в этой ветке и не стал бы использовать этот код в реальной программе, потому что сам не большой поклонник lambda, но хотел показать, как можно решить эту задачу без спискового включения. Первым ответил Фернандо Перес, создатель IPython, который привлек вни- мание к тому, что NumPy поддерживает n-мерные массивы и n-мерные срезы: >>> import numpy as np >>> my_array = np.array(my_list) >>> np.sum(my_array[:, 1]) 60 Мне кажется, что решение Переса очень изящное, но Гай Миддлтон выбрал другое, принадлежащее Полу Рубину и Скипу Монтанаро: >>> import operator >>> functools .reduce(operator .add, [sub[1] for sub in my_list], 0) 60 Затем Эван Симпсон спросил «А это чем плохо?»: 1 Я немного изменил код для включения в книгу: в 2003 году функция reduce была встроенной, но в Python 3 ее нужно импортировать. Кроме того, я заменил имена x и y на my_list и sub (от sub-list). Дополнительная литература  409\n--- Страница 409 ---\n>>> total = 0 >>> for sub in my_list: total += sub[1] >>> total 60 Многие согласились, что это решение вполне в духе Python. Алекс Мартелли даже осмелился предположить, что так написал бы сам Гвидо. Мне нравится код Эвана Симпсона, впрочем, как и комментарий к нему Дэ- вида Эпштейна: Если вы хотите просуммировать список элементов, то следует так и писать: «сумма списка элементов», а не «перебрать все элементы, завести еще одну переменную t и выполнить последовательность сложений». Зачем вообще нужны языки высокого уровня, если не для того, чтобы мы могли выразить свои намерения на высоком уровне – и пусть язык сам позаботится о том, какие низкоуровневые операции нужны для их реализации? Затем вновь возник Алекс Мартелли с таким предложением: «Сумма» нужна так часто, что я не возражал бы, если бы в Python поя- вилась такая встроенная функция. Но, на мой взгляд, «reduce(operator. add, …» – не самый лучший способ выразить эту идею (вообще-то, имея большой опыт работы с APL и будучи поклонником функцио- нального программирования, я должен был бы заценить этот код – но вот не нравится, и все тут). Алекс далее предлагает функцию sum(), которую сам же и написал. Она ста- ла встроенной в версии Python 2.3, вышедшей спустя всего три месяца после этой беседы. И вот так синтаксис, который предпочел Алекс, стал нормой: >>> sum([sub[1] for sub in my_list]) 60 В конце следующего года (ноябрь 2004) в версии Python 2.4 появились гене- раторные выражения, которые, на мой взгляд, дали самый «питонический» ответ на вопрос Гая Миддлтона: >>> sum(sub[1] for sub in my_list) 60 Этот код не только понятнее версии с reduce, но и позволяет избежать проб- лем, когда последовательность пуста: sum([]) равно 0 – вот так всё просто. В той же беседе Алекс Мартелли высказал мысль, что встроенная функция reduce в Python 2 приносит больше хлопот, чем преимуществ, потому что по- ощряет применение идиом, которые трудно объяснить. Он был очень убеди- телен: в результате в Python 3 эта функция перекочевала в модуль functools. И тем не менее у функции functools.reduce есть свое место под солнцем. Она позволила написать метод Vector.__hash__ способом, который лично я считаю вполне в духе Python. 410  Специальные методы для последовательностей",
      "debug": {
        "start_page": 380,
        "end_page": 409
      }
    },
    {
      "name": "Глава 13. Интерфейсы, протоколы и ABC 411",
      "content": "--- Страница 410 --- (продолжение)\nГлава 13 Интерфейсы, протоколы и ABC Программируйте в соответствии с интерфейсом, а не реализацией. – Гамма, Хелм, Джонсон, Влиссидес, «Первый принцип объектно-ори- ентированного программирования»1 Объектно-ориентированное программирование – это об интерфейсах. Хотите понять, что делает тип в Python, – узнайте, какие методы он предоставляет (его интерфейс), как описано в разделе «Типы определяются тем, какие операции они поддерживают» главы 8. В разных языках программирования есть один или несколько способов определения и использования интерфейсов. Начиная с версии Python 3.8 у нас таких способов четыре. Все они изображены на карте типизации (рис. 13.1). Утиная типизация Подход к типизации, по умолчанию принятый в Python с момента его воз- никновения. Мы изучаем утиную типизацию начиная с главы 1. Гусиная типизация Этот подход поддерживается абстрактными базовыми глазами (ABC) и су - ществует начиная с версии Python 2.6. В его основе лежит сравнение объ- ектов с ABC, выполняемой на этапе выполнения. Гусиная типизация – ос- новная тема этой главы. Статическая типизация Традиционный подход, принятый в статически типизированных язы- ках, в частности C и Java; поддерживается, начиная с версии Python 3.5, с помощью модуля typing и обеспечивается внешними программами про- верки типов по правилам, описанным в документе PEP 484 «Type Hints» (https://peps.python.org/pep-0484/ ). Эта тема в данной главе не рассматрива- ется. Ей посвящена большая часть главы 8, а также глава 15. Статическая утиная типизация Этот подход стал популярным благодаря языку Go; поддерживается под- классами класса typing.Protocol , появившегося в версии 3.8, и также прове- ряется внешними программами. Впервые мы встретились с ним в разделе «Статические протоколы» главы 8. 1 Design Patterns: Elements of Reusable Object-Oriented Software, «Introduction», стр. 18.\nГлава 13 Интерфейсы, протоколы и ABC Программируйте в соответствии с интерфейсом, а не реализацией. – Гамма, Хелм, Джонсон, Влиссидес, «Первый принцип объектно-ори- ентированного программирования»1 Объектно-ориентированное программирование – это об интерфейсах. Хотите понять, что делает тип в Python, – узнайте, какие методы он предоставляет (его интерфейс), как описано в разделе «Типы определяются тем, какие операции они поддерживают» главы 8. В разных языках программирования есть один или несколько способов определения и использования интерфейсов. Начиная с версии Python 3.8 у нас таких способов четыре. Все они изображены на карте типизации (рис. 13.1). Утиная типизация Подход к типизации, по умолчанию принятый в Python с момента его воз- никновения. Мы изучаем утиную типизацию начиная с главы 1. Гусиная типизация Этот подход поддерживается абстрактными базовыми глазами (ABC) и су - ществует начиная с версии Python 2.6. В его основе лежит сравнение объ- ектов с ABC, выполняемой на этапе выполнения. Гусиная типизация – ос- новная тема этой главы. Статическая типизация Традиционный подход, принятый в статически типизированных язы- ках, в частности C и Java; поддерживается, начиная с версии Python 3.5, с помощью модуля typing и обеспечивается внешними программами про- верки типов по правилам, описанным в документе PEP 484 «Type Hints» (https://peps.python.org/pep-0484/ ). Эта тема в данной главе не рассматрива- ется. Ей посвящена большая часть главы 8, а также глава 15. Статическая утиная типизация Этот подход стал популярным благодаря языку Go; поддерживается под- классами класса typing.Protocol , появившегося в версии 3.8, и также прове- ряется внешними программами. Впервые мы встретились с ним в разделе «Статические протоколы» главы 8. 1 Design Patterns: Elements of Reusable Object-Oriented Software, «Introduction», стр. 18.\n--- Страница 411 ---\nкарта типизации Четыре основных подхода к типизации, изображенных на рис. 13.1, дополня- ют друг друга: у каждого есть плюсы и минусы. Ни один не стоит отбрасывать с порога. Номинальные типы Статическая проверкаПроверка во время выполнения Утиная типизация Структурные типы Статическая типизацияЛюбая версия Python, проверка с применением isinstance не производитсяГусиная типизация Python ≥ 2.6, принадлеж- ность к ABC проверяется с помощью isinstance Python ≥ 3.8 с описанными в PEP 544 классом typing.Protocol, аннотация- ми типов и внешним средством проверки типовPython ≥ 3.5 с описанными в PEP 484 аннотациями типов и внешним средством проверки типов Статическая утиная типизация Рис. 13.1. В верхней половине описаны подходы к проверке типов во время выполнения, для которых нужен только сам интерпретатор Python, а в нижней – требующие внешнего средства проверки типов, например MyPy или IDE типа PyCharm. В левых квадрантах на- ходятся схемы типизации, основанные на структуре объекта, т. е. предоставляемых объектом методов, и не зависящие от имени класса или суперклассов. Схемы в правых квадрантах зависят от явных имен типов: имени класса объекта или его суперклассов Каждый из четырех подходов опирается на интерфейсы, но статическую ти- пизацию можно реализовать – плохо – с помощью одних только конкретных типов, не прибегая к абстракциям вроде протоколов и абстрактных базовых классов. Эта глава посвящена утиной типизации, гусиной типизации и стати- ческой утиной типизации – схемам, в основе которых лежат интерфейсы. Глава разбита на четыре крупных раздела – по числу квадрантов на карте типизации: «Два вида протоколов» – сравниваются две формы структурной типизации с помощью протоколов, представленных в левой части карты типизации; «Программирование уток» – углубленное рассмотрение обычной утиной типизации в Python, в частности вопроса о том, как сделать ее безопас - нее, не жертвуя главным достоинством: гибкостью; «Гусиная типизация» – объясняется, как ABC помогают выполнить более строгую проверку типов во время выполнения. Это самый длинный раз-412  Интерфейсы, протоколы и ABC\n--- Страница 412 ---\nдел не потому, что он важнее прочих, а потому, что об утиной типиза- ции, статической утиной типизации и статической типизации написано и в других частях книги; «Статические протоколы» – рассматривается использование, реализа- ция и проектирование подклассов typing.Protocol , полезных для статиче- ской и динамической проверок типов. чтО нОвОг О в этОй главе Эта глава существенно переработана и стала примерно на 24 % длиннее соот - ветствующей главы 11 в первом издании. Хотя некоторые разделы и многие абзацы повторяются, появилось и немало нового материала. Ниже перечисле- ны основные отличия: введение к главе и карта типизации (рис. 13.1) написаны заново. Это ключ к большей части нового материала в этой главе – и во всех осталь- ных, где речь идет о типизации в Python ≥ 3.8; в разделе «Два вида протоколов» рассматриваются сходства и различия динамических и статических протоколов; раздел «Защитное программирование и принцип быстрого отказа» в ос- новных чертах повторяет материал из первого издания, но был дорабо- тан, и теперь заголовок лучше отражает его важность; раздел «Статические протоколы» совсем новый. Он основан на перво- начальных сведениях, изложенных в разделе «Статические протоколы» главы 8; изменены диаграммы классов из модуля collections.abc на рис. 13.2, 13.3 и 13.4; теперь они включают абстрактный базовый класс Collection , по- явившийся в Python 3.6. В первом издании книги был раздел, где всячески поощрялось использо- вание ABC numbers для гусиной типизации. В разделе «ABC из пакета numbers и числовые протоколы» я объясняю, почему вместо этого следует использовать числовые статические протоколы из модуля typing, если вы планируете при- менять средства статической проверки типов наряду с проверками во время выполнения в стиле гусиной типизации. два вида прОтОкОлОв В информатике слово протокол имеет разный смысл в зависимости от кон- текста. Сетевой протокол, например HTTP, описывает, какие команды клиент может отправлять серверу: GET, PUT, HEAD и т. д. В разделе «Протоколы и утиная типизация» главы 12 мы видели, что объектный протокол определяет методы, которые объект должен предоставлять, чтобы выполнить свое предназначе- ние. В примере FrenchDeck в главе 1 продемонстрирован объектный протокол последовательности: методы, благодаря которым объект Python ведет себя как последовательность. Для реализации полного протокола, возможно, требуется написать доволь- но много методов, но зачастую достаточно реализовать только часть. Рассмот- рим класс Vowels в примере 13.1. Два вида протоколов  413\n--- Страница 413 ---\nПример 13.1. Частичная реализация протокола последовательности – метода __getitem__ >>> class Vowels: def __getitem__(self, i): return 'AEIOU'[i] >>> v = Vowels() >>> v[0] 'A' >>> v[-1] 'U' >>> for c in v: print(c) A E I O U >>> 'E' in v True >>> 'Z' in v False Реализации метода __getitem__ достаточно для получения элементов по ин- дексу, а также поддержки итерирования и оператора in. Специальный метод __getitem__ – ключ к протоколу последовательности. Приведем выдержку из «Справочного руководства по Python/C API», раздел «Протокол последователь- ности» (https://docs.python.org/3/c-api/index.html): int PySequence_Check(PyObject *o) Возвращает 1, если объект реализует протокол последовательности, ина- че 0. Отметим, что функция возвращает 1 для классов Python, реализующих метод __getitem__() , если только они не являются подклассами dict […]. Мы ожидаем, что последовательность поддерживает также метод len() пу- тем реализации специального метода __len__. В классе Vowels нет метода __len__, тем не менее в некоторых контекстах он ведет себя как последовательность. И возможно, для ваших целей этого достаточно. Потому-то я и говорю, что протокол – это «неформальный интерфейс». Именно так к протоколам отно- сится Smalltalk, первая объектно-ориентированная среда программирования, в которой этот термин употреблялся. Если не считать страниц документации по Python, относящихся к сетевому программированию, то чаще всего слово «протокол» встречается в контексте этих неформальных интерфейсов. Но теперь, после реализации документа PEP 544 «Protocols: Structural subtyping (static duck typing)» (https://peps.python.org/pep-0544/) в Python 3.8, у слова «протокол» появилось другое значение – близкое, но все же отличаю- щееся. В разделе «Статические протоколы» главы 8 мы видели, что PEP 544 по- зволяет создавать подклассы typing.Protocol с целью определить, какие методы должен реализовать (или унаследовать) класс, чтобы не раздражать програм- му статической проверки типов. Когда контекст требует точности, я буду употреблять следующие термины:414  Интерфейсы, протоколы и ABC\n--- Страница 414 ---\nДинамический протокол Неформальные протоколы, которые были в Python всегда. Динамические протоколы неявные, определяются соглашением и описаны в докумен- тации. Самые важные динамические протоколы поддерживаются самим интерпретатором Python и документированы в главе «Модель данных» (https://docs.python.org/3/reference/datamodel.html) справочного руководства. Статический протокол Протокол, определенный в документе PEP 544 «Protocols: Structural subtyping (static duck typing)», начиная с версии Python 3.8. У статического протокола имеется явное определение: подкласс typing.Protocol . Между этими двумя видами есть два основных различия: объект может реализовывать только часть динамического протокола и при этом быть полезным; но чтобы удовлетворить статическому про- токолу, объект должен предоставить все методы, объявленные в классе протокола, даже если некоторые из них программе не нужны; статические протоколы можно проверить с помощью программ стати- ческой проверки типов, динамические – нельзя. У обоих видов протоколов есть важная общая характеристика: класс не обя- зан объявлять, что поддерживает протокол с некоторым именем, например путем наследования. Помимо статических протоколов, Python предлагает еще один способ про- граммно определить явный интерфейс: абстрактный базовый класс (ABC). Далее в этой главе мы будем рассматривать динамические и статические протоколы, а также ABC. прОграммир Ование утОк Начнем обсуждение динамических протоколов с двух самых важных в Python: протоколов последовательности и итерируемого объекта. Интер- претатор из кожи вон лезет, стремясь обработать объекты, предоставляю- щие даже минимальную реализацию этих протоколов. Это демонстрируется в следующем разделе. Python в поисках следов последовательностей Философия модели данных Python заключается в том, чтобы всемерно взаи- модействовать с важнейшими динамическими протоколами. А уж если речь идет о последовательностях, то Python прилагает все усилия, соглашаясь рабо- тать даже с самыми простыми реализациями. На рис. 13.2 показано формальное определение интерфейса Sequence в виде ABC. Интерпретатор Python и встроенные последовательности list, str и др. во- обще не полагаются на ABC. Я использую его, только чтобы описать, что ожи- дается от полноценной последовательности Sequence. Программирование уток  415\n--- Страница 415 ---\n* Новое в Python 3.6 Рис. 13.2. UML-диаграмма абстрактного базового класса Sequence и связанных с ним клас - сов из модуля collections.abc . Стрелки направлены от подклассов к суперклассам. Курсивом набраны имена абстрактных методов. До версии Python 3.6 не было ABC Collection – класс Sequence был прямым подклассом Container , Iterable и Sized Большинство ABC в модуле collections.abc нужны для того, что- бы формализовать интерфейсы, реализованные встроенными объектами и неявно поддерживаемые интерпретатором, – то и другое существовало задолго до появления самих ABC. Но ABC полезны и как отправные точки для новых классов, и для под- держки явной проверки типов во время выполнения (как при гусиной типизации), и в качестве аннотаций типов для средств статической проверки типов. Глядя на рис. 13.2, мы видим, что правильно написанный подкласс Sequence должен реализовывать методы __getitem__ и __len__ (унаследованный от Sized). Все остальные методы Sequence конкретные, поэтому подклассы могут унасле- довать их реализации или предоставить собственные. Теперь вспомним класс Vowels из примера 13.1. Он не наследует abc.Sequence и реализует только __getitem__ . Метода __iter__ нет, но тем не менее экземпляры Vowels являются итерируе- мыми объектами, поскольку если Python находит метод __getitem__ и не имеет ничего лучше, то он пытается обходить объект, вызывая этот метод с цело- численными индексами, начиная с 0. Поскольку Python достаточно находчив, чтобы обойти экземпляры Vowels, ничто не мешает ему заставить работать опе- ратор in, пусть даже метод __contains__ отсутствует: нужно только произвести последовательный поиск и определить, имеется ли данный элемент. Короче говоря, осознавая важность структур данных, обладающих свойства- ми последовательностей, Python ухитряется заставить итерирование и опе- ратор in работать, вызывая метод __getitem__ в случае, когда методы __iter__ и __contains__ отсутствуют. Оригинальный класс FrenchDeck в главе 1 тоже не является подклассом abc. Sequence, но реализует оба метода протокола последовательности: __getitem__ и __len__. См. пример 13.2. Пример 13.2. Колода как последовательность карт (тот же код, что в примере 1.1) import collections Card = collections.namedtuple('Card', ['rank', 'suit']) 416  Интерфейсы, протоколы и ABC\n--- Страница 416 ---\nclass FrenchDeck: ranks = [str(n) for n in range(2, 11)] + list('JQKA') suits = 'spades diamonds clubs hearts'.split() def __init__(self): self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks] def __len__(self): return len(self._cards) def __getitem__(self, position): return self._cards[position] Ряд примеров из главы 1 работают, потому что Python специальным обра- зом обрабатывает все, что отдаленно напоминает последовательность. Прото- кол итерируемого объекта в Python представляет собой крайнюю форму ути- ной типизации: интерпретатор пробует два разных метода обхода объектов. Если быть точным, то описанные в этом разделе поведения реализованы в самом интерпретаторе, в основном на C. Они не зависят от методов ABC Sequence. Например, конкретные методы __iter__ и __contains__ в классе Sequence эмулируют встроенные поведения интерпретатора Python. Особо любозна- тельные могут посмотреть исходный код этих методов в файле Lib/_collections_ abc.py ( https://github.com/python/cpython/blob/31ceccb2c77854893f3a754aca04bedd74 bedb10/Lib/_collections_abc.py#L870). А теперь рассмотрим еще один пример, подчеркивающий динамическую природу протоколов, а заодно показывающий, почему средства статической проверки типов не имеют ни единого шанса справиться с ними. партизанСк Ое латание как Сред СтвО реализации прОтОкОла вО время выпО лнения Под партизанским латанием понимается динамическое изменение моду - ля, класса или функции во время выполнения – чтобы добавить новые воз- можности или исправить ошибки. Например, сетевая библиотека gevent по- партизански латает части стандартной библиотеки Python, чтобы реализовать облегченную конкурентность без потоков или async/await1. У класса FrenchDeck из примера 13.2 есть существенный изъян: колоду нельзя перетасовать. Много лет назад, впервые написав этот пример, я реализовал метод shuffle. Позже меня посетило питоническое озарение: если FrenchDeck ве- дет себя как последовательность, то ему не нужен собственный метод shuffle, потому что уже имеется функция random.shuffle , в документации по которой (https://docs.python.org/ 3/library/random.html#random.shuffle) написано: «Перета- совывает последовательность х на месте». Стандартная функция random.shuffle используется следующим образом: 1 В статье Википедии «Monkey patch» (https://en.wikipedia.org/wiki/Monkey_patch) есть за- бавный пример на Python. Партизанское латание как средство реализации протокола во время выполнения  417\n--- Страница 417 ---\n>>> from random import shuffle >>> l = list(range(10)) >>> shuffle(l) >>> l [5, 2, 9, 7, 8, 3, 1, 4, 0, 6] Если следовать устоявшимся протоколам, то будет больше шан- сов воспользоваться кодом, уже имеющимся в стандартной биб- лиотеке или написанным кем-то еще, – благодаря утиной типи- зации. Но, попытавшись перетасовать объект FrenchDeck , мы получим исключение (пример 11.5). Пример 13.3. random.shuffle не может работать с объектом FrenchDeck >>> from random import shuffle >>> from frenchdeck import FrenchDeck >>> deck = FrenchDeck() >>> shuffle(deck) Traceback (most recent call last): File \"<stdin>\", line 1, in <module> File \" /random.py\", line 265, in shuffle x[i], x[j] = x[j], x[i] TypeError: 'FrenchDeck' object does not support item assignment В сообщении ясно говорится: «Объект 'FrenchDeck' не поддерживает присва- ивание элементу». Проблема в том, что shuffle должна иметь возможность пере- ставить два элемента коллекции, а класс FrenchDeck реализует только протокол неизменяемой последовательности. Изменяемая последовательность должна также предоставлять метод __setitem__ . Поскольку Python – динамический язык, мы можем устранить проблему прямо во время выполнения, даже в интерактивной оболочке. В примере 11.6 показано, как это сделать. Пример 13.4. Партизанское латание класса FrenchDeck с целью сделать его изменяемым и совместимым с функцией random.shuffle (продолжение примера 13.3) >>> def set_card(deck, position, card):  deck._cards[position] = card >>> FrenchDeck.__setitem__ = set_card  >>> shuffle(deck)  >>> deck[:5] [Card(rank='3', suit='hearts'), Card(rank='4', suit='diamonds'), Card(rank='4', suit='clubs'), Card(rank='7', suit='hearts'), Card(rank='9', suit='spades')]  Создать функцию, которая принимает аргументы deck, position и card.  Присвоить эту функцию атрибуту __setitem__ класса FrenchDeck .  Теперь объект deck можно перетасовать, потому что класс FrenchDeck поддер- живает обязательный метод протокола изменяемой последовательности. Сигнатура метода __setitem__ определена в разделе 3.3.6 «Эмуляция контей- нерных типов» справочного руководства по языку Python (https://docs.python. org/3/ref erenc e/ datamodel.html#emulating-container-types). В данном случае мы на- 418  Интерфейсы, протоколы и ABC\n--- Страница 418 ---\nзвали аргументы deck, position, card – а не self, key, value, как в руководстве, – чтобы показать, что любой метод Python изначально является простой функ - цией, а имя self для первого аргумента – не более чем соглашение. В сеансе оболочки это нормально, но в исходном файле Python гораздо лучше исполь- зовать предлагаемые в документации имена self, key и value. Трюк состоит в том, что функция set_card знает о наличии в объекте deck атри- бута с именем _cards, который должен быть изменяемой последовательностью. После этого мы присоединяем функцию set_card к классу FrenchDeck в качестве специального метода __setitem__ . Это пример партизанского латания (monkey patching): изменения класса или модуля во время выполнения без модифи- кации исходного кода. Техника весьма действенная, но код, в котором она ис- пользуется, оказывается очень тесно связан с латаемой программой и зачас- тую даже вмешивается в ее закрытые и недокументированные части. Помимо партизанского латания, в примере 11.6 иллюстрируется динамич- ность протоколов: функции random.shuffle безразлично, какие аргументы ей пе- реданы, лишь бы объект реализовал часть протокола изменяемой последова- тельности. Не важно даже, получил ли объект необходимые методы «при рож- дении» или каким-то образом приобрел их позже. Не следует думать, что утиная типизация абсолютно небезопасна или что ее ужасно трудно отлаживать. В следующем разделе показано несколько полезных способов обнаружить динамический протокол, не прибегая к явным проверкам. Защитное программирование и принцип быстрого отказа Защитное программирование – как контраварийное вождение: набор практи- ческих навыков, повышающих безопасность при столкновении с беспечными программистами – или водителями. Многие ошибки можно отловить только во время выполнения, даже в по- пулярных статически типизированных языках1. В динамически типизирован- ном языке принцип быстрого отказа – прекрасный совет по созданию более безопасных и удобных для сопровождения программ. Быстрый отказ означает, что нужно возбудить исключение как можно раньше, например отвергать не- допустимые аргументы в самом начале тела функции. Приведу пример: разрабатывая код, который принимает последователь- ность элементов, обрабатываемую как list, не проверяйте, что аргумент имеет тип list. Вместо этого попробуйте сразу же построить list из аргумента. При- мер такого подхода дает метод __init__ в примере 13.10 ниже. def __init__(self, iterable): self._balls = list(iterable) Это позволит сделать код более гибким, потому что конструктор list() го- тов обрабатывать любой итерируемый объект, помещающийся в память. Если аргумент не является итерируемым, что отказ будет быстрым, а сообщение об ошибке в исключении TypeError вполне недвусмысленным и прямо в той точ- ке, где объект инициализируется. Если нужно что-то более явное, то можете обернуть list() операторными скобками try/except , чтобы настроить сообщение 1 Именно поэтому необходимо автоматизированное тестирование. Партизанское латание как средство реализации протокола во время выполнения  419\n--- Страница 419 ---\nоб ошибке, но я бы использовал такой дополнительный код только при работе с внешними API, потому что для лиц, отвечающих за сопровождение кодовой базы, ошибка будет очевидной. В любом случае проблемный вызов будет на- ходиться в конце обратной трассы вызовов, так что ошибку будет легко испра- вить. Если вы не станете обнаруживать недопустимый аргумент в конструк - торе класса, то программа рухнет позже, когда какому-то методу потребуется произвести операцию с self._balls и окажется, что это не list. В таком случае найти исходную причину будет труднее. Разумеется, передавать аргумент конструктору list() не стоит, если данные не должны копироваться, – то ли потому, что они слишком велики, то ли по- тому, что функция, в силу замысла, должна изменять его на месте, посколь- ку того требует вызывающая сторона, как в случае random.shuffle . В подобном случае рекомендуется выполнить проверку во время выполнения, например isinstance(x, abc.MutableSequence) . Если вы боитесь получить бесконечный генератор – не слишком частая проб лема, – то для начала вызовите метод len() аргумента. Тем самым вы от- сечете итераторы, но сможете безопасно обработать кортежи, массив и другие существующие и будущие классы, которые полностью реализуют интерфейс Sequence. Вызов len() обычно обходится очень дешево, а если аргумент недопус- тим, то ошибка произойдет немедленно. С другой стороны, если вы готовы принять любой итерируемый объект, то как можно быстрее вызовите метод iter(x), чтобы получить итератор, как бу- дет показано в разделе «Почему последовательности являются итерируемыми объектами: функция iter». И снова, если объект x неитерируемый, то отказ про- изойдет быстро и отлаживать исключение будет легко. В описанных выше случаях аннотация типа могла бы обнаружить раньше не- которые, но не все ошибки. Напомним, что тип Any совместим с любым другим типом. Механизм вывода типа может пометить переменную типом Any. В таком случае средство проверки типов бессильно. Кроме того, аннотации типов не про- веряются во время выполнения. Быстрый отказ – последняя линия обороны. Защитный код, в котором используется утиная типизация, может так- же включать логику обработки разных типов без привлечения проверок isinstance() или hasattr(). Например, можно было бы эмулировать обработку аргумента field_names в collections.namedtuple . Напомним, что в качестве field_names может фигурировать одна строка идентификаторов, разделенных пробелами или запятыми, или последовательность идентификаторов. В примере 13.5 показано, как я сделал бы это с помощью утиной типизации. Пример 13.5. Применение утиной типизации для обработки строки или итерируемого объ- екта строк try:  field_names = field_names.replace(',', ' ').split()  except AttributeError:  pass  field_names = tuple(field_names) if not all(s.isidentifier() for s in field_names):  raise ValueError('field_names must all be valid identifiers')420  Интерфейсы, протоколы и ABC\n--- Страница 420 ---\n Предполагаем, что это строка (проще попросить прощения, чем испраши- вать разрешение).  Заменяем запятые пробелами и разбиваем образовавшуюся строку, полу - чая список имен.  Увы, field_names не крякает, как str…, – то ли метода .replace нет, то ли он воз- вращает нечто такое, к чему нельзя применить .split.  Если было возбуждено исключение AttributeError , то аргумент field_names не является строкой str, поэтому предполагаем, что он уже является итери- руемым объектом, содержащим имена.  Чтобы убедиться в его итерируемости и заодно получить внутреннюю ко- пию, создаем кортеж из того, что имеем. Кортеж tuple компактнее, чем list, а заодно предотвращает изменение имен по ошибке.  Используем метод str.isidentifier , гарантирующий уникальность имен. Пример 13.5 демонстрирует одну ситуацию, когда утиная типизация оказы- вается более выразительной, чем статические аннотации типов. Невозможно записать аннотацию, которая говорила бы, что «field_names должен быть стро- кой идентификаторов, разделенных пробелами или запятыми». Это реле- вантная часть сигнатуры namedtuple в typeshed (полный код см. в файле stdlib/3/ collections/__init__.pyi по адресу https://github.com/python/typeshed/blob/ 24afb531ffd 07083d6a74be917342195062f7277/stdlib/collections/__init__.pyi): def namedtuple( typename: str, field_names: Union[str, Iterable[str]], *, # остальная часть сигнатуры опущена Как видите, аргумент field_names аннотирован как Union[str, Iterable[str]] , что неплохо, но недостаточно для отлавливания всех возможных ошибок. Сделав обзор динамических протоколов, обратимся к более явной форме проверки типов во время выполнения: гусиной типизации. гуСиная типизация Абстрактный класс предоставляет интерфейс. – Бьярн Страуструп, создатель C++1 В языке Python нет ключевого слова interface. Мы используем абстрактные ба- зовые классы (ABC), чтобы определить интерфейсы для явной проверки типов во время выполнения. Они также поддерживаются программами статической проверки типов. В «Глоссарии Python» статья, посвященная абстрактному базовому классу (https://docs.python.org/3/glossary.html#term-abstract-base-class), объясняет, какую ценность они привносят в языки с утиной оптимизацией: Абстрактные базовые классы дополняют утиную типизацию, поскольку предоставляют способ определять интерфейс в случаях, когда другие при- емы, например hasattr(), выглядели бы неуклюже или содержали бы тонкие 1 Бьярн Страуструп. Дизайн и эволюция C++. ДМК, 2000. С. 284. Гусиная типизация  421\n--- Страница 421 ---\nошибки (например, с помощью магических методов). ABC привносят вир- туальные подклассы, т. е. классы, которые не наследуют другому классу, но тем не менее распознаются функциями isinstance() и issubclass() ; см. описа- ние модуля abc в документации1. Гусиная типизация – это подход к проверке типов во время выполнения, ос- нованный на применении ABC. Предоставляю слово Алексу Мартелли. Я очень благодарен своим друзьям Алексу Мартелли и Анне Равенскрофт. Я показал им план этой книги на конференции OSCON 2013, и они посоветовали мне предложить ее издатель- ству O’Reilly для публикации. Впоследствии оба написали до- тошные технические рецензии. Алекс и так уже был самым ци- тируемым персонажем в этой книге, а затем еще и предложил нижеследующее эссе. Вот оно, Алекс! Водоплавающие птицы и ABC Алекс Мартелли В Википедии (http://en.wikipedia.org/wiki/Duck_typing#History) мне приписывают честь распространения полезного мема и эффектного выражения «утиная типизация» (т. е. игнорирование фактического типа объекта и акцент на то, чтобы объект реализовывал методы с именами, сигнатурами и семантикой, требуемыми для конкретного применения). В Python это сводится в основном к тому, чтобы избегать использования функ - ции isinstance для проверки типа объекта (я уже не говорю о еще более вредном подходе: проверке вида type(foo) is bar , которую следует предать анафеме, по- тому что она препятствует даже простейшим формам наследования!). В целом утиная типизация остается весьма полезной во многих контекстах, однако есть и много других, где со временем выработался иной, более пред- почтительный подход. Отсюда и начинается наш рассказ… Уже для многих поколений классификация по родам и видам (в том числе и семейства водоплавающих, известного под названием Anatidae) основыва- ется главным образом на фенетике – когда во главу угла ставится сходство морфологии и поведения… в общем, на наблюдаемых характеристиках. Ана- логия с «утиной типизацией» была очень сильной. Однако в ходе параллельной эволюции зачастую сходные характеристики, как морфологические, так и поведенческие, оказываются у видов, которые фактически не связаны друг с другом, но просто эволюционировали в по- хожих, хотя и разных, экологических нишах. Подобное «случайное сходство» встречается и в программировании. Для иллюстрации возьмем классический пример из ООП: class Artist: # художник def draw(self): # рисовать class Gunslinger: # стрелок def draw(self): # выхватить револьвер 1 По состоянию на 18 октября 2020 года. 422  Интерфейсы, протоколы и ABC\n--- Страница 422 ---\nclass Lottery: # лотерея def draw(self): # тянуть билетик Очевидно, одного лишь существования метода draw без аргументов далеко недостаточно, чтобы убедить нас в том, что два объекта x и y такие, что до- пустимы вызовы x.draw() и y.draw(), являются хоть в какой-то степени взаимо- заменяемыми или абстрактно эквивалентными, – из допустимости подобных вызовов нельзя сделать никаких выводов о схожести семантики. Понадобится опытный программист, который взялся бы уверенно подтвердить, что такая эквивалентность имеет место на каком-то уровне! В биологии (и других дисциплинах) эта проблема стала причиной появления (а во многих отношениях и преобладания) подхода, альтернативного фенети- ке, а именно кладистики – классификации с упором на характеристики, унасле- дованные от общих предков, а не появившиеся в результате независимой эво- люции. (Дешевая и быстрая методика секвенирования ДНК может сделать кла- дистику практически полезной в гораздо большем числе случаев, чем сейчас.) Например, гуси-пеганки и утки-пеганки (которые раньше в классифика- ции стояли ближе к другим гусям и уткам) теперь помещены в подсемейство Tadornidae (откуда следует, что они ближе друг к другу, чем к другим представи- телям семейства Anatidae, поскольку имеют общего предка). Кроме того, ана- лиз ДНК показал, что белокрылая каролинская утка не так близка к мускусной утке (которая является уткой-пеганкой), как можно было бы предположить по внешнему виду и поведению. Поэтому классификация каролинский утки была изменена, ее вообще исключили из подсемейства и выделили в отдельный род! Важно ли это? Все зависит от контекста! Если нужно решить, как лучше приготовить водоплавающую птицу, которую вы уже добыли, то наблюдае- мые характеристики (не все – скажем, наличие плюмажа в этом случае роли не играет) и прежде всего структура мяса и вкусовые качества (старомодная фенетика!) гораздо важнее кладистики. Но в других вопросах, например в от- ношении восприимчивости к различным патогенным организмам (следует ли пытаться выращивать птиц в неволе или сохранять их в дикой природе), близость ДНК может оказаться гораздо важнее… Итак, в силу наличия отдаленной аналогии с таксономической революцией в мире водоплавающих птиц я рекомендую дополнить старую добрую утиную типизацию (не вовсе заменить – в некоторых контекстах она нам еще послу - жит) … гусиной типизацией! Гусиная типизация означает следующее: вызов isinstance(obj, cls) теперь счи- тается приемлемым… при условии, что cls – абстрактный базовый класс, т. е. метаклассом cls является abc.ABCMeta . В модуле collections.abc можно найти немало полезных абстрактных классов (они есть также в модуле numbers из стандартной библиотеки Python)1. 1 Разумеется, вы можете определить и свои ABC, но я не советую это делать никому, кроме самых опытных питонистов, равно как не советую определять свои метаклас - сы… и даже для этих «самых опытных питонистов», знающих обо всех потаенных уголках и темных закоулках языка, это инструменты не для каждодневного использо- вания. Эти средства «углубленного метапрограммирования» предназначены авторам каркасов широкого назначения, которые предположительно будут независимо разви- вать многочисленные не связанные между собой команды разработчиков. В общем, они могут понадобиться менее чем 1 % «самых опытных питонистов»! – А. М. Гусиная типизация  423\n--- Страница 423 ---\nИз многих концептуальных преимуществ ABC по сравнению с конкретными классами (например, Скотт Мейер в своей книге «Более эффективный C++», совет 33 – http://ptgmedia.pearsoncmg.com/images/020163371x/items/item33.html, – говорит, что «все нелистовые классы должны быть абстрактными») выделим одно практически важное достоинство ABC в Python: метод класса register, который дает возможность конечному пользователю «объявить» некото- рый класс «виртуальным» подклассом ABC (для этого зарегистрированный класс должен удовлетворять требованиям ABC к имени и сигнатуре и, что еще важнее, подразумеваемому семантическому контракту, но его необяза- тельно разрабатывать с учетом ABC и, в частности, не требуется наследовать ему!). Это большой шаг на пути к устранению жесткости и сильной сцеплен- ности, из-за которых к наследованию следует относиться с куда большей настороженностью, чем позволяет себе большинство программирующих на ОО-языках… Иногда даже и регистрировать класс не нужно, чтобы ABC распознал его как подкласс! Так бывает в случае ABC, существующих только ради нескольких специаль- ных методов. Например: >>> class Struggle: def __len__(self): return 23 >>> from collections import abc >>> isinstance(Struggle(), abc.Sized) True Как видим, abc.Sized распознал Struggle как свой «подкласс» безо всякой ре- гистрации просто потому, что для этого необходимо только наличие специ- ального метода __len__ (предполагается, что он реализован правильно с точки зрения синтаксиса – вызывается без аргументов – и семантики – возвращает неотрицательное целое число, интерпретируемое как «длина» объекта; про- грамма, которая реализует специальный метод, например __len__, с какими- то другими, несогласованными синтаксисом и семантикой, в любом случае обречена на куда более серьезные проблемы). Итак, вот мое напутствие: реализуя класс, который воплощает концепции, представленные в ABC из модуля numbers, collections.abc или какого-то другого каркаса, либо делайте его подклассом ABC (если необходимо), либо регист- рируйте. В начале программы, использующей библиотеку или каркас, где определяются классы, для которых это не сделано, выполняйте регистрацию самостоятельно. Затем, если потребуется проверить, что аргумент (чаще все- го это необходимо как раз для аргументов) является, к примеру, «последова- тельностью», пишите: isinstance(the_arg, collections.abc.Sequence) И не определяйте свои ABC (или метаклассы) в производственном коде. Если вам кажется, что без этого не обойтись, держу пари, что это, скорее всего, желание поскорее забить гвоздь, раз уж в руках молоток, – вам (и тем, кому предстоит сопровождать вашу программу) будет куда комфортнее иметь дело с прямолинейным и простым кодом, где нет таких глубин. Valē!424  Интерфейсы, протоколы и ABC\n--- Страница 424 ---\nТаким образом, гусиная типизация подразумевает: порождение подклассов ABC, чтобы было ясно, что мы реализуем ранее определенный интерфейс; проверку во время выполнения с указанием ABC вместо конкретных классов в качестве второго аргумента функций isinstance и issubclass . Алекс подчеркивает, что наследование ABC не сводится к реализации необхо- димых методов, это еще и четкое заявление о намерениях разработчика. Такое на- мерение можно сделать явным также путем регистрации виртуального подкласса. Подробнее использование register рассматривается в разделе «Виртуальный класс ABC» ниже в этой главе. А пока приведу крат - кий пример. Пусть имеется класс FrenchDeck , и я хочу проверять его тип следующим образом: issubclass(FrenchDeck, Sequence) . Для этого я могу сделать его виртуальным подклассом ABC Sequence: from collections.abc import Sequence Sequence .register(FrenchDeck) Использование функций isinstance и issubclass выглядит уже не столь одиозным, если сравнивать тип с ABC, а не с конкретными классами. При использовании в со- четании с конкретными классами проверка типа ограничивает полиморфизм – существенную часть объектно-ориентированного программирования. Но с по- явлением ABC проверки становятся более гибкими. Ведь даже если компонент не является подклассом ABC, но реализует требуемые методы, его всегда можно зарегистрировать постфактум, так что он пройдет эти явные проверки типа. Однако и при использовании ABC нужно помнить, что злоупотребление функцией isinstance может быть признаком «дурно пахнущего кода» – плохо спроектированной объектно-ориентированной программы. Обычно не должно быть цепочек предложений if/elif/elif , в которых с помо- щью insinstance определяется тип объекта и в зависимости от него выполняются те или иные действия; для этой цели следует использовать полиморфизм, т. е. проектировать классы, так чтобы интерпретатор сам вызывал правильные ме- тоды, а не «зашивать» логику диспетчеризации в блоки if/elif/elif . С другой стороны, нет возражений против использования insinstance для сравнения с типом ABC, если требуется убедиться в соблюдении контракта: «Эй, чтобы меня вызывать, ты должен реализовать то-то и то-то», как выра- зился технический рецензент Леннарт Регебро. Особенно это полезно в систе- мах, основанных на архитектуре плагинов. За пределами каркасов утиная ти- пизация обычно проще и дает большую гибкость, чем проверка типов. Наконец, в своем эссе Алекс неоднократно подчеркивает, что не стоит усерд- ствовать в создании ABC. Злоупотребление ABC вынудило бы выполнять не- нужные церемонии в языке, завоевавшем популярность своей практичностью и прагматичностью. В своей рецензии на эту книгу Алекс написал: ABC предназначены для инкапсуляции очень общих концепций, абстрак - ций, характерных для каркаса, – таких вещей, как «последовательность» или «точное число». [Читателям], скорее всего, не придется писать новые ABC, а лишь правильно использовать существующие. В 99.9 % случаев это- го будет достаточно для получения всех преимуществ без риска спроекти- ровать что-то не то. Гусиная типизация  425\n--- Страница 425 ---\nНу а теперь посмотрим, как гусиная типизация выглядит на практике. СОздание пОдкла ССа ABc Следуя совету Мартелли, мы воспользуемся существующим ABC collections. MutableSequence , перед тем как изобретать свой собственный. В примере 13.6 класс FrenchDeck2 явно объявлен подклассом collections.MutableSequence . Пример 13.6. frenchdeck2.py: FrenchDeck2 , подкласс collections.MutableSequence from collections import namedtuple, abc Card = namedtuple('Card', ['rank', 'suit']) class FrenchDeck2(abc.MutableSequence): ranks = [str(n) for n in range(2, 11)] + list('JQKA') suits = 'spades diamonds clubs hearts'.split() def __init__(self): self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks] def __len__(self): return len(self._cards) def __getitem__(self, position): return self._cards[position] def __setitem__(self, position, value):  self._cards[position] = value def __delitem__(self, position):  del self._cards[position] def insert(self, position, value):  self._cards.insert(position, value)  Метод __setitem__ – все, что нам нужно для поддержки тасования…  … но чтобы создать подкласс MutableSequence , нам придется реализовать так- же __delitem__ – абстрактный метод, определенный в этом ABC.  Еще необходимо реализовать insert, третий абстрактный метод MutableSequence . На этапе импорта (когда модуль frenchdeck2.py загружается и компилирует - ся) Python не проверяет, реализованы ли абстрактные методы. Это происхо- дит только на этапе выполнения, когда мы пытаемся создать объект FrenchDeck2 . И тогда, если абстрактный метод не реализован, мы получим исключение TypeError с сообщением вида «Can't instantiate abstract class FrenchDeck2 with abstract methods __delitem__, insert» . Вот поэтому мы и обязаны реализовать методы __ delitem__ и insert, хотя в наших примерах класс FrenchDeck2 в них и не нуждается; ничего не поделаешь – абстрактный базовый класс MutableSequence требует. Как показано на рис. 13.3, не все методы ABC Sequence и MutableSequence аб- страктны.426  Интерфейсы, протоколы и ABC\n--- Страница 426 ---\n* Новое в Python 3.6 Рис. 13.3. UML-диаграмма класса MutableSequence и его суперклассов из модуля collections. abc. Стрелки направлены от подклассов к суперклассам. Курсивом набраны имена абстракт - ных классов и методов Чтобы сделать FrenchDeck2 подклассом MutableSequence , пришлось реализовать методы __delitem__ и insert, которые в моих примерах не нужны. В награду за труды FrenchDeck2 наследует пять конкретных методов от Sequence: __contains__ , __iter__, __reversed__ , index и count. От MutableSequence он получает еще шесть мето- дов: append, reverse, extend, pop, remove и __iadd__; последний поддерживает оператор += для конкатенации на месте. Конкретные методы в каждом ABC из модуля collections.abc реализованы в терминах открытого интерфейса класса, поэтому для работы им не нужны никакие знания о внутренней структуре экземпляров. Кодировщику конкретного подкласса иногда приходится пере- определять методы, унаследованные от ABC, предоставляя бо- лее эффективную реализацию. Например, унаследованный ме- тод __contains__ просматривает всю последовательность, но если в конкретной последовательности элементы всегда отсортиро- ваны, то можно написать более быстрый вариант __contains__ , который будет производить двоичный поиск с помощью функ - ции bisect. См. раздел «Средства работы с упорядоченными последовательностями в модуле bisect» (https://www.fluentpython. com/extra/ordered-sequences-with-bisect/) на сайте fluentpython.com. Чтобы работать с ABC, нужно знать, что есть в нашем распоряжении. Далее мы рассмотрим ABC коллекций. ABc в СтандартнОй БиБлиО теке Начиная с версии Python 2.6 ABC включены в стандартную библиотеку. Боль- шая их часть определена в модуле collections.abc , но есть и другие. Например, ABC можно найти в пакетах numbers и io. Но самые употребительные находятся в collections.abc . В стандартной библиотеке есть два модуля с именем abc. Мы сейчас говорим о модуле collections.abc . Чтобы уменьшить время загрузки, в версии Python 3.4 он находится не в пакете collections , а в файле Lib/_collections_abc.py (https://github.com/ python/cpython/blob/main/Lib/_collections_abc.py), поэтому импор- тируется отдельно от collections . Другой модуль abc называется ABC в стандартной библиотеке  427\n--- Страница 427 ---\nпросто abc (т. е. Lib/abc.py – https://hg.python.org/cpython/file/3.4/Lib/ abc.py), в нем определен класс abc.ABC. Все ABC зависят от этого класса, но импортировать его самостоятельно нужно только при создании нового ABC. На рис. 13.4 приведена сокращенная UML-диаграмма классов (без имен атрибутов), на которой показаны все 17 ABC, определенных в модуле collections. abc. В официальной документации по модулю collections.abc имеется симпатич- ная таблица (https://docs.python.org/3/library/collections.abc.html#collections-abstract- base-classes), в которой перечислены ABC, их взаимосвязи, а также абстрактные и конкретные методы (так называемые «методы-примеси»). На рис. 13.4 мы видим немало примеров множественного наследования. Множественному на- следованию посвящена большая часть главы 14, а пока скажем лишь, что в слу - чае абстрактных базовых классов оно обычно не составляет проблемы1. * Новое в Python 3.6 Рис. 13.4. UML-диаграмма абстрактных базовых классов из модуля collections.abc Коротко рассмотрим группы классов на рис. 13.4. Iterable , Container , Sized Любая коллекция должна либо наследовать этим ABC, либо реализовы- вать совместимые протоколы. Класс Iterable поддерживает итерирование методом __iter__, Container поддерживает оператор in методом __contains__ , а Sized – функцию len() методом __len__. Collection У этого ABC нет собственных методов, но он был добавлен в версию Python 3.6, чтобы было проще создавать подклассы, наследующие Iterable, Container и Sized. 1 Множественное наследование было сочтено вредным и исключено из языка Java. Ис- ключение было сделано для интерфейсов: в Java интерфейс может расширять не- сколько интерфейсов, а класс – реализовывать несколько интерфейсов.428  Интерфейсы, протоколы и ABC\n--- Страница 428 ---\nSequence , Mapping , Set Это основные типы неизменяемых коллекций, и у каждого есть изменя- емый подкласс. Детальная диаграмма класса MutableSequence показана на рис. 13.2, а диаграммы классов MutableMapping и MutableSet приведены в главе 3 (рис. 3.1 и 3.2). MappingView В Python 3 объекты, возвращенные методами отображения .items(), .keys() и .values(), наследуют классам ItemsView, KeysView и ValuesView соответственно. Пер- вые два также наследуют богатый интерфейс класса Set со всеми операторами, которые были описаны в разделе «Операции над множествами» главы 3. Iterator Отметим, что класс Iterator является подклассом Iterable. Мы еще вернемся к этому вопросу в главе 17. Callable , Hashable Это не коллекции, но collections.abc был первым пакетом в стандартной биб- лиотеке, где были определены ABC, а эти два класса казались достаточно важными, чтобы включить их. Их основное назначение – поддержка провер- ки типов объектов, которые должны быть вызываемыми или хешируемыми. Чтобы определить, является ли объект вызываемым, удобнее воспользо- ваться встроенной функцией callable(obj) , чем писать insinstance(obj, Callable) . Если insinstance(obj, Hashable) возвращает False, то можно точно сказать, что obj не хешируемый. Но если она возвращает True, то возможен ложноположитель- ный результат. В следующей врезке объясняется, почему. Функция isinstance для Hashable и Iterable может вводить в заблуждение Результаты применения isinstance и issubclass к ABC Hashable и Iterable легко интерпретировать неправильно. Если isinstance(obj, Hashable) возвращает True, то это лишь означает, что класс obj реализует или наследует метод __hash__. Но если obj является кортежем tuple, содержащим нехешируемые элементы, то obj не является хешируемым, несмотря на положительный результат про- верки с помощью isinstance . Технический рецензент Юрген Гмах указал, что утиная типизация дает самый надежный способ определить, является ли эк- земпляр хешируемым: вызвать hash(obj). Этот вызов приведет к исключению TypeError, если obj не хешируемый. С другой стороны, даже если isinstance(obj, Iterable) возвращает False, у Python все равно остается возможность обойти obj с помощью метода __getitem__ , кото - рый применяется для получения элементов с индексами, начиная с 0. Мы ви- дели, как это делается в главе 1 и в разделе «Python в поисках следов последо- вательностей». В документации по классу collections.abc.Iterable говорится: Единственно надежный способ определить, является ли объект ите- рируемым, – вызвать iter(obj) . ABC в стандартной библиотеке  429\n--- Страница 429 ---\nПознакомившись с некоторыми имеющимися ABC, попрактикуемся в гусиной типизации, для чего реализуем ABC с нуля и воспользуемся им. Цель не в том, чтобы очертя голову бросаться писать ABC, а в том, чтобы научиться читать ис- ходный код ABC, находящихся в стандартной библиотеке и в других пакетах. Определение и иСпО льзОвание ABc Следующее предупреждение присутствовало в главе «Интерфейсы» первого издания книги: ABC, подобно дескрипторам и метаклассам, предназначены для разра- ботки каркасов. Поэтому лишь малая часть пишущих на Python может создавать ABC, не налагая ненужных ограничений на своих коллег-про- граммистов и не заставляя их делать бессмысленную работу. Теперь у ABC появились дополнительные возможности применения в ан- нотациях типов для поддержки статической типизации. В разделе «Абстракт - ные базовые классы» главы 8 мы уже говорили, что использование ABC вместо конкретных типов для аннотирования типов аргументов функции дает больше гибкости вызывающей стороне. Чтобы оправдать создание абстрактного базового класса, нам необходим контекст для использования его в качестве точки расширения в каком-то кар- касе. Возьмем такой контекст: пусть требуется отображать на сайте или в мо- бильном приложении рекламные объявления в случайном порядке, но при этом не повторять никакое объявление, пока не будут показаны все остальные из имеющегося набора. Допустим, мы разрабатываем систему управления рек- ламой под названием ADAM. Одно из требований – поддержать предоставляемые пользователем классы случайного выбора без повторений1. Чтобы у пользова- телей ADAM не было сомнений, что понимается под «случайным выбором без повторений», мы определим ABC. В литературе по структурам данных «стек» и «очередь» описывают абстракт - ные интерфейсы в терминах физической организации объектов. Я последую этой традиции и назову наш ABC, руководствуясь следующей метафорой из реального мира: барабаны для бинго и лотереи – это машины, предназначен- ные для случайного выбора элемента из конечного множества, без повторе- ний, до полного исчерпания множества. Наш ABC будет называться Tombola, это итальянское название игры в бинго и опрокидывающегося контейнера, в котором перемешиваются номера. В ABC Tombola определены четыре метода. Два из них абстрактны: .load(…) Поместить элементы в контейнер. .pick() Извлечь случайный элемент из контейнера и вернуть его. И есть еще два конкретных метода: 1 Быть может, клиент захочет подвергнуть рандомизатор аудиту или рекламное агент - ство решит предоставить какой-то особо хитрый рандомизатор. Заранее никогда не скажешь…430  Интерфейсы, протоколы и ABC\n--- Страница 430 ---\n.loaded() Вернуть True, если в контейнере имеется хотя бы один элемент. .inspect() Вернуть кортеж tuple, составленный из элементов, находящихся в контейнере, не изменяя его содержимого (внутреннее упорядочение не сохраняется). На рис. 13.5 показан ABC Tombola и три его конкретные реализации. Рис. 13.5. UML-диаграмма ABC и трех его подклассов. Имена класса Tombola и его абстракт - ных методов набраны курсивом в соответствии с соглашениями UML. Пунктирная стрелка обозначает реализацию интерфейса, здесь она показывает, что TomboList не только реализу- ет интерфейс Tombola , но и зарегистрирован в качестве виртуального подкласса Tombola , как мы увидим ниже в этой главе1 В примере 13.7 показано определение ABC Tombola. Пример 13.7. tombola.py: Tombola – ABC с двумя абстрактными и двумя конкретными методами import abc class Tombola(abc.ABC):  @abc.abstractmethod def load(self, iterable):  \"\"\"Добавить элементы из итерируемого объекта.\"\"\" @abc.abstractmethod def pick(self):  \"\"\"Удалить случайный элемент и вернуть его. Этот метод должен возбуждать исключение `LookupError`, если объект пуст. \"\"\" 1 «registered» и «virtual subclass» – нестандартные термины UML. Мы пользуемся ими, чтобы показать взаимосвязи между классами, специфичные для Python. Определение и использование ABC  431\n--- Страница 431 ---\ndef loaded(self):  \"\"\"Вернуть `True`, если есть хотя бы 1 элемент, иначе `False`.\"\"\" return bool(self.inspect())  def inspect(self): \"\"\"Вернуть отсортированный кортеж, содержащий оставшиеся в данный момент элементы. \"\"\" items = [] while True:  try: items.append(self.pick()) except LookupError: break self.load(items)  return tuple(items)  Чтобы определить ABC, создаем подкласс abc.ABC.  Абстрактный метод помечен декоратором @abstractmethod , и зачастую его тело содержит только строку документации1.  Строка документации сообщает программисту, реализующему метод, что в случае отсутствия элементов нужно возбудить исключение LookupError .  ABC может содержать конкретные методы.  Конкретные методы ABC должны зависеть только от открытого интерфей- са данного ABC (т. е. от других его конкретных или абстрактных методов или свойств).  Мы не знаем, как в конкретных подклассах будут храниться элементы, но можем построить результат inspect, опустошив объект Tombola с помощью последовательных обращений к .pick()…  … а затем с помощью .load(…) вернуть все элементы обратно. У абстрактного метода может существовать реализация. Но даже если так, подклассы все равно обязаны переопределить его, од- нако имеют право вызывать абстрактный метод с помощью функции super(), расширяя имеющуюся функциональность, вместо того чтобы реализовывать ее с нуля. Информацию о де- талях использования декоратора @abstractmethod см. в докумен- тации по модулю abc (https://docs.python.org/3/library/abc.html). Метод .inspect() в примере 13.7, пожалуй, надуманный, но он показывает, что, имея всего лишь методы .pick() и .load(…), мы можем узнать, что находится внутри Tombola: для этого сначала нужно извлечь все элементы по одному, а за- тем загрузить их обратно. Мы хотели этим подчеркнуть, что в предоставлении конкретных методов ABC нет ничего плохого, при условии что они зависят только от других методов интерфейса. Конкретные подклассы Tombola, знаю- 1 До появления ABC абстрактные методы обычно возбуждали исключение NotImplementedError , показывающее, что за реализацию отвечают подклассы. В Smalltalk-80 тела абстрактных методов вызывали бы метод subclassResponsibility , унаследованный от object, который породил бы сообщение об ошибке «Мой подкласс должен был бы переопределить одно из моих сообщений». 432  Интерфейсы, протоколы и ABC\n--- Страница 432 ---\nщие о своих внутренних структурах данных, всегда могут подменить .inspect() более эффективной реализацией, но не обязаны это делать. Метод .loaded() в примере 13.7 содержит всего одну строку, но обходится до- рого: он строит отсортированный кортеж с помощью .inspect() только для того, чтобы применить к нему функцию bool(). Этот способ работает, но конкретный класс может поступить гораздо лучше, как мы вскоре увидим. Отметим, что в нашей «карусельной» реализации .inspect() обязательно перехватывать исключение LookupError , которое возбуждает метод self.pick() . Тот факт, что self.pick() может возбуждать исключение LookupError , составляет часть его интерфейса, но объявить это в Python можно только в документации (см. строку документации абстрактного метода pick в примере 13.7.) Я выбрал исключение LookupError из-за его места в иерархии исключений в Python по отношению к IndexError и KeyError – исключениям, которые, ско- рее всего, будут возбуждать операции со структурами данных в конкретных подклассах Tombola. Таким образом, реализация может возбуждать исключе- ние LookupError , IndexError , KeyError или пользовательского подкласса LookupError . См. рис. 13.6. BaseException ├── SystemExit ├── KeyboardInterrupt ├── GeneratorExit └── Exception ├── StopIteration ├── ArithmeticError │ ├── FloatingPointError │ ├── OverflowError │ └── ZeroDivisionError ├── AssertionError ├── AttributeError ├── BufferError ├── EOFError ├── ImportError ├── LookupError  │ ├── IndexError  │ └── KeyError  ├── MemoryError и т. д. Определение и использование ABC  433\n--- Страница 433 ---\nРис. 13.6. Часть иерархии классов Exception1  LookupError – исключение, обрабатываемое в методе Tombola.inspect .  IndexError – подкласс LookupError , это исключение возбуждается при попыт - ке получить из последовательности элемент с индексом, большим индекса последнего элемента.  Исключение KeyError возбуждается при обращении к несуществующему ключу отображения. Вот мы и создали собственный ABC Tombola. Чтобы посмотреть, как произ- водится проверка интерфейса ABC, попробуем обмануть Tombola, предоставив дефектную реализацию. Пример 13.8. Непригодная реализация Tombola не останется незамеченной >>> from tombola import Tombola >>> class Fake(Tombola):  def pick(self): return 13 >>> Fake  <class '__main__.Fake'> >>> f = Fake()  Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: Can't instantiate abstract class Fake with abstract method load 1 Полное дерево приведено в разделе 5.4 «Иерархия исключений» справочного руко- водства по стандартной библиотеке Python.434  Интерфейсы, протоколы и ABC\n--- Страница 434 ---\n Объявить Fake подклассом Tombola.  Класс создан, пока никаких ошибок.  При попытке создать экземпляр класса Fake возникает исключение TypeError. Сообщение не оставляет сомнений: класс Fake считается абстрактным, по- тому что в нем не реализован метод load – один из абстрактных методов, объявленных в ABC Tombola. Итак, мы написали свой первый ABC и проверили, как контролируется его корректность. Скоро мы создадим подкласс Tombola, но сначала поговорим о не- которых правилах программирования ABC. Синтаксические детали ABC Лучший способ объявить ABC – сделать его подклассом abc.ABC или какого-ни- будь другого ABC. Помимо базового класса ABC и декоратора @abstractmethod , в модуле abc опреде- лены декораторы @abstractclassmethod , @abstractstaticmethod и @abstractproperty . Одна - ко последние три объявлены нерекомендованными в версии Python 3.3, после того как стало возможно указывать другие декораторы поверх @abstractmethod , так что все прочие оказались избыточными. Например, вот как рекомендуется объявлять абстрактный метод класса: class MyABC(abc.ABC): @classmethod @abc.abstractmethod def an_abstract_classmethod(cls, ): pass Порядок декораторов функции в композиции обычно важен, а в случае abstractmethod документация не оставляет никаких со- мнений: Если abstractmethod() применяется в сочетании с другими дескрипторами метода, он должен быть самым внутренним декоратором…1 Иными словами, между @abstractmethod и предложением def не должно быть никаких других декораторов. Обсудив синтаксические детали ABC, опробуем Tombola на практике, реализо- вав несколько его конкретных подклассов. Создание подклассов ABC Имея ABC Tombola, мы теперь разработаем два конкретных подкласса, согласо- ванных с его интерфейсом. Они были изображены на рис. 13.5 вместе с вирту - альными подклассами, которые будут рассмотрены в следующем разделе. Класс BingoCage в примере 13.9 – это вариант примера 7.8 с более качествен- ным рандомизатором. В нем реализованы обязательные абстрактные методы load и pick. 1 Раздел @abc.abstractmethod (https://docs.python.org/dev/library/abc.html#abc.abstractmethod) документации по модулю abc. Определение и использование ABC  435\n--- Страница 435 ---\nПример 13.9. bingo.py: BingoCage – конкретный подкласс Tombola import random from tombola import Tombola class BingoCage(Tombola):  def __init__(self, items): self._randomizer = random.SystemRandom()  self._items = [] self.load(items)  def load(self, items): self._items.extend(items) self._randomizer.shuffle(self._items)  def pick(self):  try: return self._items.pop() except IndexError: raise LookupError('pick from empty BingoCage') def __call__(self):  self.pick()  Этот класс BingoCage явно расширяет Tombola.  Качества класса random.SystemRandom достаточно для программирования азарт - ных игр в сети, он реализует API random, пользуясь функцией os.urandom(…) , которая возвращает случайные байты, «пригодные для использования в криптографических приложениях» (документация по модулю os, http:// docs.python.org/3/library/os.html#os.urandom).  Делегировать начальную загрузку методу .load(…).  Вместо функции random.shuffle() использовать метод .shuffle() нашего экзем- пляра SystemRandom .  Метод pick реализован, как в примере 7.8.  Метод __call__ также заимствован из примера 7.8. Для согласованности с интерфейсом Tombola он не нужен, но дополнительные методы никакого вреда не принесут. BingoCage наследует накладный метод loaded и простодушный метод inspect от Tombola. Тот и другой можно переопределить гораздо более быстрыми одно- строчными методами, как в примере 13.10. Но хочу подчеркнуть: мы можем не утруждать себя и просто унаследовать неоптимальные конкретные методы от ABC. Методы, унаследованные от Tombola, работают не так быстро, как могли бы в BingoCage, но дают правильные результаты для любого подкласса Tombola, в котором корректно реализованы методы pick и load. В примере 13.10 показана совершенно другая, но тоже корректная реали- зация интерфейса Tombola. Вместо перетасовывания «шаров» и выталкивания последнего класс LotteryBlower выбирает элемент в случайной позиции.436  Интерфейсы, протоколы и ABC\n--- Страница 436 ---\nПример 13.10. lotto.py: LotteryBlower – конкретный подкласс, в котором переопределе- ны методы inspect и loaded ABC Tombola import random from tombola import Tombola class LottoBlower(Tombola): def __init__(self, iterable): self._balls = list(iterable)  def load(self, iterable): self._balls.extend(iterable) def pick(self): try: position = random.randrange(len(self._balls))  except ValueError: raise LookupError('pick from empty LottoBlower') return self._balls.pop(position)  def loaded(self):  return bool(self._balls) def inspect(self):  return tuple(self._balls)  Инициализатор принимает произвольный итерируемый объект, аргумент используется для построения списка.  Функция random.randrange( ) возбуждает исключение ValueError , если диапазон пуст, мы перехватываем его и возбуждаем взамен исключение LookupError , сохраняя совместимость с ABC Tombola.  В противном случае из self._balls выбирается случайный элемент.  Перегрузить метод loaded, чтобы не вызывать inspect (как в методе Tombola. loaded из примера 13.7). Мы можем ускорить его, работая непосредственно с self._balls , – нет необходимости строить заново весь кортеж.  Перегрузить метод inspect, новый код состоит всего из одной строки. В примере 13.10 иллюстрируется достойная отдельного упоминания идио- ма: в методе __init__ в атрибуте self._balls сохраняется list(iterable) , а не просто ссылка на iterable (т. е. мы не просто присваиваем iterable атрибуту self._balls ). Как отмечалось в разделе «Защитное программирование и принцип быстрого отказа» выше, это повышает гибкость класса LotteryBlower , потому что аргумент iterable может быть произвольным итерируемым объектом. Однако элементы из него сохраняются во внутреннем списке, так что нам доступен метод pop. И даже если в аргументе iterable всегда передается список, вызов list(iterable) создает копию аргумента, и это хорошо, поскольку мы удаляем из списка эле- менты, а клиент может не ожидать, что переданный ему список изменится1. 1 Раздел «Защитное программирование при наличии изменяемых параметров» гла- вы 6 посвящен проблеме псевдонимии, которую мы здесь счастливо избежали. Определение и использование ABC  437\n--- Страница 437 ---\nТеперь мы подходим к важнейшей динамической особенности гусиной ти- пизации: объявлению виртуальных подклассов методом register. Виртуальный подкласс T ombola Важнейшая характеристика гусиной типизации, благодаря которой она и за- служила «водоплавающее» имя, – возможность регистрировать класс как вир- туальный подкласс ABC, даже без наследования. При этом мы обещаем, что класс честно реализует интерфейс, определенный в ABC, а Python верит нам на слово, не производя проверку. Если мы соврем, то будем наказаны исклю- чением во время выполнения. Это делается путем вызова метода register абстрактного базового класса. В результате зарегистрированный класс становится виртуальным подклассом ABC и распознается в качестве такового функцией issubclass , однако не насле- дует ни методы, ни атрибуты ABC. Виртуальные подклассы не наследуют ABC, для которых зарегист- рированы. Их согласованность с интерфейсом ABC не проверяет - ся никогда, даже в момент создания экземпляра. Кроме того, про- граммы статической проверки типов не могут обработать вирту - альные подклассы. Детали см. в проблеме Mypy 2922 «ABCMeta. register support» (https://github.com/python/mypy/issues/2922). Метод register чаще всего вызывается как обычная функция (см. раздел «Ис- пользование функции register на практике» ниже), но может использоваться и как декоратор. В примере 13.11 мы применяем синтаксис декоратора и реа- лизуем TomboList, виртуальный подкласс Tombola, изображенный на рис. 13.7. Рис. 13.7. UML-диаграмма классов для TomboList , настоящего подкласса list и виртуального подкласса Tombola 438  Интерфейсы, протоколы и ABC\n--- Страница 438 ---\nПример 13.11. tombolist.py: TomboList – виртуальный подкласс Tombola from random import randrange from tombola import Tombola @Tombola.register  class TomboList(list):  def pick(self): if self:  position = randrange(len(self)) return self.pop(position)  else: raise LookupError('pop from empty TomboList') load = list.extend  def loaded(self): return bool(self)  def inspect(self): return tuple(self) # Tombola.register(TomboList)   Tombolist зарегистрирован как виртуальный подкласс Tombola.  Tombolist расширяет list.  Tombolist наследует от list метод __bool__, который возвращает True, если спи- сок не пуст.  Наш метод pick вызывает метод self.pop, унаследованный от list, передавая ему индекс случайного элемента.  Tombolist.load – то же самое, что list.extend .  Метод loaded делегирует работу методу bool1.  Вызывать метод register таким образом можно всегда, и это полезно, когда нужно зарегистрировать класс, который сопровождаете не вы, но который согласован с интерфейсом. Отметим, что благодаря регистрации функции issubclass и isinstance считают, что TomboList – подкласс Tombola: >>> from tombola import Tombola >>> from tombolist import TomboList >>> issubclass(TomboList, Tombola) True >>> t = TomboList(range(100)) >>> isinstance(t, Tombola) True 1 Прием, использованный в методе load(), для loaded() работать не будет, потому что в типе list не реализован метод __bool__, который я хотел бы связать с loaded. С другой стороны, встроенная функция bool() не нуждается в методе __bool__, потому что может использо- вать также метод __len__. См. раздел 4.1 «Проверка значения истинности» главы «Встро- енные типы» документации по Python (https:// docs.python.org/3/library/stdtypes.html#truth). Определение и использование ABC  439\n--- Страница 439 ---\nОднако наследование управляется специальным атрибутом класса __mro__ – Method Resolution Order (порядок разрешения методов). По существу, в нем перечисляются класс и его суперклассы в том порядке, в котором Python про- сматривает их в поисках методов1. Если вывести атрибут __mro__ класса TomboList, то мы увидим в нем только «настоящие» суперклассы – list и object: >>> TomboList.__mro__ (<class 'tombolist.TomboList'>, <class 'list'>, <class 'object'>) Класса Tombola в списке TomboList.__mro__ нет, поэтому TomboList не наследует ни одного метода от Tombola. На этом завершается изучение ABC Tombola. В следующем разделе мы рассмот- рим, как функция ABC register используется на практике. иСпОльзОвание функции register на практике В примере 13.11 мы использовали Tombola.register в качестве декоратора класса. В версиях, предшествующих Python 3.3, такое использование register запре- щено – ее следует вызывать как обычную функцию после определения класса (см. комментарий в примере 13.11). Однако, несмотря на то что теперь register можно использовать как декоратор, чаще она применяется как функция для регистрации классов, определенных где-то в другом месте. Например, в исход- ном коде модуля collections.abc (https://github.com/python/cpython/blob/0bbf30e2b9 10bc9c5899134ae9d 73a8df968da35/Lib/_collections_abc.py) встроенные типы tuple, str, range и memoryview зарегистрированы как виртуальные подклассы Sequence: Sequence.register(tuple) Sequence.register(str) Sequence.register(range) Sequence.register(memoryview) Еще несколько встроенных типов зарегистрированы как подклассы ABC, со- держащихся в файле _collections_abc.py. Эти регистрации производятся только при импорте указанного файла, но это нормально, потому что для получения самих ABC модуль так или иначе необходимо импортировать. Например, что- бы выполнить проверку isinstance(my_dict, MutableMapping) , необходимо иметь до- ступ к классу MutableMapping из модуля collections.abc . И наследование ABC, и регистрация в качестве виртуального подклас - са ABC – явные способы сделать так, чтобы проходили проверки с помощью функции issubclass , а равно и проверки с помощью функции isinstance , которая опирается на issubclass . Но некоторые ABC поддерживают также структурную типизацию. Ниже объясняется, что это такое. ABC и структурная типизация ABC чаще всего используются в сочетании с номинальной типизацией. Когда класс Sub явно наследует AnABC или регистрируется в качестве виртуального под- класса AnABC, имя AnABC связывается с классом Sub, именно поэтому во время вы- полнения вызов issubclass(AnABC, Sub) возвращает True. 1 Ниже целый раздел «Множественное наследование и порядок разрешения методов» посвящен атрибуту класса __mro__. А пока нам хватит и краткого объяснения.440  Интерфейсы, протоколы и ABC\n--- Страница 440 ---\nНапротив, структурная типизация подразумевает изучение структуры от- крытого интерфейса объекта с целью определить его тип: объект совместим с типом, если он реализует все методы, определенные в типе1. Динамическая и статическая утиные типизации – два подхода к структурной типизации. Оказывается, что некоторые ABC также поддерживают структурную типи- зацию. В своем эссе «Водоплавающие птицы и ABC» Алекс Мартелли показы- вает, что класс может быть распознан как виртуальный подкласс ABC даже без регист рации. Приведем еще раз его пример, добавив проверку с использова- нием функции issubclass : >>> class Struggle: … def __len__(self): return 23 … >>> from collections import abc >>> isinstance(Struggle(), abc.Sized) True >>> issubclass(Struggle, abc.Sized) True Функция issubclass (а значит, и isinstance ) считает класс Struggle подклассом abc. Sized, потому что abc.Sized реализует специальный метод класса __subclasshook__ . Метод __subclasshook__ в классе Sized проверяет, имеет ли переданный в аргу - менте класс атрибут с именем __len__. Если да, то класс считается виртуальным подклассом Sized. См. пример 13.12. Пример 13.12. Определение класса Sized из файла Lib/_collections_abc.py (https://github.com/ python/cpython/blob/0fbddb14dc03f61738af01af88e7d8aa8df07336/Lib/_collections_abc.py#L369) class Sized(metaclass=ABCMeta): __slots__ = () @abstractmethod def __len__(self): return 0 @classmethod def __subclasshook__(cls, C): if cls is Sized: if any(\"__len__\" in B.__dict__ for B in C.__mro__):  return True  return NotImplemented   Если в словаре __dict__ любого класса, перечисленного в C.__mro__ (т. е. C и его суперклассах), существует атрибут с именем __len__ …  … то вернуть True, сигнализируя о том, что C – виртуальный подкласс Sized.  Иначе вернуть NotImplemented , чтобы продолжить проверку подкласса. 1 Концепция совместимости типов объяснялась в разделе «“Является подтипом” и “со- вместим с”» главы 8. Использование функции register на практике  441\n--- Страница 441 ---\nЕсли вас интересуют детали проверки подкласса, загляните в ис- ходный код метода ABCMeta.__subclasscheck__ в файле Lib/abc.py (https://github.com/python/cpython/ blob/c0a9afe2ac1820409e6173bd189 3ebee2cf50270/Lib/abc.py#L196). Предупреждение: в этом коде уйма if’ов и два рекурсивных вызова. В Python 3.7 Иван Левкивский и Инада Наоки переписали на C большую часть модуля abc, что- бы повысить производительность. См. проблему Python #31333 (https://bugs.python.org/issue31333). Текущая реализация ABCMeta.__ subclasscheck__ просто вызывает _abc_subclasscheck . Относящийся к делу исходный код на C находится в файле cpython/Modules/_ abc.c#L605 ( https://github.com/python/cpython/blob/3635388f52b42e52 80229104747962117104c453/Modules/_abc.c#L605). Вот так метод __subclasshook__ позволяет ABC поддержать структурную ти- пизацию. Несмотря на наличие формального определения интерфейса в ABC и скрупулезных проверок, осуществляемых функцией isinstance , в определен- ных контекстах вполне можно использовать никак не связанный с ABC класс просто потому, что в нем реализован определенный метод (или потому, что он постарался убедить __subclasshook__ , что за него можно поручиться). Следует ли реализовывать __subclasshook__ в своих собственных ABC? Пожа- луй, нет. Все реализации __subclasshook__ , которые я встречал в исходном коде Python, находятся в ABC типа Sized, где объявлен только один специальный ме- тод, и они просто проверяют имя этого метода. Учитывая «специальный» ста- тус таких методов, можно с некоторой долей уверенности предположить, что любой метод с именем __len__ делает именно то, чего вы от него ожидаете. Но, даже не выходя за пределы специальных методов и фундаментальных ABC, делать такие предположения рискованно. Например, все отображения реали- зуют методы __len__, __getitem__ и __iter__, но они справедливо не считаются под- типами Sequence, поскольку не позволяют получить элемент по целочисленному смещению или срезу. Именно поэтому класс abc.Sequence не реализует метод __subclasshook__ . Для тех же ABC, которые могли бы написать вы или я, полагаться на метод __subclasshook__ еще более рискованно. Лично я не готов поверить, что класс с именем Spam, который реализует или наследует методы load, pick, inspect и loaded, гарантированно ведет себя как Tombola. Пусть уж лучше программист явно под- твердит это, сделав Spam подклассом Tombola или хотя бы зарегистрировав его: Tombola.register(Spam) . Конечно, ваш метод __subclasshook__ мог бы еще проверить сигнатуры методов и другие свойства, но не думаю, что оно того стоит. СтатичеСкие прОтОкОлы Впервые речь о статических протоколах заходила в разделе «Статические протоколы» главы 8. Я подумывал о том, что- бы вообще отложить рассмотрение протоколов до этой главы, но потом решил, что введение в аннотации типов в функциях не может обойтись без протоколов, потому утиная типизация – неотъемлемая часть Python, а статическая проверка типов без протоколов не очень хорошо справляется с питоническими API. 442  Интерфейсы, протоколы и ABC\n--- Страница 442 ---\nМы завершим эту главу иллюстрацией статических протоколов на двух прос тых примерах, а также обсудим числовые ABC и протоколы. Для начала покажем, как статический протокол позволяет аннотировать и проверить тип функции double(), которую мы уже встречали в разделе «Типы определяются тем, какие операции они поддерживают» главы 8. Типизированная функция double Рассказывая о Python программистам, привыкшим к статически типизирован- ным языкам, я люблю приводить в пример следующую простую функцию double: >>> def double(x): return x * 2 >>> double(1.5) 3.0 >>> double('A') 'AA' >>> double([10, 20, 30]) [10, 20, 30, 10, 20, 30] >>> from fractions import Fraction >>> double(Fraction(2, 5)) Fraction(4, 5) До появления статических протоколов не существовало способа добавить аннотации типов к double, не ограничивая возможностей ее применения1. Благодаря утиной типизации double будет работать даже с типами, которых пока не существует, например с улучшенным классом Vector, с которым мы по- знакомимся в разделе «Перегрузка оператора * для скалярного умножения» (глава 16). >>> from vector_v7 import Vector >>> double(Vector([11.0, 12.0, 13.0])) Vector([22.0, 24.0, 26.0]) Первоначальная реализация аннотаций типов в Python была основана на номинальной системе типов: имя типа в аннотации должно было совпадать с именем типа фактического аргумента или с именем одного из его суперклас - сов. Поскольку невозможно поименовать все типы, которые реализуют про- токол путем поддержки требуемых операций, утиную типизацию нельзя было описать с помощью аннотаций типов до версии Python 3.8. Теперь благодаря классу typing.Protocol мы можем сообщить Mypy, что double принимает аргумент x, поддерживающий операцию x * 2. В примере 13.13 по- казано, как именно. 1 Ну хорошо, double() полезна разве что в качестве примера. Но в стандартной биб- лиотеке Python много функций, которые нельзя было правильно аннотировать до включения статических протоколов в Python 3.8. Я помогал исправлять пару ошибок в typeshed путем добавления аннотаций типов с применением протоколов. Напри- мер, в запросе на включение, который исправлял ошибку «Должна ли Mypy предуп- реждать о потенциально недопустимых аргументах max?» (https://github.com/python/ typeshed/issues/4051) был задействован протокол _SupportsLessThan , который я исполь- зовал для улучшения аннотаций max, min, sorted и list.sort . Статические протоколы  443\n--- Страница 443 ---\nПример 13.13. double_protocol.py: определение double с использованием Protocol from typing import TypeVar, Protocol T = TypeVar('T')  class Repeatable(Protocol): def __mul__(self: T, repeat_count: int) -> T:  RT = TypeVar('RT', bound=Repeatable)  def double(x: RT) -> RT:  return x * 2  Мы будем использовать этот тип T в сигнатуре __mul__.  __mul__ – существо протокола Repeatable . Параметр self обычно не аннотиру - ется – предполагается, что его тип – сам класс. Здесь мы используем T, что- бы тип результата гарантированно совпадал с типом self. Отметим также, что в этом протоколе repeat_count может иметь только тип int.  Протокол Repeatable связывает переменную-тип RT: средство проверки ти- пов потребует, чтобы фактический тип реализовывал Repeatable .  Теперь средство проверки типов может проверить, что параметр x являет - ся объектом, который можно умножать на целое число, и при этом полу - чается значение того же типа, что и x. Этот пример объясняет, почему документ PEP 544 (https://peps.python.org/ pep-0544/) назван «Protocols: Structural subtyping (static duck typing)» (Протоколы: структурная подтипизация (статическая утиная типизация)). Номинальный тип фактического аргумента x, переданного double, не играет роли, коль скоро он умеет квакать – т. е. реализует метод __mul__. Статические протоколы, допускающие проверку во время выполнения На карте типизации (рис. 13.1) typing.Protocol располагается в области стати- ческой проверки – в нижней половине диаграммы. Но при определении под- класса typing.Protocol мы можем использовать декоратор @runtime_checkable , что- бы протокол поддерживал проверки с помощью функций isinstance/issubclass во время выполнения. Это работает, потому что typing.Protocol – абстрактный базовый класс, а значит, поддерживает метод __subclasshook__ , с которым мы встречались в разделе «Структурная типизация с помощью ABC» выше. В версии Python 3.9 модуль typing включает семь готовых к использованию протоколов, допускающих проверку во время выполнения. Мы упомянем два из них, процитировав описание из документации по модулю typing (https:// docs.python.org/3/library/typing.html#protocols): class typing.SupportsComplex ABC с одним абстрактным методом, __complex__ . class typing.SupportsFloat ABC с одним абстрактным методом, __float__.444  Интерфейсы, протоколы и ABC\n--- Страница 444 ---\nЭти протоколы предназначены для проверки числовых типов на «конверти- руемость»: если объект o реализует метод __complex__ , то вызов complex(o) должен вернуть число типа complex, потому что специальный метод __complex__ как раз и существует для поддержки встроенной функции complex(). В примере 13.14 приведен исходный код протокола typing.SupportsComplex . Пример 13.14. Исходный код протокола typing.SupportsComplex @runtime_checkable class SupportsComplex(Protocol): \"\"\"ABC с одним абстрактным методом __complex__.\"\"\" __slots__ = () @abstractmethod def __complex__(self) -> complex: pass Ключом является абстрактный метод __complex__1. В процессе статической про- верки типов объект будет считаться совместимым с протоколом SupportsComplex , если он реализует метод __complex__ , принимающий только аргумент self и воз- вращающий complex. Благодаря применению декоратора класса @runtime_checkable к SupportsComplex этот протокол теперь можно использовать в сочетании с функцией isinstance , как показано в примере 13.15. Пример 13.15. Использование SupportsComplex во время выполнения >>> from typing import SupportsComplex >>> import numpy as np >>> c64 = np.complex64(3+4j)  >>> isinstance(c64, complex)  False >>> isinstance(c64, SupportsComplex)  True >>> c = complex(c64)  >>> c (3+4j) >>> isinstance(c, SupportsComplex)  False >>> complex(c) (3+4j)  complex64 – один из пяти комплексных числовых типов в NumPy.  Ни один из комплексных типов NumPy не является подклассом встроенно- го типа complex.  Но все они реализуют метод __complex__ , поэтому согласованы с протоколом SupportsComplex .  Поэтому мы можем создавать их них объекты встроенного типа complex.  К сожалению, встроенный тип complex не реализует метод __complex__ , хотя complex(c) успешно работает, если c имеет тип complex. 1 Атрибут __slots__ к текущему обсуждению не имеет отношения – это оптимизация, которая была рассмотрена в разделе «Экономия памяти с помощью атрибута класса __slots__ » главы 11. Статические протоколы  445\n--- Страница 445 ---\nПоследний пункт, в частности, означает, что если мы хотим проверить, вер- но ли, что объект c имеет тип complex или SupportsComplex , то можем предоставить кортеж типов в качестве второго аргумента isinstance : isinstance(c, (complex, SupportsComplex)) Альтернатива – воспользоваться ABC Complex, определенным в модуле numbers. Встроенный тип complex, а также типы NumPy complex64 и complex128 зарегистрирова- ны как виртуальные подклассы numbers.Complex , поэтому следующий код работает: >>> import numbers >>> isinstance(c, numbers.Complex) True >>> isinstance(c64, numbers.Complex) True В первом издании книги я рекомендовал использовать абстрактные базо- вые классы из пакета numbers, но теперь мой совет утратил актуальность, потому что эти ABC не распознаются средствами статической проверки типов, как мы увидим в разделе «ABC из пакета numbers и числовые протоколы». В этом разделе я хотел продемонстрировать, что протокол, допускающий проверку во время выполнения, работает с функцией isinstance , но, как объ- яснено во врезке «Утиная типизация – ваш друг», это не особенно хороший пример использования isinstance . Если вы пользуетесь внешним средством проверки типов, то явная проверка с помощью isinstance дает одно преимущество: встретив предложение if с условием вида isinstance(o, MyType) , Mypy может сделать вывод, что внутри блока if тип объекта o со- вместим с MyType. Утиная типизация – ваш друг Очень часто бывает, что во время выполнения утиная типизация – лучший подход к проверке типа: вместо того чтобы вызывать isinstance или hasattr, просто попробуйте выполнить над объектом нужную операцию и обработай- те исключения. Приведем конкретный пример. Вслед предыдущему обсуждению – дан объект o, который я хочу использовать как комплексное число, – можно подойти к решению следующим образом: if isinstance(o, (complex, SupportsComplex)): # сделать что-то, требующее, чтобы `o` можно было преобразовать в complex else: raise TypeError('o must be convertible to complex') Гусиная типизация подразумевала бы использование ABC numbers.Complex : if isinstance(o, numbers.Complex): # сделать что-то с `o`, экземпляром класса `Complex` else: raise TypeError('o must be an instance of Complex') Но я предпочитаю использовать утиную типизацию и принцип EAFP (it’s easier to ask for forgiveness than permission) – проще попросить прощения, чем испрашивать разрешения): 446  Интерфейсы, протоколы и ABC\n--- Страница 446 ---\ntry: c = complex(o) except TypeError as exc: raise TypeError('o must be convertible to complex') from exc А если вы в любом случае собирались возбудить исключение TypeError, то мож - но опустить предложения try/except/raise и просто написать: c = complex(o) В этом последнем случае, если o – недопустимый тип, Python возбудит ис- ключение с предельно ясным сообщением. Например, вот что я получу, если o имеет тип tuple: TypeError: complex() first argument must be a string or a number, not 'tuple' Мне кажется, что подход на основе утиной типизации в этом случае гораздо лучше. Итак, мы знаем, как использовать статические протоколы во время выпол- нения с такими уже имеющимися типами, как complex и numpy.complex64 . Теперь об- судим ограничения протоколов, допускающих проверку во время выполнения. Ограничения протоколов, допускающих проверку во время выполнения Мы видели, что в общем случае аннотации типов игнорируются во время вы- полнения, и это также влияет на проверки статических протоколов с помощью функций isinstance и issubclass . Например, любой класс, имеющий метод __float__, считается – на этапе вы- полнения – виртуальным подклассом SupportsFloat , даже если метод __float__ не возвращает значение типа float. Рассмотрим следующий консольный сеанс: >>> import sys >>> sys.version '3.9.5 (v3.9.5:0a7dcbdb13, May 3 2021, 13:17:02) \\n[Clang 6.0 (clang-600.0.57)]' >>> c = 3+4j >>> c.__float__ <method-wrapper '__float__' of complex object at 0x10a16c590> >>> c.__float__() Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: can't convert complex to float В Python 3.9 тип complex содержит метод __float__, но лишь для того, чтобы воз- будить исключение TypeError с понятным сообщением об ошибке. Если бы у ме- тода __float__ были аннотации, то тип возвращаемого значения был бы NoReturn – как мы видели в разделе «Тип NoReturn» главы 8. Но аннотирование типа complex.__float__ в typeshed не решило бы этой пробле- мы, потому что среда выполнения Python, вообще говоря, игнорирует аннота- ции типов – да и вообще не имеет доступа к файлам заглушек в typeshed. Статические протоколы  447\n--- Страница 447 ---\nПродолжим предыдущий сеанс в Python 3.9: >>> from typing import SupportsFloat >>> c = 3+4j >>> isinstance(c, SupportsFloat) True >>> issubclass(complex, SupportsFloat) True Мы имеем обескураживающий результат: проверка SupportsFloat во время выполнения говорит, что complex можно преобразовать в float, а на самом деле мы получаем ошибку типизации. Конкретная ошибка для типа complex была исправлена в Python 3.10.0b4 просто удалением метода complex.__float__ . Но общая проблема осталась: функции isinstance/issubclass смот- рят только на наличие или отсутствие методов, не проверяя их сигнатуры, а уж тем более аннотации типов. И такое положение дел не изменится, потому что подобные проверки типа во время выполнения повлекли бы за собой неприемлемые затраты1. Теперь посмотрим, как реализовать статический протокол в пользователь- ском классе. Поддержка статического протокола Вспомним класс Vector2d, разработанный в главе 11. Учитывая, что и комплекс - ное число, и экземпляр Vector2d состоят из двух чисел с плавающей точкой, име- ет смысл поддержать преобразование Vector2d в complex. В примере 13.16 приведена реализация метода __complex__ , дополняющего последнюю версию Vector2d из примера 11.11. Для полноты можно поддержать и обратную операцию с помощью метода класса fromcomplex , который строит эк- земпляр Vector2d из complex. Пример 13.16. vector2d_v4.py: метод преобразования в complex и обратно def __complex__(self): return complex(self.x, self.y) @classmethod def fromcomplex(cls, datum): return cls(datum.real, datum.imag)   Предполагается, что у datum есть атрибуты .real и .imag. Улучшенная реализа- ция будет приведена в примере 13.17. Имея этот код и метод __abs__, который уже был в версии Vector2d из приме- ра 11.11, мы получаем следующие свойства: 1 Спасибо Ивану Левкивскому, соавтору документа PEP 544 (о протоколах), который указал, что проверка типа не сводится к проверке того, что типом x является T: про- веряется, что тип x совместим с T, а это может быть дорого. Неудивительно, что Mypy требуется несколько секунд для проверки даже короткого Python-скрипта. 448  Интерфейсы, протоколы и ABC\n--- Страница 448 ---\n>>> from typing import SupportsComplex, SupportsAbs >>> from vector2d_v4 import Vector2d >>> v = Vector2d(3, 4) >>> isinstance(v, SupportsComplex) True >>> isinstance(v, SupportsAbs) True >>> complex(v) (3+4j) >>> abs(v) 5.0 >>> Vector2d.fromcomplex(3+4j) Vector2d(3.0, 4.0) С точки зрения проверки типа во время выполнения, пример 13.16 годится, но для более полного покрытия программами статической проверки типов и бо- лее понятных сообщений об ошибках со стороны Mypy методы __abs__, __complex__ и fromcomplex должны иметь аннотации типов, как показано в примере 13.17. Пример 13.17. vector2d_v5.py: добавление аннотаций в интересующие нас методы def __abs__(self) -> float:  return math.hypot(self.x, self.y) def __complex__(self) -> complex:  return complex(self.x, self.y) @classmethod def fromcomplex(cls, datum: SupportsComplex) -> Vector2d:  c = complex(datum)  return cls(c.real, c.imag)  Аннотация типа возвращаемого значения float необходима, иначе Mypy вы- ведет тип Any и не будет проверять тело метода.  Даже без аннотации Mypy сумела вывести, что этот метод возвращает complex. Наличие аннотации предотвратит выдачу предупреждения (в зави- симости от конфигурации Mypy).  Здесь наличие SupportsComplex гарантирует, что datum допускает преобразова- ние.  Это явное преобразование необходимо, потому что SupportsComplex не объяв- ляет атрибуты .real и .imag, используемые в следующей строке. Например, у Vector2d нет этих атрибутов, но он реализует метод __complex__ . Тип возвращаемого fromcomplex значения может быть Vector2d, если в начале модуля находится предложение from __future__ import annotations . Этот импорт приводит к тому, что аннотации типов сохраняются в виде строк, а не вычис - ляются на этапе импорта, когда интерпретатор обрабатывает определения функций. Если бы __future__ не импортировался из annotations , то ссылка Vector2d была бы в этой точке недопустима (класс еще не полностью определен) и ее следовало бы записать в виде строки: 'Vector2d' , как если бы это была опережа- ющая ссылка. Импорт __future__ был предложен в документе PEP 563 «Postponed Evaluation of Annotations» (https://www.python.org/dev/peps/pep-0563/) и реализо- ван в Python 3.7. Предполагалось, что это поведение станет стандартным в вер- Статические протоколы  449\n--- Страница 449 ---\nсии 3.10, но потом изменение отложили до следующей версии1. После того как это произойдет, импорт станет излишним, но и вреда не принесет. Теперь посмотрим, как создавать, а затем и расширять новый статический протокол. Проектирование статического протокола Изучая гусиную типизацию, мы видели ABC Tombola в разделе «Определение и использование ABC». А сейчас покажем, как определить аналогичный интер- фейс с помощью статического протокола. В ABC Tombola определено два метода: pick и load. Мы могли бы определить статический протокол с такими же двумя методами, но от сообщества поль- зователей языка Go я узнал, что протоколы с единственным методом делают статическую утиную типизацию более полезной и гибкой. В стандартной биб- лиотеке Go есть несколько интерфейсов, например Reader – интерфейс ввода- вывода, который требует только метода read. Если спустя некоторое время вы поймете, что необходим более полный протокол, то сможете определить его, объединив два или более протоколов. Использование контейнера, который случайным образом выбирает элемен- ты, может потребовать перезагрузки контейнера, а может и не потребовать. Но оно, безусловно, требует метода для самого выбора, поэтому именно такой метод я буду считать необходимой принадлежностью минимального протоко- ла RandomPicker . Код этого протокола приведен в примере 13.18, а его использо- вание продемонстрировано на тестах из примера 13.19. Пример 13.18. randompick.py: определение RandomPicker from typing import Protocol, runtime_checkable, Any @runtime_checkable class RandomPicker(Protocol): def pick(self) -> Any: Метод pick возвращает тип Any. В разделе «Реализация обоб- щенного статического протокола» мы увидим, как сделать RandomPicker обобщенным типом с параметром, который позво- ляет пользователям протокола задавать тип значения, возвра- щаемого методом pick. Пример 13.19. randompick_test.py: использование RandomPicker import random from typing import Any, Iterable, TYPE_CHECKING from randompick import RandomPicker  class SimplePicker:  def __init__(self, items: Iterable) -> None: self._items = list(items) random.shuffle(self._items) 1 Читайте решение Руководящего комитета на python-dev ( https://mail.python.org/archives/ list/python-dev@python.org/thread/CLVXXPQ2T2LQ5MP2Y53VVQFCXYWQJHKZ/). 450  Интерфейсы, протоколы и ABC\n--- Страница 450 ---\ndef pick(self) -> Any:  return self._items.pop() def test_isinstance() -> None:  popper: RandomPicker = SimplePicker([1])  assert isinstance(popper, RandomPicker)  def test_item_type() -> None:  items = [1, 2] popper = SimplePicker(items) item = popper.pick() assert item in items if TYPE_CHECKING: reveal_type(item)  assert isinstance(item ,int)  Необязательно импортировать статический протокол, чтобы определить класс, который его реализует. Здесь я импортировал RandomPicker , только что- бы использовать test_isintance ниже.  SimplePicker реализует RandomPicker , но не является его подклассом. Это стати- ческая утиная типизация в действии.  Any – тип возвращаемого значения по умолчанию, так что эта аннотация, строго говоря, лишняя, но она проясняет наше намерение реализовать протокол RandomPicker , определенный в примере 13.18.  Не забывайте добавлять аннотации -> None в свои тесты, если хотите, чтобы Mypy обращала на них внимание.  Я добавил аннотацию типа для переменной popper, чтобы показать, что Mypy понимает, что SimplePicker совместим с.  Этот тест доказывает, что экземпляр SimplePicker является также экземпля- ром RandomPicker . Это работает, потому что к RandomPicker применен декоратор @runtime_checkable , а SimplePicker имеет обязательный метод pick.  Этот тест вызывает метод pick класса SimplePicker , проверяет, что он возвра- щает один из элементов, переданных SimplePicker , а затем производит ста- тические и динамические проверки возвращенного элемента.  Эта строка генерирует примечание в выводе Mypy. Как мы видели в примере 8.22, reveal_type – «магическая» функция, распо- знаваемая Mypy, поэтому она не импортируется, но вызывать ее можно только внутри блоков if с условием typing.TYPE_CHECKING , которое средство статической проверки типов считает равным True, а среда выполнения – False. Оба теста в примере 13.19 проходят. Mypy тоже не находит ошибок в этом коде и показывает результат reveal_type для объекта item, возвращенного pick: $ mypy randompick_test.py randompick_test.py:24: note: Revealed type is 'Any' Создав свой первый статический протокол, давайте познакомимся с тем, что советуют по этому поводу знающие люди. Рекомендации по проектированию протоколов После 10 лет опыта работы со статической утиной типизацией в Go стало ясно, что узкие протоколы более полезны. Часто в таких протоколах есть всего один Статические протоколы  451\n--- Страница 451 ---\nметод, а более двух – редкость. Мартин Фаулер написал статью, в которой определяется ролевой интерфейс ( https://martinfowler.com/bliki/RoleInterface.html), эту идею полезно иметь в виду при проектировании протоколов. Кроме того, иногда можно увидеть, как протокол определяется рядом с ис- пользующей его функцией, т. е. в «клиентском коде», а не в библиотеке. Это упрощает создание новых типов, вызывающих данную функцию, что неплохо с точки зрения расширяемости и тестирования с помощью объектов-имита- ций (mock). Использование узких протоколов и протоколов в клиентском коде позволяет избежать ненужной тесной сцепленности, в полном соответствии с принципом разделения интерфейса (https://en.wikipedia.org/wiki/Interface_segregation_ principle), который можно кратко формулировать так: «Клиента не следует принуждать к зависимости от интерфейсов, которыми он не пользуется». На странице «Как предлагать свой вклад в typeshed» (https://github.com/python/ typeshed/blob/master/CONTRIBUTING.md) рекомендуется следующее соглашение об именовании: выбирайте для протоколов простые имена, которые ясно описывают концепцию (например, Iterator, Container); используйте имя вида SupportsX для протоколов, предоставляющих вызы- ваемые методы (например, SupportsInt , SupportsRead , SupportsReadSeek )1; используйте имя вида HasX для протоколов, которые имеют атрибуты, до- пускающие чтение и (или) запись, либо методы чтения и установки (на- пример, HasItems, HasFileno). В стандартной библиотеке Go принято соглашение об именовании, которое мне нравится: для протоколов с единственным методом, если имя метода – глагол, то добавляйте суффикс «-er» или «-or», чтобы сделать имя протокола существительным. Например, называйте не SupportsRead , а Reader. Еще примеры: Formatter, Animator, Scanner. В поисках источника вдохновения прочитайте статью Асука Кендзи «Go (Golang) Standard Library Interfaces (Selected)» (https://gist. github.com/asukakenji/ ac8a05644a2e98f1d5ea8c299541fce9). Веская причина создавать минималистские протоколы – возможность их последующего расширения при необходимости. Сейчас мы покажем, как прос- то создать производный протокол, содержащий дополнительный метод. Расширение протокола В начале предыдущего раздела я говорил, что разработчики Go ратуют за мини- мализм при определении интерфейсов – так они называют статические прото- колы. Многие широко используемые в Go интерфейсы имеют всего один метод. Если практика показывает, что протокол с большим числом методов поле- зен, то лучше не добавлять методы в исходный протокол, а произвести от него новый. У расширения статического протокола в Python есть несколько подвод- ных камней, как показывает пример 13.20. 1 Любой метод является вызываемым, так что эта рекомендация мало что дает. Быть может, имелось в виду «предоставляющих один или два метода»? Так или иначе, это рекомендация, а не непреложное правило.452  Интерфейсы, протоколы и ABC\n--- Страница 452 ---\nПример 13.20. randompickload.py: расширение RandomPicker from typing import Protocol, runtime_checkable from randompick import RandomPicker @runtime_checkable  class LoadableRandomPicker(RandomPicker, Protocol):  def load(self, Iterable) -> None:   Если нужно, чтобы производный протокол допускал проверку во время вы- полнения, то необходимо повторно применить к нему декоратор – это по- ведение не наследуется1.  Для любого протокола необходимо явно указать typing.Protocol в качестве одного из базовых классов, в дополнение к расширяемому протоколу. Обычное наследование в Python работает не так2.  Возвращаемся к «регулярному» ООП: нужно объявлять только новый ме- тод производного протокола. Объявление метода pick унаследовано от RandomPicker . На этом завершается последний пример определения и использования ста- тического протокола в этой главе. В заключение рассмотрим числовые ABC и их возможную замену числовы- ми протоколами. ABC из пакета numbers и числовые протоколы В разделе «Падение числовой башни» главы 8 мы видели, что ABC из пакета numbers стандартной библиотеки прекрасно работают в сочетании с проверкой типов во время выполнения. Если нужно проверить, принадлежит ли объект целочисленному типу, мож - но воспользоваться вызовом isinstance(x,numbers.Integral) , который возвращает True для int, bool (подкласс int) и других целочисленных типов, предоставляе- мых внешними библиотеками, которые зарегистрировали свои типы как вир- туальные подклассы ABC из пакета numbers. Например, в NumPy имеется 21 це- лый тип (https://numpy.org/devdocs/user/basics.types.html), а также несколько типов с плавающей точкой, зарегистрированных как numbers.Real , и комплексных ти- пов с различной разрядностью, зарегистрированных как numbers.Complex . Удивительно, но тип decimal.Decimal не зарегистрирован как вир- туальный подкласс numbers.Real . Причина в том, что если в про- грамме нужна точность Decimal, то, наверное, вы предпочли бы застраховаться от случайного смешения десятичных чисел и ме- нее точных чисел с плавающей точкой. 1 Детали и обоснование см. в разделе о декораторе @runtime_checkable документа PEP 544 «Protocols: Structural subtyping (static duck typing)» (https://peps.python.org/pep- 0544/#runtime-checkable-decorator-and-narrowing-types-by-isinstance). 2 И снова отсылаю читателя, жаждущего деталей и обоснования, к документу PER 544, но на этот раз к разделу «Merging and extending protocols» (https://peps.python.org/pep- 0544/#merging-and-extending-protocols). Статические протоколы  453\n--- Страница 453 ---\nК сожалению, числовая башня не предназначалась для статической провер- ки типов. Корневой ABC – numbers.Number – не имеет методов, поэтому если объ- явить x: Number, то Mypy не позволит производить арифметические операции с x или вызывать какие-то методы x. Но если ABC из пакета numbers не поддерживаются, то какие имеются альтер- нативы? Начинать поиск решений проблем, относящихся к типизации, имеет смысл с проекта typeshed. Модуль statistics , входящий в стандартную библиоте- ку Python, сопровождается содержащим аннотации типов файлом заглуш- ки statistics.pyi ( https://github.com/python/typeshed/blob/master/stdlib/statistics.pyi) в typeshed. Там вы найдете следующие определения, которые используются для аннотирования нескольких функций: _Number = Union[float, Decimal, Fraction] _NumberT = TypeVar('_NumberT', float, Decimal, Fraction) Этот подход корректный, но имеет ограничения. Он не поддерживает чис- ловые типы за пределами стандартной библиотеки, в отличие от ABC из пакета numbers – при условии что числовые типы зарегистрированы как виртуальные подклассы. В настоящее время рекомендуется использовать числовые протоколы, предо ставляемые модулем typing, как обсуждалось в разделе «Статические протоколы, допускающие проверку во время выполнения». К сожалению, во время выполнения числовые протоколы могут вас разоча- ровать. Как упоминалось в разделе «Ограничения протоколов, допускающих проверку во время выполнения», тип complex в Python 3.9 реализует метод __ float__, но только для того, чтобы возбудить исключение TypeError с недвусмыс - ленным сообщением: «can’t convert complex to float» (не могу преобразовать complex в float). По той же причине он реализует метод __int__. Из-за нали- чия этих методов isinstance возвращает вводящие в заблуждение результаты в Python 3.9. В Python 3.10 методы complex, которые безусловно возбуждали ис- ключение TypeError, были удалены1. С другой стороны, комплексные типы в NumPy реализуют методы __float__ и __int__, которые работают, но выдают предупреждение при первом исполь- зовании: >>> import numpy as np >>> cd = np.cdouble(3+4j) >>> cd (3+4j) >>> float(cd) <stdin>:1: ComplexWarning: Casting complex values to real discards the imaginary part 3.0 Иногда встречается и противоположная проблема: встроенные типы complex, float и int, а также типы numpy.float16 и numpy.uint8 не имеют метода __complex__ , по- 1 См. проблему #41974 – Remove complex.__float__, complex.__floordiv__, etc. (https://bugs. python.org/issue41974).454  Интерфейсы, протоколы и ABC\n--- Страница 454 ---\nэтому isinstance(x, SupportsComplex) возвращает для них False1. Комплексные типы NumPy, в частности np.complex64 , реализуют __complex__ для преобразования во встроенный тип complex. Однако на практике встроенный конструктор complex() обрабатывает экзем- пляры всех этих типов, не выдавая ни ошибок, ни предупреждений: >>> import numpy as np >>> from typing import SupportsComplex >>> sample = [1+0j, np.complex64(1+0j), 1.0, np.float16(1.0), 1, np.uint8(1)] >>> [isinstance(x, SupportsComplex) for x in sample] [False, True, False, False, False, False] >>> [complex(x) for x in sample] [(1+0j), (1+0j), (1+0j), (1+0j), (1+0j), (1+0j)] Это показывает, что функция isinstance проверяет наличие метода SupportsComplex , и его отсутствие должно было бы привести к ошибке преобра- зования в complex, но в действительности все преобразования выполняются. В списке рассылки typing-sig Гвидо ван Россум указал, что встроенный кон- структор complex принимает единственный аргумент, и по этой причине ука- занные преобразования работают. С другой стороны, Mypy принимает аргументы всех шести типов при обра- щении к следующей функции to_complex() : def to_complex(n: SupportsComplex) -> complex: return complex(n) На момент написания книги в NumPy не было аннотаций типов, поэтому все числовые типы из этой библиотеки распознаются как Any2. С другой стороны, Mypy каким-то образом «знает», что встроенные типы int и float можно преоб- разовать в complex, хотя в typeshed только встроенный класс complex имеет метод __complex__3. Итак, хотя проверка числовых типов не должна представлять сложностей, текущая ситуация такова: PEP 484 неявно рекомендует пользователям сто- рониться (https://peps.python.org/pep-0484/#the-numeric-tower) числовой башни в аннотациях типов, а средствам проверки типов зашивать в код отношения тип–подтип между встроенными типами complex, float и int. Mypy так и посту - пает, а кроме того, прагматично принимает, что типы int и float совместимы с SupportsComplex , хотя и не реализуют метод __complex__ . Я наткнулся на неожиданности только при использовании isinstance для проверки числовых протоколов Supports* во время экспериментов с преобразованием в complex и обратно. Если вы не работаете с комплексными числами, то можете смело пола- гаться на эти протоколы вместо ABC из пакета numbers. 1 Я не проверял все варианты целых и чисел с плавающей точкой, предоставляемые NumPy. 2 Все числовые типы NumPy зарегистрированы как виртуальные подклассы соответ - ствующих ABC из пакета numbers, которые Mypy игнорирует. 3 Это ложь во спасение со стороны typeshed: в версии Python 3.9 встроенный тип complex на самом деле не имеет метода __complex__ . Статические протоколы  455\n--- Страница 455 ---\nСформулируем основные уроки этого раздела. ABC из пакета numbers можно использовать для проверки типов во время выполнения, но для статической типизации они не годятся. Статические числовые протоколы SupportsComplex , SupportsFloat и т. д. хоро- шо работают со статической типизацией, но ненадежны при проверке во время выполнения типов, связанных с комплексными числами. Теперь мы готовы подвести краткие итоги этой главы. резюме Карта типизации (рис. 13.1) – ключ к этой главе. После краткого введения во все четыре подхода к типизации мы сравнили динамические и статические протоколы, поддерживающие соответственно утиную и статическую утиную типизации. У обоих видов протоколов есть общая черта: от класса никогда не требуется явно объявлять поддержку конкретного протокола. Для поддерж - ки протокола достаточно, если класс реализует необходимые методы. Следующим важным разделом было «Программирование уток», где мы вы- яснили, до каких пределов готов дойти интерпретатор Python в стремлении обеспечить работоспособность динамических протоколов последовательно- стей и итерируемых объектов, пусть даже частичную. Далее мы видели, как заставить класс реализовывать протокол во время выполнения, добавив до- полнительные методы посредством партизанского латания. Мы завершили раздел об утиной типизации советами на тему защитного программирования, в частности о том, как обнаруживать структурные типы, не прибегая к явным проверкам с помощью функций isinstance или hasattr, а ограничиваясь кон- струкцией try/except и принципом быстрого отказа. Познакомившись с гусиной типизацией в эссе Алекса Мартелли «Водоплава- ющие птицы и ABC», мы увидели, как порождать подклассы существующих ABC, обсудили важные ABC в стандартной библиотеке и создали с нуля свой ABC, ко- торый затем реализовали двумя способами: с помощью традиционных подклас - сов и регистрации виртуальных подклассов. В завершение этого раздела мы по- казали, как специальный метод __subclasshook__ позволяет ABC поддержать струк - турную типизацию путем распознавания не связанных между собой классов, которые предоставляют методы, требуемые интерфейсом, определенным в ABC. Последним крупным разделом был «Статические протоколы», где мы вер- нулись к рассмотрению статической утиной типизации, начатому в гла- ве 8. Мы видели, что декоратор @runtime_checkable также пользуется методом __subclasshook__ для поддержки структурной типизации во время выполнения – хотя использовать статические протоколы все же рекомендуется в сочетании со средствами статической проверки типов, которые принимают во внимание аннотации типов, чтобы повысить надежность структурной типизации. Далее мы поговорили о проектировании и кодировании статического протокола и о том, как его расширять. В заключительном разделе «ABC из пакета numbers и числовые протоколы» мы рассказали печальную историю о рухнувшей чис- ловой башне и о нескольких недостатках предлагаемой альтернативы: стати- ческих числовых протоколах типа SupportsFloat и других, добавленных в модуль typing в версии Python 3.8.456  Интерфейсы, протоколы и ABC\n--- Страница 456 ---\nГлавный посыл этой главы – то, что в современном Python есть четыре взаи- модополняющих способа программирования с помощью интерфейсов, каж- дый со своими достоинствами и недостатками. Вы без сомнения найдете при- меры использования всех схем типизации в любой современной кодовой базе на Python сколько-нибудь значительного размера. Не стоит отвергать ни один из этих подходов, поскольку тем самым вы без нужды осложните себе работу. При всем при том Python завоевал широкую популярность, когда поддержи- вал только утиную типизацию. Другие популярные языки, например JavaScript, PHP и Ruby, а также Lisp, Smalltalk, Erlang и Clojure – не такие популярные, но очень влиятельные – раньше и теперь утверждают свое влияние, задействуя всю мощь и простоту утиной типизации. дОпО лнительная литература В качестве краткого обзора плюсов и минусов типизации, а также важности typing.Protocol для поддержания статически проверяемых кодовых баз в рабо- тоспособном состоянии я настоятельно рекомендую статью Глифа Лефковица «I Want A New Duck: typing.Protocol and the future of duck typing» (https://glyph. twistedmatrix.com/2020/07/new-duck.html). Я также многое узнал из его статьи «Interfaces and Protocols» (https://glyph.twistedmatrix.com/2021/03/interfaces-and- protocols.html), в которой typing.Protocol сравнивается с zope.interface , прежним ме- ханизмом определения интерфейсов в слабо связанных системах с плагина- ми, который используется в CMS Plone (https://plone.org/), веб-каркасе Pyramid (https://trypyramid.com/) и каркасе асинхронного программирования Twisted (https://twistedmatrix.com/trac/) – проекте, который запустил Глиф1. Во всех хороших книгах о Python – почти по определению – много внимания уделено утиной типизации. Из моих любимых книг две были переизданы пос- ле выхода первого издания этой книги: Naomi Ceder «The Quick Python Book», 3-е издание (Manning), и Alex Martelli, Anna Ravenscroft, Steve Holden «Python in a Nutshell», 3-е издание (O’Reilly). Аргументы за и против динамической типизации прозвучали в интервью, данном Гвидо ван Россумом Биллу Веннерсу и опубликованном на странице «Контракты в Python: беседа с Гвидо ван Россумом, часть IV» (http://www.artima. com/intv/pycontract.html). Познавательный и сбалансированный вклад в этот спор – статья Мартина Фаулера «Dynamic Typing» (https://martinfowler.com/bliki/ DynamicTyping.html). Он же написал статью «Role Interface» (https://martinfowler. com/bliki/RoleInterface.html), упомянутую мной в разделе «Рекомендации по про- ектированию протоколов». Хотя она и не об утиной типизации, но имеет са- мое непосредственное отношение к проектированию протоколов в Python, поскольку автор сравнивает узкие ролевые интерфейсы с более широкими от- крытыми интерфейсами классов вообще. Документация по Mypy зачастую является лучшим источником информа- ции обо всем связанном со статической типизацией в Python, включая ста- тическую утиную типизацию, которая рассматривается в главе «Protocols and structural subtyping» (https://mypy.readthedocs.io/en/stable/protocols.html). 1 Благодарю технического рецензента Юрген Гмаха, порекомендовавшего мне статью «Interfaces and Protocols». Дополнительная литература  457\n--- Страница 457 ---\nВсе остальные ссылки относятся к гусиной типизации. В книге Beazley, Jones «Python Cookbook», 3-е издание (O’Reilly), есть раздел, посвященный определе- нию ABC (рецепт 8.12). Эта книга была написана до выхода версии Python 3.4, поэтому в ней используется синтаксис с именованным параметром metaclass, а не рекомендуемое сейчас объявление ABC с помощью наследования abc.ABC. Но если не считать эту мелкую деталь, в рецепте прекрасно описаны все основ- ные особенности ABC, а завершается он советом, процитированным в конце предыдущего раздела. В книге Дуга Хеллманна «The Python Standard Library by Example» (Addison- Wesley) есть глава о модуле abc. Она опубликована также на великолепном сайте Дуга PyMOTW – Python Module of the Week (http://pymotw.com/2/abc/index.html). Хелл- манн пользуется старым стилем объявления ABC: PluginBase(metaclass=abc.ABCMeta) вместо более простого PluginBase(abc.ABC) , появившегося в версии Python 3.4. При работе с ABC множественное наследование не только часто встречает - ся, но и практически неизбежно, поскольку все фундаментальные ABC коллек - ций – Sequence, Mapping и Set – расширяют несколько ABC (см. рис. 13.4). Поэтому глава 14 станет важным дополнением к этой. В документе PEP 3119 «Introducing Abstract Base Classes» (https://www.python. org/dev/peps/pep-3119) приводится обоснование ABC, а в документе PEP 3141 «A Type Hierarchy for Numbers» (https://www.python.org/dev/peps/pep-3141) опи- сываются ABC из модуля numbers (https://docs.python.org/3/library/numbers.html), но обсуждение в проблеме Mypy #3186 «int is not a Number?» (https://github.com/ python/mypy/issues/3186) содержит дополнительные аргументы по поводу того, почему числовая башня не годится для статической проверки типов. Алекс Уэйгуд написал развернутый ответ на сайте StackOverflow (https://stackoverflow. com/questions/69334475/how-to-hint-at-number-types-i-e-subclasses-of-number-not- numbers-themselv/69383462#69383462), в котором обсуждаются способы анноти- рования числовых типов. Я буду поглядывать, что пишут в обсуждении проб- лемы Mypy #3186 в надежде на счастливый конец, который сделает статиче- скую и гусиную типизации совместимыми – какими они и должны быть. Поговорим Путешествие в мир статической типизации в Python на машине MVP Я работаю в компании Thoughtworks, мировом лидере в области разработ - ки гибкого (agile) программного обеспечения. Мы часто рекомендуем сво- им клиентам создавать и развертывать MVP (minimal viable product): мини- мально жизнеспособный продукт: «простую версию продукта, передаваемую пользователям с целью подтвердить основные бизнес-предположения», со- гласно определению моего коллеги Пауло Кароли в статье «Lean Inception» (https://martinfowler.com/articles/lean-inception/), опубликованной в коллективном блоге Мартина Фаулера. Гвидо ван Россум и другие разработчики ядра, которые спроектировали и реализовали статическую типизацию, следовали стратегии MVP начиная с 2006 года. Сначала в версии Python 3.0 был реализован документ PEP 3107 «Function Annotations» (https://peps.python.org/pep-3107/) с очень ограниченной458  Интерфейсы, протоколы и ABC\n--- Страница 458 ---\nсемантикой: только синтаксис, необходимый для присоединения аннотаций к параметрам и возвращаемым значениям функций. При этом явно стави- лась цель – провести эксперимент и собрать отзывы, а это и есть ключевые достоинства MVP. Спустя восемь лет был предложен и одобрен документ PEP 484 «Type Hints» (https://peps.python.org/pep-0484/). Его реализация в Python 3.5 не потребовала никаких изменений в языке или в стандартной библиотеке, кроме добавле- ния модуля typing, от которого никакая часть стандартной библиотеки не за- висит. PEP 484 поддерживал только номинальные типы в обобщенных ти- пах – по аналогии с Java, – но фактически статическая проверка производи- лась внешними инструментами. Отсутствовали такие важные возможности, как аннотации переменных, встроенные обобщенные типы и протоколы. Несмотря на ограничения, этот MVP оказался достаточно ценным для при- влечения инвестиций и внедрения компаниями с очень большими базами кода на Python, в т. ч. Dropbox, Google и Facebook. Его поддержка была вклю- чена и в профессиональные IDE, например PyCharm (https://www.jetbrains.com/ pycharm/), Wing (https://wingware.com/) и VS Code (https://code.visualstudio.com/). Документ PEP 526 «Syntax for Variable Annotations» (https://peps.python.org/ pep-0526/) стал первым шагом эволюции, потребовавшим внесения измене- ний в интерпретатор Python 3.6. Дополнительные изменения были внесены в интерпретатор Python 3.7 ради поддержки документов PEP 563 «Postponed Evaluation of Annotations» (https://peps.python.org/pep-0563/) и PEP 560 «Core support for typing module and generic types» (https://peps.python.org/pep-0560/), которые позволяли встроенным и библиотечным коллекциям принимать обобщенные типы в аннотациях в Python 3.9 – благодаря документу PEP 585 «Type Hinting Generics In Standard Collections» (https://peps.python.org/pep-0585/). За эти годы некоторых пользователей Python, включая меня, поддержка ти- пизации разочаровала. После изучения Go отсутствие статической утиной ти- пизации в Python казалось мне непонятным, ведь это язык, в котором утиная типизация всегда была главным достоинством. Но такова природа MVP: возможно, они не удовлетворяют всех потенциаль- ных пользователей, но зато могут быть реализованы ценой меньших усилий, а после получения отзывов по результатам практического применения даль- нейшая разработка пойдет в правильном направлении. Если нужно назвать всего один урок, который мы вынесли из Python 3, то это тот факт, что постепенный прогресс безопаснее выпуска новых версий, вклю- чающих все-все-все. Я рад, что нам не пришлось ждать выхода Python 4, – если таковой когда-нибудь состоится, – чтобы сделать Python более привлекатель- ным для крупных корпораций, считающих, что преимущества статической типизации перевешивают дополнительную сложность. Подходы к типизации в популярных языках На рис. 13.8 приведен вариант карты типизации (рис. 13.1) с названиями не- которых популярных языков, поддерживающих каждый из подходов к типи- зации. Дополнительная литература  459\n--- Страница 459 ---\nСтатическая проверкаПроверка во время выполнения Статическая типизация Статическая утиная типизацияСтруктурные типыНоминальные типыPython ≥ 3.5 T ypeScript Go JavaPython T ypeScript JavaScript SmalltalkPython ≥ 2.6 T ypeScript Go Python ≥ 3.8 T ypeScript GoУтиная типизация Гусиная типизация Рис. 13.8. Четыре подхода к проверке типов и некоторые языки, в которых они под- держиваются TypeScript и Python ≥ 3.8 – единственные языки в моей небольшой и произ- вольной выборке, которые поддерживают все четыре подхода. Go – очевидно, статически типизированный язык в традиции Pascal, но в нем впервые была применена статическая утиная типизация – по крайней мере, среди языков, широко распространенных в настоящее время. Я также помес- тил Go в квадрант гусиной типизации из-за имеющихся в нем утверждений относительно типов, которые открывают возможность для проверки и адап- тации к различным типам во время выполнения. Если бы я рисовал подобную диаграмму в 2000 году, то какие-то языки при- сутствовали бы только в квадрантах утиной и статической типизаций. Мне неизвестны языки, поддерживавшие статическую утиную или гусиную типи- зации 20 лет назад. Тот факт, что в каждом из четырех квадрантов есть как минимум три популярных языка, позволяет предположить, что каждый из четырех подходов к типизации находит немало приверженцев. Партизанское латание У партизанского латания плохая репутация. Если им злоупотреблять, то мож - но получить систему, трудную для понимания и сопровождения. Заплата обычно тесно связана с конечным объектом, что делает его хрупким. Другая проблема состоит в том, что в случае партизанского латания двух библиотек возможны конфликты, в результате которых библиотека, загруженная вто- рой, затрет заплаты, внесенные первой.460  Интерфейсы, протоколы и ABC\n--- Страница 460 ---\nНо партизанское латание может также принести пользу, например чтобы до- бавить в класс реализацию протокола на этапе выполнения. Паттерн проек - тирования Адаптер решает ту же проблему путем реализации нового класса. Код на Python легко поддается партизанскому латанию с некоторыми ограни- чениями. В отличие от Ruby и JavaScript, Python не позволяет латать встроен- ные типы. Лично я считаю это плюсом, так как есть уверенность, что объект str всегда будет иметь один и тот же набор методов. Это ограничение снижает шансы на то, что внешние библиотеки попытаются применить конфликтую- щие заплаты. Метафоры и идиомы в интерфейсах Метафора способствует пониманию, делая ясными возможности и ограниче- ния. В этом ценность слов «стек»1 и «очередь» – в описании соответствующих фундаментальных структур данных: благодаря им понятно, как добавляются и удаляются элементы. С другой стороны, Алан Купер (Alan Cooper) в книге «About Face, the Essentials of Interaction Design»2, издание 4 (Wiley), пишет: Строгая приверженность метафорам слишком тесно – без всякой на то необходимости – связывает интерфейсы с явлениями материального мира. Он имел в виду пользовательские интерфейсы, однако совет в равной мере относится и к API. Но Купер благосклонно относится к «действительно под- ходящим» метафорам, «будто упавшим с небес», и не возражает против их ис- пользования (он пишет «будто упавшим с небес», потому что найти хорошую метафору настолько трудно, что не стоит тратить времени на их целенаправ- ленный поиск). Мне кажется, что образ машины для игры в бинго, который я использовал в этой главе, удачен, и я остался верен ему. «About Face» – пожалуй, лучшая из прочитанных мной книг о пользователь- ском интерфейсе, – а я прочел не только ее. И одна из самых ценных мыслей, почерпнутых мной у Купера, – отказ от использования метафор как парадиг - мы дизайна и замена их «идиоматическими интерфейсами». В «About Face» Купер говорит не об API, но чем дольше я размышляю о его идеях, тем больше мне кажется, что они применимы и к Python. Фундамен- тальные протоколы языка – это то, что Купер называет «идиомами». Однаж - ды поняв, что такое «последовательность», мы можем применять это знание в разных контекстах. Это и есть главная тема моей книги: выявление фунда- ментальных идиом языка, что позволяет сделать код кратким, эффективным и удобочитаемым – для мастера-питониста. 1 Слово «stack» (букв. стопка) на заре развития программирования в СССР переводили как «магазин» (термин до сих пор сохранился в теории автоматов), и это была оче- видная метафора автоматного рожка. Жаль, что теперь его переводят бесцветной калькой «стек». – Прим. перев. 2 Алан Купер. Интерфейс, основы проектирования взаимодействия. 4-е изд. Питер, 2022. Дополнительная литература  461",
      "debug": {
        "start_page": 410,
        "end_page": 460
      }
    },
    {
      "name": "Глава 14. Наследование: к добру или к худу 462",
      "content": "--- Страница 461 --- (продолжение)\nГлава 14 Наследование: к добру или к худу […] нам нужна была (и до сих пор нужна) более качественная теория насле- дования вообще. Например, наследование и инстанцирование (instancing) (тоже разновидность наследования) мешают в одну кучу прагматику (на- пример, выделение общего кода для экономии памяти) и семантику (ис- пользуемую для слишком многих задач, как то: специализация, обобще- ние, видообразование и т. д.). – Алан Кэй, «The Early History of Smalltalk»1 Эта глава посвящена наследованию и подклассам. Я предполагаю, что чита- тель знаком с этими идеями, например из чтения «Пособия по языку Python» (https://docs.python.org/3/tutorial/classes.html) или по опыту работы с каким-ни- будь другим популярным объектно-ориентированным языком, например Java, C# или C++. В центре нашего внимания будут четыре специфические особен- ности Python: функция super() ; проблемы наследования встроенным типам; множественное наследование и порядок разрешения методов; классы-примеси. Множественное наследование – это способность класса иметь более одного базового класса. C++ его поддерживает, а Java и C# нет. Многие считают, что множественное наследование порождает больше проблем, чем решает. Оно было сознательно изъято из Java после печального опыта злоупотребления в ранних кодовых базах на C++. В этой главе введение в множественное наследование написано для тех, кто никогда им раньше не пользовался. Приводятся рекомендации, как работать с одиночным или множественным наследованием, если без него не обойтись. По состоянию на 2021 год имеет место отрицательное отношение к чрез- мерному использованию наследования вообще – не только множественного, 1 Alan Kay. The Early History of Smalltalk. Опубликовано в SIGPLAN Not. 28, 3 (март 1993), 69–95. Имеется также в сети (http://propella.sakura.ne.jp/earlyHistoryST/EarlyHistoryST.html). Спасибо моему другу Кристиано Андерсону, который прислал эту ссылку, когда я ра- ботал над данной главой.\nГлава 14 Наследование: к добру или к худу […] нам нужна была (и до сих пор нужна) более качественная теория насле- дования вообще. Например, наследование и инстанцирование (instancing) (тоже разновидность наследования) мешают в одну кучу прагматику (на- пример, выделение общего кода для экономии памяти) и семантику (ис- пользуемую для слишком многих задач, как то: специализация, обобще- ние, видообразование и т. д.). – Алан Кэй, «The Early History of Smalltalk»1 Эта глава посвящена наследованию и подклассам. Я предполагаю, что чита- тель знаком с этими идеями, например из чтения «Пособия по языку Python» (https://docs.python.org/3/tutorial/classes.html) или по опыту работы с каким-ни- будь другим популярным объектно-ориентированным языком, например Java, C# или C++. В центре нашего внимания будут четыре специфические особен- ности Python: функция super() ; проблемы наследования встроенным типам; множественное наследование и порядок разрешения методов; классы-примеси. Множественное наследование – это способность класса иметь более одного базового класса. C++ его поддерживает, а Java и C# нет. Многие считают, что множественное наследование порождает больше проблем, чем решает. Оно было сознательно изъято из Java после печального опыта злоупотребления в ранних кодовых базах на C++. В этой главе введение в множественное наследование написано для тех, кто никогда им раньше не пользовался. Приводятся рекомендации, как работать с одиночным или множественным наследованием, если без него не обойтись. По состоянию на 2021 год имеет место отрицательное отношение к чрез- мерному использованию наследования вообще – не только множественного, 1 Alan Kay. The Early History of Smalltalk. Опубликовано в SIGPLAN Not. 28, 3 (март 1993), 69–95. Имеется также в сети (http://propella.sakura.ne.jp/earlyHistoryST/EarlyHistoryST.html). Спасибо моему другу Кристиано Андерсону, который прислал эту ссылку, когда я ра- ботал над данной главой.\n--- Страница 462 ---\nпотому что подклассы и суперклассы тесно связаны. Тесная связанность оз- начает, что изменения в одной части программы могут иметь неожиданные и далеко идущие последствия в других ее частях, что делает систему хрупкой и трудной для понимания. Однако нам так или иначе приходится сопровождать уже написанные систе- мы, основанные на сложных иерархиях классов, или пользоваться каркасами, заставляющими прибегать к наследованию, иногда даже множественному. Мой рассказ о практическом применении множественного наследования иллюстрируется примерами из стандартной библиотеки, веб-каркаса Django и библиотеки пользовательского интерфейса Tkinter. чтО нОвОг О в этОй главе В Python не появилось никаких новых средств, относящихся к теме этой главы, но я значительно отредактировал ее, прислушавшись к мнениям технических рецензентов второго издания, особенно Леонардо Рохаэля и Калеба Хэттинга. Я написал новый вводный раздел, посвященный встроенной функции super(), и изменил примеры в разделе «Множественное наследование и поря- док разрешения методов», чтобы глубже исследовать, как super() поддерживает кооперативное множественное наследование. Раздел «Классы-примеси» также написан заново. Раздел «Множественное наследование в реальном мире» реорганизован, в нем мы рассматриваем прос тые примеры примесей из стандартной библиотеки, прежде чем перехо- дить к сложным иерархиям Django и Tkinter. Как следует из названия, подводные камни наследования всегда были одной из основных тем данной главы. Но все больше разработчиков начинают считать наследование настолько проблематичным, что я добавил пару абзацев о том, как избегать его, в конце разделов «Резюме» и «Дополнительная литература». Начнем с краткого рассказа о таинственной функции super(). функция super () Единообразное использование встроенной функции super() очень важно для удобства сопровождения объектно-ориентированных программ на Python. Метод суперкласса, переопределенный в подклассе, обычно должен вы- зывать соответствующий метод суперкласса. Ниже показано, как рекоменду - ется это делать; пример взят из документации по модулю collections, раздел «Пример и рецепты использования OrderedDict» (https://docs.python.org/3/library/ collections.html# ordereddict-examples-and-recipes)1: class LastUpdatedOrderedDict(OrderedDict): \"\"\"Элементы хранятся в порядке, определяемом последним обновлением\"\"\" def __setitem__(self, key, value): super().__setitem__(key, value) self.move_to_end(key) 1 Я изменил в примере только строку документации, потому что оригинальная вводи- ла в заблуждение. В ней было написано: «Элементы хранятся в порядке добавления ключей», но это не то, о чем недвусмысленно говорит имя класса LastUpdatedOrderedDict . Функция super()  463\n--- Страница 463 ---\nДля выполнения своей работы класс LastUpdatedOrderedDict переопределяет ме- тод __setitem__ следующим образом: 1. Воспользоваться конструкцией super().__setitem__ , чтобы вызвать метод суперкласса, который вставит или обновит пару ключ-значение. 2. Вызвать метод self.move_to_end , чтобы переместить измененную запись с ключом key в конец словаря. Вызов переопределенного метода __init__ особенно важен, поскольку позво- ляет суперклассам принять участие в инициализации экземпляра. Если вы изучали объектно-ориентированное программирова- ние на Java, то, возможно, помните, что в Java конструктор авто- матически вызывает конструктор без аргументов суперкласса. Python этого не делает. Вы должны привыкнуть к такой шаблон- ной последовательности: def __init__(self, a, b) : super() .__init__(a, b) # дополнительная инициализация Возможно, вам попадался код, в котором не используется super(), а вместо этого непосредственно вызывается метод суперкласса: class NotRecommended(OrderedDict): \"\"\"Так поступать не рекомендуется!\"\"\" def __setitem__(self, key, value): OrderedDict.__setitem__(self, key, value) self.move_to_end(key) В данном случае этот код работает, но такая практика не рекомендуется по двум причинам. Во-первых, в коде зашито имя базового класса. Имя OrderedDict встречается в предложении class и внутри __setitem__ . Тот, кто в будущем изме- нит базовый класс или добавит еще один, может забыть о том, что необходимо изменить и тело __setitem__ – вот вам и ошибка. Вторая причина в том, что super реализует логику обработки иерархий с мно- жественным наследованием. Мы вернемся к этой теме в разделе «Множест - венное наследование и порядок разрешения методов». И в заключение этого краткого обзора super полезно напомнить, как мы должны были вызывать ее в Python 2, поскольку старая сигнатура с двумя аргументами проливает свет на принцип работы этой функции: class LastUpdatedOrderedDict(OrderedDict): \"\"\"Этот код работает в Python 2 и в Python 3\"\"\" def __setitem__(self, key, value): super(LastUpdatedOrderedDict, self).__setitem__(key, value) self.move_to_end(key) Теперь оба аргумента super факультативны. Компилятор байт-кода в Python 3 автоматически подставляет их, исследуя объемлющий контекст вызова super() в методе. Аргументы имеют следующую семантику: 464  Наследование: к добру или к худу\n--- Страница 464 ---\ntype Начало пути поиска суперкласса, реализующего нужный метод. По умол- чанию это класс, которому принадлежит метод, откуда вызвана super(). object_or_type Объект (в случае вызова методов экземпляра) или класс (в случае вызова методов класса), от имени которого вызывается метод. По умолчанию это self, если вызов super() встречается в методе экземпляра. Кто бы ни предоставил эти аргументы – вы или компилятор, – вызов super() возвращает динамический прокси-объект, который находит метод (в нашем примере __setitem__ ) в суперклассе, определяемом параметром type, и связывает его с object_or_type , так что нам не нужно явно передавать объект (self), от имени которого вызывается метод. В Python 3 мы по-прежнему можем явно передать super() первый и второй аргументы1. Но нужны они только в специальных случаях, например чтобы пропустить часть MRO при тестировании или отладке или обойти нежелатель- ное поведение в суперклассе. Теперь обсудим, с какими подводными камнями можно столкнуться при на- следовании встроенным типам. СлОжнОС ти наСледОвания вСтрОенным типам В ранних версиях Python создать подкласс встроенного типа, например list или dict, было невозможно. Начиная с Python 2.2 такая возможность появилась, но с существенной оговоркой: код встроенного типа (написанный на C) обычно не вызывает специальные методы, переопределенные в пользовательских клас - сах. Суть проблемы хорошо описана в документации по интерпретатору PyPy, в главе «Различия между PyPy и CPython», раздел «Подклассы встроенных ти- пов» (https://doc.pypy.org/en/latest/cpython_differences.html#subclasses-of-built-in-types): Официально в CPython нет никаких правил, определяющих, когда пере- определенный в подклассе метод встроенного типа вызывается и вызы- вается ли он вообще. В качестве приближения к истине можно считать, что такие методы никогда не вызываются другими встроенными мето- дами того же объекта. Например, метод __getitem__() , переопределенный в подклассе dict, не будет вызываться из встроенного метода get(). Проблема иллюстрируется в примере 14.1. Пример 14.1. Наш метод __setitem__ игнорируется методами __init__ и __update__ встро- енного типа dict >>> class DoppelDict(dict): def __setitem__(self, key, value): super().__setitem__(key, [value] * 2)  >>> dd = DoppelDict(one=1)  1 Можно также задавать только первый аргумент, но это вредно и вскоре может быть объ- явлено нерекомендуемой практикой с благословения Гвидо ван Россума, который и яв- ляется автором функции super(). См. обсуждение в статье «Is it time to deprecate unbound super methods?» (https://discuss.python.org/t/is-it-time-to-deprecate-unbound-super-methods/1833). Сложности наследования встроенным типам  465\n--- Страница 465 ---\n>>> dd {'one': 1} >>> dd['two'] = 2  >>> dd {'one': 1, 'two': [2, 2]} >>> dd.update(three=3)  >>> dd {'three': 3, 'one': 1, 'two': [2, 2]}  Метод DoppelDict.__setitem__ повторяет значение при сохранении (только для того, чтобы его эффект был наглядно виден). Свою работу он делегирует методу суперкласса.  Метод __init__, унаследованный от dict, очевидно, не знает, что __setitem__ переопределен: значение 'one' не повторено.  Оператор [] вызывает наш метод __setitem__ и работает, как и ожидалось: 'two' отображается на повторенное значение [2, 2].  Метод update класса dict также не пользуется нашей версией __setitem__ : зна- чение 'three' не повторено. Поведение встроенных типов находится в явном противоречии с основным правилом объектно-ориентированного программирования: поиск методов всегда должен начинаться с класса самого объекта (self), даже если он вызыва- ется из метода, реализованного в суперклассе. Это явление называется «позд- ним связыванием», и Алан Кэй – из зала славы Smalltalk – считает его клю- чевым свойством объектно-ориентированного программирования: в любом вызове вида x.method() конкретный вызываемый метод должен определяться на этапе выполнения в зависимости от класса x1. Это печальное положение дел усугубляет проблемы, которые были описаны в разделе «Несогласованное ис- пользование __missing__ в стандартной библиотеке» главы 3. Проблема не ограничивается вызовами изнутри объекта – когда self.get() вызывает self.__getitem__() , – но возникает и для переопределенных методов других классов, которые должны вызываться из встроенных методов. При- мер 14.2 основан на примере из документации по PyPy (https://doc.pypy.org/en/ latest /cpython_differences.html#subclasses-of-built-in-types). Пример 14.2. Метод __getitem__ из класса AnswerDict игнорируется методом dict.update def __getitem__(self, key):  return 42 >>> ad = AnswerDict(a='foo')  >>> ad['a']  42 >>> d = {} >>> d.update(ad)  >>> d['a']  1 Интересно, что в C++ есть понятие виртуальных и невиртуальных методов. Для вир- туальных методов применяется позднее связывание, а невиртуальные связываются на этапе компиляции. Хотя все методы, которые мы можем написать на Python, свя- зываются поздно, как виртуальные методы, встроенные объекты, написанные на C, похоже, по умолчанию имеют невиртуальные методы, по крайней мере в CPython.466  Наследование: к добру или к худу\n--- Страница 466 ---\n'foo' >>> d {'a': 'foo'}  Метод AnswerDict.__getitem__ для любого ключа возвращает 42.  ad – экземпляр AnswerDict , инициализированный парой ('a', 'foo') .  ad['a'] возвращает 42, как и ожидалось.  d – экземпляр класса dict, обновленный объектом ad.  Метод dict.update игнорирует наш метод AnswerDict.__getitem__ . Прямое наследование таким встроенным типам, как dict, list или str, чревато ошибками, потому что встроенные методы, как правило, игнорируют написанные пользователем переопреде- ленные методы. Вместо создания подклассов встроенных объ- ектов наследуйте свои классы от классов в модуле collections (http://docs.python.org/3/library/collections.html) – UserDict, UserList и UserString , которые специально предназначены для беспроб- лемного наследования. Если наследовать подклассу collections.UserDict , а не dict, то проблемы, про- демонстрированные в примерах 14.1 и 14.2, исчезают. См. пример 14.3. Пример 14.3. Классы DoppelDict2 и AnswerDict2 работают, как и ожидалось, потому что расширяют UserDict, а не dict >>> import collections >>> >>> class DoppelDict2(collections.UserDict): def __setitem__(self, key, value): super().__setitem__(key, [value] * 2) >>> dd = DoppelDict2(one=1) >>> dd {'one': [1, 1]} >>> dd['two'] = 2 >>> dd {'two': [2, 2], 'one': [1, 1]} >>> dd.update(three=3) >>> dd {'two': [2, 2], 'three': [3, 3], 'one': [1, 1]} >>> >>> class AnswerDict2(collections.UserDict): def __getitem__(self, key): return 42 >>> ad = AnswerDict2(a='foo') >>> ad['a'] 42 >>> d = {} >>> d.update(ad) >>> d['a'] 42 >>> d {'a': 42} Сложности наследования встроенным типам  467\n--- Страница 467 ---\nДля оценки дополнительных усилий на создание подкласса встроенного типа я переписал класс StrKeyDict из примера 3.9, так чтобы он наследовал dict, а не UserDict. Чтобы проходили те же тесты, что и раньше, мне пришлось реа- лизовать методы __init__, get и update, потому что их версии, унаследованные от dict, отказывались признавать переопределенные методы __missing__ , __contains__ и __setitem__ . В подклассе UserDict из примера 3.8 было 16 строк, а в эксперимен- тальном подклассе dict – целых 33 строки1. Подведем итоги: описанная в этом разделе проблема относится только к деле- гированию методов встроенных типов, написанных на языке C, и только к поль- зовательским подклассам этих типов. Если наследовать классу, написанному на Python, например UserDict или MutableMapping , то эта проблема не возникает2. Теперь перейдем к вопросу, возникающему в связи со множественным на- следованием: если у класса есть два суперкласса, то как Python решает, какой атрибут использовать, когда вызывается super().attr , но в обоих суперклассах есть атрибуты с таким именем? мнОжеС твеннОе наСледОвание и пОряд Ок разрешения метОдОв Любой язык с множественным наследованием должен как-то разрешать кон- фликты имен в случае, когда в не связанных между собой родительских клас - сах имеются методы с одним и тем же именем. Эта «проблема ромбовидного наследования» иллюстрируется на рис. 14.1 и в примере 14.4. Рис. 14.1. Слева: последовательность активации для вызова leaf1.ping() . Справа: последо- вательность активации для вызова leaf1.pong() 1 Для любознательных читателей – экспериментальная версия находится в файле 14-inheritance/strkeydict_dictsub.py в репозитории кода к этой книге по адресу https:// github.com/fluentpython/example-code-2e. 2 Кстати говоря, в этом отношении PyPy ведет себя «корректнее», чем CPython, но це- ной незначительной несовместимости. См. раздел «Различия между PyPy и CPython» (https://doc.pypy.org/en/latest/cpython_differences.html#subclasses-of-built-in-types).468  Наследование: к добру или к худу\n--- Страница 468 ---\nПример 14.4. diamond.py: классы Leaf, A, B, Root образуют граф, показанный на рис. 14.1 class Root:  def ping(self): print(f'{self}.ping() in Root') def pong(self): print(f'{self}.pong() in Root') def __repr__(self): cls_name = type(self).__name__ return f'<instance of {cls_name}>' class A(Root):  def ping(self): print(f'{self}.ping() in A') super().ping() def pong(self): print(f'{self}.pong() in A') super().pong() class B(Root):  def ping(self): print(f'{self}.ping() in B') super().ping() def pong(self): vprint(f'{self}.pong() in B') class Leaf(A, B):  def ping(self): print(f'{self}.ping() in Leaf') super().ping()  Root предоставляет методы ping, pong и __repr__, чтобы вывод было проще чи- тать.  Оба метода ping и pong в классе A вызывают super().  В классе B только метод ping вызывает super().  Класс Leaf реализует только метод ping, который вызывает super(). Теперь посмотрим, что происходит при вызове методов ping и pong экземпля- ра Leaf (пример 14.5). Пример 14.5. Тесты вызова методов ping и pong объекта Leaf >>> leaf1 = Leaf()  >>> leaf1.ping()  <instance of Leaf>.ping() in Leaf <instance of Leaf>.ping() in A <instance of Leaf>.ping() in B <instance of Leaf>.ping() in Root >>> leaf1.pong()  <instance of Leaf>.pong() in A <instance of Leaf>.pong() in B Множественное наследование и порядок разрешения методов  469\n--- Страница 469 ---\n leaf1 – экземпляр Leaf.  Вызов leaf1.ping() активирует методы ping в Leaf, A, B и Root, потому что методы ping в первых трех классах вызывают super().ping() .  Вызов leaf1.pong() активирует метод pong в A благодаря наследованию, а тот вызывает super().pong() , что приводит к активации B.pong. Последовательности активации, показанные в примерах 14.5 и на рис. 14.1, определяются двумя факторами: порядок разрешения методов в классе Leaf; использование super() в каждом методе. В каждом классе имеется атрибут __mro__, в котором хранится кортеж ссылок на суперклассы в порядке разрешения методов, от текущего класса к классу object1. Для класса Leaf атрибут __mro__ имеет вид: >>> Leaf.__mro__ # doctest:+NORMALIZE_WHITESPACE (<class 'diamond1.Leaf'>, <class 'diamond1.A'>, <class 'diamond1.B'>, <class 'diamond1.Root'>, <class 'object'>) Глядя на рис. 14.1, можно подумать, что MRO описывает по- иск в ширину (https://en.wikipedia.org/wiki/Breadth-first_search), но это лишь совпадение для конкретной иерархии классов. MRO вычисляется опубликованным алгоритмом под названием C3. Его использование в Python подробно описано в статье Мише- ля Симионато «The Python 2.3 Method Resolution Order» (https:// www.python.org/download/releases/2.3/mro/). Это трудный текст, но Симионато пишет: «если вы не злоупотребляете множествен- ным наследованием и не работаете с особо сложными иерархия- ми, то понимать алгоритм C3 необязательно и можно спокойно не читать эту статью». MRO определяет только порядок активации, а будет ли конкретный метод активирован в каждом классе, зависит от того, вызывает реализация функцию super() или нет. Рассмотрим эксперимент с методом pong. В классе Leaf он не переопреде- лен, поэтому вызов leaf1.pong() активирует реализацию в следующем классе из Leaf.__mro__ : классе A. Метод A.pong вызывает super().pong() . Следующим в MRO идет класс B, поэтому активируется B.pong. Но этот метод не вызывает super(). pong(), поэтому последовательность активации здесь и оканчивается. Порядок MRO принимает в расчет не только граф наследования, но также порядок, в котором перечислены суперклассы в объявлении подкласса. Иными словами, если бы в файле diamond.py (пример 14.4) класс Leaf был объявлен как Leaf(B, A) , то класс B встретился бы в Leaf.__mro__ раньше A. Это повлияло бы на порядок активации методов ping, а кроме того, вызов leaf1.pong() активировал бы B.pong в силу наследования, но A.pong и Root.pong не получили бы управления, потому что B.pong не вызывает super(). 1 В классах есть также метод a.mro(), но это продвинутая возможность, предназна- ченная для программирования метаклассов, которую мы кратко обсудим в разделе «Классы как объекты» главы 24. При нормальном использовании класса важно толь- ко содержимое атрибута __mro__. 470  Наследование: к добру или к худу\n--- Страница 470 ---\nМетод, вызывающий super(), называется кооперативным. Кооперативные методы позволяют организовать кооперативное множественное наследование. Эти термины выбраны не случайно: для работы множественного наследова- ния в Python необходима активная кооперация участвующих методов. В клас - се B метод ping кооперативный, а метод pong нет. Некооперативные методы могут стать причиной тонких ошибок. Многие программисты, прочитавшие код примера 14.4, возмож - но, ожидают, что когда метод A.pong вызывает super.pong() , тот в конечном итоге активирует Root.pong . Но если B.pong активиро- ван раньше, то он «роняет мяч». Именно поэтому рекомендуется, чтобы каждый метод m некорневого класса вызывал super().m() . Кооперативные методы должны иметь совместимые сигнатуры, потому что заранее неизвестно, будет ли A.ping вызван раньше или позже, чем B.ping. По- следовательность активации зависит от порядка объявления классов A и B в каждом подклассе, наследующем им обоим. Python – динамический язык, поэтому взаимодействие super() с MRO тоже динамическое. В примере 14.6 показан удивительный результат такого дина- мического поведения. Пример 14.6. diamond2.py: классы, демонстрирующие динамическую природу super() from diamond import A  class U():  def ping(self): print(f'{self}.ping() in U') super().ping()  class LeafUA(U, A):  def ping(self): print(f'{self}.ping() in LeafUA') super().ping()  Класс A берется из diamond.py (пример 14.4).  Класс U не связан ни с A, ни с Root из модуля diamond.  Что делает super().ping() ? Ответ: зависит от ситуации. Читайте дальше.  LeafUA наследует U и A именно в таком порядке. Создав экземпляр U и попытавшись вызвать его метод ping, мы получим ошибку: >>> u = U() >>> u.ping() Traceback (most recent call last): AttributeError: 'super' object has no attribute 'ping' У объекта 'super', возвращенного функцией super(), нет атрибута 'ping', по- тому что в MRO U есть два класса: U и object, а у последнего атрибут 'ping' от- сутствует. Однако с методом U.ping не все так безнадежно. Попробуем: Множественное наследование и порядок разрешения методов  471\n--- Страница 471 ---\n>>> leaf2 = LeafUA() >>> leaf2.ping() <instance of LeafUA>.ping() in LeafUA <instance of LeafUA>.ping() in U <instance of LeafUA>.ping() in A <instance of LeafUA>.ping() in Root >>> LeafUA.__mro__ # doctest:+NORMALIZE_WHITESPACE (<class 'diamond2.LeafUA'>, <class 'diamond2.U'>, <class 'diamond.A'>, <class 'diamond.Root'>, <class 'object'>) Вызов super().ping() в LeafUA активирует U.ping, кооперативный метод, который вызывает super().ping() , что активирует A.ping и в конечном счете Root.ping. Заметим, что базовыми классами LeafUA являются (U, A) в таком порядке. Если бы базовыми классами были (A, U), то вызов leaf2.ping() так и не дошел бы до U.ping, потому что super().ping() в A.ping активировал бы Root.ping, а этот метод не вызывает super(). В реальной программе класс, подобный U, был бы классом-примесью, т. е. классом, который предназначен для работы с другими классами при множест - венном наследовании с целью придать им дополнительную функциональ- ность. Мы будем обсуждать эту тему в разделе «Классы-примеси». Чтобы подвести итоги обсуждению MRO, я на рис. 14.2 изобразил часть сложного графа множественного наследования пакета Tkinter для построения пользовательских интерфейсов из стандартной библиотеки Python. Рис. 14.2. Слева: UML-диаграмма класса виджета Text из пакета Tkinter и его суперклассов. Справа: пунктирными стрелками обозначен длинный и извилистый путь Text.__mro__ Изучая этот рисунок, начните с класса Text внизу. Класс Text реализует мно- гострочный редактируемый текстовый виджет. Он обладает богатой функцио- нальностью сам по себе, но еще и наследует многочисленные методы от дру-472  Наследование: к добру или к худу\n--- Страница 472 ---\nгих классов. В левой части рисунка показана обычная UML-диаграмма классов. А справа она дополнена стрелками, показывающими порядок MRO, получен- ный с помощью вспомогательной функции print_mro из примера 14.7: Пример 14.7. MRO класса tkinter.Text >>> def print_mro(cls): print(', '.join(c.__name__ for c in cls.__mro__)) >>> import tkinter >>> print_mro(tkinter.Text) Text, Widget, BaseWidget, Misc, Pack, Place, Grid, XView, YView, object А теперь поговорим о примесях. клаССы-примеСи Класс-примесь предназначен для того, чтобы ему наследовали вместе с еще хотя бы одним классом при организации множественного наследования. При- месь не должна быть единственным базовым классом конкретного класса, по- тому что не предоставляет полную функциональность конкретного объекта, а лишь добавляет или настраивает поведение классов-потомков или братьев. Классы-примеси – соглашение, не имеющее явной поддержки в Python и C++. Но Ruby позволяет явно определить и использовать модули, работающие как примеси, т. е. содержащие набор мето- дов, которые можно включить для расширения функционально- сти класса. В C#, PHP и Rust реализованы классы-характеристики (traits), также представляющие собой явную форму примесей. Рассмотрим простой, но практически полезный пример класса-примеси. Отображения, не зависящие от регистра В примере 14.8 показан класс UpperCaseMixin , который дает не зависящий от ре- гистра доступ к отображениям с ключами-строками. Для этого он преобразует в верхний регистр ключи при добавлении и поиске. Пример 14.8. uppermixin.py: UpperCaseMixin поддерживает отображения, не зависящие от регистра import collections def _upper(key):  try: return key.upper() except AttributeError: return key class UpperCaseMixin:  def __setitem__(self, key, item): super().__setitem__(_upper(key), item) def __getitem__(self, key): return super().__getitem__(_upper(key)) Классы-примеси  473\n--- Страница 473 ---\ndef get(self, key, default=None): return super().get(_upper(key), default) def __contains__(self, key): return super().__contains__(upper(key))  Эта вспомогательная функция принимает ключ key любого типа и пытается вернуть key.upper(); если это не получается, то возвращает исходный ключ.  Примесь реализует четыре основных метода отображений и всегда вызывает super() с ключом, преобразованным в верхний регистр (если это возможно). Поскольку все методы UpperCaseMixin вызывают super(), эта примесь зависит от класса на том же уровне иерархии, который реализует или наследует методы с такой же сигнатурой. Чтобы внести свой вклад, примесь обычно должна на- ходиться раньше других классов в MRO использующего ее подкласса. На прак - тике это означает, что примеси должны располагаться в начале кортежа базо- вых классов в объявлении класса. В примере 14.9 показаны две ситуации. Пример 14.9. uppermixin.py: два класса, использующих UpperCaseMixin class UpperDict(UpperCaseMixin, collections.UserDict):  pass class UpperCounter(UpperCaseMixin, collections.Counter):  \"\"\"Специализированный 'Counter', который переводит строковые ключи в верхний регистр\"\"\"   UpperDict не нуждается в собственной реализации, но UpperCaseMixin должен быть первым базовым классом, иначе вызывались бы методы из UserDict.  UpperCaseMixin работает также с Counter.  Вместо pass лучше включить строку документации, чтобы удовлетворить синтаксическим требованиям к телу предложения class. Ниже приведено несколько тестов для UpperDict из файла uppermixin.py: >>> d = UpperDict([('a', 'letter A'), (2, 'digit two')]) >>> list(d.keys()) ['A', 2] >>> d['b'] = 'letter B' >>> 'b' in d True >>> d['a'], d.get('B') ('letter A', 'letter B') >>> list(d.keys()) ['A', 2, 'B'] И демонстрация работы UpperCounter : >>> c = UpperCounter('BaNanA') >>> c.most_common() [('A', 3), ('N', 2), ('B', 1)] Классы UpperDict и UpperCounter кажутся почти магическими, но мне пришлось внимательно изучить код UserDict и Counter, чтобы заставить UpperCaseMixin дей- ствовать с ними заодно.474  Наследование: к добру или к худу\n--- Страница 474 ---\nНапример, в первой моей версии UpperCaseMixin не было метода get. Она ра- ботала с UserDict, но не с Counter. Класс UserDict наследует get от collections.abc. Mapping, и этот get вызывает __getitem__ , реализованный мной. Но ключи не пере- водились в верхний регистр, когда UpperCounter загружался на стадии __init__. Это было связано с тем, что Counter.__init__ вызывает Counter.update , который, в свою очередь, полагается на метод get, унаследованный от dict. Однако метод get в классе dict не вызывает __getitem__ . Это и есть корень проблемы, обсуждав- шейся в разделе «Несогласованное использование __missing__ в стандартной библиотеке» главы 3. Это также может служить яркой иллюстрацией хрупкого и подчас необъяснимого поведения программ, в которых используется насле- дование, пусть даже и в скромных масштабах. В следующем разделе мы рассмотрим несколько примеров множественного наследования, зачастую с использованием классов-примесей. мнОжеС твеннОе наСледОвание в реальнОм мире В книге «Паттерны проектирования»1 почти весь код написан на C++, но един- ственный пример множественного наследования дает паттерн Адаптер. В Python множественное наследование тоже не является нормой, но имеются важные примеры, которые я и хочу прокомментировать в этом разделе. ABC – тоже примеси В стандартной библиотеке Python множественное наследование особенно хо- рошо заметно в пакете collections.abc . И тут нет никакого противоречия: в кон- це концов, даже в Java поддерживается множественное наследование интер- фейсов, а ABC – это объявление интерфейса, которое может содержать реали- зации конкретных методов2. В официальной документации по модулю collections.abc (https://docs.python. org/3/library/collections.abc.html) термин подмешанный метод (mixin method) упо- требляется для конкретных методов, реализованных во многих ABC коллекций. ABC, предоставляющие подмешанные методы, играют две роли: это опреде- ления интерфейсов и одновременно классы-примеси. Например, реализация collections.UserDict (https://github.com/python/cpython/blob/8ece98a7e418c3c68a4c61b c47a2d0931b59a889/Lib/collections/__init__.py#L1084) опирается на несколько под- мешанных методов, предоставляемых классом collections.abc.MutableMapping . ThreadingMixIn и ForkingMixIn Пакет http.server ( https://github.com/python/cpython/blob/8ece98a7e418c3c68a4c61bc 47a2d0931b59a889/Lib/collections/__init__.py#L1084) предоставляет классы HTTPServer 1 Erich Gamma, Richard Helm, Ralph Johnson, John Vlissides. Design Patterns: Elements of Reusable Object-Oriented Software (Addison-Wesley). 2 Выше уже упоминалось, что в Java 8 интерфейсам тоже разрешено предоставлять реализации методов. Эта новая возможность в официальном «Учебнике Java» на- зывается «методы по умолчанию» (https://docs.oracle.com/javase/tutorial/java/IandI/ defaultmethods.html). Множественное наследование в реальном мире  475\n--- Страница 475 ---\nи ThreadingHTTPServer . Последний был добавлен в версии Python 3.7. В его докумен- тации сказано: class http.server.ThreadingHTTPServer(server_address, RequestHandlerClass) Этот класс идентичен HTTPServer , но для обработки запросов применяет по- токи, используя ThreadingMixIn . Это полезно при работе с браузерами, кото- рые заранее открывают сокеты, поскольку HTTPServer в этом случае ждал бы неопределенно долго. Ниже приведен полный исходный код (https://github.com/python/cpython/ blob/ 17c23167942498296f0bdfffe52e72d53d66d693/Lib/http/server.py#L144) класса ThreadingHTTPServer в Python 3.10: class ThreadingHTTPServer(socketserver.ThreadingMixIn, HTTPServer): daemon_threads = True Исходный код (https://github.com/python/cpython/blob/699ee016af5736ffc80f6835 9617611a22b72943/Lib/socketserver.py#L664) класса socketserver.ThreadingMixIn насчи- тывает 38 строк, включая комментарии и строки документации. Пример 14.10 дает представление о его реализации. Пример 14.10. Часть Lib/socketserver.py в Python 3.10 class ThreadingMixIn: \"\"\"Класс-примесь для обработки каждого запроса в отдельном потоке.\"\"\" # 8 строк опущено def process_request_thread(self, request, client_address):  # 6 строк опущено def process_request(self, request, client_address):  # 8 строк опущено def server_close(self):  super().server_close() self._threads.join()  process_request_thread не вызывает super(), потому что это новый, а не пере- определенный метод. Его реализация вызывает три метода экземпляра, которые HTTPServer предоставляет или наследует.  Этот метод переопределяет метод process_request , который HTTPServer насле- дует от socketserver.BaseServer . При этом запускается поток, а фактическая ра- бота делегируется методу process_request_thread , работающему в этом потоке. Функция super() не вызывается.  server_close вызывает super().server_close() , чтобы прекратить прием запро- сов, а затем ждет завершения потоков, запущенных process_request . Описание класса ThreadingMixIn находится в документации по модулю socketserver рядом с ForkingMixin . Последний предназначен для поддержки кон- курентных серверов, основанных на os.fork(), API для запуска дочернего про- цесса в POSIX-совместимых системах типа Unix.476  Наследование: к добру или к худу\n--- Страница 476 ---\nПримеси в обобщенных представлениях Django Для чтения этого раздела не нужно быть знатоком Django. Я использую лишь малую часть данного каркаса как прак - тический пример применения множественного насле- дования и постараюсь по ходу дела сообщить все необ- ходимые сведения, предполагая, правда, что вы имеете какой-то опыт разработки серверных веб-приложений на другом языке или с помощью иного каркаса. В Django представление – это вызываемый объект, который принимает в ка- честве аргумента объект, представляющий HTTP-запрос, и возвращает объ- ект, представляющий HTTP-ответ. Нас в этом обсуждении будут интересовать различные ответы. Они могут быть совсем простыми, например ответ с пере- направлением, вообще не имеющий тела, или весьма сложными, например страница каталога интернет-магазина, которая строится по HTML-шаблону и содержит список товаров с кнопками для покупки и ссылками на страницы подробной информации. Первоначально Django предоставлял набор функций, называемых обобщен- ными представлениями, которые реализовывали наиболее распространенные частные случаи. Например, на многих сайтах показываются результаты поис - ка, которые включают информацию о различных объектах, причем список мо- жет быть многостраничным, а для каждого объекта имеется ссылка на страни- цу с детальной информацией. В Django списковое представление и детальное представление спроектированы так, чтобы совместно решать эту задачу: спис- ковое представление отображает результаты поиска, а детальное формирует страницы с информацией об отдельных объектах. Однако изначально обобщенные представления были просто функциями, т. е. не допускали расширения. Если нужно было сделать что-то похожее на обобщенное списковое представление, но не в точности совпадающее с ним, приходилось начинать с нуля. Концепция представлений на основе классов появилась в Django 1.3 вмес те с набором классов обобщенных представлений, состоящим из базовых классов, примесей и готовых конкретных классов. В Django 3.2 базовые классы и при- меси находятся в модуле base из пакета django.views.generic (рис. 14.3). В верхней части диаграммы мы видим два класса, на которые возложены совершенно разные обязанности: View и TemplateResponseMixin . Множественное наследование в реальном мире  477\n--- Страница 477 ---\nРис. 14.3. UML-диаграмма классов из модуля django.views.generic.base Замечательным ресурсом для изучения этих классов является сайт Classy Class-Based Views (http://ccbv.co.uk/), где организована удоб- ная навигация и можно посмотреть все методы каждого класса (унаследованные, переопределенные и добавленные), диаграммы, документацию и даже перейти в исходный код на сайте GitHub (https://github.com/django/django/tree/main/django/views/generic). View является базовым классом всех представлений (он мог бы быть аб- страктным) и предоставляет основную функциональность, например метод dispatch, делегирующий работу методам-обработчикам – get, head, post и др., – ко- торые реализованы в конкретных классах для обработки различных глаголов HTTP1. Класс RedirectView наследует только View и, как видите, реализует методы get, head, post и т. д. 1 Программирующие на Django знают, что метод класса as_view – самая заметная часть интерфейса View, но нам это сейчас неинтересно. 478  Наследование: к добру или к худу\n--- Страница 478 ---\nНо если предполагается, что конкретные подклассы View реализуют методы- обработчики, то почему же они не являются частью интерфейса View? Причина проста: подклассы вольны реализовывать лишь те обработчики, которые счи- тают нужным поддержать. Класс TemplateView служит только для отображения содержимого, поэтому реализует лишь метод get. Если объекту TemplateView будет послан POST-запрос, то унаследованный метод View.dispatch обнаружит, что об- работчика post нет, и отправит HTTP-ответ 405 Method Not Allowed1. Класс TemplateResponseMixin предоставляет функциональность, интересную только представлениям, нуждающимся в шаблоне. Но, например, у представ- ления RedirectView нет тела, поэтому и шаблон ему не нужен, а значит, оно не на- следует эту примесь. Примесь TemplateResponseMixin предоставляет набор поведе- ний классу TemplateView и прочим представлениям, отрисовывающим шаблон, например ListView или DetailView , определенным в других модулях пакета django. views.generic . На рис. 14.4 показана диаграмма классов из модуля django.views. generic.list и частично из модуля base. Для пользователей Django самым важным из показанных на рис. 12.5 клас - сов является ListView; это агрегатный класс, в котором вообще нет кода (его тело не содержит ничего, кроме строки документации). У объекта класса ListView имеется атрибут экземпляра object_list , который шаблон может обойти, чтобы показать содержимое страницы; обычно это результат запроса к базе данных, содержащий несколько объектов. Вся функциональность, относящаяся к ге- нерации этого итерируемого объекта, находится в примеси MultipleObjectMixin . Эта же примесь предоставляет сложную логику разбиения на страницы, необ- ходимую для показа на одной странице части результатов и ссылок на другие страницы. Предположим, что требуется создать представление, которое не отрисовы- вает шаблон, а порождает список объектов в формате JSON. Для этой цели су- ществует класс BaseListView . Это точка расширения, которая объединяет функ - циональность классов View и MultipleObjectMixin , но без накладных расходов, обу- словленных механизмом шаблонов. Основанный на классах API представлений в Django – пример более пра- вильного, чем в Tkinter, использования множественного наследования. В част - ности, разобраться в классах-примесях здесь очень просто: у каждого свое чет- ко определенное назначение и имя, оканчивающееся суффиксом _Mixin. 1 Знакомые с паттернами проектирования заметят, что механизм диспетчеризации в Django – динамический вариант паттерна Шаблонный метод (http://en.wikipedia.org/ wiki/Template_method_pattern). Динамический – потому что класс View не заставляет свои подклассы реализовывать все обработчики, а dispatch на этапе выполнения про- веряет, существует ли обработчик поступившего запроса. Множественное наследование в реальном мире  479\n--- Страница 479 ---\nРис. 14.4. UML-диаграмма классов из модуля django.views.generic.list . Все три класса из модуля base свернуты (см. рис. 14.3). В классе ListView нет ни методов, ни атрибутов, это агрегатный класс Основанные на классах представления не все пользователи Django приняли на ура. Многие пользуются ими как черными ящиками, но если необходимо создать что-то новое, то по-прежнему пишут монолитные функции, которые берут на себя все обязанности, – вместо того чтобы попытаться повторно ис- пользовать классы представлений и примеси. Чтобы в полной мере понять, как использовать представления, основанные на классах, и как расширять их для решения задач конкретного приложения, нужно время, но я пришел к выводу, что это время будет потрачено не зря: они позволяют устранить стереотипный код, упрощают повторное использование и даже улучшают взаимодействие между членами команды – например, за счет стандартизации имен шаблонов и переменных, передаваемых в контекст шаблона. Представления, основанные на классах, – это представления Django «on rails», как в Ruby. Множественное наследование в Tkinter Экстремальный пример множественного наследования в стандартной библио- теке Python дает пакет построения графических интерфейсов Tkinter (https:// docs.python.org/3/library/tkinter.html). Я уже использовал иерархию одного виджета Tkinter для иллюстрации MRO на рис. 14.2, а на рис. 14.5 показаны все классы виджетов, присутствующие в базовом пакете tkinter (кроме них, есть еще много виджетов в подпакете tkinter.ttk – https://docs.python.org/3/library/tkinter.ttk.html).480  Наследование: к добру или к худу\n--- Страница 480 ---\nРис. 14.5. Сводная UML-диаграмма иерархии классов Tkinter; классы со стереотипом «mixin» предоставляют конкретные методы другим классам с помощью множественного наследования Когда я пишу эти строки, пакету Tkinter уже исполнилось 25 лет, и его нельзя считать примером лучших современных методик. Однако он показывает, как множественное наследование использовалось, когда кодировщики не прида- вали большого значения его недостаткам. И он послужит примером того, как делать не надо, когда в следующем разделе мы будем обсуждать рекомендуе- мые подходы. Рассмотрим классы, показанные на рис. 14.5.  Toplevel: класс окна верхнего уровня в приложении Tkinter.  Widget: суперкласс всех видимых объектов, которые можно разместить в окне.  Button: обычная кнопка.  Entry: однострочное редактируемое текстовое поле.  Text: многострочное редактируемое текстовое поле. Вот как выглядят MRO этих классов, напечатанные функцией print_mro из примера 14.7: >>> import tkinter >>> print_mro(tkinter.Toplevel) Toplevel, BaseWidget, Misc, Wm, object >>> print_mro(tkinter.Widget) Widget, BaseWidget, Misc, Pack, Place, Grid, object >>> print_mro(tkinter.Button) Button, Widget, BaseWidget, Misc, Pack, Place, Grid, object >>> print_mro(tkinter.Entry) Множественное наследование в реальном мире  481\n--- Страница 481 ---\nEntry, Widget, BaseWidget, Misc, Pack, Place, Grid, XView, object >>> print_mro(tkinter.Text) Text, Widget, BaseWidget, Misc, Pack, Place, Grid, XView, YView, object По современным стандартам, иерархия классов в Tkinter чрез- мерно глубокая. В немногих частях стандартной библиотеки Python встречается более трех-четырех уровней конкретных классов, и то же самое можно сказать о библиотеке классов Java. Однако интересно отметить, что некоторые из самых глубоких иерархий в библиотеке классов Java относятся как раз к паке- там, связанным с программированием GUI: java.awt (https://docs. oracle.com/javase/10/docs/api/java/awt/package-tree.html) и javax.swing (https://docs.oracle.com/javase/10/docs/api/javax/swing/package-tree. html). Squeak (https://squeak.org/), современная свободная версия Smalltalk, включает мощный инновационный инструментарий GUI под названием Morphic, и для него тоже характерна глубокая иерархия классов. По моему опыту, наборы инструментов для разработки GUI – та область, где наследование наиболее полезно. Обратите внимание на то, как эти классы связаны друг с другом. Toplevel – единственный графический класс, не наследующий Widget, по- тому что это окно верхнего уровня, и оно не ведет себя как виджет, на- пример его нельзя присоединить к окну или фрейму. Toplevel наследует классу Wm, который предоставляет функции прямого доступа к объем- лющему оконному менеджеру, например для установки заголовка окна и настройки его рамки. Widget наследует непосредственно BaseWidget , а также классам Pack, Place и Grid. Последние три класса – менеджеры компоновки, они отвечают за расположение виджетов в окне или фрейме. Каждый инкапсулирует свою стратегию и API размещения виджетов. Button, как и большинство виджетов, напрямую наследует только Widget, а опосредованно – классу Misc, который предоставляет десятки методов каждому виджету. Entry является подклассом Widget и XView – класса, который реализует го- ризонтальную прокрутку. Text наследует Widget, XView и YView – классу, реализующему вертикальную прокрутку. Далее мы обсудим некоторые рекомендации по использованию множест - венного наследования и посмотрим, согласуется ли с ними Tkinter. жизнь С мнО жеС твенным наСледОванием То, что писал Алан Кэй в эпиграфе к этой главе, остается верным и по сию пору: по-прежнему не существует общей теории наследования, которая могла бы служить руководством к действию для программистов-практиков. То, что у нас есть, – не более чем набор эвристических правил, паттернов проектиро- вания, «передовых практик», наукообразных акронимов, табу и т. д. Некоторые из них и вправду дают полезные рекомендации, но ни про одно нельзя сказать, что оно всеми принято или всегда применимо. 482  Наследование: к добру или к худу\n--- Страница 482 ---\nПрименяя наследование, пусть даже и не множественное, легко получить за- путанный и хрупкий дизайн. Ввиду отсутствия исчерпывающей теории приведем несколько советов, как избежать графов классов, напоминающих блюдо спагетти. Предпочитайте композицию наследованию класса Название этого раздела взято прямиком из книги «Паттерны проектирования»1, и лучше совета не придумаешь. Освоив наследование, очень легко впасть в грех злоупотребления им. Организация объектов в симпатичную иерархию импони- рует нашему чувству порядка; а программисты делают это просто забавы ради. Отдавая предпочтение композиции, мы получаем более гибкий дизайн. На- пример, класс tkinter.Widget мог бы не наследовать методы от всех менеджеров компоновки, а хранить ссылку на менеджер и вызывать его методы. В кон- це концов, Widget же не должен «быть» менеджером компоновки, но мог бы пользоваться его услугами с помощью делегирования. Тогда было бы нетрудно добавить новый менеджер компоновки, не изменяя иерархию классов видже- тов и не беспокоясь по поводу возможных конфликтов имен. Даже в случае одиночного наследования этот принцип повышает гибкость, поскольку созда- ние подкласса – форма тесной связанности, а глубокие деревья наследования обычно оказываются хрупкими. Композиция и делегирование могут заменить использование примесей, когда нужно предоставить некоторый набор поведений различным классам, но не могут заменить наследование интерфейсов как средство определения иерархии типов. Разберитесь, зачем наследование используется в каждом конкретном случае Имея дело с множественным наследованием, полезно ясно определить, по ка- ким причинам вообще создается подкласс. Основные причины таковы: наследование интерфейса создает подтип, подразумевая связь «являет - ся». Для этой цели лучше использовать ABC; наследование реализации позволяет избежать дублирования кода. В этом случае могут помочь примеси. На практике обе причины часто идут рука об руку, но если удается прояс - нить намерение, сделайте это. Наследование ради повторного использования кода – это деталь реализации, его нередко можно заменить композицией и де- легированием. С другой стороны, наследование интерфейса – это становой хребет любого каркаса. При наследовании интерфейса следует по возможно- сти использовать в качестве базовых классов только ABC. Определяйте интерфейсы явно с помощью ABC В современном Python класс, предназначенный для определения интерфей- са, следует явно делать абстрактным базовым классом или подклассом typing. Protocol. ABC должен быть подклассом только abc.ABC или другого ABC. Множест - венное наследование ABC не приводит ни к каким проблемам. 1 На стр. 20 введения. Жизнь с множественным наследованием  483\n--- Страница 483 ---\nИспользуйте примеси для повторного использования кода Если класс предназначен для того, чтобы предоставлять реализации методов различным не связанным между собой подклассам, не подразумевая связи «яв- ляется», то его следует явно делать классом-примесью. Концептуально примесь не определяет нового типа, а просто служит контейнером общеполезных методов. Примесь никогда не инстанцируется, и конкретные классы не должны ей наследо- вать. Каждая примесь должна определять четко очерченное поведение, реализуя несколько очень тесно связанных методов. В примесях желательно избегать внут- реннего состояния, т. е. в классе-примеси не должно быть атрибутов экземпляра. В Python нет формального способа сказать, что класс является примесью, поэтому настоятельно рекомендуется включать в имя суффикс Mixin. Предоставляйте пользователям агрегатные классы Класс, который конструируется в основном путем наследования приме- сям и не добавляет собственной структуры или поведения, называется агрегатным классом. – Буч и др.1 Если какая-то комбинация ABC или примесей может быть особенно полезна в кли- ентском коде, предоставьте класс, который объединяет их разумным образом. Вот, например, полный исходный код класса ListView из Django, показанного справа внизу на рис. 14.4 (https://github.com/django/django/blob/b64db05b9cedd96905 d637a2d824cbbf428e40e7/django/views/generic/list.py#L194): class ListView(MultipleObjectTemplateResponseMixin, BaseListView): \"\"\" Отобразить список объектов, заданный с помощью `self.model` или `self.queryset`. `self.queryset` может быть любым итерируемым объектом, а не только queryset. \"\"\" Тело класса ListView пусто, но сам класс несет полезную функцию: объединя- ет примесь и базовый класс, которые должны использоваться вместе. Еще один пример дает tkinter.Widget , который имеет четыре базовых класса и ни одного собственного метода или атрибута, только строку документации. Благодаря агрегатному классу Widget мы можем создать новый виджет с тре- буемыми примесями, не думая о том, в каком порядке их нужно перечислять в объявлении, чтобы все работало, как задумано. Отметим, что агрегатные классы не обязаны быть пустыми, но часто имен- но так и бывает. Наследуйте только классам, предназначенным для наследования Рецензируя эту главу, Леонардо Рохаэль предложил включить следующее предуп реждение: 1 Grady Booch et al. Object-Oriented Analysis and Design with Applications. 3-е изд. Addison-Wesley. С. 109.484  Наследование: к добру или к худу\n--- Страница 484 ---\nНаследование сложному классу и переопределение его методов – занятие, чреватое ошибками, потому что методы суперкласса могут неожиданно игнорировать переопределения, сделанные в подклассе. Старайтесь избегать переопределения методов или, по крайней мере, ограничьтесь наследованием классов, которые специально спроектированы так, чтобы их было легко расширять, и только так, как было предусмотрено при их проектировании. Совет-то хороший, но как узнать, что класс проектировался для расширения? Первый ответ – заглянуть в документацию (иногда в форме строк докумен- тации или даже комментариев в коде). Например, Python-пакет socketserver (https://docs.python.org/3/library/socketserver.html) описывается как «каркас для по- строения сетевых серверов». Входящий в него класс BaseServer (https://docs.python. org/3/library/socketserver.html#socketserver.BaseServer) предназначен для наследова- ния, как следует из самого названия. Важнее, впрочем, то, что в документации и в строке документации в исходном коде явно указано, какие из его методов предназначены для переопределения в подклассах. В Python ≥ 3.8 есть новый способ сделать такие проектные ограничения явны- ми, он описан в документе PEP 591 «Adding a final qualifier to typing» (https://peps. python.org/pep-0591/), где вводится декоратор @final (https://docs.python.org/3/library/ typing.html#typing.final), который можно применять к классам и отдельным мето- дам, в результате чего IDE или программа проверки типов сообщит о неразум- ных попытках унаследовать такому классу или переопределить такой метод1. Воздерживайтесь от наследования конкретным классам Наследование конкретным классам опаснее наследования ABC и примесям, потому что у экземпляров конкретных классов обычно имеется внутреннее состояние, которое легко можно повредить при переопределении зависящих от него методов. Даже если ваши методы кооперативные, т. е. вызывают super() , и даже если их внутреннее состояние хранится в атрибутах, закрытых благода- ря синтаксической конструкции __x, все равно не счесть возможностей внести ошибку вследствие переопределения методов. Во вставном эссе «Водоплавающие птицы и ABC» в главе 13 Алекс Мартелли приводит цитату из книги Скотта Мейерса «Наиболее эффективное использо- вание C++»2, в которой высказано еще более радикальное мнение: «все нелис - товые классы должны быть абстрактными». Иными словами, Мейер говорит, что наследовать можно только абстрактным классам. Если вам все-таки необходимо использовать наследование ради повторного использования кода, то этот код следует размещать в подмешиваемых методах ABC или в явно поименованных классах-примесях. Tkinter: хороший, плохой, злой Модуль Tkinter не следует большинству изложенных выше рекомендаций, за исключением совета предоставлять пользователям агрегатные классы. 1 В PEP 591 введена также аннотация Final (https://docs.python.org/3/library/typing. html#typing.Final) для переменных или атрибутов, которым не следует переприсваи- вать значение или переопределять. 2 Скотт Мейерс. Наиболее эффективное использование C++. М.: ДМК Пресс, 2012 // https://dmkpress.com/catalog/computer/programming/c/978-5-94074-990-5/ Жизнь с множественным наследованием  485\n--- Страница 485 ---\nНо даже в этом отношении я бы не стал ставить его в пример, потому что ком- позиция, пожалуй, была бы уместнее для интеграции менеджеров компоновки с классом Widget, о чем было написано в рекомендации «Предпочитайте компо- зицию наследованию класса». Помните, что Tkinter является частью стандартной библиотеки еще со вре- мен версии Python 1.1, выпущенной в 1994 году. Tkinter – это слой поверх ве- ликолепной библиотеки Tk, поставляемой вместе с языком Tcl. Комбинация Tcl/Tk изначально не была объектно-ориентированной, поэтому Tk API пред- ставляет собой просто обширный набор функций. Однако концептуально эта библиотека в высшей степени объектно-ориентированная, пусть даже реали- зация Tcl таковой не является. Строка документации tkinter.Widget начинается словами «Internal class». Это наводит на мысль, что Widget, наверное, следовало бы сделать ABC. Хотя у клас - са Widget нет собственных методов, он тем не менее определяет интерфейс. Его посыл таков: «Можете рассчитывать, что каждый виджет Tkinter предостав- ляет основные методы виджета (__init__, destroy и десятки функций из Tk API) в дополнение к методам всех трех менеджеров компоновки». Можно согла- ситься, что такое определение интерфейса далеко от совершенства (слишком широкое), но все же это интерфейс, а Widget «определяет» его как объединение интерфейсов своих суперклассов. Класс Tk, который инкапсулирует прикладную логику графического интер- фейса пользователя (GUI), наследует классам Wm и Misc, не являющимся ни аб- страктными, ни примесями (Wm – не совсем примесь, потому что ему наследу - ет TopLevel). От самого имени класса Misc очень сильно отдает запашком. В Misc больше 100 методов, и ему наследуют все виджеты. А разве каждому видже- ту нужны методы для работы с буфером обмена, для выделения текста, для управления таймером и т. д.? Ведь невозможно вставить что-то в кнопку из буфера обмена или выделить текст полосы прокрутки. Класс Misc следовало бы разбить на несколько специализированных классов-примесей и не заставлять все виджеты наследовать каждому из этих классов. Но будем справедливы – пользователю Tkinter вовсе необязательно знать о множественном наследовании. Эта деталь реализации скрыта за фасадом классов виджетов, которые вы инстанцируете или которым наследуете в своем коде. Однако пользователь почувствует последствия злоупотребления множест- венным наследованием, если наберет dir(tkinter. Button) и попытается найти нуж- ный метод среди 214 перечисленных атрибутов. И вам придется столкнуться лицом к лицу со сложностью, если вы пожелаете реализовать новый виджет Tk. Несмотря на все проблемы, Tkinter предлагает стабильный, гиб- кий и вполне современный на вид интерфейс, а если вы восполь- зуетесь пакетом tkinter.ttk , то получите виджеты, поддержи- вающие темы. Кроме того, некоторые оригинальные виджеты, например Canvas и Text, обладают поразительно богатыми воз- можностями. Добавив немного своего кода, вы можете превра- тить объект Canvas в простое приложение для рисования, поддер- живающее перетаскивание. С Tkinter и Tcl/Tk определенно стоит познакомиться, если вы занимаетесь программированием GUI. На этом мы завершаем экскурсию по лабиринту наследования. 486  Наследование: к добру или к худу\n--- Страница 486 ---\nрезюме Мы начали эту главу с обзора функции super() в контексте одиночного наследо- вания. Затем обсудили проблему наследования встроенным типам: их методы, реализованные на C, не вызывают методы, переопределенные в подклассах, за исключением немногих частных случаев. Именно поэтому в тех случаях, когда нам нужен специальный список, словарь или строка, проще наследовать не классам list, dict или str, а классам UserList, UserDict или UserString – все они определены в модуле collections (https://docs.python.org/3/library/collections.html) и фактически обертывают встроенные типы, делегируя им работу, – это три примера использования композиции вместо наследования в стандартной биб лиотеке. Если требуемое поведение очень сильно отличается от поведения встроенных классов, то, быть может, проще унаследовать подходящему ABC из модуля collections.abc (https://docs.python.org/3/library/collections.abc.html) и на- писать собственную реализацию. Остаток главы был посвящен обоюдоострому мечу множественного насле- дования. Сначала мы познакомились с порядком разрешения методов, кото- рый закодирован в атрибуте класса __mro__ и решает проблему потенциального конфликта имен в унаследованных методах. Мы также видели, как встроенная функция super() ведет себя, иногда неожиданно, в иерархиях с множественным наследованием. Функция super() спроектирована с целью поддержки классов- примесей, которые мы изучили на простом примере класса UpperCaseMixin для отображений, не зависящих от регистра. Мы видели, как множественное наследование и подмешанные методы используются в абстрактных базовых классах, а также в примесях для ис- полнения запросов в отдельных потоках и процессах, входящих в состав модуля socketserver . Более сложные применения множественного наследо- вания мы рассмотрели на примерах, основанных на классах представлений Django и набора инструментов Tkinter для разработки GUI. Tkinter не на- зовешь образцом современных передовых практик, это пример чрезмерно усложненных иерархий классов, которые можно встретить в унаследован- ных системах. В заключение я предложил семь рекомендаций по использованию наследо- вания и проиллюстрировал их на примере иерархии классов в Tkinter. Отказ от наследования – даже одиночного – современная тенденция. Одним из самых успешных языков, созданных в XXI веке, является Go. В нем нет кон- струкции, именуемой «класс», но можно строить типы, представляющие собой структуры инкапсулированных полей, и присоединять к этим структурам ме- тоды. Go позволяет определять интерфейсы, которые проверяются компиля- тором с помощью структурной типизации, по аналогии со статической утиной типизацией – очень похоже на то, что мы теперь имеем в виде протокольных типов, начиная с версии Python 3.8. В Go имеется специальный синтаксис для построения типов и интерфейсов посредством композиции, но наследование он не поддерживает – даже наследование интерфейсов. Таким образом, пожалуй, лучший совет по поводу наследования – избегайте его, если можете. Но зачастую просто нет выбора: применяемый каркас дик- тует свои правила. Резюме  487\n--- Страница 487 ---\nдОпО лнительная литература Если говорить о чтении, то ясность и правильно исполненная композиция дадут сто очков вперед наследованию. Поскольку код гораздо чаще чита- ют, чем пишут, избегайте подклассов вообще, но особенно сторонитесь смешения разных типов наследования и не пользуйтесь подклассами для организации разделения кода. – Хинек Шлавак, «Subclassing in Python Redux» В последний раз перечитывая эту книгу, технический рецензент Юрген Гмах ре- комендовал мне статью Хинека Шлавака «Subclassing in Python Redux» (https:// hynek.me/articles/python-subclassing-redux/), из которой взята предыдущая цитата. Шлавак – автор пакета attrs и один из основных соавторов каркаса асинхрон- ного программирования Twisted – проекта, запущенного Глифом Лефковицем в 2002 году. Со временем, по словам Шлавака, команда разработчиков ядра пришла к выводу, что слишком увлеклась наследованием. Его статья длинная, в ней много цитат из других статей и бесед. Всячески рекомендую. В заключение к той статье Хинек Шлавак писал: «Не забывайте, что чаще всего вам достаточно просто функции». Я с ним согласен, и именно по этой причине в моей книге функции подробно рассматриваются раньше классов и наследования. Я ставил себе целью показать, сколь многого можно достичь с помощью функций, обращающихся к классам из стандартной библиотеки, не прибегая до поры к созданию собственных классов. Наследование встроенным классам, функция super и такие продвинутые средства, как дескрипторы и метаклассы, – все это описано в статье Гвидо ван Россума «Unifying types and classes in Python 2.2» (https://www.python.org/ download/releases/2.2.3/descrintro/). С тех пор никаких существенных измене- ний в эти вещи не вносилось. Python 2.2 стал потрясающей вехой в эволюции языка, добавившей несколько мощных новых средств в единое целое и не нарушившей при этом обратной совместимости. Все новые возможности по умолчанию были отключены. Чтобы воспользоваться ими, нужно было явно унаследовать object – прямо или косвенно – и создать «класс в новом стиле». В Python 3 любой класс наследует object. В книге David Beazley, Brian K. Jones «Python Cookbook», 3-е издание (O’Reilly), есть несколько рецептов, демонстрирующих использование super() и классов-приме- сей. Можете начать с просветляющего раздела «8.7. Вызов метода родительского класса» (https://www.oreilly.com/library/view/python-cookbook-3rd/9781449357337/ch08. html#super) и следовать по ведущим из него внутренним ссылкам. Раймонд Хэттингер в статье «Python’s super() considered super!» (https:// rhettinger.wordpress.com/2011/05/26/super-considered-super/) объясняет работу функ - ции super и множественное наследование в Python с позитивной точки зрения. Она была написана в ответ на статью «Python’s Super is nifty, but you can’t use it» (известную также под названием «Python’s Super Considered Harmful») (https:// fuhm.net/super-harmful/) Джеймса Найта. Ответ Мартина Питерса на вопрос «How to use super() with one argument?» (https://stackoverflow.com/questions/ 30190185/ how-to-use-super-with-one-argument/30190341#30190341) содержит краткое и глу - бокое объяснение super, включая ее связь с дескрипторами, изучение которых мы отложим до главы 23. Такова природа super. Она проста в базовых случаях 488  Наследование: к добру или к худу\n--- Страница 488 ---\nприменения, но является мощным и сложным инструментом, затрагивающим самые потаенные динамические механизмы Python, которые редко встретишь в других языках. Несмотря на заглавия этих статей, проблема не в самой встроенной функции super – которая в Python 3 не так безобразна, как в Python 2. Настоящая пробле- ма – множественное наследование и присущие ему внутренние сложности. Ми- шель Симионато не ограничился критикой, а предложил решение в своей статье «Setting Multiple Inheritance Straight» (https://www.artima.com/weblogs/viewpost.jsp? thread=246488): он реализовал классы-характеристики (traits) – ограниченную форму примесей, впервые предложенную в языке Self. Перу Симионату при- надлежит целая серия статей о множественном наследовании в Python, вклю- чая «The wonders of cooperative inheritance, or using super in Python 3» (https:// www.artima.com/weblogs/viewpost.jsp?thread=281127), «Mixins considered harmful», часть 1 (https://www.artima.com/weblogs/viewpost.jsp?thread=236275) и часть 2 (https:// www.artima.com/weblogs/viewpost.jsp?thread=246483), и «Things to Know About Python Super», часть 1 (https://www.artima.com/weblogs/viewpost.jsp? thread=236275), часть 2 (https://www.artima.com/weblogs/viewpost.jsp? thread=236278) и часть 3 (https:// www.artima.com/weblogs/viewpost.jsp?thread= 237121). В ранних статьях использует - ся синтаксис super из Python 2, но они по-прежнему актуальны. Я читал первое издание книги Grady Booch et al. «Object-Oriented Analysis and Design», 3-е издание, и горячо рекомендую ее как общее введение в объектно-ори- ентированное мышление вне зависимости от языка программирования. Эта кни- га – редкий пример обсуждения множественного наследования без предрассудков. Теперь больше, чем когда-либо прежде, стало модным избегать наследова- ния, поэтому приведу две ссылки на источники, показывающие, как это сделать. Брэндон Родс написал статью «The Composition Over Inheritance Principle» (https:// python-patterns.guide/gang-of-four/composition-over-inheritance/), вошедшую в состав его прекрасного руководства «Python Design Patterns». Оджи Факлер и Натаниэль Маниста провели презентацию «The End Of Object Inheritance & The Beginning Of A New Modularity» (https://www.youtube.com/watch?v=3MNVP9-hglc) на конференции PyCon 2013. Факлер и Маниста рассуждают об организации систем вокруг интер- фейсов и функций, которые обрабатывают объекты, реализующие эти интерфей- сы, избегая тесной связанности и ошибок, присущих классам и наследованию. Это сильно напоминает мне путь Go, но они выступают за его применение в Python. Поговорим Думайте, какие классы вам действительно необходимы Мы начали продвигать идею наследования как способ, который позво- лил бы начинающим положить в основу каркасы, которые было по силам спроектировать только экспертам. – Алан Кэй, «The Early History of Smalltalk»1 1 Alan Kay. The Early History of Smalltalk. SIGPLAN Not. 28, 3 (March 1993), 69–95. Доступ- но также онлайн (http://worrydream.com/EarlyHistoryOfSmalltalk/). Спасибо моему другу Кристиано Андерсону, поделившемуся этой ссылкой. Дополнительная литература  489\n--- Страница 489 ---\nПодавляющее большинство программистов пишут приложения, а не карка- сы. Но даже те, кто разрабатывает каркасы, скорее всего, тратят значительную (если не основную) часть своего времени на создание приложений. При напи- сании приложений мы обычно не разрабатываем иерархии классов. Как пра- вило, мы пишем классы, наследующие ABC или другим классам, предоставля- емым каркасом. Авторам приложений крайне редко приходится писать класс, выступающий в роли суперкласса. Почти всегда мы создаем листовые классы (расположенные в листьях дерева наследования). Если, разрабатывая приложение, вы ловите себя на создании многоуровневой иерархии классов, то, скорее всего, имеет место что-то из перечисленного ниже. Вы изобретаете велосипед. Посмотрите, нет ли в библиотеке или каркасе компонентов, которые вы могли бы повторно использовать в своем при- ложении. Вы работаете с плохо спроектированным каркасом. Поищите альтерна- тиву. Вы чрезмерно усложняете задачу. Вспомните принцип KISS. Вам наскучило писать приложения, и вы решили создать новый каркас. Примите поздравления и пожелания успеха! Может также случиться, что к вашей ситуации применимы все четыре пункта: вам надоела рутина, и вы решили изобрести новый велосипед, построив свой чрезмерно усложненный и плохо спроектированный каркас, который застав- ляет вас писать один класс за другим для решения тривиальных задач. Наде- юсь, вы получаете от этого удовольствие или хотя бы эта работа оплачивается. Неправильное поведение встроенных типов: ошибка или так задумано? Встроенные типы dict, list и str – важнейшие структурные элементы само- го языка Python, поэтому они должны работать быстро, иначе плохо будет всем. Поэтому в CPython принят ряд компромиссных решений, из-за которых встроенные методы игнорируют методы, переопределенные в подклассах, что можно считать некорректным поведением. Возможный выход из этой ситуации: завести две реализации каждого типа: «внутреннюю», оптимизи- рованную для использования самим интерпретатором, и внешнюю, которую можно было бы расширять. Но именно это мы и имеем: классы UserDict, UserList и UserString работают не так быстро, как встроенные, зато расширяются без проблем. Принятый в CPython прагматичный подход означает, что и мы в своих приложениях обычно используем оптимизированные реализации, которым трудно насле- довать. Это имеет смысл, если принять во внимание, что не так уж часто нам нужны специальные списки, отображения или строки. Следует только пом- нить о том, чем мы жертвуем. Наследование в разных языках Алан Кэй придумал термин «объектно-ориентированный», и в языке Smalltalk было только одиночное наследование, хотя существуют клоны с различными формами поддержки множественного наследования, в частности современ- ные диалекты Squeak и Pharo Smalltalk, в которых поддерживаются характе- ристики (traits) – конструкции, играющие роль класса-примеси, но позволяю- щие избежать некоторых проблем множественного наследования.490  Наследование: к добру или к худу\n--- Страница 490 ---\nПервым популярным языком с поддержкой множественного наследования стал C++, но это средство использовалось во вред настолько часто, что про- ектировщики языка Java – задуманного как замена C++ – отказались от мно- жественного наследования реализации (т. е. от классов-примесей). И так было до выпуска Java 8, где появились методы по умолчанию, благодаря которым интерфейсы Java стали очень напоминать абстрактные классы, применяемые для определения интерфейсов в C++ и Python. После Java, пожалуй, самым распространенным языком на платформе JVM является Scala, и в нем реали- зованы характеристики. Среди других языков, поддерживающих характеристики, упомянем послед- ние стабильные версии PHP и Groovy, а также находящиеся в процессе раз- работки Rust и Raku – язык, который раньше был известен как Perl 61. Так что будет справедливо сказать, что в 2021 году классы-характеристики – модная тенденция. В Ruby принят оригинальный подход к множественному наследованию: оно не поддерживается, зато примеси являются полноправным языковым сред- ством. Класс Ruby может включать модуль, так что определенные в модуле методы становятся частью реализации класса. Это «чистая» форма примеси, не нуждающаяся ни в каком наследовании, и ясно, что примесь в Ruby никак не влияет на тип класса, в котором используется. Тем самым мы получаем все преимущества примесей без многих связанных с ними проблем. Два недавно созданных языка, привлекающих всеобщее внимание, – Go и Julia – серьезно ограничили наследование. Оба предназначены для про- граммирования «объектов» и поддерживают полиморфизм (https://en.wikipedia. org/wiki/ Polymorphism_(computer_science)), но термина «класс» избегают. В Go наследования нет вообще. В Julia иерархии типов существуют, однако подтип может наследовать только поведение, но не структуру, причем под- типы могут существовать только у абстрактных типов. Кроме того, методы в Julia реализованы с применением множественной диспетчеризации – более развитой формы механизма, который мы обсуждали в разделе «Обобщенные функции с одиночной диспетчеризацией» главы 9. 1 Мой друг и технический рецензент Леонардо Рохаэль объяснит лучше меня: «То, что Perl 6 продолжает где-то маячить, но никак не явит себя миру, положило конец эво- люции самого Perl. Теперь разработка Perl продолжается как отдельного языка (сей- час это уже версия 5.34), и нет никаких признаков, что этому будет положен конец в связи с появлением языка, который когда-то назывался Perl 6». Дополнительная литература  491",
      "debug": {
        "start_page": 461,
        "end_page": 490
      }
    },
    {
      "name": "Глава 15. Еще об аннотациях типов 492",
      "content": "--- Страница 491 --- (продолжение)\nГлава 15 Еще об аннотациях типов Дорогой ценой я выучил урок: для небольших программ динамическая типизация – благо. Но для более крупных программ необходим более дис- циплинированный подход. И хорошо, когда язык предлагает такую дис- циплину, а не говорит «Да делай ты что хочешь». – Гвидо ван Россум, фанат Монти Пайтон1 Эта глава – продолжение главы 8, в ней излагаются дополнительные сведения о системе постепенной типизации в Python. Рассматриваются следующие темы: перегруженные сигнатуры функций; использование typing.TypedDict для аннотирования словарей, используе- мых как записи; приведение типов; доступ к аннотациям типов во время выполнения; обобщенные типы: объявление обобщенного класса; вариантность: инвариантные, ковариантные и контравариантные типы; обобщенные статические протоколы. чтО нОвОг О в этОй главе Это новая глава, написанная специально для второго издания книги. Мы нач- нем с перегрузки. перегруженные Сигнатуры Функции в Python могут принимать различные комбинации аргументов. Де- коратор @typing.overload позволяет аннотировать эти комбинации. Это особенно важно, когда тип возвращаемого функцией значения зависит от типа двух или более параметров. Рассмотрим встроенную функцию sum. Ниже приведен текст справки help(sum), для удобства читателя переведенный на русский язык: 1 Из видео на YouTube «Интервью с создателями языков: Гвидо ван Россум, Джеймс Гослинг, Ларри Уолл и Андерс Хейлсберг», трансляция от 2 апреля 2019. Цитата, начи- нающаяся в 1:32:05, немного сокращена. Полную запись беседы см. по адресу https:// github.com/fluentpython/language-creators.\nГлава 15 Еще об аннотациях типов Дорогой ценой я выучил урок: для небольших программ динамическая типизация – благо. Но для более крупных программ необходим более дис- циплинированный подход. И хорошо, когда язык предлагает такую дис- циплину, а не говорит «Да делай ты что хочешь». – Гвидо ван Россум, фанат Монти Пайтон1 Эта глава – продолжение главы 8, в ней излагаются дополнительные сведения о системе постепенной типизации в Python. Рассматриваются следующие темы: перегруженные сигнатуры функций; использование typing.TypedDict для аннотирования словарей, используе- мых как записи; приведение типов; доступ к аннотациям типов во время выполнения; обобщенные типы: объявление обобщенного класса; вариантность: инвариантные, ковариантные и контравариантные типы; обобщенные статические протоколы. чтО нОвОг О в этОй главе Это новая глава, написанная специально для второго издания книги. Мы нач- нем с перегрузки. перегруженные Сигнатуры Функции в Python могут принимать различные комбинации аргументов. Де- коратор @typing.overload позволяет аннотировать эти комбинации. Это особенно важно, когда тип возвращаемого функцией значения зависит от типа двух или более параметров. Рассмотрим встроенную функцию sum. Ниже приведен текст справки help(sum), для удобства читателя переведенный на русский язык: 1 Из видео на YouTube «Интервью с создателями языков: Гвидо ван Россум, Джеймс Гослинг, Ларри Уолл и Андерс Хейлсберг», трансляция от 2 апреля 2019. Цитата, начи- нающаяся в 1:32:05, немного сокращена. Полную запись беседы см. по адресу https:// github.com/fluentpython/language-creators.\n--- Страница 492 ---\n>>> help(sum) sum(iterable, /, start=0) Вернуть сумму значения 'start' (по умолчанию 0) и чисел, составляющих итерируемый объект iterable . Если объект iterable пуст, вернуть начальное значение. Эта функция предназначена для работы с числовыми значениями и может отвергать нечисловые типы. Встроенная функция sum написана на C, но в typeshed есть для нее перегру - женные аннотации типов, в файле builtins.pyi (https://github.com/python/typeshed/ blob/a8834fc d46339e17fc8add82b5803a1ce53d3d60/stdlib/2and3/builtins.pyi#L1434): @overload def sum(__iterable: Iterable[_T]) -> Union[_T, int]: @overload def sum(__iterable: Iterable[_T], start: _S) -> Union[_T, _S]: Сначала рассмотрим общий синтаксис перегрузки. Показанный выше код – все, что написано о sum в файле-заглушке (с расширением .pyi). Реализация на- ходится в другом файле. Единственное назначение многоточия (…) – удовлет - ворить требование, предъявляемое к синтаксису тела функции, по аналогии с pass. Таким образом, pyi-файлы – допустимые Python-файлы. В разделе «Аннотирование чисто позиционных и вариадических па- раметров» главы 8 отмечалось, что два начальных знака подчеркивания в __iterable – это описанное в документе PEP 484 соглашение о чисто пози- ционных параметрах, проверяемое Mypy. Оно означает, что можно писать sum(my_list) , но не sum(__iterable = my_list) . Средство проверки типов пытается сопоставить переданные аргумен- ты с каждой перегруженной сигнатурой в порядке их перечисления. Вызов sum(range(100), 1000) не соответствует первой сигнатуре, потому что у нее всего один параметр. Но второй сигнатуре он соответствует. Можно также использовать @overload в обычном Python-модуле, для чего сле- дует записывать перегруженные сигнатуры прямо перед фактической сигна- турой и реализацией функции. В примере 15.1 показано, как могла бы выгля- деть аннотированная реализация sum в Python-модуле. Пример 15.1. mysum.py: определение функции sum с перегруженными сигнатурами import operator from collections.abc import Iterable from typing import overload, Union, TypeVar T = TypeVar('T') S = TypeVar('S')  @overload def sum(it: Iterable[T]) -> Union[T, int]:  @overload def sum(it: Iterable[T], /, start: S) -> Union[T, S]:  def sum(it, /, start=0):  return functools.reduce(operator.add, it, start) Перегруженные сигнатуры  493\n--- Страница 493 ---\n Эта вторая TypeVar понадобится во второй перегруженной сигнатуре.  Это сигнатура для простого случая: sum(my_iterable) . Результирующим типом может быть T – тип элементов, отдаваемых my_iterable , – или int, если итерируе- мый объект пуст, потому что значение параметра start по умолчанию равно 0.  Если start задано, то оно может иметь тип S, так что результирующим ти- пом является Union[T, S] . Именно поэтому нам и нужна переменная S. Если бы мы повторно использовали T, то тип start должен был бы быть таким же, как тип элементов Iterable[T] .  В сигнатуре фактической реализации функции нет аннотаций типов. Довольно много строк для аннотации однострочной функции. Да, я знаю, это перебор. Но, по крайней мере, это была не функция foo. Если вы хотите больше узнать о @overload, читая код, то в typeshed есть сотни примеров. На момент, когда я пишу этот текст, в файле-заглушке (https://github. com/ python/typeshed/blob/a8834fcd46339e17fc8add82b5803a1ce53d3d60/stdlib/2and3/ builtins.pyi) для встроенных функций Python было 186 перегруженных сигнатур – больше, чем в любом другом файле-заглушке для стандартной библиотеки. Используйте постепенную типизацию с пользой Стремление получить стопроцентно аннотированный код может привести к тому, что аннотации типов будут только вносить шум, принося мало пользы. Рефакторинг с целью упростить аннотации типов может привести к громоздким API. Иногда лучше проявить разумный прагматизм и оставить часть кода неаннотированной. Удобные API, которые мы называем питоническими, часто бывает трудно аннотировать. В следующем разделе приведен пример: для правильного анно- тирования гибкой встроенной функции max необходимо шесть перегруженных вариантов. Перегрузка max Трудно добавлять аннотации типов к функциям, которые в полной мере за- действуют мощные динамические средства Python. Изучая typeshed, я наткнулся на отчет об ошибке #4051 (https://github.com/ python/typeshed/issues/4051): Mypy не предупреждает, что недопустимо переда- вать None в качестве одного из аргументов встроенной функции max() или пере- давать итерируемый объект, который в какой-то момент отдает значение None. В обоих случаях дело кончится исключением во время выполнения: TypeError: '>' not supported between instances of 'int' and 'NoneType' Документация по max начинается таким предложением: Вернуть наибольший элемент итерируемого объекта или наибольший из двух или более аргументов. Лично мне такое описание кажется интуитивно понятным. Но если передо мной стоит задача аннотировать описанную таким образом функцию, то следует спросить: какую именно? С итерируемым объектом или с двумя или более аргументами? Реальность еще сложнее, потому что max принимает два факультативных именованных аргумента: key и default. 494  Еще об аннотациях типов\n--- Страница 494 ---\nЯ написал max на Python, чтобы было проще увидеть связь между ее рабо- той и перегруженными аннотациями (встроенная функция max написана на C); см. пример 15.2. Пример 15.2. mymax.py: функция max, переписанная на Python # предложения импорта и определения опущены, см. следующий листинг MISSING = object() EMPTY_MSG = 'max() arg is an empty sequence' # перегруженные аннотации типов опущены, см. следующий листинг def max(first, *args, key=None, default=MISSING): if args: series = args candidate = first else: series = iter(first) try: candidate = next(series) except StopIteration: if default is not MISSING: return default raise ValueError(EMPTY_MSG) from None if key is None: for current in series: if candidate < current: candidate = current else: candidate_key = key(candidate) for current in series: current_key = key(current) if candidate_key < current_key: candidate = current candidate_key = current_key return candidate В этом примере нам важна не логика max, поэтому я не буду тратить время на описание реализации, а поясню только назначение MISSING. Константа MISSING – это уникальный объект, используемый как специальный маркер. Это значение по умолчанию именованного аргумента default=, поэтому max может принимать default=None и при этом различать следующие две ситуации. 1. Пользователь не задал значение аргумента default=, поэтому оно равно MISSING, и max возбуждает исключение ValueError , если first – пустой итери- руемый объект. 2. Пользователь задал значение default=, быть может None, поэтому max воз- вращает это значение, если first – пустой итерируемый объект. Чтобы исправить проблему #4051 (https://github.com/python/typeshed/issues/4051), я написал код, показанный в примере 15.31. 1 Спасибо Джелле Зийлстра – одному из сопровождающих typeshed, – научившему меня нескольким вещам, в т. ч. как сократить число перегруженных сигнатур с девя- ти в моем оригинальном коде до шести. Перегруженные сигнатуры  495\n--- Страница 495 ---\nПример 15.3. mymax.py: начало модуля, содержащее предложения импорта, определения и перегруженные сигнатуры from collections.abc import Callable, Iterable from typing import Protocol, Any, TypeVar, overload, Union class SupportsLessThan(Protocol): def __lt__(self, other: Any) -> bool: T = TypeVar('T') LT = TypeVar('LT', bound=SupportsLessThan) DT = TypeVar('DT') MISSING = object() EMPTY_MSG = 'max() arg is an empty sequence' @overload def max(__arg1: LT, __arg2: LT, *args: LT, key: None = ) -> LT: @overload def max(__arg1: T, __arg2: T, *args: T, key: Callable[[T], LT]) -> T: @overload def max(__iterable: Iterable[LT], *, key: None = ) -> LT: @overload def max(__iterable: Iterable[T], *, key: Callable[[T], LT]) -> T: @overload def max(__iterable: Iterable[LT], *, key: None = , default: DT) -> Union[LT, DT]: @overload def max(__iterable: Iterable[T], *, key: Callable[[T], LT], default: DT) -> Union[T, DT]: Длина моей реализации max на Python примерно такая же, как длина всех этих предложений импорта и объявлений. Благодаря утиной типизации в моем коде нет проверок isinstance , а проверку ошибок он обеспечивает такую же, как аннотации типов, – но, естественно, во время выполнения. Главное преимущество @overload – максимально точное объявление типа возвращаемого значения в соответствии с типами переданных аргументов. Мы увидим, как проявляется это преимущество, когда будем рассматривать перегруженные варианты max группами по одному или по два. Аргументы, реализующие SupportsLessThan, но без задания key и default @overload def max(__arg1: LT, __arg2: LT, *_args: LT, key: None = ) -> LT: # строки опущены @overload def max(__iterable: Iterable[LT], *, key: None = ) -> LT: 496  Еще об аннотациях типов\n--- Страница 496 ---\nВ этих случаях входами являются либо отдельные аргументы типа LT, реа- лизующие протокол SupportsLessThan , либо итерируемый объект Iterable, отдаю- щий такие элементы. Тип значения, возвращаемого max, такой же, как у фак - тических аргументов или элементов, как мы видели в разделе «Связанный TypeVar» главы 8. Вот примеры вызовов, соответствующих этим перегруженным сигнатурам: max(1, 2, -3) # возвращает 2 max(['Go', 'Python', 'Rust']) # возвращает 'Rust' Аргумент key задан, аргумент default нет @overload def max(__arg1: T, __arg2: T, *_args: T, key: Callable[[T], LT]) -> T: # строки опущены @overload def max(__iterable: Iterable[T], *, key: Callable[[T], LT]) -> T: Входами могут быть отдельные элементы любого типа T или один аргумент типа Iterable[T] , а key= должен быть вызываемым объектом, который прини- мает аргумент того же типа T и возвращает значение, реализующее протокол SupportsLessThan . Тип значения, возвращаемого max, такой же, как тип фактиче- ских аргументов. Примеры вызовов, соответствующих этим перегруженным сигнатурам: max(1, 2, -3, key=abs) # возвращает -3 max(['Go', 'Python', 'Rust'], key=len) # возвращает 'Python' Аргумент default задан, аргумент key нет @overload def max(__iterable: Iterable[LT], *, key: None = , default: DT) -> Union[LT, DT]: Входом может быть итерируемый объект, отдающий элементы типа LT, реа- лизующего протокол SupportsLessThan . Тип значения, возвращаемого max, такой же, как тип фактических аргументов. Аргумент default= – это значение, возвра- щаемое, когда объект Iterable пуст. Следовательно, значение, возвращаемое max, должно иметь тип, являющийся объединением (Union) типа LT и типа аргумента default. Примеры вызовов, соответствующих этой перегруженной сигнатуре: max([1, 2, -3], default=0) # возвращает 2 max([], default=None) # возвращает None Аргументы key и default заданы @overload def max(__iterable: Iterable[T], *, key: Callable[[T], LT], default: DT) -> Union[T, DT]: Входами являются: Перегруженные сигнатуры  497\n--- Страница 497 ---\nобъект Iterable, отдающий элементы любого типа T; вызываемый объект, который принимает аргумент типа T и возвращает значение типа LT, реализующего протокол SupportsLessThan ; значение по умолчанию любого типа DT. Значение, возвращаемое max, должно иметь тип, являющийся объединением типа T и типа аргумента default: max([1, 2, -3], key=abs, default=None) # возвращает -3 max([], key=abs, default=None) # возвращает None Уроки перегрузки max Аннотации типов позволяют Mypy выдавать о вызовах вида max([None, None]) та- кое сообщение об ошибке: mymax_demo.py:109: error: Value of type variable «_LT» of «max» cannot be «None» С другой стороны, необходимость писать так много строк кода, чтобы по- мочь средству проверки типов, у многих отбивает желание программировать удобные и гибкие функции наподобие max. Если бы мне пришлось заново изо- бретать еще и функцию min, я мог бы повторно использовать значительную часть реализации max. Но я был бы вынужден скопировать все перегруженные объявления, пусть даже для min они не отличаются ничем, кроме имени функ - ции. Мой друг Жоао С. О. Буэно – один из самых талантливых разработчиков на Python, которых я знаю, – написал в Твиттере такое сообщение: Хотя выразить сигнатуру max трудно, в голове она укладывается очень легко. На мой взгляд, выразительность аннотаций очень ограничена по сравнению с выразитель- ностью самого Python. Теперь давайте изучим конструкцию TypedDict. Она не так полезна, как мне казалось поначалу, но кое-какие применения у нее есть. Эксперименты с TypedDict демонстрируют ограничения статической типизации для обработки динамических структур, таких как данные в формате JSON. typeddict Возникает искушение использовать TypedDict для защиты от оши- бок при обработке таких динамических структур данных, как от- веты от JSON API. Но приведенные ниже примеры ясно показы- вают, что корректность обработки JSON-данных должна обеспе- чиваться во время выполнения, а не путем статической проверки типов. Если хотите проверять JSON-подобные структуры во вре- мя выполнения с помощью аннотаций типов, поинтересуйтесь пакетом pydantic (https://pypi.org/project/pydantic/) в архиве PyPI. Словари Python иногда используются как записи, в которых ключами явля- ются имена полей, а их значения могут иметь разные типы. Например, рассмотрим запись, описывающую книгу, в формате JSON или на Python: 498  Еще об аннотациях типов\n--- Страница 498 ---\n{\"isbn\": \"0134757599\", \"title\": \"Refactoring, 2e\", \"authors\": [\"Martin Fowler\", \"Kent Beck\"], \"pagecount\": 478} До версии Python 3.8 не существовало хорошего способа аннотировать такую запись, потому что типы отображений, которые мы видели в разделе «Обобщенные отображения» главы 8, налагают ограничение: все значения должны быть одного типа. Вот две робкие попытки аннотировать запись, похожую на показанный выше JSON-объект: Dict[str, Any] Значения могут быть любого типа. Dict[str, Union[str, int, List[str]]] Читается с трудом и не сохраняет связь между именами полей и соответ - ствующими им типами: предполагается, что title должно иметь тип str, а не int и не List[str]. Эта проблема решена в документе PEP 589 «TypedDict: Type Hints for Dictionaries with a Fixed Set of Keys» (https://peps.python.org/pep-0589/). В приме- ре 15.4 показан простой типизированный словарь TypedDict. Пример 15.4. books.py: определение BookDict from typing import TypedDict class BookDict(TypedDict): isbn: str title: str authors: list[str] pagecount: int На первый взгляд может показаться, что typing.TypedDict похож на построи- тель класса данных наподобие typing.NamedTuple (см. главу 5). Но синтаксическое сходство обманчиво. TypedDict предназначен совершенно для другой цели. Он лишь поддерживает средства проверки типов и полно- стью игнорируется во время выполнения. TypedDict предлагает две вещи: напоминающий класс синтаксис для аннотирования словаря типами значений каждого «поля»; конструктор, который говорит средству проверки типов, что оно должно ожидать словаря с указанными ключами и значениями. На этапе выполнения конструктор типизированного словаря, например BookDict, играет роль плацебо: делает то же самое, что вызов конструктора dict с теми же аргументами. Тот факт, что BookDict создает простой словарь dict, означает также, что: «поля» в определении псевдокласса не создают атрибутов экземпляра; нельзя написать инициализаторы со значениями по умолчанию для «полей»; определения методов не допускаются. TypedDict  499\n--- Страница 499 ---\nПример 15.5. Использование BookDict не совсем так, как задумано >>> from books import BookDict >>> pp = BookDict(title='Programming Pearls',  authors='Jon Bentley',  isbn='0201657880', pagecount=256) >>> pp  {'title': 'Programming Pearls', 'authors': 'Jon Bentley', 'isbn': '0201657880', 'pagecount': 256} >>> type(pp) <class 'dict'> >>> pp.title  Traceback (most recent call last): File \"<stdin>\", line 1, in <module> AttributeError: 'dict' object has no attribute 'title' >>> pp['title'] 'Programming Pearls' >>> BookDict.__annotations__  {'isbn': <class 'str'>, 'title': <class 'str'>, 'authors': typing.List[str], 'pagecount': <class 'int'>}  Мы можем вызывать BookDict как конструктор dict с именованными аргу - ментами или передав аргумент типа dict, в т. ч. и литерал.  Ой… Я забыл, что authors принимает список. Но постепенная типизация оз- начает, что во время выполнения никакой проверки типов не производится.  Результатом вызова BookDict является простой dict…  … поэтому мы не можем читать данные с помощью нотации object.field .  Аннотации типов находятся в BookDict.__annotations__ , а не в pp. Без средства проверки типов TypedDict не полезнее комментариев: он помо- гает читать код, но не более того. Напротив, построители классов из главы 5 полезны, даже если мы не пользуемся средствами проверки типов, потому что во время выполнения они генерируют или дополняют пользовательский класс, экземпляр которого мы можем создать. Они также предоставляют полезные методы и функции, перечисленные в табл. 5.1. В примере 15.6 строится допустимый BookDict и делается попытка применить к нему некоторые операции. Это показывает, как TypedDict помогает Mypy обна- руживать ошибки (см. пример 15.7). Пример 15.6. demo_books.py: допустимые и недопустимые операции над BookDict from books import BookDict from typing import TYPE_CHECKING def demo() -> None:  book = BookDict(  isbn='0134757599' , title='Refactoring, 2e' , authors=['Martin Fowler', 'Kent Beck'], pagecount=478 ) authors = book['authors']  if TYPE_CHECKING:  reveal_type(authors)500  Еще об аннотациях типов\n--- Страница 500 ---\nauthors = 'Bob'  book['weight'] = 4.2 del book['title'] if __name__ == '__main__': demo()  Не забывайте добавить тип возвращаемого значения, иначе Mypy проиг - норирует эту функцию.  Это допустимый BookDict: все ключи присутствуют, а значения имеют пра- вильный тип.  Mypy выведет тип authors из аннотации ключа 'authors' в BookDict.  Константа typing.TYPE_CHECKING равна True, только когда работает средство про- верки типов. На этапе выполнения она всегда равна False.  Условие в предыдущем предложении if препятствует вызову reveal_ type(authors) во время выполнения. reveal_type – не функция Python, а отла- дочное средство, предоставляемое Mypy. Именно поэтому она нигде не им- портируется. Ее вывод показан в примере 15.7.  Последние три строки функции demo некорректны. Они приводят к ошиб- кам, показанным в примере 15.7. Проверка типов в скрипте demo_books.py из примера 15.6 дает результат, по- казанный в примере 15.7. Пример 15.7. Результат применения средства проверки типов к demo_books.py /typeddict/ $ mypy demo_books.py demo_books.py:13: note: Revealed type is 'built-ins.list[builtins.str]'  demo_books.py:14: error: Incompatible types in assignment (expression has type \"str\", variable has type \"List[str]\")  demo_books.py:15: error: TypedDict \"BookDict\" has no key 'weight'  demo_books.py:16: error: Key 'title' of TypedDict \"BookDict\" cannot be deleted  Found 3 errors in 1 file (checked 1 source file)  Это замечание – результат reveal_type(authors) .  Тип переменной authors был выведен из типа выражения book['authors'] , которым оно инициализировано. Нельзя присвоить str переменной типа List[str]. Программы проверки типов обычно возражают против измене- ния типа переменной1.  Нельзя присвоить значение ключу, отсутствующему в определении BookDict.  Нельзя удалить ключ, присутствующий в определении BookDict. Теперь посмотрим, как BookDict используется в сигнатурах функций для про- верки типов при вызове функции. Пусть требуется сгенерировать XML-код по записям о книгах, например: 1 По состоянию на май 2020 года pytype это разрешает. Но в FAQ сказано, что в буду - щем будет запрещено. См. вопрос «Why didn’t pytype catch that I changed the type of an annotated variable?» (Почему pytype не заметила, что я изменил тип аннотированной переменной) в pytype FAQ (https://google.github.io/pytype/faq.html). TypedDict  501\n--- Страница 501 ---\n<BOOK> <ISBN>0134757599</ISBN> <TITLE>Refactoring, 2e</TITLE> <AUTHOR>Martin Fowler</AUTHOR> <AUTHOR>Kent Beck</AUTHOR> <PAGECOUNT>478</PAGECOUNT> </BOOK> Если бы мы разрабатывали код на языке MicroPython, предназначенном для исполнения крохотным микроконтроллером, то могли бы написать функцию вроде той, что показана в примере 15.81. Пример 15.8. books.py: функция to_xml AUTHOR_ELEMENT = '<AUTHOR>{}</AUTHOR>' def to_xml(book: BookDict) -> str:  elements: list[str] = []  for key, value in book.items(): if isinstance(value, list):  elements.extend( AUTHOR_ELEMENT.format(n) for n in value)  else: tag = key.upper() elements.append(f'<{tag}>{value}</{tag}>') xml = '\\n\\t'.join(elements) return f'<BOOK> \\n\\t{xml} \\n</BOOK>'  Весь смысл этого примера: использование BookDict в сигнатуре функции.  Часто бывает необходимо аннотировать коллекции, которые вначале пус- ты, иначе Mypy не сможет вывести тип элементов2.  Mypy понимает проверки с помощью isinstance и в этом блоке рассматрива- ет value как list.  Когда я использовал key == 'authors' в качестве условия if, проверяющего вход в этот блок, Mypy обнаружила ошибку в этой строке: «object» has no attribute «__iter__» , т. к. вывела, что value, возвращенное методом book.items() , имеет тип object, а этот тип не поддерживает метод __iter__, необходимый генера- торному выражению. Если проверка производится с помощью isinstance , то все работает, потому что Mypy знает, что в этом блоке value имеет тип list. В примере 15.9 показана функция, которая разбирает строку в формате JSON типа str и возвращает BookDict. Пример 15.9. books_any.py: функция from_json def from_json(data: str) -> BookDict: whatever = json.loads(data)  return whatever  1 Я предпочитаю использовать пакет lxml (https://lxml.de/) для генерирования и раз- бора XML: с ним легко начать работу, он достаточно функциональный и быстрый. К сожалению, lxml и собственное дерево элементов Python ElementTree ( https:// docs.python.org/3/library/xml.etree.elementtree.html) не помещаются в ограниченную память моего гипотетического микроконтроллера. 2 В документации по Mypy этот вопрос обсуждается на странице «Типичные проблемы и решения» в разделе «Типы пустых коллекций».502  Еще об аннотациях типов\n--- Страница 502 ---\n Значение, возвращаемое json.loads() , имеет тип Any1.  Я могу вернуть whatever – типа Any, – потому что Any совместим с любым типом, в т. ч. указанным в объявлении возвращаемого значения типом BookDict. Второй момент примера 15.9 тоже очень важно иметь в виду: Mypy не сообща- ет об ошибке в этом коде, но во время выполнения значение переменной whatever может быть не согласовано со структурой BookDict, да и вообще быть не словарем! Если запустить Mypy с флагом --disallow-any-expr , то она будет ругаться на две строки в теле from_json: …/typeddict/ $ mypy books_any.py --disallow-any-expr books_any.py:30: error: Expression has type \"Any\" books_any.py:31: error: Expression has type \"Any\" Found 2 errors in 1 file (checked 1 source file) Упомянутые в этом фрагменте строки 30 и 31 – тело функции from_json. Мы можем подавить ошибку типизации, добавив аннотацию типа в инициа- лизацию переменной whatever, как показано в примере 15.10. Пример 15.10. books.py: функция from_json с аннотацией переменной def from_json(data: str) -> BookDict: whatever: BookDict = json.loads(data)  return whatever   Наличие флага --disallow-any-expr не вызывает ошибок, когда выражение типа Any присваивается переменной с аннотацией типа.  Теперь whatever имеет тип BookDict – тот, что объявлен для возвращаемого значения. Пусть вас не убаюкивает ложное чувство типобезопасности в примере 15.10! Глядя на код в состоянии покоя, средство про- верки типов не может предсказать, что json.loads() вернет что- то, напоминающее BookDict. Это может гарантировать только проверка во время выполнения. Статическая проверка типов не может предотвратить ошибки в принци- пиально динамическом коде, таком как json.loads() , который создает объекты Python разных типов во время выполнения, как в примерах 15.11, 15.12 и 15.13. Пример 15.11. demo_not_book.py: from_json возвращает недопустимый BookDict и to_xml принимает его from books import to_xml, from_json from typing import TYPE_CHECKING def demo() -> None: NOT_BOOK_JSON = \"\"\" {\"title\": \"Andromeda Strain\", \"flavor\": \"pistachio\", \"authors\": true} \"\"\" 1 Брэтт Кэннон, Гвидо ван Россум и другие обсуждали, как аннотировать json. loads(), начиная с 2016 года в проблеме Mypy #182 «Define a JSON type» (https:// github.com/python/typing/issues/182). TypedDict  503\n--- Страница 503 ---\nnot_book = from_json(NOT_BOOK_JSON)  if TYPE_CHECKING:  reveal_type(not_book) reveal_type(not_book['authors']) print(not_book)  print(not_book['flavor'])  xml = to_xml(not_book)  print(xml)  if __name__ == '__main__': demo()  Эта строка не порождает допустимого BookDict – см. состав NOT_BOOK_JSON .  Попросим Mypy показать два типа.  Здесь не должно быть проблем: print способна обработать любой объект и любой тип.  В BookDict нет ключа 'flavor', но в JSON-коде есть… и что же случится?  Вспомните сигнатуру: def to_xml(book: BookDict) -> str:  Как будет выглядеть выходной XML? Теперь проверим demo_not_book.py с помощью Mypy (пример 15.12). Пример 15.12. Отчет Mypy для demo_not_book.py, переформатированный для наглядности /typeddict/ $ mypy demo_not_book.py demo_not_book.py:12: note: Revealed type is 'TypedDict('books.BookDict', {'isbn': built-ins.str, 'title': built-ins.str, 'authors': built-ins.list[builtins.str], 'pagecount': built-ins.int})'  demo_not_book.py:13: note: Revealed type is 'built-ins.list[builtins.str]'  demo_not_book.py:16: error: TypedDict \"BookDict\" has no key 'flavor'  Found 1 error in 1 file (checked 1 source file)  Mypy показывает номинальный тип, а не состав not_book во время выполне- ния.  И снова это номинальный тип not_book['authors'] , определенный в BookDict. А не тип во время выполнения.  Эта ошибка относится к строке print(not_book['flavor']) : такого ключа в номи- нальном типе нет. Теперь выполним demo_not_book.py, результат показан в примере 15.13. Пример 15.13. Результат работы demo_not_book.py /typeddict/ $ python3 demo_not_book.py {'title': 'Andromeda Strain', 'flavor': 'pistachio', 'authors': True}  pistachio  <BOOK> <TITLE>Andromeda Strain</TITLE> <FLAVOR>pistachio</FLAVOR> <AUTHORS>True</AUTHORS> </BOOK>504  Еще об аннотациях типов\n--- Страница 504 ---\n Это не BookDict.  Значение not_book['flavor'] .  to_xml принимает аргумент типа BookDict, но никакой проверки во время вы- полнения нет: мусор на входе – мусор на выходе. Пример 15.13 показывает, что demo_not_book.py выводит чепуху, но не выда- ет ошибок во время выполнения. Использование TypedDict при обработке JSON- данных не сильно повысило типобезопасность. Если взглянуть на код to_xml в примере 15.8 сквозь призму утиной типиза- ции, то станет ясно, что аргумент book должен предоставлять метод .items(), ко- торый возвращает итерируемый объект кортежей вида (key, value) , где: key должен иметь метод .upper() ; value может быть любым. Что показала эта демонстрация? При обработке данных с динамической структурой, например в формате JSON или XML, TypedDict ни в коей мере не мо- жет служить заменой контроля данных во время выполнения. Для этой цели используйте пакет pydantic (https://pypi.org/project/pydantic/). У TypedDict есть еще много возможностей, в т. ч. поддержка факультативных ключей, ограниченная форма наследования и альтернативный синтаксис объ- явления. Если хотите узнать больше, поинтересуйтесь документом PEP 589 «TypedDict: Type Hints for Dictionaries with a Fixed Set of Keys» (https://peps. python.org/pep-0589/). Теперь обратимся к функции, которой лучше избегать, но иногда избежать не получается: typing.cast . приведение типОв Все системы типов несовершенны, включая средства статической проверки типов, аннотации типов в проекте typeshed и в сторонних пакетах, в которых они применяются. Специальная функция typing.cast() предлагает способ борьбы с ошибками средств проверки типов или некорректными аннотациями типов, которые мы не можем исправить. Документация по Mypy 0.930 (https://mypy.readthedocs.io/ en/stable/type_narrowing.html#casts) поясняет: Приведения используются, чтобы подавить спонтанные предупреждения средства проверки типов и немного помочь ему, когда оно не совсем по- нимает, что происходит. На этапе выполнения функция typing.cast не делает абсолютно ничего. Вот как выглядит ее реализация: def cast(typ, val): \"\"\"Привести значение к типу. Возвращает неизмененное значение. Для средства проверки типов это служит сигналом о том, что возвращаемое значение имеет указанный тип, но во время выполнения мы намеренно ничего не проверяем (хотим, чтобы программа работала максимально быстро). \"\"\" return val Приведение типов  505\n--- Страница 505 ---\nДокумент PEP 484 требует от программ проверки типов «слепой веры» в пра- вильность типа, указанного в cast. В разделе «Приведения типов» этого до- кумента (https://mypy.readthedocs.io/en/stable/type_narrowing.html#casts) приведен пример, когда средство проверки типов нуждается в помощи со стороны cast: from typing import cast def find_first_str(a: list[object]) -> str: index = next(i for i, x in enumerate(a) if isinstance(x, str)) # Мы попадаем сюда, только если есть хотя бы одна строка return cast(str, a[index]) Вызов функции next() для генераторного выражения либо возвращает ин- декс элемента типа str, либо возбуждает исключение StopIteration . Поэтому find_ first_str всегда возвращает строку, если не было исключения и если в качестве типа возвращаемого значения объявлен str. Но если бы в последней строке мы просто написали return a[index] , то Mypy вывела бы в качестве возвращаемого типа object, потому что аргумент a объяв- лен как list[object] . Поэтому руководство со стороны cast() необходимо1. Приведем еще один пример использования cast, на этот раз чтобы испра- вить устаревшую аннотацию типа в стандартной библиотеке Python. В при- мере 21.12 я создаю объект asyncio Server и хочу получить прослушиваемый сервером адрес. Я написал такую строку: addr = server.sockets[0].getsockname() Но Mypy отреагировала ошибкой: Value of type «Optional[List[socket]]» is not indexable Аннотация типов для Server.sockets в typeshed по состоянию на 2021 год корректна для Python 3.6, где атрибут sockets мог принимать значение None. Но в Python 3.7 sockets стало свойством с методом чтения, который всегда воз- вращает список – возможно, пустой, если сервер не открывал сокетов. А на- чиная с Python 3.8 метод чтения возвращает кортеж tuple (используемый как неизменяемая последовательность). Поскольку я не могу немедленно исправить typeshed2, я добавил cast: from asyncio.trsock import TransportSocket from typing import cast # много строк опущено socket_list = cast(tuple[TransportSocket, ], server.sockets) addr = socket_list[0].getsockname() 1 Я намеренно использовал enumerate в этом примере, чтобы сбить с толку программу проверки типов. Более простая реализация, которая отдает строки непосредственно, а не пропускает через enumerate , была бы правильно проанализирована Mypy, и cast() не понадобилась бы. 2 Я зарегистрировал проблему typeshed #5535 «Wrong type hint for asyncio.base_events. Server sockets attribute», и ошибку быстро исправил Себастьян Риттау. Однако я ре- шил оставить этот пример, поскольку он иллюстрирует типичную ситуацию, когда cast необходима, а мое обращение к cast безвредно.506  Еще об аннотациях типов\n--- Страница 506 ---\nПрежде чем использовать cast в этом случае, понадобилось потратить пару часов, чтобы понять проблему и заглянуть в исходный код asyncio, дабы найти правильный тип сокетов: класс TransportSocket из недокументированного модуля asyncio.trsock . Мне также пришлось добавить два предложения import и одну стро- ку кода для удобства чтения1. Но код стал безопаснее. Внимательный читатель, возможно, заметил, что вычисление sockets[0] мо- жет возбудить исключение IndexError , если список sockets пуст. Однако, насколь- ко я понимаю asyncio, в примере 21.12 такого случиться не может, потом что server готов принимать запросы на подключение к тому моменту, как я про- читал атрибут sockets, поэтому пустым список не будет. Как бы то ни было, IndexError – ошибка времени выполнения, поэтому Mypy не может обнаружить ее даже в тривиальном случае, таком как print([][0]) . Не стоит чувствовать себя комфортно, заткнув Mypy рот с по- мощью cast, потому что Mypy обычно права, когда сообщает об ошибке. Слишком частое использование cast дурно пахнет. Быть может, ваша команда неправильно пользуется аннотация- ми типов или в вашей кодовой базе имеются зависимости низ- кого качества. Несмотря на все недостатки, существуют ситуации, когда использование cast оправдано. Вот что писал об этом Гвидо ван Россум: Что дурного, если вы невзначай вызовете cast() или напишете коммента- рий # type: ignore2? Немудро полностью отказываться от cast, особенно когда другие обходные пути еще хуже: # type: ignore менее информативно3; использование Any заразно: поскольку Any совместим со всеми типами, злоупотребление им может вызвать каскадный эффект вследствие вы- вода типов, что сводит на нет попытки программы проверки типов об- наружить ошибки в других частях кода. Конечно, не все проблемы типизации можно исправить с помощью cast. Иногда необходим комментарий # type: ignore , иногда тип Any, а иногда даже лучше оставить функцию без аннотаций типов. Далее мы поговорим об использовании аннотаций на этапе выполнения. 1 Честно говоря, я сначала добавил комментарий # type: ignore в строку с server. sockets[0] , потому что после недолгих изысканий нашел похожие строки в докумен- тации по asyncio и в тесте, поэтому заподозрил, что проблема не в моем коде. 2 Сообщение от 19 мая 2020 года (https://mail.python.org/archives/list/typing-sig@python.org/ message/5LCWMN2UY2UQNLC5Z47GHBZKSPZW4I63/) в списке рассылки typing-sig. 3 Синтаксическая конструкция # type: ignore[code] позволяет указать, какой код ошиб- ки Mypy следует подавить, но коды не всегда легко интерпретировать. См. раздел «Коды ошибок» (https://mypy.readthedocs.io/en/stable/error_codes.html#error-codes) в доку - ментации по Mypy. Приведение типов  507\n--- Страница 507 ---\nчтение аннО таций типОв вО время выпО лнения На этапе импорта Python читает аннотации типов в функциях, классах и моду - лях и сохраняет их в атрибутах __annotations__ . Рассмотрим функцию clip в при- мере 15.141. Пример 15.14. clipannot.py: аннотированная сигнатура функции clip def clip(text: str, max_len: int = 80) -> str: Аннотации типов хранятся в атрибуте функции __annotations__ , представляю- щем собой словарь: >>> from clip_annot import clip >>> clip.__annotations__ {'text': <class 'str'>, 'max_len': <class 'int'>, 'return': <class 'str'>} Ключу 'return' соответствует аннотация возвращаемого типа после символа ->. Заметим, что аннотации обрабатываются интерпретатором на этапе им- порта, тогда же, когда значения по умолчанию. Именно поэтому значениями в аннотациях являются классы Python str и int, а не строки 'str' и 'int'. Вычис - ление аннотаций во время импорта является стандартом в версии Python 3.10, но это положение дел может измениться, если стандартным станет поведение, описанное в документах PEP 563 (https://peps.python.org/pep-0563/) или PEP 649 (https://peps.python.org/pep-0649/). Проблемы с аннотациями во время выполнения Расширяющееся использование аннотаций типов подняло две проблемы: импорт модулей занимает больше времени и потребляет больше памяти, если используется много аннотаций; ссылка на еще не определенные типы требует использования строк, а не фактических типов. Обе проблемы релевантны. Первая – потому что мы только что видели: аннотации вычисляются интерпретатором на этапе импорта и сохраняются в атрибуте __annotations__ . Сосредоточимся на второй. Хранение аннотаций в виде строк иногда необходимо из-за проблемы «опе- режающей ссылки»: когда аннотация типа должна сослаться на класс, опреде- ленный в том же модуле ниже. Однако типичное проявление этой проблемы в исходном коде вовсе не наводит на мысль об опережающей ссылке: прос- то метод возвращает новый объект того же класса. Поскольку объект класса не определен, пока Python не закончит вычисление тела класса, в аннотациях типов необходимо указывать имя класса в виде строки. Приведем пример: class Rectangle: # строки опущены def stretch(self, factor: float) -> 'Rectangle': return Rectangle(width=self.width * factor) 1 Я не стану углубляться в реализацию clip, но если вам интересно, можете прочитать код всего модуля в файле clip_annot.py ( https://github.com/fluentpython/example-code-2e/ blob/master/15-more-types/clip_annot.py).508  Еще об аннотациях типов\n--- Страница 508 ---\nЗапись еще не определенных типов в виде строки в аннотациях типов – стан- дартная и обязательная практика в версии Python 3.10. Средства статической проверки типов с самого начала проектировались с учетом этой проблемы. Но если вы напишете код, который во время выполнения читает аннотацию return для функции stretch, то получите строку 'Rectangle' , а не ссылку на фак- тический тип, класс Rectangle. Теперь ваша программа должна понять, что эта строка означает. В модуле typing есть три функции и класс, отнесенные к категории помощ- ников интроспекции (https://docs.python.org/3/library/typing.html#introspection- helpers). Самая важная из них typing.get_type_hints . В документации читаем: get_type_hints(obj, globals=None, locals=None, include_extras=False) […] Часто это то же самое, что obj.__annotations__ . Кроме того, опережающие ссылки, представленные строковыми литералами, обрабатываются путем вычисления их в пространствах имен globals и locals. […] Начиная с Python 3.10 следует использовать новую функцию inspect.get_annotations( ) , а не typing.get_type_hints . Однако у некоторых читателей Python 3.10, возможно, еще не установ- лена, поэтому в примерах ниже я пользуюсь typing. get_ type_ hints, которая доступна с момента появления модуля typing в Python 3.5. Одобренный документ PEP 563 «Postponed Evaluation of Annotations» (https:// peps.python.org/pep-0563/) сделал необязательной запись аннотаций в виде строк и уменьшил время, необходимое для обработки аннотаций типов во время вы- полнения. Его основная идея описана в следующих двух предложениях в раз- деле «Реферат»: В этом PEP предлагается изменить аннотации функций и переменных, так чтобы они больше не вычислялись в момент определения функции. Вместо этого они сохраняются в аннотациях в строковой форме. Начиная с версии Python 3.7 именно так обрабатываются аннотации в лю- бом модуле, который начинается следующим предложением import: from __future__ import annotations Для демонстрации последствий я поместил копию функции clip из приме- ра 15.14 в модуль clip_annot_post.py, в начале которого находится этот импорт из __future__ . Вот что было напечатано на консоли, когда я импортировал этот модуль и прочитал аннотации из clip: >>> from clip_annot_post import clip >>> clip.__annotations__ {'text': 'str', 'max_len': 'int', 'return': 'str'} Как видите, теперь все аннотации типов стали простыми строками, хотя в определении clip и не были записаны как строки в кавычках (пример 15.14). Функция typing.get_type_hints умеет разрешать многие аннотации типов, включая и те, что есть в clip: Чтение аннотаций типов во время выполнения  509\n--- Страница 509 ---\n>>> from clip_annot_post import clip >>> from typing import get_type_hints >>> get_type_hints(clip) {'text': <class 'str'>, 'max_len': <class 'int'>, 'return': <class 'str'>} Вызов get_type_hints дает нам реальные типы – даже в тех случаях, когда в ис- ходной аннотации тип был записан в виде закавыченной строки. Это рекомен- дуемый способ читать аннотации типов во время выполнения. Поведение, описанное в документе PEP 563, предполагалось сделать подразуме ваемым по умолчанию в версии Python 3.10 и тем самым избавить- ся от необходимости импортировать __future__ . Но ответственные за сопрово- ждение FastAPI и pydantic подняли тревогу, заявив, что это изменение полома- ет их код, который зависит от чтения аннотаций типов во время выполнения и не может надежно использовать функцию get_type_hints . В последующем обсуждении в списке рассылки python-dev Лукаш Ланга, ав- тор PEP 563, описал некоторые ограничения этой функции: […] оказалось, что у функции typing.get_type_hints() есть ограничения, из-за которых ее использование во время выполнения вообще обходится доро- го, но, что важнее, ее недостаточно для разрешения всех типов. Самый ти- пичный пример имеет отношение к неглобальному контексту, в котором генерируются типы (например, внутренние классы, классы внутри функ - ций и т. д.). Но один из коронных примеров опережающих ссылок – классы с методами, которые принимают или возвращают объекты их собственно- го типа, также некорректно обрабатываются функцией typing.get_type_hints() , если используется генератор классов. Можно пойти на кое-какие трюки, чтобы связать всё воедино, но в общем случае это не есть хорошо1. Руководящий комитет Python решил отложить внедрение документа PEP 563 до версии Python 3.11 или более поздней, чтобы дать разработчикам боль- ше времени на поиск решения тех проблем, которые пытался решить PEP 563, не ставя под угрозу широко распространенное применение аннотаций типов во время выполнения. Документ PEP 649 «Deferred Evaluation Of Annotations Using Descriptors» (https://peps.python.org/pep-0649/) обсуждается как возможное решение, но, возможно, будет достигнут другой компромисс. Итак: чтение аннотаций типов не стопроцентно надежно в версии Python 3.10, и это положение вряд ли изменится в 2022 году. Компании, в которых Python используется для разработки круп- номасштабных проектов, нуждаются в преимуществах статиче- ской типизации, но не хотят платить высокую цену за вычисле- ние аннотаций типов на этапе импорта. Статическая проверка производится на машинах разработчиков и на выделенных сер- верах непрерывной интеграции, но загрузка модулей выполня- ется куда чаще в производственных контейнерах, и пренебречь затратами на нее в крупном проекте никак нельзя. В сообществе Python это является причиной трений между теми, кто желает хранить аннотации типов только в виде строк – чтобы уменьшить накладные расходы на этапе загрузки, – и теми, кто 1 Сообщение «PEP 563 in light of PEP 649» (https://mail.python.org/archives/list/python-dev@ python.org/message/ZBJ7MD6CSGM6LZAOTET7GXAVBZB7O77O/), отправлено 16 апреля 2021. 510  Еще об аннотациях типов\n--- Страница 510 ---\nхочет использовать их также во время выполнения, к каковым, в частности, относятся авторы и пользователи пакетов pydantic и FastAPI, которые предпочли бы иметь под рукой готовые объ- екты типов, а не вычислять аннотации, что довольно накладно. Как решать проблему Учитывая нестабильность ситуации, сложившейся на настоящий момент, я могу дать следующие рекомендации тем, кому нужно читать аннотации во время выполнения. Избегайте чтения __annotations__ напрямую; вместо этого пользуйтесь функциями inspect.get_annotations (начиная с Python 3.10) или typing.get_ type_hints (начиная с Python 3.5). Напишите свою функцию, которая будет служить тонкой оберткой во- круг inspect.get_annotations или typing.get_type_hints , а в остальной части своей кодовой базы вызывайте эту функцию, тогда будущие изменения будут локализованы только в ней. Для демонстрации второго подхода ниже приведены начальные строки класса Checked, определенного в примере 24.5, который мы подробно изучим в главе 24: class Checked: @classmethod def _fields(cls) -> dict[str, type]: return get_type_hints(cls) # еще строки Метод класса Checked._fields экранирует другие части модуля от прямой зави- симости от typing.get_type_hints . Если в будущем get_type_hints изменится, так что понадобится дополнительная логика, или мы захотим заменить ее функцией inspect.get_annotations , то изменение будет ограничено методом Checked._fields и не повлияет на остальную программу. С учетом продолжающихся дискуссий и предлагаемых изменений в порядке инспекции аннотаций типов во время выполнения офи- циальный документ «Annotations Best Practices» (https://docs.python. org/3.10/howto/annotations.html) следует прочитать обязательно, и очень может статься, что по пути к Python 3.11 он будет обновлен. Эта инструкция написана Ларри Хастингсом, автором докумен- та PEP 649 «Deferred Evaluation Of Annotations Using Descriptors» (https://peps.python.org/pep-0649/), альтернативного предложения для решения проблем, поднятых в документе PEP 563 «Postponed Evaluation of Annotations» (https://peps.python.org/pep-0563/). Далее в этой главе мы рассмотрим обобщенные типы и начнем с того, как определить обобщенный класс, допускающий параметризацию пользователями. реализация ОБОБщеннОг О клаССа В примере 13.7 мы определили ABC Tombola: интерфейс для классов, работаю- щих как лотерейный барабан. Класс LottoBlower из примера 13.10 является кон- Реализация обобщенного класса  511\n--- Страница 511 ---\nкретной реализацией. Теперь мы рассмотрим обобщенную версию LottoBlower , использование которой показано в примере 15.15. Пример 15.15. generic_lotto_demo.py: использование обобщенного класса для розыгрыша лотереи from generic_lotto import LottoBlower machine = LottoBlower[int](range(1, 11))  first = machine.pick()  remain = machine.inspect()   Для создания экземпляра обобщенного класса мы передаем ему фактиче- ский параметр-тип, в данном случае int.  Mypy правильно выводит, что first имеет тип int…  … и что remain – кортеж tuple целых чисел. Дополнительно Mypy сообщает о нарушениях при использовании парамет- ризованного типа, выводя полезные сообщения, показанные в примере 15.16. Пример 15.16. generic_lotto_errors.py: сообщения об ошибках, выданные Mypy from generic_lotto import LottoBlower machine = LottoBlower[int]([1, .2]) ## error: List item 1 has incompatible type \"float\";  ## expected \"int\" machine = LottoBlower[int](range(1, 11)) machine.load('ABC') ## error: Argument 1 to \"load\" of \"LottoBlower\"  ## has incompatible type \"str\"; ## expected \"Iterable[int]\" ## note: Following member(s) of \"str\" have conflicts: ## note: Expected: ## note: def __iter__(self) -> Iterator[int] ## note: Got: ## note: def __iter__(self) -> Iterator[str]  После создания LottoBlower[int] Mypy помечает использование float как ошибку.  При вызове .load('ABC') Mypy объясняет, почему str не годится: str.__iter__ возвращает Iterator[str] , но LottoBlower[int] требует Iterator[int] . В примере 15.17 приведена реализация. Пример 15.17. generic_lotto.py: обобщенный класс для розыгрыша лотереи import random from collections.abc import Iterable from typing import TypeVar, Generic from tombola import Tombola T = TypeVar('T')512  Еще об аннотациях типов\n--- Страница 512 ---\nclass LottoBlower(Tombola, Generic[T]):  def __init__(self, items: Iterable[T]) -> None:  self._balls = list[T](items) def load(self, items: Iterable[T]) -> None:  self._balls.extend(items) def pick(self) -> T:  try: position = random.randrange(len(self._balls)) except ValueError: raise LookupError('pick from empty LottoBlower') return self._balls.pop(position) def loaded(self) -> bool:  return bool(self._balls) def inspect(self) -> tuple[T, ]:  return tuple(self._balls)  В объявлениях обобщенных классов часто используется множественное наследование, поскольку мы должны унаследовать Generic, чтобы объявить формальные параметры-типы – в данном случае T.  Аргумент items метода __init__ имеет тип Iterable[T] , который превращается в Iterable[int] , когда экземпляр объявляется как LottoBlower[int] .  Метод load имеет аналогичные ограничения.  Типом возвращаемого значения T в LottoBlower[int] становится int.  Здесь никакой переменной-типа нет.  Наконец, T определяет тип элементов в возвращенном кортеже. В коротком разделе «Пользовательские обобщенные типы» (https://docs.python.org/3/library/typing.html#user-defined-generic-types) документации по модулю typing приведены хорошие примеры и представлены дополнительные детали, которых я здесь не рас- сматриваю. Итак, мы посмотрели, как реализуется обобщенный класс, а теперь опреде- лим терминологию, употребляемую при обсуждении обобщенных типов. Основы терминологии, относящейся к обобщенным типам Ниже приведено несколько определений, которые, на мой взгляд, полезны при изучении обобщенных типов1. Обобщенный тип Тип, в объявлении которого присутствует одна или несколько перемен- ных-типов. Примеры: LottoBlower[T] , abc.Mapping[KT, VT] . 1 Термины взяты из классической книги Joshua Bloch «Effective Java», 3-е издание (Addison-Wesley). Определения и примеры мои. Реализация обобщенного класса  513\n--- Страница 513 ---\nФормальный параметр-тип Переменные-типы, встречающиеся в объявлении обобщенного типа. Пример: KT и VT в предыдущем примере abc.Mapping[KT,VT] . Параметризованный тип Тип, объявленный с фактическими параметрами-типами. Примеры: LottoBlower[int] , abc.Mapping[str, float] . Фактический параметр-тип Фактические типы, заданные в качестве параметров в объявлении парамет- ризованного типа. Пример: int в объявлении LottoBlower[int] . В следующем разделе мы обсудим, как сделать обобщенные типы более гибки- ми, и введем понятия ковариантности, контравариантности и инвариантности. вариантнОС ть В зависимости от вашего опыта работы с обобщенными типами в других языках этот раздел может оказаться самым трудным во всей книге. Концепция вариантности абстрактна, и попытка из- ложить ее строго сделала бы эту книгу похожей на учебник ма- тематики. На практике вариантность больше интересна авторам библио- тек, которые хотят поддержать новые обобщенные контейнер- ные типы или предоставить API на основе обратных вызовов. Но даже тогда излишней сложности можно избежать, огра- ничившись только поддержкой инвариантных контейнеров, а именно таково большинство контейнеров в стандартной биб- лиотеке Python. Так что при первом чтении можете пропустить этот раздел целиком или прочитать только те его части, которые относятся к инвариантным типам. Впервые с понятием вариантности мы столкнулись в разделе «Вариант - ность в типах Callable» главы 8 применительно к параметризованным обоб- щенным типам Callable. Здесь же мы распространим эту концепцию на обоб- щенные типы коллекций, пользуясь аналогией с «реальным миром», чтобы наполнить абстрактную концепцию конкретикой. Допустим, что в школьной столовой действует правило: разрешено устанав- ливать только автоматы для розлива соков1. Разливать любые напитки не разре- шается, чтобы не поить детей газировкой, которая запрещена советом школы2. Инвариантный разливочный автомат Попробуем смоделировать описанную ситуацию с помощью обобщенного класса BeverageDispenser , который можно параметризовать типом напитка. 1 Впервые я встретил аналогию со столовой при обсуждении вариантности в предисловии Эрика Мейера к книге Gilad Bracha «The Dart Programming Language» (Addison-Wesley). 2 Гораздо лучше, чем запрещать книги! 514  Еще об аннотациях типов\n--- Страница 514 ---\nПример 15.18. invariant.py: определения типов и функция install from typing import TypeVar, Generic class Beverage:  \"\"\"Любой напиток.\"\"\" class Juice(Beverage): \"\"\"Любой фруктовый сок.\"\"\" class OrangeJuice(Juice): \"\"\"Восхитительный сок бразильских апельсинов.\"\"\" T = TypeVar('T')  class BeverageDispenser(Generic[T]):  \"\"\"Автомат, параметризованный типом напитка.\"\"\" def __init__(self, beverage: T) -> None: self.beverage = beverage def dispense(self) -> T: return self.beverage def install(dispenser: BeverageDispenser[Juice]) -> None:  \"\"\"Установить автомат для розлива фруктовых соков.\"\"\"  Beverage, Juice и OrangeJuice из иерархии типов.  Простое объявление TypeVar.  BeverageDispenser параметризован типом напитка.  Функция install глобальна на уровне модуля. В ее аннотации типа указано, что допустим только автомат для розлива соков. При определениях в примере 15.18 следующий код допустим: juice_dispenser = BeverageDispenser(Juice()) install(juice_dispenser) Но показанный ниже код недопустим: beverage_dispenser = BeverageDispenser(Beverage()) install(beverage_dispenser) ## mypy: Argument 1 to \"install\" has ## incompatible type \"BeverageDispenser[Beverage]\" ## expected \"BeverageDispenser[Juice]\" Автомат, разливающий любой напиток Beverage, недопустим, потому что со- гласно правилам столовой разрешены только автоматы для розлива соков Juice. Удивительно, но этот код тоже недопустим: orange_juice_dispenser = BeverageDispenser(OrangeJuice()) install(orange_juice_dispenser) ## mypy: Argument 1 to \"install\" has ## incompatible type \"BeverageDispenser[OrangeJuice]\" ## expected \"BeverageDispenser[Juice]\" Автомат, специализированный для розлива апельсинового сока OrangeJuice , тоже недопустим. Подходит только BeverageDispenser[Juice] . Говорят, что тип Вариантность  515\n--- Страница 515 ---\nBeverageDispenser(Generic[T]) , если BeverageDispenser[OrangeJuice] не совместим с BeverageDispenser[Juice] , несмотря на то что OrangeJuice является подтипом Juice. Типы изменяемых коллекций в Python, например list и set, инвариантны. Класс LottoBlower из примера 15.17 тоже инвариантен. Ковариантный разливочный автомат Если мы хотим большей гибкости, т. е. нужно моделировать разливочные авто- маты как обобщенный класс, который принимает тип напитка и его подтипы, то нужно сделать этот класс ковариантным. В примере 15.19 показано, как сле- дует объявить BeverageDispenser . Пример 15.19. covariant.py: определения типов и функция install T_co = TypeVar('T_co', covariant=True)  class BeverageDispenser(Generic[T_co]):  def __init__(self, beverage: T_co) -> None: self.beverage = beverage def dispense(self) -> T_co: return self.beverage def install(dispenser: BeverageDispenser[Juice]) -> None:  \"\"\"Установить автомат для розлива фруктовых соков.\"\"\"  Установить covariant=True при объявлении переменной-типа; по соглаше- нию суффикс _co в typeshed обозначает ковариантные параметры-типы.  Использовать T_co для параметризации специального класса Generic.  Аннотации типов для install такие же, как в примере 15.18. Следующий код работает, потому что теперь ковариантный тип BeverageDispenser принимает как тип Juice, так и тип OrangeJuice : juice_dispenser = BeverageDispenser(Juice()) install(juice_dispenser) orange_juice_dispenser = BeverageDispenser(OrangeJuice()) install(orange_juice_dispenser) Но автомат для розлива произвольных напитков Beverage не принимается: beverage_dispenser = BeverageDispenser(Beverage()) install(beverage_dispenser) ## mypy: Argument 1 to \"install\" has ## incompatible type \"BeverageDispenser[Beverage]\" ## expected \"BeverageDispenser[Juice]\" Это была ковариантность: связь тип–подтип между параметризованными автоматами изменяется в том же направлении, что и связь тип–подтип между параметрами-типами. Контравариантная урна Теперь смоделируем правило по установке урн для мусора. Предположим, что еда и напитки поставляются в биоразлагаемых упаковках и пищевые отходы 516  Еще об аннотациях типов\n--- Страница 516 ---\nи одноразовые столовые приборы тоже биоразлагаемые. Урны должны быть пригодны для биоразлагаемых отходов. В педагогических целях сделаем упрощающее предположение о том, что мусор можно организовать в виде простой иерархии: Refuse – самый общий тип отходов; Biodegradable – специальный тип отходов, который со временем разлагается микроорганизмами. Некоторые виды отходов не яв- ляются биоразлагаемыми; Compostable – специальный тип биоразлагаемых отходов, который можно эффективно превратить в органическое удобрение в ком- постном баке или в установке компостирования. Не всякие био- разлагаемые отходы являются компостируемыми в смысле наше- го определения. Чтобы смоделировать правило установки урн в столовой, нам придется ввес ти концепцию контравариантности. Мы сделаем это на примере. Пример 15.20. contravariant.py: определения типов и функция install from typing import TypeVar, Generic class Refuse:  \"\"\"Любые отходы.\"\"\" class Biodegradable(Refuse): \"\"\"Биоразлагаемые отходы.\"\"\" class Compostable(Biodegradable): \"\"\"Компостируемые отходы.\"\"\" T_contra = TypeVar('T_contra', contravariant=True)  class TrashCan(Generic[T_contra]):  def put(self, refuse: T_contra) -> None: \"\"\"Хранить отходы, пока не выгружены.\"\"\" def deploy(trash_can: TrashCan[Biodegradable]): \"\"\"Установить урну для биоразлагаемых отходов.\"\"\"  Иерархия типов для отходов: Refuse – самый общий тип, Compostable – самый специфичный.  T_contra – принятое по соглашению имя контравариантной переменной-типа.  TrashCan контравариантен относительно типа отходов. При таких определениях следующие типы урн допустимы: bio_can: TrashCan[Biodegradable] = TrashCan() deploy(bio_can) trash_can: TrashCan[Refuse] = TrashCan() deploy(trash_can) Более общий тип TrashCan[Refuse] допустим, потому что может содержать лю- бые типы отходов, в т. ч. Biodegradable . Но TrashCan[Compostable] не годится, потому что не может содержать Biodegradable : Вариантность  517\n--- Страница 517 ---\ncompost_can: TrashCan[Compostable] = TrashCan() deploy(compost_can) ## mypy: Argument 1 to \"deploy\" has incompatible type \"TrashCan[Compostable]\" ## expected \"TrashCan[Biodegradable]\" Подведем итоги. Обзор вариантности Вариантность – непростое свойство. В следующих подразделах мы повторим, что такое инвариантные, ковариантные и контравариантные типы, и предло- жим несколько эвристических правил, позволяющих рассуждать о них. Инвариантные типы Обобщенный тип L инвариантен, если между двумя параметризованными типами нет отношения тип–подтип, даже если такое отношение существует между фак- тическими параметрами. Иными словами, если L инвариантен, то L[A] не является ни подтипом, ни супертипом L[B]. Они несовместимы в обоих направлениях. Как уже отмечалось, изменяемые коллекции в Python по умолчанию инва- риантны. Хорошим примером может служить тип list: list[int] не совместим с list[float] , и наоборот. В общем случае, если формальный параметр-тип встречается в аннотациях типов аргументов метода и тот же параметр встречается в типе возвращаемо- го методом значения, то параметр должен быть инвариантен, чтобы гаранти- ровать типобезопасность при обновлении коллекции и чтении из нее. Например, ниже приведена часть аннотаций типов для встроенного типа list в typeshed: class list(MutableSequence[_T], Generic[_T]): @overload def __init__(self) -> None: @overload def __init__(self, iterable: Iterable[_T]) -> None: # строки опущены def append(self, __object: _T) -> None: def extend(self, __iterable: Iterable[_T]) -> None: def pop(self, __index: int = ) -> _T: # и т. д. Заметим, что _T встречается в аргументах __init__, append и extend, а также как тип значения, возвращаемого pop. Невозможно сделать такой класс типобезо- пасным, если он ковариантен или контравариантен относительно _T. Ковариантные типы Рассмотрим два типа A и B, где B совместим с A и ни один из них не совпадает с Any. Некоторые авторы используют символы <: и :>, чтобы обозначить следу - ющие отношения: A :> B A является супертипом или совпадает с B. B <: A B является супертипом или совпадает с A.518  Еще об аннотациях типов\n--- Страница 518 ---\nЕсли A :> B, тот обобщенный тип C ковариантен, когда C[A] :> C[B] . Обратите внимание, что направление символа :> одинаково в обоих случа- ях, когда A встречается слева от B. Ковариантные обобщенные типы повторяют отношение тип–подтип между фактическими параметрами-типами. Неизменяемые контейнеры могут быть ковариантными. Например, в до- кументации (https://docs.python.org/3.10/library/typing.html#typing.FrozenSet) напи- сано, что класс typing.FrozenSet ковариантен относительно переменной-типа, и для выражения этой мысли в соответствии с принятым соглашением исполь- зуется имя T_co: class FrozenSet(frozenset, AbstractSet[T_co]): Применяя нотацию :> к параметризованным типам, имеем: float :> int frozenset[float] :> frozenset[int] Итераторы дают еще один пример ковариантных обобщенных типов: они не являются коллекциями, допускающими только чтение, как frozenset, а лишь порождают выход. Любой код, ожидающий итератор abc.Iterator[float] , который отдает числа с плавающей точкой, может безопасно использовать итератор abc.Iterator[int] , отдающие целые. По той же причине типы Callable ковариант - ны относительно типа возвращаемого значения. Контравариантные типы Если A :> B, то обобщенный тип K контравариантен, если if K[A] <: K[B] . Контравариантные обобщенные типы обращают связь тип–подтип между фактическими параметрами-типами. Примером может служить класс TrashCan: Refuse :> Biodegradable TrashCan[Refuse] <: TrashCan[Biodegradable] Контравариантный контейнер обычно представляет собой структуру дан- ных, предназначенную только для записи и называемую «стоком». В стандарт - ной библиотеке нет таких коллекций, но есть несколько типов с контравари- антными параметрами-типами. Тип Callable[[ParamType, ], ReturnType] контравариантен относительно пара- метров-типов, но ковариантен относительно ReturnType , как мы видели в разде- ле «Вариантность в типах Callable» главы 8. Кроме того, типы Generator, Coroutine и AsyncGenerator имеют по одному контравариантному параметру-типу. Тип Generator описан в разделе «Обобщенные аннотации типов для классических сопрограмм» главы 17, а типы Coroutine и AsyncGenerator обсуждаются в главе 21. В этом обсуждении вариантности главное то, что контравариантные фор- мальные параметры определяют типы аргументов, используемых для вызова или отправки данных объекту, тогда как ковариантные формальные параметры определяют типы выходов, порождаемых объектом, – тип отдаваемого или воз- вращаемого значения, в зависимости от объекта. Семантика терминов «отпра- вить» и «отдать» объясняется в разделе «Классические сопрограммы» главы 17. Из этих наблюдений над ковариантными выходами и контравариантными входами можно вывести ряд полезных рекомендаций. Вариантность  519\n--- Страница 519 ---\nЭвристические правила вариантности Напоследок приведем несколько эвристических правил, полезных при рассуж - дениях о вариантности. Если формальный параметр-тип определяет тип данных, исходящих из объекта, то он может быть ковариантным. Если формальный параметр-тип определяет тип данных, входящих в объект после его начального конструирования, то он может быть конт- равариантным. Если формальный параметр-тип определяет тип данных, исходящих из объекта, и тот же параметр определяет тип данных, входящих в объект, то он должен быть инвариантным. Чтобы ненароком не допустить ошибку, делайте формальные парамет- ры инвариантными. Тип Callable[[ParamType, ], ReturnType] служит иллюстрацией правил 1 и 2: ReturnType ковариантный, а каждый ParamType контравариантный. По умолчанию TypeVar создает инвариантные формальные параметры, и именно так аннотированы изменяемые коллекции в стандартной библиоте- ке. В разделе «Обобщенные аннотации типов для классических сопрограмм» главы 17 мы продолжим обсуждение вариантности. А теперь посмотрим, как определить обобщенные статические протоколы, применив идею ковариантности к двум новым примерам. реализация ОБОБщеннОг О СтатичеСк ОгО прОтОкОла В стандартной библиотеке Python 3.10 есть несколько обобщенных статиче- ских протоколов. Один из них, SupportsAbs , реализован в модуле typing ( https:// github.com/python/cpython/blob/46b16d0bdbb1722daed10389e27226a2370f1635/Lib/ typing.py#L1786), как показано ниже. @runtime_checkable class SupportsAbs(Protocol[T_co]): \"\"\"ABC с одним абстрактным методом __abs__, ковариантным относительно типа возвращаемого значения.\"\"\" __slots__ = () @abstractmethod def __abs__(self) -> T_co: pass T_co объявлен в соответствии с соглашением об именовании: T_co = TypeVar('T_co', covariant=True) Благодаря SupportsAbs Mypy считает код в примере 15.21 допустимым. Пример 15.21. abs_demo.py: использование обобщенного протокола SupportsAbs import math from typing import NamedTuple, SupportsAbs class Vector2d(NamedTuple): x: float520  Еще об аннотациях типов\n--- Страница 520 ---\ny: float def __abs__(self) -> float:  return math.hypot(self.x, self.y) def is_unit(v: SupportsAbs[float]) -> bool:  \"\"\"'True', если абсолютная величина 'v' близка к 1.\"\"\" return math.isclose(abs(v), 1.0)  assert issubclass(Vector2d, SupportsAbs)  v0 = Vector2d(0, 1)  sqrt2 = math.sqrt(2) v1 = Vector2d(sqrt2 / 2, sqrt2 / 2) v2 = Vector2d(1, 1) v3 = complex(.5, math.sqrt(3) / 2) v4 = 1  assert is_unit(v0) assert is_unit(v1) assert not is_unit(v2) assert is_unit(v3) assert is_unit(v4) print('OK')  Определение __abs__ делает Vector2d совместимым с SupportsAbs .  Параметризация SupportsAbs типом float гарантирует, что …  …Mypy будет считать abs(v) допустимым первым аргументом math.isclose .  Благодаря декоратору @runtime_checkable в определении SupportsAbs это допус- тимое утверждение времени выполнения.  Весь остальной код проходит проверки Mypy и утверждения времени вы- полнения.  Тип int также совместим с SupportsAbs . Согласно typeshed int.__abs__ возвраща- ет int, который совместим с параметром-типом float, объявленным в анно- тации типа для аргумента v функции is_unit. Аналогично можно написать обобщенную версию протокола RandomPicker , представленного в примере 13.18, в котором был определен единственный метод pick, возвращающий Any. В примере 15.22 показано, как сделать обобщенный RandomPicker ковариант - ным относительно типа, возвращаемого pick. Пример 15.22. generic_randompick.py: определение обобщенного RandomPicker from typing import Protocol, runtime_checkable, TypeVar T_co = TypeVar('T_co', covariant=True)  @runtime_checkable class RandomPicker(Protocol[T_co]):  def pick(self) -> T_co:   Объявить T_co ковариантным. Реализация обобщенного статического протокола  521\n--- Страница 521 ---\n Это делает RandomPicker обобщенным типом с ковариантным формальным параметром-типом.  Использовать T_co в качестве типа возвращаемого значения. Обобщенный протокол RandomPicker может быть ковариантным, потому что его единственный формальный параметр встречается в типе возвращаемого значения. На этом мы можем с чистой совестью закончить главу. резюме Мы начали эту главу с простого примера использования декоратора @overload, после чего привели и подробно изучили гораздо более сложный пример: как правильно аннотировать встроенную функцию max с помощью перегруженных сигнатур. Далее мы перешли к специальной конструкции typing.TypedDict . Я решил рас- смотреть ее здесь, а не в главе 5, где шла речь о классе typing.NamedTuple , потому что TypedDict – не построитель класса, а просто способ добавить аннотации ти- пов к переменной или аргументу, которые нуждаются в словаре, содержащем конкретный набор строковых ключей и определенных типов для каждого клю- ча – так бывает, когда мы используем dict как запись, часто в контексте обра- ботки JSON-данных. Этот раздел получился довольно длинным, потому что ис- пользование TypedDict иногда вселяет ложное ощущение безопасности, а я хотел показать, что от проверок во время выполнения и обработки ошибок не уйти, если мы пытаемся построить статически структурированные записи из дина- мических по своей природе отображений. Затем мы поговорили о функции typing.cast , позволяющей руководить ра- ботой средства проверки типов. Важно хорошенько продумывать, когда стоит использовать cast, поскольку злоупотребление ей может свести на нет все пре- имущества программы проверки типов. Доступ к аннотациям типов во время выполнения стал следующей нашей темой. Здесь главный посыл заключался в том, что нужно использовать функ - цию typing.get_type_hints , а не читать атрибут __annotations__ напрямую. Однако для некоторых аннотаций эта функция может работать ненадежно, и мы виде- ли, что разработчики ядра Python все еще трудятся над тем, как сделать анно- тации типов доступными во время выполнения, уменьшив при этом потребле- ние процессора и памяти. Последние разделы были посвящены обобщенным типам. Мы начали с обоб- щенного класса LottoBlower , который, как мы впоследствии узнали, является ин- вариантным. За этим примером последовали определения четырех основных терминов: обобщенный тип, формальный параметр-тип, параметризованный тип и фактический параметр-тип. Далее был рассмотрен важный вопрос о вариантности на примере автома- тов для розлива напитков и мусорных урн, взятых из «реальной жизни» и де- монстрирующих инвариантные, ковариантные и контравариантные обобщен- ные типы. Затем мы формализовали и применили эти понятия к примерам из стандартной библиотеки Python.522  Еще об аннотациях типов\n--- Страница 522 ---\nНапоследок показали, как определяется обобщенный статический прото- кол, для чего сначала рассмотрели протокол typing.SupportsAbs , а затем примени- ли ту же идею к типу RandomPicker , сделав его более строгим, чем оригинальный протокол из главы 13. Система типов в Python – обширная тема, которая к тому же быст ро развивается. Эта глава не претендует на полноту. Я вы- брал те аспекты, которые либо нашли широкое применение, либо особенно трудны, либо концептуально важны и потому, ве- роятно, будут оставаться актуальными еще долго. дОпО лнительная литература Статическая система типов в Python была сложна уже на этапе начального про- ектирования и с каждым годом становилась только сложнее. В табл. 15.1 пере- числены все известные мне документы PEP по состоянию на май 2021 года. Понадобилась бы целая книга, чтобы рассмотреть каждый из них. Таблица 15.1. Документы PEP, посвященные аннотациям типов со ссылками. Звездочкой отмечены PEP, достаточно важные, чтобы заслужить упоминание во вступительном абзаце документации по модулю typing. Вопросительный знак в столбце Python означает, что PEP еще обсуждается или пока не реализован; – означает, что PEP информационный и не связан ни с какой конкретной версией Python PEP Название Python Год 3107 Function Annotations 3.0 2006 483* The Theory of Type Hints – 2014 484* Type Hints 3.5 2014 482 Literature Overview for Type Hints – 2015 526* Syntax for Variable Annotations 3.6 2016 544* Protocols: Structural subtyping (static duck typing) 3.8 2017 557 Data Classes 3.7 2017 560 Core support for typing module and generic types 3.7 2017 561 Distributing and Packaging Type Information 3.7 2017 563 Postponed Evaluation of Annotations 3.7 2017 586* Literal Types 3.8 2018 585 Type Hinting Generics In Standard Collections 3.9 2019 589* TypedDict: Type Hints for Dictionaries with a Fixed Set of Keys 3.8 2019 591* Adding a final qualifier to typing 3.8 2019 593 Flexible function and variable annotations ? 2019 604 Allow writing union types as X | Y 3.10 2019 612 Parameter Specification Variables 3.10 2019 613 Explicit Type Aliases 3.10 2020 Дополнительная литература  523\n--- Страница 523 ---\nPEP Название Python Год 645 Allow writing optional types as x? ? 2020 646 Variadic Generics ? 2020 647 User-Defined Type Guards 3.10 2021 649 Deferred Evaluation Of Annotations Using Descriptors ? 2021 655 Marking individual TypedDict items as required or potentially missing ? 2021 Официальная документация по Python за всем этим не поспевает, поэтому документация по Mypy может служить необходимым справочным руковод- ством. Книга Patrick Viafore «Robust Python» (https://www.oreilly.com/library/view/ robust-python/9781098100650/) (O’Reilly) стала первым известным мне подроб- ным изложением статической системы типов в Python; она вышла в августе 2021 года. Вторую книгу вы сейчас читаете. Сложной теме вариантности посвящен отдельный раздел в PEP 484 (https:// peps.python.org/pep-0484/#covariance-and-contravariance), она также рассмотрена на странице «Обобщенные типы» (https://mypy.readthedocs.io/en/stable/ generics. html#variance-of-generic-types) документации по Mypy и на неоценимой стра- нице «Типичные проблемы» (https://mypy.readthedocs.io/en/stable/ common_issues. html#variance) там же. Документ PEP 362 «Function Signature Object» (https://peps.python.org/pep- 0362/) стоит почитать, если вы намереваетесь пользоваться модулем inspect, который дополняет функцию typing.get_type_hints . Интересующимся историей Python, возможно, будет полезно знать о сооб- щении «Adding Optional Static Typing to Python» (https://www.artima.com/weblogs/ viewpost.jsp?thread=85551), которое Гвидо ван Россум опубликовал 23 декабря 2004 года. «Python 3 Types in the Wild: A Tale of Two Type Systems» (https://dl.acm.org/ action/cookieAbsent) – научная статья, написанная Ингкаратом Рак-амноукитом и другими авторами из Ренселаерского политехнического института и Иссле- довательского центра IBM TJ Watson. В этой работе дан обзор использования аннотаций типов в проектах с открытым исходным кодом и показано, что в большинстве проектов они не используются, а также что в большинстве про- ектов, где аннотации все-таки используются, не применяется никакое сред- ство проверки типов. Мне показалось очень интересным обсуждение различ- ной семантики Mypy и программы pytype от Google; по словам авторов, это «по существу две разные системы типов». Две основополагающие работы по постепенной типизации – Gilad Bracha «Pluggable Type Systems» (http://bracha.org/pluggable TypesPosition.pdf) и Eric Meijer and Peter Drayton «Static Typing Where Possible, Dynamic Typing When Needed: The End of the Cold War Between Programming Languages» (https://www. researchgate.net/publication/213886116_Static_Typing_Where_Possible_Dynamic_Typing_ When_Needed_The_End_of_the_Cold_War_Between_Programming_Languages)1. 1 Читающие сноски, наверное, вспомнят, что я уже упоминал Эрика Мейера, когда описывал аналогию со школьной столовой при обсуждении вариантности.Окончание табл. 15.1524  Еще об аннотациях типов\n--- Страница 524 ---\nЯ многому научился, читая относящиеся к теме части книг о других языках программирования, в которых реализованы те же идеи: Bruce Eckel, Svetlana Isakova «Atomic Kotlin» (https://www.atomickotlin.com/ atomickotlin/) (Mindview); Joshua Bloch «Effective Java», 3-е издание (Addison-Wesley); Vlad Riscutia «Programming with Types: TypeScript Examples» (https://www. manning.com/books/programming-with-types) (Manning); Boris Cherny «Programming TypeScript» (https://www.oreilly.com/library/view/ programming-typescript/9781492037644/) (O’Reilly); Gilad Bracha «The Dart Programming Language» (Addison-Wesley)1. Желающим познакомиться с критическим взглядом на системы типов ре- комендую статьи Виктора Юдайкена «Bad ideas in type theory» (https://www. yodaiken.com/2017/09/15/bad-ideas-in-type-theory/) и «Types considered harmful II» (https://www.yodaiken.com/2017/11/30/types-considered-harmful-ii/). Наконец, я с удивлением обнаружил статью «Generics Considered Harmful» (https://web.archive.org/web/20071010002142/http://weblogs.java.net/blog/arnold/ archive/2005/06/generics_consid_1.html) Кена Арнольда, одного из соразработчи- ков ядра Java с самого начала, а также соавтора первых четырех изданий офи- циального руководства «The Java Programming Language» (Addison-Wesley) – вместе с Джеймсом Гослингом, главным проектировщиком Java. Как это ни печально, критические замечания Арнольда относятся и к ста- тической системе типов в Python. Читая многочисленные правила и особые случаи в документах PEP, посвященных типизации, я постоянно вспоминал следующий пассаж из статьи Гослинга: Что приводит к проблеме, о которой я всегда говорю применительно к C++ и называю ее «исключение порядка N из исключения из правила». Звучит она так: «Мы можем сделать x, но только не в случае y, если y не делает z, в каковом случае это можно сделать, если …». По счастью, у Python есть важное преимущество по сравнению Java и C++: его система типов факультативна. Мы можем заткнуть рот программам про- верки типов и опустить аннотации типов, если они становятся слишком гро- моздкими. Поговорим Кроличьи норы типизации Используя программы проверки типов, мы иногда вынуждены открывать для себя и импортировать классы, о которых и знать-то не хотели и которые на- шему коду вовсе не нужны – разве что для написания аннотаций типов. Такие классы не документированы, возможно, потому что авторы пакетов считали их деталью реализации. Вот два примера из стандартной библиотеки. 1 Эта книга была написана о Dart 1. В Dart 2 внесены существенные изменения, в т. ч. в систему типов. Тем не менее Брача – авторитетный исследователь в области про- ектирования языков программирования, и мне эта книга понравилась за его взгляд на проектирование Dart. Дополнительная литература  525\n--- Страница 525 ---\nЧтобы воспользоваться функцией cast() в примере server.sockets из раздела «Приведение типов», я вынужден был прошерстить обширную документа- цию по asyncio, а затем просмотреть исходный код нескольких модулей и па- кета, чтобы обнаружить недокументированный класс TransportSocket , входя- щий в состав недокументированного же модуля asyncio.trsock . Использовать socket.socket вместо TransportSocket было бы неправильно, потому что второй не является подтипом первого, как следует из строки документации (https:// github.com/python/cpython/blob/3e7ee02327db13e4337374597cdc4458ecb9e3ad/Lib/ asyncio/trsock.py#L5) в исходном коде. Я провалился в кроличью нору, когда добавлял аннотации типов в приме- ре 19.13, простой демонстрации пакета multiprocessing . Там я использовал объ- екты типа SimpleQueue , которые возвращают вызов multiprocessing.SimpleQueue() . Однако я не мог использовать это имя в аннотации типа, потому что ока- залось, что multiprocessing.SimpleQueue – не класс вовсе! Это связанный метод недокументированного класса multiprocessing.BaseContext , который строит и возвращает экземпляр класса SimpleQueue в недокументированном модуле multiprocessing.queues . В обоих случаях я вынужден был потратить пару часов, чтобы понять, какой недокументированный класс импортировать, – и все только ради написания одной аннотации типа. Такие изыскания – часть работы автора книги. Но ког - да я пишу код приложения, я предпочел бы обойтись без такой «охоты за предметами» ради одной непокорной строки и просто написать # type: ignore . Иногда это единственное экономически оправданное решение. Нотация вариантности в других языках Вариантность – трудная тема, и аннотации типов в Python не так хороши, как могли бы быть. Это подтверждает прямая цитата из PEP 484: Ковариантность или контравариантность – свойство не переменной- типа, а обобщенного класса, определенного с использованием этой переменной1. Коли так, то почему же ковариантность и контравариантность объявляются с помощью TypeVar, а не в обобщенном классе? Авторы PEP 484 работали в условиях добровольно наложенного на себя огра- ничения: аннотации типов должны поддерживаться без внесения изменений в интерпретатор. Для этого потребовалось ввести тип TypeVar для определения переменных-типов, а также злоупотребить скобками [], чтобы предоставить синтаксис Klass[T] для обобщенных типов – вместо нотации Klass<T>, приме- няемой в других популярных языках, включая C#, Java, Kotlin и TypeScript. Ни в одном из этих языков не требуется объявлять переменные-типы до ис- пользования. Кроме того, синтаксис Kotlin и C# ясно дает понять, является ли параметр-тип ковариантным, контравариантным или инвариантным, и именно там, где это нужно: в объявлении класса или интерфейса. В Kotlin мы могли бы объявить класс BeverageDispenser следующим образом: 1 См. последний абзац раздела «Ковариантность и контравариантность» (https:// peps.python.org/pep-0484/#covariance-and-contravariance) в документе PEP 484.526  Еще об аннотациях типов\n--- Страница 526 ---\nclass BeverageDispenser<out T> { // и т. д. } Модификатор out в формальном параметре-типе означает, что T – «выход- ной» тип, а значит, BeverageDispenser ковариантен. Вы, наверное, догадались, как можно было бы объявить TrashCan: class TrashCan<in T> { // и т. д. } Поскольку T – «входной» формальный параметр, класс TrashCan контравари- антен. Если нет ни in, ни out, то класс инвариантен относительно параметра. «Эвристические правила вариантности» вспоминаются, когда в формальных параметрах-типах присутствуют модификаторы out или in. Это наводит на мысль, что в Python было бы уместно принять следующие соглашения об именовании ковариантных и контравариантных параметров- типов: T_out = TypeVar('T_out', covariant=True) T_in = TypeVar('T_in', contravariant=True) Тогда мы могли бы следующим образом определять классы: class BeverageDispenser(Generic[T_out]): class TrashCan(Generic[T_in]): Может быть, еще не поздно изменить соглашение об именовании, предло- женное в PEP 484? Дополнительная литература  527",
      "debug": {
        "start_page": 491,
        "end_page": 526
      }
    },
    {
      "name": "Глава 16. Перегрузка операторов 528",
      "content": "--- Страница 527 --- (продолжение)\nГлава 16 Перегрузка операторов Есть вещи, которые меня смущают, например перегрузка операторов. Я принял волевое решение исключить перегрузку операторов из языка, по- тому что видел много примеров злоупотребления этой возможностью в C++. – Джеймс Гослинг, создатель Java1 В Python сложные проценты можно вычислить по следующей формуле: interest = principal * ((1 + rate) ** periods - 1) Операторы, располагающиеся между операндами, как в выражении 1 + rate, называются инфиксными. В Python инфиксные операторы могут применяться к произвольным типам. Таким образом, при работе с вещественными денеж - ными величинами можно гарантировать, что principal, rate и periods будут точ- ными числами, сделав их экземплярами класса decimal.Decimal , и формула будет работать, как написано, и давать точный результат. Но в Java, если перейти от float к BigDecimal ради получения точных резуль- татов, инфиксными операторами уже нельзя будет воспользоваться, потому что они применимы только к примитивным типам. Та же формула для работы с числами типа BigDecimal в Java выглядит так: BigDecimal interest = principal.multiply(BigDecimal.ONE.add(rate) .pow(periods).subtract(BigDecimal.ONE)); Ясно, что благодаря инфиксным операторам читать формулы гораздо про- ще. Для поддержки нотации инфиксных операторов применительно к поль- зовательским типам или типам расширения, таким как массивы в NumPy, не- обходима перегрузка операторов. Наличие перегрузки операторов в удобном для работы языке высокого уровня, возможно, и было одной из основных при- чин поразительного успеха Python как языка обработки данных, в т. ч. для соз- дания финансовых и научных приложений. В разделе «Эмуляция числовых типов» главы 1 мы видели тривиальные реа- лизации операторов в наброске класса Vector. Методы __add__ и __mul__ в приме- ре 1.2 были написаны для того, чтобы показать, как специальные методы под- держивают перегрузку операторов, но в их реализации есть тонкие проблемы, на которые мы тогда не стали обращать внимания. Кроме того, в примере 11.2 1 Источник: «Семейство языков, производных от C: интервью с Деннисом Ритчи, Бьяр- ном Страуструпом и Джеймсом Гослингом» (http://www.gotw.ca/publications/c_family_ interview.htm).\nГлава 16 Перегрузка операторов Есть вещи, которые меня смущают, например перегрузка операторов. Я принял волевое решение исключить перегрузку операторов из языка, по- тому что видел много примеров злоупотребления этой возможностью в C++. – Джеймс Гослинг, создатель Java1 В Python сложные проценты можно вычислить по следующей формуле: interest = principal * ((1 + rate) ** periods - 1) Операторы, располагающиеся между операндами, как в выражении 1 + rate, называются инфиксными. В Python инфиксные операторы могут применяться к произвольным типам. Таким образом, при работе с вещественными денеж - ными величинами можно гарантировать, что principal, rate и periods будут точ- ными числами, сделав их экземплярами класса decimal.Decimal , и формула будет работать, как написано, и давать точный результат. Но в Java, если перейти от float к BigDecimal ради получения точных резуль- татов, инфиксными операторами уже нельзя будет воспользоваться, потому что они применимы только к примитивным типам. Та же формула для работы с числами типа BigDecimal в Java выглядит так: BigDecimal interest = principal.multiply(BigDecimal.ONE.add(rate) .pow(periods).subtract(BigDecimal.ONE)); Ясно, что благодаря инфиксным операторам читать формулы гораздо про- ще. Для поддержки нотации инфиксных операторов применительно к поль- зовательским типам или типам расширения, таким как массивы в NumPy, не- обходима перегрузка операторов. Наличие перегрузки операторов в удобном для работы языке высокого уровня, возможно, и было одной из основных при- чин поразительного успеха Python как языка обработки данных, в т. ч. для соз- дания финансовых и научных приложений. В разделе «Эмуляция числовых типов» главы 1 мы видели тривиальные реа- лизации операторов в наброске класса Vector. Методы __add__ и __mul__ в приме- ре 1.2 были написаны для того, чтобы показать, как специальные методы под- держивают перегрузку операторов, но в их реализации есть тонкие проблемы, на которые мы тогда не стали обращать внимания. Кроме того, в примере 11.2 1 Источник: «Семейство языков, производных от C: интервью с Деннисом Ритчи, Бьяр- ном Страуструпом и Джеймсом Гослингом» (http://www.gotw.ca/publications/c_family_ interview.htm).\n--- Страница 528 ---\nмы отметили, что в реализации метода Vector2d.__eq__ предполагается истин- ным равенство Vector(3, 4) == [3, 4] – иногда это имеет смысл, а иногда нет. Эти вопросы станут предметом настоящей главы. Мы рассмотрим следующие темы: как в Python поддерживаются инфиксные операторы с операндами раз- ных типов; использование утиной или гусиной типизации при работе с операндами разных типов; специальное поведение операторов сравнения (например, ==, >, <=); подразумеваемая по умолчанию обработка операторов составного при- сваивания, например +=, и их корректная перегрузка. чтО нОвОг О в этОй главе Гусиная типизация – ключевая часть Python, но ABC из пакета numbers не под- держиваются статической типизацией, поэтому я изменил пример 16.11, так что теперь в нем используется утиная типизация вместо явного сравнения с типом numbers.Real с помощью isinstance1. Я рассматривал оператор матричного умножения @ в первом издании как запланированное изменение, когда версия 3.5 еще находилась на уровне аль- фа. Теперь этот оператор описывается не во врезке, а в основном тексте главы в разделе «Использование @ в качестве инфиксного оператора». Я воспользо- вался гусиной типизацией, чтобы сделать реализацию метода __matmul__ более безопасной, чем в первом издании, не жертвуя гибкостью. В разделе «Дополнительная литература» появилась пара новых ссылок, в т. ч. на статью в блоге Гвидо ван Россума. Также я добавил упоминание о двух библиотеках, которые демонстрируют эффективное использование перегруз- ки операторов за пределами математики: pathlib и Scapy. ОСнОвы перегрузки Операт ОрОв Перегрузка операторов позволяет определенным пользователем объектам взаи- модействовать с инфиксными операторами, например + и |, и с унарными опе- раторами, например - и ~. Вообще, вызов функции (()), доступ к атрибутам (.), доступ к элементам и срезам ([]) реализованы в Python тоже с помощью операто- ров, но в этой главе рассматриваются только унарные и инфиксные операторы. У перегрузки операторов сложилась дурная репутация в некоторых кругах. Это языковое средство, которое легко использовать неправильно (что не раз происходило), а результат – недоумение программиста, ошибки и неожидан- ные провалы производительности. Зато при правильном употреблении мы получаем приятный API и удобочитаемый код. Python стремится найти баланс между гибкостью, удобством и безопасностью, для чего вводятся некоторые ограничения: 1 Остальные ABC в стандартной библиотеке Python по-прежнему сохраняют ценность для гусиной и статической типизации. Проблема с ABC из пакета numbers объясняется в разделе « ABC из пакета numbers и числовые протоколы» главы 13. Основы перегрузки операторов  529\n--- Страница 529 ---\nзапрещается перегружать операторы для встроенных типов; запрещается создавать новые операторы, можно только перегружать су- ществующие; несколько операторов перегружать нельзя вовсе: is, and, or, not (на пораз- рядные операторы &, |, ~ это не распространяется). В классе Vector из главы 12 нам уже встречался инфиксный оператор ==, под- держиваемый методом __eq__. В этой главе мы улучшим реализацию __eq__, что- бы правильнее обрабатывать операнды, типы которых отличаются от Vector. Однако операторы сравнения (==, !=, >, <, >=, <=) – это особые случаи перегрузки операторов, поэтому начнем с перегрузки четырех арифметических операто- ров в классе Vector: сначала унарных - и +, а затем инфиксных + и *. Начнем с простейшей темы: унарных операторов. унарные Операт Оры В разделе 6.5 «Унарные арифметические и поразрядные операции» (https://docs. python.org/3/reference/expressions.html#unary-arithmetic-and-bitwise-operations) спра- вочного руководства по языку Python перечислены три унарных оператора, ко- торые ниже показаны вместе с относящимися к ним специальными методами. - (реализован с помощью __neg__ ) Унарный арифметический минус. Если x равно -2, то -x == 2. + (реализован с помощью __pos__ ) Унарный арифметический плюс. Обычно x == +x, но есть несколько осо- бых случаев, когда это неверно. Если вам интересно, см. врезку «Когда x не равно +x» ниже. ~ (реализован с помощью __invert__ ) Поразрядная инверсия целого числа, определяется как ~x == -(x+1) . Если x равно 2, то ~x == -31. В главе «Модель данных» (https://docs.python.org/3/reference/datamodel.html# object.__neg__) справочного руководства по языку Python встроенная функция abs() также названа унарным оператором. Ранее мы видели, что с ней связан специальный метод __abs__. Поддержать унарные операторы легко. Достаточно реализовать соответ - ствующий специальный метод, который принимает единственный аргумент self. Логика этого метода может быть произвольной, но должно удовлетво- ряться фундаментальное правило: оператор всегда возвращает новый объект. Иначе говоря, не модифицируйте self, а создавайте и возвращайте новый эк- земпляр подходящего типа. В случае операторов - и + результат, вероятно, должен быть экземпляром того же класса, что и self. Для унарного +, если объект, от имени которого вы- зывается оператор, неизменяемый, то следует возвращать self, иначе копию self. Для abs() результатом должен быть скаляр. 1 Объяснение поразрядной операции not см. по адресу https://en.wikipedia.org/wiki/ Bitwise_operation#NOT.530  Перегрузка операторов\n--- Страница 530 ---\nЧто касается оператора ~, то трудно сказать, какой результат считать разум- ным, если речь не идет о битах целого числа. В пакете для анализа данных pandas оператор тильды инвертирует булевы условия фильтрации; примеры см. в разделе «Булева индексация» (https://pandas.pydata.org/pandas-docs/stable/ user_guide/ indexing.html#boolean-indexing) документации по pandas. Как и было обещано, мы реализуем еще несколько операторов в классе Vector в дополнение к тому, что было сделано в главе 12. В примере 16.1 показан ме- тод __abs__ – тот же, что в примере 12.16, – и новые методы __neg__ и __pos__ для поддержки унарных операторов. Пример 16.1. vector_v6.py: унарные операторы - и + в дополнение к примеру 12.16 def __abs__(self): return math.hypot(*self) def __neg__(self): return Vector(-x for x in self)  def __pos__(self): return -Vector(self)   Для вычисления -v строим новый объект Vector, в котором все компоненты self имеют противоположный знак.  Для вычисления +v строим новый объект Vector с точно такими же компо- нентами, как у self. Напомним, что экземпляры Vector – итерируемые объекты, а Vector.__init__ принимает в качестве аргумента итерируемый объект, поэтому реализации __ neg__ и __pos__ оказались очень короткими и элегантными. Мы не станем реализовывать метод __invert__, поэтому при попытке выпол- нить операцию ~v для экземпляра Vector Python возбудит исключение TypeError с не оставляющим сомнений сообщением: «bad operand type for unary ~: 'Vector'». Прочитав об одном курьезе во врезке ниже, вы сможете как-нибудь при слу- чае выиграть пари, касающееся унарного +. Когда x не равно +x Все ожидают, что x == +x, и почти всегда в Python так оно и есть, но я нашел в стандартной библиотеке два случая, когда x != +x. Первый касается класса decimal.Decimal . Может получиться, что x != +x, если x – экземпляр Decimal, созданный в арифметическом контексте, а +x затем вычислялось в контексте с другими свойствами. Например, x вычисляется в контексте с некоторой точностью, затем точность изменяется, после чего вычисляется +x. См. демонстрацию в примере 16.2. Пример 16.2. Изменение точности в арифметическом контексте может привести к тому, что x будет отличаться от +x >>> import decimal >>> ctx = decimal.getcontext()  >>> ctx.prec = 40  Унарные операторы  531\n--- Страница 531 ---\n>>> one_third = decimal.Decimal('1') / decimal.Decimal('3')  >>> one_third  Decimal('0.3333333333333333333333333333333333333333') >>> one_third == +one_third  True >>> ctx.prec = 28  >>> one_third == +one_third  False >>> +one_third  Decimal('0.3333333333333333333333333333')  Получить ссылку на текущий глобальный арифметический контекст.  Установить точность арифметического контекста 40.  Вычислить 1/3 с текущей точностью.  Напечатать результат – имеем 40 цифр после точки.  Значение выражения one_third == +one_third равно True.  Понизить точность до 28 – значение по умолчанию для класса Decimal в Python 3.4.  Теперь значение выражения one_third == +one_third равно False.  Напечатать +one_third – после точки только 28 цифр. Получается, что при каждом вычислении выражения +one_third создается но- вый экземпляр Decimal со значением one_third, но с точностью, заданной в те- кущем арифметическом контексте. Второй случай, когда x != +x, описан в документации по классу collections. Counter (https://docs.python.org/3/library/collections.html#collections.Counter). В клас - се Counter реализовано несколько арифметических операторов, в том числе инфиксный +, который складывает счетчики соответственных элементов из двух объектов Counter. Однако из практических соображений сложение в клас - се Counter не включает в результат элементы с отрицательным или нулевым счетчиком. А унарный + прибавляет пустой объект Counter и, следовательно, сохраняет только те элементы, в которых счетчик больше нуля. Пример 16.3. Унарный + порождает новый объект Counter, в который не входят элементы с нулевыми и отрицательными счетчиками >>> ct = Counter('abracadabra') >>> ct Counter({'a': 5, 'r': 2, 'b': 2, 'd': 1, 'c': 1}) >>> ct['r'] = -3 >>> ct['d'] = 0 >>> ct Counter({'a': 5, 'b': 2, 'c': 1, 'd': 0, 'r': -3}) >>> +ct Counter({'a': 5, 'b': 2, 'c': 1}) Как видите, +ct возвращает объект Counter, в котором все счетчики больше нуля. А теперь вернемся к обычному программированию.532  Перегрузка операторов\n--- Страница 532 ---\nперегрузка Операт Ора СлОжения вект ОрОв + Класс Vector – это последовательность, а в разделе 3.3.6 «Эмуляция контейнер- ных типов» главы «Модель данных» (https://docs.python.org/3/reference/datamodel. html#emulating-container-types) говорится, что последовательности должны под- держивать оператор + с семантикой конкатенации и оператор * с семантикой повторения. Однако в данном случае мы реализуем + и * как математические операторы, что несколько труднее, но для типа Vector более осмысленно. Если пользователь хочет конкатенировать или повторить экзем- пляры Vector, то может преобразовать их в кортежи или спис- ки, применить оператор и преобразовать обратно – поскольку сам объект Vector итерируемый и может быть сконструирован из итерируемого объекта: >>> v_concatenated = Vector(list(v1) + list(v2)) >>> v_repeated = Vector(tuple(v1) * 5) Сложение двух евклидовых векторов дает новый вектор, компоненты кото- рого являются суммами соответственных компонент слагаемых, например: >>> v1 = Vector([3, 4, 5]) >>> v2 = Vector([6, 7, 8]) >>> v1 + v2 Vector([9.0, 11.0, 13.0]) >>> v1 + v2 == Vector([3 + 6, 4 + 7, 5 + 8]) True Что будет, если сложить два экземпляра Vector разной длины? Мы могли бы возбудить исключение, но в реальных приложениях (например, в информа- ционном поиске) лучше дополнить более короткий вектор нулями. Вот какой результат мы хотим получить: >>> v1 = Vector([3, 4, 5, 6]) >>> v3 = Vector([1, 2]) >>> v1 + v3 Vector([4.0, 6.0, 5.0, 6.0]) При таких требованиях мы можем реализовать __add__, как показано в при- мере 16.4. Пример 16.4. Метод Vector.add , попытка № 1 # в классе Vector def __add__(self, other): pairs = itertools.zip_longest(self, other, fillvalue=0.0)  return Vector(a + b for a, b in pairs)   pairs – генератор, который порождает кортежи (a, b), где a берется из self, а b – из other. Если длины self и other различаются, то более короткий вектор дополняется значениями fillvalue.  Новый объект Vector инициализируется генераторным выражением, кото- рое порождает по одной сумме для каждого элемента pairs. Перегрузка оператора сложения векторов +  533\n--- Страница 533 ---\nОбратите внимание, что __add__ возвращает новый экземпляр Vector, не из- меняя ни self, ни other. Специальные методы, реализующие унарные или инфиксные операторы, не должны изменять свои операнды. Предполага- ется, что выражения, содержащие такие операторы, вычисляют результаты, создавая новые объекты. И лишь операторы состав- ного присваивания могут изменять свой первый операнд (self), о чем речь пойдет ниже. В примере 16.4 разрешено прибавлять Vector к Vector2d, а также к кортежу или любому другому итерируемому объекту, порождающему числу. Это доказыва- ет пример 16.5. Пример 16.5. Vector.__add__ из примера 16.4 поддерживает сложение с объектами, от- личными от Vector >>> v1 = Vector([3, 4, 5]) >>> v1 + (10, 20, 30) Vector([13.0, 24.0, 35.0]) >>> from vector2d_v3 import Vector2d >>> v2d = Vector2d(1, 2) >>> v1 + v2d Vector([4.0, 6.0, 5.0]) Оба сложения в примере 16.5 работают, потому что в методе __add__ исполь- зуется функция zip_longest(…) , готовая принимать любые итерируемые объекты, а генераторное выражение, которым инициализируется новый Vector, просто выполняет операцию a + b для каждой пары, возвращаемой zip_longest(…) , по- этому подойдет любой итерируемый объект, порождающий числа. Однако если поменять операнды местами (пример 16.6), то сложение опе- рандов разных типов даст ошибку. Пример 16.6. Vector.__add__ из примера 16.4 дает ошибку, если тип левого операнда – не Vector >>> v1 = Vector([3, 4, 5]) >>> (10, 20, 30) + v1 Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: can only concatenate tuple (not \"Vector\") to tuple >>> from vector2d_v3 import Vector2d >>> v2d = Vector2d(1, 2) >>> v2d + v1 Traceback (most recent call last): File \"<stdin>\", line 1, in <module> TypeError: unsupported operand type(s) for +: 'Vector2d' and 'Vector' Для поддержки операций с объектами разных типов в Python имеется осо- бый механизм диспетчеризации для специальных методов, ассоциированных с инфиксными операторами. Видя выражение a + b, интерпретатор выполняет следующие шаги (см. рис. 16.1). 1. Если у a есть метод __add__, вызвать a.__add__(b) и вернуть результат, если только он не равен NotImplemented . 534  Перегрузка операторов\n--- Страница 534 ---\n2. Если у a нет метода __add__ или его вызов вернул NotImplemented , проверить, есть ли у b метод __radd__, и, если да, вызвать b.__radd__(a) и вернуть ре- зультат, если только он не равен NotImplemented . 3. Если у b нет метода __radd__ или его вызов вернул NotImplemented , возбудить исключение TypeError с сообщением unsupported operand types (неподдер- живаемые типы операндов). Метод __radd__ называется «инверсным» (reversed), или «отра- женным» (reflected), вариантом __add__. Я предпочитаю термин «инверсные» специальные методы1. инверсный оператор да дадаa + bу а есть __add__?у b есть __radd__? нетнет нет yes нет вернуть resultполучить result от a.__add__(b)получить result от b.__radd__(a)возбудить T ypeError result равен NotImplemented?result равен NotImplemented? Рис. 16.1. Блок-схема вычисления a + b с помощью перегруженных операторов __add__ и __radd__ 1 В документации по Python встречаются оба термина. В главе «Модель данных» (https://docs.python.org/3/reference/datamodel.html) используется «reflected», а в разде- ле 9.1.2.2 «Реализация арифметических операций» (https://docs.python.org/3/library/ numbers.html#implementing-the-arithmetic-operations) при описании модуля numbers упо- минаются «forward» (прямые) и «reverse» (инверсные) методы, и мне эта термино- логия нравится больше, потому что слова «прямой» и «инверсный» (не «обратный», чтобы не путать с обратной функцией. – Прим. перев.) сразу наводят на мысль о на- правлении, тогда как у слова «reflected» нет очевидного антонима. Перегрузка оператора сложения векторов +  535\n--- Страница 535 ---\nИтак, чтобы сложение операндов разных типов в примере 16.6 заработа- ло, мы должны реализовать метод Vector.__radd__ , который Python вызовет, если у левого операнда нет метода __add__ или есть, но возвращает значение NotImplemented , сигнализируя о том, что не знает, как обработать правый операнд. Не путайте NotImplemented с NotImplementedError . NotImplemented – это значение-синглтон, которое должен возвращать специ- альный метод инфиксного оператора, чтобы сообщить интер- претатору о том, что не умеет обрабатывать данный операнд. А NotImplementedError – исключение, которое возбуждают мето- ды-заглушки в абстрактных классах, предупреждая, что их не- обходимо переопределить в подклассах. Простейшая работающая реализация метода __radd__ показана в примере 16.7. Пример 16.7. Методы Vector.__add__ и __radd__ # в классе Vector def __add__(self, other):  pairs = itertools.zip_longest(self, other, fillvalue=0.0) return Vector(a + b for a, b in pairs) def __radd__(self, other):  return self + other  Метод __add__ такой же, как в примере 16.4; приведен только потому, что им пользуется метод __radd__.  __radd__ просто делегирует свою работу методу __add__. Часто инверсный оператор можно таким и оставить: просто делегировать работу нужному оператору, в данном случае __add__. Это относится к любому коммутативному оператору; + является коммутативным для чисел и векторов, но перестает быть таковым, когда используется для конкатенации последова- тельностей в Python. Если __radd__ просто вызывает __add__, то того же результата можно достичь и другим способом: def __add__(self, other): pairs = itertools.zip_longest(self, other, fillvalue=0.0) return Vector(a + b for a, b in pairs) __radd__ = __add__ Методы в примере 16.7 работают как с объектами Vector, так и с любыми дру- гими итерируемыми объектами, содержащими числовые элементы: Vector2d, кортеж целых чисел или массив чисел с плавающей точкой. Но если методу __add__ подсунуть неитерируемый объект, то он выдаст не слишком полезное сообщение об ошибке, как в примере 16.8. Пример 16.8. Методу Vector.__add__ необходим итерируемый операнд >>> v1 + 1 Traceback (most recent call last): File \"<stdin>\", line 1, in <module> 536  Перегрузка операторов\n--- Страница 536 ---\nFile \"vector_v6.py\", line 328, in __add__ pairs = itertools.zip_longest(self, other, fillvalue=0.0) TypeError: zip_longest argument #2 must support iteration Хуже того, мы получаем сбивающее с толку сообщение, если операнд – ите- рируемый объект, но его элементы нельзя сложить с элементами Vector, имею- щими тип float. См. пример 16.9. Пример 16.9. Методу Vector.__add__ необходим итерируемый операнд с числовыми эле- ментами >>> v1 + 'ABC' Traceback (most recent call last): File \"<stdin>\", line 1, in <module> File \"vector_v6.py\", line 329, in __add__ return Vector(a + b for a, b in pairs) File \"vector_v6.py\", line 243, in __init__ self._components = array(self.typecode, components) File \"vector_v6.py\", line 329, in <genexpr> return Vector(a + b for a, b in pairs) TypeError: unsupported operand type(s) for +: 'float' and 'str' Я пытался сложить Vector и str, но в сообщении упоминаются float и str. Однако непонятные сообщения в примерах 16.8 и 16.9 – еще не самое страшное: если специальный метод оператора не может вернуть правиль- ный результат из-за несовместимости типов, он должен возвращать значение NotImplemented , а не возбуждать исключение TypeError. Возвращая NotImplemented , вы оставляете разработчику типа другого операнда возможность выполнить опе- рацию, когда Python попробует вызвать инверсный метод. Оставаясь верны духу утиной типизации, мы воздержимся от проверки типа операнда other или его элементов. Вместо этого мы перехватим исключение и вернем NotImplemented . Если интерпретатор еще не пробовал операнды в об- ратном порядке, то сделает это. Если же значение NotImplemented вернул инверс - ный метод, то Python возбудит исключение TypeError со стандартным сообще- нием вида «unsupported operand type(s) for +: Vector and str». Окончательная реализация специальных методов для сложения объектов класса Vector приведена в примере 16.10. Пример 16.10. vector_v6.py: специальные методы оператора +, добавленные в файл vector_v5.py (пример 12.16) def __add__(self, other): try: pairs = itertools.zip_longest(self, other, fillvalue=0.0) return Vector(a + b for a, b in pairs) except TypeError: return NotImplemented def __radd__(self, other): return self + other Заметим, что теперь __add__ перехватывает TypeError и возвращает NotImplemented . Перегрузка оператора сложения векторов +  537\n--- Страница 537 ---\nЕсли метод инфиксного оператора возбуждает исключение, то работа алгоритма диспетчеризации прерывается. В частном случае исключения TypeError зачастую лучше перехватить его и вернуть значение NotImplemented . Это позволит интерпрета- тору вызвать метод инверсного оператора, который, возмож - но, сумеет завершить вычисление, поменяв местами операнды разных типов. Итак, мы безопасно перегрузили оператор +, написав методы __add__ и __radd__. Теперь займемся инфиксным оператором *. перегрузка Операт Ора умнО жения на Скаляр * Что означает запись Vector([1, 2, 3]) * x ? Если x – число, то это умножение на скаляр, результатом которого является новый объект Vector, каждая компонен- та которого является произведением x и соответственной компоненты исход- ного вектора: >>> v1 = Vector([1, 2, 3]) >>> v1 * 10 Vector([10.0, 20.0, 30.0]) >>> 11 * v1 Vector([11.0, 22.0, 33.0]) Над векторами определена и другая операция умножения: ска- лярное произведение; если представить один вектор как матрицу 1×N, а другой – как матрицу N×1, то результат перемножения этих матриц и называется скалярным произведением. Мы реализуем этот оператор в классе Vector в разделе «Использование @ как ин- фиксного оператора». Но вернемся к операции умножения на скаляр. Как и раньше, начнем с прос- тейших вариантов __mul__ и __rmul__: # в классе Vector def __mul__(self, scalar): return Vector(n * scalar for n in self) def __rmul__(self, scalar): return self * scalar Оба метода работают, если типы операндов совместимы. Аргумент scalar должен быть числом, которое при умножении на float дает float (поскольку во внутреннем представлении класса Vector используется массив чисел типа float). Поэтому число типа complex не подойдет, однако годятся типы int, bool (по- скольку bool – подкласс int) и даже fractions.Fraction . В примере 16.11 метод __mul__ не проверяет тип scalar явно, а пытается преобразовать его в тип float и возвращает NotImplemented , если эта попытка завершается неудачно. Это яркий пример утиной типизации. 538  Перегрузка операторов\n--- Страница 538 ---\nПример 16.11. vector_v7.py: добавлены методы оператора * class Vector: typecode = 'd' def __init__(self, components): self._components = array(self.typecode, components) # много методов опущено, полный код см. в файле vector_v7.py # по адресу https://github.com/fluentpython/example-code-2e def __mul__(self, scalar): try: factor = float(scalar) except TypeError:  return NotImplemented  return Vector(n * factor for n in self) def __rmul__(self, scalar): return self * scalar   Если scalar нельзя преобразовать в float…  … то мы не знаем, как его обработать, поэтому возвращаем NotImplemented , чтобы Python мог попробовать оператор __rmul__ операнда scalar.  В этом примере __rmul__ просто вычисляет произведение self * scalar , деле- гируя всю работу методу __mul__. Код из примера 16.11 позволяет умножать векторы на скалярные значения обычных и не очень обычных числовых типов: >>> v1 = Vector([1.0, 2.0, 3.0]) >>> 14 * v1 Vector([14.0, 28.0, 42.0]) >>> v1 * True Vector([1.0, 2.0, 3.0]) >>> from fractions import Fraction >>> v1 * Fraction(1, 3) Vector([0.3333333333333333, 0.6666666666666666, 1.0]) Научившись умножать Vector на скаляры, посмотрим, как реализовать умно- жение Vector на Vector. В первом издании я использовал в примере 16.11 гусиную ти- пизацию: проверял аргумент scalar метода __mul__ с помощью isinstance(scalar, numbers.Real) . Теперь я избегаю ABC из пакета numbers, потому что они не поддерживаются документом PEP 484, а использовать во время выполнения типы, которые нельзя про- верить статически, мне не нравится. Альтернативно я мог бы проверять поддержку протокола typing. SupportsFloat , как мы видели в разделе «Статические протоколы, допускающие проверку во время выполнения» главы 13. Я вы- брал в этом примере утиную типизацию, потому что считаю, что мастеровитый питонист должен свободно владеть этим при- емом кодирования. С другой стороны, метод __matmul__ в примере 16.12, добавлен- ном в этом издании, дает хороший пример гусиной типизации. Перегрузка оператора умножения на скаляр *  539\n--- Страница 539 ---\nиСпОльзОвание @ как инфик СнОг О Операт Ора Знак @ хорошо известен как префикс декораторов функций, но начиная с 2015 года он используется также в качестве инфиксного оператора. В тече- ние многих лет скалярное произведение записывалось в виде numpy.dot(a, b) в NumPy. Синтаксис вызова функции усложняет запись длинных математи- ческих формул на Python1, поэтому часть сообщества, занимающаяся числен- ными методами, пролоббировала документ PEP 465 «A dedicated infix operator for matrix multiplication» (https://peps.python.org/pep-0465/), который был реали- зован в Python 3.5. Сегодня мы можем писать a @ b, когда нужно вычислить скалярное произведение двух массивов NumPy. Оператор @ поддерживается специальными методами __matmul__ , __rmatmul__ и __imatmul__ , имена которых означают «matrix multiplication» (умножение ма- триц). В настоящее время эти методы не используются в стандартной биб- лиотеке, но интерпретатор знает о них, начиная с версии Python 3.5, так что команда NumPy, да и все мы можем поддержать оператор @ в определенных пользователем типах. Синтаксический анализатор также был изменен и те- перь умеет обрабатывать новый оператор (конструкция a @ b в Python 3.4 счи- талась синтаксической ошибкой). Следующие простые тесты показывают, как @ должен работать с экземпля- рами Vector: >>> va = Vector([1, 2, 3]) >>> vz = Vector([5, 6, 7]) >>> va @ vz == 38.0 # 1*5 + 2*6 + 3*7 True >>> [10, 20, 30] @ vz 380.0 >>> va @ 3 Traceback (most recent call last): TypeError: unsupported operand type(s) for @: 'Vector' and 'int' В примере 16.12 показан код необходимых специальных методов. Пример 16.12. vector_v7.py: методы оператора @ class Vector: # много методов опущено def __matmul__(self, other): if (isinstance(other, abc.Sized) and  isinstance(other, abc.Iterable)): if len(self) == len(other):  return sum(a * b for a, b in zip(self, other))  else: raise ValueError('@ requires vectors of equal length.') else: return NotImplemented def __rmatmul__(self, other): return self @ other 1 См. обсуждение этой проблемы в разделе «Поговорим».540  Перегрузка операторов\n--- Страница 540 ---\n Оба операнда должны реализовывать методы __len__ и __iter__ …  … и иметь одинаковую длину, чтобы можно было …  … элегантно применить sum, zip и генераторное выражение. Новая возможность zip() в Python 3.10 Начиная с версии Python 3.10 встроенная функция zip прини- мает факультативный чисто именованный аргумент strict. Если strict=True , то функция возбуждает исключение ValueError , ког- да итерируемые объекты имеют разную длину. По умолчанию strict равен False. Это новое поведение согласуется с принци- пом быстрого отказа, принятым в Python. В примере 16.12 я бы заменил внутреннее предложение if предложением try/except ValueError и добавил при вызове zip аргумент strict=True . Пример 16.12 – хорошая иллюстрация практического применения гусиной типизации. Если бы мы сравнивали тип операнда other с Vector, то лишили бы пользователей возможности использовать списки или массивы в качестве операндов @. Коль скоро один операнд имеет тип Vector, наша реализация @ поддерживает другие операнды, являющиеся экземплярами abc.Sized и abc. Iterable. Оба этих ABC реализуют метод __subclasshook__ , поэтому любой объект, предоставляющий методы __len__ и __iter__, проходит наш тест – и не нужно ни наследовать этим ABC, ни даже регистрировать их виртуальные подклас - сы (см. раздел «ABC и структурная типизация» главы 13). В частности, наш класс Vector не наследует ни abc.Sized, ни abc.Iterable, но проходит проверки на совместимость с этими ABC с помощью isinstance , потому что имеет необхо- димые методы. арифметичеСкие Операт Оры – итОги При реализации операторов + и * мы познакомились с наиболее распростра- ненными приемами программирования инфиксных операторов. Описанная техника применима ко всем операторам, перечисленным в табл. 16.1 (опера- торы, вычисляемые на месте, будут рассмотрены в разделе «Составные опера- торы присваивания» ниже). Таблица 13.1. Имена методов инфиксных операторов (операторы, вычисляемые на месте, связаны с составным присваиванием; операторы сравнения описаны в табл. 16.2) Оператор Прямой Инверсный На месте Описание + __add__ __radd__ __iadd__ Сложение или конкатенация - __sub__ __rsub__ __isub__ Вычитание * __mul__ __rmul__ __imul__ Умножение или повторение / __truediv__ __rtruediv__ __itruediv__ Истинное деление // __floordiv__ __rfloordiv__ __ifloordiv__ Деление с округлением % __mod__ __rmod__ __imod__ Деление по модулю divmod() __divmod__ __rdivmod__ __idivmod__ Возвращает кортеж, содержащий частное и остаток Арифметические операторы – итоги  541\n--- Страница 541 ---\nОператор Прямой Инверсный На месте Описание **, pow() __pow__ __rpow__ __ipow__ Возведение в степеньa @ __matmul__ __rmatmul__ __imatmul__ Матричное умножение & __and__ __rand__ __iand__ Поразрядное И | __or__ __ror__ __ior__ Поразрядное ИЛИ ^ __xor__ __rxor__ __ixor__ Поразрядное ИСКЛЮЧАЮЩЕЕ ИЛИ << __lshift__ __rlshift__ __ilshift__ Поразрядный сдвиг влево >> __rshift__ __rrshift__ __irshift__ Поразрядный сдвиг вправо a Оператор pow принимает необязательный третий аргумент, modulo : pow(a, b, modulo) , поддерживаемый также специальными методами, если они вызываются напрямую (например, a.__pow__(b, modulo) ). Для операторов сравнения действуют несколько иные правила. Операт Оры Сравнения Обработка операторов сравнения ==, !=, >, <, >=, <= интерпретатором Python по- хожа на то, что мы видели выше, но имеет два важных отличия. Для прямых и инверсных вызовов служит один и тот же набор методов. Правила приведены в табл. 16.2. Например, в случае оператора == как прямой, так и инверсный вызовы обращаются к методу __eq__, но изме- няется порядок аргументов. А прямой вызов __gt__ сопровождается ин- версным вызовом __lt__ с переставленными аргументами. В случае == и !=, если инверсный метод отсутствует или возвращает NotImplemented , Python сравнивает идентификаторы объектов, а не возбуж - дает исключение TypeError. Таблица 16.2. Операторы сравнения: инверсные методы вызываются, когда первый вызов вернул NotImplemented Группа Инфиксный операторПрямой вызов методаИнверсный вызов методаЗапасной вариант Равенство a == b a.__eq__(b) b.__eq__(a) Вернуть id(a) == id(b) a != b a.__ne__(b) b.__ne__(a) Вернуть not (a == b) Порядок a > b a.__gt__(b) a.__lt__(b) Возбудить TypeError a < b a.__lt__(b) a.__gt__(b) Возбудить TypeError a >= b a.__ge__(b) a.__le__(b) Возбудить TypeError a <= b a.__le__(b) a.__ge__(b) Возбудить TypeError Имея в виду эти правила, давайте улучшим поведение метода Vector.__eq__ , которое в файле vector_v5.py (пример 12.16) было закодировано следующим образом:Окончание табл. 13.1542  Перегрузка операторов\n--- Страница 542 ---\nclass Vector: # много строк опущено def __eq__(self, other): return (len(self) == len(other) and all(a == b for a, b in zip(self, other))) В примере 16.13 показаны результаты работы этого метода. Пример 16.13. Сравнение Vector с Vector, с Vector2d и с tuple >>> vb = Vector(range(1, 4)) >>> va == vb  True >>> vc = Vector([1, 2]) >>> from vector2d_v3 import Vector2d >>> v2d = Vector2d(1, 2) >>> vc == v2d  True >>> t3 = (1, 2, 3) >>> va == t3  True  Два объекта Vector с равными числовыми компонентами должны быть равны.  Объекты Vector и Vector2d также равны, если равны их компоненты.  Vector считается равным кортежу или любому другому итерируемому объ- екту, с числовыми элементами, соответственно равными его элементам. Последний результат в примере 13.12 вряд ли следует считать желательным. Действительно ли мы хотим, чтобы Vector считался равным кортежу, содержа- щему такие же числа? Впрочем, твердой уверенности у меня нет – все зависит от контекста. Однако в «Дзен Python» сказано: Встретив неоднозначность, отбрось искушение угадать. Излишняя либеральность при вычислении операндов может преподнести сюрпризы, а программисты их ненавидят. Если в поисках ключа обратиться к самому Python, то мы увидим, что срав- нение [1,2] == (1, 2) дает False. Поэтому будем осторожны и добавим сравнение типов. Если второй операнд – объект класса Vector (или его подкласса), то оста- вим ту же логику, что в текущей реализации __eq__. Иначе вернем NotImplemented , и пусть Python разбирается. Пример 16.14. vector_v8.py: улучшенный метод __eq__ в классе Vector def __eq__(self, other): if isinstance(other, Vector):  return (len(self) == len(other) and all(a == b for a, b in zip(self, other))) else: return NotImplemented   Если операнд other – объект класса Vector (или его подкласса), то выполнить сравнение, как и раньше.  Иначе вернуть NotImplemented . Операторы сравнения  543\n--- Страница 543 ---\nПрогнав тесты из примера 16.13 для новой реализации Vector.__eq__ , мы по- лучим следующие результаты. Пример 16.15. Те же сравнения, что в примере 16.13, последний результат изменился >>> vb = Vector(range(1, 4)) >>> va == vb  True >>> vc = Vector([1, 2]) >>> from vector2d_v3 import Vector2d >>> v2d = Vector2d(1, 2) >>> vc == v2d  True >>> t3 = (1, 2, 3) >>> va == t3  False  Тот же результат, что и раньше. Как и ожидалось.  Тот же результат, что и раньше. Но почему? Объяснение последует ниже.  Другой результат – то, что мы и хотели. Но почему это работает? Читайте дальше… Из трех результатов в примере 16.15 первый не вызывает удивления, а два других объясняются тем, что метод __eq__ из примера 16.14 вернул NotImplemented . Рассмотрим шаг за шагом, что происходит при сравнении Vector и Vector2d. 1. Для вычисления vc == v2d Python вызывает Vector.__eq__(vc, v2d) . 2. Метод Vector.__eq__(vc, v2d) видит, что v2d не принадлежит классу Vector, и возвращает NotImplemented . 3. Получив результат NotImplemented , Python вызывает Vector2d.__eq__(v2d, vc) . 4. Vector2d.__eq__(v2d, vc) преобразует оба операнда в кортежи и сравнивает их, результат оказывается равен True (код метода Vector2d.__eq__ приведен в примере 11.11). При сравнении же Vector и tuple производятся следующие шаги. 1. Для вычисления va == t3 Python вызывает Vector.__eq__(va, t3) . 2. Метод Vector.__eq__(va, t3) видит, что t3 не принадлежит классу Vector, и возвращает NotImplemented . 3. Получив результат NotImplemented , Python вызывает tuple.__eq__(t3, va) . 4. tuple.__eq__(t3, va) ничего не знает о классе Vector, поэтому возвращает NotImplemented . 5. Оператор == рассматривается как особый случай: если инверсный вызов вернул NotImplemented , то Python в качестве последнего средства сравнива- ет идентификаторы объектов. Нам не нужно реализовывать метод !=, потому что поведение метода __ne__, унаследованное от object, нас вполне устраивает: если __eq__ определен и воз- вращает что-то, кроме NotImplemented , то __ne__ возвращает противоположное значение. Иными словами, при тех же объектах, что в примере 16.15, результаты опе- ратора != непротиворечивы:544  Перегрузка операторов\n--- Страница 544 ---\n>>> va != vb False >>> vc != v2d False >>> va != (1, 2, 3) True Метод __ne__, унаследованный от object, работает, как показано в следующем фрагменте, хотя в действительности он написан на C1: def __ne__(self, other): eq_result = self == other if eq_result is NotImplemented: return NotImplemented else: return not eq_result Рассмотрев перегрузку инфиксных операторов, обратимся к операторам со- ставного присваивания. Операт Оры СОСтавнОг О приСваивания Наш класс Vector уже поддерживает операторы составного присваивания += и *=. Это объясняется тем, что для неизменяемых объектов оператор состав- ного присваивания создает новый экземпляр и связывает его с переменной в левой части. В примере 16.16 операторы составного присваивания показаны в действии. Пример 16.16. Использование += и *= для экземпляров Vector >>> v1 = Vector([1, 2, 3]) >>> v1_alias = v1  >>> id(v1)  4302860128 >>> v1 += Vector([4, 5, 6])  6 >>> v1  Vector([5.0, 7.0, 9.0]) >>> id(v1)  4302859904 >>> v1_alias  Vector([1.0, 2.0, 3.0]) >>> v1 *= 11  >>> v1  Vector([55.0, 77.0, 99.0]) >>> id(v1) 4302858336  Создать псевдоним, чтобы можно было проинспектировать объект Vector([1, 2, 3]) позже. 1 Логика методов object.__eq__ и object.__ne__ для интерпретатора CPython реали- зована в функции object_richcompare в исходном файле Objects/typeobject.c ( https:// github.com/python/cpython/blob/0bbf30e2b910bc9c5899134ae9d73a8df968da35/Objects/ typeobject.c#L4598). Операторы составного присваивания  545\n--- Страница 545 ---\n Запомнить идентификатор исходного объекта Vector, связанного с v1.  Выполнить составное сложение.  Результат ожидаемый…  …но создан новый Vector.  Проинспектировать v1_alias, чтобы убедиться, что исходный Vector не изме- нился.  Выполнить составное умножение.  Результат снова ожидаемый, но создан новый Vector. Если в классе не реализованы операторы «на месте», перечисленные в табл. 16.1, то операторы составного присваивания – не более чем синтакси- ческий сахар: a += b вычисляется точно так же, как a = a + b. Это ожидаемое поведение для неизменяемых типов, и если добавить метод __add__, то += будет работать безо всякого дополнительного кода. Однако если все-таки реализовать метод оператора «на месте», например __iadd__, то он и будет вызван для вычисления выражения a += b. Как следует из названия, такие операторы изменяют сам левый операнд, а не создают новый объект-результат. Специальные методы, вычисляемые на месте, никогда не следу - ет реализовывать для неизменяемых типов и, в частности, для нашего класса Vector. Это, в общем-то, очевидно, но лишний раз подчеркнуть не помешает. Чтобы продемонстрировать код оператора «на месте», мы расширим класс BingoCage из примера 13.9, реализовав в нем методы __add__ и __iadd__. Назовем подкласс AddableBingoCage . В примере 16.17 показано, какого поведе- ния мы ожидаем от оператора +. Пример 16.17. Оператор + создает новый экземпляр AddableBingoCage >>> vowels = 'AEIOU' >>> globe = AddableBingoCage(vowels)  >>> globe.inspect() ('A', 'E', 'I', 'O', 'U') >>> globe.pick() in vowels  True >>> len(globe.inspect())  4 >>> globe2 = AddableBingoCage('XYZ')  >>> globe3 = globe + globe2 >>> len(globe3.inspect())  7 >>> void = globe + [10, 20]  Traceback (most recent call last): TypeError: unsupported operand type(s) for +: 'AddableBingoCage' and 'list'  Создать объект globe с пятью элементами (все гласные буквы).  Извлечь один элемент и проверить, что это гласная.  Убедиться, что количество элементов в globe уменьшилось до четырех. 546  Перегрузка операторов\n--- Страница 546 ---\n Создать второй экземпляр с тремя элементами.  Создать третий экземпляр, складывая первые два. В этом экземпляре семь элементов.  Попытка сложить AddableBingoCage со списком приводит к исключению TypeError. Такое сообщение интерпретатор Python генерирует, когда наш метод __add__ возвращает NotImplemented . Объект AddableBingoCage изменяемый, и в примере 16.18 показано, как он ве- дет себя после добавления метода __iadd__. Пример 16.18. Существующий объект AddableBingoCage можно модифицировать с помо- щью оператора += (продолжение примера 16.17) >>> globe_orig = globe  >>> len(globe.inspect())  4 >>> globe += globe2  >>> len(globe.inspect()) 7 >>> globe += ['M', 'N']  >>> len(globe.inspect()) 9 >>> globe is globe_orig  True >>> globe += 1  Traceback (most recent call last): TypeError: right operand in += must be 'Tombola' or an iterable  Создать псевдоним, чтобы можно было проверить идентификатор объекта позже.  Здесь globe содержит четыре элемента.  Объект AddableBingoCage может получать элементы от другого объекта того же класса.  Правый операнд += может быть любым итерируемым объектом.  В этом примере globe все время ссылается на объект globe_orig .  Попытка сложить AddableBingoCage с неитерируемым объектом приводит к исключению TypeError с надлежащим сообщением. Отметим, что оператор += либеральнее, чем +, относится ко второму операн- ду. В случае + мы хотели, чтобы оба операнда имели одинаковый тип (в дан- ном случае AddableBingoCage ), потому что иначе было бы не понятно, какой тип должен иметь результат. Для += ситуация проще: левый объект обновляется на месте, поэтому тип результата не вызывает сомнений. Различия в поведении операторов + и += я обосновал, наблюдая за работой встроенного типа list. Запись my_list + x позволяет конкатенировать только один список с другим, но если написать my_list += x , то в правой части может стоять любой итерируемый объект x. Это согласуется с поведением метода list.extend() : он принимает произвольный итерируемый аргумент. Операторы составного присваивания  547\n--- Страница 547 ---\nПоняв, чего мы хотим от класса AddableBingoCage , рассмотрим его реализацию (пример 16.19). Напомним, что BingoCage из примера 13.9 – конкретный под- класс ABC Tombola из примера 13.7. Пример 16.19. bingoaddable.py: класс AddableBingoCage расширяет BingoCage , добавляя поддержку операторов + и += from tombola import Tombola from bingo import BingoCage class AddableBingoCage(BingoCage):  def __add__(self, other): if isinstance(other, Tombola):  return AddableBingoCage(self.inspect() + other.inspect()) else: return NotImplemented def __iadd__(self, other): if isinstance(other, Tombola): other_iterable = other.inspect()  else: try: other_iterable = iter(other)  except TypeError:  msg = ('right operand in += must be ' \"'Tombola' or an iterable\") raise TypeError(msg) self.load(other_iterable)  return self   AddableBingoCage расширяет BingoCage.  Наш метод __add__ работает, только когда вторым операндом является объ- ект класса Tombola.  В __iadd__ получить элементы из other, если это экземпляр Tombola.  В противном случае попытаться получить итератор для other1.  В случае ошибки возбудить исключение, объясняя пользователю, что де- лать. По возможности сообщения об ошибках должны содержать ясное указание, как решить проблему.  Если мы дошли до этого места, то можем загрузить объект other_iterable в self.  Очень важно: специальные методы операторов составного присваивания должны возвращать self. Именно этого ожидает пользователь. Резюмировать идею операторов «на месте» можно, сравнив предложения return, которые возвращают результаты в методах __add__ и __iadd__ из примера 16.19: __add__ Результат порождается путем вызова конструктора AddableBingoCage для соз- дания нового экземпляра. 1 Встроенная функция iter рассматривается в следующей главе. Здесь я мог бы на- писать tuple(other) , и это работало бы, но ценой построения нового кортежа, хотя методу .load(…) нужно только обойти свой аргумент.548  Перегрузка операторов\n--- Страница 548 ---\n__iadd__ Результат порождается путем возврата self после модификации. И последнее замечание к примеру 16.19: в классе AddableBingoCage я сознательно не стал реализовывать метод __radd__, т. к. в нем нет необходимости. Прямой метод __add__ работает, только когда правый операнд имеет тот же тип, что левый, поэто- му если Python попытается вычислить a + b, где a принадлежит типу AddableBingoCage , а b – нет, то получит в ответ NotImplemented – быть может, сумеет справиться класс объекта b. Но при вычислении выражения b + a, когда b не принадлежит типу AddableBingoCage и возвращает NotImplemented , лучше позволить интерпретатору сдать- ся и возбудить исключение TypeError, поскольку мы не умеем обрабатывать b. В общем случае, если прямой инфиксный оператор (например, __mul__) предназначен для работы только с операндами того же типа, что self, бесполезно реализовывать соответствующий ин- версный метод (например, __rmul__), потому что он, по определе- нию, вызывается, только когда второй операнд имеет другой тип. На этом мы завершаем рассмотрение перегрузки операторов в Python. резюме Мы начали эту главу с обзора ограничений, который Python налагает на пере- грузку операторов: запрещается перегружать операторы встроенных типов, за- прещается создавать новые операторы и перегружать операторы is, and, or и not. Потом мы занялись унарными операторами и реализовали методы __neg__ и __pos__. Далее перешли к инфиксным операторам, начав с + и поддержива- ющего его метода __add__. Мы видели, что унарные и инфиксные операторы должны возвращать новый объект в качестве результата и не должны изме- нять свои операнды. Чтобы поддержать операции с разными типами, мы воз- вращаем специальное значение NotImplemented – не исключение, – давая интер- претатору возможность попробовать еще раз: поменять операнды местами и вызвать специальный инверсный метод, соответствующий тому же операто- ру (например, __radd__). Алгоритм работы с инфиксными операторами в Python показан на рис. 16.1. Раз мы можем производить операции над объектами разных типов, то долж - ны уметь определять, что нам подсунули операнд, который мы не способны обработать. Мы применяли для этого два способа: либо в духе утиной типи- зации пробовали выполнить операцию и перехватывали возможное исключе- ние TypeError, либо – в методе __mul__ – явно проверяли тип с помощью isinstance . У обоих подходов есть свои плюсы и минусы: утиная типизация обладает боль- шей гибкостью, а явная проверка типов дает более предсказуемый результат. В общем случае библиотекам лучше использовать утиную типизацию, держа дверь открытой для любых объектов, поддерживающих необходимые опера- ции, вне зависимости от их типа. Однако алгоритм диспетчеризации операто- ров в Python может выдавать вводящие в заблуждение сообщения об ошибках или возвращать неожиданные результаты, если сочетается с утиной типиза- цией. По этой причине при написании специальных методов для перегрузки Резюме  549\n--- Страница 549 ---\nоператоров часто бывает полезно сравнивать тип с ABC посредством isinstance . Эта техника, которую Алекс Мартелли окрестил гусиной типизацией (см. раз- дел «Гусиная типизация» главы 13), предлагает разумный компромисс между гибкостью и безопасностью, поскольку существующие или будущие пользо- вательские типы можно объявить как настоящие или виртуальные подклассы ABC. Кроме того, если ABC реализует метод __subclasshook__ , то объект пройдет проверку isinstance на предмет сравнения с этим ABC, если предоставит требу - емые методы – ни наследования, ни регистрации при этом не требуется. Далее мы обсудили операторы сравнения. Мы реализовали оператор == с по- мощью метода __eq__ и выяснили, что Python предоставляет удобную реализа- цию оператора != в форме метода __ne__, унаследованного от базового класса object. Эти операторы, а также >, <, >= и <= Python вычисляет несколько иначе, применяя различную логику для выбора инверсного метода и специальный запасной вариант для операторов == и != – в этом случае исключение никогда не возбуждается, потому что интерпретатор в качестве последнего средства сравнивает идентификаторы объектов. Последний раздел был посвящен операторам составного присваивания. Мы видели, что Python по умолчанию рассматривает их как комбинацию обычного оператора и присваивания, то есть a += b вычисляется точно так же, как a = a + b. При этом всегда создается новый объект, так что оператор одина- ково хорошо работает для изменяемых и неизменяемых типов. Но для изме- няемых типов мы можем реализовать специальные методы, вычисляемые на месте, например __iadd__ для оператора +=, и модифицировать значение левого операнда. Чтобы продемонстрировать эту возможность, мы расстались с неиз- меняемым классом Vector и занялись реализацией подкласса BingoCage, поддер- живающего оператор += для добавления элементов в случайный пул – по ана- логии с тем, как встроенный тип list поддерживает оператор +=, являющийся сокращенной записью метода list.extend() . Попутно мы обсудили, почему опе- ратор + ведет себя более разборчиво, чем +=, в том, что касается допустимых типов операндов. Для типов последовательностей + обычно требуется, чтобы оба операнда имели одинаковый тип, тогда как += зачастую принимает произ- вольный итерируемый объект в качестве правого операнда. дОпО лнительная литература Гвидо ван Россум выступил в защиту перегрузки операторов в статье «Why operators are useful» (https://neopythonic.blogspot.com/2019/03/why-operators-are-useful.html). Трей Ханнер в своем блоге разместил пост «Tuple ordering and deep comparisons in Python» (https://treyhunner.com/2019/03/python-deep-comparisons-and-code-readability/), доказывая, что операторы сравнения в Python являются более гибкими и мощны- ми, чем полагают программисты, знакомые с другими языками. Перегрузка операторов – одна из областей программирования на Python, где проверки с помощью isinstance – обычное дело. Для таких проверок ре- комендуется гусиная типизация, рассмотренная в одноименном разделе гла- вы 13. Если вы ее пропустили, прочитайте сейчас. Основным источником информации о специальных методах операторов является глава «Модель данных» (https://docs.python.org/3/reference/datamodel.550  Перегрузка операторов\n--- Страница 550 ---\nhtml) справочного руководства. Еще одна относящаяся к теме часть докумен- тации – раздел 9.1.2.2 «Реализация арифметических операций» (https://docs. python.org/3/library/numbers.html#implementing-the-arithmetic-operations) в описании модуля numbers стандартной библиотеки Python. Изобретательный пример перегрузки операторов имеется в пакете pathlib (https://docs.python.org/3/library/pathlib.html), добавленном в версии Python 3.4. Класс Path перегружает оператор / с целью построения путей в файловой си- стеме из строк. Как это делается, показывает пример, взятый из документации: >>> p = Path('/etc') >>> q = p / 'init.d' / 'reboot' >>> q PosixPath('/etc/init.d/reboot') Еще один пример перегрузки операторов, не относящийся к арифметике, дает библиотека Scapy (https://pypi.org/project/scapy/), предназначенная для «от- правки, прослушивания, анализа и подделки сетевых пакетов». В Scapy опе- ратор / строит пакеты, собирая поля из различных сетевых уровней. Детали см. в разделе документации «Stacking layers» (https://scapy.readthedocs.io/en/latest/ usage.html# stacking-layers). Если вы собираетесь реализовать операторы сравнения, изучите функцию functools.total_ordering . Это декоратор класса, который автоматически генериру - ет недостающие методы для всех операторов сравнения в любом классе, где есть хотя бы два из них. См. документацию по модулю functools (https://docs. python.org/3/library/functools.html#functools.total_ordering ). Если вам интересно узнать о диспетчеризации операторных методов в языках с динамической типизацией, почитайте две основополагающие работы: Дэн Ин- голлс (один из разработчиков Smalltalk) «A Simple Technique for Handling Multiple Polymorphism» (https://dl.acm.org/doi/10.1145/960112.28732) и Курт Дж. Гебель, Ральф Джонсон «Arithmetic and Double Dispatching in Smalltalk-80» (https://www.researchgate. net/publication/239578755_Arithmetic_and_double-_dispatching_in_smalltalk-80) (Джонсон впоследствии стал знаменит как один из авторов книги «Паттерны проектирова- ния»). В обеих статьях глубоко проработан вопрос о полиморфизме в языках с ди- намической типизацией, к каковым относятся Smalltalk, Python и Ruby. В Python для обработки операторов не применяется двойная диспетчеризация, описанная в этих статьях. Используемый в Python алгоритм на основе прямого и инверсного операторов проще поддержать в пользовательских классах, чем двойную диспет - черизацию, но он требует специального внимания со стороны интерпретатора. Напротив, классическая двойная диспетчеризация – это общая техника, приме- нимая как в Python, так и в любом другом объектно-ориентированном языке, – и не только в контексте инфиксных операторов. На самом деле Инголлс, Гебель и Джонсон иллюстрируют ее на самых разных примерах. Статья «The C Family of Languages: Interview with Dennis Ritchie, Bjarne Stroustrup, and James Gosling» (http://www.gotw.ca/publications/c_family_interview. htm), из которой взят эпиграф к этой главе, а также две цитаты во врезке «По- говорим», была опубликована в журналах «Java Report», 5 (7), июль 2000, и «C++ Report», 12 (7), июль-август 2000. Это очень увлекательное чтение для всех, кто интересуется проектированием языков программирования. Дополнительная литература  551\n--- Страница 551 ---\nПоговорим Перегрузка операторов: за и против Джеймс Гослинг, процитированный в эпиграфе к этой главе, сознательно ре- шил не включать перегрузку операторов в язык Java. В том же интервью («The C Family of Languages: Interview with Dennis Ritchie, Bjarne Stroustrup, and James Gosling» – http://www.gotw.ca/publications/c_family_interview.htm) он говорит: Наверное, от 20 до 30 процентов людей считают перегрузку опера- торов порождением дьявола; кто-то делал с помощью перегрузки операторов нечто такое, что напрочь выносит мозг, поскольку ис- пользование + для вставки в список способно привести в полное за- мешательство. Проблема проистекает главным образом из того, что есть всего пяток операторов, перегружать которые имеет смысл, и ты- сячи, а то и миллионы операторов, которые программисты хотели бы определить. Поэтому приходится выбирать, и зачастую выбор входит в противоречие с интуицией. Гвидо ван Россум выбрал средний путь: он не оставил пользователям от- крытую дверь для определения новых операторов, например <=> или :-), чем предотвратил возведение Вавилонской башни нестандартных операторов и переусложнение синтаксического анализатора. Python также не позволяет перегружать операторы встроенных типов, и это ограничение тоже способ- ствует удобочитаемости и обеспечивает предсказуемую производительность. Гослинг продолжает: Из всего сообщества примерно 10 процентов используют перегрузку операторов надлежащим образом и относятся к ней ответственно, им она действительно необходима. Это почти исключительно люди, за- нимающиеся численными расчетами, где нотация обязательно долж - на быть интуитивно очевидной; возможность написать «a + b», где a и b – комплексные числа, матрицы или еще что-то в этом роде, действи- тельно полезна. Разумеется, и у решения запретить перегрузку операторов в языке есть свои плюсы. Я встречал мнение, что C лучше, чем C++ для системного програм- мирования, потому что из-за перегрузки операторов в C++ дорогостоящие операции могут показаться тривиальными. В двух современных успешных языках, которые компилируются в двоичные исполняемые файлы, приняты противоположные решения по этому поводу: в Go нет перегрузки операто- ров, а в Rust есть (https://doc.rust-lang.org/std/ops/ index.html). Но при разумном использовании перегруженные операторы упрощают чте- ние и написание кода. В современных высокоуровневых языках эта возмож - ность очень полезна. Беглый взгляд на отложенные вычисления Внимательно присмотревшись к обратной трассировке в примере 16.9, вы за- метите следы отложенного, или ленивого, вычисления генераторных выраже- ний. В примере 16.20 показана та же трассировка, но с выносками.552  Перегрузка операторов\n--- Страница 552 ---\nПример 16.20. Повторение примера 16.9 >>> v1 + 'ABC' Traceback (most recent call last): File \"<stdin>\", line 1, in <module> File \"vector_v6.py\", line 329, in __add__ return Vector(a + b for a, b in pairs)  File \"vector_v6.py\", line 243, in __init__ self._components = array(self.typecode, components)  File \"vector_v6.py\", line 329, in <genexpr> return Vector(a + b for a, b in pairs)  TypeError: unsupported operand type(s) for +: 'float' and 'str'  Конструктору Vector передается генераторное выражение в аргументе components . Пока никаких проблем.  Генераторное выражение components передается конструктору массива array. Внутри конструктора Python пытается обойти генераторное выражение, что приводит к вычислению первого элемента a + b. Именно в этот момент происходит исключение TypeError.  Исключение распространяется в вызов конструктора Vector, и там печата- ется сообщение о нем. Отсюда видно, что генераторное выражение вычисляется в последний мо- мент, а не там, где оно определено в исходном коде. С другой стороны, если бы конструктор Vector был вызван как Vector([a + b for a, b in pairs]) , то исключение произошло бы прямо здесь, поскольку спис- ковое включение попыталось бы построить список для передачи в качестве аргумента конструктору Vector(). До метода Vector.__init__ дело вообще не до- шло бы. Мы будем детально рассматривать генераторные выражения в главе 17, но я не хотел упустить случай продемонстрировать их ленивую природу. Дополнительная литература  553\n--- Страница 554 ---\nЧасть IV Поток управления",
      "debug": {
        "start_page": 527,
        "end_page": 554
      }
    },
    {
      "name": "Глава 17. Итераторы, генераторы и классические сопрограммы 556",
      "content": "--- Страница 555 --- (продолжение)\nГлава 17 Итераторы, генераторы и классические сопрограммы Видя в своих программах повторяющиеся структуры, я расцениваю их как знак беды. Форма программы должна отражать задачу, которую она при- звана решить, и только ее. Любые другие регулярности в коде означают, по крайней мере для меня, что я использую недостаточно выразительные абстракции – зачастую из-за того, что вручную расширяю макросы, кото- рые должен был бы написать. – Пол Грэхем, знаток Lisp и венчурный инвестор1 Итерирование – одна из важнейших операций обработки данных. А если про- сматривается набор данных, не помещающийся целиком в память, то нужен способ выполнять ее лениво, т. е. по одному элементу и по запросу. Именно это и делает Итератор. В этой главе мы покажем, что паттерн Итератор встроен в язык Python, поэтому реализовывать его вручную вам никогда не придется. Любая стандартная коллекция в Python является итерируемым объектом, т. е. предоставляет итератор, который используется для поддержки следую- щих операций: циклов for; списковых, словарных и множественных включений; распаковки операций присваивания; конструирования экземпляров коллекций. В этой главе рассматриваются следующие темы: как встроенная функция iter(…) используется интерпретатором для об- работки итерируемых объектов; как реализовать классический паттерн Итератор в Python; как можно заменить классический Итератор генераторной функцией или генераторным выражением; подробное построчное описание работы генераторной функции; использование генераторных функций общего назначения в стандарт - ной библиотеке; использование предложения yield from для комбинирования генераторов; почему генераторы и классические сопрограммы, несмотря на внеш- нюю схожесть, по существу сильно различаются и не должны использо- ваться совместно. 1 Из статьи в блоге «Revenge of the Nerds» (http://www.paulgraham.com/icad.html).\nГлава 17 Итераторы, генераторы и классические сопрограммы Видя в своих программах повторяющиеся структуры, я расцениваю их как знак беды. Форма программы должна отражать задачу, которую она при- звана решить, и только ее. Любые другие регулярности в коде означают, по крайней мере для меня, что я использую недостаточно выразительные абстракции – зачастую из-за того, что вручную расширяю макросы, кото- рые должен был бы написать. – Пол Грэхем, знаток Lisp и венчурный инвестор1 Итерирование – одна из важнейших операций обработки данных. А если про- сматривается набор данных, не помещающийся целиком в память, то нужен способ выполнять ее лениво, т. е. по одному элементу и по запросу. Именно это и делает Итератор. В этой главе мы покажем, что паттерн Итератор встроен в язык Python, поэтому реализовывать его вручную вам никогда не придется. Любая стандартная коллекция в Python является итерируемым объектом, т. е. предоставляет итератор, который используется для поддержки следую- щих операций: циклов for; списковых, словарных и множественных включений; распаковки операций присваивания; конструирования экземпляров коллекций. В этой главе рассматриваются следующие темы: как встроенная функция iter(…) используется интерпретатором для об- работки итерируемых объектов; как реализовать классический паттерн Итератор в Python; как можно заменить классический Итератор генераторной функцией или генераторным выражением; подробное построчное описание работы генераторной функции; использование генераторных функций общего назначения в стандарт - ной библиотеке; использование предложения yield from для комбинирования генераторов; почему генераторы и классические сопрограммы, несмотря на внеш- нюю схожесть, по существу сильно различаются и не должны использо- ваться совместно. 1 Из статьи в блоге «Revenge of the Nerds» (http://www.paulgraham.com/icad.html).\n--- Страница 556 ---\nчтО нОвОг О в этОй главе Раздел «Субгенераторы, содержащие yield from» разросся с одной до шести страниц. Теперь он включает простые эксперименты, демонстрирующие по- ведение генераторов с yield from , и пошаговую разработку примера – обхода древовидной структуры данных. В новых разделах объясняется применение аннотаций для типов Iterable, Iterator и Generator. Последний раздел этой главы «Классические сопрограммы» сжался до 9-страничного введения в тему, которая в первом издании занимала целую главу объемом 40 страниц. Я переработал эту главу и перенес ее в виде статьи на сопроводительный сайт (https://www.fluentpython.com/extra/classic-coroutines/), поскольку, с одной стороны, она была самой трудной для читателей, а с дру- гой – ее предмет стал менее актуальным, после того как в Python 3.5 появились платформенные сопрограммы, которые мы будем изучать в главе 21. Начнем с вопроса о том, как встроенная функция iter(…) делает последова- тельность итерируемой. пОСледОвательнОС ть СлОв Исследование итерируемых объектов мы начнем с реализации класса Sentence: его конструктору передается текстовая строка, после чего ее можно переби- рать слово за словом. В первой версии мы реализуем протокол последователь- ности, итерируемость будет достигнута за счет того, что все последовательно- сти – итерируемые объекты, но теперь мы точно узнаем, почему. В примере 17.1 приведен класс Sentence, который умеет извлекать из текста слово с заданным индексом. Пример 17.1. sentence.py: объект Sentence как последовательность слов import re import reprlib RE_WORD = re.compile(r'\\w+') class Sentence: def __init__(self, text): self.text = text self.words = RE_WORD.findall(text)  def __getitem__(self, index): return self.words[index]  def __len__(self):  return len(self.words) def __repr__(self): return 'Sentence(%s)' % reprlib.repr(self.text)   .findall возвращает список всех непересекающихся подстрок, соответствую- щих регулярному выражению.  self.words содержит результат .findall, поэтому мы просто возвращаем слово с заданным индексом. Последовательность слов  557\n--- Страница 557 ---\n Чтобы выполнить требования протокола последовательности, мы реализу - ем метод __len__, но для получения итерируемого объекта он не нужен.  Служебная функция reprlib.repr генерирует сокращенные строковые пред- ставления структур данных, которые могут быть очень велики1. По умолчанию reprlib.repr ограничивает сгенерированную строку 30 симво- лами. В примере 17.2 показано, как используется класс Sentence. Пример 17.2. Итерирование объекта Sentence >>> s = Sentence('\"The time has come,\" the Walrus said,')  >>> s Sentence('\"The time ha Walrus said,')  >>> for word in s:  print(word) The time has come the Walrus said >>> list(s)  ['The', 'time', 'has', 'come', 'the', 'Walrus', 'said']  По строке создается предложение – объект класса Sentence.  Обратите внимание на результат __repr__ – строку, содержащую многото- чие, которая была сгенерирована функцией reprlib.repr .  Объекты Sentence являются итерируемыми, скоро мы в этом убедимся.  Будучи итерируемыми, объекты Sentence могут быть использованы для кон- струирования списков и других итерируемых типов. Далее мы разработаем другие классы Sentence, которые будут успешно прохо- дить тесты из примера 17.2. Но реализация из примера 17.1 отличается от всех остальных тем, что является также последовательностью, а значит, допускает доступ к слову по индексу. >>> s[0] 'The' >>> s[5] 'Walrus' >>> s[-1] 'said' Любой программирующий на Python знает, что последовательности – ите- рируемые объекты. Разберемся, почему это так. пОчему пОСледОвательнОС ти итерируемы : функция iter Всякий раз как интерпретатору нужно обойти объект x, он автоматически вы- зывает функцию iter(x). 1 Впервые мы встретились с ней в разделе «Vector, попытка № 1: совместимость с Vector2d» главы 12.558  Итераторы, генераторы и классические сопрограммы\n--- Страница 558 ---\nВстроенная функция iter выполняет следующие действия. 1. Смотрит, реализует ли объект метод __iter__, и, если да, вызывает его, чтобы получить итератор. 2. Если метод __iter__ не реализован, но реализован метод __getitem__ , то Python создает итератор, который пытается извлекать элементы по по- рядку, начиная с индекса 0. 3. Если и это не получается, то возбуждается исключение – обычно с со- общением 'C' object is not iterable , где C – класс объекта. Именно поэтому любая последовательность в Python является итерируемой: все они реализуют метод __getitem__ . На самом деле стандартные последователь- ности реализуют и метод __iter__, и ваши должны поступать так же, поскольку специальная обработка метода __getitem__ оставлена только ради обратной со- вместимости и может быть исключена в будущем – хотя она не объявлена не- рекомендуемой в Python 3.10 и сомнительно, что будет когда-нибудь удалена. В разделе «Python в поисках следов последовательностей» главы 13 отме- чалось, что это крайняя форма утиной типизации: объект считается итери- руемым не только, когда он реализует специальный метод __iter__, но и когда реализует метод __getitem__ . Взгляните: >>> class Spam: def __getitem__(self, i): print('->', i) raise IndexError() >>> spam_can = Spam() >>> iter(spam_can) <iterator object at 0x10a878f70> >>> list(spam_can) -> 0 [] >>> from collections import abc >>> isinstance(spam_can, abc.Iterable) False Если класс предоставляет метод __getitem__ , то встроенная функция iter() принимает экземпляр этого класса в качестве итерируемого объекта и строит по нему итератор. Механизм итерирования Python будет вызывать __getitem__ с индексами, начинающимися с 0, и воспринимать исключение IndexError как сигнал о том, что элементы кончились. Заметим, что хотя spam_can – итерируемый объект (его метод __getitem__ мог бы поставлять элементы), он не распознается как таковой функцией isinstance , когда она сравнивает его с abc.Iterable . Если подходить с точки зрения гусиной типизации, то определение итериру - емого объекта становится более простым, но не таким гибким: объект считает - ся итерируемым, если реализует метод __iter__. Не требуется ни наследования, ни регистрации, потому что класс abc.Iterable реализует метод __subclasshook__ (см. раздел «ABC и структурная типизация» главы 13). Продемонстрируем это: >>> class GooseSpam: def __iter__(self): pass Почему последовательности итерируемы: функция iter  559\n--- Страница 559 ---\n>>> from collections import abc >>> issubclass(GooseSpam, abc.Iterable) True >>> goose_spam_can = GooseSpam() >>> isinstance(goose_spam_can, abc.Iterable) True В версии Python 3.10 самый точный способ проверить, является ли объект x итерируемым, – вызвать iter(x) и перехватить ис- ключение TypeError , если оно возникнет. Это надежнее, чем ис- пользовать isinstance(x, abc.Iterable) , потому что iter(x) учи- тывает также доставшийся в наследство метод __getitem__ , а ABC Iterable этого не делает. Явно проверять, является ли объект итерируемым, вряд ли стоит, если сразу после проверки вы намереваетесь обойти объект. Ведь если попытаться обой- ти неитерируемый объект, Python возбудит исключение с недвусмысленным сообщением: TypeError: 'C' object is not iterable . Если вы можете сделать что-то более разумное, чем возбуждать TypeError, делайте это в блоке try/except , а не пу- тем явной проверки. Явная проверка, возможно, имеет смысл, если вы хотите сохранить объект и воспользоваться им для итерирования позже; в таком слу- чае раннее обнаружение ошибки упрощает отладку. Встроенная функция iter() чаще вызывается самим интерпретатором Python, чем вашим кодом. Есть другой, не столь хорошо известный способ ее использования. Использование iter в сочетании с Callable Мы можем вызвать iter() с двумя аргументами, чтобы создать итератор из функции или вообще любого вызываемого объекта. В таком случае первый ар- гумент должен быть вызываемым объектом, который будет вызываться мно- гократно (без аргументов) для порождения значений, а второй – специальным маркером ( https://en.wikipedia.org/wiki/Sentinel_value): если вызываемый объект возвращает такое значение, то итератор не отдает его вызывающей стороне, а возбуждает исключение StopIteration . В примере ниже показано, как можно использовать iter для бросания шести- гранной кости до тех пор, пока не выпадет 1: >>> def d6(): return randint(1, 6) >>> d6_iter = iter(d6, 1) >>> d6_iter <callable_iterator object at 0x10a245270> >>> for roll in d6_iter: print(roll) 4 3 6 3 560  Итераторы, генераторы и классические сопрограммы\n--- Страница 560 ---\nЗаметим, что функция iter в этом примере возвращает callable_iterator . Цикл for может работать очень долго, но никогда не выведет 1, потому что это значе- ние является специальным маркером. Как всегда бывает с итераторами, объ- ект d6_iter после исчерпания становится бесполезным. Чтобы начать с начала, мы должны создать новый итератор, снова вызвав iter(). В документации по iter (https://docs.python.org/3.10/library/functions.html#iter) имеется следующее объяснение и пример: Вторую форму iter() можно с пользой применить для построения читателя блоков. Например, вот как можно читать блоки фиксированной длины из двоичного файла базы данных, до тех пор пока не будет достигнут конец файла: from functools import partial with open('mydata.db', 'rb') as f: read64 = partial(f.read, 64) for block in iter(read64, b''): process_block(block) Для ясности я добавил присваивание переменной read64, которого нет в ори- гинале (https://docs.python.org/3.10/library/functions.html#iter). Функция partial() необходима, потому что вызываемый объект, переданный iter(), не должен иметь аргументов. В примере специальным маркером является пустой объект bytes, потому что именно его возвращает f.read, когда больше нечего читать. В следующем разделе мы проясним связь между итерируемыми объектами и итераторами. итерируемые ОБъекты и итерат Оры Из объяснения в разделе «Почему последовательности итерируемы: функция iter» можно вывести такое определение: Итерируемый объект Любой объект, от которого встроенная функция iter может получить ите- ратор. Объекты, которые реализуют метод __iter__, возвращающий итера- тор, являются итерируемыми. Последовательности всегда итерируемы, поскольку это объекты, реализующие метод __getitem__ , который принимает индексы, начинающиеся с нуля. Важно четко понимать связь между итерируемыми объектами и итератора- ми: Python получает итераторы от итерируемых объектов. Ниже приведен простой цикл for для обхода строки str. Строка 'ABC' здесь является итерируемым объектом. Мы этого не видим, но за кулисами прячется итератор: >>> s = 'ABC' >>> for char in s: print(char) ABC Если бы не было предложения for и мы должны были бы эмулировать механизм работы for вручную с помощью цикла while, то пришлось бы написать такой код: Итерируемые объекты и итераторы  561\n--- Страница 561 ---\n>>> s = 'ABC' >>> it = iter(s)  >>> while True: try: print(next(it))  except StopIteration:  del it  break  A B C  Получить итератор it от итерируемого объекта.  В цикле вызвать метод next итератора, чтобы получить следующий элемент.  Итератор возбуждает исключение StopIteration , когда элементы кончаются.  Освободить ссылку на it – объект итератора уничтожается.  Выйти из цикла. Исключение StopIteration сигнализирует об исчерпании итератора. В циклах for и в других контекстах итерирования, например в списковом включении, при распаковке итерируемых объектов и т. д., оно обрабатывается встроенной функцией iter(). В стандартном интерфейсе итератора есть два метода: __next__ Возвращает следующий доступный элемент и возбуждает исключение StopIteration , когда элементов не осталось. __iter__ Возвращает self; это позволяет использовать итератор там, где ожидается итерируемый объект, например в цикле for. Этот интерфейс формализован в абстрактном базовом классе collections.abc. Iterator, где определен абстрактный метод __next__, и в его подклассе Iterable, где определен абстрактный метод __iter__ (см. рис. 17.1). Рис. 17.1. Абстрактные классы Iterable и Iterator . Курсивом набраны имена абстрактных методов. Конкретный метод Iterable.iter должен возвращать новый экземпляр Iterator . Конкретный Iterator должен реализовывать метод next. Метод Iterator.iter просто возвра- щает ссылку на себя562  Итераторы, генераторы и классические сопрограммы\n--- Страница 562 ---\nИсходный код класса collections.abc.Iterator приведен в примере 17.3. Пример 17.3. Класс abc.Iterator ; код взят из файла Lib/_collections_abc.py ( https://github.com/ python/cpython/blob/b1930bf75f276cd7ca08c4455298128d89adf7d1/Lib/_collections_abc.py#L271) class Iterator(Iterable): __slots__ = () @abstractmethod def __next__(self): 'Return the next item from the iterator. When exhausted, raise StopIteration' raise StopIteration def __iter__(self): return self @classmethod def __subclasshook__(cls, C):  if cls is Iterator: return _check_methods(C, '__iter__', '__next__')  return NotImplemented  __subclasshook__ поддерживает структурные проверки типов с помощью функций isinstance и issubclass . Мы видели это в разделе «ABC и структурная типизация» главы 13.  Метод _check_methods обходит __mro__ класса и проверяет, реализованы ли указанные методы в его базовых классах. Он определен в том же моду - ле Lib/_collections_abc.py. Если методы реализованы, то класс C будет рас- познан как виртуальный подкласс Iterator. Иными словами, issubclass(C, Iterable) вернет True. В Python 3 абстрактный метод класса Iterator называется it.__next__() , а в Python 2 – it.next() . Как обычно, не следует вызывать специальные методы напрямую. Просто пользуйтесь встроенной функцией next(it): она сделает все правильно – и в Python 2, и в Python 3. В исходном файле Lib/types.py ( https://hg.python.org/cpython/file/3.4/Lib/types.py) для версии Python 3.9 есть такой комментарий: # Итераторы в Python следует считать не типом, а протоколом. Многие # встроенные типы (их число постоянно изменяется) реализуют *какой-то* # вид итератора. Не проверяйте его тип! Используйте вместо этого # функцию hasattr для проверки наличия атрибутов «__iter__» и «__next__». На самом деле именно это и делает метод __subclasshook__ абстрактного клас - са abc.Iterator . Принимая во внимание рекомендацию из файла Lib/types.py и ло- гику, реализованную в файле Lib/_collections_abc.py, согласимся, что лучший способ узнать, является ли объект x итератором, – вызвать функцию isinstance(x, abc.Iterator) . Благодаря методу Iterator.__ subclasshook__ эта проверка работает даже тогда, когда класс x не яв- ляется ни настоящим, ни виртуальным подклассом Iterator. Итерируемые объекты и итераторы  563\n--- Страница 563 ---\nВозвращаясь к классу Sentence из примера 17.1, мы можем в интерактивной оболочке посмотреть, как итератор строится функцией iter(…) и производит обход с помощью next(…): >>> s3 = Sentence('Life of Brian')  >>> it = iter(s3)  >>> it # doctest: +ELLIPSIS <iterator object at 0x > >>> next(it)  'Life' >>> next(it) 'of' >>> next(it) 'Brian' >>> next(it)  Traceback (most recent call last): StopIteration >>> list(it)  [] >>> list(iter(s3))  ['Life', 'of', 'Brian']  Создать предложение s3, содержащее три слова.  Получить от s3 итератор.  next(it) возвращает следующее слово.  Больше слов нет, поэтому итератор возбуждает исключение StopIteration .  После исчерпания итератор бесполезен.  Чтобы еще раз обойти предложение, нужно создать новый итератор. Поскольку от итератора требуются только методы __next__ и __iter__, не сущест - вует другого способа узнать, остались ли еще элементы, как только вызвать next() и перехватить исключение StopInteration . И «сбросить» итератор тоже невозмож - но. Чтобы начать обход сначала, нужно вызвать функцию iter() для итерируемого объекта и получить от нее новый итератор. Вызов iter() для самого итератора не поможет, поскольку, как уже упоминалось, метод Iterator.__iter__ возвращает self, так что таким способом исчерпанный итератор не восстановить. Этот минимальный интерфейс разумен, потому что на практике не все ите- раторы допускают сброс. Например, если итератор читает пакеты из сети, то перемотать его в начало невозможно1. Первая версия класса Sentence из примера 17.1 была итерируемой вслед- ствие специальной обработки последовательностей встроенной функцией iter(). Теперь мы напишем вариант Sentence, который реализует метод __iter__ для возврата итераторов. клаССы sentence С метОдОм __iter__ Последующие варианты Sentence реализуют стандартный протокол итерируе- мого объекта, сначала путем реализации паттерна проектирования Итератор, а затем с помощью генераторных функций. 1 Спасибо Леонардо Рохаэлю за этот красивый пример.564  Итераторы, генераторы и классические сопрограммы\n--- Страница 564 ---\nКласс Sentence, попытка № 2: классический итератор Следующая версия класса Sentence строится согласно классическому паттерну проектирования Итератор, который описан в книге «Банды четырех». Отме- тим, что это не идиоматический код на Python, что станет предельно понятно, когда мы займемся его рефакторингом. Но он проясняет связь между итериру - емой коллекцией и объектом-итератором. Показанная в примере 17.4 реализация класса Sentence является итерируе- мой, потому что реализует специальный метод __iter__, который конструирует и возвращает объект SentenceIterator . Именно так работает паттерн проектиро- вания Итератор, описанный в книге «Паттерны проектирования». Пример 17.4. sentence_iter.py: класс Sentence, реализованный с помощью паттерна Итератор import re import reprlib RE_WORD = re.compile(r'\\w+') class Sentence: def __init__(self, text): self.text = text self.words = RE_WORD.findall(text) def __repr__(self): return f'Sentence({reprlib.repr(self.text)})' def __iter__(self):  return SentenceIterator(self.words)  class SentenceIterator: def __init__(self, words): self.words = words  self.index = 0  def __next__(self): try: word = self.words[self.index]  except IndexError: raise StopIteration()  self.index += 1  return word  def __iter__(self):  return self  Метод __iter__ – единственное дополнение к предыдущей реализации Sentence. В этой версии нет метода __getitem__ , тем самым мы хотим доказать, что класс является итерируемым, потому что реализует __iter__.  __iter__ выполняет требования протокола итерируемого объекта – создает и возвращает итератор. Классы Sentence с методом __iter__  565\n--- Страница 565 ---\n SentenceIterator хранит ссылку на список слов.  self.index используется для определения следующего слова.  Получить слово с индексом self.index .  Если слова с индексом self.index не существует, возбудить исключение StopIteration .  Увеличить self.index .  Вернуть слово.  Реализовать метод self.__iter__ . Код из примера 17.4 проходит тесты из примера 17.2. Отметим, что этот пример работал бы и без реализации метода __iter__ в классе SentenceIterator , но лучше все делать правильно: предполагается, что итератор реализует оба метода, __next__ и __iter__, и если мы так сделаем, то наш итератор пройдет проверку issubclass(SentenceInterator, abc.Iterator) . Если бы мы унаследовали SentenceIterator от abc.Iterator , то получили бы и конкретный метод abc.Iterator.__iter__ . Что-то многовато работы (по крайней мере, для нас, испорченных програм- мистов на Python). Обратите внимание, что большая часть кода SentenceIterator занимается управлением внутренним состоянием итератора. Вскоре мы уви- дим, как сократить эту часть. Но сначала небольшое отступление, в котором мы опишем один соблазнительный способ срезать угол, который на самом деле никуда не годится. Не делайте итерируемый объект итератором для самого себя Типичный источник ошибок при создании итерируемых объектов и итерато- ров – путаница понятий. Поясним: у итерируемого объекта есть метод __iter__, который при каждом обращении создает новый итератор. Итератор реализует метод __next__, который возвращает элементы один за другим, и метод __iter__, который возвращает self. Следовательно, итератор является итерируемым объектом, но итерируемый объект не является итератором. Возникает соблазн реализовать в классе Sentence метод __next__ в дополнение к __iter__ и тем самым сделать экземпляр Sentence одновременно итерируемым объектом и итератором над самим собой. Но это редко бывает удачной иде- ей. Типичный антипаттерн, по словам Алекса Мартелли, у которого огромный опыт рецензирования кода на Python в Google. В разделе «Применимость» главы о паттерне Итератор в книге «Банды че- тырех» написано: Используйте паттерн Итератор: для доступа к содержимому агрегированных объектов без раскрытия их внутреннего представления; для поддержки нескольких активных обходов одного и того же агрегиро- ванного объекта; для предоставления единообразного интерфейса с целью обхода различных агрегированных структур (то есть для поддержки полиморфной итерации). Чтобы «поддержать несколько активных обходов», необходимо иметь воз- можность получить несколько независимых итераторов от одного итерируе-566  Итераторы, генераторы и классические сопрограммы\n--- Страница 566 ---\nмого объекта, причем каждый итератор должен хранить собственное внутрен- нее состояние, поэтому для правильной реализации паттерна нужно всякий раз обращаться к функции iter(my_iterable) за новым независимым итерато- ром. Вот почему нам был необходим класс SentenceIterator . Теперь, продемонстрировав реализацию классического паттерна Итератор, мы можем отложить ее в сторонку. В Python включено ключевое слово yield из созданного Барбарой Лисков языка CLU, поэтому нам не нужно «вручную гене- рировать» код для реализации итераторов. В следующем разделе представлена идиоматическая реализация класса Sentence. Класс Sentence, попытка № 3: генераторная функция Реализация той же функциональности в духе Python основана на использо- вании генераторной функции для замены класса SequenceIterator . Объяснение приведено после примера 17.5. Пример 17.5. sentence_gen.py: реализация класса Sentence с помощью генератора import re import reprlib RE_WORD = re.compile(r'\\w+') class Sentence: def __init__(self, text): self.text = text self.words = RE_WORD.findall(text) def __repr__(self): return 'Sentence(%s)' % reprlib.repr(self.text) def __iter__(self): for word in self.words:  yield word   # это всё!   Обойти self.words .  Отдать текущее слово.  Явный return не нужен; функция может просто «провалиться» и вернет управ- ление автоматически. В любом случае генераторная функция не возбуждает исключения StopIteration : когда значений не остается, она просто выходит1.  Нет нужды в отдельном классе итератора! 1 Рецензируя этот код, Алекс Мартелли отметил, что тело этого метода можно было бы свести просто к return iter(self.words) . Он прав: результатом вызова __iter__ и в этом случае был бы итератор, как и положено. Но я воспользовался здесь циклом for с ключевым словом yield, чтобы ввести синтаксис функции-генератора, который бу- дет подробно рассмотрен в следующем разделе. В процессе рецензирования второго издания Леонардо Рохаэль предложил еще одну краткую форму тела __iter__: yield from self.words . Мы рассмотрим конструкцию yield from ниже в этой главе. Классы Sentence с методом __iter__  567\n--- Страница 567 ---\nВот и еще одна реализация Sentence, которая проходит все тесты из примера 17.2. В классе Sentence в примере 17.4 метод __iter__ конструировал и возвращал объект SentenceIterator . В примере же 17.5 итератор фактически является объ- ектом-генератором, который строится автоматически при вызове метода __iter__, потому что __iter__ здесь – генераторная функция. Подробное объяснение генераторов приведено ниже. Как работает генератор Любая функция в Python, в теле которой встречается ключевое слово yield, на- зывается генераторной функцией – при вызове она возвращает объект-гене- ратор. Иными словами, генераторная функция – это фабрика генераторов. Единственное синтаксическое различие между простой и гене- раторной функцией – тот факт, что в теле последней встречается ключевое слово yield. Некоторые считают, что для генераторных функций следовало бы ввести новое ключевое слово gen вместо def, но Гвидо не согласен. Его аргументы приведены в документе «PEP 255 – Simple Generators» (https://www.python.org/dev/peps/pep- 0255/)1. В примере 17.6 демонстрируется поведение генераторной функции2. Пример 17.6. Генераторная функция, отдающая три числа >>> def gen_123(): yield 1  yield 2 yield 3 >>> gen_123 # doctest: +ELLIPSIS <function gen_123 at 0x >  >>> gen_123() # doctest: +ELLIPSIS <generator object gen_123 at 0x >  >>> for i in gen_123():  print(i) 1 2 3 >>> g = gen_123()  >>> next(g)  1 >>> next(g) 2 >>> next(g) 3 >>> next(g)  Traceback (most recent call last): StopIteration 1 Иногда я включаю префикс или суффикс gen в имя генераторной функции, но это не общеупотребительная практика. И разумеется, нельзя этого делать при реализа- ции итерируемого объекта: обязательный специальный метод должен называться __iter__ – и никак иначе. 2 Спасибо за пример Дэвиду Квасту. 568  Итераторы, генераторы и классические сопрограммы\n--- Страница 568 ---\n В теле генераторной функции yield часто встречается в цикле, но это не- обязательно; здесь я просто трижды повторил yield.  Приглядевшись, мы увидим, что gen_123 – объект-функция.  Но при вызове gen_123() возвращает объект-генератор.  Объекты-генераторы реализуют интерфейс Iterator, поэтому являются так- же итерируемыми объектами.  Присваиваем новый объект-генератор переменной g, чтобы с ним можно было экспериментировать.  Поскольку g – итератор, вызов next(g) возвращает следующий элемент, по- рожденный yield.  Когда генераторная функция возвращает управление, объект-генератор возбуждает исключение StopIteration . Генераторная функция строит объект-генератор, обертывающий тело функ - ции. При передаче объекта-генератора функции next() выполнение продол- жается до следующего предложения yield в теле функции, а вызов next() воз- вращает значение, порожденное перед приостановкой выполнения функции. Наконец, при возврате из функции обертывающий ее объект-генератор воз- буждает исключение StopIteration в полном соответствии с протоколом Iterator. Я считаю, что в терминологии, касающейся получения резуль- татов от генератора, лучше соблюдать строгость. Фраза же «ге- нератор возвращает значения» вносит путаницу. Значения воз- вращают функции. Вызов генераторной функции возвращает ге- нератор. Генератор отдает значения. Генератор не «возвращает» значение в обычном смысле слова: предложение return в теле генераторной функции приводит к тому, что объект-генератор возбуждает исключение StopIteration . Если написать return x в генераторе, то вызывающая сторона сможет получить значение x из исключения StopIteration , но обычно это делается автома- тически с помощью синтаксиса yield from , как будет показано в разделе «Возврат значения из сопрограммы». В примере 17.7 во всех подробностях описано взаимодействие между цик- лом for и телом функции. Пример 17.7. Генераторная функция, печатающая сообщения во время выполнения >>> def gen_AB(): print('start') yield 'A'  print('continue') yield 'B'  print('end.')  >>> for c in gen_AB():  print('-->', c)  start  --> A  continue  --> B  end.  >>> ⓫ Классы Sentence с методом __iter__  569\n--- Страница 569 ---\n Первый неявный вызов next() в цикле for в точке  приводит к печати 'start' и приостановке на первом yield, порождающем значение 'A'.  Второй неявный вызов next() в цикле for приводит к печати 'continue' и при- остановке на втором yield, порождающем значение 'B'.  Третий вызов next() приводит к печати 'end' и возврату из функции, в ре- зультате чего объект-генератор возбуждает исключение StopIteration .  Для итерирования цикл for выполняет эквивалент предложения g = iter(gen_ AB()), чтобы получить объект-генератор, а затем на каждой итерации вы- зывает next(g).  В теле цикла печатается --> и значение, полученное от next(g). Но результат этой печати мы увидим только после строки, напечатанной функцией print внутри генераторной функции.  Строка 'start' появляется в результате работы функции print('start') в теле генераторной функции.  Предложение yield 'A' в теле генераторной функции отдает значение A, по- требляемое в цикле for, где оно присваивается переменной c и распечаты- вается в виде --> A.  Итерирование продолжается благодаря второму вызову next(g), продвигающе- му выполнение генераторной функции от yield 'A' к yield 'B'. Выводится стро- ка continue – результат второго обращения к print в теле генераторной функции.  Предложение yield 'B' отдает значение B, потребляемое в цикле for, где оно присваивается переменной c и распечатывается в виде --> B.  Итерирование продолжается благодаря третьему вызову next(g), продви- гающему выполнение в конец генераторной функции. Выводится строка end – результат третьего обращения к print в теле генераторной функции. ⓫ Когда генераторная функция доходит до конца, объект-генератор воз- буждает исключение StopIteration . Цикл for перехватывает это исключение и нормально завершается. Надеюсь, теперь понятно, как работает метод Sentence.__iter__ в примере 14.5: __iter__ – генераторная функция, которая конструирует объект-генератор, реа- лизующий интерфейс Iterator, поэтому класс SentenceIterator больше не нужен. Вторая версия Sentence получилась гораздо короче первой, но и она не такая ленивая, какой могла бы быть. В наши дни лень считается хорошим свойством, по крайней мере в языках программирования и API. Ленивая реализация от- кладывает порождение значений до последней возможности. Это экономит память и иногда позволяет избежать бесполезной работы. Далее мы напишем ленивый класс Sentence. ленивые клаССы sentence Последние варианты класса Sentence будут ленивыми, на основе ленивой функ - ции из модуля re. Класс Sentence, попытка № 4: ленивый генератор Интерфейс Iterator спроектирован ленивым: вызов next(my_iterator) порождает по одному элементу за раз. Противоположностью ленивому вычислению яв-570  Итераторы, генераторы и классические сопрограммы\n--- Страница 570 ---\nляется энергичное (eager) – оба термина применяются в теории языков про- граммирования. До сих пор наши реализации Sentence не были ленивыми, потому что __init__ энергично строит список всех слов в тексте и связывает его с атрибутом self. words. Это влечет за собой обработку всего текста, а список может занять столько же памяти, сколько сам текст (возможно, больше – это зависит от того, сколько в тексте символов, не считающихся частью слова). И большая часть этой рабо- ты будет проделана напрасно, если пользователю нужны только первые два слова. Если у вас возникает вопрос «Существует ли ленивый способ сделать это?», ответ чаще всего будет «да». Функция re.finditer – ленивая версия re.findall, вместо списка она возвращает генератор, порождающий объекты re.MatchObject по запросу. Если соответствий много, то re.finditer заметно экономит память. С ее помощью мы напишем тре- тий – ленивый – вариант класса Sentence: он читает следующее слово из текста только тогда, когда это необходимо. Пример 17.8. sentence_gen2.py: реализация класса Sentence с помощью генераторной функции, которая вызывает генераторную функцию re.finditer import re import reprlib RE_WORD = re.compile(r'\\w+') class Sentence: def __init__(self, text): self.text = text  def __repr__(self): return f'Sentence({reprlib.repr(self.text)})' def __iter__(self): for match in RE_WORD.finditer(self.text):  yield match.group()   Хранить список слов не нужно.  finditer строит итератор, который обходит все соответствия текста self.text регулярному выражению RE_WORD, порождая объекты MatchObject .  match.group() извлекает сопоставленный текст из объекта MatchObject . Генераторы – замечательный способ сократить код, но генераторные выра- жения еще круче. Класс Sentence, попытка № 5: генераторное выражение Простые генераторные функции наподобие той, что использована в преды- дущем варианте класса Sentence (пример 17.8), можно заменить генераторным выражением. Как списковое включение строит списки, так генераторное вы- ражение строит объекты-генераторы. В примере 17.9 продемонстрировано их поведение. Ленивые классы Sentence  571\n--- Страница 571 ---\nПример 17.9. Генераторная функция gen_AB используется сначала в списковом включе- нии, а затем в генераторном выражении >>> def gen_AB():  print('start') yield 'A' print('continue') yield 'B' print('end.') >>> res1 = [x*3 for x in gen_AB()]  start continue end. >>> for i in res1:  print('-->', i) --> AAA --> BBB >>> res2 = (x*3 for x in gen_AB())  >>> res2 <generator object <genexpr> at 0x10063c240> >>> for i in res2:  print('-->', i) start  --> AAA continue --> BBB end.  Та же генераторная функция gen_AB, что в примере 17.7.  Списковое включение энергично обходит элементы, порождаемые объек - том-генератором, который был создан функцией gen_AB: 'A' и 'B'. Обратите внимание на печать строк start, continue, end.  В этом цикле for мы обходим список res1, порожденный списковым вклю- чением.  Генераторное выражение возвращает res2, объект-генератор. Генератор здесь не потребляется.  Только в цикле for, где производится обход res2, этот генератор получает элементы от gen_AB. На каждой итерации цикла неявно вызывается функция next(res2) , которая, в свою очередь, вызывает метод next() объекта-генерато- ра, возвращенного gen_AB, продвигая генератор до следующего yield.  Обратите внимание на то, как строки, напечатанные внутри gen_AB, череду - ются с теми, что печатаются в самом цикле. Таким образом, мы можем воспользоваться генераторным выражением, чтобы еще сократить размер класса Sentence. См. пример 17.10. Пример 17.10. sentence_genexp.py: реализация класса Sentence с помощью генератор- ного выражения import re import reprlib572  Итераторы, генераторы и классические сопрограммы\n--- Страница 572 ---\nRE_WORD = re.compile(r'\\w+') class Sentence: def __init__(self, text): self.text = text def __repr__(self): return f'Sentence({reprlib.repr(self.text)})' def __iter__(self): return (match.group() for match in RE_WORD.finditer(self.text)) От примера 17.8 отличается только метод __iter__, который здесь не является генераторной функцией (в нем нет слова yield), а использует генераторное вы- ражение для построения генератора, который потом и возвращает. Конечный результат не меняется: код, вызывающий __iter__, получает объект-генератор. Генераторные выражения – не более чем синтаксический сахар: их всегда можно заменить генераторными функциями, но иногда выражения удобнее. Следующий раздел посвящен использованию генераторных выражений. генерат Орные выражения : кОгда иСпО льзОвать В реализации класса Vector из примера 12.16 я несколько раз пользовался ге- нераторными выражениями. В каждом из методов __eq__, __hash__, __abs__, angle, angles, format, __add__, __mul__ встречается генераторное выражение. Во всех них можно было бы обойтись и списковым включением, но ценой расхода памяти на хранение промежуточных списков. В примере 17.10 мы видели, что генераторное выражение – синтаксически более короткий способ создать генератор, не определяя и не вызывая функцию. С другой стороны, генераторные функции обладают большей гибкостью: в них можно зако- дировать сложную логику, включающую несколько предложений, и даже исполь- зовать их в качестве сопрограмм (см. раздел «Классические сопрограммы»). В простых случаях генераторное выражение легче воспринимается на взгляд, как показывает пример класса Vector. Я придерживаюсь такого эвристического правила: если генераторное выра- жение занимает больше двух строк, я предпочитаю генераторную функцию – код получается понятнее. Синтаксический совет Когда генераторное выражение передается в качестве един- ственного аргумента функции или конструктору, нет необходи- мости указывать одну пару скобок для вызова функции и дру - гую для обрамления генераторного выражения. Хватит и одной пары, как в вызове конструктора Vector из метода __mul__ в при- мере 12.16 (воспроизведен ниже): def __mul__(self, scalar): if isinstance(scalar, numbers.Real): return Vector(n * scalar for n in self) else: return NotImplemented Генераторные выражения: когда использовать  573\n--- Страница 573 ---\nОднако если после генераторного выражения есть еще аргумен- ты, то его необходимо заключить в скобки, иначе возникнет ис- ключение SyntaxError . В примерах класса Sentence мы видели, как генераторы играют роль классиче- ского паттерна Итератор: получают элементы из коллекции. Но их можно ис- пользовать также для порождения значений безо всякого источника данных. В следующем разделе приведен пример. Но сначала будет уместно краткое обсуждение в чем-то пересекающихся понятий итератора и генератора. Сравнение итераторов и генераторов В официальной документации и кодовой базе Python терминология, относя- щаяся к итераторам и генераторам, противоречива и постоянно изменяется. Я принял для себя следующие определения: итератор Общий термин, обозначающий любой объект, который реализует метод __next__. Итераторы предназначены для порождения данных, потребля- емых клиентским кодом, т. е. кодом, который управляет итератором по- средством цикла for или другой итеративной конструкции либо путем явного вызова функции next(it) для итератора – хотя такое явное исполь- зование встречается гораздо реже. На практике большинство итераторов, встречающихся в Python, являются генераторами. генератор Итератор, построенный компилятором Python. Для создания генерато- ра мы не реализуем метод __next__. Вместо этого используется ключевое слово yield, в результате чего получается генераторная функция, т. е. фаб- рика объектов-генераторов. Генераторное выражение – еще один способ построить объект-генератор. Объекты-генераторы предоставляют метод __next__, т. е. являются генераторами. Начиная с версии Python 3.5 в язык включены также асинхронные генераторы, объявляемые с помощью кон- струкции async def . Мы будем изучать их в главе 21. В глоссарии Python недавно появился термин генераторный итератор (https:// docs.python.org/3/glossary.html#term-generator-iterator), так называют объекты, по- строенные генераторными функциями, тогда как в статье о генераторных выражениях (https://docs.python.org/3/glossary.html#term-generator-expression) го- ворится, что они возвращают «итератор». Но в обоих случаях, если верить Python, возвращаются объекты-генераторы: >>> def g(): yield 0 >>> g() <generator object g at 0x10e6fb290> >>> ge = (c for c in 'XYZ') >>> ge <generator object <genexpr> at 0x10e936ce0> >>> type(g()), type(ge) (<class 'generator'>, <class 'generator'>)574  Итераторы, генераторы и классические сопрограммы\n--- Страница 574 ---\nгенерат Ор арифметичеСк Ой прОгреССии Классический паттерн Итератор относится к обходу некоторой структуры дан- ных. Но стандартный интерфейс, основанный на методе извлечения следующего элемента ряда, полезен и тогда, когда элементы порождаются «на лету», а не вы- бираются из коллекции. Например, встроенная функция range генерирует ограни- ченную арифметическую прогрессию целых чисел. А что, если нужно сгенериро- вать арифметическую прогрессию чисел произвольного типа, а не только целых? В примере 17.11 показано несколько тестов класса ArithmeticProgression , кото - рый мы вскоре напишем. Конструктор имеет сигнатуру ArithmeticProgression(begin, step[, end]) . Полная сигнатура функции range() имеет вид range(start, stop[, step]). Я выбрал другую сигнатуру, потому что для арифметической прогрес - сии шаг step обязателен, а конечное значение end – нет. Кроме того, я заменил имена аргументов start/stop на begin/end, дав понять, что сигнатура поменялась. Во всех тестах в примере 17.11 я вызываю конструктор list() для просмотра сгенерированных значений. Пример 17.11. Демонстрация класса ArithmeticProgression >>> ap = ArithmeticProgression(0, 1, 3) >>> list(ap) [0, 1, 2] >>> ap = ArithmeticProgression(1, .5, 3) >>> list(ap) [1.0, 1.5, 2.0, 2.5] >>> ap = ArithmeticProgression(0, 1/3, 1) >>> list(ap) [0.0, 0.3333333333333333, 0.6666666666666666] >>> from fractions import Fraction >>> ap = ArithmeticProgression(0, Fraction(1, 3), 1) >>> list(ap) [Fraction(0, 1), Fraction(1, 3), Fraction(2, 3)] >>> from decimal import Decimal >>> ap = ArithmeticProgression(0, Decimal('.1'), .3) >>> list(ap) [Decimal('0'), Decimal('0.1'), Decimal('0.2')] Отметим, что числа в получающейся арифметической прогрессии имеют тот же тип, что begin + step, – согласно общим правилам приведения числовых типов в Python. В примере 17.11 мы видим список чисел типа int, float, Fraction и Decimal. В примере 17.12 показана реализация класса ArithmeticProgression . Пример 17.12. Класс ArithmeticProgression class ArithmeticProgression: def __init__(self, begin, step, end=None):  self .begin = begin self .step = step self .end = end # None -> \"бесконечный\" ряд def __iter__(self): result_type = type(self .begin + self .step)  Генератор арифметической прогрессии  575\n--- Страница 575 ---\nresult = result_type(self.begin)  forever = self.end is None  index = 0 while forever or result < self.end:  yield result  index += 1 result = self.begin + self.step * index   __init__ требует двух аргументов: begin и step. Аргумент end необязательный, если он равен None, ряд будет неограниченным.  Получить тип суммы self.begin и self.step. Например, если одно имеет тип int, а другое float, то типом результата будет float.  Эта строка порождает значение result, равное self.begin , но приведенное к типу последующих слагаемых1.  Для большей понятности я завел флаг forever, который равен True, если атри- бут self.end равен None, в этом случае получается неограниченный ряд.  Этот цикл продолжается вечно или пока значение result не окажется боль- ше или равно self.end. По выходе из цикла завершается и функция.  Порождается текущее значение result.  Вычисляется следующий потенциальный результат. Возможно, он никогда не будет отдан, потому что цикл while завершится раньше. В последней строке я, вместо того чтобы прибавлять к result значение self. step на каждой итерации, решил игнорировать предыдущее значение result и каждый раз вычислять result заново путем сложения self.begin с величиной self.step, умноженной на index. Это уменьшает накопление погрешности при работе с числами с плавающей точкой. Простые эксперименты ясно показы- вают разницу: >>> 100 * 1.1 110.00000000000001 >>> sum(1.1 for _ in range(100)) 109.99999999999982 >>> 1000 * 1.1 1100.0 >>> sum(1.1 for _ in range(1000)) 1100.0000000000086 Показанный выше класс ArithmeticProgression работает, как и было задумано, и дает понятный пример использования генераторной функции для реали- зации специального метода __iter__. Однако если единственная цель класса – сконструировать генератор в методе __iter__, то класс можно свести к генера- торной функции. Ведь генераторная функция – это не что иное, как фабрика генераторов. 1 В Python 2 была встроенная функция coerce(), но в Python 3 ее убрали, сочтя лишней, т. к. правила приведения числовых типов неявно встроены в методы арифметиче- ских операторов. Поэтому единственный способ, который я смог придумать для при- ведения начального значения к тому же типу, что остальные члены ряда, – выполнить сложение и воспользоваться его типом для преобразования результата. Я задал этот вопрос в списке рассылки Python-list и получил отличный ответ от Стивена Д’Апрано (https://marc.info/?l=python-list&m=141826925106951&w=2).576  Итераторы, генераторы и классические сопрограммы\n--- Страница 576 ---\nВ примере 17.13 показана генераторная функция aritprog_gen , которая делает то же самое, что класс ArithmeticProgression , но короче. Все тесты в примере 17.11 проходят, если вызывать aritprog_gen вместо ArithmeticProgression1. Пример 14.12. Генераторная функция aritprog_gen def aritprog_gen(begin, step, end=None): result = type(begin + step)(begin) forever = end is None index = 0 while forever or result < end: yield result index += 1 result = begin + step * index Пример 17.13, конечно, элегантный, но не забывайте: в стандартной библио- теке немало готовых генераторов, и в следующем разделе мы покажем еще более короткую реализацию с использованием модуля itertools. Построение арифметической прогрессии с помощью itertools Модуль itertools в версии Python 3.10 содержит 20 генераторных функций, ко- торые можно комбинировать разными интересными способами. Например, функция itertools.count возвращает генератор, порождающий числа. Без аргументов порождается ряд целых чисел, начиная с 0. А если за- дать аргументы start и step, то получится результат, очень похожий на тот, что дают наши функции aritprog_gen : >>> import itertools >>> gen = itertools.count(1, .5) >>> next(gen) 1 >>> next(gen) 1.5 >>> next(gen) 2.0 >>> next(gen) 2.5 itertools.count никогда не останавливается, поэтому, обрабаты- вая вызов list(count()) , Python попытается построить список, не помещающийся в оперативную память, и ваша машина нач- нет сварливо брюзжать задолго до того, как вызов завершится ошибкой. С другой стороны, существует функция itertools.takewhile : она порождает ге- нератор, который потребляет другой генератор и останавливается, когда за- данный предикат станет равен False. Объединив обе функции вместе, мы мо- жем написать: 1 Каталог 14-it-generator/ directory в репозитории кода к этой книге (https://github.com/ fluentpython/example-code-2e) содержит тесты, а также скрипт aritprog_runner.py, кото - рый прогоняет все тесты для различных вариантов скриптов aritprog*.py. Генератор арифметической прогрессии  577\n--- Страница 577 ---\n>>> gen = itertools.takewhile(lambda n: n < 3, itertools.count(1, .5)) >>> list(gen) [1, 1.5, 2.0, 2.5] Благодаря использованию takewhile и count мы получаем еще более короткую реализацию, показанную в примере 17.14. Пример 17.14. aritprog_v3.py: работает, как предыдущие варианты функции aritprog_gen import itertools def aritprog_gen(begin, step, end=None): first = type(begin + step)(begin) ap_gen = itertools.count(first, step) if end is None: return ap_gen return itertools .takewhile(lambda n: n < end, ap_gen) Отметим, что функция aritprog_gen в примере 17.14 не является генератор- ной функцией: в ней нет слова yield. Но она возвращает генератор, как и гене- раторная функция. Напомним, однако, что itertools.count прибавляет на каждом шаге step, по- этому порождаемый ей ряд чисел с плавающей точкой не такой точный, как в примере 17.13. Посыл, содержащийся в примере 17.14, прост: реализуя генераторы, нужно знать, что уже есть в стандартной библиотеке, иначе велики шансы изобрести велосипед. Вот почему в следующем разделе мы рассмотрим несколько гото- вых генераторных функций. генерат Орные функции в СтандартнОй БиБлиО теке В стандартной библиотеке есть много генераторов: от объектов построчно- го чтения текстового файла до восхитительной функции os.walk (https://docs. python.org/3/library/os.html#os.walk), которая обходит дерево каталогов и отдает имена файлов, в результате чего рекурсивный поиск оказывается не сложнее обычного цикла for. Генераторная функция os.walk впечатляет, но в этом разделе я сконцент - рируюсь на функциях общего назначения, которые принимают произволь- ные итерируемые объекты в качестве аргументов и возвращают генерато- ры, порождающие выборку, результаты вычислений или элементы в другом порядке. В следующих таблицах я перечислил два десятка таких функций, встроенных и находящихся в модулях itertools и functools. Для удобства они сгруппированы по общей функциональности вне зависимости от того, где находятся. Первая группа – фильтрующие генераторные функции: они отдают под- множество элементов, порождаемых входным итерируемым объектом, не из- меняя сами элементы. Как и функция takewhile, большинство перечисленных в табл. 17.1 функций принимают предикат – булеву функцию с одним аргумен- том, которая применяется к каждому входному элементу и определяет, нужно ли отдавать его на выходе.578  Итераторы, генераторы и классические сопрограммы\n--- Страница 578 ---\nТаблица 17.1. Фильтрующие генераторные функции Модуль Функция Описание itertools compress(it, selector_it) Потребляет параллельно два итерируемых объ- екта; отдает элемент it, когда соответствующий элемент selector_it принимает похожее на ис - тину значение itertools dropwhile(predicate, it) Потребляет it, пропуская элементы, пока predicate принимает похожее на истину значение, а затем отдает все оставшиеся элементы (больше никаких проверок не делается) Встроен- наяfilter(predicate, it) Применяет предикат к каждому элементу ите- рируемого объекта, отдавая элемент, если predicate(item) принимает похожее на истину значение; если predicate равен None, отдаются только элементы, принимающие похожее на ис - тину значение itertools filterfalse(predicate, it) То же, что filter , но логика инвертирована: отда- ются элементы, для которых предикат принимает похожее на ложь значение itertools islice(it, stop) или islice(it, start, stop, step=1)Отдает элементы из среза it по аналогии с s[:stop] или s[start:stop:step] , только it мо- жет быть произвольным итерируемым объектом, а операция ленивая itertools takewhile(predicate, it) Отдает элементы, пока predicate принимает по- хожее на истину значение, затем останавливается, больше никаких проверок не делается В распечатке сеанса оболочки ниже приведены примеры применения всех функций из табл. 17.1. Пример 17.15. Примеры фильтрующих генераторных функций >>> def vowel(c): return c.lower() in 'aeiou' >>> list(filter(vowel, 'Aardvark')) ['A', 'a', 'a'] >>> import itertools >>> list(itertools.filterfalse(vowel, 'Aardvark')) ['r', 'd', 'v', 'r', 'k'] >>> list(itertools.dropwhile(vowel, 'Aardvark')) ['r', 'd', 'v', 'a', 'r', 'k'] >>> list(itertools.takewhile(vowel, 'Aardvark')) ['A', 'a'] >>> list(itertools.compress('Aardvark', (1, 0, 1, 1, 0, 1))) ['A', 'r', 'd', 'a'] >>> list(itertools.islice('Aardvark', 4)) ['A', 'a', 'r', 'd'] >>> list(itertools.islice('Aardvark', 4, 7)) ['v', 'a', 'r'] >>> list(itertools.islice('Aardvark', 1, 7, 2)) ['a', 'd', 'a'] Генераторные функции в стандартной библиотеке  579\n--- Страница 579 ---\nСледующая группа – отображающие генераторы: они отдают элементы, вы- численные для каждого элемента входного итерируемого объекта – или не- скольких таких объектов, как в случае map и starmap1. Генераторы, перечислен- ные в табл. 17.2, отдают по одному результату для каждого элемента входного итерируемого объекта. Если на вход подается несколько итерируемых объек - тов, то процесс прекращается, как только будет исчерпан хотя бы один из них. Таблица 17.2. Отображающие генераторные функции Модуль Функция Описание itertools accumulate(it, [func]) Отдает накопленные суммы; если задана функция func, то отдает результат применения ее к первой паре элементов, затем к первому результату и сле- дующему элементу и т. д. Встроенная enumerate(iterable, start=0)Отдает 2-кортежи вида (index, item) , где index начинается со значения start , а item извлекается из iterable Встроенная map(func, it1, [it2, …, itN])Применяет func к каждому элементу it и отдает результат; если задано N итерируемых объектов, то func должна принимать N аргументов, и все итери- руемые объекты обходятся параллельно itertools starmap(func, it) Применяет func к каждому элементу it и отдает результат; входной итерируемый объект должен отдавать итерируемые элементы iit, а func вы- зывается в виде func(*iit) В примере 17.16 демонстрируется несколько применений функции itertools. accumulate . Пример 17.16. Примеры применения генераторной функции itertools.accumulate >>> import itertools >>> list(itertools.accumulate(sample))  [5, 9, 11, 19, 26, 32, 35, 35, 44, 45] >>> list(itertools.accumulate(sample, min))  [5, 4, 2, 2, 2, 2, 2, 0, 0, 0] >>> list(itertools.accumulate(sample, max))  [5, 5, 5, 8, 8, 8, 8, 8, 9, 9] >>> import operator >>> list(itertools.accumulate(sample, operator.mul))  [5, 20, 40, 320, 2240, 13440, 40320, 0, 0, 0] >>> list(itertools.accumulate(range(1, 11), operator.mul)) [1, 2, 6, 24, 120, 720, 5040, 40320, 362880, 3628800]   Частичные суммы.  Частичные минимумы.  Частичные максимумы.  Частичные произведения.  Факториалы от 1! до 10!. 1 Здесь термин «отображение» никак не связан со словарями, а имеет отношение к встроенной функции map.580  Итераторы, генераторы и классические сопрограммы\n--- Страница 580 ---\nПрименение остальных функций из табл. 17.2 иллюстрируется в примере 17.17. Пример 17.17. Примеры применения отображающих генераторных функций >>> list(enumerate('albatroz', 1))  [(1, 'a'), (2, 'l'), (3, 'b'), (4, 'a'), (5, 't'), (6, 'r'), (7,'o'), (8, 'z')] >>> import operator >>> list(map(operator.mul, range(11), range(11)))  [0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100] >>> list(map(operator.mul, range(11), [2, 4, 8]))  [0, 4, 16] >>> list(map(lambda a, b: (a, b), range(11), [2, 4, 8]))  [(0, 2), (1, 4), (2, 8)] >>> import itertools >>> list(itertools.starmap(operator.mul, enumerate('albatroz', 1)))  ['a', 'll', 'bbb', 'aaaa', 'ttttt', 'rrrrrr', 'ooooooo', 'zzzzzzzz'] >>> sample = [5, 4, 2, 8, 7, 6, 3, 0, 9, 1] >>> list(itertools.starmap(lambda a, b: b / a, enumerate(itertools.accumulate(sample), 1)))  [5.0, 4.5, 3.6666666666666665, 4.75, 5.2, 5.333333333333333, 5.0, 4.375, 4.888888888888889, 4.5]  Количество букв в слове, начальное значение 1.  Квадраты целых чисел от 0 до 10.  Перемножение целых чисел из двух параллельных итерируемых объектов; опе- рация заканчивается, когда будет достигнут конец более короткого объекта.  То же самое делает встроенная функция zip.  Повторение каждой буквы слова столько раз, каков номер ее позиции. Пер- вая буква повторяется 1 раз.  Частичные средние. Далее идет группа объединяющих генераторов – все они отдают элемен- ты из нескольких входных итерируемых объектов. Функции chain и chain.from_ iterable обходят входные итерируемые объекты последовательно (один за дру- гим), а product, zip и zip_longest – параллельно. Таблица 17.3. Генераторные функции, объединяющие несколько входных итерируемых объектов Модуль Функция Описание itertools chain(it1, …, itN) Отдает все элементы из it1, затем из it2 и т. д. itertools chain.from_iterable(it) Отдает все элементы из каждого итерируемого объекта, порождаемого it, перебирая их один за другим; it должен порождать итерируемые объекты, например это может быть список ите- рируемых объектов itertools product(it1, …, itN, repeat=1)Декартово произведение: отдает N -кортежи, полу- ченные путем комбинирования элементов из каж - дого входного итерируемого объекта, – так, как это делалось бы с помощью вложенных циклов for; аргумент repeat позволяет обходить входные итерируемые объекты более одного раза Генераторные функции в стандартной библиотеке  581\n--- Страница 581 ---\nМодуль Функция Описание Встроен- наяzip(it1, …, itN, strict=False)Отдает N-кортежи, построенные из элемен- тов, которые берутся параллельно из входных итерируемых объектов; операция прекращается по исчерпании самого короткого объекта, если только не задан параметр strict=Truea itertools zip_longest(it1, …, itN, fillvalue=None)Отдает N-кортежи, построенные из элементов, которые берутся параллельно из входных ите- рируемых объектов; операция прекращается по исчерпании самого длинного объекта, а вместо недостающих элементов подставляется значе- ние fillvalue a Чисто именованный параметр strict появился в версии Python 3.10. Если strict=True , то в случае, когда итерируемые объекты имеют разную длину, возбуждается исключение ValueError . По умолчанию значение равно False ради обратной совместимости. В примере 17.18 показано использование генераторных функций itertools. chain, zip и родственных им. Напомним, что название функции zip происходит от слова zipper (застежка-молния) и не имеет никакого отношения к алгорит - му сжатия. Обе функции, zip и itertools.zip_longest , были впервые продемон- стрированы во врезке «Удивительная функция zip» в главе 12. Пример 17.18. Примеры применения объединяющих генераторных функций >>> list(itertools.chain('ABC', range(2)))  ['A', 'B', 'C', 0, 1] >>> list(itertools.chain(enumerate('ABC')))  [(0, 'A'), (1, 'B'), (2, 'C')] >>> list(itertools.chain .from_iterable(enumerate('ABC')))  [0, 'A', 1, 'B', 2, 'C'] >>> list(zip('ABC', range(5), [10, 20, 30, 40]))  [('A', 0, 10), ('B', 1, 20), ('C', 2, 30)] >>> list(itertools.zip_longest('ABC', range(5)))  [('A', 0), ('B', 1), ('C', 2), (None, 3), (None, 4)] >>> list(itertools.zip_longest('ABC', range(5), fillvalue='?'))  [('A', 0), ('B', 1), ('C', 2), ('?', 3), ('?', 4)]  chain обычно вызывается с двумя и более итерируемыми объектами.  При вызове с одним итерируемым объектом chain не делает ничего полезного.  Но chain.from_iterable берет каждый элемент из итерируемого объекта и сцеп ляет их в последовательность, при условии что каждый элемент сам является итерируемым объектом.  zip может параллельно обходить произвольное количество итерируемых объектов, но генератор останавливается, как только один из них будет ис- черпан. В Python ≥ 3.10, если задан аргумент strict=True и один итератор ис- черпывается раньше остальных, возбуждается исключение ValueError .  itertools.zip_longest работает, как zip, но не останавливается, пока не будут исчерпаны все итерируемые объекты; вместо недостающих элементов в данном случае подставляется None.  Аргумент fillvalue задает подстановочное значение.Окончание табл. 17.3582  Итераторы, генераторы и классические сопрограммы\n--- Страница 582 ---\nФункция itertools.product дает ленивый способ вычисления декартовых про- изведений, в разделе «Декартовы произведения» главы 2 мы строили их с по- мощью списковых включений с несколькими фразами for. Для ленивого по- рождения декартовых произведений также можно использовать генератор- ные выражения с несколькими фразами for. В примере 17.19 демонстрируется функция itertools.product . Пример 17.19. Примеры применения генераторной функции itertools.product [('A', 0), ('A', 1), ('B', 0), ('B', 1), ('C', 0), ('C', 1)]  >>> suits = 'spades hearts diamonds clubs'.split() >>> list(itertools.product('AK', suits))  [('A', 'spades'), ('A', 'hearts'), ('A', 'diamonds'), ('A', 'clubs'), ('K', 'spades'), ('K', 'hearts'), ('K', 'diamonds'), ('K', 'clubs')] >>> list(itertools.product('ABC'))  [('A',), ('B',), ('C',)] >>> list(itertools.product('ABC', repeat=2))  [('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'B'), ('B', 'C'), ('C', 'A'), ('C', 'B'), ('C', 'C')] >>> list(itertools.product(range(2), repeat=3)) [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 0, 0), (1, 0, 1), (1, 1, 0), (1, 1, 1)] >>> rows = itertools.product('AB', range(2), repeat=2) >>> for row in rows: print(row) ('A', 0, 'A', 0) ('A', 0, 'A', 1) ('A', 0, 'B', 0) ('A', 0, 'B', 1) ('A', 1, 'A', 0) ('A', 1, 'A', 1) ('A', 1, 'B', 0) ('A', 1, 'B', 1) ('B', 0, 'A', 0) ('B', 0, 'A', 1) ('B', 0, 'B', 0) ('B', 0, 'B', 1) ('B', 1, 'A', 0) ('B', 1, 'A', 1) ('B', 1, 'B', 0) ('B', 1, 'B', 1)  Декартово произведение строки str из трех символов и диапазона range из двух целых чисел дает шесть кортежей (потому что 3 * 2 = 6).  Произведение двух достоинств карт ('AK') и четырех мастей дает ряд из восьми кортежей.  Если задан один итерируемый объект, то product порождает ряд 1-кортежей, что не очень полезно.  Но если дополнительно задан именованный аргумент repeat=N, то product об- ходит каждый входной итерируемый объект N раз. Некоторые генераторные функции расширяют свой аргумент, отдавая более одного значения для каждого входного элемента. Они перечислены в табл. 17.4. Генераторные функции в стандартной библиотеке  583\n--- Страница 583 ---\nТаблица 17.4. Генераторные функции, расширяющие каждый входной элемент в несколько выходных Модуль Функция Описание itertools combinations(it, out_len) Отдает комбинации out_len элементов из элементов, отдаваемых it itertools combinations_with_replacement (it, out_len)Отдает комбинации out_len элементов из элементов, отдаваемых it, включая комби- нации с повторяющимися элементами itertools count(start=0, step=1) Отдает числа, начиная с start с шагом step itertools cycle(it) Отдает элементы из it, запоминая копию каждого, после чего отдает всю последова- тельность еще раз – и так до бесконечности itertools pairwise(it) Отдает пары последовательных элементов из it с перекрытиемa itertools permutations(it, out_len=None) Отдает перестановки out_len элементов из элементов, отдаваемых it; по умолчанию out_len равно len(list(it)) itertools repeat(item, [times]) Повторно отдает заданный элемент – times раз или бесконечно, если этот аргумент не задан a itertools.pairwise добавлена в версии Python 3.10. Функции count и repeat из модуля itertools возвращают генераторы, которые извлекают элементы «из воздуха»: ни одна из них не принимает итерируемый объект в качестве аргумента. Как работает функция itertools.count , мы виде- ли в разделе «Построение арифметической прогрессии с помощью itertools» выше. Генератор cycle создает внутреннюю копию входного итерируемого объекта и в бесконечном цикле отдает его элементы снова и снова. В приме- ре 17.20 показаны примеры применения count, cycle, pairwise и repeat. Пример 17.20. Функции count, cycle, pairwise и repeat >>> ct = itertools.count()  >>> next(ct)  0 >>> next(ct), next(ct), next(ct)  (1, 2, 3) >>> list(itertools.islice(itertools.count(1, .3), 3))  [1, 1.3, 1.6] >>> cy = itertools.cycle('ABC')  >>> next(cy) 'A' >>> list(itertools.islice(cy, 7))  ['B', 'C', 'A', 'B', 'C', 'A', 'B'] >>> list(itertools.pairwise(range(7))) [(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6)]  >>> rp = itertools.repeat(7)  >>> next(rp), next(rp) (7, 7)584  Итераторы, генераторы и классические сопрограммы\n--- Страница 584 ---\n>>> list(itertools.repeat(8, 4))  [8, 8, 8, 8] >>> list(map(operator.mul, range(11), itertools.repeat(5)))  [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]  count создает генератор ct.  Получить от ct первый элемент.  Построить из ct список невозможно, т. к. ct никогда не останавливается, по- этому я просто получаю следующие три элемента.  Построить список с помощью генератора count можно, если он ограничен с помощью функции islice или takewhile.  Построить генератор cycle из 'ABC' и получить от него первый элемент – 'A'.  Список можно построить, только если наложить ограничение с помощью islice; здесь извлекаются следующие семь элементов.  Для каждого элемента входного итерируемого объекта pairwise отдает 2-кортеж, содержащий этот и следующий за ним элементы, если следую- щий имеется. Доступна начиная с Python 3.10.  Построить генератор repeat, который вечно отдает число 7.  Генератор repeat можно ограничить, передав аргумент times: данном случае число 8 отдается 4 раза.  Типичное применение repeat: подстановка фиксированного аргумента в функцию map: в данном случае подставляется множитель 5. Генераторные функции combinations , combinations_with_replacement и permutations – вместе с product – в документации itertools называются комбинаторными ге- нераторами ( https://docs.python.org/3/library/itertools.html). Существует тесная связь между itertools.product и остальными комбинаторными функциями (см. пример 17.21). Пример 17.21. Комбинаторные генераторные функции отдают несколько значений для каж - дого входного элемента >>> list(itertools.combinations('ABC', 2))  [('A', 'B'), ('A', 'C'), ('B', 'C')] >>> list(itertools.combinations_with_replacement('ABC', 2))  [('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'B'), ('B', 'C'), ('C', 'C')] >>> list(itertools.permutations('ABC', 2))  [('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'C'), ('C', 'A'), ('C', 'B')] >>> list(itertools.product('ABC', repeat=2))  [('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'B'), ('B', 'C'), ('C', 'A'), ('C', 'B'), ('C', 'C')]  Все комбинации длины len()==2 из элементов строки 'ABC'; порядок эле- ментов в сгенерированных кортежах неважен (они могли бы быть и мно- жествами).  Все комбинации длины len()==2 из элементов строки 'ABC', включая комби- нации с повторяющимися элементами.  Все перестановки длины len()==2 из элементов строки 'ABC'; порядок эле- ментов в сгенерированных кортежах важен.  Декартово произведение 'ABC' и 'ABC' (это результат задания параметра repeat=2). Генераторные функции в стандартной библиотеке  585\n--- Страница 585 ---\nПоследняя рассматриваемая в этом разделе группа генераторных функций предназначена для того, чтобы отдавать все элементы входных итерируемых объ- ектов, но в каком-то другом порядке. Следующие две функции возвращают не- сколько генераторов: itertools.groupby и itertools.tee . Другая генераторная функция из этой группы, встроенная функция reversed, – единственная из описанных в этом разделе, которая принимает не произвольный итерируемый объект, а только по- следовательности. Это и понятно, ведь reversed отдает элементы в обратном по- рядке, а это возможно только для последовательности известной длины. Но на- кладных расходов на создание инвертированной копии последовательности эта функция не несет – она возвращает элементы по запросу. Я поместил функцию itertools.product в одну группу с объединяющими генераторами в табл. 17.3, пото- му что все они обходят более одного итерируемого объекта, тогда как генераторы, перечисленные в табл. 17.5, принимают не больше одного такого объекта. Таблица 17.5. Реорганизующие генераторные функции Модуль Функция Описание itertools groupby(it, key=None) Порождает 2-кортежи вида (key, group), где key – критерий группировки, а group – генератор, отдающий элементы группы Встроенная reversed(seq) Отдает элементы seq в обратном порядке, от по- следнего к первому; аргумент seq должен быть последовательностью или реализовывать специ- альный метод __reversed__ itertools tee(it, n=2) Отдает кортеж n генераторов, каждый из ко- торых независимо отдает элементы входного итерируемого объекта В примере 17.22 демонстрируется использование функций itertools.groupby и reversed. Отметим, что itertools.groupby ожидает, что входной итерируемый объект отсортирован в соответствии с критерием группировки или, по край- ней мере, что элементы, удовлетворяющие этому критерию, идут подряд, пусть даже и не по порядку. Технический рецензент Мирослав Седивы предло- жил такой пример использования: можно отсортировать объекты типа datetime хронологически, а затем сгруппировать по дню недели, тогда получится груп- па данных за понедельник, потом за вторник и т. д., а затем снова за понедель- ник (следующей недели) и т. д. Пример 17.22. itertools.groupby >>> list(itertools.groupby('LLLLAAGGG'))  [('L', <itertools._grouper object at 0x102227cc0>), ('A', <itertools._grouper object at 0x102227b38>), ('G', <itertools._grouper object at 0x102227b70>)] >>> for char, group in itertools.groupby('LLLLAAAGG'):  print(char, '->', list(group)) L -> ['L', 'L', 'L', 'L'] A -> ['A', 'A',] G -> ['G', 'G', 'G'] >>> animals = ['duck', 'eagle', 'rat', 'giraffe', 'bear',586  Итераторы, генераторы и классические сопрограммы\n--- Страница 586 ---\n'bat', 'dolphin', 'shark', 'lion'] >>> animals.sort(key=len)  >>> animals ['rat', 'bat', 'duck', 'bear', 'lion', 'eagle', 'shark', 'giraffe', 'dolphin'] >>> for length, group in itertools.groupby(animals, len):  print(length, '->', list(group)) 3 -> ['rat', 'bat'] 4 -> ['duck', 'bear', 'lion'] 5 -> ['eagle', 'shark'] 7 -> ['giraffe', 'dolphin'] >>> for length, group in itertools.groupby(reversed(animals), len):  print(length, '->', list(group)) 7 -> ['dolphin', 'giraffe'] 5 -> ['shark', 'eagle'] 4 -> ['lion', 'bear', 'duck'] 3 -> ['bat', 'rat'] >>>  groupby отдает кортежи (key, group_generator) .  Для работы с генераторами, порожденными groupby, необходимы вложенные итерации: в данном случае внешний цикл for и внутренний конструктор list.  Для использования groupby входной объект должен быть отсортирован; в данном случае слова отсортированы по длине.  Еще один цикл по парам (key, group ), чтобы вывести ключ и развернуть группу в список.  Здесь генератор reversed используется для обхода animals справа налево. Последняя генераторная функция в этой группе, iterator.tee , обладает уни- кальным поведением: она порождает несколько генераторов для одного вход- ного итерируемого объекта, каждый из которых отдает все элементы этого объекта. Эти генераторы можно потреблять независимо, как показано в при- мере 17.23. Пример 17.23. itertools.tee порождает несколько генераторов, каждый из которых от- дает все элементы входного итерируемого объекта >>> list(itertools.tee('ABC')) [<itertools._tee object at 0x10222abc8>, <itertools._tee object at 0x10222ac08>] >>> g1, g2 = itertools.tee('ABC') >>> next(g1) 'A' >>> next(g2) 'A' >>> next(g2) 'B' >>> list(g1) ['B', 'C'] >>> list(g2) ['C'] >>> list(zip(*itertools.tee('ABC'))) [('A', 'A'), ('B', 'B'), ('C', 'C')] Генераторные функции в стандартной библиотеке  587\n--- Страница 587 ---\nОтметим, что в нескольких примерах из этого раздела использовались ком- бинации генераторных функций. Это возможно, потому что все они принима- ют генераторы в качестве аргументов и возвращают генераторы. Теперь рассмотрим еще одну группу функций для работы с итераторами из стандартной библиотеки. функции редуцир Ования итерируемОг О ОБъекта Все функции, перечисленные в табл. 17.6, принимают итерируемый объект и возвращают единственный результат. Их называют «редуцирующими», «сворачивающими» или «аккумулирующими». На самом деле все эти функ - ции можно было бы реализовать с помощью functools.reduce , но они сделаны встроенными, чтобы было проще решать часто встречающиеся задачи. Более пространное рассмотрение functools.reduce было приведено в разделе «Vector, попытка № 4: хеширование и ускорение оператора ==» главы 12. Для all и any произведена важная оптимизация, которая при использова- нии reduce была бы невозможна: эти функции закорочены (т. е. прекращают об- ход итератора, как только результат становится известен). См. последний тест функции any в примере 17.24. Таблица 17.6. Встроенные функции, которые читают итерируемый объект и возвращают одиночное значение Модуль Функция Описание Встроенная all(it) Возвращает True, если все элементы it принимают похожее на истину значение, в противном случае False ; all([]) возвращает True Встроенная any(it) Возвращает True, если хотя бы один элемент it прини- мает похожее на истину значение, в противном случае False ; any([]) возвращает False Встроенная max(it, [key=,] [default=])Возвращает максимальный элемент ita; key – функция порядка, как в sorted ; значение default возвращается, если итерируемый объект пуст Встроенная min(it, [key=,] [default=])Возвращает минимальный элемент itb; key – функция порядка, как в sorted ; значение default возвращается, если итерируемый объект пуст functools reduce(func, it, [initial])Возвращает результат выполнения следующей про- цедуры: функция func применяется к первым двум эле- ментам, затем к результату и третьему элементу и т. д. Если задан аргумент initial , то он образует начальную пару вместе с первым элементом Встроенная sum(it, start=0) Сумма всех элементов it, к которой может быть при- бавлено значение start , если оно задано (для полу- чения большей точности при сложении чисел с плаваю- щей точкой пользуйтесь функцией math.fsum ) a Может также вызываться в виде max(arg1, arg2, …, [key=?]) , тогда возвращается макси- мальный аргумент. b Может также вызываться в виде min(arg1, arg2, …, [key=?]) , тогда возвращается мини- мальный аргумент.588  Итераторы, генераторы и классические сопрограммы\n--- Страница 588 ---\nРабота all и any демонстрируется в примере 17.24. Пример 17.24. Результаты применения all и any к некоторым последовательностям >>> all([1, 2, 3]) True >>> all([1, 0, 3]) False >>> all([]) True >>> any([1, 2, 3]) True >>> any([1, 0, 3]) True >>> any([0, 0.0]) False >>> any([]) a b False >>> g = (n for n in [0, 0.0, 7, 8]) >>> any(g)  True >>> next(g)  8  any продолжает итерации, пока g не отдаст 7; тогда any останавливается и возвращает True.  Именно поэтому 8 осталось. Встроенная функция sorted также принимает итерируемый объект и возвра- щает нечто иное. В отличие от генераторной функции reversed, sorted строит и возвращает настоящий список. В конце концов, каждый элемент входного итерируемого объекта можно прочитать, а раз так, то их можно и отсортиро- вать, причем сортировке подвергается список list, а значит, его sorted и воз- вращает. Я упомянул sorted в этом месте, потому что она все-таки принимает произвольный итерируемый объект. Конечно, sorted и редуцирующие функции работают только с конечными итерируемыми объектами. В противном случае они будут без конца получать элементы и никогда не вернут результат. Если вы дочитали до этого места, то уже знаете о самом важном и полезном материале данной главы. В остальных разделах рассматриваются продвинутые функции генераторов, которые большинству из нас приходится видеть или использовать не- часто. Речь идет о конструкции yield from и классических со- программах. Есть также разделы, посвященные аннотациям типов для итери- руемых объектов, итераторов и классических сопрограмм. Конструкция yield from дает новый способ комбинирования генераторов. Функции редуцирования итерируемого объекта  589\n--- Страница 589 ---\nyield from и СуБгенерат Оры Выражение yield from было добавлено в версию Python 3.3 и позволяет генера- тору делегировать работу субгенератору. Раньше мы использовали вложенные циклы for, когда генераторная функ - ция должна была отдавать значения, порождаемые другим генератором. >>> def sub_gen(): yield 1.1 yield 1.2 >>> def gen(): yield 1 for i in sub_gen(): yield i yield 2 >>> for x in gen(): print(x) 1 1.1 1.2 2 Тот же результат можно получить с помощью yield from , как показано в при- мере 17.25. Пример 17.25. Тест, демонстрирующий работу yield from >>> def sub_gen(): yield 1.1 yield 1.2 >>> def gen(): yield 1 yield from sub_gen() yield 2 >>> for x in gen(): print(x) 1 1.1 1.2 2 В примере 17.25 цикл for – это клиентский код, gen – делегирующий генератор, а sub_gen – субгенератор. Заметим, что yield from приостанавливает gen, пос ле чего sub_gen работает, пока не исчерпается. Значения, отдаваемые sub_gen, пере- даются сквозь gen напрямую клиентскому циклу for. Тем временем gen пребы- вает в нирване и не видит проходящих сквозь него значений. И лишь когда sub_gen закончит работу, gen возобновляется. Если субгенератор содержит предложение return, возвращающее значение, то это значение может быть перехвачено делегирующим генератором, если он включит конструкцию yield from в состав выражения. См. пример 17.26.590  Итераторы, генераторы и классические сопрограммы\n--- Страница 590 ---\nПример 17.26. yield from получает значение, возвращенное субгенератором >>> def sub_gen(): yield 1.1 yield 1.2 return 'Done!' >>> def gen(): yield 1 result = yield from sub_gen() print('<--', result) yield 2 >>> for x in gen(): print(x) 1 1.1 1.2 <-- Done! 2 Познакомившись с основами yield from , рассмотрим два простых, но практи- чески полезных примера ее использования. Изобретаем chain заново В табл. 17.3 мы видели, что в модуле itertools есть генератор chain, который от- дает элементы нескольких итерируемых объектов, сначала перебирая первый, потом второй и так далее до последнего. Вот как выглядит доморощенная реа- лизация такого сцепляющего генератора chain с помощью цикла for на Python1: >>> def chain(*iterables): for it in iterables: for i in it: yield i >>> s = 'ABC' >>> r = range(3) >>> list(chain(s, r)) ['A', 'B', 'C', 0, 1, 2] Этот генератор chain дает шанс поработать каждому полученному итери- руемому объекту по очереди. Внутренний цикл можно заменить выражением yield from , как показано в сеансе консоли ниже: >>> def chain(*iterables): for i in iterables: yield from i >>> list(chain(s, t)) ['A', 'B', 'C', 0, 1, 2] Конструкция yield from здесь используется правильно, и код действительно смотрится лучше, но в таком виде это всего лишь синтаксический сахар, кото- рый мало что дает. Давайте напишем более интересный пример. 1 Функция chain, как и большая часть функций из модуля itertools , написана на C. yield from и субгенераторы  591\n--- Страница 591 ---\nОбход дерева В этом разделе мы посмотрим, как можно использовать yield from в скрипте для обхода древовидной структуры. Будем продвигаться малыми шажками. Древовидной структурой в этом примере будет иерархия исключений (https://docs.python.org/3/library/exceptions.html#exception-hierarchy) в Python. Но сам паттерн можно адаптировать для показа иерархии каталогов или любой дру- гой древовидной структуры. В Python 3.10 иерархия исключений начинается с BaseException на нулевом уровне и имеет пять уровней. Первый наш шаг – показать нулевой уровень. Получив корневой класс, генератор tree в примере 17.27 отдает его имя и останавливается. Пример 17.27. tree/step0/tree.py: отдать имя корневого класса и остановиться def tree(cls): yield cls.__name__ def display(cls): for cls_name in tree(cls): print(cls_name) if __name__ == '__main__': display(BaseException) На выходе печатается единственная строка: BaseException Следующий шажок переводит нас на уровень 1. Генератор tree отдает имя корневого класса и имена всех его прямых подклассов. Имена подклассов пе- чатаются с отступом, чтобы была видна иерархия. Вот какое представление мы хотим получить: $ python3 tree.py BaseException Exception GeneratorExit SystemExit KeyboardInterrupt Это делает код в примере 17.28. Пример 17.28. tree/step1/tree.py: отдать имя корневого класса и его прямых подклассов def tree(cls): yield cls.__name__, 0  for sub_cls in cls.__subclasses__():  yield sub_cls.__name__, 1  def display(cls): for cls_name, level in tree(cls): indent = ' ' * 4 * level  print(f'{indent}{cls_name}') if __name__ == '__main__': display(BaseException)592  Итераторы, генераторы и классические сопрограммы\n--- Страница 592 ---\n Для поддержки вывода с отступами отдавать имя класса и его уровень в иерар хии.  Использовать специальный метод __subclasses__ для получения списка под- классов.  Отдать имя каждого подкласса и уровень 1.  Построить красную строку шириной 4 * level пробелов. На нулевом уровне строка будет пустой. В примере 17.29 я переработал генератор tree, чтобы отделить специальный случай корневого класса от подклассов, которые теперь обрабатываются в ге- нераторе sub_tree. Дойдя до предложения yield from , генератор tree приостанав- ливается, а обязанность отдавать значения переходит к sub_tree. Пример 17.29. tree/step2/tree.py: tree отдает имя корневого класса, а затем делегирует работу sub_tree def tree(cls): yield cls.__name__, 0 yield from sub_tree(cls)  def sub_tree(cls): for sub_cls in cls.__subclasses__(): yield sub_cls.__name__, 1  def display(cls): for cls_name, level in tree(cls):  indent = ' ' * 4 * level print(f'{indent}{cls_name}') if __name__ == '__main__': display(BaseException  Делегировать sub_tree, чтобы тот отдал имена подклассов.  Отдать имя каждого подкласса и уровень 1. Благодаря наличию yield from sub_tree(cls) внутри tree эти значения проходят мимо генераторной функ - ции…  … и доставляются прямо сюда. Придерживаясь методики малых шагов, я напишу простейший код, который позволит достичь уровня 2. Чтобы обойти дерево в глубину (https://en.wikipedia. org/wiki/Depth-first_search), я хочу после отдачи каждого узла уровня 1 отдавать непосредственные потоки этого узла уровня 2, а затем вернуться на уровень 1. Для этого можно организовать вложенный цикл for, как в примере 17.30. Пример 17.30. tree/step3/tree.py: функция sub_tree обходит уровни 1 и 2 в глубину def tree(cls): yield cls.__name__, 0 yield from sub_tree(cls) def sub_tree(cls): for sub_cls in cls.__subclasses__(): yield sub_cls.__name__, 1 for sub_sub_cls in sub_cls.__subclasses__(): yield sub_sub_cls.__name__, 2 yield from и субгенераторы  593\n--- Страница 593 ---\ndef display(cls): for cls_name, level in tree(cls): indent = ' ' * 4 * level print(f'{indent}{cls_name}') if __name__ == '__main__': display(BaseException) Вот как выглядит результат выполнения скрипта step3/tree.py в примере 17.30: $ python3 tree.py BaseException Exception TypeError StopAsyncIteration StopIteration ImportError OSError EOFError RuntimeError NameError AttributeError SyntaxError LookupError ValueError AssertionError ArithmeticError SystemError ReferenceError MemoryError BufferError Warning GeneratorExit SystemExit KeyboardInterrupt Вы уже, наверное, поняли, к чему все идет, но еще раз прибегну к методике малых шагов: мы дойдем до уровня 3, добавив еще один вложенный цикл for. Больше в программе ничего не изменилось, поэтому в примере 17.31 показан только генератор sub_tree. Пример 17.31. Генератор sub_tree из скрипта tree/step4/tree.py def sub_tree(cls): for sub_cls in cls.__subclasses__(): yield sub_cls.__name__, 1 for sub_sub_cls in sub_cls.__subclasses__(): yield sub_sub_cls.__name__, 2 for sub_sub_sub_cls in sub_sub_cls.__subclasses__(): yield sub_sub_sub_cls.__name__, 3 В примере 17.31 четко видна закономерность. В цикле for мы получаем под- классы уровня N. На каждой итерации цикла мы отдаем подкласс уровня N, а затем входим в следующий цикл for, чтобы посетить уровень N + 1. В разделе «Изобретаем chain заново» мы видели, как заменить вложенный цикл for, управляющий генератором, конструкцией yield from для того же гене-594  Итераторы, генераторы и классические сопрограммы\n--- Страница 594 ---\nратора. Эту идею можно применить и здесь, если переделать sub_tree, так чтобы она принимала параметр level и рекурсивно применяла к себе yield from , пере- давая текущий подкласс в качестве нового корневого класса со следующим но- мером уровня. См. пример 17.32. Пример 17.32. tree/step5/tree.py: рекурсивная функция sub_tree может продвинуться настолько глубоко, насколько хватит памяти def tree(cls): yield cls.__name__, 0 yield from sub_tree(cls, 1) def sub_tree(cls, level): for sub_cls in cls.__subclasses__(): yield sub_cls.__name__, level yield from sub_tree(sub_cls, level+1) def display(cls): for cls_name, level in tree(cls): indent = ' ' * 4 * level print(f'{indent}{cls_name}') if __name__ == '__main__': display(BaseException) Скрипт из примера 17.32 может обходить деревья любой глубины, един- ственным ограничением является предел на уровень рекурсии в Python. По умолчанию допускается 1000 рекурсивных вызовов. В любом нормальном пособии по рекурсии подчеркивается важность базы, позволяющей избежать бесконечной рекурсии. Базой является условное ветв- ление, в одной из ветвей которого производится возврат без рекурсивного вы- зова. Базовый случай часто реализуют с помощью предложения if. В приме- ре 17.32 в функции sub_tree нет if, но неявное условие есть в цикле for: если cls.__ subclasses__() возвращает пустой список, то тело цикла не выполняется, так что рекурсивного вызова не будет. Базовым является случай, когда класс cls не име- ет подклассов. Тогда sub_tree ничего не отдает, а просто возвращает управление. Пример 17.32 делает то, что надо, но его можно сократить, вспомнив пат- терн, который мы видели, когда дошли до уровня 3 (пример 17.31): мы отдаем подкласс уровня N, а затем входим во вложенный цикл for, чтобы посетить уро- вень N + 1. В примере 17.32 мы заменили вложенный цикл конструкцией yield from. Теперь можно объединить tree и sub_tree в один генератор. Пример 17.33 – последний шаг. Пример 17.33. tree/step6/tree.py: рекурсивным вызовам tree передается увеличенный на 1 аргумент level def tree(cls, level=0): yield cls.__name__, level for sub_cls in cls.__subclasses__(): yield from tree(sub_cls, level+1) def display(cls): for cls_name, level in tree(cls): indent = ' ' * 4 * level yield from и субгенераторы  595\n--- Страница 595 ---\nprint(f'{indent}{cls_name}') if __name__ == '__main__': display(BaseException) В начале раздела «yield from и субгенераторы» мы видели, как yield from свя- зывает субгенератор напрямую с клиентским кодом в обход делегирующего ге- нератора. Эта связь становится особенно важной, когда генераторы использу - ются в качестве сопрограмм и не только порождают, но и потребляют значения из клиентского кода, как мы увидим в разделе «Классические сопрограммы». После этого первого знакомства с yield from обратимся к аннотациям типов для итерируемых объектов и итераторов. ОБОБщенные итерируемые типы В стандартной библиотеке Python много функций, принимающих итерируе- мые объекты в качестве аргументов. В своем коде вы можете аннотировать их, как функцию zip_replace из примера 8.15 с использованием типа collections. abc.Iterable (или typing.Iterable , если нужно обязательно поддержать версию Python 3.8 или более ранние; см. объяснение во врезке «Поддержка унасле- дованных типов и нерекомендуемые типы коллекций» в главе 8). См. при- мер 17.34. Пример 17.34. replacer.py возвращает итератор по кортежам строк from collections.abc import Iterable FromTo = tuple[str, str]  def zip_replace(text: str, changes: Iterable[FromTo]) -> str:  for from_, to in changes: text = text.replace(from_, to) return text  Определить псевдоним типа; необязательно, но делает следующую анно- тацию типа более понятной. Начиная с Python 3.10 FromTo должна иметь аннотацию типа typing.TypeAlias , чтобы прояснить назначение этой строки: FromTo: TypeAlias = tuple[str, str] .  Аннотировать аргумент changes, показав, что он принимает итерируемый объект Iterable, составленный из кортежей типа FromTo. Типы Iterator встречаются не так часто, как Iterable, но употреблять их в ан- нотациях тоже просто. В примере 17.35 показан уже знакомый нам генератор чисел Фибоначчи с аннотациями. Пример 17.35. fibo_gen.py: fibonacci возвращает генератор целых чисел from collections.abc import Iterator def fibonacci() -> Iterator[int]: a, b = 0, 1 while True: yield a a, b = b, a + b596  Итераторы, генераторы и классические сопрограммы\n--- Страница 596 ---\nЗаметим, что тип Iterator используется для генераторов, оформленных в виде функций с yield, а также итераторов, написанных «вручную» как классы с методом __next__. Существует также тип collections.abc.Generator (и соответству - ющий объявленный нерекомендуемым тип typing.Generator ), который можно ис- пользовать для аннотирования объектов-генераторов, но он слишком много- словен для генераторов в роли итераторов. Если проверить код в примере 17.36 с помощью Mypy, то окажется, что тип Iterator в действительности является упрощенным частным случаем типа Generator. Пример 17.36. itergentype.py: два способа аннотирования итераторов from collections.abc import Iterator from keyword import kwlist from typing import TYPE_CHECKING short_kw = (k for k in kwlist if len(k) < 5)  if TYPE_CHECKING: reveal_type(short_kw)  long_kw: Iterator[str] = (k for k in kwlist if len(k) >= 4)  if TYPE_CHECKING:  reveal_type(long_kw)  Генераторное выражение, отдающее ключевые слова Python длиной менее 5 знаков.  Mypy выводит: typing.Generator[builtins.str*, None, None]1.  Это выражение также отдает строки, но я добавил явную аннотацию типа.  Выведенный тип: typing.Iterator[builtins.str] . abc.Iterator[str] совместим с abc.Generator[str, None, None] , поэтому в приме- ре 17.36 Mypy не выдает никаких ошибок при проверке типов. Iterator[T] – краткое обозначение Generator[T, None, None] . Обе аннотации озна- чают «генератор, который отдает объекты типа T, но не потребляет и не возвра- щает значений». Генераторы, способные потреблять и возвращать значения, называются сопрограммами, это наша следующая тема. клаССичеСкие СОпр Ограммы В документе PEP 342 «Coroutines via Enhanced Generators» (https:// peps.python.org/pep-0342/) был введен метод .send() и другие сред- ства, благодаря которым стало возможно использовать генера- торы как сопрограммы. В PEP 342 слово «сопрограмма» употреб- ляется в том же смысле, что в этом разделе. К сожалению, в официальной документации по Python и в стан- дартной библиотеке теперь употребляется несогласованная тер- минология в отношении генераторов, используемых в качестве сопрограмм, что заставляет меня применять термин «классиче- 1 В версии 0.910 Mypy все еще использует объявленные нерекомендуемыми типы из модуля typing. Классические сопрограммы  597\n--- Страница 597 ---\nская сопрограмма» в противоположность появившимся позднее объектам «платформенных сопрограмм». После выхода версии Python 3.5 наметилась тенденция исполь- зовать слово «сопрограмма» как синоним «платформенной со- программы». Но документ PEP 342 не объявлен нерекомендуе- мым, и классические сопрограммы по-прежнему работают, как было задумано, хотя уже и не поддерживаются пакетом asyncio. Понять классические сопрограммы в Python мудрено, потому что на самом деле это генераторы, только используются по-другому. Поэтому вернемся на шаг назад и рассмотрим еще одно средство Python, которое можно использо- вать двумя способами. В разделе «Кортеж – не просто неизменяемый список» главы 2 мы видели, что экземпляры tuple можно использовать как записи или как неизменяемые последовательности. Если кортеж используется как запись, то ожидается, что в нем будет определенное число элементов и у каждого элемента будет свой тип. При использовании в качестве неизменяемого списка кортеж может иметь произвольную длину, но ожидается, что все элементы будут иметь один и тот же тип. Поэтому есть два разных способа аннотирования кортежей типами: # Запись о городе, содержащая название, страну и численность населения: city: tuple[str, str, int] # Неизменяемая последовательность доменов: domains: tuple[str, ] Нечто подобное происходит и с генераторами. Обычно они используются как итераторы, но могут использоваться и как сопрограммы. Сопрограмма – это в действительности генераторная функция, в теле которой имеется клю- чевое слово yield. А объект сопрограммы физически является объектом-гене- ратором. Несмотря на общую реализацию на C, использование генераторов и сопрограмм в Python настолько отличается, что существует два способа их аннотирования: # Переменную `readings` можно связать с объектом итератора или генератора, # отдающим элементы типа `float`: readings: Iterator[float] # Переменную `sim_taxi` можно связать с сопрограммой, которая представляет # такси в алгоритме моделирования дискретных событий. Она отдает события, # получает временные метки типа `float` и возвращает количество поездок # за время моделирования: sim_taxi: Generator[Event, float, int] Как будто этого мало, чтобы внести путаницу, авторы модуля typing решили назвать этот тип Generator, хотя на самом деле он описывает API объекта-ге- нератора, который предполагается использовать как сопрограмму, тогда как генераторы чаще используются в роли простых итераторов. В документации по модулю typing (https://docs.python.org/3/library/typing.html# typing.Generator) формальные параметры-типы Generator описаны следующим образом: Generator[YieldType, SendType, ReturnType]598  Итераторы, генераторы и классические сопрограммы\n--- Страница 598 ---\nSendType нужен, только когда генератор используется в качестве сопрограм- мы. Этот параметр описывает тип x в вызове gen.send(x) . Ошибкой является вызов .send() от имени генератора, который предполагалось использовать в качестве итератора, а не сопрограммы. Аналогично параметр-тип ReturnType имеет смысл только для аннотирования сопрограммы, потому что итераторы не возвращают значения так, как делают обычные функции. Единственное разумное действие с генератором, используемым в роли итератора, – вызов метода next(it) прямо или косвенно посредством цикла for и других форм ите- рирования. YieldType – тип значения, возвращаемого при обращении к next(it). Тип Generator имеет такие же параметры-типы, как typing.Coroutine (https:// docs.python.org/3.10/library/typing.html#typing.Coroutine): Coroutine[YieldType, SendType, ReturnType] В документации по typing.Coroutine написано: «Вариантность и порядок пе- ременных-типов такой же, как в типе Generator». Но типы typing.Coroutine (объ- явленный нерекомендуемым) и collections.abc.Coroutine (обобщенный начиная с версии Python 3.9) предназначены для аннотирования только платформен- ных, но не классических сопрограмм. Если вы хотите использовать аннотации типов в сочетании с классическими сопрограммами, то будете испытывать за- мешательство, аннотируя их как Generator[YieldType, SendType, ReturnType] . Дэвид Бизли посвятил классическим сопрограммам некоторые из своих луч- ших и наиболее полных презентаций. В информационных материалах, кото- рые раздавались на конференции PyCon 2009 (http://www.dabeaz.com/coroutines/ Coroutines.pdf), есть такие положения: генераторы порождают данные для итерирования; сопрограммы являются потребителями данных; если не хотите, чтобы сорвало крышу, не путайте эти две концепции; сопрограммы не имеют никакого отношения к итерированию; примечание: у применения yield для порождения значения в сопрограмме есть свои резоны, но с итерированием они не связаны1. Теперь посмотрим, как работают классические сопрограммы. Пример: сопрограмма для вычисления накопительного среднего При обсуждении замыканий в главе 9 мы рассматривали объект для вычисле- ния накопительного среднего: в примере 9.7 приведен простой класс, а в при- мере 9.13 – функция высшего порядка, порождающая замыкание для запоми- нания переменных total и count между вызовами. В примере 17.37 показано, как то же самое сделать с помощью сопрограммы2. 1 Слайд 33 «Keeping It Straight» из презентации «A Curious Course on Coroutines and Concurrency» (http://www.dabeaz.com/coroutines/Coroutines.pdf). 2 В основу этого примера положен фрагмент, приведенный Джекобом Холмом в списке рассылки Python-ideas, его сообщение называется «Yield-From: Finalization guarantees» (https://mail.python.org/pipermail/python-ideas/2009-April/003841.html). Позже в той же ветке появились вариации на эту тему, а сам Холм объяснил ход своих мыслей в сообщении 003912 (https://mail.python.org/pipermail/python-ideas/2009-April/003912.html). Классические сопрограммы  599\n--- Страница 599 ---\nПример 17.37. coroaverager0.py: сопрограмма для вычисления накопительного среднего from collections.abc import Generator def averager() -> Generator[float, float, None]:  total = 0.0 count = 0 average = 0.0 while True:  term = yield average  total += term count += 1 average = total / count  Эта функция возвращает генератор, который отдает значения типа float, принимает значения с помощью метода .send() и не возвращает никакого полезного значения1.  В этом бесконечном цикле сопрограмма будет отдавать средние, пока кли- ентский код посылает значения.  Здесь предложение yield используется, чтобы приостановить сопрограмму, отдать результат вызывающей стороне и – впоследствии – получить значе- ние, посланное вызывающей стороной, после чего выполнение бесконеч- ного цикла продолжится. В сопрограмме total и count могут быть локальными переменными: для запо- минания контекста на время, пока сопрограмма приостановлена в ожидании следующего вызова .send(), не нужны ни атрибуты экземпляра, ни замыкания. Потому-то сопрограммы и являются привлекательной альтернативой обрат - ным вызовам при асинхронном программировании – они сохраняют локаль- ное состояние между активациями. В примере 17.38 приведены тесты, демонстрирующие использование со- программы averager. Пример 17.38. coroaverager0.py: тест, демонстрирующий использование сопрограммы вы- числения накопительного среднего из примера 17.37 >>> coro_avg = averager()  >>> next(coro_avg)  0.0 >>> coro_avg.send(10)  10.0 >>> coro_avg.send(30) 20.0 >>> coro_avg.send(5) 15.0  Создать объект сопрограммы.  Запустить сопрограмму. При этом отдается начальное значение average: 0.0.  Теперь мы в деле: каждый вызов .send() отдает текущее среднее. 1 На самом деле он вообще не возвращает управления, если только какое-то исключение не приведет к выходу из цикла. Mypy 0.910 принимает как None, так и typing.NoReturn в качестве типа значения, возвращаемого генератором, но она также принимает в этой позиции str, т. е., похоже, еще не умеет в полной мере анализировать код сопрограмм.600  Итераторы, генераторы и классические сопрограммы\n--- Страница 600 ---\nВ этом тесте вызов next(coro_avg) заставляет сопрограмму дойти до yield, при этом будет отдано начальное значение average. Запустить сопрограмму можно также, вызвав coro_avg.send(None) , – именно так и поступает встроенная функция next(). Но отправить какое-то значение, кроме None, нельзя, потому что сопрограмма может принимать отправленные значения, только когда приостановлена в точке yield. Вызов next() или .send(None) , чтобы продвинуть выполнение к первому предложению yield, называется «инициализацией со- программы». После каждой активации сопрограмма приостанавливается на выражении yield и ждет отправки значения. В строке coro_avg.send(10) значение отправля- ется, после чего сопрограмма активируется. Выражение yield отдает значение 10, которое присваивается переменной term. В оставшейся части цикла обнов- ляются переменные total, count и average. На следующей итерации цикла while от- дается значение average, и сопрограмма снова приостанавливается в точке yield. У внимательного читателя, наверное, возник вопрос, как остановить работу объекта averager (coro_avg), – ведь цикл-то бесконечный. Обычно нам не нужно завершать генератор, потому что сборщик мусора позаботится о нем, как толь- ко на него не останется ни одной ссылки. Если все-таки необходимо завершить генератор явно, воспользуйтесь методом .close(), как показано в примере 17.39. Пример 17.39. coroaverager.py: продолжение примера 17.38 >>> coro_avg.send(20)  16.25 >>> coro_avg.close()  >>> coro_avg.close()  >>> coro_avg.send(5)  Traceback (most recent call last): StopIteration  coro_avg – экземпляр, созданный в примере 17.38.  Метод .close() возбуждает исключение GeneratorExit в приостановленном выражении yield. Не будучи обработано в функции сопрограммы, исключе- ние завершает ее, а затем перехватывается объектом-генератором, обер- тывающим сопрограмму, – потому-то мы его и не видим.  Вызов .close() для уже закрытой сопрограммы ничего не делает.  Попытка выполнить .send() для закрытой сопрограммы возбуждает исклю- чение StopIteration . Помимо метода .send(), в документе PEP 342 «Coroutines via Enhanced Generators» (https://peps.python.org/pep-0342/) описан также способ возврата зна- чения из сопрограммы. В следующем разделе показано, как это делается. Возврат значения из сопрограммы Теперь мы изучим еще одну сопрограмму для вычисления среднего. Эта вер- сия не отдает частичные результаты, а возвращает кортеж, содержащий коли- чество членов последовательности и их среднее. Я разбил код на две части: примеры 17.40 и 17.41. Классические сопрограммы  601\n--- Страница 601 ---\nПример 17.40. coroaverager2.py: начало файла from collections.abc import Generator from typing import Union, NamedTuple class Result(NamedTuple):  count: int # type: ignore  average: float class Sentinel:  def __repr__(self): return f'<Sentinel>' STOP = Sentinel()  SendType = Union[float, Sentinel]   Сопрограмма averager2 в примере 17.41 вернет экземпляр Result.  Result – это подкласс tuple, имеющий метод .count(), который мне не нужен. Комментарий # type: ignore подавляет сообщения Mypy на предмет наличия поля count1.  Этот класс нужен только для того, чтобы сделать сигнальное значение по- нятным с помощью метода __repr__.  Сигнальное значение, которое я буду использовать, чтобы заставить со- программу прекратить сбор данных и вернуть результат.  Этот псевдоним типа я буду использовать в качестве второго параметра- типа в типе, возвращаемом сопрограммой Generator. Это определение SendType работает и в версии Python 3.10, но если вам не нуж - но поддерживать более ранние версии, то лучше записать его следующим об- разом, предварительно импортировав TypeAlias из typing: SendType: TypeAlias = float | Sentinel Использование | вместо typing.Union выглядит так коротко и понятно, что я бы, пожалуй, предпочел вообще не создавать этот псевдоним типа, а запи- сать сигнатуру averager2, как показано ниже: def averager2(verbose: bool=False) -> Generator[None, float | Sentinel, Result]: Теперь рассмотрим код самой сопрограммы. Пример 17.41. coroaverager2.py: сопрограмма, которая возвращает результирующее значение def averager2(verbose: bool = False) -> Generator[None, SendType, Result]:  total = 0.0 count = 0 average = 0.0 while True: term = yield  1 Я подумывал переименовать это поле, но count – лучшее имя для локальной перемен- ной в сопрограмме, и именно это имя и использовал для переменной в аналогичных примерах, так что имеет смысл оставить его для поля Result. Я без колебаний пишу # type: ignore , чтобы не натыкаться на ограничения и помехи со стороны средств статической проверки типов и не делать код хуже или сложнее, только чтобы пора- довать инструмент.602  Итераторы, генераторы и классические сопрограммы\n--- Страница 602 ---\nif verbose: print('received:', term) if isinstance(term, Sentinel):  break total += term  count += 1 average = total / count return Result(count, average)   В этой сопрограмме тип отдаваемого значения None, потому что она не от - дает никаких данных. Она получает данные типа SendType и возвращает кор- теж типа Result по завершении.  Подобное использование yield имеет смысл только в сопрограммах, пред- назначенных для потребления данных. Здесь yield отдает None, но получает term от .send(term) .  Если term является экземпляром Sentinel, то выйти из цикла. Благодаря этой проверке с помощью isinstance  …Mypy позволяет прибавить term к total, не надоедая мне жалобами на то, что нельзя прибавлять float к объекту, который может иметь тип float или Sentinel.  До этой строки дело дойдет, только если сопрограмме отправлен экзем- пляр Sentinel. Теперь посмотрим, как использовать эту сопрограмму, и начнем с простого примера, который не порождает никакого результата. Пример 17.42. coroaverager2.py: тест, демонстрирующий использование .cancel() >>> coro_avg = averager2() >>> next(coro_avg) >>> coro_avg.send(10)  >>> coro_avg.send(30) >>> coro_avg.send(6.5) >>> coro_avg.close()   Напомним, что averager2 не отдает частичных результатов. А отдает она зна- чение None, которое консоль Python не отображает.  Вызов .close() в этой сопрограмме заставляет ее прекратить выполнение, но не вернуть результат, потому что в строке yield возбуждается исключе- ние GeneratorExit и до предложения return поток выполнения не доходит. Теперь заставим сопрограмму работать, см. пример 17.43. Пример 17.43. coroaverager2.py: тест, демонстрирующий StopIteration с возвратом Result >>> coro_avg = averager2() >>> next(coro_avg) >>> coro_avg.send(10) >>> coro_avg.send(30) >>> coro_avg.send(6.5) >>> try: coro_avg.send(STOP)  except StopIteration as exc: Классические сопрограммы  603\n--- Страница 603 ---\nresult = exc.value  >>> result  Result(count=3, average=15.5)  Отправка сигнального значения STOP заставляет сопрограмму выйти из цикла и вернуть Result. Объект-генератор, обертывающий сопрограмму, за- тем возбуждает исключение StopIteration .  В экземпляре StopIteration атрибут value связан со значением предложения return, завершившего сопрограмму.  Хотите верьте, хотите нет! Эта идея «контрабандой протащить» возвращенное значение из сопрограм- мы, обернутой исключением StopIteration , кажется нечестным приемом. Тем не менее он описан в документе PEP 342 «Coroutines via Enhanced Generators» и документирован в описании исключения StopIteration (https://docs.python.org/3/ reference/expressions.html #yield-expressions) и в разделе «Выражения yield» (https:// docs.python.org/3/reference/expressions.html#yield-expressions) главы 6 справочного руководства по языку Python. Делегирующий генератор может получить возвращенное сопрограммой значение непосредственно, воспользовавшись конструкцией yield from , как по- казано в примере 17.44. Пример 17.44. coroaverager2.py: тест, демонстрирующий StopIteration с возвратом Result >>> def compute(): res = yield from averager2(True)  print('computed:', res)  return res  >>> comp = compute()  >>> for v in [None, 10, 20, 30, STOP]:  try: comp.send(v)  except StopIteration as exc:  result = exc.value received: 10 received: 20 received: 30 received: <Sentinel> computed: Result(count=3, average=20.0) >>> result  Result(count=3, average=20.0)  В res попадает значение, возвращенное averager2; механизм yield from извле- кает возвращенное значение при обработке исключения StopIteration , зна- менующего завершение сопрограммы. Если параметр verbose равен True, то сопрограмма печатает полученное значение, чтобы было видно, как она ра- ботает.  Следите за тем, что выводит эта строка во время работы генератора.  Вернуть результат. Он тоже будет обернут экземпляром StopIteration .604  Итераторы, генераторы и классические сопрограммы\n--- Страница 604 ---\n Создать объект делегирующей сопрограммы.  Этот цикл управляет делегирующей сопрограммой.  Сначала посылается значение None, чтобы инициализировать сопрограмму, а в конце сигнальное значение, чтобы остановить ее.  Перехватить StopIteration , чтобы извлечь из него значение, возвращенное compute.  После строк, напечатанных averager2 и compute, мы получаем экземпляр Result. Хотя эти примеры не делают ничего особенного, следить за кодом трудно. Управлять сопрограммой с помощью вызовов .send() и извлечения результа- та сложно, если не прибегать к yield from , но этот синтаксис допустим только внутри делегирующего генератора или сопрограммы, которые в конечном ито- ге должны приводиться в действие нетривиальным кодом типа показанного в примере 17.44. Из предыдущих примеров видно, что прямое использование сопрограмм утомительно и запутанно. А если добавить обработку исключений и метод со- программ .throw(), то примеры станут еще более мудреными. Я не буду рассма- тривать метод .throw() в этой книге, потому что он, как и .send(), полезен только для управления сопрограммами «вручную», чего я делать не рекомендую, если только вы не занимаетесь разработкой нового основанного на сопрограммах каркаса с нуля. Если вас интересует углубленное рассмотрение классических со- программ, включая и метод .throw(), обратитесь к статье «Клас - сические сопрограммы» (https://www.fluentpython.com/extra/classic- coroutines/) на сопроводительном сайте. Там имеется псевдокод на языке, похожем на Python, показывающий, как yield from при- водит в действие генераторы и сопрограммы, а также небольшая программа моделирования дискретных событий, демонстриру - ющая форму конкурентности с использованием сопрограмм, но без применения каркаса асинхронного программирования. На практике для продуктивной работы с сопрограммами необходима поддерж - ка со стороны специализированного каркаса. Именно это и предоставлял модуль asyncio для классических сопрограмм в Python 3.3. После включения платформен- ных сопрограмм в Python 3.5 разработчики ядра Python постепенно прекращают поддержку классических сопрограмм в asyncio. Но базовые механизмы очень по- хожи. Синтаксическая конструкция async def позволяет легко находить платфор- менные сопрограммы в коде, что само по себе является важным преимуществом. Внутри платформенной сопрограммы используется await вместо yield from для де- легирования работы другим сопрограммам. Всему этому посвящена глава 21. Завершим эту главу головоломным разделом, посвященным ковариантно- сти и контравариантности в аннотациях типов для сопрограмм. Аннотации обобщенных типов для классических сопрограмм В разделе «Контравариантные типы» главы 15 я упоминал typing.Generator как один из немногих стандартных библиотечных типов с контравариантным па- раметром-типом. Теперь, изучив классические сопрограммы, мы готовы разо- браться с этим обобщенным типом. Классические сопрограммы  605\n--- Страница 605 ---\nВот как был объявлен тип typing.Generator в модуле typing.py для версии Python 3.61: T_co = TypeVar('T_co', covariant=True) V_co = TypeVar('V_co', covariant=True) T_contra = TypeVar('T_contra', contravariant=True) # много строк опущено class Generator(Iterator[T_co], Generic[T_co, T_contra, V_co], extra=_G_base): Это объявление обобщенного типа означает, что аннотация типа Generator требует трех параметров-типов, которые мы уже видели раньше: my_coro : Generator[YieldType, SendType, ReturnType] Из описания переменных-типов в формальных параметрах видно, что типы YieldType и ReturnType ковариантны, но SendType контравариантен. Чтобы понять, почему это так, примите во внимание, что YieldType и ReturnType – «выходные» типы. Оба описывают данные, исходящие из объекта сопрограммы, т. е. когда объект-генератор используется в роли сопрограммы. Ковариантность относительно этих параметров имеет смысл, потому что любой код, ожидающий сопрограмму, которая отдает числа с плавающей точ- кой, может работать с сопрограммой, отдающей целые. Именно поэтому тип Generator ковариантен относительно параметра YieldType. Аналогичное рассуж - дение применимо к параметру ReturnType , тоже ковариантному. Применяя нотацию, введенную в разделе «Ковариантные типы» главы 15, мы можем выразить ковариантность первого и третьего параметров с помо- щью символов :>, указывающих в одном направлении: float :> int Generator[float, Any, float] :> Generator[int, Any, int] YieldType и ReturnType – примеры применения первого правила из раздела «Эв- ристические правила вариантности» главы 15. 1. Если формальный параметр-тип определяет тип данных, исходящих из объекта, то он может быть ковариантным. С другой стороны, SendType – «входной» параметр: это тип аргумента value в методе .send(value) объекта сопрограммы. Клиентский код должен отправлять сопрограмме числа с плавающей точкой, не может работать с сопрограммой, принимающей int в качестве SendType, потому что float не является подтипом int. Иными словами, float не совместим с int. Но клиент может работать с сопро- граммой, для которой в роли SendType выступает complex, потому что float является подтипом complex, т. е. float совместим с complex. Нотация :> делает контравариантность второго параметра видимой: 1 Начиная с версии Python 3.7 typing.Generator и другие типы, соответствующие ABC в модуле collections.abc , были переработаны и теперь являются оберткой вокруг со- ответствующего ABC, так что их обобщенные параметры не видны в исходном файле typing.py . Поэтому я здесь ссылаюсь на исходный код Python 3.6.606  Итераторы, генераторы и классические сопрограммы\n--- Страница 606 ---\nfloat :> int Generator[Any, float, Any] <: Generator[Any, int, Any] Это пример применения второго эвристического правила вариантности. 2. Если формальный параметр-тип определяет тип данных, входящих в объ- ект после его начального конструирования, то он может быть контравари- антным. На этом веселом обсуждении вариантности мы завершаем самую длинную главу данной книги. резюме Итерирование так глубоко укоренилось в языке, что я часто говорю, что Python пропитан итераторами1. Интеграция паттерна Итератор в семантику Python – яркий пример того, что паттерны проектирования не в одинаковой степени применимы во всех языках. В Python классический итератор, реализованный «вручную», как в примере 17.4, не имеет никакой практической ценности, а разве что педагогическую. В этой главе мы написали несколько вариантов класса для обхода слов в тек - стовом файле, возможно, очень длинном. Мы видели, как Python использует встроенную функцию iter() для создания итераторов из объектов, похожих на последовательности. Мы построили классический итератор как класс с мето- дом __next__() , а затем использовали генераторы, чтобы сделать каждую по- следующую версию класса Sentence короче и понятнее. Затем мы написали генератор арифметических прогрессий и показали, как с помощью модуля itertools упростить его. Далее познакомились с большин- ством генераторных функций общего назначения из стандартной библиотеки. Потом изучили выражения yield from на примерах простых генераторов chain и tree. Последний крупный раздел был посвящен классическим сопрограммам, хотя эта тема постепенно сходит на нет после добавления платформенных со- программ в версию Python 3.5. Классические сопрограммы, хотя их трудно ис- пользовать на практике, являются основой платформенных сопрограмм, а вы- ражение yield from – прямой предок await. Также были рассмотрены аннотации для типов Iterable, Iterator и Generator, последний из которых дает конкретный и редкий пример контравариантного параметра-типа. дОпО лнительная литература Детальное техническое описание генераторов можно найти в разделе 6.2.9 «Выражения yield» справочного руководства по языку Python (https://docs. python.org/3/reference/expressions.html#yieldexpr). Генераторные функции были 1 В оригинале употреблено слово «grok» и приводится такое пояснение: согласно спра- вочнику жаргона (http://catb.org/~esr/jargon/html/G/grok.html), grok означает не просто «выучить что-то», а впитать, так что «это становится частью тебя, твоей личности». Дополнительная литература  607\n--- Страница 607 ---\nвпервые определены в документе PEP 255 «Simple Generators» (https://www. python.org/dev/peps/pep-0255/). Документация по модулю itertools (https://docs.python.org/3/library/itertools.html) – отличный источник информации благодаря включенным примерам. Хотя функ - ции из этого модуля написаны на C, в документации показано, что многие из них можно было бы реализовать и на Python, часто с привлечением других функций из того же модуля. Примеры подобраны замечательно; например, в одном фраг - менте показано, как с помощью функции accumulate погасить ссуду с процентами, если задан график платежей. А в разделе «Рецепты itertools» (https://docs.python. org/3/library/ itertools.html#itertools-recipes) описаны дополнительные высокопроиз- водительные функции, построенные на базе функций из itertools. Помимо стандартной библиотеки Python, я рекомендую пакет More Itertools (https://more-itertools.readthedocs.io/en/stable/index.html), который, следуя тради- ции itertools, предоставляет мощные генераторы с многочисленными приме- рами и рядом полезных рецептов. В главе 4 «Итераторы и генераторы» книги David Beazley, Brian K. Jones «Python Cookbook», 3-издание (O’Reilly), приведено 16 рецептов, где эта тема рассматривается с разных точек зрения, но всегда с прицелом на практическое применение. Имеются поучительные рецепты с использованием yield from . Себастьян Риттау, в настоящее время руководитель группы сопровождения typeshed, объясняет, почему итераторы должны быть итерируемыми объекта- ми, в статье 2006 года «Java: Iterators are not Iterable». Синтаксическая конструкция yield from объясняется на примерах в документе «What’s New in Python 3.3» (см. PEP 380 «Syntax for Delegating to a Subgenerator», https://docs.python.org/3/whatsnew/3.3.html#pep-380-syntax-for-delegating-to-a- subgenerator). В моей статье «Классические сопрограммы» (https://www.fluentpython. com/extra/classic-coroutines/) на сопроводительном сайте книги имеется углублен- ное рассмотрение yield from, включающее псевдокод его реализации на C. Дэвид Бизли – непререкаемый авторитет во всем, что касается генераторов и сопрограмм в Python. В книге «Python Cookbook», 3-е издание, (O’Reilly), напи- санной в соавторстве с Брайаном Джонсом, приведены многочисленные при- меры сопрограмм. Пособия Бизли на эту тему, представленные на конференции PyCon, хорошо известны глубиной и широтой охвата. Первое было представ- лено на PyCon US 2008: «Generator Tricks for Systems Programmers» (http://www. dabeaz.com/generators/). На PyCon US 2009 мы увидели легендарное «A Curious Course on Coroutines and Concurrency» (http://www.dabeaz.com/coroutines/) (приво- жу ссылки на все три части видео, которые трудно найти в сети: https://archive. org/details/pyvideo_213___pycon-2009-a-curious-course-on-coroutines-and-concurrency- part-1-of-3, https://archive.org/details/pyvideo_215___pycon-2009-a-curious-course-on- coroutines-and-concurrency-part-2-of-3, http://www.dabeaz.com/finalgenerator/). На кон- ференции PyCon 2014 в Монреале он представил пособие «Generators: The Final Frontier» (http://www.dabeaz.com/finalgenerator/), в котором привел дополнитель- ные примеры, относящиеся к конкурентности, теме главы 21. Дэйв не может удержаться от искушения взорвать мозги своим слушателям, поэтому в по- следней части презентации «The Final Frontier» классический паттерн Посети- тель в вычислителе арифметических выражений был заменен сопрограммами. Сопрограммы предлагают новые способы организации кода; чтобы освоить их 608  Итераторы, генераторы и классические сопрограммы\n--- Страница 608 ---\nвозможности, нужно время – но не так ли обстоит дело с рекурсией и полиморфиз- мом (динамической диспетчеризацией)? Интересный пример классического ал- горитма, переписанного с помощью сопрограмм, приведен в статье Джеймса Па- уэлла «Greedy algorithm with coroutines» (https://web.archive.org/web/20200218150637/ http://seriously.dontusethiscode.com/2013/05/01/greedy-coroutine.html). В книге Brett Slatkins «Effective Python», 1-е издание (Addison-Wesley), есть великолепная главка «Рассматривайте сопрограммы как способ выполнить много функций одновременно». Она не включена во второе издание, но оста- лась доступна в сети как пример главы (https://effectivepython.com/2015/03/10/ consider-coroutines-to-run-many-functions-concurrently). Слаткин представляет луч- ший из известных мне примеров управления сопрограммами с помощью yield from: реализацию игры «Жизнь» (https://en.wikipedia.org/wiki/Conway’s_Game_of_Life) Джона Конвея, в которой сопрограммы отвечают за состояние каждой клетки в процессе игры. Я переработал код этого примера – выделил функции и клас - сы из тестовых фрагментов, составляющих оригинальный код Слаткина. Я так - же переписал тесты в формате doc-тестов, чтобы результат различных сопро- грамм и классов можно было видеть, не запуская скрипт. Переработанный при- мер размещен на GitHub (https://gist.github.com/ramalho/da5590bc38c973408839). Поговорим Минималистский интерфейс итератора в Python В разделе «Реализация» главы о паттерне Итератор книги «Банды четырех» написано: Минимальный интерфейс класса Iterator состоит из операций First, Next, IsDone и CurrentItem. Однако к этому предложению относится такая сноска: Этот интерфейс можно и еще уменьшить, если объединить операции Next, IsDone и Currentltem в одну, которая будет переходить к следующему объекту и возвращать его. Если обход завершен, то эта операция вернет специальное значение (например, 0), обозначающее конец итерации. Это близко к тому, что мы имеем в Python: всю работу делает один ме- тод __next__. Но вместо специального значения, на которое по ошибке можно не обратить внимания, о конце итерации возвещает исключение StopIteration . Просто и правильно: таков путь Python. Взаимозаменяемые генераторы Всякий занимающийся большими наборами данных найдет много примене- ний генераторам. Расскажу о том, как я в первый раз создавал практическое решение на основе генераторов. Много лет назад я работал в BIREME, цифровой библиотеке под управлением PAHO/WHO (Панамериканская организация здравоохранения / Всемирная орга- низация здравоохранения) в Сан-Паулу, Бразилия. В числе прочих BIREME созда- ла библиографические наборы данных LILACS (указатель по наукам о здравоох - ранении в Латинской Америке и странах Карибского бассейна) и SciELO (онлай- Дополнительная литература  609\n--- Страница 609 ---\nновая научная электронная библиотека). Это две весьма полные базы данных по региональной научно-исследовательской литературе в области здравоохранения. Начиная с конца 1980-х годов для управления LILACS использовалась не- реляционная документная база данных CDS/ISIS, созданная ЮНЕСКО. Моей задачей было, в частности, изучить возможные альтернативы для миграции LILACS, а затем и гораздо более объемной SciELO в современную базу данных с открытым исходным кодом типа CouchDB или MongoDB. В то время я напи- сал статью, в которой рассматривал слабоструктурированную модель данных и различные способы представления данных из CDS/ISIS в формате запи- сей JSON: «From ISIS to CouchDB: Databases and Data Models for Bibliographic Records» (https://journal.code4lib.org/articles/4893). Частью этого исследования стал Python-скрипт для чтения файла CDS/ISIS и записи JSON-файла, пригодного для импорта в CouchDB или MongoDB. Сна- чала скрипт читал файлы в формате ISO-2709, экспортированные из CDS/ISIS. Чтение и запись нужно было производить инкрементно, потому что полные наборы данных были гораздо больше доступной оперативной памяти. С этим проблем не возникло: на каждой итерации главного цикла for читалась одна запись из iso-файла, обрабатывалась и записывалась в json-файл. Однако, по эксплуатационным соображениям, нужно было, чтобы скрипт isis2json.py поддерживал еще один формат данных CDS/ISIS: двоичные mst- файлы, которые использовались в BIREME, – чтобы избежать дорогостоящего экспорта в формат ISO-2709. Вот теперь возникла проблема: у библиотек, при- менявшихся для чтения файлов ISO-2709 и mst-файлов, был совершенно раз- личный API. А цикл записи JSON-файла и так уже был достаточно сложным, поскольку скрипт принимал много параметров, управляющих реструктури- зацией записей. Чтение данных с помощью двух разных API в одном цикле for, порождавшем JSON-файл, сделало бы программу слишком громоздкой. Решение было найдено: изолировать логику чтения в двух генераторных функциях, по одной для каждого поддерживаемого формата. В итоге я раз- бил скрипт isis2json.py на четыре функции. Исходный код на Python 2 вместе с зависимостями есть в репозитории fluentpython/isis2json на GitHub (https:// github.com/fluentpython/isis2json)1. Ниже описана высокоуровневая структура скрипта: main Функция main вызывает argparse, чтобы прочитать аргументы командной строки, настраивающие структуру выходных записей. На основе расшире- ния имени входного файла выбирается подходящая генераторная функция чтения данных и отдачи записей, по одной. iter_iso_records Эта генераторная функция читает iso-файлы (в предположении, что они записаны в формате ISO-2709). Она принимает два аргумента: имя файла и isis_json_type , один из флагов, относящихся к структуре записи. На каж - дой итерации цикла for читается одна запись, создается пустой словарь dict, этот словарь заполняется данными полей и отдается. 1 Код написан на Python 2, потому что одной из факультативных зависимостей ста- ла библиотека на Java под названием Bruma, которую можно импортировать, когда скрипт работает под управлением Jython, а он еще не поддерживает Python 3.610  Итераторы, генераторы и классические сопрограммы\n--- Страница 610 ---\niter_mst_records Эта генераторная функция читает mst-файлы1. Заглянув в исходный код isis2json.py, вы увидите, что она посложнее iter_iso_records , но интерфейс и общая структура такие же: функция принимает имя файла и аргумент isis_json_type , после чего входит в цикл for, где на каждой итерации стро- ится и отдается словарь, представляющий одну запись. write_json Эта функция выводит JSON-записи, по одной за раз. У нее много аргумен- тов, но первым является input_gen – ссылка на генераторную функцию: iter_iso_records или iter_mst_records . Главный цикл for в функции write_json перебирает словари, отданные выбранным генератором, реструктуриру - ет их в зависимости от аргументов командной строки и добавляет JSON- запись в конец выходного файла. Благодаря генераторным функциям я смог отделить чтение от записи. Конеч- но, проще всего было прочитать все записи в память, а затем записать их на диск. Но из-за размера наборов данных такой путь не годился. Генераторы по- зволили чередовать чтение и запись, поэтому скрипт мог обрабатывать файлы любого размера. Кроме того, специальная логика чтения записи в разных фор- матах ввода отделена от логики реструктуризации записей для вывода. Теперь если понадобится использовать isis2json.py для поддержки дополни- тельного формата ввода, например MARCXML, DTD-схемы, используемой в Библиотеке Конгресса США для представления данных в формате ISO-2709, то легко будет написать третью генераторную функцию для реализации ло- гики чтения. А в сложной функции write_json ничего изменять не придется. Это, конечно, не высшая математика, но реальный пример ситуации, в ко- торой генераторы позволили получить эффективное и гибкое решение для обработки базы данных в виде потока записей. При этом потребление памяти остается низким вне зависимости от размера набора данных. 1 Библиотека для чтения сложных двоичных mst-файлов написана на Java, так что эта функциональность доступна, только когда скрипт isis2json.py выполняется интерпре- татором Jython версии 2.5 или выше. Детали см. в файле README.rst в репозитории. Зависимости импортируются внутри нуждающихся в них генераторных функций, поэтому скрипт может работать даже тогда, когда доступна только одна из внешних библиотек. Дополнительная литература  611",
      "debug": {
        "start_page": 555,
        "end_page": 610
      }
    },
    {
      "name": "Глава 18. Блоки with, match и else 612",
      "content": "--- Страница 611 --- (продолжение)\nГлава 18 Блоки with, match и else Не исключено, что контекстные менеджеры окажутся почти такими же важными, как сами подпрограммы. Мы затронули лишь самую верхушку айсберга […]. В языке Basic есть предложение with, как и во многих других языках. Но все они делают совсем не то – они лишь экономят время на повторяющемся поиске атрибутов с точкой, не производя ни инициали- зации, ни очистки. Не нужно думать, что раз названия одинаковы, то оди- наковы и функции. Предложение with – очень мощная штука. – Раймонд Хэттингер, страстный проповедник Python1 В этой главе мы обсудим средства управления потоком выполнения, которые не так часто встречаются в других языках и потому остаются малоизвестными программистам на Python или используются ими недостаточно эффективно. Вот эти средства: предложение with и протокол контекстных менеджеров; сопоставление с образцом с помощью конструкции match/case ; часть else в предложениях for, while и try. Предложение with организует временный контекст и гарантированно очи- щает его под контролем объекта контекстного менеджера. Это позволяет предотвратить ошибки и уменьшить объем стереотипного кода, одновре- менно сделав API безопаснее и проще в использовании. Программисты на Python находят много применений блокам with помимо автоматического за- крытия файлов. Мы уже видели сопоставление с образцом в других главах, а здесь по- смотрим, как можно выразить грамматику языка в виде последовательно- стей-образцов. Это позволит понять, почему match/case является эффектив- ным инструментом для создания языковых процессоров, понятных и легко расширяемых. Мы рассмотрим полный интерпретатор для небольшого, но функционального подмножества языка Scheme. Те же идеи можно приме- нить к разработке языка шаблонов или предметно-ориентированного языка (DSL) в более крупной системе. Предложение else не представляет никаких сложностей, но при правильном использовании в сочетании с for, while и try позволяет программисту лучше выразить намерения. 1 Тезисы доклада на конференции PyCon US 2013 «What Makes Python Awesome» (http:// pyvideo.org/video/1669/keynote-3); часть, относящаяся к with, начинается в 23:00 и за- канчивается в 26:15.\nГлава 18 Блоки with, match и else Не исключено, что контекстные менеджеры окажутся почти такими же важными, как сами подпрограммы. Мы затронули лишь самую верхушку айсберга […]. В языке Basic есть предложение with, как и во многих других языках. Но все они делают совсем не то – они лишь экономят время на повторяющемся поиске атрибутов с точкой, не производя ни инициали- зации, ни очистки. Не нужно думать, что раз названия одинаковы, то оди- наковы и функции. Предложение with – очень мощная штука. – Раймонд Хэттингер, страстный проповедник Python1 В этой главе мы обсудим средства управления потоком выполнения, которые не так часто встречаются в других языках и потому остаются малоизвестными программистам на Python или используются ими недостаточно эффективно. Вот эти средства: предложение with и протокол контекстных менеджеров; сопоставление с образцом с помощью конструкции match/case ; часть else в предложениях for, while и try. Предложение with организует временный контекст и гарантированно очи- щает его под контролем объекта контекстного менеджера. Это позволяет предотвратить ошибки и уменьшить объем стереотипного кода, одновре- менно сделав API безопаснее и проще в использовании. Программисты на Python находят много применений блокам with помимо автоматического за- крытия файлов. Мы уже видели сопоставление с образцом в других главах, а здесь по- смотрим, как можно выразить грамматику языка в виде последовательно- стей-образцов. Это позволит понять, почему match/case является эффектив- ным инструментом для создания языковых процессоров, понятных и легко расширяемых. Мы рассмотрим полный интерпретатор для небольшого, но функционального подмножества языка Scheme. Те же идеи можно приме- нить к разработке языка шаблонов или предметно-ориентированного языка (DSL) в более крупной системе. Предложение else не представляет никаких сложностей, но при правильном использовании в сочетании с for, while и try позволяет программисту лучше выразить намерения. 1 Тезисы доклада на конференции PyCon US 2013 «What Makes Python Awesome» (http:// pyvideo.org/video/1669/keynote-3); часть, относящаяся к with, начинается в 23:00 и за- канчивается в 26:15.\n--- Страница 612 ---\nчтО нОвОг О в этОй главе Раздел «Сопоставление с образцом в lis.py: развернутый пример» новый. Я переработал раздел «Утилиты contextlib», включив в него новые средства из модуля contextlib , добавленные начиная с версии Python 3.6, и новый ско- бочный синтаксис контекстных менеджеров, появившийся в Python 3.10. Начнем с мощного предложения with. кОнтек Стные менеджеры и БлОки with Объекты контекстных менеджеров служат для управления предложением with, точно так же, как итераторы управляют предложением for. Предложение with было задумано для того, чтобы упростить конструкцию try/finally , гарантирующую, что некоторая операция будет выполнена после блока, даже если этот блок прерван в результате исключения, предложения return или вызова sys.exit() . Код внутри части finally обычно освобождает кри- тически важный ресурс или восстанавливает временно измененное состояние. Сообщество Python находит новые необычные применения для контекст - ных менеджеров. Вот несколько примеров из стандартной библиотеки: управление транзакциями в модуле sqlite3 – см. раздел документации «Использование подключения как контекстного менеджера» (https://docs. python.org/3/library/sqlite3.html#using-the-connection-as-a-context-manager); безопасная работа с блокировками, условными переменными и сема- форами – как описано в документации по модулю threading (https://docs. python.org/3/library/threading.html#using-locks-conditions-and-semaphores-in- the-with-statement); организация специального окружения для арифметических операций с объектами Decimal – см. документацию по методу decimal.localcontext (https://docs.python.org/3/library/decimal.html#decimal.localcontext); внесение временных изменений в объекты для тестирования – см. до- кументацию по функции unittest.mock.patch (https://docs.python.org/3/library/ unittest.mock.html#patch). Интерфейс контекстного менеджера состоит из методов __enter__ и __exit__. В начале блока with вызывается метод __enter__ контекстного менеджера. Когда блок with завершается естественным или иным образом, Python вызывает ме- тод __exit__ контекстного менеджера. Самый распространенный пример with – гарантированное закрытие объекта файла, показанное в примере 18.1. Пример 18.1. Использование объекта файла в качестве контекстного менеджера >>> with open('mirror.py') as fp:  src = fp.read(60)  >>> len(src) 60 >>> fp  <_io.TextIOWrapper name='mirror.py' mode='r' encoding='UTF-8'> >>> fp.closed, fp .encoding  Контекстные менеджеры и блоки with  613\n--- Страница 613 ---\n(True, 'UTF-8') >>> fp.read(60)  Traceback (most recent call last): File \"<stdin>\", line 1, in <module> ValueError: I/O operation on closed file.  Имя fp связано с открытым файлом, потому что метод __enter__ объекта- файла возвращает self.  Прочитать 60 символов Unicode из fp.  Переменная fp все еще доступна – блоки with не определяют новую область видимости, в отличие от функций.  Мы можем прочитать атрибуты объекта fp.  Но выполнить операцию ввода-вывода для fp по завершении блока with нельзя, т. к. уже был вызван метод TextIOWrapper.__exit__ и файл закрыт. Маркер  в примере 18.1 отмечает тонкий, но важный момент: объект кон- текстного менеджера – это результат вычисления выражения после слова with, но значение, связанное с переменной в части as, – результат вызова метода __enter__ объекта контекстного менеджера. В этом примере функция open() возвращает экземпляр класса TextIOWrapper , а его метод __enter__ возвращает self. Но в другом классе метод __enter__ может возвращать какой-то другой объект, не обязательно сам контекстный менеджер. Когда поток управления покидает блок with любым способом, вызывается метод __exit__ контекстного менеджера, а не объекта, возвращенного методом __enter__. Часть as в предложении with необязательна. В случае open она необходима, чтобы получить ссылку на файл, но некоторые контекстные менеджеры воз- вращают None за неимением чего-то полезного. В примере 18.2 показана работа шутливого контекстного менеджера, един- ственный смысл которого – подчеркнуть различие между самим менеджером и объектом, который возвращает его метод __enter__. Пример 18.2. Тест класса контекстного менеджера LookingGlass >>> from mirror import LookingGlass >>> with LookingGlass() as what:  print('Alice, Kitty and Snowdrop')  print(what) pordwonS dna yttiK ,ecilA YKCOWREBBAJ >>> what  'JABBERWOCKY' >>> print('Back to normal.')  Back to normal .  Контекстный менеджер – экземпляр класса LookingGlass ; Python вызывает метод __enter__ контекстного менеджера и связывает результат с перемен- ной what.  Напечатать str, а затем значение переменной what. Любая печатаемая стро- ка выводится задом наперед.614  Блоки with, match и else\n--- Страница 614 ---\n Блок with завершился. Как видим, метод __enter__ вернул значение 'JABBERWOCKY' , сохраненное в переменной what.  Печатаемые строки больше не инвертируются. В примере 18.3 показана реализация класса LookingGlass . Пример 18.3. mirror.py: класс контекстного менеджера LookingGlass import sys class LookingGlass: def __enter__(self):  self.original_write = sys.stdout.write  sys.stdout.write = self.reverse_write  return 'JABBERWOCKY'  def reverse_write(self, text):  self.original_write(text[::-1]) def __exit__(self, exc_type, exc_value, traceback):  sys.stdout.write = self.original_write  if exc_type is ZeroDivisionError:  print('Please DO NOT divide by zero!') return True    Python вызывает __enter__ с одним лишь аргументом self.  Текущий метод sys.stdout.write сохраняется в атрибуте экземпляра для по- следующего использования.  Подменить метод sys.stdout.write своим собственным.  Вернуть строку 'JABBERWOCKY' , просто чтобы было что поместить в перемен- ную what.  Наш метод sys.stdout.write инвертирует переданный аргумент text и вызы- вает сохраненную реализацию.  Python вызывает метод __exit__ с аргументами None, None, None, если не было ошибок; если же имело место исключение, то в аргументах передаются данные об исключении, описанные ниже.  Восстановить исходный метод sys.stdout.write .  Если исключение было и его тип – ZeroDivisionError , то напечатать сообщение…  … и вернуть True, уведомляя интерпретатор о том, что исключение обрабо- тано.  Если метод __exit__ возвращает None или что-то, похожее на False, то исклю- чение, возникшее внутри блока with, распространяется дальше. Реальные приложения, перехватывающие стандартный вывод, обычно хотят временно подменить sys.stdout похожим на файл объектом, а затем восстановить исходное состояние. Именно это делает контекстный менеджер contextlib.redirect_stdout (https:// docs.python.org/3/library/contextlib.html#contextlib.redirect_stdout): просто передайте ему похожий на файл объект, который подме- нит sys.stdout . Контекстные менеджеры и блоки with  615\n--- Страница 615 ---\nИнтерпретатор вызывает метод __enter__ без аргументов – если не считать не- явного аргумента self. А методу __exit__ передаются следующие три аргумента: exc_type Класс исключения (например, ZeroDivisionError ). exc_value Объект исключения. Иногда в атрибуте exc_value.args можно найти параметры, переданные конструктору исключения, например сообщение об ошибке. traceback Объект traceback1. Детальное представление о работе контекстного менеджера дает при- мер 18.4, где объект LookingGlass используется вне блока with, чтобы можно было вручную вызвать его методы __enter__ и __exit__. Пример 18.4. Исследование LookingGlass без блока with >>> from mirror import LookingGlass >>> manager = LookingGlass()  >>> manager # doctest: +ELLIPSIS <mirror.LookingGlass object at 0x > >>> monster = manager.__enter__()  >>> monster == 'JABBERWOCKY'  eurT >>> monster 'YKCOWREBBAJ' >>> manager # doctest: +ELLIPSIS > ta tcejbo ssalGgnikooL.rorrim< >>> manager.__exit__(None, None, None)  >>> monster 'JABBERWOCKY'  Создать и проинспектировать объект manager.  Вызвать метод __enter__() контекстного менеджера и сохранить результат в переменной monster.  Переменная monster содержит строку 'JABBERWOCKY' . Идентификатор True ин- вертирован, потому что весь вывод на stdout проходит через метод write, который мы подменили в __enter__() .  Вызвать manager.__exit__ , чтобы восстановить исходный stdout.write . Скобочные контекстные менеджеры в Python 3.10 В версии Python 3.10 появился новый, более мощный синтакси- ческий анализатор (https://peps.python.org/pep-0617/), открывающий возможность для конструкций, которые были невозможны при старом анализаторе типа LL(1) (https://en.wikipedia.org/wiki/LL_parser). Одно такое синтаксическое улучшение – скобочные контекстные менеджеры: 1 Три аргумента метода __exit__ – это в точности то, что мы получили бы, вызвав метод sys.exc_info() (https://docs.python.org/3/library/sys.html#sys.exc_info) в блоке finally пред- ложения try/finally . И это понятно, если вспомнить, что предложение with призвано заменить try/finally в большинстве случаев, а вызывать sys.exc_info() часто было не- обходимо, чтобы решить, какая требуется очистка. 616  Блоки with, match и else\n--- Страница 616 ---\nwith ( CtxManager1() as example1, CtxManager2() as example2, CtxManager3() as example3, ): До версии 3.10 мы должны были записывать это в виде вложен- ных блоков with. В стандартную библиотеку входит пакет contextlib , содержащий полезные функции, классы и декораторы для построения, комбинирования и использо- вания контекстных менеджеров. Утилиты contextlib Прежде чем начинать писать собственные классы контекстных менеджеров, прочитайте раздел документации по contextlib «Утилиты для контекстов, вво- димых блоками with» (https://docs.python.org/3/library/contextlib.html). Быть может, то, что вы собираетесь делать, уже кем-то сделано. А возможно, существует класс или какой-то вызываемый объект, который облегчит вам работу. Помимо уже упоминавшегося после примера 18.3 контекстного менедже- ра redirect_stdout , в версию Python 3.5 был добавлен менеджер redirect_stderr – он делает то же самое, но для выхода, направленного в stderr. Модуль contextlib также включает другие классы и функции. closing Функция для построения контекстных менеджеров из объектов, которые предоставляют метод close(), но не реализуют интерфейс __enter__/__exit__ . suppress Контекстный менеджер для временного игнорирования заданных исклю- чений. nullcontext Контекстный менеджер, который не делает ничего, но упрощает логику во- круг объектов, которые, возможно, не реализуют подходящий контекстный менеджер. Он служит заместителем в случае, когда условный код перед блоком with может предоставить или не предоставить контекстный менед- жер для этого предложения with. Добавлен в версии Python 3.7. В модуле contextlib имеются классы и декоратор, которые применимы более широко, чем декораторы, упомянутые выше. @contextmanager Декоратор, который позволяет построить контекстный менеджер из прос- той генераторной функции, вместо того чтобы создавать класс и реализо- вывать интерфейс. См. раздел «Использование @contextmanager». AbstractContextManager Этот ABC формализует интерфейс контекстного менеджера и позволяет немного упростить процесс их создания благодаря наследованию. Добав- лен в Python 3.6. Контекстные менеджеры и блоки with  617\n--- Страница 617 ---\nContextDecorator Базовый класс для определения контекстных менеджеров на основе клас - сов, которые можно использовать также в качестве декораторов функций, так что вся функция будет работать внутри управляемого контекста. ExitStack Контекстный менеджер, который позволяет составлять композицию из пе- ременного числа контекстных менеджеров. По выходе из блока with объект ExitStack вызывает методы __exit__ запомненных контекстных менеджеров в порядке LIFO (последним вошел, первым обслужен). Этот класс приме- няется, когда заранее неизвестно количество открываемых блоков with, на- пример в случае, когда одновременно открываются все файлы из произ- вольного списка. В Python 3.7 в модуль contextlib добавились AbstractAsyncContextManager , @asynccontextmanager и AsyncExitStack . Они похожи на эквивалентные средства без префикса async, но предназначены для работы совместно с новым предложени- ем async with , которое рассматривается в главе 21. Из всех этих утилит чаще всего, безусловно, используется декоратор @contextmanager , поэтому уделим ему особое внимание. Этот декоратор интере- сен еще и тем, что предложение yield применяется в нем для целей, не связан- ных с итерированием. Использование @contextmanager Декоратор @contextmanager – элегантный и практичный инструмент, объединяю- щий три разных средства Python: декоратор функции, генератор и предложе- ние with. Использование @contextmanager уменьшает объем стереотипного кода созда- ния контекстного менеджера: вместо того чтобы писать целый класс с мето- дами __enter__/__exit__ , мы просто реализуем генератор с одним предложением yield, порождающим значение, которое должен вернуть метод __enter__. Если генератор снабжен декоратором @contextmanager , то yield разбивает тело функции на две части: все, что находится до yield, исполняется в начале блока with, когда интерпретатор вызывает метод __enter__; а все, что находится после yield, выполняется при вызове метода __exit__ в конце блока. В примере 18.5 класс LookingGlass из примера 18.3 заменен генераторной функцией. Пример 18.5. mirror_gen.py: реализация контекстного менеджера с помощью генератора import contextlib import sys @contextlib.contextmanager  def looking_glass(): original_write = sys.stdout.write  def reverse_write(text):  original_write(text[::-1])618  Блоки with, match и else\n--- Страница 618 ---\nsys.stdout.write = reverse_write  yield 'JABBERWOCKY'  sys.stdout.write = original_write   Применить декоратор contextmanager .  Сохранить исходный метод sys.stdout.write .  Функция reverse_write сможет вызывать original_write , потому что та доступ- на в замыкании.  Заменить sys.stdout.write функцией reverse_write .  Отдать значение, которое будет связано с переменной в части as предложе- ния with. В этой точке генератор приостанавливается на время выполнения блока with.  Когда управление покидает блок with любым способом, выполнение функ - ции возобновляется с места, следующего за yield; в данном случае мы вос- станавливаем исходный метод sys.stdout.write . В примере 18.6 показана функция looking_glass в действии. Пример 18.6. Тест функции контекстного менеджера looking_glass >>> from mirror_gen import looking_glass >>> with looking_glass() as what:  print('Alice, Kitty and Snowdrop') print(what) pordwonS dna yttiK ,ecilA YKCOWREBBAJ >>> what 'JABBERWOCKY' >>> print('back to normal') back to normal  Единственное отличие от примера 18.2 – имя контекстного менеджера: looking_glass вместо LookingGlass . Декоратор contextlib.contextmanager обертывает функцию классом, который реа лизует методы __enter__ и __exit__1. Метод __enter__ этого класса выполняет следующие действия: 1. Вызывает генераторную функцию, чтобы получить объект-генератор – назовем его gen. 2. Вызывает next(gen), чтобы заставить генератор выполнить код до пред- ложения yield. 3. Возвращает значение, отданное next(gen), чтобы его можно было связать с переменной в части as блока with. По завершении блока with метод __exit__ выполняет следующие действия: 1 Этот класс на самом деле называется _GeneratorContextManager . Если хотите узнать, как он работает, загляните в его исходный код (https://github.com/python/cpython/blob/8afab2 ebbc1b343cd88d058914cf622fe687a2be/ Lib/contextlib.py#L123) в файле Lib/contextlib.py из дистрибутива Python 3.10. Контекстные менеджеры и блоки with  619\n--- Страница 619 ---\n1. Смотрит, было ли передано исключение в параметре exc_type; если да, вызывает gen.throw(exception) , в результате чего строка в теле генератор- ной функции, содержащая yield, возбуждает исключение. 2. В противном случае вызывает next(gen), что приводит к выполнению ча- сти генераторной функции после yield. В примере 18.5 есть дефект: если в теле блока with возникает исключение, то интерпретатор Python перехватывает его и повторно возбуждает в выра- жении yield внутри looking_glass . Но здесь нет никакой обработки исключений, поэтому функция looking_glass аварийно завершится, не восстановив исходный метод sys.stdout.write и оставив тем самым систему в некорректном состоянии. В примере 18.7 добавлена специальная обработка исключения ZeroDivisionError , в результате чего код стал эквивалентен примеру 18.3, основанному на классе. Пример 18.7. mirror_gen_exc.py: контекстный менеджер на основе генератора, реализующий обработку исключения, – внешнее поведение такое же, как в примере 18.3 import contextlib import sys @contextlib.contextmanager def looking_glass(): original_write = sys.stdout.write def reverse_write(text): original_write(text[::-1]) sys.stdout.write = reverse_write msg = ''  try: yield 'JABBERWOCKY' except ZeroDivisionError:  msg = 'Please DO NOT divide by zero!' finally: sys.stdout.write = original_write  if msg: print(msg)   Создать переменную для хранения возможного сообщения об ошибке; это первое изменение по сравнению с примером 18.5.  Обработать исключение ZeroDivisionError – установить текст сообщения об ошибке.  Восстановить исходный метод sys.stdout.write .  Отобразить сообщение об ошибке, если оно не пусто. Напомним, что, возвращая True, метод __exit__ уведомляет интерпретатор о том, что он обработал исключение; в этом случае интерпретатор подавля- ет исключение. С другой стороны, если __exit__ не вернул никакого значения явно, то интерпретатор получает значение по умолчанию None и распростра- няет исключение дальше. При наличии декоратора @contextmanager поведение по умолчанию изменяется на противоположное: метод __exit__, предоставляемый декоратором, предполагает, что любое исключение, посланное генератору, уже обработано и должно быть подавлено.620  Блоки with, match и else\n--- Страница 620 ---\nНаличие блока try/finally (или блока with) вокруг yield – неиз- бежная плата за использование @contextmanager , потому что не- возможно заранее знать, что пользователи контекстного менед- жера будут делать внутри блока with1. У декоратора @contextmanager есть одно малоизвестное свойство: снабженные им генераторы сами могут использоваться как декораторы2. Это возможно, по- тому что @contextmanager реализован с помощью класса contextlib.ContextDecorator . В примере 18.8 показан контекстный менеджер looking_glass из примера 18.5, используемый как декоратор. Пример 18.8. Контекстный менеджер looking_glass работает и как декоратор тоже >>> @looking_glass() def verse(): print('The time has come') >>> verse()  emoc sah emit ehT >>> print('back to normal')  back to normal  looking_glass работает до и после тела verse.  Это подтверждает, что оригинальная функция sys.write была восстановлена. Сравните пример 18.8 с примером 18.6, в котором looking_glass используется как контекстный менеджер. Интересный практический пример использования @contextmanager за пределами стандартной библиотеки дает контекстный менеджер для перезаписи файла на месте, созданный Мартином Питерсом (https://www.zopatista.com/python/2013/11/26/ inplace-file-rewriting/). В примере 18.9 показано, как он используется. Пример 18.9. Контекстный менеджер для перезаписи файла на месте import csv with inplace(csvfilename, 'r', newline='') as (infh, outfh): reader = csv.reader(infh) writer = csv.writer(outfh) for row in reader: row += ['new', 'columns'] writer.writerow(row) Функция inplace – это контекстный менеджер, который предоставляет два описателя – infh и outfh – одного и того же файла, позволяющие одновременно читать и записывать файл. Это проще, чем функция fileinput.input из стандарт - ной библиотеки (https://docs.python.org/3/library/fileinput.html#fileinput.input) (кото- рая, кстати, тоже является контекстным менеджером). 1 Это прямая цитата из замечания Леонардо Рохаэля, одного из технических рецен- зентов книги. Отлично сказано, Лео! 2 По крайней мере, ни я, ни другие технические рецензенты не знали об этом, пока Калеб Хэттинг нас не просветил. Спасибо, Калеб! Контекстные менеджеры и блоки with  621\n--- Страница 621 ---\nЕсли вы хотите разобраться в исходном коде функции inplace (приведенном в вышеупомянутой статье), то ищите ключевое слово yield: все, что находит - ся до него, связано с подготовкой контекста, т. е. созданием резервной копии и последующим открытием и отдачей описателей для чтения и записи, кото- рые будут возвращены при вызове метода __enter__. В ходе обработки метода __exit__ после слова yield закрываются описатели файлов, а если что-то пошло не так, то файл восстанавливается из резервной копии. На этом завершается наш разговор о предложении with и контекстных ме- неджерах. Обратимся теперь к развернутому примеру, иллюстрирующему предложение match/case . СОпОС тавление С ОБразц Ом в lis.py: развернутый пример В разделе «Сопоставление с последовательностями-образцами в интерпрета- торе» главы 2 мы видели примеры последовательностей-образцов, взятых из функции evaluate интерпретатора lis.py, написанного Петером Норвигом и пе- ренесенного на Python 3.10. В этом разделе я хочу представить более широкую картину устройства lis.py и заодно изучить все ветви case в evaluate, объяснив не только структуру образцов, но и что делает интерпретатор в каждой ветви. Помимо желания более подробно поговорить об образцах, у меня было еще три причины для написания этого раздела. 1. Скрипт lis.py Норвига – прекрасный пример идиоматичного кода на Python. 2. Простота Scheme – отличный образчик проектирования языков. 3. Изучение работы интерпретатора позволило мне глубже понять Python и языки программирования вообще – как интерпретируемые, так и ком- пилируемые. Прежде чем переходить к Python-коду, попробуем Scheme на вкус, чтобы стал понятен смысл примера – это для тех, кто раньше не сталкивался с языка- ми Scheme или Lisp. Синтаксис Scheme В Scheme, в отличие от Python, выражение и предложения не различаются. Все выражения записываются в префиксной нотации – (+ x 13) вместо x + 13. Она же используется для записи вызовов функций, например (gcd x 13), и специальных форм, например (define x 13), которые в Python были бы записаны в виде вы- ражения присваивания x = 13. Нотация, применяемая в Scheme и большинстве диалектов Lisp, называется S-выражениями1. В примере 18.10 приведен пример простой программы на Scheme. 1 Часто люди недовольны изобилием скобок в Lisp, но при надлежащих отступах и на- личии хорошего редактора эта проблема теряет остроту. Основной проблемой в пла- не удобочитаемости является использование одной и той же нотации (f ) для вы- зовов функций и специальных форм вида (define ) , (if ) и (quote ) , которые ведут себя совсем не так, как функции.622  Блоки with, match и else\n--- Страница 622 ---\nПример 18.10. Вычисление наибольшего общего делителя на Scheme (define (mod m n) (- m (* n (quotient m n)))) (define (gcd m n) (if (= n 0) m (gcd n (mod m n)))) (display (gcd 18 45)) В этом примере мы видим три выражения Scheme: два определения функ - ций – mod и gcd – и вызов функции display, которая выводит 9, результат выраже- ния (gcd 18 45) . В примере 18.11 показан эквивалентный код на Python (он ко- роче, чем объяснение алгоритма Евклида ( https://en.wikipedia.org/wiki/Euclidean_ algorithm) на естественном языке). Пример 18.11. То же, что пример 18.10, но на Python def mod(m, n): return m - (m // n * n) def gcd(m, n): if n == 0: return m else: return gcd(n, mod(m, n)) print(gcd(18, 45)) Если бы я писал идиоматичный код, то воспользовался бы оператором %, а не изобретал бы заново mod, и вместо рекурсии было бы эффективнее использовать цикл while. Но я хотел показать для сравнения оба определения функции, сделав код максимально похожим, чтобы вам было проще читать код на Scheme. В Scheme нет команд итеративного управления потоком типа while или for. Итерирование всегда производится с помощью рекурсии. Обратите внимание, что в примерах на Scheme и Python нет присваиваний. Повсеместное исполь- зование рекурсии и минимум присваиваний – отличительные признаки про- граммирования в функциональном стиле1. Теперь перейдем к рассмотрению кода lis.py на Python 3.10. Полный исход- ный код имеется в каталоге 18-with-match/lispy/py3.10/ репозитория на GitHub по адресу fluentpython/example-code-2e ( https://github.com/fluentpython/example- code-2e/tree/ master/18-with-match/lispy/py3.10/). Предложения импорта и типы В примере 18.12 показаны первые строки скрипта lis.py. Для использования TypeAlias и оператора объединения типов | необходима версия Python 3.10. 1 Чтобы замена итерации рекурсией была практична и эффективна, в Scheme и дру - гих функциональных языках реализована корректная обработка хвостовых вызовов. Подробнее об этом написано в разделе «Поговорим». Сопоставление с образцом в lis.py: развернутый пример  623\n--- Страница 623 ---\nПример 18.12. lis.py: начало файла import math import operator as op from collections import ChainMap from itertools import chain from typing import Any, TypeAlias, NoReturn Symbol: TypeAlias = str Atom: TypeAlias = float | int | Symbol Expression: TypeAlias = Atom | list Типы определены следующим образом. Symbol Просто псевдоним str. В lis.py Symbol используется для идентификаторов; не существует строкового типа данных с такими операциями, как срез, рас- щепление и т. д.1 Atom Простой синтаксический элемент, например число или Symbol, – в противо- положность структуре, состоящей из нескольких частей, как, например, список. Expression Строительными блоками программ на Scheme являются выражения, состо- ящие из атомов и списков, возможно, вложенных. Синтаксический анализатор Анализатор Норвига состоит из 36 строк кода, демонстрирующего возмож - ности Python применительно к обработке простого рекурсивного синтакси- са S-выражений – без строковых данных, комментариев, макросов и других средств стандартного Scheme, усложняющих синтаксический разбор (при- мер 18.13). Пример 18.13. lis.py: основные функции синтаксического разбора def parse(program: str) -> Expression: \"Читать выражение Scheme из строки.\" return read_from_tokens(tokenize(program)) def tokenize(s: str) -> list[str]: \"Преобразовать строку в список лексем.\" return s.replace('(', ' ( ').replace(')', ' ) ').split() def read_from_tokens(tokens: list[str]) -> Expression: \"Читать выражение из последовательности лексем.\" # дополнительный код синтаксического разбора опущен 1 Но во втором интерпретаторе Норвига, lispy.py ( https://github.com/fluentpython/example- code-2e/blob/master/18-with-match/lispy/original/lispy.py), поддерживаются строки как тип данных, а также такие продвинутые средства, как синтаксические макросы, продол- жения и хвостовые вызовы. Однако lispy.py почти в три раза длиннее lis.py и разо- браться в нем гораздо труднее.624  Блоки with, match и else\n--- Страница 624 ---\nГлавная функция в этой группе – parse, она принимает S-выражение в виде str и возвращает объект типа Expression , определенного в примере 18.12: Atom или список list, который может содержать атомы и вложенные списки. В функции tokenize Норвиг применил ловкий трюк: он добавляет пробелы до и после каждой скобки во входных данных, а затем расщепляет строку, полу - чая список синтаксических лексем, в котором '(' и ')' представлены отдель- ными лексемами. Этот прием работает, потому что в сокращенном Scheme нет типа строки, так что каждая скобка '(' или ')' является ограничителем выражения. Код рекурсивного разбора находится в 14-строчной функции read_ from_tokens , его можно найти в каталоге fluentpython/example-code-2e в репози- тории. Я его опущу, потому что хочу уделить больше внимания другим частям интерпретатора. Ниже приведены некоторые тесты, взятые из файла lispy/py3.10/examples_test.py: >>> from lis import parse >>> parse('1.5') 1.5 >>> parse('ni!') 'ni!' >>> parse('(gcd 18 45)') ['gcd', 18, 45] >>> parse(''' (define double (lambda (n) (* n 2))) ''') ['define', 'double', ['lambda', ['n'], ['*', 'n', 2]]] Правила разбора для этого подмножества Scheme просты: 1. Лексема, похожая на число, разбирается как float или int. 2. Всё, кроме '(' и ')', разбирается как Symbol – строка str, используемая в роли идентификатора. Сюда входят, в частности, +, set! и make-counter , все это допустимые идентификаторы в Scheme, но не в Python. 3. Выражения внутри '(' и ')' разбираются рекурсивно как списки, содер- жащие атомы, или как вложенные списки, которые могут содержать ато- мы и дополнительные вложенные списки. В терминологии интерпретатора Python результатом parse является АСТ (абстрактное синтаксическое дерево): удобное представление программы на Scheme в виде вложенных списков, образующих древовидную структуру, в ко- торой самый внешний список является стволом, внутренние списки – ветвя- ми, а атомы – листьями (рис. 18.1). Сопоставление с образцом в lis.py: развернутый пример  625\n--- Страница 625 ---\nРис. 18.1. Лямбда-выражение, представленное в виде исходного кода (конкретный синтак - сис), в виде дерева и в виде последовательности объектов Python (абстрактный синтаксис) Класс Environment Класс Environment расширяет collections.ChainMap , добавляя метод change для обнов- ления значения в одном из связанных словарей, которые в экземплярах ChainMap хранятся в списке отображений: атрибуте self.maps. Метод change необходим для поддержки формы Scheme ( set! …), описанной ниже; см. пример 18.14. Пример 18.14. lis.py: класс Environment class Environment(ChainMap[Symbol, Any]): \"ChainMap, позволяющий обновлять элемент на месте.\" def change(self, key: Symbol, value: Any) -> None: \"Найти, где определен ключ, и изменить там значение.\" for map in self.maps: if key in map: map[key] = value # type: ignore[index] return raise KeyError(key) Заметим, что метод change обновляет только уже существующие ключи1. По- пытка изменить ненайденный ключ приводит к исключению KeyError. 1 Комментарий # type: ignore[index] поставлен из-за проблемы typeshed #6042 (https:// github.com/python/typeshed/issues/6042), которая на момент рецензирования этой главы оставалась неразрешенной. Класс ChainMap аннотирован как MutableMapping , но анно- тация типа в атрибуте maps говорит, что это список объектов Mapping, что косвенно делает весь ChainMap неизменяемым с точки зрения Mypy.626  Блоки with, match и else\n--- Страница 626 ---\nСледующий тест показывает, как работает Environment : >>> from lis import Environment >>> inner_env = {'a': 2} >>> outer_env = {'a': 0, 'b': 1} >>> env = Environment(inner_env, outer_env) >>> env['a']  2 >>> env['a'] = 111  >>> env['c'] = 222 >>> env Environment({'a': 111, 'c': 222}, {'a': 0, 'b': 1}) >>> env.change('b', 333)  >>> env Environment({'a': 111, 'c': 222}, {'a': 0, 'b': 333})  При чтении значений Environment работает как ChainMap: ключи ищутся во вложенных отображениях слева направо. Именно поэтому значение a в outer_env маскируется значением в inner_env.  Присваивание с применением [] перезаписывает существующие или вставляет новые элементы, но всегда в первом отображении, в данном слу- чае – inner_env.  env.change('b', 333) ищет ключ 'b' и присваивает ему новое значение на мес- те, в outer_env. Далее показана функция standard_env() , которая строит и возвращает экзем- пляр Environment с уже загруженными предопределенными функциями. Это на- поминает модуль __builtins__ в Python, который всегда доступен (пример 18.15). Пример 18.15. lis.py: standard_env() строит и возвращает глобальное окружение def standard_env() -> Environment: \"Окружение, содержащее некоторые стандартные процедуры Scheme.\" env = Environment() env.update(vars(math)) # sin, cos, sqrt, pi, env.update({ '+': op.add, '-': op.sub, '*': op.mul, '/': op.truediv, # определения других операторов опущены 'abs': abs, 'append': lambda *args: list(chain(*args)), 'apply': lambda proc, args: proc(*args), 'begin': lambda *x: x[-1], 'car': lambda x: x[0], 'cdr': lambda x: x[1:], # определения других функций опущены 'number?': lambda x: isinstance(x, (int, float)), 'procedure?': callable, 'round': round, 'symbol?': lambda x: isinstance(x, Symbol), }) return env Сопоставление с образцом в lis.py: развернутый пример  627\n--- Страница 627 ---\nТаким образом, в отображение env загружаются: все функции из модуля Python math; избранные операторы из модуля Python op; простые, но мощные функции, построенные с помощью лямбда-выра- жений Python ( lambda); переименованные встроенные функции Python (например, callable на- зывается procedure?) , а также функции с такими же именами, как в Python (например, round). Цикл REPL Цикл REPL (read-eval-print-loop – цикл чтения, вычисления, печати) в коде Норвига легко понять, но назвать его дружелюбным к пользователю сложно (см. пример 18.16). Если скрипту lis.py не передано никаких аргументов, то main(), определенная в конце модуля, вызывает функцию repl(). В ответ на при- глашение lis.py> мы должны ввести правильное и полное выражение; если не закрыть одну скобку, то lis.py аварийно завершается1. Пример 18.16. Функции цикла REPL def repl(prompt: str = 'lis.py> ') -> NoReturn: \"Цикл приглашение-чтение-вычисление-печать.\" global_env = Environment({}, standard_env()) while True: ast = parse(input(prompt)) val = evaluate(ast, global_env) if val is not None: print(lispstr(val)) def lispstr(exp: object) -> str: \"Преобразовать объект Python назад в строку, понятную Lisp.\" if isinstance(exp, list): return '(' + ' '.join(map(lispstr, exp)) + ')' else: return str(exp) Приведем краткое пояснение к этим двум функциям: repl(prompt: str = 'lis.py> ') -> NoReturn Вызывает standard_env() , чтобы сделать доступными функции из глобального окружения, затем входит в бесконечный цикл, где читает и разбирает входные строки, вычисляет их в глобальном контексте и отображает результат, если он равен None. Функция evaluate может модифицировать global_env. Например, если пользователь определяет новую глобальную переменную или именованную функцию, они сохраняются в первом отображении окружения – пустом слова- ре dict, переданном конструктору Environment в первой строчке repl. 1 Изучая скрипты Норвига lis.py и lispy.py, я разветвил проект и в свою версию mylis кое-что добавил, например мой цикл REPL принимает частичные S-выражения и выводит приглашение для ввода продолжения. Точно так же в Python цикл REPL понимает, что выражение не закончено, и предлагает вспомогательное приглашение ( ) до тех пор, пока не получит полное выражение или предложение, которое мож - но вычислить. Кроме того, mylis аккуратно обрабатывает некоторые ошибки, но все равно «уронить» его легко. Он далеко не так надежен, как цикл REPL в Python.628  Блоки with, match и else\n--- Страница 628 ---\nlispstr(exp: object) -> str Функция, обратная parse: получив объект Python, представляющий выраже- ние, parse возвращает его исходный код на Scheme. Например, для ['+', 2, 3] будет возвращено '(+ 2 3)'. Вычислитель Теперь мы можем оценить красоту вычислителя выражений в коде Норвига, который сделан немного симпатичнее благодаря использованию match/case . Функция evaluate, показанная в примере 18.17, принимает объект Expression , по- строенный parse, и объект типа Environment . Тело evaluate состоит из одного предложения match, в котором субъектом яв- ляется выражение exp. В образцах case с удивительной ясностью выражены син- таксис и семантика Scheme. Пример 18.17. evaluate принимает выражение и вычисляет его значение KEYWORDS = ['quote', 'if', 'lambda', 'define', 'set!'] def evaluate(exp: Expression, env: Environment) -> Any: \"Вычислить выражение в заданном окружении.\" match exp: case int(x) | float(x): return x case Symbol(var): return env[var] case ['quote', x]: return x case ['if', test, consequence, alternative]: if evaluate(test, env): return evaluate(consequence, env) else: return evaluate(alternative, env) case ['lambda', [*parms], *body] if body: return Procedure(parms, body, env) case ['define', Symbol(name), value_exp]: env[name] = evaluate(value_exp, env) case ['define', [Symbol(name), *parms], *body] if body: env[name] = Procedure(parms, body, env) case ['set!', Symbol(name), value_exp]: env.change(name, evaluate(value_exp, env)) case [func_exp, *args] if func_exp not in KEYWORDS: proc = evaluate(func_exp, env) values = [evaluate(arg, env) for arg in args] return proc(*values) case _: raise SyntaxError(lispstr(exp)) Рассмотрим, что делает каждая ветвь case. В некоторых случаях я добавил комментарии, показывающие, как S-выражение будет соответствовать об- разцу при построении списка Python. Тесты, взятые из файла examples_test.py (https://github.com/fluentpython/example-code-2e/blob/00e4741926e1b771ee7c75314 8b1415c0bd12e39/02-array-seq/lispy/py3.10/examples_test.py), демонстрируют каж- дую ветвь. Сопоставление с образцом в lis.py: развернутый пример  629\n--- Страница 629 ---\nВычисление чисел case int(x) | float(x): return x Субъект: Экземпляр int или float. Действие: Вернуть прочитанное значение. Пример: >>> from lis import parse, evaluate, standard_env >>> evaluate(parse('1.5'), {}) 1.5 Вычисление символов case Symbol(var): return env[var] Субъект: Экземпляр Symbol, т. е. строка, используемая как идентификатор. Действие: Найти var в env и вернуть значение. Примеры: >>> evaluate(parse('+'), standard_env()) <встроенная функция add> >>> evaluate(parse('ni!'), standard_env()) Traceback (most recent call last): KeyError: 'ni!' (quote …) Специальная форма quote позволяет рассматривать атомы и списки как дан- ные, а не подлежащие вычислению выражения. # (quote (99 bottles of beer)) case ['quote', x]: return x Субъект: Список, начинающийся символом 'quote', за которым следует одно выраже- ние x. Действие: Вернуть x без вычисления. Примеры: >>> evaluate(parse('(quote no-such-name)'), standard_env()) 'no-such-name' >>> evaluate(parse('(quote (99 bottles of beer))'), standard_env()) [99, 'bottles', 'of', 'beer']630  Блоки with, match и else\n--- Страница 630 ---\n>>> evaluate(parse('(quote (/ 10 0))'), standard_env()) ['/', 10, 0] Не будь quote, каждое из этих выражений возбудило бы исключение: no-such-name было бы не найдено в окружении, что привело бы к ошибке KeyError ; (99 bottles of beer) нельзя вычислить, потому что число 99 – не Symbol, со- держащий имя специальной формы, оператора или функции; (/ 10 0) привело бы к исключению ZeroDivisionError . Почему в языках есть зарезервированные слова Форму quote, какой бы простой она ни была, нельзя реализовать в Scheme в виде функции. Ее специальная особенность заключается в том, чтобы помешать интерпретатору вычислять (f 10) в выражении (quote (f 10)) : результатом является просто список, содержащий Symbol и int. С другой стороны, при вызове функции, например (abs (f 10)) , интерпретатор сна- чала вычисляет (f 10), а затем вызывает abs. Именно поэтому quote является зарезервированным словом: оно должно обрабатываться как специальная форма. В общем случае зарезервированные слова нужны: чтобы реализовать специальные правила, как в случае quote и lambda, – ни то, ни другое не вычисляет своих подвыражений; чтобы изменить поток управления, как в случае if и вызовов функций, – это тоже специальные правила вычисления; для управления окружением, как в случае define и set. По тем же причинам в Python и в других языках программирования необхо- димы зарезервированные слова. Подумайте о том, для чего Python нужны слова def, if, yield, import и del. (if …) # (if (< x 0) 0 x) case ['if', test, consequence, alternative]: if evaluate(test, env): return evaluate(consequence, env) else: return evaluate(alternative, env) Субъект: Список, в котором первым элементом является 'if', а за ним следуют три выражения: test, consequence и alternative . Действие: Вычислить test: если true, то вычислить consequence и вернуть его значение; в противном случае вычислить alternative и вернуть его значение. Сопоставление с образцом в lis.py: развернутый пример  631\n--- Страница 631 ---\nПримеры: >>> evaluate(parse('(if (= 3 3) 1 0))'), standard_env()) 1 >>> evaluate(parse('(if (= 3 4) 1 0))'), standard_env()) 0 Ветви consequence и alternative должны содержать ровно одно выражение. Если необходимо несколько выражений, то их можно объединить: (begin exp1 exp2…) ; в lis.py begin является функцией. См. пример 18.15. (lambda …) В Scheme форма lambda определяет анонимные функции. У нее нет ограниче- ний, присущих лямбда-выражениям в Python: любую функцию, которую во- обще можно записать в Scheme, можно записать и с применением синтаксиса (lambda …) . # (lambda (a b) (/ (+ a b) 2)) case ['lambda' [*parms], *body] if body: return Procedure(parms, body, env) Субъект: Список, начинающийся со слова 'lambda', за которым следуют: список, содержащий нуль или более имен параметров; одно или несколько выражений, собранных в body (охранное условие га- рантирует, что body не пусто). Действие: Создать и вернуть новый экземпляр класса Procedure, содержащий имена па- раметров, список выражений в качестве тела и текущее окружение. Пример: >>> expr = '(lambda (a b) (* (/ a b) 100))' >>> f = evaluate(parse(expr), standard_env()) >>> f # doctest: +ELLIPSIS <lis.Procedure object at 0x > >>> f(15, 20) 75.0 Класс Procedure реализует концепцию замыкания: вызываемый объект, в ко- тором хранятся имена параметров, тело функции и ссылка на окружение, в ко- тором функция определена. Код Procedure мы рассмотрим чуть позже. (define …) У ключевого слова define есть две разные синтаксические формы. Самая простая такова: # (define half (/ 1 2)) case ['define', Symbol(name), value_exp]: env[name] = evaluate(value_exp, env) Субъект: Строка начинается словом 'define', затем следуют Symbol и выражение.632  Блоки with, match и else\n--- Страница 632 ---\nДействие: Вычислить выражение и поместить его значение в env, используя name как ключ. Пример: >>> global_env = standard_env() >>> evaluate(parse('(define answer (* 7 6))'), global_env) >>> global_env['answer'] 42 Тест для этой ветви case создает global_env , чтобы можно было проверить, что evaluate помещает answer в окружение. Эту простую форму define можно использовать для создания переменных или для связывания имен с анонимными функциями, когда в роли value_exp высту - пает (lambda …) . В стандартном Scheme имеется сокращенная форма для определения имено- ванных функций, а именно: # (define (average a b) (/ (+ a b) 2)) case ['define', [Symbol(name), *parms], *body] if body: env[name] = Procedure(parms, body, env) Субъект: Список начинается с 'define', за которым следуют: список, начинающийся с Symbol(name) , за которым следует нуль или более элементов, собранных в список с именем parms ; одно или более выражений, собранных в список body (охранное условие гарантирует, что body не пуст). Действие: Создать новый экземпляр Procedure с заданными именами параметров, списком выражений в качестве тела и текущим окружением; поместить Procedure в env, используя name как ключ. Тест в примере 18.18 определяет функцию с именем %, которая вычисляет процент и помещает его в global_env . Пример 18.18. Определение функции %, которая вычисляет процент >>> global_env = standard_env() >>> percent = '(define (% a b) (* (/ a b) 100))' >>> evaluate(parse(percent), global_env) >>> global_env['%'] # doctest: +ELLIPSIS <lis.Procedure object at 0x > >>> global_env['%'](170, 200) 85.0 После вызова evaluate мы проверяем, что имя % связано с Procedure, которая принимает два числовых аргумента и возвращает процент. Образец для второй ветви define не гарантирует, что все элементы parms явля- ются экземплярами Symbol. Я должен был бы сам проверить это перед построе- нием Procedure, но не стал – чтобы следить за кодом было так же просто, как за кодом Норвига. Сопоставление с образцом в lis.py: развернутый пример  633\n--- Страница 633 ---\n(set! …) Форма set! изменяет значение ранее определенной переменной1. # (set! n (+ n 1)) case ['set!', Symbol(name), value_exp]: env.change(name, evaluate(value_exp, env)) Субъект: Список, начинающийся с 'set!', за которым следует Symbol и выражение. Действие: Заменить значение name в env результатом вычисления выражения. Метод Environment.change обходит сцепленные окружения в порядке от локаль- ных к глобальному и заменяет первое вхождение name новым значением. Если бы мы не стали реализовывать ключевое слово 'set!', то могли бы использовать класс Python ChainMap в качестве типа Environment всюду в этом интерпретаторе. Ключевые слова nonlocal в Python и set! в Scheme решают одну и ту же проблему Использование формы set! имеет прямое отношение к использованию клю- чевого слова nonlocal в Python: благодаря объявлению nonlocal x присваива- ние x = 10 может обновить переменную x, ранее определенную вне локальной области видимости. Не будь объявления nonlocal x , это предложение всегда создавало бы локальную переменную, как мы видели в разделе «Объявление nonlocal Declaration» главы 9. Аналогично форма (set! x 10) изменяет переменную x, которая, возможно, ранее была определена вне локального окружения функции. Напротив, пере- менная x в форме (define x 10) всегда локальна, она создается или изменяется в локальном окружении. И nonlocal, и (set! …) необходимы, чтобы можно было изменять состояние про- граммы, хранящееся в переменных в замыкании. В примере 9.13 демонстри- ровалось применение nonlocal для реализации функции, вычисляющей на- копительное среднее, для чего число элементов count и частичная сумма total хранились в замыкании. Здесь та же идея выражена на подмножестве Scheme, реализованном в lis.py: (define (make-averager) (define count 0) (define total 0) (lambda (new-value) (set! count (+ count 1)) (set! total (+ total new-value)) 1 Присваивание – одна из первых вещей, которым учат во многих пособиях по програм- мированию, но в лучшей из известных мне книг по Scheme, Abelson et al. «Structure and Interpretation of Computer Programs» (MIT Press), она же SCIP, или «Книга с мудре- цом», описание set! появляется только на 220-й странице. Кодирование в функцио- нальном стиле позволяет продвинуться очень далеко без изменения состояния, столь типичного для императивного и объектно-ориентированного программирования.634  Блоки with, match и else\n--- Страница 634 ---\n(/ total count) ) ) (define avg (make-averager))  (avg 10)  (avg 11)  (avg 15)   Создает новое замыкание с внутренней функцией, определенной с помо- щью lambda, и переменными count и total, инициализированными значе- нием 0; связывает с замыканием имя avg.  Возвращает 10.0.  Возвращает 10.5.  Возвращает 12.0. Приведенный выше код – один из тестов в файле lispy/py3.10/examples_test. py (https://github.com/fluentpython/example-code-2e/blob/master/18-with-match/ lispy/py3.10/examples_test.py). Теперь перейдем к вызову функции. Вызов функции # (gcd (* 2 105) 84) case [func_exp, *args] if func_exp not in KEYWORDS: proc = evaluate(func_exp, env) values = [evaluate(arg, env) for arg in args] return proc(*values) Субъект: Список, содержащий один или несколько элементов. Охранное условие гарантирует, что func_exp не является ни одним из клю- чевых слов ['quote', 'if', 'define', 'lambda', 'set!'] , перечисленных до evaluate в примере 18.17. Образец сопоставляется с любым списком, содержащим одно или более вы- ражений, при этом первое выражение связывается с func_exp, а остальные со списком args, который может быть пустым. Действие: Вычислить func_exp для получения функции proc; вычислить каждый элемент в args для построения списка значений ар- гументов; вызвать proc, передав значения в качестве отдельных аргументов, и вер- нуть результат. Пример: >>> evaluate(parse('(% (* 12 14) (- 500 100))'), global_env) 42.0 Этот тест – продолжение примера 18.18: предполагается, что в global_env име- ется функция с именем %. Аргументы, передаваемые %, – арифметические вы- ражения, чтобы подчеркнуть, что аргументы вычисляются до вызова функции. Сопоставление с образцом в lis.py: развернутый пример  635\n--- Страница 635 ---\nОхранное условие в этой ветви case необходимо, потому что образец [func_exp, *args] сопоставляется с любой последовательностью-субъектом, содержащей один или более элементов. Однако если func_exp – ключевое слово, но субъект не сопо- ставился ни с одной предыдущей ветвью, то мы имеем синтаксическую ошибку. Обработка синтаксических ошибок Если субъект exp не сопоставился ни с одним из рассмотренных выше образцов в ветвях case, то в универсальной ветви возбуждается исключение SyntaxError : case _: raise SyntaxError(lispstr(exp)) Ниже приведен пример некорректной формы (lambda …) , которая вызывает ошибку SyntaxError : >>> evaluate(parse('(lambda is not like this)'), standard_env()) Traceback (most recent call last): SyntaxError: (lambda is not like this) Если бы в ветви case для вызова функции не было охранного условия, отвер- гающего ключевые слова, то выражение (lambda is not like this) обрабатывалось бы как вызов функции, что привело бы к ошибке KeyError, потому что 'lambda' не является частью окружения – точно так же, как lambda не является встроен- ной функцией в Python. Procedure: класс, реализующий замыкание Класс Procedure вполне можно было бы назвать Closure, потому что это именно то, для чего он предназначен: хранить определение функции вместе с окру - жением. Определение функции включает имена параметров и выражения, составляющие тело функции. Окружение используется при вызове функции, чтобы предоставить значения свободных переменных: переменных, которые встречаются в теле функции, но не являются ни параметрами, ни локальными переменными, ни глобальными переменными. Мы знакомились с концепци- ей замыкания и свободной переменной в разделе «Замыкания» главы 9. Мы видели, как замыкания используются в Python, но теперь можем коп- нуть глубже и посмотреть, как замыкание реализовано в lis.py: class Procedure: \"Определенная пользователем процедура Scheme.\" def __init__(  self, parms: list[Symbol], body: list[Expression], env: Environment): self.parms = parms  self.body = body self.env = env def __call__(self, *args: Expression) -> Any:  local_env = dict(zip(self.parms, args))  env = Environment(local_env, self.env)  for exp in self.body:  result = evaluate(exp, env) return result 636  Блоки with, match и else\n--- Страница 636 ---\n Вызывается, когда функция определена с помощью форм lambda или define.  Сохранить имена параметров, выражения в теле и окружение для последу - ющего использования.  Вызывается при обращении к proc(*values) в последней строке кода ветви case [func_exp, *args] .  Построить отображение local_env, используя self.parms как имена локальных переменных, а args как значения.  Построить новое объединенное окружение env, поместив в начало local_env, а за ним self.env – окружение, которое было сохранено в момент определе- ния функции.  Обойти все выражения в self.body, вычисляя их в контексте объединенного окружения env.  Вернуть результат последнего вычисленного выражения. В lis.py есть еще две простые функции после evaluate: run читает полную про- грамму Scheme и выполняет ее, а main вызывает run или repl в зависимости от параметров в командной строке – так же поступает Python. Я не буду описы- вать эти функции, потому что в них нет ничего нового. Моя цель – просто раз- делить с вами восхищение красотой небольшого интерпретатора Норвига, подробнее пояснить, как работают замыкания, и убедить в том, что match/case стало прекрасным добавлением в Python. И в заключение этого пространного раздела о сопоставлении с образцами формализуем понятие OR-образца. Использование OR-образцов Последовательность образцов, разделенных знаком |, называется OR-образцом (https://peps.python.org/pep-0634/#or-patterns): сопоставление с ним завершается успешно, если удалось сопоставить субъект хотя бы с одним из подобразцов. Образец в разделе «Вычисление чисел» выше является OR-образцом: case int(x) | float(x): return x Во всех подобразцах OR-образца должны использоваться одни и те же пере- менные. Это ограничение необходимо, чтобы гарантировать, что переменные доступны охранному выражению и телу ветви case вне зависимости от того, с каким из подобразцов произошло сопоставление. В контексте ветви case оператор | имеет специальную семан- тику. Он не активирует специальный метод __or__, как при обработке выражений вида a | b в других контекстах, где он перегружен для выполнения таких операций, как объединение множеств или поразрядное OR целых чисел – в зависимости от операндов. OR-образец может встречаться не только на верхнем уровне образца. Его можно использовать также в подобразцах |. Например, если мы захотим, что- Сопоставление с образцом в lis.py: развернутый пример  637\n--- Страница 637 ---\nбы lis.py принимал греческую букву λ (лямбда)1 наряду с ключевым словом lambda, то сможем переписать этот образец в таком виде: # (λ (a b) (/ (+ a b) 2) ) case ['lambda' | 'λ', [*parms], *body] if body: return Procedure(parms, body, env) Теперь мы наконец-то можем перейти к третьей и последней теме этой гла- вы: необычным местам, в которых может встречаться фраза else в Python. делай тО, пОтОм этО: БлОки else вне if Это не секрет, а недооцененное средство языка: часть else может встречаться не только в предложениях if, но также в for, while и try. Семантика for/else, while/else и try/else похожа, но резко отличается от семан- тики if/else. Поначалу слово else мешало мне по-настоящему понять смысл этих средств, но в конце концов я их освоил. Правила таковы: for Блок else выполняется, только если цикл for дошел до конца (т. е. не было преждевременного выхода с помощью break). while Блок else выполняется, только если цикл while завершился вследствие того, что условие приняло ложное значение (а не в результате выхода с помо- щью break). try Блок else выполняется, только если в блоке try не возникало исключение. В официальной документации (https://docs.python.org/3/reference/ compound_ stmts.html) также сказано: «Исключения, возникшие в части else, не обраба- тываются в предшествующих частях except». В любом случае часть else не выполняется и тогда, когда исключение либо одно из предложений, return, break или continue, приводят к передаче управления вовне главного блока составного предложения. Я считаю, что выбор ключевого слова else крайне неудачен во всех случаях, кроме if. Оно подразумевает взаимно исключа- ющие альтернативы, например: «Выполни этот цикл, иначе сделай то-то», однако семантика else в циклах прямо противо- положна: «Выполни этот цикл, а затем сделай то-то». Таким об- разом, более подходящим словом было бы then – оно, кстати, имеет смысл и в контексте try: «Попробуй это, а затем сделай то». Однако добавление нового ключевого слова означало бы не- совместимое изменение языка – непростое решение. 1 Официальное название символа Unicode λ (U+03BB) ГРЕЧЕСКАЯ СТРОЧНАЯ БУКВА ЛЯМДА (GREEK SMALL LETTER LAMDA). Это не опечатка: в базе данных Unicode сим- вол называется именно «лямда» без «б». Согласно статье в англоязычной Википедии «Lambda», консорциум Unicode принял это написание, поскольку таковы были «по- желания, высказанные национальным органом Греции». 638  Блоки with, match и else\n--- Страница 638 ---\nИспользование else в этих предложениях часто упрощает чтение кода и по- зволяет отказаться от установки всяких флагов и добавления предложений if. Применение else обычно выглядит так: for item in my_list: if item.flavor == 'banana': break else: raise ValueError('No banana flavor found!') Что касается блоков try/except , то на первый взгляд else может показаться лишним. Ведь after_call() в следующем фрагменте и так будет выполняться, только если dangerous_call() не возбудил исключения, верно? try: dangerous_call() after_call() except OSError: log('OSError ') Однако здесь вызов after_call() помещен в блок try безо всякой причины. Чтобы код оставался ясным и корректным, в теле блока try должны быть только предложения, которые могут возбуждать ожидаемые исключения. Так лучше: try: dangerous_call() except OSError: log('OSError ') else: after_call() Теперь понятно, что блок try защищает от возможных ошибок внутри dangerous_call() , но не внутри after_call() . Кроме того, явно видно, что after_call() выполняется, только если внутри блока try не было исключений. В Python блок try/except часто используется для управления потоком выпол- нения, а не только для обработки ошибок. В официальном глоссарии Python для этого даже есть специальный акроним (https://docs.python.org/3/glossary. html#term-eafp): EAFP Проще попросить прощения, чем испрашивать разрешение (Easier to ask for forgiveness than permission). Этот принятый в Python стиль программи- рования означает следующее: лучше предположить, что ключ или атрибут существует, и перехватить исключение, если предположение окажется не- верным. Характерной особенностью этого чистого и быстрого стиля яв- ляется изобилие предложений try и except. Эта техника противоположна принятому во многих других языках, включая C, стилю LBYL. Далее в глоссарии определяется акроним LBYL: LBYL Не зная броду, не суйся в воду (Look before you leap). Этот стиль програм- мирования подразумевает проверку предусловий до вызова или поис - ка. Он противоположен стилю EAFP и характеризуется наличием мно- Делай то, потом это: блоки else вне if  639\n--- Страница 639 ---\nгочисленных предложений if. В многопоточной программе стиль LBYL чреват состоянием гонки между проверкой и выполнением. Например, код if key in mapping: return mapping[key] может привести к ошибке, если другой поток удалит ключ из отображения после проверки, но перед выборкой. Эту проблему можно решить с помощью блокировки или программирования в стиле EAFP. Принимая во внимание стиль EAFP, использование блоков else в предложе- ниях try/except выглядит еще более оправданным. Когда обсуждалось предложение match, некоторые (я в том чис- ле) считали, что у него тоже должна быть фраза else. Но в итоге было решено, что она ни к чему, потому что case _: делает то же самое1. Настало время подвести итоги. резюме Мы начали эту главу с рассмотрения контекстных менеджеров и семантики предложения with, не ограничиваясь его типичным применением для авто- матического закрытия файлов. Мы реализовали свой контекстный менеджер: класс LookingGlass с методами __enter__ и __exit__, и показали, как обрабатывать исключения в методе __exit__. Ключевой момент, который Раймонд Хэттин- гер отметил в тезисах к докладу на конференции PyCon US 2013, заключает - ся в том, что блок with – это не только средство для управления ресурсами, но и инструмент, позволяющий выделить общий код инициализации и очистки, да и вообще любую пару операций, которые должны быть выполнены до и пос- ле какой-то другой процедуры2. Мы дали обзор функций в модуле contextlib из стандартной библиотеки. Один из них, декоратор @contextmanager , дает возможность реализовать кон- текстный менеджер с помощью простого генератора с одним предложением yield – что, конечно, более лаконично, чем кодирование класса, содержащего по меньшей мере два метода. Мы переписали класс LookingGlass в виде гене- раторной функции looking_glass и обсудили, как обрабатывать исключения при использовании @contextmanager . Затем изучили элегантный скрипт Питера Норвига lis.py – интерпретатор Scheme, написанный на идиоматичном Python и переработанный с использова- нием match/case в функции evaluate, составляющей ядро интерпретатора. Для по- нимания того, как работает evaluate, нам пришлось сказать несколько слов о язы- ке Scheme, синтаксическом анализаторе S-выражений, простом цикле REPL 1 Наблюдая за дискуссией в списке рассылки python-dev, я пришел к выводу, что одной из причин отказа от else было отсутствие единого мнения о том, какой должен быть отступ внутри match: следует ли помещать else на том же уровне, что match, или на том же уровне, что case? 2 См. слайд 21 презентации «Python is Awesome» (https://speakerdeck.com/pyconslides/ pycon-keynote-python-is-awesome-by-raymond-hettinger?slide=21). 640  Блоки with, match и else\n--- Страница 640 ---\nи построении вложенных областей видимости с помощью класса Environment , на- следующего collection. ChainMap. А в конце lis.py стал для нас полигоном для подроб- ного изучения сопоставления с образцами. Он показывает, как различные части интерпретатора работают совместно, и это помогает лучше понять важные чер- ты самого Python: зачем нужны ключевые слова, как функционируют правила областей видимости, как строятся и используются замыкания. дОпО лнительная литература В главе 8 «Составные предложения» (https://docs.python.org/3/reference/ compound_ stmts.html) справочного руководства по языку Python имеется все, что можно сказать о части else в предложениях if, for, while и try. По поводу использо- вания try/except в духе Python – с else или без – Раймонд Хэттингер дал блес- тящий ответ на вопрос «Хорошо ли использовать try-except-else в Python?» (https://stackoverflow.com/questions/16138232/is-it-a-good-practice-to-use-try-except- else-in-python) на сайте StackOverflow. В книге Алекса Мартелли и др. «Python in a Nutshell», 3-е издание (O’Reilly), имеется глава об исключениях, а в ней – великолепное обсуждение стиля программирования EAFP с отсылкой к одно- му из пионеров вычислительной техники Грэйс Хоппер, придумавшей фразу: «Проще попросить прощения, чем испрашивать разрешение». В главе 4 «Встроенные типы» руководства по стандартной библиотеке Python есть раздел, посвященный типам контекстных менеджеров (http://bit.ly/1MMacTS). Специальные методы __enter__ и __exit__ документированы также в разделе «Контекстные менеджеры и предложение with» справочного руководства по языку Python (https://docs.python.org/3/library/stdtypes.html#typecontextmanager). Идея контекстных менеджеров впервые была изложена в документе PEP 343 «The ‘with’ Statement» (https://www.python.org/dev/peps/pep-0343/). Раймонд Хэттингер в тезисах к докладу на конференции PyCon US 2013 (https://speakerdeck.com/pyconslides/pycon-keynote-python-is-awesome-by-raymond- hettinger?slide=21) назвал предложение with «призовым средством языка». На той же конференции он продемонстрировал несколько интересных приме- нений контекстных менеджеров в выступлении «Преобразование кода в кра- сивую идиоматичную программу на Python» (https://speakerdeck.com/pyconslides/ transforming-code-into-beautiful-idiomatic-python-by-raymond-hettinger-1?slide=34). Статья в блоге Джеффа Прешинга «The Python with Statement by Example» (https:// preshing.com/20110920/the-python-with-statement-by-example/) интересна примерами использования контекстных менеджеров в графической библиотеке pycairo. Класс contextlib.ExitStack основан на идее Николауса Рата, который написал короткую статью, объясняющую, чем он полезен: «On the Beauty of Python’s ExitStack» (https://www.rath.org/on-the-beauty-of-pythons-exitstack.html). Рат пишет, что ExitStack похож, но гибче предложения defer в Go – на мой взгляд, одной из лучших идей в этом языке. Бизли и Джонс предлагают контекстные менеджеры для разных целей в сво- ей книге «Python Cookbook», 3-е издание (O’Reilly). В рецепте 8.3 «Наделение объектов средствами поддержки протокола управления контекстом» реализо- ван класс LazyConnection , экземпляры которого являются контекстными менед- жерами, которые автоматически открывают и закрывают сетевое соединение Дополнительная литература  641\n--- Страница 641 ---\nв блоке with. В рецепте 9.22 «Простой способ определения контекстных менед- жеров» описываются контекстные менеджеры для хронометража кода транз- акционного изменения объекта list: в блоке with создается копия списка, и все изменения производятся в этой копии. И лишь если блок with завершается без исключений, рабочая копия заменяет исходный список. Просто и остроумно. Питер Норвиг описал свои компактные интерпретаторы языка Scheme в ста- тьях «How to Write a (Lisp) Interpreter (in Python)» (https://norvig.com/lispy.html) и «An ((Even Better) Lisp) Interpreter (in Python)» (https://norvig.com/lispy2.html). Код lis.py и lispy.py находится в репозитории norvig/pytudes (https://github.com/norvig/pytudes). В моем репозитории fluentpython/lispy ( https://github.com/fluentpython/lispy) есть клон mylis скрипта lis.py, переработанный с учетом новшеств в версии Python 3.10, с улучшенным циклом REPL, интеграцией с командной строкой, примерами, до- полнительными тестами и ссылками для желающих ближе познакомиться с язы- ком Scheme. Самый лучший диалект Scheme и среда для изучения и эксперимен- тов – Racket (https://racket-lang.org/). Поговорим Выделение хлеба из бутерброда В тезисах к докладу на конференции PyCon US 2013 «What Makes Python Awesome» (http://pyvideo.org/video/1669/keynote-3) Раймонд Хэттингер признал- ся, что, впервые увидев предложение по реализации предложения with, он счел его «несколько заумным». И у меня поначалу была такая же реакция. Чи- тать PEP’ы зачастую довольно трудно, и PEP 343 в этом отношении типичен. Но потом, – как сказал нам Хэттингер, – его посетило озарение: подпрограм- мы – самое важное изобретение в истории языков программирования. Если имеются последовательности операций A;B;C и P;B;Q, то B можно выделить в виде подпрограммы. Это как выделение начинки сэндвича: тунца можно положить на разные куски хлеба. Но что, если требуется выделить сам хлеб и использовать пшеничный хлеб с разными начинками? Именно в этом и со- стоит смысл предложения with. Это дополнение к подпрограммам. Хэттингер продолжает: Предложение with – могучая штука. Я всем советую не ограничиваться поверхностным знакомством, а копнуть глубже. С его помощью можно делать поразительные вещи. И самые интересные из них еще не открыты. Я полагаю, что если мы сможем найти этому механизму хорошие приме- нения, то он войдет и в другие языки, во все будущие языки. Вы можете принять участие в деянии столь же великом, как изобретение подпро- грамм. Хэттингер признает, что немного перебрал с восхвалением with. Тем не менее это действительно очень полезное средство. Когда он воспользовался анало- гией с сэндвичем для объяснения того, как with дополняет подпрограммы, перед моим мысленным взором возник целый ряд возможностей. Если вы захотите убедить кого-то в превосходных качествах Python, посмот- рите видео тезисов Хэттингера. Часть, относящаяся к контекстным менедже- рам, занимает время с 23:00 до 26:15. Но вообще весь материал великолепен.642  Блоки with, match и else\n--- Страница 642 ---\nЭффективная хвостовая рекурсия В стандартных реализациях Scheme требуется поддержка чисто хвостовой рекурсии (proper tail calls – PTC), чтобы замена итерации рекурсией ста- ла практической альтернативой циклам while в императивных языках. Не- которые авторы называют PTC оптимизацией хвостовой рекурсии (tail call optimization – TCO), для других TCO представляется чем-то совершенно иным. Дополнительные сведения см. в статье Википедии «Tail call» (https:// en.wikipedia.org/wiki/Tail_call) и в статье «Tail call optimization in ECMAScript 6» (https://2ality.com/2015/06/tail-call-optimization.html). Хвостовой вызов имеет место, когда функция возвращает результат некото- рого вызова функции – самой себя или какой-то другой. В примерах функции gcd 18.10 и 18.11 рекурсивные хвостовые вызовы производятся в ветви if, вы- полняемой, когда условие ложно. С другой стороны, в следующей функции factorial хвостового вызова нет: def factorial(n): if n < 2: return 1 return n * factorial(n - 1) Вызов factorial в последней строке не является хвостовым, потому что зна- чение return не является результатом рекурсивного вызова: этот результат умножается на n перед возвратом. В примере ниже имеет место хвостовой вызов, поэтому такая функция явля- ется хвостово-рекурсивной: def factorial_tc(n, product=1): if n < 1: return product return factorial_tc(n - 1, product * n) В Python нет PTC, поэтому от написания хвостово-рекурсивных функций мы никакого навара не получим. А раз так, то первая версия кажется мне более короткой и понятной. Кстати, при разработке реальных программ имей- те в виду, что в Python имеется функция math.factorial , написанная на C без всякой рекурсии. Проблема в том, что даже в языках, где PTC реализована, дивиденды получают не все рекурсивные функции, а только специально на- писанные, так чтобы имел место хвостовой вызов. Если PTC поддерживается языком, то интерпретатор, видя хвостовой вызов, переходит прямо в тело вызываемой функции, не создавая новый кадр стека, что экономит память. Есть также компилируемые языки, в которых реализо- вана PTC, иногда в качестве оптимизации, включаемой по желанию. Не существует единого мнения об определении TCO или ценности PTC в языках, которые с самого начала не проектировались как функциональ- ные, например Python или JavaScript. В функциональных языках PTC явля- ется ожидаемым свойством, а не просто оптимизацией, которую хорошо бы иметь. Если в языке нет никакого механизма итерации, кроме рекурсии, то PTC необходима из практических соображений. В скрипте Норвига lis. py PTC не реализована, но в его же более развитом интерпретаторе lispy.py она есть. Дополнительная литература  643\n--- Страница 643 ---\nВозражения против хвостовой рекурсии в Python и JavaScript В CPython PTC не реализована и, скорее всего, никогда не будет. Гвидо ван Рос- сум в статье «Final Words on Tail Calls» (http://neopythonic.blogspot.com/2009/04/final- words-on-tail-calls.html) объясняет, почему. Приведу главный абзац этой статьи: Лично мне кажется, что в некоторых языках это средство представля- ет ценность, но не думаю, что оно подходит для Python: исключение из трассы стека одних вызовов и оставление других, безусловно, вы- зовет смятение у многих пользователей, которые не воспитывались в традициях хвостовой рекурсии, но, возможно, постигали семантику вызовов, трассируя их в отладчике. В 2015 году PTC была включена в стандарт ECMAScript 6 для JavaScript. По со- стоянию на октябрь 2021 года интерпретатор, входящий в WebKit (https:// webkit.org/blog/6240/ecmascript-6-proper-tail-calls-in-webkit/), ее реализует. WebKit используется в браузере Safari. Интерпретаторы JS во всех остальных ос- новных браузерах обходятся без PTC, как и Node.js, поскольку он опирает - ся на движок V8, который используется в Chrome и сопровождается Google. Транспиляторы и полифилы, транслирующие на JS, например TypeScript, ClojureScript и Babel, тоже не поддерживают PTC, как следует из таблицы со- вместимости с ECMAScript 6 (http://kangax.github.io/compat-table/es6/). Я встречал несколько объяснений бойкота PTC со стороны разработчиков, но самое распространенное – то, о чем говорил Гвидо ван Россум: PTC усложняет отладку для всех, а преимущества получают только те немногие, кто предпо- читает использовать рекурсию вместо итерации. Подробнее см. в статье Грэ- хема Марлоу «What happened to proper tail calls in JavaScript?» (https://world.hey. com/mgmarlow/what-happened-to-proper-tail-calls-in-javascript-5494c256). Бывают случаи, когда рекурсия является наилучшим решением, даже в Python без PTC. В предыдущей статье (http://neopythonic.blogspot.com/2009/04/tail- recursion-elimination.html) на эту тему Гвидо писал: […] типичная реализация Python допускает глубину рекурсии 1000. Этого вполне хватает для нерекурсивного кода и для кода, который прибегает к рекурсии для обхода, например, типичного дерева син- таксического разбора, но недостаточно, если большой список обхо- дится в рекурсивном цикле. Я согласен с Гвидо и с большинством разработчиков JS: PTC не годится для Python или JavaScript. Отсутствие PTC – главное препятствие для написания на Python программ в функциональном стиле, более серьезное, чем ограни- ченный синтаксис lambda. Если вам интересно, как PTC работает в интерпретаторе, менее функциональ- но насыщенном (и более коротком), чем скрипт lispy.py Норвига, посмотрите мой скрипт mylis_2 ( https://github.com/fluentpython/lispy/blob/main/mylis/mylis_2/lis.py). Хитрость кроется в бесконечном цикле в evaluate и в коде в ветви case для вы- зова функций: эта комбинация заставляет интерпретатор перейти в тело сле- дующей Procedure, не вызывая evaluate рекурсивно в хвостовом вызове. Такие маленькие интерпретаторы демонстрируют мощь абстракции: хотя в самом Python нет PTC, вполне возможно и даже не очень трудно написать на Python интерпретатор, который реализует PTC. Как это делается, я узнал, читая код Питера Норвига. Спасибо, что поделились, профессор!644  Блоки with, match и else\n--- Страница 644 ---\nЗамечание Норвига касательно evaluate() с сопоставлением с образцом Я отправил версию lis.py для Python 3.10 Питеру Норвигу. Пример ему по- нравился, но он предложил другое решение: вместо моих охранных условий он посоветовал иметь ровно одну ветвь case для каждого ключевого слова и производить проверки внутри case, чтобы выдавать более точные сообще- ния SyntaxError – например, когда тело пусто. Заодно это сделало бы ненуж - ным охранное условие в ветви case [func_exp, *args] if func_exp not in KEYWORDS: , потому что каждое ключевое слово обрабатывалось бы раньше, чем case для вызовов функций. Я, наверное, последую совету Норвига, когда буду добавлять функциональ- ность в mylis. Но способ, которым я структурировал evaluate в примере 18.17, имеет педагогическую ценность именно в этой книге: код легко сравнить с реализацией с помощью if/elif/… (пример 2.11), ветви case демонстрируют дополнительные возможности сопоставления с образцом, да и короче вышло. Дополнительная литература  645",
      "debug": {
        "start_page": 611,
        "end_page": 644
      }
    },
    {
      "name": "Глава 19. Модели конкурентности в Python 646",
      "content": "--- Страница 645 --- (продолжение)\nГлава 19 Модели конкурентности в Python Предмет конкурентности – как управиться со многими вещами одновре- менно. Предмет параллелизма – как делать много вещей одновременно. Не одно и то же, но близко. Первое касается структуры, второе – выполнения. Конкурентность предлагает способ структурировать решение задачи, ко- торая, возможно (но необязательно), поддается распараллеливанию. – Роб Пайк, соавтор языка Go1 Это глава о том, как заставить Python делать «много вещей одновременно». Для этого может понадобиться конкурентное или параллельное программиро- вание – даже ученые, строго следящие за употреблением терминологии, не со- гласны в том, как использовать эти термины. Я буду придерживаться неформаль- ных определений Роба Пайка, вынесенных в эпиграф к этой главе, но замечу, что встречал статьи и книги, написанные, по заявлению авторов, о параллельных вычислениях, хотя на самом деле были посвящены в основном конкурентности2. С точки зрения Пайка, параллелизм – частный случай конкурентности. Все параллельные системы являются конкурентными, но обратное неверно. В на- чале 2000-х годов мы пользовались одноядерными машинами, которые мог- ли конкурентно выполнять 100 процессов в GNU Linux. Современный ноутбук с 4 ядрами спокойно выполняет более 200 процессов в каждый момент вре- мени при нормальной повседневной загрузке. Чтобы выполнить 200 задач параллельно, нужно 200 ядер. Поэтому на практике большая часть вычисле- ний производится конкурентно, а не параллельно. ОС управляет сотнями про- цессов, гарантируя каждому возможность продвигаться вперед, даже если сам процессор может делать не более четырех вещей одновременно. 1 Слайд 8 доклада «Concurrency Is Not Parallelism» (https://go.dev/blog/waza-talk). 2 Я учился, а затем работал с профессором Имре Саймоном, который говаривал, что в науке есть два главных греха: использование разных слов для обозначения одного и того же предмета и использование одного слова для обозначения разных пред- метов. Имре Саймон (1943–2009) был пионером информатики в Бразилии. Он внес значительный вклад в теорию автоматов и стоял у истоков тропической математики. Он также отстаивал принципы бесплатного программного обеспечения и свободной культуры вообще.\nГлава 19 Модели конкурентности в Python Предмет конкурентности – как управиться со многими вещами одновре- менно. Предмет параллелизма – как делать много вещей одновременно. Не одно и то же, но близко. Первое касается структуры, второе – выполнения. Конкурентность предлагает способ структурировать решение задачи, ко- торая, возможно (но необязательно), поддается распараллеливанию. – Роб Пайк, соавтор языка Go1 Это глава о том, как заставить Python делать «много вещей одновременно». Для этого может понадобиться конкурентное или параллельное программиро- вание – даже ученые, строго следящие за употреблением терминологии, не со- гласны в том, как использовать эти термины. Я буду придерживаться неформаль- ных определений Роба Пайка, вынесенных в эпиграф к этой главе, но замечу, что встречал статьи и книги, написанные, по заявлению авторов, о параллельных вычислениях, хотя на самом деле были посвящены в основном конкурентности2. С точки зрения Пайка, параллелизм – частный случай конкурентности. Все параллельные системы являются конкурентными, но обратное неверно. В на- чале 2000-х годов мы пользовались одноядерными машинами, которые мог- ли конкурентно выполнять 100 процессов в GNU Linux. Современный ноутбук с 4 ядрами спокойно выполняет более 200 процессов в каждый момент вре- мени при нормальной повседневной загрузке. Чтобы выполнить 200 задач параллельно, нужно 200 ядер. Поэтому на практике большая часть вычисле- ний производится конкурентно, а не параллельно. ОС управляет сотнями про- цессов, гарантируя каждому возможность продвигаться вперед, даже если сам процессор может делать не более четырех вещей одновременно. 1 Слайд 8 доклада «Concurrency Is Not Parallelism» (https://go.dev/blog/waza-talk). 2 Я учился, а затем работал с профессором Имре Саймоном, который говаривал, что в науке есть два главных греха: использование разных слов для обозначения одного и того же предмета и использование одного слова для обозначения разных пред- метов. Имре Саймон (1943–2009) был пионером информатики в Бразилии. Он внес значительный вклад в теорию автоматов и стоял у истоков тропической математики. Он также отстаивал принципы бесплатного программного обеспечения и свободной культуры вообще.\n--- Страница 646 ---\nВ этой главе у читателя не предполагается предварительных знаний о кон- курентном или параллельном программировании. После краткого концепту - ального введения мы изучим простые примеры, на которых познакомимся с основными пакетами конкурентного программирования в Python – threading, multiprocessing и asyncio – и сравним их. Последние 30 % главы – общий обзор сторонних инструментов, библиотек, серверов приложений и распределенных очередей задач. Все они могут повы- сить производительность и масштабируемость Python-приложений. Это важ- ные темы, но они выходят за рамки книги, посвященной базовым возможно- стям языка Python. Тем не менее я счел необходимым уделить им внимание во втором издании книги, потому что применимость Python в области конку - рентных и параллельных вычислений не ограничивается тем, что предлагает стандартная библиотека. Именно поэтому YouTube, DropBox, Instagram, Reddit и другие смогли подстроиться под масштабы веба с момента своего основа- ния, хотя использовали Python в качестве основного языка – вопреки настой- чивым заявлениям о том, что «Python не масштабируется». чтО нОвОг О в этОй главе Этой главы не было в первом издании. Примеры анимированного индикатора в разделе «Конкурентная программа Hello World» ранее приводились в главе, посвященной asyncio. Здесь они улучшены и дают первое представление о трех подходах к конкурентности в Python: потоках, процессах и платформенных сопрограммах. Весь остальной материал новый, за исключением нескольких абзацев, взя- тых из прежних глав о concurrent.futures и asyncio. Раздел «Python в многоядерном мире» отличается от остальной книги: в нем нет примеров кода. Моей целью было рассказать о важных инструментах, ко- торые вы, возможно, захотите изучить, чтобы достичь такой производитель- ности конкурентности и параллелизма, которая выходит за рамки возможно- стей стандартной библиотеки Python. ОБщая картина Факторов, осложняющих конкурентное программирование, много, но я хочу остановиться на самом главном: запустить процессы или потоки легко, но как потом отслеживать их1? Когда мы вызываем функцию, вызывающая программа блокируется, пока функция не вернет управление. В этот момент мы знаем, что функция за- вершила свою работу, и легко можем получить возвращенное значение. Если функция возбуждает исключение, то вызывающая программа может окружить ее операторными скобками try/except и перехватить ошибку. Эти хорошо знакомые действия неприменимы, когда запускается поток или процесс: нет никакого способа автоматически узнать, когда он завершился, 1 Этот раздел предложил мой друг Брюс Эккель – автор книг о языках Kotlin, Scala, Java, и C++. Общая картина  647\n--- Страница 647 ---\nа для получения результатов или ошибок нужно организовать какой-то ком- муникационный канал, например очередь сообщений. Кроме того, запуск потока или процесса обходится недешево, поэтому вряд ли стоит это делать, только чтобы выполнить какое-то одно вычисление. Часто мы хотим амортизировать стоимость запуска, сделав поток или процесс «рабо- чей лошадкой», т. е. исполнителем, который входит в цикл и ждет поступления входных данных, которые нужно обработать. Это еще больше осложняет взаи- модействие и ставит новые вопросы. Как заставить исполнителя завершиться, когда необходимость в нем отпала? И как это сделать, не прервав работу на самом интересном месте, в результате чего могли бы остаться недообработан- ные данные и неосвобожденные ресурсы, например открытые файлы? И снова стандартные ответы подразумевают использование сообщений и очередей. Запустить сопрограмму несложно. Если для этого использовать ключевое сло- во await, то легко будет получить возвращенное значение, легко отменить сопро- грамму, и есть точно определенное место, в котором следует перехватывать ис- ключения. Но сопрограммы обычно запускаются каким-то асинхронным карка- сом, поэтому наблюдать за ними так же трудно, как за потоками или процессами. Наконец, как мы увидим, сопрограммы и потоки не подходят для счетных задач, активно потребляющих процессор. Поэтому конкурентное программирование требует овладения новыми идея- ми и приемами кодирования. Но сначала договоримся об основных терминах. немнОг О терминО лОгии Ниже приведены термины, которыми я буду пользоваться в этой и двух по- следующих главах. Конкурентность Способность обрабатывать несколько задач, чередуя выполнение или па- раллельно (если это возможно), так что каждая задача в конечном итоге успешно доходит до конца или завершается с ошибкой. Одноядерный про- цессор допускает конкурентность, если работает под управлением плани- ровщика ОС, который чередует выполнение ожидающих задач. Встречает - ся также название многозадачность. Параллелизм Способность выполнять несколько вычислений одновременно. Для этого необходим многоядерный процессор, несколько процессоров, графиче- ский процессор (GPU) или кластер из нескольких компьютеров. Единица выполнения Общий термин для объектов, выполняющих код конкурентно, каждый из ко- торых имеет независимые от других состояния и стек вызовов. Python под- держивает три вида единиц выполнения: процессы, потоки и сопрограммы. Процесс Экземпляр компьютерной программы во время ее выполнения, которо- му выделены память и квант процессорного времени. Современные опе- рационные системы для настольных компьютеров без труда управляют 648  Модели конкурентности в Python\n--- Страница 648 ---\nсотнями конкурентных процессов, при этом каждый процесс изолирован в собственном адресном пространстве. Процессы взаимодействуют по- средством каналов, сокетов или отображенных на память файлов – все они могут передавать только «голые» байты. Чтобы передать объект Python из одного процесса в другой, его необходимо сериализовать в виде последо- вательности байтов. Это дорого, и не все объекты допускают сериализа- цию. Процесс может порождать подпроцессы, или дочерние процессы. Они изолированы как друг от друга, так и от родительского процесса. Процессы допускают вытесняющую многозадачность: планировщик ОС периодиче- ски вытесняет, т. е. приостанавливает, работающий процесс, чтобы дать возможность поработать остальным. Это означает, что зависший процесс не может подвесить всю систему – теоретически. Поток Единица выполнения внутри одного процесса. Сразу после запуска процесс содержит один – главный – поток. Вызывая системные API, процесс может создавать дополнительные потоки, которые будут работать конкурентно. Потоки внутри одного процесса разделяют общее пространство памяти, в которой находятся активные объекты Python. Это позволяет потокам со- вместно использовать данные, но может приводить к повреждению дан- ных, если сразу несколько потоков пытаются обновить один и тот же объ- ект. Как и процессы, потоки допускают вытесняющую многозадачность под управлением планировщика ОС. Поток потребляет меньше ресурсов, чем процесс, для выполнения одной и той же работы. Сопрограмма Функция, которая может приостановить свое выполнение и продолжить позже. В Python классические сопрограммы строятся на основе генератор- ных функций, а платформенные определяются с помощью ключевых слов async def. В разделе «Классические сопрограммы» главы 17 это понятие было определено, а в главе 21 будет рассмотрено использование платформенных сопрограмм. В Python сопрограммы обычно исполняются в одном потоке под управлением цикла событий, который работает в том же потоке. Такие каркасы асинхронного программирования, как asyncio, Curio или Trio, пре- доставляют цикл событий и поддерживающие библиотеки для реализации неблокирующего ввода-вывода на основе сопрограмм. Сопрограммы под- держивают кооперативную многозадачность: каждая сопрограмма должна явно уступать процессор с помощью ключевого слова yield или await, чтобы другие части программы могли работать конкурентно (но не параллельно). Это означает, что любой блокирующий код внутри сопрограммы блокирует выполнение цикла событий и всех остальных сопрограмм – в отличие от вытесняющей многозадачности, которую поддерживают процессы и пото- ки. С другой стороны, сопрограммы потребляют меньше ресурсов по срав- нению с процессами и потоками, выполняющими ту же работу. Очередь Структура данных, позволяющая помещать и извлекать элементы, обычно в порядке FIFO: первым пришел, первым ушел. Очереди дают возможность Немного терминологии  649\n--- Страница 649 ---\nединицам выполнения обмениваться данными и управляющими сообще- ниями, например кодами ошибок и сигналами завершения. Реализация очереди зависит от модели конкурентности: пакет queue в стандартной биб- лиотеке Python предоставляет классы очередей для поддержки потоков, тогда как пакеты multiprocessing и asyncio реализуют собственные классы очередей. Пакеты queue и asyncio включают также очереди, обслуживаемые не в порядке FIFO: LifoQueue и PriorityQueue . Блокировка Объект, который единицы выполнения могут использовать для синхро- низации своих действий, чтобы избежать повреждения данных. Во вре- мя обновления разделяемой структуры данных исполняемый код дол- жен удерживать ассоциированную блокировку. Это служит для осталь- ных частей программы сигналом, что нужно подождать, пока блокиров- ка освободится, и только потом обращаться к той же структуре данных. Простейший вид блокировки называется мьютексом (mutual exclusion – взаимное исключение). Реализация блокировки зависит от модели кон- курентности. Состязание Спор за ограниченный ресурс. Состязание возникает, когда несколько еди- ниц выполнения пытаются обратиться к разделяемому ресурсу, например блокировке или хранилищу. Бывает также состязание за процессор, когда счетные процессы или потоки должны ждать, пока планировщик ОС вы- делит им долю процессорного времени. Теперь воспользуемся введенной терминологией, чтобы понять, как конку - рентность поддерживается в Python. Процессы, потоки и знаменитая блокировка GIL в Python Ниже описано, как только что рассмотренные понятия применяются в контек - сте программирования на Python. 1. Каждый экземпляр интерпретатора Python является процессом. До- полнительные процессы Python можно запускать с помощью библиотек multiprocessing или concurrent.futures. Библиотека subprocess предназна- чена для запуска процессов, в которых будут исполняться внешние про- граммы, написанные на любом языке. 2. Интерпретатор Python использует единственный поток, в котором вы- полняется и пользовательская программа, и сборщик мусора. Для за- пуска дополнительных потоков предназначены библиотеки threading и concurrent.futures. 3. Доступ к счетчикам ссылок на объекты и другим внутренним структу - рам интерпретатора контролируется глобальной блокировкой интер- претатора (Global Interpreter Lock – GIL). Только один поток Python мо- жет удерживать GIL в каждый момент времени. Это означает, что только один поток может выполнять Python-код, и от числа процессорных ядер это не зависит.650  Модели конкурентности в Python\n--- Страница 650 ---\n4. Чтобы помешать потоку Python удерживать GIL бесконечно, интерпре- татор байт-кода Python периодически (по умолчанию раз в 5 миллисе- кунд1) приостанавливает текущий поток и тем самым освобождает GIL. Поток может попытаться снова захватить GIL, но если его ждут другие потоки, то планировщик ОС, возможно, выберет один из них. 5. Программист, пишущий на Python, не может управлять GIL. Но встро- енная функция или расширение, написанное на C или на любом другом языке, имеющем интерфейс к Python на уровне C API, может освободить GIL во время выполнения длительной задачи. 6. Любая стандартная библиотечная функция Python, делающая систем- ный вызов2, освобождает GIL. Сюда относятся все функции, выполня- ющие дисковый ввод-вывод, сетевой ввод-вывод, а также time.sleep() . Многие счетные функции в библиотеках NumPy/SciPy, а также функции сжатия и распаковки из модулей zlib и bz2 также освобождают GIL3. 7. Расширения, интегрированные на уровне интерфейса между Python и C, могут тоже запускать потоки, не управляемые Python, на которые дей- ствие GIL не распространяется. Такие свободные от GIL потоки в общем случае не могут изменять объекты Python, но могут читать и записывать память объектов, поддерживающих протокол буфера, например bytearray, array.array и массивы NumPy. 8. Влияние GIL на сетевое программирование с помощью потоков Python сравнительно невелико, потому что функции ввода-вывода освобож - дают GIL, а чтение или запись в сеть всегда подразумевает высокую за- держку по сравнению с чтением-записью в память. Следовательно, каж- дый отдельный поток все равно тратит много времени на ожидание, так что их выполнение можно чередовать без заметного снижения общей пропускной способности. Потому-то Дэвид Бизли и говорил: «Python от- лично умеет ничего не делать»4. 9. Состязание за GIL замедляет работу счетных потоков в Python. В таких случаях последовательный однопоточный код проще и быстрее. 10. Для выполнения счетного Python-кода на нескольких ядрах нужно ис- пользовать несколько процессов Python. Процитируем удачное резюме из документации по модулю threading5: 1 Функция sys.getswitchinterval() возвращает текущее значение интервала, а функция sys.setswitchinterval(s) изменяет его. 2 Системным вызовом называется обращение из пользовательского кода к функции, находящейся в ядре операционной системы. Ввод-вывод, таймеры и блокировки – примеры служб ядра, доступных через системные вызовы. Дополнительные сведе- ния можно почерпнуть из статьи Википедии «System call» (https://en.wikipedia.org/wiki/ System_call). 3 Модули zlib и bz2 специально отмечены в сообщении Антуана Питру (он добавил GIL с квантованием времени в Python 3.2) в списке рассылки python-dev (https://mail. python.org/pipermail/python-dev/2009-October/093356.html). 4 Источник: слайд 106 пособия Бизли «Generators: The Final Frontier» (http://www.dabeaz. com/finalgenerator/). 5 Источник: последний абзац раздела «Объекты потоков» (https://docs.python.org/3/ library/threading.html#thread-objects). Немного терминологии  651\n--- Страница 651 ---\nДеталь реализации CPython. В CPython, из-за глобальной блокировки ин- терпретатора, в каждый момент времени Python-код может выполнять- ся только одним потоком (хотя некоторые высокопроизводительные библио теки умеют обходить это ограничение). Если вы хотите, чтобы приложение более эффективно использовало вычислительные ресурсы многоядерных машин, то пользуйтесь модулем multiprocessing или клас - сом concurrent.futures.ProcessPoolExecutor . Однако многопоточное выпол- нение все же является вполне пригодной моделью, если требуется одно- временно выполнять несколько задач с большим объемом ввода-вывода. Этот пассаж начинается словами «Деталь реализации CPython», потому что GIL не является частью определения языка Python. В реализациях Jython и IronPython нет GIL. К сожалению, обе они сильно отстают – все еще остаются на уровне Python 2.7. В высокопроизводительном интерпретаторе PyPy (https:// www.pypy.org/) GIL тоже имеется – в версиях 2.7 и 3.7 (последняя датирована июнем 2021 года). В этом разделе не упоминаются сопрограммы, потому что по умолчанию все они вкупе с управляющим циклом событий, кото- рый предоставлен каркасом асинхронного программирования, работают в одном потоке, поэтому GIL не оказывает на них ни- какого влияния. Можно использовать несколько потоков в асин- хронной программе, но рекомендуется, чтобы и цикл событий, и все сопрограммы исполнялись в одном потоке, а дополнитель- ные потоки выделять для специальных задач. Мы объясним эту идею в разделе «Делегирование задач исполнителям» главы 21. Но хватит пока теории. Посмотрим на код. кОнкурентная прОграмма hello world Говоря о потоках и о том, как избежать GIL, соразработчик Python Мишель Си- мионато опубликовал пример (https://mail.python.org/pipermail/python-list/2009- February/675659.html), похожий на конкурентную «Hello World» – простейшую программу, показывающую, как Python может «идти и одновременно жевать резинку». В программе Симионато используется модуль multiprocessing , а я дополни- тельно адаптировал ее под threading и asyncio. Начнем с версии для threading, ко- торая может показаться знакомой тем, кто изучал потоки в Java или C. Анимированный индикатор с потоками Идея следующих далее примеров проста: запустить функцию, которая блоки- рует выполнение на 3 секунды, пока чередует символы на экране терминала, давая пользователю понять, что программа «думает», а не зависла. Скрипт выводит анимированный индикатор, т. е. отображает символы из строки «\\|/-» в одной и той же позиции экрана1. По завершении медленного вычисления строка индикатора очищается и выводится результат: Answer: 42 . 1 В Unicode немало символов, полезных для простых анимаций, например знаки алфа- вита Брайля. Я использовал ASCII-символы \"\\|/-\", чтобы не усложнять пример. 652  Модели конкурентности в Python\n--- Страница 652 ---\nНа рис. 19.1 показано, что выводят две версии примера: первая с потоками, вторая с сопрограммами. Если вы далеко от компьютера, то представьте себе, что знак \\ в последней строке крутится. Рис. 19.1. Скрипты spinner_thread.py и spinner_asyncio.py порождают похожие результаты: repr-представление объекта spinner и текст Answer: 42 . На снимке экрана скрипт spinner_ asyncio.py еще работает, поэтому отображается сообщение \\ thinking! ; когда скрипт завер- шится, эту строку заменит Answer: 42 Сначала рассмотрим скрипт spinner_thread.py. В примере 19.1 показаны пер- вые две функции скрипта, а в примере 19.2 все остальное. Пример 19.1. spinner_thread.py: функции spin и slow import itertools import time from threading import Thread, Event def spin(msg: str, done: Event) -> None:  for char in itertools.cycle(r'\\|/-'):  status = f'\\r{char} {msg}'  print(status, end='', flush=True) if done.wait(.1):  break  blanks = ' ' * len(status) print(f'\\r{blanks}\\r', end='')  def slow() -> int: time.sleep(3)  return 42  Эта функция будет работать в отдельном потоке. Аргумент done, экземпляр класса threading.Event , – простой объект для синхронизации потоков.  Это бесконечный цикл, потому что itertools.cycle отдает по одному символу за раз и перебирает заданную строку по кругу.  Хитрость, позволяющая выполнить анимацию в текстовом режиме: воз- вращаем курсор в начало строки, печатая управляющий символ возврата каретки ( '\\r').  Метод Event.wait(timeout=None) возвращает True, когда другой поток установил событие; если же истек тайм-аут timeout, то он возвращает False. Тайм-аут .1s означает, что анимация производится с частотой 10 кадров в секунду. Чтобы индикатор крутился быстрее, задайте тайм-аут поменьше.  Выйти из бесконечного цикла.  Очистить строку состояния, затирая ее пробелами и возвращая курсор в начало строки. Конкурентная программа Hello World  653\n--- Страница 653 ---\n Функция slow() вызывается из главного потока. Представьте, что это вызов медленного API по сети. Вызов sleep блокирует главный поток, но GIL при этом освобождается, поэтому поток индикатора продолжает работать. В этом примере нужно обратить внимание на то, что time.sleep() блокирует вызывающий поток, но освобождает GIL, позволяя работать другим потокам Python. Функции spin и slow будут выполняться параллельно. Главный поток – един- ственный существующий в начале работы программы – запускает новый по- ток, исполняющий spin, а затем вызывает slow. В Python сознательно не преду - смотрен API для завершения потока. Чтобы остановить поток, ему необходимо отправить сообщение. Класс threading.Event – самый простой из имеющихся в Python механизмов сигнализации для координации потоков. В экземпляре Event имеется внутрен- ний булев флаг, который первоначально равен False. Вызов Event.set() устанав- ливает этот флаг в True. Если флаг равен False, то поток, вызвавший Event.wait() , блокируется до тех пор, пока какой-нибудь другой поток не вызовет Event.set() , и в этот момент Event.wait() возвращает True. Если функции Event.wait(s) передан тайм-аут в секундах, то по истечении тайм-аута этот вызов вернет False (или True, если раньше какой-то другой поток вызовет Event.set() ). Функция supervisor в примере 19.2 использует Event как сигнал о том, что spin должна закончить работу. Пример 19.2. spinner_thread.py: функции supervisor и main def supervisor() -> int:  done = Event()  spinner = Thread(target=spin, args=('thinking!', done))  print(f'spinner object: {spinner}')  spinner.start()  result = slow()  done .set()  spinner.join()  return result def main() -> None: result = supervisor()  print(f'Answer: {result}') if __name__ == '__main__': main()  supervisor возвращает результат slow.  Экземпляр threading.Event – ключ к координации потоков main и spinner, как будет объяснено ниже.  Чтобы создать новый экземпляр Thread, задайте функцию в именованном аргументе target, а необходимые ей позиционные аргументы передавайте в кортеже args. 654  Модели конкурентности в Python\n--- Страница 654 ---\n Отобразить объект spinner. Результатом будет представление <Thread(Thread-1, initial)>, где initial – состояние потока, означающее, что он еще не запущен.  Запустить поток spinner.  Вызвать функцию slow, которая блокирует поток main. Тем временем второй поток выполняет анимацию индикатора.  Установить флаг Event в True; в результате произойдет выход из цикла for в функции spin.  Ждать завершения потока spinner.  Вызвать функцию supervisor . Я разделил функции main и supervisor , чтобы этот пример больше походил на версию с asyncio в примере 19.4. Когда поток main устанавливает событие done, поток spinner замечает это и за- вершается чисто. Теперь рассмотрим аналогичный пример с использованием пакета multiprocessing . Индикатор с процессами Пакет multiprocessing поддерживает выполнение конкурентных задач в от - дельных процессах Python вместо потоков. После создания экземпляра multiprocessing.Process в дочернем процессе запускается новый интерпретатор Python, работающий в фоновом режиме. Так как у каждого процесса Python свой собственный GIL, это дает программе потенциальную возможность ис- пользовать все доступные процессорные ядра, но будет ли ей это позволено, зависит от планировщика операционной системы. Практические последствия мы увидим в разделе «Доморощенный пул процессов» ниже, но для нашей простой программы всё это не имеет значения. Цель этого раздела – познакомиться с пакетом multiprocessing и показать, что его API эмулирует API threading, что упрощает переход от потоков к процессам в простых программах, как показано в скрипте spinner_proc.py (пример 19.3). Пример 19.3. spinner_proc.py: показаны только изменившиеся части; весь остальной код та- кой же, как в spinner_thread.py import itertools import time from multiprocessing import Process, Event  from multiprocessing import synchronize  def spin(msg: str, done: synchronize.Event) -> None:  # [опущено] функции spin и slow не изменились по сравнению со spinner_thread.py def supervisor() -> int: done = Event() spinner = Process(target=spin,  args=('thinking!', done)) print(f'spinner object: {spinner}')  spinner.start() result = slow() done.set() spinner.join() return result # [опущено] функция main тоже не изменилась Конкурентная программа Hello World  655\n--- Страница 655 ---\n Базовый API multiprocessing имитирует API threading, но аннотации типов и Mypy выявляют различие: multiprocessing.Event – функция (а не класс, как threading.Event ), которая возвращает synchronize.Event …  … что вынуждает нас импортировать multiprocessing.synchronize …  … чтобы записать эту аннотацию типа.  Простое использование класса Process похоже на Thread.  Объект spinner отображается как <Process name='Process-1' parent=14868 initial> , где 14868 – идентификатор процесса Python, в котором исполняется скрипт spinner_proc.py. Базовые API пакетов threading и multiprocessing похожи, но их реализации сильно различаются, а API multiprocessing гораздо обширнее, что отражает слож - ность многопроцессного программирования. Например, одна из сложностей, возникающих при переходе от потоков к процессам, – как обеспечить взаи- модействие процессов, которые изолированы операционной системой и не могут разделять объекты Python. Это означает, что объекты, пересекающие границы процессов, необходимо сериализовывать и десериализовывать, неся на это дополнительные затраты. В примере 19.3 границу процессов пересекает только состояние Event, которое реализовано низкоуровневым семафором на уровне ОС в написанном на C коде модуля multiprocessing1. Начиная с версии Python 3.8 в стандартной библиотеке имеет - ся пакет multiprocessing.shared_memory , но он не поддерживает экземпляры пользовательских классов. Помимо необработан- ных байтов, этот пакет позволяет процессам разделять объекты ShareableList – это тип изменяемой последовательности, кото- рый может содержать фиксированное число элементов типа int, float, bool и None, а также str и bytes размером не более 10 МБ каждый. Дополнительные сведения см. в документации по классу ShareableList (https://docs.python.org/3/library/multiprocessing. shared_memory.html#multiprocessing.shared_memory.ShareableList). Теперь посмотрим, как такого же поведения можно достичь с помощью со- программ вместо потоков и процессов. Индикатор с сопрограммами Глава 21 целиком посвящена асинхронному программирова- нию с использованием сопрограмм. Здесь же приводится только общее введение, позволяющее сравнить этот подход с моделями конкурентности на основе потоков и процессов. Поэтому мно- гие детали опущены. Выделение процессорного времени потокам и процессам – задача планиров- щика ОС. C другой стороны, сопрограммы приводятся в действие циклом со- 1 Семафор – это фундаментальный строительный блок, который можно использовать для реализации механизмов синхронизации. Python предлагает различные классы семафоров для использования совместно с потоками, процессами и сопрограмма- ми. С классом asyncio.Semaphore мы познакомимся в разделе «Использование asyncio. as_completed и Thread» главы 21. 656  Модели конкурентности в Python\n--- Страница 656 ---\nбытий, находящимся на уровне приложения. Он управляет очередью ожидаю- щих активации сопрограмм, выполняет их по одной, отслеживает события, ге- нерируемые операциями ввода-вывода, инициированными сопрограммами, и возвращает управление соответствующей сопрограмме, когда такое событие происходит. Цикл событий, библиотечные и пользовательские сопрограммы выполняются в одном потоке. Поэтому когда какая-то сопрограмма расходует время, замедляется цикл событий – и все остальные сопрограммы. Вариант программы индикатора с сопрограммами будет проще понять, если начать с функции main, а затем перейти к supervisor . Обе показаны в при- мере 19.4. Пример 19.4. spinner_async.py: функция main и сопрограмма supervisor def main() -> None:  result = asyncio.run(supervisor())  print(f'Answer: {result}') async def supervisor() -> int:  spinner = asyncio.create_task(spin('thinking!'))  print(f'spinner object: {spinner}')  result = await slow()  spinner.cancel()  return result if __name__ == '__main__': main()  main – единственная настоящая функция в этой программе, все остальные – сопрограммы.  Функция asyncio.run запускает цикл событий, активирующий сопрограм- му, которая в конечном итоге приведет в действие и другие сопрограммы. Функция main остается блокированной, пока supervisor не вернет управле- ние. Значение, возвращенное supervisor , станет значением, возвращенным asyncio.run .  Платформенные сопрограммы определяются с помощью ключевых слов async def.  asyncio.create_task планирует выполнение spin сразу после возврата экзем- пляра asyncio.Task .  Представление repr объекта spinner имеет вид <Task pending name='Task-2' coro=<spin() running at /path/to/spinner_async.py:11>> .  Ключевое слово await вызывает slow, блокируя supervisor до возврата из slow. Значение, возвращенное slow, присваивается переменной result.  Метод Task.cancel возбуждает исключение CancelledError внутри сопрограммы spin, как мы увидим в примере 19.5. В примере 19.4 демонстрируется три основных способа выполнить сопро- грамму: asyncio.run(coro()) Вызывается из регулярной функции для управления объектом сопрограм- мы, который обычно является точкой входа в весь асинхронный код про- граммы, как supervisor в этом примере. Этот вызов блокирует выполнение, Конкурентная программа Hello World  657\n--- Страница 657 ---\nпока coro не вернет управление. Функция run() возвращает значение, воз- вращенное coro. asyncio.create_task(coro()) Вызывается из сопрограммы, чтобы запланировать выполнение другой сопрограммы. Этот вызов не приостанавливает текущую сопрограмму. Он возвращает экземпляр Task – объект, который обертывает объект сопро- граммы и предоставляет методы для управления ей и опроса ее состояния. await coro() Вызывается из сопрограммы, чтобы передать управление объекту сопро- граммы, возвращенному coro(). Этот вызов приостанавливает текущую со- программу до возврата из coro. Значением выражения await является значе- ние, возвращенное coro. Запомните: вызов сопрограммы как coro() сразу же возвращает объект сопрограммы, но не выполняет тело функции coro. Акти- вация тел сопрограмм – задача цикла событий. Теперь рассмотрим сопрограммы spin и slow в примере 19.5. Пример 19.5. spinner_async.py: сопрограммы spin и slow import asyncio import itertools async def spin(msg: str) -> None:  for char in itertools.cycle(r'\\|/-'): status = f'\\r{char} {msg}' print(status, flush=True, end='') try: await asyncio.sleep(.1)  except asyncio.CancelledError:  break blanks = ' ' * len(status) print(f'\\r{blanks}\\r', end='') async def slow() -> int: await asyncio.sleep(3)  return 42  Нам не нужен аргумент Event, который в spinner_thread.py (пример 19.1) ис- пользовался, чтобы просигнализировать о завершении slow.  Использовать await asyncio.sleep(.1) вместо time.sleep(.1) , чтобы приостано- вить выполнение без блокировки других сопрограмм. См. эксперимент пос ле этого примера.  Когда вызывается метод cancel объекта Task, управляющего этой сопрограм- мой, возбуждается исключение asyncio.CancelledError . Время выходить из цикла.  Сопрограмма slow также использует await asyncio.sleep вместо time.sleep . 658  Модели конкурентности в Python\n--- Страница 658 ---\nЭксперимент: ломаем индикатор ради озарения Я рекомендую провести следующий эксперимент, чтобы понять, как работает spinner_async.py. Импортируйте модуль time, затем перейдите к сопрограмме slow и замените строку await asyncio.sleep(3) вызовом time.sleep(3) , как в при- мере 19.6. Пример 19.6. spinner_async.py: замена await asyncio.sleep(3) на time.sleep(3) async def slow() -> int: time.sleep(3) return 42 Наблюдение за поведением лучше запоминается, чем чтение текста. Давай- те, я подожду. Вот что вы увидите при проведении эксперимента. 1. Отображается представление объекта индикатора в виде <Task pending name='Task-2' coro=<spin() running at /path/to/spinner_async.py:12>> . 2. Сам индикатор так и не появляется. Программа висит 3 секунды. 3. Отображается сообщение Answer: 42 , и программа завершается. Чтобы понять, что происходит, вспомним, что в Python-коде, где использу - ется asyncio, есть лишь один поток выполнения, если только явно не запуще- ны дополнительные потоки или процессы. Это значит, что в каждый момент времени выполняется всего одна сопрограмма. Конкурентность достигается путем передачи управления от одной сопрограммы к другой. В примере 19.7 мы сосредоточимся на том, что происходит в сопрограммах supervisor и slow в предложенном эксперименте. Пример 19.7. spinner_async_experiment.py: сопрограммы supervisor и slow async def slow() -> int: time.sleep(3) return 42  async def supervisor() -> int: spinner = asyncio.create_task(spin('thinking!'))  print(f'spinner object: {spinner}')  result = await slow()  spinner.cancel()  return result  Создается задача spinner, чтобы в конечном итоге активировать выполне- ние spin.  На экране показано, что Task находится в состоянии «pending».  Выражение await передает управление сопрограмме slow.  time.sleep(3) блокирует выполнение на 3 секунды; в программе ничего не может произойти, потому что главный поток блокирован, а он един- ственный. Операционная система продолжит заниматься другими делами. Спустя 3 секунды sleep завершается, выполнение возобновляется и slow возвращает управление.  Сразу после возврата из slow задача spinner отменяется. Поток управления так и не дошел до тела сопрограммы spin. Конкурентная программа Hello World  659\n--- Страница 659 ---\nСкрипт spinner_async_experiment.py преподал нам важный урок, который объ- ясняется в следующем предупреждении. Никогда не используйте time.sleep(…) в сопрограммах asyncio, если не хотите приостановить всю программу в целом. Если со- программа хочет потратить некоторое время, ничего не делая, она должна вызвать await asyncio.sleep(DELAY) . Так она уступит управление циклу событий asyncio, который может дать порабо- тать другим ожидающим сопрограммам. Greenlet и gevent Говоря об организации конкурентности на основе сопрограмм, важно упомя- нуть пакет greenlet ( https://greenlet.readthedocs.io/en/latest/), существующий уже много лет и активно используемый1. Этот пакет поддерживает кооператив- ную многозадачность с помощью облегченных сопрограмм – гринлетов, – ко- торые не требуют специального синтаксиса типа yield или await, а потому про- ще интегрируются с уже имеющимися последовательными кодовыми база- ми. В каркасе объектно-реляционных отображений SQL Alchemy 1.4 гринлеты используются на внутреннем уровне (https://docs.sqlalchemy.org/en/14/changelog/ migration_14.html#asynchronous-io-support-for-core-and-orm) для реализации ново- го асинхронного API (https://docs.sqlalchemy.org/en/14/orm/extensions/asyncio.html), совместимого с asyncio. Сетевая библиотека gevent ( http://www.gevent.org/) занимается партизанским латанием стандартного модуля socket и делает его неблокирующим путем за- мены части кода гринлетами. Эта библиотека в значительной степени про- зрачна для окружающего кода, что упрощает адаптацию последовательных приложений и библиотек (например, драйверов баз данных) к выполнению конкурентного сетевого ввода-вывода. gevent применяется во многих проек - тах с открытым исходным кодом (https://github.com/gevent/gevent/wiki/Projects), в т. ч. в широко распространенном проекте Gunicorn (https://gunicorn.org/), упо- мянутом в разделе «Серверы приложений WSGI» ниже. Сравнение супервизоров Количество строк в скриптах spinner_thread.py и spinner_async.py почти одина- ково. Главным в этих примерах являются функции supervisor . Давайте сравним их. В примере 19.8 показана только функция supervisor из примера 19.2. Пример 19.8. spinner_thread.py: многопоточная функция supervisor def supervisor() -> int: done = Event() spinner = Thread(target=spin, args=('thinking!', done)) print('spinner object:', spinner) spinner.start() 1 Спасибо техническим рецензентам Калебу Хэттингу и Юргену Гмаху, не давшим мне пройти мимо greenlet и gevent. 660  Модели конкурентности в Python\n--- Страница 660 ---\nresult = slow() done.set() spinner.join() return result Для сравнения в примере 19.9 показана сопрограмма supervisor из примера 19.4. Пример 19.9. spinner_async.py: асинхронная сопрограмма supervisor async def supervisor() -> int: spinner = asyncio.create_task(spin('thinking!')) print('spinner object:', spinner) result = await slow() spinner.cancel() return result Перечислим заслуживающие внимания сходства и различия между обеими реализациями supervisor : класс asyncio.Task приблизительно эквивалентен threading.Thread ; Task управляет объектом сопрограммы, а Thread обращается к вызывае- мому объекту; сопрограмма уступает управление явно с помощью ключевого слова await ; мы не создаем объекты Task самостоятельно, а получаем их, передавая сопрограмму функции asyncio.create_task(…) ; когда asyncio.create_task(…) возвращает объект Task, его выполнение уже запланировано, тогда как экземпляру Thread нужно явно сказать, что пора выполняться, вызвав его метод start ; в многопоточной версии supervisor slow является простой функцией и не- посредственно вызывается из главного потока. В асинхронной же вер- сии slow – сопрограмма, активируемая await ; не существует API для завершения потока извне, вместо этого нужно по- слать потоку сигнал, например установить объект Event done. Для задач су- ществует метод экземпляра Task.cancel() , который возбуждает исключе- ние CancelledError в том выражении await, в котором в настоящий момент приостановлено выполнение тела сопрограммы; сопрограмму supervisor нужно запускать с помощью asyncio.run в функции main. Это сравнение поможет вам понять, как asyncio координирует конкурент - ные задания и чем его подход отличается от принятого в модуле Threading, с ко - торым вы, возможно, лучше знакомы. И последний момент, отличающий потоки от сопрограмм: если вы когда- нибудь писали нетривиальную программу с потоками, то знаете, как трудно рассуждать о поведении программы, которую планировщик может прервать в любое время. Нужно не забыть поставить блокировки, защищающие крити- ческие секции программы, чтобы ее не прервали в середине многошаговой операции, что могло бы оставить данные в некорректном состоянии. В случае сопрограмм код по умолчанию защищен от прерывания. Вы долж - ны явно выполнить await, чтобы другие части программы могли поработать. Вместо синхронизации потоков с помощью блокировок сопрограммы «син- Конкурентная программа Hello World  661\n--- Страница 661 ---\nхронизированы» по определению: в каждый момент времени может работать только одна. Желая добровольно отказаться от владения процессором, мы используем await, чтобы уступить управление планировщику. Именно поэто- му сопрограмму можно безопасно отменить: по определению, сопрограмма может быть отменена только тогда, когда приостановлена в выражении await, и ничто не мешает произвести очистку, обработав исключение CancelledError . Вызов time.sleep() блокирует выполнение, но ничего не делает. В следующем эксперименте мы рассмотрим вызов счетной функции, чтобы лучше понять GIL, а также оценить влияние счетных функций на асинхронный код. Истинное влияние GIL В многопоточном коде (пример 19.1) вызов time.sleep(3) в функции slow можно заменить клиентским HTTP-запросом из какой-нибудь библиотеки, и индика- тор продолжит крутиться. Объясняется это тем, что правильно спроектирован- ная сетевая библиотека освобождает GIL на время ожидания ответа из сети. Выражение asyncio.sleep(3) в сопрограмме slow можно заменить выражени- ем await, ожидающим ответа от хорошо спроектированной сетевой библиоте- ки, потому что такие библиотеки предоставляют сопрограммы, уступающие управление циклу событий на время ожидания ответа. А тем временем инди- катор продолжает крутиться. В случае счетного кода все обстоит иначе. Рассмотрим функцию is_prime в примере 19.10, которая возвращает True, если аргумент – простое число, а иначе False. Пример 19.10. primes.py: элементарная проверка на простоту из примера ProcessPoolExecutor в документации по Python (https://docs.python.org/3/library/ concurrent. futures.html#processpoolexecutor-example) def is_prime(n: int) -> bool: if n < 2: return False if n == 2: return True if n % 2 == 0: return False root = math.isqrt(n) for i in range(3, root + 1, 2): if n % i == 0: return False return True Вызов is_prime(5_000_111_000_222_021) занимает примерно 3.3 с на корпоратив- ном ноутбуке, которым я сейчас пользуюсь1. Проверка знаний Вспомните все, чему вы научились, и попробуйте ответить на следующий во- прос, состоящий из трех частей. Одна часть трудная (по крайней мере, оказа- лась такой для меня). 1 MacBook Pro 2018 с 15-дюймовым экраном и 6-ядерным процессором Intel Core i7 2.2 ГГц.662  Модели конкурентности в Python\n--- Страница 662 ---\nЧто произойдет с анимацией индикатора, если произвести следующие изменения в предположении, что n = 5_000_111_000_222_021 – простое чис- ло, для проверки которого на моей машине потребовалось 3.3 с: 1. В spinner_proc.py заменить time.sleep(3) вызовом is_prime(n) ? 2. В spinner_thread.py заменить time.sleep(3) вызовом is_prime(n) ? 3. В spinner_async.py заменить await asyncio.sleep(3) вызовом is_prime(n) ? Прежде чем выполнять код или читать дальше, попробуйте найти ответы самостоятельно. А потом можете скопировать скрипты spinner_*.py и модифи- цировать их, как предложено. А теперь ответы, от самого простого к самому трудному. 1. Ответ для multiprocessing Индикатор управляется дочерним процессом, поэтому будет крутиться и тог - да, когда родительский процесс проверяет число на простоту1. 2. Ответ для threading Индикатор управляется дополнительным потоком, поэтому будет крутиться и тогда, когда главный поток проверяет число на простоту. Я пришел к этому ответу не сразу: я ожидал, что индикатор прекратит кру- титься, потому что переоценил воздействие GIL. В этом примере индикатор продолжает крутиться, потому что Python при- останавливает работающий поток раз в 5 мс (по умолчанию), делая GIL до- ступной другим ожидающим потокам. Поэтому главный поток, исполняющий is_prime, прерывается каждые 5 мс, так что у дополнительного потока есть воз- можность проснуться и выполнить одну итерацию цикла for, в конце которой он вызовет метод wait события done и освободит GIL. Затем главный поток за- хватит GIL и вычисление is_prime продолжится на протяжении следующих 5 мс. Это не оказывает видимого влияния на время работы этого конкретного при- мера, поскольку функция spin быстро выполняет одну итерацию и освобождает GIL в ожидании события done, поэтому интенсивность состязания за GIL невели- ка. Главный поток, исполняющий is_prime, владеет GIL большую часть времени. В этом простом примере мы разобрались со счетной задачей, потому что потоков всего два: один на всю катушку загружает процессор, а второй про- сыпается жалкие 10 раз в секунду, чтобы обновить индикатор. Но если потоков два или больше и все они алчно потребляют процессорное время, то программа будет работать медленнее, чем последовательный код. 3. Ответ для asyncio Если вызвать is_prime(5_000_111_000_222_021) в сопрограмме slow в примере spinner_async.py, то индикатор вообще не появится на экране. Эффект бу- 1 В наши дни это так, потому что вы, скорее всего, пользуетесь современной ОС с вы- тесняющей многозадачностью. Но Windows до эры NT и macOS до эры OS X не были «вытесняющими», поэтому любой процесс мог захватить процессор на 100 %, в ре- зультате чего вся система подвисала. Даже сегодня мы не совсем ушли от этой проб- лемы, но поверьте старику: в 1990-х она терзала всех пользователей, а единственным лечением был аппаратный сброс. Конкурентная программа Hello World  663\n--- Страница 663 ---\nдет такой же, как в примере 19.6, где мы заменили await asyncio.sleep(3) на time.sleep(3) : никакого вращения. Поток управления переходит от supervisor к slow и затем к is_prime. Когда is_prime возвращается, то же самое делает и slow, и supervisor возобновляет работу и отменяет задачу spinner, не дав ей выпол- ниться даже один раз. Выглядит это так, будто программа зависла на 3 с, а затем выдала ответ. Здоровый сон с помощью sleep(0) Один из способов не дать индикатору умереть – переписать is_prime в виде сопрограммы, которая периодически вызывает asyncio.sleep(0) в выражении await, чтобы уступить управление циклу событий. Пример 19.11. spinner_async_nap.py: is_prime – теперь сопрограмма async def is_prime(n): if n < 2: return False if n == 2: return True if n % 2 == 0: return False root = math.isqrt(n) for i in range(3, root + 1, 2): if n % i == 0: return False if i % 100_000 == 1: await asyncio.sleep(0)  return True  Спать после каждых 50 000 итераций (потому что шаг в функции range ра- вен 2). В проблеме 284 (https://github.com/python/asyncio/issues/284) в репозитории asyncio имеется содержательное обсуждение использования asyncio.sleep(0) . Однако имейте в виду, что это замедляет работу is_prime и – что еще важнее – цикл событий, а вместе с ним и всю программу. Когда я вставлял await asyncio. sleep(0) через каждые 100 000 итераций, индикатор крутился плавно, но про- грамма на моей машине работала 4.9 с, т. е. почти на 50 % дольше, чем при использовании оригинальной функции primes.is_prime с тем же аргументом (5_000_111_000_222_021 ). Использование await asyncio.sleep(0) следует рассматривать как временную меру перед рефакторингом асинхронного кода с целью делегирования дли- тельных вычислений другому процессу. Как это сделать с помощью функ - ции asyncio.loop.run_in_executor (https://docs.python.org/3/library/asyncio-eventloop. html#asyncio.loop.run_in_executor), мы увидим в главе 21. Еще один вариант – ор- ганизовать очередь задач – мы кратко обсудим в разделе «Распределенные очереди задач» ниже.664  Модели конкурентности в Python\n--- Страница 664 ---\nДо сих пор мы экспериментировали лишь с одним обращением к счетной функции. В следующем разделе представлено конкурентное выполнение не- скольких счетных вызовов. дОмОр Ощенный пул прОцеССОв Я написал этот раздел, чтобы продемонстрировать использова- ние нескольких процессов для решения счетных задач, а также типичный паттерн использования очередей для распределе- ния задач и сбора результатов. В главе 20 будет показан более простой способ распределения задач между процессами: класс ProcessPoolExecutor из пакета concurrent.futures , который внутри себя пользуется очередями. В этом разделе мы напишем программы, которые проверяют на простоту вы- борку из 20 чисел от 2 до 9 999 999 999 999 999, т. е. 1016 – 1, больше чем 253. Выборка содержит большие и малые простые числа, а также составные числа с большими и малыми простыми множителями. Программа sequential.py определяет эталон для сравнения. Вот пример ее прогона: $ python3 sequential.py 2 P 0.000001s 142702110479723 P 0.568328s 299593572317531 P 0.796773s 3333333333333301 P 2.648625s 3333333333333333 0.000007s 3333335652092209 2.672323s 4444444444444423 P 3.052667s 4444444444444444 0.000001s 4444444488888889 3.061083s 5555553133149889 3.451833s 5555555555555503 P 3.556867s 5555555555555555 0.000007s 6666666666666666 0.000001s 6666666666666719 P 3.781064s 6666667141414921 3.778166s 7777777536340681 4.120069s 7777777777777753 P 4.141530s 7777777777777777 0.000007s 9999999999999917 P 4.678164s 9999999999999999 0.000007s Total time: 40.31 Три столбца интерпретируются следующим образом: проверяемое число; P, если число простое, иначе пробел; время проверки этого числа на простоту. В этом примере полное время работы приближенно равно сумме времен каждой проверки, но вычисляется независимо, как показано в примере 19.12. Доморощенный пул процессов  665\n--- Страница 665 ---\nПример 19.12. sequential.py: последовательная проверка на простоту для небольшого на- бора данных #!/usr/bin/env python3 \"\"\" sequential.py: эталон для сравнения последовательного, многопроцессного и многопоточного кода счетной задачи. \"\"\" from time import perf_counter from typing import NamedTuple from primes import is_prime, NUMBERS class Result(NamedTuple):  prime: bool elapsed: float def check(n: int) -> Result:  t0 = perf_counter() prime = is_prime(n) return Result(prime, perf_counter() - t0) def main() -> None: print(f'Checking {len(NUMBERS)} numbers sequentially:') t0 = perf_counter() for n in NUMBERS:  prime, elapsed = check(n) label = 'P' if prime else ' ' print(f'{n:16} {label} {elapsed:9.6f}s') elapsed = perf_counter() - t0  print(f'Total time: {elapsed:.2f}s') if __name__ == '__main__': main()  Функция check (см. следующий маркер) возвращает кортеж Result, содержащий булево значение, возвращенное вызовом is_prime, и время его вычисления.  check(n) вызывает is_prime(n) и вычисляет время, потребовавшееся для воз- врата Result.  Для каждого числа из выборки вызываем check и отображаем результат.  Вычислить и показать полное время работы. Решение на основе процессов В следующем примере, procs.py, показано использование нескольких процес - сов для распределения проверок на простоту между процессорными ядрами. А это полученные результаты: $ python3 procs.py Checking 20 numbers with 12 processes: 2 P 0.000002s 3333333333333333 0.000021s 4444444444444444 0.000002s666  Модели конкурентности в Python\n--- Страница 666 ---\n5555555555555555 0.000018s 6666666666666666 0.000002s 142702110479723 P 1.350982s 7777777777777777 0.000009s 299593572317531 P 1.981411s 9999999999999999 0.000008s 3333333333333301 P 6.328173s 3333335652092209 6.419249s 4444444488888889 7.051267s 4444444444444423 P 7.122004s 5555553133149889 7.412735s 5555555555555503 P 7.603327s 6666666666666719 P 7.934670s 6666667141414921 8.017599s 7777777536340681 8.339623s 7777777777777753 P 8.388859s 9999999999999917 P 8.117313s 20 checks in 9.58s Последняя строка показывает, что procs.py работала в 4.2 раза быстрее, чем sequential.py. Интерпретация времени работы Отметим, что время работы в третьем столбце относится только к проверке данного конкретного числа. Например, на вычисление is_prime(7777777777777753) ушло почти 8.4 с. А в это время другие процессы параллельно проверяли дру- гие числа. Всего нужно было проверить 20 чисел. Я написал procs.py, так что количество рабочих процессов равно числу процессорных ядер, возвращенному функцией multiprocessing.cpu_count() . Общее время в этом случае гораздо меньше суммы времен отдельных про- верок. С контекстным переключением процессов и межпроцессным взаимо- действием сопряжены некоторые накладные расходы, поэтому в итоге мы по- лучили ускорение только в 4,2 раза по сравнению с последовательной версией. Это хорошо, но немного разочаровывает, учитывая, что программа запустила 12 процессов, чтобы задействовать все имеющиеся ядра. Функция multiprocessing.cpu_count() возвращает 2 на моем MacBook Pro. На самом деле это 6-ядерный Core-i7, но ОС со- общает о 12 процессорах, потому что включен режим гипер- трединга – технология Intel, позволяющая выполнять 2 потока на одном ядре. Однако результаты гипертрединга лучше, если один из потоков, занимающих ядро, работает не так интенсив- но, как второй, – скажем, первый ждет данных после непопада- ния в кеш, а в это время второй производит арифметические операции. Как бы то ни было, бесплатных завтраков не бывает: производительность этого ноутбука для счетной задачи, потреб- ляющей мало памяти, например проверки числа на простоту, соответствует 6-ядерной машине. Доморощенный пул процессов  667\n--- Страница 667 ---\nКод проверки на простоту для многоядерной машины Когда мы делегируем вычисления процессам или потокам, программа не вы- зывает рабочую функцию напрямую, поэтому мы не можем просто так по- лучить возвращенное ей значение. Вместо этого исполнитель управляется библиотекой, и она в конечном итоге возвращает результат, который нужно где-то сохранить. Координация исполнителей и сбор результатов – типичные примеры применения очередей в конкурентном программировании, а также в распределенных системах. Значительная часть нового кода в procs.py связана с организацией и исполь- зованием очередей. Начало файла показано в примере 19.13. Класс SimpleQueue был добавлен в пакет multiprocessing в версии Python 3.9. Если вы пользуетесь более ранней версией, то можете заменить SimpleQueue на Queue в примере 19.13. Пример 19.13. procs.py: многопроцессная проверка на простоту; импорт, типы и функции import sys from time import perf_counter from typing import NamedTuple from multiprocessing import Process, SimpleQueue, cpu_count ❶ from multiprocessing import queues ❷ from primes import is_prime, NUMBERS class PrimeResult(NamedTuple): ❸ n: int prime: bool elapsed: float JobQueue = queues.SimpleQueue[int] ❹ ResultQueue = queues.SimpleQueue[PrimeResult] ❺ def check(n: int) -> PrimeResult: ❻ t0 = perf_counter() res = is_prime(n) return PrimeResult(n, res, perf_counter() - t0) def worker(jobs: JobQueue, results: ResultQueue) -> None: ❼ while n := jobs.get(): ❽ results.put(check(n)) ❾ results.put(PrimeResult(0, False, 0.0)) ❿ def start_jobs( procs: int, jobs: JobQueue, results: ResultQueue ⓫ ) -> None: for n in NUMBERS: jobs.put(n) ⓬ for _ in range(procs): proc = Process(target=worker, args=(jobs, results)) ⓭ proc.start() ⓮ jobs .put(0) ⓯ 668  Модели конкурентности в Python\n--- Страница 668 ---\n❶ Стремясь эмулировать threading, пакет multiprocessing предоставляет multiprocessing.SimpleQueue , но это метод, связанный с предопределенным эк- земпляром низкоуровневого класса BaseContext . Мы должны вызвать этот SimpleQueue , чтобы построить очередь, но не можем использовать его в анно- тациях типов. ❷ В модуле multiprocessing.queues есть класс SimpleQueue , который нужен нам в ан- нотациях типов. ❸ PrimeResult включает число, проверяемое на простоту. Хранение n вместе с другими полями результата впоследствии упростит отображение резуль- татов. ❹ Это псевдоним типа SimpleQueue , которым функция main (пример 19.14) будет пользоваться для отправки чисел процессам-исполнителям. ❺ Псевдоним второго типа SimpleQueue , который будет использован для сбора результатов в main. В очереди будут храниться кортежи, состоящие из про- веряемого на простоту числа и кортежа Result. ❻ Это похоже на sequential.py. ❼ worker получает очередь подлежащих проверке чисел и другую очередь, в которую будет помещать результаты. ❽ В этой программе я использую число 0 как отравленную таблетку: сиг- нал исполнителю о необходимости завершиться. Если n не равно 0, то цикл продолжается1. ❾ Инициировать проверку на простоту и поместить PrimeResult в очередь. ❿ Отправить PrimeResult(0, False, 0.0) обратно, чтобы главный цикл знал, что этот исполнитель работу закончил. ⓫ procs – количество процессов, которые будут параллельно проверять числа. ⓬ Поместить подлежащие проверке числа в очередь jobs. ⓭ Создать дочерние процессы для всех исполнителей. Каждый дочерний процесс будет исполнять цикл в собственном экземпляре функции worker, пока не извлечет 0 из очереди jobs. ⓮ Запустить все дочерние процессы. ⓯ Поместить в очередь по одному значению 0 для каждого процесса, чтобы завершить их. Циклы, сигнальные маркеры и отравленные таблетки Функция worker в примере 19.13 следует общему паттерну конкурентного про- граммирования: выбирать элементы из очереди в бесконечном цикле и обра- батывать каждый в функции, которая выполняет фактическую работу. Цикл завершается, когда из очереди извлечен сигнальный маркер. В этом паттерне сигнальный маркер, останавливающий исполнителя, часто называют «отрав- ленной таблеткой». 1 В этом примере 0 – удобный сигнальный маркер. Также для этой цели часто исполь- зуется значение None. Но 0 позволяет упростить аннотацию типа в PrimeResult и код исполнителя. Доморощенный пул процессов  669\n--- Страница 669 ---\nВ роли сигнального маркера нередко выступает значение None, но это не го- дится, если оно может встречаться в потоке данных. Вызов object() – распро- страненный способ получит уникальное значение, которое может служить сигнальным маркером. Однако этот способ не работает, если процессов не- сколько, потому что объекты Python необходимо сериализовать для пере- дачи в другой процесс, а когда мы применяем сначала pickle.dump , а затем pickle.load к экземпляру object, десериализованный экземпляр оказывается отличен от оригинала. Хорошей альтернативой None может служить встроен- ный объект Ellipsis (или …), который не теряет своей идентичности в про- цессе сериализации1. В стандартной библиотеке Python в качестве сигнальных маркеров исполь- зуется много разных значений (https://mail.python.org/archives/list/python-dev@ python.org/message/JBYXQH3NV3YBF7P2HLHB5CD6V3GVTY55/). В документе PEP 661 «Sentinel Values» (https://peps.python.org/pep-0661/) предложен стандарт - ный тип сигнального маркера. Но по состоянию на сентябрь 2021 года он еще не был утвержден. Теперь рассмотрим функцию main в файле procs.py. Пример 19.14. procs.py: многопроцессная проверка на простоту: функция main def main() -> None: if len(sys.argv) < 2:  procs = cpu_count() else: procs = int(sys.argv[1]) print(f'Checking {len(NUMBERS)} numbers with {procs} processes:') t0 = perf_counter() jobs: JobQueue = SimpleQueue()  results: ResultQueue = SimpleQueue() start_jobs(procs, jobs, results)  checked = report(procs, results)  elapsed = perf_counter() - t0 print(f'{checked} checks in {elapsed:.2f}s')  def report(procs: int, results: ResultQueue) -> int:  checked = 0 procs_done = 0 while procs_done < procs:  n, prime, elapsed = results.get()  if n == 0:  procs_done += 1 else: checked += 1  label = 'P' if prime else ' ' print(f'{n:16} {label} {elapsed:9.6f}s') return checked if __name__ == '__main__': main() 1 Пережить сериализацию, не потеряв своей идентичности, – неплохая цель в жизни.670  Модели конкурентности в Python\n--- Страница 670 ---\n Если аргументы в командной строке не заданы, то положить количество процессов равным количеству процессорных ядер, в противном случае создать столько процессов, сколько указано в первом аргументе.  jobs и results – очереди, описанные в примере 19.13.  Запустить proc процессов, которые будут выбирать данные из очереди jobs и посещать результаты в results.  Извлечь и отобразить результаты; функция report определена в точке .  Показать количество проверенных чисел и общее затраченное время.  В качестве аргументов передаются количество процессов procs и очередь для хранения результатов.  Цикл продолжается, пока не завершатся все дочерние процессы.  Получить один PrimeResult . Вызов метода очереди .get() блокирует выполнение до тех пор, пока в очереди не появится элемент. Можно также сделать этот вызов неблокирующим или задать тайм-аут. Детали см. в документации по SimpleQueue.get (https://docs.python.org/3/library/queue.html#queue.SimpleQueue. get).  Если n равно 0, то один процесс завершился; увеличить счетчик procs_done .  В противном случае увеличить счетчик checked (в котором хранится количест во проверенных чисел) и отобразить результаты. Результаты поступают не в том порядке, в каком подавались задания. По- этому я и включил n в кортеж PrimeResult . Иначе я не смог бы сопоставить ре- зультат с проверенным числом. Если главный процесс завершится раньше, чем закончат работу все до- черние, то можно будет увидеть странные трассы вызовов в исключениях FileNotFoundError , вызванные внутренней блокировкой в пакете multiprocessing . Отлаживать конкурентный код вообще трудно, а отлаживать multiprocessing еще труднее, поскольку за фасадом «потокоподобия» скрывается немалая слож - ность. К счастью, класс ProcessPoolExecutor , с которым мы познакомимся в гла- ве 20, проще использовать, и он надежнее. Спасибо читателю Майклу Альберту, который заметил, что в коде примера 19.14, опубликованном в предварительном варианте книги, было состояние гонки ( https://en.wikipedia.org/ wiki/Race_condition). Это ошибка, которая может проявиться или не проявиться в зависимости от порядка действий, выполняе- мых конкурентными единицами выполнения. Если «A» проис - ходит раньше «B», то все хорошо, но если первым происходит «B», значит, что-то пошло не так. Это и есть гонка. Для особо любопытных я оставил дельту, показывающую, в чем со- стояла ошибка и как я ее исправил, см. https://github.com/fluentpython/ example-code-2e/commit/2c1230579db99738a5e5e6802063bda585f6476d, но отмечу, что впоследствии я переработал пример, переместив части main в функции start_jobs и report. В том же каталоге имеет - ся файл README.md, где объясняется проблема и ее решение. Эксперименты с большим и меньшим числом процессов Можете попробовать выполнить procs.py, указав в командной строке количест - во рабочих процессов. Например, следующая команда $ python3 procs.py 2 Доморощенный пул процессов  671\n--- Страница 671 ---\nзапускает два рабочих процесса и работает почти в два раза быстрее, чем sequential.py, при условии что компьютер оснащен хотя бы двумя ядрами и не слишком занят выполнением других программ. Я выполнил procs.py с числом процессов от 1 до 20 по 12 раз для каждого зна- чения, всего 240 прогонов. Затем вычислил медианное время всех прогонов с одним и тем же числом процессов и построил график на рис. 19.2. Рис. 19.2. Медианное время работы для каждого числа процессов от 1 до 20. Наибольшее медианное время составило 40,81 с, когда был всего 1 процесс. Наименьшее время равно 10,39 с при 6 процессах, оно обозначено пунктирной линией На этом 6-ядерном ноутбуке наименьшее медианное время было достиг - нуто при 6 процессах: 10.39 с, обозначенное пунктирной линией на рис. 19.2. Я ожидал, что время работы начнет расти после 6 процессов из-за конкурен- ции за процессоры, и оно действительно достигло локального максимума при 10 процессах. Но вот чего я не ожидал и что не могу объяснить – почему про- изводительность улучшилась при 11 процессах и оставалась почти постоянной при числе процессов от 13 до 20, при этом медианное время лишь немного превышает минимум, достигнутый для 6 процессов. Не решение на основе потоков Я также написал скрипт threads.py, вариант procs.py, в котором вместо multiprocessing используется threading. Код очень похож – так обычно и быва- ет, когда в простых примерах переходишь от одного из этих API к другому1. Из-за GIL и счетного характера функции is_prime многопоточная версия мед- леннее, чем последовательный код в примере 19.12, и замедляется по мере увеличения числа потоков, т. к. растет конкуренция за процессоры и стои- мость контекстного переключения. Чтобы переключиться на другой поток, ОС должна сохранить регистры процессора и изменить счетчик программы и указатель стека, что влечет за собой дорогостоящие побочные эффекты, 1 См. каталог 19-concurrency/primes/threads.py в репозитории кода.672  Модели конкурентности в Python\n--- Страница 672 ---\nнапример недействительность процессорных кешей и, возможно, выгрузку страниц памяти1. В следующих двух главах мы будем еще говорить о конкурентном про- граммировании на Python с использованием высокоуровневой библиотеки concurrent.futures для управления потоками и процессами (глава 20) и библио- теки asyncio для асинхронного программирования (глава 21). А в оставшихся разделах этой главы постараемся ответить на вопрос: С учетом всех описанных выше ограничений как Python удается процве- тать в мире многоядерных компьютеров? python в мнОг ОядернОм мире Рассмотрим следующую цитату из хорошо известной статьи Герба Саттера «The Free Lunch Is Over: A Fundamental Turn Toward Concurrency in Software» (Бесплатные завтраки кончились: фундаментальный поворот к параллелизму в программном обеспечении) (http://www.gotw.ca/publications/concurrency-ddj.htm): Основные производители и архитектуры процессоров, от Intel и AMD до Sparc и PowerPC, практически исчерпали большинство традиционных подходов к увеличению производительности процессоров. От поднятия тактовой частоты и прямолинейного увеличения пропускной способно- сти команд массово поворачиваются в сторону гипертрединга и много- ядерных архитектур. Март 2005 года. (Доступно в сети.) Саттер называет «бесплатным завтраком» стремление заставить про- граммы работать быстрее без дополнительных усилий со стороны разработ - чика, потому что процессоры с каждым годом исполняли последовательный код все быстрее и быстрее. Но начиная с 2004 года это уже не так: тактовая частота и оптимизация выполнения достигли плато, и теперь всякое сколь- ко-нибудь существенное повышение производительности возможно только благодаря задействованию нескольких ядер или гипертрединга, а эти пре- имущества доступны лишь коду, специально написанному для конкурент - ного выполнения. История Python началась в начале 1990-х годов, когда производительность выполнения последовательного кода все еще росла по экспоненте. Тогда о многоядерных процессорах говорили только в контексте суперкомпьюте- ров. В то время решение завести GIL представлялось очевидным. Благодаря GIL интерпретатор работает быстрее на одном ядре, а его реализация упро- щается2. Кроме того, GIL упрощает написание простых расширений с помо- щью Python/C API. 1 Дополнительные сведения см. в статье Википедии «Context switch» (https://en.wikipedia. org/wiki/Context_switch). 2 Вероятно, по тем же причинам Юкихиро Мацумото, создатель языка Ruby, тоже ре- шил использовать GIL в своем интерпретаторе. Python в многоядерном мире  673\n--- Страница 673 ---\nЯ написал «простые расширения», потому что расширение вообще-то не обязано иметь хоть какое-то отношение к GIL. Функция, написанная на C или на Fortran, может работать в сот - ни раз быстрее, чем эквивалентная ей на Python1. Поэтому до- полнительная сложность, связанная с освобождением GIL, что- бы можно было воспользоваться всеми ядрами многоядерного процессора, во многих случаях и не нужна. Так что мы можем поблагодарить GIL за многочисленные расширения, доступные для Python, а это, конечно, одна из причин, по которым язык так популярен сегодня. Несмотря на GIL, Python прекрасно себя чувствует в приложениях, нуждаю- щихся в конкурентном или параллельном выполнении, благодаря библиоте- кам и программным архитектурам, которые позволяют обойти ограничения CPython. Теперь обсудим, как Python применяется для системного администрирова- ния, в науке о данных и при разработке серверных приложений в распреде- ленном мире многоядерных компьютеров, существующем в 2021 году. Системное администрирование Python широко применяется для управления большими парками серверов, маршрутизаторов, балансировщиков нагрузки и сетевых устройств хранения (NAS). Он также занимает лидирующие позиции в области программно-кон- фигурируемых сетей (SDN) и этического хакинга. Главные поставщики облач- ных служб поддерживают Python в своих библиотеках и пособиях, написанных как самими поставщиками, так и многочисленными сложившимися вокруг них сообществами пользователей Python. В этой области Python-скрипты автоматизируют задачи конфигурирования, выдавая команды, подлежащие выполнению удаленными машинами, поэтому счетные операции встречаются редко. Потоки и сопрограммы прекрасно при- способлены для задач такого рода. В частности, пакет concurrent.futures , который мы будем изучать в главе 20, можно использовать для выполнения одних и тех же операций на большом числе удаленных машин одновременно, не сильно увеличивая сложность. Помимо стандартной библиотеки, существуют популярные основанные на Python проекты для управления кластерами серверов: инструменты типа Ansible ( https://www.ansible.com/) и Salt, а также библиотеки типа Fabric ( https:// www.fabfile.org/). Постоянно растет число библиотек для системного администрирования с поддержкой сопрограмм и asyncio. В 2016 году группа организации производ- ства компании Facebook писала в отчете (https://engineering.fb.com/2016/05/27/ production-engineering/python-in-production-engineering/): «Мы все сильнее полага- емся на пакет AsyncIO, появившийся в версии Python 3.4, и наблюдаем огром- ный рост производительности при переводе кодовой базы с Python 2». 1 В колледже я должен был в качестве упражнения реализовать на С алгоритм сжа- тия LZW. Но сначала я написал его на Python, чтобы проверить, правильно ли понял спецификацию. Так вот, версия на C оказалась примерно в 900 раз быстрее. 674  Модели конкурентности в Python\n--- Страница 674 ---\nНаука о данных Для науки о данных, включая искусственный интеллект, и научных расчетов в Python имеется прекрасная поддержка. В этих предметных областях прило- жения в основном счетные, но у пользователей Python есть преимущество – обширная экосистема библиотек для численных расчетов, написанных на C, C++, Fortran, Cython и т. д., многие из которых способны задействовать не- сколько ядер, GPU и (или) распределенные параллельные вычисления в гете- рогенных кластерах. По состоянию на 2021 год экосистема науки о данных в Python включала, в частности, следующие впечатляющие инструменты: Проект Jupyter (https://jupyter.org/) Два основанных на браузере интерфейса, Jupyter Notebook и JupyterLab, позволяют пользователям выполнять и документировать аналитический код, который может при необходимости работать на удаленных маши- нах. Оба являются гибридными приложениями, написанными на Python и JavaScript, поддерживают вычислительные ядра, написанные на других языках, и интегрированы с помощью ZeroMQ, библиотеки организации асинхронных сообщений для распределенных приложений. Название Jupyter происходит от Julia, Python и R – первых трех языков, поддержан- ных системой Notebook. Развитая экосистема, построенная поверх инстру - ментария Jupyter, включает Bokeh (https://docs.bokeh.org/en/latest/index.html), мощную интерактивную библиотеку визуализации, которая дает пользо- вателям возможность взаимодействовать с большими наборами данных или непрерывно обновляемыми потоковыми данными – благодаря высо- кой производительности современных движков JavaScript и браузеров. TensorFlow и PyTorch Это две самые популярные библиотеки глубокого обучения, согласно от- чету издательского дома O’Reilly за январь 2021 года (https://www.oreilly.com/ radar/where-programming-ops-ai-and-the-cloud-are-headed-in-2021/ ) об использо- вании их образовательных ресурсов в течение 2020 года. Оба проекта на- писаны на C++ и способны задействовать несколько ядер, GPU и кластеры. Они имеют интерфейсы и к другим языкам, но Python стоит на первом месте и имеет наибольшее число пользователей. TensorFlow была создана в Google и используется там для внутренних целей; PyTorch разработана компанией Facebook. Dask Библиотека параллельных вычислений, которая может распределять ра- боту между локальными процессами или кластерами компьютеров, «про- тестирована на некоторых из крупнейших в мире суперкомпьютеров», как утверждается на домашней странице проекта (https://dask.org/). Dask пред- лагает API, имеющие много общего с NumPy, pandas и scikit-learn – самы- ми популярными библиотеками в науке о данных и машинном обучении на сегодняшний день. Dask можно использовать из JupyterLab или Jupyter Notebook, она обращается к Bokeh не только для визуализации данных, но и как к интерактивной контрольной панели, на которой отображаются пото- Python в многоядерном мире  675\n--- Страница 675 ---\nки данных и вычислений в различных процессах и компьютерах в режиме, близком к реальному времени. Dask настолько впечатляет, что я рекомен- дую посмотреть видео, например 15-минутный ролик по адресу https://www. youtube.com/watch?v=ods97a5Pzw0, в котором Мэттью Роклин, отвечающий за сопровождение проекта, демонстрирует, как Dask перемалывает данные на 64 ядрах, распределенных между 8 машинами типа EC2 в облаке AWS. И это лишь несколько примеров, иллюстрирующих, как сообщество науки о данных создает решения, способные использовать лучшее из предлагаемого Python и преодолевать ограничения среды выполнения CPython. Веб-разработка на стороне сервера и на мобильных устройствах Python широко используется в веб-приложениях и для создания серверных API, поддерживающих мобильные приложения. Как Google, YouTube, Dropbox, Instagram, Quora и Reddit (в числе прочих) сумели построить на Python сер- верные приложения, обслуживающие сотни миллионов пользователей в ре- жиме 24×7? Ответ выходит за рамки того, что Python предлагает «из коробки». Прежде чем обсуждать инструменты для поддержки Python в крупномас - штабных приложениях, я обязан процитировать увещевание из издания «Technology Radar» компании Thoughtworks: Зависть к высокой производительности и масштабу веба Мы видели, как многие команды попадали впросак, т. к. выбирали слож - ные инструменты, каркасы или архитектуры, потому что «в будущем, возможно, придется масштабироваться». Такие компании, как Twitter и Netflix, вынуждены поддерживать экстремальные нагрузки, поэтому не могут обойтись без подобных архитектур, но они располагают пер- соналом высочайшей квалификации, способным справиться с их слож - ностью. В большинстве ситуаций такие инженерные подвиги ни к чему; команде следует отказаться от зависти к масштабу веба в пользу более простых решений, позволяющих решить задачу1. В масштабе веба ключом является архитектура, допускающая горизонталь- ное масштабирование. На этом уровне все системы распределенные, и вряд ли найдется единственный язык программирования, который лучше всего отве- чает потребностям каждой части решения. Распределенные системы – область академических исследований, но, к сча- стью, есть доступные книги, написанные практиками и основанные на фун- даментальных исследованиях и практическом опыте. Один из таких практи- ков – Мартин Клеппманн, автор книги «Designing Data-Intensive Applications» (O’Reilly). Взгляните на рис. 19.3, первую из многочисленных архитектурных диа- грамм в книге Клеппманна. Приведу несколько компонентов, которые встре- 1 Источник: «Консультативный совет по технологиям Thoughtworks», Technology Radar ноябрь 2015 (https://www.thoughtworks.com/radar/techniques/high-performance-envy-web- scale-envy).676  Модели конкурентности в Python\n--- Страница 676 ---\nчались мне в использующих Python организациях, где я работал или о которых я знаю не понаслышке: кеши приложений1: memcached, Redis, Varnish; реляционные базы данных: PostgreSQL, MySQL; документные базы данных: Apache CouchDB, MongoDB; полнотекстовые индексы: Elasticsearch, Apache Solr; очереди сообщений: RabbitMQ, Redis. Кеш в памяти Основная база данныхAPI Код приложения Код приложенияКод приложенияКлиентские запросы Инвалидировать или обновить кешАсинхронные задачи Поисковые запросы «Внешний мир»Очередь сообщенийОтсутствие в кеше и запросы на записьЗапросы на чтение сначала проверить, есть ли данные в кеше Полнотек- стовый индекс например, отправить по электронной почтеПрименение обновлений к поисковому индексуСбор изменений, внесенных в данные Рис. 19.3. Одна из возможных архитектур для системы, содержащей несколько компонентов2 В каждой из этих категорий существуют и другие продукты с открытым ис- ходным кодом производственного уровня. Крупные облачные поставщики также предлагают собственные альтернативы. Диаграмма Клеппманна является общей и от языка не зависит – как и вся его книга. В серверных приложениях на Python часто развертываются два кон- кретных компонента: 1 Не путайте кеши приложений (используемые напрямую кодом вашего приложения) с HTTP-кешами, которые должны бы находиться на самом верху рис. 19.3 и предна- значены для обслуживания запросов к статическим ресурсам: изображениям, CSS- и JS-файлам и т. д. Сети доставки контента (CDN) предлагают еще один тип HTTP- кеша, который развертывается в центрах обработки данных, ближайших к конечным пользователям приложения. 2 Диаграмма основана на рис. 1.1 из книги Martin Kleppmann «Designing Data-Intensive Applications» (O’Reilly). Python в многоядерном мире  677\n--- Страница 677 ---\nсервер приложений для распределения нагрузки между несколькими экземплярами приложения. Этот сервер должен находиться в верхней части рис. 19.3 и обслуживать клиентские запросы, до того как они до- стигнут кода приложения; очередь задач, построенная на базе очереди сообщений в правой части рис. 19.3. Она предоставляет высокоуровневый простой в использова- нии API для распределения задач между процессами, работающими на других машинах. В следующих двух разделах рассматриваются компоненты этого типа, ко- торые рекомендуются для развертывания в серверных Python-приложениях. WSGI-серверы приложений WSGI – шлюзовой интерфейс веб-серверов ( https://peps.python.org/pep-3333/) – это стандартный API Python-каркаса или приложения для получения запросов от HTTP-сервера и отправки ему ответов1. WSGI-серверы приложений управ- ляют одним или несколькими процессами, исполняющими приложение, обес- печивая максимальное использование доступных процессоров. На рис. 19.4 показано типичное развертывание WSGI. Если бы мы захотели объединить обе диаграммы, то содержимое обведенного штриховой линией прямоугольника на рис. 19.4 следовало бы поместить вместо блока «Код приложения» в верх - ней части рис. 19.3. Из самых известных серверов приложений для веб-проектов на Python упо- мянем следующие: mod_wsgi (https://modwsgi.readthedocs.io/en/master/); uWSGI (https://uwsgi-docs.readthedocs.io/en/latest/)2; Gunicorn (https://gunicorn.org/); NGINX Unit (https://unit.nginx.org/). Для пользователей HTTP-сервера Apache лучшим вариантом является mod_ wsgi. Он такой же старый, как сам стандарт WSGI, но активно сопровождает - ся, а теперь еще и предлагает средство запуска из командной строки mod_wsgi- express, которое упрощает конфигурирование и больше подходит для использо- вания в Docker-контейнерах. 1 Одни докладчики произносят WSGI как акроним, по буквам, другие – как одно слово, «висги». 2 uWSGI пишется со строчной буквой «u», но произносится она как греческая буква «μ», так что название в целом произносится как «микровисги». 678  Модели конкурентности в Python\n--- Страница 678 ---\nHTTP-серверКлиент HTTP Сервер приложенийМежпроцессное взаимодействиеСтатические файлы Межпроцессное взаимодействие Веб-приложение на PythonДочерний процесс 1 сервера приложений WSGI API Веб-приложение на PythonДочерний процесс 1 сервера приложений WSGI API Веб-приложение на PythonДочерний процесс 1 сервера приложений WSGI API Веб-приложение на PythonДочерний процесс 1 сервера приложений WSGI API Рис. 19.4. Клиенты подключаются к HTTP-серверу, который доставляет статические файлы и передает другие запросы серверу приложений, а тот запускает дочерние процессы для выполнения кода приложения, задействуя несколько процессорных ядер. WSGI API – связую- щий слой между сервером приложений и кодом Python-приложения uWSGI и Gunicorn чаще всего выбираются в недавних проектах, о которых мне известно. Оба нередко применяются в сочетании с HTTP-сервером NGINX. uWSGI предлагает дополнительную функциональность, включая кеш прило- жения, очередь задач, планировщик периодических задач типа cron и много всего другого. Но правильно сконфигурировать uWSGI гораздо труднее, чем Gunicorn1. NGINX Unit – новый продукт, выпущенный в 2018 году авторами широко из- вестного HTTP-сервера и обратного прокси-сервера NGINX. mod_wsgi и Gunicorn поддерживают только веб-приложения на Python, тогда как uWSGI и NGINX Unit работают и с другими языками. Дополнительные све- дения можно почерпнуть из соответствующей документации. 1 Инженеры из компании Bloomberg Петер Шперль и Бен Грин написали руковод- ство «Configuring uWSGI for Production Deployment» (https://www.bloomberg.com/tosv2. html?vid=&uuid=f46c5dc1-df27-11ec-ba90-464c446b4e6d&url=L2NvbXBhbnkvc3Rvcmllcy9jb 25maWd1cmluZy11d3NnaS1wcm9kdWN0a W9uLWRlcGxveW1lbnQv), в котором объясня- ется, сколько параметров, подразумеваемых по умолчанию в uWSGI, не годятся для многих типичных сценариев развертывания. Шперль конспективно предста- вил эти рекомендации на конференции EuroPython 2019 (https://www.youtube.com/ watch?v=p6R1h2Nn468). Горячо рекомендую всем пользователям uWSGI. Python в многоядерном мире  679\n--- Страница 679 ---\nГлавное: все эти серверы приложений потенциально могут задействовать все процессорные ядра сервера, создавая несколько процессов Python для вы- полнения традиционных веб-приложений, написанных в старом добром по- следовательном стиле, например Django, Flask, Pyramid и т. д. Это объясняет, почему веб-разработчик на Python может зарабатывать на хлеб, не изучая модули threading, multiprocessing или asyncio: серверы приложений прозрачно управляют конкурентностью. ASGI – шлюзовой интерфейс асинхронных серверов WSGI – синхронный API. Он не поддерживает сопрограмм с async/ await – самый эффективный способ реализации веб-советов или долгого HTTP-опроса на Python. Спецификация ASGI, при- шедшая на смену WSGI, спроектирована для асинхронных веб-каркасов на Python, например aiohttp, Sanic, FastAPI и т. д., а равно Django и Flask, в которые постепенно добавляется асин- хронная функциональность. Теперь обратимся к еще одному способу обхода GIL для достижения более высокой производительности в серверных Python-приложениях. Распределенные очереди задач Когда сервер приложений доставляет запрос одному из процессов Python, ис- полняющих наш код, наше приложение должно ответить быстро: мы хотим, чтобы процесс как можно скорее стал доступен для обслуживания следую- щего запроса. Однако некоторые запросы требуют выполнения достаточно длительных действий, например отправки по электронной почте или генери- рования PDF-документа. Эту проблему и призваны решить распределенные очереди задач. Наиболее известные очереди задач с открытым исходным кодом, имеющие Python API, – Celery ( https://docs.celeryq.dev/en/stable/getting-started/introduction. html) и RQ (https://python-rq.org/). Облачные поставщики также предлагают соб- ственные очереди задач. Эти продукты обертывают очередь сообщений и предоставляют высоко- уровневый API для делегирования задач исполнителям, возможно, работаю- щим на разных машинах. В контексте очередей задач вместо традиционной терминоло- гии «клиент» и «сервер» используются слова «производитель» и «потребитель». Например, обработчик представлений в Django производит задания-запросы, которые помещаются в очередь для потребления одним или несколькими процессами генериро- вания PDF. В следующей цитате из Celery F A Q (https://docs.celeryq.dev/en/stable/faq.html# what-kinds-of-things-should-i-use-celery-for) перечисляются некоторые типичные применения. 680  Модели конкурентности в Python\n--- Страница 680 ---\nВыполнение чего-то в фоновом режиме. Например, как можно скорее завершить обработку веб-запроса, а затем инкрементно об- новить страницу пользователя. Это создает у пользователя впечат - ление высокой производительности и «шустрости», хотя реальная работа может занять некоторое время. Выполнение чего-то после завершения веб-запроса. Гарантирование полного завершения чего-то, возможно, асин- хронно и за несколько попыток. Планирование периодических работ. Помимо решения этих непосредственных задач, очереди задач поддержива- ют горизонтальную масштабируемость. Связь между производителями и по- требителями разорвана: производитель не вызывает потребителя, он только помещает запрос в очередь. Потребители не должны ничего знать о произво- дителях (но запрос может включать информацию о производителе, если тре- буется подтверждение). Главное, что можно легко добавлять исполнителей для потребления задач по мере увеличения спроса. Именно поэтому Celery и RQ называют также распределенными очередями задач. Напомним, что в нашем простом скрипте procs.py (пример 19.13) использо- валось две очереди: одна для заданий-запросов, другая для сбора результатов. В распределенных архитектурах Celery и RQ применяется похожий паттерн. Та и другая поддерживают базу данных NoSQL Redis (https://redis.io/) в качестве очереди сообщений и хранилища результатов. Celery поддерживает и другие очереди сообщений, например RabbitMQ и Amazon SQS, а также иные базы дан- ных для хранения результатов. На этом мы завершаем введение в конкурентность в Python. В следующих двух главах эта тема будет продолжена, с упором на пакеты concurrent.futures и asyncio из стандартной библиотеки. резюме После краткого теоретического введения были представлены скрипты аними- рованного индикатора, реализованные с помощью каждой из трех имеющихся в Python моделей конкурентного программирования: потоки, пакет threading ; процессы, пакет multiprocessing ; асинхронные сопрограммы, пакет asyncio. Затем мы изучили реальное влияние GIL, проведя эксперимент: мы изменили написанные ранее примеры, так чтобы они проверяли большие целые числа на простоту, и понаблюдали за поведением. Было графически продемонстрировано, что при использовании asyncio счетных операций следует избегать, поскольку они блокируют цикл событий. Многопоточная версия работала хорошо – несмотря на GIL, – потому что Python периодически прерывает потоки, а в примере исполь- зовалось всего два потока: один выполнял счетную операцию, а другой управлял анимацией 10 раз в секунду, что совсем немного. Вариант на основе multiprocessing вообще обходил GIL, поскольку запускался новый процесс специально для анима- ции, тогда как главный процесс занимался проверкой на простоту. Резюме  681\n--- Страница 681 ---\nВ следующем примере, где проверялось несколько простых чисел, была про- демонстрирована разница между пакетами multiprocessing и threading и показа- но, что только процессы позволяют Python задействовать преимущества мно- гоядерных CPU. Из-за GIL потоки в Python работают хуже последовательного кода при выполнении длительных вычислений. Вопросы о GIL преобладают в обсуждениях конкурентных и параллельных вычислений на Python, но переоценивать его значимость не следует. Эта тема была поднята в разделе «Python в многоядерном мире». Например, на GIL можно не обращать внимания во многих сценариях системного админист - рирования на Python. С другой стороны, сообщества разработчиков в обла- сти науки о данных и серверных приложений нашли решения, позволяющие обойти GIL и строить решения производственного уровня, адаптированные к их конкретным потребностям. В последних двух разделах были рассмотрены два компонента, часто применяемых для поддержки крупномасштабных сер- верных Python-приложений: WSGI-серверы приложений и распределенные очереди задач. дОпО лнительная литература Список для дополнительного чтения к этой главе довольно обширен, поэтому я разбил его на части. Конкурентность с применением потоков и процессов В библиотеке concurrent.futures, рассматриваемой в главе 20, под капотом ис- пользуются потоки, процессы, блокировки и очереди, но снаружи вы их не уви- дите; все они скрыты за фасадом высокоуровневых абстракций ThreadPoolExecutor и ProcessPoolExecutor . Если вам интересно больше узнать о практике конкурент - ного программирования с помощью этих низкоуровневых объектов, начните со статьи Джима Андерсона «An Intro to Threading in Python» (https://realpython. com/intro-to-python-threading/). Дуг Хеллманн включил главу «Concurrency with Processes, Threads, and Coroutines» в свою книгу «The Python 3 Standard Library by Example» (Addison-Wesley) (https://www.pearson.com/us/higher-education/program/ Hellmann-Python-3-Standard-Library-by-Example-The/PGM328871.html) и поместил ее на свой сайт (https://pymotw.com/3/concurrency.html). Книги Brett Slatkin «Effective Python», 2-е издание (Addison-Wesley), David Beazley «Python Essential Reference», 4-е издание (Addison-Wesley), и Martelli et al. «Python in a Nutshell», 3-е издание (O’Reilly), посвящены Python в целом, и в них подробно рассматриваются пакеты threading и multiprocessing . В обширной официальной документации по пакету multiprocessing имеются полезные сове- ты в разделе «Рекомендации по программированию» (https://docs.python.org/3/ library/multiprocessing.html#programming-guidelines). Джесси Ноллер и Ричард Оудкерк, авторы пакета multiprocessing , описали его в документе PEP 371 «Addition of the multiprocessing package to the standard library» (https://peps.python.org/pep-0371/). Официальная документация по этому пакету представляет собой rst-файл размером 93 КБ (https://docs.python.org/3/ library/ multiprocessing.html) – приблизительно 63 страницы; это одна из самых длинных глав в документации по стандартной библиотеке.682  Модели конкурентности в Python\n--- Страница 682 ---\nВ книге Micha Gorelick, Ian Ozsvald «High Performance Python», 2-е издание (O’Reilly), есть глава о модуле multiprocessing с примером, посвященным провер- ке на простоту, но с помощью стратегий, отличающихся от примененной в на- шем скрипте procs.py. Для каждого числа они разбивают диапазон возможных множителей – от 2 до sqrt(n) – на поддиапазоны и поручают исполнителям ис- следовать эти поддиапазоны. Такой подход «разделяй и властвуй» характерен для научных приложений с огромными наборами данных и ситуаций, когда рабочие станции (или кластеры) имеют больше процессорных ядер, чем поль- зователей. В серверной системе, обрабатывающей запросы от многих пользо- вателей, проще и эффективнее поручить каждому процессу провести вычис - ление от начала до конца, поскольку это снижает накладные расходы на взаи- модействие и координацию процессов. Помимо пакета multiprocessing , Горелик и Освальд описывают много других способов разработки и развертывания вы- сокопроизводительных приложений в области науки о данных с использовани- ем нескольких ядер, GPU, кластеров, профилировщиков и компиляторов типа Cython и Numba. В последней главе «Полевые заметки» приводится набор по- лезных коротких примеров, предложенных другими разработчиками, практи- чески занимающимися высокопроизводительными вычислениями на Python. Книга Matthew Wilkes «Advanced Python Development» (Apress)1 – одна из тех редких книг, в которой есть короткие примеры для объяснения идей и в то же время строится реалистичное приложение, готовое к эксплуатации: агрегатор данных, похожий на системы мониторинга в DevOps или системы сбора данных для распределенных датчиков в IoT. В двух главах этой книги рассматривается конкурентное программирование с применением пакетов threading и asyncio. В книге Jan Palach «Parallel Programming with Python» (Packt, 2014) объяс - няются основные идеи, стоящие за конкурентностью и параллелизмом, и рас - сматривается стандартная библиотека Python и библиотека Celery. Глава 2 книги Caleb Hattingh «Using Asyncio in Python» (O’Reilly) называется «Вся правда о потоках»2. В ней речь идет о плюсах и минусах многопоточного программирования – с привлечением убедительных цитат из нескольких ав- торитетных источников, – так что становится понятно, что фундаментальные проблемы потоков не связаны ни с Python, ни с GIL. Процитирую фрагмент страницы 14 этой книги: Следующие аргументы повторяются снова и снова: наличие потоков затрудняет рассуждения о программе; многопоточная модель неэффективна для организации масштаб- ной конкурентности (тысячи конкурентных потоков). Если вы хотите тяжким трудом, но не рискуя потерять работу, добыть зна- ния о том, как трудно рассуждать о потоках и блокировках, попробуйте решить упражнения из книги Allen Downey «The Little Book of Semaphores» (Green Tea Press) (greenteapress.com/wp/semaphores). По трудности они варьируются от со- всем простых до нерешаемых, но даже простые способствуют просветлению. 1 Мэттью Уилкс. Профессиональная разработка на Python. ДМК Пресс, 2021 // https:// dmkpress.com/catalog/computer/programming/python/978-5-97060-930-9/ 2 Калеб – один из технических рецензентов второго издания этой книги. Дополнительная литература  683\n--- Страница 683 ---\nGIL Если вас заинтриговали тайны GIL, вспомните, что из кода на Python управ- лять ей нельзя, поэтому каноническим справочником является документа- ция по C-API: «Состояние потока и глобальная блокировка интерпретатора» (https://docs.python.org/3/c-api/init.html#thread-state-and-the-global-interpreter-lock). FAQ по библиотеке и расширениям Python отвечает на вопрос: «Можно ли из- бавиться от глобальной блокировки интерпретатора?» (https://docs.python.org/3/ faq/library.html#can-t-we-get-rid-of-the-global-interpreter-lock). Стоит также прочи- тать статьи Гвидо ван Россума и Джесси Ноллера (автора пакета multiprocessing ): «It isn’t Easy to Remove the GIL» (https://www.artima.com/weblogs/ viewpost. jsp?thread=214235) и «Python Threads and the Global Interpreter Lock» (http:// jessenoller.com/blog/2009/02/01/python-threads-and-the-global-interpreter-lock). В книге Anthony Shaw «CPython Internals» (https://realpython.com/products/cpython- internals-book/) (Real Python) объясняется, как реализован интерпретатор CPython 3 на уровне программирования на C. Самая длинная глава в этой книге – «Парал- лелизм и конкурентность», это глубокое погружение в поддержку потоков и про- цессов, включая управление GIL из расширений, следующих C/Python API. Наконец, Дэвид Бизли представил детальное исследование вопроса в презента- ции «Understanding the Python GIL» (http://www.dabeaz.com/GIL/)1. На слайде 54 пре- зентации (http://www.dabeaz.com/python/UnderstandingGIL.pdf) Бизли отмечает увели- чение времени работы конкретного теста производительности после реализации нового алгоритма GIL в версии Python 3.2. Проблема несущественна для реальных рабочих нагрузок, как заметил (https://bugs.python.org/issue7946# msg223110) Антуан Питру, реализовавший этот алгоритм, в ответ на сообщение об ошибке, отправ- ленное Бизли; см. проблему Python #7946 (https://bugs.python.org/issue7946). Конкурентность за пределами стандартной библиотеки В этой книге рассматриваются прежде всего базовые средства языка и ча- сти стандартной библиотеки. Хорошим дополнением к ней является книга «Full Stack Python» (https://www.fullstackpython.com/): она посвящена экосистеме Python и среди прочего содержит главы «Среды разработки», «Данные», «Веб- разработка» и «DevOps». Я уже упоминал две книги, где обсуждается конкурентность с использовани- ем стандартной библиотеки Python, но включен также обширный материал по сторонним библиотекам и инструментам: «High Performance Python», 2-е из- дание (https://www.oreilly.com/library/view/high-performance-python/9781492055013/), и «Parallel Programming with Python» (https://www.packtpub.com/product/ parallel-programming-with-python/9781783288397). В книге Francesco Pierfederici «Distributed Computing with Python» (https://www.packtpub.com/product/distributed- computing-with-python/9781785889691) рассматривается стандартная библиотека, а также использование облаков и высокопроизводительных (HPC) кластеров. Статья Мэттью Роклина «Python, Performance, and GPUs», опубликован- ная в июне 2019 года (https://towardsdatascience.com/python-performance-and-gpus- 1be860ffd58d), содержит актуальную информацию об использовании GPU- ускорителей. 1 Спасибо Лукасу Бруниалти, который прислал мне эту ссылку.684  Модели конкурентности в Python\n--- Страница 684 ---\n«Instagram в настоящее время является крупнейшим в мире развертывани- ем веб-каркаса Django, целиком написанного на Python». Так начинается ста- тья в блоге «Web Service Efficiency at Instagram with Python» (https://instagram- engineering.com/web-service-efficiency-at-instagram-with-python-4976d078e366), напи- санная Мин Ни – программистом, работающим в Instagram. В статье описыва- ются метрики и инструменты, которые используются в Instagram для оптимиза- ции кодовой базы на Python, а также обнаружения и диагностики снижения про- изводительности в условиях развертывания серверной части «30–50 раз в день». В книге Harry Percival, Bob Gregory «Architecture Patterns with Python: Enabling Test-Driven Development, Domain-Driven Design, and Event-Driven Microservices» (https://www.oreilly.com/library/view/architecture-patterns-with/9781492052197/) (O’Reilly) представлены архитектурные паттерны для серверных Python- приложений. Авторы также выложили книгу в свободный доступ на сайте cosmicpython.com. Существуют две элегантные и очень простые для использования библиотеки распараллеливания задач между процессами: lelo (https://pypi.python.org/pypi/lelo) Жоао С. О. Буэно и python-parallelize (https://github.com/npryce/python-parallelize) Ната Прайса. В пакете lelo определен декоратор @parallel; если применить его к любой функции, то она, как по волшебству, становится неблокирующей, поскольку вы- полняется в отдельном процессе. Пакет Ната Прайса python-parallelize предоставля- ет генератор parallelize , который можно использовать для выполнения цикла for на нескольких процессорах. В основе обоих пакетов лежит библиотека multiprocessing . Разработчик ядра Python Эрик Шоу поддерживает вики Multicore Python (https://github.com/ericsnowcurrently/multi-core-python/wiki), где рассказывает о сво- их и сторонних усилиях улучшить поддержку параллельной работы в Python. Сноу – автор документа PEP 554 «Multiple Interpreters in the Stdlib» (https://peps. python.org/pep-0554/). Если он будет одобрен и реализован, то станет основой для будущих усовершенствований, которые в конечном итоге, возможно, позволят Python задействовать несколько ядер без накладных расходов, свойственных многопроцессной обработке. Одно из основных препятствий – сложное взаи- модействие между несколькими активными дочерними интерпретаторами и расширениями, предполагающими, что интерпретатор всего один. Марк Шеннон – тоже отвечающий за сопровождение Python – создал полез- ную таблицу (https://gist.github.com/markshannon/79cace3656b40e21b7021504daee9 50c), в которой сравнивает модели конкурентности в Python, упоминавшиеся в обсуждении дочерних интерпретаторов в списке рассылки python-dev (https:// mail.python.org/archives/list/python-dev@python.org/message/YOOQZCFOKEPQ24YHW WLQSJ3RCXFMS7D7/), в котором принимали участие он сам, Эрик Сноу и другие разработчики. В таблице Шеннона есть столбец «Идеальное CSP», относящий- ся к теоретической модели взаимодействующих последовательных процессов (https://en.wikipedia.org/wiki/Communicating_sequential_processes), предложенной Тони Хоаром в 1978 году. Язык Go также допускает разделяемые объекты, нарушая фундаментальное ограничение CSP: единицы выполнения должны взаимодей- ствовать только с помощью передачи сообщений по каналам. Stackless Python ( https://github.com/stackless-dev/stackless/wiki) (или просто Stackless) – клон CPython, в котором реализованы микропотоки, т. е. облегчен- ные потоки, управляемые на уровне приложения, а не ОС. Массивно многополь- Дополнительная литература  685\n--- Страница 685 ---\nзовательская онлайновая игра EVE Online ( https://www.eveonline.com/) построена на базе Stackless, а инженеры, нанятые компанией-разработчиком CCP (https:// www.ccpgames.com/), некоторое время сопровождали (https://stackless.readthedocs.io/ en/3.6-slp/stackless-python.html#history) Stackless. Некоторые особенности Stackless были заново реализованы в интерпретаторе Pypy ( https://doc.pypy.org/en/latest/ stackless.html) и в пакете greenlet ( https://greenlet.readthedocs.io/en/latest/), лежащем в основе сетевой библиотеки gevent ( http://www.gevent.org/), которая, в свою оче- редь, является фундаментом сервера приложений Gunicorn (https://gunicorn.org/). Модель акторов в конкурентном программировании лежит в основе очень хорошо масштабируемых языков Erlang и Elixir, а также каркаса Akka для Scala и Java. Если вы хотите попробовать модель акторов в Python, обратите вни- мание на библиотеки Thespian ( http://thespianpy.com/doc/) и Pykka ( https://pykka. readthedocs.io/en/latest/). В остальных моих рекомендациях Python почти не упоминается, но они все равно могут представлять интерес для читателей, заинтересовавшихся темой этой главы. Конкурентность и масштабируемость за пределами Python Книга Alvaro Videla, Jason J. W. Williams «RabbitMQ in Action» (Manning) (https://www. manning.com/books/rabbitmq-in-action) – прекрасно написанное введение в систему RabbitMQ и стандарт Advanced Message Queuing Protocol (AMQP), с примерами на Python, PHP и Ruby. Вне зависимости от того, что еще есть в вашем техническом загашнике, и даже если вы планируете использовать Celery, в которой RabbitMQ скрыта под капотом, я рекомендую прочитать эту книгу, поскольку в ней рассма- триваются идеи, мотивация и паттерны распределенных очередей сообщений, а также эксплуатация и настройка RabbitMQ в крупномасштабных проектах. Я много узнал из книги Paul Butcher «Seven Concurrency Models in Seven Weeks1» (https://pragprog.com/titles/pb7con/seven-concurrency-models-in-seven-weeks/) (Pragmatic Bookshelf) с красноречивым подзаголовком «Когда распутываются нити». В главе 1 представлены основные идеи и проблемы программирования с потоками и блокировками в Java2. Остальные шесть глав посвящены тому, что автор считает наилучшими альтернативами средствам конкурентного и параллельного программирования, поддерживаемым различными языками, инструментами и библиотеками. В качестве примеров выбраны Java, Clojure, Elixir и C (в главе о параллельном программировании с применением карка- са OpenCL (https://en.wikipedia.org/wiki/OpenCL)). Модель CSP рассматривается на примере кода на Clojure, хотя языку Go следовало бы отдать должное за по- пуляризацию этого подхода. На примере языка Elixir иллюстрируется модель акторов. В свободно доступной альтернативной бонусной главе (https://media. pragprog.c om/titles/pb7con/Bonus_Chapter.pdf) об акторах используются Scala и кар- кас Akka. Для тех, кто незнаком со Scala, Elixir является более простым языком для изучения и экспериментов с моделью акторов и платформой распределен- ных систем Erlang/OTP. 1 Батчер П. Семь моделей конкуренции и параллелизма за семь недель. М.: ДМК Пресс, 2015 // https://dmkpress.com/catalog/computer/programming/functional/978-5-97060-720-6/ 2 На API пакетов Python threading и concurrent.futures большое влияние оказала стан- дартная библиотека Java.686  Модели конкурентности в Python\n--- Страница 686 ---\nУнмеш Йоши из компании Thoughtworks написал несколько страниц в блог Мартина Фаулера, документирующих «Паттерны распределенных систем». Пер- вая страница (https://martinfowler.com/articles/patterns-of-distributed-systems/) содержит великолепное введение в предмет, со ссылками на отдельные паттерны. Йоши добавляет паттерны постепенно, но то, что уже опубликовано, – квинтэссенция добытого тяжким трудом опыта реализации особо ответственных систем. Книга Martin Kleppmann «Designing Data-Intensive Applications» (O’Reilly) (https:// www.oreilly.com/library/view/designing-data-intensive-applications/9781491903063/) – ред- кий образчик книги, написанной практиком с богатым опытом работы в ин- дустрии и хорошей академической подготовкой. Автор работал в компании LinkedIn, имеющей крупномасштабную инфраструктуру данных, и в двух стар- тапах, после чего занялся научной работой в области распределенных систем в Кембриджском университете. Каждая глава книги Клеппманна заканчивается обширным списком литературы, включая последние научные работы. В книге также имеются многочисленные диаграммы, проясняющие суть дела, и прекрас - но исполненные карты концепций. Мне повезло присутствовать на выдающемся семинаре Франческо Чезари- ни по архитектуре надежных распределенных систем на конференции OSCON 2016: «Designing and architecting for scalability with Erlang/OTP» (видео (https:// www.oreilly.com/library/view/oscon-2016-video/9781491965153/video247021.html) имеется на образовательной платформе O’Reilly). Несмотря на название, Чеза- рини объясняет (отметка 9:35): Очень немногое из того, что я хочу сказать, специфично для Erlang […]. Факт, что Erlang устраняет целый ряд акцидентальных трудностей на пути создания надежных систем, которые никогда не отказывают и при этом масштабируемы. Поэтому ваша задача существенно упростится, если вы будете использовать Erlang или язык, работающий под управлением вир- туальной машины Erlang. Этот семинар основан на последних четырех главах книги Francesco Cesarini, Steve Vinoski «Designing for Scalability with Erlang/OTP1» (O’Reilly) (https://www. oreilly.com/library/view/designing-for-scalability/9781449361556/). Программирование распределенных систем – трудное и увлекательное за- нятие, но помните о зависти к масштабу веба ( https://www.thoughtworks.com/radar/ techniques/high-performance-envy-web-scale-envy). Принцип KISS (https://en.wikipedia. org/wiki/KISS_principle) – совет, к которому инженерам стоит прислушаться. Ознакомьтесь со статьей Frank McSherry, Michael Isard, Derek G. Murray «Scalability! But at what COST?» (https://www.usenix.org/conference/hotos15/ workshop-program/presentation/mcsherry). Авторы идентифицировали системы параллельной обработки графов, представленных на научных симпозиумах, которые требуют сотен ядер, чтобы превзойти по производительности «ком- петентную однопоточную реализацию». Они также обнаружили системы, ко- торые «работают хуже однопоточных во всех известных конфигурациях». Эти открытия напоминают мне классическую хакерскую колкость: Мой скрипт на Perl работает быстрее твоего Hadoop-кластера. 1 Чезарини Ф., Виноски С. Проектирование масштабируемых систем в Erlang/ ОТР. М.: ДМК Пресс, 2017 // https://dmkpress.com/catalog/computer/programming/ functional/978-5-97060-212-6/ Дополнительная литература  687\n--- Страница 687 ---\nПоговорим Чтобы справляться со сложностью, нужны ограничения Я учился программировать на калькуляторе TI-58. Его «язык» напоминал ас- семблер. На этом уровне все «переменные» были глобальными и такой роско- ши, как структурное управление потоком, не было и в помине. Были команды условного перехода, передававшие управление в произвольную точку – до или после текущей команды – в зависимости от значения регистра или флага процессора. На ассемблере, в общем-то, можно сделать все, что угодно, и в этом проблема: слишком мало ограничений, чтобы предотвратить ошибки и помочь сопро- вождающим понять код, когда возникает необходимость внести изменения. Вторым моим языком стал неструктурированный BASIC, стоявший на 8-раз- рядных компьютерах, – ничего похожего на Visual Basic, появившийся гораздо позже. В нем были предложения FOR, GOSUB и RETURN, но по-прежнему отсутство- вало понятие локальных переменных. Предложение GOSUB не поддерживало передачу параметров, это было просто пафосное GOTO, оно помещало номер строки возврата в стек, так чтобы предложение RETURN знало, куда перейти. Подпрограммы должны были получать параметры из глобальных данных и в них же сохранять результаты. Приходилось импровизировать и придумывать другие формы управления потоком с помощью комбинаций IF и GOTO, которое, как и раньше, позволяло перейти в любую точку программы. Я помню, с каким трудом, после нескольких лет программирования с по- мощью переходов и глобальных переменных, я перестраивал мышление на «структурное программирование», когда стал изучать Pascal. Теперь я должен был использовать предложения управления потоком, обрамляющие блоки кода с единственной точкой входа. Я не мог просто перейти в любое нужное мне место. Глобальные переменные – неизбежный атрибут BASIC – теперь оказались под запретом. Я должен был переосмыслить поток данных и явно передавать аргументы функциям. Следующим вызовом для меня стало изучение объектно-ориентированного программирования. По сути своей объектно-ориентированное программи- рование – это то же структурное программированиие, но с большим коли- чеством ограничений и полиморфизмом. Сокрытие информации заставляет снова пересмотреть представления о том, где находятся данные. Я помню, сколько раз испытывал горькое разочарование, оказываясь перед необходи- мостью переделать код, так чтобы мой метод мог получить инкапсулирован- ную в объекте информацию, до которой не мог добраться. Языки функционального программирования добавляют другие ограничения, однако особенно трудно смириться с неизменяемостью – после десятилетий императивного и объектно-ориентированного программирования. Но, при- выкнув к этим ограничениям, мы начинаем рассматривать их как благосло- вение. Они сильно упрощают рассуждения о программе. Недостаток ограничений – главная проблема модели конкурентного про- граммирования с потоками и блокировками. Подводя итог главе 1 книги «Seven Concurrency Models in Seven Weeks», Пол Бутчер писал:688  Модели конкурентности в Python\n--- Страница 688 ---\nОднако величайшая слабость этого подхода состоит в том, что про- граммировать с помощью потоков и блокировок трудно. Возможно, проектировщику языка и легко добавить их в язык, но нам, бедным программистам, они помогают очень мало. Приведу несколько примеров ничем не ограниченного поведения в этой модели: все потоки могут иметь общий доступ к произвольным изменяемым структурам данных; планировщик может прервать поток почти в любой точке, в т. ч. посреди простой операции типа a += 1. Очень немногие операции атомарны на уровне выражений в исходном коде; блокировки обычно рекомендательные. Этот технический термин означа- ет, что мы должны не забыть явно поставить блокировку, перед тем как изменить структуру данных. Если этого не сделать, то ничто не помешает нашему коду создать хаос, пока другой поток честно удерживает блоки- ровку и изменяет те же самые данные. С другой стороны, рассмотрим некоторые ограничения, налагаемые моделью акторов, в которой единица выполнения называется актором1: у актора может быть внутреннее состояние, но он не может разделять его с другими акторами; акторы могут взаимодействовать только путем отправки и получения со- общений; сообщения могу содержать лишь копии данных, но не ссылки на изменя- емые данные; актор обрабатывает только одно сообщение в каждый момент времени. Нет такого понятия, как конкурентное выполнение внутри одного актора. Конечно, стиль кодирования с помощью акторов можно принять в любом языке – нужно только следовать этим правилам. Точно так же можно исполь- зовать идиомы объектно-ориентированного программирования в C и даже паттерны структурного программирования в ассемблере. Но это требует мно- жества соглашений и дисциплины со стороны всех причастных к коду. Управлять блокировками в модели акторов, реализованной в Erlang и Elixir, где все данные неизменяемые, необязательно. Потоки и блокировки никуда не деваются. Я просто думаю, что неразумно тратить время на работу с такими низкоуровневыми понятиями при напи- сании приложений. К написанию модулей ядра или баз данных это не от - носится. 1 В сообществе Erlang для акторов используется термин «процесс». В Erlang каждый процесс является функцией в своем собственном цикле, поэтому они очень мало ве- сят и в каждый момент времени на одной машине могут работать миллионы процес - сов – ничего общего с тяжеловесными процессами ОС, о которых мы говорили в этой главе. Так что мы здесь имеем примеры обоих грехов, описанных профессором Сай- моном: использование разных слов для обозначения одной вещи и использование одного слова для обозначения разных вещей. Дополнительная литература  689\n--- Страница 689 ---\nЯ всегда оставляю за собой право изменить точку зрения. Но в данный мо- мент я убежден, что модель акторов – самая разумная из имеющихся моделей конкурентного программирования общего назначения. Модель CSP (взаимо- действующих последовательных процессов) тоже хороша, но ее реализация в Go позволяет обойти некоторые ограничения. Идея CSP заключается в том, что сопрограммы (или горутины в Go) обмениваются данными и синхро- низируются с помощью очередей (в Go они называются каналами). Однако Go поддерживает также разделение памяти и блокировки. Я даже встречал книгу о Go, в которой пропагандируется использование разделяемой памяти и блокировок вместо каналов – во имя производительности. Старые привыч- ки умирают с трудом.690  Модели конкурентности в Python",
      "debug": {
        "start_page": 645,
        "end_page": 689
      }
    },
    {
      "name": "Глава 20. Конкурентные исполнители 691",
      "content": "--- Страница 690 --- (продолжение)\nГлава 20 Конкурентные исполнители Потоки критикуют в основном системные программисты, имея в виду та- кие ситуации, с которыми типичный прикладной программист никогда не сталкивается. […] В 99 % случаев, с которыми имеет дело прикладной программист, достаточно знать, как запустить группу независимых пото- ков и собрать результаты в очередь. – Мишель Симионато, вдумчивый пользователь Python1 Эта глава посвящена классам concurrent.futures.Executor , которые инкапсулиру - ют паттерн «запуска группы независимых потоков и сбора результатов в оче- редь», описанный Мишелем Симионато. Конкурентные исполнители делают его использование почти тривиальным делом не только с помощью потоков, но и с помощью процессов – что полезно для счетных задач. Здесь же я введу понятие «будущего объекта» – объекта, представляющего асинхронное выполнение операции, по аналогии с обещаниями в JavaScript. Эта плодотворная идея лежит в основе не только библиотеки concurrent.futures , но и пакета asyncio, рассматриваемого в главе 21. чтО нОвОг О в этОй главе Раньше глава называлась «Конкурентность и будущие объекты», теперь я на- звал ее «Конкурентные исполнители», потому что именно исполнители – самое важное рассматриваемое в ней высокоуровневое средство. Будущие объекты являются низкоуровневыми объектами, им посвящен раздел «Где находятся бу- дущие объекты?», но в остальной части главы они практически не встречаются. Во всех примерах HTTP-клиентов теперь используется новая библиоте- ка HTTPX ( https://www.python-httpx.org/), предлагающая как синхронный, так и асинхронный API. Подготовка сцены для экспериментов в разделе «Загрузка с индикацией хода выполнения и обработкой ошибок» стала проще благодаря многопоточ- ному серверу, добавленному в пакет http.server в версии Python 3.7. Раньше в стандартной библиотеке имелся только однопоточный BaseHttpServer , которого 1 Из статьи Мишеля Симионато «Threads, processes and concurrency in Python: some thoughts» (https://www.artima.com/weblogs/viewpost.jsp?thread=299551), имеющей подза- головок «Removing the hype around the multicore (non) revolution and some (hopefully) sensible comment about threads and other forms of concurrency» (Развенчание реклам- ной чепухи по поводу многоядерной (не) революции и некоторые (надеюсь) полез- ные замечания о потоках и других видах конкурентности).\nГлава 20 Конкурентные исполнители Потоки критикуют в основном системные программисты, имея в виду та- кие ситуации, с которыми типичный прикладной программист никогда не сталкивается. […] В 99 % случаев, с которыми имеет дело прикладной программист, достаточно знать, как запустить группу независимых пото- ков и собрать результаты в очередь. – Мишель Симионато, вдумчивый пользователь Python1 Эта глава посвящена классам concurrent.futures.Executor , которые инкапсулиру - ют паттерн «запуска группы независимых потоков и сбора результатов в оче- редь», описанный Мишелем Симионато. Конкурентные исполнители делают его использование почти тривиальным делом не только с помощью потоков, но и с помощью процессов – что полезно для счетных задач. Здесь же я введу понятие «будущего объекта» – объекта, представляющего асинхронное выполнение операции, по аналогии с обещаниями в JavaScript. Эта плодотворная идея лежит в основе не только библиотеки concurrent.futures , но и пакета asyncio, рассматриваемого в главе 21. чтО нОвОг О в этОй главе Раньше глава называлась «Конкурентность и будущие объекты», теперь я на- звал ее «Конкурентные исполнители», потому что именно исполнители – самое важное рассматриваемое в ней высокоуровневое средство. Будущие объекты являются низкоуровневыми объектами, им посвящен раздел «Где находятся бу- дущие объекты?», но в остальной части главы они практически не встречаются. Во всех примерах HTTP-клиентов теперь используется новая библиоте- ка HTTPX ( https://www.python-httpx.org/), предлагающая как синхронный, так и асинхронный API. Подготовка сцены для экспериментов в разделе «Загрузка с индикацией хода выполнения и обработкой ошибок» стала проще благодаря многопоточ- ному серверу, добавленному в пакет http.server в версии Python 3.7. Раньше в стандартной библиотеке имелся только однопоточный BaseHttpServer , которого 1 Из статьи Мишеля Симионато «Threads, processes and concurrency in Python: some thoughts» (https://www.artima.com/weblogs/viewpost.jsp?thread=299551), имеющей подза- головок «Removing the hype around the multicore (non) revolution and some (hopefully) sensible comment about threads and other forms of concurrency» (Развенчание реклам- ной чепухи по поводу многоядерной (не) революции и некоторые (надеюсь) полез- ные замечания о потоках и других видах конкурентности).\n--- Страница 691 ---\nбыло недостаточно для экспериментов с конкурентными клиентами, поэтому в первом издании мне пришлось прибегнуть к внешним инструментам. В разделе «Запуск процессов с помощью concurrent.futures» теперь показа- но, как исполнитель упрощает код, который мы видели в разделе «Код провер- ки на простоту для многоядерной машины» главы 19. Наконец, большую часть теоретического материала я перенес в главу 19 «Модели конкурентности в Python». кОнкурентная загрузка из веБа Эффективный сетевой ввод-вывод невозможен без конкурентности: чем впус- тую растрачивать процессорное время на ожидание, лучше заняться чем-то полезным, пока из сети не пришел ответ1. Для иллюстрации этого положения я написал три простые программы за- грузки изображений флагов 20 стран из веба. Первая программа, flags.py, рабо- тает последовательно: она запрашивает следующее изображение только после того, как предыдущее загружено и записано на диск. Два других скрипта про- изводят загрузку параллельно: они запрашивают все изображения практиче- ски одновременно, а сохраняют по мере поступления. Скрипт flags_threadpool. py пользуется пакетом concurrent.futures , а flags_asyncio.py – пакетом asyncio. В примере 20.1 показаны результаты выполнения всех трех скриптов, по три раза каждый. Я также разместил на YouTube видео продолжительностью 73 с (https://www.youtube.com/watch?v=A9e9Cy1UkME), чтобы было видно, как по мере сохранения флагов в окне macOS Finder становятся видны их изображения. Скрипты загружают изображения с сайта fluentpython.com, который развернут за системой доставки контента (CDN), так что при первых прогонах они могут работать несколько медленнее. Показанные ниже результаты получены после прогрева кеша CDN. Пример 20.1. Результаты трех типичных прогонов скриптов flags.py, flags_threadpool.py и flags_asyncio.py $ python3 flags.py BD BR CD CN DE EG ET FR ID IN IR JP MX NG PH PK RU TR US VN  20 flags downloaded in 7.26s  $ python3 flags.py BD BR CD CN DE EG ET FR ID IN IR JP MX NG PH PK RU TR US VN 20 flags downloaded in 7.20s $ python3 flags.py BD BR CD CN DE EG ET FR ID IN IR JP MX NG PH PK RU TR US VN 20 flags downloaded in 7.09s $ python3 flags_threadpool.py DE BD CN JP ID EG NG BR RU CD IR MX US PH FR PK VN IN ET TR 20 flags downloaded in 1.37s  $ python3 flags_threadpool.py EG BR FR IN BD JP DE RU PK PH CD MX ID US NG TR CN VN ET IR 20 flags downloaded in 1.60s $ python3 flags_threadpool.py 1 Особенно если облачный поставщик начисляет плату посекундно вне зависимости от занятости процессоров.692  Конкурентные исполнители\n--- Страница 692 ---\nBD DE EG CN ID RU IN VN ET MX FR CD NG US JP TR PK BR IR PH 20 flags downloaded in 1.22s $ python3 flags_asyncio.py BD BR IN ID TR DE CN US IR PK PH FR RU NG VN ET MX EG JP CD 20 flags downloaded in 1.36s $ python3 flags_asyncio.py  RU CN BR IN FR BD TR EG VN IR PH CD ET ID NG DE JP PK MX US 20 flags downloaded in 1.27s $ python3 flags_asyncio.py RU IN ID DE BR VN PK MX US IR ET EG NG BD FR CN JP PH CD TR  20 flags downloaded in 1.42s  Печать результатов каждого прогона начинается с вывода кодов стран в порядке загрузки их флагов и заканчивается сообщением о том, сколько прошло времени.  Скрипту flags.py требуется в среднем 7,18 с для загрузки 20 изображений.  Скрипту flags_threadpool.py в среднем требуется 1,40 с.  Скрипту flags_asyncio.py в среднем требуется 1,35 с.  Обратите внимание на порядок стран: в случае параллельных скриптов за- грузка каждый раз происходит в другом порядке. Между двумя параллельными скриптами разница в производительности несущественна, но тот и другой работают в пять раз быстрее последовательно- го скрипта – и это на совсем небольшой задаче загрузки 20 файлов размером несколько килобайтов каждый. Если бы количество загружаемых файлов ис- числялось сотнями, то параллельные скрипты показали бы рост производи- тельности в 20 и более раз. При тестировании параллельных HTTP-клиентов в открытом вебе можно случайно организовать DoS-атаку или навлечь на себя такие подозрения. В случае примера 20.1 ничего страшного не случится, потому что в скрипты зашито ограничение: только 20 запросов. Далее в этой главе мы будем использовать для про- гона тестов стандартный пакет http.server . Теперь рассмотрим реализации двух скриптов, протестированных в приме- ре 20.1: flags.py и flags_threadpool.py. Скрипт flags_asyncio.py я отложу до главы 21, но продемонстрировать хотел сразу три, чтобы подчеркнуть два момента: 1. Независимо от используемого способа организации конкурентности – многопоточность или сопрограммы – производительность приложения, занятого сетевым вводом-выводом (при правильной реализации), ока- зывается намного выше, чем у последовательного кода. 2. Для HTTP-клиентов, умеющих контролировать количество отправляемых запросов, разница между потоками и сопрограммами несущественна1. Итак, перейдем к коду. 1 Для серверов, к которым может обращаться много клиентов, разница есть: сопро- граммы лучше масштабируются, потому что потребляют гораздо меньше памяти, чем потоки, а также уменьшают стоимость контекстного переключения, о чем я го- ворил в разделе «Не решение на основе потоков» главы 19. Конкурентная загрузка из веба  693\n--- Страница 693 ---\nСкрипт последовательной загрузки В примере 20.2 показана реализация flags.py, первого скрипта, выполненно- го в примере 20.1. Он не очень интересен, но большая часть его кода и пара- метров будет использована для реализации конкурентных скриптов, поэтому уделим ему немного внимания. Для большей ясности в примере 20.2 нет никакой проверки ошибок. Исключениями мы займемся позже, а пока хотим со- средоточиться на структуре кода, чтобы было проще сравнить этот скрипт с конкурентными. Пример 20.2. flags.py: последовательный скрипт загрузки; некоторые функции будут исполь- зованы и в других скриптах import time from pathlib import Path from typing import Callable import httpx ❶ POP20_CC = ('CN IN US ID BR PK NG BD RU JP ' 'MX PH VN ET EG DE IR TR CD FR').split() ❷ BASE_URL = 'https://www.fluentpython.com/data/flags' ❸ DEST_DIR = Path('downloaded') ❹ def save_flag(img: bytes, filename: str) -> None: ❺ (DEST_DIR / filename).write_bytes(img) def get_flag(cc: str) -> bytes: ❻ url = f'{BASE_URL}/{cc}/{cc}.gif'.lower() resp = httpx.get(url, timeout=6.1, ❼ follow_redirects=True) ❽ resp.raise_for_status() ❾ return resp.content def download_many(cc_list: list[str]) -> int: ❿ for cc in sorted(cc_list): ⓫ image = get_flag(cc) save_flag(image, f'{cc}.gif') print(cc, end=' ', flush=True) ⓬ return len(cc_list) def main(downloader: Callable[[list[str]], int]) -> None: ⓭ DEST_DIR.mkdir(exist_ok=True) ⓮ t0 = time.perf_counter() ⓯ count = downloader(POP20_CC) elapsed = time.perf_counter() - t0 print(f'\\n{count} downloads in {elapsed:.2f}s') if __name__ == '__main__': main(download_many) ⓰ 694  Конкурентные исполнители\n--- Страница 694 ---\n❶ Импортировать библиотеку httpx; она не входит в состав стандартной биб- лиотеки, поэтому, по принятому соглашению, импортируется после стан- дартных модулей, а предложение импорта отделяется пустой строкой. ❷ Список кодов стран (по стандарту ISO 3166) с наибольшим населением, от- сортированный в порядке убывания численности населения. ❸ Сайт, откуда загружаются изображения флагов1. ❹ Локальный каталог, в котором сохраняются изображения. ❺ Скопировать img (последовательность байтов) в файл с именем filename в ка - талоге DEST_DIR. ❻ Зная код страны, построить URL-адрес и загрузить изображение; вернуть двоичное содержимое ответа. ❼ Считается правильным добавлять разумный тайм-аут для сетевых опера- ций, чтобы избежать ненужной блокировки на несколько минут. ❽ По умолчанию HTTPX не выполняет перенаправление2. ❾ В этом скрипте нет обработки ошибок, но данный метод возбуждает ис- ключение, если состояние HTTP не принадлежит диапазону 2XX. Это реко- мендуемая практика, позволяющая избежать «немых» отказов. ❿ download_many – основная функция, позволяющая провести сравнение с кон- курентными реализациями. ⓫ Обойти список стран в алфавитном порядке, чтобы порядок отображения на выходе был такой же, как на входе; вернуть количество загруженных изображений. ⓬ Отображать по одному коду страны за раз. Все коды отображаются в одной строке, чтобы было видно, как происходит загрузка. Аргумент end=' ' озна- чает, что обычный символ перевода строки в конце каждой строки нужно заменить пробелом, чтобы все коды стран отображались в одной строке один за другим. Аргумент flush=True необходим, потому что по умолчанию Python буферизует выходные строки, т. е. напечатанные символы отобра- жаются только после вывода символа перевода строки. ⓭ При вызове main необходимо указывать функцию, которая производит загрузку; таким образом, main можно будет использовать как библиотеч- ную функцию, способную работать и с другими реализациями download_many в примерах threadpool и ascyncio. ⓮ Создать каталог DEST_DIR, если необходимо; не возбуждать исключение, если каталог уже существует. ⓯ Запомнить и вывести истекшее время после завершения функции загрузки. ⓰ Вызвать main, передав ей функцию download_many . 1 Оригиналы изображений взяты из мировой книги фактов ЦРУ (http://1.usa.gov/1JIsmHJ), общедоступного сайта правительства США. Я скопировал их на свой сайт во избежа- ние непреднамеренной DoS-атаки на сайт cia.gov. 2 В этом примере задавать follow_redirects=True необязательно, но я хотел подчеркнуть важное различие между библиотеками HTTPX и requests. Кроме того, задание follow_ redirects=True позволяет мне разместить файлы изображений в другом месте, если в будущем возникнет такая необходимость. Я думаю, что подразумеваемое по умол- чанию в HTTPX значение follow_redirects=False разумно, потому что неожиданное перенаправление может замаскировать лишние запросы и усложнить диагностику ошибок. Конкурентная загрузка из веба  695\n--- Страница 695 ---\nИсточником вдохновения при написании библиотеки HTTPX (https://www.python-httpx.org/) стал пакет requests, но она построе- на на более современном фундаменте. Особенно важно, что HTTPX предлагает синхронный и асинхронный API, поэтому мы можем использовать ее во всех примерах HTTP-клиентов в этой и следующей главах. Стандартная библиотека Python содержит модуль urllib.request , но у него есть только синхронный API, да и тот не особенно дружелюбен к пользователю. Ничего особенно нового в скрипте flags.py нет. Он служит просто эталоном для сравнения с другими скриптами, а использую я его как библиотеку, что- бы не писать лишний код. Теперь рассмотрим другую реализацию – на основе биб лиотеки concurrent.futures . Загрузка с применением библиотеки concurrent.futures Основой пакета concurrent.futures являются классы ThreadPoolExecutor и ProcessPoolExecutor , которые реализуют API, позволяющий передавать вызыва- емые объекты соответственно потокам или процессам. Оба класса прозрачно управляют внутренним пулом рабочих потоков или процессов и очередью под- лежащих выполнению задач. Но поскольку интерфейс высокоуровневый, нам не нужно знать об этих деталях для такого простого дела, как загрузка флагов. В примере 20.3 показан простейший способ параллельной загрузки – мето- дом ThreadPoolExecutor.map . Пример 20.3. flags_threadpool.py: многопоточный скрипт загрузки с применением класса futures.ThreadPoolExecutor from concurrent import futures from flags import save_flag, get_flag, main  def download_one(cc: str):  image = get_flag(cc) save_flag(image, f'{cc}.gif') print(cc, end=' ', flush=True) return cc def download_many(cc_list: list[str]) -> int: with futures.ThreadPoolExecutor() as executor:  res = executor.map(download_one, sorted(cc_list))  return len(list(res))  if __name__ == '__main__': main(download_many)   Использовать некоторые функции из модуля flags (пример 20.2).  Функция, загружающая одно изображение; ее будет исполнять каждый поток.  Создать экземпляр ThreadPoolExecutor как контекстный менеджер; метод executor.__exit__ вызовет executor.shutdown(wait=True) , который блокирует вы- полнение программы до завершения всех потоков. 696  Конкурентные исполнители\n--- Страница 696 ---\n Метод map похож на встроенную функцию map с тем исключением, что функ - ция download_one конкурентно вызывается из нескольких потоков; он возвра- щает генератор, который можно обойти для получения значений, возвра- щенных каждой функцией, – в данном случае каждое обращение к download_ one возвращает код страны.  Вернуть количество полученных результатов. Если функция в каком-то по- токе возбудила исключение, то оно возникнет в этом месте, когда неявный вызов next() из конструктора list попытается получить соответствующее значение от итератора, возвращенного методом .map.  Вызвать функцию main из модуля flags, передавая ей конкурентную версию download_many . Отметим, что функция download_one из примера 20.3, по сути дела, является телом цикла for в функции download_many из примера 20.2. Это типичный ре- факторинг, встречающийся при написании конкурентного кода: преобразо- вать тело последовательного цикла for в функцию, которая будет вызываться конкурентно. Пример 20.3 получился очень коротким, потому что мне уда- лось повторно использовать большинство функций из после- довательного скрипта flags.py. Одна из самых замечательных особенностей concurrent.futures – то, как просто можно добавить конкурентное выполнение поверх унаследованного последова- тельного кода. Конструктор ThreadPoolExecutor принимает несколько аргументов, но пер- вым и самым важным является max_workers , который задает максимальное число исполняемых потоков. Если max_workers равно None (по умолчанию), то ThreadPoolExecutor вычисляет значение по формуле (начиная с версии Python 3.8): max_workers = min(32, os.cpu_count() + 4) Обоснование приводится в документации по ThreadPoolExecutor (https://docs. python.org/3.10/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor): Это значение по умолчанию оставляет как минимум 5 исполнителей для задач ввода-вывода. Оно позволяет задействовать не более 32 про- цессорных ядер для счетных задач, освобождающих GIL. А это позволя- ет избежать чрезмерного потребления ресурсов на многократноядер- ных машинах. Теперь класс ThreadPoolExecutor повторно использует простаивающие ра- бочие потоки, прежде чем запускать max_workers исполнителей. Итак, вычисленное значение max_workers разумно, и ThreadPoolExecutor не запус- кает новые рабочие потоки без необходимости. Понимание логики, стоящей за вычислением max_workers , поможет вам решить, когда и как устанавливать это значение самостоятельно. Библиотека называется concurrency.futures , но в примере 20.3 мы никаких «futures» не видели. Возникает законный вопрос: где же они? Ответ дан в сле- дующем разделе. Конкурентная загрузка из веба  697\n--- Страница 697 ---\nГде находятся будущие объекты? Будущие объекты – важнейшие компоненты внутреннего механизма пакетов concurrent.futures и asyncio, но не всегда они видны пользователям этих библио- тек. В примере 20.3 будущие объекты используются за кулисами, но мой код напрямую к ним не обращается. В этом разделе сообщаются общие сведения о будущих объектах, с примером их практического применения. Начиная с версии Python 3.4 в стандартной библиотеке есть два класса с именем Future: concurrent.futures.Future и asyncio.Future . Они служат одной и той же цели: экземпляр класса Future представляет некое отложенное вычисле- ние, завершившееся или нет. Это аналог класса Deferred в Twisted, класса Future в Tornado и объектов Promise в современном JavaScript. Будущие объекты инкапсулируют ожидающие операции, так что их можно помещать в очереди, опрашивать состояние завершения и получать результа- ты (или исключения), когда они станут доступны. Важно понимать, что ни вы, ни я не должны создавать будущие объекты: предполагается, что их создает исключительно используемая библиотека, будь то concurrent.futures или asyncio. Легко понять, почему это так: объект Future представляет нечто, что должно случиться когда-то в будущем, а единствен- ный способ гарантировать, что это действительно случится, – запланировать выполнение объекта. Поэтому экземпляры класса concurrent.futures.Future соз- даются только в результате планирования выполнения какой-то операции с помощью одного из подклассов concurrent.futures.Executor . Например, метод Executor.submit() принимает вызываемый объект, планирует его выполнение и возвращает будущий объект. Прикладной код не должен изменять состояние будущего объекта: его изме- нит каркас конкурентности, когда представляемое этим объектом вычисление завершится, а мы не можем управлять тем, когда это произойдет. Оба класса Future имеют неблокирующий метод .done(), который возвра- щает булево значение, показывающее, завершился вызываемый объект, свя- занный с экземпляром этого класса, или нет. Но вместо того чтобы раз за ра- зом интересоваться, не завершил ли работу будущий объект, клиент обычно просит, чтобы его уведомили. Поэтому в обоих классах Future имеется метод .add_done_callback() : если передать ему вызываемый объект, то он будет вызван, когда будущий объект завершится, а в качестве единственного аргумента бу- дет передан сам этот будущий объект. Имейте в виду, что вызываемый объект работает в том же потоке или процессе, что и функция, обернутая будущим объектом. Существует также метод .result(), который одинаково работает в обоих клас - сах в ситуации, когда выполнение будущего объекта завершено: либо возвра- щает результат вызываемого объекта, либо повторно возбуждает исключение, возникшее во время выполнения. Но если выполнение будущего объекта еще не завершено, то метод result ведет себя совершенно по-разному. В объекте класса concurrency.futures.Future вызов f.result() блокирует вызывающий поток до тех пор, пока не будет готов результат. Если передан необязательный аргу - мент timeout и выполнение будущего объекта не завершилось в отведенное вре- мя, то возбуждается исключение TimeoutError . Метод asyncio.Future.result не под -698  Конкурентные исполнители\n--- Страница 698 ---\nдерживает задание тайм-аута, а рекомендуемый способ получения результа- та будущего объекта заключается в использовании await – к объектам класса concurrency.futures.Future этот подход неприменим. Будущие объекты возвращаются несколькими функциями из обеих библио- тек; другие пользуются ими внутри себя, невидимо для пользователя. Приме- ром второго рода может служить функция Executor.map , с которой мы встреча- лись в примере 20.3: она возвращает итератор, метод __next__ которого вы- зывает метод result каждого будущего объекта, так что мы получаем не сами будущие объекты, а результаты их выполнения. Чтобы попрактиковаться в использовании будущих объектов, перепишем пример 17.3 с использованием функции concurrent.futures.as_completed , которая принимает итерируемый объект, содержащий будущие объекты, и возвращает итератор, который отдает будущие объекты по мере их выполнения. Чтобы можно было воспользоваться функцией futures.as_completed , необхо- димо внести изменения только в функцию download_many . Вызов высокоуровне- вого метода executor.map заменяется двумя циклами for: один – для создания и планирования будущих объектов, другой – для получения их результатов. И заодно уж добавим несколько вызовов print для печати каждого будущего объекта до и после завершения. В примере 20.4 показан код новой функции download_many . Количество строк в ней увеличилось с 5 до 17, зато теперь можно присмотреться к таинственным будущим объектам. Все остальные функции такие же, как в примере 20.3. Пример 20.4. flags_threadpool_futures.py: замена executor.map на executor.submit и futures. as_completed в функции download_many def download_many(cc_list: list[str]) -> int: cc_list = cc_list[:5]  with futures.ThreadPoolExecutor(max_workers=3) as executor:  to_do: list[futures.Future] = [] for cc in sorted(cc_list):  future = executor.submit(download_one, cc)  to_do.append(future)  print(f'Scheduled for {cc}: {future}')  for count, future in enumerate(futures.as_completed(to_do), 1):  res: str = future.result()  print(f'{future} result: {res!r}')  return count  Для этой демонстрации мы ограничимся только пятью странами с самой большой численностью населения.  Установить значение max_workers равным 3, чтобы можно было следить за ожидающими будущими объектами в распечатке.  Обойти коды стран в алфавитном порядке, чтобы было понятно, что ре- зультаты поступают не по порядку.  Метод executor.submit планирует выполнение вызываемого объекта и воз- вращает объект future, представляющий ожидаемую операцию.  Сохранить каждый будущий объект, чтобы впоследствии его можно было извлечь с помощью функции as_completed . Конкурентная загрузка из веба  699\n--- Страница 699 ---\n Вывести сообщение, содержащее код страны и соответствующий ему буду - щий объект future.  as_completed отдает будущие объекты по мере их завершения.  Получить результат этого объекта future.  Отобразить объект future и результат его выполнения. Отметим, что вызов future.result() в этом примере никогда не приводит к блокировке, потому что будущий объект получен как результат as_completed . В примере 20.5 показан результат одного прогона программы из примера 20.4. Пример 20.5. Результат работы скрипта flags_threadpool_futures.py $ python3 flags_threadpool_ac.py Scheduled for BR: <Future at 0x100791518 state=running>  Scheduled for CN: <Future at 0x100791710 state=running> Scheduled for ID: <Future at 0x100791a90 state=running> Scheduled for IN: <Future at 0x101807080 state=pending>  Scheduled for US: <Future at 0x101807128 state=pending> CN <Future at 0x100791710 state=finished returned str> result: 'CN'  BR ID <Future at 0x100791518 state=finished returned str> result: 'BR'  <Future at 0x100791a90 state=finished returned str> result: 'ID' IN <Future at 0x101807080 state=finished returned str> result: 'IN' US <Future at 0x101807128 state=finished returned str> result: 'US' 5 downloads in 0.70s  Будущие объекты планируются в алфавитном порядке; метод repr() буду - щего объекта показывает его состояние: первые три объекта выполняются, поскольку есть всего три рабочих потока.  Последние два будущих объекта ожидают освобождения рабочего потока.  Первое слово CN напечатано функцией download_one , исполняемой в рабочем потоке, остаток строки напечатан функцией download_many .  Здесь два потока выводят коды стран, прежде чем download_many в главном потоке получает возможность вывести результат объекта в первом по- токе. Я рекомендую поэкспериментировать со скриптом flags_ threadpool_futures.py. Если прогнать его несколько раз подряд, то мы увидим, что порядок вывода результатов изменяется. При увеличении max_workers до 5 изменчивость порядка усиливается, а при уменьшении до 1 код начинает работать последовательно, и результаты выводятся в том же порядке, в каком коды стран подавались методом submit. Мы видели два варианта скрипта загрузки с применением библиотеки concurrent.futures : пример 20.3 на основе метода ThreadPoolExecutor.map и при- мер 20.4 на основе futures.as_completed . Если вам не терпится увидеть код скрипта flags_asyncio.py, можете взглянуть на пример 21.3 в главе 21. А теперь посмотрим, как с помощью concurrent.futures можно просто обойти GIL для счетных задач. 700  Конкурентные исполнители\n--- Страница 700 ---\nзапуСк прОцеССОв С пОмОщью concurrent .futures Страница документации по пакету concurrent.futures (https://docs.python.org/3/ library/concurrent.futures.html) имеет подзаголовок «Запуск параллельных задач». Этот пакет поддерживает параллельные вычисления на многоядерных маши- нах, потому что умеет распределять работу между несколькими процессами Python благодаря классу ProcessPoolExecutor . И ProcessPoolExecutor , и ThreadPoolExecutor реализуют обобщенный интерфейс Executor (https://docs.python.org/3.10/library/concurrent.futures.html#concurrent. futures. Executor), поэтому, работая с concurrent.futures , очень легко переходить от реше- ния на основе потоков к решению на основе процессов и обратно. Использование ProcessPoolExecutor не дает никакого преимущества в примере загрузки флагов или в любой другой программе, ограниченной скоростью вво- да-вывода. И это легко проверить – просто измените следующие строки в при- мере 20.3: def download_many(cc_list: list[str]) -> int: with futures.ThreadPoolExecutor() as executor: на такие: def download_many(cc_list: list[str]) -> int: with futures.ProcessPoolExecutor() as executor: Конструктор ProcessPoolExecutor принимает также аргумент max_workers , по умолчанию равный None. В данном случае исполнитель ограничивает число ра- бочих процессов величиной, возвращаемой функцией os.cpu_count() . Процессы потребляют больше памяти и запускаются дольше, чем потоки, поэтому ценность ProcessPoolExecutor становится очевидной только для счет - ных задач. Давайте вернемся к примеру проверки чисел на простоту из раз- дела «Доморощенный пул процессов» главы 19 и перепишем его с помощью concurrent.futures . И снова о проверке на простоту на многоядерной машине В разделе «Код проверки на простоту для многоядерной машины» главы 19 мы изучали скрипт procs.py, который проверял большие числа на простоту с помощью пакета multiprocessing . В примере 20.6 та же задача решается с по- мощью скрипта proc_pool.py, в котором используется объект ProcessPoolExecutor . От первого предложения импорта и до вызова main() в конце скрипт procs.py насчитывает 43 непустые строки кода, а proc_pool.py только 31 – на 28 % короче. Пример 20.6. proc_pool.py: procs.py, переписанный с использованием ProcessPoolExecutor import sys from concurrent import futures  from time import perf_counter from typing import NamedTuple from primes import is_prime, NUMBERS class PrimeResult(NamedTuple):  n: int Запуск процессов с помощью concurrent.futures  701\n--- Страница 701 ---\nflag: bool elapsed: float def check(n: int) -> PrimeResult: t0 = perf_counter() res = is_prime(n) return PrimeResult(n, res, perf_counter() - t0) def main() -> None: if len(sys.argv) < 2: workers = None  else: workers = int(sys.argv[1]) executor = futures.ProcessPoolExecutor(workers)  actual_workers = executor._max_workers # type: ignore  print(f'Checking {len(NUMBERS)} numbers with {actual_workers} processes:') t0 = perf_counter() numbers = sorted(NUMBERS, reverse=True)  with executor:  for n, prime, elapsed in executor.map(check, numbers):  label = 'P' if prime else ' ' print(f'{n:16} {label} {elapsed:9.6f}s') time = perf_counter() - t0 print(f'Total time: {time:.2f}s') if __name__ == '__main__': main()  Нет нужды импортировать multiprocessing , SimpleQueue и т. д., потому что concurrent.futures скрывает все это.  Кортеж PrimeResult и функция check такие же, как в скрипте procs.py, но очере- ди и функция worker больше не нужны.  Вместо того чтобы самостоятельно решать, сколько рабочих процессов ис- пользовать, когда их количество в командной строке не задано, мы присва- иваем переменной workers значение None и отдаем решение на усмотрение ProcessPoolExecutor .  Здесь я создаю ProcessPoolExecutor раньше блока with в точке , чтобы в сле- дующей строке можно было напечатать фактическое количество рабочих процессов.  Переменная _max_workers – недокументированный атрибут экземпляра в классе ProcessPoolExecutor . Я решил использовать его, чтобы показать ко- личество рабочих процессов, когда переменная workers равна None. Mypy ру- гается – и правильно, – когда я обращаюсь к ней, поэтому я поставил type: ignore comment , чтобы утихомирить ее.  Отсортировать подлежащие проверке числа в порядке убывания. Это по- зволит высветить разницу в поведении proc_pool.py и procs.py. См. объясне- ние после данного примера.  Использовать executor как контекстный менеджер.702  Конкурентные исполнители\n--- Страница 702 ---\n Вызов executor.map возвращает экземпляры PrimeResult , полученные от функ - ции check, в таком же порядке, как аргументы numbers. Выполнив пример 20.6, вы увидите, что результаты появляются строго в по- рядке убывания, как показано в примере 20.7. Напротив, на порядок резуль- татов в procs.py (показан в разделе «Решение на основе процессов» главы 19) сильно влияет трудность проверки конкретного числа на простоту. Напри- мер, procs.py показывает результат для 7777777777777777 в начале, потому что у этого числа есть малый множитель 7, поэтому is_prime быстро определяет, что число не простое. С другой стороны, 7777777536340681 равно 881917092, поэтому is_prime требу - ется гораздо больше времени, чтобы убедиться в том, что это составное число, и еще больше времени, чтобы понять, что число 7777777777777753 простое, – поэтому оба этих числа находятся в конце списка, напечатанного procs.py. Запустив proc_pool.py, вы увидите еще одну вещь – кажется, что программа зависла, напечатав результат для 9999999999999999. Пример 20.7. Вывод proc_pool.py $ ./proc_pool.py Checking 20 numbers with 12 processes: 9999999999999999 0.000024s  9999999999999917 P 9.500677s  7777777777777777 0.000022s  7777777777777753 P 8.976933s 7777777536340681 8.896149s 6666667141414921 8.537621s 6666666666666719 P 8.548641s 6666666666666666 0.000002s 5555555555555555 0.000017s 5555555555555503 P 8.214086s 5555553133149889 8.067247s 4444444488888889 7.546234s 4444444444444444 0.000002s 4444444444444423 P 7.622370s 3333335652092209 6.724649s 3333333333333333 0.000018s 3333333333333301 P 6.655039s 299593572317531 P 2.072723s 142702110479723 P 1.461840s 2 P 0.000001s Total time: 9.65s  Эта строка появляется очень быстро.  Перед печатью строки проходит более 9,5 с.  Остальные строки появляются почти сразу. Объясним, почему proc_pool.py ведет себя таким образом. Как уже отмечалось, executor.map(check, numbers) возвращает результаты в том же порядке, в каком заданы числа numbers. По умолчанию proc_pool.py использует столько рабочих процессов, сколь- ко имеется процессоров, – именно так ведет себя ProcessPoolExecutor , когда max_workers равно None. На моем ноутбуке запущено 12 процессов. Запуск процессов с помощью concurrent.futures  703\n--- Страница 703 ---\nПоскольку мы подаем numbers в порядке убывания, первое число равно 9999999999999999; у него есть делитель 9, так что проверка завершается быстро. Второе число равно 9999999999999917, это самое большое простое число в нашей выборке. На его проверку уходит больше времени, чем на про- верку любого другого числа. Тем временем остальные 11 процессов занимаются проверкой других чисел, которые являются либо простыми, либо составными с большими множителями, либо составными с очень малыми множителями. Когда процесс, отвечающий за число 9999999999999917, наконец опре- делит, что оно простое, все остальные процессы уже завершили работу, поэтому результаты появляются немедленно. Хотя продвижение скрипта proc_pool.py не так наглядно, как в случае procs.py, общее время выполнения практически такое же, как на рис. 19.2, при том же числе рабочих процессов и про- цессорных ядер. Понять поведение конкурентных программ непросто, поэтому я опишу второй эксперимент, который поможет наглядно представить, как работает Executor.map . Эксперименты с Executor.map Изучим метод Executor.map , на этот раз воспользовавшись классом ThreadPoolExecutor с тремя рабочими потоками, исполняющими пять вызываемых объектов, кото- рые выводят сообщения с временными метками. Код показан в примере 20.8, а результат в примере 20.9. Пример 20.8. demo_executor_map.py: простая демонстрация метода map объекта ThreadPoolExecutor from time import sleep, strftime from concurrent import futures def display(*args):  print(strftime('[%H:%M:%S]'), end=' ') print(*args) def loiter(n):  msg = '{}loiter({}): doing nothing for {}s ' display(msg.format('\\t'*n, n, n)) sleep(n) msg = '{}loiter({}): done.' display(msg.format('\\t'*n, n)) return n * 10 def main():  display('Script starting.') executor = futures.ThreadPoolExecutor(max_workers=3)  results = executor.map(loiter, range(5))  display('results:', results)  704  Конкурентные исполнители\n--- Страница 704 ---\ndisplay('Waiting for individual results:') for i, result in enumerate(results):  display(f'result {i}: {result}') if __name__ == '__main__': main()  Эта функция печатает переданные ей аргументы, добавляя временную метку в формате [HH:MM:SS] .  Функция loiter печатает время начала работы, затем спит n секунд и пе- чатает время окончания; знаки табуляции формируют отступ сообщения в соответствии с величиной n.  loiter возвращает n * 10, чтобы нагляднее представить результаты.  Создать объект ThreadPoolExecutor с тремя потоками.  Передать исполнителю executor пять задач (поскольку есть только три по- тока, сразу начнут выполнение лишь три из них: вызывающие loiter(0), loiter(1) и loiter(2)); это неблокирующий вызов.  Немедленно распечатать объект results, полученный от executor.map : это ге- нератор, как видно из результатов, показанных в примере 20.9.  Обращение к enumerate в цикле for неявно вызывает функцию next(results) , которая, в свою очередь, вызывает метод _f.result() (внутреннего) будуще- го объекта _f, представляющего первый вызов, loiter(0). Метод result блоки- рует программу до завершения будущего объекта, поэтому каждая итера- ция этого цикла будет ждать готовности следующего результата. Призываю вас прогнать пример 20.8 и полюбоваться на то, как постепенно печатаются сообщения. А заодно уж поэкспериментируйте с аргументом max_ workers объекта ThreadPoolExecutor и с функцией range, которая порождает аргу - менты для обращения к executor.map , – или замените ее списками подобранных вручную значений, если хотите задать другие задержки. В примере 20.9 показаны результаты прогона программы из примера 20.8. Пример 20.9. Результаты прогона скрипта demo_executor_map.py из примера 20.8 $ python3 demo_executor_map.py [15:56:50] Script starting.  [15:56:50] loiter(0): doing nothing for 0s  [15:56:50] loiter(0): done. [15:56:50] loiter(1): doing nothing for 1s  [15:56:50] loiter(2): doing nothing for 2s [15:56:50] results: <generator object result_iterator at 0x106517168>  [15:56:50] loiter(3): doing nothing for 3s  [15:56:50] Waiting for individual results: [15:56:50] result 0: 0  [15:56:51] loiter(1): done.  [15:56:51] loiter(4): doing nothing for 4s [15:56:51] result 1: 10  [15:56:52] loiter(2): done.  [15:56:52] result 2: 20 [15:56:53] loiter(3): done. [15:56:53] result 3: 30 [15:56:55] loiter(4): done.  [15:56:55] result 4: 40 Запуск процессов с помощью concurrent.futures  705\n--- Страница 705 ---\n Прогон начался в 15:56:50.  Первый поток выполняет loiter(0), поэтому спит 0 с и завершается еще до того, как второй поток запустился, но на вашей машине все может быть по- другому1.  loiter(1) и loiter(2) запускаются немедленно (поскольку в пуле три рабочих потока, он может одновременно выполнять три функции).  Отсюда видно, что объект results, возвращенный executor.map , – генератор; до сих пор никаких блокировок не было вне зависимости от количества за- дач и значения max_workers .  Поскольку loiter(0) завершилась, первый рабочий поток готов к выполне- нию loiter(3).  Здесь выполнение может быть заблокировано в зависимости от парамет- ров loiter: метод __next__ генератора results должен дождаться завершения первого будущего объекта. В данном случае блокировки не будет, потому что вызов loiter(0) завершился еще до начала цикла. Отметим, что все дей- ствия до этого места произошли в течение одной секунды: 15:56:50.  loiter(1) завершается в следующую секунду – в 15:56:51. Поток освобожда- ется и готов к выполнению loiter(4).  Показан результат loiter(1): 10. Теперь цикл for блокируется в ожидании ре- зультата loiter(2).  Картина повторяется: loiter(2) завершается и печатается его результат; за- тем то же самое для loiter(3).  loiter(4) завершается после двухсекундной задержки, поскольку началась в 15:56:51 и ничего не делала 4 с. Функцией executor.map пользоваться легко, но зачастую желательно получать результаты по мере готовности вне зависимости от порядка подачи исходных данных. Для этого нужна комбинация метода executor.submit и функции futures. as_completed , которую мы видели в примере 20.4. Мы вернемся к этой технике в разделе «Использование futures.as_completed » ниже. Комбинация executor.submit и futures.as_completed обладает боль- шей гибкостью, чем executor.map , потому что ей можно подавать различные вызываемые объекты и аргументы, тогда как executor. map предназначена для выполнения одного и того же вызывае- мого объекта с разными аргументами. Кроме того, множество будущих объектов, передаваемых futures.as_completed , может по- ступать от нескольких исполнителей – одни из них могли быть созданы экземпляром ThreadPoolExecutor , другие – экземпляром ProcessPoolExecutor . В следующем разделе мы вернемся к программам загрузки флагов, но предъ- явим новые требования, которые заставят нас обходить результаты futures.as_ completed вместо использования executor.map . 1 С потоками никогда не знаешь точную последовательность событий, которые долж - ны произойти практически одновременно; вполне возможно, что на другой машине loiter(1) начнется раньше, чем loiter(0) завершится, особенно если учесть, что sleep всегда освобождает GIL, так что Python может переключиться на другой поток, пусть даже текущий спал 0 с. 706  Конкурентные исполнители\n--- Страница 706 ---\nзагрузка С индикацией хОда выпО лнения и ОБраБО ткОй ОшиБОк Как уже отмечалось, в скриптах из раздела «Пример: три способа загрузки из веба» нет обработки ошибок. Это сделано для того, чтобы их было проще чи- тать и сравнивать три подхода: последовательный, многопоточный и асин- хронный. Для тестирования обработки различных ошибок я создал следующие скрипты: flags2_common.py Этот модуль содержит общие функции и параметры, используемые во всех flags2-скриптах, в том числе функцию main, которая занимается разбором командной строки, хронометражем и выводом результатов. Это чисто вспомогательный модуль, не имеющий прямого отношения к теме главы, поэтому я не стал помещать здесь исходный код, но вы можете найти его на сопроводительном сайте в репозитории fluentpython/example-code-2e: файл 20-executors/getflags/flags2_common.py. flags2_sequential.py Последовательный HTTP-клиент с корректной обработкой ошибок и инди- кацией хода выполнения. Функция download_one из этого модуля использует - ся также в скрипте flags2_threadpool.py. flags2_threadpool.py Конкурентный HTTP-клиент, основанный на классе futures.ThreadPoolExecutor ; демонстрирует обработку ошибок и интеграцию с индикатором хода вы- полнения. flags2_asyncio.py Та же функциональность, что в предыдущем примере, но на основе asyncio и aiohttp. Будет рассмотрен в разделе «Улучшение скрипта загрузки на ос- нове asyncio» главы 21. Будьте осторожны при тестировании параллельных клиентов При тестировании параллельных HTTP-клиентов, обращаю- щихся к публичным HTTP-серверам, количество запросов в се- кунду может быть довольно велико, а это признак DoS-атаки. Искусственно ограничивайте производительность клиентов, посылающих запросы публичным серверам. Для тестирования настройте свой локальный HTTP-сервер. Инструкции о том, как это сделать, приведены в разделе «Настройка тестовых серве- ров» ниже. Самое заметное визуальное отличие flags2-скриптов состоит в том, что они выводят анимированный текстовый индикатор хода выполнения, реализо- ванный с помощью пакета tqdm ( https://github.com/noamraph/tqdm). Я размес - тил на YouTube ролик продолжительностью 108 с (https://www.youtube.com/ watch?v=M8Z65tAl5l4), в котором показан индикатор и сравнивается скорость работы всех трех скриптов. В этом ролике я сначала запустил последователь- Загрузка с индикацией хода выполнения и обработкой ошибок  707\n--- Страница 707 ---\nный загрузчик, но через 32 с прервал его, потому что для обращения к 676 URL- адресам и загрузки 194 флагов ему требуется больше 5 минут. Затем я по три раза прогнал многопоточный и асинхронный скрипты, и всякий раз они завер- шали работу не более чем за 6 с (т. е. в 60 с лишним раз быстрее). На рис. 20.1 показаны два снимка экрана: во время и после работы flags2_threadpool.py. Рис. 20.1. Слева вверху: скрипт flags2_threadpool.py с динамическим индикатором хода вы- полнения, созданным с помощью tqdm. Справа внизу: то же окно терминала после заверше- ния скрипта Простейший пример использования TQDM приведен в анимированном GIF-файле в файле проекта README.md ( https://github.com/noamraph/tqdm/blob/ master/README.md). Установив пакет tqdm и набрав следующий код в оболоч- ке Python, вы увидите анимированный индикатор хода выполнения на месте комментария: >>> import time >>> from tqdm import tqdm >>> for i in tqdm(range(1000)): time.sleep(.01) >>> # -> здесь будет индикатор хода выполнения <- Помимо зрительно приятного эффекта, функция tqdm интересна и с концеп- туальной точки зрения: она принимает произвольный итерируемый объект и порождает итератор, при обходе которого отображаются индикатор хода вы- полнения и оценка времени, оставшегося до завершения всех итераций. Чтобы вычислить эту оценку, tqdm должна получать либо итерируемый объект, имею- щий метод len, либо второй аргумент, который содержит ожидаемое количест - во элементов. Включение tqdm в наши flags2-примеры дает возможность ближе познакомиться с внутренним устройством параллельных скриптов, поскольку заставляет использовать функции futures.as_completed (https://docs.python.org/3/ library/concurrent.futures.html#concurrent.futures.as_completed) и asyncio.as_completed (https://docs.python.org/3/library/asyncio-task.html#asyncio.as_completed), чтобы tqdm могла показать индикатор в момент завершения каждого будущего объекта. Еще одна особенность flags2-примеров – интерфейс командной строки. Все три скрипта принимают одни и те же параметры, а чтобы увидеть их, нужно запустить скрипт с флагом -h. Текст справки показан в примере 20.10.708  Конкурентные исполнители\n--- Страница 708 ---\nПример 20.10. Справка для скриптов из серии flags2 $ python3 flags2_threadpool.py -h usage: flags2_threadpool.py [-h] [-a] [-e] [-l N] [-m CONCURRENT] [-s LABEL] [-v] [CC [CC ]] Загружает флаги стран с указанными кодами. По умолчанию: 20 стран с наибольшим населением. Позиционные аргументы: CC код страны или первая буква (например, B вместо BA BZ) Необязательные аргументы: -h, --help вывести это сообщение и выйти -a, --all вывести все имеющиеся флаги (от AD до ZW) -e, --every вывести флаги для всех возможных кодов (AA ZZ) -l N, --limit N ограничиться первыми N кодами -m CONCURRENT, --max_req CONCURRENT максимальное число параллельных запросов (по умолчанию 30) -s LABEL, --server LABEL тип сервера: DELAY, ERROR, LOCAL, REMOTE (по умолчанию LOCAL) -v, --verbose выводить подробную информацию о ходе выполнения Все аргументы необязательны. Но параметр -s/--server игнорировать не следует: он позволяет задать тип и URL-адрес HTTP-сервера, к которо- му будет обращаться скрипт. Можно задать одну из четырех строк (регистр не важен): LOCAL Использовать адрес http://localhost:8000/flags ; это значение по умолчанию. Локальный HTTP-сервер следует настроить так, чтобы он отвечал на запро- сы к порту 8000. См. инструкции в следующем замечании. REMOTE Использовать http://fluentpython.com/data/flags ; это принадлежащий мне пуб- личный сайт, размещенный на разделяемом сервере. Не бомбардируй- те его слишком большим количеством параллельных запросов. Домен fluentpython.com связан с бесплатной учетной записью в Cloudflare CDN (http://www.cloudflare.com/), так что первые загрузки могут оказаться доволь- но медленными, но скорость возрастет по мере прогрева кеша CDN. DELAY Использовать http://localhost:8001/flags ; прокси-сервер, задерживающий HTTP-ответы, должен прослушивать порт 8001. Чтобы было проще экспе- риментировать, я написал скрипт slow_server.py. Вы можете найти его в ка- талоге 20-futures/getflags/ репозитория кода (https://github.com/fluentpython/ example-code-2e). См. инструкции в следующем замечании. ERROR Использовать http://localhost:8002/flags ; сервер, отправляющий коды ошибок HTTP, должен прослушивать порт 8002. Инструкции см. ниже Загрузка с индикацией хода выполнения и обработкой ошибок  709\n--- Страница 709 ---\nНастройка тестовых серверов На случай, если у вас нет локального HTTP-сервера для тести- рования, я написал инструкцию по настройке с использовани- ем только Python ≥ 3.9 (без внешних библиотек) и поместил ее в файл 20-executors/getflags/README.adoc ( https://github.com/ fluentpython/example-code-2e/tree/master/20-executors/getflags) в ка- талоге репозитория fluentpython/examplecode-2e. В двух словах README.adoc описывает, как использовать: python3 -m http.server Сервер LOCAL, прослушивающий порт 8000. python3 slow_server.py Сервер DELAY, прослушивающий порт 8001 и добавляющий случайную задержку 0 от 0,5 с до 5 с перед каждым ответом. python3 slow_server.py 8002 --error-rate .25 Сервер ERROR, прослушивающий порт 8002, который помимо случайной задержки с вероятностью 25 % возвращает ответ «418 I’m a teapot», означающий ошибку. По умолчанию каждый flags2-скрипт загружает флаги 20 стран с самым боль- шим населением с локального сервера (http://localhost:8000/flags ), открывая определенное количество соединений по умолчанию, для каждого скрипта свое. В примере 20.11 показан результат прогона скрипта flags2_sequential.py, когда все параметры заданы по умолчанию. Чтобы его выполнить, нужен ло- кальный сервер, настроенный, как описано в примечании «Будьте осторожны при тестировании параллельных клиентов» выше. Пример 20.11. Прогон flags2_sequential.py с параметрами по умолчанию: сервер LOCAL, флаги 20 самых густонаселенных стран, 1 соединение $ python3 flags2_sequential.py LOCAL site: http://localhost:8001/flags Searching for 20 flags: from BD to VN 1 concurrent connection will be used. -------------------- 20 flags downloaded. Elapsed time: 0.10s Задать набор загружаемых флагов можно несколькими способами. В приме- ре 20.12 показано, как загрузить флаги всех стран, коды которых начинаются с букв A, B, C. Пример 20.12. Прогон flags2_threadpool.py для загрузки флагов всех стран, коды которых начинаются с букв A, B, C, с сервера DELAY $ python3 flags2_threadpool.py -s DELAY a b c DELAY site: http://localhost:8002/flags Searching for 78 flags: from AA to CZ 30 concurrent connections will be used. -------------------- 43 flags downloaded. 35 not found. Elapsed time: 1.72s 710  Конкурентные исполнители\n--- Страница 710 ---\nНезависимо от способа задания кодов стран количество загружаемых фла- гов можно ограничить с помощью параметра -l/--limit . В примере 20.13 пока- зано, как выполнить ровно 100 запросов с помощью комбинации параметра -a, запрашивающего все флаги, и параметра -l 100. Пример 20.13. Прогон flags2_asyncio.py с загрузкой 100 флагов (-al 100) с сервера ERROR, 100 одновременных соединений ( -m 100) $ python3 flags2_asyncio.py -s ERROR -al 100 -m 100 ERROR site: http://localhost:8003/flags Searching for 100 flags: from AD to LK 100 concurrent connections will be used. -------------------- 73 flags downloaded. 27 errors. Elapsed time: 0.64s Так выглядит пользовательский интерфейс flags2-примеров. Теперь познако- мимся с их реализацией. Обработка ошибок во flags2-примерах Общая стратегия обработки ошибок HTTP заключается в том, что ошибки 404 (Не найдено) обрабатываются функцией, отвечающей за загрузку одного файла (download_one ), а все остальные исключения распространяются наружу и обраба- тываются функцией download_many или сопрограммой supervisor (в примере asyncio). И на этот раз начнем с рассмотрения последовательного кода, за выполне- нием которого легко проследить; многие функции из него будут использо- ваться и в многопоточном скрипте. В примере 20.14 показаны функции, кото- рые, собственно, и выполняют загрузку в скриптах flags2_sequential.py и flags2_ threadpool.py. Пример 20.14. flags2_sequential.py: базовые функции, отвечающие за загрузку, обе исполь- зуются также в скрипте flags2_threadpool.py from collections import Counter from http import HTTPStatus import httpx import tqdm # type: ignore  from flags2_common import main, save_flag, DownloadStatus  DEFAULT_CONCUR_REQ = 1 MAX_CONCUR_REQ = 1 def get_flag(base_url: str, cc: str) -> bytes: url = f'{base_url}/{cc}/{cc}.gif'.lower() resp = httpx.get(url, timeout=3.1, follow_redirects=True) resp.raise_for_status()  return resp.content def download_one(cc: str, base_url: str, verbose: bool = False) -> DownloadStatus: try: image = get_flag(base_url, cc) Загрузка с индикацией хода выполнения и обработкой ошибок  711\n--- Страница 711 ---\nexcept httpx.HTTPStatusError as exc:  res = exc.response if res.status_code == HTTPStatus.NOT_FOUND: status = DownloadStatus.NOT_FOUND  msg = f'not found: {res.url}' else: raise  else: save_flag(image, f'{cc}.gif') status = DownloadStatus.OK msg = 'OK' if verbose:  print(cc, msg) return status  Импортировать библиотеку tqdm для отображения индикатора хода выпол- нения и сказать Mypy, что проверять ее не надо1.  Импортировать две функции и перечисление Enum из модуля flags2_common .  Возбуждает исключение HTTPStatusError , если код состояния HTTP не при- надлежит диапазону range(200, 300) .  Функция download_one перехватывает исключение HTTPStatusError , чтобы об- работать ошибку с кодом 404 и только ее…  …установив локальное состояние status равным DownloadStatus.NOT_FOUND ; DownloadStatus – перечисление, импортированное из flags2_common.py.  Любое другое исключение типа HTTPStatusError возбуждается повторно и рас - пространяется в вызывающую программу.  Если задан параметр -v/--verbose , то отображается сообщение, содержащее код страны и состояние; именно так мы видим индикатор хода выполне- ния в режиме вывода подробной информации. В примере 20.15 приведена последовательная версия функции download_many . Ее код прямолинеен, но его стоит изучить хотя бы для сравнения с конкурент - ными версиями. Обратите внимание на индикацию хода выполнения, обра- ботку ошибок и подсчет количества загрузок с разным исходом. Пример 20.15. flags2_sequential.py: последовательная реализация download_many def download_many(cc_list: list[str], base_url: str, verbose: bool, _unused_concur_req: int) -> Counter[DownloadStatus]: counter: Counter[DownloadStatus] = Counter() ❶ cc_iter = sorted(cc_list) ❷ if not verbose: cc_iter = tqdm.tqdm(cc_iter) ❸ for cc in cc_iter: try: status = download_one(cc, base_url, verbose) ❹ 1 По состоянию на сентябрь 2021 года в tdqm не было аннотаций типов. Это нормально. Мир из-за этого не рухнет. Спасибо Гвидо за факультативную типизацию!712  Конкурентные исполнители\n--- Страница 712 ---\nexcept httpx.HTTPStatusError as exc: ❺ error_msg = 'HTTP error {resp.status_code} - {resp.reason_phrase}' error_msg = error_msg.format(resp=exc.response) except httpx.RequestError as exc: ❻ error_msg = f'{exc} {type(exc)}'.strip() except KeyboardInterrupt: ❼ break else: ❽ error_msg = '' if error_msg: status = DownloadStatus.ERROR ❾ counter[status] += 1 ❿ if verbose and error_msg: ⓫ print(f'{cc} error: {error_msg}') return counter ⓬ ❶ Этот объект Counter подсчитывает количество загрузок с разными исхода- ми: DownloadStatus.OK , DownloadStatus.NOT_FOUND , DownloadStatus.ERROR . ❷ В cc_iter хранится отсортированный по алфавиту список кодов стран, полу - ченных в виде аргументов. ❸ Если не задан режим подробной информации, то cc_iter передается функ - ции tqdm, которая возвращает итератор cc_iter, отдающий элементы, и одно- временно отображает анимированный индикатор хода выполнения. ❹ Последовательные обращения к download_one . ❺ Относящиеся к HTTP исключения, возбужденные функцией get_flag и не об- работанные в download_one , обрабатываются здесь. ❻ Прочие относящиеся к сети исключения обрабатываются здесь. Все осталь- ные исключения аварийно завершают скрипт, потому что в функции flags2_ common.main , из которой вызывается download_many , нет блока try/except . ❼ Выйти из цикла, если пользователь нажал Ctrl-C. ❽ Если исключение не вышло за пределы download_one , очистить сообщение об ошибке. ❾ Если произошла ошибка, устанавливаем соответствующее значение status. ❿ Увеличиваем счетчик для этого значения status. ⓫ При работе в режиме подробной информации отображаем сообщение об ошибке для текущего кода страны, если таковое имеется. ⓬ Возвращаем counter, чтобы функция main могла вывести финальный отчет. Теперь рассмотрим переработанный пример с пулом потоков, flags2_ threadpool.py. Использование futures.as_completed Чтобы включить индикатор хода выполнения и обработку ошибок, мы исполь- зуем в скрипте flags2_threadpool.py класс futures.ThreadPoolExecutor совместно с уже встречавшейся функцией futures.as_completed . В примере 20.16 приведен полный код flags2_threadpool.py. Заново реализована только функция download_many ; все остальные функции заимствованы из модулей flags2_common и flags2_sequential . Загрузка с индикацией хода выполнения и обработкой ошибок  713\n--- Страница 713 ---\nПример 20.16. flags2_threadpool.py: полный исходный код from collections import Counter from concurrent.futures import ThreadPoolExecutor, as_completed import httpx import tqdm # type: ignore from flags2_common import main, DownloadStatus from flags2_sequential import download_one ❶ DEFAULT_CONCUR_REQ = 30 ❷ MAX_CONCUR_REQ = 1000 ❸ def download_many(cc_list: list[str], base_url: str, verbose: bool, concur_req: int) -> Counter[DownloadStatus]: counter: Counter[DownloadStatus] = Counter() with ThreadPoolExecutor(max_workers=concur_req) as executor: ❹ to_do_map = {} ❺ for cc in sorted(cc_list): ❻ future = executor.submit(download_one, cc, base_url, verbose) ❼ to_do_map[future] = cc ❽ done_iter = as_completed(to_do_map) ❾ if not verbose: done_iter = tqdm.tqdm(done_iter, total=len(cc_list)) ❿ for future in done_iter: ⓫ try: status = future.result() ⓬ except httpx.HTTPStatusError as exc: ⓭ error_msg = 'HTTP error {resp.status_code} - {resp.reason_phrase}' error_msg = error_msg.format(resp=exc.response) except httpx.RequestError as exc: error_msg = f'{exc} {type(exc)}'.strip() except KeyboardInterrupt: break else: error_msg = '' if error_msg: status = DownloadStatus.ERROR counter[status] += 1 if verbose and error_msg: cc = to_do_map[future] ⓮ print(f'{cc} error: {error_msg}') return counter if __name__ == '__main__': main(download_many, DEFAULT_CONCUR_REQ, MAX_CONCUR_REQ) ❶ Повторно использовать функцию donwload_one из flags2_sequential (при- мер 20.14).714  Конкурентные исполнители\n--- Страница 714 ---\n❷ Если в командной строке не задан параметр -m/--max_req , то принимаем та- кое максимальное число конкурентных запросов, оно и станет размером пула потоков. Фактическое число потоков может быть меньше, если загру - жается меньше флагов. ❸ MAX_CONCUR_REQ – максимальное число конкурентных запросов независимо от числа загружаемых флагов и от значения параметра -m/--max_req ; это мера предосторожности, позволяющая избежать запуска слишком большого числа потоков и чрезмерного потребления памяти. ❹ Создать объект executor с параметром max_workers , равным величине concur_ req, которую функция main вычисляет как минимум из MAX_CONCUR_REQ , длины списка cc_list, и значения параметра командной строки -m/--max_req . Это по- зволяет избежать создания большего числа потоков, чем необходимо. ❺ Этот словарь отображает каждый экземпляр Future – представляющий одну загрузку – на соответствующий код страны для показа в сообщении об ошибке. ❻ Обходим список кодов стран в алфавитном порядке. Порядок результатов зависит прежде всего от времени получения HTTP-ответа, но если размер пула (определяемый величиной concur_req ) гораздо меньше len(cc_list) , то может оказаться, что результаты возвращаются по алфавиту. ❼ Каждое обращение к executor.submit планирует выполнение одного вызыва- емого объекта и возвращает экземпляр Future. Первый аргумент – сам вы- зываемый объект, остальные – передаваемые ему аргументы. ❽ Сохранить future и код страны в словаре. ❾ Функция futures.as_completed возвращает итератор, который отдает будущие объекты по мере их завершения. ❿ Если не установлен режим подробной информации, то обертываем ре- зультат as_completed функцией tqdm, которая отображает индикатор хода вы- полнения; поскольку у done_iter нет метода len, мы должны сообщить tqdm ожидаемое количество элементов в виде аргумента total=, чтобы tqdm могла оценить объем оставшейся работы. ⓫ Обойти будущие объекты по мере их завершения. ⓬ Вызов метода result будущего объекта возвращает значение, полученное от вызываемого объекта, или возбуждает исключение, которое было перехва- чено во время выполнения объекта. Этот метод может блокировать про- грамму в ожидании разрешения ситуации, но не в данном примере, пото- му что as_completed возвращает только уже завершенные будущие объекты. ⓭ Обработать потенциальные исключения; оставшаяся часть функции отли- чается от кода последовательной версии download_many (пример 20.15) только в месте следующей выноски. ⓮ Чтобы предоставить контекст для сообщения об ошибке, извлекаем код страны из словаря to_do_map, используя в качестве ключа текущий объект future. В последовательной версии это было необязательно, потому что мы обходили список кодов стран, так что текущий cc всегда был под рукой; здесь же мы обходим будущие объекты. Загрузка с индикацией хода выполнения и обработкой ошибок  715\n--- Страница 715 ---\nВ примере 20.16 используется идиома, очень полезная при рабо- те с функцией futures.as_completed : построить словарь, ставящий в соответствие каждому будущему объекту данные, которые можно будет использовать по завершении этого объекта. В дан- ном случае словарь to_do_map сопоставляет с будущим объектом соответствующий ему код страны. Это упрощает последующую обработку будущих объектов, несмотря на то что завершаться они могут не по порядку. Потоки Python отлично приспособлены к приложениям с большим объемом ввода-вывода, а благодаря пакету concurrent.futures их использование в ряде слу- чаев оказывается сравнительно простым. С помощью класса ProcessPoolExecutor мы также можем решать счетные задачи на нескольких ядрах – если вычис - ления «естественно параллельны» (https://en.wikipedia.org/wiki/Embarrassingly_ parallel). На этом мы завершаем введение в пакет concurrent.futures . резюме В начале этой главы мы сравнили два параллельных HTTP-клиента с после- довательным и убедились в том, что распараллеливание дает значительный выигрыш в производительности. Изучив первый пример, основанный на пакете concurrent.futures , мы реши- ли поближе познакомиться с будущими объектами – экземплярами класса concurrent.futures.Future или asyncio.Future , – уделив особое внимание общим чер- там этих классов (различия между ними будут рассмотрены в главе 21). Мы ви- дели, как создавать будущие объекты методом Executor.submit и как обходить завершенные объекты с помощью функции concurrent.futures.as_completed . Затем обсудили запуск нескольких процессов с помощью класса concurrent. futures.ProcessPoolExecutor , что позволяет обойти ограничение GIL и, задейство- вав несколько процессорных ядер, упростить программу проверки чисел на простоту из главы 19. В следующем разделе мы изучили, как работает класс concurrent.futures. ThreadPoolExecutor на учебном примере, где запускались задачи, которые прос- то спали несколько секунд, ничего не делая, а затем печатали свое состояние и временную метку. Далее мы вернулись к примерам загрузки изображений флагов. Чтобы до- бавить в них индикатор хода выполнения и корректную обработку ошибок, нам пришлось углубиться в детали генераторной функции future.as_completed , и в результате мы открыли для себя общий прием: сохранение будущих объектов в словаре вместе с дополнительной информацией в момент передачи испол- нителю и использование этой информации впоследствии – когда итератор as_ completed отдает завершенный будущий объект. дОпО лнительная литература Автором пакета concurrent.futures является Брайан Куинлан, который презен- товал его в блестящем докладе под названием «Будущее уже близко!» (https:// pyvideo.org/pycon-au-2010/pyconau-2010-the-future-is-soon.html) на конференции 716  Конкурентные исполнители\n--- Страница 716 ---\nPyCon Australia 2010. Доклад Куинлана не сопровождается слайдами; он де- монстрирует возможности библиотеки, вводя код прямо в оболочке Python. В качестве пояснительного примера на презентации был показан короткий ролик, созданный автором веб-комикса и программистом Рэнделлом Манро, в котором он непреднамеренно организовал DoS-атаку на сайт Google Maps, чтобы построить цветную карту времени поездок на автомобиле в своем го- роде. Формальное введение в библиотеку содержится в документе PEP 3148 «futures – execute computations asynchronously» (https://www.python.org/dev/peps/ pep-3148/). В нем Куинлан пишет, что на библиотеку concurrent.futures «большое влияние оказал пакет java.util.concurrent для Java». Дополнительные ресурсы, относящиеся к пакету concurrent.futures , рассмат- риваются в главе 19. Все ссылки, касающиеся пакетов threading и multiprocessing , приведенные в разделе «Конкурентность с применением потоков и процес - сов» главы 19, относятся к пакету concurrent.futures . Поговорим Держаться подальше от потоков Конкурентность – один из самых трудных вопросов информатики (лучше держаться от него подальше). – Дэвид Бизли, преподаватель Python и безумный ученый1 Я согласен с, казалось бы, противоречащими друг другу высказываниями Дэвида Бизли (см. выше) и Мишеля Симионато (взято в качестве эпиграфа к этой главе). Я прослушал в университете курс по конкурентности. Там мы занимались только программированием потоков POSIX (https://en.wikipedia.org/wiki/Pthreads). И я пришел к выводу, что управлять потоками и блокировками самостоятельно я хочу ничуть не больше, чем заниматься выделением и освобождением памя- ти. Такие вещи лучше оставить системным программистам, которые знают, как это делать, любят с этим возиться и располагают временем, чтобы сделать все правильно, – по крайней мере, я надеюсь на это. Мне же платят за разработку приложений, а не операционных систем. Мне ни к чему точный контроль над потоками, блокировками, malloc и free – см. статью «Динамическое распределе- ние памяти в C» (https://en.wikipedia.org/wiki/C_dynamic_memory_allocation). Потому-то я и считаю пакет concurrent.futures выдающимся достижением: в нем потоки, процессы и очереди рассматриваются как элементы инфра- структуры, а не как объекты, с которыми нужно работать напрямую. Конечно, этот пакет предназначен для сравнительно простых задач, которые принято называть естественно параллельными. Но это довольно большая часть всего множества проблем распараллеливания, с которыми приходится сталкивать- ся при разработке приложений – в противоположность операционным систе- мам или серверам баз данных, – о чем и говорит Симионато. 1 Слайд 9 из пособия «A Curious Course on Coroutines and Concurrency» (http://www. dabeaz.com/coroutines/), представленного на конференции PyCon 2009. Дополнительная литература  717\n--- Страница 717 ---\nДля задач, не являющихся «естественно параллельными», потоки и блокиров- ки – тоже не решение. На уровне ОС потоки никогда не исчезнут, но во всех языках программирования, которые мне кажутся интересными, за последние несколько лет появились более удобные высокоуровневые абстракции конку - рентности, как показывает книга Пола Бутчера «Seven Concurrency Models in Seven Weeks» (https://pragprog.com/titles/pb7con/seven-concurrency-models-in-seven- weeks/). К числу таких языков относятся Go, Elixir и Clojure. Erlang – язык, на котором написан Elixir, – блестящий пример языка, в который уже на этапе проектирования был заложен параллелизм. Мне, впрочем, он не нравится из- за уродливого синтаксиса. Это меня Python избаловал. Хосе Валим, хорошо известный как один из авторов ядра Ruby on Rails, спро- ектировал язык Elixir, наделив его приятным современным синтаксисом. По- добно Lisp и Clojure, в Elixir реализованы синтаксические макросы. Но это палка о двух концах. Синтаксические макросы позволяют строить мощные предметно-ориентированные языки (DSL), но чрезмерное изобилие подъ- языков может привести к несовместимым кодовым базам и фрагментации сообщества. Lisp утонул в макросах, каждый поставщик Lisp предлагает свой собственный сокровенный диалект. Результатом стандартизации на основе Common Lisp стал язык, разбухший от функциональных возможностей. На- деюсь, Хосе Валим не даст сообществу Elixir пойти по тому же пути. Пока все выглядит неплохо. Оберткой баз данных и генератором запросов Ecto (https:// hexdocs.pm/ecto/getting-started.html) пользоваться одно удовольствие: прекрас - ный пример использования макросов для создания гибкого, но при этом дру- жественного пользователю предметно-ориентированного языка (DSL) для взаимодействия с реляционными и нереляционными базами данных. Как и Elixir, Go – современный язык со свежими идеями. Но в некоторых от- ношениях он по сравнению с Elixir консервативен. В Go нет макросов, а его синтаксис проще, чем в Python. Go не поддерживает ни наследование, ни пе- регрузку операторов и предлагает меньше средств для метапрограммирова- ния, чем Python. Эти ограничения рассматриваются как достоинства. Они по- зволяют обеспечить более предсказуемые поведение и производительность. И это большой плюс в тех особо ответственных задачах с высоким уровнем параллелизма, где Go рассчитывает заменить C++, Java и Python. Хотя Elixir и Go – прямые конкуренты на поле конкурентности, их филосо- фия рассчитана на разную аудиторию. Скорее всего, обоим языкам уготована счастливая судьба. Но история учит, что более консервативные языки про- граммирования привлекают больше последователей.718  Конкурентные исполнители",
      "debug": {
        "start_page": 690,
        "end_page": 717
      }
    },
    {
      "name": "Глава 21. Асинхронное программирование 719",
      "content": "--- Страница 718 --- (продолжение)\nГлава 21 Асинхронное программирование Проблема всех обычных подходов к асинхронному программированию в том, что они предлагают все или ничего. Вам придется переписать весь код, чтобы нигде ничего не блокировалось, иначе вы просто зря потрати- те время. – Альваро Видела и Джейсон Дж. У. Уильямс, «RabbitMQ in Action»1 В этой главе рассматриваются три большие, тесно связанные между собой темы: конструкции Python async def, await, async with и async for ; объекты, поддерживающие эти конструкции: платформенные сопро- граммы и асинхронные варианты контекстных менеджеров, итерируе- мых объектов, генераторов и включений; asyncio и другие асинхронные библиотеки. Материал этой главы основан на идеях итерируемых объектов и генерато- ров (глава 17, в частности раздел «Классические сопрограммы»), контекстных менеджеров (глава 18) и общих концепциях конкурентного программирова- ния (глава 19). Мы будем изучать конкурентные HTTP-клиенты, подобные рассмотрен- ным в главе 20, но перепишем их с применением платформенных сопрограмм и асинхронных контекстных менеджеров. Для этой цели будем пользоваться той же библиотекой HTTPX, что и раньше, но на этот раз ее асинхронным API. Мы также увидим, как можно избежать блокирования цикла событий, делеги- руя медленные операции исполнителю в отдельном потоке или процессе. После примеров HTTP-клиентов мы рассмотрим два простых асинхронных серверных приложения, одно из которых основано на каркасе FastAPI, быстро набирающем популярность. Затем обратимся к другим языковым конструкци- ям, связанным с ключевыми словами async и await: асинхронным генераторным функциям, асинхронным включениям и асинхронным генераторным выра- жениям. Чтобы подчеркнуть, что эти языковые средства не привязаны к биб- лиотеке asyncio, мы перепишем один пример с использованием Curio – эле- гантного новаторского асинхронного каркаса, написанного Дэвидом Бизли. 1 Videla & Williams. RabbitMQ in Action (Manning); глава 4 «Solving Problems with Rabbit: coding and patterns. С. 61.\nГлава 21 Асинхронное программирование Проблема всех обычных подходов к асинхронному программированию в том, что они предлагают все или ничего. Вам придется переписать весь код, чтобы нигде ничего не блокировалось, иначе вы просто зря потрати- те время. – Альваро Видела и Джейсон Дж. У. Уильямс, «RabbitMQ in Action»1 В этой главе рассматриваются три большие, тесно связанные между собой темы: конструкции Python async def, await, async with и async for ; объекты, поддерживающие эти конструкции: платформенные сопро- граммы и асинхронные варианты контекстных менеджеров, итерируе- мых объектов, генераторов и включений; asyncio и другие асинхронные библиотеки. Материал этой главы основан на идеях итерируемых объектов и генерато- ров (глава 17, в частности раздел «Классические сопрограммы»), контекстных менеджеров (глава 18) и общих концепциях конкурентного программирова- ния (глава 19). Мы будем изучать конкурентные HTTP-клиенты, подобные рассмотрен- ным в главе 20, но перепишем их с применением платформенных сопрограмм и асинхронных контекстных менеджеров. Для этой цели будем пользоваться той же библиотекой HTTPX, что и раньше, но на этот раз ее асинхронным API. Мы также увидим, как можно избежать блокирования цикла событий, делеги- руя медленные операции исполнителю в отдельном потоке или процессе. После примеров HTTP-клиентов мы рассмотрим два простых асинхронных серверных приложения, одно из которых основано на каркасе FastAPI, быстро набирающем популярность. Затем обратимся к другим языковым конструкци- ям, связанным с ключевыми словами async и await: асинхронным генераторным функциям, асинхронным включениям и асинхронным генераторным выра- жениям. Чтобы подчеркнуть, что эти языковые средства не привязаны к биб- лиотеке asyncio, мы перепишем один пример с использованием Curio – эле- гантного новаторского асинхронного каркаса, написанного Дэвидом Бизли. 1 Videla & Williams. RabbitMQ in Action (Manning); глава 4 «Solving Problems with Rabbit: coding and patterns. С. 61.\n--- Страница 719 ---\nИ в завершение этой главы я написал короткий раздел о преимуществах и недостатках асинхронного программирования. Так что впереди у нас много работы. Место нашлось только для простых примеров, но они иллюстрируют самые важные аспекты каждой идеи. Документация по библиотеке asyncio (https://docs.python.org/3/ library/asyncio.html) стала гораздо лучше, после того ее реоргани- зовал Юрий Селиванов1, отделив немногие функции, полезные разработчикам приложений, от низкоуровневого API, предна- значенного для создателей пакетов, например веб-каркасов и драйверов баз данных. Если вас интересует целая книга, посвященная asyncio, рекомен- дую Caleb Hattingh «Using Asyncio in Python» (O’Reilly) (https:// www.oreilly.com/library/view/using-asyncio-in/9781492075325/). Заме- чание: Калеб – один из технических рецензентов этой книги. чтО нОвОг О в этОй главе Когда я работал над первым изданием этой книги, библиотека asyncio еще не устоялась, а ключевых слов async и await не было вовсе. Поэтому мне при- шлось обновить все примеры в данной главе. Я написал также новые примеры: скрипты проверки доменных имен, веб-службу на основе FastAPI и экспери- менты с новым асинхронным режимом консоли Python. В новых разделах рассматриваются языковые средства, которых в то время еще не было: платформенные сопрограммы, async with , async for и объекты, под- держивающие эти конструкции. Идеи, изложенные в разделе «Как работает асинхронный код и как он не ра- ботает», отражают выученные тяжким трудом уроки, которые, на мой взгляд, должен усвоить каждый, кто пользуется асинхронным программированием. Они могут избавить вас от кучи неприятностей – и не важно, пишете вы на Python или на Node.js. Наконец, я убрал несколько абзацев, посвященных классу asyncio.Futures , ко- торый теперь считается низкоуровневой частью API asyncio. неСкОлькО Определений В начале раздела «Классические сопрограммы» главы 17 мы видели, что начи- ная с версии Python 3.5 предлагается три вида сопрограмм: Платформенная сопрограмма Функция, определенная с помощью конструкции async def. Мы можем деле- гировать работу от одной платформенной сопрограммы другой, восполь- зовавшись ключевым словом await, по аналогии с тем, как классические со- программы уступают управление с помощью предложения yield from . Пред- ложение async def всегда определяет платформенную сопрограмму, даже 1 Селиванов реализовал async/await в Python и написал связанные с этим документы PEP 492, 525 и 530. 720  Асинхронное программирование\n--- Страница 720 ---\nесли в ее теле не встречается ключевое слово await. Слово await нельзя ис- пользовать вне платформенной сопрограммы1. Классическая сопрограмма Генераторная функция, которая потребляет данные, отправленные ей с помощью вызовов my_coro.send(data) , и читает эти данные, используя yield в выражении. Классическая сопрограмма может делегировать работу дру- гой классической сопрограмме с помощью предложения yield from . Класси- ческие сопрограммы не приводятся в действие словом await и более не под- держиваются библиотекой asyncio. Генераторные сопрограммы Генераторная функция, снабженная декоратором @types.coroutine , включен- ным в Python 3.5. Этот декоратор делает генератор совместимым с новым ключевым словом await. В этой главе нас будут интересовать платформенные сопрограммы и асин- хронные генераторы: Асинхронный генератор Генераторная функция, определенная с помощью конструкции async def и содержащая в теле yield. Она возвращает асинхронный объект-генератор, предоставляющий метод __anext__ для асинхронного получения следующе- го элемента. @asyncio.coroutine не имеет будущего2 Декоратор @asyncio.coroutine для классических и генераторных сопрограмм был объявлен нерекомендуемым в версии 3.8, а в версии Python 3.11 его планируется исключить из языка, как написано в сообщении 43216 (https://bugs.python.org/issue43216). Напротив, декоратор @types.coroutine должен остаться, если верить сообщению 36921 (https://bugs.python.org/issue36921). Он больше не поддерживается asyncio, но используется в низко- уровневом коде асинхронных каркасов Curio и Trio. Пример использования asyncio: проверка доменных имен Допустим, вы собираетесь начать новый блог, посвященный Python, и пла- нируете зарегистрировать домен, содержащий какое-нибудь ключевое слово Python и имеющий суффикс .DEV, например AWAIT.DEV. В примере 21.1 по- казан скрипт, в котором asyncio используется для конкурентной проверки не- скольких доменных имен. Вот его выход: $ python3 blogdom.py with.dev + elif.dev 1 Из этого правила есть одно исключение: если Python запущен с флагом -m asyncio , то await можно использовать прямо после приглашения >>> для вызова платформен- ной сопрограммы. Это объяснено в разделе «Эксперименты с асинхронной консолью Python». 2 Извините, не мог противиться искушению. Несколько определений  721\n--- Страница 721 ---\n+ def.dev from.dev else.dev or.dev if.dev del.dev + as.dev none.dev pass.dev true.dev + in.dev + for.dev + is.dev + and.dev + try.dev + not.dev Обратите внимание, что доменные имена не упорядочены. Запустив скрипт, вы увидите, что они отображаются один за другим с переменной задержкой. Знак + означает, что машина смогла разрешить доменное имя. В противном случае доменное имя не существует и, возможно, свободно1. В скрипте blogdom.py опрос DNS производится с помощью объектов плат - форменных сопрограмм. Поскольку асинхронные операции чередуются, вре- мя, необходимое для проверки всех 18 доменов, гораздо меньше, чем если бы они проверялись последовательно. На самом деле полное время практически совпадает со временем получения самого медленного ответа от DNS, а не рав- но сумме времен всех ответов. Пример 21.1. blogdom.py: поиск доменного имени для блога о Python #!/usr/bin/env python3 import asyncio import socket from keyword import kwlist MAX_KEYWORD_LEN = 4 ❶ async def probe(domain: str) -> tuple[str, bool]: ❷ loop = asyncio.get_running_loop() ❸ try: await loop.getaddrinfo(domain, None) ❹ except socket.gaierror: return (domain, False) return (domain, True) async def main() -> None: ❺ names = (kw for kw in kwlist if len(kw) <= MAX_KEYWORD_LEN) ❻ domains = (f'{name}.dev'.lower() for name in names) ❼ coros = [probe(domain) for domain in domains] ❽ for coro in asyncio.as_completed(coros): ❾ domain, found = await coro ❿ mark = '+' if found else ' ' print(f'{mark} {domain}') 1 Когда я это писал, домен true.dev предлагался за 360 долларов США в год. Я видел, что домен for.dev зарегистрирован, но DNS-запись не была сконфигурирована.722  Асинхронное программирование\n--- Страница 722 ---\nif __name__ == '__main__': asyncio .run(main()) ⓫ ❶ Задать максимальную длину ключевого слова в доменном имени, посколь- ку чем оно короче, тем лучше. ❷ Функция probe возвращает кортеж, содержащий доменное имя и булево значение; True означает, что имя успешно разрешено. Возврат доменного имени упрощает отображение результатов. ❸ Получить ссылку на цикл событий asyncio для будущего использования. ❹ Метод-сопрограмма loop.getaddrinfo(…) (https://docs.python.org/3/library/asyncio- eventloop.html#asyncio.loop.getaddrinfo) возвращает 5-кортеж параметров (https:// docs.python.org/3/library/socket.html#socket.getaddrinfo) для подключения к указан- ному адресу через сокет. В этом примере нам результат не нужен. Если мы получили кортеж, значит, имя разрешено, в противном случае – нет. ❺ main должна быть сопрограммой, чтобы в ней можно было использовать await. ❻ Генератор, отдающий ключевые слова Python длиной не более MAX_KEYWORD_LEN . ❼ Генератор, отдающий доменные имена с суффиксом .dev. ❽ Построить список объектов сопрограмм, вызывая сопрограмму probe с каж - дым аргументом domain. ❾ asyncio.as_completed – генератор, отдающий переданные ему сопрограммы в порядке их завершения, а не в порядке подачи. Он похож на функцию futures.as_completed , которую мы видели в примере 20.4. ❿ В этот момент мы знаем, что сопрограмма завершилась, потому что так работает as_completed . Поэтому выражение await не заблокирует выполнение, но оно все равно необходимо, чтобы получить результат от coro. Если coro возбуждала необработанное исключение, то оно будет заново возбуждено в этой точке. ⓫ asyncio.run запускает цикл событий и возвращает управление только после выхода из него. Это типичный паттерн для скриптов, в которых исполь- зуется asyncio: реализовать main как сопрограмму и выполнить ее внутри блока if __name__ == '__main__': . Функция asyncio.get_running_loop была добавлена в версии Python 3.7 для использования внутри сопрограмм, как показано в probe. Если работающего цикла нет, то она возбуждает исклю- чение RuntimeError . Ее реализация проще и быстрее, чем функ - ции asyncio.get_event_loop , которая может при необходимости запустить цикл событий. Начиная с версии Python 3.10 asyncio. get_event_loop объявлена нерекомендуемой (https://docs.python. org/3.10/library/asyncio-eventloop.html#asyncio. get_event_loop) и в ко- нечном итоге станет псевдонимом asyncio.get_running_loop . Предложенный Гвидо способ чтения асинхронного кода В asyncio много новых концепций, которые предстоит переварить, но за общей логикой примера 21.1 будет легко следить, если воспользоваться приемом, предложенным самим Гвидо ван Россумом: прищуриться и сделать вид, что ключевых слов async и await нет. Тогда вы поймете, что сопрограммы читаются, как старые добрые последовательные функции. Несколько определений  723\n--- Страница 723 ---\nНапример, представьте, что тело сопрограммы… async def probe(domain: str) -> tuple[str, bool]: loop = asyncio.get_running_loop() try: await loop.getaddrinfo(domain, None) except socket.gaierror: return (domain, False) return (domain, True) …работает, как следующая функция, с тем отличием, что волшебным образом никогда не блокирует выполнение программы: def probe(domain: str) -> tuple[str, bool]: # no async loop = asyncio.get_running_loop() try: loop.getaddrinfo(domain, None) # no await except socket.gaierror: return (domain, False) return (domain, True) Конструкция await loop.getaddrinfo( ) позволяет избежать блокирования, по- тому что await приостанавливает текущий объект сопрограммы. Например, во время выполнения сопрограммы probe('if.dev') создается новый объект сопро- граммы с помощью вызова getaddrinfo('if.dev', None) . Его ожидание запускает низкоуровневый запрос addrinfo и уступает управление циклу событий, а не при- остановленной сопрограмме probe('if.dev') . Затем цикл событий может передать управление другим ожидающим объектам сопрограмм, например probe('or.dev') . Когда цикл событий получит ответ на запрос getaddrinfo('if.dev', None) , этот объект сопрограммы возобновляется и возвращает управление probe('if.dev') , которая была приостановлена в await, а теперь может обработать возможное исключение и вернуть кортеж с результатами. До сих пор мы видели только, как asyncio.as_completed и await применяются к сопрограммам. Но они могут обработать любой допускающий ожидание объ- ект. Это понятие объясняется ниже. нОвая кОнцепция : ОБъекты , дОпуСкающие Ожидание Ключевое слово for работает с итерируемыми объектами. А ключевое слово await – с объектами, допускающими ожидание. Конечный пользователь asyncio постоянно сталкивается со следующими объектами, допускающими ожидание: объект платформенной сопрограммы, который мы получаем в результа- ты вызова функции платформенной сопрограммы; asyncio.Task , который мы обычно получаем, передав объект сопрограммы функции asyncio.create_task() . Однако пользовательский код не всегда должен ожидать Task с помощью await. Мы используем asyncio.create_task(one_coro()) , чтобы запланировать кон- курентное выполнение one_coro и не ждать, пока она вернется. Именно так мы поступили с сопрограммой spinner в скрипте spinner_async.py (пример 19.4). 724  Асинхронное программирование\n--- Страница 724 ---\nЕсли вы не собираетесь отменять задачу или ждать ее завершения, то и не нужно хранить объект Task, возвращенный функцией create_task . Достаточно просто создать задачу, чтобы запланировать выполнение сопрограммы. С другой стороны, мы используем await other_coro() , чтобы выполнить other_ coro немедленно и дождаться ее завершения, потому что для продолжения ра- боты нужен ее результат. В скрипте spinner_async.py в сопрограмме supervisor мы писали res = await slow() , чтобы выполнить slow и получить ее результат. При реализации асинхронных библиотек или дополнений самой библиоте- ки asyncio иногда приходится иметь дело со следующими низкоуровневыми объектами, допускающими ожидание: объект, имеющий метод __await__, который возвращает итератор; напри- мер, экземпляр asyncio.Future (asyncio.Task является подклассом asyncio. Future); объекты, написанные на других языках с применением Python/C API, имеющие функцию tp_as_async.am_await , возвращающую итератор (анало- гична методу __await__). В существующих кодовых базах может встречаться еще один вид объекта, допускающего ожидание: объекты генераторных сопрограмм. Но их скоро со- бираются объявить нерекомендуемыми. В документе PEP 492 утверждается (https://peps.python.org/pep- 0492/#await-expression), что выражение await «использует реали- зацию yield from с дополнительным шагом проверки аргумен- та» и что «await принимает только объект, допускающий ожида- ние». В PEP эта реализация не объясняется подробно, но дается отсылка к документу PEP 380 (https://peps.python.org/pep-0380), в котором впервые было описано предложение yield from . Я по - местил детальное объяснение в раздел «Семантика yield from» (https://www.fluentpython.com/extra/classic-coroutines/#yield_from_ meaning_sec) статьи «Классические сопрограммы» на сайте fluentpython.com. Теперь перейдем к изучению версии скрипта, загружающего изображения флагов, написанной с применением asyncio. загрузка файлОв С пОмОщью Asyncio и http X Скрипт flags_asyncio.py загружает фиксированный набор 20 флагов с сайта fluentpython.com. Впервые мы упоминали о нем в разделе «Конкурентная за- грузка из веба» главы 20, а теперь изучим более подробно, применив только что полученные знания. В версии Python 3.10 asyncio непосредственно поддерживает только про- токолы TCP и UDP, и в стандартной библиотеке нет пакетов с асинхронным HTTP-клиентом или сервером. Во всех примерах HTTP-клиентов я буду поль- зоваться библиотекой HTTPX (https://www.python-httpx.org/). Мы будем изучать скрипт flags_asyncio.py снизу вверх, т. е. сначала рассмот- рим функции, которые подготавливают действие (пример 21.2). Загрузка файлов с помощью asyncio и HTTPX  725\n--- Страница 725 ---\nЧтобы код было проще читать, в скрипте flags_asyncio.py нет обработки ошибок. Знакомясь с async/await , полезно сначала сосредоточить внимание на «успешном пути», чтобы понять, как организованы регулярные функции и сопрограммы. Начи- ная с раздела «Улучшение асинхронного загрузчика» примеры включают обработку ошибок и дополнительные возможности. Примеры скриптов flags_.py из этой главы и главы 20 разделяют общий код и данные, поэтому я поместил их в каталог example- code-2e/20-executors/getflags. Пример 21.2. flags_asyncio.py: функции подготовки def download_many(cc_list: list[str]) -> int:  return asyncio.run(supervisor(cc_list))  async def supervisor(cc_list: list[str]) -> int: async with AsyncClient() as client:  to_do = [download_one(client, cc) for cc in sorted(cc_list)]  res = await asyncio.gather(*to_do)  return len(res)  if __name__ == '__main__': main(download_many)  Это должна быть обычная функция, а не сопрограмма, чтобы ее можно было передать и вызвать из функции main, находящейся в модуле flags.py (пример 20.2).  Выполнять цикл событий, приводящий в действие объект сопрограммы supervisor(cc_list) , пока тот не вернет управление. Эта строка блокирует вы- полнение на все время работы цикла событий. Ее результатом является значение, возвращенное supervisor .  Асинхронные операции HTTP-клиента в httpx – это методы класса AsyncClient , который также является асинхронным контекстным менеджером, т. е. контекстным менеджером с асинхронными методами инициализации и очистки (подробнее об этом см. в разделе «Асинхронные контекстные менеджеры»).  Построить список объектов сопрограмм, вызвав сопрограмму download_one по разу для каждого флага.  Ждать завершения сопрограммы asyncio.gather , которая принимает один или несколько допускающих ожидание аргументов, ждет их завершения, а затем возвращает список результатов заданных объектов в том порядке, в каком они подавались на вход.  supervisor возвращает длину списка, возвращенного функцией asyncio.gather . Теперь рассмотрим начало файла flags_asyncio.py (пример 21.3). Я реоргани- зовал сопрограммы, так чтобы их можно было читать в том порядке, в каком они запускаются циклом событий. 726  Асинхронное программирование\n--- Страница 726 ---\nПример 21.3. flags_asyncio.py: импорт и функции загрузки import asyncio from httpx import AsyncClient  from flags import BASE_URL, save_flag, main  async def download_one(client: AsyncClient, cc: str):  image = await get_flag(client, cc) save_flag(image, f'{cc}.gif') print(cc, end=' ', flush=True) return cc async def get_flag(client: AsyncClient, cc: str) -> bytes:  url = f'{BASE_URL}/{cc}/{cc}.gif'.lower() resp = await client.get(url, timeout=6.1, follow_redirects=True)  return resp .read()   httpx нужно устанавливать – это не часть стандартной библиотеки.  Повторно использовать код из flags.py (пример 20.2).  download_one должна быть платформенной сопрограммой, чтобы она могла вызвать await для сопрограммы get_flag, которая выполняет HTTP-запрос. Затем она отображает загруженный флаг и сохраняет изображение.  get_flag должна получить AsyncClient , чтобы сделать запрос.  Метод get экземпляра httpx.AsyncClient возвращает объект ClientResponse , ко- торый заодно является асинхронным контекстным менеджером.  Операции сетевого ввода-вывода реализованы в виде методов-сопро- грамм, чтобы их можно было асинхронно вызывать из цикла событий asyncio. Для повышения производительности вызов save_flag из get_flag следовало бы сделать асинхронным, чтобы не блокировать цикл событий. Однако в настоящее время asyncio не предоставляет асинхронного API файловой системы – в отличие от Node.js. В разделе «Использование asyncio.as_completed в сочетании с потоком» ниже будет показано, как делегировать работу save_ flag потоку. Наш код делегирует работу сопрограммам httpx явно с помощью await или неявно с помощью специальных методов асинхронных контекстных менед- жеров, например AsyncClient и ClientResponse . Последнее мы увидим в разделе «Асинхронные контекстные менеджеры» ниже. Секрет платформенных сопрограмм: скромные генераторы Ключевое различие между примерами классических сопрограмм в разделе «Классические сопрограммы» главы 17 и скриптом flags_asyncio.py заключается в том, что во втором случае не видно никаких вызовов .send() или выражений yield. Наш код находится между библиотекой asyncio и асинхронными библио- теками, которыми мы пользуемся, например HTTPX. Это показано на рис. 21.1. Загрузка файлов с помощью asyncio и HTTPX  727\n--- Страница 727 ---\nАсинхронная библиотекаКод приложения цикл событий asyncio Рис. 21.1. В асинхронной программе пользователь ская функция запускает цикл событий, планируя начальную сопрограмму с помощью вызова asyncio.run . Каждая пользовательская сопрограмма отдает управление следующей с помощью выражения await , формируя канал, по которому взаимодействуют библиотека типа HTTPX и цикл событий Под капотом цикл событий asyncio обращается к .send, чтобы привести в дей- ствие ваши сопрограммы, а ваши сопрограммы с помощью await вызывают другие сопрограммы, в т. ч. библиотечные. Как уже было сказано, await заим- ствует большую часть реализации у предложения yield from , которое также об- ращается к .send для управления сопрограммами. Цепочка await в конце концов достигает низкоуровневого объекта, допуска- ющего ожидание, который возвращает генератор, к которому цикл событий может обращаться в ответ на такие события, как срабатывание таймера или се- тевой ввод-вывод. Низкоуровневые объекты, допускающие ожидание, и гене- раторы в конце таких цепочек await находятся глубоко внутри библиотек, они не являются частью их API и могут быть расширениями, написанными на C. Используя функции типа asyncio.gather и asyncio.create_task , мы можем создать несколько конкурентных каналов await, что позволяет конкурентно выполнять несколько операций ввода-вывода в одном цикле событий в одном потоке. Проблема «все или ничего» Обратите внимание, что в примере 21.3 я не мог повторно использовать функ - цию get_flag из файла flags.py (пример 20.2). Я вынужден был переписать ее в виде сопрограммы, чтобы воспользоваться асинхронным API HTTPX. Для до- стижения максимальной производительности при работе с asyncio мы должны заменить все функции, осуществляющие ввод-вывод, асинхронными версия- ми, которые активируются в результате выполнения await или asyncio.create_ task, для того чтобы управление возвращалось циклу событий, пока функция ждет завершения ввода-вывода. Если вы не можете переписать блокирующую функцию как сопрограмму, то ее следует запускать в отдельном потоке или процессе, как мы увидим в разделе «Делегирование задач исполнителям» ниже. Именно поэтому я и выбрал для этой главы эпиграф, включающий со-728  Асинхронное программирование\n--- Страница 728 ---\nвет: «Вам придется переписать весь код, чтобы нигде ничего не блокирова- лось, иначе вы просто зря потратите время». По той же причине я не мог повторно использовать функцию download_one из файла flags_threadpool.py (пример 20.3). Код в примере 21.3 активирует get_flag с помощью await, поэтому download_one тоже должна быть сопрограммой. Для каждого запроса в функции supervisor создается объект сопрограммы download_ one, и все они управляются сопрограммой asyncio.gather . Теперь изучим предложение async with , встречающееся в функциях supervisor (пример 21.2) и get_flag (пример 21.3). аСинхр Онные кОнтек Стные менеджеры В разделе «Контекстные менеджеры и блоки with» главы 18 мы видели, как можно использовать объект, чтобы выполнить некоторый код до и после блока with, если его класс предоставляет методы __enter__ и __exit__. Теперь рассмотрим пример 21.4, взятый из документации по asyncpg (https://magicstack.github.io/asyncpg/current/) – совместимого с asyncio драйвера PostgreSQL (https://magicstack.github.io/asyncpg/current/api/index.html#transactions). Пример 21.4. Пример из документации по драйверу PostgreSQL asyncpg tr = connection.transaction() await tr.start() try: await connection.execute(\"INSERT INTO mytable VALUES (1, 2, 3)\") except: await tr.rollback() raise else: await tr.commit() Транзакция базы данных естественно ложится на протокол контекстного менеджера: транзакцию нужно начать, изменить данные в connection.execute , а затем зафиксировать или откатить в зависимости от того, как прошли из- менения. В асинхронном драйвере типа asyncpg процедуры подготовки и завершения должны быть сопрограммами, чтобы остальные операции могли выполняться конкурентно. Однако реализация классического предложения with не поддер- живает выполнение методов __enter__ или __exit__ сопрограммами. Поэтому в документе PEP 492 «Coroutines with async and await syntax» (https:// peps.python.org/pep-0492/) было введено предложение async with , работающее с асинхронными контекстными менеджерами: объектами, реализующими ме- тоды __aenter__ и __aexit__ как сопрограммы. С помощью async with пример 21.4 можно переписать в следующем виде, тоже заимствованном из документации по asyncpg: async with connection.transaction(): await connection.execute(\"INSERT INTO mytable VALUES (1, 2, 3)\") В классе asyncpg.Transaction (https://github.com/MagicStack/asyncpg/blob/4d39a052 68ce4cc01b00458223a767542da048b8/asyncpg/transaction.py#L57) метод-сопрограм- Асинхронные контекстные менеджеры  729\n--- Страница 729 ---\nма __aenter__ выполняет await self.start() , а метод-сопрограмма __aexit__ ожидает завершения закрытых методов-сопрограмм __rollback или __commit в зависимо- сти от того, было исключение или нет. Использование сопрограмм для реали- зации класса Transaction как асинхронного контекстного менеджера позволяет asyncpg обрабатывать много транзакций конкурентно. Калеб Хэттинг об asyncpg У asyncpg есть еще одно важное достоинство – он позволяет обойти отсутствие в PostgreSQL поддержки высокой конкурент - ности (в этой СУБД используется один серверный процесс на каждое подключение), поскольку реализует пул подключений для внутреннего подключения к самой Postgres. Это означает, что не нужны дополнительные инструменты типа pgbouncer, о чем явно написано в документации по asyncpg ( https:// magicstack.github.io/asyncpg/ current/usage.html#connection-pools)1. Но вернемся к скрипту flags_asyncio.py. Класс AsyncClient из библиотеки httpx является асинхронным контекстным менеджером, поэтому может пользо- ваться объектами, допускающими ожидание, в своих специальных методах __aenter__ и __aexit__. В разделе «Асинхронные генераторы как контекстные менедже- ры» показано, как использовать библиотеку Python contextlib для создания асинхронного контекстного менеджера без написания класса. Это объяснение помещено ниже, потому что ему должен предшествовать раздел «Асинхронные генераторные функции». Теперь дополним код загрузки флагов с применением asyncio индикатором хода выполнения, что даст нам возможность поговорить про другие возмож - ности asyncio API. улучшение аСинхр ОннОг О загрузчика В разделе «Загрузка с индикацией хода выполнения и обработкой ошибок» главы 20 все flags2-примеры разделяли общий интерфейс командной стро- ки и отображали индикатор хода выполнения во время загрузки. Они также включали обработку ошибок. Я призываю вас поэкспериментировать с flags2-примерами, чтобы интуитивно почувствовать, как ведут себя конкурентные HTTP-клиенты. Флаг -h выводит экран справки, как в приме- ре 20.10. Используйте флаги -a, -e и -l для управления количест - вом загрузок, а флаг -m для задания количества конкурентных загрузок. Прогоните тесты, используя серверы LOCAL, REMOTE, DELAY и ERROR. Определите оптимальное число конкурентных загрузок, максимизирующее пропускную способность для каждого серве- ра. Протестируйте параметры тестовых серверов, как описано в примечании «Настройка тестовых серверов» в главе 20. 1 Этот совет – дословная цитата из комментария технического рецензента Калеба Хэт- тинга. Спасибо, Калеб! 730  Асинхронное программирование\n--- Страница 730 ---\nТак, в примере 21.5 показана попытка получить 100 флагов (-al 100) от сер- вера ERROR, используя 100 конкурентных запросов (-m 100). 48 ошибок в резуль- тате – либо ошибки HTTP 418, либо тайм-ауты – ожидаемое (неправильное) поведение slow_server.py. Пример 21.5. Прогон flags2_asyncio.py $ python3 flags2_asyncio.py -s ERROR -al 100 -m 100 ERROR site: http://localhost:8002/flags Searching for 100 flags: from AD to LK 100 concurrent connections will be used. 100%|█████████████████████████████████████████ | 100/100 [00:03<00:00, 30.48it/s] -------------------- 52 flags downloaded. 48 errors. Elapsed time: 3.31s Ведите себя ответственно при тестировании конкурентных клиентов Даже если общее время загрузки для многопоточного и асин- хронного HTTP-клиента различается не сильно, асинхронная версия может посылать запросы быстрее, поэтому больше веро- ятность, что сервер заподозрит DoS-атаку. Чтобы по-настоящему протестировать конкурентные клиенты «на полной тяге», ис- пользуйте локальные HTTP-серверы, как было описано в приме- чании «Настройка тестовых серверов» в главе 20. Теперь посмотрим, как реализован скрипт flags2_asyncio.py. Использование asyncio.as_completed и потока В примере 21.3 мы передавали несколько сопрограмм функции asyncio.gather , которая возвращает список результатов в том порядке, в каком подавались со- программы. Это означает, что asyncio.gather вернется только после того, как все допускающие ожидание объекты завершат работу. Однако чтобы обновлять индикатор хода выполнения, мы должны получать результаты сразу же. По счастью, в asyncio существует эквивалент генераторной функции as_ completed, которой мы пользовались в примере пула потоков с индикацией хода выполнения (пример 20.16). В примере 21.6 показано начало скрипта flags2_ asyncio.py, где определены функции get_flag и download_one . А в примере 21.7 пока- зана оставшаяся часть исходного кода – функции supervisor и download_many . Этот скрипт длиннее flags_asyncio.py из-за обработки ошибок. Пример 21.6. flags2_asyncio.py: начало скрипта; продолжение см. в примере 21.7 import asyncio from collections import Counter from http import HTTPStatus from pathlib import Path import httpx import tqdm # type: ignore Улучшение асинхронного загрузчика  731\n--- Страница 731 ---\nfrom flags2_common import main, DownloadStatus, save_flag # по умолчанию задана низкая степень конкурентности, чтобы избежать ошибок # удаленного сайта, например 503 - Service Temporarily Unavailable DEFAULT_CONCUR_REQ = 5 MAX_CONCUR_REQ = 1000 async def get_flag(client: httpx.AsyncClient,  base_url: str, cc: str) -> bytes: url = f'{base_url}/{cc}/{cc}.gif'.lower() resp = await client.get(url, timeout=3.1, follow_redirects=True)  resp.raise_for_status() return resp.content async def download_one(client: httpx.AsyncClient, cc: str, base_url: str, semaphore: asyncio.Semaphore, verbose: bool) -> DownloadStatus: try: async with semaphore:  image = await get_flag(client, base_url, cc) except httpx.HTTPStatusError as exc:  res = exc.response if res.status_code == HTTPStatus.NOT_FOUND: status = DownloadStatus.NOT_FOUND msg = f'not found: {res.url}' else: raise else: await asyncio.to_thread(save_flag, image, f'{cc}.gif')  status = DownloadStatus.OK msg = 'OK' if verbose and msg: print(cc, msg) return status  Функция get_flag очень похожа на последовательную версию из приме- ра 20.14. Первое отличие: она требует параметра client.  Второе и третье отличия: .get – метод AsyncClient и является сопрограммой, поэтому для его выполнения нужно ключевое слово await.  Использовать semaphore как асинхронный контекстный менеджер, чтобы не блокировать программу целиком; только эта сопрограмма приостанав- ливается, когда счетчик семафора обращается в нуль. Подробнее см. во врезке «Семафоры в Python» ниже.  Логика обработки ошибок такая же, как в функции download_one из приме- ра 20.14.  Сохранение изображения – операция ввода-вывода. Чтобы избежать блоки- рования цикла событий, функция save_flag выполняется в отдельном потоке. Весь сетевой ввод-вывод в asyncio производится с помощью сопрограмм, но к файловому вводу-выводу это не относится. Однако файловый ввод- вывод – тоже блокирующая операция в том смысле, что чтение и запись файлов 732  Асинхронное программирование\n--- Страница 732 ---\nзанимают в тысячи раз больше времени (https://gist.github.com/jboner/2841832), чем чтение-запись в память. А если используется сетевая система хранения (https://en.wikipedia.org/wiki/Network-attached_storage), то за кулисами может еще и выполняться сетевой ввод-вывод. Начиная с Python 3.9 сопрограмма asyncio.to_thread упрощает делегирова- ние файлового ввода-вывода пулу потоков, предоставляемому библиотекой asyncio. На случай, если нужно поддерживать Python 3.7 или 3.8, в разделе «Де- легирование задач исполнителям» показано, как это сделать, добавив всего две строки. Но сначала закончим изучение кода HTTP-клиента. Регулирование темпа запросов с помощью семафора Сетевые клиенты типа рассматриваемого здесь следует дросселировать (т. е. ограничивать), чтобы избежать затопления сервера слишком большим коли- чеством конкурентных запросов. Семафор ( https://en.wikipedia.org/wiki/Semaphore_(programming)) – это примитив синхронизации, более гибкий, чем блокировка. Семафор могут удерживать не- сколько сопрограмм, причем максимальное их число настраивается. Поэтому это идеальный механизм для ограничения количества активных конкурентных сопрограмм. Дополнительные сведения см. во врезке «Семафоры в Python». В скрипте flags2_threadpool.py (пример 20.16) эффект дросселирования до- стигался путем создания в функции download_many объекта ThreadPoolExecutor , в ко - тором обязательный аргумент max_workers задавался равным concur_req . В скрипте flags2_asyncio.py функция supervisor (см. пример 21.7) создает экземпляр asyncio. Semaphore и передает его в аргументе semaphore функции download_one (пример 21.6). Семафоры в Python Эдсгер Дейкстра изобрел семафор в начале 1960-х годов. Идея простая, но на- столько гибкая, что большинство других объектов синхронизации, например блокировки и барьеры, можно построить на основе семафоров. В стандартной библиотеке Python есть три класса Semaphore: по одному в модулях threading, multiprocessing и asyncio. Здесь мы рассмотрим последний. В классе asyncio.Semaphore имеется внутренний счетчик, который уменьшается на 1 всякий раз, как выполняется await для метода-сопрограммы .acquire() , и увеличивается на 1 при вызове метода .release() , который не является со- программой, потому что никогда не блокирует выполнение. Начальное зна- чение счетчика задается при создании объекта Semaphore: semaphore = asyncio.Semaphore(concur_req) Ожидание .acquire() не приводит к задержке, когда счетчик больше 0, но если счетчик равен 0, то .acquire() приостанавливает ожидающую сопрограмму до тех пор, пока какая-нибудь другая сопрограмма не вызовет .release() для того же семафора, увеличив тем самым счетчик. Вместо того чтобы обращаться к этим методам напрямую, безопаснее использовать semaphore как асинхронный кон- текстный менеджер, как я поступил в функции download_one из примера 21.6: async with semaphore: image = await get_flag(client, base_url, cc) Улучшение асинхронного загрузчика  733\n--- Страница 733 ---\nМетод-сопрограмма Semaphore.__aenter__ ждет завершения .acquire() , а метод- сопрограмма __aexit__ вызывает .release() . Этот код гарантирует, что в любой момент времени будет активно не более concur_req экземпляров сопрограммы get_flags. У каждого из классов Semaphore в стандартной библиотеке имеется подкласс BoundedSemaphore , налагающий дополнительное ограничение: внутренний счет - чик не может стать больше начального значения, если операций .release() окажется больше, чем .acquire()1. А теперь взглянем на оставшуюся часть скрипта. Пример 21.7. flags2_asyncio.py: продолжение скрипта из примера 21.6 async def supervisor(cc_list: list[str], base_url: str , verbose: bool, concur_req: int) -> Counter[DownloadStatus]: ❶ counter: Counter[DownloadStatus] = Counter() semaphore = asyncio.Semaphore(concur_req) ❷ async with httpx.AsyncClient() as client: to_do = [download_one(client, cc, base_url, semaphore, verbose) for cc in sorted(cc_list)] ❸ to_do_iter = asyncio.as_completed(to_do) ❹ if not verbose: to_do_iter = tqdm.tqdm(to_do_iter, total=len(cc_list)) ❺ error: httpx.HTTPError | None = None ❻ for coro in to_do_iter: ❼ try: status = await coro ❽ except httpx.HTTPStatusError as exc: error_msg = 'HTTP error {resp.status_code} - {resp.reason_phrase}' error_msg = error_msg.format(resp=exc.response) error = exc ❾ except httpx.RequestError as exc: error_msg = f'{exc} {type(exc)}'.strip() error = exc ❿ except KeyboardInterrupt: break if error: status = DownloadStatus.ERROR ⓫ if verbose: url = str(error.request.url) ⓬ cc = Path(url).stem.upper() ⓭ print(f'{cc} error: {error_msg}') counter[status] += 1 return counter def download_many(cc_list: list[str], base_url: str, verbose: bool, concur_req: int) -> Counter[DownloadStatus]: 1 Спасибо Гуто Майя, который обратил внимание, что в первом варианте этой главы понятие семафора не объяснялось.734  Асинхронное программирование\n--- Страница 734 ---\ncoro = supervisor(cc_list, base_url, verbose, concur_req) counts = asyncio.run(coro) ⓮ return counts if __name__ == '__main__': main(download_many, DEFAULT_CONCUR_REQ, MAX_CONCUR_REQ) ❶ supervisor принимает те же аргументы, что функция download_many , но ее нель- зя вызывать из main напрямую, потому что это сопрограмма, а не обычная функция. ❷ Создать семафор asyncio.Semaphore , которым смогут одновременно пользо- ваться не более concur_req сопрограмм. Значение concur_req вычисляется функцией main из модуля flags2_common.py на основе параметров команд- ной строки и констант в каждом примере. ❸ Создать список объектов сопрограмм, по одному на каждый вызов сопро- граммы download_one . ❹ Получить итератор, который будет возвращать объекты сопрограмм по мере их завершения. Я не стал помещать это обращение к as_completed в цикл for ниже, потому что, возможно, понадобится обернуть его итератором tqdm для индикатора хода выполнения – в зависимости от режима, заданного пользователем в командной строке. ❺ Обернуть итератор as_completed генераторной функцией tqdm, чтобы пока- зать индикатор хода выполнения. ❻ Объявить переменную error и инициализировать ее значением None; в этой переменной мы будем хранить исключение за пределами предложения try/except , если таковое возникнет. ❼ Обойти завершившиеся объекты сопрограмм; этот цикл похож на тот, что использовался в функции download_many из примера 20.16. ❽ Ждать завершения сопрограммы для получения результата. Это предложе- ние не приводит к блокированию, потому что as_completed порождает только уже завершившиеся сопрограммы. ❾ Это присваивание необходимо, поскольку область видимости переменной exc ограничена этой ветвью except, а мне нужно сохранить ее значение для будущего использования. ❿ То же, что и выше. ⓫ Если была ошибка, установить переменную status. ⓬ В режиме подробной диагностики извлечь URL-адрес из возникшего ис- ключения… ⓭ …и имя файла, чтобы показать код страны. ⓮ download_many создает объект сопрограммы supervisor и передает его циклу со- бытий, вызвав asyncio.run , а затем получает счетчик, который supervisor воз- вращает по завершении цикла событий. В примере 21.7 мы не могли использовать отображение будущих объектов на коды стран, которое встречали в примере 20.16, потому что допускающие ожидание объекты, возвращенные asyncio.as_completed , – это те же объекты, кото- рые мы передали при вызове as_completed . Внутренние алгоритмы asyncio могут Улучшение асинхронного загрузчика  735\n--- Страница 735 ---\nзаменить предоставленные нами объекты другими, но результаты они будут возвращать точно такие же1. Поскольку я не мог использовать объекты, допускающие ожида- ние, для извлечения кода страны из словаря в случае ошибки, я вынужден был извлекать этот код из исключения. Для этого я сохранил исключение в переменной error, к которой можно получить доступ извне предложения try/except . Python не явля- ется языком с блочной областью видимости: такие предложе- ния, как циклы и try/except , не создают локальной области ви- димости в блоках, которыми управляют. Но если в ветви except исключение связывается с переменной, как случае переменных exc в этом примере, то связь существует только внутри блока, ограниченного этой конкретной ветвью except. На этом мы завершаем обсуждение примера asyncio, функционально экви- валентного ранее рассмотренному скрипту flags2_threadpool.py. В следующем примере демонстрируется простой паттерн выполнения од- ной асинхронной задачи вслед за другой с помощью сопрограмм. Это заслу - живает внимания, потому что всякий имеющий опыт работы с JavaScript знает, что выполнение одной асинхронной функции после другой – основная причи- на паттерна вложенного кода, известного под названием «пирамида судьбы». Ключевое слово await снимает это проклятие. Поэтому await и вошло в состав Python и JavaScript. Отправка нескольких запросов при каждой загрузке Предположим, что мы хотим сохранить вместе с флагом каждой страны ее название и код, а не только код. Тогда нужно отправить два HTTP-запроса на каждый флаг: один для получения самого изображения флага, а другой для по- лучения файла metadata.json, находящегося в том же каталоге, что изображе- ние, – именно там хранится название страны. В многопоточном скрипте координировать несколько запросов в одной за- даче просто: нужно лишь отправлять запросы один за другим, дважды блоки- руя поток, и сохранять оба элемента данных (код и название страны) в локаль- ных переменных, которые понадобятся при сохранении файлов. Если мы захо- тим сделать то же самое в асинхронном скрипте с помощью обратных вызовов, то понадобятся вложенные функции, так чтобы код и название страны были доступны в их замыканиях до момента сохранения файла, – ведь каждый об- ратный вызов работает в своей локальной области видимости. Ключевое слово await освобождает от этой повинности, поскольку дает возможность запускать асинхронные запросы один за другим в общей локальной области видимости активирующей сопрограммы. 1 Подробное обсуждение этого момента можно найти в ветке, которую я создал в группе python-tulip. Она называется «Which other futures may come out of asyncio. as_completed?» (https://asgi.readthedocs.io/en/latest/implementations.html). Ответ Гвидо проливает свет на реализацию as_completed , а также на тесную связь между будущими объектами и сопрограммами в asyncio. 736  Асинхронное программирование\n--- Страница 736 ---\nЕсли при программировании асинхронного приложения вы злоупотребляете обратными вызовами, то, скорее всего, сле- дуете старым паттернам, которые в современном Python не имеют смысла. Это оправдано, если вы пишете библиоте- ку, которая имеет интерфейсы к унаследованному или низко- уровневому коду, не поддерживающему сопрограммы. Как бы то ни было, в ответе на вопрос «What is the use case for future. add_done_callback()?» (https://stackoverflow.com/questions/53701841 / what-is-the-use-case-for-future-add-done-callback/53710563) на сайте StackOverflow объясняется, почему обратные вызовы необходи- мы в низкоуровневом коде, но не очень полезны в коде совре- менного приложения на Python. В третьем варианте скрипта загрузки флагов с помощью asyncio внесено не- сколько изменений: get_country Эта новая сопрограмма скачивает файл metadata.json, соответствующий коду страны, и читает из него название страны. download_one Эта сопрограмма использует await, чтобы делегировать работу get_flag и но- вой сопрограмме get_country и, пользуясь результатом последней, построить имя сохраняемого файла. Начнем с кода get_country (пример 21.8). Обратите внимание, что он очень похож на код get_flag из примера 21.6. Пример 21.8. flags3_asyncio.py: сопрограмма get_country async def get_country(client: httpx.AsyncClient, base_url: str, cc: str) -> str:  url = f'{base_url}/{cc}/metadata.json'.lower() resp = await client.get(url, timeout=3.1, follow_redirects=True) resp.raise_for_status() metadata = resp.json()  return metadata['country']   Эта сопрограмма возвращает строку, содержащую название страны, – если все пройдет хорошо.  В metadata будет находиться словарь Python, построенный по содержимому ответа в формате JSON.  Вернуть название страны. Теперь рассмотрим модифицированную сопрограмму download_one в приме- ре 21.9; по сравнению с сопрограммой из примера 21.6 в ней изменилось всего несколько строк. Улучшение асинхронного загрузчика  737\n--- Страница 737 ---\nПример 21.9. flags3_asyncio.py: сопрограмма download_one async def download_one(client: httpx.AsyncClient, cc: str, base_url: str, semaphore: asyncio.Semaphore, verbose: bool) -> DownloadStatus: try: async with semaphore:  image = await get_flag(client, base_url, cc) async with semaphore:  country = await get_country(client, base_url, cc) except httpx.HTTPStatusError as exc: res = exc.response if res.status_code == HTTPStatus.NOT_FOUND: status = DownloadStatus.NOT_FOUND msg = f'not found: {res.url}' else: raise else: filename = country.replace(' ', '_')  await asyncio.to_thread(save_flag, image, f'{filename}.gif') status = DownloadStatus.OK msg = 'OK' if verbose and msg: print(cc, msg) return status  Удерживать семафор, чтобы дождаться результата get_flag …  … и еще раз для ожидания get_country .  Использовать название страны для создания имени файла. Работая в основ- ном в режиме командной строки, я не люблю пробелов в именах файлов. Гораздо лучше обратных вызовов! Я поместил вызовы get_flag и get_country в разные блоки with, контролируемые семафором, потому что рекомендуется удерживать семафоры и блокировки в течение как можно более короткого времени. Я мог бы запланировать параллельное выполнение get_flag и get_country , вос- пользовавшись asyncio.gather , но если get_flag возбудит исключение, то нечего будет сохранять, поэтому вызывать get_country бессмысленно. Однако бывают ситуации, когда имеет смысл с помощью asyncio.gather обратиться к несколь- ким API одновременно, а не ждать получения одного ответа, прежде чем от- править следующий запрос. В скрипте flags3_asyncio.py ключевое слово await встречается шесть раз, а async with – три раза. Надеюсь, вы уяснили суть асинхронного программирования в Python. Но нужно понимать, когда необходимо использовать await, а когда без этого можно обойтись. В принципе, ответ прост: с помощью await нужно ждать завершения сопрограмм и других объектов, допускающих ожидание, напри- мер экземпляров класса asyncio.Task . Но некоторые API запутаны, в них сопро- граммы и обычные функции сочетаются, на первый взгляд, произвольными способами. Так, например, устроен класс StreamWriter , которым мы воспользу - емся в примере 21.14.738  Асинхронное программирование\n--- Страница 738 ---\nПример 21.9 – последний из серии скриптов flags. Теперь обсудим использо- вание процессов и потоков в асинхронном программировании. делегир Ование задач иСпО лнителям Важное преимущество Node.js перед Python в плане асинхронного програм- мирования – стандартная библиотека, которая предлагает асинхронные API для всех видов ввода-вывода, а не только для сетевого. В Python беспечность может серьезно подорвать производительность асинхронных приложений, потому что чтение и запись в систему хранения в главном потоке блокируют цикл событий. В сопрограмме download_one из примера 21.6 я написал такую строку для со- хранения загруженного изображения на диск: await asyncio.to_thread(save_flag, image, f'{cc}.gif') Как уже было сказано, сопрограмма asyncio.to_thread была добавлена в Python 3.9. Если необходимо поддержать версии 3.7 или 3.8, то эту строку можно заменить строками, показанными в примере 21.10. Пример 21.10. Строки, заменяющие await asyncio.to_thread loop = asyncio.get_running_loop()  loop.run_in_executor(None, save_flag,  image, f'{cc}.gif')   Получить ссылку на цикл событий.  Первый аргумент – исполнитель; если передать None, то будет выбран эк- земпляр ThreadPoolExecutor по умолчанию, который всегда доступен в цикле событий asyncio.  Можно передать подлежащей выполнению функции позиционные аргумен- ты, но если требуется передать именованные, то придется прибегнуть к функ - ции functool.partial , как описано в документации по run_in_executor (https://docs. python.org/3/library/asyncio-eventloop.html#asyncio.loop.run_in_ executor). Более современная функция asyncio.to_thread проще и гибче, поскольку при- нимает именованные аргументы тоже. В реализации самого пакета asyncio сопрограмма run_in_executor использует - ся в нескольких местах. Например, сопрограмма loop.getaddrinfo(…) , которую мы видели в примере 21.1, реализована путем вызова функции getaddrinfo из мо- дуля socket, но это блокирующая функция, которая может работать несколько секунд, поскольку зависит от DNS-сервера. В асинхронных API часто встречается следующий паттерн: обернуть блоки- рующий вызов, являющийся деталью реализации, сопрограммой, в которой используется run_in_executor . Тем самым мы предоставляем единообразный ин- терфейс сопрограмм, которым можно управлять с помощью await, и скрываем потоки, заведенные по чисто прагматическим причинам. API асинхронного драйвера Motor (https://motor.readthedocs.io/en/stable/) для MongoDB, совмес- тимый с async/await , на самом деле является фасадом вокруг многопоточного ядра, которое общается с сервером базы данных. А. Джесси Жирью Дэвис, ве- Делегирование задач исполнителям  739\n--- Страница 739 ---\nдущий разработчик Motor, объяснил ход своих рассуждений в статье «Response to ‘Asynchronous Python and Databases’» (https://emptysqua.re/blog/response-to- asynchronous-python-and-databases/). Спойлер: Дэвис обнаружил, что пул потоков в конкретном случае драйвера базы данных работает быстрее – вопреки мифу, будто асинхронные подходы всегда быстрее потоков при выполнении сетевого ввода-вывода. Главная причина явной передачи Executor функции loop.run_in_executor – ис- пользовать ProcessPoolExecutor , если исполняемая функция счетная; тогда она смо- жет работать в другом процессе Python, избежав состязания за GIL. Из-за высо- ких накладных расходов на инициализацию лучше запустить ProcessPoolExecutor в supervisor и передавать его сопрограммам, которым он нужен. Калеб Хэттинг, автор книги «Using Asyncio in Python» (O’Reilly) (https://www. oreilly.com/library/view/using-asyncio-in/9781492075325/) и один из технических ре- цензентов этой книги, предложил включить следующее предупреждение, ка- сающееся исполнителей и asyncio. Предупреждение Калеба о run_in_executors Использование run_in_executor может приводить к трудным для отладки проблемам, потому что отмена не всегда работа- ет, как ожидается. Сопрограммы, в которых используются ис- полнители, только делают вид, что отменились: для стоящего за ними потока (если это ThreadPoolExecutor ) нет никакого ме- ханизма отмены. Например, долго работающий поток, создан- ный внутри run_in_executor , может помешать вашей асинхрон- ной программе чисто завершиться: asyncio.run будет ждать, пока исполнитель завершится, перед тем как вернуться, и это будет продолжаться вечно, если задания, выполняемые испол- нителем, не завершаются по собственной инициативе. Я по- стариковски хотел бы, чтобы эта функция называлась run_in_ executor_uncancellable . Перейдем теперь от клиентских скриптов к написанию серверов с примене- нием asyncio. напиС ание аСинхр Онных Сервер Ов Классический модельный пример TCP-сервера – эхо-сервер (https://docs. python.org/3/library/asyncio-stream.html#tcp-echo-server-using-streams). Мы создадим игрушки поинтереснее: серверные утилиты поиска символов Unicode, сначала на базе HTTP и FastAPI, а затем ограничившись чистым TCP с asyncio. Эти серверы позволят пользователям запрашивать символы Unicode, со- держащие указанные слова в стандартном имени из модуля unicodedata , ко- торый мы обсуждали в разделе «База данных Unicode Database» главы 4. На рис. 21.2 показан сеанс работы со скриптом web_mojifinder.py, первым на- шим сервером. 740  Асинхронное программирование\n--- Страница 740 ---\nРис. 21.2. Окно браузера, в котором отображаются результаты поиска по слову «mountain», полученные от службы web_mojifinder.py Логика поиска символов Unicode в этих примерах инкапсулирована в клас - се InvertedIndex , находящемся в модуле charindex.py в репозитории кода на со- проводительном сайте (https://github.com/fluentpython/example-code-2e). Никакой конкурентности в этом небольшом модуле нет, поэтому я лишь коротко опишу его во врезке ниже. Можете перейти сразу к реализации HTTP-сервера в раз- деле «Веб-служба FastAPI Web Service». Познакомьтесь с инвертированным индексом Инвертированный индекс обычно отображает слова на документы, в кото- рых они встречаются. В следующих ниже примерах mojifinder каждый «до- кумент» – это один символ Unicode. Класс charindex.InvertedIndex индексирует все слова, встречающиеся в именах символов в базе данных Unicode, и соз- дает инвертированный индекс, хранящийся в словаре defaultdict . Например, чтобы проиндексировать символ U+0037 – DIGIT SEVEN, – инициализатор InvertedIndex добавляет символ '7' в записи с ключами 'DIGIT' и 'SEVEN'. После индексирования данных Unicode 13.0.0, включенных в состав дистрибутива Python 3.9.1, слово 'DIGIT' отображается на 868 символов, а слово 'SEVEN' – на 143 символа, включая U+1F556 (CLOCK FACE SEVEN OCLOCK) и U+2790 (DINGBAT NEGATIVE CIRCLED SANS-SERIF DIGIT SEVEN) (он встречается во многих листингах в этой книге). На рис. 21.3 показаны результаты поиска по словам 'CAT' и 'FACE'1. 1 Вопросительный знак в квадратике на этом снимке экрана – не дефект печатной или электронной книги. Это символ U+101EC – PHAISTOS DISC SIGN CAT, которого нет в моем терминальном шрифте. Фестский диск – древний артефакт, вырезанный в пиктограммах, найденных на острове Крит. Написание асинхронных серверов  741\n--- Страница 741 ---\nРис. 21.3. Изучение атрибута entries и метода search класса InvertedIndex на консоли Python Метод InvertedIndex.search разбивает запрос на слова и возвращает пересече- ние найденных для каждого слова множеств символов. Поэтому запрос «face» находит 171 результат, запрос «cat» – 14 результатов, но запрос «cat face» – только 10 результатов. Красивая идея инвертированного индекса лежит в основе информационно- го поиска – теории, стоящей за поисковыми системами. См. статью «Inverted Index» (https://en.wikipedia.org/wiki/Inverted_index) в англоязычной Википедии. Веб-служба FastAPI Следующий пример – web_mojifinder.py – я написал с использованием FastAPI (https://fastapi.tiangolo.com/): одного из написанных на Python веб-каркасов ASGI, упомянутых во врезке «ASGI – шлюзовой интерфейс асинхронных сер- веров» в главе 19. На рис. 21.2 показан внешний вид интерфейса. Это очень простое одностраничное приложение (Single Page Application – SPA): после начальной загрузки HTML пользовательский интерфейс обновляется клиент - ским JavaScript-скриптом, взаимодействующим с сервером. FastAPI предназначена для реализации серверных частей SPA и мобиль- ных приложений, которые состоят по большей части из оконечных точек API, возвращающих ответ в формате JSON, а не в виде сгенерированного серве- ром HTML-кода. В FastAPI вовсю используются декораторы, аннотации типов и инт роспекция кода, чтобы устранить трафаретный код из серверных API. Кроме того, автоматически публикуется схема OpenAPI (или Swagger – (https:// swagger.io/specification/)) – интерактивная документация по созданным нами API. На рис. 21.4 показана автоматически сгенерированная страница /docs для скрипта web_mojifinder.py.742  Асинхронное программирование\n--- Страница 742 ---\nРис. 21.4. Автоматически сгенерированная схема OpenAPI для оконечной точки /search В примере 21.11 приведен код web_mojifinder.py, но это только серверный код. При запросе к корневому URL / сервер отправляет файл form.html, содер- жащий 81 строку кода, включая 54 строки на JavaScript для взаимодействия с сервером и заполнения таблицы. Если вам интересно познакомиться с прос- тым JavaScript-кодом, не зависящим ни от какого каркаса, загляните в файл 21-async/mojifinder/static/form.html в репозитории кода по адресу https://github. com/fluentpython/example-code-2e. Чтобы выполнить скрипт web_mojifinder.py, необходимо установить два па- кета и их зависимости: FastAPI и uvicorn1. Следующая команда запускает код из примера 21.11 с uvicorn в режим разработки: $ uvicorn web_mojifinder:app --reload Опишем параметры: web_mojifinder:app Имя пакета, двоеточие и имя определенного в нем ASGI-приложения; по соглашению, приложение часто называется app. --reload Поручить uvicorn отслеживать изменения в исходных файлах приложения и автоматически перезагружать их. Полезно только на этапе разработки. Теперь рассмотрим исходный код web_mojifinder.py. 1 Вместо uvicorn можно взять другой сервер ASGI, например hypercorn или Daphne. До- полнительные сведения о реализациях см. в официальной документации по ASGI (https://asgi.readthedocs.io/en/latest/ implementations.html). Написание асинхронных серверов  743\n--- Страница 743 ---\nПример 21.11. web_mojifinder.py: полный исходный код from pathlib import Path from unicodedata import name from fastapi import FastAPI from fastapi.responses import HTMLResponse from pydantic import BaseModel from charindex import InvertedIndex STATIC_PATH = Path(__file__).parent.absolute() / 'static'  app = FastAPI(  title='Mojifinder Web', description='Search for Unicode characters by name.', ) class CharName(BaseModel):  char: str name: str def init(app):  app.state.index = InvertedIndex() app.state.form = (STATIC_PATH / 'form.html').read_text() init(app)  @app.get('/search', response_model=list[CharName])  async def search(q: str):  chars = sorted(app.state.index.search(q))  return ({'char': c, 'name': name(c)} for c in chars) @app.get('/', response_class=HTMLResponse, include_in_schema=False) def form():  return app.state.form  # функции main нет  Не относится к теме этой главы, но полезно отметить: элегантное исполь- зование перегруженного оператора / в модуле pathlib1.  В этой строке определяется ASGI-приложение. Достаточно было бы напи- сать просто app = FastAPI() . Показанные параметры – это метаданные для автоматического генерирования документации.  Пидантическая схема JSON-ответа с полями char и name2.  Построить индекс и загрузить статическую HTML-форму, присоединив то и другое к app.state для последующего использования.  Выполнить init в момент загрузки этого модуля ASGI-сервером.  Маршрут к оконечной точке /search ; response_model использует пидантиче- скую модель CharName для описания формата ответа. 1 Спасибо техническому рецензенту Мирославу Седивы, который подсказал, где в при- мерах кода стоит использовать pathlib. 2 Как было сказано в главе 8, пидантичность (https://pydantic-docs.helpmanual.io/) требует проверки аннотаций типов во время выполнения с целью контроля данных.744  Асинхронное программирование\n--- Страница 744 ---\n FastAPI предполагает, что параметры, встречающиеся в сигнатуре функции или сопрограммы, но не присутствующие в пути маршрута, передаются в строке HTTP-запроса, например /search?q=cat . Поскольку для q не задано значение по умолчанию, FastAPI вернет код состояния 422 (Unprocessable Entity), если q отсутствует в строке запроса.  Возврат итерируемого объекта, состоящего из словарей и совместимого со схемой response_model , позволяет FastAPI построить JSON-ответ в соответ - ствии со схемой response_model , заданной в декораторе @app.get.  Обычные (не асинхронные) функции тоже можно использовать для гене- рирования ответов.  В этом модуле нет функции main. Он загружается и выполняется ASGI- сервером – в данном случае uvicorn. В примере 21.11 нет прямых обращений к asyncio. FastAPI построен на базе ASGI-инструментария Starlette, который, в свою очередь, использует asyncio. Отметим также, что в теле search не используются await, async with и async for, так что это могла бы быть обычная функция. Я определил search как сопрограм- му, просто чтобы показать, что FastAPI знает, как с ней поступать. В реальном приложении большинство оконечных точек обращаются к базам данных или к другим удаленным серверам, так что для FastAPI – и других ASGI-каркасов – критически важна поддержка сопрограмм, которые могут воспользоваться асинхронными библиотеками для сетевого ввода-вывода. Функции init и form, написанные мной для загрузки и отдачи статической HTML-формы, нужны только, чтобы сделать пример коротким и простым для выполнения. На практике рекоменду - ется помещать перед ASGI-сервером прокси-сервер с возмож - ностью балансировки нагрузки, который будет обрабатывать все статические файлы, а также по возможности использовать CDN (сеть доставки контента). Одним из таких прокси-серверов яв- ляется Traefik ( https://doc.traefik.io/traefik/), описываемый как «гра- ничный маршрутизатор», который «получает запросы от имени вашей системы и определяет, какие компоненты отвечают за их обработку». В состав FastAPI входят скрипты генерирования проекта (https://fastapi.tiangolo.com/project-generation/), подготавли- вающие ваш код к работе в таком режиме. Энтузиаст типизации, возможно, обратил внимание, что в search и form нет аннотаций типа возвращаемого значения. Вместо этого FastAPI полагается на именованный аргумент response_model= в маршрутных декораторах. На странице «Модель ответа» (https://fastapi.tiangolo.com/tutorial/response-model/) в документа- ции по FastAPI приводится такое объяснение: Модель ответа объявляется в этом параметре, а не в аннотации типа воз- вращаемого функцией значения, потому что функция пути может возвра- щать не саму модель ответа, а словарь, объект базы данных или какую-то другую модель, а затем использовать response_model , чтобы наложить огра- ничения и сериализовать поля. Например, в маршруте search я вернул генератор элементов типа dict, а не объектов CharName, но этого достаточно для FastAPI и пидантической схемы, Написание асинхронных серверов  745\n--- Страница 745 ---\nчтобы проверить мои данные и построить JSON-ответ, совместимый с response_ model=list[CharName] . Теперь обратимся к скрипту tcp_mojifinder.py, который отвечает на запросы, как показано на рис. 21.5. Асинхронный TCP-сервер В программе tcp_mojifinder.py используется протокол TCP для взаимодействия с клиентом типа Telnet или Netcat, поэтому я смог написать ее, используя толь- ко asyncio без внешних зависимостей – и не изобретая заново HTTP. На рис. 21.5 показан пример текстового пользовательского интерфейса. Рис. 21.5. Telnet-сеанс с сервером tcp_mojifinder.py: запрос по слову «fire» Эта программа в два раза длиннее web_mojifinder.py, поэтому я разбил ее опи- сание на три части: примеры 21.12, 21.14 и 21.15. Начало файла tcp_mojifinder. py, включая предложения import, показано в примере 21.14, но начать я решил с сопрограммы supervisor и функции main, приводящих программу в действие. Пример 21.12. tcp_mojifinder.py: простой TCP-сервер; продолжение в примере 21.14 async def supervisor(index: InvertedIndex, host: str, port: int) -> None: server = await asyncio.start_server(  functools.partial(finder, index),  host, port)  socket_list = cast(tuple[TransportSocket, ], server.sockets)  addr = socket_list[0].getsockname() print(f'Serving on {addr}. Hit CTRL-C to stop.')  await server.serve_forever()  def main(host: str = '127.0.0.1', port_arg: str = '2323'): port = int(port_arg) print('Building index.') index = InvertedIndex()  try: asyncio.run(supervisor(index, host, port))  except KeyboardInterrupt:  print('\\nServer shut down.')746  Асинхронное программирование\n--- Страница 746 ---\nif __name__ == '__main__': main(*sys .argv[1:])  Это await быстро получает экземпляр asyncio.Server , TCP-сервера. По умол- чанию start_server создает и запускает сервер, поэтому он готов к приему запросов на подключение.  Первым аргументом start_server является client_connected_cb – обратный вызов, который выполняется, когда появляется новое клиентское под- ключение. Это может быть функция или сопрограмма, но в любом случае она должна принимать ровно два аргумента: asyncio.StreamReader и asyncio. StreamWriter . Однако моей сопрограмме finder нужен также индекс, поэтому я воспользовался функцией functools.partial , чтобы привязать данный па- раметр и получить вызываемый объект, принимающий читателя и писате- ля. Адаптация пользовательских функций к API обратных вызовов – самое час тое применение functools.partial .  host и port – второй и третий аргументы start_server . Полную сигнатуру см. в документации по asyncio ( https://docs.python.org/3/library/asyncio-stream. html#asyncio.start_server).  Этот cast необходим, потому что в typeshed находится устаревшая аннота- ция типа для свойства sockets класса Server – по состоянию на май 2021 года. См. проблему #5535 в typeshed ( https://github.com/python/typeshed/issues/5535)1.  Показать адрес и порт первого сокета сервера.  Хотя start_server уже запустила сервер как конкурентную задачу, я должен добавить await при вызове метода server_forever , чтобы моя сопрограмма supervisor здесь приостановилась. Иначе supervisor вернулась бы немед- ленно, что привело бы к завершению цикла, начатого вызовом asyncio. run(supervisor(…)) , и выходу из программы. В документации по Server.serve_ forever (https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.Server. serve_ forever) написано: «Этот метод можно вызывать, если сервер уже принимает запросы на подключение».  Построить инвертированный индекс2.  Запустить цикл событий, в котором исполняется supervisor .  Перехватить исключение KeyboardInterrupt , чтобы при остановке сервера пу- тем нажатия Ctrl-C в терминале, где он исполняется, не показывалась от- влекающая внимание трасса вызовов. Понять, как устроен поток управления в tcp_mojifinder.py, будет проще, изучив распечатку на консоли сервера (см. пример 21.13). 1 Проблема #5535 была закрыта в октябре 2021 года, но с тех пор новых версий Mypy не выходило, поэтому ошибка остается. 2 Технический рецензент Леонардо Рохаэль отметил, что построение индекса мож - но было бы вынести в другой поток, вызвав loop.run_with_executor() в сопрограмме supervisor ; тогда сервер был бы готов принимать запросы немедленно, пока индекс строится. Это правда, но обращение к индексу – единственное, что этот сервер дела- ет, так что в данном примере мы бы ничего не выиграли. Написание асинхронных серверов  747\n--- Страница 747 ---\nПример 21.13. tcp_mojifinder.py: это серверная часть сеанса, изображенного на рис. 21.5 $ python3 tcp_mojifinder.py Building index.  Serving on ('127.0.0.1', 2323). Hit Ctrl-C to stop. From ('127.0.0.1', 58192): 'cat face'  To ('127.0.0.1', 58192): 10 results. From ('127.0.0.1', 58192): 'fire'  To ('127.0.0.1', 58192): 11 results. From ('127.0.0.1', 58192): '\\x00'  Close ('127.0.0.1', 58192).  ^C  Server shut down.  $  Напечатано main. До появления следующей строки я наблюдал задержку 0,6 с; в это время строился индекс.  Напечатано supervisor .  Первая итерация цикла while в finder. Стек TCP/IP назначил моему Telnet- клиенту порт 58192. Если к серверу подключилось несколько клиентов, то в распечатке будут встречаться разные порты.  Вторая итерация цикла while в finder.  Я нажал в окне клиентского терминала Ctrl-C; выход из цикла while в finder.  Сопрограмма finder печатает это сообщение, затем завершается. Тем време- нем сервер продолжает работать и готов обслужить другого клиента.  Я нажал Ctrl-C в окне серверного терминала; server.serve_forever прервана, при этом завершается supervisor и цикл событий.  Напечатано main. После того как main построила индекс и запустила цикл событий, supervisor печатает сообщение Serving on… и приостанавливается в строке await server.serve_ forever(). В этот момент управление попадает в цикл событий и там и остается, время от времени возвращаясь в сопрограмму finder, которая вновь уступает управление циклу событий всякий раз, как должна дождаться отправки или получения данных из сети. Пока цикл событий работает, для каждого клиента, подключившегося к сер- веру, будет создаваться новый экземпляр сопрограммы finder. Таким обра- зом, этот простой сервер может одновременно обслуживать много клиентов. Он продолжает работать, пока не возникнет исключение KeyboardInterrupt или процесс не будет снят ОС. Теперь рассмотрим начало скрипта tcp_mojifinder.py, где находится сопро- грамма finder. Пример 21.14. tcp_mojifinder.py: продолжение примера 21.12 import asyncio import functools import sys from asyncio.trsock import TransportSocket from typing import cast from charindex import InvertedIndex, format_results ❶748  Асинхронное программирование\n--- Страница 748 ---\nCRLF = b'\\r\\n' PROMPT = b'?> ' async def finder(index: InvertedIndex , ❷ reader: asyncio .StreamReader , writer: asyncio .StreamWriter) -> None: client = writer .get_extra_info('peername') ❸ while True: ❹ writer .write(PROMPT) # не может быть await! ❺ await writer .drain() # должно быть await! ❻ data = await reader.readline() ❼ if not data: ❽ break try: query = data.decode().strip() ❾ except UnicodeDecodeError: ❿ query = '\\x00' print(f' From {client}: {query!r}') ⓫ if query: if ord(query[:1]) < 32: ⓬ break results = await search(query, index, writer) ⓭ print(f' To {client}: {results} results.') ⓮ writer.close() ⓯ await writer.wait_closed() ⓰ print(f'Close {client}.') ⓱ ❶ format_results полезна для отображения результатов вызова InvertedIndex. search в текстовом интерфейсе, например на командной консоли или в се- ансе Telnet. ❷ Чтобы передать finder сопрограмме asyncio.start_server , я обернул ее функци- ей functools.partial , потому что сервер ожидает получить сопрограмму или функцию, принимающую только аргументы reader и writer. ❸ Получить адрес удаленного клиента, подключившегося к сокету. ❹ В этом цикле происходит диалог, который завершается, когда от клиента будет получен управляющий символ. ❺ Метод StreamWriter.write – не сопрограмма, а обычная функция; в этой стро- ке посылается приглашение ?>. ❻ StreamWriter.drain сбрасывает буфер writer; это сопрограмма, поэтому ей должно предшествовать слово await. ❼ StreamWriter.readline – сопрограмма, которая возвращает bytes. ❽ Если не было получено ни одного байта, значит, клиент закрыл соедине- ние, поэтому выходим из цикла. ❾ Декодировать bytes в str, пользуясь кодировкой UTF-8 по умолчанию. ❿ Ошибка UnicodeDecodeError может возникнуть, когда пользователь нажал Ctrl-C и Telnet-клиент отправил управляющие символы; если такое случи- лось, для простоты заменить запрос нулевым символом. ⓫ Напечатать запрос на консоли. ⓬ Выйти из цикла, если получен управляющий или нулевой символ. ⓭ Выполнить поиск; код представлен в следующем примере. Написание асинхронных серверов  749\n--- Страница 749 ---\n⓮ Напечатать ответ на консоли. ⓯ Закрыть StreamWriter . ⓰ Дождаться закрытия StreamWriter . Это рекомендуется в документации по мето- ду .close() (https://docs.python.org/3/library/asyncio-stream.html#asyncio. StreamWriter. close). ⓱ Напечатать на консоли сообщение о завершении этого сеанса с клиентом. Последняя часть данного примера – сопрограмма search (пример 21.15). Пример 21.15. tcp_mojifinder.py: сопрограмма search async def search(query: str,  index: InvertedIndex, writer: asyncio.StreamWriter) -> int: chars = index.search(query)  lines = (line.encode() + CRLF for line  in format_results(chars)) writer.writelines(lines)  await writer.drain()  status_line = f'{\"–\" * 66} {len(chars)} found'  writer.write(status_line.encode() + CRLF) await writer.drain() return len(chars)  search должна быть сопрограммой, потому что пишет в StreamWriter и должна использовать его метод-сопрограмму .drain().  Опросить инвертированный индекс.  Это генераторное выражение будет отдавать байтовые строки в кодировке UTF-8, содержащие кодовую позицию Unicode, сам символ, его имя и по- следовательность CRLF, например b'U+0039\\t9\\tDIGIT NINE\\r\\n' .  Отправить lines. Как ни странно, writer.writelines – не сопрограмма.  Но writer.drain() – сопрограмма. Не забудем await!  Построить и отправить строку состояния. Отметим, что весь сетевой ввод-вывод в tcp_mojifinder.py производит - ся в байтах (bytes); мы должны декодировать байты, поступающие из сети, и закодировать строки перед их отправкой. В Python 3 по умолчанию под- разумевается кодировка UTF-8, именно ей я неявно пользуюсь в вызовах encode и decode. Заметим, что некоторые методы ввода-вывода являются сопро- граммами, так что им должно предшествовать слово await, тогда как другие – обычные функции. Например, StreamWriter.write – обычная функция, потому что она записывает в буфер. С другой стороны, StreamWriter.drain сбрасывает буфер и выполняет сетевой ввод-вывод, поэтому является сопрограммой, как и StreamReader. readline – но не StreamWriter.writelines ! Когда я работал над пер- вым изданием книги, документация по asyncio API была улучше- на – в ней ясно сказано, что является сопрограммами, а что нет (https://docs.python.org/3/library/asyncio-stream.html#streamwriter). 750  Асинхронное программирование\n--- Страница 750 ---\nВ коде tcp_mojifinder.py используется высокоуровневый асинхронный API потоков (https://docs.python.org/3/library/asyncio-stream.html), который предо- ставляет готовый сервер, так что вам остается только реализовать функцию- обработчик в виде простого обратного вызова или сопрограммы. Существует также низкоуровневый API транспорта и протоколов (https://docs.python.org/3/ library/asyncio-protocol.html), на который оказали влияние абстракции транс - порта и протоколов в каркасе Twisted. Дополнительную информацию, в т. ч. об эхо-серверах и их клиентах на протоколах TCP и UDP, реализованных с по- мощью этого низкоуровневого API, см. в документации по asyncio (https://docs. python.org/3/library/asyncio-protocol.html#tcp-echo-server). А нашей следующей темой будет конструкция async for и объекты, приводя- щие ее в действие. аСинхр Онные итерат Оры и итерируемые ОБъекты В разделе «Асинхронные контекстные менеджеры» выше мы видели, как async with работает с объектами, реализующими методы __aenter__ и __aexit__, которые возвращают объекты, допускающие ожидание, обычно в форме объектов со- программ. Аналогично async for работает с асинхронными итерируемыми объектами, т. е. с объектами, реализующими метод __aiter__. Однако __aiter__ должен быть обычным методом, а не сопрограммой, и возвращать асинхронный итератор. Асинхронный итератор предоставляет метод-сопрограмму __anext__, кото - рый возвращает допускающий ожидание объект, чаще всего объект сопро- граммы. Ожидается также, что он реализует метод __aiter__, который обычно возвращает self. Это отражает важное различие между итерируемыми объек - тами и итераторами, которое обсуждалось в разделе «Не делайте итерируемый объект итератором для самого себя» главы 17. В документации по асинхронному драйверу PostgreSQL aiopg есть пример, иллюстрирующий использование async for для итерирования по строкам кур- сора базы данных: async def go(): pool = await aiopg.create_pool(dsn) async with pool.acquire() as conn: async with conn.cursor() as cur: await cur.execute(\"SELECT 1\") ret = [] async for row in cur: ret.append(row) assert ret == [(1,)] В этом примере запрос возвращает одну строку, но в реалистичном сцена- рии ответ на запрос SELECT может содержать тысячи строк. Для больших ответов в курсор не загружаются все строки сразу. Поэтому важно, чтобы конструкция async for row in cur: не блокировала цикл событий, пока курсор ожидает вы- борки дополнительных строк. Реализовав курсор как асинхронный итератор, aiopg может уступать управление циклу событий при каждом вызове __anext__ и возоб новлять работу, когда от PostgreSQL поступят дополнительные строки. Асинхронные итераторы и итерируемые объекты  751\n--- Страница 751 ---\nАсинхронные генераторные функции Для реализации асинхронного итератора нужно написать класс с методами __anext__ и __aiter__, но есть способ проще: написать функцию, объявленную как async def и содержащую в теле yield. Тут просматривается параллель с тем, как генераторные функции упрощают классический паттерн Итератор. Рассмотрим простой пример использования async for и реализации асин- хронного генератора. В примере 21.1 мы видели скрипт blogdom.py, который проверял доменные имена. Теперь предположим, что мы нашли другие при- менения написанной там сопрограмме probe и решили поместить ее в новый модуль, domainlib.py, вместе с новым асинхронным генератором multi_probe , который принимает список доменных имен и отдает результаты по мере за- вершения проверки. Вскоре мы покажем реализацию domainlib.py, но сначала посмотрим, как она используется в сочетании с новой асинхронной консолью Python. Эксперименты с асинхронной консолью Python Начиная с версии Python 3.8 (https://docs.python.org/3/whatsnew/3.8.html#asyncio) интерпретатор можно запускать с флагом -m asyncio , чтобы получить «асин- хронный цикл REPL»: консоль Python, которая импортирует asyncio, предостав- ляет цикл событий и принимает конструкции await, async for и async with в ответ на приглашение верхнего уровня. Иначе использование этих конструкций вне платформенных сопрограмм считалось бы синтаксической ошибкой1. Для экспериментов с domainlib.py зайдите в каталог 21-async/domains/asyncio/ в своей локальной копии репозитория кода (https://github.com/fluentpython/ example-code-2e). Затем выполните команду $ python -m asyncio Будет выведено начальное сообщение вида asyncio REPL 3.9.1 (v3.9.1:1e5d33e9b9, Dec 7 2020, 12:10:52) [Clang 6.0 (clang-600.0.57)] on darwin Use \"await\" directly instead of \"asyncio.run()\". Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import asyncio >>> Обратите внимание: в заголовке сказано, что можно использовать await вместо asyncio.run() для управления сопрограммами и другими допускающими ожидание объектами. И еще: я не вводил import asyncio . Модуль asyncio импор- тируется автоматически, и эта строка ясно сообщает об этом факте пользова- телю. Теперь импортируем модуль domainlib.py и поэкспериментируем с двумя его сопрограммами: probe и multi_probe (пример 21.16). 1 Отличный инструмент для экспериментов, похожий на консоль Node.js. Спасибо Юрию Селиванову за еще один великолепный вклад в асинхронный Python.752  Асинхронное программирование\n--- Страница 752 ---\nПример 21.16. Эксперименты с domainlib.py после запуска python3 -m asyncio >>> await asyncio.sleep(3, 'Rise and shine!')  'Rise and shine!' >>> from domainlib import * >>> await probe('python.org')  Result(domain='python.org', found=True)  >>> names = 'python.org rust-lang.org golang.org no-lang.invalid'.split()  >>> async for result in multi_probe(names):  print(*result, sep='\\t') golang.org True  no-lang.invalid False python.org True rust-lang.org True >>>  Пробуем простое await, чтобы посмотреть на асинхронную консоль в дей- ствии. Совет: сопрограмма asyncio.sleep() принимает факультативный вто- рой аргумент, который возвращается, если ожидать ее завершения с помо- щью await.  Выполнить сопрограмму probe.  Версия probe из domainlib возвращает именованный кортеж Result.  Построить список доменных имен. Домен верхнего уровня .invalid зарезер- вирован для тестирования. DNS-запросы к таким доменам всегда возвра- щают ответ NXDOMAIN от сервера, что означает «домен не существует»1.  С помощью async for обойти асинхронный генератор multi_probe и напеча- тать результаты.  Отметим, что результаты печатаются не в том порядке, в каком домен- ные имена передавались multiprobe , а в порядке получения ответов от DNS- сервера. Из примера 21.16 видно, что multi_probe – асинхронный генератор, потому что он совместим с async for. Теперь проделаем еще несколько экспериментов, продолжая начатый пример. Пример 21.17. Дополнительные эксперименты, продолжение примера 21.16 >>> probe('python.org')  <coroutine object probe at 0x10e313740> >>> multi_probe(names)  <async_generator object multi_probe at 0x10e246b80> >>> for r in multi_probe(names):  print(r) Traceback (most recent call last): TypeError: 'async_generator' object is not iterable  Вызов платформенной сопрограммы дает объект сопрограммы. 1 См. RFC 6761 «Special-Use Domain Names» (https://www.artima.com/weblogs/viewpost.jsp? thread=299551). Асинхронные итераторы и итерируемые объекты  753\n--- Страница 753 ---\n Вызов асинхронного генератора дает объект async_generator .  Мы не можем использовать обычный цикл for с асинхронными генерато- рами, потому что они реализуют метод __aiter__, а не __iter__. Асинхронные генераторы приводятся в действие конструкцией async for, ко- торая может быть предложением блока (как в примере 21.16), а также появ- ляться внутри асинхронных включений, которые мы скоро рассмотрим. Реализация асинхронного генератора Теперь рассмотрим код domainlib.py, содержащий асинхронный генератор multi_probe (пример 21.18). Пример 21.18. domainlib.py: функции для проверки доменных имен import asyncio import socket from collections.abc import Iterable, AsyncIterator from typing import NamedTuple, Optional class Result(NamedTuple):  domain: str found: bool OptionalLoop = Optional[asyncio.AbstractEventLoop]  async def probe(domain: str, loop: OptionalLoop = None) -> Result:  if loop is None: loop = asyncio.get_running_loop() try: await loop.getaddrinfo(domain, None) except socket.gaierror: return Result(domain, False) return Result(domain, True) async def multi_probe(domains: Iterable[str]) -> AsyncIterator[Result]:  loop = asyncio.get_running_loop() coros = [probe(domain, loop) for domain in domains]  for coro in asyncio.as_completed(coros):  result = await coro  yield result   Благодаря NamedTuple результат probe проще читать и отлаживать.  Этот псевдоним типа создан для того, чтобы следующая строка не оказа- лась слишком длинной для размещения на печатной странице.  probe теперь получает факультативный аргумент loop, чтобы избежать по- вторного вызова get_running_loop , когда эта сопрограмма вызывается из multi_probe .  Асинхронная генераторная функция порождает асинхронный объект-ге- нератор, который можно аннотировать типом AsyncIterator[SomeType] .  Построить список объектов сопрограммы probe, по одному для каждого до- мена.  Здесь async for не нужен, т. к. asyncio.as_completed – классический генератор.754  Асинхронное программирование\n--- Страница 754 ---\n Ждать завершения объекта сопрограммы для получения результата.  Отдать result. Эта строка превращает multi_probe в асинхронный генератор. Цикл for в примере 21.18 можно было бы сделать короче: for coro in asyncio .as_completed(coros): yield await coro Python разбирает этот код как yield (await coro) , поэтому он ра- ботает. Я подумал, что такая краткая запись в первом же примере асин- хронного генератора может оказаться непонятной, поэтому раз- бил ее на две строки. Имея domainlib.py, мы можем продемонстрировать использование асин- хронного генератора multi_probe в скрипте domaincheck.py, который принимает суффикс доменного имени и ищет домены, образованные короткими ключе- выми словами Python. Ниже приведен пример вывода domaincheck.py: $ ./domaincheck.py net FOUND NOT FOUND ===== ========= in.net del.net true.net for.net is.net none.net try.net from.net and.net or.net else.net with.net if.net as.net elif.net pass.net not.net def.net Благодаря domainlib код domaincheck.py оказался линейным, как показано в примере 21.19. Пример 21.19. domaincheck.py: утилита для проверки доменных имен с использованием модуля domainlib #!/usr/bin/env python3 import asyncio import sys from keyword import kwlist from domainlib import multi_probe async def main(tld: str) -> None: Асинхронные итераторы и итерируемые объекты  755\n--- Страница 755 ---\ntld = tld.strip('.') names = (kw for kw in kwlist if len(kw) <= 4)  domains = (f'{name}.{tld}'.lower() for name in names)  print('FOUND\\t\\tNOT FOUND')  print('=====\\t\\t=========') async for domain, found in multi_probe(domains):  indent = '' if found else '\\t\\t'  print(f'{indent}{domain}') if __name__ == '__main__': if len(sys.argv) == 2: asyncio.run(main(sys.argv[1]))  else: print('Please provide a TLD.', f'Example: {sys.argv[0]} COM.BR')  Построить список ключевых слов длины не более 4.  Построить список доменных имен с заданным суффиксом в качестве до- мена верхнего уровня (TLD).  Отформатировать заголовок для вывода таблицы.  Асинхронно обойти multi_probe(domains) .  Задать отступ indent шириной 0 или два табулятора, чтобы поместить ре- зультат в нужный столбец.  Выполнить сопрограмму main с заданным аргументом в командной строке. У генераторов есть еще одно применение, не связанное с итерированием: их можно использовать в роли контекстных менеджеров. Это относится и к асинхронным генераторам. Асинхронные генераторы в качестве контекстных менеджеров Писать свой контекстный менеджер программисту приходится нечасто, но если такая необходимость возникла, вспомните о декораторе @asynccontextmanager (https://docs.python.org/3/library/contextlib.html#contextlib.asynccontextmanager), добав- ленном в модуль contextlib в версии Python 3.7. Он очень похож на декоратор @contextmanager , который мы изучали в разделе «Использование @contextmanager» главы 18. Интересный пример совместного использования @asynccontextmanager и loop.run_in_ executor приведен в книге Калеба Хэттинга «Using Asyncio in Python». Пример 21.20 взят из кода Калеба – с одним изменением и добавленными выносками. Пример 21.20. Совместное использование @asynccontextmanager и loop.run_in_executor from contextlib import asynccontextmanager @asynccontextmanager async def web_page(url):  loop = asyncio.get_running_loop()  data = await loop.run_in_executor(  None, download_webpage, url) yield data  await loop.run_in_executor(None, update_stats, url) 756  Асинхронное программирование\n--- Страница 756 ---\nasync with web_page('google.com') as data:  process(data)  Декорированная функция должна быть асинхронным генератором.  Небольшое изменение кода Калеба: используется облегченная get_running_ loop вместо get_event_loop  Предположим, что download_webpage – блокирующая функция, в которой ис- пользуется библиотека requests; мы выполняем ее в отдельном потоке, что- бы не блокировать цикл событий.  Все строки перед этим выражением yield станут методом-сопрограммой __aenter__ асинхронного контекстного менеджера, построенного декорато- ром. Значение data будет связано с переменной data после слова as в пред- ложении async with ниже.  Строки после yield станут методом-сопрограммой __aexit__. Здесь еще один блокирующий вызов делегируется исполнителю, работающему в отдель- ном потоке.  Использовать web_page в сочетании с async with . Это сильно напоминает последовательный декоратор @contextmanager . Детали посмотрите в разделе «Использование @contextmanager» главы 18, где показа- на также обработка ошибок в строке yield. Еще один пример @asynccontextmanager см. в документации по модулю contextlib (https://docs.python.org/3/library/contextlib. html# contextlib.asynccontextmanager). Теперь подведем итог обсуждению асинхронных генераторных функций, сравнив их с платформенными сопрограммами. Асинхронные генераторы и платформенные сопрограммы Перечислим сходства и различия платформенных сопрограмм и асинхронных генераторных функций. Те и другие объявляются с помощью async def. В теле асинхронного генератора всегда имеется выражение yield – оно и делает его генератором. В платформенной сопрограмме yield никогда не встречается. Платформенная сопрограмма может возвращать с помощью return зна- чение, отличное от None. В асинхронном генераторе возможны только предложения return без указания возвращаемого значения. Платформенные сопрограммы – это допускающие ожидание объекты: они могут активироваться выражениями await или передаваться много- численным функциям в модуле asyncio, которые принимают допускаю- щие ожидание аргументы, например create_task . Асинхронные генера- торы не допускают ожидания. Они являются асинхронными итерируе- мыми объектами и активируются с помощью async for или асинхронных включений. Пришла пора поговорить об асинхронных включениях. Асинхронные итераторы и итерируемые объекты  757\n--- Страница 757 ---\nАсинхронные включения и асинхронные генераторные выражения В документе PEP 530 «Asynchronous Comprehensions» (https://peps.python.org/ pep-0530/) описана конструкция async for и использование await во включени- ях и генераторных выражениях. Эти предложения были реализованы в версии Python 3.6. Единственная конструкция, определенная в PEP 530, которая может нахо- диться вне тела async def, – асинхронное генераторное выражение. Определение и использование асинхронного генераторного выражения Имея асинхронный генератор multi_probe из примера 21.18, мы могли бы на- писать еще один асинхронный генератор, возвращающий только имена най- денных доменов. Вот как это делается – снова с применением асинхронной консоли, запускаемой с флагом -m asyncio : >>> from domainlib import multi_probe >>> names = 'python.org rust-lang.org golang.org no-lang.invalid'.split() >>> gen_found = (name async for name, found in multi_probe(names) if found)  >>> gen_found <async_generator object <genexpr> at 0x10a8f9700>  >>> async for name in gen_found:  print(name) golang.org python.org rust-lang.org  Наличие async for превращает это в асинхронное генераторное выражение. Его можно определить в любом месте Python-модуля.  Асинхронное генераторное выражение строит объект async_generator – точ- но того же вида, который возвращает асинхронная генераторная функция вроде multi_probe .  Асинхронный объект-генератор активируется предложением async for, ко- торое, в свою очередь, может находиться только внутри тела async def или на магической асинхронной консоли, которую я использовал в этом примере. Подведем итоги: асинхронное генераторное выражение может быть опре- делено в любом месте программы, но потребляться может только внутри плат - форменной сопрограммы или асинхронной генераторной функции. Остальные конструкции, введенные в PEP 530, можно определить и исполь- зовать только внутри платформенных сопрограмм или асинхронных генера- торных функций. Асинхронные включения Юрий Селиванов, автор документа PEP 530, обосновывает потребность в асин- хронных включениях тремя короткими фрагментами кода, которые воспроиз- водятся ниже.758  Асинхронное программирование\n--- Страница 758 ---\nВсе мы согласимся, что хорошо бы иметь возможность переписать следую- щий код: result = [] async for i in aiter(): if i % 2: result .append(i) в таком виде: result = [i async for i in aiter() if i % 2] Кроме того, если fun – платформенная сопрограмма, то хорошо бы иметь возможность написать: result = [await fun() for fun in funcs] Использование await в списковом включении аналогично ис- пользованию asyncio.gather . Но gather дает больше контроля над обработкой исключений благодаря факультативному аргументу return_exceptions . Калеб Хэттинг рекомендует всегда задавать return_exceptions=True (по умолчанию этот аргумент равен False). Дополнительные сведения см. в документации по asyncio.gather (https://docs.python.org/3/library/asyncio-task.html#asyncio.gather). Вернемся к магической асинхронной консоли: >>> names = 'python.org rust-lang.org golang.org no-lang.invalid'.split() >>> names = sorted(names) >>> coros = [probe(name) for name in names] >>> await asyncio.gather(*coros) [Result(domain='golang.org', found=True), Result(domain='no-lang.invalid', found=False), Result(domain='python.org', found=True), Result(domain='rust-lang.org', found=True)] >>> [await probe(name) for name in names] [Result(domain='golang.org', found=True), Result(domain='no-lang.invalid', found=False), Result(domain='python.org', found=True), Result(domain='rust-lang.org', found=True)] >>> Я отсортировал список имен, чтобы продемонстрировать, что в обоих случа- ях результаты выдаются в том порядке, в каком были поданы на вход. Документ PEP 530 позволяет использовать async for и await в списковых вклю- чениях, равно как в словарных и множественных. Например, ниже показано использование словарного включения для хранения результатов multi_probe на асинхронной консоли: >>> {name: found async for name, found in multi_probe(names)} {'golang.org': True, 'python.org': True, 'no-lang.invalid': False, 'rust-lang.org': True} Мы можем использовать ключевое слово await в выражении перед конструк - циями for или async for, а также после ключевого слова if. Ниже приведен при- мер множественного включения для сбора только уже существующих домен- ных имен: Асинхронные итераторы и итерируемые объекты  759\n--- Страница 759 ---\n>>> {name for name in names if (await probe(name)).found} {'rust-lang.org', 'python.org', 'golang.org'} Мне пришлось поставить дополнительные скобки вокруг выражения await из-за более высокого приоритета оператора . (точка), поддерживаемого мето- дом __getattr__ . Все включения также могут встречаться только в теле async def или на асин- хронной консоли. Теперь поговорим об очень важном свойстве предложений async, выражений async и создаваемых ими объектов. Эти конструкции часто используются в со- четании с asyncio, но на самом деле они не зависят от конкретной библиотеки. async за пределами asyncio: Curio Языковые конструкции async/await в Python не привязаны к конкретному цик- лу событий или библиотеке1. Благодаря расширяемому API, обеспечиваемому специальными методами, любой достаточно мотивированный программист может написать свою среду асинхронного выполнения и каркас для управле- ния платформенными сопрограммами, асинхронными генераторами и т. д. Именно это и совершил Дэвид Бизли в своем проекте Curio ( https://curio. readthedocs.io/en/latest/index.html). Ему было интересно, как эти новые языковые средства можно использовать в каркасе, созданном с нуля. Напомним, что биб- лиотека asyncio была включена в версию Python 3.4 и использовала yield from вместо await, так что ее API не допускал асинхронных контекстных менедже- ров, асинхронных итераторов и многого другого, что стало возможным после введения ключевых слов async и await. В результате Curio может похвастаться более чистым API и более простой реализацией, чем asyncio. В примере 21.21приведен скрипт blogdom.py (пример 21.1), переписанный с использованием Curio. Пример 21.21. blogdom.py: пример 21.1 с использованием Curio #!/usr/bin/env python3 from curio import run, TaskGroup import curio.socket as socket from keyword import kwlist MAX_KEYWORD_LEN = 4 async def probe(domain: str) -> tuple[str, bool]:  try: await socket.getaddrinfo(domain, None)  except socket.gaierror: return (domain, False) return (domain, True) async def main() -> None: names = (kw for kw in kwlist if len(kw) <= MAX_KEYWORD_LEN) domains = (f'{name}.dev'.lower() for name in names) async with TaskGroup() as group:  1 В отличие от JavaScript, где async и await зашиты во встроенный цикл событий и среду выполнения, т. е. браузер, Node.js или Deno.760  Асинхронное программирование\n--- Страница 760 ---\nfor domain in domains: await group.spawn(probe, domain)  async for task in group:  domain, found = task.result mark = '+' if found else ' ' print(f'{mark} {domain}') if __name__ == '__main__': run(main())   probe не нужно получать цикл событий, потому что …  … getaddrinfo – функция верхнего уровня в модуле curio.socket , а не метод объекта loop, как в asyncio.  Группа задач TaskGroup – ключевое понятие в Curio, она служит для отслежи- вания и управления несколькими сопрограммами и гарантирует, что все они выполняются, а по завершении производится очистка.  Метод TaskGroup.spawn запускает сопрограмму, управляемую конкретным эк- земпляром TaskGroup. Сопрограмма обернута экземпляром Task.  Обход TaskGroup с помощью async for отдает экземпляры Task по мере их за- вершения. Это соответствует строке примера 21.1, в которой используется конструкция for … as_completed(…): .  В Curio впервые предложен этот разумный способ запуска асинхронной программы в Python. Еще пара слов о последнем пункте: в примерах кода на основе asyncio в пер- вом издании этой книги снова и снова повторяются такие строки: loop = asyncio.get_event_loop() loop.run_until_complete(main()) loop.close() Класс Curio TaskGroup– это асинхронный контекстный менеджер, который за- меняет несколько поспешно придуманных API и способов кодирования в asyncio. Мы только что видели, как обход TaskGroup делает ненужной функцию asyncio.as_ completed(…) . Другой пример: следующий фрагмент, взятый из документации по группам задач (https://curio.readthedocs.io/en/latest/reference.html# task-groups), при- меняется вместо специальной функции gather для сбора результатов всех задач в группе: async with TaskGroup(wait=all) as g: await g.spawn(coro1) await g .spawn(coro2) await g.spawn(coro3) print('Results:', g .results) Группы задач поддерживают структурную конкурентность ( https:// en.wikipedia.org/wiki/Structured_concurrency): форму конкурентного программи- рования, в которой вся деятельность группы асинхронных задач ограничена одной точкой входа и одной точкой выхода. Это аналог структурного програм- мирования, которое поставило вне закона команду GOTO и ввело блоки, что- бы ограничить количество точек входа и выхода для циклов и подпрограмм. При использовании в качестве асинхронного контекстного менеджера TaskGroup Асинхронные итераторы и итерируемые объекты  761\n--- Страница 761 ---\nгарантирует, что при выходе из объемлющего блока все задачи, запущенные внутри группы, завершаются или отменяются, а все исключения возбуждаются. Структурная конкурентность, скорее всего, будет внедрена в asyncio в последующих версиях Python. Ясный намек на это по- явился в документе PEP 654 «Exception Groups and except*» (https:// peps.python.org/pep-0654/), одобренном для реализации в Python 3.11 (https://mail.python.org/archives/list/python-dev@python.org/thread/2ORD AW74LGE3ZI2QETPJRT2ZL7MCCPG2/). В разделе «Мотивация» (https:// peps.python.org/pep-0654/#motivation) упоминаются «ясли», как в Trio называются группы задач: «Реализация улучшенного API запуска задач в asyncio, подсказанного яслями Trio, стала основным побу - дительным мотивом для написания этого PEP». Еще одна важная особенность Curio – улучшенная поддержка программи- рования с использованием сопрограмм и потоков в одной кодовой базе, что совершенно необходимо в большинстве нетривиальных асинхронных про- грамм. Запуск потока с помощью await spawn_thread(func, ) возвращает объект AsyncThread с интерфейсом, похожим на Task. Потоки могут вызывать сопрограм- мы благодаря специальной функции AWAIT(coro) – ее имя написано прописными буквами, потому что await – теперь ключевое слово. Curio предлагает также класс UniversalQueue , который можно использовать для координации работы, выполняемой потоками, сопрограммами Curio и сопро- граммами asyncio. Все правильно – в Curio есть средства, позволяющие работать в потоке и выполнять asyncio в другом потоке того же процесса, а взаимодей- ствие при этом осуществляется с помощью UniversalQueue и UniversalEvent . API этих «универсальных» классов одинаков внутри и вне сопрограмм, но в сопро- грамме вызовам необходимо предпосылать await. В октябре 2021 года, когда я пишу эти строки, HTTPX стала первой клиент - ской библиотекой для работы с HTTP, совместимой с Curio, но я пока не знаю ни одной асинхронной библиотеки баз данных, поддерживающей ее. В репо- зитории Curio имеется внушительный набор примеров сетевого программи- рования (https://github.com/dabeaz/curio/tree/78bca8a6ad677ef51e1568ac7b3e51441a b49c42/examples), в т. ч. с использованием WebSocket, а также реализация конку - рентного программирования, описанного в RFC 8305 «Happy Eyeballs» (https:// datatracker.ietf.org/doc/html/rfc8305), который позволяет подключаться к оконеч- ным точкам IPv6, но быстро переходить к IPv4 при необходимости. Дизайн Curio оказал большое влияние на разработчиков. Каркас Trio (https:// trio.readthedocs.io/en/stable/), начатый Натаниэлем Дж. Смитом, многие идеи заимствует у Curio. Возможно также, что Curio подтолкнул соразработчиков Python сделать API asyncio удобнее для пользователей. Например, в первых версиях пользователям asyncio частенько приходилось получать и передавать объект loop, потому что некоторые необходимые функции либо были методами loop, либо требовали loop в качестве аргумента. В недавних версиях Python пря- мой доступ к циклу событий нужен не так часто; более того, некоторые функ - ции, которые принимали loop в качестве факультативного аргумента, теперь объявили эту практику нерекомендуемой. Следующей нашей темой будут аннотации асинхронных типов. 762  Асинхронное программирование\n--- Страница 762 ---\nаннО тации типОв для аСинхр Онных ОБъект Ов Тип возвращаемого платформенной сопрограммой значения описывает, что мы получим от сопрограммы по завершении await, т. е. это тип объекта, который встречается в предложениях return в теле платформенной сопро- граммы1. В этой главе встречалось много примеров аннотированных платформенных сопрограмм, в т. ч. probe в примере 21.21: async def probe(domain: str) -> tuple[str, bool]: try: await socket.getaddrinfo(domain, None) except socket.gaierror: return (domain, False) return (domain, True) Для аннотирования параметра, который принимает объект сопрограммы, применяется такой обобщенный тип: class typing.Coroutine(Awaitable[V_co], Generic[T_co, T_contra, V_co]): Этот и следующие типы были введены в версиях Python 3.5 и 3.6 для анно- тирования асинхронных объектов: class typing.AsyncContextManager(Generic[T_co]): class typing.AsyncIterable(Generic[T_co]): class typing.AsyncIterator(AsyncIterable[T_co]): class typing.AsyncGenerator(AsyncIterator[T_co], Generic[T_co, T_contra]): class typing.Awaitable(Generic[T_co]): В Python ≥ 3.9 используйте эквиваленты этих типов из модуля collections.abc . Я хочу подчеркнуть три аспекта этих обобщенных типов. Первое: все они ковариантны относительно первого параметра-типа, ко- торый описывает тип элементов, отдаваемых этими объектами. Вспомните первое из эвристических правил вариантности в главе 15: Если формальный параметр-тип определяет тип данных, исходящих из объекта, то он может быть ковариантным. Второе: AsyncGenerator и Coroutine контравариантны относительно второго и последующих параметров-типов. Это тип аргумента низкоуровневого ме- тода .send(), который цикл событий вызывает для активации асинхронных генераторов и сопрограмм. Поэтому он является «входным» типом, а значит, может быть контравариантным в соответствии со вторым эвристическим пра- вилом вариантности: 1 Это отличается от аннотаций классических сопрограмм, которые мы обсуждали в разделе «Обобщенные типы для классических сопрограмм» главы 17. Аннотации типов для асинхронных объектов  763\n--- Страница 763 ---\nЕсли формальный параметр-тип определяет тип данных, входящих в объект после его начального конструирования, то он может быть контравариантным. Третье: AsyncGenerator не имеет типа возвращаемого значения, в отличие от typing.Generator , который мы видели в разделе «Обобщенные аннотации типов для классических сопрограмм» главы 17. Возврат значения путем возбужде- ния исключения StopIteration(value) был одним из не вполне честных приемов, который позволял генераторам работать как сопрограммы и поддерживать предложение yield from, как было показано в разделе «Классические сопрограм- мы» главы 17. Между асинхронными объектами такого перекрытия нет: объ- екты AsyncGenerator не возвращают значений и полностью отделены от объектов платформенных сопрограмм, которые аннотируются типом typing.Coroutine . Наконец, вкратце рассмотрим преимущества и проблемы, свойственные асинхронному программированию. как раБО тает и как не раБО тает аСинхр ОннОС ть В заключительных разделах этой главы обсуждаются высокоуровневые идеи, относящиеся к асинхронному программированию, вне зависимости от ис- пользуемого языка или библиотеки. Начнем с объяснения главной причины, по которой асинхронное програм- мирование так привлекательно, а затем развенчаем один популярный миф. Круги, разбегающиеся вокруг блокирующих вызовов Райан Дал, автор Node.js, начинает разговор о философии своего проекта сло- вами «Наш подход к вводу-выводу совершенно неверен»1. Он определяет бло- кирующую функцию как функцию, выполняющую файловый или сетевой ввод- вывод, и утверждает, что мы не можем обращаться с ними так же, как с небло- кирующими функциями. Объясняя причину, он ссылается на числа во втором столбце табл. 21.1. Таблица 21.1. Характерные для современных компьютеров задержки чтения данных с различных устройств; в третьем столбце данные представлены в масштабе, который проще воспринять человеку Устройство Такты CPU «Человеческий» масштаб Кеш L1 3 3 секунды Кеш L2 14 14 секунд ЗУПВ 250 250 секунд Диск 41 000 000 1,3 года Сеть 240 000 000 7,6 лет Чтобы по достоинству оценить данные в табл. 21.1, имейте в виду, что совре- менные процессоры с тактовой частотой порядка гигагерц выполняют милли- арды тактов в секунду. Предположим, что CPU выполняет 1 миллиард тактов 1 Видео «Introduction to Node.js» (https://www.youtube.com/watch?v=M-sc73Y-zQA), отметка 4:55.764  Асинхронное программирование\n--- Страница 764 ---\nв секунду. Тогда за 1 секунду он может произвести 333 миллиона чтений из кеша L1 или 4 (четыре!) чтения из сети. В третьем столбце эти числа приведе- ны к другому масштабу путем умножения на постоянный коэффициент. Таким образом, в этой альтернативной вселенной чтение из кеша L1 занимает 3 се- кунды, а из сети 7,6 лет! Таблица 21.1 объясняет, почему дисциплинированный подход к асинхрон- ному программированию может резко увеличить производительность сер- веров. Проблема в том, как добиться соблюдения этой дисциплины. Первый шаг – осознать, что «системы, ограниченные вводом-выводом», – фантазия. Миф о системах, ограниченных вводом-выводом В разговорах часто повторяют, что асинхронное программирование хорошо для «систем, ограниченных вводом-выводом». Из собственного опыта я вынес урок, что не бывает таких систем. Ограничены вводом-выводом могут быть функции. Быть может, подавляющее большинство функций в вашей системе ограничено вводом-выводом, т. е. они тратят больше времени на ожидание ввода-вывода, чем на обработку данных. А пока ждут, уступают управление циклу событий, который может активировать другие готовые к выполнению задачи. Но в любой нетривиальной системе неизбежно есть счетные части, ограниченные производительностью процессора. И даже в тривиальных си- стемах такие места обнаруживаются при работе под нагрузкой. В разделе «По- говорим» ниже я расскажу историю о двух асинхронных программах, которые сражались со счетными функциями, замедлявшими цикл событий до такой степени, что это оказывало серьезное влияние на производительность. Учитывая, что в любой нетривиальной системе есть счетные функции, клю- чом к успеху асинхронного программирования является выработка правиль- ного подхода к ним. Как не попасть в ловушку счетных функций Если вы пишете крупные программы на Python, то, вероятно, имеете автома- тизированные регрессионные тесты, предназначенные для своевременного обнаружения падения производительности. Это критически важно для асин- хронного кода, но относится и к многопоточному – из-за GIL. Если дождать- ся момента, когда замедление начнет тревожить команду разработчиков, то будет уже слишком поздно. Для исправления, скорее всего, понадобится мас- штабная переделка. Предложу несколько вариантов действий при обнаружении пожирателей процессорного времени: делегировать задачу пулу Python-процессов; делегировать задачу внешней очереди задач; переписать часть кода на Cython, C, Rust или другом языке, который ком- пилируется в машинный код и имеет интерфейс к Python/C API, предпо- чтительно с освобождением GIL; решить, что вы можете позволить себе падение производительности и ничего не делать, но запротоколировать это решение, чтобы было про- ще вернуться к нему позже. Как работает и как не работает асинхронность  765\n--- Страница 765 ---\nРешение о выборе внешней очереди задачи и интеграции с ней следует при- нимать в самом начале проекта, чтобы все члены команды без колебаний ис- пользовали ее в случае необходимости. Последний вариант – ничего не делать – попадает в категорию технического долга (https://en.wikipedia.org/wiki/Technical_debt). Конкурентное программирование – чрезвычайно увлекательная тема, и я мог бы написать еще много чего. Но она не является центральной для этой книги, а эта глава и так уже получилась одной из самых длинных, так что я за- кругляюсь. резюме Проблема всех обычных подходов к асинхронному программированию в том, что они предлагают все или ничего. Вам придется переписать весь код, чтобы нигде ничего не блокировалось, иначе вы просто зря потрати- те время. – Альваро Видела и Джейсон Дж. У. Уильямс, «RabbitMQ in Action» Я выбрал этот эпиграф по двум причинам. На верхнем уровне он напомина- ет нам избегать блокирования цикла событий, делегируя медленные задачи другой единице выполнения – от простого потока до распределенной очереди задач. На нижнем уровне он предупреждает: стоит написать первое async def, как в программе неизбежно будут появляться все новые и новые async def, await, async with и async for. И внезапно использование неасинхронных библиотек ста- новится проблемой. После простых примеров вращающегося индикатора в главе 19 мы здесь со- средоточились на асинхронном программировании с применением платфор- менных сопрограмм. Мы начали со скрипта проверки доменных имен blogdom. py, а затем познакомились с понятием объектов, допускающих ожидание. Читая исходный код скрипта flags_asyncio.py, мы встретились с первым примером асинхронного контекстного менеджера. Продолжая исследование вариантов программы загрузки флагов, мы ввели в рассмотрение две мощные функции: генератор asyncio.as_completed и сопро- грамму loop.run_in_executor . Мы также познакомились с идеей семафора и при- менили его, чтобы ограничить количество конкурентных операций загрузки – такого поведения ожидают от добропорядочных HTTP-клиентов. Серверное асинхронное программирование было представлено примерами mojifinder: на основе веб-службы FastAPI и скрипта tcp_mojifinder.py – в послед- нем использовалась только библиотека asyncio и протокол TCP. Асинхронные итераторы и итерируемые объекты стали следующей крупной темой, которой посвящены разделы о конструкции async for, асинхронной кон- соли Python, асинхронных генераторах, асинхронных генераторных выраже- ниях и асинхронных включениях. Последний пример в этой главе – скрипт blogdom.py, переписанный с приме- нением каркаса Curio с целью продемонстрировать, что асинхронные средства Python не привязаны к пакету asyncio. Curio также иллюстрирует концепцию структурной конкурентности, которая, возможно, будет принята всей индуст- рией и позволит сделать конкурентный код понятнее.766  Асинхронное программирование\n--- Страница 766 ---\nНаконец, в разделе «Как работает и как не работает асинхронность» и его подразделах мы обсудили, чем привлекает асинхронное программировани- ие, развечали миф о «системах, ограниченных вводом-выводом», и дали ре- комендации о том, что делать с неизбежными в любой программе счетными частями. дОпО лнительная литература Основной доклад Дэвида Бизли на конференции PyOhio 2016 «Fear and Awaiting in Async» (https://www.youtube.com/watch?v=E-1Y4kSsAFc) – фантастиче- ское, приправленное живым кодом введение в потенциал языковых средств, открывшийся в результате добавления Юрием Селивановым ключевых слов async и await в версию Python 3.5. В одном месте Бизли сетует, что await нельзя использовать в списковых включениях, но эта проблема была решена Селива- новым в документе PEP 530 «Asynchronous Comprehensions» (https://peps.python. org/pep-0530/) и реализована в Python 3.6 в том же году. Если не считать этого момента, все остальное в докладе Бизли не привязано ко времени, поскольку он демонстрирует, как асинхронные объекты, описанные в этой главе, рабо- тают вообще без поддержки каркаса – нужна лишь простая функция run, кото - рая приводит в действие сопрограммы с помощью вызова .send(None) . Только в самом конце Бизли представляет проект Curio ( https://github.com/dabeaz/curio), который он начал в том же году в качестве эксперимента, чтобы посмотреть, насколько далеко можно зайти в асинхронном программировании, не имея фундамента в виде обратных вызовов и будущих объектов, а пользуясь только сопрограммами. Как выяснилось, зайти можно очень далеко, и это демонстри- рует эволюция Curio и последующее создание Trio ( https://trio.readthedocs.io/en/ stable/) Натаниэлем Дж. Смитом. В документации по Curio есть дополнитель- ные ссылки на выступления Бизли по этому предмету. Помимо Trio Натаниэл Дж. Смит написал две глубокие статьи в блоге, кото- рые я горячо рекомендую: «Some thoughts on asynchronous API design in a post- async/await world» (https://vorpus.org/blog/some-thoughts-on-asynchronous-api-design- in-a-post-asyncawait-world/), в которой сравнивается дизайн Curio и asyncio, и «Notes on structured concurrency, or: Go statement considered harmful» (https:// vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/) о структурной конкурентности. Смит также дал развернутый и весьма инфор- мативный ответ на вопрос «What is the core difference between asyncio and trio?» (https://stackoverlow.com/questions/4948-2969/what-is-the-core-difference-between- asyncio-and-trio) на сайте StackOverflow. Для желающих узнать больше о пакете asyncio я уже упоминал лучшие из- вестные мне на момент написания этой главы ресурсы: официальная доку - ментация (https://docs.python.org/3/library/asyncio.html) после знаменательной переделки (https://bugs.python.org/issue33649), предпринятой Юрием Селивано- вым в 2018 году, и книга Калеба Хэттинга «Using Asyncio in Python» (O’Reilly). В официальной документации обязательно прочитайте раздел «Разработка с применением asyncio» (https://docs.python.org/3/library/asyncio-dev.html), где опи- сан отладочный режим asyncio, а также обсуждаются типичные ошибки и под- водные камни и как их избежать. Дополнительная литература  767\n--- Страница 767 ---\nВполне доступное 30-минутное введение в асинхронное программирова- ние вообще и с применением asyncio в частности имеется в ролике Мигуэля Гринберга «Asynchronous Python for the Complete Beginner» (https://www.youtube. com/watch?v=iG6fr81xHKA), представленном на конференции PyCon 2017. Из еще одного замечательного введения, «Demystifying Python’s Async and Await Keywords» (https://www.youtube.com/watch?v=F19R_M4Nay4), представленного Майклом Кеннеди, я среди прочего узнал о библиотеке unsync ( https://asherman. io/projects/unsync.html), которая предоставляет декоратор для делегирования выполнения сопрограмм, функций, ограниченных вводом-выводом, и счет - ных функций модулям asyncio, threading или multiprocessing – в зависимости от потребности. На конференции EuroPython 2019 Линн Рут, возглавляющая глобальное со- общество PyLadies, выступила с блестящей презентацией «Advanced asyncio: Solving Real-world Production Problems» (https://m.youtube.com/watch?v=sW76- pRkZk8), в основу которой лег ее опыт использования Python во время работ инженером в штате компании Spotify. В 2020 году Лукаш Ланга записал серию видео, посвященных asyncio, на- чинающуюся с «Learn Python’s AsyncIO #1 – The Async Ecosystem» (https://www. youtube.com/watch?v=Xbl7XjFYsN4). Ланга также сделал превосходный ролик «AsyncIO + Music» (https://www.youtube.com/watch?v=02CLD-42VdI) для конферен- ции PyCon 2020, в котором не только показано применение библиотеки asyncio к очень конкретной событийно-ориентированной предметной области, но и объясняется вся ее архитектура снизу доверху. Еще одна область, в которой событийно-ориентированное программи- рование занимает ведущие позиции, – встраиваемые системы. Именно по- этому Дамьен Джордж добавил поддержку async/await в свой интерпретатор MicroPython (https://micropython.org/) для микроконтроллеров. На конференции PyCon Australia 2018 Мэтт Трентини продемонстрировал библиотеку uasyncio (https://docs.micropython.org/en/latest/library/uasyncio.html), подмножество asyncio, которая вошла в стандартную библиотеку MicroPython. Если вам интересны рассуждения об асинхронном программировании в Python на верхнем уровне, ознакомьтесь со статьей «Python async frameworks – Beyond developer tribalism» (https://www.encode.io/articles/python-async-frameworks- beyond-developer-tribalism) в блоге Тома Кристи. Наконец, я рекомендую статью Боба Нистрёма «What Color Is Your Function?», в которой обсуждаются несовместимые модели выполнения обычных и асин- хронных функций (сопрограмм) в JavaScript, Python, C# и других языках. Спой- лер: Нистрём приходит к выводу, что правильно все сделано в языке Go, где все функции одного цвета. Мне нравится эта особенность Go. Но я также думаю, что у Натаниэля Дж. Смита были резоны для написания статьи «Go statement considered harmful» (https://vorpus.org/blog/notes-on-structured-concurrency-or-go- statement-considered-harmful/). Ничто в мире не совершенно, а конкурентное программирование – вообще штука сложная.768  Асинхронное программирование\n--- Страница 768 ---\nПоговорим Как медленная функция чуть не подпортила тесты производительности uvloop В 2016 году Юрий Селиванов выпустил uvloop ( https://github.com/MagicStack/ uvloop), «быструю совместимую по интерфейсу замену циклу событий asyncio». Тесты производительности, представленные Селивановым в статье, анонсирующей библиотеку, очень впечатляли. Он писал: «Она по крайней мере в 2 раза бы- стрее nodejs, gevent и многих других асинхронных каркасов на Python. Про- изводительность asyncio на основе uvloop близка к производительности про- грамм на Go». Однако автор не скрывает, что uvloop может сравняться с производительно- стью Go при двух условиях: 1. Go сконфигурирован с одним потоком. В результате среда выполнения Go ведет себя аналогично asyncio: конкурентность достигается за счет нескольких сопрограмм, управляемых циклом событий, и все они рабо- тают в одном потоке1. 2. В коде Python 3.5 используется не только uvloop, но и httptools ( https:// github.com/MagicStack/httptools). Селиванов объясняет, что написал httptools после тестирования производи- тельности uvloop в сочетании с aiohttp ( https://docs.aiohttp.org/en/stable/) – одной из первых полнофункциональных библиотек HTTP, построенных на основе asyncio: Однако причиной низкой производительности aiohttp оказался вхо- дящий в нее синтаксический анализатор HTTP, настолько медленный, что уже не важно, насколько быстро работает базовая библиотека вво- да-вывода. Ради интереса мы написали интерфейс к Python для биб- лиотеки http-parser (написанная на С библиотека разбора HTTP для Node.js, первоначально разработанная для NGINX). Библиотека назы- вается httptools и доступна на Github и PyPI. А теперь подумайте вот о чем: тесты производительности HTTP, разрабо- танные Селивановым, включали простой эхо-сервер, написанный на разных языках с разными библиотеками, который нагружался с помощью инстру - мента эталонного тестирования wrk (https://github.com/wg/wrk). Большинство разработчиков назвали бы простой эхо-сервер «системой, ограниченной вво- дом-выводом», так? Но оказалось, что разбор HTTP-заголовков ограничен быстродействием процессора, а его реализация в aiohttp работала медленно, когда Селиванов прогонял свои тесты производительности в 2016 году. Как только написанная на Python функция начинала разбирать заголовки, цикл событий блокировался. Это влияние было настолько значительным, что Се- ливанов взял на себя дополнительный труд по написанию httptools. Без опти- мизации счетного кода весь выигрыш в производительности, достигаемый за счет более быстрого цикла событий, терялся. 1 Однопоточный режим подразумевался по умолчанию до выхода версии Go 1.5. А в предшествующие годы Go заслуженно заработал репутацию прекрасного языка для высококонкурентных сетевых систем. Еще одно свидетельство в пользу того, что для конкурентности не нужно ни несколько потоков, ни несколько процессорных ядер. Дополнительная литература  769\n--- Страница 769 ---\nСмерть от тысячи ран Представьте, что вместо простого эхо-сервера имеется сложная развиваю- щаяся система на Python, насчитывающая тысячи строк асинхронного кода и зависящая от многих внешних библиотек. Много лет назад меня попро- сили диагностировать проблемы производительности в такой системе. Она была написана на Python 2.7 с применением библиотеки Twisted (https:// twistedmatrix.com/trac/), во многих отношениях предшественницы самой asyncio. Python служил для построения фасада к пользовательскому веб-интерфейсу, интегрируя функциональность уже имевшихся библиотек и инструментов командной строки, написанных на других языках, но не предназначавшихся для конкурентного выполнения. Проект был амбициозным; он разрабатывался уже больше года, но до сих пор не дошел до стадии эксплуатации1. Со временем разработчики начали заме- чать, что производительность системы в целом снижается, и никак не могли найти, где затык. А произошло вот что: с каждой добавленной функцией новый счетный код замедлял цикл событий Twisted. Роль Python как связующего языка означала, что нужно разбивать данные и преобразовывать их из одного формата в дру - гой – и таких операций было много. Не было какого-то одного узкого места: проблема расползлась по бессчетному количеству небольших функций, ко- торые добавлялись в течение всего времени разработки. Чтобы исправить ситуацию, пришлось бы переосмыслить архитектуру системы, переписать массу кода, быть может, воспользоваться очередью задач, микросервисами или библиотеками, написанными на языках, более приспособленных к кон- курентному решению счетных задач. Инвесторы были не готовы вкладывать дополнительные деньги, и проект вскоре был свернут. Когда я рассказал эту историю Глифу Лефковицу, основателю проекта Twisted, он сказал, что один из его приоритетов в начале проекта, включающего асин- хронное программирование, – решить, какими инструментами пользоваться для вынесения счетных задач из цикла событий. Слова Глифа стали побуди- тельным мотивом для написания раздела «Как не попасть в ловушку счетных функций» выше. 1 Независимо от технических решений, это, наверное, была самая большая ошибка в проекте: заинтересованные стороны проигнорировали подход MVP – подготовить минимально работоспособный продукт (Minimum Viable Product) как можно скорее, а затем в постоянном темпе добавлять новые функции.770  Асинхронное программирование\n--- Страница 770 ---\nЧасть V Метапрограммирование",
      "debug": {
        "start_page": 718,
        "end_page": 770
      }
    },
    {
      "name": "Глава 22. Динамические атрибуты и свойства 772",
      "content": "--- Страница 771 --- (продолжение)\nГлава 22 Динамические атрибуты и свойства Ценность свойств заключается в том, что благодаря им можно совершен- но безопасно – и это даже рекомендуется – раскрывать атрибуты-данные как часть открытого интерфейса класса. – Мартелли, Равенскрофт, Холден, «Почему свойства важны»1 Атрибуты-данные и методы в Python носят общее название «атрибуты»; ме- тод – это просто вызываемый атрибут. Помимо атрибутов-данных и методов, мы можем создавать еще свойства, позволяющие заменить открытые атрибу - ты-данные методами-акцессорами (т. е. методами чтения и установки), не из- меняя интерфейс класса. Это согласуется с принципом единообразного доступа: Все сервисы, предоставляемые модулем, должны быть доступны с помо- щью единообразной нотации, скрывающей механизм реализации: хране- ние или вычисление2. В Python есть несколько способов реализовать динамические атрибуты. В этой главе рассматриваются самые простые: декоратор @property и специаль- ный метод __getattr__ . Пользовательский класс, в котором имеется метод __getattr__ , может реали- зовать вариант динамических атрибутов, который я называю виртуальными атрибутами; они не объявлены в исходном коде класса и отсутствуют в экзем- пляре __dict__, но могут быть получены из какого-то другого места или вычис - лены «на лету», когда программа пытается прочитать несуществующий атри- бут, например obj.no_such_attr . Динамические атрибуты – вид метапрограммирования, обычно применя- емый авторами каркасов. Однако в Python базовая техника настолько проста, что любой человек может воспользоваться ими, даже для повседневных задач обработки данных. С нее мы и начнем эту главу. чтО нОвОг О в этОй главе Побудительным мотивом для большей части изменений в этой главе стало об- суждение декоратора @functools.cached_property (появившегося в Python 3.8) и ис - 1 Alex Martelli, Anna Ravenscroft, Steve Holden. Python in a Nutshell. 3-е изд. O’Reilly. С. 123. 2 Bertrand Meyer. Object-Oriented Software Construction. 2-е изд. С. 57.\nГлава 22 Динамические атрибуты и свойства Ценность свойств заключается в том, что благодаря им можно совершен- но безопасно – и это даже рекомендуется – раскрывать атрибуты-данные как часть открытого интерфейса класса. – Мартелли, Равенскрофт, Холден, «Почему свойства важны»1 Атрибуты-данные и методы в Python носят общее название «атрибуты»; ме- тод – это просто вызываемый атрибут. Помимо атрибутов-данных и методов, мы можем создавать еще свойства, позволяющие заменить открытые атрибу - ты-данные методами-акцессорами (т. е. методами чтения и установки), не из- меняя интерфейс класса. Это согласуется с принципом единообразного доступа: Все сервисы, предоставляемые модулем, должны быть доступны с помо- щью единообразной нотации, скрывающей механизм реализации: хране- ние или вычисление2. В Python есть несколько способов реализовать динамические атрибуты. В этой главе рассматриваются самые простые: декоратор @property и специаль- ный метод __getattr__ . Пользовательский класс, в котором имеется метод __getattr__ , может реали- зовать вариант динамических атрибутов, который я называю виртуальными атрибутами; они не объявлены в исходном коде класса и отсутствуют в экзем- пляре __dict__, но могут быть получены из какого-то другого места или вычис - лены «на лету», когда программа пытается прочитать несуществующий атри- бут, например obj.no_such_attr . Динамические атрибуты – вид метапрограммирования, обычно применя- емый авторами каркасов. Однако в Python базовая техника настолько проста, что любой человек может воспользоваться ими, даже для повседневных задач обработки данных. С нее мы и начнем эту главу. чтО нОвОг О в этОй главе Побудительным мотивом для большей части изменений в этой главе стало об- суждение декоратора @functools.cached_property (появившегося в Python 3.8) и ис - 1 Alex Martelli, Anna Ravenscroft, Steve Holden. Python in a Nutshell. 3-е изд. O’Reilly. С. 123. 2 Bertrand Meyer. Object-Oriented Software Construction. 2-е изд. С. 57.\n--- Страница 772 ---\nпользование @property в сочетании с @functools.cache (новшество в 3.9). Это по- влияло на код классов Record и Event в разделе «Вычисляемые свойства». Я так - же переработал код, применив оптимизацию, описанную в документе PEP 412 «Key-Sharing Dictionary» (https://peps.python.org/pep-0412/). Чтобы уделить больше внимания наиболее существенным средствам и со- хранить удобочитаемость кода, я убрал менее важный код: объединил старый класс DbRecord с Record, заменил shelve.Shelve на dict и удалил логику скачива- ния набора данных OSCON – теперь примеры читаются из локального файла, входящего в репозиторий кода на сопроводительном сайте (https://github.com/ fluentpython/example-code-2e). применение динамичеСких атриБут Ов для ОБраБО тки данных В примерах ниже мы воспользуемся динамическими атрибутами для обра- ботки данных в формате JSON, опубликованных издательством O’Reilly для конференции OSCON 2014. В примере 19.1 показаны четыре записи из этого набора1. Пример 22.1. Примеры записей из файла osconfeed.json; значения некоторых полей со- кращены { «Schedule»: { \"conferences\": [{\"serial\": 115 }], \"events\": [ { \"serial\": 34505, \"name\": \"Why Schools Don/t Use Open Source to Teach Programming\", \"event_type\": \"40-minute conference session\", \"time_start\": \"2014-07-23 11:30:00\", \"time_stop\": \"2014-07-23 12:10:00\", \"venue_serial\": 1462, \"description\": \"Aside from the fact that high school programming \", \"website_url\": \"http://oscon.com/oscon2014/public/schedule/detail/34505\", \"speakers\": [157509], \"categories\": [\"Education\"] } ], \"speakers\": [ { \"serial\": 157509, \"name\": \"Robert Lefkowitz\", \"photo\": null, \"url\": \"http://sharewave.com/\", \"position\": \"CTO\", \"affiliation\": \"Sharewave\", \"twitter\": \"sharewaveteam\", \"bio\": \"Robert /r0ml/ Lefkowitz is the CTO at Sharewave, a startup \" } ], 1 Конференция OSCON – O’Reilly Open Source Conference – пала жертвой пандемии COVID-19. Оригинального JSON-файла размером 744 КБ, который я использовал для этих примеров, по состоянию на 10 января 2021 года в сети не было. Его копию под названием osconfeed.json можно найти в репозитории кода к этой книге (https://github. com/fluentpython/example-code-2e/blob/master/22-dyn-attr-prop/oscon/data/osconfeed.json). Применение динамических атрибутов для обработки данных  773\n--- Страница 773 ---\n\"venues\": [ { \"serial\": 1462, \"name\": \"F151\", \"category\": \"Conference Venues\" } ] } } В примере 22.1 показаны четыре из 895 записей JSON-файла. Как видим, весь набор данных – это единственный JSON-объект с ключом «Schedule» , значе- нием которого является отображение с четырьмя ключами: «conferences» (кон- ференции), «events» (мероприятия), «speakers» (докладчики) и «venues» (места про- ведения). С каждым из четырех ключей ассоциирован список записей. В пол- ном наборе данных списки «events», «speakers» и «venues» содержат десятки и даже сотни записей, тогда как список «conferences» состоит всего из одной записи, по- казанной выше. В каждой записи имеется поле «serial», уникально идентифи- цирующее запись в пределах списка. Для исследования этого набора данных я воспользовался консолью Python, как показано в примере 22.2. Пример 22.2. Интерактивное изучение osconfeed.json >>> import json >>> with open('data/osconfeed.json') as fp: feed = json.load(fp)  >>> sorted(feed['Schedule'].keys())  ['conferences', 'events', 'speakers', 'venues'] >>> for key, value in sorted(feed['Schedule'].items()): print(f'{len(value):3} {key}')  1 conferences 484 events 357 speakers 53 venues >>> feed['Schedule']['speakers'][-1]['name']  'Carina C. Zona' >>> feed['Schedule']['speakers'][-1]['serial']  141590 >>> feed['Schedule']['events'][40]['name'] 'There *Will* Be Bugs' >>> feed['Schedule']['events'][40]['speakers']  [3471, 5199]  Загрузить как словарь dict, содержащий вложенные словари и списки со строковыми и целыми значениями.  Вывести все четыре коллекции записей внутри «Schedule» .  Вывести счетчики записей в каждой коллекции.  Обойти вложенные словари и списки, чтобы получить имя последнего до- кладчика.  Получить порядковый номер этого докладчика.  У каждого мероприятия есть список 'speakers' , содержащий нуль или более порядковых номеров докладчик ов.774  Динамические атрибуты и свойства\n--- Страница 774 ---\nИсследование JSON-подобных данных с динамическими атрибутами Пример 22.2 достаточно прост, но синтаксис feed['Schedule']['events'][40]['name'] слишком громоздкий. В JavaScript то же самое можно было бы записать в виде feed.Schedule.events[40].name . На Python нетрудно реализовать похожий на словарь класс, который ведет себя подобным образом, – в сети нет недостатка в приме- рах1. Я написал класс FrozenJSON , который проще большинства готовых, т. к. под- держивает только чтение; он предназначен исключительно для исследования данных. Однако он рекурсивный и автоматически обрабатывает вложенные отображения и списки. В примере 22.3 демонстрируется использование класса FrozenJSON , а в приме- ре 22.4 приведен его исходный код. Пример 22.3. Класс FrozenJSON из примера 22.4 позволяет читать атрибуты, например name, и вызывать методы, например .keys() и .items() >>> import json >>> raw_feed = json.load(open('data/osconfeed.json')) >>> feed = FrozenJSON(raw_feed)  >>> len(feed.Schedule.speakers)  357 >>> feed.keys() dict_keys(['Schedule']) >>> sorted(feed.Schedule.keys())  ['conferences', 'events', 'speakers', 'venues'] >>> for key, value in sorted(feed.Schedule.items()):  print(f'{len(value):3} {key}') 1 conferences 484 events 357 speakers 53 venues >>> feed.Schedule.speakers[-1].name  'Carina C. Zona' >>> talk = feed.Schedule.events[40] >>> type(talk)  <class 'explore0.FrozenJSON'> >>> talk.name 'There *Will* Be Bugs' >>> talk.speakers  [3471, 5199] >>> talk.flavor  Traceback (most recent call last): KeyError: 'flavor'  Построить экземпляр FrozenJSON по словарю raw_feed, содержащему вложен- ные словари и списки.  FrozenJSON допускает обход вложенных словарей с помощью нотации атри- бутов; здесь мы получаем длину списка докладчиков. 1 Два примера: AttrDict (https://pypi.python.org/pypi/attrdict) и addict (https://pypi.python.org/ pypi/addict). Применение динамических атрибутов для обработки данных  775\n--- Страница 775 ---\n Методы скрытых за объектом FrozenJSON словарей также доступны, напри- мер метод .keys() возвращает имена коллекций.  С помощью метода items() мы можем извлечь имена коллекций записей и их содержимое, чтобы показать длину каждого значения.  Список, например feed.Schedule.speakers , остается списком, но те объек - ты внутри него, которые являются отображениями, преобразуются в тип FrozenJSON .  Элемент 40 списка events был объектом типа JSON; теперь это экземпляр класса FrozenJSON .  С каждым мероприятием связан список speakers, содержащий порядковые номера докладчиков.  При попытке прочитать несуществующий атрибут возбуждается исключе- ние KeyError, а не AttributeError , как обычно. Краеугольным камнем класса FrozenJSON является метод __getattr__ , которым мы уже пользовались в примере класса Vector из раздела «Vector, попытка № 3: доступ к динамическим атрибутам» главы 12, чтобы обращаться к компонен- там вектора по буквам – v.x, v.y, v.z и т. д. Напомним, что интерпретатор вы- зывает специальный метод __getattr__ , только если обычный поиск атрибута завершается неудачно (т. е. именованный атрибут не удается найти ни в эк - земпляре, ни в классе, ни в его суперклассах). Последняя строка в примере 22.3 выявляет небольшой дефект моего кода: попытка чтения несуществующего атрибута должна бы возбуждать исключе- ние AttributeError , а не KeyError, как у меня. Я даже реализовал такую обработ - ку ошибок, но при этом метод __getattr__ стал вдвое длиннее, и это отвлекало внимание от той важной логики, которую я стремился продемонстрировать. Учитывая, что пользователи, вероятно, знают, что FrozenJSON состоит из отобра- жений и списков, я полагаю, что ошибка KeyError никого не смутит. Пример 22.4. explore0.py: преобразование набора данных из формата JSON в объект FrozenJSON , содержащий вложенные объекты FrozenJSON , списки и значения примитив- ных типов from collections import abc class FrozenJSON: \"\"\"Допускающий только чтение фасад для навигации по JSON-подобному объекту с применением нотации атрибутов \"\"\" def __init__(self, mapping): self.__data = dict(mapping)  def __getattr__(self, name):  try: return getattr(self.__data, name)  except AttributeError: return FrozenJSON.build(self.__data[name])  def __dir__(self):  return self.__data .keys() @classmethod776  Динамические атрибуты и свойства\n--- Страница 776 ---\ndef build(cls, obj):  if isinstance(obj, abc.Mapping):  return cls(obj) elif isinstance(obj, abc.MutableSequence):  return [cls.build(item) for item in obj] else: return obj  Построить объект dict по аргументу mapping. Тем самым мы проверяем, что получили словарь (или нечто, что можно преобразовать в словарь). Два знака подчеркивания в начале __data говорят, что это закрытый атрибут.  Метод __getattr__ вызывается, только когда не существует атрибута с име- нем name.  Если имени name соответствует какой-то атрибут словаря __data, возвращаем его. Так обрабатываются вызовы методов типа feed.keys() : метод keys явля- ется атрибутом словаря __data.  В противном случае получаем элемент с ключом name из self.__data и возвра- щаем результат вызова для него метода FrozenJSON.build()1.  Это альтернативный конструктор, типичное применение декоратора @classmethod .  Если obj – отображение, строим по нему объект FrozenJSON . Это пример гуси- ной типизации (смотрите раздел «Гусиная типизация» главы 13, если под- забыли).  Если это экземпляр MutableSequence , то он должен быть списком2, поэтому строим список, рекурсивно передавая каждый элемент obj методу .build().  Если это не dict и не list, возвращаем элемент без изменения. Экземпляр FrozenJSON имеет закрытый атрибут экземпляра __data, хранящийся под именем _FrozenJSON__data , как было объяснено в разделе «Закрытые и “за- щищенные” атрибуты в Python» главы 11. Попытка получить атрибут с любым другим именем приводит к вызову __getattr__ . Этот метод сначала смотрит, есть ли в словаре self.__data атрибут (не ключ!) с таким именем; это позволяет эк- земплярам FrozenJSON обрабатывать методы самого класса dict, например items, делегируя работу методу self.__data.items() . Если в self.__data нет атрибута с име- нем name, то __getattr__ использует name как ключ, читает из self.__dict элемент с таким ключом и передает его методу FrozenJSON.build . Это позволяет обходить вложенные структуры в JSON-данных, поскольку каждое вложенное отображе- ние преобразуется в новый экземпляр FrozenJSON методом класса build. Отметим, что исходный набор данных не кешируется и не трансформиру - ется. При его обходе вложенные структуры данных всякий раз преобразуются заново в тип FrozenJSON . Но при таком размере набора это приемлемо, да и наш скрипт предназначен только для исследования и преобразования данных. 1 Именно в этой строке может возникнуть исключение KeyError: в выражении self.__ data[name] . Его следует обработать и подменить исключением AttributeError , посколь- ку такого исключения вызывающая программа ожидает от __getattr__ . Прилежному читателю предлагается написать этот код в качестве упражнения. 2 Источником данных является объект типа JSON, а он поддерживает только два типа коллекций: dict и list. Применение динамических атрибутов для обработки данных  777\n--- Страница 777 ---\nЛюбой скрипт, который генерирует или эмулирует динамические атрибу - ты с именами, полученными из произвольного источника, должен помнить об одной проблеме: ключи, хранящиеся в исходных данных, могут не удовлет - ворять правилам образования имен атрибутов. В следующем разделе мы за- ймемся этой проблемой. Проблема недопустимого имени атрибута У класса FrozenJSON есть ограничение: в нем не предусмотрена специальная об- работка имен атрибутов, являющихся ключевыми словами Python. Например, построив объект вида: >>> student = FrozenJSON({'name': 'Jim Bo', 'class': 1982}) мы не сможем прочитать атрибут grad.class, т. к. class – зарезервированное сло- во в Python: >>> student.class File \"<stdin>\", line 1 student.class ^ SyntaxError: invalid syntax Конечно, можно сделать так: >>> getattr(student, 'class') 1982 Но идея класса FrozenJSON заключалась в том, чтобы предоставить удобный доступ к данным, поэтому лучше проверять, является ли ключ отображения, переданного методу FrozenJSON.__init__ , зарезервированным словом, и если да, то добавлять в конец символ _, чтобы атрибут можно было прочитать так: >>> student.class_ 1982 Для этого достаточно заменить однострочный метод __init__ из приме- ра 22.4 кодом, показанным ниже. Пример 22.5. explore1.py: добавление _ в имена атрибутов, являющиеся зарезервиро- ванными словами Python def __init__(self, mapping): self.__data = {} for key, value in mapping.items(): if keyword.iskeyword(key):  key += '_' self.__data[key] = value  Функция keyword.iskeyword(…) – именно то, что нам нужно; для ее использова- ния необходимо импортировать модуль keyword. Похожая проблема может возникнуть, если ключ в JSON-данных не является допустимым идентификатором Python:778  Динамические атрибуты и свойства\n--- Страница 778 ---\n>>> x = FrozenJSON({'2be':'or not'}) >>> x.2be File \"<stdin>\", line 1 x.2be ^ SyntaxError: invalid syntax Такие проблематичные ключи легко выявить в Python 3, где класс str предо- ставляет метод s.isidentifier() , который сообщает, является ли s допустимым идентификатором с точки зрения грамматики языка Python. Но преобразо- вание ключа, не являющегося допустимым идентификатором, в допустимое имя атрибута – нетривиальная задача. Возможное решение – реализовать ме- тод __getitem__ , чтобы разрешить доступ к атрибуту с помощью нотации вида x['2be']. Для простоты я проигнорирую этот случай. Уделив внимание именам динамических атрибутов, обратимся к другой важной особенности класса FrozenJSON : логике метода класса build. FrozenJSON.build вызывается из __getattr__ для получения объектов разных типов в зависимости от значения обрабатываемого атрибута: вложенные структуры преобразуются в экземпляры FrozenJSON или списки экземпляров FrozenJSON . Как мы увидим ниже, ту же логику можно было бы реализовать не в методе класса, а в специальном методе __new__. Гибкое создание объектов с помощью метода __new__ Мы часто называем __init__ конструктором, но это только потому, что поза- имствовали терминологию из других языков. В Python метод __init__ получает self в качестве первого аргумента, поэтому к моменту вызова __init__ интер- претатором объект уже существует. Кроме того, __init__ не может ничего воз- вращать. Так что в действительности это инициализатор, а не конструктор. Когда класс вызывается для создания экземпляра, Python вызывает специ- альный метод класса __new__. Хотя это метод класса, обрабатывается он не так, как другие: к нему не применяется декоратор @classmethod . Python принимает экземпляр, возвращенный __new__, и передает его в качестве первого аргумента self методу __init__. Мы редко пишем __new__ самостоятельно, потому что реа- лизации, унаследованной от object, обычно достаточно. При необходимости метод __new__ может вернуть экземпляр другого класса. В таком случае интерпретатор не вызывает __init__. Иными словами, логика создания объекта в Python описывается следующим псевдокодом: # псевдокод конструирования объекта def make(the_class, some_arg): new_object = the_class.__new__(some_arg) if isinstance(new_object, the_class): the_class.__init__(new_object, some_arg) return new_object # следующие предложения приблизительно эквивалентны x = Foo('bar') x = make(Foo, 'bar') Применение динамических атрибутов для обработки данных  779\n--- Страница 779 ---\nВ примере 22.6 показан вариант класса FrozenJSON , в котором логика метода класса build перенесена в метод __new__. Пример 22.6. explore2.py: использование __new__ вместо build для конструирования но- вых объектов, которые могут быть или не быть экземплярами FrozenJSON from collections import abc import keyword class FrozenJSON: \"\"\"Допускающий только чтение фасад для навигации по JSON-подобному объекту с применением нотации атрибутов \"\"\" def __new__(cls, arg):  if isinstance(arg, abc.Mapping): return super().__new__(cls)  elif isinstance(arg, abc.MutableSequence):  return [cls(item) for item in arg] else: return arg def __init__(self, mapping): self.__data = {} for key, value in mapping.items(): if keyword.iskeyword(key): key += '_' self.__data[key] = value def __getattr__(self, name): try: return getattr(self.__data, name) except AttributeError: return FrozenJSON(self.__data[name])  def __dir__(self): return self.__data.keys()  Будучи методом класса, __new__ получает в качестве первого аргумента сам класс, а остальные аргументы – те же, что получает __init__, за исключени- ем self.  По умолчанию работа делегируется методу __new__ суперкласса. В данном случае мы вызываем метод __new__ из базового класса object, передавая ему FrozenJSON в качестве единственного аргумента.  Оставшаяся часть __new__ ничем не отличается от прежнего метода build.  Здесь раньше вызывался метод FrozenJSON.build , а теперь мы просто вызыва- ем класс FrozenJSON , а Python обрабатывает это как вызов FrozenJSON.__new__ . Метод __new__ получает в качестве первого аргумента класс, потому что обычно создается экземпляр именно этого класса. Таким образом, при вы- зове super().__new__(cls) из FrozenJSON.__new__ в действительности вызывается object.__new__(FrozenJSON) , а объект, построенный классом object, является экзем- пляром класса FrozenJSON . Атрибут __class__ нового экземпляра содержит ссыл-780  Динамические атрибуты и свойства\n--- Страница 780 ---\nку на FrozenJSON , хотя собственно конструирование производилось методом object.__new__ , реализованным на C в недрах интерпретатора. Структура набора данных OSCON не очень пригодна для интерактивного ис- следования. Например, для мероприятия с индексом 40, озаглавленного 'There *Will* Be Bugs' , зарегистрировано два докладчика, 3471 и 5199, но найти их нелег - ко, потому что это порядковые номера, а не индексы в списке Schedule.speakers . Чтобы получить запись о докладчике, придется выполнить линейный поиск по списку, пока не отыщется подходящий порядковый номер. Наша следующая задача – изменить структуру данных и автоматизировать извлечение связан- ных записей. вычиС ляемые СвОйС тва С декоратором @property мы впервые познакомились в главе 11, в разделе «Хе- шируемый класс Vector2d». В примере 11.7 я использовал два свойства Vector2d просто для того, чтобы сделать атрибуты x и y доступными только для чтения. Здесь мы рассмотрим свойства, которые вычисляют значения, и это подведет нас к вопросу о том, как кешировать такие значения. Записи в списке 'events' JSON-данных OSCON содержат последовательные целые числа, указывающие на записи в списках 'speakers' и 'venues'. Напри- мер, ниже показана запись о выступлении на конференции (описание со- кращено): { \"serial\": 33950, \"name\": \"There *Will* Be Bugs\", \"event_type\": \"40-minute conference session\", \"time_start\": \"2014-07-23 14:30:00\", \"time_stop\": \"2014-07-23 15:10:00\", \"venue_serial\": 1449, \"description\": \"If you're pushing the envelope of programming \", \"website_url\": \"http://oscon.com/oscon2014/public/schedule/detail/33950\", \"speakers\": [3471, 5199], \"categories\": [\"Python\"] } Мы реализуем класс Event со свойствами venue и speakers, которые будут авто- матически возвращать связанные данные, т. е. «разыменовывать» порядковый номер. В примере 22.7 показано желаемое поведение для заданного экземпля- ра Event. Пример 22.7. Чтение venue и speakers возвращает объекты Record >>> event  <Event 'There *Will* Be Bugs'> >>> event.venue  <Record serial=1449> >>> event.venue.name  'Portland 251' >>> for spkr in event.speakers:  print(f'{spkr.serial}: {spkr.name}') 3471: Anna Martelli Ravenscroft 5199: Alex Martelli Вычисляемые свойства  781\n--- Страница 781 ---\n Если имеется экземпляр Event …  … то чтение event.venue возвращает объект Record вместо порядкового номера.  Теперь легко получить название venue.  Свойство event.speakers возвращает список экземпляров Record. Как обычно, будем разрабатывать код по шагам и начнем с класса Record и функции, которая читает JSON-данные и возвращает dict, содержащий эк- земпляры Record. Шаг 1: создание управляемого данными атрибута В примере 22.8 показан тест, которым мы будем руководствоваться на первом шаге. Пример 22.8. Тест для разработки schedule_v1.py (из примера 22.9) >>> records = load(JSON_PATH)  >>> speaker = records['speaker.3471']  >>> speaker  <Record serial=3471> >>> speaker.name, speaker.twitter  ('Anna Martelli Ravenscroft', 'annaraven')  Загрузить в dict JSON-данные функцией load.  Ключами records являются строки, образованные типом записи и порядко- вым номером.  speaker – экземпляр класса Record, определенного в примере 22.9.  Поля первичных JSON-данных можно получить в виде атрибутов экзем- пляра Record. Код скрипта schedule_v1.py приведен в примере 22.9. Пример 22.9. schedule_v1.py: реорганизация данных о мероприятиях OSCON import json JSON_PATH = 'data/osconfeed.json' class Record: def __init__(self, **kwargs): self.__dict__.update(kwargs)  def __repr__(self): return f'<{self.__class__.__name__} serial={self.serial!r}>'  def load(path=JSON_PATH): records = {}  with open(path) as fp: raw_data = json.load(fp)  for collection, raw_records in raw_data['Schedule'].items():  record_type = collection[:-1]  for raw_record in raw_records: key = f'{record_type}.{raw_record[\"serial\"]}'  records[key] = Record(**raw_record)  return records782  Динамические атрибуты и свойства\n--- Страница 782 ---\n Стандартная идиома для построения экземпляра, атрибуты которого соз- даются из именованных аргументов (подробности см. ниже).  Использовать поле serial, чтобы построить представление Record, показан- ное в примере 22.8.  Метод load в конечном итоге вернет словарь экземпляров Record.  Разобрать JSON и вернуть объекты Python: списки, словари, числа и т. д.  Обойти все четыре списка верхнего уровня: 'conferences' , 'events', 'speakers' и 'venues'.  record_type – имя списка без последнего символа, т. е. speakers становится speaker. В Python ≥ 3.9 то же самое можно сделать явно, написав collection. removesuffix('s') – см. документ PEP 616 «String methods to remove prefixes and suffixes» (https://peps.python.org/pep-0616/).  Построить ключ в формате 'speaker.3471' .  Создать экземпляр Record и сохранить его в словаре records под ключом key. В методе Record.__init__ иллюстрируется распространенный при програм- мировании на Python прием. Напомню, что в словаре __dict__ объекта хранят - ся атрибуты – если только в классе не объявлен атрибут __slots__ (см. раздел «Экономия памяти с помощью атрибута класса __slots__» главы 11). Поэтому копирование в __dict__ отображения – быстрый способ создать сразу несколько атрибутов (bunch of attributes) экземпляра1. В зависимости от приложения в классе Record, возможно, при- дется иметь дело с ключами, которые не являются допустимыми именами атрибутов, как мы видели в разделе «Проблема недо- пустимого имени атрибута» выше. Обсуждение этой проблемы отвлекло бы нас от главной идеи данного примера, да и в наборе данных, который мы читаем, такой проблемы нет. Определение класса Record в примере 22.9 настолько простое, что вы, навер- ное, недоумеваете, почему мы не использовали его раньше вместо более слож - ного класса FrozenJSON . Причины две. Во-первых, FrozenJSON рекурсивно преоб- разует вложенные отображения и списки; в классе Record это не нужно, потому что в преобразованном наборе данных нет отображений, вложенных в другие отображения или списки. Записи могут содержать только строки, целые числа, списки строк и списки целых чисел. Вторая причина: FrozenJSON предоставляет доступ к внутреннему словарю атрибутов __data, – который мы использовали для вызова методов, например keys, – а здесь эта функциональность не нужна. В стандартной библиотеке Python есть классы, аналогичные нашему классу Record, экземпляры которых содержат произ- вольный набор атрибутов, переданных __init__ в виде име- нованных аргументов: types.SimpleNamespace (https://docs.python. org/3/library/ types.html#types.SimpleNamespace), argparse.Namespace (https://docs.python.org/3/library/argparse.html#argparse.Namespace) 1 Кстати, Bunch – имя класса, который Алекс Мартелли в 2001 году использовал при пуб ликации этого рецепта, названного им «The simple but handy collector of a bunch of named stuff class» (https://github.com/ActiveState/code/tree/master/recipes/Python/52308_ simple_but_handy_collector_bunch_named_stuff). Вычисляемые свойства  783\n--- Страница 783 ---\nи multiprocessing.Namespace (https://docs.python.org/3/library/ multiprocessing.html#multiprocessing.managers.Namespace). Я написал более простой класс Record, чтобы проиллюстрировать существо этой идеи: обновление атрибута __dict__ экземпляра в методе __init__. После проделанной реорганизации набора данных мы можем расширить класс Record, так чтобы он автоматически выбирал записи venue и speaker, на которые ссылается запись event. Для реализации этой идеи мы воспользуемся свойствами. Шаг 2: выборка связанных записей с помощью свойств Цель следующей версии такова: пусть имеется запись event, тогда чтение ее атрибута venue должно возвращать Record. Примерно то же самое делает Django ORM, когда мы обращаемся к полю models.ForeignKey : вместо ключа мы получаем связанный объект модели. Начнем со свойства venue. В примере 22.10 показана часть консольного сеанса. Пример 22.10. Извлечение из тестов для файла schedule_v2.py >>> event = Record.fetch('event.33950')  >>> event  <Event 'There *Will* Be Bugs'> >>> event.venue  <Record serial=1449> >>> event.venue.name  'Portland 251' >>> event.venue_serial  1449  Статический метод Record.fetch извлекает экземпляр Record или Event из на- бора данных.  Отметим, что event – экземпляр класса Event.  Доступ к атрибуту event.venue возвращает экземпляр Record.  Теперь легко найти название места проведения event.venue .  У экземпляра Event также имеется атрибут venue_serial , прочитанный из JSON-данных. Event – подкласс Record, в который добавлено поле venue для получения связан- ных записей и специализированный метод __repr__. Приведенный в этом разделе код находится в модуле schedule2.py в репо- зитории кода к этой книге (https://github.com/fluentpython/example-code-2e/blob/ master/22-dyn-attr-prop/oscon/schedule_v2.py). Поскольку код занимает около 60 строк, я разобью его на части и начну с улучшенного класса Record. Пример 22.11. schedule_v2.py: класс Record с новым методом fetch import inspect  import json JSON_PATH = 'data/osconfeed.json'784  Динамические атрибуты и свойства\n--- Страница 784 ---\nclass Record: __index = None  def __init__(self, **kwargs): self.__dict__.update(kwargs) def __repr__(self): return f'<{self.__class__.__name__} serial={self.serial!r}>' @staticmethod  def fetch(key): if Record.__index is None:  Record.__index = load() return Record.__index[key]   inspect будет вызываться из метода load, показанного в примере 22.13.  В закрытом атрибуте класса __index будет храниться ссылка на dict, возвра- щенный методом load.  fetch сделан статическим методом, чтобы было понятно, что его действие не зависит от экземпляра или класса, от имени которого он вызывается.  Заполнить Record.__index , если необходимо.  Нужно, чтобы извлечь запись с заданным ключом key. Это пример, когда использование декоратора staticmethod име- ет смысл. Метод fetch всегда применяется к атрибуту класса Record.__index , даже если вызван из подкласса, как, например, в случае Event.fetch() , который мы рассмотрим ниже. Сделав его методом класса, мы только запутали бы читателя, потому что первый аргумент cls не использовался бы. Теперь рассмотрим использование свойства в классе Event (пример 22.12). Пример 22.12. schedule_v2.py: класс Event class Event(Record):  def __repr__(self): try: return f'<{self.__class__.__name__} {self.name!r}>'  except AttributeError: return super().__repr__() @property def venue(self): key = f'venue.{self.venue_serial}' return self.__class__.fetch(key)   Класс Event расширяет Record.  Если в экземпляре есть атрибут name, включаем его в строковое представление. В противном случае делегируем методу __repr__, унаследованному от Record.  Свойство venue строит ключ key по атрибуту venue_serial и передает его мето- ду класса fetch, унаследованному от Record (зачем используется self.__class__ , объяснено ниже). Вычисляемые свойства  785\n--- Страница 785 ---\nВо второй строке метода venue в примере 22.12 возвращается self.__class__. fetch(key) . Почему бы не написать просто self.fetch(key) ? Это более простое вы- ражение работает для набора данных OSCON, потому что в нем нет записи о мероприятии с ключом 'fetch'. Но если бы в записи о мероприятии такой ключ был, то в соответствующем экземпляре Event выражение self.fetch было бы значением этого поля, а не ссылкой на метод класса fetch, унаследованный классом Event от Record. Это тонкая ошибка, которая легко могла бы остаться не- замеченной при тестировании, потому что зависит от набора данных. При создании имен атрибутов экземпляра из данных всегда су- ществует риск ошибок вследствие маскирования атрибутов клас - са (например, методов) или потери данных из-за случайного перезаписывания уже существующих атрибутов экземпляра. Эта опасность является, пожалуй, основной причиной, по которой словари в Python по умолчанию не похожи на объекты JavaScript. Если бы класс Record больше походил на отображение, т. е. реализовывал ди- намический метод __getitem__ , а не __gettarr__ , то можно было бы не опасаться ошибок, вызванных маскированием или перезаписью. Пользовательское ото- бражение, наверное, является наиболее отвечающим духу Python способом реа лизации Record. Но если бы я пошел по этому пути, то у нас не было бы шанса поразмышлять о ловушках, подстерегающих нас при программировании ди- намических атрибутов. И последняя часть примера – переделанная функция load. Пример 22.13. schedule2.py: функция load def load(path=JSON_PATH): records = {} with open(path) as fp: raw_data = json.load(fp) for collection, raw_records in raw_data['Schedule'].items(): record_type = collection[:-1]  cls_name = record_type.capitalize()  cls = globals().get(cls_name, Record)  if inspect.isclass(cls) and issubclass(cls, Record):  factory = cls  else: factory = Record  for raw_record in raw_records:  key = f'{record_type}.{raw_record[\"serial\"]}' records[key] = factory(**raw_record)  return records  До сих пор нет отличий от функции load из файла schedule_v1.py (при- мер 22.9).  Преобразовать первую букву record_type в верхний регистр, чтобы получить потенциальное имя класса (например, 'event' превращается в 'Event').  Получить объект с таким именем из глобальной области видимости моду - ля; если такого объекта нет, получаем Record.  Если только что полученный объект – класс, который является подклассом Record, то … 786  Динамические атрибуты и свойства\n--- Страница 786 ---\n … связать с ним имя factory. Это означает, что factory может быть произволь- ным подклассом Record, определяемым переменной record_type .  В противном случае связать имя factory с Record.  Цикл for, в котором создаются ключи и сохраняются записи, такой же, как и раньше, с тем исключением, что…  … объект, сохраняемый в records, конструируется функцией factory, которая может быть конструктором класса Record или его подкласса – в зависимости от значения record_type . Отметим, что единственное значение record_type , для которого существует пользовательский класс, – это Event, но если бы мы написали классы с именами Speaker или Venue, то load автоматически использовала бы при построении и со- хранении записей их, а не подразумеваемый по умолчанию класс Record. Теперь применим ту же идею к новому свойству speakers в классе Events. Шаг 3: переопределение существующего атрибута свойством Имя свойства venue в примере 22.12 не совпадает с именем поля в записях коллекции «events». Данные для него берутся из поля с именем venue_serial . С другой стороны, в каждой записи коллекции events имеется поле speakers, со- держащее список порядковых номеров. Мы хотим раскрыть эту информацию в виде свойства speakers экземпляра Event, которое возвращало бы список эк- земпляров Record. Этот конфликт имен требует особого внимания, как следует из примера 22.14. Пример 22.14. schedule_v3.py: свойство speakers @property def speakers(self): spkr_serials = self.__dict__['speakers']  fetch = self.__class__.fetch return [fetch(f'speaker.{key}') for key in spkr_serials]   Нужные нам данные находятся в атрибуте speakers, но получить их мы долж - ны непосредственно из экземпляра __dict__, чтобы избежать рекурсивного обращения к свойству speakers.  Вернуть список всех записей с ключами, соответствующими числам в spkr_ serials. Внутри метода speakers попытка прочитать self.speakers вызовет само свой- ство, что очень быстро приведет к исключению RecursionError . Однако если чи- тать те же самые данные из self.__dict__['speakers'] , то мы обойдем обычный алгоритм Python, предназначенный для получения атрибутов, свойство не бу - дет вызвано и мы избежим рекурсии. По этой причине чтение или запись на- прямую в атрибут объекта __dict__ является общепринятой практикой мета- программирования в Python. Вычисляемые свойства  787\n--- Страница 787 ---\nПри вычислении obj.my_attr интерпретатор сначала смотрит на класс obj. Если в классе имеется свойство с именем my_attr, то оно маскирует одноименный атрибут экземпляра. Это будет продемонстрировано на примерах из раздела «Свойства пере- определяют атрибуты экземпляра» ниже, а в главе 23 мы узнаем, что свойство реализовано как дескриптор – более мощная и об- щая абстракция. Когда я кодировал списковое включение в примере 22.14, в мой пещер- ный программистский мозг закралась мысль: «Это может оказаться дорого». На самом деле нет, потому что на мероприятиях OSCON докладчиков немного, поэтому написание более сложного кода может оказаться преждевременной оптимизацией. Однако потребность в кешировании свойств возникает ча- сто, а вместе с ней и подводные камни. Поэтому в следующих примерах мы посмот рим, как это делается. Шаг 4: кеширование свойств на заказ Кеширование свойств – востребованная операция, потому что пользователь естественно ожидает, что вычисление выражения вида event.venue не должно быть дорогим1. Какая-то форма кеширования может оказаться необходимой, если метод Record.fetch , стоящий за свойствами класса Event, обращается с за- просом к базе данных или веб API. В первом издании книги я кодировал пользовательскую логику кеширова- ния для метода speakers, как показано в примере 22.15. Пример 22.15. Пользовательская логика кеширования с применением hasattr отклю- чает оптимизацию разделения ключей @property def speakers(self): if not hasattr(self, '__speaker_objs'):  spkr_serials = self.__dict__['speakers'] fetch = self.__class__.fetch self.__speaker_objs = [fetch(f'speaker.{key}') for key in spkr_serials] return self.__speaker_objs   Если в экземпляре нет атрибута с именем __speaker_objs , выбрать объекты докладчиков и сохранить их здесь.  Вернуть self.__speaker_objs . Самодельное кеширование в примере 22.15 прямолинейно, но создание атри- бута после инициализации экземпляра отменяет оптимизацию, описанную в документе PEP 412 «Key-Sharing Dictionary» (https://peps.python.org/pep-0412/), как объясняется в разделе «Практические последствия внутреннего устройства класса dict» главы 3. В зависимости от размера набора данных разница в потре- лении памяти может оказаться существенной. 1 На самом деле это оборотная сторона принципа единообразного доступа Мейера, который я упоминал во вступлении к этой главе. Если вам интересна дискуссия на эту тему, почитайте врезку «Поговорим» в конце главы. 788  Динамические атрибуты и свойства\n--- Страница 788 ---\nПохожее самодельное решение, не противоречащее оптимизации разделе- ния ключей, требует написания метода __init__ в классе Event, который создаст атрибут __speaker_objs и инициализирует его значением None. Затем этот атрибут можно будет проверить в методе speakers. См. пример 22.16. Пример 22.16. Память выделяется в __init__, чтобы не подавлять оптимизацию раз- деления ключей class Event(Record): def __init__(self, **kwargs): self.__speaker_objs = None super().__init__(**kwargs) # 15 строк опущено @property def speakers(self): if self.__speaker_objs is None: spkr_serials = self.__dict__['speakers'] fetch = self.__class__.fetch self.__speaker_objs = [fetch(f'speaker.{key}') for key in spkr_serials] return self .__speaker_objs В примерах 22.15 и 22.16 иллюстрируется простая техника кеширования, час то встречающаяся в унаследованных кодовых базах на Python. Однако в многопоточных программах подобные самодельные кеши приводят к состо- янию гонки и потенциальному повреждению данных. Если два потока читают свойство, которое не было ранее кешировано, то первый поток должен будет вычислить данные, хранящиеся в кешированном атрибуте (__speaker_objs в на- ших примерах), а второй поток может прочитать еще не полностью сформиро- ванное кеширование значение. К счастью, в Python 3.8 появился потокобезопасный декоратор @functools. cached_property . Но, к сожалению, вместе с ним пришли и две «засады», которые объясняются ниже. Шаг 5: кеширование свойств с помощью functools Модуль functools предлагает три декоратора для кеширования. С @cache и @lru_ cache мы познакомились в разделе «Запоминание с помощью functools.cache» главы 9. А в версии Python 3.8 появился @cached_property . Декоратор functools.cached_property кеширует результат метода в одноимен- ном атрибуте экземпляра. Например, в примере 22.17 значение, вычисленное методом venue, хранится в атрибуте venue в self. Когда впоследствии клиент по- пытается прочитать venue, будет использован атрибут venue, а не метод. Пример 22.17. Простое использование @cached_property @cached_property def venue(self): key = f'venue.{self.venue_serial}' return self.__class__.fetch(key) Вычисляемые свойства  789\n--- Страница 789 ---\nВ разделе «Шаг 3: переопределение существующего атрибута свойством» выше мы видели, что свойство маскирует атрибут экземпляра с тем же именем. Но как тогда может работать @cached_property ? Коль скоро свойство переопределя- ет атрибут экземпляра, атрибут venue будет проигнорирован и всегда будет вызы- ваться метод venue, который будет каждый раз вычислять key и обращаться к fetch! Ответ немного удручает: имя cached_property неправильное. Декоратор @cached_ property не создает полноценного свойства, он создает непереопределяющий де- скриптор. Дескриптор – это объект, который управляет доступом к атрибуту в другом классе. Мы будем подробно изучать дескрипторы в главе 23. Деко- ратор property – это высокоуровневый API для создания переопределяющего де- скриптора. В главе 23 объясняется разница между тем и другим. А пока отложим в сторону реализацию и сосредоточимся на различиях меж - ду cached_property и property с точки зрения пользователя. Раймонд Хэттингер очень хорошо объяснил это в документации по Python (https://docs.python.org/3/ library/ functools.html#functools.cached_property): Механизмы работы cached_property() и property() различаются. Обычное свойство запрещает запись в атрибут, если не определен метод установки. А cached_property разрешает запись всегда. Декоратор cached_ property работает только в момент проверки существова- ния и только при условии, что атрибута с таким же именем не существует. В этом случае cached_property записывает в атрибут с таким же именем. По- следующие операции чтения и записи имеют более высокий приоритет, чем метод cached_property , поэтому кешированное свойство работает, как обычный атрибут. Кешированное значение можно очистить, удалив атрибут. После этого метод cached_property будет работать снова1. Но вернемся к классу Event: специальное поведение @cached_property делает его непригодным для декорирования speakers, потому что этот метод предполагает существование атрибута с таким же именем speakers, в котором хранятся по- рядковые номера докладчиков на мероприятии. Декоратор @cached_property имеет несколько важных ограничений: его нельзя использовать в качестве замены @property , если декорируемый метод уже зависит от существования одно- именного атрибута экземпляра; его нельзя использовать в классе, где определен атрибут __ slots__ ; он подавляет оптимизацию разделения ключей в экземпляре __dict__, потому что создает атрибут экземпляра после __init__. 1 Источник: документация по @functools.cached_property (https://docs.python.org/3/library/ functools.html#functools.cached_property). Я знаю, что автором этого объяснения является Раймонд Хэттингер, потому что он прислал мне его в ответ на зарегистрированную мной проблему: bpo42781 – в документации по functools.cached_property должно быть объяснено, что это не переопределяющий дескриптор (https://bugs.python.org/ issue42781). Хэттингер – один из основных авторов официальной документации по Python и стандартной библиотеки. Он также написал блестящее руководство по де- скрипторам «Descriptor HowTo Guide» (https://docs.python.org/3/howto/descriptor.html), которое стало основным источником для главы 23. 790  Динамические атрибуты и свойства\n--- Страница 790 ---\nНесмотря на эти ограничения, @cached_property решает распространенную проблему простым способом и является потокобезопасным. Его Python-код (https://github.com/python/cpython/blob/e6d0107e13ed957109e79b796984d3d026a866 0d/Lib/functools.py#L926) дает пример использования реентерабельной блокиров- ки (https://docs.python.org/3/library/threading.html#rlock-objects). В документации по @cached_property (https://docs.python.org/3.10/library/ functools. html#functools.cached_property) рекомендуется альтернативное решение, кото- рое можно применить к методу speakers: образовать композицию декораторов @property и @cache, как показано в примере 22.18. Пример 22.18. Композиция @property и @cache @property  @cache  def speakers(self): spkr_serials = self.__dict__['speakers'] fetch = self .__class__ .fetch return [fetch(f'speaker.{key}') for key in spkr_serials]  Порядок важен: @property должен быть расположен выше…  … @cache. Вспомните семантику этой синтаксической конструкции (врезка «Компо- зиция декораторов» в главе 9). Первые три строки примера 22.18 аналогичны следующей записи: speakers = property(cache(speakers)) Декоратор @cache применяется к методу speakers и возвращает новую функ - цию. Затем к этой функции применяется декоратор @property, который заменя- ет ее вновь сконструированным свойством. На этом мы завершаем обсуждение свойств, допускающих только чтение, и кеширующих декораторов, а вместе с ним и исследование набора данных OSCON. В следующем разделе начинается новая серия примеров, в которых создаются свойства, допускающие чтение и запись. иСпОльзОвание СвОйС тв для кОнтр Оля атриБут Ов Помимо вычисления значений атрибутов, свойства применяются с целью реа- лизации бизнес-правил. Для этого открытый атрибут заменяется атрибутом, защищенным методами чтения и установки, без изменения клиентского кода. Рассмотрим развернутый пример. LineItem, попытка № 1: класс строки заказа Представим себе приложение для магазина, который продает натуральные пищевые продукты вразвес, т. е. клиенты могут заказывать орехи, сухофрук - ты или хлопья по весу. В такой системе заказ состоит из последовательности строк, а каждую строку можно представить классом, показанным в приме- ре 22.19. Использование свойств для контроля атрибутов  791\n--- Страница 791 ---\nПример 22.19. bulkfood_v1.py: простейший класс LineItem class LineItem: def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price Красиво и просто. Пожалуй, слишком просто. В примере 20.20 показано, в чем проблема. Пример 20.20. Если вес отрицателен, то и промежуточный итог отрицателен >>> raisins = LineItem('Golden raisins', 10, 6.95) >>> raisins.subtotal() 69.5 >>> raisins.weight = -20 # мусор на входе >>> raisins.subtotal() # мусор на выходе -139.0 Пример, конечно, несерьезный, но не такой надуманный, как можно было бы предположить. Вот правдивая история, случившаяся, когда сайт Amazon. com только зарождался: Мы обнаружили, что покупатель мог заказать отрицательное количество книг! И мы бы перечислили на его кредитную карту соответствующую сумму и, надо полагать, ждали бы, когда он отгрузит книги. – Джефф Безос, основатель и генеральный директор Amazon.com1 Как это исправить? Можно было бы изменить интерфейс класса LineItem, до- бавив методы чтения и установки атрибута weight. Так поступают в Java, и ни- чего плохого в этом нет. С другой стороны, было бы естественно устанавливать атрибут weight эле- мента заказа, просто присваивая ему значение, да и не исключено, что в дру - гих частях эксплуатируемой системы уже встречается прямой доступ к атри- буту вида item.weight . В таком случае следовало бы заменить атрибут-данные свойством – это было бы в духе Python. LineItem, попытка № 2: контролирующее свойство Реализовав свойство, мы сможем использовать методы чтения и установки, но интерфейс класса LineItem при этом не изменится (т. е. для установки атрибу - та weight объекта LineItem по-прежнему нужно будет написать raisins.weight = 12 ). В примере 22.21 приведен код свойства weight, допускающего чтение и запись. 1 Цитата из статьи «Рождение продавца» Джеффа Безоса в журнале «Уолл-стрит джор- нал» (http://on.wsj.com/1ECl8Dl) (15 октября 2011). Обратите внимание, что по состоя- нию на 2021 год для чтения этой статьи нужно оформить подписку.792  Динамические атрибуты и свойства\n--- Страница 792 ---\nПример 22.21. bulkfood_v2.py: класс LineItem со свойством weight class LineItem: def __init__(self, description, weight, price): self.description = description self.weight = weight  self.price = price def subtotal(self): return self.weight * self.price @property  def weight(self):  return self.__weight  @weight.setter  def weight(self, value): if value > 0: self.__weight = value  else: raise ValueError('value must be > 0')   Здесь уже используется метод установки свойства, который гарантирует, что не может быть создан экземпляр с отрицательным значением weight.  Декоратором @property обозначается метод чтения свойства.  Имена всех методов, реализующих свойство, совпадают с именем откры- того атрибута: weight.  Фактическое значение хранится в закрытом атрибуте __weight.  У декорированного метода чтения свойства имеется атрибут .setter, кото - рый является также и декоратором; тем самым методы чтения и установки связываются между собой.  Если значение больше нуля, присваиваем его закрытому атрибуту __weight.  В противном случае возбуждаем исключение ValueError . Теперь объект LineItem с недопустимым весом создать невозможно: >>> walnuts = LineItem('walnuts', 0, 10.00) Traceback (most recent call last): ValueError: value must be > 0 Итак, мы защитили атрибут weight от присваивания отрицательных значе- ний пользователем. Но хотя покупатели обычно не вправе устанавливать цену товара, в результате ошибки служащего или программы все же может быть создан объект LineItem с отрицательной ценой price. Чтобы предотвратить и это, мы могли бы преобразовать price в свойство, но это повлекло бы за собой час- тичное повторение кода. Напомним слова Пола Грэхема, приведенные в главе 17: «Видя в своих про- граммах повторяющиеся структуры, я расцениваю их как знак беды». Лекар- ство от повторения – абстрагирование. Существует два способа абстрагиро- вать определения свойств: фабрика свойств и дескрипторный класс. Подход на основе дескрипторного класса обладает большей гибкостью, мы посвятим ему всю главу 20. На самом деле сами свойства реализованы как дескрипторные Использование свойств для контроля атрибутов  793\n--- Страница 793 ---\nклассы. А пока продолжим наше исследование и реализуем фабрику свойств в виде функции. Но прежде необходимо лучше понять природу свойств. правильный взгляд на СвОйС тва Встроенная функция property часто используется как декоратор, но в действи- тельности она является классом. В Python функции и классы нередко взаимоза- меняемы, поскольку являются вызываемыми объектами и не существует опе- ратора new для создания объекта, поэтому вызов конструктора ничем не отлича- ется от вызова фабричной функции. Как функцию, так и класс можно исполь- зовать в качестве декоратора, при условии что они возвращают новый вызы- ваемый объект, являющийся подходящей заменой декорированной функции. Вот полная сигнатура конструктора класса property: property(fget=None, fset=None, fdel=None, doc=None) Все аргументы необязательны; если для какого-то из них не указана функ - ция, то результирующий объект свойства не поддерживает соответствующую операцию. Тип property появился в версии Python 2.2, но синтаксис декоратора был до- бавлен только в версии Python 2.4, т. е. на протяжении нескольких лет свойства нужно было определять, передавая функции-акцессоры в первых двух аргу - ментах. «Классический» синтаксис определения свойств без декораторов показан в примере 22.22. Пример 22.22. bulkfood_v2b.py: то же, что пример 22.21, но без декораторов class LineItem: def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self):  return self.weight * self.price def get_weight(self): return self.__weight def set_weight(self, value):  if value > 0: self.__weight = value else: raise ValueError('value must be > 0') weight = property(get_weight, set_weight)   Простой метод чтения.  Простой метод установки.  Построить свойство и присвоить его открытому атрибуту класса.794  Динамические атрибуты и свойства\n--- Страница 794 ---\nВ некоторых случаях классическая форма удобнее синтаксиса декораторов, одним из примеров является код фабрики свойств, который мы вскоре обсу - дим. С другой стороны, в теле класса, где много методов, декораторы позво- ляют сразу опознать методы чтения и установки, не полагаясь на соглашение о префиксах get и set в именах. Наличие свойств в классе влияет на то, как можно искать атрибуты в экзем- плярах такого класса, и, на первый взгляд, это удивительно. Объясним, в чем здесь дело. Свойства переопределяют атрибуты экземпляра Свойства всегда являются атрибутами класса, но на самом деле они управляют доступом к атрибутам в экземплярах этого класса. В разделе «Переопределение атрибутов класса» главы 11 мы видели, что если экземпляр и его класс оба имеют атрибут-данные с одним и тем же име- нем, то атрибут экземпляра переопределяет, или маскирует, атрибут класса – по крайней мере, когда мы обращаемся к атрибуту от имени этого экземпляра. Проблема демонстрируется в примере 22.23. Пример 22.23. Атрибут экземпляра маскирует атрибут-данные класса >>> class Class:  data = 'the class data attr' @property def prop(self): return 'the prop value' >>> obj = Class() >>> vars(obj)  {} >>> obj.data  'the class data attr' >>> obj.data = 'bar'  >>> vars(obj)  {'data': 'bar'} >>> obj.data  'bar' >>> Class.data  'the class data attr'  Определить Class с двумя атрибутами класса: атрибутом-данными data и свойством prop.  vars возвращает атрибут __dict__ объекта obj; как видим, атрибутов экзем- пляра в нем нет.  Чтение из obj.data возвращает значение Class.data .  Запись в obj.data создает атрибут экземпляра.  Проинспектировать экземпляр, чтобы узнать, какие у него атрибуты.  Теперь, читая obj.data, мы получаем значение атрибута экземпляра. При чтении из экземпляра obj атрибут экземпляра data маскирует атрибут клас - са data.  Атрибут Class.data не изменился. Правильный взгляд на свойства  795\n--- Страница 795 ---\nПопробуем теперь переопределить атрибут prop экземпляра obj. В приме- ре 22.24 показано продолжение предыдущего сеанса. Пример 22.24. Атрибут экземпляра не маскирует свойство класса (продолжение приме- ра 22.23) >>> Class.prop  <property object at 0x1072b7408> >>> obj.prop  'the prop value' >>> obj.prop = 'foo'  Traceback (most recent call last): AttributeError: can't set attribute >>> obj.__dict__['prop'] = 'foo'  >>> vars(obj)  {'data': 'bar', 'prop': 'foo'} >>> obj.prop  'the prop value' >>> Class.prop = 'baz'  >>> obj.prop  'foo'  Чтение prop непосредственно из Class возвращает сам объект свойства, при этом его метод чтения не выполняется.  Чтение obj.prop приводит к выполнению метода чтения.  Попытка установить атрибут экземпляра prop завершается ошибкой.  Запись 'prop' напрямую в obj.__dict__ работает.  Как видим, теперь у obj есть два атрибута экземпляра: data и prop.  Однако при чтении obj.prop по-прежнему выполняется метод чтения свой- ства. Свойство не маскируется атрибутом экземпляра.  В случае перезаписывания Class.prop объект свойства уничтожается.  Теперь чтение obj.prop возвращает атрибут экземпляра. Class.prop больше не является свойством, поэтому и не переопределяет obj.prop. В качестве заключительной демонстрации добавим новое свойство в Class и убедимся, что оно переопределяет атрибут экземпляра. Пример 22.25 про- должает предыдущий. Пример 22.25. Новое свойство класса маскирует существующий атрибут экземпляра (про- должение примера 22.24) >>> obj.data  'bar' >>> Class.data  'the class data attr' >>> Class.data = property(lambda self: 'the \"data\" prop value')  >>> obj.data  'the \"data\" prop value' >>> del Class.data  >>> obj.data  'bar'796  Динамические атрибуты и свойства\n--- Страница 796 ---\n obj.data возвращает атрибут экземпляра data.  Class.data возвращает атрибут класса data.  Перезаписать Class.data новым свойством.  Теперь Class.data маскирует obj.data.  Удалить свойство.  Теперь obj.data снова возвращает атрибут экземпляра data. В этом разделе мы прежде всего хотели показать, что при вычислении выражения вида obj.data поиск data начинается не с obj. На самом деле по- иск начинается с obj.__class__ , и только если в классе не существует свойства с именем data, то Python заглядывает в сам объект obj. Это правило приме- нимо к переопределяющим дескрипторам вообще, а свойства являются лишь их частным случаем. Мы отложим дальнейшее рассмотрение дескрипторов до главы 23. А пока вернемся к свойствам. В любой единице кода Python – модулях, функциях, классах, методах – может присутствовать строка документации. В следующем разделе мы увидим, как строка документации присоединяется к свойствам. Документирование свойств Когда функции оболочки help() или интегрированной среды разработки нужно вывести документацию по свойству, она получает информацию из атрибута свойства __doc__. В случае классического синтаксиса конструктор класса property может полу - чить строку документации в виде аргумента doc: weight = property(get_weight, set_weight, doc='weight in kilograms') Строка документации метода чтения – того, который снабжен декоратором @property, – становится документацией свойства в целом. На рис. 22.1 показано, как выглядят строки документации для кода из примера 22.26. Рис. 22.1. Как выглядит оболочка Python после выполнения команд help(Foo.bar) и help(Foo) . Исходный код см. в примере 22.26 Правильный взгляд на свойства  797\n--- Страница 797 ---\nПример 22.26. Документирование свойства class Foo: @property def bar(self): \"\"\"Атрибут bar \"\"\" return self.__dict__['bar'] @bar.setter def bar(self, value): self.__dict__['bar'] = value Разобравшись с основами, вернемся к вопросу о том, как защитить атрибу - ты weight и price экземпляра LineItem, чтобы им можно было присвоить только положительные значения, – но при этом не писать вручную две почти одина- ковые пары методов чтения и установки. прОграммир Ование фаБрики СвОйС тв Мы создадим фабрику свойств quantity – такое название выбрано, потому что управляемые атрибуты представляют собой количественные величины, кото- рые в приложении должны быть положительны. В примере 22.27 показано, как выглядит класс LineItem с двумя свойствами, порожденными фабрикой quantity: для управления атрибутами weight и price. Пример 22.27. bulkfood_v2prop.py: фабрика свойств quantity в действии class LineItem: weight = quantity('weight')  price = quantity('price')  def __init__(self, description, weight, price): self.description = description self.weight = weight  self.price = price def subtotal(self): return self.weight * self.price   Использовать фабрику для определения первого свойства, weight, в виде атрибута класса.  Здесь создается второе свойство, price.  Здесь свойство уже работает, и поэтому попытка присвоить weight нулевое или отрицательное значение отвергается.  Здесь свойства также работают: с их помощью производится доступ к зна- чениям, хранящимся в экземпляре. Напомним, что свойства – атрибуты класса. При создании каждого свойства с помощью quantity мы должны передать имя атрибута LineItem, который будет управляться этим свойством. Необходимость дважды писать слово weight в сле- дующей строке удручает: weight = quantity('weight')798  Динамические атрибуты и свойства\n--- Страница 798 ---\nНо избежать такого повторения трудно, потому что свойство понятия не имеет, с каким атрибутом оно связывается. Помните: сначала вычисляется правая часть присваивания, поэтому в момент вызова функции quantity() атри- бут класса price еще даже не существует. Улучшить свойство quantity, так чтобы пользователю не прихо- дилось дважды набирать имя атрибута, – нетривиальная задача метапрограммирования. Мы решим эту проблему в главе 23. В примере 22.28 показана реализация фабрики свойств quantity1. Пример 22.28. bulkfood_v2prop.py: фабрика свойств quantity def quantity(storage_name):  def qty_getter(instance):  return instance.__dict__[storage_name]  def qty_setter(instance, value):  if value > 0: instance.__dict__[storage_name] = value  else: raise ValueError('value must be > 0') return property(qty_getter, qty_setter)   Аргумент storage_name определяет, где хранятся данные свойства; в случае свойства weight данные будут храниться в атрибуте с именем 'weight'.  Называть первый аргумент метода qty_getter именем self было бы не со- всем правильно, т. к. это не тело класса; instance ссылается на экземпляр LineItem, в котором будет храниться атрибут.  Метод qty_getter ссылается на storage_name , поэтому будет сохранен в замы- кании этой функции; значение берется непосредственно из instance.__dict__ , чтобы обойти свойство и избежать бесконечной рекурсии.  В определении метода qty_setter первым аргументом также является instance.  Значение сохраняется непосредственно в instance.__dict__ , снова в обход свойства.  Сконструировать и вернуть объект свойства. Особого внимания заслуживают части этого кода, связанные с использова- нием переменной storage_name . Когда мы реализуем свойство традиционным способом, имя атрибута, в котором хранится значение, зашито в код методов чтения и установки. Здесь же функции qty_getter и qty_setter обобщенные, им не- обходима переменная storage_name , чтобы знать, из какого места атрибута __dict__ экземпляра читать и в какое место записывать значение управляемого свой- ством атрибута. При каждом вызове фабрики quantity для порождения нового свойства переменная storage_name должна принимать уникальное значение. 1 Идея кода заимствована из рецепта 9.21 «Как избежать повторения методов свойств» в книге David Beazley, Brian K. Jones «Python Cookbook», 3-е издание (O’Reilly). Программирование фабрики свойств  799\n--- Страница 799 ---\nФункции qty_getter и qty_setter обертываются объектом property в последней строке фабричной функции. Когда впоследствии любая из этих функций бу- дет вызвана для выполнения своих обязанностей, она прочитает storage_name из своего замыкания и определит, откуда читать или куда записывать значение управляемого атрибута. В примере 22.29, где я создаю и инспектирую экземпляр LineItem, видны атрибуты, в которых хранятся значения свойств. Пример 22.29. bulkfood_v2prop.py: фабрика свойств quantity >>> nutmeg = LineItem('Moluccan nutmeg', 8, 13.95) >>> nutmeg.weight, nutmeg.price  (8, 13.95) >>> nutmeg.__dict__  {'description': 'Moluccan nutmeg', 'weight': 8, 'price': 13.95  Чтение weight и price с помощью свойств маскирует одноименные атрибуты экземпляра.  Использовать метод vars, чтобы проинспектировать экземпляр nutmeg: вид- но, в каких точно атрибутах экземпляра хранятся значения. Обратите внимание, как в свойствах, построенных нашей фабрикой, ис- пользуется поведение, описанное в разделе «Свойства переопределяют атри- буты экземпляра» выше: свойство weight переопределяет атрибут экземпляра weight, поэтому любое обращение к self.weight или nutmeg.weight обрабатывается методами доступа свойства, и обойти их можно, только работая с атрибутом __dict__ напрямую. Возможно, код в примере 22.28 понятен не с первого раза, но он корот - кий: в нем столько же строк, сколько в паре декорированных методов чтения и установки одного лишь свойства weight в примере 22.21. Определение LineItem в примере 22.27 выглядит намного лучше без шума, вносимого методами чте- ния и установки. В реальной системе такого рода проверкам могут подвергаться многие поля в нескольких классах, поэтому фабрику quantity следовало бы вынести в слу - жебный модуль. В конечном итоге эту простую фабрику можно было бы заме- нить допускающим расширение дескрипторным классом, специализирован- ные подклассы которого выполняют различные проверки. Мы займемся этим в главе 23. А пока завершим обсуждение свойств, рассмотрев вопрос об удалении атри- бутов. удаление атриБут Ов Предложение del можно использовать для удаления не только переменных, но и атрибутов: >>> class Demo: pass >>> d = Demo() >>> d.color = 'green'800  Динамические атрибуты и свойства\n--- Страница 800 ---\n>>> d.color 'green' >>> del d.color >>> d.color Traceback (most recent call last): File \"<stdin>\", line 1, in <module> AttributeError: 'Demo' object has no attribute 'color' Удаление атрибутов вряд ли можно назвать повседневно выполняемой опе- рацией, а требование обеспечить ее выполнение с помощью свойств еще бо- лее необычно. Но оно поддерживается, и я приведу для его демонстрации не- сколько искусственный пример. В определении свойства декоратор @my_propety.deleter используется, чтобы обер- нуть метод, отвечающий за удаление атрибута, управляемого свойством. Идея глупого примера 22.30 подсказана персонажем Black Knight (Черный рыцарь) из скетча «Monty Python and the Holy Grail» (Монти Пайтон и Святой Грааль)1. Пример 22.30. blackknight.py class BlackKnight: def __init__(self): self.phrases = [ ('рука', \"Это всего лишь царапина.\"), ('вторая рука', \"Это всего лишь поверхностная рана.\"), ('нога', \"Я неуязвим!\"), ('вторая нога', \"Ну ладно, пусть будет ничья.\") ] @property def member(self): print('следующий член:') return self.phrases[0][0] @member.deleter def member(self): member, text = self.phrases.pop(0) print(f'ЧЕРНЫЙ РЫЦАРЬ (утрачена {member}) -- {text}') Тесты для этого класса приведены в примере 22.31. Пример 22.31. blackknight.py: тесты для примера 22.30 (Черный рыцарь никогда не при- знает поражение) >>> knight = BlackKnight() >>> knight.member следующий член: 'рука' >>> del knight.member ЧЕРНЫЙ РЫЦАРЬ (утрачена рука) -- Это всего лишь царапина. >>> del knight.member ЧЕРНЫЙ РЫЦАРЬ (утрачена вторая рука) -- Это всего лишь поверхностная рана. >>> del knight.member ЧЕРНЫЙ РЫЦАРЬ (утрачена нога) -- Я неуязвим! 1 По состоянию на октябрь 2021 года кровавая сцена доступа на YouTube (https://www. youtube.com/watch?v=s35rVw1zskA). Удаление атрибутов  801\n--- Страница 801 ---\n>>> del knight.member ЧЕРНЫЙ РЫЦАРЬ (утрачена вторая нога) -- Ну ладно, пусть будет ничья. Если используется не декоратор, а классический синтаксис, то для задания метода удаления применяется именованный аргумент fdel. Например, свой- ство member в теле класса BlackKnight можно было бы написать так: member = property(member_getter, fdel=member_deleter) Если вы не пользуетесь свойствами, то для удаления атрибута можно было бы также реализовать низкоуровневый специальный метод __delattr__ , опи- санный в разделе «Специальные методы для управления атрибутами» ниже. Кодирование класса с применением метода __delattr__ я оставляю в качестве упражнения на досуге для читателей. Свойства – весьма полезный механизм, но иногда предпочтительнее более простые или низкоуровневые альтернативы. В последнем разделе этой главы мы рассмотрим некоторые базовые API, предлагаемые для программирования динамических атрибутов. важные атриБуты и функции для раБО ты С атриБутами И в этой главе, и раньше в книге мы уже использовали некоторые встроенные функции и специальные методы, которые Python предоставляет для работы с динамическими атрибутами. Сейчас мы соберем их в одном месте, поскольку в официальном руководстве они документированы в разных разделах. Специальные атрибуты, влияющие на обработку атрибутов Поведение многих функций и специальных методов, описанных ниже, опре- деляется тремя специальными атрибутами. __class__ Ссылка на класс объекта (т. е. obj.__class__ – то же самое, что type(obj)). Python ищет специальные методы, например __getattr__ , только в классе объекта, а не в самих экземплярах. __dict__ Отображение, в котором хранятся изменяемые атрибуты объекта или класса. Если у объекта есть атрибут __dict__, то его в любой момент можно наделить новыми атрибутами. Если в классе есть атрибут __slots__, то у его экземпляров не может быть атрибута __dict__. __slots__ Этот атрибут можно определить в классе, чтобы ограничить состав атри- бутов у экземпляров этого класса. __slots__ представляет собой кортеж строк с именами допустимых атрибутов1. Если имя '__dict__' отсутствует в __slots__, то у экземпляров класса не будет своего атрибута __dict__, по- 1 Алекс Мартелли отмечает, что __slots__ может быть и списком, но лучше не остав- лять места для недоразумений и всегда использовать кортеж, потому что измене- ние спис ка, хранящегося в __slots__ , после обработки тела класса интерпретатором, не возымеет никакого эффекта, так что использование здесь изменяемой последо- вательности лишь стало бы причиной вредных иллюзий.802  Динамические атрибуты и свойства\n--- Страница 802 ---\nэтому в них будут разрешены только атрибуты, перечисленные в __slots__. См. дополнительные сведения в разделе «Экономия памяти с помощью атрибута класса __slots__» главы 11. Встроенные функции для работы с атрибутами Существует пять встроенных функций для чтения, записи и интроспекции атрибутов: dir([object]) Перечисляет большую часть атрибутов объекта. В официальной докумен- тации (https://docs.python.org/3/library/functions.html#dir) сказано, что функ - ция dir предназначена для интерактивного использования, поэтому она выводит не полный список атрибутов, а только самые «интересные». dir умеет инспектировать объекты с атрибутом __dict__ и без него. Сам атри- бут __dict__ не входит в список, формируемый функцией dir, но ключи, хранящие ся в __dict__, входят. Есть еще несколько специальных атрибутов классов, в частности __mro__, __bases__ и __name__, которые dir не выводит. Ре- зультат, печатаемый методом dir, можно модифицировать, реализовав спе- циальный метод __dir__, как показано в примере 22.4. Если факультативный аргумент object не задан, то dir выводит имена в текущей области видимости. getattr(object, name[, default]) Получает атрибут, идентифицируемый строкой name, объекта object. Приме- няется прежде всего для получения атрибутов (или методов), чьи имена за- ранее неизвестны. В результате может быть найден атрибут, определенный в классе или суперклассе объекта. Если такого атрибута не существует, getattr возбуждает исключение AttributeError либо возвращает значение default, если оно задано. Замечательный пример использования getattr имеется в мето- де Cmd.onecmd (https://github.com/python/cpython/blob/19903085c3ad7a17c8047e155 6c700f2eb109931/Lib/cmd.py#L214) из стандартного пакета cmd – он служит для получения и выполнения заданной пользователем команды. hasattr(object, name) Возвращает True, если атрибут с указанным именем существует в объекте object или может быть найден с его помощью (например, в результате наследова- ния). В документации (https://docs.python.org/3/library/functions.html#hasattr) при- водится следующее объяснение: «Реализовано так: вызываем getattr(object, name), а затем смотрим, возникло исключение AttributeError или нет». setattr(object, name, value) Присваивает значение value поименованному атрибуту object, если object это допускает. В результате может быть создан новый атрибут или изменен существующий. vars([object]) Возвращает атрибут __dict__ объекта object; функция vars не умеет работать с классами, в которых определен атрибут __slots__ и нет атрибута __dict__ (в отличие от функции dir, которая справляется с такими экземплярами). Без аргумента vars() делает то же самое, что locals(): возвращает словарь, описывающий локальную область видимости. Важные атрибуты и функции для работы с атрибутами  803\n--- Страница 803 ---\nСпециальные методы для работы с атрибутами Специальные методы, описанные ниже, отвечают за чтение, установку, удаление и получение списка атрибутов (если они реализованы в пользовательском классе). Доступ к атрибутам – с помощью нотации с точкой или встроенных функ - ций getattr, hasattr и setattr – приводит к вызову соответствующих специальных методов. Чтение и запись атрибутов непосредственно в атрибуте __dict__ эк- земпляра производятся в обход этих специальных методов – и это общепри- нятый метод обойти их в случае необходимости. В разделе 3.3.11 «Поиск специальных методов» (https://docs.python.org/3.10/ reference/datamodel.html#special-method-lookup) главы «Модель данных» есть такое предупреждение: Для пользовательских классов правильность работы при неявном вызове специальных методов гарантируется, только если они определены в типе объекта, а не в словаре экземпляра. Иными словами, следует считать, что специальные методы ищутся в самом классе, даже если вызываются от имени экземпляра. По этой причине специ- альные методы не маскируются одноименными атрибутами экземпляра. В следующих примерах предполагается, что существует класс с именем Class, что obj – экземпляр класса Class, а attr – атрибут obj. Для всех описанных ниже специальных методов не имеет значения, как про- изводится доступ к атрибуту: с помощью нотации с точкой или встроенных функций, упомянутых в предыдущем разделе. И obj.attr, и getattr(obj, 'attr', 42) приводят к вызову функции Class.__getattribute__(obj, 'attr') . __delattr__(self, name) Вызывается при любой попытке удалить атрибут в предложении del, на- пример del obj.attr приводит к вызову Class.__delattr__(obj, 'attr') . Если attr является свойством, то его метод удаления никогда не вызывается, если в классе реализован метод __delattr__ . __dir__(self) Вызывается при вызове dir для объекта с целью получить список атрибу - тов, например dir(obj) приводит к вызову Class.__dir__(obj) . Также исполь- зуется для автоматического дополнения по нажатии клавиши Tab во всех современных консолях Python. __getattr__(self, name) Вызывается только тогда, когда попытка найти поименованный атрибут в obj, Class и суперклассах завершается неудачно. Выражения obj.no_such_attr , getattr(obj, 'no_such_attr') и hasattr(obj, 'no_such_attr') могут привести к вы- зову Class.__getattr__(obj, 'no_such_attr') , но только если атрибут с таким име- нем отсутствует в obj, Class и его суперклассах. __getattribute__(self, name) Вызывается при любой попытке получить поименованный атрибут непо- средственно из Python-кода (интерпретатор иногда обходит этот метод, например чтобы получить метод __repr__). К вызову этого метода приводит использование нотации с точкой и встроенных функций getattr и hasattr. 804  Динамические атрибуты и свойства\n--- Страница 804 ---\nМетод __getattr__ всегда вызывается после __getattribute__ и только в том слу- чае, когда __getattribute__ возбуждает исключение AttributeError . Чтобы при получении атрибутов obj не возникало бесконечной рекурсии, в реализа- ции __getattribute__ следует использовать super().__getattribute__(obj, name) . __setattr__(self, name, value) Вызывается при любой попытке установить поименованный атрибут. К вызову этого метода приводит использование нотации с точкой и встро- енной функции setattr, например и obj.attr = 42 , и setattr(obj, 'attr', 42) при- водят к вызову Class.__setattr__(obj, 'attr', 42) . Поскольку специальные методы __getattribute__ и __setattr__ вызываются безусловно и сопровождают практически каждый доступ к атрибуту, правильно использовать их труднее, чем ме- тод __getattr__ , который вызывается только для обработки имен несуществующих атрибутов. Во избежание ошибок лучше поль- зоваться не этими специальными методами, а свойствами или дескрипторами. На этом завершается наше исследование свойств, специальных методов и других приемов программирования динамических атрибутов. резюме Мы начали обсуждение динамических атрибутов с практических примеров клас - сов, которые упрощают работу с набором данных в формате JSON. Первым при- мером был класс FrozenJSON, преобразующий вложенные словари и списки во вло- женные экземпляры FrozenJSON и списки таких экземпляров. При этом мы проде- монстрировали применение специального метода __getattr__ для преобразова- ния структур данных на лету, в момент чтения их атрибутов. В последней версии FrozenJSON было показано, как использовать метод конструирования __new__, чтобы превратить класс в гибкую фабрику объектов, причем не только этого класса. Затем мы преобразовали набор JSON-данных в словарь dict, в которой хра- нятся сериализованные экземпляры класса Record. Первое воплощение Record содержало всего несколько строк, и в нем использовалась идиома self.__dict__. update(**kwargs) для создания произвольных атрибутов из именованных ар- гументов, переданных __init__. На второй итерации мы добавили класс Event, реализующий автоматический поиск связанных записей с помощью свойств. Вычисляемые свойства иногда необходимо кешировать, и мы рассмотрели не- сколько способов сделать это. Знакомство со свойствами продолжилось на примере класса LineItem, в ко - тором свойство предотвращало присваивание атрибуту weight нулевого или отрицательного значения. Глубже разобравшись с синтаксисом и семантикой свойств, мы создали фабрику свойств, которая обеспечивала одинаковую про- верку свойств weight и price, но без повторного кодирования методов чтения и установки. При реализации фабрики свойств использовались тонкие идеи – замыкание и переопределение атрибутов экземпляра свойствами, – позволив- шие предложить элегантное общее решение, по количеству строк не превыша- ющее определение одного свойства, написанное вручную. Резюме  805\n--- Страница 805 ---\nНапоследок мы вкратце рассмотрели удаление атрибутов с помощью свойств, а затем перечислили специальные атрибуты, встроенные функции и специальные методы, которые поддерживают метапрограммирование атри- бутов в Python. дОпО лнительная литература Официальной документацией по встроенным функциям для работы с атри- бутами и интроспекции является глава 2 «Встроенные функции» (https:// docs.python.org/3/library/functions.html) руководства по стандартной библиоте- ке Python. Относящиеся к этой же теме специальные методы и специальный атрибут __slots__ документированы в разделе 3.3.2 «Настройка доступа к атри- бутам» справочного руководства по языку Python (https://docs. python.org/3/ reference/datamodel.html#customizing-attribute-access). Семантика вызова специ- альных методов в обход экземпляров описана в разделе 3.3.9 «Поиск специ- альных методов» (https://docs.python.org/3/reference/datamodel.html#special-method- lookup). В разделе 4.13 «Специальные атрибуты» главы 4 «Встроенные типы» руководства по стандартной библиотеке Python (https://docs.python.org/3/library/ stdtypes.html#special-attributes) рассматриваются атрибуты __class__ и __dict__. В книге Дэвида Бизли и Брайана К. Джонса «Python Cookbook», 3-е издание (https://www.oreilly.com/library/view/python-cookbook-3rd/9781449357337/), есть не- сколько рецептов, относящихся к теме данной главы, но я упомяну только три наиболее интересных. Рецепт 8.8 «Расширение свойства в подклассе» касается непростого вопроса о переопределении методов внутри свойства, унаследо- ванного от суперкласса. В рецепте 8.15 «Делегирование доступа к атрибутам» реализован прокси-класс, демонстрирующий большинство специальных ме- тодов, описанных в разделе «Специальные методы для работы с атрибутами» этой главы. А великолепный рецепт 9.21 «Как избежать повторения методов свойств» лег в основу фабрики свойств, представленной в примере 22.28. В книге Alex Martelli, Anna Ravenscroft, Steve Holden «Python in a Nutshell», 3-е издание (O’Reilly) (https://www.oreilly.com/library/view/python-in-a/9781491913833/), материал изложен строго и объективно. Авторы уделили свойствам всего три страницы, но это потому, что в книге принят аксиоматический стиль изложе- ния: предшествующие 15 страниц посвящены детальному описанию семанти- ки классов Python, начиная с самых основ, и в том числе дескрипторам, которые составляют основу реализации свойств. Так что, дойдя до свойств, авторы смог - ли уместить на трех страницах очень много полезной информации, в том числе и замечание, взятое мной в качестве эпиграфа к этой главе. Бертран Мейер, чье определение принципа единообразного доступа приведе- но в начале этой главы, первым определил методологию проектирования по контракту, спроектировал язык Eiffel и написал великолепную книгу «Object- Oriented Software Construction», 2-е издание (Pearson). Первые шесть глав – одно из лучших концептуальных введений в объектно-ориентированный анализ и проектирование из всех мне встречавшихся. В главе 11 содержится введение в «проектирование по контракту», а в главе 35 – авторские оценки некоторых важнейших объектно-ориентированных языков: Simula, Smalltalk, CLOS (Common Lisp Object System), Objective-C, C++ и Java, а также краткие за-806  Динамические атрибуты и свойства\n--- Страница 806 ---\nмечания по поводу ряда других. Только на последней странице книги он при- знается, что «нотация», которой он пользовался при написании псевдокода, – на самом деле язык Eiffel. Поговорим Принцип единообразного доступа Мейера (любители акронимов иногда на- зывают его UAP) эстетически весьма привлекателен. Как программисту, кото- рый пользуется некоторым API, мне должно быть все равно, что делает кон- струкция coconut.price : просто читает атрибут-данные или выполняет какое-то вычисление. Но как потребителю и гражданину мне это отнюдь небезразлич- но: в современной электронной коммерции значение product.price зачастую зависит от того, кто спрашивает, т. е. это заведомо не простой атрибут. На са- мом деле цена нередко будет ниже, если запрос поступает извне магазина, скажем от системы сравнения цен. И тем самым наказываются лояльные по- купатели, которые любят гулять по данному магазину. Но это я отвлекся. Однако это отвлечение поднимает важный для программирования вопрос: хотя в идеальном мире принцип единообразного доступа, безусловно, имеет смысл, на практике пользователям API иногда нужно знать, не может ли обращение к product.price оказаться слишком накладным или долгим. Это общая проблема абстракций программирования: они сильно затрудняют рассуждения о стои- мости вычисления выражений во время выполнения. С другой стороны, аб- стракции позволяют пользователю сделать больше, написав меньше кода. Это компромисс. Как обычно, когда речь заходит о программной инженерии, стоит заглянуть на вики-сайт Уорда Каннингэма (http://wiki.c2.com/?WelcomeVisitors), где имеются поучительные соображения по поводу достоинств принципа едино- образного доступа (http://wiki.c2.com/?UniformAccessPrinciple). В объектно-ориентированных языках программирования применение или на- рушение принципа единообразного доступа обычно сводится к выбору между чтением открытых атрибутов-данных и вызовом методов чтения и установки. В Smalltalk и Ruby проблема решается просто и элегантно: они вообще не под- держивают открытые атрибуты-данные. Все атрибуты экземпляра в этих языках закрыты, поэтому доступ к ним обязательно опосредуется методами. Но это при- нуждение нивелируется удобным синтаксисом: в Ruby выражение product.price приводит к вызову метода чтения price; в Smalltalk мы пишем просто product price . На другом конце спектра находится язык Java, в котором у программиста есть выбор между четырьмя модификаторами уровня доступа, причем подразуме- ваемый по умолчанию не именуется, а в пособии по Java (https://docs.oracle.com/ javase/tutorial/java/javaOO/accesscontrol.html) называется package-private. Впрочем, принятая практика идет вразрез с синтаксисом, установленным про- ектировщиками языка Java. Все в мире Java согласны, что атрибуты должны быть закрытыми, поэтому приходится всякий раз писать private, поскольку этот уровень доступа не является умалчиваемым. Коль скоро все атрибуты закрыты, то и доступ к ним вне класса должен осуществляться с помощью акцессоров. В Java IDE имеются средства для автоматической генерации методов-акцессо- ров. К сожалению, IDE не поможет, когда спустя полгода вам придется читать свой код. Вам и только вам предстоит просеять кучу ничего не делающих акцес - соров и найти те жемчужины, в которые имеет смысл добавить бизнес-логику. Дополнительная литература  807\n--- Страница 807 ---\nАлекс Мартелли говорит от имени большей части сообщества Python, когда называет акцессоры «тупыми идиомами», и затем предлагает следующие примеры, которые выглядят совсем по-разному, но делают одно и то же1: someInstance.widgetCounter += 1 # вместо someInstance.setWidgetCounter(someInstance.getWidgetCounter() + 1) Иногда, проектируя API, я задавался вопросом, следует ли всякий метод, кото- рый не принимает аргументов (кроме self), возвращает значение (отличное от None) и является чистой функцией (т. е. не имеет побочных эффектов), заменять свойством, допускающим только чтение. В этой главе метод LineItem.subtotal (см. пример 19.23) был бы неплохим кандидатом на преобразование в свойство. Ко- нечно, речь не идет о методах, которые призваны изменять объект, например my_list.clear() . Было бы ужасной ошибкой преобразовать такой метод в свойство, потому что простое обращение my_list.clear стерло бы все содержимое списка! В библиотеке GPIO Pingo (http://www.pingo.io/docs/), одним из авторов которой я являюсь (упоминается в разделе «Метод __missing__» главы 3), значительная часть API пользовательского уровня основана на свойствах. Например, чтобы прочитать текущее значение аналогового контакта, нужно написать pin.value, а чтобы установить режим цифрового контакта – pin.mode = OUT . За кулисами то и другое может потребовать выполнения большого объема кода – в зависи- мости от драйвера платы. Мы решили использовать в Pingo свойства, потому что хотели, чтобы с API было удобно работать даже в интерактивных средах типа Jupyter Notebook, и полагали, что запись pin.mode = OUT приятнее и глазам, и пальцам, чем pin.set_mode(OUT) . Решение, принятое в Smalltalk и Ruby, мне кажется чище, но я полагаю, что подход Python лучше, чем в Java. Нам разрешено начать с простого – сделать данные-члены открытыми атрибутами, – потому что мы знаем, что впослед- ствии всегда сможем обернуть их свойствами (или дескрипторами, о которых будем говорить в следующей главе). __new__ лучше, чем new Еще один пример принципа единообразного доступа (или вариации на его тему) – тот факт, что в Python синтаксис вызова функций и создания объектов одинаков: my_obj = foo() , где foo может быть классом или любым другим вы- зываемым объектом. В других языках, позаимствовавших синтаксис C++, имеется оператор new, из- за которого создание объекта выглядит иначе, чем вызов. По большей части пользователю API безразлично, является foo функцией или классом. На про- тяжении многих лет я и сам считал, что property – это функция. При обычном использовании это не важно. Есть много причин заменить конструкторы фабриками2. Популярное обо- снование – ограничить количество экземпляров, возвращая не новые, а соз- 1 Alex Martelli. Python in a Nutshell. 2-е изд. O’Reilly. С. 101. 2 Упоминаемые мной причины приведены в статье Джонатана Амстердама из жур- нала «Dr. Dobbs Journal» под названием «Java’s new Considered Harmful» (http:// ubm.io/1cPP4PN), а также в разделе «Consider static factory methods instead of constructors» удостоенной наград книги Джошуа Блоха «Effective Java», 3-е изда- ние (Addison-Wesley).808  Динамические атрибуты и свойства\n--- Страница 808 ---\nданные ранее (как в паттерне Одиночка). Сюда же примыкает кеширование объектов, конструирование которых обходится дорого. Иногда также удобно возвращать объекты разных типов в зависимости от переданных аргументов. Писать конструктор проще, но реализация фабрики повышает гибкость це- ной дополнительного кода. В языках, где есть оператор new, проектировщик API должен заранее решить, ограничиться ли простым конструктором или потратить время на фабрику. Если первоначальное решение оказалось невер- ным, то исправление может обойтись дорого – из-за того, что new – оператор. Иногда удобнее пойти другим путем и заменить простую функцию классом. В Python классы и функции во многих ситуациях взаимозаменяемы. И не только из-за отсутствия оператора new, но и потому, что имеется специаль- ный метод __new__, который позволяет преобразовать класс в фабрику, порож - дающую объекты разных видов (как мы видели в разделе «Гибкое создание объектов с помощью метода __new__» этой главы) или возвращающую ранее созданные экземпляры, вместо того чтобы каждый раз создавать новые. Дуализм функции и класса было бы использовать еще проще, если бы в докумен- те PEP 8 «Style Guide for Python Code» (https://peps.python.org/pep-0008/#class-names) не рекомендовалось применять ВерблюжьюНотацию (CamelCase) для имен классов. С другой стороны, в стандартной библиотеке имеются десятки классов с имена- ми, составленными только из строчных букв (например, property, str, defauldict и т. д.). Так что, возможно, использование таких имен классов – вовсе не ошибка. Впрочем, как бы ни смотреть на эту проблему, разнобой в употреблении строч- ных и заглавных букв в именах классов из стандартной библиотеки Python пред- ставляет трудность для пользователей. Хотя вызов функции не отличается от вызова класса, знать, что есть что, по- лезно, поскольку у классов есть дополнительная возможность: наследование. Поэтому лично я всегда применяю ВерблюжьюНотацию для имен своих классов и хотел бы, чтобы все классы в стандартной библиотеке следовали этому со- глашению. Это я о вас, collections.OrderedDict и collections.defaultdict . Дополнительная литература  809",
      "debug": {
        "start_page": 771,
        "end_page": 808
      }
    },
    {
      "name": "Глава 23. Дескрипторы атрибутов 810",
      "content": "--- Страница 809 --- (продолжение)\nГлава 23 Дескрипторы атрибутов Изучение дескрипторов не только расширяет доступный инструмента- рий, но и позволяет глубже понять, как работает Python, и оценить эле- гантность его дизайна. – Раймонд Хэттингер, один из разработчиков ядра Python и гуру1 Дескрипторы – это способ повторного использования одной и той же логики доступа в нескольких атрибутах. Например, типы полей в объектно-ориен- тированных отображениях вроде Django ORM и SQL Alchemy – дескрипторы, управляющие потоком данных от полей в записи базы данных к атрибутам Python-объекта и обратно. Дескриптор – это класс, который реализует динамический протокол, содержа- щий методы __get__, __set__ и __delete__. Класс property реализует весь протокол де- скриптора. Как обычно, разрешается реализовывать протокол частично. На са- мом деле большинство дескрипторов, встречающихся в реальных программах, реализуют только методы __get__ и __set__, а многие – и вовсе лишь один из них. Дескрипторы – уникальная черта Python, и используются они не только на уровне приложения, но и в инфраструктуре самого языка. Пользовательские функции – это дескрипторы. Мы увидим, как протокол дескрипторов делает методы связанными или несвязанными в зависимости от способа вызова. Умение работать с дескрипторами – ключ к полному овладению Python. Им и посвящена эта глава. В этой главе мы переработаем код примеров из раздела «Использование свойств для контроля атрибутов» главы 22, заменив свойства дескрипторами. Тем самым мы упростим повторное использование уже написанной ранее логики контроля атрибутов. Мы затронем понятия переопределяющих и непереопределяющих де- скрипторов и поймем, что функции Python на самом деле являются дескриптора- ми. Наконец, мы немного расскажем о том, как реализуются дескрипторы. чтО нОвОг О в этОй главе Пример дескриптора Quantity в разделе «LineItem попытка № 4: автоматиче- ская генерация имен атрибутов хранения» существенно упрощен, что стало возможным благодаря добавлению специального метода __set_name__ в прото- кол дескрипторов в версии Python 3.6. Я удалил пример фабрики свойств из раздела «LineItem попытка № 4: ав- томатическая генерация имен атрибутов хранения», поскольку он стал не ну - 1 Raymond Hettinger. Descriptor HowTo Guide (https://docs.python.org/3/howto/descriptor.html).\nГлава 23 Дескрипторы атрибутов Изучение дескрипторов не только расширяет доступный инструмента- рий, но и позволяет глубже понять, как работает Python, и оценить эле- гантность его дизайна. – Раймонд Хэттингер, один из разработчиков ядра Python и гуру1 Дескрипторы – это способ повторного использования одной и той же логики доступа в нескольких атрибутах. Например, типы полей в объектно-ориен- тированных отображениях вроде Django ORM и SQL Alchemy – дескрипторы, управляющие потоком данных от полей в записи базы данных к атрибутам Python-объекта и обратно. Дескриптор – это класс, который реализует динамический протокол, содержа- щий методы __get__, __set__ и __delete__. Класс property реализует весь протокол де- скриптора. Как обычно, разрешается реализовывать протокол частично. На са- мом деле большинство дескрипторов, встречающихся в реальных программах, реализуют только методы __get__ и __set__, а многие – и вовсе лишь один из них. Дескрипторы – уникальная черта Python, и используются они не только на уровне приложения, но и в инфраструктуре самого языка. Пользовательские функции – это дескрипторы. Мы увидим, как протокол дескрипторов делает методы связанными или несвязанными в зависимости от способа вызова. Умение работать с дескрипторами – ключ к полному овладению Python. Им и посвящена эта глава. В этой главе мы переработаем код примеров из раздела «Использование свойств для контроля атрибутов» главы 22, заменив свойства дескрипторами. Тем самым мы упростим повторное использование уже написанной ранее логики контроля атрибутов. Мы затронем понятия переопределяющих и непереопределяющих де- скрипторов и поймем, что функции Python на самом деле являются дескриптора- ми. Наконец, мы немного расскажем о том, как реализуются дескрипторы. чтО нОвОг О в этОй главе Пример дескриптора Quantity в разделе «LineItem попытка № 4: автоматиче- ская генерация имен атрибутов хранения» существенно упрощен, что стало возможным благодаря добавлению специального метода __set_name__ в прото- кол дескрипторов в версии Python 3.6. Я удалил пример фабрики свойств из раздела «LineItem попытка № 4: ав- томатическая генерация имен атрибутов хранения», поскольку он стал не ну - 1 Raymond Hettinger. Descriptor HowTo Guide (https://docs.python.org/3/howto/descriptor.html).\n--- Страница 810 ---\nжен: смысл его был в том, чтобы показать альтернативный способ решения проблемы Quantity, но после добавления метода __set_name__ решение на основе дескриптора стало гораздо проще. Класс AutoStorage из раздела «LineItem попытка № 5: новый тип дескриптора» тоже исключен, потому что утратил актуальность после добавления __set_name__. пример деСкрипт Ора: прОверка значений атриБут Ов В разделе «Программирование фабрики свойств» главы 19 мы видели, что фаб- рика свойств позволяет избежать многократного кодирования методов чтения и установки посредством применения приемов, характерных для функцио- нального программирования. Фабрика свойств – это функция высшего поряд- ка, которая создает параметризованный набор функций-акцессоров и строит из них экземпляры пользовательских свойств, настройки которых, например storage_name , хранятся в замыканиях. Объектно-ориентированный способ реше- ния той же задачи – дескрипторный класс. Мы вернемся к примерам класса LineItem с того места, где остановились, и переделаем фабрику свойств quantity в дескрипторный класс Quantity. LineItem попытка № 3: простой дескриптор Как было сказано во введении, класс, в котором реализован хотя бы один из методов __get__, __set__ или __delete__ , является дескриптором. Для использова- ния дескриптора мы объявляем его экземпляры как атрибуты класса какого-то другого класса. Мы создадим дескриптор Quantity и включим в класс LineItem два экземпляра Quantity: для управления атрибутами weight и price. Все это изображено на диа- грамме классов на рис. 23.1. управляемый класс дескрипторный класс установить управляемый атрибут Рис. 23.1. UML-диаграмма класса LineItem и используемого в нем дескрипторного класса Quantity . Подчеркнуты атрибуты класса. Отметим, что weight и price – экземпляры класса Quantity , присоединенного к классу LineItem , но у экземпляров LineItem есть также собствен- ные атрибуты weight и price , в которых соответствующие значения хранятся Отметим, что слово weight встречается на рис. 23.1 дважды, потому что есть два разных атрибута с именем weight: первый – атрибут класса LineItem, второй – атрибут экземпляра, принадлежащий каждому объекту LineItem. То же самое от- носится и к price. Начиная с этого места я буду пользоваться следующими определениями: Пример дескриптора: проверка значений атрибутов  811\n--- Страница 811 ---\nДескрипторный класс Класс, реализующий протокол дескриптора. Это класс Quantity на рис. 23.1. Управляемый класс Класс, в котором объявлены атрибуты класса, являющиеся экземплярами дескриптора. Это класс LineItem на рис. 23.1. Экземпляр дескриптора Любой экземпляр дескрипторного класса, объявленный атрибутом класса в управляемом классе. На рис. 23.1 все экземпляры дескриптора представ- лены стрелкой композиции, снабженной подчеркнутым именем (в UML подчеркивание означает атрибут класса). Сплошные ромбы одним концом касаются класса LineItem, который содержит экземпляры дескрипторов. Управляемый экземпляр Один экземпляр управляемого класса. В нашем примере управляемыми являются экземпляры класса LineItem (на диаграмме классов не показаны). Атрибут хранения Атрибут управляемого экземпляра, в котором хранится значение управля- емого атрибута для данного экземпляра. На рис. 23.1 атрибутами хранения являются атрибуты weight и price экземпляра LineItem. Они отличаются от эк- земпляров дескриптора, которые всегда являются атрибутами класса. Управляемый атрибут Открытый атрибут управляемого класса, который обрабатывается экземпля- ром дескриптора, а значение которого хранится в одном из атрибутов хране- ния. Другими словами, экземпляр дескриптора и атрибут хранения в совокуп- ности образуют инфраструктуру для управляемого атрибута. Необходимо понимать, что экземпляры Quantity являются атрибутами класса LineItem. Этот важнейший момент иллюстрируется хреновинами и штуковина- ми на рис. 23.2. Рис. 23.2. UML-диаграмма классов, аннотированная на языке MGN (Mills & Gizmos Notation): классы представлены хреновинами, порождающими штуковины – экземпляры. Хреновина Quantity порождает две красные штуковины, присоединенные к хреновине LineItem : weight и price . Хреновина LineItem порождает синие штуковины, у которых есть собственные атрибуты weight и price , где хранятся значения812  Дескрипторы атрибутов\n--- Страница 812 ---\nВведение в нотацию хреновин и штуковин После многократного объяснения дескрипторов я понял, что UML – не луч- ший способ показа связей между классами и экземплярами, в частности связи между управляемым классом и экземплярами дескриптора1. Поэтому я изо- брел собственный «язык», нотацию хреновин и штуковин (Mills & Gizmos Notation – MGN), который применяю для аннотирования UML-диаграмм. Задача MGN – провести четкое различие между классами и экземплярами. Взгляните на рис. 23.3. В MGN класс изображается «хреновиной» (mill) – слож - ной машиной, которая производит «штуковины» (gizmo). Классы-хреновины всегда являются машинами с ручками и циферблатами. Штуковины – это эк- земпляры, они выглядят гораздо проще. Цвет штуковины всегда совпадает с цветом создавшей его хреновины (если книга напечатана в цвете). Рис. 23.3. Набросок MGN, показывающий класс LineItem с тремя экземплярами и класс Quantity с двумя. Один экземпляр Quantity извлекает значение, хранящееся в экземпляре LineItem Для рассматриваемого примера я изобразил экземпляр LineItem в виде строки табличного счета-фактуры с тремя колонками, представляющими три атри- бута (description , weight и price). Поскольку экземпляры Quantity – дескрипторы, у них имеется лупа для получения значений методом __get__ и клешня для установки значений методом __set__. Когда мы перейдем к метаклассам, вы еще скажете мне спасибо за эти каракули. Но хватит рисовать каракули. Ниже приведен код: в примере 23.1 показан дескрипторный класс Quantity, а в примере 23.2 – новый класс LineItem с двумя экземплярами Quantity. Пример 23.1. bulkfood_v3.py: дескриптор Quantity не принимает отрицательных зна- чений class Quantity:  def __init__(self, storage_name): self.storage_name = storage_name  1 Классы и экземпляры изображаются на UML-диаграммах классов прямоугольника- ми. Между ними есть визуальные различия, но экземпляры встречаются на диаграм- мах классов так редко, что разработчики их не отличают. Пример дескриптора: проверка значений атрибутов  813\n--- Страница 813 ---\ndef __set__(self, instance, value):  if value > 0: instance.__dict__[self.storage_name] = value  else: msg = f'{self.storage_name} must be > 0' raise ValueError(msg) def __get__(self, instance, owner):  return instance.__dict__[self.storage_name]  Дескриптор основан на протоколе, для его реализации не требуется насле- дование.  В каждом экземпляре Quantity имеется атрибут storage_name : имя атрибута хранения, в котором хранится значение управляемого экземпляра.  Метод __set__ вызывается при любой попытке присвоить значение управ- ляемому атрибуту. В данном случае self – экземпляр дескриптора (т. е. LineItem.weight или LineItem.price ), instance – управляемый экземпляр (экзем- пляр LineItem), а value – присваиваемое значение.  Мы должны сохранить значение атрибута непосредственно в __dict__; по- пытка вызвать setattr(instance, self.storage_name) привела бы к повторному вызову метода __set__ и, стало быть, к бесконечной рекурсии.  Реализовать __get__ необходимо, потому что имя управляемого атрибута может не совпадать с storage_name . Про аргумент owner я расскажу ниже. Реализация __get__требуется, потому что пользователь мог бы написать что- то вроде: class House: rooms = Quantity('number_of_rooms') В классе House управляемым атрибутом является rooms, а атрибутом хране- ния number_of_rooms . Если имеется экземпляр House с именем chaos_manor , то чтение и запись chaos_manor.rooms проходят через дескриптор Quantity, присоединенный к rooms, но при чтении и записи chaos_manor.number_of_rooms дескриптор обходится. Отметим, что __get__ получает три аргумента: self, instance и owner. Аргумент owner – это ссылка на управляемый класс (например, LineItem), он полезен, если мы хотим, чтобы дескриптор поддерживал получение атрибута класса – быть может, чтобы эмулировать поведение Python по умолчанию – извлекать атри- бут класса, если указанного имени нет среди атрибутов экземпляра. Если управляемый атрибут, например weight, запрашивается через класс – LineItem.weight , – то метод __get__ дескриптора получает None в качестве значения аргумента instance. Для поддержки интроспекции и других приемов метапрограммирования пользователем рекомендуется возвращать из __get__ экземпляр дескриптора, если доступ к управляемому атрибуту производится через класс. Для этого код __get__ следовало бы написать так: def __get__(self, instance, owner): if instance is None: return self else: return instance.__dict__[self .storage_name]814  Дескрипторы атрибутов\n--- Страница 814 ---\nВ примере 23.2 демонстрируется использование класса Quantity в LineItem. Пример 23.2. bulkfood_v3.py: дескрипторы Quantity управляют атрибутами в LineItem class LineItem: weight = Quantity('weight')  price = Quantity('price')  def __init__(self, description, weight, price):  self.description = description self.weight = weight self.price = price def subtotal(self): return self .weight * self .price  Первый экземпляр дескриптора связывается с атрибутом weight.  Второй экземпляр дескриптора связывается с атрибутом price.  Оставшаяся часть тела класса так же проста и понятна, как первоначаль- ный код в файле bulkfood_v1.py (пример 22.19). В примере 20.1 управляемые атрибуты называются так же, как соответству - ющий атрибут хранения, и никакой особой логики чтения нет, поэтому метод __get__ в классе Quantity не нужен. Код из примера 20.1 работает, как и ожидается, – не позволяет продать трю- фели за 0 долларов1: >>> truffle = LineItem('White truffle', 100, 0) Traceback (most recent call last): ValueError: value must be > 0 Кодируя метод __set__, не забывайте, что означают аргументы self и instance: self – это экземпляр дескриптора, а instance – управляемый экземпляр. Дескрипторы, управляющие атри- бутами экземпляра, должны хранить значения в управляемых экземплярах. Потому-то Python и передает аргумент instance методам дескриптора. Может возникнуть соблазн хранить значения всех управляемых атрибутов в экземпляре самого дескриптора, т. е. в методе __set__ вместо кода instance.__dict__[self.storage_name] = value написать: self.__dict__[self.storage_name] = value Но это совершенно неправильно! Чтобы понять, почему, вспомните, что означают первые два аргумента __set__: self и instance. Здесь self – экземпляр 1 Белые трюфели стоят тысячи долларов за фунт. Запрет продажи трюфелей за $0.01 оставляю в качестве упражнения для увлеченных читателей. Я знаю человека, кото- рый купил энциклопедию статистики, стоящую 1800 долларов, за 18 долларов из-за ошибки в ПО интернет-магазина (не Amazon.com). Пример дескриптора: проверка значений атрибутов  815\n--- Страница 815 ---\nдескриптора, т. е. фактически атрибут класса, принадлежащий управляемому классу. Одновременно в памяти могут находиться тысячи экземпляров LineItem, но экземпляров дескрипторов будет только два: LineItem.weight и LineItem.price . Поэтому все, что вы сохраняете в самих экземплярах дескрипторов, становит - ся частью атрибута класса LineItem и, следовательно, распространяется на все экземпляры LineItem. В примере 23.2 есть недостаток – необходимость повторять имена атрибу - тов, когда в теле управляемого класса создаются экземпляры дескрипторов. Хорошо было бы иметь возможность объявить класс LineItem как-то так: class LineItem: weight = Quantity() price = Quantity() # прочие методы не изменяются В версии из примера 23.2 задавать имя при каждом вызове Quantity необ- ходимо явно, а это не только неудобно, но и опасно: если при копировании и вставке кода программист забудет изменить имена, т. е. напишет что-то вро- де price = Quantity('weight') , то программа будет работать совершенно непра- вильно: затирать значение weight при изменении price. Проблема в том – и мы видели это в главе 6, – что правая часть присваи- вания вычисляется еще до того, как начинает существовать переменная. Вы- ражение Quantity() призвано создать экземпляр дескриптора, но в этот момент код в классе Quantity никак не может узнать имя переменной, с которой этот дескриптор должен быть связан ( weight или price). К счастью, протокол дескрипторов теперь поддерживает специальный ме- тод, удачно названный __set_name__ . Ниже мы увидим, как он используется. Автоматическое генерирование имени атрибута хранения де- скриптора раньше было неприятной проблемой. В первом из- дании этой книги я посвятил несколько страниц и строк кода в этой и следующей главах различным ее решениям, вклю- чая использование декоратора класса, а затем и метаклассов. В Python 3.6 все стало намного проще. LineItem попытка № 4: автоматическое генерирование имен атрибутов хранения Чтобы не набирать повторно имя атрибута в объявлении дескриптора, мы реа- лизуем специальный метод __set_name__ , который будет устанавливать атрибут storage_name в каждом экземпляре Quantity. Этот метод был добавлен в протокол дескрипторов в версии Python 3.6. Интерпретатор вызывает __set_name__ для каждого дескриптора, который находит в теле class, – если дескриптор реали- зует его1. 1 Точнее, __set_name__ вызывается из type.__new__ – конструктора объектов, представ- ляющих классы. Встроенный тип type на самом деле является метаклассом – классом по умолчанию для определенных пользователем классов. Поначалу это трудно пере- варить, но не беспокойтесь: глава 24 посвящена динамическому конфигурированию классов, в т. ч. и концепции метаклассов. 816  Дескрипторы атрибутов\n--- Страница 816 ---\nВ примере 23.3 дескриптор LineItem не нуждается в методе __init__. Вместо этого __set_name__ сохраняет имя атрибута хранения. Пример 23.3. bulkfood_v4.py: __set_name__ устанавливает имя для каждого экземпляра дескриптора Quantity class Quantity: def __set_name__(self, owner, name):  self.storage_name = name  def __set__(self, instance, value):  if value > 0: instance .__dict__[self .storage_name] = value else: msg = f'{self.storage_name} must be > 0' raise ValueError(msg) # __get__ не нужен  class LineItem: weight = Quantity()  price = Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self .weight * self .price  self – экземпляр дескриптора (неуправляемый экземпляр), owner – управ- ляемый класс, а name – имя атрибута owner, которому был назначен этот де- скриптор в теле класса owner.  Это то, что делал __init__ в примере 23.1.  Метод __set__ здесь в точности такой же, как в примере 23.1.  Реализовывать __get__ необязательно, потому что имя атрибута хранения совпадает с именем управляемого атрибута. Выражение product.price полу - чает атрибут price непосредственно из экземпляра LineItem.  Теперь нам не нужно передавать имя управляемого атрибута конструктору Quantity. В этом и заключалась цель данной версии. Глядя на пример 23.3, можно подумать, что кода слишком много для управ- ления всего-то парой атрибутов, но важно понимать, что логика дескрипто- ра теперь вынесена в отдельную кодовую единицу: класс Quantity. Обычно мы не определяем дескриптор в том же модуле, в каком он используется, а заво- дим отдельный служебный модуль, предназначенный для использования во всем приложении, а то и во многих приложениях, если разрабатывается биб- лиотека или каркас. С учетом этого пример 23.4 лучше демонстрирует типичное использование дескриптора. Пример дескриптора: проверка значений атрибутов  817\n--- Страница 817 ---\nПример 23.4. bulkfood_v4c.py: ничем не загроможденное определение LineItem; де- скрипторный класс Quantity теперь вынесен в импортированный модуль model_v4c import model_v4c as model  class LineItem: weight = model.Quantity()  price = model.Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price  Импортировать модуль model_v4c, в котором реализован дескриптор Quantity.  Использовать model.Quantity . Пользователи Django, наверное, заметили, что пример 23.4 выглядит в точ- ности как определение модели. И это не случайность: поля моделей Django являются дескрипторами. Поскольку дескрипторы определяются в классах, мы можем воспользовать- ся наследованием, чтобы повторно использовать уже написанный код в новых дескрипторах. Этим мы и займемся в следующем разделе. LineItem попытка № 5: новый тип дескриптора Воображаемый магазин натуральных пищевых продуктов столкнулся с не- ожиданной проблемой: каким-то образом была создана строка заказа с пу - стым описанием, и теперь заказ невозможно выполнить. Чтобы предотвратить такие инциденты в будущем, мы создадим новый дескриптор, NonBlank. Про- ектируя NonBlank, мы обнаруживаем, что он очень похож на дескриптор Quantity, а отличается только логика проверки. Это наводит на мысль о рефакторинге и заведении двух базовых классов: за- вести абстрактный класс Validated, переопределяющий метод __set__, вызывая метод validate, который должен быть реализован в подклассах. Затем мы переписываем Quantity и реализуем NonBlank, наследуя классу Validated, так что остается лишь написать методы validate. Соотношение между классами Validated, Quantity и NonBlank – пример паттерна проектирования Шаблонный метод, который в классической книге «Паттерны проектирования» описывается следующим образом: Шаблонный метод определяет алгоритм в терминах абстрактных опера- ций, которые переопределяются в подклассах для обеспечения конкрет - ного поведения. В примере 23.5 Validated.__set__ – шаблонный метод, self.validate – абстракт - ная операция.818  Дескрипторы атрибутов\n--- Страница 818 ---\nПример 23.5. model_v5.py: абстрактный базовый класс Validated import abc class Validated(abc.ABC): def __set_name__(self, owner, name): self.storage_name = name def __set__(self, instance, value): value = self.validate(self.storage_name, value)  instance.__dict__[self.storage_name] = value  @abc.abstractmethod def validate(self, name, value):  \"\"\"вернуть проверенное значение или возбудить ValueError\"\"\"  Метод __set__ делегирует проверку методу validate …  … а затем использует возвращенное значение value, чтобы обновить храни- мое значение.  Метод validate абстрактный, это шаблонный метод. Алекс Мартелли предпочитает называть этот паттерн проектирования са- моделегированием, и я согласен, что это более подходящее название: первая строка __set__ делегирует работу методу validate того же класса1. Конкретными подклассами Validated в этом примере являются Quantity и NonBlank, они показаны в примере 23.6. Пример 23.6. model_v5.py: Quantity и NonBlank – конкретные подклассы Validated class Quantity(Validated): \"\"\"число, большее нуля\"\"\" def validate(self, name, value):  if value <= 0: raise ValueError(f'{name} must be > 0') return value class NonBlank(Validated): \"\"\"строка, содержащая хотя бы один символ, отличный от пробела\"\"\" def validate(self, name, value): value = value.strip() if not value:  raise ValueError(f'{name} cannot be blank') return value   Реализация шаблонного метода, которой требует абстрактный метод Validated.validate  Если после удаления начальных и конечных пробелов ничего не осталось, отвергнуть значение. 1 Слайд 50 лекции Алекса Мартелли «Python Design Patterns». Горячо рекомендую. Пример дескриптора: проверка значений атрибутов  819\n--- Страница 819 ---\n Требуя, чтобы конкретные методы validate возвращали проверенное зна- чение, мы оставляем им возможность очистить, преобразовать или норма- лизовать полученные данные. В данном случае значение value перед воз- вратом очищается от начальных и конечных пробелов. Пользователям модуля model_v5.py все эти детали знать необязательно. Важ- но лишь, что они получают возможность использовать классы Quantity и NonBlank для автоматизации проверки атрибутов экземпляра. Последняя версия класса LineItem приведена в примере 20.7. Пример 23.7. bulkfood_v5.py: использование дескрипторов Quantity и NonBlank в классе LineItem import model_v5 as model  class LineItem: description = model.NonBlank()  weight = model.Quantity() price = model.Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price  Импортировать модуль model_v5 и попутно сопоставить ему более короткое имя.  Использовать model.NonBlank . Больше ничего в коде не изменилось. Приведенные в этой главе варианты класса LineItem демонстрируют типичное применение дескрипторов для управления атрибутами-данными. Дескриптор, подобный Quantity, называют еще переопределяющим, поскольку его метод __set__ переопределяет (т. е. перехватывает и подменяет) установку одноименного атри- бута в управляемом экземпляре. Однако существуют и непереопределяющие де- скрипторы. Различие между ними мы подробно изучим в следующем разделе. переОпределяющие и непереОпределяющие деСкрипт Оры Напомним, что в способе обработки атрибутов в Python существует важная асимметрия. При чтении атрибута через экземпляр обычно возвращается атрибут, определенный в этом экземпляре, а если такого атрибута в экземпля- ре не существует, то атрибут класса. С другой стороны, в случае присваивания атрибуту экземпляра обычно создается атрибут в этом экземпляре, а класс во- обще никак не затрагивается. Эта асимметрия распространяется и на дескрипторы, в результате чего обра- зуются две категории дескрипторов, различающиеся наличием или отсутстви- ем метода __set__. Если __set__ присутствует, то класс является переопределяю- щим дескриптором, иначе непереопределяющим. Эти термины начнут обретать смысл, когда мы будем изучать поведение дескрипторов в следующих примерах.820  Дескрипторы атрибутов\n--- Страница 820 ---\nЧтобы увидеть отличия в поведении, нам понадобится несколько классов, и код в примере 23.8 станет нашим тестовым стендом. Все методы __get__ и __set__ в примере 20.8 вызывают print_args , чтобы их вызовы были отчетливо видны. Понимать, как устрое- ны вспомогательные функции print_args , cls_name и display, не- обязательно, так что не отвлекайтесь на них. Пример 23.8. descriptorkinds.py: простые классы для изучения поведения переопределяю- щих и непереопределяющих дескрипторов ### вспомогательные функции для отображения ### def cls_name(obj_or_cls): cls = type(obj_or_cls) if cls is type: cls = obj_or_cls return cls.__name__.split('.')[-1] def display(obj): cls = type(obj) if cls is type: return f'<class {obj.__name__}>' elif cls in [type(None), int]: return repr(obj) else: return f'<{cls_name(obj)} object>' def print_args(name, *args): pseudo_args = ', '.join(display(x) for x in args) print(f'-> {cls_name(args[0])}.__{name}__({pseudo_args})') ### существенные для этого примера классы ### class Overriding:  \"\"\"он же дескриптор данных или принудительный дескриптор\"\"\" def __get__(self, instance, owner): print_args('get', self, instance, owner)  def __set__(self, instance, value): print_args('set', self, instance, value) class OverridingNoGet:  \"\"\"переопределяющий дескриптор без ``__get__``\"\"\" def __set__(self, instance, value): print_args('set', self, instance, value) class NonOverriding:  \"\"\"он же дескриптор без данных или маскируемый дескриптор\"\"\" def __get__(self, instance, owner): print_args('get', self, instance, owner) Переопределяющие и непереопределяющие дескрипторы  821\n--- Страница 821 ---\nclass Managed:  over = Overriding() over_no_get = OverridingNoGet() non_over = NonOverriding() def spam(self):  print(f'-> Managed.spam({display(self)})')  Типичный переопределяющий дескрипторный класс с методами __get__ и __set__.  В этом примере функция print_args вызывается из каждого метода дескрип- тора.  Переопределяющий дескриптор без метода __get__.  Здесь нет метода __set__, т. е. этот дескриптор непереопределяющий.  Управляемый класс, в котором используется по одному экземпляру каждо- го дескрипторного класса.  Метод spam включен для сравнения, потому что методы – также дескрипторы. В следующих разделах мы исследуем поведение операций чтения и записи атрибутов класса Managed и одного его экземпляра с помощью каждого из опре- деленных выше дескрипторов. Переопределяющие дескрипторы Дескриптор, в котором реализован метод __set__, называется переопределяю- щим, потому что, несмотря на то что этот дескриптор является атрибутом клас - са, он перехватывает все попытки присвоить значение атрибутам экземпляра. Именно так реализован дескриптор в примере 23.2. Свойства также являются переопределяющими дескрипторами: если мы не предоставим свою функцию установки, то по умолчанию будет использован метод __set__ из класса property, который возбуждает исключение AttributeError , показывающее, что атрибут можно только читать. Эксперименты с переопределяющим дескриптором по- казаны в примере 23.9. Разработчики Python и авторы книг и статей при обсуждении этих понятий используют разные термины. Я остановился на термине «переопределяющий дескриптор» из книги «Python in a Nutshell». В официальной документации употребляется термин «дескриптор данных», но «переопределяющий дескриптор» луч- ше отражает его специальное поведение. Переопределяющие де- скрипторы также называют «принудительными дескрипторами». Синонимами термина «непереопределяющий дескриптор» явля- ются «дескриптор без данных» и «маскируемый дескриптор». Пример 23.9. Поведение переопределяющего дескриптора: obj.over – экземпляр класса Overriding (из примера 23.8) >>> obj = Managed()  >>> obj.over  -> Overriding.__get__(<Overriding object>, <Managed object>, <class Managed>) >>> Managed.over  822  Дескрипторы атрибутов\n--- Страница 822 ---\n-> Overriding.__get__(<Overriding object>, None, <class Managed>) >>> obj.over = 7  -> Overriding .__set__(<Overriding object>, <Managed object>, 7) >>> obj.over  -> Overriding.__get__(<Overriding object>, <Managed object>, <class Managed>) >>> obj.__dict__['over'] = 8  >>> vars(obj)  {'over': 8} >>> obj.over  -> Overriding.__get__(<Overriding object>, <Managed object>, <class Managed>)  Создать объект Managed для тестирования.  obj.over активирует метод дескриптора __get__, передавая ему управляемый экземпляр obj во втором аргументе.  Managed.over активирует метод дескриптора __get__, передавая ему None во втором аргументе ( instance).  Присваивание obj.over активирует метод дескриптора __set__, передавая ему значение 7 в последнем аргументе.  Чтение obj.over по-прежнему активирует метод дескриптора __get__.  Установка значения непосредственно в obj.__dict__ в обход дескриптора.  Проверить, что значение попало в obj.__dict__ и ассоциировано с ключом over.  Однако даже при наличии атрибута экземпляра с именем over дескриптор Managed.over все равно переопределяет попытки читать obj.over. Переопределяющий дескриптор без __get__ Свойства и другие переопределяющие дескрипторы, например поля моделей в Django, реализуют оба метода __set__ и __get__, но, как мы видели в приме- ре 23.2, можно также реализовать только __set__. В таком случае дескриптор обрабатывает только операцию записи. Чтение дескриптора через экземпляр вернет сам объект дескриптора, потому что не существует метода __get__, ко- торый мог бы перехватить эту операцию доступа. Если путем прямой записи в атрибут экземпляра __dict__ был создан одноименный атрибут экземпляра с другим значением, то метод __set__ все равно будет перехватывать последу - ющие попытки изменить этот атрибут, однако его чтение просто вернет новое значение атрибута, а не объект дескриптора. Другими словами, атрибут экзем- пляра маскирует дескриптор, но только при чтении. См. пример 23.10. Пример 23.10. Переопределяющий дескриптор без __get__ >>> obj.over_no_get  <__main__.OverridingNoGet object at 0x665bcc> >>> Managed.over_no_get  <__main__.OverridingNoGet object at 0x665bcc> >>> obj.over_no_get = 7  -> OverridingNoGet.__set__(<OverridingNoGet object>, <Managed object>, 7) >>> obj.over_no_get  <__main__.OverridingNoGet object at 0x665bcc> >>> obj.__dict__['over_no_get'] = 9  >>> obj.over_no_get 9 Переопределяющие и непереопределяющие дескрипторы  823\n--- Страница 823 ---\n>>> obj.over_no_get = 7  -> OverridingNoGet.__set__(<OverridingNoGet object>, <Managed object>, 7) >>> obj.over_no_get  9  В этом переопределяющем дескрипторе нет метода __get__, поэтому чтение obj.over_no_get извлекает экземпляр дескриптора из класса.  То же происходит, если извлечь экземпляр дескриптора непосредственно из управляемого класса.  Попытка присвоить значение атрибуту obj.over_no_get активирует метод де- скриптора __set__.  Поскольку наш метод __set__ не производит никаких изменений, повтор- ное чтение obj.over_no_get извлекает все тот же экземпляр дескриптора из управляемого класса.  Установить атрибут экземпляра с именем over_no_get через атрибут __dict__ экземпляра.  Теперь новый атрибут экземпляра over_no_get маскирует дескриптор, но только при чтении.  Попытка присвоить значение атрибуту obj.over_no_get по-прежнему прохо- дит через метод __set__ дескриптора.  Но при чтении дескриптор замаскирован до тех пор, пока существует од- ноименный атрибут экземпляра. Непереопределяющий дескриптор Дескриптор, в котором не реализован метод __set__, называется непереопре- деляющим. Установка атрибута экземпляра с таким же именем маскирует де- скриптор, делая его бесполезным для обработки соответствующего атрибута в этом экземпляре. Методы реализованы как непереопределяющие дескрип- торы. В примере 23.11 показана работа непереопределяющего дескриптора. Пример 23.11. Поведение непереопределяющего дескриптора >>> obj = Managed() >>> obj.non_over  -> NonOverriding.__get__(<NonOverriding object>, <Managed object>, <class Managed>) >>> obj.non_over = 7  >>> obj.non_over  7 >>> Managed.non_over  -> NonOverriding.__get__(<NonOverriding object>, None, <class Managed>) >>> del obj.non_over  >>> obj.non_over  -> NonOverriding.__get__(<NonOverriding object>, <Managed object>, <class Managed>)  obj.non_over активирует метод дескриптора __get__, передавая ему obj во вто- ром аргументе.  Managed.non_over – непереопределяющий дескриптор, поэтому не существует метода __set__, который мог бы вмешаться в эту операцию присваивания.  Теперь в obj есть атрибут экземпляра с именем non_over, который маскирует одноименный дескрипторный атрибут в классе Managed.824  Дескрипторы атрибутов\n--- Страница 824 ---\n Дескриптор Managed.non_over по-прежнему существует и перехватывает эту операцию доступа через класс.  Если атрибут экземпляра non_over удалить…  … то чтение obj.non_over активирует метод __get__ дескриптора в классе, од- нако вторым аргументом будет управляемый экземпляр. В предыдущих примерах мы видели несколько операций присваивания атрибуту экземпляра с таким же именем, как у дескриптора; результаты ока- зываются различны в зависимости от того, реализован в дескрипторе метод __set__ или нет. Установку атрибутов класса невозможно контролировать с помощью де- скрипторов, присоединенных к тому же классу. В частности, это означает, что сами дескрипторные атрибуты можно затереть путем присваивания на уровне класса, как объясняется в следующем разделе. Перезаписывание дескриптора в классе Независимо от того, является дескриптор переопределяющим или нет, его можно перезаписать путем присваивания на уровне класса. Это техника пар- тизанского латания, но в примере 23.12 дескрипторы подменяются целыми числами, что, безусловно, приведет к «поломке» любого класса, работа которо- го зависит от дескрипторов. Пример 23.12. Дескриптор можно перезаписать в самом классе >>> obj = Managed()  >>> Managed.over = 1  >>> Managed.over_no_get = 2 >>> Managed.non_over = 3 >>> obj.over, obj.over_no_get, obj.non_over  (1, 2, 3)  Создать новый экземпляр для последующего тестирования.  Перезаписать дескрипторные атрибуты в классе.  Дескрипторов больше нет. Пример 23.12 вскрывает еще одну асимметрию в чтении и записи атрибу - тов: хотя атрибут класса можно контролировать с помощью дескриптора с ме- тодом __get__, присоединенного к управляемому классу, но запись атрибута класса невозможно перехватить с помощью дескриптора с методом __set__, присоединенного к тому же классу. Чтобы контролировать установку атрибутов класса, необходи- мо присоединить дескрипторы к классу класса – иначе говоря, к метаклассу. По умолчанию метаклассом всех пользователь- ских классов является type, а добавить атрибут в класс type не- возможно. Но в главе 24 мы научимся создавать собственные метаклассы. Теперь поговорим о том, как дескрипторы используются в Python для реа- лизации методов. Переопределяющие и непереопределяющие дескрипторы  825\n--- Страница 825 ---\nметОды являют Ся деСкрипт Орами Функция внутри класса становится связанным методом, потому что у всех определенных пользователем функций имеется метод __get__, а значит, будучи присоединены к классу, они ведут себя как дескрипторы. В примере 23.13 де- монстрируется чтение метода spam из класса Managed примера 23.8. Пример 23.13. Метод является непереопределяющим дескриптором >>> obj = Managed() >>> obj.spam  <bound method Managed.spam of <descriptorkinds.Managed object at 0x74c80c>> >>> Managed.spam  <function Managed.spam at 0x734734> >>> obj.spam = 7  >>> obj.spam 7  Чтение obj.spam возвращает объект, представляющий связанный метод.  Однако чтение Managed.spam возвращает функцию.  Присваивание атрибуту obj.spam маскирует атрибут класса, делая метод spam недоступным через объект obj. Поскольку в функциях не реализован метод __set__, они являются непере- определяющими дескрипторами, что видно из последней строки примера 23.13. Еще отметим, что в примере 23.13 чтение obj.spam и Managed.spam дает раз- ные объекты. Как для любых дескрипторов, метод __get__ функции возвращает ссылку на себя, если доступ осуществляется через управляемый класс. Но при доступе через экземпляр метод __get__ функции возвращает объект связан- ного метода: вызываемый объект, который обертывает функцию и связывает управляемый экземпляр (например, obj) с первым аргументом функции (т. е. self) – точно так же, как делает функция functools.partial (см. раздел «Фиксация аргументов с помощью functools.partial» главы 7). Чтобы лучше понять этот механизм, рассмотрим пример 23.14. Пример 23.14. method_is_descriptor.py: класс Text, наследующий UserString import collections class Text(collections.UserString): def __repr__(self): return 'Text({!r})'.format(self.data) def reverse(self): return self[::-1] Исследуем работу метода Text.reverse . Пример 23.15. Эксперименты с методом >>> word = Text('forward') >>> word  Text('forward')826  Дескрипторы атрибутов\n--- Страница 826 ---\n>>> word.reverse()  Text('drawrof') >>> Text.reverse(Text('backward'))  Text('drawkcab') >>> type(Text.reverse), type(word.reverse)  (<class 'function'>, <class 'method'>) >>> list(map(Text.reverse, ['repaid', (10, 20, 30), Text('stressed')]))  ['diaper', (30, 20, 10), Text('desserts')] >>> Text.reverse.__get__(word)  <bound method Text.reverse of Text('forward')> >>> Text.reverse.__get__(None, Text)  <function Text.reverse at 0x101244e18> >>> word.reverse  <bound method Text.reverse of Text('forward')> >>> word.reverse.__self__  Text('forward') >>> word.reverse.__func__ is Text.reverse  True  Представление repr экземпляра Text выглядит как вызов конструктора Text, создающего точно такой же экземпляр.  Метод reverse возвращает инвертированный текст.  Метод, вызванный от имени класса, работает как функция.  Обратите внимание на различие типов function и method.  Метод Text.reverse работает как функция и применим даже к объектам, не являющимся экземплярами Text.  Любая функция является непереопределяющим дескриптором. Если вы- звать ее метод __get__ от имени экземпляра, то будет возвращен метод, связанный с этим экземпляром.  Если вызвать метод __get__, указав в качестве аргумента instance объект None, то будет возвращена сама функция.  Выражение word.reverse приводит к вызову Text.reverse.__get__(word) и возврату связанного метода.  У объекта связанного метода имеется атрибут __self__, в котором хранится ссылка на экземпляр, от имени которого вызывался метод.  В атрибуте __func__ связанного метода хранится ссылка на исходную функ - цию, присоединенную к управляемому классу. У объекта связанного метода имеется метод __call__, который и отвечает за активацию. Этот метод вызывает исходную функцию, на которую ссылается атрибут __func__, передавая ей атрибут метода __self__ в первом аргументе. Именно так работает неявное связывание с традиционным аргументом self. Превращение функций в связанные методы – основной пример использова- ния дескрипторов в инфраструктуре языка. Разобравшись с тем, как работают дескрипторы и методы, дадим несколько практических советов по их использованию. Методы являются дескрипторами  827\n--- Страница 827 ---\nСОветы пО иСпО льзОванию деСкрипт ОрОв Ниже перечислены некоторые практические последствия только что описан- ных характеристик дескрипторов. Для простоты пользуйтесь классом property Встроенный класс property создает переопределяющие дескрипторы, в ко- торых реализованы оба метода __set__ и __get__, даже если вы сами не за- давали метод установки1. Подразумеваемый по умолчанию метод __set__ возбуждает исключение AttributeError: can't set attribute , поэтому свойство – это простейший способ создать доступный только для чтения атрибут и из- бежать проблемы, описанной ниже. В дескрипторах только для чтения необходим метод __set__ Если вы используете дескрипторный класс для реализации атрибута, допус кающего только чтение, то не забывайте реализовывать оба метода __get__ и __set__, иначе одноименный атрибут экземпляра замаскирует де- скриптор. Метод __set__ атрибута, доступного только для чтения, должен просто возбуждать исключение AttributeError с подходящим сообщением2. Проверяющим дескрипторам достаточно одного метода __set__ Если дескриптор предназначен только для проверки значений, то метод __set__ должен проверять полученный аргумент value и, если он правилен, устанавливать значение непосредственно в атрибуте __dict__ экземпляра, ис- пользуя в качестве ключа имя экземпляра дескриптора. Тогда чтение атри- бута с таким же именем из экземпляра будет производиться максимально быстро, т. к. не требует наличия метода __get__. Код см. в примере 23.3. Кеширование можно эффективно реализовать при наличии одного лишь __get__ Если вы напишете только метод __get__, то получите непереопределяющий дескриптор. Они полезны, когда требуется выполнить накладные вычис - ления и кешировать результат, установив атрибут экземпляра с таким же именем3. Одноименный атрибут экземпляра маскирует дескриптор, поэто- му при последующем доступе к этому атрибуту значение будет извлекать- ся непосредственно из атрибута __dict__ экземпляра в обход метода __get__ дескриптора. Декоратор @functools.cached_property на самом деле порождает непереопределяющий дескриптор. 1 Метод __delete__ также предоставляется декоратором property, даже если вы сами не определяли никакого метода удаления. 2 Python не блещет единообразием в таких сообщениях. При попытке изменить атрибут c.real комплексного числа выдается сообщение AttributeError: read-only attribute , а при попытке изменить c.conjugate (метод класса complex) – сообщение AttributeError: 'complex' object attribute 'conjugate' is read-only . 3 Напомним, однако, что создание атрибутов экземпляра после выполнения метода __init__ отключает оптимизацию разделения ключей (см. раздел «Практические по- следствия внутреннего устройства класса dict» главы 3).828  Дескрипторы атрибутов\n--- Страница 828 ---\nНеспециальные методы можно замаскировать атрибутами экземпляра Поскольку в функциях и методах реализован только метод __get__, они не перехватывают попытки установить одноименные атрибуты экземпля- ра, так что после простого присваивания my_obj.the_method = 7 последующий доступ к the_method через данный экземпляр вернет число 7, хотя на других экземплярах это никак не отразится. Однако на специальные методы это не распространяется. Интерпретатор ищет специальные методы только в самом классе, т. е. repr(x) всегда вычисляется как x.__class__.__repr__(x) , так что наличие атрибута __repr__ в x не влияет на результат repr(x). По той же причине существование атрибута с именем __getattr__ в экземпляре не ис - портит обычный алгоритм доступа к атрибутам. Может показаться, что простота переопределения неспециальных методов в экземплярах влечет за собой хрупкость дизайна и ошибки, но в моей более чем 20-летней практике программирования на Python это ни разу не приво- дило к проблемам. С другой стороны, если вы часто создаете динамические атрибуты, имена которых берутся из данных, не контролируемых вами (как в предыдущих главах этой книги), то об этом следует помнить и, наверное, включить какую-то фильтрацию или экранирование имен, чтобы динамиче- ские атрибуты имели смысл. Класс FrozenJSON из примера 22.5 защищен от маскирования методов атрибутами экземпляра, потому что в нем есть толь- ко специальные методы и метод класса build. Методы класса безопасны, если обращение к ним производится только через класс, как в выражении FrozenJSON.build в примере 22.5 – ко- торое я впоследствии заменил методом __new__ в примере 22.6. Классы Record и Event, представленные в разделе «Вычисляемые свойства» главы 21, также безопасны: в них реализованы толь- ко специальные методы, статические методы и свойства. Свой- ства являются переопределяющими дескрипторами, поэтому не мас кируются атрибутами экземпляра. В заключение рассмотрим две особенности свойств, которые не были осве- щены в контексте дескрипторов: документирование и перехват попыток уда- лить управляемый атрибут. СтрОка дОкументации деСкрипт Ора и перехват удаления Строка документации дескрипторного класса нужна для документирования экземпляров дескриптора в управляемом классе. На рис. 23.4 показано, как выглядит справка по классу LineItem с дескрипторами Quantity и NonBlank из при- меров 23.6 и 23.7. Строка документации дескриптора и перехват удаления  829\n--- Страница 829 ---\nРис. 23.4. Оболочка Python после выполнения команд help(LineItem.weight) и help(LineItem) Это не вполне удовлетворительно. В случае LineItem неплохо было бы доба- вить информацию о том, что вес weight должен быть выражен в килограммах. Для свойств это тривиальная задача, потому что каждое свойство управляет одним конкретным атрибутом. Но дескрипторный класс Quantity используется для обоих атрибутов weight и price1. Вторая деталь, которую мы обсуждали для свойств, но опустили при рас- смотрении дескрипторов, – перехват попыток удалить управляемый атри- бут. Это можно сделать, реализовав метод __delete__ вместе или вместо обыч- ных методов __get__ и (или) __set__ в дескрипторном классе. Я сознательно опустил рассмотрение __delete__ , потому что на практике он редко находит применение. Если понадобится, загляните в раздел «Реализация дескрип- торов» документации по модели данных в Python (https://docs.python.org/3.10/ reference/datamodel.html# implementing-descriptors). Написание «дурацкого» де- скрипторного класса с методом __delete__ оставляю в качестве упражнения досужему читателю. 1 Задать текст справки для каждого экземпляра дескриптора на удивление трудно. Одно из возможных решений – динамически строить обертывающий класс для каж- дого экземпляра дескриптора.830  Дескрипторы атрибутов\n--- Страница 830 ---\nрезюме В начале главы мы продолжили тему класса LineItem из главы 22. В примере 23.2 мы заменили свойства дескрипторами. Мы видели, что дескриптор – это класс, экземпляры которого занимают место атрибутов в управляемом классе. Для обсуждения этого механизма пришлось ввести специальные термины, напри- мер управляемый экземпляр и атрибут хранения. В разделе «LineItem попытка № 4: автоматическая генерация имен атрибу - тов хранения» мы отказались от требования явно задавать в объявлениях де- скриптора Quantity параметр storage_name ; это избыточно и чревато ошибками. Решение состоит в том, чтобы реализовать в классе Quantity специальный метод __set_name__ , который будет сохранять имя управляемого свойства в виде self. storage_name . В разделе «LineItem попытка № 5: новый тип дескриптора» мы показали, как унаследовать абстрактному дескрипторному классу для повторного ис- пользования кода при построении специализированных дескрипторов с пере- секающейся функциональностью. Затем мы изучили поведение дескрипторов, включающих и не включающих метод __set__, отметив принципиальное различие между переопределяющими и непереопределяющими дескрипторами. Проведя детальное тестирование, мы поняли, когда дескрипторы перехватывают управление, а когда маскиру - ются, обходятся или затираются. После этого исследовали специальную категорию непереопределяющих де- скрипторов: методы. Тестирование на консоли показало, как благодаря про- токолу дескрипторов присоединенная к классу функция становится методом при обращении через экземпляр. Наконец, в разделе «Советы по использованию дескрипторов» было пред- ставлено несколько практических советов, а в разделе «Строка документации дескриптора и перехват удаления» приведены краткие сведения о документи- ровании дескрипторов. В разделе «Что нового в этой главе» было отмечено, что несколь- ко примеров стали значительно проще благодаря специальному методу __set_name__ протокола дескрипторов, который был до- бавлен в версии Python 3.6. Так работает эволюция языка! дОпО лнительная литература Помимо официального справочного материала в главе «Модель данных» (https://docs.python.org/3/reference/datamodel.html), ценным ресурсом является по- собие Раймонда Хэттингера «Descriptor HowTo Guide» (https://docs.python.org/3/ howto/descriptor.html), оно входит в подборку практических руководств (https:// docs.python.org/3/howto/descriptor.html), являющуюся частью официальной доку - ментации по Python. Как и во всем, что касается объектной модели в Python, книга Martelli, Ravenscroft, Holden «Python in a Nutshell», 3-е издание (O’Reilly), является ав- торитетным и объективным источником. Мартелли также подготовил презен- Дополнительная литература  831\n--- Страница 831 ---\nтацию «Python’s Object Model», в которой всесторонне рассматриваются свой- ства и дескрипторы (слайды – по адресу http://www.aleax.it/Python/nylug05_om.pdf, видео – по адресу https://www.youtube.com/watch?v=VOzvpHoYQoo). Имейте в виду, что любое описание дескрипторов, созданное до того, как в 2016 году был одобрен документ PEP 487, скорее все- го, содержит примеры, которые теперь можно считать чрезмер- но усложненными, потому что до версии 3.6 метод __set_name__ не поддерживался. За дополнительными практическими примерами обратитесь к книге Дэви- да Бизли и Брайана К. Джонса «Python Cookbook», 3-е издание (O’Reilly), где есть много рецептов, иллюстрирующих дескрипторы. Особо мне хочется отметить рецепты 6.12 «Чтение вложенных структур и имеющих переменную длину дво- ичных структур», 8.10 «Свойства с отложенным вычислением», 8.13 «Реализа- ция модели данных или системы типов» и 9.9 «Определение декораторов как классов». В последнем рецепте глубоко освещаются вопросы взаимодействия между декораторами функций, дескрипторами и методами и объясняется, почему декоратор функции, реализованный в виде класса с методом __call__, должен также реализовывать метод __get__, если его предполагается применять для декорирования не только функций, но и методов. В документе PEP 487 «Simpler customization of class creation» (https://peps. python.org/pep-0487/) описан специальный метод __set_name__ и имеется пример проверяющего дескриптора. Поговорим Дизайн self Требование явно объявлять self первым аргументом методов – одно из про- тиворечивых проектных решений в Python. После 23 лет использования язы- ка я к нему привык. Я думаю, что это решение – пример философии проекти- рования «чем хуже, тем лучше», описанной Ричардом П. Гэбриелом в работе «The Rise of Worse is Better» (https://dreamsongs.com/RiseOfWorseIsBetter.html). Важ- нейший приоритет в этой философии – «простота». Вот как это звучит в из- ложении Гэбриела: Реализация и интерфейс должны быть простыми. Простота реализа- ции даже важнее простоты интерфейса. Простота – самое важное тре- бование при выборе дизайна. Явный self в Python – воплощение этой философии проектирования. Просто- та – даже элегантность – реализации достигается за счет пользовательского интерфейса: сигнатура метода – def zfill(self, width) – визуально не соответ - ствует его вызову – label.zfill(8) . Это соглашение – и использование идентификатора self – впервые появилось в языке Modula-3, но есть и отличие: в Modula-3 интерфейсы объявляются от- дельно от реализации, и в объявлении интерфейса аргумент self опущен, по- этому, с точки зрения пользователя, у метода в объявлении интерфейса ровно столько же аргументов, сколько задается при его вызове. 832  Дескрипторы атрибутов\n--- Страница 832 ---\nСо временем сообщения об ошибках, касающиеся аргументов методов, стали понятнее. Если вызывается определенный пользователем метод с одним ар- гументом, кроме self, – obj.meth() , – то в Python 2.7 возбуждается исключение TypeError: meth() takes exactly 2 arguments (1 given) (meth() принимает ровно 2 аргумента (задан 1)), тогда как в Python 3 непонятно откуда взявшийся аргумент не упоминается, а указывается имя недостающего аргумента: TypeError: meth() missing 1 required positional argument: 'x' (при вызове meth() не задан 1 обязательный позиционный аргумент: ‘x’). Помимо использования self в качестве явного аргумента, мишенью для кри- тики часто становится требование указывать его при любом доступе к атри- бутам экземпляра. См., например, знаменитое сообщение А. М. Кухлинга «Бо- родавки Python» (http://web.archive.org/web/20031002184114/www.amk.ca/python/ writing/warts.html); самого Кухлинга не очень беспокоит квалификатор self, но он упоминает эту проблему в числе прочих, быть может, отражая мнения, высказанные в группе comp.lang.python . Лично меня необходимость набирать self не раздражает: я считаю, что полезно отличать локальные переменные от атрибутов. Я больше возражаю против использования self в предложении def. Всякий, кому не нравится явное использование self в Python, отнесется к нему гораздо снисходительнее, если взглянет на путаную семантику (https:// developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/this) неявного this в JavaScript. У Гвидо были основательные причины спроектировать self именно таким образом, и он написал о них в своем блоге «История Python» в статье «Adding Support for User-Defined Classes» (http://python-history.blogspot. com/2009/02/adding-support-for-user-defined-classes.html). Дополнительная литература  833",
      "debug": {
        "start_page": 809,
        "end_page": 832
      }
    },
    {
      "name": "Глава 24. Метапрограммирование классов 834",
      "content": "--- Страница 833 --- (продолжение)\nГлава 24 Метапрограммирование классов Известно, что отладка в два раза сложнее написания программы. Поэтому если вы были предельно хитроумны при написании программы, то что же вы будете делать при ее отладке? Брайан У. Керниган, Ф. Дж. Плоджер, «Элементы стиля программирования»1 Метапрограммирование классов – это искусство создания или настройки классов во время выполнения. Классы в Python – полноправные объекты, поэтому функ - ция может в любой момент создать новый класс, не используя ключевое слово class. Декораторы классов – также функции, которые дополнительно умеют инс- пектировать и изменять декорированный класс и даже заменять его другим. На- конец, метаклассы – самое продвинутое средство метапрограммирования клас - сов: они позволяют создавать целые категории классов со специальными харак - теристиками, например уже встречавшиеся нам абстрактные базовые классы. Метаклассы – мощный механизм, но оправдать его применение трудно, а пра- вильно пользоваться еще труднее. Декораторы классов решают многие из тех же проблем, а понять их проще. Кроме того, в Python 3.6 реализован документ PEP 487 «Simpler customization of class creation» (https://peps.python.org/pep-0487/), в котором описаны специальные методы, поддерживающие задачи, которые раньше требовали метаклассов или декораторов2. В этой главе приемы метапрограммирования изложены в порядке возрас - тания сложности. Эта тема настолько завораживает, что легко увлечься. Поэтому в самом начале главы я обязан дать следующий совет. Ради удобства чтения и сопровождения программы лучше от- кажитесь от использования описанных в этой главе приемов в коде приложения. С другой стороны, это именно то, что надо, если вы собираетесь написать очередной великий каркас на Python. 1 Цитата из главы 2 книги «Элементы стиля программирования», 2-е издание (М.: Ра- дио и связь, 1984, пер. с англ. В. А. Волынского). 2 Это не значит, что из-за PEP 487 код, в котором эти средства использовались, перестал работать. Просто код, в котором до версии Python 3.6 использовались метаклассы или де- кораторы классов, теперь можно переработать, сделав проще и, возможно, эффективнее.\nГлава 24 Метапрограммирование классов Известно, что отладка в два раза сложнее написания программы. Поэтому если вы были предельно хитроумны при написании программы, то что же вы будете делать при ее отладке? Брайан У. Керниган, Ф. Дж. Плоджер, «Элементы стиля программирования»1 Метапрограммирование классов – это искусство создания или настройки классов во время выполнения. Классы в Python – полноправные объекты, поэтому функ - ция может в любой момент создать новый класс, не используя ключевое слово class. Декораторы классов – также функции, которые дополнительно умеют инс- пектировать и изменять декорированный класс и даже заменять его другим. На- конец, метаклассы – самое продвинутое средство метапрограммирования клас - сов: они позволяют создавать целые категории классов со специальными харак - теристиками, например уже встречавшиеся нам абстрактные базовые классы. Метаклассы – мощный механизм, но оправдать его применение трудно, а пра- вильно пользоваться еще труднее. Декораторы классов решают многие из тех же проблем, а понять их проще. Кроме того, в Python 3.6 реализован документ PEP 487 «Simpler customization of class creation» (https://peps.python.org/pep-0487/), в котором описаны специальные методы, поддерживающие задачи, которые раньше требовали метаклассов или декораторов2. В этой главе приемы метапрограммирования изложены в порядке возрас - тания сложности. Эта тема настолько завораживает, что легко увлечься. Поэтому в самом начале главы я обязан дать следующий совет. Ради удобства чтения и сопровождения программы лучше от- кажитесь от использования описанных в этой главе приемов в коде приложения. С другой стороны, это именно то, что надо, если вы собираетесь написать очередной великий каркас на Python. 1 Цитата из главы 2 книги «Элементы стиля программирования», 2-е издание (М.: Ра- дио и связь, 1984, пер. с англ. В. А. Волынского). 2 Это не значит, что из-за PEP 487 код, в котором эти средства использовались, перестал работать. Просто код, в котором до версии Python 3.6 использовались метаклассы или де- кораторы классов, теперь можно переработать, сделав проще и, возможно, эффективнее.\n--- Страница 834 ---\nчтО нОвОг О в этОй главе Весь код из главы «Метапрограммирование классов» в первом издании книги по-прежнему работает правильно. Но некоторые примеры уже нельзя назвать самыми простыми решениями в свете новых возможностей, добавленных в версии Python 3.6 и последующих. Я заменил эти примеры другими, уделив внимание новым средствам мета- программирования в Python или добавив новые требования, чтобы оправдать использование более продвинутых приемов. В некоторых новых примерах ис- пользуются аннотации типов, чтобы предоставить построители классов, ана- логичные декоратору @dataclass и типу typing.NamedTuple . Раздел «Метаклассы на практике» новый, в нем рассматриваются некоторые общие соображения о применимости метаклассов. Один из лучших способов рефакторинга – удалить код, ставший излишним вследствие появления новых, более простых спосо- бов решения той же задачи. Это относится в равной мере к коду и к книгам. Мы начнем с обзора атрибутов и методов, определенных в модели данных Python для всех классов. клаССы как ОБъекты Как и большинство программных сущностей в Python, классы являются объ- ектами. Каждый класс имеет ряд атрибутов, определенных в модели данных Python и документированных в разделе 4.13 «Специальные атрибуты» (https:// docs.python.org/3/library/stdtypes.html#special-attributes) главы «Встроенные типы» справочного руководства по стандартной библиотеке. Три из них мы уже встречали ранее: __class__, __name__ и __mro__. Перечислим остальные. cls.__bases__ Кортеж, содержащий базовые классы данного класса. cls.__qualname__ Полное имя класса или функции, представляющее собой путь от глобаль- ной области видимости модуля к определению класса, компоненты которо- го разделены точками. Так, в классе из модели Django, например Ox (https:// docs.djangoproject.com/en/3.2/topics/db/models/#meta-options), имеется внутрен- ний класс с именем Meta. Атрибут __qualname__ класса Meta равен Ox.Meta, тог- да как __name__ равен просто Meta. Спецификация этого атрибута приведена в документе PEP-3155 «Qualified name for classes and functions» (http://www. python.org/dev/peps/pep-3155). cls.__subclasses__() Этот метод возвращает список непосредственных подклассов данного класса. В реализации применяются слабые ссылки, чтобы избежать цикли- ческих ссылок между суперклассом и его подклассами, – которые хранят сильную ссылку на суперклассы в атрибуте __bases__. В возвращенный спи- Классы как объекты  835\n--- Страница 835 ---\nсок включаются только подклассы, которые в настоящий момент загруже- ны в память. Подклассы в еще не загруженных модулях не видны. cls.mro() Интерпретатор вызывает этот метод при построении класса, чтобы полу - чить кортеж суперклассов, который хранится в атрибуте класса __mro__. Ме- такласс может переопределить этот метод и задать другой порядок разре- шения методов в конструируемом классе. Ни один из упоминаемых в этом разделе атрибутов не включа- ется в список, возвращаемый функцией dir(…). Но если класс – это объект, то что является классом класса? type: вСтрОенная фаБрика клаССОв Обычно мы воспринимаем type как функцию, которая возвращает класс объ- екта, потому что именно это делает выражение type(my_object) : возвращает my_object.__class__ . Однако type – это класс, который создает новый класс, если вызывается с тре- мя аргументами. Рассмотрим следующий простой класс: class MyClass(MySuperClass, MyMixin): x = 42 def x2(self): return self.x * 2 С помощью конструктора type мы можем создать MyClass во время выполне- ния: MyClass = type('MyClass', (MySuperClass, MyMixin), {'x': 42, 'x2': lambda self: self.x * 2}, ) Этот вызов type функционально эквивалентен предыдущему предложению блока class MyClass… . Прочитав предложение class, Python вызывает type, чтобы построить объект класса, и передает ему следующие параметры: name Идентификатор, расположенный после ключевого слова class, например MyClass. bases Кортеж суперклассов, расположенный в скобках после идентификатора класса, или (object,), если в предложении class нет суперклассов. 836  Метапрограммирование классов\n--- Страница 836 ---\ndict Отображение имен атрибутов на значения. Вызываемые объекты стано- вятся методами, как мы видели в разделе «Методы являются дескриптора- ми» главы 23. Другие значения становятся атрибутами класса. Конструктор type принимает факультативные именованные ар- гументы, которые игнорируются самим type, но передаются без изменения методу __init_subclass__ , который должен их потре- бить. Этот специальный метод мы изучим в разделе «Введение в __init_subclass__» ниже, но об использовании именованных аргументов я рассказывать не буду. Дополнительные сведения см. в документе PEP 487 «Simpler customization of class creation» (https://peps.python.org/pep-0487/). Классом type является метакласс: класс, который строит классы. Иными сло- вами, экземплярами класса type являются классы. В стандартной библиотеке есть и другие метаклассы, но type подразумевается по умолчанию: >>> type(7) <class 'int'> >>> type(int) <class 'type'> >>> type(OSError) <class 'type'> >>> class Whatever: pass >>> type(Whatever) <class 'type'> Мы будем строить собственные метаклассы в разделе «Основы метаклассов» ниже. А следующей нашей темой будет использование встроенного типа type для создания функции, которая строит классы. функция -фаБрика клаССОв В стандартной библиотеке есть фабрика классов, с которой мы уже неодно- кратно встречались: collections.namedtuple . В главе 5 мы также видели typing. NamedTuple и @dataclass . Во всех этих построителях классов используется техника, рассматриваемая в этой главе. Мы начнем с простой фабрики классов изменяемых объектов – простейшей возможной замены декоратора @dataclass . Предположим, что мы пишем приложение для зоомагазина и хотим обра- батывать данные о собаках как простые записи. Плохо, если придется писать такой стереотипный код: class Dog: def __init__(self, name, weight, owner): self.name = name self.weight = weight self.owner = owner Функция-фабрика классов  837\n--- Страница 837 ---\nНудно-то как… каждое имя поля встречается по три раза. И даже симпатич- ного представления repr мы при этом не получили: >>> rex = Dog('Rex', 30, 'Bob') >>> rex <__main__.Dog object at 0x2865bac> Позаимствовав идею у collections.namedtuple , напишем функцию record_factory , которая будет создавать простые классы вроде Dog на лету. В примере 24.1 по- казано, как она должна работать. Пример 24.1. Тестирование record_factory , простой фабрики классов >>> Dog = record_factory('Dog', 'name weight owner')  >>> rex = Dog('Rex', 30, 'Bob') >>> rex  Dog(name='Rex', weight=30, owner='Bob') >>> name, weight, _ = rex  >>> name, weight ('Rex', 30) >>> \"{2}'s dog weighs {1}kg\".format(*rex)  \"Bob's dog weighs 30kg\" >>> rex.weight = 32  >>> rex Dog(name='Rex', weight=32, owner='Bob') >>> Dog.__mro__  (<class 'factories.Dog'>, <class 'object'>)  Фабрику можно вызывать как namedtuple : имя класса, а за ним строка имен атрибутов через пробел.  Удобное представление repr.  Экземпляры являются итерируемыми объектами, поэтому их можно рас- паковывать в момент присваивания …  … или при передаче функциям типа format.  Экземпляр записи изменяемый.  Вновь созданный класс наследует object – никакой связи с нашей фабрикой нет. Код record_factory приведен в примере 24.21. Пример 24.2. record_factory.py: простая фабрика классов from typing import Union, Any from collections.abc import Iterable, Iterator FieldNames = Union[str, Iterable[str]]  def record_factory(cls_name: str, field_names: FieldNames) -> type[tuple]:  slots = parse_identifiers(field_names)  def __init__(self, *args, **kwargs) -> None:  attrs = dict(zip(self.__slots__, args)) attrs .update(kwargs) 1 Спасибо моему другу Х. С. Буэно, предложившему это решение.838  Метапрограммирование классов\n--- Страница 838 ---\nfor name, value in attrs.items(): setattr(self, name, value) def __iter__(self) -> Iterator[Any]:  for name in self.__slots__: yield getattr(self, name) def __repr__(self):  values = ', '.join(f'{name}={value!r}' for name, value in zip(self.__slots__, self)) cls_name = self.__class__.__name__ return f'{cls_name}({values})' cls_attrs = dict(  __slots__=slots, __init__=__init__, __iter__=__iter__, __repr__=__repr__, ) return type(cls_name, (object,), cls_attrs)  def parse_identifiers(names: FieldNames) -> tuple[str, ]: if isinstance(names, str): names = names.replace(',', ' ').split()  if not all(s.isidentifier() for s in names): raise ValueError('names must all be valid identifiers') return tuple(names)  Пользователь может предоставить имена полей в виде одной строки или итерируемого объекта строк.  Принимаем такие же аргументы, как первые два в collections.namedtuple ; воз- вращаем type, т. е. класс, который ведет себя как кортеж.  Построить кортеж имен атрибутов, он станет атрибутом __slots__ нового класса.  Эта функция станет методом __init__ в новом классе. Она принимает по- зиционные и (или) именованные аргументы1.  Отдавать значения полей в порядке, определяемом атрибутом __slots__.  Породить удобное представление, обходя __slots__ и self.  Построить словарь атрибутов класса.  Построить и вернуть новый класс, вызывая конструктор type.  Преобразовать строку names, в которой имена разделены пробелами или за- пятыми, в список строк. Пример 24.2 – первый случай, когда мы встретили type в аннотации типа. Если бы аннотация содержала просто -> type, это значило бы, что record_factory возвращает класс, – и было бы правильно. Но аннотация -> type[tuple] более точна: она говорит, что возвращенный класс будет подклассом tuple. 1 Я не стал добавлять аннотации типов для аргументов, потому что фактические типы – Any. Аннотацию типа возвращаемого значения я включил, потому что иначе Mypy не стала бы заглядывать внутрь метода. Функция-фабрика классов  839\n--- Страница 839 ---\nВ последней строке функции record_factory строится класс с именем, равным значению cls_name. Он наследует object, а в его пространство имен загружены атрибуты __slots__, __init__, __iter__ и __repr__, последние три из которых являют - ся методами экземпляра. Мы могли бы назвать атрибут класса __slots__ как-то иначе, но тогда при- шлось бы реализовывать метод __setattr__ , проверяющий имена атрибутов, ко- торым присваиваются значения, потому что мы хотим, чтобы в наших классах, подобных записям, набор атрибутов всегда был один и тот же и чтобы атри- буты в нем следовали в одном и том же порядке. Напомню, однако, что ос- новное назначение __slots__ – экономия памяти в случае, когда экземпляров миллионы, и что использование __slots__ сопряжено с некоторыми недостат - ками, описанными в разделе «Экономия памяти с помощью атрибута класса __slots__» главы 11. Экземпляры классов, созданных с помощью record_factory , не се- риализуемы, т. е. их нельзя экспортировать функцией dump из мо- дуля pickle. Решение этой проблемы выходит за рамки рассматри- ваемого примера, цель которого – продемонстрировать исполь- зование класса type в простом случае. Полное решение смотрите в исходном коде collections.namedtuple (https://github.com/python/ cpython/blob/3.9/Lib/collections/ __init__.py); ищите слово «pickling». Теперь посмотрим, как эмулировать более современные построители клас - сов, например typing.NamedTuple , который принимает пользовательский класс в виде предложения class и автоматически наделяет его дополнительной функ - циональностью. Введение в __init_subclass__ Оба метода, __init_subclass__ и __set_name__ , были предложены в документе PEP 487 «Simpler customization of class creation» (https://peps.python.org/pep-0487/). С при- менением специального метода __set_name__ в дескрипторах мы познакомились в разделе «LineItem попытка № 4: автоматическое генерирование имен атри- бутов хранения» главы 23. А теперь рассмотрим метод __init_subclass__ . В главе 5 мы видели, что typing.NamedTuple и @dataclass позволяют использовать предложение class для задания атрибутов нового класса, в который построи- тель классов затем добавляет методы __init__, __repr__, __eq__ и т. д. Чтобы дополнить класс, оба построителя классов читают аннотации типов в заданном пользователем предложении class. Те же самые аннотации позво- ляют программам проверки типов проверить код, который читает или уста- навливает эти атрибуты. Однако NamedTuple и @dataclass не пользуются аннота- циями типов для проверки атрибутов во время выполнения. Зато это делает класс Checked, рассматриваемый в следующем примере. Невозможно поддержать любую мыслимую статическую анно- тацию типа при проверке на этапе выполнения. Наверное, по- этому typing.NamedTuple и @dataclass даже не пытаются это делать. Однако некоторые типы, являющиеся конкретными классами, можно использовать в сочетании с Checked. К ним относятся прос тые типы, часто используемые для полей, например str, int, float и bool, а также списки значений таких типов. 840  Метапрограммирование классов\n--- Страница 840 ---\nВ примере 24.3 показано, как использовать Checked для построения Movie. Пример 24.3. initsub/checkedlib.py: тест создания подкласса Movie класса Checked >>> class Movie(Checked):  title: str  year: int box_office: float >>> movie = Movie(title='The Godfather', year=1972, box_office=137)  >>> movie.title 'The Godfather' >>> movie  Movie(title='The Godfather', year=1972, box_office=137.0)  Movie наследует классу Checked, который будет определен в примере 24.5.  Каждый атрибут аннотируется конструктором. В данном случае я исполь- зовал встроенные типы.  При создании экземпляров Movie можно задавать только именованные ар- гументы.  В награду мы получаем удобное представление, созданное методом __repr__. В роли конструктора, используемого в качестве аннотации типа атрибута, может выступать любой вызываемый объект, который принимает нуль или бо- лее аргументов и возвращает значение, совместимое с требуемым типом поля, или отвергает аргумент, возбуждая исключение TypeError или ValueError . Использование встроенных типов для аннотаций в примере 24.3 означает, что значения должны приниматься конструктором типа. В случае int этому условию удовлетворяет любое x такое, что int(x) возвращает int. В случае str подойдет во- обще любое значение, потому что str(x) в Python работает для любого x1. При вызове без аргументов конструктор должен возвращать значение свое- го типа по умолчанию2. Это стандартное поведение встроенных в Python конструкторов: >>> int(), float(), bool(), str(), list(), dict(), set() (0, 0.0, False, '', [], {}, set()) В подклассах Checked, в частности Movie, для отсутствующих параметров соз- даются значения по умолчанию, возвращаемые конструкторами полей. На- пример: >>> Movie(title='Life of Brian') Movie(title='Life of Brian', year=0, box_office=0.0) 1 Это справедливо для любого объекта, если только его класс не переопределяет методы __str__ или __repr__, унаследованные от объекта с некорректной реализацией. 2 При таком решении нельзя будет задавать None в качестве значения по умолчанию. Избегать null-значений вообще правильно. Вообще говоря, эта цель труднодостижи- ма, но в некоторых частных случаях не вызывает сложностей. В Python, как и в SQL, я предпочитаю представлять отсутствие данных в текстовом поле пустой строкой, а не None или NULL. Изучение Go укрепило меня в этой идее: в Go переменные и поля прими- тивных типов в структурах по умолчанию инициализируются «нулевым значением». См. раздел «Zero values» в онлайновой «Экскурсии по Go» (https://go.dev/tour/basics/12), если вам интересно. Функция-фабрика классов  841\n--- Страница 841 ---\nКонструкторы используются для проверки во время создания экземпляра и когда атрибуту присваивается значение непосредственно: >>> blockbuster = Movie(title='Avatar', year=2009, box_office='billions') Traceback (most recent call last): TypeError: 'billions' is not compatible with box_office:float >>> movie.year = 'MCMLXXII' Traceback (most recent call last): TypeError: 'MCMLXXII' is not compatible with year:int Подклассы Checked и статическая проверка типов При проверке исходного py-файла, содержащего экземпляр класса Movie, определенного в примере 24.3, Mypy помечает сле- дующее присваивание как ошибку: movie.year = 'MCMLXXII' Однако Mypy не может обнаружить ошибки типизации в таком вызове конструктора: blockbuster = Movie(title='Avatar', year='MMIX') Объясняется это тем, что Movie наследует метод Checked.__init__ , а сигнатура этого метода обязана принимать любые именован- ные аргументы, чтобы поддержать произвольные определенные пользователем классы. С другой стороны, если объявить в подклассе Checked поле с ан- нотацией типа list[float] , то Mypy сможет распознать ошибку при присваивании ему списка с несовместимыми данными, но Checked будет игнорировать такой параметр-тип и рассматри- вать его так же, как list. Теперь рассмотрим реализацию checkedlib.py. Начнем с дескрипторного класса Field, показанного в примере 24.4. Пример 24.4. initsub/checkedlib.py: дескрипторный класс Field from collections.abc import Callable  from typing import Any, NoReturn, get_type_hints class Field: def __init__(self, name: str, constructor: Callable) -> None:  if not callable(constructor) or constructor is type(None):  raise TypeError(f'{name!r} type hint must be callable') self.name = name self.constructor = constructor def __set__(self, instance: Any, value: Any) -> None: if value is :  value = self.constructor() else: try: value = self.constructor(value)  except (TypeError, ValueError) as e:  type_name = self.constructor.__name__ 842  Метапрограммирование классов\n--- Страница 842 ---\nmsg = f'{value!r} is not compatible with {self.name}:{type_name}' raise TypeError(msg) from e instance .__dict__[self .name] = value   Напомним, что начиная с Python 3.9 тип Callable в аннотациях – это ABC из модуля collections.abc , а не объявленный нерекомендуемым тип typing. Callable.  Это минимальная аннотация типа Callable; параметр-тип и тип возвращае- мого значения constructor неявно равны Any.  Для проверки типа во время выполнения используется встроенная функ - ция callable1. Проверка на type(None) необходима, потому что Python воспри- нимает None в типе как NoneType, класс None (и потому вызываемый объект), а не как бесполезный конструктор, который только возвращает None.  Если Checked.__init__ присваивает value значение (встроенный объект Ellipsis), то мы вызываем constructor без аргументов.  В противном случае вызываем constructor с заданным значением value.  Если constructor возбуждает одно из этих исключений, то возбуждаем TypeError с содержательным сообщением, в котором указаны имена поля и конструктора, например 'MMIX' is not compatible with year:int .  Если исключений не было, то value сохраняется в instance.__dict__ . В методе __set__ мы должны перехватывать исключения TypeError и ValueError , потому что встроенные конструкторы могут возбуждать любое из них в за- висимости от аргумента. Например, float(None) возбуждает TypeError, но float('A') возбуждает ValueError . С другой стороны, float('8') не возбуждает исключений и возвращает 8.0. Тем самым я заявляю, что в данном демонстрационном при- мере это предусмотренное поведение, а не ошибка. В разделе «LineItem попытка № 4: автоматическое именова- ние атрибутов хранения» главы 23 мы видели, как использует - ся специальный метод __set_name__ для дескрипторов. В классе Field он нам не нужен, потому что экземпляры дескрипторов в исходном коде клиента не создаются; пользователь объявля- ет типы, являющиеся конструкторами, как мы видели в классе Movie (пример 24.3). Что же касается экземпляров дескрип- тора Field, то они создаются во время выполнения методом Checked.__init_subclass__ , как будет показано в примере 24.5. Теперь обратимся к классу Checked. Я разбил его код на две части. В приме- ре 24.5 показано начало класса, куда вошли наиболее важные методы. Осталь- ные методы показаны в примере 24.6. Пример 24.5. initsub/checkedlib.py: наиболее важные методы класса Checked class Checked: @classmethod def _fields(cls) -> dict[str, type]:  return get_type_hints(cls) 1 Я считаю, что callable следует сделать допустимым в аннотациях типов. По состоя- нию на 6 мая 2021 года этот вопрос оставался открытым. Функция-фабрика классов  843\n--- Страница 843 ---\ndef __init_subclass__(subclass) -> None:  super().__init_subclass__()  for name, constructor in subclass._fields().items():  setattr(subclass, name, Field(name, constructor))  def __init__(self, **kwargs: Any) -> None: for name in self._fields():  value = kwargs .pop(name, )  setattr(self, name, value)  if kwargs:  self.__flag_unknown_attrs(*kwargs)   Этот метод класса я написал, чтобы скрыть вызов typing.get_type_hints от остального класса. Если бы нужно было поддерживать только версии Python ≥ 3.10, то я бы вызвал inspect.get_annotations . Проблемы, связанные с этими функциями, описаны в разделе «Проблемы с аннотациями во вре- мя выполнения» главы 15.  __init_subclass__ вызывается, когда определяется подкласс текущего клас - са. Он получает новый подкласс в первом аргументе, именно поэтому я назвал аргумент subclass, а не cls, как обычно. Дополнительные сведе- ния по этому вопросу см. во врезке «__init_subclass__ – не обычный метод класса» ниже.  Вызов super().__init_subclass__() , строго говоря, не является необходимым, но полезен для правильного взаимодействия с другими классами, кото- рые реализовали .__init_subclass__() в том же графе наследования. См. раз- дел «Множественное наследование и порядок разрешения методов» гла- вы 14.  Обойти все поля name и constructor …  … создавая в subclass атрибут с данным именем name, связанный с дескрип- тором Field с параметрами name и constructor .  Для каждого поля класса name …  … получить соответствующее значение value из kwargs и удалить его из kwargs. Использование (объект Ellipsis) в качестве значения по умолчанию по- зволяет отличить заданные аргументы со значением None от незаданных1.  Этот вызов setattr вызывает срабатывание метода Checked.__setattr__ , пока- занного в примере 24.6.  Если в kwargs остались аргументы, то их имена не совпадают ни с одним из объявленных полей, и __init__ завершается ошибкой.  Об этой ошибке сообщает метод __flag_unknown_attrs , показанный в приме- ре 24.6. Он принимает аргумент *names, содержащий имена неизвестных атрибутов. Я использовал в *kwargs одну звездочку, чтобы передать ключи в виде последовательности аргументов. 1 Как отмечалось в разделе «Циклы, сигнальные маркеры и отравленные таблетки» главы 19, объект Ellipsis – удобный и безопасный сигнальный маркер. Он существует уже давно, но в последнее время ему нашлись новые применения, например в анно- тациях типов и в NumPy.844  Метапрограммирование классов\n--- Страница 844 ---\n__init_subclass__ – не обычный метод класса Декоратор @classmethod никогда не применяется к методу __init_subclass__ , но это не так важно, потому что специальный метод __new__ ведет себя как метод класса даже без @classmethod . Первый аргумент, который Python передает методу __init_ subclass__ , – это класс. Но отнюдь не класс, в котором реализован __init_subclass__ , а вновь определенный подкласс этого класса. Это непохоже на __new__ и на все остальные известные мне методы класса. Поэтому я считаю, что __init_subclass__ не является методом класса в обычном смысле слова и называть его первый ар- гумент cls было бы неразумно и только сбивало бы с толку. В документации по __init_suclass__ (https://docs.python.org/3/reference/datamodel.html#object.__init_subclass__) аргумент назван cls, но далее приводится пояснение: «… вызывается, когда созда- ется подкласс объемлющего класса. В этот момент cls – новый подкласс». Теперь рассмотрим остальные методы класса Checked. Имена методов _fields и _asdict начинаются знаком подчеркивания по той же причине, что в API класса collections.namedtuple : чтобы уменьшить вероятность конфликта с имена- ми определенных пользователем полей. Пример 24.6. initsub/checkedlib.py: остальные методы класса Checked def __setattr__(self, name: str, value: Any) -> None:  if name in self._fields():  cls = self.__class__ descriptor = getattr(cls, name) descriptor.__set__(self, value)  else: self.__flag_unknown_attrs(name)  def __flag_unknown_attrs(self, *names: str) -> NoReturn:  plural = 's' if len(names) > 1 else '' extra = ', '.join(f'{name!r}' for name in names) cls_name = repr(self.__class__.__name__) raise AttributeError(f'{cls_name} object has no attribute{plural} {extra}') def _asdict(self) -> dict[str, Any]:  return { name: getattr(self, name) for name, attr in self.__class__.__dict__ .items() if isinstance(attr, Field) } def __repr__(self) -> str:  kwargs = ', '.join( f'{key}={value!r}' for key, value in self._asdict().items() ) return f'{self.__class__.__name__}({kwargs})'  Перехватывать все попытки установить атрибут экземпляра. Необходимо, чтобы предотвратить присваивание неизвестному атрибуту.  Если атрибут с именем name известен, получить соответствующий де- скриптор. Функция-фабрика классов  845\n--- Страница 845 ---\n Обычно нам нет нужды вызывать метод __set__ дескриптора явно. Но в дан- ном случае это необходимо, потому что __setattr__ перехватывает все по- пытки установить атрибут экземпляра, даже при наличии переопределяю- щего дескриптора типа Field1.  В противном случае атрибут с именем name неизвестен, и метод __flag_unknown_ attrs возбуждает исключение.  Сконструировать полезное сообщение об ошибке, содержащее все неожи- данные аргументы, и возбудить исключение AttributeError . Это редкий при- мер специального типа NoReturn, рассмотренного в одноименном разделе главы 8.  Создать словарь, содержащий атрибуты объекта Movie. Я предпочел бы на- звать этот метод _as_dict, но решил последовать соглашению, заложенному методом _asdict в классе collections.namedtuple .  Желание реализовать полезное представление в методе __repr__ – основная причина наличия метода _asdict в этом примере. В примере Checked показано, как быть с переопределяющими дескриптора- ми при реализации метода __setattr__ , чтобы блокировать попытки присвоить значение произвольному атрибуту после создания экземпляра. Стоит ли реа- лизовывать __setattr__ в этом примере – спорный вопрос. Без него присваива- ние movie.director = 'Greta Gerwig' прошло бы успешно, но атрибут director в лю- бом случае не проверяется, поэтому он не появился бы в __repr__ и не был бы включен в словарь, возвращаемый методом _asdict (оба этих метода определе- ны в примере 24.6). В скрипте record_factory.py (пример 24.2) я решил эту проблему с помощью атрибута класса __slots__. Однако в данном случае это более простое решение не годится по причине, объясняемой ниже. Почему __init_subclass__ не может конфигурировать __slots__ Атрибут __slots__ дает эффект, только если это один из элементов в про- странстве имен класса, передаваемого type.__new__ . Добавление __slots__ в уже сущест вующий класс не дает ничего. Python вызывает __init_subclass__ только после того, как класс уже построен – слишком поздно для конфигурирования __slots__. Декоратор класса тоже не может сконфигурировать __slots__, потому что применяется еще позже, чем __init_subclass__ . Мы рассмотрим эти вопросы в разделе «Что когда происходит: этап импорта и этап выполнения» ниже. Чтобы сконфигурировать __slots__ во время выполнения, ваш код должен са- мостоятельно построить пространство имен класса, передаваемое в качестве последнего аргумента методу type.__new__ . Для этого можно написать фабрич- ную функцию наподобие той, что была показана в скрипте record_factory.py, или пойти на крайние меры и реализовать метакласс. Как динамически кон- фигурировать __slots__, мы увидим в разделе «Основы метаклассов» ниже. До того, как в документе PEP 487 (https://peps.python.org/pep-0487/) было предложено упростить настройку создания класса с помощью метода __init_ subclass__ , а в версии Python 3.7 это предложение было реализовано, подобную 1 Тонкая концепция переопределяющего дескриптора обсуждалась в главе 23.846  Метапрограммирование классов\n--- Страница 846 ---\nфункциональность приходилось реализовывать с помощью декоратора клас - сов. Это тема следующего раздела. дОпО лнение клаССа С пОмОщью декОрат Ора клаССа Декоратор класса – это вызываемый объект, который ведет себя как декоратор функции: получает декорированный класс в качестве аргумента и возвращает заменяющий его класс. Часто декораторы классов возвращают сам декориро- ванный класс после внедрения в него новых методов с помощью присваива- ния атрибутам. Пожалуй, самая распространенная причина предпочесть декоратор класса более простому методу __init_subclass__ – желание избежать интерференции с другими возможностями классов, в т. ч. наследованием и метаклассами1. В этом разделе мы изучим скрипт checkeddeco.py, который представляет ту же функциональность, что checkedlib.py, но с помощью декоратора клас - са. Как обычно, начнем с примера использования, взятого из тестов в файле checkeddeco.py (пример 24.7). Пример 24.7. checkeddeco.py: создание класса Movie, снабженного декоратором @checked >>> @checked class Movie: title: str year: int box_office: float >>> movie = Movie(title='The Godfather', year=1972, box_office=137) >>> movie.title 'The Godfather' >>> movie Movie(title='The Godfather', year=1972, box_office=137.0) Единственное различие между примерами 24.7 и 24.3 – способ объявления класса Movie: он снабжен декоратором @checked, а не наследует Checked. Со стороны поведение обеих версий выглядит одинаково, включая проверку типов и при- сваивание значений по умолчанию, показанные после примера 24.3 в разделе «Введение в __init_subclass__». Теперь обратимся к реализации checkeddeco.py. Предложения импорта и класс Field такие же, как в checkedlib.py (пример 24.4). В checkeddeco.py нет больше никаких классов, только функции. Логика, которая раньше была реализована в __init_subclass__ , теперь перене- сена в функцию checked – декоратор класса, показанный в примере 24.8. Пример 24.8. checkeddeco.py: декоратор класса def checked(cls: type) -> type:  for name, constructor in _fields(cls).items():  setattr(cls, name, Field(name, constructor))  1 Это обоснование выдвигается в реферате документа PEP 557 «Data Classes» (https:// peps.python.org/pep-0557/#abstract), чтобы объяснить, почему была выбрана реализация в виде декоратора класса. Дополнение класса с помощью декоратора класса  847\n--- Страница 847 ---\ncls._fields = classmethod(_fields) # type: ignore  instance_methods = (  __init__, __repr__, __setattr__, _asdict, __flag_unknown_attrs, ) for method in instance_methods:  setattr(cls, method.__name__, method) return cls   Напомним, что классы – это экземпляры type. Эти аннотации типов позво- ляют предположить, что мы имеем дело с декоратором класса: он прини- мает и возвращает класс.  _fields – функция верхнего уровня, определенная в модуле позднее (в при- мере 24.9).  Замена каждого атрибута, возвращенного _fields, экземпляром дескриптора Field – то, что делал метод __init_subclass__ в примере 24.5. Здесь нам пред- стоит больше работы…  Построить метод класса по _fields и добавить его в декорированный класс. Комментарий type: ignore необходим, т. к. Mypy ругается, что в type нет атрибута _fields.  Функции уровня модуля станут методами экземпляра в декорированном классе.  Добавить все элементы instance_methods в cls.  Вернуть декорированный cls, выполнив основной контракт декоратора класса. Имена всех функций верхнего уровня в checkeddeco.py начинаются знаком подчеркивания, кроме декоратора checked. Это соглашение об именовании име- ет смысл по двум причинам: checked является частью открытого интерфейса модуля checkeddeco.py, а остальные функции – нет; функции из примера 24.9 будут внедрены в декорированный класс, и префикс _ уменьшает вероятность конфликтов имени с определенны- ми пользователем атрибутами и методами этого класса. Оставшаяся часть checkeddeco.py приведена в примере 24.9. Код этих функ - ций верхнего уровня такой же, как у соответственных методов класса Checked из файла checkedlib.py. Все пояснения были даны в примерах 24.5 и 24.6. Отметим, что у функции _fields двоякая роль в файле checkeddeco.py. В пер- вой строке декоратора checked она используется как обычная функция, а затем внед ряется в качестве метода декорированного класса. Пример 24.9. checkeddeco.py: методы, внедряемые в декорированный класс def _fields(cls: type) -> dict[str, type]: return get_type_hints(cls)848  Метапрограммирование классов\n--- Страница 848 ---\ndef __init__(self: Any, **kwargs: Any) -> None: for name in self._fields(): value = kwargs.pop(name, ) setattr(self, name, value) if kwargs: self.__flag_unknown_attrs(*kwargs) def __setattr__(self: Any, name: str, value: Any) -> None: if name in self._fields(): cls = self.__class__ descriptor = getattr(cls, name) descriptor.__set__(self, value) else: self.__flag_unknown_attrs(name) def __flag_unknown_attrs(self: Any, *names: str) -> NoReturn: plural = 's' if len(names) > 1 else '' extra = ', '.join(f'{name!r}' for name in names) cls_name = repr(self.__class__.__name__) raise AttributeError(f'{cls_name} has no attribute{plural} {extra}') def _asdict(self: Any) -> dict[str, Any]: return { name: getattr(self, name) for name, attr in self.__class__.__dict__.items() if isinstance(attr, Field) } def __repr__(self: Any) -> str: kwargs = ', '.join( f'{key}={value!r}' for key, value in self._asdict().items() ) return f'{self.__class__.__name__}({kwargs})' Модуль checkeddeco.py реализует простой, но полезный декоратор класса. Декоратор Python @dataclass делает гораздо больше. Он поддерживает много конфигурационных параметров, добавляет в декорированный класс больше методов, обрабатывает конфликты с пользовательскими методами декори- рованного класса или предупреждает о них и даже обходит __mro__, чтобы со- брать определенные пользователем атрибуты, объявленные в суперклассах. Исходный код (https://github.com/python/cpython/blob/3.9/Lib/dataclasses.py) пакета dataclasses в версии Python 3.9 занимает больше 1200 строк. Если мы хотим заниматься метапрограммированием классов, то должны знать, когда интерпретатор Python обрабатывает каждый блок кода при по- строении класса. Этот вопрос рассматривается далее. чтО кОгда прОиСхОдит: этап импОрта и этап выпО лнения Программисты на Python употребляют термины «этап импорта» и «этап вы- полнения», но они определены нестрого, так что между ними существует ни- чейная земля. Что когда происходит: этап импорта и этап выполнения  849\n--- Страница 849 ---\nНа этапе импорта интерпретатор: 1) производит синтаксический анализ исходного кода py-модуля сверху вниз. Именно в это время могут возникать исключения SyntaxError ; 2) генерирует исполняемый байт-код; 3) выполняет код верхнего уровня откомпилированного модуля. Если в локальном кеше __pycache__ существует актуальный pyc-файл, то этот этап пропускается, поскольку уже имеется готовый к выполнению байт-код. Хотя синтаксический анализ и компиляция, безусловно, являются действия- ми, выполняемыми на «этапе импорта», на этой стадии могут происходить и другие вещи, потому что почти каждое предложение в Python является ис- полняемым в том смысле, что в нем может выполняться пользовательский код, изменяющий состояние программы. В частности, предложение import – не просто объявление1, оно еще и выпол- няет весь код, находящийся на верхнем уровне импортируемого модуля, при первом его импорте в память процесса. При последующих операциях импорта того же модуля используется кешированный код, так что происходит только связывание имен. Этот верхнеуровневый код может делать все, что угодно, включая такие типичные для «этапа выполнения» действия, как подключение к базе данных2. Потому-то граница между «этапом импорта» и «этапом вы- полнения» размыта: предложение import может активировать любые действия, которые принято считать частью «этапа выполнения». И наоборот, «этап им- порта» может случиться глубоко внутри этапа выполнения, потому что пред- ложение import и встроенная функция __import__ могут употребляться внутри любой обычной функции. Все это довольно тонкие и абстрактные материи, поэтому ниже описано не- сколько экспериментов, которые помогут разобраться, что когда происходит. Демонстрация работы интерпретатора Рассмотрим скрипт evaldemo.py, в котором используется декоратор класса, дескриптор и построитель класса, основанный на методе __init_subclass__ . Все они определены в модуле builderlib.py. В модулях есть несколько вызовов print, которые показывают, что происходит под капотом. Никаких других полезных функций они не несут. Цель экспериментов – узнать, в каком порядке выпол- няются эти вызовы print. Применение и декоратора, и построителя класса к классу, в ко- тором определен метод __init_subclass__ , скорее всего, является признаком зауми или отчаяния. Но эта необычная комбинация полезна, чтобы показать, в какой момент применяются декора- тор класса и __init_subclass__ . Начнем с изучения скрипта builderlib.py, разбив его на две части: приме- ры 24.10 и 24.11. 1 В отличие от предложения import в Java, которое служит только объявлением, извеща- ющим компилятор о необходимости загрузить некоторые пакеты. 2 Я не хочу сказать, что подключение к базе данных по самому факту импорта моду - ля – хорошая идея, а лишь отмечаю, что это возможно. 850  Метапрограммирование классов\n--- Страница 850 ---\nПример 24.10. builderlib.py: начало модуля print('@ builderlib module start') class Builder:  print('@ Builder body') def __init_subclass__(cls):  print(f'@ Builder.__init_subclass__({cls!r})') def inner_0(self): print(f'@ SuperA.__init_subclass__:inner_0({self!r})') cls.method_a = inner_0 def __init__(self):  super().__init__() print(f'@ Builder.__init__({self!r})') def deco(cls):  print(f'@ deco({cls!r})') def inner_1(self):  print(f'@ deco:inner_1({self!r})') cls.method_b = inner_1 return cls   Это построитель классов, в котором будет реализован …  … метод __init_subclass__ .  Определить функцию, добавляемую в подкласс в присваивании ниже.  Декоратор класса.  Функция, добавляемая в декорированный класс.  Вернуть класс, полученный в качестве аргумента. Продолжаем файл builderlib.py, начатый в примере 24.11… Пример 24.11. builderlib.py: конец модуля class Descriptor:  print('@ Descriptor body') def __init__(self):  print(f'@ Descriptor.__init__({self!r})') def __set_name__(self, owner, name):  args = (self, owner, name) print(f'@ Descriptor.__set_name__{args!r}') def __set__(self, instance, value):  args = (self, instance, value) print(f'@ Descriptor.__set__{args!r}') def __repr__(self): return '<Descriptor instance>' print('@ builderlib module end') Что когда происходит: этап импорта и этап выполнения  851\n--- Страница 851 ---\n Дескрипторный к ласс, демонстрирующий, когда …  … создается экземпляр дескриптора и когда …  … вызывается метод __set_name__ при конструировании класса owner.  Как и все прочие методы, этот метод __set__ только распечатывает свои ар- гументы и больше ничего не делает. Импортировав builderlib.py в консольном сеансе, мы увидим вот что: >>> import builderlib @ builderlib module start @ Builder body @ Descriptor body @ builderlib module end Отметим, что строки, напечатанные builderlib.py, начинаются символом @. Теперь займемся файлом evaldemo.py, который активирует специальные ме- тоды в builderlib.py (пример 24.12). Пример 24.12. evaldemo.py: скрипт для экспериментов с builderlib.py #!/usr/bin/env python3 from builderlib import Builder, deco, Descriptor print('# evaldemo module start') @deco  class Klass(Builder):  print('# Klass body') attr = Descriptor()  def __init__(self): super().__init__() print(f'# Klass.__init__({self!r})') def __repr__(self): return '<Klass instance>' def main():  obj = Klass() obj.method_a() obj.method_b() obj.attr = 999 if __name__ == '__main__': main() print('# evaldemo module end')  Применить декоратор.  Унаследовать Builder, чтобы активировать его метод __init_subclass__ .  Создать экземпляр дескриптора.  Вызывается, только если модуль запущен как главная программа. В вызовы print в evaldemo.py включен префикс #. Снова открыв консоль и им- портировав evaldemo.py, мы увидим строки, показанные в примере 24.13.852  Метапрограммирование классов\n--- Страница 852 ---\nПример 24.13. Эксперимент с evaldemo.py на консоли >>> import evaldemo @ builderlib module start @ Builder body @ Descriptor body @ builderlib module end # evaldemo module start # Klass body  @ Descriptor.__init__(<Descriptor instance>)  @ Descriptor.__set_name__(<Descriptor instance>, <class 'evaldemo.Klass'>, 'attr')  @ Builder.__init_subclass__(<class 'evaldemo.Klass'>)  @ deco(<class 'evaldemo.Klass'>)  # evaldemo module end  Первые четыре строки – результат выполнения from builderlib import… . Их не будет, если вы не закрывали консоль после предыдущего эксперимента, потому что тогда builderlib.py уже загружен.  Сигнал о том, что интерпретатор Python начал читать тело Klass. В этой точ- ке объект класса еще не существует.  Экземпляр дескриптора создан и связан с attr в пространстве имен, кото- рое Python передает конструктору объект класса по умолчанию: type.__new__ .  В этой точке Python встроенный метод type.__new__ создал объект Klass и вы- зывает метод __set_name__ каждого экземпляра дескрипторных классов, пре- доставляющих такой метод, передавая Klass в качестве аргумента owner.  Затем type.__new__ вызывает метод __init_subclass__ суперкласса Klass, пере- давая Klass в качестве единственного аргумента.  Когда type.__new__ возвращает объект класса, Python применяет декора- тор. В этом примере класс, возвращенный deco, связывается с именем Klass в пространстве имен модуля. Метод type.__new__ написан на C. Описанное выше поведение документи- ровано в разделе «Создание объекта класса» (https://docs.python.org/3/reference/ datamodel.html#creating-the-class-object) секции «Модель данных» справочного руководства по Python. Обратите внимание, что функция main() скрипта evaldemo.py в этом консоль- ном сеансе не вычислялась, поэтому экземпляр класса Klass не создавался. Все, что мы видим, – результат операций на «этапе импорта»: импортирования мо- дуля builderlib и определения Klass. Запустив evaldemo.py как скрипт, мы увидим те же строки, что в приме- ре 24.13, плюс дополнительные в конце распечатки. Эти дополнительные стро- ки – результат выполнения main() (пример 24.14). Пример 24.14. Запуск evaldemo.py как программы $ ./evaldemo.py [ 9 строк опущено ] @ deco(<class '__main__.Klass'>)  @ Builder.__init__(<Klass instance>)  # Klass.__init__(<Klass instance>) @ SuperA.__init_subclass__:inner_0(<Klass instance>)  @ deco:inner_1(<Klass instance>)  Что когда происходит: этап импорта и этап выполнения  853\n--- Страница 853 ---\n@ Descriptor.__set__(<Descriptor instance>, <Klass instance>, 999)  # evaldemo module end  Первые 10 строк, включая эту, такие же, как в примере 24.13.  Напечатана в результате выполнения super().__init__() в Klass.__init__ .  Напечатана obj.method_a() в main; method_a был внедрен методом SuperA.__init_ subclass__ .  Напечатана obj.method_b() в main; method_b был внедрен декоратором deco.  Напечатана в результате выполнения obj.attr = 999 в main. Базовый класс с методом __init_subclass__ и декоратор класса – мощные инстру - менты, но они могут работать только с классом, который уже создан методом type.__new__ где-то в недрах интерпретатора. В редких случаях, когда требуется подправить аргументы, передаваемые type.__new__ , нам необходим метакласс. И это последний вопрос, рассматриваемый в этой главе – и вообще в книге. ОСнОвы метакла ССОв Магия метаклассов не интересна 99 % пользователей. Если вы задаетесь вопросом, нужны ли они вам, значит, не нужны (люди, которым они нуж- ны, точно знают, что нуждаются в них, и не нуждаются в объяснениях). – Тим Питерс, изобретатель алгоритма timsort и плодовитый про- граммист на Python1 Метакласс – это фабрика классов, но, в отличие от функции наподобие record_ factory из примера 24.2, метакласс записывается в виде класса. Иными словами, метакласс – это класс, экземплярами которого являются классы. На рис. 24.1 изображен метакласс в нотации хреновин и штуковин: одна хреновина порож - дает другую. Рис. 24.1. Метакласс – это класс, который создает классы 1 Сообщение в группе comp.lang.python, озаглавленное: «Acrimony in c.l.p». (https://mail. python.org/pipermail/python-list/2002-December/134521.html). Это вторая часть сообщения от 23 декабря 2002, процитированного в предисловии. В тот день на TimBot, видно, напало вдохновение.854  Метапрограммирование классов\n--- Страница 854 ---\nВ объектной модели Python классы являются объектами, поэтому каждый класс должен быть экземпляром какого-то другого класса. По умолчанию классы Python являются экземплярами класса type. Иными словами, type – метакласс для большинства встроенных и пользовательских классов: >>> str.__class__ <class 'type'> >>> from bulkfood_v5 import LineItem >>> LineItem.__class__ <class 'type'> >>> type.__class__ <class 'type'> Чтобы избежать бесконечного спуска, type является экземпляром себя само- го, как видно из последней строки. Обратите внимание: я не говорю, что str или LineItem наследуют классу type. Я утверждаю, что str и LineItem – экземпляры type. И все они являются подклассами object. Возможно, рис. 24.2 поможет вам освоиться в этой странной реальности. Рис. 24.2. Обе диаграммы правильны. На левой показано, что str, type и LineItem – под - классы object . Из правой видно, что str, object и LineItem – экземпляры type, поскольку все они – классы Между классами object и type имеется удивительная связь: object – экземпляр type, а type – подкласс object. Эта связь «ма- гическая»: выразить ее средствами Python невозможно, потому что любой из этих классов должен существовать, прежде чем можно будет определить другой. И тот факт, что type является экземпляром самого себя, – тоже магия. В следующем фрагменте кода показано, что классом collections.Iterable явля- ется abc.ABCMeta . Класс Iterable абстрактный, а ABCMeta – нет; да и как может быть иначе, если Iterable является экземпляром ABCMeta: >>> from collections.abc import Iterable >>> Iterable.__class__ <class 'abc.ABCMeta'> >>> import abc >>> from abc import ABCMeta >>> ABCMeta.__class__ <class 'type'> Основы метаклассов  855\n--- Страница 855 ---\nКлассом ABCMeta также является type. Любой класс является экземпляром type, прямо или косвенно, но только метаклассы являются также подклассами type. Это самое главное, что нужно знать о метаклассах: любой метакласс, в част - ности ABCMeta, наследует от type могущество, необходимое для конструирования классов. На рис. 24.3 показана эта важнейшая связь. Рис. 24.3. Iterable – подкласс object и экземпляр ABCMeta . И object , и ABCMeta – эк - земпляры type, но ключевая связь здесь – тот факт, что ABCMeta – еще и подкласс type, поскольку ABCMeta является метаклассом. На этой диаграмме Iterable – единственный абстрактный класс Необходимо твердо запомнить, что все классы являются экземплярами type, и именно поэтому они работают как фабрики классов. Метакласс может на- страивать экземпляры посредством реализации специальных методов, как показано в следующих разделах. Как метакласс настраивает класс Чтобы использовать метакласс, важно понимать, как метод __new__ применя- ется к любому классу. Этот вопрос мы обсуждали в разделе «Гибкое создание объектов с помощью метода __new__» главы 22. Тот же механизм работает на «метауровне», когда метакласс собирается соз- дать новый экземпляр, т. е. класс. Рассмотрим следующее объявление: class Klass(SuperKlass, metaclass=MetaKlass): x = 42 def __init__(self, y): self.y = y Чтобы обработать предложение class, Python вызывает метод MetaKlass.__new__ с такими аргументами: meta_cls Сам метакласс ( MetaKlass), потому что __new__ работает как метод класса. cls_name Строка Klass.856  Метапрограммирование классов\n--- Страница 856 ---\nbases Одноэлементный кортеж (SuperKlass, ), который может иметь больше элемен- тов в случае множественного наследования. cls_dict Отображение вида: {x: 42, `__init__`: <function __init__ at 0x1009c4040>} При реализации MetaKlass.__new__ мы можем проинспектировать и изменить эти аргументы до передачи их методу super().__new__ , который в конечном итоге вызовет type.__new__ для создания нового объекта класса. После возврата из super().__new__ мы можем дообработать вновь созданный класс, перед тем как возвращать его Python. Затем интерпретатор вызывает SuperKlass.__init_subclass__ , передавая созданный нами класс, после чего приме- няет к нему декоратор класса, если таковой задан. Наконец, Python связывает объект класса с его именем в объемлющем пространстве имен – обычно это глобальное пространство имен модуля, если предложение class находится на верхнем уровне. Чаще всего в методе метакласса __new__ добавляются или заменяются эле- менты отображения cls_dict, которое представляет пространство имен кон- струируемого класса. Например, перед вызовом super().__new__ мы можем внед- рить методы в конструируемый класс, добавив функции в cls_dict. Заметим, однако, что добавлять методы можно и после построения класса, именно это и делают __init_subclass__ или декоратор класса. Атрибут, который должен быть добавлен в cls_dict до вызова type.__new__ , – __slots__; этот вопрос обсуждался в разделе «Почему __init_subclass__ не может кон- фигурировать __slots__» выше. Метод __new__ метакласса – идеальное место для конфигурирования __slots__. В следующем разделе объясняется, как это сделать. Элегантный пример метакласса Представленный ниже метакласс MetaBunch – вариация на тему последнего при- мера в главе 4 книги Alex Martelli, Anna Ravenscroft, Steve Holden «Python in a Nutshell», 3-е издание, работающего в Python 2.7 и 3.51. Для версии Python 3.6 и более поздних я смог еще упростить код. Сначала посмотрим, что предоставляет базовый класс Bunch: >>> class Point(Bunch): x = 0.0 y = 0.0 color = 'gray' 1 Авторы любезно разрешили мне воспользоваться их примером. MetaBunch впервые упоминается в сообщении, опубликованном Мартелли в группе 7 июля 2002 года, с заголовком «элегантный пример метакласса (было Re: структуры в python)» (https:// mail.python.org/pipermail/python-list/2002-July/162558.html), после обсуждения записе- подобных структур данных в Python. Оригинальный код Мартелли для Python 2.2 по-прежнему работает после одного изменения: чтобы использовать метакласс в Python 3, необходимо включить именованный аргумент metaclass в объявление класса, например Bunch(metaclass=MetaBunch) , – вместо старого соглашения, требовав- шего добавлять атрибут уровня класса __metaclass__ . Основы метаклассов  857\n--- Страница 857 ---\n>>> Point(x=1.2, y=3, color='green') Point(x=1.2, y=3, color='green') >>> p = Point() >>> p.x, p.y, p.color (0.0, 0.0, 'gray') >>> p Point() Напомним, что Checked назначает имена дескрипторам Field в подклассах, исходя из аннотаций типов в переменных класса, которые не становятся атри- бутами класса, поскольку не имеют значений. С другой стороны, в подклассах Bunch используются фактические атрибуты класса со значениями, которые затем становятся значениями атрибутов эк- земпляра по умолчанию. Сгенерированный метод __repr__ опускает аргументы для атрибутов, принимающих значения по умолчанию. MetaBunch – метакласс Bunch – генерирует атрибут __slots__ для нового класса на основе атрибутов класса, объявленных в пользовательском классе. Это блоки- рует создание и последующее присваивание необъявленным атрибутам: >>> Point(x=1, y=2, z=3) Traceback (most recent call last): AttributeError: No slots left for: 'z' >>> p = Point(x=21) >>> p.y = 42 >>> p Point(x=21, y=42) >>> p.flavor = 'banana' Traceback (most recent call last): AttributeError: 'Point' object has no attribute 'flavor' А теперь перейдем к элегантному коду MetaBunch. Пример 24.15. metabunch/from3.6/bunch.py: метакласс MetaBunch и класс Bunch class MetaBunch(type): ❶ def __new__(meta_cls, cls_name, bases, cls_dict): ❷ defaults = {} ❸ def __init__(self, **kwargs): ❹ for name, default in defaults.items(): ❺ setattr(self, name, kwargs.pop(name, default)) if kwargs: ❻ extra = ', '.join(kwargs) raise AttributeError(f'No slots left for: {extra!r}') def __repr__(self): ❼ rep = ', '.join(f'{name}={value!r}' for name, default in defaults.items() if (value := getattr(self, name)) != default) return f'{cls_name}({rep})' new_dict = dict(__slots__=[], __init__=__init__, __repr__=__repr__) ❽858  Метапрограммирование классов\n--- Страница 858 ---\nfor name, value in cls_dict.items(): ❾ if name.startswith('__') and name.endswith('__'): ❿ if name in new_dict: raise AttributeError(f\"Can't set {name!r} in {cls_name!r}\") new_dict[name] = value else: ⓫ new_dict['__slots__'].append(name) defaults[name] = value return super().__new__(meta_cls, cls_name, bases, new_dict) ⓬ class Bunch(metaclass=MetaBunch): ⓭ pass ❶ Для создания нового метакласса унаследовать type. ❷ __new__ работает, как метод класса, но класс является метаклассом, поэто- му я назвал первый аргумент meta_cls (часто употребляют также имя mcs). Остальные три аргумента такие же, как в трехаргументной сигнатуре для вызова type() с целью непосредственного создания класса. ❸ В defaults будет храниться отображение имен атрибутов на их значения по умолчанию. ❹ Этот метод будет внедрен в новый класс. ❺ Прочитать defaults и присвоить соответствующему атрибуту экземпляра значение, извлеченное из kwargs или подразумеваемое по умолчанию. ❻ Если в kwargs остались аргументы, значит, не нашлось слотов, в которые их можно было бы поместить. Мы полагаем, что быстрый отказ – правильный подход, поэтому не хотим молчаливо игнорировать лишние элементы. Быст рое и эффективное решение – выбирать элементы из kwargs по одному и пытаться установить их в экземпляре, а если не получается, сразу воз- буждать исключение AttributeError . ❼ __repr__ возвращает строку, которая выглядит как вызов конструктора, на- пример Point(x=3) . При этом именованные аргументы, принимающие зна- чения по умолчанию, опускаются. ❽ Инициализировать пространство имен для нового класса. ❾ Обойти пространство имен пользовательского класса. ❿ Если найдено имя name с двумя подчерками, копировать элемент в про- странство имен нового класса, если его там еще нет. Это не даст пользо- вателю перезаписать __init__, __repr__ и другие атрибуты, установленные самим Python, например __qualname__ и __module__ . ⓫ Если имя атрибута name не начинается двумя подчерками, добавить его в конец __slots__ и сохранить его значение value в defaults. ⓬ Построить и вернуть новый класс. ⓭ Предоставить базовый класс, чтобы пользователи не видели MetaBunch. MetaBunch работает, потому что сконфигурировал __slots__, перед тем как вы- зывать super().__new__ для построения окончательного класса. Как всегда при метапрограммировании, важно понимать последовательность действий. Про- ведем еще один эксперимент для демонстрации работы интерпретатора, на сей раз с метаклассом. Основы метаклассов  859\n--- Страница 859 ---\nДемонстрация работы метакласса Это вариация на тему раздела «Демонстрация работы интерпретатора» выше, но теперь мы добавили метакласс. Модуль builderlib.py такой же, как и раньше, а главный скрипт evaldemo_meta.py показан в примере 24.16. Пример 24.16. evaldemo_meta.py: эксперимент с метаклассом #!/usr/bin/env python3 from builderlib import Builder, deco, Descriptor from metalib import MetaKlass  print('# evaldemo_meta module start') @deco class Klass(Builder, metaclass=MetaKlass):  print('# Klass body') attr = Descriptor() def __init__(self): super().__init__() print(f'# Klass.__init__({self!r})') def __repr__(self): return '<Klass instance>' def main(): obj = Klass() obj.method_a() obj.method_b() obj.method_c()  obj.attr = 999 if __name__ == '__main__': main() print('# evaldemo_meta module end')  Импортировать MetaKlass из модуля metalib.py, который будет показан в примере 24.18.  Объявить Klass как подкласс Builder и экземпляр MetaKlass.  Этот метод внедряется MetaKlass.__new__ , как мы увидим ниже. В научных целях я в примере 24.16 вопреки всем резонам при- менил к Klass сразу три техники метапрограммирования: деко- ратор, базовый класс с методом __init_subclass__ и специали- зированный метакласс. Если вам придет в голову сделать это в реальной программе, пожалуйста, не ссылайтесь на меня. По- вторю: моей целью было показать место каждой техники в про- цессе конструирования класса и их взаимное влияние. Как и в предыдущем эксперименте, код не делает ничего полезного, а толь- ко печатает сообщения, раскрывающие ход выполнения. В примере 24.17 по- казан код первой части metalib.py, а остаток – в примере 24.18. 860  Метапрограммирование классов\n--- Страница 860 ---\nПример 24.17. metalib.py: класс NosyDict print('% metalib module start') import collections class NosyDict(collections.UserDict): def __setitem__(self, key, value): args = (self, key, value) print(f'% NosyDict.__setitem__{args!r}') super().__setitem__(key, value) def __repr__(self): return '<NosyDict instance>' В классе NosyDict я переопределил метод __setitem__ , так чтобы показывать устанавливаемые ключи key и значения value. Метакласс будет использовать экземпляр NosyDict для хранения пространства имен конструируемого класса, что позволит нам еще лучше понять, как работает интерпретатор Python. В metalib.py основной интерес представляет метакласс, показанный в при- мере 24.18. Он реализует специальный метод класса __prepare__ , который Python вызывает только для метаклассов. Метод __prepare__ – это самая ранняя воз- можность повлиять на процесс создания нового класса. При написании метакласса я стараюсь придерживаться следующе- го соглашения об именовании аргументов специального метода: использовать cls вместо self для методов экземпляра, потому что экземпляр является классом; использовать meta_cls вместо cls для методов класса, потому что класс является метаклассом. Напомню, что __new__ ведет себя как метод класса, даже без декоратора @classmethod . Пример 24.18. metalib.py: MetaKlass class MetaKlass(type): print('% MetaKlass body') @classmethod  def __prepare__(meta_cls, cls_name, bases):  args = (meta_cls, cls_name, bases) print(f'% MetaKlass.__prepare__{args!r}') return NosyDict()  def __new__(meta_cls, cls_name, bases, cls_dict):  args = (meta_cls, cls_name, bases, cls_dict) print(f'% MetaKlass.__new__{args!r}') def inner_2(self): print(f'% MetaKlass.__new__:inner_2({self!r})') cls = super().__new__(meta_cls, cls_name, bases, cls_dict.data)  cls.method_c = inner_2  return cls  Основы метаклассов  861\n--- Страница 861 ---\ndef __repr__(cls):  cls_name = cls.__name__ return f\"<class {cls_name!r} built by MetaKlass>\" print('% metalib module end')  __prepare__ следует объявлять как метод класса. Это не метод экземпляра, потому что когда Python вызывает __prepare__ , конструируемого класса еще не существует.  Python вызывает метод __prepare__ метакласса, чтобы получить отображе- ние для размещения пространства имен конструируемого класса.  Вернуть экземпляр NosyDict, который будет использоваться в роли про- странства имен.  cls_dict – экземпляр NosyDict, возвращенный методом __prepare__ .  type.__new__ требует, чтобы в последнем аргументе был настоящий словарь dict, поэтому я передаю ему атрибут data отображения NosyDict, унаследован- ного от UserDict.  Внедрить метод во вновь созданный класс.  Как обычно, __new__ должен вернуть только что созданный объект – в дан- ном случае новый класс.  Определение __repr__ в метаклассе позволяет настроить представление объектов класса. До версии Python 3.6 основным применением метода __prepare__ было предо- ставление объекта OrderedDict для хранения атрибутов конструируемого класса, так чтобы метод __new__ метакласса мог обрабатывать эти атрибуты в том по- рядке, в каком они появляются в исходном коде определения пользовательско- го класса. Но теперь dict сохраняет порядок вставки, так что __prepare__ редко бывает нужен. Его изобретательное использование будет показано в примере «Трюк с __prepare__ в метаклассе» ниже. Результат импорта metalib.py на консоли Python не особенно впечатляет. Об- ратите внимание на знак % в начале строк, выведенных этим модулем: >>> import metalib % metalib module start % MetaKlass body % metalib module end Но при импорте evaldemo_meta.py происходит масса интересного (см. при- мер 24.19). Пример 24.19. Эксперименты с evaldemo_meta.py на консоли >>> import evaldemo_meta @ builderlib module start @ Builder body @ Descriptor body @ builderlib module end % metalib module start % MetaKlass body % metalib module end # evaldemo_meta module start 862  Метапрограммирование классов\n--- Страница 862 ---\n% MetaKlass.__prepare__(<class 'metalib.MetaKlass'>, 'Klass',  (<class 'builderlib.Builder'>,)) % NosyDict.__setitem__(<NosyDict instance>, '__module__', 'evaldemo_meta')  % NosyDict.__setitem__(<NosyDict instance>, '__qualname__', 'Klass') # Klass body @ Descriptor.__init__(<Descriptor instance>)  % NosyDict.__setitem__(<NosyDict instance>, 'attr', <Descriptor instance>)  % NosyDict.__setitem__(<NosyDict instance>, '__init__', <function Klass.__init__ at …>)  % NosyDict.__setitem__(<NosyDict instance>, '__repr__', <function Klass.__repr__ at …>) % NosyDict.__setitem__(<NosyDict instance>, '__classcell__', <cell at …: empty>) % MetaKlass.__new__(<class 'metalib.MetaKlass'>, 'Klass', (<class 'builderlib.Builder'>,), <NosyDict instance>)  @ Descriptor.__set_name__(<Descriptor instance>, <class 'Klass' built by MetaKlass>, 'attr')  @ Builder.__init_subclass__(<class 'Klass' built by MetaKlass>) @ deco(<class 'Klass' built by MetaKlass>) # evaldemo_meta module end  Строки, предшествующие этой, – результат импорта builderlib.py и metalib.py.  Python вызывает __prepare__ , начиная обработку предложения class.  Перед тем как приступить к разбору тела класса, Python добавляет элемен- ты __module__ и __qualname__ в пространство имен конструируемого класса.  Экземпляр дескриптора создается и …  … связывается с именем attr в пространстве имен класса.  Определяются и добавляются в пространство имен методы __init__ и __repr__.  Закончив обработку тела класса, Python вызывает метод MetaKlass.__new__ .  Методы __set_name__ , __init_subclass__ и декоратор вызываются именно в та- ком порядке, после того как метод метакласса __new__ вернул вновь скон- струированный класс. При запуске evaldemo_meta.py как скрипта вызывается main() и происходит еще несколько любопытных вещей (пример 24.20). Пример 24.20. Запуск evaldemo_meta.py как программы $ ./evaldemo_meta.py [ 20 lines omitted ] @ deco(<class 'Klass' built by MetaKlass>)  @ Builder.__init__(<Klass instance>) # Klass.__init__(<Klass instance>) @ SuperA.__init_subclass__:inner_0(<Klass instance>) @ deco:inner_1(<Klass instance>) % MetaKlass.__new__:inner_2(<Klass instance>)  @ Descriptor.__set__(<Descriptor instance>, <Klass instance>, 999) # evaldemo_meta module end  Первые 21 строка, включая эту, такие же, как в примере 24.19.  Печатается методом obj.method_c() в main; method_c был внедрен MetaKlass.__new__ . Но вернемся к идее класса Checked с дескрипторами Field, который реализует проверку типов во время выполнения, и посмотрим, как это можно сделать с помощью метакласса. Основы метаклассов  863\n--- Страница 863 ---\nреализация checked С пОмОщью метакла ССа Я не хочу поощрять преждевременную оптимизацию и заумные решения, поэтому опишу воображаемый сценарий, чтобы оправдать переписывание checkedlib.py с добавлением атрибута __slots__, что требует применения мета- класса. Можете пропустить его, если хотите. Обоснование Наш модуль checkedlib.py с методом __init_subclass__ стал пользоваться попу - лярностью в компании, поэтому в памяти производственных серверов в каж - дый момент времени крутятся миллионы экземпляров подклассов Checked. Профилирование показало, что использование __slots__ позволило бы умень- шить счет от облачного поставщика по двум причинам: снижение потребления памяти, поскольку экземплярам Checked будет не нужен собственный __dict__ ; повышение производительности за счет исключения метода __setattr__ , который создавался только ради запрета неожиданных атрибутов, но вы- зывается в момент создания экземпляра и при каждом присваивании атрибуту, до того как будет вызван метод Field.__set__ . Следующий модуль metaclass/checkedlib.py является совместимой по интер- фейсу заменой initsub/checkedlib.py. Тесты, включенные в оба модуля, идентич- ны, равно как и файлы checkedlib_test.py для pytest. Сложность checkedlib.py скрыта от пользователя. Вот как выглядит исходный код скрипта, в котором этот пакет используется: from checkedlib import Checked class Movie(Checked): title: str year: int box_office: float if __name__ == '__main__': movie = Movie(title='The Godfather', year=1972, box_office=137) print(movie) print(movie.title) В этом коротком определении класса Movie используется три экземпляра проверяющего дескриптора Field, конфигурация __slots__, пять методов, уна- следованных от Checked, и метакласс, собирающий все воедино. Единственная видимая часть checkedlib – базовый класс Checked. Взгляните на рис. 24.4. Нотация хреновин и штуковин дополняет диа- грамму классов UML, делая связи между классами и экземплярами более наглядными. Например, класс Movie, в котором используется новый модуль checkedlib.py, является экземпляром CheckedMeta и подклассом Checked. А атрибуты title, year и box_office класса Movie – это три отдельных экземпляра Field. У каждого экзем-864  Метапрограммирование классов\n--- Страница 864 ---\nпляра Movie свои собственные атрибуты _title, _year и _box_office для хранения значений соответствующих полей. Теперь изучим код, начав с класса Field в примере 24.21. Дескрипторный класс Field сейчас немного отличается. В предыдущих при- мерах каждый экземпляр дескриптора Field хранил свое значение в управляе- мом экземпляре, используя атрибут с тем же именем. Например, в классе Movie дескриптор title хранил значение поля в атрибуте title управляемого экзем- пляра. Поэтому от Field не требовалось предоставлять метод __get__. Однако когда в классе, подобном Movie, используется __slots__, в нем не мо- жет быть одноименных атрибутов класса и экземпляра. Каждый экземпляр де- скриптора является атрибутом класса, и теперь мы должны иметь отдельные атрибуты хранения в каждом экземпляре. В коде имена дескрипторов начи- наются одним символом _. Поэтому у экземпляров Field имеются раздельные атрибуты name и storage_name , и мы реализуем метод Field.__get__ . Рис. 24.4. UML-диаграмма классов, аннотирования с помощью нотации MGN: метахре- новина CheckedMeta строит хреновину Movie . Хреновина Field строит дескрипторы title , year и box_office , являющиеся атрибутами класса Movie . Данные полей каждого экземпляра хранятся в атрибутах экземпляра _title , _year и _box_office класса Movie . Обратите внимание на границу пакета checkedlib . Разработчику Movie не нужно глубоко понимать весь механизм работы checkedlib.py В примере 24.21 приведен исходный код Field, а выноски описывают только отличия от предыдущей версии. Пример 24.21. metaclass/checkedlib.py: дескриптор Field с атрибутом storage_name и ме- тодом __get__ class Field: def __init__(self, name: str, constructor: Callable) -> None: if not callable(constructor) or constructor is type(None): raise TypeError(f'{name!r} type hint must be callable') self.name = name Реализация Checked с помощью метакласса  865\n--- Страница 865 ---\nself.storage_name = '_' + name  self.constructor = constructor def __get__(self, instance, owner=None): if instance is None:  return self return getattr(instance, self.storage_name)  def __set__(self, instance: Any, value: Any) -> None: if value is : value = self.constructor() else: try: value = self.constructor(value) except (TypeError, ValueError) as e: type_name = self.constructor.__name__ msg = f'{value!r} is not compatible with {self.name}:{type_name}' raise TypeError(msg) from e setattr(instance, self .storage_name, value)   Вычислить storage_name по аргументу name.  Если __get__ получает None в качестве аргумента instance, то дескриптор чи- тается из самого управляемого класса, а не из управляемого экземпляра. Поэтому мы возвращаем дескриптор.  В противном случае возвращаем значение, хранящееся в атрибуте с име- нем storage_name .  Теперь __set__ пользуется методом setattr для установки и изменения управляемого атрибута. В примере 24.22 приведен код метакласса, приводящего этот пример в дей- ствие. Пример 24.22. metaclass/checkedlib.py: метакласс CheckedMeta class CheckedMeta(type): def __new__(meta_cls, cls_name, bases, cls_dict):  if '__slots__' not in cls_dict:  slots = [] type_hints = cls_dict.get('__annotations__', {})  for name, constructor in type_hints.items():  field = Field(name, constructor)  cls_dict[name] = field  slots.append(field.storage_name)  cls_dict['__slots__'] = slots  return super().__new__( meta_cls, cls_name, bases, cls_dict)   __new__ – единственный метод, реализованный в CheckedMeta .  Дополнять класс, только если его cls_dict не содержит __slots__. Если __slots__ уже присутствует, предполагаем, что это базовый класс Checked, а не опреде- ленный пользователем подкласс, и строим класс, ничего не добавляя.866  Метапрограммирование классов\n--- Страница 866 ---\n В предыдущих примерах для получения аннотаций типов мы пользова- лись методом typing.get_type_hints , но он требует передачи существующе- го класса в первом аргументе. В этой точке конфигурируемый класс еще не существует, поэтому нужно получать __annotations__ непосредственно из cls_dict – пространства имен конструируемого класса, которое Python пере- дает в последнем аргументе методу метакласса __new__.  Обойти type_hints , чтобы …  … построить Field для каждого аннотированного атрибута, …  … перезаписать соответствующий элемент cls_dict экземпляром Field …  … и добавить атрибут storage_name поля в конец списка, который нам пона- добится, чтобы …  … заполнить элемент __slots__ в cls_dict – пространстве имен конструируе- мого класса.  Напоследок вызываем super().__new__ . Последняя часть metaclass/checkedlib.py – базовый класс Checked, которому пользователи этой библиотеки будут наследовать, чтобы дополнить собствен- ные классы наподобие Movie. Код этой версии Checked отличается от кода в модуле initsub/checkedlib.py (см. примеры 24.5 и 24.6) в трех местах. 1. Добавлен пустой атрибут __slots__, который служит для метода CheckedMeta.__new__ указанием на то, что этот класс не нуждается в специ- альной обработке. 2. Удален метод __init_subclass__ . Его работу теперь выполняет метод CheckedMeta.__new__ . 3. Удален метод __setattr__ . Он стал не нужен, потому что добавление __slots__ в пользовательский класс препятствует заданию необъявлен- ных атрибутов. В примере 24.23 приведен код окончательной версии Checked. Пример 24.23. metaclass/checkedlib.py: базовый класс Checked class Checked(metaclass=CheckedMeta): __slots__ = () # skip CheckedMeta.__new__ processing @classmethod def _fields(cls) -> dict[str, type]: return get_type_hints(cls) def __init__(self, **kwargs: Any) -> None: for name in self._fields(): value = kwargs.pop(name, ) setattr(self, name, value) if kwargs: self .__flag_unknown_attrs(*kwargs) def __flag_unknown_attrs(self, *names: str) -> NoReturn: plural = 's' if len(names) > 1 else '' extra = ', '.join(f'{name!r}' for name in names) cls_name = repr(self.__class__.__name__) raise AttributeError(f'{cls_name} object has no attribute{plural} {extra}') Реализация Checked с помощью метакласса  867\n--- Страница 867 ---\ndef _asdict(self) -> dict[str, Any]: return { name: getattr(self, name) for name, attr in self.__class__.__dict__.items() if isinstance(attr, Field) } def __repr__(self) -> str: kwargs = ', '.join( f'{key}={value!r}' for key, value in self._asdict().items() ) return f'{self.__class__.__name__}({kwargs})' На этом завершается третий вариант построителя классов с проверяющими дескрипторами. В следующем разделе мы рассмотрим общие вопросы, относящиеся к мета- классам. метакла ССы на практике Метаклассы – штука мощная, но трудная. Прежде чем браться за реализацию метакласса, примите во внимание описанные ниже соображения. Современные средства позволяют упростить или заменить метаклассы Со временем появились новые языковые средства, сделавшие метаклассы не- нужными в нескольких типичных ситуациях. Декораторы классов Проще, чем метаклассы, и меньше шансов на конфликты с базовыми клас - сами и метаклассами. __set_name__ Делает лишним привлечение метаклассов к автоматическому заданию имени дескриптора1. __init_subclass__ Предоставляет способ настройки создания класса, прозрачный для ко- нечного пользователя и даже более простой, чем декоратор. Но при этом в сложной иерархии классов возможны конфликты. Сохранение порядка вставки ключей во встроенном словаре Устранило главную причину для использования __prepare__ : предоставить OrderedDict для хранения пространства имен конструируемого класса. Python вызывает __prepare__ только для метаклассов, поэтому если вам нужно было 1 В первом издании книги в продвинутых версиях класса LineItem метакласс исполь- зовался только для того, чтобы задать имя для хранения атрибутов. См. код мета- классов в примерах bulkfood в репозитории для первого издания (https://github.com/ fluentpython/example-code/tree/master/21-class-metaprog/bulkfood).868  Метапрограммирование классов\n--- Страница 868 ---\nобрабатывать имена в том порядке, в каком они добавлялись в простран- ство имен класса в исходном коде, то до выхода версии Python 3.6 прихо- дилось использовать метакласс. По состоянию на 2021 год все активно поддерживаемые версии CPython поддерживали все перечисленные выше возможности. Я горячий сторонник этих средств, потому что и так вижу в нашей профес - сии слишком много ненужной сложности, а метаклассы – ворота к этой слож - ности. Метаклассы – стабильное языковое средство Метаклассы были добавлены в Python 2.2 в 2002 году вместе с так называемы- ми «классами в новом стиле», дескрипторами и свойствами. Удивительно, что пример MetaBunch, впервые опубликованный Алексом Мар- телли в июле 2002 года, все еще работает в Python 3.9 – изменился только спо- соб задания используемого метакласса: в Python 3 для этого служит синтакси- ческая конструкция class Bunch(metaclass=MetaBunch): . Ни одно из добавлений, упомянутых в разделе «Современные средства по- зволяют упростить или заменить метаклассы» выше, не «ломает» существу - ющий код с метаклассами. Но унаследованный код, в котором используются метаклассы, часто можно упростить, воспользовавшись этими средствами, особенно если вы готовы отказаться от поддержки версий Python младше 3.6 (а она уже все равно не сопровождается). У класса может быть только один метакласс Если в объявлении класса встречается два или более метаклассов, то выдается такое загадочное сообщение об ошибке: TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases Для этого даже не нужно множественное наследование. Например, следую- щее объявление приведет к такой ошибке TypeError: class Record(abc.ABC, metaclass=PersistentMeta): pass Мы видели, что abc.ABC – экземпляр метакласса abc.ABCMeta . Если метакласс PersistentMeta сам не является подклассом abc.ABCMeta , то мы получаем конфликт метаклассов. Бороться с этой ошибкой можно двумя способами: придумать, как решить задачу, обойдясь хотя бы без одного из участву - ющих метаклассов; написать собственный метакласс PersistentABCMeta , являющийся подклас - сом как abc.ABCMeta , так и PersistentMeta , и использовать его как единствен- ный метакласс Record1. 1 Если у вас голова пошла кругом от перспективы прибегнуть к множественному на- следованию метаклассов, то и хорошо. Я бы тоже держался от этого решения по- дальше. Метаклассы на практике  869\n--- Страница 869 ---\nЯ могу себе представить, что к решению с метаклассом, наследу - ющим двум базовым метаклассам, прибегают, чтобы не выбить- ся из графика. Но мой опыт показывает, что программирование метаклассов всегда занимает больше времени, чем планирова- лось, поэтому такой подход чреват рисками. Если вы все-таки пошли по этому пути и успели к сроку, то код может содержать тонкие ошибки. Даже если явных ошибок нет, все равно этот подход следует рассматривать как технический долг просто по- тому, что его трудно понять и сопровождать. Метаклассы должны быть деталью реализации Помимо type, в стандартной библиотеке Python 3.9 есть всего шесть метаклас - сов. Самыми известными, вероятно, являются abc.ABCMeta , typing.NamedTupleMeta и enum.EnumMeta . Ни один из них не предназначен для явного использования в пользовательском коде. Можно считать их деталью реализации. Хотя метаклассы открывают возможность для эксцентричного метапро- граммирования, лучше следовать принципу наименьшего удивления (https:// en.wikipedia.org/wiki/Principle_of_least_astonishment), чтобы большинство пользова- телей действительно могли относиться к ним как к детали реализации1. В последние годы некоторые метаклассы в стандартной библиотеке Python были заменены другими механизмами, не нарушив открытый API соответ - ствующих пакетов. Простейший способ обеспечить возможность развития таких API в будущем – предложить пользователям обычный класс, которому можно унаследовать для доступа к функциональности, предоставляемой ме- таклассом, как мы и поступили в приведенных примерах. В завершение рассказа о метапрограммировании классов поделюсь самым крутым, хотя и небольшим примером метакласса, который мне удалось найти при подготовке материала к этой главе. метакла ССный трюк С __prep Are__ Перерабатывая эту главу для второго издания, я хотел найти простые, но убе- дительные примеры для замены класса LineItem из модуля bulkfood, в котором после выхода Python 3.6 необходимость в метаклассах отпала. Самую простую и вместе с тем самую интересную идею применения мета- класса подал мне Жоао С. О. Буэно, которого в бразильском сообществе Python лучше знают под ником JS. Одно из применений этой идеи – создание класса, который автоматически генерирует числовые константы: >>> class Flavor(AutoConst): banana coconut vanilla >>> Flavor.vanilla 2 1 Я зарабатывал кодированием с применением Django в течение нескольких лет, преж де чем решил поинтересоваться, как в нем реализованы поля модели. И только тогда я узнал о дескрипторах и метаклассах. 870  Метапрограммирование классов\n--- Страница 870 ---\n>>> Flavor.banana, Flavor.coconut (0, 1) Да, этот код именно так и работает! На самом деле это тест, включенный в файл autoconst_demo.py. Ниже приведен ориентированный на пользователей базовый класс AutoConst и стоящий за ним метакласс, реализованные в файле autoconst.py: class AutoConstMeta(type): def __prepare__(name, bases, **kwargs): return WilyDict() class AutoConst(metaclass=AutoConstMeta): pass И это всё. Понятно, что весь фокус кроется в WilyDict. Когда Python обрабатывает пространство имен пользовательского клас - са и читает banana, он ищет это имя в отображении, предоставляемом мето- дом __prepare__ : экземпляре класса WilyDict. WilyDict реализует метод __missing__ , описанный в разделе «Метод __missing__» главы 3. Изначально в экземпляре WilyDict нет ключа 'banana', поэтому вызывается метод __missing__ . Он динамиче- ски создает запись с ключом 'banana' и значением 0 и возвращает это значение. Python вполне удовлетворен и переходит к поиску ключа 'coconut'. WilyDict с го - товностью добавляет запись с таким ключом и значением 1 и возвращает зна- чение. То же самое происходит с ключом 'vanilla', который отображается на 2. Мы уже встречали __prepare__ и __missing__ раньше. Новшество в том, как JS соединил их вместе. Ниже приведен исходный код WilyDict, также находящийся в файле autoconst.py: class WilyDict(dict): def __init__(self, *args, **kwargs): super().__init__(*args, **kwargs) self.__next_value = 0 def __missing__(self, key): if key.startswith('__') and key.endswith('__'): raise KeyError(key) self[key] = value = self.__next_value self.__next_value += 1 return value Экспериментируя, я обнаружил, что Python ищет __name__ в пространстве имен конструируемого класса, что заставляет WilyDict добавить запись __name__ и увеличить __next_value . Поэтому я добавил в __missing__ предложение if, которое возбуждает исключение KeyError для ключей, выглядящих как dunder-атрибуты. Пакет autoconst.py требует уверенного владения механизмом построения динамических классов в Python и вместе с тем иллюстрирует его. Я отлично провел время, расширяя функциональность AutoConstMeta и AutoConst, но вместо того чтобы делиться своими экспериментами, оставлю вам шанс по- лучить удовольствие, развивая этот изобретательный трюк JS. Вот несколько идей: Метаклассный трюк с __prepare__  871\n--- Страница 871 ---\nдобавьте возможность получить имя константы по ее значению. Напри- мер, выражение Flavor[2] должно возвращать 'vanilla'. Это можно сде- лать, реализовав метод __getitem__ в AutoConstMeta . Начиная с Python 3.9 можно реализовать метод __class_getitem__ в самом AutoConst ; добавьте поддержку итерирования по классу, реализовав метод __iter__ в ме- таклассе. Я бы заставил __iter__ отдавать константы в виде пар (name, value) ; реализуйте новый вариант Enum. Это будет непростым предприятием, по- тому что пакет enum полон разных трюков, в частности в нем есть ме- такласс EnumMeta, содержащий сотни строк кода и нетривиальный метод __prepare__ . Дерзайте! Специальный метод __class_getitem__ был добавлен в версию Python 3.9 для поддержки обобщенных типов как часть докумен- та PEP 585 «Type Hinting Generics In Standard Collections» (https:// peps.python.org/pep-0585/). Благодаря __class_getitem__ разработчи- ки ядра Python избавились от необходимости писать новый ме- такласс для реализации __getitem__ во встроенных типах, чтобы мы могли писать аннотации обобщенных типов вида list[int] . Это узкая сфера применения, но она дает пример потенциально- го использования метаклассов: реализация операторов и других специальных методов, работающих на уровне класса, например итерирование по самому классу, как в подклассах Enum. заключение Метаклассы, равно как декораторы классов и метод __init_subclass__ , полезны для решения следующих задач: регистрация подкласса; структурная проверка подкласса; применение декораторов сразу к нескольким методам; сериализация объектов; объектно-реляционное отображение; постоянное хранение объектов; реализация специальных методов на уровне класса; реализация средств работы с классами, имеющихся в других язы- ках, например характеристик (https://en.wikipedia.org/wiki/Trait_(computer_ programming)) и аспектно-ориентированного программирования (https:// en.wikipedia.org/wiki/Aspect-oriented_programming). Метапрограммирование классов иногда помогает решить проблемы произ- водительности, позволяя выполнять на этапе импорта действия, которые ина- че пришлось бы многократно повторять на этапе выполнения. Подводя итоги, хочу напомнить заключительный совет Алекса Мартелли из эссе «Водоплавающие птицы и ABC», приведенного в главе 13. И не определяйте свои ABC (или метаклассы) в производственном коде. Если вам кажется, что без этого не обойтись, держу пари, что это, скорее всего, желание поскорее забить гвоздь, раз уж в руках молоток, – вам (и тем, кому предстоит сопровождать вашу программу) будет куда комфорт нее иметь дело с прямолинейным и простым кодом, где нет таких глубин. 872  Метапрограммирование классов\n--- Страница 872 ---\nЯ думаю, что совет Мартелли применим не только к ABC и метаклассам, но также к иерархиям классов, перегрузке операторов, декораторам функциям, дескрипторам, декораторам классов и построителям классов, в которых ис- пользуется метод __init_subclass__ . Эти мощные инструменты предназначены в первую очередь для разра- ботки библиотек и каркасов. Естественно, приложения могут использовать эти инструменты, поскольку они предоставляются стандартной библиотекой и внешними пакетами. Но решение реализовать их в коде приложения часто является признаком преждевременного абстрагирования. Хорошие каркасы извлекаются, а не изобретаются1. – Дэвид Хейнемейер Ханссон, создатель Ruby on Rails резюме Мы начали эту главу с обзора атрибутов, встречающихся в объектах классов, в т. ч. __qualname__ , и метода __subclasses__() . Затем мы видели, как встроенный класс type можно использовать для конструирования классов во время вы- полнения. Мы познакомились со специальным методом __init_subclass__ в процессе первой попытки создать базовый класс Checked, предназначенный для замены аннотаций типа атрибутов в пользовательских подклассах экземплярами Field, которые применяют конструкторы для проверки типа этих атрибутов на этапе выполнения. Та же идея была реализована в декораторе класса @checked, который добавля- ет новые возможности в пользовательский класс по аналогии с тем, что делает метод __init_subclass__ . Мы также видели, что ни __init_subclass__ , ни декоратор класса не могут динамически сконфигурировать __slots__, потому что работают уже после создания класса. С помощью экспериментов мы прояснили понятия «этап импорта» и «этап выполнения», продемонстрировав, в каком порядке выполняется Python-код, в котором присутствуют модули, дескрипторы, декораторы классов и метод __ init_subclass__ . Рассмотрение метаклассов началось с объяснения того, что type является метаклассом, и того, как определенные пользователем метаклассы могут реа- лизовать метод __new__ для настройки создаваемых классов. Затем мы пред- ставили первый пользовательский метакласс, классический прием MetaBunch с использованием __slots__. Наш следующий эксперимент показал, что методы __prepare__ и __new__ метакласса вызываются раньше, чем __init_subclass__ и де- кораторы классов, что открывает возможности для более глубокой настройки классов. Далее был представлен третий подход к построителю классов Checked с де- скрипторами Field и пользовательской конфигурацией __slots__, после чего мы поделились общими соображениями о применении метаклассов на практике. 1 Эта фраза разошлась на цитаты. Я нашел одно из ранних прямых упоминаний в со- общении в блоге DHH, датированном 2005 годом. Резюме  873\n--- Страница 873 ---\nНаконец, мы продемонстрировали класс AutoConst, придуманный Жоао С. О. Буэно и основанный на хитроумной идее метакласса с методом __prepare__ , который возвращает отображение, реализующее метод __missing__ . Насчитыва- ющий меньше 20 строк код, скрипт autoconst.py показывает, как можно с поль- зой комбинировать приемы метапрограммирования в Python. Я еще не встречал языка, которому удалось так удачно совместить просто- ту для начинающих, практичность для профессионалов и увлекательность для хакеров, как это сделано в Python. Спасибо Гвидо ван Россуму и всем, кто внес свой вклад в достижение этой цели. дОпО лнительная литература Калеб Хэттинг, технический рецензент этой книги, написал пакет autoslot, который предоставляет метакласс для автоматического создания атрибута __slots__ в пользовательском классе. Для этого он исследует байт-код метода __init__ и находит все присваивания атрибутам self. Метакласс полезен сам по себе, а кроме того, является прекрасным учебным примером: всего 74 строки в файле autoslot.py, включая 20 строк комментариев, в которых объясняются наиболее трудные места. Основными справочными материалами к этой главе являются раздел 3.3.3 «Настройка создания класса» (https://docs.python.org/3/reference/datamodel.html# customizing-class-creation) главы «Модель данных» справочного руководства по языку Python, в котором рассматриваются метод __init_subclass__ и метаклассы. Документация по классу type (https://docs.python.org/3/library/functions.html#type) в разделе «Встроенные функции» и раздел 4.13 «Специальные атрибуты» (https://docs.python.org/3/library/stdtypes.html#special-attributes) главы «Встроенные типы» руководства по стандартной библиотеке также важны. В документации по модулю types из стандартной библиотеки (https://docs. python.org/3/library/types.html) рассматриваются две новые функции в Python 3.3, призванные оказать помощь в метапрограммировании классов: types.new_class и types.prepare_class . Декораторы классов были формально определены в документе PEP 3129 «Class Decorators» (https://peps.python.org/pep-3129/), который написал Коллин Уинтер, а эталонную реализацию предложил Джек Дидерих. Доклад Джека Дидериха на конференции PyCon 2009 «Class Decorators: Radically Simple» (ви- део – по адресу https://www.youtube.com/watch?v=cAGliEJV9_o) содержит краткое введение в эту функциональность. Помимо @dataclass , интересным – и гораз- до более простым – примером декоратора класса в стандартной библиотеке Python является functools.total_ordering (https://docs.python.org/3/library/functools. html#functools. total_ordering), который генерирует специальные методы для сравнения объектов. Основным справочником по метаклассам в документации Python является документ PEP 3115 «Metaclasses in Python 3000» (https://peps.python.org/pep-3115/), в котором был предложен специальный метод __prepare__ . Книга Alex Martelli, Anna Ravenscroft, Steve Holden «Python in a Nutshell», 3-е издание, хотя и авторитетна, но написана раньше, чем вышел документ PEP 487 «Simpler customization of class creation» (https://peps.python.org/pep-0487/). 874  Метапрограммирование классов\n--- Страница 874 ---\nГлавный пример метакласса в этой книге, MetaBunch, по-прежнему актуален, потому что его нельзя написать с помощью более простых механизмов. В кни- ге Brett Slatkin «Effective Python», 2-е издание (Addison-Wesley), есть несколько актуальных примеров на тему построения классов, в т. ч. с использованием ме- таклассов. Тем, кто хочет узнать об истоках метапрограммирования классов в Python, я рекомендую статью «Unifying types and classes in Python 2.2» (https://www. python.org/download/releases/2.2.3/descrintro/), написанную Гвидо ван Россумом в 2003 году. Она относится и к современному Python, поскольку охватыва- ет то, что тогда называлось семантикой классов «нового стиля» и стало се- мантикой по умолчанию в Python 3, в т. ч. дескрипторы и метаклассы. Гви- до ссылается, в частности, на книгу Ira R. Forman, Scott H. Danforth «Putting Metaclasses to Work: a New Dimension in Object-Oriented Programming» (Addison-Wesley), которой он поставил 5 звезд на сайте Amazon.com, сопро- водив таким комментарием: Эта книга внесла вклад в дизайн метаклассов в Python 2.2 Жаль, что она больше не переиздается; я продолжаю считать ее лучшей из известных мне работ на трудную тему кооперативного множественного наследования, поддерживаемого в Python с помощью функции super()1. Если вы увлеклись метапрограммированием, то, возможно, хотели бы, чтобы в Python был реализован механизм, являющийся королем всех средств мета- программирования: синтаксические макросы, имеющиеся в семействе языков Lisp, а из более современных – в Elixir и Rust. Синтаксические макросы – меха- низм более мощный и менее подверженный ошибкам, чем примитивные под- становочные макросы в языке C. Это специальные функции, которые преоб- разуют исходный код, написанный с применением пользовательского синтак - сиса, в стандартный код до этапа компиляции, что позволяет разработчикам внедрять новые языковые конструкции, не изменяя компилятор. Как и пере- грузку операторов, синтаксические макросы можно употребить во зло. Но при условии, что сообщество понимает потенциальные недостатки и умеет их ку- пировать, они способны поддержать мощные и дружественные по отношению к пользователю абстракции, в частности DSL (предметно-ориентированные языки). В сентябре 2020 года разработчик ядра Python Марк Шеннон опублико- вал документ PEP 638 «Syntactic Macros» (https://peps.python.org/pep-3129/), в кото - ром предложил именно это. Через год после публикации PEP 638 все еще имел статус черновой редакции и его активного обсуждения не было. Очевидно, что для разработчиков ядра Python он не стоит на первом месте. Я хотел бы, чтобы обсуждение PEP 638 возобновилось и в конечном итоге увенчалось одобрени- ем. Синтаксические макросы позволили бы сообществу Python эксперименти- ровать с вызывающими споры новыми средствами, например оператором := (PEP 572), сопоставлением с образцом (PEP 634) и альтернативными правилами вычисления аннотаций типов (PEP 563 и 649), прежде чем вносить изменения в ядро языка. А пока можете получить представление о синтаксических макро- сах из пакета MacroPy (https://github.com/lihaoyi/macropy). 1 Я купил подержанный экземпляр, это оказалось весьма трудное чтение. Дополнительная литература  875\n--- Страница 875 ---\nПоговорим Эту последнюю врезку «Поговорим» я начну длинной цитатой из Брайана Хар- ви (Brian Harvey) и Мэттью Райта (Matthew Wright), двух профессоров инфор- матики из Калифорнийского университета (в Беркли и Санта-Барбаре). В книге «Simply Scheme: Introducing Computer Science» (MIT Press) Харви и Райт пишут: Есть два направления в преподавании информатики. Схематично их можно представить следующим образом: 1. Консервативный взгляд. Компьютерные программы стали настолько большими и сложными, что человеческий мозг не в состоянии их охватить. Поэтому задача обучения информатике заключается в том, чтобы научить людей дисциплинированной работе, когда 500 средних программистов, со- бравшись вместе, могут написать программу, отвечающую спецификации. 2. Радикальный взгляд. Компьютерные программы стали настолько большими и сложными, что человеческий мозг не в состоянии их охватить. Поэтому зада- ча обучения информатике заключается в том, чтобы научить людей расширять сознание, чтобы в нем хватило места всей программе. Для этого нужно учить мыслить более крупными, более эффективными, более гибкими категориями, не ограничиваясь очевидными вещами. Каждая единица программистской мысли должна давать большую отдачу в терминах возможностей программы1. – Брайан Харви и Мэттью Райт, предисловие к книге «Simply Scheme»2 Карикатурные описания Харви и Райта относятся к преподаванию информа- тики, но они применимы и к проектированию языков программирования. Вы, наверное, уже догадались, что я приверженец «радикальной» точки зре- ния и полагаю, что Python проектировался именно в таком ключе. Идея свойств – большой шаг вперед по сравнению с подходом Java, требу - ющим применять акцессоры с самого начала. Этот подход поддерживается всеми Java IDE с помощью комбинации клавиш для генерации методов чте- ния и установки. Основное достоинство свойств заключается в том, что они позволяют начать разработку класса, сделав атрибуты открытыми – в духе принципа KISS, – понимая при этом, что в любой момент открытый атрибут можно, не прилагая особых усилий, сделать свойством. Но дескрипторы идут еще дальше, они предоставляют механизм для абстрагирования повторяю- щейся логики акцессоров. Этот механизм настолько эффективен, что исполь- зуется и в некоторых конструкциях самого языка Python. Еще одна плодотворная идея – функции как полноправные объекты. Она про- кладывает дорогу к функциям высшего порядка. Как выясняется, комбинация дескрипторов и функций высшего порядка позволяет унифицировать функ - ции и методы. Метод __get__ функции порождает объект метода на лету путем привязки экземпляра к аргументу self. Это элегантное решение3. 1 Brian Harvey, Matthew Wright. Simply Scheme. MIT Press, 1999. С. xvii. Полный текст име- ется на сайте Berkeley.edu (https://www.eecs.berkeley.edu/~bh/ss-toc2.html). 2 См. стр. xvii. Полный текст доступен на сайте Berkeley.edu (https://people.eecs.berkeley. edu/~bh/ss-toc2.html). 3 Книга «Machine Beauty» Дэвида Гелернтера (Basic Books) открывается интигующим обсуждением элегантности и эстетики в работе инженера: от мостов до программ- ного обеспечения. Последующие главы не так хороши, но начало оправдывает по- траченные деньги.876  Метапрограммирование классов\n--- Страница 876 ---\nНаконец, полноправными объектами являются и классы. Нельзя не восхи- титься дизайном, при котором доступный начинающим программистам язык предоставляет столь мощные концепции, как декораторы классов и полноценные пользовательские метаклассы. И что поразительно: про- двинутые средства интегрированы в язык таким образом, что не усложняют его применение для эпизодического программирования (а даже помогают – под капотом). Своим удобством и успешностью такие каркасы, как Django и SQLAlchemy, во многом обязаны метаклассам. Со временем метапрограм- мирование классов в Python становится все проще и проще, по крайней мере в типичных ситуациях. Лучшие языковые средства – те, от которых выигры- вают все, даже если некоторые пользователи Python о них и не знают. Но они всегда могут поучиться и написать свою, не менее грандиозную библиотеку. Я с нетерпением буду ждать вашего вклада в жизнь сообщества и в экосисте- му Python! Дополнительная литература  877\n--- Страница 877 ---\nПослесловие Python – язык, разрешающий взрослым все. – Алан Раньян, сооснователь Plone Афористичное определение Алана подчеркивает одно из лучших качеств Python: он отходит в сторону и дает возможность делать то, что вам необходи- мо. Это также означает, что он не предоставляет средств, с помощью которых вы могли бы наложить ограничения на то, что другие могут делать с вашим кодом и создаваемыми в нем объектами. В возрасте 30 лет Python все еще набирает популярность. Конечно, Python не идеален. Лично меня подчас раздражает разнобой в именовании иденти- фикаторов в стандартной библиотеке, например CamelCase, snake_case и joinedwords . Но определение языка и стандартная библиотека – лишь часть экосистемы. А лучшую ее часть составляет сообщество пользователей и авторов. Приведу пример высоких качеств сообщества. Как-то утром писал я о asyncio и впал в отчаяние из-за того, что в API так много функций, из которых десят - ки являются сопрограммами, а сопрограммы нужно вызывать с помощью yield from, тогда как к обычным функциям эта конструкция неприменима. Все это описано в документации по asyncio, но иногда приходится прочитать несколь- ко абзацев, пока до тебя дойдет, что некоторая функция является сопрограм- мой. Поэтому я отправил сообщение в список рассылки python-tulip, назвав его «Предложение: выделять сопрограммы в документации по asyncio» (https:// groups.google.com/forum/#!topic/ python-tulip/Y4bhLNbKs74). К беседе подключились Виктор Стиннер, разработчик ядра asyncio, Андрей Светлов, основной автор aiohttp, Бен Дарнелл, главный разработчик Tornado, и Глиф Лефковиц, автор Twisted. Дарнелл предложил решение, Александр Шорин объяснил, как реа- лизовать его в Sphinx, а Стиннер внес необходимые изменения в конфигура- цию и разметку. Менее чем через 12 часов после моего вопроса вся выложен- ная в сеть документация по asyncio была обновлена – в ней появились метки coroutine (https://docs.python.org/3/library/asyncio-eventloop.html#executor). Это произошло не в каком-то клубе для избранных. Любой может войти в список python-tulip, и я сам, внося это предложение, отправил несколько со- общений. Эта история лишний раз демонстрирует, что сообщество действи- тельно открыто для новых идей и новых членов. Гвидо ван Россум постоянно присутствует в python-tulip и регулярно отвечает даже на простые вопросы. Приведу еще один пример открытости: задачей фонда Python Software Foundation (PSF) является увеличение разнообразия в сообществе Python. Уже получены обнадеживающие результаты. В правление фонда в период 2013– 2014 годов впервые были избраны женщины: Джессика Маккеллар и Линн Рут. А на конференции 2015 PyCon North America в Мореале – под председатель- ством Дианы Кларк – примерно треть выступавших были женщинами. PyLadies\n--- Страница 878 ---\nстало поистине глобальным движением, и я горжусь тем, что у нас в Бразилии так много отделений PyLadies. Если вы пишете на Python, но еще не присоединились к сообществу, при- зываю вас не откладывать с этим. Ищите отделение PyLadies или группу поль- зователей Python (Python Users Group –PUG) в своем регионе. Если такой еще нет, создайте ее сами. Python присутствует везде, поэтому вы не будете одино- ки. Посещайте мероприятия, если есть такая возможность. В том числе онлай- новые. Во время пандемии Covid-19 я много узнал на «встречах в холле» он- лайновых конференций. Приезжайте на конференцию PythonBrasil – мы уже много лет предоставляем слово докладчикам из других стран. Личные встречи с коллегами-программистами дают куда больше, чем общение в сети; извест - ны примеры, когда они приносили реальные плоды, выходящие за рамки об- мена знаниями. Как работа и дружба в «реале». Я точно не мог бы написать эту книгу без помощи многочисленных друзей, которыми за годы работы обзавелся в сообществе Python. Мой отец, Хайро Рамальо, частенько говаривал «Só erra quem trabalha» – «не ошибается тот, кто ничего не делает» по-португальски. Это прекрасный совет тем, кого парализует страх наделать ошибок. Уж я-то наделал их мас- су, когда писал эту книгу. Рецензенты, редакторы и читатели предваритель- ной версии отловили многие из них. Не прошло и нескольких часов с момента публикации первой предварительной версии, как один читатель сообщил об опечатках на странице ошибок. Этот читатель был отнюдь не единственным, а друзья обращались ко мне напрямую со своими советами и поправками. Кор- ректоры из издательства O’Reilly найдут и другие ошибки на этапе производ- ства книги, который начнется сразу после того, как я наконец закончу ее пи- сать. Я принимаю на себя ответственность и приношу извинения за те ошибки, которые останутся, а также за стилистические погрешности. Я рад, что работа все же подошла к концу, несмотря на все ошибки и труд- ности, и в высшей степени благодарен всем, что помогал мне на этом пути. Надеюсь вскоре встретиться с вами на каком-нибудь реальном мероприя- тии. Не стесняйтесь поздороваться, если наткнетесь на меня! дОпО лнительная литература В конце книги я хочу привести ссылки на ресурсы, в которых объясняется, что та- кое «дух Python» – основной вопрос, на который я пытался ответить в этой книге. Брэндон Родес – блестящий преподаватель Python, а его доклад «A Python Æsthetic: Beauty and Why I Python» (https://www.youtube.com/watch?v=x-kB2o8sd5c) великолепен, начиная уже с использования символа Unicode U+00C6 (LATIN CAPITAL LETTER AE) в названии. Другой замечательный преподаватель, Рай- монд Хэттингер, говорил о красоте в Python на конференции PyCon US в своем выступлении «Transforming Code into Beautiful, Idiomatic Python» (https://www. youtube.com/watch?v=OSGv2VnC0go). Стоит почитать обсуждение «The Evolution of Style Guides» (https://mail.python. org/pipermail/python-ideas/2015-March/032557.html), начатое Яном Ли в спис - ке рассылки Python-ideas. Ли отвечает за сопровождение пакета pep8 (https:// pypi.python.org/pypi/pep8/), который проверяет исходный Python-код на совмес- Послесловие  879\n--- Страница 879 ---\nтимость с документом PEP 8. Для проверки кода в этой книге я пользовался программами flake8 (https://pypi.python.org/pypi/flake8), которая обертывает pep8, pyflakes (https://pypi.python.org/pypi/pyflakes) и плагином McCabe для оценки слож - ности, написанным Нэдом Бэтчелдером (https://pypi.python.org/pypi/mccabe). Помимо PEP 8, есть и другие авторитетные стилистические руководства: Google Python Style Guide (https://google-styleguide.googlecode.com/svn/trunk/ pyguide.html) и Pocoo Style Guide (http://www.pocoo.org/internal/styleguide/), пред- ложенное командой, подарившей нам Flake, Sphinx, Jinja 2 и другие не менее замечательные библиотеки на Python. Руководство автостопщика по Python (Hitchhiker’s Guide to Python!) (http:// docs.python-guide.org/en/latest/) – коллективный труд, посвященный написанию кода в духе Python. Наибольший вклад в него внес Кеннет Рейц, легендарный герой сообщества, прославившийся своим образцово «питоническим» па- кетом requests. Дэвид Гуджер представил на конференции PyCon US 2008 по- собие под названием «Code Like a Pythonista: Idiomatic Python» (https://david. goodger.org/projects/pycon/2007/idiomatic/handout.html). В печатном виде оно зани- мает 30 страниц. Гуджер создал reStructuredText и docutils, положенные в основу Sphinx, великолепной системы документирования для Python (кстати говоря, в ней подготовлена и официальная документация по MongoDB и многим дру- гим проектам). Мартин Фаассен поднимает вопрос «Что такое дух Python?» в своем блоге (http://blog.startifact.com/posts/older/what-is-pythonic.html) В списке рассылки python- list есть обсуждение с таким же заголовком (http://bit.ly/1e8raAA). Статья Марти- на относится к 2005 году, а это обсуждение – к 2003-му, но «питонический» иде- ал изменился не сильно – как, впрочем, и сам язык. Из обсуждений, в заголовке которых встречается слово «Pythonic», хотелось бы выделить «Pythonic way to sum n-th list element?» (https://mail.python.org/pipermail/python-list/2003-April/192027. html), которое я обильно цитировал во врезке «Поговорим» в главе 12. В документе PEP 3099 «Things that will Not Change in Python 3000» (https:// www.python.org/dev/peps/pep-3099/) объясняется, почему многие вещи реализо- ваны так, а не иначе, даже после масштабной переработки Python при выходе версии 3. Долгое время Python 3 называли Python 3000, но он появился на не- сколько столетий раньше – приведя некоторых в смятение. Автор документа PEP 3099, Георг Брандл, собрал многие высказывания нашего пожизненного ве- ликодушного диктатора, Гвидо ван Россума. На странице Python Essays (https:// www.python.org/doc/essays/) опубликовано несколько текстов самого Гвидо.880  Послесловие\n--- Страница 880 ---\nПредметный указатель @asyncio.coroutine, декоратор 721 @ знак 540 @cached_property, декоратор 790 @contextmanager, декоратор 617 @dataclass аргументы по умолчанию 190 именованные аргументы 190 переменные только для инициализации 196 метод __hash__ 191 пример использования 197 постинициализация 194 опции полей 191 типизированные атрибуты класса 196 @typing.overload, декоратор 492 ^, оператор 393 +=, оператор 77, 545 +ELLIPSIS, директива 35 + оператор 530 +, оператор 38, 76, 530, 533 +x 531 <=, оператор 542 <, оператор 542 == оператор 213, 230, 393, 542 := оператор 53 !=, оператор 542 *=, оператор 77, 545 >=, оператор 542 >, оператор 542 |=, оператор 102 |, оператор 102 ~, оператор 530 404, код ошибки (Не найдено) 711 % (деление по модулю), оператор 33 ** (двойная звездочка) 242 ** (двойная звездочка), оператор 101 __ (двойное подчеркивание) 32 __abs__ 38 __add__ 38, 78, 533, 548 .add_done_callback(), метод 698 .append(), метод 90*args 62 __bool__ 41 __builtins__ 99 __bytes__ 353 __call__ 240 __class__ 802, 835 __contains__ 35, 114 __del__ 225 __delattr__ 804 __delete__ 810 __dict__ 99, 802 __dir__ 804 __doc__ 235 __enter__ 613 __eq__ 393 .__eq__ 542 __exit__ 613 __float__ 363 __format__ 353, 358, 399, 408 .frombytes(), метод 356 __get__ 810 __getattr__ 390, 804 __getattribute__ 804 __getitem__ 33, 111, 388 __hash__ 363, 393 __iadd__ 78, 549 _ (подчеркивание) 67, 369 -, оператор 530 __init__ 37, 571, 779 __init_subclass__ 840 __int__ 363 __invert__ 530 .items(), метод 129 __iter__ 559, 562 .keys() метод 129 __len__ 33, 45, 388 __missing__ 112 __mro__ 440, 835 __mul__ 38, 538 __name__ 835 __neg__ 530 __new__ 779, 808\n--- Страница 881 ---\n__next__ 562, 566 __pos__ 530 __post_init__ 194 __prepare__ 871 __radd__ 535 __repr__ 38, 40, 353 __rmul__ 538 __set__ 810, 815 __setattr__ 805 __setitem__ 74, 418 __set_name__ 840 __slots__ 370, 393, 802, 846 __str__ 40, 353 __subclasshook__ 441 [], квадратные скобки 35, 52, 74 коллекций API 41 \\\\ (обратная косая черта) 52 [:], оператор 216 *, оператор 38, 76, 242, 538 #, оператор 45 (), оператор вызова 240 … (многоточие) 75, 383 (), скобки 52 *_, символ 68 \\\\N{} (нотация литералов Unicode) 152 {}, фигурные скобки 52 .pop(), метод 90 .result(), метод 698 !r, поле преобразования 40 %r, спецификатор 40 A ABC (абстрактный базовый класс) виртуальные подклассы 438 аннотации типов 277 в стандартной библиотеке 427 гусиная типизация 422 использование функции register 440 определение и использование 430 синтаксические детали 435 создание подкласса 426 создание подкласса гусиная типизация 426 создание подклассов ABC 435 структурная типизация 440 UML-диаграмма классов 42 abc.ABC, класс 428 abc.Iterable 280 abc.Sequence 280 and, оператор 530Any, тип 266 array.array, класс 356 asciize, функция 161 asyncio, пакет документация 720 достижение максимальной производительности 728 загрузка файлов 725 реализация очереди 93 пример скрипта 721 улучшение асинхронного загрузчика 730 asyncio, пакет предоставляемые API 93 asyncpg 729 B bisect, модуль 82 black, инструмент 260 blue, инструмент 260 BOM (маркер порядка байтов) 146 bool, тип 41 bool(x) 41 bytearray, тип 137 C Callable, абстрактный базовый класс 429 Callable, тип 288 callable(), функция 240 chain, генератор 591 ChainMap 116 Chardet, библиотека 146 classmethod, декоратор 357 clock, декоратор параметризованный 324 на основе класса 327 cls.__bases 835 cls.mro() 836 cls.__qualname__ 835 cls.__subclasses__() 835 collections.abc, модуль включенные ABC 428 ChainMap 116 collections.deque 90 collections.MutableSequence 127, 426 Counter 117 defaultdict 111 defaultdict и OrderedDict 106 множественное наследование 475882  Предметный указатель\n--- Страница 882 ---\nMapping и MutableMapping 105, 429 UserDict 118 collections.deque класс 90 collections.namedtuple, класс 34, 181 concurrent.futures загрузка файлов 696 запуск процессов 701 Container, абстрактный базовый класс 428 Container, интерфейс 42 copy, функция 218 Counter 117 CPython 225 Curio, проект 760 D Dask 675 decimal.Decimal, класс 531 deepcopy, функция 218 defaultdict 106, 111 default_factory 111 del, предложение 75, 800 deque (двусторонняя очередь) 83, 90 dis, модуль 306 Django, каркас 477 doctest, пакет для тестирования +ELLIPSIS, директива 35 dunder-методы 33 E EAFP, принцип 639 else, блоки 638 Executor.map 704 F FastAPI, каркас 742 FIFO (первым пришел, первым ушел) 83 flags2_common.py, модуль 707 flake8, инструмент 260 f-строки делегирование форматирования 358 преимущества 33 специальные методы для строкового форматирования 40 fold_equal, функция 158 for/else, комбинация 638 ForkingMixin 476 for, циклы 398 fromhex, метод класса 139 frozenset 123fsdecode(), функция 170 fsencode(), функция 170 functools, модуль декоратор cache 315 кеширование свойств 789 functools.lru_cache 315 functools.reduce 394, 588 functools.singledispatch 318 functools.wraps, декоратор 314 фиксация аргументов 248 futures.as_completed 713 G gevent, библиотека 660 greenlet, пакет 660 H Hashable, абстрактный базовый класс 429 heapq, пакет 93 HTTPServer, класс 475 HTTPX, библиотека 725 I is, оператор 213, 530 isinstance, функция 425 Iterable, абстрактный базовый класс 428 Iterable, интерфейс 42 iter, функция и специальный метод __iter__ 37 перебор слов 557 itertools, модуль 577 J JSON-подобные данные 775 Jupyter, проект 675 K key, аргумент 98 KISS, принцип 408, 490, 687 L LBYL, принцип 639 Least Recently Used (LRU) 317 lis.py, интерпретатор класс Environment 626 класс Procedure 636 предложения импорта и типы 623 синтаксический анализатор 624 синтаксис Scheme 622 сопоставление с образцом 69 Предметный указатель  883\n--- Страница 883 ---\nцикл REPL 628 функция evaluate 629 OR-образцы 637 list.sort, метод 81 locale.strxfrm, функция 163 LRU. См. Least Recently Used lru_cache, декоратор 315 M map, функция 396 Mapping, абстрактный базовый класс 429 MappingProxyType, класс-обертка 120 MappingView, абстрактный базовый класс 429 match/case, предложение 65, 102 memoryview, класс 86 MGN (нотация хреновин и штуковин) 813 MRO (порядок разрешения методов) 440, 473 multiprocessing, пакет 93, 655 MutableMapping, абстрактный базовый класс 105 MutableSet 127 Mypy, программа проверки типов 256 N namedtuple 181 nfc_equal, функция 158 NFKC/NFKD, нормализация 156 nonlocal, объявление 300 NoReturn, тип 291 not, оператор 530 NotImplemented 536 NotImplementedError 536 numbers, пакет 278, 453 абстрактные базовые классы 453 NumPy 88 O operator, модуль 245 Optional, тип 269 OrderedDict 106, 115 OR-образцы 637 or, оператор 530 os, модуль 170 os, модуль, использование типов str и bytes 170 os.walk, генераторная функция 578P pickle, модуль 117 Pingo, библиотека 120 property, класс 794 property, функция 314 PSF. См. Python Software Foundation PUG. См. Python, группы пользователей PyLadies 878 Python работа на многоядерных процессорах 673 сайт fluentpython.com 25 сообщество 878 функциональное программирование 251 Python, группы пользователей 879 Python Software Foundation 878 python-tulip, список рассылки 878 PyTorch 675 pyuca, библиотека 164, 171 PyUCA, модуль 164 Q queue, пакет 93 R reduce, функция 393, 395, 588 re.findall, функция 571 re.finditer, функция 571 register, метод 438, 440 reprlib, модуль 383 requests, библиотека 695 S sanitize.py, модуль 160 S-выражение 622 Scheme, язык 69, 622 SciPy 88 self, аргумент 815, 832 Sentence, классы 564 Sequence, абстрактный базовый класс 429 Set, абстрактный базовый класс 429 setlocale, функция 163 shelve, модуль 117 singledispatch, декоратор 318 Sized, абстрактный базовый класс 428 Sized, интерфейс 42 staticmethod, декоратор 357 str.casefold, метод 158884  Предметный указатель\n--- Страница 884 ---\nstr.format, метод 40, 358 str.format(), метод 33 StrKeyDict 118 str, функция 37 struct, модуль 136 SyntaxError, исключение 144 T TCP-сервер 746 TensorFlow 675 ThreadingHTTPServer, класс 476 ThreadingMixIn, класс 476 t[:], оператор 226 Timsort, алгоритм сортировки 98 Tkinter, инструмент разработки GUI достоинства и недостатки 485 множественное наследование 480 TQDM, пакет 707, 713 try/else, комбинация 638 Twisted, библиотека 770 TypedDict 176, 498 Typeshed, проект 279 TypeVar 280 typing, модуль 266 typing.NamedTuple 184 U UML-диаграммы классов ABC в collections.abc 428 для класса TkInter Widget и его суперклассов 472 для паттерна проектирования Команда 345 для паттерна проектирования Стратегия 335 аннотированные на языке MGN 812 из модуля django.views.generic. base 478 из модуля django.views.generic. list 480 наиболее важные типы коллекций 42 MutableSequence и его суперклассов 427 управляемых и дескрипторных 811 упрощенная для collections.abc 51 упрощенная для MutableMapping и его суперклассов 105 упрощенная для MutableSetet4 и его суперклассов 127Sequence и связанных с ним абстрактных классов 416 TomboList 438 Unicode база данных 165 базовые кодировщики и декодировщики 140 двухрежимный API 168 диакритические знаки 159 алгоритм упорядочивания (UCA) 164 алгоритм упорядочивания Unicode 164 канонические эквиваленты 155 комбинирование символов 155 обработка текстовых файлов 147 проблемы кодирования и декодирования 141 нормализация для надежного сравнения 155 нотация литералов \\\\N{} 152 основные сведения о байтах 137 сворачивание регистра 158 сравнение нормализованного текста 158 символы и стандарт Unicode 136 символы совместимости 156 сортировка текста 162 сэндвич Unicode 147 SyntaxError, исключение 144 UnicodeDecodeError 143 UnicodeEncodeError 142 Union, тип 269 UserDict 118 uvloop 769 V Vector2d пример класса 354 полный код 365 хешируемость 361 Vector, класс, многомерный доступ к динамическим атрибутам 390 __format__ 399 __hash__ и __eq__ 393 применения 382 протоколы и утиная типизация 385 последовательности, допускающие срез 386 совместимость с Vector2d 382 Предметный указатель  885\n--- Страница 885 ---\nW while/else, комбинация 638 Y экземпляр дескриптора 812 yield, ключевое слово 240, 567, 568, 574, 598, 601, 622 yield from, выражение 590 А абсолютное значение 38 агрегатные классы 484 Адаптер, паттерн 475 аргументы чисто именованные 242 key 98 фиксация с помощью functools. partial 248 self 815, 832 арифметическая прогрессия, генератор 575 арифметические операторы 535 акцессоры 772, 807 анонимные функции 239, 252 аннотаций переменных синтаксис 186 аннотации переменных семантика 186 аннотации типов для асинхронных объектов 763 аннотирование чисто позиционных и вариадических параметров 291 достоинства и недостатки 254 краткое введение 185 и поддерживаемые операции 261 обобщенных для классических сопрограмм 605 несовершенная типизация и строгое тестирование 292 постепенная типизация 255 типы, пригодные для использования в 266 асинхронные генераторы 240, 721 асинхронное программирование аннотации типов для асинхронных объектов 763 асинхронные контекстные менеджеры 729 делегирование задач исполнителям 739итераторы и итерируемые объекты 751 ловушка счетных функций 765 миф о системах, ограниченных вводом-выводом 765 написание асинхронных серверов 740 объекты, допускающие ожидание 724 пример использования asyncio 721 проект Curio 760 терминология 720 улучшение асинхронного загрузчика 730 атрибуты виртуальные 772 доступ к динамическим атрибутам 390 закрытые и защищенные 368, 379 защита и безопасность 379 имена 778 переопределение атрибутов класса 374 проверка значений с помощью дескрипторов 811 свойства и начальные затраты 378 специальные 802 удаление 800 хранения 812, 816 управляемые 812 экземпляра 829 Б байт-код, диассемблирование 306 блокировка определение термина 650 блоки with, match и else блоки else 638 контекстные менеджеры и блоки with 613 блоки with, math и else сопоставление с образцом в lis. py 622 будущие объекты общие сведения 698 практический пример 699 определение термина 691 В вариантность в типах Callable 289886  Предметный указатель\n--- Страница 886 ---\nинвариантные типы 514 ковариантные типы 516 контравариантные типы 516 кому интересна 514 нотация в других языках 526 эвристические правила 520 векторы перегрузка оператора + 533 представление двумерных 37 ВерблюжьяНотация (CamelCase) 809, 878 виртуальные атрибуты 772 виртуальные подклассы 438, 440 встроенные функции 99 вызов по соиспользованию 219, 232 вызов по ссылке 231 вызываемые объекты девять типов 240 в сочетании с iter() 560 пользовательские 241 выполнения этап 304, 417, 849 вычисляемые свойства 781 выборка связанных записей с помощью свойств 784 кеширование свойств 788 кеширование свойств с помощью functools 789 переопределение существующего атрибута свойством 787 создание управляемого данными атрибута 782 Г генераторные функции в стандартной библиотеке 578 реализация итерирования 567 определение термина 240 генераторы делегирующие 590 генераторные сопрограммы 721 генераторные функции в стандартной библиотеке 578 арифметической прогрессии 575 асинхронные генераторные функции 752 реализация класса Sentence 567 ленивые 570 ключевое слово yield 568 когда использовать генераторные выражения 573обобщенные итерируемые типы 596 примеры 568 сравнение с итераторами 574 субгенераторы 590 функции редуцирования итерируемого объекта 588 генераторные выражения 52, 55, 237, 573, 758 глобальная блокировка интерпретатора (GIL) 90, 650, 662, 673, 684 глубокая копия 218 гусиная типизация ABC в стандартной библиотеке 427 виртуальные подклассы ABC 438 использование функции register 440 определение и использование ABC 430 определение термина 411 метод __subclasshook__ 441, 559 синтаксические детали ABC 435 создание подклассов ABC 426 структурная типизация 440 Д двоичные последовательности 137 встроенные типы 137 разделение памяти 140 fromhex, метод класса 139 поддержка методов str 138 построение 139 способы отображения 138 декартово произведение, построение 54 декодирование общие сведения 140 определение термина 137 Декоратор, паттерн 314, 331 декораторы и замыкания динамическая область видимости 330 дополнение класса с помощью декоратора класса 847 в стандартной библиотеке Python 314 выполнение декораторов 302 замыкания в lis.py 636 реализация декоратора 312 регистрационные декораторы 304, 323 Предметный указатель  887\n--- Страница 887 ---\nкраткое введение в декораторы 301 композиция декораторов функций 435 назначение 300 параметризованные декораторы 322 объявление nonlocal 310 правила видимости переменных 304 пример замыкания 308 поведение декоратора 313 определение замыкания 310 основы замыканий 307 сравнение classmethod и staticmethod 357 декорирование имен 368 дерева обход 592 деструктуризация 66 дескрипторный класс 812 дескрипторы 188, 810. См. также дескрипторы атрибутов проверяющий 828 дескрипторы атрибутов дескрипторы данных 822 назначение 810 перезаписывание 825 переопределяющие и непереопределяющие 790, 820 методы как 826 проверка значений атрибутов 811 советы по использованию 828 строка документации и перехват удаления 829 терминология 811 диакритические знаки 159 динамические атрибуты и свойства важные атрибуты и функции для работы с атрибутами 802 вычисляемые свойства 781 и виртуальные атрибуты 772 использование свойств для контроля значений 791 применение для обработки данных 773 программирование фабрики свойств 798 удаление 800 property, класс 794 динамическая область видимости 330 динамические протоколы 386, 415 динамический тип 266дросселирование 733 дуализм функции и класса 809 Е единица выполнения 648 З загрузка файлов из веба индикация хода выполнения 707, 713 обработка ошибок 711 параллельная и последовательная 692 запашки в коде 176, 199, 425 запоминание 315 замыкания. См. декораторы и замыкания; защитное программирование 419 И идентификаторы объектов 213 идиомы кодирования 409 изменяемые значения вставка и обновление 108 именованные классы-образцы 202 импорта этап 302, 849 инвертированные индексы 741 индикаторы хода загрузки реализация на основе процессов 655 реализация на основе потоков 652 реализация на основе сопрограмм 656 сравнение супервизоров 660 итераторы асинхронные 751 ленивые последовательности 570 классы Sentence с методом __ iter__ 564 и итерируемые объекты 561 обобщенные итерируемые типы 596 протокол последовательности 557 сравнение с генераторами 574 функция iter() 558 итерирование 556 неявная природа 35 с помощью генераторных функций 567 итерируемые объекты 559 асинхронные 751888  Предметный указатель\n--- Страница 888 ---\nраспаковка 61 и итераторы 561 функции редуцирования 588 интернирование 227 интерфейсы. См. также гусиная типизация; протоколы ABC (абстрактный базовый класс) 426 Container 42 роль в объектно-ориентированном программировании 411 карта типизации 412 протоколы как неформальные интерфейсы 407 Iterable 42 Sequence 415 Sized 42 явные 483 инфиксные операторы 528, 540 обработка исключений 538 операнды 534 особый механизм диспетчеризации 534 К карта типизации 412, 459 канонические эквиваленты 155 кеширование и дескрипторы атрибутов 828 и слабые ссылки 226 крокозябры, определение термина 143 кладистика 423 классы агрегатные 484 дескрипторные 810 реализация обобщенного класса 511 как вызываемые объекты 240 как объекты 835, 877 недокументированные 526 примеси 477, 484 нотация MGN 813 классы протоколов 386 ключевые слова as 67 await 724 зарезервированные 631 lambda 239 nonlocal 311, 634 yield 240, 567, 574, 598, 601, 622ключи автоматическая обработка отсутствующих 111 обработка отсутствия 108 практические последствия внутреннего устройства класса dict 122 преобразование нестроковых ключей в тип str 118 постоянное хранилище для отображения 117 сортировка по нескольким 246 сохранение порядка вставки 43, 868 хешируемость 105 ковариантность. См. вариантность кодек 140 кодировка проблемы кодирования и декодирования 141 определение 136 по умолчанию 150 основные сведения 141 UCS-2 141 UTF-8 145 UTF-8-SIG 147 кодовая позиция 136 кортежи аннотации типа 273 распаковка 58 как неизменяемые списки 58 классические именованные 181 о природе 96 относительная неизменяемость 214, 226 сравнение со списками 60 упрощенная диаграмма размещения в памяти 50 typing.NamedTuple 184 коллекции как итерируемые объекты 556 колода карт, пример 33 Команда, паттерн проектирования 345 композиция 483 композиция декораторов 316 композиция объектов 483 контейнерные последовательности 97 контекстные менеджеры демонстрации 613 асинхронные 729 Предметный указатель  889\n--- Страница 889 ---\nасинхронные генераторы в качестве 756 @contextmanager, декоратор 617 интерфейс 613 назначение 613 необычные применения 613 скобочные в Python 3.10 616 утилиты contextlib 617 контравариантность. См. вариантность конкатенация 76 конкурентность загрузка с применением concurrent. futures 696 запуск задач с помощью concurrent. futures 701 индикация хода выполнения 707 использование futures.as_ completed 713 обработка ошибок 707, 711 примеры 692 сравнение параллельного и последовательного скриптов 693 тестирование параллельных клиентов 707 конкурентные исполнители загрузка с индикацией хода выполнения и обработкой ошибок 707 конкурентная загрузка из веба 692 Executor.map 704 кооперативное множественное наследование 471 копирование глубокое 218 поверхностное 215 коэффициент Отиаи 382 Л лексическая область видимости 331 ленивое вычисление 552, 570 локаль, установка 163 Лундха рецепт рефакторинга лямбда- выражений 239 М магические методы 33 массивы 50, 83 метаклассы демонстрация работы 860реализация Checked с помощью 864 предостережения 868 пример 857 определение термина 837 полезные применения 872 метаобъекты 47 метапрограммирование 302 метапрограммирование классов дополнение класса с помощью декоратора 847 достоинства и недостатки 834 встроенная фабрика классов 836 реализация Checked с помощью метакласса 864 классы как объекты 835 метод __prepare__ 870 проблемы метаклассов 868 полезные применения метаклассов 872 __init_subclass__ 840 фабрика классов 837 этап импорта и этап выполнения 849 методы встроенные 240 как дескрипторы 826 как вызываемые объекты 240 определение термина 772 мини-язык спецификации формата 359, 399 множества. См. также словари и множества литеральные 125 практические последствия внутреннего устройства класса set 126 операции над 127 множественное включение 126 теория множеств 123 множественное наследование. См. также наследование на практике 475 многоточие (…) 35, 74 многоядерная обработка веб-разработка на стороне сервера и на мобильных устройствах 676 распределенные очереди задач 680 наука о данных 675 системное администрирование 674 WSGI-серверы приложений 678890  Предметный указатель\n--- Страница 890 ---\nмодели конкурентности влияние GIL 662 конкурентная программа Hello World 652 и многоядерные процессоры 673 основные сведения 646 пулы процессов 665 структурная конкурентность 761 терминология 648 модель данных использование специальных методов 36 методы __getitem__ и __len__ 33 общие сведения 32 поведение __len__ 45 сводка специальных методов 43 Н накопительное среднее, вычисление 308, 599 наследование в разных языках 490 виртуальные подклассы ABC 438 встроенным типам 465 рекомендации 482 классы-примеси 473 и композиция 382 обобщенным базовым классам 426, 435 практические примеры 475 множественное наследование и порядок разрешения методов 468 функция super() 463 начальное значение 106 несовершенная типизация 292 неявное преобразование 135 номинальная типизация 262 О обобщенные коллекции и аннотации типов 270 параметризованные обобщенные типы и TypeVar 280 обобщенные отображения 275 обобщенные статические протоколы 520 обобщенные функции 318 область видимости глобальная область видимости модуля 306 динамическая и лексическая 330внутри включений и генераторных выражений 53 локальная область видимости функции 306 правила видимости переменных 304 обработка данных гибкое создание объектов 779 исследование JSON-подобных данных 775 применение динамических атрибутов 773 проблема недопустимого имени атрибута 778 объектная модель 46 объекты в духе Python 352 гибкое создание 779 вызываемые 240, 560 изменяемые 220, 230 классы как 835 итерируемые 559 обращение с функцией как с объектом 235 одиночки 214 полноправные 234, 876 пользовательские вызываемые 241 хешируемые 105, 361 уничтожение 231 объекты в духе Python. См. также объекты альтернативный конструктор 356 закрытые и защищенные атрибуты 368 представления объекта 353 пример класса Vector2d 354 поддержка позиционного сопоставления с образцом 363 полный код класса Vector2d 365 сравнение classmethod и staticmethod 357 создание собственных классов 352 хешируемый класс Vector2d 361 форматирование при выводе 358 экономия памяти с помощью __ slots__ 370 опережающей ссылки проблема 508 операторы составного присваивания 78, 545 Предметный указатель  891\n--- Страница 891 ---\nоптимизация хвостовой рекурсии (TCO) 643 отображения автоматическая обработка отсутствующих ключей 111 распаковка 101 не зависящие от регистра 473 обзор методов 106 неизменяемые 120 объединение 102 сопоставление с отображением- образцом 102 стандартный API 105 очереди реализация 92 распределенные очереди задач 680 deque (двусторонняя очередь) 83 определение термина 649 П параллелизм 646, 648 параллельное присваивание 62 параметризованные типы 514 параметры чисто именованные 243 чисто позиционные 244 аннотирование чисто позиционных и вариадических параметров 291 изменяемые 220, 222 интроспекция параметров функций 235 передача 231 параметры функций 219 параметры функций, интроспекция 235 партизанское латание 417, 460, 825 паттерны проектирования 333 перегруженные сигнатуры 492 перегрузка операторов 528 достоинства 529, 552 имена методов инфиксных операторов 541 инфиксные операторы 528, 541 использование @ как инфиксного оператора 540 недостатки 552 операторы сравнения 542 операторы составного присваивания 545 сложение векторов 533унарные операторы 530 умножение на скаляр 538 перегрузка функций и методов 319 переработка паттерна Стратегия дополнение декоратором 343 выбор наилучшей стратегии 341 классический паттерн 334 паттерн Команда 345 поик стратегий в модуле 342 функционально-ориентированная стратегия 338 переменные логика поиска 311 метафора этикеток и ящиков 210 свободные 309 только для инициализации 196 платформенные сопрограммы определение термина 720 сравнение с асинхронными генераторами 757 функции, определенные с помощью async def 240 подмешанные методы 475 подсчет ссылок 225 подтипизация по поведению 268 позиционное сопоставление с образцом 363 позиционные классы-образцы 204 позиционные параметры 242 полноправные объекты 234, 876 поразрядные операторы 44, 530 порядок разрешения методов 440, 473 последовательности единообразная обработка 48 альтернативы списку 83 допускающие срез 386 доступ к динамическим атрибутам 390 встроенные 49 распаковка 61 изменяемые 50, 418 кортежи 57 контейнерные 49, 97 использование + и * 76 __format__ 399 __hash__ и __eq__ 393 неизменяемые 50 протоколы и утиная типизация 385 плоские 49, 97 получение среза 72892  Предметный указатель\n--- Страница 892 ---\nпостроение 51 совместимость с Vector2d 382 сортировка 81 списковое включение и генераторные выражения 51 сопоставление с образцом 64 стратегия реализации вектора 382 последовательности байтов 145 построители классов данных аннотации типов 185 @dataclass 190 класс данных как признак кода с душком 199 классические именованные кортежи 181 основные возможности 179 сопоставление с экземплярами классов – образцами 201 типизированные именованные кортежи 184 поток влияние GIL 663 реализация индикатора хода загрузки 652 нежелательности 717 определение термина 649 улучшение асинхронного загрузчика 730 представления областей памяти 86 представления с ограниченной длиной 383 приведение типов 505 принцип единообразного доступа 772, 806, 807 принцип быстрого отказа 108, 398, 419 программ проверки типов для Python 256 процесс запуск с помощью concurrent. futures 701 определение термина 648 протоколы. См. также интерфейсы числовые 453 динамическая природа 419 динамические 386 достоинства 418 защитное программирование 419 значения слова 413 реализация во время выполнения 417реализация обобщенного статического протокола 520 как неформальные интерфейсы 407 и утиная типизация 385 последовательности 386, 414, 415, 557 статические 386, 443 псевдонимия 212 пулы процессов код проверки на простоту для многоядерной машины 668 интерпретация времени работы 667 пример задачи 665 Р распаковка вложенных объектов 63 использование * в вызовах функций и литеральных последовательностях 63 использование * для выборки лишних элементов 62 последовательностей и итерируемых объектов 61 отображений 101 распределенные очереди задач 680 регулярные выражения, str и bytes 168 ромбовидного наследования проблема 468 С сборка мусора 224, 231 серверы класс HTTPServer 475 класс ThreadingHTTPServer 476 написание асинхронных 740 тестовые 710 шлюзовой интерфейс веб-серверов (WSGI) 678 шлюзовой интерфейс асинхронных серверов (ASGI) 680 TCP-сервер 746 свободные переменные 309, 331, 636 свойства достоинства 876 выборка связанных записей 784 и атрибуты экземпляров 795 общие сведения 794 строки документации 797 фабрики свойств 798 Предметный указатель  893\n--- Страница 893 ---\nсворачивание регистра 158 семафоры 733 сетевой ввод-вывод загрузка с индикацией хода выполнения и обработкой ошибок 707 загрузка с применением asyncio 725 загрузка с применением concurrent. futures 696 миф о системах, ограниченных вводом-выводом 765 скрипт последовательной загрузки 694 улучшение асинхронного загрузчика 730 сравнения операторы 44, 213, 530, 542 срезка демонстрация 387 исключение последнего элемента среза 73 объекты среза 73 присваивание срезу 75 многомерные срезы и многоточие 74 последовательности, допускающие срез 386 синглтон 214 символы числовое значение 167 кодирование и декодирование 137 определение 136 поиск по имени 165 совместимости 156 синтаксический сахар 133 система постепенной типизации чтение аннотаций типов во время выполнения 508 абстрактные базовые классы 276 реализация обобщенного класса 511 реализация обобщенного статического протокола 520 и вариантность 514 перегруженные сигнатуры 492 параметризованные обобщенные типы и TypeVar 280 обобщенные коллекции 270 обобщенные отображения 275 на практике 256 приведение типов 505 простые типы и классы 269поддержка унаследованных типов и нерекомендуемые типы коллекций 271 отношения является подтипом и совместим с 267 тип Any 266 тип Callable 288 тип Iterable 278 тип NoReturn 291 типы кортежей 273 типы Optional и Union 269 TypedDict 498 системное администрирование 674 системы, ограниченные вводом- выводом 765 слабые ссылки 226 словари и множества вариации на тему dict 115 автоматическая обработка отсутствующих ключей 111 внутреннее устройство словарей 100 неизменяемые отображения 120 представления словаря 121 практические последствия внутреннего устройства класса dict 122 практические последствия внутреннего устройства класса set 126 операции над множествами 127 современный синтаксис словарей 100 сопоставление с отображением- образцом 102 стандартный API типов отображений 105 теоретико-множественные операции над представлениями словарей 129 теория множеств 123 словарное включение (dictcomp) 100 сложение на месте 78, 548 совместимости символы 156 специальные атрибуты 802 специальные методы для работы с атрибутами 804 булево значение пользовательского типа 41 API коллекций 42 вызов 36894  Предметный указатель\n--- Страница 894 ---\n__getitem__ и __len__ 33 назначение 32 неявная природа 37 преимущества 35 пример реализации 39 сводка 43 соглашение об именовании 32 строковое представление 40 эмуляция числовых типов 37 сортировка 81, 98 списки альтернативы 83 кортежи как неизменяемые списки 60 поверхностное копирование 215 многострочные 52 построение списка списков 76 сравнение list.sort и встроенной функции sorted 81 смешанные типы 97 списковое включение (listcomp) генерация декартова произведения 54 вложенные списки 76 асинхронное 758 замечание о синтаксисе 52 и генераторные выражения 55 как альтернатива функциям map и filter 237 локальная область видимости 53 и удобочитаемость 52 построение последовательностей 51 сопрограммы генераторные 721 влияние GIL 663 возврат значения 601 аннотации обобщенных типов 605 вычисление накопительного среднего 599 классические 598 индикатор хода выполнения 656 определение термина 649 типы 720 сопоставление с образцом вариадические параметры 291 деструктуризация 66 в интерпретаторе lis.py 622 предложение match/case 64 *_, символ 68 символ _ 66с кортежами и списками 66 с отображением-образцом 102 с экземплярами классов- образцами 201 учет информации о типе 67 составные объекты 96 состязание 650 ссылки на объекты глубокое копирование 218 del и сборка мусора 224 и неизменяемость 226 параметры функций как ссылки 219 метафора ящиков и этикеток 210 поверхностное копирование 215 псевдонимия 212 статическая типизация 411 статическая утиная типизация 288, 411, 487 статические протоколы ABC из пакета numbers и числовые протоколы 453 допускающие проверку во время выполнения 444 реализация обобщенного статического протокола 520 рекомендации по проектированию 451 расширение 452 ограничения протоколов, допускающих проверку во время выполнения 447 проектирование 450 поддержка 448 определение 415 сравнение с динамическими 386 типизированная функция double 443 Стратегия, паттерн 334 строгое тестирование 292 строки двухрежимный API 168 представление с помощью специальных методов 40 сортировка по умолчанию 82 структурная конкурентность 761 структурная типизация 440 структуры данных последовательности 48 текст и байты 135 субгенераторы 590 Предметный указатель  895\n--- Страница 895 ---\nсхема дублинского ядра 197 счетчик ссылок 231 Т текстовые файлы кодирование и декодирование 147 теория множеств литеральные множества 125 математические операции 128 операторы сравнения множеств 129 множественное включение 126 хешируемость элементов 124 типизированная функция double 443 У умножение вектора на скаляр 38, 538 унарные операторы 530 управляемые атрибуты 812 управляемые классы 812 управляемые экземпляры 812 утиная типизация 108, 262, 298, 385, 408, 411, 446 Ф фактические параметры-типы 514 фильтрующие генераторные функции 578 формальные параметры-типы 514 функции декораторы и замыкания 435 генераторные 240 abs, встроеннная функция 38 диассемблирование байт-кода 306 анонимные 252, 307 встроенные 99, 240, 803 apply() 237 dir([object]) 803 double() 443 как полноправные объекты 876 filter() 53 format() 358 getattr(object, name[, default]) 803 globals() 342 hasattr() 803 обобщенные с одиночной диспетчеризацией 318 id() 213 пользовательские 240 iter() 559len() 34 map() 53 map, filter и reduce 237 max() 494 random.choice() 35 repr() 353 setattr(object, name, value) 803 sorted() 81 str() 353 super() 392, 463 vars([object]) 803 zip() 397 функции, аннотации типов аннотирование чисто позиционных и вариадических параметров 291 достоинства и недостатки 254 несовершенная типизация и строгое тестирование 292 постепенная типизация 255 типы, пригодные для использования в аннотациях 266 функции как полноправные объекты. См. также декораторы и замыкания гибкая обработка параметров 242 анонимные функции 239 вызываемые объекты 240 обращение с функцией как с объектом 235 определение термина 234 пользовательские вызываемые типы 241 функции высшего порядка 236 функциональное программирование пакеты для 245 на Python 251 функции редуцирования 588 Х хешируемость определение 105 хешируемые объекты 361 хеш-таблицы 99 Ч числовая башня 278 числовые протоколы 453 числовые типы проверка на конвертируемость 445, 455896  Предметный указатель\n--- Страница 896 ---\nподдержка 454 хешируемость 106 эмуляция 37 эмуляция с помощью специальных методов 37 чисто именованные аргументы 242 чисто хвостовая рекурсия (PTC) 643 Ш шлюзовой интерфейс веб-серверов (WSGI) 678шлюзовой интерфейс асинхронных серверов (ASGI) 680 Э эмодзи в Музее современного искусства 173 и консольный шрифт 152 нарастание проблем 175 полнота поддержки 166 поиск символов по имени 165 создание 136 Предметный указатель  897\n--- Страница 897 ---\nКниги издательства «ДМК Пресс» можно заказать в торгово-издательском холдинге «КТК Галактика» наложенным платежом, выслав открытку или письмо по почтовому адресу: 115487, г. Москва, пр. Андропова д. 38 оф. 10. При оформлении заказа следует указать адрес (полностью), по которому должны быть высланы книги; фамилию, имя и отчество получателя. Желательно также указать свой телефон и электронный адрес. Эти книги вы можете заказать и в интернет-магазине: www.galaktika-dmk.com. Оптовые закупки: тел. (499) 782-38-89. Электронный адрес: books@alians-kniga.ru. Лусиану Рамальо Python – к вершинам мастерства Лаконичное и эффективное программирование Второе издание Главный редактор Мовчан Д. А. dmkpress@gmail.com Зам. главного редактора Сенченкова Е. А. Перевод Слинкин А. А. Корректор Синяева Г. И. Верстка Луценко С. В. Дизайн обложки Мовчан А. Г. Формат 70×100 1/16. Гарнитура «PT Serif». Печать цифровая. Усл. печ. л. 72,96. Тираж 200 экз. Веб-сайт издательства: www.dmkpress.com",
      "debug": {
        "start_page": 833,
        "end_page": 898
      }
    }
  ]
}
{
  "title": "Введение в анализ алгоритмов [2019] Солтис",
  "chapters": [
    {
      "name": "Глава 1. Предварительные условия 13",
      "content": "--- Страница 14 --- (продолжение)\nГлава 1 Предварительные условия Считается, что более 70 % (!) усилий и затрат на разработку сложной про- граммной системы посвящены, так или иначе, исправлению ошибок. Алгоритм, стр. 107 [Harel (1987)] 1.1. Ч то такое правильность ? Для того чтобы показать, что алгоритм является правильным, мы должны каким-то образом показать, что он делает то, что должен делать. Сложность состоит в том, что алгоритм разворачивается во времени, и сложно работать с перемен-ным числом шагов, то есть циклами while. Мы собираемся ввести математический каркас для доказательства правильности алгоритма (и программы), который на-зывается логикой Хоара. В этом математическом каркасе используются индукция и инвариантность (см. раздел 9.1), а также логика (см. раздел 9.4), но мы будем использовать ее неформально. Формальный пример см. в разделе 9.4.4. Мы делаем два логических утверждения, именуемых предусловием и постусло- вием; под правильностью мы имеем в виду, что всякий раз, когда предусловие соблю дается перед исполнением алгоритма, постусловие будет соблюдаться по- сле его исполнения. Под завершением (остановом) мы имеем в виду, что всякий раз, когда соблюдается предусловие, алгоритм перестанет работать после конеч- ного числа шагов. Правильность без завершения называется частичной правиль- ностью, а правильность сама по себе является частичной правильностью с завер-шением. Вся эта терминология приводится здесь для того, чтобы связать ту или иную задачу с каким-то алгоритмом, который призван ее решить. Следователь-но, мы подбираем пред- и постусловие таким путем, который отражает эту связь и доказывает ее истинность. Эти понятия можно сделать точнее, но мы должны ввести некую стандартную форму записи: булевы связки: ∧ равно «и», ∨ равно «или» и ¬ равно «не». Мы также используем → в качестве логического следствия, то есть х → y логически эквива- лентно ¬x ∨ y, и ↔ является булевой эквивалентностью, а α ↔ β выражает ((α → β) ∧ (β → α)). ∀ – это универсальный квантификатор «для всех», и ∃ – экзистенциаль- ный квантификатор «существует». Мы используем «⇒» в качестве аббревиатуры для «влечет за собой», то есть 2|x ⇒ x является четным, в то время как «⇏» является аббревиатурой для «не влечет за собой». Пусть А равно алгоритму, и пусть  A равно множеству всех хорошо сформирован- ных входных данных; идея состоит в том, что если I ∈ A, то имеет «смысл» подать\nГлава 1 Предварительные условия Считается, что более 70 % (!) усилий и затрат на разработку сложной про- граммной системы посвящены, так или иначе, исправлению ошибок. Алгоритм, стр. 107 [Harel (1987)] 1.1. Ч то такое правильность ? Для того чтобы показать, что алгоритм является правильным, мы должны каким-то образом показать, что он делает то, что должен делать. Сложность состоит в том, что алгоритм разворачивается во времени, и сложно работать с перемен-ным числом шагов, то есть циклами while. Мы собираемся ввести математический каркас для доказательства правильности алгоритма (и программы), который на-зывается логикой Хоара. В этом математическом каркасе используются индукция и инвариантность (см. раздел 9.1), а также логика (см. раздел 9.4), но мы будем использовать ее неформально. Формальный пример см. в разделе 9.4.4. Мы делаем два логических утверждения, именуемых предусловием и постусло- вием; под правильностью мы имеем в виду, что всякий раз, когда предусловие соблю дается перед исполнением алгоритма, постусловие будет соблюдаться по- сле его исполнения. Под завершением (остановом) мы имеем в виду, что всякий раз, когда соблюдается предусловие, алгоритм перестанет работать после конеч- ного числа шагов. Правильность без завершения называется частичной правиль- ностью, а правильность сама по себе является частичной правильностью с завер-шением. Вся эта терминология приводится здесь для того, чтобы связать ту или иную задачу с каким-то алгоритмом, который призван ее решить. Следователь-но, мы подбираем пред- и постусловие таким путем, который отражает эту связь и доказывает ее истинность. Эти понятия можно сделать точнее, но мы должны ввести некую стандартную форму записи: булевы связки: ∧ равно «и», ∨ равно «или» и ¬ равно «не». Мы также используем → в качестве логического следствия, то есть х → y логически эквива- лентно ¬x ∨ y, и ↔ является булевой эквивалентностью, а α ↔ β выражает ((α → β) ∧ (β → α)). ∀ – это универсальный квантификатор «для всех», и ∃ – экзистенциаль- ный квантификатор «существует». Мы используем «⇒» в качестве аббревиатуры для «влечет за собой», то есть 2|x ⇒ x является четным, в то время как «⇏» является аббревиатурой для «не влечет за собой». Пусть А равно алгоритму, и пусть  A равно множеству всех хорошо сформирован- ных входных данных; идея состоит в том, что если I ∈ A, то имеет «смысл» подать\n--- Страница 15 ---\n14  Предварительные условия I на вход в А. Понятие «хорошо сформированные» входные данные также можно уточнить, но нам будет достаточно того, что мы опираемся на наше интуитив- ное понимание – в частности, в алгоритм, который в качестве входных данных берет пары чисел, не будет «подаваться» матрица. Пусть O = A(I) равно выходу из A на I, если он существует. Пусть α A равно предусловию и βA равно постусло- вию алгоритма А; если I удовлетворяет предусловию, то мы пишем αA(I), а если O удовлетворяет постусловию, то мы пишем βA(O). Тогда частичная правильность A относительно предусловия αA и постусловия βA может быть сформулирована как: (∀I ∈ A)[(αA(I) ∧ ∃O(O = A(I))) → βA(A(I))]. (1.1) На словах: для любых хорошо сформированных входных данных I, если I удов- летворяет предусловию, а A(I) производит выходные данные (то есть завершает - ся), то эти выходные данные удовлетворяют постусловию. Полная правильность равна (1.1) вместе с логическим утверждением, что для всех I ∈ A завершается (и, следовательно, существуют O такие, что O = A(I)). Задача 1.1. Модифицируйте (1.1) так, чтобы выразить полную правильность. Фундаментальным понятием в анализе алгоритмов является понятие инва- рианта цикла; он представляет собой логическое утверждение, которое остается истинным после каждого исполнения цикла «while» (или «for»). Придумать пра-вильное логическое утверждение и доказать его представляет собой настоящее творческое начинание. Если алгоритм завершается, то инвариант цикла – это ло-гическое утверж дение, которое помогает доказать импликацию α A(I) → βA(A(I))1. После того как показано, что инвариант цикла соблюдается, он используется для доказательства частичной правильности алгоритма. Таким образом, крите- рий отбора инварианта цикла заключается в том, что он помогает доказать пост - условие. В общем случае желаемое доказательство правильности может дать ряд разных инвариантов циклов (и в этом отношении пред- и постусловия); искусство анализа алгоритмов состоит в их разумном отборе. Обычно, для того чтобы дока-зать, что выбранный инвариант цикла соблюдается после каждой итерации цик - ла, нам нужна индукция, и обычно нам также нужно предусловие, которое служит в качестве допущения в этом доказательстве. 1.1.1. Сложность С учетом алгоритма  и входных данных x временем выполнения  на х является число шагов, которые требуются  для того, чтобы завершиться на входных дан- ных x. Деликатный вопрос здесь – определить понятие «шаг», но мы отнесемся к нему неформально: мы будем считать, что у нас есть машина случайного досту - па (машина, которая может осуществлять доступ к ячейкам памяти за один шаг), и мы будем считать, что присвоение типа x ← y выполняется за один шаг, и то же самое касается арифметических операций и проверки булевых выражений (на-пример, x ≥ y ∧ y ≥ 0). Разумеется, это упрощение не отражает истинное положение дел, если, например, мы манипулируем числами из 4000 бит (как в случае крип- 1 Инвариантом называется логическое выражение, истинное перед началом выполнения цикла и после каждой итерации цикла, зависящей от переменных, изменяющихся в теле цикла. Инварианты используются для доказательства правильности выполнения цикла, а также при проектировании и оптимизации циклических алгоритмов. – Прим. перев.\n--- Страница 16 ---\nЧто такое правильность?  15 тографических алгоритмов). Но тогда мы переопределяем шаги в соответствии с контекстом. Нас интересует сложность худшего случая. То есть с учетом алгоритма  мы обозначаем через T(n) максимальное время выполнения  на любых входных данных х размера n. Здесь «размер» означает число бит в разумной фиксирован- ной кодировке х. Вместо T(n) мы, как правило, пишем Т(n), так как обсуждаемый алгоритм задается контекстом. Оказывается, что T(n) может быть очень сложным даже для простых алгоритмов, и поэтому мы соглашаемся на асимптотические границы на T(n). Для того чтобы обеспечить асимптотические аппроксимации для T(n), мы вво- дим форму записи «O » большое. Рассмотрим функции f и g из � в �, то есть функции, область которых является натуральными числами, но может варьироваться над ве-щественными. Мы говорим, что g(n) ∈ O(f(n)), если существуют константы c, n 0 ∈ � такие, что для всех n ≥ n0, g(n) ≤ cf(n), и форма записи «о » малое, g(n) ∈ o(f(n)), которая означает, что limn→∞ g(n)/f(n) = 0. Мы также говорим, что g(n) ∈ Ω(f(n)), если существу - ют константы c, n0 такие, что для всех n ≥ n0, g(n) ≥ cf(n). Наконец, мы говорим, что g(n) ∈ Θ(f(n)), если имеет место, что g(n) ∈ O(f(n)) ⋂ Ω(f(n)). Если g(n) ∈ Θ(f(n)), то f(n) называется асимптотически плотной границей для g(n), а это означает, что f(n) яв- ляется очень хорошей аппроксимацией g(n). Обратите внимание, что на практике мы часто будем писать g(n) = O(f(n)) вместо формального g(n) ∈ O(f(n)); небольшое, но удобное злоупотребление математической формой записи. Например, an2 + bn + c = Θ(n2), где a > 0. Для того чтобы это увидеть, обратите внимание, что an2 + bn + c ≤ ( a + | b| + |c|)n2 для всех n ∈ �, и поэтому an2 + bn + c = O(n2), где мы взяли абсолютное значение b , c, потому что они могут быть отри- цательными. С другой стороны, an2 + bn + c = a((n + c1)2 – c2), где c1 = b/2a и c2 = (b2 – 4ac)/4a2, благодаря чему мы можем найти c3 и n0, вследствие чего для всех n ≥ n0, c3n2 ≤ a((n + c1)2 – c2), и поэтому an2 + bn + c = Ω(n2). Задача 1.2. Найдите c3 и n0 в терминах a, b, c. Затем докажите, что для k ≥ 0 åk i=0aini = Θ(nk); этим показывается упрощающее преимущество «O» большого. 1.1.2. Деление Что может быть проще целочисленного деления? Даны два целых числа x, y, и мы хотим найти частное и остаток от деления x на y . Например, если x = 25 и y = 3, то q = 8 и r = 1. Обратите внимание, что возвращаемые алгоритмом деления q и r обычно обозначаются соответственно как div(x, y) (частное) и rem(x, y) (остаток). Алгоритм 1.1. Деление Предусловие: x ≥ 0 ∧ y > 0 ∧ x, y ∈ � 1: q ← 0 2: r ← x3: while y ≤ r do4: r ← r – y 5: q ← q + 1 6: end while7: return q, r Постусловие: x = (q · y) + r ∧ 0 ≤ r < y\n--- Страница 17 ---\n16  Предварительные условия В качестве инварианта цикла мы предлагаем следующее логическое утверж - дение: x = (q · y) + r ∧ r ≥ 0, (1.2) и мы показываем, что (1.2) соблюдается после каждой итерации цикла. Базовый случай (то есть ноль итераций цикла – мы просто находимся перед строкой 3 ал-горитма): q = 0, r = x, поэтому x = (q · y) + r и, поскольку x ≥ 0 и r = x, r ≥ 0. Индукционный шаг: предположим, что x = (q · y) + r ∧ r ≥ 0, и мы еще раз прой- демся по циклу, и пусть q′, r′ равны новым значениям соответственно q, r (вычис - ленным в строках 4 и 5 алгоритма). Так как мы исполнили цикл еще раз, то полу - чается, что y < r (это условие проверено в строке 3 алгоритма), а так как r′ = r – y, то у нас получается r′ ≥ 0. Следовательно, x = (q · y) + r = ((q + 1) · y) + (r – y) = (q′ · y) + r′, и поэтому q′, r′ по-прежнему удовлетворяет инварианту цикла (1.2). Теперь мы используем инвариант цикла, для того чтобы показать, что (если ал- горитм завершается) постусловие алгоритма деления соблюдается, если соблюда-ется предусловие. В данном случае это очень просто, так как цикл заканчивается, когда больше не является истинным, что y ≤ r, то есть когда истинно, что r < y. С другой стороны, (1.2) соблюдается после каждой итерации, и в особенности по-следней итерации. Соединяя (1.2) и r < y, мы получаем наше постусловие и, следо- вательно, частичную правильность. Для того чтобы показать завершение, мы используем принцип наименьшего чис - ла (least number principle, LNP). Нам нужно связать некую неотрицательную моно-тонную убывающую последовательность с алгоритмом; просто рассмотрим r 0, r1, r2, …, где r0 = x, и ri – это значение r после i-й итерации. Обратите внимание, что ri+1 = ri – y. Во-первых, ri ≥ 0, потому что алгоритм входит в цикл while, только если y ≤ r, а во-вторых, ri+1 < ri, так как y > 0. По принципу наименьшего числа такая по- следовательность «не может продолжаться вечно» (в том смысле, что множество {r i|i = 0, 1, 2, … } является подмножеством натуральных чисел и поэтому имеет наи- меньший элемент), поэтому алгоритм должен завершиться. Таким образом, мы показали полную правильность алгоритма деления. Задача 1.3. Каково время выполнения алгоритма 1.1? То есть сколько шагов требуется для его завершения? Будем считать, что присваивания (строки 1 и 2) и арифметические операции (строки 4 и 5), а также проверка «≤» (строка 3) все выполняются за один шаг. Задача 1.4. Предположим, что предусловие в алгоритме 1.1 изменено, скажем, на «x ≥ 0 ∧ y > 0 ∧ x, y ∈ �», где � = { , –2, –1, 0, 1, 2, }. По-прежнему ли корректен алгоритм в этом случае? Что делать, если он изменяется на следующее «y > 0 ∧ x, y ∈ �»? Как бы вы модифицировали этот алгоритм для работы с отрицательными значениями?Задача 1.5. Напишите программу, которая принимает на входе x и y и выдает на выходе промежуточные значения q и r, и, наконец, частное и остаток от деления x на y.\n--- Страница 18 ---\nЧто такое правильность?  17 1.1.3. Евклид Пусть даны два положительных целых числа a, b, тогда их наибольший общий дели- тель (greatest common divisor), обозначаемый как gcd(a, b), есть наибольшее целое число, которое делит оба числа. Алгоритм Евклида, показанный как алгоритм 1.2, представляет собой процедуру нахождения наибольшего общего делителя двух чисел. Это один из старейших известных алгоритмов; он появился в «Элементах» Евклида (книга 7, пропозиции 1 и 2) около 300 года до нашей эры. Обратите внимание, что для вычисления rem(n, m) в строках 1 и 3 алгоритма Евклида нам необходимо в качестве подпрограммы использовать алгоритм 1.1 (алгоритм деления); это типичная «композиция» алгоритмов. Также обратите внимание, что строки 1 и 3 выполняются слева направо, поэтому, в частности, в строке 3 мы сначала выполняем m ← n, затем n ← r и, наконец, r ← rem(m, n). Это важно для правильной работы алгоритма, так как при выполнении r ← rem(m, n) мы используем только что обновленные значения m, n. Алгоритм 1.2. Евклид Предусловие: a > 0 ∧ b > 0 ∧ a, b ∈ � 1: m ← a ; n ← b ; r ← rem(m, n) 2: while (r > 0) do3: m ← n ; n ← r ; r ← rem(m, n) 4: end while5: return n Постусловие: n = gcd(a, b) Для того чтобы доказать правильность алгоритма Евклида, мы покажем, что после каждой итерации цикла while соблюдается следующее логическое утверж - дение: m > 0, n > 0 и gcd(m, n) = gcd(a, b), (1.3) то есть (1.3) – это наш инвариант цикла. Мы доказываем это по индукции на числе итераций. Базовый случай: после нуля итераций (то есть непосредственно перед началом цикла while – после исполнения строки 1 и перед исполнением строки 2) мы имеем, что m = a > 0 и n = b > 0, поэтому (1.3) соблюдается тривиально. Обратите внимание, что A > 0 и b > 0 по предусловию. На индукционном шаге будем считать, что m, n > 0 и gcd(a, b) = gcd(m, n), и мы проходим по циклу еще раз, получая m′, n′. Мы хотим показать, что gcd(m, n) = gcd(m′, n′). Обратите внимание, что из строки 3 алгоритма мы видим, что m′ = n, n′ = r = rem(m, n), поэтому, в частности, m′ = n > 0 и n′ = r = rem(m, n) > 0, так как если r = rem(m, n) было бы равно нулю, то цикл завершился бы (а мы исходим из того, что проходим по циклу еще один раз). Поэтому достаточно доказать логическое утверждение в задаче 1.6. Задача 1.6. Покажите, что для всех m, n > 0, gcd(m, n) = gcd(n, rem(m, n)). Теперь правильность алгоритма Евклида следует из (1.3), так как алгоритм останавливается, когда r = rem(m, n) = 0, поэтому m = q · n, и значит gcd(m, n) = n.\n--- Страница 19 ---\n18  Предварительные условия Задача 1.7. Покажите, что алгоритм Евклида завершается, и установите его слож - ность в форме записи «О» большое. Задача 1.8. Как бы вы сделали этот алгоритм эффективнее? Этот вопрос требует простых улучшений, которые снижают время работы на постоянный коэффици- ент. Задача 1.9. Модифицируйте алгоритм Евклида так, чтобы на входе задавались целые числа m, n и на выходе получались целые числа a, b такие, что am + bn = g = gcd(m, n). Такая модификация называется расширенным алгоритмом Евклида. Следуйте этой схеме: a) используйте принцип наименьшего числа, для того чтобы показать, что если g = gcd(m, n), то существуют a, b такие, что am + bn = g; b) спроектируйте расширенный алгоритм Евклида и докажите его правиль-ность; c) обычный расширенный алгоритм Евклида имеет полином времени выпол-нения в min{m, n}; покажите, что это время является временем выполнения вашего алгоритма, или измените свой алгоритм так, чтобы он работал за это время. Задача 1.10. Напишите программу, которая реализует расширенный алгоритм Евклида. Затем выполните следующий эксперимент: выполните его на случайной подборке входных данных заданного размера для размеров, ограниченных не-которым параметром N; вычислите среднее число шагов алгоритма для каждого размера n ≤ N входных данных и используйте gnuplot1 для построения графика ре- зультата. Как выглядит f(n) – т. е. «среднее число шагов» расширенного алгоритма Евклида на размере n входных данных? Обратите внимание, что размер не со- впадает со значением; входные данные размера n являются входами с двоичным представлением из n бит. 1.1.4. Палиндромы Алгоритм 1.3 проверяет, является ли цепочка символов палиндромом, то есть сло- вом, читаемым в обоих направлениях, слева направо и справа налево, например madamimadam или racecar (на русском: казак, ротатор). Для того чтобы представить этот алгоритм, нам нужно ввести немного обозна- чений. Функции floor и ceil определяются, соответственно, следующим образом: ⌊x⌋ = max{n ∈ �|n ≤ x} и ⌈x⌉ = min{n ∈ �|n ≥ x}, ⌊x⌉ означает «округление» x и опреде- ляется как ⌊x⌉ = ⌊x + 1/2⌋. Алгоритм 1.3. Палиндромы Предусловие: n ≥ 1 ∧ A[0 … n – 1] является массивом символов 1: i ← 0 2: while (i < ⌊n/2⌋) do 1 Gnuplot – это вспомогательная консольная программа для построения графиков (http://www.gnuplot.info). Кроме того, в Python есть графопостроительная библиотека matplotlib (https://matplotlib.org).\n--- Страница 20 ---\nЧто такое правильность?  19 3: if (A[i] ≠ A[n – i – 1]) then 4: return F 5: end if 6: i ← i + 1 7: end while 8: return T Постусловие: вернуть T тогда и только тогда, когда А является палиндромом Пусть инвариант цикла равен: после k-й итерации i = k +1 и для всех j таких, что 1 ≤ j ≤ k, A[j] = A[n – j + 1]. Докажем, что инвариант цикла соблюдается по индукции на k. Базовый случай: перед тем как состоятся любые итерации, то есть после нуля итераций, нет j таких, что 1 ≤ j ≤ 0, поэтому вторая часть инварианта цикла (бес - содержательно) истинна. Первая часть инварианта цикла соблюдается, так как i изначально имеет значение 1. Индукционный шаг: мы знаем, что после k итераций A[j] = A[n – j + 1] для всех 1 ≤ j ≤ k; после еще одной итерации мы знаем, что A[k + 1] = А[n – ( k + 1) + 1], значит, данное формальное суждение вытекает для всех 1 ≤ j ≤ k + 1. Этим доказывается инвариантность цикла. Задача 1.11. С помощью инварианта цикла проаргументируйте частичную пра- вильность алгоритма палиндромов. Покажите, что алгоритм завершается. В Python легко манипулировать символьными цепочками (строками); сегмент символьной цепочки называется срезом. Рассмотрим слово palindrome ; если мы установим переменную s равной этому слову: s = 'palindrome' тогда мы можем получить доступ к разным срезам следующим образом: print s[0:5] palin print s[5:10] dromeprint s[5:] dromeprint s[2:8:2] lnr где форма записи [i:j] означает сегмент символьной цепочки, начинающийся с i-го символа (и мы всегда начинаем отсчет с нуля!) и вплоть до j-го символа, включая первый, но исключая последний. Форма записи [i:] означает от i-го сим- вола вплоть до конца, а [i:j:k] означает от i-го символа вплоть до j-го (опять же, не считая сам j-й), беря каждый k-й символ. Хорошим способом понять разделители символьной цепочки является запись индексов «между» символами, а также в начале и в конце. Например: 0p1a2l3i4n5d6r7o8m9e10 и обратите внимание, что срез [i:j] содержит все символы между индексом i и индексом j. Задача 1.12. Используя встроенные функциональные средства Python для мани- пуляции со срезами символьных цепочек, напишите краткую программу, которая проверяет, является ли данная символьная цепочка палиндромом.\n--- Страница 21 ---\n20  Предварительные условия 1.1.5. Дальнейшие примеры В этом разделе мы приводим ряд дальнейших примеров алгоритмов, которые принимают в качестве входных данных целые числа и манипулируют ими с по-мощью цикла while. Мы также приводим пример алгоритма, который очень легко описать, но для которого неизвестно доказательство завершения (алгоритм 1.6). Все они дополнительно подтверждают идею о том, что доказательства правиль-ности являются не просто педантичными упражнениями в математическом фор-мализме, а реальным свидетельством валидности того или иного алгоритмиче-ского решения. Задача 1.13. Дайте алгоритм, который принимает на входе положительное целое число n и выводит на выходе «да», если n = 2 k (то есть n – это степень числа 2) и «нет» в противном случае. Докажите, что ваш алгоритм правилен.Задача 1.14. Что вычисляет алгоритм 1.4? Докажите свое утверждение. Алгоритм 1.4. См. задачу 1.14 1: x ← m ; y ← n ; z ← 0 2: while (x ≠ 0) do3: if (rem(x, 2) = 1) then 4: z ← z + y 5: end if 6: x ← div(x, 2) 7: y ← y · 2 8: end while9: return z Задача 1.15. Что вычисляет алгоритм 1.5? Исходите из того, что а, b – это положи- тельные целые числа (то есть исходите из того, что предусловием является, что a, b > 0). Для каких начальных a, b этот алгоритм завершается? За сколько шагов он завершается, если он действительно завершается? Algorithm 1.5. См. задачу 1.15 1: while (a > 0) do 2: if (a < b) then 3: (a, b) ← (2a, b – a) 4: else 5: (a, b) ← (a – b, 2b) 6: end if 7: end while Рассмотрите приведеный ниже алгоритм 1.6. Algorithm 1.6. Алгоритм Улама Pre-condition: a > 0 x ← a while последние три значения x не равны 4, 2, 1 do\n--- Страница 22 ---\nАлгоритмы ранжирования  21 if x является четным then x ← x/2 else x ← 3x + 1 end if end while Этот алгоритм отличается от всех алгоритмов, которые мы видели до сих пор, тем, что у него нет известного доказательства завершения и, следовательно, нет известного доказательства правильности. Посмотрите, как это просто: для любо-го положительного целого числа a установить x = a и повторять следующее: если x является четным, то разделить его на 2, а если нечетным, то умножить его на 3 и прибавить 1. Повторять это до тех пор, пока последние три полученных зна-чения не будут равны 4, 2,1. Например, если a = 22, то можно проверить, что x принимает следующие значения: 22, 11, 34, 17, 52, 26, 13, 40, 20, 10, 5, 16, 8, 4, 2, 1, и алгоритм 1.6 завершается. Предполагается, что независимо от начального зна-чения a до тех пор, пока а является положительным целым числом, алгоритм 1.6 завершается. Эта гипотеза известна как «задача Улама» 1, и, несмотря на десятиле- тия работы, пока никто не смог эту задачу решить. На самом деле, как показывает недавняя работа, было продемонстрировано, что варианты задачи Улама неразрешимы. Мы рассмотрим неразрешимость в главе 9, но в работе [Lehtonen (2008)] было показано, что для очень простого варианта задачи, где мы принимаем x равным 3x + t для x в отдельном множестве A t (подробнее см. указанную статью), вообще нет никакого алгоритма, который решит, для какого начального a новый алгоритм завершается и для какого нет. Задача 1.16. Напишите программу, которая принимает a в качестве входных дан- ных и отображает все значения задачи Улама до тех пор, пока не увидит 4, 2,1, и в этот момент он останавливается. Вы только что написали почти тривиальную программу, для которой нет доказательств завершения. Теперь проделайте экс - перимент: вычислите, сколько шагов требуется для того, чтобы достичь 4, 2,1 для всех a < N, для некоторого N. Есть ли какие-либо догадки? 1.2. алгоритмы ранжирования Алгоритмы, которые мы встречали до сих пор в книге, являются классическими, однако в некоторой степени они являются «игрушечными примерами». В этом разделе мы хотим продемонстрировать силу и полезность некоторых очень хо-рошо известных «взрослых» алгоритмов. Мы сосредоточимся на трех разных алгоритмах ранжирования. Ранжирование элементов, то есть ранговая града-ция, является исконной человеческой деятельностью, и мы кратко рассмотрим про цедуры ранжирования, которые варьируются от древних, таких как процеду - ра Раймунда Луллия, жившего в XIII веке мистика и философа, до старых, таких 1 Она также называется «гипотезой Коллатца», «сиракузской задачей», «задачей Какута- ни» или «алгоритмом Хассе». Хотя следует признать, что роза с любым из этих названий будет пахнуть так же сладко, засилье имен показывает, что данная гипотеза представля-ет собой весьма заманчивую математическую задачу.\n--- Страница 23 ---\n22  Предварительные условия как работа маркиза де Кондорсе, обсуждаемая в разделе 1.2.3, до современного простого и элегантного алгоритма ранжирования страниц PageRank компании Google, обсуждаемого в следующем далее разделе. 1.2.1. Алгоритм PageRank В 1945 году Ванневар Буш написал статью в Atlantic Monthly под названием «Как мы, возможно, думаем» (As we may think) [Bush (1945)], где он продемонстриро-вал жуткое предвидение идей, которые впоследствии стали Всемирной паутиной. В этой удивительной статье Буш указал на то, что информационно-поисковые системы организованы линейно (будь то книги, базы данных, компьютерная па-мять и т. д.), но сознательный опыт человека демонстрирует то, что он назвал «ас - социативной памятью». То есть человеческий разум имеет семантическую сеть, где мы думаем об одном, и это напоминает нам о другом, и т. д. Буш предложил проект человекоподобной машины, «Memex», которая имела характеристики ur-паутины: оцифрованного человеческого знания, взаимосвязанного ассоциатив-ными связями. Когда в начале 1990-х Тим Бернерс-Ли наконец реализовал идеи Буша в виде HTML и внедрил Всемирную паутину, веб-страницы были статичными, а ссылки имели навигационную функцию. Сегодня ссылки часто вызывают сложные про-граммы, написанные на Perl, PHP , MySQL и т. д., и в то время как некоторые из них по-прежнему остаются навигационными, многие являются транзакционны-ми, реализуя такие действия, как «добавить в корзину» или «обновить мой кален-дарь». Поскольку в настоящее время существуют миллиарды активных веб-страниц, возникает вопрос, как выполнять в них поиск, для того чтобы находить соответ - ствующую высококачественную информацию? Мы достигаем этого путем ран-жирования тех страниц, которые соответствуют критериям поиска; страницы с хорошим рангом будут появляться вверху – благодаря этому результаты поиска будут иметь смысл для читателя-человека, который должен просмотреть только первые несколько результатов, чтобы (надо надеяться) найти то, чего он хочет. Эти верхние страницы называются авторитетными страницами. Для того чтобы расположить авторитетные страницы рангом выше, мы исполь- зуем тот факт, что веб состоит не только из страниц, но и из гиперссылок, которые соединяют эти страницы. Эта гиперссылочная структура (которая может быть естественным образом смоделирована ориентированным графом) содержит мно-го скрытых аннотаций, которые могут быть использованы для автоматического выведения авторитетности. В этом заключается глубокое наблюдение: в конце концов, элементы, получающие от пользователя высокий ранг, ранжируются так субъективно; эксплуатация гиперссылочной структуры позволяет нам связывать субъективный опыт пользователей с выходными данными алгоритма! Точнее говоря, создавая гиперссылку, автор выражает неявное одобрение стра- нице. Добывая коллективное суждение, выраженное этими одобрениями, мы по-лучаем картину качества (или субъективного восприятия качества) данной веб-страницы. Это очень похоже на наше восприятие качества научных цитат, когда важная публикация цитируется другими важными публикациями. Теперь возни-кает вопрос, как преобразовать эти идеи в алгоритм. Судьбоносный ответ был дан хорошо известным сегодня алгоритмом PageRank, авторами которого являются\n--- Страница 24 ---\nАлгоритмы ранжирования  23 С. Брин и Л. Пейдж, основатели Google – см. публикацию [Brin и Page (1998)]. Алго- ритм PageRank глубоко анализирует гиперссылочную структуру в интернете, для того чтобы сделать вывод об относительной важности страниц. Рассмотрим рис. 1.1, на котором изображена веб-страница X и все страницы T 1, T2, T3, , Tn, которые на нее указывают. С учетом страницы X пусть С(Х) равно числу несовпадающих ссылок, которые покидают Х, то есть это расположенные в X ссылки, которые указывают на страницу за пределами Х. Пусть PR(Х) равно рангу страницы X. Мы также привлекаем параметр D, который называем коэффи- циентом затухания и который мы объясним позже. T1 T2 T3 … XTn Рис. 1.1  Вычисление ранга страницы A Тогда ранг страницы X можно вычислить следующим образом: PR(X) = (1 − d) + d �PR(T1) С(T1) + PR(T2) С(T2) + ··· + PR(Tn) С(Tn)�. (1.4) Теперь поясним (1.4): коэффициент затухания d – это константа 0 ≤ d ≤ 1 и обыч- но устанавливается равной ,85. Данная формула постулирует поведение «слу - чайного серфера», который начинает нажимать ссылки на случайной странице, следуя по ссылке из этой страницы и нажимая ссылки (ни разу не нажимая кноп-ку «назад») до тех пор, пока случайному серферу не надоест и он не начнет этот процесс с самого начала, перейдя на случайную страницу. Таким образом, в (1.4) (1 – d) является вероятностью случайного выбора X, тогда как PR(T i) C(Ti) – вероятность достижения X в случае прихода из Ti, нормализованная по числу исходящих из Ti ссылок. Мы вносим небольшую корректировку в (1.4): нормализуем ее на размер паутины, N, то есть делим (1 – d) на N. Благодаря этому вероятность наткнуться на X корректируется на совокупный размер паутины. Задача с (1.4) заключается в том, что она выглядит зацикленной. Как изна- чально вычислить PR(Ti)? Алгоритм работает поэтапно, уточняя ранг каждой страницы на каждом этапе. Первоначально мы используем эталитарный подход и присваиваем каждой странице ранг 1/N, где N – это общее число страниц в ин- тернете. Затем пересчитываем все ранги страниц, используя (1.4) и начальные ранги страниц, и продолжаем. После каждого этапа PR(X) приближается к фак - тическому значению, и по сути дело сходится довольно быстро. Здесь есть много технических вопросов, таких как знание того, когда остановиться, и обработка вычислений с участием N, которых может быть более триллиона, но выше при- веден алгоритм PageRank в конспектном изложении. Разумеется, интернет представляет собой обширную коллекцию разнородных документов, и (1.4) является слишком простой формулой, чтобы выразить ею абсолютно все, – поиск в Google намного сложнее. Например, не все исходящие\n--- Страница 25 ---\n24  Предварительные условия ссылки обрабатываются одинаково: ссылка более крупным шрифтом или выде- ленная тегом <STRONG> будет иметь больший вес. Документы различаются внут - ренне по языку, формату, такому как PDF, изображению, тексту, звуку, видео; и внешне с точки зрения репутации источника, частоты обновления, качества, популярности и других переменных, которые теперь учитываются современной поисковой системой. Для получения дополнительной информации об алгоритме PageRank читатель должен обратиться к публикации [Franceschet (2011)]. Более того, присутствие поисковых систем также влияет на интернет. Поскольку поисковые системы направляют трафик, они сами формируют рейтинг сети. По-добный эффект в физике известен как эффект наблюдателя, где приборы изменя- ют состояние того, что они наблюдают. В качестве простого примера рассмот рим замер давления в шинах: чтобы его измерить, вы должны выпустить немного воз-духа и, следовательно, чуть изменить давление. Все эти увлекательные вопросы являются предметом анализа больших данных. Задача 1.17. Рассмотрите следующую небольшую сеть: A DB EC F Вычислите PageRank разных страниц в этой сети, используя (1.4) с коэффици- ентом затухания d = 1, то есть исходя из того, что вся навигация осуществляется путем следования по ссылкам (без случайных переходов на другие страницы).Задача 1.18. Напишите программу, которая вычисляет ранги всех страниц в дан- ной сети размера N. Пусть сеть задана матрицей 0–1, где 1 в позиции (i , j) означает, что существует ссылка со страницы i на страницу j. В противном случае в этой по- зиции находится 0. Используйте (1.4) для вычисления ранга страниц, начиная со значения 1/N . Вы должны остановиться, когда все значения сойдутся, – всегда ли этот алгоритм завершается? Также отслеживайте все значения в виде дробей a/b, где gcd(a , b) = 1; Python имеет удобную библиотеку для дробей: import fractions . 1.2.2. Стабильный брачный союз Предположим, что мы хотим сопоставить стажеров с больницами или студентов с колледжами; обе задачи являются примерами задачи процесса приема на работу или учебу, и обе имеют решение, которое оптимизирует, в определенной степени, совокупное удовлетворение всех заинтересованных сторон. Решением этой зада-чи является элегантный алгоритм решения так называемой «задачи о стабильном брачном союзе», который используется с 1960-х годов для приема в колледж и для подбора интернов в больницы. Экземпляр задачи устойчивого брачного союза размера n состоит из двух не- пересекающихся конечных множеств одинакового размера: множества юношей B = {b 1, b2, , bn} и множества девушек G = {g1, g2, , gn}. Пусть <i обозначает ранговую градацию, выполненную юношей bi, то есть g <i g′ означает, что юноша bi предпо-\n--- Страница 26 ---\nАлгоритмы ранжирования  25 читает девушку g девушке g′. Схожим образом <j обозначает ранговую градацию, выполненную девушкой gj. Каждый юноша bi имеет такую ранговую градацию (линейное упорядочение) <i множества G, которая отражает его предпочтение в отношении девушек, на которых он хочет жениться. Схожим образом каждая девушка gj имеет ранговую градацию (линейное упорядочение) <j множества B, которая отражает ее предпочтение в отношении юношей, за которых она хотела бы выйти замуж. Паросочетание (или брак) М является взаимно-однозначным соответствием между B и G. Мы говорим, что b и g являются партнерами в М, если они сочета- лись в М, и пишем p M(b) = g и pM(g) = b. Паросочетание М является неустойчивым, если существует пара (b, g) из B × G такая, что b и g не являются партнерами в M, и b предпочитает девушку pM(b) девушке g и g предпочитает юношу pM(g) юноше b. Говорят, что такая пара (b, g) блокирует паросочетание M и называется блокирую- щей парой для M (см. рис. 1.2). Паросочетание M стабильно, если оно не содержит блокирующих пар. b pM(g)g pM(b) Рис. 1.2  Блокирующая пара: b и g предпочитают друг друга своим партнерам pM(b) и pM(g) Оказывается, всегда существует решение устойчивого брачного союза задачи паросочетания. Это решение может быть вычислено с помощью знаменитого алгоритма Гейла и Шепли ([Gale и Shapley (1962)]), который выдает стабильный брачный союз для любых B, G на входе независимо от ранговой градации 1. Паросочетание M производится в несколько этапов Ms с целью того, чтобы bt всегда имел партнера в конце этапа s, где t ≤ s. Однако партнеры bt не становятся лучше, то есть pMt(bt) ≤t pMt+1(bt) ≤t ···. С другой стороны, для каждого g ∈ G, если g имеет партнера на этапе t, g будет иметь партнера на каждом этапе s ≥ t, и парт - неры не станут хуже, то есть pMt(g) ≥t pMt+1(g) ≥t . Следовательно, с увеличением s партнеры bt становятся менее предпочтительными, а партнеры g – более предпо- чтительными. В конце этапа s будем считать, что мы произвели паросочетание Ms = {(b1, g1,s), , ( bs, gs,s)}, где форма записи gi,s означает, что gi,s является партнершей юноши bi после окон- чания этапа s. Мы будем говорить, что партнеры в Ms помолвлены. Идея состоит в том, что на этапе s + 1 юноша bs+1 попытается получить партнершу, сделав предложение де- вушкам в G в его порядке предпочтения. Когда bs+1 делает предложение девушке gj, gj принимает его предложение, если gj в настоящее время не помолвлена либо 1 В 2012 году Нобелевская премия по экономике была присуждена Ллойду С. Шепли и Эл- вину Э. Роту «за теорию устойчивых размещений и практику рыночного проектирова-ния», то есть за алгоритм стабильного брачного союза.\n--- Страница 27 ---\n26  Предварительные условия в настоящее время помолвлена с менее предпочтительным юношей b, то есть bs+1 <j b. В случае, когда gj предпочитает юношу bs+1 ее нынешнему партнеру b, то gj разрывает помолвку с b, и b тогда приходится искать новую партнершу. Задача 1.19. Покажите, что каждому b нужно сделать предложение не более од- ного раза каждой g. Из задачи 1.19 мы видим, что каждый юноша может оставить в своем списке предпочтений закладку, и эта закладка движется только вперед. Когда приходит очередь юноши делать выбор, он начинает делать предложения с того места, где находится его закладка, и к тому времени, когда он закончит, его закладка будет двигаться только вперед. Обратите внимание, что на этапе s + 1 закладка каждого юноши не могла выйти за пределы номера девушки s в списке, не выбрав кого-то (после этапа s задействуется только s девушек). По мере того как юноши меняются очередями, закладка каждого юноши продвигается, поэтому закладка некоторого юноши (среди юношей в {b 1, , bs+1}) в конце концов дойдет до точки, где он дол- жен выбрать девушку. Алгоритм 1.7. Гейл-Шепли 1: Этап 1: b1 выбирает свою лучшую g и M1 ← {(b1, g)} 2: for s = 1, , s = |B| – 1, этап s + 1: do 3: M ← Ms 4: b* ← bs+1 5: for b* делает предложение всем g в порядке предпочтения: do 6: if g не была помолвлена: then 7: Ms+1 ← M ⋃ {(b *, g)} 8: закончить текущий этап 9: else g была помолвлена с b, но g предпочитает b *: then 10: M ← (M – {( b, g)}) ⋃ {(b *, g)} 11: b* ← b 12: повторить со строки 5 13: end if 14: end for 15: end for Обсуждение в предыдущем абзаце показывает, что этап s + 1 в алгоритме 1.7 должен завершиться. Озабоченность здесь вызывает то, что случай (ii) этапа s + 1 может оказаться зацикленным. Но тот факт, что закладки продвигаются, показы- вает, что это невозможно. Более того, в данной процедуре это дает верхнюю границу (s + 1)2 шагов на эта- пе (s + 1). Это означает, что имеется n этапов, и каждый этап занимает O(n2) шагов, и, следовательно, алгоритм 1.7 занимает O(n3) шагов в целом. Вопрос, конечно, в том, что мы подразумеваем под шагом? Компьютеры работают на двоичных цепочках, но здесь принимается неявное допущение, что мы сравниваем числа и получаем доступ к спискам предпочтений за один шаг. Но цена этих операций незначительна при сравнении с нашим идеализированным временем выполне-ния, и поэтому мы позволяем себе, чтобы эта поэтическая лицензия ограничива-ла совокупное время выполнения.\n--- Страница 28 ---\nАлгоритмы ранжирования  27 Задача 1.20. Покажите, что существует ровно одна девушка, которая не помолв- лена на этапе s, но помолвлена на этапе (s + 1), и что для каждой девушки gj, кото - рая помолвлена в Ms, gj будет помолвлена в Ms+1 и pMs+1(gj) <j pMs(gj). (Следовательно, как только gj станет помолвленной, она останется помолвленной, и ее партнеры только заработают в предпочтении по мере продвижения этапов.) Задача 1.21. Предположим, что |B| = |G| = n. Покажите, что Mn будет стабильным брачным союзом в конце этапа n. Мы говорим, что пара (b, g) допустима, если существует устойчивое паросочета- ние, в котором b, g являются партнерами. Мы говорим, что паросочетание являет - ся оптимальным по юноше, если каждый юноша имеет пару со своей допустимой партнершей с самым высоким рангом. Мы говорим, что паросочетание является пессимистичным по юноше, если каждый юноша имеет пару со своей допустимой партнершей с самым низким рангом. Схожим образом мы определяем оптималь- ное/пессимистичное паросочетание по девушке. Задача 1.22. Покажите, что наша версия алгоритма производит стабильное па- росочетание, оптимальное по юноше и пессимистичное по девушке. Означает ли это, что упорядочение юношей не имеет значения? Задача 1.23. Реализуйте алгоритм 1.7. 1.2.3. Попарные сравнения Фундаментальное приложение алгоритмических процедур состоит в выборе луч- шего варианта из многих. Этот отбор требует процедуры ранжирования, которая им руководит, но с учетом сложности мира в информационную эпоху процедура ранжирования и отбора часто осуществляется на основе чрезвычайного коли-чества критериев. Такой отбор может также потребовать от выборщика предо-ставить обоснование для отбора и убедить кого-то еще, что лучший вариант был все-таки выбран. Например, представьте сценарий, когда команда врачей должна решить, оперировать пациента или нет [Kakiashvili и соавт. (2012)], и насколько важно одновременно отобрать оптимальный курс действий и предоставить вес - кое обоснование для финального отбора. Действительно, обоснование в данном случае может быть не менее важным, чем отбор наилучшего варианта. Значительные усилия были посвящены исследованию ранжирования в поис - ковых системах [Easley и Kleinberg (2010)] в случае большого числа сильно разно-родных элементов. С другой стороны, была проделана относительно небольшая работа по ранжированию небольших множеств из весьма схожих (однородных) элементов, дифференцированных по большому числу критериев. Сегодняшнее состояние дел состоит из целого ряда специфичных для конкретной области си-туа тивных процедур, которые сильно зависят от области применения: один под- ход в медицинской профессии [Kakiashvili и соавт. (2012)], другой в мире менедж - мента [Koczkodaj и соавт. (2014)] и т. д. Попарные сравнения имеют удивительно старую историю для метода, который в определенной мере известен не так широко. Древние начала часто приписыва-ют мистику и философу XIII века Раймунду Луллию. В 2001 году была обнаружена рукопись Луллия под названием Ars notandi, Ars eleccionis, Alia ars eleccionis (см. [Hagele и Pukelsheim (2001); Faliszewski и соавт. (2010)]), где он обсуждал системы\n--- Страница 29 ---\n28  Предварительные условия голосования и описал прообраз метода попарных сравнений. Современное нача- ло приписывается маркизу де Кондорсе (см. его работу [Condorcet (1785)], напи-санную за четыре года до Французской революции и за девять лет до того, как он потерял свою голову). Так же, как и Луллий, Кондорсе применил метод попарных сравнений для анализа результатов голосования. Почти полтора века спустя Тер-стоун [Thurstone (1927)] этот метод усовершенствовал и использовал психологи-ческий континуум со шкальными значениями в качестве медиан распределения суждений. Можно сказать, что современный метод попарных сравнений начался с работы Саати в 1977 году [Saaty (1977)], который предложил конечную девятибалльную шкалу измерения. Более того, Саати внедрил процесс анализа иерархий (analytic hierarchy process, AHP), который представляет собой формальный метод получе-ния порядков ранговой градации из числовых попарных сравнений. Процесс ана-лиза иерархий широко используется во всем мире для принятия решений в обла-сти образования, промышленности, правительства и т. д. В публикации [Koczkodaj (1993)] была предложена меньшая пятибалльная шкала, менее мелкозернистая, чем у Саатив с его девятибалльной, но проще в использовании. Обратите внима-ние, что хотя процесс анализа иерархий является респектабельным инструмен-том для практического применения, он тем не менее рассматривается многими [Dyer (1990); Janicki (2011)] как ошибочная процедура, которая порождает произ-вольное ранжирование. Пусть X = {x 1, x2, , xn} равно конечному множеству ранжируемых объектов. Пусть aij выражает числовое предпочтение между xi и xj. Идея состоит в том, что aij оценивает, «насколько лучше» xi по сравнению с xj. Ясно, что для всех i, j, aij > 0 и aij = 1/aji. Интуиция подсказывает, что если aij > 1, то по этому фактору xi предпо- чтительнее xj. Так, например, дисплей Apple Retina имеет в четыре раза большее разрешение, чем дисплей Thunderbolt, и поэтому если xi – это Retina, а x2 – Thun- derbolt, то мы можем сказать, что качество изображения xi в четыре раза лучше, чем качество изображения x2, и поэтому a12 = 4 и a21 = 1/4. Закрепление значений aj часто осуществляется субъективно человеческими судьями. Пусть A = [aij] равно матрице попарных сравнений, также именуемой матрицей предпочтений. Мы го- ворим, что матрица попарных сравнений непротиворечива, если для всех i, j, k мы имеем, что aijajk = aik. В противном случае она противоречива. Теорема 1.24 (Саати). Матрица попарных сравнений a непротиворечива тогда и только тогда, когда существуют w1, w2, , wn такие, что aij = wi /wj. Задача 1.25. Обратите внимание, что wi , которые появляются в теореме 1.24, соз- дают ранговую градацию, в которой xj предпочтительнее xi тогда и только тогда, когда wi < wj. Предположим, что A является непротиворечивой матрицей попар- ных сравнений. Как извлечь значения wi из A? На практике субъективные оценивания aij редко бывают непротиворечивыми, что создает ряд проблем ([Janicki и Zhai (2011)]), а именно: (i) как мы измеряем противоречивость и какой уровень приемлем? (ii) как мы устраняем противоре-чивости или понижаем их до приемлемого уровня? (iii) как мы выводим значе-ния w i, начиная с противоречивой ранговой градации A? iv) как мы обосновы- ваем определенный метод устранения противоречий? Противоречивая матрица\n--- Страница 30 ---\nОтветы к избранным задачам  29 имеет ценность в том, что степень противоречивости измеряет в некоторой мере степень субъективности судей. Но мы должны быть в состоянии ответить на из-ложенные в предыдущем пункте вопросы, прежде чем сможем конструктивным образом воспользоваться противоречивой матрицей. Задача 1.26. В работе [Bozoki и Rapcsak (2008)] предлагается несколько методов измерения противоречий в матрице (см., в частности, табл. 1 на стр. 161 указан- ной статьи). Рассмотрите возможность осуществления некоторых из этих мер. Можете ли вы предложить способ устранения противоречий в матрице попарных сравнений? 1.3. ответы к избранным зада Чам Задача 1.1. (∀I ∈ A)[∃O(O = A(I)) ∧ (αA(I) → βA(A(I)))]. Тем самым говорится о том, что для любых хорошо сформированных входных данных I есть выходные дан- ные, то есть алгоритм A завершается. Это выражается через ∃O(O = A(I)). Кроме того, это выражение говорит, что если хорошо сформированные входные данные удовлетворяют предусловию, указанному как предпосылка α A(I), то выходные данные удовлетворяют постусловию, формулируемому как консеквент βA(A(I)). Задача 1.2. Очевидно, что an2 + bn + с ≥ an2 – |b|n – | c| = n2(a – | b|/n – | c|/n2), (1.5) |b| конечно, поэтому ∃nb ∈ � такие, что |b|/nb ≤ a/4. Схожим образом ∃nc ∈ � такое, что |c|/n2 c ≤ a/4. Пусть n0 = max{nb, nc}. Для n ≥ n0 a – |b|/n0 – |c|/n2 0 ≥ a – a/4 – a/4 = a/2. В сочетании с (1.5) это дает: a 2 n2 ≤ an2 + bn + c для всех n ≥ n0. Нам нужно только присвоить c3 значение a/2, чтобы завершить до- казательство, что an2 + bn + c ∈ Ω(n2). Далее мы имеем дело с общим многочленом с положительным ведущим коэф- фициентом. Пусть p(n) = åk i=1 aini = nk åk i=1 ai /nk–i, где ak > 0. Ясно, что p(n) ≤ nk åk i=1|ai| для всех n ∈ �, поэтому p(n) = O(nk). Более того, каждое ai является конечным, поэтому для каждого i ∈ � такого, что 0 ≤ i ≤ k – 1, ∃ni такие, что ai /nk–i ≤ ak /2k для всех n ≥ ni. Пусть n0 равно максимуму из этих ni. p(n) можно переписать как nk(ak + åk–1 i=0 ai /nk–i), поэтому p(n) ≥ nk (ak – åk–1 i=0 ai /nk–i). Мы показали, что для n ≥ n0, åk–1 i=0 ai /nk–i ≤ ak – k(ak /2k) = ak /2, поэтому пусть c = ak /2. Для всех n ≥ n0 p(n) ≥ (ak – ak /2)nk = cnk. Следовательно, p(n) = Ω(nk). Мы показали, что p(n) ∈ O(nk) и p(n) ∈ Ω(nk), поэтому p(n) = Θ(nk). Задача 1.3. Цикл while начинается с r = x, а затем всякий раз y вычитается; он ограничен значением x (самый медленный случай, когда y =1). Всякий раз, когда\n--- Страница 31 ---\n30  Предварительные условия цикл while исполняется, он проверяет, что y ≤ r, и пересчитывает r, q, и поэтому он стóит 3 шага. Добавив исходные два присваивания (q ← 0, r ← x), в общей сложно- сти мы получим 3x + 2 шагов. Обратите внимание, что мы исходим из того, что x, y представлены в двоичном формате (обычная кодировка) и что для кодирования x требуется log2 x бит, и, значит, время работы составляет 3 · 2log 2x + 2, то есть время работы экспоненциально длине входных данных! Это нежелательное время рабо-ты; если бы x было больши м, скажем, 1000 бит, а y – малым, то этот алгоритм занял бы больше времени, чем время жизни Солнца (10 млрд лет). Существуют гораздо более быстрые алгоритмы деления, такие как метод Ньютона–Рафсона. Задача 1.4. Исходное предусловие (при котором алгоритм является правиль- ным) равно: x ≥ 0 ∧ y > 0 ∧ x, y ∈ �, где � = {0, 1, 2, …}. И значит, в первом случае наша работа уже сделана за нас; любой член �, который ≥ 0, также находится в � (и любой член � находится в �), поэтому эти предусловия эквивалентны. С учетом того, что этот алгоритм был правильным в исходном предусловии, он также является правильным в новом. Во втором случае он не является правильным: рассмотрим x = –5 и y = 2, поэтому изначально r = –5, и цикл не будет выполняться, и r ≥ 0 в постусловии не будет ис - тинным. Задача 1.6. Сначала заметим, что если u делит x и y, то для любого a, b ∈ � u также делит ax + by. Следовательно, если i |m и i |n, то i|(m – qn) = r = rem(m, n). Поэтому i делит оба числа: n и rem(m, n), и поэтому i должно быть ограничено по их наибольшему общему делителю, то есть i ≤ gcd(n, rem(m, n)). Так как это вер- но для всех i, это, в частности, верно для i = gcd(m, n); следовательно, gcd(m, n) ≤ gcd(n, rem(m, n)). И наоборот, предположим, что i|n и i|rem(m, n). Тогда i|m = qn + r, поэтому i ≤ gcd(m, n), и опять же, gcd(n, rem(m, n)) удовлетворяет условию сущест - вования такого i, поэтому мы имеем gcd(n, rem(m, n)) ≤ gcd(m, n). Оба неравенства, взятых вместе, дают нам gcd(m, n) = gcd(n, rem(m, n)). Задача 1.7. Пусть r i равно r после i-й итерации цикла. Обратите внимание, что r0 = rem(m, n) = rem(a, b) ≥ 0, и фактически каждый ri ≥ 0 по определению остатка. Более того: ri+1 = rem(mi+1, ni+1) = rem(ni, ri) = rem(ni, rem(mi, ni)) = rem(ni, ri) < ri. И значит, мы имеем убывающую, но неотрицательную последовательность чисел; по принципу наименьшего числа он должен завершиться. Для того чтобы установить сложность, мы подсчитываем число итераций цикла while, игнорируя перестановки значений местами (поэтому, чтобы получить фактическое число итераций, мы должны умножить результат на два). Предположим, что m = qn + r. Если q ≥ 2, то m ≥ 2 n, а так как m ← n, то m уменьша- ется как минимум наполовину. Если q = 1, тогда m = n + r, где 0 < r < n, и исследуем два случая: r ≤ n/2, поэтому n уменьшается, по меньшей мере, наполовину так, как\n--- Страница 32 ---\nОтветы к избранным задачам  31 n ← r, либо r > n/2, и в этом случае m = n + r > n + n/2 = 3/2n, поэтому так как m ← n, m уменьшается на 1/3. Следовательно, можно сказать, что во всех случаях хотя бы один элемент в паре уменьшается, по крайней мере, на 1/3, и поэтому можно сказать, что время работы ограничено значением k таким, что 3 k = m · n, и, следова- тельно, сложность равна O(log(m · n)) = O(log m + log n). Поскольку входные данные считаются двоичными, из этого можно сделать вывод, что время работы линейно по размеру входных данных. Более жесткий анализ, известный как теорема Ламе, можно найти в публика- ции [Cormen и соавт. (2009)] (теорема 31.11), в которой говорится, что для любого целого числа k ≥ 1, если a > b ≥ 1 и b < F k+1, где Fi – это i-е число Фибоначчи (см. зада- чу 9.5), то для выполнения алгоритма Евклида требуется менее k итераций цикла while (не считая перестановок значений местами). Задача 1.8. Когда m < n, тогда rem(m, n) = m, и поэтому m′ = n и n′ = m. Следова- тельно, при m < n мы исполняем одну итерацию цикла, только для того чтобы по- менять местами m и n. Для того чтобы быть эффективнее, мы могли бы добавить строку 2.5 в алгоритме 1.2 следующего содержания: if (m < n) then swap(m, n). Задача 1.9. (a) Mы покажем, что если d = gcd(a, b), то существуют u, v такие, что au + bv = d. Пусть S = {ax + by |ax + by > 0}; явно S ≠ ∅. По принципу наименьшего чис - ла существует наименьшее g ∈ S. Мы покажем, что g = d. Пусть a = q · g+ r, 0 ≤ r < g. Предположим, что r > 0; тогда r = a – q · g = a – q(ax0 + by0) = a(1 – qx0) + b(–qy0). Таким образом, r ∈ S, но r < G – противоречие. Поэтому r = 0, и, значит, g|a, и по - добный аргумент показывает, что g|b. Остается показать, что g больше, чем любой другой общий делитель а, b. Предположим, c|a и c|b, поэтому c|(ax0 + by0), и поэтому c|g, а это означает, что c ≤ g. Следовательно, g = gcd(a, b) = d. (b) Pасширенный алгоритм Евклида – это алгоритм 1.8. Обратите внимание, что в данном алгоритме присваивания в строке 1 и строке 8 вычисляются слева направо. Алгоритм 1.8. Расширенный алгоритм Евклида Предусловие: m > 0, n > 0 1: a ← 0; x ← 1; b ← 1; y ← 0; c ← m; d ← n 2: loop3: q ← div(c, d) 4: r ← rem(c, d) 5: if r = 0 then 6: stop 7: end if 8: c ← d; d ← r; t ← x; x ← a; a ← t – qa; t ← y; y ← b; b ← t – qb 9: end loop Постусловие: am + bn = d = gcd(m, n) Мы можем доказать правильность алгоритма 1.8, используя следующий инва- риант цикла, состоящий из четырех логических утверждений: am + bn = d, xm + yn = c, d > 0, gcd(c, d) = gcd(m, n). (LI)\n--- Страница 33 ---\n32  Предварительные условия Базовый случай: am + bn = 0 · m + 1 · n = n = d; xm + yn = 1 · m + 0 · n = m = c; оба утверждения по строке 1. Тогда d = n > 0 по предусловию, и gcd(c, d) = gcd(m, n) по строке 1. На индукционном шаге допустим, что переменные с индексом «штрих» являются результатом еще одной полной итерации цикла на перемен-ных без индекса «штрих»: a′m + b′n = (x – qa)m + (y – qb)n по строке 8 = (xm – yn) – q(am + bn) = c – qd по индукционной гипотезе = r по строкам 3 и 4 = d′. по строке 8 Тогда x′m = y′n = am + bn = d = c′, где первое равенство является по строке 8, второе по индукционной гипотезе, а третье по строке 8. Кроме того, d′ = r по стро- ке 8, и алгоритм остановится в строке 5, если r = 0; с другой стороны, из строки 4 r = rem(c, d) ≥ 0, поэтому r > 0 и, значит, d′ > 0. В заключение gcd(c′, d′) = gcd(d, r) по строке 8 = gcd(d, rem(c, d)) по строке 4 = gcd(c, d) см. задачу 1.6 = gcd(m, n). по индукционной гипотезе Для частичной правильности достаточно показать, что если алгоритм завер- шается, то постусловие соблюдается. Если алгоритм завершается, то r = 0, поэтому rem(c, d) = 0 и gcd(c, d) = gcd(d, 0) = d. С другой стороны, по (LI), мы имеем, что am + bn = d, поэтому am + bn = d = gcd(c, d) и gcd(c, d) = gcd(m, n). (c) Hа стр. 292–293 в публикации [Delfs и Knebl (2007)] есть хороший анализ версии данного алгоритма. Авторы ограничивают время выполнения в терминах чисел Фибоначчи и получают желаемую границу времени выполнения. Задача 1.11. Для частичной правильности алгоритма 1.3 мы покажем, что если предусловие соблюдается и если алгоритм завершается, то постусловие будет со-блюдено. Итак, примем предусловие и сначала предположим, что A не является палиндромом. Тогда существует наименьшее i 0 (существует одно, и поэтому по принципу наименьшего числа существует наименьшее) такое, что A[i0] ≠ A[n – i0 + 1], и поэтому после первой i0 – 1 итерации цикла while мы знаем из инварианта цик - ла, что i = (i0 – 1) + 1 = i0, и поэтому строка 4 исполняется, и алгоритм возвращает F (False). Следовательно, «А не является палиндромом» ⇒ «вернуть F». Предположим теперь, что A является палиндромом. Тогда строка 4 ни разу не исполняется (так как такого i0 не существует), и поэтому после k = ⌊–n 2⌋-й итерации цикла while мы знаем из инварианта цикла, что i = ⌊–n 2⌋ + 1, и поэтому цикл while больше не исполняется, алгоритм переходит к строке 8 и возвращает T (True). Сле- довательно, «А является палиндромом» ⇒ «вернуть Т». Следовательно, постусловие «вернуть T тогда и только тогда, когда A являет - ся палиндромом» соблюдается. Обратите внимание, что мы использовали только часть инварианта цикла, то есть мы использовали тот факт, что после k-й ите- рации i = k + 1; по-прежнему соблюдается, что после k-й итерации для 1 ≤ j ≤ k A[j] = A[n – j + 1], но в приведенном выше доказательстве нам этот факт не нужен.\n--- Страница 34 ---\nОтветы к избранным задачам  33 Для того чтобы показать, что алгоритм завершается, пусть di = ⌊–n 2⌋ – i. По пред- условию мы знаем, что n ≥ 1. Последовательность d1, d2, d3, является убывающей последовательностью натуральных чисел (потому что i ≤ ⌊–n 2⌋), Поэтому по принци- пу наименьшего числа она конечна, и поэтому цикл завершается. Задача 1.12. Она очень легкая, как только вы поймете, что в Python срез [::–1] генерирует обратную цепочку. Таким образом, чтобы проверить, является ли це- почка s палиндромом, нам нужно только написать s == s[::–1] . Задача 1.13. Решение дано алгоритмом 1.9. Алгоритм 1.9. Степени числа 2 Предусловие: n ≥ 1 x ← n while (x > 1) do if (2|x) then x ← x/2 else остановиться и вернуть «нет» end if end whilereturn «да» Постусловие: «да» ⇔ n является степенью числа 2 Пусть инвариант цикла равен «х является степенью числа 2 тогда и только тогда, когда n является степенью числа 2». Покажем инвариант цикла по индукции на числе итераций главного цикла. Ба- зовый случай: ноль итераций, и поскольку x ← n, x = n, поэтому очевидно, что х является степенью числа 2 тогда и только тогда, когда n является степенью чис - ла 2. На индукционном шаге обратите внимание, что если нам когда-нибудь при-дется обновлять x, у нас есть x′ = x/2, и, очевидно, x′ является степенью числа 2 тогда и только тогда, когда x является степенью числа 2. Обратите внимание, что алгоритм всегда завершается (принять x 0 = n и xi+1 = xi /2 и, как обычно, применить принцип наименьшего числа). Теперь можно доказать правильность: если алгоритмы возвращают «да», то по завершении последней итерации цикла x = 1 = 20, и по инварианту цикла n явля- ется степенью числа 2. Если, с другой стороны, n является степенью числа 2, то та- ково и каждое x, поэтому в конечном итоге x = 1, и поэтому алгоритм возвращает «да». Задача 1.14. Алгоритм 1.4 вычисляет произведение m и n, то есть возвращае- мое z = m · n. Хорошим инвариантом цикла является x · y + z = m · n. Задача 1.17. Мы начинаем с инициализации всех узлов рангом 1/6, а затем по- вторно применяем следующие ниже формулы, основанные на (1.4): PR(A) = PR(F ) PR(B ) = PR(A) PR(C ) = PR(B)/4 + PR(E ) PR(D) = PR(B)/4 PR(E ) = PR(B)/4 + PR(D) PR(F ) = PR(B)/4 + PR(C )\n--- Страница 35 ---\n34  Предварительные условия Результат приведен на рис. 1.3. 0 1 2 3 4 5 6 … 17 A 0,17 0,17 0,21 0,25 0,29 0,18 0,20 0,22 В 0,17 0,17 0,17 0,21 0,25 0,29 0,18 0,22 С 0,17 0,21 0,25 0,13 0,14 0,16 0,19 … 0,17 D 0,17 0,04 0,04 0,04 0,05 0,05 0,07 0,06 E 0,17 0,21 0,08 0,08 0,09 0,11 0,14 0,11 F 0,17 0,21 0,25 0,29 0,18 0,20 0,23 0,22 Всего 1,00 1,00 1,00 1,00 1,00 1,00 1,00 … 1,00 Рис. 1.3  Схождение алгоритма Pagerank в задаче 1.17. Отметим, что данная таблица получена с помощью электронной таблицы: все значения округляются до двух десятичных знаков, но столбец 1 полу-чается путем размещения 1/6 в каждой строке, столбец 2 получается из столбца 1 с формулами, а все остальные столбцы получаются пу- тем «перетаскивания» столбца 2 до самого конца. Значения сошлись (более или менее) в столбце 17 Задача 1.19. После того как b сделал предложение g в первый раз, независимо от того, было оно успешным или нет, партнеры g могут стать только лучше. Сле- довательно, для b нет необходимости пробовать еще раз. Задача 1.20. bs+1 делает предложение девушкам в соответствии с его списком предпочтений; в итоге некая g его принимает, и если g, которая приняла предло- жение bs+1, была свободна, то она является новой партнершей. В противном случае некоторый b∗ ∈ {b1, , bs} стал свободным от помолвки, и мы повторяем тот же аргумент. Девушка g разрывает помолвку, только если предложение делает более подходящий юноша b, поэтому верно, что pMs+1(gj) <j pMs(gj). Задача 1.21. Предположим, что у нас есть блокирующая пара {b, g} (имея в виду, что {(b, g′), ( b′, g)} ⊆ Mn, но юноша b предпочитает девушку g девушке g′, и девушка g предпочитает юношу b юноше b′). b появился либо после b′, либо раньше. Если бы b появился перед b′, то g была бы помолвлена с b или с кем-то еще лучше, когда по- явился b′, поэтому g не стала бы помолвленной с b′. С другой стороны, поскольку (b′, g) является парой, девушке g не было сделано ни одного лучшего предложения после предложения от юноши b′, поэтому b не мог появиться после b′. В любом случае, мы получаем невозможность, и поэтому нет блокирующей пары {b, g}. Задача 1.22. Для того чтобы показать, что паросочетание является оптималь- ным по юноше, мы рассуждаем от противного. Пусть выражение «g является опти- мальной партнершей для b» означает, что среди всех стабильных паросочетаний g является лучшей партнершей, которую может получить b. Мы выполняем алгоритм Гейла-Шепли, и пусть b равно первому юноше, откло- ненному его оптимальной партнершей g. Это означает, что g уже находится в паре с некоторым b′, и g предпочитает юношу b′ юноше b. Более того, g желательна для b′, по крайней мере, так же, как его собственная оптимальная партнерша (по- скольку предложение b делается впервые во время выполнения алгоритма, когда юноша отклоняется его оптимальной партершей). Поскольку g является опти- мальной для b, мы знаем (по определению), что существует некоторое устойчи- вое паросочетание S, где ( b, g) является парой. С другой стороны, у b′ оптимальная партнерша ранжируется (разумеется, самим же b′), по крайней мере, так высоко,\n--- Страница 36 ---\nПримечания  35 как g, и поскольку g занята b, с кем бы ни был b′ в паре в S, скажем, g′, b′ предпо- читает девушку g девушке g′. Это дает нам нестабильную пару, потому что {b′, g} предпочитают друг друга партнерам, которые у них есть в S. Разумеется, это означает, что упорядоченность юношей не имеет значения, по- тому что есть уникальное оптимальное по юноше паросочетание, и оно не зави- сит от упорядоченности юношей. Для того чтобы показать, что алгоритм Гейла-Шепли является пессимистич- ным по девушке, мы используем тот факт, что он оптимальный по юноше (что только что показали). Опять же, мы рассуждаем от противного. Предположим, что существует устойчивое паросочетание S, где g находится в паре с b, и g предпочи- тает юношу b′ юноше b, где (b′, g) является результатом алгоритма Гейла-Шепли. Согласно оптимальности по юноше, мы знаем, что в S у нас есть (b′, g′), где g′ не выше в списке предпочтений b′, чем g, и поскольку g уже находится в паре с b, мы знаем, что g′ находится на самом деле ниже. Это говорит о том, что S нестабильна, так как {b′, g} скорее будут вместе, чем со своими партнерами. 1.4. п римеЧания Эта книга посвящена доказательству разных аспектов алгоритмов, их правиль-ности, их завершению, их времени выполнения и т. д. Искусство математических доказательств поддается освоению с трудом; очень хорошим местом для начала является книга [Velleman (2006)]. В предисловии мы упомянули про отключение электричества на северо-вос - токе Америки в 2003 году. В то время автор жил в Торонто, Канада, на 14-м этаже жилого дома (который на самом деле был 13-м этажом, но поскольку номер 13 в лифтах Торонто был запрещен, после 12-го этажа следующей кнопкой на лифте была 14). После первых 24 часов аварийные генераторы вышли из строя, и нам всем пришлось подниматься по лестнице на наши этажи; мы покидали здание и вычищали район от пищи и воды, но так как в большинстве мест не было холо-дильника, было нелегко найти свежие продукты. Короче говоря, мы действитель-но чувствовали последствия этой алгоритмической ошибки. В сноске к задаче 1.10 упоминается библиотека Python matplotlib . Ниже приве- ден простой пример построения графика функций f(x) = x3 и h(x) = –x3 над интер- валом [0, 10] с использованием этой библиотеки: import matplotlib.pyplot as plt import numpy as np def f(x): return x**3 def h(x): return -x**3 Input = np.arange(0,10.1,.5) Outputf = [f(x) for x in Input] Outputh = [h(x) for x in Input] plt.plot(Input,Outputf,'r.',label='f – метка') plt.plot(Input,Outputh,'b--',label='h – метка') plt.xlabel('Это метка оси X')plt.ylabel('Это метка оси Y')\n--- Страница 37 ---\n36  Предварительные условия plt.suptitle('Это заголовок') plt.legend()plt.show() Разумеется, matplotlib имеет целый ряд функциональных возможностей; об- ратитесь к документации для получения более сложных примеров. Палиндром madamimadam родом из романа «Улисс» Джойса. Мы обсуждали воз- можности манипулирования символьными цепочками в Python в разделе о па-линдромах, раздел 1.1.4, но, возможно, самым мощным языком для манипулиро-вания символьными цепочками является Perl. Например, предположим, что у нас есть текст, содержащий хештеги, которые являются словами символов, начинаю-щихся с #, и мы хотим собрать все эти хештеги в массив. Можно испытать дрожь от перспективы реализации этой задачи, скажем, на языке программирования C, но в Perl это может быть достигнуто в одной строке: @TAGS = ($TEXT =~ m/\\#([a-zA-Z0-9]+)/g); где $TEXT содержит текст с нулевым или большим числом хештегов, а массив @TAGS будет списком всех хештегов, которые встречаются в $TEXT без префикса #. Для получения большего удовольствия от Perl см. книгу [Schwartz и соавт. (2011)]. Поисковые системы представляют собой сложные и обширные программные системы, и ранжирование страниц является не единственной технической за-дачей, которая должна быть решена. Например, разбор ключевых слов для отбо-ра релевантных страниц (страниц, содержащих ключевые слова), прежде чем на этих страницах будет составлена та или иная ранговая градация, также является сложной задачей: поисковая система должна решить ряд задач, таких как синони- мия (несколько способов сказать одно и то же) и полисемия (несколько значений) и многие другие. См. публикацию [Miller (1995)]. Раздел 1.2.2 основан на § 2 книги [Cenzer и Remmel (2001)]. Еще одно изложе- ние задачи стабильного брачного союза см. в главе 1 [Kleinberg и Tardos (2006)]. Ссылка на Маркиза де Кондорсе в первом предложении раздела 1.2.2 взята из докторской диссертации Юнь Чжая ([Zhai (2010)]), написанной под руководством Рышарда Яницкого. В этой докторской работе Юнь Чжай ссылается на работу [Ar - row (1951)] как источник замечания относительно ранних попыток Маркиза де Кондорсе выполнить попарное ранжирование. Существует удивительно острое описание Кондорсе и его идей в «Судьбах постоянства» (Fortunes of Permanence) Роджера Кимбалла [Kimball (2012)], стр. 237–244. Кондерсе дал нам метод попар-ных сравнений, но он был трагической фигурой эпохи Просвещения: он обещал «абсолютное совершенствование человеческой расы» («perfectionnement même de l’espèce humaine»), но его утопические идеи стали предтечей бесчисленных писак, которые настаивали на совершенствовании человека, хочет он того или нет, от - крывших ящик Пандоры для неизбежных тиранических бесчинств, которые явля-ются результатом утопических мечтаний. Профессор Томас Л. Саати (теорема 1.24) умер 14 августа 2017 года. Он был вы- дающимся профессором Школы бизнеса Питтсбургского университета Каца. Пра-вительство Польши присудило профессору Саати национальную награду, после того как примененение его теории процесса анализа иерархий для принятия ре-шений привело к тому, что страна изначально не присоединилась к Европейскому союзу.",
      "debug": {
        "start_page": 14,
        "end_page": 37
      }
    },
    {
      "name": "Глава 2. Жадный алгоритм 37",
      "content": "--- Страница 38 --- (продолжение)\nГлава 2 Жадный алгоритм Быть может, вам будет полезно по- размыслить над тем, что люди на свете в алчности и коварстве не уме-ют остановиться вовремя и всегда перехватывают через край. Д. Копперфилд, [Dickens (1850)] Жадные алгоритмы – это алгоритмы, склонные добиваться сиюминутного возна-граждения. Они делают выбор, который является локально оптимальным, надеясь, что в конце они придут к глобальному оптимуму. Примером жадной процедуры является отсчитывание сдачи продавщицой в круглосуточном мини-маркете. Для того чтобы использовать как можно меньше монет, продавщица как можно дольше выдает монеты самого высокого номинала, переходя к следующему более низкому номиналу, когда это уже невозможно, и повторяет все сначала. Жадность – это простая стратегия, которая хорошо работает с некоторыми вы- числительными задачами, но оказывается безуспешной с другими. В случае от - считывания наличных, если у нас есть монеты номиналом 1, 5, 25, жадная про-цедура всегда производит наименьшее возможное число монет, но то же самое не верно для 1, 10, 25. Попробуйте выдать 30, которые жадно составят 25, 1, 1, 1, 1, 1, тогда как оптимальным будет 10, 10, 10. 2.1. остовные деревья минимальной стоимости Мы представляем конечные графы с помощью матриц смежности. Для ориен- тированного или неориентированного графа G = (V, Е) его матрицей смежности является матрица AG размера n × n, где n = |V| такое, что элемент (i, j) равен 1, если (i, j) является ребром в G, и 0 в противном случае. Сама матрица смежности может быть легко закодирована в виде цепочки сим- волов над {0, 1}. То есть с учетом AG размера n × n пусть sG ∈ {0, 1}n2, где sG – это просто конкатенация строк AG. Мы можем проверить непосредственно из sG, является ли (i, j) ребром, проверив, содержит ли позиция (i – 1) n + j в sG единицу. Неориентированный граф G представлен парой (В, Е), где V – это множество вер- шин, или узлов, и E ⊆ V × V и ( u, v) ∈ E тогда и только тогда, когда (v, u) ∈ E и ( u, u) ∉ E. Степенью вершины v является число ребер, которые касаются v. Путем в G между v1 и vk является последовательность v1, v2, , vk такая, что каждая (vi, vi+1) ∈ E. G явля- ется связным, если между каждой парой несовпадающих узлов есть путь. Цик лом является замкнутый путь v1, , vk, v1, причем все v1, , vk не совпадают и k ≥ 3. Граф\nГлава 2 Жадный алгоритм Быть может, вам будет полезно по- размыслить над тем, что люди на свете в алчности и коварстве не уме-ют остановиться вовремя и всегда перехватывают через край. Д. Копперфилд, [Dickens (1850)] Жадные алгоритмы – это алгоритмы, склонные добиваться сиюминутного возна-граждения. Они делают выбор, который является локально оптимальным, надеясь, что в конце они придут к глобальному оптимуму. Примером жадной процедуры является отсчитывание сдачи продавщицой в круглосуточном мини-маркете. Для того чтобы использовать как можно меньше монет, продавщица как можно дольше выдает монеты самого высокого номинала, переходя к следующему более низкому номиналу, когда это уже невозможно, и повторяет все сначала. Жадность – это простая стратегия, которая хорошо работает с некоторыми вы- числительными задачами, но оказывается безуспешной с другими. В случае от - считывания наличных, если у нас есть монеты номиналом 1, 5, 25, жадная про-цедура всегда производит наименьшее возможное число монет, но то же самое не верно для 1, 10, 25. Попробуйте выдать 30, которые жадно составят 25, 1, 1, 1, 1, 1, тогда как оптимальным будет 10, 10, 10. 2.1. остовные деревья минимальной стоимости Мы представляем конечные графы с помощью матриц смежности. Для ориен- тированного или неориентированного графа G = (V, Е) его матрицей смежности является матрица AG размера n × n, где n = |V| такое, что элемент (i, j) равен 1, если (i, j) является ребром в G, и 0 в противном случае. Сама матрица смежности может быть легко закодирована в виде цепочки сим- волов над {0, 1}. То есть с учетом AG размера n × n пусть sG ∈ {0, 1}n2, где sG – это просто конкатенация строк AG. Мы можем проверить непосредственно из sG, является ли (i, j) ребром, проверив, содержит ли позиция (i – 1) n + j в sG единицу. Неориентированный граф G представлен парой (В, Е), где V – это множество вер- шин, или узлов, и E ⊆ V × V и ( u, v) ∈ E тогда и только тогда, когда (v, u) ∈ E и ( u, u) ∉ E. Степенью вершины v является число ребер, которые касаются v. Путем в G между v1 и vk является последовательность v1, v2, , vk такая, что каждая (vi, vi+1) ∈ E. G явля- ется связным, если между каждой парой несовпадающих узлов есть путь. Цик лом является замкнутый путь v1, , vk, v1, причем все v1, , vk не совпадают и k ≥ 3. Граф\n--- Страница 39 ---\n38  Жадный алгоритм является ациклическим, если у него нет циклов. Дерево, по определению, является связным ациклическим графом. Остовное дерево связного графа G – это подмно- жество T ⊆ E ребер такое, что (V, T) является деревом. Другими словами, ребра в T должны связывать все узлы G и не содержать циклов. Если G имеет цикл, то для G существует более одного остовного дерева, и в об- щем случае G может иметь много остовных деревьев, но каждое остовное дерево имеет одинаковое число ребер. Лемма 2.1. Каждое дерево с n вершинами имеет ровно n – 1 ребер. Задача 2.2. Докажите лемму 2.1. (Подсказка: сначала покажите, что у каждого де- рева есть лист, то есть узел первой степени. Затем покажите лемму по индукции на n.)Лемма 2.3. Граф с n вершинами и более n – 1 ребер должен содержать хотя бы один цикл.Задача 2.4. Докажите лемму 2.3. Из лемм 2.1 и 2.3 следует, что если граф является деревом, то есть ацикличе- ским и связным, то он должен иметь (n – 1) ребер. Если у него нет ( n – 1) ребер, то он либо неациклический, либо несвязный. Если у него меньше (n – 1) ребер, то он, конечно, несвязный, и если у него больше (n – 1) ребер, он, конечно, неацикличе- ский. Ребрам в графе вполне естественно назначают стоимости, так как ребра в це- лом могут представлять расстояния, пропускную способность или в общем случае затраты на переход из A в B. Пусть c(e) обозначает стоимость ребра e, где c(e) – это неотрицательное вещественное число. Общая стоимость графа G, с(G), представ- ляет собой сумму стоимостей всех ребер в G. Будем говорить, что T есть остовное дерево минимальной стоимости для G, если T является остовным деревом для G, и при наличии любого остовного дерева T ′ для G c(T ) ≤ c(T ′). Для графа G = (V, E) и функции стоимости c, связанной с ребрами в E, мы хотим найти остовное дерево минимальной стоимости. Оказывается, что по счастливой случайности с этим справляется очевидный жадный алгоритм под названием ал- горитма Краскала. Данный алгоритм состоит в следующем: отсортировать ребра в неубывающем порядке стоимостей так, чтобы c(e 1) ≤ c(e2) ≤ … ≤ c(em), и добавлять ребра по одному за раз, за исключением случаев, когда включение ребра образует цикл с уже добавленными ребрами. Алгоритм 2.1. Краскал 1: Отсортировать ребра: c(e 1) ≤ c(e2) ≤ … ≤ c(em) 2: T ← ∅ 3: for i : 1 m do 4: if T ⋃ {ei} не имеет цикла 5: T ← T ⋃ {ei} 6: end if 7: end for Но как проверить существование цикла, то есть исполнить строку 4 в алгорит - ме 2.1? В конце каждой итерации цикла for множество T ребер делит вершины V\n--- Страница 40 ---\nОстовные деревья минимальной стоимости  39 на коллекцию V1, , Vk связных компонент. То есть V является непересекающимся объединением V1, , Vk, каждый Vi образует связный граф, используя ребра из T, и никакое ребро в T не связывает Vi и Vj, если i ≠ j. Простой способ отследить V1, , Vk – применить массив D[i], где D[i] = j, если вершина i ∈ Vj. Инициализировать D, установив D[i ] ← i для каждого i = 1, 2, , n. Для того чтобы проверить, образует ли ei = (r, s) цикл в пределах T, достаточно проверить D[r] = D[s]. Если ei не образует цикла в пределах T, то мы обновляем: T ← T ⋃ {(r, s)}, и мы совмещаем компоненту D[r] с D[s], как показано в алгорит - ме 2.2. Алгоритм 2.2. Слияние компонент k ← D[r ] l ← D[s] for j : 1 n do if D[ j] = l then D[ j] ← k end if end for Задача 2.5. С учетом того, что ребра могут быть упорядочены за m2 шагов, на- пример с помощью сортировки вставками, каково время работы алгоритма 2.1? Краткое описание алгоритмов сортировки см. в примечаниях (раздел 2.5). Задача 2.6. Напишите программу, реализующую алгоритм 2.1 с алгоритмом 2.2 для отслеживания связных компонент. Исходите из того, что входные данные за- даны в виде матрицы смежности размера n × n. Теперь мы докажем, что алгоритм Краскала работает. То, что алгоритм Краска- ла порождает остовное дерево, очевидно не сразу, не говоря уже об остовном де- реве минимальной стоимости. Для того чтобы увидеть, что результирующая кол-лекция T ребер является остовным деревом для G, исходя из того, что G связен, мы должны показать, что (V, T) является связным и ациклическим. Очевидно, что коллекция T является ациклической, потому что мы ни разу не добавляем ребро, которое приводит к циклу. Для того чтобы показать, что (V, T) является связным, мы рассуждаем следующим образом. Пусть u и v равны двум несовпадающим узлам в V. Поскольку G является связным, существует путь p, со - единяющий u и v в G. Алгоритм рассматривает каждое ребро e i графа G по очереди и помещает ei в T, если только T ⋃ {ei} не образует цикла. Но в последнем случае в T уже должен быть путь, соединяющий конечные точки ei, поэтому удаление ei не делает граф несвязным. Этот аргумент можно формализовать, показав, что следующее формальное суждение является инвариантом цикла в алгоритме Краскала: Множество ребер T ⋃ {ei+1, , em} связывает все узлы в V. (2.1) Лемма 2.7. Алгоритм 2.1 выводит дерево T при условии, что G был связен. Задача 2.8. Доказать лемму 2.7, показав, что для связного G алгоритм 2.1 выда- ет T, которое является связным и ациклическим. Для того чтобы доказать, что T\n--- Страница 41 ---\n40  Жадный алгоритм является связным, покажите, что (2.1) является инвариантом цикла. На индук - тивном шаге покажите, что если (2.1) соблюдается после исполнения i цикла, то T ⋃ {ei+2, , em} связывает все узлы V после исполнения (i + 1) цикла. Сделайте вы- вод по индукции, что (2.1) соблюдается для всех i. Наконец, покажите, как исполь- зовать этот инвариант цикла, для того чтобы доказать, что T является связным. Как вы будете аргументировать, что T является ациклическим? Задача 2.9. Предположим, что G = (V, E) не является связным. Покажите, что в этом случае, когда G передается на вход алгоритма Краскала, данный алгоритм вычисляет остовной лес G. Сначала определите понятия связной компоненты и остовного леса. Затем приведите формальное доказательство, используя идею инварианта цикла, как в задаче 2.8. Для того чтобы показать, что остовное дерево, полученное в результате этого алгоритма, на самом деле является остовным деревом минимальной стоимости, мы рассуждаем, что после каждой итерации цикла множество T ребер может быть расширено до остовного дерева минимальной стоимости, используя ребра, кото-рые еще не были рассмотрены. Следовательно, после завершения все ребра будут рассмотрены, поэтому T должно само быть остовным деревом минимальной стои- мости. Мы говорим, что множество Т ребер из G является перспективным, если T может быть расширено до остовного дерева минимальной стоимости для G, то есть T является перспективным, если существует остовное дерево минимальной стоимости Т такое, что T ⊆ T′. Лемма 2.10. Выражение «T является перспективным» является инвариантом цикла для алгоритма Краскала.Доказательство. Доказательство выполняется по индукции на числе итераций основ ного цикла алгоритма Краскала. Базовый случай: на этом этапе алгоритм прошелся по циклу ноль раз, и изначально T является пустым множеством, кото- рое, очевидно, является перспективным (пустое множество является подмножест - вом любого множества). Индукционный шаг: допустим, что T является перспективным, и покажем, что T остается перспективным после еще одной итерации цикла. Обратите внимание, что ребра, используемые для расширения T до остов- ного дерева, должны поступать из еще не рассмотренных ребер, поскольку уже рассмот ренные ребра либо уже находятся в T, либо были отклонены, так как они образуют цикл. Мы исследуем случаи по порядку относительно того, что произой-дет после рассмотрения ребра e i. Случай 1: ei отклоняется. T остается неизменным, и оно по-прежнему пер- спективно. Есть один тонкий момент: Т было перспективно перед исполнением цикла, имея в виду, что существовало подмножество ребер S ⊆ {ei, , em}, которое расширяло T до остовного дерева минимальной стоимости, то есть T ⋃ S является остовным деревом минимальной стоимости. Но после исполнения цикла ребра, расширяющие T до остовного дерева минимальной стоимости, будут прибывать из {e i+1, , em}; но это не проблема, так как ei не может быть частью S (поскольку тог - да T ⋃ S будет содержать цикл), поэтому S ⊆ {ei+1, , em}, и поэтому S по-прежнему является кандидатом для расширения T до остовного дерева минимальной стои-\n--- Страница 42 ---\nОстовные деревья минимальной стоимости  41 мости, даже после исполнения цикла. Следовательно, T остается перспективным после исполнения цикла, хотя ребра, расширяющие его до остовного дерева ми- нимальной стоимости, прибывают из меньшего множества (то есть не содержа-щего e i). Случай 2: ei принимается. Мы должны показать, что T ⋃ {ei} по-прежнему является перспективным. Поскольку T является перспективным, существует остовное дерево минимальной стоимости T1 такое, что T ⊆ T1. Рассмотрим два подслучая. Подслучай а: ei ∈ T1. Тогда очевидно, что T ⋃ {ei} является перспективным. Подслучай b: ei ∉ T1. Тогда, согласно приведенной ниже лемме о замене, в T1–T2 есть ребро ej, где T2 – это остовное дерево, полученное в результате алгоритма, такое, что T3 = (T1 ⋃ {ei}) – {ej} является остовным деревом. Обратите внимание, что i < j, так как в противном случае ej было бы отклонено из T и тем самым образовался бы цикл в T, и поэтому так же и в T1. Следовательно c(ei) ≤ c(ej), поэтому c(T3) ≤ c(T1), и поэтому Т3 также должно быть остовным деревом минимальной стоимости. По- скольку T ⋃ {ei} ⊆ T3, из этого следует, что T ⋃ {ei} является перспективным. Этим завершается доказательство индукционного шага. □ Рассмотрим граф на рис. 2.1 и выполним алгоритм Краскала, представленный на рис. 2.2, начиная с верхнего левого графа, продолжая вправо, затем до следую-щей строки графа, продвигаясь слева направо, заканчивая в нижнем правом углу результирующим остовным деревом минимальной стоимости. e1 e2 e5e6 e7 e4e3 Рис. 2.1  Все ребра имеют стоимость 1 e1 e1 e1 e1e1 e1 e1 e2 e2 e2 e2e2 e2 e6 e6 e4 e4 e4 e4 Рис. 2.2  Прогон алгоритма Краскала на графе из рис. 2.1 Изначально в левом верхнем углу у нас нет ребер и T = ∅, и на каждой итерации мы рассматриваем следующее ребро, в результате чего получаем:\n--- Страница 43 ---\n42  Жадный алгоритм Итерация Ребро Текущий Т Основное дерево минимальной стоимости (ОДМС), расширяющее Т 0 1234567е 1 е2 е3 е4 е5 е6 е7∅{е 1} {е1, е2} {е1, е2} {е1, е2, е4} {е1, е2, е4} {е1, е2, е4, е6} {е1, е2, е4, е6}{е1, е3, е4, е7} {е1, е3, е4, е7} {е1, е2, е4, е7} {е1, е2, е4, е7} {е1, е2, е4, е7} {е1, е2, е4, е7} {е1, е2, е4, е6} {е1, е2, е4, е6} Обратите внимание, что алгоритм рассматривает ребра в порядке их индексов, то есть e1, e2, e3, e4, e5, e6, e7, и что стоимость всех этих ребер равна 1. (Таким образом, любое упорядочение этих ребер породит остовное дерево минимальной стоимо- сти, но не обязательно оно будет таким же, что и каноническое упорядочение.) Лемма 2.11 (лемма о замене)1. Пусть G равно связному графу, и пусть T1 и Т2 равны любым двум остовным деревьям для G. Для каждого ребра е в T2–T1 сущест - вует ребро е′ в T1–Т2 такое, что T1 ⋃ {e} – { e′} является остовным деревом для G (cм. рис. 2.3). T1 T2 e′ e′ Рис. 2.3  Лемма о замене e1 e1 e1 e3 e3e4 e4 e2 e2 Рис. 2.4  Пример леммы о замене: левый и средний графы явля- ются двумя разными остовными деревьями одного и того же графа. Предположим, мы добавляем ребро e4 в среднее дерево; затем мы удаляем e3 и получаем крайнее правое остовное дерево Задача 2.12. Докажите эту лемму. (Подсказка: пусть e равно ребру в T2–T1. Тогда T1 ⋃ {e} содержит цикл – могут ли все ребра в этом цикле принадлежать T2?) Задача 2.13. Предположим, что ребро e1 имеет меньшую стоимость, чем любое другое ребро; то есть c(e1) < c(ei) для всех i > 1. Покажите, что каждое остовное де- рево минимальной соимости для G включает e1. 1 Лемма Стейница о замене (exchange lemma) – утверждение в линейной алгебре о том, что любое множество линейно независимых векторов в линейном пространстве можно дополнить до базиса пространства элементами некоторого заданного базиса. Лема ис - пользуется в доказывании утверждения об одинаковом числе элементов во всех базисах линейного пространства. https://uk.wikipedia.org/wiki/Лема_Стейніца_про_заміну. – Прим. перев.\n--- Страница 44 ---\nОстовные деревья минимальной стоимости  43 Задача 2.14. Прежде чем алгоритм 2.1 продолжит работу, он упорядочивает ребра в строке 1 и, предположительно, разрывает совпадения – то есть сортирует ребра с одной и той же стоимостью – произвольным образом. Покажите, что для каж - дого остовного дерева минимальной стоимости T графа G существует определен- ный способ разрыва совпадений, благодаря чему алгоритм возвращает T. Задача 2.15. Напишите программу, которая на входе принимает описание решет - ки и на выходе выводит ее остовное дерево минимальной стоимости. n-узловая решетка представляет собой граф, состоящий из n2 узлов, организованных в виде квадратного массива из n × n точек. Каждый узел может быть связан не более чем с узлами непосредственно над и под ним (если они существуют) и с двумя узлами сразу слева и справа (если они существуют). Пример 4-узловой решетки приведен на рис. 2.5. 23 7 4514 1 1 2 91 15 3 3 3 6 7 Рис. 2.5  Пример 4-узловой решетки. Обратите внимание, что она имеет 42 = 16 узлов и 17 ребер Какое наибольшее число ребер может быть у n-узловой решетки? У нас есть следующее соглашение об именовании узлов: мы именуем узлы слева направо, строка за строкой, начиная с верхней строки. Таким образом, наша 4-узловая ре-шетка описывается следующим списком смежности: 4 : (0, 1; 4), (1, 5; 3), (2, 6; 15), (3, 7; 1), (4, 5; 1), (5, 6; 1), , (2.2) где первое число – это параметр размера решетки, и первые два числа в каждой тройке обозначают два узла, которые описывают ребро, и третье число после точ-ки с запятой дает стоимость этого ребра. Если на вход подается список троек, то ваша программа должна сначала прове- рить, описывает ли этот список решетку, а затем вычислить для решетки ее остов-ное дерево минимальной стоимости. В нашем примере с 4-узловой решеткой реб-ра, обозначенные сплошной линией, описывают остовное дерево минимальной стоимости. Также обратите внимание, что ребра в (2.2) не обязательно должны быть заданы в определенном порядке. Ваша программа должна принимать на входе файл, скажем graph.txt , содержащий список, такой как (2.1). Например, 2:(0,1;9),(2,3;5),(1,3;6),(0,2;2) , и она должна выводить граф, показывающий ребра остовного дерева минимальной стоимости, прямо на экран. Граф должен быть «текстовым», в котором символ « *» описывает\n--- Страница 45 ---\n44  Жадный алгоритм узлы и символы « –» и «|» описывают ребра. В этом примере остовное дерево мини- мальной стоимости, заданное 2-узловой решеткой, представляется как: * * | | *–* 2.2. з адания с предельными сроками и прибылями Мы имеем n заданий, каждое из которых занимает единицу времени, и обра- ботчик, на котором мы хотели бы запланировать их последовательно настоль-ко прибыльно, насколько это возможно. У каждого задания есть связанная с ним прибыль, а также предельный срок; если задание не запланировано к своему пре-дельному сроку, то мы не получаем его прибыль. Поскольку каждое задание зани-мает одинаковое количество времени, мы полагаем, что расписание S состоит из последовательности ячеек заданий, или «слотов», 1, 2, 3, …, где S(t) – это задание, запланированное в ячейке t. Формально входными данными является последовательность пар (d 1, g1), (d2, g2), , (dn, gn), где gi ∈ �+ – это прибыль (прирост), получаемая от задания i, и di ∈ � – предельный срок для задания i. В разделе 4.5 мы рассмотрим случай, когда зада- ния имеют произвольную длительность – заданную положительным целым чис - лом. Однако когда длительности произвольны, а не имеют одинаковую единицу измерения, жадный подход, «похоже» 1, не справляется. Расписание представляет собой массив S(1), S(2), , S(d), где d = max di, то есть d – это последний предельный срок, после которого задания не могут быть запла-нированы. Если S(t) = i, то задание i запланировано на момент времени t, 1 ≤ t ≤ d. Если S(t) = 0, то никакого задания на момент времени t не запланировано. Распи- сание S является допустимым, если оно удовлетворяет двум условиям: условие 1: если S(t) = i > 0, то t ≤ d i, то есть каждое запланированное задание соответствует своему сроку; условие 2: если t1 ≠ t2, а также S(t1) ≠ 0, тогда S(t1) ≠ S(t2), то есть каждое за- дание планируется не более одного раза. Задача 2.16. Напишите программу, которая на входе принимает расписание S и последовательность заданий и проверяет, является ли S допустимым. Пусть суммарная прибыль расписания S равна P(S) = åd t=1 gS(t), где g0 = 0. Мы хотим найти допустимое расписание S, прибыль которого P(S) как можно больше; это может быть достигнуто с помощью жадного алгоритма 2.3, который упорядочи-вает задания в невозврастающем порядке прибыли и размещает их как можно позже в пределах их предельного срока. Удивительно, что этот алгоритм работает, и этот факт, похоже, является научным подтверждением преимуществ волокиты, именуемой также прокрастинацией. 1 Мы говорим «похоже», ставя это слово в кавычки, потому что нет известного доказатель- ства того, что жадный алгоритм не будет справляться; такое доказательство потребует строгого определения того, что означает «порождение жадным алгоритмом решения», которое само по себе является сложной задачей (см. [Allan Borodin (2003)]).\n--- Страница 46 ---\nЗадания с предельными сроками и прибылями  45 Строка 7 в алгоритме 2.3 находит последнюю свободную ячейку, которая со- ответствует предельному сроку; если такая свободная ячейка не существует, то задание выполняться не будет. То есть если нет t, удовлетворяющего как S(t) = 0, так и t ≤ di, то последняя команда в строке 7, S(t) ← i, не исполняется и цикл for рас - сматривает следующее i. Алгоритм 2.3. Планирование заданий 1: Отсортировать задания в невозрастающем порядке прибылей: g1 ≥ g2 ≥ ≥ gn 2: d ← maxi di 3: for t : 1 d do 4: S(t) ← 0 5: end for 6: for i : 1 n do 7: Найти самое крупное t такое, что S(t) = 0 и t ≤ di, S(t) ← i 8: end for Задача 2.17. Реализуйте алгоритм 2.3 для планирования заданий. Теорема 2.18. Жадное решение задачи планирования заданий является опти- мальным. То есть прибыль P(S) расписания S, вычисленная алгоритмом 2.3, явля- ется максимально большой. Расписание является перспективным, если его можно расширить до оптималь- ного расписания. Расписание S′ расширяет расписание S, если для всех 1 ≤ t ≤ d, если S(t) ≠ 0, то S(t) = S′(t). Например, S′ = (2, 0, 1, 0, 3) расширяет S = (2, 0, 0, 0, 3). Лемма 2.19. Выражение «S является перспективным» является инвариантом для (второго) цикла for в алгоритме 2.3. На самом деле, как и в случае алгоритма Краскала в предыдущем разделе, мы должны более точно определить понятие «перспективный» в лемме 2.19: мы гово- рим, что «S является перспективным после i-й итерации цикла в алгоритме 2.3», если S может быть расширено до оптимального расписания с использованием за-даний из числа {i + 1, i + 2, , n}, то есть, используя подмножество тех заданий, которые еще не были рассмотрены. Задача 2.20. Рассмотрим следующие входные данные: {(1, 10), (1, 10), (2, 8), (2, 8), (4, 6), (4, 6), (4, 6), (4, 6)}, где задания были пронумерованы внизу для удобства. Выполним трассировку работы алгоритма 2.3 на этих входных данных. Слева поместим номера заданий в соответствующие ячейки; справа покажем, как оптимальное решение коррек - тируется с целью сохранения свойства «перспективности». Начнем со следующей конфигурации: S 0 = 0000 и S0 opt = 2458. Задача 2.21. Почему из леммы 2.19 следует теорема 2.18? (Подсказка: ответ кро- ется в непосредственном наблюдении.)1 2 3 4 5 6 7 8\n--- Страница 47 ---\n46  Жадный алгоритм Теперь докажем лемму 2.19. Доказательство. Доказательство выполняется по индукции. Базовый случай: пос ле 0-й итерации цикла S = (0, 0, …, 0), и мы можем расширить его заданиями {1, 2, …, n}, то есть в нашем распоряжении есть все задания; поэтому S является перспективным, так как мы можем взять любое оптимальное расписание, и оно будет расширением S. Индукционный шаг: предположим, что S является перспективным, и пусть Sopt равно некому оптимальному расписанию, которое расширяет S. Пусть S′ равно результату еще одной итерации цикла, в котором рассматривается задание i. Мы должны доказать, что S′ остается перспективным, поэтому цель состоит в том, чтобы показать, что существует оптимальное расписание Sopt, которое расширяет S′. Рассмотрим два случая: S = 0 0 j Sopt = 0 i j Рис. 2.6  Если S имеет задание j в некой позиции, то Sopt также имеет задание j в той же позиции. Если в заданной позиции S имеет ноль (там не запланировано ни одного задания), то Sopt может иметь ноль или другое задание в той же позиции Случай 1: задание i не может быть запланировано. Тогда S′ = S, поэтому мы принимаем S′opt = Sopt, и доказательство завершено. Единственная тонкость состоит в том, что S было расширяемо до Sopt заданиями в {i, i + 1, , n}, но после i-й итера- ции в нашем распоряжении задания i больше нет. Задача 2.22. Покажите, что эта «тонкость», упомянутая в приведенном выше аб- заце, не является проблемой. Случай 2: Задание i планируется на момент времени t0, поэтому S′(t0) = i (тогда как S(t0) = 0) и t0 является самым последним возможным временем для задания i в расписании S. Мы имеем два подслучая. Подслучай a: задание i запланировано в Sopt на момент времени t1: если t1 = t0, то, как и в случае 1, просто примем S ′opt = Sopt; если t1 < t0, то пусть S′opt равно Sopt, за исключением того, что мы переставляем t0 и t1, то есть принимаем S′opt(t0) = Sopt(t1) = i и S ′opt(t1) = Sopt(t0). Тогда S′opt является допустимым (вопрос почему № 1), оно расширяет S′ (вопрос почему № 2), и P(S ′opt) = P(Sopt) (вопрос почему № 3). Случай t1 > t0 невозможен (вопрос почему № 4). Подслучай b: задание i не запланировано в Sopt. Тогда мы просто определяем S′opt таким же, как Sopt, за исключением, что S′opt(t0) = i. Поскольку Sopt является допус - тимым, то и S′opt тоже является допустимым, и поскольку S′opt расширяет Sopt, нам нужно только показать, что P(S ′opt) = Р(Sopt). Это вытекает из следующего утверждения: Утверждение 2.23. Пусть Sopt(t0) = j. Тогда gj ≤ gi. Доказательство. Докажем утверждение от обратного: предположим, что gj > gi (за- метим, что в этом случае j ≠ 0). Тогда задание j было рассмотрено перед задани-\n--- Страница 48 ---\nДальнейшие примеры и задачи  47 ем i. Поскольку задание i было запланировано на момент времени t0, задание j должно быть запланировано на момент времени t2 ≠ t0 (мы знаем, что задание j было запланировано в S, так как S(t0) = 0 и t0 ≤ dj, поэтому имелась ячейка для зада- ния j, и поэтому оно было запланировано). Но Sopt расширяет S, и S(t2) = j ≠ Sopt(t2) – противоречие. □ Этим завершается доказательство индукционного шага. □ Задача 2.24. Убедитесь, что вы можете ответить на все вопросы «почему» в при- веденном выше доказательстве. Кроме того, где в доказательстве утверждения мы используем тот факт, что j ≠ 0? Задача 2.25. При каких условиях на входных данных существует уникальное оп- тимальное расписание? Если существует более одного оптимального расписания, и при наличии одного такого оптимального расписания всегда ли существует рас - пределение заданий, которое по-прежнему находится в невозрастающем поряд-ке прибылей, приводя к тому, что алгоритм выдает это конкретное оптимальное расписание? 2.3. дальнейшие примеры и зада Чи 2.3.1. Отсчитывание сдачи Задача отсчитывания сдачи, кратко описанная во введении к этой главе, состоит в том, чтобы заплатить заданную сумму, используя наименьшее число монет, при этом применяя какой-то фиксированный номинал и неограниченный запас мо-нет каждого номинала. Рассмотрим следующий ниже жадный алгоритм для решения задачи отсчиты- вания сдачи, где номиналы равны C = {1, 10, 25, 100}. При n ∈ � на входе алгоритм выдает наименьший список L монет (из числа C ), сумма которых равна n. Обратите внимание, что s равно сумме значений монет в L и что, строго говоря, L является мультимножеством (в мультимножестве один и тот же элемент может появляться более одного раза). Задача 2.26. Реализуйте алгоритм 2.4 для отсчитывания сдачи. Задача 2.27. Покажите, что алгоритм 2.4 (с заданными номиналами) не обяза- тельно дает оптимальное решение. То есть покажите n, для которого выход L со - держит больше монет, чем оптимальное решение. Алгоритм 2.4. Отсчитывание сдачи 1: C ← {1, 10, 25, 100}; L ← ∅; s ← 0 2: while (s < n) do3: найти наибольшее х в С такое, что s + x ≤ n 4: L ← L ⋃ {x}; s ← s + x 5: end while6: return L Задача 2.28. Предположим, что C = {1, p, p 2, , pn}, где p > 1 и n ≥ 0 – это целые чис - ла. То есть «C ← {1, 10, 25, 100}» в строке 1 алгоритма 2.4 заменяется на «C ← {1, p, p2,\n--- Страница 49 ---\n48  Жадный алгоритм , pn}». Покажите, что с этой серией номиналов (для некоторых фиксированных p, n) приведенный выше жадный алгоритм всегда находит оптимальное решение. (Подсказка: начните с подходящего определения перспективного списка.) 2.3.2. Паросочетание с максимальным весом Пусть G = (V1 ⋃ V2, E) равно двудольному графу, то есть графу с реберным множест - вом E ⊆ V1 × V2 с непересекающимися множествами V1 и V2. w : E → � назначает вес w(e) ∈ � для каждого ребра e ∈ E = {e1, , em}. Паросочетанием для G является подмножество M ⊆ E такое, что никакие два ребра в M не имеют общей вершины. Вес М равен w(M) = åe∈M w(e). Задача 2.29. Дайте простой жадный алгоритм, который для заданного двудоль- ного графа с весами ребер пытается найти паросочетание с максимально возмож - ным весом. Задача 2.30. Приведите пример двудольного графа с весами ребер, для которого ваш алгоритм в задаче 2.29 не может найти паросочетание с максимально воз- можным весом. Задача 2.31. Предположим, что все веса ребер в двудольном графе не совпадают, и каждый из них является степенью числа 2. Докажите, что в этом случае вашему жадному алгоритму всегда удается найти паросочетание с максимальным весом. (В случае этого вопроса будем считать, что все ребра присутствуют, то есть что E = V × V.) 2.3.3. Кратчайший путь Следующий пример жадного алгоритма очень красив. Он напоминает одного из старых картографов, который создавал карты мира с белыми пятнами – неизвест - ными и неизведанными местами. Предположим, что у нас есть граф G = (V, E), выделенный начальный узел s и функция стоимости для каждого ребра e ∈ E, обозначенная c(e). Нас просят вы- числить самые дешевые пути из s во все остальные узлы в G, где стоимость пути равна сумме стоимостей его ребер. Рассмотрим следующий жадный алгоритм: алгоритм поддерживает множество s разведываемых узлов, и для каждого u ∈ S он хранит значение d(u), то есть самый дешевый путь внутри S, начиная в s и заканчивая в u. Изначально S = {s} и d(s) = 0. Теперь для каждого v ∈ V – S мы находим кратчай- ший путь в v, путешествуя внутри разведываемой части S до некоторого u ∈ S, за которым следует единственное ребро (u, v). См. рис. 2.7. s uve Рис. 2.7  Вычисление пути из s в u\n--- Страница 50 ---\nДальнейшие примеры и задачи  49 То есть мы вычисляем: d′(v) = min d(u) + c(e). (2.3) Мы выбираем узел в v ∈ V – S, для которого минимизируется (2.3), добавляем v в S, устанавливаем d(v) = d′(v) и повторяем. Таким образом, мы добавляем один узел за раз в разведываемую часть, и мы останавливаемся, когда S = V. Этот жадный алгоритм вычисления кратчайшего пути связан с алгоритмом ни- дерландского ученого Эдсгера Дейкстры. Нетрудно заметить, что время работы алгоритма равно O(n2). Задача 2.32. Спроектируйте алгоритм в псевдокоде и покажите, что в конце для каждого u ∈ V d(u) является стоимостью самого дешевого пути из s в u.Задача 2.33. Открытый протокол предпочтения кратчайшего пути (open shortest path first, OSPF) – это протокол маршрутизации для IP , подробно описанный в ра- бочем предложении RFC 2328 (где RFC расшифровывается как «request for comment», то есть «запрос комментария», который представляет собой серию меморанду - мов, опубликованных рабочей группой по стандартам для сети интернет , опи- сывающей работу интернета). Широко применяемый протокол маршрутизации OSPF использует жадный алгоритм Дейкстры для вычисления так называемого «дерева кратчайших путей», который для конкретного узла x в интернете пере- числяет лучшие связи со всеми другими узлами в подсети узла x. Напишите программу, реализующую упрощенный механизм политики дина- мической маршрутизации. Точнее, требуется реализовать демон управления таб-лицей маршрутизации, который поддерживает базу данных состояния связи как в протоколе внутренней маршрутизации OSPF. Мы исходим из того, что все узлы являются либо маршрутизаторами, либо сетями (то есть нет «мостов», «концент - раторов» и т. д.). Назовите свою программу routed (как в демоне маршрутизации). После запуска в командной строке она ожидает инструкций и выполняет действия: 1) add rt (маршрутизаторы) – эта команда добавляет маршрутизаторы в таб- лицу маршрутизации, где (маршрутизаторы) – это разделенный запятыми список (положительных) целых чисел и целочисленных диапазонов. То есть (маршрутизаторы) могут быть 6,9,10–13,4,8 , которые будут включать марш- рутизаторы rt4,rt6,rt8,rt9,rt10,rt11,rt12,rt13 Ваша программа должна быть достаточно робастной, чтобы принимать лю-бую такую легальную последовательность (включая одиночный маршрути-затор) и возвращать сообщение об ошибке, если команда пытается добавить уже существующий маршрутизатор (но другие валидные маршрутизаторы в списке (маршрутизаторы) должны добавляться независимо); 2) del rt (маршрутизаторы) – удаляет маршрутизаторы, указанные в спис - ке (маршрутизаторы). Если команда пытается удалить несуществующий маршрутизатор, то должно быть возвращено сообщение об ошибке; нам нужна робастность: существующие маршрутизаторы должны быть уда-лены; при попытке удалить несуществую щие маршрутизаторы должно u∈S,e=(u,v)\n--- Страница 51 ---\n50  Жадный алгоритм возвращаться сообщение об ошибке (с указанием маршрутизаторов- «нарушителей»). После показа сообщения об ошибке программа не долж - на останавливаться; 3) add nt (сети) – добавить сети согласно списку (сети); тот же формат, что и для добавления маршрутизаторов. Например, « add nt 89» приведет к добавле- нию nt89. Обработка ошибок должна проделываться аналогично случаю до- бавления маршрутизаторов; 4) del nt (сети) – удалить сети, заданные в списке (сети); 5) con x y z – связать узел х и y, где x, y – это существующие маршрутизаторы и сети (например, х = rt8 и y = rt90, или x = nt76 и y = rtl) и z – это стоимость соединения. Если x или y не существует, то должно быть возвращено сооб- щение об ошибке. Обратите внимание, что сеть является ориентированной; то есть следующие две команды не эквивалентны: « con rt3 rt5 1» и «con rt5 rt3 1». Важно отметить, что две сети не могут быть связаны напрямую; попытка это сделать должна генерировать сообщение об ошибке. Если связь между x и y уже существует, то она обновляется новой стоимостью z; 6) display – эта команда показывает таблицу маршрутизации, то есть базу дан- ных о состоянии связи. Например, в результате добавления rt3, rt5, nt8, nt9 и подачи команд « con rt5 rt3 1» и «con rt3 nt8 6» будет показана следующая ниже таблица маршрутизации: rt3 rt5 nt8 nt9rt3 1rt5nt8 6nt9 Обратите внимание, что (согласно рабочему предложению RFC 2338, описы- вающему версию OSPF 2) мы читаем таблицу следующим образом: «сначала столбец, затем строка». Тем самым в таблице говорится, что есть связь из rt5 в rt3 со стоимостью 1 и еще одна связь из rt3 в nt8 со стоимостью 6; 7) tree x – эта команда вычисляет дерево кратчайших путей из базы данных состояния связи, где x является корнем. Обратите внимание, что в этом слу - чае x должен быть маршрутизатором. Выходные данные должны быть пред- ставлены в следующем виде: w1 : x, v1, v2, , vn, y1 : нет пути в y2 w3 : x, u1, u2, , um, y3 где w1 – это стоимость пути (сумма стоимостей ребер) из x в y1 с промежу - точными узлами узла vi (то есть переходами, для того чтобы попасть из x в y1. Каждый узел yj в базе данных должен быть перечислен; если нет никакого пути из x в yj, то программа должна об этом сообщить, как в приведенном выше примере выходных данных. Продолжая пример базы данных состояния связи в объяснении команды display , выходными данными выполнения команды « tree rt5» будут:\n--- Страница 52 ---\nДальнейшие примеры и задачи  51 1 : rt5,rt3 7 : rt5,rt3,nt8 : no path to nt9 Так же, как это сделано в стандарте OSPF, дерево путей должно быть вычис - лено жадным алгоритмом Дейкстры. Наконец, между двумя узлами может быть несколько путей одинакового значения; в этом случае объясните в комментариях в вашей программе, как ваша схема выбирает один из них; 8) quit – убивает демона. 2.3.4. Коды Хаффмана Еще один важный пример жадного решения дает алгоритм Хаффмана, широко используемый и эффективный метод сжатия данных без потерь. В алгоритме Хаффмана используется таблица частот появления символов, которая предна-значена для построения оптимального способа представления каждого символа в виде двоичной строки. См. § 16.3 в книге [Cormen и соавт. (2009)] для получения подробной информации, но следующий ниже пример иллюстрирует ключевую идею. Предположим, что у нас есть строка s над алфавитом { a, b, c, d, e, f} и |s| = 100. Предположим также, что символы в s встречаются с частотами соответственно 44, 14, 11, 17, 8, 6. Так как имеется шесть символов, если бы для их представления мы использовали двоичные кодовые слова фиксированной длины, то нам потребова-лось бы три бита, а значит, 300 символов для представления строки. Вместо кодировки фиксированной длины мы хотим дать частым символам короткое кодовое слово и нечастым символам длинное кодовое слово. Мы рас - сматриваем только коды, в которых кодовое слово не является префиксом како-го-либо другого кодового слова. Такие коды называются префиксными кодами; ограничивая внимание префиксными кодами, мы не получаем никакой потери общности, так как можно показать, что любой код всегда можно заменить пре-фиксным кодом, который, по крайней мере, так же хорош. С помощью префиксного кода кодирование и декодирование выполняются лег - ко; в случае кодирования мы просто сцепляем кодовые слова, представляющие каждый символ файла. Поскольку ни одно кодовое слово не является префиксом любого другого, кодовое слово, начинающееся с закодированной строки, является однозначным, и поэтому декодирование выполняется просто. Префиксный код может быть задан двоичным деревом, в котором листья поме- чены символом и его частотой, а каждый внутренний узел помечен суммой частот листьев в его поддереве (cм. рис. 2.8). Мы строим код символа, проходя дерево, начиная с корня и записывая 0 для левого ребенка и 1 для правого ребенка. Пусть å равно алфавиту из n символов, и пусть f : å → � равно функции частот. Алгоритм Хаффмана строит дерево T, соответствующее оптимальному коду, сни- зу вверх. Он начинается со множества |å| листьев и выполняет последователь-ность из |å| – 1 операций «слияния» для создания финального дерева. На каждом шагу самые частые объекты подвергаются слиянию; результатом слияния двух объектов является новый объект, частота которого равна сумме частот двух объ-ектов, которые были слиты вместе.\n--- Страница 53 ---\n52  Жадный алгоритм a:44 c:11 f:6b:14 e:8d:17100 56 25 31 14 Рис. 2.8  Бинарное дерево для префиксного кода переменной длины Алгоритм 2.5. Хаффман n ← |å| ; Q ← å for i = 1 n – 1 do разместить новый узел z left[z] ← x = извлечь-min(Q) right[z] ← y = извлечь-min(Q) f(z) ← f(x) + f(y) вставить z в Q end for Задача 2.34. Рассмотрим файл, состоящий из 100 символов в кодировке ASCII со следующими частотами: Символ abcdefgh Частота 40 15 12 10 8 6 5 4 Используя стандартную кодировку ASCII, этот файл требует 800 бит. Вычислите префиксную кодировку переменной длины для этого файла и общее число бит при использовании данной кодировки. Задача 2.35. Напишите программу, которая на входе принимает текстовый файл, скажем, над алфавитом ASCII, и использует алгоритм Хаффмана, чтобы сжать его в двоичную строку. Сжатый файл должен иметь заголовок, содержащий привязку символов к битовым строкам с целью правильного разжатия сжатого файла. Ваша программа должна быть способна выполнять как сжатие, так и разжатие. Сравни-те свое решение со стандартными инструментами сжатия, такими как вспомога- тельная программа gzip1. 1 Вспомогательная программа gzip реализует алгоритм Лемпеля–Зива–Уэлша (Lempel– Ziv–Welch, LZW), то есть алгоритм сжатия данных без потерь, доступный на платформах UNIX. В качестве входных данных он принимает любой файл и выводит сжатую версию с расширением .gz. Он описан в рабочих предложениях RFC 1951 и 1952.\n--- Страница 54 ---\nОтветы к избранным задачам  53 2.4. ответы к избранным зада Чам Задача 2.2. Лист – это вершина с одним исходящим ребром; предположим, что листа нет. Выберите вершину, возьмите одно из исходящих из нее ребер. Посколь- ку каждая вершина имеет, по крайней мере, два смежных ребра, мы продолжаем приходить по одному ребру и уходить по другому. Поскольку существует конечное число ребер, мы должны в конечном итоге сформировать цикл. Противоречие. Теперь мы покажем по индукции на n, что дерево с n вершинами должно иметь ровно n – 1 ребер. Базовый случай: n = 1, то есть дерево состоит из одного узла, и, следовательно, оно не имеет ребер; n – 1 = 1 – 1 = 0 ребер. Индукционный шаг: предположим, что у нас есть дерево с n + 1 узлами. Выберите лист и ребро, которое соединяет его с остальной частью дерева. Удаление этого листа и его ребра при-водит к дереву с n узлами, а следовательно – по индукционной гипотезе, – с n – 1 ребрами. Таким образом, все дерево имеет (n – 1) + 1 = n ребер, как и требуется. Задача 2.4. Докажем это по индукции, с базовым случаем n = 3 (так как граф – без многочисленных ребер между одной и той же парой узлов – не может иметь цикл с менее чем 3 узлами). Если n = 3, и ребер больше, чем n – 1 = 2, то ребер должно быть ровно 3. Поэтому граф представляет собой цикл («треугольник»). Индукционный шаг: рассмотрим граф с n + 1 узлами (n ≥ 3) и, по крайней мере, n + 1 ребрами. Если у графа есть узел с нулем или одним смежным с ним ребром, то, удалив этот узел (и его ребро, если оно есть), мы получим граф с n узлами и не менее n ребрами, и поэтому – по индукционной гипотезе – результирующий граф имеет цикл, и, значит, исходный граф также имеет цикл. В противном случае все узлы имеют, по крайней мере, два смежных ребра. Предположим, что v 0 является таким узлом, и (v0, x), (v0, y) – это два ребра. Удалим v0 из графа, удалим ребра (v0, x), (v0, y) и заменим их одним ребром (х, y). Опять же – по индукционной гипотезе – в полученном графе должен быть цикл. Но тогда должен быть цикл и в исходном графе. (Обратите внимание, что существует n + 1 узлов, поэтому после удаления v 0 имеется n узлов и n ≥ 3.) Задача 2.5. Мы знаем, что строки 1–2 алгоритма 2.1 требуют не более m2 + 1 шагов. Мы также должны создать массив D, который требует еще n шагов (где n – это число вершин). Цикл for в строке 3 будет проходить ровно m итераций. Выражение «T ⋃ {ei} не имеет цикла» (где ei = (r, s)) эквивалентно выражению «D[r ] ≠ D[s]», поэтому проверка в строке 4 требует только одного шага. Для цели установления верхней границы можно с уверенностью принять допущение, что каждая проверка воз-вращает «истину», поэтому мы должны пройти весь алгоритм 2.2 целиком в каж - дой итерации цикла for. Алгоритм 2.2 требует 2 присваиваний, за которыми следует цикл, выполняе- мый n раз, и имеет не более 2 шагов; алгоритм 2.2 имеет сложность O(2n + 2) = O(n). Поэтому составной алгоритм, где алгоритм 2.2 используется для выполнения строки 4 алгоритма 2.1 и сортировка вставками используется для строки 1, явно выполняется за O(m 2 + n + 1 + m(2n + 2)). То же самое, если p = max(n, m), то алгоритм имеет сложность O(p2). Другими словами, если число ребер больше числа вершин, то узким местом яв- ляется алгоритм сортировки. Более того, исходя из допущения, что рассматри-ваемый граф является связным, число вершин равно не менее n – 1; любой граф\n--- Страница 55 ---\n54  Жадный алгоритм с n – 1 ребрами либо уже является остовным деревом, либо не является связным, поэтому можно с уверенностью допустить, что m ≥ n. Использование сортировки слиянием, пирамидальной сортировки или быстрой сортировки позволит усовер- шенствовать сложность до O(m log(m)). Задача 2.8. Начнем с базового случая: перед первой итерацией t0 является пус - тым множеством (i = 0). Поскольку G является связным, очевидно, что {e1, e2, , em} = E связывает все узлы в V. Далее мы доказываем по индукции. Допустим, что после i – 1 итераций Ti–1 ⋃ {ei, , em} связывает все узлы в V. На итерации i у нас есть два случая. Случай 1: Ti–1 ⋃ {ei} не имеет цикла, поэтому Ti = Ti–1 ⋃ {ei}. Ti ⋃ {ei+1, , em} и Ti–1 ⋃ {ei, , em} являются одним и тем же множеством, ei только что перешло из «остав- шихся» ребер в T. По гипотезе последнее из указанных реберных множеств свя- зывает все узлы в V, поэтому первое должно связывать тоже. Случай 2: Ti–1 ⋃ {ei} содержит цикл, поэтому Ti = Ti–1. Рассмотрим любые два узла u, v ∈ V. По гипотезе существует путь из u в v, состоящий из ребер в Ti–1 ⋃ {ei, , em}. Если ei в этом пути нет, то доказательство завершено. Путь между u и v по- прежнему существует, так как мы только потеряли доступ к ei. Если ei = (a, b) нахо- дится в этом пути, то мы можем заменить его другим путем из a в b; ei был в цикле, поэтому еще один такой путь обязательно существует. Мы нашли путь, связывающий произвольные u и v в Ti ⋃ {ei, , em} при условии, что он существовал в Ti–1 ⋃ {ei, , em}, тем самым завершив индукционный шаг и доказав, что (2.4) является инвариантом цикла. Очевидно, что после всех i = m итераций этот инвариант цикла читается как «Ti ⋃ {ei, , em} связывает все узлы в V», но em было последним ребром, поэтому {ei+1, } является пустым множеством. Следовательно, Tm связывает все узлы в V. По конструкции Tm не может содержать циклов; любое ребро, которое приводило бы к циклу, просто не было бы включено. Поэтому после m итераций T связывает все узлы в V и является ациклическим – T является остовным деревом G. Задача 2.9. Для заданного неориентированного графа G = (V, E) связная компо- нента C = (Vc, Ec) графа G является непустым подмножеством V′ множества V (вмес - те с его ребрами) таким, что для всех пар вершин u, v ∈ V′ существует путь из u в v (который мы будем выражать как «u и v связаны»), и, более того, для всех пар вер-шин x, y, таких, что x ∈ V′ и y ∈ V – V′, x и y не связаны (то есть отсутствует путь из x в y). Мы можем сделать несколько быстрых наблюдений о связных компонентах: 1) связные компоненты любого графа содержат разбиения его реберного и вершинного множеств, поскольку связность является отношением экви-валентности; 2) для любого ребра обе его конечные точки находятся в одной компоненте, поскольку она определяет связывающий их путь; 3) для любых двух вершин в компоненте связности существует связывающий их путь. Схожим образом любые две вершины в разных компонентах не обязательно связаны; 4) для любого пути каждое содержащееся ребро находится в одной и той же компоненте. Остовной лес – это коллекция остовных деревьев, по одному для каждой связ- ной компоненты. То есть реберное множество F ⊆ E является остовным лесом G = (V, E) тогда и только тогда, когда:\n--- Страница 56 ---\nОтветы к избранным задачам  55 1) F не содержит циклов; 2) (∀u, v ∈ V ), F связывает u и v тогда и только тогда, когда u и v связаны в G. Пусть G = (V, E) равно несвязному графу. То есть G имеет более одной компо- ненты. Обозначим через Ti состояние T в алгоритме Краскала после i итераций. Пусть C = (Vc, Ec) равно компоненте графа G. В качестве доказательства того, что алгоритм Краскала приводит к остовному лесу для G, мы будем использовать сле- дующий инвариант цикла: Реберное множество Ti ⋃ {ei+1, , em} связывает все узлы в Vc. (2.4) Базовый случай явно работает; T0 ⋃ {e1, , em} = E. Каждая вершина в Vc связана в G, и в нашем распоряжении есть каждое ребро в G. Допустим, что Ti–1 ⋃ {ei, , em} связывает все узлы в Vc. Случай 1: ei нет в Ec. Очевидно, что ei не влияет на связность Vc, так как любой путь в C должен быть подмножеством Ec. Случай 2: ei ∈ Ec и Ti–1 ⋃ {ei} содержит цикл. Пусть u, v равны узлам, смежным с ei. Ti–1 не содержит цикла по конструкции, поэтому ei завершает цикл в Ti–1 ⋃ {ei}. Тем самым в Ti–1 уже есть путь (u, v), который можно использовать для замены ei в лю- бом другом пути. Следовательно, Ti–1 ⋃ {ei+1, , em} связывает все, что было связано Ti–1 ⋃ {ei, , em}, поэтому присваивание Ti = Ti–1 с «потерей доступа» к ei сохраняет инвариантность цикла. Случай 3: ei ∈ Ec и Ti–1 ⋃ {ei} не содержат цикла. Тогда Ti = Ti–1 ⋃ {ei}, поэтому Ti ⋃ {ei+1, , em} = Ti–1 ⋃ {ei, , em}, и поэтому инвариант цикла соблюдается. Посредством индукции мы показали, что инвариант цикла (2.4) соблюдается. Обратите внимание, что C было произвольной связной компонентой, поэтому Tm для каждой компоненты C = (Vc, Ec) в G, Tm связывает каждый узел в Vc. Очевидно, что если любые два узла в V не связаны в G, то T их не связывает; для этого потре- буются ребра не в E. Следовательно, Tm удовлетворяет обоим условиям, наложен- ным на упомянутый выше остовной лес. Задача 2.12. Пусть e равно любому ребру в T2 – T1. Мы должны доказать существо- вание e′ ∈ T1 – T2 такого, что (T1 ⋃ {e}) – {e′} является остовным деревом. Поскольку e ∉ T1, добавив e в T1, мы получим цикл (по лемме 2.3, которая доказана в зада- че 2.4). Цикл имеет, по крайней мере, 3 ребра (граф G имеет, по крайней мере, 3 узла, так как в противном случае он не может иметь два несовпадающих остовных дерева!). Таким образом, в этом цикле существует ребро e′ не в T2. Причина в том, что если бы каждое ребро e′ в цикле все-таки принадлежало T2, то само T2 имело бы цикл. Убрав е′, мы нарушаем цикл, но результирующий граф, (T1 ⋃ {e}) – {e′}, по-прежнему является связным и имеет размер |T1| = |T2|, то есть правильный раз- мер для дерева, поэтому он должен быть ациклическим (в противном случае мы могли бы избавиться от какого-то ребра и иметь остовное дерево меньшего раз-мера, чем Т 1 и Т2, – но все остовные деревья имеют одинаковый размер), и поэто- му (T1 ⋃ {e}) – {e′} является остовным деревом. Задача 2.13. Сначала отметим, что если мы передадим в алгоритм Краскала G с ребрами в порядке следования их индексов (то есть пропустим шаг сортиров-ки), то результирующее дерево будет включать e 1 – цикл не может образоваться первым (или вторым) ребром, поэтому e1 будет добавлен в T на первой итерации. Следовательно, с необходимостью имеется остовное дерево Т1 графа G такое, что e1 ∈ T1.\n--- Страница 57 ---\n56  Жадный алгоритм От противного допустим, что существует остовное дерево минимальной стои- мости T2 такое, что e1 ∉ T1. По лемме о замене существует ej в T2 такое, что T3 = T2 ⋃ {e1} – { ej} является остовным деревом. Но c(e1) < c(ej), поэтому c(T3) < c(T2), то есть Т2 не является остовным деревом минимальной стоимости. Мы нашли наше противоречие; не может существовать остовного дерева минимальной стоимо- сти, которое не содержит e1. Поэтому любое остовное дерево минимальной стои- мости включает e1. Задача 2.14. Пусть T равно любому остовному дереву минимальной стоимости для графа G. Переупорядочим ребра графа G по стоимостям, как и в алгоритме Краскала. Для любого блока ребер с одинаковой стоимостью поместим эти ребра, которые появляются в T, перед всеми остальными ребрами в этом блоке. Теперь докажем следующий инвариант цикла: множество ребер S, отобранных алгорит - мом с изначальным упорядочением, как описано, всегда является подмножеством T. Изначально S = ∅ ⊆ T. На индукционном шаге S ⊆ T и S′ является результатом добавления еще одного ребра в S. Если S′ = S, то делать нечего, и если S′ = S ⋃ {e}, то мы должны показать, что e ∈ T. Предположим, что это не так. Пусть T′ равно результату алгоритма Краскала, который, как мы знаем, является остовным дере-вом минимальной стоимости. По лемме о замене мы знаем, что существует е′ ∉ T′ такое, что T ⋃ {e} – { e′} является остовным деревом, и поскольку T было остовным деревом минимальной стоимости, мы знаем, что c(e′) ≤ c(e), и, следовательно, е′ было рассмотрено перед е. Так как е′ не находится в T′, оно было отклонено, по- скольку оно должно было создать цикл в S, и, следовательно, в Т – противоречие. Следовательно, S ⋃ {e} ⊆ T. Задача 2.20. Ниже приведен след алгоритма; обратите внимание, что мы моди- фицируем оптимальное решение лишь настолько, насколько это необходимо для сохранения свойства расширения. S 1 = 1000 S1 opt = 1458; S2 = 1300 S2 opt = 1358; S3 = 1305 S3 opt = 1385; S4 = 1365 S4 opt = 1365. Задача 2.21. Допустим, что после каждой итерации расписание S является пер- спективным. После финальной итерации S по-прежнему является перспектив- ным, но единственными незапланированными заданиями являются те, которые не могут расширить S на любой момент времени. Другими словами, S не может быть расширено за пределы бессодержательного переназначения «отсутствую-щей задачи» на незанятые времена; такие расширения не изменяют стоимость S, поэтому оно должно быть оптимальным. То же самое, допустим, что последнее сделанное в расписание добавление на- ходится на итерации i. До того, как было запланировано последнее задание, S i–1 было перспективным. Кроме того, это последнее задание было единственным оставшимся заданием, которое могло реально расширить S, так как ни одно из них не было запланировано. Очевидно, что прибыль, полученная от планирова-ния этого задания, является одинаковой независимо от того, когда оно заплани-\n--- Страница 58 ---\nОтветы к избранным задачам  57 ровано, поэтому каждое расширение Si–1 имеет ту же прибыль, что и Si. Задача 2.22. Поскольку S′ = S и S ′opt = Sopt, мы должны показать, что S расширяе- мо до Sopt заданиями в {i + 1, i + 2, , n}. Поскольку задание i не могло быть запла- нировано в S и Sopt расширяет S (то есть Sopt имеет все задания, которые имело S, и, возможно, больше), из этого следует, что i тоже не могло быть в Sopt, и поэтому i не было необходимо в расширении S до Sopt. Задача 2.24. Почему № 1. Для того чтобы показать, что S′opt является допус - тимым, мы должны показать, что никакое задание не запланировано дважды и никакое задание не запланировано после его предельного срока. Первое сде-лать легко, потому что S opt было допустимым. Что касается второго, то мы аргу - ментируем так: задание, которое было в момент времени t0, теперь перемещено в t1 < t0, поэтому, безусловно, если t0 было до его предельного срока, то же самое касается и t1. Задание, которое было в момент времени ti (задание i), теперь пере- несено вперед на момент времени t0, но мы работаем, исходя из допущения, что задание i было запланировано (на этот момент времени) в ячейке t0, поэтому t0 ≤ di, и, значит, мы ответили. Почему № 2. S′opt расширяет S′, потому что Sopt рас - ширяет S, и единственное различие между ними состоит в позиции t1 и t0. Они совпадают в позиции t0 (обе имеют i), поэтому нам остается только исследовать позицию t1. Но S(t1) = 0, так как Sopt(t1) = i, и S не планирует задание i вообще. Так как единственная разница между S и S′ находится в позиции t0, то из этого следует, что S′(t1) = 0, поэтому не имеет значения, каким является S′opt(t1), оно будет расширять S′. Почему № 3. Они планируют одно и то же множество заданий, поэтому они должны иметь одинаковую прибыль. Почему № 4. Предположим, t1 > t0. Так как Sopt расширяет S, из этого следует, что S(t1) = 0. Так как Sopt(t1) = i, то из этого следует, что t1 ≤ di. Но тогда алгоритм запланировал бы i в t1, а не в t0. Дело в том, что j ≠ 0 используется в последнем предложении доказательства утверждения 2.23, где мы делаем вывод о существовании противоречия из S(t2) = j ≠ Sopt(t2). Если бы j был равен 0, то вполне могло быть, что S(t2) = j = 0, но Sopt(T2) ≠ 0. Задача 2.27. При номиналах {1, 10, 25, 100} существует ряд значений, для ко- торых алгоритм 2.4 не дает оптимального решения. Рассмотрим, например, слу - чай n = 33. Алгоритм 2.4 предоставляет решение {25, 1, 1, 1, 1, 1, 1, 1, 1} (которое содержит 9 «монет»), тогда как оптимальное решение равно {10, 10, 10, 1, 1, 1} с мощностью 6. Задача 2.28. Дадим определение перспективного списка как список, который можно расширить до оптимального списка монет. Теперь покажем, что L является перспективным и инвариантом цикла. Базовый случай: изначально L является пустым, поэтому любое оптимальное решение расширяет L. Следовательно, L яв- ляется перспективным. Индукционный шаг: допустим, что L является перспек - тивным, и покажем, что L остается перспективным после еще одного исполнения цикла: предположим, что L является перспективным и s < N. Пусть L′ равно списку, который расширяет L до оптимального решения, то есть L, L′ = L opt. Пусть x равно самому крупному элементу в C такому, что s + x ≤ N. Случай (a): x ∈ L′. Тогда L′ = x, L″, благодаря чему L, x может быть расширено до оптимального решения Lopt спис - ком L″. Случай (b): x ∉ L′. Мы показываем, что этот случай невозможен. С этой целью мы доказываем следующее утверждение. Утверждение: если x ∉ L′, то существует подсписок L0 списка L′ такой, что x = сумме элементов в L0.\n--- Страница 59 ---\n58  Жадный алгоритм Доказательство утверждения: пусть B равно наименьшему числу такому, что B ≥ x, и некий подсписок L′ суммируется в число B. Пусть этот подсписок равен {e1, e2, , el}, где ei ≤ ei+1 (то есть элементы находятся в неубывающем порядке). Так как x является самой крупной монетой, которая укладывается в N – s, и сумма монет в L′ равна N – s, то получается, что каждая монета в L′ будет ≤ x. Так как el ≠ x (поскольку x ∉ L′), то из этого следует, что l > 1. Пусть D = x – ( e2 + + el). По определению B мы знаем, что D > 0. Каждое из чисел x, e2, , el делится на e1 (чтобы это увидеть, обратите внимание, что все монеты являются степенями p, то есть во множестве {1, p, p2, , pn}, и el < x, поэтому e1 < x). Следовательно D ≥ e1. С другой стороны x ≤ e1 + e2 + + el, поэтому мы также знаем, что D ≤ e1, значит, на самом деле D = e1. Поэтому x = e1 + e2 + + el, и доказательство завершено. (Конец доказа- тельства утверждения.) Таким образом, {e1, e2, , el} может быть заменено одной монетой x. Если l = 1, то x = e1 ∈ L′, что является противоречием. Если l > 1, то L, x, L′ – { e1, e2, , el} суммируется в N, но у него меньше монет, чем L, L′ = Lopt, что является противо- речием. Следовательно, случай (b) невозможен. Задача 2.29. См. алгоритм 2.6. Алгоритм 2.6. Решение задачи 2.29 w(e1) ≥ w(e2) ≥ ≥ w(em) M ← ∅ for i : 1 m do if M ⋃ {ei} не содержит двух ребер с общей вершиной then M ← M ⋃ {e i} end ifend for Задача 2.31. Пусть M opt равно оптимальному паросочетанию. Определим утверж дение «M является перспективным» как означающее, что M может быть расширено до Mopt ребрами, которые еще не рассматривались. Мы показываем, что утверж дение «M является перспективным» является инвариантом цикла на- шего алгоритма. Результат будет следовать из него (также следует, что существует уникальное максимальное паросочетание). Базовый случай: M = ∅, поэтому оно, безусловно, является перспективным. Индукционный шаг: допустим, что M яв- ляется перспективным, и пусть M′ равно M после рассмотрения ребра ei. Мы по- казываем, что ei ∈ M ′ ⇔ ei ∈ Mopt. [⇒J Допустим, что ei ∈ M′, поскольку веса не совпадают, и степени числа 2, w(ei) > åm j=i+1 w(ej) (для того чтобы увидеть, почему это справедливо, см. задачу 9.1), поэтому если только не является истинным, что ei ∈ Mopt, w(Mopt) < w, где w – это результат алгоритма. [⇐] Допустим, что ei ∈ Mopt, поэтому M ⋃ {ei} не имеет конфликта, поэтому алго- ритм его добавит.\n--- Страница 60 ---\nПримечания  59 Задача 2.32. Эта задача относится к алгоритму Дейкстры кратчайшего пути; для получения дополнительной информации см. § 24.3, стр. 658, в книге [Cormen и соавт. (2009)] и § 4.4, стр. 137, в книге [Kleinberg и Tardos (2006)]. Доказательство простое: определим S как перспективный, если для всех узлов v в S d(v) действи- тельно является кратчайшим расстоянием из s в v. Теперь нам нужно показать по индукции на числе итераций алгоритма, что выражение «S является перспектив- ным» является инвариантом цикла. Базовый случай S = {s} и d(s) = 0, поэтому он, очевидно, соблюдается. На индукционном шаге предположим, что v – это только что добавленный узел, поэтому S′ = S ⋃ {v}. Предположим, что существует более короткий путь в графе G из s в v; назовем этот путь p (то есть p – это просто после- довательность узлов, начинающаяся в s и заканчивающаяся в v). Поскольку p на- чинается внутри S (в s) и заканчивается за пределами S (в v), из этого следует, что существует ребро (a, b) такое, что a, b – это следующие друг за другом узлы на p, где а находится в S и b находится в V – S. Пусть c(p) равно стоимости пути р, и пусть d′(v) равно стоимости, которую нашел алгоритм; мы имеем c(p) < d′(v). Теперь рас - смотрим два случая: b = v и b ≠ v, и убедимся, что оба дают противоречие. Если b = v, то алгоритм использовал бы a вместо u. Если b ≠ v, то стоимость пути из s в b будет даже меньше, чем c(p), поэтому алгоритм добавил бы b вместо v. Следовательно, такого пути p не существует. 2.5. п римеЧания В любой книге по алгоритмам есть глава о жадных алгоритмах. Например, гла-ва 16 в книге [Cormen и соавт. (2009)] или глава 4 в книге [Kleinberg и Tardos (2006)]. В задаче 2.5 обсуждается сложность алгоритма Краскала, которая зависит от того, какой алгоритм сортировки используется для расстановки ребер в порядке стоимостей. Упоминается сортировка вставками (каждый элемент в списке встав-ляется в свою правильную позицию), но есть и ряд других алгоритмов сортиров-ки. Есть также сортировка выбором (найти минимальное значение, поменять его местами со значением в первой позиции и повторить), сортировка слиянием (см. раздел 3.1), пирамидальная сортировка (как и сортировка выбором, но с исполь-зованием кучи для эффективности), быстрая сортировка (выбрать элемент, распо-ложить все меньшие элементы перед ним, все более крупные элементы после него и повторять на этих двух частях – следовательно, как и сортировка слиянием, этот алгоритм относится к категории алгоритмов «разделяй и властвуй»), сортировка пузырьком (начинается вначале и сравнивает первые два элемента, и если пер-вый больше второго, меняет их местами и продолжает для каждой пары смежных элементов до конца, начинается снова с первых двух элементов, повторяя до тех пор, пока на последнем проходе не произойдет ни одной перемены мест). Есть еще ряд других вариантов. Мы также отмечаем, что существует глубокая связь между математической структурой, именуемой матроидами, и жадными алгоритмами. Матроид, также именуемый структурой независимости, выражает понятие «независимости», как и понятие независимости в линейной алгебре. Матроид M представляет собой пару (E, I), где E – это конечное множество и I – коллекция подмножеств E (именуемых независимыми множествами) со следую- щими тремя свойствами:\n--- Страница 61 ---\n60  Жадный алгоритм i) пустое множество находится в I, то есть ∅ ∈ I; ii) каждое подмножество независимого множества также независимо, то есть если x ⊆ y, то y ∈ I ⇒ x ∈ I; iii) если x и y являются двумя независимыми множествами и x имеет больше элементов, чем y, то существует элемент в x не в y, который при добавлении в y по-прежнему дает независимое множество. Это свойство называется свойством замещения независимого множества. Последнее свойство, конечно, напоминает нашу лемму о замене, лемма 2.11.Хороший способ понять смысл этого определения – думать о E как о множестве векторов (в � n) и об I как о всех подмножествах E, состоящих из линейно незави- симых векторов; проверьте, что все три свойства соблюдаются. Обзор связи между матроидами и жадными алгоритмами см. в книге [Papadi- mitriou и Steiglitz (1998)], глава 12 «Остовные деревья и матроиды». Для изучения того, какие оптимизационные задачи могут оптимально или приближенно решаться «жадными» алгоритмами, см. [Allan Borodin (2003)]. Хорошо известным алгоритмом вычисления максимального паросочетания в двудольном графе является алгоритм Хопкрофта–Карпа; см., например, книгу [Cormen и соавт. (2009)]. Этот алгоритм работает за полиномиальное время (то есть эффективно), но он не жадный – жадный подход, по-видимому, будет безуспеш-ным, как намекает раздел 2.3.2.",
      "debug": {
        "start_page": 38,
        "end_page": 61
      }
    },
    {
      "name": "Глава 3. Разделяй и властвуй 61",
      "content": "--- Страница 62 --- (продолжение)\nГлава 3 Разделяй и властвуй Si vis pacem, para bellum (Хочешь ми- ра – готовься к войне). De Re Militari [Ренатус (IV или V век нашей эры)] Divide et impera (разделяй и властвуй) – это римская военная стратегия, состоявшая в обеспечении команды по разделению большой концентрации военной мощи на части, которые сами по себе были слабее, и методичном уничтожении этих час - тей одна за другой. В этом состоит идея алгоритмов «разделяй и властвуй»: взять большую задачу, разделить ее на более мелкие части, решить эти части рекурсивно и объединить эти решения в решение целого. Парадигматическим примером алгоритма «разделяй и властвуй» является сор- тировка слиянием, где у нас есть большой список элементов для сортировки; мы разбиваем его на два меньших списка (разделяй), сортируем их рекурсивно (вла-ствуй), а затем объединяем эти два отсортированных списка в один большой от - сортированный список. Мы представим этот алгоритм в разделе 3.1. Мы также представим алгоритм «разделяй и властвуй» для умножения двоичных целых чи-сел – раздел 3.2 и алгоритм достижимости в графе – раздел 3.3. Подход «разделяй и властвуй» часто используется в ситуациях, когда есть алго- ритм грубой силы/исчерпывающего поиска, который решает задачу, но алгоритм «разделяй и властвуй» улучшает время выполнения. Это, в частности, касается двоичного целочисленного умножения. Последним примером в этой главе явля-ется алгоритм «разделяй и властвуй» достижимости (алгоритм Саввича), который минимизирует использование памяти, а не время работы. Для того чтобы проанализировать использование ресурсов (будь то время или пространство) рекурсивной процедуры, мы должны решить рекуррентные соот - ношения; см., например, книги [Rosen (2007)] или [Cormen и соавт. (2009)] для по-лучения необходимой общей информации, в частности по «основному методу» для решения рекуррентных соотношений. Мы предлагаем краткое обсуждение данной темы в разделе примечаний в конце этой главы. 3.1. сортировка слиянием Предположим, что у нас есть два списка чисел, которые уже отсортированы. То есть у нас есть список a 1 ≤ a2 ≤ ··· ≤ an и b1 ≤ b2 ≤ ··· ≤ bm. Мы хотим объединить эти два списка в один длинный отсортированный список c1 ≤ c2 ≤ ··· ≤ cn+m. Алгоритм 3.1 выполняет эту работу.\nГлава 3 Разделяй и властвуй Si vis pacem, para bellum (Хочешь ми- ра – готовься к войне). De Re Militari [Ренатус (IV или V век нашей эры)] Divide et impera (разделяй и властвуй) – это римская военная стратегия, состоявшая в обеспечении команды по разделению большой концентрации военной мощи на части, которые сами по себе были слабее, и методичном уничтожении этих час - тей одна за другой. В этом состоит идея алгоритмов «разделяй и властвуй»: взять большую задачу, разделить ее на более мелкие части, решить эти части рекурсивно и объединить эти решения в решение целого. Парадигматическим примером алгоритма «разделяй и властвуй» является сор- тировка слиянием, где у нас есть большой список элементов для сортировки; мы разбиваем его на два меньших списка (разделяй), сортируем их рекурсивно (вла-ствуй), а затем объединяем эти два отсортированных списка в один большой от - сортированный список. Мы представим этот алгоритм в разделе 3.1. Мы также представим алгоритм «разделяй и властвуй» для умножения двоичных целых чи-сел – раздел 3.2 и алгоритм достижимости в графе – раздел 3.3. Подход «разделяй и властвуй» часто используется в ситуациях, когда есть алго- ритм грубой силы/исчерпывающего поиска, который решает задачу, но алгоритм «разделяй и властвуй» улучшает время выполнения. Это, в частности, касается двоичного целочисленного умножения. Последним примером в этой главе явля-ется алгоритм «разделяй и властвуй» достижимости (алгоритм Саввича), который минимизирует использование памяти, а не время работы. Для того чтобы проанализировать использование ресурсов (будь то время или пространство) рекурсивной процедуры, мы должны решить рекуррентные соот - ношения; см., например, книги [Rosen (2007)] или [Cormen и соавт. (2009)] для по-лучения необходимой общей информации, в частности по «основному методу» для решения рекуррентных соотношений. Мы предлагаем краткое обсуждение данной темы в разделе примечаний в конце этой главы. 3.1. сортировка слиянием Предположим, что у нас есть два списка чисел, которые уже отсортированы. То есть у нас есть список a 1 ≤ a2 ≤ ··· ≤ an и b1 ≤ b2 ≤ ··· ≤ bm. Мы хотим объединить эти два списка в один длинный отсортированный список c1 ≤ c2 ≤ ··· ≤ cn+m. Алгоритм 3.1 выполняет эту работу.\n--- Страница 63 ---\n62  Разделяй и властвуй Алгоритм 3.1. Выполнить слияние двух списков Предусловие: a1 ≤ a2 ≤ ··· ≤ an и b1 ≤ b2 ≤ ··· ≤ bm p1 ← 1; p2 ← 1; i ← 1 while i ≤ n + m do if ap1 ≤ bp2 then ci ← ap1 p1 ← p1 + 1 else ci ← bp1 p2 ← p2 + 1 end if i ← i + 1 end while Постусловие: c1 ≤ c2 ≤ ··· ≤ cn+m Задача 3.1. Обратите внимание, что алгоритм 3.1 в представленном виде являет - ся неполным; например, предположим, что n < m и все элементы списка ai меньше b1. В этом случае после n-й итерации цикла while p1 = n + 1, и еще одна итерация проверяет выражение ap1 ≤ bp2, в результате чего получается ошибка «индекс за пределами границ». Модифицируйте алгоритм, чтобы исправить эту ошибку. Алгоритм сортировки слиянием сортирует заданный список чисел, сначала разделяя их на два списка соответственно длины ⌈n/2⌉ и ⌊n/2⌋, затем рекурсивно сортируя каждый список и, наконец, объединяя результаты с помощью алгорит - ма 3.1. В алгоритме 3.2 строка 1 устанавливает L равным списку входных чисел a1, a2, , an. Они являются целыми числами, не обязательно упорядоченными. Строка 2 проверяет, является ли L пустым или состоит из одного элемента; если это так, то список уже отсортирован – это та ситуация, где рекурсия «опускается», возвращая тот же самый список. В противном случае в строке 5 мы назначаем L 1 первые ⌈n/2⌉ элементов L и L2 – последние ⌊n/2⌋ элементов L. Задача 3.2. Покажите, что L = L1 ⋃ L2. Алгоритм 3.2. Сортировка слиянием Предусловие: список целых чисел a1, a2, , an 1: L ← a1, a2, , an 2: if |L| ≤ 1 then 3: return L 4: else5: L 1 ← первые ⌈n/2⌉ элементов списка L 6: L2 ← последние ⌊n/2⌋ элементов списка L 7: return Merge(Mergesort(L1), Mergesort(L2)) 8: end if Постусловие: ai1 ≤ ai2 ≤ ··· ≤ ain В разделе 9.3.6 мы покажем, как использовать теорию неподвижных точек для\n--- Страница 64 ---\nУмножение двоичных чисел  63 доказательства правильности рекурсивных алгоритмов. Для нас это останется тео- ретической демонстрацией, так как нелегко придумать наименьшую неподвиж - ную точку, которая интерпретирует рекурсию. Мы дадим естественные доказа-тельства правильности с помощью индукции. Задача 3.3. Докажите правильность алгоритма сортировки слиянием с учетом вашего решения задачи 3.1. Пусть T(n) ограничивает время работы алгоритма сортировки слиянием на спис ках длины n. Ясно, что T(n) ≤ T(⌈n/2⌉) + T(⌊n/2⌋) + cn, где cn для некоторой константы c – это стоимость слияния двух списков (алго- ритм 3.1). Более того, асимптотические границы не затрагиваются функциями округления вверх и вниз, и поэтому мы можем просто сказать, что T(n) ≤ 2 T(n/2) + cn. Следовательно, T(n) ограничена сложностью O(n log n). Задача 3.4. Реализуйте сортировку слиянием для сортировки списка слов в лек - сикографическом порядке. 3.2. У множение двоиЧных Чисел Рассмотрим пример умножения двух двоичных чисел, используя алгоритм на-чальной школы, то есть лесенкой, приведенный на рис. 3.1. 1 2345678 x 1110 y 1101 s1 1110 s2 0000 s3 1110 s4 1110 x × y10110110 Рис. 3.1  Умножьте 1110 на 1101, т. е. 14 на 13 Этот школьный алгоритм умножения очень прост. Для того чтобы умножить x на y, где x, y – это два двоичных числа, мы проходим по y справа налево; когда мы встречаем 0, то пишем строку из стольких нулей, сколько |x|, длина х. Когда мы встречаем 1, мы копируем х. Когда мы переходим к следующему биту числа у, мы сдвигаемся на одну позицию влево. В итоге мы производим знакомую форму «лесенки» – см. s 1, s2, s3, s4 на рис. 3.1 (отныне рис. 3.1 является нашим текущим примером двоичного умножения). После того как мы получим «лесенку», мы вернемся к верхней ступеньке (стро- ка s1) и к ее самому правому биту (столбец 8). Для того чтобы получить произве- дение, мы складываем все элементы в каждом столбце с помощью обычной опе-рации переноса. Например, столбец 5 содержит две единицы, поэтому мы пишем 0 в последней строке (строка x × y) и переносим 1 в столбец 4. Нетрудно заметить, что на умножение двух n-битных целых чисел требуется О(n 2) примитивных би-\n--- Страница 65 ---\n64  Разделяй и властвуй товых операций. Теперь мы представим алгоритм «разделяй и властвуй», который требует толь- ко O(nlog 3) ≈ O(n1,59) операций. Ускорение, полученное из процедуры «разделяй и властвуй», выглядит небольшим, но это улучшение действительно становится значительным, когда n вырастает до очень крупных размеров. Пусть x и y равны двум n-битным целым числам. Мы разбиваем их на два мень- ших n/2-битных целых числа следующим образом: x = (x1 · 2n/2 + x0), y = (y1 · 2n/2 + y0). Тем самым x1 и y1 соответствуют старшим битам x и y и x0 и y0 соответствуют младшим битам x и y. В терминах этих частей произведение x и y выглядит сле- дующим образом: xy = (x1 · 2n/2 + x0)(y1 · 2n/2 + y0) = x1y1 · 2n + (x1y0 + x0 y1) · 2n/2 + x0 y0. (3.1) Процедура «разделяй и властвуй» проявляется скрытно. Для того чтобы вычис - лить произведение х и y, мы рекурсивно вычисляем четыре произведения x1y1, x1y0, x0y1, x0y0, и затем мы объединяем их в (3.1) и получаем xy . Пусть T(n) равно числу операций, необходимых для вычисления произведения двух n-битных целых чисел с помощью процедуры «разделяй и властвуй», которая получается в результате (3.1). Тогда T(n) ≤ 4T(n/2) + cn, (3.2) так как мы должны вычислить четыре произведения x1 y1, x1 y0, x0 y1, x0 y0 (вот отку - да берется составляющая 4T(n/2)), а затем мы должны выполнить три сложения n-битных целых чисел (отсюда берется составляющая cn, где c – это некоторая константа). Обратите внимание, что мы не учли произведение на 2 n и 2n/2 (в (3.1)), так как они просто состоят в сдвиге двоичной строки на соответствующее число бит влево (n для 2 n и n/2 для 2n/2). Эти операции сдвига дешевы и могут игнориро- ваться при анализе сложности. Когда мы решаем стандартное рекуррентное соотношение, заданное в (3.2), мы видим, что T(n) ≤ O(nlog 4) = O(n2), поэтому кажется, что мы ничего не получили, по сравнению с процедурой грубой силы. Из (3.1) следует, что мы должны сделать четыре рекурсивных вызова; то есть нам нужно вычислить четыре умножения x1 y1, x1 y0, x0 y1, x0 y0. Но мы можем обой- тись только тремя умножениями и, следовательно, тремя рекурсивными вызова-ми: x 1 y1, x0 y0 и (x1 + x0)(y1 + y0); причина в том, что (x1 y0 + x0 y1) = (x1 + x0)(y1 + y0) – (x1 y1 + x0 y0). (3.3) См. рис. 3.2 со сравнением стоимости операций. Умножение Сложение Сдвиги Метод (3.1) 4 3 2 Метод (3.3) 3 4 2 Рис. 3. Сокращение числа умножений на одно увеличивает число сложений и вычитаний на одно – чем-то нужно пожертвовать. Но,\n--- Страница 66 ---\nАлгоритм Савича  65 поскольку умножения стоят дороже, сделка стоит того Алгоритм 3.3 реализует идею, задаваемую в (3.3). Обратите внимание, что в строках 1 и 2 алгоритма мы разбиваем x и y на две части соответственно x1, x0 и y1, y0, где x1, y1 состоят из ⌊n/2⌋ старших бит и x0, y0 со- стоят из ⌈n/2⌉ младших бит. Задача 3.5. Докажите правильность алгоритма 3.3. Алгоритм 3.3 очевидным образом требует T(n) ≤ 3T(n/2) + dn операций. Следо- вательно, его время работы составляет O(nlog 3) ≈ O(n1,59) – для того чтобы в этом убедиться, прочитайте обсуждение решения рекуррентных соотношений в раз- деле примечаний этой главы. Алгоритм 3.3. Рекурсивное двоичное умножение Предусловие: два n-битных целых числа x и y 1: if n = 1 then 2: if x = 1 ∧ y = 1 then 3: return 1 4: else 5: return 0 6: end if 7: end if8: (x 1, x0) ← (первые ⌈n/2⌉ бит, последние ⌊n/2⌋ бит) числа x 9: (y1, y0) ← (первые ⌈n/2⌉ бит, последние ⌊n/2⌋ бит) числа y 10: z1 ← Умножить(x1 + x0, y1 + y0) 11: z2 ← Умножить(x1, y1) 12: z3 ← Умножить(x0, y0) 13: return z2 · 2n + (z1 – z2 – z3) · 2⌈n/2⌉ + z3 Задача 3.6. Реализуйте алгоритм двоичного умножения. Исходите из того, что входные данные задаются в командной строке в виде двух цепочек нулей и единиц. 3.3. алгоритм савиЧа В этом разделе мы дадим решение «разделяй и властвуй» задачи достижимости в графе. Вспомните теоретико-графовые определения, которые были даны в на-чале раздела 2.1. Здесь мы будем считать, что имеем (ориентированный) граф G, и мы хотим установить, существует ли путь из узла s в узел t; обратите внимание, что мы даже не выполняем поиск кратчайшего пути (как в разделе 2.3.3 или в раз-деле 4.2); мы просто хотим знать, достижим ли узел t из узла s. В качестве изюминки по минимизации времени работы алгоритмов мы пред- ставим очень умное решение «разделяй и властвуй», которое резко сокращает объем пространства, то есть памяти. Алгоритм Савича решает ориентированную достижимость в пространстве O(log 2 n), где n – это число вершин в графе. Он за- служивает внимания, так как O(log2 n) бит памяти действительно дает очень малое пространство для графа с n вершинами! Мы исходим из того, что граф представ- лен в виде матрицы смежности размера n × n (см. стр. 29), и поэтому он занимает\n--- Страница 67 ---\n66  Разделяй и властвуй ровно n2 бит памяти, то есть «рабочей памяти», которую мы используем для реа- лизации стека. Может показаться бесполезным рекомендовать алгоритм, который занимает O(log2 n) бит пространства, когда сами входные данные требуют n2 бит. Если вход- ные данные уже занимают так много места, какая выгода в том, что требуется небольшое пространство для вычислений? Дело в том, что входные данные не обязательно должны быть представлены полностью. Вместо явного представле- ния граф может быть задан неявно. Например, «граф» G = (V, E) может быть всей Всемирной паутиной (WWW) целиком, где V – это множество всех веб-страниц (в данный момент времени), и со страницы x на страницу y имеется ребро, если в x есть гиперссылка, указывающая на y. Мы можем быть заинтересованы в существо- вании пути в WWW, и мы можем запрашивать страницы и их ссылки по частям, не сохраняя представление всего WWW в памяти. Сам размер WWW является та-ким, что может оказаться полезным знать, что нам требуется лишь столько места, сколько составляет квадрат логарифма числа веб-страниц. Кстати, мы не говорим, что алгоритм Савича является идеальным решением «задачи связности гиперссылок WWW»; мы просто приводим пример огромного графа и алгоритма, который использует очень мало рабочего пространства по от - ношению к размеру входных данных. Определим булев предикат R(G, u, v, i) как истинный тогда и только тогда, когда в G существует путь из u в v длиной не более 2 i. Ключевая идея состоит в том, что если существует путь из u в v, то любой такой путь должен иметь срединную точку w; казалось бы, тривиальное наблюдение, которое тем не менее обусловливает очень умную рекурсивную процедуру. Другими словами, существуют пути рас - стояния не более 2 i–1 из u в w и из w в v, то есть R(G, u, v, i) ⇔ (∃w)[R(G, u, w, i – 1) ∧ R(G, w, v, i – 1)]. (3.4) Алгоритм 3.4 вычисляет предикат R(G, u, v, i) на основе рекуррентного соот - ношения, указанного в (3.4). Обратите внимание, что в алгоритме 3.4 мы вычис - ляем R(G, u, v, i); рекурсивные вызовы выполняются в строке 9, где мы вычисляем R(G, u, w, i – 1) и R(G, w, v, i – 1). Алгоритм 3.4. Савич 1: if i = 0 then2: if u = v then 3: return T 4: else if (u, v) является ребром then 5: return T 6: end if 7: else8: for каждая вершина w do 9: if R(G, u, w, i – 1) и R(G, w, v, i – 1) then 10: return T 11: end if 12: end for\n--- Страница 68 ---\nДальнейшие примеры и задачи  67 13: end if 14: return F Задача 3.7. Покажите, что алгоритм 3.4 является правильным (то есть он вычис - ляет R(G, u, v, i) правильно) и требует не более i · s пространства, где s – это число бит, необходимых для учета одного узла. Сделайте вывод, что он требует O(log2 n) пространства на графе G с n узлами. Задача 3.8. Алгоритм 3.4 действительно использует очень мало места для уста- новления связности в графе. Но какова временная сложность этого алгоритма?Задача 3.9. Ваша задача – написать программу, реализующую алгоритм Савича, такую, что на каждом шаге будет выводиться содержимое стека рекурсии. Пред- положим, например, что на вход алгоритма поступает следующий граф: • 1 •2 •3 •4. Тогда стек рекурсии будет выглядеть для первых 6 шагов следующим образом: R(1, 4, 2)R(1, 4, 1) R(1, 1, 1)R(1, 4, 2)R(1, 4, 0)R(1, 1, 0)R(1, 4, 1)R(1, 1, 1)R(1, 4, 2)F T R(1, 4, 1)R(1, 1, 1)R(1, 4, 2)R(2, 4, 0)R(1, 2, 0)R(1, 4, 1)R(1, 1, 1)R(1, 4, 2)F T R(1, 4, 1)R(1, 1, 1)R(1, 4, 2) Шаг 1 Шаг 2 Шаг 3 Шаг 4 Шаг 5 Шаг 6 3.4. дальнейшие примеры и зада Чи 3.4.1. Расширенный алгоритм Евклида Мы возвращаемся к старому другу из раздела 1.1, а именно к расширенному ал- горитму Евклида – см. задачу 1.9 и соответствующее решение на стр. 31, содер-жащее алгоритм 1.8. Мы представим рекурсивную версию как алгоритм 3.5, где этот алгоритм возвращает три значения, и, следовательно, мы используем форму записи (x, y, z) ← (x′, y′, z′) в качестве удобного сокращения для x ← x′, y ← y′ и z ← z′. Обратите внимание на интересное сходство между алгоритмом 1.8 и алгоритмом гауссовой редукции решетки 7.3. Задача 3.10. Покажите, что алгоритм 3.5 работает правильно. Алгоритм 3.5. Расширенный алгоритм Евклида (рекурсивный) Предусловие: m > 0, n ≥ 0 1: a ← m; b ← n 2: if b = 0 then3: return (a, 1, 0) 4: else5: (d, x, y) ← Euclid(b, rem(a, b)) 6: return (d, y, x – div(a, b) · y) 7: end if Постусловие: mx + ny = d = gcd(m, n)\n--- Страница 69 ---\n68  Разделяй и властвуй Задача 3.11. Реализуйте расширенный алгоритм Евклида (алгоритм 3.5). Исхо- дите из того, что входные данные заданы в командной строке в виде двух целых чисел. 3.4.2. Быстрая сортировка Быстрая сортировка является широко применяемым алгоритмом сортировки. Он был разработан в конце 1950-х годов T. Хоаром1. Быстрая сортировка легко опре- деляется: для того чтобы отсортировать элементы списка I, следует выбрать один элемент х из I (назовем этот элемент опорным) и создать два новых списка, S и L: это все те элементы, которые меньше или равны опорному, S, и все те элементы, которые больше опорного, L. Теперь рекурсивно отсортировать S и L, создав S′ и L′, и новый отсортированный список I ′ задается членами S ′, х, L′. Интересно отметить, что быструю сортировку можно легко реализовать на функциональном языке, так как он работает со списками и она естественным образом будет являться рекурсивной функцией. Например, быстрая сортировка может быть реализована на языке Haskell в нескольких строках кода следующим образом: qsort [] = [] qsort (x:xs) = qsort smaller ++ [x] ++ qsort larger where smaller = [a | a <- xs, a <= x] larger = [b | b <- xs, b > x] Обратите внимание, что в этой реализации (см. стр. 10 книги [Hutton (2007)]) в качестве опоры мы выбрали первый элемент списка; существует рандомизиро- ванная версия быстрой сортировки, где опорный элемент выбирается из списка случайно. Задача 3.12. Реализуйте быструю сортировку и проанализируйте ее сложность. Для сложности укажите время выполнения в худшем и в среднем случаях. 3.4.3. Команда git bisect Git – это широко используемая программа для управления версиями компьютер- ных файлов, а также для координации сотрудничества групп людей, работающих над большим программным проектом 2. На самом деле решения задач програм- мирования, содержащиеся в этой книге, а также реализации всех алгоритмов под-держиваются в общедоступном репозитории Git на GitHub (веб-репозитории Git): https://github.com /michaelsoltys/IAA-Code. Как объясняется в документации Git, команда git bisect использует алгоритм бинарного поиска для отыскания фиксации (коммита) в истории проекта, кото- 1 Это тот же Хоар, который уже цитировался на стр. 10; напомним также, что на стр. 13 мы ввели логику Хоара как механизм доказательства правильности алгоритма и про-граммы. 2 «Программирование» понимается здесь в широком смысле, так как оно может означать что угодно, от работы над ядром Linux до разработки веб-сайтов и до сотрудничества LaTeX. См. https://git-scm.com для получения дополнительной информации.\n--- Страница 70 ---\nОтветы к избранным задачам  69 рая внесла ошибку. Для того чтобы обратить эту команду вспять, пользователь задает «плохую» фиксацию с заранее известной ошибкой и «хорошую» фикса-цию, о которой известно, что она существовала до внесения ошибки. Затем ко-манда git bisect выбирает фиксацию между этими двумя конечными точками и спрашивает, является выбранная фиксация «хорошей» или «плохой». Она про- должает сужать диапазон до тех пор, пока не найдет точную фиксацию, которая внесла изменение. По сути дела, команду git bisect можно использовать для поиска фиксации, ко- торая изменила любое свойство проекта; например, фиксацию, которая исправи-ла ошибку, или фиксацию, которая вызвала улучшение результативности эталон-ных тестов. Для того чтобы поддержать это более общее использование, термины «старый» и «новый» могут применяться вместо терминов «хороший» и «плохой», или могут использоваться любые другие термины. 3.5. ответы к избранным зада Чам Задача 3.1. Задача возникает только тогда, когда p1 > n или p2 > m. Мы можем изменить условие цикла while на p1 ≤ n ∧ p2 ≤ m. Конечно, это означает, что цикл while завершится рано, когда один входной список не будет полностью учтен в C = {c 1, c2, }. В связи с этим после первого цикла должен быть добавлен еще один цикл. Если p1 ≤ n, то он должен назначить оставшиеся элементы из ap1, , an остальным переменным в C; в противном случае p2 ≤ m, поэтому bp2, , bm должны быть переданы остатку С. Более элегантное решение становится доступным, если мы потребуем, чтобы элементы каждого списка были конечными. Перед началом цикла while мы можем просто добавить в конец каждого списка бесконечно большой элемент; ясно, что он никогда не будет оценен как меньший, чем конечное значение, или равный ему в противоположном списке, поэтому он никогда не будет назначен элементу C . Задача 3.2. Для этого достаточно показать, что ⌈n/2⌉ + ⌊n/2⌋ = n. Если n является четным, то ⌈n/2⌉ = ⌊n/2⌋ = n/2 и n/2 + n/2 = n. Если n является нечетным, то n = 2k + 1 и поэтому ⌈n/2⌉ = k + 1, тогда как ⌊n/2⌋ = k и (k + 1) + k = 2k + 1 = n. Задача 3.3. Мы должны показать, что для списка целых чисел L = a 1, a2, , an алгоритм возвращает список L′, который состоит из чисел в L в неубывающем по- рядке. Рекурсия сама по себе свидетельствует о правильной индукции; мы ис - пользуем принцип полной индукции (см. стр. 210). Если |L| = 1, то L′ = L, и доказа- тельство завершено. В противном случае |L| = n > 1, и мы получаем два списка L1 и L2 (с длинами ⌈n/2⌉ и n – ⌈n/2⌉), которые, по индукционной гипотезе, возвраща- ются упорядоченными. Теперь осталось доказать правильность процедуры слия-ния, алгоритм 3.1, что также можно сделать по индукции. Задача 3.5. Очевидно, что базовый случай правилен; с учетом двух 1-битных целых числа, если оба числа не равны 1, то, по крайней мере, одно из них равно 0, поэтому произведение равно 0. Предположим, что алгоритм правилен для всех n < n′. Тогда умножения для на- хождения z 1, z2 и z3 являются правильными. Поэтому уравнения (3.1) и (3.3) обес - печивают индуктивное доказательство. Задача 3.8. O(2log 2 n) = O(nlog n), поэтому временная сложность алгоритма Савича сверхполиномиальна и поэтому не очень хороша.\n--- Страница 71 ---\n70  Разделяй и властвуй Задача 3.10. Прежде всего обратите внимание на то, что второй параметр уменьшается при каждом рекурсивном вызове, но по определению остатка он является неотрицательным. Таким образом, по принципу наименьшего числа ал-горитм завершается. Мы доказываем частичную правильность по индукции на значении второго аргумента. В базовом случае n = 0, поэтому в строке 1 b ← n = 0, поэтому в строке 2 b = 0, алгоритм завершается в строке 3 и возвращает (a, 1, 0) = (m, 1, 0), поэтому mx + ny = m · 1 + n · 0 = m, и доказательство завершено. На индукционном шаге мы исходим из того, что рекурсивная процедура воз- вращает правильные значения для всех пар аргументов, где второй аргумент < n (таким образом мы делаем полную индукцию). Из строк 1 и 5 мы имеем: (d, x, y) ← Extended-Euclid(b, rem(a, b)) = Extended-Euclid(n, rem(m, n)). Обратите внимание, что 0 ≤ rem(m, n) < n, и поэтому мы можем применить ин- дукционную гипотезу, и у нас есть: n · x + rem(m, n) · y = d = gcd(n, rem(m, n)). Сначала отметим, что в задаче 1.6 мы имеем, что d = gcd(m, n). Теперь мы рабо- таем над левой частью уравнения. У нас есть: n · x + rem(m, n) · y = n · x + (m – div(m, n) · n) · y = m · y + n · (x – div(m, n) · y) = m · y + n · (x – div(a, b) · y), и доказательство завершено, так как это то, что возвращается в строке 6. 3.6. п римеЧания Для получения полного обсуждения сортировки слиянием и двоичного умноже- ния см. соответственно § 5.1 и § 5.5 в книге [Kleinberg и Tardos (2006)]. Сортировка слиянием имеет интересную историю (подробнее см. главу 3 «сортировка» в кни-ге [Christian и Griffiths (2016)]): в 1945 году Джон фон Нейманн написал програм-му, демонстрирующую мощь компьютера с хранимой программой; поскольку он был гением, программа не только иллюстрировала парадигму хранимой про-граммы, но и представила новый способ сортировки: Mergesort. См. [Katajainen и Traff (1997)], где данный алгоритм изучается во всех подробностях. Для обсуждения анализа рекурсивных алгоритмов см. раздел 9.3.6.Для получения дополнительной информации об алгоритме Савича (раздел 3.3) см. теорему 7.5 в работе [Papadimitriou (1994)], § 8.1 в книге [Sipser (2006)] или тео- рему 2.7 в работе [Kozen (2006)]. Задача достижимости широко распространена в информатике. Предположим, что у нас есть граф G с n вершинами. В разделе 2.3.3 мы представили алгоритм О(n 2), жадный по времени для задачи достижимости, обусловленный Дейкстрой. В этой главе, в разделе 3.3, мы представили алгоритм «разделяй и властвуй», ко-торый требует О(log 2 n) пространства, обусловленный Савичем. В разделе 4.2 мы представим алгоритм динамического программирования, который вычисляет кратчайший путь для всех пар узлов в графе – он обусловлен Флойдом и занимает\n--- Страница 72 ---\nПримечания  71 время O(n3). В подразделе 4.2.1 представлен еще один динамический алгоритм Беллмана и Форда (который может справляться с ребрами отрицательного веса). В 2005 году Рейнгольд показал, что неориентированная достижимость может быть вычислена в пространстве O(log n); см. [Reingold (2005)] с описанием этого замеча- тельного, но трудного результата. Обратите внимание, что алгоритм Рейнгольда работает только для неориентированных графов. См. главу 7 в книге [Rosen (2007)], где приводится введение в решение рекур- рентных соотношений, и § 4.5, стр. 93–103, в книге [Cormen и соавт. (2009)], где дается очень тщательное изложение «основного метода» для решения рекуррент - ных соотношений. Здесь мы включим очень краткое обсуждение; мы хотим ре-шать рекуррентные соотношения следующего вида: T(n) = aT (n/b) + f(n), (3.5) где a ≥ 1 и b > 1 – это константы, f(n) – асимптотически положительная функция – имея в виду, что существует n 0 такой, что f(n) > 0 для всех n ≥ n0. Для решения такого рекуррентного соотношения существует три случая. Случай 1: f(n) = O(nlogb a-ε) для некой константы ε > 0; в этом случае мы имеем T(n) = Θ(nlogb a). Случай 2: f(n) = Θ(nlogb a logk n) с k ≥ 0; в этом случае мы имеем T(n) = Θ(nlogb a logk+1 n). Наконец, случай 3: f(n) = Ω(nlogb a+ε) с ε > 0, и f(n) удовлетворяет условию регуляр- ности, а именно что af(n/b) ≤ cf(n) для некой константы с < 1 и всех достаточно больших n; в этом случае T(n) = Θ(f(n)). Например, рекуррентное соотношение, которое появляется при анализе сорти- ровки слиянием, равно T(n) = 2T(n/2) + cn, поэтому a = 2 и b = 2, и поэтому logb a = log2 2 = 1, и, значит, мы можем сказать, что f(n) = Θ(nlogb a logk n) = Θ(n log n), то есть k = 1 в случае 2, и, значит, T(n) = Θ(n log n), как было отмечено в анализе.",
      "debug": {
        "start_page": 62,
        "end_page": 72
      }
    },
    {
      "name": "Глава 4. Динамическое программирование 72",
      "content": "--- Страница 73 --- (продолжение)\nГлава 4 Динамическое программирование Не помнящий прошлого обречен его повторять. Джордж Сантайяна (George Santayana) Динамическое программирование – это алгоритмический метод, тесно связан-ный с подходом «разделяй и властвуй», который мы видели в предыдущей главе. Однако, в то время как подход «разделяй и властвуй», по существу, рекурсивен, и поэтому продвигается «сверху вниз», динамическое программирование рабо-тает «снизу вверх». Алгоритм динамического программирования создает массив связанных, но более простых подзадач, а затем вычисляет решение большой сложной задачи, используя решения более простых подзадач, которые хранятся в массиве. Обычно мы хотим максимизировать прибыль или минимизировать стоимость. Существует три шага в поиске решения задачи динамического программирова- ния: (i) определить класс подзадач, (ii) дать регуррентное соотношение на основе решения каждой подзадачи в терминах более простых подзадач и (iii) дать алго-ритм вычисления рекуррентного соотношения. 4.1. з адаЧа о наибольшей монотонной подпоследовательности Вход: d, a1, a2, , ad ∈ �. Выход: L = длина самой длинной монотонной неубывающей подпоследователь- ности. Обратите внимание, что элементы подпоследовательности не обязательно должны располагаться друг за другом подряд, то есть ai1, ai2, , aik – это монотонная подпоследовательность, при условии что 1 ≤ i1 < i2 < < ik ≤ d, ai1 ≤ ai2 ≤ ≤ aik. Например, длина наибольшей монотонной подпоследовательности {4, 6, 5, 9,1} равна 3.\nГлава 4 Динамическое программирование Не помнящий прошлого обречен его повторять. Джордж Сантайяна (George Santayana) Динамическое программирование – это алгоритмический метод, тесно связан-ный с подходом «разделяй и властвуй», который мы видели в предыдущей главе. Однако, в то время как подход «разделяй и властвуй», по существу, рекурсивен, и поэтому продвигается «сверху вниз», динамическое программирование рабо-тает «снизу вверх». Алгоритм динамического программирования создает массив связанных, но более простых подзадач, а затем вычисляет решение большой сложной задачи, используя решения более простых подзадач, которые хранятся в массиве. Обычно мы хотим максимизировать прибыль или минимизировать стоимость. Существует три шага в поиске решения задачи динамического программирова- ния: (i) определить класс подзадач, (ii) дать регуррентное соотношение на основе решения каждой подзадачи в терминах более простых подзадач и (iii) дать алго-ритм вычисления рекуррентного соотношения. 4.1. з адаЧа о наибольшей монотонной подпоследовательности Вход: d, a1, a2, , ad ∈ �. Выход: L = длина самой длинной монотонной неубывающей подпоследователь- ности. Обратите внимание, что элементы подпоследовательности не обязательно должны располагаться друг за другом подряд, то есть ai1, ai2, , aik – это монотонная подпоследовательность, при условии что 1 ≤ i1 < i2 < < ik ≤ d, ai1 ≤ ai2 ≤ ≤ aik. Например, длина наибольшей монотонной подпоследовательности {4, 6, 5, 9,1} равна 3.\n--- Страница 74 ---\nЗадача кратчайшего пути для всех пар  73 Сначала определим массив подзадач: R(j) = длина самой длинной монотонной подпоследовательности, которая заканчивается в aj. Ответ может быть извлечен из массива R путем вычисления L = max1≤j≤n R(j). Следующий шаг – найти рекуррентное соотношение. Пусть R(1) = 1, и для j > 1 R(j) = � 1, если ai > aj для всех 1 ≤ i < j 1 + max1≤i<j {R(i)|ai ≤ aj} в противном случае. Мы завершим написанием алгоритма, который вычисляет R; см. алгоритм 4.1. Алгоритм 4.1. Наибольшая монотонная подпоследовательность R(1) ← 1 for j : 2 d do max ← 0 for i : 1 j – 1 do if R(i ) > max и ai ≤ aj then max ← R(i ) end if end for R(j) ← max + 1 end for Задача 4.1. После того как мы вычислили все значения массива R, как построить фактическую монотонную неубывающую подпоследовательность длины L? Задача 4.2. Каковы были бы соответствующие пред- и постусловия приведенных выше алгоритмов? Докажите правильность с приемлемым инвариантом цикла.Задача 4.3. Рассмотрите следующий вариант задачи о наибольшей монотонной подпоследовательности. Вход равен d, a 1, a2, , ad ∈ �, но выход равен длине самой длинной подпоследовательности a1, a2, , ad, где любые два следующих подряд члена подпоследовательности отличаются не более чем на 1. Например, наиболь- шая такая подпоследовательность последовательности {7, 6, 1, 4, 7, 8, 20} равна {7, 6, 7, 8}, поэтому в данном случае ответ будет 4. Дайте решение методом дина-мического программирования. Задачи 4.4. Реализуйте алгоритм 4.1; ваша программа должна принимать допол- нительный шаговый параметр, назовем его s, где, как и в задаче 4.3, любые два следующих подряд элемента подпоследовательности отличаются не более чем на S, то есть |a ij – aij+1| ≤ s, для любого 1 ≤ j < k. 4.2. з адаЧа крат Чайшего пУти для всех пар Вход: ориентированный граф G = (V, E), V = {1, 2, …, n}, функция стоимости C(i, j) ∈ �+ ⋃ {∞}, 1 ≤ i, j ≤ n, C(i, j) = ∞ если (i, j) не является ребром. Выход: массив D, где d(i, j) – это длина кратчайшего ориентированного пути из i в j. Напомним, что мы определили неориентированные графы в разделе 2.1; ори- ентированный граф (или орграф) – это граф, в котором ребра имеют направление, то есть ребра являются стрелками. Также напомним, что в разделе 2.3.3 мы дали\n--- Страница 75 ---\n74  Динамическое программирование жадный алгоритм для вычисления кратчайших путей из обозначенного узла s во все узлы в (неориентированном) графе. Задача 4.5. Постройте семейство графов {Gn}, где Gn имеет O(n) узлов и экспонен- циально много путей, то есть Ω(2n) путей. Тем самым сделайте вывод, что исчер- пывающий поиск не является возможным решением «задачи кратчайшего пути для всех пар». Определим массив подзадач: пусть А(k, i, j) равно длине кратчайшего пути из i в j такого, что все промежуточные узлы на пути находятся в {1, 2, …, k}. Тогда А(n, i, j) = D(i, j) будет решением. Условно, если k = 0, то [k] = {1, 2, , k} = 0. Определим рекуррентное соотношение: сначала инициализируем массив для k = 0, A(0, i, j) = C(i, j). Теперь мы хотим вычислить А(k, i, j) для k > 0. Проектируя рекуррентное соотношение, обратите внимание, что кратчайший путь между i и j либо включает k, либо его не включает. Допустим, что мы знаем A(k – 1, r, s) для всех r, s. Предположим, узел k не включен. Тогда очевидно, что А(k, i, j) = A(k – 1, i, j). Если, с другой стороны, узел k встречается на кратчайшем пути, то он встречается ровно один раз, поэтому А(k, i, j) = A(k – 1, i, k) + A(k – 1, k, j). Следовательно, длина кратчайшего пути получается, беря минимум из этих двух случаев: А(k, i, j) = min{A(k – 1, i, j), A(k – 1, i, k) + A(k – 1, k, j)}. Напишем алгоритм: оказывается, что нам нужно пространство только для двумерного массива B(i, j) = А(k, i, j), потому что для вычисления A(k, ∗, ∗) из A(k – 1, ∗, ∗) мы можем перезаписать A(k – 1, ∗, ∗). Нашим решением является алгоритм 4.2, именуемый алгоритмом Флойда (или алгоритмом Флойда–Уоршелла). Примечательно, что он выполняется за время O(n 3), где n – это число вершин, тогда как в таком графе может быть до O(n2) ребер. В строках 1–5 мы инициализируем массив B, то есть устанавливаем его равным C. Обратите внимание, что перед исполнением строки 6 имеет место, что b(i, j) = A(k – 1, i, j) для всех i, j. Алгоритм 4.2. Флойд 1: for i : 1 n do 2: for j : 1 n do 3: B(i, j) ← C(i, j) 4: end for 5: end for6: for k : 1 n do 7: for i : 1 n do 8: for j : 1 n do 9: B(i, j) ← min{B(i, j), B(i, k) + B(k, j)} 10: end for 11: end for 12: end for13: return D ← B Задача 4.6. Почему работает метод перезаписи в алгоритме 4.2? Опасение вызва- но тем, что B(i, k) или B(k, j), возможно, уже были обновлены (если k < j или k < i).\n--- Страница 76 ---\nПростая задача о рюкзаке  75 Однако перезапись работает; объясните, почему. Мы могли бы избежать трехмер- ного массива, вместо него храня два двумерных массива, и тогда перезапись не была бы проблемой вообще; как это будет работать? Задача 4.7. Каковы приемлемые предусловия и постусловия в алгоритме 4.2? Что такое приемлемый инвариант цикла?Задача 4.8. Реализуйте алгоритм Флойда, используя двумерный массив и метод перезаписи. 4.2.1. Алгоритм Беллмана–Форда Предположим, что мы хотим найти кратчайший путь из s в t в ориентирован- ном графе G = (V, E), где ребра имеют неотрицательные стоимости. Пусть Opt (i, v) обозначает минимальную стоимость i-членного пути из v в t, где i-членный путь – это путь, который использует не более i ребер. Пусть p равно оптималь- ному i-членному пути со стоимостью Opt(i, v); если такой p не существует, то мы условно договариваемся, что Opt (i, v) = ∞. Если р использует i – 1 ребер, то Opt(i, v) = Opt(i – 1, v), и если p использует i ребер, и первое ребро равно (v, w) ∈ E, тогда Opt(i, v) = c(v, w) + Opt(i – 1, w), где с(v, w) – это стоимость ребра (v, w). В результате получаем рекурсивную формулу для i > 0: Opt(i, v) = min{Opt (i – 1, v), minw∈V {c(v, w) + Opt(i – 1, w)}}. Задача 4.9. Реализуйте алгоритм Беллмана–Форда. 4.3. п ростая зада Ча о рюкзаке Вход: w1, w2, , wd, C ∈ �, где C – это грузоподъемность рюкзака (ранца). Выход: maxS {K(S )|K(S ) ≤ C }, где S ⊆ [d ] и K(S ) = åi∈S wi. Данная задача является NP-трудной1. Это означает, что мы ожидаемо не смо- жем найти алгоритм полиномиального времени, который работает в общем слу - чае. Мы даем решение методом динамического программирования, которое ра- ботает для относительно небольшого C; отметим, что, для того чтобы наш метод работал со входами w1, , wd, C должно быть (неотрицательными) целыми числа- ми. Название «простая задача о рюкзаке» нередко упоминается под аббревиату - рой SKS (simple knapsack problem). Определим массив подзадач: рассмотрим первые i весов (то есть [i ]), сумми- рующих вплоть до промежуточного весового предела j. Определим булев массив R следующим образом: R(i, j) = � T, если ∃S ⊆ [i ] такой, что K(S ) = j F, в противном случае 1 NP – это класс задач, решаемых за полиномиальное время на недетерминированной ма- шине Тьюринга. Задача P является NP-трудной, если каждая задача в NP сводима к P за полиномиальное время, то есть каждая задача в NP может быть эффективно переформу - лирована в терминах P . Когда задача NP-трудна, это указывает на то, что она, вероятно, неразрешима, то есть она не может быть решена эффективно в общем случае. Для полу - чения дополнительной информации см. любую книгу по теме вычислительной сложно-сти, например [Papadimitriou (1994); Sipser (2006); Soltys (2009)].\n--- Страница 77 ---\n76  Динамическое программирование для 0 ≤ i ≤ d и 0 ≤ j ≤ C. После вычисления всех значений R мы можем получить решение M следующим образом: M = maxj≤C {j|R(d, j) = T}. Определим рекуррентное соотношение: мы инициализируем R(0, j) = F для j = 1, 2, , C, и R(i, 0) = T для i = 0, 1, , d. Теперь мы определим рекуррентное соотношение для вычисления R, для i, j > 0, таким образом, что оно будет зависеть от того, включим мы объект i в рюкзак или нет. Предположим, что мы не включаем объект i. Тогда очевидно, что R(i, j) = T тогда и только тогда, когда R(i –1, j) = T. Предположим, с другой стороны, что объ- ект i включен. Тогда должно иметь место, что R(i, j) = T тогда и только тогда, когда R(i – 1, j – wi) = T и j – wi ≥ 0, то есть существует подмножество S ⊆ [i – 1] такое, что K(S) в точности равно j – wi (и в этом случае j ≥ wi). Складывая все это вместе, мы получаем следующее рекуррентное соотношение для i, j > 0: R(i, j) = T ⇔ R(i – 1, j) = T ∨ ( j ≥ wi ∧ R(i – 1, j – wi ) = T). (4.1) Рисунок 4.1 резюмирует вычисление рекуррентного соотношения. Наконец, мы проектируем алгоритм 4.3, который использует тот же хитроум- ный прием экономии пространства, что и в алгоритме 4.2; он использует одно-мерный массив S(j) для отслеживания двумерного массива R(i, j). Это делается путем перезаписи R(i, j) с помощью R(i + 1, j ). В алгоритме 4.3 в строке 1 мы инициализируем массив для i = j = 0. В строках 2–4 мы инициализируем массив для i = 0 и j ∈ {1, 2, , C}. Обратите внимание, что пос - ле каждого исполнения i-членного цикла (строка 5) имеет место, что s(j) = R(i, j) для всех j. R 0 … j – wi… j … c 0 T F…F F F…F F F…F F T T i – 1 T c b i T a T T d T Рис. 4.1  Рекуррентное соотношение, задаваемое равенством (4.1), можно интерпретировать следующим образом: мы выставляем T в клетку с надписью а тогда и только тогда, когда удовлетворяется хотя бы одно из следующих двух условий: в позиции прямо над ней имеется Т, то есть в клетке с надписью b (если мы можем постро- ить j с первыми i – 1 весами, то, безусловно, мы можем построить j с первыми i весами), либо в клетке с надписью с имеется Т (если мы можем построить j – wi с первыми i – 1 весами, то, безусловно, мы мо- жем построить j с первыми i весами). Также обратите внимание, что для заполнения клетки, помеченной буквой a, нам нужно смотреть только на две клетки, и ни одна из этих клеток не находится справа; это будет важно при проектировании алгоритма (алгоритма 4.3)\n--- Страница 78 ---\nПростая задача о рюкзаке  77 Задача 4.10. Для отслеживания двумерного массива мы используем одномерный массив, но перезапись не является проблемой; объясните, почему. Задача 4.11. Логическое утверждение S(j) = R(i, j) может быть доказано по индук - ции на числе раз, которое исполняется i-членным циклом в алгоритме 4.3. Из это- го логического утверждения следует, что после завершения алгоритма S(j) = R(d, j) для всех j. Докажите это формально, предоставив пред- и постусловия, инвариант цикла и стандартное доказательство правильности.Задача 4.12. Постройте входные данные, для которых алгоритм 4.3 допустил бы ошибку, если бы внутренний цикл «for уменьшая j : C 1 do» (строка 6) был заме- нен на «для j : 1 С».Задача 4.13. Реализуйте алгоритм 4.3. Алгоритм 4.3 является хорошей иллюстрацией мощной идеи детализации про- граммы. Начнем с идеи вычисления R(i, j) для всех i, j. Затем мы понимаем, что нам действительно нужно только две строки массива в памяти; для того чтобы вычислить строку i, нам нужно только найти строку i – 1. Затем мы развиваем эту идею дальше и видим, что, обновляя строку массива i справа налево, нам вообще не требуется строка i – 1, – мы можем сделать это прямо на месте. Начиная с на- дежной идеи и последовательно ее обрезая, мы получаем гладкое решение. Алгоритм 4.3. Простая задача о рюкзаке 1: S(0) ← T 2: for j : 1 C do 3: S(j) ← F 4: end for5: for i : 1 d do 6: for уменьшая j : C 1 do 7: if (j ≥ w i и S( j – wi ) = T) then 8: S(j) ← T 9: end if 10: end for 11: end for Но насколько хорошим является наше решение методом динамического про- граммирования с точки зрения сложности задачи? То есть сколько шагов требует - ся для вычисления решения пропорционально размеру входных данных? Мы долж - ны построить таблицу размера d × C и ее заполнить, поэтому временнáя сложность нашего решения равна O(d · C). На первый взгляд это кажется приемлемым, но во введении к этому разделу мы говорили, что простая задача о рюкзаке является NP-трудной; что же делать? Дело в том, что изначально исходят из того, что входные данные заданы в двоичном виде, и для кодирования С в двоичном виде нам потребуется только log C бит, поэтому число столбцов (С ) на самом деле экспоненциально зависит от размера входа (C = 2 log C). С другой стороны, d – это число весов, и поскольку эти веса должны быть каким-то образом перечислены, размер списка весов, безус -\n--- Страница 79 ---\n78  Динамическое программирование ловно, больше, чем d (то есть этот список не может быть закодирован – в общем случае – с использованием log d бит; он требует, по крайней мере, d бит). Мы можем сказать только то, что если C имеет размер O(dk) для некой констан- ты k, то наше решение методом динамического программирования работает за полиномиальное время в размере входных данных. Другими словами, у нас есть эффективное решение для «малых» значений C. Говоря по-другому, до тех пор, пока |C| (размер двоичного кодирования C) равен O(log d), наше решение работает за полиномиальное время. Задача 4.14. Покажите, как построить фактическое оптимальное множество ве- сов после вычисления R.Задача 4.15. Определите «естественный» жадный алгоритм решения простой за- дачи о рюкзаке; пусть M равно выходу этого алгоритма, а M равно выходу реше- ния методом динамического программирования, приведенного в этом разделе. Покажите, что либо M = M, либо M > – 1 2С. Задача 4.15 скрытно вводит понятие аппроксимационных алгоритмов. Как было упомянуто в начале этого раздела (см. сноску на стр. 75), простая задача о рюкзаке является примером NP-трудной задачи, задачи, для которой по нашим подозрениям в общем случае не может быть эффективного решения. То есть боль-шинство экспертов считает, что любой алгоритм, пытающийся решить простую задачу о рюкзаке в общем случае – на бесконечно большом числе входов, будет занимать чрезмерное число шагов (то есть время) для получения решения. Один из возможных компромиссов заключается в разработке эффективного алгоритма, не дающего оптимального решения – которого, возможно, даже не потребуется – и дающего только решение с некой гарантией в его близости к оп-тимальному решению. Таким образом, мы просто аппроксимируем оптимальное решение, но, по крайней мере, наш алгоритм работает быстро. Исследование та-ких компромиссов осуществляется с помощью аппроксимационных алгоритмов. Наконец, в приведенном ниже разделе мы даем жадное решение простой за- дачи о рюкзаке в частном случае, когда веса имеют определенное «возрастающее свойство». Оно является примером перспективной задачи, где мы можем ожидать соблюдения какого-то удобного условия во входных данных; условия, которое нам не нужно проверять, но которое допускается как имеющееся. Обратите внимание, что мы использовали термин «перспективный» для доказательства правильности жадных алгоритмов – это другое понятие, чем «перспективная задача». 4.3.1. Задача о рассредоточенном рюкзаке Вход: w1, , wd, C ∈ �, такие, что wi ≥ åd j=i+1 для i = 1, , d – 1. Вывод: Smax ⊆ [d ], где K(Smax) = max { K(S)|K(S ) ≤ C}. Задача 4.16. Дайте «естественный» жадный алгоритм, который решает задачу о рассредоточенном рюкзаке, заполняя пробелы в алгоритме 4.4. Задача 4.17. Дайте определение того, что означает быть «перспективным» для промежуточного решения S в алгоритме 4.4. Покажите, что из инварианта цикла «S является перспективным» следует, что жадный алгоритм дает оптимальное ре- шение. Наконец, покажите, что выражение «S является перспективным» является инвариантом цикла.S⊆[d ]\n--- Страница 80 ---\nЗадача выбора мероприятий  79 Алгоритм 4.4. Рассредоточенный рюкзак S ← ∅ for i : 1 d do if ______________________ then ______________________ end if end for 4.3.2. Общая задача о рюкзаке Вход: w1, w2, , wd, v1, , vd, C ∈ �. Выход: max{V(S )|K(S ) ≤ C }, K(S) = åi∉S wi, V(S) = åi∉S vi. Таким образом, общая задача о рюкзаке имеет положительное целочисленное зна-чение v i, помимо каждого веса wi, и цель заключается в том, чтобы получить как мож - но более ценный рюкзак, без превышения С , то есть грузоподъемности рюкзака. Точнее, V(S) = åi∉S vi – это суммарное значение множества S весов. Цель состоит в том, чтобы максимизировать V(S) с учетом ограничения, что K(S), которое яв- ляется суммой весов в S, не превышает C. Обратите внимание, что простая задача о рюкзаке является частным случаем общей задачи о рюкзаке, где vi = wi для всех 1 ≤ i ≤ d. Для того чтобы решить общую задачу о рюкзаке, мы начнем с вычисления того же булева массива R(i, j), который использовался для решения простой задачи о рюкзаке. Следовательно, R(i, j) игнорирует значения vi и зависит только от весов wi. Далее мы определим еще один массив V(i, j), который зависит от значений vi следующим образом: V(i, j) = max{V(S )|S ⊆ [i ] и K(S ) = j}, (4.2) для 0 ≤ i ≤ d и 0 ≤ i ≤ C. Задача 4.18. Дайте рекуррентное соотношение для вычисления массива V(i, j), используя булев массив R(i, j), – будем считать, что массив R(i, j) уже вычислен. Также дайте алгоритм вычисления V(i, j). Задача 4.19. Если определение V(i, j), данное в (4.2), изменяется, в результате чего нам требуется только K(S) ≤ j вместо K(S) = j, то булев массив R(i, j) в рекуррентном соотношении не нужен. Дайте рекуррентное соотношение в этом случае. 4.4. з адаЧа выбора мероприятий Вход: список мероприятий (s1, f1, p1), , ( sn, fn, pn), где pi > 0, si < fi и si, fi, pi – это неот - рицательные вещественные числа. Выход: множество S ⊆ [n] выбранных мероприятий таких, что никакие два вы- бранных мероприятия не накладываются и прибыль P(S) = åi∈S pi равна макси- мально возможной. Мероприятие i имеет фиксированные время начала si, время завершения fi и прибыль pi. Для заданного множества мероприятий мы хотим выбрать подмно- жество ненакладывающихся мероприятий с максимальной общей прибылью. Ти-S⊆[d ]\n--- Страница 81 ---\n80  Динамическое программирование пичным примером задачи выбора мероприятий является серия лекций с фикси- рованным временем начала и завершения, которые должны быть запланированы в одном учебном классе. Определим массив подзадач: отсортируем мероприятия по времени завер- шения, f 1 ≤ f2 ≤ ≤ fn. Поскольку возможно, что мероприятия завершаются одно- временно, мы выбираем несовпадающие времена завершения и обозначаем их u1 < u2 < < uk, где очевидно, что k ≤ n. Например, если мы имеем мероприятия, завершающиеся в моменты времени 1,24; 4; 3,77; 1,24; 5 и 3,77, то мы разбиваем их на четыре группы: мероприятия, завершающиеся в моменты времени u 1 = 1,24, u2 = 3,77, u3 = 4, u4 = 5. Пусть u0 равно min1≤i≤n si, то есть самому раннему времени начала. Следова- тельно, u0 < u1 < u2 < < uk, так как понятно, что si < fi. Определим массив A(0…k) следующим образом: A(j) = max{P(S )|S является допустимым и fi ≤ uj для каждого i ∈ S}, где расписание S является допустимым, если никакие два мероприятия в S не на- кладываются. Обратите внимание, что A(k) – это максимально возможная при- быль для всех возможных расписаний S. Задача 4.20. Дайте формальное определение того, что означает быть допусти- мым для расписания мероприятий, то есть выразите точно, что мероприятия во множестве S «не накладываются». Определим рекуррентное соотношение А(0…k). Для того чтобы дать такое ре- куррентное соотношение, сначала определим вспомогательный массив H(1…n) такой, что H(i) – это индекс наибольшего несовпадающего времени завершения, не превышающего время начала мероприятия i. Формально H(i) = l, если l – это наибольшее число такое, что ul ≤ si. Для вычисления H(i) нам нужно выполнить поиск в списке несовпадающих времен завершения. Для того чтобы это сделать эффективно, для каждого i применим процедуру двоичного поиска, которая вы- полняется за логарифмическое время в длине списка несовпадающих времен за-вершения (попробуйте сначала l = ⌊– k 2⌋). Так как длина k списка несовпадающих времен завершения не превышает n и нам нужно применить двоичный поиск для каждого элемента массива H(1 n), время, необходимое для вычисления всех эле- ментов массива, составляет O(n log n). Мы инициализируем A(0) = 0, и мы хотим вычислить A(j), при условии что у нас уже есть A(0), , A(j –1). Рассмотрим u0 < u1 < u2 < … < uj–1 < uj. Можем ли мы пре- взойти прибыль A(j –1), запланировав некое мероприятие, которое заканчива- ется в момент времени uj? Попробуем все мероприятия, которые заканчиваются в этот момент времени, и вычислим максимальную прибыль в каждом случае. Мы получим следующее рекуррентное соотношение: A(j) = max{A( j – 1), max{p i + A(H(i ))|fi = uj}}, (4.3) где H(i) – это наибольшее l такое, что ul ≤ si. Рассмотрим пример, приведенный на рис. 4.2.S⊆[n] 1≤i≤n\n--- Страница 82 ---\nЗадача выбора мероприятий  81 a b c sb = uH(b) uH(a) sb sc = uH(c) uj–1 uj Рис. 4.2  В данном примере мы хотим вычислить A(j). Предположим, что некое мероприятие, завершающееся в момент времени uj, должно быть запланировано для получения максимально возможной прибыли. На этом рисунке есть три меро- приятия, которые заканчиваются в момент времени uj: a, b, c, – заданных соответ - ственно тройками (sa, fa, pa), (sb, fb, pb), (sc, fc, pc), где, разумеется, принято допущение, что uj = fa = fb = fc. Вопрос в том, какое из этих трех мероприятий должно быть выбрано. Для того чтобы это установить, мы должны посмотреть на каждое мероприятие a, b, c по очереди и определить, какое наиболее прибыльное расписание мы можем по-лучить, если настаиваем на том, чтобы данное мероприятие было запланировано. Например, если мы настаиваем на том, чтобы было запланировано мероприятие а, то мы должны увидеть, какое самое прибыльное расписание мы можем получить, где все другие мероприятия должны закончиться к s a, что фактически означает, что все другие мероприятия должны закончиться к uH(a). Обратите внимание, что в этом примере мы имеем, что uH(a) < sa, но uH(b) = sb и uH(c) = sc. По большому счету, мы должны найти, какое из трех значений pa + A(H(a)), pb + A(H(b)), pc + A(H(c)) является максимальным Рассмотрим пример на рис. 4.3. Для того чтобы увидеть, как была вычислена нижняя строка правой таблицы на рис. 4.3, обратите внимание, что в соответ - ствии с рекуррентным соотношением (4.3) мы имеем: A(2) = max{20, 30 + A(0), 20 + A(1)} = 40, A(3) = max{40, 30 + A(0)} = 40. Мероприятие i 1 2 3 4 Начало si 0 2 3 2 Конечный fi 3 6 6 10 Прибыль pi 20 30 20 30 H(i) 0 0 1 0 j 0 1 2 3 uj 0 3 6 10 A(j) 0 20 40 40 Рис. 4.3  Пример с четырьмя мероприятиями Таким образом, максимальная прибыль равна A(3) = 40. Задача 4.21. Напишите алгоритм. Задача 4.22. С учетом того, что A было вычислено, как найти множество ме- роприятий S такое, что P(S) = A(k)? Подсказка: если A(k) = A(k – 1), то мы знаем,\n--- Страница 83 ---\n82  Динамическое программирование что никакое выбранное мероприятие не заканчивается в момент времени uk, по - этому мы переходим к рассмотрению A(k – 1). Если A(k) > A(k – 1), то некое вы- бранное мероприятие завершается в момент времени uk. Как мы находим это мероприятие? Задача 4.23. Реализуйте решение методом динамического программирования для «задачи выбора мероприятия с прибылью». Ваш алгоритм должен вычислить стоимость наиболее прибыльного множества мероприятий, а также вывести ис - черпывающий список этих мероприятий. 4.5. з адания с Указанием предельных сроков , длительностей и прибылей Вход: список заданий (d1, t1, p1), …, ( dn, tn, pn). Выход: допустимое расписание C(1…n) такое, что прибыль C, обозначаемая P(C), является максимально возможной среди допустимых расписаний. В разделе 2.2 мы рассмотрели задачи планирования заданий для случая, когда каждое задание занимает единицу времени, то есть каждая длительность di = 1. Теперь мы обобщим ее на случай, когда каждое задание i имеет произвольную длительность di, крайний срок ti и прибыль pi. Мы исходим из того, что di и ti яв- ляются положительными целыми числами, но прибыль pi может быть положи- тельным вещественным числом. Мы говорим, что расписание C(1…n) является допустимым, если выполняются следующие два условия (пусть C(i) = –1 обозна- чает, что задание i не запланировано, и, значит, C(i) ≥ 0 указывает на то, что оно запланировано, и обратите внимание, что мы разрешаем планировать задания в момент времени 0): (1) если C(i ) ≥ 0, то C(i ) + d i ≤ ti и (2) если i ≠ j и C(i ), C(j) ≥ 0, то (a) C(i ) + di ≤ C( j); или (b) C( j) + dj ≤ C(i ). Первое условие сродни утверждению, что каждое запланированное задание завершается к предельному сроку, и второе условие сродни утверждению, что никакие два запланированных задания не накладываются. Цель состоит в том, чтобы найти допустимое расписание C(1…n) для n заданий, для которых прибыль P(C) = å C(i)≥0 pi, сумма прибылей запланированных заданий максимизируется. Задание отличается от мероприятия тем, что оно может быть запланировано в любое время, если только завершается к предельному сроку; мероприятие име-ет фиксированные времена начала и завершения. Из-за гибкости планирования заданий найти оптимальное расписание для заданий «труднее», чем выбрать оп-тимальное подмножество мероприятий. Обратите внимание, что планирование заданий представляет «как минимум такую же трудность, как и простая задача о рюкзаке». На самом деле экземпляр простой задачи о рюкзаке w 1, …, wn, C можно рассматривать как задачу планиро- вания заданий, в которой каждая длительность di = wi, каждый предельный срок ti = C и каждая прибыль pi = wi. Тогда максимальная прибыль любого раписания равна максимальному весу, который можно положить в рюкзак. Эта, казалось бы,\n--- Страница 84 ---\nДальнейшие примеры и задачи  83 невинная идея о «как минимум такой же трудности» на самом деле является мощ- ным инструментом, широко используемым в области вычислительной сложности для сравнения относительной трудности задач. Пересмотрев общий экземпляр планирования заданий как экземпляр простой задачи о рюкзаке, мы обеспечили редукцию планирования расписания заданий в простую задачу о рюкзаке и тем самым показали, что если бы удалось эффективно решить задачу планирования заданий, то у вас автоматически было бы эффективное решение простой задачи о рюкзаке. Для того чтобы предоставить решение задачи планирования заданий методом динамического программирования, мы начинаем с сортировки заданий по пре- дельным срокам. Следовательно, мы исходим из того, что t 1 ≤ t2 ≤ … ≤ tn. Получается, что, для того чтобы определить подходящий массив A для решения задачи, мы должны рассмотреть все возможные целочисленные времена t, 0 ≤ t ≤ tn как предельный срок для первых i заданий. Недостаточно рассмотреть только ука- занный предельный срок ti, заданный во входных данных задачи. Таким образом, определим массив A(i, t) следующим образом: A(i, j) = max � P(C): C – это допустимое решение; планируются только те задания, которые в [i ]; все запланированные задания заканчиваются ко времени t �. Теперь мы хотим спроектировать рекуррентное соотношение для вычисления A(i, t). В обычном стиле рассмотрим два случая, когда задание i выполняется или не выполняется в оптимальном расписании (и отметим, что задание i не будет выполняться в оптимальном расписании, если di > min{ti, t}). Если задание i не встречается, то мы уже знаем оптимальную прибыль. Если, с другой стороны, задание i в оптимальном расписании все-таки встреча- ется, то мы можем также допустить, что это задание является последним (среди заданий {1, …, i}), которые должны быть запланированы, потому что оно имеет последний предельный срок. Поэтому мы допускаем, что задание i планируется как можно позже с целью его завершения либо в момент времени t, либо в момент времени ti в зависимости от того, какое из них меньше, то есть оно заканчивается в момент времени tmin = min{ti, t}. Задача 4.24. В свете обсуждения в двух приведенных выше абзацах найдите ре- куррентное соотношение для A(i, t). Задача 4.25. Реализуйте свое решение. 4.6. дальнейшие примеры и зада Чи 4.6.1. Задача суммирования сплошной подпоследовательности Вход: вещественные числа r1, , rn. Выход: для каждой сплошной подпоследовательности (то есть подпоследователь-ности с расположенными подряд элементами) вида r i, ri+1, , rj пусть Sij = ri + ri+1 + ··· + rj, где Sii = ri. Найти M = max1≤i≤j≤n Sij.\n--- Страница 85 ---\n84  Динамическое программирование Например, на рис. 4.4 мы имеем пример задачи суммирования сплошной под- последовательности. Там решение равняется M = S35 = 3 + (–1) + 2 = 4. Эта задача может быть решена за время O(n2) путем систематического вычис - ления всех сумм Sij и нахождения максимума (имеется �n 2� пар i, j ≤ n таких, что i < j). Однако существует более эффективное решение методом динамического программирования, которое работает за время O(n). Определим массив M(1 n) следующим образом: M(j) = max{S1j, S2j, , Sjj}. См. рис. 4.4 с примером. Задача 4.26. Объясните, как найти решение M из массива M(1…n). Задача 4.27. Заполните четыре строки кода, указанные в алгоритме 4.5 для вы- числения значений массива M(1…n) с учетом r1, r2, , rn. j 1 2 3 4 5 6 7 rj 1–5 3–1 2–8 3 M(j)1–4 3 2 4–4 3 Рис. 4.4  Пример вычисления M( j) Алгоритм 4.5. Задача 4.27 M(1) ← ______________________(1) for j : 2 n do if ______________________(2) then M( j) ← ______________________(3) else M( j) ← ______________________(4) end if end for 4.6.2. Перетасовка В этом разделе мы намерены изучить алгоритм, который работает с цепочками символов – строками; см. раздел 8.2 для получения общей информации по стро-кам, алфавитам и языкам. Если u, v и w – это строки над алфавитом å, тогда w – это перетасовка u и v, при условии что существуют (возможно, пустые) строки x i и yi такие, что u = x1x2 ··· xk и v = y1 y2 ··· yk и w = x1 y1x2 y2 ··· xk yk. Перетасовка иногда также называется «слияни- ем» или «чередованием». В интуитивном плане данное определение базируется на идее, что w может быть получена из u и v с помощью операции, аналогичной тасованию двух колод карт. Мы используем w = u ʘ v для обозначения, что w явля- ется перетасовкой u и v; вместе с тем обратите внимание, что, несмотря на дан- ную форму записи, из u и v может быть получено много разных перетасовок w. Строка w называется квадратом, при условии что она равна перетасовке строки u с самой собой, а именно при условии w = u ʘ u для некоторой строки u. В работе\n--- Страница 86 ---\nДальнейшие примеры и задачи  85 [Buss и Soltys (2013)] показано, что множество квадратов является NP-полным; это является истинным даже для (достаточно больших) конечных алфавитов. См. раздел 4.3, где расматривается NP-полнота. В начале 1980-х годов Мэнсфилд [Mansfield (1982, 1983)] и Вармут и Хаусслер [Warmuth и Haussler (1984)] изучали вычислительную сложность операции пере-тасовки. В работе [Mansfield (1982)] дан полиномиально-временной алгоритм ди-намического программирования для решения следующей задачи перетасовки: для заданных входов u, v, w может ли w быть выражена как перетасовка u и v, то есть w = u ʘ v? Идея в основе алгоритма [Mansfield (1982)] заключается в построении реше- точного графа с (|x | + 1) × (|y| + 1) узлами; левый нижний узел представлен (0, 0), и правый верхний узел представлен (|x |, |y|). Для любых i < |x| и j < |y| мы имеем ребра: � ((i, j), (i + 1, j )), если xi+1 = wi+j+1 ((i, j), (i, j + 1)), если yj+1 = wi+j+1. (4.4) Обратите внимание, что оба ребра могут присутствовать, и это, в свою очередь, вводит экспоненциальное число вариантов, если выполнять поиск наивно. Путь начинается в (0, 0), и когда i-й раз он идет вверх, мы выбираем xi и, когда j-й раз он идет вправо, yj. Таким образом, путь из (0,0) в (|x|, | y|) представляет собой конкретную перетасовку. Например, рассмотрим рис. 4.5. Слева мы имеем перетасовку 000 и 111, кото- рая дает 010101, и справа мы имеем перетасовку 011 и 011, которая дает 001111. Левый экземпляр имеет уникальную перетасовку, которая дает 010101, и она со-ответствует уникальному пути из (0,0) в (3, 3). Справа есть несколько возможных перетасовок 011, 011, которые дают 001111 – на самом деле восемь, каждая из ко-торых соответствует несовпадающему пути из (0, 0) в (3, 3). Алгоритм динамического программирования из работы [Mansfield (1982)] вы- числяет частичные решения вдоль левой верхней и правой нижней диагональных линий на решеточном графе. Рис. 4.5  Слева мы имеем перетасовку 000 и 111, которая дает 010101, и справа мы имеем перетасовку 011 и 011, кото- рая дает 001111. Двойная стрелка на правой диаграмме на-ходится там, показывая, что рядом со сплошными стрелками могут быть и другие стрелки; двойная стрелка равна ((1, 3), (2, 3)), и она находится там, потому что x 1+1 = x2 = 1 = w5 = w1+3+1. Ребра размещены согласно (4.4)\n--- Страница 87 ---\n86  Динамическое программирование Число путей всегда ограничено: �|x| + |y|�|x| и эта граница достигается для �1n, 1n, 12n�. Таким образом, число путей может быть экспоненциальным по размеру входных данных, и поэтому исчерпывающий по- иск вообще невозможен. Задача 4.28. С учетом обсуждения в этом разделе предложите алгоритм динами- ческого программирования, который, получая на входе w, u, v, проверяет, являет - ся ли w = u ʘ v. 4.7. ответы к избранным зада Чам Задача 4.1. После того как мы вычислили значения R, мы можем пройтись по нему в обратном порядке от конца самой длинной неубывающей подпоследова- тельности. Такая последовательность должна заканчиваться на индексе j таком, что R(j) является максимальным. Если R(j) = 1, то доказательство завершено. В противном случае, для того чтобы найти индекс, предшествующий j, найдите любой индекс i < j такой, что R(i) = R(j) – 1 и ai ≤ aj; один такой обязательно сущест - вует, или R(j) будет меньше. Продолжайте прослеживать в обратном порядке до тех пор, пока не дойдете до начала подпоследовательности, где R равно 1. Задача 4.2. Алгоритм 4.1 требует только, чтобы на входе у него была конеч- ная последовательность упорядоченных объектов (то есть объектов, для которых «≤» имеет смысл). Его постусловие, которое мы стремимся доказать, заключается в том, что для всех j в {1, 2, , d}, R(j) – это длина самой длинной неубывающей подпоследовательности, заканчивающейся в a j. Мы утверждаем, что после j итераций внешнего цикла «for» R(j) будет длиной самой длинной подпоследовательности, заканчивающейся в aj, и, более того, что то же самое верно для всех i < j. Из первого вытекает второе, так как после того, как значение присваивается элементу R(i), алгоритм ни разу не присваивает его заново. Доказательство будет по полной индукции над j. Пусть Sj обозначает любую длинную неубывающую подпоследовательность, оканчивающуюся в aj для любо- го индекса j. В базовом случае очевидно, что R(1) = 1 является правильным при- сваиванием; пустая подпоследовательность имеет длину менее 1, и единственная другая подпоследовательность, {a 1}, является тривиально неубывающей с мощно- стью 1. Допустим, что для всех i < j, R(i) было присвоено правильное значение. Если Sj = {aj}, то нет i < j такого, что ai ≤ aj, поэтому значение max никогда не будет изменено после начального присваивания значения 0. В связи с этим элементу R(j) дается правильное значение, 1. Если, с другой стороны, |S j| > 1, то существует элемент ai, непосредственно предшествовавший aj в Sj, где ai ≤ aj и i < j. Очевидно, что существует Sj такое, что Sj = Si ⋃ {aj}, поэтому |Sj| = |Si| + 1 = R(i ) + 1. Допустим, что max ≠ R(i) после итерации i внутреннего цикла for. ai ≤ aj, поэтому R(i) < max. Следовательно, существует i′ < i такой, что ai′ ≤ aj и R(i′) > R(i). Но Si′ ⋃ {aj} является неуменьшающимся, заканчивается на aj и имеет мощность, большую, чем Sj, – противоречие. Схожим образом max не может быть заново переназначен позже, так как это приведет к такому же противоречию. Следовательно, в конце\n--- Страница 88 ---\nОтветы к избранным задачам  87 итерации j элементу R(j) присваивается правильное значение R(i) + 1. Поэтому после итерации d R( j) является правильным для всех j. Задача 4.3. Для того чтобы найти длину самой длинной подпоследовательно- сти, над которой любые два следующих подряд члена отличаются не более чем на 1, мы можем просто отредактировать условие «if» в алгоритме 4.1. В частности, «a i ≤ aj» можно заменить на «|ai – aj| ≤ 1». Задача 4.5. Рассмотрим граф Gn на рис. 4.6. Он содержит 2 + n + n = 2n + 2 узлов и 2n путей из s в t; начиная в s, у нас есть выбор – идти в узел 1 или в узел 1′, и далее у нас всегда есть выбор: идти вверх или вниз, поэтому существует 2×2n–1 путей, которые приводят нас в n или n′. Наконец, мы просто идем в t. Обратите внима- ние, что мы привели неориентированный граф; но если придать всем ребрам на-правление «слева направо», то мы получим пример для ориентированных графов. s 1′ 2′ 3′ n′ t1 2 3 n Рис. 4.6  Экспоненциально много путей (задача 4.5) Задачи 4.6 и 4.7. Предусловием является то, что ∀i, j ∈ [n], и мы имеем B(i, j) = A(0, i, j). Постусловие состоит в том, что ∀i, j ∈ [n], и мы имеем B(i, j) = A(n, i, j). Инвариант цикла состоит в том, что после k-й итерации главного цикла B(i, j) = A(k, i, j). Для того чтобы доказать инвариант цикла, следует отметить, что B(i, j) за- дается с помощью min{B(i, j), B(i, k) + B(k, j)}, поэтому единственное беспокойство вызывает то, что B(i, k) или B(k, j) было уже обновлено, поэтому мы не получаем A(k – 1, i, k) или A(k – 1, k, j), как следовало бы, а наборот – A(k, i, k) или A(k, k, j). Но оказывается, что A(k, i, k) = A(k – 1, i, k) и A(k, k, j) = A(k – 1, k, j), потому что крат - чайший путь из i в k (или из k в j ) не содержит k в качестве промежуточного узла. Задача 4.10. Перезапись не создает проблем, так как значения j рассматрива- ются в убывающем порядке C, C – 1, ,1. Следовательно, когда делается ссылка, позиция массива S( j – wi) еще не была обновлена. Задача 4.11. Предусловием является то, что для всех j, S(j) = R(0, j). Постусло- вием является то, что для всех j, S(j) = R(d, j). Пусть инвариант цикла равен ло- гическому утверждению, что после i-го шага S(j) = R(i, j). Этот инвариант цикла соблюдается, так как мы начинаем «заполнять» S справа, и мы только изменяем ложь на истину (не истину на ложь – причина в том, что если бы мы могли по-строить промежуточное значение j с первыми (i – 1) весами, то мы, безусловно, по-прежнему можем построить его с первыми i весами). Задача 4.12. Рассмотрим w 1 = w2 = 1, w3 = 2 и C = 3, поэтому таблица на этих вход- ных данных будет выглядеть следующим образом: 0 1 2 3 T F F F w1 = 1 T T F F w2 = 1 T T T F w3 = 2 T T T T\n--- Страница 89 ---\n88  Динамическое программирование Теперь рассмотрим строку таблицы для wi = 1 и ячейку для столбца с меткой 2. Значение в указанной ячейке равно F, как и должно быть, но если бы цикл for в алгоритме 4.3 не был уменьшающимся циклом, то мы бы обновили эту ячейку значением T, так как для j = 2 мы имеем 2 ≥ w1 и S(2 – w1) = T. Задача 4.14. Сначала нам нужно найти решение; поэтому мы ищем в послед- ней строке (то есть строке d) наибольшее ненулевое j. Иными словами, решение дается с помощью M = max0≤j≤C[R(d, j) = T]. Теперь мы проверяем, что R(d – 1, M) = T. Если да, то мы знаем, что вес wd не нужен, поэтому мы его не включаем и про- должаем смотреть на R(d – 2, M). Если нет, то поскольку R(d, M) = T, мы знаем, что M – wd ≥ 0 ∧ R(d – 1, M – wd) = T. Поэтому мы включаем wd и продолжаем смот - реть на R(d – 1, M – wd). Мы останавливаемся, когда достигаем первого столбца массива. Задача 4.15. Естественный жадный алгоритм, который пытается решить прос - тую задачу о рюкзаке, следующий: упорядочить веса от самого тяжелого до са-мого легкого и добавлять их в этом порядке как можно дольше. Допустим, что M ≠ M, и пусть S 0 равно результату этой жадной процедуры, то есть подмножеству {1, , d} такому, что K(S0) = M. Сначала покажем, что в S0 есть хотя бы один вес. Если S0 = ∅, то M = 0, и все веса должны быть больше C, но тогда M = 0, и поэтому M = M, что не соответствует действительности по принятому допущению. Теперь покажем, что есть хотя бы один вес не в S0: если все веса находятся в S, то снова M = åd i=1 wi = M. Наконец, теперь покажем, что M > –1 2C, рассмотрев первый вес, на- зовем его wj, который был отклонен, после того как хотя бы один вес был добавлен (обратите внимание, что такой вес должен существовать; мы можем допустить, что нет весов больше, чем грузоподъемность C, а если есть, то мы можем просто их не рассматривать; поэтому первый вес в списке добавляется, и тогда мы знаем, что появится некий вес, который не будет добавлен; мы рассматриваем первый такой вес). Если w j ≤ –1 2C, то сумма весов, которые уже внутри, > –1 2C, поэтому M > –1 2C. Если wj > –1 2C, то, поскольку объекты упорядочены жадным алгоритмом в невоз- врастающем порядке весов, веса, которые уже находятся внутри, > –1 2C, поэтому снова M > –1 2C. Задача 4.16. В первом пробеле поставьте wi + åj∈S wj ≤ C, и во втором S ← S ⋃ {i}. Задача 4.17. Определим выражение «S является перспективным» как означа- ющее, что S может быть расширено с использованием еще не рассматривавшихся весов до оптимального решения Smax. В конце, когда весов для рассмотрения боль- ше не остается, инвариант цикла по-прежнему истинен, поэтому S само должно быть оптимальным. Покажем, что выражение «S является перспективным» является инвариантом цикла, по индукции на числе итераций. Базовый случай: S = ∅, поэтому S явно является перспективным. Индукционный шаг: предположим, что S является пер-спективным (поэтому S может быть расширено, используя еще не рассматривав- шиеся веса, до S max). Пусть S′ равно S после еще одной итерации. Предположим i ∈ S ′. Поскольку wi ≥ åd j=i+1 wj, из этого следует, что: K(S′) ≥ K(S) + åd j=i+1 wj, поэтому S′ уже содержит, по крайней мере, столько же веса, сколько любое расши- рение S, не включая wi. Если S′ является оптимальным, то доказательство завер-\n--- Страница 90 ---\nОтветы к избранным задачам  89 шено. В противном случае Smax имеет больший вес, чем S′, поэтому оно должно со- держать wi. Предположим i ∉ S′, тогда мы имеем, что wi + åj∈S wj > C, поэтому i ∉ Smax. В связи с этим S′ может быть расширено (используя еще не рассматривавшиеся веса!) до Smax. В обоих случаях S ′ является перспективным. Задача 4.18. V(i, j) = 0, если i = 0 или j =0. И для i, j > 0, V(i, j) равно � V(i – 1, j), если j < wi или R(i – 1, j – wi) = F, max{vi + V(i – 1, j – wi), V(i – 1, j)} в противном случае. Для того чтобы убедиться, что это работает, предположим, что j < wi. Тогда вес i не может быть включен, поэтому V(i, j) = V(i – 1, j). Если R(i – 1, j – wi) = F, то не существует подмножества S ⊆ {1, …, i} такого, что i ∈ S и K(S) = j, поэтому вес i опять не включен и V(i, j) = V(i – 1, j). В противном случае, если j ≥ wi и R(i – 1, j – wi) = T, вес i может, а может и не быть включен в S. Мы берем случай, который предлагает бóльшую величину: max{vi + V(i – 1, j – wi), V(i – 1, j)}. Задача 4.19. Изменив определение V(i, j), приведенное в (4.2), на K(S) ≤ j (вмес - то K(S) = j), мы можем взять рекуррентное соотношение, заданное для V в реше- нии задачи 4.18, и просто избавиться от части «или R(i – 1, j – wi) = F» для получения рекуррентного соотношения для V, которое не требует вычисления R. Задача 4.20. Предположим, что расписание S содержит мероприятия {a1, a2, …}, где an = (sn, fn, pn) являются временем начала, временем завершения и прибылью мероприятия an для всех n. Расписание S является допустимым, если для всех ai, aj ∈ S либо fi ≤ sj, либо fj ≤ si; то есть первое из двух должно быть завершено до начала второго, поскольку в противном случае они явно накладываются. Задача 4.21. Алгоритм должен включать вычисление несовпадающих времен окончания, то есть времен ui, а также вычисление массива H. Здесь мы просто даем алгоритм вычисления, основанный на рекуррентном соотношении (4.3). При этом мы исходим из того, что существует n мероприятий и k несовпадающих времен завершения. Алгоритм 4.6. Выбор мероприятия A(0) ← 0 for j : 1 k do max ← 0 for i = 1 n do if fi = uj then if pi + A(H(i)) > max then m a x ← pi + A(H(i )) end if end if end for if A( j – 1) > max then max ← A( j – 1) end if A(j) ← max end for\n--- Страница 91 ---\n90  Динамическое программирование Задача 4.22. Мы покажем, как найти фактическое множество мероприятий. Предположим k > 0. Если A(k) = A(k – 1), то никакое мероприятие не было запла- нировано завершиться в момент времени uk, поэтому мы продолжаем рекурсивно исследовать A(k – 1). Если, с другой стороны, A(k) ≠ A(k – 1), то мы знаем, что некое мероприятие было запланировано завершиться в момент времени uk. Мы должны выяснить, которое из них. Мы знаем, что в этом случае A(k) = max1≤i≤n{pi + A(H(i))|fi = uk}, поэтому мы исследуем все мероприятия i, 1 ≤ i ≤ n, а выдаем (первое) мероприя- тие i0 такое, что A(k) = pi0 + A(H(i0)) и fi0 ≤ uk. Теперь мы повторяем эту процедуру с A(H(i0)). Мы заканчиваем, когда k = 0. Задача 4.24. Инициализация: A(0, t) = 0, 0 ≤ t ≤ tn. Для того чтобы вычислить A(i, t) для i > 0, сначала определим tmin = min{t, ti}. Теперь A(i, t) = � A(i – 1, t), если tmin < di max{A(i – 1, t), pi + A(i – 1, tmin – di)} в противном случае. Обоснование: если задание i запланировано в оптимальном расписании, то оно завершается в момент времени tmin и начинается в момент времени tmin – di. Если оно запланировано, то максимально возможная прибыль равна A(i – 1, tmin – di) + pi. В противном случае максимальная прибыль равна A(i – 1, t). Задача 4.26. M = max1≤j≤n M(j). Задача 4.27. 1) r1(= S11); 2) M(j – 1) > 0; 3) M(j – 1) + rj; 4) rj. 4.8. п римеЧания Любой учебник по алгоритмам будет иметь раздел по динамическому програм-мированию; см., например, главу 15 в книге [Cormen и соавт. (2009)] и главу 6 в [Kleinberg и Tardos (2006)]. В отличие от матроидов, которые служат хорошей абстрактной моделью для жадных алгоритмов, в настоящее время разрабатывается общая модель динами-ческого программирования. См. [Aleknovich и соавт. (2005)]. Материал по операции перетасовки, раздел 4.6.2, взят из работ [Buss и Soltys (2013)] и [Mhaskar и Soltys (2015)]. Первоначальная работа по перетасовкам воз-никла из абстрактных формальных языков, и позже перетасовки были обусловле-ны приложениями к моделированию последовательного исполнения параллель-ных процессов. Насколько известно автору, операция перетасовки впервые была использована на формальных языках Гинзбургом и Спанье [Ginsburg и Spanier (1965)]. Ранние исследования с приложениями к параллельным процессам можно найти у Риддла [Riddle (1973, 1979)] и Шоу [Shaw (1978)]. Ряд авторов, в частно-сти [Gischer (1981); Gruber и Holzer (2009); Jantzen (1981, 1985); Jedrzejowicz (1999); Jedrzejowicz и Szepietowski (2001, 2005); Mayer и Stockmeyer (1994); Ogden и со-авт. (1978); Shoudai (1992)], впоследствии изучали различные аспекты сложности операций перетасовки и итерированной перетасовки в сочетании с операциями регулярных выражений и другими конструкциями из теории языков программи-рования.\n--- Страница 92 ---\nПримечания  91 В публикации [Mansfield (1983)] были даны алгоритмы с полиномиальным вре- менем для принятия решения о том, может ли строка w быть записана как перета- совка k строк u1, , uk, чтобы w = u1 ʘ u2 ʘ ··· ʘ uk для постоянного целого k. В работе [Mansfield (1983)] далее доказано, что если k разрешено варьироваться, то задача становится NP-полной (посредством редукции из точного покрытия с помощью 3-членных множеств1). Уормут и Хаусслер [Warmuth и Haussler (1984)] дали не- зависимое доказательство этого последнего результата и продолжили давать до-вольно поразительное улучшение, показывая, что эта задача остается NP-полной, даже если k строк u 1, , uk являются эквивалентными. То есть при наличии строк u и w вопрос, эквивалентна ли строка w итерированной перетасовке u ʘ u ʘ ··· ʘ u строки u, является NP-полным. В их доказательстве использовалась редукция из задачи с 3-членными разбиениями2. В публикации [Soltys (2013)] показано, что задача об эквивалентности w = u ʘ v может быть решена с помощью схем логариф- мической глубины, но не схем ограниченной глубины. Как упоминалось в разделе 4.6.2, строка w определяется как квадрат, если она может быть записана как w = u ʘ u для некоторой u. Эриксон [Erickson (2010)] в 2010 го ду задал вопрос на доске обсуждений Stack Exchange о вычислительной сложности распознавания квадратов и, в частности, решаема ли эта задача за по- линомиальное время. Этот вопрос был повторен как открытый вопрос в работе [Henshall и соавт. (2012)]. Онлайновый ответ на [Erickson (2010)], предоставленный Острином [Austrin (2010)], показал, что задача распознавания квадратов разреши-ма за полиномиальное время, при условии что каждый символ алфавита встреча-ется не более четырех раз в w (путем редукции из задачи 3-SAT 3); однако общий вопрос остался открытым. Настоящая работа решает эту задачу, доказывая, что задача распознавания квадратов NP-полная, даже над достаточно большим фик - сированным алфавитом. 1 3-членное множество (3-SET) здесь означает, что каждая сентенция содержит ровно три литерала. – Прим. перев. 2 Задача с 3-членными разбиениями (3-partition problem) – это задача, когда требуется разбить 3q чисел (допуская дубликаты) на q групп по 3 так, чтобы каждая группа имела одинаковую сумму. См. https://en.wikipedia.org/wiki/3-par tition_problem. – Прим. перев. 3 Задача 3-SAT (задача выполнимости формулы с 3 переменными) состоит из объедине-ния сентенций на n булевых переменных, где каждая сентенция является дизъюнкци- ей из 3 литералов. См. http://jeffe.cs.illinois.edu/teaching/algorithms/notes/30-nphard.pdf. – Прим. перев.",
      "debug": {
        "start_page": 73,
        "end_page": 92
      }
    },
    {
      "name": "Глава 5. Онлайновые алгоритмы 92",
      "content": "--- Страница 93 --- (продолжение)\nГлава 5 Онлайновые алгоритмы Нескончаемая Вальпургиева ночь. Сэр Роджер Скратон [Scruton (2015)] Представленные до этого алгоритмы были офлайновыми алгоритмами, в том смысле что все входные данные целиком подавались в самом начале. В этой главе мы меняем нашу парадигму и рассматриваем онлайновые алгоритмы, где входные данные нескончаемы и предоставляются порциями и алгоритм должен прини-мать решения, основываясь на неполной информации, не зная будущих событий. Типичным примером их применения является дисциплина кеширования; рас - смотрим жесткий диск, с которого данные считываются в память с произвольным доступом. Как правило, память с произвольным доступом намного меньше, и по-этому необходимо решить, какие данные должны перезаписываться новыми дан-ными. Новые запросы данных с жесткого диска поступают непрерывно, и трудно предсказать будущие запросы. Следовательно, мы должны перезаписывать части памяти с произвольным до- ступом новыми запросами, но должны выполнять перезапись разумно с целью минимизации будущих промахов: данными, которые требуются, но не присут - ствуют в памяти с произвольным доступом, и поэтому они должны быть достав-лены с жесткого диска. Когда будущие запросы неизвестны, минимизировать чис - ло промахов очень сложно. Правильность в контексте онлайнового алгоритма имеет другой нюанс; она озна чает, что алгоритм минимизирует стратегические ошибки. То есть онлайно- вый алгоритм, как правило, будет хуже, чем соответствующий офлайновый алго-ритм, который видит все входные данные целиком, но мы хотим, чтобы он был как можно состязательнее с учетом присущих ему ограничений. Следовательно, в контексте онлайновых алгоритмов мы занимаемся оценкой результативности. В разделе 5.1 мы вводим предмет онлайновых алгоритмов задачей доступа к списку, а затем в разделе 5.2 представляем алгоритмы замещения страниц. 5.1. з адаЧа дост Упа к списк У Мы заведуем картотечным шкафом, содержащим L промаркированных, но не отсортированных файлов. Мы получаем последовательность запросов доступа к файлам; каждый запрос представляет собой метку файла. После получения за-проса файла мы должны его найти, обработать и вернуть в шкаф.\nГлава 5 Онлайновые алгоритмы Нескончаемая Вальпургиева ночь. Сэр Роджер Скратон [Scruton (2015)] Представленные до этого алгоритмы были офлайновыми алгоритмами, в том смысле что все входные данные целиком подавались в самом начале. В этой главе мы меняем нашу парадигму и рассматриваем онлайновые алгоритмы, где входные данные нескончаемы и предоставляются порциями и алгоритм должен прини-мать решения, основываясь на неполной информации, не зная будущих событий. Типичным примером их применения является дисциплина кеширования; рас - смотрим жесткий диск, с которого данные считываются в память с произвольным доступом. Как правило, память с произвольным доступом намного меньше, и по-этому необходимо решить, какие данные должны перезаписываться новыми дан-ными. Новые запросы данных с жесткого диска поступают непрерывно, и трудно предсказать будущие запросы. Следовательно, мы должны перезаписывать части памяти с произвольным до- ступом новыми запросами, но должны выполнять перезапись разумно с целью минимизации будущих промахов: данными, которые требуются, но не присут - ствуют в памяти с произвольным доступом, и поэтому они должны быть достав-лены с жесткого диска. Когда будущие запросы неизвестны, минимизировать чис - ло промахов очень сложно. Правильность в контексте онлайнового алгоритма имеет другой нюанс; она озна чает, что алгоритм минимизирует стратегические ошибки. То есть онлайно- вый алгоритм, как правило, будет хуже, чем соответствующий офлайновый алго-ритм, который видит все входные данные целиком, но мы хотим, чтобы он был как можно состязательнее с учетом присущих ему ограничений. Следовательно, в контексте онлайновых алгоритмов мы занимаемся оценкой результативности. В разделе 5.1 мы вводим предмет онлайновых алгоритмов задачей доступа к списку, а затем в разделе 5.2 представляем алгоритмы замещения страниц. 5.1. з адаЧа дост Упа к списк У Мы заведуем картотечным шкафом, содержащим L промаркированных, но не отсортированных файлов. Мы получаем последовательность запросов доступа к файлам; каждый запрос представляет собой метку файла. После получения за-проса файла мы должны его найти, обработать и вернуть в шкаф.\n--- Страница 94 ---\nЗадача доступа к списку  93 Поскольку файлы не упорядочены, мы должны пролистывать файлы, начиная с самого начала, пока не будет найден запрошенный файл. Если файл находится в позиции i, то мы несем расходы на поиск i для его локализации. Если файла в шкафу нет, то стоимость равна l, равная суммарному числу файлов. После того как мы достанем файл, мы должны вернуть его в шкаф, но мы можем решить ре-организовать шкаф; например, мы можем разместить файл ближе к началу. Сти-мулом для такой реорганизации является то, что это может сэкономить нам не-которое время поиска в будущем: если определенный файл запрашивается часто, то целесообразно вставить его ближе к началу. Наша цель – найти правило реор-ганизации, которое минимизирует время поиска. Пусть σ = σ 1, σ2, , σn равно конечной последовательности из n запросов. Для вы- полнения поступающего запроса σi алгоритм доступа к списку ALG должен отыс - кать элемент с меткой σi, проходя список с самого начала до тех пор, пока он его не найдет. Стоимость извлечения этого элемента является индексом его позиции в списке. Таким образом, если элемент σ i находится в позиции j, то стоимость его извлечения равна j. Более того, алгоритм может реорганизовать список в любое время. Работа, связанная с реорганизацией, представляет собой минимальное число перемещений расположенных подряд элементов, необходимое для ее выпол-нения. Каждое перемещение имеет стоимость 1, однако сразу же после доступа к элементу мы даем ему переместиться бесплатно в любое место ближе к началу этого списка. Эти перемещения являются бесплатными, в то время как все осталь- ные перемещения являются платными. Пусть ALG(σ) равно сумме стоимостей об-служивания всех элементов в списке σ, то есть сумме стоимостей всех поисковых операций плюс сумма стоимостей всех платных перемещений. Задача 5.1. Чем оправдано это «бесплатное перемещение»? Другими словами, почему имеет смысл разрешить размещение элемента «бесплатно» сразу после доступа к нему? Наконец, покажите, что с учетом списка из l элементов мы всегда можем переупорядочить его любым удобным для нас способом, делая перемеще-ния только расположенных подряд элементов. Мы рассматриваем модель доступа к статическому списку, где у нас есть список из l элементов и единственными запросами являются запросы на доступ к эле- менту в списке, то есть нет ни вставок, ни удалений. Для задачи управления спис - ками был предложен целый ряд алгоритмов; мы рассмотрим алгоритм перемеще- ния в начало (move to front, MTF), где после доступа к элементу мы перемещаем его в начало списка без изменения относительного порядка других элементов. Далее, мы исходим из того, что σ состоит только из тех элементов, которые по- являются в списке MTF – это не критическое упрощение; см. задачу 5.7. Обратите внимание, что MTF(σ) – это просто сумма стоимостей всех поисковых операций, так как мы меняем положение элемента только при его извлечении, в каковом случае мы бесплатно перемещаем его в начало. Теорема 5.2. Пусть OPT равно оптимальному (офлайновому) алгоритму для мо- дели доступа к статическому списку. Предположим, что алгоритмы OPT и MTF на- чинаются с одной и той же списковой конфигурации. Тогда для любой последова- тельности запросов σ, где |σ| = n, мы имеем, что MTF(σ) ≤ 2 · OPT S(σ) + OPTP(σ) – OPTF(σ) – n, (5.1)\n--- Страница 95 ---\n94  Онлайновые алгоритмы где OPTS(σ), OPTP(σ), OPTF(σ) – это соответственно суммарная стоимость поиско- вых операций, суммарное число платных перемещений и суммарное число бес - платных перемещений алгоритма OPT на σ. Доказательство. Представим, что оба алгоритма, MTF и OPT, обрабатывают за- просы в σ, в то время как каждый алгоритм работает на своем собственном спис - ке, начиная с одинаковой начальной конфигурации. Вы можете представить, что MTF и OPT работают параллельно, начиная из одного списка, и ни один не начи-нает обработку σ i до тех пор, пока к этому не готов другой. Пусть ai = ti + (Φi – Φi–1), (5.2) где ti – это фактическая стоимость, которую несет MTF на обработку этого запроса (таким образом, ti фактически является позицией элемента σi в списке MTF после обработки первых i – 1 запросов). Φi – это потенциальная функция, и здесь она определяется как число инверсий в списке MTF по отношению к списку OPT. Ин- версия определяется как упорядоченная пара элементов xj и xk, где xj предшествует xk в списке MTF, но xk предшествует xj в списке OPT. Задача 5.3. Предположим, что l = 3, и список MTF равен x1, x2, x3, и список OPT равен x3, x2, x1. Какова Φ в этом случае? По сути дела, как вычислить OPT(σ), где σ – это произвольная последовательность запросов, не зная, как работает OPT? Обратите внимание, что Φ0 зависит только от начальных конфигураций MTF и OPT, и так как мы исходим из того, что списки изначально идентичны, Φ0 = 0. Наконец, значение ai в (5.2) называется амортизированной стоимостью, и вкла- дываемый в нее смысл – показывать стоимость доступа к σi, то есть ti плюс мера увеличения «расстояния» между списком MTF и списком OPT после обработки σi, то есть Φi – Φi–1. Совершенно очевидно, что стоимость, понесенная MTF на обработку σ, обозна- чаемая MTF(σ), составляет ån i=1 ti. Но вместо вычисления ån i=1 ti, что сложно, мы вы- числяем ån i=1 ai, что намного проще. Взаимосвязь между двумя суммированиями выражается как MTF(σ) = ån i=1 ti = Φ0 – Φn + ån i=1 ai, (5.3) и так как мы договорились, что Φ0 = 0 и Φi всегда положительна, мы имеем, что MTF(σ) ≤ ån i=1 ai. (5.4) Теперь осталось вычислить верхнюю границу для ai. Задача 5.4. Покажите второе равенство уравнения (5.3). Допустим, что i-й запрос, σi, находится в позиции j списка OPT и в позиции k списка MTF (то есть это позиция данного элемента, после того как были обработа- ны первые (i – 1) запросов). Пусть x обозначает этот элемент – см. рис. 5.1. Мы собираемся показать, что ai ≤ (2si – 1) + pi – fi, (5.5)\n--- Страница 96 ---\nЗадача доступа к списку  95 где si – это стоимостные издержки поиска, понесенные OPT для доступа к запросу σi, и pi и fi – это соответственно платное и бесплатное перемещения, осуществле- ные OPT при обработке σi. Это неравенство показывает, что ån i=1 ai ≤ ån i=1 ((2si – 1) + pi – fi) = 2�ån i=1 si� + �ån i=1 pi� – �ån i=1 fi� – n) = 2OPTS(σ) + OPTP(σ) – OPTF(σ) – n, которое вместе с неравенством (5.4) покажет (5.1). Мы доказываем (5.5) в два шага: на первом шаге свой ход делает MTF, то есть перемещает x из k-й ячейки в начало своего списка, и мы измеряем изменение потенциальной функции относительно списковой конфигурации OPT, перед тем как OPT сделает свои собственные шаги для обработки запроса на x. На втором шаге OPT делает свой ход, и теперь мы измеряем изменение потен- циальной функции относительно списков конфигурации MTF, после того как MTF завершил обработку запроса (то есть с элементом x в начале списка MTF). ∗ ∗ ∗ х x ∗ ∗ ∗MTF OPT Рис. 5.1  Элемент x находится в позиции k в MTF и в позиции j в OPT. Обратите внимание, что на рисунке видно, что j < k, но в ана- лизе мы такого допущения не делаем. Обозначим через ∗ элементы, расположенные перед х в MTF, но после х в OPT, то есть ∗ обознача- ют инверсии относительно х. Могут существовать и другие инверсии с участием х, а именно элементы, которые находятся после х в MTF, но перед х в OPT, однако нас они не касаются Посмотрим на рис. 5.1: предположим, что существует v таких ∗, то есть v ин- версий того типа, который представлен на рисунке. Тогда существует, по крайней мере, (k – 1 – v) элементов, которые предшествуют x в обоих списках. Задача 5.5. Объясните, почему, по крайней мере, (k – 1 – v) элементов предшест - вуют x в обоих списках. Но из этого следует, что (k – 1 – v) ≤ ( j –1), так как x находится в j-й позиции в OPT. Следовательно, (k – v) ≤ j. Так что же происходит, когда MTF перемещает x в начало? С точки зрения инверсии, происходят две вещи: (i) создается (k – 1 – v) новых инверсий относительно списка алгоритма OPT до того, как алгоритм OPT сам займется запросом x. (ii) исключается v инверсий, опять же относительно спис ка алгоритма OPT до того, как алгоритм OPT сам займется запросом х. Таким образом, вклад в амортизированную стоимость составляет: k + ((k – 1 – v) – v) = 2(k – v) – 1 (1) ≤ 2j – 1 (2)= 2s – 1, (5.6) где (1) следует из показанного выше (k – v) ≤ j и (2) следует из того факта, что стоимость поиска, понесенная OPT при поиске x, в точности равна j. Обратите\n--- Страница 97 ---\n96  Онлайновые алгоритмы внимание, что равенство (5.6) похоже на (5.5), но отсутствует +pi – fi. Эти члены бу - дут появляться из рассмотрения второго шага анализа: OPT делает свой ход, и мы измеряем изменение потенциала по отношению к MTF с элементом x в начале списка. Это рассматривается в следующей задаче. Задача 5.6. На втором шаге анализа алгоритм MTF сделал свой ход, и алго- ритм OPT после извлечения x переставляет свой список. Покажите, что каждое платное перемещение вносит в амортизированную стоимость вклад, равный 1, и каждое бесплатное перемещение вносит в амортизированную стоимость вклад, равный –1. На этом доказательство заканчивается. □ В модели доступа к динамическому списку у нас также есть вставки, где стоимость вставки равна l + 1 – здесь l является длиной списка – и удаления, где стоимость удаления такая же, как стоимость доступа, то есть позиция элемента в списке. Ал-горитм MTF всегда удаляет элемент в позиции l. Задача 5.7. Покажите, что теорема 5.2 по-прежнему соблюдается в динамиче- ском случае. Инфимум подмножества S ⊆ R – это наибольший элемент r, не обязательно в S, такой, что для всех s ∈ S, r ≤ s. Мы говорим, что онлайновый алгоритм является с-состязательным, если существует постоянная α такая, что для всех конечных входных последовательностей ALG(σ) ≤ c · OPT(σ) + α. Инфимум над множеством всех значений c, таких, что ALG является с-состязательным 1, называется состяза- тельным соотношением алгоритма ALG и обозначается R(ALG).Задача 5.8. Пронаблюдайте, что OPT(σ) ≤ n · l, где l – это длина списка и n равно |σ|. Задача 5.9. Покажите, что алгоритм MTF является 2-состязательным алгоритмом и что R(MTF) ≤ 2 – – 1 l. Задача 5.10. В главах, посвященных онлайновым и рандомизированным алго- ритмам (эта глава и следующая), нам нужно генерировать случайные значения. Используйте библиотеку Python random для генерирования этих случайных значе- ний; реализуйте алгоритмы OPT и MTF и сравните их на случайной последова-тельности запросов. Вы, возможно, захотите построить график состязательности алгоритма MTF относительно алгоритма OPT с помощью консольной программы gnuplot . Традиционный подход к изучению онлайновых алгоритмов укладывается в рамки распределительной сложности, также именуемой сложностью среднего случая: строится гипотеза о распределении на событийных последовательностях, 1 Состязательный анализ – это метод, служащий для анализа онлайновых алгоритмов, в котором результативность онлайнового алгоритма (который должен удовлетворять не-предсказуемую последовательность запросов, завершая каждый запрос, не имея возмож - ности видеть будущее) сравнивается с результативностью оптимального офлайнового (автономного) алгоритма, который может просматривать последовательность запросов заранее. Вместо термина «состязательный» нередко используется термин «конкурент - ный». За основу взят первый, с тем чтобы отделить его от понятия «рекуррентный». См. https://en. wikipedia. org/wiki/ Competitive_analysis_ (online_algorithm) . – Прим. перев.\n--- Страница 98 ---\nЗамещение страниц  97 и анализируется ожидаемый выигрыш в расчете на событие. Однако в этой главе мы представляем более поздний подход к состязательному анализу, при котором выигрыш онлайнового алгоритма измеряется путем сравнения его результатив-ности с оптимальным офлайновым алгоритмом. Следовательно, состязательный анализ попадает в рамки сложности худшего случая. 5.2. з амещение страниц Рассмотрим двухуровневую систему с виртуальной памятью: каждый уровень, медленный и быстрый, может хранить ряд постоянно-размерных единиц памяти, именуемых страницами. В медленной памяти хранится N страниц, и в быстрой памяти хранится k страниц, где k < N. Обычно k намного меньше N. При наличии запроса страницы p i система должна сделать страницу pi доступ- ной в быстрой памяти. Если pi уже находится в быстрой памяти – такая ситуация называется попаданием, – то системе ничего делать не нужно. В противном случае при промахе система вызывает ошибку – страничный отказ – и должна скопиро- вать страницу pi из медленной памяти в быструю память. При этом система стал- кивается со следующей проблемой: какую страницу вытеснить из оперативной памяти, освободив место для p i. Для того чтобы минимизировать число странич- ных отказов, выбор того, какую страницу вытеснять, должен делаться по-умному. Типичными примерами пары быстрой и медленной памяти являются соответ - ственно ОЗУ и жесткий диск или соответственно кеш процессора и ОЗУ. В общем случае мы будем называть быструю память «кешем». Из-за его важной роли в про-изводительности почти каждой компьютерной системы замещение страниц ши-роко изучалось начиная с 1960-х годов, и общепринятые схемы замещения стра-ниц перечислены на рис. 5.2. LRU Least Recently Used (Последней вошла/последней вышла) CLOCK Clock Replacement (Замещение по часам) FIFO First-In/First-Out (Первым вошла/первой вышла) LIFO Last-In/First-Out (Последней вошла/последней вышла) LFU Least Frequently Used (Наименее часто используемая страница) LFD Longest Forward Distance (Наибольшее расстояние вперед (вытеснить страницу, которая будет запрошена последней)) Рис. 5.2  Дисциплины замещения страниц: пять лучших онлайновых ал- горитмов; последний, наибольшее расстояние вперед (LFD), является оф- лайновым. В разделе 5.2.6 мы увидим, что алгоритм LFD на самом деле является оптимальным алгоритмом замещения страниц Все дисциплины кеширования на рис. 5.2, за исключением последней, являют - ся онлайновыми алгоритмами; то есть это алгоритмы, которые принимают реше-ния на основе прошлых событий, а не будущего. Последний алгоритм, наиболь-шего расстояния вперед (LFD), заменяет страницу, чей следующий запрос будет\n--- Страница 99 ---\n98  Онлайновые алгоритмы последним, что требует знания о будущих запросах, и, следовательно, он является офлайновым алгоритмом. 5.2.1. Замещение страниц по требованию Алгоритмы замещения страниц по требованию никогда не вытесняют страницу из кеша, если только нет страничного отказа, то есть они никогда не вытесняют упреждающе. Все дисциплины замещения страниц на рис. 5.2 являются замеще-нием страниц по требованию. Мы рассматриваем модель страничного отказа, где взимаем 1 за перенос страницы в быструю память, и мы ничего не взимаем за доступ к уже существующей странице. Как показывает следующая теорема, это очень общая модель. Теорема 5.11. Любой алгоритм замещения страниц, онлайновый или офлайновый, может быть модифицирован, став алгоритмом замещения страниц по требованию, без увеличения совокупной стоимости на любой последовательности запросов. Доказательство. В алгоритме замещения страниц по требованию страничный от - каз вызывает ровно одно вытеснение (то есть когда кеш заполнен), и между про- махами нет никаких вытеснений. Поэтому пусть ALG равен любому алгоритму замещения страниц. Мы покажем, как его модифицировать, сделав его алгорит - мом замещения страниц по требованию ALG′ таким, что на любой входной по-следовательности алгоритм ALG′ несет максимум столько же стоимостных издер-жек (делает максимум столько же перемещений страниц из медленной памяти в быст рую), сколько алгоритм ALG, то есть ∀σ, ALG ′(σ) ≤ ALG(σ). Предположим, что алгоритм ALG имеет кеш размером k. Определим алгоритм ALG ′ следующим образом: ALG′ также имеет кеш размером k плюс k регистров. Ал- горитм ALG′ выполняет симуляцию алгоритма ALG, держа в своих k регистрах но- мера страниц, которые алгоритм ALG имел бы в своем кеше. Основываясь на пове-дении алгоритма ALG, алгоритм ALG′ принимает решения о вытеснении страниц 1. Предположим, запрашивается страница p. Если p находится в кеше алгоритма ALG ′, то мы просто обработаем запрос. В противном случае, если происходит стра- ничный отказ, алгоритм ALG′ ведет себя в соответствии со следующими двумя случаями. Случай 1: если у алгоритма ALG тоже страничный отказ (то есть число p не на- ходится в регистрах) и алгоритм ALG вытесняет страницу из регистра i, освобож - дая место для p, то алгоритм ALG′ вытесняет страницу из ячейки i в своем кеше, освобождая место для p. Случай 2: если у алгоритма ALG нет страничной ошибки, то число p должно быть, скажем, в регистре i. В этом случае алгоритм ALG′ вытесняет содержимое ячейки i в своем кеше и перемещает туда p. Таким образом, алгоритм ALG′ является алгоритмом замещения страниц по за- просу. Теперь мы покажем, что алгоритм ALG′ несет стоимостные издержки не боль- ше алгоритма ALG на любой входной последовательности; то есть алгоритм ALG′ имеет максимум столько же страничных отказов, сколько алгоритм ALG. Для это- го мы сопрягаем каждое перемещение страницы алгоритмом ALG′ с перемеще- 1 Принятое в этом доказательстве допущение состоит в том, что алгоритм ALG не пере- страивает свои ячейки – то есть он никогда не переставляет содержимое своего кеша.\n--- Страница 100 ---\nЗамещение страниц  99 нием страницы алгоритмом ALG уникально следующим образом: если алгоритмы ALG ′ и ALG имеют страничный отказ, то спарить перемещения страниц. В против- ном случае если у алгоритма ALG уже была страница в кеше, то, видимо, она была перемещена туда раньше, поэтому спарить то перемещение с текущим переме-щением алгоритма ALG′. Никогда не бывает, чтобы два разных перемещения в алгоритме ALG были сопряжены с одним перемещением в алгоритме ALG. Для того чтобы это уви-деть, предположим, что на некоторой входной последовательности мы впервые сталкиваемся с ситуацией, когда два перемещения в алгоритме ALG′ сопряжены с одним и тем же перемещением в алгоритме ALG. Это может произойти только в сле дующей ситуации: запрашивается страница p, алгоритм ALG′ получает стра- ничный отказ, он перемещает p в свой кеш, и мы спариваем это перемещение с прошлым перемещением в алгоритме ALG, которое уже было спарено! Но это означает, что страница p уже была запрошена, и после того как она была запроше- на, она была вытеснена из кеша алгоритма ALG′ (в противном случае у алгоритма ALG ′ не было бы страничного отказа). Алгоритм ALG′ вытеснил страницу p, тогда как алгоритм ALG нет, поэтому они не были в одной ячейке. Но алгоритм ALG′ (первый раз) поместил p в ту же ячейку, что и алгоритм ALG, противоречие. Следовательно, мы не смогли бы спарить пе-ремещение дважды. Таким образом, мы можем спаривать каждое перемещение ALG ′ с перемещением ALG один к одному, и, следовательно, алгоритм ALG′ делает максимум столько же ходов, сколько алгоритм ALG (рис. 5.3). a bc d σ = σi = р σj = р σn σ1 σ2ALG ALG ′ Cтраница p вытеснена из кеша алгоритма ALG′ Рис. 5.3  Предположим, что i и j – это наименьшая пара такая, что существует страница р с тем свойством, что σi = σj = р. Алгоритм ALG имеет страничный отказ на σi и σj, и два соответствующих перемещения страниц ALG′ оба сопрягаются с одним перемещением страницы р, выполняемым алгоритмом ALG где-то на отрезке а. Мы покажем, что это невозможно: если алгоритм ALG′ имеет страничный отказ на σi = σj = р, то это означает, что где-то на отрезке b страница p вытесняет - ся – этот момент обозначается символом «•». Если алгоритм ALG не вытеснил p на отрезке c, то алгоритм ALG также вытесняет страницу p в «•», и поэтому он должен тогда вернуть ее в кеш на отрезке d – мы бы спарили в σj с этим перемещением. Если алгоритм ALG все-таки вытеснил p на отрезке c, то ему снова пришлось бы вернуть ее перед σj. В любом случае, существует более позднее перемещение p, которое будет сопряжено со страничным отказом алгоритма ALG в σj\n--- Страница 101 ---\n100  Онлайновые алгоритмы Задача 5.12. На рис. 5.3 мы постулируем существование «наименьшей» пары i, j с заданными свойствами. Покажите, что если такая пара существует, то существу - ет «наименьшая» такая пара; что означает «наименьший» в этом случае? Идея состоит в том, что алгоритм ALG ничего не выигрывает, перемещая стра- ницу в кеш упреждающе (до того, как страница действительно понадобится). Ал- горитм ALG′ ожидает запроса перед выполнением того же действия. В то же время (между временем, когда алгортим ALG доставляет страницу, и временем, когда она запрашивается и алгоритм ALG′ ее доставляет) алгоритм ALG ′ может только выиграть, потому что в течение этого времени нет запросов этой страницы, но может быть запрос страницы, которую алгоритм ALG вытеснил упреждающе. Обратите внимание, что в симуляции алгоритма ALG′ требуется только k допол- нительных регистров, необходимых для отслеживания номеров страниц в кеше алгоритма ALG, поэтому данная симуляция является эффективной. □ Теорема 5.11 позволяет нам ограничить наше внимание алгоритмами замеще- ния страниц по запросу и, как следствие, использовать термины «страничный от - каз» и «перемещение страницы» взаимозаменяемо, в том смысле, что в контексте замещения страниц по запросу у нас есть перемещение страницы тогда и только тогда, когда у нас есть страничный отказ. 5.2.2. Первым вошел/первым вышел (FIFO) Когда страница должна быть заменена, выбирается самая старая страница. Отсут - ствует необходимость вести учет времени перемещения страницы; для хранения всех страниц в памяти нам нужно лишь создать очередь FIFO (First-In/First-Out, первым вошел/первым вышел). Алгоритм FIFO легко понять и запрограммиро-вать, но его производительность не очень хороша в общем случае. Алгоритм FIFO также страдает от так называемой аномалии Белади. Предполо- жим, что мы имеем последовательность запросов страниц: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5. Тогда у нас больше страничных отказов при k = 4, чем при k = 3. То есть алгоритм FIFO имеет больше страничных отказов с бóльшим кешем! Задача 5.13. Для общего i предоставьте последовательность запросов страниц, ко- торая иллюстрирует аномалию Белади, испытываемую алгоритмом FIFO на раз- мерах кеша i и i + 1. В вашем анализе исходите из того, что кеш изначально пуст. 5.2.3. Наименее недавно использованная страница (LRU) Оптимальный алгоритм замещения страниц (OPT) вытесняет страницу, чей сле-дующий запрос является самым последним, и если некоторые страницы никогда не запрашиваются снова, то любая из них вытесняется. С точки зрения онлайно-вых алгоритмов этот алгоритм непрактичный, поскольку мы не знаем будущего. Однако если мы используем недавнее прошлое как аппроксимацию ближай- шего будущего, то мы заменим страницу, которая не использовалась в течение длительного периода времени. Этот подход представлен алгоритмом замещения наименее недавно использованной страницы (least recently used, LRU). Замещение в алгоритме LRU связывает с каждой страницей время последнего использования этой страницы. Когда страница должна быть заменена, алгоритм\n--- Страница 102 ---\nЗамещение страниц  101 LRU выбирает ту страницу, которая не использовалась в течение самого длитель- ного периода времени. Алгоритм LRU считается хорошим и часто реализуется – главная проблема заключается в том, как его реализовать; два типичных реше-ния – использовать счетчики и стеки. Счетчики: отслеживать время последней ссылки на данную страницу, обнов- ляя счетчик каждый раз, когда мы ее запрашиваем. Эта схема требует поиска страниц в таблице для нахождения наименее недавно использованной страницы и записи в память при каждом запросе; очевидной проблемой может быть пере-полнение часов. Стек: держать стопку номеров страниц. Всякий раз, когда на страницу ссыла- ются, она удаляется из стека и помещается сверху. Благодаря этому верх стека всегда является последней используемой страницей, а низ – наименее недавно использованной страницей (LRU). Поскольку элементы удаляются из середины стека, их лучше всего реализовывать с помощью двусвязного списка. 1 1 2 2 3 3 4 4 5 5Головной элемент Головной элемент Пусто Пусто Рис. 5.4  Реализация стека алгоритма LRU с двусвязным списком. Запрошенная страница – это страница 4; в левом списке отображается состояние до запроса страницы 4, а в правом – состояние после обработки запроса Сколько операций с указателем необходимо выполнить в примере на рис. 5.4? Шесть, если считать следующим образом: удалить старый головной элемент и до-бавить новый головной элемент (2 операции), соединить 4 с 1 (2 операции), соеди-нить 3 с 5 (2 операции). Вместе с тем мы могли бы также подсчитать отсоединение 3 от 4 и 4 от 5, что дает еще 4 операции с указателем, давая нам в общей сложности 10 операций. Третьей стратегией было бы не считать отсоединение указателей, в этом случае мы получили бы половину этих операций, 5. На самом деле не име-ет значения, как мы считаем, потому что все дело в том, что для перемещения запрошенной страницы наверх (после попадания) нам требуется небольшое по-стоянное число операций с указателем, независимо от того, как мы их считаем.\n--- Страница 103 ---\n102  Онлайновые алгоритмы Задача 5.14. Перечислите операции с указателем, которые необходимо выпол- нить, если запрашиваемая страница отсутствует в кеше. Обратите внимание, что вы должны именно перечислить операции с указателем (а не просто дать «вол-шебное число»), поскольку мы только что показали, что есть три разных (и все разумные) способа их подсчета. Опять же, дело в том, что если страница должна быть доставлена из медленной памяти в кеш, то нам требуется небольшое посто-янное число операций с указателем. Задача 5.15. Мы реализовали алгоритм LRU с помощью двусвязного списка. В чем заключалась бы проблема, если бы вместо этого мы использовали обычный связный список? То есть если бы каждая страница имела только указатель на сле-дующую страницу i j, имея в виду, что i запрашивалась более недавно, чем j, но ни одна страница не запрашивалась позже i и раньше j. Лемма 5.16. Алгоритм LRU не испытывает аномалии Белади (на любом размере кеша и любой последовательности запросов).Доказательство. Пусть σ = p 1, p2, ···, pn равно последовательности запросов, и пусть LRUi(σ) равно числу отказов, которые алгоритм LRU испытывает на σ с кешем раз- мера i. Покажем, что для всех i и σ имеет место следующее свойство: LRUi(σ) ≥ LRUi+1(σ). (5.7) Показав (5.7), из этого следует, что для любой пары i < j и любой последователь- ности запросов σ LRUi(σ) ≥ LRUj(σ), и заключим, что алгоритм LRU не испытывает аномалии Белади. Для демонстрации (5.7) мы определяем свойство двусвязных списков, которое называем встраиванием. Мы говорим, что двусвязный список размера i может быть встроен в другой двусвязный список размера i + 1, если два двусвязных спис - ка идентичны, за исключением того, что более длинный может иметь еще один элемент в «конце». См. рис. 5.5, где двусвязный список размера 3 слева может быть встроен в двусвязный список размера 4 справа. 18 18 5 5 29 29 3 Рис. 5.5  Список слева может быть встроен в список справа\n--- Страница 104 ---\nЗамещение страниц  103 В начале обработки последовательности запросов, когда кеши заполняются, два списка идентичны, но как только кеши заполнены, кеш LRUi+1 будет иметь еще один элемент. Утверждение 5.17. После обработки каждого запроса двусвязный список LRUi может быть встроен в двусвязный список LRUi+1. Доказательство. Мы доказываем это утверждение по индукции на числе шагов. Базовый случай: если n = 1, то и LRUi и LRUi+1 имеют отказ и доставляют p1. Ин - дукционный шаг: предположим, что утверждение соблюдается после шага n; мы покажем, что оно также соблюдается после шага n + 1. Рассмотрим следующие слу - чаи: (1) LRUi имеет попадание на pn+1, (2) LRUi имеет отказ на pn+1, (2а) LRUi+1 также имеет отказ, (2b) LRUi+1 не имеет отказа. Задача 5.18. Покажите, что в каждом случае свойство встраивания сохраняется. Этим завершается доказательство утверждения. □ Задача 5.19. Используйте это утверждение для доказательства (5.7). Этим завершается доказательство леммы. □ 5.2.4. Маркировочные алгоритмы Рассмотрим кеш размера k и зададим последовательность запросов σ. Мы разде- ляем последовательность запросов на фазы следующим образом: фаза 0 является пустой последовательностью. Для каждого i ≥ 1 фаза i является максимальной по- следовательностью, следующей за фазой i – 1, которая содержит не более k несо- впадающих запросов страниц; то есть если она существует, то фаза i + 1 начина- ется на запросе, который составляет (k + 1)-й несовпадающий запрос страницы с начала i-й фазы. Такое разбиение называется k-членным фазовым разбиением. Это разбиение хорошо определено и не зависит от любого конкретного алгоритма обработки σ. Например, 3-членное фазовое разбиение: 1, 2, 1, 2, 1, 2, 3, 4, 5, 6, 6, 6, 6, 6, 6, 6, 4, 5, 4, 7, 7, 7, 7, 1, 2. 3-членная фаза № 1 3-членная фаза № 2 3-членная фаза № 3 Пусть σ равно любой последовательности запросов. Мы рассмотрим ее k-член- ное фазовое разбиение. Свяжем с каждой страницей бит, именуемой маркером. Маркировка выполняется ради анализа (она реализуется не алгоритмом, а «нами», для того чтобы отслеживать действия алгоритма). Для каждой страницы, когда ее маркерный бит установлен, мы говорим, что страница промаркирована, и в про- тивном случае она не промаркирована. Предположим, что в начале каждой k-членной фазы мы снимаем маркеры со всех страниц, и мы маркируем страницу при первом ее запросе во время k-член- ной фазы. Маркировочный алгоритм никогда не вытесняет промаркированную страницу из быстрой памяти. Например, предположим, что k = 2 и σ является последовательностью запросов. Мы показываем 2-членные фазы для σ:\n--- Страница 105 ---\n104  Онлайновые алгоритмы σ = 1, 1, 3, 1, 5, 1, 5, 1, 5, 1, 3, 4, 4, 4, 2, 2, 2, 2 . (5.8) См. рис. 5.6, чтобы проанализировать маркировку в этом примере. Обратите внимание, что после каждой фазы с каждой страницы снимается маркер, и мы на- чинаем маркировать заново, и, за исключением последней фазы, все фазы всегда завершаются (в них есть ровно k несовпадающих запросов, в данном случае 2). Как только запрос страницы р в фазе i сделан в маркировочном алгоритме, р остается в кеше до конца фазы i – при первом запросе страницы p она маркиру - ется, и она остается помеченной на всю фазу, и маркировочный алгоритм никогда не вытесняет промаркированную страницу. Интуиция подсказывает, что маркировочные алгоритмы являются хорошими схемами для замещения страницы, потому что в любой данной фазе существует не более k несовпадающих страниц, поэтому все они помещаются в кеш размера k; нет смысла вытеснять их в этой фазе, поскольку мы только можем потерять от вытеснения – вытесненная страница может быть запрошена снова. Шаг 1 2 3 4 5 1 23456789×××× × ××××× ××××× Шаг 1 2 3 4 5 101112131415161718× ×××××××××××× Рис. 5.6  Маркировка в примере (5.8) Теорема 5.20. Алгоритм LRU является маркировочным алгоритмом. Доказательство. Мы аргументируем от противного; предположим, что алгоритм LRU на кеше размера k не является маркировочным алгоритмом. Пусть σ равно последовательности запросов, в которой существует k-членное фазовое разбие- ние, в течение которого вытесняется некая промаркированная страница p. Рас - смотрим первый запрос страницы p в течение этой k-членной фазы: σ = p1, p2, p3, , , , p, , , , , Сразу после того, как p доставлена, она маркируется в кеше как совсем недавно использованная страница (то есть он помещается вверх двусвязного списка). Для того чтобы р покинула кеш, алгоритм LRU должен получить страничный отказ, при этом p является наименее недавно используемой страницей. Из этого следует, что во время рассматриваемой k-членной фазы было запрошено k + 1 не - совпадающих страниц: существует k – 1 страниц, которые продвинули p в конец списка, существует p и страница, которая вытеснила p. Противоречие; k-членная фаза имеет не более k несовпадающих страниц. □ 2-членная фаза № 12-членная фаза № 32-членная фаза № 42-членная фаза № 2 k-членная фаза\n--- Страница 106 ---\nЗамещение страниц  105 5.2.5. Сброс при заполнении (FWF) Сброс при заполнении FWF (flush when full) – это очень наивный алгоритм замеще- ния страниц, который работает следующим образом: всякий раз, когда возникает страничный отказ и в кеше не остается места, вытеснить все страницы, находя-щиеся в кеше, – назовем это действие сбросом. Точнее, мы рассмотрим следующую версию алгоритма FWF: каждая ячейка в кеше имеет один связанный с ней бит. Вначале все эти биты равны нулю. Когда запрашивается страница p, алгоритм FWF проверяет только ячейки с промарки- рованным битом. Если p найдена, то она доставляется. Если p не найдена, то она должна быть доставлена из медленной памяти (даже если она на самом деле нахо-дится в кеше, в непромаркированной ячейке). Алгоритм FWF разыскивает ячейку с нулевым битом, и происходит одно из следующих событий: (1) ячейка с нулевым битом (непромаркированная страница) найдена, и в этом случае алгоритм FWF заменяет эту страницу на р; (2) ячейка с нулевым битом не найдена (все страницы промаркированы), и в этом случае алгоритм FWF снимает маркеры со всех ячеек и заменяет любую страницу на р, и он обнуляет маркерный бит страницы p. Задача 5.21. Покажите, что алгоритм FWF является маркировочным алгоритмом. Покажите, что алгоритм FIFO не является маркировочным алгоритмом.Задача 5.22. Алгоритм замещения страниц ALG является консервативным, если на любой сплошной входной подпоследовательности, содержащей k или меньше запросов несовпадающих страниц, ALG будет иметь k или меньше страничных ошибок. Докажите, что алгоритмы LRU и FIFO являются консервативными, а ал- горитм FWF – нет. 5.2.6. Наибольшее расстояние вперед (LFD) Оптимальным алгоритмом замещения страниц оказывается алгоритм с наиболь- шим расстоянием вперед LFD (longest forward distance – см. рис. 5.2). Алгоритм LFD вытесняет страницу, которая не будет использоваться в течение длительного периода времени, и в связи с этим он не может быть реализован на практике, по-тому что он требует знаний о будущем. Тем не менее он очень полезен для срав-нительных исследований, то есть для состязательного анализа. Теорема 5.23. Алгоритм LFD является оптимальным (офлайновым) алгоритмом замещения страниц, то есть OPT = LFD.Доказательство. Мы покажем, что если ALG является любым алгоритмом заме- щения страниц (онлайновым или офлайновым), то на любой последовательности запросов σ ALG(σ) ≥ LFD(σ). Как обычно, ALG(σ) обозначает число страничных от - казов алгоритма ALG на последовательности запросов σ. Мы исходим из допуще- ния, что все алгоритмы работают с кешем фиксированного размера k. Нам нужно доказать следующее утверждение. Утверждение 5.24. Пусть ALG равно любому алгоритму замещения страниц. Пусть σ = p 1, p2, , pn равно любой последовательности запросов. Тогда можно по- строить офлайновый алгоритм ALGi, удовлетворяющий следующим трем свой- ствам:\n--- Страница 107 ---\n106  Онлайновые алгоритмы 1) алгоритм ALGi обрабатывает первые i – 1 запросов σ точно так же, как алго- ритм ALG; 2) если i-й запрос приводит к страничному отказу, то алгоритм ALGi вытесняет из кеша страницу с «наибольшим расстоянием вперед»; 3) ALGi(σ) ≤ ALG(σ). Доказательство. Разделим σ на три сегмента следующим образом: σ = σ1, pi, σ2, где σ1 и σ2 каждый обозначают блок запросов. Напомним доказательство теоремы 5.11, где мы симулировали алгоритм ALG с помощью алгоритма ALG′ , выполняя «теневое симулирование» содержимого кеша алгоритма ALG на множестве регистров, чтобы алгоритм ALG′ знал, что делать со своим кешем на основе содержимого этих регистров. Здесь мы делаем то же са- мое: алгоритм ALGi выполняет симуляцию алгоритма ALG на множестве регистров. Как и на σ1, алгоритм ALGi является алгоритмом ALG, из чего следует, что ALGi(σ1) = ALG(σ1), а также что они оба испытывают или не испытывают странич- ный отказ на pi. Если этого не происходит, то пусть алгоритм ALGi продолжает вести себя так же, как алгоритм ALG на σ2 с целью, чтобы ALGi(σ) = ALG(σ). Однако если они все-таки испытывают страничный отказ на pi, то алгоритм ALGi вытесняет страницу с наибольшим расстоянием вперед из своего кеша и за- меняет ее на pi. Если алгоритм ALG также вытесняет ту же страницу, то опять же, пусть алгоритм ALGi ведет себя так же, как алгоритм ALG для остальной части σ с целью, чтобы ALGi(σ) = ALG(σ). Наконец, предположим, что они оба испытывают отказ на pi, но алгоритм ALG вытесняет некую страницу q, а алгоритм ALGi вытесняет некую страницу p, и p ≠ q; см. рис. 5.7. Если оба p, q ∉ σ2, то пусть алгоритм ALGi ведет себя в точности как алгоритм ALG, за исключением того, что ячейки с p и q меняются местами (то есть когда алгоритм ALG вытесняет из q-ячейки, алгоритм ALGi вытесняет из p-ячейки, и когда алгоритм ALG вытесняет из p-ячейки, алгоритм ALGi вытесняет из q-ячейки). ALG: q p ALGi: q p Рис. 5.7  Алгоритм ALG вытесняет q, и алгоритм ALGi вытесняет p, обозначаемые соответственно как q и p, и они оба заменяют свою вытесненную страницу на pi Если q ∈ σ2, но p ∉ σ2, то снова пусть алгоритм ALGi, когда он вынужден вытес - нять, действует так же, как алгоритм ALG, и при этом две ячейки взаимозаменя-ются. Обратите внимание, что в этом случае может случиться так, что ALG i(σ2) < ALG(σ2), поскольку алгоритм ALG вытеснил q, которая будет запрошена снова, но алгоритм ALGi вытеснил p, которая не будет запрошена никогда. Задача 5.25. Объясните, почему случай q ∉ σ2 и p ∈ σ2 невозможен. В противном случае можно допустить, что алгоритм ALGi вытесняет страницу p, алгоритм ALG вытесняет страницу q, p ≠ q иX X XX\n--- Страница 108 ---\nЗамещение страниц  107 σ2 = pi+1, , q, , p, , pn. (5.9) Допустим, что q, показанная в (5.9), является самым ранним экземпляром q в σ2. Как и раньше, пусть алгоритм ALGi действует так же, как алгоритм ALG с q-ячейкой и p-ячейкой. Мы точно знаем, что алгоритм ALG будет иметь отказ на q. Предполо- жим, алгоритм ALG не имеет отказа на р; тогда алгоритм ALG никогда не вытеснял р, поэтому алгоритм ALGi никогда не вытеснял q, и поэтому у алгоритма ALGi не было отказа на q. Следовательно, ALGi(σ2) ≤ ALG(σ2). □ Теперь мы покажем, как использовать утверждение 5.24, чтобы доказать, что алгоритм LFD на самом деле является оптимальным алгоритмом. Пусть σ = p1, p2, , pn равно любой последовательности запросов. По утверждению мы знаем, что ALG1(σ) ≤ ALG(σ). Применив утверждение снова, получим (ALG1)2(σ) ≤ ALG1(σ). Определим ALGj как (··· ((ALG1)2) ···)j. Тогда мы получаем, что ALGj(σ) ≤ ALGj–1(σ). Обратите внимание, что алгоритм ALGn действует так же, как алгоритм LFD на σ, и, следовательно, мы имеем, что LFD(σ) = ALGn(σ) ≤ ALG(σ), и доказательство за- вершено. □ Отныне алгоритм OPT можно считать синонимом алгоритма LFD. Теорема 5.26. Любой маркировочный алгоритм ALG является k k – h + 1-состя- зательным, где k – это размер кеша и h – размер кеша алгоритма OPT. Доказательство. Зададим любую последовательность запросов σ и рассмотрим ее k-членное фазовое разбиение. Допустим, на секунду, что последняя фаза по- следовательности σ завершена (в общем случае последняя фаза может быть неза- вершенной).Утверждение 5.27. Для любой фазы i ≥ 1 маркировочный алгоритм ALG испыты- вает не более k страничных отказов.Доказательство. Это вытекает из того, что на каждой фазе существует k несо- впадающих ссылок на страницы. Как только страница запрашивается, она мар- кируется и, следовательно, не может быть удалена до завершения фазы. Следо-вательно, алгоритм ALG не может испытывать отказ дважды на одной и той же странице. □ Если обозначить i-ю k-членную фазу σ через σ i, то мы можем выразить при- веденное выше утверждение как ALG(σi) ≤ k. Таким образом, если есть s фаз, то ALG(σ) ≤ s · k. Утверждение 5.28. OPT(σ) ≥ s · (k – h + 1), где опять же мы исходим из того, что за- просы равны σ = σ1, σ2, , σs, где σs является полным. Доказательство. Пусть pa равно первому запросу фазы i, а pb равно последнему за- просу фазы i. Предположим сначала, что существует фаза i + 1 (то есть i не является последней фазой). Тогда мы разбиваем σ на k-членные фазы (хотя кеш OPT имеет размер k, мы все же разбиваем σ на k-членные фазы): σ = , pa–1, pa, pa+1, , pb, pb+1, , k-членная фаза № i + 1k-членная фаза № i\n--- Страница 109 ---\n108  Онлайновые алгоритмы После обработки запроса pa алгоритм OPT имеет не более h – 1 страниц в кеше, не включая pa. Начиная с (и включая) pa+1 и вплоть до (и включая) pb+1 существует, по крайней мере, k несовпадающих запросов. Следовательно, на этом сегменте алгоритм OPT должен испытать, по крайней мере, k – (h – 1) = k – h + 1 отказов. Для того чтобы это увидеть, обратите внимание, что имеется два случая. Случай 1: pa снова появляется в pa+1, , pb+1; тогда в сегменте pa+1, , pb+1 сущест - вует, по крайней мере, (k + 1) несовпадающих запросов, и поскольку алгоритм OPT имеет кеш размера h, независимо от содержимого кеша, то будет существовать, по крайней мере, (k + 1) – h = k – h + 1 страничных отказов. Случай 2: предположим, что pa больше не появляется в pa+1, , pb+1, тогда по- скольку pa запрашивается в начале фазы i, то она, безусловно, будет в кеше, когда мы начинаем обработку pa+1, , pb+1. Так как она не запрашивается снова, она зани- мает место в кеше, поэтому самое большее число (h – 1) ячеек в кеше может быть занято некоторыми элементами, запрошенными в p a+1, , pb+1; поэтому снова у нас есть, по крайней мере, k – ( h – 1) = k – h + 1 отказов. Если i является последней фазой (то есть i = s), то у нас нет pb+1, поэтому мы можем только сказать, что у нас есть, по крайней мере, k – h отказов, но мы ком- пенсируем это с помощью p1, которая не учитывалась. □ Из утверждений 5.27 и 5.28 следует, что: ALG(σ) ≤ s · k и OPT(σ) ≥ s · (k – h + 1), с целью, чтобы ALG(σ) OPT(σ) s · k s · (k – h + 1)≤ 1 ≤ . Поэтому, наконец: ALG(σ) ≤ k k – h + 1 · OPT(σ). В случае если σ можно разделить на s полных фаз. Как уже упоминалось выше, в общем случае последняя фаза может оказаться неполной. Тогда мы повторяем этот анализ с σ = σ1, σ2, , σs–1, и для σs мы в конце используем α, и, значит, мы получаем: ALG(σ) ≤ k k – h + 1 · OPT(σ) + α. Задача 5.29. Разложите этот вывод. Следовательно, в обоих случаях мы получаем, что любой маркировочный алго- ритм ALG является k k – h + 1-состязательным. Задача 5.30. Реализуйте все дисциплины на рис. 5.2. Оцените их эксперимен- тально, выполнив их на цепочке случайных запросов и построив график их стои-мости – по сравнению с LFD.\n--- Страница 110 ---\nОтветы к избранным задачам  109 5.3. ответы к избранным зада Чам Задача 5.1. Подумайте о картотечном шкафе, упомянутом в начале этой главы. Когда мы перелистываем картотечный шкаф в поисках конкретного файла, мы по пути держим указатель в заданном месте (то есть в этом месте мы «помещаем па-лец» в качестве закладки), а затем вставляем полученный файл в это место почти без дополнительных издержек на поиск или реорганизацию. Мы также исходим из того, что нет смысла перемещать файл в более позднее место. Наконец, любая перестановка может быть записана как произведение перемещений (см. любой учебник по абстрактной алгебре). Задача 5.3. Ответ равен 3. Обратите внимание, что в списке из n элементов су - ществует n n·(n–1) 2 2= = неупорядоченных пар (и n · (n – 1) упорядоченных пар), поэтому, для того чтобы вычислить Φ, мы перечисляем все эти пары и увеличи- ваем счетчик на 1 (начиная с 0) всякий раз, когда сталкиваемся с инверсией. Что касается второго вопроса, то обратите внимание, что хотя мы не знаем, как имен-но работает алгоритм OPT, мы знаем, что он обрабатывает σ с оптимальной стои- мостью, то есть он обрабатывает σ самым дешевым способом. Таким образом, мы можем найти OPT(σ) исчерпывающим перечислением: для нашего списка x 1, x2, , xl и последовательности запросов σ = σ1, σ2, , σn мы строим дерево, где корень промаркирован x1, x2, , xl, и дети корня – это все l! перестановок списка. Тогда каждый узел, в свою очередь, имеет l! детей; глубина дерева равна n. Мы рассчи- тываем стоимость каждой ветви и маркируем листья этими стоимостями. Сто-имость каждой ветви представляет собой сумму стоимостей всех перемещений, необходимых для создания каждого следующего подряд узла, и стоимостей поис - ковых операций, связанных с соответствующими списковыми конфигурация ми. Самой дешевой ветвью (а их может быть несколько) является именно OPT(σ). Задача 5.4. ån i=1 ti = ån i=1 (ai – Φi + Φi–1) = ån i=1 ai + ån i=1Φi–1 – ån i=1Φi = ån i=1 ai + ån–1 i=0Φi – ån i=1Φi = ån i=1 ai + �Φ0 + ån–1 i=1 Φi� – �Φn + ån–1 i=1 Φi� и вычеркивание в последнем члене дают нам Φ0 – Φn + ån i=1 ai. Задача 5.5. Число элементов перед x в алгоритме MTF равно (k – 1), так как x находится в k-й позиции. Из этих (k – 1) элементов v равны ∗. Оба списка содержат точно такие же элементы, и (k – 1 – v) элементов не-∗ перед x в алгоритме MTF должны все быть перед x в алгоритме OPT (если элемент находится перед x в MTF и после x в OPT, то по определению он будет ∗). Задача 5.6. В случае платного перемещения единственное изменение в числе инверсий может исходить от двух перемещенных элементов, так как относитель-ный порядок по отношению ко всем другим элементам остается тем же. В случае бесплатного перемещения мы знаем, что алгоритм MTF уже поместил переме-щенный элемент x в начало своего списка, и мы знаем, что бесплатные переме- щения могут перемещать x только вперед, поэтому число элементов перед x в ал - горитме OPT уменьшается на 1.\n--- Страница 111 ---\n110  Онлайновые алгоритмы Задача 5.8. Алгоритм OPT является оптимальным офлайновым алгоритмом, и, следовательно, он должен работать, по крайней мере, так же хорошо, как и лю- бой алгоритм ALG. Предположим, мы выполняем все получаемые запросы один за другим наивным способом, не делая никаких перестановок. Стоимость этой схемы ограничена примерно n · l, числом запросов, умноженным на длину списка. Следовательно, OPT(σ) ≤ n · l. Задача 5.9. По теореме 5.2 мы знаем, что MTF(σ) ≤ 2 · OPT S(σ) + OPTP(σ) – OPTF(σ) – n и правая часть равна ≤ 2 · OPTS(σ) + OPTP(σ) ≤ 2 · (OPTS(σ) + OPTP(σ)) = 2 · OPT(σ). Это показывает, что алгоритм MTF является 2-состязательным (с α = 0). Для второй части мы повторим приведенный выше аргумент, но без «потери» состав-ляющей n, поэтому мы имеем MTF(σ) ≤ 2 · OPT(σ) – n. С другой стороны, OPT(σ) ≤ n · l (по задаче 5.8), поэтому 2 · OPT(σ) – n ≤ 12 –l · OPT(σ). Задача 5.12. В доказательстве теоремы 5.11 мы определяем паросочетание между перемещениями страниц (из медленной памяти в кеш) алгоритмов ALG и ALG′. Для того чтобы показать, что паросочетание получается один к одному, мы постулируем существование пары i и j, i ≠ j, со следующими свойствами: (i) существует страница р такая, что σ i = σj = p, (ii) алгоритм ALG′ испытывает отказ на σi и σj, и (iii) алгоритм ALG′ должен перемещать р в кеш для обработки σi и σj, и эти два перемещения сочетаются с таким же перемещением р алгоритмом ALG. Ради аргумента в доказательстве теоремы 5.11 мы хотим «наименьшую» такую пару – поэтому мы используем принцип наименьшего числа (см. стр. 210), для того что-бы показать, что если такие пары вообще существуют, то должны существовать пары, где i + j минимально; мы берем любую такую пару. Задача 5.13. Рассмотрим следующий список: 1, 2, 3 , i , i + 1, 1, 2, 3, , i – 1, i + 2, 1, 2, 3, , i , i + 1, i + 2. Если у нас есть кеш размера i + 1, то мы испытаем i + 1 отказов в сегменте 1 (потому что кеш изначально пуст), затем мы имеем i – 1 попаданий в сегменте 2, потом у нас есть еще один страничный отказ в сегменте 3, поэтому мы вытесняем 1, и в сегменте 4 мы отстаем на 1 на всем протяжении, поэтому мы имеем i + 2 страничных отказов. Следовательно, в общей сложности мы имеем i + 1 + 1 + i + 2 = 2i + 4 страничных отказов. Предположим теперь, что мы имеем кеш размера i. Тогда мы испытаем i + 1 страничных отказов в сегменте 1, затем у нас будет i – 1 страничных отказов в сег - менте 2 и один страничный отказ в сегменте 3, следовательно, 2i + 1 страничных отказов перед началом этапа 4. Когда начинается сегмент 4, в кеше у нас уже есть страницы с 1 по i – 1, поэтому мы имеем попадания, а затем, когда запрашивается i + 1, мы имеем отказ, и когда запрашивается i + 2, мы имеем попадание и, следо- вательно, только один отказ в сегменте 4. Таким образом, мы имеем 2i + 2 стра-2 3 4 1\n--- Страница 112 ---\nОтветы к избранным задачам  111 ничных отказов с кешем размера i. Для того чтобы разобраться в этом решении, убедитесь, что вы отслеживаете содержимое кеша после обработки каждого из четырех сегментов. Обратите внимание, что для правильной работы этого при-мера i должно равняться, по крайней мере, 3. Задача 5.14. Если запрашиваемой страницы в кеше нет, то мы должны: 1) удалить пустой указатель (+1); 2) отсоединить последний элемент от предпоследнего (+2); 3) добавить пустой указатель из нового последнего элемента (+1); 4) удалить головной элемент (+1); 5) соединить новый первый элемент (запрошенная страница) со старым пер-вым элементом (+2); 6) добавить новый головной элемент (+1), – в общей сложности 8 операций с указателями. Задача 5.15. Задача с односвязным списком заключается в том, что для на- хождения предшественника страницы нам нужно начинать поиск всегда в начале списка, увеличивая накладные расходы на поддержание стека. Задача 5.18. Случай 1. Если LRU i имеет попадание в pn+1, то то же самое про- исходит в LRUi+1, так как LRUi может быть встроен в LRUi+1 после шага h. Следова- тельно, ни один связный список не изменяется на шаге n + 1, поэтому LRUi по- прежнему может быть встроен в LRUi+1 после шага n + 1. Случай 2а. Если LRUi и LRUi+1 оба имеют отказы на pn+1, то каждый список пре- терпит два изменения: последняя (то есть наименее недавно использованная) страница будет удалена с «конца», и p i+1 будет добавлена в качестве головного эле- мента. Удаление последней страницы из каждого списка не останавливает встраи-вание LRU i в LRUi+1; оно просто приводит к тому, что каждый список заканчивает - ся на одну страницу «раньше», поэтому страница в конце LRUi после шага n теперь является «лишней» страницей в конце LRUi+1. Ясно, что добавление нового голов- ного элемента в каждый список также не подавляет встраивание, поэтому через n + 1 шагов LRUi по-прежнему может быть встроен в LRUi+1. Случай 2b. Допустим, что LRUi имеет отказ на pi+1 и LRUi+1 его не имеет. Оба списка должны содержать i страниц после шага n, и более того, страницы долж - ны быть одинаковыми и в том же порядке, для того чтобы LRUi мог быть встроен в LRUi+1. Поэтому наименее недавно использованная страница в LRUi будет удале- на на шаге n + 1, но это не остановит LRUi от его встраивания, так как удаленная страница теперь является лишней страницей в конце LRUi+1. Опять же, очевидно, что добавление одной и той же страницы pn+1 в начало обоих списков не влияет на встраивание, поэтому индукция завершена. Задача 5.19. После n – 1 шагов связный список LRUi может быть встроен в спи- сок LRUi+1. Рассмотрим любую страницу pn ∈ σ. Если pn находится в списке LRUi, то она находится в том же индексе в LRUi+1, поэтому стоимость доступа к pn иден- тична. Если pn нет в списке LRUi, то она может быть последним элементом списка LRUi+1, в каковом случае LRUi+1 получает доступ к pn с меньшей стоимостью, чем у LRUi. В противном случае ее нет ни в одном из списков, поэтому стоимость сно- ва одинакова. Поскольку это верно для каждой p ∈ σ, мы можем заключить, что LRUi(σ) ≤ LRUi+1(σ). Задача 5.21. Алгоритм FWF действительно реализует маркирующий бит, по- этому он представляет собой почти маркировочный алгоритм по определению.\n--- Страница 113 ---\n112  Онлайновые алгоритмы Алгоритм FIFO не является маркировочным алгоритмом, потому что при k = 3 и последовательности запросов 1, 2, 3, 4, 2, 1 он вытеснит элемент 2 во второй фазе, даже если он промаркирован. Задача 5.22. Мы должны исходить из того, что кеш имеет размер k. В против- ном случае утверждение не является истинным: например, предположим, что у нас есть кеш размера 1 и последовательность: 1, 2, 1, 2. Тогда в этой последова-тельности из 4 запросов есть только 2 несовпадающих запроса, но с кешем разме-ра 1 было бы 4 отказа для любого алгоритма замещения страниц. С кешем разме-ра k алгоритм LRU никогда не будет вытеснять страницу во время этой сплошной подпоследовательности, как только страница была запрошена. Таким образом, каждый несовпадающий запрос страницы может вызвать только один отказ. То же самое касается и алгоритма FIFO. Таким образом, они оба являются консер-вативными алгоритмами. Вместе с тем существует возможность, что на полпу - ти через сплошную подпоследовательность кеш алгоритма FWF будет заполнен, и алгоритм FWF вытеснит все страницы. Следовательно, алгоритм FWF может иметь более одного отказа страницы на той же странице во время этой сплошной подпоследовательности. Задача 5.25. Если p ∈ σ 2 и q ∉ σ2, то q имела бы «более длинное расстояние впе- ред», чем p, и поэтому p не была бы вытеснена алгоритмом ALG. Скорее, алгоритм ALG вытеснил бы q или какую-то другую страницу, которая не будет запрошена снова. Задача 5.29. Пусть ås–1 обозначает первые s – 1 полных фаз последовательно- сти σ. Мы знаем, что ALG(ås–1) ≤ k k – h + 1 · OPT(ås–1). Ясно, что в любом из указанных алгоритмов может произойти не более k – 1 отказов в фазе σs, так как это не полная k-членная фаза. Поэтому ALG(σ) ≤ ALG(ås–1) + k – 1 ≤ k k – h + 1 · OPT(ås–1) + k – 1 ≤ k k – h + 1 · OPT(σ) + k – 1. 5.4. п римеЧания Очень полным учебником по онлайновым алгоритмам является [Borodin и El-Yaniv (1998)]. См. также [Dorrigiv и Lopez-Ortiz (2009)] из колонки новостей SIGACT по онлайновым алгоритмам.",
      "debug": {
        "start_page": 93,
        "end_page": 113
      }
    },
    {
      "name": "Глава 6. Рандомизированные алгоритмы 113",
      "content": "--- Страница 114 --- (продолжение)\nГлава 6 Рандомизированные алгоритмы Даже на расшировку сообщения, зашиф- рованного на трехроторной Энигме, мо-жет уйти двадцать четыре часа, посколь-ку бомбы пробивались сквозь миллиарды перестановок. Работа четырехроторной Энигмы, умножающей числа на двадцать шесть порядков, теоретически заняла бы добрую часть месяца. Enigma, стр. 27 [Harris (1996)] Довольно любопытно, что мы можем проектировать процедуры, которые, столк - нувшись с изобилием вариантов, вместо того чтобы кропотливо изучать все воз-можные ответы на эти варианты, подбрасывают монетку, чтобы решить, в какую сторону идти, и, несмотря на это, «как правило», получают правильный результат. Совершенно очевидно, что когда прибегаем к случайности, мы экономим вре- мя, но совершенно удивительно то, что результаты таких процедур могут быть содержательными. То есть существуют задачи, решение которых кажется вычис - лительно очень трудным, но когда допускается использование случайности, по-является возможность проектировать процедуры, которые решают эти сложные задачи удовлетворительно: результат этой процедуры является правильным с не-большой вероятностью ошибки. На самом деле эта ошибка может быть настолько мала, что становится ничтожной (скажем, 1 к 2 100 – что равно примерному числу атомов в наблюдаемой Вселенной). Таким образом, многие эксперты считают, что определение «допустимо вычислимого» должно подразумевать «вычислимое за полиномиальное время со случайностью», а не просто «за полиномиальное вре-мя». Появление рандомизированных алгоритмов было связано с задачей провер-ки простоты (примарности), что, в свою очередь, было вызвано расцветом области криптографии. Исторически первый такой алгоритм появился благодаря работе [Solovay и Strassen (1977)]. Проверка простоты остается одной из лучших задач для демонстрации возможностей рандомизированных алгоритмов; в этой главе мы представим алгоритм Рабина–Миллера, который появился после алгоритма Соловея–Штрассена, но он несколько проще. Интересно отметить, что теперь ши-роко известен полиномиально-временной алгоритм проверки простоты (благо-даря работе [Agrawal и соавт. (2004)]), но алгоритм Рабина–Миллера по-прежнему\nГлава 6 Рандомизированные алгоритмы Даже на расшировку сообщения, зашиф- рованного на трехроторной Энигме, мо-жет уйти двадцать четыре часа, посколь-ку бомбы пробивались сквозь миллиарды перестановок. Работа четырехроторной Энигмы, умножающей числа на двадцать шесть порядков, теоретически заняла бы добрую часть месяца. Enigma, стр. 27 [Harris (1996)] Довольно любопытно, что мы можем проектировать процедуры, которые, столк - нувшись с изобилием вариантов, вместо того чтобы кропотливо изучать все воз-можные ответы на эти варианты, подбрасывают монетку, чтобы решить, в какую сторону идти, и, несмотря на это, «как правило», получают правильный результат. Совершенно очевидно, что когда прибегаем к случайности, мы экономим вре- мя, но совершенно удивительно то, что результаты таких процедур могут быть содержательными. То есть существуют задачи, решение которых кажется вычис - лительно очень трудным, но когда допускается использование случайности, по-является возможность проектировать процедуры, которые решают эти сложные задачи удовлетворительно: результат этой процедуры является правильным с не-большой вероятностью ошибки. На самом деле эта ошибка может быть настолько мала, что становится ничтожной (скажем, 1 к 2 100 – что равно примерному числу атомов в наблюдаемой Вселенной). Таким образом, многие эксперты считают, что определение «допустимо вычислимого» должно подразумевать «вычислимое за полиномиальное время со случайностью», а не просто «за полиномиальное вре-мя». Появление рандомизированных алгоритмов было связано с задачей провер-ки простоты (примарности), что, в свою очередь, было вызвано расцветом области криптографии. Исторически первый такой алгоритм появился благодаря работе [Solovay и Strassen (1977)]. Проверка простоты остается одной из лучших задач для демонстрации возможностей рандомизированных алгоритмов; в этой главе мы представим алгоритм Рабина–Миллера, который появился после алгоритма Соловея–Штрассена, но он несколько проще. Интересно отметить, что теперь ши-роко известен полиномиально-временной алгоритм проверки простоты (благо-даря работе [Agrawal и соавт. (2004)]), но алгоритм Рабина–Миллера по-прежнему\n--- Страница 115 ---\n114  Рандомизированные алгоритмы используется на практике, поскольку он эффективнее (и его вероятность ошибки незначительна). В этой главе мы представим три примера рандомизированных алгоритмов: ал- горитм идеального паросочетания, сопоставление со строковым образцом и, на-конец, алгоритм Рабина–Миллера. В заключение мы поговорим о криптографии. 6.1. и деальное паросоЧетание Рассмотрим двудольный граф G = (V ⋃ V′, E), где E ⊆ V × V′. Его матрица смежности определяется следующим образом: (AG)ij = xij, если (i, j′) ∈ EG, и (AG)ij = 0 в противном случае. См. пример, приведенный на рис. 6.1. 1 2341′2′3′4′ x11 0 00000 x 430 x22 0000 x 34 0 Рис. 6.1  Слева мы имеем двудольный граф G = (V ⋃ V′, E), где V = {1, 2, 3, 4}, V′ = {1 ′, 2′, 3′, 4′} и E ⊆ V × V ′, E = {(1, 1′), (2, 2′), (3, 4′), (4, 3′)}. Справа мы имеем соответствующую матрицу смежности AG Пусть Sn равно множеству всех перестановок n элементов. Точнее, Sn является множеством биекций (взаимно-однозначных соответствий) σ : [n] → [n]. Ясно, что |Sn| = n!, и из алгебры хорошо известно, что любая перестановка σ ∈ Sn может быть записана как произведение перемещений, или транспозиций (то есть переста- новок, которые обмениваются двумя элементами в [n] и оставляют все осталь-ные элементы нетронутыми). Любая перестановка в S n может быть записана как произведение перемещений, и хотя существует много способов это проделать (то есть представление перемещений не является уникальным), четность числа пере-мещений постоянна для любой данной перестановки σ. Пусть sgn(σ) равно 1 либо –1, в зависимости от четности σ, соответственно, четной или нечетной. Напомним формулу Лагранжа для определителя: det(A) = σ∈Sn sgn(σ) i=1n Aiσ(i). (6.1) Лемма 6.1. Пусть G = (V ⋃ V′, E) равно графу, где n = |V| = |V′| и E ⊆ V × V′. Тогда граф G имеет идеальное паросочетание (то есть каждая вершина в V может быть спарена с уникальной вершиной в V′) тогда и только тогда, когда имеет место, что det(AG) = åσ∈S n sgn(σ)∏n i=1(AG)iσ(i) ≠ 0. Задача 6.2. Докажите лемму 6.1. Поскольку |Sn| = n!, вычисление суммирования над всеми σ в Sn, как и в (6.1), вычислительно очень дорого, поэтому мы случайно назначаем значения элемен-\n--- Страница 116 ---\nИдеальное паросочетание  115 там xij. Целочисленный определитель, в отличие от символического, может быть вычислен очень эффективно – например, с помощью алгоритма Берковица. Пусть AG(x1, , xm), m = |EG| равно AG, где ее переменные переименованы в x1, , xm. Об - ратите внимание, что m ≤ n2 и каждый xi представляет некоторое xij. Мы получаем рандомизированный алгоритм для задачи идеального паросочетания – см. алго- ритм 6.1. Алгоритм 6.1. Идеальное паросочетание Выбрать m случайных целых чисел i1, , im в {1, , M}, где M = 2m вычислить целочисленный определитель матрицы AG(i1, , im) if det(AG(i1, , im)) ≠ 0 then return да, G имеет идельное паросочетание else return нет, G, вероятно, не имеет идеального паросочетания end if Алгоритм 6.1 представляет собой алгоритм Монте-Карло с полиномиальным временем выполнения: ответы «да» являются надежными и окончательными, в то время как ответы «нет» находятся под угрозой ложного отрицания. Ложное отрицание может возникнуть следующим образом: G может иметь идеальное па- росочетание, но (i 1, , im) может оказаться корнем многочлена det(AG(x1, , xm)). Однако, как мы вскоре увидим, вероятность ложного отрицания (то есть вероят - ность ошибки) можно сделать ничтожно малой. В строке 1 алгоритма 6.1 мы несколько загадочно говорим: «Выбрать m случай- ных чисел». Каким образом мы «выбираем» эти случайные числа? Оказывается, ответить на этот вопрос непросто, а получение источника случайности является ахиллесовой пятой рандомизированных алгоритмов. В нашем распоряжении есть наука о генераторах псевдослучайных чисел и другие подходы, но эта огромная тема выходит за рамки настоящей книги, и поэтому мы наивно предположим, что у нас есть «некий источник случайности». Мы хотим показать правильность на-шего рандомизированного алгоритма, поэтому нам нужно показать, что вероят - ность ошибки ничтожно мала. Начнем с леммы Шварца–Зиппеля. Лемма 6.3 (Шварца–Зиппеля). Рассмотрим многочлены над �, и пусть p(x 1, , xm) ≠ 0 равно многочлену, где степень каждой переменной ≤ d (когда многочлен записан как сумма одночленов), и пусть M > 0. Тогда число m-членных кортежей (i1, , im) ∈ {1, 2, , M }m таких, что p(i1, , im) = 0, равно ≤ mdMm–1. Доказательство. Индукция на m (числе переменных). Если m = 1, то по основной теореме алгебры p(x1) может иметь не более d = 1 · d · M1–1 корней. Предположим, что лемма соблюдается для (m – 1), и теперь мы хотим дать верх - нюю границу mdMm–1 на числе кортежей (i1, , im) таких, что p(i1, , im) = 0. Сначала мы записываем p(x1, , xm) как yd xd m + ··· + y0 x0 m, где каждый коэффициент yi = yi(x1, , xm–1) ∈ �[x1, , xm–1]. Так сколько же существует кортежей (i1, , im) таких, что p(i1, , im) = 0? Мы раз- биваем такие кортежи на два множества: те, которые задают yd = 0, и те, которые этого не делают. Результат ограничен сверху суммой верхних границ двух мно- жеств; теперь мы дадим эти верхние границы.\n--- Страница 117 ---\n116  Рандомизированные алгоритмы Множество 1. По индукционной гипотезе yd равно нулю для не более (m – 1) dMm–2 числа (i1, , im–1) кортежей, и xm может принимать M значений, поэтому p(x1, , xm) равно нулю для не более (m – 1) dMm–1 кортежей. Обратите внимание, что здесь мы переоцениваем; мы берем все кортежи, которые устанавливают yd = 0. Множество 2. Для каждой комбинации Mm–1 значений для x1, , xm–1 существует не более d корней результирующего многочлена (опять же по основной теореме алгебры), то есть dMm–1. Обратите внимание, что мы снова переоцениваем, так как некоторые из этих установок в x1, , xm приведут к yd = 0. Добавление двух верхних границ дает нам mdMm–1. □ Лемма 6.4. Алгоритм 6.1 является правильным. Доказательство. Мы хотим показать, что алгоритм 6.1 для идеального паросо- четания является надежным алгоритмом Монте-Карло, что означает, что ответы «да» на 100 % верны, в то время как ответы «нет» допускают незначительную ве- роятность ошибки. Если алгоритм отвечает «да», то det(AG(i1, , im)) ≠ 0 для некоторых случайно отобранных i1, , im, но тогда символический определитель det(AG(x1, , xm)) ≠ 0, и поэтому по лемме 6.1 G имеет идеальное паросочетание. Таким образом, от - веты «да» с абсолютной уверенностью указывают на то, что существует идеальное паросочетание. Предположим, что ответ равен «нет». Тогда мы применяем лемму 6.3 к det(A G(x1, , xm)) с M = 2m и получаем, что вероятность ложного отрицания равна m · d · Mm–1m · 1 · (2m)m–1m 1 Mm(2m)m2m 2≤ = = =. Теперь предположим, что мы проводим «много независимых экспериментов», имея в виду, что мы выполняем алгоритм 6.1 k число раз, всякий раз выбирая случайное множество i1, , im. Тогда если ответ всегда выходит равным нулю, то мы знаем, что вероятность ошибки равна ≤ (–1 2)k = –1 2k. Для k = 100 ошибка становится незначительной. □ В последнем абзаце доказательства леммы 6.4 мы говорим, что выполняем ал- горитм 6.1 k число раз, и таким образом снижаем вероятность ошибки до того, что она меньше, чем –1 2k, которая для k = 100 действительно ничтожно мала. Выпол- нение алгоритма k раз для получения ответа называется амплификацией (потому что мы резко уменьшаем вероятность ошибки и тем самым усиливаем уверен-ность в правильности ответа); обратите внимание, что красота этого подхода за-ключается в том, что пока мы выполняем алгоритм k раз, вероятность ошибки снижается экспоненциально быстро до – 1 2k. Глядя на все в перспективе, если k = 100, то –1 2100 – это такой мизер, что по сравнению с вероятностью попадания в землю большого метеорита – во время работы алгоритма – является виртуальной опре-деленностью (и если уж на то пошло, то попадание большого метеорита избавит любого от необходимости выполнять алгоритмы). Задача 6.5. Покажите, как использовать алгоритм 6.1 для поиска идеального па-\n--- Страница 118 ---\nСопоставление с образцом  117 росочетания. Идеальное паросочетание может быть легко сведено1 в задачу о максимальном потоке: в качестве примера рассмотрим задачу идеального паросочетания, при- веденную на рис. 6.1; добавим два новых узла s, t, свяжем s со всеми узлами в ле- вом столбце задачи паросочетания и свяжем t со всеми узлами в правом столбце задачи паросочетания, дадим каждому ребру емкость 1 и зададимся вопросом, есть ли поток ≥ n (где n – это число узлов в каждой из двух компонент данного двудольного графа) из s в t; см. рис. 6.2. s t… … Рис. 6.2  Сведение идеального паросочетания к максимальному потоку Поскольку задача о максимальном потоке может быть решена за полиноми- альное время без использования случайности, то из этого следует, что идеальное паросочетание также может быть решено за полиномиальное время без случай-ности. Тем не менее смысл этого раздела состоял в том, чтобы показать простой рандомизированный алгоритм, и именно этого мы и достигли. 6.2. сопоставление с образцом В этом разделе мы спроектируем рандомизированный алгоритм сопоставления (паросочетания) с образцом. Рассмотрим множество символьных цепочек, или строк, над {0, 1}, и пусть M : {0, 1} → M 2×2(�), то есть M – это отображение из строк в 2×2-матрицы над целыми числами (�), определяемое следующим образом: M(ε) = �1 0�0 1; M(0) = �1 0�1 1; M(1) = �1 1�0 1, и для строк x, y ∈ {0, 1}∗, M(xy ) = M(x)M(y), где операция с левой стороны является конкатенацией строк, а операция с правой стороны – умножением матриц. Задача 6.6. Покажите, что M(x) хорошо определено, то есть независимо от того, 1 Напомним, что мы кратко рассмотрели идею редуцирования на стр. 83.\n--- Страница 119 ---\n118  Рандомизированные алгоритмы как мы оцениваем M на x, мы всегда получаем один и тот же результат. Также по- кажите, что M взаимно-однозначно. Задача 6.7. Покажите, что для x ∈ {0, 1}n элементы M(x) ограничены n-м числом Фи- боначчи. Формальное определение чисел Фибоначчи см. в задаче 9.5 на стр. 209. Рассматривая матрицы M(x) по модулю подходящего простого числа p, то есть принимая все элементы M(x) по модулю простого числа p, мы выполняем эффек - тивное рандомизированное сопоставление с образцом. Мы хотим определить, является ли x подстрокой y, где |x| = n, | y| = m, n ≤ m. Определим y(i) = yi yi+1 yn+i–1 для соответствующего i ∈ {1, …, m – n + 1}. Выберем простое число p ∈ {1, …, nm2}, и пусть A = M(x) (mod p) и A(i ) = M(y(i )) (mod p). Заметим, что A(i + 1) = M–1(yi)A(i)M(yn+i) (mod p), что делает вычисление последующих A(i ) эффективным. Алгоритм 6.2. Сопоставление с образцом Предусловие: x, y ∈ {0, 1}*, |x| = n, | y| = m и n ≤ m 1: отобрать случайное простое число p ≤ nm2 2: A ← M(x) (mod p) 3: B ← M(y(1)) (mod p) 4: for i = 1, , m – n + 1 do 5: if A = B then 6: if x = y(i ) then 7: return найдено паросочетание в позиции i 8: end if 9: end if 10: B ← M–1(yi) · B · M(yn+i) 11: end for Какова вероятность получения ложного утверждения? Это вероятность того, что A(i) = M(y(i )) (mod p), даже если A(i) ≠ M(y(i )). Это меньше, чем вероятность того, что p ∈ {1, …, nm2} делит (ненулевой) элемент в A(i) – M(y(i )). Поскольку эти элементы ограничены условием Fn < 2n, менее n несовпадающих простых чисел могут разделить любой из них. С другой стороны (по теореме о распределении простых чисел), в {1, …, nm2} существует π(nm2) ≈ (nm2)/(log(nm2)) простых чисел. Таким образом, вероятность ложного утверждения равна O(1/m). Обратите внимание, что алгоритм 6.2 не имеет ошибки; он рандомизирован, но все потенциальные ответы проверяются на ложное утверждение (в строке 6 алгоритма). Проверка этих потенциальных кандидатов называется снятием от- печатков пальцев. Идея снятия отпечатков пальцев состоит в том, чтобы прове-рять только те подстроки, которые «выглядят» как хорошие кандидаты, гаранти-руя, что когда мы «вынюхиваем» кандидата, мы никогда не пропустим решение (в этом случае если x = y(i ) для некоторого i, то y(i) всегда будет кандидатом). С другой стороны, могут быть j такие, что x ≠ y(j), и все же они являются канди- датами; но вероятность этого мала. Использование случайности в алгоритме 6.2\n--- Страница 120 ---\nПроверка простоты  119 просто снижает средневременную сложность процедуры; такие алгоритмы назы- ваются алгоритмами Лас-Вегас. 6.3. п роверка простоты Один из способов определить, является ли число p простым, – попробовать все возможные числа n < p и проверить, являются ли они делителями1. Очевидно, что эта процедура методом грубой силы имеет экспоненциально-временную слож - ность по длине p, и поэтому она имеет запредельную временную стоимость. Хотя полиномиально-временной (детерминированный) алгоритм для примарности (определения простоты) теперь известен (см. работу [Agrawal и соавт. (2004)]), рандомизированный алгоритм Рабина–Миллера для проверки простоты проще и эффективнее и поэтому до сих пор используется на практике. Малая теорема Ферма (см. теорему 9.22) предоставляет своего рода «тест» на простоту, называемый проверкой Ферма; алгоритм Рабина–Миллера (алго-ритм 6.3) основан на этой проверке. Когда мы говорим, что p проходит проверку Ферма в a, мы имеем в виду, что a (p–1) ≡ 1 (mod p). Таким образом, все простые числа проходят проверку Ферма для всех a ∈ �p – {0}. К сожалению, существуют также составные числа n, которые проходят проверки Ферма для каждого a ∈ �∗ n; это так называемые числа Кармайкла, например 561, 1105, 1729 и т. д. Лемма 6.8. Если p равно составному числу не Кармайкла, то оно проходит не бо- лее половины проверок в �∗ p. То есть если p равно составному числу не Кармайкла, то для большей половины a во множестве �∗ p имеет место, что a(p–1) ≡ 1 (mod p). Доказательство. Мы говорим, что а является свидетелем p, если а не проходит проверку Ферма для р. То есть а является свидетелем, если a(p–1) ≢ 1. Пусть S ⊆ �∗ p со- стоит из тех элементов a ∈ �∗ p, для которых a(p–1) ≡ 1 (mod p). Легко проверить, что S является на самом деле подгруппой �∗ p. Следовательно, по теореме Лагранжа (тео- рема 9.2.3) |S | должно делить |�∗ p|. Предположим теперь, что существует элемент a ∈ �∗ p, для которого a(p–1) ≢ 1 (mod p). Тогда S ≠ �∗ p, поэтому лучшее, чем оно может быть, – это «половина» �∗ p, поэтому |S | должно быть не более половины |�∗ p|. □ Задача 6.9. Дайте альтернативное доказательство леммы 6.8 без групп. Некое число является псевдопростым, если оно является либо простым, либо Кармайкла. Последняя лемма наводит на мысль об алгоритме для проверки псев- допростоты: на входном p проверить истинность a(p–1) ≡ 1 (mod p) для некоторого случайного a ∈ �∗ p – {0}. Если p не проходит эту проверку (то есть a(p–1) ≢ 1 (mod p)), то р точно является составным. Если р проходит эту проверку, то р, вероятно, являет - ся псевдопростым. Мы показываем, что вероятность ошибки в данном случае со-ставляет ≤ 1/2. Предположим, что р не является псевдопростым. Если gcd(a, p) ≠ 1, то a (p–1) ≢ 1 (mod p) (по пропозиции 9.20), поэтому, исходя из того что p прошло проверку, действительно должно иметь место, что gcd(a, p) = 1, и поэтому a ∈ �∗ p. Но тогда, по лемме 6.8, по крайней мере, половина элементов �∗ p являются свиде- 1 Этот раздел требует немного знаний теории чисел; см. раздел 9.2 для получения всей необходимой общей информации.\n--- Страница 121 ---\n120  Рандомизированные алгоритмы телями не псевдопростоты. Задача 6.10. Покажите, что если gcd(a, p) ≠ 1, то a(p–1) ≢ 1 (mod p). Неформальный алгоритм псевдопростоты, описанный в предыдущем абзаце, является основой для алгоритма Рабина–Миллера, который мы обсудим далее. Алгоритм Рабина–Миллера расширяет проверку псевдопростоты для работы с числами Кармайкла. Алгоритм 6.3. Рабин–Миллер 1: Если n = 2, принять; если n является четным и n > 2, отклонить. 2: Выбрать случайно положительное а в � n. 3: if a(n – 1) ≢ 1 (mod n) then 4: отклонить 5: else6: Отыскать s, h такие, что s является нечетным и n – 1 = s2 h 7: Вычислить последовательность as·20, as·21, as·22, , as·2h (mod n) 8: if все элементы в последовательности равны 1 then 9: принять 10: else if последний элемент, отличный от 1, равен –1 then 11: принять 12: else 13: отклонить 14: end if 15: end if Обратите внимание, что этот алгоритм является полиномиально-временным (рандомизированным) алгоритмом: вычисление степеней (mod n) может быть эффективно выполнено с помощью многократного возведения в квадрат – напри- мер, если (n – 1)b = cr … c1c0, то вычислить a0 = a, a1 = a2 0, a2 = a2 1, , ar = a2 r–1 (mod n), и поэтому an–1 = a0c0 a1c1 ··· arcr (mod n). Таким образом, получение степеней в строках 6 и 7 не является проблемой. Задача 6.11. Реализуйте алгоритм Рабина–Миллера. В первой наивной версии алгоритм должен работать на целочисленных входах (встроенном типе int). Во второй, более сложной версии алгоритм должен выполняться на входах в виде чи- сел, закодированных как двоичные строки, с трюком многократного возведения в квадрат, чтобы справиться с большими числами. Теорема 6.12. Если n является простым числом, то алгоритм Рабина–Миллера его принимает; если n является составным, то алгоритм его отклоняет с вероят - ностью ≥ 1/2.Доказательство. Если n является простым числом, то по малой теореме Ферма a (n–1) ≡ 1 (mod n), поэтому строка 4 алгоритма не может отклонить n. Предполо- жим, что строка 13 отклоняет n; тогда существует b в �n такое, что b2 ≢ ±1 (mod n)\n--- Страница 122 ---\nПроверка простоты  121 и b2 = 1 (mod n). Поэтому b2 – 1 ≡ 0 (mod n), а следовательно: (b – 1)(b + 1) ≡ 0 (mod n). Поскольку b ≢ ±1 (mod n), то и (b – 1), и (b + 1) расположены строго между 0 и n, и поэтому простое n не может разделить их произведение. Это создает противоре- чие, и поэтому такого b не существует, и поэтому строка 13 не может отклонить n. Если n является нечетным составным числом, то мы говорим, что a является свидетелем («составности») для n, если алгоритм отклоняет на а. Мы показываем, что если n является нечетным составным числом, то, по крайней мере, 50 % а в �n являются свидетелями. Распределение этих свидетелей в �n выглядит очень не- регулярным, но если мы выберем наше a случайно, то мы попадем в свидетеля с вероятностью ≥ –1 2. Поскольку n является составным числом, то либо n является степенью нечетно- го простого числа, либо n является произведением двух нечетных взаимно прос - тых чисел. В результате получаем два случая. Случай 1: предположим, что n = qe, где q – это нечетное простое и e > 1. Устано- вим t := 1 + qe–1. Из биномиального разложения tn получаем: tn = (1 + qe–1)n = 1 + nqe–1 + ån i=2 n l (qe–1)l, (6.2) и поэтому tn ≡ 1 (mod n). Если tn–1 ≡ 1 (mod n), то tn ≡ t (mod n), что из наблюдения о t и tn невозможно, следовательно, t является свидетелем в строке 4. Но множество несвидетелей в строке 4, S1 := {a ∈ �n|a(n–1) ≡ 1 (mod n)}, является подгруппой �n, и поскольку она не равна �n (t в нем не находится), по теореме Лагранжа S1 равно не больше половины �∗ n, и поэтому оно не больше половины �n. Случай 2: предположим, что n = qr, где q, r являются взаимно простыми. Среди всех несвидетелей в строке 13 найдем несвидетеля, для которого –1 появляется в наибольшей позиции в последовательности в строке 7 алгоритма (обратите вни-мание, что –1 является несвидетелем в строке 13, поэтому множество этих несви-детелей не пустое). Пусть x равно такому несвидетелю, и пусть j равно позиции –1 в своей последовательности, где позиции нумеруются, начиная с 0; x s·2j ≡ –1 (mod n) и xs·2j+1 ≡ 1 (mod n). Несвидетели в строке 13 являются подмножеством S2 := {a ∈ �∗ n|as·2j ≡ ±1 (mod n)}, и S2 является подгруппой �∗ n. По китайской теореме об остатках существует t ∈ �n такое, что t ≡ x (mod q) ⇒ ts·2j ≡ –1 (mod q) t ≡ 1 (mod r) ts·2j ≡ 1 (mod r). Следовательно, t является свидетелем, потому что ts·2j ≢ ±1 (mod n), но с другой стороны, ts·2j+1 ≡ 1 (mod n). Задача 6.13. Покажите, что ts·2j ≢ ±1 (mod n). Поэтому, как и в случае 1, мы сконструировали t ∈ �∗ n, которое не находится в S2, и поэтому S2 может быть не больше половины �∗ n, и, значит, по крайней мере, 50 % элементов в �n являются свидетелями. □ Задача 6.14. Сначала покажите, что множества S1 и S2 (в доказательстве теоре- мы 6.12) действительно являются подгруппами �∗ n и что в случае 2 все несвидете-\n--- Страница 123 ---\n122  Рандомизированные алгоритмы ли содержатся в S2. Затем покажите, что, по крайней мере, 50 % элементов �n явля- ются свидетелями, когда n является составным, без использования теории групп. Обратите внимание, что, выполнив алгоритм k раз на независимо выбран- ном a, мы можем убедиться, что он отклоняет составное число с вероятностью ≥ 1 – –1 2k (он всегда будет принимать простое число с вероятностью 1). Таким образом, для k = 100 вероятность ошибки, то есть ложного утверждения, ничтожна. 6.4. ш ифрование с пУблиЧным клюЧом Шифрование (криптография) имеет широко известные применения в сфере безо- пасности, например мы можем использовать наши кредитные карты при покупке онлайн, потому что когда мы посылаем наши номера кредитных карт, они шиф-руются, и даже если они проходят через публичный канал, никто, кроме получа-теля, не сможет их прочесть. Шифрование также имеет увлекательную историю: от первых применений, зафиксированных Геродотом во время персидских войн V века до нашей эры, до разработок в Блетчли-Парке во время Второй мировой войны – читатель, интересующийся историей криптографии, должен прочитать вот эту увлекательную книгу [Singh (1999)]. Криптосистема с публичным ключом (public key cryptosystem, PKC) состоит из трех множеств: K, множества (из пар) ключей, M, множества простых текстовых сообщений, и C, множества зашифрованных текстовых сообщений. Пара ключей в K равна k = (k priv, kpub): соответственно, приватный (секретный) ключ и публичный (от - крытый) ключ. Для каждого kpub существует соответствующая шифрующая функ - ция ekpub : M → C, и для каждого kpriv существует соответствующая дешифрующая функция dkpriv : C → M. Свойство, которому должны удовлетворять шифрующая и дешифрующая функ - ции, заключается в том, что если K = (kpriv, kpub) ∈ K, тогда dkpriv(ekpub(m)) = m для всех m ∈ M. Необходимое допущение состоит в том, что вычислить dkpriv(с), просто зная kpub и c, должно быть трудно. Но с дополнительной потайной информацией kpriv вы- числить dkpriv(с) становится легко. В следующих разделах мы представляем три разные схемы шифрования: схе- му Диффи–Хеллмана, которая на самом деле не является схемой шифрования с публичным ключом, а скорее способом согласования секретного ключа по не-безопасному каналу, а также схемы Эль-Гамаля и RSA (аббревиатура от фамилий Rivest, Shamir и Adleman). Все три требуют больших простых чисел (на практике длиной около 2000 бит); одно простое число для схем Диффи–Хеллмана и Эль-Гамаля и пара простых чисел для схемы RSA. Но как находить большие простые числа? Ответ, конечно же, будет предусматривать использование алгоритма Раби-на–Миллера из предыдущего раздела. Вот как мы это делаем: по теореме о распределении простых чисел мы знаем, что существует π(n) = n/log n простых чисел ≤ n. Это означает, что среди n-битных целых чисел существует 2 n/n простых чисел, примерно 1 в n, и эти простые чис - ла довольно равномерно распределены. Поэтому мы выбираем случайное целое число в заданном диапазоне и применяем к нему алгоритм Рабина–Миллера. 6.4.1. Обмен ключами Диффи–Хеллмана\n--- Страница 124 ---\nШифрование с публичным ключом  123 Если p является простым, то можно показать – хотя доказать это трудно, и мы это здесь опускаем, – что существует g ∈ �∗ p такое, что �g� = {g1, g2, , gp–1} = �∗ p. Данное g называется первообразным корнем для �∗ p. Пусть дано h ∈ �∗ p, тогда задача дискрет- ного логарифмирования является задачей нахождения x ∈ {1, …, p – 1} такого, что gx ≡ h (mod p). То есть x = logg(h). Например, p = 56 609 является простым числом, и g = 2 является генератором для �∗ 56 609, то есть �∗ 56 609 = {21, 22, 23, , 256 608} и log2(38 679) = 11 235. Задача 6.15. Если p = 7, объясните, почему g = 3 будет работать как генератор для �∗ p. Является ли каждое число в �∗ 7 генератором для �∗ 7? Дискретное логарфимирование считается сложной задачей. Мы намереваемся использовать его, чтобы создать для Алисы и Боба способ договориться о секрет - ном ключе по небезопасному каналу. Сначала Алиса и Боб соглашаются на боль- шое простое число p и целое число g ∈ �∗ p. На самом деле g не обязательно должно быть первообразным корнем для p; достаточно и гораздо проще выбрать число g порядка примерно p/2. См., например, упражнение 1.31 в книге [Hoffstein и соавт. (2008)]. Числа p, g являются общеизвестными, то есть kpub = �p, g�. Затем Алиса выбирает секрет а и Боб выбирает секрет b. Алиса вычисляет A := ga (mod p), и Боб вычисляет B := gb (mod p). Затем Алиса и Боб обмениваются A и B по небезопасному соединению. С ее стороны Алиса вычисляет A′ := Ba (mod p), и Боб с его стороны вычисляет B′ := Ab (mod p). Очевидно, что A′ ≡p Ba ≡p (gb)a ≡p gab ≡p (ga)b ≡p Ab ≡p B′. Это общее значение A′ = B′ является их секретным ключом. Таким образом, схема Диффи–Хеллмана на самом деле не является полноценной криптосисте-мой с публичным ключом; это просто способ для двух сторон договориваться о секретном значении по небезопасному каналу. Также обратите внимание, что вычисление A и B предусматривает вычисление больших степеней g по модулю простого p; если это делается наивно, умножая g на само себя а число раз, то эта процедура непрактична для большого a. Вместо этого мы используем многократ - ное возведение в квадрат; см. стр. 120, где мы обсуждаем эту процедуру. Задача 6.16. Предположим, что Алиса и Боб соглашаются на p = 23 и g = 5 и что секрет Алисы a = 8, а секрет Боба b = 15. Покажите, как работает обмен Диффи– Хеллмана в этом случае. Каким будет результирующий секретный ключ? Предположим, что Ева подслушивает этот обмен. Из него она может почерп- нуть следующую информацию: �p, g, g a (mod p), gb (mod p)�. Вычисление из этой ин- формации gab (mod p) (то есть A′ = B′) называется задачей Диффи–Хеллмана (DHP) и считается сложной, когда p является большим простым числом. Но предположим, что у Евы есть эффективный способ решения задачи Диф- фи–Хеллмана. Тогда из ga (mod p) она вычисляет а, и из gb (mod p) она вычисляет b, и теперь она может легко вычислить gab (mod p). С другой стороны, неизвестно, дает ли решение задачи Диффи–Хеллмана эффективное решение.Задача 6.17. Рассмотрите алгоритм Шэнка – алгоритм 6.4. Покажите, что алго- ритм Шэнка вычисляет x такое, что g x ≡p h за время O(n log n), то есть за время O(p log( p)).\n--- Страница 125 ---\n124  Рандомизированные алгоритмы Задача 6.18. Реализуйте алгоритм 6.4. Алгоритм 6.4. Малые и гигантские шаги Шэнка Предусловие: p простое, � g� = �* p, h ∈ �* p 1: n ← 1 + p 2: L1 ← {g0, g1, g2, , gn} (mod p) 3: L2 ← {hg0, hg–n, hg–2n, , hg–n2} (mod p) 4: Найти gi ≡p hg–jn ∈ L1 ⋂ L2 5: x ← jn + i 6: return x Постусловие: gx ≡p h Хотя кажется, что трудно организовать прямую атаку на схему Диффи–Хеллма- на, то есть атаковать ее, решив родственную задачу дискретного логарифмиро-вания, существует довольно коварный способ ее взломать, который называется атакой «человек в середине» (man-in-the-middle). Он заключается в том, что Ева пользуется отсутствием аутентификации сторон; то есть откуда Боб знает, что он получает сообщение от Алисы, и откуда Алиса знает, что она получает сообще-ние от Боба? Ева может воспользоваться этим и перехватить предназначенное для Боба сообщение от Алисы и заменить его на E = g e (mod p), перехватить пред- назначенное для Алисы сообщение от Боба и также заменить его на E = ge (mod p), и с того момента читать всю переписку, притворяясь Бобом для Алисы и Алисой для Боба, транслируя сообщение, закодированное с помощью g ae (mod p) в сообще- ние, закодированное с помощью gbe (mod p), и наоборот. Задача 6.19. Предположим, что f : � × � → � является функцией со следующими свойствами: для всех a, b, g ∈ �, f(g, ab) = f(f( g, a), b) = f(f( g, b), a); для любого g, hg(c) = f(g, c) является односторонней функцией, то есть функ - цией, которую легко вычислить, но обратное которой вычислить трудно1. Объясните, как можно использовать f для шифрования с публичным ключом в стиле Диффи–Хеллмана. 6.4.2. Криптосистема Эль-Гамаля Эта схема является истинной криптографией с публичным ключом, где Алиса и Боб соглашаются о публичных p, g таких, что p – это простое число, и � ∗ p = �g�. Алиса также имеет частный a и публикует публичный A := ga (mod p). Боб хочет от - править сообщение m Алисе, поэтому он создает эфемерный ключ b и отправляет пару c1, c2 Алисе, где: c1 := gb (mod p); c2 := mAb (mod p). Затем, чтобы прочитать сообщение, Алиса вычисляет: c1–a c2 ≡p g–ab mgab ≡p m. 1 Существование таких функций является одним из базовых допущений криптографии; дискретный логарифм является примером такой функции, однако доказательство ее су - ществования отсутствует, существует только хорошо обоснованное допущение.\n--- Страница 126 ---\nШифрование с публичным ключом  125 Обратите внимание, что для вычисления c1–a Алиса сначала вычисляет обрат - ное c1 в �∗ p, что она может сделать эффективно, используя расширенный алгоритм Евклида (см. алгоритм 1.8 или алгоритм 3.5), а затем вычисляет a-ю степень ре- зультата. Если точнее, то вот как мы вычисляем обратное k в �∗ n. Наблюдаем, что если k ∈ �∗ p, то gcd(k, n) = 1, поэтому, используя алгоритм 1.8, мы получаем s, t такие, что sk + tn = 1, и далее s, t могут быть выбраны с целью, чтобы s было в �∗ n. Для того чтобы это увидеть, сначала получаем любое s, t, а затем добавляем в s соот - ветствующее число положительных или отрицательных кратных n, помещая его во множество �∗ n, и корректируем t на то же самое число кратных с противопо- ложным знаком. Задача 6.20. Пусть p = 7 и g = 3. 1. Пусть а = 4 равно секретному ключу Алисы, поэтомуA = g a (mod p) = 34 (mod 7) = 4. Пусть p = 7, g = 3, A = 4 равны публичным значениям. Предположим, что Боб хочет отправить сообщение m = 2 Алисе с эфемер- ным ключом b = 5. Какую соответствующую пару �c1, c2� он посылает Алисе? Покажите, какими будут фактические значения и как они вычисляются. 2. Что делает Алиса для прочтения сообщения �5, 4 �? То есть как Алиса извле- кает m из �c1, c2� = �5, 4�? Задача 6.21. Мы говорим, что можем взломать схему Эль-Гамаля, если у нас есть эффективный способ вычисления m из �p, g, A, c1, c2�. Покажите, что мы можем взломать схему Эль-Гамаля тогда и только тогда, когда мы можем эффективно ре- шить задачу Диффи–Хеллмана. Задача 6.22. Напишите приложение, в котором реализуется схема цифровой подпи си Эль-Гамаля. Ваша консольная программа должна вызываться следую- щим образом: sign 11 6 3 7 – затем примите одну символьную цепочку текста в формате ASCII, пока не появится символ новой строки (то есть пока вы не на- жмете клавишу Enter). То есть, после того как вы наберете в командной строке sign 11 6 3 7 и нажмете Return, вы наберете сообщение: 'A message' (сообщение), и после того как вы нажмете Return снова, ниже появится цифровая подпись, со- стоящая из пары положительных целых чисел. Теперь мы объясним, как получить эту цифровую подпись: сначала преобра- зуйте символы в символьной цепочке «A message» в соответствующие коды ASCII, а затем получите хеш этих кодов, умножив их все по модулю 11; в результате должно получиться одно число 5. Для того чтобы это увидеть, посмотрите таблицу: A 65 10 32 1m 109 10e 101 9s 115 1s 115 5a 97 1g 103 4\n--- Страница 127 ---\n126  Рандомизированные алгоритмы e 101 8 . 46 5 Первый столбец содержит символы, второй – соответствующие коды ASCII, и i-я ячейка в третьем столбце содержит произведение первых i кодов по модулю 11. Последняя ячейка в третьем столбце является хеш-значением 5. Мы подписываем хеш-значение, то есть если сообщение m = A message , то мы подписываем hash(m) = 5. Обратите внимание, что мы вызываем функцию sign с четырьмя аргументами, то есть мы вызываем ее с p, g, x, k (в нашем рабочем при- мере соответственно 11, 6, 3, 7). Здесь p должно быть простым, 1 < g, x, k < p – 1 и gcd(k, p – 1) = 1. Это условие вво- да; в своей программе вам проверять выполнение этого условия не нужно – мы можем допустить, что это так. Теперь алгоритм подписывает h(m) следующим образом: он вычисляет r = gk (mod p) s = k–1(h(m) – xr) (mod (p – 1)). Если s равно нулю, то начните сначала, выбрав другой k (соответствующий тре- буемым условиям). Подпись m представляет собой именно пару чисел (r, s). В на- шем рабочем примере мы имеем следующие значения: m = A message ; h(m) = 5; p = 11; g = 6; x = 3; k = 7, и поэтому подпись « A message » с заданными параметрами будет: r = 67 (mod 11) = 8 s = 7–1(5 – 3 · 8) (mod (11 – 1)) = 3 · (–19) (mod 10) = 3 · 1 (mod 10) = 3, то есть подпись « A message » будет (r, s) = (8, 3). Задача 6.23. В задаче 6.22: 1) можете ли вы установить (возможные) недостатки этой схемы цифровой подпи си? Можете ли вы составить другое сообщение m′ такое, что h(m) = h(m′)? 2) если вы получаете сообщение m и подписную пару (r, s), и вы лишь знаете p, g и y = gx (mod р), то есть p, g, y являются публичной информацией, как вы можете «верифицировать» подпись – и что подразумевается под верифика-цией подписи? 3) разыщите в интернете более оптимальный вариант хеш-функции h; 4) покажите, что при использовании без (хорошей) хеш-функции схема подпи-си Эль-Гамаля экзистенциально поддается подделке; то есть злоумышлен-ница Ева может сконструировать сообщение m и валидную подпись (r, s) для m; 5) на практике k представляет собой случайное число; покажите, что абсолют - но необходимо выбирать новое случайное число для каждого сообщения; 6) покажите, что при верификации подписи необходимо проверять, соблю-дается ли 1 ≤ r ≤ p – 1, потому что в противном случае Ева будет способна\n--- Страница 128 ---\nШифрование с публичным ключом  127 подписывать сообщение по своему выбору, при условии что она знает одну валидную подпись (r, s) для некого сообщения m, где m такое, что 1 ≤ m ≤ p – 1 и gcd(m, p – 1) = 1. 6.4.3. Криптосистема RSA Выберем два нечетных простых числа p, q и установим n = pq. Выберем k ∈ �∗ φ(n), k > 1. Объявим f, где f(m) ≡ mk (mod n). Вычислим l, обратное k в �∗ φ(n). Теперь (n, k) является публичным, и ключ l является секретным, а также и функция g, где g(C) ≡ Cl (mod n). Обратите внимание, что g( f(m)) ≡n mkl ≡n m. Задача 6.24. Покажите, что mkl ≡ m (mod n). На самом деле, для того чтобы это соблю далось, существует неявное допущение о m; что это за допущение? Задача 6.25. Подтвердите наблюдение, что мы могли бы взломать RSA, если бы разложение на составляющие было бы легким. Теперь мы сделаем два наблюдения о безопасности RSA. Во-первых, простые числа p, q не могут быть выбраны «близко» друг к другу. Для того чтобы понять, что мы имеем в виду, обратите внимание, что n = p + q 22 – p – q 22 . Поскольку p, q близки, мы знаем, что s := (p – q)/2 является малым, и t := (p + q)/2 лишь слегка больше n, и t2 – n = s2 представляет собой идеальный квадрат. Поэто- му мы пробуем следующие кандидатные значения для t: ⌈n⌉ + 0, ⌈ n⌉ + 1, ⌈ n⌉ + 2, До тех пор, пока t2 – n не будет идеальным квадратом s2. Ясно, что если s являет - ся малым, то мы быстро найдем такое t, и тогда p = t + s и q = t – s. Второе наблюдение состоит в том, что если бы мы могли взломать RSA путем эффективного вычисления l из n и k, то мы могли бы разложить n за рандомизи- рованное полиномиальное время. Поскольку φ(n) = φ(pq) = (p – 1)(q – 1), из этого следует, что: p + q = n – φ(n) + 1 pq = n, (6.3) и из этих двух уравнений мы получаем: (x – p)(x – q) = x2 – (p + q)x + pq = x2 – (n – φ(n) + 1)x + n. Таким образом, мы можем вычислить p, q, вычислив корни этого последнего многочлена. Используя классическую формулу квадратного уравнения x = (–b ± b2 – 4ac)/2a, мы получаем, что p, q равняются: (n − φ(n) + 1) ± (n − φ(n) + 1)2 − 4n. 2 Предположим, что Ева способна вычислить l из n и k. Если Ева знает l, тогда она знает, что каким бы ни была φ(n), она делит kl – 1 и, значит, Ева имеет уравнения (6.3) с той разницей, что φ(n) заменена на (kl – 1)/a для некоторого а. Это а может\n--- Страница 129 ---\n128  Рандомизированные алгоритмы быть вычислено за рандомизированное полиномиальное время, но мы его здесь не приводим. Тем самым следует утверждение. Если Ева способна факторизовать, то она, очевидно, способна взломать RSA; с другой стороны, если Ева способна взломать RSA – путем вычисления l из n, k, – то, значит, она способна факторизовать за рандомизированное полиномиальное время. С другой стороны, Ева может быть способна взломать RSA без вычисления l, поэтому из предыдущих наблюдений не вытекает, что взлом RSA представляет такую же трудность, что и факторизация. 6.5. дальнейшие зада Чи В криптографии существует определенный разворот приоритетов в том, что слож - ная задача становится союзником, а не препятствием. На стр. 75 мы упомянули NP-трудные задачи, то есть задачи, для которых нет допустимых решений, когда экземпляры «достаточно велики». Простая задача о рюкзаке (см. раздел 4.3) является одной из таких задач, и мы можем использовать ее для определения криптосистемы. Криптосистема Мерк - ла–Хеллмана сумм подмножеств основана на задаче о рюкзаке и работает следу - ющим образом. Сначала Алиса создает секретный ключ, состоящий из следующих элементов: сверхвозрастающая последовательность: r = (r 1, r2, , rn), где ri ∈ �, и свой- ство быть «сверхвозврастающим» относится к 2ri ≤ ri+1, для всех 1 ≤ i < n; пара положительных целых чисел A, B с двумя условиями: 2rn < B и gcd(A, B) = 1. Публичный ключ состоит из M = (M1, M2, , Mn), где Mi = Ari (mod B). Предположим, что Боб хочет отправить текстовое сообщение x ∈ {0, 1}n, то есть x является двоичной строкой длины n. Тогда он использует открытый ключ Алисы для вычисления S = ån i=1 xi Mi, где xi – это i-й бит x, интерпретируемый как целое число 0 или 1. Боб теперь посылает S Алисе. Для того чтобы прочитать сообщение, Алиса вычисляет S′ = A–1S (mod B), и она решает задачу о сумме подмножеств с использованием сверхвозврастающего r. Задача о сумме подмножеств для общей последовательности r является очень сложной, но когда r является сверхвозврастающим (отметим, что М принимается как несверхвозврастающая!), эту задачу можно решить простым жадным алго- ритмом. Точнее, Алиса находит подмножество r, сумма которого в точности равна S′. Любое подмножество r можно отождествить с двоичной строкой длины n, исходя из допущения, что xi равно 1 тогда и только тогда, когда ri находится в этом под- множестве. Следовательно, Алиса «извлекает» x из S ′. Например, пусть r = (3, 11, 24, 50, 115) и A = 113, B = 250. Проверим, что все усло- вия выполнены, и проверим, что M = (89, 243, 212, 150, 245). Для того чтобы отпра- вить секретное сообщение x = 10101, мы вычисляем S = 1 · 89 + 0 · 243 + 1 · 212 + 0 · 150 + 1 · 245 = 546. Получив S, мы умножаем его на 177, обратное от 113 в mod 250, и получаем 142.\n--- Страница 130 ---\nОтветы к избранным задачам  129 Теперь x может быть извлечено из 142 с помощью простого жадного алгоритма. Задача 6.26. Две части: 1) покажите, что если r = (r1, r2, , rn) является сверхвозрастающей последова- тельностью, то ri+1 > åi j=1 rj для всех 1 ≤ i < n; 2) предположим, что r = (r1, r2, , rn) является сверхвозрастающей последо- вательностью и что существует подмножество r, сумма которого равна S. Предоставьте (естественный) жадный алгоритм вычисления этого подмно- жества и покажите, что ваш алгоритм является правильным. Задача 6.27. Реализуйте криптосистему Меркла–Хеллмана сумм подмножеств. Вызовите программу sscrypt , и она должна работать с тремя переключателями: -e –d -v для шифрования, дешифрования и верификации. То есть sscrypt -e M1 M2 … Mn x шифрует символьную цепочку x = x1x2 … xn ∈ {0, 1}n с открытым ключом, задавае- мым M = (M1, M2, , Mn), и выдает на выходе S. С другой стороны, sscrypt -d r1 r2 … rn A B S расшифровывает символьную цепочку x = x1x2 … xn ∈ {0, 1}n из S с использованием секретного ключа, задаваемого r = (r1, r2, , rn) и A, B; то есть на выходе она выдает x при r, A, B, S на входе. Наконец, sscrypt -v r1 r2 … rn A B проверяет, что r = (r1, r2, , rn) является сверхвозрастающей, она проверяет, что 2rn < B и что gcd(A, B) = 1, и на выходе выдает соответствующий публичный ключ, задаваемый M = (M1, M2, , Mn). 6.6. ответы к избранным зада Чам Задача 6.5. Мы используем алгоритм 6.1, для того чтобы найти идеальное паро- сочетание (если таковое имеется) следующим образом: выбираем 1 ∈ V и по оче- реди рассматриваем каждое (1, i′) ∈ E, удаляем его из G, получая G1,i′ = ((V – {1}) ⋃ (V′ – {i′}), E1,i′), где E1,i′ состоит из всех ребер E, за исключением смежных 1 или i′, до тех пор, пока для некоторой i′ ∈ V′ мы не получим G1,i′, для которых алгоритм дает ответ «да». Тогда мы знаем, что существует идеальное паросочетание, которое со-четает 1 и i′. Продолжаем с G 1,i′. Задача 6.6. M(x) хорошо определено, потому что матричное умножение ассоци- ативно. Теперь мы покажем, что из M(x) = M(y) следует x = y (то есть отображение M является взаимно-однозначным). При условии что M = M(x), мы можем «расшиф- ровать» x уникально следующим образом: если первый столбец M больше второго (где сравнение производится покомпонентно), то последний бит x равен нулю, и в противном случае он равен 1. Принимаем M′ равным M, где мы вычитаем меньший столбец из большего и повторяем. Задача 6.7. Для заданной символьной цепочки x, M(x1x2 … xn) является такой, что «меньший» столбец ограничен числом fn–1 и «больший» столбец ограничен fn. Мы можем показать это индукционно: базовый случай, x = xi, очевиден. В качестве индукционного шага мы принимаем допущение, что он соблюдается для x ∈ {0, 1}n,\n--- Страница 131 ---\n130  Рандомизированные алгоритмы и покажем, что он по-прежнему соблюдается для x ∈ {0, 1}n+1: это ясно, так как независимо от того, равен ли xn+1 значению 0 либо 1, один столбец добавляется в другой, а другой столбец остается неизменным. Задача 6.9. С учетом того, что p является составным и не Кармайклом, сущест - вует, по крайней мере, одно a ∈ �∗ p такое, что a(p–1) ≢ 1 (mod p) и gcd(p, a) = 1. Пусть B = {b1, b2, …} равно множеству несвидетелей. Умножим каждый элемент B на a, по - лучив свидетелей {a1, a2, …}. Каждый из этих свидетелей уникален, так как a ∈ �∗ p, поэтому свидетелей, по крайней мере, столько же, сколько и несвидетелей. Пусть b равно потенциальному несвидетелю; то есть b равняется любому эле- менту �∗ p такому, что gcd(p, b) = 1. Если мы умножим a на любого лжеца Ферма (то есть несвидетеля), то мы получим свидетеля. Если существует только один несви- детель, то доказательство завершено. В противном случае пусть b1, b2 равны двум несвидетелям. Мы знаем, что gcd(p, b1) = gcd(p, b2) = 1, так как в противном случае b1 и b2 были бы свидетелями. Допустим, ab1 = ab2 + kp, и пусть g = gcd(a, p). Задача 6.10. Предположим, что gcd(a, p) ≠ 1. По пропозиции 9.20 мы знаем, что если gcd(a, p) ≠ 1, то a не имеет (мультипликативного) обратного в �p. Таким образом, невозможно, чтобы a(p–1) ≡ 1 (mod p) было истинным, так как из этого сле- дует, что a · a(p–2) ≡ 1 (mod p), и, следовательно, a будет иметь (мультипликативное) обратное. Задача 6.13. Для того чтобы понять, почему ts·2j ≢ ±1 (mod n), сделаем следующее наблюдение: предположим, что a ≡ –1 (mod q) и a ≡ 1 (mod r), где gcd(q, r) = 1. Пред- положим, что n = qr|(a + 1), тогда q|(a + 1) и r|(a + 1), и поскольку также r|(a – 1), из этого следует, что r|[(a + 1) – (a – 1)], поэтому r|2, и поэтому r = 2, а значит, n должно быть четным, что невозможно, поскольку мы имеем дело с четными n в строке 1 алгоритма. Задача 6.14. Показать, что S1 и S2 являются подгруппами �∗ n, достаточно легко; в обоих случаях очевидно, что там имеется 1, и замыкание и существование об-ратного можно легко проверить. Для того чтобы дать то же самое доказательство без теории групп, мы следуем случаям в доказательстве теоремы 6.12. Пусть t равно свидетелю, сконструиро- ванному в случае 1. Если d является (этап 3) несвидетелем, то мы имеем d p–1 ≡ 1 (mod p), но тогда dt (mod p) является свидетелем. Более того, если d1, d2 являются несовпадающими (этап 3) несвидетелями, то d1t ≢ d2t (mod p). В противном случае d1 ≡p d1 · t · tp–1 ≡p d2 · t · tp–1 ≡p d2. Таким образом, число (этап 3) свидетелей должно быть, по крайней мере, таким же большим, как и число несвидетелей. Мы делаем то же самое для случая 2; пусть d равно несвидетелю. Во-первых, ds·2j ≡ ±1 (mod p) и ds·2j+1 ≡ 1 (mod p) вследствие того, как было выбрано j. Поэтому dt (mod p) является свидетелем, потому что (dt)s·2j ≢ ±1 (mod p) и (dt)s·2j+1 ≡ 1 (mod p). Во-вторых, если d1 и d2 являются несовпадающими несвидетелями, то d1t ≢ d2t (mod p). Причина в том, что ts·2j+1 ≡ 1 (mod p). Следовательно, t · ts·2j+1–1 ≡ 1 (mod p). Поэтому если d1t ≡ d2t (mod p), то d1 ≡p d1t · ts·2j+1–1 ≡p d2t · ts·2j+1–1 ≡p d2. Таким образом, в случае 2 то же самое число свидетелей должно быть, по крайней мере, таким же большим, как и число несвидетелей. Задача 6.15. 3 1 = 3, 32 = 9 = 2, 33 = 2 · 3 = 6, 34 = 6 · 3 = 4, 35 = 4 · 3 = 5, 36 = 5 · 3 = 1, все вычисления (mod 7), и, следовательно, g = 3 генерирует все числа в �∗ 7. Не каждое число является генератором: например, 4 таковым не является. Задача 6.16. Алиса и Боб соглашаются использовать простое число p = 23 и ос -\n--- Страница 132 ---\nОтветы к избранным задачам  131 нование g = 5. Алиса выбирает секрет a = 8; посылает Бобу A = ga (mod p). A = 58 (mod 23) = 16. Боб выбирает секрет b = 15; отправляет Алисе B = gb (mod p). B = 515 (mod 23) = 19. Алиса вычисляет s = Ba (mod p). s = 198 (mod 23) = 9. Боб вычисляет s = Ab (mod p). s = 1615 (mod 23) = 9. Как можно видеть, оба в конечном итоге имеют s = 9, их общий секретный ключ. Задача 6.19. Предположим, что мы имеем одностороннюю функцию, как в во- просе. Сначала Алиса и Боб договариваются о публичном g и обмениваются им (поэтому злоумышленник знает g). Тогда пусть Алиса генерирует секрет а и пусть Боб генерирует секрет b. Алиса посылает f(g, а) Бобу, и Боб посылает f(g, b) Алисе. Обратите внимание, что поскольку hg является односторонней, злоумышленник не может получить a или b из hg(а) = f(g, а) и hg(b) = f(g, b). Наконец, Алиса вычисляет f(f(g, b), a), и Боб вычисляет f(f(g, a), b), и по свойствам функции оба равны f(g, ab), что является их секретным общим ключом. Злоумышленник не может правдопо- добно вычислить f( g, ab). Задача 6.20. Для первой части: c1 = gb (mod p) = 35 (mod 7) = 5; c2 = mAb (mod p) = 2 · 45 (mod 7) = 2 · 2 = 4. Для второй части: m = c1–a c2 (mod p) = 5–44 (mod 7) = (5–1)44 (mod 7) = 344 (mod 7) = 4 · 4 (mod 7) = 2. Задача 6.21. Задача Диффи–Хеллмана с �p, g, A ≡p ga, B ≡p gb� на входе выдает gab (mod p) на выходе, и задача Эль-Гамаля с �p, g, A ≡p ga, c1 ≡p gb, c2 ≡p mAb� (6.4) на входе выдает m на выходе. Мы хотим показать, что мы можем взломать схе- му Диффи–Хеллмана, то есть эффективно решить задачу Диффи–Хеллмана тогда и только тогда, когда сможем взломать схему Эль-Гамаля, то есть эффективно ре-шить задачу Эль-Гамаля. Ключевое слово здесь – эффективно, то есть за полино- миальное время. (⇒) Предположим, что мы можем эффективно решить задачу Диффи–Хеллма- на; мы даем эффективную процедуру решения задачи Эль-Гамаля: с учетом входа (6.4) в задачу Эль-Гамаля мы получаем g ab (mod p) из A ≡p ga и c1 ≡ gb, используя эффективный решатель для задачи Диффи–Хеллмана. Затем мы используем рас -\n--- Страница 133 ---\n132  Рандомизированные алгоритмы ширенный евклидов алгоритм, см. задачу 1.9 – и обратите внимание, что рас - ширенный алгоритм Евклида работает за полиномиальное время, для того чтобы получить (gab)–1 (mod p). Теперь c2 · (gab)–1 ≡p mgab(gab)–1 ≡p m = m, где последнее равенство следует из m ∈ �p. (⇐) Предположим, что у нас есть эффективный решатель для задачи Эль-Гамаля. Для того чтобы решить задачу Диффи–Хеллмана, мы конструируем следующий вход в задачу Эль-Гамаля: �p, g, A ≡p ga, c1 ≡p gb, c2 = 1�. Обратите внимание, что c2 = 1 ≡p (gab)−1Ab = m, поэтому, используя эффективный ре- шатель для задачи Эль-Гамаля, мы получаем m ≡p (gab)–1, и теперь, используя рас- ширенный алгоритм Евклида, мы получаем обратное от ( gab)–1 (mod p), то есть прос то gab (mod p), и выдаем его на выходе. Задача 6.23. 1. Слабость нашей схемы лежит в хеш-функции, которая вычисляет одинако-вые хеш-значения для разных сообщений, и на самом деле легко найти со-общения с одинаковым значением хеш-функции – например, добавив пары букв (в любой части сообщения) такие, что соответствующие им значения ASCII являются взаимно обратными по модулю p. Приведем пару примеров (заданий) сообщений с одинаковым хеш-зна че- нием: «A mess» и «L message». В общем случае по своей природе любая хеш-функция будет иметь такие коллизии, то есть сообщения, что: h(A message.) = h(A mess) = h(L message) = 5, но есть хеш-функции, коллизионно-устойчивые в том смысле, что вычис - лительно трудно найти два сообщения m, m′ такие, что h(m) = h(m′). Хоро- шая хеш-функция также является односторонней функцией в том смысле, что при наличии значения y вычислительно трудно найти m такое, что h(m) = y. 2. Верифицирование подписи означает проверку того, что документ m подпи- сало именно то лицо, которое владеет x. Здесь имеются две тонкости: сна- чала мы говорим «лицо, которое владеет x», а не «законный владелец x», просто потому, что x может быть скомпрометирован (например, украден). Во-вторых, и именно по этой причине данная схема является такой гени-альной, мы можем проверить, что «некто, владеющий x», подписал сообще- ние, даже не зная, что такое x! Мы знаем y, где y = g x (mod p), но для больших p трудно вычислить x из y (это называется задачей дискретного логарифми- рования). Ниже мы покажем, как верифицировать, что «некто, владеющий х», под- писал сообщение m. Мы проверяем 0 < r < p и 0 < s < p – 1 (см. вопрос 6), вычисляем v := gh(m) (mod p) и w := yrrs (mod p); g, p являются публичными, m известно, функция h : � → [p – 1] тоже известна, и r, s являются заданной подписью. Если v и w совпадают, то подпись валидна. Для того чтобы убедиться, что все работает, обратите внимание, что мы опре-\n--- Страница 134 ---\nОтветы к избранным задачам  133 делили s := k–1(h(m) – xr) (mod p – 1). Следовательно, h(m) = xr + sk (mod p – 1). Теперь малая теорема Ферма говорит, что gp–1 = 1 (mod p), и следовательно: gh(m) (∗)= gxr+sh = (gx)r(gk)s = yrrs (mod p). Малая теорема Ферма применяется в равенстве (∗): поскольку h(m) = xr + sk (mod p– 1), из этого следует, что (p – 1)|(h(m) – ( xr + sk)), а это означает, что (p – 1) z = h(m) – ( xr + sk) для некоторого z, и так как g(p–1)z = (g(p–1))z = 1z = 1 (mod p), отсюда следует, что gh(m)–(xr+sk) = 1 (mod p), и поэтому gh(m) = gxr+sk (mod p). 3. Приведем несколько хеш-функций, реализованных в GPG, версии 2.0.301: MD5, SHA1, RIPEMD160 , SHA256 , SHA384 , SHA512 , SHA224 . 4. Для того чтобы это увидеть, пусть b, c равны числам таким, что gcd(c , p – 1) = 1. Зададим r = gb yc, s = –rc–1 (mod p – 1) и m = –rbc–1 (mod p – 1). Тогда (m , r, s) удовлетворяет gm = yrrs. Так как на практике хеш-функция h применяется к сообщению и в реальности подписывается именно хеш-значение, подде- лать подпись для получения содержательного сообщения не так просто. Зло-умышленник должен найти содержательное сообщение m такое, что h(m) = h(m), и когда h является коллизионно-устойчивой, это очень трудно сделать. 5. Если одинаковое случайное число k используется в двух разных сообщениях m ≠ m′, то k можно вычислить следующим образом: s – s′ = (m – m′) k–1 (mod p – 1), и следовательно, k = (s – s′)–1(m – m′) (mod p – 1). 6. Пусть m′ равно сообщению по выбору Евы, u = m′m–1 (mod p – 1), s′ = su (mod p – 1), r′ и целое число такие, что r′ = r (mod p) и r′ = ru (mod p – 1). Это r′ может быть получено так называемой китайской теоремой об остатках (см. теорему 9.30). Затем (m′, r′, s′) принимается верификационной процедурой. Задача 6.24. Почему m kl ≡n m? Пронаблюдаем, что kl = 1 + (–t)φ(n), где (– t) > 0, и поэтому mkl ≡n m1+(–t )φ(n) ≡n m · (mφ(n))(–t) ≡n m, потому что mφ(n) ≡n 1. Обратите вни- мание, что это последнее формальное суждение не следует непосредственно из теоремы Эйле ра (теорема 9.29), потому что m ∈ � n, и не обязательно в �∗ n. Обратите внимание, что, для того чтобы убедиться, что m ∈ �∗ n, достаточно настоять на том, что у нас есть 0 < m < min{ p, q}; поэтому мы разбиваем большое сообщение на мелкие части. Интересно отметить, что мы можем обойти теорему Эйлера и просто применить малую теорему Ферма: мы знаем, что m(p–1) ≡p 1 и m(q–1) ≡q 1, поэтому m(p–1)(q–1) ≡p 1 и m(q–1)( p–1) ≡q 1, следовательно, mφ(n) ≡p 1 и mφ(n) ≡q 1. Это означает, что p|(mφ(n) – 1) и q|(mφ(n) – 1), поэтому, поскольку p, q являются несовпадающими простыми чис - лами, из этого следует, что (pq)|(mφ(n) – 1), и поэтому mφ(n) ≡n 1. Задача 6.25. Если бы факторизовать целые числа было легко, то схему RSA было бы легко взломать: если бы мы смогли факторизовать n, то мы получили бы все простые числа р, q и, следовательно, было бы легко вычислить φ(n) = φ(pq) = (p – 1) (q – 1), и из этого мы получаем l, инверсию k. Задача 6.26. Мы показываем, что для ∀i ∈ [n – 1] имеет место, что ri+1åi j=1 rj по индукции на i. Базовый случай равен i – 1, поэтому 1 GNU Privacy Guard (GPG) – свободная программа для шифрования информации и созда- ния электронных цифровых подписей. Последняя на конец 2018 г. версия была 2.2.12. – Прим. перев.\n--- Страница 135 ---\n134  Рандомизированные алгоритмы r2 ≥ 2r1 > r1 = åi j=1rj, где r2 ≥ 2r1 по свойству сверхвозрастания. На индукционном шаге мы имеем ri+1 ≥ 2ri = ri + ri > ri + åi=1 j=1 rj = åi j=1 rj, где мы использовали свойство сверхвозрастания и индукционную гипотезу. Приведем алгоритм для второго вопроса: X ← S Y ← ∅for i = n…1 do if (r i ≤ X) then X ← X – ri Y ← Y ⋃ { i} end if end for и пусть предусловие констатирует, что {ri}n i=1 является сверхвозрастающим и что существует S ⊆ {ri}n i=1 такое, что åi ∈ S ri = S. Пусть постусловие констатирует, что åi ∈ Y ri = S. Определим следующий инвариант цикла: «Y является перспективным» в том смысле, что оно может быть расширено, причем индексы весов еще не были рас - смотрены, в решение. То есть после рассмотрения i существует подмножество E из {i – 1, , 1} такое, что åj ∈ X ⋃ E rj = S. Базовый случай является тривиальным, так как изначально X = ∅, и поскольку предусловие гарантирует существование решения, X может быть расширено в это решение. На индукционном шаге рассмотрим два случая. Если ri > X, то i не добавляется, но Y может быть расширено с помощью E′ ⊆ {i – 1, i – 2, , 1}. Причина в том, что по индукционной гипотезе X было расширено в решение некоторым E ⊆ {i, i – 1, , 1} и i не было частью расширения, поскольку ri было слишком большим, чтобы уложиться в то, что уже было в Y, то есть E ′ = E. Если ri ≤ X, то i ∈ E, так как по предыдущей части оставшиеся веса не смогут за- крыть разрыв между S и åj ∈ Y rj. 6.7. п римеЧания Говоря об эпиграфе в начале главы, роман «Энигма» [Harris (1996)] является от - личным введением в ранние годы криптоанализа; кроме того, у данного романа есть отличная экранизация 2001 года. Хотя в этой книге мы не обсуждали задачу минимального-максимального по- тока, в большинстве вводных пособий в алгоритмы данная тема рассматривается. См., например, главу 7 в книге [Kleinberg и Tardos (2006)]. Кроме того, в работе [Fernandez и Soltys (2013)] обсуждается минимаксный принцип и связывается с несколькими другими фундаментальными принципами комбинаторики.\n--- Страница 136 ---\nПримечания  135 Генерировать случайные числа очень трудно; см., например, главу 7 в книге [Press и соавт. (2007)]. Алгоритм 6.3, алгоритм Рабина–Миллера, часто встречаемый под аббревиа- турой RM, реализован в OpenSSL, инструментальной бибилотеке для протоколов безопасности транспортного уровня (transport layer security, TLS) и уровня защи- щенных cокетов (secure sockets layer, SSL). Он также представляет собой универ-сальную криптографическую библиотеку. Очень большие числа можно проверить на простоту с помощью команды: openssl prime <число> Более новые версии инструментальной библиотеки OpenSSL также могут гене- рировать простое число из заданного количества бит: openssl prime -generate -bits 2048 Также обратите внимание, что можно легко вычислять большие степени числа по модулю простого числа с помощью Python, просто исполните команду: >>> pow(x,y,z) которая возвращает xy (mod z). Раздел 6.3 по алгоритму Рабина–Миллера был написан в то время, когда автор проводил академический год в Университете Колорадо в Боулдере, 2007–2008 гг., и этот раздел был значительно улучшен, по сравнению с обсуждениями с Яном Мициельским. Заслуга в изобретении метода Монте-Карло часто принадлежит Станиславу Уламу, математику польского происхождения, который работал в США с Джоном фон Нейманом над Манхэттенским проектом во время Второй мировой вой-ны. Улам также известен разработкой водородной бомбы с Эдвардом Теллером в 1951 го ду. Он изобрел метод Монте-Карло в 1946 году, размышляя о вероятности выигрыша в карточной игре пасьянс. Раздел 6.2 основан на работе [Karp и Rabin (1987)]. Первый полиномиально-временной алгоритм для тестирования простоты (примарности) был описан в работе [Agrawal и соавт. (2004)]. Этот алгоритм извес - тен как «AKS Primality Test» (по фамилиям изобретателей: Agrawal–Kayal–Saxena). Однако алгоритм AKS не выполним; алгоритм Рабина–Миллера по-прежнему яв-ляется стандартом для тестирования простоты. На самом деле именно рандомизированная проверка простоты вызвала ин- терес к рандомизированным вычислениям в конце 1970-х годов. Исторически первый рандомизированный алгоритм для примарности был описан в [Solovay и Strassen (1977)]; хорошее описание этого алгоритма со всеми необходимыми об-щими сведениями можно найти в § 11.1 публикации [Papadimitriou (1994)], и еще одно в § 18.5 публикации [von zur Gathen и Gerhard (1999)]. Р . Д. Кармайкл впервые отметил существование чисел Кармайкла в 1910 году, вычислил пятнадцать примеров и предположил, что хотя они нечасты, их бес - конечно много. В 1956 году Эрдос набросал технику построения больших чисел Кармайкла ([Hoffman (1998)]), и доказательство было дано в работе [Alford и соавт. (1994)] в 1994 году. Первые три числа Кармайкла равны 561, 1105, 1729, где последнее приведен-\n--- Страница 137 ---\n136  Рандомизированные алгоритмы ное в этом списке число называется числом Харди–Рамануджана по известному рассказу британского математика Г. Х. Харди о посещении индийского матема-тика Шринивасой Рамануджаном в больнице. Харди писал: «Я помню, как од-нажды ходил к нему, когда он приболел в Патни. Я ехал в такси с номером 1729 и заметил, что этот номер показался мне довольно скучным, и я надеялся, что это не будет неблагоприятным предзнаменованием. – Нет, – ответил он, – это очень интересный номер; это наименьшее число, выражаемое как сумма двух кубов двумя разными способами». Читателю предлагается посмотреть фильм «Человек, который познал бесконечность» (The Man Who Knew Infinity) 2015 года о Шринивасе Рамануджане. Раздел 6.4 основан на материалах [Hoffstein и соавт. (2008)] и [Delfs и Knebl (2007)]. Схема RSA названа по фамилии своих изобретателей: Rivest–Shamir–Adleman.GnuPG, или GPG, является свободной реализацией стандарта OpenPGP , опреде- ленного рабочим предложением RFC4880 (также известным как PGP). GPG позво-ляет шифровать и подписывать данные и коммуникации, а также имеет полную систему управления ключами. Вот еще несколько примеров использования GPG: gpg --gen-keysgpg --list-keysgpg --armor -r 9B070A58 -e example.txtgpg --armor --clearsign example.txtgpg --verify example.txt.asc Первая команда генерирует новую пару публичного и секретного ключей. Вторая выводит список всех ключей в связке ключей и отображает сводку о каж - дом. Третья команда шифрует текстовый файл example.txt с публичным ключом с идентификатором 9B070A58, который является ключом автора1. Четвертая коман да выводит подпись example.txt , которая гарантирует, что файл не был мо- дифицирован; подпись прилагается в качестве текста к файлу. Последняя коман-да верифицирует подпись, полученную в результате выполнения предыдущей коман ды. Публичные ключи можно рекламировать на личных домашних страницах или загружать в инфраструктуру открытых ключей (public key infrastructure, PKI). При-мером инфраструктуры открытых ключей является сервер публичных ключей MIT PGP , https://pgp.mit.edu, в котором можно выполнять поиск ключей (по иден- тификаторам, именам, электронным адресам и т. д.): gpg --keyserver hkp://pgp.mit.edu --search-keys 0x9B070A58 Обратите внимание, что URL-адрес сервера ключей задается с протоколом HKP , где HKP означает «протокол HTTP сервера ключей OpenPGP» (OpenPGP HTTP Key - server Protocol). Подобные операции могут быть выполнены с помощью OpenSSL; например, мы можем генерировать секретные ключи RSA следующим образом: openssl genrsa -out mysecretrsakey.pem 512 1 Открытый ключ GPG автора с идентификатором 9B070A58: http://www.msoltys.com /gpg- key.\n--- Страница 138 ---\nПримечания  137 openssl genrsa -out mysecretrsakey.pem 4096 Два параметра 512 и 4096 задают размер простых чисел; обратите внимание, что при 4096 генерирование продолжается немного дольше; именно здесь ис - пользуется алгоритм Рабина–Миллера. Следующий далее параметр создает соот - ветствующий публичный ключ: openssl rsa -in mysecretrsakey.pem -pubout Мы можем генерировать ключ на основе эллиптических кривых: openssl ecparam -out myeckey.pem -name prime256v1 -genkey и получить полный список типов эллиптических кривых: openssl ecparam -list_curves Как уже обсуждалось, мы можем использовать OpenSSL для проверки непо- средственно простоты: openssl prime 32948230523084029834023 Обратите внимание, что возвращаемое число всегда является шестнадцатерич- ным; удивительно, что такие большие числа могут быть проверены на простоту; проверку можно выполнять так быстро именно благодаря теореме Рабина–Мил-лера.",
      "debug": {
        "start_page": 114,
        "end_page": 138
      }
    },
    {
      "name": "Глава 7. Алгоритмы в линейной алгебре 138",
      "content": "--- Страница 139 --- (продолжение)\nГлава 7 Алгоритмы в линейной алгебре Kraj bez matematyki nie wytrzyma współza- wod nictwa z tymi, którzy uprawiaj¸ a mate ma ty k¸ e (Страна без математики не может конкуриро-вать с теми, кто ее придерживается). Хуго Штайнгауз цитируется на стр. 147 в книге [Duda (1977)] 7.1. в ведение В этой главе требуется понимание элементарной линейной алгебры, но не намно-го выходящее за пределы линейной независимости, детерминантов и характерис - тического многочлена. Мы сосредоточимся на матрицах, в некоторых случаях на матрицах над конечными полями. Для читателя, который незнаком с основами линейной алгебры, мы рекомендуем книгу [Halmos (1995)]. Мы говорим, что множество векторов {v 1, v2, , vn} является линейно независи- мым, если из ån i=1 civi = 0 вытекает, что ci = 0 для всех i и что они охватывают век - торное пространство V ⊆ �n, если всякий раз, когда v ∈ V, то существует ci ∈ � такое, что v = ån i=1 ci vi. Мы обозначаем это как V = промежуток – текстовый буфер{v1, v2, , vn}. Множество векторов {v1, v2, , vn} в �n является базисом для векторного пространства V ⊆ �n, если они линейно независимы и охватывают V. Пусть x · y обозначает скалярное (точечное) произведение двух векторов, определенных как x · y = (x1, x2, , xn) · (y1, y2, , yn) = ån i=1 xi yi, и норма вектора x определяется как ||x|| = x · x. Два вектора x, y являются ортогональными, если x · y = 0. 7.2. г аУссово исклюЧение Мы говорим, что матрица находится в построчно-ступенчатой форме , если она удовлетворяет следующим двум условиям: (i) если существуют ненулевые строки, то первый ненулевой элемент таких строк равен 1 (опорному элементу), и (ii) пер вый ненулевой элемент строки i + 1 находится справа от первого ненулевого элемента строки i. Короче говоря, матрица находится в построчно-ступенчатой форме, если она выглядит следующим образом:\nГлава 7 Алгоритмы в линейной алгебре Kraj bez matematyki nie wytrzyma współza- wod nictwa z tymi, którzy uprawiaj¸ a mate ma ty k¸ e (Страна без математики не может конкуриро-вать с теми, кто ее придерживается). Хуго Штайнгауз цитируется на стр. 147 в книге [Duda (1977)] 7.1. в ведение В этой главе требуется понимание элементарной линейной алгебры, но не намно-го выходящее за пределы линейной независимости, детерминантов и характерис - тического многочлена. Мы сосредоточимся на матрицах, в некоторых случаях на матрицах над конечными полями. Для читателя, который незнаком с основами линейной алгебры, мы рекомендуем книгу [Halmos (1995)]. Мы говорим, что множество векторов {v 1, v2, , vn} является линейно независи- мым, если из ån i=1 civi = 0 вытекает, что ci = 0 для всех i и что они охватывают век - торное пространство V ⊆ �n, если всякий раз, когда v ∈ V, то существует ci ∈ � такое, что v = ån i=1 ci vi. Мы обозначаем это как V = промежуток – текстовый буфер{v1, v2, , vn}. Множество векторов {v1, v2, , vn} в �n является базисом для векторного пространства V ⊆ �n, если они линейно независимы и охватывают V. Пусть x · y обозначает скалярное (точечное) произведение двух векторов, определенных как x · y = (x1, x2, , xn) · (y1, y2, , yn) = ån i=1 xi yi, и норма вектора x определяется как ||x|| = x · x. Два вектора x, y являются ортогональными, если x · y = 0. 7.2. г аУссово исклюЧение Мы говорим, что матрица находится в построчно-ступенчатой форме , если она удовлетворяет следующим двум условиям: (i) если существуют ненулевые строки, то первый ненулевой элемент таких строк равен 1 (опорному элементу), и (ii) пер вый ненулевой элемент строки i + 1 находится справа от первого ненулевого элемента строки i. Короче говоря, матрица находится в построчно-ступенчатой форме, если она выглядит следующим образом:\n--- Страница 140 ---\nГауссово исключение  139 1 ∗ . . . ∗ ∗ ∗ . . . ∗ ∗ ∗ . . . ∗ ∗ 1 ∗ . . . ∗ ∗ ∗ . . . ∗ ∗ 1 ∗ . . . ∗ ∗ 0 ∗ . . . ∗ ∗ ∗ . . . ∗ 1. . . . . . . . . , (7.1) где знаки ∗ обозначают произвольные элементы. Мы определяем функцию гауссова исключения (gaussian elimination, GE), GE : Mn×m → Mn×n, как функцию, которая при передаче ей на вход n×m-матрицы выводит n×n-матрицу GE(А) с тем свойством, что GE(A)A находится в построчно-ступенча- той форме. Мы называем это свойство условием правильности гауссова исключения. Покажем, как вычислить гауссово исключение GE(A) при наличии A. Идея, ко- нечно, состоит в том, что GE(A) равняется произведению элементарных матриц, которое приводит А к построчно-ступенчатой форме. Начнем с определения эле- ментарных матриц. Пусть Tij равно матрице с нулями везде, кроме (i, j)-й позиции, где она имеет единицу. Матрица E является элементарной матрицей, если E имеет одну из следующих трех форм: I + aTij i ≠ j (элементарная матрица 1-го рода) I + Tij + Tji – Tii – Tjj (элементарная матрица 2-го рода) I + (c – 1) Tii c ≠ 0 (элементарная матрица 3-го рода) Пусть А равно любой матрице. Если Е является элементарной матрицей 1-го ро- да, то EA равна А, в которой i-я строка заменена суммой i-й строки и произведе- ния а на j-ю строку. Если Е является элементарной матрицей 2-рода, то EA равна А, в которой i-я и j-я строки переставлены местами. Если Е является элементарной матрицей 3-го рода, то EA равна A, в которой i-я строка умножена на c ≠ 0. Алгоритм гауссова исключения представляет собой вид алгоритмов «разделяй и властвуй» с рекурсивным вызовом меньших матриц. То есть мы вычисляем GE рекурсивно, по числу строк A. Если А является 1×m-матрицей, A = [a11a12 a1m], то: GE(A) = � [1/a1i], где i = min{1, 2, , m} такое, что ai1 ≠ 0, (7.2) [1], если a11 = a12 = ··· = a1m = 0. В первом случае GE(A) = [1/a1i], GE(A) является просто элементарной матрицей размера 1×1 и 3-го рода, c = ai1. Во втором случае GE(A) является матрицей тождест - венности 1×1, то есть элементарной матрицей 1-го рода с а = 0. Также отметим, что в первом случае мы делим на a1i. Это не требуется, если лежащее в основе поле равно �2, так как ненулевой элемент с необходимостью равен 1. Однако наши ар- гументы соблюдаются независимо от лежащего в основе поля, поэтому мы хотим сделать функцию независимой от поля гауссова исключения. Предположим теперь, что n > 1. Если A = 0, то пусть GE(A) = I. В противном случае пусть: GE(A) = � 1 0 (7.2) 0 GE((EA)[1|1]) �Е, где E – это произведение не более n + 1 элементарных матриц, определенных ниже. Обратите внимание, что C[i|j] обозначает матрицу C, в которой строки i и j\n--- Страница 141 ---\n140  Алгоритмы в линейной алгебре удалены, поэтому (EA)[1/1] равна матрице A, умноженной на E слева, где затем первая строка и столбец удаляются из результата. Также обратите внимание, что мы удостоверяемся, что GE(A) имеет соответствующий размер (то есть это матри- ца размера n×n), размещая GE((EA)[1/1]) внутрь матрицы, дополненной 1 в левом верхнем углу и нулями в оставшейся части первой строки и столбца. Теперь мы определим матрицу E с учетом матрицы A, заданной на входе. Су - ществует два случая: первый столбец A равен нулю либо он не равен нулю. Случай 1: если первый столбец A равен нулю, пусть j равно первому ненулево- му столбцу A (такой столбец существует из допущения, что А ≠ 0). Пусть i равно индексу первой строки A такому, что Aij ≠ 0. Если i > 1, пусть E = I1i (E переставляет строку 1 и строку i ). Если i = 1, но Aij = 0 для 1 < l ≤ n, то E = I (ничего не делать). Если i = 1, и 1 i′1 < i′2 < ··· < i′k являются индексами остальных строк с Ai′lj ≠ 0, то пусть E = Ei′1 Ei′2 ··· Ei′k, где Ei′l – это элементарная матрица, которая добавляет первую строку матрицы А в i′l-ю строку матрицы А, чтобы она очищала j-й элемент i′l-й строки (над полем �2; над большим полем для очистки i′l-й строки нам может потребо- ваться кратное первой строки). Случай 2: если первый столбец A не равен нулю, то пусть ai1 равно его первому ненулевому элементу (то есть aj1 = 0, если j < i). Мы хотим вычислить последова- тельность элементарных матриц, произведение которых будет обозначено как Е, которое выполняет приведенную ниже последовательность шагов: 1) они переставляют первую и i-ю строки; 2) они делят первую строку на ai1; 3) они используют первую строку, чтобы очистить все остальные элементы в первом столбце. Пусть a i11, ai21, , aik1 равно списку всех ненулевых элементов в первом столбце A, не включая ai1, упорядоченному так, чтобы: i < i1 < i2 < ··· < ik. Условимся, что если ai1 является единственным ненулевым элементом в первой строке, то k = 0. Определим E в виде: E = Ei1 Ei2 ··· Eik E′E″, где Eij = I – aij1Tij1, поэтому Eij очищает первый элемент из ij-й строки матрицы A. Обратите внимание, что если k = 0 (если ai1 является единственным ненулевым элементом в первом столбце матрицы A), то E = E″E′. Пусть E″ = I + 1 ai1– 1T11 и E′ = I + Ti1 + T1i – Tii – T11. Таким образом, E″ делит первую строку на ai1, и E′ переставляет местами первую и i-ю строки. Алгоритм 7.1. Гауссово исключение Предусловие: n×m-матрица A = [aij] над неким полем � 1: if n = 1 then 2: if a11 = a12 = ··· = a1m = 0 then 3: return [1] 4: else\n--- Страница 142 ---\nГауссово исключение  141 5: return [1/a1ℓ], где ℓ = mini∈[n]{a1i ≠ 0} 6: end if 7: else 8: if A = 0 then 9: return I 10: else 11: if первый столбец матрицы А равен нулю then 12: Вычислить Е как случай 1. 13: else 14: Вычислить Е как случай 2. 15: end if 16: return 10 0 GE((EA)[1|1])E 17: end if 18: end ifПостусловие: GE(A) находится в построчно-ступенчатой форме Задача 7.1. Реализуйте алгоритм 7.1 над � = � с использованием арифметики с плавающей запятой. 7.2.1. Формальные доказательства правильности над �2 Этот раздел содержит расширенный материал, относящийся к области сложно- сти доказательства. Заинтересованному читателю предлагается первая часть об-зора 9.4, в частности 9.4.1.1, которая представляет общие сведения, связанные с пропозициональными системами доказательства на основе пропозициональ-ного исчисления PK и расширенного пропозиционального исчисления EPK 1. Для того чтобы упростить подачу материала, мы ограничимся полем из двух элементов �2 = {0,1}, но эти результаты соблюдаются над более общими полями. Однако над бóльшими полями приходится мириться с кодировкой элементов поля булевыми переменными; это тривиально в случае двухэлементного поля � 2. Мы определяем булеву формулу RowEchelon(C11, C12, , Cnm)2 как дизъюнкцию (7.4) и (7.5), показанную ниже: 1≤i≤n,1≤j ≤m¬Cij; (7.4) 1≤i≤n,1≤j ≤m 1≤k≤j–1(¬C(i+1)1 ∧ ∧ ¬C(i+1)( j−1) ∧ C(i+1) j) ⊃ Cik. (7.5) Обратите внимание, что (7.4) формулирует, что C является нулевой матрицей, и (7.5) формулирует, что первый ненулевой элемент строки i + 1 находится справа от первого ненулевого элемента строки i. Более того, если в (i + 1)-й строке есть ненулевой элемент, то в i-й строке также должен иметься ненулевой элемент. Об- 1 Пропозициональное исчисление (propositional kalkul, PK) – это пропозициональная си- стема доказательства, которая работает на секвенциях. Расширенная PK (EPK) позволяет вводить новые переменные и объявлять их эквивалентными любой формуле. – Прим. перев. 2 RowEchelon – построчно-ступенчатый. – Прим. перев.\n--- Страница 143 ---\n142  Алгоритмы в линейной алгебре ратите внимание, что нам не нужно указывать условие, что первый ненулевой элемент каждой строки равен 1, так как поле равно �2; над более общими полями мы должны были бы также указать это условие. Мы немного злоупотребим формой записи и иногда будем писать RowEchelon(C ) вместо RowEchelon(C11, C12, , Cnm). Теорема 7.2. Расширенное пропозициональное исчисление EPK доказывает пра- вильность гауссова исключения с помощью доказательств размерного многочле-на в данной матрице. Точнее, семейство тавтологий, задаваемых { Ù||C = GE(A)A||n,m ⊃ RowEchelon(C)}, (7.6) имеет короткие доказательства EPK. Доказательство. Докажем, что (7.6) имеет короткие доказательства EPK. Точнее, из приведенных ниже конструкций формальных дериваций можно вывести кон- станту d с целью, чтобы размер этих дериваций (измеряемый числом символов) был ограничен (n + m)d, n, m ≥ 1. Мы не задаем d явно. Мы строим доказательство (7.6) индуктивно на n. Сначала предположим, что A является 1×m-матрицей. Пусть G = GE(A), тогда из (7.2) мы видим, что G = [1], по- этому оно представлено одним определением расширения G11 ↔ 1. Теперь опре- делим С = GA с m определениями расширений и покажем, что Ù||C = A||1,m. По - скольку A имеет только одну строку и является матрицей над �2, из этого следует, что A находится в построчно-ступенчатой форме и, следовательно, RowEchelon(C). Теперь предположим, что A является матрицей размера (n + 1)×m. Пусть G′ = GE((EA)[1|1]), и у нас уже есть набор определений расширений для G по индукции. Следовательно, из G = �1 0�0 G′E мы получаем множество определений расширений для G = GE(A). Это множество является коротким, потому что определение E является коротким и потому что определение G′ является коротким по индукции. Точнее, Е задается не более чем n + 2 элементарными матрицами размера (n + 1)×(n + 1) каждая; следовательно, оно включает в себя n + 1 новых матричных определений, причем каждое опре- деление с размером, ограниченным O((n + 1)3) (вспомним определение ||C = A||1,m). Каждая элементарная матрица, составляющая E (см. определение E выше), над �2, имеет определение постоянного размера (в терминах элементов A). Таким об- разом, определения расширений для E имеют размер, ограниченный O((n + 1)4). Поэтому G может быть определено с помощью O((n + 1)4) + (число определений расширений для G′) определений расширений, что в общей сложности составляет (ån+1 k=1 k4) ≤ O((n + 1)5) определений расширений для . Пусть C′ = G′((EA)[1|1]) и C = GA. По индукции Ù||C′ = G′((EA)[1|1])||n ⊃ RowEchelon(C′) имеет доказательство в расширенном пропозициональном исчислении EPK раз-мера, ограниченного (n + m) d. Теперь мы хотим показать, что при наличии опре- делений расширений для G′ и G RowEchelon(C ) ⊃ RowEchelon(C ) имеет короткие доказательства в расширенном пропозициональном исчислении EPK. Поскольку\n--- Страница 144 ---\nГауссово исключение  143 C = GA = �1 0�0 G′EA = �первая строка ЕА�0 G′((EA)[1|1]) = �первая строка ЕА�0 С′. Для того чтобы это увидеть, обратите внимание, что первый столбец EA равен нулю, за исключением, возможно, первого элемента. По выбору Е, либо (ЕА)11 ≠ 0, в каковом случае мы имеем RowEchelon(С), либо первый ненулевой элемент пер- вой строки ЕА находится слева от первого ненулевого столбца С′, в каковом слу - чае мы также имеем RowEchelon(0). Также отметим, что в приведенных выше рассуждениях мы используем ассоциативность итерированных матричных про- изведений. То есть мы исходим из того, что не важно, как мы заключаем в скобки итерированное матричное произведение, так как по ассоциативности мы всегда получаем один и тот же результат. Это может быть также показано с помощью коротких доказательств в расширенном пропозициональном исчислении EPK. □ Теорема 7.3. Существование обратного GE(A) может быть показано с помощью коротких доказательств расширенной пропозициональной системы EPK. Доказательство. Мы должны показать, что при наличии ||G = GE(A)|| n булевы пере- менные G–1 11, G–1 21, , G–n n, которые соответствуют G–1, могут быть сконструи рованы с помощью коротких определений расширений и что EPK доказывает ||GG–1 = I||n с помощью коротких доказательств. Так же, как мы определили G индуктивно с помощью определений расширений, мы определяем G–1 индуктивно. С учетом E = Ei1 Ei2 ··· Eik E′E″ мы можем вычислить Е–1 сразу, приняв E″–1E′–1Eik–1 ··· Ei2–1Ei1–1. Каждая из этих инверсий может быть вычис - лена очень легко, потому что они являются элементарными матрицами. Поэтому, поскольку мы имеем дело с �2, E″ = E″, и E′ также является своей собственной ин- версией, и Eij является матрицей с единицами по диагонали, и 1 в позиции (р, q), поэтому Eij–1 является матрицей с единицами по диагонали и 1 в позиции (q, p). Таким образом, мы показали, как вычислить G–1. Нам по-прежнему нужно по- казать, что семейство тавтологий {||GG–1 = I||n,m} имеет короткие доказательства EPK для любой n×m-матрицы A. Мы можем доказать это индуктивно на числе строк матрицы A, как и в доказательстве теоремы 7.2, поэтому мы его здесь не повторяем. □ Следствие 7.4. С помощью коротких доказательств EPK можно показать, что GE(A)A имеет единицы на главной диагонали, либо ее последняя строка равна нулю. Доказательство. Истинность этого логического утверждения очевидна из (7.1). Пусть C = GA, и предположим, что на диагонали есть нулевой элемент, то есть ¬ Ù1≤i≤n Cii ↔ 1. Мы хотим показать, что последняя строка равна нулю, Ù1≤i≤n Cni ↔ 0. Мы знаем, что RowEchelon(C ) является валидной и доказуемой в полиразмерном EPK (по теореме (7.2)). Из (7.5) мы можем заключить с помощью коротких доказа-тельств EPK, что: 1≤j≤k ¬Cij ⊃ 1≤j≤k+1 ¬C(i+1) j. (7.7) То есть если первые k элементов строки i равны нулю, то первые (k + 1) элемен- тов строки (i + 1) равны нулю. Пусть Cii равно нулю, где i – наименьший. Теперь из (7.7) докажем, что:\n--- Страница 145 ---\n144  Алгоритмы в линейной алгебре 1≤j≤i ¬Cij ↔ 0. (7.8) Используя (7.7) неоднократно, для 0 ≤ k ≤ n – i, мы показываем, что первые (i + k) элементов строки (i + k) равны нулю. Таким образом, можно сделать вывод, что первые n элементов n-й строки равны нулю, и, следовательно, n-я (последняя) строка полностью равна нулю. Фактически обратите внимание, что при наличии RowEchelon( C) нам было необ- ходимо только полиразмерное исчисление PK, и этого было достаточно для доказа- тельства, что если некий Cii равен нулю, то последняя строка матрицы C равна нулю. 7.3. алгоритм грама-шмидта Задача 7.5. Пусть V ⊆ �n равно векторному пространству и {v1, v2, , vn} равно его базису. Рассмотрим алгоритм 7.2 и покажем, что он порождает ортогональный базис {v ∗ 1, v∗ 2, , v∗ n} для векторного пространства V. Другими словами, покажем, что v∗ i · v∗ j = 0 при i ≠ j и что промежуток{v1, v2, , vn} = промежуток{v∗ 1, v∗ 2, , v∗ n}. Строка 4 содержит деление на квадрат нормы v∗ j; покажите, что это никогда не приведет к попытке деления на ноль. Алгоритм 7.2. Грам-Шмидт Предусловие: {v1, , vn} – базис для �n 1: v∗ 1 ← v1 2: for i = 2, 3, …, n do 3: for j = 1, 2, , (i – 1) do 4: μij ← (vi · v∗ j) / ||v∗ j||2 5: end for 6: v∗ i ← vi –åi–1 j=1 μijv∗ j 7: end for Постусловие: {v∗ 1, , v∗ n} – ортогональный базис для �n Задача 7.6. Реализуйте алгоритм Грама-Шмидта (алгоритм 7.2), но со следующей особенностью: вместо вычисления над �, действительными числами, вычислите над �2, полем из двух элементов, где сложение и умножение определяются сле- дующим образом: +01 .01 001 000 110 101 На самом деле эта «особенность» делает реализацию намного проще, так как вам не придется решать вопросы прецизионности, связанные с реализацией опе- раций деления над полем действительных чисел. 7.4. г аУссова редУкция решетки Предположим, что {v1, v2, , vn} – это линейно независимые векторы в �n. Решетка L, охваченная этими векторами, является множеством { ån i=1 civi : ci ∈ �}, то есть L\n--- Страница 146 ---\nВычисление характеристического многочлена  145 состоит из линейных комбинаций векторов {v1, v2, , vn}, где коэффициенты огра- ничены целыми числами. Задача 7.7. Предположим, что {v1, v2} охватывают решетку в �2. Рассмотрим ал- горитм 7.3 и покажем, что он завершается и выводит новый базис {v1, v2} для L, где v1 – это кратчайший вектор в решетке L, то есть ||v1|| – это как можно меньший среди всех векторов L. Алгоритм 7.3. Гауссова редукция решетки в размерности 2 Предусловие: {v1, v2} – линейно-независимы в �2 1: loop 2: if ||v2|| < ||v1|| then 3: поменять местами v1 и v2 4: end if 5: m ← v1 · v2 / ||v1||2 6: if m = 0 then 7: return v1, v2 8: else 9: v2 ← v2 – mv1 10: end if 11: end loop 7.5. в ыЧисление характеристиЧеского многоЧлена Существует два быстрых алгоритма вычисления характеристического многочле-на матрицы: алгоритм Чанки и алгоритм Берковица. Характеристический много- член матрицы обычно определяется как p A(x) = det(xI – A) для заданной матрицы A. Обозначим через pACSANKY и pABERK коэффициенты характеристического многочлена А, заданного соответственно в виде векторов-столбцов. Пусть pACSANKY(x) и pABERK(x) обозначают фактические характеристические многочлены с коэффициентами, вычисленными соответствующими алгоритмами. 7.5.1. Алгоритм Чанки Симметричные многочлены Ньютона определяются следующим образом: s0 = 1, и для 1 ≤ k ≤ n посредством: sk = 1 k åk i=1 (–1)i–1sk–i tr(Ai). (7.9) Тогда pACSANKY(x) = s0 xn – s1 xn–1 + s2 xn–2 – ··· ±sn x0. Задача 7.8. Напишите алгоритм, который реализует алгоритм Чанки с симмет - ричными многочленами Ньютона. Теперь мы представим алгоритм Чанки с матричными операциями, следуя идеям в § 13.4 публикации [von zur Gathen (1993)]. Мы переформулируем (7.9) в мат ричной форме: s = Ts – b, где s, T, b заданы, соответственно, следующим об- разом:\n--- Страница 147 ---\n146  Алгоритмы в линейной алгебре Тогда s = –b(I – T)–1. Обратите внимание, что (I – T) является обратимой матри- цей, поскольку она является нижнетреугольной, с единицами на главной диагона- ли. Обратная от (I – T) может быть вычислена рекурсивно, используя следующую идею: если C является нижнетреугольной без нулей на главной диагонали, то C = C10 EС2 ⇒ C–1 = C1–10 –C2–1EC1–1C2–1. Существует O(log(n)) шагов, и вся процедура может быть просимулирована в O(log2(n)) параллельных шагах. Задача 7.9. Реализуйте алгоритм Чанки с матричными операциями. 7.5.2. Алгоритм Берковица Алгоритм Берковица, так же как алгоритм Чанки, позволяет нам свести вычисле-ние характеристического многочлена к матричному возведению в степень. Его преимущество в том, что он работает над любым полем. Алгоритм Берковица вычисляет характеристический многочлен матрицы в терминах характеристического многочлена ее главного минора: A = a 11R SM, (7.10) где R – это матрица-строка размера 1×(n – 1), S – это матрица-столбец размера (n – 1)×1, и M равно (n – 1)×(n – 1). Пусть p(x) и q(x) равны характеристическим мно- гочленам соответственно A и M. Предположим, что коэффициенты p образуют вектор-столбец p = (pn pn–1 p0)t, (7.11) где pi – это коэффициент xi в det(xI – A), и схожим образом для q. Тогда: p = C1q, (7.12) где С1 – это нижнетреугольная (n + 1)×n-матрица Теплица ( матрица Теплица озна- чает, что значения на каждой диагонали являются постоянными) и где элементы в первом столбце определяются следующим образом: c i1 = 1, если i = 1, ci1 = –a11, если i = 2, и ci1 = –(RMi–3S), если i ≥ 3. Алгоритм Берковица состоит в том, чтобы по- вторять это для q и продолжать с целью, чтобы p выражалось как произведение матриц. Итак: pABERK = C1C2 ··· Cn, (7.13) где Ci – это определенная выше (n + 2 – i)×(n + 1 – i)-матрица Теплица, за исключени- ем того, что A заменяется ее i-й основной подматрицей. Отметим, что Cn = (1 – ann)t.\n--- Страница 148 ---\nВычисление характеристического многочлена  147 Поскольку каждый элемент Ci может быть явно определен в терминах исполь- зования матричного возведения в степень и поскольку итерационное матричное произведение может быть сведено к матричному возведению в степень стандарт - ным методом, все произведение (7.13) может быть выражено в терминах исполь-зования матричного возведения в степень. Задача 7.10. Напишите программу, реализующую алгоритм Берковица. 7.5.3. Доказательство свойств характеристического многочлена Лемма 7.11. Подобные матрицы имеют один и тот же характеристический мно- гочлен; то есть если P является любой обратимой матрицей, то pA = pP AP–1. Доказательство. Пронаблюдаем, что tr(AB) = åi åj aij bji = åj åi bji aij = tr(BA), поэтому, используя ассоциативность матричного умножения, tr(P Ai P–1) = tr(Ai PP–1) = tr(Ai). Осматривая (7.9), мы видим, что доказательство по индукции на si доказывает эту лемму. □ Лемма 7.12. Если А является матрицей вида: B0 CD, (7.14) где B и D – это квадратные матрицы (не обязательно одинакового размера) и пра- вый верхний угол равен нулю, тогда pA(x) = pB(x) · pD(x). Доказательство. Пусть siA, siB, siD равны коэффициентам характеристических мно- гочленов (как дано в (7.9)) соответственно А, B, D. Мы хотим показать по индукции на i, что siA = å j+k=i sjB skD, из чего следует утверждение леммы. Базовый случай: s0A, s0B, s0D = 1. На индукцион- ном шаге по определению и по индукционной гипотезе мы имеем, что sA i+1 равно = åi j=0 (–1)jsA i–j tr(Aj+1) = åi j=0 (–1)j �å p+q=i–j spB sqD � tr(Aj+1) и по форме А (то есть (7.14)): = åi j=0 (–1)j �å p+q=i–j spB sqD � (tr(Bj+1) + tr(Dj+1)); чтобы увидеть, как эта формула упрощается, разделим ее на две части: = åi j=0 (–1)j �å p+q=i–j spB sqD � (tr(Bj+1) + åi j=0 (–1)j �å p+q=i–j spB sqD � tr(Dj+1)). Рассмотрим сначала левую сторону. Когда q = 0, p варьируется над {i, i – 1, …, 0}, и j + 1 варьируется над {1, 2, …, i + 1}, и, следовательно, по определению, мы полу - чаем sB i+1. Схожим образом, когда q = 1, мы получаем siB и т. д. до тех пор, пока не получим s1B. Следовательно, мы имеем:\n--- Страница 149 ---\n148  Алгоритмы в линейной алгебре = åi+1 j=0 sB i–j sjD + åi j=0 (–1)j �å p+q=i–j spB sqD � (tr(Dj+1). То же самое рассуждение, но, задавая p вместо q с правой стороны, мы полу - чаем: = åi+1 j=0 sB i–j sjD + åi+1 j=0 sjB sD i–j = å j+k=i+1 sjB skD, что дает нам индукционный шаг и доказательство леммы. □ Для того чтобы показать, что pA(A) = 0, достаточно показать, что pA(A)ei = 0 для всех векторов ei в стандартном базисе {e1, e2, , en}. Пусть k равно наибольшему целому числу такому, что {ei, Aei, , Ak–1ei} (7.15) линейно независимо; мы знаем, что k – 1 < n по принципу линейной независимо- сти (тут мы впервые используем линейную независимость). Тогда (7.15) является базисом для подпространства W на �n, и W является инвариантом относительно A, то есть при наличии любого w ∈ W, Aw ∈ W. Используя гауссово исключение, запишем Akei как линейную комбинацию век - торов в (7.15). Используя коэффициенты этой линейной комбинации, напишем монический многочлен g(x) = x k + c1xk–1 + ··· + ckx0 (7.16) такой, что g(A)ei = 0. Пусть AW равно А, ограниченной базисом (7.15), то есть AW является матрицей, представляющей линейное преобразование TA: �n → �n, индуцированное матри- цей A, ограниченной подпространством W. Матрица Аt W имеет следующую прос - тую форму: (7.17) то есть это сопровождающая матрица многочлена g(х). Поскольку pA = pAt, мы рас - сматриваем транспонированную версию AW, так как At W имеет свойство, что ее главная подматрица также является сопровождающей матрицей, и это будет ис - пользоваться в доказательстве по индукции в следующей лемме. Лемма 7.13. Многочлен g(x) является характеристическим многочленом AW, дру - гими словами, g(x) = pAW(x). Доказательство. Мы отбрасываем W из AW, поскольку нет опасности путаницы (исходная матрица A в доказательстве не появляется); таким образом, A является k×k-матрицей с единицами ниже главной диагонали и нулями везде, кроме (воз- можно) в последнем столбце, где она имеет отрицания коэффициентов g(x).\n--- Страница 150 ---\nВычисление характеристического многочлена  149 Как было отмечено выше, A подразделяется на четыре квадранта, причем левый верхний содержит только 0. Пусть R = (0 … 0 –ck) равно вектору-строке в правом верхнем квадранте. Пусть S = e1 равно вектору-столбцу в левом нижнем квадранте, то есть первому столбцу A без верхнего элемента. Наконец, пусть M равно главной подматрице A, M = A[1|1], правому нижнему квадранту. Пусть s0, s1, , sk равно симметричным многочленам Ньютона матрицы A. Для того чтобы доказать, что g(x) = pATW(x), мы докажем что-то более сильное: покажем, что (i) для всех 0 ≤ i ≤ k (–1)isi = ci и (ii) pA(A) = 0. Мы показываем это по индукции на размере матрицы A. Поскольку главная подматрица A (то есть M) является также сопровождающей матрицей, мы исхо- дим из того, что для i < k коэффициенты симметричного многочлена M равны ci и что pM(M) = 0. (Обратите внимание, что базовый случай индукции является 1×1-матрицей и он тривиален для доказательства.) Так как для i < k, tr(Ai) = tr(Mi), то из (7.9) и индукционной гипотезы следует, что для i < k, (–1)isi = ci (отметим, что s0 = c0 = 1). Далее мы показываем, что (–1)ksk = ck. По определению (то есть по (7.9)) мы име- ем, что sk равно: (1/k)(sk–1tr(A) – sk–2tr(A2) + ··· + (–1)k–2s1tr(Ak–1) + (–1)k–1s0tr(Ak)), и по индукционной гипотезе и тому факту, что для i < k tr(Ai) = tr(Mi), мы имеем: = (1/k)(–1)k–1(ck–1tr(M ) + ck–2tr(M2) + ··· + c1tr(Mk–1) + c0tr(Ak)). Обратите внимание, что tr(Ak) = – kck + tr(Mk), поэтому: = (1/k)(–1)k–1[ck–1tr(M ) + ck–2tr(M2) + ··· + c1tr(Mk–1) + c0tr(Mk)] + (–1)kck. Заметим, что tr(ck–1M + ck–2M2 + ··· + c1Mk–1 + c0 Mk) = tr(pM(M)M) = tr(0) = 0, поскольку pM(M) = 0 по индукционной гипотезе. Поэтому sk = (–1)kck. Остается доказать, что pA(A) = åk i=0 ci Ak–i = 0. Сначала покажем, что для 1 ≤ i ≤ (k – 1): Ai+1 = åi–1 j=0 MjSRM(i−1)−j + Mi+1MiSRMi0. (7.18) (Для А формы, указанной в пункте (7.17), и R, S, M, определенных как в первом абзаце доказательства.) Определяем wi, Xi, Yi, Zi следующим образом: Ai+1 = = . = wi+1 Xi Swi 0 Xi+1 wi R + Xi MXi R Yi+1 Zi SYi S Zi+1 Yi R + Zi MZi M (7.19) Мы хотим показать, что самая правая матрица в (7.19) равна правой стороне (7.18). Во-первых, обратите внимание, что: Xi+1 = åi j=0 wi–j RMj wi+1 = åi–1 j=0 (RMjS)wi–1–j. (7.20)\n--- Страница 151 ---\n150  Алгоритмы в линейной алгебре С договоренностью, что w0 = 1. Поскольку w1 = 0, прямая индукция показывает, что wi+1 = 0. Таким образом, на этом этапе самая правая матрица (7.19) может быть упрощена до: .0 RMi Zi SYi R + Zi M Снова по лемме 5.1 из работы [Soltys и Cook (2004)] у нас есть: Yi+1 = MiS + åi=2 j=0 (RMjS)Yi–1–j zi+1 = Mi+1 + åi–1 j=0 Yi–1–j RMj. По тому же рассуждению, что и выше, åi–2 j=0 (RMjS)Yi–1–j = 0, поэтому, соединив все это вместе, мы получим правую сторону (7.18). Используя индукционную гипотезу (pM(M) = 0), легко показать, что первая стро- ка и столбец pA(A) равны нулю. Кроме того, согласно индукционной гипотезе, член Mi+1 в главной подматрице pA(A) исчезает, но оставляет ckI. Таким образом, из этого следует, что pA(A) = 0, если мы покажем, что åk i=2 ck–i åi–2 j=0 MjSRM(i–2)–j (7.21) равно –ckI. Некоторые наблюдения о (7.21): для 0 ≤ j ≤ i – 2 ≤ k – 2 первый столбец Mj ра- вен ej+1. И SR является матрицей нулей, в которой –ck находится в правом верхнем углу. Таким образом, MjSR является матрицей нулей, за исключением последнего столбца –ckej+1. Таким образом, MjSRM(i–2)–j является матрицей нулей везде, кроме строки ( j + 1), где она имеет нижнюю строку M(i–2)–j, умноженную на –ck. Пусть m(i–2)–j обозначает вектор-строку размера 1×(k – 1), состоящую из нижней строки M(i–2)–j. Следовательно, (7.21) равно: (7.22) Мы хотим показать, что (7.22) равно –ck I, для того чтобы закончить доказатель- ство pA(A) = 0. Для этого пусть l обозначает l-ю строку матрицы в (7.22), начиная с нижней строки. Мы хотим показать по индукции на l, что l-я строка равна ek–l. Базовый случай равен l = 0: åk i=k ck–i m(i–k) = c0m0 = ek, и доказательство завершено. На индукционном шаге обратим внимание, что ml+1 равно ml, сдвинутому влево на одну позицию, и с ml · (–ck–1 –ck–2 – c1)t (7.23)\n--- Страница 152 ---\nВычисление характеристического многочлена  151 в последней позиции. Введем еще несколько обозначений: пусть rl обозначает строку k – l (7.22). Тем самым rl равно вектору-строке размера 1×(k – 1). Пусть ←rl обозначает rl, сдвинутый на одну позицию влево, и с нулем в последней позиции. Это можно кратко изложить следующим образом: ←rl ≝ λij�1, (k – 1), e(rl, 1, i + 1)�. Исходя из (7.22) и (7.23), видно, что: rl+1 = ←rl + [rl · (–ck–1 –ck–2 – c1)t]ek + cl m0. (Здесь знак «·» в квадратных скобках означает скалярное произведение двух век - торов.) Используя индукционную гипотезу, ←rl = ek–(l+1) и rl · (–ck–1 –ck–2 – c1)t = ek–l · (–ck–1 –ck–2 – c1)t = –cl, поэтому rl+1 = ek–l – clek + clek = ek–(l+1), как и требовалось. На этом заканчивается до- казательство того, что матрица в (7.22) является матрицей тождественности, что, в свою очередь, доказывает, что (7.21) равно –ckI, и на этом заканчивается дока- зательство pA(A) = 0, что в итоге заканчивает основной аргумент индукции и до- казывает лемму. □ Интересно отметить, что лемма 7.13 также может быть доказана (практиче- ски) для алгоритма Берковица, и это доказательство на самом деле намного про-ще: рассмотрим еще раз матрицу, заданную (7.17). Мы индуктивно исходим из того, что p MBERK (характеристический многочлен главной подматрицы ( 7.17)) задан (1 c1 c2 … ck–1)t. Поскольку R = (0 … 0 –ck) и S = e1, pABERK = B · pMBERK, где B (матрица, за- данная алгоритмом Берковица) является матрицей размера (n + 1)×n с единицами на главной диагонали, нулями везде, кроме +ck в позиции (n + 1, 1). Из этого легко увидеть, что pABERK задается с помощью (1 c1 c2 … ck)t. Лемма 7.14. Многочлен g(x) делит pA(x). Доказательство. Разложим (7.15) до полного базиса �n: B = {ei, Aei, , Ak–1ei, ej1, ej2, , ejn–k}. Это разложение можно легко выполнить с помощью гауссова исключения, про- веряя, какие векторы из стандартного базиса ({e1, e2, , en}) находятся в промежут - ке, состоящем из (7.15) и тех векторов, которые уже были добавлены, и добавляя только недобавленные. Это единственное место (кроме абзаца после доказатель-ства леммы 7.12), где мы должны использовать принцип линейной независимости. Пусть P равно изменению базиса для A из стандартного базиса в B. Тогда P AP –1 = AW0 ∗E, где AW – это блок размера k×k, E – блок размера (n – k)×(k – n) (соответствующий разложению), и у нас есть блок нулей выше Е, поскольку W инвариантно относи- тельно А. В силу леммы 7.12 следует, что pA(x) = pPAP–1(x) = pAW(x) · pE(x). По лемме 7.13, pAW = g(x), и поэтому g(x) делит pA(x). □ Теорема 7.15. Мы можем доказать теорему Кэли–Гамильтона из принципа ли- нейной независимости, когда характеристический многочлен вычисляется алго- ритмом Чанки.\n--- Страница 153 ---\n152  Алгоритмы в линейной алгебре Доказательство. По лемме 7.1: pA(A)ei = (pAW(A) · pE(A))ei = (g(A) · pE(A))ei = pE(A) · (g(A)ei) = 0. Поскольку это верно для любого ei в стандартном базисе, из этого следует, что pA(A) = 0. □ 7.6. ответы к избранным зада Чам Задача 7.5. Мы намерены доказать инвариант цикла на внешнем цикле алгорит - ма 7.2, то есть мы собираемся доказать инвариант цикла на цикле for (индексиро- ванном на i), который начинается в строке 2 и заканчивается в строке 7. Наш инва- риант состоит из двух частей: после k-й итерации цикла соблюдаются следую щие два формальных суждения: 1) множество {v∗ 1, ···, v∗ k+1} является ортогональным, и 2) промежуток{v1, ···, vk+1} = промежуток{v∗ 1, ···, v∗ k+1}. Базовый случай: после нуля итераций цикла for, то есть перед тем, как цикл for был вообще исполнен, то есть со строки 1 алгоритма, v∗ 1 ← v1, и поэтому первое формальное суждение является истинным, потому что {v∗ 1} является ортогональ- ным (множество, состоящее из единственного ненулевого вектора, всегда являет - ся ортогональным – и v∗ 1 = v1 ≠ 0, потому что допущение (то есть предусловие) за- ключается в том, что {v1, ···, vn} является линейно независимым, и поэтому ни один из этих векторов не может быть нулевым), и второе формальное суждение также соблюдается тривиально, так как если v ∗ 1 = v1, то промежуток{v1} = промежуток{v∗ 1}. Индукционный шаг: предположим, что два условия соблюдаются после первых k итераций цикла; мы покажем, что они продолжают соблюдаться после k + 1 ите - раций. Расмотрим: v∗ k+2 = vk+2 – åk+1 j=1 μ(k+1)j v∗ j, которое мы получаем непосредственно из строки 6 алгоритма; обратите внима-ние, что внешний цикл for индексируется на i, который проходит от 2 до n, по - этому после k-го исполнения строки 2 для k ≥ 1 значение индекса i равно k + 1. Покажем первое формальное суждение, то есть что {v ∗ 1, ···, v∗ k+2} являются ортого- нальными. Поскольку по индукционной гипотезе мы знаем, что {v∗ 1, ···, v∗ k+1} уже являются ортогональными, достаточно показать, что для 1 ≤ l ≤ k + 1, v∗ l · v∗ k+2 = 0, что мы и делаем далее: v∗ l · v∗ k+2 = v∗ l · �vk+2 – åk+1 j=1 μ(k+2)j v∗ j� = (v∗ l · vk+2) – åk+1 j=1 μ(k+2)j (v∗ l · v∗ j), и так как v∗ l · v∗ j = 0, если только не является истинным, что l = j, то мы имеем: = (v∗ l · vk+2) – μ(k+2)l(v∗ l · v∗ l), и, используя строку 4 алгоритма, мы записываем:\n--- Страница 154 ---\nОтветы к избранным задачам  153 = (v∗ l · vk+2) – vk+2 · v∗ l || v∗ l||2(v∗ l · v∗ l) = 0, где мы использовали тот факт, что vl · vl = ||vl||2 и что vk+2 = vk+2 · v∗ l . Для второго формального суждения инварианта цикла нам нужно показать, что span{v1, , vk+2} = span{v∗ 1, , v∗ k+2}, (7.24) приняв по индукционной гипотезе, что промежуток {v1, , vk+1} = промежуток{v∗ 1, ···, v∗ k+1}. Аргументация будет основана на строке 6 алгоритма, которая предоставляет нам следующее равенство: v∗ k+2 = vk+2 – åk+1 j=1 μ(k+2)j v∗ j . (7.25) С учетом индукционной гипотезы, для того чтобы показать (7.24), нам нужно показать только следующие две вещи: 1) vk+2 ∈ промежуток{v∗ 1, , v∗ k+2} и 2) v∗ k+2 ∈ промежуток{v1, , vk+2}. Используя (7.25), мы немедленно получаем, что vk+2 = v∗ k+2 + åk+1 j=1 μ(k+2)jv∗ j, и поэтому мы имеем (1). Для того чтобы показать (2), мы отмечаем, что промежуток{v1, , vk+2} = промежуток{v∗ 1, , v∗ k+1, vk+2} по индукционной гипотезе, и поэтому у нас есть то, что нам нужно непосред- ственно из (7.25). Наконец, обратите внимание , что в строке 4 алгоритма мы ни разу не делим на ноль, потому что мы всегда делим на ||v∗ j ||, и единственно, когда норма может быть нулем, – это если сам вектор, v∗ j , является нулевым. Но из постусловия мы знаем, что {v∗ 1, , v∗ n} является базисом, и поэтому эти векторы должны быть линейно не- зависимыми, и, значит, ни один из них не может быть нулевым. Задача 7.7. Ссылку на этот алгоритм можно найти в работе [Hoffstein и соавт. (2008)] в § 6.12.1. Также в публикации [von zur Gathen и Gerhard (1999)], § 16.2, да- ется обработка алгоритма в более высоких размерностях. Пусть p = v1 · v2 /||v1||2, и учтем следующее отношение: ⌊p⌉ = ⌊p + 1/2⌋ = m ∈ � ⇔ p ∈ [m – 1/2, m + 1/2) ⊆ �, где, следуя стандартной терминологии исчисления, множество [a, b) для а, b ∈ � обозначает множество всех x ∈ � таких, что a ≤ х < b. Теперь мы даем доказательство завершения алгоритма. Предположим, что |p| = –1 2. Если p = ––1 2, то m = 0, и алгоритм останавливается. Если p = –1 2, то m = 1, что означает, что мы проходим по циклу еще раз с v′1 = v1 и ||v ′2|| = ||v2 – v1|| = ||v2||, и, что более важно, в следующем раунде p = ––1 2, и снова алгоритм завершается. Если p = m, то есть изначально p было целым числом (давая C→E = D→′E = D→E на рис. 7.1), то просто по теореме Пифагора ||C→E|| должно быть короче ||AE|| (посколь- ку v1, v2 – ненулевые, так как m ≠ 0). Поэтому мы можем принять, что |p| ≠ –1 2 и p ≠ m. Два случая, когда m < p, давая D′, либо m > p, давая D, являются симметричными, и поэтому мы рассматриваем только последний случай. Должно быть |р| > –1 2, иначе m было бы нулем, приводя\n--- Страница 155 ---\n154  Алгоритмы в линейной алгебре к завершению. Обратите внимание, что ||C→D|| ≤ –1 2)||A→B||, потому что A→D = mA→B. Из этого и теоремы Пифагора мы знаем, что: ||A→E|| = ||A→C||2 + ||C→E||2 = p2||A→B||2 + ||C→E||2; ||D→E||2 = ||C→D||2 + ||C→E||2 ≤ p2||A→B||2 + ||C→E||2, и поэтому ||A→E||2 – ||D→E||2 ≥ (p2 – –1 4)||A→B||2, и, как мы уже отмечали, если алгоритм не заканчивается в строке 6, это означает, что |р| > –1 2, и поэтому отсюда следует, что ||A→E|| > ||D→E||, то есть v2 длиннее, чем v2 – mv1, и поэтому новый v2 (строка 9) короче, чем старый. BE D′CD A Рис. 7.1  Проекция v2, заданного как A→E, в v1, заданный как A→B. Результи- рующий вектор равен A→C = v2 – pv1, где p = v1 · v2 /||v1||2. Принимая m = p, вектор v2 – mv1, задаваемый соответственно D→′E или D→E в зависимости от того, ис - тинно ли, что m < p, или нет. Разумеется, D′ = C = D при p = m Пусть v′1, v′2 равны двум векторам, приводящим к одной итерации цикла из v1, v2. Как мы уже отмечали выше, при |p| = –1 2 алгоритм завершается за один или два шага. В противном случае ||v ′1|| + ||v ′2|| < ||v1|| + ||v2||, и так как в решетке существует конечное число пар точек, ограниченных суммой двух норм исходных векторов, и алгоритм заканчивается, когда один из векторов становится нулевым, эта про-цедура должна заканчиваться за конечное число шагов. 7.7. п римеЧания Эта глава основана на нескольких статьях автора. Разделы 7.2 и 7.2.1, гауссово ис - ключение и доказательство его правильности основаны на разделе 3.1 в работе [Soltys (2002b)]. Раздел 7.5 основан на серии работ, в которых автор искал возмож - ные доказательства основных свойств характеристического многочлена (таких свойств, как то, что характеристический многочлен матрицы также является ее аннигилятором и что постоянный член является определителем матрицы). В этой области исследований было изучено несколько алгоритмов: алгоритм Чанки, раз-дел 7.5.1, основан на работе [Soltys (2005)], а алгоритм Берковица, раздел 7.5.2, основан на работе [Soltys (2002a)]. Оригинальное представление алгоритма Бер-ковица можно найти в работе [Berkowitz (1984)].",
      "debug": {
        "start_page": 139,
        "end_page": 155
      }
    },
    {
      "name": "Глава 8. Вычислительные основы 155",
      "content": "--- Страница 156 --- (продолжение)\nГлава 8 Вычислительные основы Технология состоит в изготовлении метафор из мира природы. Полет – это метафора воз-духа, колеса – метафора воды, еда – метафо-ра земли. Метафора огня – электричество. Э. Л. Доктороу [Doctorow (1971)], стр. 224 8.1. в ведение Первая серьезная попытка построить компьютер была предпринята в 1820-х го-дах Чарльзом Бэббиджем. Машина называлась разностной машиной, вычислялась с помощью десятичной системы счисления и приводилась в действие с помощью рукоятки. Увы, Бэббиджу так и не удалось построить готовое изделие, поскольку изготовление прецизионных деталей было колоссальной инженерной пробле-мой, учитывая технологию его времени. Компьютерные программы – это не что иное, как реализации алгоритмов на выбранном языке программирования. Программы работают на аппаратном обес - печении, и подобно тому, как программы являются инстанциациями алгоритмов, аппаратное обеспечение является материальным воплощением конкретной вы-числительной модели. В этой главе мы рассмотрим различные модели вычисле-ний, которые затем инстанциируются в машине, работающей на электричестве. Мы введем несколько типов конечных автоматов и завершим презентацией ма-шины Тьюринга. 8.2. алфавиты , строки и язык Алфавит – это конечное, непустое множество разных символов, обычно обознача-емых знаком å. Например, å = {0, 1}, обычный двоичный алфавит, или å = {a, b, c, ···, z}, обычные буквы нижнего регистра английского алфавита. Строка, или сим- вольная цепочка, также именуемая словом, представляет собой конечную упоря- доченную последовательность символов, выбранных из некоторого алфавита. На-пример, 01001110101011 – это строка над двухзначным алфавитом. Форма записи |w| обозначает длину символьной цепочки (строки) w, например |010011101011| = 12. Пустая строка ε – это уникальная строка такая, что |ε| = 0. Мы иногда пишем å ε, чтобы подчеркнуть, что ε ∈ å. åk является множеством строк над å длиной ровно k, например если å = {0, 1}, то: å0 = {ε},\nГлава 8 Вычислительные основы Технология состоит в изготовлении метафор из мира природы. Полет – это метафора воз-духа, колеса – метафора воды, еда – метафо-ра земли. Метафора огня – электричество. Э. Л. Доктороу [Doctorow (1971)], стр. 224 8.1. в ведение Первая серьезная попытка построить компьютер была предпринята в 1820-х го-дах Чарльзом Бэббиджем. Машина называлась разностной машиной, вычислялась с помощью десятичной системы счисления и приводилась в действие с помощью рукоятки. Увы, Бэббиджу так и не удалось построить готовое изделие, поскольку изготовление прецизионных деталей было колоссальной инженерной пробле-мой, учитывая технологию его времени. Компьютерные программы – это не что иное, как реализации алгоритмов на выбранном языке программирования. Программы работают на аппаратном обес - печении, и подобно тому, как программы являются инстанциациями алгоритмов, аппаратное обеспечение является материальным воплощением конкретной вы-числительной модели. В этой главе мы рассмотрим различные модели вычисле-ний, которые затем инстанциируются в машине, работающей на электричестве. Мы введем несколько типов конечных автоматов и завершим презентацией ма-шины Тьюринга. 8.2. алфавиты , строки и язык Алфавит – это конечное, непустое множество разных символов, обычно обознача-емых знаком å. Например, å = {0, 1}, обычный двоичный алфавит, или å = {a, b, c, ···, z}, обычные буквы нижнего регистра английского алфавита. Строка, или сим- вольная цепочка, также именуемая словом, представляет собой конечную упоря- доченную последовательность символов, выбранных из некоторого алфавита. На-пример, 01001110101011 – это строка над двухзначным алфавитом. Форма записи |w| обозначает длину символьной цепочки (строки) w, например |010011101011| = 12. Пустая строка ε – это уникальная строка такая, что |ε| = 0. Мы иногда пишем å ε, чтобы подчеркнуть, что ε ∈ å. åk является множеством строк над å длиной ровно k, например если å = {0, 1}, то: å0 = {ε},\n--- Страница 157 ---\n156  Вычислительные основы å1 = å, å2 = {00, 01, 10, 11}. Множество å∗ называется звездой Клини алфавита å и является множеством всех строк над å. Обратите внимание, что å∗ = å0 ⋃ å1 ⋃ å2 ⋃ …, тогда как å+ = å1 ⋃ å2 ⋃ … . Если x, y являются строками, и x = a1a2 … am, и y = b1b2 … bn, тогда их конкатенацией является их смежное расположение, то есть x · y = a1a2 … amb1b2 … bn. Мы часто пишем xy вместо x · y, и wε = εw = w. Язык L представляет собой коллекцию строк над некоторым алфавитом å, то есть L ⊆ å∗. Например: L = {ε, 01, 0011, 000111, } = {0n1n|n ≥ 0}. (8.1) Обратите внимание, что {ε} ≠ ∅, один из которых является языком, состоящим из единственной строки ε, а другой является пустым языком. Обозначим через åℓ обобщенный алфавит размера ℓ. Например, пусть å1 = {1}, å2 = {0, 1} и т. д. Задача 8.1. Каков размер åk 2? Каков размер åk ℓ? Пусть L равно множеству строк над å, где ни один символ не может встречаться более одного раза; какова |L|? Пусть w = w1w2 … wn, где для каждого i, wi ∈ å. Для того чтобы подчеркнуть струк - туру массива w, мы иногда представляем его как w[1…n]. Мы говорим, что v явля- ется подсловом w, если v = wi wi+1 … wj, где i ≤ j. Если i = j, то v является единственным символом в w; если i = 1 и j = n, то v = w; если i = 1, то v является префиксом w (иногда обозначается v ⊑ w), и если j = n, то v является суффиксом w (иногда обозначается как w ⊒ v). Мы можем выразить лаконичнее, что v является подсловом, следующим образом: v = w[i…j ], и когда разделители не нужно выражать явно, мы используем форму записи v ≤ w. Мы говорим, что v является подпоследовательностью w, если v = wi1 wi2 … wik , для i1 < i2 < < ik. 8.3. р егУлярные языки В этой главе мы рассмотрим разные типы языков, то есть разные типы множеств строк. Мы классифицируем их в соответствии с вычислительными моделями, которые их описывают. Регулярные языки в некотором смысле являются прос - тейшими языками, поскольку они описываются вычислителями без памяти, так называемыми конечными автоматами. Неудивительно, что только некоторые языки являются регулярными, и для описания более сложных языков нам потре-буются более прочные модели вычислений, такие как магазинные автоматы (раз-дел 8.4.2) или машины Тьюринга (раздел 8.5). 8.3.1. Детерминированный конечный автомат Детерминированный конечный автомат (deterministic finite automaton, DFA) – это модель вычисления, заданная кортежем A = (Q, å, δ, q 0, F), где: 1) Q – это конечное множество состояний; 2) å – это алфавит, то есть конечное множество входных символов; 3) δ: Q×å → Q – это переходная функция, то есть «программа», которая испол- няет детерминированный конечный автомат. При условии что q ∈ Q, a ∈ å, δ вычисляет следующее состояние δ(q, a) = p ∈ Q;\n--- Страница 158 ---\nРегулярные языки  157 4) q0 – это исходное состояние, также именуемое начальным состоянием (q0); 5) F – это множество финальных или принимающих состояний. Для того чтобы увидеть, что А принимает строку w, мы «выполняем» А на w = a1a2 … an следующим образом: δ(q0, a1) = q1, δ(q1, a2) = q2 до тех пор, пока не будет δ(qn–1, an) = qn. Мы говорим, что A принимает w тогда и только тогда, когда qn ∈ F, то есть если qn является одним из финальных (принимающих) состояний. Точ- нее: А принимает w, если существует последовательность состояний r0, r1, , rn, где n = |w| такое, что r0 = q0, δ(ri, wi+1) = ri+1, где i = 0, 1, …, n – 1 и wj является j-м символом w, и rn ∈ F. В противном случае мы говорим, что А отклоняет w. Например, рассмотрим язык L01 = {w | w имеет форму x01y ∈ å∗}, который является множеством строк, имеющих 01 в качестве подстроки. Поэтому 111 ∉ L01, но 001 ∈ L01. Предположим, что мы хотим спроектировать детерминированный конечный автомат A = (Q, å, δ, q0, F) для L01. То есть A принимает строки в L01 и отклоняет строки не в L01. Пусть E = {0, 1}, Q = {q0, q1, q2} и F = {q1}. Существует два способа представить δ: в форме диаграммы переходов либо в форме таблицы переходов; см. рис. 8.1. q1 q2 q00 10 1 0,10 1 q0 q2 q0 q1 q1 q1 q2 q2 q1 Рис. 8.1  Детерминированный конечный автомат, принимающий L = {w | w, имеет форму x01y ∈ å∗}. Слева приведена диаграмма переходов, а справа – таблица переходов На данный момент мы знаем, что простого представления А в качестве канди- датного детерминированного конечного автомата для L01 недостаточно. Мы также должны доказать, что A является правильным. Это будет проще, как только позже в этом разделе мы определим расширенную переходную функцию, но пока будет достаточно простого аргумента по индукции на длине w ∈ å∗. Задача 8.2. Докажите, что A является правильным детерминированным конеч- ным автоматом для L01. Задача 8.3. Спроектируйте детерминированный конечный автомат для {w: | w| ≥ 3, и его третий символ равен 0}. Задача 8.4. Спроектируйте детерминированный конечный автомат для {w: каж - дая нечетная позиция w равна 1}. Задача 8.5. Рассмотрим следующие два языка: B n = {ak = aa···a : k является кратным n } ⊆ {a}∗; Cn = {(w)b ∈ {0, 1}∗ : w делится на n}.k\n--- Страница 159 ---\n158  Вычислительные основы Обратите внимание, что (w)b является двоичным представлением числа w ∈ �. Каковы их детерминированные конечные автоматы? Задача 8.6. Рассмотрим торговый автомат, который на входе принимает монеты, где разрешенные монеты составляют следующий алфавит символов: 1, 5, 10, 25. Естественно, строка представляет собой просто упорядоченную последователь- ность монет. Сконструируйте переходную функцию для торгового автомата, кото-рый принимает любую последовательность монет, где итоговая стоимость монет суммируется в кратное 25. При наличии переходной функции δ ее расширенная переходная функция, обо- значаемая как δˆ, определяется индуктивно. Базовый случай: δˆ(q, ε) = q, и индукци- онный шаг: если w = xa , w, x ∈ å ∗ и a ∈ å, то δˆ(q, w) = δ ˆ(q, xa) = δ(δ ˆ(q, x), a). Таким образом, δˆ : Q × å∗ → Q, и w ∈ L(A) ⇔ δˆ (q0, w) ∈ F. Здесь L(A) – это мно- жество всех тех строк (и только тех), которые принимаются A, именуемых язы- ком A. Теперь мы можем определить язык детерминированного конечного автома- та A равным L(A) = {w|δ ˆ(q0, w) ∈ F}, и мы можем сказать, что язык L является регулярным, если существует детерми- нированный конечный автомат A такой, что L = L(A). Возникает следующий ес - тественный вопрос: какие операции на языках сохраняют их регулярность? Регу - лярные языки хорошо себя ведут, и многие естественные операции сохраняют их регулярность; мы начинаем с трех основных, которые называются регулярными операциями: i) объединение: L ⋃ М = {w |w ∈ L или w ∈ M }; ii) конкатенации: LМ = {xy |x ∈ L и y ∈ M }; iii) звезда Клини (или замыкание Клини): L ∗ = {w |w = x1x2 xn и xi ∈ L}. Мы уже ввели звезду Клини в контексте алфавитов (раздел 8.2), где алфавиты можно рассматривать как особый язык (из строк длиной один). Но есть важная разница в том, как звезда Клини действует на следующих двух: обратите внима-ние, что å + = å∗ – {ε}, но это не является истинным в общем случае для языков, которые L+ = L∗ – {ε}. Задача 8.7. Почему L+ = L∗ – {ε} не обязательно является истинным? Теорема 8.8. Регулярные языки замкнуты при регулярных операциях (объедине- нии, конкатенации и звезде Клини). Доказательство. Предположим, что у нас есть два регулярных языка, A, B, и по- этому у них есть соответствующие детерминированные конечные автоматы, M1, M2. Рассмотрим объединение А ⋃ B: возьмем соответствующие детерминирован-\n--- Страница 160 ---\nРегулярные языки  159 ные конечные автоматы M1 и M2; пусть M равно такому, что QM = QM1 × QM2, то есть декартовому произведению двух множеств состояний. Пусть: δM((r1, r2), a) = (δM1(r1, a), δM2(r2, a)). Для конкатенации и звезды нам нужно понятие «недетерминизма», которое мы введем в следующем разделе – см. задачу 8.13. □ Ключевой идеей в доказательстве теоремы 8.8 является расширение понятия состояния. Множество состояний представляет собой по-настоящему конечное множество «описателей» различных ситуаций. Эти описатели могут быть бук - вально чем угодно, например множествами состояний из других машин – как мы увидим, когда далее введем недетерминированные конечные автоматы. 8.3.2. Недетерминированные конечные автоматы Недетерминированный конечный автомат (nondeterministic finite automaton, NFA) определяется аналогично детерминированному конечному автомату, за исклю-чением того, что переходная функция δ становится переходным отношением. Тем самым δ ⊆ Q × å × Q, то есть на одной и той же паре (q, a) может существовать более одного возможного нового состояния (или ни одного). Эквивалентным образом мы можем смотреть на δ как на δ : Q × å → P(Q), где P(Q) – это степенное множест - во множества Q. Недетерминированные конечные автоматы похожи на детерминированные конечные автоматы, однако, в отличие от последних, они допускают «ветвление». Это означает, что в конкретной конфигурации, где детерминированный конеч-ный автомат находится в одном состоянии, недетерминированный конечный ав-томат может находиться в нескольких (или в одном, или в никаком). Хорошей его аналогией является механизм ветвления в языке программирования С. Посколь- ку недетерминированный конечный автомат может находиться в нескольких со-стояниях одновременно, он допускает определенную степень параллелизма. Например, рассмотрим L n = {w| n-й символ с конца равен 1}. Недетерминиро- ванный конечный автомат для Ln приведен на рис. 8.2. qn q1 q2 q01 0,1 0,1 0,10,1 … Рис. 8.2  Недетерминированный конечный автомат для Ln = {w | n-й символ с конца равен 1} Задача 8.9. По меньшей мере сколько состояний требуется любому детермини- рованному конечному автомату, который способен распознавать Ln? Определение термина «принятие» изменяется незначительно: N принимает w, если w = y1 y2 … ym, где yi ∈ åε с целью, чтобы существовала последовательность со- стояний r0, r1, , rm таких, что r0 = q0, и ri+1 ∈ δ(ri, yi+1) для i = 0, 1, , m – 1 и rm ∈ F. То есть w принимается, если существует заполнение строки w строками ε, для которо- го существует принимающая последовательность состояний. Задача 8.10. При заполнении строки строками ε нам вовсе не нужен сплошной отрезок строк ε длиннее, чем число состояний. Другими словами, если заполне-\n--- Страница 161 ---\n160  Вычислительные основы ние существует, то его можно найти за конечное число шагов. Объясните, почему, и ограничьте время поиска рабочего заполнения. Как показано на рис. 8.3, переходы по ε очень удобны при проектировании не- детерминированных конечных автоматов. В недетерминированном конечном автомате на рис. 8.3 мы не хотим иметь точку саму по себе, то есть «.» не является надлежаще сформированным числом в десятичной форме записи; мы хотим, чтобы цифры выступали в качестве либо префикса, либо суффикса; мы могли бы уточнить его дальше, запретив сегменту нулей быть префиксом и т. д. В итоге недетерминированный конечный автомат в данном контексте точно описывает, что мы имеем в виду под числом, и тогда это определение становится способом, которым данный синтаксический анализатор, или парсер, придает значение исходному коду. q1 q3 q2 q4q0 q5 0, 1, , 90, 1, , 9 0, 1, , 9 0, 1, , 9 . .ε, +, – ε Рис. 8.3  Недетерминированный конечный автомат для множества десятичных чисел Для того чтобы определить понятие расширенной переходной функции для не- детерминированных конечных автоматов, то есть δˆ, нам нужно понятие ε-замы- кания. С учетом q ε-close(q) равно множеству всех состояний p, которые достижи- мы из q, следуя по стрелкам, помеченным символом ε. Формально q ∈ ε-close(q), и если p ∈ ε-close(q) и p →ε r, то r ∈ ε-close(q). Теперь мы можем определить расширенное переходное отношение для недетер- минированных конечных автоматов следующим образом: δˆ(q, ε) = ε-close(q); пред- положим, что w = xa и δˆ(q, x) = {p1, p2, , pn}, и, более того, ⋃n i=1δ(pi, a) = {r1, r2, , rm}. Тогда δˆ(q, w) = ⋃m i=1 ε-close(ri). Теорема 8.11. Детерминированный и недетерминированный конечные автома- ты являются эквивалентными. Доказательство. Очевидно, что детерминированные конечные автоматы – это особый случай недетерминированных конечных автоматов. Таким образом, мы должны показать, что каждый недетерминированный конечный автомат мо-жет быть перепроектирован как детерминированный конечный автомат. С этой целью мы используем прием, именуемый построением подмножеств. Сначала мы принимаем допущение, что недетерминированный конечный ав- томат N не имеет ε-переходов. Пусть M равно соответствующему детерминиро- ванному конечному автомату, и Q M = P(QN), где P(QN) – это степенное множество QN, означающее, что оно состоит из всех возможных подмножеств множеств QN, и\n--- Страница 162 ---\nРегулярные языки  161 δM(Q, a) := ⋃ q∈Q δN(q, a), где Q ∈ P(QN), и пусть FM = {Q ∈ P(QN) : Q ⋂ FN ≠ ∅}. Наконец, пусть (qM)0 := {(qN)0}. Если N имеет ε-переходы, то δM(Q, a) := ⋃ q∈Q ε-closure(δN(q, a)). Отметим, что построение подмножеств имеет стоимость: поскольку |P (QN)| = 2|QN|, мы видим, что происходит экспоненциальный рост состояний. Чего-то подобного следовало ожидать, поскольку мы симулируем более выразительную модель вы-числения (недетерминированный конечный автомат) с помощью более ограни-ченной (детерминированный конечный автомат). □ Покажем пример преобразования из недетерминированного конечного авто- мата для L 2 (L2 – это множество строк, где предпоследний символ равен 0), приве- денного на рис. 8.4, в соответствующий детерминированный конечный автомат, приведенный на рис. 8.5. 0,1 0,1 0,1 0,1 0 Рис. 8.4  Недетерминированный конечный автомат для L2 q3 q1 q0 q5 q0, q2 q1, q2 q2, q3 q1, q3 q0, q2, q3 q1, q2, q3 q0, q1, q2 q0, q1, q3 q0, q1, q2, q3q0, q1 q0, q30,11 1 11 111 10 0 000 000,1 0,10,1 0,1 0,10,1 Рис. 8.5  Детерминированный конечный автомат для L2 На диаграмме преобразования недетерминированного конечного автомата в детерминированный (рис. 8.4 и 8.5) можно заметить одну вещь: сгенерирована целая куча состояний вместе с соответствующими стрелками – но они не нужны! Это те состояния, которые расположены в правой части диаграммы, что просто расточительно. Вместо этого начнем генерировать состояния и соединения из {q 0}. Соединяем и генерируем только те состояния, которые необходимы для пере- ходов; остальное игнорируем. Иногда это не помогает, и нужны все состояния.\n--- Страница 163 ---\n162  Вычислительные основы Следствие 8.12. Язык является регулярным ⇔ он распознается неким детерми- нированным конечным автоматом ⇔ он распознается неким недетерминиро- ванным конечным автоматом. Задача 8.13. Закончите доказательство теоремы 8.8, то есть покажите, что опера- ции конкатенации и звезды сохраняют регулярность. 8.3.3. Регулярные выражения Регулярные выражения (regular expression, RE) знакомы всем, кто использует компью тер. Они являются средством поиска закономерностей в тексте. Автор книги является заядлым пользователем текстового редактора VIM1, и трудно най- ти редактор с более универсальной функцией сопоставления и замены по шабло- ну. Например, команда :23,43s/\\(.*\\n\\)\\{3\\}/&\\r/ вставляет пустую строку через каждую третью строку между строками 23 и 43 (включительно). Фактически VIM, как и большинство текстовых процессоров, реа-лизует набор команд, выходящих далеко за рамки использования только регуляр-ных выражений. Регулярное выражение – это синтаксический объект, предназначенный для вы- ражения можества строк, то есть языка. В этом смысле регулярные выражения представляют собой модель вычислений, подобную детерминированным или недетерминированным конечным автоматам. Они определяются формально по структурной индукции. В базовом случае: a ∈ å, ε, ∅. На индукционном шаге: если E, F являются регулярными выражениями, то E + F, EF, ( E) ∗, (E). Используя свое интуитивное понимание регулярного выражения, вы должны быть в состоянии решить задачу 8.14. Задача 8.14. Каковы L(a), L(ε), L(∅), L(E + F), L(EF ), L(E∗)? Эта задача просит вас определить семантику регулярного выражения.Задача 8.15. Дайте регулярное выражение для множества строк из нулей и еди- ниц, не содержащих 101 в качестве подстроки.Теорема 8.16. Язык является регулярным тогда и только тогда, когда он задан не- которым регулярным выражением. Мы собираемся доказать теорему 8.16 в двух частях. Сначала предположим, что мы хотим преобразовать регулярное выражение R в недетерминированный конечный автомат А. С этой целью мы используем структурную индукцию, и на каждом шаге конструирования мы гарантируем, что недетерминированный ко-нечный автомат А обладает следующими тремя свойствами (то есть инварианта-ми конструкции): (i) ровно одно принимающее состояние; (ii) ни одной стрелки в исходное состояние; (iii) ни одной стрелки из принимающего состояния. Мы следуем договоренности, что если из состояния на определенном символе стрелки нет, то вычисление отклоняет. Формально мы можем ввести «мусорное состояние» Т, которое представляет собой отклоняющее состояние с петлей на 1 См. http://www.vim.org.\n--- Страница 164 ---\nРегулярные языки  163 всех символах в å, и представить, что существует стрелка на σ ∈ å из состояния q в T, если не было стрелки на σ из q. Базовый случай: регулярное выражение R имеет форму: ε, ∅, a ∈ å. В этом случае недетерминированный конечный автомат имеет три соответствующие формы, изображенные на рис. 8.6. а ε Рис. 8.6  Недетерминированные конечные автоматы ε, ∅, a На индукционном шаге мы строим большие регулярные выражения из мень- ших тремя возможными способами: R + S, RS, R∗. Соответствующие недетерми- нированные конечные автоматы строятся в указанном порядке следующим об- разом: εε ε εεεε εε RRR S S Рис. 8.7  Недетерминированные конечные автоматы R + S, RS, R∗. Мы используем пунктирные круги для обозначения начального и финального состояний предыдущего недетерминированного ко- нечного автомата и волнистую линию для обозначения всех других его состояний В качестве примера мы преобразовываем регулярное выражение (0 + 01)∗ в не - детерминированный конечный автомат с помощью приведенной ниже про-цедуры. 00 : 0 : 01 :1 0 ε 1 Теперь мы докажем другое направление теоремы 8.16: при наличии недетер- минированного конечного автомата мы сконструируем соответствующее регу - лярное выражение. Мы представляем два способа выполнения этого построения.\n--- Страница 165 ---\n164  Вычислительные основы 0 0(0 + 01) : (0 + 01)∗ :0 01 1ε εε εε ε εε ε 8.3.3.1. Метод 1 Этот метод является отличным примером динамического программирования, ко- торый мы рассмотрели в главе 4. Предположим, что A имеет n состояний, и пусть Rij(k) обозначает регулярное выражение, языком которого является множество строк w такое, что: w переводит A из состояния qi в состояние qj, где все промежу - точные состояния имеют свой индекс ≤ k. Тогда R такое, что L(R) = L(A), задается следующим выражением: R := R(n) 1j1 + R(n) 1j2 + ··· + R(n) 1jk, где F = {j1, j2, , jk}. Поэтому теперь мы строим Rij(k) по индукции на k. Для базового случая пусть k = 0 и Rij(0) = x + a1 + a2 + ··· + ak, где i →al j и x = ∅, если i ≠ j и x = ε, если i = j. На индукционном шаге k > 0, и Rij(k) = Rij(k–1) + Rik(k–1)(Rkk(k–1))∗Rkj(k–1). Очевидно, что этот процесс создает соответствующее R с нуля.В качестве примера мы преобразуем детерминированный конечный автомат, который принимает только те строки, которые имеют 00 в качестве подстроки. Такой детерминированный конечный автомат приведен на рис. 8.8. q3 q3 q30,100 11 Рис. 8.8  Детерминированный конечный автомат, который принимает только те строки, которые имеют 00 в качестве подстрокиПуть не посещает k Посещает k не более одного раза\n--- Страница 166 ---\nРегулярные языки  165 Тогда: R(0) 11 = ε + 1 R(0) 12 = R(0) 23 = 0 R(0) 13 = R(0) 31 = R(0) 32 = ∅ R(0) 21 = 1 R(0) 22 = ε R(0) 33 = ε + 0 + 1 Задача 8.17. Завершите построение, вычислив R(1), R(2), R(3) и, наконец, R. 8.3.3.2. Метод 2 Мы преобразовываем детерминированный конечный автомат в регулярное вы- ражение, сначала преобразуя его в обобщенный недетерминированный конеч-ный автомат, то есть недетерминированный конечный автомат, который позво-ляет использовать регулярные выражения в качестве меток своих стрелок. Мы формально определяем обобщенный недетерминированный конечный автомат следующим образом: δ : (Q – { q accept}) × (Q – { qstart}) → R, где состояния «начать» и «принять» являются уникальными. Мы говорим, что G принимает w = w1w2 … wn, wi ∈ å∗, если существует последо- вательность состояний q0 = qstart, q1, , qn = qaccept такая, что для всех i, wi ∈ L(Ri), где Ri = δ(qi–1, qi). Во время транслирования из детерминированного конечного автомата в обоб- щенный недетерминированный, если нет стрелки i → j, то мы помечаем это знаком ∅. Для каждого i мы обозначаем петлю знаком ε. Теперь мы исключаем состоя ния из G до тех пор, пока не останется только qstart →R qaccept. Исключение состояний осу - ществляется, как показано на рис. 8.9. На этом заканчивается доказательство теоремы 8.16. 8.3.4. Алгебраические законы для регулярных выражений Регулярные выражения подчиняются ряду алгебраических законов; эти законы могут быть использованы для упрощения регулярного выражения либо для пере-формулирования регулярного выражения по-другому. q3 q3q3 q3R4 R1 R∗ 2 R3 + R4R3 R1 R2q3 Рис. 8.9  Шаг в редукции состояний\n--- Страница 167 ---\n166  Вычислительные основы Закон Описание R + P = P + R (R + P) + Q = R + (P + Q)(RP)Q = R(PQ ) ∅ + R = R + ∅ = R εR = Rε = R∅R = R∅ = ∅R(P + Q) = RP + RQ (P + Q)R = PR + QRR + R = RКоммутативность +Ассоциативность +Ассоциативность конкатенации∅-тождество для +ε-тождество для конкатенации∅-аннигилятор для конкатенацииЛевая дистрибутивностьПравая дистрибутивностьИдемпотентный закон для объединения Обратите внимание, что коммутативность конкатенации, RP = PR, явно отсут - ствует, поскольку для регулярного выражения она не верна вообще; действитель- но, в качестве строк ab ≠ ba. Вот еще шесть законов, связанных со звездой Клини: (R∗)∗ = R∗; ∅∗ = ε; ε∗ = ε; R+ = RR∗ = R∗R; R∗ = R+ + ε; (R + P)∗ = (R∗P∗)∗. Обратите внимание, что R∗ = R+ + ε не означает, что L(R+) = L(R∗) – { ε}. Теперь вопрос в том, как мы можем проверить, является ли данное формаль- ное суждение валидным алгебраическим законом? Ответ будет захватывающим, потому что он противоречит всему, чему мы научились в математике: мы можем увидеть, что заявленный закон валиден, проверив его на конкретном примере. Следовательно, мы можем проверить универсальное формальное суждение с по-мощью единственного экземпляра. Другими словами, для того чтобы проверить, является ли E = F, где E, F – это регулярные выражения с переменными (R, P, Q, ···), следует конвертировать Е, F в конкретные регулярные выражения С, D, заме- нив переменные символами. Затем проверить, истинно ли, что L(C) = L(D), и если да, то мы можем заключить, что E = F. Например, для того чтобы показать, что (R + P) ∗ = (R∗P∗)∗, мы заменяем R, P на a, b ∈ å, получив (a + b)∗ = (a∗b∗)∗, и мы прове- ряем, является ли этот конкретный экземпляр истинным. Он является истинным, и поэтому мы можем заключить, что (R + P ) ∗ = (R∗P∗)∗ является истинным. Данное свойство часто называют «тестом на алгебраические законы для регулярных вы-ражений». 8.3.5. Свойства замыкания в регулярных языках Перечислим операции на языках, которые сохраняют регулярность. Отметим, что первые три операции были представлены в теореме 8.8. 1. Объединение: если L, M являются регулярными, то и L ⋃ M тоже. 2. Конкатенация: если L, M являются регулярными, то и L · M тоже. 3. Звезда Клини: если L является регулярным, то и L ∗ тоже. 4. Дополнение: если L является регулярным, то и Lc = å∗ – L тоже. 5. Пересечение: если L, M являются регулярными, то и L ⋂ M тоже. 6. Реверс: если L является регулярным, то и LR = {wR|w ∈ L} тоже, где (w1w2 … wn)R = wnwn–1 … w1. 7. Гомоморфизм: h : å∗ → å∗, где h(w) = h(w1w2 wn) = h(w1)h(w2) h(wn). Например, h(0) = ab, h(1) = ε, тогда h(0011) = abab. h(L) = {h(w)|w ∈ L}. Если L является регулярным, то и H(L) тоже.\n--- Страница 168 ---\nРегулярные языки  167 8. Обратный гомоморфизм: h–1(L) = {w|h(w) ∈ L}. Пусть А равно детерминиро- ванному конечному автомату для L; строим детерминированный конечный автомат для h–1(L) следующим образом: δ(q, a) = δ ˆA(q, h(a)). 9. Ненадлежащий префикс: если A является регулярным, то и язык тоже. NOPREFIX(А) = {w ∈ A: ненадлежащий префикс строки w находится в А}. 10. Не расширяется: если А является регулярным, то и язык тоже.NOEXTEND(А) = {w ∈ A : w является ненадлежащим префиксом любой строки в А}. Задача 8.18. Покажите, что вышеуказанные операции сохраняют регулярность. 8.3.6. Сложность преобразований и принятия решений В этом разделе мы прорезюмируем сложность, то есть наиболее известный алго-ритм для трансформаций между разными формализациями регулярных языков. Мы будем использовать форму записи A ↪ B для обозначения преобразования из формализма A в формализм B. 1. Недетерминированный конечный автомат ↪ детерминированный конеч- ный автомат: O(n 32n). 2. Детерминированный конечный автомат ↪ недетерминированный конеч- ный автомат: O(n). 3. Детерминированный конечный автомат ↪ регулярное выражение: O(n34n). 4. Регулярное выражение ↪ недетерминированный конечный автомат: O(n). Задача 8.19. Обоснуйте сложности для каждого приведенного выше преобразо- вания. Теперь рассмотрим следующие свойства принятия решений для регулярных языков: 1. Является ли данный язык пустым? 2. Находится ли данная строка в данном языке? 3. Являются ли два данных языка фактически одним и тем же языком? Задача 8.20. В чем сложность трех указанных задач принятия решения? Обрати- те внимание, что в каждом случае необходимо уточнить, что означает «данный». То есть каким образом данный язык «задается». 8.3.7. Эквивалентность и минимизация автоматов Мы часто заинтересованы в поиске минимального детерминированного конеч-ного автомата для данного языка. Мы говорим, что два состояния эквивалентны, если для всех строк w, δˆ(p, w) принимает ⇔ δˆ(q, w) принимает. Если два состояния не эквивалентны, они различимы. У нас есть рекурсивная процедура (разделяй и властвуй) для нахождения пар различимых состояний. Сначала если p принимает и q нет, то {p, q} являет - ся парой различимых состояний. Это «нижний» случай рекурсии. Если r = δ(p, a) и s = δ(q, a), где a ∈ å и { r, s} уже найдены различимыми, то {p, q} различимы; это рекурсивный случай. Мы хотим формализовать это с помощью так называемого\n--- Страница 169 ---\n168  Вычислительные основы алгоритма заполнения таблицы, представляющего собой рекурсивный алгоритм поиска различимых пар состояний. А EB FC GD H0 11 1 11 1 10 0 00 0 00 1 A B C D E F G B × C × × D × × × E × × × F × × × × G × × × × × × H × × × × × × Рис. 8.10  Пример детерминированного конечного автомата и соответствующей таблицы. Различимые состояния отмечены знаком «×»; таблица заполняется только ниже диагонали, так как она симметрична Задача 8.21. Спроектируйте алгоритм рекурсивного заполнения таблицы. Дока- жите, что в вашем алгоритме, если два состояния алгоритмом не различаются, эти два состояния эквивалентны. Теперь мы применим алгоритм заполнения таблицы, чтобы показать эквива- лентность автоматов и их минимизировать. Пусть D1, D2 равны двум детермини- рованным конечным автоматам. Для того чтобы увидеть их эквивалентность, то есть L(D 1) = L(D2), выполним алгоритм заполнения таблицы на их «объединении» и проверим, являются ли q0D1 и q0D2 эквивалентными. Обратите внимание, что эквивалентность состояний является отношением эквивалентности (см. раздел 9.3). Мы можем использовать этот факт, чтобы ми-нимизировать детерминированные конечные автоматы. Для данного детерми-нированного конечного автомата мы выполняем алгоритм заполнения таблицы, найдя все эквивалентные состояния и, следовательно, все классы эквивалентно-сти. Мы называем каждый класс эквивалентности блоком. В примере на рис. 8.10 будут следующие блоки: {E, A}, {H, B}, {C}, {F, D}, {G}. Состояния внутри каждого блока эквивалентны, и блоки не пересекаются.Теперь мы построим минимальный детерминированный конечный автомат с состояниями, которые заданы блоками следующим образом: γ(S, a) = T, где δ(p, a) ∈ T для p ∈ S. Мы должны показать, что γ хорошо определено; предположим, мы выбираем другое q ∈ S. По-прежнему ли истинно, что δ(q, a) ∈ T? Предполо- жим, что нет, то есть (q, a) ∈ T′, поэтому δ(p, a) = t ∈ T и δ(q, a) = t′ ∈ T′. Поскольку T ≠ T′, {t, t′} является различимой парой. Но тогда такой парой является и {p, q}, что противоречит тому, что они оба находятся в S. Задача 8.22. Покажите, что из этой процедуры мы получаем минимальный де- терминированный конечный автомат.Задача 8.23. Реализуйте алгоритм минимизации. Допустим, что вход задан в виде таблицы переходов, где алфавит задан в виде {0, 1}, и строки таблицы представ- ляют состояния, где первая строка обозначает начальное состояние. Обозначьте\n--- Страница 170 ---\nРегулярные языки  169 соответствующие принимающим состояниям строки специальным символом, к примеру символом ∗. Обратите внимание, что в соответствии с этим соглашением вам не нужно подписывать строки и столбцы входных данных, за исключением символа ∗, обо- значающего принимающие состояния. Таким образом, приведенная на рис. 8.1 таблица переходов будет представлена следующим образом: 2 0 1 1 * 2 1 8.3.8. Нерегулярные языки Легко показать, что язык является регулярным; для этого нам нужно только про- демонстрировать одну из моделей вычислений, которая описывает регулярные языки: детерминированный конечный автомат, недетерминированный конеч-ный автомат или регулярное выражение. Следовательно, доказательство станет экзистенциальным и будет состоять в том, что при заданном (предполагаемом) регулярном языке L мы должны показать существование машины A такой, что L(A) = L. Но как показать, что язык не является регулярным? Предположительно мы должны показать, что для каждой машины A, L(A) ≠ L, что по контрасту является универсальным доказательством. Это, интуитивно, кажется более сложной пропо-зицией, потому что мы не сможем перечислить бесконечно много машин и про-верить каждую из них. Следовательно, нам нужен новый прием; на самом деле мы предлагаем два таких приема: «лемму о накачке» и теорему Майхилла–Нероуда. Тем самым мы входим в очень сложную область теории вычислений: доказатель-ство результатов невозможности. К счастью, результаты невозможности для регу - лярных языков, то есть показывающие, что данный язык не является регулярным, довольно просты. Это происходит потому, что регулярные языки описываются от - носительно слабыми машинами. Чем сильнее модель вычислений, тем труднее дать для нее результаты невозможности. Мы заинтересованы в свойствах регулярных языков, потому что важно по- нимать вычисления «без памяти». Многие встраиваемые устройства, такие как ритмоводители, не имеют памяти или аккумулятора для поддержания памяти. Регулярные языки могут разрешаться с помощью приборов без памяти. 8.3.8.1. Лемма о накачке Лемма 8.24 (лемма о накачке). Пусть L равно регулярному языку. Тогда существу - ет постоянная n (в зависимости от L) такая, что для всех w ∈ L, |w| ≥ n, мы можем разбить w на три части w = xyz таких, что: 1) y ≠ ε; 2) |xy| ≤ n; 3) для всех k ≥ 0, xykz ∈ L. Доказательство. Предположим, что L является регулярным. Тогда существует де- терминированный конечный автомат A такой, что L = L(A). Пусть n равно числу состояний A. Рассмотрим любое w = a1a2 … am, m ≥ n:\n--- Страница 171 ---\n170  Вычислительные основы а1 а2 а3 … аi аi+1 … аj аj+1 … аm .↑p0↑p1↑p2↑pi↑pj↑pmx y z □ Задача 8.25. Покажите, что L = {0n1n|n ≥ 0} не является регулярным. Задача 8.26. Покажите, что L = {1p| p является простым} не является регулярным. 8.3.8.2. Теорема Майхилла–Нероуда Теорема Майхилла–Нероуда обеспечивает определение регулярных языков, ко- торое дается без упоминания модели вычислений. Она характеризует регуляр-ные языки в терминах реляционных свойств строк. См. раздел 9.3, для того чтобы осве жить свои знания об отношениях эквивалентности. Начнем с некоторых определений и наблюдений. С учетом языка L ⊆ å ∗ пусть ≡L равно отношению на å∗ × å∗ такому, что x ≡L y, если для всех z, xz ∈ L ⇔ yz ∈ L. Задача 8.27. Покажите, что ≡L на самом деле является отношением эквивалент - ности. Предположим, что некоторый детерминированный конечный автомат D рас - познает L, и k = |QD|. Мы говорим, что X является множеством, которое попарно различимо языком L тогда и только тогда, когда для каждых двух несовпадающих x, y ∈ X, x ≢L y. Покажем, что если |QD| = k, то | X| ≤ k. Предположим, что {x1, x2, , xk+1} ⊆ X. Поскольку существует k состояний, существует два xi, xj, не совпадающих так, что ⇒ δˆD(q0, xi) = δˆ(q0, xj) ⇒ ∀z[δ ˆD(q0, xi z) = δ ˆ(q0, xj z)] ⇒ ∀z[xi z ∈ L ⇔ xj z ∈ L] ⇒ xi ≡L xj. Таким образом, невозможно, чтобы |X| > k. Обозначим через индекс(L) мощ- ность |X| наибольшего попарно различимого множества X ⊆ L. Теорема 8.28 (Майхилла–Нероуда). L является регулярным тогда и только тог - да, когда индекс(L) является конечным. Более того, индекс(L) является размером наименьшего детерминированного конечного автомата для L. Доказательство. Предположим, что индекс(L) = k, и пусть X = {x1, x2, , xk}; сначала отметим, что для любого x ∈ å∗, x ≡L xi для некоторого (уникального) xi ∈ X; в про- тивном случае X ⋃ {x} будет более крупным множеством, которое «попарно раз- личимо языком L». Уникальность следует за транзитивностью. Пусть D является таким, что QD = {q1, , qk} и δD(qi, a) = qj ⇔ xi a ≡L xj. Тот факт, что существует (уникальный) xj такой, что xia ≡L xj, следует из приве- денного выше наблюдения. Тем самым δ ˆ(qi, w) = qj ⇔ xiw ≡L xj. Пусть FD = {qi ∈ QD : xi ∈ L}, и пусть q0 := qi такое, что xi ≡L ε. Легко показать, что наш D работает: x ∈ L ⇔ x ≡L xi для некоторого xi ∈ L. Для того чтобы это увидеть, обратите внимание, что x ≡L xi для уникального xi, и если\n--- Страница 172 ---\nРегулярные языки  171 это xi ∉ L, то xε ∈ L, тогда как xi ε ∉ L, поэтому мы получаем противоречие x ≢L xi. Наконец, x ≡L xi тогда и только тогда, когда δ ˆ(q0, x) = qi ∈ FD. □ 8.3.9. Автоматы на членах См. раздел 9.4 для получения необходимой общей информации по математиче- ской логике. В первопорядковой логике словарь (вокабуляр) V = {f1, f2, f3, ; R1, R2, R3, } представляет собой множество символов функций (f) и отношений (R). Каждая функция и отношение имеют арность, то есть «сколько аргументов функция или отношение принимает». Функция с арностью 0 называется константой. Мы определяем V-члены (члены, когда V понимается из контекста) по струк - турной индукции следующим образом: любая константа c (то есть арность(c) = 0) является членом, и если t 1, , tn являются n-членами, и f является символом функ - ции с арностью n, то ft1 … tn тоже является членом. То есть члены конструируются путем смежного расположения. Пусть T равно множеству всех членов. Обратите внимание, что, в отличие от первопорядковой логики, мы не вводим переменные. Задача 8.29. Покажите, что члены «однозначно читаемы» (подсказка: сравните с теоремой 9.80.) V-алгебра (алгебра, когда V понимается из контекста) является интерпретаци- ей данного словаря V. То есть  представляет собой V-алгебру, если она состоит из непустого множества А (именуемого универсумом ) вместе с интерпретаци- ей всех символов функций и отношений V. То есть при наличии f ∈ V арности n  обес печивает интерпретацию для f в том смысле, что она назначает f смысл f : An → A. Мы пишем f для обозначения f, или просто f = f.  назначает каждому члену t интерпретацию t ∈ A. Задача 8.30. Определите t для произвольных членов. Какая структура данных может быть естественным образом связана с осуществлением такой интерпрета- ции? Какова естественная интерпретация для отношений, то есть какова интер-претация (Rt 1 … tn)? Четко укажите разницу в «типе» между f и R. Мы говорим, что алгебра  является автоматом, если универсум  конечен, а V имеет один унарный символ отношения R. Мы говорим, что  принимает член t ∈ T, если t ∈ R. Как и в случае детерминированного конечного автомата, мы делаем L() равным множеству t ∈ T, которое принимается алгеброй . Задача 8.31. Пусть å равно конечному алфавиту, и пусть V = å′ ⋃ {c}, где c – это но - вый символ, обозначающий функцию с арностью 0, и каждый a ∈ å интерпрети- руется как несовпадающий унарный функциональный символ a в å′ (тем самым |å| = |å′|). Покажите, что язык L над å является регулярным тогда и только тогда, когда некоторый автомат  принимает L′ = {an … a2a1c : a1a2 … an ∈ L}. Мы говорим, что подмножество L ⊆ T является регулярным, если L = L() для некоторого автомата . Обратите внимание, что это определение регулярности является более широким, поскольку не все функции в V обязательно унарны (ког - да они унарны, как показала задача 8.31, это определение «регулярности» соот - ветствует классическому определению «регулярности»).\n--- Страница 173 ---\n172  Вычислительные основы Задача 8.32. Покажите, что регулярные языки (в этой новой обстановке) замкну - ты при объединении, дополнении и пересечении. 8.4. к онтекстно -свободные языки Хомский [Chomsky (1965)] занимается проблемой определения «генеративной» грамматики для английского языка, т. е. синтаксисом, определяющим строки, которые являются хорошо сформированными предложениями английского языка. Несмотря на то что этот подход не в полной мере работает в лингвисти-ке, он имеет колоcсальные последствия в информатике, поскольку обеспечивает методы, необходимые для точного определения синтаксиса языка программи-рования. Первым языком, разработанным в соответствии с принципами Хомского, был ALGOL (великий прародитель C, C++, Pascal и др.). ALGOL был основан на грамма-тиках Хомского и, следовательно, нечитаем для людей; поэтому первые програм-мисты на языке ALGOL ввели понятие отступа. В 1960-е годы люди мыслили не в терминах алгоритмов, а скорее в терминах воображаемых машин, то есть в терминах аппаратных средств. Магазинные авто- маты (автоматы с магазинной памятью, pushdown automaton, PDA) – это маши- ны, соответствующие контекстно-свободным грамматикам (context-free grammar, CFG), так же как детерминированные конечные автоматы соответствуют регуляр-ным языкам. Основное различие между детерминированными конечными авто-матами и магазинными автоматами заключается в том, что детерминированные конечные автоматы представляются собой «алгоритмы», которые не требуют ди-намического выделения памяти (без операции malloc ), а магазинные автоматы предусматривают динамическое выделение памяти, хотя и в самом примитив-ном типе структуры данных: стеке. 8.4.1. Контекстно-свободные грамматики Контекстно-свободная грамматика (context-free grammar, CFG) выражается кор-тежем G = (V, T, P, S), где буквы обозначают множество переменных, терминалов, продукций и заданную начальную переменную. Например, в грамматике языка палиндромов используется следующая продук - ция: P → ε|0|1|0P 0|1P 1. А грамматика для языка (редуцированных) алгебраических выражений равна G = ({E, T, F}, å, P, E), где å = {a, +, ×, (,)} и P равно следующему множеству продукций: E → E + T | T; T → T × F |F; F → (E)|a. Здесь мы используем E для выражений, T для членов (термов) и F для состав- ляющих (сомножителей, факторов). В рамках нормальных интерпретаций знаков + и × три приведенные выше продукции в указанном порядке отражают следую-щие структурные факты об алгебраических выражениях:\n--- Страница 174 ---\nКонтекстно-свободные языки  173 выражение – это член либо сумма выражения и члена; член – это либо фактор, либо произведение члена и фактора; фактор – это скобочное выражение либо терминал «a». Таким образом, самым простым выражением будет выражение, состоящее из одного члена, который, в свою очередь, состоит из одного фактора: a. Рассмотрим строку αAβ над алфавитом (V ⋃ T)∗, где A ∈ V и A → γ является про- дукцией. Тогда мы можем сказать, что αAβ порождает αγβ в символах: αAβ ⇒ αγβ. Мы используем ⇒∗ для обозначения 0 или более шагов. Теперь мы можем опреде- лить язык грамматики как L(G) = {w ∈ T∗|S ⇒∗ w}. Лемма 8.33. L(({P}, {0, 1}, {P → ε|0|1|0P 0|1P 1}, P)) есть множество палиндромов над {0,1}. Доказательство. Предположим, w – это палиндром. Мы покажем по индукции на |w|, что P ⇒∗ w. Базовый случай: |w| ≤ 1, поэтому w = ε, 0, 1, и поэтому используем единственное правило P → ε, 0, 1. Индукционный шаг: для |w| ≥ 2, w = 0x0, 1 x1, и по индукционной гипотезе P ⇒∗ w. Предположим, что P ⇒∗ w. Мы показываем по индукции на числе шагов в дери- вации, что w = wR. Базовый случай: деривация имеет один шаг. Индукционный шаг: P ⇒ 0P 0 ⇒∗ 0x0 = w, где 0 вместо этого можно заменить на 1. □ Предположим, что у нас есть грамматика G = (V, T, P, S) и S ⇒∗ α, где α ∈ (V ⋃ T)∗. Тогда α называется сентенциальной формой (этой конкретной грамматики G). Пусть L(G) равно множеству этих сентенциальных форм, которые находятся в T*. Другими словами, как и в случае регулярных языков, L(G) является языком G. Мы определим дерево разбора для (G, w) следующим образом: это корневое дерево, в котором S помечает корень, и листья помечены слева направо символами w. Для каждого внутреннего узла, то есть всех узлов, кроме листьев, метки имеют следующую форму: A X1 X2 … Xn где A → X1 X2 X3 … Xn – это правило в P. Существует ряд способов продемонстрировать, что данное слово w может быть сгенерировано грамматикой G, то есть доказать, что w ∈ L(G). Эти способы следую- щие: рекурсивный вывод, деривация, левосторонняя деривация, правосторонняя де- ривация и порождение дерева разбора. Рекурсивный вывод похож на деривацию, за исключением того, что мы генерируем деривацию из w в S. Лево(право)сторонняя деривация – это деривация, которая всегда применяет правило к крайне левой (правой) переменной в промежуточной сентенциальной форме. Мы говорим, что грамматика неоднозначна, если есть слова, которые имеют два разных дерева разбора. Например, G = ({E}, [0–9], {E → E + E, E ∗ E}, E) неоднозначна, так как деревья разбора, соответствующие этим двум деривациям, различны:\n--- Страница 175 ---\n174  Вычислительные основы E ⇒ E + E ⇒ E + E ∗ E; E ⇒ E ∗ E ⇒ E + E ∗ E. Проблема в том, что деревья разбора назначают строке смысл, и два разных дерева разбора назначают два возможных смысла, отсюда и «неоднозначность». Задача 8.34. Покажите, что расширенные регулярные языки, как определено в разделе 8.3.9, содержатся в классе контекстно-свободных языков. 8.4.2. Магазинные автоматы Магазинные автоматы (PDA) – это недетерминированные конечные автоматы со стеком. Формальное определение магазинного автомата дается следующим об-разом: P = (Q, å, Γ, δ, q 0, F), где: 1) Q – конечное множество состояний; 2) å – конечный входной алфавит; 3) Γ – конечный стековый алфавит; 4) δ(q, x, a) = {(p1, b1), , ( pn, bn)}; 5) q0 – начальное состояние; 6) F – принимающие состояния. Задача 8.35. Каким является простой магазинный автомат для {wwR|w ∈ {0, 1}∗}? P вычисляет следующим образом: он принимает заданную строку w в å∗, если w = w1w2 … wm, где wi ∈ åε, где |w| = n ≤ m. То есть существует ε-заполнение w такое, что существует последовательность состояний r0, r1, , rm в Q и последовательность содержимого стека s0, s1, , sm ∈ Γ∗ такая, что соблюдаются следующие три условия: 1) r0 = q0 и s0 = ε; 2) (ri+1, b) ∈ δ(ri, wi+1, a), где si = at, si+1 = bt и a, b ∈ Γε и t ∈ Γ∗. То есть M перемеща- ется правильно в соответствии с состоянием, стеком и следующим входным символом; 3) r m ∈ F. Конфигурация – это кортеж ( q, w, γ): состояние, оставшиеся входные данные, со- держимое стека. Если (p, α) ∈ δ(q, a, X), то (q, aw, Xβ) → (p, w, αβ). Лемма 8.36. Если (q, x, α) ⇒∗ (p, y, β), то (q, xw, αγ) ⇒∗ (p, yw, βγ). Задача 8.37. Докажите лемму 8.36. Существует два эквивалентных способа точно определить, что именно озна- чает для магазинного автомата принять входное слово. Существует принятие по финальному состоянию, где: L(P) = {w|(q 0, w, $) ⇒∗ (q, ε, α), q ∈ F}, и принятие по пустому стеку: L(P) = {w|(q0, w, $) ⇒∗ (q, ε, ε)}. При проектировании магазинных автоматов удобнее использовать одно из этих определений, чем другое, но, как демонстрирует следующая теорема, оба определения выражают одно и то же множество языков.\n--- Страница 176 ---\nКонтекстно-свободные языки  175 Лемма 8.38. L принимается магазинным автоматом по конечному состоянию тогда и только тогда, когда он принимается магазинным автоматом по пустому стеку. Задача 8.39. Докажите лемму 8.38. Теорема 8.40. Контекстно-свободные грамматики и магазинные автоматы явля- ются эквивалентными.Доказательство. Сначала мы покажем, как выполнять трансляцию контекстно- свободной грамматики в эквивалентный магазинный автомат. Левая сентенци- альная форма представляет собой особый способ выразить конфигурацию, где: хАα. ∈ T ∗хвост Хвост появляется в стеке, и x является префиксом потребленных к этому мо- менту входных данных. Идея состоит в том, что входные данные для магазинного автомата заданы w = xy и Aα ⇒∗ y. Предположим, что магазинный автомат находится в конфигурации (q, y, Aα) и что он использует правило A → β и входит в (q, y, βγ). Магазинный автомат симу - лирует грамматику следующим образом: выполняется разбор начального сегмен-та β, и если есть терминальные символы, то они сравниваются с входными данны- ми и удаляются до тех пор, пока первая переменная β не появится наверху стека. Этот процесс повторяется, и магазинный автомат принимает по пустому стеку. Например, рассмотрим P → ε|0|1|0P 0|1P1. Соответствующий магазинный авто- мат имеет переходы: δ(q 0, ε, $) = {(q, P$)}; δ(q, ε,P) = {(q, 0 P0), (q, 0), (q, ε), (q, 1 P1), (q, 1)}; δ(q, 0, 0) = δ(q, 1, 1) = {(q, ε)}; δ(q, 0, 1) = δ(q, 1, 0) = ∅; δ(q, ε, $) = (q, ε). Вычисление представлено на рис. 8.11. Z P 1 P 0 P 0 P 0 0 1 Z Z P 1 P 0 P 0 0 1 Z 1 Z 0 1 0 0 1 Z Z 1 Z 0 1 Z Z 1 Z Z Рис. 8.11  Вычисление для P ⇒ 1P 1 ⇒ 10P 01 ⇒ 100P 001 ⇒ 100001 Теперь мы дадим схематичное описание того, как выполнять трансляцию из магазинного автомата в контекстно-свободную грамматику. Идея заключается в «чистом выталкивании» одного символа стека, потребляя некоторые входные данные. Переменными являются: A [pXq ] для p, q ∈ Q, X ∈ Γ. A[pXq ] ⇒∗ w тогда и только\n--- Страница 177 ---\n176  Вычислительные основы тогда, когда w переводит магазинный автомат из состояния p в состояние q и вы- талкивает Х из стека. Продукции: для всех p, S → A[q0$p], и всякий раз, когда мы имеем: (r, Y1Y2 Yk) ∈ δ(q, a, X), мы привлекаем правило: A[qXr k] → aA[rY1r1] A[r1Y2r2] A[rk–1Ykrk], где a ∈ å ⋃ {ε}, r1, r2, , rk ∈ Q – это все возможные списки состояний. Если (r, ε) ∈ δ(q, a, X), то мы имеем A[qXr ] → a. Задача 8.41. Покажите, что A[qXp ] ⇒∗ w тогда и только тогда, когда (q, w, X) ⇒∗ (p, ε, ε). Это завершает доказательство леммы. □ Магазинный автомат является детерминированным, если |δ (q, a, X)| ≤ 1, и второе условие состоит в том, что если для некоторого a ∈ å |δ(q, a, X)| = 1, то | δ(q, ε, X)| = 0. Мы называем такие машины детерминированными магазинными автоматами (deterministic PDA). Лемма 8.42. Если L является регулярным, то L = L(P) для некоторого детермини- рованного магазинного автомата P.Доказательство. Просто прослеживаем, что детерминированный конечный авто- мат – это детерминированный магазинный автомат. □ Обратите внимание, что детерминированные магазинные автоматы, которые принимают по конечному состоянию, не эквивалентны детерминированным магазинным автоматам, которые принимают по пустому стеку. Для того чтобы изучить связь между принятием по состоянию либо по пустому стеку в контексте детерминированных магазинных автоматов, введем следующее свойство языков: L имеет префиксное свойство, если существует пара (x, y), x, y ∈ L, такая, что y = xz для некоторого z. Например, {0}* имеет префиксное свойство. Лемма 8.43. L принимается детерминированным магазинным автоматом по пус тому стеку ⇔ L принимается детерминированным магазинным автоматом по конечному состоянию, и L не имеет префиксного свойства. Лемма 8.44. Если L принимается детерминированным магазинным автоматом, то L является однозначным. 8.4.3. Нормальная форма Хомского В этом разделе мы покажем, что каждая контекстно-свободная грамматика может быть помещена в особо простую форму, называемую нормальной формой Хомского (Chomsky normal form, CNF). Контекстно-свободная грамматика находится в нор-мальной форме Хомского, если все правила принимают одну из следующих трех форм: 1) S → ε, где S – это начальная переменная; 2) A → BC, где A, B, C – это переменные, возможно, повторяющиеся; 3) A → a, где A – это переменная, и a – это символ алфавита (не ε).\n--- Страница 178 ---\nКонтекстно-свободные языки  177 Нормальная форма Хомского имеет много желательных свойств, но одним из наиболее важных следствий является так называемый алгоритм CYK (алго- ритм 8.1, раздел 8.4.4), представляющий собой алгоритм динамического програм- мирования для решения w ∈ L(G) для данного слова w и контекстно-свободной грамматики G. Теперь мы покажем, как преобразовывать произвольную контекстно-свобод- ную грамматику в нормальную форму Хомского. В последующем обсуждении S – это переменная, X ∈ V ⋃ T, w ∈ T ∗ и α, β ∈ (V ⋃ T)∗. Мы говорим, что символ X является полезным, если существует деривация такая, что S ⇒∗ αXβ ⇒∗ w. Мы говорим, что X генерирует, если X ⇒∗ w ∈ T∗, и мы говорим, что X достижим, если существует деривация S ⇒∗ αXβ. Полезный символ будет генерировать и будет достижимым. Таким образом, если сначала исключить негенерирующие симво-лы, а затем из оставшейся грамматики – недостижимые символы, то останутся только полезные. Задача 8.45. Докажите, что если сначала исключить негенерирующие символы, а затем из оставшейся грамматики исключить недостижимые символы, то оста- нутся только полезные символы. Покажем, как мы устанавливаем множество генерирующих символов и мно- жество достижимых символов. Безусловно, каждый символ в T генерирует, и если A → α является продукцией, и каждый символ в α генерирует (или α = ε), то А тоже генерирует. Схожим образом S достижим, и если А достижим, и A → α является продукцией, то каждый символ в α достижим. Утверждение 8.46. Если L имеет контекстно-свободную грамматику, то L – { ε} является контекстно-свободной грамматикой без продукций в форме A → ε и без продукций в форме A → B.Доказательство. Переменная допускает наличие пустого значения, если A ⇒ ∗ ε. Для вычисления переменных, допускающих пустое значение: если A → ε является продукцией, то А допускает пустое значение; если B → C1C2 … Ck является про- дукцией, и все Ci допускают пустое значение, то и B тоже. После того как у нас все переменные допускают пустое значение, мы исключаем ε-продукции следующим образом: исключаем все A → ε. Если A → X1X2 … Xk является продукцией и m ≤ k из Xi допускают пустое значе- ние, то добавить 2m версий правила присутствия/отсутствия, допускающих пус - тое значение переменных (если m = k, то не добавлять случай, когда они все от - сутствуют). Устранение единичных продукций: A → B. Если A ⇒∗ B, то ( A, B) является единич- ной парой. Найти все пары: (А, А) является единичной парой, и если (A, B) являет - ся единичной парой, и B → C является продукцией, то (А, В) является единичной парой. Чтобы устранить единичные продукции: вычислить все единичные пары, и если (A, B) является единичной парой и B → α является неединичной продукци- ей, то добавить продукцию A → α. Отбросить все единичные продукции. □ Теорема 8.47. Каждый контекстно-свободный язык имеет контекстно-свобод- ную грамматику в нормальной форме Хомского.\n--- Страница 179 ---\n178  Вычислительные основы Доказательство. Чтобы преобразовать G в нормальную форму Хомкого, начнем с устранения всех ε-продукций, единичных продукций и бесполезных символов. Расположим все тела длиной ≥ 2 так, чтобы они состояли только из переменных (путем введения новых переменных), и, наконец, разобьем тела длиной ≥ 3 на каскад продукций, каждая из которых имеет тело длиной ровно 2. □ 8.4.4. Алгоритм CYK С учетом грамматики G в нормальной форме Хомского и строки w = a1a2 … an мы можем проверить, является ли истинным, что w ∈ L(G), используя динамический алгоритм CYK1 (алгоритм 8.1). При передаче в него G, w = a1a2 … an алгоритм 8.1 строит n×n-таблицу T, где каждый элемент содержит подмножество V. В конце w ∈ L(G) тогда и только тогда, когда начальная переменная S содержится в пози- ции (1, n) таблицы T. Главная идея – поставить переменную X1 в позицию (i, j), если Х2 находится в позиции (i, k), Х3 находится в позиции (k + 1, j) и Х1 → X2 X3 является правилом. Смысл этого заключается в том, что X1 находится в позиции (i, k) тогда и только тогда, когда X1 ⇒∗ ai … ak, то есть подстрока ai … ak входной строки может быть сгенерирована из X1. Пусть V = {X1, X2, , Xm}. Алгоритм 8.1. CYK for i = 1 n do for j = 1 m do Поместить переменную xj в (i, i) тогда и только тогда, когда Xj → ai является правилом грамматики G end forend forfor 1 ≤ i < j ≤ n do for k = i ( j – 1) do i f (∃X p ∈ (i, k) ∧ ∃Xq ∈ (k + 1, j ) ∧ ∃Xr → Xp Xq) then Поставить Xr в (i, j) end if end forend for В примере на рис. 8.12 мы показываем, какие ячейки в таблице необходимо ис - пользовать для вычисления содержимого (2, 5). Задача 8.48. Покажите правильность алгоритма 8.1. Задача 8.49. Реализуйте алгоритм CYK. Выберите условные обозначения для представления контекстно-свободных грамматик, и хорошо задокументируйте их в своем исходном коде. Вы можете исходить из того, что грамматика задана в нормальной форме Хомского, или же вы можете выполнять ее явную проверку. Для того чтобы сделать проект еще более амбициозным, вы можете реализовать трансляцию общей грамматики в нормальную форму Хомского. 1 Назван в честь изобретателей: Кока–Янгера–Касами (Cocke–Younger–Kasami).\n--- Страница 180 ---\nКонтекстно-свободные языки  179 × (2, 2) (2, 3) (2, 4) (2, 5) × × (3, 5) × × × (4, 5) × × × × (5, 5) Рис. 8.12  Вычисление элемента (2, 5): обратите внима- ние, что нам требуются все элементы в одной строке и одном столбце (за исключением тех, которые находятся ниже глав-ной диагонали). Таким образом, алгоритм CYK динамически вычисляет элементы по диагоналям, начиная с главной диа- гонали и заканчивая правым верхним углом 8.4.5. Лемма о накачке для контекстно-свободных языков Лемма 8.50 (лемма о накачке для контекстно-свободных языков). Существу - ет p такое, что любое s, | s| ≥ p, можно записать как s = uvxyz, и: 1) uvixyiz находится в языке, для всех i ≥ 0; 2) |vy| > 0; 3) |vxy| ≤ p. Доказательство. Следуя рассуждениям по принципу Дирихле (на основе голу - биных клеток), используемому для демонстрации леммы о накачке для регуляр-ных языков (см. раздел 8.3.8.1, лемма 8.24), рисунка 8.13 должно быть достаточно для того, чтобы убедить читателя: оказывается, что этот аргумент лучше всего выполняется вместе с трансляцией грамматики в нормальную форму Хомского (раздел 8.4.3). Затем находим длину входных данных, которая гарантирует высоту дерева не менее |V | + 1. Подробности оставляются читателю. □ S R R хu v y z Рис. 8.13  Если слово достаточно длинное, то высота дерева раз- бора довольно велика, для того чтобы заставить некоторую пере- менную (R) повторяться вдоль некоторой ветви Задача 8.51. Закончите доказательство леммы 8.50. Задача 8.52. Покажите, что L = {0n1n2n|n ≥ 1} не является нормальной формой Хом- ского.\n--- Страница 181 ---\n180  Вычислительные основы 8.4.6. Дальнейшие замечания по нормальной форме Хомского Нормальные формы Хомского не имеют таких же широких свойств замыкания, как регулярные языки (см. раздел 8.3.5). Нормальные формы Хомского замыкают - ся при объединении, конкатенации, звезде Клини (∗), гомоморфизмах и реверсах. Касаясь гомоморфизма, обратите внимание, что гомоморфизм может быть при-менен к деривации. Что касается реверсов, то следует просто заменить каждую A → α на A → α R. Нормальные формы Хомского не замыкаются при пересечении или дополне- нии. Для того чтобы увидеть, что они не замыкаются при пересечении, обратите внимание, что L 1 = {0n1n2i|n, i ≥ 1} и L2 = {0i1n2n|n, i ≥ 1} являются нормальными фор- мами Хомского, но L1 ⋂ L2 = {0n1n2n|n ≥ 1} таковыми не являются. Для того чтобы увидеть, что нормальные формы Хомского не замыкаются при дополнении, обратите внимание, что язык L = {ww : w ∈ {a, b}∗} не является кон- текстно-свободным, однако Lc является контекстно-свободным. Оказывается, что демонстрация того, что Lc является контекстно-свободным языком, является нетривиальной; проектирование контекстно-свободной грамматики сопряжено с трудностями: в первую очередь стоит отметить, что никакие нечетные строки не имеют формы ww , поэтому первым правилом должно быть: S → O|E O → a|b|aaO|abO|baO|bbO; здесь O генерирует все нечетные строки. С другой стороны, E генерирует строки четной длины, не имеющие форму ww , то есть все строки имеют форму: X = a b Y = b a . Нам нужно правило: E → X |Y, и теперь X → PQ , Y → VW , P → RPR, V → SVS, P → a, V → b, Q → RQR , W → SWS, Q → b, W → a, R → a |b, S → a |b. Обратите внимание, что все R могут быть заменены любым a или b, что дает нам желаемое свойство.Задача 8.53. Покажите, что если L является контекстно-свободным языком и R является регулярным языком, то L ⋂ R является контекстно-свободным языком.Задача 8.54. Мы знаем, что контекстно-свободные языки замкнуты при подста- новках (типе гомоморфизма): для каждого a ∈ å мы выбираем L a, который назы- ваем s(a). Для любого w ∈ å∗, s(w) является языком из x1x2 … xn, xi ∈ s(ai). Покажите, что если L является контекстно-свободным языком и s(a) является контекстно- свободным языком ∀а ∈ å, то s(L) = ⋃w∈L s(w) тоже является контекстно-свободным языком.\n--- Страница 182 ---\nМашины Тьюринга  181 В то время как алгоритм CYK позволяет нам решить, находится ли данная стро- ка w на языке некоторой данной контекстно-свободной грамматики G, сущест - вует много свойств контекстно-свободной грамматики, которые, к сожалению, неразрешимы. Что это означает? Это означает, что существуют вычислительные проблемы в отношении контекстно-свободной грамматики, для которых нет ал-горитмов. Например: 1) является ли данная контекстно-свободная грамматика G неоднозначной? 2) является ли данный контекстно-свободный язык внутренне неоднозначным? 3) является ли пересечение двух контекстно-свободных языков пустым? 4) с учетом G 1, G2 является ли истинным, что L(G1) = L(G2)? 5) эквивалентна ли данная контекстно-свободная грамматика å∗? Показать, что у конкретной задачи нет алгоритма, который ее решает, очень трудно. По сути дела, мы должны ввести новый метод, для того чтобы показать, что пять приведенных выше вопросов являются «неразрешимыми». Мы делаем это в разделе 8.5. Для нетерпеливых см. раздел 8.5.9. 8.4.7. Другие грамматики Контекстно-чувствительные грамматики (context-sensitive grammar, CSG) имеют правила формы: α → β, где α, β ∈ (T ⋃ V) ∗ и |α| ≤ |β|. Язык является контекстно-чувствительным, если он имеет контекстно-чувствительную грамматику. В элегантной связи со слож - ностью, как оказалось, контекстно-чувствительные языки точно описывают мно-жество тех языков, которые могут быть решены недетерминированными маши-нами Тьюринга за линейное время (см. следующий раздел). Система перезаписи (также именуемая полутуевской системой 1) – это грамма- тика, в которой нет никаких ограничений; α → β для произвольных α, β ∈ (V ⋃ T)∗. Системы перезаписи соответствуют наиболее общей модели вычислений в том смысле, что все, что может быть решено алгоритмически, может быть решено с помощью системы перезаписи. Таким образом, язык имеет систему перезаписи тогда и только тогда, когда он «вычислим», что является темой следующих раз-делов. 8.5. м ашины тьюринга Машина Тьюринга – это автомат с конечным управлением и бесконечной лентой, где бесконечная лента выражает идею «неограниченного пространства». Перво-начально входные данные помещаются на ленту, считывающе-записывающая го-ловка ленты расположена на первом символе входных данных, и состояние равно q 0. Все остальные ячейки содержат пустоты. 1 Полутуевская система – это система перезаписи слов, близкая к грамматике типа 0. Единственное различие заключается в том, что в полутуевских системах нет разделения на терминальные и нетерминальные символы и нет выделенного начального символа. См. https://pl.wikipedia.org/wiki/System_p%C3%B3%C5%82thueowski. – Прим. перев.\n--- Страница 183 ---\n182  Вычислительные основы w1 w2 w3 … wn □ □ □ … Рис. 8.14  Исходное содержимое ленты; считывающе-записывающая головка сканирует w1 Формально машина Тьюринга представляет собой кортеж (Q, å, Γ, δ, q0, qaccept, qreject), где входной алфавит å содержится в ленточном алфавите Г, и □ – это «пус - той» символ, то есть å ⋃ {□} ⊆ Γ. Переходная функция δ(q, X) = (p, Y, D), где D – это направление движения ленты, «влево» или «вправо», иногда обозначаемое как «←» или «→». Конфигурация представляет собой строку upv, где u, v ∈ Γ∗ и p ∈ Q, имея в виду, что состояние равно p, считывающе-записывающая головка сканирует первый символ v, и лента содержит только пустоты после последнего символа v. Перво- начально конфигурация равна q0w, где w = w1w2 … wn, wi ∈ å является входами, и первый символ w, w1, помещается в самую левую ячейку ленты. Соблюдая осо- бую осторожность, мы говорим, что символ, находящийся слева от последнего символа v, имеет свойство быть □ и иметь наименьший индекс среди всех этих ячеек ленты, удовлетворяя двум условиям: (i) он находится справа от головки; (ii) справа от него нет других символов, кроме □. Если δ(q i, b) = (qj, c, L), то конфигурация uaqi bv порождает конфигурацию uqj acv, и если δ(qi, b) = (qj, c, R), то uaqi bv порождает uacqjv. Иногда выражение «C1 порож - дает C2» записывается как C1 → C2. Мы исходим из того, что машина Тьюринга останавливается, когда она входит в принимающее или отклоняющее состояние, и мы определяем язык машины Тьюринга M, обозначаемый L(M), следующим об- разом: L(M ) = {w ∈ å∗|q0w ⇒∗ αqacceptβ}. Задача 8.55. Спроектируйте машину Тьюринга M такую, что L(M) является язы- ком палиндромов. Разные варианты машин Тьюринга эквивалентны; это понятие называется ро- бастностью. Например, лента бесконечна только в одном направлении, либо не-сколько лент. Между разными моделями легко выполнить «трансляцию». Принимаемые машинами Тьюринга языки называются рекурсивно перечисли- мыми (recursively enumerable, RE), или распознаваемыми, или распознаваемыми по Тьюрингу (в Sipser). Язык L является рекурсивно перечислимым, если существует машина Тьюринга М, которая останавливается в принимающем состоянии для всех x ∈ L и не принимает x ∉ L. Другими словами, L является рекурсивно пере- числимым, если существует M такая, что L = L(М ) (но М не обязательно останав- ливается на всех входах). Язык L является рекурсивным, или разрешимым, или разрешимым по Тьюрингу (в Sipser), если существует машина Тьюринга М, которая останавливается в q accept для всех x ∈ L и останавливается в qreject для всех x ∉ L. Другими словами, L является разрешимым, если существует машина Тьюринга М такая, что L = L(М ) (то есть М распознает/принимает L), а также М всегда останавливается. Рекурсивные языки соответствуют языкам, которые могут распознаваться алгоритмически. 8.5.1. Недетерминированные машины Тьюринга Напомним, что в разделе 8.3.2 мы дали определение недетерминированным ко- нечным автоматам. Недетерминизм допускает возможность нескольких возмож -\n--- Страница 184 ---\nМашины Тьюринга  183 ных ходов на одной и той же конфигурации. Эта идея сейчас используется в кон- тексте машин Тьюринга. Недетерминированная машина Тьюринга похожа на нормальную машину Тью- ринга, за исключением того, что переходная функция теперь является переход-ным отношением; тем самым существует несколько возможных ходов на данном состоянии и символе: δ(q, a) = {(q 1, b1, D1), (q2, b2, D2), , ( qk, bk, Dk)}. Так же, как и для недетерминированного конечного автомата, недетерминизм не усиливает модель вычислений, по крайней мере, не в контексте разрешимости. Но он допускает более удобный проектный формализм. Например, рассмотрим машину Тьюринга N, которая определяет следующий язык L(N) = {w ∈ {0, 1} ∗| последний символ w равен 1}. Описание N вместе с вычис - лительным деревом машины N на входных данных 011 можно найти на рис. 8.15. Теорема 8.56. Если N является недетерминированной машиной Тьюринга, то су - ществует детерминированная машина Тьюринга D такая, что L(N ) = L(D). Доказательство. D пробует все возможные ходы из N, используя поиск «сначала в ширину». D поддерживает последовательность конфигураций на ленте 1: … config1 config2 config* 1 … и использует вторую ленту для черновых заметок. Конфигурация, отмеченная сим-волом «*», является текущей конфигурацией. D копирует ее на вторую ленту и про- веряет, является ли она принимающей. Если это так, то машина принимает. Если это не так и N имеет k возможных ходов, то D добавляет k новых конфигураций, получаемых в результате этих ходов на ленте 1, и помечает следующую конфи-гурацию в списке как текущую. Если максимальное число возможных вариантов N равно m, то есть m – это степень недетерминированности N, и N делает n ходов перед принятием, то D исследует 1 + m + m 2 + m3 + ··· + mn ≈ nmn конфигураций. □ q0011 0q011 01q01 011q0 ×010q ××0q11 01r1 011r 011□qaccept δ(q0, 0) = {(q0, 0, →), ( q, 0, →)} δ(q0, 1) = {(q0, 1, →), (r, 1, →)} δ(r, □) = {(qaccept, □, →)} δ(r, 0/1) = {(q, 0, →)} Рис. 8.15  Определение N вместе с выполнением на 011 Фактически в приведенном выше доказательстве происходит то, что D симули- рует N; идея симуляции будет важной нитью в теме вычислимости. У нас всегда может быть одна машина Тьюринга, которая симулирует другую; «другая» маши-на Тьюринга может быть закодирована в состояниях симулятора. Это неудиви-\n--- Страница 185 ---\n184  Вычислительные основы тельно, поскольку машина Тьюринга является «конечным объектом», который может быть «закодирован» конечным числом символов (подробнее об этом ниже). Кроме того, описание «другой» машины можно поместить на ленту, и симулятор проверяет это описание для симулирования каждого хода на другой выделен-ной ленте. Короче говоря, тот факт, что это можно сделать, не должен удивлять, учитывая, что машины Тьюринга выражают то, что мы понимаем под термином «компью тер». Кроме того, у нас также есть симуляторы в «реальном мире» – на- пример, мы можем использовать программу VMware для симулирования ОС Win- dows на компью тере под управлением ОС Linux. Задача 8.57. Покажите, как M1 может симулировать M2. Одна идея состоит в том, чтобы иметь состояния (son, p) и (soff, p), где некоторые из p находятся в QM2 и не- которые соответствуют действиям M1. Здесь son, soff указывают на то, включена си- муляция или нет, и состояния машины M1 являются такими парами. 8.5.2. Варианты кодирования Напомним, что детерминированный конечный автомат B представляет собой кортеж (Q, å, δ, q0, F); мы исходим из того, что å = {0,1} и Q = {q1, q2, , qn}, где q0 всегда равно q1. Будем также считать, что F = {qi1, , qik}. Тогда �B� := 0n10l0 1 10l1 1 10l0 2 10l1 2 1 0l0 n 10l1 n 10i1 10i2 1 10ik, где 0l0 j 10l1 j означает, что на qj детерминированный конечный автомат B переходит в ql0 на 0 и в ql1 на 1, начальное 0n обозначает, что существует n состояний, а конеч- ное 0i1 10i2 1 10ik обозначает принимающие состояния. Обратите внимание, что в этом представлении нет двух подряд 1, поэтому �B, w� := �B�11w является хоро- шей кодировкой пары (B, w), так как кодировка B, �B� и кодировка w разделены символами 11. Схожим образом мы можем закодировать каждую машину Тьюринга стро- кой над {0,1}. Например, если M является машиной Тьюринга ({q1, q2}, {0, 1}, δ, …) и δ(q1, 1) = (q2, 0, →) является одним из переходов, то она может быть закодирована как 00 11 0 1 00 1 00 1 0 1 0 11 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 состояния q1 1 q2 0 →δ(q1, 1) = (q2, 0, →) Кодирование оставшихся переходов Не каждая строка будет валидной кодировкой машины Тьюринга; например, в нашем обозначении строка 1 ничего не кодирует. Будем говорить, что строка x ∈ {0, 1}∗ является хорошо сформированной строкой, если существует машина Тью- ринга М и строки w, такие что х = �М, w�; это означает, что х является надлежащей кодировкой пары (М, w). Легко увидеть, что мы можем создать решатель, который проверяет, что x является хорошо сформированной строкой, или, другими слова- ми, что язык хорошо сформированной строки разрешим. 8.5.3. Разрешимость Теорема 8.58. Регулярные языки разрешимы, и контекстно-свободные языки также разрешимы.\n--- Страница 186 ---\nМашины Тьюринга  185 Ниже приведены примеры разрешимых языков: ADFA := {�B, w� : B – это детерминированный конечный автомат, который при- нимает входную строку w}; ANFA: = {�B, w� : B – это недетерминированный конечный автомат, который принимает входную строку w}; AREX: = {�R, w� : R – это регулярное выражение, которое принимает входную строку w }; EDFA := {�A� : А – это детерминированный конечный автомат такой, что L(А) = ∅}; EQDFA := {�A, B� : A, B – это детерминированные конечные автоматы такие, что L(A) = L(B)}; ECFG := {�G � : G – это контекстно-свободная грамматика такая, что L(G) = ∅}. Для EQDFA используется симметрическая разность: С = (А ⋂ B) ⋃ (A ⋂ В). Теорема 8.59. Если L разрешим, то и его дополнение тоже разрешимо. Доказательство. Пусть L = å∗ – L равно дополнению L, и предположим, что L разрешим машиной М. Пусть M′ равно следующей модификации М: при пода- че x на вход M′ работает так же, как М. Однако когда М собирается принять, M′ отклоняет, и когда М собирается отклонить, M′ принимает. Ясно, что L = L(M′). Поскольку M всегда останавливается, то так же делает и M′, поэтому по опреде- лению L разрешим. □ Теорема 8.60. Если L и L оба являются рекурсивно перечислимыми, то L раз- решим. Доказательство. Пусть L = L(M1) и L = L(M2). Пусть M равно следующей машине Тьюринга: при подаче x на вход она симмулирует M1 на x на одной ленте и M2 на x на другой ленте. Поскольку L ⋃ L = å, x должны быть приняты одним либо другим. Если M1 принимает, то то же делает и M; если M2 принимает, то M отклоняет. □ 8.5.4. Т езис Черча– Тьюринга Интуитивное понятие алгоритма выражается через формальное определе- ние машины Тьюринга. Это положение называется «тезисом», потому что понятие алгоритма интуитив-но, то есть расплывчато. У всех нас есть интуитивное понимание понятия «алго-ритм» как рецепта, процедуры, набора инструкций, которые для любых входных данных определенного вида дают желаемый результат. Рассмотрим язык: A TM = {�M, w� : M – это машина Тьюринга, и М принимает w}. Этот язык иногда называют универсальным языком. Он является распознава- емым, поскольку он распознается универсальной машиной Тьюринга; это такая машина, которая при подаче на вход �M, w�, где М – это машина Тьюринга и w – строка, проверяет, что �M, w� представляет собой хорошо сформированную стро- ку, и если это так, она симулирует М на w и дает ответы соответственно тому, как отвечает М(w ). Вместе с тем обратите внимание, что U не решает ATM.\n--- Страница 187 ---\n186  Вычислительные основы Универсальная машина была революционной идеей Тьюринга; она представляла собой концепцию, которая шла вразрез с инженерными принципами своего време- ни. В эпоху Тьюринга инженерная практика заключалась в том, чтобы иметь «одну машину для решения одной задачи». И поэтому он предложил универсальную ма-шину, которая способна решать «все» задачи, означало плыть против течения. Но наши современные компьютеры – это именно универсальные машины Тьюринга, то есть мы не строим компьютер для выполнения одного алгоритма, а наоборот – наши компьютеры могут выполнять все то, что мы на них запрограммируем. Нетрудно увидеть, что универсальная машина Тьюринга может быть сконстру - ирована, но необходимо позаботиться о том, чтобы установить правила кодиро-вания машин Тьюринга и правила для кодировки �M, w�. Универсальная машина Тьюринга может иметь несколько лент, одна из которых зарезервирована для �M�, то есть лента, содержащая «программу», а другая лента, на которой U имитирует вычисление M(w ). В 1960-х годах Марвин Мински, глава отдела искусственного интеллекта в Массачусетском технологическом институте, предложил в то время самую маленькую универсальную машину Тьюринга: 7 состояний и 2 символа. В настоящее время с 2008 года рекорд принадлежит Алексу Смиту, предложивше-му универсальную машину Тьюринга с 2 состояниями и 3 символами. Проектирование универсальной машины Тьюринга является по-настоящему важным упражнением для тех, кто серьезно занимается информатикой. Такое упражнение включает в себя разработку языка программирования (то есть (M )) и интерпретатора/компилятора (то есть U, способного симулировать любой M с любыми данными на входе). Такое упражнение материализует многие понятия информатики и делает их более узнаваемыми, когда они появляются позже. 8.5.5. Неразрешимость Теорема 8.61. ATM является неразрешимым. Доказательство. Предположим, что он является разрешимым и что H его решает. Тогда L(H) = ATM, и H всегда останавливается (заметим, что L(H) = L(U), но, как мы уже говорили, не гарантируется, что U является решателем). Определим новую машину D (здесь D означает «диагональ», так как этот аргумент следует «диаго- нальному аргументу Кантора»): D(�М�) := � принять, если Н(�М, �М�� ) – отклонить, отклонить, если Н(�М, �М�� ) – принять, то есть D делает «противоположное». Тогда мы видим, что D(�D�) принимает тогда и только тогда, когда она отклоняет. Противоречие; поэтому AТМ не может быть разрешимым. □ Каково практическое следствие этой теоремы? Представьте, что вы разраба- тываете отладчик для некого языка программирования – что-то в стиле GDB1 для C. По словам команды «Проекта GNU», отладчик GDB позволяет вам видеть, что происходит «внутри» другой программы во время ее выполнения – или что другая программа делала в момент сбоя. Очень полезной функциональной возможно- стью будет запрос отладчика о том, остановится ли ваша программа на тех или 1 См. https://www.gnu.org/software/gdb/. – Прим. перев.\n--- Страница 188 ---\nМашины Тьюринга  187 иных входных данных. Например, вы выполнили свою программу на некоторых входных данных x, и ничего не происходило в течение длительного времени, пока не было нажато сочетание клавиш Ctrl+D для прерывания исполнения. Не нажали ли вы слишком быстро? Возможно, если бы вы подождали чуть дольше, то ваш ответ пришел бы; или, возможно, она никогда бы не остановилась сама по себе. «Возможность остановки» в отладчике даст вам ответ. Однако теорема 8.61 гово-рит, что эта функциональная возможность не может быть реализована. Давайте убедимся, что мы понимаем то, что утверждает теорема 8.61: она го- ворит, что A TM неразрешим и поэтому нет машины Тьюринга, которая останав- ливается на любом �M, w� с правильным ответом. Это не отменяет возможности разработки машины Тьюринга, которая останавливается на некоторых (возмож - но, даже бесконечно многих) �M, w� с правильным ответом. Теорема 8.61 гласит, что не существует алгоритма, который работает правильно для любых входных данных. См. статью Моше Варди (Moshe Vardi), касающуюся завершения/неразрешимо- сти, из июльского номера ACM Communications за 2011 год «Решение неразреши-мого» (Solving the unsolvable). Задача 8.62. Существует ли машина Тьюринга M такая, что L(M) = A TM – L′, где |L′| < ∞? То есть M решает ATM для всех, кроме конечного числа �M, w�. Функция трудолюбивого бобра (busy beaver, BB)1, å(n, m), выдает максимальное число ячеек, которые могут быть записаны с помощью машины Тьюринга с n со - стояниями и M символами алфавита, начинающимися на пустой ленте. Задав m = 2 и приняв å(n) равным å(n, 2), известно, что å(2) = 4; å(3) = 6; å(4) = 13; å(5) ≥ 4098; å(6) ≥ 3,5×1018267. Функция трудолюбивого бобра неразрешима; пред- положим, что она разрешима. Тогда мы могли бы использовать ее для того, чтобы решить ATM следующим образом: передав на вход �M, w�, конструируем машину Тьюринга M′, которая на пустой ленте пишет w, и возвращается в первую ячейку, и симулирует М на w. Затем вычисляем i = å(|QM′|, |ΓM′|) и симулируем M′. Если M′ хоть раз пересекает i-ю ячейку, то мы знаем, что M(w) не останавливается; если M′ ограничена в пределах первых i ячеек, то она либо остановится, либо войдет в «цикл». Мы можем обнаружить эту «петлю», отслеживая разные конфигурации и убеждаясь, что они не повторяются. При ограниченном пространстве число кон-фигураций ограничено |Q M|i|Γ|i. Следствие 8.63. ATM не является рекурсивно перечислимым. Доказательство. Поскольку ATM является рекурсивно перечислимым (так как L(U) = ATM), по теореме 8.60 мы знаем, что если бы ATM был также рекурсивно пере- числимым, то ATM был бы разрешимым, что по теореме 8.61 не так. □ Перечислитель – это машина Тьюринга, которая имеет рабочую ленту, пустую на входе, и выходную ленту, на которой она записывает строки, разделенные не- 1 Трудолюбивый бобер (busy beaver) – это машина Тьюринга с заранее заданным числом состояний N, которая, начиная с пустой ленты (все нули), генерирует самую длинную по- следовательность единиц (или в другой формулировке: выполняет как можно больше ша-гов), после чего останавливается. См. https://pl.wikipedia.org/wiki/Pracowity_b%C3%B3br. – Прим. перев.\n--- Страница 189 ---\n188  Вычислительные основы которыми символами, скажем символом #, никогда не перемещаясь влево. Идея состоит в том, что она «пересчитывает» строки на языке. Язык является перечис - лимым, если существует перечислитель E такой, что L = L(E ). Теорема 8.64. Язык распознаваем тогда и только тогда, когда он перечислим. Доказательство. Если язык L перечислим, то пусть M симулирует на входных дан- ных w перечислитель языка L и принимает, если на входе появляется w. Для дру - гого направления мы должны быть осторожнее: предположим, что L распознава- ем машиной M. Пусть перечислитель E работает следующим образом: в фазе i он симулирует M на первых i строках å∗ (в лексикографическом порядке), каждая для i шагов. Когда M принимает некоторую строку, E выдает ее. В этом заключается идея согласования по типу «ласточкина хвоста»1. □ 8.5.6. Редукции Используя понятие редукции, или сведения, мы можем показать, что многие дру - гие языки не являются рекурсивно перечислимыми или неразрешимыми. Рас - смотрим язык: HALTTM: = {�M, w� : M является машиной Тьюринга, которая останавливается на w }. Этот язык неразрешим, и мы можем показать это следующим образом: пред- положим, что он разрешим и что его решателем является H. Рассмотрим H′, ко - торый, получая на входе �M, w�, выполняет H(�M, w�). Если H принимает, то наш H′ симулирует M на w и отвечает соответствующим образом; в противном случае H′ отклоняет. Ясно, что L(H ′) = ATM, но поскольку H был решателем, то таковым яв- лется и H′. Но это противоречит неразрешимости ATM. Следовательно, мы только что показали от противного, что HALTTM не может быть разрешимым, то есть он неразрешим. Рассмотрим сейчас ETM: = {�M�: M является машиной Тьюринга такой, что L(M ) = ∅}. Этот язык неразрешим: предположим, что ETM разрешим; пусть R равно машине Тьюринга, которая его решает. Рассмотрим машину Тьюринга R′, спроектирован- ную следующим образом: получая на входе �M, w�, она сначала конструирует ма- шину Mw, где на x машина Mw сначала проверяет, является ли истинным, что x = w; если нет, то Mw отклоняет. В противном случае Mw выполняет M на w и принимает, если принимает M. Наконец, R′ симулирует R на �Mw�. Ясно, что L(R′) = ATM, и по- скольку R′ является решателем, то этого не может быть. Рассмотрим языкREGULAR TM := {�M� : М является машиной Тьюринга и L (М) является регулярным}. Этот язык неразрешим; предположим, что он был разрешимым, и R – ее реша- тель. Мы проектируем S следующим образом: получая на входе �M, w�, S сначала конструирует M′, которая работает следующим образом: M′ при подаче на вход x проверяет, имеет ли x форму 0n1n, и принимает, если да. Если х не имеет этой фор- 1 Ласточкин хвост (dovetailing) – это когда симулируется две или более машины Тьюринга параллельно на одной машине Тьюринга. – Прим. перев.\n--- Страница 190 ---\nМашины Тьюринга  189 мы, то она выполняет М на w и принимает, если М принимает. Наконец, S выпол- няет R на �M2�. Обратите внимание, что L(M ′) является либо нерегулярным языком {0n1n} (если M отклоняет w), либо регулярным языком {0,1}∗ (если M принимает w). 8.5.7. Т еорема Райса Оказывается, что нетривиальные свойства языков машин Тьюринга неразре- шимы. Что мы подразумеваем под «нетривиальными свойствами»? Мы имеем в виду, например, свойство не принимать никакие строки, то есть ETM. Более формально, свойство P – это всего лишь подмножество {� M�: M является машиной Тьюринга}. Мы говорим, что свойство является нетривиальным, если P ≠ ∅ и P ≠ ∅. Далее, нам потребуется следующее: если заданы две машины Тьюрин- га M 1 и М2 такие, что L(M1) = L(M2), тогда либо обе �М1� и �М2� находятся в P, либо обе не находятся в P. То есть, находится или нет �М� в P, зависит только от свойств языка М, а не от, скажем, синтаксических свойств машины, таких как число состояний. Теорема 8.65 (Райса). Каждое нетривиальное свойство неразрешимо. 8.5.8. Задача соответствий Поста Напомним, что теорема Майхилла–Нероуда (раздел 8.3.8.2) дает характеристику регулярных языков без упоминания модели вычислений. Задача Поста делает то же самое для неразрешимых языков; она дает пример конкретного неразреши-мого языка без упоминания машин Тьюринга или любой другой модели вычис - лений. Она показывает, что неразрешимость является не причудой конкретной модели вычислений, а немутируемым свойством некоторых языков. Экземпляр задачи соответствий Поста (Post’s correspondence problem, PCP) со- стоит из двух конечных списков строк над некоторым алфавитом å. Два списка должны быть одинаковой длины: A = w 1, w2, , wk; B = x1, x2, , xk. Для каждого i пара (wi, xi) называется соответствующей парой. Мы говорим, что этот экземпляр задачи соответствий Поста имеет решение, если существует по-следовательность одного или нескольких индексов: i 1, i2, , im, m ≥ 1, где индексы могут повторяться так, что: wi1 wi2 wim = xi1 xi2 xim. Задача соответствий Поста состоит в следующем: при наличии двух списков (A, B) равной длины имеет ли она решение? Мы можем выразить задачу соответ - ствий Поста как язык: LPCP := {�A, B�|(A, B) экземпляр задачи соответствий Поста с решением}. Например, рассмотрим (A, B): A = 1, 10111, 10; B = 111, 10, 0.\n--- Страница 191 ---\n190  Вычислительные основы Тогда i1 = 2, i2 = 1, i3 = 1, i4 = 3 является решением в виде: 10111 1 1 10 = 10 111 111 0 . w1w1w3 х2х1 х1х3 w2 Обратите внимание, что i1 = 2, i2 = 1, i3 = 1, i4 = 3, i5 = 2, i6 = 1, i7 = 1, i8 = 3 составляет еще одно решение. Задача 8.66. Покажите, что A = 10, 011, 101 и B = 101, 11, 011 не имеет решения. Модифицированная задача соответствий Поста (modified PCP) имеет дополни- тельное требование в том, что первая пара в решении должна быть первой парой (A, B). Поэтому i1, i2, , im, m ≥ 0 является решением для (A, B) экземпляра модифи- цированной задачи соответствий Поста, если: w1wi1wi2 wim = x1 xi1 xi2 xim. Мы также говорим, что i1, i2, , ir является частичным решением (модифициро- ванной) задачи соответствий Поста, если один из следующих префиксов является префиксом другого: (w 1)wi1wi2 wir (x1)xi1 xi2 xir. В случае модифицированной задачи соответствий Поста мы далее требуем, чтобы i1 = 1. С учетом всех этих элементов мы можем теперь показать, что задача соот - ветствий Поста является неразрешимой. Мы собираемся сделать это в три эта-па: во-первых, мы покажем, что если задача соответствий Поста разрешима, то неразрешима и модифицированная задача соответствий Поста. Во-вторых, мы показываем, что если модифицированная задача разрешима, то разрешим и A TM. В-третьих, так как ATM неразрешим, то неразрешима и (модифицированная) за- дача соответствий Поста. Лемма 8.67. Если задача соответствий Поста разрешима, то разрешима и моди- фицированная задача соответствий Поста.Доказательство. Мы показываем, что с учетом экземпляра (А, B) модифициро- ванной задачи соответствий Поста мы можем создать экземпляр (А′, B′) задачи соответствий Поста такой, что: (A, B) имеет решение ⇔ (A′, B′) имеет решение. Пусть (А, B) равно экземпляру модифицированной задачи соответствий Поста над алфавитом å. Тогда (А′, B′) является экземпляром задачи соответствий Поста над алфавитом å′ = å ⋃ {∗, $}, где ∗, $ – это новые символы. Если A = w 1, w2, w3, , wk, то A′ = ∗w_ 1∗, w_ 1∗, w_ 2∗, w_ 3∗, , w_ k∗, $. Если B = x1, x2, x3, , xk, то B′ = ∗х_ 1, ∗х_ 1, ∗х_ 2, ∗х_ 3, , ∗х_ k, ∗$, где если x = a1a2a3 … an ∈ å∗, то х_ = a1 ∗ a2 ∗ a3 ∗ … ∗ an. Например, если (A , B) является экземпляром, если модифицированная задача соответствий Поста задана как: A = 1, 10111, 10 и B = 111, 10, 0, то (А ′, B′) является экземпляром задачи соответствий Поста, задаваемой парой: A′ = ∗1∗, 1∗, 1∗0∗1∗1∗1∗, 1∗0∗, $ и B ′ = ∗1∗1∗1, ∗1∗1∗1, ∗1∗0, ∗0, ∗$. Задача 8.68 заканчивает доказательство. □ Задача 8.68. Закончите доказательство леммы 8.5.8.\n--- Страница 192 ---\nМашины Тьюринга  191 Лемма 8.69. Если модифицированная задача соответствий Поста разрешима, то разрешим ATM. Доказательство. С учетом пары (M, w), мы конструируем экземпляр (A, B) моди- фицированной задачи соответствий Поста такой, что: TM M принимает w ⇔ (A, B) имеет решение. Основная идея заключается в следующем: экземпляр модифицированной за- дачи соответствий Поста (A, B) симулирует в своих частичных решениях вычисле- ние M на w. То есть частичные решения будут иметь вид: #α1#α2#α3# , где α1 – это начальная конфигурация M на w, и для всех i конфигурация A дает конфигурацию αi+1. Частичное решение из списка B всегда будет «на одну конфигурацию впереди» списка A; списку A будет разрешено «догонять» только тогда, когда M принимает w. Для упрощения мы исходим из того, что машины Тьюринга не печатают пустые символы (то есть они не печатают «□») с целью, чтобы конфигурации имели фор-му αqβ, где α, β ∈ (Γ – { □})∗ и q ∈ Q. Задача 8.70. Покажите, что машина Тьюринга, которая не может печатать пустые символы, эквивалентна по мощности тем машинам Тьюринга, которые могут их печатать. Пусть M равно машине Тьюринга и w ∈ å ∗; мы конструируем экземпляр (A, B) модифицированной задачи соответствий Поста следующим образом: 1) A: # B: #q0w#; 2) A: a1, a2, , an, # B: a1, a2, , an, # где ai ∈ (Γ – { □})∗; 3) для симулирования хода M для всех q ∈ Q – { qaccept}: Список А Список В qa bp если δ(q, a) = (p, b, →) cqa pcb если δ(q, a) = (p, b, ←) q# bp# если δ(q, □) = (p, b, →) cq# pcb# если δ(q, □) = (p, b, ←) 4) если конфигурация в конце B принимает (то есть имеет форму αqacceptβ), то нам нужно разрешить A догнать B. Таким образом, для всех a, b ∈ (Γ – { □})∗ нам нужны следующие соответствующие пары: Список А Список В aq acceptb qaccept aq accept qaccept qacceptb qaccept 5) наконец, после использования указанных выше пунктов 4 и 3 мы получаем x# и x#qaccept#, где x – это длинная строка. Таким образом, для того чтобы до- гнать, нам нужна qaccept## в A и # в B. □\n--- Страница 193 ---\n192  Вычислительные основы Например, рассмотрим следующую машину Тьюринга M с состояниями {q1, q2, q3}, где q1 сокращает qinit, q3 сокращает qaccept и где δ задается таблицей переходов: 0 1 □ q1 (q 2, 1, →) (q 2, 0, ←) (q 2, 1, ←) q2 (q3, 1, ←) (q1, 0, →) (q 2, 0, →) Из этого M и ввода w = 01 мы получаем следующую модифицированную задачу соответствий Поста: 4 0q 30 0q 31 1q 30 1q 31 0q 3 1q 3 q30 q31q3 q3 q3 q3 q3 q3 q3 q3 5 q3###Правило Список А Список В Источник 1 # #q101# 2 0 1 #01 # 3 q10 0q 11 1q 11 0q 1# 1q 1# 0q 20 1q 20 q21 q2#1q 2 q200 q210 q201# q211# q300 q310 0q 1 0q 2#δ(q 1, 0) = (q 2, 1, →) δ(q 1, 1) = (q 2, 0, ←) δ(q 1, 1) = (q 2, 0, ←) δ(q 1, B) = (q 2, 1, ←) δ(q 1, B) = (q 2, 1, ←) δ(q 2, 0) = (q 3, 0, ←) δ(q 2, 0) = (q 3, 0, ←) δ(q 2, 1) = (q 1, 0, →) δ(q 2, B) = (q 2, 0, →) Машина Тьюринга М на входе принимает w = 01 последовательностями ходов, представленных следующими конфигурациями: q101 → 1q21 → 10q1 → 1q201 → q3101. Мы исследуем последовательность частичных решений, которая имитирует это вычисление M на w и в конечном итоге приводит к решению. Мы должны начать с первой пары (модифицированной задачи соответствий Поста): A : # B : #q101# Единственный способ расширить это частичное решение – использовать соот - ветствующую пару (q10, 1q2), поэтому мы получаем: A : #q10 B : #q101#1q2 Теперь с помощью копирования пар мы получаем: A : #q101#1 B : #q101#1q21#1 Следующая соответствующая пара (q21, 0q1): A : #q101#1q21 B : #q101#1q21#10q1 Теперь осторожно! Мы копируем только следующие два символа, в результате получив:\n--- Страница 194 ---\nМашины Тьюринга  193 A : #q101#1q21#1 B : #q101#1q21#10q1#1 потому что нам нужно 0q1, так как считывающе-записывающая головка движется влево, и мы используем следующую соответствующую пару (0q1#, q201#) и полу - чаем: A : #q101#1q21#10q1# B : #q101#1q21#10q1#1q201# Теперь мы можем сразу использовать еще одну соответствующую пару (1q20, q310), в результате получив: A : #q101#1q21#10q1#1q20 B : #q101#1q21#10q1#1q201#q310 и обратите внимание, что у нас есть принимающее состояние! Мы используем две копирующие пары, в результате получив: A : #q101#1q21#10q1#1q201# B : #q101#1q21#10q1#1q201#q3101# и теперь мы можем начать использовать правила в 4, чтобы A догнало B: A : #q31 B : #q3101#q3 и мы копируем три символа: A : #q3101# B : #q3101#q301# И снова немного наверстываем: A : #q3101#q30 B : #q3101#q301#q3 Комируем два символа:A : #q3101#q301# B : #q3101#q301#q31# и догоняем: A : #q3101#q301#q31 B : #q3101#q301#q31#q3 и компируем: A : #q3101#q301#q31# B : #q3101#q301#q31#q3# И теперь все заканчиваем соответствующей парой (q3##, #), заданной правилом 5, получив совпадающие строки: A : #q3101#q301#q31#q3## B : #q3101#q301#q31#q3##\n--- Страница 195 ---\n194  Вычислительные основы Таким образом, с учетом экземпляра �M, w� автомата ATM мы строим экземпляр (A, B)�M, w� модифицированной задачи соответствий Поста с целью, чтобы соблюда- лось следующее отношение: M принимает w ⇔ (A, B)�M, w� имеет решение. (8.2) Другими словами, мы свели ATM к модифицированной задаче соответствий Пос - та, и наше сведение задается (вычислимой) функцией f : {0, 1}∗ → {0, 1}∗, которая определяется следующим образом: f(�M, w�) = �(A, B)�M, w��. Это показывает, что если модифицированная задача соответствий Поста разрешима, то разрешим и ATM. Для того чтобы это увидеть, предположим, что модифицированная задача соот - ветствий Поста разрешима; тогда у нас есть решатель для ATM: получив на вход �M, w�, наш решатель вычисляет x = f(�M, w�) и выполняет решатель для модифи- цированной задачи соответствий Поста на x. По (8.2) мы знаем, что ответ «да» означает, что М принимает w. 8.5.9. Неразрешимые свойства контекстно-свободных языков Теперь мы можем использовать тот факт, что задача соответствий Поста неразре- шима, для того чтобы показать, что ряд вопросов о контекстно-свободных языках неразрешим. Пусть (A, B) равно экземпляру задачи соответствий Поста, где A = w 1, w2, , wk и B = x1, x2, , xk. Пусть GA и GB связаны с контекстно-свободными языками, заданными: A → w1Aa1|w2 Aa2| ··· |wk Aak|w1a1|w2a2| ··· |wk ak; B → x1Ba1|x2 Ba2| ··· |xk Bak|x1a1|x2a2| ··· |xk ak, где a1, a2, , ak – это новые символы не в алфавите (A, B). Пусть LA = L(GA) и LB = L(GB), и поэтому LA и LB состоят соответственно из всех строк формы: wi1wi2 wimaim ai2ai1; xi1 xi2 ximaim ai2ai1. Теорема 8.71. Вопрос, является ли контекстно-свободный язык неоднозначным, неразрешим. Доказательство. Пусть GAB равно контекстно-свободной грамматике, состоящей из GA, GB, с вброшенным правилом S → A|B. Таким образом, GAB является неодно- значной ⇔ задача соответствий Поста (A, B) имеет решение. Обратите внимание, что целью новых символов ai в GA и GB является обеспечение того, чтобы соответ - ствующие пары находились в одних и тех же позициях. □ Теорема 8.72. Предположим, что G1, G2 являются контекстно-свободными грам- матиками, а R является регулярным выражением, тогда следующие ниже задачи неразрешимы: 1) L(G1) ⋂ L(G2) =? ∅; 2) L(G1) =? L(G2); 3) L(G1) =? L(R); 4) L(G1) =? T∗; 5) L(G1) ⊆? L(G2); 6) L(R) ⊆? L(G2).\n--- Страница 196 ---\nОтветы к избранным задачам  195 Доказательство. Сначала мы покажем, что LA, где определенный выше LA = L(GA) также является контекстно-свободной грамматикой; мы показываем это, давая магазинный автомат P. ΓP = åA ⋃ {a1, a2, , ak}. До тех пор, пока P видит символ в åA, он сохраняет его в стек. Как только P видит ai, он выталкивает элемент из стека, чтобы убедиться, что верх строки равен wiR. (i) если нет, то принимает независимо от того, что будет дальше. (ii) если да, то существуют два подслучая: (iia) если стек еще не пуст, то продолжает. (iib) если стек пуст и входные данные закончились, то отклоняет. Если после a i, P видит символ в åA, то он принимает. Теперь мы готовы показать, что шесть перечисленных в теореме задач на са- мом деле неразрешимы: 1) пусть G1 = GA и G2 = GB, тогда L(G1) ⋂ L(G2) ≠ ∅ тогда и только тогда, когда за- дача соответствий Поста (A, B) имеет решение; 2) пусть G1 равно контекстно-свободной грамматике для LA ⋃ LB (контекстно- свободные грамматики замкнуты при объединении). Пусть G2 равно кон- текстно-свободной грамматике для регулярного языка (å ⋃ {a1, a2, , ak})∗. Обратите внимание, что L(G1) = LA ⋃ LB = LA ⋂ LB = все, что угодно, кроме решений задачи соответствий Поста (A, B). ∴ L(G1) = L(G2) тогда и только тогда, когда (A, B) не имеет решения; 3) показано в п. 2, потому что L(G2) является регулярным языком; 4) снова показано в п. 2; 5) обратите внимание, что A = B тогда и только тогда, когда A ⊆ B и B ⊆ A, по - этому следует из п. 2; 6) по пп. 3 и 5. Это показывает, что важные свойства контекстно-свободных грамматик нераз- решимы. □ 8.6. ответы к избранным зада Чам Задача 8.1. å2k – это множество уникальных строк длины k, которые могут быть по- строены с помощью å2, то есть обобщенного алфавита, содержащего два символа. Хорошим примером å2 является стандартный двоичный алфавит {0,1}. В строке длины k на этом алфавите есть k символов, каждый из которых может быть либо 1, либо 0; другими словами, чтобы построить строку длины k, принимается k «реше- ний», каждое с двумя вариантами. Таким образом, существует 2k возможностей. Можно показать, что каждая из этих возможностей является уникальной. Схожим образом в å lk существует lk уникальных слов. Далее рассмотрим множество строк над ål, где ни один символ не может быть повторен ни в одной строке. Пусть n равно длине такой строки. Ясно, что это прос - то перестановка длины n из множества ål без возврата, где 0 ≤ n ≤ l. В связи с этим число уникальных строк длины n равно l!/(l – n)!. Тем самым суммарное количест - во строк длины n ∈ {0, 1, 2, …, l} равно W(l) = ål n=0(l – n)!l!. Хотя это решение является правильным, мы можем сделать лучше с помощью небольшого анализа нашего результата. Начнем с выделения l!.\n--- Страница 197 ---\n196  Вычислительные основы W(l) = l! · ål n=0 (l – n)!l! = l! · ål n=0 n!1. Напомним, что разложение ex в ряд Тейлора равно å∞ n=0 (xn/n!), поэтому мы мо- жем переписать: W(l) = l! · �e – å∞ n=(l+1) n!1� = l! · �e – �(l + 1)!1 + (l + 2)!1 + ···�� . Далее мы распределяем: W(n) = l! · e – �(l + 1)1 + (l + 1)(l + 2)1 + ···�. Рассмотрим фрагмент в скобках; он явно меньше, чем (1/l + 1/ l2 + ···) – геометри- ческий ряд, сумма которого равна 1/(l – 1). Обратите внимание, что если l > 2, то эта сумма меньше 1, поэтому W(l) > l! · e – 1. Сумма также является положительной, поэтому W(l) < l! · e. У нас есть l! · e – 1 < W(l ) < l! · e; этого в сочетании с тем, что W(l) является целым числом, достаточно, чтобы показать, что W(l ) = l! · e. Задача 8.2. Рассмотрим строку S в форме x01y. После того как последний эле- мент x был «выполнен», мы находимся в одном из состояний q0, q1, q2. Ниже мы покажем, что независимо от состояния после x мы будем в состоянии q1 после по- следующей подстроки 01. δ(q0, 0) = q2 и δ(q2, 1) = q1; δ(q1, 0) = q1 и δ(q1, 1) = q1; δ(q2, 0) = q2 и δ(q2, 1) = q1. С этого места каждый элемент a из y равен либо 0, либо 1; в любом случае δ(q1, a) = q1, поэтому после обработки подстроки 01 мы остаемся в состоянии q1 до конца S. Поскольку q1 является конечным состоянием, S принимается А. Остается увидеть, что любая строка без подстроки 01 отклоняется A. Рассмот - рим такую строку, S′. Если она не содержит нули, то она полностью состоит из единиц. Кроме того, мы начинаем в состоянии q0, и δ(q0, 1) = q0, поэтому состояние равно q0 для всей строки, и так как q0 не является конечным состоянием, S′ откло- няется. Схожим образом, если S ′ содержит только один 0 и он является конечным символом, то S′ выглядит как 1 10 с некоторым произвольным числом 1 в про- межутке. В этом случае мы остаемся в состоянии q0 до 0 в конце, поэтому конеч- ное состояние равно q2 – которое также не является конечным состоянием. Если, с другой стороны, S′ содержит, по крайней мере, один 0, не в конце строки, то рас - смотрим первый 0. После этого первого 0 нет единиц, так как первая такая 1 обя- зательно будет концом подстроки 01, которой S′ не имеет. Таким образом, S′ = xy, где x – это строка из единиц (или пустая строка) и y – строка из нулей. В конце x мы по-прежнему находимся в состоянии q0, так как δ(q0,1) = q0 по-прежнему явля- ется неподвижной точкой. Тогда первый 0 в y приводит к δ(q0, 0) = q2, и остальные 0 ничего не делают, потому что δ(q2, 0) = q2 также является неподвижной точкой. Таким образом, в конце S′ состояние равно q2, которое не является конечным со- стоянием; S ′ отклоняется A. Гораздо более эффективное доказательство может быть дано посредством ин- дукции над длиной строки – это оставлено читателю.\n--- Страница 198 ---\nОтветы к избранным задачам  197 Задача 8.3. 0,1 0,10,1 0,1 0 1 Задача 8.4. 0,10,1 1 0 Задача 8.5. Для Bn, для каждого n, мы хотим построить (другой) детерминиро- ванный конечный автомат Dn такой, что L(Dn) = Bn. Пусть Dn состоит из состояний Q = {q0, q1, , qn–1}, и пусть переходная функция δ определена как δ(qi, 1) = q(i+1) (mod n), и пусть F = {q0}. Задача 8.6. Пусть Q = {q0, q1, , q24}, и определим δ следующим образом: δ(qi, 1) = q(i+1) (mod 25); δ(qi, 5) = q(i+5) (mod 25); δ(qi, 10) = q(i+10) (mod 25); δ(qi, 25)= qi. Наконец, пусть F = {q0}. Этот детерминированный конечный автомат будет при- нимать только величины, кратные 25. Конечно, торговый автомат должен уметь справляться с недопустимыми входами (например, аркадными жетонами или монетами с неподдерживаемыми значениями). Обозначим любой недопустимый ввод как I. Очевидно: δ(qi, I)= qi. Более того, на таком вводе δ будет вызывать дополнительное действие, для того чтобы «выплюнуть» недопустимую монету. Задача 8.7. Просто потому, что ε уже может быть в L, и поэтому если ε ∈ L, то ε ∈ L+. С другой стороны, напомним о допущении, что ε ∈ å для любого å. Задача 8.9. Ответ равен O(2n). Для того чтобы это увидеть, обратите внимание, что способ построения детерминированного конечного автомата заключается в следующем: дерево начинается с q0, ответвляется на всех возможных строках из n элементов. Каждый лист – это состояние qw, где w ∈ {0, 1}n. Принимающие листья – это листья, где w начинается с 1. Предположим, что у нас есть лист qax (то\n--- Страница 199 ---\n198  Вычислительные основы есть w = ax), тогда δ(qax, b) = qxb. Обратите внимание, что гораздо проще создать детерминированный конечный автомат для L′n, где L′n – это множество строк, где n-е символы в самом начале равны 1. Задача 8.13. Для конкатенации соедините все принимающие состояния «пер- вого» детерминированного конечного автомата ε-стрелками с начальным состоя- нием «второго» детерминированного конечного автомата. Задача 8.14. Базовые случаи состоят в следующем: L(a) = {a}; L(ε) = {ε}; L(∅) = ∅. Далее индукционные правила: L(E + F) = L(E) ⋃ L(F); L(EF) = {xy |x ∈ L(E) ∧ y ∈ L(F)}; L(E ∗) = {x0 x1 xn|∀i(xi ∈ L(E)) ∧ n ∈ �}. Задача 8.15. Множество двоичных строк без подстроки 101 может быть вы- ражено: 0∗(1∗00(0∗))∗1∗0∗. Выражение (1∗00(0∗))∗ обозначает конкатенацию элементов из множества строк, состоящего из произвольного числа ведущих единиц, за которыми следует как минимум два 0. Идея здесь заключается в том, что за каждой 1 (за исключени-ем последней 1) сразу же следует либо еще одна 1, либо, по меньшей мере, два 0, что делает подстроку 101 невозможной. Остальная часть выражения представляет собой простое заполнение; 0 ∗ в начале обозначает любой ведущий 0, и 1∗0 ∗ обо- значает любую концевую подстроку формы 11 100 0. Задача 8.17. Мы можем интуитивно сконструировать регулярное выражение для всех двоичных строк с помощью подстроки 00 – например, (ε + 0 + 1)∗00(е + 0 + 1)∗. Этот метод полезен в более сложных случаях. Обратите внимание, что нам не нужно вычислять R k ij для всех k, i, j. Единственным конечным состоянием является q3, поэтому R = R(3) 13. R(3) 13 = R(2) 13 + R(2) 13(R(2) 33)∗R(2) 33. (8.3) Поэтому нам нужно найти R(2) 13 и R(2) 33. R(2) 13 = R(1) 13 + R(1) 12(R(1) 22)∗R(1) 23. (8.4) R(2) 33 = R(1) 33 + R(1) 32(R(1) 22)∗R(1) 23. (8.5) Поэтому мы должны вычислить R(1) 12, R(1) 13, R(1) 22, R(1) 23, R(1) 32 и R(1) 33. R(1) 12 = R(0) 12 + R(0) 11(R(0) 11)∗R(0) 12 = 0 + (ε + 1)(ε + 1)∗0 = (ε + 1)∗0. Обратите внимание, что (ε + 1)(ε + 1)∗ = (ε + 1)∗, потому что ε ∈ L(ε + 1).\n--- Страница 200 ---\nОтветы к избранным задачам  199 R(1) 13 = R(0) 13 + R(0) 11(R(0) 11)∗R(0) 13 = ∅ + (ε + 1)(ε + 1)∗∅ = ∅. Этот последний шаг истинен, поскольку для любого регулярного выражения R: R∅ = ∅R = ∅. R(1) 22 = R(0) 22 + R(0) 21(R(0) 11)∗R(0) 12 = ε + 1(ε + 1)∗0. R(1) 23 = R(0) 23 + R(0) 21(R(0) 11)∗R(0) 13 = 0 + 1(ε + 1)∗∅ = 0. R(1) 32 = R(0) 32 + R(0) 31(R(0) 11)∗R(0) 13 = ∅ + ∅(ε + 1)∗0 = ∅. При соответствующих наблюдениях можно реализовать ряд сокращений. На- пример, δ(q3, a) = q3 для всех a, поэтому выйти из состояния q3 невозможно. Если j ≠ 3, то R(n) 3j = ∅. R(1) 33 = R(0) 33 + R(0) 31(R(0) 11)∗R(0) 13 = ε + 0 + 1 + ∅(…)∗… = ε + 0 + 1. Теперь мы можем найти R(2) 13 и R(2) 33 с помощью уравнений 8.4 и 8.5. R(2) 13 = R(1) 13 + R(1) 21(R(1) 22)∗R(1) 23 = ∅ + 1(ε + 1)∗0(ε + 1(ε + 1)∗0)∗0 = (ε + 1)∗0(ε + 1(ε + 1)∗0)∗0. R(2) 33 = R(1) 33 + R(1) 32(R(1) 22)∗R(1) 23 = ε + 0 + 1 + ∅(…)∗… = ε + 0 + 1. Наконец, мы можем использовать уравнение 8.3, чтобы найти R(3) 13 = R. R(3) 13 = R(2) 13 + R(2) 13(R(2) 33)∗R(2) 33 = (ε + 1)∗0(ε + 1(ε + 1)∗0)∗0 + (ε + 1)∗0(ε + 1(ε + 1)∗0)∗0(ε + 0 + 1)∗(ε + 0 + 1) = (ε + 1)∗0(ε + 1(ε + 1)∗0)∗0(ε + 0 + 1)∗. Разумеется, это выражение не упрощено; законы в табл. 8.3.4 могут его улуч- шить. Результат не должен содержать ε. Задача 8.18. Объединение: L = L(R) и M = L(S), поэтому L ⋃ M = L(R + S). Допол- нение: L = L(A), поэтому Lc = L(A′), где A′ – это детерминированный конечный авто- мат, полученный из А следующим образом: FA′ = Q – FA. Пересечение: L ⋂ M = L ⋃ M. Реверс: с учетом регулярного выражения Е определяем ER по структурной индук - ции. Единственная хитрость заключается в том, что (E1E2)R = ER 2 ER 1. Гомоморфизм: наличие регулярного выражения Е определяем h(е) подходящим образом. Задача 8.19. В случае i обратите внимание, что нам требуется O(n3) шагов для вычисления e-замыканий всех состояний, и существует 2n состояний. В случае iii обратите внимание, что существует n выражений R(k) ij , и на каждом этапе размер\n--- Страница 201 ---\n200  Вычислительные основы увеличивается вчетверо (так как нам нужно четырехэтапных (k – 1) выражений для построения одного для этапа k). Случай iv – хитрость здесь заключается в ис - пользовании эффективного метода разбора для регулярного выражения; сущест - вует О(n) методов. Задача 8.20. Для случая i используйте автоматное представление: вычислите множество достижимых состояний из q0. Если хотя бы одно принимающее состоя- ние достижимо, то оно не пустое. Что, если дано только представление в виде регу - лярного выражения? Для случая ii выполните трансляцию любого представления в детерминированный конечный автомат и выполните строку на этом автомате. Для случая iii используйте эквивалентность и минимизацию автоматов. Задача 8.21. Здесь мы представим общее доказательство «естественного алго- ритма», который вы должны были спроектировать для заполнения таблицы. Мы используем аргументацию от противного с принципом наименьшего числа. Пусть {p, q} равно различимой паре, для которой алгоритм оставил соответствующую ячейку пустой, и, более того, из всех таких «плохих» пар {p, q} имеет самую корот - кую различающую строку w. Пусть w = a 1a2 … an, δˆ(p, w) принимает, тогда как δˆ(q, w) нет. Сначала w ≠ ε, так как тогда p, q были бы найдены различимыми в базовом случае алгоритма. Пусть r = δ(p, a1) и s = δ(q, a1). Тогда {r, s} различаются строкой w′ = a2a3 … an, и поскольку |w ′| < |w|, они были обнаружены алгоритмом. Но тогда {p, q} была бы найдена на следующем этапе. Задача 8.22. Рассмотрим детерминированный конечный автомат А, на котором мы выполняем приведенную выше процедуру, для того чтобы получить М. Пред- положим, что существует N такая, что L(N) = L(M) = L(A)), и N имеет меньше состоя- ний, чем М. Выполним алгоритм заполнения таблицы на М, N вместе (переимено- вывая состояния, чтобы они не имели общих состояний). Поскольку L(M) = L(N), их начальные состояния неразличимы. Таким образом, каждое состояние в M не - различимо хотя бы от одного состояния в N. Но тогда два состояния M неразличи- мы от одного и того же состояния N Задача 8.25. Предположим, это так. По PL1 ∃p такое, что |w| ≥ p ⇒ w = xyz, где |xy| ≤ p и y ≠ ε. Рассмотрим s = 0p1p = xyz. Поскольку |xy | ≤ p, y ≠ ε, очевидно, что y = 0j, j > 0. И xy2z = 0p+j1p ∈ L, что является противоречием. Задача 8.26. Предположим, это так. По PL ∃n… Рассмотрим некоторое простое p ≥ n + 2. Пусть 1p = xyz, | y| = m > 0. Поэтому |xz| = p – m. Рассмотрим xy(p–m)z, которые должны быть в L. Но |xy(p–m)z| = |xz| + |y|(p – m) = (p – m) + m(p – m) = (p – m)(1 + m). Теперь 1 + m > 1, поскольку y ≠ ε, и p – m > 1, так как p ≥ n + 2 и m = |y| ≤ |xy | ≤ n. По - этому длина xy(p–m)z не является простым числом, и, следовательно, она не может быть в L – противоречие. Задача 8.27. Для того чтобы показать, что ≡L является отношением эквива- лентности, нам нужно показать, что оно является рефлексивным, симметричным и транзитивным. Оно явно является рефлексивным; xz ∈ L ⇔ xz ∈ L является ис - тинным, независимо от контекста, поэтому x ≡L x. Его симметрия и транзитив- ность следуют непосредственно из симметричной и транзитивной природы «⇔». Задача 8.29. Мы назначаем веса символам в V; любой предикатный символ (то есть символ функции или отношения) с арностью n имеет вес n – 1. Вес строки w = w1w2 wn равен сумме ее символов. Мы делаем следующие утверждения: 1 См. https://en.wikipedia.org/wiki/PL_(complexity). – Прим. перев.\n--- Страница 202 ---\nОтветы к избранным задачам  201 1) каждый член имеет вес –1; 2) каждый надлежащий начальный сегмент весит не менее 0. Примечание: надлежащий начальный сегмент – это строка, которая не является членом, но может быть расширена до члена путем конкатенации дополнительных символов (символа) справа. Базовый случай: для 0-арных символов это явно верно; они весят –1, и един- ственным надлежащим начальным сегментом является пустая строка ε, которая имеет вес 0. Это можно расширить по структурной индукции за счет включения всех чле- нов. Рассмотрим член T = ft1 … tn, где f – это n-арный предикатный символ. f имеет вес n – 1, и каждый член ti весит –1, поэтому чистый вес T равен (n – 1) + n · (–1), или –1. Кроме того, любой надлежащий начальный сегмент из Т состоит из f (вес n – 1), первые i членов ti (чистый вес –i ) с i < n, и, возможно, надлежащий на- чальный сегмент члена ti+1, чей вес является неотрицательным. Таким образом, чистый вес такого сегмента составляет не менее (n – 1) – i ≥ 0. Пусть T1 = f1t11 … t1n и T2 = f2 t21 … t2m, и будем считать, что T1 =syn T2 (A =syn B означает, что A и B являются идентичными строками). Очевидно, что f1 = f2 = f; они являются идентичными, единичными символами, поэтому они должны представлять одну и ту же функцию или отношение. В связи с этим n = m. Более того, t 11 и t21 начи- наются с одного индекса, и ни один не может быть начальным сегментом друго-го, поэтому они также должны заканчиваться на том же индексе. Этот аргумент может быть индуктивно расширен на все остальные входные члены для f. T 1 и T2 представляют результат идентичных входных членов в идентичном порядке на одной и той же функции или отношении. Задача 8.30. Пусть t равно ft 1 …tn для некоторого n-арного функционального символа f и членов ti. Тогда t = f(t1, , tn). Схожим образом (Rt1 … tn) является идентичным (t1, , tn) ∈ R. Разница за- ключается в интерпретации: член с ведущим символом отношения является либо истинным, либо ложным, в зависимости от того, является или нет соответствую-щая упорядоченная последовательность членов элементом интерпретируемого отношения, в то время как член с ведущим символом функции является просто результирующим элементом A. Задача 8.31. Предположим, что автомат  в конечном универсуме А принима- ет L′ = {a n … a2 a1c : a1a2 … an ∈ L}. Очевидно, что (an … a1c) = an(a n–1(··· (a1(c)) ···)) ∈ A; другими словами, L() ⊆ A. Мы определяем недетерминированный конечный ав- томат для L: начальное состояние c = q0, и остальные состояния {q1, q2, , qm} – это оставшиеся элементы A – | A| является конечным, поэтому данный недетермини- рованный конечный автомат имеет конечное число состояний. Мы определяем переходную функцию следующим образом: δ(q i, a) = a(qi). Наконец, принимаю- щие состояния F – это просто те состояния, которые принимаются . L распо- знается недетерминированным конечным автоматом, поэтому он должен быть регулярным. С учетом регулярного языка L пусть D равно наименьшему детерминирован- ному конечному автомату для L. Мы знаем, что индекс(L) и Q D являются конеч- ными и одинаковы из теоремы 8.28; пусть A = QD. Мы назначаем q0 метку c (то есть c = q0) и выбираем вот такую интерпретацию: a(t) = δ(t, a). Наконец, пусть R = FD. Мы построили автомат, который принимает L′.\n--- Страница 203 ---\n202  Вычислительные основы Задача 8.32. «Метод» принятия для автоматов напрямую соответствует пересе- чениям, объединениям и дополнениям. С учетом автоматов  и B с отношениями принятия R и RB и универсумов A и B автомат, который принимает L() ⋃ L(B), легко задается универсумом A ⋃ B и отношением R ⋃ RB. Единственный нюанс со- стоит в том, что некоторые символы в V или VB, возможно, потребуется заменить новыми символами (с тем же смыслом, что и символы, которые они заменяют), с тем чтобы избежать двойной интерпретации конкретного символа. Пересечения можно обрабатывать примерно так же. Замыкание при дополнении проистекает из конечной природы A; R  должно содержать конечное число элементов P(A), и его можно просто заменить на P(A) – R, создав автомат для дополнения L(). Задача 8.35. P = {Q, å, Γ, δ, q0, F}, где: Q = {q0, q1, q2} Σ = Γ = {1, 0} F = {q2} и переходная функция δ определена ниже. Отметим, что ε в качестве элемента å∗ обозначает ε-заполнение, тогда как ε в качестве выходного элемента из стека (то есть δ(qn, x, ε)) означает, что стек пуст. δ (q0, 0, ε) = {(q0, 0)} δ (q0, 1, ε) = {(q0, 1)} δ (q0, ε, ε) = {(q2, ε)} δ (q0, 0, 1) = {(q0, 01)} δ (q0, 1, 0) = {(q0, 10)} δ (q0, 0, 0) = {(q0, 00), (q1, ε)} δ (q0, 1, 1) = {(q0, 11), (q1, ε)} δ(q1, 1, 1) = δ(q1, 0, 0) = {(q1, ε)} δ (q1, ε, ε) = {q2, ε}. Обратите внимание, что любые неопределенные переходы отображаются в подразумеваемое «мусорное состояние». На приведенной ниже схеме стрелка из q i в qj с меткой a, b → c означает, что (qj, c) ∈ δ(qi, a, b). ε, ε → εε, ε → ε 1, 1 → ε 0, 0 → ε (1, ε → 1), (0, ε → 0), (1, 0 → 10), (0, 1 → 01), (0, 0 → 00), (1, 1 → 11) (1, 1 → ε), (0, 0 → ε) Задача 8.37. Допустим (q, x, α) ⇒∗ (p, y, β). Докажем, что (q, x, αγ) ⇒∗ (p, y, βγ) по индукции на числе шагов. Доказательство. Базовый случай: (q, x, α) → (p, y, β). Тогда x = ay для некоторого а такого, что (p, b) ∈ δ(q, a, α1) и bα2α3 ··· = β. В связи с этим xw = ayw для любой w, и bα1α3 … γ = βγ. Таким образом, (q, xw, αγ) → (q, xw, βγ). Индукционный шаг: если (q, x, α) ⇒∗ (p, y, β) за n шагов, то существует некий кортеж (o, z, σ) такой, что (q, x, α) ⇒∗ (o, z, σ) за n – 1 шагов и (o, z, σ) → (p, y, β). Ин- дукционная гипотеза гарантирует, что (q, x, αγ) ⇒∗ (o, z, σγ), и еще одно применение базового случая гарантирует, что (o, z, σγ) → (p, y, βγ). Таким образом, (q, x, αγ) ⇒∗ (p, y, βγ). □\n--- Страница 204 ---\nОтветы к избранным задачам  203 Задача 8.39. Пусть P равно магазинному автомату, который принимает по ко- нечному состоянию. Мы выполним модификацию P, чтобы он принимал тот же язык по пустому стеку. Пусть q1 равно начальному состоянию P. Для каждого a та - кого, что δ(q1, a, ε) = {(qi1, βi1), … }, заменим этот переход на δ(q1, a, ε) = {(qi1, βi1$) … }. Для каждого принимающего состояния qf в P и каждого s ∈ ΓP ⋃ {$} такого, что δ(qf , ε, s), является пустым, пусть δ(qf, ε, s) = {(qf, ε)}. Очевидно, что если у нас закончились входные данные на принимающем состоянии, эта модификация позволяет P «очистить стек», не покидая, что приводит к принятию по пустому стеку. Для каждого отклоняющего состояния qr и каждого a ∈ å, если δ(qr, a, ε) = {(qi1, βi1), …}, определено, то заменяем это определение на δ(qr, a, $) = {(qi1, βi1$)}; в противном случае оставляем δ(qr, a, $) неопределеным, поэтому стек не может опустошиться на отклоняющем состоянии. Этот измененный магазинный автомат принимает L(P) по пустому стеку. Далее, пусть P равно магазинному автомату, который принимает по пустому стеку, и пусть q 1 равно начальному состоянию. Для всех a таких, что δ(q1, a, ε), опре- деляется как некоторое множество конфигураций {(qi1, βi1) … }, убираем этот пере- ход, и вместо него пусть будет δ(q1, a, ε) = {(qi1, βi1$) … }. Добавим единственное при- нимающее состояние qf, и для каждого состояния qn пусть δ(qn, ε, $) = {(qf, ε)}. Любой вход, который был бы принят по пустому стеку в исходном P, «приземляется» на qf по конструкции, и, более того, другой способ достичь qf отсутствует (мы просто определили каждый переход к нему), поэтому не принимаются никакие входы, которые были бы отклонены первоначальным определением P. Таким образом, этот модифицированный магазинный автомат принимает такой же язык, что и P, по финальному состоянию. Задача 8.41. Допустим, что A [qXp ] ⇒∗ w. Тогда, по определению, w переводит ма- газинный автомат из состояния p в состояние q и выталкивает X из стека. В связи с этим если w – это все оставшиеся входные данные, то X – это весь стек, и мага- зинный автомат находится в состоянии q, то магазинный автомат остановится на состоянии p с пустым стеком после обработки w; то есть (q, w, X) ⇒∗ (p, ε, ε). Далее допустим, что (q, w, X) ⇒∗ (p, ε, ε). Тогда w переводит магазинный автомат из состояния p в состояние q, и в ходе этого процесса он выталкивает все содер- жимое X из стека; по определению A[qXp ] ⇒∗ w. Таким образом, (A[qXp ] ⇒∗ w) ⇔ (( q, w, X) ⇒∗ (p, ε, ε)). Задача 8.48. Пусть G равно контекстно-свободной грамматике в нормальной форме Хомского, и допустим, w ∈ L(G), где w = a1a2 … an. Ясно, что для каждого терминала al ≠ ε в w должна быть переменная Xil такая, что Xil → αalβ. Поскольку G находится в нормальной форме Хомского и al ≠ ε, должно быть истинным, что α = β = ε, поэтому Xil → al является правилом. Следовательно, для всех i ∈ [1, n], (i, i) будет заселена переменной в первом цикле for. Но из нормальной формы Хомского можно получить больше; каждое правило имеет вид A → BC и A → a; то есть каждое правило увязывает переменную либо с терминалом, либо с двумя конкатенированными переменными. Таким образом, если S ⇒∗ a1a2 … an, то ясно, что S ⇒∗ Xi1 Xi2 … Xin, где Xil → al – это правило для всех l. Рассмотрим формальное суждение S ⇒∗ Xi1 Xi2 … Xin более подробно; мы знаем, что с точки зрения введения переменных единственные из имеющихся правил имеют форму S → AB, поэтому первый «→» из S в деривации X i1 Xi2 … Xin должен быть в этой форме. Очевидно, что существует целое число o такое, что A ⇒∗ Xi1 Xi2 …\n--- Страница 205 ---\n204  Вычислительные основы Xio и B ⇒∗ Xio+1 Xio+2 Xin. В связи с этим если (1, o) и ( o + 1, n) заселяются элементами A и B, то (1, n) будет впоследствии дано S. Мы можем продолжить этот анализ рекур- сивно, для того чтобы показать, что A и B будут поставлены на свои правильные места, и поэтому S в конечном итоге будет в (1, n), и w будет принято. Единствен- ным нюансом здесь является порядок, в котором проверяются пары i, j; как по- казано на рис. 8.12, мы начинаем с главной диагонали и движемся в направлении «вправо вверх», по одной диагонали за раз. Откуда мы знаем, что никакие новые слова не принимаются? То есть как мы можем быть уверены, что нет w ∉ L(G), которые будут приняты алгоритмом CYK? Задача 8.51. Пусть L равно контестно-свободному языку с грамматикой G для L – { ε}. Допустим, что G находится в нормальной форме Хомского и, более того, что она не имеет допускающих пустое значение переменных (см. п. 8.46). Пусть G имеет n переменных. Рассмотрим s ∈ L(G) такую, что |s| ≥ 2n. Тогда s должна иметь путь в дереве разбора длиной не менее n + 2 – путь длиной n + 1 необходим для достижения строки из 2n переменных вследствие нормальной формы Хомского, и требуется дополнительный шаг для увязки этих переменных с терминалами. В связи с этим в дереве разбора существует путь, содержащий n + 1 переменных; существует только n переменных, поэтому, по крайней мере, одна повторяется. То есть существует переменная R такая, что R ⇒∗ vRy для v, y ∈ å∗; более того, с не- обходимостью существует такая переменная, что это происходит не более чем за n шагов, поэтому результат имеет длину не более 2 n. Из-за природы порождения «из переменной в переменную» в нормальной форме Хомского и отсутствия до-пускающих пустое значение переменных |vy | > 0. Поскольку R ⇒∗ vRy , также явля- ется истинным то, что R ⇒∗ vvRyy ; мы можем продолжать «расширять» R таким образом, получая любое (равное) число повторных переменных v и y. Наконец, R ⇒∗ x для некоторой строки из терминалов x, тем самым заканчивая доказатель- ство. Обратите внимание, что u и z в лемме являются (возможно, пустыми) стро- ками из начального S ⇒∗ uRz для достижения первого R, где S – это начальная пере- менная. Таким образом, мы имеем S ⇒∗ uvixyiz, где |vy | > 0 и |vxy| ≤ 2n. Задача 8.52. Допустим от обратного, что L = {0n1n2n|n ≥ 1} является контекстно- свободным языком. Пусть P равно длине накачки для L. Рассмотрим s = 0p1p2p. По лемме 8.50, s должна быть uvxyz… Если v или y содержит более одного уникального терминала, то, конкатенируя его более чем один раз, мы создадим строку, кото-рая не может быть подстрокой любого элемента из L, например если v = 01, тогда v 2 = 0101, которая не может появиться в любой w ∈ L. Но если v и y каждая являются конкатенациями единственного терминала, то только два из трех терминалов по-лучают увеличение длины в своих соответствующих подстроках. Например, если v = 11 и y = 22, тогда uv 2xy2z = 0p1p+22p+2 ∉ L. Поэтому независимо от состава v и y им не удается удовлетворить условия леммы о накачке. Задача 8.53. Пусть L равно контекстно-свободному языку, и R равно регуляр- ному языку, оба из которых определены на алфавите å. Существует магазинный автомат P для L и детерминированный конечный автомат D для R, где оба при- нимают по финальному состоянию. Обозначим через di проиндексированные состоя ния в D, и через pj проиндексированные состояния в P. Для каждого состоя- ния di в D мы создаем магазинный автомат Pi, который является копией P с дву - мя ключевыми различиями: финальные состояния в Pi являются финальными, только если di является финальным состоянием в D и никаких переходов еще не\n--- Страница 206 ---\nПримечания  205 было (чтобы мы действительно копировали только состояния). Обозначим через qij состояние в Pj, которое соответствует di в D. Наконец, мы определяем перехо- ды следующим образом: (qkl, t) ∈ δ(qij, a, s) тогда и только тогда, когда δD(di, a) = dk и (pl, t) ∈ δP(pj, a, s). Обратите внимание, что по конструкции qij является принима- ющим состоянием тогда и только тогда, когда di находится в FD и pj находится в FP. Этот магазинный автомат в связи с этим принимает w тогда и только тогда, когда w ∈ L ∧ w ∈ R. Таким образом, L ⋂ R принимается магазинным автоматом, поэтому он должен быть контекстно-свободным языком. Задача 8.54. Пусть L равно контекстно-свободному языку на å, представлен- ному контекстно-свободной грамматикой G с терминалами T. Обратите внима- ние, что T = å, исходя из того что каждый элемент алфавита å достижим, и в про- тивном случае мы можем просто удалить те, которые недостижимы. Для каждого a ∈ T у нас есть контекстно-свободный язык La и соответствующая контекстно-сво- бодная грамматика Ga = {Va, Ta, Pa, Sa}. Без потери общности мы можем допустить, что Va ⋂ Vb = ∅ для всех a, b ∈ T таких, что a ≠ b, потому что новые переменные могут быть введены по желанию. В G мы можем заменить каждый терминал a во всех продукциях на Sa, и добавить все продукции в Pa. Мы создали контекстно- свободную грамматику для s(L), поэтому он должен быть контекстно-свободным языком. Задача 8.55. Мы спроектируем машину Тьюринга M такую, что L(M) является языком бинарных палиндромов. У нас есть 8 состояний: Q = {q0, q1, q2, q3, q4, q5, qaccept, qreject}, где q0 – это начальное состояние. Мы определяем δ следующим об- разом: δ(q0, 1) = (q1, □, →) δ(q0, 0) = (q2, □, →) δ(q0, □) = qaccept δ(q1, 1) = (q1, 1, →) δ(q1, 0) = (q1, 0, →) δ(q1, □) = (q3, □, ←) δ(q2, 1) = (q2, 1, →) δ(q2, 0) = (q2, 0, →) δ(q2, □) = (q4, □, ←) δ(q3, 1) = (q5, □, ←) δ(q3, 0) = qreject δ(q3, □) = qaccept δ(q4, 1) = qreject δ(q4, 0) = (q5, □, ←) δ(q4, □) = qaccept δ(q5, 1) = (q5, 1, ←) δ(q5, 0) = (q5, 0, ←) δ(q5, □) = (q0,, →) Допустим, что ввод начинается с 1. Тогда M перейдет из q0 в q1, переписывая эту 1 как пустое место, и останется в q1, двигаясь вправо до тех пор, пока он не попадет в первое пустое место (сразу после конца ввода). В этом месте он двинет - ся влево (к текущему крайне правому непустому месту) и в q3. Если этот крайне правый вход равен 1 (то есть если он совпадает с 1 слева), то он заменит эту 1 на □, пе рейдет в q5 и будет продолжать двигаться влево до тех пор, пока не попадет в пус тое место, и в этот момент он перезапустит данный процесс. Если, с другой стороны, он встречает здесь 0, то вход начинается с 1 и заканчивается нулем, по- этому он не является палиндромом и отклоняется. Наконец, если это значение равно □, то все входные данные были перезаписаны символом □, указывая на то, что входные данные были палиндромом, и приводя к их принятию. 8.7. п римеЧания Что касается разностной машины Бэббиджа, представленной во введении к на- стоящей главе, то студентам, изучающим деловую информатику, может быть ин-тересно узнать, что окончательный провал предприятия Бэббиджа был вызван\n--- Страница 207 ---\n206  Вычислительные основы отсутствием у него деловой хватки; см. стр. 563–570, [Johnson (1991)]. Материал в этой главе опирается на великолепное введение в теорию вычисле- ний [Sipser (2006)]. В частности, доказательство теоремы 8.65 можно найти в ре- шении упражнения 5.28 на стр. 215 книги [Sipser (2006)], а теорема 8.64 является-теоремой 3.21 в указанной книге. Для дальнейшего чтения читатель также адресуется к книге [Kozen (2006)]. В частности, раздел 8.3.9 основан на стр. 109 указанной книги. Исторический материал в первом абзаце раздела 8.4 взят из лекций Анджея Эренфойхта, читавшихся в Университете Колорадо в Боулдере зимой 2008 года. В 1971 году Эренфойхта был одним из основателей кафедры компьютерных наук в Университете Колорадо. Он сформулировал игру Эренфойхта-Фрайссе, исполь-зуя метод взад-вперед, описанный Роландом Фрайссе в своей диссертации. По-следовательность Эренфойхта-Мысельски также названа его именем. Двое из его учеников, Юджин Майерс и Дэвид Хаусслер, внесли значительный вклад в секве-нирование генома человека. Регулярно-языковые операции ix и x в разделе 8.3.5 взяты из задачи 1.40 в кни- ге [Sipser (2006)]. Материал по теореме Майхилла–Нероуда, раздел 8.3.8.2, моти-вирован книгой [Sipser (2006)] [Прим. 1.51 и 1.52]. Контекстно-свободные грамматики являются основой синтаксических анали- заторов, или парсеров. Существует много инструментов, которые реализуют идеи, упомянутые в этом разделе; например, Lex, Yacc, Flex, Bison и другие. Подробнее о них можно прочитать здесь: http://dinosaur.compilertools.net. Раздел 8.4.3 основан на § 7.1 книги [Hopcroft и соавт. (2007)]. В разделе 8.2 мы обсуждаем ur-понятия, такие как символы и слова. Интригу - ющей областью изучения таких объектов является семиотика, изучение знаков и символов, их использование или интерпретация. С давних пор «маркировочные знаки» используются для хранения и обработки информации. Около 8000 лет на-зад люди использовали символы для обозначения слов и понятий. Истинные фор-мы письма развивались в течение следующих нескольких тысяч лет, и особое зна-чение имеют цилиндрические печати. Они прокатывались по влажным глиняным табличкам, в результате чего получались рельефные конструкции. Многие музеи имеют цилиндрические печати в лазурите 1, относящиеся к Ассирийской культу - ре, найденные в Вавилоне, Ирак, возраст которых оценивается в 4100–3600 лет. Рельефные конструкции были клинописными символами, которые обозначали понятия, а затем звуки и слоги. Читателю предлагается посетить, хотя бы онлайн, артефакты, выставленные в Смитсоновском музее естественной истории, Вашингтон, округ Колумбия. Там можно найти выгравированную доску из охры 2 с примитивной символикой из пещеры Бломбос, Южная Африка, которой, по оценкам, 77 000–75 000 лет. Кроме того, кости Ишанго из Конго, по оценкам, имеют возраст 25 000–20 000 лет, кото-рые являются костью ноги бабуина, с тремя рядами счетных меток для сложения и умножения (археологи не уверены, какие из них какие). И наконец, оленьи рога 1 Лазурит – редкий полудрагоценный камень, который издревле ценился за свой насы- щенный синий цвет. 2 Охра – землистый пигмент, содержащий железную окись, как правило, с глиной, варьи-рующийся по цвету от светло-желтого дл коричневого или красного цвета.\n--- Страница 208 ---\nПримечания  207 с отметками, из Мадленской культуры, Франция, по оценкам имеющие возврат 17 000–11 500 лет. В наборе текста разные стилевые формы английского алфавита называются шрифтами. Шрифты PostScript – это спецификации контурных шрифтов, разра-ботанные компанией Adobe Systems для профессионального цифрового набора, который используется в формате файла PostScript для кодирования информации о шрифтах. Контурные шрифты (или векторные шрифты) представляют собой множества векторных изображений, то есть множество линий и кривых для опре-деления границы глифа. С алгебраической точки зрения мы можем сказать, что å* вместе с оператором конкатенации · является моноидом, где · является ассоциативной операцией, а ε – элементом тождественности. Это одна из многих точек сопряжения между сим-вольными цепочками, или строками, и красивой областью алгебры, именуемой теорией групп (см. раздел 9.2.3).",
      "debug": {
        "start_page": 156,
        "end_page": 208
      }
    },
    {
      "name": "Глава 9. Математическая основа 208",
      "content": "--- Страница 209 --- (продолжение)\nГлава 9 Математическая основа И из математических рассуждений возни- кает истинный философский вопрос, во-прос, который не сможет решить никакое количество биологии: а именно что такое математика? Что же такое числа, множества и трансфинитные кардиналы? Сэр Роджер Скратон [Scruton (2014)], стр. 6 9.1. и ндУкция и инвариантность 9.1.1. Индукция Пусть � = {0, 1, 2, …} равно множеству натуральных чисел. Предположим, что S – это подмножество � со следующими двумя свойствами: первое, 0 ∈ S, и второе, всякий раз, когда n ∈ S, то также и n + 1 ∈ S. Тогда, используя принцип индукции, можно сделать вывод, что S = �. Мы будем использовать принцип индукции с более удобной формой записи; пусть P равно свойству натуральных чисел, другими словами, P – это унарное от - ношение, такое, что P(i ) либо истинно, либо ложно. Отношение P можно очевид- ным образом идентифицировать множеством SP, то есть i ∈ SP тогда и только тогда, когда P(i ) истинно. Например, если P – это свойство примарности, то P(2) и P(3) истинны, но P(6) является ложным, и SP = {2, 3, 5, 7, 11, …}. Используя эту форму записи, принцип индукции может быть сформулирован как [P(0) ∧ ∀n(P(n) → P(n + 1))] → ∀mP(m) (9.1) для любого (унарного) отношения P над �. На практике мы используем (9.1) следу - ющим образом: сначала доказываем, что P(0) соблюдается (это базовый случай). Затем мы показываем, что ∀n(P(n) → P(n + 1)) (это индукционный шаг). Наконец, используя (9.1) и модус попенс, мы заключаем, что ∀mP(m). В качестве примера пусть P равно логическому утверждению «сумма первых i нечетных чисел равна i2». Мы следуем соглашению, что сумма пустого множества чисел равна нулю; таким образом, P(0) соблюдается, поскольку множество первых нулевых нечетных чисел является пустым множеством. P(1) является истинным, так как 1 = 1 2, и P(3) также является истинным, поскольку 1 + 3 + 5 = 9 = 32. Мы хотим показать, что на самом деле ∀mP(m), то есть P всегда является истинным, и поэтому SP = �.\nГлава 9 Математическая основа И из математических рассуждений возни- кает истинный философский вопрос, во-прос, который не сможет решить никакое количество биологии: а именно что такое математика? Что же такое числа, множества и трансфинитные кардиналы? Сэр Роджер Скратон [Scruton (2014)], стр. 6 9.1. и ндУкция и инвариантность 9.1.1. Индукция Пусть � = {0, 1, 2, …} равно множеству натуральных чисел. Предположим, что S – это подмножество � со следующими двумя свойствами: первое, 0 ∈ S, и второе, всякий раз, когда n ∈ S, то также и n + 1 ∈ S. Тогда, используя принцип индукции, можно сделать вывод, что S = �. Мы будем использовать принцип индукции с более удобной формой записи; пусть P равно свойству натуральных чисел, другими словами, P – это унарное от - ношение, такое, что P(i ) либо истинно, либо ложно. Отношение P можно очевид- ным образом идентифицировать множеством SP, то есть i ∈ SP тогда и только тогда, когда P(i ) истинно. Например, если P – это свойство примарности, то P(2) и P(3) истинны, но P(6) является ложным, и SP = {2, 3, 5, 7, 11, …}. Используя эту форму записи, принцип индукции может быть сформулирован как [P(0) ∧ ∀n(P(n) → P(n + 1))] → ∀mP(m) (9.1) для любого (унарного) отношения P над �. На практике мы используем (9.1) следу - ющим образом: сначала доказываем, что P(0) соблюдается (это базовый случай). Затем мы показываем, что ∀n(P(n) → P(n + 1)) (это индукционный шаг). Наконец, используя (9.1) и модус попенс, мы заключаем, что ∀mP(m). В качестве примера пусть P равно логическому утверждению «сумма первых i нечетных чисел равна i2». Мы следуем соглашению, что сумма пустого множества чисел равна нулю; таким образом, P(0) соблюдается, поскольку множество первых нулевых нечетных чисел является пустым множеством. P(1) является истинным, так как 1 = 1 2, и P(3) также является истинным, поскольку 1 + 3 + 5 = 9 = 32. Мы хотим показать, что на самом деле ∀mP(m), то есть P всегда является истинным, и поэтому SP = �.\n--- Страница 210 ---\nИндукция и инвариантность  209 Обратите внимание, что SP = � не означает, что все числа являются нечетны- ми – совершенно очевидное ложное логическое утверждение. Мы используем на- туральные числа для индексирования нечетных чисел, то есть o1 = 1, o2 = 3, o3 = 5, o4 = 7, …, и наша индукция осуществляется над этим индексированием (где oi – это i-е нечетное число, то есть oi = 2i – 1). То есть мы доказываем, что для всех i ∈ N, o1 + o2 + o3 + ··· + oi = i2; наше логическое утверждение P(i ) является именно формаль- ным суждением «o1 + o2 + o3 + ··· + oi = i2». Теперь мы используем индукцию: базовый случай равен P(0), и мы уже пока- зали, что он соблюдается. Предположим теперь, что это логическое утверждение соблюдается для n, то есть сумма первых n нечетных чисел равна n 2, то есть 1 + 3 + 5 + ··· + (2n – 1) = n2 (это наша индукционная гипотеза, или индукционное допуще- ние). Рассмотрим сумму первых (n + 1) нечетных чисел, 1 + 3 + 5 + ··· + (2n – 1) + (2n + 1) = n2 + (2n + 1) = (n + 1)2, и тем самым мы только что доказали индукционный шаг, и по принципу индук - ции мы имеем ∀mP(m). Задача 9.1. Докажите, что 1 + åi j=0 2j = 2i+1. Иногда удобно начать нашу индукцию с более высокого значения, чем в 0. Мы имеем следующий обобщенный принцип индукции: [P(k) ∧ (∀n ≥ k)(P(n) → P(n + 1))] → (∀m ≥ k)P(m) (9.2) для любого предиката P и любого числа k. Обратите внимание, что (9.2) легко сле- дует из (9.1), если мы просто примем P(i ) равным Р(i + k) и выполним привычную индукцию на предикате P′(i ). Задача 9.2. Примените индукцию, для того чтобы доказать, что для n ≥ 1 13 + 23 + 33 + ··· + n3 = (1 + 2 + 3 + ··· + n)2. Задача 9.3. Для каждого n ≥ 1 рассмотрите площадь размера 2n×2n квадратов, в ко- торой один квадрат отсутствует. Покажите, что результирующую площадь можно заполнить фигурами в форме латинской буквы «L» – то есть кластерами из трех квадратов, где три квадрата не образуют линию. Задача 9.4. Предположим, что мы переформулируем обобщенный принцип ин- дукции (9.2) как [P(k) ∧ ∀n(P(n) → P(n + 1))] → (∀m ≥ k)P(m). (9.2′) Какова связь между (9.2) и (9.2)? Задача 9.5. Последовательность Фибоначчи определяется следующим образом: f0 = 0 и f1 = 1 и fi + 2 = fi + 1 + fi, i ≥ 0. Докажите, что для всех n ≥ 1 мы имеем: 1 1= ,n 1 0fn+1fn fnfn–1 где левая сторона – это n-я степень матрицы размера 2×2.Задача 9.6. Напишите программу, вычисляющую n-е число Фибоначчи с по- мощью матричного умножения задачи 9.5.\n--- Страница 211 ---\n210  Математическая основа Задача 9.7. Докажите следующее: если m делит n, то fm делит fn, то есть m|n ⇒ fm|fn. Принцип полной индукции подобен принципу индукции, за исключением того, что на индукционном шаге мы показываем, что если P(i ) соблюдается для всех i ≤ n, то Р(n + 1) тоже соблюдается, то есть индукционный шаг сейчас равен ∀n((∀i ≤ n) P(i) → P(n + 1)). Задача 9.8. Используйте принцип полной индукции, для того чтобы доказать, что каждое число (в n) больше 1 может быть записано как произведение одного или нескольких простых чисел. Задача 9.9. Предположим, что у нас есть плитка (швейцарского) шоколада, состо- ящая из нескольких долек, расположенных в прямоугольном узоре. Наша задача – разломить плитку на дольки (она всегда ломается вдоль линий между дольками) с минимальным количеством разламываний. Сколько разламываний потребует - ся? Выдвиньте обоснованную догадку и докажите ее по индукции. Принцип наименьшего числа говорит, что каждое непустое подмножество нату - ральных чисел должно иметь наименьший элемент. Прямым следствием данного принципа является то, что каждая убывающая неотрицательная последователь-ность целых чисел должна завершиться; то есть если R = {r 1, r2, r3, …} ⊆ �, где ri > ri+i для всех i, то R – это конечное подмножество �. Мы намерены применить принцип наименьшего числа, для того чтобы показать завершение алгоритмов. Задача 9.10. Покажите, что принцип индукции, принцип полной индукции и принцип наименьшего числа являются эквивалентными принципами. Существует три стандартных способа перечисления узлов бинарного дерева. Мы представляем их ниже вместе с рекурсивной процедурой, которая перечисля- ет узлы в соответствии с каждой схемой представления. Инфиксная: левое поддерево, корень, правое поддерево. Префиксная: корень, левое поддерево, правое поддерево. Постфиксная: левое поддерево, правое поддерево, корень. См. пример на рис. 9.1. 73 5 62 41Инфиксная: 2, 1, 6, 4, 7, 3, 5 Префиксная: 1, 2, 3, 4, 6, 7, 5 Постфиксная: 2, 6, 7, 4, 5, 3, 1 Рис. 9.1  Бинарное дерево с соответствующими представлениями Обратите внимание, что для инфиксной, префиксной и постфиксной схем представления некоторые авторы используют другое название; они называют их соответственно порядковый (inorder), предпорядковый (preorder) и постпорядко-вый (postorder) обход. Задача 9.11. Покажите, что при любых двух представлениях мы можем получить из них третье, или, другими словами, из любых двух представлений мы можем\n--- Страница 212 ---\nИндукция и инвариантность  211 восстановить дерево. Покажите, используя индукцию, что ваша реконструкция правильная. Затем покажите, что одного представления недостаточно. Задача 9.12. Напишите программу, которая принимает на входе два из трех опи- саний, а выводит третье. Один из способов представить входные данные – размес - тить их в текстовом файле, состоящем из двух строк, например инфикс: 2,1,6,4,7,3,5 постфикс: 2,6,7,4,5,3,1 и соответствующий выход будет: префикс: 1,2,3,4,6,7,5 . Обратите внимание, что каждая строка входных данных должна указывать схему описания. 9.1.2. Инвариантность Метод инвариантности – это метод доказательства логических утверждений об исходах процедур. Даный метод определяет некоторое свойство, которое остается истинным в течение исполнения процедуры. Затем, как только процедура завер-шается, мы используем это свойство, чтобы доказывать логические утверждения об исходе. В качестве примера рассмотрим доску размера 8×8, из которой были удале- ны две клетки из противоположных углов (см. рис. 9.2). Площадь доски равна 64 – 2 = 62 клетки. Теперь предположим, что у нас 31 кость домино размером 1×2. Мы хотим показать, что доска не может быть ими покрыта. Рис. 9.2  Доска размера 8×8 Верифицирование с помощью грубой силы (то есть исследование всех воз- можных покрытий доски) будет чрезвычайно трудоемким. Однако, применяя метод инвариантности, мы рассуждаем следующим образом: раскрасим клетки как шахматную доску. Каждая кость домино, покрывающая две смежные клет - ки, покрывает 1 белую и 1 черную клетку, и, следовательно, каждое размещение покрывает столько белых клеток, сколько оно покрывает черных клеток. Обра-тите внимание, что число белых клеток и число черных клеток различаются на 2 – противоположные углы, лежащие на одной диагонали, имеют один и тот же цвет – и, следовательно, никакое размещение костей домино не дает покрытия; готово! Более формально, мы кладем кости домино по одной на доску в любом удоб- ном для нас виде. Инвариант состоит в том, что после размещения каждой новой кости домино число покрытых белых квадратов совпадает с числом покрытых черных квадратов. Мы приводим доказательство, что это является инвариантом, по индукции на числе размещенных костей домино. Базовый случай – это ког -\n--- Страница 213 ---\n212  Математическая основа да было размещено ноль костей домино (и поэтому было покрыто ноль черных и ноль белых клеток). На индукционном шаге мы добавляем еще одну кость до-мино, которая, независимо от того, как мы ее размещаем, покрывает одну белую и одну черную клетки, тем самым сохраняя свойство. В конце концов, когда мы закончим размещение костей домино, у нас должно быть столько белых клеток, сколько черных клеток, что невозможно из-за характера окраски доски (то есть число черных и белых клеток не то же самое). Обратите внимание, что этот аргу - мент легко распространяется на доску размера n×n. Задача 9.13. Пусть n равно нечетному числу, и предположим, что мы имеем мно- жество {1, 2, …, 2n}. Мы выбираем во множестве любые два числа a, b, удаляем их из множества и заменяем их на |a – b|. Продолжайте повторять это до тех пор, пока во множестве не останется только одно число; покажите, что это оставшееся число должно быть нечетным. Следующие три задачи имеют общую тему, связанную с общественными со- браниями. Мы всегда исходим из того, что отношения симпатий и антипатий, дружеские или недружеские, симметричны: то есть если a нравится b, то и b тоже нравится a и т. д. См. раздел 9.3 для получения общей информации по отношени- ям – симметричные отношения определены на стр. 217. Задача 9.14. В загородном клубе каждому члену не нравится не более трех других членов. Существует два теннисных корта; покажите, что каждый член может быть приписан одному из двух кортов так, что не более одного человека, который ему не нравится, также играет на том же корте. Мы используем лексику «загородный клуб» и «теннисный корт», но ясно, что задача 9.14 представляет собой типичную ситуацию, с которой можно столкнуть-ся в информатике: например, многопоточная программа, которая выполняется на двух процессорах, где пара потоков, когда они используют много одинаковых ресурсов, воспринимается как «соперники». Потоки, требующие одинаковых ре-сурсов, должны планироваться на разных процессорах, насколько это возможно. В некотором смысле эти, казалось бы, невинные задачи являются притчами ин-форматики. Задача 9.15. Вы принимаете званый обед, где 2n человек будут сидеть за круглым столом. Как это нередко происходит в любой социальной клике, довольно часто имеет место неприязнь, но вы знаете, что любому, сидящему за столом, не нра- вятся (n – 1) людей; покажите, что вы можете рассадить людей так, чтобы никто не сидел рядом с кем-то, кого он недолюбливает. Задача 9.16. На встрече происходит обмен рукопожатиями. Мы называем чело- века нечетным лицом, если он обменялся нечетным числом рукопожатий. Пока- жите, что в любой момент существует четное число нечетных лиц. 9.2. теория Чисел В этом разделе мы будем работать со множеством целых и натуральных чисел: � = { , –3, –2, –1, 0, 1, 2, 3, }, � = {0, 1, 2, }.\n--- Страница 214 ---\nТеория чисел  213 9.2.1. Простые числа Мы говорим, что x делит y, и записываем x|y, если y = qx. Если х|y, то будем го- ворить, что x является делителем (также фактором) y. Используя терминологию, представленную в разделе 1.1.2, x|y тогда и только тогда, когда y = div(х, y) · x. Мы говорим, что число p является простым, если его делителями являются само это число и 1. Утверждение 9.17. Если p является простым числом и p|a1a2 … an, то p|ai для не- которого i.Доказательство. Достаточно показать, что если p|ab, то p|a или p|b. Пусть g = gcd(a, p). Тогда g|p, и поскольку p – это простое число, то существует два случая. Случай 1, g = р, то поскольку g|a, то p|а. Случай 2, g = 1, поэтому существуют u и v такие, что au + рv = 1 (см. алгоритм 1.8), поэтому abu + pbv = b. Поскольку p|ab, и p|p, из этого следует, что p|(abu + pbv), поэтому р|b. □ Теорема 9.18 (основная теорема арифметики). Пусть дано a ≥ 2. С учетом этого a можно записать как а = p 1e1p2e2 ··· prer, где pi – это простые числа, и, помимо переста- новки простых чисел, данная факторизация уникальна.Доказательство. Сначала мы покажем существование факторизации, а затем ее уникальность. Доказательство существования выполняется по полной индукции; базовый случай a = 2, где 2 – это простое число. Рассмотрим целое число a > 2. Если a – простое, то оно является своей собственной факторизацией (как и в базовом случае). В противном случае если а – составное, то a = b · c, где 1 < b, c < a; применя- ем индукционную гипотезу к b и c. Для того чтобы показать уникальность, предположим, что a = p 1 p2 … ps = q1q2 … qt, где мы выписали все простые числа, то есть вместо записи pe мы e раз пишем p · p ··· p. Поскольку p1|a, из этого следует, что p1|q1q2 ··· qt. Поэтому по утвержде- нию 9.17 p1|qj для некоторого j, но тогда p1 = qj, так как они оба простые. Теперь удалим p1 из первого списка и qj из второго списка и продолжим. Совершенно очевидно, что мы не сможем завершить произведением простых чисел, равным 1, поэтому два списка должны быть идентичными. □ 9.2.2. Модулярная арифметика Пусть m ≥ 1 равно целому числу. Мы говорим, что a и b конгруентны по модулю m, и записываем а ≡ b (mod m) (или иногда a ≡m b), если m|(a – b). Еще один способ сказать это состоит в том, что a и b имеют одинаковый остаток при делении на m; используя терминологию раздела 1.1, мы можем сказать, что a ≡ b (mod m) тогда и только тогда, когда rem(a, m) = rem(b, m). Задача 9.19. Покажите, что если a1 ≡m a2 и b1 ≡m b2, то a1 ± b1 ≡m a2 ± b2 и a1 · b1 ≡m a2 · b2. Пропозиция 9.20. Если m ≥ 1, то a · b ≡m 1 для некоторого b тогда и только тогда, когда gcd(a, m) = 1. Доказательство. (⇒) Если существует b такое, что a · b ≡m 1, то мы имеем m|(ab – 1) и, таким образом, существует c такое, что ab – 1 = cm, то есть ab – cm = 1. И по- скольку gcd(a, m) делит и a, и m, то он также делит ab – cm, и, значит, gcd(a, m)|1, и поэтому он должен быть равен 1.\n--- Страница 215 ---\n214  Математическая основа (⇐) Предположим, что gcd(a, m) = 1. По расширенному алгоритму Евклида (см. алгоритм 1.8) существуют u, v такие, что au + mv = 1, поэтому au – 1 = –mv, поэтому m|(au – 1), и, значит, au ≡m 1. Поэтому пусть b = u. □ Пусть �m = {0, 1, 2, …, m – 1}. Назовем �m множеством целых чисел по модулю m. Для того чтобы сложить или умножить во множестве �m, мы складываем и умно- жаем соответствующие целые числа, а затем берем остаток от деления на m в ка- честве результата. Пусть �m = {a ∈ �m|gcd(a, m) = 1}. По пропозиции 9.20 мы знаем, что �∗ m – это подмножество �m, состоящее из тех элементов, которые имеют муль- типликативные инверсии в �m. Функция φ(n) называется эйлеровой функцией и является числом элементов меньше n, взаимно простых с n, то есть φ(n) = |�∗ m|. Задача 9.21. Если мы можем факторизовать, мы также можем вычислить φ(n). Покажите, что если n = p1k1p2k2 ··· plkl, то φ(n) = ∏l i=1 piki–1(pi – 1). Теорема 9.22 (малая теорема Ферма). Пусть p равно простому числу, и gcd(a, p) = 1. Тогда ap–1 ≡ 1 (mod p). Доказательство. Для любого a такого, что gcd(a, p) = 1, все следующие произве- дения 1a, 2 a, 3a, , ( p – 1) a, (9.3) взятые по модулю p, попарно не совпадают. Для того чтобы это увидеть, пред- положим, что ja ≡ ka (mod p). Тогда ( j – k)a ≡ 0 (mod р), и поэтому p|(j – k)a. Но так как по принятому допущению gcd(a, p) = 1, отсюда следует, что p /| a, и, значит, по утверждению 9.17 действительно должно иметь место, что p|(j – k). Но так как j, k ∈ {1, 2, , p – 1}, из этого следует, что –(p – 2) ≤ j – k ≤ ( p – 2), поэтому j – k = 0, то есть j = k. Таким образом, числа в списке (9.3) являются просто переупорядочиванием списка {1, 2, , p – 1}. Следовательно: ap–1(p – 1)! ≡p ∏p–1 j=1 j · a ≡p ∏p–1 j=1 j ≡p (p – 1)!. (9.4) Поскольку все числа в {1, 2, , p – 1} имеют инверсии в �p, так как gcd(i , p) = 1 для 1 ≤ i ≤ p – 1, их произведение также имеет инверсию. То есть (p – 1)! имеет инверсию, и поэтому, умножая обе стороны (9.4) на ((p – 1)!)–1, мы получаем ре- зультат. □ Задача 9.23. Приведите второе доказательство малой теоремы Ферма, используя биномиальное разложение, то есть (x + y)n = ån j=0 �n j�xjyn–j применительно к (a + 1)p. 9.2.3. Т еория групп Мы говорим, что (G, ∗) является группой, если G является множеством и ∗ опера- цией, такой, что если a, b ∈ G, то a ∗ b ∈ G (это свойство называется замыканием). Кроме того, операция ∗ должна удовлетворять следующим трем свойствам: 1) закон существования нейтрального элемента: существует e ∈ G такой, что e ∗ a = a ∗ e = a для всех а ∈ G;\n--- Страница 216 ---\nТеория чисел  215 2) закон существования обратного элемента: для каждого а ∈ G существует эле- мент b ∈ G такой, что a ∗ b = b ∗ a = e. Этот элемент b называется обратным, и можно показать, что он уникален; следовательно, он часто обозначается как a–1; 3) ассоциативный закон: для всех a, b, c ∈ G мы имеем а ∗ (b ∗ c) = (a ∗ b) ∗ c. Если (G, ∗) также удовлетворяет коммутативному закону, то есть если для всех a, b ∈ G, a ∗ b = b * a, то это называется коммутативной, или абелевой, группой. Типичными примерами групп являются (�n, +) (целые числа по модулю n при сложении) и (�∗ n) (целые числа по модулю n при умножении). Обратите внимание, что обе эти группы абелевы. Разумеется, нас интересуют эти две группы; но есть и ряд других: (ℚ, +) – бесконечная группа (рациональных чисел при сложении), GL(n, �) (это группа из обратимых n×n-матриц на поле �) и Sn (симметрическая группа над n элементами, состоящая из перестановок [n], где ∗ – это композиция функций). Задача 9.24. Покажите, что (�n, +) и ( �∗ n, ·) являются группами, проверив, что соот - ветствующая операция удовлетворяет трем аксиомам группы. Пусть |G| обозначает число элементов в G (заметим, что G может быть беско- нечной, но мы имеем дело главным образом с конечными группами). Если g ∈ G и х ∈ �, то gx = g ∗ g ∗ ··· ∗ g, х раз. Если из контекста ясно, что операцией является ∗, то мы используем смежное расположение ab вместо a ∗ b. Предположим, что G является конечной группой и a ∈ G; тогда наименьшим d ∈ � таким, что ad = e, называется порядок а, и он обозначается как ordG(а) (или просто ord(а), если группа G ясна из контекста).Пропозиция 9.25. Если G является конечной группой, то для всех а ∈ G существу - ет d ∈ � такое, что a d = е. Если d = ordG(а) и ak = е, то d|k. Доказательство. Рассмотрим список a1, a2, a3, … . Если G является конечной, то должно существовать i < j такое, что ai = aj. Тогда, (a–1)*, примененное к обеим сто- ронам, дает aj–i = e. Пусть d = ord(a) (по принципу наименьшего числа мы знаем, что оно должно существовать!). Предположим, что k ≥ d, ak = e; пусть q, r равно соответственно делителю и остатку. Тогда е = ak = adq+r = (ad)qar. Поскольку ad = e, из этого следует, что ar = e, противореча минимальности d = ord(a), если только не r = 0. □ Если (G, ∗) является группой, то мы говорим, что H является подгруппой груп- пы G, и записываем H ≤ G, если H ⊆ G и H замыкается при ∗. То есть H является подмножеством группы G, и H сама является группой. Обратите внимание, что для любой G всегда имеет место {e} ≤ G и G ≤ G; эти два элемента называются тривиальными подгруппами группы G. Если H ≤ G и g ∈ G, то gH называется левым сомножеством группы G, и оно представляет собой просто множество {gh |h ∈ H}. Обратите внимание, что gH не обязательно является подгруппой группы G.Теорема 9.26 (Лагранжа). Если G является конечной группой и H ≤ G, то | H| делит |G|, то есть порядок H делит порядок G.Доказательство. Если g 1, g2 ∈ G, то два сомножества g1H и g2H либо идентичны, либо g1H ⋂ g2H = ∅. Для того чтобы это увидеть, предположим, что g ∈ g1H ⋂ g2H,\n--- Страница 217 ---\n216  Математическая основа поэтому g = g1h1 = g2h2. В частности, g1 = g2h2h1–1. Таким образом, g1H = (g2h2h1–1)H, и по - скольку легко можно проверить, что (аb)H = а(bH) и что hH = H для любого h ∈ H, из этого следует, что g1H = g2H. Следовательно, для конечной G = {g1, g2, , gn} коллекция множеств {g1H, g2H, , gnH} является разбиением G на подмножества, которые либо пересекаются, либо идентичные; из всех подколлекций идентичных сомножеств мы выбираем пред- ставителя, в силу чего G = gi1H ⋃ gi2H ⋃ … ⋃ gimH, и поэтому |G| = m|H|, и доказатель- ство завершено. □ Задача 9.27. Пусть H ≤ G. Покажите, что если h ∈ H, тогда hH = H, и что в общем случае для любого g ∈ G |gH| = |H|. Наконец, покажите, что (ab)H = a(bH). Задача 9.28. Если G – это группа и {g1, g2, , gk} ⊆ G, то множество g1, g2, , gk опре- деляется следующим образом: {x1 x2 ··· xp|p ∈ �, xi ∈ {g1, g2, , gk, g1–1, g2–1, , gk–1}}. Покажите, что множество g1, g2, , gk (именуемое подгруппой, генерируемой {g1, g2, , gk}) – это подгруппа группы G. Также покажите, что когда G конечна, |g| = ordG(g). 9.2.4. Приложения теории групп к теории чисел Теорема 9.29 (Эйлера). Для каждого n и каждого а ∈ �∗ n, то есть для каждой пары a, n такой, что gcd(a, n) = 1, мы имеем aφ(n) ≡ 1 (mod n). Доказательство. Сначала легко проверить, что (�∗ n, ·) является группой. Тогда по определению φ(n) = |�∗ n|, и поскольку a ≤ �∗ n по теореме Лагранжа следует, что ord(а) = |a| делит φ(n). □ Обратите внимание, что малая теорема Ферма (уже представленная как теоре- ма 9.22) является непосредственным следствием теоремы Эйлера, так как, когда p является простым, �∗ n = �p – {0} и φ(p) = (p – 1). Теорема 9.30 (китайская теорема об остатках). С учетом двух множеств чисел одинакового размера, r0, r1, , rn и m0, m1, , mn таких, что 0 ≤ ri < mi 0 ≤ i ≤ n (9.5) и gcd(mi, mj) = 1 для i ≠ j, значит, существует r такой, что r ≡ ri (mod mi) для 0 ≤ i ≤ n. Доказательство. Мы даем доказательство путем подсчета; мы показываем, что разные значения r, 0 ≤ r < ∏mi, представляют собой разные последовательности. Для того чтобы это увидеть, обратите внимание, что если r ≡ r′ (mod mi) для всех i, то mi |(r – r′) для всех i и, значит, ( ∏mi)|(r – r′), так как mi являются попарно взаимно простыми. Поэтому r ≡ r′ (mod (∏mi)), и, значит, r = r′, так как оба r, r′ ∈ {0, 1, , (∏mi) – 1}. Но суммарное число последовательностей r0, …, rn такое, что соблюдается (9.5), составляет ровно ∏mi. Следовательно, каждая такая последовательность должна быть последовательностью остатков некоторого r, 0 ≤ r < ∏mi. □ Задача 9.31. Доказательство теоремы 9.30 (китайской теоремы об остатках) яв- ляется неконструктивным. Покажите, как эффективно получить r, которое удов-\n--- Страница 218 ---\nОтношения  217 летворяет требованиям теоремы, то есть за полиномиальное время в n – таким образом, чтобы, в частности, не использовать поиск методом грубой силы. При наличии двух групп (G1, ∗1) и (G2, ∗2) отображение h : G1 → G2 является гомо- морфизмом, если он соблюдает операцию групп; формально для всех g1, g1′ ∈ G1, h(g1 ∗1 g1′) = h(g1) ∗2 h(g1′). Если гомоморфизм h также является биекцией, тогда он называется изоморфизмом. Если между двумя группами G1 и G2 существует изо- морфизм, то мы называем их изоморфными и записываем G1 ≅ G2. Если (G1, ∗1) и (G2, ∗2) – это две группы, то их произведение, обозначаемое (G1 × G2, ∗), представляет собой просто {(g1, g2) : g1 ∈ G1, g2 ∈ G2}, где (g1, g2) ∗ (g1′, g2′) равно (g1 ∗1 g1′, g2 ∗2 g2′). Произведение n групп, G1 × G2 × ··· × Gn, может быть определено аналогичным образом; используя эту форму записи, китайская теорема об остат - ках может быть сформулирована на языке теории групп следующим образом. Теорема 9.32 (китайская теорема об остатках, версия II). Если m0, m1, ···, mn – попарно взаимно простые числа, то �m0·m1· ·m n ≅ �m0 × �m1 × ··· × �mn. Задача 9.33. Докажите теорему 9.32. 9.3. отношения В этом разделе мы представляем основы отношений. При наличии двух множеств Х и Y Х × Y обозначает множество (упорядоченных) пар {(x, y)|x ∈ X ∧ y ∈ Y}, и от - ношение R равно подмножеству X × Y, то есть R ⊆ X × Y. Тем самым элементы R имеют форму (x, y), и мы записываем (х, y) ∈ R (можно также записать xRy, Rxy или R(х, y)). В дальнейшем мы исходим из допущения, что мы квантифицируем над множеством X и что R ⊆ X × X; мы говорим, что 1) R является рефлексивным, если ∀x, ( x, x) ∈ R; 2) R является симметричным, если ∀x∀y, ( x, y) ∈ R тогда и только тогда, когда (y, x) ∈ R; 3) R является антисимметричным, если ∀x∀y, если (x, y) ∈ R и (y, x) ∈ R, то х = y; 4) R является транзитивным, если ∀x∀y∀z, если (x, y) ∈ R и ( y, z) ∈ R, то также имеет место, что (x, z) ∈ R. Предположим, что R ⊆ X × Y и S ⊆ Y × Z. Композиция R и S определяется следую- щим образом: R ∘ S = {(x, y)|∃z, xRz ∧ zSy}. (9.6) Пусть R ⊆ X × X; мы можем определить Rn := R ∘ R ∘ ··· ∘ R рекурсивно следующим образом: R0 = idX := {(x, x)|x ∈ X} (9.7) и Ri+1 = Ri ∘ R. Обратите внимание, что в (9.7) существует два разных равенства; «=» является обычным равенством, а «:=» является определением. Теорема 9.34. Следующие три отношения эквивалентны: 1) R является транзитивным; 2) R2 ⊆ R; 3) ∀n ≥ 1, Rn ⊆ R.\n--- Страница 219 ---\n218  Математическая основа Задача 9.35. Докажите теорему 9.34. Существует два стандартных способа представления конечных отношений, то есть отношений на X × Y, где X и Y – это конечные множества. Пусть X = {a1, , an} и Y = {b1, , bm}, тогда мы можем представить отношение R ⊆ X × Y: 1) в виде матрицы MR = (mij), где: mij = � 1 (ai, bj) ∈ R, 0 (ai, bj) ∉ R 2) и в виде ориентированного графа GR = (VR, ER), где VR = Х ⋃ Y и ai• → •bj явля- ется ребром в ER тогда и только тогда, когда (ai, bj) ∈ R. 9.3.1. Замыкание Пусть P равно свойству1 отношений, например транзитивности или симметрии. Пусть R ⊆ X × X равно отношению, со свойством P либо без него. Отношение S, удовлетворяющее следующим трем условиям: 1) S имеет свойство P; 2) R ⊆ S; (9.8) 3) ∀Q ⊆ X × X, «Q имеет P» из R ⊆ Q следует, что S ⊆ Q, называется замыканием R относительно P . Обратите внимание, что в некоторых случаях замыкания может не существовать. Также заметим, что условие 3 может быть заменено на S ⊆ � Q. (9.9) См. рис. 9.3 с примером рефлексивного замыкания. Рис. 9.3  Пример рефлексивного замыкания: без пунктирных ли- ний эта диаграмма представляет собой отношение, которое не явля-ется рефлексивным; с пунк тирными линиями оно рефлексивно, и это на самом деле наименьшее рефлексивное отношение, содержащее три точки и четыре сплошные линии Теорема 9.36. Для R ⊆ X × X R ⋃ idX является рефлексивным замыканием R. Задача 9.37. Докажите теорему 9.36. 1 Мы встречали понятие абстрактного свойства в разделе 9.1.1. Единственная разница за- ключается в том, что в разделе 9.1.1 свойство P(i) было над i ∈ n, в то время как здесь при наличии множества X свойство определено над Q ∈ P(Х × Х), то есть P(Q), где Q ⊆ Х × Х. В этом разделе, вместо того чтобы писать P(Q), мы говорим «Q имеет свойство P».Q имеет P , R ⊆ Q\n--- Страница 220 ---\nОтношения  219 См. рис. 9.4 с примером симметричного замыкания. Теорема 9.38. При наличии отношения R ⊆ X × Y отношение R–1 ⊆ Y × X определя- ется как {(x, y)|(y, x) ∈ R}. Для R ⊆ X × X R ⋃ R–1 является симметричным замыкани- ем R. Задача 9.39. Докажите теорему 9.38. См. рис. 9.5 с примером транзитивного замыкания. Рис. 9.4  Пример симметричного замыкания: без пунктирной линии эта диаграмма представляет несимметричное отношение; с пунк тирными линиями оно симметрично Рис. 9.5  Пример транзитивного замыкания: без пунктирной ли- нии эта диаграмма представляет отношение, которое не является транзитивным; с пунктирными линиями оно – транзитивно Теорема 9.40. R+ := ⋃∞ i=1 Ri является транзитивным замыканием R. Доказательство. Мы проверяем, что R+ имеет три условия, приведенных в (9.8). Во-первых, мы проверяем, имеет ли R+ данное свойство, то есть является ли оно транзитивным: xR+y ∧ yR+z ⇔ ∃m, n ≥ 1, xRmy ∧ yRnz ⇒ ∃m, n ≥ 1, x(Rm ∘ Rn)z ⇔ ∃m, n ≥ 1, xRm+nz ⇔ xR+z. Таким образом, R+ является транзитивным. Во-вторых, мы проверяем, что R ⊆ R+ – это следует из определения R+. Мы про- веряем последнее условие. Предположим, что S является транзитивным и R ⊆ S. Поскольку S является транзитивным, то по теореме 9.34 Sn ⊆ S для n ≥ 1, то есть S+ ⊆ S, и поскольку R ⊆ S, то R+ ⊆ S+, поэтому R+ ⊆ S. Задача 9.41. Обратите внимание, что когда в доказательстве теоремы 9.40 мы показываем, что R+ само является транзитивным, вторая строка, помеченная зна- ком (†), является импликацией, а не эквивалентностью, как другие строки. Поче- му она не является эквивалентностью? Теорема 9.42. R* = ⋃∞ i=1 Ri является рефлексивным и транзитивным замыканием R. Доказательство. R * = R+ ⋃ idX. □(†)\n--- Страница 221 ---\n220  Математическая основа 9.3.2. Отношение эквивалентности Пусть X равно множеству, и пусть I равно индексному множеству. Семейство мно- жеств {Ai|i ∈ I } называется разбиением X тогда и только тогда, когда 1) ∀i, Ai ≠ ∅; 2) ∀i ≠ j, Ai ⋂ Aj = ∅; 3) X = ⋃i∈I Ai. Обратите внимание, что X = ⋃x∈X{x} – это мельчайшее возможное разбиение, то есть множество всех одноэлементных множеств. Отношение R ⊆ X × X называется отношением эквивалентности тогда и только тогда, когда 1) R является рефлексивным; 2) R является симметричным; 3) R является транзитивным. Например, если x, y являются строками над {0,1} *, то отношение, задаваемое R = {(x, y)|длина(x) = длина(y)}, является отношением эквивалентности. Еще одним примером является xRy ⇔ х = y, то есть отношение равенства является отноше- нием эквивалентности в полном смысле слова. Еще один пример: R = {(a, b)|a ≡ b (mod m)} является отношением эквивалентности (где «≡» – это отношение конгру - энтности, определенное на стр. 213). Теорема 9.43. Рассмотрим отношение эквивалентности. Тогда следующее соблю- дается: 1) a ∈ [a]; 2) a ≡ b ⇔ [a] = [b]; 3) a ≢ b, значит, [a] ⋂ [b] = ∅; 4) любые два класса эквивалентности либо равны, либо не пересекаются. Теорема 9.44. Пусть F : X → X равно любой тотальной функции (то есть функции, определенной на всех ее входах). Тогда отношение R на X, определенное как xRy F(x) ⇔ F(y), является отношением эквивалентности.Задача 9.45. Докажите теорему 9.44. Пусть R равно отношению эквивалентности на X. Для каждого x ∈ X множество [x] R = {y |xRy} является классом эквивалентности x по отношению к R. Теорема 9.46. Пусть R ⊆ X × X равно отношению эквивалентности. Следующие отношения эквивалентны: 1) aRb; 2) [a] = [b]; 3) [a] ⋂ [b] ≠ ∅. Доказательство. (1) ⇒ (2) Предположим, что aRb, и пусть c ∈ [a]. Тогда aRc, поэтому cRa (по симметрии). Поскольку cRa ∧ aRb, cRb (транзитивность), то bRc (симмет - рия), поэтому с ∈ [b]. Следовательно, [a] ⊆ [b], и схожим образом [b] ⊆ [а]. (2) ⇒ (3) очевидно, поскольку [a] непустое, так как a ∈ [a]. (3) ⇒ (1) пусть c ∈ [a] ⋂ [b], тогда aRc и bRc , поэтому по симметрии aRc ∧ cRb. И поэтому по транзитивности aRb. □ Следствие 9.47. Если R является отношением эквивалентности, то (a, b) ∉ R тогда и только тогда, когда [a] ⋂ [b] = ∅.\n--- Страница 222 ---\nОтношения  221 Для каждого отношения эквивалентности R ⊆ X × X пусть X/R обозначает мно- жество всех классов эквивалентности множества R. Теорема 9.48. Х/R является разбиением множества Х. Доказательство. С учетом теоремы 9.46 единственное, что еще предстоит дока- зать, – это что Х = ⋃A∈X/R А. Поскольку каждое А = [а] для некоторого а ∈ Х, из этого следует, что ⋃A∈X/R А = ⋃a∈X[а] = Х. □ Пусть R1, R2 равны отношениям эквивалентности. Если R1 ⊆ R2, то мы говорим, что R1 является детализацией R2. Лемма 9.49. Если R1 есть уточнение R2, то [a]R1 ⊆ [a]R2 для всех а ∈ X. Если Х/R является конечным, то индекс(R) := | Х/R|, то есть индекс R (в X) явля- ется размером Х/R.Теорема 9.50. Если R 1 ⊆ R2, то индекс(R1) ≥ индекс(R2). Задача 9.51. Докажите теорему 9.50. 9.3.3. Частичные порядки В этом разделе, вместо того чтобы использовать R для представления отношения над множеством X, мы будем использовать разные варианты неравенства: (X, ≼), (X, ⊑), (X, ≤). Отношение ≼ над X, где ≼⊆ X × X, называется частичным порядком, или частич- но упорядоченным множеством, если оно: 1) рефлексивно; 2) антисимметрично; 3) транзитивно. Отношение «≺» (где ≺⊆ X × X) является четким частичным порядком, если оно: 1) x ≺ y ⇒ ¬(y ≺ x); 2) транзитивное. Эти два стандартных отношения, «≼» и «≺», естественным образом связаны в следующей далее теореме.Теорема 9.52. Отношение ≼, определенное как x ≼ y ⇔ х ≺ y ∨ x = y, является час - тичным порядком. То есть с учетом четкого частичного порядка «≺» мы можем распространить его на частичный порядок «≼» с помощью стандартного символа равенства «=». Пусть (X, ≼) равно частичному порядку. Мы говорим, что x, y сравнимы, если x ≼ y или y ≼ x. В противном случае они несравнимы. Пусть x ~ y сокращенно обо- значают, что x и y несравнимы, то есть х ~ y ⇔ ¬(x ≼ y) ∧ ¬(y ≼ x). В общем случае для каждой пары x, y только одно из следующего является истинным: x ≺ y, y ≺ x, x = y, x ~ y. Разумеется, в контексте частичных порядков, представленных символом «≼», смысл символа «≺» выглядит следующим образом: x ≺ y ⇔ x ≼ y ∧ x ≠ y. Частичный порядок (X, ≼) является полным (тотальным) , или линейным, если все x, y сравнимы, то есть ~= ∅. Вот несколько примеров частичных порядков: если\n--- Страница 223 ---\n222  Математическая основа X является множеством, то (P(X), ⊆) – это частично упорядоченное множество. Например, если X = {1, 2, 3}, то представление в виде диаграммы Хассе этого час - тично упорядоченного множества будет таким, как показано на рис. 9.6. {1, 2, 3} {1, 3} {2} ∅{2, 3} {3}{1, 2} {1} Рис. 9.6  Представление в виде диаграммы Хассе частично упоря- доченного множества ({1, 2, 3}, ⊆). Диаграммы Хассе являются тран- зитивными редукциями – вытекающие из транзитивности отноше- ния не включены Пусть �+ равно множеству натуральных чисел, и пусть a|b равно отношению «a делит b» (которое мы определяем на стр. 213). Тогда (�+, |) является частичным порядком. Если (X1, ≼1), (X2, ≼2) являются двумя частичными порядками, то покомпонент - ный порядок (X1 × X2, ≼C) определяется следующим образом: (x1, x2) ≼ (y1, y2) ⇔ x1 ≼1 y1 ∧ x2 ≼2 y2, и он тоже является частичным порядком. Лексикографический порядок (X1 × X2, ≼L) определяется следующим образом: (x1, x2) ≼L (y1, y2) ⇔ (x1 ≼1 y1) ∨ (x1 = y1 ∧ x2 ≼2 y2). Наконец, (X, ≼) является стратифицированным порядком тогда и только тогда, когда (X, ≼) является частичным порядком, и, более того, (x ∼ y ∧ y ∼ z) ⇒ (x ∼ z ∨ x = z). Определим a ≈ b ⇔ a ∼ b ∨ a = b. Теорема 9.53. Частичный порядок (X, ≼) является стратифицированным поряд- ком тогда и только тогда, когда ≈ = ∼ ⋃ idX является отношением эквивалентности. В математике номенклатура может быть для читателей величайшим бичом. Строка символов «≈ = ∼ ⋃ idX» представляет собой отличный пример запутывания; как ее понять? Действительно, она очень лаконична, но для ее прочтения требует - ся практика. Здесь мы говорим, что порядок, который мы назвали «≈», на самом деле равен порядку, который мы получаем, взяв объединение порядка «~» и « idX». Задача 9.54. Докажите теорему 9.53. Теорема 9.55. Частичный порядок (X, ≼) является стратифицированным поряд- ком тогда и только тогда, когда существует полный порядок (Т, ≼T) и функция f : Х → Т такая, что f раскрывает и f представляет собой «порядковый гомомор- физм», то есть а ≼ b ⇔ f(a) ≼T f(b).\n--- Страница 224 ---\nОтношения  223 Задача 9.56. Докажите теорему 9.55. 9.3.4. Решетки Пусть (X, ≼) равно частичному порядку, и пусть А ⊆ X равно некоторому подмно- жеству, и a ∈ X. Тогда: 1) a является минимальным в X, если ∀x ∈ X, ¬(x ≺ a); 2) a является максимальным в X, если ∀x ∈ X, ¬(a ≺ x); 3) a является наименьшим элементом в X, если ∀x ∈ X, a ≼ x; 4) a является наибольшим элементом в X, если ∀x ∈ X, x ≼ a; 5) а является верхней границей А, если ∀x ∈ A, x ≼ a; 6) а является нижней границей А, если ∀x ∈ A, a ≼ x; 7) a является наименьшей верхней границей (супремумом) A, обозначаемой sup(A), если a) ∀x ∈ A, x ≼ a, б) ∀b ∈ X, ( ∀x ∈ A, x ≼ b) ⇒ a ≼ b; 8) а является наибольшей нижней границей (инфимуммом) А, обозначаемой inf(а), если a) ∀x ∈ A, a ≼ x, б) ∀b ∈ X, ( ∀x ∈ A, b ≼ x) ⇒ b ≼ a. Задача 9.57. Следует отметить, что в определениях 1–8 (в англоязычном ори- гинале текста) мы иногда используем определенный артикль «the», а иногда не- определенный артикль «a». В первом случае он подразумевает уникальность, во втором – наличие нескольких кандидатов. Убедитесь в уникальности, где это применимо, и приведите пример частичного порядка, где есть несколько кан-дидатов для данного элемента в других случаях. Наконец, важно отметить, что sup(A), inf(A) могут существовать или не существовать; приведите примеры, ког - да их не существует. Частичный порядок (X, ≼) является вполне упорядоченным множеством, если он является полным порядком и для каждого А ⊆ X, такого что A ≠ ∅, A, имеет наи- меньший элемент. Частичный порядок является плотным, если ∀x и y, если х < y, то ∃z, x < z < y. На - пример, (�, ≤) со стандартным определением для «≤» является полным плотным порядком, но он не является вполне упорядоченным множеством; например, ин-тервал (2, 3], который соответствует подмножеству �, состоящему из x, таких что 2 < х ≤ 3, не имеет наименьшего элемента. Частичный порядок (X, ≼) является решеткой, если ∀a, b ∈ X, то обе операции, inf({А, B}) и sup({А, B}), существуют в X. Например, каждый полный порядок явля- ется решеткой, и (P(X), ⊆) является решеткой для каждого ≼. Этот последний при- мер обусловливает следующую форму записи: a ⊔ b := sup({a, b}) и a ⊓ b := inf({a, b}). Задача 9.58. Докажите, что для решетки (P(X), ⊆) мы имеем: A ⊔ B = A ⋃ B; A ⊓ B = A ⋂ B. Не каждый частичный порядок является решеткой; рис. 9.7 дает простой при- мер.\n--- Страница 225 ---\n224  Математическая основа a c e fb d Рис. 9.7  Пример частичного порядка, который не яв- ляется решеткой. В отличие от inf({b, c}) = a и sup({d, e}) = f, супремума {b, с} не существует Теорема 9.59. Пусть (X, ≼) равно решетке. Тогда ∀a, b ∈ X, a ≼ b ⇔ a ⊓ b = a ⇔ a ⊔ b = b. Задача 9.60. Докажите теорему 9.59. Теорема 9.61. Пусть (X, ≼) равно решетке. Тогда следующее соблюдается для всех a, b, c ∈ Х: 1) a ⊔ b = b ⊔ a и a ⊓ b = b ⊓ a (коммутативность); 2) a ⊔ (b ⊔ c) = (a ⊔ b) ⊔ c и a ⊓ (b ⊓ c) = (a ⊓ b) ⊓ c (ассоциативность); 3) a ⊔ a = a и a ⊓ a = a (идемпотентность); 4) a = a ⊔ (a ⊓ b) и a = a ⊓ (a ⊔ b) (поглощение). Задача 9.62. Докажите свойства, перечисленные в качестве теоремы 9.61. Решетка (X, ≼) является полной тогда и только тогда, когда ∀A ⊆ X, sup(A), inf(A) обе существуют. Обозначим ⊥ = inf(X) и ⊤ = sup(X). Теорема 9.63. (P(х), ≼) является полной решеткой, и следующее соблюдается: ∀ ⊆ P(X), sup() = ⋃A∉  и inf() = ⋃A∉ , и ⊥ = ∅ и ⊤ = X. Задача 9.64. Докажите теорему 9.63. Теорема 9.65. Каждая конечная решетка является полной. Доказательство. Пусть А = {a1, , an}. Определим b = a1 ⊓ … ⊓ an (где скобки ассоци- ированы справа). Тогда b = inf(A). Та же идея для супремума. □ 9.3.5. Т еория неподвижных точек Предположим, что F – это функция, и рассмотрим уравнение x→ = F(x→). Решение a→ этого уравнения является неподвижной точкой F. Пусть (X, ≼) и ( Y, ⊑) равны двум множествам. Функция f : Х → Y является монотон- ной тогда и только тогда, когда ∀x, y ∈ X, x ≼ y ⇒ f(x) ⊑ f(y). Например, fB : P(X) → P(X), где B ⊆ X, определенное ∀x ⊆ X функцией fB(x) = B – x, не является монотонной. С другой стороны, gB(x) = B ⋃ x и hB(x) = B ⋂ x обе являются монотонными. Пусть (X, x→) равно частичному порядку, и пусть f : Х → Х. Значение х0 ∈ Х такое, что х0 = f(x0) является, как мы видели, неподвижной точкой f. Неподвижная точка\n--- Страница 226 ---\nОтношения  225 может не существовать, например fB в предыдущем абзаце не имеет неподвижной точки при B ≠ 0, поскольку в таком случае уравнение х = B – x не имеет решения. Также может существовать много неподвижных точек; например, f(x) = x имеет |X| число неподвижных точек. Теорема 9.66 (Кнастера–Тарского (1)). Пусть (X, ≼) равно полной решетке, и пусть f : X → X равна монотонной функции. Тогда наименьшая неподвижная точка f существует и равна inf({x |f(x) ≼ x}). Доказательство. Пусть x0 = inf({x |f(x) ≼ x}). Сначала покажем, что x0 = f(x0). Пусть B = {x|f(x) ≼ x}, и обратите внимание, что B = ∅, поскольку ⊤ = sup(X) ∈ B. Пусть x ∈ B, поэтому мы имеем x0 ≼ x, отсюда, поскольку f является монотонной, f(x0) ≼ f(x), то есть f(x0) ≼ f(x) ≼ x. Это верно для каждого x в B, поэтому f(x0) является нижней границей для B, и по - скольку x0 является наибольшей нижней границей B, из этого следует, что f(x0) ≼ x0. Поскольку f монотонна, из этого следует, что f(f(x0)) ≼ f(x0), а значит, f(x0) нахо- дится в B. Но тогда x0 ≼ f(x0), а значит, x0 = f(x0). Остается показать, что x0 является наименьшей неподвижной точкой. Пусть x′ = f(х′). Это означает, что f(x′) ≼ x′, то есть x′ ∈ B. Но тогда x0 ≼ x′. □ Теорема 9.67 (Кнастера–Тарского (2)). Пусть (X, ≼) равно полной решетке, и пусть f : X → X равно монотонной функции. Тогда существует наибольшая не- подвижная точка уравнения x = f(x), и она равна sup({x |f(x) ≼ x}). Обратите внимание, что эти теоремы не являются конструктивными, но в слу - чае конечного X существует конструктивный способ нахождения наименьшей и наибольшей неподвижных точек.Теорема 9.68 (Кнастера–Тарского: конечные множества). Пусть (X, ≼) равно решетке, |X| = m, f : Х → Х равно монотонной функции. Тогда f m(⊥) равно наимень- шей неподвижной точке, и fm(⊤) равно наибольшей неподвижной точке. Доказательство. Так как |Х| = m, ( Х, ≼) является полной решеткой, ⊥ = inf(X) и ⊤ = sup(X) обе существуют. Поскольку f является монотонной, и ⊥ ≼ f(⊥), мы имеем f(⊥) ≼ f(f(⊥)), то есть f(⊥) ≼ f2(⊥). Продолжая применять монотонность, мы получаем: f0(⊥) = ⊥ ≼ f(⊥) ≼ f2(⊥) ≼ f3(⊥) ≼ ··· ≼ fi(⊥) ≼ fi+1(⊥) ≼ ···. Рассмотрим приведенную выше последовательность вплоть до fm(⊥). Она имеет длину (m + 1), но X имеет только m элементов, поэтому существует i < j таких, что fi(⊥) = fj(⊥). Поскольку ≼ является порядком, то из этого следует, что fi(⊥) = fi+1(⊥) = ··· = fj(⊥), поэтому x0 = fi(⊥) является неподвижной точкой, так как f(x0) = f( fi(⊥)) = fi+1(⊥) = fi(⊥) = x0. Ясно, что fj+1(⊥) = f(fj(⊥)) = f(x0) = x0, поэтому, по сути дела. ∀k ≥ i, x0 = fk(⊥), и, зна- чит, fm(⊥) = x0, поэтому fm(⊥) является неподвижной точкой.\n--- Страница 227 ---\n226  Математическая основа Теперь предположим, что x является еще одной неподвижной точкой f, то есть x = f(x). Поскольку ⊥ ≼ x и f является монотонной, мы заключаем, что f(⊥) ≼ f(x) = x, то есть f(⊥) ≼ x. Опять же, поскольку f монотонна, f(f(⊥)) ≼ f(x) = x, поэтому f2(⊥) ≼ x. Следовательно, повторяя эту процедуру достаточно много раз, мы получаем fi(⊥) ≼ x для каждого i, и поэтому мы получаем x0 = fm(⊥) ≼ x. Мы приводим аналогичную аргументацию для «наибольшего». □ Ситуация гораздо лучше для стандартной решетки (P(X), ⊆), если X является конечным множеством. Теорема 9.69. Пусть X равно конечному множеству, |X| = n, f : P(X) → P(X) является монотонной. Тогда fn+1(∅) – это наименьшая неподвижная точка и fn+1(X) – наи- большая неподвижная точка.Доказательство. Обратите внимание, что предыдущая теорема говорит, что f 2(∅) является наименьшей неподвижной точкой и f2(X) – наибольшей неподвижной точкой, так как |P(X)| = 2n, ⊥ = ∅ и ⊤ = X, для решетки (P(X), ⊆). Но эта теорема утверждает, что (n + 1) вместо 2n. Причина в том, что ∅ ⊆ f(∅) ⊆ f2(∅) ⊆ ··· ⊆ fn+1(∅) должно иметь два повторяющихся множества (так как |X| = n). □ Задача 9.70. Рассмотрите решетку (P({A, b, c}), ⊆), а также функции f(x) = x ⋃ {a, b} и g(x) = x ⋂ {a, b}. Вычислите их соответствующие наименьшие/наибольшие не- подвижные точки. Пусть (X, ≼) равно полной решетке. Функция f : X → X называется: 1) восходяще-непрерывной тогда и только тогда, когда ∀A ⊆ X, f(sup(A)) = sup(f(A)); 2) нисходяще-непрерывной тогда и только тогда, когда ∀A ⊆ X, f(inf(A)) = inf(f(A)); 3) непрерывной, если она является и восходяще-, и нисходяще-непрерывной. Лемма 9.71. Если f : X → X является восходяще-(нисходяще-)непрерывной, то, значит, она является монотонной.Доказательство. Пусть f является восходяще-непрерывной и x ≼ y, значит, x = inf({x, y}) и y = sup({x, y}) и f(x) ≼ sup({f(x), f(y)}) = sup(f({x, y})) = f(sup({x, y})) = f(y). Аналогичный аргумент для нисходяще-непрерывной. □ a a⊥ ⊥ ⊤ ⊤b b Рис. 9.8  Пример упорядочения над X = {a, b, ⊥, ⊤} функцией f : X → X, обозначенного пунктирными линиями. То есть f(⊥) = ⊤ и f(a) = f(b) = f(⊤) = ⊤. Путем непосредственной проверки может быть установлено, что f является монотонной, но она не является нисхо- дяще-непрерывной\n--- Страница 228 ---\nОтношения  227 Задача 9.72. Покажите, что функция f на рис. 9.8 не является восходяще-непре- рывной. Приведите пример монотонной функции g, которая не является ни вос - ходяще-, ни нисходяще-непрерывной. Теорема 9.73 (Клини). Если (Х, ≼) является полной решеткой, f : Х → X является восходяще-непрерывной функцией, тогда х0 = sup({ fn(⊥)|n = 1, 2, …}) является наи- меньшей неподвижной точкой f.Доказательство. Обратите внимание, что ⊥ ≼ f(⊥), поэтому по монотонности функции f мы имеем, что ⊥ ≼ f(⊥) ≼ f 2(⊥) ≼ f3(⊥) ≼ ··· (9.10) и f(x0) = f(sup({ fn(⊥)|n = 1, 2, })), и так как f является восходяще-непрерывной = sup( f({fn(⊥)|n = 1, 2, })) = sup({ fn+1(⊥)|n = 1, 2, }) и по (9.10) = sup({ fn(⊥)|n = 1, 2, }) = x0, то f(х0) = х0, то есть х0 является неподвижной точкой. Пусть x = f(x). Мы имеем ⊥ ≼ X и f является монотонной, поэтому f(⊥) ≼ f(х) = х, то есть f(⊥) ≼ Х, f2(⊥) ≼ f(х) = х, и т. д., то есть fn(⊥) ≼ x для всех n, поэтому по опре- делению sup: x0 = sup({ fn(⊥)|n = 1, 2, }) ≼ x, таким образом, x0 является наименее неподвижной точкой. □ 9.3.6. Рекурсия и неподвижные точки До сих пор мы доказывали правильность циклов while и for, но есть и другой спо- соб «организации циклов» с использованием рекурсивных процедур, то есть алго- ритмов, которые «вызывают самих себя». Примеры таких алгоритмов мы увидим в главе, посвященной методу «разделяй и властвуй». Существует робастная теория правильности рекурсивных алгоритмов, основан- ная на теории неподвижных точек, в частности на теореме Клини (теорема 9.73). Мы кратко проиллюстрируем этот подход на примере. Рассмотрим рекурсивный алгоритм 9.1. Алгоритм 9.1. F(x, y) 1: if x = y then 2: return y + 1 3: else4: F(x, F(x – 1, y + 1)) 5: end if\n--- Страница 229 ---\n228  Математическая основа Для того чтобы увидеть, как работает этот алгоритм, рассмотрим вычисление F(4, 2). Сначала в строке 1 констатируется, что 4 ≠ 2, и поэтому мы должны вы- числить F(4, F(3, 3)). Мы сначала рекурсивно вычисляем F(3, 3), поэтому в строке 1 теперь констатируется, что 3 = 3, и поэтому в строке 2 y устанавливается равным 4, и это является возвращаемым значением, то есть F(3, 3) = 4, поэтому теперь мы можем вернуться и вычислить F(4, F(3, 3)) = F(4, 4), тем самым в строке 1 мы опять рекурсивно констатируем, что 4 = 4, и поэтому в строке 2 y устанавливается равным 5, а это является возвращаемым значением, то есть F(4, 2) = 5. С другой стороны, легко заметить, что F(3, 5) = F(3, F(2, 6)) = F(3, F(2, F(1, 7))) = ···, и эта процедура никогда не заканчивается, так как x никогда не будет равен у. Таким образом, F не является тотальной функцией, то есть она не определена на всех (х, y) ∈ � × �. Задача 9.74. Какова область определения F, вычисляемой алгоритмом 9.1? То есть область F равна � × �, тогда как область определения является наибольшим подмножеством S ⊆ � × � таким, что F определена для всех (х, y) ∈ S. Мы уже увиде- ли, что (4, 2) ∈ S, тогда как (3, 5) ∉ S. Теперь мы рассмотрим три разные функции, все заданные алгоритмами, кото- рые не являются рекурсивными: алгоритмы 9.2, 9.3 и 9.4, вычисляющие соответ - ственно функции f1, f2 и f3. Функция f1 имеет интересное свойство: если бы мы заменили F в алгоритме 9.1 на f1, то мы бы вернули F. Другими словами, при наличии алгоритма 9.1, если бы мы заменили строку 4 на f1(x, f1(x – 1, y + 1)) и вычисляли f1 с помощью(нерекурсивного) алгоритма 9.2 для f1, то измененный таким образом алгоритм 9.1 теперь вычислял бы F(x, y). Поэтому мы говорим, что функция f1 является фиксированной точкой рекурсивного алгоритма 9.1. Алгоритм 9.2. f1(x, y) if x = y then return y + 1 else return x + 1 end if Например, вспомните, что мы уже показали, что F(4, 2) = 5, используя ре- курсивный алгоритм 9.1 для вычисления F. Заменим строку 4 алгоритма 9.1 на f 1(х, f1(х – 1, y + 1)) и вычисим F(4, 2) заново; поскольку 4 ≠ 2, перейдем непосред- ственно к строке 4, где мы вычисляем f1(4, f1(3, 3)) = f1(4, 4) = 5. Обратите внимание, что это последнее вычисление не было рекурсивным, так как мы вычислили f1 непосредственно с помощью алгоритма 9.2, и что мы получили то же самое зна- чение. Рассмотрим теперь f2, f3, вычисляемые соответственно алгоритмами 9.3, 9.4.\n--- Страница 230 ---\nЛогика  229 Алгоритм 9.3. f2(x, y) if x ≥ y then return x + 1 else return y – 1 end if Алгоритм 9.4. f3(x, y) if x ≥ y ∧ (x – y является четным) then return x + 1 end if Обратите внимание, что если в алгоритме 9.4 не имеет место случай, что x ≥ y и x – y не является четным, то результат не определен. Таким образом, f3 является частичной функцией, и если x < y или x – y не является четным, то (x, y) не находит - ся в ее области определения. Задача 9.75. Докажите, что f1, f2, f3 являются неподвижными точками алгорит - ма 9.1. Функция f3 имеет одно дополнительное свойство. Для каждой пары целых чисел x, y таких, что f3(x, y) определена, то есть x ≥ y и x – y является четным, обе функции f1(x, y) и f2(x, y) также определены и имеют то же значение, что и f3(x, y). Мы говорим, что f3 менее определена или равна f1 и f2, и пишем f3 ⊑ f1 и f3 ⊑ f2; то есть мы опре- делили (неформально) частичный порядок на функциях f : � × � → � × �. Задача 9.76. Покажите, что f3 ⊑ f1 и f3 ⊑ f2. Напомним понятие области определе- ния, введенное в задаче 9.74. Пусть S1, S2, S3 равны областям определения соответ - ственно f1, f2, f3. Вы должны показать, что S3 ⊆ S1 и S3 ⊆ S2. Можно показать, что f3 обладает этим свойством не только по отношению к f1 и f2, но и по отношению ко всем неподвижным точкам алгоритма 9.1. Кроме того, f3(x, y) является единственной функцией, имеющей это свойство, и поэтому f3 счи - тается наименьшей (определенной) неподвижной точкой алгоритма 9.1. Важным применением теоремы Клини (теоремы 9.73) является то, что каждый рекурсив- ный алгоритм имеет единственную неподвижную точку. 9.4. логика Мы представим основы пропозициональной и предикатной логики с целью опре-деления арифметики Пеано. Арифметика Пеано является стандартной формали-зацией теории чисел, и она является логической основой для раздела 9.4.4 – фор-мальная верификация. Наше рассмотрение логики ограничено предоставлением этих общих сведений, но читатель может найти больше ресурсов в разделе при-мечаний.\n--- Страница 231 ---\n230  Математическая основа 9.4.1. Пропозициональная логика Пропозициональные (булевы) формулы строятся из пропозициональных (булевых) переменных1 p1, p2, p3, и логических связок ¬, ∧, ∨, перечисленных в предисловии на стр. 13. Для наших переменных мы часто используем различные метки (например, a, b, c, , x, y, z, , p, q, r, и т. п.) как «метапеременные», которые обозначают пере- менные, и мы определяем пропозициональные формулы по структурной индук - ции: любая переменная p является формулой, и если α, β – это формулы, то ими являются и ¬α, ( α ∧ β) и ( α ∨ β). Например, p, (p ∨ q), (¬(p ∧ q) ∧ (¬p ∨ ¬q)). Напомним также из предисловия, что → и ↔ являются соответственно связками импликации и эквивалентности. Задача 9.77. Определите пропозициональные формулы с помощью контекстно- свободной грамматики. Символ Вес ¬ ∧, ∨, ( ), р, для каждой переменной р01 –1 Рис. 9.9  Закрепление «весов» за символами Лемма 9.78. Закрепим веса за всеми символами, как показано на рис. 9.9. Вес любой формулы α равен –1, но вес надлежащего начального сегмента ≥ 0. Следо- вательно, никакой надлежащий начальный сегмент формулы не является фор- мулой. Доказательство. По структурной индукции на длине α. Базовый случай: w(p) = –1 для любой переменной p. Индукционный шаг имеет три случая: ¬α, ( α ∧ β) и ( α ∨ β). Это показывает, что любая хорошо сформированная формула имеет вес –1. Те- перь мы покажем, что любой надлежащий начальный сегмент имеет вес ≥ 0. В ба-зовом случае (единственная переменная p) начальные сегменты отсутствуют; на индукционном шаге предположим, что данное утверждение соблюдается для α и β (то есть любой начальный сегмент α и любой начальный сегмент β имеют вес ≥ 0). Тогда то же относится и к ¬α, так как любой начальный сегмент ¬α содержит ¬ (и w(¬) = 0) и некоторый (возможно, пустой) начальный сегмент α. □ Задача 9.79. Закончите детали доказательства леммы 9.78. Пусть α = syn α′ подчеркивает, что α и α′ равны как цепочка символов, то есть мы имеем не семантическое тождество, а синтаксическое тождество. Теорема 9.80 (теорема об уникальной читаемости). Предположим, что α, β, α′, β′ являются формулами, c, c′ являются бинарными связками и (αcβ) =syn (α′с ′β′). Тогда α =syn α′ и β =syn β′ и c =syn c′. 1 Пропозициональные переменные иногда называются атомами. Очень тщательное и, возможно, теперь рассматриваемое немного старомодным обсуждение «имен» в ло- гике (что такое «переменная», что такое «константа» и т. д.) можно найти в книге [Church (1996)], разделы 01 и 02.\n--- Страница 232 ---\nЛогика  231 Обратите внимание, что эта теорема говорит, что грамматика для генерирова- ния формул однозначна. Или, другими словами, она говорит, что существует толь- ко один кандидат на главную связку, то есть что дерево разбора любой формулы уникально. Напомним, что в задаче 9.11 сравнивались инфиксная, префиксная, постфиксная формы записи; булевы формулы даны в инфиксной форме записи в том смысле, что бинарные операторы (∧, ∨) помещаются между операндами, и все же оно однозначно (тогда как задача 9.11 говорит, что, для того чтобы одно-значно представить дерево, нам нужно два из трех представлений из списка {ин-фиксное, префиксное, постфиксное}). Разница в том, что в случае булевых формул у нас есть скобки для разделения подформул. Задача 9.81. Покажите, что теорема 9.80 является следствием леммы 9.78. (Под- сказка: определите вес формулы как сумму весов всех символов в ней.) Закрепление истинностного значения представляет собой отображение τ : {пе- ременные} → {T, F}. Здесь {T, F} означает «true» (истина) и «false» (ложь), иногда обозначаемые соответственно 0, 1. Закрепление истинностного значения τ может быть расширено для назначения T либо F каждой формуле следующим образом: (1) (¬α) τ = T тогда и только тогда, когда ατ = F; (2) (α ∧ β)τ = T тогда и только тогда, когда ατ = T и βτ = T; (3) (α ∨ β)τ = T тогда и только тогда, когда ατ = T или βτ = T. Ниже приведены стандартные определения: мы говорим, что закрепление ис - тинностного значения τ удовлетворяет формуле α, если ατ = Т, и τ удовлетворяет множеству формул Φ, если τ удовлетворяет всем α ∈ Φ. В свою очередь, множест - во формул Φ удовлетворимо, если некоторое τ удовлетворяет ему; в противном случае Φ неудовлетворимо. Мы говорим, что α является логическим следствием множества Φ, записываемого Φ ⊨ α, если τ удовлетворяет α для каждого τ такого, что τ удовлетворяет Φ. Формула α является валидной, если ⊨ α, то есть ατ = T для всех τ. Валидная пропозициональная формула называется тавтологией. α и β яв- ляются эквивалентными формулами (записываемыми α ⇔ β), если α ⊨ β и β ⊨ α. Обратите внимание, что знаки «⇔» и «↔» имеют разные смыслы: один является семантическим логическим утверждением, а другой – синтаксическим логиче-ским утверждением. При этом одно соблюдается тогда и только тогда, когда со-блюдается другое. Например, следующие утверждения являются тавтологиями: p ∨ ¬p, p → p, ¬(p ∧ ¬p). Экземпляр логического следствия: (p ∧ q) ⊨ (p ∨ q). Наконец, пример эквивалентности: ¬(p ∨ q) ⇔ (¬p ∧ ¬q). Это последнее формальное суждение на- зывается законом де Моргана. Задача 9.82. Покажите, что если Φ ⊨ α и Φ ⋃ {α} ⊨ β, то Φ ⊨ β. Задача 9.83. Докажите следующую теорему о двойственности: пусть α′ равно ре- зультату взаимной замены ∨ и ∧ в α и замены p на ¬p для каждой переменной p. Тогда ¬α ⇔ α′. Задача 9.84. Докажите теорему об интерполяции Крейга: пусть α и β равны лю- бым двум пропозициональным формулам. Пусть Var(α) равно множеству пере- менных, которые встречаются в α. Пусть S = Var(α) ⋂ Var(β). Предположим, что S не пустое. Если A → B является валидным, то существует формула C такая, что\n--- Страница 233 ---\n232  Математическая основа Var(C) = S, называемая «интерполянтом», такая, что A → C и C → B обе являются валидными. Один из способов констатировать, что формула α с n переменными является тавтологией, состоит в верифицировании, что ατ = T для всех 2n закреплений ис - тинностных значений τ за переменными α. Подобный исчерпывающий метод может использоваться для верификации, что Φ ⊨ α (если Φ является конечным). Еще один способ – использовать понятие формального доказательства; ниже мы представим систему доказательств на основе пропозиционального исчис - ления PK (propositional kalkul), существующую благодаря немецкому логику Гентцену. В провозициональной секвенциальной системе исчисления PK каждая строка в доказательстве является секвенцией вида: S = α 1, , αk → β1, , βl, где → – это новый символ и α1, , αk и β1, …, βl – последовательности формул (k, l ≥ 0), именуемые цедентами (соответственно антецедент и сукцедент). Закрепление истинностного значения τ удовлетворяет секвенции S тогда и толь- ко тогда, когда τ фальсифицирует некоторую αi или τ удовлетворяет некоторую βi, то есть тогда и только тогда, когда τ удовлетворяет формуле: αS = (α1 ∧ ··· ∧ αk) → (β1 ∨ ··· ∨ βl). Если антецедент является пустым, то → α эквивалентно α, и если сукцедент является пустым, то α → эквивалентно ¬α . Если оба цедента – антецедент и сук - цедент – являются пустыми, то → является ложным (является неудовлетвори- мым). У нас есть аналогичные определения валидности и логического следствия для секвенций. Например, приведем следующие валидные секвенции: α → α, → α, ¬α, α ∧ ¬α →. Формальным доказательством в пропозициональном исчислении PK являет - ся конечное корневое дерево, в котором узлы помечены секвенциями. Секвенция в корне (внизу) – это то, что доказывается: конечная секвенция (endsequent). Секвен- ции в листьях (вверху) – это логические аксиомы, и они должны иметь форму α → α, где α – это формула. Каждая секвенция, отличная от логических аксиом, должна вытекать из своей родительской секвенции (секвенций) по одному из правил ло-гического вывода, перечисленных на рис. 9.10. Задача 9.85. Приведите доказательства в пропозициональном исчислении PK для каждой из следующих валидных секвенций: ¬p ∨ ¬q → ¬(p ∨ q), ¬(p ∨ q) → ¬p ∧ ¬q и ¬p ∧ ¬q → ¬(p ∨ q), а также (p 1 ∧ (p2 ∧ (p3 ∧ p4))) → (((p1 ∧ p2) ∧ p3) ∧ p4). Задача 9.86. Покажите, что правила сокращения могут быть выведены из прави- ла усечения (с обменами и ослаблениями).Задача 9.87. Предположим, что мы допустили наличие ↔ как примитивной связ- ки вместо той, которая была введена по определению. Дайте соответствующие правила введения слева и справа для ↔.\n--- Страница 234 ---\nЛогика  233 Слабые структурные правила: Обмен влево:Γ1, α, β, Γ2 → Δ Γ1, β, α, Γ2 → ΔОбмен вправо:Γ → Δ1, α, β, Δ2 Γ → Δ1, β, α, Δ2 Сокращение вправо:Γ → Δ, α, α Γ → Δ, α Ослабление вправо:Γ → Δ Γ → Δ, αСокращение влево:Γ, α, α → Δ Γ, α → Δ Ослабление влево:Γ → Δ α, Γ → Δ Правило усечения: Γ → Δ, α α, Γ → Δ Γ → Δ Правила для введения связок: ¬-влево:Γ → Δ, α ¬α, Γ → Δ¬-вправо:α, Γ → Δ Γ → Δ, ¬α ∧-вправо:Γ → Δ, α Γ → Δ, β Γ → Δ, (α ∧ β) ∨-вправо:Γ → Δ, α, β Γ → Δ, (α ∨ β)∧-влево:α, β, Γ → Δ (α ∧ β), Γ → Δ ∨-влево:α, Γ → Δ β, Γ → Δ (α ∨ β), Γ → Δ Рис. 9.10  Правила пропозиционального исчисления PK. Обратите внимание, что Γ, Δ обозначают конечные секвенции формул Для каждого правила пропозиционального исчисления PK севенция внизу явля- ется логическим следствием секвенции (секвенций) вверху; назовем это принци- пом разумности правила. Например, в случае с ∨-вправом это может быть показа- но следующим образом: предположим, что τ удовлетворяет верхнюю секвенцию; предположим теперь, что оно удовлетворяет Г. Тогда, поскольку τ удовлетворяет верхнюю, оно должно удовлетворить одно из перечисленного: Δ, α или β. Если оно удовлетворяет Δ, то доказательство завершено; если оно удовлетворяет одно из α, β, то оно удовлетворяет α ∨ β, и доказательство также завершено. Задача 9.88. Проверьте принцип разумности правила: убедитесь, что каждое правило является разумным, то есть низ каждого правила является логическим следствием верха. Теорема 9.89 (о разумности пропозиционального исчисления PK). Каждая дока- зуемая в пропозициональном исчислении PK секвенция валидна.Доказательство. Покажем, что конечная секвенция в каждом доказательстве в пропозициональном исчислении PK валидна, по индукции на числе секвенций в доказательстве. В базовом случае доказательство представляет собой одну стро-ку; аксиома α → α, и она, очевидно, валидна. На индукционном шаге для каждого правила нужно только верифицировать, что если все верхние секвенции валидны, то нижняя секвенция валидна. Это вытекает из принципа разумности правила. □\n--- Страница 235 ---\n234  Математическая основа Следующий далее принцип называется принципом инверсии: для каждого пра- вила пропозиционального исчисления PK, за исключением ослабления, если ва- лидна нижняя секвенция, то валидны все верхние секвенции. Задача 9.90. Проверьте непосредственно каждое правило и докажите принцип инверсии. Приведем пример с ослабляющим правилом, для которого этот прин- цип не срабатывает. Теорема 9.91 (о полноте пропозиционального исчисления PK). Каждая ва- лидная пропозициональная секвенция доказуема в PK без использования усече- ния или сокращения. Доказательство. Покажем, что каждая валидная секвенция Γ → Δ имеет доказа- тельство в пропозициональном исчислении PK по индукции на суммарном числе связок ∧, ∨, ¬, встречающихся в Γ → Δ. Базовый случай: ноль связок, и поэтому каждая формула в Γ → Δ является пере- менной, а так как она является валидной, некая переменная p должна быть и в Γ, и в Δ. Следовательно, Γ → Δ может быть выведено из p → p за счет ослаблений и обменов. Индукционный шаг: предположим, что γ не является переменной в Γ или Δ. Тогда она имеет форму ¬α, ( α ∧ β), ( α ∨ β). Тогда Γ → Δ может быть выведено одним из правил введения связок с использованием обменов. Верхняя секвенция (секвенции) будет иметь на одну связку меньше, чем Γ → Δ, и будет валидна по принципу инверсии; следовательно, она имеет доказательства в пропозициональном исчислении PK по индукционной гипотезе. □ Задача 9.92. Каковы пять правил, которые не используются на индукционном шаге в приведенном выше доказательстве? Задача 9.93. Рассмотрите пропозициональное исчисление PK′, которое похоже на PK, но где аксиомы должны иметь форму p → p, то есть α должна быть перемен- ной в логических аксиомах. Является ли PK′ по-прежнему завершенным?Задача 9.94. Предположим, что {→ β 1, …, → βn} ⊨ Γ → Δ. Дайте доказательство в пропозициональном исчислении PK для Γ → Δ, где все листья являются либо ло- гическими аксиомами α → α, либо одной из нелогических аксиом → βi. (Подсказка: ваше доказательство потребует использования правила усечения.) Теперь приве- дем доказательство того, что при наличии конечного Ф такого, что Φ ⊨ Γ → Δ, существует доказательство PK для Γ → Δ, где все листья являются логическими аксиомами или секвенциями в Ф. Этим показывается, что PK также является им-пликационно завершенным. 9.4.1.1. Расширенное пропозициональное исчисление PK Существует естественное расширение системы импликационного исчисления PK в то, что называется расширенным PK (extended PK, EPK). Стандартный метод мате-матического доказательства состоит в возможности сокращения сложных формул, которые затем могут быть использованы в оставшейся части доказательства, вмес - то переписывания длинных формул всякий раз, когда они необходимы. Это можно проделывать на уровне пропозициональной логики, допуская аксиомы вида: p ↔ α,\n--- Страница 236 ---\nЛогика  235 где p – это новая переменная, которая еще не появлялась в доказательстве, и α – любая формула. Сила этой конструкции вытекает из вложенности этих определе- ний, то есть α может задействовать некоторые ранее определенные новые пере- менные. Задача 9.95. Покажите, что любое доказательство в пропозициональном исчис - лении EPK может быть переписано как доказательство в пропозициональном ис - числении PK. Что происходит в общем случае с размером нового доказательства в пропозициональном исчислении PK? Интересное наблюдение, выходящее за рамки этой книги, состоит в том, что, в отличие от пропозиционального исчисления PK, которое соответствует рассуж - дениям с булевыми формулами, расширенное пропозициональное исчисление EPK соответствует рассуждениям с булевыми схемами. См. работы [Cook и Nguyen (2010)], [Krajıcek (1995)] или [Cook и Soltys (1999)]. 9.4.2. Первопорядковая логика Первопорядковая логика, или логика первого порядка, также именуется преди-катным исчислением. Начнем с определения языка  = {f 1, f2, f3, , R1, R2, R3, }, равного множеству символов функций и отношений. Каждый символ функции и отношения имеет связанную с ним арность, то есть число аргументов, которые он принимает. -члены ( -термы) определяются по структурной индукции сле- дующим образом: каждая переменная является членом: x, y, z, , a, b, c, ; если f является символом n-арной функции и t 1, t2, , tn являются членами, то ими явля- ются и ft1t2 … tn. Символ 0-арной функции является константой (мы используем c и e в качестве метасимволов для констант). Например, если f является символом бинарной функции (с арностью 2) и G является символом унарной функции (с ар- ностью 1), то fgex, fxy, gfege являются членами. Задача 9.96. Покажите теорему об уникальной читаемости для членов. См. теоре- му 9.80, для того чтобы освежить свои знания по уникальной читаемости в про-позициональном случае. Например, язык арифметики, так называемая арифметика Пеано, задается язы- ком  A = [0, s, +, ·; =]. Вместо формальной префиксной формы записи для символов функций ·, + языка A мы используем инфиксную форму записи (определенную на стр. 234). То есть мы пишем (t1 · t2) вместо ·t1t2, и мы пишем (t1 + t2) вместо +t1t2. Например, приведем следующие A-члены: sss0, sss0, ((x + sy) · (ssz + s0)). Обрати- те внимание, что мы используем инфиксную форму записи со скобками, так как в противном случае форма записи была бы неоднозначной. Мы строим -формулы следующим образом:1) Rt 1t2 … tn – это атомарная формула, R – это символ n-арного предиката, t1, t2, , tn – это члены; 2) если α, β – это формулы, то ими являются и ¬α, ( α ∨ β), (α ∧ β); 3) если α – это формула и x – это переменная, то ∀xα и ∃xα также являются фор- мулами. Например, (¬∀xPx ∨ ∃x¬Px ), (∀x¬Qxy ∧ ¬∀zQfyz) являются первопорядковыми формулами.\n--- Страница 237 ---\n236  Математическая основа Задача 9.97. Покажите, что множество -формул может быть задано контекстно- свободной грамматикой. Мы также используем инфиксную форму записи с предикатом равенства; то есть мы пишем r = s вместо = rs и r ≠ s вместо ¬ = rs. Вхождение x в α ограничено, если оно находится в подформуле α в форме ∀xβ или ∃xβ (то есть в области действия квантификатора). В противном случае это вхождение свободно. Например, в ∃y(x = y + y) переменная x свободна, а y связана. В Px∧∀xQx переменная x появляется и как свободная, и как ограниченная. Член t или формула α замкнуты, если они не содержат свободных переменных. Замкну - тая формула называется сентенцией, или предложением. Теперь мы представим способ назначения смысла первопорядковым форму - лам: семантику Тарского; мы будем использовать стандартную терминологию и ссылаться на семантику Тарского как на основные семантические определения (basic semantic definitions, BSD). Структура (или интерпретация) придает смысл членам и формулам. -струк - тура M состоит из: 1) непустого множества M, именуемого универсумом дискурса; 2) для каждой n-арной f fM : Mn → M; 3) для каждого n-арного P PM ⊆ Mn. Если  содержит =, то =M должно быть обычным =. Таким образом, равенство является особым – оно всегда должно быть истинным равенством. С другой сторо- ны, <M может быть чем угодно, не обязательно отношением порядка, к которому мы привыкли. Каждая -сентенция становится либо истинной, либо ложной при интерпре- тации -структурой M. Если сентенция α становится истинной при M, то мы го- ворим, что M удовлетворяет α, или M является моделью для α, и пишем M ⊨ α. Если α имеет свободные переменные, то они должны получать значения из М (универсума дискурса), прежде чем α может получить истинностное значение при M. Закрепление значения за объектом, или объектное закрепление (object assign-ment) σ, для структуры M является отображением из переменных в универсум M. В данном контексте t M[σ] – это элемент в М, задаваемый структурой M и объ- ектным закреплением σ. M ⊨ α[σ] означает, что M удовлетворяет α, когда его свободным переменным назначаются значения посредством σ. Это должно быть определено очень тщательно; мы покажем, как вычислять tM[σ] по структурной индукции: 1) xM[σ] равно σ(x); 2) (ft1t2 tn)M[σ] равно fM(t1M[σ], t2M[σ], , tnM[σ]). Если x является переменной и m находится в универсуме дискурса, то есть m ∈ M, то σ(m/x) является тем же самым объектным закреплением, что и σ, за ис - ключением того, что x отображается в m. Теперь мы представим определение M ⊨ α[σ] по структурной индукции: 1) M ⊨ (Pt1 tn)[σ] тогда и только тогда, когда (t1M[σ], , tnM[σ]) ∈ PM; 2) M ⊨ ¬α[σ] тогда и только тогда, когда M ⊭ α[σ]; 3) M ⊨ (α ∧(∨)β)[σ] тогда и только тогда, когда M ⊨ α[σ] и(или) M ⊨ β[σ]; 4) M ⊨ (∀(∃) xα)[σ] тогда и только тогда, когда M ⊨ α[σ(m/x)] для всех (некото- рых) m ∈ M.\n--- Страница 238 ---\nЛогика  237 Если t замкнута, то мы пишем tM; если α является сентенцией, то мы пишем M ⊨ α. Например, пусть  = [; R, =] (R – бинарный предикат), и пусть M равно -струк - туре с универсумом � и такой, что (m, n) ∈ RM тогда и только тогда, когда m ≤ n. Тогда M ⊨ ∃x ∀yRxy, но M ⊭ ∃y ∀xRxy. Стандартная структура � для языка A имеет универсум M = �, s�(n) = n + 1 и 0, +, ·, = получают свои обычные смыслы на натуральных числах. Например, � ⊨ ∀x ∀y ∃z(x + z = y ∨ y + z = x), но � ⊭ ∀x ∃y(y + y = x). Мы говорим, что формула α удовлетворима тогда и только тогда, когда M ⊨ α[σ] для некоторого M & σ. Пусть Ф обозначает множество формул; тогда M ⊨ Φ[σ] тогда и только тогда, когда M ⊨ α[σ] для всех α ∈ Φ. Φ ⊨ α тогда и только тогда, ког - да ((∀M, σ), (M ⊨ Φ[σ] → M ⊨ α[σ]), то есть α является логическим следствием Ф. Мы говорим, что формула α является валидной и пишем ⊨ α тогда и только тогда, когда M ⊨ α[σ] для всех M & σ. Мы говорим, что α и β логически эквивалентны, и пишем α ⇔ β тогда и только тогда, когда для всех M & σ (M ⊨ α[σ] тогда и только тогда, когда M ⊨ β[σ]). Обратите внимание, что является символом «метаязыка» (русского), в отличие от ∧, ∨, ∃, …, которые являются символами первопорядковой логики. Кроме того, если Ф представляет собой всего одну формулу, то есть Φ = {β}, то мы пишем β ⊨ α вместо {β} ⊨ α. Задача 9.98. Покажите, что (∀xα ∨ ∀xβ) ⊨ ∀x(α ∨ β) для всех формул α и β. Задача 9.99. Имеет ли место, что ∀x(α ∨ β) ⊨ (∀xα ∨ ∀xβ)? Предположим, что t, u являются членами. Тогда: t(u/x) – результат замены всех вхождений x в t на u;  α(u/x) – результат замены всех свободных вхождений x в α на u. Семантически (u(t/x))M[σ] = uM[σ(m/x)], где m = tM[σ]. Например, пусть M равно � (стандартной структуре) для A. Предположим σ(x) = 5 и σ(y) = 7. Пусть: u равно члену x + у; t равно члену ss0. Тогда: u(t/x) равно ss0 + y и (u(t/x))�[σ] = 2 + 7 = 9. Схожим образом m = t� = 2, поэтому u�[σ(m/x)] = 2 + 7 = 9. Задача 9.100. Докажите, что (u(t/x))M[σ] = uM[σ(m/x)], где m = tM[σ], используя структурную индукцию на u.Задача 9.101. Применим ли результат задачи 9.100 к формулам α? То есть явля- ется ли истиной, что M ⊨ α(t/x)[σ] тогда и только тогда, когда M ⊨ α[σ(m/x)], где m = t M[σ]? Например, предположим, что α равно ∀y¬(x = y + y). Здесь написано «x является нечетным». Но α(x + y/x) равно ∀y¬(x + y = y + y), которое всегда ложно, независимо от значения σ(x). Задача в том, что y в члене x + y был «пойман» квантором ∀y. Член t свободно замещаем на х в α тогда и только тогда, когда нет ни одного свободного вхождения x в α в подформуле α формы ∀yβ или ∃yβ, где y входит в t.\n--- Страница 239 ---\n238  Математическая основа Теорема 9.102 (теорема о замещении). Если t свободно замещаем на х в α, то для всех структур M и всех объектных закреплений σ имеет место, что M ⊨ α(t/x)[σ] тогда и только тогда, когда M ⊨ α[σ(m/x)], где m = tM[σ]. Задача 9.103. Докажите теорему о замещении. (Подсказка. Используйте струк - турную индукцию на α и основные семантические определения.) Если член t не является свободно замещаемым на x в α, то причиной тому явля- ется то, что некая переменная y в t поймана квантификатором ∀y или ∃y в α. Один из способов это исправить состоит в простом переименовании «ограниченной» переменной y в α в некую новую переменную z. Это переименование не меняет смысл α. Пусть a, b, c, обозначают свободные переменные, и пусть x, y, z, обозначают ограниченные переменные. Первопорядковая формула α называется надлежащей формулой, если она удовлетворяет ограничению, что она не имеет ни одного сво-бодного вхождения любой «ограниченной» переменной и ни одного ограничен-ного вхождения любой «свободной» переменной. Схожим образом надлежащий член не имеет ни одной «ограниченной» переменной. Обратите внимание, что подформула надлежащей формулы не обязательно является надлежащей, и над-лежащая формула может содержать члены, которые не являются надлежащими. Секвенциальная система исчисления LK является расширением пропозицио- нальной системы исчисления PK, где теперь все формулы в секвенции α 1, , αk → β1, , βl должны быть надлежащими формулами. Пропозициональная система ис - числения LK является пропозициональной системой исчисления PK вместе с че-тырьмя правилами введения кванторов, приведенными на рис. 9.11. α(t), Γ → Δ ∀xα(x), Γ → ΔΓ → Δ, α(b) Γ → Δ, ∀xα(x) Γ → Δ, α(t) Γ → Δ, ∃xα(x)α(b), Γ → Δ ∃xα(x), Γ → ΔВведение ∀: Введение ∃: Рис. 9.11  Расширение исчисления PK до исчисления LK Существуют некоторые ограничения в использовании правил, приведенных на рис. 9.11. Во-первых, t – это надлежащий член, и α(t) (соответственно α(b)) – это результат замещения t (соответственно b) для всех свободных вхождений x в α(x). Обратите внимание, что t, b можно свободно заместить на x в α(х), поскольку ∀xα(x), ∃xα(x) имеют надлежащие формулы. Свободная переменная b не должна входить в заключение в ∀ справа и ∃ слева. Задача 9.104. Покажите, что четыре новых правила разумны. Задача 9.105. Приведите конкретный пример секвенции Γ → Δ,α(b), которая яв- ляется валидной, но нижняя секвенция Γ → Δ, ∀xα(x) не является валидной, по- скольку ограничение, накладываемое на b, нарушается (b входит в Γ, или Δ, или ∀xα(x)). Сделайте то же самое для ∃ слева. Доказательство в исчислении LK валидной первопорядковой секвенции может быть получено тем же методом, что и в пропозициональном случае. Напишите\n--- Страница 240 ---\nЛогика  239 целевую секвенцию внизу и двигайтесь вверх, используя правила введения в об- ратном порядке. Если есть выбор, какой квантификатор удалить следующим, выбирайте ∀ справа либо ∃ слева (продвигаясь назад), так как эти правила несут ограничение. 9.4.3. Арифметика Пеано Вспомним язык арифметики A = [0, s, +, ·; =]. Аксиомы для арифметики Пеано следующие: P1 ∀x(sx ≠ 0); P2 ∀x ∀y(sx = sy → x = y); P3 ∀x(x + 0 = x); P4 ∀x ∀y(x + sy = s(x + y)); P5 ∀x(x · 0 = 0); P6 ∀x ∀y(x · sy = x · y + x) плюс индукционная схема: ∀y 1 ∀yk[(α(0) → ∀x(α(x) → α(sx))) → ∀xα(x)], (9.11) где α – это любая A-формула, а (9.11) – сентенция. Обратите внимание, что это определение является формальным определением индукции, приведенным в разделе 9.1.1. У нас также есть схема аксиом равенства. E1 ∀x(x = x); E2 ∀x ∀y(x = y → y = x); E3 ∀x ∀y ∀z((x = y ∧ y = z) → x = z); E4 ∀x 1 ∀xn∀y1 ∀yn(x1 = y1 ∧ ··· ∧ xn = yn) → fx1 xn = fy1 yn; E5 ∀x1 ∀xn∀y1 ∀yn(x1 = y1 ∧ ··· ∧ xn = yn) → Px1 xn → Py1 yn, где E4 и E5 соблюдаются для всех n-арных функциональных и предикатных сим- волов. В A, который является интересуемым нас языком, s является унарным, +, · являются бинарными и = является бинарным. Пусть арифметика Пеано на основе исчисления LK равна системе исчисления LK, где листьям разрешено быть P1-6 и E1-5, помимо обычных аксиом α → α. На - пример, → ∀x(x = x) будет валидным листом. Задача 9.106. Покажите, что арифметика Пеано на основе LK доказывает, что все ненулевые элементы имеют предшественника.Задача 9.107. Покажите, что арифметика Пеано на основе LK доказывает следую- щее: ассоциативный и коммутативный закон сложения, ассоциативные и комму - тативные законы умножения и что умножение распределяется над сложением. Скрупулезно укажите, какие аксиомы вы используете. 9.4.4. Формальная верификация Доказательства правильности, которые мы приводили до этого, считаются «не-формальными» математическими доказательствами. Нет ничего плохого в не-формальном доказательстве, и во многих случаях такое доказательство – это все,\n--- Страница 241 ---\n240  Математическая основа что нужно для того, чтобы убедиться в валидности небольшого «фрагмента исход- ного кода». Вместе с тем существует ряд обстоятельств, когда требуется обширная формальная валидация исходного кода; в этом случае вместо неформального бу - мажно-карандашного типа аргументации мы часто используем компьютеризи-рованную верификацию программного обеспечения. Например, управление по контролю за продуктами и лекарствами США требует сертификации программ-ного обеспечения в тех случаях, когда медицинские устройства зависят от про-граммного обеспечения для их эффективной и безопасной работы. Когда требу - ется формальная верификация, все должно быть изложено четко, на формальном языке и кропотливо доказано строка за строкой. В этом разделе мы приведем пример такой процедуры. Пусть {α}P{β} означает, что если формула α истинна перед исполнением P, P исполняется и завершается, то формула β будет истинна, то есть α, β являются со- ответственно предусловием и постусловием программы P. Они обычно задаются в виде формул в некой формальной теории, такой как первопорядковая логика над некоторым языком . Мы исходим из допущения, что этим языком является арифметика Пеано; см. раздел 9.4. Используя конечное множество правил для верификации программ, мы хотим показать, что {α}P{β} соблюдается, и заключить, что программа правильна по от- ношению к спецификации α, β. Так как наш пример является небольшим, мы будем использовать ограниченное множество правил для верификации программ, при-веденное на рис. 9.12. {α}P{β} (β → γ) {α}P 1{β} {β}P2{γ} {α ∧ β}P1{γ} {α ∧ ¬β}P2{γ} {α ∧ β}P{α}(γ → α) { α}P{β} x := t{α}P{γ} {α}P1P2{γ} {α}, if β then P1 else P2{γ} {α} while β do P {α ∧ ¬β}{γ}P{β} {α(t)}x := t{α(x)}Следствие слева и справа Композиция и присвоение If While Рис. 9.12  Небольшое множество правил для верификации программы Правило «If» (если) гласит следующее: предположим, что имеет место, что {α ∧ β}P1{γ} и {α ∧ ¬β}P2{γ}. Это означает, что P1 является (частично) правильным по отношению к предусловию α ∧ β и постусловию γ, тогда как P2 является (час - тично) правильным по отношению к предусловию α ∧ ¬β и постусловию γ. Тогда\n--- Страница 242 ---\nЛогика  241 программа «if β when P1 else Р2» является (частично) правильной по отношению к предусловию α и постусловию γ, потому что если α соблюдается перед его ис - полнением, то либо β, либо ¬β должно быть истинным, и поэтому соответственно исполняется либо P1, либо Р2, в обоих случаях давая нам β. Правило «While» (до тех пор, пока) гласит следующее: предположим, что име- ет место {α ∧ β}P{α}. Это означает, что P является (частично) правильным по от - ношению к предусловию α ∧ β и постусловию α. Тогда программа «while β do P» является (частично) правильной по отношению к предусловию α и постусловию α ∧ ¬β, потому что если α соблюдается перед его исполнением, то либо β соблю- дается, в каковом случае цикл while исполняется еще раз, при этом соблюдается α ∧ β, и поэтому α по-прежнему соблюдается после исполнения P, либо β является ложным, в каковом случае β является истинным, и цикл завершается с α ∧ ¬β. В качестве примера мы верифицируем вычисление y = A · B. Обратите внима- ние, что в алгоритме 9.5, описывающем программу, которая вычисляет y = A · B, мы используем символ «=» вместо обычного «←», так как теперь мы доказываем правильность фактической программы, а не ее представление в псевдокоде. Алгоритм 9.5. mult(A,B) Предусловие: B ≥ 0 a = A; b = B;y = 0;while b > 0 do y = y + a; b = b – 1;end while Постусловие: y = A · B Мы хотим показать: {B ≥ 0} mult(A,B) {y = AB}. (9.12) Каждое прохождение по циклу while добавляет a в y, но a · b уменьшается на a, потому что b уменьшается на 1. Пусть инвариант цикла равен: (y + ( a · b) = A · B) ∧ b ≥ 0. Для того чтобы сэкономить пространство, запишем tu вместо t · u. Пусть t ≥ u является аббревиатурой A-формулы ∃x(t = u + x), и пусть t ≤ u является аббревиа- турой u ≥ t. 1 {y + a(b – 1) = AB ∧ (b – 1) ≥ 0} b=b-1; {y + ab = AB ∧ b ≥ 0} присвоение 2 {(y + a) + a(b – 1) = AB ∧ (b – 1) ≥ 0} y=y+a; {y + a(b – 1) = AB ∧ (b – 1) ≥ 0} присвоение3 (y + ab = AB ∧ b – 1 ≥ 0) → ((y + a) + a(b – 1) = AB ∧ b – 1 ≥ 0)теорема4 {y + ab = AB ∧ b – 1 ≥ 0} y=y+a; {y + a(b – 1) = AB ∧ b – 1 ≥ 0} следствие слева 2 и 35 {y + ab = AB ∧ b – 1 ≥ 0} y=y+a;b=b-1; {y + ab = AB ∧ b ≥ 0} композиция на 4 и 1\n--- Страница 243 ---\n242  Математическая основа 6 (y + ab = AB) ∧ b ≥ 0 ∧ b > 0 → (y + ab = AB) ∧ b – 1 ≥ 0 теорема7 {(y + ab = AB) ∧ b ≥ 0 ∧ b > 0} y=y+a; b=b-1; {y + ab = AB ∧ b ≥ 0} следствие слева 5 и 6 while (b>0) 8 {(y + ab = AB) ∧ b ≥ 0} y=y+a; {y + ab = AB ∧ b ≥ 0 ∧ ¬(b > 0)} b=b-1; while на 79 {(0 + ab = AB) ∧ b ≥ 0} y=0; {(y + ab = AB) ∧ b ≥ 0} присвоение 10 {(0 + ab = AB) ∧ b ≥ 0}y=0; while (b>0) y=y+a; b=b-1; {y + ab = AB ∧ b ≥ 0 ∧ ¬(b > 0)} композиция на 9 и 811 {(0 + aB = AB) ∧ B ≥ 0} b=B; {(0 + ab = AB) ∧ b ≥ 0} присвоение 12 {(0 + aB = AB) ∧ B ≥ 0} b=B; y=0;while (b>0) y=y+a; b=b-1; {y + ab = AB ∧ b ≥ 0 ∧ ¬(b > 0)} композиция на 11 и 1013 {(0 + AB = AB) ∧ B ≥ 0} a=A; {(0 + aB = AB) ∧ B ≥ 0} присвоение14 {(0 + AB = AB) ∧ B ≥ 0} mult(A,B) {y + ab = AB ∧ b ≥ 0 ∧ ¬(b > 0)} композиция на 13 и 1215 B ≥ 0 → ((0 + AB = AB) ∧ B ≥ 0)теорема16 (y + ab = AB ∧ b ≥ 0 ∧ ¬(b > 0)) → y = ABтеорема17 {B ≥ 0} mult(A,B) {y + ab = AB ∧ b ≥ 0 ∧ ¬(b > 0)} следствие слева на 15 и 1418 {B ≥ 0} mult(A,B) {y = AB} следствие справа на 16 и 17 Задача 9.108. Далее приведен скорее проект, чем упражнение. Дайте формаль- ные доказательства правильности алгоритма деления и алгоритма Евклида (ал-горитмы 1.1 и 1.2). Для того чтобы дать полное доказательство, вам нужно будет использовать арифметику Пеано, которая представляет собой формализацию тео рии чисел – именно то, что необходимо для этих двух алгоритмов. Подробно- сти арифметики Пеано приведены в разделе 9.4. 9.5. ответы к избранным зада Чам Задача 9.1. Ясно, что соблюдатся базовый случай: 1 + å0 j=0 2j = 1 + 1 = 20+1 (то есть P(0)). Для индукции предположим, что он соблюдается для некоторого n ∈ �; то есть 1 + ån j=0 2j = 2n+1. Тогда:\n--- Страница 244 ---\nОтветы к избранным задачам  243 1 + ån+1 j=0 2j = 2n+1 + 1 + ån j=0 2j. Здесь мы применяем индукционную гипотезу: = 2n+1 + 2n+1 = 2n+2. Мы показали, что P(0) истинно и, более того, что P(n) → P( n + 1). Следовательно, ∀mP(m). Задача 9.2. Базовый случай: n = 1, тогда 13 = 12. На индукционном шаге: (1 + 2 + 3 + ··· + n + (n + 1))2 = (1 + 2 + 3 + ··· + n)2 + 2(1 + 2 + 3 + ··· + n)(n + 1) + (n + 1)2, и по индукционной гипотезе: = (13 + 23 + 33 + ··· + n3) + 2(1 + 2 + 3 + ··· + n)(n + 1) + (n + 1)2 = (13 + 23 + 33 + ··· + n3) + 2n(n + 1) 2(n + 1) + (n + 1)2 = (13 + 23 + 33 + ··· + n3) + n(n + 1)2 + (n + 1)2 = (13 + 23 + 33 + ··· + n3) + (n + 1)3. Задача 9.3. Важно правильно истолковать постановку задачи: когда в ней го- ворится, что отсутствует одна клетка, это означает, что может отсутствовать лю- бая клетка. Таким образом, базовый случай: при заданной площади 2×2 клеток су ществует четыре возможных варианта отсутствия клетки; но в каждом случае оставшиеся клетки образуют букву «L». Эти четыре возможности показаны на рис. 9.13. Рис. 9.13  Четыре разные формы в виде буквы «L» Предположим, что утверждение соблюдается для n, и рассмотрим площадь размера 2n+1×2n+1 клеток. Разделим ее на четыре квадранта одинакового размера. Независимо от того, какая клетка по нашему выбору отсутствует, она будет нахо-диться в одном из четырех квадрантов; этот квадрант может быть заполнен фигу - рами «L» (то есть фигурами в форме, приведенной на рис. 9.13) по индукционной гипотезе. Что касается остальных трех квадрантов, поместим в них фигуру «L» таким образом, чтобы она охватывала все три квадранта («L» пересекает центр, оставаясь в этих трех квадрантах). Остальные клетки каждого квадранта теперь могут быть заполнены фигурами «L» по индукционной гипотезе. Задача 9.4. Поскольку ∀n(P(n) → P(n + 1)) → (∀n ≥ k)(P(n) → P(n + 1)), тогда (9.2) ⇒ (9.2′). С другой стороны, (9.2′) ⇏ (9.2). Задача 9.5. Базовый случай n = 1, и он является непосредственным. На индук - ционном шаге допустим, что равенство соблюдается для экспоненты n, и пока- жем, что оно соблюдается для экспоненты n + 1: 1 1 1 1 1 1= = . n 1 0 1 0 1 0fn+1 fn+1 + fn fn fn+1 fn fn + fn–1 fn–1 fn\n--- Страница 245 ---\n244  Математическая основа Крайне правая матрица может быть упрощена с использованием определения чисел Фибоначчи, как хотелось бы. Задача 9.7. m|n тогда и только тогда, когда n = km, поэтому покажем, что fm|fkm по индукции на k. Если k = 1, то доказывать нечего. В противном случае f(k+1)m = fkm+m. Теперь, используя отдельный индуктивный аргумент, покажем, что для y ≥ 1 fx+y = fy fx+1 + fy–1 fx, и закончим доказательство. Для того чтобы показать это послед- нее формальное суждение, пусть y = 1, и отметим, что fy fx+1 + fy–1 fx = f1 fx+1 + f0 fx = fx+1. Теперь допустим, что fx+y = fy fx+1 + fy–1 fx соблюдается. Рассмотрим: fx+(y+1) = f(x+y)+1 = f(x+y) + f(x+y)–1 = f(x+y) + fx+(y–1) = (fy fx+1 + fy–1 fx) + (fy–1 fx+1 + fy–2 fx) = fx+1(fy + fy–1) + fx(fy–1 + fy–2) = fx+1fy+1 + fx fy. Задача 9.8. Обратите внимание, что это явлется почти основной теоремой арифметики; чего не хватает, так это того факта, что до переупорядочения прос - тых чисел это представление является уникальным. Доказательство этому можно найти в разделе 9.2, теорема 9.18. Задача 9.9. Пусть наше логическое утверждение P(n) равно: минимальное ко- личество разламываний для разламывания шоколадной плитки, состоящей из n долек, равно (n – 1). Обратите внимание, что это говорит о том, что (n – 1) раз-ламываний достаточно и (n – 2) нет. Базовый случай: не требует разламываний одна-единственная долька. Индукционный шаг: предположим, что у нас m + 1 до- лек. Независимо от того, как мы разламываем плитку на две меньшие части долек a и b, a + b = m + 1. По индукционной гипотезе, часть «а» требует a – 1 разламываний, и часть «b» требует b – 1 разламываний, поэтому вместе число разламываний равняется (a – 1) + (b – 1) + 1 = a + b – 1 = m + 1 – 1 = m, и доказательство завершено. Обратите внимание, что 1 в прямоугольнике проис - ходит от первоначального разламывания, которое делит шоколадную плитку на части «a» и «b». Таким образом, «нудный» способ разламывания плитки шоколада (сначала на ряды, а затем каждый ряд отдельно на дольки) на самом деле является оптималь-ным. Задача 9.10. Пусть принцип индукции равен: [P(0) ∧ (∀n)(P(n) → P( n + 1))] → (∀m) P(m) (где n, m варьируются над натуральными числами), и пусть принцип наи- меньшего числа гласит: каждое непустое подмножество натуральных чисел имеет наименьший элемент. Эти два принципа эквивалентны в том смысле, что один может быть показан из другого. Действительно: принцип наименьшего числа ⇒ принцип индукции: предположим, что мы имеем [P(0) ∧ (∀n)(P(n) → P(n + 1))], но это вовсе не означает, что имеет место (∀m)P(m). Тогда множество S из m, для которого P(m) ложно, является непустым. По принципу наименьшего числа мы знаем, что S имеет наи- меньший элемент. Мы знаем, что этот элемент не равен 0, так как в качестве допущения было принято P(0). Таким образом, этот элемент может быть выражен как n + 1 для некоторого натурального числа n. Но так как n + 1 яв - ляется наименьшим таким числом, P(n) должно соблюдаться. Это противо-\n--- Страница 246 ---\nОтветы к избранным задачам  245 речие, поскольку мы исходили из того, что (∀n)(P(n) → P(n + 1)), и здесь мы имеем n такое, что P(n), но не P(n + 1); принцип индукции ⇒ принцип наименьшего числа: предположим, что S является непустым подмножеством натуральных чисел. Предположим, что оно не имеет наименьшего элемента; пусть P(n) равно следующему ло-гическому утверждению: «все элементы до и включая n не находятся в S». Мы знаем, что P(0) должно быть истинным, так как в противном случае 0 бу - дет в S, и тогда он будет наименьшим элементом (по определению 0). Пред- положим, что P(n) истинно (поэтому ни один из {0, 1, 2, , n} не находится в S). Предположим, что P(n + 1) ложно: тогда n + 1 обязательно будет в S (поскольку мы знаем, что ни один из {0, 1, 2, , n} не находится в S), и таким образом n + 1 будет наименьшим элементом в S. Следовательно, мы показа- ли [P(0) ∧ (∀n)(P(n) → P(n + 1))]. Поэтому по принципу индукции мы можем заключить, что (∀m)P(m). Но это означает, что S – пустое. Противоречие. Та- ким образом, S должно иметь наименьший элемент; принцип индукции ⇒ принцип полной индукции: для этого направ- ления мы используем принцип наименьшего числа, который мы только что показали как эквивалентный принципу индукции. Предположим, что у нас есть принцип индукции; допустим, что P(0) и ∀n((∀i ≤ n)P(i ) → P(n + 1)). Мы хотим показать, что ∀nP(n), поэтому мы докажем это с помощью прин- ципа индукции: задан базовый случай, P(0). Для того чтобы показать, как ∀j(P( j) → P(j + 1)), предположим, что это не соблюдается; тогда существует j такой, что P( j) и ¬P( j); пусть j равно наименьшему такому j; он существует по принципу наименьшего числа, и j ≠ 0 тем, что дано. Поэтому P(0), P(1), P(2), , P(j), но ¬P( j + 1). Однако это противоречит ∀n((∀i ≤ n)P( i) → P(n + 1)), и, следовательно, это невозможно. Отсюда следует, что ∀j(P( j) → P(j + 1)), и поэтому по принципу индукции у нас есть ∀nP(n) и, следовательно, прин- цип полной индукции. Последнее направление, принцип полной индукции ⇒ принцип индукции, сле- дует непосредственно из того, что принцип полной индукции имеет «более силь-ный» индукционный шаг. Задача 9.11. Мы используем пример на рис. 9.1. Предположим, что мы хотим получить дерево из инфиксного (2164735) и префиксного (1234675) кодирований: из префиксного кодирования нам известно, что 1 является корнем, и при этом из инфиксного кодирования нам известно, что левое поддерево имеет инфиксное кодирование 2, и поэтому префиксное кодирование 2, а правое поддерево имеет инфиксное кодирование 64735 и поэтому префиксное кодирование 34675, и мы продолжаем рекурсивно. Задача 9.13. Рассмотрим следующий инвариант: сумма S чисел, находящихся сейчас во множестве, является нечетной. Теперь докажем, что этот инвариант со-блюдается. Базовый случай: S = 1 + 2 + ··· + 2n = n(2n + 1), который является нечет - ным. Индукционный шаг: предположим, что S нечетно, пусть S равен результату еще одной итерации, поэтому S′ = S + |a – b| – a – b = S – 2min(a, b), и поскольку 2min(a, b) является четным, и S было нечетным по индукционной гипотезе, из этого следует, что S′ также должно быть нечетным. В конце, когда останется только одно число, к примеру x, S = x, поэтому x является нечетным.\n--- Страница 247 ---\n246  Математическая основа Задача 9.14. Для решения этой задачи необходимо предоставить и алгоритм, и инвариант для него. Алгоритм работает следующим образом: изначально раз- делить клуб на две группы. Пусть H равно общей сумме соперников, которых каж - дый член имеет в своей группе. Теперь повторить следующий цикл: до тех пор, пока существует m, у которого есть, по крайней мере, два соперника в его соб- ственной группе, перемещать m в другую группу (где m должен иметь не более одного соперника). Тем самым, когда m переходит из дома в дом, H уменьшается. Здесь инвариантом является «H монотонно убывает». Далее мы знаем, что после-довательность натуральных чисел не может уменьшаться вечно, поэтому, когда H достигает своего абсолютного минимума, мы получаем требуемое распределение. Задача 9.15. Сначала расположите гостей любым способом; пусть H равно числу соседних враждебно настроенных пар. Мы найдем алгоритм, который со-кращает H всегда, когда H > 0. Предположим, что H > 0, и пусть (А, B) равно враж - дебно настроенной паре, сидящей бок о бок по часовой стрелке А, B. Пройдемся вдоль стола по часовой стрелке, пока мы не найдем еще одну пару (А′, B′) такую, что A, A′ и B, B′ являются друзьями. Такая пара должна существовать: существует 2n – 2 – 1 = 2n – 3 кандидатов на A′ (это все люди, сидящие по часовой стрелке после B, у которых есть сосед, сидящий рядом с ними, снова по часовой стрелке, и этот сосед не является ни A, ни B). Так как А имеет не менее n друзей (среди лю- дей кроме самого себя), то из этих 2n – 3 кандидатов, по крайней мере, n – 1 из них являются друзьями А. Если каждый из этих друзей был недругом B, сидящего ря- дом с ним (опять же, идя по часовой стрелке), тогда B имел бы не менее n недругов, что не представляется возможным, поэтому должно быть А′ друзей с А таким об- разом, чтобы сосед А′ (по часовой стрелке) был B′ и B′ был другом B; см. рис. 9.14. Обратите внимание, что при n = 1 ни у кого нет недругов, и поэтому этот анализ применим при n ≥ 2, в каковом случае 2n – 3 ≥ 1. Теперь ситуация вокруг стола , A, B, , A′ , B′, …. Переверните всех в прямо- угольнике (то есть отобразите прямоугольник зеркально), чтобы сократить H на 1. Продолжайте повторять эту процедуру до тех пор, пока H > 0; в конце концов, H = 0 (по принципу наименьшего числа), и в этот момент не будет соседей, которые не нравятся друг другу. A, B, c1, c2, , c2n–3, c2n–2 Рис. 9.14  Список гостей, сидящих за столом по часовой стрелке, начиная с A. Нас интересуют друзья A среди c1, c2, , c2n–3, чтобы убе- диться, что имеется сосед справа, и этот сосед не является ни A и ни B; конечно, стол огибается вокруг в месте, где сидит гость c2n–2, поэтому следующим соседом гостя c2n–2 по часовой стрелке является А. Так как А имеет не более n – 1 недругов, А имеет не менее n друзей (не считая самого себя; любовь к себе не считается дружбой). Эти n дру - зей гостя А находятся среди гостей с, но если мы исключим c2n–2, то из этого следует, что А имеет, по крайней мере, n – 1 друзей среди c1, с2, , c2n–3. Если сосед ci по часовой стрелке, 1 ≤ i ≤ 2n – 3, то есть ci+i был в каждом случае недругом B, то, поскольку B уже имеет недруга A, то из этого будет следовать, что B имеет n недругов, что невозможно Задача 9.16. Мы разбиваем участников на множество Е четных лиц и множест - во О нечетных лиц. Мы наблюдаем, что во время церемонии рукопожатия мно-\n--- Страница 248 ---\nОтветы к избранным задачам  247 жество О не может изменить своего паритета. Действительно, если два нечетных человека пожимают друг другу руки, то |O| уменьшается на 2. Если два четных человека пожимают друг другу руки, то |O| увеличивается на 2, а если четный и не-четный люди пожимают руки, то |O| не меняется. Так как изначально |O| = 0, чет - ность множества сохраняется. Задача 9.19. Если a 1 ≡m a2, то существует некоторое a ∈ {0, 1, 2, …, m – 1} такое, что a1 = α1m + a и a2 = α2m + a, где α1 и α2 – это целые числа. Аналогичным образом у нас есть b1 = β1m + b и b2 = β2m + b. Таким образом, a1 ± b1 = (α1 ± β1)m + (a ± b) ≡m a ± b ≡m (α2 ± β2)m + (a ± b) = a ± b2 и a1 · b1 = (α1m + a) · (β1m + b) = α1β1 · m2 + (α1b + β1a) · m + a · b ≡m a · b ≡m α2β2 · m2 + (α2b + β2a) · m + a · b = a2 · b2, где каждый «≡m» является истинным, потому что дополнительные кратные m рав- ны 0; то есть ∀k ∈ � , k · m ≡m 0. Задача 9.21. Базовый вариант: пусть n равно простому числу. Очевидно, что n = n1 – это разложение n на простые множители, и каждый элемент �n – {0} явля- ется взаимно простым с n (то есть для каждого положительного целого числа i < n, gcd(n, i) = 1, так как n является простым). Следовательно, φ(n) = |�n| – 1 = n – 1 = n1–1 (n – 1), завершая базовый случай. Рассмотрим любое составное n = p1k1 ····· piki. Оче- видно, что мы можем разбить простой множитель p, чтобы получить n0 такое, что n = p · n0. Рассмотрим два случая. Случай 1: p|n0. Пусть m ∈ �∗ n0. Очевидно, что gcd(m, p) = gcd(m, n0) = 1, так как в противном случае m и n0 имели бы между собой общий множитель р, и мы знаем m ∈ �∗ n0. Допустим от противного, что ∃i ∈ {0, 1, 2, …, p – 1} такой, что gcd(m + in0, pn0) = o > 1. o| pn0, поэтому o = p или o|n0, но o < p, поэтому o|n0. Следовательно, o|in0, и мы уже знаем, что o |/ m, так как gcd(m, n0) = 1, поэтому o |/ (m + in0). Мы нашли наше противоречие, o не может быть делителем m + in0, если он не делит m + in0 равномерно по определению. Таким образом, ∀i ∈ �p, gcd(m + in0, pn0) = 1. Более того, m был произвольным элементом �∗ n0, поэтому это работает для каждого та- кого m – φ(n) ≥ p · φ(n0). Ясно, что для любого q ∈ �n0 – �∗ n0, q + in0 ∉ �∗ n, поэтому �∗ n не имеет никаких «дополнительных» элементов; φ(n) = p · φ(n0). На этом индукция для данного случая завершается. Случай 2: p |/ n0. Этот случай очень похож на предыдущий; единственное раз- личие заключается в том, что в конце мы должны удалить все кратные p, так как эти элементы имеют общий множитель p с n. Существует ровно φ(n0) таких крат - ных p, так как все остальные кратные имели другой общий множитель с самим n0 и в связи с этим не были включены. Тем самым φ(n) = p · φ(n0) – φ(n0) = (p – 1) · φ(n0), завершая индукцию.\n--- Страница 249 ---\n248  Математическая основа Для того чтобы прояснить, почему эти рекуррентные соотношения доказывают индукцию, рассмотрим, что происходит с ∏l i=1 piki–1(pi – 1), либо когда степень прос - того числа увеличивается на 1 (случай 1), либо когда включается новое простое число (случай 2). Задача 9.23. (a + 1)p ≡p åp j=0 �p j�ap–j1j ≡p (ap + 1) + åp–1 j=1 �p j�ap–j. Обратите внимание, что �p j� делится на p для 1 ≤ j ≤ p – 1, и поэтому мы име- ем, что åp–1 j=1 �p j�ap–j ≡p 0. Таким образом, мы можем доказать наше утверждение по индукции на а. Случай а = 1 тривиален, и на индукционном шаге мы использу - ем приведенные выше наблюдения, для того чтобы сделать вывод, что (a + 1)p ≡p (ap + 1), и мы применяем индукционную гипотезу, получая ap ≡p a. После того как мы доказали, что ap ≡p a, доказательство завершается, поскольку для а такого, что gcd(a, p) = 1, мы имеем обратное а–1, поэтому мы умножаем обе стороны на него и получаем ap–1 ≡p 1. Задача 9.24. Сначала мы рассматриваем (�n, +). Ясно, что замыкание удовле- творено, так как добавление в �n выполняется по модулю n, поэтому результат сло- жения должен быть в �n. Нейтральный элемент (тождественность) равен 0; 0 + i ≡n i для любого i ∈ �n. Мы также можем легко найти обратное: i–1 = n – i, потому что i + (n – i) = n ≡n 0. Наконец, сложение по модулю n является ассоциативным для любого n, поэтому все три аксиомы удовлетворены. Далее рассмотрим (�∗ n, ·). При наличии a, b ∈ �∗ n, gcd(a · b, n) = 1 с регулярным умножением, поэтому gcd(a · b, n) = 1 тоже с модулярным умножением – разница только в удалении «лишних» кратных n. Таким образом, мы имеем замыкание. gcd(n, 1) = 1 является независимым от значения n, поэтому 1 ∈ �∗ n. Очевидно, что 1 удовлетворяет требованиям нейтрального элемента при умножении. С учетом любого элемента a ∈ �∗ n мы знаем gcd(a, n) = 1, поэтому мы можем найти целые числа x, y такие, что ax + ny = 1. Более того, ny ≡n 0, поэтому ax ≡n 1. Если x ∉ �n, то существует х′ ∈ �n такой, что x′ ≡n x. То же самое ax′ ≡n 1; из ax мы удалили только кратное an, поэтому эффект (mod n) равен 0. Так как ax′ ≡n 1, x′ не должен иметь никаких общих множителей с n, поэтому x′ ∈ �∗ n. Таким образом, мы имеем обрат - ное. Опять же, ассоциативность является тривиальной, так как она гарантируется выбранной операцией, умножением по модулю n. Задача 9.27. Пусть H ≤ G, и допустим, что h ∈ H. Поскольку H является группой, мы знаем, что h –1 ∈ H тоже является группой. Мы также знаем, что e ∈ H, где e – это нейтральный элемент G (и, конечно же, H), опять же просто потому, что H явля- ется группой. Поскольку H замкнута, мы знаем, что для всех a ∈ H, также h–1a ∈ H, в связи с чем hh–1a = a ∈ hH. Таким образом, H ⊆ hH. Далее рассмотрим любой а′ ∈ hH; ясно, что а′ = hа для некоторого a ∈ H. Поскольку h ∈ H тоже и H является замкнутой, а′ должно быть в х. Следовательно hH ⊆ H, завершая доказательство, что hH = H. Пусть g ∈ G, и рассмотрим gH; очевидно, что |gH| ≤ |H|, так как каждый элемент gH требует уникального h ∈ H. Допустим, что |gH| < |H|. Тогда существует два уни- кальных элемента H, h1 и h2, таких, что gh1 = gh2. Но G является группой, поэтому g имеет обратное, g–1. Значит, g–1gh1 = g–1gh2, или то же самое h1 = h2 – противоречие. Тем самым |gH| = |H|.\n--- Страница 250 ---\nОтветы к избранным задачам  249 Допустим, что h′ ∈ (ab)H. Тогда ∃h ∈ H такая, что (ab)h = h′. Группы являются ас - социативными, поэтому h′ = a(bh), и в связи с этим h′ ∈ H. Доказывание того, что любой элемент a(bH) также находится в (ab)H, является почти идентичным. Задача 9.28. Для обозначения результата операции заданной группы мы будем использовать термин «произведение». Обратите внимание, что 〈g1, g2, , gk〉 – это просто коллекция произведений произвольной перестановки элементов G′ = {g1, , gk, g1–1, , gk–1} с возвратом. Ясно, что если мы умножаем любой g ∈ G′ на самого себя либо другой элемент G, результат находится в сгенерированной подгруппе (что побуждает включать тождество, при условии что инверсии включены в G′). Более того, учитывая любые два созданных элемента x1x2 ··· xp1 и y1y2 ··· yp2, про- изведение x1 ··· xp1y1 ··· yp2 отвечает требованиям, которые должны быть включены в 〈g1, g2, , gk〉. Таким образом, сгенерированная подгруппа замыкается. Она явно также включает в себя инверсии, так как инверсия произведения x1 ··· xk является просто произведением xk–1 ··· x1–1. Ассоциативность обеспечивается охватывающей группой G. Таким образом, сгенерированная подгруппа действительно является группой. Что касается |g|, обратите внимание, что любой элемент может быть за- писан как произведение элементов g и g–1. Другими словами, каждый элемент |〈g〉| может быть записан в виде gn для некоторого целого числа n. Но gord(G) = 1, значит, gn = g(n mod ord(G)). Так как существует только ord(G) несовпадающих элементов в �ord(G), то существует также только ord(G) несовпадающих элементов g. Задача 9.31. Сконструируем r поэтапно так, чтобы на этапе i оно удовлетворяло первым i конгруэнциям, то есть на этапе i мы имеем, что r ≡ rj (mod mj) для j ∈ {0, 1, …, i}. Этап 1 является легким: просто установим r ← r0. Предположим, что первые i этапов завершены; пусть r ← r + (∏i j=0 mj)x, где x удовлетворяет x ≡ (∏i j=0 mj)–1(ri+1 – r) (mod mi+1). Мы знаем, что обратное от (∏i j=0 mj) существует (в �mi+1), поскольку gcd(mi+1, (∏i j=0 mi)) = 1, и, более того, это обратное может быть эффективно получено с помощью рас - ширенного алгоритма Евклида. Задача 9.33. Мы докажем это, если m0, m1, , mn являются попарно взаимно простыми числами, тогда �m0·m1· ·m n ≅ �m0 × �m1 × ··· × �mn через индукцию над n. Пусть M = m0·m1·…·mn. Теорема 9.30 обеспечивает удобную биекцию из �M в �m0 × ··· × �mn: f(r) = (r mod m0, r mod m1, , r mod mn) для всех r ∈ �M. Обратите внимание, что операции в этих двух группах не опре- делены, потому что они вытекают из контекста; для �M операцией является сло- жение по модулю M. Мы будем обозначать ее как «+M» (на самом деле для любого натурального числа n мы будем обозначать сложение по модулю n как «+n», когда это удобно). Для �m0 × ··· × �mn она является поэлементным модулярным сложени- ем – то есть при наличии x, y ∈ �m0 × ··· × �mn «x ∗ y» будет означать (x0 +m0 y0, , xn +mn yn). f(r +M r′) = (r0 +M r0 mod m0, , rn +M r′n mod mn) = (r + r ′ mod m0, , r + r ′ mod mn) = f(r) ∗ f(r ′),\n--- Страница 251 ---\n250  Математическая основа где мы можем использовать нормальное сложение вместо модулярного сложения, потому что для всех i, mi |M. Мы уже знали, что f является биекцией; теперь мы знаем, что она является изоморфизмом, поэтому две группы являются изоморф-ными. Задача 9.35. (1) ⇒ (2) Предположим, что R является транзитивным, и пусть (x, y) ∈ R 2. Тогда по определению (9.6) мы знаем, что существует такое z, что xRz и zRy. По транзитивности мы имеем, что (x, y) ∈ R. (2) ⇒ (3) Предположим, что R2 ⊆ R. Мы показываем по индукции на n, что Rn ⊆ R. Базовый случай, n = 1, три- виален. На индукционном шаге предположим, что (x, y) ∈ Rn+i = Rn ∘ R, поэтому по определению (9.6) существует z такой, что xRnz и zRy . По индукционному допуще- нию это означает, что xRz и zRy, поэтому (х, y) ∈ R2, и поскольку R2 ⊆ R, то из этого следует, что (х, y) ∈ R, и доказательство завершено. (3) ⇒ (1) Предположим, что для всех n Rn ⊆ R. Если xRy и yRz, то xRz ∈ R2, и поэтому xRz ∈ R, и, значит, R является транзитивным. Задача 9.37. С учетом R ⊆ X × X пусть S = R ⋃ idX. Очевидно, что S является реф- лексивным, так как только idX содержит каждую пару, необходимую для обеспе- чения рефлексивности. Рассмотрим любое S′, для которого существует пара x, y такая, что xSy и ¬ xS′y. Если xRy, то R ⊈ S′. В противном случае (x, y) ∈ idX, поэтому x = y; существует элемент x такой, что ¬xS ′x, поэтому S′ не является рефлексивным. В обоих случаях S′ не является рефлексивным замыканием R. Поэтому R ⊆ S, S является рефлексивным, и любое множество, удовлетворяющее этим двум усло-виям, содержит каждый элемент S. Следовательно, S является рефлексивным за- мыканием R. Задача 9.39. Пусть S = R ⋃ R –1. Очевидно, что R ⊆ S, и S является явно симмет - ричным. Рассмотрим S′ такое, что S ⊈ S′. Существует пара (х, y) ∈ S такая, что (х, y) ∉ S′. Если (x, y) ∈ R, то R ⊈ S′. В противном случае (y, x) ∈ R; если (y, х) ∈ S′, то S′ не является симметричным, но если (y, х) ∉ S′, то R ⊈ S′. В любом случае, S′ либо не замкнуто, либо не содержит R. S, с другой стороны, содержит R, является симмет - ричным и подмножеством любого множества, которое удовлетворяет этим усло-виям. Поэтому оно является симметричным замыканием R. Задача 9.41. Причина в том, что в первой строке мы выбрали конкретный y: xR +y ∧ yR+z ⇔ ∃m, n ≥ 1, xRmy ∧ yRnz. С другой стороны, из формального суждения ∃m, n ≥ 1, x(Rm ∘ Rn)z мы можем только заключить, что существует y такой, что ∃m, n ≥ 1, xRmy′ ∧ y ′Rnz, и не обязательно имеет место, что y = y′. Задача 9.45. R является рефлексивным, поскольку F(x) = F(x); R является симметричным, поскольку из F(x) = F(y) следует F(y) = F(x) (равенство является симметричным отношением); R является транзитивным, потому что F(x) = F(y) и F(y) = F(z) означает, что F(x) = F(z) (опять же по транзитивности равенства). Задача 9.51. Из леммы 9.49 мы знаем, что ∀a ∈ X, [a]R1 ⊆ [a]R2. Следовательно, отображение f : X/R1 → X/R2, заданное f([a]R1) = [a]R2, является сюръективным, и, сле- довательно, |X/R1| ≥ |X/R2|. Задача 9.54. Мы показываем направление слева направо. Ясно, что ≈ являет - ся рефлексивным, поскольку оно содержит idX. Теперь предположим, что a ≈ b; тогда a ∼ b или a = b. Если a = b, то b = a (так как равенство, очевидно, является симметричным отношением), и поэтому b ≈ a. Если a ∼ b, то по определению не- сопоставимости ¬(a ≼ b) ∧ ¬(b ≼ a), что логически эквивалентно ¬(b ≼ a) ∧ ¬(a ≼ b), а следовательно, b ∼ a, и поэтому в данном случае также b ≈ a. Наконец, мы хотим\n--- Страница 252 ---\nОтветы к избранным задачам  251 доказать транзитивность: предположим, что a ≈ b ∧ b ≈ c; если a = b и b = c, то a = c, и мы имеем a ≈ c. Схожим образом, если a = b и b ∼ c, то a ∼ c, и поэтому a ≈ c, и если a ∼ b и b = c, тогда и a ∼ c, а также a ≈ c. Единственный оставшийся случай – это a ∼ b и b ∼ c, и именно здесь мы используем тот факт, что ≼ является стратифици- рованным порядком, так как из этого вытекает, что a ∼ c ∨ a = c, что дает нам a ≈ c. Задача 9.56. Мы показываем направление слева направо. Естественный спо- соб продвижения вперед здесь состоит в том, чтобы приравнять T множеству, со- стоящему из разных классов эквивалентности X при ∼. То есть T = {[a]∼ : a ∈ X}. Тогда T является полноупорядоченным при ≼T, определенном следующим обра- зом: для X, X′ ∈ T таких, что X ≠ X′ и Х = [х] и X′ = [х′], мы имеем, что Х ≼T X′ тогда и только тогда, когда х ≼T х′. Отметим также, что с учетом двух несовпадающих X, X′ в Т и любой пары представителей х, х′ всегда имеет место, что х ≼T х′ или х′ ≼T х, поскольку если бы ни тот и ни другой не имел место, то мы бы имели x ∼ x′, и, следовательно, [х] = [х′] и Х = X′. Тогда функция f : X → T, заданная как f(x) = [x], удовлетворяет требованиям. Задача 9.57. Пусть X = {a, b, c, d, e}. Рассмотрим частичный порядок, заданный упорядоченными парами {(a, c), (a, d), (a, e), (b, c), (b, d), (b, e), (c, d), (c, e)} (где реф- лексивные пары (то есть (a, a), (b, b)…) были опущены. Ясно, что a является мини- мальным, так как нет элемента x ≠ a такого, что x ≼ a. Схожим образом b является минимальным, d, e являются максимальными. Вместе с тем не существует наи- меньшего элемента или наибольшего элемента; наши минимальные элементы a, b несравнимы, как максимальные d, e. Обратите внимание, что в случае конечно- го линейного частичного порядка это было бы невозможно, потому что каждый элемент был бы сравним. X также не имеет супремума или инфимума, опять же потому, что никакой минимальный или максимальный элемент не может быть сравнен с другими. Существуют также простые примеры линейных частичных порядков без инфимума или супремума. Рассмотрим, например, частичный по-рядок ( � +, ≼), где �+ – это положительные действительные числа и x ≼ y тогда и только тогда, когда x, y ∈ �+ ∧ x ≤ y. Очевидно, что этот частичный порядок не имеет супремума – всегда имеется более крупное действительное число. Менее очевидно, что у него нет инфимума! Существует интуитивный кандидат на ин-фимум: 0. Однако ≼ определено только для пар элементов в � +, поэтому 0 несрав- ним ни с чем. Если вместо этого мы используем частичный порядок (� , ≤), то �+ ⊂ � имеет инфимум: 0. Пусть A ⊂ X равно {b, c, d}. Порция нашего частичного порядка на X, которая применима к A: {(b, c), (b, d), ( c, d)}. В отличие от X, A имеет четкий инфимум, су - премум, наибольший элемент и наименьший элемент, хотя его охватывающий X не является линейным. Задача 9.58. Пусть X равно множеству, и рассмотрим частичный порядок (P(X), ⊆). При наличии A, B ∈ P(X) мы стремимся доказать, что A ⊔ B = A ⋃ B. Оче- видно, что А , B ⊆ A ⋃ B. Более того, в любом собственном подмножестве A ⋃ B на - верняка отсутствует элемент A или B, поэтому для всех C ∈ P(X), A, B ⊆ C ⇒ A ⋃ B ⊆ C. Таким образом, A ⋃ B = inf({A, B}). Доказательство, что A ⊓ B = A ⋂ B подчи- няется примерно тому же процессу, но при этом подмножества и надмножества реверсированы. Задача 9.60. Мы доказываем следующую часть: a ≼ b ⇔ a ⊓ b = a. Предположим, что a ≼ b. Так как (X, ≼) представляет собой решетку, оно является частичным\n--- Страница 253 ---\n252  Математическая основа порядком, и поэтому a ≼ a (рефлексивность), и, значит, а является нижней гра- ницей множества {a, b}. Поскольку (X, ≼) представляет собой решетку, существует inf{a, b}, и, следовательно, a ≼ inf{a, b}. С другой стороны, inf{a, b} ≼ a, и поэтому по антисимметрии частичного порядка мы имеем a = inf{a, b} = a ⊓ b. В другом на- правлении a ⊓ b = a означает, что inf{a, b} = a, и поэтому a ≼ inf{a, b}, и, значит, a ≼ b. Задача 9.62. (1) непосредственно вытекает из наблюдения, что {a , b} и {b , a} яв- ляются одним и тем же множеством. (2) следует из наблюдения, что inf{a , inf{b , c}} = inf{a , b, c} = inf{inf{a , b}, c}, и то же самое для супремума. (3) следует непосредствен- но из наблюдения, что {a , a} = {a} (мы имеем дело со множествами, а не с «муль- тимножествами»). В случае (4) закон поглощения, показываем, что a = a ⊔ (a ⊓ b). Прежде всего обратите внимание, что a ≼ sup{a , ∗} (где «∗ » обозначает что угодно, в частности a ⊓ b). С другой стороны, а ⊓ b ≼ а по определению, a ≼ a по рефлек - сивности, и поэтому а является верхней границей для множества {a , a ⊓ b}. Следо- вательно, sup{a , a ⊓ b} ≼ a, и тем самым по антисимметрии a = sup{a , a ⊓ b}, то есть a = a ⊔ (a ⊓ b). Другой закон поглощения может быть доказан аналогичным образом. Задача 9.64. Для того чтобы показать, что (P(X), ⊆) является полным, доста- точно доказать другие свойства, перечисленные в теореме 9.63, так как формула для супремума и инфимума сильнее их существования. Сначала мы докажем, что ∀ ⊆ P(X), sup() = ⋃ A∉ A. Ясно, что оно удовлетворяет требованию быть верх - ней границей. Более того, в любом собственном подмножестве ⋃A∉ A отсутствует, по крайней мере, один из элементов в A ∈ , поэтому он не является верхней границей . Таким образом, ⋃A∉ A является супремумом . Обратите внимание, что это следует непосредственно из результатов задачи 9.58. Доказательство того, что inf() = ⋂ A∉ A, очень похоже (и тоже следует непосредственно из задачи 9.58). Остальные факты, ⊥ = ∅ и ⊤ = X, должны быть очень интуитивными; они также являются непосредственными выводами, которые могут быть сделаны из формул супремума и инфимума этой задачи. Задача 9.70. Например, наименее неподвижная точка f задана формулой f 4(∅) = f3({a, b}) = f2({a, b}) = f({a, b}) = {a, b}. Задача 9.72. Обратите внимание, что с sup{a, b} = ⊤, и поэтому f(sup{a, b}) = f(⊤) = ⊤. С другой стороны, f({a, b}) = {⊥}, так как f(a) = f(b) = ⊥. Следовательно, sup( f({a, b}) = sup({⊥}) = ⊥. См. рис. 9.15 для функции g, которая является монотонной, но не является ни восходяще-, ни нисходяще-непрерывной. Задача 9.74. Пусть S ⊆ �×� равно множеству, состоящему строго из этих пар целых чисел (x, y) таких, что x ≥ y и x – y является четным. Мы намерены доказать, что S является областью определения F. Прежде всего если x < y, то х ≠ y, и поэтому мы продолжаем вычислением F(x, F(x – 1, y + 1)), и теперь мы должны вычислить F(x – 1, y + 1); если х < y, то однозначно x – 1 < y + 1; это условие сохраняется, и по- этому мы завершаем вычислением F(x – i, y + i) для всех i, и, значит, эта рекурсия никогда «не достигнет дна». Предположим, что x – y является нечетным. Тогда x ≠ y (так как 0 – четно!), поэтому снова мы переходим к F(x, F(x – 1, y + 1)); если x – y является нечетным, то таковым является и (x – 1) – ( y + 1) = x – y – 2. Опять же, мы завершаем тем, что нам приходится вычислить F(x – i, y + i) для всех i, и поэтому рекурсия никогда не заканчивается. Ясно, что все пары в Sc не находятся в области определения F. Предположим теперь, что (x, y) ∈ S. Тогда x ≥ y и x – y является четным; тем са- мым x – y = 2i для некоторого i ≥ 0. Мы показываем, по индукции на i, что алгоритм\n--- Страница 254 ---\nОтветы к избранным задачам  253 завершается на таких (x, y) и выводит x + 1. Базовый случай: i = 0, поэтому x = y, и, значит, алгоритм возвращает y + 1, то есть x + 1. Предположим теперь, что x – y = 2(i + 1). Тогда x ≠ y, и поэтому мы вычисляем F(x, F(x – 1, y + 1)). a a ⊥ ⊥ c cb b e ed d⊤ ⊤f f Рис. 9.15  Пример упорядочения над X = {a, b, c, d, e, f, ⊥, ⊤,} с функ - цией g : X → X, обозначенного пунктирными линиями. В то время как g является монотонной, она не является ни восходящее-, ни нисхо- дяще-непрерывной Но (x – 1) – ( y + 1) = x – y – 2 = 2(i + 1) – 2 = 2i для i ≥ 0, и поэтому по индукции F(x – 1, y + 1) завершается и выводит (x – 1) + 1 = x. Поэтому теперь мы должны вычислить F(x, x), то есть просто x + 1, и доказатель- ство завершено. Задача 9.75. Мы показываем, что f1 является неподвижной точкой алгорит - ма 9.1. Напомним, что в задаче 9.74 мы показали, что область определения функции F, вычисляемой алгоритмом 9.1, равна S = {(x, y) : x – y = 2i, i ≥ 0}}. Теперь мы показываем, что если мы заменяем F в алгоритме 9.1 на f1, то новый алго- ритм, который является алгоритмом 9.6, по-прежнему вычисляет F, хотя и не рекурсивно (поскольку f1 определяется алгоритмом 9.2, который не является ре- курсивным). Алгоритм 9.6. Алгоритм 9.1, в котором F заменена на f1 1: if x = y then 2: return y + 1 3: else4: f 1(x, f1(x – 1, y + 1)) 5: end if\n--- Страница 255 ---\n254  Математическая основа Мы действуем следующим образом: если (x, y) ∈ S, то x – y = 2i при i ≥ 0. Из за- дачи 9.74 мы знаем, что на такой (x, y) функция F(x, y) = x + 1. Теперь рассмотрим вывод алгоритма 9.6 на такой паре (x, y). Если i = 0, то он возвращает y + 1 = x + 1, поэтому доказательство завершено. Если i > 0, то он вычисляет f1(x, f1(x – 1, y + 1)) = f1(x, x) = x + 1, и доказательство завершено. Для того чтобы понять, почему f1(x – 1, y + 1) = x, об - ратите внимание, что существует два случая: во-первых, если x – 1 = y + 1, то алго- ритм f1 (алгоритм 9.2) возвращает (y + 1) + 1 = (x – 1) + 1 = x. Во-вторых, если x – 1 > y + 1 (и это единственная другая возможность), то алгоритм 9.2 тоже возвращает (x – 1) + 1 = x. Задача 9.76. Сначала покажем, что f3 ⊑ f1. Допустим, (x, y) ∈ S3. Тогда x ≥ y, и ( x – y) является четным. Ясно, что f3(x, y) = x + 1. Если x ≠ y, то f1(x, y) = (x + 1); в противном случае f1(x, y) = (y + 1) = (x + 1). В обоих случаях f1(x, y) определена и, более того, равна f3(x, y). Следовательно f3 ⊑ f1. Далее рассмотрим f2(x, y). x ≥ y, поэтому f2 возвращает (x + 1) = f3(x, y). Тем самым f3 ⊑ f2. Задача 9.77. Пусть грамматика Gprop имеет алфавит {p, 1, ∧, ∨, ¬ (, )} и множество правил, заданных S → pX |¬S|(S ∧ S)|(S ∨ S); X → 1|X1. Переменными являются: {p1, p11, p111, p1111, …}, то есть они кодированы в унарной форме записи. Задача 9.79. По индукционной гипотезе w(α) = w(β) = 1, поэтому w(¬α) = 0 + (–1) = –1, и поскольку левая и правая круглые скобки уравновешивают друг друга, в том смысле что w((t)) = w(() + w(t) + w()) = 1 + w(t) + (–1) = w(t), результат быстро следует для (α ∧ β) и (α ∨ β). Для того чтобы показать, что любой надлежащий на- чальный сегмент (α ∘ β) (где ∘ ∈ {∧, ∨}) имеет вес ≥ 0, мы записываем его следую- щим образом: (α ∘ β) =syn (α1α2 αm ∘ β1β2 βn), где αi и βj – это соответственно символы α и β. Несколько случаев естественным образом проявляется: если начальный сегмент состоит только из открывающей скобки (, то его вес равен 1. Если начальный сегмент заканчивается элементами αi, но не кончается в αm, тогда по индукции он имеет вес ≥ 1. Если он заканчивается ровно в αm, то по индукции он имеет вес 0. Если он заканчивается в ∘, то он имеет вес 1. Схожим образом мы имеем дело с начальным сегментом, заканчивающим-ся в середине элементов β j, в βn и в последней закрывающей скобке ). Задача 9.81. Предположим, α ≠syn α′. Тогда αcβ =syn α′c′β′ , α и α′ оба являются началь- ными сегментами одной и той же символьной цепочки (строки). В связи с этим один должен быть начальным сегментом другого; мы исходим из допущения без потери общности, что α является первыми n элементами α′ и что α′ содержит бо- лее n элементов. Очевидно, что α представляет собой надлежащий начальный сег - мент, так как α′ – это валидная формула. Лемма 9.78 допускает, что вес α является неотрицательным, но α является формулой, поэтому ее вес равен –1. Допущение, что α ≠ syn α′ приводит к противоречию, значит, α =syn α′. В связи с этим c и c′ имеют об-\n--- Страница 256 ---\nОтветы к избранным задачам  255 щий индекс в идентичных строках; они являются одинаковой бинарной связкой. Более того, β и β′ должны тогда начинаться в одинаковом индексе αcβ =syn α′c′β′ ,\\ и продолжаться до конца, поэтому β =syn β′. Задача 9.82. Предположим, что мы имеем Φ ⊨ α и Φ ⋃ {α} ⊨ β. И предположим, что τ является закреплением истинностного значения, которое удовлетворяет Φ. Тогда по первому допущению оно должно удовлетворять α, и поэтому τ удовле- творяет Φ ⋃ {α}, и, следовательно, по второму допущению оно должно удовлетво- рять β. Задача 9.83. По структурной индукции на α. Понятно, если α – это просто пере- менная p, то α′ равно ¬p, и ¬ α ⇔ α′. Индукционный шаг следует сразу из законов де Моргана. Задача 9.84. Пусть переменные α равны α(x, y) и переменные β равны β(y, z). Форма записи x обозначает множество булевых переменных; используя это обо- значение, множество S = Var(α) ⋂ Var(β) = {y}. Определим булеву функцию f сле- дующим образом: f(y) = �если ∃x такое, что α(x, y) = 1 в противном случае. Здесь мы немного злоупотребляем формой записи, смешивая булевы функции и булевы формулы; y работает «сверхурочно»: он является и аргументом f, и за- креплением истинностного значения переменной α. Но смысл ясен. Пусть Cf(y) равно булевой формуле, связанной с f; она может быть получена, например, конъ- юнктивной нормальной формой. Cf – это наша формула: предположим, что τ ⊨ α; тогда τ явно удовлетворяет Cf (по его определению). Если τ ⊨ C, то должно сущест - вовать x такое, что α(x, τ) является истинным, и, следовательно, β(τ, z) является истинным по исходному допущению. Обратите внимание, что мы могли бы определить f двояко с помощью β; каким образом? Задача 9.85. Мы предлагаем доказательство того, что ¬(p ∨ q) → ¬p ∧ ¬q. Обосно- вание каждого шага приводится справа. Правила «ослабления» и «обмена» обо- значаются соответственно символами «w» и «e». Схожим образом «левый» и «пра-вый» обозначаются символами «l» и «r». p → p ∨ q q → p ∨ qp → p, q q → p, qp → p q → q ¬(p ∨ q) → ¬p ¬(p ∨ q) → ¬q ∧ ¬q¬(p ∨ q) → ¬q¬ l, r ¬ l, r∨ r ∨ rw w, e ∧ r Задача 9.86. Ниже приводится доказательство в пропозициональном исчис - лении PK левого сокращения; в связи с этим мы исходим из того, что Γ, α, α → Δ является истинным. α → α Γ, α, α → Δ Γ, α → Δ, α Γ, α → Δα, Γ, α → Δ\n--- Страница 257 ---\n256  Математическая основа Задача 9.87. Правило правого введения для ↔: α, Γ → Δ, β Γ → Δ, (α ↔ β)β, Γ → Δ, α Задача 9.88. Напомним, что каждая секвенция записывается в форме «антеце- дент → сукцедент», где антецедент – это конъюнкция и сукцедент – это дизъюнк - ция. Правила обмена являются прямым результатом коммутативности и ассоциа- тивности операторов «и» и «или». Схожим образом правила ослабления являются результатом свойств этих операторов. Учитывание дополнительной формулы в антецеденте может приводить к получению значения ложь, когда в других слу - чаях оно было бы истинным, но это не может сделать секвенцию ложной, когда в других случаях она была истинной. Схожим образом включение новой формулы в сукцедент может привести к тому, что результирующая дизъюнкция вновь будет возвращать истину, но это опять же не будет приводить к тому, что в других слу - чаях истинная секвенция будет ложной. Допустим, что Γ → Δ, α и α, Γ → Δ. То есть Γ → (Δ ∨ α) и ( α ∧ Γ) → Δ. Допустим, что Γ истинно, и допустим, ради противоречия, что Δ ложно. Тогда истина → (ложь ∨ α), а значит, α истинно. Поэтому (истина ∧ истина) → Δ, следовательно, Δ должно быть истинным. Очевидно, что мы нашли противоречие; Δ должно быть истинным вся-кий раз, когда Γ истинно, доказывая правило усечения. В задаче 9.86 мы показываем, что правильность правил сокращения может быть доказана при использовании правил обмена, ослабления и усечения. Теперь мы начинаем правила введения. Для ¬-левого правила пусть Γ → Δ ∨ α. Допустим, что Γ и ¬ α являются истинными, и допустим для противоречия, что Δ ложно. Тогда мы имеем: истина → ложь ∨ ложь; это закрепление значений про- тиворечит гипотезе. Таким образом, ¬α ∧ Γ → Δ. Схожий аргумент может быть дан для ¬-правого правила. ∧-левое и ∨-правое правила следуют из коммутативной и ассоциативной при- роды антецедента и сукцедента. ∧-правое и ∨-левое правила могут быть быстро доказаны с помощью доказательства от противного, аналогично правилам ¬. Задача 9.90. Каждое правило обмена является своей собственной инверсией, поэтому каждое является инвертируемым в результате своей собственной пра-вильности. Схожим образом правила введения ¬ являются инверсиями друг дру - га. Правила сокращения доказываются непосредственно посредством логических утверждений, что (Γ ∧ α ∧ α) ⇔ ( Γ ∧ α) и (Δ ∨ α ∨ α) ⇔ (Δ ∨ α). Схожим образом правило усечения является результатом двух явно истинных наблюдений: (α ∧ Γ) → Γ и Δ → (Δ ∨ α). ∧-правое и ∨-левое правила явно не меняют смысла секвенции при условии, что конъюнкции и дизъюнкции коммутативны и ассоциативны. В ∧-правом правиле пусть Γ → Δ, ( α ∧ β). Если Γ является ложным, тогда обе верх - ние секвенции являются истинными вне зависимости от значения их сукцеден-тов. Допустим, что Г истинно. Опять же, если Δ является истинным, то доказатель-ство завершено – допустим, что Δ является ложным. Тогда (α ∧ β) оба являются истинными по гипотезе, поэтому Δ ∨ α и Δ ∨ β являются истинными. Тем самым Γ → Δ, α и Γ → Δ, β, и доказательство завершено. Для того чтобы доказать, что ∨-левое правило является инвертируемым, пусть (α ∨ β), Γ → Δ) равно истине. Допустим, что α и Γ оба являются истинными. Тогда (α ∨ β) ∧ Γ является истинным, поэтому Δ должно быть истинно. Следовательно, α,\n--- Страница 258 ---\nОтветы к избранным задачам  257 Γ → Δ является истинным. Идентичная аргументация может быть выдвинута для того, чтобы доказать, что β, Γ → Δ, завершая доказательство. Наконец, мы приведем пример, в котором инверсия правила ослабления ока- зывается безуспешной. Пусть α, Γ → Δ равно истине. Ясно, что если α является лож - ным и Г является истинным, то никакого заключения о Δ сделать невозможно – оно может быть либо истинным, либо ложным. В случае если Δ является ложным, мы находим противоречие логическому утверждению, что Γ → Δ. Задача 9.92. Пять правил не нужны: правила сокращения, ослабления и усече- ния. Нам нужны правила обмена, для того чтобы доказательства соответствовали точному порядку следования заданных правил, и нам нужно любое правило вве-дения связок, которое применимо. Задача 9.93. Любая нетривиальная формула может быть записана в одной из следующих форм: α ∧ β, α ∨ β или ¬α . Для того чтобы доказать, что PK′ является пол- ным, нам нужно только показать, что формулы в этих формах могут быть введены из их компонентных частей. Мы обеспечиваем их построения. В первую очередь ∧: α → α β → β α, β → α α, β → α ∧ β α ∧ β → α ∧ βα, β → β . Затем ∨: α → α β → β α → α, β α ∨ β → α, β α ∨ β → α ∨ ββ → α, β . И наконец, ¬α → ¬ α является результатом двух быстрых применений правил введения ¬ к α → α. Задача 9.96. Мы закрепляем вес за каждым символом в стиле, схожем с рис. 9.9. Каждый n-арный предикатный символ имеет вес, равный (n – 1). Например, сим-вол 4-арной функции имеет вес 3. В качестве расширения этого правила констан-ты (которые на самом деле являются символами 0-арной функции) имеют вес –1. Переменные, которые (как и константы) представляют собой полные члены, также имеют вес –1. Мы утверждаем, что каждый член весит –1 и что каждый надлежащий начальный сегмент весит, по крайней мере, 0. Сначала рассмотрим тривиальный случай: член, состоящий из одной константы или переменной. Его вес равен –1, и единственным надлежащим начальным сегментом является пус - той сегмент, который имеет вес 0. Более того, это свойство является явно индуктивным. Любой нетривиальный член является n-арным предикатным символом с весом (n – 1), за которым следу - ют n членов. Если каждый из этих членов имеет вес –1, то результирующий член имеет вес (n – 1) – n = –1. Любой начальный сегмент состоит из этого n-арного сим- вола, менее n полных членов и до 1 неполного члена; этот член весит ≥ 0, и оче- видно, что недостаточно полных членов, чтобы преодолеть вес (n – 1), предпи- санный начальным предикатом – любой надлежащий начальный сегмент должен иметь вес ≥ 0. Из этого следует, что две одинаковые строки не могут представлять\n--- Страница 259 ---\n258  Математическая основа один и тот же предикат и ряд членов, поскольку из этого вытекало бы, что неко- торый включенный член является надлежащим начальным сегментом другого; более подробное объяснение этого последнего шага см. в решении задачи 9.81. Задача 9.98. Докажем это с помощью основных семантических определений: пусть M равно любой структуре и σ равно любому объектному закреплению. Предположим, M ⊨ (∀xα ∨ ∀xβ)[σ]. Тогда M ⊨ ∀xα[σ] или M ⊨ ∀xβ[σ]. Случай (1): M ⊨ ∀xα[σ]. Тогда M ⊨ α[σ(m/x)] для всех m ∈ M. Тогда M ⊨ (α ∨ β) [σ(m/x)] для всех m ∈ M. Поэтому M ⊨ ∀x(α ∨ β)[σ]. Случай (2): M ⊨ ∀xβ[σ]; та же идея, что и выше.Следовательно, M ⊨ ∀x(α ∨ β)[σ]. По определению логического следствия (∀xα ∨ ∀xβ) ⊨ ∀x(α ∨ β). Задача 9.99. Нет, не обязательно. Мы используем определение логического следствия, для того чтобы доказать это. Для того чтобы доказать, что правая сто-рона не является логическим следствием левой стороны, мы должны продемон- стрировать модель M, объектное закрепление σ и формулы α, β такие, что M ⊨ ∀x(α ∨ β)[σ], но M ⊭ (∀xα ∨ ∀xβ)[σ]. Пусть α и β равно соответственно Px и Qx ( P, Q – унарные предикаты). Теперь определим M и σ. Поскольку формулы являются сентенцией, то не нужно опре- делять σ. M: пусть универсум дискурса равен М = �. Нам все еще нужно придать смысл P, Q в M, пусть P M = {0, 2, 4, …} и QM = {1, 3, 5, …}. Тогда M ⊨ ∀x(Px ∨ Qx) (по- скольку каждое число является четным или нечетным). Но M ⊭ (∀xPx ∨ ∀xQx) (потому что не является истиной, что либо все числа чет - ные, либо все числа нечетные). Задача 9.100. Базовый случай: пусть u = ft1t2 … tn, где некоторые из входных членов ti функции f могут быть x, но ни один из них в прочих случаях не включает x. Если ни один из членов не является x, то ясно, что (u(t/x))M[σ] = uM[σ] = uM[σ(m/x)] для любого m; x не входит в u, поэтому замещения ничего не делают при примене- нии к u. В противном случае существуют некоторые i такие, что ti = x; ниже мы исхо- дим из того, что x присутствует один раз в членах, но эта деталь не имеет значения. (u(t/x))M[σ] = ((ft1 x tn)(t/x))M[σ] = (ft1 t tn)M[σ] = fM(t1M[σ], tM[σ], tnM[σ]). Схожим образом uM[σ(m/x)] = (ft1 x tn)M[σ(m/x)] = fM(t1M[σ(m/x)], , xM[σ(m/x)], , tnM[σ(m/x)]). Здесь мы используем знание о том, что не x-члены не содержат x.= f M(t1M[σ], , m, tnM[σ]) = fM(t1M[σ], tM[σ], tnM[σ]). Поэтому в этом случае (u(t/x))M[σ] = uM[σ(m/x)]. Индукция очень проста в сравнениях: если это применимо к каждому члену, который вводится в любую данную функцию, то это применимо и к выходу функ - ции вследствие рекурсивного характера оценивания членов.\n--- Страница 260 ---\nОтветы к избранным задачам  259 Задача 9.101. Например, предположим, что α равно ∀y¬(x = y + y). Здесь гово- рится, что «x является нечетным». Но α(x + y/x) равно ∀y¬(x + y = y + y), что всегда является ложным, независимо от значения σ(x). Проблема в том, что y в члене x + y «пойман» квантором ∀y. Задача 9.103. Если α является атомарной формулой, то она имеет форму Pt1 … tn. В задаче 9.100 мы показываем, что если ti является членом, то (ti(t/x))M[σ] = tiM [σ(m/x)], где m = tM[σ]. Таким образом, следующие утверждения являются эквива- лентными: M ⊨ α(t/x)[σ]; M ⊨ ((Pt1 tn)(t/x))[σ]; (t1(t/x)M[σ], , tn(t/x)M[σ]) ∈ PM; (t1M[σ(m/x)], , tnM[σ(m/x)]) ∈ PM; M ⊨ (Pt1 tn)[σ(m/x)]; M ⊨ α[σ(m/x)]. В связи с этим для любой атомной формулы α, M ⊨ α(t/x)[σ] тогда и только тогда, когда M ⊨ α[σ(m/x)]. Пусть α, β равны любым двум формулам с этим свойством. Следующие утверж - дения являются эквивалентными: M ⊨ ((α ∧ β )(t/x))[σ]; M ⊨ (α(t/x))[σ] и M ⊨ (β(t/x))[σ]; M ⊨ α[σ(m/x)] и M ⊨ β[σ(m/x)]; M ⊨ (α ∧ β )[σ(m/x)]. Более того, то же самое можно сказать о ∨ и ∧. Наконец, мы имеем следующие эквмвалентности: M ⊨ (∀y(α(t/x)))[σ]; M ⊨ α(t/x)[σ(n/y)] для всех n ∈ M. Мы применяем, что y не входит в t, для того чтобы приравнять два приведен- ных выше и два приведенных ниже утверждения: M ⊨ α[σ(m/x)(n/y)] для всех n ∈ M; M ⊨ (∀yα)[σ(m/x)].Здесь первые два идентичны вторым двум, потому что y не входит в t (в про- тивном случае t не был бы свободно замещаемым для x), поэтому два замещения не пересекаются (то есть они не влияют на какие-либо общие члены). Та же самая аргументация может быть применена к ∃ как ∀. Задача 9.104. Два правила не требуют обоснования: α(t), Γ → Δ ∀xα(x), Γ → Δ и Γ → Δ, α(t) Γ → Δ, ∃xα(x).\n--- Страница 261 ---\n260  Математическая основа Очевидно, что ∀xα(x) ⇒ α(t), поэтому если из α(t) ∧ Γ вытекает, что Δ истинно, то таковым является и ∀xα(x) ∧ Γ. Схожим образом если из Г вытекает, что Δ ∨ α(t) является истинным, то из этого также вытекает, что Δ ∨ ∃xα(x), так как α(t) ⇒ ∃xα(x). Два других менее тривиальны; на первый взгляд, не сразу ясно, что они явля- ются правильными. Ключевое понимание исходит из нашей ранее определенной номенклатуры; где t в приведенном выше примере – это конкретный член, b – свободная переменная, поэтому мы можем считать ее произвольным элементом M (или, что то же самое, любым элементом M). Давайте сначала взглянем на пра- вило правого введения для ∀: Γ → Δ, α(b) Γ → Δ, ∀xα(x). Поскольку b является произвольной (то есть не указано никакого закрепления σ для дальнейшей конкретизации смысла b), верх должен быть истинным с любым применимым x, закрепленным за b, отсюда и результат. Далее мы рассмотрим правило левого введения для ∃: α(b), Γ → Δ ∃xα(x), Γ → Δ. Опять же, ключ в том, что за b ничего не закреплено. Предпосылка заключается в том, что для любого b, α(b) ∧ Γ ⇒ Δ. В связи с этим из существования х, удовлетво- ряющего условию α(х), вытекает, что это упомянутое x может быть «подставлено вместо» b в предпосылке с целью, чтобы α(x) ∧ Γ ⇒ Δ. Задача 9.105. Пусть M равно натуральным числам. Для наших целей σ не име- ет значения, поэтому мы оставим его неопределенным. Рассмотрим следующую секвенцию: (b = y + y) → α(b), где α(b) обозначает «b является четной». Очевид- но, что эта секвенция является истинной. Рассмотрим теперь результат ∀-справа: (b = y + y) → ∀xα(x). Эта секвенция контатирует «если b является четной, то каждый x является четным», что очевидно ложно. Далее рассмотрим тривиальную секвенцию β(b) → (b > 2), где β(b) обозначает «b ≥ 3». Она очевидно является истинной, но если мы применим ∃-слева, то полу - чим: ∃xβ(x) → (b > 2). Другими словами, из существования натурального числа x ≥ 3 вытекает, что b > 2; но b является свободной переменной, она может быть равна 1 либо 0 в зависимости от σ. Задача 9.106. Пусть α(x) равно (x = 0 ∨ ∃y(x = sy)). Мы обрисуем доказатель- ство неформально, но, разумеется, доказательство может быть формализовано в арифметике Пеано на основе LK. Базовый случай: x = 0, и арифметика Пеано на основе LK легко доказывает α(0): → ∀x(x = x) 0 = 0 → 0 = 0 → 0 = 0, ∀x(x = x) ∀x(x = x) → 0 = 0 ослабление и обмен ∀-слева → 0 = 0 → 0 = 0, ∃y(0 = sy) → 0 = 0 ∨ ∃y(0 = sy)∨-справаослаблениеусечение\n--- Страница 262 ---\nПримечания  261 Индукционный шаг: показываем, что арифметика Пеано на основе LK доказы- вает ∀x(α(x) → α(sx)), то есть мы должны дать доказательство секвенции с исполь- зованием арифметики Пеано на основе LK: → ∀x(¬(x = 0 ∨ ∃y(x = sy)) ∨ (sx = 0 ∨ ∃y(sx = sy))). Это не сложно и оставлено читателю. Из формул α(0) и ∀x(α(x) → α(sx)) и с ис - пользованием аксиомы → (α(0) ∧ ∀x(α(x) → α(sx))) → ∀xα(x) теперь мы можем заключить (всего за несколько шагов): → ∀xα(x), что мы и хотели доказать. Таким образом, арифметика Пеано на основе LK доказывает ∀xα(x). 9.6. п римеЧания Эпиграфом к этой главе является цитата из плодовитого писателя-философа сэра Роджера Скратона. «Напитки в Хельсинки» (Drinks in Helsinki), глава из книги [Scruton (2005)], настолько смешна, насколько это возможно в серьезной рукопи-си, и она напоминает этому автору о его собственном опыте в Турку, Финляндия (представляя работу [Soltys (2004)]). � (множество натуральных чисел) и принцип индукции очень тесно связа- ны; строгое определение � как теоретико-множественного объекта заключает - ся в следующем: это уникальное множество, удовлетворяющее следующим трем свойствам: (i) оно содержит 0, (ii) если в нем находится n, то же самое относится и к n +1, и (iii) оно удовлетворяет принципу индукции (который в данном контекс - те формулируется следующим образом: если S есть подмножество � и S удовле- творяет указанным выше (i) и (ii), то на самом деле S = �). Ссылки в настоящем абзаце сделаны из уважения к эпохальному труду Кнута «Искусство программирования» [Knuth (1997)]. Для подробного изучения алгорит - ма Евклида см. § 1.1. Задача 9.2 проистекает из § 1.2.1, задача #8, стр. 19. См. § 2.3.1, стр. 318 за дополнительными общими сведениями по обходу деревьев. Относи-тельно истории понятия пред- и постусловий и инвариантов цикла см. стр. 17. В частности, относительно материала, связанного с расширенным алгоритмом Евклида, см. стр. 13, алгоритм E, в книге [Knuth (1997)], стр. 937 в книге [Cormen и соавт. (2009)], и стр. 292, алгоритм A.5, в книге [Delfs и Knebl (2007)]. Мы приво-дим рекурсивную версию данного алгоритма в разделе 3.4. См. книгу [Zingaro (2008)], если требуется книга, посвященная идее инвариан- тов в контексте доказательства правильности алгоритмов. Замечательным источ-ником задач по принципу инвариантности, то есть раздел 9.1.2, является глава 1 в книге [Engel (1998)]. Пример с доской 8×8 и двумя отсутствующими клетками (рис. 9.2) взят из книги [Dijkstra (1989)]. За дополнительными алгебраическими сведениями обращайтесь к книгам [Dum mit и Foote (1991)] и [Alperin и Bell (1995)]. Относительно теории чисел, в осо- бенности связанной с криптографией, см. книгу [Hoffstein и соавт. (2008)]. Класси-ческим учебником по теории чисел является книга [Hardy и Wright (1980)]. Раздел об отношениях основан на рукописных лекционных слайдах Рышар- да Яницкого. Элементарное введение в отношения можно найти в главе 8 книги\n--- Страница 263 ---\n262  Математическая основа [Rosen (2007)], а для получения очень быстрого введения в отношения (вплоть до определения классов эквивалентности) читателю предлагается прочитать восхи-тительный раздел 7 книги [Halmos (1960)]. Другой взгляд на частичные порядки предлагается в книге [Мендельсон (1970)], глава 3. В этой книге автор подходит к частичным порядкам с точки зрения бу- левой алгебры, которые определяются следующим образом: множество B вместе с двумя бинарными операциями ⋏, ⋎ (обычно обозначаемыми ∧, ∨, но мы при- меняем их для «и», «или», и поэтому здесь мы используем их «фигурные» версии, чтобы подчеркнуть, что «⋏» и «⋎» не обязательно являются стандартными буле-выми операторами) на B, операции сингулярности ′ на B и двумя конкретными элементами 0 и 1 множества B, и удовлетворяющее множество аксиом: x ⋏ y = y ⋏ x и x ⋎ y = y ⋎ x, дистрибутивность ⋏ над ⋎, и наоборот, а также x ⋏ 1 = x и x ⋎ 0 = x, x ⋎ x = 1 и x ⋏ x = 0, и наконец, 0 ≠ 1. Булева алгебра обычно обозначается секступлем B = 〈B, ⋏, ⋎, ′, 0, 1 〉, и при этом исходят из того, что она удовлетворяет только что перечисленным аксиомам. При наличии в булевой алгебре B мы определяем бинарное отношение ≼ сле - дующим образом: x ≼ y ⇔ x ⋏ y = x. Оно оказывается эквивалентным нашему понятию порядка в решетке. Затем Мендельсон абстрагирует три свойства рефлексивности, антисимметрии и тран- зитивности и говорит, что любое отношение, удовлетворяющее всем трем, явля-ется частичным порядком – и не каждый частичный порядок является решеткой. Существует ряд отличных введений в логику; например, книги [Buss (1998)] и [Bell и Machover (1977)]. Этот раздел основан на лекциях по логике Стивена Кука в Университете Торонто. Задача 9.83 является, конечно, примером общего булева «принципа двойствен- ности». Теоретико-доказательная версия этого принципа дается, например, как теорема 3.4 в книге [Мендельсон (1970)], где дуал пропозиции относительно буле- вой алгебры B является пропозицией, полученной путем замены ⋎ на ⋏ и ⋏ на ⋎ (см. стр. 293, где мы определили эти символы). Мы также заменяем 0 на 1 и 1 на 0. Тогда если высказывание выводимо из обычных аксиом булевой алгебры, то и его двойственное. Раздел 9.3.6 о правильности рекурсивных алгоритмов основан на главе 5 книги [Manna (1974)].\n--- Страница 264 ---\nБиблиография Agrawal M., Kayal N. and Saxena N. (2004). Primes is in P , Annals of Mathematics 160, 2, p. 781–793. Aleknovich M., Borodin A., Buresh-Oppenheim J., Impagliazzo R., Magen A. and Pitas- si T. (2005). Toward a model of backtracking and dynamic programming. Alford W. R., Granville A. and Pomerance C. (1994). There are infinitely many Carmi- chael numbers, Annals of Mathematics 139, 3, p. 703–722. Allan Borodin C. R., Morten N. Nielsen (2003). (incremental) priority algorithms, Al- gorithmica 37, 4, p. 295–326. Alperin J. L. and Bell R. B. (1995). Groups and Representations (Springer). Arrow K. (1951). Social Choice and Individual Values (J. Wiley).Austrin P . (2010). How hard is unshuffling a string (reply), CS Theory Stack Exchange reply to[Erickson (2010)] // http://cstheory.stackexchange.eom/q/692. Bell J. and Machover M. (1977). A course in mathematical logic (North-Holland).Berkowitz S. J. (1984). On computing the determinant in small parallel time using a small number of processors, Information Processing Letters 18, 3, p. 147–150. Borodin A. and El-Yaniv R. (1998). Online Computation and Competitive Analysis (Cambridge University Press). Bozoki S. and Rapcsak T. (2008). On saaty’s and koczkodaj’s inconsistencies of pairwise comparison matrices, Journal of Global Optimization 42, 2, p. 157–175, doi:10.1007/s10898-007-9236-z. Brin S. and Page L. (1998). The anatomy of a large-scale hypertextual web search engine, in Proceedings of the seventh international conference on World Wide Web 7, WWW7 (Elsevier Science Publishers B. V., Am-sterdam, The Netherlands, The Nether - lands), p. 107–117, URL: http://dl.acm.org/citation.cfm?id=297805.297827. Bush V. (1945). As we may think, The Atlantic Monthly.Buss S. R. (1998). An introduction to proof theory, in S. R. Buss (ed.), Handbook of Proof Theory (North Holland), p. 1–78. Buss S. R. and Soltys M. (2013). Unshuffling a square is NP-hard, Journal of Computer and System Sciences 80, 4, p. 766–776, doi: http://dx.doi.org/10.1016/j.jcss.2013.11.002, URL: http://www.sciencedirect.com/science/article/pii/S002200001300189X. Cenzer D. and Remmel J. B. (2001). Proof-theoretic strength of the stable marriage theorem and other problems, Reverse Mathematics, p. 67–103. Christian B. and Griffiths T. (2016). Algorithms to Live By: the Computer Science of Human Decisions (Henry Holt and Company, LLC). Church A. (1996). Introduction to Mathematical Logic (Princeton University Press).Clarke R. A. and Knake R. (2011). Cyber War: The Next Threat to National Security and What to Do About It (Ecco; Reprint edition). Condorcet (1785). Essai sur l’application de l’analyse ‘a la probabilite des decisions rendues a la pluralite des vois, Paris. Cook S. A. and Nguyen P . (2010). Logical Foundations of Proof Complexity (Cambridge Univeristy Press). Cook S. A. and Soltys M. (1999). Boolean programs and quantified propositional proof systems, Bulletin of the Section of Logic 28, 3, p. 119–129.\n--- Страница 265 ---\n264  Библиография Cormen T. H., Leiserson C. E., Rivest R. L. and Stein C. (2009). Introduction to Algo- rithms, 3rd edn. (McGraw-Hill Book Company), third Edition. Delfs H. and Knebl H. (2007). Introduction to Cryptography (Springer). Dickens C. (1850). David Copperfield (Penguin Classics).Dickens C. (1854). Hard Times (Everyman’s Library).Dickens C. (2013). Introduction to Computer Science using Python: A compu-tational problem solving focus (Wiley). Dijkstra E. W. (1989). On the cruelty of really teaching computing science, Commu- nications of the ACM 32, 12. Doctorow E. L. (1971). The Book of Daniel (Plume Penguin).Dorrigiv R. and Lopez-Ortiz A. (2009). On developing new models, with paging as a case study, ACM SIGACT News 40, 4. Downey A. (2015). Think Python: How to Think Like a Computer Scientist, 2nd edn. (Green Tea Press). Duda H. (1977). Zajecia pozalekcyjne z matematyki w szkole podstawowej. Zbiory i relacje (Wydawnictwa Szkolne i Pedagogiczne). Dummit D. S. and Foote R. M. (1991). Abstract Algebra (Prentice Hall).Dyer J. S. (1990). Remarks on the analytic hierarchy process, Manage. Sci. 36, 3, p. 249–258, doi:10.1287/mnsc.36.3.249, URL: http://dx.doi.org/10.1287/mnsc.36.3.249. Easley D. and Kleinberg J. (2010). Networks, crowds, and markets: reasoning about a highly connected world (Cambridge). Engel A. (1998). Problem-Solving Strategies (Springer).Erickson J. (2010). How hard is unshuffling a string? CS The¬ory Stack Exchange pos- ting // http://cstheory.stackexchange.com/questions/34/how-hard-is-unshuffling-a-string. Faliszewski P ., Hemaspaandra E. and Hemaspaandra L. A. (2010). Using complexity to protect elections, Communications of the ACM 53, 11, p. 74, doi:10.1145/1839676. 1839696, URL: http://dx.doi.org/10.1145/1839676.1839696. Fernandez A. G. and Soltys M. (2013). Feasible combinatorial matrix theory, in K. Chatterjee and J. Sgall (eds.), Mathematical Foundations of Computer Science 2013, Lecture Notes in Computer Science, Vol. 8087 (Springer Berlin Heidelberg), ISBN 978-3-642-40312-5, p. 777–788, doi: 10.1007/978-3-642-40313-2_68, URL: http://dx.doi. org/10.1007/978-3-642-40313-2_68. Franceschet M. (2011). PageRank: standing on the shoulders of giants, Communica- tions of the ACM 54, 6. Fred D. Taylor J. (2011). Software: The broken door of cyberspace security, Harvard Law School National Security Journal URL: http://harvardnsj.org/2011/02/software-the- broken-door-of-c yberspace-security/. Gale D. and Shapley L. S. (1962). College admissions and the stability of marriage, American, Mathematical Monthly 69, p. 9–14. Ginsburg S. and Spanier E. (1965). Mapping of languages by two-tape devices, Journal of the Association of Computing Machinery 12, 3, p. 423–434. Gischer J. (1981). Shuffle languages, Petri nets, and context-sensivite grammars, Communications of the ACM 24, 9, p. 597–605. Gruber H. and Holzer M. (2009). Tight bounds on the descriptional complexity of regular expressions, in Proc. Intl. Conf. on Developments in Language Theory (DLT) (Springer Verlag), p. 276–287.\n--- Страница 266 ---\nБиблиография  265 Hagele G. and Pukelsheim F. (2001). Llull’s writings on electoral systems, Studia Lulliana 41, p. 3–38, URL: https://www.math.uni-augsburg.de/htdocs/emeriti/pukelsheim/2001a. html. Halmos P . R. (1960). Naive Set Theory (Springer-Verlag). Halmos P . R. (1995). Linear algebra problem book (The mathematical association of America). Hardy G. H. and Wright E. M. (1980). An Introduction to the Theory of Num-bers, 5th edn. (Oxford University Press). Harel D. (1987). Algorithmics: The Spirit of Computing (The Addison-Wesley Pub- lishing Company), ISBN 0-201-19240-3. Harris R. (1996). Enigma (Ballantine Books).Henshall D., Rampersad N. and Shallit J. (2012). Shuffling and unshuffling, Bulletin of the EATCS 107, p. 131–142. Hoffman P . (1998). The Man Who Loved Only Numbers: The Story of Paul Erdos and the Search for Mathematical Truth (Hyperion). Hoffstein J., Pipher J. and Silverman J. H. (2008). An Introduction to Mathematical Cryptography (Springer). Hutton G. (2007). Programming in Haskell (Cambridge University Press, New York, NY, USA), ISBN 0521871727, 9780521871723. Janicki R. (2011). Approximations of arbitrary relations by partial orders: Clas¬sical and rough set models, in J. F. P . et al (ed.), Transactions on Rough Sets XIII, LNCS, Vol. 6499 (Springer-Verlag Berlin Heidelberg). Janicki R. and Zhai Y. (2011). Remarks on pairwise comparison numerical and non- numerical rankings, Lecture Notes in Computer Science 6954, p. 290–300. Jantzen M. (1981). The power of synchronizing operations on strings, Theoretical Computer Science 14, p. 127–154. Jantze M. (1985). Extending regular expressions with iterated shuffle, Theoretical Computer Science 38, p. 223–247. Jedrzejowicz J. (1999). Structural properties of shuffle automata, Grammars 2, 1, p. 35–51. Jedrzejowicz J. and Szepietowski A. (2001). Shuffle languages are in P , Theoretical Computer Science 250, 1–2, p. 31–53. Jedrzejowicz J. and Szepietowski A. (2005). On the expressive power of the shuffle op- erator matched with intersection by regular sets, Theoretical Informatics and Applica-tions 35, p. 379–388. Johnson P . (1991). The Birth of the Modern (Phoenix Giant).Kakiashvili T., Koczkodaj W. W. and Woodbury-Smith M. (2012). Improving the medi- cal scale predictability by the pairwise comparisons method: evidence from a clini-cal data study, Comput Methods Programs Biomed 105, 3, p. 210–6, doi:10.1016/j.cmpb.2011.09.011. Karp R. M. and Rabin M. O. (1987). Efficient randomized pattern-matching algo- rithms, IBM Journal ofResearch and Development 31, 2, p. 249–260. Katajainen J. and Traff J. L. (1997). A meticulous analysis of mergesort programs, in Proceedings of the Third Italian Conference on Algorithms and Complexity, CIAC ’97 (Springer-Verlag, London, UK, UK), ISBN 3-540-62592-5, p. 217–228, URL: http://dl.acm. org/citation.cfm?id=648256.752881.\n--- Страница 267 ---\n266  Библиография Kimball R. (2012). The fortunes of permanence: Culture and anarchy in an Age of Amnesia (St. Augustine’s Press). Kleinberg J. and Tardos E. (2006). Algorithm Design (Pearson Education). Knuth D. E. (1997). The Art of Computer Programming, Vol. 1, Fundamental Algo- rithms, 3rd edn. (Addison Wesley). Koczkodaj W. (1993). A new definition of consistency of pairwise compari- sons, Mathematical and Computer Modelling 18, 7, p. 79–84, doi:http://dx.doi.org/10.1016/0895-7177(93)90059-8, URL: http://www.sciencedirect.com/science/article/ pii/0895717793900598. Koczkodaj W. W., Kulakowski K. and Ligeza A. (2014). On the quality evaluation of sci- entific entities in poland supported by consistencydriven pairwise comparisons meth-od, Scientometrics 99, p. 911–926, doi: 10.1007/s11192-014-1258-y. Kozen D. (2006). Theory of Computation (Springer).Krajicek J. (1995). Bounded Arithmetic, Propositional Logic, and Complexity Theory (Cambridge). Lehtonen E. (2008). Two undecidable variants of collatz’s problems, Theoretical Com- puter Science 407, 1–3, p. 596–600, doi:10.1016/j.tcs.2008.08.029, URL: http://dx.doi. org/10.1016/j.tcs.2008.08.029. Manna Z. (1974). Mathematical Theory of Computation (McGraw-Hill Computer Sci- ence Series). Mansfield A. (1982). An algorithm for a merge recognition problem, Discrete Applied Mathematics 4, 3, p. 193–197, doi: http://dx.doi.org/10.1016/0166-218X(82)90039-7, URL: http://www.sciencedirect.com/science/article/pii/0166218X82900397. Mansfield A. (1983). On the computational complexity of a merge recognition prob- lem, Discrete Applied Mathematics 1, 3, p. 119–122. Mayer A. J. and Stockmeyer L. J. (1994). The complexity of word problems – this time with interleaving, Information and Computation 115, p. 293–311. Mendelson E. (1970). Boolean algebra and switching circuits (McGraw Hill).Mhaskar N. and Soltys M. (2015). String shuffle: Circuits and graphs, Journal of Dis- crete Algorithms 31, 0, p. 120–128, doi: http://dx.doi.org/10.1016/j.jda.2015.01.003, URL: http://www.sciencedirect.com/scienc e/article/pii/S1570866715000040, 24th Interna- tional Workshop on Combinatorial Algorithms (IWOCA 2013). Miller G. A. (1995). Wordnet: A lexical database for english, Communications of the ACM . Ogden W. F., Riddle W. E. and Rounds W. C. (1978). Complexity of expressions allowing concurrency, in Proc. 5th ACM Symposium on Principles of Programming Languages (POPL), p. 185–194. Papadimitriou C. H. (1994). Computational Complexity (Addison-Wesley).Papadimitriou C. H. and Steiglitz K. (1998). Combinatorial Optimization: Algorithms and Complexity (Dover). Press W. H., Vetterling W. T., Teukolsky S. A. and Flannery B. P . (2007). Numerical Reci- pes: The Art of Scientifc Computing, 3rd edn. (Cambridge University Press). Reingold O. (2005). Undirected st-connectivity in log-space, in STOC’05: Proceedings of the thirty-seventh annual ACM symposium on Theory of computing, p. 376–385. Renatus P . F. V. (4th or 5th century AD). De re militari.Riddle W. E. (1973). A method for the description and analysis of complex software systems, SIGPLAN Notices 8, 9, p. 133–136.\n--- Страница 268 ---\nБиблиография  267 Riddle W. E. (1979). An approach to software system modelling and analysis, Com- puter Languages 4, 1, p. 49–66. Rosen K. H. (2007). Discrete Mathematics and Its Applications, 6th edn. (Mc-Graw Hill). Saaty T. L. (1977). A scaling method for priorities in hierarchical structures, Journal of Mathematical Psychology 15, p. 234–281. Schwartz R. L., Foy B. D. and Phoenix T. (2011). Learning Perl, 6th edn. (O’Reilly Media, Inc.), ISBN 1449303587, 9781449303587. Scruton R. (2005). Gentle Regrets: Thoughts from a Life (Continuum). Scruton R. (2011). Beauty: A Very Short Introduction (Oxford University Press).Scruton R. (2014). The soul of the world (Princeton University Press).Scruton R. (2015). Living with a mind, First Things.Shaw A. C. (1978). Software descriptions with flow expressions, IEEE Transactions on Software Engineering SE-4, 3, p. 242–254. Shoudai T. (1992). A P-complete language describable with iterated shuffle, Informa- tion Processing Letters 41, 5, p. 233–238. Shustek, L. (2009). Interview, Communications of the ACM 52, 3, pp. 38–41.Singh S. (1999). The Code Book: The evolution of secrecy, from Mary, Queen of Scots, to Quantum Cryptography (Doubleday). Sipser M. (2006). Introduction to the Theory of Computation (Thompson), second Edition. Solovay R. and Strassen V. (1977). A fast monte-carlo test for primality, SIAM Journal of Computing 6, p. 84–86. Soltys M. (2002a). Berkowitz’s algorithm and clow sequences, Electronic Journal of Linear Algebra 9, p. 42–54. Soltys M. (2002b). Extended Frege and Gaussian Elimination, Bulletin of the Section of Logic 31, 4, p. 1–17. Soltys M. (2004). LA, permutations, and the Hajos calculus, in J. Diaz, J. Karhumaki, A. Lepisto and D. Sannella (eds.), Automata, Languages and Programming, 31st Inter - national Colloquium (ICALP), Lecture Notes in Computer Science, Vol. 3142, European Association of Theoretical Computer Science, University of Turku (Springer), p. 1176–1187, doi: http://dx.doi.org/10.1007/978-3-540-27836-8_97. Soltys M. (2005). Feasible proofs of matrix properties with Csanky’s algoritm, in C.-H. L. Ong (ed.), Computer Science Logic, 19th International Workshop (CSL), Lec - ture Notes in Computer Science, Vol. 3634, Oxford University Computing Laboratory (Springer), p. 493–508, doi: http://dx.doi.org/10.1007/11538363_34. Soltys M. (2009). An introduction to computational complexity (Jagiellonian Univer - sity Press). Soltys M. (2013). Circuit complexity of shuffle, in T. Lecroq and L. Mouchard (eds.), International Workshop on Combinatorial Algorithms 2013, Lecture Notes in Computer Science, Vol. 8288 (Springer), p. 402–411, doi:10. 1007/978- 3- 642-45278-9.34. Soltys M. and Cook S. (2004). The proof complexity of linear algebra, Annals of Pure and Applied Logic 130, 1–3, p. 207–275, doi: http://dx.doi.org/10.1016/j.apal.2003.12.005. Su F. E. (2010). Teaching research: encouraging discoveries, American Mathematical Monthly . Thurstone L. L. (1927). A law of comparative judgement, Psychological Review 34, 278–286.\n--- Страница 269 ---\n268  Библиография van Vliet H. (2000). Software Engineering: Principles and, Practice, 2nd edn. (Wiley). Velleman D. J. (2006). How To Prove It, 2nd edn. (Cambridge University Press).von zur Gathen J. (1993). Parallel linear algebra, in J. H. Reif (ed.), Synthesis of Parallel Algorithms (Morgan and Kaufman), p. 574–617. von zur Gathen J. and Gerhard J. (1999). Modern computer algebra (Cambridge Uni- versity Press). Warmuth M. K. and Haussler D. (1984). On the complexity of iterated shuffle, Journal of Computer and System Sciences 28, 3, p. 345–358. Whitman W. (1892). Song of myself.Zhai Y. (2010). Pairwise comparisons based non-numerical ranking, Ph.D. thesis, McMas ter University. Zingaro D. (2008). Invariants: A generative approach to programming (College Pub- lications).\n--- Страница 270 ---\nПредметный указатель C CFG. См. Контекстно-свободная грамматика CFL. См. Контекстно-свободный язык CIP . См. Принцип полной индукцииCNF. См. Нормальная форма Хомского E endsequent. См. Конечная секвенция F FIFO. См. Первым вошел/первым вышелFWF. См. Сброс при заполнении G gcd. См. Наибольший общий делительgit bisect, команда, 68 GNFA. См. Обобщенный недетерминированный конечный автомат gnuplot, консольная программа, 18, 96 gzip, вспомогательная программа, 52 L LFD. См. Наибольшее расстояние впередLMS. См. Наибольшая монотонная подпоследовательность LNP . См. Принцип наименьшего числаLRU. См. Наименее недавно использованная страница M matplotlib, библиотека Python, 35MCPC. См. Модифицированная задача соответствий Поста MCST. См. Граф, остовное дерево минимальной стоимости MTF. См. Алгоритм перемещения в начало N NP-трудный, 75 криптография, 128O OpenSSL, криптографическая библиотека, 134OSPF. См. Открытый протокол предпочтения кратчайшего пути P PageRank, алгоритм, 22 PDA. См. Магазинный автоматPKC. См. Криптосистема с публичным ключом poset. См. Частичный порядок Python, строковое значение срез, 19 R random, библиотека Python, 96 regexp. См. Регулярное выражение RFC. См. Рабочее предложение RSA. См. Криптография с публичным ключом, криптосистема S SSL, протокол безопасности, 134 T TLS. См. Протокол безопасности транспортного уровня TM. См. Машина Тьюринга V V-алгебра, 171 V-член, 171 W WWW. См. Всемирная паутина А Автомат диаграмма переходов, 157на членах, 171 сложность преобразования, 167 таблица переходов, 157 эквивалентность и минимизация, 167\n--- Страница 271 ---\n270  Тематический указатель язык, 158 Алгоритм CYK, 177, 178 c-состязательный, 96 F1(x, y), 228F2(x, y), 228F3(x, y), 228F(x, y), 227PageRank, 22аппроксимационный, 78Беллмана–Форда, 75Берковица, 115, 145 быстрая сортировка, 68выбор мероприятия, 89гауссова редукция решетки, 67, 144 гауссово исключение (метод Гаусса), 138, 140 Гейла–Шепли, 26Грама–Шмидта, 144Дейкстры, 48, 59, 70 деления, 15динамический, 72 недетерминированный конечный автомат в регулярное выражение, 164 Евклида, 17 расширенный, 18, 31, 124, 132, 214, 249, 261 расширенный рекурсивный, 67 жадный, 37заполнения таблицы, 168идеального паросочетания, 115код Хаффмана, 51, 52 Краскала, 12, 38 Лас-Вегас, 118малые и гигантские шаги Шэнка, 123 маркировочный. См. Маркировочные алгоритмы Монте-Карло, 115 наибольшая общая подпоследовательность (LMS), 73онлайновый, 92 наименее недавно использованное (LRU), 100первым вошел/первым вышел (FIFO), 100сброса при заполнении (FWF), 105 отсчитывания сдачи, 47 офлайновый, 92 наибольшее расстояние вперед (LFD), 97, 105палиндромов, 18 перемещения в начало (MTF), 93 планирование заданий, 45простой задачи о рюкзаке (SKS), 77 Рабина-Миллера, 120 свидетель, 121 разделяй и властвуй, 61 рандомизированный, 113 ранжирования, 21 рекурсивного двоичного умножения, 65 рекурсивный, 227 Савича, 65, 66, 70 слияния двух списков, 61 слияния компонент, 39сопоставления с образцом, 117 сортировка слиянием, 70 сортировки слиянием, 62 степеней двойки, 33 Улама, 20Флойда, 74 Хассе, 29Хопкрофта–Карпа, 60 Чанки, 145 Алгоритмически распознаваемый язык, 182 Алфавит, 155Амортизированная стоимость, 94 Амплификация, 116 Аномалия Белади, 100, 102 Антецедент, 232Арифметика Пеано, 235, 239 язык, 235 Асимптотически плотная граница, 15 Атака «человек-в-середине», 124Атомарная формула, 235 Б База данных о состоянии связи, 50Базис, 138 Базовый случай, 208Бесплатная транспозиция, 93 Бесплатное перемещение, 93Булева алгебра, 262 Булевы связки, 13 Буш, Ванневар, 22 В Валидный, 231, 240 Веб-страница, 66Волокита, 44\n--- Страница 272 ---\nТематический указатель  271 Всемирная паутина, 66 задача связности, 66 Выбор мероприятий, 79 допустимость, 80 мероприятие, 79 Г Гауссово исключение, 138Гиперссылка, 66Гипотеза Коллатца, 21Глобальный оптимум, 37Грамматика контекстно-свободная. См. Контекстно-свободная грамматикаконтекстно-чувствительная. См. Контекстно-чувствительная грамматика Граф ациклический, 38вершина, 37 степень, 37 двудольный, 48дерево, 38 инфиксное, 210 лист, 38 остовное дерево минимальной стоимости (MCST), 37постфиксное, 210префиксное, 210 достижимость, 65, 70 неориентированный, 37орграф, 73ориентированный, 37, 73 остовное дерево, 38остовной лес, 40паросочетание, 48путь, 37связная компонента, 39связный, 37узел, 37цикл, 37явное представление против неявного, 66 Грубая сила, 211Группа, 212, 214 GL(n, �), 215 (Q, +), 215 (� ∗ n), 215 (�n, +), 215 абелева, 215ассоциативный закон, 215 гомоморфизм, 217закон существования нейтрального элемента, 214закон существования обратного элемента, 215замыкание, 214изоморфизм, 217коммутативный закон, 215левое сомножество, 215 подгруппа, 215порядок, 215симметрическая, 215 Д Двусвязный список, 101 встраивание, 102операции с указателем, 101 Дейкстра, Эдсгер, 49, 59, 70 Деление. См. АлгоритмДеление при определении простого числа, 213Делитель (фактор), 213Демон маршрутизации, 49Дерево разбора, 173Детализации программы, 77Детерминированный конечный автомат, 156 алфавит (Σ), 156 для языка, 157исходное состояние (q 0), 157 начальное состояние (q0), 157 отклонить, 157оценивание, 157 переходная функция (δ), 156 принимающие состояния (F ), 157 принять, 157расширенная переходная функция (δ), 157 сложность преобразования, 167состояния (Q), 156 финальные состояния (F ), 157 эквивалентность с недетерминированным конечным автоматом, 160язык, 158 Детерминированный магазинный автомат однозначность, 176 префиксное свойство, 176\n--- Страница 273 ---\n272  Тематический указатель принятие, 176 Джойс, Джеймс, 36 Диаграмма Хассе, 222Динамическое программирование. См. АлгоритмДКА. См. Детерминированный конечный автомат Доказательство в пропозициональном исчислении PK, 232 Доступ к списку, 92 З Завершение, 13 Задания с предельными сроками и прибылями, 44 Задания с указанием предельных сроков, длительностей и прибылей, 82 Задача дискретного логарфимирования, 123Диффи–Хеллмана, 131Какутани, 21 о стабильном брачном союзе, 24 блокирующая пара, 25 допустимый союз, 27нестабильный союз, 24 оптимальный по юноше, 27 пессимистичным по юноше, 27 соответствий Поста, модифицированная, 190 Закон де Моргана, 231Закрепление значения за объектом, 236 Закрепление истинностного значения, 231 Замещение страниц, 97 Замещение страниц по требованию, 98 Замкнутый, 236 Звезда Клини, 156 И Идеальное паросочетание, 114Инвариантность, 211 метод, 211 Инвариант цикла, 14 Индукционная схема, 239 Индукционный шаг, 208 Индукция, 208 базовый случай, 208 индукционный шаг, 208 принцип, 208 Интерпретация, 236Инфикс, 235 Инфимум, 96 К Китайская теорема об остатках, 216 Кнут, Д., 261 Коды Хаффмана, 51 Конгруэнтность, 213Конечная секвенция, 232Конкурентый анализ. См. Состязательный анализКонтекстно-свободная грамматика, 172 генерирование, 177дерево разбора, 173деривация, 173 левосторонняя, 173правосторонняя, 173 для алгебраических выражений, 172достижимая, 177единичная продукция, 177 левая сентенциальная форма, 175наличие пустого значения, 177неоднозначная, 173полезная, 177преобразование в нормальную форму Хомского, 176сентенциальная форма, 173эквивалентность с магазинным автоматом, 174язык, 173 Контекстно-чувствительная грамматика, 181 Кратчайший путь для всех пар, 73 Криптография, 11 Криптосистема RSA, 127 Диффи–Хеллмана, 122Меркла–Хеллмана, 128Эль-Гамаля, 124 Криптосистема с публичным (открытым) ключом, 122 дешифрование, 122 зашифрованное текстовое сообщение, 122ключи, 122потайная информация, 122приватный ключ, 122публичный ключ, 122секретный ключ, 122шифрование, 122\n--- Страница 274 ---\nТематический указатель  273 Кук, Стивен, 12 Л Лемма о замене, 42 Шварца–Зиппеля, 115 Линейно-независимый, 138Логика, 229Логика Хоара, 13Логические аксиомы, 232Логически эквивалентный, 237 Логическое следствие, 231, 237 Локальный оптимум, 37 М Магазинный автомат, 174 детерминированный, 176конфигурация, 174отклонить, 174 принять, 174эквивалентность с контекстно-свободной грамматикой, 174язык, 158 Манхэттенский проект, 135 Маркировочные алгоритмы, 103 k-членное фазовое разбиение, 103 Матрица попарных сравнений, 28 непротиворечивая, 28 Матрица смежности, 37Матрица Теплица, 146 Матроид, 59 Машина Тьюринга, 75, 181 кодировки, 184конфигурация, 182 недетерминированная, 182 недетерминированная и детерминированная эквивалентность, 182 отклонить, 182 переходная функция, 182 перечислимая, 187 перечислитель, 187 порождение, 182 принять, 182 разрешимый язык, 182 распознаваемый язык, 182 редукция, 188 рекурсивный язык, 182робастность, 182универсальная, 185 язык, 182 Метод Монте-Карло, 135Многократное возведение в квадрат, 120, 123 Модель, 236Модель доступа к динамическому списку, 96Модель доступа к статическому списку, 93Модель страничного отказа, 98Модифицированная задача соответствий Поста, 189, 190 Модус попенс, 208Мультимножество, 47 Н Надлежащая формула, 238Надлежащий член, 238Наибольшая монотонная подпоследовательность, 73Наибольшее расстояние вперед (LFD), 105Наибольший общий делитель (greatest common divisor, gcd), 17Наименее недавно использованная страница, 100Недетерминированная машина Тьюринга, 182Недетерминированный конечный автомат, 159 ε-замыкание, 160для десятичных чисел, 160обобщенный, 165отклонить, 159переходное отношение (δ), 159 преобразование в детерминированный конечный автомат, 161преобразование в регулярное выражение, 165 принять, 159 расширенное переходное отношение (δ), 160 сложность преобразования, 167 эквивалентность с детерминированным конечным автоматом, 160язык, 158 Независимое множество, 59 Неразрешимость, 186 Неразрешимый, 75\n--- Страница 275 ---\n274  Тематический указатель Неудовлетворимость, 231 НКА. См. Недетерминированный конечный автоматНорма, 138 Нормальная форма Хомского, 176 преобразование в, 176 О «O» большое, 15 «О» малое, 15 Область действия, 236 Обмен ключами Диффи–Хеллмана, 122 Обобщенный недетерминированный конечный автомат, 165Общая задача о рюкзаке, 79 Ограниченный, 236 Односторонняя функция, 124 Опорный элемент, 138 Оптимальный офлайновый алгоритм, 97 Оптимизационные задачи, 12 Оптимум, 78 cтабильный брачный союз, 24отсчитывание сдачи, 57 офлайновый алгоритм, 110 офлайновый алгоритм замещения страниц, 105 паросочетание, 34 планирование заданий, 44представление строки и коды Хаффмана, 51 разламывание шоколадной плитки, 210 уникальное расписание, 47 Ортогональный, 138 Основное семантическое определение (BSD), 236 Останов. См. Завершение Остаток от деления, 15Остовное дерево минимальной стоимости, 37 Открытый протокол предпочтения кратчайшего пути, 49 Отношение, 217 антисимметричное, 217детализация, 221 замыкание, 218 композиция, 217 матричное представление, 218представление в виде ориентированного графа, 218 разбиение, 220 мельчайшее, 220 рефлексивное, 217 симметричное, 217транзитивное, 217 эквивалентность, 220 класс, 220 Отношения, 217 П Палиндром, 18Первопорядковая логика, 235 L-член, 235 арность, 235 язык, 235 Первым вошел/первым вышел (FIFO), 100Перетасовка, 84 квадрат, 84 Переходная функция, 156Переходное отношение, 159Перечислитель, 187 Перспективная задача, 78 Перспективное частичное решение, 11Перспективный, 40Планирование заданий, 82Платное перемещение, 93Полная правильность. См. ПравильностьПопадание, 97 Попарные сравнения, 27 Последовательность Фибоначчи, 118, 209, 244 Построение подмножеств, 160 Построчно-ступенчатая форма, 138 Постусловие. См. Правильность Потенциальная функция, 94 Правильность, 13 полная, 14постусловие, 13предусловие, 13частичная, 13 Предусловие. См. ПравильностьПрефиксная форма записи, 235 Префиксный код, 51 Принцип инверсии, 234индукции, 208наименьшего числа, 16, 210 полной индукции, 210\n--- Страница 276 ---\nТематический указатель  275 разумности правила, 233 Проверка простоты, 119 Проверка Ферма, 119 свидетель, 119 Прокрастинация. См. Волокита Промах, 97Промежуток, 138 Пропозициональный атомы, 230переменная, 230 формула, 230 Простая задача о рюкзаке, 75 жадная попытка, 78криптография, 128 общая, 79 рассредоточенный, 78 Простое число, 213Протокол безопасности транспортного уровня, 134Протокол безопасности уровня защищенных cокетов, 134Псевдопростое число, 119 Р Рабочая группа по стандартам для сети интернет, 49 Рабочее предложение, 49 1951, 1952, 52 2328, 49 2338, 50 Разностная машина Чарлза Бэббиджа, 155, 205 Разрешимость, 184 дополнение, 185 задача соответствий Поста и модифицированная задача соответствий Поста, 190 контекстно-свободных языков, 184 регулярных выражений, 184 Разрешимый язык, 182Расписание, 44 допустимое, 44, 82 перспективное, 45 Распознаваемый язык, 182 Распределительная сложность, 96 Расширенная переходная функция (δ ), 157 Расширенное переходное отношение, 160 Регулярное выражение, 162 алгебраические законы, 165преобразование из недетерминированного конечного состояния, 163 сложность преобразования, 167 Регулярные операции, 158Регулярный язык, 158 Редукция, 83, 117 Рейнгольд, Омер, 70Рекуррентное соотношение, 71 основной метод, 71 Рекурсивно перечислимый, 182 Рекурсивный вывод, 173Рекурсивный язык, 182Решетка, 144, 223 ассоциативность, 224 завершенная, 224идемпотентность, 224коммутативность, 224поглощение, 224 Савич, Уолтер, 65, 70 Сброс, 105Сброс при заполнении (FWF), 105Сверхвозрастающая последовательность, 128 Свободно замещаемый, 238 Свободный, 236Секвенция, 232Семантика Тарского, 236Сентенциальная форма, 173 Сентенция, 236Символьная цепочка. См. СтрокаСистема перезаписи, 181Система с виртуальной памятью, 97Скалярное произведение, 138Слово, 155 длина, 155заполнение, 159конкатенация, 156подпоследовательность, 156 подслово, 156префикс, 156пустое, 155смежное расположение, 156суффикс, 156 Сложность алгоритмов, 14Сложность худшего случая, 15Снятие отпечатков пальцев, 118Сопоставление с образцом, 117Сортировка слиянием, 61\n--- Страница 277 ---\n276  Тематический указатель Состояния блочные, 168 различимые, 168эквивалентные, 168 Состязательное соотношение, 96 Состязательный анализ, 11, 96 Средний случай, 96 Стабильный брачный союз, 24 Стандартная структура, 237 Страницы, 97 Страничный отказ, 97Строка, 155 длина, 155заполнение, 159 конкатенация, 156 подпоследовательность, 156 подслово, 156 префикс, 156пустая, 155смежное расположение, 156 суффикс, 156хорошо сформированная, 184 Структура, 236 Структура независимости, 59 Структурная индукция доказательство леммы 9.78 (о весах пропозициональных формул), 230 доказательство теоремы о двойственности, 231 доказательство теоремы о замещении, 238определение L-члена, 235 пропозициональные формулы, 230 семантика Тарского первопорядковых формул, 236 семантика Тарского первопорядковых членов (термов), 236 Структурная лингвистика, 172Сукцедент, 232 Суммирование сплошной подпоследовательности, 83Схема замещения страниц, 97 Т Тавтология, 231Тезис Черча–Тьюринга, 185 Теллер, Эдвард, 135Теорема китайская теорема об остатках, 216китайская теорема об остатках, версия II, 217 Клини, 227Кнастера–Тарского (1), 225 Кнастера–Тарского (2), 225 Кнастера–Тарского для конечных множеств, 225 Лагранжа, 119, 215 Майхилла–Нероуда, 170малая теорема Ферма, 119, 120, 133, 214 об интерполяции Крейга, 231 об уникальной читаемости, 230 о двойственности, 231 о замещении, 238о полноте пропозиционального исчисления PK, 234 о разумности пропозиционального исчисления PK, 233 о распределении простых чисел, 118, 122 основная теорема алгебры, 115 основная теорема арифметики, 213, 244 Райса, 189Эйлера, 133, 216 Теория групп, 214. См. Группа Теория чисел, 212 Теплица, матрица, 146 Точечное произведение. См. Скалярное произведение Трудолюбивый бобер, 187 У Удовлетворимо, 231 Удовлетворяет, 231 Улам, Станислав, 135 Умножение двоичных чисел, 63, 70 Универсальная машина Тьюринга, 185 Универсальный язык, 185 Универсум дискурса, 236 Усиление. См. Амплификация Условие регулярности, 71 Ф Фазы, 103 k-членное фазовое разбиение, 103 Фактор. См. Делитель, множительФон Нейман, Джон, 70 Функция ceil, 18 floor, 18 неподвижная точка, 224, 228\n--- Страница 278 ---\nТематический указатель  277 область определения, 228 тотальная, 220, 228 эйлерова, 214 Х Хоар, К. А. Р ., 10Хорошо сформированная строка, 13 Хорошо сформированный, 14, 230 Худший случай, 97 Ц Цедент, 232 Ч Частичная правильность. См. правильность алгоритмов Частичный порядок, 221 верхняя граница, 223 вполне упорядоченный, 223инфимум, 223 лексикографический, 222 линейный, 221максимальный, 223минимальный, 223 наибольшая нижняя граница, 223 наибольший элемент, 223наименьшая верхняя граница, 223наименьший элемент, 223 несравнимый, 221 нижняя граница, 223плотный, 223 покомпонентный, 222 полный, 221сравнимый, 221стратифицированный, 222супремум, 223 функция восходяще-непрерывная, 226 монотонная, 224неподвижная точка, 224непрерывная, 226 нисходяще-непрерывная, 226 четкий, 221 Частное, 15Число Кармайкла, 119 Число Фибоначчи, 118 Ш Шифрование с публичным (открытым) ключом, 122RSA, 127 обмен ключами Диффи–Хеллмана, 122 Эль-Гамаль, 124 эфемерный ключ, 124 Э Эквивалент, 231 Элементарная матрица, 139Элементы Евклида, 17 Я Язык, 156 автомата, 158 алгоритмически распознаваемый, 182замыкание Клини, 158звезда Клини, 158 индекс, 170 конкатенация, 158 контекстно-свободный, 172 замыкание, 180лемма о накачке, 179 неразрешимые свойства, 194разрешимость, 184 контекстно-чувствительный, 181нерегулярный, 169 объединение, 158 отступ, 172перечислимый, 188попарно-различающий, 170 разрешимый, 182разрешимый по Тьюрингу, 182 распознаваемый, 182 регулярный, 158, 162 замыкание, 166лемма о накачке, 169 разрешимость, 184 регулярность детерминированного и недетерминированного конечных автоматов, 162 теорема Майхилла–Нероуда, 170 рекурсивно перечислимый (RE), 182рекурсивный, 182 робастность, 182 свойство, 189 теорема Райса, 189 универсальный, 185 Яницкий, Рышард, 261\n--- Страница 279 ---\nКниги издательства «ДМК Пресс» можно заказать в торгово-издательском холдинге «Планета Альянс» наложенным платежом, выслав открытку или письмо по почтовому адресу: 115487, г. Москва, 2-й Нагатинский пр-д, д. 6А. При оформлении заказа следует указать адрес (полностью), по которому должны быть высланы книги; фамилию, имя и отчество получателя. Желательно также указать свой телефон и электронный адрес. Эти книги вы можете заказать и в интернет-магазине: www.a-planeta.ru. Оптовые закупки: тел. (499) 782-38-89. Электронный адрес: books@alians-kniga.ru. Майкл Солтис Введение в анализ алгоритмов Главный редактор Мовчан Д. А. dmkpress@gmail.com Перевод Логунов А. В. Корректор Синяева Г. И. Верстка Чаннова А. А. Дизайн обложки Мовчан А. Г. Формат 70×100 1/16. Гарнитура «PT Serif». Печать офсетная. Усл. печ. л. 22,59. Тираж 200 экз. Веб-сайт издательства: www.dmkpress.com",
      "debug": {
        "start_page": 209,
        "end_page": 279
      }
    }
  ]
}
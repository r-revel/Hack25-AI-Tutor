{
  "title": "Использование Managed Kafka® для фоновой обработки задач",
  "chapters": [
    {
      "name": "Использование Managed Kafka® для фоновой обработки задач",
      "content": "Практические руководства Evolution    \n\n # Использование Managed Kafka® для фоновой обработки задач   Эта статья полезна?          \nС помощью этого руководства вы сконфигурируете Managed Kafka® как брокер сообщений, связав его с сервисами publisher и subscriber, работающими на виртуальной машине Ubuntu 22.04.\nВы будете использовать виртуальную сеть VPC и подсети для связи виртуальной машины и сервиса Managed Kafka®.\nВы будете использовать следующие сервисы:\n- Виртуальные машины — сервис, в рамках которого предоставляется виртуальная машина.\n- Managed Kafka® — сервис для развертывания и управления кластерами Kafka®.\n- Публичный IP-адрес — для доступа к сервису через интернет.\n- VPC — изолированная виртуальная сеть для создания безопасной инфраструктуры.\nШаги:\n1. Разверните необходимые ресурсы в облаке.\n2. Настройте окружение на виртуальной машине.\n3. Разработайте сервисы publisher и subscriber.\n4. Протестируйте работу очереди сообщений.\n5. Удалите доступ по SSH для виртуальной машины.\n\n## Перед началом работы\n1. Зарегистрируйтесь в личном кабинете Cloud.ru.\nЕсли вы уже зарегистрированы, войдите под своей учетной записью.\n2. Создайте и загрузите SSH-ключ в облако.\n\n## 1. Разверните необходимые ресурсы в облаке\n1. Создайте виртуальную сеть с названием pub-sub-VPC.\n2. Создайте подсеть со следующими параметрами:\n- Название: pub-sub-subnet.\n- Адрес: 10.10.1.0/24.\n- VPC: pub-sub-VPC.\n- DNS-серверы: 8.8.8.8\nУбедитесь, что в личном кабинете на странице сервиса VPC:\n- отображается сеть pub-sub-VPC;\n- количество подсетей — 1;\n- подсеть pub-sub-subnet доступна.\n3. Создайте виртуальную машину со следующими параметрами:\n- Название: pub-sub.\n- Образ: Публичные → Ubuntu 22.04.\n- Метод аутентификации: SSH-ключ и пароль.\n- SSH-ключ: ваш SSH-ключ.\n- Пароль: ваш пароль.\n- Имя хоста: pub-sub.\n- Подключить публичный IP: включено.\n- Тип IP-адреса: Прямой.\n- Группы безопасности: SSH-access_ru.AZ-1.\n- Подсеть: pub-sub-subnet.\n- Гарантированная доля vCPU: 10%.\n- vCPU: 1.\n- RAM: 1.\nУбедитесь, что в личном кабинете на странице сервиса «Виртуальные машины» отображается виртуальная машина pub-sub в статуса «Запущена».\n4. Создайте кластер Managed Kafka® со следующими параметрами:\n- Название: pub-sub.\n- Версия Kafka: 3.9.0.\n- Брокеры: 1.\n- vCPU: 4.\n- RAM: 16.\n- Подсеть: pub-sub-subnet.\nУбедитесь, что в личном кабинете на странице сервиса Managed Kafka® отображается кластер pub-sub в статусе «Доступен».\n\n## 2. Настройте окружение на виртуальной машине\n1. Подключитесь к виртуальной машине pub-sub через серийную консоль.\n2. Активируйте сетевой интерфейс:\n```\nsudo cloud-init cleansudo cloud-init init\n```\n3. Подключитесь к виртуальной машине pub-sub по SSH.\n4. Обновите систему и установите необходимые пакеты:\n```\nsudo apt update && sudo apt upgrade -ysudo apt install -y python3 python3-venv python3-pip kafkacat\n```\n\n## 3. Разработайте сервисы publisher и subscriber\n1. Создайте директорию «pubsub» и перейдите в нее:\n```\nmkdir pubsubcd pubsub\n```\n2. Создайте файл publisher.py с помощью команды:\n```\nnano publisher.py\n```\n3. Скопируйте код в файл:\n```\nimport argparseimport jsonimport osimport sysimport uuidfrom datetime import datetime, timezone\nfrom kafka import KafkaProducerfrom dotenv import load_dotenv\n\ndef build_payload(message: str) -> str:   \"\"\"Return JSON-encoded message with id and timestamp.\"\"\"   return json.dumps(      {            \"id\": str(uuid.uuid4()),            \"timestamp\": datetime.now(timezone.utc).isoformat(),            \"message\": message,      }   )\n\ndef main() -> None:   load_dotenv()\n   parser = argparse.ArgumentParser(description=\"Publish a message to Kafka.\")   parser.add_argument(      \"message\",      nargs=\"?\",      help=\"Message text; if omitted you will be prompted.\",   )   parser.add_argument(      \"--topic\",      default=os.getenv(\"TOPIC\", \"messages\"),      help=\"Kafka topic name (default: messages)\",   )\n   args = parser.parse_args()   msg_text = args.message or input(\"Enter your message: \")\n   kafka_brokers = os.getenv(\"KAFKA_BROKERS\", \"\").split(\",\")   kafka_writer_username = os.getenv(\"KAFKA_WRITER_USERNAME\")   kafka_writer_password = os.getenv(\"KAFKA_WRITER_PASSWORD\")\n   if not kafka_brokers or not kafka_writer_username or not kafka_writer_password:      print(\"Kafka brokers, writer username and writer password are required\")      sys.exit(1)\n   try:      producer_config = {            'bootstrap_servers': kafka_brokers,            'value_serializer': lambda v: v.encode('utf-8'),            'security_protocol': 'SASL_PLAINTEXT',  # Changed from SASL_SSL            'sasl_mechanism': 'SCRAM-SHA-512',            'sasl_plain_username': kafka_writer_username,            'sasl_plain_password': kafka_writer_password,            'api_version': (2, 0, 0),      }\n      print(f\"Connecting to Kafka brokers: {kafka_brokers}\")      producer = KafkaProducer(**producer_config)\n      print(f\"Sending message to topic: {args.topic}\")      future = producer.send(args.topic, build_payload(msg_text))      result = future.get(timeout=30)\n      producer.flush()      producer.close()\n      print(f\"Published to topic '{args.topic}' (partition: {result.partition}, offset: {result.offset}).\")\n   except Exception as exc:      print(f\"Kafka connection failed: {exc}\", file=sys.stderr)      sys.exit(1)\n\nif __name__ == \"__main__\":   main()\n```\n4. Создайте файл subscriber.py с помощью команды:\n```\nnano subscriber.py\n```\n5. Скопируйте код в файл:\n```\nimport argparseimport jsonimport osimport sys\nfrom kafka import KafkaConsumer, TopicPartitionfrom dotenv import load_dotenv\n\ndef pretty_print(raw: str) -> None:   try:      print(json.dumps(json.loads(raw), indent=2))   except json.JSONDecodeError:      print(f\"[non-JSON] {raw!r}\")\n\ndef main() -> None:   load_dotenv()\n   parser = argparse.ArgumentParser(description=\"Subscribe without group coordination.\")   parser.add_argument(\"--topic\", default=os.getenv(\"TOPIC\", \"messages\"))   args = parser.parse_args()\n   brokers = os.getenv(\"KAFKA_BROKERS\", \"\").split(\",\")   username = os.getenv(\"KAFKA_READER_USERNAME\")   password = os.getenv(\"KAFKA_READER_PASSWORD\")\n   if not kafka_brokers or not kafka_writer_username or not kafka_writer_password:      print(\"Kafka brokers, writer username and writer password are required\")      sys.exit(1)\n   try:      consumer = KafkaConsumer(            bootstrap_servers=brokers,            security_protocol=\"SASL_PLAINTEXT\",            sasl_mechanism=\"SCRAM-SHA-512\",            sasl_plain_username=username,            sasl_plain_password=password,            value_deserializer=lambda v: v.decode(\"utf-8\"),            auto_offset_reset=\"earliest\",            enable_auto_commit=False,            group_id=None,  # no group join            api_version=(2, 0, 0),      )\n      parts = consumer.partitions_for_topic(args.topic)      if not parts:            print(f\"Topic '{args.topic}' not found or no partitions.\", file=sys.stderr)            sys.exit(1)\n      assignment = [TopicPartition(args.topic, p) for p in sorted(parts)]      consumer.assign(assignment)      consumer.seek_to_beginning(*assignment)\n      print(f\"Assigned without group to partitions: {assignment}\")      for msg in consumer:            pretty_print(msg.value)\n   except Exception as exc:      print(f\"Kafka connection failed: {exc}\", file=sys.stderr)      sys.exit(1)\n\nif __name__ == \"__main__\":   main()\n```\n6. Создайте файл requirements.txt с помощью команды:\n```\nnano requirements.txt\n```\n7. Скопируйте код в файл:\n```\nkafka-python==2.0.2python-dotenv==1.0.1\n```\n8. Создайте файл .env с помощью команды:\n```\nnano .env\n```\n9. Скопируйте код в файл:\n```\nKAFKA_BROKERS=<KAFKA_BROKER_IP>:9094KAFKA_WRITER_USERNAME=<KAFKA_WRITER_USERNAME>KAFKA_WRITER_PASSWORD=<KAFKA_WRITER_PASSWORD>KAFKA_READER_USERNAME=<KAFKA_READER_USERNAME>KAFKA_READER_PASSWORD=<KAFKA_READER_PASSWORD>TOPIC=messagesGROUP_ID=subscriber-group\n```\n\nГде:\n- <KAFKA_BROKER_IP> — IP-адрес сервиса Managed Kafka®.\n- <KAFKA_WRITER_USERNAME> — логин от кластера Managed Kafka® с ролью Writer.\n- <KAFKA_WRITER_PASSWORD> — пароль от кластера Managed Kafka® с ролью Writer.\n- <KAFKA_READER_USERNAME> — логин от кластера Managed Kafka® с ролью Reader.\n- <KAFKA_READER_PASSWORD> — пароль от кластера Managed Kafka® с ролью Reader.\nIP-адрес, логины и пароли можно найти на странице информации о кластере в блоке Данные для подключения.\n10. Создайте и активируйте виртуальное окружение:\n```\npython3 -m venv venvsource venv/bin/activate\n```\n11. Установите зависимости:\n```\npip install -r requirements.txt\n```\n12. Создайте топик:\n```\necho \"test message\" | kafkacat -P -b <KAFKA_BROKER_IP>:9094 -X security.protocol=SASL_PLAINTEXT -X sasl.mechanism=SCRAM-SHA-512 -X sasl.username=<KAFKA_ADMIN_USERNAME> -X sasl.password=<KAFKA_ADMIN_PASSWORD> -t messages\n```\n\nГде:\n- <KAFKA_BROKER_IP> — IP-адрес сервиса Managed Kafka®.\n- <KAFKA_ADMIN_USERNAME> — логин от кластера Managed Kafka® с ролью Admin.\n- <KAFKA_ADMIN_PASSWORD> — пароль от кластера Managed Kafka® с ролью Admin.\nIP-адрес, логины и пароли можно найти на странице информации о кластере в блоке Данные для подключения.\n\n## 4. Протестируйте работу очереди сообщений с Managed Kafka®\n1. Запустите сервис subscriber:\n```\npython subscriber.py\n```\n2. Откройте новое окно терминала, не закрывая текущий терминал.\n3. Подключитесь к виртуальной машине pub-sub по SSH.\n4. Перейдите в директорию с сервисами:\n```\ncd pubsub\n```\n5. Активируйте виртуальное окружение:\n```\nsource venv/bin/activate\n```\n6. Отправьте сообщение в очередь:\n```\npython publisher.py \"Hello from Ubuntu!\"\n```\n7. Переключитесь обратно на терминал 1 и проверьте, что сообщение успешно получено.\n\n## 5. Удалите доступ по SSH для виртуальной машины\nТак как для настроенного сервиса больше не требуется доступ по SSH, удалите доступ для повышения безопасности.\n1. В личном кабинете перейдите в сервис «Виртуальные машины» и выберите машину pub-sub, созданную на первом шаге.\n2. Перейдите в раздел Сетевые параметры.\n3. Нажмите на Изменить группы безопасности для публичного IP-адреса.\n4. Удалите группу «SSH-access_ru».\n5. Нажмите Сохранить.\n6. Попробуйте подключиться к виртуальной машине по SSH и убедитесь, что доступ отсутствует.\n\n## Результат\nВы сконфигурировали Managed Kafka® для фоновой обработки задач, связали его с сервисами publisher и subscriber, работающими на виртуальной машине.\nВы получили опыт работы с очередями сообщений и безопасным доступом.\n\n  [© 2025 Cloud.ru](https://cloud.ru)",
      "debug": {
        "start_page": 1,
        "end_page": 1
      }
    }
  ]
}
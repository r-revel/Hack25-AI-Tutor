{
  "title": "Инференс на собственных изображениях с использованием модели CNN, обученной на MNIST, на основе Notebooks",
  "chapters": [
    {
      "name": "Инференс на собственных изображениях с использованием модели CNN, обученной на MNIST, на основе Notebooks",
      "content": "Практические руководства Evolution    \n\n # Инференс на собственных изображениях с использованием модели CNN, обученной на MNIST, на основе Notebooks   Эта статья полезна?          \nС помощью этого руководства вы выполните инференс на собственных изображениях с использованием простой сверточной нейронной сети (CNN), обученной на датасете MNIST.\nВы подготовите окружение, обучите модель и сохраните полученную модель для дальнейшего использования.\nЭто практическое руководство подходит для начинающих, интересующихся компьютерным зрением и машинным обучением.\nВы будете использовать следующие сервисы и библиотеки:\n\n- Notebooks — сервис для запуска сред ML и работы DS-специалистов в ноутбуках на платформе Evolution.\n- torch — основная библиотека для работы с нейронными сетями.\n- torchvision — библиотека для работы с изображениями и наборами данных.\n- matplotlib — библиотека для визуализации данных.\n- SummaryWriter и torch.utils.tensorboard — инструменты для отслеживания и визуализации процесса обучения.\n\nШаги:\n1. Подготовьте среду.\n2. Обучите простую сверточную нейросеть (CNN) с нуля на датасете MNIST.\n3. Выполните инференс на собственных изображениях.\n4. Сохраните модель для повторного использования.\n\n## Перед началом работы\nЗарегистрируйтесь в личном кабинете Cloud.ru.\nЕсли вы уже зарегистрированы, войдите под своей учетной записью.\n\n## 1. Подготовьте среду\n1. Создайте ноутбук на основе образа с поддержкой CUDA.\n2. Установите PyTorch и torchvision:\n```\npip install torchpip install torchvision\n```\n\nПодробнее об установке PyTorch на официальном сайте.\n3. Проверьте доступность GPU:\n```\nimport torch\n# Check GPU availabilitycuda_available = torch.cuda.is_available()print(f\"CUDA доступен: {cuda_available}\")\n# If GPU is available, display the number of GPUs and the GPU nameif cuda_available:    print(f\"Количество доступных GPU: {torch.cuda.device_count()}\")    print(f\"Название GPU: {torch.cuda.get_device_name(0)}\")    device = torch.device(\"cuda\")else:    print(\"Используется CPU\")    device = torch.device(\"cpu\")\n```\n4. Импортируйте библиотеки:\n```\nfrom torch import nn, optimfrom torchvision import datasetsfrom torch.utils.data import DataLoaderimport matplotlib.pyplot as pltfrom torch.utils.tensorboard import SummaryWriter\n```\n\n## 2. Обучите простую сверточную нейросеть (CNN)\nНа этом шаге вы перейдете к практическому применению сверточных нейронных сетей (CNN) для решения задачи классификации изображений.\nМы будем использовать набор данных MNIST, который является классическим набором данных для задач машинного обучения и компьютерного зрения.\n1. Выполните трансформацию данных для MNIST (одноканальные изображения):\n```\ntransform = transforms.Compose([   transforms.ToTensor(),   transforms.Normalize((0.1307,), (0.3081,)),])\n```\n\nВ результате мы выполнили трансформацию данных из набора MNIST для обучения модели.\nЭто нужно для того, чтобы привести данные к формату, который требуется для работы с моделью.\n2. Загрузите датасеты MNIST:\n```\ntrain_dataset = datasets.MNIST(root='./mnist_data', train=True, download=True, transform=transform)test_dataset  = datasets.MNIST(root='./mnist_data', train=False, download=True, transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)test_loader  = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n```\n\nВ результате мы загрузили датасеты MNIST для обучения и тестирования модели сверточной нейронной сети (CNN).\nЭтот набор данных содержит изображения рукописных цифр от 0 до 9 и является одним из наиболее популярных наборов данных для задач классификации изображений.\n3. Для создания эффективной модели сверточной нейронной сети (CNN) необходимо определить ее архитектуру.\nВ данном случае мы будем использовать архитектуру, похожую на ResNet, которая зарекомендовала себя как одна из наиболее эффективных для задач классификации изображений.\nОпределите архитектуру простой ResNet-like CNN:\n```\nclass BasicBlock(nn.Module):   def __init__(self, in_channels, out_channels, stride=1):      super(BasicBlock, self).__init__()      self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)      self.bn1 = nn.BatchNorm2d(out_channels)      self.relu = nn.ReLU(inplace=True)      self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)      self.bn2 = nn.BatchNorm2d(out_channels)\n      self.downsample = None      if stride != 1 or in_channels != out_channels:            self.downsample = nn.Sequential(               nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),               nn.BatchNorm2d(out_channels)            )\n   def forward(self, x):      identity = x\n      out = self.conv1(x)      out = self.bn1(out)      out = self.relu(out)\n      out = self.conv2(out)      out = self.bn2(out)\n      if self.downsample is not None:            identity = self.downsample(x)\n      out += identity      out = self.relu(out)\n      return out\n```\n4. После определения архитектуры модели сверточной нейронной сети (CNN) необходимо выполнить ее инициализацию и настроить параметры для обучения.\nВыполните инициализацию модели, настройте функцию потерь и оптимизатор:\n```\nmodel = MiniResNet().to(device)criterion = nn.CrossEntropyLoss()optimizer = optim.Adam(model.parameters(), lr=0.001)\n```\n\nВ результате мы создали экземпляр модели MiniResNet, определили функцию потерь и выбрали оптимизатор, который будет использоваться для обновления весов модели в процессе обучения.\n5. Для отслеживания процесса обучения модели и оценки его эффективности необходимо создать логгер, который будет записывать метрики, такие как потери и точность модели на обучающей и тестовой выборках.\nСоздайте логгер для записи метрик при обучении модели:\n```\nwriter = SummaryWriter(log_dir='runs/mnist_experiment')\n# For example, log the model graphwriter.add_graph(model, torch.randn(1, 1, 28, 28).to(device))# Number of training epochsepochs = 10\n# Lists to store training and testing loss and accuracy valuestrain_losses = []test_losses = []train_accuracies = []test_accuracies = []\n```\n6. Проведите обучение модели и оцените точность:\n```\nfor epoch in range(epochs):   model.train()   total_train_loss = 0   correct_train = 0   total_train = 0\n   for images, labels in train_loader:      images, labels = images.to(device), labels.to(device)\n      outputs = model(images)      loss = criterion(outputs, labels)\n      optimizer.zero_grad()      loss.backward()      optimizer.step()\n      total_train_loss += loss.item()      _, predicted = outputs.max(1)      correct_train += (predicted == labels).sum().item()      total_train += labels.size(0)\n   avg_train_loss = total_train_loss / len(train_loader)   train_accuracy = correct_train / total_train\n   train_losses.append(avg_train_loss)   train_accuracies.append(train_accuracy)\n   # Evaluation on the test set   model.eval()     # Set the model to evaluation mode   total_test_loss = 0   correct_test = 0 # Number of correctly predicted samples   total_test = 0   # Total number of samples\n   with torch.no_grad():      for images, labels in test_loader:            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)            loss = criterion(outputs, labels)\n            total_test_loss += loss.item()            _, predicted = outputs.max(1)            correct_test += (predicted == labels).sum().item()            total_test += labels.size(0)\n   avg_test_loss = total_test_loss / len(test_loader)   test_accuracy = correct_test / total_test\n   test_losses.append(avg_test_loss)   test_accuracies.append(test_accuracy)\n   # Log values to TensorBoard   writer.add_scalar('Loss/Train', avg_train_loss, epoch)   writer.add_scalar('Loss/Test', avg_test_loss, epoch)   writer.add_scalar('Accuracy/Train', train_accuracy, epoch)   writer.add_scalar('Accuracy/Test', test_accuracy, epoch)\n   print(f\"Эпоха [{epoch+1}/{epochs}] \"         f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.4f} \"         f\"| Test Loss: {avg_test_loss:.4f}, Test Acc: {test_accuracy:.4f}\")\n# Close the SummaryWriter after training to free up resourceswriter.close()\n```\n\nВ этом шаге мы перешли к непосредственному обучению модели на обучающей выборке и оценке ее точности.\nДля корректной работы TensorBoard используйте расширение JupyterLab — tensorboard-pro.\n\n## 3. Выполните инференс на собственных изображениях\nПосле успешного обучения модели на наборе данных MNIST следующим шагом будет тестирование модели на новых данных.\nНа этом шаге мы рассмотрим процесс загрузки, преобразования и классификации собственных изображений с помощью обученной модели.\n1. Загрузите изображение и преобразуйте его в нужный формат:\n```\nimage_path = 'my_digit_3.jpg'\nimg = Image.open(image_path).convert('L').resize((28, 28))\n```\n2. После загрузки и преобразования изображения необходимо убедиться, что оно было правильно обработано и готово к классификации с помощью модели.\nПосмотрите на загруженное изображение:\n```\nplt.imshow(img, cmap='gray')plt.show()\n```\n3. Перед тем как подавать загруженное изображение на вход обученной модели для классификации, необходимо выполнить его преобразование в формат, который использовался во время обучения модели.\nВыполните преобразование изображения:\n```\ntransform = transforms.Compose([   transforms.ToTensor(),   transforms.Normalize((0.1307,), (0.3081,))])\ninput_tensor = transform(img).unsqueeze(0).to(device)  # (1, 1, 28, 28)\n```\n4. После того как изображение было загружено, преобразовано и подготовлено к классификации, мы можем использовать обученную модель для выполнения инференса и получения предсказания.\nВыполните инференс на подготовленном изображении:\n```\nmodel.eval()with torch.no_grad():   output = model(input_tensor)   probabilities = torch.softmax(output, dim=1)   predicted_class = probabilities.argmax(dim=1).item()\n```\n5. После того как модель классифицировала подготовленное изображение, необходимо получить и проанализировать результаты предсказания.\nПолучите результат предсказаний:\n```\nprint(f\"Модель предсказала цифру: {predicted_class}\")\ntop3_prob, top3_classes = torch.topk(probabilities, 3)for i in range(3):   print(f\"{i+1}) Цифра {top3_classes[0][i].item()} с вероятностью {top3_prob[0][i].item():.4f}\")\n```\n\n## 4. Сохраните модель для повторного использования\nПосле сохранения, вы можете загрузить и использовать модель для классификации новых изображений без необходимости повторного обучения.\nСохраните модель для повторного использования:\n```\nmodel_path = \"mini_resnet_mnist.pth\"torch.save(model.state_dict(), model_path)\nprint(f\"Веса модели сохранены в {model_path}\")\n```\n\n## Результат\nВ результате этой практической работы вы обучили простую сверточную нейронную сеть (CNN) на датасете MNIST с помощью PyTorch, а также научились отслеживать процесс обучения в TensorBoard.\nВы освоили процесс инференса модели на собственных изображениях, включая предобработку данных и интерпретацию результатов.\n\n  [© 2025 Cloud.ru](https://cloud.ru)",
      "debug": {
        "start_page": 1,
        "end_page": 1
      }
    }
  ]
}
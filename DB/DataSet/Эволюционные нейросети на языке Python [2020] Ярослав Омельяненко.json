{
  "title": "Эволюционные нейросети на языке Python [2020] Ярослав Омельяненко",
  "chapters": [
    {
      "name": "Глава 1. Обзор методов нейроэволюции 21",
      "chapters": [
        {
          "name": "1.1 Эволюционные алгоритмы и нейроэволюционные методы 22",
          "content": "--- Страница 23 --- (продолжение)\n1.1 эвОлюци Онные алгОритмы и нейр ОэвОлюци Онные метОДы Термин «искусственная нейронная сеть» обозначает граф узлов, соединенных связями, где каждая из связей имеет определенный вес. Узел нейросети явля- ется своего рода пороговым оператором, который позволяет сигналу прохо- дить дальше только после срабатывания определенной функции активации. Это отдаленно напоминает принцип, по которому организованы нейроны го- ловного мозга. Как правило, процесс обучения нейросети состоит из выбора подходящих значений веса для всех связей в сети. Таким образом, нейросеть способна аппроксимировать любую функцию и может рассматриваться как универсальный аппроксиматор, который определяется теоремой универсаль- ной аппроксимации. Чтобы познакомиться с доказательством теоремы универсальной аппрок - симации, прочтите следующие статьи: Cybenko G. (1989) Approximations by Superpositions of Sigmoidal Func - tions, Mathematics of Control, Signals, and Systems, 2 (4), 303–314; Leshno Moshe, Lin Vladimir Ya., Pinkus Allan, Schocken Shimon (January 1993). Multilayer feedforward networks with a nonpolynomial activation function can approximate any function. Neural Networks. 6 (6): 861–867. doi:10.1016/S0893-6080(05)80131-5 (https://www.sciencedirect.com/ science/ article/abs/pii/S0893608005801315?via%3Dihub); Kurt Hornik (1991). Approximation Capabilities of Multilayer Feedfor - ward Networks, Neural Networks, 4 (2), 251–257. doi:10.1016/0893- 6080(91)90009-T (https://www. sciencedirect.com/science/article/abs/ pii/089360809190009T?via%3Dihub); Hanin B. (2018). Approximating Continuous Functions by ReLU Nets of Minimal Width. arXiv preprint arXiv:1710.11278 ( https://arxiv.org/ abs/1710.11278). За последние 70 лет было придумано много методов обучения нейросетей. Однако наиболее популярная техника, получившая известность в последнем десятилетии, была предложена Джеффри Хинтоном. Она основана на об- ратном распространении ошибки прогнозирования через сеть с различны- ми методами оптимизации, построенными на основе градиентного спуска функции потерь по отношению к весам связей между узлами сети. Этот метод демонстрирует выдающуюся эффективность обучения глубоких нейронных сетей для задач, связанных в основном с распознаванием образов. Однако, несмотря на присущие ему достоинства, он имеет существенные недостат - ки. Один из этих недостатков заключается в том, что для усвоения чего-то полезного из определенного набора данных требуется огромное количество обучающих образцов. Другим существенным недостатком является фикси- рованная архитектура нейросети, созданная экспериментатором вручную, что приводит к неэффективному использованию вычислительных ресурсов. Это связано с тем, что значительное количество сетевых узлов не участвует 22  Обзор методов нейроэволюции\n1.1 эвОлюци Онные алгОритмы и нейр ОэвОлюци Онные метОДы Термин «искусственная нейронная сеть» обозначает граф узлов, соединенных связями, где каждая из связей имеет определенный вес. Узел нейросети явля- ется своего рода пороговым оператором, который позволяет сигналу прохо- дить дальше только после срабатывания определенной функции активации. Это отдаленно напоминает принцип, по которому организованы нейроны го- ловного мозга. Как правило, процесс обучения нейросети состоит из выбора подходящих значений веса для всех связей в сети. Таким образом, нейросеть способна аппроксимировать любую функцию и может рассматриваться как универсальный аппроксиматор, который определяется теоремой универсаль- ной аппроксимации. Чтобы познакомиться с доказательством теоремы универсальной аппрок - симации, прочтите следующие статьи: Cybenko G. (1989) Approximations by Superpositions of Sigmoidal Func - tions, Mathematics of Control, Signals, and Systems, 2 (4), 303–314; Leshno Moshe, Lin Vladimir Ya., Pinkus Allan, Schocken Shimon (January 1993). Multilayer feedforward networks with a nonpolynomial activation function can approximate any function. Neural Networks. 6 (6): 861–867. doi:10.1016/S0893-6080(05)80131-5 (https://www.sciencedirect.com/ science/ article/abs/pii/S0893608005801315?via%3Dihub); Kurt Hornik (1991). Approximation Capabilities of Multilayer Feedfor - ward Networks, Neural Networks, 4 (2), 251–257. doi:10.1016/0893- 6080(91)90009-T (https://www. sciencedirect.com/science/article/abs/ pii/089360809190009T?via%3Dihub); Hanin B. (2018). Approximating Continuous Functions by ReLU Nets of Minimal Width. arXiv preprint arXiv:1710.11278 ( https://arxiv.org/ abs/1710.11278). За последние 70 лет было придумано много методов обучения нейросетей. Однако наиболее популярная техника, получившая известность в последнем десятилетии, была предложена Джеффри Хинтоном. Она основана на об- ратном распространении ошибки прогнозирования через сеть с различны- ми методами оптимизации, построенными на основе градиентного спуска функции потерь по отношению к весам связей между узлами сети. Этот метод демонстрирует выдающуюся эффективность обучения глубоких нейронных сетей для задач, связанных в основном с распознаванием образов. Однако, несмотря на присущие ему достоинства, он имеет существенные недостат - ки. Один из этих недостатков заключается в том, что для усвоения чего-то полезного из определенного набора данных требуется огромное количество обучающих образцов. Другим существенным недостатком является фикси- рованная архитектура нейросети, созданная экспериментатором вручную, что приводит к неэффективному использованию вычислительных ресурсов. Это связано с тем, что значительное количество сетевых узлов не участвует 22  Обзор методов нейроэволюции\n--- Страница 24 ---\nв процессе вывода. Кроме того, методы обратного распространения имеют проблемы с передачей полученных знаний в другие смежные области. Наряду с методами обратного распространения применяются очень мно- гообещающие эволюционные алгоритмы, которые могут решать вышеупомя- нутые проблемы. Эти основанные на биологии методы черпают вдохновение из теории эволюции Дарвина и используют принципы эволюции видов для создания искусственных нейронных сетей. Основная идея нейроэволюции состоит в том, чтобы создавать нейросеть с помощью стохастических методов поиска, основанных на популяции. Используя эволюционный подход, мож - но разработать оптимальные архитектуры нейронных сетей, которые точно решают конкретные задачи. В результате могут быть созданы компактные и энергоэффективные сети с умеренными требованиями к вычислительной мощности. Процесс эволюции реализуется путем применения генетических операторов (мутация, кроссовер) к популяции хромосом (генетически коди- рованные представления нейросетей или решений) на протяжении многих поколений. Большие надежды на этот метод основаны на том, что в природ- ных биологических системах каждое последующее поколение становится все более приспособленным к внешним обстоятельствам, которые можно вы- разить целевой функцией, то есть они становятся лучшими приближениями целевой функции. Далее мы обсудим основные понятия генетических алгоритмов. Вам до- статочно будет иметь умеренный уровень понимания принципов работы ге- нетических алгоритмов. 1.1.1 Генетические операторы Генетические операторы находятся в самом сердце каждого эволюционного алгоритма, и от них зависит результативность любого нейроэволюционно- го алгоритма. Существует два основных генетических оператора: мутация и кроссовер (рекомбинация). В этой главе вы узнаете об основах генетических алгоритмов и о том, как они отличаются от обычных алгоритмов, в которых для обучения нейросети используются методы обратного распространения ошибок. Оператор мутации Оператор мутации выполняет важную роль сохранения генетического разно- образия популяции в процессе эволюции и предотвращает остановку в локаль- ных минимумах, когда хромосомы организмов в популяции становятся слиш- ком похожими. Эта мутация изменяет один или несколько генов в хромосоме в соответствии с вероятностью мутации, определенной экспериментатором. Вводя случайные изменения в хромосому решателя (solver), мутация позволя- ет эволюционному процессу исследовать новые области в пространстве поиска возможных решений и находить все лучшие и лучшие решения на протяжении поколений. На рис. 1.1 показаны распространенные типы операторов мутации. 1.1 Эволюционные алгоритмы и нейроэволюционные методы  23\n--- Страница 25 ---\nБитовая инверсия Изменение порядка Изменение значения Изменение экспрессии гена Рис. 1.1. Типы операторов мутации Точный тип оператора мутации зависит от вида генетического кодирова- ния, используемого конкретным генетическим алгоритмом. Среди различ- ных типов мутаций, с которыми мы сталкиваемся, можно выделить следую- щие основные варианты: битовая инверсия: инвертируется случайно выбранный бит (бинар- ное кодирование); изменение порядка: изменение положения двух случайно выбранных генов в геноме (кодирование пермутации); изменение значения: к рабочему гену в случайной позиции добавля- ется небольшое значение (кодирование значения); изменение экспрессии гена: выбранный случайным образом ген до- бавляется в генотип / удаляется из генотипа (структурное кодирова- ние). Генотипы могут быть закодированы с использованием схем генетическо- го кодирования с фиксированной и переменной длиной хромосомы. Первые три мутации могут быть применены к обоим типам схем кодирования. По- следняя мутация может происходить только в генотипах, которые были за- кодированы с использованием переменной длины. Оператор кроссовера Оператор кроссовера (рекомбинации) позволяет нам стохастически генериро- вать новые поколения (решения) из существующих популяций путем реком- бинации генетической информации от двух родителей для генерации потом- ка. Таким образом, доли хороших решений от родительских организмов могут быть объединены и потенциально могут привести к лучшему потомству. Как правило, после операции кроссовера полученное потомство подвергается му- тации перед добавлением в популяцию следующего поколения. Различные операторы кроссовера показаны на рис. 1.2.24  Обзор методов нейроэволюции\n--- Страница 26 ---\nОдноточечный кроссовер Двухточечный кроссовер Унифицированный кроссовер Рис. 1.2. Типы операторов кроссовера (рекомбинации) Различные типы операторов кроссовера также зависят от схемы кодиро- вания генома, используемого конкретными алгоритмами, но наиболее рас- пространенными являются следующие: одноточечный кроссовер: выбирается случайная точка пересечения, часть генома от начала до точки пересечения копируется в потомство от одного родителя, а остаток копируется от другого родителя; двухточечный кроссовер: случайным образом выбираются две точки пересечения, часть генома от начала до первой точки копируется из первого родителя, часть между первой и второй точками пересечения копируется из второго родителя, и остаток копируется из первого ро- дителя; унифицированный кроссовер: гены случайным образом копируются из первого или второго родителя. 1.1.2 Схемы кодирования генома Одним из наиболее важных решений при разработке нейроэволюционного ал- горитма является выбор генетического представления нейронной сети, кото- рое может быть реализовано следующими способами: стандартная мутация (см. раздел «Оператор мутации»); операторы комбинирования (см. раздел «Оператор кроссовера»). В настоящее время существуют две основные схемы кодирования генома: прямая и косвенная. Рассмотрим каждую схему более подробно. Прямое кодирование генома Прямое кодирование генома пытались использовать в методах нейроэволюции для создания нейросетей, относящихся к сетям с фиксированной топологией, – то есть топология сети определяется только экспериментатором. Здесь гене- 1.1 Эволюционные алгоритмы и нейроэволюционные методы  25\n--- Страница 27 ---\nтический код (генотип) реализуется как вектор действительных чисел, пред- ставляющих силу (вес) связей между узлами сети. Эволюционные операторы изменяют значения вектора весовых коэффи- циентов с помощью оператора мутации и объединяют векторы родительских организмов с помощью оператора кроссовера для получения потомства. По- зволяя легко применять эволюционные операторы, упомянутый метод ко- дирования в то же время имеет некоторые существенные недостатки. Один из его основных недостатков заключается в том, что топология сети опреде- ляется экспериментатором с самого начала и остается постоянной для всех поколений за время выполнения эксперимента. Этот подход противоречит естественному эволюционному процессу, при котором в ходе эволюции из- меняются не только свойства, но и физическая структура организмов, что по- зволяет охватывать максимально широкое пространство поиска и находить оптимальные решения. На рис. 1.3 показан эволюционный процесс. Кроссовер Мутация Рис. 1.3. Эволюционный процесс Чтобы устранить недостатки методов с фиксированной топологией, Кен- нет О. Стэнли предложил метод нейроэволюции с развитием топологии (neu- roevolution of augmenting topologies, NEAT). Основная идея этого алгоритма заключается в том, что эволюционные операторы применяются не только к вектору с весами всех связей, но и к топологии созданной нейронной сети. Таким образом, путем генерации популяций организмов проверяются раз- личные топологии с различными весами связей. Мы обсудим особенности алгоритма NEAT позже в этой главе. Алгоритм NEAT демонстрирует выдающуюся эффективность в самых раз- ных задачах – от традиционного обучения с подкреплением до управления сложными автономными персонажами в компьютерных играх – и стал од- ним из самых популярных эволюционных алгоритмов за всю историю ма- шинного обучения. Тем не менее он принадлежит к семейству алгоритмов прямого кодирования, которое ограничивает его использование до разви- тия только нейросетей небольшого размера, где пространство параметров ограничено максимум тысячами связей. Это связано с тем, что каждая связь кодируется непосредственно в генотипе, и при большом количестве зако- дированных связей вычислительные требования значительно возрастают. Это делает невозможным использование алгоритма для развития больших нейронных сетей.26  Обзор методов нейроэволюции\n--- Страница 28 ---\nКосвенное кодирование генома Чтобы преодолеть проблемы размерности в подходе с прямым кодированием, Кеннет О. Стэнли предложил метод косвенного кодирования, который основан на кодировании фенотипа посредством генома в ДНК. Он основан на том фак- те, что физический мир построен вокруг геометрии и закономерностей (струк - турных паттернов), где естественные симметрии встречаются повсюду. Таким образом, размер кода любого физического процесса может быть значитель- но уменьшен путем повторного использования определенного набора блоков кодирования для одной и той же структуры, которая повторяется много раз. Предложенный метод, называемый нейроэволюцией с развитием топологии на основе гиперкуба (hypercube-based neuroevolution of augmenting topologies, HyperNEAT), предназначен для построения крупномасштабных нейронных се- тей с использованием геометрических закономерностей. HyperNEAT исполь- зует сети, производящие составные паттерны (compositional pattern producing network, CPPN), для представления связей между узлами как функции декар- това пространства. Мы обсудим HyperNEAT более подробно далее в этой главе. 1.1.3 Коэволюция В природе популяции разных видов часто одновременно развиваются во взаи- модействии друг с другом. Этот тип межвидовых отношений называется коэво- люцией. Коэволюция является мощным инструментом естественной эволюции, и неудивительно, что она привлекла внимание разработчиков нейроэволюци- онных алгоритмов. Существует три основных типа коэволюции: мутуализм, когда два или более вида мирно сосуществуют и взаимно выигрывают друг от друга; конкурентная коэволюция: хищничество, когда один организм убивает другой и потребляет его ресурсы; паразитизм, когда один организм использует ресурсы другого, но не убивает его; комменсализм, когда представители одного вида получают выгоды, не причиняя вреда и не принося выгоды другим видам. Исследователи изучили существующие стратегии коэволюции и выяви- ли их плюсы и минусы. В этой книге мы представим нейроэволюционный алгоритм, который использует принцип комменсализма для поддержания двух одновременно развивающихся групп: совокупности возможных реше- ний и совокупности целевых функций кандидатов. Мы обсудим алгоритм эволюции решений и приспособленности (solution and fitness evolution, SAFE) в главе 9. 1.1.4 Модульность и иерархия Другим важным аспектом организации естественных когнитивных систем является модульность и иерархия. При изучении человеческого мозга ней- робиологи обнаружили, что это не монолитная система с однородной струк - турой, а сложная иерархия модульных структур. Кроме того, из-за ограни- 1.1 Эволюционные алгоритмы и нейроэволюционные методы  27\n--- Страница 29 ---\nчений скорости распространения сигнала в биологических тканях структура мозга обеспечивает принцип локальности, когда связанные задачи обраба- тываются геометрически смежными структурами в мозге. Эти особенности природных систем не остались без внимания исследователей нейроэволю- ции и реализованы во многих эволюционных алгоритмах. В главе 8 мы обсу - дим создание модульных нейросетей с использованием алгоритма на основе нейроэволюции.",
          "debug": {
            "start_page": 23,
            "end_page": 29
          }
        },
        {
          "name": "1.2 Обзор алгоритма NEAT 28",
          "content": "--- Страница 29 --- (продолжение)\n1.2 О бзОр алгОритма NEAT Метод NEAT предназначен для уменьшения размерности пространства поиска параметров посредством постепенного развития структуры нейросети в про- цессе эволюции. Эволюционный процесс начинается с популяции маленьких, простых геномов (семян) и постепенно увеличивает их сложность с каждым новым поколением. Геномы семян имеют очень простую топологию: доступны (экспрессиро- ваны) только входные, выходные и смещающие нейроны. На начальном эта- пе скрытые узлы отсутствуют, чтобы гарантировать, что поиск решения на- чинается в пространстве параметров (весов связей) с наименьшим числом измерений. С каждым новым поколением вводятся дополнительные гены, расширяющие пространство поиска решения, представляя новое измерение, которое ранее не существовало. Таким образом, эволюция начинается с поиска в небольшом простран- стве, которое можно легко оптимизировать, и при необходимости добав- ляет новые измерения. При таком подходе сложные фенотипы (решения) могут быть обнаружены постепенно, шаг за шагом, что намного эффектив- нее, чем запуск поиска непосредственно в обширном пространстве оконча- тельных решений. Естественная эволюция использует похожую стратегию, время от времени добавляя новые гены, которые делают фенотипы более сложными. В биологии этот процесс постепенного усложнения называется комплексным расширением. Основная цель метода NEAT – минимизировать сложность структуры ге- нома – касается не только конечного продукта, но и всех промежуточных поколений организмов. Таким образом, эволюция топологии сети приводит к значительному выигрышу в производительности за счет сокращения об- щих решений для пространства поиска. Например, многомерное простран- ство окончательного решения возникает только в конце эволюционного про- цесса. Еще одна существенная особенность алгоритма заключается в том, что каждая структура, представленная в геноме, является предметом последую- щих оценок пригодности в будущих поколениях. Кроме того, во время эволю- ционного процесса выживут только полезные структуры. Другими словами, структурная сложность генома всегда оправдана целями. 1.2.1 Схема кодирования NEAT Схема генетического кодирования NEAT разработана таким образом, чтобы можно было легко сопоставлять соответствующие гены во время процесса 28  Обзор методов нейроэволюции\n1.2 О бзОр алгОритма NEAT Метод NEAT предназначен для уменьшения размерности пространства поиска параметров посредством постепенного развития структуры нейросети в про- цессе эволюции. Эволюционный процесс начинается с популяции маленьких, простых геномов (семян) и постепенно увеличивает их сложность с каждым новым поколением. Геномы семян имеют очень простую топологию: доступны (экспрессиро- ваны) только входные, выходные и смещающие нейроны. На начальном эта- пе скрытые узлы отсутствуют, чтобы гарантировать, что поиск решения на- чинается в пространстве параметров (весов связей) с наименьшим числом измерений. С каждым новым поколением вводятся дополнительные гены, расширяющие пространство поиска решения, представляя новое измерение, которое ранее не существовало. Таким образом, эволюция начинается с поиска в небольшом простран- стве, которое можно легко оптимизировать, и при необходимости добав- ляет новые измерения. При таком подходе сложные фенотипы (решения) могут быть обнаружены постепенно, шаг за шагом, что намного эффектив- нее, чем запуск поиска непосредственно в обширном пространстве оконча- тельных решений. Естественная эволюция использует похожую стратегию, время от времени добавляя новые гены, которые делают фенотипы более сложными. В биологии этот процесс постепенного усложнения называется комплексным расширением. Основная цель метода NEAT – минимизировать сложность структуры ге- нома – касается не только конечного продукта, но и всех промежуточных поколений организмов. Таким образом, эволюция топологии сети приводит к значительному выигрышу в производительности за счет сокращения об- щих решений для пространства поиска. Например, многомерное простран- ство окончательного решения возникает только в конце эволюционного про- цесса. Еще одна существенная особенность алгоритма заключается в том, что каждая структура, представленная в геноме, является предметом последую- щих оценок пригодности в будущих поколениях. Кроме того, во время эволю- ционного процесса выживут только полезные структуры. Другими словами, структурная сложность генома всегда оправдана целями. 1.2.1 Схема кодирования NEAT Схема генетического кодирования NEAT разработана таким образом, чтобы можно было легко сопоставлять соответствующие гены во время процесса 28  Обзор методов нейроэволюции\n--- Страница 30 ---\nспаривания, когда к двум родительским геномам применяется оператор крос - совера. Геном NEAT является линейным представлением схемы связей кодиро- ванной нейронной сети, как показано на рис. 4.1. Гены узлов Геном (генотип) Гены связей Сеть (фенотип)датчик датчик датчик отключенвыход включенУзел 1 Вх.: 1 Вых.: 4 вес: 0,5 инн: 1 инн: 2 инн: 3 инн: 4 инн: 5 инн: 6 инн: 12вес: 0,7 вес: 0,4 вес: 0,6 вес: –0,1 вес: –0,3 вес: –0,8Вых.: 4 Вых.: 4 Вых.: 4 Вых.: 5 Вых.: 5 Вых.: 5Вх.: 2 Вх.: 3 Вх.: 1 Вх.: 5 Вх.: 2 Вх.: 4Узел 2 Узел 3 Узел 4 Узел 5 включен включен включенскрытый включен включен Рис. 1.4. Схема генома NEAT Каждый геном представлен в виде списка генов связей, которые кодиру - ют связи между узлами нейронной сети. Кроме того, существуют гены узлов, которые кодируют информацию о сетевых узлах, такую как идентификатор узла, тип узла и тип функции активации. Ген связи кодирует следующие па- раметры связи между узлами: идентификатор входного узла; идентификатор выходного узла; сила (вес) связи; бит, который указывает, включена (экспрессирована) связь или нет; номер обновления, который позволяет сопоставлять гены во время ре- комбинации. На нижней части рис. 4.1 представлена схема того же генома в виде ориен- тированного графа. 1.2.2 Структурные мутации Специфический для NEAT оператор мутации может изменить силу (вес) связи и структуру сети. Существует два основных типа структурных мутаций: добавление новой связи между узлами; добавление нового узла в сеть. Структурные мутации алгоритма NEAT схематически изображены на рис. 1.5. 1.2 Обзор алгоритма NEAT  29\n--- Страница 31 ---\nМутация добавлением связи Мутация добавлением узла выкл. выкл. выкл.выкл. выкл. Рис. 1.5. Структурные мутации в алгоритме NEAT Когда оператор мутации применяется к геному NEAT, вновь добавленному гену (гену связи или гену узла) присваивается очередной номер обновления. В ходе эволюционного процесса геномы организмов в популяции постепен- но становятся больше, и образуются геномы различных размеров. Этот про- цесс приводит к тому, что в одинаковых позициях в геноме находятся разные гены связей, что делает процесс сопоставления между генами одного и того же происхождения чрезвычайно сложным. 1.2.3 Кроссовер с номером обновления В эволюционном процессе есть неочевидная информация, которая точно го- ворит нам, какие гены должны совпадать между геномами любого организма в топологически разнообразной популяции. Это информация, при помощи ко- торой каждый ген сообщает нам, от какого предка он был получен. Гены связей с одним и тем же историческим происхождением представ- ляют одну и ту же структуру, несмотря на то что, возможно, имеют разные значения весов. Историческое происхождение генов в алгоритме NEAT от- ражено в увеличивающихся номерах обновлений, которые позволяют нам отслеживать хронологию структурных мутаций. В то же время в процессе кроссовера потомки наследуют номера обнов- лений генов от родительских геномов. Таким образом, номера обновлений конкретных генов никогда не меняются, что позволяет сопоставить сходные гены из разных геномов в ходе кроссовера. Номера обновлений совпадаю-30  Обзор методов нейроэволюции\n--- Страница 32 ---\nщих генов одинаковы. Если номера обновлений не совпадают, ген принадле- жит непересекающейся или избыточной части генома, в зависимости от того, находится ли его номер обновления внутри или вне диапазона других роди- тельских номеров. Непересекающиеся или избыточные гены представляют собой структуры, которых нет в геноме другого родителя и которые требуют особой обработки во время фазы кроссовера. Таким образом, потомство на- следует гены, которые имеют одинаковые номера обновлений. Они случай- ным образом выбираются у одного из родителей. Потомство всегда наследу - ет непересекающиеся или избыточные гены от родителей с самой высокой степенью приспособленности. Эта особенность позволяет алгоритму NEAT эффективно выполнять рекомбинацию генов с использованием линейного кодирования генома без необходимости проведения сложного топологиче- ского анализа. На рис. 1.6 показан пример кроссовера (рекомбинации) между двумя ро- дителями с использованием алгоритма NEAT. Геномы обоих родителей вы- равниваются при помощи номера обновления (число в верхней части ячейки гена связи). После этого производится потомство путем случайного выбора от любого из родителей генов связи с совпадающими номерами обновле- ний – это гены с номерами от одного до пяти. Наконец, от любого из роди- телей безусловным образом добавляются непересекающиеся и избыточные гены, которые выстраиваются по нарастанию номера обновления. Родитель № 1 Родитель № 1 Родитель № 2 Потомствовыкл выкл выкл выкл выкл выклвыклнепересекающийся непересекающийся избыточныйвыклРодитель № 2 Рис. 1.6. Кроссовер (рекомбинация) алгоритма NEAT 1.2 Обзор алгоритма NEAT  31\n--- Страница 33 ---\n1.2.4 Видообразование В процессе эволюции организмы могут из поколения в поколение создавать разнообразные топологии, но они не могут производить и поддерживать собственные топологические обновления. Меньшие сетевые структуры оп- тимизируются быстрее, чем большие, что искусственно уменьшает шансы на выживание потомка генома после добавления нового узла или связи. Таким образом, недавно дополненные топологии испытывают отрицательное эволю- ционное давление из-за временного снижения приспособленности организмов в популяции. В то же время новые топологии могут содержать инновации, ко- торые в конечном итоге приводят к выигрышному решению, и было бы жал- ко их потерять. Для решения проблемы временного снижения пригодности в алгоритм NEAT была введена концепция видообразования. Видообразование ограничивает круг организмов, которые могут спариваться, вводя узкие ниши, когда организмы, принадлежащие к одной и той же нише, в фазе кроссовера конкурируют только друг с другом, а не со всеми организмами в популяции. Видообразование реализуется путем деления популяции так, чтобы организ- мы с похожей топологией принадлежали к одному и тому же виду, то есть за счет кластеризации геномов по видам. Обобщенная форма алгоритма видо- образования представлена на рис. 1.7. Рис. 1.7. Обобщенная форма алгоритма видообразования Метод NEAT позволяет создавать сложные нейросети, способные решать раз- личные задачи оптимизации управления, а также другие проблемы обучения без учителя. Благодаря способности топологии нейросети эволюционировать посредством усложнения и видообразования полученные решения, как прави- ло, имеют оптимальную производительность обучения и логического вывода. Результирующая топология растет строго в соответствии с проблемой, ко- торая должна быть решена, без каких-либо лишних скрытых слоев, вводимых 32  Обзор методов нейроэволюции\n--- Страница 34 ---\nобычными методами проектирования топологии нейросетей, обучаемых на основе обратного распространения ошибки. Подробнее прочитать про алгоритм NEAT можно в оригинальной статье по адресу: http://nn.cs.utexas.edu/downloads/papers/stanley.phd04.pdf.",
          "debug": {
            "start_page": 29,
            "end_page": 34
          }
        },
        {
          "name": "1.3 NEAT на основе гиперкуба 33",
          "content": "--- Страница 34 --- (продолжение)\n1.3 NEAT на ОСнОве гиперкуба Интеллект является продуктом мозга, а человеческий мозг как структура сам является продуктом естественной эволюции. Такая сложная структура раз- вивалась в течение миллионов лет под давлением суровых условий и в то же время конкурировала за выживание с другими живыми существами. В резуль- тате возникла чрезвычайно развитая система со многими слоями, модулями и триллионами связей между нейронами. Структура человеческого мозга яв- ляется нашей путеводной звездой и помогает нам в создании систем искус - ственного интеллекта. Однако как мы можем постичь всю сложность челове- ческого мозга с помощью наших несовершенных инструментов? Изучая мозг человека, нейробиологи обнаружили, что его пространствен- ная структура играет важную роль во всех задачах восприятия и познания – от зрения до абстрактного мышления. Было найдено много сложных геометри- ческих структур, таких как клетки коры мозга, которые помогают нам в инер- циальной навигации, и кортикальные столбцы, которые связаны с сетчаткой глаза для обработки зрительных образов. Было доказано, что структура мозга позволяет нам эффективно реагировать на образы в сигналах, поступающих от сенсориума1, с помощью обособленных нейронных структур, которые ак- тивируются определенными образами на входах. Эта особенность мозга по- зволяет ему использовать чрезвычайно эффективный способ представления и обработки всего разнообразия входных данных, полученных из окружаю- щей среды. Наш мозг превратился в набор эффективных механизмов рас- познавания и обработки образов, которые активно применяют повторное использование нейронных модулей, тем самым значительно сокращая коли- чество необходимых нейронных структур. Это стало возможным только бла- годаря сложной модульной иерархии и пространственной интеграции раз- личных частей. Иными словами, биологический мозг реализует сложные иерархические и пространственно-ориентированные процедуры обработки данных. Это вдохновило исследователей нейроэволюции на внедрение аналогичных ме- тодов обработки данных в области искусственных нейронных сетей. При про- ектировании подобных систем необходимо учитывать следующие проблемы: огромное количество входных признаков и параметров обучения, ко- торые требуют построения крупномасштабных нейросетей; эффективное представление естественных геометрических законо- мерностей и симметрий, которые наблюдаются в физическом мире; 1 Совокупность органов чувств (источников биологических сигналов) и клеток голов- ного мозга, непосредственно принимающих эти сигналы. – Прим. перев. 1.3 NEAT на основе гиперкуба  33\n1.3 NEAT на ОСнОве гиперкуба Интеллект является продуктом мозга, а человеческий мозг как структура сам является продуктом естественной эволюции. Такая сложная структура раз- вивалась в течение миллионов лет под давлением суровых условий и в то же время конкурировала за выживание с другими живыми существами. В резуль- тате возникла чрезвычайно развитая система со многими слоями, модулями и триллионами связей между нейронами. Структура человеческого мозга яв- ляется нашей путеводной звездой и помогает нам в создании систем искус - ственного интеллекта. Однако как мы можем постичь всю сложность челове- ческого мозга с помощью наших несовершенных инструментов? Изучая мозг человека, нейробиологи обнаружили, что его пространствен- ная структура играет важную роль во всех задачах восприятия и познания – от зрения до абстрактного мышления. Было найдено много сложных геометри- ческих структур, таких как клетки коры мозга, которые помогают нам в инер- циальной навигации, и кортикальные столбцы, которые связаны с сетчаткой глаза для обработки зрительных образов. Было доказано, что структура мозга позволяет нам эффективно реагировать на образы в сигналах, поступающих от сенсориума1, с помощью обособленных нейронных структур, которые ак- тивируются определенными образами на входах. Эта особенность мозга по- зволяет ему использовать чрезвычайно эффективный способ представления и обработки всего разнообразия входных данных, полученных из окружаю- щей среды. Наш мозг превратился в набор эффективных механизмов рас- познавания и обработки образов, которые активно применяют повторное использование нейронных модулей, тем самым значительно сокращая коли- чество необходимых нейронных структур. Это стало возможным только бла- годаря сложной модульной иерархии и пространственной интеграции раз- личных частей. Иными словами, биологический мозг реализует сложные иерархические и пространственно-ориентированные процедуры обработки данных. Это вдохновило исследователей нейроэволюции на внедрение аналогичных ме- тодов обработки данных в области искусственных нейронных сетей. При про- ектировании подобных систем необходимо учитывать следующие проблемы: огромное количество входных признаков и параметров обучения, ко- торые требуют построения крупномасштабных нейросетей; эффективное представление естественных геометрических законо- мерностей и симметрий, которые наблюдаются в физическом мире; 1 Совокупность органов чувств (источников биологических сигналов) и клеток голов- ного мозга, непосредственно принимающих эти сигналы. – Прим. перев. 1.3 NEAT на основе гиперкуба  33\n--- Страница 35 ---\nэффективная обработка входных данных благодаря внедрению прин- ципа локальности, то есть когда пространственно- и семантически смежные структуры данных обрабатываются модулями взаимосвязан- ных нейронных блоков, которые занимают одну и ту же компактную область всей сетевой структуры. В этом разделе вы узнали о методе HyperNEAT на основе гиперкуба, кото- рый был предложен Кеннетом О. Стэнли для решения различных задач с ис- пользованием многомерных геометрических структур. Далее мы рассмотрим сети, производящие составные паттерны (CPPN). 1.3.1 Сети, производящие составные паттерны Алгоритм HyperNEAT расширяет исходный алгоритм NEAT, вводя новый тип схемы кодирования косвенного генома под названием CPPN. Этот тип коди- рования позволяет представлять паттерны связей нейросети фенотипа как функцию его геометрии. HyperNEAT сохраняет паттерн связей нейронной сети фенотипа в виде че- тырехмерного гиперкуба, где каждая точка кодирует связь между двумя уз- лами (то есть координатами исходного и целевого нейронов), а CPPN рисует в нем различные паттерны. Другими словами, CPPN вычисляет четырехмер- ную функцию, которая определяется следующим образом: ( )1 2 2 2 wCPPNx,y,x,y = . Здесь исходный узел находится в точке (x1, y2), а целевой узел – в точке (x1, y2). На этом этапе CPPN возвращает вес для каждой связи между каждым уз- лом в сети фенотипа, который представлен в виде сетки. По соглашению связь между двумя узлами не экспрессируется (не участвует в процессах генома), если величина веса связи, вычисленная с помощью CPPN, меньше минималь- ного порогового значения (wmin). Таким образом, паттерн связей, созданный CPPN, может представлять произвольную топологию сети. Паттерн связей может использоваться для кодирования крупномасштабных нейросетей пу- тем обнаружения закономерностей в обучающих данных и может повторно использовать тот же набор генов для кодирования повторений. Паттерн свя- зей, созданный CPPN, принято называть субстратом (substrate). На рис. 1.8 показана интерпретация паттерна геометрической связности на основе гиперкуба. В отличие от традиционных нейросетевых архитектур, CPPN может ис- пользовать различные функции активации для своих скрытых узлов и тем самым отражать различные геометрические закономерности. Например, для представления повторений можно использовать тригонометрический синус, а для обеспечения локальности в определенной части сети (то есть симметрии вдоль оси координат) – гауссову кривую. Таким образом, схема кодирования CPPN может компактно представлять паттерны с различными геометрическими закономерностями, такими как симметрия, повторение, повторение с закономерностями и т. д.34  Обзор методов нейроэволюции\n--- Страница 36 ---\nСубстрат (фенотип) Связная CPPN Рис. 1.8. Интерпретация паттерна геометрической связности на основе гиперкуба 1.3.2 Конфигурация субстрата Компоновка сетевых узлов в субстрате, к которому подключается CPPN, мо- жет принимать различные формы, которые лучше всего подходят для решения конкретных задач. Экспериментатор отвечает за выбор подходящей компо- новки для достижения оптимальной производительности. Например, выход- ные узлы, которые управляют радиальным объектом, таким как механизм с шестью шагающими конечностями, удобнее всего располагать в круговой форме, чтобы паттерн связей мог быть представлен в полярных координатах. Существует несколько распространенных типов конфигурации субстрата, которые обычно используются с HyperNEAT (рис. 1.9): двухмерная сетка: регулярная сетка узлов сети в двухмерном декар- товом пространстве с центром в (0, 0); трехмерная сетка: регулярная сетка узлов сети в трехмерном декарто- вом пространстве с центром в (0, 0, 0); сэндвич: две двухмерные плоские сетки с узлами входа и выхода, где один слой может выстраивать связи в направлении другого; круговая: упорядоченная радиальная структура, которая подходит для определения закономерностей в полярных координатах. 2D-сетка 3D-сетка СэндвичИсточник (x1,y1)Цель (х2, y2) Круговая Рис. 1.9. Примеры конфигурации слоев субстрата 1.3 NEAT на основе гиперкуба  35\n--- Страница 37 ---\n1.3.3 CPPN с развивающимися связями и алгоритм HyperNEAT Метод называется HyperNEAT, потому что он использует модифицированный алгоритм NEAT для развития CPPN, представляющих объемные структуры в гиперпространстве. Каждая экспрессированная (доступная для генетиче- ских операций) точка паттерна, находящаяся в гиперкубе (hypercube), пред- ставляет собой связь между двумя узлами графа нижнего измерения (суб- страта). Таким образом, размерность гиперпространства в два раза больше размерности нижележащего графа наименьшего измерения. Далее в главе 8 мы рассмотрим некоторые примеры, в которых используются двумерные паттерны связей. Обобщенная форма алгоритма HyperNEAT представлена на рис. 1.10. Рис. 1.10. Обобщенная форма алгоритма HyperNEAT Любой ген связи или ген узла, который был добавлен к CPPN во время ее эволюции, приводит к открытию нового глобального измерения вариаций паттернов связей через субстрат фенотипа (новые признаки). Каждая моди- фикация генома CPPN представляет новый способ изменения всего паттер- на связей. Кроме того, ранее разработанные CPPN могут быть использова- ны в качестве основы для создания паттернов связей для субстрата с более высоким разрешением, чем то, которое использовалось для его обучения. Это позволяет нам получить рабочее решение прежней проблемы при лю- бом разрешении, возможно, без ограничения верхнего предела. Вышеупо- мянутые свойства сделали HyperNEAT мощным инструментом для развития крупномасштабных искусственных нейронных сетей, имитирующих биоло- гические объекты. Больше информации о методе HyperNEAT вы можете найти по адресу https://eplex.cs.ucf.edu/papers/stanley_alife09.pdf .36  Обзор методов нейроэволюции",
          "debug": {
            "start_page": 34,
            "end_page": 37
          }
        },
        {
          "name": "1.4 HyperNEAT с развиваемым субстратом 37",
          "content": "--- Страница 38 --- (продолжение)\n1.4 H ypErNEAT С развиваемым СубСтрат Ом Метод HyperNEAT основан на идее, что геометрические структуры живого мозга могут быть полноценно представлены искусственными нейронными сетями с узлами, расположенными в определенных пространственных место- положениях. Таким образом, нейроэволюция получает значительные преиму - щества и позволяет обучать крупномасштабные нейросети для сложных задач, что было невозможно с обычным алгоритмом NEAT. В то же время хотя под- ход HyperNEAT и основан на структуре естественного мозга, ему по-прежнему не хватает пластичности процесса естественной эволюции. Позволяя эволю- ционному процессу разрабатывать различные паттерны связей между узлами сети, метод HyperNEAT накладывает жесткое ограничение на то, где разме- щаются узлы. Экспериментатор должен определить расположение узлов сети с самого начала, и любое неверное предположение, сделанное исследователем, снизит эффективность эволюционного процесса. Размещая сетевой узел в определенном месте на субстрате, эксперимента- тор создает непреднамеренное ограничение на паттерн весов, создаваемый CPPN. Это ограничение затем мешает CPPN, когда она пытается закодиро- вать геометрические закономерности мира природы в топографию реша- ющей нейросети (фенотип). В данном случае паттерн связей, создаваемый CPPN, должен идеально совпадать со слоем субстрата, который определен экспериментатором; возможны только связи между сетевыми узлами, кото- рые определены заранее. Такое ограничение приводит к ненужным ошиб- кам аппроксимации, которые портят результат. Если позволить CPPN раз- рабатывать паттерны связей для узлов, которые находятся в немного других местах, это может оказаться более эффективным подходом. 1.4.1 Плотность информации в гиперкубе Почему мы должны начинать с наложения подобных ограничений на рас- положение узлов? Разве не было бы лучше, если бы неявные подсказки, по- лученные из паттернов связей, стали бы указаниями к тому, где разместить следующий узел, чтобы лучше представить естественные закономерности фи- зического мира? Области с одинаковыми весами связей кодируют небольшое количество информации и, следовательно, имеют небольшое функциональное значение. В то же время области с огромными градиентами значений веса являются чрезвычайно информационными. Такие области могут получить выгоду от размещения дополнительных узлов сети для более точного кодирования природного процесса. Как вы помните из нашего обсуждения алгоритма HyperNEAT, связь между двумя узлами в субстрате можно представить в виде точки в четырехмерном гиперкубе. Главная идея предложенного алгоритма ES-HyperNEAT состоит в том, чтобы разместить больше гиперточек в тех об- ластях гиперкуба, где обнаруживаются бо́льшие вариации весов связей. В то же время в областях с меньшим разбросом весов связей размещается мень- шее количество гиперточек. 1.4 HyperNEAT с развиваемым субстратом  37\n1.4 H ypErNEAT С развиваемым СубСтрат Ом Метод HyperNEAT основан на идее, что геометрические структуры живого мозга могут быть полноценно представлены искусственными нейронными сетями с узлами, расположенными в определенных пространственных место- положениях. Таким образом, нейроэволюция получает значительные преиму - щества и позволяет обучать крупномасштабные нейросети для сложных задач, что было невозможно с обычным алгоритмом NEAT. В то же время хотя под- ход HyperNEAT и основан на структуре естественного мозга, ему по-прежнему не хватает пластичности процесса естественной эволюции. Позволяя эволю- ционному процессу разрабатывать различные паттерны связей между узлами сети, метод HyperNEAT накладывает жесткое ограничение на то, где разме- щаются узлы. Экспериментатор должен определить расположение узлов сети с самого начала, и любое неверное предположение, сделанное исследователем, снизит эффективность эволюционного процесса. Размещая сетевой узел в определенном месте на субстрате, эксперимента- тор создает непреднамеренное ограничение на паттерн весов, создаваемый CPPN. Это ограничение затем мешает CPPN, когда она пытается закодиро- вать геометрические закономерности мира природы в топографию реша- ющей нейросети (фенотип). В данном случае паттерн связей, создаваемый CPPN, должен идеально совпадать со слоем субстрата, который определен экспериментатором; возможны только связи между сетевыми узлами, кото- рые определены заранее. Такое ограничение приводит к ненужным ошиб- кам аппроксимации, которые портят результат. Если позволить CPPN раз- рабатывать паттерны связей для узлов, которые находятся в немного других местах, это может оказаться более эффективным подходом. 1.4.1 Плотность информации в гиперкубе Почему мы должны начинать с наложения подобных ограничений на рас- положение узлов? Разве не было бы лучше, если бы неявные подсказки, по- лученные из паттернов связей, стали бы указаниями к тому, где разместить следующий узел, чтобы лучше представить естественные закономерности фи- зического мира? Области с одинаковыми весами связей кодируют небольшое количество информации и, следовательно, имеют небольшое функциональное значение. В то же время области с огромными градиентами значений веса являются чрезвычайно информационными. Такие области могут получить выгоду от размещения дополнительных узлов сети для более точного кодирования природного процесса. Как вы помните из нашего обсуждения алгоритма HyperNEAT, связь между двумя узлами в субстрате можно представить в виде точки в четырехмерном гиперкубе. Главная идея предложенного алгоритма ES-HyperNEAT состоит в том, чтобы разместить больше гиперточек в тех об- ластях гиперкуба, где обнаруживаются бо́льшие вариации весов связей. В то же время в областях с меньшим разбросом весов связей размещается мень- шее количество гиперточек. 1.4 HyperNEAT с развиваемым субстратом  37\n--- Страница 39 ---\nРазмещение узлов и образование связей между ними может быть про- диктовано изменением веса связей, которые создаются эволюционирую- щей CPPN для данной области субстрата. Другими словами, для принятия решения о размещении следующего узла в субстрате нет необходимости в дополнительной информации, кроме той, что мы уже получаем от CPPN, кодирующей паттерны связей сети. Основным руководящим принципом для алгоритма определения топографии субстрата становится плотность информации. Размещение узла в фенотипе нейросети отражает информацию, которая закодирована в паттернах связей, созданных CPPN. 1.4.2 Квадродерево как эффективный экстрактор информации Для представления гиперточек, которые кодируют веса связей внутри ги- перкуба, алгоритм ES-HyperNEAT использует квадродерево. Квадродерево – это древовидная структура данных, в которой каждый внутренний узел имеет ровно четыре дочерних узла. Эта структура данных была выбрана благодаря присущим ей свойствам, что позволяет ей представлять двумерные области на разных уровнях детализации. С помощью квадродерева можно организо- вать эффективный поиск в двухмерном пространстве, разбив любую интере- сующую область на четыре подобласти, и каждая из них становится листом дерева, а корневой (родительский) узел представляет исходную (декомпози- рованную) область. Используя метод извлечения информации на основе квадродерева, ме- тод ES-HyperNEAT итеративно ищет новые связи между узлами в двумерном пространстве субстрата нейросети, начиная с узлов ввода и вывода, которые были предварительно определены экспериментатором. Этот метод намно- го эффективнее в вычислительном отношении, чем поиск непосредственно в четырехмерном пространстве гиперкуба. На рис. 1.11 показан пример извлечения информации с использованием квадродерева.38  Обзор методов нейроэволюции\n--- Страница 40 ---\nДеление и инициализация 1 × 1 2 × 2 4 × 4 Обрезка и извлечениеЗапрос CPPNвычисление обход, пока низкая дис - персиясоздание связей с надлежа-щими узламиделение до нужного разрешения Рис. 1.11. Пример извлечения информации с использованием квадродерева Алгоритм поиска на основе квадродерева работает в два основных этапа: 1. Деление и инициализация. На этом этапе квадродерево создается пу- тем рекурсивного деления исходного пространства субстрата, занима- ющего область от (–1, –1) до (1, 1). Деление останавливается, когда до- стигается желаемая глубина дерева. От этого неявно зависит, сколько подпространств помещается в начальное пространство субстрата (раз- решение инициализации). После этого для каждого узла дерева с цент- ром в (a, b) запрашивается CPPN с аргументами (a, b, xi, yi) для определе- ния весов связей. Когда веса связей для k конечных узлов конкретного узла p квадродерева найдены, дисперсию этого узла можно рассчитать по следующей формуле: 1.4 HyperNEAT с развиваемым субстратом  39\n--- Страница 41 ---\n()22 1k i iσωω ==−∑ . Здесь ϖ – средний вес соединения между k конечных узлов и ωi – вес со- единения с конкретным конечным узлом. Рассчитанное значение дисперсии является эвристическим индикатором наличия информации в конкретной области субстрата. Если это значение выше, чем конкретный порог деления (определяющий желаемую плотность информации), то для соответствующего квадрата можно повторить стадию деления. Таким образом алгоритм может обеспечить требуемую плотность информации. Посмотрите на верхнюю часть рис. 1.11, чтобы увидеть, как выполняются деление и инициализация с исполь- зованием квадродерева. 2. Обрезка и извлечение. Чтобы гарантировать, что в областях с высокой плотностью информации (большой разброс весов) будет экспрессирова- но большее количество связей (и узлов в субстрате), для созданного на предыдущем этапе квадродерева выполняется процедура обрезки и из- влечения. Для квадродерева выполняют поиск в глубину, пока дисперсия текущего узла не станет меньше порога дисперсии 2 tσ или пока не окажет - ся, что у узла нет дочерних элементов (нулевая дисперсия). Для каждого отвечающего этим условиям узла экспрессирована связь с соответствую- щим центром (x, y), и каждый родительский узел уже определен либо экс- периментатором, либо найден при предыдущем запуске этих двух этапов (то есть среди скрытых узлов, которые уже были созданы методом ES- HyperNEAT). Фаза обрезки и извлечения наглядно представлена на ниж - ней части рис. 1.11. 1.4.3 Алгоритм ES-HyperNEAT Алгоритм ES-HyperNEAT начинается с определяемых пользователем вход- ных узлов и подробно исследует исходящие из них связи, направленные ко вновь экспрессированным скрытым узлам. Экспрессия паттернов исходящих связей и размещения скрытых узлов в пространстве субстрата выполняется с использованием метода извлечения информации из квадродерева, который мы описали ранее. Процесс извлечения информации применяется итеративно до тех пор, пока не будет достигнут желаемый уровень плотности представле- ния информации или пока в гиперкубе не перестанет обнаруживаться новая информация. После этого результирующая сеть соединяется с определенны- ми пользователем выходными узлами путем экспрессии паттернов входящих подключений, направленных к выходам. Для этого мы также используем из- влечение информации из квадродерева. В конечной (экспрессированной) сети остаются только те скрытые узлы, которые имеют путь как к входному, так и к выходному узлу. Теперь у нас определено множество узлов и связей внутри субстрата фено- типа нейросети. Может быть выгодно удалить некоторые узлы из сети, введя дополнительную стадию обрезки. На этой стадии мы сохраняем только точки в пределах определенной полосы и удаляем точки на краю полосы. Делая по- лосы шире или уже, CPPN может управлять плотностью закодированной ин- формации. Для получения более подробной информации о стадии обрезки, 40  Обзор методов нейроэволюции\n--- Страница 42 ---\nпожалуйста, прочтите статью про ES-HyperNEAT (https://eplex.сs.ucf.edu/ papers/risi_alife12.pdf). Обобщенная форма алгоритма ES-HyperNEAT представлена на рис. 1.12. Рис. 1.12. Обобщенная форма алгоритма ES-HyperNEAT Алгоритм ES-HyperNEAT использует все преимущества методов NEAT и HyperNEAT и предоставляет еще более мощные новые функции, в том числе: 1.4 HyperNEAT с развиваемым субстратом  41\n--- Страница 43 ---\nавтоматическое размещение скрытых узлов внутри субстрата для точно- го соответствия паттернам связи, которые выражены развитыми CPPN; позволяет нам гораздо проще создавать модульные нейросети феноти- па благодаря специфической способности сразу начать эволюционный поиск с уклоном в сторону локальности (благодаря особому устройству исходных архитектур CPPN); с помощью ES-HyperNEAT можно уточнить существующую структу - ру фенотипа нейросети, увеличив число узлов и связей в субстрате в процессе эволюции – в противоположность методу HyperNEAT, где количест во узлов субстрата предопределено. Алгоритм ES-HyperNEAT позволяет нам использовать исходную архитек - туру HyperNEAT без изменения генетической структуры части NEAT. Это по- зволяет нам решать проблемы, которые трудно решить с помощью алгоритма HyperNEAT из-за сложностей с предварительным созданием соответствую- щей конфигурации субстрата. Подробнее ознакомиться с алгоритмом ES-HyperNEAT и механизма- ми, лежащими в его основе, можно в статье по адресу https://eplex. cs.ucf.edu/papers/risi_alife12.pdf",
          "debug": {
            "start_page": 38,
            "end_page": 43
          }
        },
        {
          "name": "1.5 Метод оптимизации поиском новизны 42",
          "content": "--- Страница 43 --- (продолжение)\n1.5 метОД Оптимизации пОиСкОм нОвизны Большинство методов машинного обучения, включая эволюционные алгорит - мы, основывают свое обучение на оптимизации целевой функции. Основная идея, лежащая в основе методов оптимизации целевой функции (objective func - tion), заключается в том, что лучший способ улучшить производительность решателя (solver) – вознаграждать его за приближение к цели. В большинстве эволюционных алгоритмов близость к цели измеряется приспособленностью (fitness) решателя. Мера полезности организма определяется функцией при- способленности (fitness function), которая является метафорой эволюционного давления на организм для адаптации к окружающей среде. Согласно этой па- радигме, наиболее приспособленный организм лучше приспособлен к окружа- ющей среде и лучше всего подходит для поиска решения. Хотя методы прямой оптимизации функций приспособленности хорошо ра- ботают во многих простых случаях, при решении более сложных задач они час- то становятся жертвами ловушки локального оптимума. Сходимость к локаль- ному оптимуму означает, что ни один локальный шаг в пространстве поиска не обеспечивает каких-либо улучшений в процессе оптимизации функции при- способленности. Традиционные генетические алгоритмы используют мутаци- онные и островные механизмы, чтобы вырваться из таких локальных оптиму - мов. Однако, как мы выясним позже, выполняя эксперименты в данной книге, эти подходы не всегда работают при решении обманчивых проблем, или может потребоваться слишком много времени, чтобы найти успешное решение. Многие реальные проблемы имеют такие обманчивые ландшафты функций приспособленности, которые не могут быть успешно пройдены с помощью процесса оптимизации, основанного исключительно на измерении близости 42  Обзор методов нейроэволюции\n1.5 метОД Оптимизации пОиСкОм нОвизны Большинство методов машинного обучения, включая эволюционные алгорит - мы, основывают свое обучение на оптимизации целевой функции. Основная идея, лежащая в основе методов оптимизации целевой функции (objective func - tion), заключается в том, что лучший способ улучшить производительность решателя (solver) – вознаграждать его за приближение к цели. В большинстве эволюционных алгоритмов близость к цели измеряется приспособленностью (fitness) решателя. Мера полезности организма определяется функцией при- способленности (fitness function), которая является метафорой эволюционного давления на организм для адаптации к окружающей среде. Согласно этой па- радигме, наиболее приспособленный организм лучше приспособлен к окружа- ющей среде и лучше всего подходит для поиска решения. Хотя методы прямой оптимизации функций приспособленности хорошо ра- ботают во многих простых случаях, при решении более сложных задач они час- то становятся жертвами ловушки локального оптимума. Сходимость к локаль- ному оптимуму означает, что ни один локальный шаг в пространстве поиска не обеспечивает каких-либо улучшений в процессе оптимизации функции при- способленности. Традиционные генетические алгоритмы используют мутаци- онные и островные механизмы, чтобы вырваться из таких локальных оптиму - мов. Однако, как мы выясним позже, выполняя эксперименты в данной книге, эти подходы не всегда работают при решении обманчивых проблем, или может потребоваться слишком много времени, чтобы найти успешное решение. Многие реальные проблемы имеют такие обманчивые ландшафты функций приспособленности, которые не могут быть успешно пройдены с помощью процесса оптимизации, основанного исключительно на измерении близости 42  Обзор методов нейроэволюции\n--- Страница 44 ---\nтекущего решения к цели. В качестве примера мы можем рассмотреть задачу навигации по неизвестному городу с нерегулярным рисунком улиц. В такой за- даче движение к месту назначения часто означает путешествие по обманчивым дорогам, которые уводят вас еще дальше, только чтобы привести вас к месту на- значения после нескольких поворотов. Но если вы решите начать с дорог, кото- рые лучше всего направлены на пункт назначения, они могут завести вас в ту- пик, в то время как пункт назначения находится прямо за стеной, но недоступен. 1.5.1 Поиск новизны и естественная эволюция Рассматривая, как естественный отбор работает в физическом мире, мы видим, что движущей силой эволюционного разнообразия является поиск новизны (novelty search, NS). Другими словами, любой развивающийся вид получает непосредственные эволюционные преимущества по сравнению с конкурентами, находя новые модели поведения. Это позволяет ему более эффективно использовать окружающую среду. У естественной эволюции нет определенных целей, и она расширяет пространство поиска решений, воз- награждая за исследование и использование новых форм поведения. Новиз- ну можно рассматривать как точку приложения усилий для многих скрытых творческих сил в мире природы, что позволяет эволюции разрабатывать еще более сложные модели поведения и биологические структуры. Вдохновившись естественной эволюцией, Джоэл Леман предложил новый метод поисковой оптимизации для искусственного эволюционного процес - са, названный поиском новизны. При использовании этого метода для по- иска решения не определяется и не используется никакая конкретная функ - ция приспособленности; вместо этого новизна каждого найденного решения вознаграждается непосредственно в процессе нейроэволюции. Таким образом, новизна найденных решений направляет нейроэволюцию к конечной цели. Такой подход дает нам возможность использовать творче- ские силы эволюции, не зависящие от адаптивного давления, стремящегося приспособить решение к определенной нише. Эффективность поиска новизны может быть продемонстрирована с по- мощью эксперимента по навигации в лабиринте, где поиск на основе бли- зости к цели находит решение для простого лабиринта за гораздо большее количество шагов (поколений), чем поиск новизны. Кроме того, в случае сложного лабиринта с дезориентирующей конфигурацией поиск на основе близости к цели вообще не может найти решение. Мы обсудим эксперименты по навигации в лабиринте в главе 5. 1.5.2 Метрика новизны Алгоритм поиска новизны использует метрику новизны для отслеживания уникальности поведения каждого нового организма. То есть метрика новиз- ны – это мера того, насколько далеко новый организм находится от остальной части популяции в пространстве поведения (behavior space). Эффективная реа- лизация метрики новизны должна позволить нам вычислить разреженность (sparseness) в любой точке пространства поведения. Любая область с более плотным скоплением посещенных точек менее нова и дает меньшее эволюци- онное вознаграждение. 1.5 Метод оптимизации поиском новизны  43\n--- Страница 45 ---\nНаиболее простой мерой разреженнос ти в точке является среднее расстояние до k-ближайших соседей этой точки в пространстве поведения. Когда это рас- стояние велико, интересующий объект находится в разреженной области. В то же время более плотным областям присущи меньшие значения расстояний. Та- ким образом, разреженность в точке вычисляется по следующей формуле: ()() 01k i ix distx,kρ µ ==∑ . Здесь µi – это i-й ближайший сосед x, определенный по метрике расстояния dist(xi, µi). Метрика расстояния является предметно-ориентированной мерой поведенческой разницы между двумя индивидуумами. Кандидаты из разреженных областей получают более высокие оценки но- визны. Когда эта оценка превышает некоторый минимальный порог ρmin, ин- дивидуум в этой точке добавляется в архив лучших исполнителей, характе- ризующий распределение предыдущих решений в пространстве поведения. Нынешнее поколение населения в сочетании с архивом определяет, где был поиск раньше и где он будет происходить сейчас. Таким образом, градиент по- иска направляется на новое поведение без какой-либо явной цели, просто мак- симизируя показатель новизны. Тем не менее поиск новизны по-прежнему основывается на прикладной информации, потому что изучение нового по- ведения требует всестороннего исследования области поиска. Обобщенная форма алгоритма поиска новизны показана на рис. 1.13. Рис. 1.13. Обобщенная форма алгоритма поиска новизны44  Обзор методов нейроэволюции\n--- Страница 46 ---\nМетод оптимизации поиска новизны позволяет эволюции искать решения в любом дезориентирующем пространстве и находить оптимальные реше- ния. С помощью этого метода возможно реализовать дивергентную эволю- цию, когда популяция вынуждена не останавливаться на конкретном нише- вом решении (локальный оптимум) и должна исследовать все пространство решений. Как показали эксперименты, это очень эффективный метод поис - ковой оптимизации, несмотря на его нелогичный подход, который полно- стью игнорирует явную цель во время поиска. Более того, он может найти окончательное решение в большинстве случаев даже быстрее, чем традици- онный поиск на основе целей, измеряющий приспособленность как расстоя- ние от окончательного решения. Подробное описание алгоритма можно найти по адресу http:// joellehman.com/lehman-dissertation.pdf.",
          "debug": {
            "start_page": 43,
            "end_page": 46
          }
        },
        {
          "name": "1.6 Заключение 45",
          "content": "1.6 заключение В этой главе мы начали с обсуждения различных методов, которые исполь- зуются для обучения искусственных нейронных сетей. Мы рассмотрели, чем традиционные методы градиентного спуска отличаются от методов, основан- ных на нейроэволюции. Затем мы представили один из самых популярных ал- горитмов нейроэволюции (NEAT) и два способа его расширения (HyperNEAT и ES-HyperNEAT). Наконец, вы познакомились с методом поисковой оптими- зации (поиск по новизне), способным найти решение для множества дезори- ентирующих проблем, которые не могут быть решены с помощью традицион- ных методов поиска на основе целей. Теперь вы готовы применить эти знания на практике после настройки необходимой среды моделирования, которую мы обсудим в следующей главе. В следующей главе мы также рассмотрим доступные библиотеки, позво- ляющие проводить эксперименты с нейроэволюцией в виде кода на языке Python. Вы узнаете, как настроить рабочую среду и какие инструменты при- годятся для управления зависимостями в экосистеме Python.",
          "debug": {
            "start_page": 46,
            "end_page": 46
          }
        },
        {
          "name": "1.7 Дополнительное чтение 45",
          "content": "--- Страница 46 --- (продолжение)\n1.6 заключение В этой главе мы начали с обсуждения различных методов, которые исполь- зуются для обучения искусственных нейронных сетей. Мы рассмотрели, чем традиционные методы градиентного спуска отличаются от методов, основан- ных на нейроэволюции. Затем мы представили один из самых популярных ал- горитмов нейроэволюции (NEAT) и два способа его расширения (HyperNEAT и ES-HyperNEAT). Наконец, вы познакомились с методом поисковой оптими- зации (поиск по новизне), способным найти решение для множества дезори- ентирующих проблем, которые не могут быть решены с помощью традицион- ных методов поиска на основе целей. Теперь вы готовы применить эти знания на практике после настройки необходимой среды моделирования, которую мы обсудим в следующей главе. В следующей главе мы также рассмотрим доступные библиотеки, позво- ляющие проводить эксперименты с нейроэволюцией в виде кода на языке Python. Вы узнаете, как настроить рабочую среду и какие инструменты при- годятся для управления зависимостями в экосистеме Python. 1.7 Д ОпОлнительн Ое чтение Для более глубокого понимания тем, которые мы обсуждали в этой главе, изучите дополнительные материалы по следующим ссылкам: NEAT: http://nn.cs.utexas.edu/downloads/papers/stanley.phd04.pdf; HyperNEAT: https://eplex.cs.ucf.edu/papers/stanley_alife09.pdf; ES-HyperNEAT: https://eplex.cs.ucf.edu/papers/risi_alife12.pdf; Novelty Search: http://joellehman.com/lehman-dissertation.pdf. 1.7 Дополнительное чтение  45\n1.7 Д ОпОлнительн Ое чтение Для более глубокого понимания тем, которые мы обсуждали в этой главе, изучите дополнительные материалы по следующим ссылкам: NEAT: http://nn.cs.utexas.edu/downloads/papers/stanley.phd04.pdf; HyperNEAT: https://eplex.cs.ucf.edu/papers/stanley_alife09.pdf; ES-HyperNEAT: https://eplex.cs.ucf.edu/papers/risi_alife12.pdf; Novelty Search: http://joellehman.com/lehman-dissertation.pdf. 1.7 Дополнительное чтение  45",
          "debug": {
            "start_page": 46,
            "end_page": 47
          }
        }
      ]
    },
    {
      "name": "Глава 2. Библиотеки Python и настройка среды разработки 47",
      "chapters": [
        {
          "name": "2.1 Библиотеки Python для экспериментов с нейроэволюцией 47",
          "content": "--- Страница 48 --- (продолжение)\nГлава 2 Библиотеки Python и настройка среды разработки В этой главе вы познакомитесь с библиотеками Python, которые мы будем ис- пользовать для реализации алгоритмов нейроэволюции, упомянутых в пре- дыдущей главе. Мы также обсудим сильные и слабые стороны каждой пред- ставленной библиотеки. В дополнение к этому рассмотрим обзорные примеры использования. Затем вы узнаете, как настроить среду для экспериментов, ко- торые мы будем выполнять позже в этой книге. Наконец, вы познакомитесь с настройкой рабочей среды при помощи Anaconda Distribution – популярного у исследователей данных инструмента для управления зависимостями Python и виртуальными средами. В данной главе вы узнаете, как начать использовать Python для экспериментов с алгоритмами нейроэволюции, которые будут рас- смотрены в этой книге. В этой главе рассмотрены следующие темы: библиотеки Python для экспериментов с нейроэволюцией; настройка среды разработки. 2.1 библи Отеки pyTHoN Для экСперимент Ов С нейр ОэвОлюцией Язык программирования Python является одним из самых популярных язы- ков для деятельности, связанной с машинным обучением, а также исследо- ваниями и разработками в области искусственного интеллекта. Наиболее известные фреймворки либо написаны на Python, либо предоставляют соот - ветствующие интерфейсы. Такую популярность можно объяснить коротким циклом обучения программированию на Python и тем, что это язык написа- ния сценариев, которые позволяют быстро и просто проводить эксперименты. В соответствии с тенденциями в сообществе машинного обучения на Python было написано несколько библиотек с поддержкой нейроэволюции, и число подобных библиотек со временем продолжает расти. Далее мы рассмотрим\n2.1 библи Отеки pyTHoN Для экСперимент Ов С нейр ОэвОлюцией Язык программирования Python является одним из самых популярных язы- ков для деятельности, связанной с машинным обучением, а также исследо- ваниями и разработками в области искусственного интеллекта. Наиболее известные фреймворки либо написаны на Python, либо предоставляют соот - ветствующие интерфейсы. Такую популярность можно объяснить коротким циклом обучения программированию на Python и тем, что это язык написа- ния сценариев, которые позволяют быстро и просто проводить эксперименты. В соответствии с тенденциями в сообществе машинного обучения на Python было написано несколько библиотек с поддержкой нейроэволюции, и число подобных библиотек со временем продолжает расти. Далее мы рассмотрим\n--- Страница 49 ---\nнаиболее стабильные библиотеки Python для экспериментов в области эво- люционных алгоритмов. 2.1.1 Библиотека NEAT -Python Как следует из названия, это реализация алгоритма NEAT на языке програм- мирования Python. Библиотека NEAT-Python обеспечивает реализацию стан- дартных методов NEAT для моделирования генетической эволюции геномов организмов в популяции. Она содержит утилиты для преобразования геноти- па организма в его фенотип (искусственную нейронную сеть) и предоставля- ет удобные методы для загрузки и сохранения конфигураций генома вместе с параметрами NEAT. Кроме того, она предлагает исследователям полезные подпрограммы, помогающие собирать статистику о ходе эволюционного про- цесса и сохранять/загружать промежуточные контрольные точки. Контроль- ные точки позволяют нам периодически сохранять состояние эволюционного процесса и позже возобновлять выполнение процесса из сохраненных конт- рольных точек. Достоинства библиотеки NEAT-Python: стабильная реализация; всесторонняя документация; доступность для легкой установки при помощи менеджера пакетов PIP; наличие встроенных инструментов сбора статистики и поддержка со- хранения контрольных точек выполнения, а также возобновление вы- полнения с заданной контрольной точки; наличие нескольких типов функций активации; поддержка фенотипов рекуррентных нейронных сетей непрерывного времени; легко расширяется для поддержки различных модификаций NEAT. Недостатки библиотеки NEAT-Python: по умолчанию реализован только алгоритм NEAT; активная разработка библиотеки прекращена, и сейчас она находится в состоянии текущей технической поддержки и мелких доработок. Пример использования NEAT -Python Ниже приведен общий пример использования библиотеки NEAT-Python без прицела на какую-либо конкретную проблему. Он описывает типичные шаги, которые необходимо предпринять, чтобы получить необходимые результаты. Мы будем широко использовать эту библиотеку в данной книге. В принципе, вы можете сразу перейти к следующей главе и приступить к изучению более сложного примера применения, но лучше дочитать эту главу до конца, чтобы узнать больше об альтернативных библиотеках. Давайте начнем. 1. Загрузим настройки NEAT и начальную конфигурацию генома: config = neat.Config (neat.DefaultGenome, neat.DefaultReproduction, neat. DefaultSpeciesSet, neat.DefaultStagnation, config_file) Здесь параметр config_file указывает на файл, который содержит настройки библиотеки NEAT-Python и конфигурацию исходного генома по умолчанию.48  Библиотеки Python и настройка среды разработки\n--- Страница 50 ---\n2. Создадим популяцию организмов из данных конфигурации: p = neat.Population(config) 3. Добавим репо́ртер статистики и сборщик контрольных точек: # Вывод текущего состояния в консоль. p.add_reporter(neat.StdOutReporter(True)) stats = neat.StatisticsReporter() p.add_reporter(stats) p.add_reporter(neat.Checkpointer(5)) 4. Запустим процесс эволюции на определенное количество поколений (в нашем случае 300): winner = p.run(eval_genomes, 300) Здесь eval_genomes – это функция, которая используется для оценки гено- мов всех организмов в популяции с учетом конкретной функции приспособ- ленности, а winner – это лучший генотип. 5. Фенотип нейросети может быть создан из генома следующим образом: winner_ann = neat.nn.FeedForwardNetwork.create(winner, config) 6. После этого мы можем передать в нейросеть входные данные и запросить результаты: for xi in xor_inputs: output = winner_ann.activate(xi) print(xi, output) # Печать результатов. Библиотеку можно скачать по адресу https://github.com/CodeReclaimers/neat-python. Предыдущий пример кода должен дать вам лишь общее представление о библиотеке. Более развернутые примеры кода будут предоставлены в сле- дующих главах. 2.1.2 Библиотека PyT orch NEAT Эта библиотека построена как оболочка вокруг библиотеки NEAT-Python. Она обеспечивает простую интеграцию сущностей, созданных библиотекой NEAT- Python с платформой PyTorch. В результате появляется возможность преобра- зовать геном NEAT в фенотип нейросети, который основан на реализации ре- куррентных нейронных сетей посредством PyTorch. Кроме того, это позволяет нам представлять сети CPPN в виде структур PyTorch, которые являются ос- новными строительными блоками метода HyperNEAT. Благодаря интеграции с PyTorch мы получаем возможность использовать графические процессоры для вычислений, потенциально ускоряя эволюционный процесс благодаря по- вышенной скорости оценки геномов организмов в развивающейся популяции. Достоинства библиотеки PyTorch NEAT: построена на основе стабильной библиотеки NEAT-Python, что позво- ляет нам использовать все ее преимущества; 2.1 Библиотеки Python для экспериментов с нейроэволюцией  49\n--- Страница 51 ---\nинтеграция с платформой PyTorch; применение GPU ускоряет оценку геномов NEAT; включает в себя реализацию CPPN, которая является строительным блоком алгоритма HyperNEAT; интеграция со средой OpenAI GYM. Недостатки PyTorch NEAT заключаются в следующем: полностью реализован только алгоритм NEAT; обеспечивает лишь частичную поддержку реализации алгоритма HyperNEAT. Про OpenAI GYM можно больше узнать по адресу https://gym.openai.com. Пример использования PyT orch NEAT Ниже приведен пример использования библиотеки PyTorch NEAT для реализа- ции контроллера балансировки обратного маятника. Пока это лишь обзорный пример. Позже в этой книге мы более подробно рассмотрим проблему балан- сировки маятника на тележке. Давайте начнем. 1. Загрузим настройки NEAT и конфигурацию начального генома: config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction, neat.DefaultSpeciesSet, neat.DefaultStagnation, config_file) Здесь файл config_file хранит настройки алгоритма NEAT, а также конфи- гурацию генома по умолчанию. 2. Создадим популяцию организмов на основе конфигурации: pop = neat.Population(config) 3. Подготовим оценщик генома в мультисредах на основе PyTorch и OpenAI GYM: def make_env(): return gym.make(\"CartPole-v0\") def make_net(genome, config, bs): return RecurrentNet.create(genome, config, bs) def activate_net(net, states): outputs = net.activate(states).numpy() return outputs[:, 0] > 0.5 evaluator = MultiEnvEvaluator( make_net, activate_net, make_env=make_env, max_env_steps=max_env_steps) def eval_genomes(genomes, config): for _, genome in genomes: genome.fitness = evaluator.eval_genome(genome, config)50  Библиотеки Python и настройка среды разработки\n--- Страница 52 ---\nЗдесь вызов функции gym.make(\"CartPole-v0\") – это обращение к фреймвор- ку OpenAI GYM для создания среды балансировки одиночного маятника. 4. Добавим сбор статистики и ведение отчета: stats = neat.StatisticsReporter() pop.add_reporter(stats) reporter = neat.StdOutReporter(True) pop.add_reporter(reporter) logger = LogReporter(\"neat.log\", evaluator.eval_genome) pop.add_reporter(logger) 5. Запустим процесс эволюции на определенное количество поколений (в нашем случае 100): winner = pop.run(eval_genomes, 100) Здесь eval_genomes – это функция для оценки геномов всех организмов в по- пуляции по определенной функции пригодности, и победителем является наиболее эффективный найденный генотип. 6. Создадим из генома фенотип нейросети: winner_ann = RecurrentNet.create(genome, config, bs) Здесь genome – это конфигурация генома NEAT, config – объект, который ин- капсулирует настройки NEAT, а bs – параметр, указывающий желаемый раз- мер пакета. 7. Теперь мы можем передать в нейросеть входные данные и запросить ре- зультат: action = winner_ann.activate(states).numpy() Здесь action – это спецификатор действия, который будет использоваться в симуляции, а states – это тензор, который включает текущее состояние сре- ды, полученное из симулятора. Исходный код библиотеки доступен по адресу https://github.com/ uber-research/PyT orch-NEAT. Предыдущий исходный код должен дать вам общее представление о биб- лиотеке. Полные примеры кода будут предоставлены в следующих главах. 2.1.3 Библиотека MultiNEAT Библиотека MultiNEAT является самой универсальной среди библиотек, ко- торые мы обсудим в этой книге, поскольку она поддерживает стандартный алгоритм NEAT и два важнейших расширения: HyperNEAT и ES-HyperNEAT. Кроме того, библиотека MultiNEAT обеспечивает реализацию метода оптими- зации поиском новизны. Библиотека написана на языке программирования C++, но предоставляет полный интерфейс в среде Python. Установочный пакет MultiNEAT Python также доступен посредством менеджера пакетов Anaconda, который упрощает установку и использование в любой ОС. Достоинства библиотеки MultiNEAT: 2.1 Библиотеки Python для экспериментов с нейроэволюцией  51\n--- Страница 53 ---\nстабильная реализация; реализует множество алгоритмов из семейства NEAT, таких как: NEAT; HyperNEAT; ES-HyperNEAT; обеспечивает реализацию метода оптимизации поиском новизны; поддерживает пластичные нейронные сети Хебба; обеспечивает визуализацию генотипов и фенотипов при помощи OpenCV в Python; интеграция со средой OpenAI GYM; комплексная документация. Недостатки библиотеки MultiNEAT: нет поддержки графического процессора; не поддерживает контрольные точки. Пример использования MultiNEAT Ниже приведен пример использования библиотеки MultiNEAT для реа- лизации решателя XOR с использованием нейроэволюции. Это всего лишь обзорный пример без реализации оценщика приспособленности XOR ( evalu- ate_xor), который будет обсуждаться в следующей главе. Давайте начнем. 1. Зададим настройки конфигурации NEAT: params = NEAT.Parameters() params.PopulationSize = 100 # Остальные настройки опущены для краткости. 2. Создадим минимальную конфигурацию генома и породим популяцию организмов из этого генома: g = NEAT.Genome(0, 3, 0, 1, False, NEAT.ActivationFunction.UNSIGNED_SIGMOID, NEAT.ActivationFunction.UNSIGNED_SIGMOID, 0, params, 0) pop = NEAT.Population(g, params, True, 1.0, i) 3. Запустим процесс эволюции на 1000 поколений или пока не будет най- ден победитель: for generation in range(1000): # Оценка геномов. genome_list = NEAT.GetGenomeList(pop) fitnesses = EvaluateGenomeList_Serial(genome_list, evaluate_xor, display=False) [genome.SetFitness(fitness) for genome, fitness inzip(genome_list, fitnesses)] # Оценка значения пригодности относительно заданного порога. best = max(fitness_list) if best > 15.0: # Получаем фенотип наилучшего организма. net = NEAT.NeuralNetwork() pop.Species[0].GetLeader().BuildPhenotype(net)52  Библиотеки Python и настройка среды разработки\n--- Страница 54 ---\n# Возвращаем приспособленность и фенотип нейросети победителя. return (best, net) # Следующая эпоха. pop.Epoch() 4. Ниже приводится запрос фенотипа нейросети победителя, а также вход- ные данные: net.Input( [ 1.0, 0.0, 1.0 ] ) net.Activate() output = net.Output() Библиотеку можно скачать по адресу https://github.com/peter-ch/ MultiNEAT. Предыдущий исходный код дает вам общее представление о библиотеке. Развернутые примеры кода будут предоставлены в следующих главах. 2.1.4 Библиотека Deep Neuroevolution Глубокие нейронные сети ( deep neural networks, DNN) демонстрируют выдаю- щийся прирост производительности в задачах, связанных с распознаванием образов и обучением с подкреплением, используя возможности параллельной обработки современных графических процессоров. В контексте нейроэволю- ции особенно интересно исследовать, как обычные методы глубокого обучения с подкреплением ( deep reinforcement learning, RL) можно сопоставить с метода- ми, основанными на глубокой нейроэволюции. Чтобы ответить на этот вопрос, исследовательская группа из лаборатории UberAI разработала и опубликовала библиотеку Deep Neuroevolution на языке программирования Python, которая использует платформу TensorFlow для вычислений, связанных с обучением нейронной сети на устройствах с графическим процессором. Библиотека обеспечивает реализацию простого генетического алгоритма (genetic algorithm, GA) и метода оптимизации поиском новизны. Она также реализует метод эволюционных стратегий, который представляет собой еще один вид эволюционного алгоритма. Вы можете найти более подробную информацию о методе эволюцион- ных стратегий в статье: Hans-Georg Beyer. The Theory of Evolution Strategies. Springer April 27, 2001. Достоинства библиотеки Deep Neuroevolution заключаются в следующем: стабильная реализация; поддержка графического процессора через интеграцию с TensorFlow; способность работать напрямую с многомерными задачами, например учиться действовать прямо на уровне пикселей; наличие метода оптимизации поиском новизны; безградиентный метод для оптимизации DNN; обеспечивает визуализацию процесса обучения с помощью визуального инспектора для нейроэволюции (visual inspector for neuroevolution, VINE); 2.1 Библиотеки Python для экспериментов с нейроэволюцией  53\n--- Страница 55 ---\nобеспечивает интеграцию со средой OpenAI GYM; обеспечивает интеграцию со средой игр Atari. Недостаток библиотеки Deep Neuroevolution заключается в том, что она не обеспечивает реализацию алгоритмов нейроэволюции семейства NEAT, то есть NEAT, HyperNEAT и ES-HyperNEAT. Генетический алгоритм, который реализован в библиотеке Deep Neuroevolution, контролирует эволюцию популяции организмов с геномами, кодирующими вектор параметров обучения (веса соединений) для глубокой нейронной сети. В каждом поколении каждый генотип оценивается и дает оценку пригодности. После этого определенное количество организмов вы- бирается случайным образом из числа наиболее подходящих людей, чтобы стать родителями следующего поколения. Генотип каждого выбранного ро- дительского организма затем мутирует путем добавления гауссова шума. Кроме того, в алгоритме используется понятие элитарности, при котором конкретное количество организмов, наиболее подходящих по форме, из пре- дыдущего поколения добавляется к следующему без каких-либо изменений. Оператор кроссовера не применяется во время эволюционного процесса для упрощения алгоритма. Топология DNN, используемая в этом алгоритме, фик - сирована и установлена экспериментаторами вручную. Рассмотрим следующий простой генетический алгоритм, представленный в общей форме на рис. 2.1. 54  Библиотеки Python и настройка среды разработки\n--- Страница 56 ---\nРис. 2.1. Пример простого генетического алгоритма в общей форме Больше информации о реализации библиотеки Deep Neuroevolution можно найти по адресу https://github.com/uber-research/deep-neuro- evolution. 2.1.5 Сравнение библиотек Python, реализующих нейроэволюцию В табл. 2.1 приведена сравнительная информация о библиотеках Python, кото- рые мы обсуждали в этой главе. Таблица 2.1 Сравнение библиотек Python, реализующих алгоритмы нейроэволюции NEAT -Python PyT orch NEAT MultiNEAT Deep Neuroevolution NEAT Да Да Да Нет HyperNEAT Нет Частично (только CPPN) Да Нет ES-HyperNEAT Нет Нет Да Нет Поиск новизны Нет Нет Да Да OpenAI GYM Нет Да Да Да Визуализация Нет Нет Да Да Поддержка GPU Нет Да Нет Да PIP Да Нет Нет Нет Anaconda Нет Нет Да Нет Контрольные точки Да Да Нет Да Библиотека NEAT-Python обеспечивает отличную интеграцию визуализа- ции и проста в использовании. Однако ее существенный недостаток в том, что она реализована исключительно на языке Python и, как следствие, имеет очень низкую скорость выполнения. Подходит только для простых задач. Библиотека MultiNEAT Python имеет ядро, реализованное на C ++, что дает ей немного лучшую производительность по сравнению с библиотекой NEAT- Python. Она может быть использована для решения более сложных задач, требующих создания более крупных фенотипов нейросети. Кроме того, она обеспечивает реализацию методов HyperNEAT и ES-HyperNEAT, что делает ее правильным выбором для задач, связанных с обучением крупномасштабных нейросетей. Библиотека Deep Neuroevolution является самой продвинутой реализа- цией нейроэволюции и позволяет нам использовать возможности графиче- ских процессоров для выполнения задач машинного обучения с миллионами обуча емых параметров. Ей можно найти хорошее применение в области об- работки визуальных данных. 2.1 Библиотеки Python для экспериментов с нейроэволюцией  55\n--- Страница 57 ---\nПозже в этой книге мы познакомимся с каждой из упомянутых библиотек Python поближе и применим их на практике.",
          "debug": {
            "start_page": 48,
            "end_page": 57
          }
        },
        {
          "name": "2.2 Настройка среды 56",
          "content": "--- Страница 57 --- (продолжение)\n2.2 наСтрОйка СреДы При работе с библиотеками Python важно правильно настроить рабочую среду. Существует много зависимостей, включая версию на языке Python и двоичные файлы, доступные в системе; все они должны быть собраны в одном месте и иметь совместимые версии. В процессе подбора и установки зависимостей легко могут возникнуть конфликтующие конфигурации библиотек и языковых версий, что огорчит исследователя и заставит его потратить много часов на поиск и исправ- ление ошибок. Чтобы решить эту проблему, в языке программирования Python была введена концепция виртуальной среды. Виртуальная среда позволяет нам создавать изолированные среды Python, которые содержат все необходимые за- висимости и исполняемые файлы, которые используются в конкретном проекте Python. Такая виртуальная среда может быть легко создана и удалена после того, как она больше не нужна, не оставляя никаких следов в системе. Среди наиболее популярных инструментов для работы с виртуальными средами Python можно выделить следующие: Pipenv; Virtualenv; Anaconda. 2.2.1 Pipenv Pipenv – это инструмент, который объединяет менеджер пакетов с менедже- ром виртуальных сред. Основная цель – упростить для разработчиков настрой- ку уникальной рабочей среды для конкретного проекта со всеми необходимы- ми зависимостями. Pipenv можно установить с помощью PIP (установщик пакета для Python), введя в терминале следующую команду: $ pip install --user pipenv Эта команда устанавливает инструмент pipenv в пространство пользовате- ля, чтобы не допустить вмешательства в любые общесистемные пакеты. Чтобы установить все зависимости и создать новую виртуальную среду (если она отсутствует) для вашего проекта, перейдите в каталог проекта и за- пустите процесс установки следующим образом: $ cd my_project_folder $ pipenv install <package> Эта команда создает новую виртуальную среду в my_project_folder и уста- навливает в нее пакет <package> . Вот и все. Вы можете предоставить файл конфигурации (Pipfile), который указывает установщику, какие пакеты должны быть установлены, а также другую ин- формацию, относящуюся к процессу построения среды. Когда вы запускаете install в первый раз, файл Pipfile будет создан автоматически, если он еще не существует.56  Библиотеки Python и настройка среды разработки\n2.2 наСтрОйка СреДы При работе с библиотеками Python важно правильно настроить рабочую среду. Существует много зависимостей, включая версию на языке Python и двоичные файлы, доступные в системе; все они должны быть собраны в одном месте и иметь совместимые версии. В процессе подбора и установки зависимостей легко могут возникнуть конфликтующие конфигурации библиотек и языковых версий, что огорчит исследователя и заставит его потратить много часов на поиск и исправ- ление ошибок. Чтобы решить эту проблему, в языке программирования Python была введена концепция виртуальной среды. Виртуальная среда позволяет нам создавать изолированные среды Python, которые содержат все необходимые за- висимости и исполняемые файлы, которые используются в конкретном проекте Python. Такая виртуальная среда может быть легко создана и удалена после того, как она больше не нужна, не оставляя никаких следов в системе. Среди наиболее популярных инструментов для работы с виртуальными средами Python можно выделить следующие: Pipenv; Virtualenv; Anaconda. 2.2.1 Pipenv Pipenv – это инструмент, который объединяет менеджер пакетов с менедже- ром виртуальных сред. Основная цель – упростить для разработчиков настрой- ку уникальной рабочей среды для конкретного проекта со всеми необходимы- ми зависимостями. Pipenv можно установить с помощью PIP (установщик пакета для Python), введя в терминале следующую команду: $ pip install --user pipenv Эта команда устанавливает инструмент pipenv в пространство пользовате- ля, чтобы не допустить вмешательства в любые общесистемные пакеты. Чтобы установить все зависимости и создать новую виртуальную среду (если она отсутствует) для вашего проекта, перейдите в каталог проекта и за- пустите процесс установки следующим образом: $ cd my_project_folder $ pipenv install <package> Эта команда создает новую виртуальную среду в my_project_folder и уста- навливает в нее пакет <package> . Вот и все. Вы можете предоставить файл конфигурации (Pipfile), который указывает установщику, какие пакеты должны быть установлены, а также другую ин- формацию, относящуюся к процессу построения среды. Когда вы запускаете install в первый раз, файл Pipfile будет создан автоматически, если он еще не существует.56  Библиотеки Python и настройка среды разработки\n--- Страница 58 ---\nБольше информации об этом инструменте можно найти по адресу https://pipenv.kennethreitz.org/en/latest/. 2.2.2 Virtualenv Virtualenv – это инструмент, который используется для создания изолирован- ных сред Python, начиная с Python v3.3, и частично интегрирован в стандарт - ную библиотеку в модуле venv. Основная проблема, которая решается с по- мощью этого инструмента, заключается в поддержании уникального набора зависимостей, версий и разрешений для каждого проекта Python по отдель- ности. Virtualenv решает эту задачу, создавая отдельную среду с собственными установочными каталогами для каждого проекта. Это не позволяет нам сме- шивать какие-либо зависимости и библиотеки с другими проектами. Также можно заблокировать доступ к глобально установленным библиотекам. Virtualenv – это чистый менеджер виртуальных сред, который не предо- ставляет никаких процедур менеджера пакетов. Поэтому для управления за- висимостями проекта он обычно нуждается в менеджере пакетов, таком как PIP. Давайте коротко продемонстрируем работу с Virtualenv. Установите Virtualenv при помощи менеджера пакетов PIP: $ pip install virtualenv 1. Убедитесь, что установка прошла успешно: $ virtualenv --version 2. Создайте виртуальную среду для вашего проекта с помощью следующих команд: $ cd my_project_folder $ virtualenv venv Эти команды создают новую виртуальную среду в каталоге вашего про- екта my_project_folder . Свежая среда включает в себя папку с исполняемыми файлами Python внутри нее, а также копию библиотеки PIP, которая является менеджером пакетов, позволяющим устанавливать другие зависимости. 3. Перед началом использования виртуальную среду необходимо активи- ровать с помощью следующей команды, которую необходимо ввести в окне терминала: $ source /path/to/ENV/bin/activate После выполнения этой команды все необходимые переменные среды бу- дут установлены в правильные значения, характерные для вашего проекта, и текущий сеанс терминала будет использовать их для любых последующих введенных команд. 4. С помощью PIP в активную среду можно легко установить дополнитель- ные пакеты: $ pip install sqlite Данная команда устанавливает пакет SQLite в текущей активной среде. 2.2 Настройка среды  57\n--- Страница 59 ---\nЕсли после команды pip install не указано имя пакета, менеджер PIP будет искать в текущем каталоге файл requirements.txt для определения перечня устанавливаемых пакетов. Дополнительная информация доступна по адресу https://virtualenv. pypa.io/en/latest/. 2.2.3 Anaconda Distribution Anaconda Distribution – это установочный пакет и менеджер виртуальной сре- ды, который популярен среди специалистов по обработке данных и машинно- му обучению, поскольку он обеспечивает легкий доступ к обширной коллекции специализированных научных библиотек (более 1500) и полезных инструмен- тов. Кроме того, он позволяет вам писать исходный код и выполнять скрипты на Python и R из одного места. С помощью Anaconda можно легко создавать, сохранять, загружать и переключаться между виртуальными средами, а также устанавливать из хранилища в каждую виртуальную среду тысячи пакетов, ко- торые были проверены и подготовлены группой Anaconda. Для установки Anaconda необходимо скачать установочный файл, со- ответствующий вашей операционной системе, по адресу https://www. anaconda.com/distribution/. После установки Anaconda вы можете создать новую среду для вашего про- екта с помощью следующих команд: $ cd my_project_folder $ conda create --name ENV_NAME <package> Эти команды создают новую виртуальную среду для вашего проекта и уста- навливают в нее указанный пакет или несколько пакетов. Дополнительные па- кеты могут быть легко установлены в новую среду позже, после ее активации. Список всех доступных в системе сред можно получить с помощью следу - ющей команды: $ conda env list Любая существующая среда может быть активирована следующим образом: $ conda activate ENV_NAME Чтобы деактивировать текущую активную среду, используйте команду $ conda deactivate Дополнительные библиотеки могут быть установлены в текущей среде либо через стандартный менеджер PIP, либо с помощью команды conda in- stall: $ conda install sqlite После выполнения предыдущей команды в текущую активную среду будет установлен пакет SQLite.58  Библиотеки Python и настройка среды разработки\n--- Страница 60 ---\nВ этой книге мы будем использовать Anaconda для управления зависимо- стями и средами для большинства наших проектов. Если вы хотите больше узнать о командах Anaconda, обратитесь по адресу https://docs.anaconda.com/anaconda-cloud/commandreference/.",
          "debug": {
            "start_page": 57,
            "end_page": 60
          }
        },
        {
          "name": "2.3 Заключение 59",
          "content": "--- Страница 60 --- (продолжение)\n2.3 Заключение В этой главе вы узнали о четырех популярных библиотеках Python, которые можно использовать для экспериментов в области нейроэволюции. Мы обсу - дили сильные и слабые стороны каждой представленной библиотеки и рас - смотрели обзорные примеры использования этих библиотек в Python. После этого рассмотрели, как настроить рабочую среду для экспериментов в окруже- нии Python, чтобы избежать побочных эффектов наличия нескольких версий одной и той же библиотеки в пути Python. Мы обнаружили, что лучший способ сделать это – создать изолированные виртуальные среды для каждого проекта Python, и разобрали несколько популярных решений этой задачи, созданных сообществом открытого исходного кода. Наконец, вы познакомились с инстру - ментом Anaconda Distribution, который включает, помимо прочего, менеджер пакетов и менеджер среды. В оставшейся части этой книги мы будем использо- вать Anaconda для правильной настройки среды в наших экспериментах. В следующей главе мы обсудим, как использовать алгоритм NEAT для ре- шения классической проблемы информатики. Вы создадите решатель проб- лемы XOR, используя библиотеку NEAT-Python, которую мы обсуждали в этой главе. Мы также обсудим гиперпараметры, которые используются для на- стройки алгоритма NEAT, и способы их подбора для повышения производи- тельности процесса нейроэволюции. 2.2 Настройка среды  59\n2.3 Заключение В этой главе вы узнали о четырех популярных библиотеках Python, которые можно использовать для экспериментов в области нейроэволюции. Мы обсу - дили сильные и слабые стороны каждой представленной библиотеки и рас - смотрели обзорные примеры использования этих библиотек в Python. После этого рассмотрели, как настроить рабочую среду для экспериментов в окруже- нии Python, чтобы избежать побочных эффектов наличия нескольких версий одной и той же библиотеки в пути Python. Мы обнаружили, что лучший способ сделать это – создать изолированные виртуальные среды для каждого проекта Python, и разобрали несколько популярных решений этой задачи, созданных сообществом открытого исходного кода. Наконец, вы познакомились с инстру - ментом Anaconda Distribution, который включает, помимо прочего, менеджер пакетов и менеджер среды. В оставшейся части этой книги мы будем использо- вать Anaconda для правильной настройки среды в наших экспериментах. В следующей главе мы обсудим, как использовать алгоритм NEAT для ре- шения классической проблемы информатики. Вы создадите решатель проб- лемы XOR, используя библиотеку NEAT-Python, которую мы обсуждали в этой главе. Мы также обсудим гиперпараметры, которые используются для на- стройки алгоритма NEAT, и способы их подбора для повышения производи- тельности процесса нейроэволюции. 2.2 Настройка среды  59\n--- Страница 62 ---\nЧасть II Применение методов нейроэволюции для решения классических задач информатики В этой части книги речь пойдет о том, как применять нейроэволюционные алгоритмы для решения классических проблем информатики. Вы изучите основные приемы и навыки, необходимые для использования нейроэволю- ционных алгоритмов при решении классических задач информатики, а так - же подготовитесь к работе с более продвинутыми методами, описанными в третьей части книги. Эта часть состоит из следующих глав: главы 3 «Использование NEAT для оптимизации решения задачи XOR»; главы 4 «Эксперименты по балансировке маятника»; главы 5 «Автономное прохождение лабиринта»; главы 6 «Метод оптимизации поиском новизны».",
          "debug": {
            "start_page": 60,
            "end_page": 63
          }
        }
      ]
    },
    {
      "name": "Глава 3. Использование NEAT для оптимизации решения задачи XOR 63",
      "chapters": [
        {
          "name": "3.1 Технические требования 63",
          "content": "--- Страница 64 --- (продолжение)\nГлава 3 Использование NEAT для оптимизации решения задачи XOR В этой главе вы узнаете об одном из классических компьютерных экспери- ментов, который демонстрирует, что алгоритм NEAT работоспособен и может создать правильную топологию сети. Вы узнаете из первых рук о написании целевой функции для решения задачи XOR. Также узнаете, как выбрать пра- вильные гиперпараметры алгоритма NEAT, оптимальные для решения задачи XOR. Цель этой главы – познакомить вас с основными приемами применения алгоритма NEAT для решения классических задач информатики. После завершения эксперимента и выполнения упражнений, описанных в этой главе, вы получите четкое представление об особенностях экспери- мента XOR и получите практические навыки, необходимые для написания соответствующего исходного кода Python с использованием библиотеки NEAT-Python. Вы также получите опыт настройки гиперпараметров библи- отеки NEAT-Python и использования специальных утилит для визуализации результатов эксперимента. После этого вы будете готовы приступить к экс - периментам с более сложными задачами, о которых узнаете немного позже. В этой главе мы рассмотрим следующие темы: суть задачи XOR; как определить целевую функцию для решателя задачи XOR; выбор гиперпараметров для эксперимента XOR; запуск эксперимента XOR. 3.1 техничеСкие требОвания Для проведения экспериментов, описанных в этой главе, ваш компьютер дол- жен удовлетворять следующим техническим требованиям: Windows 8/10, macOS 10.13 или новее, или современный Linux; Anaconda Distribution версия 2019.03 или новее.\n3.1 техничеСкие требОвания Для проведения экспериментов, описанных в этой главе, ваш компьютер дол- жен удовлетворять следующим техническим требованиям: Windows 8/10, macOS 10.13 или новее, или современный Linux; Anaconda Distribution версия 2019.03 или новее.\n--- Страница 65 ---\nИсходный код примеров этой главы можно найти в каталоге Chapter3 в фай- ловом архиве книги.",
          "debug": {
            "start_page": 64,
            "end_page": 65
          }
        },
        {
          "name": "3.2 Суть задачи XOR 64",
          "content": "--- Страница 65 --- (продолжение)\n3.2 С уть заДачи Xor Классический многослойный персептрон ( multilayer perceptron, MLP) или ис- кусственная нейронная сеть (artificial neural network, ANN), не обладающие скрытыми узлами топологии, способны правильно решать только задачи с линейно разделяемым пространством решений. В результате такие кон- фигурации не могут использоваться в качестве шаблона решения задач рас- познавания или управления. Однако, используя более сложные архитектуры MLP, включающие в себя скрытые элементы с некоторой нелинейной функ - цией активации (например, сигмоидальной), можно аппроксимировать лю- бую функцию с заданной точностью. Поэтому мы можем взять нелинейно разделяемую задачу и проверить, способен ли процесс нейроэволюции вы- растить произвольное количество скрытых элементов в фенотипе нейросети решателя задачи. Решатель задачи XOR – это классический компьютерный эксперимент в об- ласти обучения с подкреплением, который не может быть решен без введе- ния нелинейного этапа в алгоритм решателя. Пространство поиска решения задачи имеет минимальный размер и подходит для демонстрации того, что алгоритм NEAT способен развивать топологию нейросети, начиная с очень простой и постепенно увеличивая сложность, чтобы найти подходящую структуру сети, в которой все связи организованы надлежащим образом. Де- монстрируя способность алгоритма NEAT последовательно наращивать соот - ветствующую топологию, эксперимент XOR также демонстрирует, что NEAT может избежать локальных максимумов ландшафта приспособленности. Ло- кальный максимум – это ловушка, в которой решатель может застрять, соз- дав локального лидера с неправильной схемой связей. После этого локаль- ный чемпион может доминировать над популяцией настолько, что решатель не сможет решить задачу. Таблица истинности функции XOR выглядит следующим образом: Таблица 2.1. Таблица истинности функции XOR (исключающее ИЛИ) Вход 1 Вход 2 Выход 1 1 0 1 0 1 0 1 1 0 0 0 XOR (исключающее ИЛИ) – это двоичный логический оператор, который возвращает логическую единицу (истину), если только на одном из входов присутствует единица. Для получения правильного выходного сигнала два входных сигнала должны быть объединены нелинейным скрытым элемен- том. Не существует линейной функции для комбинации входов XOR, которая могла бы правильно разделить их на классы.64  Использование NEAT для оптимизации решения задачи XOR\n3.2 С уть заДачи Xor Классический многослойный персептрон ( multilayer perceptron, MLP) или ис- кусственная нейронная сеть (artificial neural network, ANN), не обладающие скрытыми узлами топологии, способны правильно решать только задачи с линейно разделяемым пространством решений. В результате такие кон- фигурации не могут использоваться в качестве шаблона решения задач рас- познавания или управления. Однако, используя более сложные архитектуры MLP, включающие в себя скрытые элементы с некоторой нелинейной функ - цией активации (например, сигмоидальной), можно аппроксимировать лю- бую функцию с заданной точностью. Поэтому мы можем взять нелинейно разделяемую задачу и проверить, способен ли процесс нейроэволюции вы- растить произвольное количество скрытых элементов в фенотипе нейросети решателя задачи. Решатель задачи XOR – это классический компьютерный эксперимент в об- ласти обучения с подкреплением, который не может быть решен без введе- ния нелинейного этапа в алгоритм решателя. Пространство поиска решения задачи имеет минимальный размер и подходит для демонстрации того, что алгоритм NEAT способен развивать топологию нейросети, начиная с очень простой и постепенно увеличивая сложность, чтобы найти подходящую структуру сети, в которой все связи организованы надлежащим образом. Де- монстрируя способность алгоритма NEAT последовательно наращивать соот - ветствующую топологию, эксперимент XOR также демонстрирует, что NEAT может избежать локальных максимумов ландшафта приспособленности. Ло- кальный максимум – это ловушка, в которой решатель может застрять, соз- дав локального лидера с неправильной схемой связей. После этого локаль- ный чемпион может доминировать над популяцией настолько, что решатель не сможет решить задачу. Таблица истинности функции XOR выглядит следующим образом: Таблица 2.1. Таблица истинности функции XOR (исключающее ИЛИ) Вход 1 Вход 2 Выход 1 1 0 1 0 1 0 1 1 0 0 0 XOR (исключающее ИЛИ) – это двоичный логический оператор, который возвращает логическую единицу (истину), если только на одном из входов присутствует единица. Для получения правильного выходного сигнала два входных сигнала должны быть объединены нелинейным скрытым элемен- том. Не существует линейной функции для комбинации входов XOR, которая могла бы правильно разделить их на классы.64  Использование NEAT для оптимизации решения задачи XOR\n--- Страница 66 ---\nАлгоритм NEAT начинается с начальной популяции, которая кодирует очень простой фенотип, и постепенно развивает топологию фенотипа, пока не бу - дет создана структура успешной нейросети. Начальная структура фенотипа нейросети не содержит никаких скрытых узлов и состоит из двух входных уз- лов, одного выходного узла и одного узла смещения. Два входных узла и узел смещения связаны с выходным узлом, то есть исходный генотип имеет три гена связи и четыре гена узла. Узел смещения – это особый тип ввода, кото- рый всегда инициализируется определенным значением, большим 0 (обычно это 1,0 или 0,5). Узел смещения необходим, если мы хотим привести актива- цию нейрона (выходного или скрытого) – которая рассчитывается соответ - ствующей функцией активации, применяемой к сумме входов и смещения, – к определенному ненулевому значению, если оба входа имеют значение 0. Начальный и оптимальный (наименьший возможный) фенотипы решате- ля XOR показаны на рис. 2.1. Фенотип наименьшего возможного решения Сеть из начальной популяции Рис. 3.1. Начальный и оптимальный фенотипы решателя XOR Фенотип становится все сложнее, пока не будет найдено окончательное решение путем добавления одного или нескольких дополнительных скры- тых узлов. Наименьший возможный решатель включает в себя только один скрытый узел, а метод NEAT демонстрирует свою мощь, находя оптимальную конфигурацию решателя среди более сложных.",
          "debug": {
            "start_page": 65,
            "end_page": 66
          }
        },
        {
          "name": "3.3 Целевая функция для эксперимента XOR 65",
          "content": "--- Страница 66 --- (продолжение)\n3.3 целевая функция Для экСперимента Xor В эксперименте XOR приспособленность организма в популяции опре- деляется как квадрат расстояния между правильным ответом и суммой вы- ходных данных, которые генерируются для всех четырех входных состояний XOR. Она рассчитывается следующим образом: 1. Фенотип нейросети активируется всеми четырьмя входными состояния- ми XOR. 2. Выходные значения вычитаются из правильных ответов для каждого со- стояния, а затем суммируются абсолютные значения результатов. 3.3 Целевая функция для эксперимента XOR  65\n3.3 целевая функция Для экСперимента Xor В эксперименте XOR приспособленность организма в популяции опре- деляется как квадрат расстояния между правильным ответом и суммой вы- ходных данных, которые генерируются для всех четырех входных состояний XOR. Она рассчитывается следующим образом: 1. Фенотип нейросети активируется всеми четырьмя входными состояния- ми XOR. 2. Выходные значения вычитаются из правильных ответов для каждого со- стояния, а затем суммируются абсолютные значения результатов. 3.3 Целевая функция для эксперимента XOR  65\n--- Страница 67 ---\n3. Значение ошибки, найденное на предыдущем шаге, вычитается из мак- симального значения приспособленности (4) для расчета приспособлен- ности текущего организма. Наивысшая приспособленность означает наилучшую точность решателя. 4. Затем рассчитанная приспособленность возводится в квадрат, чтобы пропорционально повысить приспособленность организмов, тем самым получая решающие нейросети, которые дают более близкие к правиль- ному ответу решения. Такой подход делает эволюционное давление бо- лее интенсивным. Исходя из сказанного, целевую функцию можно определить следующим образом: ()24 14 12i i i if y ANNx,x = =−−    ∑ . Соответствующий исходный код, основанный на библиотеке NEAT-Python, выглядит так: # Входы XOR и ожидаемые выходные значения. xor_inputs = [(0.0, 0.0), (0.0, 1.0), (1.0, 0.0), (1.0, 1.0)] xor_outputs = [ (0.0,), (1.0,), (1.0,), (0.0,)] def eval_fitness(net): error_sum = 0.0 for xi, xo in zip(xor_inputs, xor_outputs): output = net.activate(xi) error_sum += abs(output[0] - xo[0]) # Вычисляем усиленную приспособленность. fitness = (4 - error_sum) ** 2 return fitness Обратите внимание, что нет необходимости нормализовать значение при- способленности для соответствия диапазону [0,1] (как это происходит с мето- дами на основе обратного распространения), потому что в процессе обучения не используются вычисления обратного градиента. Показатели приспособ- ленности организмов сравниваются напрямую на основе их абсолютных зна- чений. Таким образом, диапазон значений не важен. Вы можете попробовать собственные варианты расчета баллов приспособлен- ности. Например, вы можете реализовать функцию, напоминающую среднеквад- ратичную ошибку, и сравнить точность алгоритма для различных реализаций целевой функции. Единственное требование состоит в том, что целевая функция должна давать более высокие оценки приспособленности для лучших решателей.",
          "debug": {
            "start_page": 66,
            "end_page": 67
          }
        },
        {
          "name": "3.4 Настройка гиперпараметров 66",
          "content": "--- Страница 67 --- (продолжение)\n3.4 н аСтрОйка гиперпараметр Ов Эксперимент XOR, который мы обсудим в этой главе, в качестве фреймвор- ка использует библиотеку NEAT-Python. Библиотека NEAT-Python использует набор гиперпараметров, которые влияют на выполнение и точность алгорит - ма NEAT. Файл конфигурации хранится в формате, аналогичном файлам .ini 66  Использование NEAT для оптимизации решения задачи XOR\n3.4 н аСтрОйка гиперпараметр Ов Эксперимент XOR, который мы обсудим в этой главе, в качестве фреймвор- ка использует библиотеку NEAT-Python. Библиотека NEAT-Python использует набор гиперпараметров, которые влияют на выполнение и точность алгорит - ма NEAT. Файл конфигурации хранится в формате, аналогичном файлам .ini 66  Использование NEAT для оптимизации решения задачи XOR\n--- Страница 68 ---\nWindows, – каждая секция начинается с имени в квадратных скобках [секция], за которым следуют пары ключ–значение, разделенные знаком равенства ( =). В этом разделе мы обсудим некоторые гиперпараметры библиотеки NEAT- Python, которые можно найти в разделах файла конфигурации. Полный перечень гиперпараметров библиотеки NEAT-Python можно найти по адресу https://neat-python.readthedocs.io/en/latest/config_ file.html. 3.4.1 Секция NEAT В этой секции указываются параметры, специфичные для алгоритма NEAT. Раздел включает в себя следующие параметры: fitness_criterion – функция, которая вычисляет критерий завершения из набора значений приспособленности всех геномов в популяции. Значения параметров – это имена стандартных агрегатных функций, таких как min, max и mean. Значения min и max используются для заверше- ния процесса эволюции, если минимальная или максимальная приспо- собленность популяции превышает заданный порог fitness_threshold . Когда значение задано как mean, в качестве критерия завершения ис- пользуется средняя приспособленность популяции; fitness_threshold – пороговое значение, которое сравнивается с при- способленностью, вычисленной с помощью функции fitness_criterion для проверки необходимости завершения эволюции; no_fitness_termination – флаг, который запрещает завершение эволюци- онного процесса на основе приспособленности, определенной преды- дущими параметрами. Если установлено значение True, эволюция будет прекращена только после того, как будет оценено максимальное коли- чество поколений; pop_size – количество отдельных организмов в каждом поколении; reset_on_extinction – флаг, который определяет, следует ли создавать но- вую случайную популяцию, если все виды в текущем поколении вымер- ли из-за стагнации. Если установлено значение False, после полного ис- чезновения популяции будет выброшен флаг CompleteExtinctionException . 3.4.2 Секция DefaultStagnation Эта секция определяет параметры, которые являются специфическими для подпрограмм стагнации видов, реализованных в классе DefaultStagnation . Сек- ция включает в себя следующие параметры: species_fitness_func – вид функции, которая используется для вычис - ления приспособленности видов, то есть для расчета совокупного зна- чения приспособленности всех организмов, принадлежащих к опреде- ленному виду. Допустимые значения: max, min и mean; max_stagnation – виды, которые не показали улучшение значения при- способленности, рассчитываемого функцией species_fitness_func в те - чение более чем max_stagnation числа поколений, считаются застойны- ми и подвержены вымиранию; 3.4 Настройка гиперпараметров  67\n--- Страница 69 ---\nspecies_elitism – количество элитных видов, которые безоговорочно защищены от стагнации. Они предназначены для предотвращения полного вымирания популяции до появления новых видов. Указанное количество видов с наивысшей приспособленностью всегда выживает в популяции, несмотря на то что дальнейшее улучшение приспособ- ленности не наблюдается. 3.4.3 Секция DefaultReproduction В этой секции представлена конфигурация для подпрограмм воспроизведе- ния, которые реализованы встроенным классом DefaultReproduction . Секция включает в себя следующие параметры: elitism – количество наиболее приспособленных организмов каждого вида, которые копируются без изменений в следующее поколение. Этот фактор позволяет нам сохранить любые полезные мутации, которые были обнаружены в предыдущих поколениях; survival_threshold – доля организмов каждого вида, которые могут быть родителями следующего поколения, то есть имеют право на половое размножение (кроссовер). Регулируя это значение, можно определить самый низкий показатель приспособленности организма, который по- зволяет ему участвовать в процессе воспроизводства. Это возможно благодаря тому, что фракция survivial_threshold берется из отсорти- рованного списка организмов, упорядоченных по приспособленности в порядке убывания; min_species_size – минимальное количество организмов каждого вида, которое необходимо сохранить после цикла размножения. 3.4.4 Секция DefaultSpeciesSet В этой секции представлена конфигурация процесса видообразования, ко- торый реализован встроенным классом DefaultSpeciesSet и включает в себя следующий единственный параметр: compatibility_threshold – пороговое значение, от которого зависит, при- надлежат ли организмы к одному и тому же виду (геномное расстояние меньше этого значения) или другому виду. Более высокие значения поро- га уменьшают склонность эволюционного процесса к видообразованию. 3.4.5 Секция DefaultGenome В этой секции определяются параметры конфигурации, которые задействова- ны в создании и поддержке генома, реализованных классом DefaultGenome . Сек- ция включает в себя следующие параметры: activ_default – имя функции активации для использования в генах уз- лов; activation_mutate_rate – если геном поддерживает несколько функций активации (например, для генома CPPN), то этот параметр определяет вероятность того, что мутация заменит функцию активации текущего узла новой, полученной из списка поддерживаемых функций (см. acti- vation_options );68  Использование NEAT для оптимизации решения задачи XOR\n--- Страница 70 ---\nactivation_options – разделенный пробелами список функций актива- ции, которые могут использоваться генами узла; aggregation_default – имя агрегатной функции по умолчанию, которая будет использоваться сетевым узлом для любых агрегированных вход- ных сигналов, полученных от других узлов до активации; aggregation_mutate_rate – если геном поддерживает несколько агрегат - ных функций, то этот параметр определяет вероятность мутации, ко- торая заменяет агрегатную функцию текущего узла новой из списка агрегатных функций (см. aggregation_options ); aggregation_options – разделенный пробелами список агрегатных функ - ций, которые могут использоваться генами узлов. Поддерживаемые значения: sum, min, max, mean, median и maxabs; compatibility_threshold – пороговое значение для принятия решения о том, принадлежат ли организмы одному и тому же виду (геномное расстояние меньше этого значения) или разным видам. Более высокие значения порога означают, что эволюционный процесс обладает мень- шей склонностью к видообразованию; compatibility_disjoint_coefficient – коэффициент, который использу - ется при вычислении геномного расстояния для выяснения того, как непересекающиеся или избыточные гены влияют на результат вычис - ления. Более высокие значения этого параметра усиливают значимость присутствия непересекающихся или избыточных генов при расчете ге- номного расстояния; compatibility_weight_coefficient – коэффициент, от которого зависит то, как вычисленные значения разницы между атрибутами смещения и отклика генов узлов и весовыми атрибутами генов связей влияют на результаты; conn_add_prob – вероятность мутации, которая вводит новый ген связи между существующими генами узлов; conn_delete_prob – вероятность мутации, которая удаляет существую- щий ген связи из генома; enabled_default – значение по умолчанию для атрибута состояния (вклю- чено/выключено) вновь созданных генов связей; enabled_mutate_rate – вероятность мутации, которая переключает атри- бут состояния гена связи; feed_forward – управляет типом фенотипических сетей, которые будут генерироваться во время генеза. Если установлено значение True, то по- вторяющиеся соединения не допускаются; initial_connection – указывает начальный шаблон связей для вновь соз- данных геномов. Допустимые значения включают unconnected , fs_neat_ nohidden, fs_neat_hidden , full_direct , full_nodirect , partial_direct и par- tial_nodirect ; node_add_prob – вероятность мутации, которая добавляет новый ген узла; node_delete_prob – вероятность мутации, которая удаляет из генома су- ществующий ген узла и все связи с ним; num_hidden , num_inputs , num_outputs – количество скрытых, входных и вы- ходных узлов в геномах исходной популяции; 3.4 Настройка гиперпараметров  69\n--- Страница 71 ---\nsingle_structural_mutation – если установлено значение True, то в процессе эволюции разрешены только структурные мутации, то есть лишь добав- ление или удаление узлов либо связей. 3.4.6 Гиперпараметры эксперимента XOR Эксперимент XOR начинается с очень простой начальной конфигурации гено- ма, которая имеет только два входных узла, один выходной узел и один специ- альный вход – узел смещения. В исходном геноме скрытый узел отсутствует: [DefaultGenome] # Параметры сети num_hidden = 0 num_inputs = 2 num_outputs = 1 # Параметры узла смещения bias_init_mean = 0.0bias_init_stdev = 1.0 Функция активации всех узлов сети является сигмоидальной, а входы уз- лов агрегируются функцией суммы ( sum): [DefaultGenome] # Параметры активации узла activation_default = sigmoid # Параметры агрегации узла aggregation_default = sum Тип закодированной сети – полносвязная сеть прямого распространения: [DefaultGenome] feed_forward = True initial_connection = full_direct В ходе эволюции новые сетевые узлы и связи добавляются и/или удаляют - ся с определенной вероятностью: [DefaultGenome] # Вероятность добавления/удаления узла node_add_prob = 0.2 node_delete_prob = 0.2 # Вероятность добавления/удаления связи conn_add_prob = 0.5conn_delete_prob = 0.5 Все связи включены по умолчанию, с очень низкой вероятностью отклю- чения из-за мутации: [DefaultGenome] # Параметры состояния связи enabled_default = True enabled_mutate_rate = 0.0170  Использование NEAT для оптимизации решения задачи XOR\n--- Страница 72 ---\nЧтобы стимулировать разнообразие видов, мы зададим сильное влияние избыточных/непересекающихся частей родительских геномов на расстояние между геномами: [DefaultGenome] # Параметры расстояния между геномами compatibility_disjoint_coefficient = 1.0 compatibility_weight_coefficient = 0.5 Стагнация видов может длиться до 20 поколений, а уникальные виды час- тично защищены от вымирания: [DefaultStagnation] species_fitness_func = max max_stagnation = 20 species_elitism = 2 Порог выживания организмов в пределах вида установлен достаточно низ- ким, чтобы сузить эволюционный процесс, позволяя размножаться только наиболее приспособленным организмам (верхние 20 % списка организмов, упорядоченные по приспособленности). В то же время вводится элитарность, чтобы безоговорочно копировать двух наиболее приспособленных особей в следующее поколение каждого вида. Минимальный размер вида также влия- ет на видообразование, и мы оставляем для него значение по умолчанию: [DefaultReproduction] elitism = 2 survival_threshold = 0.2 min_species_size = 2 Порог совместимости видов определяет разнообразие видов в популяции. Более высокие значения этого параметра приводят к более разнообразной популяции. Разнообразие видов должно быть сбалансировано, чтобы под- держивать эволюционный процесс в желаемом направлении, избегая иссле- дования слишком большого количества векторов поиска, но в то же время позволяя исследовать новинки: [DefaultSpeciesSet] compatibility_threshold = 3.0 Численность популяции установлена в 150, что довольно умеренно, но достаточно для такой простой проблемы, как XOR. Критерий завершения (fitness_threshold ) установлен на 15.5, чтобы гарантировать, что эволюция завершается, когда найденное решение максимально близко к цели (в соот - ветствии с нашей функцией fitness максимальная оценка приспособленно- сти составляет 16.0). В этой задаче мы заинтересованы в поиске лидера эволюции, способного решить проблему XOR, поэтому наша функция завершения (fitness_criteri- on) – это функция max, которая выбирает максимальную приспособленность среди всех организмов в популяции: [NEAT]fitness_criterion = max 3.4 Настройка гиперпараметров  71\n--- Страница 73 ---\nfitness_threshold = 15.5 pop_size = 150reset_on_extinction = False Полный конфигурационный файл xor_config.ini можно найти в фай- ловом архиве книги. Мы представили только основные гиперпараметры, которые сильно влия- ют на производительность алгоритма NEAT. Значения гиперпараметров были протестированы при создании работающего решателя XOR, но вы можете из- менить их по своему усмотрению и посмотреть, что произойдет.",
          "debug": {
            "start_page": 67,
            "end_page": 73
          }
        },
        {
          "name": "3.5 Выполнение эксперимента XOR 72",
          "content": "--- Страница 73 --- (продолжение)\n3.5 выпОлнение экСперимента Xor Прежде чем мы начнем работать над экспериментом XOR, нам нужно правиль- но настроить нашу среду Python в соответствии с требованиями библиотеки NEAT-Python, которую мы выбрали в качестве основы для написания нашего кода. Библиотека NEAT-Python доступна из PyPI, поэтому мы можем исполь- зовать команду pip для ее установки в виртуальную среду эксперимента XOR. 3.5.1 Настройка среды Прежде чем мы начнем писать код, относящийся к эксперименту XOR, не- обходимо создать соответствующую среду Python, и в нее должны быть уста- новлены все зависимости. Выполните следующие шаги, чтобы правильно на- строить рабочую среду. 1. Виртуальная среда Python 3.5 для эксперимента XOR создается с по- мощью команды conda из Anaconda Distribution: $ conda create --name XOR_neat python=3.5 Убедитесь, что пакет Anaconda Distribution установлен на ваш компью- тер, как сказано в главе 2. 2. Чтобы использовать вновь созданную виртуальную среду, вы должны ак- тивировать ее: $ conda activate XOR_neat 3. После этого библиотеку NEAT-Python можно установить в активную сре- ду с помощью следующей команды: $ pip install neat-python == 0.92 Мы используем версию 0.92, которая была самой новой на момент работы над книгой. 4. Наконец, нам нужно установить дополнительные зависимости, которые используются утилитами визуализации. Это можно сделать с помощью команды conda:72  Использование NEAT для оптимизации решения задачи XOR\n3.5 выпОлнение экСперимента Xor Прежде чем мы начнем работать над экспериментом XOR, нам нужно правиль- но настроить нашу среду Python в соответствии с требованиями библиотеки NEAT-Python, которую мы выбрали в качестве основы для написания нашего кода. Библиотека NEAT-Python доступна из PyPI, поэтому мы можем исполь- зовать команду pip для ее установки в виртуальную среду эксперимента XOR. 3.5.1 Настройка среды Прежде чем мы начнем писать код, относящийся к эксперименту XOR, не- обходимо создать соответствующую среду Python, и в нее должны быть уста- новлены все зависимости. Выполните следующие шаги, чтобы правильно на- строить рабочую среду. 1. Виртуальная среда Python 3.5 для эксперимента XOR создается с по- мощью команды conda из Anaconda Distribution: $ conda create --name XOR_neat python=3.5 Убедитесь, что пакет Anaconda Distribution установлен на ваш компью- тер, как сказано в главе 2. 2. Чтобы использовать вновь созданную виртуальную среду, вы должны ак- тивировать ее: $ conda activate XOR_neat 3. После этого библиотеку NEAT-Python можно установить в активную сре- ду с помощью следующей команды: $ pip install neat-python == 0.92 Мы используем версию 0.92, которая была самой новой на момент работы над книгой. 4. Наконец, нам нужно установить дополнительные зависимости, которые используются утилитами визуализации. Это можно сделать с помощью команды conda:72  Использование NEAT для оптимизации решения задачи XOR\n--- Страница 74 ---\n$ conda install matplotlib $ conda install graphviz $ conda install python-graphviz Теперь мы готовы к написанию исходного кода. 3.5.2 Исходный код эксперимента XOR Чтобы начать эксперимент, нам нужно создать каталог с именем Chapter3, ис- пользуя команду mkdir (для Linux и macOS) или md (для Windows): $ mkdir Chapter3 В этом каталоге будут храниться все файлы исходных кодов, имею- щих отношение к эксперименту, упомянутому в главе 3. Затем нам нужно скопировать файл xor_config.ini из файлового архива исходного кода, связанного с этой главой, во вновь созданный каталог. Этот файл содержит полную конфигурацию гиперпараметров для эксперимента XOR, которую мы обсуждали ранее. Эксперименты, которые будут рассмотре- ны в данной книге, используют различные утилиты для визуализации резуль- татов, чтобы наглядно продемонстрировать внутренние аспекты процесса нейроэволюции. Эксперимент XOR также зависит от конкретных утилит ви- зуализации, которые реализованы в файле visualize.py из файлового архива этой книги. Вам также необходимо скопировать этот файл в каталог Chapter3. Установочный пакет Anaconda Distribution включает в себя бесплат - ный кросс-платформенный редактор кода VS Code. Он достаточно прост с точки зрения функциональности, но обеспечивает отличную поддержку Python и позволяет легко переключаться между виртуаль-ными средами. Вы можете использовать его для написания исходного кода для экспериментов, описанных в этой книге. Наконец, создайте файл под названием xor_experiment.py в каталоге Chap- ter3 и используйте ваш любимый редактор исходного кода Python для на- писания кода. 1. Сначала определим импорт библиотек, которые понадобятся позже: # Импорт стандартных библиотек Python. import os # Импорт библиотек NEAT-Python. import neat # Импорт утилиты для визуализации результатов.import visualize 2. Далее напишем код оценки приспособленности в соответствии с тем, что мы говорили ранее: # Входы и ожидаемые выходы XOR для оценки приспособленности. xor_inputs = [(0.0, 0.0), (0.0, 1.0), (1.0, 0.0), (1.0, 1.0)] xor_outputs = [ (0.0,), (1.0,), (1.0,), (0.0,)] 3.5 Выполнение эксперимента XOR  73\n--- Страница 75 ---\ndef eval_fitness(net): \"\"\" Оценивает приспособленность генома, который был использован для создания предоставленной сети Аргументы: net: нейросеть прямого распространения, созданная из генома Возвращает: Оценка приспособленности – чем выше балл, тем лучше приспособленность организма. Максимальная оценка: 16.0 \"\"\" error_sum = 0.0 for xi, xo in zip(xor_inputs, xor_outputs): output = net.activate(xi) error_sum += abs(xo[0] - output[0]) # Вычисление усиленного значения приспособленности fitness = (4 - error_sum) ** 2 return fitness Никогда не упускайте возможность оставлять в исходном коде ком- ментарии, которые описывают назначение функции, ее входные па-раметры и результаты выполнения. Также полезно комментировать некоторые интересные или необычные части исходного кода, чтобы их было проще понять человеку, который увидит код позже (это мо-жете оказаться вы!). 3. С помощью функции оценки приспособленности вы можете написать функцию для оценки всех организмов в текущем поколении и соответ - ственно обновить приспособленность каждого генома: def eval_genomes(genomes, config): \"\"\" Функция для оценки приспособленности каждого генома в списке геномов. Предоставленная конфигурация используется для создания нейронной сети прямого распространения из каждого генома, и после этого нейронная сеть оценивается по ее способности решать задачу XOR. В результате выполнения этой функции показатель приспособленности каждого генома обновляется до новой оценки. Аргументы: genomes: Список геномов из популяции в текущем поколении config: Файл конфигурации, содержащий гиперпараметры \"\"\" for genome_id, genome in genomes: genome.fitness = 4.0 net = neat.nn.FeedForwardNetwork.create(genome, config) genome.fitness = eval_fitness(net) 4. Теперь, когда реализована функция оценки приспособленности отдель- ного генома и определена целевая функция, пришло время реализовать функцию для запуска эксперимента. Функция run_experiment загружает 74  Использование NEAT для оптимизации решения задачи XOR\n--- Страница 76 ---\nконфигурацию гиперпараметра из файла конфигурации и создает на- чальную популяцию генома: # Загрузка конфигурации. config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction, neat.DefaultSpeciesSet, neat.DefaultStagnation, config_file) # Создает популяцию, которая является объектом верхнего уровня. p = neat.Population(config) 5. Нам пригодится сбор статистики для оценки эксперимента и наблюде- ния за процессом в реальном времени. Также важно сохранить конт- рольные точки, что позволяет восстановить выполнение с заданной кон- трольной точки в случае сбоя. Два типа репо́ртеров (стандартный вывод и сборщик статистики) и сборщик контрольных точек могут быть заре- гистрированы следующим образом: # Добавление репортера stdout для отображения хода процесса в терминале. p.add_reporter(neat.StdOutReporter(True)) stats = neat.StatisticsReporter()p.add_reporter(stats) p.add_reporter(neat.Checkpointer(5, filename_prefix='out/neat-checkpoint-')) 6. Теперь мы готовы запустить нейроэволюцию в течение 300 поколений, предоставив в качестве аргумента функцию eval_genome , которая служит для оценки показателей приспособленности каждого генома в популя- ции каждого поколения, пока не будет найдено решение или процесс не достигнет максимального числа поколений: # Выполнение в течение 300 поколений. best_genome = p.run(eval_genomes, 300) 7. Когда выполнение алгоритма NEAT останавливается по достижении успеха или максимального числа поколений, возвращается наиболее подходящий геном. Можно проверить, является ли этот геном победите- лем, то есть способен ли решить задачу XOR с заданной точностью: # Проверяем, является ли лучший геном адекватным решателем задачи XORbest_genome_fitness = eval_fitness(net) if best_genome_fitness > config.fitness_threshold: print(\"\\n\\nSUCCESS: The XOR problem solver found!!!\") else: print(\"\\n\\nFAILURE: Failed to find XOR problem solver!!!\") 8. Наконец, собранные статистические данные и наиболее подходящий ге- ном можно визуализировать, чтобы изучить результаты процесса ней- роэволюции и увидеть, как геном развивался от нуля до максимального числа поколений: # Визуализация результатов эксперимента node_names = {-1:'A', -2: 'B', 0:'A XOR B'} visualize.draw_net(config, best_genome, True, 3.5 Выполнение эксперимента XOR  75\n--- Страница 77 ---\nnode_names=node_names, directory=out_dir) visualize.plot_stats(stats, ylog=False, view=True, filename=os.path.join(out_dir, 'avg_fitness.svg'))visualize.plot_species(stats, view=True, filename=os.path.join(out_dir, 'speciation.svg')) Полный исходный код эксперимента XOR можно найти в файле xor_ experiment.py в файловом архиве книги. Для визуализации графов и статистики, полученных в результате выпол- нения кода эксперимента, будет использоваться библиотека Matplotlib. Так- же будет представлен сетевой граф наиболее подходящего генома. 3.5.3 Запуск эксперимента и анализ результатов Для запуска эксперимента, находясь в каталоге Chapter3, введите в окне тер- минала следующую команду: $ python xor_experiment.py Не забудьте активировать виртуальную среду XOR_neat с помощью ко- манды $ conda activate XOR_neat . В противном случае будут возникать ошибки, связанные с отсутствием пакета neat. Вы можете использовать любое приложение терминала командной строки на свое усмотрение. После ввода команды алгоритм NEAT начинает выполне- ние, и окно терминала выводит промежуточные результаты в режиме реаль- ного времени. Для каждого поколения вывод выглядит следующим образом: ****** Running generation 43 ****** Population's average fitness: 6.01675 stdev: 2.53269 Best fitness: 14.54383 - size: (4, 7) - species 2 - id 5368Average adjusted fitness: 0.238Mean genetic distance 2.482, standard deviation 0.991Population of 151 members in 5 species: ID age size fitness adj fit stag ==== === ==== ======= ======= ==== 1 43 28 9.0 0.241 0 2 33 42 14.5 0.274 7 3 20 39 9.0 0.306 0 4 4 34 9.0 0.221 0 5 1 8 8.4 0.149 0 Total extinctions: 0 Generation time: 0.045 sec (0.038 average) Средняя приспособленность популяции в поколении 43 составляет всего 6.01675, что довольно мало по сравнению с критерием завершения, установ- ленным в файле конфигурации (fitness_threshold=15.5 ). Тем не менее похо- же, что у нас есть потенциальный вид-чемпион (ID:2), который находится на пути к достижению целевого порога приспособленности путем развития организма-чемпиона с показателем приспособленности 14.54383, который 76  Использование NEAT для оптимизации решения задачи XOR\n--- Страница 78 ---\nкодирует фенотип нейросети, состоящий из четырех узлов и семи соедине- ний (размер (4,7)). Популяция включает 151 особь и разделена на пять видов со следующими свойствами: id – идентификатор вида; age – возраст видов как количество поколений от их создания до на- стоящего времени; size – количество особей, принадлежащих к данному виду; fitness – показатель приспособленности вида, рассчитанный по его особям (в нашем случае max); adj fit – приспособленность определенного вида, которая была скор- ректирована с учетом показателей приспособленности всей популя- ции; stag – возраст стагнации конкретного вида как число поколений с мо- мента последнего улучшения приспособленности вида. Когда с помощью алгоритма NEAT найден подходящий решатель задачи XOR, в окне терминала отображается результат. Он начинается с общей ста- тистики об окончательной популяции генома и победителе (успешном реша- теле XOR): ****** Running generation 44 ****** Population's average fitness: 6.04705 stdev: 2.67702 Best fitness: 15.74620 - size: (3, 7) - species 2 - id 6531 Best individual in generation 44 meets fitness threshold - complexity: (3, 7) Из предыдущего вывода мы можем заключить, что в поколении 44 процесс эволюции создает геном, который кодирует фенотип нейросети, способный решить проблему XOR с заданной точностью. Этот геном принадлежит орга- низму из вида с ID:2, и этот вид уже отвечал за эволюционный процесс в те- чение последних семи поколений. Организм-чемпион (ID:6531) поколения 44 является мутацией организма (ID:5368) в виде с ID:2 из предыдущего поко- ления, который потерял один скрытый узел и теперь имеет три узла с семью связями ( size: (3, 7)). Затем следует секция лучшего генома: Best genome: Key: 6531 Fitness: 15.74619841601669 Nodes: 0 DefaultNodeGene(key=0, bias=-3.175506745721987, response=1.0,activation=sigmoid, aggregation=sum) 224 DefaultNodeGene(key=224, bias=-2.5796785460461154, response=1.0,activation=sigmoid, aggregation=sum) 612 DefaultNodeGene(key=612, bias=-1.626648521448398, response=1.0, activation=sigmoid, aggregation=sum) Connections: DefaultConnectionGene(key=(-2, 224), weight=1.9454770276940339, 3.5 Выполнение эксперимента XOR  77\n--- Страница 79 ---\nenabled=True) DefaultConnectionGene(key=(-2, 612), weight=2.1447044917213383,enabled=True) DefaultConnectionGene(key=(-1, 0), weight=-2.048078253002224, enabled=True) DefaultConnectionGene(key=(-1, 224), weight=3.6675667680178328,enabled=True) DefaultConnectionGene(key=(224, 0), weight=6.1133731818187655,enabled=True) DefaultConnectionGene(key=(612, 0), weight=-2.1334321035742474,enabled=True) DefaultConnectionGene(key=(612, 224), weight=1.5435290073038443, enabled=True) Секция вывода лучшего генома представляет статистику точности чем- пиона популяции, а также конфигурацию его генома. Входные узлы имеют идентификаторы –1 и –2 и не показаны, потому что они относительно просты, и всего лишь предоставляют нам способ для ввода значений в сетевой граф. Выходной узел и два скрытых узла имеют идентификаторы 0, 224 и 612 со- ответственно. Кроме того, DefaultNodeGene содержит значения смещения, имя функции активации и имя функции, которая используется для агрегирования входных данных на каждом узле. Гены связей (DefaultConnectionGene ), которые будут представлены позже, предоставляют идентификаторы исходного и це- левого узлов вместе с соответствующим весом соединения. Наконец, давайте взглянем на раздел Output: Output: input (0.0, 0.0), expected output (0.0,), got [1.268084297765355e-07] input (0.0, 1.0), expected output (1.0,), got [0.9855287279878023] input (1.0, 0.0), expected output (1.0,), got [0.9867962503269723] input (1.0, 1.0), expected output (0.0,), got [0.004176868376596405] В секции Output представлены выходные значения, которые выданы нейро- сетью, построенной по фенотипу лидера популяции при получении четырех пар входных данных. Как мы видим, результат близок к ожидаемым значени- ям в пределах указанной точности. Каталог Output также содержит схему графа нейросети успешного решателя XOR, которая выглядит следующим образом (рис. 3.2):78  Использование NEAT для оптимизации решения задачи XOR\n--- Страница 80 ---\nРис. 3.2. Граф нейросети успешного решателя XOR Нейросеть фенотипа-победителя близка к оптимальной конфигурации, которую мы описали ранее, но у нее есть еще один скрытый узел (ID:612). Узел смещения не показан на графе, поскольку библиотека NEAT-Python не выделяет смещение в отдельный узел; вместо этого она присваивает зна- чение смещения каждому сетевому узлу в качестве атрибута, который можно увидеть в списке вывода (каждый DefaultNodeGene имеет атрибут смещения). График изменения приспособленности по поколениям эволюции также со- храняется в каталог Output (рис. 3.3). 3.5 Выполнение эксперимента XOR  79\n--- Страница 81 ---\nСредняя и лучшая приспособленность популяции Поколениясредняя –1 СКО +1 СКО лучшаяПриспособленность Рис. 3.3. График изменения приспособленности по поколениям эволюции Этот график визуализирует изменения лучших и средних показателей приспособленности популяции за поколения эволюции. Средняя приспособ- ленность популяции увеличилась незначительно. Тем не менее благодаря функции видообразования, которая была введена в алгоритм NEAT, некото- рые виды продемонстрировали выдающуюся эффективность с самых ран- них поколений (#10), и благодаря сохранению полезной мутации им наконец удалось создать организм-чемпион, который решает задачу XOR с заданной точностью. Выходной каталог также содержит график видообразования, показанный на рис. 3.4.80  Использование NEAT для оптимизации решения задачи XOR\n--- Страница 82 ---\nПоколенияВидообразованиеРазмер по видам Рис. 3.4. График видообразования по поколениям эволюции График видообразования демонстрирует, как на протяжении поколений популяции организмов развивался процесс видообразования. Каждый от- дельный вид отмечен своим цветом. Эволюция началась с одного вида (ID:1), который включает в себя всю популяцию. Затем около 10-го поколения заро- дился второй вид (ID:2), и в конечном итоге он произвел организм-чемпион. Кроме того, на более поздних этапах эволюции популяция разветвлялась на еще три вида в поколениях 23, 39 и 42.",
          "debug": {
            "start_page": 73,
            "end_page": 82
          }
        },
        {
          "name": "3.6 Упражнения 81",
          "content": "--- Страница 82 --- (продолжение)\n3.6 упражнения Теперь, когда у нас есть исходный код нейроэволюционного решателя XOR, по- пробуйте поэкспериментировать, изменив гиперпараметры NEAT, влияющие на эволюционный процесс. Одним из параметров, представляющих особый интерес, является compat- ibility_threshold , который можно найти в разделе файла конфигурации De- faultSpeciesSet : попробуйте увеличить значение этого параметра и следите за видообра- зованием популяции. Сравните производительность алгоритма с новым значением и значением по умолчанию ( 3.0). Она становится лучше? что произойдет, если вы уменьшите значение этого параметра? Срав- ните новую производительность со значением по умолчанию. 3.6 Упражнения  81\n3.6 упражнения Теперь, когда у нас есть исходный код нейроэволюционного решателя XOR, по- пробуйте поэкспериментировать, изменив гиперпараметры NEAT, влияющие на эволюционный процесс. Одним из параметров, представляющих особый интерес, является compat- ibility_threshold , который можно найти в разделе файла конфигурации De- faultSpeciesSet : попробуйте увеличить значение этого параметра и следите за видообра- зованием популяции. Сравните производительность алгоритма с новым значением и значением по умолчанию ( 3.0). Она становится лучше? что произойдет, если вы уменьшите значение этого параметра? Срав- ните новую производительность со значением по умолчанию. 3.6 Упражнения  81\n--- Страница 83 ---\nДругим важным параметром, который управляет эволюционным процес - сом, является min_species_size , который можно найти в разделе DefaultRepro- duction. Изменяя значения этого параметра, вы можете напрямую контро- лировать минимальное количество особей на вид и неявно контролировать разнообразие видов: 1. Установите значение параметра compatibility_threshold в значение по умолчанию (3.0) и попытайтесь увеличить значение параметра min_spe- cies_size в диапазоне [2, 8]. Сравните производительность алгоритма со значением по умолчанию. Посмотрите, как разнообразие видов меняет - ся от поколения к поколению. Просмотрите выходные данные алгорит - ма и проверьте, не случалась ли стагнация каких-либо видов и удаление вида из-за превышения возраста стагнации. 2. Установите чрезвычайно высокое значение параметра min_species_size для нашей популяции (32) и найдите взрыв видового разнообразия в конце процесса эволюции на графике видообразования. Почему это происходит? Изучите граф, изображающий конфигурацию фенотипа нейросети в файле Digraph.gv.svg . Является ли этот граф оптимальным? Увеличение минимального размера видов делает эволюционный процесс более сложным и позволяет ему сохранять более полезные мутации. В ре- зультате у нас увеличивается вероятность получения оптимального генома, который кодирует нейросеть фенотипа минимального решателя XOR. Граф нейросети минимального решателя XOR показан на рис. 3.5. Рис. 3.5. Граф нейросети минимального решателя XOR Как мы уже упоминали, нейросеть минимального решателя XOR имеет только один скрытый узел, как показано на рис. 3.5. Попробуйте написать модифицированный код для решения тройной задачи XOR (A xor B xor C). 82  Использование NEAT для оптимизации решения задачи XOR\n--- Страница 84 ---\nМожно ли решить эту проблему с помощью тех же гиперпараметров, которые мы использовали в эксперименте, описанном в этой главе?",
          "debug": {
            "start_page": 82,
            "end_page": 84
          }
        },
        {
          "name": "3.7 Заключение 83",
          "content": "--- Страница 84 --- (продолжение)\n3.7 з аключение В этой главе мы представили классическую задачу информатики, связанную с созданием оптимального решателя XOR. Мы обсудили основы задачи XOR и продемонстрировали ее важность в качестве первого эксперимента с нейро- эволюцией – она позволяет проверить, может ли алгоритм NEAT развить более сложную топологию нейросети, начиная с самой простой конфигурации. Затем мы определили целевую функцию для оптимального решателя XOR и рассмо- трели подробное описание гиперпараметров NEAT. После этого использовали библиотеку NEAT-Python для написания исходного кода решателя XOR с при- менением определенной целевой функции и провели эксперименты. Результаты проведенного нами эксперимента позволили нам сделать вы- вод о взаимосвязи между количеством видов в популяции, минимальным размером каждого вида и производительностью алгоритма, а также полу - ченными топологиями нейросетей. В следующей главе вы узнаете о классических экспериментах по обуче- нию с подкреплением, которые часто используются в качестве эталонов для реа лизации стратегии управления. Вы узнаете, как писать точные симуляции реальных физических устройств и как использовать такие симуляции при определении целевых функций для алгоритма NEAT. Вы получите собствен- ный опыт написания стратегий управления для различных контроллеров ба- лансировки обратного маятника на тележке с использованием библиотеки NEAT-Python. 3.7 Заключение  83\n3.7 з аключение В этой главе мы представили классическую задачу информатики, связанную с созданием оптимального решателя XOR. Мы обсудили основы задачи XOR и продемонстрировали ее важность в качестве первого эксперимента с нейро- эволюцией – она позволяет проверить, может ли алгоритм NEAT развить более сложную топологию нейросети, начиная с самой простой конфигурации. Затем мы определили целевую функцию для оптимального решателя XOR и рассмо- трели подробное описание гиперпараметров NEAT. После этого использовали библиотеку NEAT-Python для написания исходного кода решателя XOR с при- менением определенной целевой функции и провели эксперименты. Результаты проведенного нами эксперимента позволили нам сделать вы- вод о взаимосвязи между количеством видов в популяции, минимальным размером каждого вида и производительностью алгоритма, а также полу - ченными топологиями нейросетей. В следующей главе вы узнаете о классических экспериментах по обуче- нию с подкреплением, которые часто используются в качестве эталонов для реа лизации стратегии управления. Вы узнаете, как писать точные симуляции реальных физических устройств и как использовать такие симуляции при определении целевых функций для алгоритма NEAT. Вы получите собствен- ный опыт написания стратегий управления для различных контроллеров ба- лансировки обратного маятника на тележке с использованием библиотеки NEAT-Python. 3.7 Заключение  83",
          "debug": {
            "start_page": 84,
            "end_page": 85
          }
        }
      ]
    },
    {
      "name": "Глава 4. Балансировка тележки с обратным маятником 85",
      "chapters": [
        {
          "name": "4.1 Технические требования 85",
          "content": "--- Страница 86 --- (продолжение)\nГлава 4 Балансировка тележки с обратным маятником В этой главе вы узнаете о классическом эксперименте по обучению с подкреп- лением, который также является общепринятым эталоном для тестирования различных реализаций стратегий управления. Мы рассмотрим три модифика- ции эксперимента по балансировке тележки с обратным маятником и разра- ботаем стратегии управления, которые можно использовать для стабилизации аппаратов с обратным маятником заданных конфигураций. Вы узнаете, как писать точные симуляции реальных физических систем и как использовать их при определении целевой функции для алгоритма NEAT. После прочтения этой главы вы будете готовы применить алгоритм NEAT для реализации контролле- ров, способных напрямую управлять физическими устройствами. В этой главе мы рассмотрим следующие темы: задача балансировки обратного маятника в обучении с подкреплением; реализация симулятора устройства с тележкой в Python; определение целевой функции балансировочного контроллера с по- мощью симулятора; особенности задачи балансировки двух маятников; реализация симулятора тележки с двумя маятниками в Python; определение целевой функции для контроллера балансировки двух ма- ятников. 4.1 техниче Ские треб Ования Для проведения экспериментов, описанных в этой главе, ваш компьютер дол- жен удовлетворять следующим техническим требованиям: Windows 8/10, macOS 10.13 или новее, или современный Linux; Anaconda Distribution версия 2019.03 или новее. Исходный код примеров этой главы можно найти в каталоге Chapter4 в фай- ловом архиве книги.\n4.1 техниче Ские треб Ования Для проведения экспериментов, описанных в этой главе, ваш компьютер дол- жен удовлетворять следующим техническим требованиям: Windows 8/10, macOS 10.13 или новее, или современный Linux; Anaconda Distribution версия 2019.03 или новее. Исходный код примеров этой главы можно найти в каталоге Chapter4 в фай- ловом архиве книги.",
          "debug": {
            "start_page": 86,
            "end_page": 86
          }
        },
        {
          "name": "4.2 Задача балансировки обратного маятника 86",
          "content": "--- Страница 87 --- (продолжение)\n4.2 заДача балан СирОвки Обратн ОгО маятника Обратный маятник представляет собой неустойчивую механическую систему, центр масс которой находится выше точки вращения. Его можно стабилизи- ровать, прикладывая внешние силы под управлением специализированной системы, которая контролирует угол маятника и перемещает точку вращения горизонтально назад и вперед под центром масс, когда маятник начинает па- дать. Балансировщик обратного маятника – это классическая задача в теории динамики и управления, которая используется в качестве эталона для тести- рования стратегий управления, в том числе основанных на методах обучения с подкреплением. Мы особенно заинтересованы в реализации специального алгоритма управления, основанного на нейроэволюции, для стабилизации об- ратного маятника в течение заданного периода времени. Эксперимент, описанный в этой главе, предусматривает моделирование обратного маятника, реализованного в виде тележки, которая может переме- щаться горизонтально, с установленными на ней сверху шарниром и маятни- ком в виде вертикального стержня1. Конструкция системы показана на рис. 4.1. Рис. 4.1. Система из тележки и обратного стержневого маятника Прежде чем мы начнем писать исходный код симулятора, нам нужно опре- делить уравнение движения, которое можно использовать для оценки значений переменных состояния балансировщика маятника в любой момент времени. 4.2.1 Уравнения движения балансировщика Задача контроллера состоит в том, чтобы приложить к центру масс тележки последовательность сил Fx таким образом, чтобы маятник уравновешивался в течение определенного (или бесконечного) промежутка времени, а тележка оставалась в пределах дорожки, то есть не ударялась о левую или правую стену. Принимая во внимание упомянутую механику, мы можем квалифицировать задачу балансировки маятника как проблему управляемого избегания, потому 1 Такой маятник принято называть обратным, потому что его опорный шарнир рас- положен снизу. – Прим. перев.86  Балансировка тележки с обратным маятником\n4.2 заДача балан СирОвки Обратн ОгО маятника Обратный маятник представляет собой неустойчивую механическую систему, центр масс которой находится выше точки вращения. Его можно стабилизи- ровать, прикладывая внешние силы под управлением специализированной системы, которая контролирует угол маятника и перемещает точку вращения горизонтально назад и вперед под центром масс, когда маятник начинает па- дать. Балансировщик обратного маятника – это классическая задача в теории динамики и управления, которая используется в качестве эталона для тести- рования стратегий управления, в том числе основанных на методах обучения с подкреплением. Мы особенно заинтересованы в реализации специального алгоритма управления, основанного на нейроэволюции, для стабилизации об- ратного маятника в течение заданного периода времени. Эксперимент, описанный в этой главе, предусматривает моделирование обратного маятника, реализованного в виде тележки, которая может переме- щаться горизонтально, с установленными на ней сверху шарниром и маятни- ком в виде вертикального стержня1. Конструкция системы показана на рис. 4.1. Рис. 4.1. Система из тележки и обратного стержневого маятника Прежде чем мы начнем писать исходный код симулятора, нам нужно опре- делить уравнение движения, которое можно использовать для оценки значений переменных состояния балансировщика маятника в любой момент времени. 4.2.1 Уравнения движения балансировщика Задача контроллера состоит в том, чтобы приложить к центру масс тележки последовательность сил Fx таким образом, чтобы маятник уравновешивался в течение определенного (или бесконечного) промежутка времени, а тележка оставалась в пределах дорожки, то есть не ударялась о левую или правую стену. Принимая во внимание упомянутую механику, мы можем квалифицировать задачу балансировки маятника как проблему управляемого избегания, потому 1 Такой маятник принято называть обратным, потому что его опорный шарнир рас- положен снизу. – Прим. перев.86  Балансировка тележки с обратным маятником\n--- Страница 88 ---\nчто состояние системы тележка–маятник должно поддерживаться таким обра- зом, чтобы избегать определенных областей пространства состояний. Для до- стижения соответствующего состояния не существует единственного решения, поэтому приемлемым является любое решение уравнений движения, позво- ляющее избежать определенных областей. Для обучения контроллера балансировки маятника алгоритм обучения дол- жен получать из среды минимальное количество знаний о задаче. Такие знания должны отражать близость нашего контроллера к цели. Задача уравновешива- ния маятника состоит в том, чтобы стабилизировать нестабильную систему и удерживать контроль над ней как можно дольше. Таким образом, подкрепля- ющий сигнал rt, полученный из среды моделирования, должен отражать воз- никновение отказа (потери контроля). Отказ может быть вызван отклонени- ем маятника больше допустимого угла или столкновением тележки с одной из стен. Подкрепляющий сигнал rt можно определить следующим образом: 0 021 021 24 24 1 t t t r если , , радиан; и , x , м в остальных случаях θ = −<< −<<  −. В этом уравнении θt – угол между маятником и вертикалью, положительный по часовой стрелке; xt – горизонтальная позиция тележки относительно центра дорожки. Обратите внимание, что подкрепляющий сигнал rt не зависит ни от угло- вой скорости маятника , ни от горизонтальной скорости тележки . Он лишь предоставляет информацию о том, находится ли динамическая система тележка–маятник в заранее установленных пределах. Уравнения движения системы тележка–маятник без учета трения выгля- дят следующим образом: . Здесь – угловая скорость маятника, – угловое ускорение маятника, – гори- зонтальная скорость тележки, – ускорение тележки вдоль оси x. В нашем эксперименте мы будем использовать следующие параметры системы: mc = 1,0 кг – масса тележки; mp = 0,1 кг – масса маятника; L = 0,5 м – расстояние от центра масс маятника до шарнира; g = 9,8 м/с2 – ускорение свободного падения. 4.2.2 Уравнения состояния и управляющие воздействия Экспериментальная система тележка–маятник моделируется путем численной аппроксимации уравнений движения с использованием метода Эйлера с ша- гом τ = 0,02 с. Уравнения состояния можно определить следующим образом: 4.2 Задача балансировки обратного маятника  87\n--- Страница 89 ---\nt t t ¨tt t t t t ¨ tt tx x x x x xτ τ τ ττ τ θθτθ θθτθ+ + + +=+ =+ =+ =+   , ; , . Для небольшого диапазона углов маятника, который применяется в на- шем эксперименте, мы можем использовать линейную аппроксимацию по- верхности, которая делит пространство всех возможных состояний системы, требующих различных действий (поверхность переключения). Таким об- разом, пространство действия состоит из левого и правого толкающих дей- ствий. Контроллер тележки, который мы используем в нашем эксперименте, не предназначен для создания нулевой силы. Вместо этого на каждом шаге по времени t он прикладывает силу к центру масс тележки с одинаковой амп- литудой, но в одном из двух противоположных направлений. Такая система управления называется двухпозиционным регулятором (bang-bang controller) и может быть определена с помощью следующего уравнения: 1 10Н 0. 10Нxесли at ,Fесли at , =  == −    . Здесь a[t] – сигнал действия, полученный от решателя. Исходя из значения этого сигнала, двухпозиционный регулятор прикладывает силу Fx с одинако- вой амплитудой (10 Н), но в одном из двух противоположных направлений, в зависимости от того, какое действие выбрал решатель. 4.2.3 Взаимодействие между решателем и симулятором В каждый данный момент времени t решатель получает масштабированные значения упомянутых ранее переменных состояния. Эти значения служат входными данными для нейросети, созданной на основе фенотипа, и опреде- ляются следующим образом: 0 10 x t .,= () 112448x t xt . ,.= +   () 31021042x t t . ,.θ= +    () 21153x t xt . , =+   () 4124x t t .θ= +   В первом уравнении x0 – это постоянное смещение, а x1… x4 относятся к го- ризонтальной позиции тележки, горизонтальной скорости, углу отклонения маятника от вертикали и угловой скорости соответственно. Принимая во внимание установленные ранее ограничения системы (см. rt), масштабированные значения x1 и x3 гарантированно лежат в интервале [0, 1], 88  Балансировка тележки с обратным маятником\n--- Страница 90 ---\nв то время как масштабированные значения x2 и x4 в основном попадают в интервал [0, 1], но, в конце концов, могут выйти за его пределы. Перемен- ные состояния масштабируются для достижения двух основных целей: устранить предвзятость в обучении, которая может возникнуть, когда члены с доминирующе большим размахом значений оказывают более значительное влияние на ученика из-за эффектов округления; поскольку значения переменных состояния сосредоточены вокруг нуля, для этой конкретной задачи можно найти нейросеть решателя, которая не нуждается в скрытых узлах. Тем не менее мы заинтересо- ваны в развитии топологии нейронных сетей с помощью алгоритма NEAT. Введенная схема масштабирования гарантирует, что процесс нейро эволюции в конечном итоге приводит к фенотипам, которые ко- дируют скрытые узлы. Контроллер балансировки маятника принимает масштабированные вход- ные значения и выдает выходной сигнал, являющийся двоичным значением, определяющим действие, которое должно быть применено в момент време- ни t, как обсуждалось ранее. Частота дискретизации переменных состояния системы тележка–маятник и частота, с которой прикладывается управляю- щее усилие, такие же, как частота симуляции 1/ τ = 50 Гц. Таким образом, начальная конфигурация нейросети контроллера может быть представлена в виде схемы на рис. 4.2. Видо- образо- вание Рис. 4.2. Начальная конфигурация нейросети балансировщика обратного маятника Начальная конфигурация нейросети балансировщика одиночного обрат - ного маятника включает в себя пять входных узлов: для горизонтального по- ложения тележки (x1) и его скорости (x2), для вертикального угла маятника (x3) и его угловой скорости (x4) и дополнительный входной узел для смеще- ния (x0) (которое может быть необязательным в зависимости от конкретной используемой библиотеки NEAT). Выходной узел (a) является двоичным узлом, выдающим управляющий сигнал [0 или 1]. Скрытый узел (h) является необя- зательным и может быть пропущен. 4.2 Задача балансировки обратного маятника  89",
          "debug": {
            "start_page": 87,
            "end_page": 90
          }
        },
        {
          "name": "4.3 Целевая функция для эксперимента по балансировке одиночного маятника 90",
          "content": "--- Страница 91 --- (продолжение)\n4.3 целевая функция Для экСперимента пО балан СирОвке ОДинОчнОгО маятника Наша цель – создать контроллер балансировки одиночного обратного маятни- ка, который сможет поддерживать систему в стабильном состоянии в рамках определенных ограничений как можно дольше, но, по крайней мере, в течение ожидаемого количества временных шагов, указанных в конфигурации экспе- римента (500 000). Таким образом, целевая функция должна оптимизировать продолжительность стабильной балансировки маятника и может быть опре- делена как логарифмическая разница между ожидаемым количеством шагов и фактическим количеством шагов, полученных во время оценки фенотипа нейросети. Функция ошибки задается следующим образом: max eval maxlogt logt.logt−= В данном эксперименте tmax – это ожидаемое количество шагов от конфигу - рации эксперимента, а teval – фактическое количество шагов, в течение кото- рых контроллер смог поддерживать стабильное состояние балансировщика в допустимых пределах (см. определение сигнала подкрепления rt для ин- формации о допустимых пределах). 4.3.1 Моделирование тележки Приведенное выше определение целевой функции предполагает, что мы мо- жем измерить количество шагов, в течение которых балансировщик маятника находился в стабильном состоянии. Чтобы выполнить такие измерения, нам нужно реализовать симулятор системы с тележкой, используя уравнения дви- жения и ограничения, определенные ранее. Исходный код примеров этой главы можно найти в каталоге Chapter4 фай- лового архива книги. Во-первых, нам нужно создать в рабочем каталоге файл с именем cart_ pole.py. Этот файл содержит исходный код уравнений движения и функцию для оценки приспособленности балансировщика одиночного маятника. 1. Начнем с определения констант, описывающих физику системы с тележ- кой: GRAVITY = 9.8 # m/s^2 MASSCART = 1.0 # kg MASSPOLE = 0.5 # kg TOTAL_MASS = (MASSPOLE + MASSCART) # Расстояние от центра масс маятника до шарнира# (обычно половина длины стержневого маятника).LENGTH = 0.5 # mPOLEMASS_LENGTH = (MASSPOLE * LENGTH) # kg * m FORCE_MAG = 10.0 # N FOURTHIRDS = 4.0/3.0 # Количество секунд между обновлениями состояния. TAU = 0.02 # sec90  Балансировка тележки с обратным маятником\n4.3 целевая функция Для экСперимента пО балан СирОвке ОДинОчнОгО маятника Наша цель – создать контроллер балансировки одиночного обратного маятни- ка, который сможет поддерживать систему в стабильном состоянии в рамках определенных ограничений как можно дольше, но, по крайней мере, в течение ожидаемого количества временных шагов, указанных в конфигурации экспе- римента (500 000). Таким образом, целевая функция должна оптимизировать продолжительность стабильной балансировки маятника и может быть опре- делена как логарифмическая разница между ожидаемым количеством шагов и фактическим количеством шагов, полученных во время оценки фенотипа нейросети. Функция ошибки задается следующим образом: max eval maxlogt logt.logt−= В данном эксперименте tmax – это ожидаемое количество шагов от конфигу - рации эксперимента, а teval – фактическое количество шагов, в течение кото- рых контроллер смог поддерживать стабильное состояние балансировщика в допустимых пределах (см. определение сигнала подкрепления rt для ин- формации о допустимых пределах). 4.3.1 Моделирование тележки Приведенное выше определение целевой функции предполагает, что мы мо- жем измерить количество шагов, в течение которых балансировщик маятника находился в стабильном состоянии. Чтобы выполнить такие измерения, нам нужно реализовать симулятор системы с тележкой, используя уравнения дви- жения и ограничения, определенные ранее. Исходный код примеров этой главы можно найти в каталоге Chapter4 фай- лового архива книги. Во-первых, нам нужно создать в рабочем каталоге файл с именем cart_ pole.py. Этот файл содержит исходный код уравнений движения и функцию для оценки приспособленности балансировщика одиночного маятника. 1. Начнем с определения констант, описывающих физику системы с тележ- кой: GRAVITY = 9.8 # m/s^2 MASSCART = 1.0 # kg MASSPOLE = 0.5 # kg TOTAL_MASS = (MASSPOLE + MASSCART) # Расстояние от центра масс маятника до шарнира# (обычно половина длины стержневого маятника).LENGTH = 0.5 # mPOLEMASS_LENGTH = (MASSPOLE * LENGTH) # kg * m FORCE_MAG = 10.0 # N FOURTHIRDS = 4.0/3.0 # Количество секунд между обновлениями состояния. TAU = 0.02 # sec90  Балансировка тележки с обратным маятником\n--- Страница 92 ---\n2. После этого мы готовы реализовать уравнения движения, используя следующие константы: force = -FORCE_MAG if action <= 0 else FORCE_MAG cos_theta = math.cos(theta) sin_theta = math.sin(theta) temp = (force + POLEMASS_LENGTH * theta_dot * theta_dot * \\ sin_theta) / TOTAL_MASS # Угловое ускорение маятника. theta_acc = (GRAVITY * sin_theta - cos_theta * temp) /\\ (LENGTH * (FOURTHIRDS - MASSPOLE * \\ cos_theta * cos_theta / TOTAL_MASS))# Линейное ускорение тележки. x_acc = temp - POLEMASS_LENGTH * theta_acc * \\ cos_theta / TOTAL_MASS # Обновление четырех переменных состояния по методу Эйлера. x_ret = x + TAU * x_dotx_dot_ret = x_dot + TAU * x_acctheta_ret = theta + TAU * theta_dottheta_dot_ret = theta_dot + TAU * theta_acc Чтобы разобраться с назначением констант, изучите реализацию функции do_step(action , x, x_dot , theta , theta_dot ) в исходном коде примера этой главы. Приведенный выше фрагмент кода в качестве входных данных использует текущее состояние системы (x, x_dot, theta, theta_dot ) вместе с управляющим действием и применяет уравнения движения, описанные ранее, для обнов- ления состояния системы перед следующим шагом. Обновленное состояние системы затем возвращается, чтобы обновить симулятор и проверить нару - шения ограничений. В целом получается цикл моделирования, организован- ный в соответствии с описанием в следующем разделе. 4.3.2 Цикл моделирования Итак, мы полностью реализовали уравнения движения и числовую аппрок - симацию переменных состояния для одного шага моделирования устрой- ства с тележкой. После этого мы готовы начать реализацию полного цик- ла моделирования, в котором используется нейросеть контроллера, чтобы оценить текущее состояние системы и выбрать соответствующее действие (усилие, которое будет приложено к тележке) для следующего шага. Упомя- нутая ранее нейросеть создается для каждого генома популяции на опреде- ленном поколении эволюции, что позволяет нам оценивать эффективность всех геномов. Изучите реализацию функции run_cart_pole_simulation(net, max_bal_ steps,random_start=True) для более глубокого понимания работы ал- горитма. Полный цикл моделирования может состоять из следующих шагов: 4.3 Целевая функция для эксперимента по балансировке одиночного маятника  91\n--- Страница 93 ---\n1. Во-первых, нам нужно инициализировать переменные начального со- стояния либо нулевыми значениями, либо случайными значениями в рамках ограничений, описанных ранее и сосредоточенных вокруг нуля. Случайные значения состояния могут быть созданы следующим образом: # -1.4 < x < 1.4 x = (random.random() * 4.8 - 2.4) / 2.0 # -0.375 < x_dot < 0.375 x_dot = (random.random() * 3 - 1.5) / 4.0 # -0.105 < theta < 0.105 theta = (random.random() * 0.42 - 0.21) / 2.0 # -0.5 < theta_dot < 0.5theta_dot = (random.random() * 4 - 2) / 4.0 Мы намеренно сократили диапазон всех значений по сравнению с соответствующими масштабированными ограничениями, чтобы убедиться, что алгоритм не запускается в критическом состоянии, то есть когда стабилизация изначально невозможна. 2. После этого мы готовы начать цикл моделирования через определен- ное количество шагов, которые задаются параметром max_bal_steps . Следующий код выполняется внутри цикла моделирования. 3. Переменные состояния необходимо масштабировать, чтобы они со- ответствовали диапазону [0,1], прежде чем загружать их в качестве входных данных в нейросеть контроллера. Эта процедура дает вычис - лительные и эволюционные преимущества, о чем мы говорили ранее. Здесь мы не указываем значение смещения в явном виде, поскольку фреймворк NEAT-Python обрабатывает его внутренне, поэтому вход- ные данные нейросети можно определить следующим образом: input[0] = (x + 2.4) / 4.8 input[1] = (x_dot + 1.5) / 3 input[2] = (theta + 0.21) / .42 input[3] = (theta_dot + 2.0) / 4.0 4. Затем масштабированные входные данные можно использовать для активации нейросети, а выходные данные нейросети применяются для получения дискретного значения действия: # Активация NET output = net.activate(input) # Получаем значение, определяющее действие.action = 0 if output[0] < 0.5 else 1 5. Получив значение действия и текущие значения переменных состоя- ния, вы можете запустить один шаг моделирования тележки с маятни- ком. После шага моделирования возвращенные переменные состояния проверяются на соответствие ограничениям, чтобы проверить, нахо- дится ли состояние системы в допустимых границах.92  Балансировка тележки с обратным маятником\n--- Страница 94 ---\nВ случае обнаружения неудачи возвращается текущее количество шагов моделирования, и это значение будет использоваться для оценки приспособ- ленности фенотипа: # Применяем действие к симулятору тележки x, x_dot, theta, theta_dot = do_step(action = action, x = x, x_dot = x_dot, theta = theta, theta_dot = theta_dot ) # Проверяем на соответствие допустимым границам. # В случае выхода за границы возвращаем число шагов.if x < -2.4 or x > 2.4 or theta < -0.21 or theta > 0.21: return steps Если нейросеть контроллера смогла поддерживать стабильное состояние балансировки системы тележка–маятник для всех шагов моделирования, функция run_cart_pole_simulation возвращает значение с максимальным ко- личеством шагов моделирования. 4.3.3 Оценка приспособленности генома Используя количество успешных шагов моделирования, возвращенных функ - цией run_cart_pole_simulation , описанной ранее, мы готовы реализовать функ - цию оценки приспособленности генома. 1. Сначала мы запускаем цикл симуляции тележки с маятником, который возвращает количество успешных шагов симуляции: steps = run_cart_pole_simulation(net, max_bal_steps) 2. После этого мы готовы оценить приспособленность конкретного генома, как описано ранее: log_steps = math.log(steps) log_max_steps = math.log(max_bal_steps) # Значение ошибки в интервале [0, 1] error = (log_max_steps - log_steps) / log_max_steps # Приспособленность вычисляется как разность единицы и ошибкиfitness = 1.0 - error Для углубленного понимания работы кода изучите реализацию функ - ции eval_fitness(net, max_bal_steps=500000) . Мы используем логарифмическую шкалу, потому что большинство прого- нов симуляции дают сбой примерно за 100 шагов, но мы проверяем 500 000 шагов балансировки.",
          "debug": {
            "start_page": 91,
            "end_page": 94
          }
        },
        {
          "name": "4.4 Эксперимент по балансировке одиночного маятника 93",
          "content": "--- Страница 94 --- (продолжение)\n4.4 экСперимент пО балан СирОвке ОДинОчнОгО маятника Теперь, когда у нас есть целевая функция, определенная и реализованная вмес- те с симулятором динамической системы тележка–маятник, мы готовы начать писать исходный код для запуска нейроэволюционного процесса с помощью 4.4 Эксперимент по балансировке одиночного маятника  93\n4.4 экСперимент пО балан СирОвке ОДинОчнОгО маятника Теперь, когда у нас есть целевая функция, определенная и реализованная вмес- те с симулятором динамической системы тележка–маятник, мы готовы начать писать исходный код для запуска нейроэволюционного процесса с помощью 4.4 Эксперимент по балансировке одиночного маятника  93\n--- Страница 95 ---\nалгоритма NEAT. Мы будем использовать ту же библиотеку NEAT-Python, что и в эксперименте XOR в предыдущей главе, но с соответствующим образом настроенными гиперпараметрами NEAT. Гиперпараметры хранятся в файле single_pole_config.ini , который можно найти в каталоге исходного кода, отно- сящегося к этой главе. Вам нужно скопировать этот файл в локальный каталог Chapter4, в котором у вас уже должен быть скрипт Python с симулятором тележ - ки, который мы создали ранее. 4.4.1 Выбор гиперпараметров В секции NEAT файла конфигурации мы определяем популяцию из 150 отдель- ных организмов и порог приспособленности со значением 1.0 в качестве кри- терия прекращения. Приспособленность fitness_criterion установлена в значение max, что озна- чает завершение эволюционного процесса, когда любая особь достигает зна- чения приспособленности, равного значению fitness_threshold : [NEAT] fitness_criterion = max fitness_threshold = 1.0 pop_size = 150 reset_on_extinction = False Кроме того, мы значительно снизили вероятность добавления нового узла, чтобы сместить эволюционный процесс в разработку большего количества паттернов связей с минимальным количеством узлов в контроллере. Таким образом мы стремимся снизить энергопотребление нейросети развитого контроллера и сократить вычислительные затраты на обучение. Соответствующие параметры в файле конфигурации следующие: # Вероятность добавления/удаления узла node_add_prob = 0.02 node_delete_prob = 0.02 Параметры, описывающие нашу начальную конфигурацию сети по коли- честву скрытых, входных и выходных узлов, задаются следующим образом: # Параметры сети num_hidden = 0 num_inputs = 4num_outputs = 1 Мы увеличили порог совместимости видов, чтобы сместить эволюцион- ный процесс в сторону меньшего количества видов. Кроме того, мы увели- чили минимальный размер вида, чтобы указать, что мы заинтересованы в гораздо более густонаселенных видах, которые имеют больше шансов на сохранение полезных мутаций. В то же время мы уменьшили максимальный возраст стагнации, чтобы интенсифицировать эволюционный процесс, уси- лив раннее вымирание стагнирующих видов, которые не показывают каких- либо улучшений приспособленности. Соответствующие параметры в файле конфигурации:94  Балансировка тележки с обратным маятником\n--- Страница 96 ---\n[DefaultSpeciesSet] compatibility_threshold = 4.0 [DefaultStagnation] species_fitness_func = max max_stagnation = 15 species_elitism = 2 [DefaultReproduction]elitism = 2survival_threshold = 0.2min_species_size = 8 Изучите файл конфигурации single_pole_config.ini . Исходя из этих параметров конфигурации, в ходе эволюционного процесса будут использоваться более многочисленные виды, однако количество уни- кальных видов будет оставаться небольшим. 4.4.2 Настройка рабочей среды Прежде чем вы начнете писать исходный код движка эксперимента, вы долж - ны настроить виртуальную среду Python и установить все необходимые зави- симости. Вы можете сделать это с помощью Anaconda, выполнив следующие команды в командной строке: $ conda create --name single_pole_neat python=3.5 $ conda activate single_pole_neat $ pip install neat-python==0.92$ conda install matplotlib$ conda install graphviz $ conda install python-graphviz Сначала эти команды создают и активируют виртуальную среду single_pole_ neat с Python 3.5. После этого устанавливается библиотека NEAT-Python вер- сии 0.92, а также другие зависимости, необходимые для утилит визуализации. 4.4.3 Исходный код эксперимента Во-первых, вам нужно создать файл single_pole_experiment.py в рабочем катало- ге Chapter4. В этом файле будет сохранен исходный код эксперимента по балан- сировке одиночного маятника. Также вам необходимо скопировать файл visu- alize.py из файлового архива главы в рабочий каталог. Мы будем использовать утилиты из этого файла для визуализации результатов эксперимента. Исходный код движка эксперимента включает две основные функции. Функция оценки приспособленности всех геномов в популяции Первая функция получает список всех геномов в популяции и назначает оцен- ку приспособленности для каждого из них. Эта функция передается по ссылке в движок нейроэволюции библиотеки NEAT-Python. Исходный код этой функ - ции выглядит следующим образом: 4.4 Эксперимент по балансировке одиночного маятника  95\n--- Страница 97 ---\ndef eval_genomes(genomes, config): for genome_id, genome in genomes: genome.fitness = 0.0 net = neat.nn.FeedForwardNetwork.create(genome, config) fitness = cart.eval_fitness(net) if fitness >= config.fitness_threshold: # Выполняем дополнительные шаги оценки со случайными начальными состояниями, # чтобы гарантировать, что мы нашли стабильную стратегию управления, # а не какой-то особый случай начального состояния. success_runs = evaluate_best_net(net, config, additional_num_runs) # Нормируем приспособленность fitness = 1.0 - (additional_num_runs - success_runs) / \\ additional_num_runs genome.fitness = fitness Обратите внимание, что мы вводим дополнительные прогоны симу- ляции для победившего генома, чтобы убедиться, что его стратегия управления стабильна при запуске из множества случайных началь-ных состояний. Эта дополнительная проверка гарантирует, что мы нашли настоящего победителя, а не особый случай, специфичный для конкретного исходного состояния. Предыдущая функция получает список всех геномов в популяции и па- раметры конфигурации NEAT. Для каждого конкретного генома она созда- ет фенотип нейросети и использует его в качестве контроллера для запуска моделирования тележки с обратным маятником, как задано в следующей строке кода: fitness = cart.eval_fitness(net) Полученное значение приспособленности затем сравнивается с порого- вым значением, которое мы определили в параметрах конфигурации. Если приспособленность превышает пороговое значение, мы можем предполо- жить, что был найден успешный контроллер. Чтобы дополнительно прове- рить успешность найденного контроллера, сначала будут запущены допол- нительные прогоны моделирования, а затем будет рассчитан окончательный показатель приспособленности. Это делает следующий фрагмент приведен- ного выше кода: success_runs = evaluate_best_net(net, config, additional_num_runs) fitness = 1.0 - (additional_num_runs - success_runs) / additional_num_runs Дополнительные прогоны моделирования используют различные началь- ные значения для генератора случайных чисел, чтобы покрыть большинство возможных начальных состояний тележки с обратным маятником.96  Балансировка тележки с обратным маятником\n--- Страница 98 ---\nФункция выполнения эксперимента Вторая функция конфигурирует, выполняет и выводит результаты процесса нейроэволюции. Здесь мы наметим некоторые критические места в реализа- ции функции выполнения эксперимента. 1. Функция начинается с загрузки гиперпараметров из файла конфигура- ции и порождает начальную популяцию, используя загруженную кон- фигурацию: # Загружаем конфигурацию. config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction, neat.DefaultSpeciesSet, neat.DefaultStagnation, config_file) # Создаем популяцию, которая является объектом верхнего уровня NEAT. p = neat.Population(config) 2. После этого функция настраивает репо́ртеры для сбора статистики, ка- сающейся выполнения эволюционного процесса. Также добавляются выходные репортеры для вывода результатов выполнения на консоль в режиме реального времени. Сборщик контрольных точек настроен на сохранение промежуточных этапов выполнения, что может пригодить- ся, если позже вам потребуется восстановить процесс обучения: # Добавляем репортер вывода хода выполнения в консоль. p.add_reporter(neat.StdOutReporter(True)) stats = neat.StatisticsReporter() p.add_reporter(stats) p.add_reporter(neat.Checkpointer(5, filename_prefix=‘out/spb-neat—checkpoint-')) 3. Наконец, процесс эволюции выполняется в течение указанного числа поколений, а результаты сохраняются в каталоге Output: # Запуск для N поколений. best_genome = p.run(eval_genomes, n=n_generations) # Отображение лучшего генома из поколений. print('\\nBest genome:\\n{!s}'.format(best_genome)) # Проверяем, дает ли нам лучший геном контроллер-победитель # для балансировки тележки с одним обратным маятником.net = neat.nn.FeedForwardNetwork.create(best_genome, config)best_genome_fitness = cart.eval_fitness(net)if best_genome_fitness >= config.fitness_threshold: print(\"\\n\\nSUCCESS: The Single-Pole balancing controller has been found!!!\")else: print(\"\\n\\nFAILURE: Failed to find Single-Pole balancing controller!!!\") 4.4 Эксперимент по балансировке одиночного маятника  97\n--- Страница 99 ---\nПолная реализация представлена в коде функции run_ experiment(config_file, n_generations=100) в файловом архиве книги. После того как в ходе эволюционного процесса найден лучший геном, проверяем, действительно ли он соответствует критериям порога приспо- собленности, которые мы установили в файле конфигурации. Возможно, во время этого процесса не будет найдено никакого рабочего решения, но тем не менее библиотека NEATPython вернет геном с формально наилучшим со- ответствием. Вот почему мы нуждаемся в этой дополнительной проверке, чтобы гарантировать, что наиболее подходящий геном может действительно решить проблему на практике. 4.4.4 Запуск эксперимента по балансировке одиночного маятника Вам необходимо перейти в каталог, содержащий файл single_pole_experiment.py , и выполнить следующую команду: $ python single_pole_experiment.py Не забудьте активировать соответствующую виртуальную среду с по- мощью команды conda activate single_pole_neat . Во время выполнения скрипта эксперимента на консоль будут выводиться следующие выходные данные для каждого поколения эволюции: ****** Running generation 13 ****** Population's average fitness: 0.26673 stdev: 0.12027 Best fitness: 0.70923 - size: (1, 2) - species 1 - id 2003 Average adjusted fitness: 0.161 Mean genetic distance 1.233, standard deviation 0.518 Population of 150 members in 1 species: ID age size fitness adj fit stag ==== === ==== ======= ======= ==== 1 13 150 0.7 0.161 7Total extinctions: 0Generation time: 4.635 sec (0.589 average) В выходных данных вы можете видеть, что средняя приспособленность населения в поколении 14 низкая, но приспособленность организма с луч- шими показателями (0.70923) уже близка к нашему пороговому значению завершения (fitness_threshold = 1.0), которое было установлено в файле кон- фигурации. Организм-чемпион кодирует фенотип нейросети, состоящий из одного нелинейного узла (выход) и только двух соединений (size: (1, 2)). Также интересно отметить, что в популяции существует только один вид. После того как победитель найден, вывод консоли имеет следующие строки:98  Балансировка тележки с обратным маятником\n--- Страница 100 ---\n****** Running generation 14 ****** Population's average fitness: 0.26776 stdev: 0.13359 Best fitness: 1.00000 - size: (1, 3) - species 1 - id 2110 Best individual in generation 14 meets fitness threshold - complexity: (1, 3) Best genome: Key: 2110 Fitness: 1.0 Nodes: 0 DefaultNodeGene(key=0, bias=-3.328545880116371, response=1.0, activation=sigmoid, aggregation=sum)Connections: DefaultConnectionGene(key=(-4, 0), weight=2.7587300138861037,enabled=True) DefaultConnectionGene(key=(-3, 0), weight=2.951449584136504, enabled=True) DefaultConnectionGene(key=(-1, 0), weight=0.9448711043565166, enabled=True) Evaluating the best genome in random runs Runs successful/expected: 100/100SUCCESS: The stable Single-Pole balancing controller has been found!!! Лучший геном, который является победителем эволюции, кодирует фено- тип нейросети, состоящий только из одного нелинейного узла (выход) и трех соединений из входных узлов (size: (1, 3)). Интересно отметить, что эволю- ция смогла выработать надежную стратегию управления, которая полностью игнорирует линейную скорость тележки и использует только три других вхо- да: x, θ и θ. Этот факт является еще одним признаком правильности эволю- ционного отбора, потому что мы решили игнорировать трение тележки, что фактически исключает линейную скорость тележки из уравнений движения. Граф нейросети победившего контроллера балансировки одиночного об- ратного маятника представлен на рис. 4.3. действие Рис. 4.3. Граф оптимального контроллера балансировки обратного маятника, найденный алгоритмом NEAT 4.4 Эксперимент по балансировке одиночного маятника  99\n--- Страница 101 ---\nГрафик изменения значений приспособленности на протяжении поколе- ний эволюции показан на рис. 4.4. Средняя и лучшая приспособленность популяции Поколениясредняя –1 СКО +1 СКО лучшаяПриспособленность Рис. 4.4. Среднее и лучшее значения функции приспособленности в эксперименте с обратным маятником Средняя приспособленность популяции во всех поколениях была низкой, но с самого начала произошла полезная мутация, которая породила опреде- ленную линию организмов. Из поколения в поколение одаренные особи из этой линии смогли не только сохранить свои полезные черты, но и улучшить их, что в конечном итоге привело к появлению победителя эволюции.",
          "debug": {
            "start_page": 94,
            "end_page": 101
          }
        },
        {
          "name": "4.5 Упражнения 100",
          "content": "--- Страница 101 --- (продолжение)\n4.5 упражнения 1. Попробуйте увеличить значение параметра node_add_prob и посмотреть, что произойдет. Производит ли алгоритм какое-то количество скры- тых узлов, и если да, то сколько? 2. Попробуйте уменьшить/увеличить значение compatibility_threshold . Что произойдет, если вы установите его на 2.0 или 6.0? Сможет ли алго- ритм найти решение в каждом случае? 3. Попробуйте установить значение elitism в разделе DefaultReproduction рав- ным нулю. Посмотрите, что получится. Сколько времени понадобилось эволюционному процессу, чтобы найти приемлемое решение на этот раз?100  Балансировка тележки с обратным маятником\n4.5 упражнения 1. Попробуйте увеличить значение параметра node_add_prob и посмотреть, что произойдет. Производит ли алгоритм какое-то количество скры- тых узлов, и если да, то сколько? 2. Попробуйте уменьшить/увеличить значение compatibility_threshold . Что произойдет, если вы установите его на 2.0 или 6.0? Сможет ли алго- ритм найти решение в каждом случае? 3. Попробуйте установить значение elitism в разделе DefaultReproduction рав- ным нулю. Посмотрите, что получится. Сколько времени понадобилось эволюционному процессу, чтобы найти приемлемое решение на этот раз?100  Балансировка тележки с обратным маятником\n--- Страница 102 ---\n4. Задайте для параметра survival_threshold в разделе DefaultReproduction значение 0.5. Посмотрите, как это влияет на видообразование в про- цессе эволюции. Почему так происходит? 5. Увеличьте значения additional_num_runs и additional_steps на порядок величины, чтобы дополнительно изучить, насколько хорошо обобщена найденная стратегия управления. Алгоритм все еще в состоянии найти выигрышное решение? Последнее упражнение приведет к увеличению времени выполнения алгоритма.",
          "debug": {
            "start_page": 101,
            "end_page": 102
          }
        },
        {
          "name": "4.6 Задача балансировки двойного маятника 101",
          "content": "--- Страница 102 --- (продолжение)\n4.6 заДача балан СирОвки ДвОйнОгО маятника Задача балансировки одиночного маятника не вызывает затруднений у алго- ритма NEAT, способного быстро найти оптимальную стратегию управления для поддержания стабильного состояния системы. Чтобы усложнить экспе- римент, мы представляем более продвинутую версию задачи балансировки. В этой версии на тележке установлены два обратных маятника на шарнире. Схема новой системы с двумя маятниками показана на рис. 4.5. Рис. 4.5. Система из тележки с двумя маятниками Прежде чем перейти к деталям реализации эксперимента, нам необходи- мо определить переменные состояния и уравнения движения для моделиро- вания тележки с двумя обратными маятниками. 4.6.1 Переменные состояния системы и уравнения движения Задача контроллера – прикладывать усилие к тележке таким образом, чтобы как можно дольше удерживать в равновесии два перевернутых маятника. В то же время тележка должна оставаться в определенных границах. Как и в случае с задачей балансировки одиночного маятника, рассмотренной ранее, страте- гию управления можно определить как задачу управляемого избегания. Это означает, что контроллер должен поддерживать стабильное состояние систе- мы, избегая опасных зон, когда тележка выходит за границы пути или любой 4.6 Задача балансировки двойного маятника  101\n4.6 заДача балан СирОвки ДвОйнОгО маятника Задача балансировки одиночного маятника не вызывает затруднений у алго- ритма NEAT, способного быстро найти оптимальную стратегию управления для поддержания стабильного состояния системы. Чтобы усложнить экспе- римент, мы представляем более продвинутую версию задачи балансировки. В этой версии на тележке установлены два обратных маятника на шарнире. Схема новой системы с двумя маятниками показана на рис. 4.5. Рис. 4.5. Система из тележки с двумя маятниками Прежде чем перейти к деталям реализации эксперимента, нам необходи- мо определить переменные состояния и уравнения движения для моделиро- вания тележки с двумя обратными маятниками. 4.6.1 Переменные состояния системы и уравнения движения Задача контроллера – прикладывать усилие к тележке таким образом, чтобы как можно дольше удерживать в равновесии два перевернутых маятника. В то же время тележка должна оставаться в определенных границах. Как и в случае с задачей балансировки одиночного маятника, рассмотренной ранее, страте- гию управления можно определить как задачу управляемого избегания. Это означает, что контроллер должен поддерживать стабильное состояние систе- мы, избегая опасных зон, когда тележка выходит за границы пути или любой 4.6 Задача балансировки двойного маятника  101\n--- Страница 103 ---\nиз маятников отклоняется от вертикали больше допустимого. Единственного решения этой задачи не существует, но можно найти подходящую стратегию управления, учитывая, что маятники имеют разную длину и массу. Поэтому они по-разному реагируют на управляющее воздействие. Текущее состояние балансировщика двух маятников может быть опреде- лено следующими переменными: горизонтальная позиция тележки x ; скорость тележки ; угол отклонения первого маятника от вертикали ; угловая скорость первого маятника ; угол отклонения второго маятника ; угловая скорость второго маятника . Уравнения движения для двух несвязанных маятников, сбалансированных на одной тележке, которая игнорирует трение между колесами и дорожкой, имеют следующий вид: 3 4¨ ¨ pii ii i i iixcos gsinL mLµθθ θθ  =− ++    2 1 2 1¨x ii iiF F x M m= =− = +∑ ∑  ; . В этом уравнении – сила реакции от i-го маятника на тележке: 2 3 4pii i iii i i i i iiFmLsin mcos gsinmLµθθθ θ θ  = + +   . Далее, – эффективная масса i -го маятника: 2 314i i i m m cosθ =−   . В модели двух маятников на тележке используются параметры, перечис - ленные в табл. 4.1. Таблица 4.1. Параметры модели тележки с двумя обратными маятниками Символ Описание Значения x Позиция тележки на дорожке ∈ [–2.4, 2.4] м θ Отклонение маятника от вертикали ∈ [–36, 36] градусов Fx Сила, приложенная к тележке ∓10H Li Расстояние от центра масс маятника до шарнира L1 = 0,5 м, L2 = 0,05 м M Масса тележки 1.0 кг mi Масса i-го маятника m1 = 0,1 кг, m2 = 0,01 кг µp Коэффициент трения в шарнире i-го маятника 0.000002 g Ускорение свободного падения –9,8 м/с2102  Балансировка тележки с обратным маятником\n--- Страница 104 ---\nСледующий фрагмент кода определяет эти параметры системы как кон- станты: GRAVITY = -9.8 # m/s^2 – уравнения движения системы из двух маятников # подразумевают отрицательное значение MASS_CART = 1.0 # kg FORCE_MAG = 10.0 # N # Первый маятник MASS_POLE_1 = 1.0 # kg LENGTH_1 = 0.5 # m – обычно половина длины первого маятника# Второй маятникMASS_POLE_2 = 0.1 # kgLENGTH_2 = 0.05 # m – обычно половина длины второго маятника # Коэффициент трения шарнира MUP = 0.000002 Реализация уравнений движения в коде Python выглядит следующим об- разом: # Находим направление приложенной силы. force = (action - 0.5) * FORCE_MAG * 2.0 # действие имеет бинарное значение # Вычисляем проекцию сил, действующих на маятники cos_theta_1 = math.cos(theta1) sin_theta_1 = math.sin(theta1)g_sin_theta_1 = GRAVITY * sin_theta_1cos_theta_2 = math.cos(theta2)sin_theta_2 = math.sin(theta2)g_sin_theta_2 = GRAVITY * sin_theta_2# Вычисляем промежуточные значения ml_1 = LENGTH_1 * MASS_POLE_1 ml_2 = LENGTH_2 * MASS_POLE_2temp_1 = MUP * theta1_dot / ml_1temp_2 = MUP * theta2_dot / ml_2fi_1 = (ml_1 * theta1_dot * theta1_dot * sin_theta_1) + \\ (0.75 * MASS_POLE_1 * cos_theta_1 * (temp_1 + g_sin_theta_1))fi_2 = (ml_2 * theta2_dot * theta2_dot * sin_theta_2) + \\ (0.75 * MASS_POLE_2 * cos_theta_2 * (temp_2 + g_sin_theta_2)) mi_1 = MASS_POLE_1 * (1 - (0.75 * cos_theta_1 * cos_theta_1)) mi_2 = MASS_POLE_2 * (1 - (0.75 * cos_theta_2 * cos_theta_2)) # Вычисляем результаты: ускорение тележки и угловые ускорения маятниковx_ddot = (force + fi_1 + fi_2) / (mi_1 + mi_2 + MASS_CART)theta_1_ddot = -0.75 * (x_ddot * cos_theta_1 + \\ g_sin_theta_1 + temp_1) / LENGTH_1theta_2_ddot = -0.75 * (x_ddot * cos_theta_2 + \\ g_sin_theta_2 + temp_2) / LENGTH_2 Полный исходный код представлен в файле cart_two_pole.py , кото - рый хранится в файловом архиве книги в каталоге Chapter4 . Озна- комьтесь с функцией calc_step(action, x, x_dot, theta1, theta1_dot, theta2, theta2_dot) . 4.6 Задача балансировки двойного маятника  103\n--- Страница 105 ---\nПриведенный выше код получает текущее состояние системы (x, x_dot, theta1, theta1_dot, theta2, theta2_dot ) наряду с управляющим сигналом и вы- числяет производные (ускорение тележки и угловое ускорение обоих маят - ников). 4.6.2 Подкрепляющий сигнал После выполнения действий среда моделирования должна возвращать мини- мальную информацию о состоянии системы в виде сигнала подкрепления rt. Сигнал подкрепления показывает, нарушает ли контроллер балансировки двух маятников установленные ограничения после применения действия. Его мож - но определить следующим образом: 0 063 063 24 24 1 в остальных случаяхt i t t если , , радиан; и , x , мr θ −<< −<< =. Реализация сигнала подкрепления в Python выглядит так: res = x < -2.4 or x > 2.4 or \\ theta1 < -THIRTY_SIX_DEG_IN_RAD or theta1 > THIRTY_SIX_DEG_IN_RAD or \\ theta2 < -THIRTY_SIX_DEG_IN_RAD or theta2 > THIRTY_SIX_DEG_IN_RAD Условие проверяет, что угол отклонения каждого маятника от вертикали находится в диапазоне ±36 градусов (0,63 радиан) и что расстояние от тележ - ки до центра дорожки лежит в диапазоне ±2,4 м. 4.6.3 Начальные условия и обновление состояния В эксперименте по балансировке одиночного маятника мы использовали слу- чайные условия начального состояния, но в эксперименте с двумя маятника- ми начальные условия немного проще. Эксперимент запускается с нулевыми значениями для всех скоростей тележки и маятников. Начальное отклонение длинного маятника составляет один градус от вертикали, а короткий маятник находится строго в вертикальном положении. Мы устанавливаем следующие начальные условия: ; ; ; ; ; . Состояние системы тележка–маятники обновляется на каждом этапе мо- делирования путем численной аппроксимации уравнений движения с ис - пользованием метода Рунге–Кутты четвертого порядка с размером шага 0,01 секунды. Метод аппроксимации Рунге–Кутты четвертого порядка позво- ляет рассчитать отклик системы с учетом переменных состояния текущего временнóго шага. Новые управляющие входы генерируются каждую секунду. 104  Балансировка тележки с обратным маятником\n--- Страница 106 ---\nТаким образом, частота управления составляет 50 Гц, а частота обновления состояния системы – 100 Гц. Реализация метода Рунге–Кутты четвертого порядка в Python выглядит следующим образом. 1. Используем текущие переменные состояния системы тележка–маят - ники, чтобы обновить промежуточное состояние для следующего шага полупериода и выполнить первый шаг моделирования: hh = tau / 2.0 yt = [None] * 6 # Обновляем промежуточное состояние. for i in range(6): yt[i] = y[i] + hh * dydx[i] # Выполняем шаг моделирования. x_ddot, theta_1_ddot, theta_2_ddot = calc_step(action = f, yt[0],yt[1], yt[2], yt[3], yt[4], yt[5]) # Сохраняем производные. dyt = [yt[1], x_ddot, yt[3], theta_1_ddot, yt[5], theta_2_ddot] 2. Обновляем промежуточное состояние, используя производные, полу - ченные на первом этапе моделирования, и выполняем второй этап мо- делирования: # Обновляем промежуточное состояние. for i in range(6): yt[i] = y[i] + hh * dyt[i] # Выполняем один шаг моделирования. x_ddot, theta_1_ddot, theta_2_ddot = calc_step(action = f, yt[0],yt[1], yt[2], yt[3], yt[4], yt[5]) # Сохраняем производные. dym = [yt[1], x_ddot, yt[3], theta_1_ddot, yt[5], theta_2_ddot] 3. Обновляем промежуточное состояние, используя производные, полу - ченные на первом и втором этапах моделирования, и выполняем тре- тий этап моделирования, используя обновленное состояние: # Обновляем промежуточное состояние. for i in range(6): yt[i] = y[i] + tau * dym[i] dym[i] += dyt[i] # Выполняем один шаг моделирования. x_ddot, theta_1_ddot, theta_2_ddot = calc_step(action = f, yt[0],yt[1], yt[2], yt[3], yt[4], yt[5]) # store derivatives dyt = [yt[1], x_ddot, yt[3], theta_1_ddot, yt[5], theta_2_ddot] 4.6 Задача балансировки двойного маятника  105\n--- Страница 107 ---\nНаконец, воспользуемся производными от первых трех этапов моделиро- вания, чтобы аппроксимировать конечное состояние системы, которое будет использоваться в дальнейшем моделировании: # Находим состояние системы после аппроксимации. yout = [None] * 6 # Аппроксимированное состояние системы. h6 = tau / 6.0 for i in range(6): yout[i] = y[i] + h6 * (dydx[i] + dyt[i] + 2.0 * dym[i]) Давайте рассмотрим элементы предыдущего уравнения: f – управляющее действие, применяемое во время моделирования (0 или 1); y – список с текущими значениями переменных состояния (1 1 2 2 x , , ,, , xθθθθ  ); dydx – это список производных переменных состояния ( 1 2 1 2 , ¨ ¨ ¨xx , , , ,θθθθ   ); tau – размер шага по времени для приближения. Для более подробного знакомства с тонкостями реализации изучите код функции rk4(f, y, dydx, tau) в файле cart_two_pole.py . Реализация метода Рунге–Кутты четвертого порядка получает текущее состояние системы (x, x_dot, theta1, theta1_dot, theta2, theta2_dot ) вместе с их производными и аппроксимирует состояние системы на следующем шаге. 4.6.4 Управляющие действия Как и в случае эксперимента с балансировкой одиночного маятника, который обсуждался ранее в этой главе, контроллер балансировки двойного маятника генерирует только два управляющих сигнала: толчок влево и толчок вправо с постоянной силой. Таким образом, действующая сила в момент t может быть определена следующим образом: 1 10Н 0 10Нtесли at ,Fесли at , =  == −    . В данном уравнении a[t] – управляющий сигнал, полученный от контрол- лера в момент t. 4.6.5 Взаимодействие между решателем и симулятором Прежде чем применить переменные состояния в качестве входных дан- ных для нейросети контроллера, их следует масштабировать, чтобы привести к интервалу [0,1]. Уравнения для предварительной обработки входных пере- менных имеют следующий вид:106  Балансировка тележки с обратным маятником\n--- Страница 108 ---\n4() 012448x t xt . ,.= +   ( ) 2 1106281256x t t . ,.θ= +     ( ) 4 2106281256x t t . ,.θ= +    () 11153x t xt . , =+   () 3 112 x t t , θ= +   )( 5 2124x t t . θ= +   В этих уравнениях переменные x0 x5 соответствуют горизонтальному по- ложению тележки, ее горизонтальной скорости, углу первого маятника от- носительно вертикали, его угловой скорости, а также углу и угловой скорости второго маятника соответственно. Принимая во внимание системные ограничения, определенные ранее (см. определение rt), масштабированные значения x0, x2 и x4 гарантированно находятся в интервале [0, 1], в то время как масштабированные значения x1, x3 и x5 в основном попадают в интервал 0…1, но могут рано или поздно выйти за эти пределы. Соответствующий код для масштабирования входных данных выглядит так: input[0] = (state[0] + 2.4) / 4.8 input[1] = (state[1] + 1.5) / 3.0 input[2] = (state[2] + THIRTY_SIX_DEG_IN_RAD) / (THIRTY_SIX_DEG_IN_RAD * 2.0) input[3] = (state[3] + 2.0) / 4.0 input[4] = (state[4] + THIRTY_SIX_DEG_IN_RAD) / (THIRTY_SIX_DEG_IN_RAD * 2.0)input[5] = (state[5] + 2.0) / 4.0 Список состояний содержит переменные текущего состояния в следующем порядке: 1 1 1 2 2 x, x, , , , θθθθ  .",
          "debug": {
            "start_page": 102,
            "end_page": 108
          }
        },
        {
          "name": "4.7 Целевая функция для эксперимента по балансировке двойного маятника 107",
          "content": "--- Страница 108 --- (продолжение)\n4.7 целевая функция Для экСперимента пО балан СирОвке ДвОйнОгО маятника Целевая функция для этой задачи аналогична целевой функции, определенной ранее для задачи балансировки одиночного маятника и задается следующими уравнениями: 10max eval maxlogt logt,logt .−= =−  . В этих уравнениях tmax – это ожидаемое количество шагов, указанных в конфигурации эксперимента (100 000), и teval – фактическое количество ша- гов, в течение которых контроллер смог поддерживать стабильное состояние балансировщика в допустимых пределах. 4.7 Целевая функция для эксперимента по балансировке двойного маятника  107\n4.7 целевая функция Для экСперимента пО балан СирОвке ДвОйнОгО маятника Целевая функция для этой задачи аналогична целевой функции, определенной ранее для задачи балансировки одиночного маятника и задается следующими уравнениями: 10max eval maxlogt logt,logt .−= =−  . В этих уравнениях tmax – это ожидаемое количество шагов, указанных в конфигурации эксперимента (100 000), и teval – фактическое количество ша- гов, в течение которых контроллер смог поддерживать стабильное состояние балансировщика в допустимых пределах. 4.7 Целевая функция для эксперимента по балансировке двойного маятника  107\n--- Страница 109 ---\nМы используем логарифмические шкалы, потому что большинство испы- таний завешаются неудачей в первые несколько сотен шагов, но мы тести- руем кандидатов на протяжении 100 000 шагов. С логарифмической шкалой мы имеем лучшее распределение показателей приспособленности даже по сравнению с небольшим количеством шагов в неудачных испытаниях. Первое из предыдущих уравнений определяет ошибку, которая находится в диапазоне [0, 1], а второе – это показатель приспособленности, который до- полняет значение ошибки. Таким образом, значения показателя приспособлен- ности находятся в диапазоне [0, 1], и чем выше значение, тем лучше результат. Исходный код Python аналогичен определению целевой функции в экспе- рименте с балансировкой одиночного маятника, но он использует другие вы- зовы симулятора для получения количества шагов балансировки: # Сначала мы запускаем цикл моделирования, возвращающий # количество успешных шагов. steps = cart.run_markov_simulation(net, max_bal_steps) if steps == max_bal_steps: # Максимальная приспособленность. return 1.0elif steps == 0: # Нужно избежать ошибки при попытке взять log(0) # Минимальная приспособленность. return 0.0else: log_steps = math.log(steps) log_max_steps = math.log(max_bal_steps) # Значение ошибки в интервале [0, 1] error = (log_max_steps - log_steps) / log_max_steps # Приспособленность является дополнением значения ошибки return 1.0 - error Здесь мы используем логарифмическую шкалу, потому что большинство прогонов дают сбой слишком рано, в пределах 100 шагов или около того, но мы запускаем моделирование на 100 000 шагов.",
          "debug": {
            "start_page": 108,
            "end_page": 109
          }
        },
        {
          "name": "4.8 Эксперимент по балансировке 108",
          "content": "--- Страница 109 --- (продолжение)\n4.8 экСперимент пО балан СирОвке В этом эксперименте используется версия задачи балансировки двойного ма- ятника, которая предполагает полное знание текущего состояния системы, включая угловые скорости маятников и скорость тележки. Критерием успеха в этом эксперименте является поддержание баланса обоих маятников в тече- ние 100 000 шагов или приблизительно 33 минут условного смоделированного времени. Маятник считается сбалансированным, когда он отклоняется не бо- лее чем на ±36 градусов от вертикали, а тележка остается в пределах ±2,4 метра от центра дорожки. 4.8.1 Выбор гиперпараметров По сравнению с предыдущим экспериментом, описанным в этой главе, задача балансировки двух маятников решается гораздо труднее из-за сложной дина-108  Балансировка тележки с обратным маятником\n4.8 экСперимент пО балан СирОвке В этом эксперименте используется версия задачи балансировки двойного ма- ятника, которая предполагает полное знание текущего состояния системы, включая угловые скорости маятников и скорость тележки. Критерием успеха в этом эксперименте является поддержание баланса обоих маятников в тече- ние 100 000 шагов или приблизительно 33 минут условного смоделированного времени. Маятник считается сбалансированным, когда он отклоняется не бо- лее чем на ±36 градусов от вертикали, а тележка остается в пределах ±2,4 метра от центра дорожки. 4.8.1 Выбор гиперпараметров По сравнению с предыдущим экспериментом, описанным в этой главе, задача балансировки двух маятников решается гораздо труднее из-за сложной дина-108  Балансировка тележки с обратным маятником\n--- Страница 110 ---\nмики движения. Таким образом, пространство поиска для успешной стратегии контроля шире и требует более разнообразной популяции. Чтобы увеличить разнообразие популяции, мы задаем ее размер в 10 раз больше, чем в экспе- рименте с балансировкой одиночного маятника. Пороговое значение приспособленности осталось прежним: [NEAT] fitness_criterion = max fitness_threshold = 1.0 pop_size = 1000 reset_on_extinction = False Чтобы еще больше усилить эволюционное разнообразие, мы увеличиваем вероятность добавления новых узлов и связей, а также меняем схему конфи- гурации исходных связей. Кроме того, значение параметра initial_connection содержит вероятность создания связи, что вносит дополнительную неопре- деленность в процесс формирования графа связей: # Вероятность добавления/удаления связей. conn_add_prob = 0.5 conn_delete_prob = 0.2 initial_connection = partial_direct 0.5# Вероятность добавления/удаления узлов. node_add_prob = 0.2 node_delete_prob = 0.2 Наконец, принимая во внимание размер популяции и возможный раз- мер вида, мы сократили долю особей, которым разрешено размножаться (survival_threshold ). Эта настройка ограничивает пространство поиска ре- шения, позволяя участвовать в процессе рекомбинации только самым под- ходящим организмам: [DefaultReproduction] elitism = 2 survival_threshold = 0.1 min_species_size = 2 Последний параметр противоречив и может снизить эффективность эволюционного процесса в целом. Но с большой популяцией он часто работает хорошо, уменьшая количество возможных рекомбинаций. Таким образом, как правило, большие значения порога выживания используются для небольших популяций, а небольшие значения – для больших популяций. Из-за повышенной сложности этого эксперимента один из гиперпара- метров становится чрезвычайно важным для конечного результата. Про- цесс нейроэволюции строится вокруг вероятности возникновения мутаций, а вероятность мутации зависит от значений, выданных генератором слу- чайных чисел. 4.8 Эксперимент по балансировке  109\n--- Страница 111 ---\nКак вы знаете, в обычных компьютерах нет истинного источника случай- ности. Вместо этого случайность генерируется псевдослучайным алгорит - мом, который сильно зависит от некого начального числа, с которого начи- нается генерирование последовательности случайных чисел. На самом деле начальное значение точно определяет последовательность всех псевдослу - чайных чисел, которые будут выданы данным генератором. Таким образом, мы можем рассматривать начальное число как существен- ный параметр, определяющий начальные условия. Этот параметр устанавли- вает свойства случайного аттрактора, который будет усиливать крошечные изменения в числовом пространстве поиска алгоритма. Эффект усиления в конечном итоге определяет, сможет ли алгоритм найти победителя и сколь- ко времени это займет. Начальное значение генератора случайных чисел определяется в строке с номером 100 файла two_pole_markov_experiment.py : # Начальное значение генератора случайных чисел seed = 1559231616 random.seed(seed) Полный список гиперпараметров, задействованных в эксперименте с двумя маятниками, можно найти в файле two_pole_markov_config.ini . Данный код устанавливает начальное значение стандартного генератора случайных чисел, поставляемого со средой Python. 4.8.2 Настройка рабочей среды Рабочую среду для эксперимента по балансировке двух маятников можно на- строить с помощью следующих команд, введенных в любом выбранном вами приложении терминала: $ conda create --name double_pole_neat python=3.5 $ conda activate double_pole_neat $ pip install neat-python==0.92$ conda install matplotlib$ conda install graphviz $ conda install python-graphviz Эти команды создают и активируют виртуальную среду double_pole_neat с Python 3.5. После этого устанавливается библиотека NEAT-Python версии 0.92, а также другие зависимости, используемые нашими утилитами визуа- лизации. 4.8.3 Реализация эксперимента Исходный код, реализующий оценку приспособленности генома, аналогичен тому, который используется для эксперимента по балансированию одного маятника. Основное отличие состоит в том, что он будет ссылаться на другую среду моделирования, чтобы получить количество сбалансированных шагов. Вы можете обратиться к исходному коду функций eval_fitness(net, max_bal_110  Балансировка тележки с обратным маятником\n--- Страница 112 ---\nsteps=100000) и eval_genomes(genomes, config) в файле two_pole_markov_experiment.py для изучения деталей реализации. В этом эксперименте мы ввели адаптивное обучение, которое попытается найти правильную длину короткого маятника в процессе эволюции. Длина короткого маятника меняет динамику движения системы. Не все комбина- ции гиперпараметров в сочетании с определенной длиной короткого маят - ника могут привести к успешной стратегии управления. В данном случае мы реализуем последовательное увеличение длины короткого маятника, пока не будет найдено решение: # Запуск эксперимента pole_length = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8] num_runs = len(pole_length) for i in range(num_runs): cart.LENGTH_2 = pole_length[i] / 2.0 solved = run_experiment(config_path, n_generations=100, silent=False) print(\"run: %d, solved: %s, length: %f\" % (i + 1, solved, cart.LENGTH_2)) if solved: print(\"Solution found in: %d run, short pole length: %f\" % (i + 1, cart.LENGTH_2)) break Полный код примера доступен для детального ознакомления в файле two_pole_markov_experiment.py . Этот код запускает моделирование с использованием различных значений длины короткого маятника, пока не будет найдено решение. 4.8.4 Запуск эксперимента с двумя маятниками Реализовав симулятор балансировки тележки с двумя маятниками, анализатор приспособленности генома и код движка эксперимента, мы готовы приступить к экспериментам. Войдите в каталог, содержащий файл two_pole_markov_experi- ment.py, и выполните в окне терминала команду $ python two_pole_markov_experiment.py Не забудьте активировать соответствующую виртуальную среду с по- мощью команды conda activate double_pole_neat . Эта команда запустит эволюционный процесс под управлением алгоритма NEAT, используя гиперпараметры, указанные в файле two_pole_markov_config. ini, а также симулятор тележки с двумя маятниками, который мы реализова- ли раньше. Спустя 96 поколений мы можем найти победителя в поколении 97. Вывод в консоль для последнего поколения выглядит примерно так: 4.8 Эксперимент по балансировке  111\n--- Страница 113 ---\n****** Running generation 97 ****** Population's average fitness: 0.27393 stdev: 0.10514 Best fitness: 1.00000 - size: (1, 6) - species 26 - id 95605 Best individual in generation 97 meets fitness threshold - complexity: (1, 6)Best genome: Key: 95605Fitness: 1.0 Nodes: 0 DefaultNodeGene(key=0, bias=7.879760594997953, response=1.0, activation=sigmoid, aggregation=sum) Connections: DefaultConnectionGene(key=(-6, 0), weight=1.9934757746640883,enabled=True) DefaultConnectionGene(key=(-5, 0), weight=3.703109977745863, enabled=True) DefaultConnectionGene(key=(-4, 0), weight=-11.923951805881497, enabled=True) DefaultConnectionGene(key=(-3, 0), weight=-4.152166115226511,enabled=True) DefaultConnectionGene(key=(-2, 0), weight=-3.101569479910728,enabled=True) DefaultConnectionGene(key=(-1, 0), weight=-1.379602358542496, enabled=True) Evaluating the best genome in random runs Runs successful/expected: 1/1SUCCESS: The stable Double-Pole-Markov balancing controller found!!!Random seed: 1559231616run: 1, solved: True, half-length: 0.050000 Solution found in: 1 run, short pole length: 0.100000 В выводе консоли мы видим, что у победившего генома размерность (1, 6), что означает, что у него есть только один нелинейный узел – выход – и пол- ный набор соединений от шести входов до выходных узлов. Мы можем пред- положить, что была найдена минимально возможная конфигурация нейро- сети контроллера, поскольку она не включает в себя никаких скрытых узлов, а вместо этого кодирует поведение контроллера при помощи найденных ве- сов связей. Кроме того, интересно отметить, что решение было найдено для наименьшего значения из списка всех возможных значений длины коротко- го маятника. Конфигурация нейросети контроллера, способного осуществлять страте- гию надежного управления, показана на следующем графе рис. 4.6.112  Балансировка тележки с обратным маятником\n--- Страница 114 ---\nдействие Рис. 4.6. Граф нейросети оптимального балансировщика двух маятников Показатели приспособленности варьируются в зависимости от поколения, как показано на графике (рис. 4.7). Средняя и лучшая приспособленность популяции Поколениясредняя –1 СКО +1 СКО лучшаяПриспособленность Рис. 4.7. Оценка приспособленности по поколениям в эксперименте с двумя маятниками Последний график заслуживает особого внимания, если вы хотите знать, как работает эволюция. Вы можете видеть, что, прежде чем выявить побе- дителя, показатель приспособленности резко падает. Это связано с выми- 4.8 Эксперимент по балансировке  113\n--- Страница 115 ---\nранием стагнирующих видов, которые достигли плато со средневысокими показателями приспособленности, но не показали улучшения за последние 15 поколений. После этого вакантное место занимают свежие виды, наде- ленные генетическими знаниями, унаследованными от вымерших видов. Эти новорожденные виды также вносят полезную мутацию, которая объ- единяет наследственные достижения с новыми уловками и в конечном ито- ге дает победителя. В этом эксперименте мы решили усилить разнообразие видов путем зна- чительного увеличения размера популяции и внесения других изменений в гиперпараметры. На следующем графике вы можете видеть, что мы достиг - ли нашей цели и что процесс нейроэволюции проходит через множество ви- дов, пока не будет найдено решение (рис. 4.8). ПоколенияВидообразованиеРазмер по видам Рис. 4.8. Видовое разнообразие в эксперименте с двумя маятниками Далее мы хотели бы узнать, как изменение начального значения генера- тора случайных чисел влияет на алгоритм NEAT. Для начала мы увеличили значение начального числа только на единицу (все остальное не измени- лось). С этим новым условием алгоритм NEAT все еще смог найти стабиль- ную стратегию управления, но создал другую, причудливую конфигурацию нейросети контроллера (рис. 4.9) вместо оптимальной конфигурации, по- казанной ранее на рис. 4.6.114  Балансировка тележки с обратным маятником\n--- Страница 116 ---\nдействие Рис. 4.9. Нейросеть контроллера балансировки двух маятников после увеличения началь- ного числа на единицу (все остальное не изменяется) Когда значение начального числа генератора случайных чисел увеличили еще больше, например на 10, процесс нейроэволюции вообще не смог найти какое-либо решение задачи балансировки. Этот эксперимент выявил еще один важный аспект методов, основан- ных на нейроэволюции, – влияние начальных условий, определяемых значением начального числа генератора случайных чисел. Случайное начальное число определяет свойства случайного аттрактора, кото-рый усиливает эффекты процесса эволюции, как хорошие, так и пло-хие. Следовательно, в этом эксперименте крайне важно найти подхо-дящее значение начального случайного числа, чтобы успешно пройти процесс нейроэволюции. Мы обсудим методы поиска подходящих значений начальных случайных чисел в конце этой книги.",
          "debug": {
            "start_page": 109,
            "end_page": 116
          }
        },
        {
          "name": "4.9 Упражнения 115",
          "content": "--- Страница 116 --- (продолжение)\n4.9 упражнения 1. Попробуйте установить в файле конфигурации значение параметра node_add = 0.02 и посмотрите, что произойдет. 2. Измените начальное значение генератора случайных чисел и посмот - рите, что произойдет. Было ли найдено решение с новым значением? Чем оно отличается от того, что мы представили в этой главе? 4.9 Упражнения  115\n4.9 упражнения 1. Попробуйте установить в файле конфигурации значение параметра node_add = 0.02 и посмотрите, что произойдет. 2. Измените начальное значение генератора случайных чисел и посмот - рите, что произойдет. Было ли найдено решение с новым значением? Чем оно отличается от того, что мы представили в этой главе? 4.9 Упражнения  115",
          "debug": {
            "start_page": 116,
            "end_page": 116
          }
        },
        {
          "name": "4.10 Заключение 116",
          "content": "--- Страница 117 --- (продолжение)\n4.10 заключение В данной главе вы узнали, как реализовать стратегии управления для контрол- леров, которые могут поддерживать стабильное состояние тележки с одним или двумя обратными маятниками, установленными вертикально. Вы улуч- шили навыки работы с Python и расширили свои знания о библиотеке NEAT- Python, написав точную модель физического устройства, которая использо- валась для определения целевых функций при проведении экспериментов. Кроме того, вы узнали о двух методах численной аппроксимации дифферен- циальных уравнений – Эйлера и Рунге–Кутты и реализовали их в Python. Мы обнаружили, что начальные условия, которые определяют нейроэво- люционный процесс, такие как начальное случайное число, оказывают зна- чительное влияние на результативность алгоритма. Эти значения опреде- ляют всю последовательность числового ряда, который будет сгенерирован генератором случайных чисел. Они служат случайным аттрактором, который может усиливать или ослаблять эффекты эволюции. В следующей главе мы обсудим, как использовать нейроэволюцию для соз- дания агентов-навигаторов, способных проходить через лабиринт. Вы узнаете, как определить целевую функцию для решения задачи прохождения лабирин- та и как написать точную симуляцию робота-агента, который может переме- щаться по лабиринту. Мы рассмотрим два типа лабиринтов и продемонстри- руем, как может оплошать целенаправленная функция приспособленности, которая пытается найти решение в обманчивой среде сложного лабиринта.116  Балансировка тележки с обратным маятником\n4.10 заключение В данной главе вы узнали, как реализовать стратегии управления для контрол- леров, которые могут поддерживать стабильное состояние тележки с одним или двумя обратными маятниками, установленными вертикально. Вы улуч- шили навыки работы с Python и расширили свои знания о библиотеке NEAT- Python, написав точную модель физического устройства, которая использо- валась для определения целевых функций при проведении экспериментов. Кроме того, вы узнали о двух методах численной аппроксимации дифферен- циальных уравнений – Эйлера и Рунге–Кутты и реализовали их в Python. Мы обнаружили, что начальные условия, которые определяют нейроэво- люционный процесс, такие как начальное случайное число, оказывают зна- чительное влияние на результативность алгоритма. Эти значения опреде- ляют всю последовательность числового ряда, который будет сгенерирован генератором случайных чисел. Они служат случайным аттрактором, который может усиливать или ослаблять эффекты эволюции. В следующей главе мы обсудим, как использовать нейроэволюцию для соз- дания агентов-навигаторов, способных проходить через лабиринт. Вы узнаете, как определить целевую функцию для решения задачи прохождения лабирин- та и как написать точную симуляцию робота-агента, который может переме- щаться по лабиринту. Мы рассмотрим два типа лабиринтов и продемонстри- руем, как может оплошать целенаправленная функция приспособленности, которая пытается найти решение в обманчивой среде сложного лабиринта.116  Балансировка тележки с обратным маятником",
          "debug": {
            "start_page": 117,
            "end_page": 117
          }
        }
      ]
    },
    {
      "name": "Глава 5. Автономное прохождение лабиринта 117",
      "chapters": [
        {
          "name": "5.1 Технические требования 117",
          "content": "--- Страница 118 --- (продолжение)\nГлава 5 Автономное прохождение лабиринта Автономное прохождение лабиринта является классической задачей ин- форматики, относящейся к области автономной навигации. В этой главе вы узнаете, как можно использовать методы нейроэволюции для решения за- дач прохождения лабиринта. Также мы объясним, как определить функцию приспособленности с использованием оценки приспособленности агента- навигатора, рассчитанной как производная от расстояния агента до конеч- ной цели. К концу главы вы усвоите основы обучения автономного нави- гационного агента с использованием методов нейроэволюции и сможете создать более продвинутый решатель лабиринтов, который будет представ- лен в следующей главе. Вы познакомитесь с новыми методами визуали- зации, которые облегчат понимание результатов выполнения алгоритма. Кроме того, получите практический опыт написания симуляторов роботов, способных ориентироваться в лабиринте, и связанных с ними сред лаби- ринта на языке Python. В этой главе вы познакомитесь со следующими темами: обманчивый характер проблемы навигации в лабиринте; написание симулятора робота-решателя лабиринта, оснащенного мас - сивом датчиков и исполнительных механизмов; определение целеориентированной функции приспособленности для управления обучением решателя лабиринта на основе нейроэволюции; проведение экспериментов с простыми и сложными конфигурациями лабиринта. 5.1 техниче Ские треб Ования Для проведения экспериментов, описанных в этой главе, ваш компьютер должен удовлетворять следующим техническим требованиям: Windows 8/10, macOS 10.13 или новее, или современный Linux; Anaconda Distribution версия 2019.03 или новее. Исходный код примеров этой главы можно найти в каталоге Chapter5 в фай- ловом архиве книги.\n5.1 техниче Ские треб Ования Для проведения экспериментов, описанных в этой главе, ваш компьютер должен удовлетворять следующим техническим требованиям: Windows 8/10, macOS 10.13 или новее, или современный Linux; Anaconda Distribution версия 2019.03 или новее. Исходный код примеров этой главы можно найти в каталоге Chapter5 в фай- ловом архиве книги.",
          "debug": {
            "start_page": 118,
            "end_page": 118
          }
        },
        {
          "name": "5.2 Задача навигации в лабиринте 118",
          "content": "--- Страница 119 --- (продолжение)\n5.2 заДача навигации в лабиринте Задача прохождения лабиринта является классической проблемой инфор- матики, которая тесно связана с созданием автономных агентов навигации, способных найти путь в неоднозначных средах. Окружающая среда в виде ла- биринта – классическая иллюстрация целого класса проблем, которые имеют обманчивый ландшафт приспособленности. Это означает, что целеориентиро- ванная функция приспособленности (goal-oriented fitness function) может иметь крутые градиенты показателей приспособленности в тупиках лабиринта, ко- торые близки к конечной цели. Такие области лабиринта становятся локаль- ными оптимумами для алгоритмов поиска на основе близости к цели, которые могут сходиться в этих областях. Когда алгоритм поиска застревает в таком обманчивом локальном оптимуме, он не может найти адекватного агента, способного пройти лабиринт. На рис. 5.1 изображен двухмерный лабиринт, в котором затемнены локаль- но оптимальные тупики. Рис. 5.1. Двухмерный лабиринт с локально оптимальными тупиками (затемнены) Конфигурация лабиринта на этом рисунке демонстрирует ландшафт об- манчивых показателей приспособленности, сосредоточенных в локально оптимальных тупиках (помеченных как закрашенные сегменты). Агент- решатель лабиринта, перемещающийся от начальной точки (нижний круг) к точке выхода (верхний круг) и обученный на основе критерия близости к цели, будет склонен застревать в локальных тупиках. Кроме того, подоб- ная обманчивая оценка приспособленности может воспрепятствовать ал- горитму обучения на основе близости к цели найти успешный решатель лабиринтов.118  Автономное прохождение лабиринта\n5.2 заДача навигации в лабиринте Задача прохождения лабиринта является классической проблемой инфор- матики, которая тесно связана с созданием автономных агентов навигации, способных найти путь в неоднозначных средах. Окружающая среда в виде ла- биринта – классическая иллюстрация целого класса проблем, которые имеют обманчивый ландшафт приспособленности. Это означает, что целеориентиро- ванная функция приспособленности (goal-oriented fitness function) может иметь крутые градиенты показателей приспособленности в тупиках лабиринта, ко- торые близки к конечной цели. Такие области лабиринта становятся локаль- ными оптимумами для алгоритмов поиска на основе близости к цели, которые могут сходиться в этих областях. Когда алгоритм поиска застревает в таком обманчивом локальном оптимуме, он не может найти адекватного агента, способного пройти лабиринт. На рис. 5.1 изображен двухмерный лабиринт, в котором затемнены локаль- но оптимальные тупики. Рис. 5.1. Двухмерный лабиринт с локально оптимальными тупиками (затемнены) Конфигурация лабиринта на этом рисунке демонстрирует ландшафт об- манчивых показателей приспособленности, сосредоточенных в локально оптимальных тупиках (помеченных как закрашенные сегменты). Агент- решатель лабиринта, перемещающийся от начальной точки (нижний круг) к точке выхода (верхний круг) и обученный на основе критерия близости к цели, будет склонен застревать в локальных тупиках. Кроме того, подоб- ная обманчивая оценка приспособленности может воспрепятствовать ал- горитму обучения на основе близости к цели найти успешный решатель лабиринтов.118  Автономное прохождение лабиринта\n--- Страница 120 ---\nАгент, перемещающийся по лабиринту, представляет собой робота, обо- рудованного набором датчиков, позволяющих ему обнаруживать близ- лежащие препятствия и определять направление к выходу из лабиринта. Перемещение робота осуществляется двумя приводами, влияющими на ли- нейное и угловое движение корпуса робота. Приводы робота управляются нейросетью, которая получает данные от датчиков и выдает два управляю- щих сигнала на приводы.",
          "debug": {
            "start_page": 119,
            "end_page": 120
          }
        },
        {
          "name": "5.3 Среда моделирования лабиринта 119",
          "content": "--- Страница 120 --- (продолжение)\n5.3 С реДа мОДелир Ования лабиринта Среда моделирования лабиринта состоит из трех основных компонентов, ко- торые реализованы в виде отдельных классов Python: Agent – класс, который хранит информацию, связанную с агентом на- вигатора лабиринта, задействованного в симуляции (см. подробности реализации в файле agent.py); AgentRecordStore – класс, который управляет хранением записей, от- носящихся к оценкам всех решающих агентов в ходе эволюционного процесса. Собранные записи можно использовать для анализа эволю- ционного процесса после его завершения (см. подробности реализации в файле agent.py); MazeEnvironment – класс, который содержит информацию о среде модели- рования лабиринта. Этот класс также предоставляет методы, которые управляют средой моделирования, управляют положением решающего агента, выполняют обнаружение столкновений и генерируют входные данные для датчиков агента (см. подробности реализации в файле maze_ environment.py ). В следующих разделах мы рассмотрим каждый компонент среды модели- рования лабиринта более подробно. 5.3.1 Агент-решатель лабиринта В этой главе мы рассмотрим задачу прохождения двухмерного лабиринта. Эту задачу легко визуализировать, и относительно легко написать симуля- тор робота-навигатора для двухмерного лабиринта. Основная цель робота – пройти по лабиринту к определенной цели за указанное количество шагов симуляции. Роботом управляет нейросеть, которая развивается в процессе нейроэволюции. Алгоритм нейроэволюции начинается с очень простой начальной конфи- гурации нейросети, которая имеет только входные узлы для датчиков и вы- ходные узлы для приводов и постепенно становится все более сложной, пока не будет найден успешный решатель лабиринтов. Эта задача усложняется особой конфигурацией лабиринта, в которой есть несколько тупиков, ме- шающих найти путь к цели и заманивающих агента в локальные оптимумы ландшафта приспособленности, как упоминалось ранее. На рис. 5.2 представлено схематическое изображение агента-решателя, выполненного в виде робота и задействованного в моделировании решения задачи лабиринта. 5.3 Среда моделирования лабиринта  119\n5.3 С реДа мОДелир Ования лабиринта Среда моделирования лабиринта состоит из трех основных компонентов, ко- торые реализованы в виде отдельных классов Python: Agent – класс, который хранит информацию, связанную с агентом на- вигатора лабиринта, задействованного в симуляции (см. подробности реализации в файле agent.py); AgentRecordStore – класс, который управляет хранением записей, от- носящихся к оценкам всех решающих агентов в ходе эволюционного процесса. Собранные записи можно использовать для анализа эволю- ционного процесса после его завершения (см. подробности реализации в файле agent.py); MazeEnvironment – класс, который содержит информацию о среде модели- рования лабиринта. Этот класс также предоставляет методы, которые управляют средой моделирования, управляют положением решающего агента, выполняют обнаружение столкновений и генерируют входные данные для датчиков агента (см. подробности реализации в файле maze_ environment.py ). В следующих разделах мы рассмотрим каждый компонент среды модели- рования лабиринта более подробно. 5.3.1 Агент-решатель лабиринта В этой главе мы рассмотрим задачу прохождения двухмерного лабиринта. Эту задачу легко визуализировать, и относительно легко написать симуля- тор робота-навигатора для двухмерного лабиринта. Основная цель робота – пройти по лабиринту к определенной цели за указанное количество шагов симуляции. Роботом управляет нейросеть, которая развивается в процессе нейроэволюции. Алгоритм нейроэволюции начинается с очень простой начальной конфи- гурации нейросети, которая имеет только входные узлы для датчиков и вы- ходные узлы для приводов и постепенно становится все более сложной, пока не будет найден успешный решатель лабиринтов. Эта задача усложняется особой конфигурацией лабиринта, в которой есть несколько тупиков, ме- шающих найти путь к цели и заманивающих агента в локальные оптимумы ландшафта приспособленности, как упоминалось ранее. На рис. 5.2 представлено схематическое изображение агента-решателя, выполненного в виде робота и задействованного в моделировании решения задачи лабиринта. 5.3 Среда моделирования лабиринта  119\n--- Страница 121 ---\nРис. 5.2. Схематическое изображение навигационного агента На этой схеме закрашенный круг обозначает твердый корпус робота. Стрел- ка внутри закрашенного круга показывает направление движения робота. Шесть стрелок вокруг закрашенного круга представляют шесть дальномер- ных датчиков, которые указывают расстояние до ближайшего препятствия в заданном направлении. Четыре сегмента внешнего круга обозначают че- тыре радарных датчика с секторным обзором, которые действуют как ком- пас, указывающий направление к цели (выходу из лабиринта). Специальный радарный датчик активируется, когда линия от точки цели до центра робота попадает в его поле обзора (field of view, FOV). Дальность обнаружения радарного датчика ограничена областью лабиринта, которая попадает в его поле зрения. Таким образом, в любой момент времени ак- тивирован один из четырех радарных датчиков, указывающий направление выхода из лабиринта. Радарные датчики имеют следующие зоны обзора относительно курса ро- бота: Датчик Поле обзора, градусы Передний 315,0 ~ 405,0 Левый 45,0 ~ 135,0 Задний 135,0 ~ 225,0 Правый 225,0 ~ 315,0 Дальномерный датчик – это следящий луч, направленный от центра робота в определенном направлении. Активируется при пересечении с любым пре- пятствием и возвращает расстояние до обнаруженного препятствия. Даль- ность обнаружения этого датчика определяется конкретным параметром конфигурации. Дальномерные датчики робота отслеживают следующие направления от- носительно направления движения:120  Автономное прохождение лабиринта\n--- Страница 122 ---\nДатчик Направление, градусы Правый –90,0 Передний правый –45,0 Передний 0,0 Передний левый 45,0 Левый 90,0 Задний –180,0 Движение робота контролируется двумя приводами, прикладывающими силы, которые поворачивают и/или приводят в движение корпус робота, то есть изменяют его линейную и/или угловую скорость. В реализации робота-навигатора на языке Python есть несколько полей для хранения его текущего состояния и для поддержания состояний активности его датчиков: def __init__(self, location, heading=0, speed=0, angular_vel=0, radius=8.0, range_finder_range=100.0): self.heading = heading self.speed = speed self.angular_vel = angular_vel self.radius = radius self.range_finder_range = range_finder_range self.location = location # Определяем датчики дальномера. self.range_finder_angles = [-90.0, -45.0, 0.0, 45.0, 90.0, -180.0] # Определяем радарные датчики self.radar_angles = [(315.0, 405.0), (45.0, 135.0), (135.0, 225.0), (225.0, 315.0)] # Список состояний активности дальномеров self.range_finders = [None] * len(self.range_finder_angles) # Список состояний активности секторных радаров. self.radar = [None] * len(self.radar_angles) Для изучения подробностей реализации кода рассмотрите файл agent.py в файловом архиве книги. В предыдущем блоке кода показан конструктор по умолчанию класса Agent, в котором инициализированы все поля агента. Симулятор среды лабиринта будет использовать эти поля для хранения текущего состояния агента на каж- дом шаге симуляции. 5.3.2 Реализация среды моделирования лабиринта Чтобы смоделировать поведение решающего агента, исследующего лаби- ринт, нам нужно определить среду, которая управляет конфигурацией лаби- ринта, отслеживает положение агента, исследующего лабиринт, и обеспечи- вает входные данные для массивов данных датчика навигационного робота. 5.3 Среда моделирования лабиринта  121\n--- Страница 123 ---\nВсе эти функции помещаются в один логический блок, который инкапсу - лирован в класс Python MazeEnvironment , имеющий следующие поля: def __init__(self, agent, walls, exit_point, exit_range=5.0): self.walls = walls self.exit_point = exit_point self.exit_range = exit_range # Агент-решатель лабиринта. self.agent = agent # Флаг индикации о том, что выход найден. self.exit_found = False # Начальное расстояние от агента до выхода. self.initial_distance = self.agent_distance_to_exit() В предыдущем коде показан конструктор по умолчанию класса MazeEnviron- ment с инициализацией всех его полей: конфигурация лабиринта определяется списком стен и точки выхо- да. Стены – это списки отрезков; каждый отрезок линии представляет определенную стену в лабиринте, а точка выхода exit_point – это место- положение выхода из лабиринта; в поле exit_range хранится значение расстояния до точки выхода, опре- деляющее зону выхода. Мы считаем, что агент успешно прошел лаби- ринт, когда его позиция находится в зоне выхода; поле agent содержит ссылку на инициализированный класс агента, опи- санный в предыдущем разделе, который определяет начальное место- положение агента в лабиринте и прочие поля агента; поле initial_distance хранит расстояние от начальной позиции агента до точки выхода из лабиринта. Это значение будет позже использовано для расчета показателя приспособленности агента. Генерация данных датчиков Агент, проходящий лабиринт, управляется нейросетью, которой необходимо иметь данные датчиков на входе для формирования соответствующих управ- ляющих сигналов на выходе. Как мы уже упоминали, робот-навигатор осна- щен массивом датчиков двух типов: шесть дальномерных датчиков для предотвращения столкновений со стенами лабиринта, которые показывают расстояние до ближайшего препятствия в определенном направлении; четыре секторных радарных датчика, которые указывают направление к точке выхода из лабиринта из любого места в лабиринте. Показания датчиков необходимо обновлять на каждом шаге моделирова- ния, а класс MazeEnvironment предоставляет два ссылочных метода, которые об- новляют датчики обоих типов. Массив дальномерных датчиков обновляется следующим образом (см. функцию update_rangefinder_sensors ): for i, angle in enumerate(self.agent.range_finder_angles): rad = geometry.deg_to_rad(angle) projection_point = geometry.Point(122  Автономное прохождение лабиринта\n--- Страница 124 ---\nx = self.agent.location.x + math.cos(rad) * \\ self.agent.range_finder_range, y = self.agent.location.y + math.sin(rad) * \\ self.agent.range_finder_range ) projection_point.rotate(self.agent.heading, self.agent.location) projection_line = geometry.Line(a = self.agent.location, b = projection_point) min_range = self.agent.range_finder_range for wall in self.walls: found, intersection = wall.intersection(projection_line) if found: found_range = intersection.distance( self.agent.location) if found_range < min_range: min_range = found_range # Сохраняем расстояние до ближайшего препятствия. self.agent.range_finders[i] = min_range Этот код перечисляет все направления дальномерных датчиков, которые определяются углами направления (см. инициализацию поля range_finder_an- gles в конструкторе класса Agent). Затем для каждого направления выстраива- ется линия проекции, начиная с текущей позиции робота и с длиной, равной дальности обнаружения дальномера. После этого линия проверяется на пред- мет того, пересекает ли она стены лабиринта. Если обнаружено несколько пересечений, расстояние до ближайшей стены сохраняется как текущее зна- чение для конкретного дальномера. В противном случае в качестве текущего значения будет сохранена величина максимальной дальности обнаружения. Массив секторных радарных датчиков обновляется при помощи кода в классе MazeEnvironment : def update_radars(self): target = geometry.Point(self.exit_point.x, self.exit_point.y) target.rotate(self.agent.heading, self.agent.location) target.x -= self.agent.location.x target.y -= self.agent.location.y angle = target.angle() for i, r_angles in enumerate(self.agent.radar_angles): self.agent.radar[i] = 0.0 # reset specific radar if (angle >= r_angles[0] and angle < r_angles[1]) or (angle + 360 >= r_angles[0] and angle + 360 < r_angles[1]): # Запуск радара. self.agent.radar[i] = 1.0 Этот код создает копию точки выхода из лабиринта и поворачивает ее от- носительно курса и положения агента в глобальной системе координат. Затем целевая точка транслируется в локальную систему координат агента, иссле- дующего лабиринт; агент находится в начале координат. После этого мы вы- числяем угол вектора, образованного от начала координат до целевой точки 5.3 Среда моделирования лабиринта  123\n--- Страница 125 ---\nв локальной системе координат агента. Этот угол является азимутом к точке выхода из лабиринта из текущей позиции агента. Когда азимутальный угол найден, мы перечисляем зарегистрированные радарные датчики, чтобы най- ти тот, у которого текущий азимутальный угол попадает в поле зрения. Соот - ветствующий радарный датчик активируется путем установки его значения в 1, в то время как другие радарные датчики деактивируются путем обнуле- ния их значений. Обновление позиции агента Положение агента в лабиринте необходимо обновлять на каждом этапе моде- лирования после получения соответствующих сигналов управления от ней- росети контроллера. Для обновления позиции агента выполняется следую- щий код: def update(self, control_signals): if self.exit_found: return True # Maze exit already found self.apply_control_signals(control_signals) vx = math.cos(geometry.deg_to_rad(self.agent.heading)) * \\ self.agent.speed vy = math.sin(geometry.deg_to_rad(self.agent.heading)) * \\ self.agent.speed self.agent.heading += self.agent.angular_vel if self.agent.heading > 360: self.agent.heading -= 360 elif self.agent.heading < 0: self.agent.heading += 360 new_loc = geometry.Point( x = self.agent.location.x + vx, y = self.agent.location.y + vy ) if not self.test_wall_collision(new_loc): self.agent.location = new_loc self.update_rangefinder_sensors() self.update_radars() distance = self.agent_distance_to_exit() self.exit_found = (distance < self.exit_range) return self.exit_found Функция update(self, control_signals) определена в классе MazeEnvironment и вызывается на каждом шаге моделирования. Она получает список с управ- ляющими сигналами в качестве входных данных и возвращает логическое значение, указывающее, достиг ли агент зоны выхода после обновления сво- ей позиции. Код в начале этой функции применяет полученные управляющие сигналы к текущим значениям угловой и линейной скоростей агента следующим об- разом (см. функцию apply_control_signals(self, control_signals) ): self.agent.angular_vel += (control_signals[0] - 0.5) self.agent.speed += (control_signals[1] - 0.5)124  Автономное прохождение лабиринта\n--- Страница 126 ---\nЗатем вычисляются компоненты скорости x и y вместе с направлением условной «передней части» агента и используются для оценки его нового положения в лабиринте. Если эта новая позиция не сталкивается ни с од- ной из стен лабиринта, то она назначается агенту и становится его текущей позицией: vx = math.cos(geometry.deg_to_rad(self.agent.heading)) * \\ self.agent.speed vy = math.sin(geometry.deg_to_rad(self.agent.heading)) * \\ self.agent.speed self.agent.heading += self.agent.angular_vel if self.agent.heading > 360: self.agent.heading -= 360elif self.agent.heading < 0: self.agent.heading += 360new_loc = geometry.Point( x = self.agent.location.x + vx, y = self.agent.location.y + vy ) if not self.test_wall_collision(new_loc): self.agent.location = new_loc Далее новая позиция агента используется в функциях, которые обновляют дальномерные и радарные датчики, получая значения новых входов датчи- ков для следующего временного шага: self.update_rangefinder_sensors() self.update_radars() Наконец, следующая функция проверяет, достиг ли агент выхода из лаби- ринта, который определяется круглой областью вокруг точки выхода с радиу- сом, равным значению поля exit_range : distance = self.agent_distance_to_exit()self.exit_found = (distance < self.exit_range) return self.exit_found Если выход из лабиринта был достигнут, значение поля exit_found устанав- ливается равным True, чтобы сообщить об успешном решении задачи, и это значение возвращается из вызова функции. Для подробного изучения деталей реализации обратитесь к файлу maze_environment.py в файловом архиве книги. 5.3.3 Хранение записей агента После завершения эксперимента нам понадобится оценка и визуализация того, как каждый отдельный решающий агент работал в течение эволюцион- ного процесса на протяжении всех поколений. Для этого мы собираем допол- нительные статистические данные о каждом агенте после запуска модели про- хождения лабиринта в течение определенного количества временных шагов. 5.3 Среда моделирования лабиринта  125\n--- Страница 127 ---\nКоллекция записей агента опосредуется двумя классами Python: AgentRecord и AgentRecordStore . Класс AgentRecord состоит из нескольких полей данных, как видно из кон- структора класса: def __init__(self, generation, agent_id): self.generation = generation self.agent_id = agent_id self.x = -1 self.y = -1 self.fitness = -1 self.hit_exit = False self.species_id = -1 self.species_age = -1 Поля имеют следующее назначение: generation содержит идентификатор поколения, когда была создана запись агента; agent_id – уникальный идентификатор агента; x и y – позиция агента в лабиринте после завершения симуляции; fitness – итоговая оценка приспособленности агента; hit_exit – это флаг, который указывает, достиг ли агент области выхода из лабиринта; species_id и species_age – идентификатор и возраст вида, к которому от- носится агент. Класс AgentRecordStore содержит список записей агента и предоставляет функции для сохранения собранных записей в определенный файл и чтения из него. Для изучения деталей реализации рассмотрите файл agent.py из файлового архива книги. Новые экземпляры AgentRecord добавляются в хранилище после оценки приспособленности генома, при помощи функции eval_fitness(genome_id, ge- nome, config, time_steps=400) , реализованной в файле maze_experiment.py . Это де- лается с помощью следующего кода: def eval_fitness(genome_id, genome, config, time_steps=400): maze_env = copy.deepcopy(trialSim.orig_maze_environment) control_net = neat.nn.FeedForwardNetwork.create(genome, config) fitness = maze.maze_simulation_evaluate( env=maze_env, net=control_net, time_steps=time_steps) record = agent.AgentRecord( generation=trialSim.population.generation, agent_id=genome_id) record.fitness = fitness record.x = maze_env.agent.location.x record.y = maze_env.agent.location.y record.hit_exit = maze_env.exit_found 126  Автономное прохождение лабиринта\n--- Страница 128 ---\nrecord.species_id = trialSim.population.species.\\ get_species_id(genome_id) record.species_age = record.generation - \\ trialSim.population.species.get_species(genome_id).created trialSim.record_store.add_record(record) return fitness Этот код сначала создает полную копию исходной среды лабиринта, что- бы избежать взаимного влияния между оценочными прогонами. После этого он создает контрольную нейросеть из заданного генома, используя конфи- гурацию, предоставленную NEAT, и начинает оценочное моделирование ла- биринта для заданного количества временных шагов. Возвращенная оценка приспособленности агента вместе с другой статистикой затем сохраняется в конкретном экземпляре AgentRecord и добавляется в хранилище записей. Записи, собранные во время одной пробной версии эксперимента, будут сохранены в файле data.pickle в каталоге output и использованы для визуали- зации работоспособности всех оцененных агентов. Для изучения деталей реализации рассмотрите файл maze_experi- ment.py в файловом архиве книги. 5.3.4 Визуализация записей агента После того как в ходе нейроэволюционного процесса будут собраны все оце- ночные записи всех агентов, нам будет полезно визуализировать записанные данные, чтобы получить представление о положении дел в нашей эволюции. Ви- зуализация должна включать конечные позиции всех решающих агентов и по- зволять устанавливать пороговое значение приспособленности вида для контро- ля за тем, какие виды будут добавлены к соответствующему участку. Мы решили представить собранные записи агентов на двух графиках, нарисованных один над другим. Верхний график предназначен для записей агентов, которые от- носятся к видам, у которых показатель приспособленности больше или равен указанному пороговому значению, а нижний график – для остальных записей. Визуализация записей агента реализована в новых методах в скрипте vi- sualize.py . Вы уже должны быть знакомы с этим скриптом по предыдущим экспериментам, описанным в этой книге. Рассмотрите определение функции draw_maze_records(maze_env, re- cords, best_threshold=0.8, filename=None, view=False, show_axes=False, width=400, height=400) в файле visualize.py в файловом архиве книги.",
          "debug": {
            "start_page": 120,
            "end_page": 128
          }
        },
        {
          "name": "5.4 Определение целевой функции с использованием показателя приспособленности 127",
          "content": "--- Страница 128 --- (продолжение)\n5.4 О преДеление целев Ой функции С иСпОльзОванием пОказателя при СпОСО бленн ОСти В этом разделе вы узнаете о создании успешных агентов, которые проходят лабиринт, используя целеориентированную целевую функцию (goal-oriented ob- jective function) для руководства эволюционным процессом. Целевая функция 5.4 Определение целевой функции с использованием показателя  127\n5.4 О преДеление целев Ой функции С иСпОльзОванием пОказателя при СпОСО бленн ОСти В этом разделе вы узнаете о создании успешных агентов, которые проходят лабиринт, используя целеориентированную целевую функцию (goal-oriented ob- jective function) для руководства эволюционным процессом. Целевая функция 5.4 Определение целевой функции с использованием показателя  127\n--- Страница 129 ---\nэтого типа основана на оценке показателя приспособленности решателя лаби- ринта путем измерения расстояния между его конечным положением и целью (выходом из лабиринта) после выполнения 400 этапов моделирования. Иными словами, целенаправленная целевая функция ориентирована на конкретную цель и зависит исключительно от конечной цели эксперимента – достижения области выхода из лабиринта. В следующей главе мы рассмотрим другой подход к оптимизации поиска решения, который основан на методе оптимизации поиском новизны ( novelty search, NS). Метод оптимизации поиском новизны основан на изучении но- вых конфигураций решающего агента в процессе эволюции и не включает определение конечной цели (в данном случае выхода из лабиринта) в опре- деление целевой функции. Мы покажем, что подход поиска новизны может превзойти традиционную целенаправленную целевую функцию, которую мы используем в этой главе. Целенаправленная целевая функция, задействованная в этом эксперимен- те, определяется следующим образом. Во-первых, нам нужно определить функцию ошибки как евклидово расстояние между конечной позицией аген- та в конце симуляции и позицией выхода из лабиринта: ()22 1i i ia b . ==−∑ Здесь L – функция ошибки, a – координаты конечной позиции агента и b – координаты выхода из лабиринта. В этом эксперименте мы используем дву- мерный лабиринт, поэтому у координат есть два значения, по одному для каждого измерения. Имея функцию ошибки, мы можем определить функцию приспособленности: 10 exit n. LR остальные≤= . Здесь Rexit – радиус зоны выхода вокруг точки выхода из лабиринта, а Fn – нор- мализованный показатель приспособленности, который определяется следу - ющим образом: init n initD.D−= Dinit – это начальное расстояние от решающего агента до выхода из лабиринта в начале навигационного моделирования. Уравнение нормализует показатель приспособленности, чтобы он распо- лагался в диапазоне (0, 1], но может вернуть отрицательные значения в тех редких случаях, когда конечная позиция агента находится далеко и от его на- чальной позиции, и от выхода из лабиринта. Чтобы избежать отрицательных значений, мы будем применять к нормализованному показателю приспособ- ленности следующие поправки:128  Автономное прохождение лабиринта\n--- Страница 130 ---\n001 0 n n n, . остальное≤ =  Когда показатель приспособленности меньше или равен 0 , ему будет при- своено минимальное поддерживаемое значение 0,01; в противном случае он останется как есть. Мы выбрали минимальный показатель приспособленно- сти выше нуля, чтобы дать каждому геному шанс на размножение. Следующий код в Python реализует целенаправленную целевую функцию: # Вычисляем показатель приспособленности на основе расстояния до выхода. fitness = env.agent_distance_to_exit() if fitness <= self.exit_range: fitness = 1.0 else: # Нормализуем показатель приспособленности к интервалу (0,1]. fitness = (env.initial_distance - fitness) / \\ env.initial_distance if fitness <= 0.01: fitness = 0.01 Сначала код вызывает функцию agent_distance_to_exit() , которая вычисля- ет евклидово расстояние от текущей позиции агента до выхода из лабиринта и использует полученное значение в качестве первого приближения оценки приспособленности. После этого оценка приспособленности (расстояние до выхода из лабиринта) сравнивается со значением диапазона выхода. Если оценка приспособленности меньше или равна значению self.exit_range , мы присваиваем ей окончательное значение 1.0. В противном случае норма- лизованный показатель приспособленности рассчитывается путем деления разницы между конечным и начальным расстояниями от агента до выхода из лабиринта на начальное расстояние. Иногда это может привести к отри- цательному значению нормализованного значения приспособленности, ко- торое корректируется путем сравнения значения приспособленности с 0.01 и внесения необходимых поправок. С деталями реализации можно ознакомиться в файле maze_environ- ment.py .",
          "debug": {
            "start_page": 128,
            "end_page": 130
          }
        },
        {
          "name": "5.5 Проведение эксперимента с простой конфигурацией лабиринта 129",
          "content": "--- Страница 130 --- (продолжение)\n5.5 прОвеДение экСперимента С прОСтОй кОнфигурацией лабиринта Итак, мы начинаем наш эксперимент по созданию успешного агента навига- ции, который исследует простую конфигурацию лабиринта. Подобная конфи- гурация лабиринта, несмотря на упомянутые ранее обманчивые локальные ту- пики оптимальности, подразумевает относительно прямой путь от начальной точки к конечной точке. 5.5 Проведение эксперимента с простой конфигурацией лабиринта  129\n5.5 прОвеДение экСперимента С прОСтОй кОнфигурацией лабиринта Итак, мы начинаем наш эксперимент по созданию успешного агента навига- ции, который исследует простую конфигурацию лабиринта. Подобная конфи- гурация лабиринта, несмотря на упомянутые ранее обманчивые локальные ту- пики оптимальности, подразумевает относительно прямой путь от начальной точки к конечной точке. 5.5 Проведение эксперимента с простой конфигурацией лабиринта  129\n--- Страница 131 ---\nНа рис. 5.3 изображена конфигурация простого лабиринта, задействован- ного в текущем эксперименте. Рис. 5.3. Конфигурация простого лабиринта Лабиринт имеет две фиксированные позиции, отмеченные закрашенны- ми кружками. Верхний левый кружок обозначает начальную позицию агента (решателя лабиринта). Нижний правый кружок отмечает точное местополо- жение выхода из лабиринта, который должен быть найден решателем. Задача решателя лабиринта – добраться до окрестности точки выхода из лабиринта, то есть оказаться достаточно близко от нее, в пределах расстояния, заданного в конфигурации. 5.5.1 Выбор гиперпараметров Согласно определению целевой функции, максимальное значение пока- зателя приспособленности агента, которое может быть получено при дости- жении заданной окрестности выхода из лабиринта, составляет 1.0. Мы также ожидаем, что начальная конфигурация нейросети контроллера является бо- лее сложной, чем в предыдущих экспериментах, описанных ранее в книге, и это повлияет на скорость выполнения алгоритма. Из-за этого на среднем ПК потребуется слишком много времени, чтобы завершить алгоритм ней- роэволюции с заметно большей популяцией генома. Но в то же время стоя- щая перед нами задача намного сложнее, чем в предыдущих экспериментах, и для успешного поиска решения необходимо использовать более широкую область поиска. Методом проб и ошибок мы обнаружили, что численность популяции может быть задана равной 250. Следующий раздел файла конфигурации содержит определение парамет- ров, которые мы только что обсудили: [NEAT] fitness_criterion = max fitness_threshold = 1.0 pop_size = 250 reset_on_extinction = False Начальная конфигурация фенотипа нейросети включает 10 входных уз- лов, 2 выходных узла и 1 скрытый узел. Узлы входа и выхода соответствуют входным датчикам и выходам управляющего сигнала. Скрытый узел пред-130  Автономное прохождение лабиринта\n--- Страница 132 ---\nназначен для введения нелинейности с самого начала нейроэволюционного процесса и экономии времени эволюции на добавление этого узла. Конфигу - рация нейросети выглядит следующим образом: num_hidden = 1 num_inputs = 10 num_outputs = 2 Для расширения области поиска решений нам нужно увеличить видовое разнообразие популяции, чтобы попробовать разные конфигурации генома в течение ограниченного числа поколений. Это может быть сделано либо пу- тем уменьшения порога совместимости, либо путем увеличения значений коэффициентов, которые используются для расчета показателей совмести- мости генома. В этом эксперименте мы использовали обе поправки, потому что ланд- шафт функции приспособленности обманчив и нам нужно подчеркнуть даже крошечные изменения в конфигурации генома, чтобы создать новые виды. На это влияют следующие параметры конфигурации: [NEAT] compatibility_disjoint_coefficient = 1.1 [DefaultSpeciesSet] compatibility_threshold = 3.0 Мы особенно заинтересованы в создании оптимальной конфигурации нейросети, которая имеет минимальное количество скрытых узлов и связей. Оптимальная конфигурация менее затратна в вычислительном отношении во время обучения нейроэволюционным методом, а также во время фазы вывода в симуляторе прохождения лабиринта. Оптимальную конфигурацию нейросети можно получить, уменьшив вероятность добавления новых узлов, как показано в следующем фрагменте из файла конфигурации NEAT: node_add_prob = 0.1 node_delete_prob = 0.1 Наконец, мы позволяем нейроэволюционному процессу использовать не только нейросеть с прямой связью, но и рекуррентные нейросети. Раз- решая рекуррентные соединения, мы даем возможность нейросети иметь память и стать конечным автоматом. Это полезно для эволюционного про- цесса. Следующий гиперпараметр конфигурации влияет на этот фактор: feed_forward = False Гиперпараметры, описанные в этом разделе, оказались полезными для ал- горитма NEAT, который используется в эксперименте для обучения в течение ограниченного числа поколений успешного агента, проходящего лабиринт. Полный список гиперпараметров, задействованных в эксперименте с простым лабиринтом, можно найти в файле maze_config.ini в фай- ловом архиве книги. 5.5 Проведение эксперимента с простой конфигурацией лабиринта  131\n--- Страница 133 ---\n5.5.2 Файл конфигурации лабиринта Конфигурация лабиринта для нашего эксперимента представлена в виде прос- того текста. Этот файл загружается в среду моделирования, и в ней создается лабиринт с соответствующей конфигурацией. Файл конфигурации имеет со- держимое следующего вида: 11 30 22 0270 1005 5 295 5295 5 295 135295 135 5 135 Формат файла конфигурации лабиринта следующий: первая строка содержит количество стен в лабиринте; вторая строка определяет начальную позицию агента (x, y); третья строка обозначает начальный курс агента в градусах; четвертая строка содержит позицию выхода из лабиринта (x , y); следующие строки определяют стены лабиринта. Стена лабиринта представлена в виде отрезка, где первые два числа опре- деляют координаты начальной точки, а последние два числа – координаты конечной точки. Начальная позиция агента и выход из лабиринта представ- лены в виде двух чисел, обозначающих координаты x и y точки в двумерном пространстве. 5.5.3 Настройка рабочей среды Рабочую среду эксперимента по прохождению простого лабиринта можно на- строить с помощью следующих команд, введенных в выбранном вами прило- жении терминала: $ conda create --name maze_objective_neat python=3.5 $ conda activate maze_objective_neat $ pip install neat-python==0.92$ conda install matplotlib$ conda install graphviz$ conda install python-graphviz Эти команды создают и активируют виртуальную среду maze_objective_neat с Python 3.5. После этого устанавливается библиотека NEAT-Python версии 0.92, а также другие зависимости, используемые нашими утилитами визуа- лизации. Теперь мы готовы приступить к реализации движка эксперимента. 5.5.4 Реализация движка эксперимента Движок эксперимента представлен в файле maze_experiment.py , к которому вы должны обратиться для получения полной информации о реализации. Этот скрипт Python предоставляет функции для чтения аргументов команд-132  Автономное прохождение лабиринта\n--- Страница 134 ---\nной строки, для настройки и запуска процесса нейроэволюции, а также для отображения результатов эксперимента после его завершения. Кроме того, он включает в себя реализацию функций обратного вызова для оценки при- способленности геномов, принадлежащих к определенной популяции. Эти функции обратного вызова будут предоставлены окружению библиотеки NEAT-Python во время инициализации. Далее мы обсудим основные части реализации эксперимента, которые ра- нее не рассматривались в этой главе. 1. Начнем с инициализации среды моделирования лабиринта следующи- ми строками: maze_env_config = os.path.join(local_dir, '%s_maze.txt' % args.maze) maze_env = maze.read_environment(maze_env_config) Параметр args.maze ссылается на аргумент командной строки, предостав- ленный пользователем при запуске скрипта Python, и относится к типу сре- ды лабиринта, с которой мы хотели бы поэкспериментировать. Он может иметь два значения: medium (средний) и hard (сложный). Первый относится к простой конфигурации лабиринта, которую мы используем в этом экс- перименте. 2. После этого мы задаем конкретный начальный номер для генератора случайных чисел, создаем объект конфигурации NEAT, а затем объект neat.Population , используя только что созданный объект конфигурации: seed = 1559231616 random.seed(seed) config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction, neat.DefaultSpeciesSet, neat.DefaultStagnation, config_file)p = neat.Population(config) Бывает, что случайное начальное значение, найденное в эксперимен- те по балансировке двойного маятника, также подходит для этого эксперимента. Можно предположить, что мы нашли случайный атт - рактор, специфичный для стохастического процесса, реализуемого библиотекой NEAT-Python. Позже в книге мы проверим, верно ли это и для других экспериментов. 3. Теперь мы готовы создать соответствующую среду моделирования ла- биринта и сохранить ее как глобальную переменную, чтобы упростить доступ к ней из функции обратного вызова оценки приспособленности: global trialSim trialSim = MazeSimulationTrial(maze_env=maze_env, population=p) Объект MazeSimulationTrial содержит поля, которые обеспечивают доступ к исходной среде моделирования лабиринта и хранилищу записей, исполь- зуемому для сохранения результатов оценки агентов, решающих лабиринт. 5.5 Проведение эксперимента с простой конфигурацией лабиринта  133\n--- Страница 135 ---\nПри каждом вызове функции обратного вызова для оценки приспособлен- ности eval_fitness(genome_id, genome, config, time_steps=400) исходная среда моделирования лабиринта дублируется и используется для моделирования прохождения лабиринта конкретным агентом в течение 400 временных ша- гов. После этого полная статистика об агенте, проходящем лабиринт, вклю- чая его окончательное положение в лабиринте, будет собрана из среды и до- бавлена в хранилище записей. 4. Следующий код стал стандартным для наших экспериментов и связан с добавлением различных репо́ртеров статистики: p.add_reporter(neat.StdOutReporter(True)) stats = neat.StatisticsReporter() p.add_reporter(stats) p.add_reporter(neat.Checkpointer(5, filename_prefix='%s/maze-neat-checkpoint-' % trial_out_dir)) Репортеры используются для вывода промежуточных результатов процес - са нейроэволюции в консоль, а также для сбора более подробной статистики, которая будет отображаться после завершения процесса. 5. Наконец, мы запускаем процесс нейроэволюции для указанного числа поколений и проверяем, было ли найдено решение: start_time = time.time() best_genome = p.run(eval_genomes, n=n_generations) elapsed_time = time.time() - start_time solution_found = (best_genome.fitness >= \\ config.fitness_threshold)if solution_found: print(\"SUCCESS: The stable maze solver controller was found!!!\")else: print(\"FAILURE: Failed to find the stable maze solver controller!!!\") Мы предполагаем, что решение было найдено, если лучший геном, воз- вращаемый библиотекой NEATPython, имеет показатель приспособленности, который больше или равен пороговому значению приспособленности, уста- новленному в файле конфигурации (1.0). Чтобы показать в выводе консоли, сколько времени потребовалось для завершения процесса, производится подсчет затраченного времени. Оценка приспособленности генома Функция обратного вызова для оценки приспособленности всех геномов, при- надлежащих к определенной популяции организмов, реализована следующим образом: def eval_genomes(genomes, config): for genome_id, genome in genomes: genome.fitness = eval_fitness(genome_id, genome, config)134  Автономное прохождение лабиринта\n--- Страница 136 ---\n5.5.5 Проведение эксперимента по навигации в простом лабиринте Имея симулятор решателя лабиринта, движок эксперимента и функцию оцен- ки приспособленности, мы готовы начать эксперимент по поиску решателя ла- биринта. Убедитесь, что вы скопировали все нужные скрипты Python и файлы конфигурации ( maze_config.ini и medium_maze.txt ) в рабочий каталог. После этого войдите в рабочий каталог и выполните следующую команду в выбранном вами приложении терминала: $ python maze_experiment.py -m medium -g 150 Не забудьте активировать соответствующую виртуальную среду при помощи команды conda activate maze_objective_neat. Предыдущая команда загружает простую конфигурацию лабиринта из файла medium_maze.txt и создает соответствующую среду моделирования ла- биринта. После этого она запускает нейроэволюционный процесс под управ- лением алгоритма NEAT, используя гиперпараметры, указанные в файле maze_config.ini . Алгоритм NEAT применяет среду моделирования лабиринта для оценки приспособленности каждого генома, созданного в ходе нейро- эволюции в течение 150 поколений ( -g в аргументах командной строки). После 144 поколений эволюции успешный агент-решатель лабиринтов был найден в поколении 145. Вывод консоли для последнего поколения выглядит следующим образом. 1. Сначала идет общая статистика по геному популяции: ****** Running generation 145 ****** Maze solved in 388 steps Population's average fitness: 0.24758 stdev: 0.25627Best fitness: 1.00000 - size: (3, 11) - species 7 - id 35400 Best individual in generation 145 meets fitness threshold - complexity: (3, 11) 2. Далее следует конфигурация генома, кодирующего нейросеть успешно- го решателя: Best genome: Key: 35400 Fitness: 1.0Nodes:0 DefaultNodeGene(key=0, bias=5.534849614521037, response=1.0, activation=sigmoid, aggregation=sum) 1 DefaultNodeGene(key=1, bias=1.8031133229851957, response=1.0, activation=sigmoid, aggregation=sum) 5.5 Проведение эксперимента с простой конфигурацией лабиринта  135\n--- Страница 137 ---\n158 DefaultNodeGene(key=158, bias=-1.3550878188609456, response=1.0, activation=sigmoid, aggregation=sum)Connections:DefaultConnectionGene(key=(-10, 158), weight=-1.6144052085440168, enabled=True) DefaultConnectionGene(key=(-8, 158), weight=-1.1842193888036392,enabled=True)DefaultConnectionGene(key=(-7, 0), weight=-0.3263706518456319,enabled=True)DefaultConnectionGene(key=(-7, 1), weight=1.3186165993348418,enabled=True) DefaultConnectionGene(key=(-6, 0), weight=2.0778575294986945, enabled=True)DefaultConnectionGene(key=(-6, 1), weight=-2.9478037554862824,enabled=True)DefaultConnectionGene(key=(-6, 158), weight=0.6930281879212032, enabled=True) DefaultConnectionGene(key=(-4, 1), weight=-1.9583885391583729, enabled=True) DefaultConnectionGene(key=(-3, 1), weight=5.5239054588484775,enabled=True)DefaultConnectionGene(key=(-1, 0), weight=0.04865917999517305,enabled=True)DefaultConnectionGene(key=(158, 0), weight=0.6973191076874032,enabled=True) SUCCESS: The stable maze solver controller was found!!! Record store file: out/maze_objective/medium/data.pickle В выводе консоли вы можете видеть, что во время эволюции был найден успешный решатель лабиринта, который смог достичь области выхода из ла- биринта за 388 шагов из отведенных 400. Конфигурация нейросети успешно- го решателя содержит 2 выходных узла и 1 скрытый узел, с 11 связями между этими узлами и входами. Окончательная конфигурация нейросети показана на рис. 5.4. Рис. 5.4. Конфигурация нейросети, соответствующей успешному решателю простого лабиринта136  Автономное прохождение лабиринта\n--- Страница 138 ---\nИнтересно взглянуть на граф нейросети с точки зрения влияния различ- ных входов датчиков на выходные управляющие сигналы. Мы можем видеть, что конфигурация нейросети полностью игнорирует входные сигналы от пе- реднего и левого дальномерных датчиков (RF_FR и RF_L) и от секторного ра- дарного датчика RAD_B робота. В то же время линейные и угловые скорости робота зависят от уникальных комбинаций других датчиков. Кроме того, мы можем видеть агрегацию левого и правого радарных дат- чиков (RAD_L и RAD_R) с дальномером RF_B через скрытый узел, который затем ретранслирует агрегированный сигнал узлу, управляющему угловой скоростью. Если мы посмотрим на изображение простой конфигурации ла- биринта (рис. 5.3), то подобная агрегация выглядит довольно естественной. Она позволяет роботу развернуться и продолжить исследовать лабиринт, ког- да он застрял в одном из тупиков, где расположены локальные оптимумы. Оценка приспособленности агентов по поколениям показана на рис. 5.5. Средняя и лучшая приспособленность популяции Поколениясредняя –1 СКО +1 СКО лучшаяПриспособленность Рис. 5.5. Средние оценки приспособленности агентов по поколениям На этом графике мы можем видеть, что эволюционный процесс смог произ- вести довольно успешных агентов, способных пройти лабиринт, в поколении 44 с оценкой приспособленности 0,96738. Но потребовалось еще 100 поколе- ний, чтобы развить геном, который кодирует нейросеть успешного агента. Кроме того, интересно отметить, что повышение производительности в по- колении 44 генерируется видами с ID 1, но геном успешного решателя принад- 5.5 Проведение эксперимента с простой конфигурацией лабиринта  137\n--- Страница 139 ---\nлежит виду с ID 7, который даже не был известен во время первого всплеска. Виды, породившие чемпиона, появились спустя 12 поколений и оставались в по- пуляции до конца, сохраняя полезную мутацию и совершенствуясь на ее основе. Видообразование в течение нескольких поколений показано на рис. 5.6. ПоколенияВидообразованиеРазмер по видам Рис. 5.6. Видообразование по поколениям На графике видообразования мы наблюдаем вид с ID 7, отмеченный розо- вым. Этот вид в конечном итоге произвел геном успешного решателя в ходе эволюционного процесса. Размер вида 7 значительно варьируется на про- тяжении всей его жизни, и в свое время он был единственным видом во всей популяции в течение нескольких поколений (от 105 до 108). Визуализация записи агента В этом эксперименте мы представили новый метод визуализации, который позволяет нам визуально различать эффективность различных видов в эволю- ционном процессе. Визуализация может быть выполнена с помощью следую- щей команды, выполненной из рабочего каталога эксперимента: $ python visualize.py -m medium -r out/maze_objective/medium/data.pickle --width 300 --height 150 Команда загружает записи об оценке приспособленности каждого агента, проходящего лабиринт во время эволюции, которые хранятся в файле data.138  Автономное прохождение лабиринта\n--- Страница 140 ---\npickle. После этого визуализатор рисует конечные позиции агентов на кар- те лабиринта в конце симуляции прохождения. Конечная позиция каждого агента представлена в виде цветного кружка. Цвет кружка обозначает вид, к которому принадлежит конкретный агент. Каждый вид, полученный в ходе эволюции, имеет уникальный цветовой код. Результаты этой визуализации можно увидеть на рис. 5.7. Приспособленность < 0.8Приспособленность > = 0.8, виды: 6 Рис. 5.7. Визуализация процесса развития решающего агента Чтобы сделать визуализацию более информативной, мы ввели порог при- способленности для фильтрации наиболее эффективных видов. Верхняя по- ловина рисунка показывает конечные позиции решающих агентов, принад- лежащих к видам-чемпионам (показатель приспособленности выше 0,8). Как вы можете видеть, организмы, принадлежащие к этим шести видам, явля- ются активными исследователями, у которых есть гены, провоцирующие по- иск в неизвестных местах в лабиринте. Их конечные местоположения почти равномерно распределены по области лабиринта вокруг начальной точки и имеют низкую плотность в тупиках локальных оптимумов. В то же время на нижней половине рисунка вы можете увидеть, что эволю- ционные неудачники демонстрируют более консервативное поведение, кон- центрируясь в основном возле стен в стартовой зоне и в самой выраженной 5.5 Проведение эксперимента с простой конфигурацией лабиринта  139\n--- Страница 141 ---\nобласти локального оптимума – самом большом тупике, который находится в нижней части лабиринта. 5.6 упражнения 1. Попробуйте увеличить параметр compatibility_disjoint_coefficient в файле maze_config.ini и запустить эксперимент с новыми настройка- ми. Какое влияние эта модификация оказывает на количество видов, произведенных в ходе эволюции? Способен ли процесс нейроэволю- ции найти успешный решатель лабиринтов? 2. Увеличить численность населения на 200 % (параметр pop_size). Был ли процесс нейроэволюции способен найти решение в этом случае, и если да, сколько поколений это заняло? 3. Измените начальное значение генератора случайных чисел (см. стро- ку 118 файла maze_experiment.py ). Успешен ли процесс нейроэволюции с этим новым значением?",
          "debug": {
            "start_page": 130,
            "end_page": 141
          }
        },
        {
          "name": "5.7 Эксперимент со сложной конфигурацией лабиринта 140",
          "content": "--- Страница 141 --- (продолжение)\n5.7 экСперимент СО СлОжнОй кОнфигурацией лабиринта Следующий эксперимент в этой главе представляет собой запуск процесса нейроэволюции, чтобы обучить агента, способного пройти лабиринт с более сложной конфигурацией стен. Этот лабиринт содержит мощные локальные ло- вушки наилучшей приспособленности и не имеет прямого пути от начальной позиции агента к зоне выхода из лабиринта. Конфигурация лабиринта изо- бражена на рис. 5.8. Рис. 5.8. Лабиринт со сложной конфигурацией Начальная позиция агента находится в левом нижнем углу и отмечена зеле- ным кружком, а целевая позиция выхода из лабиринта – в верхнем левом углу и отмечена красным кружком. Чтобы пройти лабиринт, агент должен разрабо- тать сложную стратегию управления, которая позволяет ему избегать локаль- ных ловушек наилучшей приспособленности вокруг начальной точки. Стратегия 140  Автономное прохождение лабиринта\n5.7 экСперимент СО СлОжнОй кОнфигурацией лабиринта Следующий эксперимент в этой главе представляет собой запуск процесса нейроэволюции, чтобы обучить агента, способного пройти лабиринт с более сложной конфигурацией стен. Этот лабиринт содержит мощные локальные ло- вушки наилучшей приспособленности и не имеет прямого пути от начальной позиции агента к зоне выхода из лабиринта. Конфигурация лабиринта изо- бражена на рис. 5.8. Рис. 5.8. Лабиринт со сложной конфигурацией Начальная позиция агента находится в левом нижнем углу и отмечена зеле- ным кружком, а целевая позиция выхода из лабиринта – в верхнем левом углу и отмечена красным кружком. Чтобы пройти лабиринт, агент должен разрабо- тать сложную стратегию управления, которая позволяет ему избегать локаль- ных ловушек наилучшей приспособленности вокруг начальной точки. Стратегия 140  Автономное прохождение лабиринта\n--- Страница 142 ---\nуправления должна провести агента от начальной точки до выхода по сложной траектории, имеющей несколько поворотов и больше локальных ловушек. 5.7.1 Настройка гиперпараметров Для этого эксперимента мы будем использовать те же гиперпараметры, ко- торые использовали в простом эксперименте по решению лабиринтов. Идея заключается в том, чтобы взять прежние начальные условия для нейроэволю- ционного алгоритма и посмотреть, сможет ли он обучить успешного решателя для другой, более сложной конфигурации лабиринта. Это покажет, насколько хорошо алгоритм обобщается с использованием гиперпараметров, заданных для иной конфигурации лабиринта. 5.7.2 Настройка рабочей среды и движок эксперимента Настройка рабочей среды остается такой же, как для эксперимента по нави- гации в простом лабиринте. Движок эксперимента также остается прежним. Мы изменяем только файл, описывающий конфигурацию среды лабиринта. 5.7.3 Выполнение эксперимента по прохождению сложного лабиринта Как мы уже упоминали, мы будем использовать ту же реализацию движка экс- перимента и те же настройки гиперпараметров NEAT, что и в предыдущем экс- перименте. Но мы настроим другую среду лабиринта следующим образом: $ python maze_experiment.py -m hard -g 500 Дождавшись завершения эксперимента, мы обнаружили, что даже после 500 поколений эволюции успешный решатель не был найден. Лучший геном, полученный с использованием алгоритма нейроэволюции, кодирует причуд- ливую и непрактичную конфигурацию нейросети контроллера, которая по- казана на рис. 5.9. Рис. 5.9. Конфигурация нейросети решателя сложного лабиринта 5.7 Эксперимент со сложной конфигурацией лабиринта  141\n--- Страница 143 ---\nНа графе видно, что вращение робота зависит только от датчика фрон- тального дальномера (RF_FR), а линейное движение контролируется комби- нацией нескольких дальномеров и радарных датчиков. Такая конфигурация управления приводит к упрощенным линейным перемещениям робота до тех пор, пока перед ним не окажется стена. Наше предположение о шаблонах движения подтверждается, когда мы смотрим на визуализацию журнала раз- вития агента (рис. 5.10). Приспособленность < 0.8Приспособленность > = 0.8, виды: 0 Рис. 5.10. Визуализация журнала развития агента Визуализация конечных положений агентов демонстрирует, что большин- ство видов поймано в ловушку вокруг начальной позиции, где расположены некоторые области локальных оптимальных показателей приспособленности. Ни один из видов не смог даже преодолеть заданный порог приспособлен- ности (0,8). Так же, как мы упоминали ранее, существуют четко различимые вертикальные линии, образованные конечными положениями агентов (серые 142  Автономное прохождение лабиринта\n--- Страница 144 ---\nточки, создающие вертикальные столбцы). Это подтверждает наше предполо- жение о неправильной конфигурации нейросети контроллера, которая была закодирована лучшим геномом, найденным в ходе эволюционного процесса. Средние показатели приспособленности по поколениям показаны на рис. 5.11. Средняя и лучшая приспособленность популяции Поколениясредняя –1 СКО +1 СКО лучшаяПриспособленность Рис. 5.11. Средние показатели приспособленности по поколениям На графике средних показателей приспособленности мы можем видеть, что нейроэволюционный процесс смог значительно увеличить показатели приспо- собленности агентов в самых первых поколениях, но после этого он остановил- ся на плато, не показав улучшений. Это означает, что дальнейшее увеличение числа поколений эволюции не имеет никакого смысла, и необходимо принять другие меры для улучшения характеристик нейроэволюционного процесса.",
          "debug": {
            "start_page": 141,
            "end_page": 144
          }
        },
        {
          "name": "5.8 Упражнения 143",
          "content": "--- Страница 144 --- (продолжение)\n5.8 упражнения Попробуйте увеличить размер популяции, изменив параметр pop_size в файле maze_config.ini . Помогло ли это нейроэволюционному процессу развить успеш- ный лабиринт? Выполнение может занять длительное время. 5.8 Упражнения  143\n5.8 упражнения Попробуйте увеличить размер популяции, изменив параметр pop_size в файле maze_config.ini . Помогло ли это нейроэволюционному процессу развить успеш- ный лабиринт? Выполнение может занять длительное время. 5.8 Упражнения  143",
          "debug": {
            "start_page": 144,
            "end_page": 144
          }
        },
        {
          "name": "5.9 Заключение 144",
          "content": "--- Страница 145 --- (продолжение)\n5.9 заключение В этой главе вы узнали о классе задач планирования и управления, в которых используются целенаправленные функции приспособленности, имеющие об- манчивый ландшафт. В этом ландшафте есть несколько ловушек, созданных локальными областями оптимума функции приспособленности, которые вво- дят в заблуждение процесс поиска решения, если он основан только на оценке приспособленности, рассчитанной как производная от расстояния от агента до цели. Вы узнали, что обычная целенаправленная функция приспособленности помогла процессу эволюции создать агента для прохождения простой конфи- гурации лабиринта, но потерпела неудачу с более сложным лабиринтом из-за ловушек локальных оптимумов. Вы познакомились с полезным методом, который позволяет визуали- зировать конечные позиции всех оцененных агентов на карте лабиринта. С по мощью этой визуализации вы можете делать предположения о характе- ристиках эволюционного процесса. Затем можете принять решение об изме- нениях параметров конфигурации, которые могут привести к дальнейшему повышению качества обучения агента. Кроме того, вы узнали, что, когда существует более высокая вероятность конвергенции функции приспособленности в локальных оптимумах, процесс нейроэволюции приводит к уменьшению количества видов. В крайних случа- ях он создает только один вид, который препятствует инновациям и эволюци- онному процессу. Чтобы избежать этого, можно повысить видообразование, изменив значение коэффициента совместимости, который используется при расчете коэффициента совместимости генома. Этот коэффициент контроли- рует вес, который будет присвоен избыточным или непересекающимся частям сравниваемых геномов. Более высокие значения коэффициентов подчеркива- ют важность топологических различий в сравниваемых геномах и позволяют более разнородным геномам принадлежать к одному и тому же виду. В следующей главе вы познакомитесь с методом оптимизации поиском новизны, который лучше подходит для решения обманчивых задач, таких как ориентирование в лабиринте.144  Автономное прохождение лабиринта\n5.9 заключение В этой главе вы узнали о классе задач планирования и управления, в которых используются целенаправленные функции приспособленности, имеющие об- манчивый ландшафт. В этом ландшафте есть несколько ловушек, созданных локальными областями оптимума функции приспособленности, которые вво- дят в заблуждение процесс поиска решения, если он основан только на оценке приспособленности, рассчитанной как производная от расстояния от агента до цели. Вы узнали, что обычная целенаправленная функция приспособленности помогла процессу эволюции создать агента для прохождения простой конфи- гурации лабиринта, но потерпела неудачу с более сложным лабиринтом из-за ловушек локальных оптимумов. Вы познакомились с полезным методом, который позволяет визуали- зировать конечные позиции всех оцененных агентов на карте лабиринта. С по мощью этой визуализации вы можете делать предположения о характе- ристиках эволюционного процесса. Затем можете принять решение об изме- нениях параметров конфигурации, которые могут привести к дальнейшему повышению качества обучения агента. Кроме того, вы узнали, что, когда существует более высокая вероятность конвергенции функции приспособленности в локальных оптимумах, процесс нейроэволюции приводит к уменьшению количества видов. В крайних случа- ях он создает только один вид, который препятствует инновациям и эволюци- онному процессу. Чтобы избежать этого, можно повысить видообразование, изменив значение коэффициента совместимости, который используется при расчете коэффициента совместимости генома. Этот коэффициент контроли- рует вес, который будет присвоен избыточным или непересекающимся частям сравниваемых геномов. Более высокие значения коэффициентов подчеркива- ют важность топологических различий в сравниваемых геномах и позволяют более разнородным геномам принадлежать к одному и тому же виду. В следующей главе вы познакомитесь с методом оптимизации поиском новизны, который лучше подходит для решения обманчивых задач, таких как ориентирование в лабиринте.144  Автономное прохождение лабиринта",
          "debug": {
            "start_page": 145,
            "end_page": 145
          }
        }
      ]
    },
    {
      "name": "Глава 6. Метод оптимизации поиском новизны 145",
      "chapters": [
        {
          "name": "6.1 Технические требования 145",
          "content": "--- Страница 146 --- (продолжение)\nГлава 6 Метод оптимизации поиском новизны В этой главе вы узнаете о продвинутом методе оптимизации поиска реше- ния, который можно использовать для создания автономно ориентирующих - ся агентов. Этот метод называется поиском новизны ( novelty search, NS). Ос- новная идея данного метода заключается в том, что целевая функция может быть определена исходя из новизны поведения, демонстрируемого агентом, а не расстоянием до цели в пространстве поиска решения. В этой главе вы также узнаете, как использовать методы оптимизации на основе поиска новизны с алгоритмом нейроэволюции для обучения успеш- ных агентов, ориентирующихся в лабиринте. Проведя эксперименты, пред- ставленные в этой главе, вы убедитесь, что в определенных случаях метод поиска новизны превосходит традиционный метод целеориентированной оптимизации поиска. К концу этой главы вы изучите основы метода оптими- зации поиском новизны. Вы научитесь определять функцию приспособлен- ности, используя оценку новизны, и применять ее для решения практиче- ских задач, связанных с вашей работой или экспериментами. В этой главе будут рассмотрены следующие темы: метод оптимизации поиском новизны; основы реализации оценки новизны; функция приспособленности на основе оценки новизны; эксперимент с простой конфигурацией лабиринта; эксперимент со сложной конфигурацией лабиринта. 6.1 техниче Ские треб Ования Для проведения экспериментов, описанных в этой главе, ваш компьютер должен удовлетворять следующим техническим требованиям: Windows 8/10, macOS 10.13 или новее, или современный Linux; Anaconda Distribution версия 2019.03 или новее. Исходный код примеров этой главы можно найти в каталоге Chapter6 в фай- ловом архиве книги.\n6.1 техниче Ские треб Ования Для проведения экспериментов, описанных в этой главе, ваш компьютер должен удовлетворять следующим техническим требованиям: Windows 8/10, macOS 10.13 или новее, или современный Linux; Anaconda Distribution версия 2019.03 или новее. Исходный код примеров этой главы можно найти в каталоге Chapter6 в фай- ловом архиве книги.",
          "debug": {
            "start_page": 146,
            "end_page": 146
          }
        },
        {
          "name": "6.2 Метод оптимизации поиском новизны 146",
          "content": "--- Страница 147 --- (продолжение)\n6.2 метОД Оптимизации пОиСкОм нОвизны Основная идея, заложенная в основу метода поиска новизны, заключается в том, чтобы вознаграждать новизну созданного решения, а не его близость к конечной цели. Эта идея вдохновлена естественной эволюцией. При поиске успешного решения не всегда очевиден точный порядок действий, которые следует предпринять. Естественная эволюция непрерывно производит но- вые формы с различными фенотипами, пытающимися использовать окру - жающую среду и приспосабливаться к изменениям. Это привело к взрыву разнообразия форм жизни на Земле и вызвало качественные скачки в эво- люции жизни. Тот же процесс позволил формам жизни покинуть море и по- корить землю. Необычайный генез эукариот стал источником всех высших форм жизни на планете. Все это примеры поощрения новизны в процессе эволюции. В то же время в естественной эволюции нет четкой задачи или конечной цели. Как вы узнали из предыдущей главы, обычные целенаправленные функ - ции приспособленности чувствительны к ловушкам локального оптимума. Эта патология оказывает давление на эволюционный процесс, заставляя его сходиться к единому решению, которое часто застревает в тупиках в про- странстве поиска, при этом отсутствуют локальные шаги, которые могут улучшить эффективность функции приспособленности. В результате застре- вания в тупике успешное решение остается неисследованным. И наоборот, поиск новизны ведет эволюцию к разнообразию. Этот подход помогает процессу нейроэволюции производить успешных решающих аген- тов, даже для задач с обманчивым ландшафтом функции приспособленно- сти, таких как задача прохождения лабиринта. Практическим примером такой обманчивой задачи является навигация по неизвестному городу. Если вы посещаете старый город с хаотичной си- стемой дорог, вам нужно использовать иную стратегию, чтобы добраться из точки А в точку В, чем в современных городах с четкой линейной системой улиц. В современных городах достаточно проехать по дорогам, которые бо- лее-менее точно указывают в направлении пункта назначения, но навига- ция в старых городах намного сложнее. Направление к месту назначения часто приводит вас в тупик (обманчивый локальный оптимум). Вы должны использовать более исследовательский подход, тестируя новые и часто не- логичные решения, которые, казалось бы, уводят вас от пункта назначения. Однако, завернув за очередной угол, вы достигнете своей цели. Тем не менее обратите внимание, что с самого начала нам было неочевидно, какие по- вороты применять, основываясь только на расстоянии до конечного пункта назначения (то есть на целеориентированном показателе приспособленно- сти). Повороты, ведущие к оптимальному решению, часто находятся в нело- гичных местах, которые, кажется, уводят вас в сторону, но в конечном итоге помогают достичь цели. Про оптимизацию поиском новизны мы говорили в главе 1.146  Метод оптимизации поиском новизны\n6.2 метОД Оптимизации пОиСкОм нОвизны Основная идея, заложенная в основу метода поиска новизны, заключается в том, чтобы вознаграждать новизну созданного решения, а не его близость к конечной цели. Эта идея вдохновлена естественной эволюцией. При поиске успешного решения не всегда очевиден точный порядок действий, которые следует предпринять. Естественная эволюция непрерывно производит но- вые формы с различными фенотипами, пытающимися использовать окру - жающую среду и приспосабливаться к изменениям. Это привело к взрыву разнообразия форм жизни на Земле и вызвало качественные скачки в эво- люции жизни. Тот же процесс позволил формам жизни покинуть море и по- корить землю. Необычайный генез эукариот стал источником всех высших форм жизни на планете. Все это примеры поощрения новизны в процессе эволюции. В то же время в естественной эволюции нет четкой задачи или конечной цели. Как вы узнали из предыдущей главы, обычные целенаправленные функ - ции приспособленности чувствительны к ловушкам локального оптимума. Эта патология оказывает давление на эволюционный процесс, заставляя его сходиться к единому решению, которое часто застревает в тупиках в про- странстве поиска, при этом отсутствуют локальные шаги, которые могут улучшить эффективность функции приспособленности. В результате застре- вания в тупике успешное решение остается неисследованным. И наоборот, поиск новизны ведет эволюцию к разнообразию. Этот подход помогает процессу нейроэволюции производить успешных решающих аген- тов, даже для задач с обманчивым ландшафтом функции приспособленно- сти, таких как задача прохождения лабиринта. Практическим примером такой обманчивой задачи является навигация по неизвестному городу. Если вы посещаете старый город с хаотичной си- стемой дорог, вам нужно использовать иную стратегию, чтобы добраться из точки А в точку В, чем в современных городах с четкой линейной системой улиц. В современных городах достаточно проехать по дорогам, которые бо- лее-менее точно указывают в направлении пункта назначения, но навига- ция в старых городах намного сложнее. Направление к месту назначения часто приводит вас в тупик (обманчивый локальный оптимум). Вы должны использовать более исследовательский подход, тестируя новые и часто не- логичные решения, которые, казалось бы, уводят вас от пункта назначения. Однако, завернув за очередной угол, вы достигнете своей цели. Тем не менее обратите внимание, что с самого начала нам было неочевидно, какие по- вороты применять, основываясь только на расстоянии до конечного пункта назначения (то есть на целеориентированном показателе приспособленно- сти). Повороты, ведущие к оптимальному решению, часто находятся в нело- гичных местах, которые, кажется, уводят вас в сторону, но в конечном итоге помогают достичь цели. Про оптимизацию поиском новизны мы говорили в главе 1.146  Метод оптимизации поиском новизны",
          "debug": {
            "start_page": 147,
            "end_page": 147
          }
        },
        {
          "name": "6.3 Основы реализации алгоритма поиска новизны 147",
          "content": "--- Страница 148 --- (продолжение)\n6.3 О СнОвы реализации алгОритма пОиСка нОвизны Реализация алгоритма поиска новизны должна включать структуру данных для хранения информации о рассматриваемом новом элементе и структуру для работы со списком новых элементов. В нашей реализации эта функцио- нальность заключена в трех классах Python: NoveltyItem – структура, которая содержит всю соответствующую ин- формацию о степени новизны особи, которая оценивалась в ходе эво- люции; NoveltyArchive – класс, который поддерживает список соответствующих экземпляров NoveltyItem . Он предоставляет методы для оценки новиз- ны отдельных геномов по сравнению с уже накопленными экземпляра- ми NoveltyItem и текущей популяцией; ItemsDistance – вспомогательная структура, которая содержит значение метрики расстояния (новизны) между двумя экземплярами NoveltyItem . Она используется в расчетах среднего расстояния до k-ближайшего со- седа, которое используется в качестве значения оценки новизны в на- шем эксперименте. С подробностями реализации кода можно ознакомиться в файле nov- elty_archive.py в файловом архиве книги. 6.3.1 NoveltyItem Этот класс является основной структурой, которая содержит информацию о балле новизны каждой особи, получившей оценку в ходе эволюции. Как мож - но видеть в исходном коде, он имеет несколько полей для хранения соответ - ствующей информации: def __init__(self, generation=-1, genomeId=-1, fitness=-1, novelty=-1): self.generation = generation self.genomeId = genomeId self.fitness = fitness self.novelty = novelty self.in_archive = False self.data = [] Поле generation содержит идентификатор поколения, в котором был создан этот элемент. По сути, genomeId – это идентификатор оцениваемого генома, а fitness – это целенаправленная оценка приспособленности оцениваемого генома (близость к выходу из лабиринта). Кроме того, novelty – это оценка новизны, присвоение которой оцениваемому геному мы обсудим в следую- щем разделе, а data – это список точек данных, представляющих координаты конкретных положений лабиринта, которые агент решателя посетил во вре- мя моделирования. Этот список данных используется для оценки расстояния между текущим и остальными элементами. Вычисленное расстояние после этого можно использовать для оценки показателя новизны, связанной с кон- кретным обновленным геномом. 6.3 Основы реализации алгоритма поиска новизны  147\n6.3 О СнОвы реализации алгОритма пОиСка нОвизны Реализация алгоритма поиска новизны должна включать структуру данных для хранения информации о рассматриваемом новом элементе и структуру для работы со списком новых элементов. В нашей реализации эта функцио- нальность заключена в трех классах Python: NoveltyItem – структура, которая содержит всю соответствующую ин- формацию о степени новизны особи, которая оценивалась в ходе эво- люции; NoveltyArchive – класс, который поддерживает список соответствующих экземпляров NoveltyItem . Он предоставляет методы для оценки новиз- ны отдельных геномов по сравнению с уже накопленными экземпляра- ми NoveltyItem и текущей популяцией; ItemsDistance – вспомогательная структура, которая содержит значение метрики расстояния (новизны) между двумя экземплярами NoveltyItem . Она используется в расчетах среднего расстояния до k-ближайшего со- седа, которое используется в качестве значения оценки новизны в на- шем эксперименте. С подробностями реализации кода можно ознакомиться в файле nov- elty_archive.py в файловом архиве книги. 6.3.1 NoveltyItem Этот класс является основной структурой, которая содержит информацию о балле новизны каждой особи, получившей оценку в ходе эволюции. Как мож - но видеть в исходном коде, он имеет несколько полей для хранения соответ - ствующей информации: def __init__(self, generation=-1, genomeId=-1, fitness=-1, novelty=-1): self.generation = generation self.genomeId = genomeId self.fitness = fitness self.novelty = novelty self.in_archive = False self.data = [] Поле generation содержит идентификатор поколения, в котором был создан этот элемент. По сути, genomeId – это идентификатор оцениваемого генома, а fitness – это целенаправленная оценка приспособленности оцениваемого генома (близость к выходу из лабиринта). Кроме того, novelty – это оценка новизны, присвоение которой оцениваемому геному мы обсудим в следую- щем разделе, а data – это список точек данных, представляющих координаты конкретных положений лабиринта, которые агент решателя посетил во вре- мя моделирования. Этот список данных используется для оценки расстояния между текущим и остальными элементами. Вычисленное расстояние после этого можно использовать для оценки показателя новизны, связанной с кон- кретным обновленным геномом. 6.3 Основы реализации алгоритма поиска новизны  147\n--- Страница 149 ---\n6.3.2 NoveltyArchive Этот класс ведет список соответствующих обновленных элементов и предо- ставляет методы для оценки новизны отдельных геномов, а также всей попу - ляции геномов в целом. В конструкторе определены следующие поля: def __init__(self, threshold, metric): self.novelty_metric = metric self.novelty_threshold = threshold self.novelty_floor = 0.25 self.items_added_in_generation = 0 self.time_out = 0 self.neighbors = KNNNoveltyScore self.generation = 0 self.novel_items = [] self.fittest_items = [] Обратите внимание, что novelty_metric – это ссылка на функцию, которую можно использовать для оценки метрики новизны или расстояния между двумя новинками. Кроме того, novelty_threshold определяет текущее минимальное значение новизны для NoveltyItem , при котором новый элемент может быть добав- лен в архив. Это значение является динамическим и изменяется во время выполнения, чтобы поддерживать размер архива в определенных преде- лах; novelty_floor – это минимально возможное значение novelty_threshold . Поля items_added_in_generation и time_out используются для планирования динамики изменения значений novelty_threshold . Поле neighbors – это число k-ближайших соседей по умолчанию, которое используется для оценки но- визны. generation – это нынешнее эволюционное поколение. novel_items – это список всех соответствующих экземпляров NoveltyItem , собранных до насто- ящего времени, а fittest_items – это список новых элементов, имеющих мак- симальный целенаправленный показатель приспособленности. Динамика поля novelty_threshold определяется следующим исходным ко- дом: def _adjust_archive_settings(self): if self.items_added_in_generation == 0: self.time_out += 1 else: self.time_out = 0 if self.time_out >= 10: self.novelty_threshold *= 0.95 if self.novelty_threshold < self.novelty_floor: self.novelty_threshold = self.novelty_floor self.time_out = 0 if self.items_added_in_generation >= 4: self.novelty_threshold *= 1.2 self.items_added_in_generation = 0 Данная функция вызывается в конце каждого эволюционного поколения, чтобы настроить значение поля novelty_threshold для следующего поколения. 148  Метод оптимизации поиском новизны\n--- Страница 150 ---\nКак вы знаете, это значение определяет, сколько новых элементов следует добавить в архив в следующем поколении. Динамическая регулировка этого параметра необходима для поддержа- ния соответствующей сложности поиска новых решений с течением времени при использовании метода поиска новизны. В начале эволюции существуют огромные возможности для поиска новых решений с высокими показате- лями новизны, поскольку в лабиринте исследовано всего несколько путей. Однако ближе к концу эволюции становится все труднее находить новинки, потому что остается меньше неизведанных путей. Чтобы компенсировать это усложнение, если новый путь не найден в последних 2500 оценках (10 по- колений), значение novelty_threshold снижается на 5 %. С другой стороны, чтобы снизить скорость добавления нового элемента NoveltyItem в архив на ранних этапах эволюции, значение novelty_threshold увеличивается на 20 %, если в последнем поколении было добавлено более четырех элементов. Следующий исходный код показывает, как значение novelty_threshold ис- пользуется для определения, какой элемент NoveltyItem заслуживает добав- ления в архив: def evaluate_individual_novelty(self, genome, genomes, n_items_map, only_fitness=False): item = n_items_map[genome.key] result = 0.0 if only_fitness: result = self._novelty_avg_knn(item=item, genomes=genomes, n_items_map=n_items_map)else:result = self._novelty_avg_knn(item=item, neighbors=1,n_items_map=n_items_map)if result > self.novelty_threshold or \\len(self.novel_items) < ArchiveSeedAmount: self._add_novelty_item(item) item.novelty = resultitem.generation = self.generationreturn result Чтобы оценить новизну предоставленного генома, в данном блоке кода исполь- зуется функция приспособленности с оценкой новизны, которую мы подробно рассмотрим далее. Если эта функция вызывается в режиме обновления архива (only_fitness = False), то полученное значение оценки новизны (result) сравнива- ется с текущим значением поля novelty_threshold . На основании результата срав- нения принимается решение о добавлении объекта NoveltyItem в объект NoveltyAr- chive. Кроме того, для начального заполнения архива экземплярами NoveltyItem в начале эволюции, когда архив еще пуст, вводится константа ArchiveSeedAmount .",
          "debug": {
            "start_page": 148,
            "end_page": 150
          }
        },
        {
          "name": "6.4 Функция приспособленности с оценкой новизны 149",
          "content": "--- Страница 150 --- (продолжение)\n6.4 функция при СпОСО бленн ОСти С Оценк Ой нОвизны Теперь, когда мы определили основные принципы, лежащие в основе метода по- иска новизны, нам нужно найти способ интегрировать его в определение функ - ции приспособленности, которая будет применяться для управления процессом 6.4 Функция приспособленности с оценкой новизны  149\n6.4 функция при СпОСО бленн ОСти С Оценк Ой нОвизны Теперь, когда мы определили основные принципы, лежащие в основе метода по- иска новизны, нам нужно найти способ интегрировать его в определение функ - ции приспособленности, которая будет применяться для управления процессом 6.4 Функция приспособленности с оценкой новизны  149\n--- Страница 151 ---\nнейроэволюции. Другими словами, нам нужно определить метрику новизны, способную отразить количество новизны, привнесенное конкретным решаю- щим агентом в ходе эволюционного процесса. Есть несколько характеристик, которые можно использовать как метрики новизны для решающего агента: новизна структуры генотипа решателя – структурная новизна; поведенческие шаги, найденные в пространстве поиска решения, – по- веденческая новизна. Наша основная цель в этой главе – обучить успешного агента-решателя лабиринта. Чтобы успешно перемещаться по лабиринту, агент должен уде- лять одинаковое внимание большинству мест в лабиринте. Такое поведение может быть достигнуто за счет вознаграждения агентов, которые выбирают уникальный путь исследования по сравнению с уже известными путями ра- нее протестированных агентов. Возвращаясь к ранее упомянутым метрикам новизны, это означает, что нам нужно определить функцию приспособлен- ности, используя метрику, основанную на поведенческой новизне. 6.4.1 Оценка новизны Поведенческое пространство агента, проходящего лабиринт, определяется его траекторией, пролегающей через лабиринт, во время моделирования прохож - дения лабиринта. Эффективная реализация оценки новизны должна вычислять разреженность в любой точке такого поведенческого пространства. Любая об- ласть с более плотным кластером посещенных точек пространства поведения является менее новой, что дает меньшее вознаграждение решающему агенту. Как было сказано в главе 1, наиболее простой мерой разреженности в точке является среднее расстояние от нее до k-ближайших соседей. Разреженные области имеют более высокие значения расстояния, а более плотные обла- сти имеют низкие значения расстояния. Следующая формула дает разрежен- ность в точке x поведенческого пространства: ()() 01 k i ix distx, .kρ µ ==∑ Здесь mi– i-й ближайший сосед x для расчета метрики расстояния (новизны) dist(x, y). Рассчитанная по приведенной выше формуле разреженность в определен- ной точке поведенческого пространства представляет собой показатель но- визны, который может использоваться функцией приспособленности. Код Python для нахождения показателя новизны представлен в виде сле- дующей функции: def _novelty_avg_knn(self, item, n_items_map, genomes=None, neighbors=None): distances = None if genomes is not None: distances = self._map_novelty_in_population(item=item, genomes=genomes, n_items_map=n_items_map) else: distances = self._map_novelty(item=item)150  Метод оптимизации поиском новизны\n--- Страница 152 ---\ndistances.sort() if neighbors is None: neighbors = self.neighbors density, weight, distance_sum = 0.0, 0.0, 0.0 length = len(distances) if length >= ArchiveSeedAmount: length = neighbors if len(distances) < length: length = len(distances) i = 0 while weight < float(neighbors) and i < length: distance_sum += distances[i].distance weight += 1.0 i += 1 if weight > 0: sparsity = distance_sum / weight return sparsity Эта функция состоит из нескольких основных частей. 1. Сначала мы проверяем, содержит ли аргумент функции _novelty_avg_knn список всех геномов в текущей популяции. В этом случае мы начнем с заполнения списка расстояний между поведенческими характерис - тиками всех геномов в популяции, включая все объекты NoveltyItem из NoveltyArchive . В противном случае мы используем предоставленную новинку (item), чтобы найти расстояния между ней и всеми объектами NoveltyItem из NoveltyArchive . distances = None if genomes is not None: distances = self._map_novelty_in_population(item=item, genomes=genomes, n_items_map=n_items_map) else: distances = self._map_novelty(item=item) 2. После этого мы сортируем список расстояний в порядке возрастания, чтобы в начале списка стояло наименьшее расстояние, потому что нас интересуют точки, которые являются ближайшими к предоставленно- му новому элементу в поведенческом пространстве: distances.sort() 3. Затем мы инициализируем все промежуточные переменные, необхо- димые для вычисления оценок k-ближайших соседей, и проверяем, превышает ли количество значений расстояний, собранных на преды- дущем шаге, постоянное значение ArchiveSeedAmount : if neighbors is None: neighbors = self.neighbors density, weight, distance_sum = 0.0, 0.0, 0.0 length = len(distances) 6.4 Функция приспособленности с оценкой новизны  151\n--- Страница 153 ---\n4. Теперь мы можем проверить, меньше ли длина списка найденных рас- стояний, чем количество соседей, которых мы хотим проверить на со- ответствие (neighbors ). Если это так, мы обновляем значение связанной переменной: if length >= ArchiveSeedAmount: length = neighbors if len(distances) < length: length = len(distances) 5. После того как всем локальным переменным присвоены правильные значения, мы можем запустить цикл, собирающий сумму всех расстоя- ний и весов для каждой связи: i = 0 while weight < float(neighbors) and i < length: distance_sum += distances[i].distance weight += 1.0 i += 1 6. Когда предыдущий цикл завершается из-за того, что вычисленное зна- чение веса превышает указанное число соседей, или если мы уже про- шлись по всем значениям расстояния в списке distances , мы готовы рассчитать оценку новизны для данного элемента как среднее расстоя- ние к k-ближайшим соседям: if weight < 0: sparsity = distance_sum / weight Затем функция возвращает вычисленное значение оценки новизны. Подробности реализации можно найти в файле исходного кода nov- elty_archive.py в файловом архиве книги. 6.4.2 Метрика новизны Метрика новизны является мерой того, насколько текущее решение отлича- ется от уже известных. Она используется для вычисления оценки новизны при подсчете расстояния от текущей точки в поведенческом пространстве до ее k-ближайших соседей. В нашем эксперименте метрика новизны, отражающая разницу в пове- дении двух агентов, определяется поэлементным расстоянием между двумя векторами траектории (один вектор на агента). Вектор траектории содержит координаты позиций, которые посетил агент во время симуляции. Следую- щая формула дает определение метрики: () 01n j j jdistx, x .nµ µ ==−∑ Здесь n – размер вектора траектории, а µi и xj – значения сравниваемых век- торов и в позиции j .152  Метод оптимизации поиском новизны\n--- Страница 154 ---\nВ эксперименте по прохождению лабиринта нас больше всего интересует конечная позиция решающего агента. Таким образом, вектор траектории мо- жет содержать только окончательные координаты агента после выполнения всех необходимых шагов в симуляторе прохождения лабиринта или при об- наружении выхода из лабиринта. Код Python для вычисления метрики новизны выглядит следующим образом: def maze_novelty_metric(first_item, second_item): diff_accum = 0.0 size = len(first_item.data) for i in range(size): diff = abs(first_item.data[i] - second_item.data[i]) diff_accum += diff return diff_accum / float(size) Этот код берет двух новичков-претендентов и находит поэлементное рас- стояние между двумя векторами траектории, содержащими позиции соот - ветствующих агентов во время симуляции прохождения лабиринта. 6.4.3 Функция приспособленности Функция приспособленности, используемая в экспериментах данной главы, непосредственно использует показатель новизны, определенный ранее как значение приспособленности генома. В результате процесс нейроэволюции пытается максимизировать новизну произведенных особей, исходя из этой функции приспособленности. Для различных задач в этом эксперименте мы используем различные фак- торы приспособленности: оценка новизны используется, чтобы направлять процесс нейроэволю- ции (оптимизация поиска решения). Она присваивается каждому гено- му в качестве значения приспособленности и используется для оценки генома в ходе эволюции; оценка целеориентированной приспособленности (расстояние до выхода из лабиринта), полученная из симулятора лабиринта, используется для проверки достижения конечной цели (то есть выхода из лабиринта) – это значение записывается как показатель эффективности каждого агента. Исходный код для вычисления значений приспособленности представлен в двух функциях: функция обратного вызова для оценки показателей приспособленно- сти всей популяции ( eval_genomes ); функция для оценки отдельных геномов с помощью симуляции про- хождения лабиринта ( eval_individual ). Функция оценки приспособленности популяции Функция оценки приспособленности – это функция обратного вызова, зарегист- рированная в библиотеке NEAT-Python и позволяющая этой библиотеке вы- полнять оценку геномов популяции в зависимости от определенных условий конкретной задачи, которую необходимо решить. Мы реализуем эту функцию, 6.4 Функция приспособленности с оценкой новизны  153\n--- Страница 155 ---\nчтобы оценить каждый геном в текущей популяции согласно тому, как он ре- шает задачу прохождения лабиринта, и использовать полученный показатель новизны как оценку приспособленности генома. Библиотека NEAT-Python не позволяет нам отправлять какие-либо указа- ния о завершении задачи из функции обратного вызова, кроме как путем установки конкретного значения приспособленности генома-победителя. Это значение приспособленности должно быть выше порога приспособлен- ности в конфигурации гиперпараметров NEAT-Python. Однако с помощью алгоритма поиска новизны невозможно точно оценить верхнюю границу значения новизны, которая может быть достигнута геномом победителя. Кроме того, геном победителя может иметь значение показателя новизны, которое ниже значений, полученных геномами ранее в процессе эволюции, когда пространство поиска решения не было так тщательно исследовано. Поэтому, учитывая, что оценка новизны присваивается геномам в качест- ве их значений приспособленности, нам необходимо найти обходной путь, который позволяет нам использовать стандартные критерии завершения, определенные библиотекой NEAT-Python. Мы достигаем этого, используя заданное оценочное значение новизны, которое является достаточно боль- шим, чтобы не встретиться случайно во время нормального выполнения алгоритма. Это значение определяет критерий завершения, передаваемый через конфигурацию гиперпараметров NEAT-Python. Мы используем 800000 в качестве индикативной меры оценки новизны и ее натуральный логарифм (примерно 13.59) в качестве подходящего порога приспособленности. Полный исходный код функции выглядит следующим образом: def eval_genomes(genomes, config): n_items_map = {} solver_genome = None for genome_id, genome in genomes: found = eval_individual(genome_id=genome_id, genome=genome, genomes=genomes, n_items_map=n_items_map, config=config) if found: solver_genome = genome trial_sim.archive.end_of_generation() # Вычисляем приспособленность каждого генома в популяции for genome_id, genome in genomes: fitness = trial_sim.archive.evaluate_individual_novelty( genome=genome, genomes=genomes, n_items_map=n_items_map, only_fitness=True) if fitness > 1: fitness = math.log(fitness) else: fitness = 0 genome.fitness = fitness154  Метод оптимизации поиском новизны\n--- Страница 156 ---\nif solver_genome is not None: solver_genome.fitness = math.log(800000) # ~=13.59 Функция состоит из трех важных частей: 1. Сначала мы создаем словарь для хранения новинок (n_items_map ) для каждого генома в популяции и циклически перебираем все геномы в популяции, оценивая их эффективность решения лабиринтов: n_items_map = {} solver_genome = None for genome_id, genome in genomes: found = eval_individual(genome_id=genome_id, genome=genome, genomes=genomes, n_items_map=n_items_map, config=config) if found: solver_genome = genometrial_sim.archive.end_of_generation() 2. После этого мы перебираем все геномы в популяции еще раз, чтобы назначить оценки приспособленности для геномов, используя оценки новизны. В процессе оценки новизны используются объекты Novelty- Item, собранные в n_items_map в первом цикле (описанном ранее) во вре- мя моделирования прохождения лабиринта: for genome_id, genome in genomes: fitness = trial_sim.archive.evaluate_individual_novelty( genome=genome, genomes=genomes, n_items_map=n_items_map, only_fitness=True) if fitness > 1: fitness = math.log(fitness) else: fitness = 0 genome.fitness = fitness 3. Наконец, если в первом цикле обнаружен геном успешного решателя, мы присваиваем ему значение приспособленности, равное индикатив- ному показателю приспособленности, описанному ранее ( ~13.59): if solver_genome is not None: solver_genome.fitness = math.log(800000) # ~13.59 Обратите внимание, что мы применяем натуральный логарифм к полу - ченным значениям оценки новизны и к индикативной оценке новизны, чтобы сохранить их числовую близость. В результате мы сможем правильно отображать графики производительности, используя статистику, собранную в ходе эксперимента. 6.4 Функция приспособленности с оценкой новизны  155\n--- Страница 157 ---\nФункция оценки индивидуальной приспособленности Эта функция является важной частью оценки приспособленности популяции, и она вызывается из функции eval_genomes , обсуждавшейся ранее, для оценки эффективности прохождения лабиринта каждым геномом в популяции. Оценка отдельного генома как агента, проходящего лабиринт, выглядит следующим образом: def eval_individual(genome_id, genome, genomes, n_items_map, config): n_item = archive.NoveltyItem( generation=trial_sim.population.generation, genomeId=genome_id) n_items_map[genome_id] = n_item maze_env = copy.deepcopy(trial_sim.orig_maze_environment) control_net = neat.nn.FeedForwardNetwork.create(genome, config) goal_fitness = maze.maze_simulation_evaluate( env=maze_env, net=control_net, time_steps=SOLVER_TIME_STEPS, n_item=n_item, mcns=MCNS) if goal_fitness == -1: # Особь не удовлетворяет критерию минимальной приспособленности. print(\"Individ with ID %d marked for extinction, MCNS %f\" % (genome_id, MCNS)) return False record = agent.AgentRecord( generation=trial_sim.population.generation, agent_id=genome_id) record.fitness = goal_fitness record.x = maze_env.agent.location.x record.y = maze_env.agent.location.y record.hit_exit = maze_env.exit_found record.species_id = trial_sim.population.species \\ .get_species_id(genome_id) record.species_age = record.generation - \\ trial_sim.population.species.get_species(genome_id).created trial_sim.record_store.add_record(record) if not maze_env.exit_found: record.novelty = trial_sim.archive \\ .evaluate_individual_novelty(genome=genome, genomes=genomes, n_items_map=n_items_map) trial_sim.archive.update_fittest_with_genome(genome=genome, n_items_map=n_items_map) return maze_env.exit_found156  Метод оптимизации поиском новизны\n--- Страница 158 ---\nДавайте подробно разберем назначение всех основных частей реализации функции eval_individual . 1. Сначала мы создаем объект NoveltyItem для хранения информации о сте- пени новизны, связанной с конкретным геномом, и сохраняем его под ключом genome_id в словаре n_items_map : n_item = archive.NoveltyItem( generation=trial_sim.population.generation, genomeId=genome_id) n_items_map[genome_id] = n_item 2. После этого создаем глубокую копию исходной среды лабиринта, чтобы избежать побочных эффектов во время симуляции, и формируем кон- трольную нейросеть на основе предоставленного генома: maze_env = copy.deepcopy(trial_sim.orig_maze_environment) control_net = neat.nn.FeedForwardNetwork.create(genome, config) 3. Теперь, используя копию среды лабиринта и созданную контрольную нейросеть, мы запускаем симуляцию прохождения лабиринта для за- данного количества шагов: goal_fitness = maze.maze_simulation_evaluate( env=maze_env, net=control_net, time_steps=SOLVER_TIME_STEPS, n_item=n_item, mcns=MCNS) 4. После завершения симуляции возвращенная оценка целеориентирован- ной приспособленности (оценка близости к выходу из лабиринта) и дру - гие параметры симуляции и генома сохраняются в записи AgentRecord , которая затем добавляется в хранилище записей: record = agent.AgentRecord( generation=trial_sim.population.generation, agent_id=genome_id) record.fitness = goal_fitness record.x = maze_env.agent.location.x record.y = maze_env.agent.location.y record.hit_exit = maze_env.exit_foundrecord.species_id = trial_sim.population.species \\ .get_species_id(genome_id)record.species_age = record.generation - \\ trial_sim.population.species.get_species(genome_id).createdtrial_sim.record_store.add_record(record) 5. Наконец, мы оцениваем новизну данного генома, если он не является победителем, и при необходимости обновляем список наиболее под- ходящих геномов в NoveltyArchive с помощью NoveltyItem текущего ге- нома: 6.4 Функция приспособленности с оценкой новизны  157\n--- Страница 159 ---\nif not maze_env.exit_found: record.novelty = trial_sim.archive \\ .evaluate_individual_novelty(genome=genome, genomes=genomes, n_items_map=n_items_map) trial_sim.archive.update_fittest_with_genome(genome=genome, n_items_map=n_items_map) В этом эксперименте оценка приспособленности генома определяется как два отдельных значения, каждое из которых служит своей цели. Пока- затель целеориентированной приспособленности помогает проверить, было ли найдено решение, и собирает полезную статистику производительности. Оценка приспособленности на основе новизны направляет процесс нейро- эволюции в сторону максимального разнообразия поведения решателя, то есть градиент поиска решения направлен на изучение различных вариантов поведения без какой-либо явной цели. Подробности реализации можно изучить в файле исходного кода maze_experiment.py в файловом архиве книги.",
          "debug": {
            "start_page": 150,
            "end_page": 159
          }
        },
        {
          "name": "6.5 Эксперимент с простой конфигурацией лабиринта 158",
          "content": "--- Страница 159 --- (продолжение)\n6.5 экСперимент С прОСтОй кОнфигурацией лабиринта Теперь мы готовы провести эксперименты, используя простую конфигурацию лабиринта, подобную описанной в предыдущей главе. Однако для управления процессом нейроэволюции вместо целеориентированной целевой функции мы используем метод оптимизации поиском новизны. Мы надеемся, что с по- мощью метода поиска новизны удастся найти успешный решатель с меньшим количеством этапов эволюции. Схема простого лабиринта изображена на рис. 6.1. Рис. 6.1. Схема простого лабиринта Конфигурация лабиринта такая же, как в предыдущей главе. Однако нам необходимо настроить некоторые гиперпараметры NEAT для соответствия спецификациям метода поиска новизны.158  Метод оптимизации поиском новизны\n6.5 экСперимент С прОСтОй кОнфигурацией лабиринта Теперь мы готовы провести эксперименты, используя простую конфигурацию лабиринта, подобную описанной в предыдущей главе. Однако для управления процессом нейроэволюции вместо целеориентированной целевой функции мы используем метод оптимизации поиском новизны. Мы надеемся, что с по- мощью метода поиска новизны удастся найти успешный решатель с меньшим количеством этапов эволюции. Схема простого лабиринта изображена на рис. 6.1. Рис. 6.1. Схема простого лабиринта Конфигурация лабиринта такая же, как в предыдущей главе. Однако нам необходимо настроить некоторые гиперпараметры NEAT для соответствия спецификациям метода поиска новизны.158  Метод оптимизации поиском новизны\n--- Страница 160 ---\n6.5.1 Настройка гиперпараметров Целевая функция, используемая в экспериментах, описанных в этой главе, основана на метрике новизны, которая не имеет четкого верхнего гранично- го значения. Следовательно, мы не можем точно оценить пороговое значение приспособленности. Чтобы сигнализировать о появлении агента-победите- ля, мы воспользуемся ориентировочным значением, которое достаточно ве- лико, чтобы его нельзя было случайно встретить при обычном выполнении алгоритма. В качестве ориентировочного значения оценки новизны мы выбрали 800000. Однако для улучшения визуального представления графика результа- тов эксперимента мы используем натуральный логарифм значения новиз- ны. Поэтому пороговое значение приспособленности, используемое в файле конфигурации, становится равным 13.5, что немного меньше максималь- но возможной оценки приспособленности (13.59), чтобы избежать проблем с округлением чисел с плавающей запятой. Кроме того, мы увеличиваем размер популяции по сравнению со значением, описанным в предыдущей главе (250), чтобы сделать пространство поиска решения более обширным, поскольку нам необходимо изучить максимальное количество уникальных мест в лабиринте: [NEAT] fitness_criterion = max fitness_threshold = 13.5 pop_size = 500 reset_on_extinction = False Теперь в каждом испытании мы проходим через большее количество по- колений, чем в эксперименте в предыдущей главе. Поэтому мы увеличили допустимую продолжительность стагнации, чтобы дольше сохранять разно- образие видов: [DefaultStagnation] max_stagnation = 100 Все остальные гиперпараметры NEAT имеют значения, аналогичные зна- чениям, представленным в предыдущей главе. При необходимости вернитесь к пояснениям относительно выбора конкретных значений гиперпараметров в предыдущей главе. Полный перечень гиперпараметров, задействованных в эксперимен- те, содержится в файле maze_config.ini в файловом архиве книги. 6.5.2 Настройка рабочей среды Рабочая среда для проведения эксперимента должна включать все зависимо- сти и может быть создана с помощью следующих команд Anaconda: $ conda create --name maze_ns_neat python=3.5 $ conda activate maze_ns_neat 6.5 Эксперимент с простой конфигурацией лабиринта  159\n--- Страница 161 ---\n$ pip install neat-python==0.92 $ conda install matplotlib$ conda install graphviz$ conda install python-graphviz Эти команды создают и активируют виртуальную среду maze_ns_neat с Python 3.5. После этого устанавливается библиотека NEAT-Python версии 0.92, а также другие зависимости, используемые нашими утилитами визуализации. 6.5.3 Реализация движка эксперимента Реализация движка эксперимента, использованная в этой главе, по большей части похожа на реализацию, использованную в предыдущей главе, но имеет существенные отличия, которые мы обсудим в данном разделе. Цикл испытаний В этой главе мы представляем обновление реализации эксперимента. Мы реа- лизуем поддержку для запуска нескольких испытаний последовательно, пока не будет найдено решение. Такое обновление значительно упрощает последо- вательную работу с несколькими экспериментами, особенно с учетом того, что выполнение каждого испытания может занять много времени. Основной цикл движка эксперимента теперь выглядит следующим обра- зом (см. __main__ в скрипте maze_experiment.py ): print(\"Starting the %s maze experiment (Novelty Search), for %d trials\" % (args.maze, args.trials)) for t in range(args.trials): print(\"\\n\\n----- Starting Trial: %d ------\" % (t)) # Создаем архив новинок novelty_archive = archive.NoveltyArchive( threshold=args.ns_threshold, metric=maze.maze_novelty_metric) trial_out_dir = os.path.join(out_dir, str(t)) os.makedirs(trial_out_dir, exist_ok=True) solution_found = run_experiment(config_file=config_path, maze_env=maze_env, novelty_archive=novelty_archive, trial_out_dir=trial_out_dir, n_generations=args.generations, args=args, save_results=True, silent=True) print(\"\\n------ Trial %d complete, solution found: %s ------\\n\" % (t, solution_found)) Цикл запускает испытания в количестве args.trials , где значение args.tri- als предоставляется пользователем из командной строки. Первые строки цикла создают объект NoveltyArchive , который является ча- стью алгоритма поиска новизны. Позже, во время конкретного испытания, этот объект будет применяться для хранения всех соответствующих элемен- тов NoveltyItems :160  Метод оптимизации поиском новизны\n--- Страница 162 ---\nnovelty_archive = archive.NoveltyArchive( threshold=args.ns_threshold, metric=maze.maze_novelty_metric) Обратите внимание, что maze.maze_novelty_metric является ссылкой на функ - цию, которая используется для оценки новизны каждого агента-решателя. В исходном коде для этой главы представлена реализация двух функций метрики новизны: метрика поэлементного расстояния ( maze.maze_novelty_metric ); метрика евклидового расстояния ( maze.maze_novelty_metric_euclidean ). Однако в наших экспериментах мы используем первую реализацию. Вто- рая реализация предназначена для запуска дополнительных экспериментов. Функция движка эксперимента Данная функция движка имеет много сходств с функцией движка, представ- ленной в предыдущей главе, но в то же время у нее есть уникальные особен- ности, характерные для алгоритма оптимизации поиском новизны. Давайте рассмотрим наиболее важные части реализации. 1. Функция начинается с выбора определенного начального значения для генератора случайных чисел на основе текущего системного времени: seed = int(time.time()) random.seed(seed) 2. После этого она загружает конфигурацию алгоритма NEAT и создает начальную популяцию геномов: config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction, neat.DefaultSpeciesSet, neat.DefaultStagnation, config_file)p = neat.Population(config) 3. Чтобы сохранить промежуточные результаты после оценки каждо- го поколения, мы инициализируем глобальную переменную trial_sim с объектом MazeSimulationTrial . Мы используем глобальную перемен- ную, которая обеспечивает доступ с помощью функции обратного вы- зова к оценке приспособленности (eval_genomes(genomes, config)), пере- даваемой в среду NEAT-Python: global trial_sim trial_sim = MazeSimulationTrial(maze_env=maze_env, population=p, archive=novelty_archive) 4. Также традиционно мы регистрируем в объекте Population несколько ре- портеров для вывода результатов алгоритма и сбора статистики: p.add_reporter(neat.StdOutReporter(True)) stats = neat.StatisticsReporter() p.add_reporter(stats) 6.5 Эксперимент с простой конфигурацией лабиринта  161\n--- Страница 163 ---\n5. Теперь мы готовы запустить алгоритм NEAT для заданного числа по- колений и оценить результаты: start_time = time.time() best_genome = p.run(eval_genomes, n=n_generations) elapsed_time = time.time() - start_time # Отображаем лучшие геномы по поколениям. print('\\nBest genome:\\n%s' % (best_genome)) solution_found = \\ (best_genome.fitness >= config.fitness_threshold) if solution_found: print(\"SUCCESS: The stable maze solver controller was found!!!\")else: print(\"FAILURE: Failed to find the stable maze solver controller!!!\") 6. После этого собранные статистические и архивные записи можно ви- зуализировать и сохранить в файловой системе: node_names = {-1:'RF_R', -2:'RF_FR', -3:'RF_F', -4:'RF_FL', -5:'RF_L', -6: 'RF_B', -7:'RAD_F', -8:'RAD_L', -9:'RAD_B', -10:'RAD_R', 0:'ANG_VEL', 1:'VEL'} visualize.draw_net(config, best_genome, view=show_results, node_names=node_names, directory=trial_out_dir, fmt='svg')if args is None: visualize.draw_maze_records(maze_env, trial_sim.record_store.records, view=show_results) else: visualize.draw_maze_records(maze_env, trial_sim.record_store.records, view=show_results, width=args.width, height=args.height, filename=os.path.join(trial_out_dir, 'maze_records.svg'))visualize.plot_stats(stats, ylog=False, view=show_results, filename=os.path.join(trial_out_dir, 'avg_fitness.svg'))visualize.plot_species(stats, view=show_results, filename=os.path.join(trial_out_dir, 'speciation.svg'))# Сохраняем архивные записи NoveltyItemstrial_sim.archive.write_fittest_to_file( path=os.path.join(trial_out_dir, 'ns_items_fittest.txt'))trial_sim.archive.write_to_file( path=os.path.join(trial_out_dir, 'ns_items_all.txt'))162  Метод оптимизации поиском новизны\n--- Страница 164 ---\n7. Наконец, мы запускаем представленные в этой главе дополнительные процедуры визуализации, отображающие путь агентов через лабиринт. Мы делаем это, запустив симуляцию прохождения лабиринта с конт- роллером на основе нейросети лучшего решающего агента, найденного в ходе эволюции. Во время этого прогона симуляции все точки пути, посещенные решающим агентом, собираются для последующей визуа- лизации функцией draw_agent_path : maze_env = copy.deepcopy(trial_sim.orig_maze_environment) control_net = neat.nn.FeedForwardNetwork.create( best_genome, config)path_points = []evaluate_fitness = maze.maze_simulation_evaluate( env=maze_env, net=control_net, time_steps=SOLVER_TIME_STEPS, path_points=path_points)print(\"Evaluated fitness of best agent: %f\" % evaluate_fitness)visualize.draw_agent_path(trial_sim.orig_maze_environment, path_points, best_genome, view=show_results, width=args.width, height=args.height, filename=os.path.join(trial_out_dir, 'best_solver_path.svg')) В конце функция run_experiment возвращает логическое значение, указы- вающее, был найден во время испытания успешный агент-решатель задачи лабиринта или нет. Изучите реализацию функции run_experiment(config_file, maze_env, novelty_archive, trial_out_dir, args=None, n_generations=100, save_ results=False, silent=False) в файле maze_experiment.py из файлового архива книги. 6.5.4 Простой эксперимент по навигации в лабиринте с поиском новизны Убедитесь, что вы скопировали все связанные скрипты Python и файлы кон- фигурации (maze_config.ini и medium_maze.txt ) в локальный каталог из файлового архива книги. Теперь войдите в рабочий каталог и выполните следующую команду в удобном для вас приложении терминала: python maze_experiment.py -g 500 -t 10 -m medium --width 300 --height 150 Не забудьте активировать соответствующую виртуальную среду с по- мощью команды conda activate maze_ns_neat. 6.5 Эксперимент с простой конфигурацией лабиринта  163\n--- Страница 165 ---\nПредыдущая команда запускает 10 испытаний эксперимента по нави- гации в лабиринте с простой конфигурацией, загруженной из файла medi- um_maze.txt . Алгоритм нейроэволюции оценивает 500 поколений решателей лабиринтов в каждом испытании, используя данные конфигурации NEAT, загруженные из файла maze_config.ini . Параметры width и height задают раз- меры секции графика (подробнее см. в реализации функции visualize.draw_ maze_records ). Спустя 99 поколений эволюции успешный агент-решатель лабиринта был найден в поколении 100. Имеются общие статистические данные о популя- ции геномов в последнем поколении эволюции. В консольном выводе завер- шенной программы Python вы увидите следующий текст для последнего по- коления эволюции: ****** Running generation 100 ****** Maze solved in 391 steps Population's average fitness: 1.28484 stdev: 0.90091Best fitness: 13.59237 - size: (2, 8) - species 1 - id 48354 Best individual in generation 100 meets fitness threshold - complexity: (2, 8) Далее отображается конфигурация генома-победителя и общая статистика прогона: Best genome: Key: 48354 Fitness: 13.592367006650065Nodes: 0 DefaultNodeGene(key=0, bias=-2.1711339938349026, response=1.0,activation=sigmoid, aggregation=sum) 1 DefaultNodeGene(key=1, bias=6.576480565646596, response=1.0,activation=sigmoid, aggregation=sum)Connections: DefaultConnectionGene(key=(-10, 1), weight=-0.5207773885939109,enabled=True) DefaultConnectionGene(key=(-9, 0), weight=1.7778928210387814,enabled=True) DefaultConnectionGene(key=(-7, 1), weight=-2.4940590667086524, enabled=False) DefaultConnectionGene(key=(-6, 1), weight=-1.3708732457648565,enabled=True) DefaultConnectionGene(key=(-4, 0), weight=4.482428082179011,enabled=True) DefaultConnectionGene(key=(-4, 1), weight=-1.3103728328721098,enabled=True) DefaultConnectionGene(key=(-3, 0), weight=-0.4583080031587811,enabled=True) DefaultConnectionGene(key=(-3, 1), weight=4.643599450804774,164  Метод оптимизации поиском новизны\n--- Страница 166 ---\nenabled=True) DefaultConnectionGene(key=(-2, 1), weight=-0.9055329546235956,enabled=True) DefaultConnectionGene(key=(-1, 0), weight=-1.5899992185951817,enabled=False)SUCCESS: The stable maze solver controller was found!!! Record store file: out/maze_ns/medium/0/data.pickle Random seed: 1567086899Trial elapsed time: 7452.462 secPlot figure width: 6.8, height: 7.0Maze solved in 391 stepsEvaluated fitness of best agent: 1.000000 Plot figure width: 7.8, height: 4.0 Консольный вывод сообщает нам, что геном победителя, кодирующий нейросеть успешного решателя лабиринта, имеет только два гена узла и во- семь генов связей. Эти гены соответствуют двум выходным узлам в нейросе- ти контроллера, причем восемь соединений используются для установления связей с входами. Итоговая конфигурация нейросети показана на рис. 6.2. Рис. 6.2. Конфигурация нейросети успешного решателя лабиринта Данная конфигурация нейросети успешного решателя лучше, чем конфи- гурация, описанная в предыдущей главе, которая была с использованием це- леориентированного метода оптимизации. В этом эксперименте оптимальная конфигурация нейросети полностью исключает скрытые узлы, и эволюцион- ный процесс занимает меньше поколений, чтобы найти ее. Таким образом, мы можем предположить, что метод оптимизации поис - ком новизны по крайней мере так же эффективен, как и метод, ориентиро- ванный на цель. Это наблюдается даже при том, что метод оптимизации по- иском новизны вообще не учитывает близость к конечной цели, а всего лишь вознаграждает новое поведение. Процесс нейроэволюции привел к созданию успешного агента-решателя задачи лабиринта, без намеков на близость к ко- нечной цели (выходу из лабиринта), и это просто удивительно. Также интересно посмотреть на график видообразования во время эволю- ции (рис. 6.3). 6.5 Эксперимент с простой конфигурацией лабиринта  165\n--- Страница 167 ---\nПоколенияВидообразованиеРазмер по видам Рис. 6.3. График видообразования На графике видообразования видно, что общее количество видов в ходе эволюционного процесса не превышает девяти. Кроме того, большинство из них присутствуют с самых первых поколений эволюции, пока не будет най- ден успешный решатель. Визуализация записей агента Мы использовали метод визуализации записей агента, который был представ- лен в предыдущей главе, и добавили новый метод для визуализации пути аген- та через лабиринт. Записи агентов для каждого завершенного испытания автоматически со- храняются в виде SVG-файла obj_medium_maze_records.svg в выходном каталоге соответствующего эксперимента. Визуализация записей агентов для эксперимента, описанного в этой главе, показана на рис. 6.4.166  Метод оптимизации поиском новизны\n--- Страница 168 ---\nПриспособленность < 0.8Приспособленность > = 0.8, виды: 8 Рис. 6.4. Визуализация записей агента Верхняя часть графика отображает конечные позиции агентов, принад- лежащих к наиболее приспособленным видам, у которых целеориентиро- ванное значение показателя приспособленности выше 0,8. Мы смогли найти восемь видов, которые исследовали почти все области лабиринта и наконец смогли найти выход из лабиринта. В то же время даже эволюционные не- удачники (нижняя часть графика) продемонстрировали весьма выраженное исследовательское поведение, равномерно заполняя первую половину обла- сти лабиринта (сравните это с аналогичным графиком в предыдущей главе). Кроме того, важно отметить, что восемь из девяти видов, созданных в ходе эволюционного процесса, демонстрируют самые высокие целевые показате- ли приспособленности; то есть они были почти в состоянии достигнуть вы- хода из лабиринта (и один из них в конечном счете достиг его). Это достиже- ние резко контрастирует с экспериментом в предыдущей главе, где только половина всех видов (шесть из двенадцати) достигли таких же результатов. Однако наиболее захватывающая визуализация представляет собой путь успешного агента, который смог найти выход из лабиринта (рис. 6.5). 6.5 Эксперимент с простой конфигурацией лабиринта  167\n--- Страница 169 ---\nИндекс генома: 48354, длина пути: 390 Рис. 6.5. Путь успешного агента, который нашел выход из лабиринта Эту визуализацию можно найти в выходном каталоге эксперимента в файле best_solver_path.svg . Как вы можете видеть, успешный агент, решающий задачу лабиринта, смог най- ти почти оптимальный путь через лабиринт, хотя вначале он немного запутался. Просто удивительно, что такой извилистый путь через лабиринт может быть найден без малейшего намека на местоположение выхода из лабиринта, а только путем вознаграждения за новизну каждого промежуточного решения. 6.5.5 Упражнение 1 1. Установите для параметра размера популяции (pop_size) в файле maze_ config.ini значение 250. Проверьте, можно ли найти в этом случае ре- шатель лабиринтов. 2. Измените значение параметра, указывающего вероятность добавле- ния нового узла (node_add_prob ). Был ли процесс нейроэволюции в со- стоянии найти решение и является ли оно оптимальным с топологиче- ской точки зрения? 3. Измените исходную конфигурацию генома, чтобы вначале не было скры- тых узлов ( num_hidden ). Как это влияет на производительность алгоритма? 4. Попробуйте использовать другую метрику новизны, которая предо- ставляется с исходным кодом (maze.maze_novelty_metric_euclidean ), и по- смотрите, что произойдет. 5. Измените параметр командной строки location_sample_rate со значения по умолчанию (4000), которое позволяет включать только конечную по- зицию решателя лабиринта в его вектор поведения. Попробуйте зна- чения меньше 400 (количество шагов моделирования лабиринта). На- пример, если мы установим для этого параметра значение 100, вектор поведения будет включать в себя координаты максимум четырех точек траектории для каждого решающего агента. Посмотрите, как этот па- раметр может влиять на производительность алгоритма. Вы можете за- дать значение эт ого параметра, выполнив следующую команду: python maze_experiment.py -g 500 -t 10 -r 100 -m medium --width 300 --height 150 Предыдущая команда запускает эксперимент простого лабиринта с пара- метром location_sample_rate , равным 100.168  Метод оптимизации поиском новизны",
          "debug": {
            "start_page": 159,
            "end_page": 169
          }
        },
        {
          "name": "6.6 Эксперимент со сложной конфигурацией лабиринта 169",
          "content": "--- Страница 170 --- (продолжение)\n6.6 экСперимент СО СлОжнОй кОнфигурацией лабиринта В следующем эксперименте мы оценим эффективность метода оптимизации поиском новизны в более сложной задаче. В этой задаче мы пытаемся обучить агента, способного найти путь через лабиринт со сложной конфигурацией. Для этого эксперимента мы используем сложную для прохождения кон- фигурацию лабиринта, представленную в предыдущей главе. Такой подход позволяет сравнивать результаты, полученные с помощью метода оптимиза- ции поиском новизны, с результатами, полученными с помощью метода оп- тимизации, основанного на близости к цели, использованного в предыдущей главе. Конфигурация лабиринта повышенной сложности показана на рис. 6.6. Рис. 6.6. Конфигурация лабиринта повышенной сложности Эта конфигурация лабиринта идентична описанной в главе 5. При необхо- димости обратитесь к этой главе за подробным описанием. 6.6.1 Настройка гиперпараметров и рабочей среды Гиперпараметры для этого эксперимента те же, что мы использовали ранее в дан- ной главе для эксперимента с простым лабиринтом. Мы решили оставить гиперпа- раметры без изменений, чтобы проверить, насколько хорошо алгоритм обобщается при попытке найти решение задачи в той же области, но с другой конфигурацией. Рабочая среда для этого эксперимента полностью совместима со средой, уже созданной для эксперимента с простым лабиринтом. Поэтому мы также используем прежнюю среду. 6.6.2 Выполнение эксперимента по прохождению труднодоступного лабиринта Для запуска этого эксперимента мы можем использовать тот же движок, кото- рый разработали для эксперимента с простым лабиринтом, с той лишь разни- цей, что вначале должны быть указаны другие параметры командной строки. 6.6 Эксперимент со сложной конфигурацией лабиринта  169\n6.6 экСперимент СО СлОжнОй кОнфигурацией лабиринта В следующем эксперименте мы оценим эффективность метода оптимизации поиском новизны в более сложной задаче. В этой задаче мы пытаемся обучить агента, способного найти путь через лабиринт со сложной конфигурацией. Для этого эксперимента мы используем сложную для прохождения кон- фигурацию лабиринта, представленную в предыдущей главе. Такой подход позволяет сравнивать результаты, полученные с помощью метода оптимиза- ции поиском новизны, с результатами, полученными с помощью метода оп- тимизации, основанного на близости к цели, использованного в предыдущей главе. Конфигурация лабиринта повышенной сложности показана на рис. 6.6. Рис. 6.6. Конфигурация лабиринта повышенной сложности Эта конфигурация лабиринта идентична описанной в главе 5. При необхо- димости обратитесь к этой главе за подробным описанием. 6.6.1 Настройка гиперпараметров и рабочей среды Гиперпараметры для этого эксперимента те же, что мы использовали ранее в дан- ной главе для эксперимента с простым лабиринтом. Мы решили оставить гиперпа- раметры без изменений, чтобы проверить, насколько хорошо алгоритм обобщается при попытке найти решение задачи в той же области, но с другой конфигурацией. Рабочая среда для этого эксперимента полностью совместима со средой, уже созданной для эксперимента с простым лабиринтом. Поэтому мы также используем прежнюю среду. 6.6.2 Выполнение эксперимента по прохождению труднодоступного лабиринта Для запуска этого эксперимента мы можем использовать тот же движок, кото- рый разработали для эксперимента с простым лабиринтом, с той лишь разни- цей, что вначале должны быть указаны другие параметры командной строки. 6.6 Эксперимент со сложной конфигурацией лабиринта  169\n--- Страница 171 ---\nВы можете запустить эксперимент со сложным лабиринтом с помощью следу - ющей команды: $ python maze_experiment.py -m hard -g 500 -t 10 --width 200 --height 200 Эта команда запускает эксперимент со сложным лабиринтом для серии из 10 испытаний по 500 поколений в каждом. Параметры width и height определя- ют размеры рабочей области для визуализации записей, собранных во время эксперимента. Используя библиотеку NEAT-Python для эксперимента со сложным лаби- ринтом, мы не смогли найти успешный решатель в течение 10 испытаний, даже с помощью метода оптимизации поиском новизны. Тем не менее ре- зультаты, полученные с помощью поиска новизны, являются более много- обещающими, чем с помощью метода целеориентированной оптимизации из предыдущей главы. Вы можете увидеть это на рис. 6.7, где показаны конеч- ные позиции агент ов во время симуляции прохождения лабиринта. Приспособленность < 0.8Приспособленность > = 0.8, виды: 0 Рис. 6.7. Визуализация конечных позиций агентов-решателей задачи лабиринта170  Метод оптимизации поиском новизны\n--- Страница 172 ---\nГрафик, который визуализирует конечные позиции всех оцененных аген- тов, показывает, что в ходе этого эксперимента за счет оптимизации поис - ком новизны было исследовано больше областей лабиринта, чем при попыт - ке ориентации на цель. Кроме того, вы можете видеть, что некоторые виды почти достигли финиша, оказавшись всего в нескольких шагах от выхода из лабиринта. Путь наиболее успешного агента показан на рис. 6.8. Рис. 6.8. Путь наиболее успешного агента, решающего задачу лабиринта Путь через лабиринт, пройденный наиболее успешным агентом, демон- стрирует, что агент смог обнаружить ключевые отношения между входами датчиков и маневрами, которые необходимо выполнить. Тем не менее ему все еще не хватает точности в применении сигналов управления. Из-за это- го недостатка некоторые управляющие действия формируют неэффектив- ную траекторию, напрасно расходующую драгоценное время на прохожде- ние лабиринта. Наконец, интересно взглянуть на топологию нейросети самого успешного решателя задачи лабиринта (рис. 6.9). Вы можете видеть, что в принятие решения вовлечены все входы датчи- ков, в отличие от топологии нейросети, разработанной в предыдущем экс- перименте этой главы. Кроме того, топология включает в себя два скрытых узла, что позволяет агенту реализовывать сложную стратегию управления для прохождения более трудного лабиринта. 6.6 Эксперимент со сложной конфигурацией лабиринта  171\n--- Страница 173 ---\nРис. 6.9. Топология наиболее успешной нейросети Несмотря на то что в этом эксперименте с использованием библиотеки NEAT-Python нам не удалось до конца обучить решателя задачи лабиринта с помощью метода оптимизации поиска новизны, это скорее проблема неэф- фективной реализации алгоритма NEAT библиотекой, чем недостаток метода поиска новизны. Я реализовал алгоритм NEAT на языке программирования GO, кото- рый с высокой эффективностью решает задачу прохождения сложно-го лабиринта. Вы можете получить код на GitHub по адресу https:// github.com/yaricom/goNEAT_ NS. 6.6.3 Упражнение 2 В файловом архиве исходного кода для этой главы также представлена реа- лизация движка эксперимента на основе библиотеки Python MultiNEAT, ко- торую мы обсуждали в главе 2. Вы можете попытаться использовать этот код для решения задачи прохож - дения сложного лабиринта следующим образом. 1. Обновите текущую среду Anaconda, установив библиотеку Python MultiNEAT с помощью следующей команды: $ conda install -c conda-forge multineat 172  Метод оптимизации поиском новизны\n--- Страница 174 ---\n2. Запустите движок эксперимента на основе библиотеки MultiNEAT: $ python maze_experiment_multineat.py -m hard -g 500 -t 10 --width 200 --height 200 Эти команды устанавливают библиотеку MultiNEAT в текущей среде Anaconda и запускают 10 испытаний (по 500 поколений в каждом) экспери- мента со сложным лабиринтом с использованием соответствующего движка эксперимента.",
          "debug": {
            "start_page": 170,
            "end_page": 174
          }
        },
        {
          "name": "6.7 Заключение 173",
          "content": "--- Страница 174 --- (продолжение)\n6.7 заключение В этой главе вы узнали о методе оптимизации поиском новизны и о том, как его можно использовать для управления процессом нейроэволюции в таких проблемных условиях, как прохождение лабиринта. Мы провели те же экспе- рименты по прохождению лабиринта, что и в предыдущей главе. После этого сравнили полученные результаты, чтобы определить, имеет ли метод поиска новизны преимущества по сравнению с методом целеориентированной опти- мизации, рассмотренным в предыдущей главе. Вы получили практический опыт написания исходного кода на Python и экспериментировали с настройкой важных гиперпараметров алгоритма NEAT. Также познакомились с новым методом визуализации, позволяющим увидеть путь агента через лабиринт. С помощью этого метода вы можете легко сравнить, как разные агенты пытаются решить проблему навигации в лабиринте, и сделать вывод, является найденный путь через лабиринт оп- тимальным или нет. В следующей главе представлены более продвинутые приложения алго- ритма NEAT. Мы начнем с задачи зрительного различения и познакомим вас с расширением HyperNEAT алгоритма NEAT. Метод HyperNEAT позволяет работать с крупномасштабными нейросетями, охватывающими тысячи или миллионы параметров. Операции такого масштаба невозможны с классиче- ским алгоритмом NEAT. 6.7 Заключение  173\n6.7 заключение В этой главе вы узнали о методе оптимизации поиском новизны и о том, как его можно использовать для управления процессом нейроэволюции в таких проблемных условиях, как прохождение лабиринта. Мы провели те же экспе- рименты по прохождению лабиринта, что и в предыдущей главе. После этого сравнили полученные результаты, чтобы определить, имеет ли метод поиска новизны преимущества по сравнению с методом целеориентированной опти- мизации, рассмотренным в предыдущей главе. Вы получили практический опыт написания исходного кода на Python и экспериментировали с настройкой важных гиперпараметров алгоритма NEAT. Также познакомились с новым методом визуализации, позволяющим увидеть путь агента через лабиринт. С помощью этого метода вы можете легко сравнить, как разные агенты пытаются решить проблему навигации в лабиринте, и сделать вывод, является найденный путь через лабиринт оп- тимальным или нет. В следующей главе представлены более продвинутые приложения алго- ритма NEAT. Мы начнем с задачи зрительного различения и познакомим вас с расширением HyperNEAT алгоритма NEAT. Метод HyperNEAT позволяет работать с крупномасштабными нейросетями, охватывающими тысячи или миллионы параметров. Операции такого масштаба невозможны с классиче- ским алгоритмом NEAT. 6.7 Заключение  173\n--- Страница 176 ---\nЧасть III Передовые методы нейроэволюции В этой части обсуждаются передовые методы нейроэволюции и способы их использования для решения практических задач. Вы узнаете о продвинутых методах нейроэволюции и найдете идеи для новых проектов. Часть состоит из следующих глав: главы 7 «Зрительное различение с NEAT на основе гиперкуба»; главы 8 «Метод ES-HyperNEAT и задача сетчатки»; главы 9 «Коэволюция и метод SAFE»; главы 10 «Глубокая нейроэволюция».",
          "debug": {
            "start_page": 174,
            "end_page": 177
          }
        }
      ]
    },
    {
      "name": "Глава 7. Зрительное различение с NEAT на основе гиперкуба 177",
      "chapters": [
        {
          "name": "7.1 Технические требования 177",
          "content": "--- Страница 178 --- (продолжение)\nГлава 7 Зрительное различение с NEAT на основе гиперкуба В этой главе вы узнаете об основных принципах, заложенных в основу ал- горитма NEAT на основе гиперкуба, и задачах, для решения которых он был разработан. Мы рассмотрим проблемы, которые возникают при попытке ис- пользовать прямое кодирование генома с крупномасштабными искусствен- ными нейронными сетями, и покажем, как они могут быть решены путем введения схемы косвенного кодирования генома. Вы узнаете, как сети, про- изводящие составные паттерны ( compositional pattern producing network, CPPN), могут использоваться для хранения информации о кодировании ге- нома с очень высокой степенью сжатия и как CPPN используются алгорит - мом HyperNEAT. Наконец, вы познакомитесь с практическими примерами, которые демонстрируют мощь алгоритма HyperNEAT. В этой главе мы обсудим следующие темы: проблема с прямым кодированием масштабных естественных сетей в алгоритме NEAT, и как HyperNEAT может помочь за счет метода кос- венного кодирования; эволюция CPPN при помощи NEAT для нахождения геометрических закономерностей в гиперкубе, что позволяет нам эффективно кодиро- вать паттерны связей в целевой нейросети; применение метода HyperNEAT для обнаружения и распознавания объ- ектов в поле зрения; определение целевой функции для эксперимента по зрительному раз- личению; обсуждение результатов эксперимента по зрительному различению. 7.1 техниче Ские треб Ования Для проведения экспериментов, описанных в этой главе, ваш компьютер дол- жен удовлетворять следующим техническим требованиям: Windows 8/10, macOS 10.13 или новее, или современный Linux; Anaconda Distribution версия 2019.03 или новее. Исходный код примеров этой главы можно найти в каталоге Chapter7 в фай- ловом архиве книги.\n7.1 техниче Ские треб Ования Для проведения экспериментов, описанных в этой главе, ваш компьютер дол- жен удовлетворять следующим техническим требованиям: Windows 8/10, macOS 10.13 или новее, или современный Linux; Anaconda Distribution версия 2019.03 или новее. Исходный код примеров этой главы можно найти в каталоге Chapter7 в фай- ловом архиве книги.",
          "debug": {
            "start_page": 178,
            "end_page": 178
          }
        },
        {
          "name": "7.2 Косвенное кодирование нейросетей с CPPN 178",
          "content": "--- Страница 179 --- (продолжение)\n7.2 кОСвенн Ое кОДирОвание нейр ОСетей С CppN В предыдущих главах вы узнали о прямом кодировании нейросетей на ос- нове позаимствованной у природы концепции генотипа, который в соотно- шении 1:1 отображается на фенотип, представляющий топологию нейросети. Это отображение дает возможность использовать расширенные функции ал- горитма NEAT, такие как номер инновации, позволяющий отслеживать, когда в ходе эволюции появилась конкретная мутация. Каждый ген в геноме имеет определенное значение числа инноваций, что позволяет быстро и точно скре- щивать родительские геномы, чтобы произвести потомство. Несмотря на то что эта возможность предоставляет огромные преимущества, а также снижает вычислительные затраты, необходимые для сопоставления родительских ге- номов во время рекомбинации, прямое кодирование, используемое для пред- ставления топологии фенотипа, имеет существенный недостаток, поскольку ограничивает размер кодируемой нейросети. Чем больше соответствующая нейросеть, тем больше становится геном, который оценивается во время эво- люции, и это влечет за собой огромные вычислительные затраты. Существует много задач, в первую очередь связанных с распознаванием образов в изображениях или других многомерных источниках данных, кото- рые нуждаются в сетях со сложной топологией, включающей большое коли- чество слоев, узлов и связей между ними. Такие конфигурации не могут быть эффективно обработаны классическим алгоритмом NEAT из-за ограничений прямого кодирования. Для устранения этого недостатка был предложен новый метод кодирова- ния фенотипа нейросети, сохраняющий все преимущества алгоритма NEAT. Мы обсудим его в следующем разделе. 7.2.1 Кодирование CPPN Предложенная схема кодирования использует метод получения паттернов связей в фенотипе целевой нейросети (которую мы хотим обучить) путем за- проса к другой специализированной нейронной сети о весах связей между уз- лами. Эта специализированная нейронная сеть называется CPPN. Ее основная задача состоит в том, чтобы представить паттерны связей фенотипа целевой нейросети как функцию его геометрии. Результирующий паттерн связей пред- ставлен в виде четырехмерного гиперкуба. Каждая точка гиперкуба кодирует связь между двумя связанными узлами в фенотипе целевой нейросети и опи- сывается четырьмя числами: координатами исходного узла и координатами целевого узла. В свою очередь, соединительная CPPN принимает в качестве входных данных каждую точку гиперкуба и вычисляет вес связей между каж- дым узлом в фенотипе целевой нейросети. Кроме того, связь между двумя узлами не экспрессируется, если значение веса связи, возвращаемого CPPN, меньше минимального порогового значения (wmin). Таким образом, мы можем определить соединительную CPPN как четырехмерную функцию, возвращаю- щую вес связи в соответствии со следующей формулой: ( )1 1 2 2 wCPPNx,y,x,y. =178  Зрительное различение с NEAT на основе гиперкуба\n7.2 кОСвенн Ое кОДирОвание нейр ОСетей С CppN В предыдущих главах вы узнали о прямом кодировании нейросетей на ос- нове позаимствованной у природы концепции генотипа, который в соотно- шении 1:1 отображается на фенотип, представляющий топологию нейросети. Это отображение дает возможность использовать расширенные функции ал- горитма NEAT, такие как номер инновации, позволяющий отслеживать, когда в ходе эволюции появилась конкретная мутация. Каждый ген в геноме имеет определенное значение числа инноваций, что позволяет быстро и точно скре- щивать родительские геномы, чтобы произвести потомство. Несмотря на то что эта возможность предоставляет огромные преимущества, а также снижает вычислительные затраты, необходимые для сопоставления родительских ге- номов во время рекомбинации, прямое кодирование, используемое для пред- ставления топологии фенотипа, имеет существенный недостаток, поскольку ограничивает размер кодируемой нейросети. Чем больше соответствующая нейросеть, тем больше становится геном, который оценивается во время эво- люции, и это влечет за собой огромные вычислительные затраты. Существует много задач, в первую очередь связанных с распознаванием образов в изображениях или других многомерных источниках данных, кото- рые нуждаются в сетях со сложной топологией, включающей большое коли- чество слоев, узлов и связей между ними. Такие конфигурации не могут быть эффективно обработаны классическим алгоритмом NEAT из-за ограничений прямого кодирования. Для устранения этого недостатка был предложен новый метод кодирова- ния фенотипа нейросети, сохраняющий все преимущества алгоритма NEAT. Мы обсудим его в следующем разделе. 7.2.1 Кодирование CPPN Предложенная схема кодирования использует метод получения паттернов связей в фенотипе целевой нейросети (которую мы хотим обучить) путем за- проса к другой специализированной нейронной сети о весах связей между уз- лами. Эта специализированная нейронная сеть называется CPPN. Ее основная задача состоит в том, чтобы представить паттерны связей фенотипа целевой нейросети как функцию его геометрии. Результирующий паттерн связей пред- ставлен в виде четырехмерного гиперкуба. Каждая точка гиперкуба кодирует связь между двумя связанными узлами в фенотипе целевой нейросети и опи- сывается четырьмя числами: координатами исходного узла и координатами целевого узла. В свою очередь, соединительная CPPN принимает в качестве входных данных каждую точку гиперкуба и вычисляет вес связей между каж- дым узлом в фенотипе целевой нейросети. Кроме того, связь между двумя узлами не экспрессируется, если значение веса связи, возвращаемого CPPN, меньше минимального порогового значения (wmin). Таким образом, мы можем определить соединительную CPPN как четырехмерную функцию, возвращаю- щую вес связи в соответствии со следующей формулой: ( )1 1 2 2 wCPPNx,y,x,y. =178  Зрительное различение с NEAT на основе гиперкуба\n--- Страница 180 ---\nИсходный узел фенотипа целевой нейросети находится в (x1, y1), а конеч- ный узел в (x2, y2). Другая существенная особенность CPPN состоит в том, что в отличие от обычных нейросетей, которые используют только один тип функции акти- вации для каждого узла (обычно из семейства сигмовидных функций), CPPN могут использовать в качестве активаторов узла несколько геометрических функций. Благодаря этому CPPN могут выражать в создаваемых паттернах связей богатый набор геометрических последовательностей: симметрия (функция Гаусса); несовершенная симметрия (функция Гаусса в сочетании с асимметрич- ной системой координат); повторение (синус); повторение с вариациями (синус в сочетании с системой координат, которая не повторяется). Учитывая упомянутые особенности CPPN, мы можем предположить, что создаваемый ими паттерн связей способен описывать любую топологию фе- нотипа целевой нейросети. Кроме того, паттерн связей может использоваться для кодирования крупномасштабных топологий путем обнаружения законо- мерностей в обучающих данных и повторного использования того же набора генов в CPPN для кодирования повторений в фенотипе целевой нейросети. 7.2.2 Нейроэволюция с развитием топологии на основе гиперкуба Упомянутая выше методика была изобретена Кеннетом О. Стэнли и получила название нейроэволюции с развитием топологии на основе гиперкуба (hyper - cube-based neuroevolution of augmenting topologies, HyperNEAT). Как следует из названия, это расширение алгоритма NEAT, который мы уже использовали в этой книге. Основное различие между старым и новым методами состоит в том, что метод HyperNEAT использует схему косвенного кодирования, ос- нованную на CPPN. В ходе эволюции метод HyperNEAT применяет алгоритм NEAT для развития популяции геномов, кодирующих топологию соедини- тельной CPPN. После этого каждая созданная CPPN может использоваться для формирования паттернов связей в пределах конкретного фенотипа целевой нейросети. Наконец, этот фенотип нейросети можно оценить в пространстве предметной области. До сих пор мы рассуждали о том, как паттерны связей развиваются с ис - пользованием NEAT и CPPN и как они могут применяться к узлам фенотипа целевой нейросети. Однако мы не упомянули, откуда берется начальное гео- метрическое расположение узлов. Ответственность за объявление узлов и их позиции (расположение) возлагается на человека-архитектора. Архитектор анализирует пространство предметной области и использует наиболее под- ходящий макет. Исходную компоновку узлов фенотипа целевой нейросети принято назы- вать субстратом. Существует несколько типов конфигурации субстрата (ма- кета), доказавших свою эффективность при решении конкретных задач: 7.2 Косвенное кодирование нейросетей с CPPN  179\n--- Страница 181 ---\nдвумерная сетка – регулярная сетка узлов сети в двумерном декарто- вом пространстве с центром в (0,0); трехмерная сетка – регулярная сетка узлов сети в трехмерном декарто- вом пространстве с центром в (0,0,0); сэндвич пространства состояний – две двумерные плоские сетки с со- ответствующими исходными и целевыми узлами, в которых один слой может отправлять соединения только в направлении другого; круговая – регулярная радиальная структура, подходящая для опреде- ления закономерностей в радиальной геометрии на основе полярных координат. Располагая узлы нейросети на субстрате в подходящей компоновке, мож - но использовать закономерности в геометрии предметной области. Это зна- чительно повышает эффективность кодирования за счет использования со- единительной CPPN для создания паттернов связей между узлами субстрата. Далее мы обсудим основы эксперимента по зрительному различению. Более подробное описание метода HyperNEAT приведено в главе 1.",
          "debug": {
            "start_page": 179,
            "end_page": 181
          }
        },
        {
          "name": "7.3 Основы эксперимента по зрительному различению 180",
          "content": "--- Страница 181 --- (продолжение)\n7.3 О СнОвы экСперимента пО зрительн Ому различению Как мы уже упоминали, основным преимуществом косвенного кодирова- ния, используемого алгоритмом HyperNEAT, является возможность эконо- мично кодировать топологию крупномасштабной нейросети. В этом разделе мы рассмот рим эксперимент, нацеленный на проверку способности метода HyperNEAT обучать крупномасштабные нейросети. Задачи зрительного рас- познавания образов обычно нуждаются в больших нейросетях из-за высокой размерности входных данных (высота изображения, умноженная на ширину изображения). В этой главе мы рассмотрим разновидность задачи распознава- ния образов, именуемую задачей зрительного различения. Задача зрительного различения состоит в том, чтобы отличить крупный объект от маленького объекта в двумерном зрительном пространстве неза- висимо от их расположения в поле зрения и положения относительно друг друга. Задача зрительного различения решается специализированной раз- личающей нейросетью – зрительным дискриминатором, – которая развива- ется на субстрате, сконфигурированном как сэндвич пространства состоя- ний с двумя слоями: зрительное поле представляет собой двумерный массив датчиков, ко- торые могут находиться в двух состояниях: включено или выключено (черно-белое изображение); целевое поле – это двумерный массив выходов со значениями актива- ции в диапазоне [0,1]. Схема задачи зрительного различения показана на рис. 7.1.180  Зрительное различение с NEAT на основе гиперкуба\n7.3 О СнОвы экСперимента пО зрительн Ому различению Как мы уже упоминали, основным преимуществом косвенного кодирова- ния, используемого алгоритмом HyperNEAT, является возможность эконо- мично кодировать топологию крупномасштабной нейросети. В этом разделе мы рассмот рим эксперимент, нацеленный на проверку способности метода HyperNEAT обучать крупномасштабные нейросети. Задачи зрительного рас- познавания образов обычно нуждаются в больших нейросетях из-за высокой размерности входных данных (высота изображения, умноженная на ширину изображения). В этой главе мы рассмотрим разновидность задачи распознава- ния образов, именуемую задачей зрительного различения. Задача зрительного различения состоит в том, чтобы отличить крупный объект от маленького объекта в двумерном зрительном пространстве неза- висимо от их расположения в поле зрения и положения относительно друг друга. Задача зрительного различения решается специализированной раз- личающей нейросетью – зрительным дискриминатором, – которая развива- ется на субстрате, сконфигурированном как сэндвич пространства состоя- ний с двумя слоями: зрительное поле представляет собой двумерный массив датчиков, ко- торые могут находиться в двух состояниях: включено или выключено (черно-белое изображение); целевое поле – это двумерный массив выходов со значениями актива- ции в диапазоне [0,1]. Схема задачи зрительного различения показана на рис. 7.1.180  Зрительное различение с NEAT на основе гиперкуба\n--- Страница 182 ---\nЗрительное поле Целевое поле (обнаружение)Активация типа max Рис. 7.1. Задача зрительного различения На рисунке мы видим, что различаемые объекты представлены в виде двух квадратов, разделенных пустым пространством. Большой объект в три раза превосходит маленький по каждому измерению. Алгоритм, который мы пы- таемся построить, должен найти центр более крупного объекта. Обнаружение основано на измерении значений активации узлов нейросети в целевом поле. Положение узла с наивысшим значением активации указывает на центр об- наруженного объекта. Наша цель – найти правильный паттерн связей между зрительным полем и целевым полем, который сопоставляет выходной узел с наибольшей активацией в целевом поле с центром большого объекта в зри- тельном поле. Кроме того, результат работы нейросети не должен зависеть от взаимного расположения объектов. Алгоритм для задачи зрительного различения должен оценивать большое количество входных данных – значений, представляющих ячейки в зритель- ном поле. Кроме того, успешный алгоритм должен обнаружить стратегию, способную обрабатывать входные данные из нескольких ячеек одновремен- но. Такая стратегия должна основываться на общем принципе, позволяющем определять относительные размеры объектов в зрительном поле, которое в нашем эксперименте представлено в виде двумерной сетки. Следователь- но, общим геометрическим принципом, который должен быть обнаружен, является локальность. Мы можем использовать принцип локальности в конфигурации целевой (различающей) нейросети, применяя определенный паттерн в схеме соеди- нений между узлами зрительного поля и целевого поля. В этой схеме соеди- нений отдельные узлы зрительного поля соединены со множеством смежных узлов вывода вокруг определенного местоположения в целевом поле. В ре- зультате активация выходного узла зависит от того, как много сигналов по- ступает в него через соединения с отдельными входными узлами. Чтобы эффективно использовать упомянутый ранее принцип локально- сти, представление связей должно учитывать геометрию субстрата различа- ющей нейросети и тот факт, что правильный паттерн связей повторяется по 7.3 Основы эксперимента по зрительному различению  181\n--- Страница 183 ---\nвсей сети. Наилучшим кандидатом для такого представления является CPPN, которая может один раз обнаружить локальный паттерн связей и повторить его по сетке субстрата для сколь угодно большого разрешения. 7.3.1 Определение целевой функции Основная задача зрительного дискриминатора – правильно определить поло- жение более крупного объекта независимо от взаимного расположения обо- их объектов. Отсюда мы можем определить целевую функцию для управления процессом нейроэволюции. Целевая функция должна основываться на евкли- довом расстоянии между точным положением более крупного объекта в поле зрения и его прогнозируемым положением в целевом поле. Функция ошибки может быть представлена непосредственно как евклидо- во расстояние между фактическим и прогнозируемым положениями следу - ющим образом: ()22 1i i iGP ==−∑ , где L – функция ошибки, Gi – истинные координаты большого объекта, а Pi – координаты, предсказанные нейросетью. Используя функцию ошибки, определенную ранее, мы можем представить целевую функцию следующим образом: 10n max. .D=− Здесь Dmax – максимально возможное расстояние между двумя точками в пре- делах целевого пространства поля. Формула целевой функции гарантирует, что рассчитанный показатель приспособленности (Fn) всегда находится в ин- тервале [0,1]. Теперь, когда мы сформировали основы эксперимента по зри- тельному различению, можно заняться непосредственно подготовкой к экс - перименту.",
          "debug": {
            "start_page": 181,
            "end_page": 183
          }
        },
        {
          "name": "7.4 Подготовка эксперимента по зрительному различению 182",
          "content": "--- Страница 183 --- (продолжение)\n7.4 пОДгОтОвка экСперимента пО зрительн Ому различению В нашем эксперименте, во время обучения нейросети зрительного дискрими- натора, мы используем фиксированное разрешение зрительного и целевого полей, с размерностью 11×11. Следовательно, соединительная CPPN должна как-то связать между собой 121 вход зрительного поля и 121 выход целевого поля, что в итоге потенциально может дать 14 641 значение веса связи. На рис. 7.2 показана схема субстрата для нейросети зрительного дискри- минатора. Нейросеть дискриминатора на рис. 7.2 имеет два слоя с узлами, образу - ющими по одной двумерной плоской сетке на слой. Соединительная CPPN «рисует» паттерны связей, проводя связи от узлов одного уровня к узлам другого уровня.182  Зрительное различение с NEAT на основе гиперкуба\n7.4 пОДгОтОвка экСперимента пО зрительн Ому различению В нашем эксперименте, во время обучения нейросети зрительного дискрими- натора, мы используем фиксированное разрешение зрительного и целевого полей, с размерностью 11×11. Следовательно, соединительная CPPN должна как-то связать между собой 121 вход зрительного поля и 121 выход целевого поля, что в итоге потенциально может дать 14 641 значение веса связи. На рис. 7.2 показана схема субстрата для нейросети зрительного дискри- минатора. Нейросеть дискриминатора на рис. 7.2 имеет два слоя с узлами, образу - ющими по одной двумерной плоской сетке на слой. Соединительная CPPN «рисует» паттерны связей, проводя связи от узлов одного уровня к узлам другого уровня.182  Зрительное различение с NEAT на основе гиперкуба\n--- Страница 184 ---\nЗрительное поле (x1, y1)Целевое поле (x2, y2) Рис. 7.2. Субстрат пространства состояний для нейросети зрительного дискриминатора На каждом поколении эволюции каждый индивидуум в популяции (ге- ном, кодирующий CPPN) оценивается на его способность создавать паттер- ны связей нейросети дискриминатора. Затем зрительный дискриминатор проверяется, чтобы определить, может ли он найти центр большого объекта в поле зрения. Всего для текущей нейросети предусмотрено 75 оценочных испытаний, в которых два объекта расположены в разных местах. В каждом испытании мы помещаем маленький объект в одну из 25 позиций, равно- мерно распределенных в поле зрения. Центр большого объекта находится в пяти шагах от маленького объекта вправо, вниз или по диагонали. Если большой объект не полностью вписывается в поле зрения, он переходит на другую сторону. Таким образом, учитывая логику размещения объектов от- носительно друг друга и сетки, мы должны суметь оценить все возможные конфигурации в 75 испытаниях. Среда эксперимента состоит из двух основных частей, которые мы обсу - дим в следующих разделах. 7.4.1 Т естовая среда зрительного дискриминатора Сначала нам нужно определить тестовую среду и предоставить доступ к набору данных, который содержит все возможные конфигурации зрительных полей, как сказано в предыдущем разделе. Набор данных, используемый в этом экс- перименте, создается во время инициализации тестовой среды. Мы обсудим создание набора данных позже. Тестовая среда состоит из двух основных компонентов: структура данных для хранения определений зрительного поля; менеджер тестовой среды, который хранит набор данных и предостав- ляет средства для оценки нейросети дискриминатора. Далее вы познакомитесь с подробным описанием этих компонентов. Определение зрительного поля Конфигурация зрительного поля для каждого из упомянутых ранее 75 ис- пытаний сохраняется в классе Python VisualField . Он имеет следующий кон- структор: 7.4 Подготовка эксперимента по зрительному различению  183\n--- Страница 185 ---\ndef __init__(self, big_pos, small_pos, field_size): self.big_pos = big_pos self.small_pos = small_pos self.field_size = field_size self.data = np.zeros((field_size, field_size)) # Позиция маленького объекта. self._set_point(small_pos[0], small_pos[1]) # Позиция большого объекта. offsets = [-1, 0, 1] for xo in offsets: for yo in offsets: self._set_point(big_pos[0] + xo, big_pos[1] + yo) Конструктор VisualField принимает в качестве параметров кортеж с коор- динатами (x, y) большого и маленького объектов, а также размер зрительно- го поля. Мы рассматриваем квадратное поле, поэтому размер зрительного поля одинаковый вдоль каждой оси. Внутренним представлением зри- тельного поля является двумерный двоичный массив, где единицы пред- ставляют позиции, занятые объектами, а нули – это пустые пространства. Он хранится в поле self.data , которое представляет собой массив NumPy с размерностью (2, 2). Маленький объект имеет размер 1×1, а размерность большого объекта в три раза больше. Следующий фрагмент из исходного кода конструктора создает представление большого объекта в массиве данных: offsets = [-1, 0, 1] for xo in offsets: for yo in offsets: self._set_point(big_pos[0] + xo, big_pos[1] + yo) Конструктор класса VisualField получает координаты центра большого объ- екта в виде кортежа (x, y). Предыдущий фрагмент кода рисует большой объ- ект, начиная с верхнего левого угла (x-1, y-1) и заканчивая нижним правым углом (x+1, y+1). Функция _set_point(self,x,y) , упомянутая в предыдущем фрагменте, уста- навливает значение 1.0 в определенной позиции в поле self.data : def _set_point(self, x, y): px, py = x, y if px < 0: px = self.field_size + px elif px >= self.field_size: px = px - self.field_size if py < 0: py = self.field_size + py elif py >= self.field_size: py = py - self.field_size self.data[py, px] = 1 # В Numpy индекс имеет вид [строка, столбец]184  Зрительное различение с NEAT на основе гиперкуба\n--- Страница 186 ---\nФункция _set_point(self, x, y) выполняет перенос координат, когда зна- чение координат превышает допустимое количество измерений на ось. На- пример, для оси x исходный код для переноса значений координат выглядит следующим образом: if px < 0: px = self.field_size + px elif px >= self.field_size: px = px - self.field_size Исходный код для переноса координат вдоль оси y аналогичен. После переноса координат, указанных в качестве параметров функции (при необходимости), мы присваиваем соответствующим позициям в поле self.data значение 1.0. NumPy выполняет индексацию в виде [строка, столбец] . Поэтому мы должны поставить y в первую позицию и x во вторую позицию индекса. Рабочая среда зрительного дискриминатора Рабочая среда зрительного дискриминатора содержит сгенерированный на- бор данных с описаниями зрительного поля. Кроме того, она предоставляет методы для создания набора данных и оценки нейросети дискриминатора на конкретном наборе данных. Класс Python VDEnvironment содержит опреде- ления всех упомянутых методов, а также соответствующих структур данных. Далее мы рассмотрим все важные компоненты класса VDEnvironment . Конструктор класса определяется следующим образом: def __init__(self, small_object_positions, big_object_offset, field_size): self.s_object_pos = small_object_positions self.data_set = [] self.b_object_offset = big_object_offset self.field_size = field_size self.max_dist = self._distance((0, 0), (field_size - 1, field_size - 1)) # Создание тестового набора данных self._create_data_set() Первый параметр конструктора VDEnvironment представляет собой массив с определениями всех возможных положений малых объектов, определен- ных как последовательность значений координат для каждой оси. Второй параметр определяет смещение координат центра большого объекта от ко- ординат малого объекта. В нашем эксперименте в качестве значения этого параметра мы используем 5. Наконец, третий параметр – это размер зритель- ного поля в двух измерениях. 7.4 Подготовка эксперимента по зрительному различению  185\n--- Страница 187 ---\nСохранив все полученные параметры в полях объекта, мы вычисляем мак- симально возможное расстояние между двумя точками в зрительном поле следующим образом: self.max_dist = self._distance((0, 0), (field_size - 1, field_size - 1)) Евклидово расстояние между верхним левым и нижним правым углами зрительного поля сохраняется в поле self.max_dist . Это значение будет ис- пользовано позже для нормализации расстояний между точками зрительно- го поля, чтобы сохранить их в интервале [0,1]. Функция _create_data_set() создает все возможные наборы данных с учетом заданных параметров среды. Исходный код этой функции вы- глядит следующим образом: def _create_data_set(self): for x in self.s_object_pos: for y in self.s_object_pos: # Диагональ vf = self._create_visual_field(x, y, x_off=self.b_object_offset, y_off=self.b_object_offset) self.data_set.append(vf) # Вправо vf = self._create_visual_field(x, y, x_off=self.b_object_offset, y_off=0) self.data_set.append(vf) # Вниз vf = self._create_visual_field(x, y, x_off=0, y_off=self.b_object_offset) self.data_set.append(vf) Функция выполняет итерацию по позициям маленького объекта вдоль двух осей и пытается создать большой объект по координатам, расположен- ным справа, снизу или по диагонали от координат маленького объекта. Функция _create_visual_field создает соответствующую конфигурацию зрительного поля, используя координаты маленького объекта (sx, sy) и смещение центра большого объекта (x_off, y_off). Следующий исход- ный код показывает, как это реализовано: def _create_visual_field(self, sx, sy, x_off, y_off): bx = (sx + x_off) % self.field_size # Перенос по координате X by = (sy + y_off) % self.field_size # Перенос по координате Y # Создаем зрительное поле. return VisualField(big_pos=(bx, by), small_pos=(sx, sy), field_size=self.field_size)186  Зрительное различение с NEAT на основе гиперкуба\n--- Страница 188 ---\nЕсли координаты большого объекта, вычисленные предыдущей функцией, находятся вне пространства зрительного поля, мы применяем перенос сле- дующим образом: if bx >= self.field_size: bx = bx - self.field_size # Перенос Предыдущий фрагмент показывает перенос по оси x. Перенос по оси y вы- полняется аналогично. Наконец, мы создаем объект VisualField и возвращаем его для добавления в набор данных. Тем не менее наиболее интересная часть описания VDEnvironment связа- на с оценкой нейросети дискриминатора, которая выполняется в функ - ции evaluate_net(self, net) следующим образом: def evaluate_net(self, net): avg_dist = 0 # Вычисление предсказанной позиции for ds in self.data_set: # Вычисляем выходные значения outputs, x, y = self.evaluate_net_vf(net, ds) # Находим расстояние до большого объекта dist = self._distance((x, y), ds.big_pos) avg_dist = avg_dist + dist avg_dist /= float(len(self.data_set)) # Нормализация ошибки предсказания позиции error = avg_dist / self.max_dist # Приспособленность fitness = 1.0 - error return fitness, avg_dist Эта функция получает нейросеть зрительного дискриминатора в качестве параметра и возвращает вычисленную оценку приспособленности и среднее расстояние между предсказанными и истинными координатами большого объекта, рассчитанное для всех рассмотренных зрительных полей. Среднее расстояние рассчитывается следующим образом: for ds in self.data_set: # Вычисляем выходные значения _, x, y = self.evaluate_net_vf(net, ds) # Находим расстояние до большого объекта dist = self._distance((x, y), ds.big_pos) avg_dist = avg_dist + distavg_dist /= float(len(self.data_set)) Предыдущий исходный код перебирает все объекты VisualField в наборе данных и использует нейросеть зрительного дискриминатора для предска- 7.4 Подготовка эксперимента по зрительному различению  187\n--- Страница 189 ---\nзания координат большого объекта. После этого мы вычисляем расстояние (ошибку предсказания) между истинным и предсказанным положениями большого объекта. Наконец, находим среднее значение ошибки предсказа- ния и нормализуем его следующим образом: # Нормализованная ошибка предсказания error = avg_dist / self.max_dist В соответствии с предыдущим кодом максимально возможное значение ошибки составляет 1.0. Значение показателя приспособленности вычисля- ется как разность между 1.0 и значением ошибки, поскольку приспособлен- ность возрастает по мере уменьшения ошибки: # fitnessfitness = 1.0 - error Функция evaluate_net возвращает рассчитанный показатель приспособлен- ности вместе с ненормализованной ошибкой обнаружения. Функция evaluate_net_vf(self, net, vf) предоставляет средства для оценки нейросети дискриминатора на конкретном объекте VisualField и реа лизована в следующем блоке кода: def evaluate_net_vf(self, net, vf): depth = 1 # У нас только 2 слоя net.Flush() # Подготовка входа inputs = vf.get_data() net.Input(inputs) # Активация [net.Activate() for _ in range(depth)] # Получаем выходы outputs = net.Output() # Находим координаты большого объекта x, y = self._big_object_coordinates(outputs) return outputs, x, y Предыдущая функция получает нейросеть дискриминатора в качестве первого параметра и объект VisualField в качестве второго параметра. После этого она формирует развернутый входной массив из объекта VisualField и использует его в качестве входных данных для нейросети дискриминатора: inputs = vf.get_data() net.Input(inputs) После того как мы определили входы дискриминатора, он должен быть активирован для распространения входных значений по всем сетевым уз- лам. Наша нейросеть дискриминатора имеет только два слоя, что определя- ется пространственной конфигурацией субстрата. Следовательно, нам нужно 188  Зрительное различение с NEAT на основе гиперкуба\n--- Страница 190 ---\nактивировать ее дважды – по одному разу для каждого слоя. После распро- странения сигнала активации через оба уровня нейросети дискриминатора мы можем определить положение большого объекта в целевом поле через индекс максимального значения в выходном массиве. Используя функцию _big_object_coordinates(self, outputs), мы можем извлечь декартовы коорди- наты (x, y) большого объекта в целевом поле. Наконец, функция evaluate_net_vf возвращает необработанный выходной массив вместе с извлеченными декартовыми координатами (x, y) большого объекта в пространстве целевого поля. Функция _big_object_coordinates(self, outputs) извлекает декартовы ко- ординаты большого объекта в пространстве целевого поля из необра- ботанных выходных данных, полученных из нейросети дискриминато- ра. Исходный код функции выглядит следующим образом: def _big_object_coordinates(self, outputs): max_activation = -100.0 max_index = -1 for i, out in enumerate(outputs): if out > max_activation: max_activation = out max_index = i # Получение координат точки максимальной активации x = max_index % self.field_size y = int(max_index / self.field_size) return (x, y) Сначала функция перебирает выходной массив и находит индекс макси- мального значения: max_activation = -100.0 max_index = -1 for i, out in enumerate(outputs): if out > max_activation: max_activation = out max_index = I После этого она использует найденный индекс для вычисления декарто- вых координат с учетом размера целевого поля: x = max_index % self.field_size y = int(max_index / self.field_size) Наконец, функция возвращает кортеж (x, y) с декартовыми координатами большого объекта в целевом поле. Полный исходный код можно найти в файле vd_environment.py в фай- ловом архиве книги. 7.4 Подготовка эксперимента по зрительному различению  189\n--- Страница 191 ---\n7.4.2 Движок эксперимента Как мы упоминали ранее, задачу зрительного различения можно решить с по- мощью метода HyperNEAT. Для этого нам нужно воспользоваться библиоте- кой, которая обеспечивает реализацию алгоритма HyperNEAT. Библиотека MultiNEAT Python является подходящим кандидатом для нашего эксперимен- та, поэтому дальше мы будем использовать эту библиотеку. Далее обсудим наиболее важные компоненты движка эксперимента. Полный исходный код можно найти в файле vd_experiment_multineat. py в файловом архиве книги. Функция движка эксперимента Функция run_experiment позволяет нам проводить эксперимент, используя до- ступные гиперпараметры и инициализированную тестовую среду зрительного дискриминатора. Код функции состоит из нескольких важных частей. Инициализация первой популяции геномов CPPN В представленном далее блоке кода сначала мы инициализируем начальное число генератора случайных чисел текущим системным временем. После этого мы создаем подходящую конфигурацию субстрата для нейросети дискрими- натора, способную работать со зрительным полем заданной размерности. За- тем на основе конфигурации субстрата мы создаем геном CPPN: # Начальное значение генератора случайных чисел. seed = int(time.time()) # Создаем субстрат. substrate = create_substrate(num_dimensions) # Создаем геном CPPN и популяцию.g = NEAT.Genome(0, substrate.GetMinCPPNInputs(), 0, substrate.GetMinCPPNOutputs(), False, NEAT.ActivationFunction.UNSIGNED_SIGMOID, NEAT.ActivationFunction.UNSIGNED_SIGMOID, 0, params, 0)pop = NEAT.Population(g, params, True, 1.0, seed)pop.RNG.Seed(seed) Геном CPPN, созданный в предыдущем коде, имеет необходимое количест - во входных и выходных узлов, предоставляемых субстратом. Сначала в ка- честве функции активации узла он использует беззнаковый сигмоид. Позже, в ходе эволюции тип функции активации каждого узла CPPN будет изменен в соответствии с процедурами алгоритма HyperNEAT. Наконец, на основе инициализированного генома CPPN и гиперпараметров HyperNEAT создает - ся исходная популяция.190  Зрительное различение с NEAT на основе гиперкуба\n--- Страница 192 ---\nЗапуск нейроэволюции в течение нужного числа поколений Сначала мы создаем промежуточные переменные для хранения результатов выполнения и сборщик статистики (Statistics ). После этого выполняем цикл эволюции для числа поколений, указанного в параметре n_generations : start_time = time.time() best_genome_ser = None best_ever_goal_fitness = 0 best_id = -1solution_found = False stats = Statistics() for generation in range(n_generations): В рамках цикла эволюции мы получаем список геномов, принадлежащих к популяции в текущем поколении, и оцениваем все геномы из списка на приспособленность к условиям тестовой среды следующим образом: genomes = NEAT.GetGenomeList(pop) # Получаем геномы. genome, fitness, distances = eval_genomes(genomes, vd_environment=vd_environment, substrate=substrate, generation=generation)stats.post_evaluate(max_fitness=fitness, distances=distances)solution_found = fitness >= FITNESS_THRESHOLD Мы сохраняем в сборщик статистики значения, возвращенные функцией eval_genomes(genomes, substrate, vd_environment, generation) для текущего поко- ления. Кроме того, используем возвращаемую функцией оценку приспособ- ленности, чтобы оценить, было найдено успешное решение или нет. Если показатель приспособленности превышает значение FITNESS_THRESHOLD , мы считаем, что было найдено успешное решение. Далее, если было найдено успешное решение или текущий показатель при- способленности является максимальным из когда-либо достигнутых показа- телей приспособленности, мы сохраняем геном CPPN и текущий показатель приспособленности: if solution_found or best_ever_goal_fitness < fitness: best_genome_ser = pickle.dumps(genome) best_ever_goal_fitness = fitness best_id = genome.GetID() Кроме того, если будет найдено успешное решение, мы прерываем цикл эволюции и переходим к этапу вывода отчетов, который обсудим позже: if solution_found: print('Solution found at generation: %d, best fitness: %f, species count: %d' % (generation, fitness, len(pop.Species))) break Если удачное решение не было найдено, мы выводим в консоль статистику для текущего поколения и переходим к следующему поколению: 7.4 Подготовка эксперимента по зрительному различению  191\n--- Страница 193 ---\n# Переходим к следующему поколению pop.Epoch()# Выводим статистику в консольgen_elapsed_time = time.time() - gen_time print(\"Best fitness: %f, genome ID: %d\" % (fitness, best_id)) print(\"Species count: %d\" % len(pop.Species))print(\"Generation elapsed time: %.3f sec\" % (gen_elapsed_time))print(\"Best fitness ever: %f, genome ID: %d\" % (best_ever_goal_fitness, best_id)) После завершения основного цикла эволюции в консоль выводятся резуль- таты эксперимента, основанные на статистике, собранной в цикле. Сохранение результатов эксперимента Результаты эксперимента собираются и сохраняются в текстовом и графиче- ском представлениях (файлы SVG). Мы начнем с вывода на печать общей ста- тистики производительности алгоритма: print(\"\\nBest ever fitness: %f, genome ID: %d\" % (best_ever_goal_fitness, best_id)) print(\"\\nTrial elapsed time: %.3f sec\" % (elapsed_time)) print(\"Random seed:\", seed) Первые три строки данного кода выводят на консоль лучшую оценку при- способленности, полученную среди всех поколений эволюции. После этого мы выводим на печать продолжительность эксперимента и используемое случайное начальное значение. Если мы захотим сохранить или показать визуализацию, то будут вызваны соответствующие функции: # Визуализация результатов эксперимента show_results = not silent if save_results or show_results: net = NEAT.NeuralNetwork() best_genome.BuildPhenotype(net) visualize.draw_net(net, view=show_results, node_names=None, directory=trial_out_dir, fmt='svg') Этот фрагмент кода рисует сетевой граф CPPN и выводит на печать ста- тистику графа. Далее мы переходим к визуализации вывода нейросети дис- криминатора: # Визуализация активаций от наилучшего генома net = NEAT.NeuralNetwork() best_genome.BuildHyperNEATPhenotype(net, substrate) # Выбор случайного зрительного поля index = random.randint(0, len(vd_environment.data_set) - 1)vf = vd_environment.data_set[index]# Отображение активацийoutputs, x, y = vd_environment.evaluate_net_vf(net, vf)visualize.draw_activations(outputs, found_object=(x, y), vf=vf, dimns=num_dimensions, view=show_results,192  Зрительное различение с NEAT на основе гиперкуба\n--- Страница 194 ---\nfilename=os.path.join(trial_out_dir, \"best_activations.svg\")) В предыдущем коде мы создаем нейросеть зрительного дискриминатора, используя лучший геном CPPN, найденный в ходе эволюции. После этого представляем в графическом виде выходные данные активации, полученные путем запуска нейросети дискриминатора в тестовой среде. Мы используем зрительное поле, которое выбирается случайным образом из набора данных эксперимента. Наконец, отображаем общую статистику, собранную во время эксперимента: # Visualize statistics visualize.plot_stats(stats, ylog=False, view=show_results, filename=os.path.join(trial_out_dir, 'avg_fitness.svg')) Графическое отображение статистики включает в себя лучшие оценки при- способленности и средние расстояния ошибок, собранные за поколения эво- люции. Полный исходный код функций визуализации, упомянутых в этом раз- деле, можно найти в файле visualize.py из файлового архива книги. Функция конструктора субстрата Метод HyperNEAT построен вокруг понятия субстрата, определяющего струк - туру нейросети дискриминатора. Поэтому крайне важно создать правильную конфигурацию субстрата, которая будет задействована во время выполнения эксперимента. Процедуры создания субстрата определены в следующих двух функциях. Функция конструктора субстрата create_substrate создает объект суб- страта: def create_substrate(dim): # Строим конфигурации входных и выходных декартовых листов inputs = create_sheet_space(-1, 1, dim, -1) outputs = create_sheet_space(-1, 1, dim, 0) substrate = NEAT.Substrate( inputs, [], # hidden outputs) substrate.m_allow_input_output_links = True substrate.m_hidden_nodes_activation = \\ NEAT.ActivationFunction.SIGNED_SIGMOID substrate.m_output_nodes_activation = \\ NEAT.ActivationFunction.UNSIGNED_SIGMOID substrate.m_with_distance = True substrate.m_max_weight_and_bias = 3.0 return substrate Данная функция сначала создает два разбитых на сетку декартовых лис- та, которые представляют входные данные (зрительное поле) и выходные данные (целевое поле) в конфигурации субстрата. Как вы помните, для этого 7.4 Подготовка эксперимента по зрительному различению  193\n--- Страница 195 ---\nэксперимента мы выбрали конфигурацию слоев типа «сэндвич». Затем эк- земпляр субстрата инициализируется в соответствии с созданными конфи- гурациями полей: inputs = create_sheet_space(-1, 1, dim, -1) outputs = create_sheet_space(-1, 1, dim, 0) substrate = NEAT.Substrate( inputs, [], # hidden outputs) Обратите внимание, что субстрат не использует никаких скрытых уз- лов; вместо них мы предоставляем пустой список. Затем мы настраиваем субстрат, чтобы разрешить только соединения, направленные от входных к выходным узлам, и использовать сигмоидную функцию активации со знаком на выходных узлах. Наконец, мы устанавли- ваем максимальные значения для смещения и веса соединения. Функция create_sheet_space , вызываемая конструктором субстрата, определяется следующим образом: def create_sheet_space(start, stop, dim, z): lin_sp = np.linspace(start, stop, num=dim) space = [] for x in range(dim): for y in range(dim): space.append((lin_sp[x], lin_sp[y], z)) return space Функция create_sheet_space получает начальную и конечную координаты сетки в одном измерении вместе с количеством измерений сетки. Также ука- зана координата z листа. Используя указанные параметры, предыдущий код создает равномерное линейное пространство с координатами, начинающи- мися в диапазоне [start, stop], с шагом dim: lin_sp = np.linspace(start, stop, num = dim) Затем мы используем это линейное пространство, чтобы заполнить дву- мерный массив координатами узлов сетки: space = [] for x in range(dim): for y in range(dim): space.append((lin_sp[x], lin_sp[y], z)) Функция create_sheet_space возвращает конфигурацию сетки в виде дву- мерного массива. Оценка приспособленности Оценка приспособленности генома является важной частью любого алгорит - ма нейроэволюции, включая метод HyperNEAT. Как вы видели, главный цикл эксперимента вызывает функцию eval_genomes для оценки приспособленности всех геномов в популяции для каждого поколения. Давайте рассмотрим детали 194  Зрительное различение с NEAT на основе гиперкуба\n--- Страница 196 ---\nреализации оценки приспособленности, которая состоит из двух основных функций. Функция eval_genomes оценивает все геномы в популяции: def eval_genomes(genomes, substrate, vd_environment, generation): best_genome = None max_fitness = 0 distances = [] for genome in genomes: fitness, dist = eval_individual(genome, substrate, vd_environment) genome.SetFitness(fitness) distances.append(dist) if fitness > max_fitness: max_fitness = fitness best_genome = genome return best_genome, max_fitness, distances Функция eval_genomes в качестве параметров принимает список геномов, конфигурацию субстрата нейросети дискриминатора, инициализированную тестовую среду и идентификатор текущего поколения. Первые строки функ - ции создают промежуточные переменные для хранения результатов оценки: best_genome = None max_fitness = 0 distances = [] После этого мы перебираем все геномы популяции и собираем соответ - ствующую статистику: for genome in genomes: fitness, dist = eval_individual(genome, substrate, vd_environment) genome.SetFitness(fitness) distances.append(dist) if fitness > max_fitness: max_fitness = fitness best_genome = genome Наконец, функция eval_genomes возвращает собранную статистику в виде кортежа (best_genome, max_fitness, distance) . Функция eval_individual позволяет нам оценить приспособленность от- дельного генома: def eval_individual(genome, substrate, vd_environment): # Создает нейросеть из генома CPPN и субстрата. net = NEAT.NeuralNetwork() genome.BuildHyperNEATPhenotype(net, substrate) fitness, dist = vd_environment.evaluate_net(net) return fitness, dist 7.4 Подготовка эксперимента по зрительному различению  195\n--- Страница 197 ---\nВначале вышеприведенный исходный код создает фенотип нейросети дис- криминатора с использованием генома CPPN, предоставленного в качестве параметра. После этого фенотип нейросети дискриминатора оценивается на приспособленность к тестовой среде. Функция eval_individual возвращает оценку приспособленности и величи- ну ошибки, полученные из тестовой среды во время оценки фенотипа. Те- перь, когда мы завершили настройку, давайте приступим к эксперименту по зрительному различению.",
          "debug": {
            "start_page": 183,
            "end_page": 197
          }
        },
        {
          "name": "7.5 Эксперимент по зрительному различению объектов 196",
          "content": "--- Страница 197 --- (продолжение)\n7.5 экСперимент пО зрительн Ому различению Объект Ов Выполнив все необходимые шаги по настройке, мы готовы начать эксперимент. В эксперименте по зрительному различению мы используем следующую конфигурацию зрительного поля: Параметр Значение Размер видимого поля 11×11 Положение мелких объектов в поле зрения вдоль каждой оси [1, 3, 5, 7, 9] Размер маленького объекта 1×1 Размер большого объекта 3×3 Смещение центра большого объекта от маленького объекта 5 Далее нужно выбрать подходящие значения гиперпараметров HyperNEAT, что позволит нам найти успешное решение задачи зрительного различения. Обратите внимание, что гиперпараметр, который мы опишем далее, определяет, как развивать соединительную CPPN, используя процесс нейроэволюции. Нейросеть зрительного дискриминатора создается путем наложения соединительной CPPN на субстрат. 7.5.1 Выбор гиперпараметра Библиотека MultiNEAT использует класс Parameters для хранения всех необхо- димых гиперпараметров. Чтобы установить соответствующие значения гипер- параметров, мы определяем функцию create_hyperparameters в скрипте Python для запуска эксперимента. Здесь мы опишем основные гиперпараметры, ко- торые оказывают существенное влияние на производительность алгоритма HyperNEAT в этом эксперименте. 1. Функция create_hyperparameters начинается с создания объекта Parameters для хранения параметров HyperNEAT: params = NEAT.Parameters() 2. Мы решили начать с популяции геномов среднего размера, чтобы уско- рить вычисления. В то же время мы хотим сохранить достаточное коли- чество организмов в популяции для эволюционного разнообразия. Чис- ленность популяции определяется следующим образом:196  Зрительное различение с NEAT на основе гиперкуба\n7.5 экСперимент пО зрительн Ому различению Объект Ов Выполнив все необходимые шаги по настройке, мы готовы начать эксперимент. В эксперименте по зрительному различению мы используем следующую конфигурацию зрительного поля: Параметр Значение Размер видимого поля 11×11 Положение мелких объектов в поле зрения вдоль каждой оси [1, 3, 5, 7, 9] Размер маленького объекта 1×1 Размер большого объекта 3×3 Смещение центра большого объекта от маленького объекта 5 Далее нужно выбрать подходящие значения гиперпараметров HyperNEAT, что позволит нам найти успешное решение задачи зрительного различения. Обратите внимание, что гиперпараметр, который мы опишем далее, определяет, как развивать соединительную CPPN, используя процесс нейроэволюции. Нейросеть зрительного дискриминатора создается путем наложения соединительной CPPN на субстрат. 7.5.1 Выбор гиперпараметра Библиотека MultiNEAT использует класс Parameters для хранения всех необхо- димых гиперпараметров. Чтобы установить соответствующие значения гипер- параметров, мы определяем функцию create_hyperparameters в скрипте Python для запуска эксперимента. Здесь мы опишем основные гиперпараметры, ко- торые оказывают существенное влияние на производительность алгоритма HyperNEAT в этом эксперименте. 1. Функция create_hyperparameters начинается с создания объекта Parameters для хранения параметров HyperNEAT: params = NEAT.Parameters() 2. Мы решили начать с популяции геномов среднего размера, чтобы уско- рить вычисления. В то же время мы хотим сохранить достаточное коли- чество организмов в популяции для эволюционного разнообразия. Чис- ленность популяции определяется следующим образом:196  Зрительное различение с NEAT на основе гиперкуба\n--- Страница 198 ---\nparams.PopulationSize = 150 3. Мы заинтересованы в создании компактных геномов CPPN, которые имеют как можно меньше узлов для повышения эффективности кос- венного кодирования. Поэтому устанавливаем очень маленькую веро- ятность добавления нового узла во время эволюции, а также оставляем довольно низкую вероятность создания новой связи: params.MutateAddLinkProb = 0.1 params.MutateAddNeuronProb = 0.03 4. Метод HyperNEAT создает геномы CPPN с различными типами функ - ций активации в скрытых и выходных узлах. Следовательно, мы долж - ны определить вероятность мутации, которая меняет тип активации узла. Кроме того, в этом эксперименте мы заинтересованы в исполь- зовании только четырех типов функции активации: гауссовой со зна- ком, сигмоиды со знаком, синусоиды со знаком и линейной функции. Мы устанавливаем вероятности выбора любого из упомянутых четы- рех типов активации равными 1.0, что фактически уравнивает вероят - ность выбора каждого типа: params.MutateNeuronActivationTypeProb = 0.3params.ActivationFunction_SignedGauss_Prob = 1.0 params.ActivationFunction_SignedSigmoid_Prob = 1.0 params.ActivationFunction_SignedSine_Prob = 1.0 params.ActivationFunction_Linear_Prob = 1.0 5. Наконец, мы определяем количество видов в популяции, которое должно оставаться в интервале [5,10], и устанавливаем допустимую длительность стагнации вида в течение 100 поколений. Эта конфигу - рация поддерживает умеренное видовое разнообразие, но сохраняет виды достаточно долго, чтобы позволить им развиваться и создавать полезные конфигурации генома CPPN: params.SpeciesMaxStagnation = 100 params.MinSpecies = 5 params.MaxSpecies = 10 Представленные здесь гиперпараметры продемонстрировали высокую эф- фективность получения успешных геномов CPPN в ходе эволюции. 7.5.2 Настройка рабочей среды В этом эксперименте мы используем библиотеку MultiNEAT, которая обеспе- чивает реализацию алгоритма HyperNEAT. Нам остается лишь создать соответ - ствующую среду Python, которая включает в себя библиотеку MultiNEAT и все необходимые зависимости. Это можно сделать с помощью Anaconda, выпол- нив следующие команды в командной строке: $ conda create --name vd_multineat python=3.5 $ conda activate vd_multineat $ conda install -c conda-forge multineat$ conda install matplotlib 7.5 Эксперимент по зрительному различению объектов  197\n--- Страница 199 ---\n$ conda install -c anaconda seaborn $ conda install graphviz$ conda install python-graphviz Эти команды создают и активируют виртуальную среду vd_multineat на ос- нове Python 3.5. После этого они устанавливают последнюю версию библио- теки MultiNEAT вместе с зависимостями, которые используются нашим ко- дом для визуализации результатов. 7.5.3 Запуск эксперимента по зрительному различению Чтобы запустить эксперимент, вам нужно перейти в локальный каталог, со- держащий скрипт vd_experiment_multineat.py , и выполнить следующую команду: $ python vd_experiment_multineat.py Не забудьте активировать соответствующую виртуальную среду с по- мощью команды $ conda activ vd_multineat . Спустя определенное количество поколений будет найдено успешное ре- шение, и вы увидите в окне терминала строки наподобие таких: ****** Generation: 16 ****** Best fitness: 0.995286, genome ID: 2410 Species count: 11 Generation elapsed time: 3.328 secBest fitness ever: 0.995286, genome ID: 2410 ****** Generation: 17 ****** Solution found at generation: 17, best fitness: 1.000000, species count: 11 Best ever fitness: 1.000000, genome ID: 2565 Trial elapsed time: 57.753 sec Random seed: 1568629572 CPPN nodes: 10, connections: 16Running test evaluation against random visual field: 41 Substrate nodes: 242, connections: 14641 found (5, 1) target (5, 1) В данном консольном выводе говорится, что решение было найдено в 17-м поколении. Идентификатор успешного генома CPPN – 2565, и этот геном имеет 10 узлов и 16 связей между ними. Кроме того, вы можете уви- деть результаты оценки нейросети дискриминатора, полученного с по- мощью лучшего генома CPPN в отношении случайно выбранного зритель- ного поля.198  Зрительное различение с NEAT на основе гиперкуба\n--- Страница 200 ---\nВ нашем случае найденные декартовы координаты большого объекта в це- левом поле и фактические координаты в зрительном поле совпадают (5, 1), что свидетельствует о способности найденного решения различать объекты с высокой точностью. Далее интересно взглянуть на визуальное представление уровней актива- ции выходов нейросети зрительного дискриминатора, полученных во время тестового прогона (рис. 7.3). Зрительное поле Карта активации нейросети Рис. 7.3. Активации целевого поля зрительного дискриминатора Правая часть рисунка отображает значения активации целевого поля (вы- ходного слоя) нейросети дискриминатора, которые мы получили во время оценки на случайном зрительном поле. В левой части графика вы можете увидеть фактическую конфигурацию зрительного поля. Как видите, макси- мальное значение активации целевого поля (самая темная ячейка) находится точно в той же позиции, что и центр большого объекта с координатами в зри- тельном поле (5,1). Мы также видим, что значениям активации нейросети присущ чрезвычай- но низкий уровень: минимальная активация составляет ~ 1×10–13, а макси- мальная – только ~ 9×10–13. Разработанная человеком нейросеть, вероятно, была бы нормализована так, чтобы выходной сигнал лежал в интервале [0,1], имея минимум, близкий к нулю, и максимум, близкий к единице. Однако нам достаточно, чтобы активация просто имела максимум в нужном месте, и нейросеть вправе выбрать любую схему активации выходов, которую боль- шинство людей сочли бы необычной. Следующий график позволяет изучить ход процесса эволюции в течение нескольких поколений и сделать вывод о том, насколько хорошо полученные соединительные CPPN справляются с задачей построения успешной нейро- сети зрительного дискриминатора (рис. 7.4). 7.5 Эксперимент по зрительному различению объектов  199\n--- Страница 201 ---\nЛучшая приспособленность в популяции и среднее расстояниеРасстояния Приспособленность Поколениясреднее расстояние –1 СКО +1 СКО Рис. 7.4. Наилучшие оценки приспособленности и средние ошибки для нейросети зрительного дискриминатора На рис. 7.4 показано изменение оценок приспособленности (восходящая линия) и средних ошибок (нисходящая линия) для каждого поколения эволю- ции. Вы можете видеть, что показатели приспособленности почти достигли максимального значения уже в третьем поколении эволюции, но потребо- валось еще семь поколений, чтобы проработать конфигурации генома CPPN и найти победителя. Кроме того, вы можете видеть, что среднее расстояние между предсказанным и истинным положениями большого объекта посте- пенно уменьшается в процессе эволюции. Однако самая захватывающая часть данного эксперимента представлена на графе фенотипа CPPN (рис. 7.5). Рис. 7.5. Граф фенотипа CPPN лучшего генома200  Зрительное различение с NEAT на основе гиперкуба\n--- Страница 202 ---\nГраф демонстрирует топологию сети фенотипа CPPN, который использо- вался для построения связей в нейросети успешного зрительного дискрими- натора. На графе фенотипа CPPN входные узлы помечены квадратами, вы- ходные узлы – закрашенные кружки, а узел смещения – ромб. Два выходных узла CPPN имеют следующее значение: первый узел (8) предоставляет вес связи; второй узел (9) определяет, экспрессирована ли связь. Назначение входных узлов CPPN определено следующим образом: первые два узла (0 и 1) задают координаты точки (x, y) во входном слое субстрата; следующие два узла (2 и 3) задают координаты точки (x, y) в скрытом слое субстрата (не использовались в нашем эксперименте); следующие два узла (4 и 5) задают координаты точки (x, y) в выходном слое субстрата; последний узел (6) задает евклидово расстояние от точки на входном слое до начала координат. Также вы можете видеть, что фенотип CPPN не содержит скрытых узлов. Нейроэволюционному процессу удалось найти подходящие типы функций активации для выходных узлов CPPN в задаче зрительного различения. Это решение позволяет соединительной CPPN «выращивать» правильные пат- терны связей на субстрате нейросети дискриминатора. Подсчитав количество узлов и соединений между ними, представленных на графе рис. 7.5, вы можете почувствовать мощь метода косвенного коди- рования, предложенного алгоритмом HyperNEAT. Имея всего 16 соединений между 10 узлами, фенотип CPPN смог закодировать паттерн связей, который способен покрыть субстрат зрительного поля разрешением 11×11, потенци- ально имеющего 14 641 соединение между узлами зрительного и целево- го полей. Таким образом, мы достигли степени сжатия информации около 0,11 %, что весьма впечатляет. Такая высокая степень сжатия стала возможной благодаря обнаружению геометрических закономерностей в связях субстрата соединительной CPPN. Используя обнаруженные закономерности, CPPN может обойтись только не- сколькими паттернами (мотивами локальной связности) для всего простран- ства связей субстрата. После этого CPPN может неоднократно применять эти локальные паттерны в разных позициях субстрата, чтобы нарисовать полную схему связей между слоями субстрата – в нашем случае чтобы нарисовать связи между входным слоем (зрительное поле) и выходным слоем (целевое поле).",
          "debug": {
            "start_page": 197,
            "end_page": 202
          }
        },
        {
          "name": "7.6 Упражнения 201",
          "content": "--- Страница 202 --- (продолжение)\n7.6 упражнения 1. Попытайтесь уменьшить значение параметра params.PopulationSize и посмотрите, что произойдет. Как это повлияло на производитель- ность алгоритма? 2. Попробуйте установить нулевые вероятности для значений следующих гиперпараметров: params.ActivationFunction_SignedGauss_Prob , params. ActivationFunction_SignedSigmoid_Prob и params.ActivationFunction_Signed- 7.6 Упражнения  201\n7.6 упражнения 1. Попытайтесь уменьшить значение параметра params.PopulationSize и посмотрите, что произойдет. Как это повлияло на производитель- ность алгоритма? 2. Попробуйте установить нулевые вероятности для значений следующих гиперпараметров: params.ActivationFunction_SignedGauss_Prob , params. ActivationFunction_SignedSigmoid_Prob и params.ActivationFunction_Signed- 7.6 Упражнения  201\n--- Страница 203 ---\nSine_Prob . Было ли найдено успешное решение с этими изменениями? Как это повлияло на конфигурацию связей субстрата? 3. Распечатайте геном-победитель, попробуйте придумать визуализа- цию, а затем посмотрите, насколько ваше представление о геноме со- впадает с визуализированной CPPN.",
          "debug": {
            "start_page": 202,
            "end_page": 203
          }
        },
        {
          "name": "7.7 Заключение 202",
          "content": "--- Страница 203 --- (продолжение)\n7.7 заключение В этой главе мы узнали о методе косвенного кодирования топологии нейро- сети с использованием CPPN. Узнали о расширении HyperNEAT алгоритма NEAT, использующем соединительную CPPN для выявления паттернов связей в субстрате фенотипа нейросети зрительного дискриминатора. Также мы про- демонстрировали, как схема косвенного кодирования позволяет алгоритму HyperNEAT работать с топологиями крупномасштабных нейросетей, что часто встречается в задачах распознавания образов и зрительного различения. Благодаря полученным теоретическим знаниям у вас появилась возможность улучшить свои навыки кодирования, реализовав решение задачи зрительного различения объектов с использованием Python и библиотеки MultiNEAT. Кро- ме того, вы узнали о новом методе визуализации, изображающем уровни ак- тивации узлов в выходном слое нейросети зрительного дискриминатора, и на- учились использовать эту визуализацию для проверки решения. В следующей главе мы обсудим, как можно улучшить метод HyperNEAT, введя автоматическое создание соответствующей конфигурации субстрата. Мы рассмотрим расширение Evolvable Substrate HyperNEAT (ES-HyperNEAT) алгоритма NEAT и посмотрим, как его можно применять для решения прак - тических задач, требующих наличия модульной топологии нейросети решаю- щего устройства.202  Зрительное различение с NEAT на основе гиперкуба\n7.7 заключение В этой главе мы узнали о методе косвенного кодирования топологии нейро- сети с использованием CPPN. Узнали о расширении HyperNEAT алгоритма NEAT, использующем соединительную CPPN для выявления паттернов связей в субстрате фенотипа нейросети зрительного дискриминатора. Также мы про- демонстрировали, как схема косвенного кодирования позволяет алгоритму HyperNEAT работать с топологиями крупномасштабных нейросетей, что часто встречается в задачах распознавания образов и зрительного различения. Благодаря полученным теоретическим знаниям у вас появилась возможность улучшить свои навыки кодирования, реализовав решение задачи зрительного различения объектов с использованием Python и библиотеки MultiNEAT. Кро- ме того, вы узнали о новом методе визуализации, изображающем уровни ак- тивации узлов в выходном слое нейросети зрительного дискриминатора, и на- учились использовать эту визуализацию для проверки решения. В следующей главе мы обсудим, как можно улучшить метод HyperNEAT, введя автоматическое создание соответствующей конфигурации субстрата. Мы рассмотрим расширение Evolvable Substrate HyperNEAT (ES-HyperNEAT) алгоритма NEAT и посмотрим, как его можно применять для решения прак - тических задач, требующих наличия модульной топологии нейросети решаю- щего устройства.202  Зрительное различение с NEAT на основе гиперкуба",
          "debug": {
            "start_page": 203,
            "end_page": 203
          }
        }
      ]
    },
    {
      "name": "Глава 8. Метод ES-HyperNEAT и задача сетчатки 203",
      "chapters": [
        {
          "name": "8.1 Технические требования 204",
          "content": "8.1 техниче Ские треб Ования Для проведения экспериментов, описанных в этой главе, ваш компьютер дол- жен удовлетворять следующим техническим требованиям: Windows 8/10, macOS 10.13 или новее, или современный Linux; Anaconda Distribution версия 2019.03 или новее. Исходный код примеров этой главы можно найти в каталоге Chapter8 в фай- ловом архиве книги.",
          "debug": {
            "start_page": 205,
            "end_page": 205
          }
        },
        {
          "name": "8.2 Ручное и эволюционное формирование топографии узлов 204",
          "content": "--- Страница 205 --- (продолжение)\n8.1 техниче Ские треб Ования Для проведения экспериментов, описанных в этой главе, ваш компьютер дол- жен удовлетворять следующим техническим требованиям: Windows 8/10, macOS 10.13 или новее, или современный Linux; Anaconda Distribution версия 2019.03 или новее. Исходный код примеров этой главы можно найти в каталоге Chapter8 в фай- ловом архиве книги. 8.2 ручнОе и эвОлюци ОннОе фОрмир Ование тОпОграфии узлОв Метод HyperNEAT, который мы обсуждали в главе 7, позволяет нам исполь- зовать нейроэволюцию для решения различных задач, требующих наличия крупномасштабных нейросетевых структур. Этот класс задач охватывает мно- жество прикладных областей, включая визуальное распознавание образов. Главной отличительной чертой всех этих задач является высокая размерность входных/выходных данных. В предыдущей главе вы узнали, как определить конфигурацию субстра- та дискриминатора для решения задачи зрительного различения. Вы также узна ли, что крайне важно использовать правильную конфигурацию субстра- та, которая соответствует геометрическим особенностям пространства поис - ка конкретной задачи. Используя метод HyperNEAT, вы как архитектор долж - ны заранее определить конфигурацию субстрата, используя только ваше понимание пространственной геометрии задачи. Однако не всегда возможно заранее узнать обо всех геометрических закономерностях, скрытых за кон- кретным пространством поиска. Если вы проектируете субстрат вручную, то создаете непреднамеренное ограничение для паттерна весов, налагаемого поверх субстрата соедини- тельной сетью (CPPN). Размещая узлы в определенных местах на субстрате, вы мешаете способности CPPN обнаруживать геометрические закономер- ности мира природы. CPPN вынуждена создавать паттерн связей, который идеально соответствует структуре придуманного вами субстрата, где связи возможны только между узлами этой структуры. Это ограничение приводит к ненужным ошибкам аппроксимации, которые портят результаты, когда вы используете усовершенствованную CPPN для создания топологии нейросети решателя (фенотип). Однако почему мы должны начинать с ограничений, которые налагает ручная настройка субстрата? Не лучше ли позволить CPPN самостоятельно детализировать схемы связей между узлами субстрата, которые автоматиче- ски размещаются в правильных местах? Похоже, что развиваемые паттерны связей в субстрате предоставляют ценные неявные подсказки, помогающие оценить размещение узлов для следующей эпохи эволюции. Поход, основан- ный на эволюции конфигурации субстрата во время обучения CPPN, получил название развиваемого субстрата (evolvable substrate, ES).204  Метод ES-HyperNEAT и задача сетчатки\n8.2 ручнОе и эвОлюци ОннОе фОрмир Ование тОпОграфии узлОв Метод HyperNEAT, который мы обсуждали в главе 7, позволяет нам исполь- зовать нейроэволюцию для решения различных задач, требующих наличия крупномасштабных нейросетевых структур. Этот класс задач охватывает мно- жество прикладных областей, включая визуальное распознавание образов. Главной отличительной чертой всех этих задач является высокая размерность входных/выходных данных. В предыдущей главе вы узнали, как определить конфигурацию субстра- та дискриминатора для решения задачи зрительного различения. Вы также узна ли, что крайне важно использовать правильную конфигурацию субстра- та, которая соответствует геометрическим особенностям пространства поис - ка конкретной задачи. Используя метод HyperNEAT, вы как архитектор долж - ны заранее определить конфигурацию субстрата, используя только ваше понимание пространственной геометрии задачи. Однако не всегда возможно заранее узнать обо всех геометрических закономерностях, скрытых за кон- кретным пространством поиска. Если вы проектируете субстрат вручную, то создаете непреднамеренное ограничение для паттерна весов, налагаемого поверх субстрата соедини- тельной сетью (CPPN). Размещая узлы в определенных местах на субстрате, вы мешаете способности CPPN обнаруживать геометрические закономер- ности мира природы. CPPN вынуждена создавать паттерн связей, который идеально соответствует структуре придуманного вами субстрата, где связи возможны только между узлами этой структуры. Это ограничение приводит к ненужным ошибкам аппроксимации, которые портят результаты, когда вы используете усовершенствованную CPPN для создания топологии нейросети решателя (фенотип). Однако почему мы должны начинать с ограничений, которые налагает ручная настройка субстрата? Не лучше ли позволить CPPN самостоятельно детализировать схемы связей между узлами субстрата, которые автоматиче- ски размещаются в правильных местах? Похоже, что развиваемые паттерны связей в субстрате предоставляют ценные неявные подсказки, помогающие оценить размещение узлов для следующей эпохи эволюции. Поход, основан- ный на эволюции конфигурации субстрата во время обучения CPPN, получил название развиваемого субстрата (evolvable substrate, ES).204  Метод ES-HyperNEAT и задача сетчатки\n--- Страница 206 ---\nНеявные данные, позволяющие нам предсказать положение следующего узла, представляют собой некоторый объем информации, закодированный паттерном связей в конкретной области субстрата. Области с равномерным распределением весов связей содержат небольшое количество информа- ции, что требует наличия лишь нескольких узлов субстрата в этих областях. В то же время области субстрата с большими градиентами весов связей яв- ляются информационно насыщенными и могут извлечь выгоду из допол- нительных узлов, размещенных в этих областях. Размещая дополнительные узлы в таких областях субстрата, вы помогаете CPPN формировать гораздо более детальную кодировку сущностей окружающего мира. Иными словами, размещение узлов и паттерн связей могут зависеть от распределения весов связей, в то время как CPPN находит веса связей в ходе эволюции. HyperNEAT представляет каждую связь между двумя узлами субстрата в виде точки в четырехмерном гиперкубе. Алгоритм HyperNEAT с развива- емым субстратом расширяет HyperNEAT, автоматически размещая меньше гиперточек в областях гиперкуба с меньшим градиентом весов связей. Сле- довательно, ES-HyperNEAT использует плотность информации в качестве основного критерия при формировании топологии субстрата в процессе эволюции. В следующем разделе мы обсудим особенности алгоритма ES- HyperNEAT.",
          "debug": {
            "start_page": 205,
            "end_page": 206
          }
        },
        {
          "name": "8.3 Извлечение информации из квадродерева и основы ESHyperNEAT 205",
          "content": "--- Страница 206 --- (продолжение)\n8.3 и звлечение инфОрмации из кваДрОДерева и ОСнОвы ESH ypErNEAT Для эффективного расчета плотности информации в паттернах связей суб- страта мы должны использовать соответствующую структуру данных. Нам необходимо применять структуру данных, которая позволяет выполнять эффективный поиск в двухмерном пространстве субстрата на разных уров- нях детализации. В информатике существует структура данных, которая идеально соответствует нашим потребностям. Эта структура называется квадродеревом. Квадродерево – это структура данных, которая позволяет организовать эф- фективный поиск по двумерному пространству разбиением любой интересу - ющей области на четыре подрегиона. Соответственно, каждый из этих подре- гионов становится листом дерева, а корневой узел представляет начальную область. ES-HyperNEAT использует структуру данных квадродерева для итератив- ного поиска новых соединений и узлов в субстрате, начиная с входных и вы- ходных узлов, предварительно определенных специалистом по данным. Ис- пользование квадродерева для поиска новых соединений и узлов намного эффективнее в вычислительном отношении, чем поиск в четырехмерном пространстве гиперкуба. Схема извлечения информации с использованием квадродерева показана на рис. 8.1. 8.3 Извлечение информации из квадродерева и основы ESHyperNEAT  205\n8.3 и звлечение инфОрмации из кваДрОДерева и ОСнОвы ESH ypErNEAT Для эффективного расчета плотности информации в паттернах связей суб- страта мы должны использовать соответствующую структуру данных. Нам необходимо применять структуру данных, которая позволяет выполнять эффективный поиск в двухмерном пространстве субстрата на разных уров- нях детализации. В информатике существует структура данных, которая идеально соответствует нашим потребностям. Эта структура называется квадродеревом. Квадродерево – это структура данных, которая позволяет организовать эф- фективный поиск по двумерному пространству разбиением любой интересу - ющей области на четыре подрегиона. Соответственно, каждый из этих подре- гионов становится листом дерева, а корневой узел представляет начальную область. ES-HyperNEAT использует структуру данных квадродерева для итератив- ного поиска новых соединений и узлов в субстрате, начиная с входных и вы- ходных узлов, предварительно определенных специалистом по данным. Ис- пользование квадродерева для поиска новых соединений и узлов намного эффективнее в вычислительном отношении, чем поиск в четырехмерном пространстве гиперкуба. Схема извлечения информации с использованием квадродерева показана на рис. 8.1. 8.3 Извлечение информации из квадродерева и основы ESHyperNEAT  205\n--- Страница 207 ---\nДеление и инициализация 1 × 1 2 × 2 4 × 4Деление до желаемого разрешения Обход и извлечение Погружение при низкой дисперсииВычисление дисперсии для родительских узлов Создание связей для отобранных узловЗапрос CPPN Рис. 8.1. Схема извлечения информации с использованием квадродерева Метод извлечения информации из квадродерева состоит из двух основных частей. 1. В верхней части рис. 8.1 представлен этап деления и инициализации. На этом этапе квадродерево создается путем рекурсивного деления на- чальной области субстрата, которая охватывает от (-1,-1) до (1,1). Деле- ние прекращается, когда достигается желаемая глубина квадродерева. Теперь у нас есть несколько подрегионов, которые составляют субстрат, определяя начальное разрешение субстрата (r). Затем для каждого узла квадродерева с центром в (xi,yi) мы обращаемся к CPPN, чтобы найти вес соединения (w) между этим узлом и конкретным входным или выходным нейроном в координатах (a, b). После того как мы вычислили веса связей для k конечных узлов в поддереве квадродерева p, мы готовы вычислить информационную дисперсию узла в квадродереве следующим образом:206  Метод ES-HyperNEAT и задача сетчатки\n--- Страница 208 ---\n()22 1k i iw w . σ ==−∑ Здесь ()22 1k i iw w . σ ==−∑ – средний вес соединения среди k конечных узлов и ()22 1k i iw w . σ ==−∑ – вес соедине- ния с каждым конечным узлом. Мы можем использовать это оценочное значение дисперсии в качестве эв- ристического показателя плотности информации в конкретном подрегионе субстрата. Чем выше это значение, тем выше плотность информации. Дис- персию можно использовать для управления плотностью информации в кон- кретном подрегионе субстрата путем введения порога деления. Если диспер- сия превышает порог деления, то этап деления повторяется до тех пор, пока не будет достигнута требуемая плотность информации. На этом этапе мы создаем ориентировочную структуру, которая позволяет CPPN решать, где устанавливать связи в пределах данного субстрата. На сле- дующем этапе обработки все необходимые связи размещаются с использова- нием созданной структуры квадродерева. 2. В нижней части рис. 8.1 представлен этап обрезки и извлечения. На этом этапе мы используем развернутую структуру квадродерева предыдущего этапа, чтобы найти регионы с высокой дисперсией и убе- диться, что между узлами этих регионов экспрессировано больше свя- зей. Мы обходим квадродерево в глубину и останавливаем обход в узле, у которого значение дисперсии меньше заданного порога дисперсии ( ), или когда текущий узел не имеет дочерних элементов (то есть имеет нулевую дисперсию). Для каждого узла квадродерева, найденного по- иском по глубине, мы экспрессируем (делаем действующей) связь меж - ду текущим узлом (x, y) и каждым родительским узлом, который уже определен. Родительский узел может быть определен архитектором (узлы ввода/вывода) или найден в предыдущих запусках метода извле- чения информации, то есть из скрытых узлов, уже созданных методом ES-HyperNEAT. Когда этот этап завершается, конфигурация субстрата будет иметь больше узлов в областях с высокой плотностью информа- ции и меньше узлов в областях, кодирующих небольшое количество информации. В следующем разделе мы обсудим, как использовать алгоритм ES- HyperNEAT, который мы только что описали, при решении задачи модульной сетчатки. Для получения более подробной информации об алгоритме ES- HyperNEAT см. главу 1.",
          "debug": {
            "start_page": 206,
            "end_page": 208
          }
        },
        {
          "name": "8.4 Основы задачи модульной сетчатки 207",
          "content": "--- Страница 208 --- (продолжение)\n8.4 О СнОвы заДачи мОДульн Ой Сетчатки Иерархические модульные структуры являются неотъемлемой частью сложных биологических организмов и играют незаменимую роль в их эво- люции. Модульность повышает способность к развитию, позволяя выпол- нять рекомбинацию различных модулей в процессе эволюции. Развитая 8.4 Основы задачи модульной сетчатки  207\n8.4 О СнОвы заДачи мОДульн Ой Сетчатки Иерархические модульные структуры являются неотъемлемой частью сложных биологических организмов и играют незаменимую роль в их эво- люции. Модульность повышает способность к развитию, позволяя выпол- нять рекомбинацию различных модулей в процессе эволюции. Развитая 8.4 Основы задачи модульной сетчатки  207\n--- Страница 209 ---\nиерархия модульных компонентов ускоряет процесс эволюции, позволяя выполнять операции над совокупностью сложных структур, а не над базо- выми генами. При таком подходе нейроэволюционному процессу не нужно тратить времени на повторное развитие необходимой функциональности. Вместо этого готовые к использованию модульные компоненты могут ис- пользоваться в качестве строительных блоков для создания очень сложных нейронных сетей. В данной главе мы будем искать решение задачи сетчатки при помощи ES-HyperNEAT. Задача сетчатки заключается в одновременном опознава- нии подходящих рисунков с разрешением 2×2 левой и правой частями ис- кусственной сетчатки с разрешением 4×2. Инициализируя среду экспери- мента, мы создаем рисунки, предназначенные только для правой стороны, только для левой стороны или для обеих сторон одновременно, а затем слу- чайным образом «показываем» их нейросети зрительного детектора. Нейро- сеть должна решить, являются ли рисунки, проецируемые на левую и правую стороны сетчатки, подходящими для соответствующей стороны сетчатки (левой или правой). В задаче сетчатки левый и правый компоненты четко разделены на раз- личные функциональные единицы. В то же время одни компоненты могут присутствовать на каждой стороне сетчатки, тогда как другие являются уни- кальными для определенной стороны сетчатки. Таким образом, чтобы соз- дать успешную нейросеть детектора, процесс нейроэволюции должен найти модульные структуры отдельно для левой и правой стороны. Задача сетчатки схематически показана на рис. 8.2. Сетчатка Левые объекты Правые объекты Рис. 8.2. Схематическое представление задачи сетчатки На этой схеме искусственная сетчатка представлена в виде 2D-сетки с раз- решением 4×2 пикселей. Значения двумерного массива, представляющие ри- сунки, спроецированные на сетчатку, составляют входы нейросети детекто- ра. Закрашенным пикселям в массиве соответствует значение 1.0, а пустым пикселям соответствует значение 0.0. С данным разрешением можно нарисо-208  Метод ES-HyperNEAT и задача сетчатки\n--- Страница 210 ---\nвать 16 различных рисунков 2×2 для левой и правой частей сетчатки. Мы на- значим восемь подходящих образцов для левой стороны сетчатки и восемь подходящих образцов для правой стороны сетчатки. Некоторые из упомяну - тых рисунков являются подходящими для обеих сторон сетчатки. Схема принятия решения нейросетью детектора в пространстве решений задачи сетчатки выглядит, как показано на рис. 8.3. Входные паттерны Выходы да/нет да/нетЛевый объект?Правый объект? Рис. 8.3. Схема принятия решения нейросетью детектора Нейросеть детектора имеет восемь входов для ввода входных данных с обеих сторон сетчатки и два выходных узла. Каждый из выходных узлов производит значение, которое можно использовать для классификации ри- сунка на каждой стороне сетчатки. Первый выходной узел присвоен левой, а второй выходной узел – правой стороне сетчатки соответственно. Значе- ние активации выходного узла, которое больше или равно 0.5, классифици- рует рисунок для соответствующей стороны сетчатки как подходящий. Если значение активации меньше 0.5, рисунок считается неподходящим. Чтобы еще больше упростить детектирование, мы применяем округление к значе- ниям выходных узлов до уровня «да/нет», как показано на рисунке. Таким образом, каждый выходной узел нейросети детектора служит двоичным классификатором для соответствующей стороны сетчатки и выдает значе- ние 0.0 или 1.0, чтобы пометить входной рисунок соответственно как непод- ходящий или подходящий. 8.4.1 Определение целевой функции Задача нейросети детектора состоит в том, чтобы правильно классифициро- вать входы с левой и правой сторон сетчатки как подходящие или нет, создав вектор двоичных выходов со значениями 0.0 или 1.0. Выходной вектор имеет длину 2, которая равна числу выходных узлов. Мы можем определить ошибку классификации как евклидово расстояние между вектором с контрольными данными и вектором с выходными значе- ниями нейросети, как сделано в следующей формуле: 8.4 Основы задачи модульной сетчатки  209\n--- Страница 211 ---\n()222 1i i ie a b . ==−∑ Здесь e2 – квадрат ошибки классификации для одного испытания, a – век- тор выходных данных нейросети детектора и b – вектор с контрольными данными. На каждом поколении эволюции мы оцениваем каждую нейросеть детек - тора (фенотип) по всем 256 возможным комбинациям рисунков сетчатки 4×2, которые получаются путем комбинирования 16 различных рисунков 2×2 для каждой стороны сетчатки. Таким образом, чтобы получить окончательное значение ошибки классификации для конкретной нейросети детектора, мы вычисляем сумму 256 значений ошибок, полученных для каждой конфигура- ции рисунков сетчатки, как указано в следующей формуле: 256 2 1i ie.ε ==∑ Здесь E является суммой всех ошибок, полученных в ходе 256 испытаний, и 256 2 1i ie.ε ==∑ является квадратом ошибки классификации для конкретного испытания. Функция приспособленности может быть определена как обратная сумма ошибок, полученных из всех 256 испытаний на всех возможных рисунках сет- чатки, как показано в следующей формуле: 1000 1.=+ Мы добавляем 1 к сумме ошибок (E) в знаменателе, чтобы избежать де- ления на 0 в тех случаях, когда все испытания не дают ошибок. Таким обра- зом, в соответствии с формулой функции приспособленности максимальное значение показателя приспособленности, которое мы позже будем исполь- зовать в качестве порогового значения приспособленности, в нашем экспе- рименте составляет 1000.",
          "debug": {
            "start_page": 208,
            "end_page": 211
          }
        },
        {
          "name": "8.5 Подготовка эксперимента с модульной сетчаткой 210",
          "content": "--- Страница 211 --- (продолжение)\n8.5 пОДгОтОвка экСперимента С мОДульн Ой Сетчатк Ой В этом разделе мы обсудим детали эксперимента, направленного на поиск успешного решения задачи модульной сетчатки. В нашем эксперименте мы используем эту задачу в качестве эталона для проверки способности метода ES-HyperNEAT обнаруживать модульные топологии в фенотипе нейросети. 8.5.1 Начальная конфигурация субстрата Как было сказано ранее в этой главе, сетчатка имеет размеры 4×2, с двумя об- ластями 2×2, одна с левой стороны и одна с правой стороны. Особенности гео- метрии сетчатки должны быть представлены в геометрии исходной конфигу - рации субстрата. В нашем эксперименте мы используем трехмерный субстрат, показанный на рис. 8.4.210  Метод ES-HyperNEAT и задача сетчатки\n8.5 пОДгОтОвка экСперимента С мОДульн Ой Сетчатк Ой В этом разделе мы обсудим детали эксперимента, направленного на поиск успешного решения задачи модульной сетчатки. В нашем эксперименте мы используем эту задачу в качестве эталона для проверки способности метода ES-HyperNEAT обнаруживать модульные топологии в фенотипе нейросети. 8.5.1 Начальная конфигурация субстрата Как было сказано ранее в этой главе, сетчатка имеет размеры 4×2, с двумя об- ластями 2×2, одна с левой стороны и одна с правой стороны. Особенности гео- метрии сетчатки должны быть представлены в геометрии исходной конфигу - рации субстрата. В нашем эксперименте мы используем трехмерный субстрат, показанный на рис. 8.4.210  Метод ES-HyperNEAT и задача сетчатки\n--- Страница 212 ---\nвыходы входыскрытые слои Рис. 8.4. Начальная конфигурация субстрата Как видно по этому рисунку, входные узлы расположены в плоскости XZ, которая ортогональна плоскости XY. Они представлены в двух группах, с че- тырьмя узлами для описания левой и правой сторон сетчатки. Два выходных узла и узлы смещения расположены в плоскости XY, которая делит плоскость Z пополам между группами входных узлов. Эволюция субстрата создает но- вые скрытые узлы в той же плоскости XY, где расположены выходные узлы. Развитая соединительная CPPN рисует паттерны связей между всеми узлами внутри субстрата. Наша конечная цель состоит в том, чтобы развить CPPN и конфигурацию субстрата, которая дает подходящий модульный граф ней- росети детектора. Этот граф должен включать два модуля, каждый из которых представляет соответствующую конфигурацию для двоичного классифика- тора, рассмотренного нами ранее. Далее мы перейдем к тестовой среде для задачи модульной сетчатки. 8.5.2 Т естовая среда для задачи модульной сетчатки Мы начнем с создания тестовой среды, которая будет использоваться для оценки результатов процесса нейроэволюции, направленного на создание успешной нейросети детектора. Тестовая среда должна создать набор рисун- ков, включающий все возможные сочетания расположения пикселей на сет- чатке. Кроме того, она должна предоставлять функции для оценки нейросети по каждому рисунку в наборе данных. Таким образом, тестовую среду можно разделить на две основные части: структура данных для хранения рисунков, относящихся к левой, правой или обеим сторонам сетчатки; тестовая среда, хранящая набор данных и предоставляющая функции для оценки нейросети. Далее мы подробно рассмотрим каждую часть. 8.5 Подготовка эксперимента с модульной сетчаткой  211\n--- Страница 213 ---\nОпределение визуального объекта Каждая из разрешенных конфигураций пикселей в определенной части про- странства сетчатки может быть представлена как отдельный визуальный объ- ект. Класс Python, инкапсулирующий соответствующую функциональность, называется VisualObject и определяется в файле retina_experiment.py . Он имеет следующий конструктор: def __init__(self, configuration, side, size=2): self.size = size self.side = side self.configuration = configuration self.data = np.zeros((size, size)) # Чтение конфигурации lines = self.configuration.splitlines() for r, line in enumerate(lines): chars = line.split(\" \") for c, ch in enumerate(chars): if ch == 'o': # Пиксель активен self.data[r, c] = 1.0 else: # Пиксель не активен self.data[r, c] = 0.0 Конструктор получает конфигурацию конкретного визуального объекта в виде строки вместе с надлежащим местоположением этого объекта в про- странстве сетчатки (справа, слева или обе стороны). После этого он назначает полученные параметры внутренним полям и создает двумерный массив дан- ных, содержащий состояния пикселей в визуальном объекте. Состояния пикселей получают путем анализа строки конфигурации визу - ального объекта следующим образом: # Чтение конфигурации lines = self.configuration.splitlines() for r, line in enumerate(lines): chars = line.split(\" \") for c, ch in enumerate(chars): if ch == 'o': # Пиксель активен self.data[r, c] = 1.0 else: # П self.data[r, c] = 0.0 Строка конфигурации визуального объекта содержит четыре символа, ис- ключая разрыв строки, которые определяют состояние соответствующего пикселя в визуальном объекте. Если в определенной позиции строки конфи- гурации стоит символ o, тогда пиксель в соответствующей позиции визуаль- ного объекта устанавливается в состояние ON (активен), и для этой позиции в массиве данных сохраняется значение 1.0.212  Метод ES-HyperNEAT и задача сетчатки\n--- Страница 214 ---\nОпределение среды сетчатки Среда сетчатки создает и хранит набор данных, состоящий из всех возможных визуальных объектов, и предоставляет функции для оценки приспособленно- сти нейросети. Ее реализация также состоит из нескольких основных частей. Функция создания набора данных со всеми возможными визуальными объектами В этой функции мы создаем визуальные объекты для набора данных следую- щим образом: def create_data_set(self): # Объекты для левой стороны сетчатки self.visual_objects.append(VisualObject(\". .\\n. .\", side=Side.BOTH))self.visual_objects.append(VisualObject(\". .\\n. o\", side=Side.BOTH)) self.visual_objects.append(VisualObject(\". o\\n. o\", side=Side.LEFT))self.visual_objects.append(VisualObject(\". o\\n. .\", side=Side.BOTH))self.visual_objects.append(VisualObject(\". o\\no o\", side=Side.LEFT))self.visual_objects.append(VisualObject(\". .\\no .\", side=Side.BOTH)) self.visual_objects.append(VisualObject(\"o o\\n. o\", side=Side.LEFT))self.visual_objects.append(VisualObject(\"o .\\n. .\", side=Side.BOTH)) Предыдущий код создает визуальные объекты для левой стороны сетчат - ки. Визуальные объекты для правой стороны создаются аналогичным об- разом: # Объекты для правой стороны сетчатки self.visual_objects.append(VisualObject(\". .\\n. .\", side=Side.BOTH)) self.visual_objects.append(VisualObject(\"o .\\n. .\", side=Side.BOTH)) self.visual_objects.append(VisualObject(\"o .\\no .\", side=Side.RIGHT))self.visual_objects.append(VisualObject(\". .\\no .\", side=Side.BOTH))self.visual_objects.append(VisualObject(\"o o\\no .\", side=Side.RIGHT))self.visual_objects.append(VisualObject(\". o\\n. .\", side=Side.BOTH)) self.visual_objects.append(VisualObject(\"o .\\no o\", side=Side.RIGHT))self.visual_objects.append(VisualObject(\". .\\n. o\", side=Side.BOTH)) 8.5 Подготовка эксперимента с модульной сетчаткой  213\n--- Страница 215 ---\nСозданные визуальные объекты представляют собой набор данных для оценки приспособленности нейросети зрительного детектора, развившегося в процессе нейроэволюции на основе исходного субстрата. Функция для оценки нейросети детектора по двум визуальным объектам Эта функция оценивает качество нейросети зрительного детектора по отноше- нию к двум заданным визуальным объектам – по одному на каждую сторону пространства сетчатки. Полный исходный код функции def _evaluate (self, net, left, right, deep, debug = False) вы можете найти в файле retina_environment.py . Исходный код функции состоит из следующих основных частей. 1. Сначала мы подготавливаем входы для нейросети детектора в том по- рядке, в котором они определены для конфигурации субстрата: inputs = left.get_data() + right.get_data() inputs.append(0.5) # Смещение net.Input(inputs) Массив входных данных начинается с данных левой части и продолжается данными правой части. После этого в конец массива входных данных добав- ляется значение смещения, и полный массив передается в качестве входных данных в нейросеть детектора. 2. После заданного количества активаций нейросети выходные значения извлекаются и округляются: outputs = net.Output() outputs[0] = 1.0 if outputs[0] >= 0.5 else 0.0 outputs[1] = 1.0 if outputs[1] >= 0.5 else 0.0 3. Затем нам нужно вычислить квадратичную ошибку обнаружения, ко- торая представляет собой евклидово расстояние между вектором вы- ходных сигналов и вектором истинных значений. Сначала мы создаем вектор истинных значений: left_target = 1.0 if left.side == Side.LEFT or \\ left.side == Side.BOTH else 0.0 right_target = 1.0 if right.side == Side.RIGHT or \\ right.side == Side.BOTH else 0.0targets = [left_target, right_target] Соответствующее значение истинности устанавливается равным 1.0, если визуальный объект предназначен для данной стороны сетчатки или обеих сторон. В противном случае значение истинности устанавливается равным 0.0, чтобы указать на неправильное назначение визуального объекта. 4. Наконец, квадратичная ошибка обнаружения рассчитывается следую- щим образом: error = (outputs[0]-targets[0]) * (outputs[0]-targets[0]) + \\ (outputs[1]-targets[1]) * (outputs[1]-targets[1]) Функция возвращает ошибку обнаружения и выходы нейросети зритель- ного детектора. В следующем разделе мы обсудим реализацию движка экс- перимента.214  Метод ES-HyperNEAT и задача сетчатки\n--- Страница 216 ---\nДля получения полной информации о реализации обратитесь к фай- лу retina_environment.py в файловом архиве книги. 8.5.3 Движок эксперимента Чтобы решить задачу модульной сетчатки, нам нужно использовать библиоте- ку Python, которая предоставляет реализацию алгоритма ES-HyperNEAT. Если вы читали предыдущую главу, то уже знакомы с библиотекой MultiNEAT, в ко- торой также есть реализация алгоритма ES-HyperNEAT. Мы можем использо- вать эту библиотеку для создания движка нового эксперимента с сетчаткой. Давайте обсудим основные компоненты реализации движка. Для получения полной информации о реализации обратитесь к фай-лу retina_experiment.py в файловом архиве книги. Функция движка эксперимента Функция run_experiment запускает эксперимент, используя предварительно на- строенные гиперпараметры и инициализированную среду тестирования, что- бы оценить найденные нейросети детектора применительно к разным рисун- кам на сетчатке. Реализация функции имеет следующие важные части: 1. Сначала идет инициализация популяции исходных геномов CPPN: seed = 1569777981 # Создаем субстрат substrate = create_substrate() # Создаем геном CPPN и популяцию g = NEAT.Genome(0, substrate.GetMinCPPNInputs(), 2, # скрытые узлы substrate.GetMinCPPNOutputs(), False, NEAT.ActivationFunction.TANH, NEAT.ActivationFunction.SIGNED_GAUSS, # скрытый 1, # начальное количество скрытых слоев params, 1) # один скрытый слойpop = NEAT.Population(g, params, True, 1.0, seed)pop.RNG.Seed(seed) Сначала этот код присваивает такое начальное значение генератора случай- ных чисел, которое оказалось полезным для генерации успешных решений пу- тем последовательного запуска многих экспериментальных испытаний. Пос- ле этого мы создаем конфигурацию субстрата, подходящую для эксперимента с сетчаткой, с учетом геометрии пространства сетчатки. Затем мы создаем исходный геном CPPN, используя конфигурацию субстра- та, которую уже имеем. Геном CPPN должен иметь несколько входных и выход- ных узлов, совместимых с конфигурацией субстрата. Кроме того, мы инициа- 8.5 Подготовка эксперимента с модульной сетчаткой  215\n--- Страница 217 ---\nлизируем исходный геном CPPN двумя скрытыми узлами с гауссовой функцией активации, чтобы ускорить процесс нейроэволюции в правильном направле- нии. Скрытые узлы с гауссовой активацией начинают нейроэволюционный по- иск с уклоном в сторону создания определенных топологий нейросети детекто- ра. Этими скрытыми узлами мы вводим в паттерны связей субстрата принцип симметрии, чего и ожидаем достичь в топологии успешного детектора. Для ре- шения задачи сетчатки мы должны найти симметричную конфигурацию ней- росети, включающую два симметричных модуля классификатора. 2. Затем мы готовим промежуточные переменные для хранения резуль- татов выполнения эксперимента и сборщик статистики. После этого запус каем цикл эволюции для заданного количества поколений: start_time = time.time() best_genome_ser = None best_ever_goal_fitness = 0best_id = -1solution_found = False stats = Statistics() 3. Внутри цикла эволюции мы получаем список геномов, принадлежащих текущей популяции, и оцениваем его в тестовой среде следующим об- разом: # Получаем список текущих геномов genomes = NEAT.GetGenomeList(pop) # Оценка геномов genome, fitness, errors = eval_genomes(genomes, rt_environment=rt_environment, substrate=substrate, params=params)stats.post_evaluate(max_fitness=fitness, errors=errors)solution_found = fitness >= FITNESS_THRESHOLD Функция eval_genomes возвращает кортеж, который имеет следующие компо- ненты: наиболее подходящий геном, наивысший показатель приспособленно- сти среди всех оцененных геномов и список ошибок обнаружения для каждого оцененного генома. Мы сохраняем соответствующие параметры в сборщике статистики и оцениваем полученную оценку соответствия по критерию за- вершения поиска, который определяется как константа FITNESS_THRESHOLD со значением 1000.0. Эволюционный поиск успешно завершается, если лучший показатель приспособленности в популяции превышает или равен значению FITNESS_THRESHOLD . 4. Если было найдено успешное решение или текущий лучший показатель приспособленности популяции выше, чем максимальный показатель приспособленности, который был достигнут ранее, мы сохраняем луч- ший геном CPPN и текущий показатель приспособленности следующим образом:216  Метод ES-HyperNEAT и задача сетчатки\n--- Страница 218 ---\nif solution_found or best_ever_goal_fitness < fitness: # Сохраняем, чтобы заморозить состояние генома. best_genome_ser = pickle.dumps(genome) best_ever_goal_fitness = fitness best_id = genome.GetID() 5. После этого, если значение переменной solution_found было установлено в True, мы завершаем цикл эволюции: if solution_found: print('Solution found at generation: %d, best fitness: %f, species count: %d' % (generation, fitness, len(pop.Species))) break 6. Если эволюция не привела к успешному решению, мы выводим в кон- соль статистику для текущего поколения и переходим к следующему по- колению: # Переход к следующему поколению. pop.Epoch() # Печать статистики. gen_elapsed_time = time.time() - gen_time print(\"Best fitness: %f, genome ID: %d\" % (fitness, best_id)) print(\"Species count: %d\" % len(pop.Species))print(\"Generation elapsed time: %.3f sec\" % (gen_elapsed_time)) print(\"Best fitness ever: %f, genome ID: %d\" % (best_ever_goal_fitness, best_id)) Остальная часть кода движка выводит результаты эксперимента в различ- ных форматах. 7. Мы выводим результаты эксперимента в текстовом и визуальном фор- матах, используя статистику, собранную в цикле эволюции. Кроме того, файлы визуализации сохраняются в локальной файловой системе в век - торном формате SVG: print(\"\\nBest ever fitness: %f, genome ID: %d\" % (best_ever_goal_fitness, best_id)) print(\"\\nTrial elapsed time: %.3f sec\" % (elapsed_time)) print(\"Random seed:\", seed) Эти строки кода выводят в консоль общую статистику о выполнении экс- перимента, такую как наивысшая достигнутая оценка приспособленности, продолжительность эксперимента и начальное значение генератора случай- ных чисел. 8. Следующая часть кода посвящена наиболее информативной части экс- перимента – визуализации результатов, – и вам следует уделить ей осо- бое внимание. Мы начнем с визуализации сети CPPN, которая создана из лучшего генома, найденного в ходе эволюции: 8.5 Подготовка эксперимента с модульной сетчаткой  217\n--- Страница 219 ---\nif save_results or show_results: # Рисуем граф CPPN. net = NEAT.NeuralNetwork() best_genome.BuildPhenotype(net) visualize.draw_net(net, view=False, node_names=None, filename=\"cppn_graph.svg\", directory=trial_out_dir, fmt='svg')print(\"\\nCPPN nodes: %d, connections: %d\" %(len(net.neurons), len(net.connections))) 9. После этого мы визуализируем топологию нейросети детектора, кото- рая создана с использованием лучшего генома CPPN и субстрата сет- чатки: net = NEAT.NeuralNetwork() best_genome.BuildESHyperNEATPhenotype(net, substrate, params)visualize.draw_net(net, view=False, node_names=None, filename=\"substrate_graph.svg\", directory=trial_out_dir, fmt='svg')print(\"\\nSubstrate nodes: %d, connections: %d\" % (len(net.neurons), len(net.connections)))inputs = net.NumInputs()outputs = net.NumOutputs()hidden = len(net.neurons) - net.NumInputs() - \\ net.NumOutputs() print(\"\\n\\tinputs: %d, outputs: %d, hidden: %d\" % (inputs, outputs, hidden)) 10. Кроме того, мы выводим на печать результаты оценки нейросети детек - тора, созданного предыдущим кодом, по двум случайно выбранным ви- зуальным объектам и полному набору визуальных данных: # Тест на двух случайно выбранных визуальных объектах. l_index = random.randint(0, 15) r_index = random.randint(0, 15) left = rt_environment.visual_objects[l_index] right = rt_environment.visual_objects[r_index] err, outputs = rt_environment._evaluate(net, left, right, 3)print(\"Test evaluation error: %f\" % err)print(\"Left flag: %f, pattern: %s\" % (outputs[0], left))print(\"Right flag: %f, pattern: %s\" % (outputs[1], right)) # Тест на полном наборе визуальных объектов. fitness, avg_error, total_count, false_detections = \\ rt_environment.evaluate_net(net, debug=True) print(\"Test evaluation against full data set [%d], fitness: %f, average error: %f, false detections: %f\" % (total_count,fitness, avg_error, false_detections))218  Метод ES-HyperNEAT и задача сетчатки\n--- Страница 220 ---\nНаконец, мы отображаем статистические данные, собранные в ходе экс- перимента: # Визуализация статистики visualize.plot_stats(stats, ylog=False, view=show_results, filename=os.path.join(trial_out_dir, ‘avg_fitness.svg’)) Все упомянутые здесь графики визуализации могут быть найдены после выполнения эксперимента в каталоге trial_out_dir локальной файловой си- стемы. Далее вы узнаете, как реализована функция построителя субстрата. Функция построителя субстрата Метод ES-HyperNEAT запускает процесс нейроэволюции, включающий в себя эволюцию геномов CPPN наряду с эволюцией конфигурации субстрата. Од- нако, хотя субстрат способен успешно эволюционировать, очень выгодно на- чинать с подходящей начальной конфигурации субстрата. Эта конфигурация должна соответствовать геометрии проблемного пространства. Для эксперимента с сетчаткой соответствующая конфигурация субстрата создается следующим образом. 1. Сначала создадим конфигурацию входного слоя субстрата. Как вы знае- те из раздела 8.5.1, восемь узлов входного слоя расположены в плоско- сти XZ, которая ортогональна плоскости XY. Кроме того, чтобы отразить геометрию пространства сетчатки, узлы левого объекта должны быть соответственно размещены на левой стороне плоскости, а узлы право- го объекта – на правой стороне плоскости. Узел смещения должен быть расположен в центре плоскости входных узлов. В коде эксперимента входной слой создается следующим образом: # Входной слой. x_space = np.linspace(-1.0, 1.0, num=4) inputs = [ # Левая сторона. (x_space[0], 0.0, 1.0), (x_space[1], 0.0, 1.0), (x_space[0], 0.0, -1.0), (x_space[1], 0.0, -1.0), # the right side (x_space[2], 0.0, 1.0), (x_space[3], 0.0, 1.0), (x_space[2], 0.0, -1.0), (x_space[3], 0.0, -1.0), (0,0,0) # the bias ] Два выходных узла расположены в плоскости XY, которая ортогональна плос кости ввода. Эта конфигурация допускает естественную эволюцию суб- страта путем размещения найденных скрытых узлов в плоскости XY. 2. Выходной слой создается следующим образом: # Выходной слой outputs = [(-1.0, 1.0, 0.0), (1.0, 1.0, 0.0)] 3. Далее мы определяем общие параметры конфигурации субстрата: 8.5 Подготовка эксперимента с модульной сетчаткой  219\n--- Страница 221 ---\n# Разрешаем следующие связи: входной –> скрытый, скрытый -> выходной # и скрытый -> скрытый. substrate.m_allow_input_hidden_links = True substrate.m_allow_hidden_output_links = True substrate.m_allow_hidden_hidden_links = True substrate.m_allow_input_output_links = False substrate.m_allow_output_hidden_links = Falsesubstrate.m_allow_output_output_links = Falsesubstrate.m_allow_looped_hidden_links = False substrate.m_allow_looped_output_links = False substrate.m_hidden_nodes_activation = \\ NEAT.ActivationFunction.SIGNED_SIGMOIDsubstrate.m_output_nodes_activation = \\ NEAT.ActivationFunction.UNSIGNED_SIGMOID # Отправляем длину связи в CPPN как параметр substrate.m_with_distance = True substrate.m_max_weight_and_bias = 8.0 Мы разрешаем субстрату иметь связи между входными и скрытыми узла- ми, между скрытыми узлами и от скрытых к выходным узлам. Мы указыва- ем, что скрытые узлы должны использовать функцию активации «знаковая сигмоида», в то время как выходные узлы должны использовать функцию ак- тивации «беззнаковая сигмоида». Мы выбираем для выходных узлов беззна- ковую сигмоиду, чтобы выходные значения нейросети детектора находились в интервале [0,1]. В следующем разделе мы обсудим реализацию функций для оценки при- способленности решений. Оценка фитнеса Процесс нейроэволюции требует средств для оценки приспособленности по- пуляции генома в каждом поколении эволюции. Оценка приспособленности в нашем эксперименте состоит из двух частей, которые мы обсуждаем здесь. Функция eval_genomes Эта функция оценивает приспособленность всей популяции. У нее есть следу - ющее определение: def eval_genomes(genomes, substrate, rt_environment, params): best_genome = None max_fitness = 0 errors = [] for genome in genomes: fitness, error, total_count, false_detetctions = eval_individual( genome, substrate, rt_environment, params) genome.SetFitness(fitness) errors.append(error)220  Метод ES-HyperNEAT и задача сетчатки\n--- Страница 222 ---\nif fitness > max_fitness: max_fitness = fitness best_genome = genome return best_genome, max_fitness, errors Функция eval_genomes в качестве параметров принимает список геномов CPPN из текущей популяции, конфигурацию субстрата, инициализирован- ную тестовую среду и гиперпараметры ES-HyperNEAT. В начале кода мы создаем промежуточный объект для сбора результатов оценки каждого конкретного генома: best_genome = None max_fitness = 0 errors = [] После этого мы запускаем цикл, который перебирает все геномы и оцени- вает каждый геном в соответствии с условиями текущей тестовой среды: for genome in genomes: fitness, error, total_count, false_detetctions = eval_individual( genome, substrate, rt_environment, params) genome.SetFitness(fitness) errors.append(error) if fitness > max_fitness: max_fitness = fitness best_genome = genome Наконец, функция возвращает результаты оценки в виде кортежа, который включает лучший геном, наивысшую оценку приспособленности и список всех ошибок классификации для каждого оцениваемого генома. Функция eval_individual Эта функция оценивает приспособленность каждого отдельного генома и име- ет следующее определение: def eval_individual(genome, substrate, rt_environment, params): # Создаем нейросеть на основе генома CPPN и субстрата net = NEAT.NeuralNetwork() genome.BuildESHyperNEATPhenotype(net, substrate, params) fitness, dist, total_count, false_detetctions = \\ rt_environment.evaluate_net(net, max_fitness=MAX_FITNESS) return fitness, dist, total_count, false_detetctions Она получает в качестве параметров оцениваемый геном CPPN, конфигу - рацию субстрата, среду тестирования и гиперпараметры ES-HyperNEAT. Ис- пользуя предоставленные параметры, мы создаем конфигурацию нейронной сети детектора и оцениваем ее в текущей тестовой среде. Затем функция воз- вращает результат оценки. 8.5 Подготовка эксперимента с модульной сетчаткой  221",
          "debug": {
            "start_page": 211,
            "end_page": 222
          }
        },
        {
          "name": "8.6 Эксперимент с модульной сетчаткой 222",
          "content": "--- Страница 223 --- (продолжение)\n8.6 экСперимент С мОДульн Ой Сетчатк Ой Теперь мы готовы начать эксперименты в тестовой среде, которая имитиру - ет проблемное пространство модульной сетчатки. В следующих разделах вы узнае те, как выбрать подходящие гиперпараметры, настроить среду и запу - стить эксперимент. После этого мы обсудим результаты эксперимента. 8.6.1 Настройка гиперпараметров Гиперпараметры определены как класс Python, и библиотека MultiNEAT ссы- лается на него для получения необходимых параметров конфигурации. В ис - ходном коде эксперимента мы определяем специализированную функцию create_hyperparameters , которая инкапсулирует логику инициализации гипер- параметров. Далее мы опишем наиболее важные гиперпараметры и причины выбора конкретных значений. 1. Мы используем популяцию генома CPPN среднего размера. Это сделано для ускорения эволюции за счет доступа к изначально большому про- странству вариантов для поиска решения. Численность популяции опре- деляется следующим образом: params.PopulationSize = 300 2. Затем мы определяем количество видов, которые будут сохраняться в ходе эволюции в интервале [5,15], и устанавливаем продолжитель- ность стагнации видов до 100 поколений. Эта конфигурация позволяет нам иметь здоровое разнообразие видов и поддерживать их в течение достаточно долгого времени, чтобы успеть найти решение: params.SpeciesMaxStagnation = 100 params.MinSpecies = 5 params.MaxSpecies = 15 3. Мы заинтересованы в создании сверхкомпактной конфигурации гено- мов CPPN, поэтому задаем очень маленькие значения вероятности по- явления новых узлов и связей в геномах: params.MutateAddLinkProb = 0.03 params.MutateAddNeuronProb = 0.03 4. Метод ES-HyperNEAT является расширением метода HyperNEAT, кото- рый в ходе эволюции может изменять тип функций активации в скры- том и выходном узлах. В этом эксперименте мы задаем равную вероят - ность выбора следующих типов активации: params.ActivationFunction_SignedGauss_Prob = 1.0params.ActivationFunction_SignedStep_Prob = 1.0 params.ActivationFunction_Linear_Prob = 1.0params.ActivationFunction_SignedSine_Prob = 1.0params.ActivationFunction_SignedSigmoid_Prob = 1.0 5. Наконец, мы определяем специфические гиперпараметры ES-Hyper - NEAT, которые управляют развитием субстрата. Следующие гиперпара- метры управляют динамикой создания узлов и связей внутри субстрата в процессе эволюции:222  Метод ES-HyperNEAT и задача сетчатки\n8.6 экСперимент С мОДульн Ой Сетчатк Ой Теперь мы готовы начать эксперименты в тестовой среде, которая имитиру - ет проблемное пространство модульной сетчатки. В следующих разделах вы узнае те, как выбрать подходящие гиперпараметры, настроить среду и запу - стить эксперимент. После этого мы обсудим результаты эксперимента. 8.6.1 Настройка гиперпараметров Гиперпараметры определены как класс Python, и библиотека MultiNEAT ссы- лается на него для получения необходимых параметров конфигурации. В ис - ходном коде эксперимента мы определяем специализированную функцию create_hyperparameters , которая инкапсулирует логику инициализации гипер- параметров. Далее мы опишем наиболее важные гиперпараметры и причины выбора конкретных значений. 1. Мы используем популяцию генома CPPN среднего размера. Это сделано для ускорения эволюции за счет доступа к изначально большому про- странству вариантов для поиска решения. Численность популяции опре- деляется следующим образом: params.PopulationSize = 300 2. Затем мы определяем количество видов, которые будут сохраняться в ходе эволюции в интервале [5,15], и устанавливаем продолжитель- ность стагнации видов до 100 поколений. Эта конфигурация позволяет нам иметь здоровое разнообразие видов и поддерживать их в течение достаточно долгого времени, чтобы успеть найти решение: params.SpeciesMaxStagnation = 100 params.MinSpecies = 5 params.MaxSpecies = 15 3. Мы заинтересованы в создании сверхкомпактной конфигурации гено- мов CPPN, поэтому задаем очень маленькие значения вероятности по- явления новых узлов и связей в геномах: params.MutateAddLinkProb = 0.03 params.MutateAddNeuronProb = 0.03 4. Метод ES-HyperNEAT является расширением метода HyperNEAT, кото- рый в ходе эволюции может изменять тип функций активации в скры- том и выходном узлах. В этом эксперименте мы задаем равную вероят - ность выбора следующих типов активации: params.ActivationFunction_SignedGauss_Prob = 1.0params.ActivationFunction_SignedStep_Prob = 1.0 params.ActivationFunction_Linear_Prob = 1.0params.ActivationFunction_SignedSine_Prob = 1.0params.ActivationFunction_SignedSigmoid_Prob = 1.0 5. Наконец, мы определяем специфические гиперпараметры ES-Hyper - NEAT, которые управляют развитием субстрата. Следующие гиперпара- метры управляют динамикой создания узлов и связей внутри субстрата в процессе эволюции:222  Метод ES-HyperNEAT и задача сетчатки\n--- Страница 224 ---\nparams.DivisionThreshold = 0.5 params.VarianceThreshold = 0.03 Параметр params.DivisionThreshold определяет, сколько новых узлов и со- единений вводится в субстрат при каждом поколении эволюции. Параметр params.VarianceThreshold определяет, сколько узлов и соединений может оставаться в субстрате после фазы обрезки и извлечения. Вы можете вер- нуться к разделу 8.3 за более подробной информацией об этих пороговых значениях. 8.6.2 Настройка рабочей среды В этом эксперименте мы используем библиотеку MultiNEAT, которая обеспе- чивает реализацию алгоритма ES-HyperNEAT. Нам нужно создать соответству - ющую среду Python, которая включает в себя библиотеку MultiNEAT и все не- обходимые зависимости. Это можно сделать с помощью Anaconda, выполнив следующие команды в командной строке: $ conda create --name rt_multineat python=3.5$ conda activate vd_multineat $ conda install -c conda-forge multineat $ conda install matplotlib$ conda install -c anaconda seaborn$ conda install graphviz$ conda install python-graphviz Эти команды создают и активируют виртуальную среду rt_multineat на ос- нове Python 3.5. Затем они устанавливают последнюю версию библиотеки MultiNEAT вместе с зависимостями, которые нужны вашему коду для визуа- лизации результатов. 8.6.3 Запуск эксперимента с модульной сетчаткой На этом этапе у вас уже есть сценарий запуска эксперимента, полностью опре- деленный в файле retina_experiment.py . Вы можете начать эксперимент, клони- ровав соответствующий репозиторий Git и запустив скрипт с помощью следу - ющих команд: $ git clone https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python.git $ cd Hands-on-Neuroevolution-with-Python/Chapter8 $ python retina_experiment.py -t 1 -g 1000 Не забудьте активировать соответствующее виртуальное окружение при помощи команды conda activate rt_multineat . Предыдущая команда запускает один прогон эксперимента для 1000 по- колений эволюции. Спустя некоторое количество поколений должно быть найдено успешное решение, которое сопровождается приблизительно таким выводом в консоль: 8.6 Эксперимент с модульной сетчаткой  223\n--- Страница 225 ---\n****** Generation: 949 ****** Solution found at generation: 949, best fitness: 1000.000000, species count: 6 Best ever fitness: 1000.000000, genome ID: 284698Trial elapsed time: 1332.576 sec Random seed: 1569777981 CPPN nodes: 21, connections: 22 Substrate nodes: 15, connections: 28 Как следует из этого примера вывода, в данном случае успешное решение было найдено в поколении 949. Оно было создано геномом CPPN, включающим 21 узел и 22 связи между ними. В то же время субстрат, определяющий тополо- гию нейросети детектора, имеет 15 узлов и 28 связей между ними. Успешное решение было получено с использованием случайного начального значения 1569777981 . Использование других случайных начальных значений может не при- вести к успешному решению или потребует еще многих поколений эволюции. Далее интересно взглянуть на график средней приспособленности и по- грешности за время эволюции (рис. 8.5). ПоколенияЛучшая приспособленность в популяции и среднее расстояниеCредняя ошибка Приспособленностьсреднее расстояние –1 СКО +1 СКО Рис. 8.5. Средняя приспособленность и ошибка по поколениям224  Метод ES-HyperNEAT и задача сетчатки\n--- Страница 226 ---\nМожно сделать вывод, что в течение большинства поколений эволюции оценка приспособленности была очень мала (около 20), но неожиданно на- шелся успешный геном CPPN, который совершил резкий эволюционный ска- чок всего за одно поколение. Конфигурация успешного генома CPPN показана на рис. 8.6. Рис. 8.6. Граф фенотипа CPPN успешного генома Схема на рис. 8.6 чрезвычайно любопытна, потому что, как вы можете ви- деть, успешный геном CPPN использует не все доступные входные данные (серые квадраты) для предсказания выходных данных. Более того, еще бо- лее удивительным является использование только координаты x входного (0) и координаты y скрытого (3) узлов субстрата при принятии решения об акти- вации связи между этими узлами субстрата. В то же время обе координаты x и y выходных узлов субстрата участвуют в процессе принятия решений (4 и 5). 8.6 Эксперимент с модульной сетчаткой  225\n--- Страница 227 ---\nЕсли вы посмотрите на исходную конфигурацию субстрата, которую мы представили ранее (рис. 8.4), то увидите, что упомянутые нами особенности полностью основаны на топологии субстрата. Мы разместили входные узлы в плоскости XZ. Таким образом, координата y для них не имеет значения. В то же время скрытые узлы расположены внутри плоскости XY, причем ко- ордината y определяет расстояние от плоскости входов. Наконец, выходные узлы также расположены в плоскости XY. Их координата x определяет сторо- ну сетчатки, к которой относится каждый выходной узел. Следовательно, для выходных узлов естественно учитывать обе координаты x и y. На графе фенотипа CPPN входные узлы помечены квадратами, выходные узлы – закрашенные кружки, узел смещения – ромб, а скрытые узлы – пустые кружки. Два выходных узла на диаграмме CPPN имеют следующее назначение: первый узел (8) обеспечивает вес связи; второй узел (9) определяет, активирована связь или нет. Входные узлы CPPN определены следующим образом: первые два узла (0 и 1) задают координаты точки (x, z) во входном слое субстрата; следующие два узла (2 и 3) задают координаты точки (x, y) в скрытом слое субстрата; следующие два узла (4 и 5) задают координаты точки (x, y) в выходном слое субстрата; последний узел (6) устанавливает евклидово расстояние до точки во входном слое от начала координат. Тем не менее наиболее захватывающая часть результатов эксперимента показана на следующей схеме (рис. 8.7). Это конфигурация успешной нейро- сети зрительного детектора. Рис. 8.7. Конфигурация успешной нейросети зрительного детектора226  Метод ES-HyperNEAT и задача сетчатки\n--- Страница 228 ---\nКак и на предыдущей схеме, мы помечаем входные узлы квадратами, вы- ходные узлы – закрашенными кружками, узел смещения – ромбом, а скры- тые узлы – пустыми кружками. Как видите, у нас есть две четко разделенные модульные структуры с ле- вой и правой сторон графика. Каждый модуль подключен к соответствующим входам с левой (узлы 0, 1, 2 и 3) и правой (узлы 4, 5, 6 и 7) сторон сетчатки. Оба модуля имеют одинаковое количество скрытых узлов, которые связаны с соответствующими выходными узлами: узел 9 для левой стороны и узел 10 для правой стороны сетчатки. Также вы можете видеть, что паттерны связей в левом и правом модулях похожи. Скрытый узел 11 слева имеет связность, аналогичную узлу 14 справа, и то же самое можно сказать об узлах 12 и 13. Просто удивительно, как стохастический эволюционный процесс смог об- наружить такое простое и элегантное решение. Результаты этого экспери- мента полностью подтвердили нашу гипотезу о том, что задача сетчатки мо- жет быть решена путем поиска модульных топологий нейросети зрительного детектора. Более подробную информацию о задаче модульной сетчатки мож - но найти в оригинальной статье по адресу http://eplex.cs.ucf.edu/ papers/risi_ alife12.pdf.",
          "debug": {
            "start_page": 223,
            "end_page": 228
          }
        },
        {
          "name": "8.7 Упражнения 227",
          "content": "8.7 упражнения 1. Попробуйте запустить эксперимент с различными значениями генера- тора случайных чисел, которые можно изменить в строке 101 скрипта retina_experiment.py . Посмотрите, получится ли найти успешные реше- ния с другими значениями. 2. Попытайтесь увеличить начальный размер популяции до 1000, изменив значение параметра params.PopulationSize . Как это повлияло на произво- дительность алгоритма? 3. Попробуйте изменить количество типов функций активации, исполь- зованных в ходе эволюции, устанавливая вероятность выбора опреде- ленной функции равной 0. Особенно интересно посмотреть, что про- изойдет, если вы исключите из выбора типы активации ActivationFunc- tion_SignedGauss_Prob и ActivationFunction_SignedStep_Prob .",
          "debug": {
            "start_page": 228,
            "end_page": 228
          }
        },
        {
          "name": "8.8 Заключение 227",
          "content": "--- Страница 228 --- (продолжение)\n8.7 упражнения 1. Попробуйте запустить эксперимент с различными значениями генера- тора случайных чисел, которые можно изменить в строке 101 скрипта retina_experiment.py . Посмотрите, получится ли найти успешные реше- ния с другими значениями. 2. Попытайтесь увеличить начальный размер популяции до 1000, изменив значение параметра params.PopulationSize . Как это повлияло на произво- дительность алгоритма? 3. Попробуйте изменить количество типов функций активации, исполь- зованных в ходе эволюции, устанавливая вероятность выбора опреде- ленной функции равной 0. Особенно интересно посмотреть, что про- изойдет, если вы исключите из выбора типы активации ActivationFunc- tion_SignedGauss_Prob и ActivationFunction_SignedStep_Prob . 8.8 заключение В этой главе вы узнали о методе нейроэволюции, который позволяет конфигу - рации субстрата развиваться в процессе поиска решения задачи. Такой подход освобождает разработчика от необходимости проработки подходящей конфи- гурации субстрата до мельчайших деталей и позволяет обойтись только основ- ными очертаниями. Алгоритм автоматически найдет оставшиеся подробности конфигурации субстрата в процессе эволюции. Кроме того, вы узнали о модульных структурах нейросети, которые мож - но использовать для решения различных задач, включая задачу модульной сетчатки. Модульные топологии нейросетей – это очень мощная концепция, 8.8 Заключение  227\n8.8 заключение В этой главе вы узнали о методе нейроэволюции, который позволяет конфигу - рации субстрата развиваться в процессе поиска решения задачи. Такой подход освобождает разработчика от необходимости проработки подходящей конфи- гурации субстрата до мельчайших деталей и позволяет обойтись только основ- ными очертаниями. Алгоритм автоматически найдет оставшиеся подробности конфигурации субстрата в процессе эволюции. Кроме того, вы узнали о модульных структурах нейросети, которые мож - но использовать для решения различных задач, включая задачу модульной сетчатки. Модульные топологии нейросетей – это очень мощная концепция, 8.8 Заключение  227\n--- Страница 229 ---\nкоторая позволяет многократно использовать успешный модуль фенотипа нейросети для построения сложной иерархической топологии. Кроме того, у вас была возможность отточить свои навыки работы с языком программи- рования Python, реализовав решение задачи с использованием библиотеки MultiNEAT. В следующей главе мы обсудим увлекательную концепцию коэволюции и то, как ее можно использовать для одновременного развития решателя и целевой функции, которая используется для оптимизации. Мы обсудим ме- тод эволюции решения и приспособленности, и вы узнаете, как применить его в модифицированном эксперименте по прохождению лабиринта.228  Метод ES-HyperNEAT и задача сетчатки",
          "debug": {
            "start_page": 228,
            "end_page": 229
          }
        }
      ]
    },
    {
      "name": "Глава 9. Коэволюция и метод SAFE 229",
      "chapters": [
        {
          "name": "9.1 Технические требования 229",
          "content": "9.1 техниче Ские треб Ования Для проведения экспериментов, описанных в данной главе, ваш компьютер должен удовлетворять следующим техническим требованиям: Windows 8/10, macOS 10.13 или новее, или современный Linux; Anaconda Distribution версия 2019.03 или новее. Исходный код примеров этой главы можно найти в каталоге Chapter9 в фай- ловом архиве книги.",
          "debug": {
            "start_page": 230,
            "end_page": 230
          }
        },
        {
          "name": "9.2 Общие стратегии коэволюции 229",
          "content": "--- Страница 230 --- (продолжение)\nГлава 9 Коэволюция и метод SAFE В этой главе мы представим концепцию коэволюции и объясняем, как ее можно использовать для совместной эволюции решателя и целевой функ - ции, которая оптимизирует эволюцию решателя. Затем обсудим метод ко- эволюции решателя и приспособленности (solution and fitness evolution, SAFE) и дадим краткий обзор различных стратегий коэволюции. Вы узнаете, как объединить коэволюцию с нейроэволюционными методами, а также полу - чите практический опыт реализации модифицированного эксперимента по прохождению лабиринта. В данной главе мы рассмотрим следующие темы: принцип коэволюции и общие стратегии коэволюции; основы метода SAFE; модифицированный эксперимент по прохождению лабиринта; обсуждение результатов эксперимента. 9.1 техниче Ские треб Ования Для проведения экспериментов, описанных в данной главе, ваш компьютер должен удовлетворять следующим техническим требованиям: Windows 8/10, macOS 10.13 или новее, или современный Linux; Anaconda Distribution версия 2019.03 или новее. Исходный код примеров этой главы можно найти в каталоге Chapter9 в фай- ловом архиве книги. 9.2 О бщие Стратегии кОэвОлюции Естественная эволюция биологических систем не может рассматриваться от- дельно от концепции коэволюции. Коэволюция является одной из основных движущих сил эволюции, от которой зависит текущее состояние биосферы и разнообразие организмов. Мы можем определить коэволюцию как взаимовыгодную стратегию одно- временной эволюции множества генеалогий разных организмов. Эволюция одного вида невозможна без других видов. В ходе эволюции совместно эво- люционирующие виды взаимодействуют друг с другом, и эти межвидовые\n9.2 О бщие Стратегии кОэвОлюции Естественная эволюция биологических систем не может рассматриваться от- дельно от концепции коэволюции. Коэволюция является одной из основных движущих сил эволюции, от которой зависит текущее состояние биосферы и разнообразие организмов. Мы можем определить коэволюцию как взаимовыгодную стратегию одно- временной эволюции множества генеалогий разных организмов. Эволюция одного вида невозможна без других видов. В ходе эволюции совместно эво- люционирующие виды взаимодействуют друг с другом, и эти межвидовые\n--- Страница 231 ---\nотношения формируют их эволюционную стратегию. Существует три основ- ных типа коэволюции: мутуализм, когда два или более вида мирно сосуществуют и взаимно выигрывают друг от друга; конкурентная коэволюция: хищничество, когда один организм убивает другой и потребляет его ресурсы; паразитизм, когда один организм использует ресурсы другого, но не убивает его; комменсализм, когда представители одного вида получают выгоды, не причиняя вреда и не принося выгоды другим видам. Исследователи изучили каждый тип коэволюции и нашли у них не толь- ко достоинства, но и недостатки при использовании в качестве основного принципа нейроэволюции. Однако недавно группа исследователей достигла многообещающих результатов при использовании комменсализма. Они соз- дали алгоритм SAFE, который мы обсудим в этой главе. Подробнее об алгоритме SAFE можно прочитать в статье https://doi. org/10.1007/978-3-030-16670-0_10. Теперь, когда вы познакомились с общими типами коэволюции, давайте перейдем к изучению метода SAFE.",
          "debug": {
            "start_page": 230,
            "end_page": 231
          }
        },
        {
          "name": "9.3 Метод SAFE 230",
          "content": "--- Страница 231 --- (продолжение)\n9.3 метОД SAFE Как следует из названия, метод коэволюции решателя и приспособленности основан на совместной эволюции решения и функции приспособленности, ко- торая направляет оптимизацию поиска решения. Метод SAFE построен вокруг стратегии комменсалистической коэволюции двух популяций: популяция потенциальных решений, которые развиваются, чтобы ре- шить непосредственно поставленную задачу; популяция кандидатов на целевые функции, которые эволюциониру - ют, чтобы направлять эволюцию популяции решений. В этой книге мы уже обсудили несколько стратегий оптимизации, которые можно использовать для управления развитием потенциальных кандидатов на решение. Эти стратегии основаны на объективной оптимизации приспосо- бленности и оптимизации поиском новизны. Первая стратегия оптимизации идеальна в ситуациях, когда у нас простой ландшафт функции приспособ- ленности и мы можем сосредоточить оптимизацию на близости к конечной цели. В этом случае мы можем использовать объективную метрику, которая оценивает в каждом поколении эволюции, насколько близко наше текущее решение к месту назначения. Стратегия оптимизации поиском новизны устроена иначе. В этой страте- гии нас не интересует близость к конечной цели, но вместо этого нас больше всего интересует путь, который выбирают потенциальные решения. Основ- ная идея метода поиска новизны – постепенно исследовать все новые сту-230  Коэволюция и метод SAFE\n9.3 метОД SAFE Как следует из названия, метод коэволюции решателя и приспособленности основан на совместной эволюции решения и функции приспособленности, ко- торая направляет оптимизацию поиска решения. Метод SAFE построен вокруг стратегии комменсалистической коэволюции двух популяций: популяция потенциальных решений, которые развиваются, чтобы ре- шить непосредственно поставленную задачу; популяция кандидатов на целевые функции, которые эволюциониру - ют, чтобы направлять эволюцию популяции решений. В этой книге мы уже обсудили несколько стратегий оптимизации, которые можно использовать для управления развитием потенциальных кандидатов на решение. Эти стратегии основаны на объективной оптимизации приспосо- бленности и оптимизации поиском новизны. Первая стратегия оптимизации идеальна в ситуациях, когда у нас простой ландшафт функции приспособ- ленности и мы можем сосредоточить оптимизацию на близости к конечной цели. В этом случае мы можем использовать объективную метрику, которая оценивает в каждом поколении эволюции, насколько близко наше текущее решение к месту назначения. Стратегия оптимизации поиском новизны устроена иначе. В этой страте- гии нас не интересует близость к конечной цели, но вместо этого нас больше всего интересует путь, который выбирают потенциальные решения. Основ- ная идея метода поиска новизны – постепенно исследовать все новые сту-230  Коэволюция и метод SAFE\n--- Страница 232 ---\nпеньки, которые в конечном итоге ведут к месту назначения. Эта стратегия оптимизации идеальна для ситуаций, когда у нас сложный ландшафт функ - ции приспособленности со многими обманчивыми тупиками и локальными оптимумами. Основная идея метода SAFE состоит в том, чтобы извлечь выгоду из обоих методов оптимизации поиска, упомянутых здесь. Далее мы обсудим моди- фицированный эксперимент с лабиринтом, который для руководства про- цессом нейроэволюции использует оба метода поисковой оптимизации.",
          "debug": {
            "start_page": 231,
            "end_page": 232
          }
        },
        {
          "name": "9.4 Модифицированный эксперимент с лабиринтом 231",
          "content": "--- Страница 232 --- (продолжение)\n9.4 мОДифицир Ованный экСперимент С лабиринт Ом В этой книге мы уже обсуждали, как применять методы поисковой оптими- зации на основе близости к цели или поиска новизны к задаче решения ла- биринта. В данной главе мы представляем модифицированный эксперимент по прохождению лабиринта, в котором пытаемся объединить оба метода оп- тимизации поиска, используя алгоритм SAFE. Мы представляем коэволюцию двух популяций: агентов-решателей лаби- ринта и кандидатов на целевые функции. Следуя методу SAFE, мы используем в нашем эксперименте комменсалистическую стратегию коэволюции. Давай- те сначала обсудим устройство агента, который будет проходить лабиринт. 9.4.1 Агент-решатель задачи лабиринта Агент-решатель задачи лабиринта оснащен набором датчиков, позволяющих ему воспринимать среду лабиринта и знать направление к выходу из лабирин- та на каждом этапе. Расположение датчиков показано на рис. 9.1. Рис. 9.1. Расположение датчиков на агенте-решателе На этом рисунке темные стрелки обозначают дальномерные датчики, позволяющие агенту обнаруживать препятствия и находить расстояние до препятствия в заданном направлении. Четыре сектора, нарисованных во- круг тела робота, представляют собой радиолокаторы с секторным обзором, которые определяют направление к выходу из лабиринта на каждом шаге симуляции. Светлая стрелка внутри тела робота определяет направление, в котором он движется. 9.4 Модифицированный эксперимент с лабиринтом  231\n9.4 мОДифицир Ованный экСперимент С лабиринт Ом В этой книге мы уже обсуждали, как применять методы поисковой оптими- зации на основе близости к цели или поиска новизны к задаче решения ла- биринта. В данной главе мы представляем модифицированный эксперимент по прохождению лабиринта, в котором пытаемся объединить оба метода оп- тимизации поиска, используя алгоритм SAFE. Мы представляем коэволюцию двух популяций: агентов-решателей лаби- ринта и кандидатов на целевые функции. Следуя методу SAFE, мы используем в нашем эксперименте комменсалистическую стратегию коэволюции. Давай- те сначала обсудим устройство агента, который будет проходить лабиринт. 9.4.1 Агент-решатель задачи лабиринта Агент-решатель задачи лабиринта оснащен набором датчиков, позволяющих ему воспринимать среду лабиринта и знать направление к выходу из лабирин- та на каждом этапе. Расположение датчиков показано на рис. 9.1. Рис. 9.1. Расположение датчиков на агенте-решателе На этом рисунке темные стрелки обозначают дальномерные датчики, позволяющие агенту обнаруживать препятствия и находить расстояние до препятствия в заданном направлении. Четыре сектора, нарисованных во- круг тела робота, представляют собой радиолокаторы с секторным обзором, которые определяют направление к выходу из лабиринта на каждом шаге симуляции. Светлая стрелка внутри тела робота определяет направление, в котором он движется. 9.4 Модифицированный эксперимент с лабиринтом  231\n--- Страница 233 ---\nТакже у робота есть два привода: один для изменения его угловой ско- рости (вращение) и другой для изменения его линейной скорости (пере- движение). Мы используем ту же конфигурацию робота, что и в главе 5. Рекомендую вернуться к этой главе и перечитать раздел 5.3.1. Далее мы рассмотрим среду лабиринта. 9.4.2 Среда лабиринта Лабиринт определяется как пространство, окруженное снаружи сплошными стенами. Внутри лабиринта несколько внутренних перегородок создают мно- жество тупиков с локальными оптимумами, что делает оптимизацию по бли- зости к цели не очень эффективной. Кроме того, сосредоточенные на близости к цели агенты могут застревать в тупиках, полностью останавливая процесс эволюции. Тупики локальных оптимумов показаны на рис. 9.2. Рис. 9.2. Расположение локальных оптимумов внутри лабиринта На рис. 9.2 начальная позиция агента-решателя отмечена закрашенным кружком в нижнем левом углу, а выход из лабиринта отмечен закрашен- ным кружком в верхнем левом углу. Обманчивые области локальных оп- тимумов показаны в виде закрашенных секторов относительно начальной позиции агента. Среда лабиринта определена в файле конфигурации, а для имитации про- хождения агента через лабиринт применяется симулятор. Мы обсуждали реа лизацию симулятора лабиринта в разделе 5.3.2, и сейчас вы можете пере- читать этот раздел, чтобы вспомнить подробности. В данной главе мы обсудим модификации, которые были внесены в исход- ный эксперимент для реализации стратегии SAFE. Самое важное различие заключается в том, как определяется функция приспособленности, и мы об- судим это в следующем разделе. Вы найдете полный исходный код симулятора лабиринта в файле maze_environment.py .232  Коэволюция и метод SAFE\n--- Страница 234 ---\n9.4.3 Определение функции приспособленности Метод SAFE – это коэволюция кандидатов в успешные решатели и кандидатов в целевые функции, то есть мы имеем две популяции эволюционирующих ви- дов. Таким образом, нам нужно определить две функции приспособленности: одну для кандидатов на решение (решатели лабиринтов) и другую для канди- датов на целевые функции. В этом разделе мы обсудим оба варианта. Функция приспособленности для решателя задачи лабиринта В каждом поколении эволюции каждый индивидуум (решатель лабиринта) оценивается всеми кандидатами на целевые функции. Мы используем макси- мальную оценку приспособленности, полученную во время оценивания реша- теля каждым кандидатом на целевую функцию, в качестве оценки приспособ- ленности решения. Функция приспособленности решателя лабиринта представляет собой со- вокупность двух метрик – расстояния от выхода из лабиринта (оценка бли- зости к цели) и новизны конечной позиции решателя (оценка новизны). Эти оценки арифметически объединяются с использованием пары коэффициен- тов, полученных в качестве выходных данных от конкретного индивидуума в популяции кандидатов на целевую функцию. Следующая формула дает комбинацию этих показателей в качестве оцен- ки приспособленности: ()1 i i i ia bNS.D=×+×  Здесь Oi(Si) – это значения приспособленности, полученные путем оценки кандидата на решение Si, относительно целевой функции Oi. Пара коэффи- циентов [a, b] – это выход конкретного кандидата на целевую функцию. Эта пара определяет, в какой мере расстояние до выхода из лабиринта (Di) и по- веденческая новизна (NSi) решения влияют на конечную оценку приспособ- ленности решателя лабиринта в конце траектории. Расстояние до выхода из лабиринта (Di) определяется как евклидово рас- стояние между последними координатами решателя лабиринта в его тра- ектории и координатами выхода из лабиринта. Расстояние вычисляется по следующей формуле: ()()2 2 i s m s m D x x yy , =−+− xs и ys – последние координаты решателя, а xm и ym – координаты выхода из лабиринта. Оценка новизны NSi каждого решателя лабиринта определяется его окон- чательным положением в лабиринте (точка x). Она рассчитывается как сред- нее расстояние от этой точки до k-ближайших соседних точек, которые явля- ются окончательными позициями других решателей лабиринтов. Следующая формула дает значение оценки новизны в точке x поведенче- ского пространства: 9.4 Модифицированный эксперимент с лабиринтом  233\n--- Страница 235 ---\n() 01k i i iNS distx, .kµ ==∑ , где mi – это i-й ближайший сосед x , а dist( x, mi) – расстояние между x и mi. Расстояние между двумя точками является метрикой новизны, измеряю- щей, насколько текущее решение (x) отличается от другого (mi), созданного различными решателями лабиринтов. Показатель новизны рассчитывается как евклидово расстояние между двумя точками: ()()22 1j j jdistx, x . µ µ ==−∑ Здесь mj и xj – значения в позиции j координатных векторов, содержащих ко- ординаты точек m и x соответственно. Далее мы обсудим, как определить функцию приспособленности для опти- мизации кандидатов на роль целевой функции. Функция приспособленности для кандидатов на целевую функцию Метод SAFE основан на комменсалистическом коэволюционном подходе, ко- торый означает, что одна из совместно эволюционирующих популяций не по- лучает ни пользы, ни вреда в ходе эволюции. В нашем эксперименте коммен- салистическая популяция представляет собой совокупность кандидатов на целевые функции. Для этой совокупности нам нужно определить такую функ - цию приспособленности, которая не зависит от качества работы решателей лабиринтов. Подходящим вариантом является функция приспособленности, которая в качестве оценки приспособленности использует показатель новизны. Фор- мула для расчета оценки новизны каждого кандидата на роль целевой функ - ции такая же, как и для решателей лабиринтов. Единственное отличие состо- ит в том, что в случае кандидатов на роль целевой функции мы рассчитываем оценку новизны, используя векторы с выходными значениями каждого ин- дивидуума. После этого применяем значение показателя новизны в качестве показателя приспособленности особи. Этот метод оценки новизны является частью модифицированного метода поиска новизны, который мы обсудим в следующем разделе.",
          "debug": {
            "start_page": 232,
            "end_page": 235
          }
        },
        {
          "name": "9.5 Модифицированный поиск новизны 234",
          "content": "--- Страница 235 --- (продолжение)\n9.5 мОДифицир Ованный пОиСк нОвизны Вы познакомились с методом поиска новизны в главе 6. В текущем экспери- менте мы используем слегка модифицированный вариант метода, который обсудим далее. Модификации метода поиска новизны, которые мы представим в этом экс- перименте, относятся к новому способу сохранения архива баллов новизны (новинок). Балл новизны отражает местоположение агента-решателя в конце траектории, которое комбинируется с оценкой новизны. В более традиционной версии метода размер архива новинок является ди- намическим, что позволяет добавлять новый элемент, если его оценка но-234  Коэволюция и метод SAFE\n9.5 мОДифицир Ованный пОиСк нОвизны Вы познакомились с методом поиска новизны в главе 6. В текущем экспери- менте мы используем слегка модифицированный вариант метода, который обсудим далее. Модификации метода поиска новизны, которые мы представим в этом экс- перименте, относятся к новому способу сохранения архива баллов новизны (новинок). Балл новизны отражает местоположение агента-решателя в конце траектории, которое комбинируется с оценкой новизны. В более традиционной версии метода размер архива новинок является ди- намическим, что позволяет добавлять новый элемент, если его оценка но-234  Коэволюция и метод SAFE\n--- Страница 236 ---\nвизны превышает определенный порог (порог новизны). Кроме того, порог новизны может быть скорректирован во время выполнения с учетом того, как быстро обнаруживаются новые точки новизны в ходе эволюции. Эти на- стройки позволяют нам в некоторой степени контролировать максимальный размер архива. Однако нам нужно начать с начального порогового значения новизны, и этот выбор не очевиден. Модифицированный метод поиска новизны подразумевает архив фикси- рованного размера, чтобы решить вопрос выбора правильного порогового значения новизны. Новые элементы добавляются в архив до тех пор, пока он не заполнится. После этого новый элемент добавляется в архив путем вытесне- ния текущего элемента с минимальной оценкой только в том случае, если его оценка новизны превышает текущий минимальный балл архива. Таким обра- зом, мы можем поддерживать фиксированный размер архива новинок и хра- нить в нем только самые ценные новинки, обнаруженные в ходе эволюции. Исходный код модифицированного поиска новизны представлен в файле novelty_archive.py в файловом архиве книги. Далее давайте обсудим наиболее интересные части реализации. 9.5.1 Функция _add_novelty_item Эта функция позволяет добавлять новые элементы в архив при сохранении его размера. Она имеет следующую реализацию: if len(self.novel_items) >= MAXNoveltyArchiveSize: # Проверяем, превышает ли новизна этой точки check # минимальное значение в архиве (минимальную новизну). if item > self.novel_items[-1]: # Заменяем значение self.novel_items[-1] = itemelse: # Просто добавляем новое значение. self.novel_items.append(item) # Сортируем элементы массива по убыванию значений self.novel_items.sort(reverse=True) Код сначала проверяет, не был ли еще превышен размер архива новинок, и в этом случае напрямую добавляет к нему новый элемент. В противном случае новый элемент вытесняет последний элемент в архиве, то есть эле- мент с наименьшим баллом новизны. Мы можем быть уверены, что послед- ний элемент в архиве имеет наименьшую оценку новизны, потому что пос- ле добавления нового элемента в архив мы сортируем элементы в порядке убывания баллов. 9.5.2 Функция evaluate_novelty_score Эта функция предоставляет механизм для вычисления баллов новизны по всем элементам, уже собранным в архиве новинок, и всем новинкам, обнару - 9.5 Модифицированный поиск новизны  235\n--- Страница 237 ---\nженным в текущей популяции. Мы рассчитываем балл новизны как среднее расстояние до k = 15 ближайших соседей, выполнив следующие шаги. 1. Собираем расстояния от рассматриваемой точки до всех элементов, уже хранящихся в архиве новинок: distances = [] for n in self.novel_items: if n.genomeId != item.genomeId: distances.append(self.novelty_metric(n, item)) else: print(\"Novelty Item is already in archive: %d\" % n.genomeId) 2. После этого складываем расстояния от рассматриваемой точки до всех особей в текущей популяции: for p_item in n_items_list: if p_item.genomeId != item.genomeId: distances.append(self.novelty_metric(p_item, item)) 3. Наконец, вычисляем среднее значение k-ближайших соседей: distances = sorted(distances) item.novelty = sum(distances[:KNN])/KNN Мы сортируем список по расстояниям в порядке возрастания, чтобы га- рантировать, что ближайшие элементы находятся первыми в списке. После этого мы вычисляем сумму первых k = 15 элементов в списке и делим ее на количество суммированных значений. Таким образом, мы получаем значе- ние среднего расстояния до k-ближайших соседей. Модифицированный метод оптимизации поиском новизны лежит в основе оценки приспособленности как для популяции решателей лабиринта, так и для популяции кандидатов на роль целевой функции. Мы широко используем его в реализации эксперимента, о которой поговорим в следующем разделе.",
          "debug": {
            "start_page": 235,
            "end_page": 237
          }
        },
        {
          "name": "9.6 Движок модифицированного эксперимента с лабиринтом 236",
          "content": "--- Страница 237 --- (продолжение)\n9.6 Д виж Ок мОДифицир Ованн ОгО экСперимента С лабиринт Ом Реализация движка эксперимента основана на библиотеке MultiNEAT, которую мы использовали в нескольких экспериментах в этой книге. Развитие каждой совместно эволюционирующей популяции происходит в соответствии с базо- вым алгоритмом NEAT, который обсуждался в главах 3–5. Тем не менее в этом разделе мы покажем, как использовать алгоритм NEAT для поддержания коэволюции двух независимых популяций видов: решате- лей лабиринтов и кандидатов в целевые функции. Далее мы обсудим основные части модифицированного движка экспери- мента. Для детального изучения исходного кода обратитесь к файлу maze_ex- periment_safe.py из файлового архива книги.236  Коэволюция и метод SAFE\n9.6 Д виж Ок мОДифицир Ованн ОгО экСперимента С лабиринт Ом Реализация движка эксперимента основана на библиотеке MultiNEAT, которую мы использовали в нескольких экспериментах в этой книге. Развитие каждой совместно эволюционирующей популяции происходит в соответствии с базо- вым алгоритмом NEAT, который обсуждался в главах 3–5. Тем не менее в этом разделе мы покажем, как использовать алгоритм NEAT для поддержания коэволюции двух независимых популяций видов: решате- лей лабиринтов и кандидатов в целевые функции. Далее мы обсудим основные части модифицированного движка экспери- мента. Для детального изучения исходного кода обратитесь к файлу maze_ex- periment_safe.py из файлового архива книги.236  Коэволюция и метод SAFE\n--- Страница 238 ---\n9.6.1 Создание совместно эволюционирующих популяций В этом эксперименте нам необходимо создать две совместно развивающиеся популяции видов с различными исходными конфигурациями генотипа, чтобы удовлетворить фенотипические требования продуцируемых видов. Фенотип решателя лабиринтов имеет 11 входных узлов для приема сиг- налов от датчиков и два выходных узла для выдачи управляющих сигналов. В то же время фенотип кандидата на целевую функцию имеет один входной узел, принимающий фиксированное значение (0,5), которое преобразуется в два выходных значения, которые используются в качестве коэффициентов функции приспособленности решателя лабиринта. Начнем с обсуждения того, как создать популяцию кандидатов на целевую функцию. Создание популяции кандидатов на целевую функцию Генотип, кодирующий фенотип кандидатов на целевую функцию, должен соз- давать конфигурации фенотипа, которые имеют по крайней мере один вход- ной узел и два выходных узла, как было сказано ранее. Создание популяции в функции create_objective_fun реализовано следующим образом: params = create_objective_fun_params() # Геном имеет один вход (0.5) и два выхода (a и b). genome = NEAT.Genome(0, 1, 1, 2, False, NEAT.ActivationFunction.TANH, # hidden layer activation NEAT.ActivationFunction.UNSIGNED_SIGMOID, # output layer activation 1, params, 0) pop = NEAT.Population(genome, params, True, 1.0, seed)pop.RNG.Seed(seed) obj_archive = archive.NoveltyArchive( metric=maze.maze_novelty_metric_euclidean) obj_fun = ObjectiveFun(archive=obj_archive, genome=genome, population=pop) В этом коде мы создаем генотип NEAT с одним входным узлом, двумя вы- ходными узлами и одним скрытым узлом. Скрытый узел предварительно внесен в исходный геном, чтобы ускорить эволюцию с заранее определенной нелинейностью. В качестве функции активации скрытого слоя с поддержкой отрицательных выходных значений выбран гиперболический тангенс. Эта особенность важна для нашей задачи. Отрицательное значение одного из коэффициентов, созданных кандидатом на целевую функцию, может указы- вать на то, что конкретный компонент функции приспособленности решате- ля лабиринта оказывает отрицательное влияние, и таким образом посылает сигнал, что эволюция должна пробовать другие пути. В конце мы создаем объект ObjectiveFun для хранения растущей популяции кандидатов на целевую функцию. Далее обсудим, как создается популяция решателей лабиринтов. 9.6 Движок модифицированного эксперимента с лабиринтом  237\n--- Страница 239 ---\nСоздание популяции решателей лабиринтов Агент-решатель лабиринта должен получать входные данные от 11 датчи- ков и генерировать два управляющих сигнала, которые влияют на угловую и линейную скорости робота. Следовательно, геном, кодирующий фенотип решателя лабиринта, должен определять конфигурации, которые включают 11 входных узлов и два выходных узла. Чтобы узнать, как создается начальная популяция геномов для решателя, изучите код функции create_robot : params = create_robot_params() # Геном имеет 11 входов и два выхода genome = NEAT.Genome(0, 11, 0, 2, False, NEAT.ActivationFunction.UNSIGNED_SIGMOID, NEAT.ActivationFunction.UNSIGNED_SIGMOID, 0, params, 0) pop = NEAT.Population(genome, params, True, 1.0, seed) pop.RNG.Seed(seed) robot_archive = archive.NoveltyArchive(metric=maze.maze_novelty_metric) robot = Robot(maze_env=maze_env, archive=robot_archive, genome=genome, population=pop) В коде мы получаем соответствующие гиперпараметры NEAT из функции create_robot_params . После этого используем их для создания исходного NEAT- генотипа с соответствующим количеством входных и выходных узлов. Нако- нец, мы создаем объект Robot, который инкапсулирует все данные, относящие- ся к популяции решателей лабиринтов, а также среду симулятора лабиринта. Теперь, когда мы создали две совместно эволюционирующие популяции, нам необходимо реализовать оценку приспособленности для особей из обеих попу - ляций. В следующем разделе обсудим реализацию оценки приспособленности. 9.6.2 Оценка приспособленности совместно развивающихся популяций Определив две совместно развивающиеся популяции, нам необходимо соз- дать функции для оценки показателей приспособленности особей в каждой популяции. Как мы уже упоминали, показатели приспособленности особей в популяции решателей лабиринта зависят от выходных значений, произво- димых популяцией кандидатов на целевую функцию. В то же время оценка приспособ ленности каждого кандидата на целевую функцию полностью опре- деляется оценкой новизны этой особи. Таким образом, у нас есть два разных подхода к оценке показателей при- способленности, и нам нужно реализовать две разные функции. Далее мы обсудим обе реализации. Оценка приспособленности кандидатов на целевую функцию Оценка приспособленности каждого индивидуума в популяции кандидатов на целевые функции определяется его баллом новизны, который рассчитывается, как мы обсуждали ранее. Реализация оценки приспособленности состоит из двух функций – evaluate_obj_functions и evaluate_individ_obj_function . Давайте рассмотрим реализации обеих функций.238  Коэволюция и метод SAFE\n--- Страница 240 ---\nРеализация функции evaluate_obj_functions Эта функция принимает объект ObjectiveFun , который содержит совокупность кандидатов на целевые функции, и использует его для оценки приспособлен- ности каждого индивидуума в популяции, выполнив следующие действия. 1. Сначала мы перебираем все геномы в популяции и собираем баллы но- визны для каждого генома: obj_func_genomes = NEAT.GetGenomeList(obj_function.population) for genome in obj_func_genomes: n_item = evaluate_individ_obj_function(genome=genome, generation=generation) n_items_list.append(n_item) obj_func_coeffs.append(n_item.data) В коде баллы новизны, полученные с помощью функции evaluate_individ_ obj_function , добавляются к списку баллов новизны в популяции. Также мы добавляем данные балла новизны в список пар коэффициентов. Позже спи- сок пар коэффициентов будет использоваться для вычисления показателей приспособленности индивидуальных решателей лабиринтов. 2. Затем мы перебираем список геномов популяции и получаем оцен- ку новизны каждого генома, используя баллы новизны, собранные на предыдущем шаге: max_fitness = 0 for i, genome in enumerate(obj_func_genomes): fitness = obj_function.archive.evaluate_novelty_score( item=n_items_list[i],n_items_list=n_items_list) genome.SetFitness(fitness) max_fitness = max(max_fitness, fitness) Оценка новизны, вычисленная с использованием баллов новизны, уже включена в архив новинок и в список новинок, созданный для текущей по- пуляции. После этого мы устанавливаем найденный показатель новизны как показатель приспособленности соответствующего генома. Кроме того, нахо- дим максимальное значение показателя приспособленности и возвращаем его вместе со списком пар коэффициентов. Реализация функции evaluate_individ_obj_function Эта функция принимает NEAT-геном кандидата в целевую функцию и возвра- щает результаты расчета балла новизны: n_item = archive.NoveltyItem(generation=generation, genomeId=genome_id) # Запуск симуляции multi_net = NEAT.NeuralNetwork() genome.BuildPhenotype(multi_net) depth = 2try: genome.CalculateDepth() depth = genome.GetDepth() except: pass 9.6 Движок модифицированного эксперимента с лабиринтом  239\n--- Страница 241 ---\nobj_net = ANN(multi_net, depth=depth) # Задаем вход и получаем выход ([a, b]) output = obj_net.activate([0.5]) # Сохраняем коэффициенты n_item.data.append(output[0])n_item.data.append(output[1]) Мы начнем с создания объекта NoveltyItem для хранения данных балла но- визны для данного генома. После этого строим фенотип нейросети и активи- руем его значением 0.5. Наконец, используем выходные данные нейросети, чтобы создать очередную точку новизны. В следующем разделе мы обсудим оценку приспособленности особей в по- пуляции решателей лабиринтов. Оценка приспособленности агентов, решающих лабиринт Мы находим оценку приспособленности каждой особи в популяции лабирин- тов как сочетание двух компонентов: оценки новизны и расстояния до выхода из лабиринта в конце траектории. Влияние каждого компонента определяется парой коэффициентов, возвращаемой особями из популяции кандидатов на целевые функции. Код для расчета приспособленности состоит из трех функций, которые мы обсудим далее. Реализация функции evaluate_solutions Функция evaluate_solutions в качестве входного параметра получает объект Ro- bot, который инкапсулирует популяцию агентов-решателей и симулятор среды лабиринта. Кроме того, она получает список пар коэффициентов, сгенериро- ванных во время оценки популяции кандидатов на целевые функции. Мы используем входные параметры функции для оценки каждого генома в популяции и вычисления его приспособленности. Функция состоит из сле- дующих основных частей. 1. Сначала мы запускаем симуляцию прохождения лабиринта каждой особью в популяции и находим расстояние до выхода из лабиринта в конце траектории: robot_genomes = NEAT.GetGenomeList(robot.population) for genome in robot_genomes: found, distance, n_item = evaluate_individual_solution( genome=genome, generation=generation, robot=robot) # Сохраняем полученное значение. distances.append(distance) n_items_list.append(n_item) 2. Затем перебираем все геномы в популяции и вычисляем оценку но- визны каждой особи. Кроме того, мы берем полученное ранее соответ - ствующее расстояние до выхода из лабиринта и объединяем его с рас - считанной оценкой новизны, чтобы получить окончательную оценку приспособленности генома:240  Коэволюция и метод SAFE\n--- Страница 242 ---\nfor i, n_item in enumerate(n_items_list): novelty = robot.archive.evaluate_novelty_score(item=n_item, n_items_list=n_items_list) # Проверка правильности. assert robot_genomes[i].GetID() == n_item.genomeId # Вычисление приспособленности. fitness, coeffs = evaluate_solution_fitness(distances[i], novelty, obj_func_coeffs) robot_genomes[i].SetFitness(fitness) В первой половине кода мы используем функцию robot.archive.evaluate_ novelty_score , чтобы получить оценку новизны каждой особи в популяции. Вторая половина вызывает функцию evaluate_solution_fitness , чтобы полу - чить оценку приспособленности каждой особи, используя оценку новизны и расстояние до выхода из лабиринта. 3. Наконец, мы собираем статистику об эффективности лучшего генома решателя в популяции: if not solution_found: # Находим лучший геном в популяции if max_fitness < fitness: max_fitness = fitness best_robot_genome = robot_genomes[i] best_coeffs = coeffs best_distance = distances[i] best_novelty = noveltyelif best_robot_genome.GetID() == n_item.genomeId: # Сохраняем приспособленность решения-победителя max_fitness = fitness best_coeffs = coeffs best_distance = distances[i] best_novelty = novelty Завершая работу, функция возвращает всю статистику, собранную во время оценки популяции. Далее мы обсудим, как с помощью симулятора среды лабиринта оценива- ется отдельный геном решателя. Реализация функции evaluate_individual_solution Данная функция оценивает производительность отдельного генома решателя в симуляторе среды лабиринта. Это происходит следующим образом. 1. Сначала мы создаем фенотип нейросети решателя и используем эту нейросеть в качестве контроллера для управления движением робота через лабиринт: n_item = archive.NoveltyItem(generation=generation, genomeId=genome_id) # Запуск симуляции maze_env = copy.deepcopy(robot.orig_maze_environment)multi_net = NEAT.NeuralNetwork() 9.6 Движок модифицированного эксперимента с лабиринтом  241\n--- Страница 243 ---\ngenome.BuildPhenotype(multi_net) depth = 8try: genome.CalculateDepth() depth = genome.GetDepth() except: passcontrol_net = ANN(multi_net, depth=depth)distance = maze.maze_simulation_evaluate( env=maze_env, net=control_net, time_steps=SOLVER_TIME_STEPS, n_item=n_item) В этой части кода мы создаем объект NoveltyItem для хранения точки новиз- ны, которая определяется конечной позицией робота в лабиринте. После это- го создаем фенотип нейросети и запускаем симулятор лабиринта, используя нейросеть в качестве контроллера робота на заданном количестве времен- ных шагов (400). После завершения симуляции получаем расстояние между конечной позицией решателя и выходом из лабиринта. 2. Затем мы сохраняем статистику моделирования в объекте AgentRecord , который проанализируем в конце эксперимента: record = agent.AgenRecord(generation=generation, agent_id=genome_id) record.distance = distancerecord.x = maze_env.agent.location.xrecord.y = maze_env.agent.location.y record.hit_exit = maze_env.exit_found record.species_id = robot.get_species_id(genome)robot.record_store.add_record(record) Функция возвращает кортеж со следующими значениями: флаг, указы- вающий, найдено ли решение, расстояние до выхода из лабиринта в конце траектории робота и объект NoveltyItem , инкапсулирующий информацию об обнаруженной точке новизны. В следующем разделе мы обсудим реализацию функции приспособленно- сти решателя лабиринта. Реализация функции evaluate_solution_fitness Это реализация функции приспособленности решателя лабиринта, которую мы обсуждали ранее. Функция получает расстояние до выхода из лабиринта, оценку новизны и список пар коэффициентов, сгенерированных текущим по- колением кандидатов на целевую функцию. Затем она использует полученные входные параметры для расчета оценки приспособленности: normalized_novelty = novelty if novelty >= 1.00: normalized_novelty = math.log(novelty)norm_distance = math.log(distance) max_fitness = 0 best_coeffs = [-1, -1]242  Коэволюция и метод SAFE\n--- Страница 244 ---\nfor coeff in obj_func_coeffs: fitness = coeff[0] / norm_distance + coeff[1] * normalized_novelty if fitness > max_fitness: max_fitness = fitness best_coeffs[0] = coeff[0] best_coeffs[1] = coeff[1] Сначала мы должны нормализовать значения расстояния и оценки новиз- ны, используя натуральный логарифм. Нормализация приводит значения расстояния и оценки новизны к одному масштабу. Это важно, потому что пара коэффициентов всегда находится в интервале [0,1]. Следовательно, если значения расстояния и оценки новизны имеют разный масштаб, пара коэф- фициентов не сможет правильно влиять на значимость каждого значения при расчете оценки приспособленности. Код перебирает список пар коэффициентов и для каждой пары коэффици- ентов вычисляет оценку приспособленности, комбинируя значения расстоя- ния и оценки новизны. В качестве окончательного показателя приспособленности решателя бе- рется максимальное значение среди всех найденных показателей приспособ- ленности. Затем функция возвращает это значение и соответствующую пару коэффициентов. 9.6.3 выпОлнение экСперимента мОДифицир Ованн ОгО лабиринта Теперь, когда мы подготовили все необходимые процедуры для создания со- вместно развивающихся популяций и оценки приспособленности особей в этих популяциях, мы готовы приступить к реализации цикла эксперимента. Полный исходный код функции run_experiment можно найти в файле maze_experiment_safe.py в файловом архиве книги. Полный рабочий цикл эксперимента состоит из следующих шагов. 1. Начинаем с создания популяций совместно эволюционирующих видов: robot = create_robot(maze_env, seed=seed) obj_func = create_objective_fun(seed) 2. Запускаем цикл эволюции и оцениваем обе популяции: for generation in range(n_generations): # Оцениваем популяцию кандидатов на функцию приспособленности. obj_func_coeffs, max_obj_func_fitness = \\ evaluate_obj_functions(obj_func, generation) # Оцениваем популяцию решателей. robot_genome, solution_found, robot_fitness, distances, \\ obj_coeffs, best_distance, best_novelty = \\ evaluate_solutions(robot=robot, obj_func_coeffs=obj_func_coeffs, generation=generation) 9.6.3 Выполнение эксперимента модифицированного лабиринта  243\n--- Страница 245 ---\n3. Получив оценки популяций, сохраняем результаты в виде статистики текущего поколения эволюции: stats.post_evaluate(max_fitness=robot_fitness, errors=distances) # Сохраняем лучший геном best_fitness = robot.population.GetBestFitnessEver() if solution_found or best_fitness < robot_fitness: best_robot_genome_ser = pickle.dumps(robot_genome) best_robot_id = robot_genome.GetID() best_obj_func_coeffs = obj_coeffs best_solution_novelty = best_novelty 4. Если в текущем поколении решение не нашлось, то в конце цикла эво- люции мы просим обе популяции перейти к следующему поколению: if solution_found: print('Solution found at generation: %d, best fitness: %f, species count: %d' % (generation, robot_fitness, len(pop.Species))) break# Переход к следующему поколению.robot.population.Epoch()obj_func.population.Epoch() 5. После того как цикл эволюции совершил итерации в течение заданного числа поколений, мы визуализируем накопленные записи о прохожде- нии лабиринта: if args is None: visualize.draw_maze_records(maze_env, robot.record_store.records, view=show_results)else: visualize.draw_maze_records(maze_env, robot.record_store.records, view=show_results, width=args.width, height=args.height, filename=os.path.join(trial_out_dir, 'maze_records.svg')) Упомянутые здесь записи прохождения лабиринта содержат статистику оценок каждого генома решателя в симуляторе лабиринта, собранную во время эволюции в виде объектов AgentRecord . В визуализации мы отображаем конечную позицию каждого рассмотренного решателя в лабиринте. 6. Далее мы моделируем прохождение лабиринта с помощью управляющей нейросети, которая была создана с использованием лучшего генома, най- денного в ходе эволюции. Траектория движения по лабиринту во время моделирования может быть визуализирована следующим образом: multi_net = NEAT.NeuralNetwork() best_robot_genome.BuildPhenotype(multi_net) control_net = ANN(multi_net, depth=depth)244  Коэволюция и метод SAFE\n--- Страница 246 ---\npath_points = [] distance = maze.maze_simulation_evaluate( env=maze_env, net=control_net, time_steps=SOLVER_TIME_STEPS, path_points=path_points) print(\"Best solution distance to maze exit: %.2f, novelty: %.2f\" % (distance, best_solution_novelty))visualize.draw_agent_path(robot.orig_maze_environment, path_points, best_robot_genome, view=show_results, width=args.width, height=args.height, filename=os.path.join(trial_out_dir, 'best_solver_path.svg')) Сначала код создает фенотип нейросети из лучшего решающего генома. Затем он запускает симулятор лабиринта, используя созданный фенотип в качестве контроллера робота. Потом создается рисунок, отображающий точки траектории робота. 7. Наконец, мы отображаем график со средними показателями приспособ- ленности для каждого поколения: visualize.plot_stats(stats, ylog=False, view=show_results, filename=os.path.join(trial_out_dir,'avg_fitness.svg')) Все упомянутые здесь визуализации также сохраняются в локальной фай- ловой системе в виде файлов SVG и могут быть использованы позже для ана- лиза результатов. В следующем разделе мы обсудим выполнение модифицированного экс- перимента с лабиринтом и результаты эксперимента.",
          "debug": {
            "start_page": 237,
            "end_page": 246
          }
        },
        {
          "name": "9.7 Эксперимент с модифицированным лабиринтом 245",
          "content": "--- Страница 246 --- (продолжение)\n9.7 экСперимент С мОДифицир Ованным лабиринт Ом Мы почти готовы запустить процесс коэволюции в модифицированном экс- перименте с лабиринтом. Однако сначала мы должны настроить гиперпара- метры для каждой эволюционирующей популяции. 9.7.1 Гиперпараметры для популяции агентов-решателей Для этого эксперимента мы решили использовать библиотеку MultiNEAT, ко- торая использует класс Python Parameters для ведения списка всех поддержи- ваемых гиперпараметров. Инициализация гиперпараметров для популяции агентов-решателей происходит в функции create_robot_params . Далее мы обсу - дим основные гиперпараметры и причины выбора конкретных значений. 1. Мы решили с самого начала иметь популяцию среднего размера, обес- печивающую достаточно обширное разнообразие особей: params.PopulationSize = 250 2. Мы заинтересованы в создании компактной топологии генома во вре- мя эволюции и ограничении числа видов в популяции. Поэтому опре- деляем маленькие вероятности добавления новых узлов и соединений в ходе эволюции: 9.7 Эксперимент с модифицированным лабиринтом  245\n9.7 экСперимент С мОДифицир Ованным лабиринт Ом Мы почти готовы запустить процесс коэволюции в модифицированном экс- перименте с лабиринтом. Однако сначала мы должны настроить гиперпара- метры для каждой эволюционирующей популяции. 9.7.1 Гиперпараметры для популяции агентов-решателей Для этого эксперимента мы решили использовать библиотеку MultiNEAT, ко- торая использует класс Python Parameters для ведения списка всех поддержи- ваемых гиперпараметров. Инициализация гиперпараметров для популяции агентов-решателей происходит в функции create_robot_params . Далее мы обсу - дим основные гиперпараметры и причины выбора конкретных значений. 1. Мы решили с самого начала иметь популяцию среднего размера, обес- печивающую достаточно обширное разнообразие особей: params.PopulationSize = 250 2. Мы заинтересованы в создании компактной топологии генома во вре- мя эволюции и ограничении числа видов в популяции. Поэтому опре- деляем маленькие вероятности добавления новых узлов и соединений в ходе эволюции: 9.7 Эксперимент с модифицированным лабиринтом  245\n--- Страница 247 ---\nparams.MutateAddNeuronProb = 0.03 params.MutateAddLinkProb = 0.05 3. Оценка новизны служит вознаграждением за нахождение уникальных позиций в лабиринте. Одним из способов заработать вознаграждение является усиление численной динамики в рамках фенотипа. Поэтому мы увеличили интервал значений весов связей: params.MaxWeight = 30.0 params.MinWeight = -30.0 4. Чтобы поддержать эволюционный процесс, мы решили ввести элитар- ность, определив долю геномов, которые будут переданы следующему поколению: params.Elitism = 0.1 Значение элитарности определяет, что примерно одна десятая часть по- пуляции будет отнесена к следующему поколению. 9.7.2 Гиперпараметры популяции кандидатов на целевую функцию Инициализация гиперпараметров для эволюции популяции кандидатов на целевую функцию происходит в функции create_objective_fun_params . Наи- более важными являются следующие гиперпараметры. 1. Мы решили начать с небольшой популяции, чтобы уменьшить вычис - лительные затраты. Кроме того, не ожидается, что генотипы кандида- тов на целевую функцию будут очень сложными. Следовательно, не- большой популяции должно быть достаточно: params.PopulationSize = 100 2. Как и в случае с решателями, мы заинтересованы в создании компакт - ных геномов. Поэтому задаем очень маленькую вероятность добавле- ния новых узлов и соединений: params.MutateAddNeuronProb = 0.03 params.MutateAddLinkProb = 0.05 Мы не ожидаем получить сложную топологию геномов в популяции кан- дидатов на целевую функцию. Поэтому для большинства гиперпараметров оставлены значения по умолчанию. 9.7.3 Настройка рабочей среды В этом эксперименте мы используем библиотеку MultiNEAT. Перед запуском эксперимента нам нужно создать соответствующую среду Python, которая включает эту библиотеку и другие зависимости. Вы можете настроить среду Python с помощью Anaconda, выполнив следующие команды: $ conda create --name maze_co python=3.5$ conda activate maze_co $ conda install -c conda-forge multineat$ conda install matplotlib246  Коэволюция и метод SAFE\n--- Страница 248 ---\n$ conda install graphviz $ conda install python-graphviz Эти команды создают виртуальную среду maze_co с Python 3.5 и устанавли- вают в нее все необходимые зависимости. 9.7.4 Проведение модифицированного эксперимента с лабиринтом Теперь мы готовы запустить эксперимент в созданной виртуальной среде. Вы можете начать эксперимент, клонировав соответствующий репозиторий Git и запустив скрипт с помощью следующих команд: $ git clone https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Python.git $ cd Hands-on-Neuroevolution-with-Python/Chapter9 $ python maze_experiment_safe.py -t 1 -g 150 -m medium Не забудьте активировать рабочую среду при помощи команды conda activate maze_co. Предыдущая команда запускает одно испытание эксперимента для 150 поколений эволюции, используя конфигурацию лабиринта средней сложности. Примерно через 100 поколений эволюции, в процессе нейроэво- люции, будет найдено успешное решение, и вы сможете увидеть следующий вывод в консоли: ****** Generation: 105 ****** Maze solved in 338 steps Solution found at generation: 105, best fitness: 3.549289, species count: 7 ================================== Record store file: out/maze_medium_safe/5/data.pickleRandom seed: 1571021768Best solution fitness: 3.901621, genome ID: 26458Best objective func coefficients: [0.7935419704765059, 0.9882050653334634]------------------------------ Maze solved in 338 steps Best solution distance to maze exit: 3.56, novelty: 19.29------------------------Trial elapsed time: 4275.705 sec================================== В данном примере успешный решатель лабиринтов был найден в поколе- нии 105 и смог пройти лабиринт за 338 шагов из отведенных 400. Кроме того, интересно отметить, что пара коэффициентов, созданная лучшим кандида- том на целевую функцию, придает немного большее значение компоненту оценки новизны в функции приспособленности решателя. 9.7 Эксперимент с модифицированным лабиринтом  247\n--- Страница 249 ---\nИнтересно взглянуть на график лучших показателей приспособленности по поколениям (рис. 9.3). ПоколенияЛучшая приспособленность в популяции и среднее расстояниеCреднее расстояние Приспособленностьсреднее расстояние –1 СКО +1 СКО Рис. 9.3. Показатели лучшей приспособленности по поколениям На этом графике хорошо видно, что лучший показатель приспособленно- сти имеет максимум в ранних поколениях эволюции. Это связано с высокими значениями оценки новизны, которые легче получить в начале эволюции, потому что есть много областей лабиринта, которые не были исследованы. Еще один важный момент, на который следует обратить внимание, – это то, что среднее расстояние до выхода из лабиринта остается почти на одном уровне для большинства поколений эволюции. Отсюда мы можем предпо- ложить, что правильное решение было найдено не постепенными улучше- ниями, а скорее за счет качественного скачка генома победителя. Этот вы- вод также подтверждается следующей визуализацией, на которой показаны запи си прохождения лабиринта по видам (рис. 9.4). Визуализация состоит из двух частей: верхняя часть для видов с целе- ориентированной оценкой приспособленности (на основе расстояния от выхода из лабиринта) более 0,8 и нижняя часть для других видов. Вы мо- жете видеть, что только один вид произвел геном потомка, который смог достичь окрестности выхода из лабиринта. Кроме того, вы можете видеть, что геномы, принадлежащие этому виду, демонстрируют выраженное ис- следовательское поведение, исследуя больше областей лабиринта, чем все другие виды вместе взятые.248  Коэволюция и метод SAFE\n--- Страница 250 ---\nПриспособленность < 0.8Приспособленность >= 0.8, виды: 1 Рис. 9.4. Записи прохождения лабиринтов решателями с указанием финальных позиций Наконец, мы можем рассмотреть визуализацию пути успешного решателя через лабиринт (рис. 9.5). Индекс генома: 26 458, длина пути: 337 Рис. 9.5. Путь успешного решателя через лабиринт Траектория успешного решателя является почти оптимальной для данной конфигурации лабиринта. Этот эксперимент также демонстрирует важность начальных условий в по- иске успешного решения. Начальные условия определяются начальным зна- чением генератора случайных чисел, которое мы выбираем перед запуском эксперимента. 9.7 Эксперимент с модифицированным лабиринтом  249",
          "debug": {
            "start_page": 246,
            "end_page": 250
          }
        },
        {
          "name": "9.8 Упражнения 250",
          "content": "--- Страница 251 --- (продолжение)\n9.8 упражнения 1. Мы включили сложную конфигурацию лабиринта в исходный код экс- перимента в файле hard_maze.txt в файловом архиве книги. Вы можете попытаться пройти сложный лабиринт с помощью следующей команды: python maze_experiment_safe.py -g 120 -t 5 -m hard --width 200 -- height 200 . 2. Мы нашли успешное решение, используя 1571021768 в качестве началь- ного значения генератора случайных чисел. Попробуйте найти дру- гое случайное начальное значение, дающее успешное решение. Через сколько поколений удалось найти успешное решение в вашем случае? 9.9 заключение В этой главе мы обсудили коэволюцию двух популяций. Вы узнали, как может быть реализована комменсалистическая коэволюция, создающая популяцию успешных решателей задачи лабиринта. Мы познакомили вас с захватываю- щим подходом к разработке функции приспособленности агента-решателя, которая комбинирует оценку близости к цели и оценку новизны при помощи коэффициентов, возвращаемых популяцией кандидатов на целевую функцию. Кроме того, вы узнали о модифицированном методе поиска новизны и о том, как он отличается от оригинального метода, о котором мы говорили в главе 6. Используя знания, полученные в этой главе, вы сможете применять ком- менсалистический коэволюционный подход к своей работе или исследова- тельским задачам, которые не имеют четкого определения функции приспо- собленности. В следующей главе вы узнаете о методе глубокой нейроэволюции и о том, как использовать его для развития агентов, способных играть в классические игры Atari.250  Коэволюция и метод SAFE\n9.8 упражнения 1. Мы включили сложную конфигурацию лабиринта в исходный код экс- перимента в файле hard_maze.txt в файловом архиве книги. Вы можете попытаться пройти сложный лабиринт с помощью следующей команды: python maze_experiment_safe.py -g 120 -t 5 -m hard --width 200 -- height 200 . 2. Мы нашли успешное решение, используя 1571021768 в качестве началь- ного значения генератора случайных чисел. Попробуйте найти дру- гое случайное начальное значение, дающее успешное решение. Через сколько поколений удалось найти успешное решение в вашем случае? 9.9 заключение В этой главе мы обсудили коэволюцию двух популяций. Вы узнали, как может быть реализована комменсалистическая коэволюция, создающая популяцию успешных решателей задачи лабиринта. Мы познакомили вас с захватываю- щим подходом к разработке функции приспособленности агента-решателя, которая комбинирует оценку близости к цели и оценку новизны при помощи коэффициентов, возвращаемых популяцией кандидатов на целевую функцию. Кроме того, вы узнали о модифицированном методе поиска новизны и о том, как он отличается от оригинального метода, о котором мы говорили в главе 6. Используя знания, полученные в этой главе, вы сможете применять ком- менсалистический коэволюционный подход к своей работе или исследова- тельским задачам, которые не имеют четкого определения функции приспо- собленности. В следующей главе вы узнаете о методе глубокой нейроэволюции и о том, как использовать его для развития агентов, способных играть в классические игры Atari.250  Коэволюция и метод SAFE",
          "debug": {
            "start_page": 251,
            "end_page": 251
          }
        }
      ]
    },
    {
      "name": "Глава 10. Глубокая нейроэволюция 251",
      "chapters": [
        {
          "name": "10.1 Технические требования 251",
          "content": "--- Страница 252 --- (продолжение)\nГлава 10 Глубокая нейроэволюция В этой главе вы узнаете о методе глубокой нейроэволюции, который можно ис- пользовать для обучения глубоких нейронных сетей ( deep neural networks, DNN). Глубокие нейросети обычно обучаются с использованием методов обратного распространения, основанных на снижении градиента ошибки, который вычис - ляется относительно весов связей между нейронными узлами. Хотя градиентное обучение является мощным методом, который положил начало нынешней эпохе глубокого машинного обучения, у него есть свои недостатки, такие как длитель- ное время обучения и огромные требования к вычислительной мощности. В этой главе мы покажем, как методы глубокой нейроэволюции можно ис- пользовать для обучения с подкреплением и как они значительно превосхо- дят традиционные методы обучения нейросетей, основанные на градиентах. К концу этой главы у вас сформируется ясное понимание методов глубокой нейроэволюции, и вы получите практический опыт их применения. Вы узнае- те, как научить нейросеть играть в классические игры Atari, используя метод глубокой нейроэволюции. Также узнаете, как использовать визуальный конт- роль нейроэволюции ( visual inspector for neuroevolution, VINE) для проверки результатов экспериментов. В этой главе мы рассмотрим следующие темы: глубокая нейроэволюция для глубокого обучения с подкреплением; обучение агента игре Atari Frostbite с использованием глубокой нейро- эволюции; эксперимент с игрой Atari Frostbite; запуск эксперимента Atari Frostbite; проверка результатов при помощи VINE. 10.1 техниче Ские треб Ования Для проведения экспериментов, описанных в этой главе, ваш компьютер должен удовлетворять следующим техническим требованиям: современный ПК с графическим ускорителем Nvidia GeForce GTX 1080Ti или лучше; MS Windows 10, Ubuntu Linux 16.04 или macOS 10.14 с дискретным гра- фическим процессором; Anaconda Distribution версии 2019.03 или новее.\n10.1 техниче Ские треб Ования Для проведения экспериментов, описанных в этой главе, ваш компьютер должен удовлетворять следующим техническим требованиям: современный ПК с графическим ускорителем Nvidia GeForce GTX 1080Ti или лучше; MS Windows 10, Ubuntu Linux 16.04 или macOS 10.14 с дискретным гра- фическим процессором; Anaconda Distribution версии 2019.03 или новее.\n--- Страница 253 ---\nИсходный код примеров этой главы можно найти в каталоге Chapter10 в файловом архиве книги.",
          "debug": {
            "start_page": 252,
            "end_page": 253
          }
        },
        {
          "name": "10.2 Глубокая нейроэволюция для глубокого обучения с подкреплением 252",
          "content": "--- Страница 253 --- (продолжение)\n10.2 глубОкая нейр ОэвОлюция Для глуб ОкОгО Обучения С пОДкреплением В этой книге уже говорилось о том, как метод нейроэволюции можно применять для решения простых задач обучения с подкреплением, таких как балансировка одинарного и двойного обратного маятника на тележке в главе 4. Однако хотя эксперимент по балансировке маятника выглядит захватывающе, он слишком прост и работает с крошечными искусственными нейронными сетями. В этой главе мы обсудим, как применить нейроэволюцию к задачам обучения с подкреп- лением (reinforcement learning, RL), которые требуют огромных нейросетей для аппроксимации функции истинности1 (value function) алгоритма RL. Алгоритм RL учится методом проб и ошибок. Почти все варианты алго- ритмов RL пытаются оптимизировать функцию истинности, отображающую текущее состояние системы на соответствующее действие, которое будет вы- полнено в следующем шаге времени. Наиболее широко используемая клас - сическая версия алгоритма RL использует метод Q-обучения. В основе этого метода лежит матрица состояний ( Q-матрица), связанная с правилами по- ведения, которым должен следовать алгоритм после завершения обучения. Обучение состоит в обновлении ячеек Q-матрицы путем итеративного вы- полнения некоторых действий в определенных состояниях и последующего получения сигналов вознаграждения. Следующая формула описывает про- цесс обновления конкретной ячейки в Q-матрице: ()()() () ( ) 1 1new t t t t t taQ s,a Qs,a r maxQs,a. α αγ+ =− ++ Здесь rt – вознаграждение, получаемое при переходе системы от состояния st к состоянию st+1, at – действие, предпринимаемое во время t, ведущее к из- менению состояния, α – скорость обучения и γ – фактор дисконтирования, от которого зависит весомость будущих вознаграждений. Скорость обучения определяет, в какой степени новая информация переопределяет существую- щую информацию в конкретной ячейке Q-матрицы. Если мы установим ну- левую скорость обучения, то не получим новые знания, а если установим ее на 1, то не сохраним ранее полученные знания. Таким образом, скорость об- учения определяет, насколько быстро система может получать новые знания, сохраняя при этом полезные, уже проверенные данные. Простая версия алгоритма Q-обучения перебирает все возможные ком- бинации действий и состояний и обновляет ячейки Q-матрицы, как мы уже обсуждали. Этот подход довольно хорошо работает для простых задач с не- большим количеством пар действие–состояние, но быстро терпит неудачу с увеличением числа таких пар, то есть с увеличением размерности простран- 1 Иногда переводится как функция ценности или общее подкрепление (на всем сроке жизни агента). – Прим. перев. 252  Глубокая нейроэволюция\n10.2 глубОкая нейр ОэвОлюция Для глуб ОкОгО Обучения С пОДкреплением В этой книге уже говорилось о том, как метод нейроэволюции можно применять для решения простых задач обучения с подкреплением, таких как балансировка одинарного и двойного обратного маятника на тележке в главе 4. Однако хотя эксперимент по балансировке маятника выглядит захватывающе, он слишком прост и работает с крошечными искусственными нейронными сетями. В этой главе мы обсудим, как применить нейроэволюцию к задачам обучения с подкреп- лением (reinforcement learning, RL), которые требуют огромных нейросетей для аппроксимации функции истинности1 (value function) алгоритма RL. Алгоритм RL учится методом проб и ошибок. Почти все варианты алго- ритмов RL пытаются оптимизировать функцию истинности, отображающую текущее состояние системы на соответствующее действие, которое будет вы- полнено в следующем шаге времени. Наиболее широко используемая клас - сическая версия алгоритма RL использует метод Q-обучения. В основе этого метода лежит матрица состояний ( Q-матрица), связанная с правилами по- ведения, которым должен следовать алгоритм после завершения обучения. Обучение состоит в обновлении ячеек Q-матрицы путем итеративного вы- полнения некоторых действий в определенных состояниях и последующего получения сигналов вознаграждения. Следующая формула описывает про- цесс обновления конкретной ячейки в Q-матрице: ()()() () ( ) 1 1new t t t t t taQ s,a Qs,a r maxQs,a. α αγ+ =− ++ Здесь rt – вознаграждение, получаемое при переходе системы от состояния st к состоянию st+1, at – действие, предпринимаемое во время t, ведущее к из- менению состояния, α – скорость обучения и γ – фактор дисконтирования, от которого зависит весомость будущих вознаграждений. Скорость обучения определяет, в какой степени новая информация переопределяет существую- щую информацию в конкретной ячейке Q-матрицы. Если мы установим ну- левую скорость обучения, то не получим новые знания, а если установим ее на 1, то не сохраним ранее полученные знания. Таким образом, скорость об- учения определяет, насколько быстро система может получать новые знания, сохраняя при этом полезные, уже проверенные данные. Простая версия алгоритма Q-обучения перебирает все возможные ком- бинации действий и состояний и обновляет ячейки Q-матрицы, как мы уже обсуждали. Этот подход довольно хорошо работает для простых задач с не- большим количеством пар действие–состояние, но быстро терпит неудачу с увеличением числа таких пар, то есть с увеличением размерности простран- 1 Иногда переводится как функция ценности или общее подкрепление (на всем сроке жизни агента). – Прим. перев. 252  Глубокая нейроэволюция\n--- Страница 254 ---\nства действия–состояния. Большинство реальных задач имеют большую раз- мерность пространства действия–состояния, непосильную для классической версии Q-обучения. Для решения проблемы высокой размерности был предложен метод ап- проксимации Q-функцией. В этом методе правила поведения определяются не таблицей состояний, которую мы упоминали ранее, а аппроксимируют - ся функцией. Одним из способов достижения этой аппроксимации является использование нейросети в качестве универсального аппроксиматора. Бла- годаря использованию нейросетей, особенно глубоких, для аппроксимации Q-матрицы удается использовать алгоритмы RL для очень сложных задач, даже на непрерывном пространстве состояний. С этой целью был разработан метод глубоких Q-сетей ( deep Q-network, DQN), который использует глубо- кие нейросети для аппроксимации Q-значений. Алгоритм RL, основанный на аппроксимации функции истинности, получил название глубокого обучения c подкреплением (deep RL, глубокое RL). С глубоким RL можно извлечь правила поведения непосредственно из пикселей видеопотока. Это позволяет нам использовать видеопоток, на- пример, для обучения агентов видеоиграм. Тем не менее метод DQN мож - но считать разновидностью метода градиентного обучения. Он использует обратное распространение ошибки для обучения аппроксиматора функции Q-значений. Будучи мощным методом, он имеет высокую вычислительную сложность и нуждается в использовании графических процессоров для умно- жения матриц во время вычислений, связанных с градиентным спуском. Одним из методов, которые можно использовать для уменьшения вычисли- тельных затрат, являются генетические алгоритмы ( genetic algorithms, GA), такие как нейроэволюция. Нейроэволюция позволяет нам обучать нейросеть для ап- проксимации Q-матрицы без каких-либо градиентных вычислений. В недавних исследованиях было показано, что методы генетических алгоритмов без гради- ента показывают отличную производительность, когда речь идет о сложных за- дачах с глубоким RL, и что они могут даже превзойти традиционные аналоги. В следующем разделе вы узнаете, как метод глубокой нейроэволюции можно использовать для обучения успешных агентов прохождению одной из классиче- ских игр Atari, просто считывая пиксельное изображение игрового поля.",
          "debug": {
            "start_page": 253,
            "end_page": 254
          }
        },
        {
          "name": "10.3 Обучение агента игре Atari Frostbite с использованием глубокой нейроэволюции 253",
          "content": "--- Страница 254 --- (продолжение)\n10.3 О бучение агента игре ATAri FroSTbiTE С иСпОльзОванием глуб ОкОй нейр ОэвОлюции Недавно классические игры Atari были инкапсулированы в так называемую обуча ющую среду Atari ( Atari learning environment, ALE), которая служит эта- лоном для тестирования различных реализаций алгоритмов RL. Алгоритмы, которые подвергаются проверке на ALE, должны уметь считывать состояние игры в виде пикселей игрового экрана и развивать сложную логику управле- ния, позволяющую агенту выигрывать игру. Таким образом, задача алгорит - ма состоит в том, чтобы развить понимание игровой ситуации с точки зрения игрового персонажа и его противников. Кроме того, алгоритм должен правиль- но понимать сигнал вознаграждения, поступающий с игрового экрана в виде окончательного счета в конце одиночного прогона игры. 10.3 Обучение агента игре Atari Frostbite с использованием глубокой  253\n10.3 О бучение агента игре ATAri FroSTbiTE С иСпОльзОванием глуб ОкОй нейр ОэвОлюции Недавно классические игры Atari были инкапсулированы в так называемую обуча ющую среду Atari ( Atari learning environment, ALE), которая служит эта- лоном для тестирования различных реализаций алгоритмов RL. Алгоритмы, которые подвергаются проверке на ALE, должны уметь считывать состояние игры в виде пикселей игрового экрана и развивать сложную логику управле- ния, позволяющую агенту выигрывать игру. Таким образом, задача алгорит - ма состоит в том, чтобы развить понимание игровой ситуации с точки зрения игрового персонажа и его противников. Кроме того, алгоритм должен правиль- но понимать сигнал вознаграждения, поступающий с игрового экрана в виде окончательного счета в конце одиночного прогона игры. 10.3 Обучение агента игре Atari Frostbite с использованием глубокой  253\n--- Страница 255 ---\n10.3.1 Игра Atari Frostbite Frostbite1 – это классическая игра Atari, в которой вы управляете игровым пер- сонажем, возводящим и́глу – домик из ледяных блоков. Экран игры показан на рис. 10.1. Рис. 10.1. Экран игры Atari Frostbite Нижняя часть экрана – вода с плавающими в ней ледяными блоками, рас- положенными в четыре ряда. Персонаж прыгает из одного ряда в другой, пы- таясь избежать различных противников. Если игровой персонаж попадает на белый ледяной блок, этот блок достается персонажу и используется для стро- ительства и́глу на берегу в правом верхнем углу экрана. После этого белый ледяной блок меняет свой цвет и больше не может использоваться. Чтобы построить иглу, персонаж должен собрать 15 ледяных блоков в тече- ние 45 секунд. В противном случае игра заканчивается, потому что персонаж погибает от переохлаждения. Когда иглу построено, персонаж должен ока- заться внутри него, чтобы завершить текущий уровень. Чем быстрее персо- наж завершает уровень, тем больше бонусных очков начисляется игроку. Далее мы обсудим, как состояние экрана игры отображается на входные данные, задействованные в нейроэволюции. 10.3.2 Отображение игрового экрана на действия Чтобы научиться играть в игры Atari, глубокая нейросеть должна иметь воз- можность напрямую отображать пиксели на экране в систему управления игрой. Это означает, что наш алгоритм должен прочитать игровой экран и ре- 1 Обморожение, гибель от холода. – Прим. перев.254  Глубокая нейроэволюция\n--- Страница 256 ---\nшить, какое игровое действие предпринять в данный момент, чтобы получить максимально возможный игровой счет. Эта задача может быть разделена на две логические подзадачи: задача анализа изображения, которая кодирует состояние текущей игровой ситуации на экране, включая положение игрового персонажа, препятствия и противников; задача обучения с подкреплением, которая сводится к обучению нейро- сети, аппроксимирующей Q-матрицу для построения правильного со- ответствия между конкретным состоянием игры и действиями игрока. В задачах, связанных с анализом визуальных образов или других евклидо- вых данных большой размерности, обычно используются сверточные нейрон- ные сети (convolutional neural network, CNN). Мощь CNN основана на их способ- ности значительно сократить количество параметров обучения по сравнению с другими типами нейросетей в задачах зрительного распознавания. Иерархия CNN обычно имеет несколько последовательных сверточных слоев в сочета- нии с нелинейными полностью связанными слоями и заканчивается полно- стью связанным слоем, за которым следует слой потерь. Последние полностью связанные слои и слой потерь образуют архитектуру построения логическо- го вывода нейронной сети. В случае глубокого RL эти слои аппроксимируют Q-значения. Далее мы рассмотрим детали реализации сверточного слоя. Сверточные слои Изучая организацию зрительной коры высших форм жизни (в том числе лю- дей), исследователи нашли источник вдохновения для разработки CNN. Каж - дый нейрон зрительной коры головного мозга реагирует на сигналы, посту - пающие из ограниченной области поля зрения – рецептивного поля нейрона. Рецептивные поля различных нейронов частично перекрываются, что позво- ляет им покрывать все поле зрения, как показано на рис. 10.2. Рис. 10.2. Схема связей между рецептивным полем (слева) и нейронами в сверточном слое (справа) 10.3 Обучение агента игре Atari Frostbite с использованием глубокой  255\n--- Страница 257 ---\nСверточный слой состоит из столбца нейронов, где каждый нейрон в од- ном столбце связан с одним и тем же рецептивным полем. Этот столбец пред- ставляет собой набор фильтров1 (ядер, kernel). Каждый фильтр определяется размером рецептивного поля и количеством каналов. Количество каналов определяет глубину столбца нейронов, в то время как размер рецептивного поля определяет количество столбцов в сверточном слое. Когда рецептивное поле перемещается над полем зрения, на каждом шаге активируется новый столбец нейронов. Как мы упоминали ранее, каждый сверточный слой обычно объединяется с полностью связанным слоем с нелинейной активацией, таким как выпрям- ленный линейный блок ( rectified linear unit, ReLU). Функция активации ReLU позволяет отфильтровывать отрицательные значения в соответствии со сле- дующей формулой: () ()0 fx x max,x.+== Здесь x – вход нейрона. В архитектуре нейросети несколько сверточных уровней соединены с несколькими полностью связанными уровнями, которые осуществляют построе ние логического вывода. Далее мы обсудим архитектуру CNN, кото- рая используется в нашем эксперименте. Архитектура CNN для обучения игрового агента Atari В нашем эксперименте мы будем использовать архитектуру CNN, состоя- щую из трех сверточных слоев с 32, 64 и 64 каналами, за которыми следует полностью связанный слой с 512 узлами и выходной слой с количеством узлов, соответствующих количеству игровых действий. Сверточные слои имеют размеры ядра 8×8, 4×4 и 3×3 и перемещаются с шагом 4, 2 и 1 соот - ветственно. За всеми сверточными и полностью связными слоями следует нелинейный блок ReLU. Исходный код для создания описанной модели сетевого графа с использо- ванием инфраструктуры TensorFlow выглядит следующим образом: class LargeModel(Model): def _make_net(self, x, num_actions): x = self.nonlin(self.conv(x, name='conv1', num_outputs=32, kernel_size=8, stride=4, std=1.0)) x = self.nonlin(self.conv(x, name='conv2', num_outputs=64, kernel_size=4, stride=2, std=1.0)) x = self.nonlin(self.conv(x, name='conv3', num_outputs=64, kernel_size=3, stride=1, std=1.0)) x = self.flattenallbut0(x) x = self.nonlin(self.dense(x, 512, 'fc')) return self.dense(x, num_actions, 'out', std=0.1) 1 Иногда эти фильтры называют ядрами или кернелами, от англ. kernel. – Прим. перев.256  Глубокая нейроэволюция\n--- Страница 258 ---\nВ результате построения этой архитектуры CNN содержит около 4 млн обуча емых параметров. Далее мы обсудим, как происходит процесс глубоко- го обучения с подкреплением в нашем эксперименте. Полный исходный код представлен в файле dqn.py в файловом архиве книги. 10.3.3 Обучение игрового агента В нашем эксперименте для обучения с подкреплением использован метод нейроэволюции. Этот метод основан на простом генетическом алгоритме, ко- торый развивает популяцию особей. Генотип каждой особи кодирует вектор обучаемых параметров нейросети игрового агента. Под обучаемыми парамет- рами мы подразумеваем веса связей между узлами сети. В каждом поколении каждый генотип оценивается в тестовой среде на игре Frostbite и возвращает определенный показатель приспособленности. Мы оцениваем каждого агента (геном) на 20 000 фреймов игры. В течение периода оценки игровой персонаж может играть несколько раз, и итоговая оценка игры Atari – это оценка при- способленности, которая служит сигналом вознаграждения с точки зрения RL. Далее мы обсудим схему кодирования генома, которая позволяет нам за- кодировать более 4 млн обучаемых параметров нейросети игрового агента. Схема кодирования генома Глубокая нейросеть, которую мы используем в качестве контроллера игрового агента, имеет около 4 млн обучаемых параметров. Каждый обучаемый пара- метр – это вес связи между двумя узлами нейронной сети. Традиционно обуче- ние нейронных сетей заключается в поиске подходящих значений всех весов связей, что позволяет нейронной сети аппроксимировать функцию, которая описывает специфику моделируемого процесса. Традиционный способ оценки этих обучаемых параметров состоит в ис - пользовании некоторой формы обратного распространения ошибки на осно- ве градиентного спуска, которая является вычислительно затратной. С другой стороны, алгоритм нейроэволюции позволяет нам обучать нейросеть, ис- пользуя заимствованный у природы генетический алгоритм. Алгоритм ней- роэволюции ищет правильную конфигурацию нейросети, применяя к обуча- емым параметрам ряд мутаций и рекомбинаций. Однако для использования генетического алгоритма мы должны разработать соответствующую схему кодирования фенотипа нейросети. После этого популяция особей (геномы, кодирующие фенотип нейросети) может создаваться и развиваться с исполь- зованием простого генетического алгоритма, который мы обсудим позже. Как мы упоминали ранее, схема кодирования должна создавать компакт - ные геномы, способные кодировать значения более 4 млн весов связей между узлами глубокой нейросети, управляющей игровым агентом. Мы нуждаемся в компактных геномах, чтобы уменьшить вычислительные затраты, связан- ные с оценкой генетического алгоритма. Далее обсудим схему кодирования генома, которая может быть использована для построения нейросети с боль- шим фенотипом. 10.3 Обучение агента игре Atari Frostbite с использованием глубокой  257\n--- Страница 259 ---\nСхема кодирования генома Исследователи из лаборатории Uber AI предложили схему кодирования, кото- рая использует для кодирования фенотипа нейросети начальное число гене- ратора псевдослучайных чисел. В этой схеме геном представлен в виде списка начальных значений, который применяется последовательно для генерации значений всех весов связей (обучаемых параметров), экспрессированных меж - ду узлами нейросети. Другими словами, первое начальное значение в списке представляет начальное значение инициализации системы правил, которое совмест - но используется генеалогией потомков одного родителя. Все последующие начальные значения представляют специфические мутации, которые при- обретаются потомством в процессе эволюции. Каждое начальное случайное значение применяют последовательно для получения вектора параметров нейросети определенного фенотипа. Следующая формула описывает полу - чение вектора параметров фенотипа для конкретной особи (n ): ()1 0 1n n i i. θθσετ− ==+∑ Здесь τ – кодировка ()1 0 1n n i i. θθσετ− ==+∑ и состоит из списка начальных значений мутации; представляет собой детерминированный генератор гауссовых псевдослучайных чисел с начальным числом τi, которое создает вектор дли- ной | ()1 0 1n n i i. θθσετ− ==+∑| ()1 0 1n n i i. θθσετ− ==+∑; – вектор начальных параметров, который создается во время инициализации следующим образом: , где – детерминирован- ная функция инициализации; σ – степень мутации, которая определяет силу влияния всех последующих векторов параметров на вектор начальных параметров ()1 0 1n n i i. θθσετ− ==+∑. В текущей реализации – это предварительно вычисленная табли- ца с 250 млн случайных векторов, проиндексированных с использованием 28-разрядных начальных чисел. Это сделано для ускорения обработки во время выполнения, поскольку поиск по индексу выполняется быстрее, чем генерация новых случайных чисел. Далее мы обсудим, как реализовать схему кодирования в исходном коде Python. Реализация схемы кодирования генома Следующий исходный код реализует получение параметров нейросети, как определено формулой из предыдущего раздела (см. функцию compute_weights_ from_seeds ): idx = seeds[0] theta = noise.get(idx, self.num_params).copy() * self.scale_by for mutation in seeds[1:]: idx, power = mutation theta = self.compute_mutation(noise, theta, idx, power) return theta Функция compute_mutation выполняет один шаг вычисления мутировавших параметров нейросети следующим образом:258  Глубокая нейроэволюция\n--- Страница 260 ---\ndef compute_mutation(self, noise, parent_theta, idx, mutation_power): return parent_theta + mutation_power * noise.get(idx, self.num_params) Этот код берет вектор обучаемых параметров родителя и добавляет к нему случайный вектор, который создается детерминированным псевдослучай- ным генератором с использованием определенного начального индекса. Па- раметр степени мутации масштабирует сгенерированный случайный вектор перед его добавлением к вектору параметров родителя. Для получения дополнительной информации о реализации обрати- тесь к файлу base.py в файловом архиве книги. Далее мы обсудим особенности простого генетического алгоритма, который используется для обучения игрового агента навыкам игры в Atari Frostbite. Простой генетический алгоритм Простой генетический алгоритм, который используется в нашем эксперимен- те, развивает популяцию N особей в течение нескольких поколений эволюции. Как мы упоминали ранее, каждый отдельный геном кодирует вектор обуча- емых параметров нейросети. Кроме того, в каждом поколении мы выбираем T лучших особей, которые станут родителями следующего поколения. Процесс воспроизводства следующего поколения реализуется следующим образом. Для N – 1 повторов мы делаем вот что. 1. Родитель выбирается равномерным случайным образом и удаляется из списка выбора. 2. К выбранному родителю применяется мутация путем прибавления ад- дитивного гауссова шума к вектору параметров, который закодирован в особи. 3. Затем мы добавляем новый организм в список особей для следующего поколения. После этого лучшая особь из текущего поколения копируется в неизменен- ном состоянии в следующее поколение (элитарность). Чтобы гарантировать, что была выбрана лучшая особь, мы оцениваем каждого из 10 лучших игро- ков в текущем поколении на 30 дополнительных сеансах игры. Особь с са- мым высоким средним показателем приспособленности затем выбирается в качест ве элиты для копирования в следующее поколение. Мутация родительской особи реализована следующим образом: def mutate(self, parent, rs, noise, mutation_power): parent_theta, parent_seeds = parent idx = noise.sample_index(rs, self.num_params) seeds = parent_seeds + ((idx, mutation_power), ) theta = self.compute_mutation(noise, parent_theta, idx, mutation_power) return theta, seeds Эта функция получает фенотип и генотип родительской особи, источник случайных чисел, а также таблицу предварительно подготовленных шумов 10.3 Обучение агента игре Atari Frostbite с использованием глубокой  259\n--- Страница 261 ---\n(250 млн векторов) и значение степени мутации. Источник случайных чи- сел выдает случайное начальное число (idx), которое используется в качестве индекса, чтобы мы могли выбрать соответствующий вектор параметров из таблицы шумов. После этого создаем геном потомства, комбинируя список родительских начальных случайных чисел с новым начальным случайным числом. Наконец, создаем фенотип потомства, комбинируя фенотип роди- теля с гауссовым шумом, который был извлечен из общей таблицы шума, используя случайный начальный индекс, который мы получили ранее (idx). В следующем разделе рассмотрим эксперимент по обучению агента навыкам игры в Frostbite.",
          "debug": {
            "start_page": 254,
            "end_page": 261
          }
        },
        {
          "name": "10.4 Обучение агента навыкам игры в Frostbite 260",
          "content": "--- Страница 261 --- (продолжение)\n10.4 О бучение агента навыкам игры в FroSTbiTE Теперь, когда мы обсудили теорию реализации игрового агента, мы готовы приступить к практике. Наша реализация основана на исходном коде, предо- ставленном Uber AI Lab на GitHub по адресу https://github.com/uber-research/ deep-neuroevolution. Исходный код в этом репозитории содержит реализа- цию двух методов обучения глубокой нейросети: методы на основе ЦП для многоядерных систем (до 720 ядер) и методы на основе графического процес - сора. Мы заинтересованы в реализации на основе графического процессора, потому что большинство пользователей не имеют доступа к таким продвину - тым технологиям, как компьютер с 720 процессорными ядрами. В то же время не составит особого труда обзавестись графическим процессором Nvidia. Далее мы обсудим детали программной реализации. 10.4.1 Учебная среда Atari Во время обучения агентов нам нужно смоделировать реальный игровой про- цесс в системе Atari. Это можно сделать с помощью среды эмуляции игр ALE, которая имитирует систему Atari, запускающую образы игр из ПЗУ. ALE предо- ставляет интерфейс, позволяющий нам захватывать кадры игрового экрана и управлять игрой, эмулируя игровой контроллер. Здесь мы будем использо- вать модификацию ALE, которая доступна по адресу https://github.com/yari- com/atari-py. Наша реализация использует инфраструктуру TensorFlow для реализации мо- делей искусственных нейронных сетей и выполнения их на графическом про- цессоре. Следовательно, мы должны выстроить мост между ALE и TensorFlow. Это делается путем добавления пользовательской операции TensorFlow с ис - пользованием языка программирования C++ для повышения эффективности. Соответствующий интерфейс Python также доступен в виде класса Python At- ariEnv , который можно найти в файле tf_atari.py в файловом архиве книги. Класс AtariEnv включает функции, позволяющие выполнить один шаг игры, сбросить настройки игры и получить текущее состояние игры (наблюдение). Далее мы обсудим каждую функцию. Функция шага игры Функция шага игры выполняет один шаг игры, используя переданные ей дей- ствия:260  Глубокая нейроэволюция\n10.4 О бучение агента навыкам игры в FroSTbiTE Теперь, когда мы обсудили теорию реализации игрового агента, мы готовы приступить к практике. Наша реализация основана на исходном коде, предо- ставленном Uber AI Lab на GitHub по адресу https://github.com/uber-research/ deep-neuroevolution. Исходный код в этом репозитории содержит реализа- цию двух методов обучения глубокой нейросети: методы на основе ЦП для многоядерных систем (до 720 ядер) и методы на основе графического процес - сора. Мы заинтересованы в реализации на основе графического процессора, потому что большинство пользователей не имеют доступа к таким продвину - тым технологиям, как компьютер с 720 процессорными ядрами. В то же время не составит особого труда обзавестись графическим процессором Nvidia. Далее мы обсудим детали программной реализации. 10.4.1 Учебная среда Atari Во время обучения агентов нам нужно смоделировать реальный игровой про- цесс в системе Atari. Это можно сделать с помощью среды эмуляции игр ALE, которая имитирует систему Atari, запускающую образы игр из ПЗУ. ALE предо- ставляет интерфейс, позволяющий нам захватывать кадры игрового экрана и управлять игрой, эмулируя игровой контроллер. Здесь мы будем использо- вать модификацию ALE, которая доступна по адресу https://github.com/yari- com/atari-py. Наша реализация использует инфраструктуру TensorFlow для реализации мо- делей искусственных нейронных сетей и выполнения их на графическом про- цессоре. Следовательно, мы должны выстроить мост между ALE и TensorFlow. Это делается путем добавления пользовательской операции TensorFlow с ис - пользованием языка программирования C++ для повышения эффективности. Соответствующий интерфейс Python также доступен в виде класса Python At- ariEnv , который можно найти в файле tf_atari.py в файловом архиве книги. Класс AtariEnv включает функции, позволяющие выполнить один шаг игры, сбросить настройки игры и получить текущее состояние игры (наблюдение). Далее мы обсудим каждую функцию. Функция шага игры Функция шага игры выполняет один шаг игры, используя переданные ей дей- ствия:260  Глубокая нейроэволюция\n--- Страница 262 ---\ndef step(self, action, indices=None, name=None): if indices is None: indices = np.arange(self.batch_size) with tf.variable_scope(name, default_name='AtariStep'): rew, done = gym_tensorflow_module.environment_step( self.instances, indices, action) return rew, done Эта функция применяет игровое действие, полученное от нейросети конт роллера, к текущей игровой среде. Обратите внимание, что эта функ - ция может выполнять один шаг игры одновременно в нескольких игровых экземплярах. Параметр self.batch_size или длина входного тензора indices определяет количество экземпляров игры, которыми мы располагаем. Функ - ция возвращает два тензора: один тензор с вознаграждениями (счет игры) и другой с флагами, указывающими, завершена ли текущая сессия игры после этого шага (пройдена или провалена). Оба тензора имеют длину, равную self. batch_size , или длину входного тензора indices. Далее мы обсудим, как выполняется наблюдение за игрой. Функция наблюдения за игрой Эта функция получает текущее состояние игры из среды Atari в качестве буфе- ра экрана и реализована следующим образом: def observation(self, indices=None, name=None): if indices is None: indices = np.arange(self.batch_size) with tf.variable_scope(name, default_name='AtariObservation'): with tf.device('/cpu:0'): obs = gym_tensorflow_module.environment_observation( self.instances, indices, T=tf.uint8) obs = tf.gather(tf.constant(self.color_pallete), tf.cast(obs,tf.int32)) obs = tf.reduce_max(obs, axis=1) obs = tf.image.resize_bilinear(obs, self.warp_size, align_corners=True) obs.set_shape((None,) + self.warp_size + (1,)) return obs Данная функция получает скриншот из среды Atari и оборачивает его в тен- зор, совместимый со средой TensorFlow. Функция наблюдения за игрой тоже позволяет нам получать состояние из нескольких игр, количество которых определяется либо параметром self.batch_size , либо длиной входного пара- метра indices. Функция возвращает скриншоты из нескольких игр, обернутые в тензор. Нам также необходимо иметь функцию для сброса среды Atari в случайное начальное состояние. Функция сброса среды Atari Чтобы обучить игровых агентов, нам нужно реализовать функцию, которая запус- кает среду Atari из определенного случайного состояния. Крайне важно реализо- 10.4 Обучение агента навыкам игры в Frostbite  261\n--- Страница 263 ---\nвать стохастическую функцию сброса среды, чтобы наш агент мог играть в игру из любого начального состояния. Функция реализована следующим образом: def reset(self, indices=None, max_frames=None, name=None): if indices is None: indices = np.arange(self.batch_size) with tf.variable_scope(name, default_name='AtariReset'): noops = tf.random_uniform(tf.shape(indices), minval=1, maxval=31, dtype=tf.int32) if max_frames is None: max_frames = tf.ones_like(indices, dtype=tf.int32) * \\ (100000 * self.frameskip) import collections if not isinstance(max_frames, collections.Sequence): max_frames = tf.ones_like(indices, dtype=tf.int32) * \\ max_frames return gym_tensorflow_module.environment_reset(self.instances, indices, noops=noops, max_frames=max_frames) Эта функция использует входной параметр indices для одновременного сброса нескольких экземпляров игр Atari в случайные начальные состояния. Функция также определяет максимальное количество фреймов для каждого экземпляра игры. Далее мы обсудим, как выполняется расчет RL на ядрах графического про- цессора. 10.4.2 Расчет RL на ядрах GPU В нашем эксперименте мы реализуем расчет RL с использованием инфраструк - туры TensorFlow на устройствах с графическим процессором. Это означает, что все вычисления, связанные с распространением входных сигналов через контроллер нейросети, выполняются на графическом процессоре. Такой прием позволяет нам эффективно рассчитывать более 4 млн параметров обучения – весов связей между управляющими узлами нейросети – для каждого шага игры. Кроме того, мы можем одновременно моделировать несколько сеансов игры, каждый из которых управляется отдельной нейросетью контроллера. Одновременный обсчет нескольких нейросетей игровых контроллеров реа лизуется двумя классами Python: RLEvalutionWorker и ConcurrentWorkers . Да- лее мы обсудим каждый класс. Полный исходный код представлен в файле concurrent_worker.py в файловом архиве книги. Класс RLEvalutionWorker Этот класс содержит конфигурацию и сетевой граф нейросети контроллера. Он предоставляет нам методы, позволяющие создавать сетевой граф нейросе- ти контроллера, запускать цикл расчетов для созданного сетевого графа и по- мещать новые задачи в цикл обсчета. Далее мы обсудим, как из сетевой модели получается сет евой граф.262  Глубокая нейроэволюция\n--- Страница 264 ---\nСоздание графа сети Сетевой граф TensorFlow создается функцией make_net, которая в качестве вход- ных параметров получает конструктор нейросети модели, идентификатор устройства GPU и размер пакета. Сетевой граф создается следующим образом. 1. Начнем с создания модели нейросети контроллера и среды выполнения игры: self.model = model_constructor() … with tf.variable_scope(None, default_name='model'): with tf.device(‘/cpu:0'): self.env = self.make_env_f(self.batch_size) 2. Далее мы создадим заполнители, чтобы могли получать значения во время вычисления сетевого графа. Также создадим оператор для сбро- са игры перед началом нового игрового эпизода: self.placeholder_indices = tf.placeholder(tf.int32, shape=(None, )) self.placeholder_max_frames = tf.placeholder( tf.int32, shape=(None, )) self.reset_op = self.env.reset( indices=self.placeholder_indices, max_frames=self.placeholder_max_frames) 3. После этого, используя контекст доступного устройства графического процессора, мы создадим двух операторов, которые будут получать наблюдения за состоянием игры и вычислять последующие действия игры: with tf.device(device): self.obs_op = self.env.observation( indices=self.placeholder_indices) obs = tf.expand_dims(self.obs_op, axis=1) self.action_op = self.model.make_net(obs, self.env.action_space, indices=self.placeholder_indices, batch_size=self.batch_size, ref_batch=ref_batch) 4. Оператор action возвращает массив значений вероятности действия, которые необходимо отфильтровать, если пространство действия дис- кретно: if self.env.discrete_action: self.action_op = tf.argmax( self.action_op[:tf.shape( self.placeholder_indices)[0]], axis=-1, output_type=tf.int32) Код проверяет, требует ли текущая игровая среда дискретных действий, и оборачивает оператор action, используя встроенный оператор tf.argmax платформы TensorFlow. Оператор tf.argmax возвращает индекс действия 10.4 Обучение агента навыкам игры в Frostbite  263\n--- Страница 265 ---\nс наибольшим значением, который может служить указанием на необходи- мость выполнения конкретного игрового действия. Игровая среда Atari представляет собой дискретную среду, что означа- ет, что на каждый временной шаг принимается только одно действие. 5. Наконец, мы создаем оператор для выполнения одного игрового шага: with tf.device(device): self.rew_op, self.done_op = \\ self.env.step(self.action_op, indices=self.placeholder_indices) Этот код создает оператор, который возвращает операции для получения вознаграждений self.rew_op и статус завершения игры self.done_op после вы- полнения одного шага игры. Далее мы обсудим, как реализован цикл расчетов. Цикл оценочного испытания графа Это цикл, который мы используем для оценочного испытания ранее созданно- го сетевого графа на нескольких играх параллельно – количество игр, которые можно оценить одновременно, определяется параметром batch_size . Цикл оценки определен в функции _loop и реализован следующим образом. 1. Мы начинаем с создания массивов для хранения значений оценки игры в нескольких эпизодах: running = np.zeros((self.batch_size,), dtype=np.bool) cumrews = np.zeros((self.batch_size, ), dtype=np.float32) cumlen = np.zeros((self.batch_size, ), dtype=np.int32) 2. Затем запускаем цикл и устанавливаем соответствующие индексы мас- сива running, который мы только что создали, равными True: while True: # Ничего не загружено if not any(running): idx = self.queue.get() if idx is None: break running[idx] = True while not self.queue.empty(): idx = self.queue.get() if idx is None: break running[idx] = True 3. Используя массив indices, мы готовы выполнить один оператор шага игры и собрать результаты: indices = np.nonzero(running)[0] rews, is_done, _ = self.sess.run( [self.rew_op, self.done_op, self.incr_counter], {self.placeholder_indices: indices})264  Глубокая нейроэволюция\n--- Страница 266 ---\ncumrews[running] += rews cumlen[running] += 1 4. Наконец, нам нужно проверить, не завершилась ли какая-либо из оце- ненных игр выигрышем или достижением максимального количества фреймов. Для всех выполненных задач мы выполняем ряд операций, а именно: if any(is_done): for idx in indices[is_done]: self.sample_callback[idx](self, idx, (self.model.seeds[idx],cumrews[idx], cumlen[idx])) cumrews[indices[is_done]] = 0. cumlen[indices[is_done]] = 0. running[indices[is_done]] = False Предыдущий код использует индексы всех выполненных задач и вызыва- ет соответствующие зарегистрированные обратные вызовы перед сбросом переменных коллектора по определенным индексам. Теперь мы готовы обсудить, как добавить и запустить новое задание с по- мощью воркера (worker). Система запуска асинхронных задач Эта функция регистрирует конкретную задачу для выполнения воркером в контексте графического процессора. В качестве входных данных она при- нимает идентификатор задачи, владельца объекта задачи и обратный вызов, который должен быть выполнен при завершении задачи. Эта функция опреде- лена под именем run_async и реализована следующим образом. 1. Сначала она извлекает соответствующие данные из объекта задачи и за- гружает их в текущий сеанс TensorFlow: theta, extras, max_frames=task self.model.load(self.sess, task_id, theta, extras) if max_frames is None: max_frames = self.env.env_default_timestep_cutoff Здесь theta представляет собой массив со всеми весами связей в нейросети контроллера, extras содержит список начальных случайных чисел соответ - ствующего генома, а max_frames – это предельное количество фреймов игры. 2. Затем мы запускаем сеанс TensorFlow с self.reset_op , который сбрасы- вает определенную игровую среду с указанным индексом: self.sess.run(self.reset_op, {self.placeholder_indices:[task_id], self.placeholder_max_frames:[max_frames]}) self.sample_callback[task_id] = callback self.queue.put(task_id) Код запускает self.reset_op в сеансе TensorFlow. Кроме того, мы регистри- руем текущий идентификатор задачи с оператором reset и предельным количеством фреймов игры для данной задачи. Идентификатор задачи ис- пользуется в цикле оценки, чтобы связать результаты оценки сетевого графа 10.4 Обучение агента навыкам игры в Frostbite  265\n--- Страница 267 ---\nс определенным геномом в популяции. Далее мы обсудим, как поддержива- ются параллельные асинхронные воркеры. Класс ConcurrentWorkers Класс ConcurrentWorkers содержит конфигурацию среды параллельного выпол- нения, которая включает в себя несколько оценивающих воркеров (экземпля- ры RLEvalutionWorker ) и вспомогательные подпрограммы для поддержки мно- жественного выполнения параллельных задач. Создание оценивающих воркеров Одной из основных обязанностей класса ConcurrentWorkers является создание и управление экземплярами RLEvalutionWorker . Это делается в конструкторе класса следующим образом: self.workers = [RLEvalutionWorker(make_env_f, *args, ref_batch=ref_batch, **dict(kwargs, device=gpus[i])) for i in range(len(gpus))]self.model = self.workers[0].model self.steps_counter = sum([w.steps_counter for w in self.workers]) self.async_hub = AsyncTaskHub()self.hub = WorkerHub(self.workers, self.async_hub.input_queue, self.async_hub) Здесь мы создаем определенное количество экземпляров RLEvalutionWorker , которые соотносятся с количеством графических процессоров, доступных в системе. Затем инициализируем выбранную графовую модель нейросети и создаем вспомогательные подпрограммы для управления параллельным выполнением асинхронных задач. Далее мы обсудим, как планируется вы- полнение рабочих заданий. Выполнение рабочих заданий и результаты мониторинга Чтобы использовать механизм оценки RL, который мы описали ранее, нам ну- жен метод планирования рабочих заданий для оценки и мониторинга резуль- татов. Он реализован в функции monitor_eval , которая получает список геномов в популяции и оценивает их успешность в игровой среде Atari. Эта функция состоит из двух важных частей. 1. Сначала мы перебираем все геномы в списке и создаем асинхронное рабочее задание, чтобы каждый геном получил свою оценку в игровой среде Atari: tasks = [] for t in it: tasks.append(self.eval_async(*t, max_frames=max_frames, error_callback=error_callback)) if time.time() - tstart > logging_interval: cur_timesteps = self.sess.run(self.steps_counter) tlogger.info('Num timesteps:', cur_timesteps, 'per second:', (cur_timesteps-last_timesteps)//(time.time()-tstart), 'num episodes finished: {}/{}'.format(266  Глубокая нейроэволюция\n--- Страница 268 ---\nsum([1 if t.ready() else 0 for t in tasks]), len(tasks))) tstart = time.time() last_timesteps = cur_timesteps Этот код планирует асинхронную оценку каждого генома из списка и со- храняет ссылку на каждое асинхронное задание для последующего исполь- зования. Также мы периодически выводим результаты процесса оценки уже запланированных заданий. Теперь давайте посмотрим, как отслеживать ре- зультаты оценки. 2. Следующий блок кода ожидает завершения асинхронных заданий: while not all([t.ready() for t in tasks]): if time.time() - tstart > logging_interval: cur_timesteps = self.sess.run(self.steps_counter) tlogger.info('Num timesteps:', cur_timesteps, 'per second:', (cur_timesteps-last_timesteps)//(time.time()-tstart), 'num episodes:', sum([1 if t.ready() else 0 for t in tasks])) tstart = time.time() last_timesteps = cur_timesteps time.sleep(0.1) Здесь перебираем все ссылки на запланированные асинхронные задания и ожидаем их завершения. Также мы периодически выводим результаты оце- нивания. 3. Наконец, после выполнения всех заданий мы собираем оценки: tlogger.info( 'Done evaluating {} episodes in {:.2f} seconds'.format( len(tasks), time.time()-tstart_all))return [t.get() for t in tasks] Код перебирает все ссылки на запланированные асинхронные задания и создает список результатов оценивания. Далее мы обсудим реализацию движка эксперимента. 10.4.3 Движок эксперимента Движок эксперимента считывает конфигурацию эксперимента, определенную в файле JSON, и запускает процесс нейроэволюции в течение указанного коли- чества игровых шагов. В нашем эксперименте оценивание генома прекраща- ется после достижения 1,5 млрд шагов по времени Frostbite. Далее мы обсудим детали конфигурации эксперимента. Файл конфигурации эксперимента Файл конфигурации для нашего эксперимента имеет следующее содержание: { \"game\": \"frostbite\", \"model\": \"LargeModel\", \"num_validation_episodes\": 30, \"num_test_episodes\": 200, \"population_size\": 1000, 10.4 Обучение агента навыкам игры в Frostbite  267\n--- Страница 269 ---\n\"episode_cutoff_mode\": 5000, \"timesteps\": 1.5e9, \"validation_threshold\": 10, \"mutation_power\": 0.002, \"selection_threshold\": 20 } Назначение параметров конфигурации: game – это название игры, под которым она зарегистирована в ALE. Пол- ный список поддерживаемых игр доступен в файле tf_atari.ру в фай- ловом архиве книги; model – название модели сетевого графа, которую следует использовать для построения нейросети контроллера. Модели определены в файле dqn.py в файловом архиве книги; num_validation_episodes – определяет, сколько игровых эпизодов исполь- зуется для оценки лучших особей в популяции. После этого шага мы можем выбрать истинную элиту популяции; num_test_episodes – устанавливает количество игровых эпизодов, кото- рые можно использовать для проверки производительности выбран- ной элиты популяции; population_size – определяет количество геномов в популяции; episode_cutoff_mode – определяет, по какому условию останавливается оценочная игра для определенного генома. Текущий эпизод игры мо- жет остановиться либо после выполнения определенного количества временных шагов, либо с помощью сигнала остановки по умолчанию соответствующей игровой среды; timesteps – устанавливает общее количество временных шагов игры, ко- торые должны быть выполнены в процессе нейроэволюции; validation_threshold – задает количество лучших особей, выбранных из каждого поколения для дополнительной проверки. Элита популяции выбирается из этих особей; mutation_power – определяет, в какой степени последующие мутации, применяемые к особи, влияют на обучаемые параметры (веса связей); selection_threshold – определяет, сколько родительских особей может производить потомство в следующем поколении. Теперь мы готовы обсудить подробности реализации движка эксперимента. Конфигурация эксперимента хранится в файле ga_atari_config.json в файловом архиве книги. Реализация движка эксперимента Движок эксперимента создает среду параллельной оценки геномов и запуска- ет эволюционный цикл для множества особей. Давайте обсудим основные де- тали реализации. 1. Мы начинаем с настройки среды оценки, загружая модель нейросети контроллера и создавая параллельные воркеры:268  Глубокая нейроэволюция\n--- Страница 270 ---\nModel = neuroevolution.models.__dict__[config['model']] all_tstart = time.time() def make_env(b): return gym_tensorflow.make(game=config[\"game\"], batch_size=b) worker = ConcurrentWorkers(make_env, Model, batch_size=64) 2. Затем создаем таблицу со случайными шумоподобными значениями, которая будет использоваться в качестве случайных начальных чисел, и определяем функцию для создания потомства в следующем поколении: noise = SharedNoiseTable() rs = np.random.RandomState() def make_offspring(): if len(cached_parents) == 0: return worker.model.randomize(rs, noise) else: assert len(cached_parents) == config['selection_threshold'] parent = cached_parents[rs.randint(len(cached_parents))] theta, seeds = worker.model.mutate( parent, rs, noise, mutation_power=state.sample( state.mutation_power)) return theta, seeds 3. После этого начинается основной цикл эволюции. Мы используем ранее определенную функцию, чтобы создать популяцию потомства для теку - щего поколения: tasks = [make_offspring() for _ in range( config['population_size'])] for seeds, episode_reward, episode_length in \\ worker.monitor_eval(tasks, max_frames=state.tslimit * 4): results.append(Offspring(seeds, [episode_reward], [episode_length])) state.num_frames += sess.run(worker.steps_counter) - \\ frames_computed_so_far Здесь мы создаем рабочие задания для каждого потомства в популяции и ставим каждое задание в очередь на оценку в игровой среде. 4. Завершив оценку каждой особи в популяции, мы начинаем оценивать лучших особей, чтобы выбрать элиту: state.population = sorted(results, key=lambda x:x.fitness, reverse=True) …validation_population = state.\\ population[:config['validation_threshold']] if state.elite is not None: validation_population = [state.elite] + \\ validation_population[:-1] validation_tasks = [ 10.4 Обучение агента навыкам игры в Frostbite  269\n--- Страница 271 ---\n(worker.model.compute_weights_from_seeds(noise, validation_population[x].seeds, cache=cached_parents), validation_population[x].seeds) for x in range( config['validation_threshold'])]_,population_validation, population_validation_len =\\ zip(*worker.monitor_eval_repeated(validation_tasks, max_frames=state.tslimit * 4, num_episodes=config['num_validation_episodes'])) 5. Используя результаты оценки 10 лучших особей, мы выбираем элиту популяции и проводим финальные тесты, чтобы оценить ее эффектив- ность: population_elite_idx = np.argmax(population_validation) state.elite = validation_population[population_elite_idx] elite_theta = worker.model.compute_weights_from_seeds( noise, state.elite.seeds, cache=cached_parents) _,population_elite_evals,population_elite_evals_timesteps=\\ worker.monitor_eval_repeated( [(elite_theta, state.elite.seeds)], max_frames=None, num_episodes=config[‘num_test_episodes’])[0] Элитные особи будут скопированы в следующее поколение, как есть. 6. Наконец, мы выбираем лучшие особи из текущей популяции, которые станут родителями следующего поколения: if config['selection_threshold'] > 0: tlogger.info(\"Caching parents\") new_parents = [] if state.elite in \\ state.population[:config['selection_threshold']]: new_parents.extend([ (worker.model.compute_weights_from_seeds( noise, o.seeds, cache=cached_parents), o.seeds) for o in state.population[:config['selection_threshold']]]) else: new_parents.append( (worker.model.compute_weights_from_seeds( noise, state.elite.seeds, cache=cached_parents), state.elite.seeds)) new_parents.extend([ (worker.model.compute_weights_from_seeds( noise, o.seeds, cache=cached_parents), o.seeds) for o in state.population[:config[‘selection_threshold']-1]]) Предыдущий код собирает лучшие особи популяции, которые достойны стать родителями следующего поколения. Кроме того, он добавляет текущую элиту в список родителей, если ее еще нет. Теперь мы готовы обсудить, как запустить эксперимент.270  Глубокая нейроэволюция",
          "debug": {
            "start_page": 261,
            "end_page": 271
          }
        },
        {
          "name": "10.5 Запуск эксперимента с игрой Atari Frostbite 271",
          "content": "--- Страница 272 --- (продолжение)\n10.5 запуСк экСперимента С игрОй ATAri FroSTbiTE Итак, мы обсудили все нюансы исходного кода, и пришло время запустить экс- перимент. Тем не менее первое, что нам нужно сделать, – это создать рабочую среду, о которой мы поговорим позже. 10.5.1 Настройка рабочей среды Обучение агента навыкам прохождения игр Atari подразумевает, что в про- цессе эксперимента необходимо обучить большую нейросеть контроллера. Мы уже говорили, что нейросеть имеет более 4 млн обучаемых параметров и требует много вычислительных ресурсов для оценки. К счастью, совре- менные графические ускорители позволяют выполнять тяжелые параллель- ные вычисления. Эта возможность пригодится для нашего эксперимента, потому что в процессе эволюции нам нужно неоднократно оценивать про- хождение игры каждой особью. Без графического ускорителя эти расчеты заняли бы много времени или потребовали огромного количества процес - сорных ядер (около 720). Итак, давайте приступим к пошаговой подготовке рабочей среды. 1. Для работы требуется наличие в системе видеоускорителя Nvidia (напри- мер, GeForce 1080Ti); также нужно установить соответствующую версию Nvidia CUDA SDK. Более подробную информацию о CUDA SDK и его уста- новке можно найти по адресу https://developer.nvidia.com/cuda-toolkit. 2. Далее необходимо установить инструмент сборки CMake, как описано на https://cmake.org. 3. Теперь при помощи Anaconda нужно создать новую среду Python и установить все зависимости, которые используются в реализации эксперимента: $ conda create -n deep_ne python=3.5 $ conda activate deep_ne $ conda install -c anaconda tensorflow-gpu $ pip install gym $ pip install Pillow Эти команды создают и активируют новую среду Python 3.5, а затем уста- навливают TensorFlow, OpenAI Gym и библиотеку изображений Python в ка- честве зависимостей. 4. После этого вам необходимо клонировать репозиторий с исходным ко- дом эксперимента: $ git clone https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Pyt hon.git $ cd Hands-on-Neuroevolution-with-Python/Chapter10 После выполнения этих команд в вашем текущем рабочем каталоге по- явится исходный код эксперимента. 5. Теперь вам нужно построить среду ALE и интегрировать ее в свой экс- перимент. Клонируйте репозиторий ALE в соответствующий каталог и соберите среду с помощью следующих команд: 10.5 Запуск эксперимента с игрой Atari Frostbite  271\n10.5 запуСк экСперимента С игрОй ATAri FroSTbiTE Итак, мы обсудили все нюансы исходного кода, и пришло время запустить экс- перимент. Тем не менее первое, что нам нужно сделать, – это создать рабочую среду, о которой мы поговорим позже. 10.5.1 Настройка рабочей среды Обучение агента навыкам прохождения игр Atari подразумевает, что в про- цессе эксперимента необходимо обучить большую нейросеть контроллера. Мы уже говорили, что нейросеть имеет более 4 млн обучаемых параметров и требует много вычислительных ресурсов для оценки. К счастью, совре- менные графические ускорители позволяют выполнять тяжелые параллель- ные вычисления. Эта возможность пригодится для нашего эксперимента, потому что в процессе эволюции нам нужно неоднократно оценивать про- хождение игры каждой особью. Без графического ускорителя эти расчеты заняли бы много времени или потребовали огромного количества процес - сорных ядер (около 720). Итак, давайте приступим к пошаговой подготовке рабочей среды. 1. Для работы требуется наличие в системе видеоускорителя Nvidia (напри- мер, GeForce 1080Ti); также нужно установить соответствующую версию Nvidia CUDA SDK. Более подробную информацию о CUDA SDK и его уста- новке можно найти по адресу https://developer.nvidia.com/cuda-toolkit. 2. Далее необходимо установить инструмент сборки CMake, как описано на https://cmake.org. 3. Теперь при помощи Anaconda нужно создать новую среду Python и установить все зависимости, которые используются в реализации эксперимента: $ conda create -n deep_ne python=3.5 $ conda activate deep_ne $ conda install -c anaconda tensorflow-gpu $ pip install gym $ pip install Pillow Эти команды создают и активируют новую среду Python 3.5, а затем уста- навливают TensorFlow, OpenAI Gym и библиотеку изображений Python в ка- честве зависимостей. 4. После этого вам необходимо клонировать репозиторий с исходным ко- дом эксперимента: $ git clone https://github.com/PacktPublishing/Hands-on-Neuroevolution-with-Pyt hon.git $ cd Hands-on-Neuroevolution-with-Python/Chapter10 После выполнения этих команд в вашем текущем рабочем каталоге по- явится исходный код эксперимента. 5. Теперь вам нужно построить среду ALE и интегрировать ее в свой экс- перимент. Клонируйте репозиторий ALE в соответствующий каталог и соберите среду с помощью следующих команд: 10.5 Запуск эксперимента с игрой Atari Frostbite  271\n--- Страница 273 ---\n$ cd cd gym_tensorflow/atari/ $ git clone https://github.com/yaricom/atari-py.git $ cd ./atari-py && make Теперь у вас есть рабочая среда ALE, интегрированная с TensorFlow. Мы мо- жем использовать ее для оценки нейросетей контроллера, которые создаются из популяции геномов, претендующих на победу в игре Atari (в нашем экс- перименте это игра Frostbite). 6. После завершения сборки ALE вам нужно организовать связь между OpenAI Gym и TensorFlow, которая является специфической для реали- зации данного эксперимента: $ cd / gym_tensorflow && make Теперь у вас есть полностью настроенная рабочая среда, и вы готовы при- ступить к экспериментам. Далее мы обсудим, как запустить эксперимент. 10.5.2 запуСк экСперимента Итак, мы настроили рабочую среду и готовы начать эксперимент. Для запуска эксперимента достаточно войти в каталог Chapter10 и выполнить следующую команду: $ python ga.py -c configurations/ga_atari_config.json -o out Эта команда запускает эксперимент с использованием файла конфигура- ции, указанного в качестве первого параметра. Результаты эксперимента бу- дут сохранены в каталоге out. После завершения эксперимента консольный вывод должен выглядеть примерно так: | PopulationEpRewMax | 3.47e+03 | | PopulationEpRewMean | 839 || PopulationEpCount | 1e+03 || PopulationTimesteps | 9.29e+05 | | NumSelectedIndividuals | 20 | | TruncatedPopulationRewMean | 3.24e+03 || TruncatedPopulationValidationRewMean | 2.36e+03 || TruncatedPopulationEliteValidationRew | 3.1e+03 || TruncatedPopulationEliteIndex | 0 | | TruncatedPopulationEliteTestRewMean | 3.06e+03 | Current elite: (47236580, (101514609, 0.002), (147577692, 0.002),(67106649, 0.002), (202520553, 0.002), (230555280, 0.002), (38614601,0.002), (133511446, 0.002), (27624159, 0.002), (233455358, 0.002),(73372122, 0.002), (32459655, 0.002), (181449271, 0.002), (205743718, 0.002), (114244841, 0.002), (129962094, 0.002), (24016384, 0.002), (77767788, 0.002), (90094370, 0.002), (14090622, 0.002), (171607709, 0.002), (147408008, 0.002), (150151615, 0.002), (224734414, 0.002), (138721819, 0.002), (154735910, 0.002), (172264633, 0.002))272  Глубокая нейроэволюция\n--- Страница 274 ---\nВ выводе представлен набор статистических данных после определенного поколения эволюции. Вы можете увидеть следующие результаты: максимальный балл вознаграждения, который достигнут во время оценки популяции, составляет 3470 (PopulationEpRewMax ); максимальный балл, полученный лучшими особями в дополнительных 30 эпизодах проверки, составляет 3240 (TruncatedPopulationRewMean ); средний балл оценки лучших особей составляет 2360 (TruncatedPopula- tionValidationRewMean ); средний балл элитных особей, полученный во время дополнительных 200 прогонов теста, составляет 3060 (TruncatedPopulationEliteTestRewMean ). Достигнутые оценки вознаграждений довольно высоки по сравнению с другими методами обучения, если сравнить их с результатами, которые были опубликованы на https://arxiv.org/abs/1712.06567v3. Кроме того, в конце выходных данных вы можете увидеть геномное пред- ставление элиты популяции. Мы можем воспользоваться элитным геномом для визуализации прохождения игры Frostbite нейросетью, созданной по этому геному. Далее мы обсудим, как выполнить такую визуализацию. 10.5.3 визуализация прОхО жДения игры FroSTbiTE Теперь, когда у нас есть обученный игровой агент, было бы интересно посмот- реть, как найденное решение играет в игру Frostbite в среде Atari. Чтобы за- пустить симуляцию, вам нужно скопировать текущее представление элитного генома из выходных данных и вставить его в поле seeds файла display.py . После этого можно запустить симуляцию с помощью следующей команды: $ python display.py Эта команда использует предоставленный элитный геном для создания нейросети, управляющей действиями игрового агента Frostbite. Откроется окно игры, где вы сможете воочию наблюдать, как работает нейросеть кон- троллера. Игра будет продолжаться до тех пор, пока у игрового персонажа не закончатся «жизни». На рис. 10.3 показано несколько скриншотов игровых экранов во время выполнения display.py в среде Ubuntu 16.04. Рис. 10.3. Скриншоты игры Frostbite, полученные во время игрового сеанса с элитным геномом 10.5.3 Визуализация прохождения игры Frostbite  273\n--- Страница 275 ---\nУдивительно наблюдать, насколько плавный игровой процесс демонстри- рует нейросеть, обученная исключительно на основе наблюдений за игровым экраном. Далее мы обсудим дополнительный метод визуализации, который позво- ляет нам анализировать результаты.",
          "debug": {
            "start_page": 272,
            "end_page": 275
          }
        },
        {
          "name": "10.6 Визуальный инспектор нейроэволюции 274",
          "content": "--- Страница 275 --- (продолжение)\n10.6 визуальный инСпект Ор нейр ОэвОлюции В процессе нейроэволюции мы развиваем популяцию особей. Каждая особь оценивается в тестовой среде (такой как игра Atari), и для каждой особи на каждом поколении эволюции записываются баллы вознаграждений. Чтобы ис- следовать общую динамику процесса нейроэволюции, нам нужен инструмент, способный визуализировать облако результатов, достигнутых каждой особью в каждом поколении эволюции. Кроме того, интересно наблюдать за измене- ниями в оценке приспособленности элитной особи, чтобы понять прогресс процесса эволюции. Для решения этих задач исследователи из Uber AI разработали инструмент VINE, который мы и обсудим далее. 10.6.1 Настройка рабочей среды Чтобы воспользоваться инструментом VINE, установите дополнительные биб- лиотеки в виртуальную среду Python с помощью следующих команд: $ pip install click $ conda install matplotlib $ pip install colour$ conda install pandas Эти команды устанавливают все необходимые зависимости в виртуальную среду Python, которую мы создали для нашего эксперимента. Далее мы обсу - дим, как использовать инструмент VINE для визуализации результатов. Не забудьте предварительно активировать соответствующую вирту- альную среду с помощью следующей команды: conda activ deep_ne . 10.6.2 Использование VINE для визуализации эксперимента После установки зависимостей в виртуальной среде Python мы готовы исполь- зовать инструмент VINE. Сначала вам нужно клонировать его из репозитория Git с помощью следующих команд: $ git clone https://github.com/uber-research/deep-neuroevolution.git $ cd visual_inspector Мы клонировали репозиторий deep-neuroevolution в текущий каталог и пе- решли в папку visual_inspector , где находится исходный код инструмента VINE. Давайте рассмотрим пример того, как можно использовать VINE для визуа лизации результатов эксперимента по нейроэволюции, для чего вос- пользуемся результатами эксперимента с человеческой походкой в симуля-274  Глубокая нейроэволюция\n10.6 визуальный инСпект Ор нейр ОэвОлюции В процессе нейроэволюции мы развиваем популяцию особей. Каждая особь оценивается в тестовой среде (такой как игра Atari), и для каждой особи на каждом поколении эволюции записываются баллы вознаграждений. Чтобы ис- следовать общую динамику процесса нейроэволюции, нам нужен инструмент, способный визуализировать облако результатов, достигнутых каждой особью в каждом поколении эволюции. Кроме того, интересно наблюдать за измене- ниями в оценке приспособленности элитной особи, чтобы понять прогресс процесса эволюции. Для решения этих задач исследователи из Uber AI разработали инструмент VINE, который мы и обсудим далее. 10.6.1 Настройка рабочей среды Чтобы воспользоваться инструментом VINE, установите дополнительные биб- лиотеки в виртуальную среду Python с помощью следующих команд: $ pip install click $ conda install matplotlib $ pip install colour$ conda install pandas Эти команды устанавливают все необходимые зависимости в виртуальную среду Python, которую мы создали для нашего эксперимента. Далее мы обсу - дим, как использовать инструмент VINE для визуализации результатов. Не забудьте предварительно активировать соответствующую вирту- альную среду с помощью следующей команды: conda activ deep_ne . 10.6.2 Использование VINE для визуализации эксперимента После установки зависимостей в виртуальной среде Python мы готовы исполь- зовать инструмент VINE. Сначала вам нужно клонировать его из репозитория Git с помощью следующих команд: $ git clone https://github.com/uber-research/deep-neuroevolution.git $ cd visual_inspector Мы клонировали репозиторий deep-neuroevolution в текущий каталог и пе- решли в папку visual_inspector , где находится исходный код инструмента VINE. Давайте рассмотрим пример того, как можно использовать VINE для визуа лизации результатов эксперимента по нейроэволюции, для чего вос- пользуемся результатами эксперимента с человеческой походкой в симуля-274  Глубокая нейроэволюция\n--- Страница 276 ---\nторе Mujoco, предоставленными Uber AI Lab. Более подробную информацию об эксперименте с симулятором Mujoco можно найти по адресу https://eng. uber.com/deep-neuroevolution/. Теперь мы можем запустить визуализацию результатов эксперимента с симулятором Mujoco, которые находятся в папке sample_data , с помощью следующей команды: $ python -m main_mujoco 90 99 sample_data/mujoco/final_xy_bc/ Эта команда использует те же данные, которые были предоставлены Uber AI Lab из их эксперимента по обучению человекоподобным перемещениям, и выводит на экран визуализацию (рис. 10.4). Рис. 10.4. Инструмент VINE для визуализации результатов обучения персонажа человеческой походке В левой части рис. 10.4 вы можете увидеть облако результатов для каждой особи в популяции, начиная с 90-го поколения и заканчивая 99-м поколени- ем. В правой части графика вы можете увидеть оценку приспособленности элиты популяции по поколениям. На графике справа видно, что эволюцион- ный процесс демонстрирует положительную динамику от поколения к поко- лению, по мере того как оценка элиты возрастает. Каждая точка на левом графике демонстрирует точки поведенческой ха- рактеристики для каждой особи в популяции. Поведенческая характеристи- ка для задачи обучения человеческой походке – это конечная позиция гума- ноидного персонажа в конце траектории. Чем дальше он ушел от исходных координат (0,0), тем выше оценка приспособленности особи. С развитием эволюции облако результатов удаляется от исходных координат. Это движе- ние облака результатов также является сигналом о положительной динами- ке обуче ния, потому что каждая особь может сохранять равновесие на ногах в течение более длительного периода. Для получения более подробной информации об эксперименте Mujoco Humanoid locomotion, пожалуйста, обратитесь к статье на https://eng.uber.com/deep-neuroevolution/. 10.6 Визуальный инспектор нейроэволюции  275",
          "debug": {
            "start_page": 275,
            "end_page": 276
          }
        },
        {
          "name": "10.7 Упражнения 276",
          "content": "10.7 упражнения 1. Попробуйте увеличить параметр pop_size в настройках эксперимента и посмотрите, что произойдет. 2. Попробуйте вывести результаты эксперимента, которые можно визуа- лизировать с помощью VINE. Для этого вы можете использовать вспо- могательные функции master_extract_parent_ga и master_extract_cloud_ga в скрипте ga.py.",
          "debug": {
            "start_page": 277,
            "end_page": 277
          }
        },
        {
          "name": "10.8 Заключение 276",
          "content": "--- Страница 277 --- (продолжение)\n10.7 упражнения 1. Попробуйте увеличить параметр pop_size в настройках эксперимента и посмотрите, что произойдет. 2. Попробуйте вывести результаты эксперимента, которые можно визуа- лизировать с помощью VINE. Для этого вы можете использовать вспо- могательные функции master_extract_parent_ga и master_extract_cloud_ga в скрипте ga.py. 10.8 заключение В этой главе мы обсудили, как использовать нейроэволюцию для обучения больших нейросетей с более чем 4 млн обучаемых параметров. Вы узнали, как применить данный метод обучения для создания успешных игровых агентов, способных играть в классические игры Atari, изучая правила игры исключи- тельно из наблюдения за игровыми экранами. При подготовке к проведению эксперимента с игрой Atari вы узнали о сверточных нейронных сетях и о том, как их можно использовать для отображения многомерных входных данных, таких как изображения на игровом экране, в соответствующие игровые дей- ствия. Теперь у вас есть четкое понимание того, как можно использовать свер- точные нейросети для аппроксимации Q-матрицы в методе глубокого обуче- ния с подкреплением, основанном на алгоритме глубокой нейроэволюции. Обладая знаниями, приобретенными в этой главе, вы сможете применять методы глубокой нейроэволюции для работы с входными данными большого размера, например полученными с камер или других источников изображений. В следующей главе мы кратко обобщим то, о чем говорилось в этой книге, и дадим несколько советов о том, как вы можете продолжить свое самооб- разование.276  Глубокая нейроэволюция\n10.8 заключение В этой главе мы обсудили, как использовать нейроэволюцию для обучения больших нейросетей с более чем 4 млн обучаемых параметров. Вы узнали, как применить данный метод обучения для создания успешных игровых агентов, способных играть в классические игры Atari, изучая правила игры исключи- тельно из наблюдения за игровыми экранами. При подготовке к проведению эксперимента с игрой Atari вы узнали о сверточных нейронных сетях и о том, как их можно использовать для отображения многомерных входных данных, таких как изображения на игровом экране, в соответствующие игровые дей- ствия. Теперь у вас есть четкое понимание того, как можно использовать свер- точные нейросети для аппроксимации Q-матрицы в методе глубокого обуче- ния с подкреплением, основанном на алгоритме глубокой нейроэволюции. Обладая знаниями, приобретенными в этой главе, вы сможете применять методы глубокой нейроэволюции для работы с входными данными большого размера, например полученными с камер или других источников изображений. В следующей главе мы кратко обобщим то, о чем говорилось в этой книге, и дадим несколько советов о том, как вы можете продолжить свое самооб- разование.276  Глубокая нейроэволюция\n--- Страница 278 ---\nЧасть IV Обсуждение результатов и заключительные замечания В заключительной части книги представлено краткое изложение того, что вы узнали в предыдущих главах, и рассказано о ресурсах, которые вы можете ис- пользовать, чтобы узнать больше об алгоритмах на основе нейроэволюции. Эта часть состоит из следующих глав: главы 11 «Лучшие методы, советы и подсказки»; главы 12 «Заключительные замечания».",
          "debug": {
            "start_page": 277,
            "end_page": 279
          }
        }
      ]
    },
    {
      "name": "Глава 11. Лучшие методы, советы и подсказки 279",
      "chapters": [
        {
          "name": "11.1 Первичный анализ задачи 279",
          "content": "--- Страница 280 --- (продолжение)\nГлава 11 Лучшие методы, советы и подсказки В этой главе вы получите несколько советов по практическому использованию передовых методов и узнаете о некоторых приемах разработки и анализа ал- горитмов нейроэволюции. К концу главы вы узнаете, как начать работу с при- кладной задачей, как настроить гиперпараметры алгоритма нейроэволюции, как использовать расширенные инструменты визуализации и какие метрики можно применять для анализа производительности алгоритма. Кроме того, вы узнаете о лучших приемах кодирования на языке Python, которые помогут вам в реализации ваших проектов. В данной главе мы рассмотрим следующие темы: первичный анализ задачи; выбор оптимального метода поисковой оптимизации; использование современных инструментов визуализации; назначение и правильная настройка гиперпараметров; выбор нужных показателей производительности алгоритма; программирование на языке Python, советы и рекомендации. 11.1 первичный анализ заДачи Рецепт вашего успеха – начинать с правильного анализа проблемного про- странства. Нейроэволюция прощает многие ошибки программиста. С точки зрения нейроэволюции подобные ошибки являются частью окружающей сре- ды, и процесс эволюции способен адаптироваться к ним. Однако существует определенная категория ошибок, которые могут помешать процессу эволюции найти успешное решение: числовая стабильность процесса эволюции. Боль- шинство функций активации предназначены для работы в интервале входных значений от нуля до единицы. В результате слишком большие или отрицатель- ные значения не оказывают заметного влияния на процесс эволюции. Таким образом, возможно, вам придется предварительно обработать вход- ные данные, чтобы избежать проблемы числовой стабильности. Не пропус - кайте этапы анализа и предварительной обработки данных. Далее мы обсудим предварительную обработку входных данных.\n11.1 первичный анализ заДачи Рецепт вашего успеха – начинать с правильного анализа проблемного про- странства. Нейроэволюция прощает многие ошибки программиста. С точки зрения нейроэволюции подобные ошибки являются частью окружающей сре- ды, и процесс эволюции способен адаптироваться к ним. Однако существует определенная категория ошибок, которые могут помешать процессу эволюции найти успешное решение: числовая стабильность процесса эволюции. Боль- шинство функций активации предназначены для работы в интервале входных значений от нуля до единицы. В результате слишком большие или отрицатель- ные значения не оказывают заметного влияния на процесс эволюции. Таким образом, возможно, вам придется предварительно обработать вход- ные данные, чтобы избежать проблемы числовой стабильности. Не пропус - кайте этапы анализа и предварительной обработки данных. Далее мы обсудим предварительную обработку входных данных.\n--- Страница 281 ---\n11.1.1 Предварительная обработка данных Всегда исследуйте возможный диапазон входных данных и проверяйте на- личие выбросов. Если вы обнаружите, что масштаб одного входного парамет- ра отличается от другого на порядок, вам необходимо предварительно об- работать выборки входных данных. В противном случае признаки (features)1, представленные во входных данных с большей величиной, окажут настолько значительное влияние на процесс обучения, что в конечном итоге перекроют вклад других признаков. Однако небольшие сигналы, генерируемые входны- ми данными с малой величиной, часто имеют решающее значение для поиска успешного решения. Слабые входные сигналы могут характеризовать тонкие, но ценные нюансы базового процесса обучения. Стандартизация данных Большинство алгоритмов машинного обучения значительно выигрывают от входных данных, которые имеют нормальное распределение; то есть среднее значение и единичная дисперсия равны нулю. Такой подход называется стан- дартизацией данных. В общем виде стандартизация входных данных для полу - чения нулевого среднего значения и единичной дисперсии выражается следу - ющей формулой: xuz .s−= Здесь z – это стандартизованная входная оценка, x – выборка входных дан- ных, u – среднее значение обучающих выборок и s – стандартное отклонение обучающих выборок. Вы можете использовать библиотеку Python Scikit-learn, чтобы применить стандартизацию к вашим образцам входных данных. Следующий исходный код демонстрирует практический пример стандартизации: >>> from sklearn.preprocessing import StandardScaler >>> data = [[0, 0], [0, 0], [1, 1], [1, 1]] >>> scaler = StandardScaler() >>> print(scaler.fit(data)) StandardScaler(copy=True, with_mean=True, with_std=True) >>> print(scaler.mean_) [0.5 0.5]>>> print(scaler.transform(data))[[-1. -1.] 1 Здесь автор внезапно упоминает понятие признаков ( features), никак его не объясняя. В машинном обучении под признаками понимают такие данные из общего массива больших данных (big data), которые имеют значение для обучения модели в пред- метной области. Например, в предсказании погоды значащими признаками будут влажность, атмосферное давление, температура воздуха и т. д. В общем случае при- знаки имеют разную значимость (вес) для модели. Составление перечня признаков и присвоение им индивидуального веса называется извлечением, или конструирова- нием, признаков ( feature engineering) и обычно выполняется разработчиком вручную на этапе анализа предметной области, хотя, как упоминалось в этой книге, нейроэво- люция иногда способна самостоятельно оценить важность признаков. – Прим. перев.280  Лучшие методы, советы и подсказки\n--- Страница 282 ---\n[-1. -1.] [ 1. 1.] [ 1. 1.]] В этом коде мы сначала создаем выборки входных данных. После этого для центрирования и масштабирования входных выборок используется класс StandardScaler . Результаты преобразования данных показаны в последних строках листинга. Другой метод предварительной обработки данных – это масштабирование входных данных для приведения к определенному интервалу. Приведение входных данных к заданному интервалу Масштабирование входных данных, то есть приведение их к заданному ин- тервалу значений, является еще одним методом предварительной обработ - ки данных. Этот метод является альтернативой стандартизации. В результате масштабирования получаются выборки данных, которые лежат строго в ин- тервале между минимальным и максимальным значениями. Часто этот метод используется для масштабирования входных данных в интервале от нуля до единицы. Для масштабирования данных до нужного интервала вы можете ис- пользовать MinMaxScaler из библиотеки Python Scikit-learn, как показано в сле- дующем примере: >>> import sklearn.preprocessing >>> X_train = np.array([[ 1., -1., 2.], [ 2., 0., 0.], [ 0., 1., -1.]]) >>> min_max_scaler = preprocessing.MinMaxScaler()>>> X_train_minmax = min_max_scaler.fit_transform(X_train)>>> X_train_minmaxarray([[0.5 , 0. , 1. ], [1. , 0.5 , 0.33333333], [0. , 1. , 0. ]]) Пример начинается с создания выборки данных и преобразования с по- мощью класса MinMaxScaler . В последних строках листинга вы можете видеть масштабированные данные. Иногда вам нужно иметь образцы данных с одинаковыми единицами из- мерения. Этот метод предварительной обработки называется нормализацией. Мы обсудим его в следующем разделе. Нормализация данных Зачастую ваши входные данные имеют разные единицы измерения. Например, в эксперименте по балансировке обратного маятника положение тележки из- мерялось в метрах, линейная скорость выражалась в метрах в секунду, а угловая скорость – в радианах в секунду. Полезно нормализовать входные данные, что- бы упростить сравнение признаков, представленных во входных данных. Процесс нормализации эффективно исключает единицы измерения из вы- борок входных данных. После этого все выборки будут находиться в интер- вале от нуля до единицы. 11.1 Первичный анализ задачи  281\n--- Страница 283 ---\nВ статистике существуют разные типы нормализации. Мы уже упомина- ли два метода: стандартизацию и масштабирование. Кроме того, Scikit-learn предоставляет специальный преобразователь для нормализации данных, ко- торый масштабирует отдельные выборки до так называемой единичной нор- мы. Следующий код демонстрирует, как его использовать: >>> import sklearn.preprocessing >>> X = [[ 1., -1., 2.], [ 2., 0., 0.], [ 0., 1., -1.]]>>> X_normalized = preprocessing.normalize(X, norm='l2')>>> X_normalizedarray([[ 0.40 , -0.40 , 0.81 ], [ 1. , 0. , 0. ], [ 0. , 0.70 , -0.70 ]]) Код создает образец тестовых данных и применяет к нему нормализацию с использованием нормы l2 и выводит результаты. Библиотека Scikit-learn обеспечивает реализацию многих других ме- тодов предварительной обработки данных. Вам было бы полезно по-знакомиться с ними. Вы можете найти отличный учебник по адресу https://scikit-learn.org/stable/modules/preprocessing.html. 11.1.2 Исследование проблемной области В этой книге некоторые из экспериментов, которые мы обсуждали, были свя- заны с реальными процессами в физическом мире. Чтобы найти успешные решения для таких процессов, вам необходимо хорошо понимать основные физические законы и принципы. Например, задача балансировки обратного маятника на тележке требует, чтобы мы определили полный набор уравнений движения и написали точный симулятор задачи. Также для большинства задач в области робототехники вам необходимо написать симулятор, который использует корректную физическую модель и уравнения базового аппарата. Вам необходимо полностью понять фи- зику процесса, чтобы правильно реализовать симулятор. И даже если вы используе те готовый симулятор, понимание физических принципов, реали- зованных в нем, чрезвычайно полезно для вас, потому что понимание ди- намики реального процесса позволяет вам настроить гиперпараметры алго- ритма обучения соответствующим образом. 11.1.3 Написание хороших симуляторов При работе над конкретной задачей крайне важно написать качественный симулятор, который правильно реализует особенности моделируемого про- цесса. Если вы используете такой симулятор, то сможете запускать длинные эпизоды обучения, что невозможно при использовании прямого ввода с фи- зических устройств. Хороший симулятор должен позволять вам контролировать продолжи- тельность одного временно́го шага моделируемого процесса. Во время про-282  Лучшие методы, советы и подсказки\n--- Страница 284 ---\nгона нейроэволюции вам необходимо оценить каждую особь в популяции по отношению к данному симулятору. Таким образом, во время обучения име- ет смысл сделать длительность одного временного шага как можно меньше, чтобы увеличить скорость выполнения. С другой стороны, когда решение найдено и вам необходимо проверить его вручную, было бы полезно иметь возможность запускать симулятор с нормальной скоростью выполнения. Кроме того, вы можете использовать для своих проектов готовые тщательно проработанные симуляторы, что может сэкономить вам много времени. Озна- комьтесь с хорошо известными пакетами симуляторов с открытым исходным кодом. Они часто предоставляют расширенные физические модели, а также набор готовых строительных блоков для ваших виртуальных роботов и сред. Вы можете начать поиск по адресу https://github.com/cyberbotics/webots. Далее мы обсудим, как выбрать правильный метод оптимизации поиска для вашего эксперимента.",
          "debug": {
            "start_page": 280,
            "end_page": 284
          }
        },
        {
          "name": "11.2 Выбор оптимального метода поисковой оптимизации 283",
          "content": "--- Страница 284 --- (продолжение)\n11.2 выбОр Оптимальн ОгО метОДа пОиСкОвОй Оптимизации В этой книге мы представили вам два основных метода поиска оптимального решения: поиск по близости к цели (целеориентированный) и поиск новизны. Первый способ более прост в реализации и проще для понимания. Однако по- иск новизны удобен в тех случаях, когда функция приспособленности имеет обманчивый ландшафт со многими локальными ловушками оптимальности. В следующем разделе мы кратко обсудим оба метода, чтобы напомнить вам о деталях и помочь выбрать, какой из них использовать в вашей ситуа- ции. Начнем с целеориентированного поиска. 11.2.1 Целеориентированный поиск оптимального решения Целеориентированный поиск оптимального решения основан на измерении близости решения к конечной цели. Чтобы вычислить среднее расстояние до цели, он часто использует такую метрику, как среднеквадратичная ошибка. Далее мы обсудим особенности метрики среднеквадратичной ошибки. Среднеквадратичная ошибка Среднеквадратичная ошибка – это среднеквадратичная разница между полу - ченными результатами и фактическими значениями, которая вычисляется по следующей формуле: ()2 11n i i iMSE yy.n==−∑ . Здесь yi является предсказанным значением, а ()2 11n i i iMSE yy.n==−∑ является фактическим зна- чением. Мы использовали изменение среднеквадратичной ошибки, чтобы опреде- лить целевую функцию для эксперимента XOR. Далее обсудим целеориенти- рованные метрики для задач, связанных с позиционированием в евклидо- вом пространстве. 11.2 Выбор оптимального метода поисковой оптимизации  283\n11.2 выбОр Оптимальн ОгО метОДа пОиСкОвОй Оптимизации В этой книге мы представили вам два основных метода поиска оптимального решения: поиск по близости к цели (целеориентированный) и поиск новизны. Первый способ более прост в реализации и проще для понимания. Однако по- иск новизны удобен в тех случаях, когда функция приспособленности имеет обманчивый ландшафт со многими локальными ловушками оптимальности. В следующем разделе мы кратко обсудим оба метода, чтобы напомнить вам о деталях и помочь выбрать, какой из них использовать в вашей ситуа- ции. Начнем с целеориентированного поиска. 11.2.1 Целеориентированный поиск оптимального решения Целеориентированный поиск оптимального решения основан на измерении близости решения к конечной цели. Чтобы вычислить среднее расстояние до цели, он часто использует такую метрику, как среднеквадратичная ошибка. Далее мы обсудим особенности метрики среднеквадратичной ошибки. Среднеквадратичная ошибка Среднеквадратичная ошибка – это среднеквадратичная разница между полу - ченными результатами и фактическими значениями, которая вычисляется по следующей формуле: ()2 11n i i iMSE yy.n==−∑ . Здесь yi является предсказанным значением, а ()2 11n i i iMSE yy.n==−∑ является фактическим зна- чением. Мы использовали изменение среднеквадратичной ошибки, чтобы опреде- лить целевую функцию для эксперимента XOR. Далее обсудим целеориенти- рованные метрики для задач, связанных с позиционированием в евклидо- вом пространстве. 11.2 Выбор оптимального метода поисковой оптимизации  283\n--- Страница 285 ---\nЕвклидово расстояние Евклидово расстояние является удобной метрикой для задач, связанных с на- вигацией в евклидовом пространстве. В евклидовом пространстве мы опреде- ляем цель задачи как точку с определенными координатами. Используя евклидово расстояние, легко рассчитать расстояние между по- ложением навигационного агента и целевой точкой, которую он пытается достичь. Следующая формула вычисляет евклидово расстояние между двумя векторами: ()22 1i i ia b . ==−∑ Здесь D – евклидово расстояние между вектором положения агента ai и вектором конечной цели bi. Мы использовали эту метрику для определения целевой функции агента, проходящего через лабиринт, в главе 5. Однако главная проблема автономного прохождения лабиринта заключается в обманчивом ландшафте функции приспособленности, что делает целеориен- тированную оптимизацию неэффективной. Далее мы обсудим метод оптими- зации поиском новизны, который способен устранить эту неэффективность. 11.2.2 Оптимизация поиском новизны Как мы уже упоминали, прохождение лабиринта является обманчивой за- дачей, которая требует использования особой функции приспособленности. В главе 5 мы представили вам конкретную конфигурацию лабиринта, в кото- рой существуют области с выраженными локальными оптимумами целеори- ентированной функции приспособленности. В результате процесс обучения может оказаться в ловушке внутри этих областей и не сможет прийти к успеш- ному решению. Для решения проблем с обманчивыми ландшафтами функций приспособленности был разработан метод оптимизации поиском новизны. Поиск новизны вознаграждает за новизну решения, а не за его близость к конечной цели. Кроме того, метрика новизны, которая используется для расчета оценки приспособленности каждого решения, полностью игнориру - ет близость решения к конечной цели. Существует два популярных подхода для расчета оценки новизны: исходя из различий в архитектуре решений; на основе уникальных вариаций поведения решений в общем поведен- ческом пространстве. Первый подход рассчитывает разницу между кодировкой текущего реше- ния и всех предыдущих решений. Второй подход сравнивает результат, полу - ченный текущим решением в поведенческом пространстве, с результатами, полученными другими решениями. Для вычисления приспособленности найденных решений мы использова- ли оценки новизны, основанные на уникальности проявленного поведения. Траектория движения через лабиринт полностью определяет поведенческое пространство агента и может использоваться для расчета оценки новизны. В данном случае оценка новизны – это евклидово расстояние между вектора- ми траекторий текущего решения и всех остальных решений.284  Лучшие методы, советы и подсказки\n--- Страница 286 ---\nТеперь, когда мы обсудили важность выбора подходящего метода оптими- зации поиска, мы можем перейти к обсуждению еще одного важного аспекта успешного эксперимента. Вы должны иметь хорошую визуализацию резуль- татов эксперимента, чтобы получить представление о его результатах. Далее мы обсудим визуализацию результатов.",
          "debug": {
            "start_page": 284,
            "end_page": 286
          }
        },
        {
          "name": "11.3 Качественная визуализация 285",
          "content": "11.3 качеСтвенная визуализация Почти всегда правильная визуализация входных данных и результатов имеет решающее значение для успеха вашего эксперимента. Благодаря правильной визуализации вы получите наглядное представление о том, что пошло не так и что нужно исправить. Всегда старайтесь визуализировать процесс работы симулятора. Такая визуа- лизация может сэкономить вам часы отладки, когда вы получите неожиданный результат. Обычно при надлежащей визуализации вы можете сразу увидеть, что что-то пошло не так – например, агент-решатель лабиринта застрял в углу. При использовании алгоритмов нейроэволюции вам также необходимо визуализировать ход выполнения генетического алгоритма для каждого по- коления. Вы должны визуализировать видообразование от поколения к по- колению, чтобы увидеть, не застыл ли эволюционный процесс в одном со- стоянии. Застоявшаяся эволюция не в состоянии создать достаточно видов для поддержания здорового разнообразия среди решателей задачи. С другой стороны, чрезмерное разнообразие видов препятствует эволюции, уменьшая шансы спаривания между различными организмами. Еще одна важная визуализация позволяет нам увидеть топологию феноти- па искусственной нейронной сети. Полезно визуально проверить топологию полученного решения, чтобы проверить, соответствует ли она вашим ожида- ниям. Например, когда мы обсуждали проблему модульной сетчатки в гла- ве 8, было полезно убедиться, что модульные структуры эволюционировали в рациональные топологии успешных решений. Вам необходимо ознакомиться со стандартными научными библиотеками построения графиков на языке Python, чтобы создавать адекватную визуа- лизацию для результатов ваших экспериментов. Следует развивать практи- ческие навыки работы с такими библиотеками визуализации, как Matplotlib (https://matplotlib.org) и Seaborn (https://seaborn.pydata.org). Далее мы обсудим важность настройки гиперпараметров перед запуском процесса нейроэволюции.",
          "debug": {
            "start_page": 286,
            "end_page": 286
          }
        },
        {
          "name": "11.4 Настройка гиперпараметров 285",
          "content": "--- Страница 286 --- (продолжение)\n11.3 качеСтвенная визуализация Почти всегда правильная визуализация входных данных и результатов имеет решающее значение для успеха вашего эксперимента. Благодаря правильной визуализации вы получите наглядное представление о том, что пошло не так и что нужно исправить. Всегда старайтесь визуализировать процесс работы симулятора. Такая визуа- лизация может сэкономить вам часы отладки, когда вы получите неожиданный результат. Обычно при надлежащей визуализации вы можете сразу увидеть, что что-то пошло не так – например, агент-решатель лабиринта застрял в углу. При использовании алгоритмов нейроэволюции вам также необходимо визуализировать ход выполнения генетического алгоритма для каждого по- коления. Вы должны визуализировать видообразование от поколения к по- колению, чтобы увидеть, не застыл ли эволюционный процесс в одном со- стоянии. Застоявшаяся эволюция не в состоянии создать достаточно видов для поддержания здорового разнообразия среди решателей задачи. С другой стороны, чрезмерное разнообразие видов препятствует эволюции, уменьшая шансы спаривания между различными организмами. Еще одна важная визуализация позволяет нам увидеть топологию феноти- па искусственной нейронной сети. Полезно визуально проверить топологию полученного решения, чтобы проверить, соответствует ли она вашим ожида- ниям. Например, когда мы обсуждали проблему модульной сетчатки в гла- ве 8, было полезно убедиться, что модульные структуры эволюционировали в рациональные топологии успешных решений. Вам необходимо ознакомиться со стандартными научными библиотеками построения графиков на языке Python, чтобы создавать адекватную визуа- лизацию для результатов ваших экспериментов. Следует развивать практи- ческие навыки работы с такими библиотеками визуализации, как Matplotlib (https://matplotlib.org) и Seaborn (https://seaborn.pydata.org). Далее мы обсудим важность настройки гиперпараметров перед запуском процесса нейроэволюции. 11.4 наСтрОйка гиперпараметр Ов При правильной настройке гиперпараметров вы можете значительно повы- сить скорость обучения и эффективность процесса нейроэволюции. Вот не- сколько практических советов: сделайте короткие прогоны с различными начальными значениями гене- ратора случайных чисел и обратите внимание, как изменяется качество работы алгоритма. После этого выберите начальное значение, которое дает наилучший результат, и используйте его для длительных прогонов; 11.4 Настройка гиперпараметров  285\n11.4 наСтрОйка гиперпараметр Ов При правильной настройке гиперпараметров вы можете значительно повы- сить скорость обучения и эффективность процесса нейроэволюции. Вот не- сколько практических советов: сделайте короткие прогоны с различными начальными значениями гене- ратора случайных чисел и обратите внимание, как изменяется качество работы алгоритма. После этого выберите начальное значение, которое дает наилучший результат, и используйте его для длительных прогонов; 11.4 Настройка гиперпараметров  285\n--- Страница 287 ---\nвы можете увеличить количество видов в популяции, уменьшив порог совместимости и немного увеличив значение весового коэффициента пересечения/несовпадения генов; если процесс нейроэволюции споткнулся при попытке найти решение, попытайтесь уменьшить значение порога выживания NEAT. Этот коэф- фициент определяет долю лучших организмов в популяции, которые получили возможность размножаться. Уменьшая коэффициент, вы по- вышаете качество особей, которым разрешено воспроизводить потом- ство в зависимости от их приспособленности; увеличив максимальный возраст стагнации, вы можете гарантировать, что виды проживут достаточно долго, чтобы иметь возможность полу - чить полезные мутации на более поздних стадиях эволюции. Иногда такая операция помогает подтолкнуть остановившийся процесс нейро- эволюции. Тем не менее вы всегда должны начинать с небольших зна- чений допустимой стагнации (15–20 поколений), чтобы инициировать быстрое обновление видов, и значительно увеличивать этот параметр только в случае неудачи всех других настроек; после настройки гиперпараметров выполните прогон эволюции на нескольких десятках поколений, чтобы увидеть динамику изменения приспособленности. Обратите особое внимание на количество видов – в популяции должно быть не менее одного вида. Слишком много ви- дов – это тоже плохой знак. Хорошо, если видовое разнообразие варьи- руется в интервале от 5 до 20 видов; используйте визуализацию, чтобы быстро получить наглядное пред- ставление о результатах эксперимента. Никогда не упускайте возмож - ность визуализировать топологию нейросетей обнаруженных реше- ний. Эти визуализации могут дать вам бесценное понимание того, как настроить процесс нейроэволюции; не тратьте свое время на длинные эволюционные прогоны. Если в ходе эксперимента не удается найти успешное решение через 1000 по- колений, есть большая вероятность, что что-то не так с вашим кодом или библиотекой, которую вы используете. Для большинства простых проблем удачное решение может быть найдено всего через 100 по- колений; численность популяции является критическим параметром эволюци- онного процесса. С большой популяцией вы с самого начала получае- те большое разнообразие особей, что ускоряет процесс эволюции. Тем не менее большая популяция увеличивает вычислительную нагрузку. Поэтому всегда приходится искать компромисс между численностью популяции и вычислительными затратами. Как правило, если вам труд- но найти другие подходящие гиперпараметры, попробуйте увеличить размер популяции и посмотреть, поможет ли это. Но будьте готовы дольше ждать, пока завершится процесс нейроэволюции; всегда распечатывайте отладочную информацию и сохраняйте проме- жуточные точки, что позволит вам перезапустить эксперимент с любо- го этапа вычислений. Всегда больно, когда вы находите решение после двух дней вычислений, но из-за нелепой ошибки в коде происходит 286  Лучшие методы, советы и подсказки\n--- Страница 288 ---\nсбой вашей программы при попытке вывести сообщение с поздравле- нием. Вам нужно вывести, по крайней мере, начальное значение гене- ратора случайных чисел в начале каждого испытания. Это поможет вам точно воссоздать все поколения эволюции в случае неудачи. Не стоит недооценивать важность настройки гиперпараметров. Даже при- нимая во внимание, что процесс нейроэволюции может справиться со многи- ми ошибками программирования, выбор правильных гиперпараметров может значительно повысить производительность процесса. В результате вы сможете найти успешное решение за сотни поколений, а не за тысячи или более. Чтобы сравнить успешность различных решений, вам нужно использовать соответствующие метрики качества, которые мы обсудим далее.",
          "debug": {
            "start_page": 286,
            "end_page": 288
          }
        },
        {
          "name": "11.5 Метрики качества модели 287",
          "content": "--- Страница 288 --- (продолжение)\n11.5 метрики каче Ства мОДели После того как найдено успешное решение, важно сравнить его с другими ре- шениями, чтобы оценить, насколько оно хорошее. Есть много важных статис- тических показателей, относительно которых сравнивают разные модели. Ознакомьтесь с такими понятиями, как оценка точности, оценка отзыва, оценка F1, ROC AUC и достоверность. Понимание этих метрик поможет вам сравнить результаты, полученные различными моделями в различных зада- чах классификации. Далее мы даем краткий обзор этих метрик. 11.5.1 Т очность Точность (precision) отвечает на вопрос о том, какая доля положительных от- ветов соответствует истине. Оценка точности может быть рассчитана следую- щим образом: TPprecision .TPFP=+ TP (true positive) – это истинно положительные ответы, а FP (false positive) – ложноположительные ответы. 11.5.2 Отклик Отклик (recall) отвечает на вопрос о том, какая доля от фактически положи- тельных результатов была определена правильно. Оценка отклика вычисляет - ся по следующей формуле: TPrecall .TPFN=+ TP – это истинно положительные результаты, а FN (false negative) – ложноотри- цательные. 11.5.3 Оценка F1 Оценка F1 – это средневзвешенное значение между оценками точности и от - клика. Наилучшее значение в баллах F1 – один, а худшее – ноль. Оценка F1 по- 11.5 Метрики качества модели  287\n11.5 метрики каче Ства мОДели После того как найдено успешное решение, важно сравнить его с другими ре- шениями, чтобы оценить, насколько оно хорошее. Есть много важных статис- тических показателей, относительно которых сравнивают разные модели. Ознакомьтесь с такими понятиями, как оценка точности, оценка отзыва, оценка F1, ROC AUC и достоверность. Понимание этих метрик поможет вам сравнить результаты, полученные различными моделями в различных зада- чах классификации. Далее мы даем краткий обзор этих метрик. 11.5.1 Т очность Точность (precision) отвечает на вопрос о том, какая доля положительных от- ветов соответствует истине. Оценка точности может быть рассчитана следую- щим образом: TPprecision .TPFP=+ TP (true positive) – это истинно положительные ответы, а FP (false positive) – ложноположительные ответы. 11.5.2 Отклик Отклик (recall) отвечает на вопрос о том, какая доля от фактически положи- тельных результатов была определена правильно. Оценка отклика вычисляет - ся по следующей формуле: TPrecall .TPFN=+ TP – это истинно положительные результаты, а FN (false negative) – ложноотри- цательные. 11.5.3 Оценка F1 Оценка F1 – это средневзвешенное значение между оценками точности и от - клика. Наилучшее значение в баллах F1 – один, а худшее – ноль. Оценка F1 по- 11.5 Метрики качества модели  287\n--- Страница 289 ---\nзволяет измерить точность классификации, характерную для определенного класса, и определяется так: 12precisionrecallF .precisionrecall×=+ Здесь precision – оценка точности, а recall – оценка отклика относительно определенного положительного класса. В следующем разделе мы рассмотрим кривую рабочей характеристики приемника ( receiver operating characteristic, ROC) и площадь под кривой ( area under curve, AUC). 11.5.4 ROC AUC Мы строим кривую ROC, нанося на график точки в координатах истинно поло- жительных и ложноположительных показателей при разных пороговых значе- ниях. Кривая показывает точность классифицирующей модели при различных пороговых значениях. Коэффициент истинно положительных результатов ( true positive rate, TPR) является синонимом отклика, о котором мы говорили ранее. Он вычисляется по формуле: TPTPR .TPFN=+ Коэффициент ложноположительных результатов ( false positive rate, FPR) рассчитывается следующим образом: FPFPR .FPTN=+ Здесь TN – это истинно отрицательные результаты. AUC позволяет нам оценить различающую способность (discrimination pow - er) классифицирующей модели, то есть способность модели правильно при- сваивать более высокую оценку случайным положительным точкам по срав- нению со случайными отрицательными точками. На рис. 11.1 показан пример кривой ROC. Чем больше AUC (площадь под кривой), тем точнее модель классификатора. Пунктирная линия показывает наихудшую точность классификатора. Как правило, чем ближе кривая ROC к верхнему левому углу, тем выше качество классифицирующей модели.288  Лучшие методы, советы и подсказки\n--- Страница 290 ---\nДоля ложноположительных решенийПример рабочей характеристики приемникаДоля истинно положительных решений Кривая ROC (площадь = 0,79) Рис. 11.1. Пример кривой ROC 11.5.5 Достоверность Достоверность (accuracy) – это показатель, сообщающий, сколько правильных предсказаний смогла сделать наша модель. Достоверность определяется по следующей формуле: TPTNaccuracy .TPTNFPFN+=+++ Здесь FP – ложноположительные срабатывания, а FN – ложноотрицательные. Более подробную информацию можно найти по адресу https:// scikitlearn.org/stable/auto_examples/model_selection/plot_precision_ recall.html. Далее вы найдете советы по программированию на языке Python.",
          "debug": {
            "start_page": 288,
            "end_page": 290
          }
        },
        {
          "name": "11.6 Python, кодирование, советы и рекомендации 289",
          "content": "--- Страница 290 --- (продолжение)\n11.6 pyTHoN, кОДирОвание , СОветы и рекОмен Дации Решив работать с Python, важно изучить лучшие практики использования язы- ка. В этом разделе я дам вам несколько советов и рекомендаций для самостоя- тельного обучения. 11.6 Python, кодирование, советы и рекомендации  289\n11.6 pyTHoN, кОДирОвание , СОветы и рекОмен Дации Решив работать с Python, важно изучить лучшие практики использования язы- ка. В этом разделе я дам вам несколько советов и рекомендаций для самостоя- тельного обучения. 11.6 Python, кодирование, советы и рекомендации  289\n--- Страница 291 ---\n11.6.1 Советы и рекомендации Следующие советы и рекомендации помогут вам освоить программирование на языке Python: научитесь пользоваться популярными библиотеками машинного обуче ния, такими как NumPy (https://numpy.org), pandas (https:// pandas.pydata.org) и Scikitlearn (https://scikit-learn.org/stable). Ос- воение этих библиотек откроет перед вами огромные возможности в обработке и анализе данных. Навык работы с этими библиотеками поможет вам избежать многих ошибок и позволит легко отлаживать программы, исходя из результатов экспериментов; изучите объектно-ориентированную парадигму программирования. Это позволит вам писать чистый и понятный исходный код, который легко разобрать. Вы можете начать с учебника https://www.datacamp. com/community/tutorials/python-oop-tutorial; не сваливайте весь код в одну огромную функцию. Разбейте ваш код на более мелкие блоки многократного использования, реализованные в виде функций или классов, которые можно повторно использовать в нескольких проектах и легко отлаживать; всегда выводите на печать промежуточные и отладочные данные, что- бы понимать, что происходит в вашей программе. Обладая достаточ- ным количеством отладочных данных, намного проще понять, что не так с выполнением программы; пишите комментарии, относящиеся к функциям, классам и сложным местам в вашем исходном коде. Хорошие комментарии значительно облегчают понимание кода. Написание комментариев по ходу реали- зации алгоритма также поможет прояснить ваши собственные мысли; при написании комментариев к функции опишите все входные и вы- ходные параметры и их значения по умолчанию, если таковые имеются; если вы решили продолжить работу с Python, потратьте некоторое время на изучение стандартных библиотек. Python – это зрелый язык программирования со множеством служебных функций, встроенных в его стандартные библиотеки. У него также есть много функций, реа- лизующих продвинутые манипуляции с данными, которые могут при- годиться в задачах машинного обучения. Более подробную информа- цию о стандартных библиотеках Python можно найти по адресу https:// docs.python.org/3/library/index.html; следуйте стандартным соглашениям исходного кода Python при при- своении имен переменным и классам. Следование стандартным со- глашениям об именах делает ваш код более читабельным и понятным для всех, кто имеет опыт работы с Python. Вы можете найти более под- робную информацию по адресу https://docs.pythonguide.org/writing/ style/ и https://www.python.org/dev/peps/pep-0008/; ознакомьтесь с современными системами контроля версий, такими как Git. Система контроля версий ( version control system, VCS) – это мощ- ный инструмент, который может сэкономить вам часы и даже дни по- пыток восстановить утраченную работу, вызванную поломкой жестко-290  Лучшие методы, советы и подсказки\n--- Страница 292 ---\nго диска. Вы можете узнать о Git по адресу https://github.github.com/ training-kit/downloads/github-git-cheat-sheet.pdf и https://www. atlassian.com/git/tutorials; используйте онлайн-хранилища кода, такие как GitHub (https://github. com) и Bitbucket (https://bitbucket.org), где вы можете поделиться своим исходным кодом и изучить исходный код других исследователей данных. Другим важным условием написания хороших программ является пра- вильная настройка рабочей среды и использование подходящих инструмен- тов программирования. 11.6.2 Рабочая среда и инструменты программирования Для правильной настройки рабочей среды всегда полезно использовать один из развитых менеджеров пакетов Python, например Anaconda Distribution. В качестве дополнительного преимущества вы получите множество бесплат - ных пакетов для научного и машинного обучения, которые готовы к установке одной командой. Кроме того, Anaconda Distribution управляет всеми косвен- ными зависимостями и помогает поддерживать все ваши пакеты в актуаль- ном состоянии. Вы можете найти Anaconda Distribution по адресу https://www. anaconda.com/distribution/. Всегда создавайте новую виртуальную среду Python для каждого из ваших экспериментов. После этого, если что-то пойдет не так с зависимостями, вы сможете очистить все одной командой и начать с нуля. Новая среда Python может быть создана с помощью Anaconda Distribution следующим образом: $ conda create --name <name> $ conda activate <name> При создании новой среды всегда указывайте точную версию Python, ко- торую вы планируете использовать. Упоминание точной версии поможет вам избежать многих неприятностей, вызванных несовместимостью. Версия Python для новой среды может быть определена следующим образом: $ conda create --name <name> python=3.5 Если вам нужно использовать новую зависимость в вашем проекте, снача- ла убедитесь, что в Anaconda Cloud существует соответствующий установоч- ный пакет. Используя библиотеки из Anaconda Cloud, вы можете избежать проблем с установкой косвенных зависимостей. Кроме того, некоторые плат - формы, такие как TensorFlow, требуют установки дополнительных системных драйверов и заголовочных файлов. Эта задача может оказаться очень гро- моздкой и потребовать дополнительных навыков. Используйте хороший редактор кода, который поддерживает автоза- вершение ввода, просмотр документации и поддержку виртуальных сред Python. Удачный вариант для начала – бесплатный редактор Visual Studio Code, предоставляемый Microsoft. Вы можете найти его на https://code. visualstudio.com. Познакомьтесь с современными операционными системами Linux, та- кими как Ubuntu. Большинство библиотек машинного обучения намного проще использовать с Linux. Это особенно верно для библиотек, которые 11.6 Python, кодирование, советы и рекомендации  291\n--- Страница 293 ---\nиспользуют графические ускорители. Более подробную информацию об Ubuntu и установке этой операционной системы можно найти по адресу https://ubuntu.com.",
          "debug": {
            "start_page": 290,
            "end_page": 293
          }
        },
        {
          "name": "11.7 Заключение 292",
          "content": "--- Страница 293 --- (продолжение)\n11.7 заключение В этой главе вы получили практические советы, которые, как я надеюсь, об- легчат вашу жизнь. Вы узнали о стандартных методах предварительной об- работки данных и о популярных статистических показателях, которые можно использовать для оценки производительности созданных вами моделей. На- конец, вы узнали, как улучшить свои навыки программирования и где искать дополнительную информацию по темам Python и машинного обучения. В следующей главе приведены заключительные замечания, основанные на том, что вы узнали в книге, и соображения о том, где вы можете применить полученные знания в будущем.292  Лучшие методы, советы и подсказки\n11.7 заключение В этой главе вы получили практические советы, которые, как я надеюсь, об- легчат вашу жизнь. Вы узнали о стандартных методах предварительной об- работки данных и о популярных статистических показателях, которые можно использовать для оценки производительности созданных вами моделей. На- конец, вы узнали, как улучшить свои навыки программирования и где искать дополнительную информацию по темам Python и машинного обучения. В следующей главе приведены заключительные замечания, основанные на том, что вы узнали в книге, и соображения о том, где вы можете применить полученные знания в будущем.292  Лучшие методы, советы и подсказки",
          "debug": {
            "start_page": 293,
            "end_page": 293
          }
        }
      ]
    },
    {
      "name": "Глава 12. Заключительные замечания 293",
      "chapters": [
        {
          "name": "12.1 Что вы узнали в этой книге 293",
          "content": "--- Страница 294 --- (продолжение)\nГлава 12 Заключительные замечания Настало время кратко обобщить все, что вы узнали в этой книге, и предоста- вить дополнительную информацию, чтобы вы могли продолжить свое самооб- разование. Эта глава поможет вам объединить темы, которые мы рассмотре- ли в формате отдельных глав, а затем подскажет направление дальнейшего развития, поделившись некоторыми подробностями об Uber AI Labs, alife.org и открытой эволюции в Reddit. Вы также найдете здесь краткий обзор катало- га программного обеспечения NEAT и статьи про алгоритм NEAT. В этой главе мы рассмотрим следующие темы: что вы узнали в этой книге; в каком направлении развиваться дальше. 12.1 чтО вы узнали в этОй книге Я надеюсь, что благодаря экспериментам и упражнениям вы получили чет- кое представление о нейроэволюционном методе обучения искусственных нейронных сетей. Мы использовали нейроэволюцию, чтобы найти решения различных задач, от классических проблем информатики до создания аген- тов, способных играть в игры Atari. Мы также рассмотрели задачи, связанные с компьютерным зрением и зрительным различением. 12.1.1 Обзор методов нейроэволюции В первой главе вы узнали об основных понятиях генетических алгоритмов, таких как генетические операторы и схемы кодирования генома. Мы обсудили два основных генетических оператора, которые позволяют нам поддерживать эволюционный процесс: оператор мутации – реализует случайные мутации потомства, что вно- сит генетическое разнообразие в популяцию; оператор кроссовера – генерирует потомство путем отбора генов от каждого родителя. После этого мы продолжили дискуссию о важности выбора правильной схемы кодирования генома. Мы рассмотрели два основных формата кодиро- вания: прямое и косвенное кодирования генома. Первый формат вводит вза- имно-однозначное соотношение между геномом и закодированным феноти- пом нейросети. Обычно прямое кодирование применяется для кодирования\n12.1 чтО вы узнали в этОй книге Я надеюсь, что благодаря экспериментам и упражнениям вы получили чет- кое представление о нейроэволюционном методе обучения искусственных нейронных сетей. Мы использовали нейроэволюцию, чтобы найти решения различных задач, от классических проблем информатики до создания аген- тов, способных играть в игры Atari. Мы также рассмотрели задачи, связанные с компьютерным зрением и зрительным различением. 12.1.1 Обзор методов нейроэволюции В первой главе вы узнали об основных понятиях генетических алгоритмов, таких как генетические операторы и схемы кодирования генома. Мы обсудили два основных генетических оператора, которые позволяют нам поддерживать эволюционный процесс: оператор мутации – реализует случайные мутации потомства, что вно- сит генетическое разнообразие в популяцию; оператор кроссовера – генерирует потомство путем отбора генов от каждого родителя. После этого мы продолжили дискуссию о важности выбора правильной схемы кодирования генома. Мы рассмотрели два основных формата кодиро- вания: прямое и косвенное кодирования генома. Первый формат вводит вза- имно-однозначное соотношение между геномом и закодированным феноти- пом нейросети. Обычно прямое кодирование применяется для кодирования\n--- Страница 295 ---\nнебольших нейросетей, которые имеют ограниченное количество подклю- ченных узлов. Более продвинутая схема косвенного кодирования позволяет нам кодировать развивающуюся топологию крупномасштабных нейросетей, часто с миллионами связей. Косвенное кодирование дает возможность по- вторно использовать повторяющиеся паттерны кодирования, тем самым значительно уменьшая размер генома. Ознакомившись с основными схемами кодирования генома, мы приступили к обсуждению метода нейроэволюции, который использует различные схемы кодирования. Мы начали с введения в алгоритм NEAT, который использует схе- му прямого кодирования генома и дополняет ее концепцией числа инноваций. Число инноваций, связанное с каждым геном генотипа, позволяет точно отсле- живать, когда была введена конкретная мутация. Эта функция делает опера- ции кроссовера между двумя родителями простыми и легкими в реализации. Метод NEAT подчеркивает важность запуска эволюции с очень простого гено- ма, который постепенно становится более сложным. Таким образом, эволюци- онный процесс имеет прекрасную возможность найти оптимальное решение. Кроме того, была введена концепция видообразования, которая сохраняет полезные мутации, выделяя их у определенных видов (ниш). Видам в преде- лах одной ниши разрешено скрещиваться только друг с другом. Видообра- зование является великой движущей силой естественной эволюции, и было показано, что оно также оказывает большое влияние на нейроэволюцию. Обсудив основной алгоритм NEAT, мы приступили к изучению его расши- рений, устраняющих ограничения исходного алгоритма. Один из существен- ных недостатков алгоритма NEAT вызван использованием схемы прямого ко- дирования генома. Эта схема, хотя и проста для визуализации и реализации, кодирует только топологии небольших нейросетей. С увеличением размера фенотипа нейросети размер генома увеличивается в линейной пропорции. Это увеличение размера генома в конечном итоге затрудняет реализацию ал- горитма. Для устранения этого недостатка был представлен ряд расширений, основанных на схемах косвенного кодирования генома, таких как HyperNEAT и ES-HyperNEAT. Метод HyperNEAT использует расширенный формат для представления связей между узлами фенотипа нейросети в виде четырехмерных точек в ги- перкубе. Размерность выбранного гиперкуба основана на том факте, что свя- зи между двумя узлами в нейросети могут быть закодированы координатами конечных точек соединения в среде, называемой субстратом. Топология суб- страта обусловливает структуру, которая образует связи между узлами фено- типа нейросети. Вес связи, которая устанавливается между двумя конкрет - ными узлами на субстрате, оценивается вспомогательной нейронной сетью, известной как сеть, производящая составные паттерны ( compositional pattern producing network, CPPN). CPPN получает координаты гиперточки (координа- ты конечных точек связи) в качестве входных данных и возвращает вес связи. Кроме того, она вычисляет значение флага, который указывает, должно со- единение быть экспрессировано или нет. Экспериментатор заранее определя- ет конфигурацию субстрата. Она определяется геометрическими свойствами решаемой задачи. В то же время топология CPPN развивается в процессе ней- роэволюции с использованием алгоритма NEAT. Таким образом, мы получа-294  Заключительные замечания\n--- Страница 296 ---\nем лучшее из обоих миров. Мощь алгоритма NEAT позволяет нам развивать оптимальные конфигурации CPPN. В то же время CPPN поддерживает схему непрямого кодирования и позволяет представлять масштабные нейросети. Метод ES-HyperNEAT является продолжением развития оригинальных методов NEAT и HyperNEAT и добавляет возможность развивать субстрат по мере эволюции CPPN. Развитие субстрата основано на понятии плотности информации, что позволяет более плотно размещать узлы в областях с боль- шей изменчивостью информации. Этот подход позволяет процессу нейро- эволюции находить конфигурации субстрата, которые точно следуют геомет- рическим закономерностям, скрытым в решаемой задаче. Мы завершили первую главу обсуждением увлекательного метода поиско- вой оптимизации, известного как поиск новизны ( novelty search, NS). В основе этого метода управления эволюционным поиском лежит метрика новизны найденных решений. Традиционно поисковая оптимизация основана на це- леориентированных критериях пригодности, которые измеряют, насколько мы близки к цели. Но есть целый ряд реальных задач, которые имеют об- манчивые ландшафты функций приспособленности с глубокими ловушками локальных оптимумов. Целеориентированный поиск имеет большой шанс застрять в одной из этих ловушек и не найти окончательного решения. В то же время метод поисковой оптимизации, поощряющий новизну найденного решения, позволяет нам избежать этих ловушек, полностью игнорируя бли- зость к конечной цели. Было показано, что метод поиска новизны эффекти- вен в задачах автономного прохождения лабиринта с ловушками оптимумов и заметно превосходит целеориентированные методы. В следующей главе говорилось о том, как правильно настроить рабочую среду и какие библиотеки Python можно использовать для экспериментов с нейроэволюцией. 12.1.2 Библиотеки Python и настройка среды разработки Во второй главе мы начали с обсуждения практических аспектов нейроэволю- ции. Вы узнали про достоинства и недостатки популярных библиотек Python, которые предоставляют реализации алгоритма NEAT и его расширений. Наряду с обсуждением каждой библиотеки Python вы рассмотрели неболь- шие фрагменты кода, дающие вам представление о том, как использовать каждую конкретную библиотеку в предстоящих экспериментах. После этого мы приступили к обсуждению правильной настройки рабочей среды. В рабочей среде должны быть установлены необходимые зависимо- сти, позволяющие использовать упомянутые ранее библиотеки Python. Уста- новка может быть выполнена несколькими способами. Мы рассмотрели два наиболее распространенных из них – стандартный установщик пакетов для утилиты Python (PIP) и Anaconda Distribution. Другим важным аспектом под- готовки рабочей среды является создание изолированных виртуальных сред Python для каждого конкретного эксперимента. Виртуальные среды допуска- ют наличие различных конфигураций зависимостей для разных эксперимен- тов и используемых в них библиотек NEAT. Размещение зависимостей в виртуальной среде также позволяет легко управлять всеми установленными зависимостями в целом. Среда может быть 12.1 Что вы узнали в этой книге  295\n--- Страница 297 ---\nбыстро удалена с вашего ПК вместе со всеми установленными файлами, осво- бождая тем самым место на диске. Вы также можете повторно использовать определенную виртуальную среду для различных экспериментов, которые зависят от той же библиотеки реализации NEAT. Вы познакомились со всеми необходимыми инструментами, чтобы начать эксперименты с нейроэволюцией. В следующей главе мы приступили к об- суждению эксперимента с решателем задачи XOR на основе базового алго- ритма NEAT. 12.1.3 Использование NEAT для оптимизации решения задачи XOR Это была первая глава, в которой мы начали экспериментировать с алгорит - мом NEAT. Мы сделали это, реализовав решатель одной из классических за- дач информатики. Мы начали с создания решателя для задачи XOR. Решатель задачи XOR – это компьютерный эксперимент в области обучения с подкреп- лением. Проблема XOR не может быть линейно разделена и, следовательно, нуждается в решателе, предлагающем нелинейный путь выполнения. Однако мы можем ввести нелинейность, внедряя скрытые слои в структуру нейросети. Вы убедились, что алгоритм NEAT идеально справляется с этой задачей благодаря присущей ему способности развивать нейросеть из очень простой или сложной топологии путем постепенной оптимизации. В эксперименте XOR мы начали с простой топологии нейросети, которая состояла из двух входных узлов и одного выходного узла. В ходе эксперимента была найдена подходящая топология нейросети решателя, и алгоритм ввел дополнитель- ный скрытый узел, представляющий нелинейность, как мы и ожидали. Кроме того, вы узнали, как определить подходящую функцию приспособ- ленности для управления эволюционным поиском и реализовать ее в скрипте Python. Мы уделили большое внимание описанию гиперпараметров, которые точно настраивают характеристики библиотеки NEAT для эксперимента XOR. В этой главе вы приобрели навыки, необходимые для реализации базовых решателей, и приготовились перейти к более сложным экспериментам. 12.1.4 Балансировка тележки с обратным маятником В четвертой главе вы продолжили эксперименты, связанные с классическими задачами информатики в области обучения с подкреплением. Глава началась с обсуждения того, как при помощи алгоритма NEAT оптимизировать нейро- сеть контроллера балансировки тележки с обратным маятником. Вы начали с балансировки одиночного маятника и рассмотрели все необходимые урав- нения движения, которые позволяют численно аппроксимировать физическое устройство реального мира. Вы узнали, как выполняется балансировка тележки при помощи двухпо- зиционного регулятора. Двухпозиционный регулятор – это уникальная систе- ма управления, которая прикладывает к объекту управляющие воздействия всегда с одинаковой силой, но в одном из двух противоположных направ- лений. Для управления двухпозиционным регулятором нейросеть должна постоянно считывать и анализировать состояние тележки с обратным ма-296  Заключительные замечания\n--- Страница 298 ---\nятником и генерировать соответствующие управляющие сигналы. Входные сигналы системы определяются горизонтальным положением тележки на до- рожке, ее линейной скоростью, текущим углом наклона маятника и угловой скоростью маятника. Выход системы представляет собой двоичный сигнал, указывающий направление воздействия, прикладываемого к тележке. Процесс нейроэволюции использует симулятор тележки с маятни- ком для реализации поиска решения методом проб и ошибок в стиле об- учения с подкреплением. Он поддерживает популяцию геномов, которые эволюцио нируют из поколения в поколение до тех пор, пока не будет най- ден успешный решатель. В ходе своей эволюции каждый организм в попу - ляции проверяется на приспособленность путем моделирования тележки с обратным маятником. В конце симуляции организм получает сигнал воз- награждения в виде количества временных шагов, в течение которых он мог сохранять баланс маятника в пределах дорожки. Полученный сигнал возна- граждения определяет приспособленность организма и решает его судьбу в процессе нейроэволюции. Затем вы узнали, как можно определить целевую функцию, используя упо- мянутый сигнал вознаграждения, и реализовать эту функцию на языке Python. Закончив первый эксперимент по балансировке маятника, мы перешли к модифицированной версии этого эксперимента. Модифицированная вер- сия состояла из двух маятников разной длины, соединенных с подвижной тележкой. Во втором случае необходимо было поддерживать баланс двух маятников одновременно. Этот эксперимент имел более сложную физику и нуждался в поиске гораздо более совершенного контроллера. Оба эксперимента, представленных в этой главе, подчеркнули важность поддержания сбалансированной популяции решателей с умеренным числом видов. Слишком большое видовое разнообразие популяции может препят - ствовать процессу нейроэволюции, уменьшая вероятность спаривания орга- низмов, принадлежащих к разным видам. Кроме того, принимая во внимание, что размер популяции фиксирован, чем больше видов в популяции, тем меньше численность каждого вида. Ма- лочисленные виды снижают вероятность возникновения полезных мутаций. С другой стороны, наличие отдельных видов позволяет нам поддерживать полезные мутации в каждой нише видообразования и использовать каждую мутацию в последующих поколениях. Таким образом, слишком низкое ви- довое разнообразие также вредит эволюции. В конце эксперимента по ба- лансировке тележки с маятником вы приобрели некоторые практические навыки, связанные с поддержанием разумного баланса числа видов путем настройки соответствующих гиперпараметров алгоритма NEAT (таких как порог совмес тимости видов). Другая существенная особенность процесса нейроэволюции, которая была подчеркнута в эксперименте по балансировке, связана с выбором правиль- ного начального числа для генератора псевдослучайных чисел, который управляет эволюционным процессом. Реализация метода нейроэволюции построена вокруг генератора псевдослучайных чисел, который определяет вероятность мутаций генома и скорость кроссовера. В генераторе псевдо- случайных чисел последовательность выходных значений определяется 12.1 Что вы узнали в этой книге  297\n--- Страница 299 ---\nтолько начальным значением, которое подается в генератор вначале. Ис- пользуя одно и то же начальное значение, можно создавать одинаковые по- следовательности псевдослучайных чисел. В результате эксперимента с поиском нейросети контроллера для баланси- ровки тележки мы обнаружили, что вероятность нахождения успешного ре- шения сильно зависит от начального значения генератора случайных чисел. Освоение экспериментов по балансировке маятников позволило вам под- готовиться к решению более сложных проблем, связанных с автономной на- вигацией, которые обсуждались в следующей главе. 12.1.5 Автономное прохождение лабиринта В пятой главе вы продолжили эксперименты с нейроэволюцией и попыта- лись создать решатель, который может найти выход из лабиринта. Прохож - дение лабиринта является увлекательной задачей, поскольку оно позволяет изучить новый метод поисковой оптимизации – поиск новизны. В главах 5 и 6 мы рассмотрели серию экспериментов по прохождению лабиринта, ис- пользуя целеориентированную оптимизацию поиска и метод оптимизации поиском новизны. В этой главе вы ознакомились с симулятором робота, оснащенного масси- вом датчиков, которые обнаруживают препятствия и отслеживают положение робота в лабиринте. Также мы обсудили, как реализовать целевую функцию для управления эволюционным процессом. Упомянутая реализация целевой функции рассчитывается как евклидово расстояние между конечным поло- жением робота и выходом из лабиринта. Используя симулятор лабиринта и выбранную целевую функцию, вы провели два эксперимента с простой и сложной конфигурациями лабирин- та. Результаты экспериментов дают представление о влиянии обманчиво- го ландшафта функции приспособленности на эффективность эволюцион- ного процесса. В областях локального оптимума нейроэволюция склонна производить меньше видов, что ограничивает ее способность исследовать новые решения. В крайних случаях это приводит к вырождению эволюци- онного процесса, и может случиться так, что во всей популяции останется только один вид. В то же время вы узнали, как избежать подобных неприятностей, настро- ив гиперпараметры NEAT, такие как коэффициент совместимости видов. Этот параметр контролирует степень влияния топологических различий в сравниваемых геномах на их совместимость для последующего скрещи- вания. В результате мы смогли увеличить видообразование и повысить раз- нообразие популяции. Это изменение оказало положительное влияние на поиск успешного решения, и мы смогли найти его для простой конфигу - рации лабиринта. Тем не менее сложная конфигурация лабиринта с более экстремальными локальными оптимумами не поддалась нашим попыткам найти удачный решатель с помощью целеориентированной функции при- способленности. Таким образом, вы пришли к необходимости узнать о методе оптимизации поиском новизны, который был разработан для преодоления ограничений целеориентированного поиска.298  Заключительные замечания\n--- Страница 300 ---\n12.1.6 Метод оптимизации поиском новизны Во всех экспериментах, предшествующих шестой главе, мы определяли це- левую функцию на основе метрики близости к конечной цели. Тем не менее задача прохождения лабиринта в общем случае не может быть решена с по- мощью измерения текущего расстояния до цели. Определенные конфигура- ции лабиринта могут создавать сильные локальные оптимумы, в которых за- стревает процесс поиска, ориентированный на близость к цели. Поэтому мы воспользовались практическим опытом, полученным при создании решателя задачи лабиринта в предыдущей главе, и вступили на путь создания более совершенного решателя. Для управления эволюцион- ным процессом новый решатель использовал метод оптимизации поиском новизны. Однако перед этим нам пришлось определить соответствующую метрику новизны для оценки степени новизны каждого решения в каждом поколении. Полученный с помощью этой метрики балл новизны служил по- казателем приспособленности, который присваивался геномам в популяции решателей. Таким образом, нам удалось интегрировать метрику новизны в стандартный процесс нейроэволюции. Метрика новизны должна показывать, насколько новое решение отлича- ется от решений, найденных в прошлых поколениях, и всех других решений текущего поколения. Существует два способа измерения новизны решения: генотипическая новизна является показателем внутренней новизны и показывает, как генотип текущего решения отличается от генотипов всех других найденных решений; поведенческая новизна показывает, как поведение текущего решения в проблемном пространстве отличается от поведения всех остальных решений. Для решения задачи лабиринта хорошим выбором является использова- ние оценки поведенческой новизны, потому что, в конце концов, мы заин- тересованы в достижении выхода из лабиринта, чему может способствовать определенный тип поведения. Кроме того, оценку новизны поведения гораз- до легче рассчитать, чем оценку новизны генотипа. Траектория движения конкретного решателя через лабиринт определяет его поведенческое пространство. Следовательно, мы можем оценить степень новизны, сравнивая векторы траекторий решателей. Численно оценка новизны может быть рассчитана путем вычисления ев- клидова расстояния между векторами траектории. Чтобы еще больше упрос- тить эту задачу, мы можем использовать для вычисления балла новизны только координаты последней точки траектории решателя. Определив метрику новизны, вы узнали, как реализовать ее в исходном коде на языке Python и интегрировать в симулятор лабиринта, созданный вами в главе 5. После этого повторили эксперименты из предыдущей главы и сравнили результаты. Эксперимент с решателем простого лабиринта продемонстрировал улуч- шение топологии полученной нейросети. Топология стала оптимальной и менее сложной. К сожалению, эксперимент со сложной конфигурацией лабиринта снова не привел к успешному решению, как это уже было в главе 5. Похоже, сбой 12.1 Что вы узнали в этой книге  299\n--- Страница 301 ---\nвызван неэффективностью конкретной реализации алгоритма NEAT, исполь- зованной в эксперименте. Я реализовал алгоритм NEAT на языке Go, чтобы он легко находил решение задачи сложного лабиринта, используя оптимиза- цию поиском новизны. Вы можете найти исходный код на GitHub по адресу https://github.com/yaricom/goNEAT_NS. В главе 6 вы узнали, что метод оптимизации поиском новизны позволя- ет найти решение, даже если функция приспособленности имеет обманчи- вый ландшафт со многими локальными ловушками оптимальности, разбро- санными внутри. Вы узнали, что шаги, из которых состоит путь к решению, не всегда очевидны. Иногда нужно сделать шаг назад, чтобы найти правиль- ный путь. Это основная идея метода поиска новизны. Он пытается найти ре- шение, полностью игнорируя близость к конечной цели и поощряя новизну каждого промежуточного решения, которое встречается на пути. В этой главе вы познакомились со стандартным алгоритмом NEAT и под- готовились к экспериментам с его более продвинутыми расширениями. 12.1.7 Зрительное различение с NEAT на основе гиперкуба Седьмая глава была первой из четырех глав, в которых мы обсуждали передо- вые методы нейроэволюции. В этой главе вы узнали о схеме косвенного коди- рования генома, в которой для кодирования топологий нейросетей с большим фенотипом используется CPPN. Схема кодирования CPPN, представленная расширением NEAT, называется HyperNEAT. Это расширение построено вокруг концепции субстрата связности, который представляет топологию нейросети. В то же время связи между узлами субстрата представлены точками внутри четырехмерного гиперкуба. В методе HyperNEAT топология CPPN эволюцио- нирует в соответствии с алгоритмом NEAT. Мы уже обсуждали особенности HyperNEAT, поэтому пропустили остальные детали HyperNEAT для краткости. В этой главе вы встретили интересную задачу зрительного различения, которая подчеркивает способность алгоритма HyperNEAT различать шабло- ны в поле зрения. Вы узнали, что метод HyperNEAT может найти успешный дискриминатор зрительных образов благодаря присущей ему способности повторно использовать успешные шаблоны связей, найденные в субстра- те, который кодирует фенотип нейросети решателя. Это стало возможным благодаря CPPN, которая способна находить правильную стратегию переда- чи сигналов от входных узлов (восприятие изображения) к выходным узлам (представление результатов). Вы узнали, как выбрать правильную геометрию субстрата, чтобы эффек - тивно использовать возможности CPPN для поиска геометрических зако- номерностей. После этого у вас была возможность применить полученные знания на практике, реализовав зрительный дискриминатор, обученный с использованием алгоритма HyperNEAT. Кроме того, завершив эксперимент со зрительным дискриминатором, вы смогли проверить эффективность схемы косвенного кодирования. Эффек - тивность кодирования вычислялась путем сравнения топологии, найденной CPPN, с максимально возможным количеством соединений в различающей нейросети. Результаты эксперимента со зрительным дискриминатором оказа- лись довольно впечатляющими. Благодаря кодированию схемы связей среди 300  Заключительные замечания\n--- Страница 302 ---\n14 641 возможной связи субстрата нам удалось достичь степени сжатия инфор- мации 0,11 %, причем у нас осталось только 16 связей между 10 узлами CPPN. Задачи компьютерного зрения предъявляют высокие требования к архи- тектуре нейросети из-за высокой размерности входного сигнала. Поэтому в главе 8 мы приступили к изучению другого класса задач зрительного рас- познавания. 12.1.8 Метод ES-HyperNEAT и задача сетчатки В восьмой главе вы узнали, как выбрать конфигурацию субстрата, которая луч- ше всего подходит для конкретной проблемной области. Однако выбор кон- фигурации не всегда очевиден. Неправильно выбранная конфигурация может существенно повлиять на производительность процесса обучения. В результа- те процесс нейроэволюции может не найти успешное решение. Кроме того, конкретные особенности конфигурации субстрата обнаруживаются только во время процесса обучения и не могут быть известны заранее. Проблема с поиском подходящей конфигурации субстрата была решена с помощью метода ES-HyperNEAT. В этой главе вы узнали, что процесс ней- роэволюции может автоматически дорабатывать конфигурацию субстрата в ходе эволюции CPPN-связей. Вы познакомились с концепцией структуры данных в виде квадродерева, которая позволяет совершать эффективный обход топологии субстрата и обнаруживать области с высокой плотностью информации. Оказывается, полезно автоматически размещать новые узлы в этих областях для создания более точных паттернов связей, которые описы- вают скрытые закономерности, существующие в реальном мире. Ознакомившись с деталями работы алгоритма ES-HyperNEAT, вы узнали, как применять его для решения задачи визуального распознавания, извест - ной как проблема сетчатки. В этой задаче процесс нейроэволюции должен найти решателя, который способен распознавать подходящие изображения одновременно в двух отдельных полях зрения. Иными словами, нейросеть зрительного детектора должна решить, подходят ли изображения, представ- ленные в правом и левом полях зрения, для каждого поля. Решение этой зада- чи может быть найдено путем введения модульной архитектуры в топологию нейросети детектора. В такой конфигурации каждый модуль нейросети отве- чает за распознавание образов только на соответствующей стороне сетчатки. В этой главе мы реализовали успешное решение задачи сетчатки, исполь- зуя метод ES-HyperNEAT, и смогли визуально доказать, что полученная то- пология нейросети детектора содержит модульные структуры. Кроме того, из результатов эксперимента вы узнали, что найденная структура нейросети детектора имеет почти оптимальную сложность. Этот эксперимент еще раз продемонстрировал потенциал нейроэволюции в поиске эффективных ре- шений методом постепенного усложнения. Во всех экспериментах, включая описанный в этой главе, использовалась особая форма функции приспособленности, которая была заранее определе- на до начала экспериментов. Тем не менее было бы интересно изучить, как изменяется производительность алгоритма нейроэволюции, если функция приспособленности развивается вместе с решением, которое она пытается оптимизировать. 12.1 Что вы узнали в этой книге  301\n--- Страница 303 ---\n12.1.9 Коэволюция и метод SAFE В девятой главе вы узнали, что стратегия коэволюции широко распространена в природе и может быть перенесена в область нейроэволюции. Мы перечисли- ли наиболее распространенные стратегии коэволюции, которые можно найти в природе: мутуализм, конкуренция (хищничество или паразитизм) и ком- менсализм. В нашем эксперименте мы исследовали комменсалистический тип эволюции, который можно определить следующим образом: представи- тели одного вида получают выгоды, не причиняя вреда и не принося пользы другим сосуществующим видам. Зная о стратегиях эволюции в мире природы, вам было проще понять концепции, лежащие в основе метода SAFE. Название метода SAFE (solution and fitness evolution, коэволюции решателя и приспособленности) говорит о том, что у нас есть две совместно развивающиеся популяции: совокуп- ность потенциальных решений и совокупность кандидатов на роль функции приспособленности. В каждом поколении эволюции мы оцениваем каждое потенциальное решение при помощи всех кандидатов на роль функции при- способленности и выбираем лучший показатель приспособленности, кото- рый рассматривается как пригодность решения для кодирования генома. В то же время мы развиваем комменсалистическую совокупность кандида- тов на роль функции приспособленности, используя метод поиска новизны. Поиск новизны использует геномную новизну каждого генома в популяции в качестве метрики для оценки индивидуальной приспособленности. В этой главе вы узнали, как реализовать модифицированный эксперимент по прохождению лабиринтов на основе метода SAFE для проверки эффектив- ности стратегии коэволюции. Кроме того, вы узнали, как определить целевую функцию, чтобы направлять эволюцию популяции потенциальных решений. Эта целевая функция включает в себя две метрики приспособленности: пер- вая – это расстояние до выхода из лабиринта, а вторая – поведенческая новизна найденного решения. Эти метрики объединяются с использованием коэффи- циентов, найденных популяцией кандидатов на функцию приспособленности. Как и во всех предыдущих главах, вы продолжали совершенствовать свои навыки работы с Python, реализуя метод SAFE с использованием библиотеки MultiNEAT. В следующей главе мы продолжили изучение еще более продви- нутых методов, что позволило использовать нейроэволюцию для обучения игровых агентов Atari. 12.1.10 Глубокая нейроэволюция В десятой главе вы познакомились с концепцией глубокой нейроэволюции, ко- торую можно использовать для обучения глубоких искусственных нейронных сетей (DNN). Вы узнали, как глубокая нейроэволюция может быть использова- на для обучения игровых агентов Atari с использованием алгоритма глубокого подкрепления. Мы начали с обсуждения основных концепций обучения с подкреплением, уделив особое внимание популярному алгоритму Q-обучения, который яв- ляется одной из классических реализаций обучения с подкреплением. После этого вы узнали, как DNN можно использовать для аппроксимации функции 302  Заключительные замечания\n--- Страница 304 ---\nQ-значений для сложных задач, которые не могут быть аппроксимированы простой матрицей действий с Q-значениями. Далее мы обсудили, как можно найти обучаемые параметры DNN при помощи нейроэволюции. Вы узнали, что нейроэволюция развивает DNN для аппроксимации Q-значений. В ре- зультате мы можем обучить DNN, не используя трудоемкий способ обратного распространения ошибки, который является обычным в традиционных ме- тодах обучения DNN. Узнав о глубоком обучении с подкреплением, вы перешли к применению полученных знаний на практике, разработав агента-решателя для прохожде- ния игр Atari. Чтобы агент научился играть в игру Atari, ему нужно прочитать пиксели игрового экрана и определить текущее состояние игры. После этого, используя извлеченное игровое состояние, агент должен выбрать соответству - ющее действие, которое будет выполнено в игровой среде. Конечная цель аген- та – максимизировать окончательное вознаграждение в конце определенного игрового эпизода. Таким образом, у нас получается классическое обучение ме- тодом проб и ошибок, в котором и заключается суть обучения с подкреплением. Как мы уже упоминали, игровой агент должен анализировать пиксели игрового экрана. Лучший способ сделать это – использовать сверточную нейронную сеть (convolutional neural network, CNN) для обработки входных данных, полученных с игрового экрана. В этой главе мы обсудили основы архитектуры CNN и ее интеграцию с игровым агентом. Вы узнали, как реали- зовать CNN в Python, используя популярный фреймворк TensorFlow. Кроме того, вы узнали об уникальной схеме кодирования генома, которая была разработана специально для задач, связанных с глубокой нейроэволю- цией. Эта схема позволяет нам кодировать фенотип нейросети с миллиона- ми обучаемых параметров. Предложенная схема использует начальные числа генератора псевдослучайных чисел для кодирования весов связей нейросети. В этой схеме кодирования геном представлен в виде списка случайных на- чальных чисел. Каждое начальное число используется последовательно для генерации всех весов связей при помощи генератора псевдослучайных чисел. Разобравшись с реализацией кодирования генома, мы перешли к экспери- менту, целью которого было создание агента, способного играть в игру Atari Frostbite. Кроме того, вы узнали, как использовать современный графический процессор для ускорения вычислений в процессе обучения. В конце этой гла- вы вы познакомились с продвинутым инструментом визуализации (VINE), который позволяет изучать результаты экспериментов по нейроэволюции. Этой главой мы закончили наше краткое знакомство с наиболее популяр- ными методами нейроэволюции, существовавшими на момент написания книги. Тем не менее есть еще много вещей, которые заслуживают вашего внимания в быстро растущей области прикладного искусственного интел- лекта и методов нейроэволюции.",
          "debug": {
            "start_page": 294,
            "end_page": 304
          }
        },
        {
          "name": "12.2 Куда двигаться дальше 303",
          "content": "--- Страница 304 --- (продолжение)\n12.2 куДа Двигать Ся Дальше Я надеюсь, что ваше путешествие по методам нейроэволюции, которые были представлены в этой книге, было приятным и полезным. Я сделал все возмож - ное, чтобы представить вам самые последние достижения в области нейроэво- 12.2 Куда двигаться дальше  303\n12.2 куДа Двигать Ся Дальше Я надеюсь, что ваше путешествие по методам нейроэволюции, которые были представлены в этой книге, было приятным и полезным. Я сделал все возмож - ное, чтобы представить вам самые последние достижения в области нейроэво- 12.2 Куда двигаться дальше  303\n--- Страница 305 ---\nлюции. Однако эта область прикладной информатики стремительно развива- ется, и почти каждый месяц исследователи объявляют о новых достижениях. В университетах, а также в корпорациях по всему миру существует множест - во лабораторий, работающих над применением методов нейроэволюции для решения задач, которые выходят за рамки традиционных алгоритмов глубо- кого обучения. Я надеюсь также, что вам понравились методы нейроэволюции, которые мы обсуждали, и вы готовы применить их в своей работе и экспериментах. Тем не менее вам необходимо продолжить самообразование, чтобы идти в ногу с последними достижениями в этой области. Дальше я расскажу про несколько мест, где вы можете продолжить свое образование. 12.2.1 Uber AI Labs В основе исследовательского центра Uber AI Labs лежит стартап Geometric Intelligence, основанный совместно с Кеннетом О. Стэнли – одним из выдаю- щихся пионеров в области нейроэволюции. Он является автором алгоритма NEAT, который мы часто использовали в этой книге. Вы можете следить за работами Uber AI Labs на сайте https://eng.uber.com/category/articles/ai/. 12.2.2 alife.org Международное общество искусственной жизни (international society for ar- tificial life, ISAL) – это солидное сообщество исследователей и энтузиастов со всего мира, которые вовлечены в научно-исследовательскую деятельность, связанную с искусственной жизнью. Генетические алгоритмы и нейроэво- люция также входят в сферу интересов этого общества. ISAL издает журнал Artificial Life и спонсирует различные конференции. Вы можете узнать боль- ше о деятельности ISAL на сайте http://alife.org. 12.2.3 Открытая эволюция в Reddit Концепция открытой эволюции напрямую связана с генетическими алго- ритмами в целом и нейроэволюцией в частности. Открытая эволюция пред- полагает наличие эволюционного процесса, который не связан какой-либо конкретной целью. Этот подход вдохновлен естественной эволюцией био- логических организмов, которые произвели нас, людей. Существует специ- альный сабреддит1, где все желающие обсуждают исследования по открытой эволюции. Вы можете найти его по адресу https://www.reddit.com/r/oee/. 12.2.4 Каталог программного обеспечения NEAT Университет Центральной Флориды ведет список программных библиотек, которые реализуют алгоритм NEAT и его расширения. Модератором програм- мы является Кеннет О. Стэнли, автор алгоритма NEAT. Моя реализация алго- ритмов NEAT и поиска новизны на языке Go также присутствует в этом катало- ге. Вы можете найти каталог по адресу http://eplex.cs.ucf.edu/neat_software/. 1 Раздел социально-новостного сайта reddit.com, посвященный отдельной теме. – Прим. перев.304  Заключительные замечания\n--- Страница 306 ---\n12.2.5 arXiv.org arXiv.org – это известный сервис, публикующий препринты статей по многим отраслям науки. Как правило, это отличный источник новейшей информа- ции в области компьютерных наук. Вы можете искать в нем документы, свя- занные с нейроэволюцией, используя следующий поисковый запрос: http:// search.arxiv.org:8081/?query=neuroevolution&in=grp_cs. 12.2.6 Оригинальная публикация про алгоритм NEAT Оригинальная диссертация, написанная Кеннетом О. Стэнли с описанием алго- ритма NEAT, очень полезна для чтения и рекомендуется всем, кто интересуется нейроэволюцией. Она доступна по адресу http://nn.cs.utexas.edu/downloads/ papers/stanley.phd04.pdf.",
          "debug": {
            "start_page": 304,
            "end_page": 306
          }
        },
        {
          "name": "12.3 Заключение 305",
          "content": "--- Страница 306 --- (продолжение)\n12.3 заключение В этой главе кратко изложено то, что вы узнали в данной книге. Вы также узнали о местах, где можно искать дальнейшие идеи и продолжать самообразование. Я счастлив жить в эпоху, когда будущее становится реальностью настолько быстро, что мы совершенно не замечаем огромных изменений, которые про- исходят в нашей жизни. Человечество стремительно движется по пути к освое- нию чудес редактирования генов и синтетической биологии. Мы продолжаем проникать в тайны человеческого мозга, что открывает путь к окончательному пониманию сути сознания. Сложнейшие эксперименты в области космологии приближают нас к самым первым мгновениям существования Вселенной. Мы создали усовершенствованный математический аппарат, который по- зволяет описывать такие загадочные объекты, как нейтрино, которое на сво- ем пути может стать электроном, а затем снова нейтрино. Как говорил Артур Кларк, наши технологические достижения неотличимы от магии. Жизнь – это ощущение красоты сущего. Держите свой ум острым и всегда будьте любопытным. Мы стоим на пороге великих событий, когда исследова- ния искусственного сознания породят эволюцию новых форм жизни. И кто знает – может быть, это предстоит сделать именно вам. Спасибо, мой дорогой читатель, за потраченное время и усилия. Я с нетер- пением жду встречи с тем, что вы создадите, используя знания, полученные из этой книги. 12.3 Заключение  305\n12.3 заключение В этой главе кратко изложено то, что вы узнали в данной книге. Вы также узнали о местах, где можно искать дальнейшие идеи и продолжать самообразование. Я счастлив жить в эпоху, когда будущее становится реальностью настолько быстро, что мы совершенно не замечаем огромных изменений, которые про- исходят в нашей жизни. Человечество стремительно движется по пути к освое- нию чудес редактирования генов и синтетической биологии. Мы продолжаем проникать в тайны человеческого мозга, что открывает путь к окончательному пониманию сути сознания. Сложнейшие эксперименты в области космологии приближают нас к самым первым мгновениям существования Вселенной. Мы создали усовершенствованный математический аппарат, который по- зволяет описывать такие загадочные объекты, как нейтрино, которое на сво- ем пути может стать электроном, а затем снова нейтрино. Как говорил Артур Кларк, наши технологические достижения неотличимы от магии. Жизнь – это ощущение красоты сущего. Держите свой ум острым и всегда будьте любопытным. Мы стоим на пороге великих событий, когда исследова- ния искусственного сознания породят эволюцию новых форм жизни. И кто знает – может быть, это предстоит сделать именно вам. Спасибо, мой дорогой читатель, за потраченное время и усилия. Я с нетер- пением жду встречи с тем, что вы создадите, используя знания, полученные из этой книги. 12.3 Заключение  305\n--- Страница 307 ---\nПредметный указатель A Алгоритм генетический 53, 253 В Видообразование 32, 294 Виртуальная среда Python 56Воркер 265Выпрямленный линейный блок 256 Г Ген связей 29узлов 29 Генетический оператор 23 кроссовер 293кроссовер (рекомбинация) 23мутация 23, 293 Геном косвенное кодирование 27прямое кодирование 25 Гиперкуб 36Глубокое обучение с подкреплением 53, 253 Д Датчик дальномерный 120, 122радарный 120, 122 поле обзора 120 Двухпозиционный регулятор 88, 296Дерево квадрантов. См. Квадродерево Достоверность 289 Е Евклидово расстояние 284 З Задача зрительного различения 180модульной сетчатки 203прохождения лабиринта 118 сетчатки 208 Зрительное поле 180И Изолированная виртуальная среда 295 Исключающее ИЛИ 64 Искусственный интеллект 21 К Квадродерево 38, 205 порог деления 207 порог дисперсии 207 Кодирование генома косвенное 293 прямое 293 Комплексное расширение 28 Коэволюция 27, 229, 302 комменсализм 27, 230 конкурентная 27, 230 мутуализм 27, 230 Коэффициент истинно положительных результатов 288 ложноположительных результатов 288 Л Ловушка локального максимума 42 Локально оптимальный тупик 118 Локальный максимум 64 Локальный оптимум 118 М Матрица состояний 252Метод Q-обучения 252глубоких Q-сетей 253коэволюции решателя и приспособленности 229 обратного распространения ошибки 251 поиска новизны 43, 128, 145, 295 Метрика новизны 43 Многослойный перцептрон 64\n--- Страница 308 ---\nН Нейронная сеть зрительный дискриминатор 180, 182 искусственная 16, 64 глубокая 17, 53, 251 обучение с подкреплением 252 различающая способность 288 сверточная 255, 303связь 22 вес 22 с фиксированной топологией 25 узел 22 Н Нейроэволюция 16 визуальный контроль 251 с развитием топлогии в гиперкубе 179 с развитием топологии 26 Новизна генотипическая 299поведенческая 299 О Обратный маятник 86 балансировщик 86 Обучающая среда Atari 253 Отклик 287Открытая эволюция 304Отрицательное давление 32 Оценка новизны 153целеориентированной приспособленности 153 Оценка F1 287 П Площадь под кривой 288 Поведенческая разница 44Подготовка данных масштабирование 281нормализация 281стандартизация 280 Поэлементное расстояние 152Признаки 280Принцип локальности 28 Приспособленность 42 Пространство поведения 43 Р Рабочая характеристика приемника 288Разреженность 43 Решатель 23, 42 задачи XOR 64 С Сенсориум 33 Система контроля версий 290 Среднеквадратичная ошибка 283 Субстрат 179 двумерная сетка 180 круговой 180 начальная конфигурация 219 развиваемый 203 сэндвич пространства состояний 180 трехмерная сетка 180 Т Точка новизны 242Точность 287 У Универсальный аппроксиматор 22Управляемое избегание 86 Уравнение движения 86 Ф Функция истинности 252приспособленности 42 целеориентированная 118 целевая 42 целеориентированная 127 Ц Целевое поле 180 A Area under curve, AUC 288 Artificial intellect, AI 21 Artificial neural network, ANN 21, 64 Atari learning environment, ALE 253 C Compositional pattern producing network, CPPN 17, 27, 177, 294 Convolutional neural network, CNN 255 D Deep neural networks, DNN 53, 251 Deep Q-network, DQN 253 Deep reinforcement learning, RL 53 Предметный указатель  307\n--- Страница 309 ---\nE Evolvable substrate, ES 204 F False positive rate, FPR 288 G Genetic algorithm, GA 53, 253 H Hypercube-based neuroevolution of augmenting topologies, HyperNEAT 27, 179 M Multilayer perceptron, MLP 64 N Neuroevolution of augmenting topologies, NEAT 26 Novelty search, NS 128, 145, 295Q Q-матрица. См. Матрица состояний R Receiver operating characteristic, ROC 288 Rectified linear unit, ReLU 256 Reinforcement learning, RL 252 S Solution and fitness evolution, SAFE 27, 229 T True positive rate, TPR 288 V Version control system, VCS 290 Visual inspector for neuroevolution, VINE 53, 251308  Предметный указатель\n--- Страница 310 ---\nКниги издательства «ДМК Пресс» можно заказать в торгово-издательском холдинге «Планета Альянс» наложенным платежом, выслав открытку или письмо по почтовому адресу: 115487, г. Москва, 2-й Нагатинский пр-д, д. 6А. При оформлении заказа следует указать адрес (полностью), по которому должны быть высланы книги; фамилию, имя и отчество получателя. Желательно также указать свой телефон и электронный адрес. Эти книги вы можете заказать и в интернет-магазине: www.a-planeta.ru. Оптовые закупки: тел. (499) 782-38-89. Электронный адрес: books@alians-kniga.ru. Ярослав Омельяненко Эволюционные нейросети на языке Python Главный редактор Мовчан Д. А. dmkpress@gmail.com Перевод Яценков В. С. Корректор Синяева Г. И. Верстка Луценко С. В. Дизайн обложки Мовчан А. Г. Формат 70×100 1/16. Гарнитура «PT Serif». Печать цифровая. Усл. печ. л. 25,19. Тираж 200 экз. Веб-сайт издательства: www.dmkpress.com Отпечатано в ПАО «Т8 Издательские Технологии» 109316, Москва, Волгоградский проспект, д. 42, корпус 5.",
          "debug": {
            "start_page": 306,
            "end_page": 310
          }
        }
      ]
    }
  ]
}
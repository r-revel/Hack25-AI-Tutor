{
  "title": "Глубокое обучение [2018] Гудфеллоу Я., Бенджио И.",
  "chapters": [

    {
      "name": "Глава 1. Введение 21",
      "content": "--- Страница 22 --- (продолжение)\nГлава 1 Введение Изобретатели давно мечтали создать думающую машину. Эти мечты восходят еще к Древней Греции. Персонажей мифов – Пигмалиона, Дедала, Гефеста – можно было бы назвать легендарными изобретателями, а их творения – Галатею, Талоса и Пандо- ру – искусственной жизнью (Ovid and Martin, 2004; Sparkes, 1996; Tandy, 1997). Впервые задумавшись о программируемых вычислительных машинах, человек за- дался вопросом, смогут ли они стать разумными, – за сотню с лишним лет до построе- ния компьютера (Lovelace, 1842). Сегодня искусственный интеллект (ИИ) – бур- но развивающаяся дисциплина, имеющая многочисленные приложения. Мы хотим иметь интеллектуальные программы, которые могли бы автоматизировать рутинный труд, понимали речь и изображения, ставили медицинские диагнозы и поддерживали научные исследования. Когда наука об искусственном интеллекте только зарождалась, были быстро ис- следованы и решены некоторые задачи, трудные для человека, но относительно прос- тые для компьютеров – описываемые с помощью списка формальных математиче- ских правил. Настоящим испытанием для искусственного интеллекта стали задачи, которые легко решаются человеком, но с трудом поддаются формализации, – задачи, которые мы решаем интуитивно, как бы автоматически: распознавание устной речи или лиц на картинке. Эта книга посвящена решению таких интуитивных задач. Цель заключается в том, чтобы компьютер мог учиться на опыте и понимать мир в терминах иерархии по- нятий, каждое из которых определено через более простые понятия. Благодаря при-обретению знаний опытным путем этот подход позволяет исключить этап формаль-ного описания человеком всех необходимых компьютеру знаний. Иерархическая организация дает компьютеру возможность учиться более сложным понятиям путем построения их из более простых. Граф, описывающий эту иерархию, будет глубо-ким – содержащим много уровней. Поэтому такой подход к ИИ называется глубоким обучением. Ранние успехи ИИ в большинстве своем были достигнуты в относительно сте- рильной формальной среде, где от компьютера не требовались обширные знания о мире. Взять, к примеру, созданную IBM шахматную программу Deep Blue, которая в 1997 году обыграла чемпиона мира Гарри Каспарова (Hsu, 2002). Шахматы – это очень простой мир, состоящий всего из 64 клеток и 32 фигур, которые могут ходить лишь строго определенным образом. Разработка успешной стратегии игры в шахма- ты – огромное достижение, но трудность задачи – не в описании множества фигур и допустимых ходов на языке, понятном компьютеру. Для полного описания игры дос таточно очень короткого списка формальных правил, который заранее составля- ется программистом.\nГлава 1 Введение Изобретатели давно мечтали создать думающую машину. Эти мечты восходят еще к Древней Греции. Персонажей мифов – Пигмалиона, Дедала, Гефеста – можно было бы назвать легендарными изобретателями, а их творения – Галатею, Талоса и Пандо- ру – искусственной жизнью (Ovid and Martin, 2004; Sparkes, 1996; Tandy, 1997). Впервые задумавшись о программируемых вычислительных машинах, человек за- дался вопросом, смогут ли они стать разумными, – за сотню с лишним лет до построе- ния компьютера (Lovelace, 1842). Сегодня искусственный интеллект (ИИ) – бур- но развивающаяся дисциплина, имеющая многочисленные приложения. Мы хотим иметь интеллектуальные программы, которые могли бы автоматизировать рутинный труд, понимали речь и изображения, ставили медицинские диагнозы и поддерживали научные исследования. Когда наука об искусственном интеллекте только зарождалась, были быстро ис- следованы и решены некоторые задачи, трудные для человека, но относительно прос- тые для компьютеров – описываемые с помощью списка формальных математиче- ских правил. Настоящим испытанием для искусственного интеллекта стали задачи, которые легко решаются человеком, но с трудом поддаются формализации, – задачи, которые мы решаем интуитивно, как бы автоматически: распознавание устной речи или лиц на картинке. Эта книга посвящена решению таких интуитивных задач. Цель заключается в том, чтобы компьютер мог учиться на опыте и понимать мир в терминах иерархии по- нятий, каждое из которых определено через более простые понятия. Благодаря при-обретению знаний опытным путем этот подход позволяет исключить этап формаль-ного описания человеком всех необходимых компьютеру знаний. Иерархическая организация дает компьютеру возможность учиться более сложным понятиям путем построения их из более простых. Граф, описывающий эту иерархию, будет глубо-ким – содержащим много уровней. Поэтому такой подход к ИИ называется глубоким обучением. Ранние успехи ИИ в большинстве своем были достигнуты в относительно сте- рильной формальной среде, где от компьютера не требовались обширные знания о мире. Взять, к примеру, созданную IBM шахматную программу Deep Blue, которая в 1997 году обыграла чемпиона мира Гарри Каспарова (Hsu, 2002). Шахматы – это очень простой мир, состоящий всего из 64 клеток и 32 фигур, которые могут ходить лишь строго определенным образом. Разработка успешной стратегии игры в шахма- ты – огромное достижение, но трудность задачи – не в описании множества фигур и допустимых ходов на языке, понятном компьютеру. Для полного описания игры дос таточно очень короткого списка формальных правил, который заранее составля- ется программистом.\n--- Страница 23 ---\n22  Введение Забавно, что абстрактные, формально поставленные задачи, требующие значи- тельных умственных усилий от человека, для компьютера как раз наиболее просты. Компьютеры давно уже способны обыграть в шахматы сильнейших гроссмейстеров, но лишь в последние годы стали сопоставимы с человеком в части распознавания объектов или речи. В повседневной жизни человеку необходим гигантский объем знаний о мире. Знания эти субъективны и представлены на интуитивном уровне, поэтому выразить их формально затруднительно. Но чтобы вести себя «разумно», компьютерам нужны такие же знания. Одна из основных проблем искусственного интеллекта – как заложить эти неформальные знания в компьютер. Авторы нескольких проектов в области ИИ пытались представить знания о мире с помощью формальных языков. Компьютер может автоматически рассуждать о предложениях на таком языке, применяя правила логического вывода. В основе та- ких подходов лежит база знаний. Ни один из этих проектов не привел к существен- ному успеху. Одним из самых известных был проект Cyc (Lenat and Guha, 1989) – машина логического вывода и база утверждений на языке CycL. За ввод утверждений отвечал штат учителей-людей. Процесс оказывается крайне громоздким. Люди изо всех сил пытаются придумать формальные правила, достаточно сложные для точного описания мира. Например, Cyc не сумел понять рассказ о человеке по имени Фред, который бреется по утрам (Linde, 1992). Его машина вывода обнаружила в рассказе противоречие: он знал, что в людях нет электрических деталей, но, поскольку Фред держал электрическую бритву, система решила, что объект «БреющийсяФред» со-держит электрические детали. И задала вопрос: является ли Фред по-прежнему че- ловеком, когда бреется. Трудности, с которыми сталкиваются системы, опирающиеся на «зашитые в код» знания, наводят на мысль, что система с искусственным интеллектом должна уметь самостоятельно накапливать знания, отыскивая закономерности в исходных данных. Это умение называется машинным обучением. С появлением машинного обучения перед компьютерами открылась возможность подступиться к задачам, требующим знаний о реальном мире, и принимать решения, кажущиеся субъективными. Прос- той алгоритм машинного обучения – логистическая регрессия – может решить, следует ли рекомендовать кесарево сечение (Mor-Y osef et al., 1990). Другой простой алгоритм – наивный байесовский классификатор – умеет отделять нормальную электронную почту от спама. Качество этих простых алгоритмов сильно зависит от представления исходных данных. Так, система ИИ, выдающая рекомендации о показанности кесарева сече- ния, не осматривает пациента. Вместо этого врач сообщает системе относящуюся к делу информацию, например о наличии или отсутствии рубца на матке. Каждый отдельный элемент информации, включаемый в представление о пациенте, называ- ется признаком. Алгоритм логистической регрессии анализирует, как признаки па- циента коррелируют с различными результатами. Но он не может никаким образом повлиять на определение признаков. Если алгоритму предложить снимок МРТ, а не формализованные врачом сведения, то он не сможет выдать полезную рекоменда-цию. Отдельные пиксели снимка практически не коррелированы с осложнениями, которые могут возникнуть во время родов. Эта зависимость от представления является общим явлением, проявляющимся как в информатике, так и в повседневной жизни. Если говорить об информатике, то такие операции, как поиск в коллекции данных, будут производиться многократно\n--- Страница 24 ---\nСтохастическая максимизация правдоподобия  23 быстрее, если коллекция структурирована и подходящим образом индексирована. Люди же легко выполняют арифметические операции с числами, записанными араб- скими цифрами, но тратят куда больше времени, если используются римские цифры. Неудивительно, что выбор представления оказывает огромное влияние на качество и производительность алгоритмов машинного обучения. На рис. 1.1 приведен прос- той наглядный пример. Многие задачи ИИ можно решить, если правильно подобрать признаки, а затем предъявить их алгоритму машинного обучения. Например, в задаче идентифика- ции говорящего по звукам речи полезным признаком является речевой тракт. Он позволяет с большой точностью определить, кто говорит: мужчина, женщина или ребенок. Но во многих задачах нелегко понять, какие признаки выделять. Допустим, к при- меру, что мы пишем программу обнаружения автомобилей на фотографиях. Мы знаем, что у автомобилей есть колеса, поэтому могли бы счесть присутствие колеса признаком. К сожалению, на уровне пикселей трудно описать, как выглядит колесо. Колесо имеет простую геометрическую форму, но распознавание его изображения может быть осложнено отбрасыванием теней, блеском солнца на металлических де-талях автомобиля, наличием щитка, защищающего колесо от грязи, или объектов на переднем плане, частично загораживающих колесо, и т. д. xДекартовы координаты rПолярные координатыy θ Рис. 1.1  Пример различных представлений: предположим, что требу- ется разделить две категории данных, проведя прямую на диаграмме рас-сеяния. На левом рисунке данные представлены в декартовых координа- тах, и задача неразрешима. На правом рисунке те же данные представлены в полярных координатах и разделяются вертикальной прямой (рисунок подготовлен совместно с Дэвидом Уорд-Фарли) Одно из решений этой проблемы – воспользоваться машинным обучением не только для того, чтобы найти отображение представления на результат, но и чтобы определить само представление. Такой подход называется обучением представле- ний. На представлениях, полученных в ходе обучения, часто удается добиться гораз- до более высокого качества, чем на представлениях, созданных вручную. К тому же это позволяет системам ИИ быстро адаптироваться к новым задачам при минималь-\n--- Страница 25 ---\n24  Введение ном вмешательстве человека. Для простой задачи алгоритм обучения представлений может найти хороший набор признаков за несколько минут, для сложных – за время от нескольких часов до нескольких месяцев. Проектирование признаков вручную для сложной задачи требует много времени и труда, на это могут уйти десятилетия рабо- ты всего сообщества исследователей. Квинтэссенцией алгоритма обучения представлений является автокодировщик. Это комбинация функции кодирования, которая преобразует входные данные в дру- гое представление, и функции декодирования, которая преобразует новое представ- ление в исходный формат. Обучение автокодировщиков устроено так, чтобы при кодировании и обратном декодировании сохранялось максимально много инфор- мации, но чтобы при этом новое представление обладало различными полезными свойствами. Различные автокодировщики ориентированы на получение различных свойств. При проектировании признаков или алгоритмов обучения признаков нашей целью обычно является выделение факторов вариативности, которые объясняют наблюдаемые данные. В этом контексте слово «фактор» означает просто источник влияния, а не «сомножитель». Зачастую факторы – это величины, не наблюдаемые непосредственно. Это могут быть ненаблюдаемые объекты или силы в физическом мире, оказывающие влияние на наблюдаемые величины. Это могут быть также умо-зрительные конструкции, дающие полезные упрощающие объяснения или логически выведенные причины наблюдаемых данных. Их можно представлять себе как кон-цепции или абстракции, помогающие извлечь смысл из данных, характеризуемых высокой вариативностью. В случае анализа записи речи к факторам вариативности относятся возраст и пол говорящего, акцент и произносимые слова. В случае анализа изображения автомобиля факторами вариативности являются положение машины, ее цвет, а также высота солнца над горизонтом и его яркость. Источник трудностей в целом ряде практических приложений искусственного интеллекта – тот факт, что многие факторы вариативности оказывают влияние аб- солютно на все данные, доступные нашему наблюдению. Отдельные пиксели изобра-жения красного автомобиля ночью могут быть очень близки к черному цвету. Форма силуэта автомобиля зависит от угла зрения. В большинстве приложений требуется разделить факторы вариативности и отбросить те, что нам не интересны. Разумеется, может оказаться очень трудно выделить такие высокоуровневые абст- рактные признаки из исходных данных. Многие факторы вариативности, к примеру акцент говорящего, можно идентифицировать, только если наличествует очень глу-бокое, приближающееся к человеческому понимание природы данных. Но раз полу- чить представление почти так же трудно, как решить исходную задачу, то, на первый взгляд, обучение представлений ничем не поможет. Глубокое обучение решает эту центральную проблему обучения представлений, вводя представления, выражаемые в терминах других, более простых представле- ний. Глубокое обучение позволяет компьютеру строить сложные концепции из более прос тых. На рис. 1.2 показано, как в системе глубокого обучения можно представить концепцию изображения человека в виде комбинации более простых концепций – углов и контуров, – которые, в свою очередь, определены в терминах границ.\n--- Страница 26 ---\nСтохастическая максимизация правдоподобия  25 АВТО- МОБИЛЬЧЕЛОВЕКЖИ- ВОТНОЕВыход (тип объекта) Третий скрытый слой (части объектов) Второй скрытый слой (углы и контуры) Первый скрытый слой (границы) Видимый слой (исходные пиксели) Рис. 1.2  Иллюстрация модели глубокого обучения. Компьютеру трудно понять смысл исходных данных, полученных от сенсоров, таких, например, как изображение, представленное в виде набора значений пикселей. Функ- ция, отображающая множество пикселей в распознанный объект, очень сложна. Если подходить к задаче вычисления или обучения этого отобра- жения в лоб, то она выглядит безнадежной. Г лубокое обучение разрешает эту проблему, разбивая искомое сложное отображение на ряд более прос-тых вложенных, каждое из которых описывается отдельным слоем модели. Входные данные представлены видимым слоем, он называется так, потому что содержит переменные, доступные наблюдению. За ним идет ряд скры-тых слоев, которые извлекают из изображения все более и более абстракт- ные признаки. Слово «скрытый» означает, что значения, вырабатываемые этими слоями, не присутствуют в данных; сама модель должна определить, какие концепции полезны для объяснения связей в наблюдаемых данных. На рисунке показаны признаки, представленные каждым скрытым слоем. Зная исходные пиксели, первый слой легко может найти границы, для это-го нужно лишь сравнить яркости соседних пикселей. Имея описание гра-ниц, выработанное первым скрытым слоем, второй скрытый слой находит углы и контуры в виде наборов границ. По этому описанию третий скрытый слой может распознать части конкретных объектов, представленные сово-купностями контуров и углов определенного вида. Наконец, по описанию изображения в терминах частей объектов можно распознать сами объекты. Изобра жения взяты из работы Zeiler and Fergus (2014) с разрешения авторов\n--- Страница 27 ---\n26  Введение Типичным примером модели глубокого обучения является глубокая сеть прямо- го распространения, или многослойный перцептрон (МСП). Многослойный пер- цептрон – это просто математическая функция, отображающая множество входных значений на множество выходных. Эта функция является композицией нескольких более простых функций. Каждое применение одной математической функции можно рассматривать как новое представление входных данных. Идея нахождения подходящего представления данных путем обучения – это лишь один взгляд на глубокое обучение. Другой взгляд состоит в том, что глубина по- зволяет обучать многошаговую компьютерную программу. Каждый слой представ-ления можно мыслить себе как состояние памяти компьютера после параллельного выполнения очередного набора инструкций. Чем больше глубина сети, тем больше инструкций она может выполнить последовательно. Последовательное выполнение инструкций расширяет возможности, поскольку более поздние инструкции могут об-ращаться к результатам выполнения предыдущих. При таком взгляде на глубокое обучение не всякая информация, используемая для активации слоев, обязательно кодирует факторы вариативности, объясняющие входные данные. В представлении хранится также вспомогательная информация о состоянии, помогающая выполнить программу, способную извлекать смысл из дан- ных. Эту информацию можно уподобить счетчику или указателю в традиционной компьютерной программе. Она не имеет никакого отношения к содержанию входных данных, но помогает модели в организации их обработки. Есть два основных способа измерить глубину модели. Первый оценивает архитек- туру на основе числа последовательных инструкций, которые необходимо выпол-нить. Можно считать, что это длина самого длинного пути в графе, описывающем вычисление каждого выхода модели по ее входам. Как у двух эквивалентных компью- терных программ могут быть разные длины пути в зависимости от языка, на котором они написаны, так и одна и та же функциональность может быть изображена графами с разной длиной пути в зависимости от того, какие функции допускаются в качестве шагов. На рис. 1.3 показано, как выбор языка может дать разные результаты измере-ний для одной и той же архитектуры. При другом подходе, используемом в глубоких вероятностных моделях, глубиной модели считается не глубина графа вычислений, а глубина графа, описывающего связи концепций. В этом случае граф вычислений, выполняемых для вычисления представления каждой концепции, может быть гораздо глубже, чем граф самих кон-цепций. Связано это с тем, что понятие системы о простых концепциях можно уточ- нять, располагая информацией о более сложных. Например, система ИИ, наблю- дающая изображение лица, на котором один глаз находится в тени, первоначально может распознать только один глаз. Но, обнаружив присутствие лица, система мо-жет заключить, что должен быть и второй глаз. В таком случае граф концепций со- держит только два слоя – для глаз и для лиц, тогда как граф вычислений содержит 2n слоев, если мы n раз уточняем оценку каждой концепции при известной инфор- мации о второй. Поскольку не всегда ясно, какой из двух подходов – глубина графа вычислений или глубина графа вероятностной модели – более релевантен, и поскольку разные\n--- Страница 28 ---\nСтохастическая максимизация правдоподобия  27 люди по-разному выбирают наборы примитивных элементов, из которых строятся графы, не существует единственно правильного значения глубины архитектуры, как не существует единственно правильной длины компьютерной программы. И нет об- щего мнения о том, какой должна быть глубина, чтобы модель можно было считать «глубокой». Однако можно все-таки сказать, что глубокое обучение – это наука о мо- делях, в которых уровень композиции обученных функций или обученных концеп- ций выше, чем в традиционном машинном обучении. Набор элементовНабор элементов Логисти- ческая регрессия w1 w2 w х1 х2 xЛогисти- ческая регрессия Рис. 1.3  Иллюстрация графов вычислений, переводящих вход в выход; в каждом узле выполняется некоторая операция. Г лубиной считается длина самого длинного пути от входа к выходу, она зависит от определения до- пустимого шага вычисления. Оба графа описывают выход модели логисти-ческой регрессии σ(w Tx), где σ – логистическая сигмоида. Если в качестве элементов языка используются сложение, умножение и логистические сиг- моиды, то глубина модели равна 3. Если же логистическая регрессия сама считается элементом языка, то глубина равна 1 Итак, глубокое обучение – тема этой книги – один из подходов к ИИ. Конкретно, это вид машинного обучения – методики, которая позволяет компьютерной системе совершенствоваться по мере накопления опыта и данных. Мы твердо убеждены, что машинное обучение – единственный жизнеспособный подход к построению систем ИИ, которые могут функционировать в сложных окружающих условиях. Глубокое обучение – это частный случай машинного обучения, позволяющий достичь большей эффективности и гибкости за счет представления мира в виде иерархии вложенных концепций, в которой каждая концепция определяется в терминах более простых концепций, а более абстрактные представления вычисляются в терминах менее аб- страктных. На рис. 1.4 показано соотношение между разными отраслями ИИ, а на рис. 1.5 – высокоуровневое описание каждого подхода.\n--- Страница 29 ---\n28  Введение Пример: базы знанийГлубокое обучение Пример: МСП Обучение представленийПример: мелкие автокодировщики Машинное обучениеПример: логистическая регрессия ИИ Рис. 1.4  На этой диаграмме Венна показано, что глубокое обучение – частный случай обучения представлений, которое, в свою очередь, являет- ся частным случаем машинного обучения, используемого во многих, но не во всех подходах к ИИ. На каждой части диаграммы Венна приведен пример технологии ИИ Обучение представленийВыход Программа, написанная вручную ВходВыход Отображение признаков Признаки, спроектированные вручную ВходВыход Отображение признаков Простые признаки ВходВыход Отображение признаков Дополнительные слои более абстрактных признаков Выход Вход Системы, основанные на правилахКлассическое машинное обучениеГлубокое обучение Рис. 1.5  Связь различных частей системы ИИ между собой в рамках разных подходов к ИИ. Серым цветом показаны компоненты, способные обучаться на данных\n--- Страница 30 ---\nИсторические тенденции в машинном обучении  29 1.1. На кого ориентирована эта книга Книга будет полезна разным читателям, но мы писали ее, имея в виду две целевые аудитории. Во-первых, это студенты университетов (как младших, так и старших курсов), изучающие машинное обучение, в том числе и те, кто начинает строить карье ру в области машинного обучения и искусственного интеллекта. Во-вторых, это разработчики ПО, которые не изучали машинное обучение или статистику, но хотят быстро освоить эти дисциплины и приступить к использованию глубокого обучения в своем продукте или платформе. Глубокое обучение доказало полезность во многих направлениях ПО, в т. ч. компьютерном зрении, распознавании речи и аудиозаписей, обработке естественных языков, робототехнике, биоинформатике и химии, видео- играх, поисковых системах, интернет-рекламе и финансах. Книга разделена на три части, чтобы лучше удовлетворить потребности разных категорий читателей. В части I излагается базовый математический аппарат и дается введение в концепции машинного обучения. В части II описаны самые известные ал- горитмы глубокого обучения, которые можно считать сформировавшимися техноло-гиями. Часть III посвящена более спорным идеям, которые многие считают важными для будущих исследований в области глубокого обучения. Читатель может без ущерба для понимания пропускать части, не отвечающие его интересам или подготовке. Например, знакомые с линейной алгеброй, теорией веро- ятностей и фундаментальными концепциями машинного обучения могут пропустить часть I, а желающим реализовать работающую систему нет необходимости читать дальше части II. Чтобы читателю было проще понять, какие главы ему интересны, на рис. 1.6 показано, как устроена книга в целом. Мы предполагаем, что читатели имеют подготовку в области информатики: зна- комы с программированием, понимают, что такое производительность вычислений и теория сложности, знают начала математического анализа и некоторые положения и термины теории графов. 1.2. Исторические тенденции в машинном обучении Понять глубокое обучение проще всего в историческом контексте. Мы не станем детально описывать историю глубокого обучения, а выделим несколько ключевых тенденций: у глубокого обучения долгая и богатая история, но оно фигурировало под раз- ными названиями, отражающими различные философские воззрения, в связи с чем его популярность то усиливалась, то ослабевала; полезность глубокого обучения возросла, когда увеличился объем доступных обучающих данных; размер моделей глубокого обучения увеличивался по мере того, как совершен-ствовалась компьютерная инфраструктура (программная и аппаратная); со временем с помощью глубокого обучения удавалось решать все более слож- ные задачи со все большей точностью.\n--- Страница 31 ---\n30  Введение 1. Введение 2. Линейная алгебра 6. Глубокие сети прямого распространения4. Численные методы 8. Оптимизация3. Теория вероятностей и теория информации 7. Регуляризация5. Основы машинного обучения 9. Сверточные нейронные сети 11. Практическая методология10. Рекуррентные нейронные сети 17. Методы Монте-Карло16. Структурные вероятностные модели 18. Статистическая сумма19. Логический вывод15. Обучение представлений13. Линейные факторные модели14. Автокодировщики 20. Глубокие порождающие модели12. ПриложенияЧасть I. Основы математики и машинного обучения Часть II. Глубокие сети: современные методы Часть III. Исследования по глубокому обучению Рис. 1.6  Структура книги. Стрелки означают, что одна глава содержит материал, необходимый для понимания другой 1.2.1. Нейронные сети: разные названия и переменчивая фортуна Мы полагаем, что многие читатели слышали о глубоком обучении как о сулящей чу- деса новой технологии и удивлены, встретив слово «история» в применении к толь- ко зарождающейся дисциплине. Но в действительности глубокое обучение возник- ло еще в 1940-х годах. Оно кажется новым лишь потому, что в течение нескольких\n--- Страница 32 ---\nИсторические тенденции в машинном обучении  31 лет, предшествующих нынешнему всплеску популярности, прозябало в тени, а также потому, что названия менялись, и только недавно эта дисциплина стала называть- ся «глубоким обучением». Прежние названия отражали вес разных исследователей в научных кругах и разные точки зрения на предмет. Изложение полной истории глубокого обучения выходит за рамки этого учебника. Но кое-какие базовые сведения помогут лучше понять его смысл. Если отвлечься от деталей, то было три волны разработок: в 1940–1960-х годах глубокое обучение было известно под названием кибернетики, в 1980–1990-х – как коннекционизм, а в со- временной инкарнации – под нынешним названием – оно возродилось в 2006 году. Количественная картина показана на рис. 1.7. ГодЧастота слова или фразы0,000250 0,000200 0,000150 0,000100 0,000050 0,000000 1940 1950 1960 1970 1980 1990 2000cybernetics connectionism или neural networks Рис. 1.7  Две из трех исторических волн исследований по искусствен- ным нейронным сетям, оцененные по частоте фраз «cybernetics» и «con- nectionism или neural networks» согласно Google Books (третья волна нача- лась недавно и еще не отражена). Первая волна, связанная с кибернетикой, приходится на 1940–1960-е годы, когда разрабатывались теории биологи-ческого обучения (McCulloch and Pitts, 1943; Hebb, 1949) и были реализо- ваны первые модели, в частности перцептрон (Rosenblatt, 1958), позво- лявшие обучить один нейрон. Вторая волна периода 1980–1995 гг . связана с коннекционистским подходом, когда метод обратного распространения (Rumelhart et al., 1986a) был применен к обучению нейронной сети с одним или двумя скрытыми слоями. Третья волна, глубокое обучение, началась примерно в 2006 году (Hinton et al., 2006; Bengio et al., 2007; Ranzato et al., 2007a) и только теперь – в 2016 году – описывается в виде книги. Книги, по- священные двум другим волнам, также вышли гораздо позже активизации исследований в соответствующей области Некоторые из самых ранних алгоритмов обучения сегодня мы назвали бы компью- терными моделями биологического обучения, т. е. процессов, которые происходят или могли бы происходить в мозге. Поэтому одно из прежних названий глубокого обучения – искусственные нейронные сети (ИНС). Им соответствует взгляд на мо- дели глубокого обучения как на инженерные системы, устроенные по образцу биоло- гического мозга (человека или животного). Но хотя были попытки использовать ней-ронные сети, применяемые в машинном обучении, чтобы понять, как функционирует мозг (Hinton and Shallice, 1991), в общем случае при их проектировании не ставилась задача создать реалистическую модель биологической функции. Нейронный подход к глубокому обучению основан на двух главных идеях. Во-первых, мозг – доказатель-\n--- Страница 33 ---\n32  Введение ный пример того, что разумное поведение возможно. Поэтому концептуально прямой путь к построению искусственного интеллекта состоит в том, чтобы проанализиро- вать с вычислительной точки зрения принципы работы мозга и воспроизвести его функциональность. Во-вторых, вообще было бы очень интересно понять, как работа-ет мозг и какие принципы лежат в основе разума человека, поэтому модели машинно- го обучения, проливающие свет на эти фундаментальные научные вопросы, полезны вне зависимости от их применимости к конкретным инженерным задачам. Современный термин «глубокое обучение» выходит за рамки нейробиологиче- ского взгляда на модели машинного обучения. В нем заложен более общий принцип обуче ния нескольких уровней композиции, применимый к системам машинного обуче ния, не обязательно устроенным по примеру нейронов. Предтечами современного глубокого обучения были простые линейные модели на основе нейробиологических аналогий. Они принимали множество n входных значе- ний x 1, …, xn и ассоциировали с ними выход y. В ходе обучения модель должна была найти веса w1, …, wn и вычислить выход в виде f(x, w) = x1w1 + … + xnwn. Эта первая волна нейронных сетей известна под названием кибернетики (рис. 1.7). Нейрон Маккаллока–Питтса (McCulloch and Pitts, 1943) был ранней моделью функционирования мозга. Эта линейная модель могла распознавать две категории выходов, проверяя, является значение f(x, w) положительным или отрицательным. Конечно, чтобы модель соответствовала желаемому определению категорий, нужно было правильно подобрать веса. Веса задавал человек. В 1950-е годы был изобретен перцептрон (Rosenblatt, 1958, 1962) – первая модель, которая могла в процессе обуче- ния находить веса, определяющие категории, имея примеры входных данных из каж-дой категории. Модель адаптивного линейного элемента (ADALINE), относящаяся примерно к тому же времени, просто возвращала само значение f(x) для предсказа- ния вещественного числа (Widrow and Hoff, 1960) и также могла обучаться предска- занию чисел на данных. Эти простые алгоритмы обучения оказали заметное влияние на современный ландшафт машинного обучения. Алгоритм обучения, использованный для подбора весов в модели ADALINE, был частным случаем алгоритма стохастического гради- ентного спуска. Его немного модифицированные варианты и по сей день остаются основными алгоритмами моделей глубокого обучения. Модели на основе функции f(x, w), используемые в перцептроне и ADALINE, на- зываются линейными моделями. Они до сих пор относятся к числу наиболее рас- пространенных моделей машинного обучения, хотя часто обучаются иначе, чем было принято раньше. У линейных моделей много ограничений. Самое известное состоит в невоз- можности обучить функцию XOR, для которой f([0, 1], w) = 1 и f([1, 0], w) = 1, но f([1, 1], w) = 0 и f([0, 0], w) = 0. Критики, отмечавшие эти изъяны линейных моделей, вообще возражали против обучения, основанного на биологических аналогиях (Min-sky and Papert, 1969). Это стало первым серьезным ударом по популярности нейрон-ных сетей. В настоящее время нейробиология рассматривается как важный источник идей для исследований в области глубокого обучения, но уже не занимает домини- рующих позиций. Главная причина снижения роли нейробиологии в исследованиях по глубокому обучению – тот факт, что у нас попросту не хватает информации о мозге, чтобы ис- пользовать ее в качестве образца и руководства к действию. Чтобы по-настоящему\n--- Страница 34 ---\nИсторические тенденции в машинном обучении  33 понять алгоритмы работы мозга, нужно было бы одновременно наблюдать за актив- ностью тысяч (как минимум) взаимосвязанных нейронов. Не имея такой возмож-ности, мы далеки от понимания даже самых простых и хорошо изученных областей мозга (Olshausen and Field, 2005). Нейробиология дала надежду на то, что один алгоритм глубокого обучения смо- жет решить много разных задач. Нейробиологи выяснили, что хорьки могут «ви-деть» с помощью области мозга, отвечающей за обработку слуховой информации, если перенаправить нервы из глаз в слуховую кору (Von Melchner et al., 2000). Это наводит на мысль, что значительная часть мозга млекопитающих, возможно, исполь-зует единый алгоритм для решения большинства задач. До появления этой гипотезы исследования по машинному обучению были более фрагментированы: обработкой естественных языков, компьютерным зрением, планированием движения и распоз- наванием речи занимались разные группы ученых. Эти сообщества и по сей день раз- делены, но ученые, работающие в области глубокого обучения, зачастую занимаются многими или даже всеми этими предметами. Мы можем почерпнуть из нейробиологии кое-какие соображения. Основная идея, навеянная осмыслением работы мозга, – наличие большого числа вычислительных блоков, которые обретают разум только в результате взаимодействий. Неокогнитрон (Fukushima, 1980) предложил архитектуру модели, эффективную для обработки изображений. Идея сложилась под влиянием структуры зрительной системы мле-копитающих и впоследствии легла в основу современной сверточной сети (LeCun et al., 1998b), с которой мы познакомимся в разделе 9.10. Большинство современных нейронных сетей основано на модели нейрона, которая называется блоком линей- ной ректификации. Оригинальная модель когнитрона (Fukushima, 1975) была более сложной, основанной на наших знаниях о работе мозга. В современной упрощенной модели объединены различные точки зрения; в работах Nair and Hinton (2010) и Glo- rot et al. (2011a) отмечено влияние нейробиологии, а в работе Jarrett et al. – скорее, инженерных дисциплин. Каким бы важным источником идей ни была нейробиоло-гия, считать, что от нее нельзя отклониться ни на шаг, вовсе необязательно. Мы знаем, что настоящие нейроны вычисляют совсем не те функции, что блоки линейной рек-тификации, но большее приближение к реальности пока не привело к повышению ка- чества машинного обучения. Кроме того, хотя нейробиология легла в основу несколь- ких успешных архитектур нейронных сетей, мы до сих пор знаем о биологическом обучении недостаточно, чтобы полнее использовать нейробиологию для построения алгоритмов обучения этих архитектур. В социальных сетях часто подчеркивают сходство между глубоким обучением и мозгом. Да, действительно, исследователи, занимающиеся глубоким обучением, чаще говорят о влиянии аналогий с мозгом на свою работу, чем те, кто занимается другими методами машинного обучения, например ядерными методами или байесов-ской статистикой. Но не следует думать, что цель глубокого обучения – попытка ими- тировать мозг. Современное глубокое обучение черпает идеи из разных дисциплин, особенно из таких отраслей прикладной математики, как линейная алгебра, теория вероятностей, теория информации и численная оптимизация. Некоторые ученые считают нейробиологию важным источником идей, другие не упоминают ее вовсе. Отметим, что попытки понять, как работает мозг на алгоритмическом уровне, не прекращаются. Эта область исследований, известная под названием «вычис-лительная нейробиология», не совпадает с глубоким обучением. Нередко ученые\n--- Страница 35 ---\n34  Введение переходят из одной области в другую. Предмет глубокого обучения – построение компьютерных систем, способных успешно решать задачи, требующие интеллекта, а предмет вычислительной нейробиологии – построение более точных моделей ра- боты мозга. В 1980-е годы поднялась вторая волна исследований по нейронным сетям, вы- званная главным образом движением под названием коннекционизм, или парал- лельная распределенная обработка (Rumelhart et al., 1986c; McClelland et al., 1995). Коннекционизм возник в контексте когнитивистики – междисциплинарного под- хода к пониманию процесса познания, объединяющего несколько разных уровней анализа. В начале 1980-х годов большинство когнитивистов изучало модели при- нятия решений путем манипулирования символами (symbolic reasoning). Несмотря на популярность символических моделей, трудно было объяснить, как мозг мог бы реализовать их с помощью нейронов. Коннекционисты начали изучать модели по- знания, которые допускали реализацию на основе нейронов (Touretzky and Minton, 1985), возродив многие идеи психолога Дональда Хебба, высказанные в 1940-х годах (Hebb, 1949). Центральная идея коннекционизма состоит в том, что при наличии большого ко- личества вычислительных блоков, объединенных в сеть, удастся достичь разумного поведения. Эта идея относится в равной мере к нейронам в биологических нервных системах и к скрытым блокам в компьютерных моделях. Движение коннекционизма породило несколько ключевых концепций, которые и по сей день играют важнейшую роль в глубоком обучении. Одна из них – распределенное представление (Hinton et al., 1986). Идея в том, что каждый вход системы следует представлять многими признаками, а каждый признак должен участвовать в представлении многих возможных входов. Пусть, например, имеется зрительная система, способная распознавать легковые автомобили, грузови-ки и птиц, причем объекты могут быть красного, зеленого или синего цвета. Один из способов представления таких входов – завести отдельный нейрон или скрытый блок для активации каждой из девяти возможных комбинаций: красный грузовик, красная легковушка, красная птица, зеленый грузовик и т. д. Тогда потребуется девять ней- ронов, и каждый нейрон необходимо независимо обучить концепциям цвета и типа объекта. У лучшить ситуацию можно, воспользовавшись распределенным представ-лением, в котором три нейрона описывают цвет, а еще три – тип объекта. Тогда пона- добится всего шесть нейронов, и нейрон, отвечающий за красное, можно обучить на изображениях легковушек, грузовиков и птиц, а не только на изображениях объек- тов одного типа. Концепция распределенного представления является центральной в этой книге и подробно рассматривается в главе 15. Еще одним крупным достижением коннекционистов стали успешное использова- ние обратного распространения для обучения глубоких нейронных сетей с внутрен- ними представлениями и популяризация алгоритма обратного распространения (Ru- melhart et al., 1986a; LeCun, 1987). Его популярность то возрастала, то убывала, но на данный момент это преобладающий подход к обучению глубоких моделей. 1990-е годы стали временем важных достижений в моделировании последователь- ностей с помощью нейронных сетей. В работах Hochreiter (1991) и Bengio et al. (1994) сформулирован ряд фундаментальных математических трудностей моделирования длинных последовательностей (см. раздел 10.7). В работе Hochreiter and Schmidhuber (1997) введено понятие сетей с долгой краткосрочной памятью (long short-term me-\n--- Страница 36 ---\nИсторические тенденции в машинном обучении  35 mory – LSTM) для разрешения некоторых из описанных трудностей. Сегодня LSTM- сети широко используются во многих задачах моделирования последовательностей, в т. ч. для обработки естественных языков в Google. Вторая волна работ по нейронным сетям продолжалась до середины 1990-х годов. Но компании, специализирующиеся на нейронных сетях и других технологиях ИИ, стали давать чрезмерно амбициозные обещания в попытках привлечь инвестиции. Когда ИИ не оправдал этих неразумных надежд, инвесторы испытали разочарова-ние. В то же время имел место заметный прогресс в других областях машинного об- учения. Ядерные методы (Boser et al., 1992; Cortes and Vapnik, 1995; Schölkopf et al., 1999) и графические модели (Jordan, 1998) позволили достичь хороших результатов при решении многих важных задач. В совокупности эти два фактора привели к спаду интереса к нейронным сетям, который продолжался до 2007 года. В это время нейронные сети по-прежнему показывали впечатляющее качество на некоторых задачах (LeCun et al., 1998b; Bengio et al., 2001). Канадский институт пер-спективных исследований (Canadian Institute for Advanced Research – CIFAR) помог нейронным сетям остаться на плаву, профинансировав исследовательскую програм-му нейронных вычислений и адаптивного восприятия (Neural Computation and Adap- tive Perception – NCAP). В рамках этой программы объединились группы Джеффри Хинтона из Торонтского университета, Иошуа Бенджио из Монреальского универ-ситета и Янна Лекуна из Нью-Йоркского университета. Мультидисциплинарная ис- следовательская программа CIFAR NCAP включала также нейробиологов и специа- листов по человеческому и компьютерному зрению. Тогда сложилось общее мнение, что обучить глубокие сети очень трудно. Теперь мы знаем, что алгоритмы, существовавшие начиная с 1980-х годов, работают отлично, но это не было очевидно до 2006 года. Причина, наверное, в том, что с вычислитель- ной точки зрения эти алгоритмы очень накладны, поэтому было невозможно экспе-риментировать с ними на имевшемся тогда оборудовании. Третья волна работ по нейронным сетям началась с прорыва в 2006 году. Джефф- ри Хинтон показал, что так называемые глубокие сети доверия можно эффектив- но обучать с помощью стратегии жадного послойного предобучения (Hinton et al., 2006), которую мы подробно опишем в разделе 15.1. Другие аффилированные с CI- FAR исследовательские группы быстро показали, что ту же стратегию можно ис-пользовать для обучения многих других видов глубоких сетей (Bengio et al., 2007; Ranzato et al., 2007a), и систематически улучшали степень обобщения на тестовых примерах. Благодаря этой волне исследований в обиход вошел термин «глубокое обучение», подчеркивающий, что теперь можно обучать более глубокие нейронные сети, чем раньше, и привлекающий внимание к теоретической важности глубины (Bengio and LeCun, 2007; Delalleau and Bengio, 2011; Pascanu et al., 2014a; Montufar et al., 2014). В то время глубокие нейронные сети превзошли конкурирующие системы ИИ – как основанные на других технологиях машинного обучения, так и спроекти- рованные вручную. Третья волна популярности нейронных сетей продолжается и во время написания этой книги, хотя фокус исследований значительно сместился. По-началу в центре внимания находились методы обучения без учителя и способность глубоких моделей, обученных на небольших наборах данных, к обобщению. А теперь больший интерес вызывают гораздо более старые алгоритмы обучения с учителем и возможность задействовать большие размеченные наборы данных при обучении глубоких моделей.\n--- Страница 37 ---\n36  Введение 1.2.2. Увеличение размера набора данных Может возникнуть вопрос, почему лишь недавно была осознана роль глубокого обуче ния как ключевой технологии, хотя первые эксперименты с искусственными нейронными сетями были проведены еще в 1950-х годах. Глубинное обучение успеш- но применяется в коммерческих приложениях, начиная с 1990-х, но часто его рассмат- ривали не как технологию, а как искусство – как нечто такое, что подвластно только экспертам. Так было до недавнего времени. Действительно, чтобы добиться хорошего качества от алгоритма глубокого обучения, нужен некоторый навык. Но, к счастью, потребность в таком навыке снижается по мере увеличения объема обучаю щих дан- ных. Алгоритмы обучения, по качеству приближающиеся к возможностям челове- ка при решении сложных задач, остались почти такими же, как алгоритмы, с трудом справлявшиеся с игрушечными задачами в 1980-х, но модели, которые мы с их по- мощью обучаем, претерпели изменения, позволившие упростить обучение очень глубоких архитектур. Самое важное новшество заключается в том, что сегодня мы можем предоставить этим алгоритмам необходимые для успеха ресурсы. На рис. 1.8 показано изменение эталонных наборов данных со временем. Эта тенденция обуслов-лена возрастающей цифровизацией общества. Чем активнее применяются компьюте-ры, тем больше записей о том, что мы делаем. А поскольку компьютеры объединяют- ся в сети, становится проще централизованно хранить эти записи и построить из них набор данных, подходящий для машинного обучения. С наступлением эры «больших данных» машинное обучение значительно упростилось, поскольку ключевая пробле-ма статистического оценивания – высокое качество обобщения на новые данные пос- ле обучения на небольшом количестве примеров – теперь далеко не так актуальна. В 2016 году действует грубое эвристическое правило: алгоритм глубокого обучения с учителем достигает приемлемого качества при наличии примерно 5000 помеченных примеров на категорию и оказывается сопоставим или даже превосходит человека, если обучается на наборе данных, содержащем не менее 10 миллионов помеченных примеров. Как добиться успеха при работе с наборами данных меньшего размера – важная область исследований, и акцент в ней делается на том, чтобы воспользоваться преимуществами большого количества непомеченных примеров, применяя обучение без учителя или с частичным привлечением учителя. 1.2.3. Увеличение размера моделей Еще одна причина нынешнего роста популярности нейронных сетей после сравни-тельно скромных успехов в 1980-е годы – наличие вычислительных ресурсов, доста- точных для работы с гораздо более крупными моделями. Один из главных выводов коннекционизма состоит в том, что животные проявляют интеллект, когда много ней- ронов работает совместно. Один нейрон или небольшой их набор не принесет особой пользы. Плотность соединений между биологическими нейронами не слишком велика. Как видно по рис. 1.10, в наших моделях машинного обучения число соединений в расчете на один нейрон примерно на порядок выше, чем даже в мозгу млекопитающих, и та- кое положение существует уже несколько десятков лет.\n--- Страница 38 ---\nИсторические тенденции в машинном обучении  37Размер набора данных (число примеров) 109 106 103108 105 102107 104 101 100Canadian Hansard WMT Sports-1M ImageNet10k Public SVHN CriminalsImageNet ILSVRC 2014 MNIST CIFAR-10 T vs. G vs. F Rotated T vs. C Iris 1900 1950 1985 2000 2015 Рис. 1.8  Увеличение размера набора данных со временем. В начале 1900-х годов статистики изучали наборы данных, содержащие от сотен до тысяч вручную подготовленных измерений (Garson, 1900; Gosset, 1908; Anderson, 1935; Fisher, 1936). В период между 1950-ми и 1980-ми пионе- ры биокомпьютерного зрения зачастую работали с небольшими синтети- ческими наборами данных, например растровыми изображениями букв низкого разрешения, специально спроектированными так, чтобы снизить стоимость вычислений и продемонстрировать, что нейронные сети можно обучить функциям специального вида (Widrow and Hoff, 1960; Rumelhart et al., 1986b). В 1980-е и 1990-е машинное обучение стало в большей степе- ни статистическим, а наборы данных уже насчитывали десятки тысяч при- меров, как, например, набор MNIST (рис. 1.9) отсканированных рукопис-ных цифр (LeCun et al., 1998b). В первом десятилетии XXI века продолжали создавать более изощренные наборы данных того же размера, например CIFAR-10 (Krizhevsky and Hinton, 2009). В конце этого периода и в первой по- ловине 2010-х появление гораздо больших наборов данных, содержащих от сотен тысяч до десятков миллионов примеров, полностью изменило пред-ставление о возможностях глубокого обучения. К таким наборам относится общедоступный набор номеров домов (Street View House Numbers) (Netzer et al., 2011), различные варианты набора ImageNet (Deng et al., 2009, 2010a; Russakovsky et al., 2014a) и набор Sports-1M (Karpathy et al., 2014). В верх- ней части диаграммы мы видим, что наборы переведенных предложений, например набор, построенный IBM по официальным отчетам о заседаниях канадского парламента (Brown et al., 1990), и набор WMT 2014 переводов с английского на французский (Schwenk, 2014), по размеру намного пре- восходят большинство остальных наборов\n--- Страница 39 ---\n38  Введение Рис. 1.9  Несколько примеров из набора данных MNIST . Акроним «NIST» означает «National Institute of Standards and Technology» (Национальный инс титут стандартов и технологий) – учреждение, первоначально собрав- шее эти данные. А буква «M» означает «модифицированный», поскольку данные были подвергнуты предварительной обработке, чтобы упростить применение алгоритмов машинного обучения. Набор данных MNIST содер-жит отсканированные изображения рукописных цифр и ассоциированные с ними метки, описывающие, какая цифра от 0 до 9 изображена. Это одна из самых простых задач классификации, поэтому набор широко используется для тестирования в исследованиях по глубокому обучению. Он сохраняет популярность, хотя для современных методов задача не представляет тру-да. Джеффри Хинтон назвал его «дрозофилой машинного обучения», имея в виду, что он позволяет специалистам по машинному обучению исследо- вать свои алгоритмы в контролируемых лабораторных условиях, как био- логи изучают фруктовых мушек Если говорить об общем числе нейронов, то до недавнего времени нейронные сети были на удивление малы (рис. 1.11). После добавления скрытых блоков размер ис-кусственных нейронных сетей удваивался в среднем каждые 2,4 года, чему способст- вовало появление более быстрых компьютеров с большим объемом памяти, а также наличие крупных наборов данных. Чем больше сеть, тем выше ее точность на более сложных задачах. Эта тенденция прослеживается на протяжении десятилетий. Если темпы масштабирования не ускорятся в результате внедрения новых технологий, то искусственная нейронная сеть сравняется с человеческим мозгом по числу нейронов\n--- Страница 40 ---\nИсторические тенденции в машинном обучении  39 не раньше 2050-х годов. Биологические нейроны могут представлять более сложные функции, чем современные искусственные, поэтому биологические нейронные сети могут оказаться даже больше, чем показано на диаграмме. Количество соединений на один нейрон 101102103104 1950 1985 2000 2015Фруктовая мушкаМышьКошкаЧеловек Рис. 1.10  Рост количества соединений в расчете на один нейрон со временем. Первоначально число соединений между нейронами в искус- ственной нейронной сети было ограничено возможностями оборудования. Сегодня оно в основном является параметром проектирования. В некото- рых нейронных сетях число соединений почти такое же, как у кошки, а сети с числом соединений, как у мелких млекопитающих типа мыши, встреча- ются сплошь и рядом. Даже в мозге человека число соединений на нейрон нельзя назвать заоблачным. Размеры биологических нейронных сетей взя-ты из Википедии (2015) 1. Адаптивный линейный элемент (Widrow and Hoff, 1960)2. Неокогнитрон (Fukushima, 1980)3. GPU-ускоренная сверточная сеть (Chellapilla et al., 2006)4. Г лубокая машина Больцмана (Salakhutdinov and Hinton, 2009a)5. Сверточная сеть без учителя (Jarrett et al., 2009)6. GPU-ускоренный многослойный перцептрон (Ciresan et al., 2010)7. Распределенный автокодировщик (Le et al., 2012)8. Сверточная сеть с несколькими GPU (Krizhevsky et al., 2012)9. Сверточная сеть без учителя на компьютерах типа COTS HPC (Coates et al., 2013)10. GoogLeNet (Szegedy et al., 2014a) В ретроспективе не кажется удивительным, что нейронные сети с числом нейронов меньше, чем у пиявки, не могли справиться с решением сложных задач искусствен- ного интеллекта. Даже нынешние сети, которые мы считаем очень большими с вы- числительной точки зрения, меньше нервной системы сравнительно примитивных позвоночных животных, например лягушек. Увеличение размера моделей вследствие доступности более быстрых процессоров, GPU общего назначения (см. раздел 12.1.2), более быстрых сетей и более совершен- ной инфраструктуры распределенных вычислений – одна из самых важных тенден- ций в истории глубокого обучения. Ожидается, что она продолжится и в будущем.\n--- Страница 41 ---\n40  Введение Количество нейронов (в логарифмическом масштабе) 10–210–1103 100104 101105108 102106109 10710101011 1950 1985 2000 2015 2056Морская губкаЛягушка Пчела Муравей Пиявка НематодаОсьминогЧеловек Рис. 1.11  Рост размера нейронной сети со временем. После добавле- ния скрытых блоков размер нейронных сетей удваивался примерно каждые 2,4 го да. Размеры биологических нейронных сетей взяты из Википедии (2015) 1. Перцептрон (Rosenblatt, 1958, 1962)2. Адаптивный линейный элемент (Widrow and Hoff, 1960)3. Неокогнитрон (Fukushima, 1980)4. Ранняя сеть с обратным распространением (Rumelhart et al., 1986b)5. Рекуррентная нейронная сеть для распознавания речи (Robinson and Fallside, 1991)6. Многослойный перцептрон для распознавания речи (Bengio et al., 1991)7. Сигмоидальная сеть доверия со средним полем (Saul et al., 1996)8. LeNet-5 (LeCun et al., 1998b)9. Нейронная эхо-сеть (Jaeger and Haas, 2004)10. Г лубокая сеть доверия (Hinton et al., 2006)11. GPU-ускоренная сверточная сеть (Chellapilla et al., 2006)12. Г лубокая машина Больцмана (Salakhutdinov and Hinton, 2009a)13. GPU-ускоренная сеть глубокого доверия (Raina et al., 2009)14. Сверточная сеть без учителя (Jarrett et al., 2009)15. GPU-ускоренный многослойный перцептрон (Ciresan et al., 2010)16. Сеть OMP-1 (Coates and Ng, 2011)17. Распределенный автокодировщик (Le et al., 2012)18. Сверточная сеть с несколькими GPU (Krizhevsky et al., 2012)19. Сверточная сеть без учителя на компьютерах типа COTS HPC (Coates et al., 2013)20. GoogLeNet (Szegedy et al., 2014a) 1.2.4. Повышение точности и сложности и расширение круга задач Начиная с 1980-х годов точность распознавания и прогнозирования глубоких моде- лей постоянно росла. И вместе с тем все разнообразнее становились задачи, которые удавалось решать с их помощью. Самые первые глубокие модели использовались для распознавания отдельных объ- ектов в кадрированных изображениях совсем небольшого размера (Rumelhart et al., 1986a). С тех пор размер изображений, которые можно было обработать с по мощью нейронной сети, постепенно увеличивался. Современные сети распознавания объек-тов обрабатывают фотографии с высоким разрешением и не требуют кадрирования фотографии по месту расположения объекта (Krizhevsky et al., 2012). Кроме того, ран-ние сети умели распознавать только два вида объектов (а в некоторых случаях при-\n--- Страница 42 ---\nИсторические тенденции в машинном обучении  41 сутствие или отсутствие объектов одного вида), тогда как типичная современная сеть распознает не менее 1000 категорий объектов. Самый крупный конкурс по распозна-ванию объектов – ImageNet Large Scale Visual Recognition Challenge (ILSVRC) – про- водится каждый год. Переломным моментом, ознаменовавшим стремительный взлет глубокого обучения, стала победа с большим отрывом сверточной сети, которая участ- вовала впервые и сразу уменьшила частоту непопадания в первые пять (top-5 error rate) с 26,1 до 15,3% (Krizhevsky et al., 2012). Смысл этого показателя следующий: свер- точная сеть порождала для каждого изображения ранжированный список возможных категорий, и правильная категория отсутствовала среди первых пяти элементов этого списка только в 15,3% тестовых примеров. С тех пор подобные конкурсы неизменно выигрывали сверточные сети, и на данный момент прогресс глубокого обучения по- зволил довести частоту непопадания в первые пять до 3,6% (рис. 1.12). Год2010 2011 2012 2013 2014 2015 0,30 0,150,25 0,100,20 0,05 0,00Частота ошибок классификации в конкурсе ILSVRC Рис. 1.12  Уменьшение частоты ошибок со временем. С тех пор как глубокие сети достигли масштаба, необходимого для участия в конкурсе ImageNet Large Scale Visual Recognition Challenge, они неизменно выигры- вают его, с каждым разом демонстрируя все меньшую и меньшую частоту ошибок. Данные взяты из работ Russakovsky et al. (2014b) и He et al. (2015) Глубокое обучение также оказало огромное влияние на распознавание речи. По- сле прогресса, достигнутого на протяжении 1990-х годов, в качестве распознавания речи наступил застой. Применение глубокого обучения (Dahl et al., 2010; Deng et al., 2010b; Seide et al., 2011; Hinton et al., 2012a) привело к резкому уменьшению частоты ошибок, иногда аж наполовину. Мы вернемся к этой теме в разделе 12.3. Глубокие сети добились также впечатляющих успехов в обнаружении пешеходов и сегментации изображений (Sermanet et al., 2013; Farabet et al., 2013; Couprie et al., 2013), а в задаче классификации дорожных знаков показали себя лучше человека (Ci- resan et al., 2012). Одновременно с повышением размера и точности глубоких сетей росла и сложность решаемых с их помощью задач. В работе Goodfellow et al. (2014d) показано, что нейрон- ные сети можно научить распознаванию целых последовательностей символов в изобра- жении, а не только идентификации одиночного объекта. Ранее считалось, что для тако- го обучения необходимо помечать отдельные элементы последовательности (Gü lçehre\n--- Страница 43 ---\n42  Введение and Bengio, 2013). Рекуррентные нейронные сети, в частности вышеупомянутая модель LSTM, теперь применяются для моделирования связей последовательностей с другими последовательностями, а не только с фиксированными входами. Такое обучение типа «последовательность в последовательность», похоже, привело к революции в другом приложении: машинном переводе (Sutskever et al., 2014; Bahdanau et al., 2015). Эта тенденция к увеличению сложности была доведена до логического завершения с вводом в рассмотрение нейронных машин Тьюринга (Graves et al., 2014a), которые обучаются читать из ячеек памяти и писать произвольные данные в ячейки памяти. Такие нейронные сети могут обучаться простым программам на примерах желаемо- го поведения. Например, они могут научиться сортировать списки чисел, если им предъявить примеры отсортированных и неотсортированных последовательностей. Эта технология самопрограммирования пока находится в зачаточной стадии, но в бу- дущем теоретически может быть применена почти к любой задаче. Еще одним венцом глубокого обучения является обобщение на обучение с под- креплением. В этом контексте автономный агент должен научиться выполнять не- которое задание методом проб и ошибок, без какой-либо подсказки со стороны чело- века. Компания DeepMind продемонстрировала систему обучения с подкреплением, основанную на технологиях глубокого обучения, которая способна научиться играть в видеоигры Atari, достигая во многих случаях уровня, сравнимого с человеческим (Mnih et al., 2015). Глубокое обучение позволило также значительно усовершенство-вать качество обучения с подкреплением в робототехнике (Finn et al., 2015). Многие приложения глубокого обучения приносят солидную прибыль. Эти тех- нологии используются в таких крупных компаниях, как Google, Microsoft, Facebook, IBM, Baidu, Apple, Adobe, Netflix, NVIDIA и NEC. Прогресс в глубоком обучении сильно зависит от достижений в области программ- ной инфраструктуры. Библиотеки Theano (Bergstra et al., 2010; Bastien et al., 2012), PyLearn2 (Goodfellow et al., 2013c), Torch (Collobert et al., 2011b), DistBelief (Dean et al., 2012), Caffe (Jia, 2013), MXNet (Chen et al., 2015) и TensorFlow (Abadi et al., 2015) применяются в важных исследовательских проектах и в коммерческих продуктах. Глубокое обучение внесло вклад и в другие науки. Современные сверточные сети для распознавания объектов дают модель визуальной обработки, изучаемую в нейро- биологии (DiCarlo, 2013). Кроме того, глубокое обучение предоставляет полезные ин-струменты для обработки больших массивов данных и прогнозирования в различных научных дисциплинах. Оно было успешно применено к прогнозированию взаимодей- ствия молекул в интересах фармацевтических компаний, занимающихся поиском но- вых лекарств (Dahl et al., 2014), к поиску субатомных частиц (Baldi et al., 2014) и к ав- томатическому распознаванию сделанных микроскопом изображений для построения трехмерной карты человеческого мозга (Knowles-Barley et al., 2014). В будущем мы ожидаем проникновения глубокого обучения во все новые и новые отрасли науки. Резюмируя, можно сказать, что глубокое обучение – это развивавшийся в течение нескольких десятилетий подход к машинному обучению, основанный главным обра- зом на наших знаниях о человеческом мозге, на статистике и прикладной математике. В последние годы глубокое обучение переживает стремительный рост популярности и полезности благодаря в первую очередь появлению более мощных компьютеров, больших наборов данных и методов обучения более глубоких сетей. Будущее сулит нам новые проблемы и возможности дальнейшего совершенствования глубокого об- учения с выходом на новые рубежи.\n--- Страница 44 ---\nЧасть I ОСНОВЫ ПРИКЛАДНОЙ МАТЕМАТИКИ И МАШИННОГО ОБУЧЕНИЯ В этой части книги вводятся основные математические идеи, необходимые для по- нимания глубокого обучения. Мы начнем с общего математического аппарата: опре- деления функций многих переменных, нахождения их минимумов и максимумов и численной оценки степени доверия. Затем мы сформулируем фундаментальные цели машинного обучения и опишем, как их достичь с помощью задания модели, представляющей некоторые гипотезы, проектирования функции стоимости, которая измеряет степень соответствия гипотез реальности, и использования алгоритма обучения для минимизации функции стои- мости. Этот элементарный аппарат является основной для самых разнообразных алгорит- мов машинного обучения, не обязательно глубокого. В последующих частях книги мы с его помощью разработаем алгоритмы глубокого обучения.",
      "debug": {
        "start_page": 22,
        "end_page": 44
      }
    },
    {
      "name": "Глава 2. Линейная алгебра 44",
      "content": "--- Страница 45 --- (продолжение)\nГлава 2 Линейная алгебра Линейная алгебра – это раздел математики, который широко используется в науке и технике. Но поскольку линейная алгебра имеет дело с непрерывными, а не дис- кретными величинами, специалисты по информатике редко с ней сталкиваются. Од- нако для понимания многих алгоритмов машинного обучения, особенно глубокого, уверенное владение аппаратом линейной алгебры необходимо. Поэтому мы пред-пошлем введению в глубокое обучение концентрированное изложение основ линей- ной алгебры. Если вы уже знакомы с линейной алгеброй, то можете пропустить эту главу. Если вам раньше доводилось встречаться с этим аппаратом, но нужен подробный справоч- ник, чтобы освежить в памяти формулы, то рекомендуем книгу «The Matrix Cook- book» (Petersen and Pedersen, 2006). Если вы совсем ничего не знаете о линейной алгебре, то из этой главы вы почерпнете достаточно сведений для чтения книги, но мы настоятельно советуем обратиться к еще какому-нибудь источнику, посвященно- му исключительно линейной алгебре, например книге Шилова, Shilov (1977). В этой главе не рассматриваются многие вопросы линейной алгебры, не существенные для понимания глубокого обучения. 2.1. Скаляры, векторы, матрицы и тензоры В линейной алгебре изучаются математические объекты нескольких видов. Скаляры. Скаляр – это просто число, в отличие от большинства других изучае- мых в линейной алгебре объектов, представляющих собой массивы чисел. Мы будем обозначать скаляры курсивным шрифтом и, как правило, строчными буквами. Вводя в рассмотрение скаляр, мы будем указывать, что он означает, например: «Пусть s ∈ ℝ обозначает угловой коэффициент прямой» (веществен- ное число) или «Обозначим n ∈ ℕ число блоков» (целое натуральное число). Векторы. Вектор – это массив чисел. Элементы вектора расположены в опре- деленном порядке. Отдельный элемент определяется своим индексом. Обычно векторы обозначаются строчными буквами курсивным полужирным шриф-том, например x. Для обозначения элемента вектора указывается имя векто- ра курсивным шрифтом с подстрочным индексом. Первый элемент вектора x обозначается x 1, второй – x2 и т. д. Необходимо также указать тип хранящихся в векторе чисел. Если каждый элемент вектора принадлежит ℝ, а всего элемен- тов n, то вектор принадлежит декартову произведению n экземпляров ℝ, оно обозначается ℝn. Если требуется явно перечислить элементы вектора, то они записываются в столбик в квадратных скобках:\nГлава 2 Линейная алгебра Линейная алгебра – это раздел математики, который широко используется в науке и технике. Но поскольку линейная алгебра имеет дело с непрерывными, а не дис- кретными величинами, специалисты по информатике редко с ней сталкиваются. Од- нако для понимания многих алгоритмов машинного обучения, особенно глубокого, уверенное владение аппаратом линейной алгебры необходимо. Поэтому мы пред-пошлем введению в глубокое обучение концентрированное изложение основ линей- ной алгебры. Если вы уже знакомы с линейной алгеброй, то можете пропустить эту главу. Если вам раньше доводилось встречаться с этим аппаратом, но нужен подробный справоч- ник, чтобы освежить в памяти формулы, то рекомендуем книгу «The Matrix Cook- book» (Petersen and Pedersen, 2006). Если вы совсем ничего не знаете о линейной алгебре, то из этой главы вы почерпнете достаточно сведений для чтения книги, но мы настоятельно советуем обратиться к еще какому-нибудь источнику, посвященно- му исключительно линейной алгебре, например книге Шилова, Shilov (1977). В этой главе не рассматриваются многие вопросы линейной алгебры, не существенные для понимания глубокого обучения. 2.1. Скаляры, векторы, матрицы и тензоры В линейной алгебре изучаются математические объекты нескольких видов. Скаляры. Скаляр – это просто число, в отличие от большинства других изучае- мых в линейной алгебре объектов, представляющих собой массивы чисел. Мы будем обозначать скаляры курсивным шрифтом и, как правило, строчными буквами. Вводя в рассмотрение скаляр, мы будем указывать, что он означает, например: «Пусть s ∈ ℝ обозначает угловой коэффициент прямой» (веществен- ное число) или «Обозначим n ∈ ℕ число блоков» (целое натуральное число). Векторы. Вектор – это массив чисел. Элементы вектора расположены в опре- деленном порядке. Отдельный элемент определяется своим индексом. Обычно векторы обозначаются строчными буквами курсивным полужирным шриф-том, например x. Для обозначения элемента вектора указывается имя векто- ра курсивным шрифтом с подстрочным индексом. Первый элемент вектора x обозначается x 1, второй – x2 и т. д. Необходимо также указать тип хранящихся в векторе чисел. Если каждый элемент вектора принадлежит ℝ, а всего элемен- тов n, то вектор принадлежит декартову произведению n экземпляров ℝ, оно обозначается ℝn. Если требуется явно перечислить элементы вектора, то они записываются в столбик в квадратных скобках:\n--- Страница 46 ---\nСкаляры, векторы, матрицы и тензоры  45 (2.1) Можно считать, что векторам соответствуют точки в пространстве, а каждый элемент – координата вдоль одной из осей. Иногда необходимо обозначить подмножество элементов вектора. В таком слу- чае мы будем указывать в качестве подстрочного индекса множество индексов интересующих элементов. Например, чтобы адресовать элементы x1, x3 и x6, мы определим множество S = {1, 3, 6} и будем писать xS. Для обозначения дополне- ния ко множеству будем использовать знак –. Например, x–1 обозначает вектор, содержащий все элементы x, кроме x1, а x–S – вектор, содержащий все элементы x, кроме x1, x3 и x6. Матрицы. Матрица – это двумерный массив чисел, в котором каждый элемент идентифицируется двумя индексами, а не одним. Обычно матрицы обознача- ются прописными буквами полужирным курсивным шрифтом, например A. Если матрица вещественных чисел A имеет высоту m и ширину n, то говорят, что A ∈ ℝm×n. Элементы матрицы обычно обозначаются светлым курсивным шрифтом, а индексы перечисляются через запятую. Например, A1, 1 – элемент A в левом верхнем углу, а Am, n – в правом нижнем. Для адресации всех элемен- тов в одной строке мы указываем номер этой строки i, а вместо номера столб- ца – двоеточие, например Ai, : обозначает i-ю строку A. Аналогично A:, i обозна- чает i-й столбец A. Если требуется явно поименовать элементы матрицы, то мы записываем их в виде прямоугольной таблицы, заключенной в квадратные скобки: (2.2) Иногда требуется индексировать матричные выражения, не обозначенные од-ной буквой. Тогда нижние индексы ставятся после всего выражения. Напри-мер, f(A) i, j обозначает элемент в позиции (i, j) матрицы, полученной примене- нием функции f к матрице A. Тензоры. Бывает, что нужен массив размерности, большей 2. В общем случае массив чисел в узлах равномерной сетки с произвольным числом осей назы- вается тензором. Тензор с именем «A» будет обозначаться таким шрифтом: A, а его элемент в позиции (i, j, k) – Ai, j, k. Важной операцией над матрицами является транспонирование. Транспонирован- ной называется матрица, отраженная относительно главной диагонали, идущей из левого верхнего угла направо и вниз. На рис. 2.1 показано графическое изображение этой операции. Результат транспонирования матрицы A обозначается A ⏉ и формаль- но определяется следующим образом: (A⏉)i, j = Aj, i. (2.3) Векторы можно считать матрицами с одним столбцом. Тогда результатом транс- понирования вектора будет матрица с одной строкой. Иногда мы будем записывать\n--- Страница 47 ---\n46  Линейная алгебра вектор прямо в основном тексте в виде матрицы-строки, тогда транспонирование преобразует его в стандартный вектор-столбец, например: x = [x1, x2, x3]⏉. Скаляр можно рассматривать как матрицу из одного элемента. Это значит, что ре- зультатом транспонирования скаляра является он сам: a = a⏉. Рис. 2.1  Транспонирование матрицы можно рассматривать как отражение относительно главной диагонали Матрицы одинакового размера можно складывать поэлементно: C = A + B означа- ет, что Ci, j = Ai, j + Bi, j. Определены также операции сложения матрицы со скаляром и умножения матри- цы на скаляр. Для этого нужно произвести соответствующую операцию для каждого элемента матрицы: D = a · B + c означает, что Di, j = a · Bi, j + c. В контексте глубокого обучения применяется также не совсем традиционная но- тация. Мы определяем операцию сложения матрицы и вектора, дающую матрицу: C = A + b означает, что Ci, j = Ai, j + bj. Иными словами, вектор b прибавляется к каждой строке матрицы. Такая сокращенная запись позволяет обойтись без определения мат-рицы, в которой каждая строка содержит вектор b. Это неявное копирование b сразу в несколько мест называется укладыванием (broadcasting). 2.2. Умножение матриц и векторов Одна из самых важных операций над матрицами – перемножение двух матриц. Про- изведением матриц A и B также является матрица, C. Она определена, только если число столбцов A равно числу строк B. Если A имеет размер m×n, а B – размер n×p, то C будет иметь размер m×p. Для обозначения произведения имена матриц записы- ваются подряд, например: С = AB. (2.4) Произведение определяется следующим образом: (2.5) Отметим, что обычное произведение двух матриц получается не в результате по- элементного перемножения. Но такая операция тоже существует – она называется произведением Адамара и обозначается A ⊙ B. Скалярным произведением двух векторов x и y одинаковой размерности называ- ется произведение матриц x⏉y. Таким образом, элемент Ci, j матрицы C = AB является скалярным произведением i-й строки A и j-го столбца B. Операции над матрицами обладают рядом полезных свойств, упрощающих их ма- тематический анализ. Например, операция умножения дистрибутивна относительно сложения:\n--- Страница 48 ---\nЕдиничная и обратная матрица  47 A(B + C) = AB + AC . (2.6) Она также ассоциативна: A(BC) = (AB)C. (2.7) В отличие от умножения скаляров, умножение матриц не коммутативно (равен- ство AB = BA справедливо не всегда). Но скалярное произведение векторов комму- тативно: x⏉y = y⏉x. (2.8) Операции транспонирования и умножения связаны простой формулой: (AB)⏉ = B⏉A⏉. (2.9) Отсюда следует доказательство тождества (2.8), поскольку скалярное произведе- ние – это скаляр и, значит, совпадает с результатом транспонирования: x⏉y = (x⏉y)⏉ = y⏉x. (2.10) Поскольку эта книга – не учебник по линейной алгебре, мы не станем приводить полный список полезных свойств матричного произведения, а просто сообщим, что их еще очень много. Теперь мы знаем о принятых в линейной алгебре обозначениях достаточно, для того чтобы записать систему линейных уравнений: Ax = b, (2.11) где A ∈ ℝm×n – известная матрица, b ∈ ℝm – известный вектор, а x ∈ ℝn – неизвестный вектор, элементы которого, xi, мы хотим найти. Каждая строка A и соответственный элемент b дают одно ограничение. Уравнение (2.11) можно переписать в виде: A1, : x = b1 (2.12) A2, : x = b2 (2.13) … (2.14) Am, : x = bm (2.15) или даже в еще более явном виде: A1, 1x1 + A1, 2x2 + … + A1, nxn = b1 (2.16) A2, 1x1 + A2, 2x2 + … + A2, nxn = b2 (2.17) … (2.18) Am, 1x1 + Am, 2x2 + … + Am, nxn = bm (2.19) Нотация умножения матрицы на вектор позволяет записывать такие уравнения более компактно. 2.3. Единичная и обратная матрица В линейной алгебре определена операция обращения матриц, которая позволяет ана- литически решить уравнение (2.11) для многих значений A. Чтобы описать операцию обращения, мы должны сначала определить единичную матрицу. Так называется матрица, которая при умножении на любой вектор оставля-\n--- Страница 49 ---\n48  Линейная алгебра ет этот вектор без изменения. Единичную матрицу, сохраняющую n-мерные векторы, будем обозначать In. Формально говоря, In ∈ ℝn×n и ∀x ∈ ℝn, Inx = x. (2.20) Единичная матрица устроена просто: все элементы главной диагонали равны еди- нице, а все остальные – нулю. Пример приведен на рис. 2.2. Рис. 2.2  Пример единичной матрицы I3 Матрица, обратная к A, обозначается A–1 и по определению удовлетворяет сле- дующему соотношению: A–1A = In. (2.21) Теперь для решения уравнения (2.11) нужно проделать следующие действия: Ax = b ; (2.22) A–1Ax = A–1b; (2.23) Inx = A–1b; (2.24) x = A–1b. (2.25) Разумеется, эта процедура предполагает, что матрицу A–1 можно найти. В следую- щем разделе мы обсудим условия существования обратной матрицы. В случае, когда A–1 существует, для ее нахождения в замкнутой форме можно при- менить один из нескольких алгоритмов. Теоретически один раз найденную обрат- ную матрицу можно использовать многократно для решения уравнения с разными значениями b. Однако на практике A–1 редко используется в программах. Поскольку матрицу A–1 можно представить в компьютере лишь с ограниченной точностью, ал- горитмы, в которых используется значение b, обычно дают более точные оценки x. 2.4. Линейная зависимость и линейная оболочка Для существования A–1 уравнение (2.11) должно иметь единственное решение для любого значения b. Бывает и так, что система уравнений не имеет ни одного реше- ния или имеет бесконечно много решений для некоторых значений b. Но никогда не может быть так, что система имеет конечное число решений, большее 1; если x и y – решения, то z = αx + (1 – α)y (2.26) тоже решение при любом вещественном α. Чтобы проанализировать, сколько решений имеет уравнение, представим себе, что столбцы A определяют различные направления от начала координат (точки, соответ- ствующей вектору, все элементы которого равны нулю), а затем подумаем, сколько\n--- Страница 50 ---\nЛинейная зависимость и линейная оболочка  49 есть способов достичь точки b. Тогда элемент xi определяет, как далеко следует прой- ти в направлении столбца i: (2.27) В общем случае такое выражение называется линейной комбинацией. Формально для получения линейной комбинации некоторого множества векторов {v(1), …, v(n)} нужно умножить каждый вектор v(i) на скалярный коэффициент и сложить резуль- таты: (2.28) Линейной оболочкой множества векторов называется множество всех векторов, представимых в виде их линейных комбинаций. Таким образом, чтобы определить, имеет ли уравнение Ax = b решение, нужно про- верить, входит ли b в линейную оболочку столбцов матрицы A. Эта линейная оболоч- ка называется пространством столбцов, или областью значений матрицы A. Итак, чтобы система Ax = b имела решение для любого b ∈ ℝm, необходимо, чтобы пространство столбцов A совпадало с ℝm. Если в ℝm существует точка b, не принад- лежащая пространству столбцов, то для такого значения b система не будет иметь решения. Из требования о совпадении пространства столбцов A с ℝm сразу следует, что в A должно быть по меньшей мере m столбцов, т. е. n ≥ m. Иначе размерность про- странства столбцов была бы меньше m. Рассмотрим, к примеру, матрицу 3×2. Правая часть b имеет размерность 3, а размерность x равна всего 2, поэтому путем изменения x мы в лучшем случае сможем замести двумерную плоскость в ℝ3. Уравнение будет иметь решение тогда и только тогда, когда b лежит в этой плоскости. Условие n ≥ m необходимо, чтобы система имела решение для любой правой части, но недостаточно, поскольку некоторые столбцы могут быть избыточны. Рассмотрим матрицу 2×2, в которой оба столбца одинаковы. Ее пространство столбцов такое же, как у матрицы 2×1, содержащей только один экземпляр повторяющегося столбца. Иными словами, пространство столбцов – прямая, не покрывающая все ℝ2, несмотря на то что столбцов два. Такой вид избыточности называется линейной зависимостью. Множество векто- ров называется линейно независимым, если ни один вектор из этого множества не является линейной комбинацией других. Если добавить во множество вектор, яв-ляющийся линейной комбинацией каких-то других, то линейная оболочка исходно-го множества не пополнится новыми точками. Следовательно, для того чтобы про-странство столбцов матрицы совпадало со всем пространством ℝ m, матрица должна содержать, по меньшей мере, один набор m линейно независимых столбцов. Это необ- ходимое и достаточное условие существования у уравнения (2.11) решения для лю- бого значения b. Отметим, что в условии говорится о наличии в точности m линейно независимых столбцов в наборе, а не хотя бы m. Ни один набор m-мерных векторов не может содержать более m линейно независимых векторов, но матрица, имеющая более m столбцов, может содержать несколько таких наборов. Для существования обратной матрицы необходимо еще, чтобы уравнение (2.11) имело не более одного решения для каждого значения b. Это означает, что в матрице может быть не больше m столбцов, иначе существовало бы более одного способа па- раметризовать каждое решение.\n--- Страница 51 ---\n50  Линейная алгебра Собирая все вместе, мы заключаем, что матрица должна быть квадратной, т. е. m = n, и что ее столбцы должны быть линейно независимы. Квадратная матрица с ли- нейно зависимыми столбцами называется вырожденной (особенной, сингулярной). Если A не квадратная или квадратная, но вырожденная, то решить уравнение все- таки можно, но метод обращения матрицы не подойдет. До сих пор при обсуждении обратных матриц мы имели в виду умножение слева. Но можно также определить матрицу, обратную относительно умножения справа: AA–1 = I. (2.29) Для квадратных матриц обе обратные матрицы совпадают. 2.5. Нормы Иногда требуется получить длину вектора. В машинном обучении для измерения длины применяются функции, называемые нормами. Норма Lp определяется сле- дующим образом: (2.30) для p ∈ ℝ, p ⩾ 1. Нормы, в т. ч. и норма Lp, – это функции, отображающие векторы на неотрицатель- ные числа. Интуитивно норма вектора x измеряет расстояние от точки x до начала координат. Более строго, нормой называется любая функция f, обладающая следую- щими свойствами: f(x) = 0 ⟹ x = 0; f(x + y) ⩽ f(x) + f(y) (неравенство треугольника); ∀α ∈ ℝ f(αx) = | α|f(x). Норма L2 называется евклидовой нормой, это просто евклидово расстояние от на- чала координат до точки, определяемой вектором x. Норма L2 применяется в машин- ном обучении так часто, что ее обозначают просто || x||, опуская надстрочный индекс 2. Кроме того, длину вектора принято измерять как квадрат нормы L2, который можно записать в виде x⏉x. Квадрат нормы L2 удобнее самой нормы с точки зрения математических выкладок и вычислений. Например, частная производная квадрата нормы L2 по каждому эле- менту x зависит только от этого элемента, тогда как производные самой нормы L2 за- висят от всего вектора в целом. Во многих контекстах квадрат нормы L2 нежелателен, потому что он слишком медленно растет вблизи начала координат. В некоторых при- ложениях машинного обучения важно различать элементы, в точности равные нулю и мало отличающиеся от нуля. В таких случаях мы прибегаем к функции, которая всюду растет с одинаковой скоростью, но сохраняет математическую простоту: норме L1. Норму L1 можно записать в виде: (2.31) Эта норма часто используется в машинном обучении, когда важно различать ну- левые и ненулевые элементы. Всякий раз как элемент вектора x отдаляется от 0 на ε, норма L1 увеличивается на ε.\n--- Страница 52 ---\nСпециальные виды матриц и векторов  51 Иногда длина вектора измеряется количеством его ненулевых элементов. Некото- рые авторы называют такую функцию «нормой L0», но такая терминология некоррек- тна. Количество ненулевых элементов вектора нормой не является, поскольку при умножении вектора на α это количество не меняется. Зачастую вместо подсчета не- нулевых элементов используют норму L1. В машинном обучении также часто возникает норма L∞, которую еще называют максимальной нормой. Она определяется как максимальное абсолютное значение элементов вектора: (2.32) Иногда возникает необходимость оценить размер матрицы. В контексте глубокого обучения для этого обычно применяют норму Фробениуса: (2.33) аналогичную норме L2 вектора. Скалярное произведение двух векторов можно выразить через нормы: x⏉y = ||x||2 ||y||2 cosθ, (2.34) где θ – угол между x и y. 2.6. Специальные виды матриц и векторов Некоторые частные случаи матриц и векторов особенно полезны. В диагональной матрице все элементы, кроме находящихся на главной диагона- ли, равны нулю. Точнее, матрица D называется диагональной, если Di, j = 0 для всех i ≠ j. Примером диагональной матрицы служит единичная матрица, в которой все эле- менты на главной диагонали равны 1. Квадратная диагональная матрица, диагональ которой описывается вектором v, обозначается diag(v). Диагональные матрицы пред- ставляют особый интерес, потому что произведение с такой матрицей вычисляется очень эффективно. Чтобы вычислить diag(v)x, нужно умножить каждый элемент xi на vi. Иначе говоря, diag(v)x = v ⊙ x. Обратить квадратную диагональную матрицу тоже просто. Обратная к ней матрица существует, только если все диагональные эле- менты отличны от нуля, и тогда diag(v)–1 = diag([1/v1, …, 1/vn]⏉). Во многих случаях алгоритм машинного обучения можно сформулировать в терминах произвольных матриц, но получить менее накладный (но и менее общий) алгоритм, ограничившись только диагональными матрицами. Диагональная матрица может быть не только квадратной, но и прямоугольной. У неквадратной диагональной матрицы нет обратной, но умножение на нее все рав- но обходится дешево. Произведение диагональной матрицы D на вектор x сводится к умножению каждого элемента x на некоторое число и дописыванию нулей в конец получившегося вектора, если высота D больше ее ширины, или отбрасыванию по- следних элементов вектора в противном случае. Матрица называется симметричной, если совпадает с транспонированной: A = A⏉. (2.35)\n--- Страница 53 ---\n52  Линейная алгебра Симметричные матрицы часто образуются, когда их элементы порождаются не- которой функцией двух аргументов, результат которой не зависит от порядка аргу- ментов. Например, если Ai, j – расстояние от точки i до точки j, то Ai, j = Aj, i, поскольку функция расстояния симметрична. Единичным вектором называется вектор с нормой, равной 1: ||x||2 = 1. (2.36) Говорят, что векторы x и y ортогональны, если x⏉y = 0. Если нормы обоих век- торов не равны 0, то это значит, что угол между векторами составляет 90 градусов. В пространстве ℝ n можно найти не более n взаимно ортогональных ненулевых век- торов. Ортогональные векторы, норма которых равна 1, называются ортонормиро- ванными. Ортогональной называется квадратная матрица, строки и столбцы которой обра- зуют ортонормированные системы векторов: A⏉A = AA⏉ = I. (2.37) Отсюда следует, что A–1 = A⏉. (2.38) Ортогональные матрицы интересны из-за простоты вычисления обратной матри- цы. Обратите внимание на определение ортогональной матрицы: ее строки должны образовывать не просто ортогональную, а ортонормированную систему векторов. Не существует специального термина для матриц, строки и столбцы которых образуют ортогональную, но не ортонормированную систему векторов. 2.7. Спектральное разложение матрицы Многие математические объекты удается лучше понять, если разложить их на со-ставные части или найти какие-то универсальные свойства, не зависящие от способа представления. Например, целые числа можно разложить на простые множители. Способ пред- ставления числа 12 зависит от того, в какой системе счисления оно записано, напри- мер двоичной или десятичной, но в любом случае 12 = 2×2×3. Из этого представле- ния можно вывести ряд полезных свойств, например что 12 не делится на 5 или что любое число, делящееся на 12, делится также на 3. Таким образом, истинная природа целого числа раскрывается в результате раз- ложения его на простые множители. И точно так же мы можем разложить матрицу и тем самым получить о ее функциональных свойствах некоторую информацию, не очевидную из представления матрицы в виде массива элементов. Одно из самых популярных разложений матрицы называется спектральным раз- ложением, или разложением на множество собственных векторов и собственных зна- чений. Собственным вектором квадратной матрицы A называется ненулевой вектор v – такой, что умножение A на v изменяет лишь масштаб v: Av = λv. (2.39)\n--- Страница 54 ---\nСпектральное разложение матрицы  53 Скаляр λ называется собственным значением, соответствующим этому собст- венному вектору. (Можно также искать левые собственные векторы, для которых v⏉A = λv⏉, но обычно нас интересуют только правые собственные векторы.) Если v – собственный вектор A, то собственным будет и вектор sv для любого s ∈ ℝ, s ≠ 0. Более того, вектору sv соответствует то же собственное значение, что и v. По- этому мы обычно ищем только единичные собственные векторы. Пусть матрица A имеет n линейно независимых собственных векторов {v(1), …, v(n)} с собственными значениями {λ1, …, λn}. Образуем из них матрицу V, в которой каждый столбец – это собственный вектор: V = [ v(1), …, v(n)]. А из собственных значений обра- зуем вектор λ = [ λ1, …, λn]⏉. Тогда спектральное разложение матрицы A описывается формулой: A = V diag( λ)V–1. (2.40) Мы видели, что конструирование матриц с заданными собственными значениями и собственными векторами позволяет растягивать пространство в нужных направле- ниях. Но часто бывает нужно разложить имеющуюся матрицу по ее собственным век-торам и собственным значениям. Это помогает анализировать некоторые свойства матрицы точно так же, как разложение целого числа на простые множители помогает понять поведение этого числа. Не у каждой матрицы есть спектральное разложение. Иногда спектральное разложение существует, но состоит из комплексных, а не вещественных чисел. К счастью , в этой книге нам обычно придется иметь дело только с матрицами спе- циального вида, у которых имеется простое разложение. Точнее, у любой симмет- ричной вещественной матрицы все собственные векторы и собственные значения вещественные. A = QΛQ⏉, (2.41) где Q – ортогональная матрица, образованная собственными векторами A, а Λ – диа- гональная матрица. Собственное значение Λi, i ассоциировано с собственным векто- ром в i-м столбце Q, обозначаемым Q:, i. Поскольку Q – ортогональная матрица, мож- но считать, что A масштабирует пространство с коэффициентом λi в направлении v(i). На рис. 2.3 показан пример. Хотя для любой симметричной вещественной матрицы A существует спектральное разложение, это разложение может быть не единственным. Если какие-то два или более собственных векторов имеют одинаковое собственное значение, то любые орто-гональные векторы, принадлежащие их линейной оболочке, также будут собственны-ми векторами A с тем же самым собственным значением, поэтому матрицу Q можно с тем же успехом образовать из этих векторов. По принятому соглашению элементы Λ обычно располагаются в порядке убывания. При таком соглашении спектральное разложение единственно, только если все собственные значения различны. Спектральное разложение может многое рассказать о матрице. Матрица является вырожденной тогда и только тогда, когда у нее есть хотя бы одно нулевое собствен- ное значение. Кроме того, спектральное разложение вещественной симметричной матрицы можно использовать для оптимизации квадратичных форм вида f(x) = x ⏉Ax при условии ||x||2 = 1. Если x – собственный вектор A, то f равно его собственному зна- чению. Максимальное (минимальное) значение f при заданном ограничении равно максимальному (минимальному) собственному значению.\n--- Страница 55 ---\n54  Линейная алгебра До умножения После умножения v(1)v(1)λ1v(1) λ2v(1) x1x1 x′1 x′0v(2) v(2)3 2 1 0 –1–2–332 1 0 –1–2–3 –3 –3 –2 –2 –1 –1 0 0 1 1 2 2 3 3 Рис. 2.3  Г еометрический смысл собственных векторов и собственных значений. У матрицы A два ортонормированных собственных вектора: v (1) с собственным значением λ1 и v(2) с собственным значением λ2. (Слева) Множество всех единичных векторов u ∈ R2 изображено в виде единичной окружности. (Справа) Изображено множество точек Au. Наблюдая, во что A переводит единичную окружность, мы можем сделать вывод, что она мас- штабирует пространство в направлении v(i) с коэффициентом λi Матрица, все собственные значения которой положительны, называется положи- тельно определенной. Если же все собственные значения положительны или рав- ны нулю, то матрица называется положительно полуопределенной. Аналогично, если все собственные значения отрицательны, то матрица называется отрицательно определенной, а если отрицательны или равны нулю – то отрицательно полуопре- деленной. Положительно полуопределенные матрицы интересны тем, что для них выполняется неравенство x⏉Ax ≥ 0 при любом x. Положительная определенность до- полнительно гарантирует, что x⏉Ax = 0 ⟹ x = 0. 2.8. Сингулярное разложение В разделе 2.7 мы видели, как разложить матрицу по собственным векторам и собствен- ным значениям. Сингулярное разложение ( singular value decomposition —SVD) – это другой способ разложения матрицы: по сингулярным векторам и сингулярным зна- чениям. SVD несет ту же информацию, что спектральное разложение, но применимо в более общем случае. Сингулярное разложение есть у любой вещественной матрицы, чего не скажешь о спектральном разложении. Например, если матрица не квадратная, то спектральное разложение не определено, поэтому мы вынуждены использовать сингулярное разложение. Напомним, что для получения спектрального разложения матрицы A нужно найти матрицу V собственных векторов и вектор λ собственных значений – такие, что: A = V diag( λ)V–1. (2.42) Сингулярное разложение аналогично, но теперь A записывается в виде произведе- ния трех матриц:\n--- Страница 56 ---\nПсевдообратная матрица Мура–Пенроуза  55 A = UDV⏉. (2.43) Пусть A – матрица m×n. Тогда U должна быть матрицей m×m, D – матрицей m×n, а V – матрицей n×n. Эти матрицы обладают определенными свойствами. Матрицы U и V ортогональ- ные, а матрица D диагональная (при этом необязательно квадратная). Элементы на диагонали D называются сингулярными значениями матрицы A. Столбцы U называются левыми сингулярными векторами, а столбцы V – правыми сингулярными векторами. Сингулярное разложение A можно интерпретировать в терминах спектрального разложения функций A. Левые сингулярные векторы A являются собственными век- торами AA⏉, а правые сингулярные векторы A – собственными векторами A⏉A. Нену- левые сингулярные значения A равны квадратным корням из собственных значений A⏉A (и AA⏉). Но, пожалуй, самое полезное свойство сингулярного разложения – использование его для обобщения операции обращения матриц на неквадратные матрицы, о чем мы и поговорим в следующем разделе. 2.9. Псевдообратная матрица Мура–Пенроуза Операция обращения определена только для квадратных матриц. Допустим, что тре- буется найти левую обратную матрицу B для матрицы A, что позволило бы решить линейное уравнение Ax = y (2.44) путем умножения обеих частей слева на B: x = By (2.45) Единственное отображение A на B возможно не всегда; это зависит от характера задачи. Если высота A больше ширины, то у такого уравнения может не оказаться реше- ний. Если же ширина A больше высоты, то решений может быть много. Операция псевдообращения Мура–Пенроуза позволяет кое-что сделать и в этих случаях. Псевдообратная к A матрица определяется следующим образом: A+ = lim(A⏉A + αI)–1A⏉. α0 (2.46) Применяемые на практике алгоритмы вычисления псевдообратной матрицы осно- ваны не на этом определении, а на формуле A+ = VD+U⏉, (2.47) где U, D и V составляют сингулярное разложение A, а псевдообратная матрица D+ диагональной матрицы D получается путем обращения всех ненулевых диагональ- ных элементов с последующим транспонированием. Если число столбцов A больше числа строк, то решение линейного уравнения, най- денное псевдообращением, – лишь одно из многих возможных. Точнее, будет найдено решение x = A+y с минимальной евклидовой нормой || x||2.\n--- Страница 57 ---\n56  Линейная алгебра Если число строк A больше числа столбцов, то может не оказаться ни одного ре- шения. В таком случае псевдообращение находит такой вектор x, для которого Ax максимально близко к y в терминах евклидовой нормы || Ax – y ||2. 2.10. Оператор следа Оператор следа вычисляет сумму всех диагональных элементов матрицы: (2.48) Этот оператор полезен по многим причинам. Некоторые операции, которые трудно выразить, не прибегая к нотации суммирования, можно записать с помощью произве- дения матриц и оператора следа. Вот, например, как можно переписать определение нормы Фробениуса матрицы: (2.49) Если в выражение входит оператор следа, то открываются возможности преобра- зовывать это выражение, пользуясь различными тождествами. Например, след инва- риантен относительно транспонирования: Tr(A) = Tr( A⏉). (2.50) След квадратной матрицы, представленной в виде произведения сомножителей, инвариантен также относительно перемещения последнего сомножителя в начало, если формы матриц допускают такую операцию: Tr(ABC ) = Tr( CAB ) = Tr( BCA ), (2.51) или в более общем виде: (2.52) Эта инвариантность относительно циклической перестановки имеет место даже тогда, когда меняется форма произведения. Например, если A ∈ ℝm×n, B ∈ ℝn×m, то Tr(AB) = Tr( BA), (2.53) несмотря на то что AB ∈ ℝm×m, а BA ∈ ℝn×n. Полезно также помнить, что след скаляра равен ему самому: a = Tr(a). 2.11. Определитель Определитель квадратной матрицы, обозначаемый det(A ), – это функция, сопо- ставляющая матрице вещественное число. Определитель равен произведению всех собственных значений матрицы. Абсолютную величину определителя можно рас-сматривать как меру сжатия или расширения пространства матрицей. Если опре-делитель равен 0, то пространство полностью сворачивается хотя бы по одному из-мерению, т. е. теряется весь объем. Если определитель равен 1, то преобразование сохраняет объем.\n--- Страница 58 ---\nПример: метод главных компонент  57 2.12. Пример: метод главных компонент Один из простых алгоритмов машинного обучения, метод главных компонент ( prin- cipal components analysis – PCA), можно вывести из основ линейной алгебры. Пусть имеется набор m точек {x(1), …, x(m)} в пространстве ℝn, и мы хотим подверг- нуть их сжатию с потерей информации, т. е. сохранить точки в меньшем объеме па- мяти, возможно, ценой некоторой потери точности. Но хотелось бы свести эти потери к минимуму. Один из способов кодирования точек – представить их в пространстве меньшей размерности. Для каждой точки x(i) ∈ ℝn мы ищем соответствующий ей кодовый вектор c(i) ∈ ℝl. Если l меньше n, то для хранения кодированных точек потребуется меньше па- мяти, чем для исходных. Мы хотим найти функцию кодирования f(x) = c и функцию декодирования, реконструирующую исходную точку по кодированной, x ≈ g(f(x)). Алгоритм PCA определяется выбором функции декодирования. Чтобы упростить декодер, мы будем использовать умножение матриц для обратного перехода в ℝn. Пусть g(c) = Dc, где D ∈ ℝn×l – матрица, определяющая декодирование. Вычисление оптимального декодера может оказаться трудной задачей. Для ее упрощения в методе PCA на матрицу D налагается ограничение: ее столбцы должны быть ортогональны (но это не означает, что D – ортогональная матрица в определен- ном выше смысле, разве что l = n). У поставленной задачи бесконечно много решений, поскольку мы можем увели- чить масштаб D:, i, одновременно пропорционально уменьшив ci для всех точек. Для получения единственного решения потребуем еще, чтобы норма всех столбцов D была равна 1. Чтобы превратить смутную идею в алгоритм, нужно первым делом решить, как генерировать оптимальную кодовую точку c* для каждой исходной точки x. Один из способов – минимизировать расстояние между x и ее реконструкцией g(c*). Для из- мерения этого расстояния применим какую-нибудь норму. В алгоритме главных ком- понент берется норма L2: (2.54) Мы можем использовать квадрат нормы L2, а не ее саму, потому что минимум до- стигается при одном и том же значении c, т. к. норма L2 неотрицательна, а операция возведения в квадрат – монотонно возрастающая для неотрицательных аргументов. (2.55) Минимизируемую функцию можно переписать в виде: (x – g(c))⏉(x – g(c)) (2.56) (по определению нормы L2 из формулы (2.30)) = x⏉x – x⏉g(c) – g(c)⏉x + g(c)⏉g(c) (2.57) (в силу дистрибутивности) = x⏉x – 2x⏉g(c) + g(c)⏉g(c) (2.58) (поскольку результат транспонирования скаляра g(c)⏉x совпадает с ним самим).\n--- Страница 59 ---\n58  Линейная алгебра Снова изменим минимизируемую функцию, опустив первый член, не зависящий от c: – 2x⏉g(c) + g(c)⏉g(c). (2.59) Теперь подставим сюда определение g(c): – 2x⏉Dc + c⏉D⏉Dc (2.60) – 2x⏉Dc + c⏉Ilc (2.61) (в силу ограничений на ортогональность и нормированность D) – 2x⏉Dc + c⏉c. (2.62) Для решения этой задачи оптимизации мы можем воспользоваться векторным ма- тематическим анализом (если вы не знаете, что это такое, обратитесь к разделу 4.3): ∇с(–2x⏉Dc + c⏉c) = 0 (2.63) – 2D⏉x + 2c = 0 (2.64) с = D⏉x. (2.65) Получается очень эффективный алгоритм: для оптимального кодирования x до- статочно всего лишь операций над матрицами и векторами, т. е. функция кодирова- ния выглядит так: f(x) = D⏉x. (2.66) Еще раз применив умножение на матрицу, мы сможем определить операцию ре- конструкции в алгоритме PCA: r(x) = g(f(x)) = DD⏉x. (2.67) Далее следует выбрать кодировочную матрицу D. Для этого вернемся к идее мини- мизации расстояния в смысле нормы L2 между исходными и реконструированными точками. Поскольку для декодирования всех точек используется одна и та же матрица D, мы больше не можем рассматривать точки изолированно, а должны минимизиро- вать норму Фробениуса матрицы ошибок, вычисленных для всех измерений и точек: при условии D⏉D = Il. (2.68) Для вывода алгоритма нахождения D* сначала рассмотрим случай l = 1. Тогда D – это просто одиночный вектор, который мы обозначим d. Подставляя (2.67) в (2.68) и заменяя D на d, мы сводим задачу к такой: ||x(i) – dd⏉x(i)||2 2 при условии ||d ||2 = 1. (2.69) Этот прямой результат подстановки – не самый красивый способ записи уравне- ния. Скалярное значение d⏉x(i) находится справа от вектора d. Но обычно скалярные коэффициенты записываются слева от вектора, поэтому перепишем выражение в та- ком виде:\n--- Страница 60 ---\nПример: метод главных компонент  59 ||x(i) – d⏉x(i)d||2 2 при условии ||d ||2 = 1. (2.70) или, воспользовавшись тем, что операция транспонирования не изменяет скаляр: ||x(i) – x(i)⏉dd||2 2 при условии ||d ||2 = 1. (2.71) Читателю следует стремиться к свободному владению такими косметическими преобразованиями. Теперь было бы полезно переформулировать задачу в терминах одной матрицы примеров, а не суммы по отдельным векторам. Это позволит записать ее более ком- пактно. Обозначим X ∈ ℝm×n матрицу, образованную всеми векторами, рассматривае- мыми как строки, т. е. Xi, : = x(i)⏉. Тогда уравнение (2.71) можно переписать в виде: ||X – Xdd⏉||2 F при условии d⏉d = 1. (2.72) Забудем ненадолго об ограничении и упростим часть, содержащую норму Фробе- ниуса: ||X – Xdd⏉||F2 (2.73) = Tr((X – Xdd⏉)⏉(X – Xdd⏉)) (2.74) (в силу формулы (2.49)) = Tr(X⏉X – X⏉Xdd⏉ – dd⏉X⏉X + dd⏉X⏉Xdd⏉) (2.75) = Tr(X⏉X) – Tr(X⏉Xdd⏉) – Tr(dd⏉X⏉X) + Tr(dd⏉X⏉Xdd⏉) (2.76) = – Tr(X⏉Xdd⏉) – Tr(dd⏉X⏉X) + Tr(dd⏉X⏉Xdd⏉) (2.77) (поскольку члены, не содержащие d, на влияют на arg min) = – 2Tr(X⏉Xdd⏉) + Tr(dd⏉X⏉Xdd⏉) (2.78) (поскольку матрицы внутри оператора следа можно циклически переставлять, фор- мула (2.52)) = – 2Tr(X⏉Xdd⏉) + Tr(X⏉Xdd⏉dd⏉) (2.79) (еще раз применяя то же свойство).Теперь снова вспомним об ограничении: – 2Tr(X⏉Xdd⏉) + Tr(X⏉Xdd⏉dd⏉) при условии d⏉d = 1 (2.80) = – 2Tr(X⏉Xdd⏉) + Tr(X⏉Xdd⏉) при условии d⏉d = 1 (2.81) (в силу ограничения) = – Tr(X⏉Xdd⏉) при условии d⏉d = 1 (2.82) = Tr(X⏉Xdd⏉) при условии d⏉d = 1 (2.83) = Tr(d⏉X⏉Xd) при условии d⏉d = 1 (2.84)\n--- Страница 61 ---\n60  Линейная алгебра Эту задачу оптимизации можно решить с помощью спектрального разложения: оптимальным будет собственный вектор матрицы X⏉X с наибольшим собственным значением. Этот вывод применим только к случаю l = 1 и восстанавливает лишь первую глав- ную компоненту. В более общем случае, когда требуется восстановить базис главных компонент, матрица D определяется l собственными векторами с наибольшими соб- ственными значениями. Доказательство можно провести по индукции, и мы оставля- ем его читателю в качестве упражнения. Линейная алгебра – один из важнейших разделов математики, необходимых для понимания машинного обучения. Другой раздел, без которого машинное обучение немыслимо, – теория вероятностей, к которой мы и переходим.",
      "debug": {
        "start_page": 45,
        "end_page": 61
      }
    },
    {
      "name": "Глава 3. Теория вероятностей и теория информации 61",
      "content": "--- Страница 62 --- (продолжение)\nГлава 3 Теория вероятностей и теория информации В этой главе мы изложим основы теории вероятностей и теории информации. Теория вероятностей – это раздел математики, в котором рассматриваются недос- товерные утверждения. Она дает средства количественно описать недостоверность, а также аксиомы для вывода новых недостоверных утверждений. В применении к искусственному интеллекту теория вероятностей используется в основном двумя способами. Во-первых, ее правила говорят нам, как должна рассуждать система ИИ, поэтому мы проектируем алгоритмы, которые вычисляют или аппроксимируют раз-личные выражения, полученные на основе теории вероятностей. Во-вторых, теорию вероятностей и математическую статистику можно применить для теоретического анализа поведения предлагаемых систем ИИ. Теория вероятностей лежит в основе многих научно-технических дисциплин. Эта глава включена для того, чтобы читатели с подготовкой в области программной инжене- рии, плохо знакомые с теорией вероятностей, понимали изложенный в книге материал. Если теория вероятностей позволяет формулировать недостоверные утверждения и рассуждать в условиях неопределенности, то теория информации дает возможность количественно оценить меру неопределенности распределения вероятности. Если вы уже знакомы с теорией вероятностей и теорией информации, то можете сразу перейти к разделу 3.14, в котором описываются графы, применяемые для опи- сания структурных вероятностных моделей в машинном обучении. Если же вы со- всем ничего не знаете об этих темах, то изложенного в этой главе материала должно хватить для успешного выполнения исследовательских проектов в области глубокого машинного обучения, но мы все же рекомендуем почитать дополнительные источни-ки, например книгу Jaynes (2003). 3.1. Зачем нужна вероятность? Во многих разделах информатики имеют дело в основном с детерминированными сущностями. Обычно программист может предполагать, что процессор выполня-ет машинные команды без ошибок. Аппаратные ошибки бывают, но они настолько редки, что в большинстве программ учитывать такую возможность необязательно. Однако если большинство теоретиков и инженеров-программистов работант в срав- нительно стерильных и определенных условиях, то почему же в машинном обучении так часто используется теория вероятностей?\nГлава 3 Теория вероятностей и теория информации В этой главе мы изложим основы теории вероятностей и теории информации. Теория вероятностей – это раздел математики, в котором рассматриваются недос- товерные утверждения. Она дает средства количественно описать недостоверность, а также аксиомы для вывода новых недостоверных утверждений. В применении к искусственному интеллекту теория вероятностей используется в основном двумя способами. Во-первых, ее правила говорят нам, как должна рассуждать система ИИ, поэтому мы проектируем алгоритмы, которые вычисляют или аппроксимируют раз-личные выражения, полученные на основе теории вероятностей. Во-вторых, теорию вероятностей и математическую статистику можно применить для теоретического анализа поведения предлагаемых систем ИИ. Теория вероятностей лежит в основе многих научно-технических дисциплин. Эта глава включена для того, чтобы читатели с подготовкой в области программной инжене- рии, плохо знакомые с теорией вероятностей, понимали изложенный в книге материал. Если теория вероятностей позволяет формулировать недостоверные утверждения и рассуждать в условиях неопределенности, то теория информации дает возможность количественно оценить меру неопределенности распределения вероятности. Если вы уже знакомы с теорией вероятностей и теорией информации, то можете сразу перейти к разделу 3.14, в котором описываются графы, применяемые для опи- сания структурных вероятностных моделей в машинном обучении. Если же вы со- всем ничего не знаете об этих темах, то изложенного в этой главе материала должно хватить для успешного выполнения исследовательских проектов в области глубокого машинного обучения, но мы все же рекомендуем почитать дополнительные источни-ки, например книгу Jaynes (2003). 3.1. Зачем нужна вероятность? Во многих разделах информатики имеют дело в основном с детерминированными сущностями. Обычно программист может предполагать, что процессор выполня-ет машинные команды без ошибок. Аппаратные ошибки бывают, но они настолько редки, что в большинстве программ учитывать такую возможность необязательно. Однако если большинство теоретиков и инженеров-программистов работант в срав- нительно стерильных и определенных условиях, то почему же в машинном обучении так часто используется теория вероятностей?\n--- Страница 63 ---\n62  Теория вероятностей и теория информации Машинное обучение по необходимости имеет дело с недостоверными, а иногда и стохастическими (недетерминированными) величинами. Недостоверность и неде- терминированность проистекают из многих источников. Теоретические аргументы в пользу количественной оценки недостоверности с помощью теории вероятностей приводились уже в 1980-х годах. Многие перечисленные ниже аргументы взяты из работы Pearl (1988) или навеяны ей. Почти во всех отраслях знания требуется возможность рассуждать в присутствии неопределенности. На самом деле, если не считать математических утверждений, кото-рые истинны по определению, трудно привести пример какого-нибудь высказывания, которое было бы абсолютно верным, или события, которое произойдет гарантированно. Существуют три источника неопределенности:1) стохастичность, присущая моделируемой системе. Например, в большинстве интерпретаций квантовой механики динамика субатомных частиц описывает-ся в вероятностных терминах. Можно также сконструировать теоретические сценарии с постулированной случайной динамикой, например гипотетическая карточная игра в предположении, что карты перетасованы случайно; 2) неполнота наблюдаемых данных. Даже детерминированная система может казать-ся стохастической, если мы не в состоянии наблюдать все переменные, описываю- щие ее поведение. Например, в парадоксе Монти Холла участник игрового шоу выбирает одну из трех дверей и получает скрытый за ней приз. За двумя дверьми находятся козы, за третьей – автомобиль. Исход при любом выборе участника де- терминирован, но, с точки зрения самого участника, исход неопределенный; 3) неполнота модели. Если используется модель, которая отбрасывает часть наблю даемой информации, то отброшенная информация приводит к недосто- верности полученных от модели предсказаний. Допустим, к примеру, что мы конструируем робота, который способен точно фиксировать положения всех находящихся поблизости от него объектов. Если робот дискретизирует прост-ранство, стремясь спрогнозировать положения объектов в будущем, то сам акт дискретизации уже делает информацию о положении объектов недостоверной: каждый объект может находиться в дискретной области, окружающей занимае- мое им место в пространстве. Во многих случаях практичнее использовать простое неопределенное правило, чем сложное определенное, даже если истинное правило детерминировано, и систе- ма моделирования позволяет его адекватно представить. Например, простое правило «Большинство птиц умеет летать» легко формулируется и в общем случае полезно, тогда как правило «Птицы умеют летать, за исключением очень молодых птенцов, которые еще не научились летать, больных и травмированных птиц, которые утрати- ли способность летать, нелетающих птиц, включая казуара, страуса и киви…» трудно сформулировать, сопровождать и передавать другим людям, и даже после всех уси- лий оно оказывается хрупким и уязвимым к неточностям. Хотя понятно, что необходимы средства для представления недостоверности и рас- суждений в условиях неопределенности, не сразу очевидно, что теория вероятностей располагает всеми инструментами, которые нужны в приложениях искусственного интеллекта. Первоначально теория вероятностей разрабатывалась для анализа час-тоты событий. Легко видеть, как применить ее для изучения таких событий, как сдача карт в покере. Подобные события зачастую повторяемы. Говоря, что вероятность не- которого исхода равна p, мы имеем в виду, что если повторить эксперимент (напри-\n--- Страница 64 ---\nРаспределения вероятности  63 мер, сдачу карт) бесконечное число раз, то доля таких исходов составит p. Не понят- но, как такое рассуждение может быть применимо к неповторяемым событиям. Когда врач осматривает пациента и говорит, что у него грипп с вероятностью 40 процентов, то это означает что-то совсем другое – мы не можем создать бесконечно много копий пациента и не имеем никаких оснований утверждать, что у разных копий будут такие же симптомы, но различные заболевания. В случае медицинской диагностики веро- ятность описывает степень веры, причем 1 означает абсолютную уверенность в том, что у пациента грипп, а 0 – абсолютную уверенность в том, что у пациента нет гриппа. Первый вид вероятности, связанный с частотой возникновения событий, называется частотной вероятностью, а второй, связанный с качественным уровнем уверенно- сти, – байесовской вероятностью. Если перечислить несколько свойств, которыми в согласии со здравым смыслом долж- ны обладать рассуждения о недостоверности, то окажется, что единственный способ удовлетворить эти свойства состоит в том, чтобы рассматривать поведение байесовских вероятностей в точности так же, как частотных. Например, при вычислении вероятности получения определенной комбинации в покере используются те же формулы, что при вычислении вероятности заболевания при наличии определенных симптомов. Подроб- нее о том, почему из небольшого набора основанных на здравом смысле предположений вытекают одни и те же аксиомы для обоих видов вероятности, см. Ramsey (1926). Вероятность можно рассматривать как обобщение логики на рассуждения в усло- виях неопределенности. Логика дает нам набор формальных правил, позволяющих определить, истинно некоторое высказывание или ложно, в зависимости от предпо- ложения об истинности или ложности других высказываний. Теория вероятностей предлагает набор формальных правил для определения правдоподобия высказыва-ния при условии правдоподобия других высказываний. 3.2. Случайные величины Случайной величиной называется величина, случайно принимающая различные значения. Обычно сама случайная величина обозначается строчной буквой прямым шрифтом, а ее значения – строчными курсивными буквами. Например, x 1 и x2 – воз- можные значения случайной величины x. Векторные случайные величины обознача-ются x, а их значения – x. Сама по себе случайная величина – это просто описание возможных состояний, ее можно использовать вместе с распределением вероятности, показывающим, насколько вероятно каждое состояние. Случайные величины бывают дискретными и непрерывными. Дискретная слу- чайная величина может иметь конечное или счетное число состояний. Отметим, что состояния – необязательно целые числа, допускаются также просто именованные со- стояния, с которыми не ассоциировано числовое значение. С непрерывной случай- ной величиной ассоциированы вещественные значения. 3.3. Распределения вероятности Распределение вероятности описывает, с какой вероятностью случайная величина или множество случайных величин принимает каждое возможное значение. Способ задания распределения вероятности зависит от того, является случайная величина непрерывной или дискретной.\n--- Страница 65 ---\n64  Теория вероятностей и теория информации 3.3.1. Дискретные случайные величины и функции вероятности Распределение вероятности дискретной величины может быть описано с помощью функции вероятности. Обычно функции вероятности обозначаются прописной буквой P. Часто со случайными величинами ассоциируются разные функции ве- роятности, и читатель должен понимать, о какой функции идет речь, ориентируясь на природу случайной величины, а не на имя функции; P(x) обычно не то же самое, что P (y). Функция вероятности отображает состояние случайной величины на вероятность того, что случайная величина находится в этом состоянии. Вероятность, что x = x, обозначается P(x), причем вероятность 1 означает, что событие x = x достоверно, а ве- роятность 0 – что оно невозможно. Иногда, чтобы недвусмысленно указать, какая функция вероятности используется, мы будем записывать имя случайной величины явно: P(x = x). В некоторых случаях мы сначала определяем случайную величину, а затем используем знак ∼ для обозначения ее распределения: x ~ P(x). Функции вероятности могут применяться сразу к нескольким величинам. Такая функция вероятности многих переменных называется совместным распределением вероятности. Запись P(x = x, y = y) означает, что x = x и y = y одновременно. Для крат- кости мы иногда будем писать просто P(x, y). Чтобы функция P случайной величины могла рассматриваться как функция веро- ятности, она должна удовлетворять следующим условиям. Областью определения P является множество всех возможных состояний x. ∀x ∈ x 0 ≤ P(x) ≤ 1. Невозможное событие имеет вероятность 0, и никакое со- стояние не может быть менее вероятно. Аналогично событие, которое произой-дет наверняка, имеет вероятность 1, и никакое состояние не может быть более вероятно. ∑ x∈x P(x) = 1. Это равенство называется свойством нормировки. Не будь его, можно было бы получить значение, большее 1, при вычислении вероятности одного из многих событий. Рассмотрим, к примеру, одиночную дискретную случайную величины x с k состоя- ниями. Мы можем задать равномерное распределение x – когда все состояния равно- вероятны, – определив функцию вероятности следующим образом: (3.1) для всех i. Это определение удовлетворяет всем требованиям к функции вероятности. Значение 1/k положительно, потому что k – положительное число. Кроме того, (3.2) так что распределение правильно нормировано. 3.3.2. Непрерывные случайные величины и функции плотности вероятности Распределение непрерывных случайных величин описывается функцией плотности вероятности (ФПВ), а не функцией вероятности. Такая функция p должна обладать следующими свойствами.\n--- Страница 66 ---\nУсловная вероятность  65 Область определения p – множество всех возможных состояний x. ∀x ∈ x, p(x) ≥ 0; отметим, что мы не требуем выполнения условия p(x) ≤ 1. ∫p(x)dx = 1. Функция плотности вероятности p(x) определяет не вероятность конкретного со- стояния, а вероятность попадания в бесконечно малую окрестность размера δx, кото- рая равна p(x)δx. Для нахождения вероятности множества точек следует проинтегрировать функ- цию плотности. Точнее, вероятность, что x принадлежит множеству 𝕊, равна инте- гралу p(x) по этому множеству. В одномерном случае вероятность принадлежности x отрезку [a, b] равна ∫[a, b] p(x)dx. В качестве примера рассмотрим равномерное распределение непрерывной случай- ной величины на отрезке вещественных чисел. Для этого нужно определить функции u(x; a, b), где a и b – концы отрезка и b > a. Нотация «;» означает «параметризовано», т. е. x является аргументом функции, а a и b – ее параметрами. Чтобы гарантировать, что вся масса вероятности находится внутри отрезка, положим u(x; a, b) = 0 для всех x ∉ [a, b], а для точек внутри [a, b] определим u(x; a, b) = 1/(b – a). Легко видеть, что так определенная функция всюду неотрицательна. Кроме того, ее интеграл равен 1. Мы часто пишем x ∼ U(a, b), желая сказать, что x равномерно распределена на [ a, b]. 3.4. Маргинальное распределение вероятности Иногда известно распределение вероятности множества величин, а мы хотим узнать распределение вероятности подмножества этих величин. Оно называется маргиналь- ным распределением вероятности. Предположим, к примеру, что есть две дискретные случайные величины x и y и из- вестна функция P(x, y). Для нахождения P(x) можно воспользоваться прави- лом сложения: (3.3) Название «маргинальное распределение» напоминает о процессе вычисления маргинальных вероятностей на полях1 листа бумаги. Если записать значения P(x, y) в ячейках таблицы, строки которой соответствуют значениям x, а столбцы – значе- ниям y, то будет естественно просуммировать по каждой строке таблицы и записать сумму P(x) на полях справа от строки. Для непрерывных величин суммирование заменяется интегрированием: (3.4) 3.5. Условная вероятность Часто нас интересует вероятность некоторого события, при условии что произошло какое-то другое событие. Это называется условной вероятностью. Условная вероят- ность того, что y = y при условии, что x = x, записывается в виде P(y = y | x = x) и вы- числяется по формуле: 1 Английское margin – поле. – Прим. перев.\n--- Страница 67 ---\n66  Теория вероятностей и теория информации (3.5) Условная вероятность определена только тогда, когда P(x = x) > 0 . Невозможно вы- числить условную вероятность при условии события, которое не может произойти. Важно не путать условную вероятность с вычислением того, что могло бы произой ти, если бы было предпринято некоторое действие. Условная вероятность того, что человек родом из Германии, если он говорит по-немецки, довольно высока, но если случайно выб ранного человека научить говорить по-немецки, то страна его рождения не изме- нится. Вычисление последствий действия называется запросом о вмешательстве и со- ставляет предмет причинного моделирования, которое в этой книге не рассматривается. 3.6. Цепное правило Любое совместное распределение вероятности нескольких случайных величин мож-но разложить в произведение условных вероятностей одной величины: P(x (1), …, x(n)) = P(x(1))∏n i=2 P(x(i) | x(1), …, x(i–1)). (3.6) Эта формула называется цепным правилом, или правилом умножения вероятно- стей. Она сразу следует из определения условной вероятности (3.5). Применив его дважды, получим: P(a, b, c) = P(a | b, c)P(b, c) P(b, c) = P(b | c)P(c) P(a, b, c) = P(a | b, c)P(b | c)P(c) 3.7. Независимость и условная независимость Две случайные величины x и y называются независимыми, если их совместное рас- пределение вероятности можно представить в виде произведения двух сомножите- лей, один из которых содержит только x, а другой – только y: ∀x ∈ x, y ∈ y, p(x = x, y = y) = p(x = x)p(y = y). (3.7) Две случайные величины x и y называются условно независимыми при условии случайной величины z, если условное распределение вероятности x и y можно сле- дую щим образом представить в виде произведения для любого значения z: ∀x ∈ x, y ∈ y, z ∈ z, p(x = x, y = y | z = z) = p(x = x | z = z)p(y = y | z = z). (3.8) Для обозначения независимости и условной независимости будем применять ком- пактную нотацию: x⊥y означает, что x и y независимы, а x⊥y | z – что x и y условно независимы при условии z. 3.8. Математическое ожидание, дисперсия и ковариация Математическим ожиданием, или ожидаемым значением, функции f(x) относи- тельно распределения вероятности P(x) называется среднее значение f, когда x вы-\n--- Страница 68 ---\nМатематическое ожидание, дисперсия и ковариация  67 бирается из P. Для дискретных величин математическое ожидание вычисляется сум- мированием: (3.9) а для непрерывных – интегрированием: (3.10) Если характер распределения ясен из контекста, то можно просто написать имя случайной величины, по которой вычисляется математическое ожидание: 𝔼x[f(x)]. А если и относительно случайной величины не возникает сомнений, то можно во- обще опустить подстрочный индекс: 𝔼[f(x)]. По умолчанию предполагается, что 𝔼[·] производит усреднение по всем случайным величинам в квадратных скобках. Если не возникает двусмысленности, то квадратные скобки можно опускать. Операция математического ожидания линейна, т. е. 𝔼x[αf(x) + βg(x)] = α𝔼x[f(x)] + β𝔼x[g(x)], (3.11) где α и β не зависят от x. Дисперсия измеряет разброс значений функции случайной величины x с задан- ным распределением вероятности: Var(f(x)) = 𝔼[(f(x) – 𝔼[f(x)])2]. (3.12) Если дисперсия мала, то значения f(x) сгруппированы в окрестности ожидаемого значения. Квадратный корень из дисперсии называется стандартным отклонением. Ковариация дает представление о силе линейной связи между двумя функциями случайных величин, а также о масштабе этих величин: Cov(f(x), g(y)) = 𝔼[(f(x) – 𝔼[f(x)])(g(y) – 𝔼[g(y)])]. (3.13) Если абсолютная величина ковариации высока, то значения различаются очень сильно и одновременно далеки от своих средних. Если ковариация положительна, обе величины принимают большие значения одновременно, а если отрицательна, то в тот момент, когда одна величина принимает большие значения, другая принимает малые значения (и наоборот). Другие метрики, например корреляция, нормируют вклад каждой величины, чтобы измерить только связь между самими величинами, не включая в рассмотрение их масштабы. Понятия ковариации и зависимости взаимосвязаны, но различны. Связаны они потому, что две независимые случайные величины имеют нулевую ковариацию, а две величины с ненулевой ковариацией зависимы. Однако независимость отличается от ковариации. Чтобы две величины имели нулевую ковариацию, между ними не долж-но быть линейной зависимости. Независимость же – более строгое требование, чем нулевая ковариация, поскольку она исключает также наличие нелинейных связей. Может случиться так, что две случайные величины зависимы, но их ковариация рав-на нулю. Предположим, к примеру, что мы сначала выбрали вещественное число x из равномерного распределения на отрезке [–1, 1]. Затем выбираем вторую случайную величину s. С вероятностью 1/2 значение s равно 1, иначе –1. Далее порождаем слу- чайную величину y = sx. Очевидно, что x и y не являются независимыми, поскольку x однозначно определяет абсолютную величину y. Однако же Cov(x, y) = 0.\n--- Страница 69 ---\n68  Теория вероятностей и теория информации Ковариационной матрицей случайного вектора x ∈ ℝn называется матрица раз- мера n×n – такая, что Cov(x)i, j = Cov(xi, xj). (3.14) Диагональные элементы ковариационной матрицы равны дисперсии: Cov(xi, xj) = Var(xi). (3.15) 3.9. Часто встречающиеся распределения вероятности В контексте машинного обучения полезно несколько простых распределений вероят-ности. 3.9.1. Распределение Бернулли Распределение Бернулли – это распределение одной случайной величины, прини- мающей всего два значения. У него имеется единственный параметр ϕ ∈ [0, 1], опре- деляющий, с какой вероятностью случайная величина равна 1. Это распределение обладает следующими свойствами: P(x = 1) = ϕ (3.16) P(x = 0) = 1 – ϕ (3.17) P(x = x) = ϕx(1 – ϕ)1–x (3.18) 𝔼x[x] = ϕ (3.19) Varx(x) = ϕ(1 – ϕ) (3.20) 3.9.2. Категориальное распределение Категориальным распределением (или распределением «multinoulli») называется распределение одной дискретной случайной величины, принимающей конечное чис-ло значений k 1. Категориальное распределение параметризовано вектором p ∈ [0, 1]k–1, где pi – вероятность i-го состояния. Вероятность последнего, k-го, состояния равна 1 – 1⏉p. При этом необходимо наложить ограничение 1⏉p ≤ 1. Категориальные рас- пределения часто используются для описания распределения категорий объектов, поэтому мы обычно не будем предполагать, что состоянию 1 соответствует числовое значение 1 и т. д. По этой причине нам, как правило, не нужно вычислять математи- ческое ожидание или дисперсию случайных величин с категориальным распределе- нием. Двух распределений – Бернулли и категориального – достаточно для описания любого распределения в соответствующей области определения. Это так не пото- му, что они такие общие, а потому, что область определения проста; моделируются 1 Термин «multinoulli» недавно предложил Густаво Ласердо и популяризовал Мэрфи (Murphy 2012). Это частный случай мультиномиального распределения, т. е. распределения векто- ров {0, …, n}k, описывающего, сколько раз встретится каждая из k категорий при выборке объ- ема n из категориального распределения. Во многих источниках словом «мультиномиаль- ное» обозначают категориальное распределение, не уточняя, что речь идет только о случае n = 1.\n--- Страница 70 ---\nЧасто встречающиеся распределения вероятности  69 дискретные величины, для которых можно перечислить все возможные состояния. В случае непрерывных случайных величин множество состояний несчетно, поэтому любое распределение, описываемое небольшим количеством параметров, по необхо-димости налагает строгие ограничения. 3.9.3. Нормальное распределение Самым распространенным распределением вещественных чисел является нормаль- ное, или гауссово, распределение: (3.21) График функции плотности нормального распределения показан на рис. 3.1.У нормального распределения два параметра: μ ∈ ℝ и σ ∈ (0, ∞). Параметр μ опреде- ляет абсциссу центрального пика и одновременно является средним значением рас- пределения: 𝔼[x] = μ. Стандартное отклонение этого распределения равно σ, а дис- персия – σ 2. В выражение для функции плотности вероятности входит обратный квадрат σ. Если требуется часто вычислять ФПВ с разными параметрами, то эффективнее па- раметризовать распределение параметром β ∈ (0, ∞), который задает точность, или обратную дисперсию распределения: (3.22) Нормальные распределения являются разумным выбором для многих прило- жений. В отсутствие априорных знаний о форме распределения вещественных чи- сел нормальное распределение выбирается по умолчанию в силу двух основных причин: 0,40 0,350,30 0,25 0,200,150,10 0,05 0,00Максимум при x = μ Точки перегиба при x = μ ± σ –2,0 –1,5p(x) –1,0 –0,5 0 0,5 1,0 1,5 2,0 Рис. 3.1  Нормальное распределение 𝒩(x; μ, σ2) имеет классическую колоколообразную форму, при этом абсцисса центрального пика задается параметром μ, а ширина пика определяется параметром 𝒩. На этом рисун- ке показано стандартное нормальное распределение с μ = 0, σ = 1\n--- Страница 71 ---\n70  Теория вероятностей и теория информации Во-первых, многие моделируемые распределения действительно близки к нор- мальному. Согласно центральной предельной теореме, сумма многих независимых случайных величин аппроксимируется нормальным распределением. На практике это означает, что многие сложные системы успешно моделируются как нормально распределенный шум, даже если систему можно разложить на части с более структу- рированным поведением. Во-вторых, из всех возможных распределений вероятности вещественных чисел с одной и той же дисперсией нормальное распределение обладает максимальной не- определенностью. То есть можно считать, что нормальное распределение привно-сит в модель минимум априорных знаний. Для развития и обоснования этой идеи необходим дополнительный математический аппарат, поэтому мы отложим это до раздела 19.4.2. Нормальное распределение обобщается на пространство ℝ n и тогда называется многомерным нормальным распределением. Оно параметризуется по- ложительно определенной симметричной матрицей Σ: (3.23) Параметр μ по-прежнему задает среднее значение распределения, хотя теперь это вектор. Параметр Σ определяет ковариационную матрицу распределения. Как и в одномерном случае, если требуется вычислять ФПВ многократно с разными па- раметрами, то ковариационная матрица – не лучший способ параметризации, по- скольку для вычисления ФПВ ее приходится обращать. Лучше использовать мат- рицу точности β: (3.24) Часто ковариационная матрица является диагональной. Еще более простой слу- чай – изотропное нормальное распределение, когда ковариационная матрица не только диагональная, но и все элементы на диагонали одинаковы. 3.9.4. Экспоненциальное распределение и распределение Лапласа В контексте глубокого обучения нам часто необходимо распределение вероятно- сти с острым пиком в точке x = 0. Для этого подходит экспоненциальное распре- деление: p(x, λ) = λ 1x≥0 exp(–λx). (3.25) В определении экспоненциального распределения используется индикаторная функция 1x≥0, равная нулю для всех отрицательных значений x. С экспоненциальным тесно связано распределение Лапласа, позволяющее распо- ложить пик массы вероятности в произвольной точке μ: (3.26)\n--- Страница 72 ---\nЧасто встречающиеся распределения вероятности  71 3.9.5. Распределение Дирака и эмпирическое распределение В некоторых случаях мы хотим иметь распределение, в котором вся масса вероят- ности сосредоточена в одной точке. Для этого можно использовать дельта-функцию Дирака δ(x): p(x) = δ(x – μ). (3.27) Дельта-функция Дирака определена таким образом, что равна нулю всюду, кро- ме точки 0, но тем не менее ее интеграл равен 1. Это не обычная функция, которая сопоставляет каждому значению x некоторое вещественное значение, а иной мате- матический объект – обобщенная функция, определяемая в терминах свойств ин- тег рируемости. Дельта-функцию Дирака можно представлять себе как предел по- следовательности функций, которые оставляют все меньше и меньше массы во всех точках, кроме нуля. Определив p(x) как сдвиг δ на величину –μ, мы получили бесконечно узкий и бес- конечно высокий пик массы вероятности в точке x = μ. Дельта-распределение Дирака часто применяется в качестве компоненты эмпири- ческого распределения: (3.28) которое сопоставляет массу вероятности 1/m каждой из точек x(1), …, x(m), образуя заданный набор примеров. Дельта-распределение Дирака нужно только для опре-деления эмпирического распределения непрерывных величин. Для дискретных ве-личин все проще: эмпирическое распределение можно концептуально представить как категориальное распределение, в котором вероятность каждого возможного входного значения просто равна эмпирической частоте этого значения в обучаю- щем наборе. Эмпирическое распределение, образованное набором обучающих примеров, мож- но рассматривать как распределение, из которого производится выборка при обуче-нии модели на этом наборе. Еще один важный взгляд на эмпирическое распределение заключается в том, что это плотность вероятности, доставляющая максимум правдо- подобию обучающих данных (см. раздел 5.5). 3.9.6. Смеси распределений Часто новые распределения вероятности определяются путем комбинирования более простых. Один из самых употребительных способов комбинирования – построение смеси распределений, состоящей из нескольких компонент. При каждом испытании определяется, из какого распределения будет производиться выборка, причем для выборки компоненты используется категориальное распределение: (3.29) где P(c) – категориальное распределение компонент. Один пример смеси распределений мы уже видели: эмпирическое распределение вещественных случайных величин – это смесь распределений Дирака, по одному для каждого обучающего примера.\n--- Страница 73 ---\n72  Теория вероятностей и теория информации Модель смеси – простая стратегия комбинирования распределений вероятности для получения более сложного распределения. В главе 16 мы рассмотрим искусство построения сложных распределений из простых более подробно. Модель смеси позволяет предварительно познакомиться с концепцией, которая в дальнейшем будет играть важнейшую роль – скрытой, или латентной, переменной. Латентной называется случайная величина, которую мы не наблюдаем непосредствен- но. Примером может служить величина c, определяющая компоненту смеси распреде-лений. Латентные переменные могут быть связаны с x совместным распределением, в таком случае P(x, c) = P(x | c)P (c). Распределение P(c) латентной переменной и рас- пределение P(x | c), связывающее латентные переменные с видимыми, определяют форму распределения P(x), пусть даже имеется возможность описать P(x), не прибе- гая к латентной переменной. Латентные переменные будут обсуждаться в разделе 16.5. Очень полезна и широко употребляется модель гауссовой смеси, в которой компо- ненты p(x | c = i) – нормальные распределения. Каждая компонента независимо па- раметризуется средним значением μ (i) и ковариацией Σ(i). На некоторые смеси могут налагаться дополнительные ограничения. Например, у разных компонент могут быть одинаковые ковариации, т. е. Σ(i) = Σ, ∀i. Как и в случае одного нормального распре- деления, можно ограничиться только такими смесями, для которых ковариационная матрица каждой компоненты диагональная или изотропная. Помимо средних и ковариаций, гауссова смесь параметризуется априорными ве- роятностями α i = P(c = i) каждой компоненты i. Слово «априорная» означает, что речь идет о гипотезе относительно значения c до наблюдения x. Напротив, P(c | x) на- зывается апостериорной вероятностью, потому что вычисляется после наблюдения x. Модель гауссовой смеси является универсальным приближением для плотностей в том смысле, что любую гладкую функцию плотности можно аппроксимировать с любой наперед заданной точностью смесью нормальных распределений с достаточ- но большим числом компонент. На рис. 3.2 показаны выборки из модели гауссовой смеси. x1x2 Рис. 3.2  Выборки из модели гауссовой смеси. Показаны три компонен- ты. Если смотреть слева направо, то первая компонента имеет изотропную ковариационную матрицу, т. е. дисперсия во всех направлениях одинако- ва. Вторая компонента имеет диагональную ковариационную матрицу, т. е. дисперсию можно задавать независимо вдоль каждой оси. В этом примере дисперсия вдоль оси x 2 больше, чем вдоль оси x1. Третья компонента имеет ковариационную матрицу полного ранга, позволяющую задавать диспер-сии вдоль произвольного базиса\n--- Страница 74 ---\nПолезные свойства употребительных функций  73 3.10. Полезные свойства употребительных функций При работе с распределениями вероятности, особенно в контексте глубокого обуче- ния, некоторые функции встречаются очень часто. Одна из них – логистическая сигмоида: (3.30) Логистическая сигмоида обычно используется для порождения параметра ϕ рас- пределения Бернулли, поскольку она принимает значения из интервала (0, 1), при- надлежащего области допустимых значений параметра ϕ. На рис. 3.3 показан гра- фик сигмоидной функции. Как видно, если абсолютное значение аргумента велико, то функция выходит на плато, т. е. становится очень плоской и малочувствительной к небольшим изменениям аргумента. σ(x)1,0 0,8 0,6 0,40,20,0 –10 –5 0 5 10 Рис. 3.3  Логистическая сигмоида Часто встречается также функция softplus (Dugas et al., 2001): ζ(x) = log (1 + exp(x)) . (3.31) Эта функция может быть полезна для порождения параметра β или α нормаль- ного распределения, поскольку принимает значения из интервала (0, ∞). Она также нередко возникает при работе с выражениями, содержащими сигмоиды. Название softplus объясняется тем, что это сглаженный (смягченный – «softened») вариант функции x+ = max(0 , x). (3.32) График функции softplus показан на рис. 3.4. Приведенные ниже свойства настолько полезны, что имеет смысл запомнить их: (3.33) (3.34) 1 – σ(x) = σ(–x) (3.35) log σ(x) = –ζ(–x) (3.36)\n--- Страница 75 ---\n74  Теория вероятностей и теория информации (3.37) (3.38) ∀x > 0, ζ–1(x) = log(exp(x) – 1) (3.39) (3.40) ζ(x) – ζ(–x) = x (3.41) 10 8 6 4 2 0 –10ζ(x) –5 0 5 10 Рис. 3.4  Функция softplus В статистике функция σ–1(x) называется logit, но в машинном обучении этот тер- мин используется редко. Формула (3.41) дает еще одно обоснование названия «softplus». Назначение функции softplus – служить сглаженным вариантом функции положительной час- ти x+ = max{0, x}, дополнением к которой является функция отрицательной части x– = max{0, –x}. Для сглаживания отрицательной части можно взять функцию ζ(–x). Величину x можно восстановить по положительной и отрицательной частям благо- даря тождеству x+ – x– = x, а в силу тождества (3.41) x можно восстановить также по ζ(x) и ζ(–x). 3.11. Правило Байеса Часто возникает ситуация, когда известна вероятность P(y | x), а требуется узнать P(x | y). К счастью, если мы знаем также P(x), то можем вычислить искомую вероят- ность по правилу Байеса: (3.42) Отметим, что в эту формулу входит P(y), но обычно можно вычислить P(y) = = ΣxP(y | x)P(x), так что без знания P(y) можно обойтись. Правило Байеса непосредственно следует из определения условной вероятности, но знать название этой формулы полезно, потому что оно часто встречается в различ- ных публикациях. Формула названа в честь преподобного Томаса Байеса, который первым открыл ее частный случай. В общем виде, представленном выше, ее незави- симо открыл Пьер-Симон Лаплас.\n--- Страница 76 ---\nТехнические детали непрерывных величин  75 3.12. Технические детали непрерывных величин Для формального изложения непрерывных случайных величин и функций плотно- сти вероятности необходимо знакомство с разделом математики, который называется теория меры. Эта теория выходит за рамки книги, но мы можем бегло осветить во- просы, которые она решает. В разделе 3.3.2 мы видели, что вероятность нахождения непрерывной векторной случайной величины x в некотором множестве 𝕊 равна интегралу функции p(x), взятому по этому множеству. Но при определенном выборе 𝕊 возникают парадоксы. Например, можно построить два множества 𝕊1 и 𝕊2, так что p(x ∈ 𝕊1) + p(x ∈ 𝕊2) > 1, но 𝕊1 ∩ 𝕊2 = ∅. При построении таких множеств используются инфинитезимальные свойства вещественных чисел, например строятся фрактальные множества или мно- жества, получаемые преобразованием множества рациональных чисел1. Один из основ ных вкладов теории меры – характеристика множества множеств, для которых можно вычислить вероятность, не сталкиваясь с парадоксами. В этой книге интегри- рование производится только по относительно простым множествам, так что этот аспект теории меры не имеет большого значения. Для наших целей теория меры более полезна с точки зрения теорем, применимых к большинству точек ℝ n, за исключением некоторых граничных случаев. Теория меры позволяет строго описать, что такое пренебрежимо малое множество точек. Говорят, что такое множество имеет меру нуль. Мы здесь не станем формально определять это понятие. Достаточно интуитивного представления о том, что множество меры нуль не занимает никакого объема в рассматриваемом пространстве. Например, в ℝ 2 пря- мая имеет меру нуль, а залитый многоугольник – положительную меру. Точно так же отдельно взятая точка имеет меру нуль. Объединение счетного множества множеств меры нуль само имеет меру нуль (так что множество всех рациональных чисел имеет меру нуль). Еще один полезный термин из теории меры – почти всюду. Говорят, что свойство выполняется почти всюду, если оно выполняется для всех точек пространства, за ис-ключением множества меры нуль. Поскольку исключения занимают пренебрежимо малую часть пространства, в большинстве приложений их можно без опаски игнори- ровать. Некоторые важные результаты теории вероятностей справедливы для всех дискретных случайных величин, но лишь «почти всюду» для непрерывных. Еще одна техническая деталь, относящаяся к непрерывным величинам, – рабо- та с непрерывными случайными величинами, являющимися детерминированными функциями других случайных величин. Допустим, имеются две случайные величины x и y – такие, что y = g(x), где g – обратимое, непрерывное, дифференцируемое преоб- разование. Можно было бы ожидать, что p y(y) = px(g–1(y)). На самом деле это не так. В качестве простого примера предположим, что имеются скалярные случайные величины x и y. Пусть y = x / 2 и x ∼ U(0, 1). Если бы имело место тождество py(y) = = px(2y), то py было бы равно 0 всюду, кроме отрезка [0, 1/2], и 1 на этом отрезке. Тогда (3.43) что противоречит определению распределения вероятности. Это типичная ошибка. Проблема в том, что при таком подходе не учитывается искажение пространства, вно- 1 Забавный пример таких множеств дает теорема Банаха–Тарского.\n--- Страница 77 ---\n76  Теория вероятностей и теория информации симое функцией g. Напомним, что вероятность попадания x в бесконечно малую об- ласть объема δx равна p(x)δx. Поскольку g может расширять или сжимать простран- ство, бесконечно малая окрестность x в пространстве x может иметь другой объем в пространстве y. Чтобы понять, как справиться с этой трудностью, вернемся к скалярному случаю. Нам требуется сохранить свойство |py(g(x))dy | = |px(x)dx |. (3.44) Решая это уравнение, получаем (3.45) или эквивалентно (3.46) В пространстве более высокой размерности обобщением производной является определитель матрицы Якоби: Ji, j = ∂xi/∂yj. Следовательно, для вещественных векто- ров x и y (3.47) 3.13. Теория информации Теория информации – это раздел прикладной математики, в котором изучается ко- личественное содержание информации в сигнале. Первоначально она была создана для изучения передачи сообщений, состоящих из символов дискретного алфавита, по зашумленному каналу, например в случае радиопередачи. В этом контексте теория информации подсказывает, как построить оптимальный код и вычислить ожидаемую длину сообщений, выбираемых из конкретного распределения вероятности при раз-личных схемах кодирования. В контексте машинного обучения теорию информации можно применить также к непрерывным величинам, когда некоторые интерпретации длины сообщения бессмысленны. Теория информации является основополагающей для многих разделов электротехники и информатики. В этой книге мы будем поль- зоваться лишь немногими ключевыми идеями теории информации, чтобы охаракте-ризовать распределения вероятности или количественно измерить сходство между двумя распределениями. Дополнительные сведения см. в книгах Cover and Thomas (2006) или MacKay (2003). В основе теории информации лежит интуитивное соображение, согласно кото- рому в наблюдении маловероятного события содержится больше информации, чем в наблю дении вероятного события. Сообщение «сегодня утром взошло солнце» на- столько неинформативно, что его и передавать не нужно, а вот сообщение «сегодня утром было солнечное затмение» очень информативно. Мы хотели бы количественно измерить информацию, чтобы формализовать эту идею.\n--- Страница 78 ---\nТеория информации  77 Вероятные события должны иметь низкое информационное содержание, а ес- ли событие наступает гарантированно, то информационное содержание отсут- ствует полностью. Чем меньше вероятность события, тем выше информационное содержание. Информация, содержащаяся в независимых событиях, складывается. Напри- мер, событие, заключающееся в выпадении орла два раза, должно содержать в два раза больше информации, чем событие однократного выпадения орла. Чтобы удовлетворить все три свойства, определим собственную информацию со- бытия x = x: I(x) = –log P(x). (3.48) В этой книге log всегда означает натуральный логарифм (по основанию e). Поэто- му в нашем определении I(x) измеряется в натах. Один нат равен количеству инфор- мации, содержащемуся в наблюдении события с вероятностью 1/e. В других учебни- ках используются логарифмы по основанию 2, соответствующие единицы измерения называются битами, или шеннонами; информация, измеренная в битах, отличается от измеренной в натах только постоянным коэффициентом. Если x – непрерывная случайная величина, то по аналогии используется точно такое же определение информации, но некоторые свойства, справедливые в дискрет- ном случае, утрачиваются. Например, событие с единичной плотностью содержит нулевую информацию, хотя и не является достоверным. Собственная информация относится только к одному исходу. Мы можем количе- ственно выразить неопределенность всего распределения вероятности, воспользо-вавшись энтропией Шеннона H(x) = 𝔼x∼P[I(x)] = –𝔼x∼P[log P(x)], (3.49) которая обозначается также H(P). Иными словами, энтропия Шеннона распределе- ния – это математическое ожидание количества информации в событии, выбираемом из этого распределения. Энтропия дает нижнюю границу числа бит (если логарифм берется по основанию 2, в противном случае единицы измерения иные), необходимое в среднем для кодирования символов, выбираемых из распределения P. Почти де- терминированные распределения (когда исход испытания почти достоверен) имеют низкую энтропию; распределения, близкие к равномерному, – высокую. Энтропия иллюстрируется на рис. 3.5. Если x – непрерывная величина, то энтропия Шеннона называется дифференциальной энтропией. Если P(x) и Q(x) – два распределения вероятности одной и той же случайной ве- личины x, то измерить, насколько они различаются, позволяет расхождение Кульба- ка–Лейблера (КЛ): (3.50) Для дискретных величин это дополнительное количество информации (измерен- ное в битах, если используется логарифм по основанию 2, но в машинном обучении обычно используются натуральный логарифм и наты), необходимое для отправки со- общения, содержащего символы, выбранные из распределения P, если используется код, спроектированный для минимизации длины сообщений, выбираемых из распре-деления Q.\n--- Страница 79 ---\n78  Теория вероятностей и теория информации Энтропия Шеннона в натах0,7 0,6 0,5 0,40,30,20,1 0,0 0,0 0,2 0,4 0,6 0,8 1,0 Рис. 3.5  Энтропия Шеннона бинарной случайной величины. На графи- ке видно, что у распределений, близких к детерминированному, энтропия низкая, а у близких к равномерному – высокая. По горизонтальной оси отло- жена вероятность p того, что бинарная случайная величина близка к 1. Энт- ропия вычисляется по формуле (p – 1) log(1 – p) – p log p. Если p близка к 0, то распределение почти детерминировано, поскольку случайная величина почти всегда равна 0. Если p близка к 1, то распределение почти детерми- нировано, поскольку случайная величина почти всегда равна 1. При p = 0,5 энтропия максимальна, поскольку оба исхода распределены равномерно Расхождение КЛ обладает многими полезными свойствами, самое главное из ко- торых – неотрицательность. Расхождение КЛ равно 0 тогда и только тогда, когда P и Q – одно и то же рас- пределение в случае дискретных величин или когда эти распределения совпадают «почти всюду» – в случае непрерывных. Поскольку расхождение КЛ неотрицательно и измеряет различие между двумя распределениями, его часто концептуально вос- принимают как средство измерения некоторого расстояния между распределениями. Но, строго говоря, эта мера – не расстояние, поскольку не является симметричной: D KL(P||Q) ≠ DKL(Q||P) для некоторых P и Q. Наличие асимметрии означает, что от вы- бора DKL(P||Q) или DKL(Q||P) многое зависит. Детали показаны на рис. 3.6. С расхождением КЛ тесно связана перекрестная энтропия H(P, Q) = H(P) + + DKL(P||Q), аналогичная расхождению КЛ, но без левого члена: H(P, Q) = –𝔼x∼P log Q(x). (3.51) Минимизация перекрестной энтропии относительно Q равносильна минимизации расхождения КЛ, потому что Q не входит в опущенный член. При вычислении подобных величин часто встречаются выражения вида 0 log 0. По принятому в теории информации соглашению, они трактуются как limx⟶0 x log x = 0. 3.14. Структурные вероятностные модели В алгоритмах машинного обучения часто встречаются распределения вероятности очень большого числа случайных величин. Нередко в этих распределениях наличе- ствуют прямые взаимодействия между сравнительно небольшим количеством пере-менных. Использовать одну функцию для описания всего совместного распределе-ния вероятности может оказаться очень неэффективно (и с вычислительной, и со статистической точки зрения).\n--- Страница 80 ---\nСтруктурные вероятностные модели  79 q* = arg minq DКЛ(p||q) q* = arg minq DКЛ(q||p) p(x) q*(x)p(x)q *(x) х хПлотность распределения вероятностей Плотность распределения вероятностей Рис. 3.6  Расхождение КЛ несимметрично. Предположим, что мы хо- тим аппроксимировать распределение p(x) другим распределением q(x). Можно выбирать, что минимизировать: DKL(p||q) или DKL(q||p). На рисунке показаны последствия выбора в случае, когда p – смесь двух нормальных распределений, а q – обычное нормальное распределение. Выбор направ- ления расхождения зависит от задачи. Для одних приложений нужна ап- проксимация, в которой вероятность высока там, где высока вероятность истинного распределения, а для других – чтобы была низкая вероятность там, где низка вероятность истинного распределения. (Слева) Результат минимизации D KL(p||q). В этом случае q выбирается так, чтобы была высокая вероятность там, где высока вероятность p. Если p имеет несколько мод, то q стремится размазать моды, собрав заключенную в них массу вероятно- сти. (Справа) Результат минимизации DKL(q||p). В этом случае q выбирается так, чтобы была низкая вероятность там, где низка вероятность p. Если p имеет несколько достаточно далеко отстоящих мод, как на этом рисунке, то расхождение КЛ достигает минимума, когда выбирается одна мода, чтобы предотвратить размещение массы вероятности в областях низкой вероят- ности между модами p. На рисунке показан результат, когда q выбрано, так чтобы усилить левую моду. Такое же значение расхождения КЛ можно было бы получить, выбрав правую моду. Если моды не разделены достаточно вы-раженной областью малой вероятности, то и при таком выборе направле- ния расхождения КЛ может произойти размазывание мод Вместо этого мы можем разделить распределение вероятности на много перемно- жаемых факторов. Допустим, к примеру, что имеются три случайные величины: a, b и c. Предположим, что a влияет на b, b влияет на c, но a и c независимы при условии b. Распределение вероятности всех трех переменных можно представить в виде про- изведения распределений двух переменных: p(a, b, c) = p(a)p(b | a)p(c | b). (3.52) Такая факторизация может существенно уменьшить число параметров, необходи- мых для описания распределения. Число параметров каждого фактора экспоненци- ально зависит от числа переменных в нем. Это значит, что стоимость представления распределения удастся значительно сократить, если мы сможем разложить его в про- изведение распределений с меньшим числом переменных. Подобные факторизации можно описывать с помощью графов; под графом здесь понимается множество вершин, некоторые из которых соединены ребрами. Если факторизация распределения вероятности представлена в виде графа, то мы называ- ем его структурной вероятностной моделью, или графической моделью.\n--- Страница 81 ---\n80  Теория вероятностей и теория информации Существуют два основных вида структурных вероятностных моделей: ориенти- рованные и неориентированные. В обоих случаях используется граф 𝒢, в котором каждая вершина соответствует случайной величине, а наличие ребра между двумя вершинами означает, что распределение вероятности способно представить прямые взаимодействия между соответствующими величинами. В ориентированных моделях используются графы с ориентированными ребрами, они представляют разложение в произведение условных распределений вероятности, как в примере выше. Точнее, ориентированная модель содержит по одному фактору для каждой случайной величины xi в распределении, и этот фактор состоит из услов- ного распределения xi при условии родителей xi, обозначаемых Pa𝒢(xi): (3.53) На рис. 3.7 приведены пример ориентированного графа и представляемая им фак- торизация распределения вероятности. a c eb d Рис. 3.7  Ориентированная графическая модель случайных величин a, b, c, d, e. Этот граф соответствует такой факторизации распределения ве- роятности: p(a, b, c, d, e) = p(a)p(b | a)p(c | a, b)p(d | b)p(e | c) (3.54) Эта графическая модель позволяет быстро выявить некоторые свойства распределения. Например, a и c взаимодействуют непосредственно, тогда как a и e – только косвенно, через c В неориентированных моделях используются графы с неориентированными реб- рами, они представляют разложение в произведение множества функций. В отличие от ориентированного случая, функции необязательно должны быть распределения-ми вероятности. Любое множество попарно соединенных вершин графа 𝒢 называется кликой. Всякая клика 𝒞 (i) в неориентированной модели ассоциированна с фактором ϕ(i)(𝒞(i). Эти факторы – просто функции, а не распределения вероятности. Результат каждого фактора должен быть неотрицателен, но не требуется, чтобы сумма значений фактора или интеграл от него был равен 1, как в случае распределения вероятности. Вероятность конфигурации случайных величин пропорциональна произведению всех факторов – комбинации, которые приводят к большим значениям факторов, более вероятны. Разумеется, нет никакой гарантии, что сумма произведений будет равна 1. Поэтому мы делим ее на нормировочную константу Z, определенную как сумма или интеграл по всем состояниям произведений функций ϕ, чтобы получить нормированное распределение вероятности:\n--- Страница 82 ---\nСтруктурные вероятностные модели  81 (3.55) На рис. 3.8 приведены пример неориентированного графа и представляемая им факторизация распределения вероятности. a c eb d Рис. 3.8  Неориентированная, графическая модель случайных величин a, b, c, d, e. Этот граф соответствует такой факторизации распределения вероятности (3.56) Эта графическая модель позволяет быстро выявить некоторые свойства распределения. Например, a и c взаимодействуют непосредственно, тогда как a и e – только косвенно, через c. Имейте в виду, что эти графические представления факторизаций – лишь язык описания распределений вероятности. Они не являются взаимно исключающими семействами распределений. Ориентированность или неориентированность – свой- ство не самого распределения вероятности, а конкретного описания распределения, и любое распределение можно описать обоими способами. В частях I и II книги мы используем структурные вероятностные модели просто как язык, позволяющий описать, какие прямые вероятностные связи представлены различными алгоритмами машинного обучения. Более глубокое понимание струк-турных вероятностных моделей не понадобится вплоть до обсуждения тем для ис-следования в части III, где эти модели будут рассмотрены более детально. В этой главе мы привели краткий обзор концепций теории вероятностей, имеющих прямое отношение к глубокому обучению. Осталось рассмотреть еще одну часть фун- даментального математического аппарата: численные методы.",
      "debug": {
        "start_page": 62,
        "end_page": 82
      }
    },
    {
      "name": "Глава 4. Численные методы 82",
      "content": "--- Страница 83 --- (продолжение)\nГлава 4 Численные методы В алгоритмах машинного обучения обычно приходится выполнять много численных расчетов. Как правило, речь идет о применении методов, которые итеративно уточня- ют решение, а не ищут его аналитически по формуле. Типичные операции – оптими-зация (нахождение значения, которое доставляет минимум или максимум некоторой функции) и решение системы линейных уравнений. Но даже само вычисление мате- матической функции с помощью цифрового компьютера может оказаться трудной задачей, если в выражение функции входят вещественные числа, которые нельзя представить точно в памяти конечного размера. 4.1. Переполнение и потеря значимости Фундаментальная сложность выполнения непрерывных математических операций на цифровом компьютере заключается в том, как представить бесконечно много ве- щественных чисел с помощью конечного числа комбинаций битов. Это означает, что почти для всех вещественных чисел производится некоторая аппроксимация и, сле- довательно, возникает ошибка округления. Такие ошибки составляют проблему, особенно если накапливаются в результате выполнения многих операций. Это мо- жет привести к тому, что теоретически правильный алгоритм, при проектировании которого не была предусмотрена минимизация накопления ошибок округления, на практике не работает. Особенно неприятной разновидностью ошибок округления является потеря зна- чимости. Это происходит, когда число, близкое к нулю, округляется до нуля. Многие функции ведут себя качественно различно, когда аргумент равен нулю, а не малому положительному числу. Например, обычно мы стремимся избежать деления на нуль (в одних программных средах это приводит к возбуждению исключения, а других – к возврату специального значения «не число») или взятия логарифма от нуля (обыч- но результат рассматривается как –∞ и преобразуется в «не число» при попытке ис- пользования в последующих арифметических операциях). Еще одна разновидность численных ошибок, приводящая к катастрофическим последствиям, – переполнение. Это происходит, когда абсолютная величина числа слишком велика и аппроксимируется как ∞ или –∞. При последующих арифметиче- ских операциях такие бесконечные значения преобразуются в «не число». Примером функции, которую необходимо защищать от потери значимости и пере- полнения, является softmax. Эта функция часто применяется для прогнозирования вероятностей, ассоциированных с категориальным распределением. Определяется она следующим образом:\nГлава 4 Численные методы В алгоритмах машинного обучения обычно приходится выполнять много численных расчетов. Как правило, речь идет о применении методов, которые итеративно уточня- ют решение, а не ищут его аналитически по формуле. Типичные операции – оптими-зация (нахождение значения, которое доставляет минимум или максимум некоторой функции) и решение системы линейных уравнений. Но даже само вычисление мате- матической функции с помощью цифрового компьютера может оказаться трудной задачей, если в выражение функции входят вещественные числа, которые нельзя представить точно в памяти конечного размера. 4.1. Переполнение и потеря значимости Фундаментальная сложность выполнения непрерывных математических операций на цифровом компьютере заключается в том, как представить бесконечно много ве- щественных чисел с помощью конечного числа комбинаций битов. Это означает, что почти для всех вещественных чисел производится некоторая аппроксимация и, сле- довательно, возникает ошибка округления. Такие ошибки составляют проблему, особенно если накапливаются в результате выполнения многих операций. Это мо- жет привести к тому, что теоретически правильный алгоритм, при проектировании которого не была предусмотрена минимизация накопления ошибок округления, на практике не работает. Особенно неприятной разновидностью ошибок округления является потеря зна- чимости. Это происходит, когда число, близкое к нулю, округляется до нуля. Многие функции ведут себя качественно различно, когда аргумент равен нулю, а не малому положительному числу. Например, обычно мы стремимся избежать деления на нуль (в одних программных средах это приводит к возбуждению исключения, а других – к возврату специального значения «не число») или взятия логарифма от нуля (обыч- но результат рассматривается как –∞ и преобразуется в «не число» при попытке ис- пользования в последующих арифметических операциях). Еще одна разновидность численных ошибок, приводящая к катастрофическим последствиям, – переполнение. Это происходит, когда абсолютная величина числа слишком велика и аппроксимируется как ∞ или –∞. При последующих арифметиче- ских операциях такие бесконечные значения преобразуются в «не число». Примером функции, которую необходимо защищать от потери значимости и пере- полнения, является softmax. Эта функция часто применяется для прогнозирования вероятностей, ассоциированных с категориальным распределением. Определяется она следующим образом:\n--- Страница 84 ---\nПлохая обусловленность  83 (4.1) Рассмотрим, что произойдет, когда все xi равны некоторой константе c. Формально очевидно, что все компоненты результата должны быть равны 1/n. Но в процессе вы- числений так может не получиться, если абсолютная величина c очень велика. Если при этом c отрицательно, то при вычислении exp(c) произойдет потеря значимости. Тогда знаменатель softmax будет равен 0, и окончательный результат не определен. Если же c очень велико и положительно, то вычисление exp(c) приведет к перепол- нению, и результат выражения опять-таки будет не определен. Обе проблемы можно устранить, если вычислять softmax(z), где z = x – maxi xi. Простые алгебраические выкладки показывают, что значение softmax не изменяется, если прибавить к вход- ному вектору произвольный скаляр. После вычитания maxi xi наибольший аргумент exp оказывается равен 0, что исключает возможность переполнения. Кроме того, по меньшей мере одно слагаемое в знаменателе равно 1, так что невозможна и потеря значимости в знаменателе, приводящая к делению на 0. Но остается еще одна мелкая проблема. Из-за потери значимости в числителе все выражение может обратиться в нуль. Это означает, что если мы попытаемся вычис- лить log softmax(x), вызвав функцию softmax и передав результат функции log, то получим неверный результат –∞. Поэтому мы должны вместо этого реализовать от-дельную функцию, которая вычисляет log softmax численно устойчивым способом. Стабилизировать ее можно с помощью того же приема, что мы применили для стаби- лизации вычисления softmax. Как правило, мы не будем явно оговаривать все детали вычислений, относящиеся к реализации описываемых в книге алгоритмов. Разработчики низкоуровневых биб- лиотек должны помнить о проблемах численных расчетов при реализации алгорит- мов глубокого обучения. Большинство читателей книги может просто полагаться на то, что низкоуровневые библиотеки позаботились о вычислительной устойчивости. Библиотека Theano (Bergstra et al., 2010; Bastien et al., 2012) – пример пакета, кото- рый автоматически обнаруживает и стабилизирует многие вычислительно неустой- чивые выражения, часто встречающиеся в контексте глубокого обучения. 4.2. Плохая обусловленность Под обусловленностью функции понимают скорость ее изменения в ответ на малые изменения аргументов. Функции, которые быстро изменяются при слабом возмуще-нии аргументов, могут стать причиной проблем в научных расчетах, поскольку ошиб- ки округления аргументов способны вызвать сильное изменение результата. Рассмотрим функцию f(x) = A –1x. Если матрица A ∈ ℝn×n имеет спектральное раз- ложение, то ее число обусловленности равно (4.2) Это абсолютная величина отношения самого большого и самого маленького соб- ственного значения. Если это число велико, то операция вычисления обратной мат-рицы особенно чувствительна к погрешности исходных данных.\n--- Страница 85 ---\n84  Численные методы Такая чувствительность – внутреннее свойство матрицы, а не результат ошибок окру- гления при ее обращении. Если матрица плохо обусловлена, то уже имеющиеся погреш- ности усиливаются при умножении на истинно обратную к ней. На практике ошибка увеличивается еще больше из-за погрешностей, возникающих в процессе обращения. 4.3. Оптимизация градиентным методом Большинство алгоритмов машинного обучения в том или ином виде включает опти- мизацию, т. е. нахождение минимума или максимума функции f(x) при изменении x. Обычно задачу оптимизации формулируют в терминах нахождения минимума. Для на- хождения максимума достаточно применить алгоритм минимизации к функции –f (x). Функция, для которой мы ищем минимум или максимум, называется целевой функцией, или критерием. Если речь идет о минимизации, то употребляют также термины функция стоимости, функция потерь или функция ошибок. В этой книге все эти термины используются как синонимы, хотя в других публикациях по машин- ному обучению некоторым из них приписывается специальный смысл. Значение, доставляющее минимум или максимум функции, мы часто будем обо- значать надстрочным индексом *, например: x* = arg min f(x ). Мы предполагаем, что читатель знаком с математическим анализом, но все же при- ведем краткий обзор понятий, относящихся к оптимизации. Рассмотрим функцию y = f(x), где x и y – вещественные числа. Ее производная обозначается f′(x) или dy/dx. Производная f′(x) определяет наклон f(x) в точке x, т. е. коэффициент, на который нужно умножить малое изменение аргумента, чтобы получить соответственное изменение результата: f(x + ε) ≈ f(x) + εf ′(x). Производная полезна для минимизации функции, потому что описывает, как из- менить x, чтобы получить небольшое улучшение y. Например, мы знаем, что f(x – – ε sign(f′(x))) меньше f(x) при достаточно малом ε. Поэтому мы можем уменьшить f(x), сдвигая x небольшими шагами в направлении, противоположном знаку произ- водной. Этот метод называется градиентным спуском (Cauchy, 1847). Пример его применения показан на рис. 4.1. 2,0 1,5 1,0 0,50,0 –0,5–1,0–1,5 –2,0 –2,0 0,0 –1,0 1,0 –1,5 0,5 –0,5 1,5 2,0f(x) = 1/2 x2 fʹ(x) = xПри x > 0 имеем f ′(x) > 0, поэтому f можно уменьшить, двигаясь влевоГлобальный минимум в точке x = 0. Поскольку f′(x) = 0, здесь гради- ентный спуск останавливается При x < 0 имеем f ′(x) < 0, поэтому f можно уменьшить, двигаясь вправо Рис. 4.1  Градиентный спуск. Иллюстрация применения метода градиент- ного спуска с использованием производной для перехода в точку минимума\n--- Страница 86 ---\nОптимизация градиентным методом  85 Если f′(x) = 0, то производная не дает информации о том, в каком направлении сме- щаться. Точки, в которых f′(x) = 0, называются критическими, или стационарными. Локальным минимумом называется точка, в которой f(x) меньше, чем во всех точках малой окрестности, поэтому уменьшить f(x) путем изменения аргумента на неболь- шую величину невозможно. Локальным максимумом называется точка, в которой f(x) больше, чем во всех точках малой окрестности, поэтому невозможно увеличить f(x) путем изменения аргумента на небольшую величину. Некоторые критические точки не являются ни минимумами, ни максимумами. Они называются седловыми точками. На рис. 4.2 показаны примеры всех критических точек. Седловая точка Минимум Максимум Рис. 4.2  Типы критических точек. Примеры трех типов критических то- чек в одномерном случае. Критической называется точка с нулевым угло- вым коэффициентом. Это может быть локальный минимум, в котором зна- чение функции больше значений в окрестных точках, локальный максимум, в котором значение функции меньше значений в окрестных точках, или седловая точка, в которой значение функции может быть как больше, так и меньше значений в окрестных точках Точка, в которой достигается абсолютно наименьшее значение f(x), называется глобальным минимумом. У функции может быть один или несколько глобальных минимумов. Могут также существовать локальные минимумы, не являющиеся гло-бальными. В контексте глубокого обучения мы оптимизируем функции, у которых может быть много неоптимальных локальных минимумов, а также много седловых точек, окруженных очень плоскими участками. Все это затрудняет оптимизацию, особенно если речь идет о функциях нескольких переменных. Поэтому обычно счита- ется достаточным найти малое значение f, формально не являющееся минимальным. Пример показан на рис. 4.3. Этот локальный минимум почти так же хорош, как глобальный, поэтому в этой точке можно остановиться В идеале мы хотели бы найти глобальный минимум, но это не всегда возможноЭто плохой локальный минимум, его следует избегатьf(x) x Рис. 4.3  Приближенная минимизация. Алгоритмы оптимизации могут не найти глобального минимума, если имеется несколько локальных мини- мумов или плато. В глубоком обучении мы обычно соглашаемся на такие решения, несмотря на то что это не настоящий минимум, при условии что они соответствуют действительно низким значениям функции стоимости\n--- Страница 87 ---\n86  Численные методы Часто приходится минимизировать функции нескольких переменных: f : ℝn ⟶ ℝ. Чтобы понятие минимума имело смысл, результатом функции должен быть скаляр. Для функций нескольких переменных следует ввести понятие частной производ- ной. Частная производная (∂/∂xi)f(x) показывает, как изменяется f при изменении аргумента x только в одном направлении xi. Градиент обобщает понятие производной на вектор: градиентом функции f называется вектор всех ее частных производных, он обозначается ∇x f(x). i-м элементом градиента является частная производная f по xi. В многомерном случае критическими называются точки, в которых все элементы градиента равны 0. Производной по направлению в направлении единичного вектора u называется угловой коэффициент функции f в направлении u. Иначе говоря, производная по на- правлению – это производная функции f(x + αu) по α, вычисленная при α = 0 . По правилу вычисления сложной производной (∂/∂α)f(x + αu) равно u⏉∇x f(x) при α = 0. Для минимизации f мы хотели бы найти направление, в котором f убывает быстрее всего. Это можно сделать с помощью производной по направлению: (4.3) (4.4) где θ – угол между u и градиентом. Если подставить || u||2 = 1 и игнорировать множи- тели, не зависящие u, то остается minu cos θ. Эта величина достигает минимума, когда u направлен противоположно градиенту. Иначе говоря, градиент указывает направ- ление вверх, а отрицательный градиент – вниз. Чтобы уменьшить f, мы должны дви-гаться в направлении отрицательного градиента. Этот алгоритм называется методом наискорейшего спуска, или градиентным спуском. В методе наискорейшего спуска предлагается выбирать новую точку xʹ = x – ε∇ xf(x), (4.5) где ε – скорость обучения, положительный скаляр, определяющий длину шага. Вы- бирать ε можно разными способами. Популярный подход – взять некоторую малую константу. Иногда удается найти размер шага, при котором производная по направ- лению обращается в нуль. Другой подход – вычислить f(x – ε∇x f(x)) для нескольких значений ε и выбрать то, при котором целевая функция принимает наименьшее зна- чение. Эта стратегия называется линейным поиском. Метод наискорейшего спуска сходится, если все элементы градиента равны 0 (или, на практике, очень близки к нулю). В некоторых случаях можно избежать примене- ния итеративного алгоритма и сразу перейти к критической точке, решив уравнение ∇x f(x) = 0 относительно x. Хотя градиентный спуск применим только к задачам оптимизации в непрерывных пространствах, идея выполнения малых шагов (аппроксимирующих наилучший ма-лый шаг) для приближения к оптимальной конфигурации обобщается и на дискрет- ные пространства. Поиск максимума целевой функции дискретных параметров на-зывается методом восхождения на вершину ( hill climbing) (Russel and Norvig, 2003). 4.3.1. Не только градиент: матрицы Якоби и Гессе Иногда требуется найти все частные производные функции, аргументами и значени- ем которой являются векторы. Матрица, содержащая такие частные производные, на-\n--- Страница 88 ---\nОптимизация градиентным методом  87 зывается матрицей Якоби, или якобианом. Точнее, если имеется функция f : ℝm ⟶ ℝn, то ее матрица Якоби J ∈ ℝm×n определяется как Ji, j = (∂/∂xj) f(x)i. Иногда нас интересует также производная производной, или вторая производная. Например, для функции f : ℝn ⟶ ℝ производная по xi от производной f по xj обозна- чается (∂2/∂xi∂xj)f. В одномерном случае (d2f/dx2)f обозначается также f″(x). Вторая производная ха- рактеризует скорость изменения первой производной при изменении аргумента. Это важно, поскольку позволяет оценить, принесет ли шаг градиентного спуска ожидае-мое улучшение. Можно считать, что вторая производная измеряет кривизну. Допус- тим, имеется квадратичная функция (многие возникающие на практике функции, хотя и не являются квадратичными, могут быть достаточно точно аппроксимирова- ны ими, по крайней мере локально). Если вторая производная такой функции равна нулю, значит, кривизны нет. Это идеально плоская линия, значение которой можно предсказать, зная только градиент. Если градиент равен 1, то можно сделать шаг дли-ны ε вдоль направления отрицательного градиента, и функция стоимости уменьшит- ся на ε. Если вторая производная отрицательна, то функция изгибается вниз, поэтому функция стоимости уменьшится больше чем на ε. Наконец, если вторая производная положительна, то функция изгибается вверх, поэтому функция стоимости умень-шится меньше чем на ε. На рис. 4.4 показано, как от кривизны зависит связь между истинным значением функции стоимости и значением, предсказанным на основе ана- лиза градиента. Отрицательная кривизнаНулевая кривизнаПоложительная кривизнаf(x)f(x)f(x) x x x Рис. 4.4  Вторая производная определяет кривизну функции. Показаны квадратичные функции с разной кривизной. Штриховой линией обозначено значение функции стоимости, ожидаемое на основе анализа одного лишь градиента. Если кривизна отрицательна, то функция стоимости убывает быстрее, чем предсказывает градиент. Если кривизна равна нулю, то гра-диент правильно предсказывает значение. Если кривизна положительна, то функция стоимости убывает медленнее, чем предсказывает градиент, и в конечном счете начинает возрастать, поэтому если шаг выбран слишком большим, то можно случайно получить завышенное значение В случае функции нескольких переменных вторых производных много. Их можно собрать в матрицу Гессе, или гессиан. Матрица Гессе H(f)(x) определяется следую- щим образом:\n--- Страница 89 ---\n88  Численные методы (4.6) Можно также сказать, что матрица Гессе является якобианом градиента. Всюду, где вторые частные производные непрерывны, операторы дифференциро- вания коммутативны, т. е. их можно менять местами: (4.7) Это означает, что Hi, j = Hj, i, т. е. в таких точках матрица Гессе симметрична. Для большинства функций, встречающихся в глубоком обучении, матрица Гессе является вещественной и симметричной почти всюду. А раз так, то мы можем найти множест во вещественных собственных значений и ортогональный базис собственных векторов. Вторая производная в направлении единичного вектора d, по определению, равна d⏉Hd. Если d – собственный вектор H, то вторая производная в этом направлении равна соответствующему собственному значению. Для других направлений d вторая производная по направлению равна взвешенному среднему всех собственных значе-ний с весами от 0 до 1, причем чем меньше угол между собственным вектором и d, тем больше вес этого вектора. Максимальное собственное значение определяет макси-мальную вторую производную, а минимальное – минимальную. Вторая производ ная по направлению дает информацию об ожидаемом качестве шага градиентного спус-ка. Можно аппроксимировать функцию f(x) в окрестности точки x (0), оставив только члены не выше второго порядка в ее разложении в ряд Тейлора: f(x) ≈ f(x(0)) + (x – x(0))⏉g + 1/2(x – x(0))⏉H(x – x(0)), (4.8) где g – градиент, а H – гессиан в точке x(0). Если скорость обучения равна ε, то новая точка x определяется по формуле x(0) – εg. Подставляя в приведенную выше формулу, получаем: f(x(0) – εg) ≈ f(x(0)) – εg⏉g + 1/2 ε2g⏉Hg. (4.9) В этой формуле три члена: исходное значение функции, ожидаемое улучшение, обуслов ленное наклоном функции, и поправка на кривизну функции. Если послед- ний член слишком велик, то шаг градиентного спуска может в действительности при- вести к подъему. Если g⏉Hg равно нулю или отрицательно, то аппроксимация рядом Тейлора предсказывает, что при постоянном увеличении ε функция f будет постоянно убывать. На практике ряд Тейлора редко дает точную аппроксимацию для больших ε, поэтому при выборе значения ε приходится прибегать к различным эврис тическим соображениям. Если g ⏉Hg положительно, то, решая уравнение, находим оптималь- ную величину шага, при которой аппроксимация функции рядом Тейлора убывает в наибольшей степени: (4.10) В худшем случае, когда g совпадает по направлению с собственным вектором H, соответствующим максимальному собственному значению λmax, эта оптимальная ве- личина шага равна 1/λmax. Следовательно, если минимизируемую функцию вообще\n--- Страница 90 ---\nОптимизация градиентным методом  89 можно хорошо аппроксимировать квадратичной, собственные значения матрицы Гес- се определяют масштаб скорости обучения. Вторую производную можно использовать, чтобы узнать, является ли критиче- ская точка локальным максимумом, локальным минимумом или седловой точкой. Напомним, что в критической точке f′(x) = 0. Если вторая производная f′′(x) > 0, то первая производная f′(x) возрастает при сдвиге вправо и убывает при сдвиге влево, т. е. f′(x – ε) < 0 и f′(x + ε) > 0 для достаточно малых ε. Иными словами, когда мы смещаемся вправо, угловой коэффициент указывает на подъем с правой стороны, а при смещении влево – на подъем с левой стороны. Следовательно, если f′(x) = 0 и f′′(x) > 0, мы заключаем, что x – локальный минимум. Аналогично, если f′(x) = 0 и f′′(x) < 0, то x – локальный максимум. Это так называемая проверка по второй производной. К сожалению, если f′′(x) = 0, то эта проверка не дает однозначного ре- зультата. В таком случае x может быть седловой точкой или находиться на плоском участке. В многомерном случае необходимо исследовать все вторые производные функции. С помощью спектрального разложения матрицы Гессе мы можем обобщить проверку по второй производной на многомерный случай. В критической точке ∇x f(x) = 0, по- этому путем анализа собственных значений гессиана можно узнать, является ли эта точка локальным максимумом, локальным минимумом или седловой точкой. Если матрица Гессе положительно определенная (все ее собственные значения положи-тельны), то это локальный минимум. В этом можно убедиться, заметив, что вторая производная по любому направлению должна быть положительна, и сославшись на проверку по второй производной в одномерном случае. Аналогично, если матрица Гессе отрицательно определенная (все собственные значения отрицательны), точ-ка является локальным максимумом. В многомерном случае иногда удается найти свидетельства в пользу седловой точки. Если имеется хотя бы одно положительное и хотя бы одно отрицательное собственное значение, то мы знаем, что x является ло- кальным максимумом в одном сечении f и локальным минимумом в другом. Пример приведен на рис. 4.5. Наконец, проверка по второй производной в многомерном слу- чае может не давать однозначного результата, как и в одномерном. Так бывает, когда все ненулевые собственные значения одного знака, но имеется хотя бы одно нуле-вое. Неоднозначность возникает из-за недостаточной информативности одномерной проверки второй производной в сечении, соответствующем нулевому собственному значению. В многомерном случае в одной точке вторые производные по каждому направле- нию различны. Число обусловленности матрицы Гессе в точке измеряет степень раз- личия вторых производных. Если число обусловленности велико, то градиентный спуск будет работать плохо. Это объясняется тем, что в одном направлении производ- ная растет быстро, а в другом медленно. Метод градиентного спуска не в курсе этого различия, поэтому не знает, что предпочтительным направлением для исследования является то, в котором производная дольше остается отрицательной. Из-за плохого числа обусловленности трудно выбрать хорошую величину шага. Шаг должен быть достаточно малым, что не пропустить минимум и подниматься вверх во всех направ- лениях, где кривизна строго положительна. Но обычно это означает, что шаг слишком мал для заметного продвижения в направлениях с меньшей кривизной. Пример при- веден на рис. 4.6.\n--- Страница 91 ---\n90  Численные методы –15–15500 –5000 00 x1x2 1515 f(x1, x2) Рис. 4.5  Седловая точка, в которой присутствует как положительная, так и отрицательная кривизна. Представлен график функции f(x) = x12 – x2 2. Вдоль оси x1 функция изгибается вверх. Направление этой оси – собствен- ный вектор матрицы Г ессе с положительным собственным значением. Вдоль оси x2 функция изгибается вниз. Это направление собственного век- тора матрицы Г ессе с отрицательным собственным значением. Название «седловая точка» связано с тем, что эта поверхность напоминает седло. Это хрестоматийный пример функции с седловой точкой. В многомерном случае для наличия седловой точки необязательно, чтобы собственное значение было равно 0; необходимо лишь, чтобы существовали как поло- жительные, так и отрицательные собственные значения. В седловой точке, соответствующей собственным значениям разных знаков, в одном сечении достигается локальный максимум, а в другом – локальный минимум Эту проблему можно решить, используя матрицу Гессе для управления поиском. Простейший метод такого рода известен под названием метода Ньютона. Он основан на разложении f(x) в ряд Тейлора с точностью до членов второго порядка в окрест- ности точки x(0): f(x) ≈ f(x(0)) + (x – x(0))⏉∇x f(x(0)) + 1/2(x – x(0))⏉H(f)(x(0))(x – x(0)). (4.11) Из этого уравнения находим критическую точку функции: x* = x(0) – H( f)(x(0))–1∇x f(x(0)). (4.12) Если f – положительно определенная квадратичная функция, то метод Ньютона состоит в однократном применении уравнения (4.12) для непосредственного нахож- дения точки минимума. Если функция f не квадратичная, но может быть локально аппроксимирована положительно определенной квадратичной функцией, то уравне- ние (4.12) нужно применить несколько раз. Итеративное уточнение аппроксимации с нахождением минимума аппроксимирующей функции позволяет достичь крити- ческой точки гораздо быстрее, чем метод градиентного спуска. Это полезное свой-ство вблизи локального минимума, но оно может оказаться опасным в окрестности седловой точки. В разделе 8.2.3 мы увидим, что метод Ньютона годится, только если ближайшая критическая точка является минимумом (все собственные значения мат-рицы Гессе положительны), тогда как метод градиентного спуска не притягивается к седловой точке, если только на нее не указывает градиент. Алгоритмы оптимизации, основанные только на градиенте, в частности метод гра- диентного спуска, называются алгоритмами оптимизации первого порядка. Если\n--- Страница 92 ---\nОптимизация градиентным методом  91 учитывается также гессиан, как в методе Ньютона, то это алгоритм оптимизации второго порядка (Nocedal and Wright, 2006). 20 10 0 –10–20 –30 –30 –20 –10 0 х 1х2 10 20 Рис. 4.6  Метод градиентного спуска не использует информацию о кри- визне, содержащуюся в гессиане. Здесь градиентный спуск применяется для минимизации квадратичной функции f(x), для которой число обуслов- ленности гессиана равно 5. Это означает, что величина кривизны в направ- лениях наибольшей и наименьшей кривизны различается в пять раз. В дан- ном случае направление наибольшей кривизны совпадает с вектором [1, 1]⏉, а наименьшей – с вектором [1, –1]⏉. Красной линией показан путь, которым следует метод градиентного спуска. Эта вытянутая квадратичная функция напоминает длинный каньон. Градиентный спуск бесполезно тратит много времени, раз за разом спускаясь по стенкам каньона, поскольку это направ-ления наискорейшего спуска. Так как шаг слишком большой, мы проскакива-ем мимо дна каньона и вынуждены спускаться по противоположной стенке на следующей итерации. Большое положительное значение матрицы Г ессе, соответствующее собственному вектору в этом направлении, подсказывает, что производная по этому направлению быстро возрастает, поэтому алго-ритм оптимизации мог бы воспользоваться гессианом и понять, что в данном случае производить поиск в направлении наискорейшего спуска не стоит Алгоритмы оптимизации, применяемые в большинстве случаев, рассматриваемых в этой книге, годятся для широкого спектра функций, но не дают почти никаких га- рантий. Отсутствие гарантий связано с тем, что функции, используемые в глубоком обучении, чрезвычайно сложны. Во многих других областях принято разрабатывать алгоритмы оптимизации для ограниченного семейства функций. В контексте глубокого обучения иногда можно получить некоторые гарантии, если ограничиться функциями, которые либо удовлетворяют условию Липшица, либо имеют производные, удовлетворяющие этому условию. Говорят, что функция f удовлетворяет условию Липшица, если скорость ее изменения ограничена некоторой константой ℒ, которая называется постоянной Липшица: ∀x, ∀y, | f(x) – f(y)| ≤ ℒ|| x – y || 2. (4.13) Это свойство полезно, т. к. позволяет количественно выразить предположение о том, что небольшое изменение аргументов, как, например, в алгоритме градиентно-\n--- Страница 93 ---\n92  Численные методы го спуска, приводит к небольшому изменению функции. Условие Липшица является довольно слабым ограничением, и многие задачи оптимизации в глубоком обучении можно свести к этому случаю путем сравнительно небольшой модификации. Пожалуй, самым успешным примером специализированной оптимизации являет- ся выпуклая оптимизация. Алгоритмы выпуклой оптимизации могут дать куда боль- шие гарантии ценой более строгих ограничений. Они применимы только к выпуклым функциям – таким, для которых матрица Гессе является всюду положительно полу- определенной. Такие функции хорошо себя ведут, потому что не могут иметь сед-ловых точек, а все локальные минимумы обязательно глобальны. Однако большин- ство задач глубокого обучения трудно выразить в терминах выпуклой оптимизации. Выпуклая оптимизация применяется только в качестве подпрограммы в некоторых алгоритмах глубокого обучения. Идеи, заимствованные из выпуклой оптимизации, бывают полезны для доказательства сходимости алгоритмов, но в общем случае цен- ность выпуклой оптимизации в контексте глубокого обучения невелика. Дополни- тельные сведения о выпуклой оптимизации см. в работах Boyd and Vandenberghe (2004) или Rockafellar (1997). 4.4. Оптимизация с ограничениями Иногда задача состоит в том, чтобы найти максимум или минимум функции f(x) не во всей области допустимых значений x, а лишь в некотором ее подмножестве 𝕊. Та- кая задача называется оптимизацией с ограничениями, или ограниченной оптимиза- цией. В этом случае точки множества 𝕊 называются допустимыми. Часто нас интересует решение, которое в некотором смысле мало. В таких случаях обычно налагается ограничение на норму, например || x|| ≤ 1. Для решения задачи оптимизации с ограничениями можно просто изменить метод градиентного спуска, учтя ограничение. Если используется небольшой постоянный шаг ε, то можно выполнить шаги градиентного спуска, а затем спроецировать резуль- таты обратно в 𝕊. При использовании линейного поиска можно искать только с та- кими шагами, при которых новая точка x оказывается допустимой, или же проеци- ровать каждую точку на прямой обратно в область ограничения. Там, где возможно, эффективность этого метода можно повысить, проецируя градиент на касательное пространство к допустимой области, перед тем как делать шаг или начинать линей- ный поиск (Rosen, 1960). Более сложный подход – сформулировать другую задачу оптимизации без ограни- чений, решение которой можно преобразовать в решение исходной задачи с ограниче- ниями. Например, если мы хотим минимизировать f(x) для x ∈ ℝ 2 с ограничением – x должно иметь строго единичную норму L2, то можно вместо этого минимизировать функцию g(θ) = f([cos θ, sin θ]⏉) относительно θ, а затем вернуть [cos θ, sin θ] в каче- стве решения исходной задачи. Этот подход требует изобретательности; для каждой задачи оптимизации приходится придумывать отдельное преобразование. Метод Каруша–Куна–Таккера (ККТ) 1 предлагает очень общий подход к реше- нию задач оптимизации. Вводится новая функция, называемая обобщенным лагран- жианом, или обобщенной функцией Лагранжа. 1 Метод ККТ является обобщением метода множителей Лагранжа, который допускает толь- ко ограничения типа равенств.\n--- Страница 94 ---\nОптимизация с ограничениями  93 Чтобы определить лагранжиан, мы сначала должны описать 𝕊 с помощью равенств и неравенств, т. е. m функций g(i) и n функций h(j) – таких, что 𝕊= {x | ∀i, g(i)(x) = 0 и ∀j, h(j)(x) ≤ 0}. Условия, содержащие функции g(i), называются ограничениями типа равенств, а содержащие функции h(i) – ограничениями типа неравенств. Для каждого ограничения вводятся новые переменные λi и αj, называемые множи- телями ККТ. Обобщенный лагранжиан записывается в виде: . (4.14) Теперь задачу минимизации с ограничениями можно решить, подвергнув обоб- щенный лагранжиан оптимизации без ограничений. Если существует хотя бы одна допустимая точка и f(x) не может принимать значение 1, то (4.15) обладает такой же целевой функцией и множеством оптимальных точек x, что и (4.16) Это следует из того, что если ограничения удовлетворяются, то , (4.17) а если некоторое ограничение нарушается, то (4.18) Эти свойства гарантируют, что никакая недопустимая точка не может быть опти- мальной, а величина оптимума на множестве допустимых точек не изменяется. Чтобы выполнить максимизацию с ограничениями, мы можем построить обоб- щенный лагранжиан –f(x), который приводит к такой задаче оптимизации: (4.19) Можно также свести задачу к задаче максимизации во внешнем цикле: (4.20) Знак члена, содержащего ограничения типа равенств, не имеет значения; можно выбрать как плюс, так и минус, потому что алгоритм оптимизации волен выбирать любые знаки коэффициентов λi. Ограничения типа неравенств особенно интересны. Мы говорим, что ограничение h(i)(x) активно, если h(i)(x*) = 0. Если ограничение не активно, то решение задачи, найденное при наличии этого ограничения, останется, по меньшей мере, локальным решением, если ограничение снять. Может случиться, что неактивное ограничение исключает другие решения. Например, в выпуклой задаче, где имеется целая об- ласть глобально оптимальных точек (широкая плоская область с одинаковой стои- мостью), некоторое подмножество этой области может исключаться ограничениями. А в невыпуклой задаче, возможно, удалось бы найти лучшие локальные стационар- ные точки, но они исключаются ограничениями, неактивными в точке сходимости. Тем не менее точка сходимости остается стационарной точкой вне зависимости от\n--- Страница 95 ---\n94  Численные методы того, включены или нет неактивные ограничения. Поскольку значение неактивной функции h(i) отрицательно, в решении задачи minx maxλ maxα, α≥0 L(x, λ, α) коэффици- ент αi = 0. Таким образом, в решении α ⊙ h(x) = 0. Иначе говоря, для всех i мы знаем, что хотя бы одно из ограничений – αi ≥ 0 или h(i)(x) ≤ 0 – должно быть активно для решения. Интуитивно эту мысль можно выразить, сказав, что решение либо нахо-дится на границе, определяемой неравенством, и тогда мы должны использовать его множитель ККТ, либо неравенство вообще не влияет на решение, и тогда его множи- тель ККТ обнуляется. У оптимальных точек задач оптимизации с ограничениями есть простой набор свойств, называемых условиями Каруша–Куна–Таккера (Karush, 1939; Kuhn and Tucker, 1951). Это необходимые, но недостаточные условия оптимальности точки. Градиент обобщенного лагранжиана равен нулю. Все ограничения на x и на множители ККТ удовлетворяются. Ограничения типа неравенств обладают свойством «дополняющей нежестко-сти»: α ⊙ h(x) = 0. Дополнительные сведения о методе ККТ см. в работе Nocedal and Wright (2006). 4.5. Пример: линейный метод наименьших квадратов Требуется найти значение x, минимизирующее функцию f(x) = 1/2||Ax – b||2 2. (4.21) В линейной алгебре рассматриваются специализированные алгоритмы для эффек- тивного решения этой задачи, но мы покажем, как решить ее методами градиентной оптимизации. Сначала получим выражение для градиента: ∇ x f(x) = A⏉(Ax – b) = A⏉Ax – A⏉b. (4.22) Затем будем небольшими шагами спускаться вдоль направления градиента. Дета- ли описаны в алгоритме 4.1. Алгоритм 4.1. Алгоритм минимизации f(x) = 1/2||Ax – b||22 относительно x методом градиентного спуска, начиная с произвольного значения x Взять в качестве величины шага (ε ) и допуска (δ ) небольшие положительные числа. while ||A⏉Ax – A⏉b||2 > δ do x ⟵ x – ε(A⏉Ax – A⏉b) end while Эту задачу можно решить также методом Ньютона. Поскольку истинная функция квадратичная, то квадратичная аппроксимация в методе Ньютона является точной, и алгоритм сходится к глобальному минимуму за один шаг. Теперь предположим, что требуется минимизировать ту же функцию, но при на- личии ограничения x⏉x ≤ 1. Введем в рассмотрение лагранжиан: L(x, λ) = f(x) + λ(x⏉x – 1) . (4.23)\n--- Страница 96 ---\nПример: линейный метод наименьших квадратов  95 Теперь можно решать задачу: (4.24) Решение задачи без ограничений с наименьшей нормой можно найти с помощью псевдообратной матрицы Мура–Пенроуза: x = A+b. Если эта точка допустима, то мы нашли решение задачи с ограничениями. В противном случае нужно найти решение, для которого ограничение активно. Продифференцировав лагранжиан по x, получа- ем уравнение: A⏉Ax – A⏉b + 2λx = 0. (4.25) Отсюда следует, что решение нужно искать в виде: x = (A⏉A + 2λI)–1A⏉b. (4.26) Абсолютную величину λ следует выбирать так, чтобы результат удовлетворял ограничению. Чтобы найти такое значение, можно выполнить градиентный подъем по λ. Для этого заметим, что (4.27) Когда норма x превышает 1, эта производная положительна, поэтому, чтобы под- ниматься вверх в направлении производной и увеличивать лагранжиан относительно λ, мы увеличиваем λ. Поскольку штрафной коэффициент при x⏉x увеличился, разре- шение линейного уравнения относительно x теперь даст решение с меньшей нормой. Процесс решения линейного уравнения и корректировки λ продолжается до тех пор, пока норма x не окажется допустимой и производная по λ не станет равна 0. На этом мы завершаем обзор математического аппарата, который понадобится для разработки алгоритмов машинного обучения. Все готово к построению и анализу полноценных систем обучения.",
      "debug": {
        "start_page": 83,
        "end_page": 96
      }
    },
    {
      "name": "Глава 5. Основы машинного обучения 96",
      "content": "--- Страница 97 --- (продолжение)\nГлава 5 Основы машинного обучения Глубокое обучение – частный случай машинного обучения. Чтобы хорошо пони- мать глубокое обучение, нужно как следует усвоить основные принципы машинного обуче ния. В этой главе кратко излагаются самые важные общие принципы машин- ного обучения, которые найдут применение в остальной части книги. Читателям, совсем незнакомым с предметом или желающим получить более широкое представ- ление о нем, рекомендуем учебники, в которых фундаментальные основы рассматри- ваются более подробно, например Murphy (2012) или Bishop (2006). Если вы уже зна-комы с машинным обучением, можете сразу перейти к разделу 5.11, где обсуждаются некоторые взгляды на традиционное машинное обучение, оказавшие значительное влияние на разработку алгоритмов глубокого обучения. Начнем с определения алгоритма обучения и приведем пример: алгоритм линей- ной регрессии. Затем опишем, чем проблема соответствия обучающим данным отли-чается от проблемы поиска закономерностей, которые обобщаются на новые данные. У большинства алгоритмов машинного обучения есть настройки, которые называ- ются гиперпараметрами и должны определяться вне самого алгоритма обучения; мы обсудим, как задавать их с помощью дополнительных данных. Машинное обучение по сути своей является вариантом прикладной статистики, когда особый упор делает-ся на использовании компьютеров для статистического оценивания сложных функ-ций, а меньше внимания уделяется определению доверительных интервалов для этих функций. Поэтому мы представим два основных подхода к статистике: частотные оценки и байесовский вывод. Большинство алгоритмов машинного обучения можно отнести к одной из двух категорий: с учителем и без учителя; мы опишем, что это значит, и приведем примеры простых алгоритмов из каждой категории. Большин- ство алгоритмов глубокого обучения основано на алгоритме оптимизации, который называется стохастическим градиентным спуском. Мы покажем, как алгоритм глу-бокого обучения собирается из составных частей: алгоритма оптимизации, функции стоимости, модели и набора данных. Наконец, в разделе 5.11 мы опишем некоторые факторы, ограничивающие способность традиционного машинного обучения к обоб- щению. Именно стремление преодолеть эти проблемы и стало побудительным моти- вом к разработке алгоритмов глубокого обучения.\nГлава 5 Основы машинного обучения Глубокое обучение – частный случай машинного обучения. Чтобы хорошо пони- мать глубокое обучение, нужно как следует усвоить основные принципы машинного обуче ния. В этой главе кратко излагаются самые важные общие принципы машин- ного обучения, которые найдут применение в остальной части книги. Читателям, совсем незнакомым с предметом или желающим получить более широкое представ- ление о нем, рекомендуем учебники, в которых фундаментальные основы рассматри- ваются более подробно, например Murphy (2012) или Bishop (2006). Если вы уже зна-комы с машинным обучением, можете сразу перейти к разделу 5.11, где обсуждаются некоторые взгляды на традиционное машинное обучение, оказавшие значительное влияние на разработку алгоритмов глубокого обучения. Начнем с определения алгоритма обучения и приведем пример: алгоритм линей- ной регрессии. Затем опишем, чем проблема соответствия обучающим данным отли-чается от проблемы поиска закономерностей, которые обобщаются на новые данные. У большинства алгоритмов машинного обучения есть настройки, которые называ- ются гиперпараметрами и должны определяться вне самого алгоритма обучения; мы обсудим, как задавать их с помощью дополнительных данных. Машинное обучение по сути своей является вариантом прикладной статистики, когда особый упор делает-ся на использовании компьютеров для статистического оценивания сложных функ-ций, а меньше внимания уделяется определению доверительных интервалов для этих функций. Поэтому мы представим два основных подхода к статистике: частотные оценки и байесовский вывод. Большинство алгоритмов машинного обучения можно отнести к одной из двух категорий: с учителем и без учителя; мы опишем, что это значит, и приведем примеры простых алгоритмов из каждой категории. Большин- ство алгоритмов глубокого обучения основано на алгоритме оптимизации, который называется стохастическим градиентным спуском. Мы покажем, как алгоритм глу-бокого обучения собирается из составных частей: алгоритма оптимизации, функции стоимости, модели и набора данных. Наконец, в разделе 5.11 мы опишем некоторые факторы, ограничивающие способность традиционного машинного обучения к обоб- щению. Именно стремление преодолеть эти проблемы и стало побудительным моти- вом к разработке алгоритмов глубокого обучения.\n--- Страница 98 ---\nАлгоритмы обучения  97 5.1. Алгоритмы обучения Алгоритм машинного обучения – это алгоритм, способный обучаться на данных. Но что мы понимаем под обучением? В работе Mitchell (1997) дано такое лаконичное определение: «Говорят, что компьютерная программа обучается на опыте E относи- тельно некоторого класса задач T и меры качества P, если качество на задачах из T, измеренное с помощью P, возрастает с ростом опыта E». Можно представить себе ши- рокое разнообразие опыта E, задач T и мер качества P, и в этой книге мы не будем пытаться формально определить, что можно использовать в качестве каждой из этих сущностей. Вместо этого в следующих разделах мы приведем интуитивно понятные описания и примеры различных задач, мер качества и видов опыта, пригодных для конструирования алгоритмов машинного обучения. 5.1.1. Задача T Машинное обучение позволяет справляться с задачами, которые слишком сложны для решения с помощью фиксированных программ, спроектированных и написан- ных людьми. С научной и философской точки зрения, машинное обучение интересно тем, что чем лучше мы понимаем его, тем глубже становится наше понимание прин- ципов, лежащих в основе разума. Говоря о «задаче», сразу отметим, что сам процесс обучения задачей не является. Обучение – это средство, благодаря которому мы получаем возможность выполнить задачу. Например, если мы хотим, чтобы робот мог ходить, то хождение – это задача. Мы можем запрограммировать робота на обучение хождению или попробовать вруч-ную написать программу, которая описывает, как надо ходить. Задачи машинного обучения обычно описываются в терминах того, как система машинного обучения должна обрабатывать пример. Примером является набор при- знаков, полученных в результате количественного измерения некоторого объекта или события, которые система должна научиться обрабатывать. Как правило, при-мер представляется в виде вектора x ∈ ℝ n, каждый элемент которого – признак. Так, признаками изображения обычно являются значения его пикселей. С помощью машинного обучения можно решать разнообразные задачи. Перечис- лим наиболее типичные. Классификация. В задачах этого типа программа должна ответить, какой из k категорий принадлежит некоторый пример. Для решения этой задачи алгоритм обучения обычно просят породить функцию f : ℝ n ⟶ {1, …, k}. Если y = f(x), то модель относит входной пример, описываемый вектором x, к категории с чис- ловым кодом y. Существуют и другие варианты задачи классификации, напри- мер когда f – распределение вероятности принадлежности к классам. Приме- ром задачи классификации является распознавание объектов, когда на вход подается изображение (обычно представленное множеством значений яркости пикселей), а на выходе получается числовой код, который идентифицирует присутствующий в изображении объект. Например, робот Willow Garage PR2 может исполнять функции официанта: он умеет распознавать различные на-питки и по команде приносить их людям (Goodfellow et al., 2010). В настоящее время распознавание объектов лучше всего производится методами глубокого обучения (Krizhevsky et al., 2012; Ioffe and Szegedy, 2015). Распознавание объ-ектов основано на той же базовой технологии, которая позволяет компьютерам\n--- Страница 99 ---\n98  Основы машинного обучения распознавать лица (Taigman et al., 2014). Это можно использовать для автома- тической пометки людей в коллекциях фотографий и для организации более естественного взаимодействия компьютера с пользователями. Классификация при отсутствии некоторых данных. Классификация ослож- няется, если нет гарантии, что программа получает во входном векторе ре-зультаты всех измерений. Чтобы решить задачу классификации, алгоритм обучения должен определить всего одну функцию, отображающую входной вектор на код категории. Но если часть входных данных отсутствует, то алго-ритм должен обучить набор функций. Каждая функция соответствует класси-фикации x в условиях, когда отсутствуют различные подмножества данных. Один из способов эффективно определить такое большое множество функ-ций – обучить распределение вероятности всех релевантных величин, а за- тем решать задачу классификации, вычисляя маргинальные распределения отсутствующих величин. Если на вход подается n величин, то существует 2 n различных функций классификации для каждого возможного набора отсут-ствующих данных, однако программе нужно обучить только одну функцию, описывающую совместное распределение вероятности. Пример глубокой ве-роятностной модели, применимой к такой задаче, приведен в работе Goodfel- low et al. (2013b). Многие другие задачи, описанные в этом разделе, также допускают обобщение на случай отсутствующих данных; классификация при отсутствии некоторых данных – лишь один пример того, на что способно ма- шинное обучение. Регрессия. В этой задаче программа должна предсказать числовое значение по входным данным. Для ее решения алгоритм обучения просят породить функ-цию f : ℝ n ⟶ ℝ. Регрессия отличается классификации форматом выхода. При- мером может служить прогнозирование суммы претензии, на которую будет претендовать застрахованный (это нужно для определения размера страховой премии), или прогнозирование будущей стоимости ценных бумаг. Такого рода прогнозы применяются также в алгоритмическом трейдинге. Транскрипция. В задачах такого типа системе машинного обучения предлага- ется проанализировать неструктурированное представление некоторых дан-ных и преобразовать его в дискретную текстовую форму. Например, программе распознавания текста предъявляется фотография текста, а она должна вернуть текст в виде последовательности символов (скажем, в кодировке ASCII или Unicode). В системе Google Street View глубокое обучение используется для подобной обработки табличек с адресами домов (Goodfellow et al., 2014d). Дру- гой пример – распознавание речи, когда программе предъявляется аудиосиг- нал, а она выводит последовательность символов или идентификаторов про- изнесенных слов. Глубокое обучение – важнейший компонент современных систем распознавания речи, используемых в таких компаниях, как Microsoft, IBM и Google (Hinton et al., 2012b). Машинный перевод. В этой задаче входные данные – последовательность символов на одном языке, а программа должна преобразовать ее в последо- вательность символов на другом языке. Обычно такие системы применяются к естественным языкам, скажем, для перевода с английского на французский. В последнее время глубокое обучение стало проникать и в эту область (Suts ke- ver et al., 2014; Bahdanau et al., 2015).\n--- Страница 100 ---\nАлгоритмы обучения  99 Структурный вывод. Под структурным выводом понимается любая задача, в которой на выходе порождается вектор (или иная структура, содержащая несколько значений), между элементами которого существуют важные связи. Это широкая категория, в которую входят, в частности, задачи транскрипции и перевода. Еще одна задача – грамматический разбор, т. е. преобразование предложения на естественном языке в дерево, описывающее его грамматиче- скую структуру; узлы такого дерева снабжены метками «глагол», «существи-тельное», «наречие» и т. д. Пример применения глубокого обучения к задаче грамматического разбора имеется в работе Collobert (2011). Можно также рассмотреть пиксельную сегментацию изображения, когда программа долж-на отнести каждый пиксель к определенной категории. Например, глубокое обуче ние можно использовать для аннотирования дорог на аэрофотоснимках (Mnih and Hinton, 2010). Формат выхода не всегда так точно повторяет формат ввода, как в задачах, сводящихся к аннотированию. Например, в задаче подпи- сывания изображений программе предъявляется изображение, а она выводит его описание в виде предложения на естественном языке (Kiros et al., 2014a,b; Mao et al., 2015; Vinyals et al., 2015b; Donahue et al., 2014; Karpathy and Li, 2015; Fang et al., 2015; Xu et al., 2015). Название «структурный вывод» отражает тот факт, что программа должна вывести несколько тесно связанных между собой значений. Так, слова, порождаемые программой подписывания изображений, должны образовывать допустимое предложение. Обнаружение аномалий. В этой задаче программа анализирует множество со- бытий или объектов и помечает некоторые из них как нетипичные. Примером может служить обнаружение мошенничества с кредитными картами. Благо- даря моделированию покупательских привычек компания-эмитент кредитных карт может обнаружить аномальное использование карты. Покупки человека, укравшего вашу карту или информацию о ней, зачастую характеризуются не таким распределением вероятности, как ваши. Обнаружив аномальную покуп-ку, компания сможет предотвратить мошенничество, заблокировав счет. Обзор методов обнаружения аномалий приведен в работе Chandola et al. (2009). Синтез и выборка. В задачах этого типа алгоритм машинного обучения дол- жен генерировать новые примеры, похожие на обучающие данные. Синтез и выборка методами машинного обучения полезны в мультимедийных при- ложениях, когда генерирование больших объемов данных вручную обходится дорого, скучно или занимает слишком много времени. Например, видеоигры умеют автоматически генерировать текстуры для больших объектов или ланд-шафтов, не заставляя художника вручную помечать каждый пиксель (Luo et al., 2013). В некоторых случаях мы хотим, чтобы процедура выборки или син- теза генерировала определенный выход по заданному входу. Например, в зада- че синтеза речи программе передается написанная фраза, а она должна выдать аудиосигнал, содержащий ее же в произнесенном виде. Это разновидность структурного вывода с дополнительной особенностью: для заданного входа не существует единственно правильного выхода, мы специально допускаем большую вариативность выхода, чтобы речевой сигнал звучал естественно и реалистично. Подстановка отсутствующих значений. В этом случае алгоритму машин- ного обучения предъявляется новый пример x ∈ ℝ n, в котором некоторые\n--- Страница 101 ---\n100  Основы машинного обучения элементы xi отсутствуют. Алгоритм должен спрогнозировать значения отсут- ствующих элементов. Шумоподавление. В этой задаче алгоритму машинного обучения предъявля- ется искаженный помехами пример x� ∈ ℝn, полученный из чистого примера x ∈ ℝn в результате неизвестного процесса искажения. Алгоритм должен вос- становить чистый пример x по искаженному x� или, в более общем случае, вер- нуть условное распределение вероятности p(x | x �). Оценка функции вероятности или функции плотности вероятности. В зада- че оценки плотности алгоритм должен обучить функцию pmodel : ℝn ⟶ ℝ, где pmodel(x) интерпретируется как функция плотности вероятности (если x – не- прерывная случайная величина) или как функция вероятности (в дискретном случае) в пространстве, из которого были взяты примеры. Чтобы решить эту задачу хорошо (что это значит, мы точно определим в разделе о мерах качества), алгоритм должен выявить структуру предъявленных данных. Он должен по-нять, где примеры расположены тесно, а где их появление маловероятно. Для большинства описанных выше задач требуется, чтобы алгоритм хотя бы неявно уловил структуру распределения вероятности. В задаче оценки плотности это распределение должно быть определено явно. В принципе, найденное распре- деление впоследствии можно использовать для решения других задач. Напри-мер, получив распределение вероятности p(x), мы можем воспользоваться им для подстановки отсутствующих значений. Если значение x i отсутствует, а все остальные значения, множество которых обозначается x–i, имеются, то мы зна- ем, что распределение xi имеет вид p(xi | x–i). На практике оценка плотности не всегда позволяет решить все сопутствующие задачи, потому что операции, кото-рые нужно выполнить с p(x), требуют непомерно большого объема вычислений. Разумеется, есть много других типов задач. Перечисленные выше типы – лишь пример того, на что способно машинное обучение, а не строгая систематизация. 5.1.2. Мера качества P Чтобы оценить возможности алгоритма машинного обучения, мы должны иметь ко-личественную меру его качества. Обычно мера качества P специфична для решаемой системой задачи T. Для таких задач, как классификация, классификация при отсутствии части данных и транскрипция, часто измеряется верность (accuracy) модели. Верностью называет- ся доля примеров, для которых модель выдала правильный результат. Эквивалент-ную информацию можно получить путем измерения частоты ошибок – доли при- меров, для которых модель выдала неправильный результат. Иногда частота ошибок описывается бинарной функцией потерь, которая принимает для данного примера значение 0, если он классифицирован правильно, и 1, если неправильно. В задаче оценки плотности не имеет смысла измерять верность, частоту ошибок или любой другой бинарный показатель. Нужна какая-то другая мера качества, принимающая значения из непрерывного диапазона. Чаще всего для этой цели используется сред-няя логарифмическая вероятность, присваиваемая примерам моделью. Обычно нас интересует, насколько хорошо алгоритм машинного обучения работает на данных, которых прежде не видел, поскольку это показывает, как будет вести себя модель, развернутая в реальном приложении. Поэтому меры качества вычисляются для тестового набора данных, отдельного от данных, на которых система обучалась.\n--- Страница 102 ---\nАлгоритмы обучения  101 Выбор меры качества может показаться простым и объективным делом, но зачас- тую очень трудно найти такую меру, которая точно соответствует желаемому поведе- нию системы. Иногда причина в том, что трудно решить, что же нужно измерять. Например, в за- даче транскрипции нужно измерять верность при транскрипции всей последователь-ности или лучше использовать более детальную меру, которая поощряет за правиль-ную транскрипцию отдельных элементов последовательности? В задаче регрессии за что штрафовать систему сильнее: за частые ошибки средней серьезности или за редкие, но очень серьезные ошибки? Ответ на такие вопросы зависит от приложения. Но бывает и так, что мы точно знаем, что хотели бы измерить в идеале, только сам процесс измерения практически не реализуем. Такое часто случается в контекс- те оценивания плотности. Многие из лучших вероятностных моделей представляют распределение вероятности лишь неявно. Вычислить фактическую вероятность кон-кретной точки в пространстве в подобных моделях технически невозможно. В таких случаях нужно придумать альтернативный критерий, который все же соответствует проектным целям, или предложить хорошую аппроксимацию желаемого критерия. 5.1.3. Опыт E Алгоритмы машинного обучения можно разделить на два больших класса, без учите- ля и с учителем, в зависимости от того, на каком опыте они могут обучаться. Можно считать, что большинству алгоритмов обучения, описываемых в этой кни- ге, в качестве опыта доступен весь набор данных. Набором данных называется сово- купность большого числа примеров в смысле раздела 5.1.1. Иногда примеры называ- ются замерами, или точками. Один из самых старых наборов данных, используемых исследователями в области статистики и машинного обучения, – Iris (Fisher, 1936). Это результаты измерений различных частей 150 растений семейства ирисовых. Каждому растению соответству-ет один пример. Признаками являются обмеры частей растения: длина чашелистика, ширина чашелистика, длина лепестка и ширина лепестка. Указано также, к какому виду относится растение. Всего в наборе данных представлены три вида. Алгоритму обучения без учителя в качестве опыта предъявляется набор данных, содержащий много признаков, а алгоритм должен выявить полезные структурные свойства этого набора. В глубоком обучении нас обычно интересует полное распре- деление вероятности, описывающее предъявленный набор – явно, как в задаче оцени- вания плотности, или неявно, как в задачах синтеза или очистки от шума. Некоторые алгоритмы обучения без учителя решают другие задачи, например алгоритм класте-ризации, который должен выделить в наборе данных кластеры похожих примеров. Алгоритму обучения с учителем предъявляется набор данных, содержащий при- знаки, в котором каждый пример снабжен меткой, или целевым классом. Так, в на- боре данных Iris примеры аннотированы видами растений. Алгоритм должен проана-лизировать набор Iris и научиться определять класс ириса по результатам измерений. Грубо говоря, обучение без учителя означает наблюдение нескольких примеров случайного вектора x с последующей попыткой вывести, явно или неявно, распре- деление вероятности p(x) или некоторые интересные свойства этого распределения. А обучение с учителем сводится к наблюдению нескольких примеров случайного вектора x и ассоциированного с ним значения или вектора y с последующей попыт- кой предсказать y по x, обычно в виде оценки p(y | x). Мы считаем, что метка y предо-\n--- Страница 103 ---\n102  Основы машинного обучения ставлена неким учителем, который объясняет системе машинного обучения, что де- лать, – отсюда и название «обучение с учителем». В обучении без учителя никакого учителя не существует, и алгоритм должен извлечь из данных смысл без подсказки. Обучение с учителем и без учителя – термины, не имеющие формального опреде- ления. Границы между тем и другим часто размыты. Многие технологии машинно- го обучения применимы к решениям задач обоих типов. Например, цепное правило вероятностей утверждает, что для вектора x ∈ ℝn совместное распределение можно представить в виде произведения: (5.1) Такое разложение означает, что моделирование p(x), которое на первый взгляд ка- жется задачей без учителя, можно разделить на n задач обучения с учителем. С дру- гой стороны, задачу обучения с учителем, состоящую в вычислении p(y | x), можно решить с помощью традиционных методов обучения без учителя: найти совместное распределение p(x, y), а затем вычислить (5.2) Хотя обучение с учителем и без учителя – понятия, не формализованные и не раз- деленные четкой границей, они все же помогают приблизительно распределить по категориям некоторые задачи, решаемые в машинном обучении. Принято относить задачи регрессии, классификации и структурного вывода к обучению с учителем, а задачу оценивания плотности – к обучению без учителя. Возможны и другие варианты парадигмы обучения. Например, в случае обучения с частичным привлечением учителя одни примеры снабжены метками, а другие – нет. В многовариантном обучении вся совокупность примеров помечается как содержа- щая или не содержащая пример класса, но отдельные ее элементы никак не помеча-ются. Недавний пример многовариантного обучения глубоких моделей см. в работе Kotzias et al. (2015). В некоторых алгоритмах машинного обучения в роли опыта выступает не только фиксированный набор данных. Так, алгоритмы обучения с подкреплением взаимо- действуют с окружающей средой, так что между системой обучения и ее опытом обра- зуется контур с обратной связью. Такие алгоритмы выходят за рамки нашей книги. Дополнительные сведения об обучении с подкреплением см. в работах Sutton and Barto (1998) или Bertsekas and Tsitsiklis (1996), а о подходе к этой теме на основе глубокого обучения – Mnih et al. (2013). В большинстве алгоритмов машинного обучения опытом является просто набор данных, который можно описать разными способами. Но в любом случае набор дан- ных – это совокупность примеров, каждый из которых является совокупностью при- знаков. Один распространенный способ описания набора данных – матрица плана. В стро- ках этой матрицы расположены примеры, а в столбцах – признаки. Например, в на- боре данных Iris 150 примеров с четырьмя признаками на каждый. Следовательно, его можно представить матрицей плана X ∈ ℝ 150×4, где Xi, 1 – длина чашелистика i-го расте- ния, Xi, 1 – ширина чашелистика i-го растения и т. д. Большинство алгоритмов обуче-\n--- Страница 104 ---\nАлгоритмы обучения  103 ния в этой книге описывается в терминах работы с наборами данных, представленны- ми в виде матрицы плана. Разумеется, описать набор данных матрицей плана можно, только если каждый пример описывается вектором, причем все эти векторы должны быть одинакового размера. Так бывает не всегда. Например, в коллекции фотографий разной ширины и высоты фотографии состоят из разного числа пикселей и, значит, описываются векторами разной длины. В разделе 9.7 и в главе 10 мы обсудим, как работать с гете- рогенными данными. В подобных случаях набор данных описывается не матрицей с m строками, а множеством m элементов: {x(1), x(2),…, x(m)}. Такая нотация не предпо- лагает, что любые два вектора-примера x(i) и x(j) имеют одинаковый размер. В случае обучения с учителем пример содержит не только набор признаков, но и мет- ку. Так, если мы хотим обучить алгоритм распознавать объекты на фотографиях, то должны будем указать, какие объекты присутствуют на каждой фотографии. Для это-го можно задавать числовой код: 0 – человек, 1 – автомобиль, 2 – кошка и т. д. Часто при работе с набором данных в виде матрицы плана с наблюдаемыми признаками X мы предоставляем также вектор меток y, в котором элемент y i содержит метку i-го примера. Конечно, не всегда метка – единственное число. Так, если мы хотим научить систе- му распознавания речи транскрибировать целые предложения, то меткой для каждо-го примера будет последовательность слов. Как не существует формального опреде-ления обучения с учителем и без учителя, так нет и строгой систематизации наборов данных или видов опыта. Описанные выше структуры покрывают большинство слу-чаев, но для новых приложений всегда можно придумать что-то необычное. 5.1.4. Пример: линейная регрессия Наше определение алгоритма машинного обучения как алгоритма, способного улуч-шить качество работы программы для решения некоторой задачи на основе опыта, звучит несколько абстрактно. Чтобы добавить конкретики, приведем пример прос-того алгоритма машинного обучения: линейной регрессии. Мы будем не раз воз-вращаться к нему по ходу знакомства с дополнительными концепциями машинного обуче ния, чтобы лучше понять поведение алгоритма. Как следует из названия, линейная регрессия решает задачу регрессии. Иными словами, наша цель – построить систему, которая принимает на входе вектор x ∈ ℝ n, а на выходе порождает скалярное значение y ∈ ℝ. Результатом линейной регрессии является линейная функция входных данных. Обозначим y� – значение y, предсказан- ное моделью. Определим результат модели в виде y� = w⏉x, (5.3) где w ∈ ℝn – вектор параметров. Параметры – это величины, управляющие поведением системы. В данном случае wi – коэффициент, на который нужно умножить признак xi перед включением в сумму вкладов всех признаков. Иными словами, w – набор весов, описывающих влияние от- дельных признаков на результат предсказания. Если вес wi признака xi положителен, то увеличение признака приводит к увеличению результата y�, а если отрицателен, то к уменьшению. Если абсолютная величина веса признака велика, то его влияние на предсказание значительно. Если же вес признака равен 0, то признак вообще не влияет на предсказание.\n--- Страница 105 ---\n104  Основы машинного обучения Таким образом, определение нашей задачи T выглядит следующим образом: пред- сказать y по x, вычислив значение y� = w⏉x. Далее необходимо определение меры ка- чества P. Пусть имеется матрица плана с m примерами, которые мы будем использовать не для обучения, а только для оценки качества работы модели. Имеется также вектор ме- ток, содержащий правильные значения y для каждого из этих примеров. Поскольку этот набор данных будет использоваться только для контроля качества, назовем его тестовым набором. Обозначим матрицу плана X(test), а вектор меток регрессии – y(test). Один из способов измерения качества модели – вычислить среднеквадратиче- скую ошибку модели на тестовом наборе. Если вектор y�(test) содержит предсказания модели на тестовом наборе, то среднеквадратическая ошибка определяется по фор-муле: (5.4) Эта мера ошибки обращается в 0, когда y �(test) = y(test). Кроме того, (5.5) поэтому ошибка тем больше, чем больше евклидово расстояние между предсказани-ями и метками. Мы должны спроектировать алгоритм машинного обучения, который улучшает веса w таким образом, что MSE test уменьшается по мере того, как алгоритм получает новый опыт, наблюдая обучающий набор (X(train), y(train)). Интуитивно понятный спо- соб добиться этой цели (мы обоснуем его в разделе 5.5.1) – минимизировать средне- квадратическую ошибку на обучающем наборе, MSEtrain. Для минимизации MSEtrain нужно просто приравнять градиент 0 и решить полу- чившееся уравнение: ∇wMSEtrain = 0 (5.6) (5.7) (5.8) ⇒ ∇w (X(train)w – y(train))⏉(X(train)w – y(train)) = 0 (5.9) ⇒ ∇w(w⏉X(train)⏉X(train)w – 2w⏉X(train)⏉y(train) + y(train)⏉y(train)) = 0 (5.10) ⇒ 2X(train)⏉X(train)w – 2X(train)⏉y(train) = 0 (5.11) ⇒ w = (X(train)⏉X(train))–1X(train)⏉y(train) (5.12) Система уравнений, решение которой дает формула (5.12), называется нормаль- ными уравнениями. Вычисление выражения (5.12) и есть простой алгоритм обуче- ния. На рис. 5.1 показан алгоритм обучения линейной регрессии в действии. Отметим, что термином линейная регрессия часто обозначают несколько более сложную модель с одним дополнительным параметром – свободным членом b. В этой модели y� = w⏉x + b, (5.13)\n--- Страница 106 ---\nЕмкость, переобучение и недообучение  105 поэтому отображение параметров на предсказания по-прежнему описывается линей- ной функцией, но отображение признаков на предсказания теперь является аффин-ной функцией. Это обобщение означает, что график предсказанной модели – прямая, которая не обязана проходить через начало координат. Вместо добавления параметра b можно продолжать пользоваться моделью одних лишь весов, но дополнить вектор x элементом, который всегда равен 1. Вес, соответствующий этому элементу, играет роль свободного члена. В этой книге мы часто будем употреблять термин «линей- ный» в применении к аффинным функциям. Пример линейной регрессии Оптимизация w 3 210 –1 –2 –3 –1,0 –0,5 0,0 0,5 0,5 1,0 1,0 1,5 x 1 w1y0,55 0,50 0,450,40 0,35 0,30 0,25 0,20MSE(train) Рис. 5.1  Задача линейной регрессии, в которой обучающий набор со- стоит из десяти примеров, по одному признаку в каждом. Поскольку признак всего один, вектор весов w содержит единственный подлежащий обуче нию параметр w1. (Слева) Модель линейной регрессии обучила вес w1, так что прямая y = w1x проходит максимально близко ко всем обучающим приме- рам. (Справа) Точка на графике соответствует значению w1, найденному из нормальных уравнений, которое, как мы видим, минимизирует среднеквад- ратическую ошибку на обучающем наборе Свободный член b часто называют параметром смещения (bias) аффинного преоб- разования. Это связано с тем, что результат преобразования смещается в сторону b, если входных данных нет вообще. Это словоупотребление не имеет ничего общего со статистическим смещением, когда оценка некоторой величины, полученная алгорит-мом статистического оценивания, не совпадает с истинным значением. Конечно, линейная регрессия – очень простой и ограниченный алгоритм обучения, но он дает представление о том, как такие алгоритмы могут работать. В последующих разделах мы опишем базовые принципы, лежащие в основе проектирования алгорит- мов обучения, и продемонстрируем, как эти принципы применяются к построению более сложных алгоритмов. 5.2. Емкость, переобучение и недообучение Главная проблема машинного обучения состоит в том, что алгоритм должен хорошо работать на новых данных, которых он раньше не видел, а не только на тех, что ис- пользовались для обучения модели. Эта способность правильной работы на ранее не предъявлявшихся данных называется обобщением.\n--- Страница 107 ---\n106  Основы машинного обучения Обычно при обучении модели мы имеем доступ к обучающему набору: можем вы- числить некоторую меру ошибки на обучающем наборе, которая называется ошибкой обучения, и постараться минимизировать ее. То, что мы только что описали, – всего лишь задача оптимизации. Машинное обучение отличается от оптимизации тем, что мы хотим еще и уменьшить ошибку обобщения (ее также называют ошибкой тес- тирования). Ошибка обобщения – это математическое ожидание ошибки на новых входных данных. Здесь математическое ожидание вычисляется по возможным вход-ным данным, выбираемым из распределения, которое, как мы думаем, может встре-титься на практике. Как правило, для оценки ошибки обобщения модели измеряется ее качество на тестовом наборе данных, отдельном от обучающего набора. В примере линейной регрессии мы обучали модель путем минимизации следую- щей ошибки обучения: (5.14) но в действительности нас интересует ошибка тестирования Как можно повлиять на качество работы на тестовом наборе, если для наблюдения доступен только обучающий набор? Некоторые ответы дает теория статистического обучения. Если обучающий и тестовый наборы готовились произвольным образом, то действительно мало что можно сделать. Но если разрешено делать предположения о порядке сбора данных для обучающего и тестового наборов, то удается продвинуть- ся дальше. Обучающий и тестовый наборы генерируются из распределения вероятности тес- товых наборов процессом генерации данных. Обычно считаются справедливыми предположения, в совокупности называемые i.i.d. (independent and identically-dis- tributed), а именно: примеры в каждом наборе независимы и оба набора одинаково распределены, т. е. выбираются из одного и того же распределения вероятности. Это общее распределение называется порождающим распределением и обозначается p data. При таких предположениях мы можем математически проанализировать связь между ошибкой обучения и ошибкой тестирования. Сразу заметим, что ожидаемая ошибка обучения случайно выбранной модели рав- на ожидаемой ошибке тестирования той же модели. Пусть имеется распределение ве-роятности p(x, y), и мы повторно производим из него выборку для генерации обучаю- щего и тестового наборов. Для фиксированного значения w ожидаемая ошибка на обучающем наборе в точности равна ожидаемой ошибке на тестовом наборе, потому что оба математических ожидания являются результатом одного и того же процесса выборки. Разница лишь в названии набора данных. Конечно, при использовании алгоритма машинного обучения мы не фиксируем параметров заранее, с тем чтобы потом произвести выборку обоих наборов данных. Мы выбираем обучающий набор, используем его для минимизации ошибки обуче-ния, а затем выбираем тестовый набор. При таком процессе ожидаемая ошибка тести- рования больше или равна ожидаемой ошибке обучения. Факторов, определяющих качество работы алгоритма машинного обучения, два: 1) сделать ошибку обучения как можно меньше; 2) сократить разрыв между ошибками обучения и тестирования.\n--- Страница 108 ---\nЕмкость, переобучение и недообучение  107 Эти факторы соответствуют двум центральным проблемам машинного обучения: недообучению и переобучению. Недообучение имеет место, когда модель не позво- ляет получить достаточно малую ошибку на обучающем наборе, а переобучение – когда разрыв между ошибками обучения и тестирования слишком велик. Управлять склонностью модели к переобучению или недообучению позволяет ее емкость ( capacity). Неформально говоря, емкость модели описывает ее способность к аппроксимации широкого спектра функций. Модели малой емкости испытывают сложности в аппроксимации обучающего набора. Модели большой емкости склонны к переобучению, поскольку запоминают свойства обучающего набора, не присущие тестовому. Один из способов контроля над емкостью алгоритма обучения состоит в том, чтобы выбрать его пространство гипотез – множество функций, которые алгоритм может рассматривать в качестве потенциального решения. Например, пространством гипо- тез алгоритма линейной регрессии является множество всех линейных функций от входных данных. Мы можем обобщить линейную регрессию, включив в пространство гипотез многочлены более высокой степени. При этом увеличится емкость модели. Ограничившись только многочленами степени 1, мы получим модель линейной регрессии, с которой уже знакомы: y� = b + wx. (5.15) Добавив еще один признак, коэффициент при x2, мы сможем обучить модель в виде квадратичной функции от x: y� = b + w1x + w2x2. (5.16) Хотя эта модель ищет квадратичную функцию входных данных, результат по- прежнему линейно зависит от параметров, так что мы можем использовать нормаль- ные уравнения для обучения модели в замкнутой форме. Продолжая добавлять в ка- честве признаков коэффициенты при более высоких степенях, мы можем получить, например, многочлен степени 9: (5.15) В общем случае алгоритмы машинного обучения работают оптимально, когда ем- кость модели соответствует истинной сложности задачи и объему обучающих дан- ных. Модель недостаточной емкости не способна решать сложные задачи. Модель избыточной емкости может решать сложные задачи, но если емкость слишком высока для конкретной задачи, то возникает риск переобучения. На рис. 5.2 иллюстрируется этот принцип. Мы применяем три модели – линейную, квадратичную и полиномиальную степени 9 – к задаче аппроксимации, когда истин- ная функция – квадратичная. Линейная модель не способна уловить кривизну истин- ной кривой, поэтому является недообученной. Модель степени 9 может представить правильную функцию, но вместе с ней еще бесконечно много функций, проходящих через те же точки, поскольку параметров больше, чем обучающих примеров. Мало шансов, что из такого несметного множества совершенно непохожих кандидатов бу-дет выбрано хорошо обобщающееся решение. В данном случае квадратичная модель точно соответствует истинной структуре задачи, поэтому она хорошо обобщается на новые данные\n--- Страница 109 ---\n108  Основы машинного обучения Недообучение Адекватная емкость Переобучениеy y y x0 x0 x0 Рис. 5.2  На одном обучающем наборе обучены три модели. Обучаю- щие данные сгенерированы синтетически: значения x выбирались слу- чайно, а значения y вычислялись детерминированно путем применения квадратичной функции. (Слева) Линейная функция, аппроксимирующая данные, страдает от недообучения – она не улавливает присущую данным кривизну. (В центре) Квадратичная функция, аппроксимирующая данные, хорошо обобщается на новые точки. Ей не свойственны ни недообучение, ни переобучение. (Справа) Многочлен степени 9 аппроксимирует данные, но страдает от переобучения. Для решения недоопределенной системы нормальных уравнений мы воспользовались псевдообратной матрицей Мура–Пенроуза. Найденная кривая проходит через все обучающие точки, но мы не смогли выявить правильную структуру. Между двумя обучающими точками присутствует глубокая впадина, которой нет в истинной функции. Кроме того, функция резко возрастает слева от данных, тогда как истинная функция в этой области убывает Пока что мы описали только один способ изменения емкости модели: модифи- кация числа признаков с одновременным добавлением ассоциированных с этими признаками параметров. Но на самом деле есть много способов настройки емко- сти. Емкость определяется не только выбором модели. Модель задает семейство функций, из которого может выбирать алгоритм обучения в процессе варьирования параметров. Это называется репрезентативной емкостью модели. Во многих слу- чаях отыскание наилучшей функции в семействе является трудной задачей опти- мизации. На практике алгоритм обучения находит не лучшую функцию, а лишь та- кую, которая существенно уменьшает ошибку обучения. Наличие дополнительных ограничений, в частности несовершенство алгоритма оптимизации, означает, что эффективная емкость алгоритма обучения может быть меньше репрезентативной емкости модели. Современные идеи об обобщаемости моделей машинного обучения восходят еще к античным философам, в частности Птолемею. Многие ученые прежних времен исповедовали принцип экономии, который сейчас больше известен под названием «бритва Оккама» (приблизительно 1287–1347). Этот принцип утверждает, что из всех гипотез, одинаково хорошо объясняющих наблюдения, следует выбирать «прос-тейшую». Эта идея была формализована и уточнена в XX веке основателями теории статистического обучения (Vapnik and Chervonenkis, 1971; Vapnik, 1982; Blumer et al., 1989; Vapnik, 1995).\n--- Страница 110 ---\nЕмкость, переобучение и недообучение  109 Теория статистического обучения предлагает различные способы количественного выражения емкости модели. Самый известный из них – размерность Вапника–Чер- воненкиса, или VC-размерность, измеряющая емкость бинарного классификатора. VC-размерность определяется как наибольшее возможное значение m – такое, что существует обучающий набор m разных точек x, которые классификатор может по- метить произвольным образом. Количественное выражение емкости модели позволяет теории статистического об- учения делает количественные предсказания. Самые важные результаты этой теории показывают, что расхождение между ошибкой обучения и ошибкой обобщения огра- ничено сверху величиной, которая растет с ростом емкости модели, но убывает по мере увеличения количества обучающих примеров (Vapnik and Chervonenkis, 1971; Vapnik, 1982; Blumer et al., 1989; Vapnik, 1995). Наличие такого ограничения является теоретическим обоснованием работоспособности алгоритмов машинного обуче ния, но на практике используется редко в применении к алгоритмам глубокого обуче- ния. Отчасти это связано с нестрогостью оценки границ, а отчасти со сложностью определения емкости алгоритмов глубокого обучения. Последняя проблема особен-но трудна, потому что эффективная емкость ограничена возможностями алгоритма оптимизации, а у нас мало теоретических результатов об общих задачах невыпуклой оптимизации, встречающихся в глубоком обучении. Следует помнить, что хотя лучшая способность к обобщению (малым разрывом между ошибками обучения и тестирования) свойственна скорее простым функциям, нам все равно приходится выбирать достаточно сложные гипотезы для достижения малой ошибки обучения. В типичном случае ошибка обучения убывает, асимпто- тически приближаясь к минимально возможной ошибке с ростом емкости модели (в предположении, что у меры ошибки есть минимальное значение). А типичная ошибка обобщения имеет форму U-образной кривой, как показано на рис. 5.3. Емкость ОшибкаЗона недообученияЗона переобученияОшибка обучения Ошибка обобщения 0Разрыв Оптимальная емкость Рис. 5.3  Типичная связь между емкостью и ошибкой. Ошибки обучения и тестирования ведут себя по-разному. В левой части графика обе ошибки принимают большие значения. Это режим недообучения. По мере увеличе- ния емкости ошибка обучения снижается, а разрыв между ошибкой обуче- ния и обобщения растет. В конечном итоге величина разрыва перевешива- ет уменьшение ошибки обучения, и мы попадаем в режим переобучения, где емкость слишком сильно превышает оптимальную емкость\n--- Страница 111 ---\n110  Основы машинного обучения Чтобы подойти к крайнему случаю произвольно высокой емкости, введем понятие непараметрической модели. До сих пор мы рассматривали только параметрические модели типа линейной регрессии. Параметрическая модель обучает функцию, опи- санную вектором параметров, размер которого конечен и фиксируется до наблюде- ния данных. У непараметрических моделей такого ограничения нет. Иногда непараметрические модели представляют собой просто теоретические абст- ракции (например, алгоритм, который производит поиск среди всех возможных рас-пределений вероятности), не реализуемые на практике. Однако можно также спро-ектировать практически полезные непараметрические модели, сделав их сложность функцией от размера обучающего набора. Примером такого алгоритма может служить регрессия методом ближайшего соседа. В отличие от линейной регрессии, когда раз- мер вектора весов фиксирован, модель регрессии методом ближайшего соседа просто сохраняет X и y из обучающего набора. Когда модель просят классифицировать те- стовую точку x, она находит ближайшую к x точку обучающего набора и возвращает ассоциированную с ней метку. Иными словами, y� = y i, где i = arg min ||Xi, : – x||22. Этот алгоритм легко обобщается на метрики, отличные от нормы L2, например найденные в процессе обучения (Goldberger et al., 2005). Если позволено разрешать неоднознач- ности путем усреднения значений yi по всем Xi, : являющимся ближайшими соседями, то этот алгоритм может достичь минимально возможной ошибки обучения (которая может оказаться больше нуля, если с двумя одинаковыми примерами ассоциированы разные метки) на любом наборе данных для регрессии. Наконец, мы можем создать непараметрический алгоритм обучения, обернув па- раметрический алгоритм другим, который увеличивает число параметров по мере необходимости. Представьте, к примеру, внешний цикл обучения, который изменяет степень многочлена, обучаемого в результате регрессии. Идеальной моделью являлся бы оракул, который просто знает истинное распре- деление вероятности, на основе которого генерируются данные. Но даже такая мо-дель будет давать некоторую ошибку для многих задач из-за шума. В случае обучения с учителем отображение x в y может быть действительно стохастическим, но также возможно, что y – детерминированная функция, только у нее есть дополнительные аргументы, помимо включенных в x. Расхождение предсказаний оракула с истинным распределением p(x, y) называется байесовской ошибкой. Ошибки обучения и обобщения могут варьироваться в зависимости от размера обучающего набора. Ожидаемая ошибка обобщения никогда не может увеличиться с ростом количества обучающих примеров. Для непараметрических моделей увели- чение объема данных приводит к лучшему обобщению до тех пор, пока не будет до- стигнута наименьшая возможная ошибка. Любая фиксированная параметрическая модель емкостью ниже оптимальной асимптотически приближается к значению ошибки, большему байесовской. Это показано на рис. 5.4. Может случиться и так, что емкость модели оптимальна, и тем не менее существует большой разрыв между ошиб- ками обучения и обобщения. В такой ситуации разрыв, возможно, удастся сократить, увеличив число обучающих примеров. 5.2.1. Теорема об отсутствии бесплатных завтраков Теория обучения утверждает, что алгоритм может хорошо обобщаться после обуче-ния на конечном множестве примеров. На первый взгляд, это противоречит базовым принципам логики. Индуктивное рассуждение, когда общие правила выводятся из Среднеквадратическая ошибка3,5 3,0 2,5 2,01,5 1,0 0,50,0 20 15 10 50Байесовская ошибка Обучение (квадратичная) Тестирование (квадратичная) Тестирование (оптимальная емкость) Обучение (оптимальная емкость) Число обучающих примеров Число обучающих примеров100 100101 101102 102103 103104 104105 105Оптимальная емкость (степень многочлена) Рис. 5.4  Влияние размера обучающего набора данных на ошибки обучения и тести- рования, а также на оптимальную емкость модели. Мы синтезировали задачу регрес- сии, добавив умеренный шум к многочлену степени 5, сгенерировали один тестовый набор, а затем несколько обучающих наборов разного размера. Для каждого размера было сгенерировано 40 различных обучающих наборов, чтобы нанести на график от- резки, отражающие 95%-ные доверительные интервалы. (Вверху) Среднеквадратиче- ская ошибка на обучающем и тестовом наборах для двух разных моделей: квадратичной и полиномиальной, для которой выбрана степень, минимизирующая тестовую ошибку. Обе модели выражены в замкнутой форме. Для квадратичной модели ошибка обучения возрастает с ростом обучающего набора, поскольку чем больше набор, тем труднее его аппроксимировать. Одновременно ошибка тестирования убывает, поскольку меньше не- правильных гипотез совместимо с обучающими данными. Емкость квадратичной модели недостаточна для решения этой задачи, поэтому ошибка тестирования асимптотически приближается к высокому значению. Ошибка тестирования при оптимальной емкости асимптотически приближается к байесовской ошибке. Ошибка обучения может стать ниже байесовской, поскольку алгоритм обучения способен запоминать конкретные эк-земпляры обучающего набора. Когда размер обучающего набора стремится к бесконеч- ности, ошибка обучения любой модели фиксированной емкости (в данном случае квад-ратичной) должна возрастать как минимум до байесовской ошибки. (Внизу) С ростом размера обучающего набора оптимальная емкость (показанная здесь как степень опти-мального полиномиального регрессора) увеличивается. Оптимальная емкость выходит на плато после достижения сложности, достаточной для решения задачи\n--- Страница 112 ---\nЕмкость, переобучение и недообучение  111 Чтобы подойти к крайнему случаю произвольно высокой емкости, введем понятие непараметрической модели. До сих пор мы рассматривали только параметрические модели типа линейной регрессии. Параметрическая модель обучает функцию, опи- санную вектором параметров, размер которого конечен и фиксируется до наблюде- ния данных. У непараметрических моделей такого ограничения нет. Иногда непараметрические модели представляют собой просто теоретические абст- ракции (например, алгоритм, который производит поиск среди всех возможных рас-пределений вероятности), не реализуемые на практике. Однако можно также спро-ектировать практически полезные непараметрические модели, сделав их сложность функцией от размера обучающего набора. Примером такого алгоритма может служить регрессия методом ближайшего соседа. В отличие от линейной регрессии, когда раз- мер вектора весов фиксирован, модель регрессии методом ближайшего соседа просто сохраняет X и y из обучающего набора. Когда модель просят классифицировать те- стовую точку x, она находит ближайшую к x точку обучающего набора и возвращает ассоциированную с ней метку. Иными словами, y� = y i, где i = arg min ||Xi, : – x||22. Этот алгоритм легко обобщается на метрики, отличные от нормы L2, например найденные в процессе обучения (Goldberger et al., 2005). Если позволено разрешать неоднознач- ности путем усреднения значений yi по всем Xi, : являющимся ближайшими соседями, то этот алгоритм может достичь минимально возможной ошибки обучения (которая может оказаться больше нуля, если с двумя одинаковыми примерами ассоциированы разные метки) на любом наборе данных для регрессии. Наконец, мы можем создать непараметрический алгоритм обучения, обернув па- раметрический алгоритм другим, который увеличивает число параметров по мере необходимости. Представьте, к примеру, внешний цикл обучения, который изменяет степень многочлена, обучаемого в результате регрессии. Идеальной моделью являлся бы оракул, который просто знает истинное распре- деление вероятности, на основе которого генерируются данные. Но даже такая мо-дель будет давать некоторую ошибку для многих задач из-за шума. В случае обучения с учителем отображение x в y может быть действительно стохастическим, но также возможно, что y – детерминированная функция, только у нее есть дополнительные аргументы, помимо включенных в x. Расхождение предсказаний оракула с истинным распределением p(x, y) называется байесовской ошибкой. Ошибки обучения и обобщения могут варьироваться в зависимости от размера обучающего набора. Ожидаемая ошибка обобщения никогда не может увеличиться с ростом количества обучающих примеров. Для непараметрических моделей увели- чение объема данных приводит к лучшему обобщению до тех пор, пока не будет до- стигнута наименьшая возможная ошибка. Любая фиксированная параметрическая модель емкостью ниже оптимальной асимптотически приближается к значению ошибки, большему байесовской. Это показано на рис. 5.4. Может случиться и так, что емкость модели оптимальна, и тем не менее существует большой разрыв между ошиб- ками обучения и обобщения. В такой ситуации разрыв, возможно, удастся сократить, увеличив число обучающих примеров. 5.2.1. Теорема об отсутствии бесплатных завтраков Теория обучения утверждает, что алгоритм может хорошо обобщаться после обуче-ния на конечном множестве примеров. На первый взгляд, это противоречит базовым принципам логики. Индуктивное рассуждение, когда общие правила выводятся из Среднеквадратическая ошибка3,5 3,0 2,5 2,01,5 1,0 0,50,0 20 15 10 50Байесовская ошибка Обучение (квадратичная) Тестирование (квадратичная) Тестирование (оптимальная емкость) Обучение (оптимальная емкость) Число обучающих примеров Число обучающих примеров100 100101 101102 102103 103104 104105 105Оптимальная емкость (степень многочлена) Рис. 5.4  Влияние размера обучающего набора данных на ошибки обучения и тести- рования, а также на оптимальную емкость модели. Мы синтезировали задачу регрес- сии, добавив умеренный шум к многочлену степени 5, сгенерировали один тестовый набор, а затем несколько обучающих наборов разного размера. Для каждого размера было сгенерировано 40 различных обучающих наборов, чтобы нанести на график от- резки, отражающие 95%-ные доверительные интервалы. (Вверху) Среднеквадратиче- ская ошибка на обучающем и тестовом наборах для двух разных моделей: квадратичной и полиномиальной, для которой выбрана степень, минимизирующая тестовую ошибку. Обе модели выражены в замкнутой форме. Для квадратичной модели ошибка обучения возрастает с ростом обучающего набора, поскольку чем больше набор, тем труднее его аппроксимировать. Одновременно ошибка тестирования убывает, поскольку меньше не-правильных гипотез совместимо с обучающими данными. Емкость квадратичной модели недостаточна для решения этой задачи, поэтому ошибка тестирования асимптотически приближается к высокому значению. Ошибка тестирования при оптимальной емкости асимптотически приближается к байесовской ошибке. Ошибка обучения может стать ниже байесовской, поскольку алгоритм обучения способен запоминать конкретные эк-земпляры обучающего набора. Когда размер обучающего набора стремится к бесконеч- ности, ошибка обучения любой модели фиксированной емкости (в данном случае квад-ратичной) должна возрастать как минимум до байесовской ошибки. (Внизу) С ростом размера обучающего набора оптимальная емкость (показанная здесь как степень опти-мального полиномиального регрессора) увеличивается. Оптимальная емкость выходит на плато после достижения сложности, достаточной для решения задачи\n--- Страница 113 ---\n112  Основы машинного обучения ограниченного множества примеров, не является логически корректным. Чтобы вы- вести правило, описывающее каждый элемент множества, необходимо иметь инфор-мацию о каждом элементе. Машинное обучение позволяет частично обойти эту проблему, поскольку пред- лагает только вероятностные правила, а не однозначно определенные, как в чистой логике. Машинное обучение обещает найти правила, с некоторой вероятностью спра- ведливые для большинства элементов множества. К сожалению, даже это не решает проблему полностью. Теорема об отсутствии бесплатных завтраков в машинном обучении (Wolpert, 1996) утверждает, что в сред- нем по всем возможным порождающим определениям у любого алгоритма классифи- кации частота ошибок классификации ранее не наблюдавшихся примеров одинакова. Самый изощренный алгоритм, который мы только можем придумать, в среднем (по всем возможным задачам) дает такое же качество, как простейшее предсказание: все точки принадлежат одному классу. По счастью, эти результаты справедливы, только если производить усреднение по всем возможным порождающим распределениям. Если сделать предположения о ви- дах распределений вероятности, встречающихся в реальных приложениях, то можно спроектировать алгоритмы обучения, хорошо работающие для таких распределений. Это означает, что цель работ по машинному обучению – не в том, чтобы найти универсальный или самый лучший алгоритм обучения, а в том, чтобы понять, какие виды распределений характерны для «реального мира», в котором функционирует агент ИИ, и какие виды алгоритмов машинного обучения хорошо работают для инте- ресных нам порождающих распределений. 5.2.2. Регуляризация Из теоремы об отсутствии бесплатных завтраков следует, что алгоритмы машинно-го обучения нужно проектировать, так чтобы они хорошо работали для конкретной задачи. Для этого мы встраиваем в алгоритм набор предпочтений. Если эти пред- почтения согласованы с задачами, которые решает алгоритм, то он будет работать лучше. До сих пор мы обсуждали только один способ модификации алгоритма обучения: увеличение или уменьшение репрезентативной емкости модели путем добавления или удаления функций в пространстве гипотез, описывающем, какие решения мо- жет выбирать алгоритм. Мы привели пример: увеличение или уменьшение степени многочлена в задаче регрессии. Но это чрезмерно упрощенный взгляд на вещи. На поведение алгоритма сильно влияет не только разнообразие множества функций в пространстве гипотез, но и конкретный вид этих функций. Для алго- ритма линейной регрессии пространство гипотез состояло из множества линейных функций от входных данных. Они могут быть полезны для задач, в которых связь между входом и выходом действительно близка к линейной. Но если поведение нелинейно, то полезность оказывается куда меньше. Например, линейная регрес-сия покажет плачевные результаты при попытке предсказать поведение функции sin(x ). Таким образом, мы можем контролировать качество алгоритма, выбирая вид функций, которые могут выступать в роли решения, а также управляя количе- ством таких функций. Кроме того, мы можем настроить алгоритм обучения, так чтобы он отдавал пред- почтение определенным решениям из пространства гипотез. Это означает, что до-\n--- Страница 114 ---\nЕмкость, переобучение и недообучение  113 пустимы функции любого вида, но при прочих равных условиях выбираться будет функция предпочтительного вида. Другое решение будет выбрано, только если оно аппроксимирует обучающие данные значительно лучше предпочтительного. Например, в критерий обучения для линейной регрессии можно включить сниже- ние весов. Для выполнения линейной регрессии со снижением весов мы пытаемся минимизировать сумму, состоящую из среднеквадратической ошибки на обучающих данных и критерия J(w), который отдает предпочтение весам с меньшим квадратом нормы L 2. Точнее, J(w) = MSEtrain + λw⏉w, (5.18) где λ – заранее выбранное значение, задающее силу предпочтения малых весов. При λ = 0 никаких предпочтений нет, а чем больше λ, тем сильнее стремление к малым весам. В процессе минимизации J(w) выбираются веса, выражающие компромисс между аппроксимацией обучающих данных и малостью весов. Это дает решение, для которого либо угловой коэффициент меньше, либо веса назначаются меньшему числу признаков. В качестве примера того, как можно управлять тенденцией модели к переобучению или недообучению с помощью снижения весов, мы обучили поли- номиальную модель регрессии высокой степени с разными значениями λ. Результат показан на рис. 5.5. Переобучение (λ⟶0) Недообучение (λ слишком велико)Подходящее снижение весов (Среднее λ)y y y х0 х0 х0 Рис. 5.5  Аппроксимация обучающего набора, показанного на рис. 5.2, полиномиальной моделью регрессии высокой степени. Истинная функция квадратичная, но мы здесь используем только модели степени 9. Мы варьи- руем степень снижения весов, чтобы предотвратить переобучение моде- ли высокой степени. (Слева) Выбрав λ очень большим, можно заставить модель обучить функцию вообще без наклона. Такая модель недообучена, поскольку может представить только постоянную функцию. (В центре) При среднем значении λ алгоритм обучения реконструирует кривую примерно правильной формы. И хотя модель способна представить функции гораздо более сложной формы, из-за снижения веса она вынуждена использовать более простые функции с малыми весовыми коэффициентами. (Справа) Когда λ приближается к нулю (т. е. регуляризация минимальна, и мы исполь- зуем псевдообратную матрицу Мура–Пенроуза для решения недоопреде-ленной задачи), многочлен степени 9 оказывается сильно переобученным, что мы уже видели на рис. 5.2\n--- Страница 115 ---\n114  Основы машинного обучения Вообще, мы можем регуляризовать модель, которая обучает функцию f(x, θ), при- бавив к функции стоимости штраф, называемый регуляризатором. В случае сниже- ния весов регуляризатор имеет вид Ω(w) = w⏉w. В главе 7 мы встретим много других регуляризаторов. Выражение предпочтения одной функции перед другой – более общий способ управления емкостью модели, чем расширение или сужение пространства гипотез. Исключение функции из пространства гипотез можно трактовать как бесконечно большое «предпочтение» против этой функции. В примере снижения весов мы явно выразили предпочтение линейным функциям с меньшими весами, включив дополнительный член в минимизируемый критерий. Есть много других способов – явных и неявных – отдать предпочтение другим реше- ниям. Все такие подходы называются регуляризацией. Регуляризация – это любая модификация алгоритма обучения, предпринятая с целью уменьшить его ошибку обобщения, не уменьшая ошибку обучения. Регуляризация – одна из важнейших тем машинного обучения, с которой соперничать может только оптимизация. Из теоремы об отсутствии бесплатных завтраков вытекает, что не существует наи- лучшего алгоритма машинного обучения и, в частности, наилучшей формы регуляри- зации. Мы должны выбирать ту форму регуляризации, которая отвечает конкретной решаемой задаче. Философия глубокого обучения вообще и этой книги в частности состоит в том, что имеется широкий круг задач (например, все интеллектуальные за- дачи, выполняемые людьми), которые можно эффективно решить, применяя весьма универсальные формы регуляризации. 5.3. Гиперпараметры и контрольные наборы У большинства алгоритмов машинного обучения имеются гиперпараметры, управ-ляющие поведением алгоритма. Значения гиперпараметров не отыскиваются самим алгоритмом (хотя можно построить вложенную процедуру, в которой один алгоритм обучения будет находить гиперпараметры для другого). В примере полиномиальной регрессии на рис. 5.2 один гиперпараметр: степень многочлена, он играет роль гиперпараметра емкости. Другой пример гиперпарамет-ра – значение λ, контролирующее силу снижения весов. Иногда настройку делают гиперпараметром, а не обучают, потому что оптимиза- ция слишком сложна. Но чаще причина в том, что бессмысленно обучать гиперпара- метр на обучающем наборе. Это относится ко всем гиперпараметрам, управляющим емкостью модели. При попытке обучить их на обучающем наборе всегда выбиралась бы максимально возможная емкость модели, что приводило бы к переобучению (см. рис. 5.3). Например, мы всегда можем взять многочлен высокой степени и положить коэффициент снижения весов λ = 0 – аппроксимация обучающего набора при этом будет лучше, чем для многочлена более низкой степени и положительного λ. Для решения этой проблемы нам нужен контрольный набор примеров, которых алгоритм не видел в процессе обучения. Выше мы обсуждали, как можно использовать тестовый набор примеров, выбран- ных из того же распределения, что и обучающий, для оценки ошибки обобщения уже после завершения процесса обучения. Важно, что тестовые примеры вообще не используются для принятия каких-либо решений о модели, в т. ч. и касающихся ее гиперпараметров. Поэтому ни один пример из тестового набора не должен входить в контрольный. Следовательно, контрольный набор всегда формируется из обучаю-\n--- Страница 116 ---\nОценки, смещение и дисперсия  115 щих данных. Точнее, мы разбиваем обучающие данные на два непересекающихся под- множества. Одно из них используется для обучения параметров, а другое является контрольным набором и служит для оценки ошибки обобщения во время обучения или по его завершении; это позволяет подстраивать гиперпараметры. Подмножество данных, используемое для обучения параметров, по-прежнему называется обучаю-щим набором, несмотря на возможную путаницу с более широким набором данных, фигурирующим в процессе всего обучения. Подмножество данных, используемое для управления выбором гиперпараметров, называется контрольным набором. Обычно 80% всех обучающих данных резервируется для обучения, а 20% – для контроля. По- скольку контрольный набор используется для «обучения» гиперпараметров, ошибка на контрольном наборе является заниженной оценкой ошибки обобщения, но, как правило, на меньшую величину, чем ошибка обучения. По завершении оптимизации гиперпараметров ошибку обобщения можно оценить на тестовом наборе. На практике, когда один и тот же тестовый набор на протяжении многих лет ис- пользуется для оценки качества различных алгоритмов, а научное сообщество при- лагает максимум усилий, чтобы превысить предыдущие достижения именно на этом наборе, дело заканчивается тем, что результаты, измеренные на тестовом наборе, ока-зываются чрезмерно оптимистичными. То, что раньше считалось эталоном, устаре-вает и перестает отражать истинное качество обученной системы на реальных дан- ных. Тогда сообщество постепенно переходит на новый (обычно более амбициозный и объемный) эталонный набор данных. 5.3.1. Перекрестная проверка Разделение набора данных на фиксированные обучающий и тестовый становится проблематичным, если в тестовом наборе оказывается слишком мало данных. Малый тестовый набор – причина статистической недостоверности в оценке средней ошиб- ки тестирования, из-за которой трудно утверждать, что алгоритм A работает лучше алгоритма B на конкретной задаче. Если набор данных насчитывает сотни тысяч и более примеров, то особой пробле- мы не возникает. Но когда набор данных мал, можно прибегнуть к альтернативным про цедурам, которые позволяют использовать все примеры для оценивания средней ошибки тестирования ценой увеличения объема вычислений. Идея этих процедур – в том, чтобы повторять обучение и оценку на разных случайно выбранных подмно- жествах (разделениях) исходного набора данных. Наиболее распространена процедура k-групповой перекрестной проверки (алгоритм 5.1), в которой набор данных разбивает- ся на k непересекающихся подмножеств. Ошибку тестирования можно оценить, усред- нив ошибки тестирования по k испытаниям. В ходе i-го испытания i-е подмножество используется в качестве тестового набора, а остальные данные – в качестве обучающе- го. Проблема в том, что не существует несмещенных оценок дисперсии такой средней ошибки (Bengio and Grandvalet, 2004), но обычно используются аппроксимации. 5.4. Оценки, смещение и дисперсия Математическая статистика дает много инструментов для достижения основной цели машинного обучения: не только решить задачу на обучающем наборе, но и обес- печить возможность обобщения. Такие фундаментальные понятия, как оценивание параметров, смещение и дисперсия, полезны для формальной характеристики обоб- щения, недообучения и переобучения.\n--- Страница 117 ---\n116  Основы машинного обучения 5.4.1. Точечное оценивание Точечное оценивание – это попытка найти единственное «наилучшее» предсказание интересующей величины. В общем случае интересующей величиной может быть один или несколько параметров некоторой параметрической модели, например веса в примере линейной регрессии из раздела 5.1.4, а также целая функция. Чтобы отличить оценку параметра от истинного значения, мы будем обозначать оценку параметра θ символом θ ˆ. Пусть {x(1), …, x(m)} – множество m независимых и одинаково распределенных точек. Точечной оценкой, или статистикой, называется любая функция этих данных: θˆm = g(x(1), …, x(m)) . (5.19) В этом определении не требуется, чтобы g возвращала значение, близкое к истин- ному значению θ, ни даже чтобы область значений g совпадала со множеством до- пустимых значений θ. Определение точечной оценки весьма общее и предоставляет проектировщику большую свободу. Хотя в соответствии с ним оценкой можно на- звать почти любую функцию, хорошей оценкой будет та, значение которой близко к истинному распределению θ, из которого выбирались обучающие данные. Алгоритм 5.1. Алгоритм k-групповой перекрестной проверки. Применяется для оценивания ошибки обобщения алгоритма обучения A, когда имеющийся набор данных 𝔻 слишком мал для того, чтобы простое разделение на обучающий и тес- товый или обучающий и контрольный наборы могло дать точную оценку ошибки обобщения, поскольку среднее значение потери L на малом тестовом наборе может иметь высокую дисперсию. Элементами набора данных 𝔻 являются абстрактные примеры z(i) вида (вход, выход) z(i) = (x(i), y(i)) в случае обучения с учителем или просто вход z(i) = x(i) в случае обучения без учителя. Алгоритм возвращает векторы ошибок e для каждого примера из 𝔻, усреднение по которым считается оценкой ошибки обобщения. Ошибки на отдельных примерах можно использовать для вы-числения доверительного интервала вокруг среднего (уравнение 5.47). Хотя дове-рительные интервалы после перекрестной проверки не очень хорошо теоретически обоснованы, на практике их все же часто используют, объявляя, что алгоритм A лучше алгоритма B, только если доверительный интервал ошибки алгоритма A ле- жит ниже и не пересекается с доверительным интервалом алгоритма B. Define KFoldXV (𝔻, A, L, k): Require: 𝔻 – набор данных, состоящий из элементов z (i) Require: A – алгоритм обучения, т. е. функция, которая принимает набор данных и возвращает обученную функциюRequire: L – функция потерь, т. е. функция от обученной функции f и примера z (i) ∈ 𝔻, возвращающая скаляр ∈ ℝ Require: k – число групп Разбить 𝔻 на k непересекающихся подмножеств 𝔻i, объединение которых равно 𝔻 for i от 1 до k do fi = A(𝔻\\𝔻i) for z(j) из 𝔻i do ej = L(fi, z(j)) end for end forReturn e\n--- Страница 118 ---\nОценки, смещение и дисперсия  117 Пока что примем частотный подход к статистике, т. е. будем предполагать, что истинное значение параметра θ фиксировано, но неизвестно, а точечная оценка θˆ является функцией от этих данных. Поскольку данные порождаются случайным процессом, любая функция от них также случайная. Таким образом, θˆ – случайная величина. Точечную оценку можно также рассматривать как оценку связи между входной и выходной величинами. Такие типы точечных оценок мы будем называть оценками функций. Оценивание функций. Иногда нас интересует оценивание (или аппроксимация) функции. В этом случае мы пытаемся предсказать величину y, зная входной вектор x. Предполагается, что существует функция f(x), приближенно описывающая связь между y и x. Например, можно предположить, что y = f(x) + ε, где ε обозначает часть y, которую невозможно предсказать, зная x. Оценивание функции сводится к аппрок- симации f моделью или оценкой fˆ. Оценивание функции – по существу, то же самое, что оценивание параметра θ; fˆ – это просто точечная оценка в пространстве функций. Примеры линейной (раздел 5.1.4) и полиномиальной (раздел 5.2) регрессий можно интерпретировать либо как оценку параметра w, либо как оценку функции fˆ, отобра- жающей x в y. Теперь рассмотрим те свойства оценок, которые чаще всего изучаются, и обсудим, какую информацию об оценках они несут. 5.4.2. Смещение Смещение оценки определяется следующим образом: bias(θ ˆm) = 𝔼(θ ˆm) – θ, (5.20) где математическое ожидание вычисляется по данным (рассматриваемым как вы-борка из случайной величины), а θ – истинное значение параметра, которое опре- деляет порождающее распределение. Оценка θˆ m называется несмещенной, если bias(θ ˆm) = 0, т. е. 𝔼(θˆm) = θ. Оценка θˆm называется асимптотически несмещенной, если limm⟶∞ bias(θ ˆm) = 0, т. е. limm⟶∞ 𝔼(θˆm) = θ. Пример: распределение Бернулли. Рассмотрим множество независимых приме- ров {x(1), …, x(m)}, имеющих одно и то же распределение Бернулли со средним θ: P(x(i), θ) = θx(i)(1 – θ)(1–x(i)). (5.21) Стандартной оценкой параметра θ этого распределения является среднее значение обучающих примеров: (5.22) Чтобы узнать, является ли эта оценка смещенной, подставим (5.22) в (5.20): (5.23) (5.24) (5.25)\n--- Страница 119 ---\n118  Основы машинного обучения (5.26) (5.27) = θ – θ = 0 (5.28) Поскольку bias(θ ˆ) = 0, оценка θ ˆ является несмещенной. Пример: оценка среднего нормального распределения. Теперь рассмотрим мно- жество независимых примеров {x(1), …, x(m)}, имеющих одно и то же нормальное рас- пределение p(x(i)) = 𝒩(x(i), μ; σ2), где i ∈ {1, …, m}. Напомним, что функция плотности вероятности нормального распределения имеет вид: (5.29) Стандартная оценка среднего нормального распределения называется выбороч- ным средним: (5.30) Чтобы найти смещение выборочного среднего, нужно вычислить его математиче- ское ожидание: (5.31) (5.32) (5.33) (5.34) = μ – μ = 0 (5.35) Таким образом, выборочное среднее – несмещенная оценка среднего значения нор- мального распределения. Пример: оценки дисперсии нормального распределения. В этом примере мы сравним две оценки параметра σ2, определяющего дисперсию нормального распреде- ления. Нас будет интересовать, являются ли они смещенными. Первая оценка σ2 называется выборочной дисперсией: (5.36) где μ �m – выборочное среднее. Нас интересует величина bias[σ�m2] = 𝔼[σ�m2] – σ2. (5.37)\n--- Страница 120 ---\nОценки, смещение и дисперсия  119 Сначала вычислим член 𝔼[σ �m2]: (5.38) (5.39) Возвращаясь к формуле (5.37), заключаем, что смещение σ�m2 равно –σ2/m. Следова- тельно, эта оценка смещенная. Несмещенная оценка дисперсии выглядит так: (5.40) Покажем, что 𝔼[σ �2 m] = σ2. (5.41) (5.42) (5.43) = σ2 (5.44) Итак, у нас есть две оценки: смещенная и несмещенная. Хотя несмещенные оцен- ки, очевидно, желательны, не всегда они являются «наилучшими». Мы часто будем использовать смещенные оценки, которые обладают другими важными свойствами. 5.4.3. Дисперсия и стандартная ошибка Еще одно интересное свойство оценки – насколько сильно она изменяется как функ- ция примера. Для определения смещения мы вычисляли математическое ожидание оценки, но точно так же можем вычислить и ее дисперсию. Дисперсией оценки на- зывается выражение: Var(θˆ), (5.45) где случайной величиной является обучающий набор. Стандартной ошибкой SE(θˆ) называется квадратный корень из дисперсии. Дисперсия, как и стандартная ошибка, оценки измеряет, как будет изменяться оценка, вычисленная по данным, при независимой повторной выборке из набора дан-ных, генерируемого порождающим процессом. Желательные оценки – обладающие не только малым смещением, но и относительно малой дисперсией. При вычислении любой статистики по выборке конечного размера оценка истин- ного значения параметра всегда недостоверна в том смысле, что, взяв другую выборку из того же распределения, мы получили бы другую статистику. Ожидаемая степень вариативности оценки – источник ошибки, который мы хотим выразить количест- венно.\n--- Страница 121 ---\n120  Основы машинного обучения Стандартная ошибка среднего равна (5.46) где σ2 – истинная дисперсия выборки xi. Стандартную ошибку часто оценивают с по- мощью оценки σ. К сожалению, ни квадратный корень из выборочной дисперсии, ни квадратный корень из несмещенной оценки дисперсии не является несмещенной оценкой стандартного отклонения. В обоих случаях оценка истинного стандартно- го отклонения оказывается заниженной, тем не менее та и другая используются на практике. Квадратный корень из несмещенной оценки дисперсии – менее занижен- ная оценка. Для больших m аппроксимация вполне приемлема. Стандартная ошибка среднего очень полезна в экспериментах по машинному обуче нию. Мы часто оцениваем ошибку обобщения, вычисляя выборочное среднее ошибки на тестовом наборе. Количество примеров в тестовом наборе определяет точ- ность оценки. Воспользовавшись центральной предельной теоремой, согласно кото-рой среднее имеет приблизительно нормальное распределение, мы можем применить стандартную ошибку для вычисления вероятности того, что истинное математиче-ское ожидание находится в выбранном интервале. Например, 95-процентный дове- рительный интервал вокруг среднего μ � m определяется формулой (μ�m – 1.96SE(μ �m), μ�m + 1.96SE(μ �m)) (5.47) при нормальном распределении со средним μ�m и дисперсией SE(μ �m)2. В эксперимен- тах по машинному обучению принято говорить, что алгоритм A лучше алгоритма B, если верхняя граница 95-процентного доверительного интервала для ошибки алго-ритма A меньше нижней границы 95-процентного доверительного интервала для ошибки алгоритма B. Пример: распределение Бернулли. Снова рассмотрим множество независимых примеров {x (1), …, x(m)}, имеющих одно и то же распределение Бернулли (напом- ним, что P(x(i); θ) = θx(i)(1 – θ)(1–x(i))). На этот раз нас интересует дисперсия оценки θˆm = (1/m)Σm i=1x(i). (5.48) (5.49) (5.50) (5.51) (5.52) Дисперсия оценки является убывающей функцией от m, количества примеров в наборе данных. Это общее свойство популярных оценок, к которому мы еще вер- немся при обсуждении состоятельности в разделе 5.4.5.\n--- Страница 122 ---\nОценки, смещение и дисперсия  121 5.4.4. Поиск компромисса между смещением и дисперсией для минимизации среднеквадратической ошибки Смещение и дисперсия – два источника ошибки оценки. Смещение измеряет ожи- даемое отклонение от истинного значения функции или параметра, а дисперсия – это мера отклонения от ожидаемого значения оценки в произвольной выборке данных. Что, если имеются две оценки, у одной из которых больше смещение, а у другой дисперсия? Какую выбрать? Представим, к примеру, что мы хотим аппроксимиро- вать функцию на рис. 5.2, и на выбор предлагаются только две модели: с большой дисперсией и с большим смещением. Какую предпочесть? Самый распространенный подход к выбору компромиссного решения – воспользо- ваться перекрестной проверкой. Эмпирически продемонстрировано, что перек рест- ная проверка дает отличные результаты во многих реальных задачах. Можно также сравнить среднеквадратическую ошибку (MSE) обеих оценок: MSE = 𝔼[(θ ˆm – θ)2] (5.53) = Bias(θ ˆm)2 + Var(θ ˆm). (5.54) MSE измеряет ожидаемое расхождение (в смысле квадрата ошибки) между оцен- кой и истинным значением параметра θ. Из формулы (5.54) видно, что в вычислении MSE участвует как смещение, так и дисперсия. Желательной является оценка с ма- лой MSE, именно такие оценки держат под контролем и смещение, и дисперсию. Соотношение между смещением и дисперсией тесно связано с возникающими в ма- шинном обучении понятиями емкости модели, недообучения и переобучения. Если ошибка обобщения измеряется посредством MSE (и тогда смещение и дисперсия ста- новятся важными компонентами ошибки обобщения), то увеличение емкости влечет за собой повышение дисперсии и снижение смещения. Это показано на рис. 5.6, где мы снова видим U-образную кривую зависимости ошибки обобщения от емкости. Емкость Оптимальная емкостьОшибка обобщения Смещение ДисперсияЗона недообучения Зона переобучения Рис. 5.6  С ростом емкости (ось x) смещение (пунктирная линия) умень- шается, а дисперсия (штриховая линия) увеличивается, в результате чего получается еще одна U-образная кривая для ошибки обобщения (жирная линия). В какой-то точке на оси x емкость оптимальна, слева от этой точки имеет место недообучение, справа – переобучение. Это соотношение ана- логично соотношению между емкостью, недообучением и переобучением, которое рассматривалось в разделе 5.2 и на рис. 5.3\n--- Страница 123 ---\n122  Основы машинного обучения 5.4.5. Состоятельность До сих пор мы обсуждали свойства различных оценок для обучающего набора фик- сированного размера. Обычно нас интересует также поведение оценки по мере роста этого размера. В частности, мы хотим, чтобы при увеличении числа примеров точеч- ные оценки сходились к истинным значениям соответствующих параметров. Фор- мально это записывается в виде: plim m⟶∞θˆm = θ. (5.55) Символом plim обозначается сходимость в смысле вероятности, т. е. для любого ε > 0 P(|θˆm – θ| > ε) ⟶ 0 при m ⟶ ∞. Условие (5.55) называется состоятельностью. Иногда его называют слабой состоятельностью, понимая под сильной состоятель-ностью сходимость почти наверное θˆ к θ. Говорят, что последовательность случай- ных величин x (1), x(2), … сходится к x почти наверное, если p(limm⟶∞ x(m) = x) = 1. Состоятельность гарантирует, что смещение оценки уменьшается с ростом числа примеров. Однако обратное неверно – из асимптотической несмещенности не вы- текает состоятельность. Рассмотрим, к примеру, оценивание среднего μ нормального распределения 𝒩(x; μ, σ2) по набору данных, содержащему m примеров: {x(1), …, x(m)}. Можно было бы взять в качестве оценки первый пример: θˆ = x(1). В таком случае 𝔼(θˆm) = θ, поэтому оценка является несмещенной вне зависимости от того, сколько примеров мы видели. Отсюда, конечно, следует, что оценка асимптотически несме-щенная. Но она не является состоятельной, т. к. неверно, что θ ˆ m ⟶ θ при m ⟶ ∞. 5.5. Оценка максимального правдоподобия Мы познакомились с определениями нескольких оценок и проанализировали их свойства. Но откуда взялись эти оценки? Хотелось бы не угадывать функцию, кото-рая могла бы оказаться хорошей оценкой, и затем анализировать смещение и диспер- сию, а располагать каким-то общим принципом, позволяющим выводить функции, являющиеся хорошими оценками для разных моделей. Чаще всего для этой цели применяется принцип максимального правдоподобия . Рассмотрим множество m примеров 𝕏 = {x (1), …, x(m)}, независимо выбираемых из неизвестного порождающего распределения pdata(x). Обозначим pmodel(x; θ) параметрическое семейство распределений вероятности над одним и тем же пространством, индексированное параметром θ. Иными словами, pmodel(x; θ) отображает произвольную конфигурацию x на вещественное число, даю- щее оценку истинной вероятности pdata(x). Тогда оценка максимального правдоподобия для θ определяется формулой: (5.56) (5.57) Такое произведение большого числа вероятностей по ряду причин может быть не- удобно. Например, оно подвержено потере значимости. Для получения эквивалент- ной, но более удобной задачи оптимизации заметим, что взятие логарифма правдопо-добия не изменяет arg max, но преобразует произведение в сумму: (5.58)\n--- Страница 124 ---\nОценка максимального правдоподобия  123 Поскольку arg max не изменяется при умножении функции стоимости на констан- ту, мы можем разделить правую часть на m и получить выражение в виде математи- ческого ожидания относительно эмпирического распределения p�data, определяемого обучающими данными: data (5.59) Один из способов интерпретации оценки максимального правдоподобия состоит в том, чтобы рассматривать ее как минимизацию расхождения Кульбака–Лейблера между эмпирическим распределением p�data, определяемым обучающим набором, и мо- дельным распределением. Расхождение Кульбака–Лейблера определяется формулой DKL(p�data||pmodel) = 𝔼x~p�data [log p�data(x) – log pmodel(x)]. (5.60) Первый член разности в квадратных скобках зависит только от порождающего данные процесса, но не от модели. Следовательно, при обучении модели, минимизи- рующей расхождение КЛ, мы должны минимизировать только величину – 𝔼x∼p�data [log pmodel(x)], (5.61) а это, конечно, то же самое, что максимизация величины (5.59). Минимизация расхождения КЛ в точности соответствует минимизации пере- крестной энтропии между распределениями. Многие авторы употребляют термин «перекрестная энтропия» для обозначения исключительно отрицательного логариф-мического правдоподобия распределения Бернулли или softmax, но это неправильно. Любая функция потерь, содержащая отрицательное логарифмическое правдоподо-бие, является перекрестной энтропией между эмпирическим распределением, опре-деляемым обучающим набором, и распределением, определяемым моделью. Напри- мер, среднеквадратическая ошибка – перекрестная энтропия между эмпирическим распределением и гауссовой моделью. Таким образом, мы видим, что максимальное правдоподобие – это попытка совмес- тить модельное распределение с эмпирическим распределением p� data. В идеале мы хо- тели бы совпадения с истинным порождающим распределением pdata, но непосред- ственного доступа к нему у нас нет. Хотя оптимальное значение θ не зависит от того, максимизируем мы правдоподобие или минимизируем расхождение КЛ, значения целевых функций различны. При раз-работке программ мы часто называем то и другое минимизацией функции стоимости. В таком случае поиск максимального правдоподобия становится задачей минимиза- ции отрицательного логарифмического правдоподобия (ОЛП), или, что эквивалент-но, минимизации перекрестной энтропии. Взгляд на максимальное правдоподобие как на минимальное расхождение КЛ в этом случае становится полезен, потому что известно, что минимум расхождения КЛ равен нулю. А отрицательное логарифмиче- ское правдоподобие может принимать отрицательные значения при вещественных x . 5.5.1. Условное логарифмическое правдоподобие и среднеквадратическая ошибка Оценку максимального правдоподобия легко обобщить для оценивания условной вероятности P(y | x; θ), чтобы предсказывать y при известном x. На самом деле это вполне типичная ситуация, лежащая в основе большинства алгоритмов обучения\n--- Страница 125 ---\n124  Основы машинного обучения с учителем. Если X представляет все входы, а Y – все наблюдаемые выходы, то оценка условного максимального правдоподобия равна (5.62) Если предположить, что все примеры независимы и одинаково распределены, то это выражение можно представить в виде суммы: (5.62) Пример: линейная регрессия и максимальное правдоподобие. Линейную регрес- сию (раздел 5.1.4) можно интерпретировать как нахождение оценки максимального правдоподобия. Ранее мы описывали линейную регрессию как алгоритм, который обучается порождать значение y� по входным данным x. Отображение x в y� выбира- ется, так чтобы минимизировать среднеквадратическую ошибку – критерий, взятый более-менее произвольно. Теперь мы рассмотрим линейную регрессию с точки зре- ния оценки максимального правдоподобия. Будем считать, что цель не в том, что- бы вернуть одно предсказание y�, а чтобы построить модель, порождающую условное распределение p(y | x). Можно представить себе, что в бесконечно большом обучаю- щем наборе мы могли бы встретить несколько обучающих примеров с одним и тем же значением x, но с разными значениями y. Цель алгоритма обучения теперь – ап- проксимировать p(y | x), подогнав его под все эти разные значения y, совместимые с x. Для вывода такого же алгоритма линейной регрессии, как и раньше, определим p(y | x) = 𝒩(y; y�(x; w), σ 2). Функция y�(x; w) дает предсказание среднего значения нормального распределения. В этом примере мы предполагаем, что дисперсия фик- сирована и равна константе σ2, задаваемой пользователем. Мы увидим, что при таком выборе функциональной формы p(y | x) нахождение оценки максимального правдо- подобия сводится к тому же алгоритму обучения, что был разработан ранее. Посколь- ку предполагается, что примеры независимы и одинаково распределены, то условное логарифмическое правдоподобие (формула 5.63) записывается в виде: (5.64) (5.65) где y�(i) – результат линейной регрессии для i-го примера x(i), а m – число обучающих примеров. Сравнивая логарифмическое правдоподобие со среднеквадратической ошибкой (5.66) мы сразу же видим, что максимизация логарифмического правдоподобия относи-тельно w дает ту же оценку параметров w, что минимизация среднеквадратической ошибки. Значения этих критериев различны, но положение оптимума совпадает. Это служит обоснованием использования среднеквадратической ошибки в качестве оценки максимального правдоподобия. Как мы увидим, оценка максимального прав-доподобия обладает рядом желательных свойств.\n--- Страница 126 ---\nБайесовская статистика  125 5.5.2. Свойства максимального правдоподобия Главное достоинство оценки максимального правдоподобия заключается в том, что с точки зрения скорости сходимости она является асимптотически наилучшей оцен- кой, когда количество примеров m ⟶ ∞. При определенных условиях оценка максимального правдоподобия обладает свой- ством состоятельности (см. раздел 5.4.5), т. е. когда число обучающих примеров стре- мится к бесконечности, оценка максимального правдоподобия параметра сходится к истинному значению этого параметра. Вот эти условия: истинное распределение pdata принадлежит семейству модельных распределе- ний pmodel(·; θ). В противном случае никакая оценка не сможет реконструиро- вать pdata; истинное распределение pdata соответствует ровно одному значению θ. В про- тивном случае оценка максимального правдоподобия сможет реконструиро- вать pdata, но не сможет определить, какое значение θ было использовано в по- рождающем процессе. Существуют и другие индуктивные принципы, помимо оценки максимального правдоподобия, и многие из них обладают свойством состоятельности. Однако сос- тоятельные оценки могут различаться по статистической эффективности, т. е. некая оценка может давать меньшую ошибку обобщения при фиксированном числе при-меров m или, эквивалентно, требовать меньше примеров для получения заданного уровня ошибки обобщения. Статистическая эффективность обычно изучается в параметрическом случае (например, в линейной регрессии), когда наша цель – оценить значение параметра (в предположении, что выявить истинный параметр возможно), а не значение функ- ции. Для измерения степени близости к истинному значению параметра использует- ся ожидаемая среднеквадратическая ошибка, описывающая квадрат разности между оценкой и истинным значением параметра, причем математическое ожидание вы- числяется по m обучающим примерам, взятым из порождающего распределения. Эта параметрическая среднеквадратическая ошибка убывает с ростом m, и для больших m справедливо неравенство Крамера–Рао (Rao, 1945; Cramе́r, 1946), показывающее, что ни для какой состоятельной оценки среднеквадратическая ошибка не может быть меньше, чем для оценки максимального правдоподобия. По этим причинам (состоятельность и эффективность) оценка максимального правдоподобия часто считается предпочтительной в машинном обучении. Если ко- личество примеров настолько мало, что есть угроза переобучения, то можно приме-нить стратегии регуляризации, например снижение весов, которые дают смещенный вариант оценки максимального правдоподобия с меньшей дисперсией. 5.6. Байесовская статистика До сих пор мы обсуждали частотные статистики и подходы, основанные на оценива- нии единственного значения θ, которое затем использовалось для всех предсказаний. Другой подход состоит в том, чтобы делать предсказание, рассматривая все возмож- ные значения θ. Это область байесовской статистики. Как было сказано в разделе 5.4.1, частотный подход предполагает, что истинное зна- чение θ фиксировано, хотя и неизвестно, а точечная оценка θˆ – случайная величина ввиду того, что она является функцией набора данных (который считается случайным).\n--- Страница 127 ---\n126  Основы машинного обучения Байесовский подход к статистике совершенно иной. Вероятность в этом случае отражает степень уверенности в наших знаниях. Набор данных доступен прямому наблюдению и, следовательно, не является случайным. С другой стороны, истинный параметр θ неизвестен или недостоверен и потому представляется случайной пере- менной. Еще до наблюдения данных мы представляем свои знания про θ в виде априорного распределения вероятности p(θ). В машинном обучении априорное распределение обычно берется достаточно широким (имеющим большую энтропию), что отражает высокую степень неопределенности значения θ до наблюдения. Например, априори можно предположить, что θ равномерно распределен в некоторой конечной области. Во многих априорных распределениях предпочтение, наоборот, отдается «более про-стым» решениям (например, коэффициентам с меньшими абсолютными величинами или функции, близкой к постоянной). Рассмотрим теперь набор примеров {x (1), …, x(m)}. Можно реконструировать влияние данных на наши гипотезы про θ, объединив правдоподобие данных p(x(1), …, x(m) | θ) с априорным распределением посредством правила Байеса: (5.67) В тех ситуациях, где обычно применяется байесовское оценивание, в качестве априорного представления берется относительно равномерное или нормальное распределение с большой энтропией, а наблюдение данных, как правило, приводит к апостериорному распределению с меньшей энтропией, сосредоточенному в окрест- ности вероятных значений параметров. По сравнению с оценкой максимального правдоподобия, у байесовской оценки есть два важных отличия. Во-первых, в подходе на основе максимального правдоподобия предсказания делаются с использованием точечной оценки θ, а в байесовском – с ис- пользованием полного распределения θ. Например, после наблюдения m примеров предсказанное распределение следующего примера x (m+1) описывается формулой (5.68) Здесь каждое значение θ с положительной плотностью вероятности вносит вклад в предсказание следующего примера с весом, равным самой апостериорной плотно- сти. Если после наблюдения примеров {x(1), …, x(m)} мы все еще не уверены в значении θ, то эта неопределенность включается прямо в предсказания. В разделе 5.4 мы обсуждали, как в частотном подходе решается вопрос о неопре- деленности данной точечной оценки θ путем вычисления ее дисперсии. Дисперсия оценки – это суждение о том, как могла бы измениться оценка в случае другой вы- борки наблюдаемых данных. Байесовский подход дает другой ответ на вопрос о не- определенности оценки – просто проинтегрировать по ней, и это хорошо защищает от переобучения. Этот интеграл – не что иное, как применение законов вероятности, поэтому байесовский подход легко обосновать, тогда как частотный механизм по-строения оценки основан на довольно-таки произвольном решении свести все зна-ния, содержащиеся в наборе данных, к одной точечной оценке. Второе важное различие между байесовским подходом к оцениванию и подходом на основе максимального правдоподобия обусловлено вкладом байесовского апри-\n--- Страница 128 ---\nБайесовская статистика  127 орного распределения. Влияние этого распределения состоит в сдвиге плотности ве- роятности в сторону тех областей пространства параметров, которые априори пред- почтительны. На практике априорное распределение часто выражает предпочтение более простым или более гладким моделям. Критики байесовского подхода называют априорное распределение источника субъективных суждений влияющим на предска-зания. Обычно байесовские методы обобщаются гораздо лучше при ограниченном объеме обучающих данных, но становятся вычислительно более накладными, когда количе-ство обучающих примеров велико. Пример: байесовская линейная регрессия. Рассмотрим байесовский подход к обуче нию параметров линейной регрессии. Мы хотим обучить линейное отображе- ние входного вектора x ∈ ℝ n для предсказания скалярного значения y ∈ ℝ. Предсказа- ние параметризуется вектором w ∈ ℝn: y� = w⏉x. (5.69) Если дано множество m обучающих примеров (X(train), y(train)), то предсказание y по всему обучающему набору можно выразить в виде y�(train) = X(train)w. (5.70) Предполагая нормальное условное распределение y(train), имеем p(y(train) | X(train), w) = 𝒩(y(train); X(train)w, I), (5.71) ∝ exp(–1/2(y(train) – X(train)w)⏉(y(train) – X(train)w)), (5.72) где используется стандартное для записи среднеквадратической ошибки предполо-жение о том, что дисперсия y равна 1. В дальнейшем мы во избежание громоздкости будем вместо (X (train), y(train)) писать просто (X, y). Для определения апостериорного распределения вектора параметров модели w нужно сначала задать априорное распределение. Оно должно отражать наши наивные представления о ценности параметров. Иногда выразить априорные представления в терминах параметров модели трудно или неестественно, но на практике мы обычно предполагаем довольно широкое распределение, выражающее высокую степень не-определенности θ. Для вещественных параметров часто в качестве априорного берут нормальное распределение. p(w) = 𝒩(w; μ 0, Λ0) ∝ exp(–1/2(w – μ0)⏉ Λ0–1(w – μ0)), (5.73) где μ0 и Λ0 – средний вектор априорного распределения и ковариационная матрица соответственно1. При таком задании априорного распределения мы теперь можем перейти к опреде- лению апостериорного распределения параметров модели: p(w | X, y) ∝ p(y | X, w)p(w), (5.74) ∝ exp(–1/2(y – Xw )⏉(y – Xw )) exp(–1/2(w – μ0)⏉ Λ0–1(w – μ0)) (5.75) ∝ exp(–1/2(–2y⏉Xw + w⏉X⏉Xw + w⏉Λ0–1w – 2μ0⏉Λ0–1w)). (5.76) 1 Если нет причин использовать конкретную структуру ковариационной матрицы, то обычно берется диагональная Λ0 = diag(λ0).\n--- Страница 129 ---\n128  Основы машинного обучения Определим Λm = (X⏉X + Λ0–1)–1 и μm = Λm(X⏉y + Λ0–1μ0). При так определенных новых переменных апостериорное распределение можно записать в виде нормаль- ного: p(w | X, y) ∝ exp(–1/2(w – μm)⏉ Λm–1(w – μm) + 1/2μm⏉Λm–1μm), (5.77) ∝ exp(–1/2(w – μm)⏉ Λm–1(w – μm)). (5.78) Все члены, не включающие вектор параметров w, опущены; они подразумеваются в силу того факта, что распределение должно быть нормировано, так чтобы интеграл оказался равен 1. Как нормируется многомерное нормальное распределение, показа- но в формуле (3.23). Изучение этого апостериорного распределения позволяет составить интуитивное представление о поведении байесовского вывода. В большинстве случаев мы задаем μ0 равным 0. Если положить Λ0 = (1/α)I, то μm дает ту же оценку w, что и частотная линейная регрессия со снижением веса αw⏉w. Одно отличие заключается в том, что байесовская оценка не определена, если α равно 0 – запрещается начинать процесс байесовского обучения с бесконечно широким априорным распределением w. Но есть и более важное отличие – байесовская оценка дает ковариационную матрицу, показывающую, насколько вероятны все значения w, а не только оценку μm. 5.6.1. Оценка апостериорного максимума (MAP) Хотя принципиальный подход состоит в том, чтобы делать предсказания, используя полное байесовское апостериорное распределение параметра θ, часто все же жела- тельно иметь одну точечную оценку. Одна их причин – тот факт, что операции, вклю- чающие байесовское апостериорное распределение для большинства интересных моделей, как правило, вычислительно неразрешимы, а точечная оценка предлагает разрешимую аппроксимацию. Вместо того чтобы просто возвращать оценку макси-мального правдоподобия, мы можем все-таки воспользоваться некоторыми преиму-ществами байесовского подхода, разрешив априорному распределению влиять на выбор точечной оценки. Один из рациональных способов сделать это – взять оценку апостериорного максимума (MAP). Это точка, в которой достигается максимальная апостериорная вероятность (или максимальная плотность вероятности в более рас- пространенном случае непрерывной величины θ). θ MAP = p(θ | x) = log p(x | θ) + log p(θ). (5.79) В правой части мы видим знакомый член log p(x | θ) – стандартное логарифмиче- ское правдоподобие, а также слагаемое log p(θ), соответствующее априорному рас- пределению. В качестве примера рассмотрим модель линейной регрессии с нормальным апри- орным распределением весов w. Если это распределение 𝒩(w; 0, (1/λ)I2), то член log p(θ) в формуле (5.79) пропорционален знакомому штрафу в виде снижения ве- сов λw⏉w плюс член, не зависящий от w и не влияющий на процесс обучения. Таким образом, байесовский вывод MAP с нормальным априорным распределением весов соответствует снижению весов. Байесовский вывод MAP , как и полный байесовский вывод, обладает тем преиму- ществом, что задействует информацию, содержащуюся в априорном распределении, но отсутствующую в обучающих данных. Эта дополнительная информация помогает\n--- Страница 130 ---\nАлгоритмы обучения с учителем  129 уменьшить дисперсию точечной оценки MAP (по сравнению с оценкой максималь- ного правдоподобия). Однако за это приходится расплачиваться увеличенным сме- щением. Многие регуляризированные стратегии оценивания, в частности оценку макси- мального правдоподобия со снижением весом, можно интерпретировать как MAP-аппроксимацию байесовского вывода. Эта точка зрения применима, когда процедура регуляризации сводится к прибавлению дополнительного члена к целевой функции, который соответствует log p(θ). Не все регуляризующие штрафы совместимы с байе- совским выводом. Например, возможны члены-регуляризаторы, не являющиеся ло-гарифмом распределения вероятности. Бывает и так, что член-регуляризатор зависит от данных, что, конечно, недопустимо для априорного распределения. Байесовский вывод MAP предлагает простой способ проектирования сложных, но все же допускающих интерпретацию регуляризующих членов. Например, более хитроумный штрафной член можно получить, взяв в качестве априорного смесь нор- мальных распределений, а не единственное такое распределение (Nowlan and Hinton, 1992). 5.7. Алгоритмы обучения с учителем В разделе 5.1.3 было сказано, что алгоритм обучения с учителем – это такой алго- ритм, в котором обучающий набор примеров содержит не только входные данные x, но и ассоциированные с ними выходные данные y. Во многих случаях выходные данные трудно собрать автоматически, поэтому их должен предоставить человек – «учитель», однако сам термин применяется и тогда, когда метки входных данных со- бирались автоматически. 5.7.1. Вероятностное обучение с учителем Большинство алгоритмов обучения с учителем, рассматриваемых в этой книге, осно- вано на оценивании распределения вероятности p(y | x). Это можно сделать, просто воспользовавшись оценкой максимального правдоподобия, чтобы найти наилучший вектор параметров θ для параметрического семейства распределений p(y | x; θ). Мы уже видели, что линейная регрессия соответствует семейству p(y | x; θ) = 𝒩(y; θ ⏉x, I). (5.80) Мы можем обобщить линейную регрессию на случай классификации, определив другое семейство распределений вероятности. Если имеются два класса: 0 и 1, то нуж- но лишь задать вероятность каждого класса. При этом вероятность класса 1 одно- значно определяет вероятность класса 0, поскольку сумма обоих значений должна быть равна 1. Нормальное распределение вещественных чисел, с которым мы имели дело в за- даче линейной регрессии, параметризуется величиной среднего. Допустимо любое значение среднего. Распределение бинарной величины несколько сложнее, потому что ее среднее должно заключаться между 0 и 1. Решить эту проблему можно: напри- мер, воспользоваться логистической сигмоидой, которая «втискивает» значение ли-нейной функции в интервал (0, 1), и интерпретировать это значение как вероятность: p(y = 1 | x; θ) = σ( θ⏉x). (5.81)\n--- Страница 131 ---\n130  Основы машинного обучения Этот подход называется логистической регрессией (довольно странное название, поскольку модель используется не для регрессии, а для классификации). В задаче линейной регрессии мы смогли найти оптимальные веса, решив нормаль- ные уравнения. С логистической регрессией дело обстоит сложнее. В этом случае не существует замкнутой формулы для нахождения оптимальных весов. Их нужно ис- кать путем максимизации функции логарифмического правдоподобия. Сделать это можно, найдя минимум отрицательного логарифмического правдоподобия методом градиентного спуска. Ту же стратегию можно применить практически к любой задаче обучения с учите- лем, выписав параметрическое семейство условных распределений вероятности под-ходящих входных и выходных величин. 5.7.2. Метод опорных векторов Из методов, оказавших наибольшее влияние на обучение с учителем, следует упомя- нуть прежде всего метод опорных векторов (support vector machine – SVM) (Boser et al., 1992; Cortes and Vapnik, 1995). Эта модель похожа на логистическую регрессию тем, что описывается линейной функцией w ⏉x + b. Но, в отличие от логистической регрессии, метод опорных векторов вычисляет не вероятности, а только класс. SVM предсказывает положительный класс, если значение w⏉x + b положительно, и отри- цательный – если оно отрицательно. Одно из основных новшеств, принесенных методом опорных векторов, – это kernel trick (трюк с ядром). Идея этого приема заключается в том, что многие алгоритмы ма- шинного обучения можно выразить исключительно в терминах скалярного произве- дения примеров. Например, можно показать, что линейную функцию, используемую в методе опорных векторов, можно переписать в виде: w ⏉x + b = b + αi x⏉x(i), ( 5.82) где x(i) – обучающий пример, а α – вектор коэффициентов. Записав алгоритм обучения в таком виде, мы сможем заменить x результатом заданной функции признаков ϕ(x), а скалярное произведение – функцией k(x, x(i)) = ϕ(x) · ϕ(x(i)), которая называется ядром. Оператор · представляет скалярное произведение, аналогичное ϕ(x)⏉ϕ(x(i)). Для некоторых пространств признаков использовать скалярное произведение векто- ров в чистом виде невозможно. В некоторых бесконечномерных пространствах нуж- ны другие виды скалярного произведения, например основанные на интегрировании, а не на суммировании. Разработка полной теории таких вариантов скалярного про- изведения выходит за рамки книги. Заменив скалярные произведения вычислением ядра, мы можем делать предсказания, пользуясь функцией f(x) = b + αi k(x, x(i)). (5.83) Эта функция нелинейно зависит от x, но соотношение между ϕ(x) и f(x) линейное. Также линейным является соотношение между α и f(x). Основанная на ядре функция в точности эквивалентна предварительной обработке путем применения ϕ(x) ко всем входным данным с последующим обучением линейной модели в новом преобразо- ванном пространстве. Трюк с ядром полезен по двум причинам. Во-первых, он позволяет обучать моде- ли, нелинейно зависящие от x, применяя методы выпуклой оптимизации, о которых\n--- Страница 132 ---\nАлгоритмы обучения с учителем  131 точно известно, что они сходятся эффективно. Это возможно, потому что мы считаем ϕ фиксированным и оптимизируем только α, т. е. алгоритм оптимизации может счи- тать, что решающая функция линейна, но в другом пространстве. Во-вторых, ядерная функция k часто допускает реализацию, значительно более эффективную с вычисли- тельной точки зрения, чем наивное построение двух векторов ϕ(x) и явное вычисле- ние их скалярного произведения. В некоторых случаях вектор ϕ(x) может быть даже бесконечномерным, что при наивном подходе вылилось бы в бесконечно длинное вычисление. Часто k(x, x′) – не- линейная, но разрешимая функция x, даже если ϕ(x) неразрешима. В качестве при- мера бесконечномерного пространства признаков с разрешимым ядром построим отобра жение ϕ(x), когда признаки x – неотрицательные целые числа. Это отобра- жение возвращает вектор, содержащий x единиц, за которыми следует бесконечное число нулей. Тогда ядерная функция k(x, x(i)) = min(x, x(i)) в точности эквивалентна скалярному произведению таких бесконечномерных векторов. Самым распространенным является гауссово ядро k(u, v) = 𝒩(u – v; 0, σ2I), (5.84) где 𝒩(x; μ, Σ) – стандартная функция плотности нормального распределения. Это ядро называется также радиально-базисной функцией (RBF), потому что его зна- чение убывает вдоль прямых в пространстве v, исходящих из u. Гауссово ядро соот- ветствует скалярному произведению в бесконечномерном пространстве, но описание этого пространства не так тривиально, как в примере ядра min над целыми числами. Можно считать, что ядро Гаусса реализует некое сравнение с образцом. Обучаю- щий пример x, с которым ассоциирована метка y, становится образцом класса y. Если тестовая точка x′ близка к x в смысле евклидова расстояния, то гауссово ядро дает большой отклик, показывающий, что x′ очень похож на образец x. Тогда модель на- значает большой вес ассоциированной обучающей метке y. Итоговое предсказание объединяет много обучающих меток, взвешенных в соответствии с похожестью на соответствующие обучающие примеры. Метод опорных векторов – не единственный алгоритм, который можно улучшить с помощью трюка с ядром. Категория алгоритмов, в которых используется трюк с ядром, называется ядерными методами (Williams and Rasmussen, 1996; Schölkopf et al., 1999). Главный недостаток ядерных методов – тот факт, что сложность вычисления ре шающей функции линейно зависит от числа обучающих примеров, поскольку i-й пример вносит член αi k(x, x(i)) в решающую функцию. В методе опорных векторов эта проб лема сглаживается тем, что обучаемый вектор α содержит в основном нули. Тогда для классификации нового примера требуется вычислить ядерную функцию только для обучающих примеров с ненулевыми αi. Эти обучающие примеры и назы- ваются опорными векторами. Для ядерных методов характерна также высокая стоимость обучения при большом наборе данных. Мы вернемся к этому вопросу в разделе 5.9. Ядерные методы с ядрами общего вида плохо обобщаются. Почему это так, мы объясним в разделе 5.11. Глубо- кое обучение в своем современном воплощении предназначено для преодоления этих ограничений ядерных методов. Ренессанс глубокого обучения начался с работы Hin- ton et al. (2006), где было продемонстрировано, что нейронная сеть способна превзой-ти метод SVM с радиально-базисным ядром на эталонном наборе данных MNIST.\n--- Страница 133 ---\n132  Основы машинного обучения 5.7.3. Другие простые алгоритмы обучения с учителем Мы уже встречались с другим невероятностным алгоритмом обучения с учителем – регрессией методом ближайшего соседа. В общем случае для классификации или регрессии используется семейство методов с k ближайшими соседями. Будучи не- параметрическим алгоритмом обучения, метод k ближайших соседей не ограничен фиксированным числом параметров. Обычно считается, что этот алгоритм вообще не имеет параметров, а реализует простую функцию от обучающих данных. На са- мом деле в нем даже нет настоящего этапа обучения. Просто на этапе тестирования, желая породить выход y для тестового примера x, мы ищем в обучающем наборе X k ближайших соседей x, а затем возвращаем среднее соответствующих им меток y. Эта идея работает для любого вида обучения с учителем, при условии что можно опре- делить понятие средней метки. В случае классификации усреднять можно по уни- тарным кодовым векторам c, в которых cy = 1 и ci = 0 для всех остальных i. Среднее по таким векторам можно интерпретировать как распределение вероятности классов. Алгоритм k ближайших соседей, являясь непараметрическим, может достигать очень высокой емкости. Предположим, к примеру, что имеются задача многоклассовой классификации и мера производительности с бинарной функцией потерь. В таком случае метод одного ближайшего соседа сходится к удвоенной байесовской частоте ошибок, когда число обучающих примеров стремится к бесконечности. Превышение над байесовской ошибкой связано с тем, что мы случайным образом выбираем одного из равноудаленных соседей. Если число обучающих примеров бесконечно, то у всех тестовых точек x будет бесконечно много соседей из обучающего набора на нулевом расстоянии. Если бы алгоритм разрешал соседям проголосовать, а не выбирал слу- чайного соседа, то процедура сходилась бы к байесовской частоте ошибок. Высокая емкость алгоритма k ближайших соседей позволяет получить высокую верность, если имеется большой обучающий набор. Но за это приходится расплачиваться высокой стоимостью вычислений, а при малом обучающем наборе алгоритм плохо обобща- ется. Одно из слабых мест алгоритма k ближайших соседей – неумение понять, что один признак является более отличительным, чем другой. Возьмем, к примеру, задачу регрессии, в которой x ∈ ℝ 100 выбирается из изотропного нормального распределения, но результат зависит только от переменной x1. Предположим еще, что результат по- просту совпадает с этим признаком, т. е. y = x1 во всех случаях. Регрессия методом ближайшего соседа не сможет уловить эту простую закономерность. Ближайший со-сед большинства точек x будет определяться по большому числу признаков от x 2 до x100, а не только по признаку x1. Поэтому на небольшом обучающем наборе результат будет, по существу, случайным. Еще один тип алгоритма обучения, также разбивающий пространство входов на области, каждая из которых описывается отдельными параметрами, – решающее дерево (Breiman et al., 1984) и его многочисленные варианты. На рис. 5.7 показано, что с каждым узлом решающего дерева ассоциирована область пространства входов, и внутренние узлы разбивают эту область на две части – по одной для каждого дочер- него узла (обычно рассекая параллельно оси). Таким образом, пространство входов делится на непересекающиеся области, взаимно однозначно соответствующие лис-товым узлам. Обычно каждый листовый узел сопоставляет каждой входной точке в своей области один и тот же выход. Для обучения решающих деревьев применяются специальные алгоритмы, выходящие за рамки этой книги. Алгоритм обучения можно Рис. 5.7  Описание работы решающего дерева. (Вверху) Каждый узел дерева выбирает, кому отправить входной пример: левому потомку (0) или правому (1). Внутренние узлы изображены кружочками, листовые – квад- ратиками. Каждый узел обозначается строкой нулей и единиц, описываю- щей его позицию в дереве. Строка получается дописыванием одного разряда к идентификатору родительского узла (0 – слева от родителя, 1 – справа от родителя). (Внизу) Дерево разбивает пространство на области. На рисунке приведен пример разбиения плоскости ℝ 2. На этой плоскости нарисованы узлы дерева, через каждый внутренний узел проходит разде-лительная линия, показывающая, как он классифицирует примеры, а лис- товые узлы находятся в центре множества попадающих в них примеров. В результате получается кусочно-постоянная функция, сопоставляющая свой «кусок» каждому листовому узлу. В каждом листовом узле должен на- ходиться хотя бы один пример, так что решающее дерево не может обучить функцию, имеющую больше локальных максимумов, чем число обучающих примеров.\n--- Страница 134 ---\nАлгоритмы обучения с учителем  133 5.7.3. Другие простые алгоритмы обучения с учителем Мы уже встречались с другим невероятностным алгоритмом обучения с учителем – регрессией методом ближайшего соседа. В общем случае для классификации или регрессии используется семейство методов с k ближайшими соседями. Будучи не- параметрическим алгоритмом обучения, метод k ближайших соседей не ограничен фиксированным числом параметров. Обычно считается, что этот алгоритм вообще не имеет параметров, а реализует простую функцию от обучающих данных. На са- мом деле в нем даже нет настоящего этапа обучения. Просто на этапе тестирования, желая породить выход y для тестового примера x, мы ищем в обучающем наборе X k ближайших соседей x, а затем возвращаем среднее соответствующих им меток y. Эта идея работает для любого вида обучения с учителем, при условии что можно опре- делить понятие средней метки. В случае классификации усреднять можно по уни- тарным кодовым векторам c, в которых cy = 1 и ci = 0 для всех остальных i. Среднее по таким векторам можно интерпретировать как распределение вероятности классов. Алгоритм k ближайших соседей, являясь непараметрическим, может достигать очень высокой емкости. Предположим, к примеру, что имеются задача многоклассовой классификации и мера производительности с бинарной функцией потерь. В таком случае метод одного ближайшего соседа сходится к удвоенной байесовской частоте ошибок, когда число обучающих примеров стремится к бесконечности. Превышение над байесовской ошибкой связано с тем, что мы случайным образом выбираем одного из равноудаленных соседей. Если число обучающих примеров бесконечно, то у всех тестовых точек x будет бесконечно много соседей из обучающего набора на нулевом расстоянии. Если бы алгоритм разрешал соседям проголосовать, а не выбирал слу- чайного соседа, то процедура сходилась бы к байесовской частоте ошибок. Высокая емкость алгоритма k ближайших соседей позволяет получить высокую верность, если имеется большой обучающий набор. Но за это приходится расплачиваться высокой стоимостью вычислений, а при малом обучающем наборе алгоритм плохо обобща- ется. Одно из слабых мест алгоритма k ближайших соседей – неумение понять, что один признак является более отличительным, чем другой. Возьмем, к примеру, задачу регрессии, в которой x ∈ ℝ 100 выбирается из изотропного нормального распределения, но результат зависит только от переменной x1. Предположим еще, что результат по- просту совпадает с этим признаком, т. е. y = x1 во всех случаях. Регрессия методом ближайшего соседа не сможет уловить эту простую закономерность. Ближайший со-сед большинства точек x будет определяться по большому числу признаков от x 2 до x100, а не только по признаку x1. Поэтому на небольшом обучающем наборе результат будет, по существу, случайным. Еще один тип алгоритма обучения, также разбивающий пространство входов на области, каждая из которых описывается отдельными параметрами, – решающее дерево (Breiman et al., 1984) и его многочисленные варианты. На рис. 5.7 показано, что с каждым узлом решающего дерева ассоциирована область пространства входов, и внутренние узлы разбивают эту область на две части – по одной для каждого дочер- него узла (обычно рассекая параллельно оси). Таким образом, пространство входов делится на непересекающиеся области, взаимно однозначно соответствующие лис-товым узлам. Обычно каждый листовый узел сопоставляет каждой входной точке в своей области один и тот же выход. Для обучения решающих деревьев применяются специальные алгоритмы, выходящие за рамки этой книги. Алгоритм обучения можно Рис. 5.7  Описание работы решающего дерева. (Вверху) Каждый узел дерева выбирает, кому отправить входной пример: левому потомку (0) или правому (1). Внутренние узлы изображены кружочками, листовые – квад- ратиками. Каждый узел обозначается строкой нулей и единиц, описываю- щей его позицию в дереве. Строка получается дописыванием одного разряда к идентификатору родительского узла (0 – слева от родителя, 1 – справа от родителя). (Внизу) Дерево разбивает пространство на области. На рисунке приведен пример разбиения плоскости ℝ 2. На этой плоскости нарисованы узлы дерева, через каждый внутренний узел проходит разде-лительная линия, показывающая, как он классифицирует примеры, а лис- товые узлы находятся в центре множества попадающих в них примеров. В результате получается кусочно-постоянная функция, сопоставляющая свой «кусок» каждому листовому узлу. В каждом листовом узле должен на- ходиться хотя бы один пример, так что решающее дерево не может обучить функцию, имеющую больше локальных максимумов, чем число обучающих примеров.\n--- Страница 135 ---\n134  Основы машинного обучения считать непараметрическим, если ему разрешено обучать дерево произвольного раз- мера, хотя обычно решающие деревья регуляризируются с помощью ограничений на размер, так что на практике модель становится параметрической. В том виде, в каком решающие деревья обычно используются – с осепараллельным разделением в узлах и постоянным выходом в каждом узле, – они с трудом решают некоторые задачи, с которыми легко справляется даже логистическая регрессия. Например, если име- ется двухклассовая задача и класс положителен тогда и только тогда, когда x2 > x1, то решающая граница не параллельна оси. Поэтому решающему дереву придется аппроксимировать решающую границу большим количеством узлов – реализовать ступенчатую функцию с осепараллельными шагами, которая постоянно колеблется по обе стороны истинной решающей функции. Как мы видели, у предикторов на основе ближайших соседей и решающих деревьев много ограничений. Тем не менее эти алгоритмы обучения полезны, когда мы стес-нены в вычислительных ресурсах. Мы также можем интуитивно оценить поведение более сложных алгоритмов обучения, размышляя о сходстве и различии между ними и эталонами: ближайшими соседями и решающими деревьями. Дополнительный материал об алгоритмах обучения с учителем см. в работах Murphy (2012), Bishop (2006), Hastie et al. (2001) и других учебниках по машинному обучению. 5.8. Алгоритмы обучения без учителя Напомним (раздел 5.1.3), что алгоритмом обучения без учителя называется алго-ритм, который получает на входе только «признаки» без какой-либо подсказки со стороны учителя. Различие между обучением с учителем и без учителя определено не формально и жестко, потому что не существует объективного критерия, что считать признаком, а что – меткой. Неформально под обучением без учителя понимают по- пытки извлечь информацию из распределения, выборка из которого не была вручную аннотирована человеком. Этот термин обычно ассоциируется с оцениванием плотно- сти, выборкой примеров из распределения, очисткой выбранных из некоторого рас-пределения данных от шума, нахождением многообразия, рядом с которым распола- гаются данные, или кластеризацией данных – выделением групп похожих примеров. Классическая задача обучения без учителя – найти «наилучшее» представление данных. Под «наилучшим» можно понимать разные вещи, но в общем случае ищется представление, которое сохраняет как можно больше информации о x, соблюдая при этом ограничения, призванные сделать представление проще или понятнее, чем само x. Определить более простое представление можно многими способами. Три самых распространенных: представления меньшей размерности, разреженные представле-ния и независимые представления. В случае понижения размерности мы пытаемся спрессовать как можно больше информации об x в представление меньшего разме- ра. Разреженное представление (Barlow, 1989; Olshausen and Field, 1996; Hinton and Ghahramani, 1997) – это погружение набора данных в представление, где большинству входов соответствуют нули. В этом случае размерность представления обычно увели- чивается, так чтобы наличие многих нулей не приводило к отбрасыванию слишком большого объема информации. В результате получается представление, в котором данные распределены в основном вдоль осей. Независимые представления – это по- пытка разделить источники вариативности в истинном распределении данных, чтобы измерения представления оказались статистически независимыми.\n--- Страница 136 ---\nАлгоритмы обучения без учителя  135 Разумеется, эти критерия не исключат друг друга. Представления низкой размер- ности часто дают элементы, между которыми меньше зависимостей или зависимости более слабые, чем в исходных данных высокой размерности. Так происходит, потому что один из способов уменьшить размер представления – найти и устранить избы- точность. Чем больше избыточности удается устранить, тем больше степень сжатия и тем меньше потери информации. Понятие представления – одна из центральных тем глубокого обучения, а вместе с тем и книги. В этом разделе мы приведем несколько простых алгоритмов обучения представлений. В совокупности эти примеры показывают, как вышеупомянутые кри- терии выглядят на практике. В последующих главах будут описаны дополнительные алгоритмы обучения представлений, где эти критерии развиваются в разных направ- лениях или вводятся новые. 5.8.1. Метод главных компонент В разделе 2.12 мы видели, что метод главных компонент позволяет сжимать данные. PCA можно рассматривать как алгоритм обучения без учителя, который ищет пред-ставление данных, основанное на двух из трех описанных выше критериев простого представления. PCA обучает представление, имеющее меньшую размерность, чем ис-ходное. Кроме того, в этом представлении между элементами нет линейной корреля- ции. Это первый шаг к нахождению представления со статистически независимыми элементами. Чтобы полностью избавиться от зависимостей, алгоритм обучения дол-жен удалить также нелинейные связи между переменными. 20 10 0 –10–202010 0 –10–20 –20 –20 –10 –10 0 0 10 10 20 20 х 1 х1х2 х2 Рис. 5.8  Результатом PCA являются проекции на прямые, параллель- ные направлению наибольшей дисперсии. Они становятся осями нового пространства. (Слева) Исходные данные содержат выборку из x. В этом пространстве дисперсия может быть максимальна вдоль прямых, не па-раллельных осям. (Справа) После преобразования z = x ⏉W наибольшее изменение сосредоточено вдоль оси z1. Направление второй по величине дисперсии стало осью z2 PCA находит ортогональное линейное преобразование, переводящее входные данные x в представление z, как показано на рис. 5.8. В разделе 2.12 мы видели, что можно обучить одномерное представление, наилучшим образом реконструирующее\n--- Страница 137 ---\n136  Основы машинного обучения исходные данные (в смысле среднеквадратической ошибки), и что это представле- ние на самом деле соответствует первой главной компоненте данных. Следовательно, мы можем использовать PCA как простой и эффективный метод понижения размер- ности, который сохраняет столько присутствующей в данных информации, сколько возможно (опять же на основе измерения ошибки реконструкции по методу наимень-ших квадратов). Ниже мы изучим, как представление PCA устраняет корреляцию из исходного представления X. Рассмотрим матрицу плана X размера m×n. Будем предполагать, что математиче- ское ожидание данных 𝔼[x] = 0. Если это не так, центрирования легко добиться, выч- тя среднее из всех примеров на этапе предварительной обработки. Несмещенная выборочная ковариационная матрица, ассоциированная с X, опре- деляется по формуле (5.85) PCA находит представление (посредством линейного преобразования) z = W⏉x, для которого Var[z] – диагональная матрица. В разделе 2.12 мы видели, что главные компоненты матрицы плана X определяют- ся собственными векторами X⏉X. Таким образом, X⏉X = WΛW⏉. (5.86) В этом разделе мы по-другому подойдем к выводу главных компонент. Их можно получить также путем сингулярного разложения (SVD). Точнее, это правые сингу- лярные векторы X. Чтобы убедиться в этом, предположим, что W – правые сингу- лярные векторы в разложении X = UΣW⏉. Тогда исходное уравнение собственных векторов можно переписать в базисе W: X⏉X = (UΣW⏉)⏉UΣW⏉ = WΣ2W⏉. (5.87) Разложение SVD полезно для доказательства того, что PCA приводит к диагональ- ной матрице Var[z]. Применяя сингулярное разложение X, мы можем выразить дис- персию X в виде: (5.88) (5.89) (5.90) (5.91) где используется тот факт, что U⏉U = I, поскольку матрица U в сингулярном разло- жении по определению ортогональная. Отсюда следует, что ковариационная матрица z диагональная, что и требовалось доказать: (5.92)\n--- Страница 138 ---\nАлгоритмы обучения без учителя  137 (5.93) (5.94) . (5.95) На этот раз мы воспользовались тем, что W⏉W = I – опять же по определению сингулярного разложения. Проведенный анализ показывает, что представление, полученное в результате прое цирования данных x на z посредством линейного преобразования W, имеет диа- гональную ковариационную матрицу (Σ2). А отсюда сразу вытекает, что взаимная корреляция отдельных элементов z равна нулю. Это свойство PCA – преобразовывать данные в представление с взаимно не кор- релированными элементами – очень важно. Оно дает простой пример представления, пытающегося разделить неизвестные факторы вариативности данных. В случае PCA разделение сводится к поиску такого вращения пространства входных данных (описываемого матрицей W), которое делает главные оси дисперсии базисом нового пространства представления z. Хотя корреляция – важная категория зависимостей между элементами данных, при обучении представлений нам также интересно разделить более сложные виды зависимостей между признаками, не исчерпывающимися простыми линейными пре-образованиями. 5.8.2. Кластеризация методом k средних Еще один пример простого алгоритма обучения представлений дает кластеризация методом k средних. Этот алгоритм разбивает обучающий набор на k кластеров, содер- жащих близкие примеры. Можно считать, что этот алгоритм вырабатывает k-мерный унитарный кодовый вектор h, представляющий вход x. Если x принадлежит i-му клас теру, то h i = 1, а все остальные элементы h равны 0. Унитарный код, порождаемый кластеризацией методом k средних, – пример разре- женного представления, поскольку для каждого входного примера большинство эле-ментов представления равно нулю. Впоследствии мы разработаем другие алгоритмы, вырабатывающие более гибкие разреженные представления, в которых ненулевыми может быть несколько элементов. Унитарный код – крайний случай разреженного представления, в котором утрачены многие преимущества распределенных представ- лений. Но все же у него есть некоторые статистические достоинства (он естествен- но передает идею о том, что все примеры из одного кластера похожи друг на друга), а также чисто вычислительное преимущество: все представление можно выразить одним целым числом. В начале работы алгоритма инициализируется k различных центроидов {μ (1), …, μ(k)}, а затем поочередно выполняются два шага до достижения сходимости. На одном шаге каждый обучающий пример относится к i-му кластеру, где i – индекс ближайшего центроида μ(i). На другом шаге каждому центроиду μ(i) присваивается значение, равное среднему всех отнесенных к i-му кластеру примеров x(j). Одной из проблем является тот факт, что задача кластеризации некорректно по- ставлена в том смысле, что не существует однозначного критерия, позволяющего су-\n--- Страница 139 ---\n138  Основы машинного обучения дить, в какой мере найденная кластеризация данных соответствует реальности. Мы можем измерить такие свойства кластеризации, как среднее евклидово расстояние от центроида кластера до его членов. Это позволит сказать, насколько хорошо можно реконструировать обучающие данные по отнесению к кластерам. Но мы не знаем, на- сколько хорошо отнесение примеров к кластерам отражает свойства реального мира. Более того, может существовать несколько разных способов кластеризации, одинако-во хорошо описывающих реальный мир. Быть может, мы надеялись найти кластери-зацию, относящуюся к одному признаку, а нашли совсем другую, не менее хорошую кластеризацию, не имеющую ни малейшего отношения к нашей задаче. Предполо- жим, к примеру, что мы выполнили два разных алгоритма кластеризации для на- бора данных, содержащего изображения красных грузовиков, красных легковушек, серых грузовиков и серых легковушек. Если мы попросим каждый алгоритм найти два кластера, то один может найти кластер грузовиков и кластер легковушек, а дру- гой – кластеры красных и серых транспортных средств. Допустим, есть еще и третий алгоритм, умеющий сам определять число кластеров. Он может отнести примеры к четырем кластерам: красные легковушки, красные грузовики, серые легковушки, серые грузовики. Новая кластеризация улавливает оба атрибута, но теряет информа-цию о сходстве. Красные легковушки не попали ни в кластер серых легковушек, ни в кластер серых грузовиков. Результат этого алгоритма ничего не говорит о том, что красные легковушки больше похожи на серые легковушки, чем на серые грузовики. Они отличаются и от того, и от другого, но это все, что мы знаем. Эти проблемы иллюстрируют причины, по которым распределенное представле- ние может оказаться лучше унитарного. В распределенном представлении можно было бы хранить два атрибута для каждого транспортного средства: цвет и тип (гру- зовик или легковушка). По-прежнему не ясно, какое распределенное представление оптимально (как алгоритм обучения мог бы узнать, что нас интересует цвет и тип, а не, скажем, производитель и возраст машины?), но хранение нескольких атрибутов, по крайней мере, позволяет алгоритму не гадать, какой единственный атрибут нас интересует, и дает возможность измерять сходство между объектами более детально, сравнивая многие атрибуты, а не просто проверяя совпадение одного единственного. 5.9. Стохастический градиентный спуск Почти всё глубокое обучение основано на одном очень важном алгоритме: стохасти-ческом градиентном спуске (СГС). Это обобщение алгоритма градиентного спуска, описанного в разделе 4.3. В машинном обучении постоянно возникает одна и та же проблема: большой обучаю щий набор необходим для более качественного обобщения, но обучение на нем обходится дорого с точки зрения вычислений. Функция стоимости, применяемая в алгоритмах машинного обучения, часто пред- ставляется в виде суммы по всем примерам некоторой функции потерь, определен- ной для одного примера. Так, отрицательное условное логарифмическое правдоподо-бие обучающих данных можно записать в виде: (5.96) где L – потеря на одном примере L(x, y, θ) = –log p(y | x; θ).\n--- Страница 140 ---\nСтохастический градиентный спуск  139 Для таких аддитивных функций потерь метод градиентного спуска вычисляет вы- ражение (5.97) Вычислительная сложность этой операции составляет O(m). Если обучающий на- бор содержит миллиарды примеров, то время одного шага вычисления градиента ста- новится недопустимо большим. Идея метода СГС состоит в том, что градиент – это математическое ожидание, и, следовательно, его можно оценить по небольшому множеству примеров. Точнее, на каждом шаге алгоритма мы можем взять мини-пакет (minibatch) – небольшую равномерную выборку из обучающего набора 𝔹 = { x(1), …, x(m′)}. Размер мини-паке- та m′ обычно составляет от одной до нескольких сотен. Важно, что m′, как правило, фиксируется, т. е. не изменяется с ростом размера обучающего набора m. Мы можем аппроксимировать многомиллиардный обучающий набор, производя вычисления только на сотне примеров. Оценку градиента дает следующее выражение: (5.98) в котором используются только примеры из мини-пакета 𝔹. Затем алгоритм стохас- тического градиентного спуска следует в направлении градиента: θ ⟵ θ – εg, (5.99) где ε – скорость обучения. Вообще говоря, градиентный спуск часто считался медленным или ненадежным методом. В прошлом применение градиентного спуска к задачам невыпуклой опти- мизации рассматривали как авантюризм или беспринципность. Сегодня мы знаем, что модели машинного обучения, описанные в части II, прекрасно работают после обучения методом градиентного спуска. Пусть и не гарантируется, что алгоритм оп- тимизации найдет хотя бы локальный минимум за разумное время, зачастую он все же находит очень малое значение функции стоимости достаточно быстро, для того чтобы считаться полезным. Стохастический градиентный спуск имеет важные применения и за пределами глубокого машинного обучения. Это основной способ обучения больших линейных моделей на очень больших наборах данных. Для модели фиксированного размера стоимость одного шага СГС не зависит от размера обучающего набора m. На практи- ке мы часто увеличиваем размер модели по мере роста размера обучающего набора, но это необязательно. Количество шагов до достижения сходимости обычно возрас-тает с ростом размера обучающего набора. Но когда m стремится к бесконечности, модель в конечном итоге сходится к наилучшей возможной ошибке тестирования еще до того, как СГC проверил каждый пример из обучающего набора. Дальнейшее увеличение m не увеличивает время обучения, необходимое для достижения наилуч- шей ошибки тестирования. С этой точки зрения можно сказать, что асимптотическая стоимость обучения модели методом СГС как функция m имеет порядок O(1). До изобретения глубокого обучения основным способом обучения нелинейных моделей была комбинация трюка с ядром и линейной модели. Для многих ядерных\n--- Страница 141 ---\n140  Основы машинного обучения алгоритмов обучения нужно было построить матрицу m×m Gi, j = k(x(i), x(j)). Слож- ность построения такой матрицы равна O(m2), что, очевидно, неприемлемо для на- боров данных с миллиардами примеров. Начиная с 2006 года интерес к глубокому обучению в академических кругах поначалу был обусловлен тем, что, по сравнению с конкурирующими алгоритмами, оно лучше обобщается на новые примеры при на- боре данных среднего размера – с десятками тысяч примеров. Но вскоре после этого в отрасли пробудился дополнительный интерес, поскольку глубокое обучение да- вало масштабируемый способ обучения нелинейных моделей на больших наборах данных. Метод стохастического градиентного спуска и его многочисленные усовершен- ствования подробно описаны в главе 8. 5.10. Построение алгоритма машинного обучения Почти все алгоритмы глубокого обучения можно описать как варианты одного прос-того рецепта: комбинация набора данных, функции стоимости, процедуры оптимиза-ции и модели. Например, алгоритм линейной регрессии – это комбинация набора данных, состоя- щего из X и y, функции стоимости J(w, b) = –𝔼 x, y∼p �data log pmodel(y | x), (5.100) спецификации модели pmodel(y | x) = 𝒩(y; x⏉w + b, 1) и в большинстве случаев алго- ритма оптимизации, который путем решения нормальных уравнений находит точки, где градиент функции стоимости обращается в 0. Осознав, что любой из этих компонентов можно заменить – как правило, независи- мо от остальных, – мы можем получить широкий спектр алгоритмов. Типичная функция стоимости включает, по меньшей мере, один член, благодаря которому в процессе обучения производится статистическое оценивание. Чаще всего в роли функции стоимости выступает отрицательное логарифмическое правдоподо- бие, поэтому ее минимизация дает оценку максимального правдоподобия. Функция стоимости может включать и дополнительные члены, например для ре- гуляризации. Так, к функции стоимости линейной регрессии можно прибавить по- ощрение за снижение весов: J(w, b) = λ|| w|| 22 – 𝔼x, y∼p �data log pmodel(y | x). (5.101) И в этом случае возможна оптимизация в замкнутой форме.Если перейти от линейных моделей к нелинейным, то для большинства функций стоимости оптимизация в замкнутой форме уже невозможна. Придется выбрать какую-то процедуру численной оптимизации, например градиентный спуск. Рецепт построения алгоритма обучения путем комбинирования модели, функции стоимости и алгоритма оптимизации подходит для обучения как с учителем, так и без оного. Линейная регрессия дает пример обучения с учителем. А для обучения без учителя нужно будет определить набор данных, содержащий только X, и предоста- вить походящую функцию стоимости и модель. Например, для получения первого вектора методом PCA можно задать такую функцию потерь: J(w) = 𝔼 x∼p �data ||x – r(x; w)||22 (5.102)\n--- Страница 142 ---\nПроблемы, требующие глубокого обучения  141 и модель, в которой w имеет единичную норму, а в качестве функции реконструкции используется r(x) = w⏉xw. В некоторых случаях функцию стоимости невозможно вычислить из-за высокой стоимости вычислений. Но и тогда мы можем минимизировать ее приближенно, при- меняя итеративную численную оптимизацию, при условии что существует какой-то способ аппроксимации ее градиентов. В большинстве алгоритмов машинного обучения используется именно этот рецепт, хотя не всегда это очевидно с первого взгляда. Если алгоритм кажется ни что не по- хожим или спроектирован вручную, обычно его можно понять, рассматривая как оп-тимизацию в особом случае. Для некоторых моделей, например решающих деревьев и k средних, требуются специальные оптимизации, потому что их функции стоимости имеют плоские участки, из-за которых минимизация градиентными методами не годит-ся. Осознание того, что большинство алгоритмов машинного обучения можно описать таким рецептом, позволяет рассматривать различные алгоритмы как результат систе-матизации методов для решения сходных задач, которые работают по сходным при-чинам, а не как длинный список алгоритмов, у каждого из которых свое обоснование. 5.11. Проблемы, требующие глубокого обучения Простые алгоритмы машинного обучения, описанные в этой главе, хорошо работают для самых разных задач. Однако они потерпели неудачу при решении центральных проблем ИИ, в частности распознавании речи и объектов. Среди стимулов для разработки глубокого обучения была в том числе и неспособ- ность традиционных алгоритмов добиться обобщаемости на таких задачах ИИ. В этом разделе мы покажем, что трудность проблемы обобщения на новые при- меры экспоненциально возрастает при работе с многомерными данными и что меха- низмов обобщения, работающих в традиционном машинном обучении, недостаточно для обучения сложных функций в многомерных пространствах, поскольку стоимость вычислений становится слишком высока. Глубокое обучение призвано преодолеть эти и другие препятствия. 5.11.1. Проклятие размерности Многие алгоритмы машинного обучения резко усложняются, когда размерность дан-ных велика. Это явление называется проклятием размерности. Особенно неприятно, что количество возможных конфигураций множества переменных возрастает экспо-ненциально с увеличением числа переменных. Проклятие размерности возникает в разных разделах информатики, но особенно часто в машинном обучении. Один из аспектов проклятия размерности связан со статистикой. На рис. 5.9 видно, что статистическая проблема возникает из-за того, что число возможных конфигура-ций x гораздо больше, чем число обучающих примеров. Чтобы разобраться, в чем тут дело, рассмотрим пространство входов, организованное в виде сетки, как на рисунке. Пространство низкой размерности можно описать небольшим числом ячеек сетки, по большей части занятых данными. При обобщении на новый пример мы обычно можем сказать, что делать, просто исследовав обучающие примеры, находящиеся в той же ячейке, что и новый. Например, в качестве оценки плотности вероятности в некоторой точке x мы можем просто вернуть число обучающих примеров в том же\n--- Страница 143 ---\n142  Основы машинного обучения единичном объеме, что и x, поделенное на общее число обучающих примеров. Чтобы классифицировать пример, мы возвращаем класс большинства обучающих примеров в той же ячейке. В случае регрессии мы можем усреднить значения, наблюдавшиеся для примеров в этой ячейке. Но как быть с ячейками, для которых мы не видели ни одного примера? Поскольку в пространстве высокой размерности количество кон- фигураций огромно – гораздо больше числа примеров, – в большинстве ячеек сетки обучающих примеров нет. И как можно сказать что-то осмысленное о новых конфи- гурациях? В большинстве традиционных алгоритмов машинного обучения прос то предполагается, что выход в новой точке должен быть примерно таким же, как в бли- жайшей обучающей точке. Рис. 5.9  С увеличением размерности данных (слева направо) коли- чество представляющих интерес конфигураций растет экспоненциально. (Слева) В одномерном случае имеется одна переменная, и для нее всего 10 интересных областей. При достаточном числе примеров, попадающих в каждую область (на рисунке область соответствует одной клетке), от ал- горитма обучения легко добиться правильного обобщения. Самый прямо-линейный способ – оценить значение метки в каждой области с возможной интерполяцией между соседними областями). (В центре) В двумерном слу- чае уже труднее различить 10 разных значений каждой переменной. Нам приходится учитывать 10×10 = 100 областей, и, чтобы их все покрыть, нуж-но, по крайней мере, столько же примеров. (Справа) В трехмерном случае число областей возрастает до 103 = 1000, и соответственно растет число примеров. Если имеется d измерений и нужно различать v значений вдоль каждой оси, то потребуется O(v d) областей и примеров. Это и есть прокля- тие размерности. Рисунок любезно предоставил Николас Чападос 5.11.2. Регуляризация для достижения локального постоянства и гладкости Чтобы алгоритм хорошо обобщался, необходимо иметь априорное представление о том, какого рода функцию он должен обучить. Мы видели, что эти априорные пред- положения выражаются явно в виде распределения вероятности параметров моде- ли. Неформально мы можем также полагать, что априорные знания непосредственно влияют на саму функцию и лишь опосредованно на параметры, считая это резуль- татом связи между параметрами и функцией. Кроме того, неформально априорные предположения неявно выражаются в виде выбора алгоритма, смещенного в поль- зу определенного класса функций, хотя такое смещение, возможно, и не выражено (а иногда его попросту невозможно выразить) в терминах распределения вероятно- сти, описывающего степень уверенности в выборе той или иной функции.\n--- Страница 144 ---\nПроблемы, требующие глубокого обучения  143 Из самых распространенных неявных «априорных предположений» отметим априорное предположение о гладкости, или априорное предположение о локаль- ном постоянстве. То и другое означает, что обучаемая функция не должна сильно изменяться в небольшой области. Обобщаемость многих простых алгоритмов опирается исключительно на это апри- орное предположение, и потому они плохо масштабируются в условиях статистиче- ских проблем, присущих задачам ИИ. Ниже в этой книге мы увидим, что глубокое обучение вводит дополнительные (явные и неявные) априорные предположения, чтобы уменьшить ошибку обобщения на сложных задачах. А сейчас объясним, по- чему одного предположения о гладкости недостаточно. Существует много способов явно или неявно выразить априорное предположение о том, что обучаемая функция должна быть гладкой или локально постоянной. Все они направлены на то, чтобы заставить процесс обучения находить функцию f *, удов- летворяющую условию f *(x) ≈ f *(x + ε) (5.103) для большинства конфигураций x и небольшого изменения ε. Иными словами, если мы знаем хороший ответ для входа x (например, если x – помеченный обучающий пример), то этот ответ, вероятно, будет хорошим и в окрестности x. Если в некоторой окрестности есть несколько хороших ответов, то можно скомбинировать их (путем какой-то формы усреднения или интерполяции) и получить ответ, согласующийся с большинством вариантов. Крайнее проявление подхода на основе локального постоянства – алгоритмы обуче ния на основе k ближайших соседей. Такие предикторы действительно посто- янны в области, содержащей все точки x с одним и тем же множеством k ближайших соседей из обучающего набора. Для k = 1 число различимых областей не может пре- вышать количество обучающих примеров. Если алгоритм k ближайших соседей формирует выход, копируя близкие обучаю- щие примеры, то большинство ядерных методов выполняет интерполяцию меток близких примеров. Важным классом ядер является семейство локальных ядер, для ко- торых k(u, v) велико, если u = v, и убывает мере роста расстояния между u и v. Локаль- ное ядро можно представлять себе как функцию сходства, которая производит сравне-ние с образцом, измеряя сходство между тестовым примером x и каждым обучаю щим примером x (i). На развитие глубокого обучения в немалой степени повлия ло изучение ограничений локального сравнения с образцом и того, как глубокие модели могут до- биться успеха там, где этот метод терпит неудачу (Bengio et al., 2006b). Решающие деревья также подвержены ограничениям обучения, основанного толь- ко на предположении о гладкости, поскольку разделяют пространство на столько областей, сколько имеется листьев, и используют отдельный параметр (а в случае обобщений случайных деревьев – несколько параметров) в каждой области. Если для верного представления выходной функции требуется дерево, имеющее как минимум n листьев, то для построения такого дерева нужно, по крайней мере, n обучающих примеров. А для обеспечения хоть какой-то статистической уверенности в предска- заниях дерева примеров нужно в несколько раз больше n. В общем случае для различения O(k) областей в пространстве входов всем этим методам нужно O(k) примеров. Как правило, существует O(k) параметров, и с каждой областей ассоциировано O(1) параметров. На рис. 5.10 показан случай использова-\n--- Страница 145 ---\n144  Основы машинного обучения ния одного ближайшего соседа, когда каждый обучающий пример можно использо- вать для определения самое большее одной области. Рис. 5.10  Как алгоритм ближайшего соседа разбивает пространство входов на области. Пример (представлен кружочком) внутри каждой обла-сти определяет ее границы (представлены прямыми линиями). Значение y, ассоциированное с каждым примером, определяет, что будет возвращено для всех точек соответствующей области. Области, определяемые сравне-нием с ближайшим соседом, образуют геометрическую конструкцию, на- зываемую диаграммой Вороного. Число таких смежных областей не может расти быстрее числа обучающих примеров. Хотя на этом рисунке иллюст-рируется поведение конкретного алгоритма ближайшего соседа, другие алгоритмы машинного обучения, опирающиеся для обобщения только на априорное предположение о гладкости, демонстрируют аналогичное пове- дение: каждый обучающий пример информирует алгоритм обучения только о том, как производить обобщение в некоторой окрестности этого примера. Существует ли способ представить сложную функцию, для которой число подле- жащих различению областей гораздо больше числа обучающих примеров? Очевидно, что одного предположения о гладкости функций для этого недостаточно. Предпо- ложим, к примеру, что выходная функция напоминает шахматную доску. Вариатив- ность шахматной доски велика, но все варианты укладываются в простую структуру. Подумаем, что произойдет, если число обучающих примеров намного меньше числа черных и белых клеток. Опираясь только на локальное обобщение и гипотезу о глад- кости или локальном постоянстве, можно гарантировать, что алгоритм обучения пра-вильно угадает цвет новой точки, если она находится в одной клетке с каким-нибудь обучающим примером. Но нет никакой гарантии, что алгоритм обучения сумеет пра-вильно обобщить структуру шахматной доски на точки, попадающие в клетки, где нет обучающих примеров. Если у нас нет ничего, кроме этого априорного предполо- жения, то пример может сообщить лишь о цвете своей клетки, и, чтобы узнать цвета всех клеток шахматной доски, мы должны поместить в каждую хотя бы один пример. Предположение о гладкости и соответствующие ему непараметрические алгорит- мы обучения прекрасно работают, если примеров достаточно, чтобы алгоритм увидел верхние точки большинства пиков и нижние точки большинства впадин истинной функции. Вообще говоря, это справедливо, когда обучаемая функция достаточно гладкая и ее изменение сосредоточено в небольшом числе измерений. В простран- стве высокой размерности даже очень гладкая функция может изменяться плавно, но по-разному вдоль каждого измерения. Если к тому же функция ведет себя различно\n--- Страница 146 ---\nПроблемы, требующие глубокого обучения  145 в разных областях, то обучить ее на наборе примеров может оказаться очень трудно. Если функция сложна (т. е. мы хотим различать гораздо больше областей, чем есть примеров), то есть ли надежда на хорошую обобщаемость? Ответ на оба вопроса – можно ли эффективно представить сложную функцию и может ли оцененная функция хорошо обобщаться на новые данные – положителен. Ключевая идея заключается в том, что очень большое число областей, порядка O(2k), можно определить с помощью O(k) примеров, если только мы введем некоторые зави- симости между областями посредством дополнительных предположений об истинном порождающем распределении. Таким образом, появляется возможность нелокального обобщения (Bengio and Monperrus, 2005; Bengio et al., 2006c). И чтобы воспользовать- ся ей, во многих алгоритмах глубокого обучения принимаются явные или неявные предположения, действительные для широкого круга задач ИИ. В других подходах к машинному обучению часто делаются еще более сильные, зависящие от задачи до- пущения. Например, задачу о шахматной доске было бы легко решить, предположив, что выходная функция периодическая. Обычно такие сильные предположения не включаются в нейронные сети, чтобы сохранить возможность обобщения на гораздо более широкий спектр структур. Структура задач ИИ слишком сложна, чтобы ограни-чиваться простыми, задаваемыми вручную свойствами типа периодичности, поэтому мы хотим, чтобы алгоритмы обучения основывались на более универсальных предпо-ложениях. Основная идея глубокого обучения состоит в том, что данные предположи- тельно были порождены композицией факторов, или признаков, возможно, организо- ванных иерархически. Есть много других не менее общих предположений, которые позволяют еще повысить качество алгоритмов глубокого обучения. Эти, на первый взгляд, скромные предположения позволяют добиться экспоненциального улучше-ния связи между числом примеров и числом различимых областей. Мы опишем этот экспоненциальный выигрыш более точно в разделах 6.4.1, 15.4 и 15.5. Экспоненциаль- ный выигрыш от применения глубоких распределенных представлений противостоит экспоненциальным проблемам, вызванным проклятием размерности. 5.11.3. Обучение многообразий В основе многих идей машинного обучения лежит концепция многообразия. Многообразие – это связная область. С точки зрения математики, это множество точек, ассоциированных с окрестностью каждой точки. Из любой точки многообра- зие локально выглядит как евклидово пространство. В повседневной жизни мы вос- принимаем поверхность земли как двумерную плоскость, но на самом деле это сфе-рическое многообразие в трехмерном пространстве. Из идеи окрестности каждой точки вытекает существование преобразований для перемещения из одного места многообразия в другое. В примере земной поверхности как многообразия мы можем пойти на север, юг, восток и запад. Хотя у термина «многообразие» есть строгое математическое определение, в ма- шинном обучении его используют менее формально для обозначения связного мно-жества точек в пространстве высокой размерности, которое можно хорошо аппрок- симировать, вводя в рассмотрение лишь небольшое число степеней свободы, или измерений. Каждое измерение соответствует локальному направлению изменения. На рис. 5.11 показан пример обучающих данных, лежащих в окрестности одномер- ного многообразия, погруженного в двумерное пространство. В машинном обучении допускаются многообразия, размерность которых различна в разных точках. Так ча-\n--- Страница 147 ---\n146  Основы машинного обучения сто бывает, когда у многообразия есть точки самопересечения. Например, цифра во- семь – это одномерное многообразие всюду, кроме точки самопересечения в центре. 2,5 2,0 1,51,0 0,5 0,0 –0,5–1,0 0,5 1,0 1,5 2,0 2,5 3,0 3,5 4,0 Рис. 5.11  Выборка данных в двумерном пространстве концентрирует- ся в окрестности одномерного многообразия и напоминает спутанную ве- ревку. Сплошной линией показано многообразие, которое требуется найти в процессе обучения Многие задачи машинного обучения кажутся безнадежными, если мы ожидаем, что в результате обучения алгоритм должен найти функции с нетривиальными из- менениями во всем пространстве ℝn. Алгоритмы обучения многообразий преодоле- вают это препятствие, предполагая, что большая часть ℝn – недопустимые входные данные, а интересные входы сосредоточены только в наборе многообразий, содержа- щем небольшое подмножество точек, причем интересные изменения результирую-щей обучен ной функции происходят только вдоль направлений, принадлежащих какому-то одному многообразию, или при переходе с одного многообразия на другое. Обучение многообразий зародилось при рассмотрении непрерывных данных в слу- чае обучения без учителя, хотя сама идея концентрации вероятности обобщается и на дискретные данные, и на обучение с учителем: ключевое допущение заключается в том, что масса вероятности сконцентрирована в малой области. Предположение о том, что данные расположены вдоль многообразия низкой раз- мерности, не всегда оказывается правильным или полезным. Мы утверждаем, что в задачах ИИ, в частности при обработке изображений, звука или текста, предполо- жение о многообразии, по крайней мере, приближенно правильно. В пользу этой ги- потезы можно привести наблюдения двух видов. Первое наблюдение в пользу гипотезы о многообразии заключается в том, что встречающееся в жизни распределение вероятности в изображениях, строках текс- та и звуковых фрагментах имеет высокую концентрацию. Равномерный шум почти никогда не походит на структурированные входные данные из этих предметных обла-стей. На рис. 5.12 показано, что равномерно распределенные точки выглядят как ста-тический шум на экране аналогового телевизора в отсутствие сигнала. Или, если мы будем генерировать документ, случайным образом выбирая буквы, то какова вероят-ность получить осмысленный текст на английском языке? Почти нулевая, потому что\n--- Страница 148 ---\nПроблемы, требующие глубокого обучения  147 большинство длинных последовательностей букв не соответствует последователь- ностям, встречающимся в естественном языке: распределение последовательностей естественного языка занимает лишь малый объем всего пространства последователь-ностей букв. Рис. 5.12  Результатом случайной выборки пикселей из равномерного распределения является белый шум. Хотя существует ненулевая вероят-ность сгенерировать таким образом изображение лица или иного объекта, встречающегося в приложениях ИИ, на практике такое не наблюдается. Это означает, что изображения, встречающиеся в приложениях ИИ, занимают пренебрежимо малую долю всего пространства изображений Конечно, концентрированного распределения вероятности еще недостаточно для доказательства того, что данные расположены на сравнительно небольшом числе многообразий. Нужно еще установить, что предъявленные примеры связаны между собой другими примерами, так что каждый пример окружен похожими на него и до\n--- Страница 149 ---\n148  Основы машинного обучения них можно добраться, применяя преобразования для перемещения по многообразию. Второй аргумент в пользу гипотезы о многообразии состоит в том, что, хотя бы не- формально, можно представить себе такие окрестности и такие преобразования. Если речь идет об изображениях, то, безусловно, можно придумать много преобразований, позволяющих перемещаться по многообразию в пространстве изображения: плавное ослабление или усиления освещения, плавный сдвиг или поворот объектов, плавное изменение цвета на поверхностях объектов и т. д. В большинстве приложений, скорее всего, будет присутствовать несколько многообразий. Например, многообразие чело-веческих лиц вряд ли связано с многообразием кошачьих мордочек. Эти мысленные эксперименты дают интуитивное обоснование гипотезы о много- образиях. Более строгие эксперименты (Cayton, 2005; Narayanan and Mitter, 2010; Schölkopf et al., 1998; Roweis and Saul, 2000; Tenenbaum et al., 2000; Brand, 2003; Belkin and Niyogi, 2003; Donoho and Grimes, 2003; Weinberger and Saul, 2004) со всей очевид-ностью поддерживают эту гипотезу для большого класса наборов данных, представ-ляющих интерес для ИИ. Если данные расположены на многообразии малой размерности, то в алгоритме машинного обучения их наиболее естественно представлять координатами на этом многообразии, а не в ℝ n. В быту мы рассматриваем дороги как одномерные много- образия, погруженные в трехмерное пространство. Желая сообщить адрес дома, мы указываем его номер относительно дороги, а не координаты в пространстве. Переход в систему координат многообразия – трудная задача, но ее решение обещает заметное улучшение многих алгоритмов машинного обучения. Этот общий принцип приме-ним в самых разных контекстах. На рис. 5.13 показана структура многообразия для набора данных о лицах. К концу книги мы разработаем методы, необходимые для обучения структуре такого многообразия. На рис. 20.6 будет показано, как алгоритм машинного обучения с успехом решает эту задачу. Рис. 5.13  Обучающие примеры из набора данных QMUL Multiview Face Dataset (Gong et al., 2000), при составлении которого людей просили по-зировать так, чтобы покрыть двумерное многообразие, соответствующее двум углам поворота. Мы хотели бы, чтобы алгоритмы обучения смогли вы-явить координаты на таком многообразии. На рис. 20.6 показан результат решения этой задачи На этом мы завершаем часть I, где были изложены основы математики и машинно- го обучения, применяемые в остальных частях книги. Теперь вы готовы приступить к изучению глубокого обучения.\n--- Страница 150 ---\nЧасть II ГЛУБОКИЕ СЕТИ: СОВРЕМЕННЫЕ ПОДХОДЫ В этой части книги описано современное состояние глубокого обучения – как оно применяется для решения практических задач. У машинного обучения долгая история и многочисленные притязания. Ряд под- ходов пока не принес желанных плодов. Некоторые амбициозные планы еще ждут своей реализации. Разговор об этих, не столь детально разработанных, разделах глу-бокого обучения мы отложим до третьей части книги. А в этой части сосредоточимся на тех подходах, которые доведены до уровня рабо- тающих технологий и широко применяются в промышленности. Современное глубокое обучение предлагает развитую инфраструктуру обучения с учителем. Благодаря добавлению дополнительных слоев и блоков в пределах од- ного слоя глубокая сеть может представлять все более и более сложные функции. Большинство задач, сводящихся к отображению входного вектора на выходной, с ко- торыми человек справляется легко и непринужденно, может быть решено методами глубокого обучения при наличии достаточно больших моделей и наборов помечен- ных примеров. Другие задачи, которые нельзя описать как ассоциирование одного вектора с другим, или настолько трудные, что человеку нужно время для их решения, пока не поддаются глубокому обучению. В этой части книги описаны базовые технологии аппроксимации параметрических функций, лежащие в основе почти всех практических приложений глубокого обуче- ния. Мы начнем с модели глубокой сети прямого распространения, используемой для представления таких функций. Затем мы представим передовые методы регуляриза-ции и оптимизации таких моделей. Для масштабирования моделей на большой объем входных данных, например на изображения высокого разрешения или на длинные вре-менные последовательности, необходима специализация. Мы познакомимся со свер-точной сетью, применяемой для масштабирования на большие изображения, и с рекур- рентной нейронной сетью для обработки временных последовательностей. Наконец, мы дадим общие рекомендации по практическому проектированию, построению и на- стройке приложений глубокого обучения и приведем обзор некоторых приложений. Эти главы наиболее интересны для специалистов-практиков – тех, кто хочет уже сегодня приступить к реализации и использованию алгоритмов глубокого обучения.",
      "debug": {
        "start_page": 97,
        "end_page": 150
      }
    },
    {
      "name": "Глава 6. Глубокие сети прямого распространения 150",
      "content": "--- Страница 151 --- (продолжение)\nГлава 6 Глубокие сети прямого распространения Глубокие сети прямого распространения, которые называют также нейронными сетями прямого распространения, или многослойными перцептронами (МСП), – самые типичные примеры моделей глубокого обучения. Цель сети прямого расп- рост ранения – аппроксимировать некоторую функцию f *. Например, в случае клас- сификатора y = f *(x) отображает вход x в категорию y. Сеть прямого распространения определяет отображение y = f(x; θ) и путем обучения находит значения параметров θ, дающие наилучшую аппроксимацию. Слова «прямое распространение» означают, что распространение информации начинается с x, проходит через промежуточные вычисления, необходимые для опре- деления f, и заканчивается выходом y. Не существует обратных связей, по которым выходы модели подаются на ее вход. Обобщенные нейронные сети, включающие та- кие обратные связи, называются рекуррентными и рассматриваются в главе 10. Сети прямого распространения исключительно важны для практического приме- нения машинного обучения. Они лежат в основе многих важных коммерческих при- ложений. Например, сверточные сети, используемые для распознавания объектов на фотографиях, – это частный случай сетей прямого распространения. Сети прямого распространения – концептуальная веха на пути к рекуррентным сетям, стоящим за многими приложениями в области естественных языков. Нейронные сети прямого распространения называются сетями, потому что они, как правило, образованы композицией многих различных функций. С моделью ас- социирован ориентированный ациклический граф, описывающий композицию. На-пример, можно связать три функции f (1), f(2) и f(3) в цепочку f(x) = f(3)(f(2)(f(1)(x))). Та- кие цепные структуры чаще всего используются в нейронных сетях. В данном случае f(1) называется первым слоем сети, f(2) – вторым слоем и т. д. Общая длина цепочки определяет глубину модели. Название «глубокое обучение» непосредственно связа- но с этой терминологией. Последний слой сети прямого распространения называется выходным. В ходе обучения нейронной сети мы стремимся приблизить f(x) к f *(x). Обучающие данные – это зашумленные приближенные примеры f *(x), вычисленные в различных точках. Каждый пример x сопровождается меткой y ≈ f *(x). Обучающие примеры напрямую указывают, что в выходном слое должно соответствовать каждой точке x, – это должно быть значение, близкое к y. Поведение остальных слоев на- прямую обучающими данными не определяется. Алгоритм обучения должен решить, как использовать эти слои для порождения желаемого выхода, но обучающие дан-\nГлава 6 Глубокие сети прямого распространения Глубокие сети прямого распространения, которые называют также нейронными сетями прямого распространения, или многослойными перцептронами (МСП), – самые типичные примеры моделей глубокого обучения. Цель сети прямого расп- рост ранения – аппроксимировать некоторую функцию f *. Например, в случае клас- сификатора y = f *(x) отображает вход x в категорию y. Сеть прямого распространения определяет отображение y = f(x; θ) и путем обучения находит значения параметров θ, дающие наилучшую аппроксимацию. Слова «прямое распространение» означают, что распространение информации начинается с x, проходит через промежуточные вычисления, необходимые для опре- деления f, и заканчивается выходом y. Не существует обратных связей, по которым выходы модели подаются на ее вход. Обобщенные нейронные сети, включающие та- кие обратные связи, называются рекуррентными и рассматриваются в главе 10. Сети прямого распространения исключительно важны для практического приме- нения машинного обучения. Они лежат в основе многих важных коммерческих при- ложений. Например, сверточные сети, используемые для распознавания объектов на фотографиях, – это частный случай сетей прямого распространения. Сети прямого распространения – концептуальная веха на пути к рекуррентным сетям, стоящим за многими приложениями в области естественных языков. Нейронные сети прямого распространения называются сетями, потому что они, как правило, образованы композицией многих различных функций. С моделью ас- социирован ориентированный ациклический граф, описывающий композицию. На-пример, можно связать три функции f (1), f(2) и f(3) в цепочку f(x) = f(3)(f(2)(f(1)(x))). Та- кие цепные структуры чаще всего используются в нейронных сетях. В данном случае f(1) называется первым слоем сети, f(2) – вторым слоем и т. д. Общая длина цепочки определяет глубину модели. Название «глубокое обучение» непосредственно связа- но с этой терминологией. Последний слой сети прямого распространения называется выходным. В ходе обучения нейронной сети мы стремимся приблизить f(x) к f *(x). Обучающие данные – это зашумленные приближенные примеры f *(x), вычисленные в различных точках. Каждый пример x сопровождается меткой y ≈ f *(x). Обучающие примеры напрямую указывают, что в выходном слое должно соответствовать каждой точке x, – это должно быть значение, близкое к y. Поведение остальных слоев на- прямую обучающими данными не определяется. Алгоритм обучения должен решить, как использовать эти слои для порождения желаемого выхода, но обучающие дан-\n--- Страница 152 ---\nПроблемы, требующие глубокого обучения  151 ные ничего не говорят о том, что должен делать каждый слой. Алгоритму обучения предстоит самостоятельно решить, как с помощью этих слоев добиться наилучшей аппроксимации f *. Поскольку обучающие данные не определяют выходов каждого из этих слоев, они называются скрытыми слоями. Наконец, сети называются нейронными, потому что их идея заимствована из ней- робиологии. Каждый скрытый слой сети обычно вырабатывает векторные значения. Размерность скрытых слоев определяет ширину модели. Каждый элемент вектора можно интерпретировать как нейрон. Вместо того чтобы рассматривать слой как пред-ставление функции с векторными аргументами и векторными значениями, мы можем считать, что слой состоит из многих блоков, работающих параллельно, и что каждый такой блок представляет функцию, отображающую вектор в скаляр. Каждый блок на- поминает нейрон в том смысле, что получает данные от многих других блоков и вычис- ляет собственное значение активации. Идея использования многих слоев векторных представлений пришла из нейробиологии. Выбор функций f (i)(x), используемых для вычисления этих представлений, также изначально навеян экспериментально полу-ченными фактами о функциях, вычисляемых биологическими нейронами. Но в осно- ве современных исследований по нейронным сетям лежат математика и инженерные дисциплины, а перед нейронной сетью не ставится цели точно смоделировать работу мозга. Лучше рассматривать сети прямого распространения не как модели функцио-нирования мозга, а как машины для аппроксимации функций, спроектированные с целью статистического обобщения и иногда использующие наши знания о мозге. Один из способов разобраться в сетях прямого распространения состоит в том, чтобы начать с линейных моделей и подумать, как преодолеть их ограничения. Ли- нейные модели, в т. ч. логистическая регрессия и линейная регрессия, так привлека- тельны, потому что дают эффективную и надежную аппроксимацию – в замкнутой форме или посредством выпуклой оптимизации. Но у линейных моделей есть оче- видный недостаток – емкость модели ограничена линейными функциями, поэтому модель неспособна понять произвольную связь между двумя величинами. Чтобы обобщить линейную модель на представление нелинейных функций от x, мы можем применить ее не к самому x, а к результату вычисления ϕ(x), где ϕ – не- линейное преобразование. Или, что то же самое, применить трюк с ядром, описанный в разделе 5.7.2, для получения нелинейного алгоритма обучения, основанного на не- явном применении преобразования ϕ. Можно считать, что ϕ дает набор признаков, описывающих x, или новое представление x. Тогда вопрос сводится к выбору отображения ϕ.1. Один из вариантов – взять очень общее ϕ, например бесконечномерное, неяв- но используемое в ядерных методах, основанных на радиально-базисном ядре. Если размерность ϕ(x) достаточна велика, то емкости модели хватит для ап- проксимации обучающего набора, но обобщаемость на тестовый часто оставля-ет желать лучшего. Очень общие отображения признаков обычно основаны на принципе локальной гладкости, и закодированной в них априорной информа- ции недостаточно для решения сложных задач. 2. Другой вариант – спроектировать ϕ вручную. До наступления эры глубокого обучения так в основном и поступали. Но для каждой задачи требуются деся- тилетия человеческого труда и специалисты в соответствующей предметной области, например распознавания речи или компьютерного зрения, а передачи знаний между разными областями почти нет.\n--- Страница 153 ---\n152  Г лубокие сети прямого распространения 3. Стратегия глубокого обучения состоит в обучении ϕ. При таком подходе име- ется модель y = f(x; θ, w) = ϕ(x; θ)⏉w. Теперь у нас есть параметры θ, используе- мые для обучения ϕ, выбираемой из широкого класса функций, и параметры w, отображающие ϕ(x) в желаемый выход. Это пример глубокой сети прямого распространения, где ϕ определяет скрытый слой. Это единственный из трех подходов, который порывает с предположением о выпуклости задачи обучения, но его достоинства перевешивают недостатки. В этом случае мы параметризуем представление в виде ϕ(x; θ) и применяем алгоритм оптимизации для нахожде- ния отображения ϕ, которому соответствует хорошее представление. Если мы пожелаем, то у этого подхода будут все преимущества общности первого – для этого нужно только взять очень широкое семейство функций ϕ(x; θ). Глубокое обучение может также воспользоваться достоинствами второго подхода. Ис- следователь может включить в модель свои знания, спроектировав семейство функций, которое, по его мнению, должно хорошо обобщаться. Преимущество в том, что человеку нужно только отыскать подходящее семейство функций, а не одну конкретную функцию. Общий принцип улучшения моделей путем обучения признаков выходит за рамки описываемых в этой главе сетей прямого распространения. Эта тема снова и снова возникает в глубоком обучении и относится ко всем видам моделей, рассматривае- мым в книге. Сети прямого распространения – применение этого принципа к обуче- нию детерминированных отображений x в y без обратных связей. Ниже будут представлены другие модели, в которых тот же принцип применяется к обучению стохастических отображений, функций с обратной связью и распределений вероят- ности одиночного вектора. Мы начнем эту главу с простого примера сети прямого распространения. Затем мы рассмотрим все проектные решения, принимаемые при развертывании таких сетей. Во-первых, при обучении сети прямого распространения приходится думать о тех же вещах, что для линейных моделей: выборе оптимизатора, функции стоимости и вида выходных блоков. Мы рассмотрим эти основы градиентного обучения, а затем пе- рейдем к решениям, характерным только для сетей прямого распространения. По- скольку в таких сетях есть скрытые слои, то мы должны выбрать функции активации, используемые для вычисления вырабатываемых ими значений. Кроме того, нужно спроектировать архитектуру сети: сколько в ней скрытых слоев, как эти слои связаны между собой, сколько блоков в каждом слое. Обучение в контексте глубоких ней- ронных сетей подразумевает вычисление градиентов сложных функций. Мы опишем алгоритм обратного распространения и его современные реализации, позволяющие эффективно вычислять градиенты. И завершим главу историческим обзором. 6.1. Пример: обучение XOR Чтобы наполнить конкретикой понятие сети прямого распространения, рассмотрим полный пример сети, решающей очень простую задачу: обучение функции XOR. Функция XOR (исключающее ИЛИ) применяется к двум двоичным значениям, x 1 и x2. Если ровно одно из них равно 1, то XOR возвращает 1, во всех остальных случаях – 0. Функция XOR является целевой функцией y = f *(x), которую мы хотим обучить. Наша модель описывает функцию y = f(x; θ), а алгоритм обучения должен подобрать параметры θ, так чтобы f была максимально похожа на f *.\n--- Страница 154 ---\nПример: обучение XOR  153 В этом простом примере нас не интересует статистическое обобщение. Мы хотим, чтобы сеть правильно работала на четырех точках 𝕏 = {[0, 0]⏉, [0, 1]⏉, [1, 0]⏉, [1, 1]⏉}, и будем обучать ее на всех этих точках. Единственная проблема – аппроксимировать обучать набор. Эту проблему можно рассматривать как задачу регрессии и использовать средне- квадратическую функцию потерь. Мы выбрали такую функцию потерь, чтобы мак- симально упростить математические выкладки. На практике среднеквадратическая ошибка (СКО) редко подходит для моделирования двоичных данных. Более разум-ные подходы описаны в разделе 6.2.2.2. Вычисленная на всем обучающем наборе среднеквадратическая функция потерь имеет вид: (6.1) Теперь нужно выбрать форму модели f(x; θ). Допустим, что выбирается линейная модель, в которой θ состоит из параметров w и b: f(x; w , b) = x⏉w + b . (6.2) Мы можем минимизировать J(θ) относительно w и b в замкнутой форме с по- мощью нормальных уравнений. Решив нормальные уравнения, получаем w = 0, b = 1/2. Линейная модель просто порождает постоянное выходное значение 0.5. Почему так? По рис. 6.1 видно, что ли-нейная модель не способна представить функцию XOR. Чтобы решить эту проблему, мы можем взять другое пространство признаков, в котором линейной модели будет уже достаточно для представления решения. Конкретно, рассмотрим простую сеть прямого распространения с одним скрытым слоем, содержащим два скрытых блока. Она показана на рис. 6.2. В этой модели имеет- ся вектор скрытых блоков h, вычисляемых функцией f (1)(x; W, c). Значения скрытых блоков служат входами для второго слоя, который одновременно является выходным слоем сети. Выходной слой – это просто модель линейной регрессии, но применяется она к h, а не к x. Теперь сеть содержит две функции, h = f (1)(x; W, c) и y = f(2)(h; w, b), а полная модель образована их композицией f(x; W, c, w, b) = f(2)(f(1)(x)). Что должна вычислять функция f(1)? До сих пор линейные модели служили нам ве- рой и правдой, поэтому велико искушение сделать f(1) линейной. К сожалению, если бы f(1) была линейной, то и вся сеть прямого распространения оказалась бы линей- ной функцией входа. Забудем ненадолго про свободные члены и предположим, что f(1)(x) = W⏉x, f(2)(h) = h⏉w. Тогда f(x) = w⏉W⏉x. Эту функцию можно представить в виде f(x) = x⏉w′, где w′ = Ww . Очевидно, что для описания признаков нужна нелинейная функция. В большинстве нейронных сетей используют композицию аффинного преобразования с обучен ными параметрами и фиксированной нелинейной функции активации. Воспользуемся этой стратегией и мы, положив h = g(W⏉x + c), где W – веса линейного преобразования, а c – смещения. Ранее в модели линейной регрессии мы использовали веса и скаляр- ный параметр смещения для описания аффинного преобразования входного вектора в выходной скаляр. Теперь же мы описываем аффинное преобразование вектора x в вектор h, поэтому смещение должно быть вектором. В качестве функции активации обычно берут функцию, применяемую к каждому элементу: h i = g(x⏉W:, i + ci). В со-\n--- Страница 155 ---\n154  Г лубокие сети прямого распространения временных нейронных сетях по умолчанию рекомендуют использовать блок линей- ной ректификации (rectified linear unit – ReLU) (Jarrett et al., 2009; Nair and Hinton, 2010; Glorot et al., 2011a), определяемый функцией активации g(z) = max{0, z}, кото- рая изобра жена на рис. 6.3. Пространство входов xПространство обученных параметров h 1 1 11 0 0 00х2 х2 х1 х1 Рис. 6.1  Решение задачи о функции XOR путем обучения представле- ния. Жирными цифрами обозначены значения, которые обученная функция должна вывести в каждой точке. (Слева) Линейная модель, применяемая непосредственно к входным данным, неспособна реализовать функцию XOR. При x1 = 0 выход модели должен возрастать с ростом x2. При x1 = 1 вы- ход модели должен убывать с ростом x2. В линейной модели должен быть фиксированный коэффициент между w2 и x2. Поэтому линейная модель не может использовать значение x1 для изменения коэффициента при x2 и, стало быть, не в состоянии решить задачу. (Справа) В преобразованном пространстве признаков, выделяемых нейронной сетью, линейная модель может решить задачу. В нашем случае обе точки, которые должны выводить 1, схлопнуты в одну точку пространства признаков. Иными словами, нели- нейное преобразование отображает точки x = [1, 0] ⏉ и x = [0, 1]⏉ в одну точку пространства признаков h = [1, 0]⏉. Теперь линейная модель может описать функцию, возрастающую относительно h1 и убывающую относительно h2. В этом примере причиной для обучения в пространстве признаков было всего лишь желание увеличить емкость модели, так чтобы она могла ап- проксимировать обучающий набор. В реальных приложениях обученное та- ким образом представление способствует лучшей обобщаемости модели Теперь можно определить всю сеть целиком: f(x; W, c, w, b) = w⏉ max{0, W⏉x + c} + b. (6.3) Теперь мы можем описать решение задачи о функции XOR. Обозначим (6.4) (6.5) (6.6) и положим b = 0.\n--- Страница 156 ---\nПример: обучение XOR  155 y h1 x1h2 x2y h xw W Рис. 6.2  Пример сети обратного распространения, нарисованной дву- мя способами. Это та сеть, которой мы воспользовались для решения зада- чи о функции XOR. В сети имеется скрытый слой с двумя блоками. (Слева) Здесь каждый блок представлен вершиной графа. Этот способ явный и од- нозначный, но когда сеть побольше, чем в этом примере, рисунок занимает слишком много места. (Справа) В этом случае вершина графа соответству- ет целому вектору, представляющему все активации в слое. Такой способ гораздо компактнее. Иногда ребра графа аннотируются именами парамет-ров, описывающих связь между двумя слоями. Здесь мы указали, что мат-рица W описывает отображение x в h, а вектор w – отображение h в y. Как правило, свободные члены для каждого слоя в таких метках опускаются. 00 zg(z) = max{0, z} Рис. 6.3  Ректифицированная линейная функция активации. Эта функ- ция по умолчанию рекомендуется для большинства нейронных сетей пря-мого распространения. Применение ее к выходу линейного преобразова- ния дает нелинейное преобразование. Функция, впрочем, очень близка к линейной – она является кусочно-линейной с двумя линейными участка- ми. Поскольку блоки линейной ректификации почти линейны, сохраняются многие свойства, благодаря которым линейные модели легко поддаются оптимизации градиентными методами. Сохраняются также свойства, обес-печивающие хорошую обобщаемость линейных моделей. Общий принцип информатики – строить сложные системы из минимальных компонентов. От памяти машины Тьюринга требуется только способность хранить нуль и единицу, а универсальный аппроксиматор можно построить из ректифи- цированных линейных функций\n--- Страница 157 ---\n156  Г лубокие сети прямого распространения Посмотрим по шагам, как модель обрабатывает входные данные. Обозначим X матрицу плана, содержащую все четыре точки в пространстве двоичных входов, по одному примеру в строке: (6.7) Первый шаг нейронной сети – умножение матрицы входов на матрицу весов пер- вого слоя: (6.8) Затем она прибавляет вектор смещений c, получая в результате (6.9) В этом пространстве все примеры расположены на прямой с угловым коэффици- ентом 1. При движении вдоль этой прямой выход вначале должен быть равен 0, затем поднимается до 1, потом снова падает до 0. Линейная модель такую функцию реали-зовать не может. Чтобы завершить вычисление h для каждого примера, применим преобразование линейной ректификации: (6.10) Это преобразование изменило соотношение между примерами. Они больше не ле- жат на одной прямой. Как видно по рис. 6.1, теперь они расположены в пространстве, где линейная модель может решить задачу. В завершение умножаем на вектор весов w: (6.11) Нейронная сеть получила правильный ответ для каждого входного примера.В этом примере мы просто задали решение, а затем показали, что его можно по- лучить с нулевой ошибкой. В реальной ситуации количество параметров модели\n--- Страница 158 ---\nОбучение градиентными методами  157 и обучаю щих примеров может исчисляться миллиардами, поэтому заранее угадать решение невозможно. Вместо этого применяется алгоритм градиентной оптимиза- ции, который способен найти параметры с очень небольшой ошибкой. Описанное ре- шение задачи о XOR соответствует глобальному минимуму функции потерь, поэтому метод градиентного спуска мог бы сойтись к нему. Существуют эквивалентные реше- ния этой задачи, которые также могли бы быть найдены градиентным спуском. К ка- кой точке сойдется градиентный спуск, зависит от начальных значений параметров. На практике градиентный спуск обычно находит не такие «чистые», целочисленные, с первого взгляда понятные решения, как описанное в этом разделе. 6.2. Обучение градиентными методами Проектирование и обучение нейронной сети мало отличается от обучения любой другой модели методом градиентного спуска. В разделе 5.10 мы описали, как постро- ить алгоритм машинного обучения путем задания процедуры оптимизации, функции стоимости и семейства моделей. Основное различие между линейными моделями, встречавшимися нам до сих пор, и нейронными сетями состоит в том, что из-за нелинейности нейронной сети большинство интересных функций потерь оказывается невыпуклыми. Это озна-чает, что нейронные сети обычно обучаются с помощью итеративных градиентных оптимизаторов, которые просто находят очень малое значение функции стоимости, а не с помощью методов решения линейных уравнений, применяемых при обучении моделей регрессии, или алгоритмов выпуклой оптимизации, гарантированно сходя-щихся к глобальному оптимуму, которые используются при обучении логистической регрессии или модели опорных векторов. Алгоритм выпуклой оптимизации сходится при любых начальных параметрах (теоретически на практике он устойчивый, но мо-жет столкнуться с численными проблемами). Метод стохастического градиентного спуска, применяемый к невыпуклым функциям потерь, не дает таких гарантий схо- димости и чувствителен к начальным значениям параметров. Для нейронных сетей прямого распространения важно инициализировать все веса небольшими случай-ными значениями. Смещения можно инициализировать нулями или небольшими положительными значениями. Итеративные алгоритмы градиентной оптимизации, применяемые для обучения сетей прямого распространения и почти всех прочих глу- боких моделей, подробно описаны в главе 8, а инициализация параметров обсужда- ется в разделе 8.4. Пока достаточно понимать, что алгоритм обучения почти всегда основан на использовании градиентного спуска для минимизации функции стоимо-сти тем или иным способом. Конкретные алгоритмы являются улучшением и уточ- нением идей градиентного спуска, описанных в разделе 4.3, а чаще всего алгоритма стохастического градиентного спуска из раздела 5.9. Мы, конечно, можем обучать методом градиентного спуска и такие модели, как линейная регрессия и опорные векторы, и так действительно делают, когда обучаю- щий набор очень велик. С этой точки зрения, обучение нейронной сети не сильно отличается от обучения любой другой модели. Для нейронной сети вычисление гра-диента несколько сложнее, но все равно его можно выполнить эффективно и точно. В разделе 6.5 мы опишем, как найти градиент с помощью алгоритма обратного рас- пространения и его современных модификаций. Как и для других моделей машинного обучения, для применения обучения на ос- нове градиента нужно выбрать функцию стоимости и способ представления выхода\n--- Страница 159 ---\n158  Г лубокие сети прямого распространения модели. Давайте вернемся к проектным соображениям, уделив особое внимание слу- чаю нейронных сетей. 6.2.1. Функции стоимости Важный аспект проектирования глубокой нейронной сети – выбор функции стоимо- сти. По счастью, функции стоимости для нейронных сетей мало отличаются от при- меняемых в других параметрических моделях, в т. ч. линейных. В большинстве случаев параметрическая модель определяет распределение p(y | x; θ), и мы должны просто воспользоваться принципом максимального правдо- подобия. Это означает, что в роли функции стоимости выступает перекрестная энтро- пия между обучающими данными и предсказаниями модели. Иногда принимается более простой подход: вместо предсказания полного распре- деления вероятности y мы предсказываем какую-то статистику y при условии x. Спе- циализированные функции потерь позволяют обучать предиктор таких оценок. Полная функция стоимости, применяемая при обучении нейронной сети, часто является комбинацией одной из основных функций стоимости, описанных ниже, с регуляризирующим членом. Мы уже встречались с простыми примерами регуля- ризации в применении к линейным моделям в разделе 5.2.2. Снижение весов, исполь- зуемое в линейных моделях, безо всяких изменений применимо и к глубоким нейрон- ным сетям и является одной из самых популярных стратегий регуляризации. Более сложные стратегии регуляризации нейронных сетей описаны в главе 7. 6.2.1.1. Обучение условных распределений с помощью максимального правдоподобия Большинство современных нейронных сетей обучается с помощью максимального правдоподобия. Это означает, что в качестве функции стоимости берется отрица- тельное логарифмическое правдоподобие, которое можно эквивалентно описать как перекрестную энтропию между обучающими данными и распределением модели. Эта функция задается формулой J(θ) = –𝔼 x, y∼p �data log pmodel(y | x). (6.12) Конкретная форма функции стоимости изменяется от модели к модели в зависи- мости от формы log pmodel. Раскрытие этой формулы обычно дает члены, которые не зависят от параметров модели и могут быть отброшены. Например, в разделе 5.5.1 мы видели, что если pmodel(y | x) = 𝒩(y; f(x; θ), I), то можно свести стоимость к среднеквад- ратической ошибке J(θ) = 1/2𝔼x, y∼p �data||y – f(x; θ)||2 + const (6.13) с точностью до масштабного коэффициента 1/2 и члена, не зависящего от θ. Отбро- шенная константа включает дисперсию нормального распределения, которую мы в данном случае решили не делать параметром. Ранее мы видели, что для линейной модели имеет место эквивалентность между оценкой максимального правдоподобия выходного распределения и минимизацией среднеквадратической ошибки, но на са- мом деле эта эквивалентность не зависит от функции f(x; θ), используемой для пред- сказания среднего значения нормального распределения. Преимущество такого подхода – вывода функции стоимости из оценки максималь- ного правдоподобия – в том, что отпадает необходимость проектировать функцию\n--- Страница 160 ---\nОбучение градиентными методами  159 стоимости заново для каждой модели. Задание модельного распределения p(y | x) ав- томатически определяет функцию стоимости log p(y | x). При проектировании нейронной сети вновь и вновь всплывает одна и та же проб- лема: если мы хотим использовать градиент функции стоимости для управления ал- горитмом обучения, то он должен быть большим и достаточно предсказуемым. Функ- ции с насыщением (становящиеся очень плоскими) не отвечают этому требованию, потому что градиент становится очень малым. Во многих случаях это происходит, потому что функции активации, применяемые для порождения выхода скрытых или выходных блоков, асимптотически горизонтальны. Для многих моделей отрицатель-ное логарифмическое правдоподобие позволяет избежать этой проблемы. Логарифм, входящий в эту функцию стоимости, компенсирует экспоненциальный характер не- которых выходных блоков. Мы обсудим связь между функцией стоимости и выбо- ром выходного блока в разделе 6.2.2. Одно необычное свойство перекрестной энтропии, используемой при вычислении оценки максимального правдоподобия, заключается в том, что для типичных встре- чающихся на практике моделей у нее, как правило, нет минимального значения. Если выходная величина дискретна, то в большинстве моделей параметризация устроена так, что модель неспособна представить вероятность 0 или 1, но может подойти к ней сколь угодно близко. Примером может служить логистическая регрессия. В случае вещественных выходных величин, если модель может управлять плотностью выход-ного распределения (например, путем обучения параметра дисперсии нормального выходного распределения), становится возможным назначение очень высокой плот-ности правильным выходам обучающего набора, и тогда перекрестная энтропия стре- мится к отрицательной бесконечности. Методы регуляризации, описанные в главе 7, предлагают еще несколько способов модифицировать задачу обучения, так чтобы мо-дель не смогла таким образом получить неограниченное поощрение. 6.2.1.2. Обучение условных статистик Вместо обучения полного распределения вероятности p(y | x; θ) мы часто хотим обучить только одну условную статистику y при заданном x. Например, возможно, мы хотим использовать некоторый предиктор f(x; θ) для предсказания среднего значения y. Если нейронная сеть достаточно мощная, то можно считать, что она в состоянии представить любую функцию f из широкого класса функций, связанного только та- кими условиями, как непрерывность и ограниченность, а не конкретной параметри- ческой формой. В таком случае функцию стоимости можно рассматривать как функ- ционал, а не просто функцию. Функционалом называется отображение множества функций во множество вещественных чисел. Процесс обучения можно рассматри-вать как выбор функции, а не набора параметров. Можно спроектировать функцио- нал стоимости, так чтобы он принимал минимум в некоторой желательной для нас функции, например так чтобы минимум достигался в функции, которая отобража- ет x на ожидаемое значение y при заданном x. Для решения задачи оптимизации на множестве функций имеется специальный математический аппарат – вариационное исчисление, описываемый в разделе 19.4.2. Для понимания материала этой главы знакомство с вариационным исчислением необязательно. Пока что достаточно по- нимать, что вариационное исчисление можно использовать для вывода двух сформу-лированных ниже результатов.\n--- Страница 161 ---\n160  Г лубокие сети прямого распространения Первый результат заключается в том, что решение задачи оптимизации f * = 𝔼x, y∼pdata||y – f(x)||2 (6.14) имеет вид f *(x) = 𝔼y∼pdata(y|x)[y] (6.15) при условии, что эта функция принадлежит классу, по которому мы производим оп- тимизацию. Иными словами, если бы мы могли обучать на бесконечно большом ко-личестве примеров, выбранных из истинного порождающего распределения данных, то минимизация среднеквадратической ошибки дала бы функцию, которая предска-зывает среднее значение y для каждого значения x. Разные функции стоимости дают разные статистики. Второй результат примене- ния вариационного исчисления состоит в том, что уравнение f * = 𝔼x, y∼pdata|| y – f(x)||1 (6.16) описывает функцию, которая предсказывает медианное значение y для каждого x, при условии что такую функцию можно описать семейством функций, по которому производится оптимизация. Эта функция стоимости обычно называется средней аб- солютной ошибкой. К сожалению, среднеквадратическая ошибка и средняя абсолютная ошибка часто дают плохие результаты в сочетании с градиентной оптимизацией. Некоторые выход- ные блоки с насыщением при использовании таких функций стоимости имеют очень малые градиенты. И это одна из причин, почему перекрестная энтропия в качестве функции стоимости более популярна, чем среднеквадратическая ошибка и средняя абсолютная ошибка, даже в тех случаях, когда нет необходимости оценивать все рас- пределение p(y | x). 6.2.2. Выходные блоки Выбор функции стоимости тесно связан с выбором выходного блока. Как правило, мы просто используем перекрестную энтропию между распределением данных и мо- дельным распределением. Выбор представления выхода определяет форму функции перекрестной энтропии. Любой блок нейронной сети, который можно использовать в качестве выходного, годится и на роль скрытого. Сейчас нас больше интересуют выходные блоки модели, но, в принципе, их можно использовать и во внутренних слоях. Мы еще вернемся к вопросу о скрытых блоках в разделе 6.3. В этом разделе мы предполагаем, что сеть прямого распространения содержит мно- жество скрытых признаков, описываемое функцией h = f(x; θ). Тогда роль выходного слоя состоит в том, чтобы предоставить дополнительную информацию, почерпнутую из признаков, для решения задачи, стоящей перед сетью. 6.2.2.1. Линейные блоки для нормальных выходных распределений Простой выходной блок основан на аффинном преобразовании без нелинейностей. Часто такие блоки называются просто линейными. Если обозначить признаки h, то слой линейных выходных блоков порождает век- тор y � = W ⏉h + b.\n--- Страница 162 ---\nОбучение градиентными методами  161 Линейные выходные слои часто применяются для порождения среднего условного нормального распределения: p(y | x) = 𝒩(y; y �, I). (6.17) Тогда максимизация логарифмического правдоподобия эквивалентна минимиза- ции среднеквадратической ошибки. Схема на основе максимального правдоподобия позволяет также упростить обуче- ние ковариации нормального распределения или сделать ковариацию функцией вхо- да. Однако на ковариационную матрицу необходимо наложить ограничение – она должна быть положительно определенной для всех входов. Удовлетворить такому ограничению с помощью линейного выходного слоя трудно, поэтому обычно для па- раметризации ковариации используются другие выходные блоки. Подходы к моде- лированию ковариации кратко описаны в разделе 6.2.2.4. Поскольку линейные блоки не подвержены насыщению, они не представляют осо- бых проблем для алгоритмов градиентной оптимизации и могут использоваться с са- мыми разными алгоритмами оптимизации. 6.2.2.2. Сигмоидные блоки и выходное распределение Бернулли Во многих задачах требуется предсказать значение бинарной величины y. В таком виде можно представить задачу классификации с двумя классами. Подход на основе максимального правдоподобия заключается в определении рас- пределения Бернулли величины y при условии x. У распределения Бернулли всего один числовой параметр. Нейронная сеть должна предсказать только P(y = 1 | x). Чтобы эта величина могла интерпретироваться как вероятность, она должна принадлежать отрезку [0, 1]. Для удовлетворения этого условия нужно тщательное проектирование. Допустим, что имеется линейный блок, и обрежем его сверху и снизу, чтобы получить допусти- мое значение вероятности. P(y = 1 | x) = max{0, min{1, w⏉h + b}}. (6.18) Эта формула действительно определяет корректное условное распределение, но эффективно обучить его методом градиентного спуска не получится. Всякий раз, как w ⏉h + b выходит за пределы единичного отрезка, градиент выхода модели от- носительно ее параметров будет равен 0. Градиент 0 обычно приводит к проблемам, потому что у алгоритма обучения нет никаких указаний на то, как улучшить пара- метры. Лучше применить другой подход, который гарантирует, что градиент обязательно будет достаточно большим, если модель дает неверный ответ. Этот подход основан на использовании сигмоидных выходных блоков в сочетании с максимальным прав- доподобием. Сигмоидный выходной блок определяется формулой y� = σ(w ⏉h + b), (6.19) где σ – логистическая сигмоида, описанная в разделе 3.10. Можно считать, что сигмоидный выходной блок состоит из двух компонентов. Во- первых, в нем есть линейный слой, вычисляющий z = w⏉h + b, а во-вторых, сигмоид- ная функция активации, преобразующая z в вероятность.\n--- Страница 163 ---\n162  Г лубокие сети прямого распространения На время забудем о зависимости от x и обсудим, как определить распределение вероятности y, используя значение z. Применение сигмоиды оправдывается возмож- ностью получить ненормированное распределение вероятности P~(y), сумма которого не равна 1. Затем мы делим на подходящую константу, чтобы получить правильное распределение вероятности. Если начать с предположения, что логарифм ненорми- рованных вероятностей линейно зависит от y и z, то можно выполнить потенцирова- ние и получить сами ненормированные вероятности. После нормировки получается распределение Бернулли, управляемое сигмоидным преобразованием z: logP~(y) = yz, (6.20) P~(y) = exp(yz), (6.21) (6.22) P(y) = σ((2y – 1)z). (6.23) Распределения вероятности, основанные на потенцировании и нормировке, часто встречаются в литературе по статистическому моделированию. Переменная z, опре- деляющая такое распределение бинарных величин, называется логит. Этот подход к предсказанию вероятностей в логарифмическом пространстве есте- ственно использовать в сочетании с обучением на основе максимального правдопо- добия. Поскольку в этом случае используется функция стоимости –log P(y | x), вхо- дящий в нее логарифм компенсирует экспоненту в сигмоиде. Не будь этого эффекта, насыщение сигмоиды могло бы помешать градиентному обучению. Функция потерь для обучения параметризованного сигмоидой распределения Бернулли методом максимального правдоподобия имеет вид: J(θ) = –log P(y | x) (6.24) = –log σ ((2y – 1)z) (6.25) = ζ ((1 – 2y)z). (6.26) При выводе использованы некоторые свойства из раздела 3.10. Записав поте- ри в терминах функции softplus, мы видим, что насыщение наступает, только ког- да (1 – 2y)z принимает большое по абсолютной величине отрицательное значение. Поэтому насыщение имеет место тогда, когда модель уже получила правильный от-вет – когда y = 1 и z положительно и очень велико или когда y = 0 и z отрицательно и очень велико по абсолютной величине. Если знак z не тот, то аргумент функции softplus, (1 – 2y)z можно упростить до | z|. Когда | z| растет при несоответствующем знаке z, функция softplus асимптотически приближается к функции, возвращающей свой аргумент, | z|. Производная по z асимптотически приближается к sign(z), поэтому в пределе – когда z совершенно неправильно – функция softplus вообще не сжимает градиент. Это свойство полезно, потому что означает, что обучение градиентными методами может быстро действовать в направлении быстрого исправления ошибоч- ного z. При использовании других функций потерь, например среднеквадратической ошибки, потеря может достигать насыщения одновременно с насыщением σ(z). Сиг- моидная функция активации асимптотически стремится к 0, когда z стремится к ми- нус бесконечности, и к 1, когда z стремится к бесконечности. При таких условиях\n--- Страница 164 ---\nОбучение градиентными методами  163 сжатие градиента слишком мало и для обучения бесполезно вне зависимости от того, дает модель правильный или неправильный ответ. Поэтому максимальное правдопо- добие почти всегда является предпочтительным подходом к обучению сигмоидных выходных блоков. Аналитически логарифм сигмоиды всегда определен и конечен, поскольку сиг- моида возвращает значения из открытого интервала (0, 1), а не из всего замкнутого диапазона допустимых вероятностей [0, 1]. Но в программных реализациях во из- бежание проблем с численной неустойчивостью лучше записывать отрицательное логарифмическое правдоподобие в виде функции от z, а не от y� = σ(z). Если из-за потери значимости сигмоида обращается в 0, то взятие логарифма y� дает минус бес- конечность. 6.2.2.3. Блоки softmax и категориальное выходное распределение Если требуется представить распределение вероятности дискретной величины, при-нимающей n значений, то можно воспользоваться функцией softmax. Ее можно рас- сматривать как обобщение сигмоиды, которая использовалась для представления распределения бинарной величины. Функция softmax чаще всего используется как выход классификатора для пред- ставления распределения вероятности n классов. Реже функция softmax использует- ся внутри самой модели, когда мы хотим, чтобы модель выбрала один из n вариантов какой-то внутренней переменной. В случае бинарных величин требовалось породить одно число y� = P(y = 1 | x). (6.27) Поскольку это число должно было находиться между 0 и 1 и поскольку мы хотели, чтобы его логарифм хорошо вел себя при градиентной оптимизации логарифмиче- ского правдоподобия, мы решили вместо него порождать число z = logP~(y = 1 | x). Потенцирование и нормировка дали нам распределение Бернулли, управляемое сиг- моидной функцией. Чтобы обобщить это на случай дискретной случайной величины с n значениями, мы должны породить вектор y�, для которого y� i = P(y = i | x). Мы требуем не только, чтобы каждый элемент y�i находился между 0 и 1, но и чтобы сумма всех элементов была равна 1 и таким образом представляла корректное распределение вероятности. Подход, который работает для распределения Бернулли, обобщается и на категори- альное распределение. Сначала линейный слой предсказывает ненормированные ло-гарифмы вероятностей: z = W ⏉h + b, (6.28) где zi = logP~(y = i | x). Функция softmax может затем потенцировать и нормировать z для получения желаемого y�. Формально функция softmax определяется следующим образом: (6.29) Как и в случае логистической сигмоиды, использование функции exp дает хоро- шие результаты при обучении softmax с целью порождения выходного значения y\n--- Страница 165 ---\n164  Г лубокие сети прямого распространения с применением логарифмического правдоподобия. В этом случае мы хотим максими- зировать log P(y = i; z) = log softmax(z)i. Определение softmax через exp естественно, потому что логарифм, входящий в логарифмическое правдоподобие, компенсирует потенцирование в softmax: (6.30) Первый член в выражении (6.30) показывает, что вход zi дает прямой вклад в функ- цию стоимости. Поскольку этот член не испытывает насыщения, то обучение всегда может продолжиться, даже если вклад zi во второй член становится очень мал. При максимизации логарифмического правдоподобия первый член поощряет увеличение z i, а второй – уменьшение всех элементов z. Чтобы составить интуитивное представ- ление о втором члене log Σj exp(zj), заметим, что его можно грубо аппроксимировать величиной maxj zj. В основе такой аппроксимации лежит то соображение, что exp(zk) несущественно для любого zk, значительно меньшего, чем maxj zj. Отсюда следует, что отрицательное логарифмическое правдоподобие в роли функции стоимости всегда сильнее штрафует самое активное неправильное предсказание. Если правильный от-вет уже дает самого большого вклада в softmax, то члены –z i и log Σj exp(zj) ≈ maxj zj = zi приблизительно взаимно уничтожаются. Такой пример, следовательно, даст малый вклад в общую стоимость обучения, в которой будут преобладать другие примеры, пока еще классифицированные неправильно. До сих пор мы обсуждали только один пример. В целом нерегуляризованное мак- симальное правдоподобие побуждает модель обучать параметры, при которых soft-max предсказывает долю наблюдений каждого исхода в обучающем наборе: (6.31) Поскольку максимальное правдоподобие – состоятельная оценка, это гаранти- рованно произойдет при условии, что модельное семейство способно представить обучаю щее распределение. На практике из-за ограниченной емкости и несовершен- ной оптимизации модель способна только аппроксимировать эти доли. Многие целевые функции, отличные от логарифмического правдоподобия, не так хорошо сочетаются с функцией softmax. Конкретно, целевые функции, в которых не используется логарифм для компенсации функции exp, входящей в softmax, не обуча ются, когда аргумент exp становится отрицательным и большим по абсолютной величине, что приводит к обнулению градиента. В частности, среднеквадратическая ошибка – плохая функция потерь для блоков softmax, она не всегда побуждает модель изменить свой выход, даже если модель весьма уверенно дает неправильные пред-сказания (Bridle, 1990). Чтобы понять, в чем тут дело, необходимо внимательно рас- смотреть саму функцию softmax. Как и сигмоида, функция активации softmax склонна к насыщению. У сигмоиды всего один выход, и она насыщается, когда абсолютная величина аргумента очень велика. У softmax выходных значений несколько. Они насыщаются, когда велика аб- солютная величина разностей между входными значениями. Когда softmax насыща-ется, многие основанные на ней функции стоимости также насыщаются, если только они не способны обратить насыщающуюся функцию активации.\n--- Страница 166 ---\nОбучение градиентными методами  165 Чтобы понять, как softmax реагирует на разность между входными значениями, за- метим, что выход softmax инвариантен относительно прибавления одного и того же скаляра ко всем входам: softmax(z) = softmax(z + c). (6.32) Пользуясь этим свойством, мы можем вывести численно устойчивый вариант soft- max: softmax(z) = softmax(z – maxi zi). (6.33) Этот новый вариант позволяет вычислять softmax с малыми численными погреш- ностями, даже когда z содержит очень большие по абсолютной величине элементы. Изучив численно устойчивый вариант, мы видим, что на функцию softmax оказывает влияние отклонение ее аргументов от maxi zi. Значение softmax(z)i асимптотически приближается к 1, когда соответствующий аргумент максимален (zi = maxi zi) и zi много меньше остальных входов. Значение softmax(z)i может также приближаться к 0, когда zi не максимально, а максимум на- много больше. Это обобщение того способа, которым достигается насыщение сигмо-идных блоков, и оно может стать причиной аналогичных трудностей при обучении, если функция потерь не компенсирует насыщения. Аргумент z функции softmax можно породить двумя разными способами. Самый распространенный – просто заставить предыдущий слой нейронной сети выводить каждый элемент z, как описано выше на примере линейного слоя z = W ⏉h + b. При всей своей простоте этот подход означает, что у распределения избыточное количе- ство параметров. Ограничение, согласно которому сумма n выходов должна быть равна 1, означает, что необходимо только n – 1 параметров; вероятность n-го значе- ния можно получить путем вычитания суммы первых n – 1 вероятностей из 1. Таким образом, один элемент z можно зафиксировать, например потребовать, чтобы zn = 0. Но это в точности то, что делает сигмоидный блок. Определение P(y = 1 | x) = σ(z) эк- вивалентно определению P(y = 1 | x) = softmax(z)1 в случае двумерного z и z1 = 0. Оба подхода к softmax – с n – 1 и с n аргументами – описывают одно и то же множество распределений вероятности, но обладают разной динамикой обучения. На практике редко возникает существенное различие между перепараметризованным и ограни- ченным вариантом, а перепараметризованный реализовать проще. С точки зрения нейробиологии, интересна интерпретация softmax как способа создания некоторой формы конкуренции между блоками, которые в ней участвуют: выходы softmax в сумме всегда дают 1, поэтому увеличение значения одного блока не- минуемо влечет уменьшение значений других. Это аналог латерального торможения, которое, как полагают, существует между близкими нейронами коры головного мозга. В крайней своей форме (когда разность между максимальным a i и всеми остальными велика по абсолютной величине) складывается ситуация, когда победитель получает все (один выход почти равен 1, остальные почти равны 0). Название «softmax» вносит некоторую путаницу. Эта функция ближе к arg max, чем к max. Часть «soft» связана с тем, что функция softmax непрерывная и дифферен- цируемая. Функция же arg max, результат которой представлен унитарным вектором, не является ни непрерывной, ни дифференцируемой. Следовательно, softmax – это «сглаженный» вариант arg max. Соответствующий сглаженный вариант функции\n--- Страница 167 ---\n166  Г лубокие сети прямого распространения max – softmax(z)⏉z. Пожалуй, было бы правильнее вместо softmax использовать «soft- argmax», но принятое название уже прочно укоренилось. 6.2.2.4. Другие типы выходных блоков Описанные выше выходные блоки – линейные, сигмоидные и softmax – применяют- ся наиболее часто. Но нейронные сети обобщаются практически на любой желаемый выходной слой. Принцип максимального правдоподобия подсказывает, как спроек-тировать хорошую функцию стоимости. В общем случае, если определено условное распределение p(y | x; θ), то согласно принципу максимального правдоподобия следует использовать в качестве функции стоимости –log p(y | x; θ). Вообще говоря, можно считать, что нейронная сеть представляет функцию f(x; θ). Но значения этой функции не являются прямыми предсказаниями значения y, вмес- то этого f(x; θ) = ω дает параметры распределения y. Тогда нашу функцию потерь можно интерпретировать как –log p(y; ω(x)). Например, пусть требуется обучить дисперсию условного нормального распреде- ления y при известном x. В простом случае, когда дисперсия σ 2 постоянна, ее мож- но выразить в замкнутой форме, потому что оценка максимального правдоподобия дисперсии – это не что иное, как эмпирическое среднее квадратов разностей между наблю дениями и ожидаемыми значениями y. Вычислительно более дорогой подход, не требующий обработки частного случая, состоит в том, чтобы включить дисперсию как одно из свойств распределения p(y | x), управляемого функцией ω = f(x; θ). Тогда отри- цательное логарифмическое правдоподобие –log p(y; ω(x)) дает функцию стоимости с подходящими членами, необходимыми, чтобы процедура оптимизации итеративно находила дисперсию. В простом случае, когда стандартное отклонение не зависит от входных данных, мы можем ввести в сеть новый параметр, который непосредственно копируется в ω. Этот новый параметр может совпадать с σ, или называться v и пред- ставлять σ2, или называться β и представлять 1/σ2 в зависимости от того, как мы хотим параметризовать распределение. Возможно, мы хотим, чтобы модель предсказывала разную величину дисперсии y для различных значений x. Такая модель называется гетероскедастической. В этом случае нужно просто описать дисперсию как одно из значений, порождаемых функцией f(x; θ). Часто для этой цели выражают нормальное распределение с помощью точности, а не дисперсии, как в уравнении (3.22). В много- мерном случае чаще всего используют диагональную матрицу точности diag(β). (6.34) Такое выражение хорошо сочетается с градиентным спуском, потому что формула логарифмического правдоподобия нормального распределения, параметризованного β, содержит только умножение на β i и прибавление log βi. Для операций умножения, сложения и логарифмирования градиент ведет себя хорошо. Для сравнения: при па- раметризации в терминах дисперсии пришлось бы использовать деление. Функция деления становится произвольно крутой в окрестности нуля. Конечно, большие гра- диенты могут помочь обучению, но если они произвольно велики, то обычно воз-никает неустойчивость. При параметризации в терминах стандартного отклонения логарифмическое правдоподобие включало бы деление и возведение в квадрат. По- следняя операция ведет к обращению градиента в нуль в окрестности нуля, что за- трудняет обучение возведенных в квадрат параметров. Но что бы мы ни использова-\n--- Страница 168 ---\nОбучение градиентными методами  167 ли – стандартное отклонение, дисперсию или точность, необходимо гарантировать, что ковариационная матрица нормального распределения положительно определен- ная. Поскольку собственные значения матрицы точности обратны собственным зна-чениям ковариационной матрицы, это условие эквивалентно условию положитель-ной определенности матрицы точности. Если использовать диагональную матрицу или единичную матрицу, умноженную на скаляр, то единственное условие, которое необходимо обеспечить для выхода модели, – положительность. Если обозначить a исходную активацию модели, используемой для определения диагональной матрицы точности, то для получения положительного вектора точности можно взять функ-цию softplus: β = ζ(a). Та же стратегия применима при использовании дисперсии или стандартного отклонения вместо точности, или единичной матрицы, умноженной на скаляр, вместо диагональной. Редко бывает, что ковариационную матрицу или матрицу точности обучают в виде более сложном, чем диагональная матрица. Если ковариация полная и условная, то па- раметризацию следует выбирать так, чтобы предсказанная ковариационная матрица была положительно определенной. Этого можно добиться, положив Σ(x) = B(x)B ⏉(x), где B – произвольная квадратная матрица. На практике, правда, возникает проблема: если это матрица полного ранга, то вычисление правдоподобия обходится дорого, т. к. вычисление определителя матрицы d×d и обратной матрицы Σ–1(x) (или, что экви- валентно и делается чаще, спектральное разложение Σ(x) или B(x)) имеет сложность O(d3). Часто мы хотим выполнить многомодальную регрессию, т. е. предсказать веще- ственные значения, зная условное распределение p(y | x), которое может иметь не- сколько пиков в пространстве y для одного и того же значения x. В таком случае есте- ственным представлением выхода является гауссова смесь (Jacobs et al., 1991; Bishop, 1994). Нейронные сети с гауссовыми смесями на выходе часто называют сетями со смесовой плотностью (mixture density networks). Выход в виде смеси n гауссовых компонент описывается таким условным распределением вероятности: (6.35) Нейронная сеть должна давать три выхода: вектор, определяющий p(c = i | x), мат- рица, задающая μ(i)(x) для всех i, и тензор, описывающий Σ(i)(x) для всех i. Эти вы- ходы должны удовлетворять различным ограничениям. 1. Компоненты смеси p(c = i | x): образуют категориальное распределение n ком- понент, ассоциированное с латентной переменной1 c, и обычно могут быть полу- чены применением softmax к n-мерному вектору; это гарантирует, что элементы выходного вектора положительны и в сумме дают 1. 2. Средние μ(i)(x): задают среднее значение (центр) i-й гауссовой компоненты, ни- какие ограничения на них не накладываются (обычно в этих выходных блоках нет никакой нелинейности). Если y – d-мерный вектор, то сеть должна выво- дить матрицу n×d, содержащую все n этих d-мерных векторов. Обучение средних с применением максимального правдоподобия несколько сложнее, чем обучение 1 Мы считаем c латентной, потому что не наблюдаем ее в данных: зная вход x и выход y, не- возможно уверенно сказать, какая гауссова компонента отвечает за y, но мы можем пред- положить, что y сгенерирована путем выбора одной из них, и сделать этот ненаблюдаемый выбор случайной величиной.\n--- Страница 169 ---\n168  Г лубокие сети прямого распространения средних распределения с единственной модой. Мы хотим обновлять среднее только для компоненты, которая действительно породила наблюдение. На прак- тике мы не знаем, какая компонента какое наблюдение породила. В выражении отрицательного логарифмического правдоподобия естественно взвешены вкла-ды каждого примера в функцию потерь каждой компоненты, в роли веса высту- пает вероятность того, что данная компонента породила данный пример. 3. Ковариации Σ (i)(x): определяют ковариационную матрицу каждой компоненты i. Как и при обучении одной гауссовой компоненты, мы обычно берем диагональ- ную матрицу, чтобы избежать вычисления определителей. Как и при обучении средних смеси, метод максимального правдоподобия осложняется необходи-мостью приписать часть ответственности за каждую точку компонентам смеси. Алгоритм градиентного спуска автоматически будет следовать за правильным процессом, если ему предоставить корректную спецификацию отрицательного логарифмического правдоподобия для модели смеси. Сообщалось, что градиентная оптимизация условных гауссовых смесей (на выходе нейронных сетей) может оказаться ненадежной, отчасти из-за операций деления (на дисперсию), которые могут быть численно неустойчивыми (если какая-то дисперсия получается слишком малой для конкретного примера, что приводит к очень большим градиентам). Одно из решений – обрезать градиенты (см. раздел 10.11.1), другое – эвристически масштабировать градиенты (Murray and Larochelle, 2014). Гауссовы смеси на выходе особенно эффективны в порождающих моделях речи (Schuster, 1999) и перемещения физических объектов (Graves, 2013). Стратегия сме- совой плотности позволяет сети представить многомодальный выход и управлять дисперсией выхода, что очень важно для получения высококачественного результата в тех предметных областях, где на выходе получаются вещественные числа. Пример сети со смесовой плотностью показан на рис. 6.4. xy Рис. 6.4  Примеры получены от нейронной сети с выходным слоем в виде смеси распределений. Вход x выбирается из равномерного распре- деления, а выход y – из pmodel(y | x). Нейронная сеть способна обучить нели- нейные отображения входа на параметры выходного распределения. В со- став этих параметров входят вероятности, управляющие тем, какая из трех компонент смеси порождает выход, а также параметры отдельных компо- нент. Каждая компонента смеси – нормальное распределение с предска- занными средним и дисперсией. Все эти аспекты выходного распределе- ния могут изменяться в зависимости от x, причем нелинейно\n--- Страница 170 ---\nСкрытые блоки  169 В общем случае мы можем захотеть продолжить моделирование векторов y, со- держащих все больше переменных, и налагать на эти переменные все более сложную структуру. Например, если мы хотим, чтобы нейронная сеть выводила последователь- ность символов, образующих предложение, то можем и дальше применять принцип максимального правдоподобия к нашей модели p(y; ω(x)). В этом случае модель, ис- пользуемая для описания y, становится слишком сложной для рассмотрения в этой главе. В главе 10 мы опишем, как использовать рекуррентные нейронные сети для описания таких моделей последовательностей, а в части III опишем передовые мето- ды моделирования произвольных распределений вероятности. 6.3. Скрытые блоки До сих пор мы ограничивались обсуждением проектных решений при построении нейронных сетей, типичных для большинства параметрической моделей машинного обучения, обучаемых методами градиентной оптимизации. Теперь займемся пробле-мой, возникающей только в нейронных сетях прямого распространения: как выбрать тип блока в скрытых слоях модели. Проектирование скрытых блоков – чрезвычайно активная область исследований, в которой не так уж много руководящих теоретических принципов. Блоки линейной ректификации – отличный выбор для скрытых блоков в отсут- ствие дополнительных аргументов. Но есть и много других типов. Бывает трудно решить, какой тип взять в конкретном случае (хотя обычно блоки линейной ректи- фикации дают приемлемый результат). Мы опишем кое-какие интуитивные сооб-ражения, стоящие за выбором типа скрытого блока. Они помогут принять решение, но заранее предсказать, какой тип окажется оптимальным, как правило, невозможно. Процесс проектирования – это последовательность проб и ошибок, когда высказы- вается гипотеза о подходящем блоке, затем обучается сеть с таким типом скрытых блоков и результат оценивается на контрольном наборе. Некоторые скрытые блоки, включенные в список, не являются всюду дифферен- цируемыми. Например, функция линейной ректификации g(z) = max{0, z} не диффе- ренцируема в точке z = 0. Может показаться, что из-за этого g непригодна для работы с алгоритмом обучения градиентными методами. Но на практике градиентный спуск работает для таких моделей машинного обучения достаточно хорошо. Отчасти это свя-зано с тем, что алгоритмы обучения нейронных сетей обычно не достигают локального минимума функции стоимости, а просто находят достаточно малое значение, как пока- зано на рис. 4.3 (эти идеи найдут дальнейшее развитие в главе 8). Поскольку мы не ожи- даем, что обучение выйдет на точку, где градиент равен 0, то можно смириться с тем, что минимум функции стоимости соответствует точкам, в которых градиент не определен. Недифференцируемые скрытые блоки обычно не дифференцируемы лишь в немногих точках. В общем случае функция g(z) имеет производную слева, определяемую коэф- фициентом наклона функции слева от z, и аналогично производную справа. Функция дифференцируема в точке z, только если производные слева и справа определены и рав- ны между собой. Для функций, встречающихся в контексте нейронных сетей, обычно определены производные слева и справа. Для функции g(z) = max{0, z} производная слева в точке z = 0 равна 0, а производная справа – 1. В программных реализациях обучения нейронной сети обычно возвращается какая-то односторонняя производная, а не сообщается, что производная не определена и не возбуждается исключение. Эври-\n--- Страница 171 ---\n170  Г лубокие сети прямого распространения стически это можно оправдать, заметив, что градиентная оптимизация на цифровом компьютере в любом случае подвержена численным погрешностям. Когда мы просим вычислить g(0), крайне маловероятно, что истинное значение действительно равно 0. Скорее всего, это какое-то малое значение ε, округленное до 0. В некоторых случаях возможны теоретически более убедительные обоснования, но обычно к обучению ней- ронных сетей они не относятся. Важно, что на практике можно спокойно игнорировать недифференцируемость функций активации скрытых блоков, описанных ниже. В большинстве случаев скрытый блок можно описать следующим образом: полу- чить вектор входов x, вычислить аффинное преобразование z = W ⏉x + b и применить к каждому элементу нелинейную функцию g(z). Друг от друга скрытые блоки отли- чаются только функцией активации g(z). 6.3.1. Блоки линейной ректификации и их обобщения В блоке линейной ректификации используется функция активации g(z) = max{0, z}. Эти блоки легко оптимизировать, потому что они очень похожи на линейные. Раз- ница только в том, что блок линейной ректификации в половине своей области опре- деления выводит 0. Поэтому производная блока линейной ректификации остается большой всюду, где блок активен. Градиенты не только велики, но еще и согласова- ны. Вторая производная операции ректификации всюду равна нулю, а первая про- изводная равна 1 всюду, где блок активен. Это означает, что направление градиента гораздо полезнее для обучения, чем в случае, когда функция активации подвержена эффектам второго порядка. Блоки линейной ректификации обычно применяются после аффинного преобра- зования: h = g(W ⏉x + b). (6.36) При инициализации параметров аффинного преобразования рекомендуется при- сваивать всем элементам b небольшое положительное значение, например 0.1. Тогда блок линейной ректификации в начальный момент с большой вероятностью окажется активен для большинства обучающих примеров, и производная будет отлична от нуля. Существует несколько обобщений блока линейной ректификации. Большинство из них демонстрирует более высокое качество лишь в отдельных случаях. Недостатком блоков линейной ректификации является невозможность обучить их градиентными методами на примерах, для которых функция активации блока равна нулю. Различные обобщения гарантируют, что градиент имеется в любой точке. Три обобщения блоков линейной ректификации основаны на использовании не- нулевого углового коэффициента α i, когда zi < 0: hi = g(z, α)i = max(0, zi) + αi min(0, zi). В случае абсолютной ректификации (absolute value rectification) берутся фиксиро- ванные значения αi = –1, так что g(z) = | z|. Такая функция активации используется при распознавании объектов в изображении (Jarrett et al., 2009), где имеет смысл ис- кать признаки, инвариантные относительно изменения полярности освещения. Дру-гие обобщения находят более широкие применения. В случае ReLU с утечкой (leaky ReLU) (Maas et al., 2013) α i принимаются равными фиксированному малому значе- нию, например 0.01, а в случае параметрического ReLU, или PReLU αi, считается обучаемым параметром (He et al., 2015). Maxout-блоки (Goodfellow et al., 2013a) – это дальнейшее обобщение блоков ли- нейной ректификации. Вместо того чтобы применять функцию g(z) к каждому эле-\n--- Страница 172 ---\nСкрытые блоки  171 менту, вектор z разбивается на группы по k значений. Затем каждый maxout-блок вы- водит максимальный элемент одной из групп: (6.37) где 𝔾(i) – множество индексов входов, входящих в i-ю группу, {(i – 1)k + 1, …, ik}. Это позволяет обучать кусочно-линейную функцию, дающую отклик в нескольких на- правлениях в пространстве входов x. Maxout-блок может обучить кусочно-линейную выпуклую функцию, состоящую из k участков. Поэтому такие блоки можно рассматривать как средство обучения са- мой функции активации, а не просто связи между блоками. При достаточно больших k maxout-блок может научиться аппроксимировать любую выпуклую функцию с про- извольной точностью. В частности, maxout-слой с двумя участками линейности мож- но обучить реализации той же функции от входа x, что и традиционный слой с бло- ком линейной ректификации, абсолютной ректификации, ректификации с утечкой или параметрической ректификации, а также реализации совершенно другой функ- ции. Разумеется, maxout-слой параметризуется не так, как слои других типов, поэто- му динамика обучения будет иной даже в случае, когда maxout обучают реализации той же функции от x, что и другие слои. Каждый maxout-блок параметризуется k векторами весов вместо одного, поэтому для них нужно больше регуляризации, чем для блоков линейной ректификации. Они могут хорошо работать вообще без регуляризации, если обучающий набор достаточ-но велик, а количество участков линейности в каждом блоке мало (Cai et al., 2013). У maxout-блоков есть еще несколько преимуществ. В некоторых случаях можно получить статистический и вычислительный выигрыш от уменьшения числа пара- метров. Точнее, если признаки, собранные n разными линейными фильтрами, можно обобщить без потери информации, взяв максимум по каждой группе k признаков, то следующий уровень может обойтись в k раз меньшим числом весов. Поскольку каждый блок «питается» несколькими фильтрами, maxout-блоки обла- дают некоторой избыточностью, позволяющей им противостоять феномену катаст- рофической забывчивости, когда нейронная сеть забывает, как решать задачи, кото- рым ее обучили в прошлом (Goodfellow et al., 2014a). Блоки линейной ректификации и все их обобщения основаны на принципе, со- гласно которому модель проще обучить, если ее поведение близко к линейному. Тот же общий принцип использования линейного поведения для упрощения опти-мизации применим не только к глубоким линейным сетям. Рекуррентные сети мо- гут обучаться на последовательностях и порождать последовательность состояний и выходов. В ходе их обучения необходимо передавать информацию от одного шага к другому, что гораздо проще, когда производятся линейные вычисления (некоторые производные по направлению близки к 1). В одной из самых лучших архитектур ре- куррентных сетей, LSTM, информация распространяется во времени путем сумми-рования – особенно простого вида линейной активации. Мы вернемся к этой теме в разделе 10.10. 6.3.2. Логистическая сигмоида и гиперболический тангенс Блоки линейной ректификации стали использоваться сравнительно недавно, а рань- ше в большинстве нейронных сетей в роли функции активации применялась логис- тическая сигмоида\n--- Страница 173 ---\n172  Г лубокие сети прямого распространения g(z) = σ(z) (6.38) или гиперболический тангенс g(z) = tanh(z). (6.39) Эти функции активации тесно связаны: tanh(z) = 2σ(2z) – 1. Мы уже видели сигмоидальные блоки в качестве выходных, предсказывающих ве- роятность того, что бинарная величина равна 1. В отличие от кусочно-линейных, сиг- моидальные блоки близки к асимптоте в большей части своей области определения – приближаются к высокому значению, когда z стремится к бесконечности, и к низкому, когда z стремится к минус бесконечности. Высокой чувствительностью они облада- ют только в окрестности нуля. Из-за насыщения сигмоидальных блоков градиентное обучение сильно затруднено. Поэтому использование их в качестве скрытых блоков в сетях прямого распространения ныне не рекомендуется. Применение же в качестве выходных блоков совместимо с обучением градиентными методами, если функция стоимости компенсируется насыщением сигмоиды в выходном слое. Если использовать сигмоидальную функцию активации необходимо, то лучше взять не логистическую сигмоиду, а гиперболический тангенс. Он ближе к тождест- венной функции в том смысле, что tanh(0) = 0, тогда как σ(0) = 1/2. Поскольку tanh походит на тождественную функцию в окрестности нуля, обучение глубокой ней- ронной сети y� = w⏉ tanh(U⏉ tanh(V⏉x)) напоминает обучение линейной модели y� = w⏉U⏉V⏉x, при условии что сигналы активации сети удается удерживать на низ- ком уровне. При этом обучение сети с функцией активации tanh упрощается. Сигмоидальные функции активации все же применяются, но не в сетях прямого распространения. К рекуррентным сетям, многим вероятностным моделям и некото- рым автокодировщикам предъявляются дополнительные требования, исключающие использование кусочно-линейных функций активации и делающие сигмоидальные блоки более подходящими, несмотря на проблемы насыщения. 6.3.3. Другие скрытые блоки Существует много других типов скрытых блоков, но используются они реже. Вообще говоря, многие дифференцируемые функции показывают отличные ре- зультаты. Есть целый ряд неопубликованных функций активации, которые ведут себя ничуть не хуже популярных. Приведем конкретный пример: мы тестировали сеть прямого распространения с функцией h = cos(Wx + b) на наборе данных MNIST и получили частоту ошибок менее 1 процента, что сравнимо с результатами, полу- ченными с использованием более традиционных функций активации. В ходе иссле- дований и разработки новых методов нередко тестируется много разных функций активации и обнаруживается, что результаты, полученные при отходе от стандарт- ной практики, вполне сопоставимы. Это означает, что новые типы скрытых блоков обычно публикуются только в случае, когда улучшение весомо и очевидно. Скрытые блоки, работающие примерно так же, как известные, – дело настолько обычное, что рассматривать их неинтересно. Бессмысленно перечислять все типы скрытых блоков, описанные в литературе. Мы отметим только несколько особенно полезных и непохожих на другие. Одна из возможностей – не использовать функцию активации g(z) вовсе. Мож- но считать, что в этой роли выступает тождественная функция. Мы уже видели, что\n--- Страница 174 ---\nПроектирование архитектуры  173 линейный блок может быть полезен в выходном слое нейронной сети. Его можно ис- пользовать и в качестве скрытого блока. Если каждый слой сети состоит только из линейных преобразований, то сеть в целом будет линейной. Однако некоторые слои могут быть и чисто линейными – это вполне нормально. Рассмотрим слой нейронной сети, имеющий n входов и p выходов, h = g(W⏉x + b). Его можно заменить двумя сло- ями, в одном из которых используется матрица весов U, а в другом – матрица весов V. Если в первом слое нет функции активации, то мы, по сути дела, разложили на множители матрицу весов исходного слоя, основанного на W. Подход, основанный на разложении в произведение, состоит в том, чтобы вычислить h = g(V⏉U⏉x + b). Если U порождает q выходов, то U и V вместе содержат только (n + p)q параметров, тогда как W – np параметров. Для малых q экономия параметров может быть суще- ственной. Платой за это является ограничение – линейное преобразование должно иметь низкий ранг, но таких низкоранговых связей часто достаточно. Таким образом, линейные скрытые блоки предлагают эффективный способ уменьшить число пара-метров сети. Блоки softmax – еще один вид блоков, часто используемых на выходе (см. раз- дел 6.2.2.3), но иногда они применяются и в скрытых слоях. Такие блоки естественно представляют распределение вероятности дискретной переменной, принимающей k значений, поэтому они могут играть роль своего рода переключателей. Обычно такие скрытые блоки применяются только в более сложных архитектурах, которые явно обучаются манипулировать памятью (см. раздел 10.12). Из других довольно распространенных скрытых блоков упомянем следующие: блок в виде радиально-базисной функции (RBF): h i = exp((–1/σi2)||W:, i – x||2). Эта функция становится более активной, когда x стремится к образцу W:, i. По- скольку для большинства x она асимптотически равна 0, оптимизировать ее трудно; Softplus: g(a) = ζ(a) = log(1 + ea). Это сглаженный вариант ректификатора, ис- пользованный в работе Dugas et al. (2001) для аппроксимации функций и в ра- боте Nair and Hinton (2010) для условных распределений в неориентированных вероятностных моделях. В работе Glorot et al. (2011a) сравнивались softplus и ректификатор и обнаружилось, что результаты последнего лучше. Примене- ние softplus, вообще говоря, не рекомендуется. Функция softplus демонстриру-ет, что качество скрытых блоков может противоречить интуиции, – казалось бы, она должна иметь преимущество над ректификатором в силу дифферен- цируемости всюду или не столь полного насыщения, но опыт показывает, что это не так; Hardtanh. По форме эта функция похожа на tanh и на ректификатор, но, в от- личие от последнего, ограничена: g(a) = max(–1, min(1, a)). Она введена в ра- боте Collobert (2004). В области проектирования скрытых слоев до сих пор ведутся активные исследова- ния, и многие полезные типы слоев ждут своего открытия. 6.4. Проектирование архитектуры Еще один ключевой аспект нейронных сетей – задание архитектуры. Под архитекту- рой понимается общая структура сети: сколько в ней должно быть блоков и как эти блоки соединены между собой.\n--- Страница 175 ---\n174  Г лубокие сети прямого распространения Большинство нейронных сетей организовано в виде групп блоков, именуемых слоя ми. В большинстве архитектур нейронных сетей слои собраны в цепочку, так что каждый слой является функцией от предыдущего. В этой структуре первый слой за- дается уравнением h(1) = g(1)(W(1)⏉x + b(1)), (6.40) второй слой – уравнением h(2) = g(2)(W(2)⏉h(1) + b(2)) (6.41) и так далее. В таких цепных архитектурах главное – выбор глубины сети и ширины каждого слоя. Как мы увидим, даже сети всего с одним скрытым слоем достаточно для ап- проксимации обучающего набора. Более глубокие сети часто способны обходиться гораздо меньшим числом блоков в одном слое и гораздо меньшим числом параметров и, кроме того, хорошо обобщаются на тестовый набор, но их труднее оптимизировать. Идеальная архитектура сети для данной задачи ищется в ходе экспериментов, на- правление которых определяется ошибкой на контрольном наборе. 6.4.1. Свойства универсальной аппроксимации и глубина Линейная модель, отображающая признаки на выходы посредством умножения на матрицу, по определению способна представить только линейные функции. Ее пре-имущество – простота обучения, потому что многие функции потерь в случае приме- нения к линейной модели приводят к задачам выпуклой оптимизации. К сожалению, от систем часто требуется обучать нелинейные функции. На первый взгляд кажется, что для обучения нелинейной функции нужно про- ектировать специализированное семейство моделей для каждого вида нелинейно-сти. По счастью, сети прямого распространения со скрытыми слоями предоставляют универсальную инфраструктуру аппроксимации. Точнее, универсальная теорема аппроксимации (Hornik et al., 1989; Cybenko, 1989) утверждает, что сеть прямого распространения с линейным выходным слоем и, по крайней мере, одним скрытым слоем с произвольной «сплющивающей» функцией активации (такой, например, как логистическая сигмоида) может аппроксимировать любую измеримую по Борелю функцию, отображающую одно конечномерное пространство в другое с любой точ- ностью, при условии что в сети достаточно скрытых блоков. Производные сети прямо- го распространения могут также аппроксимировать производные функции с любой точностью (Hornik et al., 1990). Понятие измеримости по Борелю выходит за рамки этой книги; нам достаточно знать, что любая непрерывная функция на замкнутом ограниченном подмножестве ℝ n измерима по Борелю и потому может быть аппрок- симирована нейронной сетью. Нейронная сеть также может аппроксимировать про-извольную функцию, отображающую одно конечномерное дискретное пространство в другое. Хотя первоначально эти теоремы были доказаны в терминах блоков с функ- циями активации, которые насыщаются при стремлении аргумента к бесконечности любого знака, универсальные теоремы аппроксимации справедливы также для бо-лее широкого класса функций активации, включающего ныне широко используемые блоки линейной ректификации (Leshno et al., 1993). Универсальная теорема аппроксимации означает, что какой бы ни была обучаемая функция, найдется достаточно большой МСП, способный ее представить. Однако не\n--- Страница 176 ---\nПроектирование архитектуры  175 гарантируется, что алгоритм обучения сможет эту функцию обучить. Даже если МСП может представить функцию, обучение может оказаться невозможным по двум причи- нам. Во-первых, применяемый при обучении алгоритм оптимизации может не найти соответствующие ей значения параметров. Во-вторых, из-за переобучения алгоритм оптимизации может выбрать не ту функцию. Напомним (раздел 5.2.1), что согласно теореме об отсутствии бесплатных завтраков не существует универсального верхов-ного алгоритма машинного обучения. Сети прямого распространения являются уни-версальной системой представления функций в том смысле, что для любой заданной функции найдется аппроксимирующая ее сеть. Но не существует универсальной про-цедуры исследования набора конкретных обучающих примеров и выбора функции, которая хорошо обобщалась бы на примеры, не принадлежащие этому набору. По универсальной теореме аппроксимации, существует достаточно большая сеть, аппроксимирующая функцию с любой точностью, но теорема ничего не говорит о том, насколько велика эта сеть. В работе Barron (1993) даны верхние границы раз- мера сети с одним уровнем, необходимой для аппроксимации широкого класса функ- ций. К сожалению, в худшем случае может понадобиться экспоненциальное число скрытых блоков (возможно, по одному скрытому блоку на каждую нуждающуюся в различении конфигурацию входов). Проще всего убедиться в этом в бинарном слу- чае: число возможных бинарных функций от векторов v ∈ {0, 1} n равно 22n, и для вы- бора одной такой функции нужно 2n бит, так что в общем случае необходимо O(2n) степеней свободы. Короче говоря, сети прямого распространения с одним слоем достаточно для пред- ставления любой функции, но этот слой может оказаться невообразимо большим, не поддающимся обучению и плохо обобщающимся. Во многих случаях примене- ние глубоких моделей позволяет уменьшить число необходимых блоков и величину ошибки обобщения. Различные семейства функций можно эффективно аппроксимировать с помощью архитектуры с глубиной, большей некоторой величины d, но требуется гораздо боль- шая по размеру модель, если глубина должна быть меньше или равна d. Во многих слу- чаях количество скрытых блоков, необходимое «мелкой» модели, экспоненциально зависит от n. Подобные результаты сначала были доказаны для моделей, ничем не на- поминающих непрерывные дифференцируемые нейронные сети, применяемые в ма- шинном обучении, но затем обобщены и на такие модели. Первые результаты были получены для электрических схем, состоящих из логических вентилей (Hå stad, 1986). Впоследствии они были обобщены на линейные пороговые блоки с неотрицатель- ными весами (Hå stad and Goldmann, 1991; Hajnal et al., 1993), а еще позже – на сети с непрерывными функциями активации (Maass, 1992; Maass et al., 1994). Во многих современных нейронных сетях используются блоки линейной ректификации. В рабо- те Leshno et al. (1993) показано, что мелкие сети с широким классом неполиномиаль- ных функций активации, включающим и блоки линейной ректификации, обладают свойствами универсальной аппроксимации, но эти результаты не затрагивают вопроса о глубине или эффективности – они утверждают лишь, что с помощью достаточно большой сети ректификаторов можно представить произвольную функцию. В рабо- те Montufar et al. (2014) показано, что для функций, представимых глубокой сетью ректификаторов, может потребоваться экспоненциальное число скрытых блоков, если сеть мелкая (один скрытый слой). Точнее, показано, что кусочно-линейные сети (по-лучаемые с помощью нелинейностей типа ректификаторов или maxout-блоков) могут\n--- Страница 177 ---\n176  Г лубокие сети прямого распространения представить любые функции, но число линейных участков экспоненциально зависит от глубины сети. На рис. 6.5 показано, как сеть с абсолютной ректификацией создает зеркальное изображение функции, вычисленной некоторым скрытым блоком, относи-тельно входа этого блока. Каждый скрытый блок задает место, где нужно «перегнуть» пространство входов, чтобы получить зеркальный отклик (по обе стороны абсолют-ной нелинейности). С помощью композиции таких операций перегибания мы полу- чаем экспоненциально растущее число участков нелинейности и тем самым можем уловить любые регулярные (т. е. повторяющиеся) паттерны. Рис. 6.5  Интуитивное геометрическое объяснение экспоненциального характера глубоких сетей ректификаторов, формально доказанного в рабо- те Montufar et al. (2014). (Слева) Блок абсолютной ректификации порожда-ет одинаковые выходы для любой пары зеркально симметричных входов. Ось симметрии задается гиперплоскостью, определяемой весами и сме- щением блока. Функция, вычисляемая этим блоком (зеленая решающая поверхность), будет зеркальным отражением более простого паттерна от-носительно этой оси симметрии. (В центре) Функцию можно получить пу-тем перегибания пространства по этой оси симметрии. (Справа) На первый повторяющийся паттерн можно наложить еще один (с помощью блока сле-дующего слоя) и получить тем самым еще одну симметрию (четырехкрат- ное повторение при двух скрытых слоях). Рисунок взят из работы Montufar et al. (2014) с разрешения авторов Основная теорема в работе Montufar et al. (2014) утверждает, что число линейных участков, представимых глубокой сетью ректификаторов с d входами, глубиной l и n блоками в каждом скрытом слое, равно (6.42) т. е. экспоненциально зависит от глубины l. В случае maxout-сетей с k фильтрами на один блок число линейных участков равно O(k(l – 1) + d). (6.43) Конечно, нет никакой гарантии, что функции, которые мы хотим обучать в прило- жениях машинного обучения (и особенно ИИ), обладают таким свойством. Выбор глубокой модели может быть продиктован и статистическими соображе- ниями. При выборе конкретного алгоритма машинного обучения мы неявно форму-лируем некоторые априорные предположения о характере функции, которую этот алгоритм должен обучить. В глубокой модели закодирована очень общая гипотеза, согласно которой обучаемая функция должна быть композицией более простых.\n--- Страница 178 ---\nПроектирование архитектуры  177 С точки зрения обучения представлений, эту гипотезу можно интерпретировать, ска- зав, что задача обучения состоит в выявлении множества истинных факторов вариа- тивности, которое, в свою очередь, можно описать в терминах других, более простых факторов вариативности. По-другому использование глубокой архитектуры можно интерпретировать как выражение нашей веры в том, что функция, которую мы хотим обучить, является компьютерной программой, состоящей из нескольких шагов, на каждом из которых используется результат предыдущего шага. Эти промежуточные результаты не обязательно являются факторами вариативности, их можно уподобить счетчикам или указателям, с помощью которых сеть организует свою внутреннюю работу. Эмпирически показано, что для широкого класса задач увеличение глубины влечет улучшение обобщаемости (Bengio et al., 2007; Erhan et al., 2009; Bengio, 2009; Mesnil et al., 2011; Ciresan et al., 2012; Krizhevsky et al., 2012; Sermanet et al., 2013; Fara-bet et al., 2013; Couprie et al., 2013; Kahou et al., 2013; Goodfellow et al., 2014d; Szegedy et al., 2014a). Примеры таких эмпирических результатов приведены на рис. 6.6 и 6.7. Они наводят на мысль, что глубокие архитектуры действительно выражают полез-ную априорную информацию о пространстве функций, обучаемых моделью. 96,5 96,0 95,5 95,094,5 94,0 93,593,0 92,5 92,0 3 4 5 6 7 8 9 10 11Верность на тестовом наборе (в процентах) Рис. 6.6  Влияние глубины. Эмпирические результаты показывают, что более глубокие сети лучше обобщаются в задаче распознавания несколь- ких цифр на фотографиях адресов. Данные взяты из работы Goodfellow et al. (2014d). Верность на тестовом наборе монотонно растет при увеличении глубины. На рис. 6.7 приведены результаты контрольного эксперимента, показывающие, что увеличение других размерных характеристик модели не дает такого же эффекта 6.4.2. Другие архитектурные подходы До сих пор мы описывали нейронную сеть как состоящую из простой цепочки слоев, а основными параметрами были глубина сети и ширина каждого слоя. На практике нейронные сети куда более разнообразны. Многие архитектуры нейронных сетей разрабатывались под конкретные задачи. В главе 9 описаны сверточные сети – специальные архитектуры, применяемые в за- дачах компьютерного зрения. Сети прямого распространения также обобщаются на рекуррентные нейронные сети для обработки последовательностей (глава 10), у ко- торых имеются собственные архитектурные особенности.\n--- Страница 179 ---\n178  Г лубокие сети прямого распространения Число параметров ×108 3, сверточная 3, полносвязная11, сверточнаяВерность на тестовом наборе (в процентах)97 96 95 94 93 92 91 0,0 0,2 0,4 0,6 0,8 1,0 Рис. 6.7  Влияние числа параметров. Более глубокие модели обычно работают лучше. Но это не просто потому, что модель больше. Экспери- мент, описанный в работе Goodfellow et al. (2014d), показывает, что уве- личение числа параметров в слоях сверточной сети, не сопровождаемое увеличением ее глубины, далеко не так эффективно с точки зрения обоб- щения на тестовый набор. В надписях на рисунке указана глубина сети, со- ответствующей каждой кривой, и что именно отражает кривая: изменение размера сверточных или полносвязных слоев. Мы видим, что мелкие мо-дели в этом контексте оказываются переобучены, когда число параметров составляет примерно 20 миллионов, а качество глубоких продолжает улуч- шаться вплоть до числа параметров порядка 60 миллионов. Это позволяет предположить, что глубокая модель выражает полезную гипотезу о прост- ранстве обучаемых ей функций, а именно она выражает веру в то, функ- ция должна быть образована композицией многих более простых функций. Результатом может быть либо обучение представления, составленного из более простых представлений (например, углы, определяемые в терминах границ), либо обучение программы, состоящей из последовательных зави-симых друг от друга шагов (например, сначала найти множество объектов, затем сегментировать их, отделив друг от друга, и потом распознать их) В общем случае слои необязательно должны быть соединены в цепочку, хотя это наи- более распространенная практика. Во многих архитектурах строится главная цепочка, а затем на нее накладываются специальные свойства, например прямые связи (skip con- nections), ведущие от слоя i к слою i + 2 и выше. Благодаря таким связям упрощается распространение градиента от выходных слоев к слоям, расположенным ближе к входу. Еще один ключевой архитектурный вопрос – как именно соединяются между собой пары слоев. В стандартном слое нейронной сети, описываемом матрицей линейного преобразования W, каждый входной блок соединен с каждым выходным. Но во мно- гих специальных сетях, описываемых в следующих главах, число соединений меньше, т. е. каждый блок входного слоя соединен лишь с небольшим подмножеством блоков выходного слоя. Такие стратегии позволяют уменьшить число параметров и объем вы- числений, необходимых для обсчета сети, но зачастую сильно зависят от характера задачи. Например, в сверточных сетях (глава 9) применяется особая структура раз- реженных соединений, весьма эффективная в задачах компьютерного зрения. В этой главе трудно дать более конкретный совет касательно архитектуры нейронной сети общего вида. В последующих главах мы разработаем архитектурные стратегии для частных случаев, доказавшие свою эффективность в различных предметных областях.\n--- Страница 180 ---\nОбратное распространение и другие алгоритмы дифференцирования  179 6.5. Обратное распространение и другие алгоритмы дифференцирования При использовании нейронной сети прямого распространения, которая принимает вход x и порождает выход y�, информация передается по сети в одном направлении – вперед. Вход x содержит начальную информацию, которая доходит до скрытых бло- ков каждого слоя, и в конечном итоге порождается y�. Это и называется прямым рас- пространением. На этапе обучения прямое распространение может продолжаться, пока не будет получена скалярная стоимость J(θ). Алгоритм обратного распростра- нения (Rumelhart et al., 1986a) позволяет передавать информацию о стоимости об- ратно по сети для вычисления градиента. Аналитически выписать выражение для градиента легко, но его численное вычис- ление может оказаться накладным. В алгоритме обратного распространения для это- го применяется простая и недорогая процедура. Сам термин «обратное распространение» зачастую трактуют неверно, понимая под ним весь алгоритм обучения многослойных нейронных сетей. На самом деле обратное распространение относится только к вычислению градиента, тогда как для обучения с помощью этого градиента применяют другие алгоритмы, например стохастическо- го градиентного спуска. Кроме того, иногда ошибочно полагают, что обратное рас-пространение касается только многослойных нейронных сетей, хотя, в принципе, так можно вычислять производные любой функции (для некоторых функций правиль-ным ответом является сообщение о том, что производная не определена). Мы опи- шем, как вычислить градиент ∇ x f(x, y) произвольной функции f, где x – множество аргументов, по которым производные вычисляются, а y – дополнительное множе- ство аргументов, по которым они не вычисляются. В алгоритмах обучения нас чаще всего интересует градиент функции стоимости относительно ее параметров ∇θ J(θ). Во многих задачах машинного обучения приходится вычислять и другие произво- дные – в процессе обучения или для анализа обученной модели. Алгоритм обратного распространения можно применить и к таким задачам тоже. Идея вычисления про- изводных путем распространения информации по сети очень общая, она применима, в частности, к вычислению якобиана функции f, порождающей много значений. Но мы ограничимся наиболее типичным случаем, когда значением f является скаляр. 6.5.1. Графы вычислений До сих пор мы использовали при обсуждении нейронных сетей сравнительно нефор-мальный язык графов. Но для точного описания алгоритма обратного распростране-ния полезно иметь более формальный язык графов вычислений. Есть много способов формализации вычислений в виде графов.В данном случае вершины графа будут соответствовать переменным. Переменная может быть скаляром, вектором, матрицей, тензором или иметь еще какой-то тип. Для формализации графов нам понадобится также ввести понятие операции. Опе- рация – это простая функция одной или многих переменных. Язык графов сопрово- ждается множеством допустимых операций. Функции, более сложные, чем операции, можно описать с помощью композиции операций. Без ограничения общности можно считать, что операция возвращает единствен- ную переменную. Общность не теряется, потому что эта переменная может состоять\n--- Страница 181 ---\n180  Г лубокие сети прямого распространения из нескольких элементов, как, например, вектор. Программные реализации алгорит- ма обратного распространения обычно поддерживают операции с несколькими вы- ходами, но в нашем описании мы отказываемся от этого, чтобы не погрязнуть в не- принципиальных для понимания деталях. Если переменная y вычисляется применением некоторой операции к переменной x, то мы проводим в графе ориентированное ребро от x к y. Иногда выходная вершина аннотируется именем примененной операции, а иногда эта метка опускается, если операция понятна из контекста. На рис. 6.8 приведены примеры графов вычислений. y� y�z u(1) U(2)U(1) X x W w b λu(2) Hu(2) u(1)u(3)x x y+ +w b× ×σ dot sum sqrdotmatmulrelu(a) (c)(b) (d) Рис. 6.8  Примеры графов вычислений. (a) Граф, в котором операция × используется для вычисления z = xy. (b) Граф вычисления логистической регрессии y� = σ(x⏉w + b). Некоторые промежуточные выражения не поиме- нованы в алгебраическом выражении, но должны иметь имена в графе. Мы просто обозначаем i-ю переменную такого рода u(i). (c) Граф вычисления выражения H = max{0, XW + b}, который вычисляет матрицу плана H, содер- жащую блоки линейной ректификации, если дана матрица плана, содержа-щая мини-пакет входов X. (d) В примерах a–c к каждой переменной при- менялось не более одной операции, но это необязательно. Здесь показан граф вычислений, в котором применяется более одной операции к весам w модели линейной регрессии. Веса используются как для вычисления пред-сказания y�, так и для вычисления штрафа за сложность λΣ iwi2, поощряющего снижение весов\n--- Страница 182 ---\nОбратное распространение и другие алгоритмы дифференцирования  181 6.5.2. Правило дифференцирования сложной функции Это правило применяется для вычисления производных функций, являющихся ком- позициями других функций, чьи производные известны. Алгоритм обратного рас-пространения как раз и посвящен реализации таких вычислений путем очень эффек- тивного упорядочения операций. Пусть x – вещественное число, а f и g – функции, отображающие одно веществен- ное число в другое. Обозначим y = g(x), z = f(g(x)) = f(y). Тогда правило дифферен- цирования сложной функции записывается в виде: (6.44) Мы можем обобщить эту формулу на случай нескольких переменных. Пусть x ∈ ℝm, y ∈ ℝn, g отображает ℝm в ℝn, а f отображает ℝn в ℝ. Если y = g(x), z = f(y), то (6.45) В векторной нотации эту формулу можно записать так: (6.46) где ∂y/∂x – матрица Якоби функции g размера n×m. Отсюда видно, что градиент по переменной x можно получить, умножив матри- цу Якоби ∂y/∂x на градиент ∇y z. Алгоритм обратного распространения заключает- ся в вычислении такого произведения якобиана на градиент для каждой операции в графе. Обычно алгоритм обратного распространения применяется к тензорам произ- вольной размерности, а не просто к векторам. Концептуально это то же самое, что применение к векторам. Разница только в том, как числа организуются в сетке для представления тензора. Можно вообразить, что тензор сериализуется в вектор пе- ред обратным распространением, затем вычисляется векторнозначный градиент, после чего градиент снова преобразуется в тензор. В таком переупорядоченном представлении обратное распространение – это все то же умножение якобиана на градиенты. Для обозначения градиента значения z относительно тензора X мы пишем ∇ Xz, как если бы X был просто вектором. Теперь индексы элементов X составные – напри- мер, трехмерный тензор индексируется тремя координатами. Мы можем абстрагиро-ваться от этого различия, считая, что одна переменная i представляет целый кортеж индексов. Для любого возможного индексного кортежа i (∇ Xz)i обозначает частную производную ∂z/∂Xi – точно так же, как для любого целого индекса i (∇xz)i обозначает ∂z/∂xi. В этих обозначениях можно записать правило дифференцирования сложной функции в применении к тензорам. Если Y = g(X) и z = f(Y), то (6.47)\n--- Страница 183 ---\n182  Г лубокие сети прямого распространения 6.5.3. Рекурсивное применение правила дифференцирования сложной функции для получения алгоритма обратного распространения С помощью правила дифференцирования сложной функции легко записать алгебра-ическое выражение для градиента скаляра относительно любой вершины графа вы-числений, приведшей к этому скаляру. Но при вычислении этого выражения компью- тером возникают дополнительные вопросы. Точнее, в выражении градиента могут многократно встречаться некоторые подвы- ражения. Процедура вычисления градиента должна решить, следует ли эти подвы-ражения хранить или каждый раз вычислять заново. На рис. 6.9 показано, как та-кие подвыражения могут возникать. В некоторых случаях вычисление одного и того же подвыражения дважды – расточительство. В сложных графах количество таких бессмысленных вычислений может расти экспоненциально, в результате чего наи- вная реализация правила дифференцирования сложной функции становится невоз-можной. А иногда повторное вычисление одного подвыражения является способом уменьшить потребление памяти за счет увеличения времени работы. Начнем с варианта алгоритма обратного распространения, в котором порядок вычисления градиента задается непосредственно (алгоритм 6.2 в сочетании с ал- горитмом 6.1 ассоциированного прямого вычисления) – путем рекурсивного при- менения правила дифференцирования сложной функции. Эти вычисления можно выполнить напрямую или считать описание алгоритма символической специфика-цией графа вычислений обратного распространения. Однако в этой формулировке отсутствует явное построение символического графа манипуляций, необходимых для вычисления градиента. Такая формулировка приведена в разделе 6.5.6 – это алгоритм 6.5, заодно обобщенный на случай вершин, содержащих произвольные тензоры. Сначала рассмотрим граф вычислений, описывающий, как вычислить один ска- ляр u (n) (скажем, потерю на обучающем примере). Это та величина, для которой мы хотим получить градиент относительно ni входных вершин от u(1) до u(ni). Иными сло- вами, мы хотим вычислить ∂u(n)/∂u(i) для всех i ∈ {1, 2, …, ni}. Если алгоритм обратного распространения применяется к вычислению градиентов для градиентного спуска по параметрам, то u(n) – стоимость, ассоциированная с примером или мини-пакетом, а u(1), …, u(ni) соответствуют параметрам модели. Будем предполагать, что вершины графа упорядочены таким образом, что можно вычислять их выходы один за другим, начиная с u(ni+1) и до u(n). В алгоритме 6.1 пред- полагается, что с вершиной u(i) ассоциирована операция f(i), а вычисления в ней про- изводятся по формуле u(i) = f(𝔸 (i)), (6.48) где 𝔸 (i) – множество всех вершин, являющихся родителями u(i). Этот алгоритм определяет вычисления при прямом распространении, которые можно было бы поместить в граф 𝒢. Для выполнения обратного распространения мы можем построить граф вычислений, который зависит от 𝒢 и добавляет дополнитель- ные вершины. Эти вершины образуют подграф ℬ, содержащий по одной вершине на каждую вершину 𝒢. Вычисления в ℬ производятся в порядке, обратном вычислениям\n--- Страница 184 ---\nОбратное распространение и другие алгоритмы дифференцирования  183 в 𝒢, а каждая вершина ℬ вычисляет производную ∂u(n)/∂u(i), ассоциированную с вер- шиной u(i) графа прямого распространения. Делается это с помощью правила диффе- ренцирования сложной функции применительно к скалярному выходу u(n): (6.49) как описано в алгоритме 6.2. Подграф ℬ содержит ровно одно ребро для каждого ребра из вершины u(j) в вершину u(i) графа 𝒢. Ребро из u(j) в u(i) ассоциировано с вычис- лением ∂u(i)/∂u(j). Кроме того, для каждой вершины вычисляется скалярное произве- дение между уже вычисленным градиентом относительно вершин u(i), являющихся непосредственными потомками u(j), и вектором, содержащим частные производные ∂u(i)/∂u(j) для тех же дочерних вершин u(i). Таким образом, объем вычислений в ал- горитме обратного распространения линейно зависит от числа ребер графа 𝒢, а об- работка каждого ребра состоит в вычислении частной производной (одной вершины по одной из ее родительских вершин), одного умножения и одного сложения. Ниже мы обобщим этот анализ на тензорнозначные вершины, цель которых – сгруппиро- вать несколько скалярных значений в одной вершине и повысить эффективность реализации. Алгоритм 6.1. Процедура, которая выполняет вычисления, отображающие ni входов u(1), …, u(ni) в выход u(n). Она определяет граф вычислений, в котором каж- дая вершина вычисляет числовое значение u(i) путем применения функции f(i) ко множеству аргументов 𝔸 (i), содержащему значения предыдущих вершин u(j), j < i и j ∈ Pa(u(i)). Входом для графа вычислений является вектор x, хранящийся в пер- вых ni вершинах u(1), …, u(ni). Результат графа вычислений читается из последней (выходной) вершины u(n). for i = 1, …, ni do u(i) ⟵ xi end for for i = ni + 1, …, n do 𝔸 (i) ⟵ {u(j) | j ∈ Pa (u(i))} u(i) ⟵ f(i)(𝔸 (i)) end forreturn u (n) Алгоритм обратного распространения призван уменьшить количество общих подвыражений без учета доступной памяти. Точнее, он вычисляет порядка одного произведения якобиана на вектор на каждую вершину графа. Это видно из того, что алгоритм 6.2 посещает каждое ребро из вершины u (j) в вершину u(i) графа ровно один раз для вычисления ассоциированной с ним частной производной ∂u(i)/∂u(j). Таким образом, алгоритм обратного распространения предотвращает экспоненци-альный рост повторяющихся подвыражений. Другие алгоритмы могут еще умень-шить число подвыражений путем упрощения графа вычислений, а могут сэконо- мить память, повторно вычисляя некоторые подвыражения вместо их сохранения. Мы вернемся к этим идеям, после того как опишем сам алгоритм обратного рас- пространения.\n--- Страница 185 ---\n184  Г лубокие сети прямого распространения z y x wfff Рис. 6.9  Граф вычислений градиента, в котором возникают пов- торяющиеся подвыражения. Обозначим w ∈ ℝ – вход графа. В качестве опе- рации, применяемой на каждом шаге цепочки, используем ту же функцию f : ℝ ⟶ ℝ, т. е. x = f(w), y = f(x), z = f(y). Для вычисления ∂z/∂w применяем уравнение 6.44 и получаем: (6.50) (6.51) = f ′(y)f ′(x)f ′(w) (6.52) = f’(f(f(w)))f ′(f(w))f ′(w). (6.53) Уравнение (6.52) подсказывает реализацию: вычислить значение f(w) один раз и сохранить его в переменной x. Именно такой подход применяется в ал- горитме обратного распространения. Альтернативный подход подсказан уравнением (6.53), в котором подвыражение f(w) встречается более одного раза. В этом случае f(w) заново вычисляется всякий раз, как понадобится. Если памяти для хранения значений подвыражений достаточно, то подход, подсказанный уравнением (6.52), очевидно, предпочтительнее, т. к. требует меньше времени. Но и уравнение (6.53) – допустимая реализация правила дифференцирования сложной функции, полезная, когда память ограничена. Алгоритм 6.2. Упрощенный вариант алгоритма обратного распространения для вычисления производных u(n) по переменным в графе. Этот пример позволит луч- ше понять алгоритм в простом случае, когда все переменные – скаляры, а мы хотим вычислить производные по u(1), …, u(ni). Вычислительная сложность этого алгорит- ма пропорциональна числу ребер графа в предположении, что вычисление частной производной, ассоциированной с каждым ребром, занимает постоянное время. По- рядок тот же, что для объема вычислений в алгоритме прямого распространения. Каждая производная ∂u(i)/∂u(j) является функцией от родителей u(j) вершины u(i), и таким образом вершины прямого графа связываются с добавленными в граф об- ратного распространения.\n--- Страница 186 ---\nОбратное распространение и другие алгоритмы дифференцирования  185 Выполнить алгоритм прямого распространения (алгоритм 6.1) для вычисления функций активации сети.Инициализировать grad_table , структуру данных, в которой будут храниться вычисленные производные. В элементе grad_table [u(i)] хранится вычисленное значение ∂u(n)/∂u(i). grad_table [u(n)] ⟵ 1 for j = n – 1 down to 1 do В следующей строке вычисляется с использованием сохраненных значений: grad_table [u(j)] ⟵ grad_table [u(i)] . end for return {grad_table [u(i)] | i = 1, …, ni} 6.5.4. Вычисление обратного распространения в полносвязном МСП Чтобы прояснить данное выше определение вычисления обратного распространения, рассмотрим конкретный граф, ассоциированный с полносвязным многослойным перцептроном. Сначала в алгоритме 6.3 показано прямое распространение, которое отображает параметры на потерю обучения с учителем L(y�, y), ассоциированную с одним обуча- ющим примером (x, y), где y� – выход нейронной сети, на вход которой подан вектор x. Затем в алгоритме 6.4 показано соответствующее вычисление, в котором к этому графу применяется алгоритм обратного распространения. Алгоритмы 6.3 и 6.4 – демонстрации для лучшего понимания идеи. Они специали- зированы для решения одной конкретной задачи. Современные программные реализации основаны на обобщенной форме обратно- го распространения, описанной в разделе 6.5.6 ниже, они применимы к любому графу вычислений, поскольку явно манипулируют структурой данных для представления символьных вычислений. Алгоритм 6.3. Прямое распространение по типичной глубокой нейронной сети и вычисление функции стоимости. Потеря L(y�, y) зависит от выхода y� и метки y (см. раздел 6.2.1.1, где приведены примеры функций потерь). Для получения пол- ной стоимости J потерю можно сложить с регуляризатором Ω(θ), где θ содержит все параметры (веса и смещения). Алгоритм 6.4 показывает, как вычислить гради- енты J относительно параметров W и b. Для простоты в этой демонстрации есть только один входной пример x. На практике следует использовать мини-пакет. Более реалистичная демонстрация приведена в разделе 6.5.7. Require: глубина сети l Require: W (i), i ∈ {1, …, l }, матрица весов модели Require: b(i), i ∈ {1, …, l }, смещения модели Require: x, входа процесса Require: y, метки h(0) = x for k = 1, …, l do\n--- Страница 187 ---\n186  Г лубокие сети прямого распространения a(k) = b(k) + W(k)h(k–1) h(k) = f(a(k)) end for y� = h(l) J = L(y �, y) + λΩ(θ) Алгоритм 6.4. Вычисление обратного распространения для глубокой нейронной сети из алгоритма 6.3, в котором помимо входа x используются метки y. В резуль- тате вычисления получаются градиенты функций активации a(k) для каждого слоя k, начиная с выходного и до первого скрытого слоя. Эти градиенты можно интер- претировать как указания о том, как следует изменить выход каждого слоя, чтобы уменьшить ошибку, и, зная их, мы можем вычислить градиенты параметров каж-дого слоя. Градиенты весов и смещений можно тут же использовать для обновле- ния стохастического градиента (обновление выполняется сразу после вычисления градиентов) или в составе других градиентных методов оптимизации. После вычисления прямого распространения вычислить градиент выходного слоя:g ⟵ ∇ y� J = ∇y�L(y�, y) for k = l, l – 1, …, 1 do Преобразовать градиент выходного слоя в градиент функций активации до применения нелинейности (поэлементное умножение, если f поэлементная): g ⟵ ∇a(k) J = g ⊙ f ′(a(k)) Вычислить градиенты весов и смещений (включая член регуляризации там, где необходимо):∇ b(k) J = g + λ∇b(k)Ω(θ) ∇W(k) J = g h(k–1)⏉ + λ∇W(k)Ω(θ) Распространить градиенты на функции активации предыдущего скрытого уровня:g ⟵ ∇ h(k–1) J = W(k)⏉g end for 6.5.5. Символьно-символьные производные Алгебраические выражения и графы вычислений оперируют символами, т. е. пере- менными, не имеющими конкретного значения. Соответствующие представления называются символьными представлениями. В ходе использования или обучения нейронной сети мы должны приписать символам конкретные значения. Символьный вход сети x заменяется числовым значением, например [1.2, 3.765, –1.8] ⏉. В некоторых подходах к обратному распространению берутся граф вычислений и множество числовых значений, подаваемых на вход графа, а возвращается множе- ство числовых значений, равных градиентам во входных точках. Такой подход мы на-зываем символьно-числовым дифференцированием. Он реализован в библиотеках Torch (Collobert et al., 2011b) и Caffe (Jia, 2013). Другой подход – взять граф вычислений и добавить в него дополнительные вер- шины, содержащие символьное описание требуемых производных. Он использу-ется в библиотеках Theano (Bergstra et al., 2010; Bastien et al., 2012) и TensorFlow\n--- Страница 188 ---\nОбратное распространение и другие алгоритмы дифференцирования  187 (Abadi et al., 2015). Пример его работы показан на рис. 6.10. Основное преимуще- ство такого подхода в том, что производные описываются на том же языке, что и исходное выражение. Поскольку производные – просто еще один граф вычис- лений, становится возможным прогнать алгоритм обратного распространения еще раз, т. е. продифференцировать производные для получения производных высше- го порядка (вычисление производных высшего порядка рассматривается в разде- ле 6.5.10). z z y ydz dy dy dxdz dx dx dwdz dwf f f′ f′× × f′f f f fx x w w Рис. 6.10  Пример символьно-символьного подхода к вычислению производных. В этом случае алгоритму обратного распрост ранения во- обще не нужен доступ к фактическим числовым значениям. Вместо этого в граф вычислений добавляются вершины, описы ваю щие, как вычислять производные. Впоследствии универсальный движок обсчета графа может вычислить производные для любых конкретных значений. (Слева) В этом примере мы начали с графа, представляющего вычисление z = f(f(f(w))). (Справа) Мы выполнили алгоритм обратного распространения, потребовав построить граф для выражения, соответствующего dz/dw. Здесь мы не объ- ясняем, как работает алгоритм обратного распространения. Единственная цель – показать желаемый результат: это граф вычислений, содержащий символьное описание производной Мы будем пользоваться вторым подходом и опишем алгоритм обратного распрост ранения в терминах построения графа вычислений производных. Впо- следствии любое подмножество графа можно вычислить, подставив конкретные числовые значения. Это позволяет не указывать точно, в какой момент должна быть вычислена каждая операция, поскольку универсальный движок обсчета гра-фа умеет вычислять каждую вершину, как только становятся доступными значения ее родителей. Описанный символьно-символьный подход включает в себя символьно-числовой. Последний можно рассматривать как выполнение в точности тех же вычислений, ка-\n--- Страница 189 ---\n188  Г лубокие сети прямого распространения кие выполняет граф, построенный в первом случае. Основное различие состоит в том, что при символьно-числовом подходе этот граф явно не создается. 6.5.6. Общий алгоритм обратного распространения Алгоритм обратного распространения очень прост. Чтобы вычислить градиент неко- торой скалярной величины z относительно одного из предков в графе, мы прежде всего заметим, что градиент по z равен dz/dz = 1 . Затем можно вычислить градиент по каждо- му родителю z в графе, умножая текущий градиент на якобиан операции, породившей z. И так мы продолжаем умножать на якобианы, двигаясь в обратном направлении по графу, пока не дойдем до x. Если некоторая вершина достижима из z по двум или более путям, то мы просто суммируем градиенты, полученные вдоль каждого пути. Более формально, каждая вершина графа 𝒢 соответствует некоторой переменной. Для максимальной общности будем считать, что эта переменная описывается тензо-ром V. В общем случае число размерностей тензора произвольно. Скаляры, векторы и матрицы являются частными случаями тензоров. Будем предполагать, что с каждой переменной V ассоциированы следующие под- программы:  get_operation (V): возвращает операцию, которая вычисляет V, представляя ее в виде ребер графа вычислений, входящих в V. Например, на языке C++ (или Python) можно написать класс, представляющий операцию умножения матриц, и функцию get_operation . Предположим, что некоторая переменная является результатом умножения матриц, C = AB. Тогда get_operation (V) воз- вращает указатель на экземпляр соответствующего класса C++. get_consumers (V, 𝒢): возвращает список переменных, представленных дочерни- ми вершинами V в графе вычислений 𝒢. get_inputs (V, 𝒢): возвращает список переменных, представленных родитель- скими вершинами V в графе вычислений 𝒢. С каждой операцией op ассоциированна также операция bprop . Она умеет вычис- лять произведение якобиана на вектор, описываемое формулой (6.47). Именно так алгоритм обратного распространения достигает максимальной общности. Каждая операция знает, как выполнить обратное распространение по ребрам графа, в кото- рых она участвует. Например, для создания переменной C = AB используется опера- ция умножения матриц. Пусть градиент скалярной величины z относительно C равен матрице G. Тогда операция матричного умножения отвечает за определение двух пра- вил обратного распространения, по одному для каждого аргумента. Если мы знаем, что градиент по выходу равен G, то метод bprop операции умножения матриц должен сказать, что градиент относительно A равен GB⏉. Аналогично, если запросить у мето- да bprop градиент относительно B, то операция умножения матриц, ответственная за реализацию bprop , сообщит, что нужный нам градиент равен A⏉G. Сам метод обратно- го распространения ничего не знает о правилах дифференцирования. Он только вы- зывает методы bprop каждой операции, передавая им нужные аргументы. Формально метод op.bprop(inputs, X,G) должен вернуть (∇Xop.f(inputs )i)Gi, (6.54) а это и есть реализация правила дифференцирования сложной функции, выраженной уравнением (6.47). Здесь inputs – это список входов операции, op.f – математическая\n--- Страница 190 ---\nОбратное распространение и другие алгоритмы дифференцирования  189 функция, реализуемая операцией, X – входы, градиенты которых мы хотим вычис- лить, а G – градиент по выходу операции. Метод op.bprop всегда должен считать, что все его входы отличны друг от друга, даже если на самом деле это не так. Например, если оператору mul передаются две копии x для вычисления x2, то метод op.bprop все равно должен вернуть x в качестве производной по обоим входам. Впоследствии алгоритм обратного распространения сложит оба аргумента и получит 2x – правильную полную производную по x. Программные реализации алгоритма обратного распространения обычно предо- ставляют как операции, так и их методы bprop , поэтому пользователь библиотеки глубокого обучения может выполнить обратное распространение по графам, постро-енным из таких общеупотребительных операций, как умножение матриц, потенциро-вание, логарифмирование и т. д. Программисты, создающие новые реализации обрат- ного распространения, а также опытные пользователи, которым нужно добавить свои операции в дополнение к существующим в библиотеке, должны реализовать методы op.bprop новых операций самостоятельно. Формально алгоритм обратного распространения описан в алгоритме 6.5. Алгоритм 6.5. Внешняя обвязка алгоритма обратного распространения. Здесь про- изводятся только инициализация и очистка. Основная работа выполняется в под- программе build_grad , описанной в алгоритме 6.6. Require: 𝕋, множество переменных, градиенты которых нужно вычислить. Require: 𝒢, граф вычислений.Require: z, переменная, подлежащая дифференцированию Обозначим 𝒢′ часть графа 𝒢, содержащую только вершины, являющиеся пред- ками z и потомками вершин из 𝕋.Инициализировать grad_table , структуру данных, ассоциирующую тензоры с их градиентами grad_table [z] ⟵ 1 for V in 𝕋 do build_grad (V, 𝒢, 𝒢′, grad_table ) end forReturn ограничение grad_table на 𝕋 Алгоритм 6.6. Подпрограмма build_grad (V, 𝒢, 𝒢′, grad_table ), вызываемая в цикле алгоритма обратного распространения 6.5 Require: V, переменная, градиент которой следует добавить в 𝒢 и grad_table Require: 𝒢, модифицируемый граф Require: 𝒢′, ограничение 𝒢 на вершины, участвующие в вычислении градиентаRequire: grad_table , структура данных, отображающая вершины на их градиенты if V находится в grad_table then Return grad_table [V] end ifi ⟵ 1for C in get_consumers (V, 𝒢′) do op ⟵ get_operation (C) D ⟵ build_grad (C, 𝒢, 𝒢′, grad_table ) G(i) ⟵ op.bprop (get_inputs (C, 𝒢′), V, D)\n--- Страница 191 ---\n190  Г лубокие сети прямого распространения i ⟵ i + 1 end for G ⟵ Σi G(i) grad_table [V] = G Вставить G и участвовавшие в его создании операции в 𝒢Return G В разделе 6.5.2 мы объяснили, что алгоритм обратного распространения был раз- работан, чтобы избежать многократного вычисления одного и того же выражения при дифференцировании сложной функции. Из-за таких повторов время выполнения наивного алгоритма могло расти экспоненциально. Теперь, описав алгоритм обратно-го распространения, мы можем оценить его вычислительную сложность. Если пред-положить, что стоимость вычисления всех операций приблизительно одинакова, то вычислительную сложность можно проанализировать в терминах количества выпол- ненных операций. Следует помнить, что под операцией мы понимаем базовую едини-цу графа вычислений, в действительности она может состоять из нескольких арифме- тических операций (например, умножение матриц может считаться одной операцией в графе). Вычисление градиента в графе с n вершинами никогда не приводит к выпол- нению или сохранению результатов более O(n 2). Здесь мы подсчитываем операции в графе вычислений, а не отдельные аппаратные операции, поэтому важно понимать, что время выполнения разных операций может значительно различаться. Например, умножение двух матриц, содержащих миллионы элементов, может считаться одной операцией в графе. Легко видеть, что для вычисления градиента требуется не более O(n 2) операций, потому что на этапе прямого распространения в худшем случае будут обсчитаны все n вершин исходного графа (в зависимости от того, какие значения мы хотим вычислить, может потребоваться обойти весь граф). Алгоритм обратного рас-пространения добавляет по одному произведению якобиана на вектор, выражаемому через O(1) вершин, на каждое ребро исходного графа. Поскольку граф вычислений – это ориентированный ациклический граф, число ребер в нем не более O(n 2). Для ти- пичных графов, встречающихся на практике, ситуация даже лучше. В большинстве нейронных сетей функции стоимости имеют в основном цепную структуру, так что сложность обратного распространения равна O(n). Это намного лучше, чем наивный подход, при котором число обрабатываемых вершин иногда растет экспоненциально. Откуда возникает экспоненциальный рост, можно понять, раскрыв и переписав пра- вило дифференцирования сложной функции (6.49) без рекурсии: (6.55) Поскольку количество путей из вершины j в вершину n может экспоненциально зависеть от длины пути, то число слагаемых в этой сумме, равное числу таких путей, может расти экспоненциально с увеличением глубины графа прямого распростра- нения. Такая высокая сложность связана с многократным вычислением ∂u(i)/∂u(j). Чтобы избежать повторных вычислений, мы можем рассматривать обратное распро- странение как алгоритм заполнения таблицы, в которой хранятся промежуточные результаты ∂u(n)/∂u(i). Каждой вершине графа соответствует элемент таблицы, в ко- тором хранится градиент для этой вершины. Заполняя таблицу в определенном по- рядке, алгоритм обратного распространения избегает повторного вычисления мно-\n--- Страница 192 ---\nОбратное распространение и другие алгоритмы дифференцирования  191 гих общих подвыражений. Такую стратегию заполнения таблицы иногда называют динамическим программированием. 6.5.7. Пример: применение обратного распространения к обучению МСП В качестве примера подробно проанализируем применение алгоритма обратного рас-пространения к обучению многослойного перцептрона. Мы разработаем очень простой многослойный перцептрон всего с одним скрытым слоем. Для обучения этой модели будем использовать метод стохастического гради-ентного спуска с мини-пакетом. Алгоритм обратного распространения вычисляет градиент функции стоимости на одном мини-пакете. Точнее, мы используем мини-пакет примеров из обучающего набора, представленного в виде матрицы плана X и вектора ассоциированных меток класса y. Сеть вычисляет слой скрытых признаков H = max{0, XW (1)}. Для простоты в этой модели отсутствуют смещения. Мы предпо- лагаем, что язык графов включает операцию relu, которая поэлементно вычисляет max{0, Z}. Затем выдаются предсказания в виде ненормированных логарифмов веро-ятностей классов HW (2). Мы предполагаем также, что язык графов включает опера- цию cross_entropy , вычисляющую перекрестную энтропию между метками y и рас- пределением вероятности, определяемым этими ненормированными логарифмами вероятностей. Результат вычисления перекрестной энтропии определяет стоимость J MLE. Минимизация перекрестной энтропии дает оценку максимального правдоподо- бия классификатора. Но, чтобы сделать пример более реалистичным, мы включили еще член регуляризации. Общая стоимость равна (6.56) и состоит из перекрестной энтропии и члена снижения весов с коэффициентом λ. Граф вычислений показан на рис. 6.11. Граф вычислений градиента в этом примере настолько велик, что и рисовать, и чи- тать его утомительно. Это наглядная демонстрация одного из преимуществ алгорит-ма обратного распространения: он автоматически генерирует градиенты, ручной вы-вод которых хотя и не представляет принципиальных трудностей, но требует много времени. Мы можем составить приблизительное представление о поведении алгоритма об- ратного распространения, взглянув на граф прямого распространения на рис. 6.11. Для обучения нам нужно вычислить ∇ W(1) J и ∇W(2) J. Пройти назад от J к весам можно по двум путям: через стоимость перекрестной энтропии и через стоимость снижения весов. Путь через стоимость снижения весов относительно прост; он всегда вносит вклад 2λW (i) в градиент по W(i). Другой путь – через стоимость перекрестной энтропии – несколько сложнее. Обо- значим G градиент по ненормированным логарифмам вероятностей U(2), предос- тавляемым операцией cross_entropy . Алгоритм обратного распространения должен теперь исследовать две ветви. На более короткой он прибавляет H⏉G к градиенту W(2), применяя правило обратного распространения для второго аргумента опера- ции умножения матриц. Вторая ветвь соответствует более длинной цепочке, идущей на рисунке вниз. Сначала алгоритм вычисляет ∇ H J = GW(2)⏉, применяя правило об-\n--- Страница 193 ---\n192  Г лубокие сети прямого распространения ратного распространения для первого аргумента операции матричного умножения. Затем применяется правило обратного распространения операции relu, чтобы обну- лить компоненты градиента, соответствующие тем элементам U(1), которые меньше 0. Обозначим результат G′. На последнем шаге правило обратного распространения применяется ко второму аргументу операции matmul , в результате чего к градиенту W(1) прибавляется X⏉G′. J JMLE U(2)y H U(1) X W(1)U(3)u(4)W(2)U(5)u(6)u(7) λu(8)+ +× sumsum sqrsqr matmulrelumatmulcross_entropy Рис. 6.11  Граф вычислений, используемый для вычисления стоимости обучения в примере МСП с одним скрытым слоем, перекрестной энтропией в качестве функции потерь и регуляризацией в форме снижения весов После того как все градиенты вычислены, для обновления параметров можно при- менить алгоритм градиентного спуска или какой-нибудь другой алгоритм оптими- зации. В случае МСП вычислительная сложность определяется в первую очередь сто- имостью умножения матриц. На этапе прямого распространения мы умножаем на каждую матрицу весов, что дает O(w) операций сложения-умножения, где w – число весов. На этапе обратного распространения мы умножаем на транспонированные ма-трицы весов, стоимость этой операции такая же. Потребление оперативной памяти определяется необходимостью хранить входные аргументы для функции нелинейно-сти скрытого слоя. Эти значения хранятся с момента вычисления и до момента, когда на обратном проходе мы вернемся в ту же точку. Таким образом, объем необходимой памяти составляет O(mn h), где m – количество примеров в мини-пакете, а nh – коли- чество скрытых слоев. 6.5.8. Осложнения Наше описание алгоритма обратного распространения проще, чем в практических реализациях.\n--- Страница 194 ---\nОбратное распространение и другие алгоритмы дифференцирования  193 Как уже было сказано, при определении операции мы ограничились функциями, возвращающими один тензор. Большинство программных реализаций вынуждено поддерживать операции, возвращающие более одного тензора. Например, если мы хотим вычислить как максимальный элемент тензора, так и его индекс, то лучше это делать за один проход по памяти, поэтому ради эффективности процедуру следует реализовать как одну операцию с двумя выходами. Мы не описали, как управлять потреблением памяти на этапе обратного распро- странения. Алгоритм обратного распространения включает сложение многих тензо-ров. При наивной реализации каждый тензор вычислялся бы по отдельности, а сум- мирование производилось бы на втором шаге. Но при этом потребляется очень много памяти, чего можно избежать, если завести один буфер и прибавлять к нему каждое значение по мере вычисления. В практических реализациях обратного распространения необходимо также об- рабатывать разные типы данных: 32- или 64-разрядные с плавающей точкой, целые и т. д. Стратегию работы с каждым типом нужно тщательно спроектировать. В некоторых операциях встречаются неопределенные градиенты, поэтому важно отслеживать такие случаи и устанавливать, определен запрошенный пользователем градиент или нет. Есть и другие технические детали, осложняющие дифференцирование. Они не яв- ляются непреодолимыми, в этой главе мы описали основные средства, необходимые для вычисления производных, но важно знать о существовании всяческих нюансов. 6.5.9. Дифференцирование за пределами сообщества глубокого обучения Глубокое обучение оказалось в какой-то степени изолировано от более широкого сообщества специалистов по информатике и разрабатывало собственные традиции в отношении дифференцирования. В более общей области автоматического диф- ференцирования изучается вопрос об алгоритмическом вычислении производных. Описанный выше алгоритм обратного распространения – лишь один из подходов к автоматическому дифференцированию. Это частный случай более широкого класса методов, имеющих общее название обратное аккумулирование (reverse mode accu- mulation). В других подходах подвыражения в правиле дифференцирования сложной функции вычисляются в различном порядке. Вообще говоря, определение порядка вычислений, при котором стоимость вычислений минимальна, – трудная задача. За- дача о нахождении оптимальной последовательности операций вычисления градиен- та является NP-полной (Naumann, 2008) в том смысле, что может потребовать упро- щения алгебраических выражений до наименее затратной формы. Например, пусть имеются переменные p 1, p2, …, pn, представляющие вероятности, и переменные z1, z2, …, zn, представляющие ненормированные логарифмы вероятно- стей. Определим (6.57) т. е. функцию softmax, вычисление которой включает потенцирование, суммиро- вание и деление, и построим функцию потерь на основе перекрестной энтропии J = –Σi pi log qi. Математик заметит, что производная J по zi имеет очень простой вид:\n--- Страница 195 ---\n194  Г лубокие сети прямого распространения qi – pi. Но алгоритм обратного распространения не может упростить градиент таким образом и будет распространять градиенты через все операции логарифмирования и потенцирования, присутствующие в исходном графе. Некоторые библиотеки, на- пример Theano (Bergstra et al., 2010; Bastien et al., 2012), умеют выполнять такого рода алгебраические подстановки, чтобы улучшить граф, предложенный чистым алгорит-мом обратного распространения. Если граф прямого распространения 𝒢 содержит единственную выходную вер- шину, и каждую частную производную ∂u (i)/∂u(j) можно вычислить за постоянное время, то алгоритм обратного распространения гарантирует, что объем вычислений при вычислении градиентов имеет такой же порядок, как при прямом вычислении: это видно из алгоритма 6.2, поскольку в рекурсивной формулировке правила диф- ференцирования сложной функции (6.49) каждая локальная частная производная ∂u (i)/∂u(j) должна быть вычислена только один раз вместе с ассоциированным с ней умножением и сложением. Следовательно, общая вычислительная сложность со- ставляет O(число ребер). Ее теоретически можно уменьшить, если удастся упро- стить граф вычислений, построенный алгоритмом обратного распрост ранения, но это NP-полная задача. В библиотеках Theano и TensorFlow делаются попытки ите- ративно упростить граф, применяя эвристики, основанные на сравнении с извест- ными типами упрощения. Мы определили обратное распространение только для вычисления градиента скалярного выхода, но это определение можно обобщить и на вычисление якобиана (либо k разных скалярных вершин графа, либо тензор- нозначной вершины, содержащей k значений). Наивная реализация потребовала бы в k раз больше вычислений: для каждой внутренней скалярной вершины ис- ходного прямого графа вычислялось бы k градиентов вместо одного. Если число выходов в графе больше числа входов, то иногда предпочтительнее другая форма автоматического дифференцирования – с прямым аккумулированием (forward mode accumulation). Прямое аккумулирование было предложено для вычисления градиентов в режиме реального времени в рекуррентных сетях, см., например, Wil- liams and Zipser, 1989. При таком подходе удается также избежать хранения значе-ний и градиентов для всего графа, пожертвовав частью вычислительной эффектив- ности ради памяти. Связь между прямым и обратным режимами аккумулирования аналогична связи между умножением слева и справа при перемножении последо- вательности матриц: ABCD. (6.58) Можно считать, что это матрицы Якоби. Например, если D – вектор-столбец, а A содержит много строк, то в графе будет один выход и много входов. Если выпол- нять умножения от конца к началу, то вычислять нужно будет только произведения мат рицы на вектор. Это соответствует обратному аккумулированию. Напротив, если умно жать слева направо, то нужно будет вычислять произведения матрицы на матри- цу, и все вычисление окажется намного дороже. Однако если число строк A меньше числа столбцов D, то дешевле выполнять умножение слева направо, что соответству- ет прямому аккумулированию. Во многих сообществах, не связанных с машинным обучением, принято писать код дифференцирования на традиционном языке программирования, например Py-thon или C, и автоматически сгенерированная программа применяется к функциям,\n--- Страница 196 ---\nОбратное распространение и другие алгоритмы дифференцирования  195 написанным на том же языке. Но в глубоком обучении графы вычислений обычно представляются с помощью явных структур данных, создаваемых специальными библиотеками. У такого подхода есть недостаток: разработчик библиотеки должен определить методы bprop для каждой операции, а пользователь ограничен лишь теми операциями, которые определил автор. Однако у него есть и достоинство: для каждой операции можно написать специализированные правила обратного распространения, что позволяет повысить быстродействие и устойчивость неочевидными способами, которые автоматическая процедура вряд ли смогла бы повторить. Таким образом, обратное распространение – не единственный и не оптимальный способ вычисления градиента, но это удобный на практике метод, который удовлет-воряет потребности сообщества машинного обучения. В будущем, когда специали- сты-практики будут лучше знать о достижениях общей теории автоматического диф- ференцирования, технология дифференцирования для глубоких сетей, возможно, усовершенствуется. 6.5.10. Производные высшего порядка В некоторых программных системах поддерживается использование производных высшего порядка. Среди библиотек глубокого обучения этим отличаются как ми-нимум Theano и TensorFlow. В этих библиотеках для описания производных ис- пользуется та же структура данных, что для описания исходной дифференцируемой функции. Поэтому механизм символьного дифференцирования можно применить к производным. В контексте глубокого обучения редко приходится вычислять одну вторую произ- водную скалярной функции. Обычно нас интересуют свойства матрицы Гессе. Если имеется функция f : ℝ n ⟶ ℝ, то ее матрица Гессе имеет размер n×n. В типичном при- ложении машинного обучения n – это количество параметров модели, которое легко может исчисляться миллиардами. Поэтому представить матрицу Гессе целиком не-реально. Вместо явного вычисления гессиана в глубоком обучении обычно используют методы Крылова. Это набор итеративных приемов выполнения различных опера- ций, например приближенного обращения матрицы или нахождения ее собственных значений и собственных векторов, с использованием только умножения матрицы на вектор. Чтобы применить методы Крылова к гессиану, нужно только уметь вычислять про- изведение матрицы Гессе H и произвольного вектора v. Сделать это просто (Christian- son, 1992): Hv = ∇ x[(∇x f(x))⏉v]. (6.59) Оба градиента в этом выражении можно вычислить автоматически с помощью подходящей библиотеки. Отметим, что внешний градиент применяется к внутренне- му градиенту функции. Если сам вектор v порожден графом вычислений, то программе автоматического дифференцирования необходимо сказать, чтобы она не дифференцировала граф, по-рождающий v. Обычно вычислять гессиан не рекомендуется, но можно обойтись произведениями гессиана на вектор. Просто вычисляется He (i) для всех i = 1, …, n, где e(i) – унитарный вектор, в котором ei(i) = 1, а все остальные элементы равны 0.\n--- Страница 197 ---\n196  Г лубокие сети прямого распространения 6.6. Исторические замечания Сети прямого распространения можно рассматривать как эффективный способ ап- проксимации функций, основанный на использовании градиентного спуска для ми-нимизации ошибки. С этой точки зрения, современные сети прямого распростране- ния – кульминация многовекового развития общей теории аппроксимации. Правило дифференцирования сложной функции, лежащее в основе алгоритма об- ратного распространения, было открыто в XVII веке (Leibniz, 1676; L’Hôpital, 1696). Математический анализ и алгебра с давних пор использовались для решения задач оптимизации в замкнутой форме, но метод градиентного спуска как способ итератив- ной аппроксимации решения задач оптимизации появился только в XIX веке (Cau- chy, 1847). Начиная с 1940-х годов, методы аппроксимации функций использовались в моде- лях машинного обучения, в частности в перцептроне. Однако ранние модели были линейными. Критики, в т. ч. Марвин Минский, отмечали несколько изъянов в семей- стве линейных моделей, например невозможность обучить функцию XOR, и это при- вело к отрицанию всего подхода на основе нейронных сетей. Для обучения нелинейных функций понадобилось разработать многослойный перцептрон и средства вычисления градиентов. Эффективные применения правила дифференцирования сложной функции, основанные на динамическом программи-ровании, начали появляться в 1960–1970-е годы, в основном в задачах автоматиче- ского управления (Kelley, 1960; Bryson and Denham, 1961; Dreyfus, 1962; Bryson and Ho, 1969; Dreyfus, 1973), но также и в анализе чувствительности (Linnainmaa, 1976). В работе Werbos (1981) описано, как применить эти методы к обучению искусствен- ных нейронных сетей. В конечном итоге идея получила практическое воплощение, после того как ее несколько раз переоткрывали в разных формах (LeCun, 1985; Parker, 1985; Rumelhart et al., 1986a). В книге «Parallel Distributed Processing» представлены результаты первых успешных экспериментов с алгоритмом обратного распростране- ния. Ее глава, написанная Румельхартом с соавторами (Rumelhart et al., 1986b), стала значительным вкладом в популяризацию обратного распространения и ознаменова- ла начало периода очень активных исследований по многослойным нейронным се-тям. Идеи, выдвинутые авторами книги, в особенности Румельхартом и Хинтоном, выходят далеко за рамки обратного распространения. Среди них ключевые идеи о возможности вычислительной реализации некоторых ключевых аспектов познания и обучения, получившие собирательное название «коннекционизм» из-за той важно- сти, которую адепты этой школы придавали связям между нейронами как органами, отвечающими за обучение и память. В частности, эти идеи включают понятие рас- пределенного представления (Hinton et al., 1986). На волне успехов алгоритма обратного распространения исследования в области нейронных сетей обрели популярность, достигшую пика в начала 1990-х годов. Затем им на смену пришли другие методы машинного обучения, и так продолжалось до воз- рождения современного глубокого обучения в 2006 году. Основные идеи, лежащие в основе сетей прямого распространения, не сильно из- менились с 1980-х годов. По-прежнему используются все тот же алгоритм обратно- го распространения и те же подходы к градиентному спуску. Повышением качества работы, имевшим место в промежутке между 1986 и 2015 годом, нейронные сети обязаны в основном двум факторам. Во-первых, благодаря более крупным наборам\n--- Страница 198 ---\nИсторические замечания  197 данных статистическое обобщение перестало быть серьезным препятствием на пути развития нейронных сетей. Во-вторых, сами нейронные сети стали гораздо больше благодаря более мощным компьютерам и улучшению программной инфраструктуры. Некоторые алгоритмические изменения также заметно повысили качество сетей. Одним из таких изменений стала замена среднеквадратической ошибки семей- ством функций потерь на основе перекрестной энтропии. Среднеквадратическая ошибка была популярна в 1980-е и 1990-е годы, но постепенно ее вытеснили идеи перекрестной энтропии и принцип максимального правдоподобия, распространив- шиеся среди специалистов по статистике и машинному обучению. Использование потерь в форме перекрестной энтропии заметно повысило качество моделей с сиг- моидой и softmax в роли функций активации, которые раньше – когда потери из- мерялись среднеквадратической ошибкой – страдали от насыщения и медленного обучения. Еще одно важное алгоритмическое изменение, резко улучшившее качество сетей прямого распространения, – замена сигмоидных скрытых блоков кусочно-линейны- ми, например блоками линейной ректификации. Ректификация с использованием функции max{0, z} появилась еще в ранних моделях нейронных сетей и восходит, по меньшей мере, к когнитрону и неокогнитрону (Fukushima, 1975, 1980). Но тог- да не использовались блоки линейной ректификации, а вместо этого ректификация применялась к нелинейным функциям. Несмотря на популярность ректификации в ранних моделях, в 1980-е годы ее почти всюду заменили сигмоиды, поскольку они лучше работают в очень малых нейронных сетях. В начале 2000-х блоков линейной ректификации старательно избегали из-за какой-то суеверной боязни использовать функции активации, недифференцируемые в некоторых точках. Положение начало меняться в 2009 году. В работе Jarrett et al. (2009) было отмечено, что «использова- ние ректифицирующей нелинейности – самый важный фактор улучшения качества системы распознавания» наряду с другими аспектами проектирования архитектуры нейронной сети. В работе Jarrett et al. (2009) также отмечалось, что для небольших наборов данных использование ректифицирующих нелинейностей даже важнее, чем обучение весов скрытых слоев. Случайных весов достаточно для распространения полезной инфор-мации по сети с линейной ректификацией, что позволяет классифицирующему вы- ходному слою обучаться отображению различных векторов признаков на идентифи-каторы классов. Если доступно больше данных, то процесс обучения начинает извлекать так много полезных знаний, что превосходит по качеству случайным образом выбранные пара-метры. В работе Glorot et al. (2011a) показано, что обучение гораздо легче проходит в ректифицированных линейных сетях, чем в глубоких сетях, для которых функ- ции активации характеризуются кривизной или двусторонним насыщением. Бло-ки линейной ректификации представляют также исторический интерес, поскольку демонстрируют, что нейробиология по-прежнему оказывает влияние на разработку алгоритмов глубокого обучения. В работе Glorot et al. (2011a) в обоснование блоков линейной ректификации выдвигаются биологические соображения. Ректификация на полупрямой была предложена для улавливания следующих свойств биологиче-ских нейронов: 1) для некоторых входных сигналов биологические нейроны вообще неактивны; 2) для некоторых входных сигналов выходной сигнал биологического нейрона пропорционален входному сигналу; 3) большую часть времени биологиче-\n--- Страница 199 ---\n198  Г лубокие сети прямого распространения ские нейроны пребывают в состоянии неактивности (т. е. характеризуются разре- женной активацией). Когда в 2006 году началось возрождение глубокого обучения, сети прямого рас- пространения по-прежнему пользовались дурной репутацией. В период с 2006 по 2012 год превалировало мнение, что такие сети не могут работать хорошо, если им не ассистируют другие модели, например вероятностные. Сегодня известно, что при наличии адекватных ресурсов и инженерных навыков сети прямого распростране- ния работают отлично. В наши дни обучение сетей прямого распространения гради- ентными методами служит инструментом для разработки вероятностных моделей, как, например, вариационный автокодировщик и порождающие состязательные сети, описанные в главе 20. Начиная с 2012 года обучение сетей прямого распростране- ния градиентными методами перестало считаться ненадежной технологией, которая должна обязательно поддерживаться другими методами. Теперь это мощная техно-логия, применимая ко многим задачам машинного обучения. В 2006 году сообщество использовало обучение без учителя для поддержки обучения с учителем, а теперь – по иронии судьбы – все обстоит «с точностью до наоборот». У сетей прямого распространения есть еще не раскрытый потенциал. Мы ожида- ем, что в будущем они найдут применение во многих других задачах и что благодаря достижениям в разработке алгоритмов оптимизации и проектирования моделей их качество еще возрастет. В этой главе мы в общих чертах описали семейство моделей на основе нейронных сетей. А в последующих вплотную займемся их использовани- ем – расскажем, как их регуляризировать и обучать.",
      "debug": {
        "start_page": 151,
        "end_page": 199
      }
    },
    {
      "name": "Глава 7. Регуляризация в глубоком обучении 199",
      "content": "--- Страница 200 --- (продолжение)\nГлава 7 Регуляризация в глубоком обучении Центральная проблема машинного обучения – как создать алгоритм, который будет хорошо работать не только на обучающих, но и на новых данных. Многие используе- мые стратегии специально предназначены для уменьшения ошибки тестирования, быть может, за счет увеличения ошибки обучения. Эти стратегии известны под об-щим названием «регуляризация». В распоряжении специалиста по глубокому обуче- нию много вариантов регуляризации. На самом деле разработка все более эффектив-ных стратегий регуляризации – одно из основных направлений исследований в этой области. В главе 5 были введены понятия обобщения, недообучения, переобучения, сме- щения, дисперсии и регуляризации. Если вы пока незнакомы с ними, ознакомьтесь с главой 5, прежде чем продолжать чтение. В этой главе мы опишем регуляризацию подробно, уделив особое внимание стра- тегиям регуляризации глубоких моделей или моделей, которые используются в каче- стве их строительных блоков. В некоторых разделах этой главы речь идет о стандартных концепциях машинного обучения. Если вы уже знакомы с ними, можете спокойно пропустить эти разделы. Но большая часть главы посвящена обобщению базовых концепций на случай ней-ронных сетей. В разделе 5.2.2 мы определили регуляризацию как «любую модификацию алгорит- ма обучения, предпринятую с целью уменьшить его ошибку обобщения, не уменьшая ошибки обучения». Существует много стратегий регуляризации. В одних налагаются дополнительные ограничения на модель машинного обучения, например на значе-ния параметров. В других в целевую функцию включаются дополнительные члены, которые можно рассматривать как мягкие ограничения на значения параметров. При правильном выборе такие дополнительные ограничения и штрафы могут при- водить к повышению качества на тестовом наборе. Иногда ограничения и штрафы проектируются, чтобы выразить предпочтение более простому классу моделей и тем повысить обобщаемость. А иногда они необходимы, чтобы преобразовать недоопре- деленную задачу в определенную. В других вариантах регуляризации, называемых ансамблевыми методами, комбинируется несколько гипотез, объясняющих обучаю-щие данные. В контексте глубокого обучения большинство стратегий регуляризации основано на регуляризирующих оценках. Смысл регуляризация оценки – в увеличении сме-\nГлава 7 Регуляризация в глубоком обучении Центральная проблема машинного обучения – как создать алгоритм, который будет хорошо работать не только на обучающих, но и на новых данных. Многие используе- мые стратегии специально предназначены для уменьшения ошибки тестирования, быть может, за счет увеличения ошибки обучения. Эти стратегии известны под об-щим названием «регуляризация». В распоряжении специалиста по глубокому обуче- нию много вариантов регуляризации. На самом деле разработка все более эффектив-ных стратегий регуляризации – одно из основных направлений исследований в этой области. В главе 5 были введены понятия обобщения, недообучения, переобучения, сме- щения, дисперсии и регуляризации. Если вы пока незнакомы с ними, ознакомьтесь с главой 5, прежде чем продолжать чтение. В этой главе мы опишем регуляризацию подробно, уделив особое внимание стра- тегиям регуляризации глубоких моделей или моделей, которые используются в каче- стве их строительных блоков. В некоторых разделах этой главы речь идет о стандартных концепциях машинного обучения. Если вы уже знакомы с ними, можете спокойно пропустить эти разделы. Но большая часть главы посвящена обобщению базовых концепций на случай ней-ронных сетей. В разделе 5.2.2 мы определили регуляризацию как «любую модификацию алгорит- ма обучения, предпринятую с целью уменьшить его ошибку обобщения, не уменьшая ошибки обучения». Существует много стратегий регуляризации. В одних налагаются дополнительные ограничения на модель машинного обучения, например на значе-ния параметров. В других в целевую функцию включаются дополнительные члены, которые можно рассматривать как мягкие ограничения на значения параметров. При правильном выборе такие дополнительные ограничения и штрафы могут при- водить к повышению качества на тестовом наборе. Иногда ограничения и штрафы проектируются, чтобы выразить предпочтение более простому классу моделей и тем повысить обобщаемость. А иногда они необходимы, чтобы преобразовать недоопре- деленную задачу в определенную. В других вариантах регуляризации, называемых ансамблевыми методами, комбинируется несколько гипотез, объясняющих обучаю-щие данные. В контексте глубокого обучения большинство стратегий регуляризации основано на регуляризирующих оценках. Смысл регуляризация оценки – в увеличении сме-\n--- Страница 201 ---\n200  Регуляризация в глубоком обучении щения в обмен на уменьшение дисперсии. Эффективным считается регуляризатор, который находит выгодный компромисс, т. е. значительно уменьшает дисперсию, не слишком увеличивая смещение. Обсуждая обобщение и переобучение в главе 5, мы выделили три ситуации, когда обучаемое семейство моделей либо (1) не включает ис- тинный процесс, порождающий данные, – это соответствует недообучению и прово- цирует смещение, либо (2) соответствует истинному порождающему процессу, либо (3) включает как истинный порождающий процесс, так и много других потенциаль- ных процессов, – это режим переобучения, когда в ошибке оценивания превалирует дисперсия, а не смещение. Цель регуляризации – перевести модель из третьего режи- ма во второй. На практике чрезмерно сложное семейство моделей не обязательно включает не то что целевую функцию или истинный порождающий процесс, но даже хорошее при-ближение к тому или другому. Мы почти никогда не имеем доступа к истинному по- рождающему процессу, поэтому не можем знать наверняка, включает оцениваемое семейство этот процесс или нет. Однако алгоритмы глубокого обучения по большей части применяются в предметных областях, где истинный порождающий процесс почти наверняка не входит в семейство моделей. Алгоритмы глубокого обучения обычно используются в чрезвычайно сложных областях – обработка изображений, звуковых последовательностей и текстов, где истинный порождающий процесс, по существу, сводится к моделированию всего универсума. Не будет таким уж преуве- личением сказать, что мы всегда пытаемся воткнуть квадратный колышек (порожда-ющий процесс) в круглое отверстие (наше семейство моделей). Это означает, что управление сложностью модели – не просто поиск модели пра- вильного размера с правильным числом параметров. Вместо этого мы могли обнару- жить – и в реальных приложениях глубокого обучения так почти всегда и бывает – что наилучшая эмпирическая модель (в смысле минимизации ошибки обобщения) – это большая модель, подходящим образом регуляризированная. Далее мы дадим обзор нескольких стратегий создания большой регуляризирован- ной глубокой модели. 7.1. Штрафы по норме параметров Регуляризация применялась в течение десятков лет до изобретения глубокого обуче- ния. Такие линейные модели, как линейная регрессия и логистическая регрессия, до- пускают простые и эффективные стратегии регуляризации. Многие подходы к регуляризации основаны на ограничении емкости моделей (нейронных сетей, линейной регрессии или логистической регрессии) путем прибав-ления штрафа по норме параметра Ω(θ) к целевой функции J. Мы будем обозначать регуляризованную целевую функцию J~: J~(θ; X, y) = J(θ; X, y) + αΩ(θ), (7.1) где α ∈ [0, ∞) – гиперпараметр, задающий вес члена Ω, штрафующего по норме, от- носительно стандартной целевой функции J. Если α равен 0, то регуляризация отсут- ствует. Чем больше значение α, тем сильнее регуляризация. Минимизируя регуляризованную целевую функцию J~, наш алгоритм обучения одновременно уменьшает исходную целевую функцию J на обучающих данных и не- которую меру величины параметров θ (или какого-то подмножества параметров).\n--- Страница 202 ---\nШтрафы по норме параметров  201 В зависимости от выбора нормы параметров предпочтительными будут те или иные решения. В этом разделе мы обсудим влияние различных норм, используемых для штрафования параметров модели. Прежде чем с головой погрузиться в обсуждение различных норм с точки зрения регуляризации, отметим, что в нейронных сетях мы обычно предпочитаем штрафо- вать по норме только веса аффинного преобразования в каждом слое, оставляя сме- щения нерегуляризированными. Для точного подбора смещений, как правило, тре- буется меньше данных, чем для весов. Каждый вес описывает взаимодействие двух переменных. Для правильного подбора веса требуются результаты наблюдений этих переменных в разных обстоятельствах. Каждое смещение контролирует только одну переменную. Поэтому, игнорируя регуляризацию смещений, мы не слишком сильно увеличим дисперсию. Кроме того, регуляризация параметров смещения может стать причиной значительного недообучения. Далее вектор w будет обозначать все веса, на которые распространяется штраф по норме, а вектор θ – все параметры, включая как w, так и нерегуляризированные. В контексте нейронных сетей иногда желательно использовать штрафы с разными коэффициентами α в каждом слое. Поскольку подбор правильных значений несколь- ких гиперпараметров иногда обходится дорого, все равно разумно использовать одно и то же снижение весов во всех слоях, просто чтобы уменьшить размер пространства поиска. 7.1.1. Регуляризация параметров по норме L2 В разделе 5.2.2 мы уже встречали один из самых простых и распространенных видов штрафа параметров – по норме L2, – который часто называют снижением весов. Цель такой стратегии регуляризации – выбирать веса, близкие к началу координат1, за счет прибавления к целевой функции члена регуляризации Ω(θ) = 1/2||w||22. В других науч- ных сообществах регуляризацию по норме L2 называют также гребневой регрессией, или регуляризацией Тихонова. Получить качественное представление о поведении регуляризации методом сни- жения весов можно, изучив градиент регуляризированной целевой функции. Для простоты опустим параметр смещения, т. е. будем считать, что θ совпадает с w. Пол- ная целевая функция в такой модели имеет вид: J~(w; X, y) = (α/2)w ⏉w + J(w; X, y), (7.2) а градиент по параметрам: ∇w J~(w; X, y) = αw + ∇w J(w; X, y). (7.3) Один шаг обновления весов с целью уменьшения градиента имеет вид: w ⟵ w – ε(αw + ∇w J(w; X, y)). (7.4) 1 В общем случае мы могли бы путем регуляризации отдавать предпочтение параметрам вблизи любой наперед заданной точки пространства и, как ни странно, получить эффект регуляризации. Но результаты оказываются лучше, если эта точка близка к истинной, а нуль является разумным значением по умолчанию, когда мы не знаем, положительно истинное значение или отрицательно. Поскольку в большинстве случае при регуляризации стремятся сделать параметры близкими к нулю, мы будем рассматривать только этот частный случай.\n--- Страница 203 ---\n202  Регуляризация в глубоком обучении То же самое можно переписать в виде: w ⟵ (1 – εα)w – ε∇w J(w; X, y)). (7.5) Как видим, добавление члена сложения весов изменило правило обучения: теперь мы на каждом шаге умножаем вектор весов на постоянный коэффициент, меньший 1, перед тем как выполнить стандартное обновление градиента. Итак, мы описали, что происходит на одном шаге. А в целом в процессе обучения? Еще упростим анализ, предположив квадратичную аппроксимацию целевой функции в окрестности того значения весов, при котором достигается минимальная стоимость обучения без регуляризации, w* = arg minw J(w). Если целевая функция действительно квадратичная, как в случае модели линейной регрессии со среднеквад- ратической ошибкой, то такая аппроксимация идеальна. Аппроксимация J� описыва- ется формулой: Jˆ(θ) = J(w*) + 1/2(w – w*)⏉H(w – w*), (7.6) где H – матрица Гессе J относительно w, вычисленная в точке w*. В этой квадратичной аппроксимации нет члена первого порядка, потому что w*, по определению, точка ми- нимума, в которой градиент обращается в нуль. Из того, что w* – точка минимума J, следует также, что матрица H положительно полуопределенная. Минимум J� достигается там, где градиент ∇w J�(w) = H(w – w*) (7.7) равен 0. Чтобы изучить эффект снижения весов, модифицируем уравнение (7.7), прибавив градиент снижения весов. Теперь мы можем найти из него минимум регуляризиро-ванного варианта J�. Обозначим w~ положение точки минимума. αw~ + H(w~ – w * ) = 0. (7.8) (H + αI)w~ = Hw* . (7.9) w~ = (H + αI)–1Hw* . (7.10) Когда α стремится к 0, регуляризированное решение w~ стремится к w*. Но что про- исходит, когда α возрастает? Поскольку матрица H вещественная и симметричная, мы можем разложить ее в произведение диагональной матрицы Λ и ортогональной матрицы собственных векторов Q: H = QΛQ⏉. Подставляя это разложение в уравне- ние (7.10), получаем w~ = (QΛQ⏉ + αI)–1QΛQ⏉w* , (7.11) = [Q(Λ + αI)Q⏉]–1QΛQ⏉w* , (7.12) = Q(Λ + αI)–1ΛQ⏉w* . (7.13) Мы видим, что результатом снижения весов является масштабирование w* вдоль направлений собственных векторов H. Точнее, компонента w*, параллельная i-му соб- ственному вектору H, умножается на коэффициент λi /(λi + α). (Этот вид масштабиро- вания ранее был проиллюстрирован на рис. 2.3.) Вдоль направлений, для которых собственные значения H относительно велики, например когда λi ≫ α, эффект регуляризации сравнительно мал. Те же компоненты, для которых λi ≪ α, сжимаются почти до нуля. Это показано на рис. 7.1.\n--- Страница 204 ---\nШтрафы по норме параметров  203 w~w* w1w2 Рис. 7.1  Иллюстрация влияния регуляризации по норме L2 (снижения весов) на значение оптимального вектора w. Сплошными эллипсами пред- ставлены линии равных значений нерегуляризированной целевой функции, а пунктирными – линии равных значений L 2-регуляризатора. В точке w~ эти конкурирующие цели достигают равновесия. По первому измерению соб-ственное значение гессиана J мало. Целевая функция слабо растет при удалении от w * по горизонтали. Поскольку целевая функция не выказывает сильного предпочтения этому направлению, регуляризатор дает для него значительный эффект. Регуляризатор подтягивает w 1 ближе к нулю. По вто- рому направлению целевая функция очень чувствительна к удалению от w*. Соответствующее собственное значение велико, что указывает на сильную кривизну. Поэтому снижение весов влияет на положение w 2 сравнительно слабо Относительно неизменными остаются только те направления, в которых пара- метры дают сильный вклад в уменьшение целевой функции. Если направление не дает вклада в уменьшение целевой функции, то собственное значение гессиана мало, т. е. движение в этом направлении не приводит к заметному возрастанию градиента. Компоненты вектора весов, соответствующие таким малозначимым направлениям, снижаются почти до нуля благодаря использованию регуляризации в ходе обучения. До сих пор мы обсуждали снижение весов в терминах воздействия на оптимизацию абстрактной квадратичной функции стоимости. Но как эти эффекты проявляются конкретно в машинном обучении? Это можно выяснить на примере изучения линей- ной регрессии – модели, в которой истинная функция стоимости квадратичная и по- тому поддается проведенному выше анализу. Повторяя те же рассуждения, мы полу-чим для этого частного случая результат, сформулированный в терминах обучающих данных. Для линейной регрессии функция стоимости равна сумме квадратов ошибок: (Xw – y) ⏉(Xw – y). (7.14) После добавления L2-регуляризации целевая функция принимает вид: (Xw – y)⏉(Xw – y) + 1/2αw⏉w. (7.15) В результате нормальные уравнения, из которых ищется решение: w = (X⏉X)–1X⏉y (7.16)\n--- Страница 205 ---\n204  Регуляризация в глубоком обучении принимают вид w = (X⏉X + αI)–1X⏉y. (7.17) Матрица X⏉X в уравнении (7.16) пропорциональна ковариационной матрице (1/m)X⏉X. Применение L2-регуляризации заменяет эту матрицу на (X⏉X + αI)–1 в уравнении (7.17). Новая матрица отличается от исходной только прибавлением α ко всем диагональным элементам. Диагональные элементы этой матрицы соответ- ствуют дисперсии каждого входного признака. Таким образом, L2-регуляризация за- ставляет алгоритм обучения «воспринимать» вход X как имеющий более высокую дисперсию и, следовательно, уменьшать веса тех признаков, для которых ковариация с выходными метками мала, по сравнению с добавленной дисперсией. 7.1.2. L1-регуляризация Регуляризация по норме L2 – самая распространенная форма снижения весов, но есть и другие способы штрафовать за величину параметров модели. Одним из них явля- ется L1-регуляризация. Формально L1-регуляризация параметров модели w определяется по формуле (7.18) т. е. как сумма абсолютных величин отдельных параметров1. Обсудим влияние L1-ре- гу ляризации на простую модель линейной регрессии без параметра смещения – ту самую, что рассматривалась в ходе анализа L2-регуляризации. Особенно нас инте- ресуют различия между двумя видами регуляризации. Как и в предыдущем случае, сила регуляризации контролируется путем умножения штрафа на положительный гиперпараметр α. Таким образом, регуляризированная целевая функция J~(w; X, y) описывается формулой J~(w; X, y) = α ||w|| 1 + J(w; X, y), (7.19) а ее градиент (точнее, частичный градиент) равен ∇w J~(w; X, y) = α sign(w) + ∇w J(w; X, y), (7.20) где sign(w) означает, что функция sign применяется к каждому элементу w. Из уравнения (7.20) сразу видно, что эффект L1-регуляризации совсем не такой, как L2-регуляризации. Теперь вклад регуляризации в градиент уже не масштабирует- ся линейно с ростом каждого wi, а описывается постоянным слагаемым, знак которого совпадает с sign(wi). Одним из следствий является тот факт, что мы уже не получим изящных алгебраических выражений квадратичной аппроксимации J(X; y, w), как в случае L2-регуляризации. В нашей простой линейной модели имеется квадратичная функция стоимости, ко- торую можно представить ее рядом Тейлора. Можно вместо этого считать, что это первые члены ряда Тейлора, аппроксимирующие функцию стоимости более сложной модели. Градиент в этой конфигурации равен 1 Как и в случае L2-регуляризации, можно было бы сдвигать параметры не к нулю, а к какому- то значению w(o). Тогда L1-регуляризация свелась бы к добавлению члена Ω(θ) = || w – w(o)||1 = = Σi|wi – wi (o)|.\n--- Страница 206 ---\nШтрафы по норме параметров  205 ∇w J�(w) = H(w – w*), (7.21) где H – снова матрица Гессе J относительно w, вычисленная в точке w*. Поскольку штраф по норме L1 не допускает простого алгебраического выражения в случае полного гессиана общего вида, то мы сделаем еще одно упрощающее предпо- ложение: будем считать матрицу Гессе диагональной, H = diag([H1, 1, …, Hn, n]), где все Hi, i > 0. Это предположение справедливо, если данные для задачи линейной регрессии были подвергнуты предварительной обработке для устранения корреляции между входными признаками, например методом главных компонент. Нашу квадратичную аппроксимацию L1-регуляризированной целевой функции можно представить в виде суммы по параметрам: (7.22) У задачи минимизации этой приближенной функции стоимости имеется аналити- ческое решение (для каждого измерения i) вида: (7.23) Предположим, что wi* > 0 для всех i. Тогда есть два случая: 1) wi* ≤ α/Hi, i. Тогда оптимальное значение wi для регуляризированной целевой функции будет просто wi = 0. Причина в том, что вклад J(w; X, y) в регуля- ризированную целевую функцию перевешивается – в направлении i – L1-ре- гуляризацией, которая сдвигает значение wi в нуль; 2) wi* > α/Hi, i. Тогда регуляризация не сдвигает оптимальное значение wi в нуль, а просто смещает его в этом направлении на расстояние α/Hi, i. Аналогичное рассуждение проходит, когда wi* < 0, только L1-штраф увеличивает wi на α/Hi, i или обращает в 0. По сравнению с L2-регуляризацией, L1-регуляризация дает более разреженное ре - шение. В этом контексте под разреженностью понимается тот факт, что у некоторых параметров оптимальное значение равно 0. Разреженность L1-регуляризации являет- ся качественным отличием от поведения L2-регуляризации. Уравнение (7.13) дает ре- шение w~ для L2-регуляризации. Применив к нему предположение о диагональности и положительной определенности гессиана H, которое мы приняли для анализа L1-ре- гуляризации, найдем, что Если wi* было не равно 0, то и w~ i окажется не равным нулю. Это значит, что L2-регуляризация не приводит к разреженности пара- метров, тогда как в случае L1-регуляризации это возможно, если α достаточно велико. Свойство разреженности, присущее L1-регуляризации, активно эксплуатирова- лось как механизм отбора признаков, идея которого состоит в том, чтобы упростить задачу машинного обучения за счет выбора некоторого подмножества располагаемых признаков. В частности, хорошо известная модель LASSO (Tibshirani, 1995) (least absolute shrinkage and selection operator) объединяет L 1-штраф с линейной моделью и среднеквадратической функцией стоимости. Благодаря L1-штрафу некоторые веса обращаются в 0, и соответствующие им признаки отбрасываются. В разделе 5.6.1 мы видели, что многие стратегии регуляризации можно интерпре- тировать как байесовский вывод на основе оценки апостериорного максимума (MAP)\n--- Страница 207 ---\n206  Регуляризация в глубоком обучении и что, в частности, L2-регуляризация эквивалентна байесовскому выводу на основе MAP с априорным нормальным распределением весов. В случае L1-регуляризации штраф αΩ(w) = αΣi|wi|, применяемый для регуляризации функции стоимости, экви- валентен члену, содержащему логарифм априорного распределения, который макси- мизируется байесовским выводом на основе MAP , когда в качестве априорного ис- пользуется изотропное распределение Лапласа (3.26) векторов w ∈ ℝn: (7.24) С точки зрения обучения посредством максимизации относительно w, мы можем игнорировать члены log α – log 2, поскольку они зависят от w. 7.2. Штраф по норме как оптимизация с ограничениями Рассмотрим функцию стоимости, регуляризированную путем добавления штрафа по норме параметров: J~(θ; X, y) = J(θ; X, y) + αΩ(θ). (7.25) Напомним (см. раздел 4.4), что для минимизации функции при наличии ограниче- ний мы можем построить обобщенную функцию Лагранжа, состоящую из исходной целевой функции плюс набор штрафов. Каждый штраф имеет вид произведения ко-эффициента, называемого множителем Каруша–Куна–Таккера (ККТ), на функцию, показывающую, удовлетворяется ли ограничение. Если мы хотим, чтобы ограниче-ние Ω(θ) было меньше некоторой константы k, то можем определить такую обобщен- ную функцию Лагранжа: ℒ(θ, α; X, y) = J(θ; X, y)+ α(Ω(θ) – k). (7.26) Решение задачи с ограничениями имеет вид: θ * = ℒ(θ, α). (7.27) Как описано в разделе 4.4, для решения этой задачи необходимо модифицировать и θ, и α. В разделе 4.5 был приведен пример линейной регрессии с L2-ограничением. Есть также много других процедур – в одних используется метод градиентного спус- ка, в других аналитически ищутся точки, в которых градиент равен нулю, – но в лю- бом случае α должно увеличиваться, когда Ω(θ) > k, и уменьшаться, когда Ω(θ) < k. Любое положительное α побуждает Ω(θ) к уменьшению. Оптимальное значение α* поощряет уменьшение Ω(θ), но не настолько сильно, чтобы Ω(θ) оказалось меньше k. Чтобы составить представление о влиянии ограничения, зафиксируем α* и будем рассматривать задачу как функцию только от θ: θ* = ℒ(θ, α*) = J(θ; X, y) + α*Ω(θ). (7.28) Это в точности то же самое, что регуляризированная задача обучения путем мини- мизации J~. Таким образом, можно считать, что штраф по норме параметра налагает ограничение на веса. Если в качестве нормы Ω берется L2, то веса должны лежать\n--- Страница 208 ---\nШтраф по норме как оптимизация с ограничениями  207 в единичном L2-шаре. Если же Ω – это норма L1, то веса должны лежать в области с ограниченной нормой L1. Обычно нам неизвестен размер области ограничений, со- ответствующей снижению весов с коэффициентом α*, потому что значение α* не го- ворит прямо о значении k. В принципе, можно решать уравнение относительно k, но связь между k и α* зависит от вида J. Но хотя мы не знаем точный размер области ограничений, мы можем грубо управлять им, уменьшая или увеличивая α с целью увеличить или уменьшить область ограничений. Чем больше α, тем меньше область ограничений, и наоборот. Иногда мы хотим использовать явные ограничения, а не штрафы. Как описано в разделе 4.4, мы можем модифицировать алгоритм, например стохастического гра- диентного спуска, так чтобы он производил шаг спуска по J(θ), а затем выполнял об- ратное проецирование θ в ближайшую точку, для которой Ω(θ) < k. Это бывает полез- но, если мы заранее знаем, какое значение k приемлемо, и не хотим тратить времени на поиск значения α, соответствующего этому k. Еще одна причина использовать явные ограничения и обратное проецирование, а не косвенные ограничения в виде штрафов, состоит в том, что из-за штрафа про- цедура невыпуклой оптимизации может застрять в локальном минимуме, соответ- ствующем малому θ. При обучении нейронных сетей это обычно проявляется в виде сети, обучившейся с несколькими «мертвыми блоками». Так называются блоки, ко- торые мало что вносят в поведение обученной сетью функции, потому что веса всех входных или выходных сигналов очень малы. При обучении со штрафом на норму весов такие конфигурации могут оказаться локально оптимальными, даже если воз-можно значительно уменьшить J, сделав веса больше. Явные ограничения, реализо- ванные с помощью обратного проецирования, в таких случаях могут работать гораздо лучше, потому что не поощряют приближения весов к началу координат. Такие явные ограничения вступают в силу, только когда веса становятся большими и грозят выйти за пределы области ограничений. Наконец, явные ограничения на основе обратного проецирования могут быть по- лезны, потому что привносят устойчивость в процедуру оптимизации. Если скорость обучения высока, то есть риск попасть в петлю с положительной обратной связью, когда большие веса приводят к большим градиентам, а это, в свою очередь, приводит к большому обновлению весов. Если такие обновления стабильно увеличивают веса, то θ быстро отдаляется от начала координат, пока не наступит численное перепол- нение. Явные ограничения с обратным проецированием не дают таким петлям вы- зывать неограниченный рост весов. В работе Hinton et al. (2012c) рекомендуется ис- пользовать ограничения в сочетании с высокой скоростью обучения, чтобы быстрее исследовать пространство параметров без потери устойчивости. В частности, рекомендуется стратегия, предложенная в работе Srebro and Shraib- man (2005): ограничивать норму каждого столбца матрицы весов слоя нейронной сети, а не норму Фробениуса всей матрицы. Ограничение нормы каждого столбца препятствует назначению высокого веса отдельным скрытым блокам. Если преоб-разовать это ограничение в штраф в функции Лагранжа, то он был бы похож на сни- жение весов по норме L 2, только у веса каждого скрытого блока был бы отдельный множитель ККТ. Все эти множители по отдельности подвергались бы динамическо-му обновлению, так чтобы каждый скрытый блок подчинялся своему ограничению. На практике ограничения на нормы столбцов всегда реализуются с помощью явных ограничений с обратным проецированием.\n--- Страница 209 ---\n208  Регуляризация в глубоком обучении 7.3. Регуляризация и недоопределенные задачи В некоторых случаях без регуляризации просто невозможно корректно поставить за- дачу машинного обучения. Многие линейные модели в машинном обучении, в т. ч. линейная регрессия и PCA, включают обращение матрицы X⏉X. Это невозможно, если X⏉X сингулярна. Матрица может оказаться сингулярной, если порождающее распределение действительно не имеет дисперсии в некотором направлении или если в некотором направлении не наблюдается дисперсии, потому что число примеров (строк X) меньше числа входных признаков (столбцов X). В таком случае во многих вариантах регуляризации прибегают к обращению матрицы X⏉X + αI. Гарантируется, что такая регуляризированная матрица обратима. У этих линейных задач может существовать решение в замкнутой форме, если со- ответствующая матрица обратима. Может также случиться, что задача, не имеющая решения в замкнутой форме, недоопределена. Примером является применение ло- гистической регрессии к задаче, в которой классы линейно разделимы. Если вектор весов w может дать идеальную классификацию, то вектор 2w также дает идеальную классификацию, но более высокое правдоподобие. Итеративная процедура оптими-зации, например стохастический градиентный спуск, будет все время увеличивать абсолютную величину w и теоретически никогда не остановится. На практике рано или поздно веса достигнут такой величины, что произойдет переполнение, и даль- нейшее поведение зависит от того, как программист решил обрабатывать значения, не являющиеся числами. В большинстве вариантов регуляризации гарантируется сходимость итерацион- ных методов, применяемых к недоопределенным задачам. Например, в случае сни- жения весов градиентный спуск перестанет увеличивать веса, когда угловой коэффи-циент правдоподобия сравняется с коэффициентом снижения весов. Идея применения регуляризации к решению недоопределенных задач выходит за рамки одного лишь машинного обучения. Она полезна и в нескольких классических задачах линейной алгебры. В разделе 2.9 мы видели, что недоопределенную систему линейных уравнений можно решить с помощью псевдообратной матрицы Мура–Пенроуза. Напомним ее определение: X + = lim(X⏉X + αI)–1X⏉. α0 (7.29) Мы узнаём в уравнении (7.29) линейную регрессию со снижением весов. Точнее, (7.29) это предел уравнения (7.17), когда коэффициент регуляризации стремится к нулю. Поэтому псевдообращение можно интерпретировать как стабилизацию не- доопределенных задач с помощью регуляризации. 7.4. Пополнение набора данных Самый лучший способ повысить обобщаемость модели машинного обучения – обу- чить ее на большем объеме данных. Но, конечно же, на практике объем данных ограни-чен. Один из путей решения проблемы – добавить в обучающий набор искусственно сгенерированные данные. Для некоторых задач создать такие данные довольно легко. Проще всего применить этот подход к классификации. Классификатор принимает сложный многомерный вход x и сопоставляет ему идентификатор категории y. Это\n--- Страница 210 ---\nПополнение набора данных  209 означает, что для классификатора главное – инвариантность относительно широко- го спектра преобразований. Мы легко можем сгенерировать новые пары (x, y) путем различных преобразований данных x, уже имеющихся в обучающем наборе. Применение этого подхода ко многим другим задачам сталкивается с трудностя- ми. Например, сложно сгенерировать искусственные данные для задачи оценивания плотности, пока мы не знаем ее решения. Пополнение набора данных доказало высокую эффективность в конкретной за- даче классификации: распознавание объектов. Изображения характеризуются высо-кой размерностью и огромным количеством факторов изменчивости, многие из ко- торых легко смоделировать. Такие операции, как сдвиг обучающих изображений на несколько пикселей в каждом направлении, могут значительно улучшить обобщае- мость, даже если при проектировании модели уже была заложена частичная инвари-антность относительно параллельных переносов путем применения методов свертки и пулинга, описанных в главе 9. Многие другие операции, например поворот или мас- штабирование изображения, также оказались весьма эффективными. Но не следует применять преобразования, которые могут изменить правильный класс. Например, в случае распознавания символов нужно отличать «b» от «d» и «6» от «9», поэтому в таких задачах отражение относительно вертикальной оси и поворот на 180 градусов – недопустимые способы пополнения набора данных. Существуют также преобразования, относительно которых классификаторы должны быть инвариантными, но выполнить которые не так-то просто. Например, внеплоскостной поворот невозможно реализовать как простую геометрическую опе-рацию над входными пикселями. Пополнение набора данных эффективно также в задачах распознавания речи (Jait- ly and Hinton, 2013). Привнесение шума во входные данные нейронной сети (Sietsma and Dow, 1991) тоже можно рассматривать как вид пополнения данных. Для многих задач классифи-кации и даже регрессии требуется, чтобы задача была разрешима и тогда, когда дан- ные немного зашумлены. Однако, как оказалось, нейронные сети не очень устойчивы к шуму (Tang and Eliasmith, 2010). Один из путей повышения робастности нейрон- ных сетей – обучать их на данных, к которым добавлен случайный шум. Привнесение шума – часть некоторых алгоритмов обучения без учителя, например шумоподавляю- щего автокодировщика (Vincent et al., 2008). Эта идея работает и в случае, когда шум примешивается к скрытым блокам, что можно расценивать как пополнение набора данных на нескольких уровнях абстракции. В недавней работе Poole et al. (2014) по- казано, что этот подход может оказаться весьма эффективным, при условии что вели-чина шума тщательно подобрана. Прореживание, мощная стратегия регуляризации, описанная в разделе 7.12, тоже может считаться процессом конструирования новых входных данных путем умножения на шум. При сравнении результатов эталонных тестов алгоритмов машинного обучения важно принимать во внимание пополнение набора данных. Зачастую вручную спро-ектированные схемы пополнения могут кардинально уменьшить ошибку обобщения метода машинного обучения. Для сравнения качества разных алгоритмов необходи-мо ставить эксперименты в контролируемых условиях. Сравнивая алгоритм A с ал- горитмом B, следите за тем, чтобы оба алгоритма оценивались с применением од- ной и той же схемы пополнения. Предположим, что алгоритм A плохо работает на непополненном наборе данных, а алгоритм B хорошо работает, когда набор данных\n--- Страница 211 ---\n210  Регуляризация в глубоком обучении пополнен различными искусственно сгенерированными примерами. В таком случае вполне вероятно, что причиной улучшения качества стали сами искусственные пре- образования, а не особенности алгоритма B. Иногда для решения о том, правильно ли поставлен эксперимент, необходимо субъективное суждение. Например, алгоритмы машинного обучения, привносящие шум во входные данные, выполняют некий вид пополнения набора данных. Обычно универсальные операции (например, добавле-ние гауссова шума) считаются частью самого алгоритма, а операции, специфичные для конкретной предметной области (например, случайная обрезка изображения), – отдельными шагами предварительной обработки. 7.5. Робастность относительно шума В разделе 7.4 наложение шума на входные данные обосновывалось как стратегия пополнения набора данных. Для некоторых моделей добавление шума с очень ма- лой дисперсией к входу модели эквивалентно штрафованию по норме весов (Bishop, 1995a,b). В общем случае важно помнить, что привнесение шума может дать куда больший эффект, чем простое уменьшение параметров, особенно если шум примеши-вается к скрытым блокам. Подача шума на скрытые блоки – тема настолько важная, что заслуживает отдельного обсуждения; алгоритм прореживания, описанный в раз- деле 7.12, – главное развитие этого подхода. Еще один способ использования шума ради регуляризации моделей – прибавление его к весам. Эта техника применялась в основном в контексте рекуррентных нейрон- ных сетей (Jim et al., 1996; Graves, 2011). Ее можно интерпретировать как стохасти-ческую реализацию байесовского вывода весов. В байесовском подходе к обучению веса модели считаются неопределенными и представляются распределением вероят- ности, отражающим эту неопределенность. Прибавление шума к весам – практически удобный стохастический способ отразить неопределенность. Применение шума к весам можно также интерпретировать как эквивалент (при определенных допущениях) более традиционной формы регуляризации, поощряю-щей устойчивость обучаемой функции. Рассмотрим случай регрессии, когда мы хотим обучить функцию y�(x), отображающую вектор признаков x, в скаляр с ис- пользованием в качестве функции стоимости среднеквадратической ошибки между предсказаниями модели y �(x) и истинными значениями y: J = 𝔼 p(x, y)[y�(x) – y)2]. (7.30) Обучающий набор содержит m помеченных примеров {(x(1), y(1)), …, (x(m), y(m))}. Теперь предположим, что к каждому входу добавлено случайное возмущение εW ∼ 𝒩(ε; 0, ηI) сетевых весов. Допустим, что мы имеем дело со стандартным l-слой- ным МСП. Обозначим возмущенную модель y�εW (x). Несмотря на привнесенный шум, мы по-прежнему хотим минимизировать среднеквадратическую ошибку выхо-да сети. Таким образом, целевая функция принимает вид: J~ W = 𝔼p(x;y;εW)[(y�εW(x) – y)2] (7.31) = 𝔼p(x;y;εW)[(y�2 εW(x) – 2yy �εW(x) + y2]. (7.32) Для малых η минимизация J с добавленным весовым шумом (с ковариацией ηI) эк- вивалентна минимизации J с добавленным членом регуляризации η𝔼p(x, y)[||∇Wy�(x)||2].\n--- Страница 212 ---\nОбучение с частичным привлечением учителя  211 Такая форма регуляризации поощряет сдвиг в область пространства параметров, где малые возмущения весов оказывают слабое влияние на выход. Иными словами, модель сдвигается в область нечувствительности к небольшим изменениям весов, т. е. ищутся не просто минимумы, а минимумы, окруженные плоскими участками (Hochreiter and Schmidhuber, 1995). В случае линейной регрессии (когда, например, y�(x) = w⏉x + b) этот регуляризирующий член упрощается до η𝔼p(x)[||x||2], а эта функ- ция не зависит от параметров и потому не дает вклада в градиент J~ W относительно параметров модели. 7.5.1. Привнесение шума в выходные метки В большинстве наборов данных выходные метки y содержат сколько-то ошибок. Максимизация log p(y | x), когда y ошибочно, чревата неприятными последствиями. Предотвратить это можно, в частности, путем явного моделирования шума в метках. Так, мы можем предположить, что для некоторой малой константы ε метка обучающе- го набора y правильна с вероятностью 1 – ε, а в противном случае правильной может быть любая другая возможная метка. Это предположение легко включить в функцию стоимости аналитически, а не путем явной выборки зашумленных примеров. Напри- мер, сглаживание меток регуляризирует модель, основанную на функции softmax с k выходными значениями, путем замены жестко заданных идентификаторов классов 0 и 1 метками ε/(k–1) и 1 – ε соответственно. Затем к этим мягким меткам можно применить стандартную функцию потерь на базе перекрестной энтропии. Обучение методом максимального правдоподобия с softmax-классификатором и жесткими мет- ками может никогда не сойтись – softmax не умеет предсказывать вероятность, в точ- ности равную 0 или 1, поэтому будет бесконечно продолжать обучать все большие и большие веса, делая все более экстремальные предсказания. Такого развития собы- тий можно избежать, применив другие стратегии регуляризации, например снижение весов. У сглаживания меток есть то преимущество, что оно предотвращает стремле- ние к жестким вероятностям, не ставя под угрозу правильность классификации. Эта стратегия используется начиная с 1980-х годов и до сих пор занимает видное место в современных нейронных сетях (Szegedy et al., 2015). 7.6. Обучение с частичным привлечением учителя В случае обучения с частичным привлечением учителя для оценивания P(y | x) или предсказания y по x используются как непомеченные примеры из P(x), так и поме- ченные из P(x, y). В контексте глубокого обучения под обучением с частичным привлечением учи- теля обычно понимают обучение представления h = f(x). Цель – сделать так, что- бы примеры из одного класса имели похожие представления. Обучение без учителя может дать полезную информацию о том, как сгруппировать примеры в простран- стве представлений. Примеры, попадающие в один кластер в пространстве входов, должны отображаться в сходные представления. Линейный классификатор в новом пространстве во многих случаях может достичь более высокого качества (Belkin and Niyogi, 2002; Chapelle et al., 2003). Проверенный временем вариант этого подхода – применить метод главных компонент в качестве шага предварительной обработки до применения классификатора (к спроецированным данным).\n--- Страница 213 ---\n212  Регуляризация в глубоком обучении Вместо включения раздельных компонент с учителем и без учителя в одну модель можно построить модели, в которых порождающая модель P(x) или P(x, y) разделяет параметры с дискриминантной моделью P(y | x). Затем можно выбрать компромисс между критерием обучения с учителем –log P(y | x) и критерием без учителя или по- рождающим критерием (например, –log P(x) или –log P(x, y)). Тогда порождающий критерий выражает некую априорную гипотезу о решении задачи обучения с учите- лем (Lasserre et al., 2006), а именно что структура P(x) связана со структурой P(y | x) таким способом, который улавливается совместной параметризацией. Управляя тем, какая часть порождающего критерия включается в общий, мы можем найти лучший компромисс, чем чисто порождающий или чисто дискриминантный критерий обуче-ния (Lasserre et al., 2006; Larochelle and Bengio, 2008). В работе Salakhutdinov and Hinton (2008) описан способ обучения ядра ядерного метода регрессии, в котором использование непомеченных примеров для моделиро- вания P(x) оказывается существенно лучше, чем P(y | x). Дополнительные сведения об обучении с частичным привлечением учителя см. в работе Chapelle et al. (2006). 7.7. Многозадачное обучение Многозадачное обучение (Caruana, 1993) – способ улучшить обобщаемость путем пулинга примеров (которые можно рассматривать как мягкие ограничения на пара-метры), возникающих в нескольких задачах. Дополнительные обучающие примеры оказывают большее давление на параметры модели, отдавая предпочтение значени-ям, которые хорошо обобщаются, и точно так же, если часть модели совместно ис- пользуется несколькими задачами, то эта часть испытывает больше ограничений, направляющих ее в сторону хороших значений (в предположении, что разделение обосновано), что зачастую улучшает обобщаемость. На рис. 7.2 показана широко распространенная форма многозадачного обучения, при которой разные задачи обучения с учителем (предсказание y (i) при известном x) разделяют один и тот же вход x, а также некоторое промежуточное представление h(shared), запоминающее общий пул факторов. В общем случае модель можно разделить на части двух видов и ассоциированные с ними параметры: 1) параметры, специфичные для конкретной задачи (для достижения хорошей обобщаемости им нужны только примеры, относящиеся к «своей» задаче). Это верхние слои нейронной сети на рис. 7.2; 2) общие параметры, разделяемые всеми задачами (они извлекают выгоду из орга-низации пула данных всех задач). Это нижние слои сети на рис. 7.2. У лучшенной обобщаемости и ограничения ошибки обобщения (Baxter, 1995) мож- но достичь благодаря разделяемым параметрам, статистическую мощность которых можно значительно повысить (соразмерно с увеличенным числом примеров для раз- деляемых параметров, по сравнению со случаем однозадачных моделей). Разумеется, для этого нужно, чтобы выполнялись некоторые предположения относительно ста-тистической связи между различными задачами, выражающие тот факт, что у неко- торых задач действительно имеется что-то общее. С точки зрения глубокого обучения, априорная гипотеза состоит в следующем: среди факторов, объясняющих вариативность, наблюдаемую в данных, ассоциирован- ных с разными задачами, некоторые являются общими для двух или более задач .\n--- Страница 214 ---\nРанняя остановка  213 h(shared) xh(2)y(2) h(1)y(1) h(3) Рис. 7.2  Многозадачное обучение находит несколько применений в си- стемах глубокого обучения, на этом рисунке показана типичная ситуация, когда задачи разделяют общий вход, но у них разные выходные случайные величины. Нижние слои глубокой сети (все равно, идет ли речь об обуче-нии с учителем и прямом распространении или присутствует порождающая компонента с направленными вниз стрелками) могут разделяться задача- ми, тогда как специфичные для задач параметры (ассоциированные соот-ветственно с весами входных и выходных сигналов h (1) и h(2)) могут быть об- учены в дополнение к тем, что входят в разделяемое представление h(shared). Предполагается, что существует общий пул факторов, объясняющих ва-риативность входа x, а с каждой задачей ассоциированно подмножество этих факторов. В данном примере дополнительно предполагается, что бло- ки верхнего скрытого слоя h (1) и h(2) специализированы для каждой задачи (предсказывают соответственно y(1) и y(2)), тогда как некое промежуточное представление h(shared) разделяется всеми задачами. В контексте обучения без учителя имеет смысл не ассоциировать с некоторыми верхнеуровневы- ми факторами никакие выходы задач (h(3)): это те факторы, которые объяс- няют часть вариативности входа, но не имеют отношения к предсказаниям y(1) или y(2) 7.8. Ранняя остановка При обучении больших моделей, репрезентативная емкость которых достаточна для переобучения, мы часто наблюдаем, что ошибка обучения монотонно убывает со временем, но ошибка на контрольном наборе снова начинает расти. Пример такого устойчивого поведения показан на рис. 7.3. Это означает, что мы могли бы получить модель с более низкой ошибкой на конт- рольном наборе (и, хочется надеяться, на тестовом тоже), вернувшись к тем значени- ям параметров, которые существовали на момент наименьшей ошибки. Всякий раз как ошибка на контрольном наборе улучшается, мы сохраняем копию параметров мо-дели. Когда алгоритм обучения завершается, мы возвращаем именно эти, а не самые последние параметры. А завершается алгоритм, когда на протяжении заранее задан- ного числа итераций не удается улучшить параметры, по сравнению с наилучшими запомненными ранее. Формально эта процедура описана в алгоритме 7.1.\n--- Страница 215 ---\n214  Регуляризация в глубоком обучении Время (периоды) Потеря на обучающем наборе Потеря на контрольном набореФункция потерь (отрицательное логарифмическое правдоподобие)0,20 0,150,10 0,05 0,00 0 50 100 150 200 250 Рис. 7.3  Кривые обучения, показывающие изменение отрица- тельного логарифмического правдоподобия со временем (пред- ставленного в виде количества итераций обучения на наборе дан- ных, или периодов). В данном случае обучалась maxout-сеть на наборе MNIST . Отметим, что целевая функция монотонно убывает, но средняя потеря на контрольном наборе в какой-то момент снова начинает расти, так что образуется U-образная кривая Эта стратегия называется ранней остановкой. Пожалуй, это самая распространен- ная форма регуляризации в машинном обучении. Своей популярностью она обязана простоте и эффективности. Алгоритм 7.1. Метаалгоритм ранней остановки для определения оптимального времени обучения. Эта общая стратегия хорошо работает для широкого круга ал-горитмов обучения и способов оценки ошибки на контрольном наборе. Обозначим n число шагов между вычислениями ошибки. Обозначим p «терпение» – сколько раз разрешается наблюдать ухудшение ошибки на контрольном наборе, прежде чем отказаться от продолжения.Обозначим θ o начальные параметры. θ ⟵ θo i ⟵ 0j ⟵ 0v ⟵ ∞θ * ⟵ θ i* ⟵ i while j < p do Обновить θ, дав алгоритму обучения проработать n шагов.i ⟵ i + nv′ ⟵ ValidationSetError(θ)if v′ < v then j ⟵ 0θ * ⟵ θ i* ⟵ i v ⟵ v′ else j ⟵ j + 1\n--- Страница 216 ---\nРанняя остановка  215 end if end while Наилучшие параметры θ*, наилучшее число шагов обучения i*. Одна из возможных интерпретаций ранней остановки – очень эффективный алго- ритм выбора гиперпараметров. С этой точки зрения, число шагов обучения – просто еще один гиперпараметр. На рис. 7.3 видно, что кривая качества этого гиперпара-метра, измеренного на контрольном наборе, имеет U-образную форму. Большинство гиперпараметров, управляющих емкостью модели, имеет именно такую кривую качества, как было продемонстрировано на рис. 5.3. В случае ранней остановки мы управляем эффективной емкостью модели, определяя, сколько шагов ей может по-требоваться для аппроксимации обучающего набора. Большинство гиперпараметров приходится выбирать, применяя дорогостоящий процесс выдвижения и проверки гипотез: вначале мы задаем гиперпараметр, а потом производим несколько шагов об- учения, чтобы посмотреть, что получилось. Гиперпараметр «время обучения» уника-лен в том, что по определению в одном прогоне цикла обучения проверяется сразу много его значений. Когда этот параметр автоматически устанавливается путем ран-ней остановки, платить приходится только за периодическую проверку на контроль-ном наборе в ходе обучения. В идеале это следует делать параллельно с процессом обучения на отдельной машине, отдельном процессоре или отдельном GPU, не за-действованных в основном процессе обучения. Если таких ресурсов нет, то стоимость периодических вычислений можно уменьшить: сделать контрольный набор неболь-шим, по сравнению с обучающим, или вычислять ошибку на контрольном наборе не так часто, смирившись с меньшей разрешающей способностью оценки оптимального времени обуче ния. К дополнительным расходам на раннюю остановку следует также отнести хране- ние копии наилучших параметров. Вообще говоря, эти расходы пренебрежимо малы, поскольку параметры можно хранить в медленной памяти большого объема (напри- мер, обучение производится в памяти GPU, а оптимальные параметры хранятся в па- мяти хост-компьютера или на диске). Поскольку оптимальные параметры записыва-ются сравнительно редко и никогда не читаются в процессе обучения, такие нечастые операции записи слабо сказываются на общем времени обучения. Ранняя остановка – ненавязчивая форма регуляризации в том смысле, что не тре- буется вносить почти никаких изменений в базовую процедуру обучения, целевую функцию или множество допустимых значений параметров. Следовательно, раннюю остановку можно легко использовать, не изменяя динамику обучения. Совершенно не так обстоит дело со снижением весов, когда нужно внимательно следить за тем, чтобы не снизить веса слишком сильно и не завести сеть в плохой локальный мини- мум, соответствующий патологически малым весам. Раннюю остановку можно использовать автономно или в сочетании с другими стратегиями регуляризации. Даже если применяются стратегии регуляризации, модифицирующие целевую функцию во имя лучшей обобщаемости, редко быва-ет так, что наилучшая обобщаемость достигается в локальном минимуме целевой функции. Для ранней остановки необходим контрольный набор, а значит, часть обучающих данных не следует подавать на вход модели. Чтобы использовать эти отложенные данные более эффективно, можно провести дополнительное обучение, после того как\n--- Страница 217 ---\n216  Регуляризация в глубоком обучении начальная фаза с ранней остановкой завершилась, и тогда уже включить все обучаю- щие данные. На этом втором раунде обучения применяются две основные стратегии. Первая (алгоритм 7.2) – снова инициализировать модель и заново обучить ее на всех данных. Но при этом мы ограничиваемся числом шагов, которое было приз- нано оптимальным в первом раунде. Тут есть некоторые тонкости. Например, не существует хорошего способа решить, следует ли при повторном обучении про-изводить столько же обновлений параметров или столько же проходов по набору данных, как в первом раунде. Во втором раунде каждый проход по набору данных приводит к большему числу обновлений параметров, потому что сам обучающий набор больше. Алгоритм 7.2. Метаалгоритм использования ранней остановки для определения времени обучения с последующим повторным обучением на всех данных Обозначим X (train) и y(train) обучающий набор. Разделить X(train) и y(train) на (X(subtrain), X(valid)) и (y(subtrain), y(valid)) соответственно. Выполнить обучение с ранней остановкой (алгоритм 7.1), начав со случайных параметров θ и используя X(subtrain), y(subtrain) в качестве обучающих данных, а X(valid) и y(valid) в качестве контрольных. В результате возвращается оптимальное число шагов i*. Снова присвоить θ случайные значения.Выполнить i * шагов обучения на наборе X(train), y(train). Другая стратегия использования всех данных – оставить параметры, получен- ные на первом раунде, и продолжить обучение, но уже на всех данных. Теперь у нас больше нет подсказок, после скольких шагов остановиться. Вместо этого мы сле-дим за функцией потерь на контрольном наборе и продолжаем обучение, пока ее среднее значение не окажется меньше величины целевой функции, при которой сработала ранняя остановка. Эта стратегия позволяет избежать дорогостоящего повторного обучения модели с нуля, но ее поведение оставляет желать лучшего. Например, целевая функция может никогда не достичь нужного значения на конт- рольном наборе, и тогда обучение не завершится. Формально эта стратегия описа- на в алгоритме 7.3. Ранняя остановка полезна также тем, что уменьшает вычислительную стоимость процедуры обучения. Помимо очевидного сокращения стоимости вследствие огра- ничения числа итераций, она еще и обеспечивает преимущества регуляризации, не требуя включения дополнительных штрафов в функцию стоимости и вычисления градиентов этих добавочных членов. Каким образом ранняя остановка выступает в роли регуляризатора. Мы уже не раз отмечали, что ранняя остановка является стратегией регуляризации, но в обос- нование этого заявления привели только кривые обучения, на которых ошибка на контрольном наборе имеет U-образную форму. А каков истинный механизм регуля- ризации модели с помощью ранней остановки? Алгоритм 7.3. Метаалгоритм использования ранней остановки для определения того, при каком значении целевой функции начинается переобучение, с последую- щим продолжением обучения до тех пор, пока не будет достигнуто это значение\n--- Страница 218 ---\nРанняя остановка  217 Обозначим X(train) и y(train) обучающий набор. Разделить X(train) и y(train) на (X(subtrain), X(valid)) и (y(subtrain), y(valid)) соответственно. Выполнить обучение с ранней остановкой (алгоритм 7.1), начав со случайных параметров θ и используя X(subtrain), y(subtrain) в качестве обучающих данных, а X(valid) и y(valid) в качестве контрольных. При этом обновляется θ. ε ⟵ J(θ, X(subtrain), y(subtrain)) while J(θ, X(valid), y(valid)) > ε do Выполнить n шагов обучения на наборе X(train), y(train). end while В работах Bishop (1995a) и Sjöberg and Ljung (1995) утверждается, что благодаря ранней остановке процедура оптимизации ограничивается просмотром сравнитель- но небольшой области пространства параметров в окрестности начального значения параметров θo, как показано на рис. 7.4. Точнее, допустим, что выбрано τ шагов опти- мизации (что соответствует τ итерациям обучения) и скорость обучения ε. Произве- дение ετ можно рассматривать как меру эффективной емкости. В предположении, что градиент ограничен, наложение ограничений на число итераций и скорость обучения лимитируют область пространства параметров, достижимую из θo. В этом смысле ετ ведет себя как величина, обратная коэффициенту снижения весов. w*w~ w~w* w1w2 w2 w1 Рис. 7.4  Результат ранней остановки. (Слева) Сплошными линиями показаны изолинии отрицательного логарифмического правдоподобия, штриховыми – траектория стохастического градиентного спуска, начатого из начала координат. Благодаря ранней остановке траектория заканчива-ется не в точке w *, минимизирующей стоимость, а в более ранней точке w~. (Справа) Результат L2-регуляризации для сравнения. Штриховыми кругами показаны изолинии штрафа по норме L2, благодаря которому минимум пол- ной функции стоимости оказывается ближе к началу координат, чем мини- мум нерегуляризированной функции стоимости Действительно, можно показать, что в случае простой линейной модели с квадра- тичной функцией ошибки и обычного градиентного спуска ранняя остановка эквива- лентна L2-регуляризации. Для сравнения с классической L2-регуляризацией рассмотрим простую конфи- гурацию, в которой единственными параметрами являются линейные веса (θ = w).\n--- Страница 219 ---\n218  Регуляризация в глубоком обучении Функцию стоимости J можно смоделировать с помощью квадратичной аппроксима- ции в окрестности эмпирического оптимума весов w*: J�(θ) = J(w*) + 1/2(w – w*)⏉H(w – w*), (7.33) где H – гессиан J относительно w, вычисленный в точке w*. Поскольку мы предполо- жили, что w* – точка минимума J(w), то H является положительно полуопределенной. Аппроксимируя разложением в ряд Тейлора, получаем выражение для градиента: ∇w J�(w) = H(w – w*). (7.34) Мы изучим траекторию вектора параметров в процессе обучения. Для простоты пусть начальный вектор параметров совпадает с началом координат1, w(0) = 0. Мы составим приближенное представление о поведении градиентного спуска по J, про- анализировав градиентный спуск по J�: w(τ) = w(τ–1) – ε∇w J�(w(τ–1)) (7.35) = w(τ–1) – εH(w(τ–1) – w*) (7.36) w(τ) – w* = (I – εH)(w(τ–1) – w*). (7.37) Перепишем это выражение в пространстве собственных векторов H, воспользовав- шись спектральным разложением H: H = QΛQ⏉, где Λ – диагональная матрица, а Q – ортогональная матрица собственных векторов. w(τ) – w* = (I – εQΛQ⏉)(w(τ–1) – w*), (7.38) Q⏉(w(τ) – w*) = (I – εΛ)Q⏉(w(τ–1) – w*). (7.39) В предположении, что w(0) = 0 и что ε достаточно мало, чтобы выполнялось условие |1 – ελi| < 1, траектория параметров в процессе обучения после τ обновлений парамет- ров описывается уравнением: Q⏉w(τ) = [(I – (I – εΛ)τ]Q⏉w*. (7.40) Выражение Q⏉w~ в уравнении (7.13) L2-регуляризации можно переписать в виде: Q⏉w~ = (Λ + αI)–1ΛQ⏉w*, (7.41) Q⏉w~ = [I – (Λ + αI)–1α]Q⏉w*. (7.42) Сравнивая уравнения (7.40) и (7.42), мы заключаем, что если выбрать гиперпара- метры ε, α и τ, так чтобы (I – εΛ)τ = (Λ + αI)–1α, (7.43) то L2-регуляризацию и раннюю остановку можно считать эквивалентными (по край- ней мере, в предположении о квадратичной аппроксимации целевой функции). Мы можем пойти даже дальше: прологарифмировав и воспользовавшись разложением в ряд функции log(1 + x), приходим к выводу, что если все λi малы (то есть ελi ≪ 1 и λi /α ≪ 1), то 1 В случае нейронных сетей мы хотим нарушить симметрию между скрытыми блоками и по- тому не можем инициализировать все параметры нулями (см. раздел 6.2). Однако то же рассуждение проходит и для любого другого начального значения w (0).\n--- Страница 220 ---\nСвязывание и разделение параметров  219 (7.44) (7.45) Таким образом, в этих предположениях число итераций обучения τ играет роль ве- личины, обратно пропорциональной параметру L2-регуляризации, а число, обратное ετ, – роль коэффициента снижения весов. Значения параметров, соответствующие направлениям сильной кривизны целе- вой функции, регуляризируются меньше, чем в направлениях меньшей кривизны. В контексте ранней остановки это в действительности означает, что параметры, соот- ветствующие направлениям сильной кривизны, обучаются раньше параметров, соот- ветствующих направлениям меньшей кривизны. Выкладки, приведенные в этом разделе, показывают, что траектория длины τ об- рывается в точке, соответствующей минимуму L2-регуляризированной целевой функции. Конечно, ранняя остановка – больше, чем простое ограничение на длину траектории; ранняя остановка обычно подразумевает наблюдение за ошибкой на конт рольном наборе, чтобы оборвать траекторию в удачной точке пространства. По- этому, по сравнению со снижением весов, у ранней остановки есть то преимущество, что она автоматически определяет правильную степень регуляризации, тогда как при использовании снижения весов требуется много экспериментов с разными значения- ми гиперпараметра. 7.9. Связывание и разделение параметров До сих пор в этой главе, обсуждая ограничения и штрафы, налагаемые на парамет- ры, мы всегда отталкивались от фиксированной области или точки. Например, L2-ре- гуляризация (или снижение весов) штрафует параметры модели за отклонение от фиксированного значения – нуля. Но иногда требуются другие способы выражения априорных знаний о подходящих значениях параметров модели. Возможно, мы не знаем точно, какие значения должны принимать параметры, но имеющиеся знания о предметной области и архитектуре модели позволяют заключить, что между пара- метрами должны существовать некие зависимости. Распространенный тип зависимости – близость некоторых параметров друг к дру- гу. Рассмотрим такую ситуацию: есть две модели, решающие одну и ту же задачу классификации (с одинаковым набором классов), но с различающимися распределе- ниями входных данных. Формально имеется модель A с параметрами w (A) и модель B с параметрами w(B). Обе модели отображают входы в разные, но взаимосвязанные выходы: y �(A) = f(w(A), x) и y �(B) = g(w(B), x). Допустим, что задачи похожи настолько (быть может, имеют похожие распреде- ления входов и выходов), что есть основания полагать, что их параметры должны быть близки: ∀i wi(A) должно быть близко к wi(B). Эту информацию можно применить для регуляризации: использовать штраф по норме параметров вида Ω(w(A), w(B)) = = ||w(A) – w(B)||22. В данном случае для вычисления штрафа мы применили норму L2, но возможны и другие варианты. Такой подход предложен в работе Lasserre et al. (2006), где параметры одной моде- ли, обученной для классификации с учителем, регуляризируются с целью сделать их\n--- Страница 221 ---\n220  Регуляризация в глубоком обучении близкими параметрам другой модели, обученной без учителя (для нахождения рас- пределения наблюдаемых входных данных). Архитектуры были устроены так, чтобы многим параметрам в модели классификации можно было сопоставить параметры второй модели. Хотя штраф по норме параметров можно использовать для регуляризации пара- метров с целью обеспечить их близость, более популярен другой способ: наложить ограничения, требующие, чтобы множества параметров совпадали. Этот метод ре- гуляризации часто называют разделением параметров, поскольку мы считаем, что разные модели или компоненты моделей разделяют некоторое общее множество параметров. Важным преимуществом разделения параметров над регуляризацией с целью обеспечения близости (посредством штрафа по норме) является тот факт, что в памяти нужно хранить только подмножество всех параметров (общее множе- ство). В некоторых моделях, например в сверточных нейронных сетях, это помогает существенно уменьшить потребность модели в памяти. 7.9.1. Сверточные нейронные сети Конечно, самое популярное и важное применение идея разделения параметров на- ходит в сверточных нейронных сетях (СНС) в компьютерном зрении. У естественных изображений есть много статистических свойств, инвариант- ных к параллельному переносу. Например, фотография кошки остается таковой, если сдвинуть ее на один пиксель вправо. В СНС это свойство учитывается с по- мощью разделения параметров по нескольким областям изображения. Один и тот же признак (скрытый блок с одинаковыми весами) вычисляется по нескольким участкам входных данных. Это означает, что один и тот же детектор кошек найдет кошку вне зависимости от того, находится она в столбце изображения с номером i или i + 1. Разделение параметров дает СНС возможность значительно уменьшить число уникальных параметров модели и увеличить размер сети, не требуя соответствен- ного увеличения объема обучающих данных. Это по сей день остается одним из луч-ших примеров эффективного включения знаний о предметной области в архитекту- ру сети. Более подробно СНС рассматриваются в главе 9. 7.10. Разреженные представления Снижение весов работает благодаря штрафованию непосредственно параметров модели. Другая стратегия – штрафовать за активацию блоков нейронной сети, стремясь к разреженности активаций. Это налагает косвенный штраф на парамет- ры модели. Мы уже обсуждали (см. раздел 7.1.2), что штраф по норме L 1 ведет к разреженной параметризации, т. е. многие параметры обращаются в 0 (или оказываются близки к 0). С другой стороны, под разреженным понимается такое представление, многие элементы которого равны 0 (или близки к 0). Упрощенно это различие можно про- иллюстрировать на примере линейной регрессии:\n--- Страница 222 ---\nРазреженные представления  221 (7.46) (7.47) В первом случае мы имеем пример модели линейной регрессии с разреженной па- раметризацией, а во втором – линейную регрессию с разреженным представлением h данных x. Это означает, что h – функция от x, которая в каком-то смысле представля- ет информацию, присутствующую в x, но с помощью разреженного вектора. Для регуляризации представлений применяются те же механизмы, что для регу- ляризации параметров. Регуляризация представления путем штрафа по норме производится путем при- бавления к функции потерь J штрафа по норме представления. Этот штраф обознача- ется Ω(h). Как и раньше, будем обозначать регуляризированную функцию потерь J~: J~(θ; X, y) = J(θ; X, y) + αΩ(h), (7.48) где α ∈ [0, ∞) – относительный вес штрафа; чем больше α, тем сильнее регуляризация. Точно так же, как штраф по норме L1 параметров индуцирует разреженность па- раметров, штраф по норме L1 элементов представления индуцирует разреженность представления: Ω(h) = || h||1 = Σi |hi|. Разумеется, L1-штраф – лишь один из возможных штрафов, приводящих к разреженному представлению. Из других назовем штрафы на основе априорного t-распределения Стьюдента (Olshausen and Field, 1996; Bergs- tra, 2011) и расхождения Кульбака–Лейблера (Larochelle and Bengio, 2008), особенно полезные для представлений, элементы которых принадлежат единичному интерва- лу. В работах Lee et al. (2008) и Goodfellow et al. (2009) приведены примеры стра- тегий, основанных на регуляризации, требующей, чтобы активация, усредненная по нескольким примерам (1/m)Σ i hi, была близка к некоторому целевому значению, ска- жем, вектору, все элементы которого равны 0,01. В других подходах разреженность представления достигается за счет жесткого ограничения на значения активации. Например, в методе ортогонального согласо- ванного преследования (orthogonal matching pursuit – OMP) (Pati et al., 1993) вход x кодируется с помощью представления h, решающего следующую задачу оптимиза- ции с ограничениями:\n--- Страница 223 ---\n222  Регуляризация в глубоком обучении (7.49) где ||h||0 – число ненулевых элементов h. Эту задачу можно эффективно решить, когда на матрицу W наложено ограничение ортогональности. Этот метод часто называют OMP-k, где k обозначает допустимое число ненулевых признаков. В работе Coates and Ng (2011) показано, что OMP-1 может быть чрезвычайно эффективным экстрак- тором признаков для глубоких архитектур. На самом деле любую модель со скрытыми блоками можно сделать разреженной. В этой книге нам встретится много примеров разреженной регуляризации в различ- ных контекстах. 7.11. Баггинг и другие ансамблевые методы Баггинг (bagging, сокращение от «bootstrap aggregating») – это метод уменьшения ошибки обобщения путем комбинирования нескольких моделей (Breiman, 1994). Идея заключается в том, чтобы раздельно обучить разные модели, а затем организо- вать их голосование за результаты на тестовых примерах. Это частный случай общей стратегии машинного обучения – усреднения моделей. Методы, в которых эта стра- тегия используется, называются ансамблевыми методами. Идея усреднения моделей работает, потому что разные модели обычно не делают одни и те же ошибки на тестовом наборе. В качестве примера рассмотрим набор из k моделей регрессии. Предположим, что каждая модель делает ошибку ε i на каждом примере, причем ошибки имеют много- мерное нормальное распределение с нулевым средним, дисперсиями 𝔼[εi2] = v и ко- вариациями 𝔼[εi εj] = c. Тогда ошибка, полученная в результате усреднения предска- заний всего ансамбля моделей, равна (1/k)Σi εi. Математическое ожидание квадрата ошибки ансамблевого предиктора равно , (7.50) (7.51) В случае, когда ошибки идеально коррелированы, т. е. c = v, среднеквадратическая ошибка сводится к v, так что усреднение моделей ничем не помогает. В случае, когда ошибки вообще не коррелированы, т. е. c = 0, среднеквадратическая ошибка ансамб- ля равна всего (1/k)v и, значит, линейно убывает с ростом размера ансамбля. Ины- ми словами, в среднем ансамбль показывает качество не хуже любого из его членов, а если члены совершают независимые ошибки, то ансамбль работает значительно лучше своих членов. Существуют разные методы конструирования ансамбля моделей. Например, чле- ны могут быть сформированы в результате обучения моделей разного вида разными алгоритмами или с разными целевыми функциями. Баггинг – это метод, который по- зволяет повторно использовать один и тот же вид модели, алгоритм обучения и це- левую функцию. Точнее, баггинг подразумевает построение k разных наборов данных. В каждом на- боре столько же примеров, сколько в исходном, но строятся они путем выборки с воз-\n--- Страница 224 ---\nБаггинг и другие ансамблевые методы  223 вращением из исходного набора данных. Это означает, что с высокой вероятностью в каждом наборе данных отсутствуют некоторые примеры из исходного набора и при- сутствует несколько дубликатов (в среднем, если размер результирующего набора равен размеру исходного, в него попадет две трети примеров из исходного набора). Затем i-я модель обучается на i-м наборе данных. Различия в составе примеров, вклю- ченных в набор, обусловливают различия между обученными моделями. На рис. 7.5 приведена иллюстрация. Нейронные сети дают настолько широкое разнообразие решений, что усреднение моделей может оказаться выгодным, даже если все модели обучались на одном и том же наборе данных. Различия, обусловленные случайной инициализацией, случайным выбором мини-пакетов, разными гиперпараметрами и результатами недетерминиро- ванной реализации нейронной сети, зачастую достаточны, чтобы различные члены ансамбля допускали частично независимые ошибки. Исходный набор данных Набор данных после первой повторной выборки Набор данных после второй повторной выборкиПервый член ансамбля Второй член ансамбля Рис. 7.5  Иллюстрация работы баггинга. Допустим, что мы обучаем де- тектор цифры 8 на показанном наборе данных, содержащем 8, 6 и 9. Пред- положим, мы хотим создать два разных набора данных на основе исходного. Процедура баггинга строит каждый набор путем выборки с возвращением из исходного набора. В первом наборе отсутствует 9, но два раза встреча- ется 8. На этом наборе данных детектор научится, что кружочек в верхней части цифры соответствует 8. На втором наборе повторяется 9 и отсутству- ет 6. В этом случае детектор научится, что кружочек в нижней части соот- ветствует 8. Каждое правило по отдельности ненадежно, но если усреднить результаты, то получится робастный детектор, дающий максимальную уве-ренность, только когда присутствуют оба кружочка Усреднение моделей – исключительно мощный и надежный метод уменьшения ошибки обобщения. Его не рекомендуют использовать для эталонного тестирова- ния алгоритмов в научных статьях, потому что любой алгоритм машинного обуче- ния можно значительно улучшить путем усреднения моделей, но ценой увеличения времени вычислений и потребления памяти. По этой причине сравнение с эталоном обычно производят с использованием одной модели. Соревнования по машинному обучению, как правило, выигрывают методы, произ- водящие усреднение по десяткам моделей. Показателен недавний пример конкурса Netflix Grand Prize (Koren, 2009).\n--- Страница 225 ---\n224  Регуляризация в глубоком обучении Не все методы построения ансамблей призваны сделать ансамбль более регуляри- зированным, чем отдельные модели. Например, метод усиления (boosting) (Freund and Schapire, 1996b,a) строит ансамбль с более высокой емкостью, чем у составляю- щих его моделей. Усиление применялось для построения ансамблей нейронных сетей (Schwenk and Bengio, 1998) путем инкрементного добавления сетей в ансамбль. Так- же усиление применялось для интерпретации одной нейронной сети как ансамбля (Bengio et al., 2006a) путем инкрементного добавления скрытых блоков в сеть. 7.12. Прореживание Прореживание (dropout) (Srivastava et al., 2014) – это вычислительно недорогой, но мощный метод регуляризации широкого семейства моделей. В первом приближении прореживание можно представлять себе как метод, посредством которого баггинг ста-новится практичным для ансамблей, состоящих из очень большого числа больших нейронных сетей. Баггинг подразумевает обучение нескольких моделей и пропускание через них каждого тестового примера. Если в качестве модели используется большая нейронная сеть, то это непрактично, потому что обучение и оценка примера обходятся дорого с точки зрения времени и памяти. Обычно используются ансамбли, содержащие от пяти до десяти сетей, – в работе Szegedy et al. (2014a), выигравшей конкурс ILSVRC, использовалось шесть – а если ансамбль больше, то работать с ним очень скоро стано- вится неудобно. Прореживание предлагает дешевую аппроксимацию обучения и вы- числения баггингового ансамбля экспоненциально большого числа нейронных сетей. Точнее говоря, в процессе прореживания обучается ансамбль, состоящий из под- сетей, получаемых удалением невыходных блоков из базовой сети, как показано на рис. 7.6. В большинстве современных нейронных сетей, основанных на последова- тельности аффинных преобразований и нелинейностей, можно эффективно удалить блок, умножив его выход на 0. Эта процедура требует небольшой модификации та-ких моделей, как сеть радиально-базисных функций, которые принимают разность между состоянием блока и некоторым опорным значением. Ниже мы для простоты опишем алгоритм прореживания в терминах умножения на 0, но путем тривиальной модификации его можно приспособить к операциям удаления блока из сети. Напомним, что для обучения методом баггинга мы определяем k различных мо- делей, строим k различных наборов данных путем выборки с возвращением из обучаю щего набора, а затем обучаем i-ю модель на i-м наборе. Цель прореживания – аппроксимировать этот процесс на экспоненциально большом числе нейронных се-тей. Точнее говоря, для обучения методом прореживания мы используем алгоритм, основанный на мини-пакетах, который делает небольшие шаги, например алгоритм стохастического градиентного спуска. При загрузке каждого примера в мини-пакет мы случайным образом генерируем битовую маску, применяемую ко всем входным и скрытым блокам сети. Элемент маски для каждого блока выбирается независимо от всех остальных. Вероятность включить в маску значение 1 (означающее, что соот- ветствующий блок включается) – гиперпараметр, фиксируемый до начала обучения, а не функция текущего значения параметров модели или входного примера. Обычно входной блок включается с вероятностью 0.8, а скрытый – с вероятностью 0.5. За- тем, как обычно, производятся прямое распространение, обратное распространение и обновление. На рис. 7.7 показано, как работает прямое распространение с проре- живанием.\n--- Страница 226 ---\nПрореживание  225 Ансамбль подсетей Базовая сеть Рис. 7.6  Прореживание обучает ансамбль, состоящий из всех подсе- тей, которые можно построить путем удаления невыходных блоков из базо- вой сети. В данном случае мы начинаем с сети, имеющей два видимых и два скрытых блока. Из этих четырех блоков можно составить 16 подмножеств. На рисунке показаны все 16 подсетей, которые можно построить выбра-сыванием разных подмножеств блоков из исходной сети. В этом крохот- ном примере есть много сетей, в которых вообще нет входных блоков или не существует пути, соединяющего вход с выходом. Эта проблема теряет остроту для сетей с более широкими слоями, когда вероятность выбросить все возможные пути от входов к выходам уменьшается Формально, пусть вектор-маска μ определяет, какие блоки включать, а J(θ, μ) – стоимость модели с параметрами θ и маской μ. Тогда обучение с прореживанием за- ключается в минимизации 𝔼μ J(θ, μ). Математическое ожидание содержит экспонен- циально много членов, но мы можем получить несмещенную оценку его градиента путем выборки значений μ. Обучение с прореживанием – не совсем то же, что баггинг. В случае баггинга все модели независимы, а в случае прореживания модели разделяют общие параметры, причем все модели наследуют разные множества параметров от родительской ней-ронной сети. Такое разделение параметров позволяет представить экспоненциаль-но большое число моделей в памяти обозримого объема. В случае баггинга каждая модель обучается до сходимости на своем обучающем наборе, а в случае прорежи- вания большинство моделей явно не обучаются вовсе – обычно исходная модель настолько велика, что для перебора всех возможных подсетей не хватило бы и вре-\n--- Страница 227 ---\n226  Регуляризация в глубоком обучении мени существования вселенной. Вместо этого лишь для малой толики возможных подсетей проводится один шаг обучения, а благодаря разделению остальные под- сети получают хороший набор параметров. Это и все различия. Во всем остальном прореживание повторяет алгоритм баггинга. Например, обучающий набор, который видит каждая подсеть, в действительности получен выборкой с возвращением из ис- ходного набора. y yh1h1 hˆ 1x1 x1h1μh1 μx1xˆ1h2h2 hˆ 2x2 x2h2μh2 μx2xˆ2 Рис. 7.7  Пример прямого распространения в сети с помощью прорежи- вания. (Вверху) Сеть прямого распространения в этом примере имеет два входных блока, один скрытый слой с двумя блоками и один выходной блок. (Внизу) Для прямого распространения с прореживанием мы случайно выби- раем вектор μ, имеющий по одному элементу для каждого входного и скры- того блока. Элементами μ являются нули или единицы, и каждый элемент выбирается независимо от других. Вероятность единицы – гиперпараметр, который обычно равен 0.5 для скрытых блоков и 0.8 для входных. Каждый блок сети умножается на соответствующий элемент маски, а затем прямое распространение продолжается по оставшейся части сети, как обычно. Это эквивалентно случайному выбору одной из подсетей на рис. 7.6 и прямому распространению в ней Чтобы сделать предсказания, баггинговый ансамбль должен собрать голоса всех своих членов. В этом контексте такой процесс называется выводом. До сих пор в опи- сании баггинга и прореживания не было явного требования о вероятностной при- роде модели. Теперь мы предположим, что роль модели заключается в нахождении\n--- Страница 228 ---\nПрореживание  227 распределения вероятностей. В случае баггинга i-я модель порождает распределение p(i)(y | x). Тогда предсказанием ансамбля будет среднее арифметическое всех распре- делений: (7.52) В случае прореживания каждая подмодель, задаваемая вектором-маской μ, опреде- ляет распределение вероятности p(y | x, μ). Среднее арифметическое по всем маскам равно (7.53) где p(μ) – распределение вероятности, которое использовалось для выборки μ на эта- пе обучения. Поскольку количество членов в этой сумме экспоненциально велико, вычислить ее можно только в случае, когда структура модели допускает какое-то упрощение. Пока что неизвестны нейронные сети, допускающие такое упрощение. Но мы можем аппроксимировать вывод с помощью выборки, усреднив выходы для нескольких ма-сок. Даже 10–20 масок часто достаточно для получения хорошего качества. Но есть подход еще лучше – он позволяет получить хорошую аппроксимацию предсказаний всего ансамбля, произведя всего одно прямое распространение. Для этого мы вместо среднего арифметического распределений, предсказанных члена-ми ансамбля, будем вычислять среднее геометрическое. В работе Warde-Farley et al. (2014) приведены аргументы и эмпирические свидетельства в пользу того, что в этом контексте среднее геометрическое дает качество, сравнимое со средним ариф- метическим. Вообще говоря, не гарантируется, что среднее геометрическое нескольких распре- делений вероятности само является распределением вероятности. Чтобы получить такую гарантию, мы потребуем, чтобы ни одна подмодель не назначала никаким со-бытиям вероятность 0, а затем произведем нормировку получившегося распределе- ния. Ненормированное распределение вероятности, определяемое средним геомет-рическим, имеет вид: (7.54) где d – число блоков, которые можно выбросить. Здесь для простоты взято равно- мерное распределение μ, но неравномерные распределения тоже допустимы. Чтобы можно было делать предсказания, необходимо перенормировать ансамбль: (7.55) Основная идея (Hinton et al., 2012c) прореживания состоит в том, что pensemble можно аппроксимировать, вычислив p(y | x) для одной модели: она включает все блоки, но веса связей, исходящих из i-го блока, умножаются на вероятность включения этого блока. Обоснование такой модификации – стремление получить правильное ожидае- мое значение выхода блока. Этот подход мы называем правилом вывода с масштаби- рованием весов. Пока не существует теоретического доказательства точности этого\n--- Страница 229 ---\n228  Регуляризация в глубоком обучении приближенного правила вывода в глубоких нелинейных сетях, но его эмпирическое поведение очень хорошее. Поскольку обычно принимается вероятность включения 1/2, то правило масшта- бирования весов сводится к делению весов пополам в конце обучения, после чего мо- дель используется как обычно. Другой способ получить тот же результат – умножать состояния блоков на 2 на этапе обучения. Как бы то ни было, цель состоит в том, что- бы ожидаемый суммарный вход в блок на этапе тестирования был приблизительно равен ожидаемому суммарному входу в тот же блок на этапе обучения, несмотря на то что в среднем половина блоков во время обучения отсутствует. Для многих классов моделей, не имеющих нелинейных скрытых блоков, правило вывода с масштабированием весов является точным. В качестве простого примера рассмотрим регрессионный классификатор с функцией softmax и n входными пере- менными, представленными вектором v: P(y = y | v) = softmax (W⏉v + b)y. (7.56) Мы можем проиндексировать это семейство моделей с помощью поэлементного умножения входа на двоичный вектор d: P(y = y | v; d) = softmax (W⏉(d ⊙ v + b)y. (7.57) Ансамблевый предиктор определяется путем нормировки среднего геометриче- ского предсказаний всех членов ансамбля: , (7.58) где (7.59) Чтобы убедиться, что правило масштабирования весов точное, упростим P~ ensemble : (7.60) (7.61) (7.62) (7.63) Поскольку P~ будет подвергнуто нормировке, мы можем игнорировать множители, не зависящие от y: (7.64)\n--- Страница 230 ---\nПрореживание  229 (7.65) (7.66) Подставляя это выражение в уравнение (7.58), получаем softmax-классификатор с весами 1/2W. Правило масштабирования весов является точным и в других конфигурациях, в т. ч. в регрессионных сетях с условно нормальными распределениями на выходе, а также в глубоких сетях, в скрытых слоях которых нет нелинейностей. Однако для глубоких моделей с нелинейностями это правило – всего лишь аппроксимация. Хотя теоретической оценки этой аппроксимации не существует, на практике она часто дает хорошие результаты. В работе Goodfellow et al. (2013a) экспериментально показано, что аппроксимация на основе масштабирования весов может работать лучше (в тер-минах верности классификации), чем аппроксимации методом Монте-Карло ансамб-левого предиктора. Это справедливо даже тогда, когда для аппроксимации методом Монте-Карло было разрешено делать выборку из 1000 подсетей. С другой стороны, в работе Gal and Ghahramani (2015) обнаружено, что для некоторых моделей удается получить более высокую верность классификации с помощью выборки объемом 20 и аппроксимации методом Монте-Карло. Похоже, что оптимальная аппроксимация вывода зависит от задачи. В работе Srivastava et al. (2014) показано, что прореживание эффективнее других стандартных вычислительно недорогих регуляризаторов: снижения весов, фильтра-ции с ограничением по норме и разреженной активации. Дальнейшего улучшения можно добиться, комбинируя прореживание с другими видами регуляризации. Одно из преимуществ прореживания – вычислительная простота. Применение прореживания на этапе обучения требует всего O(n) вычислений на каждый пример на каждое обновление – для генерирования n случайных двоичных чисел и умноже- ния их на состояние. В зависимости от реализации может понадобиться также память объемом O(n) для сохранения этих двоичных чисел до этапа обратного распростра- нения. Стоимость вывода с помощью обученной модели в расчете на один пример такая же, как если бы прореживание не использовалось, хотя к накладным расходам следует отнести стоимость однократного деления весов на 2 до применения вывода к примерам. У прореживания есть еще одно важное преимущество: оно не налагает существен- ных ограничений на тип модели или процедуру обучения. Оно одинаково хорошо работает практически с любой моделью, если в ней используется распределенное представление и ее можно обучить методом стохастического градиентного спуска. Сюда входят нейронные сети прямого распространения, вероятностные модели типа ограниченных машин Больцмана (Srivastava et al., 2014) и рекуррентные нейронные сети (Bayer and Osendorfer, 2014; Pascanu et al., 2014a). Многие другие стратегии ре-гуляризации сравнимой мощности налагают куда более строгие ограничения на ар-хитектуру модели. Хотя стоимость одного шага применения прореживания к конкретной модели пре- небрежимо мала, его общая стоимость для модели в целом может оказаться значи- тельной. Будучи методом регуляризации, прореживание уменьшает эффективную\n--- Страница 231 ---\n230  Регуляризация в глубоком обучении емкость модели. Чтобы компенсировать этот эффект, мы должны увеличить размер модели. Как правило, оптимальная ошибка на контрольном наборе при использова-нии прореживания намного ниже, но расплачиваться за это приходится гораздо боль-шим размером модели и числом итераций алгоритма обучения. Для очень больших наборов данных регуляризация не сильно снижает ошибку обобщения. В таких слу- чаях вычислительная стоимость прореживания и увеличение модели могут переве- сить выигрыш от регуляризации. Есть в нашем распоряжении очень мало помеченных обучающих примеров, то прореживание менее эффективно. Байесовские нейронные сети (Neal, 1996) оказы-ваются лучше на наборе данных Alternative Splicing Dataset (Xiong et al., 2011), со-держащем менее 5000 примеров (Srivastava et al., 2014). Если дополнительно име-ются непомеченные данные, то отбор признаков путем обучения без учителя может превзой ти прореживание. В работе Wager et al. (2013) показано, что в случае применения к линейной ре- грессии прореживание эквивалентно снижению весов по норме L 2, когда для каждого входного признака задается свой коэффициент снижения веса. Абсолютная величина каждого коэффициента определяет дисперсией признака. Аналогичные результаты имеют место для других линейных моделей. Для глубоких моделей прореживание не эквивалентно снижению весов. Использование стохастичности в обучении с прореживанием не является необхо- димым условием успеха. Это просто средство аппроксимации суммы по всем под-моделям. В работе Wang and Manning (2013) получены аналитические аппроксима- ции этой маргинализации. Найденная ими аппроксимация, известная под названием «быст рое прореживание», сходится быстрее благодаря уменьшению стохастично- сти при вычислении градиента. Этот метод можно применять и на стадии тестиро- вания, как теоретически более обоснованную (хотя вычислительно более дорогую) аппроксимацию среднего во всем подсетям, по сравнению с масштабированием весов. Быстрое прореживание по качеству почти не уступает стандартному на небольших нейронных сетях, но пока не сумело достичь существенного улучшения и не приме- нялось к большим задачам. Мало того что стохастичность не является необходимой для достижения регуляри- зирующего эффекта прореживания, она еще и недостаточна. Чтобы продемонстриро- вать это, в работе Warde-Farley et al. (2014) поставлены контрольные эксперименты с помощью метода усиленного прореживания (dropout boosting), в котором исполь- зуется точно такой же масочный шум, что в традиционном прореживании, однако эф- фект регуляризации не достигается. Алгоритм усиленного прореживания обучает ан-самбль совместно максимизировать логарифмическое правдоподобие на обучающем наборе. В том же смысле, в каком традиционное прореживание аналогично баггингу, этот подход аналогичен усилению. Как и предполагалось, эксперименты с усиленным прореживанием не показали почти никакого эффекта регуляризации, по сравнению с обучением всей сети как одной модели. Это показывает, что интерпретация проре- живания как баггинга не исчерпывается его интерпретацией как устойчивости к шуму. Эффект регуляризации баггингового ансамбля достигается, только когда стохастиче-ски выбранные члены ансамбля обучаются хорошо работать независимо друг от друга. Идея прореживания дала начало другим стохастическим подходам к обучению экспоненциально больших ансамблей моделей, разделяющих веса. Метод DropCon-nect – частный случай прореживания, в котором каждое произведение одного скаляр-\n--- Страница 232 ---\nПрореживание  231 ного веса и состояния одного скрытого блока рассматривается как блок, подлежащий выбрасыванию (Wan et al., 2013). Стохастический пулинг – это вариант рандоми- зированного пулинга (см. раздел 9.3) для построения ансамблей сверточных сетей, в котором каждая сеть занимается своей пространственной областью каждой карты признаков. До настоящего времени прореживание остается самым широко употреби-тельным методом неявных ансамблей. Одна из главных идей прореживания заключается в том, что обучение сети с эле- ментами стохастичности и предсказание путем усреднения по многим стохасти- ческим решениям является формой баггинга с разделением параметров. Выше мы описывали прореживание как баггинг ансамбля моделей, образованного путем вклю-чения и исключения блоков. Однако эта стратегия усреднения моделей может приме- няться не только к включению и исключению. В принципе, допустимы любые виды случайной модификации. На практике следует выбирать классы модификаций так, чтобы нейронная сеть могла обучиться стойкости к ним. В идеале хотелось бы также, чтобы семейство моделей допускало быстрое приближенное правило вывода. Мож-но представлять себе любой вид модификации, параметризованный вектором μ, как обуче ние ансамбля, состоящего из p(y | x, μ) для всех возможных значений μ. Не тре- буется, чтобы число значений μ было конечным. Например, μ может принимать веще- ственные значения. В работе Srivastava et al. (2014) показано, что умножение весов на μ ∼ 𝒩(1, I) может по качеству превосходить прореживание, основанное на двоичных масках. Поскольку 𝔼[μ] = 1, стандартная сеть автоматически реализует приближен- ный вывод в ансамбле без всякого масштабирования весов. До сих пор мы описывали прореживание исключительно как средство эффективно- го приближенного баггинга. Но есть и другой, гораздо более широкий взгляд на про- реживание. Метод прореживания обучает не просто баггинговый ансамбль моделей, а ансамбль моделей с общими скрытыми блоками. Это означает, что каждый скры- тый блок должен демонстрировать хорошее поведение вне зависимости от того, какие еще скрытые блоки есть в модели. Скрытые блоки должны быть готовы к тому, что окажутся в другой модели. На авторов работы Hinton et al. (2012c) оказала влия ние идея, заимствованная из биологии: половое размножение, состоящее в обмене генами между двумя разными организмами, оказывает давление эволюционного отбора на гены – они должны быть хороши не только сами по себе, но и готовы к обмену между организмами. Такие гены и такие признаки устойчивы к изменениям в окружающей среде, поскольку неспособны по ошибке адаптироваться к необычным признакам ор- ганизма или модели. Таким образом, прореживание регуляризирует каждый скры-тый блок, делая его не просто хорошим признаком, а хорошим в разных контекстах. В работе Warde-Farley et al. (2014) обучение с прореживанием сравнивается с обуче- нием больших ансамблей, и делается вывод, что прореживание дополнительно улуч- шает ошибку обобщения сверх того, что может быть получено с помощью ансамблей независимых моделей. Важно понимать, что своей мощью прореживание в немалой степени обязано тому факту, что к скрытым блокам применяется маскирующий шум. Это можно рассмат- ривать как форму высокоразумного адаптивного уничтожения информационного содержания входа, а не уничтожения исходных входных значений. Например, если модель обучает скрытый блок h i, который обнаруживает лицо, найдя нос, то выбра- сывание hi соответствует стиранию информации о присутствии носа в изображении. Модель должна обучить еще один hi, который либо избыточно кодирует присутствие\n--- Страница 233 ---\n232  Регуляризация в глубоком обучении носа, либо обнаруживает лицо по наличию другого признака, например рта. Тради- ционные приемы зашумления – добавление неструктурированного шума к входу – неспособны случайным образом стереть информацию о носе из изображения лица, разве что величина шума настолько велика, что из изображения удаляется почти вся информация. Уничтожение выделенных признаков, а не исходных значений позволя- ет процессу уничтожения воспользоваться всей накопленной моделью информацией о входном распределении. Еще один важный аспект прореживания – мультипликативность шума. Если бы шум был аддитивным с фиксированным масштабом, то скрытый блок линейной ректи- фикации h i с добавленным шумом ε мог бы просто обучиться делать hi очень большим, чтобы на его фоне добавленный шум казался незначительным. Мультипликативный шум препятствует таким патологическим решениям проблемы устойчивости к шуму. Еще один алгоритм глубокого обучения, пакетная нормировка, изменяет парамет- ризацию модели, стремясь ввести в скрытые блоки как аддитивный, так и мультипли- кативный шум на этапе обучения. Основная цель пакетной нормировки – улучшить оптимизацию, но шум может давать регуляризирующий эффект, так что иногда проре-живание оказывается излишним. Мы вернемся к пакетной нормировке в разделе 8.7.1. 7.13. Состязательное обучение Во многих случаях нейронные сети демонстрируют сравнимое с человеком качество в применении к независимому и одинаково распределенному тестовому набору. По- этому естественно задаться вопросом, смогли ли эти модели достичь по-настоящему человеческого понимания таких задач. Чтобы оценить уровень понимания задачи сетью , можно поискать примеры, которые модель классифицирует неправильно. В ра- боте Szegedy et al. (2014b) обнаружено, что даже нейронные сети, демонстрирующие верность классификации, приближающуюся к уровню человека, ошибаются почти в 100 процентах случаев, если им предъявить примеры, намеренно построенные с по- мощью специальной процедуры, которая ищет вход x′ вблизи точки x – такой, что выход модели сильно отличается в x′. Во многих случаях x′ может быть настолько по- хожа на x, что человек не сможет отличить исходный пример от состязательного, од- нако сеть будет давать совершенно разные предсказания. Пример показан на рис. 7.8. «гиббон» с уверенностью 99,3%«нематода» с уверенностью 8,2%y = «панда» с уверенностью 57,7% + ,007 × = x sign(∇x J(θ; x; y)) x + εsign(∇x J(θ; x; y)) Рис. 7.8  Г енерация состязательного примера, примененного к сети GoogLeNet (Szegedy et al., 2014a) на наборе данных ImageNet. Прибавив к входу неощутимо малый вектор, элементы которого равны знакам эле- ментов градиента функции стоимости, мы можем заставить GoogLeNet изменить классификацию изображения. Взято из работы Goodfellow et al. (2014b) с разрешения авторов\n--- Страница 234 ---\nТангенциальное расстояние, алгоритм распространения по касательной  233 У состязательного обучения много применений, в частности в области компьютер- ной безопасности, но они выходят за рамки этой главы. Однако же они представля- ют интерес в контексте регуляризации, поскольку состязательное обучение позволяет уменьшить частоту ошибок на исходном независимом и одинаково распределенном тес товом наборе – путем обучения на искусственно возмущенных примерах из обучаю- щего набора (Szegedy et al., 2014b; Goodfellow et al., 2014b). В работе Goodfellow et al. (2014b) показано, что одна из основных причин таких состязательных примеров – их избыточная линейность. Нейронные сети строятся в основном из линейных блоков. В некоторых экспериментах оказывалось, что в результате реализуемая ими полная функция почти линейна. Такие линейные функции хорошо поддаются оптимизации. К сожалению, значение линейной функции может очень быстро изменяться, если входов много. Если изменить каждый вход на ε, то линейная функция с весами w мо- жет измениться на ε||w|| 1, а в случае многомерного вектора w эта величина может ока- заться очень большой. Состязательное обучение подавляет такое излишне локально чувст вительное линейное поведение, побуждая сеть сохранять локальное постоянство в окрестности обучающих данных. Это можно рассматривать как явное введение апри- орной информации о локальном постоянстве в нейронную сеть, обучаемую с учителем. Состязательное обучение иллюстрирует широкие возможности использования большого семейства функций в комбинации с агрессивной регуляризацией. Чисто линейные модели, например логистическая регрессия, не могут противостоять состя-зательным примерам, поскольку обязаны быть линейными. Нейронные сети способ-ны представлять функции от почти линейных до почти локально постоянных и пото- му обладают достаточной гибкостью, чтобы уловить в обучающих данных тенденцию к линейности и вместе с тем обучиться противостоять локальным возмущениям. Состязательные примеры предоставляют также средства для обучения с частич- ным привлечением учителя. Если с точкой x не ассоциирована метка, то модель сама назначает ей некоторую метку y�. Назначенная моделью метка может отличаться от истинной, но если модель высокого качества, то вероятность правильности y� велика. Мы можем поискать состязательный пример x′, который заставляет классификатор выдать метку y′ – такую, что y′ ≠ y�. Состязательные примеры, при генерации которых используется не истинная метка, а метка, назначенная обученной моделью, называ- ются виртуальными состязательными примерами (Miyato et al., 2015). Затем класси- фикатор можно обучить назначать одинаковые метки примерам x и x′. Это побуждает классификатор обучать функцию, устойчивую к малым изменениям вдоль многооб- разия, на котором лежат непомеченные данные. В основу этого подхода положено предположение о том, что разные классы обычно лежат на несвязных многообразиях, так что малое возмущение не может привести к «перепрыгиванию» с одного много- образия на другое. 7.14. Тангенциальное расстояние, алгоритм распространения по касательной и классификатор по касательной к многообразию Многие алгоритмы машинного обучения стремятся преодолеть проклятие размерно-сти, предполагая, что данные лежат в окрестности многообразия низкой размерности (см. раздел 5.11.3).\n--- Страница 235 ---\n234  Регуляризация в глубоком обучении Одна из ранних попыток воспользоваться гипотезой о многообразии – алгоритм тангенциального расстояния (tangent distance) (Simard et al., 1993, 1998). Это не- параметрический алгоритм ближайшего соседа, в котором в качестве метрики ис- пользуется не обычное евклидово расстояние, а расстояние, выведенное из знания о многообразиях, вблизи которых сконцентрирована вероятность. Предполагает- ся, что мы пытаемся классифицировать примеры и что примеры, принадлежащие одному и тому же многообразию, относятся к одной и той же категории. Посколь- ку классификатор должен быть инвариантен относительно локальных факторов вариативности, соответствующих перемещению по многообразию, имеет смысл использовать в качестве меры близости соседей x 1 и x2 расстояние между много- образиями M1 и M2, которым эти точки принадлежат. Эта задача может оказаться вычислительно трудной (для нахождения ближайшей пары точек на M1 и M2 необ- ходимо решить задачу оптимизации), но есть и дешевая альтернатива – локально аппроксимировать Mi касательной плоскостью в точке xi и измерить расстояние между двумя касательными или между точкой и касательной плоскостью. Для это- го нужно решить систему небольшого числа линейных уравнений (их число равно размерности многообразий). Разумеется, в этом алгоритме необходимо задать ка- сательные векторы. Похожий алгоритм распространения по касательной (tangent prop) (Simard et al., 1992) (рис. 7.9) обучает классификатор на основе нейронной сети с дополнительным штрафом, цель которого – сделать каждый выход f(x) сети локально инвариантным относительно известных факторов вариативности. Эти факторы соответствуют пере-мещению вдоль многообразия, вблизи которого концентрируются примеры из од-ного класса. Локальная инвариантность достигается за счет требования, что вектор ∇ x f(x) ортогонален известным касательным векторам многообразия v(i) в точке x или, эквивалентно, что производная по направлению функции f в точке x в направлениях v(i) мала. Для этого добавляется регуляризирующий штраф Ω: (7.67) Конечно, этот регуляризатор можно умножить на подходящий гиперпараметр, и для большинства нейронных сетей нужно будет просуммировать по многим выхо- дам, а не ограничиваться одним выходом f(x), как мы для простоты поступили здесь. Как и в алгоритме тангенциального расстояния, касательные векторы задаются зара- нее, обычно исходя из формальных знаний о влиянии на изображения таких преобра- зований, как параллельный перенос, поворот и масштабирование. Алгоритм распро- странения по касательной применялся не только для обучения с учителем (Simard et al., 1992), но и в контексте обучения с подкреплением (Thrun, 1995). Распространение по касательной тесно связано с пополнением набора данных. В обоих случаях пользователь алгоритма кодирует априорные знания о задаче, за- давая множество преобразований, которые не должны изменять выход сети. Разни-ца же в том, что в случае пополнения набора данных сеть явно обучается правильно классифицировать разные входы, созданные применением таких преобразований. А для распространения по касательной не нужно явно посещать новую входную точ- ку. Вмес то этого алгоритм аналитически регуляризирует модель, обучая ее проти- востоять возмущениям в направлениях, соответствующих заданному преобразова- нию. Хотя такой аналитический подход обладает интеллектуальной элегантностью,\n--- Страница 236 ---\nТангенциальное расстояние, алгоритм распространения по касательной  235 у него есть два крупных недостатка. Во-первых, он регуляризирует модель только для противостояния бесконечно малым возмущениям. Явное пополнение набора данных прививает устойчивость к более сильным возмущениям. Во-вторых, инфи- нитезимальный подход испытывает трудности в применении к моделям, основанным на блоках линейной ректификации. В таких моделях уменьшение производных до- стигается только путем отключения блоков или уменьшения их весов. Они не могут уменьшить производные путем насыщения при больших значениях с сохранением больших весов, как сигмоида или гиперболический тангенс. Что же касается попол-нения набора данных, то оно хорошо работает с блоками линейной ректификации, поскольку для разных преобразованных вариантов одних и тех же исходных данных могут активироваться различные подмножества ректифицированных блоков. НормальКасательная x1x2 Рис. 7.9  Иллюстрация основной идеи алгоритма распространения по касательной (Simard et al., 1992) и классификатора по касательной к много- образию (Rifai et al., 2011c); тот и другой регуляризируют выходную функ- цию классификатора f(x). Каждая кривая представляет многообразие для одного класса, в данном случае они показаны как одномерные много- образия в двумерном пространстве. На одной кривой мы выбрали точку и провели два вектора: касательный и нормальный к многообразию клас- са. В многомерном пространстве касательных и нормальных направлений много. Мы ожидаем, что функция классификации будет быстро изменяться в направлении нормали к многообразию и не изменяться при перемеще- нии вдоль многообразия класса. И алгоритм распространения по каса- тельной, и классификатор по касательной к многообразию регуляризируют f(x), так чтобы она изменялась не слишком сильно, когда x перемещается вдоль многообразия. Для применения алгоритма распространения по ка-сательной пользователь должен вручную задать функции, вычисляющие касательные направления (например, исходя из того, что малый сдвиг не изменяет класса изображения), а классификатор по касательной к много- образию оценивает касательные направления, обучая автокодировщик аппроксимировать обучающие данные. Использование автокодировщиков для оценивания многообразий рассматривается в главе 14\n--- Страница 237 ---\n236  Регуляризация в глубоком обучении Распространение по касательной также связано с двойным обратным распрост- ранением (Drucker and LeCun, 1992) и состязательным обучением (Szegedy et al., 2014b; Goodfellow et al., 2014b). Идея двойного обратного распространения – регу- ляризировать якобиан с целью его уменьшения, тогда как при состязательном обуче- нии ищутся входы рядом с исходными входами, и модель обучается так, чтобы по- рождать на них те же самые выходы, что на исходных входах. И распространение по касательной, и пополнение набора данных с заданными вручную преобразованиями требуют, чтобы модель была инвариантна относительно заданных направлений из- менения входных данных. И двойное обратное распространение, и состязательное обучение требуют, чтобы модель была инвариантна во всех направлениях изменения входных данных при условии, что изменение мало. Как пополнение набора данных является неинфинитезимальным вариантом распространения по касательной, так состязательное обучение – неинфинитезимальный вариант двойного обратного рас- пространения. Классификатор по касательной к многообразию (Rifai et al., 2011c) позволяет обойтись без априорного знания касательных векторов. В главе 14 мы увидим, что автокодировщики умеют оценивать касательные векторы многообразия. Классифи-катор использует эту технику, чтобы избежать задания касательных векторов пользо-вателем. На рис. 14.10 показано, что оценки касательных векторов выходят за рамки классических инвариантов, вытекающих из геометрии изображений (относительно параллельного переноса, поворота и масштабирования), и включает факторы, кото- рые можно найти только в процессе обучения, потому что они зависят от объекта (например, движущиеся части тела). Поэтому алгоритм классификатора по касатель-ной к многообразию прост: (1) воспользоваться автокодировщиком, чтобы выявить структуру многообразия в процессе обучения без учителя, и (2) использовать най- денные касательные векторы для регуляризации классификатора на базе нейронной сети, как в алгоритме распространения по касательной (уравнение 7.67). В этой главе мы описали большинство общих стратегий регуляризации нейронных сетей. Регуляризация – центральная тема машинного обучения, и потому мы часто будем возвращаться к ней в других главах. Еще одна важная тема – оптимизация – будет рассмотрена в следующей главе.",
      "debug": {
        "start_page": 200,
        "end_page": 237
      }
    },
    {
      "name": "Глава 8. Оптимизация в обучении глубоких моделей 237",
      "content": "--- Страница 238 --- (продолжение)\nГлава 8 Оптимизация в обучении глубоких моделей Алгоритмы глубокого обучения включают оптимизацию в самых разных контекстах. Например, для выполнения вывода в таких моделях, как метод главных компонент, необходимо решать задачу оптимизации. Мы часто применяем аналитическую опти- мизацию для доказательства правильности или проектирования алгоритмов. Из всех многочисленных задач оптимизации, решаемых в глубоком обучении, самые трудные возникают при обучении нейронной сети. Нередко приходится затрачивать от не-скольких дней до нескольких месяцев работы на сотнях машин, чтобы решить всего одну задачу обучения нейронной сети. Поскольку проблема так важна, а ее решение обходится так дорого, разработаны специальные методы оптимизации. В этой главе мы рассмотрим методы оптимизации для обучения нейронных сетей. Если вы незнакомы с базовыми принципами градиентной оптимизации, рекомен- дуем прочитать главу 4, где приведен краткий обзор числовой оптимизации вообще. В этой главе нас будет интересовать один частный случай: нахождение парамет- ров θ нейронной сети, значительно уменьшающих функцию стоимости J(θ), которая обычно служит мерой качества, вычисляется на всем обучающем наборе и содержит дополнительные регуляризирующие члены. Начнем с того, чем оптимизация, используемая в алгоритме машинного обучения, отличается от чистой оптимизации. Затем перечислим несколько конкретных проб-лем, делающих оптимизацию нейронных сетей такой трудной задачей. После этого мы опишем несколько практических алгоритмов, включая как сами алгоритмы опти-мизации, так и стратегии выбора начальных параметров. Более развитые алгоритмы подстраивают свою скорость обучения или используют информацию о вторых произ- водных функции стоимости. И в заключение приведем обзор нескольких стратегий, заключающихся во включении простых алгоритмов оптимизации в высокоуровне- вые процедуры. 8.1. Чем обучение отличается от чистой оптимизации Алгоритмы оптимизации, используемые для обучения глубоких моделей, отличают-ся от традиционных алгоритмов оптимизации в нескольких отношениях. Машинное обучение обычно работает не напрямую. В большинстве ситуаций нас интересует не-\nГлава 8 Оптимизация в обучении глубоких моделей Алгоритмы глубокого обучения включают оптимизацию в самых разных контекстах. Например, для выполнения вывода в таких моделях, как метод главных компонент, необходимо решать задачу оптимизации. Мы часто применяем аналитическую опти- мизацию для доказательства правильности или проектирования алгоритмов. Из всех многочисленных задач оптимизации, решаемых в глубоком обучении, самые трудные возникают при обучении нейронной сети. Нередко приходится затрачивать от не-скольких дней до нескольких месяцев работы на сотнях машин, чтобы решить всего одну задачу обучения нейронной сети. Поскольку проблема так важна, а ее решение обходится так дорого, разработаны специальные методы оптимизации. В этой главе мы рассмотрим методы оптимизации для обучения нейронных сетей. Если вы незнакомы с базовыми принципами градиентной оптимизации, рекомен- дуем прочитать главу 4, где приведен краткий обзор числовой оптимизации вообще. В этой главе нас будет интересовать один частный случай: нахождение парамет- ров θ нейронной сети, значительно уменьшающих функцию стоимости J(θ), которая обычно служит мерой качества, вычисляется на всем обучающем наборе и содержит дополнительные регуляризирующие члены. Начнем с того, чем оптимизация, используемая в алгоритме машинного обучения, отличается от чистой оптимизации. Затем перечислим несколько конкретных проб-лем, делающих оптимизацию нейронных сетей такой трудной задачей. После этого мы опишем несколько практических алгоритмов, включая как сами алгоритмы опти-мизации, так и стратегии выбора начальных параметров. Более развитые алгоритмы подстраивают свою скорость обучения или используют информацию о вторых произ- водных функции стоимости. И в заключение приведем обзор нескольких стратегий, заключающихся во включении простых алгоритмов оптимизации в высокоуровне- вые процедуры. 8.1. Чем обучение отличается от чистой оптимизации Алгоритмы оптимизации, используемые для обучения глубоких моделей, отличают-ся от традиционных алгоритмов оптимизации в нескольких отношениях. Машинное обучение обычно работает не напрямую. В большинстве ситуаций нас интересует не-\n--- Страница 239 ---\n238  Оптимизация в обучении глубоких моделей которая мера качества P, которая определена относительно тестового набора и может оказаться вычислительно неприступной. Поэтому мы оптимизируем P косвенно. Мы уменьшаем другую функцию стоимости J(θ) в надежде, что при этом улучшится и P. Это резко отличается от чистой оптимизации, где минимизация J и есть конечная цель. Кроме того, алгоритмы оптимизации для обучения глубоких моделей обычно включают специализации для конкретной структуры целевых функций. Типичную функцию стоимости можно представить в виде среднего по обучающе- му набору: J(θ) = 𝔼(x, y)∼p �dataL(f(x; θ), y), (8.1) где L – функция потерь на одном примере, f(x; θ) – предсказанный выход для входа x, а p�data – эмпирическое распределение. В случае обучения с учителем y – ассоцииро- ванная с входом метка. В этой главе мы будем рассматривать нерегуляризированное обучение с учителем, когда аргументами L являются f(x; θ) и y. Этот случай три- виально обобщается, например, на включение в качестве аргументов θ или x или на исключение y из числа аргументов с целью разработки различных видов регуляриза- ции или обучения без учителя. Уравнение (8.1) определяет целевую функцию относительно обучающего набора. Но мы обычно предпочитаем минимизировать соответствующую целевую функцию, в которой математическое ожидание берется по порождающему данные распределе- нию p data, а не просто по конечному обучающему набору: J*(θ) = 𝔼(x, y)∼pdataL(f(x; θ), y). (8.2) 8.1.1. Минимизация эмпирического риска Цель алгоритма машинного обучения – уменьшить математическое ожидание ошиб- ки обобщения, описываемое формулой (8.2). Эта величина называется риском. Подчеркнем еще раз, что математическое ожидание берется по истинному распре-делению p data. Если бы мы знали истинное распределение pdata(x, y), то минимизация риска была бы задачей оптимизации, решаемой с помощью алгоритма оптимизации. Но когда pdata(x, y) неизвестно, а есть только обучающий набор примеров, мы имеем задачу машинного обучения. Простейший способ преобразовать задачу машинного обучения в задачу оптими- зации – минимизировать ожидаемые потери на обучающем наборе. Это значит, что мы заменяем истинное распределение p(x, y) эмпирическим распределением p�(x, y), определяемым по обучающему набору. И теперь требуется минимизировать эмпири- ческий риск: (8.3) где m – количество обучающих примеров. Процесс обучения, основанный на минимизации этой средней ошибки обучения, называется минимизацией эмпирического риска. В такой постановке машинное обуче ние все еще очень похоже на чистую оптимизацию. Вместо оптимизации риска напрямую мы оптимизируем эмпирический риск и надеемся, что и риск тоже заметно уменьшится. Существуют теоретические результаты, устанавливающие условия, при которых можно ожидать того или иного уменьшения истинного риска.\n--- Страница 240 ---\nЧем обучение отличается от чистой оптимизации  239 Тем не менее минимизация эмпирического риска уязвима для переобучения. Моде- ли высокой емкости могут попросту запомнить обучающий набор. Во многих случаях минимизация эмпирического риска практически неосуществима. Самые эффективные современные алгоритмы оптимизации основаны на градиентном спуске, но для мно-гих полезных функций потерь, например бинарной, производная малоинтересна (либо равна нулю, либо не определена). Из-за этих двух проблем минимизация эмпирическо-го риска редко применяется в контексте глубокого обучения. Вместе нее используется несколько иной подход, при котором фактически оптимизируемая величина еще силь-нее отличается от той, которую мы хотели бы оптимизировать на самом деле. 8.1.2. Суррогатные функции потерь и ранняя остановка Иногда реально интересующая нас функция потерь (скажем, ошибка классификации) и та, что может быть эффективно оптимизирована, – «две большие разницы». Напри- мер, задача точной минимизации ожидаемой бинарной функции потерь обычно нераз-решима (она экспоненциально зависит от размерности входных данных), даже для ли-нейного классификатора (Marcotte and Savard, 1992). В таких случаях оптимизируют суррогатную функцию потерь, выступающую в роли заместителя истинной, но обла- дающую рядом преимуществ. Например, в качестве суррогата бинарной функции по- терь часто берут отрицательное логарифмическое правдоподобие правильного класса. Отрицательное логарифмическое правдоподобие позволяет модели оценить условную вероятность классов при известном выходе, и если модель делает это хорошо, то она сможет выбрать классы, дающие наименьшую ожидаемую ошибку классификации. В некоторых случаях суррогатная функция потерь позволяет достичь даже боль- ших успехов в обучении. Например, на тестовом наборе бинарная потеря продолжает уменьшаться еще долго после того, как на обучающем наборе достигла нуля, если обучение производилось с использованием суррогата в виде логарифмического прав- доподобия. Объясняется это тем, что даже когда ожидаемая бинарная потеря равна 0, робастность классификатора можно еще улучшить, отодвинув классы дальше друг от друга и получив тем самым более уверенный и надежный классификатор, который извлекает больше информации из обучающих данных, чем было бы возможно в слу- чае простой минимизации средней бинарной потери на обучающем наборе. Очень важное различие между оптимизацией вообще и применяемой в алгоритмах обучения заключается в том, что алгоритмы обучения обычно останавливаются не в локальном минимуме. Вместо этого алгоритм, как правило, минимизирует сурро- гатную функцию потерь, но останавливается, когда выполнено условие сходимости, основанное на идее ранней остановки (раздел 7.8). Типичное условие ранней останов-ки основано на истинной функции потерь, например вычислении бинарной функции потерь на контрольном наборе, и предназначено для того, чтобы остановить работу алгоритма, когда возникает угроза переобучения. Обучение зачастую заканчивается, когда производные суррогатной функции потерь все еще велики, и этим разительно отличается от чистой оптимизации, при которой считается, что алгоритм сошелся, если градиент стал очень малым. 8.1.3. Пакетные и мини-пакетные алгоритмы Еще одно отличие алгоритмов машинного обучения от общих алгоритмов оптимиза- ции состоит в том, что целевая функция обычно представлена в виде суммы по обучаю- щим примерам. Типичный алгоритм оптимизации в машинном обучении вычисляет\n--- Страница 241 ---\n240  Оптимизация в обучении глубоких моделей каждое обновление параметров, исходя из ожидаемого значения функции стоимости, оцениваемого только по подмножеству членов полной функции стоимости. Например, оценка максимального правдоподобия, рассматриваемая в логарифми- ческом пространстве, представлена в виде суммы по всем примерам: (8.4) Максимизация этой суммы эквивалентна максимизации математического ожида- ния эмпирического распределения, определяемого обучающим набором: J(θ) = 𝔼x, y∼p�datalog pmodel(x, y; θ). (8.5) Большинство свойств целевой функции J, используемой чуть ли не во всех наших алгоритмах оптимизации, также выражается в терминах математического ожидания по обучающему набору. Например, чаще всего используется ее градиент: ∇θ J(θ) = 𝔼x, y∼p�data∇θ log pmodel(x, y; θ). (8.6) Вычисление точного значения этого математического ожидания обошлось бы очень дорого, потому что для этого нужно вычислить модель на каждом примере из набора данных. На практике можно случайно выбрать небольшое число примеров и усреднить только по ним. Напомним, что стандартная ошибка среднего (формула 5.46), оцененная по выбор- ке объема n, равна σ/√_ n, где σ – истинное стандартное отклонение выборки. Знамена- тель σ/√_ n показывает, что точность оценки градиента с увеличением объема выборки растет медленнее, чем линейно. Сравним две гипотетические оценки градиента, одна на основе 100 примеров, другая – 10 000. Для вычисления второй оценки потребу- ется в 100 раз больше времени, но стандартная ошибка среднего уменьшится только в 10 раз. Большинство алгоритмов оптимизации сходится гораздо быстрее (в терми- нах общего времени вычислений, а не числа обновлений), если им позволено быстро вычислять приближенные оценки градиента вместо медленного вычисления точного значения. Еще одно сообщение в пользу статистического оценивания градиента по небольшой выборке связано с избыточностью обучающего набора. В худшем случае все m приме- ров в обучающем наборе в точности совпадают. Оценка градиента по выборке дала бы правильное значение, взяв всего один пример, т. е. было бы затрачено в m раз меньше времени, чем при наивном подходе. На практике нам вряд ли встретится худший слу-чай, но все же можно найти много примеров, дающих очень похожий вклад в градиент. Алгоритмы оптимизации, в которых используется весь обучающий пакет, назы- ваются пакетными, или детерминированными, градиентными методами, поскольку обрабатывают сразу все примеры одним большим пакетом. Эта терминология может вызывать путаницу, потому что слово «пакет» часто употребляется также для обозна-чения мини-пакета, применяемого в алгоритме стохастического градиентного спуска. Как правило, термин «пакетный градиентный спуск» подразумевает использование всего обучающего набора, а термин «пакет», применяемый для описания группы примеров, таких коннотаций *уточнить слово* не имеет. Например, словосочетание «размер пакета» часто означает размер мини-пакета. Алгоритмы оптимизации, в которых используется по одному примеру за раз, иног- да называют стохастическими, или онлайновыми, методами. Термин «онлайновый»\n--- Страница 242 ---\nЧем обучение отличается от чистой оптимизации  241 обычно резервируется для случая, когда примеры выбираются из непрерывного по- тока, а не из обучающего набора фиксированного размера, по которому можно совер- шать несколько проходов. Большинство алгоритмов, используемых в глубоком обучении, находится где-то посередине – число примеров в них больше одного, но меньше размера обучающего набора. Традиционно они назывались мини-пакетными, или мини-пакетными стоха- стическими, методами, а сейчас – просто стохастическими. Канонический пример стохастического метода – стохастический градиентный спуск, который подробно будет описан в разделе 8.3.1. На размер мини-пакета оказывают влияние следующие факторы: чем больше пакет, тем точнее оценка градиента, но зависимость хуже линейной; если пакет очень мал, то не удается в полной мере задействовать преимущества многоядерной архитектуры. Поэтому существует некий абсолютный минимум размера пакета – такой, что обработка мини-пакетов меньшего размера не дает никакого выигрыша во времени; если все примеры из пакета нужно обрабатывать параллельно (так обычно и бывает), то размер пакета лимитирован объемом памяти. Для многих аппа- ратных конфигураций размер пакета – ограничивающий фактор; для некоторых видов оборудования оптимальное время выполнения достига-ется при определенных размерах массива. Так, для GPU наилучшие результаты получаются, когда размер пакета – степень 2. Типичный пакет имеет размер от 32 до 256, а для особо больших моделей иногда пробуют 16; небольшие пакеты могут дать эффект регуляризации (Wilson and Marti-nez, 2003), быть может, из-за шума, который они вносят в процесс обучения. Ошибка обобщения часто оказывается наилучшей для пакета размера 1. Но для обуче ния с таким маленьким размером пакета нужна небольшая скорость обучения для обеспечения устойчивости из-за высокой дисперсии оценки гра-диента. Общее время работы может оказаться очень большим из-за увеличения числа шагов – как из-за пониженной скорости обучения, так и потому, что для перебора всего обучающего набора требуется больше шагов. В зависимости от вида алгоритма используется разная информация из мини-па- кета, причем разными способами. Одни алгоритмы более чувствительны к ошибке выборки, чем другие, либо потому что в них используется информация, которую трудно оценить точно на небольшой выборке, либо потому что информация исполь-зуется так, что ошибка выборки усиливается. Методы, которые вычисляют обновле-ния только на основе градиента g, обычно сравнительно устойчивы и могут работать с пакетами небольшого размера, порядка 100. Методы второго порядка, в которых используется также матрица Гессе H и которые вычисляют такие обновления, как H –1g, обычно нуждаются в пакетах гораздо большего размера, порядка 10 000. Та- кие большие пакеты нужны, чтобы свести к минимуму флуктуации в оценках H–1g. Предположим, что H оценена идеально, но ее число обусловленности плохое. Тогда умно жение на H или на обратную к ней матрицу усиливает уже имеющиеся ошибки, в данном случае ошибки оценки g. Следовательно, очень малые изменения в оценке g могут привести к большим изменениям при обновлении H–1g, хотя оценка H точна. На самом деле оценка H – всего лишь аппроксимация, поэтому ошибка обновления H–1g будет даже больше, чем вследствие одного лишь применения плохо обусловлен- ной операции к оценке g.\n--- Страница 243 ---\n242  Оптимизация в обучении глубоких моделей Важно также, чтобы мини-пакеты выбирались случайно. Для вычисления несме- щенной оценки ожидаемого градиента по выборке необходимо, чтобы примеры были независимы. Мы также хотим, чтобы две последовательные оценки градиента были независимы друг от друга, поэтому два последовательных мини-пакета примеров тоже должны быть независимы. Многие наборы данных естественно упорядочены так, что между последовательными примерами имеется высокая корреляция. Напри-мер, длинный список результатов анализа крови, скорее всего, организован так, что сначала идут пять анализов одного пациента, взятых в разные моменты времени, за- тем – три анализа второго пациента и т. д. Если бы мы выбирали примеры из такого на- бора, то каждый мини-пакет оказался бы очень сильно смещенным, т. к. представлял бы преимущественно одного пациента из многих присутствующих в наборе данных. В тех случаях, когда порядок примеров в наборе не случаен, необходимо перетасовать пакет, прежде чем формировать мини-пакеты. Для очень больших наборов, насчи-тывающих миллиарды примеров, выбирать примеры по-настоящему случайно при каждом построении мини-пакета не всегда возможно. К счастью, на практике обычно достаточно перетасовать набор один раз и затем хранить его в таком виде. При этом получается фиксированный набор возможных мини-пакетов последовательных при-меров, которым вынуждены будут пользоваться все обучаемые впоследствии модели, и каждая модель будет видеть примеры в одном и том же порядке при проходе по обучаю щим данных. Но похоже, что такое отклонение от истинно случайного выбора не оказывает значимого негативного эффекта. Тогда как полное пренебрежение пере-тасовкой примеров способно серьезно снизить эффективность алгоритма. Во многих задачах оптимизации в машинном обучении примеры структурирова- ны достаточно хорошо, чтобы можно было параллельно вычислять несколько обнов-лений по разным примерам. Иными словами, мы можем вычислять обновление, минимизирующее J(X) для одного мини-пакета X, одновременно с вычислением об- новления для нескольких других мини-пакетов. Такие асинхронные параллельные распределенные подходы обсуждаются подробнее в разделе 12.1.3. Интересным обоснованием мини-пакетного стохастического градиентного спуска является тот факт, что он происходит в направлении градиента истинной ошибки обоб- щения (уравнение 8.2), при условии что примеры не повторяются. В большинстве реа- лизаций этого алгоритма набор данных перетасовывается один раз, после чего по нему производится несколько проходов. На первом проходе каждый мини-пакет использу-ется для вычисления несмещенной оценки истинной ошибки обобщения. На втором проходе оценка становится смещенной, потому что получена повторной выборкой уже использованных значений, а не новых примеров из порождающего распределения. Тот факт, что алгоритм стохастического градиентного списка действительно мини- мизирует ошибку обобщения, отчетливее всего виден в онлайновом обучении, когда примеры или мини-пакеты выбираются из потока данных. Иными словами, обучае-мая модель не получает обучающего набора фиксированного размера, а, подобно жи-вому существу, в каждый момент времени видит новый пример; при этом каждый пример (x, y) поступает из порождающего распределения p data(x, y). В такой ситуации примеры никогда не повторяются, каждое испытание – честная выборка из pdata. Эквивалентность проще всего установить, когда x и y – дискретные величины. В таком случае ошибку обобщения (8.2) можно переписать в виде суммы: (8.7)\n--- Страница 244 ---\nПроблемы оптимизации нейронных сетей  243 и точный градиент равен (8.8) Мы уже демонстрировали тот же факт для логарифмического правдоподобия в уравнениях (8.5) и (8.6); теперь мы видим, что это справедливо и для других функ- ций L. Аналогичный результат можно доказать для случая, когда x и y непрерывны, если наложить на pdata и L не слишком обременительные ограничения. Таким образом, мы можем получить несмещенную оценку точного градиента ошибки обобщения, выбрав мини-пакет примеров {x(1), …, x(m)} с соответственными метками y(i) из порождающего распределения pdata, а затем вычислив для этого мини- пакета градиент функции потерь относительно параметров: (8.9) Для обновления θ в направлении g � выполняется СГС по ошибке обобщения. Разумеется, эта интерпретация справедлива, только когда примеры не используются повторно. Тем не менее обычно для получения наилучших результатов стоит сделать не- сколько проходов по обучающему набору, если только он не слишком велик. Если ис-пользуется несколько таких периодов, то лишь в первом спуск происходит в направле- нии несмещенного градиента ошибки обобщения, но, конечно, дополнительные периоды обычно дают достаточный выигрыш в плане уменьшения ошибки обучения, чтобы пере- весить вред от увеличения разрыва между ошибкой обучения и ошибкой тестирования. В тех случаях, когда размер набора данных растет быстрее, чем вычислительные ресурсы для его обработки, все чаще в машинном обучении переходят к практике, когда каждый обучающий пример используется ровно один раз, или даже произво-дится неполный проход по обучающему набору. Если обучающий набор очень велик, то переобучение перестает быть проблемой, и на первый план выходят проблемы не- дообучения и вычислительной эффективности. См. также работу Bottou and Bous- quet (2008), где обсуждается влияние вычислительных узких мест на ошибку обоб-щения при увеличении числа обучающих примеров. 8.2. Проблемы оптимизации нейронных сетей В общем случае оптимизация – чрезвычайно трудная задача. Традиционно в машин- ном обучении избегали сложностей общей оптимизации за счет тщательного выбора целевой функции и ограничений, гарантирующих выпуклость задачи оптимизации. При обучении нейронных сетей приходится сталкиваться с общим невыпуклым слу- чаем. Но даже выпуклая оптимизация не обходится без осложнений. В этом разделе мы дадим обзор нескольких наиболее заметных проблем оптимизации, возникающих в процессе обучения глубоких моделей. 8.2.1. Плохая обусловленность Ряд проблем возникает даже при оптимизации выпуклых функций. Самая известная из них – плохая обусловленность матрицы Гессе H. Это очень общая проблема, при- сущая большинству методов численной оптимизации, все равно, выпуклой или нет, она подробно описана в разделе 4.3.1.\n--- Страница 245 ---\n244  Оптимизация в обучении глубоких моделей Считается, что проблема плохой обусловленности присутствует во всех задачах обучения нейронных сетей. Она может проявляться в «застревании» СГС в том смыс- ле, что даже очень малые шаги увеличивают функцию стоимости. Напомним, что согласно формуле (4.9) разложение функции стоимости в ряд Тей- лора до членов второго порядка показывает, что шаг градиентного спуска величиной –εg увеличивает стоимость на 1/2 ε2g⏉Hg – εg⏉g. (8.10) Плохая обусловленность градиента становится проблемой, когда 1/2 ε2g⏉Hg больше εg⏉g. Чтобы понять, страдает ли задача обучения нейронной сети от плохой обуслов- ленности, можно понаблюдать за квадратом нормы градиента g⏉g и членом g⏉Hg. Во многих случаях норма градиента не сильно уменьшается за время обучения, тогда как член g ⏉Hg возрастает больше, чем на порядок. В результате обучение происходит очень медленно, несмотря на большой градиент, т. к. приходится уменьшать скорость обучения, чтобы компенсировать еще большую кривизну. На рис. 8.1 приведен при-мер, когда градиент значительно увеличивается в ходе успешного обучения нейрон- ной сети. Время обучения (периоды) Время обучения (периоды) 16 14 1210 86 4 20 –21,0 0,9 0,80,7 0,6 0,5 0,4 0,30,2 0,1Норма градиента Частота ошибок классификации –50 050100150200250 050100 150 200 250 Рис. 8.1  Градиентный спуск часто не находит никакой критической точки. В этом примере норма градиента возрастает на протяжении всего процесса обучения сверточной нейронной сети для обнаружения объек- тов. (Слева) На диаграмме рассеяния показана зависимость вычисленной нормы градиента от времени. Для наглядности показана лишь одна нор-ма на каждый период. Скользящее среднее всех норм градиента показано сплошной линией. Очевидно, что норма градиента со временем возрастает, а не убывает, как было бы, если бы процесс обучения сходился к критиче- ской точке. (Справа) Несмотря на возрастание градиента, процесс обуче-ния можно считать успешным. Ошибка классификации на контрольном на-боре убывает до низкого уровня Хотя плохая обусловленность характерна не только для обучения нейронных се- тей, некоторые методы борьбы с ней, используемые в других контекстах, к нейронным сетям плохо применимы. Например, метод Ньютона – отличное средство минимиза-ции выпуклых функций с плохо обусловленными гессианами, но, как мы покажем в следующих разделах, для применения к нейронным сетям этот метод нуждается в существенной модификации.\n--- Страница 246 ---\nПроблемы оптимизации нейронных сетей  245 8.2.2. Локальные минимумы Одна из самых важных черт выпуклой оптимизации состоит в том, что такую задачу можно свести к задаче нахождения локального минимума. Гарантируется, что любой локальный минимум одновременно является глобальным. У некоторых выпуклых функций в нижней части графика имеется не единственный глобальный минимум, а целый плоский участок. Однако любая точка на плоском участке является допусти- мым решением. При оптимизации выпуклой функции мы точно знаем, что, обнару- жив критическую точку любого вида, мы нашли хорошее решение. У невыпуклых функций, в частности нейронных сетей, локальных минимумов может быть несколько. Более того, почти у любой глубокой модели гарантированно имеется множество локальных минимумов. Впрочем, как мы увидим, это не всегда является серьезной проблемой. Нейронные сети и вообще любые модели с несколькими эквивалентно параметри- зованными латентными переменными имеют несколько локальных минимумов из-за проблемы идентифицируемости модели. Говорят, что модель идентифицируемая, если существует достаточно большой обучающий набор, который может исключить все конфигурации параметров модели, кроме одной. Модели с латентными перемен- ными часто не являются идентифицируемыми, потому что мы можем получить эк-вивалентные модели, меняя латентные переменные местами. Например, можно было бы взять нейронную сеть и модифицировать слой 1, заменив входящий вектор весов для блока i входящим векторов весов для блока j и наоборот, а затем проделав то же самое для исходящих векторов весов. Если имеется m слоев по n блоков в каждом, то существует n! m способов упорядочить скрытые блоки. Такой вид неидентифицируе- мости называется симметрией пространства весов. Помимо симметрии пространства весов, во многих разновидностях нейронных се- тей есть и другие причины неидентифицируемости. Например, в любой сети с блока- ми линейной ректификации или maxout-блоками можно умножить все входящие веса и смещения блока на α, одновременно умножив исходящие веса на 1/α. Это означает, что если функция стоимости не включает таких членов, как снижение весов, которые напрямую зависят от весов, а не от выходов модели, то все локальные минимумы сети лежат на (m×n)-мерном гиперболоиде эквивалентных локальных минимумов. Проблема идентифицируемости модели означает, что функция стоимости нейрон- ной сети может иметь очень большое, даже несчетное, множество локальных миниму-мов. Однако все локальные минимумы, проистекающие из неидентифицируемости, эквивалентны между собой с точки зрения значения функции стоимости. Поэтому такое проявление невыпуклости не составляет проблемы. Локальные минимумы становятся проблемой, если значение функции стоимости в них велико, по сравнению со значением в глобальном минимуме. Можно постро- ить небольшую нейронную сеть, даже без скрытых блоков, в которой стоимость в ло- кальных минимумах будет выше, чем в глобальном (Sontag and Sussman, 1989; Brady et al., 1989; Gori and Tesi, 1992). Если локальные минимумы с высокой стоимостью встречаются часто, то градиентные алгоритмы оптимизации сталкиваются с серьез- ной проблемой. Вопрос о том, много ли локальных минимумов с высокой стоимостью в практиче- ски интересных сетях и наталкиваются ли на них алгоритмы оптимизации, остается открытым. В течение многих лет среди практиков бытовало мнение, что локальные минимумы – распространенная проблема, преследующая оптимизацию нейронных\n--- Страница 247 ---\n246  Оптимизация в обучении глубоких моделей сетей. Но сегодня так не кажется. В этой области ведутся активные исследования, но специалисты склоняются к мнению, что для достаточно больших нейронных се- тей в большинстве локальных минимумов значение функции стоимости мало и что важно не столько найти глобальный минимум, сколько какую-нибудь точку в прост- ранстве параметров, в которой стоимость низкая, пусть и не минимальная (Saxe et al., 2013; Dauphin et al., 2014; Goodfellow et al., 2015; Choromanska et al., 2014). Многие специалисты-практики приписывают почти все трудности, связанные с оптимизацией нейронных сетей, локальным минимумам. Мы призываем их тща- тельнее изучать конкретные задачи. Чтобы исключить локальные минимумы как возможную причину проблем, имеет смысл построить график зависимости нормы градиента от времени. Если норма градиента не убывает почти до нуля, то проблема не в локальных минимумах и вообще не в критических точках. В пространствах высо- кой размерности установить с полной определенностью, что корень зла – локальные минимумы, бывает очень трудно. Малые градиенты характерны для многих особен-ностей строения, помимо локальных минимумов. 8.2.3. Плато, седловые точки и другие плоские участки Для многих невыпуклых функций в многомерных пространствах локальные мини- мумы (и максимумы) встречаются гораздо реже других точек с нулевым градиентом: седловых точек. В одних точках в окрестности седловой стоимость выше, чем в сед- ловой точке, в других – ниже. В седловой точке матрица Гессе имеет как положитель- ные, так и отрицательные собственные значения. В точках, лежащих вдоль собствен- ных векторов с положительными собственными значениями, стоимость выше, чем в седловой точке, а в точках, лежащих вдоль собственных векторов с отрицательны- ми собственными значениями, – ниже. Можно считать, что седловая точка является локальным минимумом в одном сечении графика функции стоимости и локальным максимумом – в другом. Это иллюстрирует рис. 4.5. Многие классы случайных функций демонстрируют следующее поведение: в прост- ранствах низкой размерности локальные минимумы встречаются часто, а в простран- ствах большей размерности они редкость, зато часто встречаются седловые точки. Для функции f : ℝ n → ℝ такого типа ожидаемое отношение числа седловых точек к числу локальных максимумов растет экспоненциально с ростом n. Чтобы интуитивно по- нять причины такого поведения, заметим, что в локальном минимуме все собственные значения матрицы Гессе положительны. В седловой точке у матрицы Гессе есть как положительные, так и отрицательные собственные значения. Представьте себе, что знак собственного значения определяется подбрасыванием монеты. В одномерном случае для получения локального минимума достаточно, чтобы один раз выпал орел. А в n-мерном случае вероятность, что n раз подряд выпадет орел, экспоненциально убывает. Обзор теоретических работ на эту тему см. в Dauphin et al. (2014). У многих случайных функций есть удивительное свойство: вероятность положи- тельности собственных значений матрицы Гессе возрастает при приближении к об- ластям низкой стоимости. В нашей аналогии с подбрасыванием монеты это означает, что вероятность n раз подряд выкинуть орла выше, если мы находимся в критической точке с низкой стоимостью. Это также означает, что локальные минимумы с низкой стоимостью гораздо вероятнее, чем с высокой. Критические точки с высокой стои- мостью с куда большей вероятностью являются седловыми точками. А критические точки с очень высокой стоимостью, скорее всего, являются локальными максимумами.\n--- Страница 248 ---\nПроблемы оптимизации нейронных сетей  247 Это верно для многих классов случайных функций. А для нейронных сетей? В ра- боте Baldi and Hornik (1989) теоретически доказано, что мелкие автокодировщики (описанные в главе 14 сети прямого распространения, обученные копировать вход в выход) без нелинейностей имеют глобальные минимумы и седловые точки, но не имеют локальных минимумов со стоимостью выше, чем в глобальном минимуме. Не приводя доказательства, они заметили, что эти результаты обобщаются и на более глубокие сети без нелинейностей. Выходом такой сети является линейная функция от входа, но они полезны в качестве модели нелинейных нейронных сетей, поскольку функция потерь такой сети – невыпуклая функция своих параметров. Подобные сети, по существу, представляют собой просто композицию нескольких матриц. В работе Saxe et al. (2013) приведены точные решения для полной динамики обучения такой сети и показано, что обучение таких моделей улавливает многие качественные осо- бенности, наблюдаемые при обучении глубоких моделей с нелинейными функциями активации. В работе Dauphin et al. (2014) экспериментально показано, что у реальных нейронных сетей также имеются функции потерь, содержащие очень много седловых точек с высокой стоимостью. В работе Choromanska et al. (2014) приведены допол- нительные теоретические аргументы, доказывающие, что это справедливо еще для одного класса многомерных случайных функций, родственного нейронным сетям. Каковы последствия изобилия седловых точек для алгоритмов обучения? В слу- чае оптимизации первого порядка, когда используется только информация о гради- енте, ситуация неясна. Градиент часто оказывается очень мал в окрестности седловой точки. С другой стороны, есть эмпирические свидетельства в пользу того, что метод градиентного спуска во многих случаях способен выйти из седловой точки. В работе Goodfellow et al. (2015) наглядно показано несколько траекторий обучения современ-ных нейронных сетей, один из таких примеров приведен на рис. 8.2. На этих рисунках видно уплощение функции стоимости вблизи выраженной седловой точки, где все веса равны нулю, но видно и то, что траектория градиентного спуска быстро поки- дает этот участок. В той же работе высказывается предположение, что можно анали- тически доказать, что седловая точка отталкивает, а не притягивает траекторию не- прерывного по времени градиентного спуска, но что ситуация может оказаться иной в более реалистичных случаях применения метода градиентного спуска. Для метода Ньютона седловые точки представляют очевидную проблему. Идея алгоритма градиентного спуска – «спуск с горы», а не явный поиск критических точек. С другой стороны, метод Ньютона специально предназначен для поиска то- чек с нулевым градиентом. Без надлежащей модификации он вполне может найти седловую точку. Изобилие седловых точек в многомерных пространствах объясняет, почему методы второго порядка не смогли заменить градиентный спуск в обучении нейронных сетей. В работе Dauphin et al. (2014) описан бесседловой метод Нью- тона (saddle-free Newton method) для оптимизации второго порядка и показано, что он значительно улучшает традиционный вариант. Методы второго порядка все еще с трудом масштабируются на большие нейронные сети, но если этот бесседловой ме- тод удастся масштабировать, то он сулит интересные перспективы. Помимо минимумов и седловых точек, существуют и другие виды точек с нулевым градиентом. С точки зрения оптимизации, максимумы очень похожи на седловые точки – многие алгоритмы не притягиваются к ним, но немодифицированный метод Ньютона не из их числа. Для многих классов случайных функций в многомерном пространстве максимумы – такая же экспоненциальная редкость, как и минимумы.\n--- Страница 249 ---\n248  Оптимизация в обучении глубоких моделей Проекция 2 θПроекция 1 θJ(θ) Рис. 8.2  Визуализация функции стоимости нейронной сети. Похожие визуализации характерны для нейронных сетей прямого распространения, а также сверточных и рекуррентных, применяемых в реальных задачах рас- познавания объектов и обработки естественных языков. Как ни странно, на этих визуализациях обычно не встретишь много бросающихся в глаза препятствий. До триумфа алгоритма стохастического градиентного спуска в применении к обучению очень больших моделей, датируемого пример- но 2012 годом, считалось, что поверхности функций стоимости нейронных сетей обладают куда более невыпуклой структурой, чем видно на этих про-екциях. Основное присутствующее здесь препятствие – седловая точка вы- сокой стоимости вблизи начальных значений параметров, но, как показы-вает синяя линия, траектория обучения СГС быстро покидает эту седловую точку. Основное время затрачено на пересечение сравнительно плоской долины функции стоимости, наверное, вследствие высокого шума при вы-числении градиента, плохой обусловленности гессиана в этой области или просто из-за необходимости обойти высокую «гору», видную на рисунке, по огибающей дуге. Изображение взято из работы Goodfellow et al. (2015) с разрешения авторов Могут также существовать широкие плоские области с постоянным значением. В этих областях равны нулю и градиент, и гессиан. Такие вырожденные участки – серь езная проблема для всех алгоритмов численной оптимизации. В выпуклой задаче широкая плоская область должна целиком состоять из глобальных минимумов, но в общем случае ей могут соответствовать и большие значения целевой функции. 8.2.4. Утесы и резко растущие градиенты В нейронных сетях с большим числом слоев часто встречаются очень крутые участ- ки, напоминающие утесы (рис. 8.3). Это связано с перемножением нескольких боль- ших весов. На стене особенно крутого утеса шаг обновления градиента может при-вести к очень сильному изменению параметров, что обычно заканчивается «срывом» с утеса. Утес представляет опасность вне зависимости от того, приближаемся мы к нему сверху или снизу, но, по счастью, самых печальных последствий можно избежать с по- мощью эвристической техники отсечения градиента, описанной в разделе 10.11.1. Основная идея – вспомнить, что градиент определяет не оптимальный размер шага, а лишь оптимальное направление в бесконечно малой области. Когда традиционный алгоритм градиентного спуска предлагает сделать очень большой шаг, вмешивает-ся эвристика отсечения, и в результате шаг уменьшается, так что становится менее\n--- Страница 250 ---\nПроблемы оптимизации нейронных сетей  249 вероятным выход за пределы области, в которой градиент указывает приближен- ное направление самого крутого спуска. Утесы чаще всего встречаются в функциях стои мости рекуррентных нейронных сетей, поскольку в таких моделях вычисляет- ся произведение большого числа множителей, по одному на каждый временной шаг. Поэтому чем длиннее временная последовательность, тем больше количество пере-множений. 8.2.5. Долгосрочные зависимости Еще одна трудность для алгоритмов оптимизации нейронной сети возникает, когда граф вычислений становится очень глубоким. Такие графы характерны для много-слойных сетей прямого распространения, а также для рекуррентных сетей (глава 10), в которых очень глубокий граф вычислений создается в результате применения од- ной и той же операции на каждом шаге длинной временной последовательности. Пов- торное применение одних и тех же параметров вызывает особенно трудно преодоли- мые сложности. w b J(w; b) Рис. 8.3  Целевая функция сильно нелинейной глубокой нейронной сети или рекуррентной сети часто характеризуется резкими нелинейностями в пространстве параметров, возникающими из-за перемножения несколь- ких параметров. В местах таких нелинейностей значения производных очень велики. Когда параметры приближаются к подобному утесу, шаг об- новления в методе градиентного спуска может сдвинуть параметры очень далеко, при этом может потеряться все, чего удалось достичь в ходе пред- шествующей оптимизации. Рисунок взят из работы Pascanu et al. (2013) с разрешения авторов Например, предположим, что граф вычислений содержит путь, состоящий из пов- торных умножений на матрицу W. Выполнение t шагов эквивалентно умножению на Wt. Пусть спектральное разложение W имеет вид W = V diag(λ)V–1. В этом случае легко видеть, что Wt = (V diag(λ)V–1)t = V diag(λ)tV–1. (8.11) Все собственные значения λi, кроме близких к 1 по абсолютной величине, либо резко возрастают (если их абсолютная величина больше 1), либо почти обращаются в 0 (если абсолютная величина меньше 1). Когда говорят о проблеме исчезающего и взрывного градиента, имеют в виду, что в результате вычислений с таким графом градиенты также умножаются на коэффициент diag(λ) t. Если градиент обращается\n--- Страница 251 ---\n250  Оптимизация в обучении глубоких моделей в 0, то трудно понять, в каком направлении изменять параметры, чтобы улучшить функцию стоимости, а если резко возрастает, то обучение становится численно не- устойчивым. Описанные выше утесистые структуры, для борьбы с которыми приме- няется отсечение градиента, – пример феномена взрывного градиента. Повторное умножение на W на каждом временном шаге очень похоже на степен- ной метод нахождения наибольшего собственного значения матрицы W и соответ- ствующего ему собственного вектора. С этой точки зрения неудивительно, что опера- ция x⏉Wt в конечном итоге отбрасывает все компоненты x, ортогональные главному собственному вектору W. В рекуррентных сетях на каждом временном шаге используется одна и та же мат- рица W, но в сетях прямого распространения это не так, поэтому даже в очень глу- боких сетях прямого распространения, как правило, удается избежать проблемы ис-чезающего и взрывного градиента (Sussillo, 2014). Мы отложим дальнейшее обсуждение проблем обучения рекуррентных сетей до раздела 10.7, когда опишем такие сети более детально. 8.2.6. Неточные градиенты Большинство алгоритмов оптимизации исходит из предположения, что имеется дос-туп к точному градиенту или гессиану. На практике же обычно налицо только зашум- ленная или даже смещенная оценка этих величин. Почти все алгоритмы глубокого обучения опираются на выборочные оценки, по крайней мере в том, что касается ис- пользования мини-пакета обучающих примеров для вычисления градиента. Бывает и так, что целевая функция, которую мы хотим минимизировать, вычис- лительно неразрешима. В таком случае неразрешимой обычно является и задача вы- числения градиента, и тогда нам остается только аппроксимировать градиент. Такие проблемы чаще всего возникают в более сложных моделях, рассматриваемых в час- ти III. Например, алгоритм сопоставительного расхождения (contrastive divergence) предлагает метод аппроксимации градиента функции логарифмического правдопо-добия машины Больцмана. Для компенсации неточной оценки градиента разработаны различные алгоритмы оптимизации нейронных сетей. Проблему можно обойти также путем выбора сурро-гатной функции потерь, которую проще аппроксимировать, чем истинную. 8.2.7. Плохое соответствие между локальной и глобальной структурами Многие рассмотренные выше проблемы касаются свойств функции потерь в одной точке – трудно сделать следующий шаг, если J(θ) плохо обусловлена в текущей точке θ, или если θ находится на стене утеса, или если θ является седловой точкой, маски- рующей возможность добиться улучшения путем «спуска с горы». Все эти проблемы можно преодолеть в одной точке и тем не менее остаться «на бобах», если найденное направление наибольшего локального улучшения не ведет в сторону отдаленных областей с гораздо меньшей стоимостью. В работе Goodfellow et al. (2015) утверждается, что длительность обучения опреде- ляется в первую очередь длиной траектории, ведущей к решению. На рис. 8.2 видно, что траектория обучения резко удлиняется из-за необходимости обогнуть по широ-кой дуге скалообразную структуру.\n--- Страница 252 ---\nПроблемы оптимизации нейронных сетей  251 В центре многих исследований, посвященных трудностям оптимизации, находит- ся вопрос о том, достигает ли обучение глобального минимума, локального миниму- ма или седловой точки, но на практике нейронные сети не находят никакую крити- ческую точку. На рис. 8.1 показано, что нейронная сеть часто не достигает области малых градиентов. Да, собственно, таких критических точек может и не оказаться. Например, у функции потерь –log p(y | x; θ) может не быть точки глобального ми- нимума, вместо этого она асимптотически приближается к некоторому значению, по мере того как модель становится более уверенной. Для классификатора с дискрет- ными метками y и softmax-функцией p(y | x) отрицательное логарифмическое прав- доподобие может оказаться сколь угодно близким к нулю, если модель правильно классифицирует каждый обучающий пример, но никогда не принимает значения 0. Аналогично у вещественной модели p(y | x) = 𝒩(y; f(θ), β –1) отрицательное логариф- мическое правдоподобие может асимптотически приближаться к минус бесконеч- ности – если f(θ) правильно предсказывает значение y для всех обучающих приме- ров, то алгоритм обучения будет неограниченно увеличивать β. На рис. 8.4 приведен пример, когда локальная оптимизация терпит неудачу при поиске хорошей функции стои мости даже в отсутствие локальных минимумов или седловых точек. J(θ) θ Рис. 8.4  Оптимизация, основанная на локальном спуске, может потер- петь неудачу, если локальное направление не ведет к глобальному реше- нию. Здесь показано, как такое может произойти даже в отсутствие локаль- ных минимумов или седловых точек. Функция стоимости в этом примере только асимптотически приближается к низким значениям, но не имеет ми- нимумов. Проблема вызвана тем, что начальные значения выбраны не по ту сторону «горы», и алгоритм не может перебраться через нее. В многомер- ных пространствах алгоритмы обучения обычно способны обогнуть такие горы, но траектория может оказаться длинной, и обучение займет слишком много времени (см. рис. 8.2) Будущим исследователям необходимо глубже разобраться в природе факторов, влияющих на длину траектории обучения, и лучше охарактеризовать результат про- цесса. Многие из современных направлений исследований нацелены на поиск хороших начальных значений параметров в задачах с трудной глобальной структурой, а не на разработку алгоритмов с нелокальным перемещением.\n--- Страница 253 ---\n252  Оптимизация в обучении глубоких моделей Градиентный спуск и практически все алгоритмы, доказавшие эффективность при обучении нейронных сетей, основаны на небольших локальных шагах. В предыдущих разделах мы в основном говорили о трудностях вычисления правильного направления этих шагов. Не исключено, что некоторые свойства целевой функции, в т. ч. ее градиент, можно вычислить только приближенно, и оценка правильного направления будет либо смещенной, либо имеющей большую дисперсию. В таких случаях локальный спуск может дать или не дать разумно короткий путь к решению, но мы не можем последо- вать по этому пути. У целевой функции могут быть различные проблемы, например плохая обусловленность или разрывные градиенты, из-за которых область, в которой градиент дает хорошую модель целевой функции, очень мала. Тогда локальный спуск с шагами размера ε, возможно, и определяет разумно короткий путь к решению, но мы в состоянии вычислить направление локального спуска только с шагами размера δ ≪ ε. В этом случае может оказаться, что путь к решению, определяемый методом локально- го спуска, содержит слишком много шагов, и пройти по нему невозможно из-за высо- кой вычислительной стоимости. Иногда локальная информация не дает вообще ника-ких указаний, например когда у функции имеется широкий плоский участок или если нас угораздило попасть точно в критическую точку (такое обычно бывает, только если алгоритм находит критические точки в явном виде, как, например, метод Ньютона). В таких случаях локальный спуск вообще не определяет путь к решению. Бывает и так, что локальное перемещение оказывается слишком «жадным» и уводит нас по пути, ко- торый идет хоть и вниз, но в сторону от решения, как на рис. 8.4, или к решению, но по неоправданно длинной траектории, как на рис. 8.2. В настоящее время мы не понимаем, какие из этих проблем в наибольшей степени связаны с трудностями оптимизации ней- ронных сетей, и в этой области ведутся активные исследования. Но вне зависимости от того, какие проблемы наиболее значимы, всех их можно из- бежать, если существует область пространства, связанная с решением относительно прямым путем, который может найти метод локального спуска, и если мы сумеем инициализировать параметры, так чтобы они попали в эту «хорошую» область. И эта точка зрения побуждает к исследованиям в области поиска хороших начальных зна- чений для традиционных алгоритмов оптимизации. 8.2.8. Теоретические пределы оптимизации Есть несколько теоретических результатов, показывающих, что существуют пределы качества у любого мыслимого алгоритма оптимизации для нейронных сетей (Blum and Rivest, 1992; Judd, 1989; Wolpert and MacReady, 1997). Как правило, такие резуль-таты бесполезны для практического использования нейронных сетей. Ряд теоретических результатов относится только к случаю, когда блоки нейронной сети выводят дискретные значения. В большинстве нейронных сетей блоки выводят гладко возрастающие значения, благодаря чему и возможна оптимизация методом локального поиска. Другие результаты показывают, что существуют классы неразре-шимых задач, но трудно сказать, попадает ли в такой класс данная конкретная задача. Есть также результаты, доказывающие невозможность найти решение для сети задан-ного размера, но на практике легко можно найти решение, используя сеть большего размера, для которой гораздо больше конфигураций параметров соответствуют при-емлемому решению. Кроме того, в контексте обучения нейронных сетей нас обычно не интересует нахождение точного минимума функции, нужно лишь найти значение, достаточно малое для получения хорошей ошибки обобщения. Теоретически про-\n--- Страница 254 ---\nОсновные алгоритмы  253 анализировать, может ли алгоритм оптимизации достичь этой цели, исключительно трудно. Поэтому разработка более реалистичных границ качества алгоритмов опти-мизации остается важной целью исследований по машинному обучению. 8.3. Основные алгоритмы Мы уже познакомились с алгоритмом градиентного спуска (раздел 4.3), идея которо- го – перемещаться в направлении убывания градиента всего обучающего набора. Ра- боту можно значительно ускорить, воспользовавшись стохастическим градиентным спуском для случайно выбранных мини-пакетов, как описано в разделах 5.9 и 8.1.3. 8.3.1. Стохастический градиентный спуск Метод стохастического градиентного спуска (СГС) и его варианты – пожалуй, са- мые употребительные алгоритмы машинного обучения вообще и глубокого обучения в частности. Как было сказано в разделе 8.1.3, можно получить несмещенную оценку градиента, усреднив его по мини-пакету m независимых и одинаково распределенных примеров, выбранных из порождающего распределения. В алгоритме 8.1 показано, как осуществить спуск вниз, пользуясь этой оценкой. Алгоритм 8.1. Обновление на k-ой итерации стохастического градиентного спуска (СГС) Require: скорость обучения εk Require: Начальные значения параметров θ while критерий остановки не выполнен do Выбрать из обучающего набора мини-пакет m примеров {x(1), …, x(m)} и соот- ветствующие им метки y(i). Вычислить оценку градиента: g � ← +(1/m)∇θ ΣiL(f(x(i); θ), y(i)). Применить обновление: θ ← θ – εg �. end while Основной параметр алгоритма СГС – скорость обучения. Ранее при описании СГС мы считали скорость обучения ε фиксированной. На практике же необходимо посте- пенно уменьшать ее со временем, поэтому будем обозначать εk скорость обучения на k-ой итерации. Связано это с тем, что СГС-оценка градиента вносит источник шума (случайная выборка m обучающих примеров), который не исчезает, даже когда мы нашли ми- нимум. Напротив, при использовании пакетного градиентного спуска истинный гра- диент полной функции стоимости уменьшается по мере приближения к минимуму и обращается в 0 в самой точке минимума, так что скорость обучения можно зафик- сировать. Достаточные условия сходимости СГС имеют вид: (8.12) и (8.13)\n--- Страница 255 ---\n254  Оптимизация в обучении глубоких моделей На практике скорость обучения обычно уменьшают линейно до итерации с номе- ром τ: εk = (1 – α)ε0 + αετ, (8.15) где α = k/τ. После τ-й итерации ε остается постоянным. Скорость обучения можно выбрать методом проб и ошибок, но обычно лучше по- наблюдать за кривыми обучения – зависимостью целевой функции от времени. Здесь больше искусства, чем науки, поэтому большинство рекомендаций по этому вопросу следует воспринимать с долей скептицизма. Если скорость изменяется линейно, то нужно задать параметры ε0, ετ и τ. Обычно в качестве τ выбирают число итераций, необходимое для выполнения нескольких сотен проходов по обучающему набору. Величину ε τ задают равной примерно 1% от ε0. Главный вопрос: как задать ε0. Если значение слишком велико, то кривая обучения будет сильно осциллировать, а функ- ция стоимости – значительно увеличиваться. Слабые осцилляции не несут угрозы, особенно если для обучения используется стохастическая функция стоимости, как, например, в случае прореживания. Если скорость обучения слишком мала, то обуче- ние происходит медленно, а если слишком мала и начальная скорость, то обучение может застрять в точке с высокой стоимостью. Как правило, оптимальная началь- ная скорость обучения с точки зрения общего времени обучения и конечной стои- мости выше, чем скорость, которая дает наилучшее качество после первых примерно 100 итераций. Поэтому обычно имеет смысл последить за первыми несколькими ите- рациями и взять скорость обучения большую, чем наилучшая на этом отрезке, но не настолько высокую, чтобы дело закончилось сильной неустойчивостью. Самое важное свойство СГС и схожих методов мини-пакетной или онлайновой градиентной оптимизации заключается в том, что время вычислений в расчете на одно обновление не увеличивается с ростом числа обучающих примеров. Следова- тельно, сходимость возможна, даже когда число обучающих примеров очень велико. Если набор данных достаточно велик, то СГС может сойтись с некоторым фиксиро- ванным отклонением от финальной ошибки на тестовом наборе еще до завершения обработки всего обучающего набора. Для изучения скорости сходимости алгоритма оптимизации часто измеряют ошибку превышения J(θ) – min θ J(θ), т. е. величину, на которую текущая функция стоимости превышает минимально возможную стоимость. При применении СГС к выпуклой задаче ошибка превышения равна O(1/√_ k) после k итераций, тогда как в строго выпуклом случае она составляет O(1/k). Эти границы нельзя улучшить без дополнительных предположений. Теоретически у пакетного градиентного спуска скорость сходимости должна быть выше, чем у стохастического. Но из неравенства Крамера–Рао (Crame �r, 1946; Rao, 1945) следует, что ошибка обобщения не может убывать быстрее, чем O(1/k). В работе Bottou and Bousquet (2008) утверждается, что в таком случае в задачах машинного обучения не имеет смысла искать алгоритм опти- мизации, который сходится быстрее, чем O(1/k), – более быстрая сходимость, скорее всего, приведет к переобучению. Кроме того, асимптотический анализ игнорирует многие преимущества стохастического градиентного спуска с небольшим числом шагов. На больших наборах способность СГС быстро достигать прогресса на началь-ной стадии после обсчета небольшого числа примеров перевешивает его медленную асимптотическую сходимость. Большинство описываемых далее алгоритмов облада-ет практически важными достоинствами, которые скрыты за постоянным множите-\n--- Страница 256 ---\nОсновные алгоритмы  255 лем в асимптотической оценке O(1/k). Можно также попытаться найти компромисс между пакетным и стохастическим градиентным спусками, постепенно увеличивая размер мини-пакета в процессе обучения. Дополнительные сведения о СГС см. в работе Bottou (1998). 8.3.2. Импульсный метод Стохастический градиентный спуск остается популярной стратегией оптимизации, но обучение с его помощью иногда происходит слишком медленно. Импульсный ме- тод (Polyak, 1964) призван ускорить обучение, особенно в условиях высокой кри- визны, небольших, но устойчивых градиентов или зашумленных градиентов. В им- пульсном алгоритме вычисляется экспоненциально затухающее скользящее среднее прошлых градиентов и продолжается движение в этом направлении. Работа импульс- ного метода иллюстрируется на рис. 8.5. 20 10 0 –10–20–30 –30 –20 –10 010 20 Рис. 8.5  Импульсный метод призван решить две проблемы: плохую обусловленность матрицы Г ессе и дисперсию стохастического градиента. На рисунке показано, как преодолевается первая проблема. Эллипсы обо- значают изолинии квадратичной функции потерь с плохо обусловленной матрицей Г ессе. Красная линия, пересекающая эллипсы, соответствует траектории, выбираемой в соответствии с правилом обучения методом мо- ментов в процессе минимизации этой функции. Для каждого шага обуче- ния стрелка показывает, какое направление выбрал бы в этот момент метод градиентного спуска. Как видим, плохо обусловленная квадратичная целе-вая функция выглядит как длинная узкая долина или овраг с крутыми скло- нами. Импульсный метод правильно перемещается вдоль оврага, тогда как градиентный спуск впустую тратил бы время на перемещение вперед-на- зад поперек оврага. Сравните также с рис. 4.6, где показано поведение гра- диентного спуска без учета импульса Формально говоря, в импульсном алгоритме вводится переменная v, играющая роль скорости, – это направление и скорость перемещения в пространстве парамет- ров. Скорость устанавливается равной экспоненциально затухающему скользящему среднему градиента со знаком минус. Название алгоритма проистекает из физиче-ской аналогии, согласно которой отрицательный градиент – это сила, под действием которой частица перемещается в пространстве параметров согласно законам Нью- тона. В физике импульсом называется произведение массы на скорость. В импульс-\n--- Страница 257 ---\n256  Оптимизация в обучении глубоких моделей ном алгоритме масса предполагается единичной, поэтому вектор скорости v можно рассматривать как импульс частицы. Гиперпараметр α ∈ [0, 1) определяет скорость экспоненциального затухания вкладов предшествующих градиентов. Правило об- новления имеет вид: (8.15) θ ← θ + v. (8.16) Алгоритм 8.2. Стохастический градиентный спуск (СГС) с учетом импульса Require: скорость обучения ε, параметр импульса α Require: начальные значения параметров θ, начальная скорость v while критерий остановки не выполнен do Выбрать из обучающего набора мини-пакет m примеров {x(1), …, x(m)} и соот- ветствующие им метки y(i). Вычислить оценку градиента: g ← (1/m)∇θΣiL(f(x(i); θ), y(i)). Вычислить обновление скорости: v ← αv – εg. Применить обновление: θ ← θ + v. end while В скорости v суммируются градиенты ∇θ((1/m)Σm i=1L(f(x(i); θ), y(i))). Чем больше α относительно ε, тем сильнее предшествующие градиенты влияют на выбор текущего направления. СГС с учетом импульса описан в алгоритме 8.2. Раньше размер шага был равен просто норме градиента, умноженной на скорость обучения. Теперь же шаг зависит от величины и сонаправленности предшествующих градиентов. Размер шага максимален, когда много последовательных градиентов ука- зывают точно в одном и том же направлении. Если импульсный алгоритм всегда ви- дит градиент g, то он будет ускоряться в направлении –g, пока не достигнет конечной скорости, при которой размер шага равен (8.17) Таким образом, полезно рассматривать гиперпараметр импульса в терминах 1/(1 – α). Например, α = 0.9 соответствует умножению максимальной скорости на 10 относительно стандартного алгоритма градиентного спуска. На практике обычно задают α равным 0.5, 0.9 или 0.99. Как и скорость обучения, α может меняться со временем. Как правило, начинают с небольшого значения и по- степенно увеличивают его. Изменение α со временем не так важно, как уменьшение ε со временем. Импульсный алгоритм можно рассматривать как имитацию движения частицы, под- чиняющейся динамике Ньютона. Физическая аналогия помогает составить интуитив-ное представление о поведении алгоритма градиентного спуска и импульсного метода. Положение частицы в любой момент времени описывается функцией θ(t). К час- тице приложена суммарная сила f(t), под действием которой частица ускоряется: (8.18)\n--- Страница 258 ---\nОсновные алгоритмы  257 Вместо того чтобы рассматривать это как дифференциальное уравнение второ- го порядка, описывающее положение частицы, мы можем ввести переменную v(t), представляющую скорость частицы в момент t, и выразить ньютоновскую динамику в виде уравнения первого порядка: (8.19) (8.20) Тогда для применения импульсного алгоритма нужно численно решить эту си- стему дифференциальных уравнений. Простой способ решения дает метод Эйлера, который заключается в моделировании динамики, описываемой уравнением, путем небольших конечных шагов в направлении каждого градиента. Итак, мы описали базовую форму обновления параметров импульсным мето- дом, но что конкретно представляют собой силы? Одна сила пропорциональна отрицательному градиенту функции стоимости: –∇ θJ(θ). Эта сила толкает час- тицу вниз по поверхности функции стоимости. Алгоритм градиентного спуска прос то сделал бы один шаг, основанный на градиенте, но в импульсном алгоритме эта сила изменяет скорость частицы. Можно считать частицу хоккейной шайбой, скользящей по ледяной поверхности. Во время спуска по крутому склону она на-бирает скорость и продолжает скользить в одном направлении, пока не начнется очередной подъем. Но необходима еще одна сила. Если бы единственной силой был градиент функ- ции стоимости, то частица могла бы никогда не остановиться. Представьте себе шай-бу, скользящую вниз по одному склону оврага, затем вверх по противоположному склону – если предположить, что трения нет, то она так и будет опускаться и подни- маться бесконечно. Для решения этой проблемы мы добавим еще одну силу, пропор-циональную –v(t). В физике мы назвали бы ее вязким сопротивлением, как если бы частица должна была прокладывать себе путь в сопротивляющейся среде, например в сиропе. В результате частица постепенно теряет энергию и в конце концов остано- вится в локальном минимуме. Зачем использовать –v(t) и конкретно вязкое сопротивление? Отчасти из-за ма- тематического удобства – с целой степенью скорости проще работать. Но в других физических системах встречаются и иные виды сопротивления, основанные на це- лых степенях скорости. Например, частица, движущаяся в воздухе, испытывает тур- булентное сопротивление, пропорциональное квадрату скорости, а частица, движу- щаяся по земле, – сопротивление трения силу постоянной величины. Но оба этих варианта следует отвергнуть. Турбулентное сопротивление, пропорциональное ква-драту скорости, оказывается очень малым при малых скоростях. Его не хватит, чтобы заставить частицу остановиться. Частица с ненулевой начальной скоростью, на ко- торую действует только сила турбулентного сопротивления, будет вечно удаляться от начальной точки, причем расстояние до нее растет как O(log t). Поэтому нужно брать меньшую степень скорости. Если взять степень 0, соответствующую сухому трению, то сила окажется слишком большой. Когда сила, обусловленная градиентом функции стоимости, мала, но все же отлична от нуля, постоянная сила трения может остановить частицу еще до достижения локального минимума. Сила вязкого сопро-тивления позволяет избежать обеих проблем – она достаточно слаба, чтобы градиент\n--- Страница 259 ---\n258  Оптимизация в обучении глубоких моделей продолжал вызывать движение до достижения минимума, и достаточна сильна, что- бы предотвратить движение, не оправдываемое градиентом. 8.3.3. Метод Нестерова В работе Sutskever et al. (2013) описан вариант импульсного алгоритма, созданный под влиянием метода ускоренного градиента Нестерова (Nesterov, 1983, 2004). Пра-вила обновления в этом случае имеют вид: (8.21) θ ← θ + v, (8.22) Алгоритм 8.3. Стохастический градиентный спуск (СГС) методом Нестерова Require: скорость обучения ε, параметр импульса α Require: начальные значения параметров θ, начальная скорость v while критерий остановки не выполнен do Выбрать из обучающего набора мини-пакет m примеров {x(1), …, x(m)} и соот- ветствующие им метки y(i). Выполнить промежуточное обновление: θ~ ← θ + αv Вычислить градиент (в промежуточной точке): g ← (1/m)∇θ~Σi L(f(x(i); θ~), y(i)). Вычислить обновление скорости: v ← αv – εgПрименить обновление: θ ← θ + v. end while где параметры α и ε играют ту же роль, что в стандартном импульсном методе. Раз- ница между методом Нестерова и стандартным импульсным методом заключается в точке, где вычисляется градиент. В методе Нестерова градиент вычисляется после применения текущей скорости. Таким образом, метод Нестерова можно интерпрети-ровать как попытку добавить поправочный множитель к стандартному импульсному методу. Полностью метод Нестерова представлен в алгоритме 8.3. В случае выпуклой оптимизации пакетным градиентным спуском метод Нестеро- ва повышает скорость сходимости ошибки превышения с O(1/k) (после k шагов) до O(1/k 2), как доказано в работе Nesterov (1983). К сожалению, в случае стохастическо- го градиентного спуска метод Нестерова не улучшает скорости сходимости. 8.4. Стратегии инициализации параметров Некоторые алгоритмы оптимизации по природе своей не итеративные, они просто решают уравнение. Другие алгоритмы хоть и итеративные, но в применении к под- ходящему классу задач оптимизации сходятся к приемлемому решению за приемле- мое время вне зависимости от начальных значений. Алгоритмы глубокого обучения обычно не обладают столь приятными свойствами. Как правило, они итеративные, и потому пользователь должен указать, с какой точки начинать итерации. Кроме того, обучение глубоких моделей – задача настолько сложная, что большинство ал- горитмов сильно зависит от выбора начальных значений. От начальной точки мо-жет зависеть, сойдется ли вообще алгоритм, причем некоторые начальные точки так\n--- Страница 260 ---\nСтратегии инициализации параметров  259 неустойчивы, что алгоритм сталкивается с численными трудностями и завершается ошибкой. Если все-таки алгоритм сходится, то начальная точка определяет скорость сходимости и стоимость в конечной точке – высокую или низкую. Кроме того, для то- чек с сопоставимой стоимостью ошибка обобщения может различаться очень сильно, и на нее начальная точка тоже может оказывать влияние. Современные стратегии инициализации просты и основаны на эвристических со- ображениях. Проектирование улучшенной стратегии инициализации – трудная зада- ча, потому что еще нет отчетливого понимания оптимизации нейронных сетей. Боль-шинство стратегий основано на стремлении получить некоторые полезные свойства сети в начальный момент. Однако мы плохо понимаем, какие из этих свойств и при каких условиях сохраняются после начала процесса обучения. Дополнительная труд-ность состоит в том, что некоторые начальные точки хороши с точки зрения оптими- зации, но никуда не годятся с точки зрения обобщаемости. Наше понимание того, как начальная точка влияет на обобщаемость, совсем уж примитивно, оно не дает почти или вообще никаких указаний на то, как выбирать начальную точку. Пожалуй, единственное, что мы знаем наверняка, – это то, что начальные парамет- ры должны «нарушить симметрию» между разными блоками. Если два скрытых бло-ка с одинаковыми функциями активации соединены с одними и теми же входами, то у этих блоков должны быть разные начальные параметры. Если начальные параметры одинаковы, то детерминированный алгоритм обучения, применяемый к детерминиро- ванной функции стоимости и модели, будет всякий раз обновлять эти блоки одинаково. Даже если модель или алгоритм обучения способны стохастически вычислять разные обновления разных блоков (например, если при обучении используется прорежива-ние), обычно предпочтительнее инициализировать каждый блок, так чтобы он вычис-лял свою функцию иначе, чем все остальные блоки. Это позволит гарантировать, что никакие входные паттерны не потеряются в нуль-пространстве прямого распростра- нения, и никакие паттерны градиентов не потеряются в нуль-пространстве обратного распространения. Стремление к тому, чтобы все блоки вычисляли разные функции, диктует выбор в пользу случайной инициализации параметров. Мы могли бы провес- ти явный поиск в большом множестве взаимно различных базисных функций, но это зачастую дорого обходится с точки зрения вычислений. Например, если число выходов не превышает число входов, то можно было бы воспользоваться ортогонализацией Гра-ма–Шмидта матрицы начальных весов и тем самым гарантировать, что все блоки будут вычислять очень сильно различающиеся функции. Случайная инициализация на осно-ве распределения с высокой энтропией в многомерном пространстве вычислительно дешевле, а вероятность назначить двум блокам одинаковую функцию крайне мала. В типичном случае мы выбираем в качестве смещений блоков эвристически выбран ные константы, а случайно инициализируем только веса. Дополнительные параметры, например условная дисперсия предсказания, обычно тоже задаются эв-ристическими константами. Почти всегда веса модели инициализируются случайными значениями с нормаль- ным или равномерным распределением. Вопрос о том, какое распределение лучше, похоже, не играет особой роли, но тщательно он не изучался. А вот масштаб началь- ного распределения сильно влияет как на результат процедуры оптимизации, так и на способность сети к обобщению. Чем больше начальные веса, тем сильнее эффект нарушения симметрии, что по- могает избежать избыточных блоков. Большие начальные веса помогают также пре-\n--- Страница 261 ---\n260  Оптимизация в обучении глубоких моделей дотвратить потерю сигнала во время прямого или обратного распространения через линейные компоненты каждого слоя – чем больше значения в матрице, тем больше результат умножения матриц. Однако если начальные веса слишком велики, то мо-жет случиться взрывной рост значений во время прямого или обратного распрост-ранения. В рекуррентных сетях большие веса также могут привести к хаосу (на- столько высокой чувствительности к малым возмущениям входного сигнала, что поведение детерминированной процедуры прямого распространения представляется случайным). Проблему взрывного градиента можно в какой-то мере сгладить путем отсечения градиента (сравнения градиента с порогом перед выполнением шага гра- диентного спуска). Кроме того, большие веса могут стать причиной экстремальных значений, что ведет к насыщению функции активации и полной потере градиента при распространении через насыщенные блоки. Балансирование этих разнонаправлен-ных факторов и определяет идеальный масштаб весов. Взгляды на проблему с точки зрения регуляризации и оптимизации могут дать со- вершенно разные подходы к инициализации сети. С точки зрения оптимизации, веса должны быть достаточно большими, чтобы способствовать успешному распростране-нию информации. Но соображения регуляризации побуждают делать веса поменьше. Использование таких алгоритмов оптимизации, как стохастический градиентный спуск, который производит инкрементные изменения весов и выказывает тенденцию к остановке в областях, близких к начальным параметрам (то ли из-за застревания в области низких градиентов, то ли потому, что сработал критерий ранней остановки вследствие угрозы переобучения), выражает априорное знание о том, что конечные параметры должны быть близки к начальным. Напомним (см. раздел 7.8), что для не- которых моделей градиентный спуск с ранней остановкой эквивалентен снижению весов. В общем случае градиентный спуск с ранней остановкой – не то же самое, что снижение весов, но между ними можно провести некоторую аналогию, позволяющую рассуждать об эффекте инициализации. Мы можем считать инициализацию парамет-ров θ значениями θ 0 аналогом гипотезы о нормальном априорном распределении p(θ) со средним θ0. С этой точки зрения, имеет смысл выбирать θ0 близким к 0. При таком априорном распределении отсутствие взаимодействия между блоками вероятнее его наличия. Блоки взаимодействуют, только если член правдоподобия в целевой функ- ции выражает сильное предпочтение к такому взаимодействию. С другой стороны, если инициализировать θ 0 большими значениями, то априорная гипотеза говорит о том, какие блоки должны взаимодействовать между собой и как именно. Существуют некоторые эвристики для выбора начального масштаба весов. Одна из них – инициализировать веса в полносвязном слое с m входами и n выходами, вы- бирая каждый вес из распределения U(–1/√_ m, 1/√_ m). А в работе Glorot and Bengio (2010) предлагается использовать нормированную инициализацию (8.23) Эта последняя эвристика выражает компромисс между желанием инициализиро- вать все слои, так чтобы была одинакова дисперсия активации, и желанием инициа- лизировать их, так чтобы была одинаковая дисперсия градиента. Формула выведена в предположении, что сеть включает только цепочку умножений матриц безо всяких нелинейностей. Очевидно, что реальные нейронные сети не удовлетворяют этому\n--- Страница 262 ---\nСтратегии инициализации параметров  261 предположению, но многие стратегии, разработанные для линейных моделей, дают неплохие результаты и в нелинейных сетях. В работе Saxe et al. (2013) рекомендуется в качестве начальных значений брать случайные ортогональные матрицы с тщательно подобранным масштабным коэффи- циентом усиления g, который учитывает нелинейности в каждом слое. Авторы при- водят конкретные значения масштабного коэффициента для нелинейных функций активации разных типов. Обоснованием такой схемы инициализации также служит модель глубокой сети как последовательности умножений матриц без нелинейно-стей. При такой модели схема гарантирует, что общее число итераций обучения, не-обходимое для достижения сходимости, не зависит от глубины. Увеличение масштабного коэффициента g переводит сеть в режим, когда норма ак- тивации возрастает при прямом распространении, а норма градиента – при обратном. В работе Sussillo (2014) показано, что правильного выбора коэффициента усиления достаточно для обучения глубоких сетей с 1000 уровней без применения ортогональ- ной инициализации. Главная идея этого подхода состоит в том, что в сетях прямо- го распространения активация и градиент могут возрастать или убывать на каждом шаге прямого или обратного распространения, как при случайном блуждании. Объ-ясняется это тем, что в сетях прямого распространения в каждом слое используется своя матрица весов. Если настроить это случайное блуждание, так чтобы норма со-хранялась, то сеть прямого распространения сможет в большинстве случаев избежать проблемы исчезающих и взрывных градиентов, которая возникает, когда на каждом шаге используется одна и та же матрица (см. раздел 8.2.5). К сожалению, оптимальные критерии для начальных весов зачастую не приводят к оптимальному качеству. Тому может быть три причины. Во-первых, неподходящий критерий – возможно, он не способствует сохранению нормы сигнала во всей сети. Во-вторых, свойства, справедливые в момент инициализации, могут нарушаться после начала обучения. В-третьих, критерий может ускорять оптимизацию, но не-преднамеренно увеличивать ошибку обобщения. На практике масштаб весов обычно следует рассматривать как гиперпараметр, оптимальное значение которого близко к теоретически предсказанному, но не совпадает с ним. Недостаток правил масштабирования, при которых все начальные веса имеют оди- наковое стандартное отклонение, например 1/√ _ m, состоит в том, что каждый отдель- ный вес становится очень малым, когда число слоев растет. В работе Martens (2010) предложена альтернативная схема, названная разреженной инициализацией, при которой каждому блоку в начальный момент назначается ровно k ненулевых весов. Идея в том, чтобы сделать общий объем входящей в блок информации независимым от числа входов m, не заставляя абсолютную величину отдельных весовых элементов уменьшаться вместе с m. Разреженная инициализация помогает обеспечить боль- шее разнообразие блоков на стадии инициализации. Однако она также предполагает очень сильные априорные предположения о весах, которые должны иметь большие нормально распределенные значения. Поскольку градиентному спуску понадобит-ся много времени, чтобы сократить «неправильные» большие значения, эта схема инициализации может вызывать проблемы для таких блоков (в частности, maxout-блоков), у которых есть несколько фильтров, которые должны быть тщательно ско- ординированы друг с другом. Если вычислительные ресурсы позволяют, обычно имеет смысл рассматривать начальный масштаб весов в каждом слое как гиперпараметр и выбирать масштабы,\n--- Страница 263 ---\n262  Оптимизация в обучении глубоких моделей применяя какой-нибудь из алгоритмов поиска гиперпараметров, описанных в раз- деле 11.4.2, например случайный поиск. Или можно вручную поискать наилучшие возможные веса. Хорошее эвристическое правило выбора начальных масштабов – проанализировать диапазон стандартного отклонения активаций или градиентов на одном мини-пакете данных. Если веса слишком малы, то диапазон активаций будет сужаться по мере прямого распространения по сети. Раз за разом определяя первый слой с неприемлемой малой активацией и увеличивая веса в нем, можно в конце кон- цов получить сеть с разумными начальными активациями снизу доверху. Если в этом момент обучение все еще происходит слишком медленно, то полезно также проана-лизировать диапазон стандартных отклонений градиентов и активаций. В принципе, эту процедуру можно автоматизировать, и в общем случае она вычислительно дешев- ле, чем оптимизация гиперпараметра, основанная на ошибке на контрольном наборе, поскольку в основе лежит обратная связь с поведением начальной модели на одном пакете данных, а не с обученной моделью на контрольном наборе. Этот эвристиче- ский протокол используется уже долгое время, но лишь недавно он был формализо-ван и изучен в работе Mishkin and Matas (2015). До сих пор мы говорили об инициализации весов. К счастью, инициализация дру- гих параметров обычно проще. Подходы к заданию смещений и весов должны быть согласованы. Инициализация всех смещений нулями совместима с большинством схем инициализации весов. Есть несколько ситуаций, в которых разумно присваивать некоторым смещениям ненуле- вые значения. Если речь идет о смещении для выходного блока, то часто имеет смысл ини- циализировать его так, чтобы получилась правильная маргинальная статисти-ка выхода. Для этого предположим, что начальные веса настолько малы, что выход блока определяется только смещением. Это оправдывает выбор в каче- стве смещения величины, обратной значению функции активации, применен-ной к маргинальной статистике выхода в обучающем наборе. Например, если выходом является распределение классов, и это распределение сильно скоше- но, а маргинальная вероятность i-го класса задается элементом c i некоторого вектора c, то вектор смещений b можно найти из уравнения softmax(b) = c. Это относится не только к классификаторам, но и к моделям, с которыми мы встре- тимся в части III, например автокодировщикам и машинам Больцмана. В этих моделях имеются слои, выход которых должен быть похож на вход x, и было бы очень полезно инициализировать смещения таких слоев в соответствии с мар- гинальным распределением x. Иногда мы хотим выбрать смещение так, чтобы предотвратить слишком силь-ное насыщение на стадии инициализации. Например, мы можем задать смеще-ние скрытого ReLU-блока равным 0.1, а не 0, чтобы избежать его насыщения. Но этот подход несовместим со схемами инициализации весов, которые не ожидают сильного входного сигнала от смещений. Например, его не рекомен-дуется использовать вместе с инициализацией случайным блужданием (Sus- sillo, 2014). Иногда один блок управляет тем, могут ли другие блоки принимать участие в вычислении функции. В таких ситуациях имеются блок с выходом u и другой блок h ∈ [0, 1], они перемножаются, и на выходе получается uh. Мы можем рас- сматривать h как вентиль, определяющий, будет ли uh ≈ u или uh ≈ 0. Тогда мы\n--- Страница 264 ---\nАлгоритмы с адаптивной скоростью обучения  263 хотим на этапе инициализации задать смещение для h, так чтобы h ≈ 1 большую часть времени. В противном случае у u не будет возможности обучиться. На- пример, в работе Jozefowicz et al. (2015) рекомендуется устанавливать смеще- ние 1 для вентиля забывания в модели LSTM, описанной в разделе 10.10. Еще один распространенный параметр – дисперсия, или точность. Например, мы можем выполнить линейную регрессию с оценкой условной дисперсии с помощью модели p(y | x) = 𝒩(y | wTx + b, 1/β), (8.24) где β – параметр точности. Обычно безопасно инициализировать дисперсию, или точность, значением 1. Другой подход – предположить, что начальные веса настолько близки к нулю, что смещения можно задавать, игнорируя влияние ве- сов, и тогда задать смещения так, чтобы порождалось правильное маргинальное среднее выхода, а дисперсии сделать равными маргинальной дисперсии выхода в обучаю щем наборе. Помимо простых методов инициализации параметров модели постоянными или случайными значениями, можно для этой цели применить машинное обуче- ние. Типичная стратегия, обсуждаемая в части III, – инициализировать модель с учителем параметрами, обученными с помощью модели без учителя на тех же входных данных. Можно также выполнить обучение с учителем на родственной задаче. Даже обучение с учителем на никак не связанной задаче может иногда дать начальные значения, обеспечивающие более быструю, по сравнению со случайной инициализацией, сходимость. Некоторые стратегии инициализации такого рода могут приводить к ускоренной сходимости и лучшей обобщаемости, потому что в них закодирована информация о распределении начальных параметров модели. Другие дают хорошие результаты, по всей видимости, из-за того, что выбирают правильный масштаб параметров или настраивают блоки на вычисление различ-ных функций. 8.5. Алгоритмы с адаптивной скоростью обучения Специалисты по нейронным сетям давно поняли, что скорость обучения – один из самых трудных для установки гиперпараметров, поскольку она существенно влия ет на качество модели. В разделах 4.3 и 8.2 мы говорили о том, что стоимость зачастую очень чувствительна в некоторых направлениях пространства параметров и нечув- ствительна в других. Импульсный алгоритм может в какой-то мере сгладить эти проб- лемы, но ценой введения другого гиперпараметра. Естественно возникает вопрос, нет ли какого-то иного способа. Если мы полагаем, что направления чувствительности почти параллельны осям, то, возможно, имеет смысл задавать скорость обучения от-дельно для каждого параметра и автоматически адаптировать эти скорости на про- тяжении всего обучения. Алгоритм delta-bar-delta (Jacobs, 1988) – один из первых эвристических подходов к адаптации индивидуальных скоростей обучения параметров модели. Он основан на простой идее: если частная производная функции потерь по данному параметру модели не меняет знак, то скорость обучения следует увеличить. Если же знак ме-няется, то скорость следует уменьшить. Конечно, такого рода правило применимо только к оптимизации на полном пакете.\n--- Страница 265 ---\n264  Оптимизация в обучении глубоких моделей Позже был предложен целый ряд инкрементных (или основанных на мини-паке- тах) методов для адаптации скоростей обучения параметров. В этом разделе мы крат- ко рассмотрим некоторые из них. 8.5.1. AdaGrad Алгоритм AdaGrad (алгоритм 8.4) по отдельности адаптирует скорости обучения всех параметров модели, умножая их на коэффициент, обратно пропорциональный квадратному корню из суммы всех прошлых значений квадрата градиента (Duchi et al., 2011). Для параметров, по которым частная производная функции потерь наи-большая, скорость обучения уменьшается быстро, а если частная производная мала, то и скорость обучения уменьшается медленнее. В итоге больший прогресс получа- ется в направлениях пространства параметров со сравнительно пологими склонами. В случае выпуклой оптимизации у алгоритма AdaGrad есть некоторые желатель- ные теоретические свойства. Но эмпирически при обучении глубоких нейронных сетей накапливание квадратов градиента с самого начала обучения может привести к преждевременному и чрезмерному уменьшению эффективной скорости обучения. AdaGrad хорошо работает для некоторых, но не для всех моделей глубокого обучения. 8.5.2. RMSProp Алгоритм RMSProp (Hinton, 2012) – это модификация AdaGrad, призванная улуч- шить его поведение в невыпуклом случае путем изменения способа агрегирования градиента на экспоненциально взвешенное скользящее среднее. AdaGrad разрабаты-вался для быстрой сходимости в применении к выпуклой функции. Если же он приме- няется к невыпуклой функции для обучения нейронной сети, то траектория обучения может проходить через много разных структур и в конечном итоге прийти в локально выпуклую впадину. AdaGrad уменьшает скорость обучения, принимая во внимание всю историю квадрата градиента, и может случиться так, что скорость станет слиш- ком малой еще до достижения такой выпуклой структуры. В алгоритме RMSProp ис- пользуется экспоненциально затухающее среднее, т. е. далекое прошлое отбрасывает- ся, чтобы повысить скорость сходимости после обнаружения выпуклой впадины, как если бы внутри этой впадины алгоритм AdaGrad был инициализирован заново. Алгоритм 8.4. Алгоритм AdaGrad Require: глобальная скорость обучения εRequire: начальные значения параметров θRequire: небольшая константа δ, например 10 –7, для обеспечения численной устойчивости Инициализировать переменную для агрегирования градиента r = 0 while критерий остановки не выполнен do Выбрать из обучающего набора мини-пакет m примеров {x(1), …, x(m)} и соот- ветствующие им метки y(i). Вычислить градиент: g ← (1/m)∇θΣiL(f(x(i); θ), y(i)). Агрегировать квадраты градиента: r ← r + g ⊙ g. Вычислить обновление: Δθ ← – ⊙ g (операции деления и извлечения корня применяются к каждому элементу). Применить обновление: θ ← θ + Δθ. end while\n--- Страница 266 ---\nАлгоритмы с адаптивной скоростью обучения  265 Алгоритм 8.5 содержит описание RMSProp в стандартной форме, а алгоритм 8.6 – в сочетании с методом Нестерова. По сравнению с AdaGrad вводится новый гипер- параметр ρ, управляющий масштабом длины при вычислении скользящего среднего. Алгоритм 8.5. Алгоритм RMSProp Require: глобальная скорость обучения ε, скорость затухания ρ Require: начальные значения параметров θRequire: небольшая константа δ, например 10 –6, для стабилизации деления на малые числа Инициализировать переменную для агрегирования градиента r = 0 while критерий остановки не выполнен do Выбрать из обучающего набора мини-пакет m примеров {x(1), …, x(m)} и соот- ветствующие им метки y(i). Вычислить градиент: g ← (1/m)∇θΣi L(f(x(i); θ), y(i)). Агрегировать квадраты градиента: r ← ρr + (1 – ρ) g ⊙ g. Вычислить обновление параметров: Δθ ← – ⊙ g (операция применяется к каждому элементу). Применить обновление: θ ← θ + Δθ. end while Алгоритм 8.6. Алгоритм RMSProp в сочетании с методом Нестерова Require: глобальная скорость обучения ε, скорость затухания ρ, коэффициент импульса α Require: начальные значения параметров θ, начальная скорость v Инициализировать переменную для агрегирования градиента r = 0 while критерий остановки не выполнен do Выбрать из обучающего набора мини-пакет m примеров {x(1), …, x(m)} и соот- ветствующие им метки y(i). Вычислить промежуточное обновление: θ~ ← θ + αv Вычислить градиент: g ← (1/m)∇θ~ΣiL(f(x(i); θ~), y(i)). Агрегировать градиент: r ← ρr + (1 – ρ) g ⊙ g.Вычислить обновление скорости: v ← αv – ( ε/√_ r) ⊙ g (операция 1/√_ r при- меняется к каждому элементу).Применить обновление: θ ← θ + v. end while Эмпирически показано, что RMSProp – эффективный и практичный алгоритм оптимизации глубоких нейронных сетей. В настоящее время он считается одним из лучших методов оптимизации и постоянно используется в практической работе. 8.5.3. Adam Adam (Kingma and Ba, 2014) – еще один алгоритм оптимизации с адаптивной ско- ростью обучения – описан в алгоритме 8.7. Название «Adam» – сокращение от «adap- tive moments» (адаптивные моменты). Его, наверное, правильнее всего рассматривать как комбинацию RMSProp и импульсного метода с несколькими важными отличия- ми. Во-первых, в Adam импульс включен непосредственно в виде оценки первого момента (с экспоненциальными весами) градиента. Самый прямой способ добавить\n--- Страница 267 ---\n266  Оптимизация в обучении глубоких моделей импульс в RMSProp – применить его к масштабированным градиентам. У использо- вания импульса в сочетании с масштабированием нет ясного теоретического обос- нования. Во-вторых, Adam включает поправку на смещение в оценки как первых моментов (член импульса), так и вторых (нецентрированных) моментов для учета их инициализации в начале координат (см. алгоритм 8.7). RMSProp также включает оценку (нецентрированного) второго момента, однако в нем нет поправочного коэф- фициента. Таким образом, в отличие от Adam, в RMSProp оценка второго момента может иметь высокое смещение на ранних стадиях обучения. Вообще говоря, Adam считается довольно устойчивым к выбору гиперпараметров, хотя скорость обучения иногда нужно брать отличной от предлагаемой по умолчанию. Алгоритм 8.7. Алгоритм Adam Require: величина шага ε (по умолчанию 0.001). Require: коэффициенты экспоненциального затухания для оценок моментов ρ 1 и ρ2, принадлежащие диапазону [0, 1) (по умолчанию 0.9 и 0.999 соответст- венно).Require: небольшая константа δ для обеспечения численной устойчивости (по умолчанию 10 –8). Require: начальные значения параметров θ. Инициализировать переменные для первого и второго моментов s = 0, r = 0 Инициализировать шаг по времени t = 0while критерий остановки не выполнен do Выбрать из обучающего набора мини-пакет m примеров {x (1), …, x(m)} и соот- ветствующие им метки y(i). Вычислить градиент: g ← (1/m)∇θΣi L(f(x(i); θ), y(i)). t ← t + 1Обновить смещенную оценку первого момента: s ← ρ 1s + (1 – ρ1)g Обновить смещенную оценку второго момента: r ← ρ2r + (1 – ρ2)g ⊙ g Скорректировать смещение первого момента: Скорректировать смещение второго момента: Вычислить обновление: (операции применяются к каждому элементу) Применить обновление: θ ← θ + Δθ. end while 8.5.4. Выбор правильного алгоритма оптимизации Мы обсудили ряд родственных алгоритмов, каждый из которых пытается решить проблему оптимизации глубоких моделей, адаптируя скорость обучения каждого па-раметра. Возникает естественный вопрос: какой алгоритм выбрать? К сожалению, в настоящее время единого мнения нет. В работе Schaul et al. (2014) представлено ценное сравнение большого числа алгоритмов оптимизации в примене- нии к различным задачам обучения. И хотя результаты показывают, что семейство ал- горитмов с адаптивной скоростью обучения (представленное алгоритмами RMSProp и AdaDelta) ведет себя достаточно устойчиво, явный победитель не выявлен.\n--- Страница 268 ---\nПриближенные методы второго порядка  267 Сейчас наиболее популярны и активно применяются алгоритмы СГС, СГС с уче- том импульса, RMSProp, RMSProp с учетом импульса, AdaDelta и Adam. Какой из них использовать, зависит главным образом от знакомства пользователя с алгорит- мом (читай: умения настраивать гиперпараметры). 8.6. Приближенные методы второго порядка В этом разделе мы обсудим применение методов второго порядка к обучению глу- боких сетей. Одно из первых изложений этой темы см. в работе LeCun et al. (1998a). Для простоты мы будем рассматривать только одну целевую функцию: эмпириче- ский риск: (8.25) Впрочем, рассматриваемые здесь методы легко обобщаются на другие целевые функции, в т. ч. включающие члены регуляризации, обсуждавшиеся в главе 7. 8.6.1. Метод Ньютона В разделе 4.3 мы познакомились с градиентными методами второго порядка. В от- личие от методов первого порядка, в этом случае для улучшения оптимизации за- действуются вторые производные. Самый известный метод второго порядка – метод Ньютона. Опишем его более подробно с акцентом на применении к обучению ней- ронных сетей. Метод Ньютона основан на использовании разложения в ряд Тейлора с точностью до членов второго порядка для аппроксимации J(θ) в окрестности некоторой точки θ 0, производные более высокого порядка при этом игнорируются. J(θ) ≈ J(θ0) + (θ – θ0)⏉∇θJ(θ0) + 1/2(θ – θ0)⏉H(θ – θ0), (8.26) где H – гессиан J относительно θ, вычисленный в точке θ0. Пытаясь найти критиче- скую точку этой функции, мы приходим к правилу Ньютона для обновления пара- метров: θ* = θ0 – H–1∇θJ(θ0). (8.27) Таким образом, для локально квадратичной функции (с положительно определен- ной матрицей H) умножение градиента на H–1 сразу дает точку минимума. Если це- левая функция выпуклая, но не квадратичная (имеются члены более высокого поряд-ка), то это обновление можно повторить, получив тем самым алгоритм обучения 8.8, основанный на методе Ньютона. Для неквадратичных поверхностей метод Ньютона можно применять итеративно, при условии что матрица Гессе остается положительно определенной. Отсюда выте-кает двухшаговая итеративная процедура. Сначала мы обновляем или вычисляем об-ратный гессиан (путем обновления квадратичной аппроксимации). Затем обновляем параметры в соответствии с формулой (8.27). Алгоритм 8.8. Метод Ньютона с целевой функций J(θ) = (1/m)Σ m i=1L(f(x(i); θ), y(i)) Require: начальные значения параметров θ0. Require: обучающий набор m примеров\n--- Страница 269 ---\n268  Оптимизация в обучении глубоких моделей while критерий остановки не выполнен do Вычислить градиент: g ← (1/m)∇θΣi L(f(x(i); θ), y(i)) Вычислить гессиан: H ← (1/m)∇θ2Σi L(f(x(i); θ), y(i)) Вычислить обратный гессиан: H–1 Вычислить обновление: Δθ = –H–1g Применить обновление: θ ← θ + Δθ. end while В разделе 8.2.3 мы говорили, что метод Ньютона применим, только если матрица Гессе положительно определенная. В глубоком обучении поверхность целевой функ- ции обычно невыпуклая и имеет много особенностей типа седловых точек, с которы- ми метод Ньютона не справляется. Если не все собственные значения гессиана по- ложительны, например вблизи седловой точки, то метод Ньютона может произвести обновление не в том направлении. Такую ситуацию можно предотвратить с помощью регуляризации гессиана. Одна из распространенных стратегий регуляризации – при- бавление константы α ко всем диагональным элементам гессиана. Тогда регуляризи- рованное обновление принимает вид: θ * = θ0 – [H(f(θ0)) + αI]–1∇θ f(θ0). (8.27) Эта стратегия регуляризации применяется в аппроксимациях метода Ньютона, например в алгоритме Левенберга–Марквардта (Levenberg, 1944; Marquardt, 1963), и работает неплохо, если отрицательные собственные значения гессиана сравнитель- но близки к нулю. Если же в некоторых направлениях кривизна сильнее, то значе- ние α следует выбирать достаточно большим для компенсации отрицательных соб- ственных значений. Однако по мере увеличения α в гессиане начинает доминировать диагональ αI, и направление, выбранное методом Ньютона, стремится к стандарт- ному градиенту, поделенному на α. При наличии сильной кривизны α должно быть настолько большим, чтобы метод Ньютона делал меньшие шаги, чем градиентный спуск с подходящей скоростью обучения. Помимо проблем, связанных с такими особенностями целевой функции, как сед- ловые точки, применение метода Ньютона к обучению больших нейронных сетей ли- митируется требованиями к вычислительным ресурсам. Число элементов гессиана равно квадрату числа параметров, поэтому при k параметрах (а даже для совсем не- большой нейронной сети параметры могут исчисляться миллионами) метод Ньюто-на требует обращения матрицы размера k×k, а вычислительная сложность этой опе- рации составляет O(k 3). Кроме того, поскольку параметры изменяются при каждом обновлении, обратный гессиан нужно вычислять на каждой итерации обучения. По-этому лишь сети с очень небольшим числом параметров реально обучить методом Ньютона. Далее в этом разделе мы обсудим альтернативы, смысл которых – восполь- зоваться некоторыми достоинствами метода Ньютона, не взваливая на себя неподъ-емного груза вычислений. 8.6.2. Метод сопряженных градиентов Метод сопряженных градиентов позволяет избежать вычисления обратного гессиана посредством итеративного спуска в сопряженных направлениях. Идея этого подхо- да вытекает из внимательного изучения слабого места метода наискорейшего спуска (детали см. в разделе 4.3), при котором поиск итеративно производится в направле-\n--- Страница 270 ---\nПриближенные методы второго порядка  269 нии градиента. На рис. 8.6 показано, что метод наискорейшего спуска в квадратичной впадине неэффективен, т. к. продвигается зигзагами. Так происходит, потому что на- правление линейного поиска, определяемое градиентом на очередном шаге, гаранти- рованно ортогонально направлению поиска на предыдущем шаге. 20 10 0 –10–20–30 –30 –20 –10 100 20 Рис. 8.6  Метод наискорейшего спуска в применении к поверхности квадратичной целевой функции. В этом методе на каждом шаге произво- дится переход в точку с наименьшей стоимостью вдоль прямой, определяе- мой градиентом в начале этого шага. Это решает некоторые показанные на рис. 4.6 проблемы, которые обусловлены фиксированной скоростью обучения, но даже при оптимальной величине шага алгоритм все равно продвигается к оптимуму зигзагами. По определению, в точке минимума целевой функции вдоль заданного направления градиент в конечной точке ортогонален этому направлению Обозначим dt–1 направление предыдущего поиска. В точке минимума, где поиск за- вершается, производная по направлению dt–1 равна нулю: ∇θJ(θ) · dt–1 = 0. Поскольку градиент в этой точке определяет текущее направление поиска, dt = ∇θJ(θ) не дает вклада в направлении dt–1. Следовательно, dt ортогонально dt–1. Эта связь между dt–1 и dt иллюстрируется на рис. 8.6 для нескольких итераций метода наискорейшего спуска. Как видно по рисунку, выбор ортогональных направлений спуска не сохра- няет минимума вдоль предыдущих направлений поиска. Отсюда и зигзагообразная траектория, поскольку после спуска к минимуму в направлении текущего градиента мы должны заново минимизировать целевую функцию в направлении предыдуще- го градиента. А значит, следуя направлению градиента в конце каждого отрезка, мы в некотором смысле перечеркиваем достигнутое в направлении предыдущего отрез- ка. Метод сопряженных градиентов и призван решить эту проблему. В методе сопряженных градиентов направление следующего поиска является со- пряженным к направлению предыдущего, т. е. мы не отказываемся от того, что было достигнуто в предыдущем направлении. На t-ой итерации обучения направление сле- дующего поиска определяется формулой: dt = ∇θJ(θ) + βtdt–1, (8.29) где βt – коэффициент, определяющий, какую часть направления dt–1 следует приба- вить к текущему направлению поиска.\n--- Страница 271 ---\n270  Оптимизация в обучении глубоких моделей Два направления dt и dt–1 называются сопряженными, если dt⏉Hdt–1 = 0, где H – мат- рица Гессе. Самый простой способ обеспечить сопряженность – вычислить собственные век- торы H для выбора βt – не отвечает исходной цели разработать метод, который был бы вычислительно проще метода Ньютона при решении больших задач. Можно ли найти сопряженные направления, не прибегая к таким вычислениям? К счастью, да. Существуют два популярных метода вычисления βt. 1. Метод Флетчера-Ривса: (8.30) 2. Метод Полака-Рибьера: (8.31) Для квадратичной поверхности сопряженность направлений гарантирует, что мо- дуль градиента вдоль предыдущего направления не увеличится. Поэтому минимум, найденный вдоль предыдущих направлений, сохраняется. Следовательно, в k-мерном пространстве параметров метод сопряженных градиентов требует не более k поисков для нахождения минимума. Этот метод описан в алгоритме 8.9. Нелинейный метод сопряженных градиентов. До сих пор мы обсуждали метод сопряженных градиентов в применении к квадратичной целевой функции. Но в этой главе нас интересуют в основном методы оптимизации для обучения нейронных се- тей и других глубоких моделей, в которых целевая функция далека от квадратичной. Как ни странно, метод сопряженных градиентов применим и в такой ситуации, хотя и с некоторыми изменениями. Если целевая функция не квадратичная, то уже нельзя гарантировать, что поиск в сопряженном направлении сохраняет минимум в преды- дущих направлениях. Поэтому в нелинейном алгоритме сопряженных градиентов время от времени производится сброс, когда метод сопряженных градиентов заново начинает поиск вдоль направления неизмененного градиента. Алгоритм 8.9. Метод сопряженных градиентов Require: начальные значения параметров θ 0. Require: обучающий набор m примеров Инициализировать ρ0 = 0 Инициализировать g0 = 0 Инициализировать t = 1while критерий остановки не выполнен do Инициализировать градиент g t = 0 Вычислить градиент: gt ← (1/m)∇θΣi L(f(x(i); θ), y(i)) Вычислить βt = ((gt – gt–1)⏉gt)/g⏉ t–1 gt–1 (метод Полака–Рибьера) (Нелинейный метод сопряженных градиентов: иногда сбрасывать βt в 0, на- пример если t кратно некоторой константе k, скажем k = 5)Вычислить направление поиска: ρ t = –gt + βt ρt–1 Произвести поиск с целью нахождения: ε* = argminε(1/m)Σm i=1L(f(x(i); θt + + ερt), y(i))\n--- Страница 272 ---\nПриближенные методы второго порядка  271 (Если функция стоимости строго квадратичная, не искать ε*, а вычислить аналитически) Применить обновление: θt+1 = θt + ε*ρt t ← t + 1 end while Есть сообщения, что нелинейный метод сопряженных градиентов дает неплохие ре- зультаты при обучении нейронных сетей, хотя часто имеет смысл инициализировать оптимизацию, выполнив несколько итераций стохастического градиентного спуска, и только потом переходить к нелинейным сопряженным градиентам. Кроме того, хотя нелинейный алгоритм сопряженных градиентов традиционно считался пакетным ме-тодом, его мини-пакетные варианты успешно применялись для обучения нейронных сетей (Le et al., 2011). Позже были предложены адаптации метода сопряженных гради-ентов, например алгоритм масштабированных сопряженных градиентов (Moller, 1993). 8.6.3. Алгоритм BFGS Алгоритм Бройдена–Флетчера–Гольдфарба–Шанно (BFGS) – попытка взять не- которые преимущества метода Ньютона без обременительных вычислений. В этом смысле BFGS аналогичен методу сопряженных градиентов. Однако в BFGS подход к аппроксимации обновления Ньютона более прямолинейный. Напомним, что об- новление Ньютона определяется формулой θ* = θ0 – H–1∇θ J(θ0), (8.32) где H – гессиан J относительно θ, вычисленный в точке θ0. Основная вычислительная трудность при применении обновления Ньютона – вычисление обратного гессиана H–1. В квазиньютоновских методах (из которых алгоритм BFGS самый известный) обратный гессиан аппроксимируется матрицей Mt, которая итеративно уточняется в ходе обновлений низкого ранга. Определение и вывод аппроксимации BFGS приводятся во многих учебниках по оптимизации, в т. ч. Luenberger (1984). После нахождения аппроксимации гессиана Mt направление спуска ρt определя- ется по формуле ρt = Mt gt. В этом направлении производится линейный поиск для определения величины шага ε*. Окончательное обновление параметров производит- ся по формуле θt+1 = θt + ε*ρt. (8.33) Как и в методе сопряженных градиентов, в алгоритме BFGS производится после- довательность линейных поисков в направлениях, вычисляемых с учетом информа- ции второго порядка. Но, в отличие от метода сопряженных градиентов, успех не так сильно зависит от того, находит ли линейный поиск точку, очень близкую к истин- ному минимуму вдоль данного направления. Поэтому BFGS тратит меньше времени на уточнение результатов каждого линейного поиска. С другой стороны, BFGS дол- жен хранить обратный гессиан M, для чего требуется память объема O(n 2), поэтому BFGS непригоден для современных моделей глубокого обучения, насчитывающих мил лионы параметров. BFGS в ограниченной памяти (L-BFGS). Потребление памяти в алгоритме BFGS можно значительно уменьшить, если не хранить полную аппроксимацию обратного\n--- Страница 273 ---\n272  Оптимизация в обучении глубоких моделей гессиана M. В алгоритме L-BFGS аппроксимация M вычисляется так же, как в BFGS, но, вместо того чтобы сохранять аппроксимацию между итерациями, делается пред- положение, что M(t–1) – единичная матрица. При использовании совместно с точным линейным поиском направления, вычисляемые алгоритмом L-BFGS, являются вза-имно сопряженными. Однако, в отличие от метода сопряженных градиентов, эта про- цедура ведет себя хорошо, даже когда линейный поиск находит только приближен-ный минимум. Описанную стратегию L-BFGS без запоминания можно обобщить, включив больше информации о гессиане; для этого нужно хранить некоторые век- торы, используемые для обновления M на каждом шаге, тогда потребуется только память объемом O(n). 8.7. Стратегии оптимизации и метаалгоритмы Многие методы оптимизации – не совсем алгоритмы, а скорее общие шаблоны, ко- торые можно специализировать и получить алгоритмы или подпрограммы, включае- мые в различные алгоритмы. 8.7.1. Пакетная нормировка Пакетная нормировка (Ioffe and Szegedy, 2015) – одна из наиболее интересных нова- ций в области оптимизации глубоких нейронных сетей – вообще алгоритмом не яв- ляется. Это метод адаптивной перепараметризации, появившийся из-за трудностей обучения очень глубоких моделей. Для очень глубоких моделей характерна композиция нескольких функций, или слоев. Градиент говорит, как обновлять каждый параметр в предположении, что дру- гие слои не изменяются. На практике мы обновляем все слои одновременно. При вы-полнении обновления могут произойти неожиданности, потому что ко всем образую-щим композицию функции одновременно применяются обновления, вычисленные в предположении, что прочие функции сохраняют постоянство. Рассмотрим простой пример: предположим, что имеется глубокая нейронная сеть, в каждом слое которой находится по одному блоку и в скрытых слоях не используется функция активации: y� = xw 1w2w3…wl. Здесь wi – вес в i-м слое. Выход i-го слоя hi = hi–1wi. Выход y� линей- но зависит от входа x, но нелинейно от весов wi. Предположим, что наша функция стоимости дала градиент 1 по y�, поэтому мы хотим немного уменьшить y�. Тогда ал- горитм обратного распространения может вычислить градиент g = ∇wy�. Посмотрим, что произой дет, когда мы произведем обновление w ← w – εg. Разложение y� в ряд Тей- лора до членов первого порядка предсказывает, что значение y� уменьшится на εg⏉g. Если бы мы хотели уменьшить y� на 0.1, то, исходя из этой информации первого по- рядка, содержащейся в градиенте, могли бы установить скорость обучения ε равной 0.1/(g⏉g). Однако фактическое обновление будет включать также эффекты второго, третьего, …, l-го порядка. Новое значение y � равно: x(w1 – εg1)(w2 – εg2)…(wl – εgl). (8.34) Пример члена второго порядка, возникающего при таком обновлении, – ε2g1g2∏l i=3wi. Этот член может быть пренебрежимо мал, если произведение ∏l i=3wi мало, а может быть экспоненциально велик, если веса в слоях с 3 по l больше 1. Поэтому очень трудно выбрать правильную скорость обучения, т. к. эффект обновления параметров одного слоя сильно зависит от всех остальных слоев. Алгоритмы оптимизации второго по-\n--- Страница 274 ---\nСтратегии оптимизации и метаалгоритмы  273 рядка решают эту проблему, учитывая при вычислении обновления взаимодействия второго порядка, но, как мы видим, в очень глубоких сетях даже взаимодействия бо- лее высокого порядка могут быть существенными. Но уж если оптимизация второ-го порядка обходится дорого и обычно требует многочисленных аппроксимаций, не позволяющих точно учесть значимых взаимодействий второго порядка, то попытка построения алгоритма оптимизации n-го порядка при n > 2 выглядит совершенно безнадежной. Что же предпринять вместо этого? Пакетная нормировка предлагает элегантный способ перепараметризации почти любой глубокой сети. Перепараметризация значительно снижает остроту проблемы координации обновлений между многими слоями. Пакетную нормировку можно применить к входному и любому скрытому слою сети. Пусть H – мини-пакет актива- ций нормируемого слоя, представленный в виде матрицы плана, так что активации для каждого примера занимают одну строку матрицы. Для нормировки заменим H матрицей (8.35) где μ – вектор средних всех блоков, а σ – вектор стандартных отклонений всех блоков. Приведенная выше формула выражает применение векторов μ и σ к каждой строке матрицы H. Внутри каждой строки операция применяется поэлементно, т. е. для нор- мировки Hi; j нужно вычесть μj и разделить на σj. Остальная сеть работает с H′ точно так же, как исходная работала с H. На этапе обучения (8.36) и (8.37) где δ – небольшое положительное число, например 10–8, введенное, чтобы избежать неопределенного градиента √_ z в точке z = 0. И важнейший момент – мы выполняем об- ратное распространение сквозь эти операции, чтобы вычислить среднее и стандарт- ное отклонения и применить их к нормировке H. Это означает, что градиент никогда не предлагает операцию, действие которой сводится просто к увеличению стандарт- ного отклонения или среднего hi; операции нормировки устраняют результат такого действия и обнуляют его компоненту в градиенте. Это и было главным нововведени- ем пакетной нормировки. В прежних подходах к функции стоимости прибавлялись штрафы, направленные на то, чтобы блоки имели нормированные статистики акти-вации, или после каждого шага градиентного спуска производилось вмешательство с целью перенормировать статистики блока. Первый подход обычно приводил к неи- деальной нормировке, а последний – к значительным затратам времени впустую, по- тому что алгоритм обучения раз за разом предлагает изменить среднее и дисперсию, а на шаге нормировки это изменение отменяется. Пакетная нормировка перепараме- тризует модель, так что некоторые блоки всегда стандартизованы по определению, и тем самым ловко обходит обе проблемы.\n--- Страница 275 ---\n274  Оптимизация в обучении глубоких моделей На этапе тестирования μ и σ можно заменить скользящими средними, подготов- ленными на этапе обучения. Это позволяет вычислять модель для одного примера, не прибегая к определениям μ и σ, которые зависят от всего мини-пакета. Возвра- щаясь к примеру y� = xw1w2 … wl, мы видим, что трудности обучения модели можно по большей части разрешить путем нормировки hl–1. Предположим, что x имеет нор- мальное распределение с нулевым средним и единичной дисперсией. Тогда hl–1 тоже имеет нормальное распределение, потому что преобразование x в hl линейно. Однако у hl–1 среднее уже не равно 0, а дисперсия не равна 1. После применения пакетной нормировки мы получаем h� l–1 с восстановленными свойствами нулевого среднего и единичной дисперсии. Почти для любого обновления нижних слоев h� l–1 сохра- няет эти свойства. Тогда выход y� можно обучить как простую линейную функцию y� = wl h� l–1. Обучение этой модели стало совсем простым делом, потому что параметры нижних слоев в большинстве случаев ни на что не влияют; их выход всегда перенор- мируется в нормальное распределение с нулевым средним и единичной дисперсией. В некоторых патологических ситуациях нижние слои могут оказывать влияние. Из- менение одного из весов нижнего слоя на 0 может привести к вырожденному выходу, а изменение знака одного веса может обратить связь между h� l–1 и y. Такие ситуации очень редки. Без нормировки почти любое обновление очень сильно влияло бы на статистику h l–1. Таким образом, в результате пакетной нормировки обучить эту мо- дель стало гораздо проще. Конечно, в этом примере ценой за простоту обучения стала бесполезность нижних уровней. В этой линейной ситуации нижние уровни не дают вредного эффекта, но и полезного тоже. Объясняется это тем, что в результате нор- мировки мы устранили статистики первого и второго порядка, а это всё, на что мо- жет повлиять линейная сеть. В глубокой нейронной сети с нелинейными функциями активации нижние уровни могут выполнять нелинейные преобразования данных, поэтому остаются полезными. Действие пакетной нормировки направлено на стан-дартизацию только среднего и дисперсии каждого блока с целью стабилизировать обучение, но она не препятствует изменению связей между блоками и нелинейных статистик одного блока. Поскольку последний слой сети способен обучиться линейному преобразованию, мы на самом деле можем попробовать удалить все линейные связи между блоками в пределах одного слоя. Именно так и поступили авторы работы Desjardins et al. (2015), которая подсказала идею пакетной нормировки. К сожалению, исключение всех линейных взаимодействий обходится гораздо дороже стандартизации среднего и стандартного отклонений каждого отдельного блока, так что пакетная нормировка до сих пор остается наиболее практичным решением. Нормировка среднего и стандартного отклонений блока может снизить вырази- тельную мощность нейронной сети, содержащей этот блок. Для сохранения вырази-тельной мощности обычно заменяют пакет активаций скрытых блоков H на γH′ + β, а не просто на нормированную матрицу H′. Переменные γ и β – обученные парамет- ры, благодаря которым новая величина может иметь произвольные среднее и стан- дартное отклонения. На первый взгляд, это кажется бессмысленным – зачем было устанавливать среднее в 0, а потом вводить параметр, который позволяет снова пере- установить его в произвольное значение β? Да затем, что новая параметризация мо- жет представить то же самое семейство функций от входных данных, что и старая, но при этом обладает другой динамикой обучения. В старой параметризации среднее H определялось сложным взаимодействием между параметрами на уровнях ниже H.\n--- Страница 276 ---\nСтратегии оптимизации и метаалгоритмы  275 В новой же параметризации среднее γH′ + β определяется только величиной β. При новой параметризации модель гораздо легче обучить методом градиентного спуска. Большинство слоев нейронных сетей имеет вид ϕ(XW + b), где ϕ – фиксированная нелинейная функция активации, например, преобразование линейной ректифика- ции. Естественно спросить, следует ли применять пакетную нормировку ко входу X или к уже преобразованному значению XW + b. В работе Ioffe and Szegedy (2015) ре- комендуется последнее. Точнее говоря, XW + b следует заменить результатом норми- ровки XW. Член смещения нужно опустить, потому что он становится избыточным ввиду параметра β, применяемого в ходе перепараметризации. Входом слоя обычно является выход нелинейной функции активации (например, функции линейной рек-тификации) предыдущего слоя. Поэтому статистика входа сильнее отличается от нормального распределения и хуже поддается стандартизации посредством линей- ных операций. В сверточных сетях (см. главу 9) важно применять одну и ту же норми- ровку μ и σ в каждой точке пространства в карте признаков, чтобы статистика карты признаков оставалась одинаковой вне зависимости от положения в пространстве. 8.7.2. Покоординатный спуск В некоторых случаях задачу оптимизации можно быстро решить, разбив на отдель-ные части. Если минимизировать f(x) сначала по переменной x i, затем по переменной xj и т. д., перебрав в цикле все переменные, то мы гарантированно окажемся в (ло- кальном) минимуме. Такой подход называется покоординатным спуском, поскольку в каждый момент времени производится оптимизация по одной координате. В более общем случае блочно-покоординатного спуска одновременно производится мини- мизация по подмножеству переменных. Термин «покоординатный спуск» часто упо-требляется не только в своем строгом смысле, но и для обозначения блочно-покоор- динатного спуска. Покоординатный спуск наиболее осмыслен, когда различные переменные в задаче оптимизации можно разбить на группы с относительно изолированными ролями или когда оптимизация по одной группе переменных значительно эффективнее, чем по всем. Рассмотрим, к примеру, такую функцию стоимости: (8.38) Эта функция описывает проблему обучения, которая называется разреженным ко- дированием. Цель состоит в том, чтобы найти матрицу весов W, которая может ли- нейно декодировать матрицу значений активации H и реконструировать обучающий набор X. В большинстве применений разреженного кодирования участвует также снижение весов или ограничение на нормы столбцов W, чтобы предотвратить пато- логические решения с очень малой H и большой W. Функция J невыпуклая. Однако мы можем разбить входы алгоритма обучения на два множества: словарные параметры W и представление кода H. Минимизация це- левой функции по любому из этих двух множеств – выпуклая задача. Поэтому метод блочно-покоординатного спуска позволяет использовать эффективные алгоритмы выпуклой оптимизации, выполнив сначала оптимизацию по W с фиксированным H, а затем оптимизацию по H с фиксированным W. Покоординатный спуск – не самая удачная стратегия, когда значение одной пе- ременной сильно влияет на оптимальное значение другой, как в функции f(x) =\n--- Страница 277 ---\n276  Оптимизация в обучении глубоких моделей = (x1 – x2)2 + α(x12 + x22), где α – положительная постоянная. Для минимизации первого члена нужно, чтобы переменные мало отличались друг от друга, а для минимизации второго – чтобы обе были близки к нулю. Минимум достигается, когда обе перемен- ные равны 0. Методом Ньютона эту задачу можно было бы решить за один шаг, по- тому что она квадратичная и положительно определенная. Однако при малых α метод покоординатного спуска сходится очень медленно, потому что первый член не дает изменить одну переменную, так чтобы ее значение сильно отличалось от значения второй переменной. 8.7.3. Усреднение Поляка Усреднение Поляка (Polyak and Juditsky, 1992) заключается в усреднении несколь- ких точек на траектории алгоритма оптимизации в пространстве параметров. Если на протяжении t итераций градиентного спуска алгоритм посетил точки θ(1), …, θ(t), то вы- ходом алгоритма усреднения Поляка будет θ�(t) = (1/t)Σiθ(i). Для некоторых классов задач, например градиентного спуска в применении к выпуклым задачам, этот подход дает сильные гарантии сходимости. В применении к нейронным сетям обоснование скорее эвристическое, но на практике дает неплохие результаты. Основная идея со-стоит в том, что алгоритм оптимизации может несколько раз пересечь овраг, так и не попав в точку на его дне. Но усреднение по точкам на каждом склоне оврага должно быть расположено ближе ко дну. В невыпуклых задачах траектория оптимизации может оказаться очень сложной и заходить во много различных областей. Вряд ли полезно включать точки, посещен- ные в далеком прошлом, которые могут быть отделены от текущей точки большими барьерами на поверхности функции стоимости. Поэтому, когда усреднение Поляка применяется к невыпуклым задачам, обычно берут экспоненциально затухающее скользящее среднее: θ� (t) = αθ�(t–1) + (1 – α)θ(t). (8.39) Такой подход используется в многочисленных приложениях. Недавний пример см. в работе Szegedy et al. (2015). 8.7.4. Предобучение с учителем Иногда прямое обучение модели для решения конкретной задачи – слишком амбици- озная цель, если модель сложная и с трудом поддается оптимизации или сама задача очень трудна. Бывает, что эффективнее обучить более простую модель для решения той же задачи, а затем усложнить ее. Или обучить модель решению более простой за- дачи, а затем перейти к настоящей задаче. Стратегии обучения простых моделей на простых задачах, перед тем как приступить к обучению желаемой модели на желае- мой задаче, имеют собирательное название: предобучение. Жадные алгоритмы разбивают задачу на несколько компонент, а затем находят оптимальное решение для каждой компоненты в отдельности. К сожалению, не га- рантируется, что комбинация оптимальных компонент дает оптимальное решение задачи в целом. Тем не менее жадные алгоритмы вычислительно могут оказаться го- раздо дешевле алгоритмов, ищущих наилучшее совместное решение, а их качество, хоть и неоптимальное, зачастую приемлемо. После завершения жадного алгоритма можно выполнить фазу окончательной настройки, когда алгоритм совместной опти-\n--- Страница 278 ---\nСтратегии оптимизации и метаалгоритмы  277 мизации ищет оптимальное решение задачи в целом. Если инициализировать алго- ритм совместной оптимизации решением, найденным жадным алгоритмом, то можно существенно ускорить поиск окончательного решения и улучшить его качество. Предобучение, и особенно жадное предобучение, встречается в глубоком обучении повсеместно. В этом разделе мы опишем алгоритмы предобучения, в которых задача обучения с учителем разбивается на несколько более простых задач такого же типа. Этот подход называется жадным предобучением с учителем. В оригинальном варианте жадного предобучения с учителем (Bengio et al., 2007) каждый этап состоит из задачи обучения с учителем, содержащей только часть сло- ев финальной нейронной сети. На рис. 8.7 показан пример жадного предобучения с учителем, когда каждый скрытый слой предварительно обучен в составе мелкого МСП с учителем, принимающего на входе выход предыдущего скрытого слоя. Вмес- то предобучения по одному слою за раз в работе Simonyan and Zisserman (2015) про- изводится предобучение глубокой сверточной сети (11 слоев весов), а затем первые четыре и последние три слоя этой сети используются для инициализации еще более глубоких сетей (до 19 слоев). Средние слои новой, очень глубокой сети инициали-зируются случайным образом. Затем производится совместное обучение новой сети. Другой вариант, исследованный в работе Yu et al. (2010), – применять выходы ранее обученных МСП, а также первоначальные входные данные в качестве входов каждо- го дополнительного этапа. Почему жадное предобучение с учителем дает какой-то эффект? В пионерской ра- боте Bengio et al. (2007) высказана гипотеза, что оно дает более правильное направле-ние промежуточным слоям глубокой иерархии. В общем случае предобучение может оказаться полезным как для оптимизации, так и для обобщаемости. Обобщением предобучения с учителем является перенос обучения (transfer lear- ning): в работе Y osinski et al. (2014) была предобучена глубокая сверточная сеть с восьмью уровнями весов на наборе задач (подмножество, состоящее из 1000 кате- горий объектов из набора ImageNet), а затем сеть того же размера была инициали- зирована первыми k слоями первой сети. Далее все слои второй сети (верхние слои которой были инициализированы случайным образом) были совместно обучены для выполнения различных наборов задач (другое подмножество ImageNet из 1000 кате-горий объектов), но число обучающих примеров было меньше, чем для первого набо-ра. Другие подходы к переносу обучения в контексте нейронных сетей обсуждаются в разделе 15.2. Сюда же можно отнести подход FitNets (Romero et al., 2015). Он начинается с обуче ния сети достаточно малой глубины и достаточно большой ширины (число блоков в слое), чтобы ее было легко обучить. Затем эта сеть становится учителем для второй сети, называемой учеником. Сеть-ученик гораздо глубже и уже (от 11 до 19 слоев), и обучить ее методом СГС при нормальных обстоятельствах было бы за- труднительно. Обучение сети-ученика облегчается тем, что ученик учится предсказы-вать не только выход исходной задачи, но и значение среднего слоя сети-учителя. Эта дополнительная задача предоставляет ряд рекомендаций по использованию скрытых слоев и может упростить задачу оптимизации. Вводятся дополнительные параметры, чтобы восстановить средний слой пятислойной сети-учителя по среднему слою бо-лее глубокой сети-ученика. Но целью является не предсказание финального класса, а предсказание скрытого среднего слоя сети-учителя. Таким образом, у нижних слоев сети-ученика две цели: помочь выходам выполнить свою задачу, а также предсказать\n--- Страница 279 ---\n278  Оптимизация в обучении глубоких моделей промежуточный слой сети-учителя. Хотя обучать узкую и глубокую сеть труднее, чем широкую и мелкую, но узкая и глубокая сеть лучше обобщается и, безуслов но, для узкой сети с небольшим числом параметров вычислительная стоимость обучения ниже. Без рекомендаций по скрытому слою сеть-ученик в экспериментах вела себя очень плохо – как на обучающем, так и на тестовом наборе. Таким образом, рекомен- дации по средним слоям, быть может, являются одним из средств обучения нейрон-ных сетей, с трудом поддающихся обучению другими методами. Но не исключено, что другие методы оптимизации или изменение архитектуры тоже могло бы решить проблему. y y y y y y x (с)x (a)h(1) h(2) h(1) W(1)W(1) W(2) W(1)W(1) W(2) U(1)U(1) U(2) U(1)U(1) U(2)h(1) h(2) h(1) x (d)x (b) Рис. 8.7  Иллюстрация одного из видов жадного предобучения с учите- лем (Bengio et al., 2007). (a) Начинаем с обучения достаточно мелкой архи- тектуры. (b) Другой вид той же архитектуры. (c) Оставляем только сигналы между входным и скрытым слоями исходной сети и отбрасываем сигналы между скрытым и выходным слоями. Передаем выход первого скрытого слоя на вход еще одного однослойного МСП с учителем, который обучает- ся с той же целевой функцией, что и первая сеть, и таким образом добав- ляем второй скрытый слой. Эту операцию можно повторить сколько угодно раз. (d) Тот же результат, представленный в виде сети прямого распростра- нения. Чтобы улучшить оптимизацию, мы можем произвести совместную окончательную настройку всех слоев – либо в самом конце, либо на каждом этапе процесса\n--- Страница 280 ---\nСтратегии оптимизации и метаалгоритмы  279 8.7.5. Проектирование моделей с учетом простоты оптимизации Лучшая стратегия улучшения оптимизации не всегда связана с улучшением алгорит- ма. Вместо этого можно изначально проектировать модели так, чтобы их было проще оптимизировать. В принципе, можно было бы использовать немонотонные функции активации, кото- рые то возрастают, то убывают, но тогда оптимизация оказалась бы крайне трудным де-лом. На практике важнее выбирать семейство моделей, легко поддающееся оптимизации, чем мощный алгоритм оптимизации. Прогресс в области нейронных сетей за последние тридцать лет в основном был связан именно с изменением семейства моделей. Стоха- стический градиентный спуск с учетом импульса, использовавшийся для обучения се- тей еще в 1980-х годах, и по сей день применяется в самых передовых приложениях. Говоря конкретно, в современных нейронных сетях предпочтение отдается линей- ным преобразованиям между слоями и функциями активации, дифференцируемым почти всюду и имеющим значительный наклон на больших участках своей области определения. Такие новации в области проектирования моделей, как LSTM, блоки линейной ректификации и maxout-блоки, все направлены на использование более линейных функций, чем в предыдущих моделях типа глубоких сетей с сигмоидны- ми блоками. У таких моделей есть полезные свойства, упрощающие оптимизацию. Градиент распространяется сквозь много слоев, при условии что у якобиана линей- ного преобразования имеются разумные сингулярные значения. К тому же линей- ные функции монотонно возрастают в одном направлении, так что даже если выход модели очень далек от правильного, из вычисления градиента сразу становится ясно, в каком направлении должен сместиться выход, чтобы уменьшить функцию потерь. Иными словами, современные нейронные сети проектируются так, чтобы локальная информация о градиенте достаточно хорошо соответствовала движению в сторону далеко находящегося решения. Есть и другие стратегии проектирования моделей, способствующие упрощению оптимизации. Например, линейные пути или прямые связи между слоями уменьша-ют длину кратчайшего пути от параметров нижних слоев к выходу, а потому смягчают проблему исчезающего градиента (Srivastava et al., 2015). К идее прямых связей близ- ка идея о добавлении дополнительных копий выходов, которые были бы соединены с промежуточными слоями сети, как в GoogLeNet (Szegedy et al., 2014в a) и сетях с глубоким проникновением учителя (deeply supervised nets) (Lee et al., 2014). Эти «вспомогательные головы» обучаются решать ту же задачу, что основной верхний слой сети, чтобы нижние слои получали больший градиент. По завершении обучения вспомогательные головы можно отбросить. Это альтернатива стратегиям предобуче-ния, описанным в предыдущем разделе. При таком подходе можно совместно обучать все слои на одной стадии, но изменить архитектуру, так чтобы промежуточные слои (особенно ниже расположенные) могли получать рекомендации о том, что делать, по более короткому пути. Эти рекомендации несут нижним слоям сигнал об ошибке. 8.7.6. Методы продолжения и обучение по плану Как было сказано в разделе 8.2.7, многие проблемы оптимизации проистекают из глобальной структуры функции стоимости, их невозможно разрешить просто за счет улучшения оценки направления локального обновления. Основная стратегия пре-одоления таких проблем – попытаться присвоить параметрам начальные значения,\n--- Страница 281 ---\n280  Оптимизация в обучении глубоких моделей находящиеся в области, связанной с решением коротким путем в пространстве пара- метров, который можно найти методом локального спуска. Методы продолжения – это семейство стратегий, которые упрощают оптими- зацию посредством выбора таких начальных точек, чтобы локальная оптимизация проходила в основном в областях пространства с хорошим поведением. Идея заклю- чается в том, чтобы построить последовательность целевых функций от одних и тех же параметров. Чтобы минимизировать функцию стоимости J(θ), мы строим новые функции стоимости { J(0), …, J(n)}. Сложность этих функций постепенно нарастает, так что минимизировать J(0) сравнительно легко, а функция J(n), которую труднее всего минимизировать, совпадает с J(θ) – истинной функцией стоимости, ради которой все и затевалось. Говоря, что J(i) проще J(i+1), мы имеем в виду, что она хорошо себя ведет в большей части пространства θ. Случайно выбранные начальные значения с большей вероятностью окажутся в области, где метод локального спуска способен минимизировать функцию стоимости, просто потому что эта область больше. После-довательность функций стоимости проектируется так, чтобы решение одной функ-ции было хорошим начальным приближением для другой. Таким образом, мы снача-ла находим решение легкой задачи, а затем постепенно уточняем его для решения все более трудных задач, пока не найдем решения исходной задачи. Традиционные методы продолжения (которые появились задолго до применения этой идеи к обучению нейронных сетей) обычно основываются на сглаживании це- левой функции. В работе Wu (1997) приведены пример такого метода и обзор род- ственных ему. Методы продолжения также тесно связаны с имитацией отжига, когда к параметрам добавляется шум (Kirkpatrick et al., 1983). В последние годы методы продолжения применялись чрезвычайно успешно. В статье Mobahi and Fisher (2015) имеется обзор недавних работ, особенно в области приложений ИИ. Традиционно методы продолжения проектировались прежде всего для преодоле- ния проблем, связанных с наличием локальных минимумов. Точнее, их цель – найти глобальный минимум, несмотря на присутствие многих локальных. Для этого стро-ятся более простые функции стоимости путем «размытия» исходной. Эту операцию размытия можно выполнить, если выборочно аппроксимировать функцию J (i)(θ) = 𝔼θ′~𝒩(θ ′;θ,σ(i)2) J(θ′). (8.40) Интуитивное соображение в пользу этого подхода заключается в том, что некото- рые невыпуклые функции становятся приближенно выпуклыми после размытия. Во многих случаях размытие сохраняет достаточно информации о положении глобаль- ного минимума, так что его можно найти, решая варианты задачи с уменьшающейся степенью размытия. Но эта идея может не сработать по трем причинам. Прежде всего нам, возможно, и удастся определить последовательность функций стоимости, в ко- торой первая функция будет выпуклой, и, проследив оптимум при переходе от одной функции к другой, в итоге найти глобальный минимум, но количество промежуточ- ных функций будет настолько велико, что стоимость всей процедуры останется слиш-ком большой. NP-трудная задача остается NP-трудной, даже если методы продолже-ния к ней применимы. Другие две причины неудачи соответствуют неприменимости метода в принципе. Во-первых, не исключено, что функция не становится выпуклой ни при какой степени размытия. Взять, к примеру, функцию J(θ) = –θ ⏉θ. Во-вторых, функция может оказаться выпуклой после размытия, но прослеживание ее минимума приводит к локальному, а не глобальному минимуму исходной функции стоимости.\n--- Страница 282 ---\nСтратегии оптимизации и метаалгоритмы  281 Хотя методы продолжения изначально разрабатывались для решения проблемы локальных минимумов, в контексте оптимизации нейронных сетей эта проблема уже не считается самой животрепещущей. Тем не менее методы продолжения по- прежнему полезны. Упрощение целевой функции может устранить плоские участки, уменьшить дисперсию оценки градиента, улучшить обусловленность матрицы Гессе или сделать еще что-то, что либо облегчит вычисление локальных обновлений, либо улучшит соответствие между локальными обновлениями направлений и движением в сторону глобального решения. В работе Bengio et al. (2009) отмечено, что подход, называемый обучением по плану (curriculum learning), или шейпингом (shaping), можно интерпретировать как метод продолжения. В основе обучения по плану лежит идея планирования процесса обуче- ния, когда начинают с простых понятий и постепенно вводят более сложные. Ранее эта базовая стратегия применялась, чтобы ускорить обучение животных (Skinner, 1958; Peterson, 2004; Krueger and Dayan, 2009), и в машинном обучении (Solomonoff, 1989; Elman, 1993; Sanger, 1994). В работе Bengio et al. (2009) приведено ее обосно- вание как метода продолжения, в котором простота предшествующих функций J (i) обес печивается увеличением влияния более простых примеров (либо за счет того, что их вкладу в функцию стоимости назначаются большие коэффициенты, либо потому что они выбираются чаще). Экспериментально продемонстрировано, что при реше-нии крупномасштабной задачи моделирования языка нейронной сетью обучение по плану улучшает результаты. Обучение по плану успешно применялось к широкому кругу задач в области обработки естественных языков (Spitkovsky et al., 2010; Col- lobert et al., 2011a; Mikolov et al., 2011b; Tu and Honavar, 2011) и компьютерного зре- ния (Kumar et al., 2010; Lee and Grauman, 2011; Supancic and Ramanan, 2013). Также установлено, что обучение по плану согласуется с тем, как преподает человек (Khan et al., 2011): преподаватель сначала показывает более простые и прототипичные при- меры, а затем помогает обучаемому уточнить поверхность решений на менее очевид- ных случаях. Такие стратегии не только более эффективны для обучения людей, чем основанные на равномерной выборке примеров, но и могут повысить эффективность других стратегий обучения (Basu and Christensen, 2013). Еще один важный вклад в исследования в области обучения по плану связан с обуче- нием рекуррентных нейронных сетей улавливанию долговременных зависимостей. В работе Zaremba and Sutskever (2014) обнаружено, что гораздо лучшие результаты по- лучаются при использовании стохастического плана, когда обучаемому всегда предъ- является случайная смесь простых и трудных примеров, но средняя доля трудных примеров (тех, в которых имеются долговременные зависимости) постепенно увеличи- вается. Когда использовался детерминированный план, никакого улучшения по срав-нению с эталоном (обычное обучение на полном обучающем наборе) не наблюдалось. Итак, мы описали базовое семейство моделей нейронных сетей и способы их ре- гуляризации и оптимизации. В последующих главах мы займемся частными случая- ми этого семейства, когда сеть масштабируется на очень большие объемы данных и обрабатываются данные со специальной структурой. Рассмотренные выше методы оптимизации часто применимы к таким специализированным архитектурам после небольшой модификации или даже в неизменном виде.",
      "debug": {
        "start_page": 238,
        "end_page": 282
      }
    },
    {
      "name": "Глава 9. Сверточные сети 282",
      "content": "--- Страница 283 --- (продолжение)\nГлава 9 Сверточные сети Сверточная сеть (LeCun, 1989), она же сверточная нейронная сеть (СНС), – это спе- циальный вид нейронной сети для обработки данных с сеточной топологией. При- мерами могут служить временные ряды, которые можно рассматривать как одномер- ную сетку примеров, выбираемых через регулярные промежутки времени, а также изображения, рассматриваемые как двумерная сетка пикселей. Сверточные сети до-бились колоссального успеха в практических приложениях. Своим названием они обязаны использованию математической операции свертки. Свертка – это особый вид линейной операции. Сверточные сети – это просто нейронные сети, в которых вместо общей операции умножения на матрицу, по крайней мере в одном слое, исполь- зуется свертка. В этой главе мы сначала опишем, что такое свертка. Затем мы объясним причины использования свертки в нейронных сетях. Далее будет описана операция пулин- га, применяемая почти во всех сверточных сетях. Обычно операция, используемая в сверточной нейронной сети, не вполне соответствует определению свертки в других областях, например в инженерных дисциплинах и в чистой математике. Мы опишем несколько вариантов функции свертки, широко применяемых в нейронных сетях. Мы также покажем, как можно применить свертку к различным видам данных в прост- ранствах разной размерности. Затем мы обсудим, как повысить эффективность свертки. Сверточные сети – яркий пример того, как принципы нейробиологии ока- зывают влияние на глубокое обучение. Мы обсудим эти принципы и завершим главу замечаниями о роли сверточных сетей в истории глубокого обучения. В этой главе не затрагивается вопрос о выборе архитектуры сверточной сети. Цель главы – описать инструментарий, предоставляемый сверточными сетями, а в главе 11 мы приведем общие рекомендации по выбору инструментов в конкретных условиях. Прогресс в изучении сверточных сетей настолько быстрый, что сообщения о новой оптималь- ной архитектуре для данного эталонного теста появляются через каждые несколько недель или месяцев, поэтому называть какую-то архитектуру лучшей в книге пока преждевременно. Тем не менее все лучшие архитектуры скомпонованы из описанных в книге строительных блоков. 9.1. Операция свертки В самом общем виде свертка – это операция над двумя функциями вещественного аргумента. Чтобы обосновать определение свертки, начнем с примеров возможных функций. Допустим, что мы следим за положением космического корабля с помощью лазер- ного датчика. Наш датчик выдает единственное значение x(t), положение корабля\nГлава 9 Сверточные сети Сверточная сеть (LeCun, 1989), она же сверточная нейронная сеть (СНС), – это спе- циальный вид нейронной сети для обработки данных с сеточной топологией. При- мерами могут служить временные ряды, которые можно рассматривать как одномер- ную сетку примеров, выбираемых через регулярные промежутки времени, а также изображения, рассматриваемые как двумерная сетка пикселей. Сверточные сети до-бились колоссального успеха в практических приложениях. Своим названием они обязаны использованию математической операции свертки. Свертка – это особый вид линейной операции. Сверточные сети – это просто нейронные сети, в которых вместо общей операции умножения на матрицу, по крайней мере в одном слое, исполь- зуется свертка. В этой главе мы сначала опишем, что такое свертка. Затем мы объясним причины использования свертки в нейронных сетях. Далее будет описана операция пулин- га, применяемая почти во всех сверточных сетях. Обычно операция, используемая в сверточной нейронной сети, не вполне соответствует определению свертки в других областях, например в инженерных дисциплинах и в чистой математике. Мы опишем несколько вариантов функции свертки, широко применяемых в нейронных сетях. Мы также покажем, как можно применить свертку к различным видам данных в прост- ранствах разной размерности. Затем мы обсудим, как повысить эффективность свертки. Сверточные сети – яркий пример того, как принципы нейробиологии ока- зывают влияние на глубокое обучение. Мы обсудим эти принципы и завершим главу замечаниями о роли сверточных сетей в истории глубокого обучения. В этой главе не затрагивается вопрос о выборе архитектуры сверточной сети. Цель главы – описать инструментарий, предоставляемый сверточными сетями, а в главе 11 мы приведем общие рекомендации по выбору инструментов в конкретных условиях. Прогресс в изучении сверточных сетей настолько быстрый, что сообщения о новой оптималь- ной архитектуре для данного эталонного теста появляются через каждые несколько недель или месяцев, поэтому называть какую-то архитектуру лучшей в книге пока преждевременно. Тем не менее все лучшие архитектуры скомпонованы из описанных в книге строительных блоков. 9.1. Операция свертки В самом общем виде свертка – это операция над двумя функциями вещественного аргумента. Чтобы обосновать определение свертки, начнем с примеров возможных функций. Допустим, что мы следим за положением космического корабля с помощью лазер- ного датчика. Наш датчик выдает единственное значение x(t), положение корабля\n--- Страница 284 ---\nОперация свертки  283 в момент t. Переменные x и t принимают вещественные значения, т. е. показания дат- чика в любые два момента времени могут различаться. Теперь предположим, что датчик подвержен помехам. Чтобы получить менее зашумленную оценку положения корабля, необходимо усреднить несколько ре- зультатов измерений. Разумеется, недавние измерения более важны, поэтому мы хотим вычислять взвешенное среднее, придавая недавним измерениям больший вес. Для этого можно воспользоваться весовой функцией w(a), где a – давность измерения. Применив такую операцию усреднения в каждый момент времени, мы получим новую функцию, которая дает сглаженную оценку положения космиче-ского корабля: (9.1) Эта операция называется сверткой и обычно обозначается звездочкой: s(t) = (x ∗ w)(t). (9.2) В нашем примере w должна быть функцией плотности вероятности, иначе усред- нения не получится. Кроме того, w должна быть равна 0 для всех отрицательных значений аргумента, иначе она будет способна заглядывать в будущее, что вряд ли в пределах наших возможностей. Но эти ограничения характерны только для данного примера. В общем случае свертку можно определить для любых функций, для кото- рых определен показанный выше интеграл, и использовать не только для получения взвешенного среднего. В терминологии сверточных сетей первый аргумент (в нашем примере функция x) называется входом, а второй (функция w) – ядром. Выход иногда называют картой признаков. Лазерных датчиков, способных выдавать результаты измерений в любой момент времени, в действительности не бывает. Обычно при работе с данными в компьюте- ре время дискретизировано, и наш датчик будет выдавать данные через регулярные интервалы. Пожалуй, было бы реалистичнее предположить, что лазер производит измерения раз в секунду. Индекс момента времени t может принимать только целые значения. Если теперь предположить, что x и w определены только для целых t, то мы получим определение дискретной свертки: (9.3) В приложениях машинного обучения входом обычно является многомерный мас- сив данных, а ядром – многомерный массив параметров, адаптированных алгорит- мом обучения. Будем называть эти массивы тензорами. Поскольку каждый элемент входа и ядра должен храниться отдельно в явном виде, обычно предполагается, что эти функции равны нулю всюду, кроме конечного множества точек, для которых мы храним значения. На практике это означает, что сумму от минус до плюс бесконеч-ности можно заменить суммированием по конечному числу элементов массива. Наконец, мы часто используем свертки сразу по нескольким осям. Например, если входом является двумерное изображение I, то и ядро должно быть двумерным: (9.4)\n--- Страница 285 ---\n284  Сверточные сети Операция свертки коммутативна, поэтому формулу можно записать и так: (9.5) Обычно вторую формулу проще реализовать в библиотеке машинного обучения, поскольку диапазон допустимых значений m и n меньше. Свойство коммутативности свертки имеет место, потому что мы отразили ядро относительно входа, т. е. при увеличении m индекс входа увеличивается, а индекс ядра уменьшается. Единственная причина такого отражения – обеспечить коммута- тивность. И хотя коммутативность полезна для доказательства теорем, в реализации нейронных сетей она обычно роли не играет. Вместо этого во многих библиотеках реа лизована родственная функция – перекрестная корреляция – та же свертка, только без отражения ядра: (9.6) Во многих библиотеках машинного обучения реализована именно перекрестная корреляция, но называется она сверткой. Далее мы будем придерживаться этого соглашения и называть сверткой обе операции, а в тех местах, где отражение ядра имеет значение, будем это явно оговаривать. В контексте машинного обучения ал- горитм обучения ставит найденные значения ядра в правильную позицию, поэтому если алгоритм основан на свертке с отражением ядра, то он обучит ядро, отраженное относительно того, которое обучено алгоритмом со сверткой без отражения. Редко бывает так, чтобы свертка использовалась в машинном обучении сама по себе; чаще она комбинируется с другими функциями, и такие комбинации не коммутативны вне зависимости от того, используется в ядре-свертке отражение или нет. На рис. 9.1 приведен пример свертки (без отражения ядра) в применении к дву- мерному тензору. Дискретную свертку можно рассматривать как умножение на матрицу, на элемен- ты которой наложены некоторые ограничения. Например, в случае одномерной дис- кретной свертки каждая строка матрицы должна быть равна предыдущей, сдвину-той на один элемент. Это утверждение называется теоремой Теплица. В двумерном случае свертке соответствует дважды блочно-циркулянтная матрица. Помимо огра- ничений на равенство некоторых элементов, свертке обычно соответствует сильно разреженная матрица (в которой большинство элементов равно нулю). Связано это с тем, что ядро, как правило, гораздо меньше входного изображения. Любой алгоритм нейронной сети, основанный на умножении матриц и не зависящий от особенностей структуры этих матриц, должен работать и со сверткой без каких-либо модификаций самой сети. В типичных сверточных нейронных сетях все же используются особен- ности структуры, чтобы организовать эффективную обработку больших входов, но с теоретической точки зрения это необязательно. 9.2. Мотивация Со сверткой связаны три важные идеи, которые помогают улучшить систему машин-ного обучения: разреженные взаимодействия, разделение параметров и эквивари- антные представления. Кроме того, свертка предоставляет средства для работы со входами переменного размера. Опишем эти идеи поочередно.\n--- Страница 286 ---\nМотивация  285 Вход a e ic gw kyb f jd hx lz aw + bx + ey + fz ew + fx + iy + jzbw + cx + fy + gz fw + gx + jy + kzcw + dx + gy + hz gw + hx + ky + lzЯдро Выход Рис. 9.1  Пример двумерной свертки без отражения ядра. Выход огра- ничен только теми позициями, для которых ядро целиком укладывается в изображение; в некоторых контекстах такая свертка называется «допусти- мой». Прямоугольник с указывающими на него стрелками показывает, как левый верхний элемент выходного тензора образуется путем применения ядра к соответствующей левой верхней области входного тензора В слоях традиционной нейронной сети применяется умножение на матрицу па- раметров, в которой взаимодействие между каждым входным и каждым выходным блоками описывается отдельным параметром. Это означает, что каждый выходной блок взаимодействует c каждым входным блоком. Напротив, в сверточных сетях вза- имодействия обычно разреженные (это свойство называют еще разреженной связ- ностью, или разреженными весами). Достигается это за счет того, что ядро меньше входа. Например, входное изображение может содержать тысячи или миллионы пикселей, но небольшие значимые признаки, например границы, можно обнаружить с помощью ядра, охватывающего всего десятки или сотни пикселей. Следователь- но, нужно хранить меньше параметров, а это снижает требования модели к объему памяти и повышает ее статистическую эффективность. Кроме того, для вычисления выхода потребуется меньше операций. Все вместе обычно намного повышает эффек-тивность сети. Если имеется m входов и n выходов, то для умножения матриц нуж- но m×n параметров, и сложность практически используемых алгоритмов составляет O(m×n) (в расчете на один пример). Если ограничить число соединений с каждым выходом величиной k, то потребуется только k×n параметров, и сложность составит O(k×n). Во многих практических приложениях можно получить хорошее качество на задаче машинного обучения, когда k на несколько порядков меньше m. Графически разреженная связность иллюстрируется на рис. 9.2 и 9.3. В глубокой сверточной сети блоки нижних уровней могут косвенно взаимодействовать с большей частью сети,\n--- Страница 287 ---\n286  Сверточные сети как показано на рис. 9.4. Это дает сети возможность эффективно описывать сложные взаимодействия между многими переменными путем составления из простых строи- тельных блоков, каждый из которых описывает только разреженные взаимодействия. Рис. 9.4  Рецептивное поле блоков в глубоких слоях сверточной сети больше рецептивного поля в слоях, близких к поверхности. Этот эффект усиливается, если сеть включает такие архитектурные особенности, как свертка с шагом (рис. 9.12) или пулинг (раздел 9.3). Это означает, что хотя прямые связи в сверточной сети действительно очень разрежены, блоки в глубоких слоях могут быть косвенно связаны со всем входным изображе- нием или с большей его частью Под разделением параметров понимают, что один и тот же параметр используется в нескольких функциях модели. В традиционной нейронной сети каждый элемент мат рицы весов используется ровно один раз при вычислении выхода слоя. Он умно- жает на один элемент входа, и больше мы к нему никогда не возвращаемся. Вместо употребления термина «разделение параметров» можно сказать, что в сети присут- ствуют связанные веса, поскольку значение веса, примененного к одному входу, связано со значением веса, примененного где-то еще. В сверточной нейронной сети каждый элемент ядра применяется к каждой позиции входа (за исключением, быть может, некоторых граничных пикселей – в зависимости от того, как решено обраба- тывать границу). Разделение параметров означает, что вместо обучения отдельного набора параметров для каждой точки мы должны обучить только один набор. Это не влияет на время прямого распространения – оно по-прежнему имеет порядок O(k×n), – но дополнительно уменьшает требования к объему памяти: достаточно хранить k параметров. Напомним, что k обычно на несколько порядков меньше m. Поскольку величины m и n приблизительно равны, то k практически несущественно по сравнению с m×n. Таким образом, свертка многократно эффективнее умножения матриц с точки зрения требований к памяти и статистической эффективности. Меха- низм разделения параметров наглядно изображен на рис. 9.5. Для иллюстрации практического применения первых двух принципов на рис. 9.6 показано, что разреженная связность и разделение параметров кардинально улучша- ют эффективность линейной функции при обнаружении границ в изображении. В случае свертки специальный вид разделения параметров наделяет слой свой- ством, которое называется эквивариантностью относительно параллельного пере- носа. Говорят, что функция эквивариантна, если при изменении входа выход меня-ется точно так же. Точнее, функция f(x) эквивариантна относительно функции g, Рис. 9.2  Разреженная связность при взгляде снизу. Выделен один вход- ной блок x3 и выходные блоки в слое s, на которые этот блок влияет. (Вверху) Если s образован сверткой с ядром ширины 3, то x3 влияет только на три вы- хода. (Внизу) Если s образован умножением на матрицу, то связность уже не разреженная, поэтому x3 влияет на все выходы Рис. 9.3  Разреженная связность при взгляде сверху. Выделен один выходной блок s3 и выходные блоки в слое x, которые на него влияют. Со- вокупность этих блоков называется рецептивным полем s3. (Вверху) Если s образован сверткой с ядром ширины 3, то на s3 влияют только три входа. (Внизу) Если s образован умножением на матрицу, то связность уже не раз- реженная, поэтому на s3 влияют все входы\n--- Страница 288 ---\nМотивация  287 как показано на рис. 9.4. Это дает сети возможность эффективно описывать сложные взаимодействия между многими переменными путем составления из простых строи- тельных блоков, каждый из которых описывает только разреженные взаимодействия. Рис. 9.4  Рецептивное поле блоков в глубоких слоях сверточной сети больше рецептивного поля в слоях, близких к поверхности. Этот эффект усиливается, если сеть включает такие архитектурные особенности, как свертка с шагом (рис. 9.12) или пулинг (раздел 9.3). Это означает, что хотя прямые связи в сверточной сети действительно очень разрежены, блоки в глубоких слоях могут быть косвенно связаны со всем входным изображе- нием или с большей его частью Под разделением параметров понимают, что один и тот же параметр используется в нескольких функциях модели. В традиционной нейронной сети каждый элемент мат рицы весов используется ровно один раз при вычислении выхода слоя. Он умно- жает на один элемент входа, и больше мы к нему никогда не возвращаемся. Вместо употребления термина «разделение параметров» можно сказать, что в сети присут- ствуют связанные веса, поскольку значение веса, примененного к одному входу, связано со значением веса, примененного где-то еще. В сверточной нейронной сети каждый элемент ядра применяется к каждой позиции входа (за исключением, быть может, некоторых граничных пикселей – в зависимости от того, как решено обраба- тывать границу). Разделение параметров означает, что вместо обучения отдельного набора параметров для каждой точки мы должны обучить только один набор. Это не влияет на время прямого распространения – оно по-прежнему имеет порядок O(k×n), – но дополнительно уменьшает требования к объему памяти: достаточно хранить k параметров. Напомним, что k обычно на несколько порядков меньше m. Поскольку величины m и n приблизительно равны, то k практически несущественно по сравнению с m×n. Таким образом, свертка многократно эффективнее умножения матриц с точки зрения требований к памяти и статистической эффективности. Меха- низм разделения параметров наглядно изображен на рис. 9.5. Для иллюстрации практического применения первых двух принципов на рис. 9.6 показано, что разреженная связность и разделение параметров кардинально улучша- ют эффективность линейной функции при обнаружении границ в изображении. В случае свертки специальный вид разделения параметров наделяет слой свой- ством, которое называется эквивариантностью относительно параллельного пере- носа. Говорят, что функция эквивариантна, если при изменении входа выход меня-ется точно так же. Точнее, функция f(x) эквивариантна относительно функции g, Рис. 9.2  Разреженная связность при взгляде снизу. Выделен один вход- ной блок x3 и выходные блоки в слое s, на которые этот блок влияет. (Вверху) Если s образован сверткой с ядром ширины 3, то x3 влияет только на три вы- хода. (Внизу) Если s образован умножением на матрицу, то связность уже не разреженная, поэтому x3 влияет на все выходы Рис. 9.3  Разреженная связность при взгляде сверху. Выделен один выходной блок s3 и выходные блоки в слое x, которые на него влияют. Со- вокупность этих блоков называется рецептивным полем s3. (Вверху) Если s образован сверткой с ядром ширины 3, то на s3 влияют только три входа. (Внизу) Если s образован умножением на матрицу, то связность уже не раз- реженная, поэтому на s3 влияют все входы\n--- Страница 289 ---\n288  Сверточные сети если f(g(x)) = g(f(x)). В случае свертки, если g – параллельный перенос, или сдвиг входа, то функция свертки эквивариантна относительно g. Пусть, например, функ- ция I определяет яркость в точках с целыми координатами, и пусть g – функция, отображаю щая одну функцию изображения в другую функцию изображения, так что I′ = g(I) – функция изображения, для которой I′(x, y) = I(x – 1, y). Это сдвиг каждого пикселя I на одну позицию вправо. Если применить это преобразование к I, а затем выполнить свертку, то результат будет таким же, как если бы мы сначала применили свертку к I′, а затем преобразование g к результату. При обработке временных рядов это означает, что свертка порождает своего рода временную шкалу, на которой пока-зано время появления различных признаков во входных данных. Рис. 9.5  Разделение параметров. Черными стрелками показаны связи, в которых участвует конкретный параметр в двух разных моделях. (Ввер- ху) Черными стрелками показано использование центрального элемента 3-элементного ядра в сверточной модели. Благодаря разделению пара- метров этот параметр используется для всех элементов входа. (Внизу) Одиночная черная стрелка показывает использование центрального эле-мента матрицы весов в полносвязной модели. Здесь никакого разделения параметров нет, поэтому параметр используется только один раз Если перенести событие на более поздний момент времени во входных данных, то на выходе появится точно такое же его представление, только позже. А при ра- боте с изображениями свертка создает двумерную карту появления определенных признаков во входном изображении. Если переместить объект во входном изображе-нии, то его представление на выходе переместится на такую же величину. Это бывает нужно, когда мы знаем, что некоторая функция от небольшого числа пикселей по-лезна при применении к нескольким участкам входа. Например, в случае обработки изображений полезно обнаруживать границы в первом слое сверточной сети. Одни и те же границы встречаются более-менее везде в изображении, поэтому имеет смысл разделять параметры по всему изображению. Но в некоторых случаях такое глобаль- ное разделение параметров нежелательно. Например, если мы обрабатываем изобра-жения, которые были кадрированы, так чтобы в центре оказалось лицо человека, то,\n--- Страница 290 ---\nМотивация  289 наверное, хотим выделять разные признаки в разных точках – часть сети будет обра- батывать верхнюю часть лица в поисках бровей, а другая часть – искать подбородок в нижней части лица. Рис. 9.6  Эффективность обнаружения границ. Правое изображение получено вычитанием из каждого пикселя исходного изображения зна- чения пикселя слева от него. В результате мы получаем силу всех верти- кальных границ во входном изображении, что бывает полезно для обна-ружения объектов. Высота обоих изображений 280 пикселей. Ширина входного изображения 320 пикселей, а выходного – 319. Это преобразо- вание можно описать как свертку с ядром, содержащим два элемента, оно требует 319 × 280 × 3 = 267 960 операций с плавающей точкой (два умно- жения и одно сложение на каждый выходной пиксель). Если то же самое преобразование выполнять путем перемножения матриц, то потребуется 320 × 280 × 319 × 280, т. е. больше восьми миллиардов элементов матри- цы, так что с точки зрения потребления памяти свертка эффективнее та- кого преобразования в четыре миллиарда раз. При прямом перемножении матриц пришлось бы выполнить свыше 16 миллиардов операций с плаваю- щей точкой, так что и с этой точки зрения свертка примерно в 60 000 раз эффективнее. Конечно, большинство элементов матрицы было бы равно нулю. Если хранить только ненулевые элементы, то в обоих случаях при- шлось бы выполнить примерно одно и то же число операций с плавающей точкой. Но все равно в матрице было бы 2 × 319 × 280 = 178 640 элементов. Свертка – чрезвычайно эффективный способ описания преобразований, в которых одно и то же линейное преобразование многократно применяет- ся к небольшим участкам изображения Свертка не эквивариантна относительно некоторых других преобразований, на- пример масштабирования или поворота. Для обработки таких преобразований нуж-ны другие механизмы. Наконец, существуют типы данных, которые нельзя обработать с помощью ней- ронных сетей, определяемых путем умножения на матрицу фиксированной формы. Свертка позволяет обрабатывать некоторые данные такого рода. Мы вернемся к это- му вопросу в разделе 9.7.\n--- Страница 291 ---\n290  Сверточные сети 9.3. Пулинг Типичный слой сверточной сети состоит из трех стадий (рис. 9.7). На первой стадии слой параллельно выполняет несколько сверток и порождает множество линейных активаций. На второй стадии каждая линейная активация пропускается через нели-нейную функцию активации, например функцию линейной ректификации. Эту ста-дию часто называют детекторной. На третьей стадии используется функция пулинга для дальнейшей модификации выхода слоя. Терминология сложных слоев Терминология простых слоев Сверточный слойСледующий слой Следующий слой Вход слоя Вход слоевСтадия пулинга Слой пулинга Детекторная стадия: нелинейность, например блок линейной ректификацииДетекторный слой: нелинейность, например блок линейной ректификации Стадия свертки: аффинное преобразованиеСлой свертки: аффинное преобразование Рис. 9.7  Компоненты типичного слоя сверточной нейронной сети. Для описания таких слоев применяется двоякая терминология. (Слева) В этой терминологии сверточная сеть рассматривается как небольшой набор от- носительно сложных слоев, каждый из которых имеет много «стадий». При этом существует взаимно однозначное соответствие между ядерными тен-зорами и слоями сети. В этой книге мы в основном придерживаемся такой терминологии. (Справа) В этой терминологии сверточная сеть рассматри- вается как большой набор простых слоев слоев, а каждый шаг обработки считается полноправным слоем. Это означает, что не у каждого «слоя» есть параметры Функция пулинга заменяет выход сети в некоторой точке сводной статистикой близлежащих выходов. Например, операция max-пулинга (Zhou and Chellappa, 1988) возвращает максимальный выход в прямоугольной окрестности. Из других употре- бительных функций пулинга отметим усреднение по прямоугольной окрестности, L2-норму в прямоугольной окрестности и взвешенное среднее с весами, зависящими от расстояния до центрального пикселя. В любом случае пулинг позволяет сделать представление приблизительно инва- риантным относительно малых параллельных переносов входа. Инвариантность от- носительно параллельного переноса означает, что если сдвинуть вход на небольшую\n--- Страница 292 ---\nПулинг  291 величину, то значения большинства подвергнутых пулингу выходов не изменятся. На рис. 9.8 показан пример работы этого механизма. Локальная инвариантность от- носительно параллельного переноса полезна, если нас больше интересует сам факт существования некоторого признака, а не его точное местонахождение. Например, когда мы хотим определить, присутствует ли в изображении лицо, нам не важно по- ложение глаз с точностью до пикселя, нужно только знать, есть ли глаз слева и глаз справа. В других ситуациях важнее сохранить местоположение признака. Например, если мы ищем угловую точку, образованную пересечением двух границ, ориентиро-ванных определенным образом, то необходимо сохранить положение границ настоль-ко точно, чтобы можно было проверить, пересекаются ли они. Стадия пулинга Стадия пулингаДетекторная стадия Детекторная стадия Рис. 9.8  Мax-пулинг привносит инвариантность. (Вверху) Середина вы- ходного слоя сверточной сети. В нижней строке показаны выходы нелиней- ности, а в верхней – выходы max-пулинга с шагом в один пиксель между областями пулинга, каждая из которых имеет ширину три пикселя. (Вверху) Та же самая сеть, сдвинутая вправо на один пиксель. В нижней строке изме- нились все значения, а в верхней – только половина, потому что блоки max- пулинга чувствительны лишь к максимальному значению в своей окрестно- сти, а не точному положению этого значения Пулинг можно рассматривать как добавление бесконечно сильного априорного предположения, что обучаемая слоем функция должна быть инвариантна к малым параллельным переносам. Если это предположение правильно, то оно может сущест-венно улучшить статистическую эффективность сети. Пулинг по пространственным областям порождает инвариантность к параллель- ным переносам, но если он производится по выходам сверток с различными парамет- рами, то признаки могут обучиться, к каким преобразованиям стать инвариантными (см. рис. 9.9).\n--- Страница 293 ---\n292  Сверточные сети Большой отклик от детекторного блока 1Большой отклик от детекторного блока 3Большой отклик от блока пулингаБольшой отклик от блока пулинга Рис. 9.9  Пример обученной инвариантности. Блок, выполняющий пу- линг по нескольким признакам, обученным с разными параметрами, мо- жет обучиться инвариантности к преобразованиям входа. Здесь мы видим набор из трех обученных фильтров и блок max-пулинга, который обучился инвариантности к вращению. Все три фильтра предназначены для рас- познавания рукописной цифры 5. Каждый фильтр настроен на свою ори- ентацию пятерки. Если на входе появляется цифра 5, то соответствующий фильтр распознает ее, что даст большой отклик на детекторный блок. Тогда блок max-пулинга даст большой отклик независимо от того, какой детек-торный блок был активирован. На рисунке показано, как сеть обрабатывает два разных входа, активирующих разные детекторные блоки. В обоих слу- чаях выход блока пулинга примерно одинаков. Этот принцип используется в maxout-сетях (Goodfellow et al., 2013a) и других сверточных сетях. Max- пулинг по пространственной области обладает естественной инвариантно- стью к параллельным переносам; такой многоканальный подход необходим только для обучения другим преобразованиям Поскольку пулинг агрегирует отклики по целой окрестности, количество блоков пулинга можно сделать меньшим, чем количество детекторных блоков, если агреги- ровать статистику по областям, отстоящим друг от друга на k > 1 пикселей. Пример приведен на рис. 9.10. Тем самым повышается вычислительная эффективность сети, поскольку следующему слою предстоит обработать примерно в k раз меньше входов. Если число параметров в следующем слое – функция от размера входа (например, когда следующий слой полносвязный и основан на умножении матриц), то уменьше- ние размера входа также может повысить статистическую эффективность и умень- шить требования к объему памяти для хранения параметров. В большинстве задач пулинг необходим для обработки входов переменного раз- мера. Например, если мы хотим классифицировать изображения разного размера, то код слоя классификации должен иметь фиксированный размер. Обычно это достига-ется за счет варьирования величины шага между областями пулинга, так чтобы слой классификации всегда получал одинаковый объем сводной статистики независимо от размера входа. Так, можно определить финальный слой пулинга в сети, так чтобы он выводил четыре сводных статистических показателя, по одному на каждый квад-рант изображения, вне зависимости от размера самого изображения.\n--- Страница 294 ---\nСвертка и пулинг как бесконечно сильное априорное распределение  293 Рис. 9.10  Пулинг с понижающей передискретизацией. Здесь max-пу- линг используется с пулом ширины 3 и шагом 2 между пулами. В результа- те размер представления уменьшается вдвое, что снижает вычислительную и статистическую нагрузки на следующий слой. Отметим, что размер самой правой области пулинга меньше остальных, но ее все равно необходимо включить, если мы не хотим игнорировать некоторые детекторные блоки Существуют кое-какие теоретические рекомендации по выбору вида пулинга в различных ситуациях (Boureau et al., 2010). Можно также динамически агрегиро- вать признаки, например путем выполнения алгоритма кластеризации в местах инте- ресных признаков (Boureau et al., 2011). При таком подходе получаются различные множества областей пулинга для каждого изображения. Другой подход – обучить единую структуру пулинга и затем применять ее ко всем изображениям (Jia et al., 2012). Пулинг может внести усложнения в некоторые архитектуры нейронных се- тей, где используется нисходящая информация, как, например, машины Больцма-на и автокодировщики. Мы обсудим эти вопросы, когда дойдем до сетей этого типа в части III. Пулинг в сверточных машинах Больцмана представлен в разделе 20.6. Операции квазиобращения над блоками пулинга, необходимые в некоторых диффе- ренцируемых сетях, обсуждаются в разделе 20.10.6. Примеры полных архитектур сети для классификации с использованием свертки и пулинга показаны на рис. 9.11. 9.4. Свертка и пулинг как бесконечно сильное априорное распределение Напомним понятие априорного распределения вероятности, введенное в разде- ле 5.2. Это распределение вероятности параметров модели, в котором закодированы наши предварительные – еще до знакомства с данными – предположения о том, какие модели считать разумными. Априорное распределение может быть сильным или слабым в зависимости от концентрации плотности вероятности. Слабым называется априорное распределе-ние с высокой энтропией, например нормальное распределение с большой диспер- сией. При таком априорном распределении параметры могут сдвигаться в зависи- мости от данных более или менее свободно. У сильного априорного распределения очень низкая энтропия, как, например, у нормального распределения с малой дис- персией. Такое распределение играет более активную роль в определении конечных параметров. В бесконечно сильном априорном распределении вероятность некоторых парамет- ров нулевая, т. е. утверждается, что такие значения параметров запрещены вне зави- симости от того, поддерживаются они данными или нет.\n--- Страница 295 ---\n294  Сверточные сети Результат softmax: вероятности 1000 классов Результат пулинга с шагом 4: 16×16×64Результат умножения матриц: 1000 блоков Результат свертки + ReLU: 64×64×64Результат сериализации в вектор: 16 384 блока Результат пулинга с шагом 4: 64×64×64 Результат свертки + ReLU: 256×256×64 Входное изображение: 256×256×3Результат softmax: вероятности 1000 классов Результат пулинга в области 3×3: 3×3×64Результат умножения матриц: 1000 блоков Результат свертки + ReLU: 64×64×64Результат сериализации в вектор: 576 блоков Результат пулинга с шагом 4: 64×64×64 Результат свертки + ReLU: 256×256×64 Входное изображение: 256×256×3Результат softmax: вероятности 1000 классов Результат пулинга с шагом 4: 16×16×64Результат пулинга усреднением: 1×1×1000 Результат свертки + ReLU: 64×64×64Результат свертки: 16×16×1000 Результат пулинга с шагом 4: 64×64×64 Результат свертки + ReLU: 256×256×64 Входное изображение: 256×256×3 Рис. 9.11  Примеры архитектур для классификации на основе сверточ- ных сетей. Конкретные величины шага и глубины на этом рисунке не сле- дует рассматривать как рекомендации для практического применения; они выбраны так, чтобы рисунок поместился на страницу. Кроме того, реальные сверточные сети часто являются сильно разветвленными, а не цепными, как на этом рисунке. (Слева) Сверточная сеть для обработки изображений фик-сированного размера. После чередования нескольких сверточных и пулин- говых слоев форма тензора сверточной карты признаков меняется, чтобы выстроить все пространственные измерения в один плоский вектор. Далее следует обычный классификатор в виде сети прямого распространения, описанный в главе 6. (В центре) Сверточная сеть для обработки изображе- ний переменного размера, в которой по-прежнему имеется полносвязный участок. В сети применяется операция пулинга с фиксированным числом пулов переменного размера, которая порождает вектор из 576 блоков, по-даваемый на вход полносвязного участка сети. (Справа) Сверточная сеть, в которой вообще нет полносвязного слоя весов. Вместо этого последний сверточный слой выводит по одной карте признаков на каждый класс. Пред- положительно модель обучает карту тому, насколько вероятно появление каждого класса в каждой пространственной области. Единственное значе- ние, получающееся в результате усреднения карты признаков, подается на вход softmax-классификатора в верхнем слое Сверточную сеть можно представлять себе как полносвязную сеть с бесконечно сильным априорным распределением весов. Оно говорит, что веса некоторого скрыто- го слоя должны быть идентичны весам соседнего с ним слоя, но сдвинуты в простран-\n--- Страница 296 ---\nВарианты базовой функции свертки  295 стве. Априорное распределение говорит также, что веса должны быть равны 0 всю- ду, кроме малого рецептивного поля, состоящего из смежных блоков, поставленных в соответствие данному скрытому блоку. Короче говоря, можно считать, что свертка вводит бесконечно сильное априорное распределение вероятности параметров слоя, согласно которому обучаемая данным слоем функция допускает только локальные взаимодействия и эквивариантна относительно параллельных переносов. Аналогично пулинг вводит бесконечно сильное априорное распределение, согласно которому каж-дый блок должен быть инвариантен относительно малых параллельных переносов. Разумеется, реализация сверточной сети как полносвязной сети с бесконечно силь- ным априорным распределением с вычислительной точки зрения была бы неимо- верно расточительной. Но такая интерпретация может пролить свет на механизмы работы сверточных сетей. Одно из ключевых открытий состоит в том, что свертка и пулинг могут стать при- чиной недообучения. Как любое априорное распределение, свертка и пулинг полез- ны, только когда предположения, выраженные этим распределением, достаточно верны. Если в задаче необходимо сохранять точную пространственную информацию, то применение пулинга по всем признакам может увеличить ошибку обучения. Не-которые архитектуры сверточных сетей (Szegedy et al., 2014a) рассчитаны на при-менение пулинга только к части каналов, чтобы получить как признаки с высокой степенью инвариантности, так и признаки, не подверженные недообучению в случае, когда априорное предположение об инвариантности относительно параллельных переносов неверно. Если задача подразумевает включение в состав входных данных информации из очень отдаленных областей, то априорное распределение, ассоции-руемое со сверткой, может оказаться непригодным. Еще одно важное соображение заключается в том, что при эталонном тестиро- вании качества статистического обучения сверточные модели следует сравнивать только с другими сверточными моделями. Модели, в которых свертка не использу- ется, смогут обучиться, даже если мы переставим все пиксели в изображении. Для многих наборов изображений существуют раздельные эталонные тесты для моделей, которые инвариантны относительно перестановок и должны в процессе обучения выявить концепцию топологии, и для моделей, в которые проектировщик заложил знания о пространственных связях. 9.5. Варианты базовой функции свертки При обсуждении свертки в контексте нейронных сетей мы обычно не имеем в виду стандартную операцию дискретной свертки в том смысле, в каком она понимается в математической литературе. Практически используемые функции немного отлича- ются. Ниже мы детально опишем эти различия и выделим некоторые полезные свой- ства функций, применяемых в нейронных сетях. Прежде всего под сверткой в нейронных сетях мы обычно понимаем операцию, состоящую из многих параллельных вычислений свертки. Связано это с тем, что свертка с одним ядром может выделить только один вид признаков, хотя и во многих местах. Обычно мы хотим, чтобы каждый слой сети выделял много разных признаков во многих местах. Кроме того, вход обычно является не просто сеткой вещественных значений, а сеткой векторных наблюдений. Например, каждый пиксель цветного изображения состоит из\n--- Страница 297 ---\n296  Сверточные сети красной, зеленой и синей компонент. В многослойной сверточной сети входом второго слоя является выход первого, который обычно состоит из результатов многих разных сверток в каждой позиции. При работе с изображениями мы обычно интерпретируем вход и выход свертки как трехмерные тензоры, в которых по одному измерению на- ходятся цветовые каналы, а по двум другим – пространственные координаты каналов. Программные реализации обычно работают в пакетном режиме, так что на самом деле используются четырехмерные тензоры, в которых четвертая ось соответствует приме- рам в пакете, но в нашем описании мы для простоты будем эту ось опускать. Поскольку в сверточных сетях свертка обычно применяется к нескольким кана- лам, коммутативность соответствующих операций не гарантируется, даже при ис-пользовании ядра с отражением. Такие многоканальные операции коммутативны, только если число выходных каналов равно числу входных. Предположим, что имеется четырехмерный тензор K, элемент K i, j, k, l которого опре- деляет силу связи между блоком i-го выходного канала и j-го входного канала, когда входной и выходной блоки отстоят друг от друга на k строк и l столбцов. Предполо- жим также, что вход состоит из данных наблюдений V, где элемент Vi, j, k содержит зна- чение i-го канала входного блока на пересечении j-ой строки и k-го столбца. И пусть выход Z имеет такой же формат, как V. Если Z порожден сверткой V со скользящим ядром K без отражения K, то (9.7) где суммирование производится по всем индексам l, m, n, для которых элементы тен- зоров под знаком суммы существуют. В линейной алгебре индексирование массива начинается с 1, что объясняет появление –1 в формуле выше. В таких языках прог- раммирования, как C и Python, индексирование начинается с 0, так что выражение даже упрощается. Для уменьшения стоимости вычислений некоторые положения ядра иногда про- пускают (ценой снижения точности выделения признаков). Мы можем рассматри- вать это как понижающую передискретизацию выхода полной функции свертки. Если мы хотим выбирать только каждый s-ый пиксель в каждом направлении выхода, то можем определить функцию свертки пониженного разрешения c: . (9.8) Будем называть s шагом свертки пониженного разрешения. Можно также опреде- лить разные шаги по каждому направлению движения (см. рис. 9.12). Важное свойство любой реализации сверточной сети – возможность неявно допол- нять нулями вход V, чтобы расширить его. Без этого ширина представления умень- шается на ширину ядра без одного пикселя в каждом слое. Дополнение входа нулями позволяет управлять шириной ядра и размером выхода независимо. Не будь допол- нения, мы были бы вынуждены выбирать между быстрым уменьшением простран-ственной протяженности сети и использованием малых ядер – то и другое значитель- но ограничивает выразительную мощность сети. Пример приведен на рис. 9.13. Заслуживают упоминания три частных случая дополнения нулями. Первый – когда дополнение не используется вовсе, а ядру свертки разрешено занимать только те по- зиции, где ядро целиком умещается внутри изображения. В терминологии MATLAB это называется корректной (valid) сверткой. В таком случае каждый выходной пиксель\n--- Страница 298 ---\nВарианты базовой функции свертки  297 является функцией одного и того же числа входных, поэтому поведение выходных пик- селей несколько более регулярно. Но размер выхода при этом уменьшается на каждом слое. Если ширина входного изображения равна m, а ширина ядра – k, то ширина вы- хода будет равна m – k + 1. Скорость такого сжатия может быть очень велика, если ис- пользуются большие ядра. Поскольку сжатие больше 0, число сверточных слоев в сети ограничено. По мере добавления слоев пространственная протяженность сети рано или поздно снизится до 1× 1, после чего новые слои нельзя считать сверточными. Другой частный случай – дополнение столькими нулями, чтобы размер выхода был равен раз- меру входа. В MATLAB это называется конгруэнтной (same) сверткой. В этом случае сеть может содержать столько сверточных слоев, сколько может поддержать оборудо-вание, поскольку операция свертки не изменяет архитектурных возможностей следую-щего слоя. Однако входные пиксели в окрестности границы оказывают меньшее влия- ние на выходные, чем пиксели, расположенные ближе к центру. Из-за этого граничные пиксели будут недостаточно представлены в модели. Это и послужило основанием для еще одного крайнего случая, называемого в MATLAB полной (full) сверткой, когда до- бавляется столько нулей, чтобы каждый пиксель посещался k раз в каждом направле- нии. В результате размер выходного изображения становится равен m + k – 1. В таком случае выходные пиксели вблизи границы являются функциями меньшего числа вход-ных пикселей, чем пиксели в центре. Из-за этого трудно обучить единственное ядро, которое вело бы себя хорошо во всех позициях сверточной карты признаков. Обычно оптимальная степень дополнения нулями (в терминах верности классификации на тес- товом наборе) лежит между «корректной» и «конгруэнтной» сверткой. СверткаСвертка с шагом Понижающая передискретизацияs1 s1x1 x1z1s2 s2x3 x3z3x2 x2z2s3 s3x5 x5z5x4 x4z4 Рис. 9.12  Свертка с шагом. В этом примере шаг равен 2. (Вверху) Свертка с шагом 2, реализованная в виде одной операции. (Внизу) Свертка с шагом больше 1 пикселя математически эквивалентна свертке с шагом 1, за которой следует понижающая передискретизация. Очевидно, что такой двухэтапный подход вычислительно расточителен, поскольку многие вы-численные значения затем отбрасываются\n--- Страница 299 ---\n298  Сверточные сети Рис. 9.13  Влияние дополнения нулями на размер сети. Рассматривает- ся сверточная сеть с ядром ширины 6 в каждом слое. В этом примере пулинг не используется, поэтому уменьшение размера сети вызвано только самой операцией свертки. (Вверху) В этой сверточной сети нет никакого неявного дополнения нулями. Поэтому ширина представления уменьшается на пять пикселей с каждым слоем. Если ширина входа равна 16 пикселям, то в сети может быть не более трех сверточных слоев, причем по последнему пере- местить ядро невозможно, так что лишь два слоя можно назвать сверточны- ми. Скорость сжатия можно уменьшить, если использовать ядра поменьше, но малые ядра обладают меньшей выразительностью, а сжатие как таковое все равно присутствует. (Снизу) Неявно добавив пять нулей в каждый слой, мы препятствуем сжатию представления. В результате глубина сверточной сети может быть любой. Бывает, что мы хотим использовать не свертку, а локально связные слои (LeCun, 1986, 1989). В таком случае матрица смежности графа нашего МСП не изменяется, но у каждого соединения имеется собственный вес, определяемый шестимерным тензо- ром W. Индексы W следующие: i – выходной канал, j – выходная строка, k – выходной столбец, l – входной канал, m – смещение строки внутри входа, n – смещение столбца внутри входа. Тогда линейная часть локально связного слоя описывается формулой: (9.9) Иногда эту операцию называют неразделяемой сверткой ( unshared convolution), потому что она похожа на дискретную свертку с малым ядром, но без разделения параметров в разных позициях. На рис. 9.14 проведено сравнение локально связной, сверточной и полносвязной сетей.\n--- Страница 300 ---\nВарианты базовой функции свертки  299 Рис. 9.14  Сравнение локальной связности, свертки и полной связности. (Вверху) Локально связный слой с патчем шириной два пикселя. Все ребра помечены разными буквами, т. е. с каждым ребром ассоциирован свой ве- совой параметр. (В центре) Сверточный слой с ядром шириной два пиксе- ля. Связность этой модели точно такая же, как у локально связного слоя. Различие не в том, какие блоки взаимодействуют друг с другом, а в том, как разделяются параметры. В локальном связном слое никакого разделения параметров нет. В сверточном слое два одинаковых же веса повторно ис- пользуются для всего входного слоя, это видно из повторения буквенных меток ребер. (Внизу) Полносвязный слой похож на локально связный в том смысле, что у каждого ребра свой собственный параметр (их слишком мно- го, чтобы расставлять буквы на рисунке). А отличие в том, что в локальном связном слое связность ограничена Локально связные слои полезны, если мы знаем, что каждый признак должен быть функцией небольшого участка пространства, но нет причин полагать, что один и тот же признак должен встречаться во всем пространстве. Например, если нам нужно только определить, изображено ли на картинке лицо, то требуется лишь поискать рот в нижней части изображения. Иногда бывают полезны варианты сверточных или локально связных слоев, в ко- торых на связность наложены дополнительные ограничения, например что каждый выходной канал i должен быть функцией лишь подмножества входных каналов l. Для этого, как правило, связывают первые m выходных каналов только с первыми n вход- ными, следующие m выходных каналов – только со следующими n входными и т. д. (см. рис. 9.15). Поскольку моделируется взаимодействие между небольшим числом каналов, число параметров сети можно уменьшить, а значит, сократить потребление памяти, повысить статистическую эффективность и уменьшить объем вычислений,\n--- Страница 301 ---\n300  Сверточные сети необходимых для прямого и обратного распространений. И всех этих целей мы до- стигаем без уменьшения числа скрытых блоков. Выходной тензор Входной тензорКанальные координаты Пространственные координаты Рис. 9.15  Сверточная сеть, в которой первые два выходных канала свя- заны только с первыми двумя входными каналами, а следующие два выход- ных канала – только со следующими двумя входными Периодическая свертка (tiled convolution) (Gregor and LeCun, 2010a; Le et al., 2010) представляет собой компромисс между сверточным и локально связным слоя- ми. Вместо того чтобы обучать отдельный набор весов в каждой области простран- ства, мы обучаем набор ядер, который затем сдвигаем по пространству как единое целое. Это означает, что в соседних областях фильтры будут разные, как в локально связном слое, но требования к объему памяти для хранения параметров возрастают лишь пропорционально размеру набора ядер, а не как при хранении всей выходной\n--- Страница 302 ---\nВарианты базовой функции свертки  301 карты признаков. На рис. 9.16 проведено сравнение локально связных слоев, перио- дической и стандартной сверток. Рис. 9.16  Сравнение локально связных слоев, периодической свертки и стандартной свертки. Во всех трех случаях при использовании ядра од- ного размера набор связей между блоками один и тот же. На этом рисунке предполагается, что ширина ядра составляет два пикселя. Различие между методами – в разделении параметров. (Вверху) В локально связном слое параметры не разделяются вовсе. Все связи помечены разными буквами, т. е. у каждой связи свой вес. (В центре) В случае периодической свертки имеется набор из t разных ядер. В данном случае t = 2. Ребра первого ядра помечены буквами «a» и «b», а ребра второго – буквами «c» и «d». При сме- щении в выходном слое на один пиксель вправо мы переходим к исполь- зованию другого ядра. Это означает, что, как и в локально связном слое, у соседних выходных блоков параметры разные. Но, в отличие от локально связного слоя, после перебора всех t имеющихся ядер мы снова возвраща- емся к первому. Два выходных блока, разделенных числом шагов, кратным t, разделяют общие параметры. (Внизу) Традиционная свертка эквивалент-на периодической с t = 1. Существует всего одно ядро, которое применяет- ся во всех точках. На рисунке это следует из того, что все ребра помечены буквами «a» и «b» Чтобы определить периодическую свертку алгебраически, рассмотрим шестимер- ный тензор K, два измерения которого соответствуют различным позициям в выход- ной карте. Вместо отдельного индекса для каждой позиции выходной карты индексы будут циклически пробегать множество t различных положений группы ядер в каждом направлении. Если t равно ширине выхода, то мы получаем локально связный слой.\n--- Страница 303 ---\n302  Сверточные сети (9.10) где знак процента обозначает операцию деления по модулю: t%t = 0 , (t + 1)%t = 1 и т. д. Эта формула легко обобщается на различные периоды по каждому направлению. Локально связные слои и слои с периодической сверткой интересно взаимо- действуют с max-пулингом: детекторные блоки таких слоев управляются разными фильтрами. Если эти фильтры обучены обнаруживать различные преобразованные варианты одних и тех же базовых признаков, то блоки max-пулинга оказываются инвариантны относительно обученных преобразований (см. рис. 9.9). В сверточные слои изначально «зашита» инвариантность относительно параллельного переноса. Для реализации сверточной сети обычно необходимы и другие операции, помимо свертки. Для обучения нужно уметь вычислять градиент относительно ядра, если из-вестен градиент относительно выходов. В некоторых простых случаях эту операцию можно выполнить с помощью свертки, но большинство интересных случаев, в т. ч. свертка с шагом 1, не обладает этим свойством. Напомним, что свертка – это линейная операция и потому может быть описана как умножение на матрицу (если предварительно вытянуть входной тензор в плоский вектор). Соответствующая матрица является функцией от ядра свертки. Эта матри-ца разреженная, и каждый элемент ядра копируется в несколько элементов матрицы. Такое представление поможет нам вывести некоторые дополнительные операции, не-обходимые для реализации сверточной сети. Одна из таких операций – умножение на матрицу, транспонированную к матрице, определяемой сверткой. Эта операция нужна для обратного распространения ошиб-ки через сверточный слой, а стало быть, необходима для обучения сверточных се- тей, содержащих более одного скрытого слоя. Она же встречается, когда требуется реконструировать видимые блоки по скрытым (Simard et al., 1992). Реконструкция видимых блоков часто используется в моделях, описанных в третьей части книги: автокодировщики, ограниченные машины Больцмана и разреженное кодирование. Транспонирование свертки необходимо для построения сверточных вариантов таких моделей. Как и операцию градиента относительно ядра, эту операцию над градиентом входа иногда удается выполнить с помощью свертки, но в общем случае требуется реа лизовать третью операцию. Следует соблюдать осторожность при координирова- нии операции транспонирования с прямым распространением. Размер выхода, воз- вращаемого операцией транспонирования, зависит от стратегии дополнения нулями и шага операции прямого распространения, а также от размера выходной карты пря- мого распространения. В некоторых случаях разные размеры входа прямого распро- странения могут давать одинаковый размер выхода, поэтому операции транспониро-вания нужно явно указать размер первоначального входа. Этих трех операций – свертка, обратное распространение от выхода к весам и об- ратное распространение от выхода к входам – достаточно для вычисления всех гради- ентов, необходимых для обучения сверточной сети прямого распространения любой глубины, а также для обучения сверточной сети с функциями реконструкции, осно- ванными на транспонировании свертки. Полный вывод уравнений в общем много- мерном случае с несколькими примерами см. в работе Goodfellow (2010). Чтобы вы могли составить представление о том, как эти уравнения работают, рассмотрим дву- мерный случай с одним примером. Допустим, мы хотим обучить сверточную сеть, в которой имеется свертка с ша- гом s группы ядер K, применяемых к многоканальному изображению V, опреде-\n--- Страница 304 ---\nВарианты базовой функции свертки  303 ленная функцией c(K, V, s), как в формуле (9.8). Предположим, что требуется ми- нимизировать некую функцию потерь J(V, K). На этапе прямого распространения нам нужно будет использовать саму функцию c, чтобы вывести Z, который затем распространяется по остальной части сети и применяется для вычисления функции стои мости J. На этапе обратного распространения мы получим тензор G – такой, что Gi;j;k = (∂/∂Zi, j, k)J(V, K). Для обучения сети нам потребуется вычислить производные по весам в ядре. Для этого можно воспользоваться функцией (9.11) Если это не нижний слой сети, то потребуется также вычислить градиент по V для обратного распространения ошибки. Для этого воспользуемся функцией (9.12) (9.13) Автокодировщики, описанные в главе 14, – это сети прямого распространения, обучен ные копировать вход в выход. Простой пример дает метод главных компонент PCA, который копирует свой вход x в приближенную реконструкцию r, применяя функцию W⏉Wx. В более общих автокодировщиках тоже часто используется умно- жение на транспонированную матрицу весов, как в PCA. Чтобы превратить такие модели в сверточные, мы можем воспользоваться функцией h, которая транспони- рует операцию свертки. Пусть имеются скрытые блоки H в том же формате, что и Z; определим преобразование реконструкции в виде R = h(K, H, s). (9.14) Для обучения автокодировщика получим градиент относительно R в виде тензо- ра E. Для обучения декодера нужно получить градиент относительно K. Он имеет вид g(H, E, s). Для обучения кодера нужен градиент относительно H. Он имеет вид c(K, E, s). Можно также продифференцировать g, используя c и h, но эти операции не нужны для алгоритма обратного распространения в стандартных архитектурах сети. В общем случае для преобразования входов в выходы в сверточном слое исполь- зуются не только линейные операции. К каждому выходу еще прибавляется смеще- ние, и лишь потом применяется нелинейность. Тогда возникает вопрос, как разделить параметры между смещениями. Для локально связных слоев естественно приписать каждому блоку свое смещение, а для периодической свертки – разделять смещения с таким же периодом, как и ядра. В сверточных слоях, как правило, используют одно смещение на выходной канал и разделяют его между всеми позициями в пределах каждой выходной карты. Но если размер входа известен и фиксирован, то можно так- же обучить отдельные смещения в каждой позиции выходной карты. Это несколько снижает статистическую эффективность модели, но позволяет ей корректировать различия между статистиками изображения в разных позициях. Например, если при- меняется неявное дополнение нулями, то детекторные блоки на границе изображения получают меньше информации от входов и могут нуждаться в больших смещениях.\n--- Страница 305 ---\n304  Сверточные сети 9.6. Структурированный выход Сверточные сети можно использовать для вывода многомерного структурированно- го объекта, а не просто для предсказания метки класса в случае классификации или вещественного значения в случае регрессии. Обычно таким объектом является тен- зор, порождаемый стандартным сверточным слоем. Например, модель может порож-дать тензор S, в котором S i; j; k – вероятность того, что входной пиксель в позиции (j, k) принадлежит классу i. Это позволяет модели пометить каждый пиксель изображения и нарисовать точные маски, выделяющие контуры отдельных объектов. Часто возникает проблема из-за того, что выходная плоскость меньше входной, как показано на рис. 9.13. В архитектурах, которые обычно применяются для клас- сификации одного объекта в изображении, уменьшение числа пространственных измерений сети связано прежде всего с использованием слоев пулинга с большим шагом. Чтобы вывести карту примерно такого же размера, как вход, можно вообще отказаться от пулинга (Jain et al., 2007). Другая стратегия – порождать сетку меток более низкого разрешения (Pinheiro and Collobert, 2014, 2015). Наконец, в принципе, можно использовать оператор пулинга с единичным шагом. Одна из стратегий попиксельной пометки изображений – взять какую-нибудь на- чальную гипотезу о метках, а затем уточнять ее, используя взаимодействия между соседними пикселями. Многократное повторение шага уточнения соответствует ис-пользованию одинаковых сверток на каждом этапе с разделением весов между послед- ними слоями глубокой сети (Jain et al., 2007). В результате последовательность вычис- лений, выполняемых соседними сверточными слоями с весами, разделяемыми между слоями, становится специальным видом рекуррентной сети (Pinheiro and Collobert, 2014, 2015). На рис. 9.17 показана архитектура такой рекуррентной сверточной сети. Yˆ(1) H(1) ХV V V W UUUWYˆ(2) H(2)Yˆ(3) H(3) Рис. 9.17  Пример рекуррентной сверточной сети для пометки пикселей. Вхо- дом является тензор изображения X, оси которого соответствуют строкам, столб- цам и каналам (красный, зеленый, синий) изображения. Цель – построить тензор меток Yˆ, содержащий распределение вероятности меток каждого пикселя. Оси этого тензора соответствуют строкам, столбцам и классам. Вместо того чтобы выводить Yˆ за один присест, рекуррентная сеть итеративно уточняет оценку Yˆ, используя предыдущую оценку как исходные данные для вычисления новой. Для каждого приближения к оценке используются одни и те же параметры, количество уточнений может быть любым. На каждом шаге используется тензор сверточных ядер U для вычисления скрытого представления входного изображения. Ядерный тензор V используется для порождения оценки меток при заданных скрытых зна- чениях. На всех шагах, кроме первого, ядра W сворачиваются с Yˆ для вычисления входа скрытого слоя. На первом шаге этот член заменяется нулем. Поскольку пара-метры на всех шагах одинаковы, это пример рекуррентной сети в смысле главы 10\n--- Страница 306 ---\nТипы данных  305 Получив предсказания для всех пикселей, мы можем применить различные мето- ды для последующей обработки предсказания, чтобы сегментировать изображение на отдельные участки (Briggman et al., 2009; Turaga et al., 2010; Farabet et al., 2013). Общая идея в том, что большие группы смежных пикселей предположительно ассо- циированы с одной и той же меткой. С помощью графических моделей можно опи- сать вероятностные связи между соседними пикселями. Или обучить сверточную сеть максимизировать аппроксимацию целевой функции графической модели (Ning et al., 2005; Thompson et al., 2014). 9.7. Типы данных Данные, используемые в сверточной сети, обычно состоят из нескольких каналов, каждый из которых содержит наблюдение какой-то величины в определенной точке пространства или в определенный момент времени. Примеры типов данных разной размерности с разным числом каналов приведены в табл. 9.1. Таблица 9.1. Примеры форматов данных в сверточных сетях Одноканальные Многоканальные 1D Аудиосигналы: ось свертки соответствует времени. Мы дискретизируем время и измеряем амплитуду сигнала один раз в каждом временном интервалеДанные анимации «скелета»: анима-ции трехмерного отрисовываемого компьютером персонажа генериру-ются путем изменения положения «скелета» со временем. В каждый момент положение скелета описы-вается углами сочленения костей в каждом суставе. Каждый канал дан-ных, подаваемых на вход сверточной сети, представляет угол относительно одной оси одного сустава 2D Аудиоданные, предварительно обработанные с по-мощью преобразования Фурье. Мы можем преоб-разовать аудиосигнал в двумерный тензор, строки которого соответствуют частотам, а столбцы – мо-ментам времени. Применение свертки по времени делает модель эквивариантной относительно вре-менных сдвигов. Применение свертки по оси частот делает модель эквивариантной относительно частоты, т. е. одна и та же мелодия в разных октавах порождает на входе сети одно и то же представле-ние, но с разной высотойДанные цветного изображения: один канал содержит красные пиксели, другой – зеленые, третий – синие. Ядро свертки сдвигается по двум осям изображения, обеспечивая эквивари-антность относительно параллельного переноса в обоих направлениях 3D Объемные данные: типичным источником таких данных являются технологии медицинской интро-скопии, например компьютерной томографииДанные цветного видео: одна ось со-ответствует времени, другая – высоте кадра, третья – ширине кадра Пример применения сверточной сети к обработке видео см. в работе Chen et al. (2010). До сих пор мы рассматривали только случай, когда все примеры в обучающем и тес товом наборах данных имели одинаковые пространственные размеры. Но свер- точные сети способны также обрабатывать входные данные с разной пространствен- ной протяженностью. Такие данные вообще невозможно представить с помощью тра- диционных нейронных сетей, основанных на умножении матриц. И это убедительная причина использовать сверточные сети даже тогда, когда вычислительная стоимость и переобучение не составляют проблемы.\n--- Страница 307 ---\n306  Сверточные сети Рассмотрим, к примеру, собрание изображений, в котором у всех изображений раз- ная ширина и высота. Не понятно, как можно смоделировать такие входные данные с помощью матрицы весов фиксированного размера. А со сверткой никаких проблем не возникает; ядро просто применяется разное число раз в зависимости от размера входа, и выход операции свертки масштабируется соответственно. Свертку можно рассматривать как умножение на матрицу; одно и то же ядро индуцирует дважды блочно-циркулянтные матрицы разного размера, зависящего от размера входа. Иног- да не только вход, но и выход сети может иметь разный размер, например если мы хотим сопоставить метку класса каждому входному пикселю. В этом случае ниче- го специально проектировать не нужно. А бывает и так, что сеть должна порождать выход фиксированного размера, например если мы хотим сопоставить одну метку класса всему изображению. Тогда следует предпринять дополнительные действия, например вставить слой пулинга, в котором области агрегирования масштабируются пропорционально размеру входа, чтобы количество выходов пулинга было фиксиро-ванным. Примеры такой стратегии показаны на рис. 9.11. Отметим, что использование свертки для обработки входных данных переменного размера имеет смысл, только если переменность размера вызвана тем, что вход со-держит разный объем данных наблюдений одной и той же сущности: аудиозаписи разной продолжительности, космические снимки разной ширины и т. д. Свертка не имеет смысла, если размер входных данных изменяется, потому что включены раз-нородные наблюдения. Например, если обрабатываются заявления о поступлении в колледж и признаками являются оценки в аттестате и результаты экзаменов, но не все поступающие сдают экзамены, то бессмысленно сворачивать одни и те же веса с признаками, соответствующими оценкам и результатам экзаменов. 9.8. Эффективные алгоритмы свертки В современных приложениях сверточных сетей часто участвуют сети, содержащие более миллиона блоков. Для работы с ними необходимы эффективные реализации, задействующие средства распараллеливания вычислений (см. раздел 12.1). Но во многих случаях работу можно ускорить, выбрав подходящий алгоритм свертки. Свертка эквивалентна переводу входа и ядра в частотную область с помощью пре- образования Фурье, поточечному перемножению двух сигналов и возврату во времен- ную область с помощью обратного преобразования Фурье. При определенном размере задачи это может оказаться быстрее наивной реализации дискретной свертки в лоб. Если d-мерное ядро можно представить в виде внешнего произведения d векторов, по одному на каждое измерение, то ядро называется сеперабельным. Для сепарабель- ных ядер наивная свертка неэффективна. Она эквивалентна композиции d одномер- ных сверток с каждым из этих векторов. Это гораздо быстрее вычисления d-мерной свертки с их внешним произведением. Кроме того, для представления ядра в виде векторов требуется меньше параметров. Если ядро состоит из w элементов в каждом направлении, то для наивной многомерной свертки потребуется время O(w d) и столь- ко же места в памяти для хранения параметров, тогда как для сеперабельной свертки нужно время и память порядка O(w×d). Разумеется, не всякую свертку можно пред- ставить подобным образом. Поиск более быстрых способов вычислить свертку точно или приближенно, не принося в жертву верности модели, – область активных исследований. Даже мето-\n--- Страница 308 ---\nСлучайные признаки и признаки, обученные без учителя  307 ды, улучшающие эффективность одного лишь прямого распространения, уже полез- ны, потому что в коммерческих системах обычно больше ресурсов расходуется не на обуче ние, а на развертывание сети. 9.9. Случайные признаки и признаки, обученные без учителя Обычно самой дорогостоящей частью обучения сверточной сети является обучение признаков. Выходной слой, как правило, обходится относительно недорого, потому что ему на вход подается небольшое число признаков, прошедших несколько слоев пулинга. Если производится обучение с учителем методом градиентного спуска, то на каждом шаге необходимо выполнить полный цикл прямого и обратного распростра- нений по всей сети. Один из способов уменьшить стоимость обучения сверточной сети – использовать признаки, для которых не применялось обучение с учителем. Есть три основные стратегии получения сверточных ядер без обучения с учите- лем. Первый – просто инициализировать случайным образом. Второй – спроекти- ровать вручную, настроив каждое ядро на обнаружение границ определенной ори-ентации или в определенном масштабе. Наконец, можно обучать ядра без учителя. Например, в работе Coates et al. (2011) кластеризация методом k средних применена к малым патчам изображения, а затем каждый обученный центроид использовался в качестве ядра свертки. В части III мы опишем много других подходов к обучению без учителя. Обучение признаков без учителя позволяет определять их отдельно от слоя классификации, занимающего верхнее место в архитектуре. Следовательно, можно выделить признаки для всего обучающего набора только один раз, по суще-ству построив новый обучающий набор для последнего слоя. Тогда обучение послед-него слоя часто оказывается задачей выпуклой оптимизации в предположении, что этот слой реализует логистическую регрессию, метод опорных векторов или что-то подобное. Случайные фильтры нередко работают на удивление хорошо в сверточных сетях (Jarrett et al., 2009; Saxe et al., 2011; Pinto et al., 2011; Cox and Pinto, 2011). В работе Saxe et al. (2011) показано, что слои, состоящие из свертки, за которой следует пулинг, естественно становятся частотно-избирательными и инвариантными относительно параллельного переноса, если им приписать случайные веса. Авторы предлагают сле-дующий дешевый способ выбора архитектуры сверточной сети: сначала оценить ка-чество нескольких архитектур, обучив только последний слой, а затем взять лучшую архитектуру и обучить ее целиком, применив более дорогой способ. Промежуточное решение – обучить признаки, но не использовать методов, требую- щих полного прямого и обратного распространений на каждом шаге вычисления градиента. Как и в многослойных перцептронах, мы применяем жадное послойное предобучение, чтобы обучить первый слой отдельно, затем выделяем все признаки только из первого слоя, потом обучаем отдельно второй слой, зная эти признаки, и т. д. В главе 8 мы описали, как выполняется жадное послойное предобучение с учителем, а в части III обобщим эту идею на жадное послойное предобучение, применяя в каж-дом слое критерий, не требующий учителя. Канонический пример жадного послой-ного предобучения сверточной модели дает сверточная глубокая сеть доверия (Lee et al., 2009). Сверточные сети дают возможность продвинуть стратегию предобуче ния на шаг дальше, чем было возможно в многослойных перцептронах. Вместо обуче ния\n--- Страница 309 ---\n308  Сверточные сети всего сверточного слоя за раз мы можем обучить модель небольшого патча, как сдела- но в работе Coates et al. (2011) с применением метода k средних. Затем параметры этой обученной на патче модели можно использовать для определения ядер сверточного слоя. Это означает, что для обучения сверточной сети можно применить обучение без учителя, даже не используя в процессе обучения свертку. При таком подходе можно обучать очень большие модели, а стоимость вычисления будет высока только на этапе вывода (Ranzato et al., 2007b; Jarrett et al., 2009; Kavukcuoglu et al., 2010; Coates et al., 2013). Эта идея была очень популярна с 2007 по 2013 год, когда размеченные наборы данных были невелики, а вычислительные ресурсы ограничены. Сегодня большин- ство сверточных сетей обучают в режиме чистого обучения с учителем, производя на каждой итерации полное прямое и обратное распространения по всей сети. Как и в других подходах к предобучению без учителя, трудно разделить причины некоторых достоинств этой методики. Предобучение без учителя может как обеспе-чить частичную регуляризацию, по сравнению с обучением с учителем, так и просто дать возможность обучать гораздо более масштабные архитектуры вследствие сниже-ния вычислительной стоимости правила обучения. 9.10. Нейробиологические основания сверточных сетей Сверточные сети – пожалуй, самый яркий пример успешного применения биотех- нологического искусственного интеллекта. Хотя на них оказали влияние и многие другие научные дисциплины, некоторые ключевые принципы были почерпнуты из нейробиологии. История сверточных сетей начинается с нейробиологических экспериментов, поставленных задолго до создания соответствующих компьютерных моделей. Ней-рофизиологи Давид Хубель и Торстен Визель в течение нескольких лет совместно установили большинство основных фактов, касающихся работы зрительной систе-мы млекопитающих (Hubel and Wiesel, 1959, 1962, 1968). За свои достижения они были отмечены Нобелевской премией. Их открытия, оказавшие огромное влияние на современные модели глубокого обучения, были основаны на регистрации актив-ности отдельных нейронов в мозге кошек. Они наблюдали, как нейроны реагируют на изображения, проецируемые точно на определенные участки экрана, расположен-ного перед кошкой. Важнейшее открытие состояло в том, что нейроны первичных зрительных центров сильнее реагируют на очень специфические зрительные паттер-ны, например точно ориентированные полоски, и гораздо слабее – на все остальные паттерны. Их работа помогла охарактеризовать многие аспекты функционирования мозга, выходящие за рамки этой книги. С точки зрения глубокого обучения, нас интересует в основном упрощенная, схематическая картина. И в этой упрощенной картине мы сосредоточимся на области мозга, которая на- зывается зоной V1, или первичной зрительной корой. Это первая область мозга, ко- торая начинает значимую обработку зрительной информации. Не вдаваясь в детали, скажем, что изображение формируется благодаря попаданию в глаз света, который стимулирует сетчатку, светочувствительный орган, составляющий внутреннюю обо-лочку глаза. Нейроны сетчатки выполняют простую предобработку изображения,\n--- Страница 310 ---\nНейробиологические основания сверточных сетей  309 но не слишком сильно изменяют способ его представления. Затем изображение по зрительному нерву поступает в область мозга, которая называется латеральным ко- ленчатым телом. Главная интересующая нас задача обоих этих анатомических обра-зований – передать сигнал из глаза в зону V1, расположенную на затылке. Слой сверточной сети улавливает три свойства зоны V1:1) зона V1 организована в виде пространственной карты. Она имеет двумерную структуру, повторяющую структуру изображения на сетчатке. Так, свет, падаю-щий на верхнюю половину сетчатки, воздействует только на соответствующую половину зоны V1. Сверточная сеть улавливает это свойство, поскольку ее при-знаки определены в терминах двумерных карт; 2) зона V1 состоит из большого числа простых клеток. Активность клетки мож- но до некоторой степени охарактеризовать линейной функцией изображения в малом пространственно локализованном рецептивном поле. Детекторные блоки сверточной сети призваны имитировать именно эти свойства простых клеток; 3) в зоне V1 имеется также много сложных клеток. Они реагируют на признаки, похожие на детектируемые простыми клетками, но инвариантны относительно небольших изменений в положении признаков. Отсюда берут начало пулинго- вые блоки сверточных сетей. Сложные клетки инвариантны также относитель-но некоторых изменений освещения, которые невозможно уловить с помощью простого агрегирования по пространственным областям. Эти виды инвариант-ности стали причиной некоторых стратегий межканального пулинга в сверточ- ных сетях, например maxout-блоков (Goodfellow et al., 2013a). Хотя мы знаем в основном о зоне V1, общее мнение склоняется к тому, что те же базовые принципы применимы и к другим частям зрительной системы. В нашем упрощенном представлении базовая стратегия детектирования, сопровождаемая пулингом, снова и снова применяется по мере продвижения вглубь мозга. Пройдя через многие анатомические уровни мозга, мы наконец обнаруживаем клетки, кото-рые реагируют на специфические концепции и инвариантны относительно многих преобразований входной информации. Эти клетки получили название «бабушкиных клеток» 1, напоминающее о том, что может существовать нейрон, который активиру- ется, когда человек видит изображение своей бабушки, вне зависимости от того, рас-положено оно справа или слева в поле зрения, содержит только увеличенное лицо или всю фигуру, ярко освещено или находится в тени и т. д. Доказано, что такие бабушкины клетки действительно существуют в мозге чело- века, в области, которая называется медиальной височной долей (Quiroga et al., 2005). Ученые проверяли, какие нейроны реагируют на фотографии известных личностей. Обнаружился так называемый «нейрон Холли Берри», который активируется кон-цепцией этой актрисы. Этот нейрон возбуждается, когда человек видит фотографию Холли Берри, рисунок Холли Берри или даже текст со словами «Холли Берри». Разуме ется, в самой Холли Берри нет ничего особенного; другие нейроны реагируют на присутствие Билла Клинтона, Дженнифер Энистон и т. д. Нейроны медиальной височной доли несколько более общие, чем современные сверточные сети, которые не могут автоматически обобщаться для идентификации 1 Официальное русскоязычное название — «нейроны графических объектов», или «аффе- рентно-инвариантные нейроны объектов». – Прим. перев.\n--- Страница 311 ---\n310  Сверточные сети человека или объекта, увидев его имя или название. Ближайшим аналогом последне- го слоя признаков сверточной сети является область мозга, называемая инферотем- поральной корой (IT). При рассматривании объекта информация попадает сначала на сетчатку, проходит через латеральное коленчатое тело в зону V1, затем в V2, потом в V4 и, наконец, в IT. Это происходит в течение первых 100 мс после попадания объ- екта в поле зрения. Если человек получает возможность смотреть на объект дольше, то информация начинает течь в обратном направлении, т. к. мозг использует нисходя- щую обратную связь, чтобы обновить активации в областях нижних уровней. Но если прервать взгляд и понаблюдать только за частотой пульсации в результате первых 100 мс, отведенных в основном на активацию прямой связи, то зона IT оказывается похожей на сверточную сеть. Сверточные сети могут предсказать частоту пульсации IT и работают аналогично человеку (с его временными ограничениями) при решении задач распознавания объектов (DiCarlo, 2013). Вместе с тем существует много различий между сверточными сетями и зритель- ной системой млекопитающих. Некоторые из них хорошо известны компьютерным нейробиологам, но выходят за рамки книги. Другие пока неизвестны, потому что на многие вопросы о зрительной системе млекопитающих еще нет ответов. Приведем лишь краткий перечень. У человеческого глаза очень низкое разрешение всюду, кроме небольшого пят-на, называемого центральной ямкой, которая видит область размером при- мерно с ноготь большого пальца на расстоянии вытянутой руки. Нам кажется, что мы видим всю сцену с высокой разрешающей способностью, но на самом деле это иллюзия, создаваемая подсознательной частью мозга, которая сшива-ет много фрагментов малых областей. Большинство сверточных сетей полу-чает на входе большие фотографии высокого разрешения. Человеческий мозг вынуждает глаза совершить несколько быстрых скачкообразных движений (саккад) для рассматривания самых выделяющихся или относящихся к задаче частей сцены. Включение аналогичных механизмов внимания в модели глубо- кого обучения – направление активных исследований. В контексте глубокого обучения механизмы внимания добились наибольшего успеха при обработке естественных языков (см. раздел 12.4.5.1). Было разработано несколько моде-лей зрения с механизмами, аналогичными центральной ямке, но пока они не могут претендовать на роль доминирующего подхода (Larochelle and Hinton, 2010; Denil et al., 2012). Зрительная система человека интегрирована с другими органами чувств, на- пример слухом, а также такими факторами, как наше настроение и мысли. Сверточные сети пока относятся только к зрению. Зрительная система человека отвечает далеко не только за распознавание объектов. Она способна понимать целые сцены, включающие много объектов и связей между ними, и умеет обрабатывать сложную трехмерную геометриче- скую информацию, без чего наше тело не могло бы взаимодействовать с окру- жающим миром. Были попытки применить сверточные сети к решению таких задач, но пока эти исследования пребывают в зачаточном состоянии. Даже такие простые области мозга, как зона V1, сильно зависят от обратной связи с более высокими уровнями. Применению обратной связи в нейронных сетях посвящено много работ, но пока с ее помощью не удалось достичь су- щественного улучшения.\n--- Страница 312 ---\nНейробиологические основания сверточных сетей  311 Хотя частота пульсации в зоне IT отражает примерно ту же информацию, что признаки сверточной сети, не ясно, насколько похожи промежуточные вычис- ления. Вероятно, в мозгу используются совершенно другие функции актива- ции и пулинга. Активацию отдельного нейрона вряд ли можно хорошо оха- рактеризовать откликом одного линейного фильтра. Недавняя модель зоны V1 включает четыре квадратичных фильтра для каждого нейрона (Rust et al., 2005). Вообще, наше схематичное разделение на «простые» и «сложные» клет- ки может отражать несуществующее различие; возможно, что простые и слож- ные клетки – это один и тот же вид клеток, но их «параметры» допускают бес- конечную градацию поведения – от «простого» до «сложного». Отметим также, что нейробиология мало что говорит о том, как обучать сверточ- ные сети. Структуры моделей с разделением параметров между несколькими прост- ранственными областями восходят еще к ранним коннекционистским моделям зрения (Marr and Poggio, 1976), но в этих моделях не использовались современные алгоритмы обратного распространения и градиентного спуска. Так, неокогнитрон (Fukushima, 1980) включал большинство архитектурных элементов современной сверточной сети, но опирался на алгоритм послойной кластеризации без учителя. В работе Lang and Hinton (1988) впервые использовалось обратное распростране- ние для обучения нейронных сетей с временной задержкой ( time-delay neural net- work – TDNN). В современной терминологии TDNN – это одномерная сверточная сеть в применении к временным рядам. Применение обратного распространения в та- ких моделях не основано ни на каких нейробиологических наблюдениях, и некото- рые ученые считают его биологически неправдоподобным. На волне успеха обучения TDNN на основе обратного распространения в работе LeCun et al. (1989) была разра- ботана современная сверточная сеть путем применения того же алгоритма обучения к двумерным сверткам изображений. До сих пор мы говорили, что простые клетки приблизительно линейны и изби- рательны к некоторым признакам, что сложные клетки в большей степени нели- нейны и приобретают инвариантность относительно некоторых преобразований признаков, найденных простыми клетками, и что наличие нескольких уровней, чередующих избирательность и инвариантность, возможно, приводит к бабуш- киным клеткам, распознающим конкретные явления. Мы еще точно не описали, что могут обнаруживать эти индивидуальные клетки. В глубокой нелинейной сети трудно понять функции отдельных клеток. Простые клетки первого уровня про-анализировать легче, потому что их отклик описывается линейной функцией. В ис- кусственной нейронной сети мы можем просто показать изображение ядра свертки и увидеть, на что реагирует соответствующий канал сверточного слоя. В биологи- ческой нейронной сети у нас нет доступа к самим весам. Вместо этого мы подводим электрод к нейрону, помещаем несколько примеров белого шума перед сетчаткой животного и регистрируем, какие примеры приводят к возбуждению нейрона. За- тем мы подгоняем к этим откликам линейную модель, чтобы получить аппроксима- цию весов нейронов. Этот подход, получивший название обратной корреляции (Ringach and Shapley, 2004), показывает, что веса большинства клеток зоны V1 описываются функциями Габора. Функция Габора описывает вес в точке двумерного изображения. Можно считать изображение функцией координат на двумерной плоскости, I(x, y). Анало- гично простую клетку можно рассматривать как выборку из изображения во множе-\n--- Страница 313 ---\n312  Сверточные сети стве позиций, определяемую множествами абсцисс 𝕏 и ординат 𝕐, с последующим применением весов, которые также являются функциями позиции, w(x, y). Тогда от- клик простой клетки на изображение имеет вид (9.15) Точнее говоря, w(x, y) – функция Габора: w(x, y, α, βx, βy, f, ϕ, x0, y0, τ) = α exp(–βxx′2 – βy y′2)cos(fx′ + ϕ), (9.16) где x′ = (x – x0)cos(τ) + (y – y0)sin(τ) (9.17) и y′ = –(x – x0)sin(τ) + (y – y0)cos(τ). (9.18) Здесь α, βx, βy, f, ϕ, x0, y0 и τ – параметры, определяющие свойства функции Габора. На рис. 9.18 приведено несколько примеров функций Габора с разными значениями параметров. Параметры x0, y0 и τ определяют систему координат. Для получения x′ и y′ из x и y производятся параллельный перенос и поворот. Точнее, простая клетка реагирует на признаки изображения с центром в точке (x0, y0) и на изменения яркости при движе- нии вдоль прямой, повернутой на угол τ радиан относительно горизонтальной оси. Рис. 9.18  Функция Габора с различными параметрами. Белым цветом обозначен большой положительный вес, черным – большой отрицательный вес, а серым фоном – нулевой вес. (Слева) Функции Габора с различными параметрами, описывающими систему координат: x0, y0 и τ. Каждой функ- ции Габора в этой сетке соответствуют значения x0 и y0, пропорциональные ее позиции в сетке, а τ выбрано так, чтобы фильтр Габора бы чувствителен к направлению, исходящему из центра сетки. На двух остальных графиках x0, y0 и τ равны нулю. (В центре) Функции Габора с разными значениями параметров гауссианы βx и βy. Функции расположены в порядке возраста- ния ширины (убывания βx) при движении по сетке слева направо и в поряд- ке возрастания высоты (убывания βy) при движении сверху вниз. На двух остальных графиках значения β фиксированы и равны ширине изображе- ния, умноженной на 1.5. (Справа) Функции Габора с различными парамет- рами синусоиды f и ϕ. При движении по сетке сверху вниз возрастает f, а при движении слева направо возрастает ϕ. На двух остальных графиках ϕ = 0, а f в 5 раз больше ширины изображения\n--- Страница 314 ---\nНейробиологические основания сверточных сетей  313 Функция w, рассматриваемая как функция от x′ и y′, реагирует на изменение ярко- сти вдоль оси x′. Она является произведением двух важных сомножителей: функции Гаусса и косинуса. Первый сомножитель α exp(–βxx′2 – βyy′2) можно рассматривать как вентиль, гарантирующий, что простая клетка будет реагировать только на значе- ния в окрестности точки с нулевыми координатами x′ и y′, иными словами, вблизи центра рецептивного поля клетки. Масштабный коэффициент α задает абсолютную величину отклика простой клетки, а параметры βx и βy определяют скорость спадания рецептивного поля. Множитель cos(fx ′ + ϕ) определяет реакцию простых клеток на изменение яркости вдоль оси x ′. Параметр f – частота косинусоиды, а ϕ – сдвиг фазы. Собирая все вместе, можно сказать, что это схематичное представление означает, что простая клетка реагирует на определенную пространственную частоту яркости в определенном направлении и в определенном месте. Возбуждение простой клетки максимально, если сигнал яркости в изображении имеет такую же фазу, как веса. Это происходит, когда изображение яркое в области положительности весов и темное – в области отрицательности. Торможение простых клеток максимально, когда сигнал яркости находится в противофазе с весами – изображение темное там, где веса по- ложительны, и яркое – там, где веса отрицательны. Схематичное представление сложной клетки состоит в том, что она вычисля- ет норму L 2 двумерного вектора, содержащего отклики двух простых клеток: c(I) = = Важный частный случай – когда совпадают все параметры s1 и s0, кроме ϕ, а ϕ задан так, что сдвиг фазы s1 и s0 равен четверти периода. В этом случае s0 и s1 образуют квадратурную пару. Так определенная сложная клетка реагирует, когда взвешенное гауссово изображение I(x, y)exp(–βxx′2 – βyy′2) содержит высокоампли- тудный синусоидальный сигнал с частотой f в направлении τ вблизи точки (x0, y0), независимо от сдвига фазы. Иными словами, сложная клетка инвариантна относи- тельно небольших параллельных переносов изображения в направлении τ и инвер- тирования изображения (замены черного на белый и наоборот). Самые поразительные аналогии между нейробиологией и машинным обучением связаны с визуальным сравнением признаков, найденных в результате обучения мо- делей, с теми, что обрабатываются зоной V1. В работе Olshausen and Field (1996) показано, что простой алгоритм обучения без учителя, разреженное кодирование, обучает признаки с рецептивными полями, напоминающими поля простых клеток. С тех пор было обнаружено, что самые разные алгоритмы статистического обучения обучают признаки с габороподобными функциями при применении к естественным изображениям. Сюда входит и большинство алгоритмов глубокого обучения, кото- рые обучают эти признаки в первом слое. На рис. 9.19 показано несколько примеров. Поскольку существует так много разных алгоритмов обучения детекторов границ, трудно определенно утверждать, что некий конкретный алгоритм является «правиль-ной» моделью мозга, исходя только из обучаемых им признаков (хотя, безуслов но, можно считать плохим знаком, если алгоритм не обучает какой-то детектор границ при применении к естественным изображениям). Эти признаки – важная составная часть статистической структуры естественных изображений, и восстановить их по- зволяют разные подходы к статистическому моделированию. Обзор состояния дел в области статистики естественных изображений имеется в работе Hyvä rinen et al. (2009).\n--- Страница 315 ---\n314  Сверточные сети Рис. 9.19  Многие алгоритмы машинного обучения обучают признаки для обнаружения любых границ или границ определенного цвета в естест- венных изображениях. Такие детекторы напоминают функции Габора, при- нимающие участие в работе первичной зрительной коры. (Слева) Веса, обученные алгоритмом обучения без учителя (разреженное кодирование типа Spike-and-Slab) в применении к небольшим участкам изображения. (Справа) Сверточные ядра, обученные с учителем первым слоем свер- точной maxout-сети. Соседние пары фильтров управляют одним и тем же maxout-блоком 9.11. Сверточные сети и история глубокого обучения Сверточные сети сыграли важную роль в истории глубокого обучения. Это яркий пример успешного применения идей, высказанных в процессе изучения человеческо- го мозга, к машинному обучению. Заодно они оказались одними из первых глубоких моделей хорошего качества, задолго до того как глубокие модели вообще были при-знаны жизнеспособными. Сверточные сети были также одними из первых нейронных сетей, нашедших применение в важных коммерческих приложениях, и до сих пор они остаются в первых рядах коммерческих применений глубокого обучения. Напри- мер, в 1990-е годы исследовательская группа по нейронным сетям в компании AT&T разработала сверточную сеть для распознавания чеков (LeCun et al., 1998b). К концу 1990-х годов эта система была развернута компанией NEC и распознавала 10% всех чеков в США. Позже несколько систем распознавания символов и рукописных текс- тов на основе сверточных сетей было развернуты корпорацией Microsoft (Simard et al., 2003). Подробнее об этих и других современных применениях сверточных сетей см. главу 12. Более полный обзор истории сверточных сетей до 2010 года см. в работе LeCun et al. (2010). Системы на основе сверточных сетей выигрывали много конкурсов. Современ- ный всплеск коммерческого интереса к глубокому обучению начался, когда система, описанная в работе Krizhevsky et al. (2012), победила в конкурсе по распознаванию объектов ImageNet, но сверточные сети побеждали и в других соревнованиях по ма- шинному обучению и компьютерному зрению задолго до того, хотя это и не вызывало такого ажиотажа.\n--- Страница 316 ---\nСверточные сети и история глубокого обучения  315 Сверточные сети были одними из первых работающих глубоких сетей, обученных с применением обратного распространения. Не вполне понятно, почему сверточные сети добились успеха там, где сети общего назначения с обратным распространением потерпели неудачу. Может быть, дело в том, что сверточные сети вычислительно эф- фективнее полносвязных сетей, поэтому было проще ставить эксперименты и опти- мизировать реализацию и гиперпараметры. Кроме того, чем больше сеть, тем легче ее обучить. На современном оборудовании большие полносвязные сети дают неплохие результаты на многих задачах даже при использовании наборов данных и функций активации, которые были доступны и популярны в те времена, когда считалось, что от полносвязных сетей невозможно добиться хорошего качества. Возможно также, что основные барьеры на пути к успеху нейронных сетей были чисто психологическо- го свойства (специалисты-практики не ожидали от них хорошего качества, а потому не особенно старались их использовать). Как бы то ни было, нам повезло, что свер-точные сети хорошо работали несколько десятков лет тому назад. Во многих смыслах они передали эстафету остальным разделам глубокого обучения и проложили путь принятию нейронных сетей в целом. Сверточные сети позволяют специализировать нейронные сети для работы с дан- ными, имеющими четко выраженную сеточную топологию, и хорошо масштабиро- вать такие модели к задачам очень большого размера. Особенно успешным этот под- ход оказался в применении к двумерным изображениям. Для обработки одномерных последовательных данных следует обратиться к еще одной эффективной специализа- ции: рекуррентным нейронным сетям. Ими мы и займемся в следующей главе.",
      "debug": {
        "start_page": 283,
        "end_page": 316
      }
    },
    {
      "name": "Глава 10. Моделирование последовательностей: рекуррентные и рекурсивные сети 316",
      "content": "--- Страница 317 --- (продолжение)\nГлава 10 Моделирование последовательностей: рекуррентные и рекурсивные сети Рекуррентные нейронные сети, или РНС (Rumelhart et al., 1986a), – это семейство нейронных сетей для обработки последовательных данных. Если сверточная сеть предназначена для обработки сетки значений X типа изображения, то рекуррент- ная нейронная сеть предназначена для обработки последовательности значений x (1), …, x(τ). Если сверточная сеть легко масштабируется на изображения большой ши- рины и высоты, а некоторые сети даже могут обрабатывать изображения перемен- ного размера, то рекуррентная сеть масштабируется на гораздо более длинные по-следовательности, чем было бы практически возможно для неспециализированных нейронных сетей. Большинство рекуррентных сетей способно также обрабатывать последовательности переменной длины. Для перехода от многослойных сетей к рекуррентным мы воспользуемся одной из ранних идей машинного обучения и статистического моделирования, появившей- ся еще в 1980-е годы: разделение параметров между различными частями модели. Разделение параметров позволяет применить модель к примерам различной формы (в данном случае – длины) и выполнить для них обобщение. Если бы для каждого временного индекса были отдельные параметры, то мы не смогли бы ни обобщить модель на длины последовательностей, не встречавшиеся на этапе обучения, ни рас-пространить статистическую силу на последовательности разной длины и на разные моменты времени. Такое разделение особенно важно, если некоторая часть инфор-мации может встречаться в нескольких местах последовательности. Например, рас- смотрим два предложения: «Я ездил в Непал в 2009 году» и «В 2009 году я ездил в Непал». Когда мы просим модель прочитать каждое предложение и выделить год, в котором рассказчик ездил в Непал, мы ожидаем получить 2009 вне зависимости от того, находится интересующая нас информация в шестом или во втором слове. Пред- положим, что мы обучили сеть прямого распространения обрабатывать предложе-ния фиксированной длины. В традиционной полносвязной сети были бы отдельные параметры для каждого входного признака, поэтому потребовалось бы обучать всем\nГлава 10 Моделирование последовательностей: рекуррентные и рекурсивные сети Рекуррентные нейронные сети, или РНС (Rumelhart et al., 1986a), – это семейство нейронных сетей для обработки последовательных данных. Если сверточная сеть предназначена для обработки сетки значений X типа изображения, то рекуррент- ная нейронная сеть предназначена для обработки последовательности значений x (1), …, x(τ). Если сверточная сеть легко масштабируется на изображения большой ши- рины и высоты, а некоторые сети даже могут обрабатывать изображения перемен- ного размера, то рекуррентная сеть масштабируется на гораздо более длинные по-следовательности, чем было бы практически возможно для неспециализированных нейронных сетей. Большинство рекуррентных сетей способно также обрабатывать последовательности переменной длины. Для перехода от многослойных сетей к рекуррентным мы воспользуемся одной из ранних идей машинного обучения и статистического моделирования, появившей- ся еще в 1980-е годы: разделение параметров между различными частями модели. Разделение параметров позволяет применить модель к примерам различной формы (в данном случае – длины) и выполнить для них обобщение. Если бы для каждого временного индекса были отдельные параметры, то мы не смогли бы ни обобщить модель на длины последовательностей, не встречавшиеся на этапе обучения, ни рас-пространить статистическую силу на последовательности разной длины и на разные моменты времени. Такое разделение особенно важно, если некоторая часть инфор-мации может встречаться в нескольких местах последовательности. Например, рас- смотрим два предложения: «Я ездил в Непал в 2009 году» и «В 2009 году я ездил в Непал». Когда мы просим модель прочитать каждое предложение и выделить год, в котором рассказчик ездил в Непал, мы ожидаем получить 2009 вне зависимости от того, находится интересующая нас информация в шестом или во втором слове. Пред- положим, что мы обучили сеть прямого распространения обрабатывать предложе-ния фиксированной длины. В традиционной полносвязной сети были бы отдельные параметры для каждого входного признака, поэтому потребовалось бы обучать всем\n--- Страница 318 ---\nРазвертка графа вычислений  317 правилам языка отдельно в каждой позиции в предложении. А в рекуррентной ней- ронной сети одни и те же веса разделяются между несколькими временными шагами. Родственная идея – применить свертку к одномерной временной последователь- ности. Такой сверточный подход лежит в основе нейронных сетей с временной за- держкой (Lang and Hinton, 1988; Waibel et al., 1989; Lang et al., 1990). Операция сверт- ки позволяет сети разделять параметры во времени, но является «мелкой». На выходе свертки получается последовательность, каждый член которой – функция от неболь- шого числа соседних членов входной последовательности. Идея разделения парамет-ров проявляется в применении одного и того же ядра свертки на каждом временном шаге. В рекуррентных сетях разделение параметров происходит по-другому. Каждый выходной член – функция предыдущих выходных членов и порождается с помощью применения одного и того же правила обновления к предыдущим членам. Такая ре- куррентная формулировка дает возможность разделять параметры в очень глубоком графе вычислений. Для простоты изложения будем считать, что РНС воздействует на последователь- ность векторов x (t) с индексом временного шага t в диапазоне от 1 до τ. На практике рекуррентные сети обычно применяются к мини-пакетам таких последовательностей с разной длиной последовательности τ для каждого элемента мини-пакета. Для прос- тоты обозначений мы опускаем индексы мини-пакетов. Кроме того, индекс времен-ного шага необязательно буквально соответствует течению времени в реальном мире. Иногда это просто позиция внутри последовательности. РНС можно также применять к двумерным пространственным данным типа изображений, а если речь идет о дан- ных, в которых участвует время, то в сети могут существовать связи, ведущие назад во времени, при условии что вся последовательность известна до передачи ее сети. В этой главе мы обобщим идею графа вычислений, включив в него циклы. Циклы представляют влияние текущего значения переменной на ее же значение на будущем временном шаге. С помощью таких графов вычислений можно определять рекур- рентные нейронные сети. Затем мы опишем различные способы построения, обуче-ния и использования рекуррентных нейронных сетей. За дополнительными сведениями о рекуррентных нейронных сетях отсылаем чи- тателя к книге Graves (2012). 10.1. Развертка графа вычислений Граф вычислений – это формальный способ описать структуру множества вычисле- ний, например необходимых для отображения входов и параметров на выходы и по- терю. Общее введение в эту тему приведено в разделе 6.5.1. А сейчас мы объясним идею развертки (unfolding) рекурсивного или рекуррентного вычисления в граф вы- числений с повторяющейся структурой, обычно соответствующей цепочке событий. Развертка такого графа приводит к разделению параметров между структурными элементами глубокой сети. Например, рассмотрим классическую форму динамической системы : s(t) = f(s(t–1); θ), (10.1) где s(t) называется состоянием системы. Выражение (10.1) рекуррентное, потому что определение s в момент t ссылается на то же самое определение в момент t – 1.\n--- Страница 319 ---\n318  Моделирование последовательностей: рекуррентные и рекурсивные сети Для конечного числа временных шагов τ граф можно развернуть, применив это определение τ – 1 раз. Например, если развернуть выражение (10.1) для τ = 3 шагов, то получим: s(3) = f(s(2); θ) (10.2) = f(f(s(1); θ); θ). (10.3) После такой развертки путем повторного применения определения получается выражение, не содержащее рекурсии. Такое выражение можно представить тради- ционным ациклическим ориентированным графом вычислений. Развернутый граф вычислений выражений (10.1) и (10.3) показан на рис. 10.1. Рис. 10.1  Классическая динамическая система, описываемая выра- жением (10.1), в виде развернутого графа вычислений. Каждая вершина представляет состояние в некоторый момент t, а функция f отображает со- стояние в момент t на состояние в момент t + 1. Одни и те же параметры (значение θ, параметризующее f) используются на всех временных шагах В качестве другого примера рассмотрим динамическую систему, управляемую внешним сигналом x(t): s(t) = f(s(t–1), x(t); θ). (10.4) Теперь состояние содержит информацию обо всей прошлой последовательности. Рекуррентные нейронные сети можно строить разными способами. Как почти лю- бую функцию можно рассматривать как нейронную сеть прямого распространения, так и практически любую рекуррентную функцию можно рассматривать как рекур- рентную нейронную сеть. Во многих рекуррентных нейронных сетях используется уравнение (10.5) или аналогичное для задания значений скрытых блоков. Чтобы под-черкнуть, что состояние – это на самом деле скрытые блоки сети, перепишем уравне- ние (10.4), используя для представления состояния переменную h: h (t) = f(h(t–1), x(t); θ). (10.5) Такая сеть показана на рис. 10.2; в типичных РНС есть дополнительные архитек- турные особенности, например выходные слои, которые читают информацию из со-стояния h, чтобы сделать предсказание. Когда рекуррентную сеть обучают решать задачу, в которой требуется предсказы- вать будущее по прошлому, сеть обычно обучается использовать h (t) как сводку от- носящихся к задаче аспектов последовательности входных данных, предшествующей моменту t. В общем случае в сводке по необходимости утрачивается часть инфор- мации, потому что она отображает последовательность произвольной длины (x(t), x(t–1), x(t–2), …, x(2), x(1)) на вектор фиксированной длины h(t). В зависимости от крите- рия обуче ния некоторые аспекты прошлой последовательности могут запоминаться в сводке с большей точностью, чем остальные. Например, если РНС используется для статистического моделирования языка, как правило, для предсказания следующего слова по известным предыдущим, то достаточно сохранить только информацию, не-\n--- Страница 320 ---\nРазвертка графа вычислений  319 обходимую для предсказания остатка предложения. Самая трудная ситуация склады- вается, когда мы хотим, чтобы вектор h(t) был достаточно полным для приближенного восстановления входной последовательности, как в автокодировщиках (глава 14). Развернуть Рис. 10.2  Рекуррентная сеть без выходов. Эта сеть просто обрабаты- вает информацию из входа x, включая ее в состояние h, которое передает- ся дальше во времени. (Слева) Принципиальная схема. Черный квадратик обозначает задержку на один временной шаг . (Справа) Та же сеть в виде развернутого графа вычислений, в котором каждая вершина ассоциирова- на с одним моментом времени Уравнение (10.5) можно изобразить двумя способами. Первый способ – нарисо- вать диаграмму, содержащую по одному узлу для каждой компоненты, которая могла бы существовать в физической реализации модели, например в биологической ней- ронной сети. В этом случае сеть определяет схему, которая содержит физические де- тали и работает в режиме реального времени, а ее текущее состояние может оказывать влия ние на будущее; этот вариант изображен в левой части рис. 10.2. В этой главе черный квадратик на принципиальной схеме сети означает, что взаимодействие име-ет место с задержкой на один временной шаг, т. е. происходит переход из состояния в момент t в состояние в момент t + 1. Другой способ изобразить РНС – нарисовать развернутый граф вычислений, в котором каждая компонента представлена многими переменными состояния, по одной на временной шаг. Каждая переменная на каж-дом временном шаге изображается в виде отдельной вершины графа вычислений, как в правой части рис. 10.2. Разверткой мы называем операцию, которая отображает принципиальную схему в граф вычислений с повторяющимися частями. Размер раз- вернутого графа зависит от длины последовательности. Мы можем представить развернутое рекуррентное выражение после t шагов функ- цией g (t): h(t) = g(t)(x(t), x(t–1), x(t–2), …, x(2), x(1)) (10.6) = f(h(t–1), x(t); θ). (10.7) Функция g(t) принимает на входе всю прошлую последовательность (x(t), x(t–1), x(t–2), …, x(2), x(1)) и порождает текущее состояние, но развернутая рекуррентная структура позволяет представить g(t) в виде многократного применения функции f. Таким об- разом, процесс развертки дает два важных преимущества: 1) независимо от длины последовательности размер входа обученной модели всегда один и тот же, поскольку он описывается в терминах перехода из одного состояния в другое, а не в терминах истории состояний переменной длины; 2) одну и ту же функцию перехода f с одними и теми же параметрами можно ис- пользовать на каждом шаге.\n--- Страница 321 ---\n320  Моделирование последовательностей: рекуррентные и рекурсивные сети Эти два фактора позволяют обучить одну модель f, которая действует на всех вре- менных шагах и для последовательностей любой длины, не прибегая к обучению отдельных моделей g(t) для каждого временного шага. Обучение единственной раз- деляемой модели открывает возможность обобщения на такие длины последователь- ности, которые не встречались в обучающем наборе, и позволяет оценивать модель при наличии гораздо меньшего числа обучающих примеров, чем понадобилось бы без разделения параметров. Как у рекуррентного, так и у развернутого графа есть свои достоинства. Рекуррент- ный граф лаконичен, развернутый дает явное описание всех вычислений. Кроме того, развернутый граф иллюстрирует идею протекания информации во времени вперед (вычисление выходов и потерь) и назад (вычисление градиентов), поскольку явно содержит путь, по которому течет информация. 10.2. Рекуррентные нейронные сети Вооружившись механизмами развертки графов и разделения параметров, мы можем перейти к проектированию разнообразных рекуррентных нейронных сетей. Вот несколько важных паттернов проектирования таких сетей: рекуррентные сети, порождающие выход на каждом временном шаге и имею- щие рекуррентные связи между скрытыми блоками (рис. 10.3); рекуррентные сети, порождающие выход на каждом временном шаге и имею- щие рекуррентные связи только между выходами на одном временном шаге и скрытыми блоками на следующем (рис. 10.4); рекуррентные сети с рекуррентными связями между скрытыми блоками, ко- торые читают последовательность целиком, а затем порождают единственный выход (рис. 10.5). На рис. 10.3 изображен достаточно репрезентативный пример, к которому мы не раз будем возвращаться в этой главе. Рекуррентная нейронная сеть на рис. 10.3 и уравнение (10.8) универсальны в том смысле, что любая функция, вычислимая машиной Тьюринга, может быть вычислена и такой рекуррентной сетью конечного размера. Результат можно прочитать из РНС после выполнения числа шагов, асимптотически линейно зависящего от числа времен-ных шагов машины Тьюринга и от длины входной последовательности (Siegelmann and Sontag, 1991; Siegelmann, 1995; Siegelmann and Sontag, 1995; Hyotyniemi, 1996). Функции, вычислимые машиной Тьюринга, дискретны, и потому эти результаты от- носятся к точной реализации функции, а не к аппроксимациям. Когда РНС исполь- зуется как машина Тьюринга, она принимает на входе двоичную последовательность, а ее выходы можно дискретизировать для получения двоичного результата. В таких предположениях можно вычислить любую функцию с помощью одной конкретной РНС конечного размера (в работе Siegelmann and Sontag [1995] используется РНС с 886 блоками). «Входом» машины Тьюринга является спецификация вычисляемой функции, поэтому той же сети, которая моделирует машину Тьюринга, достаточно для решения всех задач. Теоретическая РНС, применяемая в доказательстве, умеет моделировать неограниченный стек, представляя его активации и веса рациональны- ми числами неограниченной точности. Теперь выведем уравнения прямого распространения для РНС, изображенной на рис. 10.3. На этом рисунке не показана конкретная функция активации для скрытых\n--- Страница 322 ---\nРекуррентные нейронные сети  321 блоков. Будем предполагать, что это гиперболический тангенс. Кроме того, на рисун- ке точно не указана форма выхода и функции потерь. Будем предполагать, что выход дискретный, как если бы РНС применялась для предсказания слов или символов. Естественный способ представления дискретных величин – рассматривать выход как ненормированные логарифмические вероятности каждого возможного значения дискретной величины. Тогда на этапе постобработки можно применить операцию softmax и получить вектор yˆ нормированных вероятностей. Прямое распространение начинается с задания начального состояния h (0). Затем для каждого временного шага от t = 1 до t = τ применяем следующие уравнения обновления: a(t) = b +Wh(t–1) + Ux(t) (10.8) h(t) = tanh(a(t)) (10.9) o(t) = c + Vh(t) (10.10) yˆ(t) = softmax(o(t)), (10.11) Развернуть Рис. 10.3  Граф вычислений потерь при обучении рекуррентной сети, которая отображает входную последовательность значений x в соответ- ствующую выходную последовательность значений o. Функция потерь L из- меряет, насколько далеко каждый элемент o отстоит от соответствующей метки y. В случае применения к выходам функции softmax можно предпо- лагать, что o – ненормированные логарифмические вероятности. Внутри функция L вычисляет yˆ = softmax(o) и сравнивает эту величину с меткой y. В РНС имеются связи между входным и скрытым слоями, параметризован- ные матрицей весов U, рекуррентные связи между скрытыми блоками, па- раметризованные матрицей весов W, и связи между скрытым и выходным слоями, параметризованные матрицей весов V. Уравнение (10.8) опреде- ляет прямое распространение в этой модели. (Слева) РНС и ее функция потерь, представленные в виде рекуррентных связей. (Справа) То же в виде развернутого во времени графа вычислений, в котором каждая вершина ассоциирована с одним моментом времени\n--- Страница 323 ---\n322  Моделирование последовательностей: рекуррентные и рекурсивные сети где параметрами являются векторы смещения b и c, а также матрицы весов U, V и W соответственно для связей между входным и скрытым слоями, между скрытым и вы- ходным слоями и между скрытыми блоками. Это пример рекуррентной сети, которая отображает входную последовательность на выходную той же длины. Полная потеря для данной входной последовательности x в совокупности с последовательностью меток y равна сумме потерь по всем временным шагам. Например, если L(t) – отрица- тельное логарифмическое правдоподобие y(t) при условии x(1), …, x(t), то L({x(1), …, x(τ)}, {y(1), …, y(τ)}) (10.12) (10.13) (10.14) Развернуть Рис. 10.4  РНС, в которой единственным видом рекурсии является об- ратная связь между выходным и скрытым слоями. На каждом временном шаге t вход обозначен xt, активации скрытого слоя – h(t), выходы – o(t), мет- ки – y(t), а потеря – L(t). (Слева) Принципиальная схема. (Справа) Развер- нутый граф вычислений. Такая РНС менее мощная (способна выразить меньшее множество функций), чем РНС из семейства на рис. 10.3. РНС, показанная на рис. 10.3, может поместить любую информацию о прошлом в скрытое представление h и передать h в будущее. РНС на этом рисунке обучена помещать конкретное выходное значение в o, и o – единственная информация, которую разрешено передавать в будущее. Не существует прямых горизонтальных связей, исходящих из h. Предыдущий h связан с настоящим только косвенно – с помощью порожденных им предсказаний. Если размерность вектора o не слишком велика, то в нем обычно отсут- ствует какая-то важная информация о прошлом. Поэтому такая РНС менее мощная, но зато ее легче обучить, потому что каждый временной шаг можно обучать отдельно от всех остальных, благодаря чему возможно в большей степени распараллелить обучение (см. раздел 10.2.1)\n--- Страница 324 ---\nРекуррентные нейронные сети  323 где pmodel(y(t) | {x(1), …, x(t)}) берется из элемента y(t) выходного вектора модели yˆ(t). Вы- числение градиента этой функции потерь относительно параметров – дорогая опе- рация. Для вычисления градиента необходимо выполнить прямое распространение, двигаясь слева направо по развернутому графу на рис. 10.3, а затем обратное распро- странение, двигаясь справа налево по тому же графу. Время работы имеет порядок O(τ), и его нельзя уменьшить за счет распараллеливания, потому что граф прямого распространения принципиально последовательный: каждый временной шаг можно обсчитать только после завершения предыдущего. Состояния, вычисленные во вре-мя прямого прохода, необходимо хранить до повторного использования на обратном проходе, поэтому объем потребляемой памяти также имеет порядок O(τ). Алгоритм обратного распространения, применяемый к развернутому графу и имеющий слож- ность O(τ), называется обратным распространением во времени (back-propagation through time – BPTT) и будет подробно рассмотрен в разделе 10.2.2. Таким образом, сеть с рекурсией между скрытыми блоками является очень мощной, но дорогой для обучения. Существует ли альтернатива? 10.2.1. Форсирование учителя и сети с рекурсией на выходе Сеть, в которой имеются только рекуррентные связи между выходными блоками на одном временном шаге и скрытыми блоками на следующем (рис. 10.4), является строго менее мощной, потому что ей недостает рекуррентных связей между скрыты-ми блоками. Так, с ее помощью нельзя смоделировать универсальную машину Тью- ринга. Поскольку в сети нет рекуррентных связей между скрытыми блоками, необхо- димо, чтобы выходные блоки запоминали всю ту информацию о прошлом, которую сеть будет использовать для предсказания будущего. Поскольку выходные блоки Рис. 10.5  Развернутая во времени рекуррентная нейронная сеть с единственным выходом в конце последовательности. Такую сеть можно использовать для агрегирования последовательности и порождения пред- ставления фиксированного размера, подаваемого на вход следующего этапа обработки. В самом конце может быть сравнение с меткой (как по- казано на рисунке), но можно также получить градиент o (t) посредством об- ратного распространения от последующих модулей\n--- Страница 325 ---\n324  Моделирование последовательностей: рекуррентные и рекурсивные сети явно обуча ются совпадению с метками обучающего набора, то маловероятно, что они запомнят нужную информацию о прошлой истории входов, – разве что пользова- тель знает, как описать полное состояние системы, и включает эти сведения в состав выходных меток обучающего набора. Но у исключения рекуррентных связей между скрытыми блоками есть и преимущество – для любой функции потерь, основанной на сравнении предсказания в момент t с меткой в момент t, все временные шаги пол- ностью независимы. Следовательно, обучение можно распараллелить и вычислять градиент для каждого шага t изолированно. Нет нужды вычислять сначала выход для предыдущего временного шага, потому что обучающий набор уже содержит идеаль- ное значение этого выхода. Модели, в которых имеются рекуррентные связи, идущие от выходов обратно в мо- дель, можно обучить методом форсирования учителя (teacher forcing). Форсирова- ние учителя – процедура, берущая начало в критерии максимального правдоподобия, когда во время обучения модель получает истинную метку y(t) в качестве входа в мо- мент t + 1. Как это происходит, можно видеть, рассмотрев последовательность с двумя временными шагами. Критерий условного максимального правдоподобия имеет вид: log p(y(1), y(2) | x(1), x(2)) (10.15) = log p(y(2) | y(1), x(1), x(2)) + log p(y(1) | x(1), x(2)). (10.16) Здесь мы видим, что в момент t = 2 модель обучается максимизировать условную вероятность y(2) при известной до этого момента последовательности x и предыду- щем значении y из обучающего набора. Таким образом, критерий максимального правдоподобия говорит, что на этапе обучения мы должны подать обратно на вход не собственный выход модели, а значения меток, описывающие, каким должен быть правильный выход. Это показано на рис. 10.6. Исходным обоснованием форсирования учителем было желание избежать обрат- ного распространения во времени в моделях, где нет связей между скрытыми блока- ми. Его можно применять и к моделям, где такие связи есть, при условии что имеют- ся связи между выходом на одном временном шаге и значениями, вычисленными на следующем шаге. Но коль скоро скрытые блоки становятся функцией предшествую-щих временных шагов, необходим алгоритм BPTT. Поэтому некоторые модели мож-но обучать, применяя и форсирование учителя, и BPTT. Недостаток строгого метода форсирования учителя проявляется, если впослед- ствии предполагается использовать сеть в режиме с разомкнутой обратной связью, когда выходы сети (или примеры, выбранные из выходного распределения) подают-ся обратно на вход. В таком случае входные данные, которые сеть видит в процес- се обуче ния, могут сильно отличаться от того, что она видит на этапе тестирования. Один из способов сгладить эту проблему – обучать как на форсированных, так и на свободных входах, например выдавая в качестве предсказания правильную метку че- рез несколько шагов в будущем с использованием развернутых рекуррентных путей между выходом и входом. Таким образом, можно обучить сеть принимать во внимание входные условия (скажем, те, что она генерирует сама в свободном режиме), которые не встречались во время обучения, и отображать состояние обратно в такое, которое заставит сеть генерировать правильные выходы после нескольких шагов. Еще один подход (Bengio et al., 2015b) сократить разрыв между входами, предъявляемыми на этапе обучения и на этапе тестирования, – случайно выбирать между подачей на вход\n--- Страница 326 ---\nРекуррентные нейронные сети  325 сгенерированных или фактических значений. В этом подходе используется стратегия обучения по плану, с тем чтобы постепенно увеличивать долю сгенерированных зна- чений на входе. На этапе обучения На этапе тестирования Рис. 10.6  Форсирование учителя – метод обучения, применимый к РНС, в которых есть связи между выходом и скрытым состоянием на следующем временном шаге. (Слева) На этапе обучения мы подаем истинный выход y(t), взятый из обучающего набора, на вход h(t+1). (Справа) После того как модель развернута, истинный выход, вообще говоря, неизвестен. В таком случае мы аппроксимируем истинный выход y(t) выходом модели o(t) и по- даем этот выход обратно в модель 10.2.2. Вычисление градиента в рекуррентной нейронной сети Вычисление градиента в рекуррентной нейронной сети не вызывает трудностей. Нужно просто применить обобщенный алгоритм обратного распространения из раз- дела 6.5.6 к развернутому графу вычислений. Никаких специальных алгоритмов не нужно. Градиенты, полученные в результате обратного распространения, можно за- тем использовать в сочетании с любым универсальным градиентным методом для обучения РНС. Чтобы составить интуитивное представление о поведении алгоритма BPTT, при- ведем пример вычисления градиентов для уравнений РНС выше (уравнение 10.8 и 10.12). В нашем графе вычислений имеются параметры U, V, W, b и c, а также по- следовательность вершин, индексированных временем t: x (t), h(t), o(t) и L(t). Для каждой вершины N мы должны рекурсивно вычислить градиент ∇NL, зная градиенты, вычис- ленные в вершинах, следующих за ней в графе. Рекурсия начинается с вершин, непо- средственно предшествующих окончательной потере: (10.17)\n--- Страница 327 ---\n326  Моделирование последовательностей: рекуррентные и рекурсивные сети Предполагается, что выходы o(t) используются в качестве аргумента функции softmax для получения вектора вероятностей выходов yˆ. Предполагается также, что функция потерь – это отрицательное логарифмическое правдоподобие истинной метки y(t) при известных к этому моменту входах. Градиент ∇o(t)L по выходам в момент t для всех i, t имеет вид: (10.18) Мы движемся в направлении от конца последовательности к началу. В последний момент времени τ у h(τ) есть только один потомок o(τ), поэтому вычислить градиент просто: ∇h(τ)L = V⏉∇o(τ)L. (10.19) Затем можно совершать итерации назад во времени для обратного распростране- ния градиентов от t = τ – 1 до t = 1. Заметим, что потомками h(t) (для t < τ) являются o(t) и h(t+1). Следовательно, градиент равен (10.20) (10.21) где diag(1 – (h(t+1))2) – диагональная матрица с элементами 1 – (hi(t+1))2. Это якобиан функции гиперболического тангенса, ассоциированный со скрытым блоком i в мо- мент t + 1. Получив градиенты по внутренним вершинам графа вычислений, мы можем затем получить градиенты по вершинам параметров. Поскольку параметры разделяются между временными шагами, следует аккуратно подходить к обозначениям аналити- ческих операций с участием этих переменных. В нужных нам уравнениях использу- ется метод bprop из раздела 6.5.6, который вычисляет вклад в градиент одного ребра графа вычислений. Но оператор ∇W f, применяемый в математическом анализе, при- нимает во внимание вклад W в значение f, вносимый всеми ребрами графа вычисле- ний. Для разрешения этой неоднозначности мы введем фиктивные переменные W(t), определенные как копии W, только каждая W(t) используется лишь на временном шаге t. Тогда ∇W(t) f можно использовать для обозначения вклада весов на шаге t в гра- диент. В этой нотации градиенты по остальным параметрам имеют вид (10.22) (10.23) (10.24) (10.25)\n--- Страница 328 ---\nРекуррентные нейронные сети  327 (10.26) (10.27) . (10.28) Нам не нужно вычислять градиент по x(t) для обучения, потому что среди его пред- ков в графе вычислений, определяющем потерю, нет параметров. 10.2.3. Рекуррентные сети как ориентированные графические модели В разработанном выше примере рекуррентной сети в роли потери L(t) выступала пе- рекрестная энтропия между метками y(t) и выходами o(t). Как и в сетях прямого рас- пространения, в рекуррентной сети, в принципе, можно использовать почти любую функцию потерь. Выбирать ее следует в зависимости от задачи. Как и в сети прямого распространения, мы обычно хотим интерпретировать выход РНС как распределение вероятности, а для определения потерь используем ассоциированную с этим распре- делением перекрестную энтропию. Например, среднеквадратическая ошибка – это потеря в виде перекрестной энтропии, ассоциированной с нормальным распределе- нием выхода с нулевым средним и единичной дисперсией, – как и в сети прямого распространения. Когда в качестве целевой функции обучения используется логарифмическое прав- доподобие, как в уравнении (10.12), мы обучаем РНС оценивать условное распреде- ление следующего элемента последовательности y(t) при условии прошлых входов: log p(y(t) | x(1), …, x(t)) (10.29) или если модель включает связи между выходом на одном временном шаге и на сле- дующем за ним, то: log p(y(t) | x(1), …, x(t), y(1), …, y(t–1)). (10.30) Разложение совместного распределения последовательности значений y в серию одношаговых предсказаний вероятности – это один из способов запомнить полное совместное распределение во всей последовательности. Если мы подаем прошлые значения y в качестве входов, обусловливающих предсказание на следующем шаге, то в ориентированной графической модели не будет ребер, ведущих из любого y (i) в прошлом в текущий y(t). В этом случае выходы y условно независимы при усло- вии последовательности значений x. Если же мы подаем фактические значения y (не предсказания, а наблюдаемые или сгенерированные значения) обратно в сеть, то ори- ентированная графическая модель содержит ребра из всех значений y(i) в прошлом в текущее значение y(t). В качестве простого примера рассмотрим случай, когда РНС моделирует только последовательность скалярных случайных величин 𝕐 = {y(1), …, y(τ)} без дополнитель- ных входов x. Входом на временном шаге t является выход шага t – 1. Тогда РНС определяет ориентированную модель над переменными y. Параметризуем совмест-ное распределение этих наблюдений, применив цепное правило условных вероятно-стей (формула 3.6):\n--- Страница 329 ---\n328  Моделирование последовательностей: рекуррентные и рекурсивные сети (10.31) где при t = 1 справа от вертикальной черты, конечно, ничего нет. При такой модели от- рицательное логарифмическое правдоподобие множества значений {y(1), …, y(τ)} имеет вид (10.32) где L(t) = –log P(y(t) = y(t) | y(t–1), y(t–2), …, y(1)). (10.33) Ребра графической модели показывают, какие переменные прямо зависят от дру- гих переменных. Многие графические модели стремятся повысить статистическую и вычислительную эффективность, опуская ребра, которым не соответствуют силь- ные взаимодействия. Например, часто принимают марковское предположение о том, что графическая модель должна содержать только ребра, ведущие из {y(t–k), …, y(t–1)} в y(t), а не ребра, описывающие всю историю. Но в некоторых случаях мы полагаем, что на следующий элемент последовательности должны оказывать влияние все прошлые входы. РНС полезны, когда мы считаем, что распределение y (t) может зависеть от зна- чения y(i) из отдаленного прошлого способом, не отраженным во влиянии y(i) на y(t–1). Интерпретировать РНС как графическую модель можно, в частности, рассматри- вая сеть как определение графической модели, имеющей вид полного графа, спо-собного представить прямые зависимости между любой парой значений y. Модель с такой структурой показана на рис. 10.7. Интерпретация РНС как полного графа основана на игнорировании скрытых блоков h (t), которые исключаются из модели. Рис. 10.7  Полносвязная графическая модель последовательности y(1), y(1), …, y(t), …. Любое прошлое наблюдение y(i) может повлиять на условное распределение некоторых y(t) (для t > i) при условии предыдущих значений. Параметризация графической модели в точном соответствии с эти графом (как в формуле 10.6) может оказаться крайне неэффективной, посколь- ку число входов и параметров для каждого следующего элемента после- довательности будет постоянно возрастать. РНС, обеспечивающая такую же связность, но при этом эффективную параметризацию, показана на рис. 10.8\n--- Страница 330 ---\nРекуррентные нейронные сети  329 Интереснее взглянуть на структуру графической модели РНС, получающуюся, если рассматривать скрытые блоки h(t) как случайные величины1. Включение скрытых блоков в графическую модель показывает, что РНС дает эффективную параметри- зацию совместного распределения наблюдений. Предположим, что мы представили совместное распределение дискретных значений в виде таблицы – массива, содер- жащего по одному элементу для каждой возможной комбинации значений, равному вероятности этой комбинации. Если y может принимать k значений, то в табличном представлении будет O(k τ) параметров. Для сравнения – благодаря разделению чис- ло параметров РНС как функция длины последовательности имеет порядок O(1). Число параметров РНС можно изменять для управления емкостью модели, но оно не обязано увеличиваться вместе с длиной последовательности. Из формулы (10.5) вид- но, что РНС эффективно параметризует долгосрочные связи между переменными, рекуррентно применяя одну и ту же функцию f и одни и те же параметры θ на каждом временном шаге. На рис. 10.8 показана графическая интерпретация модели. Верши-ны h (t), включенные в графическую модель, разрывают связь между прошлым и бу- дущим, играя роль посредника между ними. Переменная y(i) в отдаленном прошлом может оказывать влияние на переменную y(t) посредством влияния на h. Структура этого графа показывает, что модель можно эффективно параметризовать, используя на каждом шаге одни и те же условные распределения вероятности, и что когда все переменные получены в результате наблюдения, вероятность их совместной комби- нации можно эффективно вычислить. Рис. 10.8  Введение переменной состояния в графическую модель РНС, хотя она и является детерминированной функцией своих аргументов, по- могает понять, как можно получить очень эффективную параметризацию, основанную на формуле (10.5). Все участки этой последовательности (со-держащие h (t) и y(t)) имеют одинаковую структуру (одно и то же число входов для каждой вершины) и могут разделять параметры с другими участками Даже в случае эффективной параметризации графической модели некоторые опе- рации остаются вычислительно сложными. Например, трудно предсказать отсут-ствующие значения в середине последовательности. За сокращение числа параметров рекуррентным сетям приходится расплачиваться трудностями оптимизации этих параметров. Разделение параметров в рекуррентных сетях основано на предположении о том, что одинаковые параметры можно использовать на разных временных шагах. Это в точ- ности означает, что условное распределение вероятности переменных в момент t + 1 1 Условное распределение таких величин при условии их родителей детерминировано. Это вполне допустимо, хотя графические модели с такими детерминированными скрытыми блоками проектируют нечасто.\n--- Страница 331 ---\n330  Моделирование последовательностей: рекуррентные и рекурсивные сети при условии переменных в момент t стационарно, т. е. соотношение между состоянием системы в предыдущий и в последующий моменты не зависит от t. В принципе, можно было бы считать t дополнительным входом на каждом временном шаге и позволить обучаемой модели выявить временные зависимости между различными шагами. Это было бы гораздо лучше, чем использовать разные условные распределения для каж-дого t , но тогда сеть должна была бы выполнять экстраполяцию на новые значения t . Чтобы завершить рассмотрение РНС как графической модели, мы должны еще опи- сать, как производить выборку из модели. Основная интересующая нас операция – выборка примера из условного распределения на каждом временном шаге. Однако имеется одно дополнительное осложнение. У РНС должен быть какой-то механизм определения длины последовательности. Достичь этого можно разными способами. Если выходом является символ, выбираемый из словаря, то можно включить спе- циальный символ, обозначающий конец последовательности (Schmidhuber, 2012). Если сгенерирован такой символ, то процесс выборки останавливается. В каждом обучающем примере мы вставляем такой символ в качестве дополнительного члена последовательности, сразу после x (τ). Другой вариант – ввести в модель дополнительный выход с распределением Бер- нулли, который говорит, продолжать генерацию после данного временного шага или остановиться. Это более общий подход, чем включение специального символа в сло- варь, поскольку он применим не только к РНС, порождающей последовательность символов. Например, он годится для РНС, которая выводит последовательность ве-щественных чисел. Новый выходной блок обычно берут сигмоидным и при его обуче- нии используют перекрестную энтропию в качестве функции потерь. Иначе говоря, сигмоида обучается максимизировать логарифмическую вероятность правильного предсказания окончания последовательности на каждом временном шаге. Еще один способ определить длину последовательности τ – добавить в модель вы- ход, который предсказывает само целое число τ. Модель сначала выбирает значение τ, а затем данные для τ шагов. При таком подходе необходимо включать дополни- тельный вход в рекуррентное обновление на каждом временном шаге, чтобы модель знала, подходит она к концу сгенерированной последовательности или еще нет. Этот вход может содержать либо само значение τ, либо число оставшихся шагов τ – t. Без него РНС могла бы генерировать внезапно обрывающиеся последовательности, на-пример неполные предложения. Такой подход основан на разложении P(x (1), …, x(τ)) = P(τ)P(x(1), …, x(τ) | τ). (10.34) Стратегия прямого предсказания τ применялась, например, в работе Goodfellow et al. (2014d). 10.2.4. Моделирование контекстно-обусловленных последовательностей с помощью РНС В предыдущем разделе мы описали соответствие между РНС и ориентированной графической моделью последовательности случайных величин y(t) вообще без входов x. Конечно, наша формулировка РНС в виде уравнения (10.8) включает последова- тельность входов x(1), x(2), …, x(τ). В общем случае представление РНС в виде графи- ческой модели применимо не только к совместному распределению величин y, но и к услов ному распределению y при условии x. В контексте сетей прямого распро- странения в разделе 6.2.1.1 уже обсуждалось, что любую модель, представляющую величину P(y; θ), можно интерпретировать как модель, представляющую распределе-\n--- Страница 332 ---\nРекуррентные нейронные сети  331 ние P(y | ω), где ω = θ. Мы можем обобщить такую модель на представление распреде- ления P(y | x), воспользовавшись тем же P(y | ω), что и раньше, но сделав ω функцией от x. В случае РНС это можно сделать несколькими способами. Мы рассмотрим са- мые распространенные и очевидные. Выше мы обсуждали РНС, которые принимают на входе последовательность век- торов x(t) для t = 1, …, τ. Но можно взять в качестве входа всего один вектор x. Если размер вектора фиксирован, то мы можем просто сделать его дополнительным вхо- дом РНС, генерирующей последовательность y. Вот несколько типичных способов подать дополнительный вход РНС: 1) в качестве дополнительного входа на каждом временном шаге; 2) в качестве начального состояния h(0); 3) то и другое. Первый, самый распространенный подход показан на рис. 10.9. Взаимодействие между входом x и каждым векторным скрытым блоком h(t) параметризуется матри- цей весов R, которой не было в модели, содержащей только последовательность зна- чений y. Одно и то же произведение x⏉R добавляется в качестве дополнительного входа скрытых блоков на каждом временном шаге. Выбор x можно рассматривать как определение значения x⏉R, которое, по существу, является новым параметром смеще- ния, используемым в каждом скрытом блоке. Веса остаются независимыми от входа. Мы можем считать, что эта модель берет параметры θ безусловной модели и преоб- разует их в ω, где параметры смещения внутри ω теперь являются функцией входа. Рис. 10.9  РНС, отображающая вектор фиксированной длины x в рас- пределение последовательностей Y. Эта РНС подходит для таких задач, как подписывание изображений, когда одно изображение подается на вход модели, порождающей его описание в виде последовательности слов. Каждый элемент y(t) наблюдаемой выходной последовательности служит одновременно входом (для текущего временного шага) и – на этапе обуче- ния – меткой (для предыдущего временного шага)\n--- Страница 333 ---\n332  Моделирование последовательностей: рекуррентные и рекурсивные сети РНС может получать на входе не единственный вектор x, а последовательность векторов x(t). РНС, описываемая уравнением (10.8), соответствует условному рас- пределению P(y(1), …, y(τ) | x(1), , x(τ)), для которого справедливо предположение об условной независимости, согласно которому его можно представить в виде произ- ведения (10.35) Чтобы избавиться от предположения об условной независимости, мы можем до- бавить связи между выходом в момент t и скрытым блоком в момент t + 1, как по- казано на рис. 10.10. Тогда модель сможет представить произвольное распределение вероятности последовательности y. У таких моделей, описывающих распределение вероятности одной последовательности при условии другой последовательности, все же остается одно ограничение: длины обеих последовательностей должны быть рав-ны. Как снять это ограничение, мы покажем в разделе 10.4. Рис. 10.10  Условная рекуррентная нейронная сеть, отображающая по- следовательность значений x переменной длины в распределение после- довательностей значений y такой же длины. По сравнению с рис. 10.3, эта РНС содержит связи между предыдущим выходом и текущим состоянием. Эти связи позволяют РНС моделировать произвольное распределение по-следовательностей y при условии последовательностей x такой же длины. РНС на рис. 10.3 способна представить только распределения, в которых значения y условно независимы друг от друга при условии значений x 10.3. Двунаправленные РНС Все рассмотренные до сих пор рекуррентные сети имели «каузальную» структуру, т. е. на состояние в момент t влияет только информация в прошлые моменты времени\n--- Страница 334 ---\nАрхитектуры кодировщик-декодер или последовательность в последовательность  333 x(1), …, x(t–1) и текущий вход x(t). Некоторые обсуждавшиеся модели допускают также влияние прошлых значений y на текущее состояние, если значения y доступны. Но во многих приложениях мы хотим получать предсказание y(t), которое может зависеть от всей входной последовательности. Например, в задаче распознавания речи правильная интерпретация текущего звука как фонемы может зависеть от не- скольких следующих фонем из-за коартикуляции и даже от нескольких следующих слов из-за лингвистических зависимостей между соседними словами: если акустиче-ски допустимы две интерпретации текущего слова, то, чтобы различить их, возмож-но, понадобится заглянуть далеко в будущее (или в прошлое). Это относится также к распознаванию рукописных текстов и многих других задач обучения одной после- довательности на основе другой, рассматриваемых в следующем разделе. Двунаправленные рекуррентные нейронные сети были придуманы для удовлетво- рения именно этой потребности (Schuster and Paliwal, 1997). Они оказались чрезвы-чайно успешными (Graves, 2012) в распознавании рукописных текстов (Graves et al., 2008; Graves and Schmidhuber, 2009), распознавании речи (Graves and Schmidhuber, 2005; Graves et al., 2013) и биоинформатике (Baldi et al., 1999). Как следует из самого названия, двунаправленные РНС являются комбинацией РНС, движущейся вперед во времени (от начала последовательности к ее концу), и РНС, движущейся в обратном направлении. На рис. 10.11 показана типичная дву- направленная РНС; h (t) обозначает состояние той РНС, что движется вперед, а g(t) – той, что движется назад. Это позволяет выходным блокам o(t) вычислять представле- ние, которое зависит как от прошлого, так и от будущего, но наиболее чувствительно к входным значениям вблизи момента t; при этом задавать окно фиксированного размера вокруг t необязательно (в отличие от сетей прямого распространения, свер- точных сетей и обычных РНС с буфером предвыборки фиксированного размера). Эта идея естественно обобщается на двумерные входные данные, например изобра- жения, для чего нужны четыре РНС, по одной в каждом направлении: вверх, вниз, влево, вправо. Тогда в каждой точке (i, j) двумерной сети выходной блок Oi, j мог бы вы- числять представление, которое улавливает в основном локальную информацию, но может зависеть и от удаленных входов, если РНС способна такую информацию нес- ти. По сравнению со сверточной сетью, применение РНС к изображениям обходится дороже, зато может учитывать дальние боковые взаимодействия между элементами одной карты признаков (Visin et al., 2015; Kalchbrenner et al., 2015). Действительно, уравнения прямого распространения для таких РНС можно записать в виде, пока- зывающем, что в них используется свертка, которая вычисляет вход снизу в каждый слой, а только потом производится рекуррентное распространение поперек карты признаков, учитывающее боковые взаимодействия. 10.4. Архитектуры кодировщик-декодер или последовательность в последовательность На рис. 10.5 мы видели, что РНС может отобразить входную последовательность в вектор фиксированного размера. На рис. 10.9 было показано, что РНС может ото- бра1зить вектор фиксированного размера в последовательность, а на рис. 10.3, 10.4, 10.10 и 10.11 – что РНС способна отобразить входную последовательность на выход- ную такой же длины.\n--- Страница 335 ---\n334  Моделирование последовательностей: рекуррентные и рекурсивные сети Рис. 10.11  Вычисление типичной двунаправленной рекуррентной ней- ронной сети, которая должна обучиться отображать входные последова- тельности x на выходные последовательности y, с функцией потерь L(t) на каждом шаге t. Рекуррентные блоки h распространяют информацию вперед во времени (слева направо), а блоки g – назад во времени (справа нале- во). Таким образом, в каждой точке t выходные блоки o(t) могут пользовать- ся сводной информацией о прошлом из входа h(t) и сводной информацией о будущем из входа g(t) В этом разделе мы обсудим, как обучить РНС отображать входную последователь- ность на выходную необязательно такой же длины. Такая задача возникает во многих приложениях, например распознавании речи, машинном переводе и вопросно-ответ- ных системах, где входные и выходные последовательности в обучающем наборе, во- обще говоря, имеют разную длину (хотя их длины могут быть взаимосвязаны). Вход такой РНС часто называют «контекстом». Мы хотим породить представле- ние контекста C. Контекст C может быть вектором или последовательностью векто- ров, агрегирующей входную последовательность X = (x (1), …, x(nx)). Простейшая архитектура РНС для отображения одной последовательности пере- менной длины на другую была предложена сначала в работе Cho et al. (2014a), а вскоре вслед за ней в работе Sutskever et al. (2014), авторы которой независимо разработали эту архитектуру и впервые применили ее к машинному переводу. Первая система осно- вана на оценке предложений, генерируемых другой системой машинного перевода, а во второй используется автономная рекуррентная сеть для генерации переводов. Авто-ры назвали эту архитектуру (рис. 10.12) кодировщик-декодер (encoder-decoder) или последовательность в последовательность (sequence-to-sequence). Идея очень проста:\n--- Страница 336 ---\nАрхитектуры кодировщик-декодер или последовательность в последовательность  335 (1) Кодировщик или читатель, или входная РНС обрабатывает входную последова- тельность. Кодировщик порождает контекст C, обычно в виде простой функции конеч- ного скрытого состояния. (2) Декодер, или писатель, или выходная РНС обусловлена этим вектором фиксированной длины (как на рис. 10.9) и генерирует выходную по- следовательность Y = (y(1), …, y(ny)). От представленных выше в этой главе архитектур эта отличается тем, что длины nx и ny могут различаться, тогда как в предыдущих архи- тектурах действовало ограничение nx = ny = τ. В архитектуре последовательность в по- следовательность обе РНС совместно обучаются максимизировать среднее величины log P(y(1), …, y(ny)) | x(1), …, x(nx)) по всем парам последовательностей x и y в обучающем наборе. Последнее состояние hnx кодирующей РНС обычно используется как представ- ление C входной последовательности, подаваемой на вход декодирующей РНС. Кодировщик Декодер Рис. 10.12  Пример архитектуры РНС типа кодировщик-декодер, или последовательность в последовательность, которая обучается генериро- вать выходную последовательность y(1), …, y(ny) по входной последователь- ности x(1), x(2), …, x(nx). Сеть состоит из кодирующей РНС, которая читает входную последовательность, и декодирующей РНС, которая генерирует выходную последовательность (или вычисляет вероятность заданной вы-ходной последовательности). Конечное скрытое состояние кодирующей РНС используется для вычисления контекстной переменной C фиксирован- ного размера, которая представляет собой семантическую сводку входной последовательности и подается на вход декодирующей РНС Если контекстом C является вектор, то декодирующая РНС – обычная РНС, отобра жающая вектор в последовательность, описанная в разделе 10.2.4. Как мы ви-\n--- Страница 337 ---\n336  Моделирование последовательностей: рекуррентные и рекурсивные сети дели, существуют, по меньшей мере, два способа организовать вход такой РНС. Вхо- дом можно считать начальное состояние РНС, или вход можно соединять со скрыты-ми блоками на каждом временном шаге. Можно также сочетать оба способа. Не требуется, чтобы размеры скрытого слоя кодировщика и декодера совпадали.Очевидное ограничение этой архитектуры проявляется, когда размер контекста C, порождаемого кодировщиком, слишком мал для формирования надлежащей сводки длинной последовательности. Это явление отмечено в работе Bahdanau et al. (2015) в применении к машинному переводу. Авторы предложили сделать C последователь- ностью переменной длины, а не вектором фиксированной длины. Кроме того, они вве- ли механизм внимания, который обучается ассоциировать элементы последователь- ности C с элементами выходной последовательности. Детали см. в разделе 12.4.5.1. 10.5. Глубокие рекуррентные сети Вычисления в большинстве РНС можно разложить на три блока параметров и ассо- циированные с ними преобразования: 1) из входа в скрытое состояние; 2) из предыдущего скрытого состояния в следующее; 3) из скрытого состояния в выход. В архитектуре РНС, показанной на рис. 10.3, с каждым из этих трех блоков ассоции- рована одна матрица весов. Иными словами, при развертке сети каждый блок будет со-ответствовать мелкому преобразованию. Под «мелким» мы понимаем преобразование, которое было бы представлено одним слоем в глубоком МСП. Как правило, это обучен- ное аффинное преобразование, за которым следует фиксированная нелинейность. Даст ли какой-нибудь выигрыш наделение этих операций глубиной? Эксперимен- ты (Graves et al., 2013; Pascanu et al., 2014a) уверенно свидетельствуют в пользу такого предположения. Экспериментальные факты согласуются с идеей о том, что для вы- полнения требуемых отображений нужна достаточная глубина. См. также более ран-ние работы по глубоким РНС Schmidhuber (1992), El Hihi and Bengio (1996) и Jaeger (2007a). В работе Graves et al. (2013) впервые продемонстрировано значительное преиму- щество от разложения состояния РНС в несколько слоев, как на рис. 10.13a. Мож- но считать, что нижние слои в иерархии, показанной на рис. 10.13a, играют роль в преобразовании входных данных в представление, более подходящее для верхних уровней скрытого состояния. В работе Pascanu et al. (2014a) сделан следующий шаг: предложено включать отдельный МСП (возможно, глубокий) для каждого из трех перечисленных выше блоков, как показано на рис. 10.13b. По соображениям репре-зентативной емкости, кажется естественным наделить каждый из трех шагов доста-точно большой емкостью, но если для этого увеличивать глубину, то обучение может осложниться из-за трудностей оптимизации. В общем случае оптимизировать проще более мелкие архитектуры, а увеличение глубины на рис. 10.13b приводит к удлине- нию кратчайшего пути от переменной на шаге t к переменной на шаге t + 1. Например, если для перехода состояний используется МСП с одним скрытым слоем, то длина кратчайшего пути между переменными на любых двух временных шагах удваивает-ся, по сравнению с обычной РНС на рис. 10.3. Однако в работе Pascanu et al. (2014a) отмечено, что эту проблему можно сгладить путем добавления прямых связей внутри скрытого слоя, как показано на рис. 10.13c.\n--- Страница 338 ---\nРекурсивные нейронные сети  337 (a) (b) (c) Рис. 10.13  Рекуррентную нейронную сеть можно сделать глубокой раз- ными способами (Pascanu et al., 2014a). (a) Скрытое рекуррентное состоя- ние можно разделить на иерархически организованные группы. (b) Между входом и скрытым состоянием, между двумя скрытыми уровнями скрытого состояния и между скрытым состоянием и выходом можно поместить более глубокое вычисление (например, МСП). Это может удлинить кратчайший путь, соединяющий разные временные шаги. (c) Эффект удлинения пути можно сгладить путем добавления прямых связей 10.6. Рекурсивные нейронные сети Рекурсивные нейронные сети1 – еще один вид обобщения рекуррентных сетей, для которого характерен граф вычислений, структурированный как глубокое дерево, а не как цепная структура, присущая РНС. Типичный граф вычислений для рекурсивной сети показан на рис. 10.14. Рекурсивные нейронные сети были введены в работе Pollack (1990), а их потенциальное применение к обучению рассуждениям описано в работе Bottou (2011). Рекурсивные сети успешно применялись для обработки структур дан-ных, используемых в качестве входа нейронной сети (Frasconi et al., 1997, 1998), в об- работке естественных языков (Socher et al., 2011a,c, 2013a) и в компью терном зрении (Socher et al., 2011b). Одно очевидное преимущество рекурсивных сетей по сравнению с рекуррентны- ми – тот факт, что для последовательности одной и той же длины τ глубину (изме- ренную как количество композиций нелинейных операций) можно резко снизить с τ до O(log τ), это может оказаться весьма полезно при работе с долгосрочными зависи- мостями. Открытый вопрос – как лучше всего структурировать дерево. Один из ва- риантов – выбрать структуру, не зависящую от данных, например сбалансированное 1 Мы не употребляем аббревиатуру РНС для рекурсивных нейронных сетей во избежание путаницы с рекуррентными нейронными сетями.\n--- Страница 339 ---\n338  Моделирование последовательностей: рекуррентные и рекурсивные сети двоичное дерево. В некоторых предметных областях подходящая структура диктует- ся внешними соображениями. Например, при обработке предложений естественного языка в качестве структуры дерева рекурсивной сети можно взять структуру дерева грамматического разбора предложения, которое строит анализатор языка (Socher et al., 2011a, 2013a). В идеале хотелось бы, чтобы обучаемая модель сама выводила структуру дерева, соответствующую любому заданному входу, как предложено в ра- боте Bottou (2011). Рис. 10.14  Граф вычислений рекурсивной сети является деревом, а не цепочкой, как в рекуррентных сетях. Последовательность переменной дли- ны x(1), x(2), …, x(t) можно отобразить на представление фиксированного раз- мера (выход o) с фиксированным набором параметров (матрицы весов U, V, W). На рисунке показан случай обучения с учителем, когда предъявляет- ся метка y, ассоциированная со всей последовательностью У идеи рекурсивной сети много вариантов. Например, в работах Frasconi et al. (1997) и Frasconi et al. (1998) со структурой дерева ассоциируются данные, а с от- дельными узлами дерева – входы и метки. Необязательно, чтобы в каждом узле выполнялись традиционные для искусственного нейрона вычисления (аффинное преобразование всех выходов, за которым следует монотонная нелинейность). На-пример, в работе Socher et al. (2013a) предложено использовать тензорные операции и билинейные формы, которые раньше с успехом применялись для моделирования связей между концептами (Weston et al., 2010; Bordes et al., 2012), представленными непрерывными векторами (вложениями).\n--- Страница 340 ---\nПроблема долгосрочных зависимостей  339 10.7. Проблема долгосрочных зависимостей Математическая проблема обучения долгосрочных зависимостей в рекуррентных сетях описана в разделе 8.2.5. Основная трудность состоит в том, что градиенты, рас- пространяющиеся через много слоев, либо исчезают (в большинстве случаев), либо начинают взрывообразно расти (редко, но с большим уроном для оптимизации). Даже если предположить, что при заданных параметрах рекуррентная сеть устойчива (может хранить воспоминания без взрывного роста градиентов), все равно остается проблема назначения долгосрочным зависимостям экспоненциально меньших (из-за перемножения большого числа якобианов) весов, чем краткосрочным. Во многих ис-точниках этот вопрос освещается более глубоко (Hochreiter, 1991; Doya, 1993; Bengio et al., 1994; Pascanu et al., 2013). В этом разделе мы подробнее опишем саму проблему, а в последующих – подходы к ее преодолению. В рекуррентных сетях композиция одной и той же функции вычисляется много- кратно – по одному разу на каждом временном шаге. Это может приводить к поведе- нию, весьма далекому от линейного (рис. 10.15). Координата входаПроекция выхода4 32 1 0 –1–2–3 –4 –60 –40 –20 0 20 40 601 2 3 4 5 6 Рис. 10.15  Повторная композиция функций. Многократная композиция нелинейной функции (например, показанного здесь гиперболического тан- генса) приводит к сильно нелинейному результату; обычно в большинстве точек производная очень мала, в некоторых велика, и часто наблюдается переход от возрастания к убыванию и наоборот. На этом рисунке показана линейная проекция 100-мерного скрытого состояния на одно измерение, отложенное по оси y. По оси x отложена координата начального состоя- ния вдоль случайно выбранного направления в 100-мерном пространстве. Таким образом, этот график можно рассматривать как сечение графика многомерной функции. На графиках показана функция после каждого вре- менного шага, или, эквивалентно, результат многократной композиции функции перехода с самой собой В частности, композиция функция, применяемая в рекуррентных нейронных се- тях, чем-то напоминает умножение матриц. Рекуррентное соотношение h(t) = W⏉h(t–1) (10.36) можно рассматривать как очень простую РНС без функции активации и без входов x. В разделе 8.2.5 было отмечено, что это соотношение, по существу, описывает воз- ведение в степень. Его можно упростить следующим образом:\n--- Страница 341 ---\n340  Моделирование последовательностей: рекуррентные и рекурсивные сети h(t) = (Wt)⏉h(0), (10.37) а если W допускает спектральное разложение вида W = QΛQ⏉, (10.38) где Q – ортогональная матрица, то это соотношение можно еще упростить: h(t) = Q⏉ΛtQh(0). (10.39) Собственные значения возводятся в степень t, в результате чего собственные зна- чения, которые по абсолютной величине меньше 1, стремятся к нулю, а те, что больше 1, резко возрастают. В конечном итоге компоненты h(0), не сонаправленные наиболь- шему собственному вектору, будут отброшены. Эта проблема особенно остро стоит для рекуррентных сетей. Возьмем скалярный случай и представим себе многократное умножение веса w на себя. В зависимости от абсолютной величины w произведение wt будет стремиться либо к нулю, либо к бес- конечности. Если построить нерекуррентную сеть с различными весами w(t) на каж- дом временном шаге, то ситуация будет иной. Если начальное состояние равно 1, то состояние в момент t равно произведению ∏t w(t). Предположим, что значения w(t) ге- нерируются случайным образом независимо друг от друга с нулевым средним и дис- персией v. Тогда дисперсия произведения равна O(vn). Чтобы получить желае мую дисперсию v*, мы можем подобрать индивидуальные веса, так чтобы их дисперсия была равна v = n√_ v*. Таким образом, даже в очень глубоких сетях за счет тщательно по- добранного масштабирования можно избежать проблемы исчезающего и взрывного градиента (см. Sussillo (2014)). Проблема исчезающего и взрывного градиента для РНС была независимо обна- ружена несколькими исследователями (Hochreiter, 1991; Bengio et al., 1993, 1994). Можно было бы надеяться избежать ее, просто оставаясь в области пространства параметров, где градиенты не исчезают и не растут взрывообразно. К сожалению, для хранения «воспоминаний» способом, устойчивым к малым возмущениям, РНС должна войти в область пространства параметров, где градиенты исчезают (Bengio et al., 1993, 1994). Точнее говоря, если модель способна представить долгосрочные за-висимости, то абсолютная величина градиента долгосрочного взаимодействия экспо-ненциально меньше, чем краткосрочного. Это не означает, что сеть вообще невозмож-но обучить, просто обучение долгосрочных зависимостей может занять очень много времени, потому что сигнал об этих зависимостях будет замаскирован мельчайшими флуктуациями, возникающими из-за краткосрочных зависимостей. Эксперименты, описанные в работе Bengio et al. (1994), показывают, что на практике по мере уве- личения протяженности зависимостей, которые требуется запоминать, градиентная оптимизация становится все труднее, и вероятность успешно обучить традиционную РНС методом стохастического градиентного спуска быстро спадает до 0, когда длина последовательностей равна всего 10 или 20. Более глубокое рассмотрение рекуррентных сетей как динамических систем см. в работах Doya (1993), Bengio et al. (1994), Siegelmann and Sontag (1995), а обзор ли- тературы – в работе Pascanu et al. (2013). Далее в этой главе мы рассмотрим различ- ные подходы, предложенные с целью уменьшить трудность обучения долгосрочных зависимостей (иногда удается обучить РНС зависимостям, существующим на про-тяжении сотен шагов), однако отметим, что эта проблема остается одной из главных в машинном обучении.\n--- Страница 342 ---\nНейронные эхо-сети  341 10.8. Нейронные эхо-сети Отображение рекуррентных весов h(t–1) в h(t) и отображение входов на веса – x(t) в h(t) – параметры рекуррентной сети, которые труднее всего поддаются обучению. Для борьбы с этими трудностями было предложено (Jaeger, 2003; Maass et al., 2002; Jaeger and Haas, 2004; Jaeger, 2007b) задавать рекуррентные веса так, чтобы скрытые рекур-рентные блоки запоминали историю прошлых входов, а обучать только выходные веса. Эта идея была независимо предложена для эхо-сетей (echo state networks), или ESN (Jaeger and Haas, 2004; Jaeger, 2007b), и машин неустойчивых состояний (liquid state machines) (Maass et al., 2002). Обе модели похожи, но в первой используются скрытые блоки с непрерывными значениями, а во второй – импульсные нейроны (с бинарным выходом). И эхо-сети, и машины неустойчивых состояний объединены общим названием резервуарные вычисления (reservoir computing) (Lukoševicius and Jaeger, 2009), отражающим тот факт, что скрытые блоки образуют резервуар времен-ных признаков, которые могут запоминать различные аспекты истории входов. В некотором смысле такие рекуррентные сети с резервуарными вычислениями напоминают ядерные методы: они отображают последовательность произвольной длины (историю входов до момента t) на вектор фиксированной длины (рекуррент- ное состояние h (t)), к которому можно применить линейный предиктор (обычно ли- нейную регрессию) для решения интересующей проблемы. В таком случае критерий обуче ния легко спроектировать в виде выпуклой функции выходных весов. Напри- мер, если выход получается в результате линейной регрессии скрытых входов на вы- ходные метки, а критерий обучения – среднеквадратическая ошибка, то функция вы- пуклая, и задачу можно надежно решить с помощью простых алгоритмов обучения (Jaeger, 2003). Следовательно, возникает важный вопрос: как задать вход и рекуррентные веса, чтобы в состоянии рекуррентной нейронной сети можно было представить достаточ- но полную историю? В литературе по резервуарным вычислениям предлагается рас- сматривать рекуррентную сеть как динамическую систему и задавать входы и веса, так чтобы эта система была близка к устойчивости. Первоначальная идея состояла в том, чтобы сделать собственные значения якобиа- на функции перехода состояний близкими к 1. В разделе 8.2.5 говорилось, что важной характеристикой рекуррентной сети является спектр собственных значений якобиа-нов J (t) = (∂s(t)/ ∂s(t–1)). Особый интерес представляет спектральный радиус J(t), опре- деляемый как максимум абсолютных величин собственных значений. Чтобы понять, на что влияет спектральный радиус, рассмотрим простой случай обратного распространения, в котором матрица Якоби J не зависит от t. Так бывает, например, когда сеть чисто линейная. Предположим, что у J имеется собственный вектор v, соответствующий собственному значению λ. Посмотрим, что происходит, когда вектор градиента распространяется назад во времени. Если начать с градиента g, то после одного шага обратного распространения градиент будет равен Jg, а по- сле n шагов – Jng. Теперь посмотрим, что случится, если обратному распространению подвергнуть возмущенный вектор g. Если начать с g + δv, то после одного шага полу- чится J(g + δv), а после n шагов – Jn(g + δv). Отсюда видно, что результаты обратного распространения, начавшегося с g и с g + δv, после n шагов расходятся на δJnv. Если в качестве v взять единичный собственный вектор J с собственным значением λ, то умножение на якобиан просто масштабирует разность на каждом шаге. Результаты\n--- Страница 343 ---\n342  Моделирование последовательностей: рекуррентные и рекурсивные сети двух описанных выше выполнений обратного распространения разделены расстоя- нием δ|λ|n: если v соответствует наибольшему значению | λ|, то это возмущение дает наибольшее возможное расхождение с начальным возмущением δ. Если | λ| > 1, то величина расхождения δ|λ|n экспоненциально возрастает, если | λ| < 1, то экспоненциально убывает. Разумеется, в этом примере предполагалось, что якобиан одинаков на всех времен- ных шагах, что соответствует рекуррентной нейронной сети без нелинейностей. Если же нелинейность присутствует, то ее производная после многих шагов будет близка к нулю, что позволит предотвратить взрывообразный рост из-за большого спектраль- ного радиуса. На самом деле в большинстве недавних работ по эхо-сетям предлагается использовать спектральный радиус, много больший 1 (Yildiz et al., 2012; Jaeger, 2012). Все сказанное выше об обратном распространении посредством повторного умно- жения на матрицу равным образом применимо и к прямому распространению в сети без нелинейностей, когда состояние h (t+1) = h(t)⏉W. Если линейное отображение W⏉ всегда уменьшает h по норме L2, то говорят, что отображение сжимающее. Если спектральный радиус меньше 1, то отображение h(t) в h(t+1) сжимающее, поэтому небольшое изменение с каждым шагом становится все меньше. Поэтому сеть неизбежно забывает информацию о прошлом, если для хра- нения вектора состояния используются вычисления конечной точности (например, с 32-разрядными целыми). Матрица Якоби говорит, как малое изменение h (t) распространяется на один шаг вперед, или, эквивалентно, как градиент h(t+1) распространяется на один шаг назад в ходе обратного распространения. Отметим, что ни W, ни J не обязаны быть сим- метричными (хотя обе матрицы квадратные и вещественные), поэтому они могут иметь комплексные собственные значения, мнимые части которых соответствуют по-тенциально колебательному поведению (при повторном применении одного и того же якобиана). Хотя h (t) или небольшая вариация h(t) при обратном распространении принимают вещественные значения, их можно выразить в таком комплексном бази- се. Важно лишь, что происходит с абсолютной величиной (модулем комплексного числа) координат в потенциально комплексном базисе при умножении матрицы на вектор. Собственные значения, абсолютная величина которых больше 1, соответ-ствуют увеличению (при повторном применении – экспоненциальному росту) или уменьшению (экспоненциальному убыванию). В случае нелинейного отображения якобиан может изменяться на каждом шаге. По- этому динамика становится более сложной. Но по-прежнему небольшое изменение может стать большим после нескольких шагов. Одно из различий между линейным и нелинейным случаями состоит в том, что «сплющивающая» нелинейность типа tanh может сделать рекуррентную динамику ограниченной. Отметим, что динамика обрат-ного распространения может оставаться неограниченной, даже если прямое распростра-нение имеет ограниченную динамику, например когда все tanh-блоки, принадлежащие последовательности, находятся в середине своего почти линейного участка и связаны матрицами весов со спектральными радиусами больше 1. Впрочем, редко случается, что все tanh-блоки одновременно оказываются на линейном участке активации. В эхо-сетях принята простая стратегия – зафиксировать веса, так чтобы спектраль- ный радиус был равен примерно 3, тогда информация переносится вперед во време-ни, но взрывного роста нет из-за стабилизирующего влияния насыщающих нелиней-ностей типа tanh.\n--- Страница 344 ---\nБлоки с утечками и другие стратегии нескольких временных масштабов  343 Сравнительно недавно было показано, что методы, используемые для задания ве- сов в эхо-сетях, можно применять и для инициализации весов в рекуррентных сетях полного обучения (когда рекуррентные веса между скрытыми слоями обучаются с помощью обратного распространения во времени), что помогает обучаться долго- срочным зависимостям (Sutskever, 2012; Sutskever et al., 2013). В этой конфигурации хорошие результаты дает выбор начального спектрального радиуса 1.2 в сочетании со схемой разреженной инициализации, описанной в разделе 8.4. 10.9. Блоки с утечками и другие стратегии нескольких временных масштабов Один из способов включения долгосрочных зависимостей – спроектировать модель, работающую в нескольких временных масштабах, так что одни части модели работа- ют в мелком масштабе и могут обрабатывать мелкие детали, а другие – работающие в крупном масштабе – эффективно передают информацию из отдаленного прошлого в настоящее. Существуют различные стратегии построения мелких и крупных мас- штабов: добавление прямых связей сквозь время; «блоки с утечками», которые интег- рируют сигналы с разными временными постоянными; удаление некоторых связей, используемых для моделирования мелких масштабов. 10.9.1. Добавление прямых связей сквозь время Для получения грубого временного масштаба можно добавить прямые связи между переменными в отдаленном прошлом и переменными в настоящем. Идея таких пря- мых связей восходит к работе Lin et al. (1996) и вытекает из идеи включения задержек в нейронные сети прямого распространения (Lang and Hinton, 1988). В обыкновен- ной рекуррентной сети рекуррентная связь идет из блока в момент t к блоку в момент t + 1. Но можно построить рекуррентные сети с большими задержками (Bengio, 1991). В разделе 8.2.5 мы видели, что градиенты могут исчезать или экспоненциально расти при увеличении числа шагов. Для смягчения этой проблемы в работе Lin et al. (1996) введены рекуррентные соединения с временной задержкой d. Теперь гради- ент экспоненциально убывает как функция τ/d, а не τ. Поскольку имеются как связи с задержкой, так и одношаговые связи, градиенты все же могут экспоненциально расти относительно τ. Это позволяет алгоритму обучения улавливать долгосрочные зависимости, хотя и не все такие зависимости хорошо представляются подобным образом. 10.9.2. Блоки с утечкой и спектр разных временных масштабов Еще один способ получить пути, на которых произведение производных близко к 1, – включать блоки с линейными соединениями с самими собой (самосоединениями), имеющими веса, близкие к единице. В формуле вычисления скользящего среднего μ(t) некоторой величины v(t): μ(t) ← αμ(t–1) + (1 – α)v(t) параметр α является примером линейного самосоединения μ(t–1) с μ(t). Если α близко к 1, то скользящее среднее помнит информацию о прошлом на протяжении долгого времени, а если α близко к 0, то информация о прошлом быст ро забывается. Скрытые блоки с линейными самосоединениями могут вести себя анало- гично скользящему среднему и называются блоками с утечкой, или протекающими.\n--- Страница 345 ---\n344  Моделирование последовательностей: рекуррентные и рекурсивные сети Прямые связи с пропуском d временных шагов гарантируют, что блок сможет обучить ся влиянию значений, находящихся от него на d шагов в прошлом. Исполь- зование линейных самосоединений с весом, близким к 1, – другой способ обеспечить блоку доступ к прошлым значениям. И этот подход допускает более плавную и гиб- кую настройку путем изменения вещественного параметра α, а не целочисленной длины пропуска. Эти идеи предложены в работах Mozer (1992) и by El Hihi and Bengio (1996). Блоки с утечкой оказались полезны также в контексте эхо-сетей (Jaeger et al., 2007). Существуют две основные стратегии задания временных констант для настройки блоков с утечкой. Одна – вручную зафиксировать их значения, например выбрав их из некоторого распределения один раз на этапе инициализации. Вторая – сделать константы свободными параметрами и обучить их. Похоже, что включение блоков с утечкой в разных временных масштабах помогает справиться с долгосрочными за- висимостями (Mozer, 1992; Pascanu et al., 2013). 10.9.3. Удаление связей Еще один подход к обработке долгосрочных зависимостей – организация состояния РНС в нескольких временных масштабах (El Hihi and Bengio, 1996) с целью упрос- тить протекание информации на большое расстояние в более медленном масштабе. Эта идея отличается от прямых связей сквозь время, поскольку подразумевается активное удаление связей длины 1 и замена их более длинными. Модифицирован- ные таким способом блоки вынуждены работать в более протяженном временном масштабе. Прямые связи добавляют ребра. Блоки, получившие новые связи, могут обучить ся работе в протяженном временном масштабе, но могут поступить и наобо- рот, предпочтя другие, более короткие связи. Есть несколько способов принудить группу рекуррентных блоков к работе в раз- ных временных масштабах. Один из них – сделать рекуррентные блоки протекаю- щими, но ассоциировать разные группы блоков с разными фиксированными времен- ными маштабами. Эта идея предложена в работе Mozer (1992) и успешно воплощена в работе Pascanu et al. (2013). Другой способ – производить явные дискретные обнов- ления в разные моменты времени с разной частотой для разных групп блоков. Этот подход применен в работах El Hihi and Bengio (1996) и Koutnik et al. (2014). Он по- казал хорошие результаты на ряде эталонных наборов данных. 10.10. Долгая краткосрочная память и другие вентильные РНС На момент написания книги самыми эффективными моделями последовательностей в практических приложениях были вентильные РНС (gated RNN). К ним относятся долгая краткосрочная память (long short-term memory – LSTM) и сети, основанные на вентильных рекуррентных блоках. Как и блоки с утечкой, вентильные РНС основаны на идее прокладывания таких путей сквозь время, на которых производные не обнуляются и не устремляются резко вверх. В случае блоков с утечкой это достигалось с помощью весов связей – посто- янных, задаваемых вручную или являющихся параметрами. Вентильные РНС обоб-щают эту идею на веса связей, которые могут изменяться на каждом временном шаге.\n--- Страница 346 ---\nДолгая краткосрочная память и другие вентильные РНС  345 Блоки с утечкой позволяют сети накапливать информацию (например, свидетель- ства в пользу конкретного признака или категории) на протяжении длительного вре- мени. Но иногда полезно, чтобы после использования этой информации нейронная сеть забыла старое состояние. Например, если последовательность состоит из под-последовательностей и мы хотим, чтобы блок с утечкой накапливал свидетельства внутри каждой подпоследовательности, то необходим механизм забывания старого состояния – сброса его в нуль. И хорошо бы, чтобы нейронная сеть обучилась, когда это нужно делать, не обременяя нас принятием решения. Именно для этого и предна- значены вентильные РНС. 10.10.1. Долгая краткосрочная память Удачная мысль о введении петель для создания путей, по которым градиент может течь длительное время, – основной вклад в первоначальную модель долгой кратко- срочной памяти (Hochreiter and Schmidhuber, 1997). Позднее было внесено важней-шее дополнение – вес петли должен быть контекстно-обусловленным, а не фикси- рованным (Gers et al., 2000). Сделав вес петли вентильным (управляемым другим скрытым блоком), мы можем динамически изменять временной масштаб интегри-рования. В данном случае имеется в виду, что даже для LSTM с фиксированными параметрами временной масштаб интегрирования может изменяться в зависимости от входной последовательности, поскольку временные константы выводятся самой моделью. Идея LSTM оказалась чрезвычайно успешной во многих приложениях, например: неограниченное распознавание рукописных текстов (Graves et al., 2009), распознавание речи (Graves et al., 2013; Graves and Jaitly, 2014), порождение рукопис-ных текстов (Graves, 2013), машинный перевод (Sutskever et al., 2014), подписывание изобра жений (Kiros et al., 2014b; Vinyals et al., 2014b; Xu et al., 2015) и грамматиче- ский разбор (Vinyals et al., 2014a). Принципиальная схема LSTM показана на рис. 10.16. Ниже приведены соответ- ствующие уравнения прямого распространения для архитектуры мелкой рекуррент-ной сети. Есть также примеры успешного использования более глубоких архитектур (Graves et al., 2013; Pascanu et al., 2014a). Вместо блока, который просто применяет поэлементную нелинейность к аффинному преобразованию входов и рекуррентным блокам, в рекуррентных LSTM-сетях имеются «LSTM-ячейки», обладающие внут- ренней рекуррентностью (петлей) в дополнение к внешней рекуррентности РНС. У каждой ячейки такие же входы и выходы, как у обыкновенной рекуррентной сети, но еще имеются дополнительные параметры и система вентильных блоков, управ- ляющих потоком информации. Самым важным компонентом является блок состоя-ния s i(t) с линейной петлей, аналогичный описанным выше блокам с утечкой. Однако теперь вес петли (или ассоциированная временная константа) управляется вентиль- ным блоком забывания fi(t) (для временного шага t и ячейки i), который присваивает этому весу значение от 0 до 1 с помощью сигмоиды: (10.40) где x(t) – текущий входной вектор, h(t) – вектор текущего скрытого слоя, содержа- щий выходы всех LSTM-ячеек, а bf ,Uf, Wf – соответственно смещения, веса входов и рекуррентные веса для вентилей забывания. Таким образом, внутреннее состояние\n--- Страница 347 ---\n346  Моделирование последовательностей: рекуррентные и рекурсивные сети LSTM-ячейки обновляется по следующей формуле, в которой присутствует услов- ный вес петли fi(t): (10.41) где b, U и W – соответственно смещения, веса входов и рекуррентные веса LSTM- ячейки. Блок внешнего входного вентиля gi(t) вычисляется аналогично вентилю за- бывания (с использованием сигмоиды для получения значения от 0 до 1), но со сво- ими параметрами: (10.42) выход петля состояние входвходной вентильвентиль забываниявыходной вентиль Рис. 10.16  Принципиальная схема «ячейки» рекуррентной LSTM-сети. Ячейки, рекуррентно связанные между собой, заменяют стандартные скры- тые блоки в обыкновенных рекуррентных сетях. Входной признак вычис- ляется регулярным блоком искусственного нейрона. Его значение можно аккумулировать в состоянии, если сигмоидный входной вентиль это допус- кает. В блоке состояния имеется линейная петля, вес которой управляется вентилем забывания. Выход ячейки можно перекрыть с помощью выходно- го вентиля. Во всех вентильных блоках имеется сигмоидная нелинейность, тогда как во входном блоке разрешены произвольные сплющивающие не-линейности. Черным квадратиком обозначена задержка на одном времен-ном шаге\n--- Страница 348 ---\nДолгая краткосрочная память и другие вентильные РНС  347 Выход hi(t) LSTM-ячейки можно перекрыть с помощью выходного вентиля qi(t), в котором также используется сигмоида: hi(t) = tanh(si(t))qi(t), (10.43) (10.44) и bo, Uo, Wo – смещения, веса входов и рекуррентные веса соответственно. Один из вариантов – использовать состояние ячейки si(t) как дополнительный вход (со своим весом) всех трех вентилей i-го блока, как показано на рис. 10.16. Тогда потребуются три дополнительных параметра. Показано, что LSTM-сети легче обучаются долгосрочным зависимостям, чем прос- тые рекуррентные архитектуры: сначала на искусственных наборах данных, спроек- тированных специально для тестирования способности к обучению долгосрочным зависимостям (Bengio et al., 1994; Hochreiter and Schmidhuber, 1997; Hochreiter et al., 2001), а затем и на трудных задачах обработки последовательностей, при решении которых было достигнуто качество, не уступающее лучшим образцам (Graves, 2012; Graves et al., 2013; Sutskever et al., 2014). Ниже обсуждаются варианты и альтернати- вы LSTM, которые изучались и нашли практическое применение. 10.10.2. Другие вентильные РНС Какие части архитектуры LSTM действительно необходимы? Какие еще можно при-думать успешные архитектуры, позволяющие сети динамически управлять времен-ным масштабом и поведением забывания различных блоков? Ответы на некоторые из этих вопросов даны в недавних работах по вентильным РНС, блоки которых известны также под названием вентильных рекуррентных бло-ков (gated recurrent unit – GRU) (Cho et al., 2014b; Chung et al., 2014, 2015a; Jozefowicz et al., 2015; Chrupala et al., 2015). Основное отличие от LSTM заключается в том, что один вентильный блок одновременно управляет и коэффициентом забывания, и ре- шением об обновлении блока состояния. Уравнения обновления имеют вид: (10.45) где u обозначает вентиль «обновления», а r – вентиль «сброса». Их значения опреде- ляются как обычно: ; (10.46) (10.47) Вентили обновления и сброса могут «игнорировать» части вектора состояния. Вентили обновления действуют как условные интеграторы с утечкой с линейной функцией по любому измерению, т. е. могут либо скопировать вход (один конец сиг- моиды), либо полностью проигнорировать его (противоположный конец), заменив новым «целевым состоянием» (к которому интегратор с утечкой желает сойтись). Вентили сброса контролируют, какие части состояния использовать для вычисления\n--- Страница 349 ---\n348  Моделирование последовательностей: рекуррентные и рекурсивные сети следующего целевого состояния, и вносят дополнительный нелинейный эффект в со- отношение между прошлым и будущим состояниями. На эту тему возможно еще много вариаций. Например, выход вентиля сброса (или вентиля забывания) можно разделить между несколькими скрытыми блоками. Или использовать произведение глобального вентиля (управляющего целой группой бло-ков, например всем слоем) и локального вентиля (управляющего одним блоком) для комбинирования глобального и локального управлений. Однако в нескольких иссле- дованиях архитектурных вариантов LSTM и GRU не найдено решения, которое было бы очевидно лучше обоих на широком круге задач (Greff et al., 2015; Jozefowicz et al., 2015). В работе Greff et al. (2015) установлено, что вентиль забывания – ключевой ингредиент архитектуры, а в работе Jozefowicz et al. (2015) – что прибавление смеще- ния 1 к вентилю забывания LSTM, рекомендованное в работе Gers et al. (2000), делает LSTM не уступающей лучшим из изученных архитектурных вариантов. 10.11. Оптимизация в контексте долгосрочных зависимостей В разделах 8.2.5 и 10.7 описана проблема исчезающих и взрывных градиентов, воз- никающая при оптимизации РНС на большом числе временных шагов. В работе Martens and Sutskever (2011) высказана интересная идея: вторые произ- водные могут становиться исчезающе малыми одновременно с первыми. Алгоритмы оптимизации второго порядка можно грубо интерпретировать как деление первой производной на вторую (в многомерном случае – деление градиента на обратный гес- сиан). Если вторая производная убывает примерно с такой же скоростью, как первая, то отношение первой и второй производных будет оставаться относительно посто- янным. К сожалению, у методов второго порядка много недостатков, в т. ч. высокая вычислительная стоимость, необходимость брать большой мини-пакет и притяжение к седловым точкам. В работе Martens and Sutskever (2011) получены многообещаю- щие результаты с использованием методов второго порядка. Позже, в работе Sutskever et al. (2013), было установлено, что аналогичные результаты можно получить и бо- лее простыми методами, а именно методом Нестерова с тщательно подобран ными начальными значениями. Дополнительные сведения см. в работе Sutskever (2012). Оба этих подхода в значительной степени заменены применением СГС (даже без им- пульса) к LSTM-сетям. Это пример постоянно встречающегося в машинном обуче- нии явления: гораздо легче спроектировать простую для оптимизации модель, чем изобретать более мощный алгоритм оптимизации. 10.11.1. Отсечение градиентов В разделе 8.2.4 отмечалось, что у сильно нелинейных функций, таких, например, как те, что вычисляются рекуррентной сетью через много временных шагов, производные нередко слишком малы или слишком велики по абсолютной величине. Это показано на рис. 8.3 и 10.17, где «ландшафт» целевой функции (как функции параметров) со- держит «уступы»: широкие и довольно плоские участки, разделенные чрезвычайно узкими областями, где целевая функция быстро изменяется. Трудность состоит в том, что когда градиент параметров очень велик, при обновле- нии параметров градиентного спуска параметры могут быть отброшены очень далеко в область больших значений целевой функции, и тогда значительная часть работы,\n--- Страница 350 ---\nОптимизация в контексте долгосрочных зависимостей  349 проделанной для нахождения текущего решения, пойдет насмарку. Градиент ука- зывает направление, соответствующее наискорейшему спуску в бесконечно малой окрестности текущих параметров. Вне этой окрестности функция стоимости может снова начать возрастать. Обновление следует выбирать достаточно малым, чтобы предо твратить слишком сильный подъем. Обычно мы берем скорости обучения, сни- жающиеся достаточно медленно для того, чтобы на соседних шагах скорость обуче-ния была примерно одинаковой. Размер шага, подходящий на сравнительно плоских участках ландшафта, зачастую не годится, т. к. приводит к подъему, когда на следую- щем шаге мы оказываемся на более искривленном участке. Без отсечения С отсечением w w b bJ(w, b) J(w, b) Рис. 10.17  Пример эффекта отсечения градиента в рекуррентной сети с двумя параметрами w и b. В результате отсечения метод градиентного спуска иногда ведет себя более разумно вблизи особенно крутых уступов. Такие крутые уступы часто встречаются в рекуррентных сетях рядом с участ- ками, где сеть ведет себя почти линейно. Крутизна уступа экспоненциально возрастает с увеличением числа временных шагов, поскольку на каждом шаге матрица весов умножается на себя же. (Слева) Градиентный спуск без отсечения градиента проскакивает дно этого небольшого ущелья, после чего градиент резко возрастает на стенке уступа. Большой градиент при-водит к катастрофическому уходу параметров от оптимума. (Справа) Гра- диентный спуск с отсечением градиента реагирует на уступ не так резко. Хотя подъем имеет место, размер шага ограничен, поэтому мы не можем уйти слишком далеко от крутой области рядом с решением. Рисунок взят из работы Pascanu et al. (2013) с разрешения авторов На практике уже много лет используется простое решение: отсечение градиента. У этой идеи много вариантов (Mikolov, 2012; Pascanu et al., 2013). Один из них – отсе- кать градиент параметров на примерах из мини-пакета поэлементно (Mikolov, 2012), непосредственно перед обновлением параметров. Другой – отсекать норму || g|| гра- диента g (Pascanu et al., 2013) непосредственно перед обновлением параметров: if ||g|| > v, (10.48) (10.49) где v – порог нормы, а g используется для обновления параметров. Поскольку гради- ент всех параметров (включая различные группы, как, например, веса и смещения)\n--- Страница 351 ---\n350  Моделирование последовательностей: рекуррентные и рекурсивные сети совместно перенормируется с одним масштабным коэффициентом, у второго метода есть преимущество: он гарантирует, что каждый шаг происходит все еще в направ- лении градиента; впрочем, эксперименты показывают, что оба метода работают при-мерно одинаково. Хотя обновление параметров направлено в ту же сторону, что ис- тинный градиент, в случае отсечения градиента по норме норма вектора обновления оказывается ограниченной, вследствие чего алгоритм избегает убийственного шага при резком росте градиента. На самом деле даже случайный выбор шага в случае, ког- да абсолютная величина превышает порог, работает почти так же хорошо. Если рост настолько сильный, что градиент принимает значение Inf или Nan (бесконечность или «не число»), то, взяв случайный размер шага v, мы, как правило, уйдем из области численной неустойчивости. Отсечение нормы градиента на мини-пакет не изменяет направления градиента для отдельного мини-пакета. Однако усреднение отсеченных по норме градиентов по многим мини-пакетам не эквивалентно отсечению нормы ис-тинного градиента (образованного при использовании всех примеров). Вклад при-меров с большой нормой градиента, а также примеров, входящих в один мини-пакет с ними, в конечное направление уменьшается. Это контрастирует с традиционным мини-пакетным градиентным спуском, когда направление истинного градиента сов-падает с результатом усреднения всех мини-пакетных градиентов. По-другому мож- но сказать, что в традиционном стохастическом градиентном спуске используется несмещенная оценка градиента, тогда как в градиентном спуске с отсечением по нор- ме вводится эвристическое смещение, которое, как мы знаем, эмпирически полезно. В случае поэлементного отсечения направление обновления не совпадает с направле- нием истинного или мини-пакетного градиента, но все равно является приемлемым. Предлагалось (Graves, 2013) отсекать градиент на этапе обратного распространения (с учетом скрытых блоков), но результаты сравнения этого варианта с другими не опубликованы; отсюда мы заключаем, что все эти методы ведут себя более-менее оди-наково. 10.11.2. Регуляризация с целью подталкивания информационного потока Отсечение градиента помогает бороться с взрывными градиентами, но ничего не мо- жет поделать с исчезающими. Говоря о решении проблемы исчезающих градиентов и о лучшем улавливании долгосрочных зависимостей, мы обсуждали идею создания путей в графе вычислений развернутой рекуррентной архитектуры, вдоль которых произведение градиентов, ассоциированных с ребрами, близко к 1. Один из способов сделать это дают LSTM-сети и другие механизмы петель и вентилей, рассмотренные в разделе 10.10. Еще одна идея – регуляризировать параметры или наложить на них ограничения, с тем чтобы подтолкнуть «информационный поток». Конкретно, мы хотели бы, чтобы распространяющийся обратно вектор градиента ∇h(t)L сохранял аб- солютную величину, даже если функция потерь штрафует только выход в конце по- следовательности. Формально требуется, чтобы величина (10.50) была так же велика, как ∇h(t)L. (10.51)\n--- Страница 352 ---\nЯвная память  351 С этой целью в работе Pascanu et al. (2013) предложен такой регуляризатор: (10.52) Может показаться, что вычислить градиент этого регуляризатора трудно, но в ра- боте Pascanu et al. (2013) предложена аппроксимация, в которой распространяющиеся обратно векторы ∇h(t)L рассматриваются как постоянные (применительно к этому регу- ляризатору, т. е. нет необходимости производить через них обратное распространение). Эксперименты показывают, что в сочетании с эвристикой отсечения по норме (для борьбы с взрывными градиентами) этот регуляризатор может значительно увеличить временную протяженность зависимостей, которым может обучиться РНС. Поскольку он удерживает динамику РНС на грани взрывного роста градиентов, отсечение осо-бенно важно – без него рост градиентов не позволит обучению успешно завершиться. Главный недостаток этого подхода в низкой, по сравнению с LSTM, эффективности на задачах, где данных в изобилии, например в задаче моделирования языка. 10.12. Явная память Интеллект нуждается в знаниях, а знания приобретаются в процессе обучения, что и стало стимулом для разработки крупномасштабных глубоких архитектур. Однако знания бывают разные. Есть знания неявные, подсознательные, с трудом выражае- мые словами: как ходить или чем собака отличается от кошки. Другие знания явные, декларативные, сравнительно легко облекаемые в слова – это могут быть как зна- ния, основанные на бытовом здравом смысле, например «кошка – это животное», так и весьма специфичные факты, знать которые необходимо для достижения текущих целей, например «собрание отдела продаж состоится в 15:00 в комнате 141». Нейронные сети прекрасно справляются с хранением неявных знаний, но сталки- ваются с трудностями при запоминании фактов. Методу стохастического градиент- ного спуска нужно много раз предъявить одни и те же входные данные, чтобы он смог запомнить их в параметрах нейронной сети, но и тогда нельзя сказать, что эти дан- ные хранятся точно. В работе Graves et al. (2014b) высказана гипотеза, что причина этого в том, что нейронным сетям недостает эквивалента кратковременной памяти, которая позволяет людям явно хранить и оперировать фрагментами информации, от- носящимися к достижению некоторой цели. Такие компоненты явной памяти позво- лили бы нашим системам не только быстро и «намеренно» запоминать и извлекать конкретные факты, но и последовательно рассуждать о них. Потребность в нейрон- ных сетях, которые могут обрабатывать информацию, выполняя последовательность шагов, на каждом из которых изменяется способ подачи входных данных в сеть, давно уже осознана как важная предпосылка рассуждений, а не автоматической, интуитив- ной реакции на вход (Hinton, 1990). Для разрешения этой проблемы в работе Weston et al. (2014) введена концепция се- тей с памятью, в которые входят набор ячеек памяти и механизм их адресации. Ори- гинальные сети с памятью требовали инструкции от учителя по использованию ячеек памяти. В работе Graves et al. (2014b) введено понятие нейронной машины Тьюринга\n--- Страница 353 ---\n352  Моделирование последовательностей: рекуррентные и рекурсивные сети (НМТ), способной обучиться чтению и записи произвольного содержимого в ячейки памяти без явных указаний со стороны учителя о том, какие действия предприни- мать. Там же описан сквозной процесс обучения без сигнала от учителя посредством механизма мягкого внимания, основанного на содержимом (см. Bahdanau et al.[2015] и раздел 12.4.5.1). Этот механизм мягкой адресации стал стандартом и в других род- ственных архитектурах, он позволяет эмулировать алгоритмические механизмы, не отказываясь от градиентной оптимизации (Sukhbaatar et al., 2015; Joulin and Mikolov, 2015; Kumar et al., 2015; Vinyals et al., 2015a; Grefenstette et al., 2015). Каждую ячейку памяти можно рассматривать как обобщение ячеек памяти в LSTM и GRU. Разница в том, что на выходе сети будет внутреннее состояние, которое вы- бирает, какую ячейку читать или записывать, точно так же, как при доступе к памяти компьютера задается адрес, по которому производить чтение или запись. Трудно оптимизировать функции, порождающие точные целочисленные адре- са. Чтобы как-то решить эту проблему, НМТ на самом деле читает и пишет сразу в несколько ячеек памяти. Результатом чтения является взвешенное среднее многих ячеек. А в процессе записи значения нескольких ячеек изменяются на разную вели- чину. Коэффициенты для этих операций подбираются так, чтобы сфокусироваться на небольшом числе ячеек, например с применением функции softmax. Использова- ние этих весов с ненулевыми производными позволяет применить метод градиент- ного спуска для оптимизации функций, управляющих доступом к памяти. Градиент по этим коэффициентам указывает, нужно ли их увеличить или уменьшить, но, как правило, градиент будет большим только для адресов памяти, получивших большой коэффициент. Ячейки памяти обычно дополняются возможностью хранить вектор, а не только одиночный скаляр, как в ячейках LSTM или GRU. Есть две причины для увеличения размера ячейки памяти. Первая состоит в том, что мы увеличили стоимость доступа к ячейке. Мы платим за порождение коэффициента для многих ячеек, но ожидаем, что эти коэффициенты кластеризуются вокруг небольшого числа ячеек. Читая век-торное, а не скалярное значение, мы амортизируем часть стоимости. Другая причи- на – то, что векторнозначные ячейки памяти допускают адресацию по содержимо- му, когда вес, используемый для чтения или записи ячейки, является функцией этой ячейки. Векторнозначные ячейки позволяют извлекать содержимое памяти целиком, если мы в состоянии сгенерировать образец, которому соответствуют некоторые, но не все элементы. Тут можно провести аналогию с тем, как человек вспоминает текст песни, услышав несколько слов. Инструкцию чтения на основе содержимого мож-но сравнить с указанием «извлечь слова песни, в которой есть припев “We all live in a yellow submarine”». Адресация по содержимому более полезна, когда извлекаемые объекты велики, – если бы каждая буква текста песни хранилась в отдельной ячейке памяти, мы не смогли бы найти их таким способом. Для сравнения – позиционная адресация не допускает ссылки на содержимое памяти. Инструкцию позиционной адресации можно было бы сформулировать так: «Извлечь слова песни по адресу 347». Позиционная адресация часто является вполне разумным механизмом, даже когда размер ячеек памяти мал. Если содержимое ячейки памяти копируется (а не забывается) на большинстве временных шагов, то хранящуюся в ней информацию можно распространять вперед во времени, а градиенты – назад во времени, не опасаясь ни исчезновения, ни взрыв- ного роста.\n--- Страница 354 ---\nЯвная память  353 Явная память иллюстрируется на рис. 10.18, где «нейронная сеть для решения за- дачи» сопряжена с памятью. Нейронная сеть может быть как прямого распростра- нения, так и рекуррентной, но система в целом является рекуррентной сетью. Сеть для решения задачи может выбирать, по каким адресам в памяти производить чтение или запись. Похоже, что явная память позволяет модели обучаться таким задачам, которые недоступны обыкновенным РНС или рекуррентным LSTM-сетям. Возмож-но, что одной из причин является тот факт, что информацию и градиенты можно рас- пространять (соответственно вперед и назад во времени) в течение очень длительных промежутков времени. Ячейки памяти Механизм записиМеханизм чтения Сеть для решения задачи, управляющая памятью Рис. 10.18  Схема сети с явной памятью, отражающая некоторые клю- чевые элементы проекта нейронной машины Тьюринга. На этом рисунке «репрезентативная» часть модели («сеть для решения задачи», в данном случае рекуррентная сеть внизу) отделена от «памяти» (набора ячеек), в ко- торой хранятся факты. Сеть для решения задачи обучается «управлять» памятью, т. е. решать, какие ячейки читать и записывать (с помощью меха- низмов чтения и записи, обозначенные жирными стрелками, которые ука- зывают на адреса) В качестве альтернативы обратному распространению посредством взвешенно- го среднего ячеек памяти мы можем интерпретировать коэффициенты адресации памяти как вероятности и стохастически читать только одну ячейку (Zaremba and Sutskever, 2015). Для оптимизации моделей, принимающих дискретные решения, нужны специальные алгоритмы, описанные в разделе 20.9.1. В настоящее время обуче ние стохастических архитектур, принимающих дискретные решения, остается более трудным делом, чем обучение детерминированных алгоритмов, принимающих мягкие решения. Не важно, является ли механизм выбора адреса мягким (допускающим обратное распространение) или стохастическим и жестким, по своей форме он идентичен ме- ханизму внимания, который мы уже упоминали в контексте машинного перевода (Bahdanau et al., 2015) и будем подробнее обсуждать в разделе 12.4.5.1. Идея механиз-\n--- Страница 355 ---\n354  Моделирование последовательностей: рекуррентные и рекурсивные сети мов внимания для нейронных сетей появилась даже раньше, в контексте генерации рукописных текстов (Graves, 2013), где этот механизм был ограничен только пере- мещением по последовательности вперед во времени. В случае машинного перевода и сетей с памятью фокус внимания на текущем и предыдущем шагах может находить- ся в совершенно разных местах. Рекуррентные нейронные сети позволяют распространить глубокое обучение на последовательные данные. Это последний из основных инструментов глубокого обуче ния в нашем арсенале. Далее мы перейдем к вопросу о том, как выбирать под- ходящие инструменты при решении реальных задач.",
      "debug": {
        "start_page": 317,
        "end_page": 355
      }
    },
    {
      "name": "Глава 11. Практическая методология 355",
      "content": "--- Страница 356 --- (продолжение)\nГлава 11 Практическая методология Для успешного применения глубокого обучения недостаточно просто хорошего зна- комства с существующими алгоритмами и принципами их работы. Настоящий спе- циалист должен еще знать, как выбрать алгоритм для конкретного приложения и как собрать и проанализировать полученные в ходе эксперимента данные, чтобы улуч- шить систему машинного обучения. В своей повседневной работе по созданию таких систем специалисту-практику приходится решать, нужно ли добавить еще данных, повысить или понизить емкость модели, добавить или убрать регуляризирующие признаки, стоит ли улучшить оптимизацию и приближенный вывод модели и как от- ладить ее программную реализацию. Все эти эксперименты занимают много времени, и это лишь самая меньшая из всех трудностей, поэтому так важно заранее выбрать правильный курс действий, а не тыкаться вслепую. Основная часть этой книги посвящена различным моделям машинного обучения, алгоритмам обучения и целевым функциям. Поэтому может сложиться впечатление, будто самое важное качество специалиста по машинному обучению – знать как много больше разных методов и хорошо разбираться в математике. Но на практике успеха обычно добивается тот, кто правильно применяет широко известный алгоритм, а не прибегает к запутанному алгоритму, толком не понимая, как он работает. Для пра- вильного применения алгоритма необходимо уверенно владеть какой-нибудь прос-той методологией. Многие рекомендации, приведенные в этой главе, заимствованы из работы Ng (2015). Мы рекомендуем применять на практике следующий процесс проектирования. Определите цели – какую вы будете использовать метрику ошибок и с чем сравнивать результаты для оценки ошибки. Метрика ошибок должна опреде-ляться решаемой задачей. Как можно скорее организуйте комплексный рабочий конвейер, включающий и оценку показателей качества. Оснастите систему измерительными средствами для определения узких мест. Диагностируйте компоненты, работающие хуже, чем ожидалось, и разберитесь, чем вызвано плохое качество: переобучением, недообучением или дефектами данных либо программ. Основываясь на результатах измерений, шаг за шагом вносите изменения: сбор новых данных, подстройку гиперпараметров или смену алгоритмов. В качестве примера мы будем использовать систему транскрипции уличных адре- сов Street View (Goodfellow et al., 2014d). Цель этого приложения – добавить здания\nГлава 11 Практическая методология Для успешного применения глубокого обучения недостаточно просто хорошего зна- комства с существующими алгоритмами и принципами их работы. Настоящий спе- циалист должен еще знать, как выбрать алгоритм для конкретного приложения и как собрать и проанализировать полученные в ходе эксперимента данные, чтобы улуч- шить систему машинного обучения. В своей повседневной работе по созданию таких систем специалисту-практику приходится решать, нужно ли добавить еще данных, повысить или понизить емкость модели, добавить или убрать регуляризирующие признаки, стоит ли улучшить оптимизацию и приближенный вывод модели и как от- ладить ее программную реализацию. Все эти эксперименты занимают много времени, и это лишь самая меньшая из всех трудностей, поэтому так важно заранее выбрать правильный курс действий, а не тыкаться вслепую. Основная часть этой книги посвящена различным моделям машинного обучения, алгоритмам обучения и целевым функциям. Поэтому может сложиться впечатление, будто самое важное качество специалиста по машинному обучению – знать как много больше разных методов и хорошо разбираться в математике. Но на практике успеха обычно добивается тот, кто правильно применяет широко известный алгоритм, а не прибегает к запутанному алгоритму, толком не понимая, как он работает. Для пра- вильного применения алгоритма необходимо уверенно владеть какой-нибудь прос-той методологией. Многие рекомендации, приведенные в этой главе, заимствованы из работы Ng (2015). Мы рекомендуем применять на практике следующий процесс проектирования. Определите цели – какую вы будете использовать метрику ошибок и с чем сравнивать результаты для оценки ошибки. Метрика ошибок должна опреде-ляться решаемой задачей. Как можно скорее организуйте комплексный рабочий конвейер, включающий и оценку показателей качества. Оснастите систему измерительными средствами для определения узких мест. Диагностируйте компоненты, работающие хуже, чем ожидалось, и разберитесь, чем вызвано плохое качество: переобучением, недообучением или дефектами данных либо программ. Основываясь на результатах измерений, шаг за шагом вносите изменения: сбор новых данных, подстройку гиперпараметров или смену алгоритмов. В качестве примера мы будем использовать систему транскрипции уличных адре- сов Street View (Goodfellow et al., 2014d). Цель этого приложения – добавить здания\n--- Страница 357 ---\n356  Практическая методология на карты Google Maps. Разъезжающие по городу автомобили Street View фотографи- руют здания и в каждой фотографии прикладывают GPS-координаты. Сверточная сеть распознает адрес дома на каждой фотографии, что позволяет Google Maps занести местонахождение соответствующего здания в базу данных. История разработки этого коммерческого приложения дает пример следования рекомендуемой методологии. Переходим к описанию шагов процесса. 11.1. Показатели качества Определение целей в терминах метрики ошибок – обязательный первый шаг, потому что от выбранной метрики ошибок зависят все последующие действия. Кроме того, вы должны понимать, какой уровень качества желателен. Помните, что для большинства приложений невозможно достичь полной безоши- бочности. Байесовская частота ошибок дает минимальную частоту, на которую мы можем рассчитывать, даже если объем обучающих данных бесконечен и есть возмож- ность восстановить истинное распределение вероятности. Причина может заклю-чаться в том, что входные признаки содержат неполную информацию о выходной величине, или в том, что система принципиально стохастическая. Кроме того, нас ограничивает конечный объем обучающих данных. Объем обучающих данных может быть ограничен по разным причинам. Если ваша цель – построить наилучший возможный продукт или услугу, то обычно можно со- брать больше данных, но следует сопоставить выигрыш от дальнейшего уменьшения ошибки со стоимостью сбора дополнительных данных. Для сбора данных нужны вре-мя, деньги, а возможно, даже страдания людей (если, к примеру, для получения дан- ных требуются инвазивные медицинские исследования). Если же цель – ответить на теоретический вопрос о том, какой алгоритм лучше работает на фиксированном эта- лонном тесте, то в спецификации теста обычно указан обучающий набор, и собирать дополнительные данные запрещено. Как определить разумный уровень ожидаемого качества? В академических иссле- дованиях обычно имеется некоторая оценка частоты ошибок, основанная на ранее опубликованных результатах эталонного тестирования. При разработке коммерче-ского продукта у нас есть представление о том, какая частота ошибок необходима, чтобы приложение можно было считать безопасным, рентабельным или привлека-тельным для пользователей. После того как реалистические требования к частоте ошибок сформулированы, в основе всех дальнейших решений должно быть стремле- ние к достижению этой частоты. Помимо целевого значения показателя качества, есть еще вопрос о выборе показа- теля. Для измерения эффективности полного приложения, включающего компонент машинного обучения, есть несколько показателей качества. Обычно это не то же самое, что функция стоимости, используемая при обучении модели. В разделе 5.1.2 отмеча- лось, что принято измерять верность, или, эквивалентно, частоту ошибок системы. Однако во многих приложениях нужны более содержательные метрики.Иногда одни ошибки обходятся гораздо дороже других. Например, в системе обна- ружения почтового спама возможны ошибки двух типов: неправильная классифика-ция нормального сообщения как спама и неправильный пропуск спама во входящую почту. Заблокировать нормальное сообщение гораздо хуже, чем пропустить сомни-тельное. Вместо того чтобы измерять частоту ошибок классификатора спама, хоте-\n--- Страница 358 ---\nПоказатели качества  357 лось бы измерить некую полную стоимость, в которой стоимость блокировки нор- мальных сообщений выше стоимости пропуска спама. Иногда требуется обучить бинарный классификатор, обнаруживающий редкие со- бытия, например тест для диагностики редкого заболевания. Предположим, что за- болевание встречается у одного человека на миллион. Мы легко можем получить для этой задачи распознавания верность 99.9999, просто заставив классификатор всегда сообщать об отсутствии заболевания. Очевидно, что верность не годится для оценки качества такой системы. Решить проблему можно, если измерять не верность, а точ- ность (precision) и полноту (recall). Точностью называется доля правильных ответов модели, а полнотой – доля обнаруженных истинных событий. Детектор, утверждаю- щий, что нет ни одного больного, имеет идеальную точность, но нулевую полноту. Детектор, утверждающий, что больны все, достигает идеальной полноты, но его точ-ность равна процентной доле людей, страдающих заболеванием (0.0001 в случае, ког- да заболеванием страдает один человек на миллион). При использовании точности и полноты часто строят ТП-кривую, когда по оси y откладывается точность, а по оси x – полнота. Порождаемая классификатором оценка выше, если подлежащее обна- ружению событие действительно произошло. Например, сеть прямого распростра-нения, предназначенная для обнаружения болезни, выводит оценку yˆ = P(y = 1 | x) вероятности того, что человек, чьи медицинские анализы описываются признаками x, болен. Сеть сообщает, что событие обнаружено, если эта оценка превышает заданный порог. Варьируя порог, мы можем отдавать предпочтение либо точности, либо полно-те. Во многих случаях желательно охарактеризовать качество классификатора одним числом, а не кривой. Для этого точность p и полнота r объединяются в F-меру: (11.1) Еще один вариант – сообщать площадь под ТП-кривой. В некоторых приложени- ях система машинного обучения может отказаться принимать решение. Это полез-но, если алгоритм способен оценить степень уверенности в своем решении, особенно если неверное решение может нанести вред, а у оператора есть возможность взять от- ветственность на себя. Примером может служить система транскрипции Street View. Ее задача – найти на фотографии номер дома, чтобы можно было связать координаты места съемки с адресом на карте. Поскольку ценность неточной карты резко снижа- ется, важно добавлять адрес, только если транскрипция правильна. Если система ма-шинного обучения полагает, что правильность транскрипции сомнительна, то лучше всего перепоручить обработку фотографии человеку. Разумеется, система полезна, только если она кардинально уменьшает количество фотографий, требующих внима-ния человека. В этой ситуации естественным показателем качества является покры- тие, т. е. доля примеров, для которых система смогла дать ответ. Необходимо соблю- дать баланс между покрытием и верностью. Всегда можно получить стопроцентную верность, вообще отказавшись от обработки примеров, но тогда покрытие упадет до 0. В проекте Street View ставилась задача добиться верности транскрипции, не усту- пающей человеку, при 95-процентном покрытии. Считалось, что человек правильно транскрибирует адрес в 98% случаев. Существует много других метрик. Например, можно измерять кликабельность, проводить опрос удовлетворенности пользователей и т. д. В специализированных приложениях применяются также специальные критерии.\n--- Страница 359 ---\n358  Практическая методология Важно заранее определить, какой показатель качества мы будем улучшать, а затем сконцентрироваться на этой цели. Не имея четко сформулированных целей, трудно сказать, принесло некое изменение системы успех или нет. 11.2. Выбор базовой модели по умолчанию После выбора целей и показателей качества следующим шагом разработки любого практического приложения является организация разумной комплексной системы, причем делать это надо как можно раньше. В этом разделе мы порекомендуем, с ка- ких алгоритмов начинать в различных ситуациях. Помните, что прогресс в области глубокого обучения стремительный, поэтому вполне вероятно, что вскоре после вы-хода этой книги из печати наилучшими по умолчанию будут считаться другие алго-ритмы. В зависимости от сложности задачи вы, возможно, захотите на начальной стадии вообще обойтись без глубокого обучения. Если есть шанс, что задачу удастся решить, просто правильно подобрав несколько линейных весов, то лучше начать с простой статистической модели типа логистической регрессии. Если заведомо понятно, что задача относится к «ИИ в чистом виде», как, например, распознавание объектов, распознавание речи, машинный перевод и т. д., то для начала стоит выбрать подходящую модель глубокого обучения. Прежде всего выберите общую категорию моделей, исходя из структуры своих данных. Если вам нужно провести обучение с учителем с векторами фиксированного размера на входе, возьмите сеть прямого распространения с полносвязными слоями. Если известна топологическая структура входа (например, входом является изобра-жение), то воспользуйтесь сверточной сетью. В этих случаях начинать следует с ка- кого-нибудь кусочно-линейного блока (ReLU или его обобщения: Leaky ReLU, PreLu или maxout). Если входом или выходом является последовательность, то пользуйтесь вентильной рекуррентной сетью (LSTM или GRU). В качестве алгоритма оптимизации стоит взять СГС с импульсом и затухающей скоростью обучения (к числу популярных схем затухания, которые на одних задачах работают лучше, на других хуже, относятся: линейное затухание до достижения фик-сированной минимальной скорости обучения, экспоненциальное затухание и умень- шение скорости обучения в 2–10 раз при каждом выходе ошибки на контрольном наборе на плато). Еще одна разумная альтернатива – Adam. Пакетная нормировка может оказать заметное влияние на качество оптимизации, особенно в случае свер- точных сетей и сетей с сигмоидными нелинейностями. Хотя на первой итерации име- ет смысл опустить пакетную нормировку, к ней следует вернуться сразу, как только в ходе оптимизации появятся признаки проблем. Если обучающий набор не насчитывает десятков миллионов примеров, следует с самого начала включить какие-то мягкие формы регуляризации. Ранняя останов- ка – почти универсальная рекомендация. Прореживание – отличный способ регуля- ризации, легко реализуемый и совместимый со многими моделями и алгоритмами обучения. Пакетная нормировка также иногда уменьшает ошибку обобщения и по- зволяет отказаться от прореживания благодаря шуму в оценке статистик, вносимому для нормировки каждой переменной. Если ваша задача похожа на какую-то другую, уже хорошо изученную, то вы по- ступите мудро, если для начала скопируете модель и алгоритм, которые показали\n--- Страница 360 ---\nНадо ли собирать дополнительные данные?  359 наилучшие результаты раньше. Возможно, стоит даже скопировать уже обученную модель. Например, при решении разных задач компьютерного зрения нередко ис-пользуются признаки из сверточной сети, обученной на наборе данных ImageNet (Girshick et al., 2015). Часто задают вопрос, стоит ли начинать с обучения без учителя, описанного далее в части III. Все зависит от предметной области. Известно, что в некоторых задачах, скажем в обработке естественного языка, методы обучения без учителя, например по- гружение слов, приносят колоссальный эффект. А, к примеру, в компьютерном зре- нии современные методы обучения без учителя не дают особого выигрыша, за исклю-чением обучения с частичным привлечением учителя, когда помеченных примеров очень мало (Kingma et al., 2014; Rasmus et al., 2015). Если ваше приложение относится к классу задач, для которых польза обучения без учителя доказана, включайте такую модель уже в первую версию комплексной системы. В противном случае поступай- те так, только если решаемая задача принципиально не подразумевает учителя. Вы всегда сможете добавить обучение без учителя позже, если заметите, что начальная базовая модель переобучена. 11.3. Надо ли собирать дополнительные данные? Построив начальный вариант комплексной системы, можно приступать к измерению качества алгоритма и поиску способов его улучшения. Часто начинающие испытыва- ют соблазн что-то улучшить, пробуя много разных алгоритмов. Но обычно гораздо разумнее собрать больше данных, чем пытаться улучшить алгоритм обучения. Как решить, следует ли собирать дополнительные данные? Прежде всего опре- делите, устраивает ли вас качество на обучающем наборе. Если качество плохое, то алгоритм обучения не использует должным образом даже тех данных, что уже есть, так что собирать новые бессмысленно. Попробуйте вместо этого увеличить размер модели, добавив слои или скрытые блоки в каждый слой. Попробуйте также поиграть с алгоритмом обучения, например настройте гиперпараметр скорости обучения. Если модель большая и алгоритмы оптимизации тщательно настроены, а результата все равно нет, то, возможно, проблема в качестве обучающих данных. Быть может, они слишком сильно зашумлены или не содержат входов, необходимых для правильного предсказания выходов. Тогда стоит начать все сначала, собрав более чистые данные или используя улучшенный набор признаков. Если качество на обучающем наборе приемлемое, то измерьте качество на тестовом наборе. Если и оно приемлемое, то все уже сделано. Если же качество на тестовом наборе гораздо хуже, чем на обучающем, то сбор дополнительных данных – одно из самых эффективных решений. Главное, что нужно принять во внимание, – стоимость и саму возможность сбора дополнительных данных, стоимость и возможность умень- шить ошибку тестирования другими способами, а также ожидаемый объем данных, при котором можно будет значительно повысить качество на тестовом наборе. Боль-шие интернет-компании с миллионами и миллиардами пользователей могут собрать большие наборы данных, и стоимость этого мероприятия может оказаться намного ниже альтернатив, поэтому ответ почти всегда – увеличить объем обучающих дан- ных. Например, разработка больших размеченных наборов данных была одним из главных факторов успеха при решении задачи о распознавании объектов. В других контекстах, например в медицинских приложениях, сбор дополнительных данных\n--- Страница 361 ---\n360  Практическая методология может стоить дорого или вообще невозможен. Простая альтернатива сбору дополни- тельных данных – уменьшить размер модели или улучшить регуляризацию, добавив такие параметры, как коэффициенты снижения весов, или включив такие стратегии регуляризации, как прореживание. Если разрыв между качеством на обучающем и тестовом наборах остается неприемлемым даже после настройки гиперпараметров регуляризации, то рекомендуется собрать еще данные. При решении вопроса о сборе дополнительных данных нужно еще определиться, сколько именно данных необходимо. Тут полезно построить кривые зависимости между размером обучающего набора и ошибкой обобщения, как на рис. 5.4. Экстра- поляция таких кривых может подсказать, сколько еще данных необходимо для дос-тижения требуемого уровня качества. Обычно незначительное увеличение общего числа примеров не оказывает заметного влияния на ошибку обобщения. Поэтому рекомендуется применять к размеру обучающего набора логарифмический масштаб, например удваивать число примеров в каждом новом эксперименте. Если собрать намного больше данных невозможно, то остается только один способ уменьшить ошибку обобщения – улучшить сам алгоритм обучения. Но это уже на- учно-исследовательская работа, а не рекомендации для специалистов-прикладников. 11.4. Выбор гиперпараметров Во многих алгоритмах глубокого обучения имеются гиперпараметры, управляющие различными аспектами поведения алгоритма. Одни влияют на время работы и по- требление памяти, другие – на качество модели, восстанавливаемой в процессе обуче- ния, и на ее способность давать правильные результаты при предъявлении новых примеров. Есть два основных подхода к выбору гиперпараметров: ручной и автоматический. Для выбора вручную нужно понимать, для чего предназначен каждый гиперпараметр и как модель машинного обучения достигает хорошей обобщаемости. Алгоритмы ав- томатического выбора не требуют от пользователя понимания всех этих тонкостей, но зачастую обходятся гораздо дороже с вычислительной точки зрения. 11.4.1. Ручная настройка гиперпараметров Для ручного задания гиперпараметров необходимо понимать связи между гиперпа-раметрами, ошибкой обучения, ошибкой обобщения и вычислительными ресурсами (памятью и временем работы), а следовательно, основательное знакомство с фунда- ментальными идеями, касающимися эффективной емкости алгоритма обучения, ко-торые были изложены в главе 5. Целью ручной настройки обычно является достижение наименьшей ошибки обобщения при ограничениях на время работы и потребление памяти. Мы не будем обсуж дать, как различные гиперпараметры влияют на время работы и объем памяти, поскольку это сильно зависит от платформы. Основная цель ручного подбора гиперпараметров – привести эффективную ем- кость модели в соответствие со сложностью задачи. Эффективная емкость ограниче- на тремя факторами: репрезентативной емкостью модели, способностью алгоритма обучения минимизировать функцию стоимости, используемую для обучения моде-ли, и степенью регуляризации модели посредством функции стоимости и процедуры обучения. Чем больше число слоев модели и число скрытых блоков в каждом слое,\n--- Страница 362 ---\nВыбор гиперпараметров  361 тем выше репрезентативная емкость, т. е. модель может представить более сложные функции. Но она не сможет обучиться всем этим функциям, если алгоритм обучения не способен установить, что некоторые функции хорошо минимизируют стоимость, или если регуляризирующие члены, например снижение весов, запрещают использо-вание некоторых функций. График ошибки обобщения как функции одного из гиперпараметров обычно имеет вид U-образной кривой (рис. 5.3). На одном конце значение гиперпараметра соот-ветствует низкой емкости, а ошибка обобщения велика, потому что велика ошибка обучения. Это режим недообучения. На другом конце значение гиперпараметра со-ответствует высокой емкости, а ошибка обобщения велика, потому что велик разрыв между ошибкой обучения и тестирования. Где-то посередине находится оптимальная емкость модели, при которой ошибка обобщения минимальна, поскольку и разрыв, и ошибка обучения умеренные. Для некоторых гиперпараметров слишком большое значение приводит к пере- обучению. Примером может служить число скрытых блоков в слое, поскольку с уве- личением числа скрытых блоков возрастает емкость модели. А бывает и наоборот – когда к переобучению ведет малое значение гиперпараметра. Например, наименьшее допустимое значение коэффициента снижения весов, равное нулю, соответствует наибольшей эффективной емкости алгоритма обучения. Не каждый гиперпараметр принимает все значения, лежащие на U-образной кри- вой. Многие гиперпараметры дискретны, как, например, число блоков в слое или число линейных участков maxout-блока, так что им соответствует лишь несколько точек на кривой. Бывают и бинарные гиперпараметры. Обычно это переключатели, которые говорят, нужно ли использовать какую-то необязательную компоненту алго-ритма обучения, например шаг предобработки, на котором производится нормировка входных признаков (вычитание среднего и деление на стандартное отклонение). Та- ким гиперпараметрам соответствуют всего две точки на кривой. У некоторых гипер- параметров есть минимальное или максимальное значения, ограничивающие область их присутствия на кривой. Например, минимальный коэффициент снижения весов равен нулю. Это означает, что если модель недообучена, когда снижение весов ну-левое, то путем модификации коэффициента снижения мы не сможем попасть в об- ласть переобучения. Иными словами, некоторые гиперпараметры способны только уменьшить емкость. Пожалуй, самым важным гиперпараметром является скорость обучения. Если у вас есть время для настройки только одного гиперпараметра, займитесь скоростью обучения. Она управляет эффективной емкостью модели не столь прямо, как осталь-ные гиперпараметры: эффективная емкость максимальна, когда скорость обучения правильно подобрана для задачи оптимизации, а не когда она особенно велика или мала. График зависимости ошибки обучения от скорости обучения имеет U-образную форму, показанную на рис. 11.1. Если скорость обучения слишком велика, то ме-тод градиентного спуска может по случайности увеличить, а не уменьшить ошибку обуче ния. В идеализированном квадратичном случае это происходит, когда скорость обучения не менее чем в два раза превосходит оптимальное значение (LeCun et al., 1998a). Если скорость обучения слишком мала, то обучение не только протекает мед-ленно, но может и вообще застрять, так и не добившись снижения ошибки обучения. Этот феномен пока понят плохо (но такое не может произойти для выпуклой функ-ции потерь).\n--- Страница 363 ---\n362  Практическая методология Ошибка обучения 8 76543210 10 –210–1100 Скорость обучения (в логарифмическом масштабе) Рис. 11.1  Типичная зависимость ошибки обучения от скорости обуче- ния. Обратите внимание на резкое возрастание ошибки, когда скорость выше оптимального значения. Это относится к фиксированному времени обучения, потому что снижение скорости обучения иногда может всего лишь замедлить обучение пропорционально уменьшению скорости. Ошиб- ка обобщения может описываться этой же кривой или осложняется эффек- тами регуляризации, возникающими из-за слишком большой или слишком малой скорости обучения, поскольку неудачная оптимизация может до некоторой степени уменьшить или вообще предотвратить переобучение, и даже в точках с одинаковой ошибкой обучения ошибка обобщения может различаться Для настройки параметров, отличных от скорости обучения, необходимо следить за ошибкой обучения и тестирования, чтобы понять, является ли модель переобучен- ной или недообученной, а затем соответственно подкорректировать емкость. Если ошибка на обучающем наборе выше целевой частоты ошибок, то нет другого выбора, кроме как увеличить емкость. Если вы не пользуетесь регуляризацией, но уверены в правильности алгоритма оптимизации, то следует увеличить число слоев сети или добавить скрытые блоки. К сожалению, это увеличивает вычислительную стоимость модели. Если ошибка на тестовом наборе выше целевой частоты ошибок, то можно посту- пить двояко. Ошибка тестирования равна сумме ошибки обучения и разрыва между ошибкой тестирования и ошибкой обучения. Для нахождения оптимальной ошиб- ки тестирования нужно сбалансировать эти величины. Нейронные сети обычно ра-ботают оптимально, когда ошибка обучения очень мала (а потому емкость велика), а ошибка тестирования в основном обусловлена разрывом между ошибкой обуче ния и тестирования. Ваша цель – уменьшить этот разрыв, не увеличивая ошибку обуче- ния быстрее, чем сокращается разрыв. Для уменьшения разрыва измените гиперпара-метры регуляризации, так чтобы уменьшить эффективную емкость модели, например добавьте прореживание или снижение весов. Обычно наилучшее качество достигает- ся для большой хорошо регуляризированной (например, с помощью прореживания) модели. Большинство гиперпараметров можно задать, поняв, увеличивают они емкость мо- дели или уменьшают. В табл. 11.1 приведено несколько примеров.\n--- Страница 364 ---\nВыбор гиперпараметров  363 Таблица 11.1. Влияние различных гиперпараметров на емкость модели Гипер- параметрУвеличивает емкость, когда…Причина Подводные камни Число скрытых блоковВозрастает Увеличение числа скрытых блоков увеличивает репрезен-тативную емкость моделиУвеличение числа скрытых блоков приводит к увеличению времени работы и объема потребляемой памяти для всех операций модели Скорость обученияНастроена оптимальноЕсли скорость обучения слиш-ком велика или слишком мала, эффективная емкость модели падает из-за плохой оптими-зации Ширина ядра сверткиВозрастает Чем больше ширина ядра, тем больше параметров у моделиУвеличение ширины ядра при-водит к уменьшению ширины выхода, а значит, и к умень-шению емкости модели, если только не применяется допол-нение нулями для компенсации этого эффекта. Чем шире ядро, тем больше памяти нужно для хранения параметров и тем больше время работы, однако уменьшение ширины выхода снижает потребление памяти Неявное дополнение нулямиВозрастает Добавление неявных нулей перед сверткой позволяет со-хранить объем представленияУвеличивается время работы и потребление памяти Коэффици-ент сниже-ния весовУбывает Благодаря уменьшению коэффициента снижения весов открывается возмож-ность для увеличения пара-метров модели Коэффици-ент проре-живанияУбывает Не столь частое выбрасывание блоков дает блокам возмож-ность «договориться» между собой об аппроксимации обучаю щего набора Увлекшись ручной настройкой гиперпараметров, не упустите из виду конечную цель: хорошее качество на тестовом наборе. Один из путей достижения этой цели – до- бавление регуляризации. При условии что ошибка обучения остается малой, вы всегда можете уменьшить ошибку обобщения, собрав дополнительные обучающие данные. Лобовой способ, практически гарантирующий успех, – продолжать увеличивать ем- кость модели и размер обучающего набора, пока задача не будет решена. Конечно, при этом растет вычислительная стоимость обучения и вывода, так что применять этот способ можно только при наличии достаточных ресурсов. В принципе, этот подход может потерпеть неудачу из-за трудностей оптимизации, но для многих задач опти-мизация не является серьезным барьером, если только выбрана подходящая модель. 11.4.2. Алгоритмы автоматической оптимизации гиперпараметров Идеальный алгоритм обучения принимает набор данных и выводит функцию, не требуя ручной настройки гиперпараметров. Популярность таких алгоритмов, как ло-\n--- Страница 365 ---\n364  Практическая методология гистическая регрессия и метод опорных векторов, зиждется на способности хорошо работать после настройки всего одного-двух гиперпараметров. Нейронные сети ино- гда тоже показывают неплохие результаты при небольшом числе гиперпараметров, но чаще настраивать приходится сорок, а то и больше. Ручная настройка гиперпара- метров может дать отличный эффект, если у пользователя есть хорошая отправная точка, например определенная другими исследователями, работавшими с аналогич- ным приложением и архитектурой, или если пользователь имеет многомесячный или многолетний опыт изучения оптимальных значений гиперпараметров для подобных нейронных сетей. Увы, для многих приложений такой отправной точки нет. И тогда к отысканию полезных значений гиперпараметров можно привлечь автоматизиро- ванные алгоритмы. Поразмыслив о том, как пользователь алгоритма обучения ищет хорошие значения гиперпараметров, мы придем к выводу о наличии оптимизации: мы пытаемся най- ти такие значения, которые оптимизируют некоторую целевую функцию, например ошибку на контрольном наборе, иногда в условиях ограничений (на время обучения, на потребление памяти или на время распознавания). Поэтому, в принципе, возмож- но разработать алгоритмы оптимизации гиперпараметров, которые обертывают ал- горитм обучения и подбирают для него гиперпараметры, скрывая их от пользователя. К сожалению, у алгоритмов оптимизации гиперпараметров есть свои гиперпарамет- ры, например диапазон потенциальных значений каждого из гиперпараметров алго-ритма обучения. Но такие вторичные гиперпараметры задать обычно проще в том смысле, что один и тот же их набор позволяет добиться приемлемого качества для широкого круга задач. 11.4.3. Поиск на сетке Когда гиперпараметров всего три или того меньше, часто прибегают к поиску на сет- ке. Для каждого гиперпараметра пользователь выбирает небольшое конечное мно-жество потенциальных значений. Затем алгоритм поиска обучает модель для каждой возможной комбинации значений гиперпараметров. Наилучшими считаются гипер-параметры, при которых была достигнута наименьшая ошибка на контрольном на-боре. На рис. 11.2 слева показана сетка значений гиперпараметров. Как выбирать списки потенциальных значений? В случае числовых (упорядочен- ных) гиперпараметров наибольший и наименьший элементы каждого списка выби- раются с запасом, основываясь на результатах аналогичных экспериментов в прош- лом, чтобы оптимальное значение с большой вероятностью оказалось в выбранном диапазоне. Как правило, при поиске на сетке значения выбираются примерно в лога- рифмическом масштабе, например скорость обучения берется из множества {0.1, 0.01, 10 –3, 10–4, 10–5}, а число скрытых блоков – из множества {50, 100, 200, 500, 1000, 2000}. Поиск на сетке обычно дает наилучшие результаты, если повторяется несколько раз. Предположим, к примеру, что мы провели поиск на сетке гиперпараметра α с по- тенциальными значениями {–1, 0, 1}. Если наилучшим оказалось значение 1, то мы не полностью рассмотрели диапазон, в котором находится оптимальное значение α, и потому должны повторить поиск на сдвинутой сетке, например {1, 2, 3}. Если же наилучшим оказалось значение 0, то следует уточнить оценку, уменьшив масштаб, например, на сетке {–0.1, 0, 0.1}. С поиском на сетке связана очевидная проблема: вычислительная стоимость экс- поненциально растет с увеличением числа гиперпараметров. Если имеется m гипер-\n--- Страница 366 ---\nВыбор гиперпараметров  365 параметров и каждый принимает n значений, то число раундов обучения-вычисления растет как O(nm). Раунды можно распараллелить, причем между машинами, на кото- рых производятся вычисления, почти не требуется передавать данных. К сожалению, из-за экспоненциальной стоимости поиска на сетке даже распараллеливание может не принести желаемых результатов. На сетке Случайный Рис. 11.2  Сравнение поиска на сетке и случайного поиска. Для на- глядности показаны всего два гиперпараметра, но на практике их обычно гораздо больше. (Слева) Для поиска на сетке задается множество значе- ний каждого гиперпараметра. Алгоритм производит обучение для каждой комбинации этих значений. (Справа) Для случайного поиска задается рас-пределение вероятности совместных конфигураций гиперпараметров. Как правило, гиперпараметры независимы друг от друга. В качестве распре- деления одного гиперпараметра часто берут равномерное или логариф- мически равномерное (для выборки из логарифмически равномерного распределения нужно взять экспоненту значения, выбранного из равно-мерного распределения). Алгоритм поиска производит случайную выборку из совместного распределения гиперпараметров и выполняет обучение для каждой выбранной комбинации. Оба алгоритма – поиска на сетке и слу- чайного поиска – вычисляют ошибку на контрольном наборе и возвращают лучшую из найденных конфигураций. На рисунке показан типичный случай, когда лишь некоторые гиперпараметры оказывают существенное влияние на результат. В данном случае существенным оказался только гиперпара- метр, отложенный по горизонтальной оси. Время, впустую расходуемое алгоритмом поиска на сетке, экспоненциально зависит от числа несуще-ственных гиперпараметров, тогда как алгоритм случайного поиска почти на каждом испытании проверяет уникальные значения каждого существен- ного гиперпараметра. Рисунок взят из работы Bergstra and Bengio (2012) с разрешения авторов 11.4.4. Случайный поиск По счастью, поиску на сетке есть альтернатива, которая столь же проста для програм- мирования, но удобнее в использовании и сходится к хорошим значениям гиперпара- метров гораздо быстрее: случайный поиск (Bergstra and Bengio, 2012). Случайный поиск производится следующим образом. Сначала задаем маргиналь- ное распределение каждого гиперпараметра, например распределение Бернулли и ка-\n--- Страница 367 ---\n366  Практическая методология тегориальное распределение для бинарных и дискретных параметров соответственно либо логарифмически равномерное распределение для гиперпараметров, принимаю- щих положительные вещественные значения. Например: log_learning_rate ∼ u(–1, –5), (11.2) log_learning_rate = 10log_learning_rate, (11.3) где u(a, b) – выборка из равномерного распределения в интервале (a, b). Аналогично log_number_of_hidden_units можно выбрать из u(log(50), log(2000)). В отличие от поиска на сетке, здесь не нужно дискретизировать значения гиперпа- раметров, поэтому можно исследовать более широкое множество значений, избежав дополнительных вычислительных затрат. Как показано на рис. 11.2, случайный по-иск может оказаться экспоненциально эффективнее поиска на сетке, если существует несколько гиперпараметров, не оказывающих существенного влияния на показатель качества. Этот вопрос скрупулезно изучен в работе Bergstra and Bengio (2012), где по- казано, что случайный поиск снижает ошибку на контрольном наборе гораздо быст-рее, чем поиск на сетке, если оценивать по числу раундов. Как и при поиске на сетке, зачастую имеет смысл повторить случайный поиск, что- бы уточнить значения, найденные при первом прогоне. Основная причина, по которой случайный поиск находит хорошие решения быст- рее, чем поиск на сетке, – отсутствие лишних экспериментальных раундов, встречаю- щихся при поиске на сетке, когда два значения некоторого гиперпараметра (при за-данных значениях остальных) дают один и тот же результат. При поиске на сетке у остальных значений гиперпараметра в этих двух раундах будут одинаковые значе- ния, а при случайном поиске – обычно разные. Поэтому если различие между этими двумя значениями не оказывает существенного влияния на ошибку на контрольном наборе, то поиск на сетке без нужды повторяет два эквивалентных эксперимента, тог-да как случайный поиск произведет два независимых испытания других гиперпара-метров. 11.4.5. Оптимизация гиперпараметров на основе модели Поиск хороших значений гиперпараметров можно рассматривать как задачу оптими-зации. Параметрами решения являются гиперпараметры. Подлежащая оптимизации функция стоимости – ошибка на контрольном наборе, возникающая при обучении с такими гиперпараметрами. В упрощенной постановке, когда можно вычислить гра- диент какой-то дифференцируемой метрики ошибки на контрольном наборе относи-тельно гиперпараметров, мы можем просто двигаться в направлении этого градиента (Bengio et al., 1999; Bengio, 2000; Maclaurin et al., 2015). К сожалению, в большинстве практических задач этот градиент недоступен – либо из-за высокой стоимости вы- числений и потребности в памяти, либо потому что взаимодействие гиперпараметров с ошибкой на контрольном наборе описывается недифференцируемой функцией, как в случае дискретных гиперпараметров. Чтобы компенсировать отсутствие градиента, мы можем построить модель ошиб- ки на контрольном наборе, а затем выдвинуть гипотезу о значениях гиперпараметров, выполнив оптимизацию в рамках этой модели. В большинстве подобных алгоритмов поиска гиперпараметров применяется байесовская модель регрессии для оценки как ожидаемого значения ошибки для каждого гиперпараметра, так и неопределенности\n--- Страница 368 ---\nСтратегии отладки  367 этой оценки. Таким образом, оптимизация подразумевает поиск компромисса между исследованием (предложением гиперпараметров с высокой неопределенностью, ко- торые могут дать заметное улучшение, а могут и не дать) и использованием (пред- ложением гиперпараметров, относительно которых модель уверена, что они будут работать так же хорошо, как виденные ей ранее, – обычно это значения, очень близ- кие к наблюдавшимся прежде). Из современных подходов к оптимизации гиперпара- метров отметим алгоритмы Spearmint (Snoek et al., 2012), TPE (Bergstra et al., 2011) и SMAC (Hutter et al., 2011). В настоящее время мы не можем однозначно порекомендовать байесовскую опти- мизацию гиперпараметров в качестве общепринятого средства улучшения результа- тов глубокого обучения или получения результатов с меньшими усилиями. Иногда байесовская оптимизация дает результаты, сравнимые с полученными человеком, иногда даже лучшие, но терпит катастрофические неудачи на других задачах. По-смотреть, как она будет работать на конкретной задаче, пожалуй, имеет смысл, но пока этот подход нельзя назвать ни зрелым, ни надежным. Тем не менее оптимизация гиперпараметров – важная область исследований, и хотя ее развитием движут в ос- новном потребности глубокого обучения, ее достижения сулят выигрыш не только машинному обучению в целом, но и всем техническим дисциплинам. Всем алгоритмам оптимизации гиперпараметров, более сложным, чем случайный поиск, присущ общий недостаток: чтобы из раунда обучения можно было извлечь полезную информацию, он должен быть доведен до конца. Это сильно снижает эф-фективность, поскольку обычно уже на ранних стадиях эксперимента человек может сказать, что некоторая комбинация гиперпараметров абсолютно бессмысленна. В ра- боте Swersky et al. (2014) приведена первая версия алгоритма, который хранит набор из нескольких экспериментов. В различные моменты времени алгоритм оптимиза- ции гиперпараметров может принять решение: начать новый эксперимент, «заморо-зить» текущий эксперимент, не обещающий ничего интересного, или «разморозить» и возоб новить эксперимент, который ранее был заморожен, но теперь, с появлением новой информации, выглядит многообещающе. 11.5. Стратегии отладки Если система машинного обучения работает плохо, то обычно трудно сказать, в чем корень зла: то ли это недостаток самого алгоритма, то ли ошибка в его реализации. Отладка систем машинного обучения затруднена по разным причинам. В большинстве случаев нам заранее неизвестно предполагаемое поведение алго- ритма. Ведь суть машинного обучения в том и состоит, чтобы выявить некое полезное поведение, которое мы не смогли описать сами. Если мы обучили нейронную сеть новой задаче классификации и получили на тестовом наборе ошибку 5 процентов, то как узнать, ожидаемое это поведение или далеко не оптимальное? Следующая трудность заключается в том, что у большинства моделей машинного обучения несколько частей, и все они адаптивны. Если какая-то часть работает непра- вильно, то остальные могут адаптироваться, и общее качество останется более-менее приемлемым. Предположим, к примеру, что мы обучаем нейронную сеть с несколь- кими слоями, параметризованными весами W и смещениями b. Предположим еще, что мы вручную реализовали правила градиентного спуска для каждого параметра в отдельности, но допустили ошибку в обновлении смещений:\n--- Страница 369 ---\n368  Практическая методология b ⟵ b – α, (11.4) где α – скорость обучения. В этом ошибочном правиле обновления градиент не ис- пользуется вовсе. Поэтому в ходе обучения смещения всегда будут становиться отри- цательными, что, очевидно, не может считаться корректной реализацией разумного алгоритма обучения. Но найти эту ошибку путем изучения выхода модели не всегда легко. При некоторых распределениях входных данных веса могут адаптироваться и компенсировать отрицательные смещения. Большинство стратегий отладки нейронных сетей предназначено для преодоления одной из этих трудностей или сразу обеих. Либо мы строим тест настолько простой, что правильное поведение можно предсказать, либо такой, в котором проверяется лишь одна часть реализации сети изолированно от остальных. Перечислим несколько важных стратегий отладки.Визуализировать модель в действии. Во время обучения модели обнаружения объ- ектов в изображении показать несколько изображений с наложенными контурами обнаруженных объектов. Если обучается порождающая модель речи, прослушать не-сколько сгенерированных ей образчиков. Вроде бы совершенно очевидно, но очень легко впасть в грех ознакомления только с количественными измерениями качества работы, например верности или логарифмического правдоподобия. Прямое наблюде-ние за тем, как модель справляется со своей задачей, помогает установить, являются ли достигнутые ей количественные показатели разумными. Ошибки оценивания мо-гут быть самыми губительными, потому что вселяют уверенность, что система рабо-тает правильно, хотя на самом деле это совсем не так. Визуализация самых серьезных ошибок. Большинство моделей может вывести какой-то показатель уверенности в полученных результатах. Например, классифи- каторы, в которых выходной слой основан на функции softmax, назначают вероят- ность каждому классу. Следовательно, вероятность, назначенная самому вероятному классу, и дает оценку уверенности модели в принятом решении. Обычно обучение на основе максимального правдоподобия дает завышенные оценки, а не точные веро- ятности правильного предсказания, но все равно они полезны, поскольку примеры, которые с меньшей вероятностью помечены правильно, получат от модели меньшую оценку вероятности. Изучив примеры, для которых модель испытывает наибольшие трудности, зачастую удается вскрыть проблемы в предобработке или пометке данных. Например, в системе транскрипции Street View была ошибка, из-за которой система обнаружения номера дома слишком сильно обрезала изображение, так что несколько цифр выпадало из кадра. Затем сеть транскрипции назначала слишком низкую ве-роятность правильному ответу для таких изображений. После того как ошибка была исправлена и ширина обрезанного кадра стало гораздо больше, качество системы в целом резко возросло, хотя сети пришлось иметь дело с большей вариативностью позиций и масштабов номеров домов. Логическое рассуждение о программе с использованием ошибок обучения и тестиро- вания. Часто бывает трудно определить, правильно ли реализована программа. Кое-какую информацию можно получить из анализа ошибок обучения и тестирования. Если ошибка обучения мала, а ошибка тестирования велика, то, вероятно, процедура обучения работает правильно, а модель переобучена вследствие фундаментальных алгоритмических причин. Возможно также, что ошибка тестирования измерена не-правильно из-за проблем в связи с сохранением обученной модели и последующей\n--- Страница 370 ---\nСтратегии отладки  369 ее загрузкой для обработки тестового набора или из-за того, что тестовые данные го- товились не так, как обучающие. Если и ошибка обучения, и ошибка тестирования велики, то трудно сказать, то ли это дефект программы, то ли модель недообучена вследствие фундаментальных алгоритмических причин. В таком случае необходимы дополнительные тесты, описанные ниже. Аппроксимация крохотного набора данных. Если ошибка на обучающем наборе ве- лика, нужно решить, в чем причина: в недообученности или в дефекте программы. Обычно даже небольшую модель можно гарантированно обучить аппроксимации достаточно малого набора. Например, если набор для обучения классификатора со-держит всего один пример, то для его аппроксимации достаточно просто правильно установить смещения в выходном слое. Если вы не можете обучить классификатор правильно помечать один пример, автокодировщик – успешно воспроизводить один пример с высокой точностью, или порождающую модель – устойчиво генерировать примеры, напоминающие заданный, то следует заподозрить ошибку в программе, препятствующую успешной оптимизации на обучающем наборе. Этот тест можно обобщить на наборы данных с небольшим числом примеров. Сравнение производных, вычисленных методом обратного распространения, с чис- ленными производными. Если программная система требует, чтобы вы самостоятель-но реализовали вычисления градиента, или если вы добавили новую операцию в биб- лиотеку дифференцирования и должны определить для нее метод bprop , то частой причиной ошибок является некорректная реализация выражения градиента. Прове-рить, так ли это, можно, сравнив производные, вычисленные вашей процедурой авто-матического дифференцирования, с производными, вычисленными методом конеч- ных разностей. Поскольку (11.5) мы можем аппроксимировать производную, взяв малое значение ε: (11.6) Точность аппроксимации можно повысить, вычислив центральную разность: (11.7) Величина возмущения ε должна быть достаточно большой, чтобы предотвратить слишком сильное округление в процессе вычисления конечных разностей. Обычно мы хотим протестировать градиент якобиана или векторной функции g : ℝm ⟶ ℝn. К сожалению, метод конечных разностей позволяет вычислять только одну производную в каждый момент времени. Следовательно, можно либо приме- нить его mn раз для вычисления всех частных производных g, либо выполнить тест для новой функции, в которой берутся случайные проекции на вход и выход g. На- пример, можно применить тест к реализации производных функции f(x) = uТg(vx), где u и v – случайно выбранные векторы. Для правильного вычисления f′(x) нужно уметь корректно выполнять обратное распространение через g, но это можно сделать эффективно и с помощью метода конечных разностей, потому что у f всего один ска-\n--- Страница 371 ---\n370  Практическая методология лярный аргумент и одно выходное значение. Обычно имеет смысл повторить тест для нескольких значений u и v, чтобы не проглядеть ошибок, ортогональных направле- нию случайного проецирования. Если речь идет о вычислениях с комплексными числами, то существует очень эф- фективный способ численной оценки градиента путем передачи функции комплексно- го аргумента (Squire and Trapp, 1998). В основе метода лежит следующее наблюдение: f(x + iε) = f(x) + iεf ′(x) + O(ε2), (11.8) Re(f(x + iε)) = f(x) + O(ε2), (11.9) где i = . В отличие от рассмотренного выше вещественного случая, здесь нет по- тери значащих цифр, потому что вычисляется разность между значениями f в разных точках. Это позволяет брать очень малые значения ε, например 10–150, так что погреш- ность O(ε2) практически несущественна. Мониторинг гистограмм активаций и градиента. Часто бывает полезно визуали- зировать статистику активаций и градиента нейронной сети, собранную по многим итерациям обучения (быть может, по одному периоду). Значения скрытых блоков до активации могут сказать, являются ли блоки насыщенными и как часто такое случа- ется. Например, если речь идет о блоках линейной ректификации, то как часто они выключены? А есть ли блоки, которые всегда выключены? В случае tanh-блоков о на- сыщении блока говорит среднее абсолютных величин до активации. В глубокой сети, где распространяемые градиенты быстро растут или быстро приближаются к нулю, могут возникнуть препятствия для оптимизации. Наконец, полезно сравнить модули градиентов параметров с модулями самих параметров. В работе Bottou (2015) реко- мендуется, чтобы модуль изменения параметра по мини-пакету составлял примерно 1% от модуля параметра, а не 50% и не 0.001% (тогда изменение параметров было бы слишком медленным). Может оказаться, что некоторые группы параметров изменя-ются в хорошем темпе, тогда как другие топчутся на месте. Если данные разрежены (как в естественном языке), то некоторые параметры могут обновляться очень редко, и об этом следует помнить, наблюдая за их эволюцией. Наконец, многие алгоритмы глубокого обучения дают некоторые гарантии относи- тельно результатов на каждом шаге. Например, в части III мы встретимся с алгорит- мами приближенного вывода, в основе которых лежит алгебраическое решение задач оптимизации. Обычно для их отладки можно проверить выполнение каждой гаран-тии. Приведем несколько примеров подобных гарантий: целевая функция никогда не увеличивается после одного шага алгоритма; градиент относительно некоторого под-множества переменных равен 0 после каждого шага алгоритма; градиент по всем пере-менным равен 0 по достижении сходимости. Обычно из-за ошибок округления эти условия выполняются неточно, поэтому при отладке нужно делать небольшой допуск. 11.6. Пример: распознавание нескольких цифр В качестве примера практического применения комплексной методологии проекти- рования мы кратко опишем систему транскрипции Street View с точки зрения про- ектирования компонентов глубокого обучения. Понятно, что не менее важную роль играют и многие другие компоненты системы, в частности автомобили Street View,\n--- Страница 372 ---\nПример: распознавание нескольких цифр  371 инфраструктура базы данных и т. д. С точки зрения машинного обучения процесс на- чинается со сбора данных. Автомобили собирают исходные данные, а люди помечают их. Собственно, транскрипции предшествовала большая работа по подготовке набора данных, в т. ч. применение других методов машинного обучения для обнаружения номеров данных. В начале работы над проектом мы определили показатели качества и их жела- тельные значения. Важный общий принцип – выбирать показатели в соответствии с бизнес-целями проекта. Поскольку карты ценны, лишь если они верны, важным требованием к проекту было достижение высокой верности. Точнее, ставилась цель достичь такой же верности, как при определении номеров домов человеком, – 98%. Добиться такой верности не всегда возможно, поэтому система транскрипции Street View пожертвовала покрытием. Таким образом, покрытие стало главным показате-лем качества, который и требовалось оптимизировать при ограничении на верность 98%. По мере совершенствования нейронной сети появилась возможность снизить порог доверия, ниже которого система отказывалась транскрибировать вход, так что в итоговой системе покрытие превзошло намеченные 95%. Следующим после выбора количественных целей шагом рекомендуемой методоло- гии является скорейшая организация разумной базовой системы. Для задач компью-терного зрения это сверточная сеть с блоками линейной ректификации. Именно та- кую модель мы и выбрали в начале проекта. В то время редко можно было встретить сверточные сети, порождавшие последовательность предсказаний. В первой, самой простой модели выходной слой состоял из n softmax-блоков для предсказания после- довательности n символов. Эти блоки обучались так, как если бы речь шла о задаче классификации, каждый softmax-блок обучался независимо от остальных. Наша методология рекомендует итеративно уточнять базовую модель и прове- рять, привело ли очередное изменение к улучшению. Первое изменение системы транскрипции Street View было связано с теоретическим осмыслением метрики по- крытия и структуры данных. Точнее, система отказывалась классифицировать вход x, если вероятность выходной последовательности p(y | x) < t для некоторого порога t. Первоначальное определение p(y | x) было упрощенным, основанным на простом перемножении всех выходов функций softmax. Возникла потребность в разработке специализированного выходного слоя и функции стоимости, которая вычисляла бы теоретически правильное логарифмическое правдоподобие. При таком подходе ме-ханизм отклонения примеров стал работать намного эффективнее. На этом этапе покрытие оставалось ниже 90%, но очевидных теоретических проб- лем не просматривалось. Поэтому в соответствии с нашей методологией нужно было оснастить систему средствами измерения качества на обучающем и тестовом набо- рах, чтобы понять, вызвана проблема переобучением или недообучением. В данном случае ошибки на обучающем и тестовом наборах были почти одинаковы. Вообще, главная причина, по которой работа над проектом шла так гладко, – доступность на- бора данных, содержащего десятки миллионов помеченных примеров. Коль скоро ошибки на обоих наборах оказались так близки, возникло подозрение, что корень проблемы – недообучение или какой-то дефект в подготовке обучающих данных. Одна из рекомендуемых нами стратегий отладки предполагает визуализировать самые серьезные ошибки модели. В данном случае это означало визуализацию не- правильно транскрибированных примеров из обучающего набора, которым модель приписала самую высокую степень уверенности. Оказалось, что большинство таких\n--- Страница 373 ---\n372  Практическая методология примеров было слишком сильно обрезано, так что из кадра выпало несколько цифр адреса. Например, после обрезки на фотографии адреса «1849» могли остаться только цифры «849». Проблему можно было бы решить, потратив несколько недель, чтобы повысить верность системы обнаружения номера дома и выделения интересую щей области. Вместо этого было принято гораздо более практичное решение – просто уве- личить ширину кадра, делая ее всегда больше той, что предсказывала система обнару-жения номера дома. Одно лишь это изменение повысило покрытие на 10%. И еще несколько процентов удалось выжать путем настройки гиперпараметров. Свелась она в основном к увеличению размера модели с сохранением некоторых ограничений на вычислительную стоимость. Поскольку ошибки обучения и тестиро- вания оставались примерно равными, всегда было понимание, что недотягивание до целевых показателей качества связано с недообучением и, быть может, несколькими оставшимися проблемами в самом наборе данных. В общем и целом проект транскрипции оказался весьма успешным, он позволил транскрибировать сотни миллионов адресов быстрее и дешевле, чем было бы воз- можно в случае привлечения людей. Мы надеемся, что благодаря принципам проектирования, описанным в этой главе, количество подобных успешных начинаний будет множиться.",
      "debug": {
        "start_page": 356,
        "end_page": 373
      }
    },
    {
      "name": "Глава 12. Приложения 373",
      "content": "--- Страница 374 --- (продолжение)\nГлава 12 Приложения В этой главе мы опишем, как применить глубокое обучение к компьютерному зрению, распознаванию речи, обработке естественных языков и другим задачам, представляю- щим коммерческий интерес. Начнем с обсуждения реализации крупномасштабных нейронных сетей, необходимых в большинстве серьезных приложений ИИ. Затем дадим обзор нескольких конкретных приложений, в которых глубокое обучение по- могло найти решение. Хотя одной из основных целей глубокого обучения является проектирование алгоритмов, способных решать широкий круг задач, в настоящий момент некоторая специализация все же необходима. Например, в задачах компью- терного зрения требуется обрабатывать много входных признаков (пикселей) для каждого примера. А в задачах обработки языка нужно моделировать много возмож- ных значений (слов из словаря) на каждый входной признак. 12.1. Крупномасштабное глубокое обучение Глубокое обучение основано на философии коннекционизма: отдельный биологиче- ский нейрон или отдельный признак в модели машинного обучения не обладает ин- теллектом, но большая популяция таких нейронов или признаков, действующих со-вместно, может демонстрировать разумное поведение. Важно подчеркнуть, что число нейронов должно быть большим. Один из ключевых факторов, способствовавших повышению верности нейронных сетей и сложности решаемых ими задач в период начиная с 1980-х годов и по сегодняшний день, – кардинальное увеличение размера сетей. В разделе 1.2.3 мы видели, что на протяжении последних тридцати лет раз- мер сетей рос экспоненциально, и тем не менее искусственные нейронные сети всего лишь сравнялись по размеру с нервными системами насекомых. Поскольку размер нейронной сети играет решающую роль, для глубокого обуче- ния необходимы высокопроизводительное оборудование и соответствующая прог- раммная инфраструктура. 12.1.1. Реализации на быстрых CPU Традиционно обучение нейронных сетей производилось на одной машине с одним центральным процессором (CPU). Сегодня это считается недостаточным. Мы ис-пользуем в основном вычисления на графических процессорах (GPU) или на CPU многих машин, связанных в единую сеть. Но прежде чем перейти на такие дорогостоя- щие конфигурации, исследователям пришлось немало потрудиться, чтобы доказать, что CPU уже не справляются с вычислительной нагрузкой, необходимой нейронным сетям.\nГлава 12 Приложения В этой главе мы опишем, как применить глубокое обучение к компьютерному зрению, распознаванию речи, обработке естественных языков и другим задачам, представляю- щим коммерческий интерес. Начнем с обсуждения реализации крупномасштабных нейронных сетей, необходимых в большинстве серьезных приложений ИИ. Затем дадим обзор нескольких конкретных приложений, в которых глубокое обучение по- могло найти решение. Хотя одной из основных целей глубокого обучения является проектирование алгоритмов, способных решать широкий круг задач, в настоящий момент некоторая специализация все же необходима. Например, в задачах компью- терного зрения требуется обрабатывать много входных признаков (пикселей) для каждого примера. А в задачах обработки языка нужно моделировать много возмож- ных значений (слов из словаря) на каждый входной признак. 12.1. Крупномасштабное глубокое обучение Глубокое обучение основано на философии коннекционизма: отдельный биологиче- ский нейрон или отдельный признак в модели машинного обучения не обладает ин- теллектом, но большая популяция таких нейронов или признаков, действующих со-вместно, может демонстрировать разумное поведение. Важно подчеркнуть, что число нейронов должно быть большим. Один из ключевых факторов, способствовавших повышению верности нейронных сетей и сложности решаемых ими задач в период начиная с 1980-х годов и по сегодняшний день, – кардинальное увеличение размера сетей. В разделе 1.2.3 мы видели, что на протяжении последних тридцати лет раз- мер сетей рос экспоненциально, и тем не менее искусственные нейронные сети всего лишь сравнялись по размеру с нервными системами насекомых. Поскольку размер нейронной сети играет решающую роль, для глубокого обуче- ния необходимы высокопроизводительное оборудование и соответствующая прог- раммная инфраструктура. 12.1.1. Реализации на быстрых CPU Традиционно обучение нейронных сетей производилось на одной машине с одним центральным процессором (CPU). Сегодня это считается недостаточным. Мы ис-пользуем в основном вычисления на графических процессорах (GPU) или на CPU многих машин, связанных в единую сеть. Но прежде чем перейти на такие дорогостоя- щие конфигурации, исследователям пришлось немало потрудиться, чтобы доказать, что CPU уже не справляются с вычислительной нагрузкой, необходимой нейронным сетям.\n--- Страница 375 ---\n374  Приложения Описание эффективной реализации вычислений на CPU выходит за рамки этой книги, но отметим, что тщательно продуманная реализация на CPU нескольких се- мейств может принести весомые плоды. Например, в 2011 году на лучших в то вре- мя CPU код нейронных сетей выполнялся быстрее при использовании арифметики с фиксированной, а не с плавающей точкой. В работе Vanhoucke et al. (2011) благодаря тщательно оптимизированной реализации с фиксированной точкой удалось добить- ся трехкратного ускорения по сравнению с системой на базе арифметики с плаваю- щей точкой. Характеристики каждой новой модели CPU отличаются от предыду-щей, поэтому иногда можно ускорить и реализации с плавающей точкой. Принцип остается общим – специализация численных процедур может дать значительный выигрыш. Есть и другие стратегии, в т. ч. оптимизация структур данных с целью из- бежать промахов кэша и использование векторных команд. Многие исследователи, занимающиеся машинным обучением, пренебрегают такими деталями реализации, но если производительность реализации ограничивает размер модели, то страдает верность модели. 12.1.2. Реализации на GPU Большинство современных реализаций нейронных сетей основано на использовании графических процессоров (GPU) – специализированного оборудования, которое из- начально разрабатывалось для графических приложений. Потребительский рынок систем для видеоигр подстегнул создание графических карт. Как выяснилось, харак-теристики производительности, необходимые для игровых систем, подходят и для нейронных сетей. Для отрисовки экрана в видеоиграх необходимо быстро выполнять много парал- лельных операций. Модели персонажей и окружения описываются в виде списков трехмерных координат вершин. Графическая карта должна параллельно выполнять умножение и деление матриц в большом числе вершин для преобразования трехмер- ных координат сцены в двумерные экранные координаты. Затем карта должна парал- лельно выполнить вычисления в каждом пикселе, чтобы определить его цвет. В обоих случаях вычисления довольно простые и не содержат такого большого количества ветвлений, как в типичной программе, выполняемой на CPU. Например, каждая вер- шина одного твердого тела умножается на одну и ту же матрицу; не нужно выполнять в каждой вершине предложение if, чтобы понять, на какую матрицу умножать. К тому же вычисления абсолютно независимы и, следовательно, легко распараллеливаются. Кроме того, в процессе вычислений производятся обращения к большим буферам в памяти, в которых хранятся растры, описывающие текстуру (цветовой узор) каждо- го отрисовываемого объекта. Поэтому при проектировании графических карт закла-дываются высокая степень параллелизма и пропускная способность памяти, а рас- плачиваться за это приходится меньшей тактовой частотой и не столь развитыми средствами ветвления, как в традиционных процессорах. Алгоритмам нейронных сетей свойственны такие же характеристики производи- тельности, как для графических алгоритмов реального времени. В нейронных сетях обычно имеется много больших буферов параметров, значений активации и градиен- тов, каждый из которых необходимо полностью обновлять на каждом шаге обучения. Эти буферы не помещаются в кэш стандартного настольного компьютера, поэтому пропускная способность памяти часто оказывается лимитирующим фактором. Важное преимущество GPU над CPU заключается именно в высокой пропускной способно-\n--- Страница 376 ---\nКрупномасштабное глубокое обучение  375 сти памяти. В алгоритмах обучения нейронных сетей обычно не так много ветвлений и сложных средств управления потоком вычислений, поэтому они пригодны для ра- боты на GPU. Поскольку нейронную сеть можно разложить на множество отдельных «нейронов», обрабатываемых независимо от других нейронов в том же слое, то для их обучения средства распараллеливания, имеющиеся в GPU, оказываются весьма кстати. Оборудование GPU первоначально было специализировано только под графи- ческие задачи. Со временем оно стало более гибким, позволяющим использовать пользовательские подпрограммы для преобразования координат вершин и назначе- ния цветов пикселям. В принципе, не требуется, чтобы пиксели были как-то связаны с задачей отрисовки. Такие GPU можно использовать для научных расчетов, если записывать результаты вычислений в буфер значений пикселей. В работе Steinkrau et al. (2005) реализована двухслойная полносвязная нейронная сеть на GPU и отме- чено трехкратное ускорение, по сравнению с эталоном, работающим на CPU. Вскоре после этого в работе Chellapilla et al. (2006) было продемонстрировано, что такую же технику можно применить для ускорения сверточных сетей с учителем. Использование графических карт для обучения нейронных сетей испытало на- стоящий взрыв популярности с появлением GPU общего назначения (GP-GPU), которые могут исполнять произвольный код, а не только подпрограммы отрисовки. Похожий на C язык программирования CUDA, разработанный компанией NVIDIA, дал средства для написания произвольного кода. Благодаря сравнительно удобной модели программирования, массовому параллелизму и высокой пропускной способ- ности памяти GP-GPU стали идеальной платформой для программирования нейрон-ных сетей. Эта платформа была с восторгом принята специалистами по глубокому обучения сразу после появления (Raina et al., 2009; Ciresan et al., 2010). Написание эффективного кода для GP-GPU остается трудной задачей, которую лучше оставить специалистам. Приемы достижения высокой производительности на GPU сильно отличаются от того, к чему мы привыкли на CPU. Например, хоро- шая программа для CPU обычно проектируется так, чтобы по возможности читать данные из кэша. На GPU большая часть допускающей запись памяти не кэширует-ся, поэтому быстрее вычислить одно и то же значение дважды, чем вычислить одно- кратно, а потом прочитать из памяти. Код для GPU принципиально многопоточный, и потоки необходимо тщательно синхронизировать. Например, операции с памятью выполняются быстрее, если их можно объединить. Объединенная операция чтения или записи имеет место, когда несколько потоков могут одновременно прочитать или записать нужные им значения в составе одной транзакции доступа к памяти. Разные модели GPU умеют объединять разные последовательности операций чтения и запи- си. Обычно операции с памятью проще объединить, если i-й из n потоков обращается к (i + j)-му байту памяти и j кратно степени двойки. Точные спецификации зависят от модели GPU. Еще один важный аспект программы для GPU – следить за тем, чтобы все потоки в группе выполняли одну и ту же команду одновременно. Это означает, что реализовать ветвление на GPU трудно. Потоки разбиваются на небольшие груп-пы, называемые канатами (warp). Каждый поток каната в каждом цикле выполняет одну и ту же команду, поэтому если два потока из одного каната должны пройти по разным путям в коде, то проходить их придется последовательно, а не параллельно. В связи с трудностями написания высокопроизводительного кода для GPU работу следует построить так, чтобы избежать разработки нового GPU-кода для тестирова-ния новых моделей или алгоритмов. Обычно для этого создают библиотеку функций\n--- Страница 377 ---\n376  Приложения для таких операций, как свертка и умножение матриц, а затем специфицируют моде- ли в терминах обращений к библиотеке. Например, в библиотеке машинного обуче- ния Pylearn2 (Goodfellow et al., 2013c) все алгоритмы специфицированы в терминах обращений к библиотекам Тheano (Bergstra et al., 2010; Bastien et al., 2012) и cuda- convnet (Krizhevsky, 2010), предоставляющих высокопроизводительные операции. Такое распределение обязанностей заодно упрощает поддержку разнородного обору-дования. Например, одна и та же программа, использующая Тheano, может работать как на CPU, так и на GPU безо всякого изменения обращений к самой Theano. Другие библиотеки, например ТensorFlow (Abadi et al., 2015) и Тorch (Collobert et al., 2011b), предлагают похожие возможности. 12.1.3. Крупномасштабные распределенные реализации Часто вычислительных ресурсов одной машины недостаточно. Поэтому хотелось бы распределить рабочую нагрузку обучения и вывода между несколькими машинами. Распределить вывод просто, потому что каждый входной пример можно обрабо- тать на отдельной машине. Это называется распараллеливанием по данным. Существует также режим распараллеливания модели, когда несколько машин сов местно работает над одним примером, причем каждая машина выполняет свою часть модели. Это возможно как для обучения, так и для вывода. Распараллеливание по данным на этапе обучения несколько сложнее. Мы можем увеличить размер мини-пакета, используемого на одном шаге СГС, но обычно вы-игрыш в терминах производительности оптимизации получается меньше линейного. Было бы лучше, чтобы несколько машин параллельно вычисляли несколько шагов градиентного спуска. К сожалению, в стандартной формулировке алгоритм градиент- ного спуска строго последовательный: градиент на шаге t является функцией пара- метров, найденных на шаге t – 1. Эту проблему можно решить с помощью асинхронного стохастического гради- ентного спуска (Bengio et al., 2001; Recht et al., 2011). В этом случае несколько про- цессорных ядер сообща использует память для представления параметров. Каждое ядро читает параметры без блокировки, затем вычисляет градиент, после чего инкре-ментирует параметры без блокировки. Это уменьшает среднее улучшение на каждом шаге градиентного спуска, потому что некоторые ядра перезаписывают достигнутое другими ядрами, но за счет увеличенного темпа выполнения шагов процесс обучения в целом протекает быстрее. В работе Dean et al. (2012) этот подход к градиентному спуску без блокировок впервые реализован на нескольких машинах, когда параметры хранятся не в разделяемой памяти, а на сервере параметров. Распределенный асин- хронный градиентный спуск остается основной стратегией обучения больших глубо-ких сетей и применяется большинством групп, занимающих лидирующие позиции в индустрии (Chilimbi et al., 2014; Wu et al., 2015). Академические учреждения обыч- но не могут позволить себе распределенные системы обучения такого масштаба, но в ряде исследований изучается вопрос о построении распределенных сетей на срав- нительно дешевом оборудовании, имеющемся в университетах (Coates et al., 2013). 12.1.4. Сжатие модели Во многих коммерческих приложениях гораздо важнее, чтобы время и потребле- ние памяти были низкими на этапе вывода модели машинного обучения, тогда как затраты на этапе обучения не столь критичны. Если приложение не требует персо-\n--- Страница 378 ---\nКрупномасштабное глубокое обучение  377 нализации, то модель можно обучить один раз, а затем развернуть для миллиардов пользователей. Во многих случаях у конечного пользователя ресурсов меньше, чем у разработчика. Например, сеть распознавания речи можно обучить на кластере из мощных компьютеров, а затем установить в мобильный телефон. Ключевая стратегия сокращения стоимости вывода – сжатие модели (Buciluă et al., 2006). Основная идея – заменить исходную дорогостоящую модель другой, по- требляющей меньше памяти и работающей быстрее. Сжатие модели применимо, когда размер исходной модели обусловлен в основ- ном стремлением предотвратить переобучение. В большинстве случаев модель с наи- меньшей ошибкой обобщения представляет собой ансамбль нескольких независимо обученных моделей. Вычислять предсказание всех n членов ансамбля дорого. Иногда даже одна модель обобщается лучше, если она велика (например, если применялась регуляризация прореживанием). Такие большие модели обучают некоторую функцию f(x), но используют при этом гораздо больше параметров, чем необходимо для решения задачи. Их размер велик только потому, что число обучающих примеров ограничено. После того как функция f(x) аппроксимирована, мы можем сгенерировать обучающий набор, содержащий бесконечно много примеров, просто применив f к случайной выборке x. Затем мы обуча ем новую, меньшую модель, так чтобы она совпадала с f(x) на этой выборке. Чтобы емкость новой модели использовалась наиболее эффективно, лучше выбирать новые точки x из распределения, похожего на реальные тестовые данные, которые бу- дут предъявлены модели впоследствии. Это можно сделать, слегка исказив обучаю-щие примеры или произведя выборку из порождающей модели, обученной на исход-ном обучающем наборе. Альтернативно можно обучить меньшую модель только на исходных обучающих примерах, но научить ее копировать другие признаки модели, например апостериор-ное распределение неправильных классов (Hinton et al., 2014, 2015). 12.1.5. Динамическая структура Одна из общих стратегий ускорения систем обработки данных – построить систе- му с динамической структурой в виде графа, описывающего вычисления, необходи- мые для обработки входных данных. Системы обработки данных могут динамически определить, какую часть большого множества нейронных сетей выполнять для за-данного входа. Отдельные нейронные сети также могут иметь внутреннюю динами-ческую структуру, т. е. определять, какое подмножество признаков (скрытых блоков) вычислять при имеющейся входной информации. Такую форму динамической струк-туры внутри нейронной сети иногда называют условным вычислением (Bengio, 2013; Bengio et al., 2013b). Поскольку многие компоненты архитектуры могут иметь отно-шение только к небольшому количеству возможных входов, система будет работать быстрее, если эти признаки вычисляются только по мере необходимости. Динамическая структура вычислений – базовый принцип информатики, повсе- местно применяемый в программной инженерии. Простейшие варианты динамиче- ской структуры в контексте нейронных сетей основаны на определении того, какое подмножество некоторой группы нейронных сетей (или иных моделей машинного обучения) следует применить к конкретному входу. Давно сложившаяся стратегия ускорения вывода – использовать каскад класси- фикаторов. Ее можно применить, когда стоит задача обнаружить присутствие ред-\n--- Страница 379 ---\n378  Приложения кого объекта (или события). Для полной уверенности мы должны использовать изощренный классификатор высокой емкости, а его работа обходится дорого. Но поскольку объект редкий, мы зачастую можем ограничиться куда меньшими вычис-лениями, чтобы отклонить входы, не содержащие объекты. В такой ситуации можно обучить последовательность классификаторов. У начальных классификаторов ем- кость низкая, а при их обучении предпочтение отдается полноте. Иными словами, они не отклоняют по ошибке вход, если объект присутствует. При обучении послед-него классификатора на первое место ставится точность. На этапе тестирования мы последовательно выполняем классификаторы и отклоняем пример, как только его отвергнет первый же классификатор. Вообще говоря, это позволяет с высокой уве- ренностью проверить присутствие объекта, пользуясь моделью высокой емкости, но при этом не платить за полный вывод для каждого примера. Есть два способа обеспе-чить высокую емкость каскада. Первый – сделать так, чтобы все члены, находящи- еся ближе к концу каскада, имели высокую емкость. Очевидно, что тогда и система в целом будет иметь высокую емкость, поскольку таковы некоторые ее компоненты. Можно поступить иначе – построить каскад, в котором емкость каждой отдельной модели низкая, но система в целом обладает высокой емкостью, будучи комбинацией большого числа малых моделей. В работе Viola and Jones (2001) каскад усиленных ре- шающих деревьев использовался для построения быстрого и устойчивого детектора лиц, пригодного для использования в портативных цифровых камерах. В созданном ими классификаторе для локализации лица применяется метод скользящего окна: исследуется много прямоугольных окон и отбрасываются те, в которых лиц нет. Еще в одной версии каскада предшествующие модели используются для реализации свое- го рода механизма внимания: первые члены каскада локализуют объект, а последую- щие выполняют дополнительную обработку, зная, где объект расположен. Например, Google транскрибирует номера домов на изображениях Street View с помощью двух- ступенчатого каскада, в котором для нахождения номера дома применяется одна мо- дель машинного обучения, а для транскрипции – другая (Goodfellow et al., 2014d). Решающие деревья сами по себе являются примером динамической структуры, по- скольку каждый узел дерева определяет, какое поддерево вычислять для поступив-шего входа. Чтобы объединить глубокое обучение с динамической структурой, мож- но, например, обучить решающее дерево, в каждом узле которого имеется нейронная сеть, принимающая решение о разделении (Guo and Gelfand, 1992), хотя обычно глав- ная цель такого подхода не в том, чтобы ускорить вывод. Продолжая в том же духе, можно использовать нейронную сеть, называемую прив- ратником (gater), для выбора одной из нескольких экспертных сетей, вычисляющих выход по текущему входу. Первый вариант этой идеи получил название «коллектив экспертов» (mixture of experts) (Nowlan, 1990; Jacobs et al., 1991) – привратник вы- водит набор вероятностей или весов (полученных с помощью нелинейности типа softmax), по одному на каждого эксперта, а конечный выход получается взвешивани- ем выходов экспертов. В этом случае применение привратника не снижает вычисли- тельную стоимость, но если бы для каждого примера привратник предлагал только одного эксперта, то мы получили бы строгий (hard) коллектив экспертов (Collobert et al., 2001, 2002), способный значительно ускорить обучение и вывод. Такая страте- гия хорошо работает, когда число решений привратника мало, а не растет комбина- торно. Но если мы хотим выбирать различные подмножества блоков или параметров, то воспользоваться «мягким переключателем» не получится, потому что требуется\n--- Страница 380 ---\nКрупномасштабное глубокое обучение  379 перечислить все конфигурации привратника (и вычислить для них выходы). Что- бы справиться с этой проблемой, было предложено несколько подходов к обучению комбинаторных привратников. В работе Bengio et al. (2013b) описаны эксперименты с несколькими оценками градиента по вероятностям привратника, а в работах Bacon et al. (2015) и Bengio et al. (2015a) использовалась техника обучения с подкреплени- ем (градиент политики – policy gradient) для реализации разновидности условного прореживания, применяемого к группам скрытых блоков, с целью реально снизить вычислительную стоимость, не ухудшив качества аппроксимации. Еще один вид динамической структуры – переключатель, когда скрытый блок мо- жет получать входные данные от разных блоков в зависимости от контекста. Такую динамическую маршрутизацию можно интерпретировать как механизм внимания (Olshausen et al., 1993). Пока что эффективность жесткого переключателя в крупно- масштабных приложениях не доказана. Вместо этого в современных системах приме- няется взвешенное среднее многих возможных входов, что не позволяет реализовать все потенциальные вычислительные преимущества динамической структуры. Совре-менные механизмы внимания описаны в разделе 12.4.5.1. Одно из главных препятствий на пути использования систем с динамической структурой – снижение степени параллелизма из-за того, что выполнение идет по разным ветвям для разных входов. Это означает, что лишь немногие операции сети можно описать как умножение матриц или пакетную свертку на мини-пакете приме-ров. Можно написать более специализированные подпрограммы, которые сворачи-вают каждый пример с разными ядрами или умножают каждую строку матриц плана на разное подмножество столбцов матрицы весов. К сожалению, такие подпрограм- мы трудно реализовать эффективно. Реализации для CPU будут медленными из-за отсутствия когерентности кэшей, а реализации для GPU – тоже медленными из-за отсутствия объединенных транзакций доступа к памяти и необходимости сериали- зовывать канаты, когда входящие в них потоки выполняют разные ветви програм- мы. Иногда эти проблемы можно смягчить, разбив примеры на группы, для которых выполнение идет по одной ветви, а затем обработав каждую группу одновременно. Такая стратегия может оказаться приемлемой для минимизации времени обработки фиксированного числа примеров в офлайновой конфигурации. Но в режиме реаль- ного времени, когда примеры должны обрабатываться непрерывно, разбиение задачи на части может привести к проблемам с балансированием нагрузки. Например, если назначить одну машину для обработки первой ступени каскада, а другую – для об- работки последней, то первая машина может оказаться перегруженной, а вторая – не- догруженной. Аналогичные проблемы возникают, если разным машинам поручить реализацию различных узлов нейронного решающего дерева. 12.1.6. Специализированные аппаратные реализации глубоких сетей Когда исследования по нейронным сетям только начинались, инженеры-электрони- ки уже задумались над специализированным оборудованием, способным ускорить обучение или вывод. Ранние и сравнительно недавние обзоры специализированного оборудования для глубоких сетей можно найти в работах Lindsey and Lindblad, 1994, Beiu et al., 2003, Misra and Saha, 2010. За несколько десятков лет были разработаны разнообразные виды специализиро- ванного оборудования (Graf and Jackel, 1989; Mead and Ismail, 2012; Kim et al., 2009;\n--- Страница 381 ---\n380  Приложения Pham et al., 2012; Chen et al., 2014a,b) на базе ASIC (интегральных схем специального назначения): цифровых, аналоговых (Graf and Jackel, 1989; Mead and Ismail, 2012) или гибридных. В последние годы фокус сместился в сторону более гибких реали- заций на основе ППВМ (программируемых пользователем вентильных матриц), до-пускающих конфигурацию пользователем после изготовления. Хотя в программных реализациях для процессоров общего назначения (CPU и GPU) обычно используются 32- или 64-разрядные числа с плавающей точкой, давно известно, что можно обойтись и меньшей точностью, по крайней мере на эта- пе вывода (Holt and Baker, 1991; Holi and Hwang, 1993; Presley and Haggard, 1994; Simard and Graf, 1994; Wawrzynek et al., 1996; Savich et al., 2007). В последние годы этот вопрос приобрел особую остроту, поскольку глубокое обучение стало широко использоваться в промышленных изделиях, а на примере GPU продемонстрирован серьезный выигрыш, который может дать более быстрое оборудование. Еще одним фактором, стимулирующим исследования в области специализированного оборудо- вания для глубокого обучения, является замедление прогресса в разработке одного ядра CPU и GPU; теперь повышение быстродействия происходит в основном за счет распараллеливания обработки между несколькими ядрами (как в CPU, так и в GPU). Эта ситуация сильно отличается от сложившейся в 1990-е годы (время предыдуще- го поколения нейронных сетей), когда аппаратные реализации нейронных сетей (на создание которых могло уйти до двух лет с начала проекта до выпуска готовой микро- схемы) не могли конкурировать с CPU общего назначения ни по темпам развития, ни по стоимости. Таким образом, специализированное оборудование – это способ вый ти за привычные рамки во времена, когда проектируется новое оборудование для устройств с низким энергопотреблением (например, смартфонов), а его цель – сделать общедоступными приложения глубокого обучения (распознавание речи, компью терное зрение, обработка естественных языков). Недавние работы по реализации нейронных сетей с обратным распространением на оборудовании с арифметикой низкой точности (Vanhoucke et al., 2011; Courbariaux et al., 2015; Gupta et al., 2015) позволяют сделать вывод, что для обучения и исполь- зования таких сетей достаточно от 8 до 16 разрядов. Ясно также, что на этапе обуче-ния нужна большая точность, чем на этапе вывода, и что для снижения разрядности можно использовать некоторые формы динамического представления чисел с фик- сированной точкой. Традиционно числа с фиксированной точкой занимают фикси- рованный диапазон (как если бы зафиксировать показатель степени в представлении с плавающей точкой). Динамические представления с фиксированной точкой позво- ляют разделить этот диапазон между множеством чисел (например, весов в одном слое). Использование фиксированной точки вместо плавающей и понижение разряд- ности уменьшают площадь, занимаемую оборудованием, энергопотребление и время выполнения операции умножения, а именно на эти операции приходится основное время при обучении и использовании современной глубокой сети с обратным рас- пространением. 12.2. Компьютерное зрение Компьютерное зрение традиционно является одной из основных областей примене-ния глубокого обучения, потому что зрение не требует никаких усилий от человека и многих животных, но является сложной задачей для компьютеров (Ballard et al.,\n--- Страница 382 ---\nКомпьютерное зрение  381 1983). Многие из самых популярных стандартных эталонных задач для сравнения алгоритмов глубокого обучения так или иначе связаны с распознаванием объектов или текста. Компьютерное зрение – это очень широкая дисциплина, охватывающая раз- личные способы обработки изображений и поразительное разнообразие прило- жений – от воспроизведения зрительных способностей человека, например рас- познавания лиц, до создания совершенно новых видов зрительных способностей. В качестве примера из последней категории можно назвать недавнее приложение по распознаванию звуковых волн по вибрациям, которые они вызывают в предме- тах, присутствующих на видео (Davis et al., 2014). Большая часть исследований по глубокому обучению в контексте компьютерного зрения посвящена не таким эк- зотическим приложениям, расширяющим горизонты возможного, а сравнительно узким базовым задачам ИИ – воспроизведению человеческих способностей. Речь идет о той или иной форме обнаружения или распознавания объектов: констатация присутствия объекта в изображении, обведение найденных в изображении объек- тов рамочкой, транскрибирование последовательности символов в изображении или пометка каждого пикселя изображения идентификатором объекта, которому он принадлежит. Поскольку основополагающим принципом глубокого обучения изна-чально являлось порождающее моделирование, существует много работ по синтезу изображений с помощью глубоких моделей. Синтез изображений из ничего обычно не считается крупным достижением в компьютерном зрении, но модели, способ- ные к синтезу, часто бывают полезными для восстановления изображений – задачи компью терного зрения, подразумевающей исправление дефектов и удаление объ- ектов из изображения. 12.2.1. Предобработка Во многих приложениях требуется изощренная предварительная обработка, потому что исходные данные представлены в виде, малопригодном для архитектур глубоко- го обучения. В компьютерном зрении объем такой предобработки сравнительно не- велик. Изображения следует привести к стандартному виду, так чтобы значения всех пикселей принадлежали одному и тому же разумному диапазону, например [0,1] или [–1, 1]. Если в одних изображениях пиксели лежат в диапазоне [0,1], а в других – в диапазоне [0, 255], то попытка их обработать обычно не приводит ни к чему хоро- шему. Во многих архитектурах компьютерного зрения требуется, чтобы все изобра-жения были стандартного размера, поэтому их необходимо либо обрезать, либо масштабировать. Но даже такое масштабирование не всегда необходимо. Некоторые сверточные модели принимают входные данные переменного размера и динамиче- ски подстраивают свои области пулинга, так чтобы размер выхода был постоянным (Waibel et al., 1989). В других сверточных моделях размер выхода переменный, ав- томатически подстраиваемый под размер входа, например в моделях, предназначен- ных для очистки от шумов или для пометки каждого пикселя изображения (Hadsell et al., 2007). Пополнение набора данных можно рассматривать как вид предобработки одного лишь обучающего набора. В большинстве моделей машинного зрения это отличный способ уменьшить ошибку обобщения. На этапе тестирования применима похожая идея: предъявить много разных вариантов одного и того же входа (например, одно изображение, обрезанное немного по-разному) и организовать голосование разных\n--- Страница 383 ---\n382  Приложения экземпляров модели для определения выхода. Это можно интерпретировать как раз- новидность ансамблевого подхода, уменьшающего ошибку обобщения. Другие виды предобработки применяются как к обучающему, так и к тестовому на- бору с целью привести каждый пример к канонической форме, уменьшив тем самым вариативность, которую модель должна учитывать. Снижение степени вариативно-сти способствует уменьшению ошибки обобщения и размера модели, необходимого для аппроксимации обучающего набора. Для решения более простых задач достаточ-но моделей меньшего размера, а чем проще решение, тем больше шансов, что оно хо- рошо обобщается. Предобработку такого рода обычно проектируют так, чтобы устра-нить вариативность, которую проектировщик может легко описать и которая точно не имеет существенной связи с основной задачей. При обучении больших моделей на больших наборах данных такая предобработка часто излишня, и лучше дать модели возможность обучиться всем видам вариативности, к которым она должна быть ин- вариантна. Например, в системе AlexNet для классификации набора ImageNet есть только один шаг предобработки: вычитание среднего значения каждого пикселя, вы-численного по всем обучающим примерам (Krizhevsky et al., 2012). 12.2.1.1. Нормализация контрастности Один из самых очевидных источников вариативности, который во многих задачах можно без опаски устранить, – контрастность изображения, т. е. абсолютная вели- чина разности между яркими и темными пикселями. Существует много способов выразить контрастность количественно. В контексте глубокого обучения обычно контрастностью называют стандартное отклонение пикселей всего изображения или его части. Допустим, что изображение представлено тензором X ∈ ℝ r×c×3, где Xi, j, 1 – яр- кость красного в точке на пересечении i-й строки и j-го столбца, Xi, j, 2 – яркость зелено- го, а Xi, j, 3 – яркость синего. Тогда контрастность всего изображения равна (12.1) где X_ – средняя яркость всего изображения: . (12.2) Цель глобальной нормализации контрастности (ГНК) – уравнять контрастность изображения; для этого из каждого пикселя вычитается среднее значение по всему изображению, а затем производится нормировка изображения, так чтобы стандарт- ное отклонение по всем пикселям было равно некоторой константе s. Дополнитель- ная сложность заключается в том, что ни при каком нормировочном коэффициенте невозможно изменить контрастность изображения с нулевой контрастностью (ког- да яркость всех пикселей одинакова). Изображения с очень низкой, но ненулевой контрастностью обычно не несут почти никакого информационного содержания. Деление на истинное стандартное отклонение ничего не дает, а только усиливает шум сенсоров или артефакты сжатия. Поэтому вводится небольшой положительный регуляризационный параметр λ, чтобы сместить оценку стандартного отклонения. Вместо этого можно наложить ограничение на знаменатель: не менее ε. Если дано входное изображение X, то в результате ГНК получается выходное изображение X′, определенное следующим образом:\n--- Страница 384 ---\nКомпьютерное зрение  383 (12.3) В наборе данных, состоящем из больших изображений, обрезанных по границе ин- тересующих объектов, вряд ли имеются изображения с почти постоянной яркостью. В таком случае можно без опаски игнорировать проблему малого знаменателя, поло- жив λ = 0, и избежать деления на 0, возможного в редчайших случаях, взяв в качестве ε какое-нибудь очень малое значение, например 10–8. Именно такой подход принят в работе Goodfellow et al. (2013a) для набора данных CIFAR-10. Для небольших слу- чайно обрезанных изображений шансы получить почти постоянную яркость выше, поэтому агрессивная регуляризация имеет больше смысла. В работе Coates et al. (2011) взяты значения ε = 0, λ = 10 для небольших случайно выбранных фрагментов изображений из набора CIFAR-10. Параметр масштабирования s обычно можно положить равным 1, как сделано в ра- боте Coates et al. (2011), или выбрать так, чтобы стандартное отклонение каждого отдельного пикселя по всем примерам было близко к 1, как в работе Goodfellow et al. (2013a). Стандартное отклонение в формуле (12.3) – это просто умноженная на коэффи- циент норма L 2 изображения (в предположении, что среднее уже вычтено). ГНК предпочтительнее определять в терминах стандартного отклонения, а не нормы L2, поскольку первое включает деление на число пикселей, так что одно и то же значе- ние s можно использовать независимо от размера изображения. Однако тот факт, что норма L2 пропорциональна стандартному отклонению, позволяет сделать не- которые интуитивные заключения. ГНК можно интерпретировать как отображение примеров на сферическую оболочку, как показано на рис. 12.1. Это полезное свой-ство, потому что нейронные сети часто лучше откликаются на пространственные направления, а не на точные позиции. Для отклика на различные расстояния в од- ном направлении необходимы скрытые блоки с коллинеарными векторами весов, но разными смещениями. Такую взаимосвязь алгоритму обучения выявить трудно. Кроме того, у многих мелких графических моделей возникают трудности, когда нужно представить несколько раздельных мод на одной прямой. ГНК предотвра-щает такие проблемы, сводя каждый пример к направлению, а не к комбинации на- правления и расстояния. В противоречие с интуицией существует операция предобработки, называемая сферингом (sphering), отличающаяся от ГНК. Результатом сферинга является не отображение данных на поверхность сферы, а нормировка главных компонент на одинаковую дисперсию, так чтобы многомерное нормальное распределение, исполь-зуемое в алгоритме PCA, имело сферические контуры. Операция сферинга больше известна под названием отбеливание (whitening). Применение глобальной нормализации контрастности зачастую не выделяет тех признаков изображения, которые мы хотели бы подчеркнуть, например границ и углов. Если на сцене имеется большая темная и большая светлая область (напри- мер, городской сквер, половина которого находится в тени здания), то ГНК гаранти- рует значительную разницу между яркостью темной и светлой областей. Однако нет никакой гарантии, что границы внутри темной области будут выделяться.\n--- Страница 385 ---\n384  Приложения ГНК, λ = 10–2 Исходные данные ГНК, λ = 0 1.5 0.0 –1.5 –1.5 –1.5 –1.5 0.0 0.0 0.0 х0 х0 х0х1 1.5 1.5 1.5 Рис. 12.1  ГНК отображает примеры на сферу. (Слева) У исходных дан- ных норма может быть любой. (В центре) ГНК с λ = 0 отображает все не- нулевые примеры на поверхность сферы. В данном случае s = 1 и ε = 10–8. Поскольку ГНК основана на стандартном отклонении, а не на норме L2, эта сфера не единичная. (Справа) Регуляризированная ГНК с λ > 0 сдвигает примеры в сторону сферы, но не полностью устраняет дисперсию нормы. Значения s и λ те же, что и раньше Поэтому нам нужна также локальная нормализация контрастности. Она гаран- тирует нормализацию контрастности в каждом небольшом окне, а не во всем изобра- жении. На рис. 12.2 приведено сравнение глобальной и локальной нормализаций контрастности. Исходное изображениеГлобальная локализацияЛокальная локализация Рис. 12.2  Сравнение глобальной и локальной нормализаций контраст- ности. Визуально эффект глобальной нормализации почти не заметен. Все изображения приводятся примерно к одной шкале, чтобы не заставлять алго- ритм обучения обрабатывать несколько шкал. Локальная нормализация конт-растности изменяет изображение гораздо сильнее, отбрасывая все области постоянной яркости. В результате модель может сосредоточиться только на границах. Области с мелкой текстурой, например дома во втором ряду, могут утратить детали, если ширина ядра нормализации слишком велика Локальную нормализацию контрастности можно определить по-разному. В любом случае модифицируется каждый пиксель: из него вычитается среднее близлежащих\n--- Страница 386 ---\nРаспознавание речи  385 пикселей, и результат делится на стандартное отклонение близлежащих пикселей. Иногда речь идет о настоящем среднем и стандартном отклонениях по прямоуголь- ному окну с центром в модифицируемом пикселе (Pinto et al., 2008). А иногда берется взвешенное среднее и взвешенное стандартное отклонения с весами, имеющими нор- мальное распределение с центром в модифицируемом пикселе. Для цветных изобра- жений есть разные стратегии: в одних цветовые каналы обрабатываются раздельно, в других информация из разных цветовых каналов комбинируется при нормализа- ции каждого пикселя (Sermanet et al., 2012). Обычно локальную нормализацию контрастности можно эффективно реализовать с помощью сепарабельной свертки (см. раздел 9.8), которая вычисляет карты приз- наков локальных средних и локальных стандартных отклонений, с последующим по- элементным вычитанием и поэлементным делением разных карт признаков. Локальная нормализация контрастности – дифференцируемая операция, ее мож- но использовать как в качестве нелинейности, применяемой к скрытым слоям сети, так и в качестве операции предобработки, применяемой к входному изображению. Как и в случае глобальной нормализации контрастности, обычно необходимо ре- гуляризировать локальную нормализацию, чтобы избежать деления на нуль. А по- скольку локальная нормализация применяется к меньшим окнам, то регуляризация даже более важна. В малом окне больше шансов, что значения всех пикселей будут примерно одинаковы, и, стало быть, больше вероятность получить нулевое стандарт- ное отклонение. 12.2.1.2. Пополнение набора данных Как было сказано в разделе 7.4, повысить обобщаемость классификатора можно, прос то увеличив размер обучающего набора путем добавления копий примеров, ко- торые были модифицированы с помощью преобразований, не изменяющих класса. Такой вид пополнения набора данных особенно хорош в применении к распознава- нию объектов, поскольку класс инвариантен к самым разным преобразованиям, так что ко входу можно применить различные геометрические операции. Как уже отме-чалось, классификатор можно улучшить, если включить в набор данных случайные параллельные переносы, повороты, а в некоторых случаях и отражения изображения относительно оси. В специализированных приложениях компьютерного зрения на- бор пополняют и результатами более сложных преобразований, например случайно- го возмущения цветов (Krizhevsky et al., 2012) и нелинейного геометрического иска- жения входа (LeCun et al., 1998b). 12.3. Распознавание речи Задача распознавания речи состоит в том, чтобы отобразить акустический сигнал, содержащий текст, произнесенный на естественном языке, в последовательность слов. Обозначим X = ( x(1), x(2), …, x(Т)) последовательность векторов акустического входа (обычно получаемую разбиением сигнала на отрезки длительностью 20 мс). В большинстве систем распознавания речи для предобработки входа используются специальные спроектированные вручную признаки, но некоторые системы глубоко-го обучения (Jaitly and Hinton, 2011) обучаются признакам прямо на исходных дан-ных. Обозначим y = (y 1, y2, …, yN) целевую выходную последовательность (обычно по- следовательность слов или символов). Задача автоматического распознавания речи\n--- Страница 387 ---\n386  Приложения (АРР , англ. ASR) – создать функцию f* ASR, вычисляющую наиболее вероятную линг- вистическую последовательность y по заданной акустической последовательности X: (12.4) где P* – истинное условное распределение, связывающее входы X с выходами y. Начиная с 1980-х годов и примерно до 2009–2012-го системы распознавания речи строились в основном с помощью комбинации скрытых марковских моделей (СММ) и моделей гауссовых смесей (МГС). МГС моделируют ассоциацию между акусти- ческими признаками и фонемами (Bahl et al., 1987), а СММ – последовательность фонем. В семействе моделей СММ-МГС акустические сигналы рассматриваются как порожденные следующим процессом: сначала СММ генерирует последовательность фонем и подфонемных состояний (начало, середина и конец каждой фонемы), затем МГС преобразует каждый дискретный символ в короткий сегмент акустического сиг- нала. Системы СММ-МГС еще недавно занимали доминирующее положение, но рас-познавание речи стало одной из первых областей применений нейронных сетей, и во многих системах АРР , созданных в конце 1980-х и в начале 1990-х годов, они исполь- зовались (Bourlard and Wellekens, 1989; Waibel et al., 1989; Robinson and Fallside, 1991; Bengio et al., 1991, 1992; Konig et al., 1996). В то время качество систем АРР на основе нейронных сетей было приблизительно таким же, как систем СММ-МГС. Например, в работе Robinson and Fallside (1991) была достигнута частота ошибок распознавания фонем 26% на корпусе текстов TIMIT (Garofolo et al., 1993), содержащем 39 различи-мых фонем, что было сравнимо с СММ-системами или даже лучше. С тех пор корпус TIMIT стал эталоном для распознавания фонем и играет такую же роль, как набор данных MNIST для распознавания объектов. Тем не менее из-за технических сложно-стей построения программных систем для распознавания речи и тех усилий, которые были вложены в создание таких систем на основе СММ-МГС, индустрия не увидела убедительных аргументов в пользу перехода на нейронные сети. Поэтому до конца 2000-х проводимые в академических и промышленных кругах исследования по при- менению нейронных сетей к распознаванию речи были в основном сосредоточены на обучении дополнительных признаков для систем СММ-МГС. Позже, когда модели стали гораздо больше и глубже, а размер наборов данных резко увеличился, верность распознавания удалось значительно повысить, используя ней-ронные сети вместо МГС для ассоциированния акустических признаков с фонемами (или подфонемными состояниями). Начиная с 2009 года ученые применили к рас- познаванию речи вариант глубокого обучения на базе обучения без учителя. В основе этого подхода лежало применение неориентированных вероятностных моделей, на-зываемых ограниченными машинами Больцмана (ОМБ, англ. RBM), к моделирова- нию входных данных. ОМБ описаны в третьей части книги. Для распознавания речи использовали предобучение без учителя для построения глубокой сети прямого рас-пространения, слои которой инициализировались посредством обучения ОМБ. Эти сети принимали представление акустического спектра во входном окне фиксирован-ного размера (вокруг центрального кадра) и предсказывали условные вероятности состояний СММ для этого центрального кадра. Обучение глубоких сетей позволило значительно повысить частоту распознавания на корпусе TIMIT (Mohamed et al., 2009, 2012a), снизив частоту ошибок с 26 до 20.7%. В работе Mohamed et al. (2012b) проанализированы причины успеха таких моделей. Распространение на конвейер распознавания в телефоне привело к добавлению адаптивных признаков (Mohamed\n--- Страница 388 ---\nРаспознавание речи  387 et al., 2011), что позволило еще снизить частоту ошибок. Затем быстро последовали работы по обобщению архитектуры с распознавания фонем (тема корпуса TIMIT) на распознавание речи с большим словарем (Dahl et al., 2012), т. е. распознавание по- следовательностей слов, взятых из большого словаря. В конечном итоге акцент в при- менении глубоких сетей для распознавания речи сместился с предобучения и машин Больцмана на такие темы, как блоки линейной ректификации и прореживание (Zeiler et al., 2013; Dahl et al., 2013). К тому времени большинство известных коллективов в промышленности приступило к исследованию глубокого обучения совместно с уче- ными из академического сообщества. В работе Hinton et al. (2012a) описаны проры- вы, которых удалось достичь в результате такого сотрудничества, сейчас они внедре- ны в смартфоны и другие изделия. Впоследствии, по мере увеличения размеченных наборов данных и включения не- которых методов инициализации, обучения и настройки архитектуры глубоких се- тей, эти группы пришли к выводу, что этап предобучения без учителя либо излишний, либо не дает существенного улучшения. Качественный прорыв в терминах частоты ошибок распознавания слов был бес- прецедентным (около 30%), и за ним последовал длительный период, примерно 10 лет, в течение которого применение традиционной технологии СММ-МГС не при- водило к существенному снижению частоты ошибок, несмотря на постоянно увели- чивающийся размер обучающих наборов (см. рис. 2.4 в работе Deng and Yu [2014]). В результате исследователи в области распознавания речи обратили взоры в сторону глубокого обучения. Не прошло и двух лет, как большинство коммерческих продук- тов для распознавания речи включало глубокие нейронные сети, что подхлестнуло новые исследования по алгоритмам глубокого обучения и архитектурам АРР . Эти исследования продолжаются и по сей день. Одним из новшеств стало использование сверточных сетей (Sainath et al., 2013), реплицирующих веса по времени и частоте, что привело к улучшению качества, по сравнению с нейронными сетями с временной задержкой, в которых веса реплициро- вались только по времени. В новых двумерных сверточных моделях входная спект- рограмма рассматривалась не как один длинный вектор, а как изображение, одна ось которого соответствует времени, а другая – частоте спектральных составляющих. Еще одно важное направление, работы в котором по-прежнему ведутся, – переход к сквозным системам распознавания речи на базе глубокого обучения, из которых вообще устранены СММ. Первым значительным прорывом в этом направлении ста- ла работа Graves et al. (2013), в которой обучена глубокая рекуррентная нейронная сеть LSTM (см. раздел 10.10), использующая вывод на базе максимума апостериор-ной вероятности поверх совмещения кадров с фонемами, как в работе LeCun et al. (1998b) и в системе CTC (Graves et al., 2006; Graves, 2012). В глубокой РНС (Graves et al., 2013) имеются переменные состояния из нескольких слоев на каждом временном шаге, что придает развернутому графу два вида глубины: обычную, обусловленную наличием нескольких слоев, и вследствие развертки во времени. В этой работе час- тоту ошибок распознавания фонем на корпусе TIMIT удалось снизить до рекордных 17.7%. О вариантах глубоких РНС, применяемых в других ситуациях, см. работы Pascanu et al. (2014a) и Chung et al. (2014). Еще один недавний шаг в сторону сквозного глубокого обучения систем АРР – на- учить систему «совмещать» акустическую информацию с фонетической (Chorowski et al., 2014; Lu et al., 2015).\n--- Страница 389 ---\n388  Приложения 12.4. Обработка естественных языков Под обработкой естественных языков (ОЕЯ, англ. NLP) понимается использование таких языков, как английский или русский, компьютером. Компьютерные програм- мы обычно читают и порождают тексты на искусственных языках, спроектированных с целью обеспечить эффективный и однозначный грамматический разбор. Естествен- ные языки зачастую неоднозначны и не поддаются формальному описанию. К сфере обработки естественных языков относятся такие приложения, как машинный пере-вод, когда обучаемая система читает предложение на одном языке и порождает экви- валентное ему на другом языке. Многие приложения ОЕЯ основаны на языковых мо-делях, в которых определено распределение вероятности последовательностей слов, символов и байтов в естественном языке. Как и в случае других обсуждаемых в этой главе приложений, весьма общие ней- росетевые методы можно с успехом применить и к обработке естественных языков. Но для достижения высокого качества и масштабируемости важны предметно-ори- ентированные стратегии. Для построения эффективной модели естественного языка обычно используются методы, специализированные для обработки последователь-ных данных. Во многих случаях мы предпочитаем рассматривать естественный язык как последовательность слов, а не отдельных символов или байтов. Поскольку число слов велико, словесные модели языка должны работать в разреженных дискретных пространствах очень высокой размерности. Разработано несколько стратегий обеспе-чения вычислительной и статистической эффективности таких моделей. 12.4.1. n-граммы В языковой модели определено распределение вероятности последовательностей лексем естественного языка. В зависимости от вида модели лексемой может быть слово, символ или даже байт. Лексемы всегда дискретны. В самых ранних успешных языковых моделях использовались последовательности лексем фиксированной дли-ны, называемые n-граммами. В моделях на основе n-грамм определена условная вероятность n-ой лексемы при условии предыдущих n – 1 лексем. Произведения этих условных вероятностей опре- деляют распределение вероятности более длинных последовательностей: (12.5) Это разложение – не что иное, как цепное правило вероятностей. Распределение вероятности начальной последовательности P(x1, …, xn–1) можно смоделировать с по- мощью другой модели с меньшим значением n. Обучение n-граммных моделей не вызывает трудностей, потому что оценку мак- симального правдоподобия можно вычислить, просто подсчитав, сколько раз каждая возможная n-грамма встречается в обучающем наборе. Модели на основе n-грамм были основным компонентом статистического моделирования языков в течение мно- гих десятилетий (Jelinek and Mercer, 1980; Katz, 1987; Chen and Goodman, 1999). Для небольших значений n у n-грамм даже есть специальные названия: униграмма для n = 1, биграмма для n = 2 и триграмма для n = 3. Эти названия образуются из ла- тинского префикса числительного и греческого суффикса «грамма», обозначающего нечто написанное.\n--- Страница 390 ---\nОбработка естественных языков  389 Обычно модели n-грамм и (n–1)-грамм обучаются одновременно. Это упрощает вычисление (12.6) – нужно лишь найти две сохраненные вероятности. Чтобы точно воспроизвести вы- вод в модели Pn, мы должны опустить последний символ каждой последовательности при обучении Pn–1. В качестве примера продемонстрируем, как триграммная модель вычисляет ве- роятность предложения «THE DOG RAN AWAY» (собака убежала). Первые слова предло- жения нельзя обработать с помощью формулы по умолчанию, основанной на услов- ной вероятности, потому что в начале предложения еще нет никакого контекста. Поэтому вначале используются безусловные вероятности слов. Таким образом, мы вычисляем P 3(THE DOG RAN). Последнее же слово можно предсказать стандартно, вос- пользовавшись условным распределением P(AWAY | DOG RAN). Подстановка в формулу (12.6) дает: P(THE DOG RAN AWAY) = P3(THE DOG RAN)P3(DOG RAN AWAY)/P2(DOG RAN). (12.7) Фундаментальное ограничение максимального правдоподобия в n-граммных мо- делях состоит в том, что оценка Pn по счетчикам в обучающем наборе во многих слу- чаях близка к нулю, несмотря даже на то, что кортеж (xt–n+1, …, xt) может встречать- ся в тестовом наборе. Это может привести к катастрофическим последствиям двух видов. Если Pn–1 равно нулю, то отношение не определено, поэтому модель вообще не дает разумного ответа. Если же Pn–1 не равно нулю, но Pn равно нулю, то логариф- мическая вероятность равна –∞ . Чтобы избежать таких неприятностей, в большин- стве n-граммных моделей используется та или иная форма сглаживания. Смысл этого приема состоит в том, чтобы сдвинуть массу вероятности от наблюдавшихся кортежей к ненаблюдавшимся, но похожим. Обзор и эмпирические сравнения см. в работе See Chen and Goodman (1999). Одна из основных техник – прибавить не- нулевую массу вероятности ко всем возможным значениям символов. Этот метод можно обосновать как байесовский вывод, в котором априорное распределение счет- чиков равномерно или является распределением Дирихле. Еще одна очень популяр-ная идея – образовать смесовую модель из n-граммных моделей высокого и низкого порядков, где модели высокого порядка обеспечивают большую емкость, а модели низкого порядка с большей вероятностью избегают нулевых счетчиков. Возвратные методы ищут n-граммы низкого порядка, если частота контекста x t–1, …, xt–n+1 слишком мала для использования модели более высокого порядка. Точнее, они оценивают рас-пределение x t с использованием контекстов xt–n+k, …, xt–1 для возрастающих k, пока не будет найдена достаточно надежная оценка. Классические n-граммные модели особенно уязвимы к проклятию размерности. Существует |𝕍|n возможных n-грамм, и |𝕍| зачастую очень велико. Даже при наличии массивного обучающего набора и умеренном n большинство n-грамм в обучающем наборе не встречается. Классическую n-граммную модель можно рассматривать как поиск ближайшего соседа, т. е. как локальный непараметрический предиктор, похо- жий на метод k ближайших соседей. Статистические проблемы, присущие таким экст- ремально локальным предикторам, описаны в разделе 5.11.2. Но в языковой модели проблема даже серьезнее, чем обычно, потому что два любых разных слова находятся\n--- Страница 391 ---\n390  Приложения на одинаковом расстоянии друг от друга в пространстве унитарных векторов. По- этому трудно извлечь хоть какую-то информацию из «соседей» – лишь обучающие примеры, буквально повторяющие один и тот же контекст, полезны для локального обобщения. Для преодоления этих проблем модель языка должна уметь разделять знания между одним словом и другими семантически похожими словами. Чтобы улучшить статистическую эффективность n-граммных моделей, в классо- вые языковые модели (Brown et al., 1992; Ney and Kneser, 1993; Niesler et al., 1998) введено понятие категории слова, и статистическая сила разделяется между словами из одной категории. Идея в том, чтобы применить алгоритм кластеризации для раз- биения слов по кластерам, или классам, исходя из частоты совместной встречаемости с другими словами. После этого модель может использовать идентификаторы клас- сов, а не идентификаторы отдельных слов для представления контекста справа от вертикальной черты в выражении условной вероятности. Возможны также состав- ные модели, в которые словесные и классовые модели комбинируются путем сме- шения или перебора с возвратом. Хотя классы слов допускают обобщение на после- довательности, в которых одно слово заменено другим из того же класса, при таком представлении теряется много информации. 12.4.2. Нейронные языковые модели Нейронные языковые модели (НЯМ, англ. NLM) предназначены для преодоления проклятия размерности при моделировании последовательностей слов естествен-ного языка посредством распределенного представления слов (Bengio et al., 2001). В отличие от классовых n-граммных моделей, нейронные языковые модели способ- ны понять, что два слова похожи, не жертвуя возможностью кодировать каждое сло-во независимо от остальных. В нейронных языковых моделях статистическая сила разделяется между одним словом (и его контекстом) и другими похожими словами и контекстами. Распределенное представление, которому модель обучается для каж- дого слова, обеспечивает такое разделение, позволяя модели обрабатывать слова с об- щими признаками схожим образом. Например, если слова dog (собака) и cat (кошка) отображаются в представления, имеющие много общих атрибутов, то предложения, содержащие слово cat, могут влиять на предсказания, которые модель дает для пред- ложений со словом dog, и наоборот. Поскольку таких атрибутов много, существует много способов обобщения, т. е. информация из каждого обучающего предложения переносится на экспоненциально большое число семантически родственных предло-жений. Проклятие размерности требует, чтобы количество предложений, на которые обобщается модель, экспоненциально зависело от длины предложения. Модель про-тивостоит проклятию, сопоставляя каждому обучающему предложению экспонен-циально большое число похожих предложений. Иногда такие представления слов называются векторными представлениями, или погружениями слов (word embedding). При такой интерпретации мы рассматриваем исходные символы как точки в пространстве с числом измерений, равным размеру словаря. А векторное представление погружает эти точки в пространство призна- ков меньшей размерности. В исходном пространстве каждое слово представляется унитарным вектором, т. е. евклидово расстояние между любой парой слов равно √_ 2. В пространстве признаков близки слова, часто встречающиеся в похожих контекстах (или любая пара слов с общими «признаками», которым обучилась модель). Часто это приводит к тому, что слова с похожим смыслом оказываются соседями. На рис. 12.3\n--- Страница 392 ---\nОбработка естественных языков  391 приведены некоторые области пространства обученных признаков слов, чтобы пока- зать, как семантически похожие слова отображаются в близкие представления. Нейронные сети в других предметных областях также определяют погружения. Например, скрытый слой сверточной сети определяет «погружение изображения». Но для специалистов по ОЕЯ идея погружения представляет особый интерес, по-тому что изначально естественный язык не лежит в вещественном векторном прост- ранстве. Скрытый слой дает качественно иное представление данных, существенно отличающееся от исходного. –6 –7–8–9 –10–11–12 –13 –1422 2120 19 1817–34 –32 –30 –28 –26 35.0 35.5 36.0 36.5 37.0 37.538.0 Рис. 12.3  Двумерная визуализация погружения слов, полученных от нейронной модели машинного перевода (Bahdanau et al., 2015). Выделе- ны области, где векторы, соответствующие семантически родственным словам, близки друг к другу. Слева показаны страны, справа – числа. Не забывайте, что двумерное векторное представление показано только для наглядности. В реальных приложениях размерность векторного представ- ления обычно выше, поскольку одновременно улавливаются различные аспекты сходства между словами Идея использования распределенных представлений для улучшения моделей обработки естественных языков не ограничивается нейронными сетями. Ее можно распространить и на графические модели, имеющие распределенные представления в форме нескольких скрытых переменных (Mnih and Hinton, 2007). 12.4.3. Многомерные выходы Во многих приложениях для обработки естественных языков мы хотим, чтобы мо-дель выводила слова, а не символы. Если словарь большой, то вычислительно очень трудно представить выходное распределение выбора слов. Часто словарь 𝕍 насчи- тывает сотни тысяч слов. Наивный подход к представлению такого распределения – выполнить аффинное преобразование скрытого представления на пространство выходов, а затем применить функцию softmax. Пусть имеется словарь 𝕍 размера |𝕍|. Матрица весов, описывающая линейную составляющую такого аффинного преобра-зования, очень велика, поскольку размерность результата составляет |𝕍|. Поэтому для ее хранения требуется много памяти, а умножение на нее займет много времени. По- скольку softmax нормируется по всем |𝕍| выходам, придется выполнять полное умно-жение на матрицу как на этапе обучения, так и на этапе тестирования – мы не можем ограничиться только вычислением скалярного произведения на вектор весов. Таким\n--- Страница 393 ---\n392  Приложения образом, вычислительная стоимость выходного слоя велика как во время обучения (нужно вычислять правдоподобие и его градиент), так и во время тестирования (нуж- но вычислять вероятности всех или избранных слов). Для специальных функций по-терь градиент можно вычислить эффективно (Vincent et al., 2015), но применение стандартной перекрестной энтропии к традиционному выходному слою с функцией softmax сталкивается с многочисленными трудностями. Предположим, что h – верхний скрытый слой, используемый для предсказания вероятностей выходов yˆ. Если параметризовать преобразование h в yˆ обученными весами W и смещениями b, то выходной слой с аффинным преобразованием и функ- цией softmax выполняет следующие вычисления: ; (12.8) (12.9) Если h содержит nh элементов, то сложность этой операции равна O(|𝕍|nh). Когда nh порядка тысячи, а |𝕍| порядка сотен тысяч, на эту операцию приходится основное время вычислений в большинстве моделей на основе нейронных сетей. 12.4.3.1. Использование короткого списка В первых нейронных языковых моделях (Bengio et al., 2001, 2003) проблема высо-кой стоимости использования softmax при большом числе выходных слов решалась ограничением размера словаря 10–20 тысячами слов. В работах Schwenk and Gauvain (2002) и Schwenk (2007) этот подход подвергся дальнейшему развитию: словарь 𝕍 был разделен на короткий список 𝕃 самых частых слов (обрабатываемый нейронной сетью) и хвост 𝕋 = 𝕍\\𝕃 более редких слов (обрабатываемый n-граммной моделью). Чтобы оба предсказания можно было объединить, нейронная сеть должна также пред-сказывать вероятность, что слово, следующее за контекстом C, принадлежит хвос- товому списку. Для этого можно добавить дополнительный сигмоидный выходной блок, дающий оценку P(i ∈ 𝕋 | C). Тогда дополнительный выход можно использовать для получения оценки распределения вероятности всех слов из 𝕍: P(y = i | C) = 1 i∈𝕃P(y = i | C, i ∈ 𝕃 )(1 – P(i ∈ 𝕋 | C)) + 1i∈𝕋P(y = i | C, i ∈ 𝕋)P(i ∈ 𝕋 | C), (12.10) где P(y = i | C, i ∈ 𝕃) порождается нейронной языковой моделью, а P(y = i | C, i ∈ 𝕋) – n-граммной моделью. После небольшой модификации этот подход будет работать, если ввести дополнительное выходное значение в softmax-слой нейронной языковой модели, а не заводить отдельный сигмоидный блок. Очевидный недостаток короткого списка состоит в том, что потенциальный вы- игрыш от обобщаемости нейронных языковых моделей ограничен самыми часто встречающимися словами, а они-то как раз наименее полезны. Этот недостаток сти- мулировал интерес к описанным ниже альтернативным методам работы с многомер- ным выходным слоем. 12.4.3.2. Иерархическое вычисление softmax Классический подход (Goodman, 2001) к уменьшению вычислительной нагрузки на многомерные выходные слои при большом размере словаря 𝕍 – иерархическое раз-\n--- Страница 394 ---\nОбработка естественных языков  393 ложение вероятностей. Объем вычислений, пропорциональный | 𝕍| (и количеству скрытых слоев nh), можно сократить до величины, пропорциональной log| 𝕍|. В ра- ботах Bengio (2002) и Morin and Bengio (2005) эта идея факторизации применена в контексте нейронных языковых моделей. Иерархию можно представлять себе как построение категорий слов, затем катего- рий категорий слов и т. д. Вложенные категории образуют дерево, в листьях которо- го находятся слова. Глубина сбалансированного дерева равна O(log|𝕍|). Вероятность выбора слова равна произведению вероятностей выбора ветви на всем пути, ведущем от корня к этому слову. На рис. 12.4 приведен простой пример. В работе Mnih and Hinton (2009) описано также, как использовать несколько путей для идентификации одного слова, чтобы лучше смоделировать слова, имеющие несколько значений. Тог-да вычисление вероятности слова сводится к суммированию по всем ведущим к нему путям. Для предсказания условных вероятностей, необходимых в каждом узле дерева, мы обычно используем модель логистической регрессии в узлах и подаем на вход всех моделей один и тот же контекст C. Поскольку правильный выход уже указан в обучаю щем наборе, для обучения моделей логистической регрессии можно приме- нить обучение с учителем. Обычно при этом используется стандартная перекрестная энтропия в качестве функции потерь, что соответствует максимизации логарифмиче- ского правдоподобия правильной последовательности решений. Поскольку выходное логарифмическое правдоподобие можно вычислить эффек- тивно (объем вычислений пропорционален log| 𝕍|, а не |𝕍|), то и градиенты тоже вы- числяются эффективно. И это относится не только к градиентам по выходным пара- метрам, но и к градиентам по активациям скрытых слоев. Возможно, хотя на практике так обычно не поступают, оптимизировать структуру дерева, чтобы уменьшить ожидаемый объем вычислений. Методы теории информа-ции говорят, как построить оптимальный двоичный код, если известны относитель-ные частоты слов. Для этого мы могли бы структурировать дерево так, чтобы число бит, ассоциированных со словом, было приблизительно равно логарифму частоты этого слова. На практике, однако, такая экономия редко стоит усилий, потому что вычисление выходных вероятностей – это лишь часть общего объема вычислений в нейронной языковой модели. Предположим, к примеру, что имеется l полносвязных скрытых слоев ширины n h. Обозначим nb взвешенное среднее числа бит, необходимых для идентификации слова, в котором вес слова равен его частоте. В нашем случае чис- ло операций, выполняемых для вычисления скрытых активаций, растет как O(lnh2), а объем вычислений выхода – как O(nhnb). Если nb ≤ lnh, то для сокращения объема вычислений лучше уменьшать nh, а не nb. На самом деле nb часто мало. Поскольку размер словаря редко превышает миллион слов, а log2(106) ≈ 20, можно уменьшить nb примерно до 20, тогда как nh обычно гораздо больше – порядка 103 и более. Вместо того чтобы тщательно оптимизировать дерево с коэффициентом ветвления 2, мы мо- жем определить дерево глубины 2 с коэффициентом ветвления √_ |𝕍|. Такое дерево со- ответствует определению множества взаимно исключающих классов слов. Простой подход, основанный на дереве глубины 2, сохраняет большую часть вычислительных преимуществ иерархической стратегии. Остается открытым один вопрос – как лучше всего определить классы слов, или как определить иерархию слов вообще. В ранних работах использовались существую- щие иерархии (Morin and Bengio, 2005), однако иерархию тоже можно обучить, в иде-\n--- Страница 395 ---\n394  Приложения але совместно с нейронной языковой моделью. Обучать иерархию трудно. Точная оптимизация логарифмического правдоподобия представляется невозможной, пото- му что выбор иерархии слов – дискретная задача, к которой градиентная оптимиза- ция неприменима. Однако можно воспользоваться дискретной оптимизацией, чтобы приблизительно аппроксимировать разбиение слов по классам. Рис. 12.4  Иллюстрация простой иерархии категорий слов на примере 8 слов w0, …, w7, организованных в трехуровневую иерархию. В листьях де- рева находятся сами слова. Внутренние узлы представляют группы слов. Каждый узел можно индексировать последовательностью бинарных реше-ний (0 = влево, 1 = вправо), описывающих путь от корня к этому узлу. Супер- класс (0) содержит два класса: (0, 0) и (0, 1), содержащих соответственно множества слов {w 0, w1} и {w2, w3}. Аналогично суперкласс (1) содержит два класса: (1, 0) и (1, 1), содержащих соответственно множества слов {w4, w5} и {w6, w7}. Если дерево достаточно сбалансировано, то максимальная глу- бина (число бинарных решений) по порядку величины равна логарифму числа слов |𝕍|: для выбора одного из |𝕍| слов нужно произвести O(log |𝕍|) операций (по одной для каждого узла на пути от корня). В этом примере для вычисления вероятности слова y нужно перемножить три вероятности, ассоциированные с бинарными решениями, принимаемыми в каждом узле на пути от корня к узлу y. Обозначим bi(y) – i-е бинарное решение, прини- маемое в процессе обхода дерева на пути к значению y. Тогда вероятность выборки выхода y разлагается в произведение условных вероятностей. На- пример, вероятность w4 можно представить в виде произведения следую- щим образом: P(y = w4) = P(b0 = 1, b1 = 0, b2 = 0) (12.11) = P(b0 = 1)P(b1 = 0 | b0 = 1)P(b2 = 0 | b0 = 1, b1 = 0). (12.12)\n--- Страница 396 ---\nОбработка естественных языков  395 Важное преимущество иерархического вычисления softmax – тот факт, что вычис- лительный выигрыш достигается как на этапе обучения, так и на этапе тестирования, если во время тестирования мы захотим вычислить вероятности конкретных слов. Разумеется, вычисление вероятностей всех |𝕍| слов по-прежнему обходится дорого, даже при иерархическом подходе. Еще одна важная операция – выбор самого вероят- ного слова в данном контексте. К сожалению, древовидная структура не дает эффек- тивного и точного решения этой задачи. Недостаток состоит в том, что на практике иерархическое вычисление softmax час- то дает при тестировании худшие результаты, чем выборочные методы, описанные ниже. Это может быть связано с неудачным выбором классов слов. 12.4.3.3. Выборка по значимости Ускорить обучение нейронных языковых моделей можно, в частности, избежав явно- го вычисления вклада в градиент от всех слов, которые не встречаются в следующей позиции. У любого недопустимого слова должна быть низкая вероятность в модели. Перечисление всех таких слов стоит дорого. Но можно вместо этого выбрать лишь их подмножество. В обозначениях из формулы (12.8) градиент можно записать в сле- дующем виде: (12.13) (12.14) (12.15) (12.16) где a – вектор активаций до применения softmax (оценок), по одному элементу на каждое слово. Первый член – положительная фаза, толкающая ay вверх, второй член – отрицательная фаза, толкающая ai вниз с весом P(i | C) для всех i. Поскольку отрицательная фаза – это математическое ожидание, то оценить ее можно по выборке Монте-Карло. Однако для этого потребовалось бы производить выборку из самой модели. Выборка из модели подразумевает вычисление P(i | C) для всех i в словаре, а это как раз то, чего мы хотим избежать. Вместо выборки из модели мы можем произвести выборку из другого распреде- ления, которое называется вспомогательным распределением (proposal distribution) и обозначается q, и использовать подходящие веса для корректировки смещения вследствие выборки не из того распределения (Bengio and Senecal, 2003; Bengio and Senecal, 2008). Это пример применения более общей техники, называемой выборкой по значимости, подробно она будет описана в разделе 17.2. К сожалению, даже точная выборка по значимости не эффективна, потому что требуется вычисление весов p i/qi, где pi = P(i | C), а их можно вычислить, только если вычислены все веса ai. Специально для данного приложения предложено решение, называемое смещенной выборкой по значимости, когда веса нормированы, так что их сумма равна 1. Если выбрано отри-цательное слово n i, то ассоциированный градиент входит с весом\n--- Страница 397 ---\n396  Приложения (12.17) С помощью этих весов придается подходящая значимость m отрицательным при- мерам из q, используемым для формирования оценки вкладка отрицательной фазы в градиент: (12.18) В качестве вспомогательного распределения q вполне можно использовать распре- деление униграмм или биграмм. Параметры такого распределения легко оценить по данным. После оценки параметров выборка из распределения производится очень эффективно. Выборка по значимости полезна не только для ускорения работы моде-лей с большими выходными softmax-слоями, но и во всех случаях, когда нужно уско- рить обучение при наличии большого выходного слоя, представленного разреженным вектором, а не выбором 1 из n. Примером может служить набор слов (bag of words). Это разреженный вектор v, элемент v i которого обозначает присутствие или отсут- ствие в документе i-го слова из словаря. Альтернативно vi может показывать, сколь- ко раз встречается i-е слово. Обучить модель машинного обучения, порождающую такие векторы, бывает трудно по ряду причин. На ранних стадиях обучения модель не всегда порождает по-настоящему разреженный выход. Кроме того, используемая при обучении функция потерь, возможно, более естественно описывается в терминах сравнения каждого элемента выхода с меткой. Это означает, что не всегда очевидно, есть ли вычислительный выигрыш от использования разреженного выхода, посколь-ку модель может сделать большинство выходных элементов ненулевыми, и все эти ненулевые элементы придется сравнивать с соответствующими обучающими метка- ми, даже если метка нулевая. В работе Dauphin et al. (2011) продемонстрировано, что такие модели можно ускорить с помощью выборки по значимости. Эффективный ал- горитм минимизирует реконструкцию потери для «положительных слов» (для кото-рых метка ненулевая) и равного числа «отрицательных слов». Отрицательные слова выбираются случайным образом с применением эвристики для выбора слов, которые с большей вероятностью будут ошибочными. Смещение, вызванное такой выборкой с запасом, можно затем скорректировать с помощью весов значимости. Во всех этих случаях вычислительная сложность оценивания градиента для вы- ходного слоя уменьшается и становится пропорциональной числу отрицательных примеров, а не размеру выходного вектора. 12.4.3.4. Шумосопоставительное оценивание и потеря ранжирования Были предложены и другие способы уменьшения вычислительной сложности обуче- ния нейронных языковых моделей с большими словарями. Один из ранних подхо- дов – потеря ранжирования (ranking loss) – описан в работе Collobert and Weston (2008a), где выход нейронной языковой модели для каждого слова рассматривается как балльная оценка и производится попытка сделать так, чтобы оценка правильного слова a y ранжировалась выше, по сравнению с остальными оценками ai. Тогда потеря ранжирования равна (12.19)\n--- Страница 398 ---\nОбработка естественных языков  397 Градиент для i-го члена равен нулю, если оценка наблюдаемого слова ay больше оценки отрицательного слова ai не менее, чем на 1. У этого критерия есть недоста- ток – он не дает оценку условных вероятностей, что полезно в некоторых приложе- ниях, в т. ч. для распознавания речи и порождения текста (включая условное порож- дение текста, как в случае перевода). Позже в качестве целевой функции обучения для нейронных языковых моделей было предложено шумосопоставительное оценивание (noise-contrastive estimation), описанное в разделе 18.6 (Mnih and Teh, 2012; Mnih and Kavukcuoglu, 2013). 12.4.4. Комбинирование нейронных языковых моделей с n-граммами Важное преимущество n-граммных моделей, по сравнению с нейронными сетями, со- стоит в том, что первые достигают высокой емкости (за счет хранения частот очень большого числа кортежей) при очень скромном объеме вычислений в ходе обработ- ки примера (требуется найти лишь немного примеров, соответствующих текущему контексту). Если для доступа к счетчикам использовать хэш-таблицы или деревья, то объем вычислений в n-граммной модели почти не зависит от емкости. Для срав- нения – удвоение числа параметров нейронной сети обычно приводит к увеличению времени вычислений примерно вдвое. Исключение составляют модели, в которых на каждом проходе используются не все параметры. При наличии слоев погружения на каждом проходе индексируется только одно погружение, поэтому размер словаря можно увеличить, не увеличивая времени обработки каждого примера. В некоторых других моделях, например периодических сверточных сетях, можно добавлять па-раметры, одновременно уменьшая степень разделения параметров, чтобы сохранить объем вычислений на прежнем уровне. Но в слоях типичных нейронных сетей, осно- ванных на умножении матриц, объем вычислений пропорционален числу парамет ров. Таким образом, для увеличения емкости можно поступить просто: построить ан- самбль, содержащий нейронную и n-граммную языковую модель (Bengio et al., 2001, 2003). Как и любая ансамблевая техника, этот метод может уменьшить ошибку тести- рования, если члены ансамбля совершают ошибки независимо друг от друга. В ан- самб левом обучении есть много способов скомбинировать предсказания отдельных членов, в т. ч. равномерное взвешивание и выбор весов на контрольном наборе. В ра- боте Mikolov et al. (2011a) ансамбль обобщен с двух моделей на большой массив мо- делей. Можно также объединить нейронную сеть с моделью максимальной энтропии и обучить обе совместно (Mikolov et al., 2011b). Этот подход можно рассматривать как обучение нейронной сети с дополнительным множеством входов, напрямую свя- занных с выходом и не связанных ни с какой другой частью модели. Дополнительные входы указывают на присутствие определенных n-грамм во входном контексте, так что эти переменные имеют очень высокую размерность и сильно разрежены. Увели- чение емкости модели получается гигантским – новая часть архитектуры содержит до |sV| n параметров, но дополнительный объем вычислений минимален, потому что добавленные входные данные крайне разрежены. 12.4.5. Нейронный машинный перевод Задача машинного перевода состоит в чтении предложения на одном естественном языке и выводе предложения с эквивалентным смыслом на другом языке. Системы машинного перевода обычно состоят из многих компонент. На верхнем уровне име-\n--- Страница 399 ---\n398  Приложения ется один компонент, который предлагает большое число потенциальных переводов. Многие переводы грамматически некорректны из-за различий между языками. На-пример, в некоторых языках прилагательные ставятся после существительных, так что при переводе на английский получаются фразы типа «apple red». Механизм пред-ложений рекомендует много вариантов перевода, и в идеале среди них будет и «red apple». Второй компонент системы перевода, языковая модель, оценивает предло-женные переводы и может поставить варианту «red apple» более высокую оценку, чем варианту «apple red». Уже в самых первых исследованиях применения нейронных сетей к машинно- му переводу встречалась идея кодировщика и декодера (Allen 1987; Chrisman 1991; Forcada and Ñeco 1997), а первым крупным коммерческим приложением в этой области стал переход на нейронную языковую модель в одной системе перевода (Schwenk et al., 2006; Schwenk, 2010). Ранее в большинстве систем машинного пере-вода для этой цели применялась n-граммная модель. В машинном переводе исполь- зуются не только традиционные возвратные n-граммные модели (Jelinek and Mercer, 1980; Katz, 1987; Chen and Goodman, 1999), но также языковые модели максималь- ной энтропии (Berger et al., 1996), в которых слой с аффинным преобразованием и функцией softmax предсказывает следующее слово при наличии частых n-грамм в контексте. Традиционные языковые модели просто возвращают вероятность предложения естественного языка. Поскольку задача машинного перевода – породить выходное предложение по известному входному, имеет смысл обобщить модель естественного языка, сделав ее условной. В разделе 6.2.1.1 был описан прямолинейный способ обоб- щения модели, определяющей маргинальное распределение некоторой переменной таким образом, чтобы она определяла условное распределение той же переменной при заданном контексте C, где C может быть одной переменной или списком пере- менных. В работе Devlin et al. (2014) превзойдено лучшее достижение на некоторых эталонных тестах для машинного перевода; для этого авторы использовали МСП, ко-торый оценивал фразу t 1, t2, …, tk на целевом языке, зная фразу s1, s2, …, sn на исходном языке. МСП вычисляет оценку в виде вероятности P(t1, t2, …, tk | s1, s2, …, sn). Оцен- ка, вычисленная этим МСП, используется вместо оценки, предложенной условной n-граммной моделью. Недостаток подхода на основе МСП состоит в том, что последовательности нуж- но предварительно обработать, так чтобы их длина была фиксирована. Для повыше-ния гибкости перевода хотелось бы иметь модель, которая подстраивается под вхо-ды и выходы переменной длины. Такую возможность дает рекуррентная нейронная сеть. В разделе 10.2.4 описано несколько способов построения РНС, представляющей условное распределение последовательности при условии входа, а в разделе 10.4 – как реализовать такое обусловливание, когда входом является последовательность. В любом случае сначала одна модель читает входную последовательность и порожда- ет структуру данных, содержащую ее сводку. Эта сводка называется «контекстом» C. Контекст может быть списком векторов, вектором или тензором. Модель, которая чи-тает вход и порождает C, может представлять собой РНС (Cho et al., 2014a; Sutskever et al., 2014; Jean et al., 2014) или сверточную сеть (Kalchbrenner and Blunsom, 2013). Затем вторая модель, обычно РНС, читает контекст C и порождает предложение на целевом языке. Эта общая идея кодировщика-декодера для машинного перевода по-казана на рис. 12.5.\n--- Страница 400 ---\nОбработка естественных языков  399 КодировщикВыходной объект (предложение на английском языке) Промежуточное семантическое представление Исходный объект (предложение на французском языке или изображение)Декодер Рис. 12.5  Архитектура кодировщик-декодер, реализующая отобра- жение между поверхностным представлением (например, последова- тельностью слов или изображением) и семантическим представлением. Кодировщик преобразует данные, представленные в одной модальности (например, предложение на французском языке в скрытое представление, улавливающее смысл предложения), и его выход подается на вход деко- дера, ориентированного на другую модальность (например, преобразую-щего скрытое семантическое представление в предложение на английском языке). Применяя кодировщик и декодер, мы можем обучить систему для перевода из одной модальности в другую. Эта идея с успехом применялась не только к машинному переводу, но и для генерации подписей к изобра- жениям Чтобы сгенерировать все предложение, обусловленное предложением на исход- ном языке, модель должна как-то представить целое исходное предложение. Ранние модели умели представлять только отдельные слова или фразы. Было бы полезно обучить такое представление, что предложения с одинаковым смыслом имеют схо- жие представления и на исходном, и на целевом языке. Сначала была предпринята попытка реализовать такую стратегию с использованием комбинации свертки с РНС (Kalchbrenner and Blunsom, 2013). Позже РНС стала применяться для оценки пред-ложенных переводов (Cho et al., 2014a) и порождения переведенных предложений (Sutskever et al., 2014). В работе Jean et al. (2014) эти модели масштабированы на словари большего размера. 12.4.5.1. Использование механизма внимания и совмещение частей данных У ловить все семантические детали очень длинного предложения, скажем из 60 слов, в представлении фиксированного размера крайне трудно. Этого можно добиться, обучая достаточно большую РНС в течение достаточно длительного времени, как показано в работах Cho et al. (2014a) и Sutskever et al. (2014). Но есть и более эф- фективный подход: прочитать все предложение или абзац (чтобы получить контекст и в общих чертах понять, о чем речь), а затем порождать переводы слов по одному, всякий раз фокусируясь на новой части входного предложения, чтобы собрать семан-тические детали, необходимые для порождения следующего слова. Эта идея впервые была реализована в работе Bahdanau et al. (2015). Механизм внимания, использо-\n--- Страница 401 ---\n400  Приложения ванный для фокусирования на отдельных частях входного предложения на каждом временном шаге, иллюстрируется на рис. 12.6. Рис. 12.6  Современный механизм внимания, введенный в работе Bahdanau et al. (2015), по существу, представляет собой взвешенное среднее. Вектор контекста c образуется путем вычисления взвешенного среднего векторов признаков h(t) с весами α(t). В некоторых приложениях векторы признаков h – скрытые блоки нейронной сети, но это могут быть и исходные данные модели. Веса α(t) порождает сама модель. Обычно это значения из отрезка [0, 1], которые концентрируются вокруг единственного значения h(t), чтобы взвешенное среднее аппроксимировало чтение имен- но на этом временном шаге. Как правило, веса α(t) являются результатом применения функции softmax к оценкам релевантности, вычисленным дру- гой частью модели. Вычислительно механизм внимания дороже прямого индексирования желаемого h(t), но прямому индексированию невозможно обучиться методом градиентного спуска. Механизм внимания, основанный на взвешенных средних, – гладкая дифференцируемая аппроксимация, до- пускающая обучение существующими алгоритмами оптимизации Можно считать, что система с механизмом внимания состоит из трех компонентов: 1) процесс, который читает исходные данные (например, слова исходного пред- ложения) и преобразует их в распределенное представление, ассоциируя один вектор признаков с каждой позицией слова; 2) список векторов признаков, построенный читателем. Его можно трактовать как память, содержащую последовательность фактов, которые можно впоследствии извлекать, необязательно в том же порядке и необязательно перебирая все; 3) процесс, который последовательно выполняет некоторую задачу, обращаясь к содержимому памяти. На каждом временном шаге у него есть возможность ак- центировать внимание на содержимом одного элемента памяти (или несколь-ких, с разными весами). Третий компонент порождает переведенное предложение.Когда слова предложения, написанного на одном языке, совмещаются с соответ- ственными словами переведенного предложения, становится возможным сопоста- вить соответствующие погружения слов. В более ранней работе показано, как обучить своего рода матрицу перевода, сопоставляющую погружения слов на разных языках\n--- Страница 402 ---\nОбработка естественных языков  401 (Kocisky et al., 2014), получив при этом меньшую частоту ошибок совмещения, чем в традиционных решениях, основных на подсчете частот в таблице фраз. Существует и еще более ранняя работа по обучению межъязыковых векторов слов (Klementiev et al., 2012). Этот подход можно развить в разных направлениях. Например, более эффективное межъязыковое совмещение (Gouws et al., 2014) позволяет проводить обучение на бoльших наборах данных. 12.4.6. Историческая справка Идея распределенных представлений символов впервые была высказана в работе Rumelhart et al. (1986a) – одном из первых исследований обратного распространения; символы там соответствовали идентификаторам членов семьи, нейронная сеть улав-ливала связи между членами семьи, а обучающие примеры представлялись тройками вида (Колин, мать, Виктория). Первый слой сети обучался представлению каждого члена семьи. Например, для Колина могли быть выделены такие признаки: в каком генеалогическом древе он находится, в какой ветви этого древа, в каком поколении и т. д. Можно считать, что нейронная сеть вычисляет правила, связывающие эти атри- буты для получения желаемых предсказаний. Обученная сеть может, например, вы-вести, кто приходится матерью Колину. Идея формирования погружения символа была обобщена на идею погружения слова в работе Deerwester et al. (1990). Для обучения погружений использовалось спектральное разложение. Позже для этой цели применили бы нейронные сети. История обработки естественных языков отмечена сменой популярности различ-ных представлений входа модели. По следам этой ранней работы по символам и сло- вам в первых приложениях нейронных сетей к ОЕЯ (Miikkulainen and Dyer, 1991; Schmidhuber, 1996) вход представлялся в виде последовательности литер. В работе Bengio et al. (2001) произошел возврат к моделированию слов и были введены нейронные языковые модели, порождающие интерпретируемые погруже-ния слов. Эти модели постепенно масштабировались: от представлений небольшо-го набора символов в 1980-х годах до миллионов слов (включая имена собственные и неправильные написания) в современных приложениях. Усилия, направленные на достижение вычислительной масштабируемости, привели к изобретению техник, описанных в разделе 12.4.3. В самом начале использование слов в качестве фундаментальных единиц языка привело к повышению качества языкового моделирования (Bengio et al., 2001). Се- годня появились новые методы и для моделей на основе литер (Sutskever et al., 2011), и для моделей на основе слов (Gillick et al., 2015), и даже для моделирования отдель- ных байтов литер в кодировке Unicode. Идеи, стоящие за нейронными языковыми моделями, были распространены и на другие приложения ОЕЯ, в т. ч. грамматический разбор (Henderson, 2003, 2004; Collobert, 2011), частеречная разметка, пометка семантических ролей, фрагментация (chunking) и т. д. Иногда при этом применяется единая многозадачная архитектура обучения (Collobert and Weston, 2008a; Collobert et al., 2011a), в которой погружения слов сообща используются разными задачами. Двумерная визуализация погружений стала популярным инструментом анализа языковых моделей после разработки алгоритма понижения размерности t-SNE (van der Maaten and Hinton, 2008) и его широко известного применения к задаче визуали- зации погружений слов, предложенного Джозефом Турианом в 2009 году.\n--- Страница 403 ---\n402  Приложения 12.5. Другие приложения В этом разделе мы рассмотрим еще несколько приложений глубокого обучения, по- мимо описанных выше стандартных задач распознавания объектов, распознавания речи и обработки естественных языков. В третьей части книги мы добавим к этому перечню задачи, пока еще не вышедшие из стадии исследования. 12.5.1. Рекомендательные системы Одно из основных семейств приложений машинного обучения к информационным технологиям – возможность давать рекомендации потенциальным пользователям или заказчикам товаров и услуг. Можно выделить два типа приложений: онлайновая реклама и рекомендация продуктов (зачастую рекомендации преследуют ту же цель: продать продукт). В обоих случаях требуется предсказать ассоциацию между поль- зователем и продуктом – для того чтобы предсказать либо вероятность некоторого действия (покупки продукта или какого-то эквивалента этому действию), либо ожи-даемую выгоду (которая может зависеть от ценности продукта) от показа рекламного объявления или рекомендации продукта пользователю. В настоящее время Интернет финансируется в значительной мере за счет различных видов онлайновой рекламы. Многие отрасли экономики зависят от покупок через Интернет. Такие компании, как Amazon и eBay, применяют машинное обучение, в т. ч. глубокое, для рекомендова- ния своих товаров и услуг. Иногда речь вообще не идет о продаже чего-либо. В ка- честве примеров можно назвать отбор сообщений, отображаемых в новостной ленте со циальной сети, рекомендование фильмов, анекдотов, советов специалистов, подбор партнеров для видеоигр или паросочетания в сервисах знакомств. Часто проблема ассоциации рассматривается как задача обучения с учителем: зная какую-то информацию о продукте и пользователе, предсказать тот или иной вариант выражения заинтересованности (переход пользователем по ссылке, ввод рейтинга, нажатие на кнопку «Нравится», покупка продукта, трата какой-то суммы денег на продукт, переход на страницу с описанием продукта и т. д.). Часто все сводится либо к задаче регрессии (предсказать ожидаемое значение при некоторых условиях), либо к задаче вероятностной классификации (предсказать условную вероятность дискрет- ного события). Ранние работы по рекомендательным системам опирались на минимальную вход- ную информацию для предсказаний: идентификатор пользователя и идентификатор продукта. В этом контексте для обобщения можно полагаться только на сходство между паттернами значений целевой переменной для разных пользователей или раз-ных продуктов. Предположим, что пользователям 1 и 2 нравятся продукты A, B и C. Отсюда можно сделать вывод, что у пользователей 1 и 2 схожие вкусы. Если пользо- вателю 1 нравится продукт D, то велики шансы, что он понравится и пользователю 2. Алгоритмы, основанные на этой идее, называются коллаборативной фильтрацией. Возможны как непараметрические подходы (метод ближайших соседей, основанный на оценке сходства между паттернами предпочтений), так и параметрические. Пара- метрические методы зачастую опираются на обучение распределенного представле-ния (называемого также погружением) для каждого пользователя и каждого продук- та. Билинейное предсказание целевой переменной (например, рейтинга) – простой параметрический метод, оказавшийся чрезвычайно успешным и часто встречающий- ся в самых передовых системах в качестве одного из компонентов. Для предсказа-\n--- Страница 404 ---\nДругие приложения  403 ния вычисляется скалярное произведение погружения пользователя и погружения продукта (возможно, скорректированное с помощью констант, зависящих только от идентификатора пользователя или продукта). Обозначим Rˆ матрицу наших предска- заний, A – матрицу, в которой по строкам расположены погружения пользователей, а B – матрицу, в котором по столбцам расположены погружения объектов. Пусть b и c – векторы, содержащие соответственно разновидности смещения для пользова- телей (насколько пользователь брюзгливый или жизнерадостный) и для продуктов (общая популярность продукта). Тогда билинейное предсказание имеет вид: (12.20) Обычно стремятся минимизировать квадратичную ошибку между предсказанны- ми рейтингами Rˆ u, i и фактическими рейтингами Ru, i. Погружения пользователей и про- дуктов можно удобно визуализировать, предварительно понизив размерность (до 2 или 3), или использовать для сравнения пользователей или продуктов между собой так же, как это делается для погружений слов. Один из способов получить погруже-ния – вычислить сингулярное разложение матрицы R фактических целей (например, рейтингов). Это соответствует разложению R = UDV ′ (или нормированного варианта) в произведение двух множителей: матриц низкого ранга A = UD и B = V′. Проблема в том, что в сингулярном разложении отсутствующие элементы произвольным обра- зом трактуются так, будто они соответствуют целевому значению 0. А мы вообще не хотели бы платить за предсказания, сделанные на основе отсутствующих значений. К счастью, сумму квадратов ошибок на наблюдаемых рейтингах также легко миними- зировать градиентными методами. Сингулярное разложение и билинейное предска- зание (12.20) показали очень хорошие результаты в соревновании на приз компании Netflix (Bennett and Lanning, 2007), где требовалось предсказать рейтинги фильмов, зная только предыдущие рейтинги, выставленные большим числом анонимных поль-зователей. В этом соревновании, проходившем в период с 2006 по 2009 год, участвова- ли многие специалисты по машинному обучению. Оно стимулировало новые исследо-вания по применению передовых методов машинного обучения к рекомендательным системам и в конечном итоге привело к улучшению последних. И хотя ни простое билинейное предсказание, ни сингулярное разложение не добились победы сами по себе, они были компонентами ансамблевых моделей, представленных большинством участников, в т. ч. победителями (Tö scher et al., 2009; Koren, 2009). Одно из первых применений нейронных сетей к коллаборативной фильтрации было основано на неориентированной вероятностной модели в виде ограниченной машины Больцмана (Salakhutdinov et al., 2007). ОМБ входила важной составной частью в ансамбль моделей, выигравший соревнование на приз Netflix (Töscher et al., 2009; Koren, 2009). В сообществе нейронных сетей исследовались и более продви- нутые варианты идеи факторизации матрицы рейтингов (Salakhutdinov and Mnih, 2008). Однако у систем коллаборативной фильтрации есть существенное ограничение: когда появляется новый пользователь или продукт, у него нет никакой истории рей- тингования, а потому невозможно оценить его сходство с другими пользователями или продуктами или степень ассоциации между новым пользователем и существую- щими продуктами. Это проблема холодного старта. Общий способ ее решения – доба- вить информацию о пользователях и продуктах. Это может быть, например, профиль\n--- Страница 405 ---\n404  Приложения пользователя или признаки продукта. Рекомендательные системы, в которых такая информация используется, называются системами фильтрации по содержимому. Отображение подробного набора признаков пользователей или продуктов на погру- жение можно обучить, применив архитектуру глубокого обучения (Huang et al., 2013; Elkahky et al., 2015). Для выделения признаков из сложного содержимого, например из музыкальных треков для рекомендования музыки, также применялись специализированные архи- тектуры глубокого обучения, в частности сверточные сети (van den Oörd et al., 2013). В этой работе сверточная сеть принимала на входе акустические признаки и вычис- ляла векторное представление соответствующей песни. Затем скалярное произведе-ние векторных представлений песни и пользователя использовалось, чтобы предска- зать, будет пользователь слушать песню или нет. 12.5.1.1. Исследование и использование В задаче выработки рекомендаций для пользователей возникает проблема, выходя-щая за рамки обычного обучения с учителем в плоскость обучения с подкреплением. Многие проблемы рекомендования теоретически точнее всего описываются как кон- текстуальные бандиты (Langford and Zhang, 2008; Lu et al., 2010). Проблема в том, что при использовании рекомендательной системы для сбора данных мы получаем сме-щенное и неполное представление о предпочтениях пользователей: мы видим откли- ки пользователей только на те продукты, что им были рекомендованы, а все прочие остаются за кадром. Кроме того, в некоторых случаях мы можем не получить вообще никакой информации о пользователях, которым не было дано рекомендаций (напри- мер, на аукционе рекламы может случиться, что цена, предложенная за размещение объявления, ниже минимальной цены или не стала победителем, так что объявление не показано вовсе). Важно, что у нас нет информации о том, что случилось бы, если бы были рекомендованы какие-то другие продукты. Тут можно провести аналогию с обучением классификатора, когда для каждого обучающего примера x выбирается один класс yˆ (обычно класс с наибольшей вероятностью согласно модели) и в каче- стве обратной связи мы узнаем только, правильный это класс или нет. Очевидно, что каждый пример несет меньше информации, чем в случае обучения с учителем, когда известна истинная метка y, поэтому необходимо больше примеров. Хуже того, если не проявить осторожность, то можно получить систему, которая будет принимать невер-ные решения, сколько бы данных ни подать ей на вход, потому у правильного реше- ния изначально была очень низкая вероятность: пока обучаемая система не выберет это правильное решение, она не узнает, что оно правильно. Это похоже на ситуацию в обучении с подкреплением, когда наблюдаемой величиной является только возна- граждение за выбранное действие. В общем случае обучение с подкреплением может содержать последовательность из многих действий и многих вознаграждений. Сцена- рий с бандитами – это частный случай обучения с подкреплением, когда обучаемый предпринимает единственное действие и получает единственное вознаграждение. Проблема бандита проще в том смысле, что обучаемый знает, какое вознаграждение с каким действием ассоциировано. В общем же случае большое или малое вознаграж- дение может быть вызвано как недавним действием, так и действием в отдаленном прошлом. Термин «контекстуальные бандиты» относится к случаю, когда действие предпринято в контексте некоторой входной переменной, которая может повлиять на решение. Например, мы знаем как минимум идентификатор пользователя и хо- тим выбрать для него продукт. Отображение контекста на действие называют также\n--- Страница 406 ---\nДругие приложения  405 политикой. Петля обратной связи между обучаемым и распределением данных (ко- торое теперь зависит от действий обучаемого) – центральный вопрос в литературе по обучению с подкреплением и бандитам. Для обучения с подкреплением требуется выбрать компромисс между исследова- нием (exploration) и использованием (exploitation). Под использованием понимается выполнение действий, вытекающих из текущей наилучшей версии обученной поли- тики, – действий, которые, как мы знаем, повлекут за собой большое вознаграждение. А исследование – это выполнение действий, направленных специально на получе- ние дополнительных обучающих данных. Если мы знаем, что при данном контексте x действие a принесет вознаграждение 1, то это еще не значит, что это максимально возможное вознаграждение. Мы можем использовать текущую политику и продол- жать выполнять действие a, чтобы более-менее гарантированно получить вознаграж- дение 1. Но можем и заняться исследованием, попробовав действие a′. Мы не знаем, что произойдет, если выполнить действие a′. Мы надеемся получить вознаграждение 2, но рискуем остаться с вознаграждением 0. Но в любом случае приобретем какие-то знания. Есть разные способы реализации исследования: можно время от времени пред- принимать случайные действия в расчете охватить все пространство возможных действий, а можно положить в основу модель, которая вычисляет действие в зависи- мости от ожидаемого вознаграждения и заложенной в модель степени неопределен- ности этого вознаграждения. Что предпочесть – исследование или использование, зависит от многих факторов. Один из самых важных – интересующий нас временной масштаб. Если у агента име- ется ограниченное время для накопления вознаграждения, то мы предпочли бы ис-пользование. Если же времени достаточно, то стоит начать с исследования, чтобы планировать будущие действия более эффективно, опираясь на полученные знания. Обучив достаточно хорошую политику, можно переходить к использованию. В обучении с учителем не нужно выбирать между исследованием и использовани- ем, потому что сигнал от учителя всегда говорит, какой выход правилен для данного входа. Нет нужды пробовать различные выходы, чтобы понять, удастся ли улучшить текущий оптимальный выход модели, – мы заведомо знаем, что лучшим выходом яв- ляется метка. Помимо компромисса между исследованием и использованием, в контексте обуче- ния с подкреплением возникает еще одна трудность: оценка и сравнение различных политик. Обучение с подкреплением предполагает взаимодействие между обучае- мым и окружением. Эта петля обратной связи означает, что нельзя просто оценить качество обучаемой системы, пользуясь фиксированным тестовым набором вход-ных значений. Сама политика определяет, какие входы будут предъявлены. В работе Dudik et al. (2011) представлены методы оценки контекстуальных бандитов. 12.5.2. Представление знаний, рассуждения и ответы на вопросы Глубокому обучению удалось добиться больших успехов в языковом моделировании, машинном переводе и обработке естественных языков благодаря использованию по- гружений для символов (Rumelhart et al., 1986a) и слов (Deerwester et al., 1990; Bengio et al., 2001). Погружения представляют семантические знания об отдельных словах и концепциях. На переднем крае исследований находится разработка погружений\n--- Страница 407 ---\n406  Приложения для фраз и связей между словами и фактами. В поисковых системах для этой цели уже используется машинное обучение, но еще многое предстоит сделать для улучше- ния этих продвинутых представлений. 12.5.2.1. Знания, отношения и ответы на вопросы Интересное направление исследований – выяснить, как можно обучить распределен- ные представления улавливать отношения между двумя сущностями. Такие связи помогают формализовать факты, касающиеся объектов и их взаимодействий. В математике бинарным отношением называется множество упорядоченных пар объектов. Если пара объектов присутствует в этом множестве, то говорят, что между этими объектами имеется отношение. Например, можно задать отношение «мень-ше» на множестве сущностей {1, 2, 3}, определив множество упорядоченных пар 𝕊 = {(1, 2), (1, 3), (2, 3)}. После того как отношение определено, его можно использо- вать как наречие (или глагол – в зависимости от названия отношения). Поскольку (1, 2) ∈ 𝕊, мы говорим, что 1 меньше 2. А так как (2, 1) ∉ 𝕊, мы не можем сказать, что 2 меньше 1. Конечно, связанные отношением сущности необязательно должны быть числами. Можно было бы определить отношение имеет_тип , содержащее кортежи вида (собака, млекопитающее) . В контексте ИИ мы воспринимаем отношение как предложение в синтаксически простом сильно структурированном языке. Отношение играет роль глагола, а два его аргумента – роли подлежащего (субъекта) и дополнения (объекта). Предложения имеют вид тройки лексем (подлежащее; глагол; дополнение) (12.21) со значениями (сущностьi; отношениеj; сущностьk). (12.22) Можно определить также атрибут – концепцию, аналогичную отношению, с тем отличием, что атрибут принимает всего один аргумент: (сущностьi; атрибутj). (12.23) Например, можно определить атрибут имеет_мех и применять его к сущностям типа собака . Во многих приложениях требуется представлять отношения и рассуждать о них. Как лучше всего сделать это в контексте нейронных сетей? Разумеется, моделям ма- шинного обучения нужны обучающие данные. Мы можем вывести отношения меж-ду сущностями из обучающих наборов данных, содержащих неструктурированные предложения на естественном языке. Но есть и структурированные базы данных, в которых отношения определены явно. Как правило, для этой цели используются реляционные базы данных, в которых хранится информация того же сорта, правда, не представленная в виде троек лексем. Если база данных предназначена для переда- чи системе искусственного интеллекта общеизвестных знаний о повседневной жизни или специальных знаний о предметной области, то мы называем ее базой знаний. Су- ществуют как общие базы знаний: Freebase , OpenCyc , WordNet , Wikibase1, так и специа- 1 Размещенные на сайтах freebase.com , cyc.com/opencyc , wordnet.princeton.edu , wikiba.se соот- ветственно.\n--- Страница 408 ---\nДругие приложения  407 лизированные, например GeneOntology1. Представления сущностей и отношений можно обучить, рассматривая каждую тройку в базе знаний как обучающий пример и максимизируя целевую функцию, которая улавливает их совместное распределе- ние (Bordes et al., 2013a). Помимо обучающих данных, нам нужно также определить семейство подлежа- щих обучению моделей. Общий подход – распространить нейронные языковые мо- дели на моделирование сущностей и отношений. Результатом обучения нейронной языковой модели является вектор, который дает распределенное представление каждого слова. Она также обучается взаимодействиям между словами, например: какое слово может встретиться после заданной последовательности слов, для чего обучаются функции этих векторов. Этот подход можно распространить на сущности и отношения, если обучить вектор погружений для каждого отношения. На самом деле параллель между моделированием языка и моделированием знаний, закоди- рованных в виде отношений, настолько тесная, что исследователи обучали пред- ставления таких сущностей, используя одновременно базы знаний и предложения на естественном языке (Bordes et al., 2011, 2012; Wang et al., 2014a) или комбинируя данные из нескольких реляционных баз данных (Bordes et al., 2013b). Есть много вариантов параметризации такой модели. В ранних работах по обучению отношений между сущностями (Paccanaro and Hinton, 2000) были предложены параметриче-ские формы с сильными ограничениями («линейные реляционные погружения»), причем для представления отношений и сущностей часто использовались различ- ные формы. Например, в работах Paccanaro and Hinton (2000) и Bordes et al. (2011) использовались векторы для сущностей и матрицы для отношений, обосновывая это тем, что отношение выступает в роли оператора над сущностями. Можно также рассматривать отношения как любую другую сущность (Bordes et al., 2012), что по-зволяет высказывать утверждения относительно отношений, но большей гибкостью обладает механизм, который комбинирует их с целью моделирования совместного распределения. В качестве примера практического применения таких моделей можно назвать предсказание связей – отсутствующих ребер в графе знаний. Это форма обобщения на новые факты на основе старых фактов. Большинство существующих ныне баз зна-ний было построено вручную, поэтому многие, а быть может, и большинство истин- ных отношений в базе отсутствует. Примеры таких приложений приведены в работах Wang et al. (2014b), Lin et al. (2015) и Garcia-Duran et al. (2015). Оценка качества модели для задачи предсказания связей вызывает трудности, по- тому что у нас имеется только набор положительных примеров (заведомо истинных фактов). Если модель предлагает факт, отсутствующий в наборе, мы не знаем на- верняка, то ли модель допустила ошибку, то ли действительно открыла новый, ранее неизвестный факт. Поэтому все метрики не вполне точны и основаны на проверке того, как модель ранжирует зарезервированный набор заведомо правильных фактов по сравнению с другими фактами, которые могут быть и неправильны. Стандартный способ конструирования интересных, предположительно отрицательных примеров (фактов, которые с большой вероятностью ложны) – начать с истинного факта и соз- дать его искаженные версии, например подменив одну сущность в отношении другой, выбранной случайным образом. Популярная метрика «точность на 10 процентах» 1 geneontology.org .\n--- Страница 409 ---\n408  Приложения подсчитывает, сколько раз модель включает «правильный» факт в первые 10% всех искаженных версий этого факта. Еще одно применение баз знаний и их распределенных представлений – разре- шение неоднозначности смысла слов (Navigli and Velardi, 2005; Bordes et al., 2012), т. е. решение вопроса о том, какое значение слова соответствует заданному контексту. В конечном итоге знание отношений в сочетании с процессом рассуждения и пони- манием естественного языка позволят нам построить общую вопросно-ответную си- стему. Такая система должна обрабатывать входную информацию и запоминать важ- ные факты, организуя их таким образом, чтобы впоследствии их можно было извлечь и рассуждать о них. Это остается трудной проблемой, решенной только в ограничен- ном «игрушечном» окружении. В настоящее время наилучшим подходом к запоми- нанию и извлечению конкретных декларативных фактов считается использование механизма явной памяти, описанного в разделе 10.2. Сети с памятью также впервые были использованы для создания игрушечной вопросно-ответной системы (Weston et al., 2014). В работе Kumar et al. (2015) предложено обобщение, в котором рекур- рентные сети GRU применяются для чтения входных данных в памяти и порождения ответа при заданном состоянии памяти. Глубокое обучение применялось и ко многим другим задачам, помимо описанных выше, и без сомнения найдет еще больше применений уже после выхода книги из печати. Невозможно представить себе нечто, хотя бы отдаленно напоминающее ис-черпывающий трактат на эту тему. Приведенный обзор – репрезентативная выборка из того, что было возможно на момент написания книги. На этом заканчивается часть II, в которой описаны современные практические применения глубоких сетей, охватывающие все наиболее успешные методы. Вообще говоря, в этих методах используется градиент функции стоимости для нахождения таких параметров модели, которые лучше всего аппроксимируют некоторую жела-тельную функцию. При наличии достаточного объема обучающих данных это чрез-вычайно мощный подход. Далее мы переходим к части III, где ступаем на территорию активных исследований – методов, которые должны работать при меньшем объеме обучающих данных или решать более разнообразные задачи. Проблемы здесь труд-нее и не так близки к решению, как в описанных выше ситуациях.\n--- Страница 410 ---\nЧасть III ИССЛЕДОВАНИЯ ПО ГЛУБОКОМУ ОБУЧЕНИЮ В этой части книги описываются передовые подходы к глубокому обучению, разви- ваемые в настоящее время исследовательским сообществом. В предыдущих частях мы показали, как решаются задачи обучения с учителем: как обучить отображение одного вектора на другой, если имеется достаточно примеров такого отображения. Но не все интересующие нас задачи попадают в эту категорию. Иногда требуется генерировать новые примеры, определить вероятность какой-то точки в простран- стве событий, обработать отсутствие значений или воспользоваться большим набо-ром непомеченных примеров либо примерами для родственных задач. У современ- ных промышленных приложений есть существенный недостаток: для достижения приемлемой верности алгоритмам обучения нужно много подготовленных учителем данных. В этой части книги мы обсудим некоторые теоретически мыслимые подходы к уменьшению объема размеченных данных, необходимого для качественной рабо- ты существующих моделей и их применения к более широкому кругу задач. Обычно для достижения этих целей приходится прибегать к той или иной форме обучения без учителя или с частичным привлечением учителя. Придумано много алгоритмов глубокого обучения без учителя, но ни один из них не способен продемонстрировать такое же качество, как при решении задач обучения с учителем. Мы опишем сущест- вующие подходы к обучению без учителя и некоторые популярные идеи о том, как добиться прогресса в этой области. Основная причина трудностей обучения без учителя – высокая размерность мо- делируемых случайных величин. Из-за этого возникают две проблемы: статистиче-ская и вычислительная. Статистическая проблема касается обобщения: количество конфигураций, которые мы хотели бы различать, может экспоненциально возрастать с ростом числа представляющих интерес измерений и в итоге очень быстро оказы- вается намного больше, чем количество доступных примеров (или превышает воз-можности ограниченных вычислительных ресурсов). Вычислительная проблема многомерных распределений связана с тем, что многие алгоритмы обучения или ис- пользования уже обученной модели (особенно те, что основаны на оценивании явной функции вероятности) подразумевают вычисления, объем которых экспоненциально зависит от числа измерений и превосходит возможности оборудования.\n--- Страница 411 ---\n410  Исследования по глубокому обучению В вероятностных моделях вычислительные проблемы возникают из-за необходи- мости произвести неразрешимый вывод или нормировать распределение. Неразрешимый вывод. Вывод обсуждается преимущественно в главе 19. Речь идет об угадывании вероятных значений некоторых величин a при условии других величин b в модели, которая хранит совместное распределение вели- чин a, b и c. Чтобы просто вычислить такие условные вероятности, необходимо просуммировать по значениям величин c, а также вычислить нормировочную постоянную, что требует суммирования по значениям a и c. Неразрешимые нормировочные постоянные (статистическая сумма). Стати-стическая сумма обсуждается в основном в главе 18. Нормировочные посто- янные функций вероятности возникают как при выводе (см. выше), так и при обучении. Такие постоянные входят во многие вероятностные модели. К сожа- лению, для обучения такой модели часто необходимо вычислять градиент лога-рифма статистической суммы по параметрам модели. Эти вычисления в общем случае так же сложны, как и вычисление самой статистической суммы. Для ра- боты со статистической суммой (вычисления ее самой или ее градиента) часто применяются методы Монте-Карло по схеме марковских цепей (Monte Carlo Markov chain – MCMC) (глава 17). Увы, они испытывают трудности, когда у распределения много мод и они далеко отстоят друг от друга, что особенно характерно для пространств высокой размерности (раздел 17.5). Один из способов борьбы с такими неразрешимыми вычислениями – аппрокси- мация, и в этом направлении предложено много методов, обсуждаемых ниже. Дру- гой интересный подход – вообще избежать таких вычислений, и методы, в которых удается обойтись без них, выглядят очень соблазнительно. С этой целью в последние годы предложено несколько порождающих моделей. Широкий спектр современных подходов к порождающему моделированию обсуждается в главе 20. Часть III представляет особый интерес для исследователей – тех, кто хочет понять всю широту направлений, изучаемых в области глубокого обучения, и продвинуться на пути к настоящему искусственному интеллекту.",
      "debug": {
        "start_page": 374,
        "end_page": 411
      }
    },
    {
      "name": "Глава 13. Линейные факторные модели 411",
      "content": "--- Страница 412 --- (продолжение)\nГлава 13 Линейные факторные модели На передовых рубежах глубокого обучения часто требуется построить вероятностную модель входа, pmodel(x). В принципе, в такой модели может использоваться вероятност- ный вывод для предсказания любой переменной в ее окружении при известных дру- гих переменных. Во многих моделях имеются также латентные переменные h, так что pmodel(x) = 𝔼h pmodel(x | h). Латентные переменные дают еще один способ представления данных. Распределенные представления, основанные на латентных переменных, могут пользоваться всеми преимуществами обучения представлений, о которых мы говорили при обсуждении глубоких сетей прямого распространения и рекуррентных сетей. В этой главе мы опишем простейшие вероятностные модели с латентными перемен- ными: линейные факторные модели. Иногда они используются в качестве составных частей смесовых моделей (Hinton et al., 1995a; Ghahramani and Hinton, 1996; Roweis et al., 2002) или более крупных глубоких вероятностных моделей (Тang et al., 2012). На их примере можно также продемонстрировать основные подходы к построению порождающих моделей, которые обобщаются в более передовых глубоких моделях. Линейная факторная модель определяется стохастической линейной функцией декодера, которая генерирует x посредством прибавления шума к результату линей- ного преобразования h. Эти модели интересны тем, что позволяют выявить объясняющие факторы, имею- щие простое совместное распределение. Благодаря простоте линейных декодеров эти модели стали первыми моделями с латентными переменными, подвергшимися прис- тальному изучению. Линейная факторная модель описывает порождающий данные процесс следую- щим образом. Сначала производится выборка объясняющих факторов h из распре- деления: h ∼ p(h), (13.1) где p(h) – факторное распределение: p(h) = ∏ i p(hi), из которого легко производить выборку. Затем мы производим выборку вещественных наблюдаемых переменных при условии факторов x = Wh + b + noise, (13.2) где шум noise обычно имеет нормальное диагональное (независимое по разным осям) распределение. Это показано на рис. 13.1.\nГлава 13 Линейные факторные модели На передовых рубежах глубокого обучения часто требуется построить вероятностную модель входа, pmodel(x). В принципе, в такой модели может использоваться вероятност- ный вывод для предсказания любой переменной в ее окружении при известных дру- гих переменных. Во многих моделях имеются также латентные переменные h, так что pmodel(x) = 𝔼h pmodel(x | h). Латентные переменные дают еще один способ представления данных. Распределенные представления, основанные на латентных переменных, могут пользоваться всеми преимуществами обучения представлений, о которых мы говорили при обсуждении глубоких сетей прямого распространения и рекуррентных сетей. В этой главе мы опишем простейшие вероятностные модели с латентными перемен- ными: линейные факторные модели. Иногда они используются в качестве составных частей смесовых моделей (Hinton et al., 1995a; Ghahramani and Hinton, 1996; Roweis et al., 2002) или более крупных глубоких вероятностных моделей (Тang et al., 2012). На их примере можно также продемонстрировать основные подходы к построению порождающих моделей, которые обобщаются в более передовых глубоких моделях. Линейная факторная модель определяется стохастической линейной функцией декодера, которая генерирует x посредством прибавления шума к результату линей- ного преобразования h. Эти модели интересны тем, что позволяют выявить объясняющие факторы, имею- щие простое совместное распределение. Благодаря простоте линейных декодеров эти модели стали первыми моделями с латентными переменными, подвергшимися прис- тальному изучению. Линейная факторная модель описывает порождающий данные процесс следую- щим образом. Сначала производится выборка объясняющих факторов h из распре- деления: h ∼ p(h), (13.1) где p(h) – факторное распределение: p(h) = ∏ i p(hi), из которого легко производить выборку. Затем мы производим выборку вещественных наблюдаемых переменных при условии факторов x = Wh + b + noise, (13.2) где шум noise обычно имеет нормальное диагональное (независимое по разным осям) распределение. Это показано на рис. 13.1.\n--- Страница 413 ---\n412  Линейные факторные модели x = Wh + b + noise Рис. 13.1  Ориентированная графическая модель, описывающая се- мейство линейных факторных моделей. Предполагается, что наблюдаемый вектор x является линейной комбинацией независимых латентных факто- ров h и шума. В различных моделях, например в вероятностном методе главных компонент, факторном анализе и анализе независимых компонент (ICA), делаются различные предположения о форме шума и априорном распределении p(h) 13.1. Вероятностный PCA и факторный анализ В факторном анализе (Bartholomew, 1987; Basilevsky, 1994) латентная переменная имеет априорное нормальное распределение с единичной дисперсией h ∼ 𝒩(h; 0, I), (13.3) а наблюдаемые переменные xi предполагаются условно независимыми при условии h. Точнее говоря, предполагается, что шум выбирается из нормального распределе-ния с диагональной ковариационной матрицей ψ = diag(σ 2), где σ2 = [σ12, σ22, …, σn2]⏉ – вектор дисперсий отдельных переменных. Таким образом, роль латентных переменных – в улавливании зависимостей между различными наблюдаемыми переменными xi. Действительно, легко показать, что x – просто случайная величина с многомерным нормальным распределением: x ∼ 𝒩(x; b, WW⏉ + ψ). (13.4) Чтобы переформулировать метод главных компонент (PCA) в вероятностном кон- тексте, мы можем внести небольшую модификацию в модель факторного анализа, сделав условные дисперсии σi2 равными. В таком случае ковариация x равна просто WW⏉ + σ2I, где σ2 – теперь скаляр. Тогда условное распределение имеет вид x ∼ 𝒩(x; b, WW⏉ + σ2I), (13.5) или, эквивалентно, x = Wh + b + σz, (13.6) где z ∼ 𝒩(z; 0, I) – гауссов шум. Далее, как показано в работе Тipping and Bishop (1999), можно использовать итеративный EM-алгоритм для оценивания параметров W и σ 2. В этой модели вероятностного PCA предполагается, что своей вариативностью данные обязаны прежде всего латентным переменным h с точностью до небольшой остаточной ошибки реконструкции σ2. Как показано в работе Тipping and Bishop (1999), вероятностный PCA превращается в PCA, когда σ → 0. В этом случае услов-\n--- Страница 414 ---\nАнализ независимых компонент (ICA)  413 ное математическое ожидание h при условии x становится ортогональной проекцией x – b на пространство, натянутое на d столбцов W, как в PCA. При σ → 0 модель плотности, определяемая вероятностным PCA, становится очень острой в направлении тех d измерений, которые натянуты на столбцы W. Поэтому модель может назначать очень низкое правдоподобие данным, если они в действи- тельности не образуют кластера в окрестности этой гиперплоскости. 13.2. Анализ независимых компонент (ICA) Анализ независимых компонент (independent component analysis – ICA) – один из самых старых алгоритмов обучения представлений (Herault and Ans, 1984; Jutten and Herault, 1991; Comon, 1994; Hyvärinen, 1999; Hyvärinen et al., 2001a; Hinton et al., 2001; Тeh et al., 2003). Идея этого подхода к моделированию линейных факторов заклю- чается в том, чтобы представить наблюдаемый сигнал в виде линейной комбинации нескольких составляющих. Предполагается, что эти сигналы полностью независимы, а не просто не коррелированы 1. Под общим названием ICA объединено несколько разных методологий. На дру- гие описанные здесь порождающие модели больше всего похож вариант (Pham et al., 1992), в котором обучается полностью параметрическая порождающая модель. Априорное распределение объясняющих факторов p(h) должно быть зафиксирова- но пользователем заранее. Затем модель детерминированно порождает x = Wh. Для определения p(x) мы можем произвести нелинейную замену переменных (пользуясь формулой 3.47). Далее обучение модели протекает как обычно, с применением мак- симального правдоподобия. Обоснование этого подхода состоит в том, что, выбирая p(h) независимым, мы мо- жем восстановить объясняющие факторы, которые настолько близки к независимым, насколько возможно. Обычно это используется не для того, чтобы уловить высоко-уровневые абстрактные каузальные факторы, а чтобы восстановить низкоуровневые сигналы, которые можно смешать. При такой постановке каждый обучающий при-мер – это один момент времени, каждый x i – одно наблюдение смешанных сигналов, полученное от датчика, а каждый hi – одна оценка одного из исходных сигналов. На- пример, пусть одновременно разговаривают n человек. Если в разных точках установ- лено n микрофонов, то метод ICA позволяет обнаружить изменения громкости каж- дого говорящего, зафиксированной каждым микрофоном, и разделить сигналы таким образом, что каждая компонента hi содержит отчетливую речь одного человека. Это часто применяется для снятия электроэнцефалограмм – электрических сигналов моз- га. На голове пациента закрепляется несколько электродов для измерения электриче-ских сигналов тела. Обычно экспериментатора интересуют только сигналы мозга, но сигналы, исходящие от сердца и глаз, достаточно сильны, чтобы исказить результаты измерений, произведенных на черепе. Электроды снимают смешанный сигнал, поэто-му для отделения электрической сигнатуры сердца от сигналов мозга, а также для раз- деления сигналов от различных участков мозга необходимо применение ICA. Как уже было сказано, существует много вариантов ICA. Некоторые добавляют шум в процесс генерации x вместо использования детерминированного декодера. 1 Обсуждение вопроса о том, чем некоррелированные величины отличаются от независимых, см. в разделе 3.8.\n--- Страница 415 ---\n414  Линейные факторные модели В большинстве не используется критерий максимального правдоподобия, а вместо этого ставится цель сделать элементы h = W–1x независимыми друг от друга. Есть много критериев, позволяющих добиться этой цели. В формуле (3.47) необходимо вычислять определитель W, а это дорогая и вычислительно неустойчивая операция. В некоторых вариантах ICA эту проблему обходят, требуя, чтобы матрица W была ортогональной. Во всех вариантах ICA требуется, чтобы распределение p(h) было негауссовым. Связано это с тем, что если p(h) – независимое априорное распределение с гауссо- выми компонентами, то матрица W определена неодозначно. Одно и то же распре- деление p(x) можно получить при разных значениях W. В этом состоит разительное отличие от других линейных факторных моделей, в т. ч. вероятностного PCA и фак- торного анализа, где часто требуется, чтобы p(h) было гауссовым, поскольку тогда многие операции с моделью могут быть выражены в замкнутой форме. В подходе на основе максимального правдоподобия, когда пользователь задает распределение явно, типичным выбором является p(hi) = (d/dhi)σ(hi). Эти негауссовы распределе- ния обычно выбирают так, чтобы пик в окрестности нуля был выше, чем у гауссова, поэтому в большинстве реализаций ICA обучаются разреженные признаки. Многие варианты ICA не являются порождающими моделями в обычном смыс- ле слова. В этой книге порождающая модель либо представляет распределение p(x), либо умеет производить выборку из него. Многие варианты ICA знают только, как выполнить преобразование между x и h, но не имеют средств для представления p(h), а потому не подразумевают никакого конкретного распределения p(x). Так, во мно- гих вариантах ICA ставится цель увеличить куртозис h = W –1x, поскольку высокий куртозис является признаком негауссовости p(h), но этой цели можно достичь и без явного представления p(h). Дело в том, что ICA чаще используется как аналитиче- ский инструмент для разделения сигналов, а не для порождения данных или оценки плотности. Как PCA можно обобщить на нелинейные автокодировщики, описанные в гла- ве 14, так и ICA обобщается на нелинейные порождающие модели, в которых для генерации наблюдаемых данных используется нелинейная функция f. Первой ра- ботой по нелинейному ICA была статья Hyvä rinen and Pajunen (1999), а его успеш- ное применение к ансамблевому обучению описано в работах Roberts and Everson (2001) и Lappalainen et al. (2000). Еще одно нелинейное обобщение ICA – нели- нейное оценивание независимых компонент (nonlinear independent components estimation – NICE) (Dinh et al., 2014), когда строится последовательность обра- тимых преобразований (ступеней кодировщика), обладающая тем свойством, что определитель матрицы Якоби каждого преобразования допускает эффективное вы-числение. Это позволяет точно вычислить правдоподобие; как и ICA, NICE пыта- ется преобразовать данные в пространство, где они имеют факторизованное марги- нальное распределение, но теперь, благодаря нелинейности кодировщика, шансов на успех этого предприятия больше. Поскольку с кодировщиком ассоциирован де- кодер, являющийся его точным обращением, то выборка из модели не представляет никаких трудностей (нужно сначала произвести выборку из p(h), а затем приме- нить декодер). Еще одно обобщение ICA – обучение групп признаков, когда статистическая за- висимость допускается внутри группы, но запрещается между группами (Hyvärinen and Hoyer, 1999; Hyvärinen et al., 2001b). Если выбираются непересекающиеся груп-\n--- Страница 416 ---\nАнализ медленных признаков  415 пы взаимосвязанных блоков, то метод называется анализом независимых подпрост- ранств (independent subspace analysis). Можно также назначить пространственные координаты каждому скрытому блоку и сформировать пересекающиеся группы прост ранственно соседних блоков. Это побуждает близкие блоки обучаться похожим признакам. В применении к естественным изображениям этот топографический ва- риант ICA обучает фильтры Габора, так чтобы у соседних признаков была одинаковая ориентация, местоположение или частота. Внутри каждой области встречается много разных сдвигов фаз похожих функций Габора, поэтому пулинг по небольшим облас-тям дает инвариантность относительно параллельного переноса. 13.3. Анализ медленных признаков Анализ медленных признаков (slow feature analysis – SFA) – линейная факторная модель, в которой для обучения инвариантных признаков используется информация от сигналов времени (Wiskott and Sejnowski, 2002). В основе анализа медленных признаков лежит общий принцип медленности. Идея в том, что важные характеристики сцены изменяются очень медленно, по сравнению с отдельными измерениями, из которых складывается описание сцены. Например, в компьютерном зрении значения отдельных пикселей могут изменяться очень быст- ро. Если имеется ряд изображений зебры, бегущей слева направо, то значения пик- селей быстро меняются с черного на белый и наоборот. Однако признак, показываю- щий, присутствует в изображении зебра или нет, не изменяется вовсе, а признак, описывающий положение зебры, изменяется медленно. Поэтому возникает желание регуляризировать модель, так чтобы она обучилась признакам, которые медленно из-меняются во времени. Принцип медленности появился намного раньше анализа медленных признаков и с успехом применялся к широкому кругу моделей (Hinton, 1989; Földiаk, 1989; Mobahi et al., 2009; Bergstra and Bengio, 2009). В общем случае принцип медленности можно применить к любой дифференцируемой модели, обученной методом гради- ентного спуска. Для этого нужно включить в функцию стоимости член вида (13.5) где λ – гиперпараметр, определяющий силу регуляризирующего члена, t – индекс временной последовательности примеров, f – экстрактор подлежащих регуляриза- ции признаков, а L – функция потерь, измеряющая расстояние между f(x(t)) и f(x(t+1)). В качестве L обычно берут квадрат среднеквадратического отклонения. Анализ медленных признаков – особенно эффективное применение принципа медленности. Эффективность объясняется тем, что модель применяется к экстрак- тору линейных признаков и потому может быть обучена в замкнутой форме. Как и некоторые варианты ICA, SFA, строго говоря, не является порождающей моде- лью, поскольку определяет линейное отображение между пространством входов и пространством признаков, но не определяет априорного распределения в прост- ранстве признаков и потому не налагает никакого распределения p(x) на прост- ранство входов. Алгоритм SFA (Wiskott and Sejnowski, 2002) требует, чтобы f(x; θ) было линейным преобразованием и решает задачу оптимизации\n--- Страница 417 ---\n416  Линейные факторные модели (13.6) при ограничениях 𝔼tf(x(t))i = 0 (13.9) и 𝔼t[f(x(t))i2] = 1. (13.10) Среднее значение обученного признака должно быть равно нулю, чтобы у задачи было единственное решение; в противном случае можно было бы прибавить ко всем признакам одну и ту же константу и получить другое решение с тем же значением це- левой функции медленности. А дисперсия должна быть равна 1, чтобы предотвратить патологическую ситуацию, когда все признаки оказываются равны 0. Как и в случае PCA, признаки SFA упорядочены, причем на первом месте находится самый медлен- ный. Для обучения нескольким признакам нужно добавить еще ограничение ∀i < j, 𝔼t[f(x(t))if(x(t))j] = 0. (13.11) Это означает отсутствие линейной корреляции между обученными признаками. Не будь этого ограничения, все обученные признаки просто запомнили бы самый медленный сигнал. Можно представить себе и другие механизмы принудительной диверсификации признаков, например минимизацию ошибки реконструкции, но требование отсутствия корреляции допускает простое решение в силу линейности признаков SFA. Задачу оптимизации SFA можно решить в замкнутой форме, приме- няя методы линейной алгебры. Обычно SFA применяется для обучения нелинейным признакам посредством при- менения к x нелинейного расширения базиса до выполнения SFA. Например, часто заменяют x квадратичным расширением базиса – вектором, содержащим элементы x ixj для всех i и j. Затем можно составить композицию модулей линейного SFA для обучения глубоких нелинейных экстракторов медленных признаков, для чего нужно несколько раз повторить следующие действия: обучить линейный экстрактор, при-менить к его выходу нелинейное расширение базиса и обучить еще один линейный экстрактор признаков SFA на результатах расширения. При обучении на небольших пространственных участках видео естественных сцен SFA с квадратичным расширением базиса обучается признакам, имеющим много об- щих характеристик со сложными клетками в зоне V1 первичной зрительной коры (Berkes and Wiskott, 2005). При обучении на видео случайного движения в отрисо- ванной компьютером трехмерной сцене глубокая модель SFA обучается признакам, имеющим много общих характеристик с нейронами в мозгу крыс, отвечающими за ориентацию в пространстве (Franzius et al., 2007). Таким образом, модель SFA пред- ставляется биологически правдоподобной. Главное достоинство SFA состоит в том, что можно теоретически предсказать, ка- ким именно признакам обучится SFA, даже в глубокой нелинейной конфигурации. Для этого необходимо знать динамику окружения в терминах конфигурационно- го пространства (например, для случайного движения в трехмерном отрисованном окружении теоретический анализ основывается на знании распределения вероятно-сти положения и скорости перемещения камеры). Зная, как на самом деле изменяют- ся объясняющие факторы, можно аналитически найти оптимальные функции, выра-\n--- Страница 418 ---\nРазреженное кодирование  417 жающие эти факторы. На практике эксперименты с применением глубокой модели SFA к имитированным данным, похоже, восстанавливают теоретически предсказан- ные функции. Это большое преимущество, по сравнению с другими алгоритмами обуче ния, где функция стоимости сильно зависит от конкретных значений пикселей, из-за чего установить, каким функциям обучится модель, гораздо труднее. Глубокий SFA применялся также для обучения признакам для распознавания объектов и оценки расположения (Franzius et al., 2008). Пока еще принцип медлен- ности не лег в основу современных передовых приложений. Не ясно, что именно ограничивает его качество. Мы подозреваем, что априорная гипотеза медленности слишком сильная и что лучше бы не требовать, чтобы признаки были приблизи- тельно постоянны, а наложить ограничение, что их должно быть легко предсказать при переходе от предыдущего шага к следующему. Положение объекта – полезный признак вне зависимости от того, велика или мала его скорость, но принцип мед-ленности поощряет модель игнорировать положение быстро перемещающихся объ-ектов. 13.4. Разреженное кодирование Разреженное кодирование (Olshausen and Field, 1996) – это линейная факторная модель, которая активно изучалась как механизм обучения признакам без учителя и выделения признаков. Строго говоря, термин «разреженное кодирование» относит- ся к процессу вывода значения h в этой модели, а «разреженное моделирование» – к процессу проектирования и обучения модели, но часто под «разреженным кодиро- ванием» понимают то и другое. Как и в большинстве линейных факторных моделей, здесь используется линейный декодер плюс шум для получения реконструкций x в соответствии с формулой (13.2). Точнее, в моделях разреженного кодирования обычно предполагается, что в линей- ных факторах присутствует гауссов шум с изотропной точностью β: (13.12) Распределение p(h) выбирается так, чтобы были острые пики вблизи 0 (Olshausen and Field, 1996). Обычно используются факторизованные распределения Лапласа, Коши или t-распределения Стьюдента. Например, априорное распределение Лапла- са, параметризованное штрафом разреженности λ, имеет вид: (13.13) а t-распределение Стьюдента: (13.14) Обучить модель разреженного кодирования методом максимального правдоподо- бия невозможно из-за гигантского объема вычислений. Вместо этого чередуют коди-рование данных с обучением декодера для лучшей реконструкции данных при задан-\n--- Страница 419 ---\n418  Линейные факторные модели ной кодировке. В разделе 19.3 мы приведем теоретическое обоснование этого подхода в качестве аппроксимации максимального правдоподобия. Для моделей типа PCA мы уже видели, как используется параметрическая функ- ция кодирования, которая предсказывает h и включает только умножение на матрицу весов. В разреженном кодировании используется не параметрический кодировщик, а алгоритм оптимизации, который решает задачу нахождения одного наиболее веро- ятного значения кода: h* = f(x) = p(h | x). (13.15) В сочетании с формулами (13.13) и (13.12) получаем следующую задачу оптими- зации: p(h | x) (13.16) = log p(h | x) (13.17) = λ||h||1 + β||x – Wh ||22, (13.18) где мы опустили члены, не зависящие от h, и для простоты поделили на положитель- ные масштабные коэффициенты. Поскольку для h используется норма L1, эта процедура даст разреженный вектор h* (см. раздел 7.1.2). Чтобы обучить модель, а не просто произвести вывод, мы чередуем минимизацию по h с минимизацией по W. Здесь β рассматривается как гиперпараметр. Обычно ему присваивают значение 1, потому что в этой задаче оптимизации у него общая роль с λ, а заводить два гиперпараметра нет смысла. В принципе, можно было бы рассматри- вать β как параметр модели и обучить его. В нашем изложении отброшены некоторые члены, не зависящие от h, но зависящие от β. Если мы хотим обучить β, то эти члены следует включить, иначе β выродится в 0. Не во всех подходах к разреженному кодированию явно строятся p(h) и p(x | h). Иногда мы хотим только обучить словарь признаков со значениями активации, кото- рые часто будут равны 0 при выделении с помощью этой процедуры вывода. Если h выбирается из априорного распределения Лапласа, то обращение любого элемента h в 0 – невозможное событие. Сама порождающая модель не особенно раз- реженная, таковым является только экстрактор признаков. В работе Goodfellow et al. (2013d) описан приближенный вывод в другом семействе моделей – разреженного кодирования типа Spike-and-Slab, – для которого выборка из априорного распреде- ления обычно содержит нули. Разреженное кодирование в сочетании с использованием непараметрического ко- дировщика, в принципе, может минимизировать комбинацию ошибки реконструкции с логарифмической априорной вероятностью лучше, чем любой конкретный парамет- рической кодировщик. Еще одно преимущество состоит в том, что у кодировщика нет ошибки обобщения. Параметрический кодировщик должен обучиться такому отобра-жению x на h, которое хорошо обобщается. Для необычных x, не похожих на обучаю- щие данные, обученный параметрический кодировщик может не найти h, приводя- щее к верной реконструкции или к разреженному коду. В подавляю щем большинстве формулировок моделей разреженного кодирования, если задача вывода выпуклая,\n--- Страница 420 ---\nИнтерпретация PCA в терминах многообразий  419 процедура оптимизации гарантированно находит оптимальный код (за исключени- ем вырожденных случаев, как, например, повторяющиеся векторы весов). Очевидно, что затраты на разреженность и реконструкцию все равно могут быть выше для не- знакомых точек, но это из-за ошибки обобщения в весах декодера, а не из-за ошиб- ки обобщения в кодировщике. Благодаря отсутствию ошибки обобщения в процессе разреженного кодирования, основанного на оптимизации, ошибка обобщения в слу- чае использования разреженного кодирования в качестве экстрактора признаков для классификатора может оказаться лучше, чем при использовании параметрической функции для предсказания кода. В работе Coates and Ng (2011) показано, что призна- ки, найденные с помощью разреженного кодирования, лучше обобщаются в задачах распознавания объектов, чем признаки, найденные родственной моделью, основанной на параметрическом кодировщике, – линейно-сигмоидным автокодировщиком. По следам этой работы в работе Goodfellow et al. (2013d) показано, что вариант разрежен- ного кодирования обобщается лучше, чем другие экстракторы признаков, в режиме, когда доступно очень мало меток (двадцать или даже меньше на каждый класс). Основной недостаток непараметрического кодировщика в том, что ему требуется больше времени для вычисления h при известном x из-за необходимости выполнять итеративный алгоритм. В параметрическом автокодировщике, который будет опи- сан в главе 14, используется только фиксированное число слоев, часто всего один. Еще один недостаток – сложность обратного распространения через непараметриче- ский кодировщик, что затрудняет предобучение модели разреженного кодирования с помощью критерия без учителя и последующую настройку с помощью критерия с учителем. Существуют модифицированные варианты разреженного кодирования, допускающие приближенные производные, но они не получили широкого распрост-ранения (Bagnell and Bradley, 2009). Разреженное кодирование, как и другие линейные факторные модели, часто по- рождает плохие примеры, как показано на рис. 13.2. Так бывает, даже когда модель способна хорошо реконструировать данные и предоставляет полезные признаки классификатору. Причина в том, что каждый отдельный признак может быть обучен хорошо, но факторное априорное распределение скрытого кода приводит к тому, что модель включает случайные подмножества всех признаков в каждый сгенерирован- ный пример. Это является стимулом для разработки более глубоких моделей, кото-рые могут применять нефакторное распределение в самом глубоком слое кода, а так- же для разработки более изощренных мелких моделей. 13.5. Интерпретация PCA в терминах многообразий Линейные факторные модели, в т. ч. PCA и факторный анализ, можно интерпрети- ровать как обучение многообразия (Hinton et al., 1997). Мы можем рассматривать вероятностный PCA как определение блинообразной области высокой вероятно-сти – нормальное распределение, очень узкое вдоль некоторых осей, как блин вдоль своей вертикальной оси, и сильно вытянутое вдоль остальных осей, как блин вдоль горизонтальных осей (см. рис. 13.3). PCA можно интерпретировать как совмещение этого блина с линейным многообразием в пространстве более высокой размерности. Такая интерпретация относится не только к традиционному PCA, но и к любому ли- нейному автокодировщику, который обучается матрицам W и V, добиваясь, чтобы реконструкция x находилась как можно ближе к x.\n--- Страница 421 ---\n420  Линейные факторные модели Рис. 13.2  Образцы примеров и весов из модели разреженного коди- рования типа Spike-and-Slab, обученной на наборе данных MNISТ . (Слева) Выборка из модели не похожа на обучающие примеры. На первый взгляд можно предположить, что модель плохо обучена. (Справа). Векторы весов модели обучены представлять росчерки пера и иногда целые цифры. Сле- довательно, модель обучилась полезным признакам. Проблема в том, что факторное априорное распределение признаков приводит к комбинирова- нию случайных подмножеств признаков. Немногие из таких подмножеств годятся для образования распознаваемой цифры из набора MNISТ . Отсюда необходимость разработки порождающих моделей с более мощными рас- пределениями латентных кодов. Рисунок взят из работы Goodfellow et al. (2013d) с разрешения авторов Пусть кодировщик имеет вид h = f(x) = W⏉(x – μ). (13.19) Кодировщик вычисляет представление h низкой размерности. С точки зрения ав- токодировщика, мы имеем декодер, вычисляющий реконструкцию xˆ = g(h) = b + Vh. (13.20) Выбору линейного кодировщика и декодера, минимизирующих ошибку реконст- рукции 𝔼[||x – xˆ||2], (13.21) соответствует V = W, μ = b = 𝔼[x], а столбцы матрицы W образуют ортонормирован- ный базис, определяющий то же подпространство, что и главные собственные векто- ры ковариационной матрицы C = 𝔼[(x – μ)(x – μ)⏉]. (13.22) В случае PCA столбцами W являются эти собственные векторы, упорядоченные по абсолютной величине соответствующих собственных значений (которые все ве- щественные и неотрицательные).\n--- Страница 422 ---\nИнтерпретация PCA в терминах многообразий  421 Рис. 13.3  Плоское нормальное распределение с высокой концентраци- ей вероятности в окрестности многообразия низкой размерности. На ри- сунке показана верхняя половина «блина» над «плоскостью многообразия», проходящей через его середину. Дисперсия в направлении, ортогональном многообразию, очень мала (стрелка в направлении наружу от плоскости) и может считаться «шумом», тогда как дисперсии в других направлениях (стрелки внутри плоскости) велики и соответствуют «сигналу» и определя- ют систему координат для данных пониженной размерности Можно также показать, что собственное значение λi матрицы C соответствует дис- персии x в направлении собственного вектора v(i). Если x ∈ ℝD, h ∈ ℝd и d < D, то оптимальная ошибка реконструкции (при указанном выше выборе μ, b, V и W) равна (13.23) Поэтому если ковариационная матрица имеет ранг d, то собственные значения от λd+1 до λD равны 0 и ошибка реконструкции равна 0. Далее, можно показать, что это же решение может быть получено максимизацией дисперсий элементов h при условии ортогональности W, а не минимизацией ошибки реконструкции. Линейные факторные модели относятся к простейшим порождающим моделям и к простейшим моделям, обучающимся представлению данных. Как линейные клас- сификаторы и модели линейной регрессии можно обобщить на глубокие сети пря- мого распространения, так и линейные факторные модели обобщаются на сети-ав- токодировщики и глубокие вероятностные модели, которые решают те же задачи, но образуют гораздо более мощное и гибкое семейство моделей.",
      "debug": {
        "start_page": 412,
        "end_page": 422
      }
    },
    {
      "name": "Глава 14. Автокодировщики 422",
      "content": "--- Страница 423 --- (продолжение)\nГлава 14 Автокодировщики Автокодировщиком называется нейронная сеть, обученная пытаться скопировать свой вход в выход. На внутреннем уровне в ней имеется скрытый слой h, который описывает код, используемый для представления входа. Можно считать, что сеть со- стоит из двух частей: функция кодирования h = f(x) и декодер, порождающий ре- конструкцию r = g(h). Эта архитектура показана на рис. 14.1. Если автокодировщику удается просто обучиться всюду сохранять тождество g(f(x)) = x, то это не особенно полезно. На самом деле автокодировщики проектируются так, чтобы они не могли обучиться идеальному копированию. Обычно налагаются ограничения, позволяю-щие копировать только приближенно и только тот вход, который похож на обучаю- щие данные. Поскольку модель заставляют расставлять подлежащие копированию аспекты данных по приоритетам, то часто она обучается полезным свойствам данных. Рис. 14.1  Общая структура автокодировщика, отображающего вход x на выход r (называемый реконструкцией) через внутреннее представление, или код h. Автокодировщик состоит из двух частей: кодировщик f (отобра- жение x в h) и декодер g (отображение h в r) В современных автокодировщиках идея кодировщика и декодера обобщена с де- терминированных на стохастические отображения pencoder(h | x) и pdecoder(x | h). Идея автокодировщиков исторически является частью ландшафта нейронных се- тей уже несколько десятилетий (LeCun, 1987; Bourlard and Kamp, 1988; Hinton and Zemel, 1994). Традиционно их использовали для понижения размерности и обуче- ния признакам. Выявленные недавно теоретические связи между автокодировщика-ми и моделями с латентными переменными вывели автокодировщики на передний фронт порождающего моделирования, как мы увидим в главе 20. Автокодировщики можно рассматривать как частный случай сетей прямого распространения и обучать, применяя те же методы, обычно мини-пакетный градиентный спуск в направлении градиентов, вычисленных в ходе обратного распространения. Но, в отличие от общих сетей прямого распространения, автокодировщики можно обучать также с помощью\nГлава 14 Автокодировщики Автокодировщиком называется нейронная сеть, обученная пытаться скопировать свой вход в выход. На внутреннем уровне в ней имеется скрытый слой h, который описывает код, используемый для представления входа. Можно считать, что сеть со- стоит из двух частей: функция кодирования h = f(x) и декодер, порождающий ре- конструкцию r = g(h). Эта архитектура показана на рис. 14.1. Если автокодировщику удается просто обучиться всюду сохранять тождество g(f(x)) = x, то это не особенно полезно. На самом деле автокодировщики проектируются так, чтобы они не могли обучиться идеальному копированию. Обычно налагаются ограничения, позволяю-щие копировать только приближенно и только тот вход, который похож на обучаю- щие данные. Поскольку модель заставляют расставлять подлежащие копированию аспекты данных по приоритетам, то часто она обучается полезным свойствам данных. Рис. 14.1  Общая структура автокодировщика, отображающего вход x на выход r (называемый реконструкцией) через внутреннее представление, или код h. Автокодировщик состоит из двух частей: кодировщик f (отобра- жение x в h) и декодер g (отображение h в r) В современных автокодировщиках идея кодировщика и декодера обобщена с де- терминированных на стохастические отображения pencoder(h | x) и pdecoder(x | h). Идея автокодировщиков исторически является частью ландшафта нейронных се- тей уже несколько десятилетий (LeCun, 1987; Bourlard and Kamp, 1988; Hinton and Zemel, 1994). Традиционно их использовали для понижения размерности и обуче- ния признакам. Выявленные недавно теоретические связи между автокодировщика-ми и моделями с латентными переменными вывели автокодировщики на передний фронт порождающего моделирования, как мы увидим в главе 20. Автокодировщики можно рассматривать как частный случай сетей прямого распространения и обучать, применяя те же методы, обычно мини-пакетный градиентный спуск в направлении градиентов, вычисленных в ходе обратного распространения. Но, в отличие от общих сетей прямого распространения, автокодировщики можно обучать также с помощью\n--- Страница 424 ---\nРегуляризированные автокодировщики  423 рециркуляции (Hinton and McClelland, 1988) – алгоритма обучения, основанного на сравнении активаций сети на оригинальных и реконструированных входных данных. Рециркуляция считается биологически более правдоподобным механизмом, чем об- ратное распространение, но редко применяется в приложениях машинного обучения. 14.1. Понижающие автокодировщики Копирование входа в выход может показаться бесполезным делом, но, как правило, нас не интересует выход декодера. Вместо этого мы надеемся, что, обучая автоко-дировщик задаче копирования входа, мы получим код h, обладающий полезными свойствами. Один из способов получить такие свойства – наложить ограничение, согласно которому размерность h должна быть меньше размерности x. Такие авто- кодировщики называются понижающими (undercomplete). Обучение понижающе- го представления заставляет автокодировщик улавливать наиболее отличительные признаки обучающих данных. Процесс обучения описывается просто как минимизация функции потерь L(x, g(f(x))), (14.1) где функция L штрафует g(f(x)) за непохожесть на x; например, это может быть сред- неквадратическая ошибка. Если декодер – линейная функция, а L – среднеквадратическая ошибка, то по- нижающий автокодировщик обучается тому же подпространству, что PCA. В таком случае автокодировщик, обученный выполнять задачу копирования, в качестве по- бочного эффекта находит главное подпространство обучающих данных. Следовательно, автокодировщики с нелинейными функциями кодирования f и де- кодирования g могут обучиться более мощным нелинейным обобщениям PCA. К со- жалению, если разрешить слишком большую емкость кодировщика и декодера, то автокодировщик будет решать задачу копирования, не извлекая полезной информа- ции о распределении данных. Теоретически можно вообразить автокодировщик с од- номерным кодом, но очень мощным нелинейным кодировщиком, который обучит ся представлять каждый обучающий пример x (i) кодом i. Декодер можно было бы об- учить отображению этих целочисленных индексов обратно на значения конкретных обучающих примеров. Такой сценарий, на практике не встречающийся, ясно показы-вает, что автокодировщик, обученный копированию, может не собрать никакой по-лезной информации о наборе данных, если его емкость слишком велика. 14.2. Регуляризированные автокодировщики Понижающие автокодировщики, для которых размерность кода меньше размерности входа, могут обучиться наиболее отличительным признакам распределения данных. Мы видели, что такие автокодировщики не обучаются ничему полезному, если ем-кость кодировщика и декодера слишком велика. Похожая проблема возникает, если скрытый код имеет такую размерность, как вход, а также в случае повышающего (overcomplete) автокодировщика, когда раз- мерность скрытого кода больше размерности входа. В этих случаях даже линейные кодировщик и декодер могут научиться копировать вход в выход, не узнав ничего полезного о распределении данных.\n--- Страница 425 ---\n424  Автокодировщики В идеале можно было бы успешно обучить любую архитектуру автокодировщика, выбрав размерность кода и емкость кодировщика и декодера, исходя из сложности моделируемого распределения. Такую возможность предоставляют регуляризиро- ванные автокодировщики. Вместо того чтобы ограничивать емкость модели, стре-мясь сделать кодировщик и декодер мелкими, а размер кода малым, регуляризи- рованный автокодировщик использует такую функцию потерь, которая побуждает модель к приобретению дополнительных свойств, помимо способности копировать вход в выход. К числу таких свойств относятся разреженность представления, малая величина производной представления и устойчивость к шуму или отсутствию части входных данных. Регуляризированный автокодировщик может быть нелинейным и повышающим и тем не менее узнать что-то полезное о распределении данных, даже если емкость модели достаточно велика, чтобы обучить тривиальную тождественную функцию. Помимо описанных ниже методов, которые наиболее естественно интерпретиру- ются как регуляризированные автокодировщики, почти любая порождающая мо-дель с латентными переменными и процедурой вывода (для вычисления латентных представлений по входу) может рассматриваться как некий вид автокодировщика. Су ществуют два подхода к порождающему моделированию, подчеркивающие та- кую связь с автокодировщиками: ведущие происхождение от машины Гельмгольца (Hinton et al., 1995b), например вариационный автокодировщик (раздел 20.10.3), и порождающие стохастические сети (раздел 20.12). Эти модели естественно обуча- ются повышающему кодированию входа с высокой емкостью и оказываются полез- ными даже без регуляризации кодирования. Созданные ими коды полезны, потому что модель обучалась приближенно максимизировать вероятность обучающих дан-ных, а не копировать вход в выход. 14.2.1. Разреженные автокодировщики Разреженным называется автокодировщик, для которого критерий обучения вклю-чает штраф разреженности Ω(h) на кодовом слое h в дополнение к ошибке реконст- рукции: L(x, g(f(x))) + Ω(h), (14.2) где g(h) – выход декодера и обычно h = f(x) – выход кодировщика. Разреженные автокодировщики чаще всего применяются для обучения признакам в интересах другой задачи, например классификации. Автокодировщик, регуляри- зированный с целью добиться разреженности, должен откликаться на уникальные статистические особенности набора данных, на котором обучался, а не просто высту- пать в роли тождественной функции. Поэтому обучение копированию со штрафом разреженности может дать модель, которая попутно обучилась каким-то полезным признакам. Штраф Ω(h) можно рассматривать как регуляризирующий член, добавленный к сети прямого распространения, основная задача которой – копировать вход в вы- ход (целевая функция для обучения без учителя) и, возможно, решать еще какую-то задачу обучения с учителем, зависящую от найденных разреженных признаков. В отличие от других регуляризаторов, например снижения весов, у этого регуляри- затора нет очевидной байесовской интерпретации. Как было сказано в разделе 5.6.1, обучение со снижением весов и другими регуляризирующими штрафами можно ин-\n--- Страница 426 ---\nРегуляризированные автокодировщики  425 терпретировать как аппроксимацию байесовского вывода максимумом апостериор- ной вероятности с добавлением регуляризирующего штрафа, который соответствует априорному распределению вероятности параметров модели. С этой точки зрения, регуляризированное максимальное правдоподобие соответствует максимизации p(θ | x), что эквивалентно максимизации log p(x | θ) + log p(θ). Член log p(x | θ) – обычное логарифмическое правдоподобие данных, а член log p(θ), логарифмическое априорное распределение параметров, знаменует предпочтение определенным значе-ниям θ. Этот взгляд на вещи описан в разделе 5.6. Для регуляризированных автоко- дировщиков такая интерпретация не годится, потому что регуляризатор зависит от данных и поэтому по определению не может считаться априорным распределением в формальном смысле слова. Однако мы по-прежнему можем считать, что регуляри- зирующие члены неявно выражают предпочтение некоторым функциям. Вместо того чтобы считать штраф разреженности регуляризатором для копиро- вания данных, мы можем рассматривать всю инфраструктуру разреженного авто- кодирования как обучение порождающей модели с латентными переменными, ап- проксимирующее максимальное правдоподобие. Предположим, что имеется модель с видимыми переменными x, латентными переменными h и явным совместным рас- пределением p model(x, h) = pmodel(h)pmodel(x | h). Мы называем pmodel(h) априорным рас- пределением латентных переменных и считаем, что оно представляет априорную веру модели в то, что она увидит x. Эта трактовка отличается от предыдущего упо- требления слова «априорный», которое обозначало распределение p(θ), описываю- щее наши гипотезы о параметрах модели еще до знакомства с обучающими данными. Логарифмическое правдоподобие можно представить в виде (14.3) Мы можем рассматривать автокодировщик как аппроксимацию этой суммы то- чечной оценкой для всего одного значения h, имеющего высокую вероятность. Это похоже на порождающую модель разреженного кодирования (раздел 13.4), только h теперь является выходом параметрического кодировщика, а не результатом опти- мизации, которая выводит наиболее вероятное значение h. С этой точки зрения, при таком выборе h мы максимизируем функцию log pmodel(h, x) = log pmodel(h) + log pmodel(x | h). (14.4) Член log pmodel(h) может индуцировать разреженность. Например, априорное расп- ределение Лапласа (14.5) соответствует штрафу разреженности по норме L1 (сумма абсолютных величин). Действительно, (14.6) (14.7) где постоянный член зависит только от λ и не зависит от h. Обычно λ считается ги- перпараметром, а постоянный член отбрасывается, потому что не влияет на обучение\n--- Страница 427 ---\n426  Автокодировщики параметров. Разреженность могут индуцировать и другие априорные распределения, например t-распределение Стьюдента. При таком взгляде на разреженность как ре- зультат влияния pmodel(h) на обучение с целью аппроксимации максимального правдо- подобия штраф разреженности вообще не является регуляризирующим членом. Это просто следствие распределения латентных переменных модели. Такой взгляд дает еще один мотив для обучения автокодировщика: это способ приближенного обуче-ния порождающей модели. И попутно выясняется еще одна причина полезности при- знаков, обученных автокодировщиком: они описывают латентные переменные, объ-ясняющие входные данные. В ранних работах по разреженным автокодировщикам (Ranzato et al., 2007a, 2008) исследовались различные формы разреженности и была предложена связь между штрафом разреженности и членом log Z, который возникает в случае приме- нения максимального правдоподобия к неориентированной вероятностной модели p(x) = (1/Z)p~(x). Идея в том, что минимизация log Z не дает вероятностной модели достичь высокой вероятности всюду, а наложение ограничения разреженности на ав- токодировщик предотвращает низкую ошибку реконструкции всюду. В этом случае связь прослеживается на уровне интуитивного понимания общего механизма, а не математически строгого соответствия. Интерпретация штрафа разреженности как соответствия величине log p model(h) в ориентированной модели pmodel(h)pmodel(x | h) ма- тематически более очевидна. Один из способов достижения настоящих нулей в коде h для разреженных (и шу- моподавляющих) автокодировщиков предложен в работе Glorot et al. (2011b). Идея в том, чтобы использовать блоки линейной ректификации для порождения кодового слоя. Взяв априорное распределение, которое толкает представления в сторону нуля (например, штраф по норме L1), можно косвенно управлять средним числом нулей в представлении. 14.2.2. Шумоподавляющие автокодировщики Получить автокодировщик, который обучается чему-то полезному, можно не только путем добавления штрафа в функцию стоимости, но и изменив в ней член реконст- рукции ошибки. Традиционно автокодировщики минимизируют некоторую функцию L(x, g(f(x))), (14.8) где L – функция потерь, штрафующая g(f(x)) за непохожесть на x, например норма L 2 разности. Это побуждает g ∘ f быть просто тождественной функцией, если емкости g и f для этого достаточно. Шумоподавляющий автокодировщик (denoising autoencoder – DAE) вместо этого минимизирует функцию L(x, g(f(x~))), (14.9) где x~ – копия x, искаженная каким-то шумом. Поэтому шумоподавляющий автоко- дировщик должен скорректировать искажение, а не просто скопировать свой вход. Как показано в работах Alain and Bengio (2013) и Bengio et al. (2013c), обучение с целью шумоподавления принуждает f и g неявно обучиться структуре pdata(x). Следовательно, шумоподавляющие автокодировщики – еще один пример того, как полезные свойства могут оказаться побочным результатом минимизации ошибки\n--- Страница 428 ---\nРепрезентативная способность, размер слоя и глубина  427 реконструкции. Вместе с тем это пример того, как повышающую модель с высокой емкостью можно использовать в качестве автокодировщика, если позаботиться о том, чтобы она не обучилась тождественной функции. Шумоподавляющие автокодиров- щики более детально описаны в разделе 14.5. 14.2.3. Регуляризация посредством штрафования производных Еще одна стратегия регуляризации автокодировщика подразумевает использование штрафа, как в разреженных автокодировщиках: L(x, g(f(x))) + Ω(h, x), (14.10) но с Ω другого вида: (14.11) Это понуждает модель обучить функцию, которая не сильно изменяется при малом изменении x. Поскольку этот штраф применяется только к обучающим примерам, он заставляет автокодировщик обучиться признакам, улавливающим информацию об обучающем распределении. Регуляризированный таким способом автокодировщик называется сжимающим (contractive autoencoder – CAE). Существуют теоретические связи между этим под- ходом и шумоподавляющими автокодировщиками, обучением многообразий и ве- роятностным моделированием. Сжимающие автокодировщики подробнее описаны в разделе 14.7. 14.3. Репрезентативная способность, размер слоя и глубина Часто при обучении автокодировщиков используют кодировщик и декодер всего с одним слоем. Но это необязательно. На самом деле глубокие кодировщики и деко- деры дают целый ряд преимуществ. Напомним (см. раздел 6.4.1), что у глубоких сетей прямого распространения есть много достоинств. Поскольку автокодировщики – это сети прямого распростране- ния, то все эти достоинства свойственны и им тоже. Более того, кодировщик и деко- дер по отдельности тоже являются сетями прямого распространения, поэтому каждая компонента автокодировщика может получить выигрыш от глубины. Важное преимущество нетривиальной глубины состоит в том, что согласно уни- версальной теореме аппроксимации нейронной сетью прямого распространения хотя бы с одним скрытым слоем гарантированно можно аппроксимировать любую функцию (из весьма широкого класса) с произвольной точностью, при условии что количество скрытых блоков достаточно велико. Это означает, что автокодировщик с одним скрытым слоем способен представить тождественную функцию в области определения данных с произвольной точностью. Однако отображение входа на код мелкое, т. е. мы не можем наложить произвольных ограничений, например потребо- вать, чтобы код был разреженным. Глубокий автокодировщик, имеющий, по край-ней мере, один дополнительный скрытый слой внутри самого кодировщика, может аппроксимировать любое отображение входа на код с произвольной точностью при наличии достаточного числа скрытых блоков.\n--- Страница 429 ---\n428  Автокодировщики Увеличение глубины может экспоненциально уменьшить вычислительную стои- мость представления некоторых функций, а также объем данных, необходимых для обучения некоторых функций. Обзор преимуществ глубины в сетях прямого распро- странения см. в разделе 6.4.1. Экспериментально показано, что глубокие автокодировщики достигают гораздо более высокой степени сжатия, чем соответствующие мелкие или линейные автоко- дировщики (Hinton and Salakhutdinov, 2006). Общая стратегия обучения глубокого автокодировщика состоит в жадном пред- обучении глубокой архитектуры посредством обучения ряда мелких автокодировщи-ков, именно поэтому мы часто встречаем мелкие автокодировщики даже тогда, когда целью является обучение глубокого. 14.4. Стохастические кодировщики и декодеры Автокодировщики – это просто сети прямого распространения. Те же функции по- терь и типы выходных блоков, что применяются в традиционных сетях прямого рас- пространения, можно использовать и в автокодировщиках. Как было сказано в разделе 6.2.2.4, общая стратегия проектирования выходных блоков и функции потерь в сети прямого распространения заключается в том, чтобы определить выходное распределение p(y | x) и минимизировать отрицательное лога- рифмическое правдоподобие –log p(y | x). В такой постановке y – это вектор целей, например меток классов. В автокодировщике x является не только входом, но и целью. Но тем не менее мы можем применить тот же механизм, что и раньше. Можно считать, что декодер дает условное распределение pdecoder(x | h) при условии скрытого кода h. Тогда можно обучить автокодировщик путем минимизации –log pdecoder(x | h). Точная форма этой функции потерь будет зависеть от формы декодера. Как и в традиционных сетях прямого распространения, когда x принимает вещественные значения, мы обычно используем линейные выходные блоки для параметризации среднего нормального распределения. В этом случае отрицательное логарифмическое правдоподобие дает критерий среднеквадратической ошибки. Аналогично бинарным значениям x соот- ветствует распределение Бернулли, параметры которого задаются сигмоидным вы-ходным блоком, дискретным значениям x – softmax-распределение и т. д. Как прави- ло, выходные переменные считаются условно независимыми при условии h, чтобы это распределение вероятности было проще вычислить, но существуют методы, на-пример выход в виде смеси распределений, которые позволяют моделировать корре- лированный выход с приемлемыми вычислительными затратами. Чтобы еще дальше отойти от сетей прямого распространения, мы можем обобщить понятие функции кодирования f(x) на распределение кодирования p encoder(h | x), как показано на рис. 14.2. Любая модель с латентными переменными pmodel(h, x) определяет стохастический кодировщик pencoder(h | x) = pmodel(h | x) (14.12) и стохастический декодер pdecoder(x | h) = pmodel(x | h). (14.13)\n--- Страница 430 ---\nШумоподавляющие автокодировщики  429 Рис. 14.2  Структура стохастического автокодировщика, в которой ко- дировщик и декодер – функции, содержащие шум, т. е. их выход можно рассматривать как выборку из распределения pencoder(h | x) для кодировщика и pdecoder(x | h) для декодера В общем случае распределения кодировщика и декодера не обязательно явля- ются условными распределениями, совместимыми с совместным распределением pmodel(x, h). В работе Alain et al. (2015) показано, что обучение кодировщика и декоде- ра как шумоподавляющего автокодировщика делает их асимптотически совместимы- ми (при достаточной емкости и количестве обучающих примеров). 14.5. Шумоподавляющие автокодировщики Шумоподавляющим автокодировщиком (DAE) называется автокодировщик, кото- рый получает на входе искаженные данные и обучается предсказывать истинные, не- искаженные данные. Процедура обучения DAE показана на рис. 14.3. Мы вводим искажающий процесс C(x~ | x), который представляет условное распределение искаженных примеров x~ при условии истинных примеров x. Затем автокодировщик обучается распределению реконструкции preconstruct (x | x~), которое оценивается по обучающим парам (x, x~) сле- дующим образом: 1) выбрать обучающий пример x из обучающих данных; 2) выбрать искаженную версию x~ из C(x~ | x = x); 3) использовать (x, x~) в качестве обучающего примера для оценки распределения реконструкции автокодировщика preconstruct (x | x~) = pdecoder(x | h), где h – выход кодировщика f(x~), а pdecoder обычно определяется декодером g(h). Как правило, мы можем просто выполнить приближенную градиентную миними- зацию (например, мини-пакетный градиентный спуск) отрицательного логарифми-ческого правдоподобия –log p decoder(x | h). Если кодировщик детерминирован, то шу- моподавляющий автокодировщик является сетью прямого распространения, и для его обучения можно применить все те же методы, что для любой сети прямого рас-пространения. Таким образом, мы можем считать, что DAE применяет метод стохастического гра- диентного спуска к следующему математическому ожиданию: –𝔼 x~pˆdata(x)𝔼x~~C(x~|x)log pdecoder(x | h = f(x ~)), (14.14) где pˆdata(x) – распределение обучающих данных.\n--- Страница 431 ---\n430  Автокодировщики Рис. 14.3  Граф вычислений функции стоимости для шумоподавляю- щего автокодировщика, обученного реконструировать чистые данные x по искаженным x~. Это достигается путем минимизации потери L = = –log pdecoder(x | h = f(x~)), где x~ – искаженная версия примера x, полученная посредством заданного искажающего процесса C(x~ | x). Обычно pdecoder яв- ляется факторным распределением, средние параметры которого порож- даются сетью прямого распространения g 14.5.1. Сопоставление рейтингов Сопоставление рейтингов (score matching) (Hyvärinen, 2005) – альтернатива мак- симальному правдоподобию. Этот метод дает состоятельную оценку распределений вероятности, поощряя модель иметь такой же рейтинг (score), как распределение дан- ных на каждом обучающем примере x. В этом контексте рейтингом является конкрет- ное поле градиента: ∇x log p(x). (14.15) Мы вернемся к обсуждению сопоставления рейтингов в разделе 18.4. Пока что до- статочно понимать, что обучения поля градиента log pdata – один из способов обучить- ся структуре самого распределения pdata. У шумоподавляющих автокодировщиков есть очень важное свойство: критерий их обучения (с условно нормальным p(x | h)) таков, что автокодировщик обучается векторному полю (g(f(x)) – x), являющемуся оценкой для рейтинга распределения данных. Это показано на рис. 14.4. Шумоподавляющее обучение автокодировщиков конкретного вида (с сигмоид- ными скрытыми блоками и линейными блоками реконструкции) с использованием гауссова шума и среднеквадратической ошибки в качестве стоимости реконструкции эквивалентно (Vincent, 2011) обучению специального вида неориентированной веро- ятностной модели – ограниченной машины Больцмана (ОМБ) с гауссовыми види- мыми блоками. Эта модель подробно описана в разделе 20.5.1; сейчас нам достаточно знать, что она дает явное распределение pmodel(x; θ). Если ОМБ обучается с примене- нием шумоподавляющего сопоставления рейтингов (Kingma and LeCun, 2010), то алгоритм обучения эквивалентен шумоподавляющему обучению в соответствующем автокодировщике. При фиксированном уровне шума регуляризированное сопостав-ление рейтингов не является состоятельной оценкой, оно восстанавливает размытую версию распределения. Но если уровень шума стремится к 0, когда число примеров\n--- Страница 432 ---\nШумоподавляющие автокодировщики  431 стремится к бесконечности, то состоятельность восстанавливается. Шумоподавляю- щее сопоставление рейтингов обсуждается в разделе 18.5. Рис. 14.4  Шумоподавляющий автокодировщик обучается отображать искаженные данные x~ на исходные x. Обучающие примеры x обозначе- ны красными крестиками, лежащими в окрестности многообразия низкой размерности, показанного жирной черной линией. Искажающий процесс C(x~ | x) представлен серой окружностью с равновероятными искажения- ми. Серая стрелка показывает, как один обучающий пример преобразуется в результат одной выборки из искажающего процесса. Когда шумоподавля- ющий автокодировщик обучается минимизировать среднее квадратичных ошибок ||g(f(x~)) – x|| 2, реконструкция g(f(x~)) оценивает 𝔼x, x~~pdata(x)C(x~|x)[x | x~]. Вектор g(f(x~)) – x~ направлен приблизительно в сторону ближайшей точки на многообразии, поскольку g(f(x~)) оценивает центр тяжести неискаженных точек x, которые могли бы привести к x~. Таким образом, автокодировщик обучается векторному полю g(f(x)) – x, обозначенному зелеными стрелка- ми. Это векторное поле является оценкой рейтинга ∇x log pdata(x) с точностью до множителя, равного среднеквадратической ошибке реконструкции Существуют и другие связи между автокодировщиками и ОМБ. Сопоставление рейтингов в применении к ОМБ дает функцию стоимости, идентичную ошибке ре- конструкции в сочетании с регуляризирующим членом, аналогичным сжимающему штрафу CAE (Swersky et al., 2011). В работе Bengio and Delalleau (2009) показано, что градиент автокодировщика дает аппроксимацию обучения ОМБ методом сопостави- тельного расхождения (contrastive divergence). Для непрерывных x шумоподавляющий критерий с гауссовым искажением и рас- пределением реконструкции дает оценку рейтинга, применимую к общим параметри- зациям кодировщика и декодера (Alain and Bengio, 2013). Это означает, что общей ар- хитектурой кодировщик-декодер можно воспользоваться для оценивания рейтинга, если проводить обучение с критерием квадратичной ошибки ||g(f(x~)) – x || 2 (14.16)\n--- Страница 433 ---\n432  Автокодировщики и искажающим процессом C(x~ = x~ | x) = 𝒩(x~; μ = x, Σ = σ2I) (14.17) с дисперсией шума σ2. Принцип работы иллюстрируется на рис. 14.5. В общем случае не гарантируется, что реконструкция g(f(x)) минус вход x соот- ветствует градиенту хоть какой-нибудь функции, не говоря уже о рейтинге. Именно поэтому ранние результаты (Vincent, 2011) специализированы для конкретных па- раметризаций, когда g(f(x)) – x можно получить в виде производной какой-то дру- гой функции. В работе Kamyshanska and Memisevic (2015) результат Vincent (2011) обобщен путем идентификации такого семейства мелких автокодировщиков, что g(f(x)) – x соответствует рейтингу для всех членов этого семейства. Рис. 14.5  Обученное шумоподавляющим автокодировщиком вектор- ное поле вокруг одномерного искривленного многообразия, в окрестности которого сконцентрированы двумерные данные. Каждая стрелка по длине пропорциональна реконструкции минус входной вектор автокодировщика и направлена в сторону увеличения вероятности в соответствии с неявной оценкой распределения вероятности. Векторное поле обращается в нуль в точках максимума и минимума оцененной функции плотности (на много- образии). Так, отрезок спирали образует одномерное многообразие со-единенных друг с другом локальных максимумов. Локальные минимумы находятся вблизи середины разрыва между двумя отрезками. Если норма ошибки реконструкции (пропорциональная длинам стрелок) велика, то ве-роятность можно значительно повысить, двигаясь в направлении стрелки; такое бывает в основном на участках низкой вероятности. Автокодиров- щик отображает такие точки с низкой вероятностью на реконструкции, имеющие более высокую вероятность. Там, где вероятность максимальна, стрелка укорачивается, поскольку реконструкция становится более точной. Рисунок взят из работы Alain and Bengio (2013) с разрешения авторов\n--- Страница 434 ---\nОбучение многообразий с помощью автокодировщиков  433 До сих пор мы описывали только, как шумоподавляющий автокодировщик обуча- ется представлять распределение вероятности. В более общем случае можно исполь- зовать автокодировщик как порождающую модель и делать выборку из этого распре- деления. Это описывается в разделе 20.11. 14.5.1.1. Историческая справка Идея использовать МСП для шумоподавления восходит к работам LeCun (1987) и Gallinari et al. (1987). В работе Behnke (2001) рекуррентные сети использовались для очистки изображений от шумов. В некотором смысле шумоподавляющие автоко- дировщики – это просто МСП, обученные шумоподавлению. Однако название «шумоподавляющий автокодировщик» относится к модели, которая должна не просто обучиться очищать вход от шумов, но и найти хорошее внутреннее представление в качестве побочного эффекта. Эта идея возникла много позже (Vincent et al., 2008, 2010). Затем обученное представление можно исполь-зовать для предобучения более глубокой сети без учителя или с учителем. Как и в случае разреженного кодирования, разреженных, сжимающих и прочих регуля- ризированных автокодировщиков, мотивом для разработки шумоподавляющих ав-токодировщиков было стремление обучить кодировщики очень высокой емкости, не дав в то же время кодировщику и декодеру обучиться бесполезной тождествен- ной функции. Еще до появления современных DAE в работе Inayoshi and Kurita (2005) иссле- довалось достижение части тех же целей некоторыми из описанных выше методов. Подход авторов был основан на минимизации ошибки реконструкции в дополнение к целевой функции при внесении шума в скрытый слой обучаемого с учителем МСП, а целью было улучшить обобщаемость за счет введения ошибки реконструкции и привнесенного шума. Но они применяли линейный кодировщик и не могли обучать столь же мощные семейства функций, как современные DAE. 14.6. Обучение многообразий с помощью автокодировщиков Как и во многих других алгоритмах машинного обучения, в автокодировщиках ис- пользуется гипотеза о концентрации данных в окрестности многообразия низкой раз- мерности или небольшого множества таких многообразий (см. раздел 5.11.3). В неко- торых алгоритмах эта идея ограничена лишь обучением функций, которые корректно ведут себя на многообразии, но поведение может оказаться необычным, если предъ-явить пример, лежащий вне многообразия. Автокодировщики идут дальше и стре- мятся обучиться структуре многообразия. Чтобы понять, как они это делают, необходимо познакомиться с некоторыми ха- рактеристиками многообразий. Важной характеристикой является множество касательных плоскостей. Касатель- ная плоскость в точке x на d-мерном многообразии определяется d базисными векто- рами в локальных направлениях допустимых изменений. Как показано на рис. 14.6, эти локальные направления описывают, какие возможны бесконечно малые измене-ния x, не выводящие за пределы многообразия.\n--- Страница 435 ---\n434  Автокодировщики Рис. 14.6  Иллюстрация понятия касательной гиперплоскости. Здесь создается одномерное многообразие в 784-мерном пространстве. Мы берем изображение из набора данных MNISТ , содержащее 784 пикселя, и преобразуем его, выполняя параллельный перенос по вертикали. Вели- чина переноса определяет координату вдоль одномерного многообразия, которая описывает искривленный путь в пространстве изображения. На графике показано несколько точек на этом многообразии. Для наглядно-сти мы спроецировали многообразие на двумерное пространство методом PCA. У n-мерного многообразия в каждой точке имеется n-мерная каса- тельная плоскость. Эта плоскость имеет с многообразием ровно одну об- щую точку и ориентирована параллельно его поверхности в этой точке. Она определяет направления, в которых можно двигаться, оставаясь на много- образии. У данного одномерного многообразия касательная плоскость вы- рождается в прямую. Мы привели пример касательной прямой в одной точ- ке вместе с изображением, показывающим, как ее направление выглядит в пространстве изображения. Серым цветом обозначены пиксели, которые не изменяются при движении вдоль касательной, белым – пиксели, кото- рые становятся ярче, а черным – те, что становятся темнее Любая процедура обучения автокодировщика включает компромисс между двумя стремлениями. 1. Обучить такое представление h обучающего примера x, чтобы x можно было приближенно восстановить по h с помощью декодера. Тот факт, что x выбира- ется из обучающих данных, критически важен, поскольку означает, что автоко- дировщик не обязан успешно реконструировать входы, не вероятные с точки зрения порождающего данные распределения. 2. Удовлетворить ограничение или регуляризирующий штраф. Это может быть ар-хитектурное ограничение, ограничивающее емкость автокодировщика, или ре-\n--- Страница 436 ---\nОбучение многообразий с помощью автокодировщиков  435 гуляризирующий член, прибавленный к стоимости реконструкции. Смысл в лю- бом случае – отдавать предпочтение решениям, менее чувствительным к входу. Очевидно, что поодиночке оба стремления бесполезны: ни копирование входа в выход, ни полное игнорирование входа нам ни к чему. Но вместе они становятся осмысленными, потому что вынуждают скрытое представление уловить информацию о структуре порождающего данные распределения. Важный принцип заключается в том, что автокодировщик может ограничиться представлением только тех измене- ний, которые необходимы для реконструкции обучающих примеров. Если порождаю-щее распределение концентрируется вблизи многообразия низкой размерности, то получатся представления, которые неявно улавливают локальную систему координат этого многообразия: лишь изменения, касательные к многообразию в точке x, должны соответствовать изменениям h = f(x). Следовательно, кодировщик обучается такому отображению из пространства входов x в пространство представления, которое чувст- вительно только к изменениям вдоль направлений, касательных к многообразию, и нечувствительно к изменениям вдоль ортогональных к многообразию направлений. На рис. 14.7 приведен одномерный пример, показывающий, что, сделав функцию реконструкции нечувствительной к возмущениям входа в окрестности данных, мы заставили автокодировщик восстановить структуру многообразия. 1.0 0.8 0.6 0.40.20.0х 0 х1 хr(х) х2Тождественная функция Оптимальная реконструкция Рис. 14.7  Если автокодировщик обучает функцию реконструкции, ин- вариантную к малым возмущениям в окрестности входных точек, то он улавливает структуру многообразия, на котором лежат данные. В данном случае структурой является набор 0-мерных многообразий. Штриховая диагональная прямая обозначает тождественную целевую функцию, под-лежащую реконструкции. Оптимальная функция реконструкции пере-секает график тождественной функции в каждой точке данных. Г оризон- тальные стрелки в нижней части рисунка обозначают вектор направления реконструкции r(x) – x в пространстве входов и всегда указывают в сторону ближайшего «многообразия» (единственной точки в одномерном случае). Шумоподавляющий автокодировщик пытается сделать производную функ-ции реконструкции r(x) малой в окрестности входных точек. Сжимающий автокодировщик делает то же самое для кодировщика. Хотя производную r(x) понуждают быть малой вблизи входных точек, между ними она может быть большой. Пространство между входными точками соответствует об-ласти между многообразиями, где функция реконструкции должна иметь большую производную, чтобы вернуть искаженные точки на многообразие\n--- Страница 437 ---\n436  Автокодировщики Чтобы понять, почему автокодировщики полезны для обучения многообразий, поучительно сравнить их с другими подходами. Для характеристики многообразия обычно обучают представление точек данных на многообразии (или вблизи него). Для конкретного примера такое представление называют также его погружением. Как правило, оно описывается вектором более низкой размерности, чем у объемлю- щего пространства, подмножеством которого является многообразие. Некоторые алгоритмы (обсуждаемые ниже непараметрические алгоритмы обучения многообра-зий) непосредственно обучают погружение для каждого обучающего примера, тогда как другие обучают более общее отображение, иногда называемое кодировщиком, или функцией представления, которое переводит любую точку объемлющего прост-ранства (пространства входов) в ее погружение. Обучение многообразий по большей части включает в себя процедуры обучения без учителя, пытающиеся эти многообразия уловить. В большинстве ранних работ по обучению нелинейных многообразий акцент ставился на непараметрические мето- ды, основанные на графе ближайших соседей. В этом графе имеется одна вершина для каждого обучающего примера и ребра, соединяющие ближайших соседей. Эти методы (Schölkopf et al., 1998; Roweis and Saul, 2000; Tenenbaum et al., 2000; Brand, 2003; Belkin and Niyogi, 2003; Donoho and Grimes, 2003; Weinberger and Saul, 2004; Hinton and Roweis, 2003; van der Maaten and Hinton, 2008) связывают с каждой вер- шиной касательную плоскость, натянутую на направления изменения, определяе-мые векторами разностей между примером и его соседями, как показано на рис. 14.8. Глобальную систему координат можно затем получить с помощью оптимизации или путем решения системы линейных уравнений. На рис. 14.9 показано, как можно замо-стить многообразие большим числом локально линейных «блинов», напоминающих гауссианы, плоские в касательных направлениях. Фундаментальная трудность таких локальных непараметрических подходов к обуче нию многообразий описана в работе Bengio and Monperrus (2005): если мно- гообразие не слишком гладкое (имеет много пиков, впадин и скручиваний), то для покрытия всех вариаций может понадобиться очень много обучающих примеров, но шансов обобщения на ранее не предъявлявшиеся вариации все равно не будет. Действительно, эти методы способны обобщить форму многообразия только путем интерполяции соседних примеров. К сожалению, многообразия, встречающиеся в за- дачах ИИ, могут иметь очень сложную структуру, которую трудно уловить одной лишь локальной интерполяцией. Рассмотрим пример многообразия, полученного в результате параллельных переносов, на рис. 14.6. Если мы наблюдаем только одну координату входного вектора x i по мере переноса изображения, то будем видеть мак- симум или минимум этой координаты всякий раз, как в яркости изображения встре- чается пик или впадина. Иными словами, сложность паттернов яркости в исходном изображении определяет сложность многообразий, порождаемых его простыми пре-образованиями. Это наводит на мысль об использовании распределенных представ-лений и глубокого обучения для улавливания структуры многообразия. 14.7. Сжимающие автокодировщики Сжимающий автокодировщик (CAE) (Rifai et al., 2011a,b) вводит явный регуляризи- рующий член для кода h = f(x), поощряющий за небольшую величину производных f: (14.18)\n--- Страница 438 ---\nСжимающие автокодировщики  437 Рис. 14.8  Непараметрические процедуры обучения многообразий строят граф ближайших соседей, вершины которого представляют обучаю- щие примеры, а ориентированные ребра – связи с ближайшими соседями. Существуют различные процедуры, позволяющие получить касательную плоскость, ассоциированную с соседством в этом графе, а также систему координат, кторая ассоциирует каждый обучающий пример с положением вещественного вектора, или погружением. Такое представление обобща- ется на новые примеры с помощью интерполяции. Если число примеров достаточно велико для покрытия кривизны и скручивания многообразия, то такие методы работают хорошо. Изображения взяты из набора данных QMUL Multiview Face Dataset (Gong et al., 2000) Штраф Ω(h) равен квадрату нормы Фробениуса (сумма квадратов элементов) мат- рицы Якоби, состоящей из частных производных функции кодирования. Существует связь между шумоподавляющим и сжимающим автокодировщиками: в работе Alain and Bengio (2013) показано, что в пределе малого гауссова входного шума ошибка реконструкции шумоподавляющего автокодировщика эквивалентна сжимающему штрафу в функции реконструкции, которая отображает x в r = g(f(x)). Иными словами, шумоподавляющий автокодировщик понуждает функцию реконст-рукции сопротивляться малым, но конечным возмущениям входа, тогда как сжимаю-щий автокодировщик заставляет функцию выделения признаков сопротивляться бесконечно малым возмущениям входа. Когда сжимающий штраф на основе матрицы Якоби применяется для предобучения признаков f(x) с целью последующего исполь- зования в классификаторе, наилучшая верность классификации обычно получается, если применять штраф к f(x), а не к g(f(x)). Сжимающий штраф в f(x) также имеет тесные связи с сопоставлением рейтингов, которое обсуждалось в разделе 14.5.1. Термин сжимающий объясняется тем, как CAE деформирует пространство. По- скольку CAE обучен противиться возмущениям входа, то поощряется отображение окрестности входной точки в меньшую окрестность выходной точки. Это можно рас- сматривать как сжатие окрестности входной точки.\n--- Страница 439 ---\n438  Автокодировщики Рис. 14.9  Если касательные плоскости (см. рис. 14.6) в каждой точке известны, то из них можно образовать глобальную систему координат, или функцию плотности. Каждую локальную «плитку» можно рассматривать как локальную евклидову систему координат или как локально плоское нор-мальное распределение («блин») с очень малой дисперсией в направлени- ях, ортогональных блину, и очень большой в направлениях, определяющих систему координат блина. Смесь таких нормальных распределений дает оценку функции плотности, как в методе окна Парзена для многообразий (Vincent and Bengio, 2003), или его нелокальном варианте, основанном на нейронной сети (Bengio et al., 2006c) Уточним, что CAE является сжимающим только локально – все возмущения точки x обучающего набора отображаются в малую окрестность f(x). Глобально образы f(x) и f(x′) точек x и x′ могут отстоять друг от друга дальше, чем исходные точки. Вполне может случиться, что между многообразиями или вдали от них функция f будет не сжимающей, а, наоборот, расширяющей (см., например, что происходит в тривиаль- ном одномерном примере на рис. 14.7). Если штраф Ω(h) применяется к сигмоидным блокам, то для сжатия якобиана достаточно потребовать, чтобы эти блоки асимпто-тически приближались к 0 или 1. Тогда штраф поощряет CAE кодировать входные точки экстремальными значениями сигмоиды, что можно интерпретировать как дво-ичный код. Также гарантируется, что CAE будет рассредоточивать кодовые значения по большей части гиперкуба, покрываемого его сигмоидными скрытыми блоками. Мы можем рассматривать матрицу Якоби J в точке x как аппроксимацию нели- нейного кодировщика f(x) линейным оператором. Это позволяет формализовать слово «сжимающий». В теории линейных операторов говорят, что линейный опера- тор сжимающий, если норма Jx меньше или равна 1 для всех векторов x с единичной нормой. Иначе говоря, J сжимающий, если он стягивает единичную сферу. Можно считать, что CAE штрафует норму Фробениуса локальной линейной аппроксимации f(x) в каждой точке x обучающего набора, стремясь сделать все такие локальные ли- нейные операторы сжимающими.\n--- Страница 440 ---\nСжимающие автокодировщики  439 Как описано в разделе 14.6, регуляризированные автокодировщики обучают многообразия, балансируя под действием двух противоположно направленных сил. В случае CAE в роли таких сил выступают ошибка реконструкции и сжимающий штраф Ω(h). Одна лишь ошибка реконструкции поощряла бы CAE обучиться тож- дественной функции, а один лишь сжимающий штраф – обучиться признакам, по- стоянным относительно x. В результате компромисса между тем и другим получается автокодировщик, у которого производные ∂f(x)/∂x в основном очень малы. И лишь для немногих скрытых блоков, которые соответствуют небольшому числу направле-ний во входных данных, производные могут быть велики. Цель CAE – обучиться структуре многообразия данных. В направлениях x с боль- шими значениями Jx вектор h быстро изменяется, поэтому они, вероятно, являют- ся направлениями, аппроксимирующими касательные плоскости к многообразию. Эксперименты, описанные в работе Rifai et al. (2011a,b), показывают, что обучение CAE приводит к тому, что в большинстве своем сингулярные числа J по абсолют- ной величине меньше 1, т. е. являются сжимающими. Но некоторые сингулярные числа все же оказываются больше 1, поскольку штраф за ошибку реконструкции поощряет CAE кодировать направления с наибольшей локальной дисперсией. На- правления, соответствующие наибольшим сингулярным числам, интерпретиру-ются как касательные направления, обученные сжимающим автокодировщиком. В идеале они должны соответствовать реальной вариативности данных. Например, в случае применения к изображениям CAE должен обучиться касательным век- торам, которые показывают, как изменяется изображение, когда присутствующие в нем объекты постепенно меняют расположение, как на рис. 14.6. Визуализация экспериментально полученных сингулярных векторов, похоже, действительно со-ответствует осмысленным преобразованиям входного изображения, как видно по рис. 14.10. С критерием регуляризации CAE возникает одна практическая проблема: его вы- числение в случае автокодировщика с одним скрытым слоем обходится дешево, но становится гораздо дороже, когда слоев больше. В работе Rifai et al. (2011a) приме- нена следующая стратегия – последовательность однослойных автокодировщиков обуча ется так, чтобы каждый следующий обучался реконструировать скрытый слой предыдущего. Их композиция и образует глубокий автокодировщик. Поскольку каж- дый слой локально сжимающий, то и глубокий автокодировщик тоже будет сжимаю- щим. Результат получается не таким же, как при совместном обучении всей архитек-туры со штрафом на якобиан глубокой модели, но многие желательные качественные характеристики улавливаются. Еще одна практическая проблема состоит в том, что применение сжимающего штрафа может давать бесполезные результаты, если не задать какого-то масштаба декодера. Например, действие кодировщика может заключаться в умножении входа на небольшую константу ε, а действие декодера – в делении кода на ε. Когда ε стре- мится к 0, кодировщик устремляет сжимающий штраф Ω(h) к 0, так ничего и не узнав о распределении. А тем временем декодер демонстрирует идеальную реконструкцию. В работе Rifai et al. (2011a) для предотвращения такой ситуации веса f и g связывают- ся. И f, и g – стандартные слои нейронной сети, состоящие из аффинного преобразо-вания с последующей поэлементной нелинейностью, поэтому можно просто сделать матрицу весов g транспонированной к матрице весов f.\n--- Страница 441 ---\n440  Автокодировщики Входные данныеКасательные векторы Локальные PCA (без разделения между участками) Сжимающий автокодировщик Рис. 14.10  Касательные векторы к многообразию, оцененные локаль- ным методом главных компонент (PCA) и сжимающим автокодировщиком. Позиция на многообразии определяется входным изображением собаки, взятым из набора данных CIFAR-10. Для оценки касательных векторов ис- пользуются первые сингулярные векторы матрицы Якоби ∂h/∂x отображе- ния входа на код. Хотя и PCA, и CAE могут найти локальные касательные, CAE дает более точные оценки на ограниченном объеме обучающих дан- ных, поскольку в нем присутствует разделение параметров между разными позициями, совместно использующими некоторое подмножество активных скрытых блоков. Касательные направления, найденные CAE, обычно соот-ветствуют перемещающимся или изменяющимся частям объекта (скажем, голове или лапам). Изображение взято из работы Rifai et al. (2011c) с раз- решения авторов 14.8. Предсказательная разреженная декомпозиция Предсказательная разреженная декомпозиция (ПРД) (predictive sparse decom po- sition – PSD) – гибридная модель, в которой сочетаются разреженное кодирование и параметрические автокодировщики (Kavukcuoglu et al., 2008). Параметрический кодировщик обучается предсказывать результат итеративного вывода. ПРД приме- нялась к обучению признаков без учителя для распознавания объектов в изображе- ниях и видео (Kavukcuoglu et al., 2009, 2010; Jarrett et al., 2009; Farabet et al., 2011), а также к обработке звуковой информации (Henaff et al., 2011). Модель включает ко- дировщик f(x) и декодер g(h) – оба параметрические. В процессе обучения h контро- лируется алгоритмом оптимизации. Обучение заключается в минимизации ||x – g(h)||2 + λ|h|1 + γ||h – f(x)||2. (14.19) Как в случае разреженного кодирования, алгоритм обучения чередует минимиза- цию относительно h с минимизацией относительно параметров модели. Минимиза- ция относительно h производится быстро, потому что f(x) дает хорошее начальное значение h, а функция стоимости налагает на h ограничение – оставаться близко к f(x). Простым градиентным спуском можно получить разумные значения h всего за десять шагов. Процедура обучения в ПРД не сводится к обучению сначала модели разреженного кодирования, а затем обучению f(x) для предсказания значений признаков разрежен- ного кодирования. На самом деле эта процедура регуляризирует декодер, так чтобы использовались параметры, для которых f(x) может вывести хорошие значения кода.\n--- Страница 442 ---\nПрименения автокодировщиков  441 Предсказательная разреженная декомпозиция – пример обученного приближен- ного вывода. В разделе 19.5 мы вернемся к этой теме. Из материала, изложенного в главе 19, следует, что ПРД можно интерпретировать как обучение ориентированной вероятностной модели разреженного кодирования путем максимизации нижней гра- ницы логарифмического правдоподобия модели. В практических приложениях ПРД итеративная оптимизация используется толь- ко на этапе обучения. Параметрический кодировщик f применяется для вычисления обучен ных признаков после развертывания модели. Вычисление f обходится недо- рого, по сравнению с выводом h методом градиентного спуска. Поскольку f – диф- ференцируемая параметрическая функция, то модели ПРД можно объединить и ис- пользовать для инициализации глубокой сети, обучаемой по другому критерию. 14.9. Применения автокодировщиков Автокодировщики успешно применялись в задачах понижения размерности и ин- формационного поиска. Понижение размерности было одним из первых приложений обучения представлений и глубокого обучения, а также одним из ранних стимулов к изучению автокодировщиков. Например, в работе Hinton and Salakhutdinov (2006) был обучен стек ОМБ, а затем их веса использовались для инициализации глубокого автокодировщика с постепенно уменьшающимися скрытыми слоями, так что в по- следнем слое было всего 30 блоков. Получившийся код давал меньшую ошибку ре-конструкции, чем PCA, в 30 направлениях, а обученное представление оказалось про- ще качественно интерпретировать и связать с объясняющими категориями, которые проявлялись в виде четко разделенных кластеров. Представления низкой размерности могут повысить качество во многих задачах, в т. ч. классификации. Чем меньше пространство, тем меньше памяти занимает модель и тем быстрее производятся расчеты. Многие способы понижения размерности поме- щают семантически похожие примеры рядом, как замечено в работах Salakhutdinov and Hinton (2007b) и Torralba et al. (2008). Информация, сохраняемая при отображе- нии в пространство меньшей размерности, способствует лучшей обобщаемости. Особенно сильно выигрывает от понижения размерности информационный по- иск – задача об отыскании в базе данных записей, похожих на указанную в запросе. Дополнительный выигрыш связан с тем, что в некоторых видах пространств низкой размерности поиск может оказаться чрезвычайно эффективен. Точнее, если обучить алгоритм понижения размерности порождать двоичный код низкой размерности, то мы сможем поместить всю базу в хэш-таблицу, которая отображает двоичные кодо- вые векторы на полные записи. Тогда результатом информационного поиска будет множество всех записей базы данных с таким же двоичным кодом, как у запрошен- ной. Мы можем также очень эффективно искать чуть менее похожие данные, для чего нужно просто инвертировать отдельные биты в кодовом представлении запро- са. Такой подход к информационному поиску посредством понижения размерно- сти и бинаризации называется семантическим хэшированием (Salakhutdinov and Hinton, 2007b, 2009b), он успешно применялся к поиску как текстов (Salakhutdinov and Hinton, 2007b, 2009b), так и изображений (Torralba et al., 2008; Weiss et al., 2008; Krizhevsky and Hinton, 2011). Для порождения двоичных кодов семантического хэширования обычно исполь- зуется функция кодирования с сигмоидными блоками в последнем слое. Эти блоки\n--- Страница 443 ---\n442  Автокодировщики необходимо обучить так, чтобы они были асимптотически близки к 0 или к 1 для всех входных значений. Один из способов добиться этого – внести аддитивный шум перед сигмоидной нелинейностью во время обучения. Абсолютная величина шума должна возрастать со временем. Чтобы противостоять шуму и сохранить как можно больше информации, сеть должна увеличивать величину входов сигмоидной функции до на-ступления насыщения. Идея обучения хэш-функции исследовалась в нескольких направлениях, в т. ч. для обучения оптимизирующих потерю представлений, которые в большей мере ориен- тированы на поиск близких примеров в хэш-таблице (Norouzi and Fleet, 2011).",
      "debug": {
        "start_page": 423,
        "end_page": 443
      }
    },
    {
      "name": "Глава 15. Обучение представлений 443",
      "content": "--- Страница 444 --- (продолжение)\nГлава 15 Обучение представлений В этой главе мы сначала обсудим, что значит обучить представление и чем понятие представления может быть полезно при проектировании глубоких архитектур. Мы рассмотрим, как алгоритмы обучения разделяют статистическую силу между разны-ми задачами, в т. ч. поговорим об использовании обучения без учителя для реше- ния задач обучения с учителем. Разделяемые представления полезны для обработки нескольких модальностей, или доменов, а также для передачи полученных в ходе обуче ния знаний задачам, для которых примеров мало или нет вовсе, зато существует представление. Наконец, мы вернемся назад и порассуждаем о том, почему обучение представлений оказалось столь успешным, начав с теоретических достоинств рас- пределенных (Hinton et al., 1986) и глубоких представлений и закончив более общей идеей объясняющих предположений о процессе порождения данных и, в частности, об истинных причинах наблюдаемых данных. Многие задачи обработки информации могут оказаться очень простыми или очень трудными в зависимости от представления информации. Этот общий принцип дей- ствует и в повседневной жизни, и в информатике вообще, и в машинном обучении в частности. Например, любой человек без труда разделит 210 на 6 с помощью деле- ния в столбик. Но задача становится куда труднее, если числа записать в римской но- тации. Если предложить современному человеку разделить CCX на VI, то он, скорее всего, сначала преобразует римские цифры в арабскую позиционную нотацию, до- пускающую деление в столбик. Мы можем количественно оценить асимптотическое время выполнения различных операций при использовании подходящего и непод- ходящего представлений. Так, вставка числа в нужную позицию отсортированного списка занимает время O(n), если в качестве представления выбран связный список, и только O(log n), если выбрано красно-черное дерево. А чем одно представление лучше другого в контексте машинного обучения? Вооб- ще говоря, хорошим является представление, которое упрощает последующее обуче-ние. Выбор представления обычно зависит от задачи обучения. Сети прямого распространения, обучаемые с учителем, можно рассматривать как своего рода обучение представления. Точнее говоря, последний слой сети обычно является линейным классификатором, например softmax-регрессией. А вся осталь- ная сеть формирует для этого классификатора представление. Обучение с учителем естественно создает в каждом скрытом слое представление с такими свойствами, ко- торые делают классификацию проще (и чем ближе к верхнему слою, тем это вернее).\nГлава 15 Обучение представлений В этой главе мы сначала обсудим, что значит обучить представление и чем понятие представления может быть полезно при проектировании глубоких архитектур. Мы рассмотрим, как алгоритмы обучения разделяют статистическую силу между разны-ми задачами, в т. ч. поговорим об использовании обучения без учителя для реше- ния задач обучения с учителем. Разделяемые представления полезны для обработки нескольких модальностей, или доменов, а также для передачи полученных в ходе обуче ния знаний задачам, для которых примеров мало или нет вовсе, зато существует представление. Наконец, мы вернемся назад и порассуждаем о том, почему обучение представлений оказалось столь успешным, начав с теоретических достоинств рас- пределенных (Hinton et al., 1986) и глубоких представлений и закончив более общей идеей объясняющих предположений о процессе порождения данных и, в частности, об истинных причинах наблюдаемых данных. Многие задачи обработки информации могут оказаться очень простыми или очень трудными в зависимости от представления информации. Этот общий принцип дей- ствует и в повседневной жизни, и в информатике вообще, и в машинном обучении в частности. Например, любой человек без труда разделит 210 на 6 с помощью деле- ния в столбик. Но задача становится куда труднее, если числа записать в римской но- тации. Если предложить современному человеку разделить CCX на VI, то он, скорее всего, сначала преобразует римские цифры в арабскую позиционную нотацию, до- пускающую деление в столбик. Мы можем количественно оценить асимптотическое время выполнения различных операций при использовании подходящего и непод- ходящего представлений. Так, вставка числа в нужную позицию отсортированного списка занимает время O(n), если в качестве представления выбран связный список, и только O(log n), если выбрано красно-черное дерево. А чем одно представление лучше другого в контексте машинного обучения? Вооб- ще говоря, хорошим является представление, которое упрощает последующее обуче-ние. Выбор представления обычно зависит от задачи обучения. Сети прямого распространения, обучаемые с учителем, можно рассматривать как своего рода обучение представления. Точнее говоря, последний слой сети обычно является линейным классификатором, например softmax-регрессией. А вся осталь- ная сеть формирует для этого классификатора представление. Обучение с учителем естественно создает в каждом скрытом слое представление с такими свойствами, ко- торые делают классификацию проще (и чем ближе к верхнему слою, тем это вернее).\n--- Страница 445 ---\n444  Обучение представлений Например, классы, которые не были линейно разделимыми на входных признаках, могут стать таковыми в последнем скрытом слое. В принципе, последний слой мо- жет быть моделью любого вида, например классификатором по ближайшему соседу (Salakhutdinov and Hinton, 2007a). Признаки в предпоследнем слое должны обучить- ся различным свойствам в зависимости от типа последнего слоя. Обучение сетей прямого распространения с учителем не налагает явных условий на обученные промежуточные признаки. Другие алгоритмы обучения представлений нередко проектируются так, что форма представления задается явно. Предположим, к примеру, что мы хотим обучить представление, упрощающее оценку плотности. Легче поддаются моделированию распределения с большей степенью независимости, поэтому мы могли бы спроектировать целевую функцию, поощряющую независи-мость элементов вектора представления h. Как и у сетей с учителем, у алгоритмов глубокого обучения без учителя есть главная цель обучения, но в качестве побочного эффекта они обучаются некоторому представлению. Вне зависимости от способа по-лучения это представление можно использовать для решения другой задачи. Или же можно вместе обучить несколько моделей (одни с учителем, другие без), разделяю- щих общее внутреннее представление. В большинстве проблем обучения представле- ния приходится выбирать между сохранением как можно более полной информации о входе и приобретением полезных свойств (таких как независимость). Обучение представлений особенно интересно, потому что дает способ провести обуче ние без учителя и с частичным привлечением учителя. Часто у нас имеется очень много непомеченных обучающих данных и сравнительно мало помеченных. Обучение с учителем на помеченном подмножестве нередко приводит к сильному переобучению. Обучение с частичным привлечением учителя дает шанс решить эту проблему, поскольку производится и на непомеченных данных тоже. То есть мы мо- жем обучить хорошие представления непомеченных данных, а затем воспользоваться ими для решения задачи обучения с учителем. Люди и животные умеют учиться на очень небольшом числе помеченных приме- ров. Мы пока не знаем, как это получается. Объяснить высокую обучаемость челове-ка можно было бы разными причинами – например, мозг может пользоваться очень большими ансамблями классификаторов или техникой байесовского вывода. Попу-лярна гипотеза, согласно которой мозг способен задействовать механизмы обуче ния без учителя или с частичным привлечением учителя. Есть много способов с поль- зой употребить непомеченные данные. В этой главе мы сосредоточимся на гипотезе о том, что непомеченные данные можно использовать для обучения хорошего пред- ставления. 15.1. Жадное послойное предобучение без учителя Обучение без учителя сыграло важнейшую роль в воскрешении глубоких нейрон- ных сетей, позволив исследователям впервые обучить глубокую сеть с учителем, не требуя специализации архитектуры, например свертки или рекурсии. Мы называем эту процедуру предобучением без учителя, или, если быть точным, жадным послой- ным предобучением без учителя. Это канонический пример того, как представле- ние, обучен ное для одной задачи (обучение без учителя, пытающееся уловить форму входного распределения), иногда оказывается полезным для другой задачи (обуче-ние с учителем на том же входном домене).\n--- Страница 446 ---\nЖадное послойное предобучение без учителя  445 Жадное послойное предобучение без учителя опирается на алгоритм обучения од- нослойного представления, например: ОМБ, однослойный автокодировщик, модель разреженного кодирования или еще какая-то модель, обучающая латентные пред-ставления. Каждый слой предобучается без учителя, получая выход от предыдущего слоя и порождая в качестве выхода новое представление данных с предположительно более простым распределением (или более простыми связями с другими переменны- ми, скажем, категориями, которые нужно предсказать). Процедуры жадного послойного обучения без учителя давно уже используют- ся, чтобы обойти трудности совместного обучения слоев глубокой нейронной сети с учителем. Этот подход восходит еще к неокогнитрону (Fukushima, 1975). Возрож- дение глубокого обучения в 2006 году началось с открытия, что процедуру жадно- го обучения можно использовать для отыскания хороших начальных значений для процедуры совместного обучения всех слоев, причем так можно с успехом обучать даже полносвязные архитектуры (Hinton et al., 2006; Hinton and Salakhutdinov, 2006; Hinton, 2006; Bengio et al., 2007; Ranzato et al., 2007a). До этого открытия считалось практически возможным обучить только глубокие сверточные сети и сети, своей глу- биной обязанные рекурсии. Сейчас мы знаем, что для обучения полносвязной глубо-кой архитектуры необязательно использовать жадное послойное предобучение, но это был первый успешный подход. Жадное послойное предобучение называется жадным, потому что это жадный ал- горитм, т. е. он оптимизирует каждую часть решения независимо, а не совместно все части сразу. Оно называется послойным, потому что этими независимыми частями являются слои сети. Точнее говоря, в ходе жадного послойного обучения обрабатыва- ется по одному слою за раз – во время обучения k-го слоя все остальные фиксирова- ны. В частности, нижние слои (обучаемые первыми) уже не изменяются после пере- хода к верхним. В названии процедуры употребляется фраза «без учителя», потому что каждый слой обучается с помощью алгоритма обучения представления без учи- теля. А «предобучение» – так как предполагается, что это первый шаг, предшествую- щий применению алгоритма совместного обучения для настройки работы всех слоев вмес те. В контексте задачи обучения с учителем эту процедуру можно рассматривать как регуляризатор (в некоторых экспериментах предобучение уменьшает ошибку тес тирования, не уменьшая ошибку обучения) и как вид инициализации параметров. Обычно слово «предобучение» относится не только к самому этапу предобуче- ния, но и ко всему двухфазному протоколу, в котором фаза предобучения сочетается с фазой обучения с учителем. Фаза обучения с учителем может включать обучение простого классификатора на признаках, выявленных в фазе предобучения, или окон- чательную настройку с учителем всей сети, построенной в фазе предобучения. В боль- шинстве случаев общая схема обучения одна и та же и не зависит ни от конкретного алгоритма обучения без учителя, ни от типа модели. Хотя выбор алгоритма обучения без учителя, безусловно, влияет на детали, большинство приложений предобучения без учителя следует этому общему протоколу. Жадное послойное предобучение без учителя можно также использовать для ини- циализации других алгоритмов обучения без учителя, в частности глубоких автоко- дировщиков (Hinton and Salakhutdinov, 2006) и вероятностных моделей со многими слоями латентных переменных. К числу таких моделей относятся глубокие сети до- верия (Hinton et al., 2006) и глубокие машины Больцмана (Salakhutdinov and Hinton, 2009a). Эти глубокие порождающие модели описаны в главе 20.\n--- Страница 447 ---\n446  Обучение представлений Как было сказано в разделе 8.7.4, возможно также жадное послойное предобучение с учителем. В его основе лежит предположение о том, что обучить мелкую сеть про- ще, чем глубокую, похоже, подтверждающееся в некоторых контекстах (Erhan et al., 2010). 15.1.1. Когда и почему работает предобучение без учителя? Часто жадное послойное предобучение без учителя может дать значительное умень- шение ошибки тестирования в задачах классификации. Именно из-за этого наблюде- ния в 2006 году вновь пробудился интерес к глубоким нейронным сетям (Hinton et al., 2006; Bengio et al., 2007; Ranzato et al., 2007a). Но во многих других задачах предо-бучение без учителя либо не дает никакого выигрыша, либо даже наносит заметный вред. В работе Ma et al. (2015) изучалось влияние предобучения на модели предска- зания химической активности и обнаружилось, что в среднем предобучение наносит небольшой вред, но в ряде задач оказывается очень полезно. Поскольку предобуче- ние без учителя иногда полезно, но часто вредно, важно понимать, когда и почему оно работает, чтобы определить, применимо ли оно к конкретной задаче. Алгоритм 15.1. Протокол жадного послойного предобучения без учителяДано: алгоритм ℒ обучения признаков без учителя, который принимает обучаю- щий набор примеров и возвращает кодировщик f. Исходные данные представлены в виде матрицы X, по одной строке на пример, а f (1)(X) – выход первой фазы ко- дировщика. Если требуется окончательная настройка, то используется обучаемая модель 𝒯, которая принимает начальную функцию f, входные примеры X (а в слу- чае если для настройки применяется алгоритм обучения с учителем, – еще и ассо- циированные метки Y) и возвращает настроенную функцию. Число фаз равно m. f ← тождественная функцияX~ = X for k = 1, …, m do f (k) = ℒ(X~) f ← f(k) ∘ f X~ ← f(k)(X~) end forif окончательная-настройка then f ← 𝒯(f, X, Y) end ifReturn f С самого начала уточним, что это обсуждение в основном касается только жадного предобучения без учителя. Существуют другие, принципиально отличающиеся па-радигмы обучения с частичным привлечением учителя в применении к нейронным сетям, например виртуальное состязательное обучение, описанное в разделе 7.13. Можно также обучить автокодировщик или порождающую модель одновременно с моделью, обученной с учителем. К таким одношаговым подходам можно отнести дискриминантную ОМБ (Larochelle and Bengio, 2008) и ступенчатую сеть (ladder network) (Rasmus et al., 2015), в которой целевая функция явно представлена в виде суммы двух членов (в одном используются только метки, а в другом – только вход- ные данные).\n--- Страница 448 ---\nЖадное послойное предобучение без учителя  447 В предобучении без учителя объединены две идеи. Во-первых, идея о том, что вы- бор начальных значений параметров глубокой нейронной сети может оказывать суще- ственное регуляризирующее влияние на модель (и, в меньшей степени, способствовать улучшению оптимизации). Во-вторых, общая идея о том, что знание о распределении входных данных может помочь при обучении отображения входов на выходы. В обоих случаях имеют место сложные и не до конца понятные взаимодействия между несколькими частями алгоритма машинного обучения. Менее всего понятны причины регуляризирующего эффекта выбора начальных параметров. Когда предобучение только вошло в моду, оно интерпретировалось как инициализация модели таким образом, чтобы она сошлась к одному локальному ми- нимуму, а не к другому. В наши дни локальные минимумы уже не считаются серьезной проблемой для оптимизации нейронной сети. Мы знаем, что стандартные процедуры обучения нейронных сетей обычно не достигают критических точек. Остается воз-можность, что предобучение инициализирует модель так, что она окажется в точке, которая иначе была бы недоступна, – например, внутри области, окруженной участ- ками, в которых функция стоимости изменяется от примера к примеру так сильно, что мини-пакеты дают лишь очень зашумленную оценку градиента, или участками, где матрица Гессе так плохо обусловлена, что величина шага в методах градиентного спуска должна быть очень малой. Однако у нас нет уверенности в том, какие именно аспекты предобученных параметров сохраняются на этапе обучения с учителем. Это одна из причин, по которой в современных подходах обучение с учителем и без учи- теля обычно используется одновременно, а не в виде двух этапов, следующих друг за другом. Сложностей, связанных с тем, как в ходе оптимизации на этапе обучения с учителем сохраняется информация, полученная на этапе обучения без учителя, можно также избежать, попросту заморозив параметры экстракторов признаков и ис- пользуя обучение с учителем только для того, чтобы добавить классификатор поверх уже обученных признаков. Вторая идея – что алгоритм обучения может использовать информацию, найден- ную на этапе обучения без учителя, для повышения качества на этапе обучения с учи- телем, – более понятна. Дело в том, что признаки, полезные в задаче обучения без учителя, могут пригодиться и в задаче обучения с учителем. Например, порождаю- щая модель изображений автомобилей и мотоциклов должна знать о существовании колес и о том, сколько их должно быть. Если нам повезет, то представление колес будет таким, что у модели, обучаемой с учителем, будет к нему удобный доступ. Пока у этого предположения нет теоретического, математически строгого обоснования, по- этому не всегда можно предсказать, какие задачи больше всего выигрывают от такого предобучения без учителя. Многие аспекты этого подхода сильно зависят от того, какая конкретно модель используется. Например, если мы хотим добавить линей-ный классификатор поверх предобученных признаков, то признаки нужно выбирать так, чтобы классы были линейно разделимы. Подобные свойства часто возникают естественным образом, но это не обязательно. И это еще одна причина, по которой предпочтительно одновременное обучение с учителем и без учителя, – ограничения, налагаемые выходным слоем, естественно включаются с самого начала. Если рассматривать предобучение без учителя как обучение представления, то можно ожидать, что оно будет более эффективным, когда начальное представление плохое. Яркий пример – погружения слов. Слова, представленные унитарными век- торами, не очень информативны, потому что любые два различных унитарных век-\n--- Страница 449 ---\n448  Обучение представлений тора находятся на одинаковом расстоянии друг от друга (корень из 2 по норме L2). Обучен ные погружения слов естественным образом кодируют сходство между слова- ми по расстоянию между ними. Поэтому предобучение без учителя особенно полезно при обработке слов. Для обработки изображений оно не так полезно, быть может, потому что изображения и так уже принадлежат векторному пространству, в котором расстояние дает низкокачественный показатель сходства. Если рассматривать предобучение без учителя как регуляризатор, то можно ожи- дать, что польза от него будет особенно велика, когда число помеченных примеров очень мало. Поскольку источником информации для предобучения без учителя явля-ются непомеченные данные, можно также ожидать, что его качество будет тем лучше, чем больше непомеченных примеров. Преимущества обучения с частичным привле- чением учителя в ситуации, когда имеется много непомеченных примеров и мало по- меченных и предварительно выполняется обучение без учителя, особенно наглядно проявились в 2011 году, когда методика предобучения без учителя победила в двух международных соревнованиях по переносу обучения (Mesnil et al., 2011; Goodfellow et al., 2011), где число помеченных примеров в задаче варьировалось от нескольких штук до нескольких десятков на каждый класс. Подобные эффекты были также доку-ментированы по результатам экспериментов, проведенных в строго контролируемых условиях (Paine et al., 2014). Возможно, существуют и другие факторы. Например, предобучение без учителя, скорее всего, особенно полезно, когда обучаемая функция очень сложна. Предобуче-ние без учителя отличается от регуляризаторов типа снижения весов тем, что не поощряет обучаемую модель к поиску простой функции, а, скорее, побуждает ее выявлять функции-признаки, полезные для задачи обучения без учителя. Если ис-тинные функции сложны и обусловлены регулярностями входного распределения, то предобуче ние без учителя может оказаться более подходящим регуляризатором. Теперь оставим эти рассуждения в стороне и проанализируем некоторые ситуа- ции, когда предобучение без учителя действительно привело к успеху, и объясним, что известно о его причинах. Предобучение без учителя чаще всего применялось для улучшения классификаторов и представляет наибольший интерес с точки зрения уменьшения ошибки на тестовом наборе. Но предобучение без учителя может быть полезно и в задачах, не связанных с классификацией, оно может повысить качество оптимизации, а не просто выступать в роли регуляризатора. Например, оно может уменьшить ошибку реконструкции глубоких автокодировщиков одновременно на обучающих и на тестовых данных (Hinton and Salakhutdinov, 2006). В работе Erhan et al. (2010) описано много экспериментов для объяснения несколь- ких успешных случаев применения предобучения без учителя. Уменьшение обеих ошибок – обучения и тестирования – можно объяснить попаданием параметров в об- ласть, которая иначе была бы недоступна. Обучение нейронной сети не детерминиро-вано и сходится к новой функции при каждом прогоне. Обучение может остановиться в точке, где градиент оказался мал; в точке, где сработал критерий ранней остановки, предотвращающий переобучение, или в точке, где градиент велик, но трудно опреде- лить величину следующего шага из-за стохастичности или плохой обусловленности матрицы Гесса. Нейронные сети, предобученные без учителя, стабильно останавлива-ются в одной и той же области пространства функций, тогда как сети без предобуче- ния всякий раз останавливаются в новой области. На рис. 15.1 это явление показано наглядно. Область, в которой оказывается предобученная сеть, меньше, и это позво-\n--- Страница 450 ---\nЖадное послойное предобучение без учителя  449 ляет предположить, что предобучение уменьшает дисперсию процесса оценивания, что, в свою очередь, снижает риск серьезного переобучения. Иными словами, благо- даря предобучению без учителя начальные значения параметров сети оказываются в такой области, которую уже не могут покинуть, так что результаты обучения более стабильны и реже получаются совсем уж никуда не годными. С предобучением Без предобучения1500 1000 500 0 –500 –1000 –1500 –4000 1000 –3000 2000 –2000 3000 –1000 4000 0 Рис. 15.1  Визуализация посредством нелинейного проецирования траекторий обучения различных нейронных сетей в пространстве функций (не в пространстве параметров, чтобы избежать проблемы отображения нескольких векторов параметров на одну функцию) с различными случайно выбранными начальными значениями, с предобучением и без него. Каж- дой точки соответствует отдельная нейронная сеть в определенный мо- мент процесса обучения. Рисунок основан на рисунке из работы в Erhan et al. (2010). В пространстве функций координатой является бесконечномер- ный вектор, ассоциирующий каждый вход x с выходом y. В работе Erhan et al. (2010) производилось линейное проецирование на пространство высо- кой размерности путем конкатенации значений y для многих точек x с по- следующим нелинейным проецированием на плоскость методом Isomap (Тenenbaum et al., 2000). Цветом представлено время. Все сети инициа- лизированы вблизи центральной точки графика (соответствует области в пространстве функций, где порождаются приблизительно равномерные распределения класса y для большинства входов). С течением времени обучение сдвигает функцию наружу – туда, где предсказания увереннее. Обучение стабильно завершается в одной области, если предобучение применяется, и в другой – если не применяется. Метод Isomap стремится сохранить глобальные относительные расстояния (а стало быть, и объемы), поэтому небольшой размер области, соответствующей предобученным моделям, может указывать на то, что у оценки, полученной с применением предобучения, дисперсия меньше. В работе Erhan et al. (2010) даны также некоторые ответы на вопрос о том, ког- да предобучение работает лучше всего, – среднее и дисперсия ошибки тестирова- ния уменьшались тем сильнее, чем более глубокая сеть подвергалась предобучению. Следует помнить, что эти эксперименты проводились до того, как были изобретены и обрели популярность современные методы обучения очень глубоких сетей (блоки линейной ректификации, прореживание и пакетная нормировка), поэтому о совмест- ном эффекте предобучения без учителя и современных подходов известно меньше.\n--- Страница 451 ---\n450  Обучение представлений Важный вопрос – каким образом предобучение без учителя играет роль регуляри- затора? Одна из гипотез состоит в том, что предобучение поощряет алгоритм обуче- ния находить признаки, связанные с истинными причинами порождения наблюдае- мых данных. Эта важная идея, положенная в основу многих других алгоритмов, помимо предобучения без учителя, описана более подробно в разделе 15.3. По сравнению с другими видами обучения без учителя, у предобучения есть не- достаток – наличие двух раздельных фаз обучения. Многие стратегии регуляриза- ции позволяют пользователю управлять степенью регуляризации путем изменения единственного гиперпараметра. У предобучения без учителя нет очевидного способа управлять степенью регуляризации, возникающей вследствие этапа обучения без учителя. Вместо этого есть очень много гиперпараметров, эффект которых можно из-мерить по факту, но зачастую трудно предсказать заранее. Когда вместо предобуче ния мы производим обучение с учителем и без учителя одновременно, существует един- ственный гиперпараметр – обычно коэффициент, назначаемый стоимости обуче ния без учителя, – который определяет, насколько сильно целевая функция без учителя будет регуляризировать модель, обучаемую с учителем. Уменьшение этого коэффи- циента предсказуемо приводит к ослаблению регуляризации. В случае же предобуче- ния без учителя не существует способа гибко подстраивать степень регуляризации – либо для модели, обучаемой с учителем, берутся предобученные начальные значения параметров, либо нет. Еще один недостаток двух раздельных фаз обучения состоит в том, что у каждой фазы свои гиперпараметры. Качество второй фазы обычно невозможно предсказать на первой, поэтому между предложением гиперпараметров для первой фазы и их обновл ением по результатам второй фазы проходит длительное время. Теоретически самый правильный подход – использовать для выбора гиперпараметров фазы предо- бучения ошибку на контрольном наборе, как описано в работе Larochelle et al. (2009). Но на практике некоторые гиперпараметры, например число итераций предобуче-ния, удобнее задавать на этапе предобучения, применяя раннюю остановку к целевой функции без учителя, – это хоть и не идеально, но вычислительно обходится куда дешевле, чем использование целевой функции с учителем. В наши дни от предобучения без учителя отказались почти везде, кроме обработки естественных языков, где естественное представление слов в виде унитарных векто- ров не несет никакой информации о сходстве и при этом доступны очень большие неразмеченные наборы данных. Преимущество предобучения в этом случае – воз- можность обучить модель один раз на огромном неразмеченном наборе (скажем, кор-пусе текстов, содержащем миллиарды слов), найти хорошее представление (обычно слов, но, возможно, и предложений), а затем пользоваться этим представлением или дополнительно настроить его для решения задачи обучения с учителем, в которой обучаю щий набор содержит гораздо меньше примеров. Впервые этот подход был апробирован в работах Collobert and Weston (2008b), Тurian et al. (2010) и Collobert et al. (2011a) и до сих пор широко применяется. Глубокие сети, основанные на обучении с учителем и регуляризации путем проре- живания или пакетной нормировки, во многих задачах не уступают человеку, но только при наличии очень больших размеченных наборов данных. Те же методы превосходят предобучение без учителя на наборах данных среднего размера, например CIFAR-10 и MNISТ, насчитывающих примерно по 5000 помеченных примеров на каждый класс. На совсем небольших наборах, таких, например, как данные об альтернативном сплай-\n--- Страница 452 ---\nПеренос обучения и адаптация домена  451 синге, байесовские методы оказываются лучше тех, что основаны на предобуче нии без учителя (Srivastava, 2013). Потому-то популярность предобучения без учителя и со- шла на нет. Тем не менее оно остается важной вехой в истории глубокого обучения и продолжает оказывать влияние на современные подходы. Идея предобучения была обобщена на предобучение с учителем (см. раздел 8.7.4) и стала очень распростра- ненным подходом к переносу обучения. Предобучение с учителем в контексте пере- носа обучения популярно (Oquab et al., 2014; Y osinski et al., 2014) в сверточных сетях, предобучен ных на наборе данных ImageNet. Для таких обученных сетей публику- ются параметры так же, как в задачах обработки естественных языков публикуются предобучен ные векторы слов (Collobert et al., 2011a; Mikolov et al., 2013a). 15.2. Перенос обучения и адаптация домена Термины «перенос обучения» и «адаптация домена» относятся к ситуации, когда нечто обученное в одной ситуации (например, распределение P1) используется для улучшения обобщаемости в другой ситуации (например, при распределении P2). Это обобщение идеи из предыдущего раздела, в котором мы переносили представление с задачи обучения без учителя на задачу обучения с учителем. При переносе обучения обучаемая модель должна выполнить две или более задач, но предполагается, что многие факторы, объясняющие вариативность P1, относятся и к изменениям, которые предстоит уловить для обучения P2. Обычно это интерпре- тируется в контексте обучения с учителем, когда вход один и тот же, а природа меток может быть разной. Например, мы можем обучиться чему-то, относящемуся к одно- му набору зрительных категорий, скажем собакам и кошкам, а затем перейти к дру- гим категориям, скажем осам и муравьям. Если в первом случае данных (выбранных из распределения P1) намного больше, то, возможно, имеет смысл обучить представ- ления, полезные для быстрого обобщения при наличии лишь небольшой выборки из P2. У многих зрительных категорий есть общие особенности: низкоуровневые при- знаки – границы и формы, эффекты от применения геометрических преобразова- ний, изменений освещения и т. д. В общем случае перенос обучения, многозадачное обуче ние (раздел 7.7) и адаптацию домена можно реализовать путем обучения пред- ставления, если существуют признаки, полезные в различных ситуациях или зада- чах, которые соответствуют объясняющим факторам, встречающимся в нескольких ситуациях. Это показано на рис. 7.2, где нижние слои являются общими, а верхние зависят от задачи. Но иногда общей для разных задач является семантика выхода, а не входа. На- пример, система распознавания речи должна порождать правильные предложения в выходном слое, но предшествующие слои могут распознавать очень разные вари- анты одних и тех же фонем или субфонемных огласовок, зависящие от говорящего. В таких случаях разумнее разделять верхние слои нейронной сети и выполнять за- висящую от задачи предобработку, как показано на рис. 15.2. Что касается адаптации домена, то задача (оптимальное отображение входа на вы- ход) остается той же самой во всех ситуациях, но распределения входа несколько различаются. Например, рассмотрим задачу анализа эмоциональной окраски, ког-да нужно определить, выражает ли комментарий положительные или отрицатель-ные эмоции. Комментарии в вебе могут иметь разное происхождение. Проблема адаптации домена возникает, когда предиктор эмоциональной окраски, обученный\n--- Страница 453 ---\n452  Обучение представлений на отзывах пользователей книг, видео и музыки, затем используется для анализа комментариев, относящихся, скажем, к потребительской электронике: телевизорам и смартфонам. Можно представить себе, что существует базовая функция, которая выдает эмоциональную окраску – положительную, нейтральную или отрицательную, но, конечно, словарный состав и стиль могут зависеть от предметной области – до- мена, что затрудняет обобщение с одного домена на другой. Простое предобучение без учителя (с помощью шумоподавляющих автокодировщиков) показало прекрас- ные результаты при анализе эмоциональной окраски посредством адаптации домена (Glorot et al., 2011b). Переключатель Рис. 15.2  Пример архитектуры для многозадачного обучения и перено- са обучения, когда у переменной y общая для нескольких задач семантика, а вход x имеет разную семантику (и, возможно, даже разную размерность) для каждой задачи (или, к примеру, каждого пользователя): x(1), x(2), x(3). Нижние уровни (до переключателя) зависят от задачи, а верхние являют- ся общими. Нижние уровни обучаются транслировать зависящие от задачи входы в универсальный набор признаков Родственная задача – дрейф концепций (concept drift), ее можно рассматривать как форму переноса обучения в силу постепенных изменений распределения данных со временем. И дрейф концепций, и перенос обучения можно считать особыми ви- дами многозадачного обучения. Хотя термин «многозадачное обучение» чаще при- меняется к задачам обучения с учителем, более общее понятие переноса обучения применимо также к обучению без учителя и к обучению с подкреплением. Во всех этих случаях цель – воспользоваться знаниями, приобретенными в пер- вой конфигурации, для извлечения информации, которая может пригодиться для обучения или даже прямого предсказания во второй конфигурации. Ключевая идея обучения представлений состоит в том, что одно и то же представление может быть полезно в обеих конфигурациях. А это позволяет обогатить представление, пользуясь обучающими данными, доступными для обеих задач. Как уже упоминалось, глубокое обучение без учителя в применении к перено- су обуче ния снискало успех в нескольких соревнованиях по машинному обучению (Mesnil et al., 2011; Goodfellow et al., 2011). В первом из них предлагалась такая задача.\n--- Страница 454 ---\nПеренос обучения и адаптация домена  453 Каждому участнику сначала был выдан набор данных из первой конфигурации (вы- борка из распределения P1) с примерами, относящимися к какому-то множеству ка- тегорий. На нем участники должны были обучить хорошее пространство признаков (отображение исходных данных на некоторое представление) – такое, что примене- ние этого обученного преобразования к входным данным для переноса обучения (вы- борке из распределения P 2) позволяет на небольшом количестве помеченных приме- ров обучить линейный классификатор, который бы хорошо обобщался. Среди самых поразительных результатов, полученных в ходе этого соревнования, был тот факт, что по мере использования все более глубоких представлений (обученных без всяко-го присутствия учителя на данных, выбранных из первого распределения P 1) кривая обучения на новых категориях второй конфигурации P2 (перенос) оказывается гораз- до лучше. При наличии глубокого представления для достижения асимптотической обобщаемости на перенесенных задачах нужно меньше помеченных примеров. Два крайних случая переноса обучения – обучение на одном примере (one-shot learning) и обучение без примеров (zero-shot learning), или обучение без данных (zero-data learning). В первом случае для перенесенной задачи имеется только один помеченный пример, а во втором – ни одного. Обучение на одном примере (Fei-Fei et al., 2006) возможно, потому что представле- ние обучается четко различать классы на первом этапе. А на этапе переноса обучения достаточно одного помеченного примера, чтобы вывести метку многих возможных тестовых примеров, сконцентрированных вокруг одной точки в пространстве пред- ставления. Это работает, если факторы вариативности, соответствующие этим инва-риантам, четко отделены от других факторов в пространстве обученного представ- ления и если мы каким-то образом сумели установить, какие факторы существенны, а какие несущественны для различения объектов определенных категорий. Обучение без примеров можно проиллюстрировать на задаче, в которой обучае- мая модель должна прочитать большой корпус текстов, а затем решить некую задачу распознавания объектов. Распознать класс объекта можно, даже никогда не видя его изобра жения, если у класса имеется достаточно хорошее текстовое описание. Напри- мер, прочитав, что у кошки четыре ноги и заостренные уши, обучаемая система могла бы предположить, что на картинке изображена кошка, хотя никогда ее не видела. Обучение без данных (Larochelle et al., 2008) и обучение без примеров (Palatucci et al., 2009; Socher et al., 2013b) возможны только потому, что во время обучения ис-пользовалась дополнительная информация. Можно считать, что в обучении без дан- ных присутствуют три случайные величины: традиционный вход x, традиционный выход или метки y и дополнительная случайная величина, описывающая задачу, Т. Модель обучается оценивать условное распределение p(y | x, Т), где Т – описание задачи, которую должна решать модель. В нашем примере распознавания кошек по их текстовому описанию выходом является бинарная переменная y – такая, что y = 1 означает «да», а y = 0 – «нет». Тогда величина Т представляет вопросы, требующие ответа, например: «Присутствует ли в изображении кошка?» Если имеется обучаю- щий набор, содержащий непомеченные примеры объектов, принадлежащих тому же пространству, что и Т, то мы могли бы вывести смысл экземпляров Т, которых раньше не видели. В нашем случае важно наличие непомеченных текстовых данных, содер- жащих предложения вида «у кошки четыре ноги» или «у кошки заостренные уши». Для обучения без примеров требуется, чтобы Т была представлена в виде, допус- кающем какое-то обобщение. Например, Т не может быть просто унитарным кодом,\n--- Страница 455 ---\n454  Обучение представлений обозначающим категорию объекта. В работе Socher et al. (2013b) предложено альтер- нативное распределенное представление категорий объектов посредством обученно- го погружения слов, ассоциированных с каждой категорией. Похожий феномен встречается в машинном переводе (Klementiev et al., 2012; Mikolov et al., 2013b; Gouws et al., 2014): имеются слова на одном языке и связи меж- ду словами, которые можно обучить на корпусе одноязычных текстов; с другой сто- роны, имеются переведенные предложения, сопоставляющие слова на двух разных языках. И хотя у нас может не быть помеченных примеров перевода слова A на язы- ке X в слово B на языке Y, мы можем произвести обобщение и предложить перевод слова A, поскольку обучили распределенные представления слов языка X и языка Y, а затем создали связь (возможно, двустороннюю) между обоими пространствами по- средством обучающих примеров, состоящих из соответственных пар предложений на двух языках. Такой перенос будет особенно успешным, если все три составные части (два представления и связи между ними) обучались совместно. Обучение без примеров – частный случай переноса обучения. Тот же принцип объясняет, как можно провести многомодальное обучение, которое строит представ- ление в двух разных модальностях и связь (в общем случае совместное распределе- ние) между парами (x, y), где x – наблюдение в одной модальности, а y – в другой (Srivastava and Salakhutdinov, 2012). Путем обучения всех трех наборов параметров (из x в его представление, из y в его представление и связь между обоими представ- лениями) концепции из одного представления привязываются к концепциям из дру- гого, и наоборот, что позволяет осмысленно производить обобщение на новые пары. Эта процедура показана на рис. 15.3. 15.3. Разделение каузальных факторов с частичным привлечением учителя В связи с обучением представлений возникает важный вопрос: из-за чего одно пред- ставление лучше другого? Одна из гипотез заключается в том, что идеальным яв- ляется представление, в котором признаки соответствуют объясняющим причинам наблюдаемых данных, причем разные признаки или направления в пространстве признаков соответствуют разным причинам, так что представление отделяет причи- ны друг от друга. Следуя этой гипотезе, мы сначала ищем хорошее представление для p(x). Оно может также оказаться хорошим представлением для вычисления p(y | x), если y – одна из наиболее выраженных причин x. Эта идея вдохновляла немало исследований по глубокому обучению аж с 1990-х годов (Becker and Hinton, 1992; Hinton and Sejnowski, 1999). Другие соображения о том, когда обучение с частичным привлечением учителя может превосходить чистое обучение с учителем, см. в разде- ле 1.2 работы Chapelle et al. (2006). В других подходах к обучению представлений нас часто интересовало представ- ление, которое проще моделировать, – например, с разреженными или независимы- ми друг от друга элементами. Представление, которое четко разделяет каузальные факторы, необязательно просто моделируется. Однако у гипотезы, выдвигаемой в обоснование обучения с частичным привлечением учителя посредством представ- ления без учителя, есть вторая часть – для многих задач ИИ справедливо следующее утверж дение: если мы можем получить объяснение наблюдаемым фактам, то обычно\n--- Страница 456 ---\nРазделение каузальных факторов с частичным привлечением учителя  455 легко разделить отдельные атрибуты. Точнее говоря, если представление h представ- ляет многие объясняющие причины наблюдения x, а выходы y входят в число самых выраженных причин, то легко предсказать y по h. Пространство x Пространство y ytesthx = fx(x) hy = fy(y) xtestfyfx Пары (x, y) в обучающем наборе fx: функция кодирования для x fy: функция кодирования для y Связь между погруженными точками в пределах одного из доменовОтображения между пространствами представлений Рис. 15.3  Перенос обучения между доменами x и y делает возможным обучение без примеров. Помеченные или непомеченные примеры x позво- ляют обучить функцию представления fx и аналогично с примерами y и функ- цией fy. Каждое применение функций fx и fy обозначено направленной вверх стрелкой, а стиль стрелок показывает, какая функция применена. Расстоя- ние в пространстве hx определяет меру сходства между любой парой точек в пространстве x, возможно, более осмысленное, чем расстояние в самом пространстве x. Аналогично расстояние в пространстве hy определяет меру сходства между парами точек в пространстве y. Обе эти функции сходства обозначаются штриховыми двусторонними стрелками. Помеченные при- меры (штриховые горизонтальные линии) – это пары (x, y), которые позво- ляют обучить одностороннее или двустороннее отобра жение (сплошная двусторонняя стрелка) между представлениями fx(x) и fy(y) и скрепить эти представления друг с другом. После этого обучение без примеров произ- водится следующим образом. Мы можем ассоциировать изображение xtest со словом ytest, даже если нет ни одного изображения этого слова, просто потому что представления слова fy(ytest) и изображения fx(xtest) можно свя- зать между собой с помощью отображения между пространствами пред- ставлений. Это работает, потому что, хотя изображение и слово никогда не были объединены в пару, соответствующие им векторы признаков fx(xtest) и fy(ytest) сопоставлены друг с другом. Идея рисунка подсказана Грантом Хачатряном\n--- Страница 457 ---\n456  Обучение представлений Сначала поговорим о том, как обучение с частичным привлечением учителя мо- жет закончиться неудачей, поскольку обучение p(x) без учителя ничем не помогает обуче нию p(y | x). Рассмотрим, к примеру, случай, когда p(x) имеет равномерное рас- пределение и мы хотим обучить f(x) = 𝔼[y | x]. Очевидно, что наблюдение одного лишь обучающего набора значений x не дает никакой информации о p(y | x). Теперь рассмотрим простой пример ситуации, когда обучение с частичным при- влечением учителя может принести успех. Пусть распределение x – это смесь распре- делений, в которой каждой компоненте соответствует одно значение y, как показано на рис. 15.4. Если компоненты смеси четко разделены, то моделирование p(x) точно определит, где какая компонента, и тогда одного помеченного примера каждого клас- са будет достаточно для идеального обучения p(y | x). Но в более общем случае что может связывать p(y | x) и p(x)? y = 1 y = 2 y = 3p(x) x Рис. 15.4  Смесовая модель. Плотность распределения x является смесью трех компонент. Каждая компонента соответствует истинному объ- ясняющему фактору y. Поскольку компоненты смеси (например, классы естественных объектов в изображениях) статистически выражены, то прос- тое моделирование p(x) без учителя, при полном отсутствии помеченных примеров, уже выявляет фактор y Если величина y прочно ассоциируется с одним из каузальных факторов x, то p(x) и p(y | x) будут сильно связаны, и обучение без учителя представления, которое пы- тается разделить каузальные факторы вариативности, вероятно, будет полезно в ка- честве стратегии обучения с частичным привлечением учителя. Предположим, что y – один из каузальных факторов x, и пусть h – представление всех таких факторов. Можно считать, что истинный порождающий процесс струк- турирован в виде следующей ориентированной графической модели, в которой h – родитель x: p(h, x) = p(x | h)p(h). (15.1) Следовательно, безусловная вероятность данных равна p(x) = 𝔼hp(x | h). (15.2) Из этого простого наблюдения мы заключаем, что наилучшей моделью x (с точки зрения обобщаемости) будет такая, которая вскрывает приведенную выше «истин- ную» структуру, в которой h – латентная переменная, объясняющая наблюдаемую\n--- Страница 458 ---\nРазделение каузальных факторов с частичным привлечением учителя  457 вариативность x. Поэтому в ходе обучения «идеального» представления следует вы- явить все такие латентные факторы. Если y – один из них (или тесно связан с одним из них), то будет легко научиться предсказывать y по такому представлению. Мы также видим, что условное распределение y при условии x по правилу Байеса связано с компонентами в уравнении выше: (15.3) Таким образом, безусловная вероятность p(x) тесно связана с условной вероят- ностью p(y | x), и знание структуры первой должно помочь при обучении послед- ней. Следовательно, в ситуациях, отвечающих сформулированным предположениям, обуче ние с частичным привлечением учителя должно повысить качество. Важная исследовательская проблема связана с тем фактом, что у большинства наблю дений чрезвычайно много объясняющих причин. Допустим, что y = hi, но обучае мая без учителя модель не знает, какой именно фактор hi. Решение в лоб – обучить без учителя представление, которое улавливает все сколько-нибудь выра- женные порождающие факторы hj и отделяет их друг от друга, так что становится легко предсказать y по h вне зависимости от того, какой hi ассоциирован с y. На практике такое лобовое решение не годится, потому что невозможно выделить все или хотя бы большую часть факторов вариативности, оказывающих влияние на наблюдение. Например, если имеется визуальная сцена, то должно ли представление кодировать самые мельчайшие объекты на заднем плане? Хорошо известен психоло-гический феномен – человек не воспринимает изменений в окружающей среде, если они не относятся непосредственно к тому делу, которым он занимается, – см., напри- мер, Simons and Levin (1998). На переднем крае обучения с частичным привлечением учителя находится вопрос о том, что же кодировать в конкретной ситуации. В настоя- щее время есть две основные стратегии обращения с большим числом обусловливаю- щих причин: одновременно использовать сигналы обучения с учителем и без учите- ля, так чтобы модель выбрала наиболее релевантные факторы вариативности, или брать гораздо более объемные представления в режим чистого обучения без учителя. Постепенно вырисовывается стратегия обучения без учителя – изменить опреде- ление того, какие объясняющие причины являются самыми выраженными. Истори-чески автокодировщики и порождающие модели обучались оптимизировать фикси- рованный критерий, зачастую похожий на среднеквадратическую ошибку. Именно такие критерии и определяют, что считать выраженными причинами. Например, среднеквадратическая ошибка в применении к пикселям изображения неявно озна- чает, что объясняющая причина является выраженной, только если она сильно изме-няет яркость большого числа пикселей. Это может стать проблемой, если решаемая задача подразумевает взаимодействие с малыми объектами. На рис. 15.5 приведен пример робототехнической задачи, в которой автокодировщик не смог научиться ко- дировать мячик для игры в настольный теннис. Но тот же самый робот успешно взаи- модействует с более крупными объектами, например бейсбольными мячами, которые более выражены в терминах среднеквадратической ошибки. Возможны и другие определения выраженности. Например, если группа пикселей образует легко распознаваемый паттерн, пусть даже не экстремально яркий или тем-ный, то такой паттерн можно было бы счесть чрезвычайно выраженным. Чтобы реа-лизовать такое определение выраженности, можно воспользоваться недавно появив-\n--- Страница 459 ---\n458  Обучение представлений шимся подходом – порождающими состязательными сетями (generative adversarial network) (Goodfellow et al., 2014c). В нем порождающая модель обучается обманы- вать классификатор с прямым распространением, который пытается распознавать все примеры, порожденные моделью, как фальшивки, а все примеры из обучающего набора – как настоящие. В этой системе любой структурный паттерн, который сеть прямого распространения может распознать, является сильно выраженным. Исходные данные Реконструкция Рис. 15.5  Автокодировщик, обученный с применением среднеквадра- тической ошибки, не справился с робототехнической задачей реконструк- ции мячика для настольного тенниса. Само присутствие мячика и все его пространственные координаты – важные каузальные факторы, имеющие отношение к задаче робота. К сожалению, емкость автокодировщика огра- ничена, и обучение с использованием среднеквадратической ошибки не позволило идентифицировать мячик как достаточно выраженный фактор для кодирования. Изображения любезно предоставила Челси Финн Порождающая состязательная сеть более подробно описана в разделе 20.10.4. Сей- час же нам достаточно понимать, что сети обучаются тому, что считать выраженным. В работе Lotter et al. (2015) показано, что модели, обученные генерировать изобра- жения головы человека, часто не генерируют уши, если обучались с применением среднеквадратической ошибки, но благополучно делают это, если при обучении ис-пользовалась состязательная сеть. Поскольку уши не являются слишком яркими или темными на фоне окружающей кожи, то они не считаются выраженным фактором относительно среднеквадратической ошибки в качестве функции потерь, но уши имеют характерную форму и находятся в одном и том же месте, поэтому сеть пря- мого распространения можно легко обучить их распознаванию, а значит, в модели на основе порождающей состязательной сети они будут ярко выраженными факторами. Примеры изображений см. на рис. 15.6. Порождающие состязательные – лишь один шаг на пути к определению того, какие факторы следует представлять. Мы ожидаем, что будущие исследователи найдут более удачные способы определения того, какие факторы представлять, и разработают механизмы представления различных факто- ров, зависящие от задачи. В работе Schölkopf et al. (2012) отмечено, что преимущество обучения каузальных факторов состоит в том, что если для истинного порождающего процесса x – след- ствие, а y – причина, то моделирование p(x | y) устойчиво относительно изменения\n--- Страница 460 ---\nРаспределенное представление  459 p(y). Если бы мы изменили причинно-следственную связь на противоположную, то это уже было бы неверно, потому что согласно правилу Байеса p(x | y) была бы чувствительна к изменениям p(y). Очень часто, когда мы рассматриваем изменения в распределении из-за различных доменов, нестационарности во времени или измене- ний в характере задачи, каузальные механизмы остаются инвариантными («законы Вселенной постоянны»), тогда как маргинальное распределение причин вариатив-ности может изменяться. Поэтому лучшей обобщаемости и устойчивости к разного рода изменениям можно ожидать, когда обученная порождающая модель стремится выявить каузальные факторы h и p(x | h). Истинная картинаСостязательное обучениеСреднеквадратическая ошибка Рис. 15.6  Предсказательные порождающие сети – пример, демонстри- рующий, как важно обучиться тому, какие признаки являются выраженны-ми. В данном случае порождающая сеть обучена предсказывать внешний вид трехмерной модели головы человека при заданном угле обзора. (Сле-ва) Истинная картина. Это то изображение, которое должна выдать сеть. (В центре) Изображение, порожденное сетью, обученной с применением одной лишь среднеквадратической ошибки. Поскольку уши не слишком выделяются по яркости на фоне соседних участков кожи, модель не соч-ла эти признаки достаточно выраженными для включения в представле- ние. (Справа) Изображение, порожденное моделью, которая была обучена с применением комбинации среднеквадратической ошибки и состязатель- ной потери. При такой функции стоимости уши – достаточно выраженный признак, потому что образуют предсказуемый паттерн. Выявление в про- цессе обучения тех объясняющих причин, которые достаточно важны и ре- левантны модели, – важное направление современных исследований. Ри- сунки взяты из работы Lotter et al. (2015) 15.4. Распределенное представление Распределенные представления концепций, т. е. представления, составленные из не- скольких элементов, которые можно задавать независимо друг от друга, – один из самых важных инструментов обучения представлений. Связано это с тем, что рас- пределенное представление дает возможность использовать n признаков с k значе- ниями для описания kn различных концепций. Как мы уже не раз видели в этой книге, и в нейронных сетях с несколькими скрытыми блоками, и в вероятностных моделях с несколькими латентными переменными используется стратегия распределенных представлений. Теперь добавим еще одно наблюдение. В основе многих алгоритмов\n--- Страница 461 ---\n460  Обучение представлений глубокого обучения лежит предположение, что скрытые блоки можно обучить пред- ставлениям каузальных факторов, объясняющих данные, как описано в разделе 15.3. При таком подходе распределенные представления возникают естественно, потому что каждому направлению в пространстве представления можно поставить в соот- ветствие значение отдельной обусловливающей конфигурационной переменной. Примером распределенного представления является вектор n бинарных призна- ков, принимающий 2 n значений, каждому из которых может соответствовать отдель- ная область пространства входов, как показано на рис. 15.7. Это можно сравнить с символическим представлением, в котором вход ассоциирован с одним символом или категорией. Если словарь содержит n символов, то можно представить себе n де- текторов признаков, каждый из которых определяет присутствие ассоциированной категории. В этом случае возможно только n различных конфигураций простран- ства представления, вырезающих n областей в пространстве входов, как показано на рис. 15.8. Такое символическое представление называется унитарным, поскольку описывается бинарным вектором, в котором единичным может быть только один из n бит. Символическое представление – частный случай более широкого класса не- распределенных представлений, которые могут состоять из многих элементов, но не допускают осмысленного контроля над каждым из них. Ниже приведено несколько примеров алгоритмов обучения, основанных на нерас- пределенных представлениях. Методы кластеризации, включая алгоритм k средних: каждая входная точка относится ровно к одному кластеру. Алгоритмы k ближайших соседей: с заданным входом ассоциируется один или несколько примеров-прототипов, или шаблонов. Если k > 1, то каждый вход описывается несколькими значениями, но ими нельзя управлять независимо, поэтому по-настоящему распределенным такое представление назвать нельзя. Решающие деревья: для каждого входа активируется только один листовый узел (и все узлы на пути к нему от корня). Гауссовы смеси и коллективы экспертов: шаблоны (центры кластеров), или эксперты теперь ассоциируются со степенью активации. Как и в случае алго- ритма k ближайших соседей, каждый вход представляется несколькими значе- ниями, но управлять ими по отдельности невозможно. Ядерные методы с гауссовым (или другим локальным) ядром: хотя степень активации каждого «опорного вектора», или примера-шаблона теперь непре-рывна, возникают те же проблемы, что с гауссовыми смесями. Модели языка или перевода, основанные на n-граммах: множество контекстов (последовательностей символов) разбивается в соответствии со структурой суффиксного дерева. Листовый узел может соответствовать, например, кон-тексту, в котором два последних слова равны w 1 и w2. Для каждого листового узла вычисляется своя оценка параметров (при этом возможно некоторое раз-деление параметров). Для некоторых из описанных нераспределенных алгоритмов выход для каждой части не постоянный, а является интерполяцией выходов соседних областей. Связь между числом параметров (или примеров) и числом определяемых ими областей остается линейной.\n--- Страница 462 ---\nРаспределенное представление  461 Рис. 15.7  Как алгоритм, основанный на распределенном представле- нии, разбивает пространство входов на области. В данном случае имеются три бинарных признака h1, h2 и h3. Каждый признак определен посредством бинаризации выхода обученного линейного преобразования и разбивает ℝ2 на две полуплоскости. Обозначим hi+ множество входных точек, для ко- торых hi = 1, а hi– – множество точек, для которых hi = 0. На рисунке каждая прямая представляет решающую границу для одного hi, а соответствую- щая стрелка направлена в сторону hi+ от границы. Представление в целом принимает уникальное значение в каждой области, на которые разбивают плоскость три полуплоскости. Например, значение представления [1, 1, 1]⏉ соответствует области h1+ ∩ h2+ ∩ h3+. Сравните это с нераспределенными представлениями на рис. 15.8. В общем случае d-мерного входа распре- деленное представление разбивает ℝd на области пересечения полупрост- ранств, а не полуплоскостей. Распределенное представление с n при- знаками назначает уникальные коды O(nd) различным областям, тогда как алгоритм ближайших соседей с n примерами – только n областям. Поэто- му распределенное представление способно различить экспоненциально больше областей, чем нераспределенное. Следует иметь в виду, что не все значения h практически реализуемы (в данном примере нет значения h = 0) и что линейный классификатор поверх распределенного представления не может назначить различные классы всем соседним областям; даже у глу- бокой сети с линейными порогами VC-размерность имеет порядок только O(w log w), где w – количество весов (Sontag, 1998). Комбинация мощно- го слоя представления со слабым слоем классификации может оказаться хорошим регуляризатором; классификатору, пытающемуся обучиться раз-личению концепций «человек» и «не человек», не нужно назначать разные классы входам, представленным как «женщина в очках» и «мужчина без очков». Благодаря этому ограничению на емкость каждый классификатор фокусируется на небольшом числе h i, а h обучается представлять классы линейно разделимым способом\n--- Страница 463 ---\n462  Обучение представлений Рис. 15.8  Как алгоритм ближайшего соседа разбивает пространство входов на различные области. Этот пример алгоритма обучения, основан- ного на нераспределенном представлении. У нераспределенных алгорит- мов может быть разная геометрия, но все они обычно разбивают прост-ранство входов на несколько областей, в каждой из которых свой набор параметров. Преимущество нераспределенного подхода состоит в том, что при наличии достаточного числа параметров можно аппроксимировать обучающий набор, не решая трудных уравнений оптимизации, посколь-ку можно независимо выбирать различные выходы для каждой области. Недос таток же в том, что такие нераспределенные модели обобщаются только локально, исходя из априорного предположения о гладкости, по- этому трудно обучить сложную функцию, для которой число пиков и впадин превышает располагаемое число примеров. Сравните с распределенным представлением на рис. 15.7 С различием между распределенным и символическим представлениями связана еще одна важная идея: возможность обобщения проистекает из разделения атрибу- тов между разными концепциями. Как чистые символы слова « кошка » и «собака » так же далеки друг от друга, как два любых других символа. Но если ассоциировать их с осмысленным распределенным представлением, то многое из того, что можно ска- зать о кошках, обобщается на собак – и наоборот. Например, в распределенном пред- ставлении могут быть атрибуты « имеет_мех » и «число_ног », и их значения одинаковы для погружений слов « кошка » и «собака ». Нейронные языковые модели, работающие с распределенными представлениями слов, обобщаются гораздо лучше моделей, ра- ботающих напрямую с унитарными представлениями слов (см. раздел 2.4). Распреде- ленные представления индуцируют полезное метрическое пространство, в котором расстояние между семантическими близкими концепциями (или входами) мало, – этим свойством чисто символические представления не обладают. Когда и почему использование распределенного представления в качестве части алгоритма обучения может дать статистическое преимущество? Когда сложную на первый взгляд структуру можно компактно представить с помощью небольшого чис- ла параметров. Некоторые традиционные нераспределенные алгоритмы обучения обобщаются только в предположении гладкости, согласно которому если u ≈ v, то це- левая функция f, которую предстоит обучить, такова, что f(u) ≈ f(v). Есть много спо- собов формализовать это предположение, но конечный результат всегда один: если имеется пример (x, y), для которого известно, что f(x) ≈ y, то мы выбираем оценку\n--- Страница 464 ---\nРаспределенное представление  463 fˆ, которая приблизительно удовлетворяет этим ограничениям и при этом как можно меньше изменяется при переходе к близкому входу x + ε. Очевидно, что это предпо- ложение очень полезно, но оно подвержено проклятию размерности: чтобы обучить целевую функцию, которая многократно возрастает и убывает во многих областях1, число примеров должно быть никак не меньше числа различимых областей. Можно считать каждую такую область категорией или символом: если у каждого символа (или области) имеется отдельная степень свободы, то мы можем обучить произволь-ный декодер, отображающий символ в значение. Однако такой декодер не обобщает- ся на новые символы для новых областей. Если нам повезет, то у целевой функции может оказаться еще какая-то регуляр- ность, помимо гладкости. Например, сверточная сеть с max-пулингом способна распознать объект вне зависимости от его положения в изображении, пусть даже параллельный перенос в пространстве не соответствует гладкому преобразованию пространства входов. Рассмотрим частный случай алгоритма обучения распределенного представления, который извлекает бинарные признаки посредством бинаризации линейных функ-ций входа. Каждый бинарный признак в таком представлении разбивает ℝ d на два полупространства, как показано на рис. 15.7. Экспоненциально большое число об-ластей, высекаемых n полупространствами, определяет, сколько областей способно различить такое распределенное представление. Сколько же именно областей гене-рируется конфигурацией n гиперплоскостей в ℝ d? Применяя общий результат о пере- сечении гиперплоскостей (Zaslavsky, 1975), можно показать (Pascanu et al., 2014b), что число областей, различимых таким представлением бинарных признаков, равно (15.4) Таким образом, мы видим, что число областей экспоненциально зависит от размера входа и полиномиально от числа скрытых блоков. Тем самым мы получаем геометрическое объяснение обобщаемости распределен- ного представления: имея O(nd) параметров (n линейных пороговых признаков в ℝd), мы можем представить O(nd) различных областей в пространстве входов. Если бы мы не делали никаких предположений о данных, использовали представление с одним уникальным символом для каждой области и отдельные параметры для каждого сим- вола для распознавания соответствующей ему области ℝd, то для задания O(nd) обла- стей потребовалось бы O(nd) примеров. Вообще, аргументацию в пользу распределен- ного представления можно обобщить на случай, когда вместо линейных пороговых блоков используются экстракторы нелинейных, возможно, непрерывных признаков для каждого атрибута распределенного представления. В этом случае аргументация сводится к тому, что если параметрическое преобразование с k параметрами может обучиться распознавать r областей в пространстве входов, где k ≪ r, и если такое пред- 1 Теоретически может потребоваться обучить функцию, поведение которой различается в экспоненциально большом числе областей: в d-мерном пространстве, где нужно различать, по крайней мере, два значения по каждому измерению, нам может понадобиться функция f, которая принимает разные значения в 2 d областях, для ее обучения необходимо O(2d) при- меров.\n--- Страница 465 ---\n464  Обучение представлений ставление оказалось полезно для интересующей нас задачи, то, возможно, мы могли бы добиться гораздо лучшей обобщаемости по сравнению с нераспределенным пред- ставлением, для которого нужно было бы иметь O(r) примеров, чтобы получить те же признаки и ассоциированное с ними разбиение пространства входов на r областей. Коль скоро для представления модели требуется меньше примеров, то и подстраи- ваться придется под меньшее число параметров, а значит, для хорошей обобщаемости понадобится гораздо меньше примеров. Дополнительный аргумент, объясняющий хорошую обобщаемость моделей на ос- нове распределенных представлений, состоит в том, что их емкость остается огра- ниченной, несмотря на способность кодировать так много различных областей. На-пример, VC-размерность нейронной сети линейных пороговых блоков равна всего O(w log w), где w – количество весов (Sontag, 1998). Это ограничение возникает, по- тому что хоть мы и можем назначить очень много уникальных кодов пространству представления, но мы не можем ни использовать абсолютно все пространство кодов, ни обучить произвольные функции, отображающие пространство представления h на выходы y с применением линейного классификатора. Поэтому использование распределенного представления в сочетании с линейным классификатором выра- жает априорное предположение о том, что подлежащие распознаванию классы ли- нейно разделимы как функция каузальных факторов, запомненных в h. Обычно мы хотим обучить категории, например множество всех изображений зеленых объектов или всех изображений автомобилей, но не категории, требующие нелинейной XOR-логики. Например, нам, как правило, не требуется разбивать данные на класс красных легковых автомобилей плюс зеленых грузовиков и класс зеленых легковых автомо- билей плюс красных грузовиков. Обсуждавшиеся выше идеи были довольно абстрактными, но их можно проверить экспериментально. В работе Zhou et al. (2015) показано, что скрытые блоки глубо- кой сверточной сети, обученной на эталонных наборах данных ImageNet и Places, обучаются признакам, которые часто можно интерпретировать как метки, которые присвоил бы человек. Конечно, на практике не всегда бывает так, что для признаков, которым обучились скрытые блоки, в естественном языке имеется простое название, но интересно наблюдать, как они вырисовываются ближе к верхним уровням лучших глубоких сетей, применяемых в компьютерном зрении. У таких признаков есть одна общая черта: можно представить себе, что каждому из них можно обучиться, не видя всех конфигураций остальных. В работе Radford et al. (2015) показано, что порождаю- щая модель может обучить представление изображений лица, так что различные на-правления в пространстве представления будут улавливать разные факторы вариа- тивности. На рис. 15.9 показано, что одно направление в пространстве представления соответствует полу человека, а другое – наличию очков. Эти признаки были выявле- ны автоматически, а не заданы заранее. Классификаторам в скрытых блоках не нуж- ны метки: метод градиентного спуска для заданной целевой функции естественным образом обучает сеть семантически значимым признакам, если такие признаки нуж-ны в задаче. Мы можем обучить сеть различию между мужчиной и женщиной или наличию или отсутствию очков, не пытаясь охарактеризовать все конфигурации n – 1 прочих признаков с помощью примеров, покрывающих все комбинации их значений. Такая форма статистической разделимости и есть то, что открывает возможность обобщения на новые конфигурации признаков человека, которые не предъявлялись во время обучения.\n--- Страница 466 ---\nЭкспоненциальный выигрыш от глубины  465 Рис. 15.9  Порождающая модель обучилась распределенному пред- ставлению, которое разделяет концепции пола и ношения очков. Если на- чать с представления концепции мужчины в очках, затем вычесть вектор, представляющий концепцию мужчины без очков, и, наконец, прибавить вектор, представляющий концепцию женщины без очков, то мы получим вектор, представляющий концепцию женщины в очках. Порождающая мо- дель корректно декодирует все эти представляющие векторы в изображе- ния, которые можно распознать как члены правильного класса. Изображе-ния взяты из работы Radford et al. (2015) с разрешения авторов 15.5. Экспоненциальный выигрыш от глубины В разделе 6.4.1 мы видели, что многослойные перцептроны являются универсальны- ми аппроксиматорами и что некоторые функции можно представить экспоненциаль- но меньшими глубокими сетями, сравнимыми с мелкими сетями. Такое уменьшение размера модели ведет к улучшению статистической эффективности. В этом разделе мы опишем обобщение подобных результатов на другие виды моделей с распределен- ными скрытыми представлениями. В разделе 15.4 был приведен пример порождающей модели, которая обучилась факторам, объясняющим изображения лиц: пол человека и ношение очков. Эта по- рождающая модель была основана на глубокой нейронной сети. Было бы странно ожидать, что мелкая сеть, например линейная, сможет обучиться сложной связи между абстрактными объясняющими факторами и пикселями изображения. В этой и других задачах ИИ факторы, которые выбираются почти независимо друг от друга, скорее всего, будут очень высокого уровня и связаны с входными данными нелиней- но. Мы утверждаем, что для этого необходимы глубокие распределенные представле- ния, в которых высокоуровневые признаки (рассматриваемые как функции входа) или факторы (рассматриваемые как порождающие причины) получаются в резуль- тате композиции большого числа нелинейностей. Для многих ситуаций было доказано, что организация вычислений посредством композиции многих нелинейностей и иерархии повторно используемых признаков может дать экспоненциальный прирост статистической эффективности помимо экс-поненциального же прироста за счет использования распределенного представления. Можно показать, что многие виды сетей (в т. ч. с насыщающими нелинейностями, бу- левыми вентилями, суммами-произведениями или радиально-базисными блоками) с одним скрытым слоем являются универсальными аппроксиматорами. Такое семей-\n--- Страница 467 ---\n466  Обучение представлений ство моделей может аппроксимировать широкий класс функций (включающий все непрерывные функции) с произвольной точностью. Однако необходимое для этого число скрытых блоков может быть очень велико. Есть теоретические результаты о выразительной мощности глубоких архитектур, согласно которым существуют се- мейства функций, допускающих эффективное представление архитектурой глубины k, но для этого требуется экспоненциально большое число скрытых блоков (относи-тельно размера входа) с недостаточной глубиной (2 или k – 1). В разделе 6.4.1 мы видели, что детерминированные сети прямого распространения являются универсальными аппроксиматорами функций. Многие структурные веро-ятностные модели с одним скрытым слоем, в т. ч. ограниченные машины Больцмана и глубокие сети доверия, являются универсальными аппроксиматорами распределе- ний вероятности (Le Roux and Bengio, 2008, 2010; Montufar and Ay, 2011; Montufar, 2014; Krause et al., 2013). В разделе 6.4.1 мы видели, что достаточно глубокая сеть прямого распростране- ния может давать экспоненциальный выигрыш по сравнению со слишком мелкой сетью. Подобные результаты можно получить и для других моделей, например веро- ятностных. Одна из таких вероятностных моделей – сеть сумм и произведений (sum- product network – SPN) (Poon and Domingos, 2011). В этих моделях используются полино миальные цепочки для вычисления распределения вероятности множества случайных величин. В работе Delalleau and Bengio (2011) показано, что существуют распределения вероятности, для которых требуется некоторая минимальная глуби-на SPN, чтобы избежать экспоненциально большой модели. В более поздней работе Martens and Medabalimi (2014) показано, что существуют значительные различия между любыми двумя конечными значениями глубины SPN и что некоторые огра- ничения, которые вводят для того, чтобы с SPN можно было практически работать, могут ограничить их репрезентативную способность. Интересны также теоретические результаты по выразительной мощности глубо- ких контуров, связанных со сверточными сетями, которые демонстрируют экспо-ненциальный выигрыш глубокого контура, даже когда мелкий контур разрешено ис-пользовать только для аппроксимации функции, вычисленной глубоким контуром (Cohen et al., 2015). Для сравнения отметим, что в предыдущей теоретической работе рассматривался только случай, когда мелкий контур обязан точно реплицировать конкретные функции. 15.6. Ключ к выявлению истинных причин В заключение этой главы вернемся к одному из исходных вопросов: благодаря чему одно представление оказывается лучше другого? В разделе 15.3 мы дали один ответ: идеальным является представление, которое разделяет каузальные факторы вариатив-ности данных, особенно те, что напрямую относятся к нашему приложению. Большин- ство стратегий обучения представлений основано на введении ключей, которые по-могают процедуре обучения находить факторы вариативности. Ключи могут помочь обучаемому отделить эти наблюдаемые факторы от остальных. В обучении с учите- лем имеется очень сильный ключ: метка y, сопровождающая каждый вход x; обычно она непосредственно задает значение, по меньшей мере, одного фактора вариативно-сти. В более общем случае, чтобы воспользоваться большим объемом непомеченных данных, процедура обучения представления пользуется другими, не столь прямыми подсказками, касающимися каузальных факторов. Эти подсказки могут иметь вид\n--- Страница 468 ---\nКлюч к выявлению истинных причин  467 априорных предположений, вводимых проектировщиками алгоритма, для того чтобы направить обучаемого в нужную сторону. Такие результаты, как теорема об отсутствии бесплатных завтраков, показывают, что для достижения хорошей обобщае мости не- обходима какая-то стратегия регуляризации. Конечно, найти превосходную во всех отношениях стратегию регуляризации невозможно, но одна из целей глубокого обуче-ния – отыскать набор достаточно общих стратегий, применимых к широкому спектру задач ИИ типа тех, с которыми легко справляются люди и животные. Ниже приведен список этих общих стратегий регуляризации. Конечно, он не исчер- пывающий, но содержит конкретные примеры того, как алгоритм обучения можно на-править на выявление признаков, соответствующих каузальным факторам. Этот список приведен в разделе 3.1 работы Bengio et al. (2013d) и частично воспроизводится здесь. Гладкость. Это предположение о том, что f(x + εd) ≈ f(x) для единичного век- тора d и малого ε. Благодаря ему обучаемая модель может обобщаться на точки в пространстве входов, близкие к обучающим примерам. Эта идея эксплуати- руется во многих алгоритмах машинного обучения, но ее недостаточно для преодоления проклятия размерности. Линейность. Во многих алгоритмах машинного обучения предполагается, что связи между некоторыми переменными линейны. Это позволяет алгоритму да-вать предсказания даже в областях, очень далеких от наблюдаемых данных, но иногда предсказания получаются излишне экстремальными. В большинстве простых алгоритмов, не предполагающих гладкости, делается предположение о линейности. В действительности это разные предположения – линейные функции с большими весами, применяемые в пространствах высокой размер- ности, могут быть не слишком гладкими. Дальнейшее обсуждение ограниче-ний предположения о линейности см. в работе Goodfellow et al. (2014b). Несколько объясняющих факторов. В основе многих алгоритмов обучения пред- ставлений лежит предположение о множественности факторов, объясняю щих данные, и о том, что большинство задач легко решается, если известно состоя- ние каждого фактора. В разделе 15.3 описано, как такой взгляд на вещи обосно- вывает обучение с частичным привлечением учителя посредством обучения представлений. Чтобы обучиться структуре p(x), нужно обучиться некоторым признакам, полезным для моделирования p(y | x), потому что то и другое за- висит от одних и тех же объясняющих факторов. В разделе 15.4 описано, как этот взгляд обосновывает использование распределенных представлений, ког-да разные направления в пространстве представлений соответствуют разным факторам вариативности. Каузальные факторы. Модель строится так, чтобы факторы вариативности, описываемые обученным представлением h, рассматривались как причины наблю даемых данных x, а не наоборот. Как было сказано в разделе 15.3, это полезно для обучения с частичным привлечением учителя и делает обученную модель более устойчивой, когда распределение причин изменяется или когда модель применяется к решению новой задачи. Глубина, или иерархическая организация объясняющих факторов. Высокоуров-невые абстрактные концепции можно определить в терминах более простых концепций, образующих иерархию. С иной точки зрения, использование глу- бокой архитектуры выражает нашу веру в то, что задачу следует решать с по- мощью многошаговой программы, каждый шаг которой опирается на результа-ты обработки, произведенной на предыдущих шагах.\n--- Страница 469 ---\n468  Обучение представлений Факторы, разделяемые между задачами. Когда имеется много задач, соответ- ствующих разным переменным yi, разделяющим общий вход x, или когда каждая задача ассоциирована с подмножеством или функцией f(i)(x) глобального входа x, предполагается, что каждая yi ассоциирована со своим подмножеством обще- го пула релевантных факторов h. Поскольку эти подмножества пересекаются, обуче ние всех P(yi | x) посредством промежуточного разделяемого представле- ния P (h | x) дает возможность разделить статистическую силу между задачами. Многообразия. Масса вероятности имеет тенденцию концентрироваться, а обла- сти, в которых она концентрируется, локально связны и занимают очень малый объем. В непрерывном случае эти области можно аппроксимировать многооб- разиями гораздо меньшей размерности, чем исходное пространство данных. Многие алгоритмы машинного обучения разумно ведут себя только на таком многообразии (Goodfellow et al., 2014b). Некоторые алгоритмы, особенно авто-кодировщики, пытаются явно обучиться структуре такого многообразия. Естественная кластеризация. Во многих алгоритмах машинного обучения предполагается, что каждому связному многообразию в пространстве входов можно сопоставить один класс. Данные могут располагаться на нескольких несвязных многообразиях, но внутри каждого из них класс остается постоян-ным. Это предположение лежит в основе разнообразных алгоритмов обучения, включая касательное распространение, двойное обратное распространение, классификатор по касательной к многообразию и состязательное обучение. Временная и пространственная когерентность. Анализ медленных признаков и родственные алгоритмы предполагают, что наиболее важные объясняющие факторы изменяются во времени медленно или, по крайней мере, что истин-ные объясняющие факторы предсказать легче, чем сами наблюдения, напри-мер значения пикселей. Дополнительные детали см. в разделе 13.3. Разреженность. Предполагается, что большинство признаков не должно быть релевантно описанию большинства входов, т. е. нет нужды использовать при- знак, обнаруживающий большегрузный грузовик, если мы представляем изобра жение кошки. Поэтому разумно наложить априорное ограничение: лю- бой признак, который можно интерпретировать как «присутствует» или «от-сутствует», в большинстве случаев принимает значение «отсутствует». Простота зависимостей между факторами. В хорошем высокоуровневом представлении факторы связаны между собой простыми зависимостями. Прос тейшая из них – безусловная независимость, P(h) = ∏ i P(hi), но линейные зависимости или зависимости, улавливаемые мелким автокодировщиком, так-же разумны. Это предположение, имеющее место во многих физических зако-нах, делается, когда поверх обученного представления реализуется линейный предиктор или факторизованное априорное распределение. Идея обучения представлений связывает воедино многие формы глубокого обуче- ния. Сети прямого распространения и рекуррентные сети, автокодировщики и глу- бокие вероятностные модели – все они обучают представления и используют их. Обучение наилучшего из возможных представлений остается увлекательным на-правлением исследований.",
      "debug": {
        "start_page": 444,
        "end_page": 469
      }
    },
    {
      "name": "Глава 16. Структурные вероятностные модели в глубоком обучении 469",
      "content": "--- Страница 470 --- (продолжение)\nГлава 16 Структурные вероятностные модели в глубоком обучении Глубокое обучение опирается на многочисленные формализмы моделирования, ко- торыми исследователи могут пользоваться при проектировании и описании алгорит- мов. Один из таких формализмов – идея структурной вероятностной модели. Мы уже кратко обсуждали их в разделе 3.14, и этого обсуждения было достаточно, что- бы понять, как структурные вероятностные модели используются в качестве языка для описания некоторых алгоритмов. Теперь же, в третьей части книги, такие модели предстанут в виде ключевого ингредиента многих из наиболее важных направлений исследований в глубоком обучении. Эта глава задумана независимой от остальной книги: для ее чтения не придется обращаться к ранее изложенному материалу. Структурная вероятностная модель – это способ описания распределения вероят- ности с помощью графа, показывающего, какие случайные величины взаимодейству- ют между собой непосредственно. Здесь слово «граф» употребляется в смысле теории графов и обозначает множество вершин, соединенных ребрами. Поскольку структура модели определена в виде графа, такие модели часто называют также графическими. Ученые, работающие в этой области, разработали много разных моделей, алго- ритмов обучения и алгоритмов вывода. В этой главе мы познакомимся с основными идеями, делая упор на концепциях, которые оказались особенно полезны в контекс- те глубокого обучения. Если вы уже хорошо знакомы с графическими моделями, то можете спокойно пропустить большую часть главы. Однако даже специалисту бу-дет небезынтересно прочитать последний раздел 16.7, в котором описываются не- которые специфические способы применения графических моделей в алгоритмах глубокого обучения. В глубоком обучении структуры моделей алгоритмы обучения и про цедуры вывода используются совсем не так, как принято среди исследователей графических моделей. В этой главе мы расскажем об этих отличиях и объясним, в чем причина. Сначала поговорим о проблемах, возникающих при построении крупномасштаб- ных вероятностных моделей, а затем покажем, как использовать граф для описа- ния структуры распределения вероятности. Хотя этот подход позволяет преодолеть многие трудности, у него есть собственные проблемы. Одна из главных трудностей графического моделирования – понять, какие величины должны взаимодействовать\nГлава 16 Структурные вероятностные модели в глубоком обучении Глубокое обучение опирается на многочисленные формализмы моделирования, ко- торыми исследователи могут пользоваться при проектировании и описании алгорит- мов. Один из таких формализмов – идея структурной вероятностной модели. Мы уже кратко обсуждали их в разделе 3.14, и этого обсуждения было достаточно, что- бы понять, как структурные вероятностные модели используются в качестве языка для описания некоторых алгоритмов. Теперь же, в третьей части книги, такие модели предстанут в виде ключевого ингредиента многих из наиболее важных направлений исследований в глубоком обучении. Эта глава задумана независимой от остальной книги: для ее чтения не придется обращаться к ранее изложенному материалу. Структурная вероятностная модель – это способ описания распределения вероят- ности с помощью графа, показывающего, какие случайные величины взаимодейству- ют между собой непосредственно. Здесь слово «граф» употребляется в смысле теории графов и обозначает множество вершин, соединенных ребрами. Поскольку структура модели определена в виде графа, такие модели часто называют также графическими. Ученые, работающие в этой области, разработали много разных моделей, алго- ритмов обучения и алгоритмов вывода. В этой главе мы познакомимся с основными идеями, делая упор на концепциях, которые оказались особенно полезны в контекс- те глубокого обучения. Если вы уже хорошо знакомы с графическими моделями, то можете спокойно пропустить большую часть главы. Однако даже специалисту бу-дет небезынтересно прочитать последний раздел 16.7, в котором описываются не- которые специфические способы применения графических моделей в алгоритмах глубокого обучения. В глубоком обучении структуры моделей алгоритмы обучения и про цедуры вывода используются совсем не так, как принято среди исследователей графических моделей. В этой главе мы расскажем об этих отличиях и объясним, в чем причина. Сначала поговорим о проблемах, возникающих при построении крупномасштаб- ных вероятностных моделей, а затем покажем, как использовать граф для описа- ния структуры распределения вероятности. Хотя этот подход позволяет преодолеть многие трудности, у него есть собственные проблемы. Одна из главных трудностей графического моделирования – понять, какие величины должны взаимодействовать\n--- Страница 471 ---\n470  Структурные вероятностные модели в глубоком обучении непосредственно, т. е. какие графовые структуры лучше всего подходят для данной задачи. В разделе 16.5 мы наметим два подхода к решению этой проблемы, основан- ных на понятии зависимости. И в разделе 16.7 завершим обсуждение, рассказав, ка- ким подходам к графическому моделированию отдают предпочтение специалисты по глубокому обучению. 16.1. Проблема бесструктурного моделирования Цель глубокого обучения состоит в том, чтобы масштабировать методы машинного обучения на задачи, возникающие в области искусственного интеллекта. Это озна- чает, что мы должны понимать данные высокой размерности с развитой структурой. Например, мы хотели бы, чтобы алгоритмы ИИ понимали естественные изображе- ния1, звуковые сигналы, соответствующие речи, и документы, содержащие много слов и знаков препинания. Алгоритмы классификации могут получать входные данные из такого многомер- ного распределения и сопоставлять им обобщающую метку категории: какой объект изображен на фотографии, какое слово произнесено, какой теме посвящен документ. В процессе классификации большая часть присутствующей во входных данных ин- формации отбрасывается и порождается единственный выход (или распределение вероятности значений выхода). Кроме того, классификатор часто способен игнори-ровать многие части входа. Например, при распознавании объекта на фотографии мы обычно можем игнорировать фон. Вероятностную модель можно попросить выполнить эти и многие другие задачи. Зачастую они обходятся дороже классификации. Некоторые из них порождают не-сколько выходных значений. Большинство требует полного понимания структуры входных данных в целом, не допуская игнорирования отдельных участков. К числу таких задач относятся следующие: оценка плотности. По входу x система машинного обучения возвращает оцен- ку истинной плотности p(x) порождающего данные распределения. Результа- том является единственное значение, но требуется полное понимание входных данных. Если хотя бы один элемент вектора необычен, система должна назна-чить всему вектору низкую вероятность; шумоподавление. Видя поврежденный или искаженный в результате наблю- дения входной сигнал x~, система машинного обучения возвращает оценку ис- ходного или правильного сигнала x. Например, систему машинного обучения можно попросить удалить пыль или царапины со старой фотографии. Резуль-татом будет много выходов (каждый элемент очищенного от шумов примера x), и требуется понимание всего входа (потому что даже при наличии всего одного поврежденного участка окончательная оценка будет «поврежден»); восполнение отсутствующих значений. Видя результаты наблюдений некото- рых элементов x, модель возвращает оценку распределения вероятности неко- торых или всех ненаблюдавшихся элементов x. Выходов получается несколь- ко. Поскольку может потребоваться восстановить произвольные элементы x, модель должна понимать структуру всего входа; 1 Естественным называется изображение, снятое камерой в обычных окружающих условиях, в отличие от синтезированного изображения, снимка веб-страницы и т. п.\n--- Страница 472 ---\nПроблема бесструктурного моделирования  471 выборка. Модель генерирует новую выборку из распределения p(x). К таким приложениям относится синтез речи, т. е. порождение звуковых сигналов, похо- жих на естественную человеческую речь. Необходимы несколько выходных зна- чений и хорошая модель всего входа. Если в выборке присутствует хотя бы один элемент из неправильного распределения, то результат всей выборки не годится. Пример задачи выборки с использованием небольших естественных изображений приведен на рис. 16.1. Рис. 16.1  Вероятностное моделирование естественных изображений. (Сверху) Примеры цветных изображений 32×32 из набора данных CIFAR-10 (Krizhevsky and Hinton, 2009). (Снизу) Выборка из структурной вероятност-ной модели, обученной на этом наборе данных. Каждый элемент выборки находится в той же позиции сетки, что и обучающий пример, ближайший к нему в евклидовом пространстве. Это сопоставление показывает, что модель действительно синтезирует новые изображения, а не просто за- поминает обучающие данные. Контрастность обоих наборов изображений подобра на для дисплея. Рисунок взят из работы Courville et al. (2011) Моделирование нетривиального распределения тысяч или миллионов случайных величин – трудная задача как с вычислительной, так и со статистической точки зре- ния. Предположим, что требуется моделировать только бинарные величины. Даже этот простейший случай вызывает, на первый взгляд, непреодолимые сложности. Для небольшого цветного (RGB) изображения размера 32× 32 существуют 2 3072 возможных бинарных изображений. Это число в 10800 больше числа атомов во Вселенной. В общем случае для моделирования случайного вектора x, содержащего n дискрет- ных величин, каждая из которых принимает k значений, при наивном подходе к пред- ставлению P(x) потребуется хранить таблицу вероятностей каждого возможного вы- хода, т. е. kn параметров!\n--- Страница 473 ---\n472  Структурные вероятностные модели в глубоком обучении Это невозможно по нескольким причинам: память – стоимость хранения представления. Для сколько-нибудь больших n и k в таблице, представляющей распределение, придется хранить слишком много значений; статистическая эффективность. С увеличением числа параметров модели возрастает и объем обучающих данных, необходимых для выбора значений этих параметров с помощью статистического оценивателя. Поскольку в табличной модели число параметров астрономически велико, для ее точной аппроксима- ции понадобится столь же гигантский обучающий набор. Любая такая модель окажется сильно переобученной, если не ввести дополнительные предполо-жения о связях между элементами таблицы (как, например, в возвратных или сглаженных n-граммных моделях, см. раздел 12.4.1); этап выполнения – стоимость вывода. Пусть мы хотим произвести вывод, ис- пользуя модель совместного распределения P(x) для вычисления какого-то другого распределения, например маргинального распределения P(x 1) или услов ного распределения P(x2 | x1). Для вычисления этих распределений пона- добится выполнить суммирование по всей таблице, поэтому стоимость таких операций так же недопустимо высока, как и стоимость хранения модели; этап выполнения – стоимость выборки. Предположим, что требуется про- извести выборку из модели. Наивный способ – выбрать какое-то значение u ∼ U(0, 1), а затем обходить таблицу, складывая значения вероятностей до тех пор, пока сумма не превзойдет u, после чего вернуть в качестве результата эле- мент в соответствующей позиции таблицы. Но в худшем случае для этого по- надобится прочитать всю таблицу, так что стоимость этой операции, как и про- чих, экспоненциально высока. Проблема табличного подхода в том, что мы явно моделируем все возможные взаи- модействия между всеми возможными подмножествами величин. Распределения ве-роятности, встречающиеся в реальных задачах, гораздо проще. Обычно большинство величин влияет друг на друга только косвенно. Рассмотрим, к примеру, моделирование времени финиширования команды в эста- фете. Пусть команда состоит из трех человек: Анна, Борис и Вера. В начале эстафе- ты палочка находится у Анны, которая начинает бежать по дорожке. Завершив свой этап, она передает палочку Борису. Борис бежит свой этап и передает палочку Вере, которой выпал последний этап. Мы можем смоделировать время финиширования каждого участника команды с помощью непрерывной случайной величины. Время финиширования Анны не зависит от других участников, поскольку она бежит пер-вой. Время финиширования Бориса зависит от Анны, потому что Борис не может на-чать свой этап, пока Анна не придет к финишу. Если Анна прибежит быстрее, то при прочих равных условиях и Борис финиширует быстрее. Наконец, время финиширо- вания Веры зависит от обоих ее товарищей по команде. Если Анна бежит медленно, то и Борис, вероятно, финиширует слишком поздно. Следовательно, Вера поздно начнет бежать и, скорее всего, поздно придет к финишу. Однако время финиширова- ния Веры зависит от времени финиширования Анны лишь косвенно – через Бориса. Если мы уже знаем время финиширования Бориса, то не получим более точной оцен-ки времени финиширования Веры, узнав, когда финишировала Анна. Таким образом, для моделирования эстафеты достаточно всего двух взаимодействий: влияние Анны на Бориса и влияние Бориса на Веру. Третье, косвенное взаимодействие между Анной и Верой из модели можно исключить.\n--- Страница 474 ---\nПрименение графов для описания структуры модели  473 Структурные вероятностные модели предлагают формальную систему моделиро- вания только прямых взаимодействий между случайными величинами. Это позволя- ет обойтись значительно меньшим числом параметров модели и, следовательно, по-лучить надежную оценку при меньшем объеме данных. Уменьшение размера модели также кардинально снижает вычислительную стоимость с точки зрения памяти для хранения модели, времени выполнения вывода и выборки из модели. 16.2. Применение графов для описания структуры модели В структурных вероятностных моделях для представления взаимодействий между случайными величинами применяются графы. Вершины представляют случайные величины, а ребра – прямые взаимодействия. Прямые взаимодействия подразумева- ют также наличие косвенных, но явно моделируются только первые. Существует несколько способов описать взаимодействия случайных величин с по- мощью графа. В следующих разделах мы опишем несколько наиболее популярных и полезных подходов. Графические модели можно разбить на две большие категории: основанные на ориентированных ациклических графах и основанные на неориенти- рованных графах. 16.2.1. Ориентированные модели Один из видов структурных вероятностных моделей – ориентированная графиче- ская модель, известная также под названиями сеть доверия или байесовская сеть1 (Pearl, 1985). Ориентированные графические модели называются «ориентированными», по- тому что ребра графа ориентированы, т. е. направлены от одной вершины к другой. Направление ребра обозначается стрелкой. Стрелка показывает, что распределение вероятности одной величины определяется в терминах другой. Наличие стрелки, направленной от a к b, означает, что распределение вероятности b определено с по- мощью условного распределения, причем a – одна из величин, находящихся справа от вертикальной черты. Иными словами, распределение b зависит от значения a. Продолжая пример эстафеты из раздела 16.1, обозначим время финиширования Анны t 0, Бориса – t1, а Веры – t2. Как мы уже видели, оценка t1 зависит от t0. Оценка t2 прямо зависит от t1, но лишь косвенно от t0. Мы можем изобразить эти связи в виде ориентированной графической модели, показанной на рис. 16.2. Формально ориентированная графическая модель над величинами x определя- ется ориентированным ациклическим графом 𝒢, вершины которого соответствуют случайным величинам модели, и множеством локальных условных распределений вероятности p(xi | Pa𝒢(xi)), где Pa𝒢(xi) обозначает множество родителей xi в 𝒢. Распре- деление вероятности x имеет вид p(x) = ∏ip(xi | Pa𝒢(xi)). (16.1) 1 Джуда Пирл предлагал использовать термин «байесовская сеть», когда нужно «подчеркнуть оценочную» природу значений, вычисляемых сетью, т. е. тот факт, что они представляют степень веры, а не частоты событий.\n--- Страница 475 ---\n474  Структурные вероятностные модели в глубоком обучении Анна Борис Вера Рис. 16.2  Ориентированная графическая модель эстафеты. Время фи- ниширования Анны t0 влияет на время финиширования Бориса t1, поскольку Борис не начинает бежать, пока Анна не придет к финишу. Аналогично Вера начинает бежать только после того, как Борис финиширует, поэтому время финиширования Бориса t1 прямо влияет на время финиширования Веры t2 В нашем примере эстафеты, описываемом графом на рис. 16.2, это означает, что: p(t0, t1, t2) = p(t0)p(t1 | t0)p(t2 | t1). (16.2) Это наше первое знакомство со структурной вероятностной моделью в действии. Изучив стоимость ее использования, мы увидим, что структурное моделирование имеет много преимуществ по сравнению с бесструктурным. Предположим, что мы дискретизировали интервал времени от нулевой до десятой минуты, разбив его на 6-секундные промежутки. Тогда каждая из случайных вели- чин t0, t1 и t2 может принимать 100 различных значений. Если бы мы попытались представить p(t0, t01, t2) таблицей, то понадобилось бы хранить 999 999 значений (100 значений t0 × 100 значений t1 × 100 значений t2 минус 1, поскольку вероятность одной конфигурации можно не задавать, т. к. сумма всех вероятностей должна быть равна 1). Если же завести по одной таблице для каждого условного распределения, то для хранения распределения t0 нужно 99 значений, для хранения t1 при условии t0 – 9900 значений и столько же для хранения t2 при условии t1. Всего получается 19 899 значений. То есть применение ориентированной графической модели позво- лило уменьшить число параметров больше чем в 50 раз! В общем случае для моделирования n дискретных величин, каждая из которых принимает k значений, решение с одной таблицей имеет порядок O(kn), как мы виде- ли раньше. Теперь предположим, что мы построили ориентированную графическую модель над этими величинами. Если m – максимальное число величин по любую сторону от вертикальной черты в одном условном распределении вероятности, то стои мость хранения таблиц для ориентированной модели имеет порядок O(k m). Если удастся спроектировать модель, в которой m << n, то мы получим очень существен- ное улучшение. Иными словами, если у каждой величины в графе мало родителей, то для пред- ставления распределения нужно очень мало параметров. Введя дополнительные ограничения на структуру графа, например потребовав, что он был деревом, мы так-же сможем гарантировать, что такие операции, как вычисление маргинального или условного распределения подмножеств величин, производятся эффективно. Важно понимать, какие виды информации можно закодировать в виде графа, а ка- кие нельзя. В графе представлены только упрощающие предположения о том, ка- кие величины условно независимы. Можно также вводить другие типы упрощаю- щих предположений. Предположим, к примеру, что Борис всегда бежит одинаково вне зависимости от результата, показанного Анной. (На практике результат Анны, скорее всего, влияет на результат Бориса – увидев, что Анна пробежала необычно быстро, Борис может воодушевиться и сделать все возможное, чтобы не уступить ей\n--- Страница 476 ---\nПрименение графов для описания структуры модели  475 или, наоборот, решить, что дело сделано, и бежать спустя рукава). Тогда единственное влияние Анны на время финиширования Бориса заключается в том, что нужно при- бавить время Анны к заранее известному времени Бориса. Это наблюдение позволяет определить модель с O(k) параметрами вместо O(k2). Отметим, однако, что t0 и t1 по- прежнему прямо зависят друг от друга, т. к. t1 представляет абсолютное время фини- ширования Бориса, а не время, потраченное им на свой этап. Это значит, что в графе должна остаться стрелка из t0 в t1. Предположение, что личное время Бориса ни от чего не зависит, невозможно закодировать в графе с вершинами t0, t1 и t2. Вместо этого мы должны закодировать эту информацию в определении самого условного распре- деления. Теперь условное распределение не является таблицей с k×k – 1 элементами, индексированной величинами t0 и t1, а описывается несколько более сложной фор- мулой всего с k – 1 параметрами. Синтаксис ориентированной графической модели не налагает никаких ограничений на способ определения условных распределений. Он лишь определяет, какие случайные величины могут входить в них в качестве ар- гументов. 16.2.2. Неориентированные модели Ориентированные графические модели предлагают один из возможных языков описания структурных вероятностных моделей. Другой популярный язык – не- ориентированные модели, или марковские случайные поля, или марковские сети (Kindermann, 1980). Как следует из самого названия, в неориентированных моделях используются графы с неориентированными ребрами. Ориентированные модели естественны в ситуациях, когда есть очевидные причи- ны нарисовать стрелку в определенном направлении. Так часто бывает, когда мы по- нимаем причинно-следственные связи, и эти связи однонаправленные. Пример такой ситуации – моделирование эстафеты. Участники, бегущие раньше, оказывают влия- ние на время финиширования бегущих позже, а те, кто бежит позже, никак не влияют на результат уже пробежавших. Но не во всех интересующих нас ситуациях можно однозначно определить направ- ление взаимодействия. Когда у взаимодействия нет очевидного направления или когда оно действует в обоих направлениях, лучше использовать неориентированную модель. В качестве примера рассмотрим модель распределения с тремя бинарными величинами: вы больны или нет, ваш коллега болен или нет и ваш сосед по комнате болен или нет. Как и в примере с эстафетой, мы можем принять упрощающие пред- положения об имеющихся взаимодействиях. В предположении, что коллега и сосед незнакомы, крайне маловероятно, что один мог заразить другого напрямую. Это со-бытие можно счесть настолько редким, что моделировать его бессмысленно. Однако вполне вероятно, что каждый из них мог заразить вас и что вы могли передать заразу другому. Мы можем смоделировать косвенную передачу болезни от коллеги соседу, смоделировав передачу от коллеги вам и от вас соседу. В этом случае с равным успехом как вы можете быть причиной заболевания со- седа, так и он – вашего, поэтому очевидного направления взаимодействия не сущест- вует. Следовательно, напрашивается применение неориентированной модели. Как и в ориентированных моделях, если две вершины соединены ребром, то соответст- вующие им случайные величины взаимодействуют непосредственно. Но, в отличие от ориентированной модели, в неориентированной на ребре нет стрелки, и с ним не ассоциировано никакое условное распределение вероятности.\n--- Страница 477 ---\n476  Структурные вероятностные модели в глубоком обучении Обозначим случайную величину, представляющую состояние вашего здоровья, hy, состояние здоровья вашего соседа hr, а состояние здоровья коллеги – hc. Граф, описы- вающий эту ситуацию, показан на рис. 16.3. Рис. 16.3  Ориентированный граф, представляющий взаимное влияние состояния здоровья вашего коллеги hr, ваше hy и вашего соседа hc. Вы и ваш сосед могли заразить друг друга, и то же самое относится к коллеге. Но в предположении, что коллега и сосед незнакомы, они могли заразить друг друга только через вас Формально говоря, неориентированная графическая модель – это структурная ве- роятностная модель, определенная над неориентированным графом 𝒢. Для каждой клики 𝒞 графа1 фактор ϕ(𝒞) (или потенциал клики) измеряет склонность случайных величин, входящих в эту клику, к пребыванию в каждом из возможных совместных состояний. Факторы по определению неотрицательны. Вместе они образуют ненор- мированное распределение вероятности p~(x) = ∏𝓒∈𝓖 ϕ(𝒞). (16.3) Работа с этим ненормированным распределением будет эффективна при условии, что клики малы. Его идея в том, что состояния с высокой взаимной склонностью бо- лее вероятны. Однако, в отличие от байесовской сети, в определении клик нет ника- кой особенной структуры, поэтому нет гарантии, что их перемножение даст коррект- ное распределение вероятности. На рис. 16.4 приведен пример чтения информации о факторизации из неориентированного графа. Рис. 16.4  Из этого графа следует, что распределение p(a, b, c, d, e, f) можно записать в виде (1/Z)ϕa, b(a, b)ϕb, c(b, c)ϕa, d(a, d)ϕb, e(b, e)ϕe, f(e, f) при под- ходящем выборе функций ϕ В примере с распространением болезни между тремя лицами есть две клики. Одна из них содержит hy и hc. Фактор этой клики можно определить с помощью таблицы такого вида: hy = 0 hy = 1 hc = 0 2 1 hc = 1 1 10 1 Кликой называется подмножество вершин графа, любые две из которых соединены ребром.\n--- Страница 478 ---\nПрименение графов для описания структуры модели  477 Состояние 1 означает, что человек здоров, а состояние 0 – что он болен (подхватил простуду). И вы, и ваш коллега обычно здоровы, поэтому склонность соответствую- щего состояния максимальна. Состояние, в котором только один из вас болен, имеет наименьшую склонность, поскольку оно встречается редко. У состояния, в котором вы оба больны (поскольку один заразил другого), склонность выше, хотя оно встре- чается не столь часто, как состояние, когда вы оба здоровы. Чтобы завершить построение модели, нужно еще определить аналогичный фактор для клики, содержащей hy и hr. 16.2.3. Статистическая сумма Для ненормированного распределения вероятности гарантируется, что оно всюду не-отрицательно, но не гарантируется, что сумма или интеграл равны 1. Чтобы получить корректное распределение вероятности, необходимо произвести нормировку 1: (16.4) где коэффициент Z обеспечивает равенство суммы вероятностей или интеграла плот- ности единице: (16.5) Z можно считать константой, если функции ϕ постоянны. Отметим, что если у функций ϕ есть параметры, то Z – функция этих параметров. В литературе при- нято записывать Z без параметров для экономии места. Нормировочная постоянная Z называется статистической суммой, этот термин заимствован из статистической физики. Поскольку Z – это интеграл или сумма по всем возможным совместным распре- делениям состояния x, вычислить его зачастую невозможно. Чтобы все же получить нормированное распределение вероятности неориентированной модели, структура модели и определения функций ϕ должны допускать эффективное вычисление Z. В контексте глубокого обучения точное вычисление Z – обычно неразрешимая за- дача. А раз так, то мы должны прибегнуть к аппроксимациям. Такие приближенные алгоритмы – тема главы 18. При проектировании неориентированных моделей важно иметь в виду, что задать факторы можно таким образом, что Z вообще не существует. Это происходит, если некоторые случайные величины в модели непрерывны, а интеграл p~ по их области определения расходится. Предположим, к примеру, что мы хотим построить модель одной скалярной величины x ∈ ℝ с одним потенциалом клики ϕ(x) = x 2. В таком случае (16.6) Поскольку этот интеграл расходится, не существует распределения вероятно- сти, соответствующего такому выбору ϕ(x). Иногда от выбора некоторого пара- метра функций ϕ зависит, определено ли распределение вероятности. Например, для ϕ(x; β) = exp(–β x2) параметр β определяет существование Z. При положитель- 1 Распределение, полученное нормировкой произведений потенциалов клик, называют так- же распределением Гиббса.\n--- Страница 479 ---\n478  Структурные вероятностные модели в глубоком обучении ных β получается нормальное распределение x, а при всех остальных ϕ невозможно нормировать. Одно из основных различий между ориентированным и неориентированным моде- лированием состоит в том, что ориентированные модели с самого начала определены непосредственно в терминах распределений вероятности, тогда как неориентирован- ные – более свободно, в терминах функций ϕ, которые впоследствии преобразуются в распределения вероятности. Поэтому при работе с этими моделями интуитивные соображения различны. Имея дело с неориентированными моделями, важно пом- нить, что область определения каждой величины сильно влияет на вид распределе- ния вероятности, соответствующего данному множеству функций ϕ. Рассмотрим, на- пример, n-мерную векторную случайную величину x и неориентированную модель, параметризованную вектором смещений b. Предположим, что для каждого элемента x имеется одна клика ϕ(i)(xi) = exp(bixi). Какое распределение вероятности при этом получается? Для ответа на этот вопрос недостаточно информации, потому что мы еще не задали область определения x. Если x ∈ ℝ n, то интеграл, определяющий Z, расходит- ся, и никакого распределения вероятности не существует. Если x ∈ {0, 1}n, то p(x) раз- лагается в произведение n независимых распределений: p(xi = 1) = sigmoid(bi). Если область определения x – множество элементарных базисных векторов ({[1, 0, …, 0], [0, 1, …, 0], …, [0, 0, …, 1]}), то p(x) = softmax(b), поэтому большое значение bi факти- чески сокращает p(xj = 1) для j ≠ i. Часто за счет специального подбора области опре- деления случайной величины можно получить сложное поведение из сравнительно простого множества функций ϕ. Практическое применение этой идеи мы рассмотрим в разделе 20.6. 16.2.4. Энергетические модели Многие интересные теоретические результаты о неориентированных моделях осно- ваны на предположении о том, что ∀x p~(x) > 0. Удобный способ наложить такое огра- ничение – воспользоваться энергетической моделью (energy-based model – EBM), в которой p~(x) = exp(–E(x)), (16.7) а E(x) называется функцией энергии. Поскольку exp(z) положительно для всех z, гарантируется, что при любой функции энергии все состояния x будут иметь нену- левую вероятность. Возможность выбирать абсолютно произвольную функцию энер-гии упрощает обучение. Если бы мы обучали потенциалы клик непосредственно, то пришлось бы использовать ограниченную оптимизацию, чтобы задать неизвестно как выбранное минимальное значение вероятности. А обучая функцию энергии, мы можем пользоваться неограниченной оптимизацией 1. В энергетической модели веро- ятности могут быть сколь угодно близки к нулю, но никогда не обращаются в нуль. Распределение вида (16.7) называется распределением Больцмана. Поэтому мно- гие энергетические модели называются машинами Больцмана (Fahlman et al., 1983; Ackley et al., 1985; Hinton et al., 1984; Hinton and Sejnowski, 1986). Не существует общепринятого соглашения о том, когда называть модель энергетической, а когда – машиной Больцмана. Термин «машина Больцмана» был введен для обозначения мо- 1 Для некоторых моделей все же приходится прибегать к ограниченной оптимизации, чтобы гарантировать существование Z.\n--- Страница 480 ---\nПрименение графов для описания структуры модели  479 дели, в которой все переменные бинарные, но сегодня так называются многие мо- дели с вещественными переменными, например ограниченные машины Больцмана с усред нением и ковариацией. Хотя в первоначальном определении машины Боль- цмана охватывали модели с латентными переменными и без них, в наши дни этот термин чаще всего относится к моделям с латентными переменными, а машины Боль- цмана без латентных переменных обычно называют случайными марковскими поля- ми, или лог-линейными моделями. Клики в неориентированном графе соответствуют факторам ненормированной функции вероятности. Поскольку exp(a)exp(b) = exp(a + b), это означает, что разные клики соответствуют разным членам функции энергии. Иными словами, энергети-ческая модель – это просто частный случай марковской сети: операция потенциро- вания сопоставляет каждому члену функции энергии фактор отдельной клики. На рис. 16.5 показано, как получить функцию энергии по неориентированному графу. Энергетическую модель с функцией энергии, содержащей несколько членов, мож- но рассматривать как произведение экспертов (Hinton, 1999). Каждый член функ- ции энергии соответствует фактору распределения вероятности, его можно считать «экспертом», который определяет, удовлетворяется ли некоторое мягкое ограниче-ние. Каждый эксперт может налагать только одно ограничение, относящееся лишь к проекции случайных величин на пространство низкой размерности, но в сочетании с произведением вероятностей сообщество экспертов налагает сложное ограничение высокой размерности. Рис. 16.5  Из этого графа следует, что E(a, b, c, d, e, f) можно записать в виде Ea,b(a, b) + Eb,c(b, c) + Ea,d(a, d) + Eb,e(b, e) + Ee,f(e, f) при подходящем вы- боре функции энергии для каждой клики. Отметим, что функции на рис. 16.4 можно получить, положив каждую равной экспоненте соответствующей от-рицательной энергии, например: ϕ a,b(a, b) = exp(–E(a, b)) В определении энергетической модели есть часть, не несущая никакой полезной функции с точки зрения машинного обучения: знак – в формуле (16.7). Его можно было бы включить в определение E, поскольку во многих случаях алгоритм обучения вправе выбрать любой знак энергии. Знак – присутствует главным образом для того, чтобы сохранить совместимость между литературой по машинному обучению и по физике. Многими своими достижениями вероятностное моделирование обязано ста-тистической физике, где E обозначает физическую энергию и не может иметь произ- вольного знака. Термины «энергия» и «статистическая сумма» заимствованы именно оттуда, хотя их математическое применение шире, чем в том физическом контексте, в котором они возникли. Некоторые специалисты по машинному обучению (напри- мер, Smolensky [1986], который называл отрицательную энергию гармонией) убира- ли знак минус, но это не стало стандартным соглашением.\n--- Страница 481 ---\n480  Структурные вероятностные модели в глубоком обучении Во многих алгоритмах для работы с вероятностными моделями нужно вычислять не pmodel(x), а только log p~ model(x). В энергетических моделях с латентными переменны- ми h такие алгоритмы иногда формулируются в терминах этой величины со знаком минус, называемой свободной энергией: (16.8) В этой книге мы предпочитаем более общую формулировку: log p~ model(x). 16.2.5. Разделенность и d-разделенность Ребра в графической модели несут информацию о том, какие переменные взаимодей- ствуют непосредственно. Часто бывает необходимо знать о переменных, взаимодей- ствующих косвенно. Некоторые косвенные взаимодействия можно запретить или раз- решить посредством наблюдения других переменных. Формально говоря, мы хотели бы знать, какие подмножества переменных условно независимы друг от друга при известных значениях других подмножеств переменных. Выявить условную независимость в графе неориентированной модели просто. В этом случае условная независимость, вытекающая из структуры графа, называется разделенностью. Мы говорим, что множества переменных 𝔸 и 𝔹 разделены третьим заданным множеством переменных 𝕊, если из структуры графа следует, что 𝔸 не за- висит от 𝔹 при условии 𝕊. Если две переменные a и b соединены путем, содержащим только ненаблюдаемые переменные, то они не являются разделенными. Если между ними вообще нет пути или все соединяющие пути содержат хотя бы одну наблюдае-мую переменную, то a и b разделены. Пути, содержащие только ненаблюдаемые пере- менные, называются «активными», а включающие наблюдаемую переменную – «не- активными». Наблюдаемые переменные изображаются в графе серым цветом. На рис. 16.6 по- казано, как при этом выглядят активные и неактивные пути в неориентированной модели, а на рис. 16.7 – как определять разделенность по неориентированному графу. (a) (b) Рис. 16.6  (a) Путь между случайными величинами a и b, проходящий че- рез s, активен, поскольку величина s не наблюдаемая. Это означает, что a и b не разделены. (b) Здесь s закрашена серым, т. е. является наблюдаемой. Поскольку единственный путь между a и b проходит через s и этот путь не- активен, можно заключить, что a и b разделены величиной s Похожие идеи применимы и к ориентированным моделям, только в этом контекс- те говорят о d-разделенности. Буква «d» означает «dependence» (зависимость). Для ориентированных графов d-разделенность определяется так же, как разделенность для неориентированных: множества переменных 𝔸 и 𝔹 называются d-разделенными третьим множеством переменных 𝕊, если из структуры графа следует, что 𝔸 не зави- сит от 𝔹 при условии 𝕊.\n--- Страница 482 ---\nПрименение графов для описания структуры модели  481 Рис. 16.7  Пример определения разделенности по неориентированно- му графу. Здесь b закрашена серым, потому что является наблюдаемой. Поскольку наблюдение b блокирует единственный путь из a в c, можно утверж дать, что a и c разделены величиной b. Наблюдение b блокирует так- же один путь между a и d, но между ними существует другой, активный путь. Следовательно, a и d не разделены b Как и в случае неориентированных моделей, мы можем исследовать независи- мость, вытекающую из структуры графа, глядя на активные пути в нем. Как и рань- ше, две переменные независимы, если между ними существует активный путь, и d-разделенные, если такого пути нет. В ориентированных сетях определить, являет- ся ли путь активным, несколько сложнее. Рисунок 16.8 может служить руководством по нахождению активных путей в ориентированной модели. А на рис. 16.9 приведен пример определения некоторых свойств по графу. Важно помнить, что разделенность и d-разделенность говорят только о тех ус- ловных независимостях, которые следуют из графа. Не требуется, чтобы из графа вытекали все существующие отношения независимости. В частности, всегда можно использовать полный граф (в котором проведены все возможные ребра) для пред-ставления любого распределения. На самом деле некоторые распределения содержат независимости, которые невозможно представить с помощью существующей нота- ции графов. Контекстными независимостями называются такие отношения неза- висимости, которые присутствуют в зависимости от значений некоторых величин в сети. Например, рассмотрим модель с тремя бинарными величинами: a, b и c. Пред- положим, что при a = 0 величины b и c независимы, а при a = 1 b всегда равно c. Чтобы представить такое поведение при a = 1, необходимо провести ребро между b и c. Но тогда граф не сможет показать, что b и c независимы при a = 0. Вообще, граф никогда не позволяет сделать вывод о наличии независимости, если таковой не существует. Однако могут существовать независимости, не представлен-ные в графе. 16.2.6. Преобразование между ориентированными и неориентированными графами Мы часто называем конкретную модель машинного обучения ориентированной или неориентированной. Например, ограниченная машина Больцмана обычно считается неориентированной моделью, а разреженное кодирование – ориентированной. Такой выбор слов вносит некоторую путаницу, потому что никакая вероятностная модель не является внутренне ориентированной или неориентированной. Просто одни мо-дели проще описывать с помощью ориентированного графа, а другие – с помощью неориентированного.\n--- Страница 483 ---\n482  Структурные вероятностные модели в глубоком обучении (c)(a) (d)(b) Рис. 16.8  Все возможные виды активных путей длины 2 между случай- ными величинами a и b. (a) Любой путь со стрелками в одном направлении: от a к b или наоборот. Такой путь будет блокирован, если s – наблюдаемая величина. Мы уже встречались с такими путями в примере эстафеты. (b) Величины a и b связаны общей причиной s. Допустим, к примеру, что ве- личина s определяет наличие урагана, а величины a и b измеряют скорость вет ра в двух соседних метеостанциях. Если на станции a наблюдается очень сильный ветер, то можно ожидать сильного ветра и на станции b. Путь такого вида может блокироваться наблюдением s. Если мы уже знаем, что ураган есть, то можно ожидать сильного ветра в b вне зависимости от того, что наблюдается в a. Если ветер в a слабее ожидаемого (для урагана), то ожидаемая сила ветра в b от этого не изменится (при условии что мы знаем о наличии урагана). Но если s – ненаблюдаемая величина, то a и b за- висимы, т. е. путь активен. (c) Величины a и b – родители s. Это называется V-структурой, или коллизией. V-структура связывает a и b путем оправ- дания (explaining away). В данном случае путь активен, когда s наблюдае- мая. Предположим, к примеру, что величина s описывает отсутствие вашего коллеги на работе. Величина a говорит, болен ли он, а величина b – находит- ся ли он в отпуске. Если мы наблюдаем, что коллега отсутствует, то можем предположить, что он болен или в отпуске, но маловероятно, что то и дру- гое произошло одновременно. Если выясняется, что он в отпуске, то одно- го этого факта достаточно для оправдания отсутствия. Отсюда мы можем сделать вывод, что коллега, вероятно, не болен. (d) Оправдание имеет мес- то, даже когда любой потомок s – наблюдаемая величина! Предположим, к примеру, что величина c представляет факт получения отчета от коллеги. Если вы замечаете, что не получили отчета, то это увеличивает оценку того, что коллеги сегодня нет на работе, из чего, в свою очередь, с вероятностью следует, что он либо болен, либо в отпуске. Путь через V-структуру блокиру- ется только тогда, когда ни один из потомков общей дочерней вершины не является наблю даемой величиной\n--- Страница 484 ---\nПрименение графов для описания структуры модели  483 Рис. 16.9  Из этого графа мы можем получить несколько свойств d-раз- де ленности, например: • a и b d-разделены пустым множеством; • a и e d-разделены вершиной c; • d и e d-разделены вершиной c. Мы также видим, что некоторые величины перестают быть d-разделенными, если наблюдаются другие величины:• a и b не являются d-разделенными вершиной c; • a и b не являются d-разделенными вершиной d И у ориентированных, и у неориентированных моделей есть свои плюсы и минусы. Ни тот, ни другой подходы нельзя считать наилучшим и предпочтительным во всех случаях. Нужно просто решить, какой язык использовать в каждой задаче. Отчасти выбор определяется тем, какое распределение вероятности мы хотим описать. Пред-почтительный вид модели может зависеть от того, какой граф позволяет представить большинство независимостей или в каком графе число ребер меньше. На выбор язы- ка влияют и другие факторы. Даже при работе с одним распределением вероятно- сти иногда выгодно переходить от одного языка моделирования к другому. Иногда другой язык оказывается более подходящим, если мы наблюдаем определенное под-множество переменных или если хотим решить другую вычислительную задачу. На-пример, ориентированная модель часто позволяет эффективно производить выборку (см. раздел 16.3), а неориентированная бывает полезна для выполнения процедур приближенного вывода (как мы увидим в главе 19, где роль неориентированных мо- делей выражена формулой (19.56)). Любое распределение вероятности можно представить ориентированной или неориентированной моделью. В худшем случае распределение всегда можно пред- ставить «полным графом». В случае ориентированной модели полным называется любой ориентированный ациклический граф, в котором определено некоторое отно- шение порядка на случайных величинах, и для каждой величины все предшествую- щие ей в этом порядке величины являются ее предками в графе. В случае неориенти- рованной модели полным называется просто граф, содержащий единственную клику, в которую входят все величины. Пример показан на рис. 16.10. Разумеется, полезность графической модели заключается в том, что из структуры графа вытекает, что некоторые величины не взаимодействуют непосредственно. Пол-ный граф не особенно полезен, потому что из него нельзя извлечь никакой информа-ции о независимости.\n--- Страница 485 ---\n484  Структурные вероятностные модели в глубоком обучении Рис. 16.10  Примеры полных графов с четырьмя случайными величина- ми, способных описать любое распределение вероятности. (Слева) Пол- ный неориентированный граф; в этом случае существует только один пол- ный граф. (Справа) Полный ориентированный граф. В этом случае полных графов много. Мы выбрали некоторое отношение порядка на множестве случайных величин и провели дугу из каждой величины в величину, которая следует за ней в этом порядке. Поэтому число полных ориентированных графов равно факториалу числа случайных величин. В данном случае вели- чины упорядочены слева направо сверху вниз Представляя распределение вероятности в виде графа, мы хотим выбрать граф так, чтобы независимостей было как можно больше, но только не таких, которых в дей- ствительности не существует. С этой точки зрения, одни распределения более эффективно представляются ори- ентированными моделями, а другие – неориентированными. Иными словами, в ори- ентированной модели можно закодировать некоторые независимости, не представи- мые неориентированной моделью, и наоборот. В ориентированной модели можно использовать одну структуру специального вида, которую трудно представить в неориентированной модели. Речь идет об амо- ральности. Эта структура имеет место, когда две случайные величины a и b являются родителями третьей величины c, но не существует ребра, соединяющего a и b хотя бы в одном направлении. (Странное название «аморальность» употребляется в литера- туре по графическим моделям как намек на родителей, не сочетавшихся законным браком.) Для преобразования ориентированной модели с графом 𝒟 в н е ориентиро- ванную модель нужно построить новый граф 𝒰. Для каждой пары величин x и y в 𝒰 включается неориентированное ребро, соединяющее x и y, если в 𝒟 существует ори- ентированное ребро между x и y (в любом направлении) или если x и y – родители третьей величины z в 𝒟 . Получившийся граф 𝒰 называется моральным графом. На рис. 16.11 приведены примеры преобразований ориентированных моделей в неори- ентированные посредством морализации. С другой стороны, неориентированные модели могут содержать структуры, не представимые ориентированной моделью. Точнее говоря, ориентированный граф 𝒟 не может представить всех условных независимостей, следующих из неориентиро-ванного графа 𝒰, когда 𝒰 содержит цикл длины больше 3, если только этот цикл не со- держит также хорду. Циклом называется последовательность величин, соединенных неориентированными ребрами, такая, что последняя величина соединена с первой. Хордой называется соединение между любыми двумя несоседними величинами в по- следовательности, определяющей цикл. Если 𝒰 содержит циклы длины 4 или больше и не содержит хорд для этих циклов, то перед преобразованием в ориентированную модель мы должны добавить хорды. Добавление хорд приводит к частичному отбра- сыванию информации о независимости, закодированной в 𝒰. Граф, образованный до-\n--- Страница 486 ---\nПрименение графов для описания структуры модели  485 бавлением хорд в 𝒰, называется хордовым, или триангулированным, поскольку все циклы теперь можно описать в терминах меньших треугольных циклов. Для построе- ния ориентированного графа 𝒟 из хордового графа мы должны также назначить каж- дому ребру направление. Но при этом нужно избегать появления ориентированных циклов в 𝒟 , потому что иначе получившаяся ориентированная вероятностная модель окажется некорректной. Чтобы назначить ребрам 𝒟 направления, мы можем выбрать некоторое отношение порядка на случайных величинах, а затем приписать каждому ребру такое направление, чтобы начальной была меньшая относительно этого поряд- ка величина, а конечной – большая. Это иллюстрируется на рис. 16.12. Рис. 16.11  Примеры преобразования ориентированных моделей (верхний ряд) в неориентированные (нижний ряд). (Слева) Эту простую це- почку можно преобразовать в моральный граф, просто заменив ориентиро- ванные ребра неориентированными. Из получившейся неориентированной модели вытекает точно такое же множество независимостей и условных независимостей. (В центре) Это простейшая ориентированная модель, ко-торую невозможно преобразовать в неориентированную без потери части независимостей. Граф представляет собой одну-единственную амораль-ность. Поскольку a и b являются родителями c, то они соединены активным путем, если c наблюдаемая. Чтобы отразить эту зависимость, неориентиро-ванная модель должна включать клику, содержащую все три величины. Но эта клика не может представить тот факт, что a⊥b. (Справа) В общем случае морализация может добавить в граф много ребер, что приведет к утрате многих вытекающих из графа независимостей. Например, для этого графа разреженного кодирования нужно добавить морализирующие ребра между каждой парой скрытых блоков, что ведет к появлению квадратичного числа новых прямых зависимостей\n--- Страница 487 ---\n486  Структурные вероятностные модели в глубоком обучении Рис. 16.12  Преобразование неориентированной модели в ориенти- рованную. (Слева) Эту неориентированную модель нельзя преобразовать в ориентированную, потому что в ней есть цикл длины 4 без хорд. Это озна- чает, что данная модель кодирует две разные независимости, которые никакая ориентированная модель не может представить одновременно: a⊥c | {b, d} и b⊥d | {a, c}. (В центре) Для преобразования неориентированной модели в ориентированную необходимо триангулировать граф, так чтобы все циклы длины больше 3 содержали хорду. Для этого мы можем добавить ребро, соединяющее a и c, или ребро, соединяющее b и d. В этом примере мы добавили ребро между a и c. (Справа) Чтобы завершить процесс преоб- разования, необходимо назначить каждому ребру направление, не создав при этом ориентированных циклов. Для этого мы можем ввести отношение порядка на множестве вершин и назначать ребру направление так, чтобы меньшая вершина была начальной, а большая – конечной. В данном случае вершины упорядочены в алфавитном порядке своих имен 16.2.7. Факторные графы Факторные графы – еще один способ изобразить неориентированную модель, устра- няющий неоднозначность, присутствующую в стандартном синтаксисе. В неориенти- рованной модели областью действия каждой функции ϕ должно быть подмножество некоторой клики графа. Неоднозначность возникает из-за того, что не понятно, дей-ствительно ли у каждой клики имеется фактор, область действия которого охваты- вает всю клику. Например, клика, содержащая три вершины, может соответствовать фактору над всеми тремя вершинами или трем факторам над каждой парой вершин. Факторные графы разрешают эту неоднозначность посредством явного представ-ления области действия каждой функции ϕ. Точнее говоря, факторный граф – это графическое представление неориентированной модели, состоящее из двудольного неориентированного графа. Некоторые вершины изображаются кружочками – они соответствуют случайным величинам, как в стандартной неориентированной моде- ли. Остальные вершины изображаются квадратиками и соответствуют факторам ϕ ненормированного распределения вероятности. Случайные величины и факторы мо- гут быть соединены неориентированными ребрами. Величина и фактор соединены ребром тогда и только тогда, когда данная величина является одним из аргументов фактора в ненормированном распределении вероятности. Никакой фактор не может быть соединен ни с каким другим фактором, и никакая величина не может быть со- единена с другой величиной. На рис. 16.13 приведен пример того, как факторные гра- фы разрешают неоднозначность интерпретации неориентированных сетей\n--- Страница 488 ---\nВыборка из графических моделей  487 Рис. 16.13  Пример разрешения неоднозначности интерпретации не- ориентированных сетей с помощью факторного графа. (Слева) Неориенти- рованная сеть с кликой из трех случайных величин a, b и c. (В центре) Фак- торный граф, соответствующий той же неориентированной модели. В этом графе имеется всего один фактор над всеми тремя величинами. (Справа) Другой допустимый факторный граф для той же модели – с тремя фактора- ми, по одному для каждой пары величин. Представление, вывод и обучение для этого графа асимптотически дешевле, чем для графа в центре, несмот- ря на то что оба представляют одну и ту же неориентированную модель 16.3. Выборка из графических моделей Графические модели также упрощают операцию выборки из модели. Одно из пре-имуществ ориентированных моделей состоит в том, что простая и эффективная про- цедура предковой выборки (ancestral sampling) может дать пример из совместного распределения, представленного моделью. Основная идея заключается в том, чтобы произвести топологическую сортиров- ку вершин x i графа, так что для всех i и j справедливо утверждение: j больше i, если xi – родитель xj. Тогда выборку из случайных величин можно производить в этом по- рядке. Иначе говоря, сначала производим выборку x1 ∼ P(x1), затем из P(x2 | Pa𝒢(x2)) и т. д., пока не дойдем до P(xn | Pa𝒢(xn)). Если выборку из каждого условного распре- деления P(xi | Pa𝒢(xi)) произвести легко, то легко сделать выборку и из всей модели. Топологическая сортировка гарантирует, что мы сможем прочитать условные распре-деления (16.1) и произвести из них выборку по порядку. Без сортировки мы могли бы попытаться произвести выборку случайной величины до того, как станут доступны ее родители. Для некоторых графов топологический порядок не единственный. Предковую вы- борку можно применять с любым возможным порядком. В общем случае предковая выборка работает очень быстро (в предположении, что производить выборку из каждого условного распределения легко) и удобно. Недостаток предковой выборки – в том, что она применима только к ориентиро- ванным графическим моделям. Другой недостаток – в том, что предковая выборка не поддерживает произвольную операцию условной выборки. Если мы хотим про-извести выборку из подмножества случайных величин в ориентированной графи- ческой модели при условии некоторых других величин, то часто требуется, чтобы все обуслов ливающие величины встречались в упорядоченном графе раньше, чем величины, из которых производится выборка. В таком случае мы можем выбрать из локальных условных распределений вероятности, заданных модельным распределе-нием. В противном случае условные распределения, из которых мы должны произ-\n--- Страница 489 ---\n488  Структурные вероятностные модели в глубоком обучении водить выборку, являются апостериорными распределениями при условии наблю- даемых переменных. Эти апостериорные распределения обычно не заданы и не па раметризованы в модели явно. Их вывод может оказаться дорогостоящей опера- цией. В тех моделях, где дело обстоит именно так, предковая выборка неэффективна. К сожалению, предковая выборка применима только к ориентированным моде- лям. Для выборки из неориентированной модели мы можем сначала преобразовать ее в ориентированную, но при этом зачастую возникают неразрешимые задачи выво- да (чтобы определить маргинальное распределение корневых вершин нового ориен-тированного графа) или приходится добавлять так много ребер, что получающаяся ориентированная модель становится вычислительно неприступной. Выборка из не-ориентированной модели без предварительного преобразования в ориентированную требует разрешения циклических зависимостей. Каждая величина взаимодействует со всеми другими величинами, поэтому у процесса выборки нет очевидной начальной точки. К сожалению, выборка из неориентированной графической модели является дорогостоящей многопроходной процедурой. Концептуально самым простым подхо-дом является выборка по Гиббсу. Предположим, что имеется графическая модель над n-мерным вектором случайных величин x. Мы итеративно посещаем каждую ве- личину x i и производим выборку, обусловленную всеми остальными величинами, из распределения p(xi | x–i). Благодаря свойствам разделенности графической модели это то же самое, что обусловливание только соседями xi. К сожалению, после того как выполнен один проход по графической модели и произведена выборка из всех n ве- личин, мы еще не получаем справедливой выборки p(x). Мы должны повторить весь процесс, произведя повторную выборку из всех n величин, пользуясь обновленны- ми значениями соседей. Асимптотически, после многих итераций, процесс сходится к выборке из корректного распределения. Но бывает трудно решить, когда достигну- то достаточно точное приближение к желаемому распределению. Методы выборки из неориентированных моделей – трудный и интересный вопрос, который более по- дробно рассматривается в главе 17. 16.4. Преимущества структурного моделирования Основное преимущество структурных вероятностных моделей заключается в том, что они кардинально снижают стоимость представления распределений вероятности, а также обучения и вывода. В случае ориентированных моделей ускоряется еще и вы- борка, хотя для неориентированных моделей ситуация сложнее. Главная причина, из-за которой все эти операции требуют меньше времени и памяти, состоит в том, что не- которые взаимодействия не моделируются. Графические модели сообщают важную информацию посредством выбрасывания ребер. Если между какими-то величинами ребра нет, значит, их прямое взаимодействие моделировать не нужно. У структурных вероятностных моделей есть также достоинство, в меньшей сте- пени поддающееся количественной оценке: они позволяют явно отделить представ-ление знаний от обучения знаниям или вывода с использованием существующих знаний. Поэтому такие модели проще разрабатывать и отлаживать. Мы можем про- ектировать, анализировать и оценивать алгоритмы обучения и вывода, применимые к широким классам графов. Заодно открывается возможность проектировать модели, отражающие те связи внутри данных, которые мы считаем важными. Комбинируя различные алгоритмы и структуры, мы можем получить декартово произведение раз-\n--- Страница 490 ---\nОбучение и зависимости  489 нообразных возможностей. Было бы гораздо труднее отдельно проектировать комп- лексные алгоритмы для каждой возможной ситуации. 16.5. Обучение и зависимости Хорошая порождающая модель должна верно отражать распределение наблюдаемых, или «видимых», переменных v. Часто различные элементы v сильно зависят друг от друга. В контексте глубокого обучения наиболее распространенный подход к моде- лированию таких зависимостей состоит в том, чтобы завести несколько латентных, или «скрытых», переменных h. Тогда модель может представить зависимости между любой парой переменных v i и vj косвенно, посредством прямых зависимостей между vi и h и прямых зависимостей между h и vj. В хорошей модели v, не содержащей никаких латентных переменных, должно было бы присутствовать очень много родителей каждого узла в байесовской сети или очень большие клики в марковской сети. Даже просто представить такие взаимодействия высшего порядка обходится дорого – как в вычислительном смысле, поскольку число параметров, хранящихся в памяти, экспоненциально возрастает с ростом числа чле- нов клики, так и в статистическом, т. к. при таком гигантском числе параметров для вычисления точной оценки нужно очень много данных. Если модель предназначена для улавливания зависимостей между видимыми переменными, соединенными напрямую, то соединять между собой все перемен-ные практически бессмысленно, поэтому граф следует проектировать так, чтобы были соединены лишь тесно связанные переменные, и опускать все остальные ребра. Этой проблеме посвящен целый раздел машинного обучения – структурное обуче- ние. Хорошим справочным пособием по этой теме может служить книга (Koller and Friedman, 2009). По большей части методы структурного обучения сводятся к тому или иному виду жадного поиска. Предлагается некоторая структура, и обучается мо- дель с такой структурой, затем ей присваивается оценка. Эта оценка поощряет за вер- ность аппроксимации обучающего набора и штрафует за сложность модели. На сле- дующем шаге поиска предлагаются модели-кандидаты с малым числом добавленных или удаленных ребер. Производится поиск новой структуры, от которой ожидается улучшение оценки. Применение латентных переменных вместо адаптивной структуры позволяет от- казаться от дискретных операций поиска и нескольких раундов обучения. Фиксиро- ванная структура над видимыми и латентными переменными может использовать прямые взаимодействия между видимыми и скрытыми блоками для определения косвенных взаимодействий между видимыми блоками. Применяя простые методы обучения параметров, мы можем обучить модель с фиксированной структурой, кото- рая накладывает правильную структуру на маргинальное распределение p(v). Достоинства латентных переменных не исчерпываются их ролью в эффективном отражении p(v). Новые переменные h дают также альтернативное представление v. Например, как было отмечено в разделе 3.9.6, модель гауссовой смеси обучается ла- тентной переменной, соответствующей категории примеров, из которой выбирались входные данные. Это означает, что модель гауссовой смеси можно использовать для классификации. В главе 14 мы видели, что простые вероятностные модели типа раз- реженного кодирования обучаются латентным переменным, которые можно исполь-зовать как входные признаки для классификатора или как координаты на многооб-\n--- Страница 491 ---\n490  Структурные вероятностные модели в глубоком обучении разии. Так же можно использовать и другие модели, но глубокие модели и модели с разными видами взаимодействий способны создать еще более развитые описания входных данных. Во многих подходах обучение признаков достигается путем обуче- ния латентным переменным. Часто при наличии некоторой модели v и h эксперимен- тальные наблюдения показывают, что 𝔼[h | v] или arg maxh p(h, v) – хорошее отобра- жение признаков для v. 16.6. Вывод и приближенный вывод Один из основных способов использования вероятностной модели заключается в за- давании вопросов о связи между различными величинами. Располагая набором ме- дицинских анализов, мы можем спросить, чем болен пациент. В модели с латентными переменными интересно выделить признаки 𝔼[h | v], описывающие наблюдаемые пе- ременные v. Иногда подобные проблемы приходится решать для выполнения других задач. Часто мы обучаем модели, применяя принцип максимального правдоподобия. Поскольку log p(v) = 𝔼 h∼p(h |v) [log p(h, v) – log p(h | v)], (16.9) то требуется вычислить p(h | v), чтобы реализовать правило обучения. Все это при- меры проблем вывода, в которых нужно предсказать значения одних переменных по значениям других или предсказать распределение вероятности одних переменных, зная значения других. К сожалению, для большинства интересных глубоких моделей эти проблемы не- разрешимы, даже если для их упрощения использовать структурную графическую модель. Граф позволяет представить сложные распределения высокой размерности с разумным числом параметров, но применяемые в глубоком обучении графы обычно недостаточно ограничительны, чтобы еще и обеспечить эффективный вывод. Легко видеть, что вычисление маргинальной вероятности общей графической мо- дели #P – трудная задача. Класс сложности #P – обобщение класса сложности NP. Для класса NP нужно только определить, есть ли у задачи решение, и, если есть, найти какое-нибудь. В случае класса #P требуется подсчитать число решений. Для построе- ния графической модели в худшем случае рассмотрим определение модели над би- нарными переменными в задаче выполнимости булевых формул в k-конъюнктивной нормальной форме (3-SAТ). Мы можем считать, что эти переменные равномерно распределены, а затем добавить по одной бинарной латентной переменной на каж- дый дизъюнкт, которая показывает, выполняется ли этот дизъюнкт. Далее добавля-ется еще одна латентная переменная, показывающая, выполняются ли все дизюнкты. Это можно сделать, не создавая большую клику, путем построения дерева редукции латентных переменных, в котором каждый узел дерева сообщает, выполнены ди две другие переменные. Листьями этого дерева являются переменные для каждого дизъ-юнкта. Тогда корень дерева сообщает, выполнена ли вся формула. Вследствие рав-номерного распределения литералов маргинальное распределение корня дерева ре-дукции определяет долю комбинаций значений переменных, решающих задачу. Это искусственный пример худшего случая, но NP-трудные графы регулярно возникают в практических ситуациях. Следовательно, необходим приближенный вывод. В контексте глубокого обуче- ния под этим обычно понимают вариационный вывод, когда истинное распределение\n--- Страница 492 ---\nПодход глубокого обучения к структурным вероятностным моделям  491 p(h | v) аппроксимируется максимально близким к нему распределением q(h | v). Эта и другие техники более подробно описаны в главе 19. 16.7. Подход глубокого обучения к структурным вероятностным моделям Специалисты по глубокому обучению на практике пользуются тем же базовым вы- числительным инструментарием, что и другие специалисты по машинному обучению, работающие со структурными вероятностными моделями. Но мы обычно по-другому комбинируем инструменты, так что получающиеся алгоритмы и модели сильно от- личаются от традиционных графических моделей. В глубоком обучении не всегда применяются очень уж глубокие графические мо- дели. Глубина графической модели определяется в терминах ее графа, а не графа вы- числений. Будем говорить, что глубина латентной переменной h i равна j, если крат- чайший путь от hi к наблюдаемой переменной состоит из j шагов. Глубиной модели называется максимальная глубина по всем таким переменным hi. Так определенная глубина отличается от глубины, индуцированной графом вычислений. Во многих по-рождающих моделях, встречающихся в глубоком обучении, латентных переменных нет вообще или имеется всего один слой таких переменных, но при этом использу-ются графы вычислений для определения условных распределений внутри модели. По существу, в глубоком обучении всегда присутствует идея распределенных представлений. Даже мелкие модели, применяемые для целей глубокого обучения (например, предобучение мелких моделей, из которых впоследствии будет состав-лена глубокая), почти всегда содержат один большой слой латентных переменных. В моделях глубокого обучения латентных переменных, как правило, больше, чем на- блюдаемых. Сложные нелинейные взаимодействия между переменными имеют вид непрямых соединений, включающих несколько латентных переменных. Напротив, в традиционных графических моделях большинство переменных хотя бы изредка наблюдается, даже если многие из них отсутствуют в некоторых обучаю- щих примерах. В традиционных моделях по большей части используются члены выс- шего порядка и техника структурного обучения, чтобы выявить сложные нелиней- ные взаимодействия между переменными. Если латентные переменные и есть, то их обычно немного. Методы проектирования латентных переменных в глубоком обучении также отли- чаются. Обычно проектировщик не стремится заранее придать латентным перемен-ным какую-то определенную семантику – алгоритм обучения свободен придумывать любые концепции, необходимые для моделирования конкретного набора данных. В большинстве случае человеку нелегко интерпретировать латентные переменные по завершении обучения, хотя существуют методы визуализации, позволяющие хотя бы примерно понять, что именно они представляют. Когда латентные переменные используются в традиционных графических моделях, им часто приписывается впол- не определенная семантика – тема документа, интеллектуальный уровень студента, болезнь, вызвавшая у пациента наблюдаемые симптомы, и т. д. Такие модели гораздо проще для интерпретации и зачастую имеют больше теоретических гарантий, но они хуже масштабируются на сложные задачи и, в отличие от глубоких моделей, не до- пускают повторного использования в различных контекстах.\n--- Страница 493 ---\n492  Структурные вероятностные модели в глубоком обучении Еще одно очевидное различие связано с типом связности, который обычно встре- чается в глубоком обучении. В типичной глубокой графической модели имеются большие группы блоков, каждый из которых связан с другими группами, так что взаимодействия между двумя группами можно описать одной матрицей. В традици- онных графических моделях связей очень мало, и выбор связей для каждой пере- менной часто проектируется вручную. Проектирование структуры модели тесно связано с выбором алгоритма вывода. В традиционных подходах целью обычно яв- ляется практическая реализуемость точного вывода. Если это ограничение слишком сильное, применяется популярный алгоритм приближенного вывода – циклическое распространение доверия. Оба подхода часто хорошо работают с разреженными графами. Для сравнения – в моделях, применяемых в глубоком обучении, каждый видимый блок v i обычно связан со многими скрытыми блоками hj, так чтобы h могло служить распределенным представлением vi (и, быть может, еще нескольких наблю- даемых переменных). У распределенных представлений много достоинств, но с точки зрения графических моделей и вычислительной сложности у них есть недостаток – они обычно приводят к графам, недостаточно разреженным для применения тради- ционных методов вывода и циклического распространения доверия. Поэтому одно из самых разительных отличий между графическими моделями вообще и глубокими графическими моделями состоит в том, что метод циклического распространения до- верия почти никогда не применяется для глубокого обучения. Вместо этого глубокие модели проектируются так, чтобы были эффективны алгоритмы выборки по Гиббсу или вариационного вывода. Еще следует принять во внимание, что поскольку модели глубокого обучения содержат очень много латентных переменных, на первый план выходит эффективность численных методов. Это дополнительный (помимо выбо-ра высокоуровневого алгоритма вывода) довод в пользу группировки блоков в слои с помощью матрицы, описывающей взаимодействие между двумя слоями. Это по- зволяет реализовать отдельные шаги алгоритма посредством эффективных операций умножения матриц или их обобщений на разреженные графы, например перемноже-ния блочно-диагональных матриц или свертки. Наконец, для глубокого подхода к графическому моделированию характерна от- кровенная терпимость к неизвестному. Вместо того чтобы упрощать модель до тех пор, пока не появится возможность точно вычислить все интересующие нас вели-чины, мы увеличиваем мощность модели до такой степени, что ее едва-едва можно обучить или использовать. Часто мы используем модели, маргинальные распределе- ния которых вычислить невозможно, и довольствуемся возможностью произвести из них приближенную выборку. Встречаются модели с неразрешимой целевой функци- ей, которую даже аппроксимировать за разумное время невозможно, но тем не менее мы умудряемся приближенно обучить ее, если удается эффективно оценить градиент такой функции. Подход глубокого обучения зачастую состоит в том, чтобы понять, какой минимум информации абсолютно необходим, а затем придумать, как в крат- чайшие сроки получить разумную аппроксимацию этой информации. 16.7.1. Пример: ограниченная машина Больцмана Ограниченная машина Больцмана (ОМБ) (Smolensky, 1986), или гармониум, – ти- пичный пример применения графических моделей в глубоком обучении. Сама по себе ОМБ не является глубокой моделью. У нее есть один слой латентных перемен-\n--- Страница 494 ---\nПодход глубокого обучения к структурным вероятностным моделям  493 ных, который можно использовать для представления входа. В главе 20 мы увидим, как можно использовать ОМБ для построения различных более глубоких моделей. А сейчас покажем, как ОМБ на практике воплощает многие идеи, применяемые в раз- нообразных глубоких графических моделях: ее блоки организованы в большие груп- пы, называемые слоями, связи между слоями описываются матрицей, связность от-носительно плотная, при проектировании модели учтена возможность выборки по Гиббсу, и акцент сделан на том, чтобы предоставить алгоритму обучения свободу вы- являть латентные переменные, семантика которых не была задана проектировщиком. В разделе 20.2 мы еще вернемся к ОМБ. Каноническая ОМБ – это энергетическая модель с бинарными видимыми и скры- тыми блоками. Ее функция энергии имеет вид E(v, h) = –b ⏉v – c⏉h – v⏉Wh, (16.10) где b, c и W – вещественные подлежащие обучению параметры, на которые не накла- дываются ограничения. Видно, что модель разбита на две группы блоков: v и h – и что взаимодействие между ними описывается матрицей W. Графически модель показана на рис. 16.14. Как ясно по рисунку, важным аспектом модели является отсутствие прямых взаимодействий между любыми двумя видимыми или любыми двумя скры-тыми блоками (отсюда и слово «ограниченная»; в произвольной машине Больцмана допустимы любые связи). Рис. 16.14  ОМБ в виде марковской сети Из ограничений на структуру ОМБ вытекают полезные свойства: p(h | v) = ∏ip(hi | v) (16.11) и p(v | h) = ∏ip(vi | h). (16.12) Отдельные условные вероятности также легко вычислить. Для бинарной ОМБ по- лучаем: P(hi = 1 | v) = σ(v⏉W:, i + bi), (16.13) P(hi = 0 | v) = 1 – σ(v⏉W:, i + bi). (16.14) В совокупности эти свойства позволяют эффективно производить блочную вы- борку по Гиббсу, когда выборка сразу всего h чередуется с выборкой сразу всего v. Примеры, полученные в результате выборки по Гиббсу из модели ОМБ, показаны на рис. 16.15.\n--- Страница 495 ---\n494  Структурные вероятностные модели в глубоком обучении Рис. 16.15  Выборка из обученной ОМБ вместе с весами. (Слева) При- меры из модели, обученной на наборе данных MNISТ , полученные с по- мощью выборки по Гиббсу. Каждый столбец – результат независимого про- цесса выборки. В каждой строке представлены результаты еще 1000 шагов выборки по Гиббсу. Соседние примеры сильно коррелированы между со- бой. (Справа) Соответствующие векторы весов. Сравните с примерами и весами для линейной факторной модели на рис. 13.2. Здесь примеры го- раздо лучше, потому априорное распределение p(h) не обязано быть фак- торным. В процессе выборки ОМБ может обучиться тому, какие признаки должны присутствовать вместе. С другой стороны, апостериорное распре- деление ОМБ p(h | v) факторное, тогда как апостериорное распределение разреженного кодирования таковым не является, поэтому модель разре-женного кодирования может оказаться лучше для выделения признаков. Существуют и другие модели, в которых оба распределения p(h) и p(h | v) нефакторные. Изображение взято из работы LISA (2008) Поскольку функция энергии линейно зависит от параметров, ее производные лег- ко вычисляются, например: (16.15) Эти два свойства: эффективная выборка по Гиббсу и эффективное вычисление производных – способствуют удобству обучения. В главе 18 мы увидим, что неори- ентированные модели можно обучать посредством вычисления таких производных для выборки из модели. Обучение модели индуцирует представление h данных v. Часто можно использо- вать 𝔼 h∼p(h |v)[h] как набор признаков для описания v. В целом ОМБ демонстрирует типичный подход глубокого обучения к графиче- ским моделям: обучение представления в виде слоев латентных переменных в соче- тании с эффективным взаимодействием между слоями, параметризованными с по- мощью матриц. Графические модели предлагают элегантный, гибкий и ясный язык для описания вероятностных моделей. В следующих главах мы воспользуемся им (наряду с други- ми идеями) для описания широкого круга глубоких вероятностных моделей.",
      "debug": {
        "start_page": 470,
        "end_page": 495
      }
    },
    {
      "name": "Глава 17. Методы Монте-Карло 495",
      "content": "--- Страница 496 --- (продолжение)\nГлава 17 Методы Монте-Карло Рандомизированные алгоритмы можно отнести к двум большим категориям: алго- ритмы Лас-Вегаса и алгоритмы Монте-Карло. Алгоритм Лас-Вегаса всегда должен вернуть точный и правильный ответ (или сообщить об ошибке). Такие алгоритмы потребляют случайный объем ресурсов, обычно памяти или времени. Напротив, ал- горитм Монте-Карло возвращает ответ со случайной ошибкой. Величину ошибки, как правило, можно уменьшить, увеличив потребление ресурсов (обычно времени работы или объема памяти). При любом фиксированном бюджете ресурсов алгоритм Монте-Карло может выдать приближенный ответ. Многие задачи машинного обучения настолько трудны, что рассчитывать на полу- чение точного ответа не приходится. Это сразу исключает точные детерминирован-ные алгоритмы и алгоритмы Лас-Вегаса. Вместо них мы должны обходиться прибли- женными детерминированными алгоритмами или алгоритмами Монте-Карло. Оба подхода встречаются в машинном обучении повсеместно. В этой главе мы займемся методами Монте-Карло. 17.1. Выборка и методы Монте-Карло Многие важные технологии, применяемые в машинном обучении, основаны на вы- борке примеров из некоторого распределения вероятности и их использовании для вычисления оценки интересующей величины по методу Монте-Карло. 17.1.1. Зачем нужна выборка? Желание произвести выборку из распределения вероятности может возникнуть по разным причинам. Выборка – это гибкий способ относительно дешевой аппроксима- ции многих сумм и интегралов. Иногда мы применяем его, чтобы существенно уско- рить хоть и осуществимое, но дорогостоящее вычисление; например, с помощью ми- ни-пакетов мы уменьшаем полную стоимость обучения. В других случаях алгоритм обучения требует аппроксимировать недоступную для прямого вычисления сумму или интеграл, например градиент логарифма статистической суммы неориентиро-ванной модели. Бывает также, что выборка и есть конечная цель в том смысле, что мы хотим обучить модель, которая будет производить выборку из обучающего рас-пределения. 17.1.2. Основы выборки методом Монте-Карло Если сумму или интеграл нельзя вычислить точно (например, число слагаемых экспо-ненциально велико и, как упростить сумму, неизвестно), то часто можно аппроксими-\nГлава 17 Методы Монте-Карло Рандомизированные алгоритмы можно отнести к двум большим категориям: алго- ритмы Лас-Вегаса и алгоритмы Монте-Карло. Алгоритм Лас-Вегаса всегда должен вернуть точный и правильный ответ (или сообщить об ошибке). Такие алгоритмы потребляют случайный объем ресурсов, обычно памяти или времени. Напротив, ал- горитм Монте-Карло возвращает ответ со случайной ошибкой. Величину ошибки, как правило, можно уменьшить, увеличив потребление ресурсов (обычно времени работы или объема памяти). При любом фиксированном бюджете ресурсов алгоритм Монте-Карло может выдать приближенный ответ. Многие задачи машинного обучения настолько трудны, что рассчитывать на полу- чение точного ответа не приходится. Это сразу исключает точные детерминирован-ные алгоритмы и алгоритмы Лас-Вегаса. Вместо них мы должны обходиться прибли- женными детерминированными алгоритмами или алгоритмами Монте-Карло. Оба подхода встречаются в машинном обучении повсеместно. В этой главе мы займемся методами Монте-Карло. 17.1. Выборка и методы Монте-Карло Многие важные технологии, применяемые в машинном обучении, основаны на вы- борке примеров из некоторого распределения вероятности и их использовании для вычисления оценки интересующей величины по методу Монте-Карло. 17.1.1. Зачем нужна выборка? Желание произвести выборку из распределения вероятности может возникнуть по разным причинам. Выборка – это гибкий способ относительно дешевой аппроксима- ции многих сумм и интегралов. Иногда мы применяем его, чтобы существенно уско- рить хоть и осуществимое, но дорогостоящее вычисление; например, с помощью ми- ни-пакетов мы уменьшаем полную стоимость обучения. В других случаях алгоритм обучения требует аппроксимировать недоступную для прямого вычисления сумму или интеграл, например градиент логарифма статистической суммы неориентиро-ванной модели. Бывает также, что выборка и есть конечная цель в том смысле, что мы хотим обучить модель, которая будет производить выборку из обучающего рас-пределения. 17.1.2. Основы выборки методом Монте-Карло Если сумму или интеграл нельзя вычислить точно (например, число слагаемых экспо-ненциально велико и, как упростить сумму, неизвестно), то часто можно аппроксими-\n--- Страница 497 ---\n496  Методы Монте-Карло ровать ее с помощью выборки методом Монте-Карло. Идея в том, чтобы рассмат ривать сумму или интеграл как математическое ожидание относительно некоторого распре- деления и аппроксимировать его с помощью соответствующего среднего. Обозначим (17.1) или (17.2) подлежащую оценке сумму или интеграл, переписанные в виде математического ожидания, с тем ограничением, что p – распределение вероятности (в случае суммы) или плотность вероятности (в случае интеграла) случайной величины x. Мы можем аппроксимировать s, произведя выборку объема n из p: x(1), …, x(n), а за- тем вычислив эмпирическое среднее: (17.3) В обоснование такой аппроксимации можно привести несколько соображений. Первое тривиальное наблюдение заключается в том, что оценка sˆ несмещенная, т. к. (17.4) Кроме того, согласно закону больших чисел, если примеры x(i) независимы и оди- наково распределены, то средние почти наверняка сходятся к математическому ожи- данию: (17.5) при условии что дисперсия отдельных членов Var[f(x(i))] ограничена. Чтобы убедить- ся в этом, рассмотрим дисперсию sˆn с ростом n. Дисперсия Var[s ˆn] убывает и сходится к 0, коль скоро Var[f(x(i))] ] < ∞: , (17.6) (17.7) Этот полезный результат заодно говорит, как оценить недостоверность среднего Монте-Карло, или, эквивалентно, величину ожидаемой погрешности аппроксимации Монте-Карло. Мы вычисляем одновременно эмпирическое среднее f[(x (i))] и эмпи- рическую дисперсию1, а затем делим оценку дисперсии на число примеров n для по- лучения оценки Var[s ˆn]. Согласно центральной предельной теореме, распределение среднего sˆn сходится к нормальному распределению со средним значением s и дис- персией Var[f(x)]/n. Это позволяет оценить доверительные интервалы вокруг оцен-ки sˆ n с помощью интегральной функции распределения нормальной плотности. 1 Часто предпочтительнее несмещенная оценка дисперсии, в которой сумма квадратов раз- ностей делится на n – 1, а не n.\n--- Страница 498 ---\nВыборка по значимости  497 Все это опирается на возможность произвести выборку из базового распределения p(x), что, однако, не всегда возможно. Если выборка из p не осуществима, то мож- но вместо нее воспользоваться выборкой по значимости, описанной в разделе 17.2. Более общий подход – построить последовательность оценок, сходящуюся к интере- сующему нас распределению; он называется методом Монте-Карло по схеме марков- ских цепей (раздел 17.3). 17.2. Выборка по значимости Важным шагом в декомпозиции подынтегрального выражения (или слагаемого) в выражении (17.2) является решение о том, какая его часть будет выступать в роли вероятности p(x), а какая – в роли случайной величины f(x), математическое ожида- ние которой (относительно данного распределения) мы хотим оценить. Не сущест-вует однозначно определенной декомпозиции, потому что p(x)f(x) всегда можно переписать в виде (17.8) так что выборка теперь производится из q, а оцениваемой величиной является pf/q. Во многих случаях мы хотим вычислить математическое ожидание для заданных p и f, и поскольку задача с самого начала поставлена как нахождение математического ожидания, то декомпозиция на p и f выглядит естественно. Однако исходная поста- новка задачи может быть неоптимальна с точки зрения количества примеров, необхо- димых для достижения заданной точности. По счастью, легко вывести, как выглядит оптимальный выбор q *. Оптимальное q* соответствует так называемой оптимальной выборке по значимости. В силу тождества (17.8) любую оценку Монте-Карло (17.9) можно преобразовать в оценку выборки по значимости (17.10) Легко видеть, что математическое ожидание оценки не зависит от q: 𝔼q[sˆq] = 𝔼q[sˆp] = s. (17.11) Однако дисперсия оценки выборки по значимости может быть весьма чувстви- тельна к выбору q. Дисперсия вычисляется по формуле (17.12) Минимум дисперсии достигается, когда q равно (17.13)\n--- Страница 499 ---\n498  Методы Монте-Карло где Z – нормировочная постоянная, выбранная так, чтобы сумма или интеграл q*(x) были равны 1. В лучших выборочных распределениях по значимости вес больше там, где больше подынтегральное выражение. На самом деле если f(x) не меняет знак, то Var[sˆq*] = 0, т. е. при использовании оптимального распределения достаточно одного примера. Конечно, так происходит только потому, что вычисление q* по существу уже решило исходную задачу, так что на практике не имеет особого смысла производить выборку одного примера из оптимального распределения. Допустимо любое выборочное распределение q (в том смысле, что оно дает пра- вильное значение математического ожидания), а q* является оптимальным (в том смысле, что дает минимальную дисперсию). Выборка из q* обычно неосуществима, но при другом выборе q может оказаться возможной, и при этом дисперсия все равно уменьшается. Еще один подход состоит в использовании смещенной выборки по значимости, для которой не требуется нормировать p или q. Для дискретных случайных величин оценка смещенной выборки по значимости определяется по формуле (17.14) (17.15) (17.16) где p~ и q~ – ненормированные формы p и q, а x(i) – выборка из q. Эта оценка смещена, потому что 𝔼[sˆBIS] ≠ s, а лишь асимптотически приближается к s, когда n → ∞ и знаме- натель в выражении (17.14) стремится к 1. Поэтому эта оценка называется асимпто- тически несмещенной. Хороший выбор q может значительно повысить эффективность оценки методом Монте-Карло, но при плохом выборе эффективность может резко снизиться. Возвра-щаясь к формуле (17.12), мы видим, что если существуют выборочные примеры из q, для которых (p(x)| f(x)|)/q(x) принимает большие значения, то дисперсия оценки будет очень велика. Так может случиться, если q(x) близка к нулю, а p(x) и f(x) не- достаточно малы, чтобы компенсировать это. Распределение q обычно выбирается простым, чтобы из него было легко произвести выборку. Когда размерность x велика, простое распределение q плохо аппроксимирует p или p|f|. Если q(x (i)) ≫ p(x(i))|f(x(i))|, то выборка по значимости содержит бесполезные примеры (суммируются очень ма-лые или нулевые значения). С другой стороны, если q(x (i)) ≪ p(x(i))|f(x(i))|, что случа- ется реже, то отношение будет очень велико. Поскольку такие события встречаются редко, в типичной выборке они могут отсутствовать, поэтому, как правило, мы по- лучаем заниженную оценку s, которая изредка компенсируется сильно завышенной\n--- Страница 500 ---\nМетоды Монте-Карло по схеме марковской цепи  499 оценкой. Такие очень большие или очень малые числа типичны при высокой размер- ности x, поскольку в этом случае динамический диапазон совместных вероятностей может быть очень широк. Несмотря на эту опасность, выборка по значимости и ее варианты оказались очень полезными во многих алгоритмах машинного обучения, в т. ч. глубокого. Например, она применяется для ускорения обучения в нейронных языковых моделях с большим словарем (раздел 12.4.3.3) и в других нейронных сетях с большим количеством вы- ходов. См. также описание использования выборки по значимости для оценивания статистической суммы (нормировочной постоянной распределения вероятности) в разделе 18.7 и для оценивания логарифмического правдоподобия в таких глубоких моделях, как вариационный автокодировщик, – в разделе 20.10.3. Выборка по зна- чимости полезна также для улучшения оценки градиента функции стоимости при обуче нии параметров модели методом стохастического градиентного спуска, особен- но в моделях типа классификаторов, где основная часть величины функции стоимо- сти приходится на небольшое число неправильно классифицированных примеров. В таких случаях более частая выборка более трудных примеров может уменьшить дисперсию градиента (Hinton, 2006). 17.3. Методы Монте-Карло по схеме марковской цепи Во многих случаях мы хотели бы воспользоваться методом Монте-Карло, но не- возможно произвести точную выборку из распределения pmodel(x) или из хорошего (с низкой дисперсией) выборочного распределения по значимости q(x). В контекс- те глубокого обучения так чаще всего происходит, когда pmodel(x) представлено не- ориентированной моделью. В таких случаях применяется математический аппарат марковских цепей для приближенной выборки из pmodel(x). Семейство алгоритмов, в которых для получения оценки методом Монте-Карло используются марковские цепи, называется методами Монте-Карло по схеме марковской цепи (Markov chain Monte Carlo – MCMC). Применение MCMC-методов в машинном обучении под- робно описано в книге Koller and Friedman (2009). Стандартные общие гарантии для MCMC-методов применимы, только когда модель не назначает ни одному состоя-нию нулевую вероятность. Поэтому их удобно представлять как выборку из энер- гетической модели p(x) ∝ exp (–E(x)), описанной в разделе 16.2.4, поскольку в этом случае гарантируется, что вероятности всех состояний ненулевые. На самом деле сфера применения MCMC-методов шире, их можно использовать и для многих рас- пределений вероятности, включающих состояния с нулевой вероятностью. Однако теоретические гарантии относительно их поведения следует доказывать для каждого такого семейства распределений отдельно. В глубоком обучении принято полагаться на общие теоретические результаты, естественно распространяющиеся на все энерге-тические модели. Чтобы понять, почему выборка из энергетической модели – трудное дело, рассмот- рим энергетическую модель с двумя переменными, определяющую распределение p(a, b). Для выбора a мы должны произвести выборку из p(a | b), а для выбора b – из p(b | a). Получается неразрешимая проблема «яйцо или курица». В ориентированных моделях такой проблемы не возникает, потому что граф ориентированный и ацикли-\n--- Страница 501 ---\n500  Методы Монте-Карло ческий. Чтобы произвести предковую выборку, мы просто выбираем значение каждой случайной величины в порядке топологической сортировки при условии ее родите- лей, для которых выборка уже гарантированно произведена (см. раздел 16.3). Пред- ковая выборка определяет эффективный однопроходный метод получения выборки. В энергетической модели порочный круг можно разорвать посредством выборки с применением марковской цепи. Основная идея марковской цепи – взять состояние x, начинающееся с произвольного значения. С течением времени мы случайным об- разом изменяем x. В конечном итоге x приближается к истинной выборке из p(x). Формально говоря, марковская цепь определяется случайным состоянием x и пере- ходным распределением T(x′ | x), задающим вероятность того, что случайное из- менение переведет состояние x в состояние x′. Под выполнением марковской цепи понимается многократный переход из состояния x в состояние x′ в соответствии с распределением T(x ′ | x). Для теоретического осмысления принципов работы MCMC-методов полезно бу- дет перепараметризовать задачу. Сначала сосредоточимся на случае, когда множество состояний случайной величины x счетно. Тогда любое состояние можно представить целым положительным числом x. Различные целые значения x можно затем отобра- зить на различные значения x в исходной задаче. Посмотрим, что произойдет, если параллельно выполнять бесконечно много мар- ковских цепей. Все состояния марковских цепей выбираются из некоторого распре-деления q (t)(x), где t – число уже произведенных шагов. В начальный момент q(0) – не- которое распределение, которое мы использовали для произвольной инициализации x для каждой марковской цепи. Затем на q (t) оказывают влияние все уже произведен- ные шаги марковской цепи. Наша цель – добиться, чтобы q(t)(x) сходилось к p(x). Поскольку мы перепараметризовали задачу в терминах целого положительного x, то можем описать распределение вероятности q с помощью вектора v – такого, что q(x = i) = vi. (17.17) Посмотрим, что происходит, когда состояние x одной марковской цепи изменяется на x′. Вероятность, что новым состоянием будет x ′, равна (17.18) Пользуясь целочисленной параметризацией, мы можем представить действие опе- ратора перехода T с помощью матрицы A. Определим A следующим образом: Ai, j = T(x ′ = i | x = j). (17.19) Перепишем формулу (17.18), воспользовавшись этим определением. Вместо того чтобы использовать q и T для описания изменения одного состояния, мы можем с по- мощью v и A описать, как меняется распределение всех марковских цепей (выпол- няемых параллельно) после перехода состояния: v(t) = Av(t–1). (17.20) Изменение состояния марковской цепи соответствует умножению на матрицу A. Иными словами, весь процесс можно описать как возведение матрицы A в степень: v(t) = Atv(0). (17.21)\n--- Страница 502 ---\nМетоды Монте-Карло по схеме марковской цепи  501 Матрица A обладает специальной структурой, поскольку ее столбцы представляют распределения вероятности. Такие матрицы называются стохастическими. Если су- ществует ненулевая вероятность перехода из любого состояния x в любое другое со- стояние x′ для некоторой степени t, то по теореме Перрона–Фробениуса (Perron, 1907; Frobenius, 1908) наибольшее собственное значение матрицы вещественно и равно 1. Мы видим, что с течением времени все собственные значения возводятся в степень: v(t) = (V diag(λ)V–1)t v(0) = V diag(λ)tV–1v(0). (17.22) В результате все собственные значения, не равные 1, стремятся к нулю. При неко- торых довольно мягких условиях гарантируется, что A имеет только один собствен- ный вектор с собственным значением 1. Поэтому процесс сходится к стационарному распределению, которое иногда называют равновесным распределением. В пределе v′ = Av = v, (17.23) и это условие справедливо для каждого дополнительного шага. Это не что иное, как уравнение собственного вектора. Чтобы оказаться стационарной точкой, v должен быть собственным вектором с собственным значением 1. Это условие гарантиру- ет, что после достижения стационарного распределения последующее применение процедуры переходной выборки не изменяет распределения состояний всех марков- ских цепей (хотя, разумеется, оператор перехода изменяет каждое отдельное со-стояние). Если T выбрано правильно, то стационарное распределение q будет совпадать с распределением p, из которого мы хотим производить выборку. В разделе 17.4 мы расскажем, как выбирать T. Большую часть свойств марковских цепей со счетным множеством состояний можно обобщить на непрерывные величины. В такой ситуации некоторые авторы на- зывают марковскую цепь цепью Харриса, но мы будем в обоих случаях использовать термин «марковская цепь». В общем случае марковская цепь с оператором перехода T сходится (при довольно мягких условиях) к неподвижной точке, описываемой урав- нением q′(x′) = 𝔼 x∼qT(x′ | x), (17.24) которое в дискретном случае сводится к уравнению (17.23). Если x – дискретная ве- личина, то математическое ожидание записывается в виде суммы, а если непрерыв- ная, то в виде интеграла. Независимо от того, является состояние непрерывной или дискретной случайной величиной, все методы на основе марковских цепей заключаются в повторном при- менении стохастического обновления до тех пор, пока состояние не начнет давать вы- борку из равновесного распределения. Выполнение марковской цепи до достижения равновесного распределения называется приработкой марковской цепи. Затем из равновесного распределения можно выбирать бесконечно много примеров. Все они имеют одинаковое распределение, но любые два соседних примера сильно коррелиро-ваны между собой. Поэтому конечная последовательность примеров может оказаться недостаточно репрезентативной выборкой из равновесного распределения. Один из путей смягчения этой проблемы – возвращать каждый n-ый пример, чтобы оценка ста-\n--- Страница 503 ---\n502  Методы Монте-Карло тистики равновесного распределения была в меньшей степени смещена из-за корре- ляции между каждым примером и несколькими следующими за ним. Использованию марковских цепей присущи высокие накладные расходы из-за времени приработки к равновесному распределению и времени перехода от одного примера к следующему, слабо коррелированному с ним, уже после достижения равновесия. Если необходимы действительно независимые примеры, то можно параллельно выполнять несколько марковских цепей. При таком подходе применяется распараллеливание вычислений, чтобы избежать задержки. Стратегия использования единственной марковской цепи для порождения всех примеров и стратегия использования отдельной цепи для каж- дого примера – две крайности; на практике в глубоком обучении количество цепей берут примерно равным числу примеров в мини-пакете, а затем выбирают столько примеров, сколько нужно, из этого фиксированного набора марковских цепей. Число цепей часто равно 100. Еще одна трудность связана с тем, что мы заранее не знаем, сколько нужно вы- полнить шагов, прежде чем марковская цепь достигнет равновесного распределения. Этот промежуток времени иногда называют временем приработки, или временем перемешивания (mixing time). Проверить, достигла ли марковская цепь равновесия, тоже трудно. Теория недостаточно точна для ответа на этот вопрос. Утверждается лишь, что цепь сходится, но не более того. Анализ марковской цепи с точки зрения воздействия матрицы A на вектор вероятностей v показывает, что цепь приработа- лась, когда A t потеряла практически все собственные значения A, кроме единствен- ного, равного 1. Это означает, что абсолютная величина второго по величине соб-ственного значения определяет время перемешивания. Но на практике мы не можем представить марковскую цепь матрицей. Число возможных состояний вероятност-ной модели экспоненциально зависит от числа переменных, поэтому представить v, A или собственные значения A не получится. Из-за этого и других препятствий мы обычно не знаем, приработалась ли цепь. Вместо этого мы просто даем цепи прорабо-тать какое-то время, которое считаем достаточным, исходя из грубой оценки, и при- меняем эвристические методы, чтобы понять, приработалась ли цепь. К числу таких методов относится просмотр примеров вручную или измерение корреляции между соседними примерами. 17.4. Выборка по Гиббсу До сих пор мы говорили о том, как производить выборку из распределения q(x) путем повторного обновления x ← x′ ∼ T(x′ | x). Мы ничего не сказали о том, как убедить- ся, что q(x) – полезное распределение. В этой книге рассматриваются два основных подхода. Первый – вывести T из заданного обученного распределения pmodel – описан ниже вместе со случаем выборки из энергетической модели. Второй – непосредствен- но параметризовать и обучить T, так чтобы его стационарное распределение неявно определяло интересующее нас распределение pmodel. Примеры второго подхода обсуж- даются в разделах 20.12 и 20.13. В контексте глубокого обучения мы обычно используем марковские цепи, что- бы производить выборку из энергетической модели, определяющей распределение p model(x). В этом случае мы хотим, чтобы распределение q(x) для марковской цепи сов падало с pmodel(x). Для получения желаемого q(x) необходимо выбрать подходя- щее распределение T(x ′ | x).\n--- Страница 504 ---\nПроблема перемешивания разделенных мод  503 Концептуально простой и эффективной способ построения марковской цепи, ко- торая производит выборку из pmodel(x), дает выборка по Гиббсу, когда выборка из T(x′ | x) производится путем выбора одной величины xi и выборки ее значений из pmodel при условии соседей в неориентированном графе 𝒢, определяющем структуру энерге- тической модели. Мы можем также одновременно производить выборку нескольких величин, если только они условно независимы при условии всех своих соседей. Как показано в примере ОМБ в разделе 16.7.1, из всех скрытых блоков можно произво- дить выборку одновременно, потому что они условно независимы друг от друга при условии всех видимых блоков. И точно так же можно одновременно производить вы- борку из всех видимых блоков, потому что они условно независимы друг от друга при условии всех скрытых блоков. Если одновременно обновляется несколько величин, то говорят о блочной выборке по Гиббсу. Есть и другие подходы к проектированию марковских цепей для выборки из p model. Например, в других дисциплинах широко используется алгоритм Метрополиса–Га- стингса. Но в глубоком обучении применительно к неориентированному моделиро- ванию редко применяется что-то, кроме выборки по Гиббсу. У лучшение методов вы-борки – передний край исследований. 17.5. Проблема перемешивания разделенных мод Главная трудность, присущая MCMC-методам, – плохое перемешивание. В идеале последовательные примеры, выбранные из марковской цепи, спроектированной для выборки из p(x), должны быть абсолютно независимы, и частота попадания в различ- ные области пространства x должна быть пропорциональна вероятности области. На самом же деле, особенно в пространствах высокой размерности, примеры, выбранные MCMC-методом, оказываются сильно коррелированными. То есть налицо медленное перемешивание или даже полное отсутствие перемешивания. Можно считать, что MCMC-методы с медленным перемешиванием непреднамеренно выполняют нечто вроде зашумленного градиентного спуска вдоль функции энергии, или, эквивалентно, зашумленного восхождения на вершину функции вероятности относительно состоя-ния цепи (отбираемых случайных величин). Цепь демонстрирует тенденцию к малым шагам (в пространстве состояний марковской цепи) из конфигурации x (t–1) в конфи- гурацию x(t), когда энергия E(x(t)) в общем случае меньше или приблизительно равна энергии E(x(t–1)), причем предпочтение отдается переходам в конфигурации с более низкой энергией. Начав с маловероятной конфигурации (энергия выше, чем для ти- пичных примеров, выбранных из p(x)), цепь стремится постепенно уменьшать энер- гию состояния и лишь изредка переходит на другую моду. После того как цепь нашла область низкой энергии (например, в случае, когда случайными величинами являются пиксели изображения, областью низкой энергии может быть связное многообразие изображений одного и того же объекта), которую мы называем модой, она начинает перемещаться вокруг этой моды (совершая своего рода случайное блуждание). Вре-мя от времени цепь покидает эту моду и либо возвращается к ней, либо (если найдет путь выхода) переходит к другой моде. Проблема в том, что для многих интересных распределений успешные пути выхода встречаются редко, поэтому марковская цепь продолжает выбирать примеры из одной и той же моды дольше, чем хотелось бы. Это очень наглядно проявляется при рассмотрении алгоритма выборки по Гиббсу (раздел 17.4). В этом контексте рассмотрим вероятность перехода из одной моды в со-\n--- Страница 505 ---\n504  Методы Монте-Карло седнюю за данное количество шагов. Эта вероятность определяется формой «энерге- тического барьера» между модами. Переходы между модами, разделенными высоким барьером (областью низкой вероятности), экспоненциально менее вероятны (в тер- минах высоты барьера). Это показано на рис. 17.1. Проблема возникает, когда есть несколько мод с высокой вероятностью, разделенных областями низкой вероятности, особенно если каждый шаг выборки по Гиббсу должен обновить только небольшое подмножество переменных, значения которых в основном определяются другими переменными. Рис. 17.1  Пути следования выборки по Гиббсу для трех распределе- ний, во всех случаях марковская цепь инициализирована внутри моды. (Слева) Многомерное нормальное распределение двух независимых ве- личин. Выборка по Гиббсу хорошо перемешивается, поскольку величины независимы. (В центре) Многомерное нормальное распределение сильно коррелированных величин. Из-за корреляции перемешивание марковской цепи затруднено. Поскольку обновление каждой величины должно быть обусловлено другой величиной, наличие корреляции замедляет скорость ухода марковской цепи от начальной точки. (Справа) Смесь нормальных распределений с широко разделенными модами, не находящимися на од- ной оси. Выборка по Гиббсу перемешивается очень медленно, потому что трудно сменить моду, изменяя в каждый момент времени только одну ве- личину В качестве простого примера рассмотрим энергетическую модель двух бинарных случайных величин a и b, принимающих значения –1 и 1. Если E(a, b) = –wab для большого положительного числа w, то модель выражает сильную веру в то, что зна- ки a и b одинаковы. Рассмотрим обновление b посредством шага выборки по Гиббсу с a = 1. Условное распределение b описывается формулой P(b = 1 | a = 1) = σ(w). Если w велико, то сигмоида насыщается, и вероятность, что b тоже будет присвоено значение 1, близка к 1. Аналогично, если a = –1, то вероятность, что и b будет равно –1, близка к 1. Согласно распределению Pmodel(a, b), знаки обеих величин равновероятны. Со- гласно же Pmodel(a | b), обе величины должны иметь одинаковый знак. Следовательно, выборка по Гиббсу очень редко изменяет знаки этих величин. На практике проблема даже более серьезна, потому что нас интересуют не только переходы между двумя модами, но и вообще между всеми многочисленными модами, присутствующими в реальной модели. Если несколько таких переходов затруднено из-за сложности перемешивания мод, то получить надежный набор примеров, охва- тывающий большинство мод, будет чрезвычайно дорого, а сходимость цепи к стацио- нарному распределению окажется очень медленной.\n--- Страница 506 ---\nПроблема перемешивания разделенных мод  505 Иногда проблему можно решить путем нахождения групп сильно зависимых бло- ков и их одновременного обновления. К сожалению, когда зависимости сложны, вы- борка из группы становится вычислительно неразрешимой задачей. В конце концов, проблема, которую марковские цепи и призваны были решить, – это проблема вы- борки из большой группы случайных величин. В контексте моделей с латентными переменными, которые определяют совмест- ное распределение pmodel(x, h), мы часто производим выборку из x, чередуя выборку из pmodel(x | h) с выборкой из pmodel(h | x). С точки зрения скорости перемешивания, мы хотели бы, чтобы у pmodel(h | x) была высокая энтропия. А с точки зрения обуче- ния полезного представления h, нам нужно, чтобы в h было закодировано достаточ- но информации о x для ее успешной реконструкции. Это означает, что взаимная информация h и x должна быть велика. Эти две цели противоречат друг другу. Мы часто обуча ем порождающие модели, которые очень точно кодируют x в h, но плохо перемешиваются. Такая ситуация часто возникает в случае машин Больцмана – чем острее распределение, обучаемое машиной Больцмана, тем сложнее обеспечить хоро- шее перемешивание выборки из распределения модели с помощью марковской цепи. Эта проблема иллюстрируется на рис. 17.2. Все это могло бы снизить полезность MCMC-методов, когда интересующее нас распределение имеет структуру нескольких многообразий, по одному для каждого класса: распределение концентрируется вокруг нескольких мод, разделенных обшир-ными областями высокой энергии. Именно такого типа распределения мы ожидаем во многих задачах классификации, но тогда MCMC-методы сходились бы очень мед-ленно из-за плохого перемешивания мод. Рис. 17.2  Иллюстрация проблемы медленного перемешивания в глубо- ких вероятностных моделях. Каждую таблицу следует читать слева направо сверху вниз. (Слева) Соседние примеры из выборки по Гиббсу, применен-ной к глубокой машине Больцмана, обученной на наборе данных MNISТ . Со- седние примеры похожи друг на друга. Поскольку выборка по Гиббсу про-изводится в глубокой графической модели, это сходство основано скорее на семантике, чем на визуальных признаках, но все равно марковской цепи трудно перейти из одной моды распределения в другую, например путем изменения цифры. (Справа) Соседние примеры для предковой выборки из порождающей состязательной сети. Поскольку предковая выборка порож-дает примеры независимо, то проблемы перемешивания нет\n--- Страница 507 ---\n506  Методы Монте-Карло 17.5.1. Применение темперирования для перемешивания мод Если в распределении имеются острые пики высокой вероятности, окруженные об- ластями низкой вероятности, то перемешивание разных мод затруднено. Несколько приемов повышения скорости перемешивания основано на построении альтернатив-ных вариантов целевого распределения, в котором пики не такие высокие, а окру- жающие их долины не такие низкие. В энергетических моделях сделать это особенно просто. До сих пор мы описывали энергетическую модель как определяющую рас-пределение вероятности вида p(x) ∝ exp (–E(x)). (17.25) Энергетические модели можно дополнить параметром β, контролирующим остро- ту пика: p β(x) ∝ exp (–βE(x)). (17.26) Параметр β часто называют обратной температурой, что отражает истоки энерге- тических моделей – статистическую физику. Когда температура стремится к нулю, а β устремляется к бесконечности, энергетическая модель становится детерминиро- ванной. Если же температура стремится к бесконечности, а β – к нулю, то распреде- ление (для дискретных x) становится равномерным. Обычно модель обучают при β = 1. Однако можно использовать и другие темпера- туры, в частности β < 1. Темперирование (tempering)1 – это общая стратегия быстро- го перемешивания мод p1 путем выборки примеров с β < 1. Марковские цепи, основанные на темперированных переходах (Neal, 1994), вре- менно производят выборку из высокотемпературных распределений, чтобы пере-мешать разные моды, а затем возобновляют выборку из распределения с единичной температурой. Такие методы применялись к моделям типа ОМБ (Salakhutdinov, 2010). Другой подход – использование параллельного темперирования (Iba, 2001), когда марковская цепь параллельно имитирует много различных состояний при раз-ных температурах. Высокотемпературные состояния медленно перемешиваются, а низкотемпературные (с температурой 1) дают верные выборки из модели. Опера- тор перехода включает стохастический обмен состояний из двух разных температур-ных режимов, так чтобы пример с достаточно большой вероятностью из высокотем- пературного состояния мог перескочить в низкотемпературное. Этот подход также применялся к ОМБ (Desjardins et al., 2010; Cho et al., 2010). Хотя темперирование – многообещающая идея, в настоящее время она не позволила далеко продвинуться в решении проблемы выборки из сложных энергетических моделей. Возможно, дело в том, что существуют критические температуры, в окрестности которых темпера- турный переход (постепенное понижение температуры) должен быть очень медлен-ным, и только тогда темперирование оказывается эффективным. 17.5.2. Глубина может помочь перемешиванию Говоря о выборке из модели с латентными переменными p(h, x), мы видели, что если p(h | x) кодирует x слишком хорошо, то выборка из p(x | h) не сильно изменяет x, и пе- ремешивание оказывается плохим. Один из способов решения этой проблемы – сде- 1 Темперированием в металлургии называют процесс закалки сплава с последующим отпус- ком. – Прим. перев.\n--- Страница 508 ---\nПроблема перемешивания разделенных мод  507 лать h глубоким представлением, закодировав x в h таким образом, чтобы марковская цепь в пространстве h легче перемешивалась. Многие алгоритмы обучения представ- лений, в т. ч. автокодировщики и ОМБ, имеют тенденцию порождать маргинальное распределение h, более равномерное и более близкое к унимодальному, чем исходное распределение x. Можно предположить, что это объясняется попыткой минимизиро- вать ошибку реконструкции, используя все доступное пространство представления, поскольку минимизацию ошибки реконструкции по обучающим примерам проще осуществить, когда различные примеры легко различимы в h-пространстве и потому хорошо разделены. В работе Bengio et al. (2013a) отмечено, что более глубокие стеки регуляризированных автокодировщиков или ОМБ дают маргинальные распределе-ния в h-пространстве верхнего уровня, которые выглядят более вытянутыми и более равномерными, причем промежуток между областями, соответствующими разным модам (в экспериментах – категориям), меньше. Обучение ОМБ в этом пространстве более высокого уровня привело к более быстрому перемешиванию мод при выборке по Гиббсу. Однако остается неясным, как воспользоваться этим наблюдением в целях улучшения обучения и выборки из глубоких порождающих моделей. Несмотря на трудности перемешивания, методы Монте-Карло полезны и зачастую являются лучшими из имеющихся инструментов. На самом деле это основной инст-румент борьбы с вычислительно неразрешимой статистической суммой в неориенти- рованных моделях. Именно об этом пойдет речь в следующей главе.",
      "debug": {
        "start_page": 496,
        "end_page": 508
      }
    },
    {
      "name": "Глава 18. Преодоление трудностей, связанных со статической суммой 508",
      "content": "--- Страница 509 --- (продолжение)\nГлава 18 Преодоление трудностей, связанных со статической суммой В разделе 16.2.2 мы видели, что многие вероятностные модели (точнее, неориентиро- ванные графические модели) определены в терминах ненормированного распределе- ния вероятности p~(x; θ). Для получения корректного распределения вероятности мы должны нормировать p~, поделив на статистическую сумму Z(θ): (18.1) Статистическая сумма – это интеграл (для непрерывных величин) или сумма (для дискретных величин) ненормированных вероятностей всех состояний: (18.2) или (18.3) Для многих интересных моделей эта операция вычислительно неразрешима.В главе 20 мы увидим, что несколько моделей глубокого обучения специально спроектировано так, чтобы нормировочную постоянную можно было вычислить, или так, чтобы p(x) можно было не вычислять вовсе. Тем не менее в других моделях при- ходится сталкиваться с проблемой неразрешимых статистических сумм. В этой главе мы опишем методы, применяемые для обучения и использования моделей с нераз- решимыми статистическими суммами. 18.1. Градиент логарифмического правдоподобия Обучение неориентированных моделей методом максимального правдоподобия осо-бенно осложняется тем, что статистическая сумма зависит от параметров. Градиент логарифмического правдоподобия по параметрам содержит член, соответствующий градиенту статистической суммы: ∇ θ log p(x; θ) = ∇θ log p~(x; θ) – ∇θ log Z(θ). (18.4)\nГлава 18 Преодоление трудностей, связанных со статической суммой В разделе 16.2.2 мы видели, что многие вероятностные модели (точнее, неориентиро- ванные графические модели) определены в терминах ненормированного распределе- ния вероятности p~(x; θ). Для получения корректного распределения вероятности мы должны нормировать p~, поделив на статистическую сумму Z(θ): (18.1) Статистическая сумма – это интеграл (для непрерывных величин) или сумма (для дискретных величин) ненормированных вероятностей всех состояний: (18.2) или (18.3) Для многих интересных моделей эта операция вычислительно неразрешима.В главе 20 мы увидим, что несколько моделей глубокого обучения специально спроектировано так, чтобы нормировочную постоянную можно было вычислить, или так, чтобы p(x) можно было не вычислять вовсе. Тем не менее в других моделях при- ходится сталкиваться с проблемой неразрешимых статистических сумм. В этой главе мы опишем методы, применяемые для обучения и использования моделей с нераз- решимыми статистическими суммами. 18.1. Градиент логарифмического правдоподобия Обучение неориентированных моделей методом максимального правдоподобия осо-бенно осложняется тем, что статистическая сумма зависит от параметров. Градиент логарифмического правдоподобия по параметрам содержит член, соответствующий градиенту статистической суммы: ∇ θ log p(x; θ) = ∇θ log p~(x; θ) – ∇θ log Z(θ). (18.4)\n--- Страница 510 ---\nГ радиент логарифмического правдоподобия  509 Это хорошо известное разложение на положительную и отрицательную фазы обуче ния. Для большинства интересных неориентированных моделей отрицательная фаза представляет сложности. Если в модели нет латентных переменных или между ними немного взаимодействий, то положительная фаза обычно разрешима. Типичный при- мер модели с простой положительной и трудной отрицательной фазой – ОМБ, в ко- торой имеются скрытые блоки, условно независимые друг от друга при условии види-мых блоков. Случай трудной положительной фазы со сложными взаимодействиями между латентными переменными рассмотрен в главе 19. Здесь же мы займемся труд- ностями отрицательной фазы. Присмотримся к градиенту log Z поближе: ∇ θ log Z, (18.5) (18.6) (18.7) (18.8) Если модель гарантирует, что p(x) > 0 для всех x, то мы можем подставить exp(log p~(x)) вместо p~(x): (18.9) (18.10) (18.11) (18.12) (18.13) В этом выводе используется суммирование по дискретной величине x, но анало- гичный результат имеет место для интегрирования по непрерывной x. В этом случае мы применяем правило Лейбница дифференцирования под знаком интеграла: (18.14) Это тождество применимо только при некоторых условиях регулярности на p~ и ∇θ p~(x). В терминах теории меры эти условия формулируются так: (1) ненорми- рованное распределение p~ должно быть интегрируемой по Лебегу функцией x для любого значения θ; (2) градиент ∇θ p~(x) должен существовать для всех θ и почти всех x; (3) должна существовать интегрируемая функция R(x), ограничивающая ∇θ p~(x) в том смысле, что maxi|(∂/∂θi)p~(x)| ≤ R(x) для всех θ и почти всех x. К счастью, боль- шинство интересных моделей машинного обучения обладает этими свойствами.\n--- Страница 511 ---\n510  Преодоление трудностей, связанных со статической суммой Следующее тождество ∇θ log Z = 𝔼x∼p(x)∇θ log p~(x) (18.15) лежит в основе разнообразных методов Монте-Карло для приближенной максимиза- ции правдоподобия моделей с неразрешимыми статистическими суммами. Подход к обучению неориентированных моделей методом Монте-Карло пред- лагает интуитивно понятную схему, в рамках которой мы можем рассуждать о по- ложительной и отрицательной фазах. В положительной фазе мы увеличиваем log p~(x) для x, выбранного из данных. В отрицательной фазе мы уменьшаем ста- тистическую сумму за счет уменьшения log p~(x) для x, выбранного из модельного распределения. В литературе по глубокому обучению принято параметризовать log p~ в терминах функции энергии (уравнение 16.7). В этом случае мы можем интерпретировать поло- жительную фазу как толкание вниз энергии обучающих примеров, а отрицательную фазу – как толкание вверх энергии примеров, выбранных из модели (см. рис. 18.1). 18.2. Стохастическая максимизация правдоподобия и сопоставительное расхождение Наивный способ реализации уравнения (18.15) состоит в том, чтобы вычислить его посредством приработки множества марковских цепей, инициализированных слу- чайным образом, всякий раз как понадобится градиент. Если обучение производится методом стохастического градиентного спуска, то это означает, что приработка долж-на производиться один раз на каждом шаге вычисления градиента. Получающаяся процедура обучения описана в алгоритме 18.1. Из-за высокой стоимости приработки марковских цепей во внутреннем цикле эта процедура вычислительно неосуществи-ма, но она может служить отправной точкой, на аппроксимацию которой нацелены более практичные алгоритмы. Алгоритм 18.1. Наивный MCMC-алгоритм максимизации логарифмического правдоподобия с неразрешимой статистической суммой посредством градиентно- го восхождения Установить размер шага ε равным малому положительному числу.Установить число шагов выборки по Гиббсу k достаточно большим для прира- ботки. Для обучения ОМБ на небольшом фрагменте изображения может хва-тить значения 100.while не сошелся do Выбрать мини-пакет m примеров {x (1), …, x(m)} из обучающего набора g ← Инициализировать набор m примеров {x~(1), …, x~(m)} случайными значениями (выбранными, например, из равномерного или нормального распределения или, возможно, из распределения, маргиналы которого совпадают с маргина- лами модели).for i = 1 to k do for j = 1 to m do\n--- Страница 512 ---\nСтохастическая максимизация правдоподобия  511 x~(j) ← gibbs_update(x~(j)) end for end for g ← g – θ ← θ + εg end while Мы можем рассматривать подход MCMC к максимальному правдоподобию как попытку уравновесить две силы, одна из которых толкает распределение модели вверх там, где имеются данные, а другая толкает его вниз там, где имеются приме- ры, выбранные из модели. Этот процесс иллюстрируется на рис. 18.1. Две силы соот-ветствуют максимизации log p~ и минимизации log Z. Возможно несколько аппрокси- маций отрицательной фазы, каждую из которых можно рассматривать как попытку сделать эту фазу вычислительно более простой, но одновременно и как толкание ее вниз не в тех точках, что нужно. pmodel(x) pdata(x)pmodel(x) pdata(x) х хp(x) p(x)Положительная фаза Отрицательная фаза Рис. 18.1  Взгляд на алгоритм 18.1 с точки зрения положительной и от- рицательной фаз. (Слева) В положительной фазе мы выбираем точки из распределения данных и толкаем вверх их ненормированную вероятность. Это означает, что точки, которые с вероятностью принадлежат данным, проталкиваются выше вверх. (Справа) В отрицательной фазе мы выбира- ем точки из модельного распределения и толкаем вниз их ненормирован- ную вероятность. Это противодействует стремлению положительной фазы прос то всюду прибавить большую постоянную к ненормированной веро- ятности. Если распределение данных и модельное распределение совпа- дают, то у положительной фазы такие же шансы поднять точку вверх, как у отрицательной – опустить вниз. Если такое происходит, то градиент мате- матического ожидания обнуляется, и обучение следует остановить Поскольку в отрицательной фазе примеры выбираются из модельного распределе- ния, то мы можем интерпретировать ее как нахождение точек, в которые модель силь- но верит. Так как действие отрицательной фазы сводится к уменьшению вероятности этих точек, обычно они рассматриваются как неверные представления модели о мире. В литературе эти точки часто называют «галлюцинациями», или «воображаемыми час- тицами» (fantasy particles). На самом деле отрицательная фаза была предложена как\n--- Страница 513 ---\n512  Преодоление трудностей, связанных со статической суммой возможное объяснение снов у человека и других животных (Crick and Mitchison, 1983). Идея в том, что мозг хранит вероятностную модель мира и следует в направлении гра- диента log p~, сталкиваясь с реальными событиями в состоянии бодрствования, и в на- правлении отрицательного градиента log p~, стремясь минимизировать log Z, когда спит и сталкивается с событиями, выбранными из текущей модели. Такой взгляд на вещи объясняет терминологию, используемую при описании алгоритмов с положитель- ной и отрицательной фазами, но его правильность не доказана нейробиологическими экспериментами. В моделях машинного обучения обычно необходимо использовать положительную и отрицательную фазы одновременно, а не в раздельные периоды бодрствования и фазы быстрого сна. В разделе 19.5 мы увидим, что другие алгорит- мы машинного обучения выбирают примеры из модельного распределения для других целей и что такие алгоритмы также могли бы дать объяснение функции сновидений. При таком понимании роли положительной и отрицательной фаз обучения мы мо- жем попытаться спроектировать более дешевую альтернативу алгоритма 18.1. Основ-ная часть стоимости наивного алгоритма MCMC – стоимость приработки случайным образом инициализированных марковских цепей на каждом шаге. Естественное ре-шение – инициализировать цепь, воспользовавшись распределением, очень близким к модельному, тогда приработка займет меньше времени. Алгоритм сопоставительного расхождения (contrastive divergence) (CD, или CD- k, чтобы показать, что это алгоритм CD с k шагами выборки по Гиббсу) инициализи- рует марковскую цепь на каждом шаге примерами, выбранными из распределения данных (Hinton, 2000, 2010). Эта идея представлена в алгоритме 18.2. Получение при- меров из распределения данных ничего не стоит, потому что они уже присутствуют в наборе данных. Первоначально распределение данных сильно отличается от мо- дельного, поэтому отрицательная фаза не очень точна. Но, к счастью, положительная фаза все-таки может верно увеличивать вероятность данных в модели. Если дать по- ложительной фазе поработать некоторое время, то модельное распределение окажет-ся ближе к распределению данных, и верность негативной фазы начнет расти. Алгоритм 18.2. Алгоритм сопоставительного расхождения, в котором в качестве процедуры оптимизации используется градиентное восхождение Установить размер шага ε равным малому положительному числу.Установить число шагов выборки по Гиббсу k достаточно большим для того, что- бы выборка по схеме марковской цепи из p(x; θ) перемешивалась при инициали- зации из p data. Для обучения ОМБ на небольшом фрагменте изображения можно взять значение от 1 до 20.while не сошелся do Выбрать мини-пакет m примеров {x (1), …, x(m)} из обучающего набора g ← for i = 1 to m do x~(i) ← x(i) end forfor i = 1 to k do for j = 1 to m do x~ (j) ← gibbs_update(x~(j)) end for\n--- Страница 514 ---\nСтохастическая максимизация правдоподобия  513 end for g ← g – θ ← θ + εg end while Разумеется, алгоритм CD по-прежнему является лишь приближением к правиль- ной отрицательной фазе. Основная причина, по которой CD качественно не справ- ляется с реализацией отрицательной фазы, заключается в невозможности подавить области высокой вероятности, далекие от реальных обучающих примеров. Такие об-ласти, в которых вероятность в модели высокая, а в истинном порождающем данные распределении низкая, называются паразитными модами. На рис. 18.2 показано, по- чему это происходит. Дело в том, что моды модельного распределения, далекие от распределения данных, посещаются марковскими цепями, инициализированными в обучающих точках, только если k очень велико. pmodel(x) pdata(x)p(x) x Рис. 18.2  Паразитная мода. Иллюстрация того, как отрицательная фаза сопоставительного расхождения (алгоритм 18.2) не справляется с по- давлением паразитных мод. Паразитной называется мода, присутствую-щая в модельном распределении, но отсутствующая в истинном распре- делении данных. Поскольку в алгоритме сопоставительного расхождения марковские цепи инициализируются по точкам из распределения данных и работают всего несколько шагов, то маловероятно, что они посетят моды модели, далеко отстоящие от данных. Это означает, что при выборке из модели мы иногда будем получать примеры, не похожие на данные. Кроме того, из-за расходования части массы вероятности на эти моды модель бу-дет испытывать трудности с размещением областей высокой вероятности в правильных модах. Для наглядности на этом рисунке используется не- сколько упрощенное понятие расстояния – паразитная мода далеко отстоит от правильной моды вдоль горизонтальной оси в ℝ. Это соответствует мар- ковской цепи, которая производит локальные перемещения с единствен- ной случайной величиной x из ℝ. В большинстве глубоких вероятностных моделей марковские цепи основаны на выборке по Гиббсу и могут нело- кально перемещать любую величину, но не все сразу. Для таких задач обыч- но лучше рассматривать не евклидово, а редакторское расстояние между модами. Однако редакторское расстояние в многомерном пространстве трудно изобразить на двумерном рисунке\n--- Страница 515 ---\n514  Преодоление трудностей, связанных со статической суммой В работе Carreira-Perpin~an and Hinton (2005) экспериментально показано, что CD-оценка является смещенной для ограниченных и полностью видимых машин Больцмана в том смысле, что сходится не к тем же точкам, что оценка максималь- ного правдоподобия. Авторы замечают, что поскольку смещение невелико, то алго- ритм CD можно было бы использовать как дешевый способ инициализации модели, а затем уточнить модель, применяя более дорогостоящие MCMC-методы. В работе Bengio and Delalleau (2009) показано, что CD можно интерпретировать как отбрасы-вание наименьших членов правильного градиента MCMC-обновления, объясняю-щего смещение. Алгоритм CD полезен для обучения мелких моделей типа ОМБ. Собрав несколько таких моделей, можно инициализировать более глубокие модели, например глубо-кие сети доверия или глубокие машины Больцмана. Но CD мало чем может помочь в непосредственном обучении более глубоких моделей. Все дело в трудности полу- чения примеров скрытых блоков при наличии примеров видимых блоков. Поскольку скрытые блоки не включаются в данные, инициализация по обучающим примерам не решает проблему. Даже если видимые блоки инициализированы на основе данных, мы все равно должны приработать марковскую цепь, чтобы получить выборку из рас-пределения скрытых блоков при условии видимых примеров. Можно считать, что алгоритм CD штрафует модель за наличие марковской цепи, которая быстро изменяет вход, если тот поступает из данных. Это означает, что обуче-ние с помощью CD чем-то напоминает обучение автокодировщика. Несмотря на то что смещение CD больше, чем у некоторых других методов обучения, этот алгоритм может быть полезен для предобучения мелких моделей, которые впоследствии соби-раются в стек. Объясняется это тем, что предшествующие модели в стеке копируют больше информации в свои латентные переменные, делая ее доступной последую- щим моделям. Это следует рассматривать скорее как часто эксплуатируемый побоч-ный эффект обучения с помощью CD, нежели как принципиальную особенность, за- ложенную в проект. В работе Sutskever and Тieleman (2010) показано, что направление обновления в CD не совпадает с направлением градиента какой-либо функции. В результате CD может зациклиться, но на практике это не представляет серьезной проблемы. Другая стратегия, решающая многие проблемы, присущие CD, – инициализи- ровать марковские цепи на каждом шаге градиентного спуска состояниями с пре- дыдущего шага. Впервые этот подход получил распространение под названием стохастической максимизации правдоподобия (СМП) в прикладной математике и статистике (Y ounes, 1998), а впоследствии был независимо открыт в сообществе глубокого обучения под названием устойчивое сопоставительное расхождение (per sistent contrastive divergence – PCD или PCD-k, чтобы показать, что использу- ется k шагов выборки по Гиббсу на каждое обновление) (Тieleman, 2008). См. алго- ритм 18.3. Основная идея состоит в том, что коль скоро шаги алгоритма стохасти- ческого градиентного спуска малы, модели, построенные на двух соседних шагах, будут похожи. Отсюда следует, что примеры, выбранные из распределения предыду-щей модели, будут очень близки к настоящим примерам из распределения текущей модели, так что марковская цепь, инициализированная этими примерами, не потре-бует много времени для приработки. Поскольку все марковские цепи непрерывно обновляются на протяжении всего процесса обучения, а не перезапускаются на каждом шаге вычисления градиента, то\n--- Страница 516 ---\nСтохастическая максимизация правдоподобия  515 они могут забрести достаточно далеко, чтобы обнаружить все моды модели. Поэтому СМП оказывается гораздо устойчивее к формированию моделей с паразитными мо- дами, чем CD. Кроме того, благодаря возможности запоминать состояние всех пере-менных, из которых производится выборка, как видимых, так и латентных, СМП по- ставляет начальные данные для скрытых и видимых блоков. CD может обеспечить инициализацию только видимых блоков, поэтому в глубоких моделях требуется при- работка. СМП способен обучать глубокие модели более эффективно. В работе Marlin et al. (2010) проведено сравнение СМП со многими другими критериями, описан-ными в этой главе. Показано, что СМП дает наилучшее логарифмическое правдопо- добие на тестовом наборе для ОМБ и что если скрытые блоки ОМБ используются в качестве признаков для SVM-классификатора, то СМП дает наилучшую верность классификации. Алгоритм 18.3. Алгоритм стохастической максимизации правдоподобия (устой- чивого сопоставительного расхождения), в котором в качестве процедуры оптими- зации используется градиентное восхождение Установить размер шага ε равным малому положительному числу.Установить число шагов выборки по Гиббсу k достаточно большим для того, чтобы выборка по схеме марковской цепи из p(x; θ + εg) приработалась, начав с примеров из p(x; θ). Для обучения ОМБ на небольшом фрагменте изображе- ния можно взять значение 1, для более сложной модели, например глубокой сети доверия, – от 5 до 50. Инициализировать набор m примеров {x~ (1), …, x~(m)} случайными значениями (выбран ными, например, из равномерного или нормального распределения или, возможно, из распределения, маргиналы которого совпадают с маргиналами мо- дели). while не сошелся do Выбрать мини-пакет m примеров {x(1), …, x(m)} из обучающего набора g ← for i = 1 to k do for j = 1 to m do x~(j) ← gibbs_update(x~(j)) end for end for g ← g – θ ← θ + εg end while СМП может утратить верность, если стохастический градиентный алгоритм пере- мещает модель настолько быстро, что марковская цепь не успевает прирабатываться между шагами. Это может случиться, если k слишком мало или ε слишком велико. К сожалению, допустимый диапазон значений сильно зависит от задачи. Неизвестно, как можно формально проверить, успешно ли прирабатывается цепь между шагами. Субъективно, если скорость обучения слишком высока для выбранного числа шагов выборки по Гиббсу, то оператор-человек будет наблюдать, что дисперсия примеров\n--- Страница 517 ---\n516  Преодоление трудностей, связанных со статической суммой в отрицательной фазе гораздо больше между шагами вычисления градиента, чем между различными марковскими цепями. Например, модель, обученная на наборе данных MNISТ, на одном шаге может выбрать исключительно цифры 7. Тогда про-цесс обучения сильно опустит вниз моду, соответствующую семерке, и на следующем шаге модель выберет только цифры 9. При вычислении выборки из модели, обученной с помощью СМП, следует прояв- лять осторожность. Производить выборку следует, начиная с новой марковской цепи, инициализированной в случайной начальной точке, после того как обучение модели закончено. На примеры, присутствующие в запомненных отрицательных цепях, ис- пользованных для обучения, оказали влияние несколько последних версий модели, поэтому может показаться, что емкость модели больше, чем на самом деле. В работе Berglund and Raiko (2013) поставлены эксперименты для изучения сме- щения и дисперсии оценок градиента, полученных методами CD и СМП. Показано, что CD дает меньшую дисперсию, чем оценка, основанная на точной выборке. У СМП дисперсия выше. Причина низкой дисперсии CD – в том, что в этом алгоритме одни и те же обучающие примеры используются в положительной, и в отрицательной фа- зах. Если в отрицательной фазе производить инициализацию на других обучающих данных, то дисперсия будет выше, чем у оценки, основанной на точной выборке. Все методы, основанные на применении MCMC для выборки из модели, в прин- ципе, можно использовать почти с любым вариантом MCMC. Это означает, что та- кие алгоритмы, как СМП, можно улучшить, применив любой усовершенствованный MCMC-метод из числа описанных в главе 17, например параллельное темперирова- ние (Desjardins et al., 2010; Choet al., 2010). Один из подходов к ускорению перемешивания в ходе обучения опирается не на изменение технологии выборки методом Монте-Карло, а на выборе другой парамет- ризации модели и функции стоимости. В алгоритме Fast PCD, или FPCD (Тieleman and Hinton, 2009) параметры θ традиционной модели заменяются выражением θ = θ (slow) + θ(fast). (18.16) Теперь параметров вдвое больше, чем раньше, и их поэлементная сумма дает пара- метры, используемые в исходном определении модели. «Быстрые» параметры θ(fast) обучаются при гораздо большей скорости обучения, что позволяет им быстро адапти-роваться в ответ на отрицательную фазу обучения и подталкивать марковскую цепь к исследованию новой территории. Поэтому цепь быстрее прирабатывается, хотя этот эффект наблюдается только во время обучения, пока быстрые веса могут беспре-пятственно изменяться. Как правило, к быстрым весам применяется также тактика снижения весов, поощряющая их сходиться к небольшим значениям, после того как они оставались большими достаточно долго, для того чтобы побудить марковскую цепь к смене моды. Одно из важных преимуществ MCMC-методов, описанных в этом разделе, состоит в том, что они дают оценку градиента log Z, и потому мы можем представить задачу в виде суммы вкладов log p~ и log Z. Затем можно использовать любой другой метод для обработки log p~(x) и просто прибавить к вычисленному им градиенту наш гра- диент в отрицательной фазе. В частности, это означает, что в положительной фазе можно использовать методы, которые дают только нижнюю границу p~. Большинство других методов работы с log Z, представленных в этой главе, несовместимо с метода- ми в положительной фазе, основанными на оценке границы.\n--- Страница 518 ---\nПсевдоправдоподобие  517 18.3. Псевдоправдоподобие Аппроксимации статистической суммы и ее градиента методами Монте-Карло прямо направлены на преодоление связанных со статистической суммой трудностей. В дру- гих подходах эта проблема обходится посредством обучения модели без вычисления статистической суммы. Многие такие подходы основаны на возможности легко вы-числить отношения вероятностей в неориентированной вероятностной модели. Свя- зано это с тем, что статистическая сумма, входящая в числитель и знаменатель дроби, сокращается: (18.17) Псевдоправдоподобие основано на том, что условные вероятности имеют вид та- кого отношения, поэтому их можно вычислить, не зная статистическую сумму. Пред-положим, что мы разбили x на a, b и c, где a содержит величины, чье условное рас- пределение мы хотим найти, b – обусловливающие величины, а c – величины, не являющиеся частью запроса: (18.18) Отсюда требуется исключить a, эта операция может быть выполнена очень эффек- тивно, при условии что a и c содержат немного величин. В предельном случае a состо- ит всего из одной величины, а c пусто, так что требуется вычислить p~ лишь столько раз, сколько значений может принимать одна случайная величина. К сожалению, чтобы вычислить логарифмическое правдоподобие, нам нужно ис- ключать большие множества величин. Если всего имеется n величин, то требуется исключить множество размера n – 1. Согласно цепному правилу вероятностей: log p(x) = log p(x1) + log p(x2 | x1) + … + p(xn | x1:n–1). (18.19) В данном случае мы взяли наименьшее возможное a, но c может составлять x2:n. А что, если просто переместить c в b, чтобы уменьшить вычислительную стоимость? Тогда получится целевая функция псевдоправдоподобия (Besag, 1975), основанная на предсказании значения признака xi при условии всех остальных признаков x–i: (18.20) Если каждая случайная величина может принимать k значений, то для вычисления p~ потребуется произвести только k×n операций вместо kn операций, необходимых для вычисления статистической суммы. На первый взгляд, это кажется беспринципным трюком, но можно доказать, что оценка, полученная максимизацией псевдоправдоподобия, асимптотически состоя-тельная (Mase, 1995). Конечно, если набор данных нельзя назвать большой выбор-кой, то поведение псевдоправдоподобия может отличаться от оценки максимального правдоподобия. Мы можем предпочесть вычислительную сложность отклонению от оценки мак- симального правдоподобия, воспользовавшись оценкой обобщенного псевдоправ-\n--- Страница 519 ---\n518  Преодоление трудностей, связанных со статической суммой доподобия (Huang and Ogata, 2002), в которой используется m различных множеств 𝕊(i), i = 1, …, m индексов величин, встречающихся вместе слева от вертикальной черты в выражении условной вероятности. В предельном случае, когда m = 1 и 𝕊(1) = 1, …, n, обобщенное псевдоправдоподобие сводится к логарифмическому правдоподобию. В другом предельном случае, когда m = n и 𝕊(i) = {i}, обобщенное псевдоправдоподобие сводится к псевдоправдоподобию. Целевая функция обобщенного псевдоправдопо- добия имеет вид (18.21) Качество алгоритмов, основанных на псевдоправдоподобии, сильно зависит от способа использования модели. Псевдоправдоподобие плохо работает в задачах, где требуется хорошая модель полного совместного распределения p(x), таких, напри- мер, как оценивание плотности или выборка. Оно демонстрирует лучшее качество, чем максимальное правдоподобие, в задачах, где на этапе обучения требуются только условные распределения, например для восполнения небольшого числа отсутствую-щих значений. Методы на основе обобщенного псевдоправдоподобия особенно эф-фективны, если данные обладают регулярной структурой, позволяющей проектиро-вать множества индексов 𝕊, так чтобы улавливались наиболее важные корреляции, и опускать группы величин, корреляция между которыми пренебрежимо мала. На- пример, в естественных изображениях пиксели, далеко отстоящие друг от друга в пространстве, слабо коррелированы, поэтому можно применить метод обобщенного псевдоправдоподобия, выбирая в качестве 𝕊 небольшое пространственно локализо- ванное окно. Слабое место оценки псевдоправдоподобия – невозможность использовать ее сов- местно с другими аппроксимациями, которые дают только нижнюю границу p~(x), например вариационным выводом, рассматриваемым в главе 19. Дело в том, что p~ на- ходится в знаменателе. Нижняя граница знаменателя дает только верхнюю границу выражения в целом, а максимизация верхней границы не дает никакого выигрыша. Это затрудняет применение псевдоправдоподобия к таким моделям, как глубокие ма- шины Больцмана, поскольку вариационные методы – один из преобладающих под- ходов к приближенному исключению многих слоев скрытых переменных, взаимо- действующих друг с другом. Тем не менее псевдоправдоподобие находит применение в глубоком обучении, поскольку его можно использовать для обучения однослойных моделей или глубоких моделей с помощью приближенных методов вывода, не опи- рающихся на оценку нижней границы. Для псевдоправдоподобия характерна гораздо более высокая стоимость одного шага вычисления градиента, чем для СМП, поскольку приходится явно вычислять все условные распределения. Но обобщенное псевдоправдоподобие и другие подоб- ные критерии все же могут хорошо работать, если при обработке каждого примера вычисляется только одно случайно выбранное условное распределение (Goodfellow et al., 2013b), так что вычислительная стоимость оказывается сопоставимой с СМП. Хотя оценка псевдоправдоподобия явно не минимизирует log Z, ее тем не менее можно рассматривать как нечто, похожее на отрицательную фазу. Знаменатели в каждом условном распределении приводят к тому, что алгоритм обучения подав- ляет вероятность всех состояний, в которых только одна переменная отличается от обучающего примера.\n--- Страница 520 ---\nСопоставление рейтингов и сопоставление отношений  519 Теоретический анализ асимптотической эффективности псевдоправдоподобия см. в работе Marlin and de Freitas (2011). 18.4. Сопоставление рейтингов и сопоставление отношений Сопоставление рейтингов (score matching) (Hyvärinen, 2005) – еще один способ обучить модель, не оценивая ни статистическую сумму Z, ни ее производные. Про- исхождение названия связано с терминологией, согласно которой производные лога- рифма плотности по ее аргументу, ∇x log p(x), называются рейтингом (score). В методе сопоставления рейтингов стратегия заключается в минимизации ожидаемого квадра- та разности между градиентом логарифма модельной плотности по входу и градиен- том логарифма плотности данных по входу: (18.22) (18.23) (18.24) При такой целевой функции мы избегаем трудностей дифференцирования статис- тической суммы Z, поскольку Z не зависит от x и, следовательно, ∇x Z = 0. Поначалу кажется, что у сопоставления рейтингов другая сложность: чтобы вычислить рейтинг распределения данных, необходимо знать истинное порождающее распределение обучаю щих данных, pdata. По счастью, минимизация ожидаемого значения L(x; θ) эк- вивалентна минимизации ожидаемого значения выражения (18.25) где n – размерность x. Поскольку в методе сопоставления рейтингов требуется вычислять производные по x, он не применим к моделям с дискретными данными, но латентные переменные модели могут быть дискретными. Как и псевдоправдоподобие, метод сопоставления рейтингов работает только тог- да, когда мы можем непосредственно вычислить функцию log p~(x) и ее производные. Он не совместим с методами, которые дают только нижнюю границу log p~(x), по- тому что для сопоставления рейтингов нужны производные и вторые производные log p~(x), а нижняя граница не несет никакой информации о производных. Это означа- ет, что метод сопоставления рейтингов неприменим к оцениванию моделей со слож- ными взаимодействиями между скрытыми блоками, например моделям разреженно- го кодирования или глубоким машинам Больцмана. И хотя сопоставление рейтингов можно применять для предобучения первого скрытого слоя большой модели, этот метод никогда не применялся в качестве стратегии предобучения более глубоких сло- ев. Возможно, дело в том, что скрытые слои таких моделей обычно содержат какие-то дискретные переменные.\n--- Страница 521 ---\n520  Преодоление трудностей, связанных со статической суммой В методе сопоставления рейтингов нет явной отрицательной фазы, но его можно рассматривать как вариант состязательного расхождения, если использовать марков- скую цепь специального вида (Hyvärinen, 2007a). В данном случае марковская цепь определяется не выборкой по Гиббсу, а совсем другим способом, в котором локальные перемещения направляются градиентом. Сопоставление рейтингов эквивалентно ал-горитму CD с марковской цепью такого вида, когда величина локальных перемеще- ний стремится к нулю. В работе Lyu (2009) метод сопоставления рейтингов обобщен на дискретный слу- чай (но в доказательстве была допущена ошибка, исправленная в работе Marlin et al. [2010]). В работе Marlin et al. (2010) обнаружено, что обобщенное сопоставление рейтингов (generalized score matching – GSM) не работает в многомерных дискрет- ных пространствах, где наблюдаемая вероятность многих событий равна 0. Более плодотворный подход к обобщению основных идей сопоставления рейтин- гов на дискретные данные – сопоставление отношений (ratio matching) (Hyvärinen, 2007b). Этот метод применим только к бинарным данным и заключается в миними- зации усреднения по всем примерам следующей целевой функции: (18.26) где f(x, j) возвращает вектор x, в котором бит в позиции j изменен на противополож- ный. Чтобы избежать вычисления статистической суммы, в методе сопоставления от- ношений применен тот же прием, что и в оценке псевдоправдоподобия: в отношении двух вероятностей статистическая сумма сокращается. В работе Marlin et al. (2010) показано, что метод сопоставления отношений превосходит СМП, псевдоправдопо- добие и GSM с точки зрения способности обученной модели очищать изображения из тестового набора от шума. Как и в оценке псевдоправдоподобия, в методе сопоставления отношений требу- ется n раз вычислить p~ на каждый пример, поэтому его вычислительная стоимость в расчете на одно обновление примерно в n раз выше, чем стоимость СМП. Как и оценку псевдоправдоподобия, сопоставление отношений можно интерпре- тировать как толкание вниз для всех воображаемых состояний, в которых только одна переменная отличается от обучающего примера. Поскольку метод сопоставле-ния отношений применяется исключительно к бинарным данным, это означает, что он воздействует на все воображаемые состояния, находящиеся от обучающих данных на расстоянии Хэмминга 1. Сопоставление отношений может быть полезно в качестве основы для работы с раз- реженными данными большой размерности, например векторами счетчиков слов. Для MCMC-методов такие данные составляют проблему, потому что представить данные в плотном формате обходится очень дорого, а компонент выборки MCMC не выдает разреженных данных, пока модель не обучится представлять разреженность в рас- пределении данных. В работе Dauphin and Bengio (2013) эта трудность преодолена путем проектирования несмещенной стохастической аппроксимации сопоставления отношений. Аппроксимация вычисляет только случайно выбранное подмножество членов целевой функции и не требует, чтобы модель порождала полные воображае- мые выборки.\n--- Страница 522 ---\nШумосопоставительное оценивание  521 Теоретический анализ асимптотической эффективности сопоставления отноше- ний см. в работе Marlin and de Freitas (2011). 18.5. Шумоподавляющее сопоставление рейтингов Иногда бывает полезно регуляризировать сопоставление рейтингов, аппроксимируя распределение (18.27) а не истинное распределение pdata. Распределение q(x | y) описывает искажающий про- цесс, обычно он формирует x, прибавляя небольшой шум к y. Шумоподавляющее сопоставление рейтингов особенно полезно, потому что на практике мы обычно не имеем доступа к истинному pdata, а только к эмпирическому распределению, определенному выборкой из pdata. При достаточной емкости любая состоятельная оценка превратит pmodel во множество распределений Дирака с центра- ми в обучающих точках. Сглаживание с помощью q помогает устранить эту проблему ценой утраты свойства асимптотической состоятельности, описанного в разделе 5.4.5. В работе Kingma and LeCun (2010) описана процедура выполнения регуляризирован- ного сопоставления рейтингов, когда сглаживающее распределение q – нормально распределенный шум. Напомним (см. раздел 14.5.1), что некоторые алгоритмы обучения автокодиров- щиков эквивалентны сопоставлению рейтингов или шумоподавляющему сопостав-лению рейтингов. Следовательно, эти алгоритмы также решают проблему статисти-ческой суммы. 18.6. Шумосопоставительное оценивание Большинство методов оценивания моделей с вычислительно неразрешимыми ста- тистическими суммами не дает оценки этой суммы. Алгоритмы СМП и CD оцени- вают только градиент логарифма статистической суммы, а не ее саму. Методы сопо- ставления рейтингов и псевдоправдоподобия вообще избегают вычисления величин, связанных со статистической суммой. Шумосопоставительное оценивание (noise-contrastive estimation – NCE) (Gutmann and Hyvarinen, 2010) предлагает другую стратегию. В этом методе распределение ве- роятности, оцениваемое моделью, представляется явно в виде log pmodel(x) = log p~ model(x; θ) + c, (18.28) где c вводится как аппроксимация –log Z(θ). Вместо того чтобы оценивать только θ, процедура шумосопоставительного оценивания рассматривает c как еще один пара- метр и оценивает θ и c одновременно, применяя один и тот же алгоритм. Результи- рующее log pmodel(x) может не соответствовать точно корректному распределению ве- роятности, но приближается к нему по мере улучшения оценки c1. 1 Метод NCE применим также к задачам с вычислимой статистической суммой, когда нет нужды вводить дополнительный параметр c. Но наибольший интерес он вызывает как сред- ство оценивания моделей с трудно вычислимыми статистическими суммами.\n--- Страница 523 ---\n522  Преодоление трудностей, связанных со статической суммой Такой подход был бы невозможен, если бы в качестве критерия оценки исполь- зовалось максимальное правдоподобие. Критерий максимального правдоподобия стремился бы присвоить c как можно большее значение, а не достичь корректного распределения вероятности. В основу работы NCE положено сведение зад,ачи обучения без учителя, заклю- чающейся в оценивании p(x), к обучению вероятностного бинарного классифика- тора, в котором одна из категорий соответствует данным, порожденным моделью. Эта задача обучения с учителем конструируется так, что оценка максимального правдоподобия определяет асимптотически состоятельную оценку для исходной задачи. Точнее говоря, мы вводим второе распределение шумов p noise(x). Оно должно быть легко вычислимо и выборка из него не должна вызывать затруднений. Теперь мы мо- жем построить модель, включающую x и новую бинарную переменную класса y. Для новой совместной модели мы постулируем: pjoint(y = 1) = 1/2, (18.29) pjoint(x | y = 1) = pmodel(x), (18.30) и pjoint(x | y = 0) = pnoise(x). (18.31) Иными словами, переменная y – переключатель, определяющий, из какого распре- деления выбирать x: из модели или из шума. Можно построить аналогичную совместную модель обучающих данных. В этом случае переключатель определяет, выбирается x из распределения данных или из шума. Формально ptrain(y = 1) = 1/2, ptrain(x | y = 1) = pdata(x), ptrain(x | y = 0) = pnoise(x). Теперь можно применить стандартное обучение методом максимального правдо- подобия к задаче обучения с учителем, заключающейся в подгонке pjoint к ptrain. (18.32) Распределение pjoint – это, по существу, модель логистической регрессии, приме- ненная к разности логарифмов распределения вероятности модели и шума. (18.33) (18.34) (18.35) (18.36) = σ(log pmodel(x) – log pnoise(x)). (18.37)\n--- Страница 524 ---\nШумосопоставительное оценивание  523 Таким образом, метод NCE применить просто при условии, что log p~ model легко под- дается обратному распространению, и, как было сказано выше, pnoise легко вычисляет- ся (для вычисления pjoint) и допускает простую выборку (для генерации обучающих данных). Особенный успех методу NCE сопутствует в задачах с небольшим числом случай- ных величин, но он неплохо работает и тогда, когда эти величины принимают много разных значений. Например, он успешно применялся к моделированию условного распределения слова при известном контексте (Mnih and Kavukcuoglu, 2013). Слово в данном случае всего одно, хотя и может выбираться из большого словаря. Применение NCE к задачам с большим числом случайных величин менее эффек- тивно. Классификатор на основе логистической регрессии может отклонить зашум-ленный пример, выявив всего одну переменную с маловероятным значением. Это означает, что обучение сильно замедляется, после того как p model обучилось базовой маргинальной статистике. Представьте себе обучение модели изображений лиц, в ко- торой в качестве pnoise используется неструктурированный гауссов шум. Если pmodel обучилась распознавать глаза, то она может отклонять почти все зашумленные при-меры, так ничего и не узнав о других признаках лица, например ртах. Ограничение на простоту вычисления и выборки из p noise может оказаться чрез- мерно строгим. Если распределение pnoise простое, то большинство примеров, скорее всего, будет слишком очевидно отличаться от данных, так что заметного улучшения p model достичь не удастся. Подобно сопоставлению рейтингов и псевдоправдоподобию, NCE не работает, если известна только нижняя граница p~. Нижнюю границу можно было бы использо- вать для получения нижней границы pjoint(y = 1 | x), но она позволяет получить лишь верхнюю границу распределения pjoint(y = 0 | x), которое встречается в половине чле- нов целевой функции NCE. Точно так же бесполезна нижняя граница pnoise, потому что она дает только верхнюю границу pjoint(y = 1 | x). Когда модельное распределение копируется для определения нового распределе- ния шумов перед каждым шагом градиентного спуска, NCE определяет процедуру самосопоставительного оценивания (self-contrastive estimation), для которой ожи- даемый градиент эквивалентен ожидаемому градиенту максимального правдоподо-бия (Goodfellow, 2014). Частный случай NCE, когда зашумленные примеры порожда-ются моделью, наводит на мысль, что оценку максимального правдоподобия можно интерпретировать как процедуру, которая заставляет модель постоянно обучаться отличать реальность от собственных эволюционирующих представлений, тогда как шумосопоставительная оценка достигает некоторого снижения вычислительной стои мости, заставляя модель отличать реальность только от фиксированного этало- на (модели шума). Применение задачи обучения учителем, заключающейся в различении обучающих и порожденных примеров (когда в определении классификатора участвует функция энергии модели), для предоставления градиента модели ранее уже встречалось в раз- ных формах (Welling et al., 2003b; Bengio, 2009). В основе шумосопоставительного оценивания лежит идея о том, что хорошая по- рождающая модель должна быть способна отличить данные от шума. С этим тесно связана другая идея: хорошая порождающая модель должна уметь порождать при-меры, которые ни один классификатор не сможет отличить от данных. Эта идея ведет к порождающим состязательным сетям (раздел 20.10.4).\n--- Страница 525 ---\n524  Преодоление трудностей, связанных со статической суммой 18.7. Оценивание статистической суммы Большая часть этой главы посвящена описанию методов, позволяющих избежать вы- числения неразрешимой статистической суммы Z(θ), ассоциированной с неориенти-рованной графической моделью, но в этом разделе мы обсудим несколько методов прямого оценивания этой суммы. Умение оценивать статистическую сумму нужно в случае, когда мы хотим вычис- лить нормированное правдоподобие данных. Это важно при оценивании модели, мо- ниторинге качества обучения и сравнении моделей между собой. Пусть, например, имеются две модели: ℳ A, определяющая распределение вероят- ности pA(x; θA) = (1/ZA)p~ A(x; θA), и ℳB, определяющая распределение вероятности pB(x; θB) = (1/ZB)p~ B(x; θB). Обычный способ сравнить две модели заключается в том, чтобы вычислить и сравнить правдоподобие, которое они назначают тестовому на- бору независимых и одинаково распределенных данных. Предположим, что тестовый набор состоит из m примеров {x(1), …, x(m)}. Если ∏i pA(x(i); θA) > ∏i pB(x(i); θB) или, что то же самое, , (18.38) то мы говорим, что ℳA лучше ℳB (или, по крайней мере, что ℳA лучше моделирует данный тестовый набор) в том смысле, что логарифмическое правдоподобие на тесто- вом наборе выше. К сожалению, для проверки этого условия нужно знать статистиче- скую сумму. Для вычисления выражения (18.38) требуется знать логарифм вероят-ности, которую модель назначает каждой точке, а для этого, в свою очередь, нужно вычислить статистическую сумму. Ситуацию можно немного упростить, переписав (18.38) в виде, где нужно знать только отношение статистических сумм двух моделей: (18.39) Таким образом, мы можем установить, что модель ℳA лучше ℳB, не зная статисти- ческую сумму каждой модели, а зная только их отношение. Как мы вскоре увидим, это отношение можно оценить с помощью выборки по значимости, при условии что обе модели похожи. Однако если бы мы захотели вычислить фактическую вероятность тестовых дан- ных в модели ℳA или ℳB, то пришлось бы вычислять значения самых статистических сумм. Но если бы мы знали отношение статистических сумм r = Z(θB)/Z(θA) и факти- ческое значение хотя бы одной из них, скажем Z(θA), то могли бы вычислить значение другой: (18.40) Для оценки статистической суммы можно воспользоваться методом Монте-Карло, например простой выборкой по значимости. Мы опишем этот подход для непрерыв-ных случайных величин, но он легко переносится и на дискретные величины – нужно только заменить интегрирование суммированием. Воспользуемся вспомогательным распределением p 0(x) = (1/Z0)p~ 0(x), для которого возможно произвести выборку и вы- числить как статистическую сумму Z0, так и ненормированное распределение p~ 0(x).\n--- Страница 526 ---\nОценивание статистической суммы  525 (18.41) (18.42) (18.43) , где x(k) ∼ p0. (18.44) В последней строчке записана оценка Монте-Карло Zˆ 1 интеграла, полученная по- средством выборки из p0(x) с последующим умножением каждого примера на вес, равный отношению ненормированного распределения p~ 1 к вспомогательному p0. Этот подход позволяет также оценить отношение статистических сумм в виде: , где x(k) ∼ p0. (18.45) Затем это значение можно использовать непосредственно для сравнения двух мо- делей, как описано в формуле (18.39). Если распределение p0 близко к p1, то выражение (18.44) может дать эффектив- ный способ оценивания статистической суммы (Minka, 2005). К сожалению, в боль- шинстве случаев p1 не только сложное (обычно многомодальное), но и определено в прост ранстве высокой размерности. Трудно найти распределение p0, которое было бы, с одной стороны, достаточно простым для вычисления, а с другой – достаточно близким к p1, чтобы дать высококачественную аппроксимацию. Если p0 и p1 не близки, то у большинства примеров из p0 будет низкая вероятность относительно p1, поэтому они вносят (сравнительно) пренебрежимо малый вклад в сумму в выражении (18.44). Присутствие в этой сумме небольшого числа примеров со значительными весами приводит к оценке низкого качества из-за высокой дисперсии. Количественно это можно понять, оценив дисперсию нашей оценки Z ˆ 1: (18.46) Эта величина будет наибольшей, когда имеется значительное расхождение между значениями весов p~ 1(x(k))/p~ 0(x(k)). Теперь обратимся к двум родственным стратегиям, предназначенным для решения трудной задачи оценивания статистической суммы сложных распределений в много- мерных пространствах: выборке по значимости с отжигом и мостиковой выборке. Обе начинаются с простой выборки по значимости, описанной выше, и стремятся решить проблему непохожести вспомогательного распределения p0 на p1, вводя промежуточ- ные распределения, наводящие мост между p0 и p1. 18.7.1. Выборка по значимости с отжигом В ситуациях, когда расстояние Кульбака–Лейблера DKL(p0||p1) велико (т. е. пере- крытие между p0 и p1 мало), стратегия выборки по значимости с отжигом (annealed importance sampling – AIS) пытается перебросить мост между двумя распределения-\n--- Страница 527 ---\n526  Преодоление трудностей, связанных со статической суммой ми, вводя промежуточные распределения (Jarzynski, 1997; Neal, 2001). Рассмотрим последовательность распределений pη0, …, pηn, где 0 = η0 < η1 < … < ηn–1 < ηn = 1, такую, что первое распределение в последовательности совпадает с p0, а последнее – с p1. Это позволяет оценить статистическую сумму многомодального распределения в многомерном пространстве (например, распределения, соответствующего обучен- ной ОМБ). Мы начинаем с более простой модели с известной статистической суммой (например, ОМБ с нулевыми весами) и оцениваем отношение между статистически- ми суммами двух моделей. Оценка этого отношения основана на оценке отношений последовательности многих похожих распределений, например последовательности ОМБ с весами, образующими интерполяцию между нулевыми и обученными весами. Отношение Z 1/Z0 можно записать в виде: (18.47) (18.48) (18.49) При условии что распределения pηj и pηj+1 достаточно близки для всех 0 ≤ j ≤ n – 1, мы можем надежно оценить каждый сомножитель Zηj+1/Zηj с помощью простой выбор- ки по значимости, а затем воспользоваться этими оценками для получения оценки Z1/Z0. Откуда берутся эти промежуточные распределения? Так же как и вспомогательное распределение p, они задаются проектировщиком, т. е. специально строятся под конк- ретную задачу. Часто в качестве промежуточных распределений берут взвешенное среднее геометрическое целевого распределения p1 и начального вспомогательного распределения p0, для которого статистическая сумма известна: pηj ∝ p1ηj p01–ηj. (18.50) Для выборки из этих промежуточных распределений мы определяем последова- тельность переходных функций марковской цепи Tηj(x′ | x), которые задают услов- ное распределение вероятности перехода в x′ при условии нахождения в x. Оператор перехода Tηj(x′ | x) определяется так, чтобы pηj(x) было инвариантным: (18.51) Эти переходы можно строить в виде любого MCMC-метода (например, Метропо- лиса–Гастингса или Гиббса), в т. ч. и включающего несколько проходов по всем слу- чайным величинам или какую-то другую форму итерации. Стратегия выборки AIS заключается в том, чтобы произвести выборку из p0, а за- тем с помощью операторов перехода последовательно порождать выборки из проме- жуточных распределений, пока не дойдем до выборки из целевого распределения p1: for k = 1 … K – произвести выборку xη1(k) ∼ p0(x) – произвести выборку xη2(k) ∼ Tη1(xη2(k) | xη1(k)) – …\n--- Страница 528 ---\nОценивание статистической суммы  527 – произвести выборку x(k) ηn–1 ∼ Tηn–2(x(k) ηn–1 | x(k) ηn–2) – произвести выборку x(k) ηn ∼ Tηn–1(xηn(k) | x(k) ηn–1) end Для k-ой выборки мы можем вывести вес значимости, перемножив веса значимо- сти для переходов между промежуточными распределениями в выражении (18.49): (18.52) Во избежание численных трудностей, в т. ч. переполнения, лучше вычислять log w(k), складывая и вычитая логарифмы вероятностей, а не сам вес w(k), для чего тре- буется выполнять умножение и деление. При так определенной процедуре выборки и вычисления весов значимости полу- чается следующая оценка отношения статистических сумм: (18.53) Для проверки того, что эта процедура определяет корректную схему выборки по значимости, можно показать (Neal, 2001), что она соответствует простой выборке по значимости в расширенном пространстве состояний, когда точки выбираются из про- изведения пространств [xη1, …, xηn–1, x1]. Для этого определим распределение в расши- ренном пространстве: p~(xη1, …, xηn–1, x1) (18.54) = p~ 1(x1)T~ ηn–1(xηn–1 | x1)T~ ηn–2(xηn–2 | xηn–1) … T~ η1(xη1 | xη2), (18.55) где T~ a – обращение оператора перехода Ta (путем применения правила Байеса): . (18.56) Подставляя это в выражение для совместного распределения в расширенном прост ранстве состояний (18.55), имеем: p~(xη1, …, xηn–1, x1) (18.57) (18.58) (18.59) Теперь мы получили способ произвести выборку из совместного вспомогательного распределения q в расширенном пространстве, которое определяется формулой: q(xη1, …, xηn–1, x1) = p0(xη1)Tη1(xη2 | xη1) … Tηn–1(x1 | xηn–1). (18.60) Мы имеем совместное распределение в расширенном пространстве, описываемое формулой (18.59). Если взять q(xη1, …, xηn–1, x1) в качестве вспомогательного распреде- ления в расширенном пространстве, из которого мы можем произвести выборку, то останется определить веса значимости:\n--- Страница 529 ---\n528  Преодоление трудностей, связанных со статической суммой (18.61) Это те же веса, что предложенные в алгоритме AIS. Следовательно, AIS можно интерпретировать как простую выборку по значимости в применении к расширенно- му состоянию, и его корректность немедленно вытекает из корректности выборки по значимости. Выборка по значимости с отжигом впервые была предложена в работе Jarzynski (1997), а затем независимо в работе Neal (2001). В настоящее время это самый рас- пространенный способ оценивания статистической суммы для неориентированных вероятностных моделей. Возможно, это больше связано с авторитетом авторов пуб- ликации Salakhutdinov and Murray (2008), в которой описывается его применение к оцениванию статистической суммы ограниченных машин Больцмана и глубоких сетей доверия, чем с внутренне присущими методу достоинствами. Обсуждение свойств оценки AIS (в частности, дисперсии и эффективности) име- ется в работе Neal (2001). 18.7.2. Мостиковая выборка Мостиковая выборка (bridge sampling) (Bennett, 1976) – еще один метод, который, как и AIS, направлен на преодоление недостатков выборки по значимости. Но вместо цепочки промежуточных распределений в методе мостиковой выборки используется единственное распределение p*, называемое мостиком, для интерполяции между рас- пределением с известной статистической суммой p0 и распределением p1, для которо- го мы пытаемся оценить статистическую сумму Z1. В методе мостиковой выборки отношение Z1/Z0 оценивается как отношение ожи- даемых весов значимости между p~ 0 и p~ * и между p~ 1 и p~ *: (18.62) Если мостиковое распределение p* тщательно выбрано таким образом, что оно сильно перекрывается и с p0, и с p1, то мостиковая выборка допускает гораздо большее расстояние между двумя распределениями (точнее, DKL(p0||p1)), чем при стандартной выборке по значимости. Можно показать, что оптимальное мостиковое распределение описывается форму- лой p*(opt)(x) ∝ (p~ 0(x)p~ 1(x))/(rp~ 0(x) + p~ 1(x)), где r = Z1/Z0. На первый взгляд кажется, что это бесполезная конструкция, потому что в выражение входит именно та величи- на, которую мы и пытаемся оценить, Z1/Z0. Но можно начать с грубой оценки r и ис- пользовать получившееся мостиковое распределение для ее итеративного уточнения (Neal, 2005). То есть мы итеративно пересчитываем отношение и на каждой итерации обновляем значение r. Связанная выборка по значимости. У обоих методов – AIS и мостиковой выбор- ки – есть свои плюсы. Если D KL(p0||p1) не слишком велико (поскольку p0 и p1 достаточ- но близки), то мостиковая выборка может оказаться более эффективным способом оценивания отношения статистических сумм, чем AIS. Если же два распределения отстоят слишком далеко друг от друга, чтобы для наведения моста между ними хва-тило одного распределения p *, то для перехода от p0 к p1 можно использовать AIS с не-\n--- Страница 530 ---\nОценивание статистической суммы  529 сколькими промежуточными распределениями. В работе Neal (2005) показано, как метод связанной выборки по значимости может воспользоваться стратегией мости- ковой выборки, чтобы связать промежуточные распределения, используемые в AIS, и существенно улучшить общую оценку статистической суммы. Оценивание статистической суммы на этапе обучения. Хотя AIS принят в каче- стве стандартного метода оценивания статистической суммы для многих неориен-тированных моделей, он требует настолько большого объема вычислений, что ис-пользовать его на этапе обучения невозможно. Изучались альтернативные стратегии, позволяющие вычислять оценку статистической суммы в процессе обучения. Применив комбинацию мостиковой выборки, AIS с короткой цепочкой и парал- лельное темперирование, авторы работы Desjardins et al. (2011) придумали, как про-слеживать статистическую сумму ОМБ на всем протяжении обучения. Стратегия основана на хранении независимых оценок статистических сумм ОМБ при каждом значении температуры в схеме параллельного темперирования. Авторы объединили оценки мостиковой выборки отношений статистических сумм соседних цепочек (по-лученных параллельным темперированием) с оценками AIS в разные моменты вре- мени и в результате получили оценку статистической суммы с низкой дисперсией на каждой итерации обучения. Описанные в этой главе средства дают много способов преодолеть проблему вы- числительно неразрешимых статистических сумм, но в обучении и использовании порождающих моделей есть и другие трудности. Самая главная из них – проблема неразрешимого вывода, к которой мы и переходим.",
      "debug": {
        "start_page": 509,
        "end_page": 530
      }
    },
    {
      "name": "Глава 19. Приближенный вывод 530",
      "content": "--- Страница 531 --- (продолжение)\nГлава 19 Приближенный вывод Многие вероятностные модели сложно обучить из-за трудностей вывода. В контекс- те глубокого обучения у нас обычно имеется множество наблюдаемых переменных v и множество латентных переменных h. Говоря о трудности вывода, мы обычно имеем в виду проблему вычисления p(h | v) или математических ожиданий относительно этого распределения. Такие операции необходимы, например, при обучении с ис- пользованием максимального правдоподобия. Многие простые графические модели с одним скрытым слоем, например ограни- ченные машины Больцмана и вероятностный метод главных компонент, определены таким образом, что операции вывода типа вычисления p(h | v) или математического ожидания выполняются просто. К сожалению, в большинстве графических моделей с несколькими скрытыми слоями апостериорные распределения не поддаются вы- числению. В таких моделях любая операция точного вывода требует экспоненциаль- ного времени. И эта проблема существует даже в некоторых однослойных моделях, например в модели разреженного кодирования. В этой главе мы познакомимся с некоторыми приемами преодоления проблемы неразрешимого вывода. А в главе 20 опишем, как они применяются к обучению веро- ятностных моделей, которые иначе оказались бы неразрешимыми, в т. ч. к глубоким сетям доверия и к глубоким машинам Больцмана. Неразрешимые проблемы вывода в глубоком обучении обычно возникают из-за взаимодействий между латентными переменными в структурной графической моде- ли. На рис. 19.1 показано несколько примеров. Это могут быть прямые взаимодей-ствия в неориентированных моделях или «оправдывающие» взаимодействия между предками одного и того же видимого блока в ориентированных моделях. 19.1. Вывод как оптимизация Во многих подходах к решению проблемы трудного вывода используется тот факт, что точный вывод можно описать как задачу оптимизации. Поэтому можно постро-ить приближенный алгоритм вывода, аппроксимируя соответствующую задачу оп-тимизации. Для построения задачи оптимизации предположим, что имеется вероятностная модель, содержащая наблюдаемые переменные v и латентные переменные h. Мы хо- тели бы вычислить логарифмическое распределение вероятности наблюдаемых дан-ных log p(v; θ). Иногда вычислить log p(v; θ) слишком трудно, если исключение h обходится дорого. Вместо этого мы можем вычислить нижнюю границу ℒ(v, θ, q) ве- личины log p(v; θ). Эта граница называется нижней границей свидетельств (evidence\nГлава 19 Приближенный вывод Многие вероятностные модели сложно обучить из-за трудностей вывода. В контекс- те глубокого обучения у нас обычно имеется множество наблюдаемых переменных v и множество латентных переменных h. Говоря о трудности вывода, мы обычно имеем в виду проблему вычисления p(h | v) или математических ожиданий относительно этого распределения. Такие операции необходимы, например, при обучении с ис- пользованием максимального правдоподобия. Многие простые графические модели с одним скрытым слоем, например ограни- ченные машины Больцмана и вероятностный метод главных компонент, определены таким образом, что операции вывода типа вычисления p(h | v) или математического ожидания выполняются просто. К сожалению, в большинстве графических моделей с несколькими скрытыми слоями апостериорные распределения не поддаются вы- числению. В таких моделях любая операция точного вывода требует экспоненциаль- ного времени. И эта проблема существует даже в некоторых однослойных моделях, например в модели разреженного кодирования. В этой главе мы познакомимся с некоторыми приемами преодоления проблемы неразрешимого вывода. А в главе 20 опишем, как они применяются к обучению веро- ятностных моделей, которые иначе оказались бы неразрешимыми, в т. ч. к глубоким сетям доверия и к глубоким машинам Больцмана. Неразрешимые проблемы вывода в глубоком обучении обычно возникают из-за взаимодействий между латентными переменными в структурной графической моде- ли. На рис. 19.1 показано несколько примеров. Это могут быть прямые взаимодей-ствия в неориентированных моделях или «оправдывающие» взаимодействия между предками одного и того же видимого блока в ориентированных моделях. 19.1. Вывод как оптимизация Во многих подходах к решению проблемы трудного вывода используется тот факт, что точный вывод можно описать как задачу оптимизации. Поэтому можно постро-ить приближенный алгоритм вывода, аппроксимируя соответствующую задачу оп-тимизации. Для построения задачи оптимизации предположим, что имеется вероятностная модель, содержащая наблюдаемые переменные v и латентные переменные h. Мы хо- тели бы вычислить логарифмическое распределение вероятности наблюдаемых дан-ных log p(v; θ). Иногда вычислить log p(v; θ) слишком трудно, если исключение h обходится дорого. Вместо этого мы можем вычислить нижнюю границу ℒ(v, θ, q) ве- личины log p(v; θ). Эта граница называется нижней границей свидетельств (evidence\n--- Страница 532 ---\nВывод как оптимизация  531 lower bound – ELBO), а также отрицательной вариационной свободной энергией. Точнее говоря, нижняя граница свидетельств определена как ℒ(v, θ, q) = log p(v; θ) – DKL(q(h | v)|| p(h | v; θ)), (19.1) где q – произвольное распределение вероятности h. Рис. 19.1  Неразрешимые проблемы вывода в глубоком обучении обыч- но являются результатом взаимодействий между латентными переменны- ми в структурной графической модели. Эти взаимодействия могут быть вызваны ребрами, непосредственно соединяющими две латентные пере-менные, или более длинными путями, которые активируются, когда пото- мок V-структуры – наблюдаемая переменная. (Слева) Полуограниченная машина Больцмана (Osindero and Hinton, 2008) со связями между скры-тыми блоками. Из-за этих прямых связей между латентными переменными апостериорное распределение неразрешимо, поскольку имеются большие клики латентных переменных. (В центре) Для глубокой машины Больцмана, состоящей из слоев переменных без внутрислойных связей, апостериор-ное распределение все равно неразрешимо из-за связей между слоями. (Справа) В этой ориентированной модели взаимодействия между латент- ными переменными присутствуют, когда видимые переменные наблюдае-мые, поскольку каждые две латентные переменные являются родителями одной видимой. В некоторых вероятностных моделях вывод латентных переменных все-таки возможен, несмотря на изображенные на рисунке графические структуры. Так бывает, когда условные распределения вероят-ности выбраны так, что вносят дополнительные отношения независимости помимо представленных в графе. Например, в вероятностном методе глав- ных компонент структура графа такая, как на правом рисунке, но вывод тем не менее простой благодаря специальным свойствам конкретных услов ных распределений (линейная комбинация нормальных распределений с вза- имно ортогональными базисными векторами) Поскольку разность между log p(v) и ℒ(v, θ, q) равна расхождению Кульбака– Лейб лера, а оно всегда неотрицательно, то ℒ не может быть больше интересующего нас логарифма вероятности. Равенство достигается тогда и только тогда, когда рас- пределения q и p(h | v) в точности совпадают. Как ни странно, для некоторых распределений q вычислить ℒ гораздо проще. С по- мощью простых алгебраических преобразований мы можем привести ℒ к более удоб- ному виду:\n--- Страница 533 ---\n532  Приближенный вывод ℒ(v, θ, q) = log p(v; θ) – DKL(q(h | v)||p(h | v; θ)), (19.2) (19.3) (19.4) = log p(v; θ) – 𝔼h∼q [log q(h | v) – log p(h, v; θ) + log p(v; θ)] (19.5) = – 𝔼h∼q [log q(h | v) – log p(h, v; θ)]. (19.6) В результате приходим к каноническому определению нижней границы свиде- тельств: ℒ(v, θ, q) = 𝔼h∼q[log p(h, v)] + H(q). (19.7) При подходящем выборе q функцию ℒ можно вычислить. При любом выборе q ℒ дает нижнюю границу правдоподобия. Чем лучше q(h | v) аппроксимирует p(h | v), тем граница ℒ точнее, т. е. ближе к log p(v). Когда q(h | v) = p(h | v), аппроксимация идеальна и ℒ(v, θ, q) = log p(h, θ). Мы можем рассматривать вывод как процедуру нахождения q, доставляющего максимум ℒ. Точный вывод максимизирует ℒ идеально, т. к. поиск производится во всем семействе функций q, включающем p(h | v). В этой главе мы продемонстрируем различные виды приближенного вывода с использованием приближенной оптимиза- ции для нахождения q. Мы можем сделать процедуру оптимизации менее дорогой, но приближенной, ограничив семейство распределений q, в котором разрешено произ- водить поиск, или применяя неточную процедуру оптимизации, которая, возможно, не находит истинного максимума функции ℒ, а просто значительно увеличивает ее. При любом выборе q функция ℒ остается нижней границей. Граница может быть более или менее точной, более или менее дешевой для вычисления в зависимости от того, какой выбрать подход к задаче оптимизации. Можно получить плохую ап- проксимацию q, но уменьшить вычислительную стоимость, воспользовавшись либо неточной процедурой оптимизации, либо точной процедурой, но по ограниченному семейству распределений q. 19.2. EM-алгоритм Первый основанный на максимизации нижней границы ℒ алгоритм, который мы рас- смотрим, – это популярный EM-алгоритм (expectation maximization) обучения моде- лей с латентными переменными. Здесь мы опишем его интерпретацию, предложен- ную в работе Neal and Hinton (1999). В отличие от большинства других алгоритмов в этой главе, EM – это подход не столько к приближенному выводу, сколько к обуче- нию с приближенным апостериорным распределением. EM-алгоритм состоит из двух чередующихся шагов, повторяемых до достижения сходимости. E-шаг (вычисление математического ожидания). Обозначим θ(0) значение па- раметров в начале шага. Положим q(h(i) | v) = p(h(i) | v(i); θ(0)) для всех индексов i примеров v(i), на которых мы производим обучение (допустимы оба варианта: пакетный и мини-пакетный). Таким образом, q определено в терминах теку-\n--- Страница 534 ---\nMAP-вывод и разреженное кодирование  533 щего значения параметра θ(0); если мы изменим θ, то p(h | v; θ) изменится, но q(h | v) останется равным = p(h | v; θ(0)). M-шаг (максимизация). Полностью или частично максимизировать выра- жение (19.8) относительно θ, воспользовавшись любым удобным алгоритмом. Это можно рассматривать как алгоритм покоординатного восхождения для мак- симизации ℒ. На одном шаге мы максимизируем ℒ относительно q, а на другом – ℒ относительно θ. Стохастическое градиентное восхождение в моделях с латентными переменными можно рассматривать как частный случай EM-алгоритма, в котором M-шаг состоит из одного шага вычисления градиента. В других вариантах EM-алгоритма таких ша- гов может быть гораздо больше. Для некоторых семейств моделей M-шаг можно даже выполнять аналитически, находя оптимальное θ при текущем q. Несмотря на то что E-шаг включает точный вывод, мы можем считать, что в EM- алгоритме в некотором смысле используется приближенный вывод. Точнее говоря, на M-шаге предполагается, что одно и то же значение q можно использовать для всех значений θ. Это порождает разрыв между ℒ и истинным log p(v), по мере того как M-шаг все дальше уходит от значения θ(0) на E-шаге. По счастью, E-шаг снова сокра- тит этот разрыв до нуля при следующем входе в цикл. EM-алгоритм содержит несколько разных идей. Прежде всего присутствует базо- вая структура процесса обучения, согласно которой мы обновляем параметры модели с целью повысить правдоподобие пополненного набора данных, в котором все отсут- ствующие переменные получили значения, предлагаемые оценкой апостериорного распределения. Эта идея встречается не только в EM-алгоритме. Например, примене- ние градиентного спуска для максимизации логарифмического правдоподобия обла-дает тем же свойством; для вычисления градиента логарифмического правдоподобия нужно находить математические ожидания относительно апостериорного распреде-ления скрытых блоков. Еще одна важная идея EM-алгоритма – то, что мы можем продолжать использовать одно значение q даже после того, как перешли к другому значению θ. Эта идея повсеместно используется в классическом машинном обуче- нии для обновлений с большим M-шагом. В контексте глубокого обучения модели, как правило, слишком сложны, чтобы можно было найти оптимальное обновление с большим M-шагом, так что эта вторая идея, в большей степени относящаяся именно к EM-алгоритму, используется редко. 19.3. MAP-вывод и разреженное кодирование Обычно термин вывод относится к вычислению распределения вероятности одного множества переменных при условии другого множества. При обучении вероятност- ных моделей с латентными переменными нас обычно интересует вычисление p(h | v). Альтернативная форма вывода заключается в вычислении одного самого вероятного значения отсутствующих переменных, а не вывода всего распределения их возмож- ных значений. В контексте моделей с латентными переменными это означает, что нужно вычислить\n--- Страница 535 ---\n534  Приближенный вывод (19.9) Это называется выводом апостериорного максимума, или MAP-выводом. MAP-вывод обычно не считается приближенным выводом, т. к. он сводится к точ- ному вычислению самого вероятного значения h*. Однако если мы хотим разработать процесс обучения, основанный на максимизации ℒ(v, h, q), то полезно рассматривать MAP-вывод как процедуру, поставляющую значение q. В этом смысле можно интер- претировать MAP-вывод как приближенный вывод, поскольку он не дает оптималь-ного q. Напомним (см. раздел 19.1), что точный вывод заключается в максимизации функции ℒ(v, θ, q) = 𝔼 h∼q[log p(h, v)] + H(q) (19.10) относительно q на неограниченном семействе распределений вероятности с приме- нением точного алгоритма оптимизации. Мы можем определить MAP-вывод как вид приближенного вывода, ограничив семейство распределений, из которого выбирает-ся q. Точнее говоря, потребуем, чтобы q было распределением Дирака: q(h | v) = δ(h – μ). (19.11) Это означает, что теперь мы можем управлять q с помощью одного лишь параметра μ. Если опустить члены ℒ, не зависящие от μ, то остается такая задача оптимизации: (19.13) эквивалентная задаче MAP-вывода (19.13) Таким образом, мы можем обосновать процедуру обучения, похожую на EM-ал- горитм, в которой MAP-вывод h* чередуется с обновлением θ с целью увеличения log p(h*, v). Как и EM-алгоритм, это вариант покоординатного спуска по ℒ, когда ис- пользование вывода для оптимизации ℒ относительно q чередуется с обновлением параметров для оптимизации ℒ относительно θ. В обоснование процедуры в целом можно сослаться на тот факт, что ℒ является нижней границей log p(v). В случае MAP-вывода это обоснование бессодержательно, т. к. граница бесконечно неточная из-за того, что дифференциальная энтропия распределения Дирака равна минус бес- конечности. Но прибавление шума к μ снова делает границу осмысленной. MAP-вывод обычно используется в глубоком обучении для выделения признаков и в качестве механизма обучения. Основное применение он находит в моделях разре- женного кодирования. Напомним (раздел 13.4), что разреженное кодирование – это линейная факторная модель с априорным распределением скрытых блоков, индуци- рующим разреженность. Чаще всего выбирается факторное априорное распределе-ние Лапласа, для которого p(h i) = (λ/2)e–λ|hi|. (19.14) Затем видимые блоки порождаются путем выполнения линейного преобразования и прибавления шума:\n--- Страница 536 ---\nВариационный вывод и обучение  535 p(x | h) = 𝒩(v; Wh + b, β–1I). (19.15) Вычислить или хотя бы представить p(h | v) трудно. Любые две переменные hi и hj являются родителями v. Это означает, что если v наблюдаемая, то графическая мо- дель содержит активный путь, соединяющий hi и hj. Следовательно, все скрытые бло- ки принадлежат одной большой клике в p(h | v). Если бы модель была гауссовой, то эти взаимодействия можно было бы эффективно смоделировать с помощью ковариа- ционной матрицы, но из-за разреженности априорного распределения взаимодей- ствия гауссовыми не являются. Поскольку p(h | v) вычислительно неразрешима, то таковы же логарифмическое правдоподобие и его градиент. Поэтому мы не можем воспользоваться точным обуче- нием с критерием максимального правдоподобия. Вместо этого мы применим MAP- вывод и будем обучать параметры путем максимизации ELBO, определяемой рас- пределением Дирака вокруг MAP-оценки h. Если собрать все векторы h из обучающего набора в матрицу H, а все векторы v – в матрицу V, то процесс обучения модели разреженного кодирования сведется к ми- нимизации функции (19.16) В большинстве применений разреженного кодирования участвует также снижение весов или ограничение на нормы столбцов W, чтобы предотвратить патологическое решение с очень малой H и большой W. Для минимизации J мы можем чередовать минимизацию относительно H с мини- мизацией относительно W. Обе подзадачи выпуклые. На самом деле минимизация относительно W – просто задача линейной регрессии. Но минимизация J относи- тельно обоих аргументов обычно не является выпуклой задачей. Для минимизации относительно H требуются специальные алгоритмы, например алгоритм поиска знака признака (Lee et al., 2007). 19.4. Вариационный вывод и обучение Мы видели, что нижняя граница свидетельств ℒ(v, θ, q) является нижней границей log p(v; θ), что вывод можно рассматривать как максимизацию ℒ относительно q, а обуче ние – как максимизацию ℒ относительно θ. Мы видели, что EM-алгоритм по- зволяет делать большие шаги обучения с фиксированным q и что алгоритмы обуче- ния, основанные на MAP-выводе, дают возможность обучать модель с применением точечной оценки p(h | v), не выводя всего распределения целиком. Теперь разработа- ем более общий подход к вариационному обучению. Основная идея вариационного обучения заключается в том, чтобы максимизиро- вать ℒ на ограниченном семействе распределений q. Это семейство следует выбирать так, чтобы было легко вычислить 𝔼qlog p(h | v). Обычно для этого вводятся предпо- ложения о способе представления q в виде произведения. Типичный подход к вариационному обучению – потребовать, чтобы q было фак- торным распределением: (19.17)\n--- Страница 537 ---\n536  Приближенный вывод Это так называемый подход среднего поля. В общем случае мы можем наложить на q структуру произвольной графической модели, чтобы гибко определить, сколько взаимодействий должна улавливать наша аппроксимация. Такой общий подход на- зывается структурным вариационным выводом (Saul and Jordan, 1996). Элегантность вариационного подхода состоит в том, что не нужно задавать конк- ретную параметрическую форму q. Мы описываем, как оно должно факторизовать- ся, но затем задача оптимизации сама определяет оптимальное распределение веро-ятности, удовлетворяющее этим ограничениям на факторизацию. Для дискретных латентных переменных это просто означает, что мы пользуемся традиционными ме-тодами оптимизации конечного числа переменных, описывающих распределение q. Для непрерывных латентных переменных это означает использование раздела мате-матики, называемого вариационным исчислением, для оптимизации на пространстве функций, в результате чего определяется, какой функцией представлять q. Именно вариационное исчисление стоит за терминами «вариационное обучение» и «вариа- ционный вывод», хотя они применяются и в том случае, когда латентные переменные дискретны и вариационное исчисление ни при чем. В случае непрерывных латентных переменных вариационное исчисление оказывается мощной техникой, снимающей большую часть забот с проектировщика модели, который теперь должен только за- дать вид факторизации q, а не гадать, как спроектировать конкретное q, способное верно аппроксимировать апостериорное распределение. Поскольку ℒ(v, θ, q) определена как log p(v; θ) – D KL(q(h | v)||p(h | v; θ)), то максимизацию ℒ относительно q можно интерпретировать как минимизацию DKL(q(h | v)||p(h | v)). В этом смысле мы подгоняем q к p. Однако при этом направ- ление расхождения Кульбака–Лейблера противоположно тому, к которому мы при- выкли при подгонке аппроксимации. Если для подгонки модели к данным применя- ется критерий максимального правдоподобия, то мы минимизируем DKL(pdata||pmodel). Как показано на рис. 3.6, это означает, что максимальное правдоподобие поощряет модель иметь высокую вероятность всюду, где высока вероятность данных, тогда как наша основанная на оптимизации процедура вывода поощряет q иметь низкую веро- ятность там, где низка вероятность апостериорного распределения. У обоих направ- лений расхождения Кульбака–Лейблера есть желательные и нежелательные свой- ства. Какое из них использовать, зависит от того, какие свойства приоритетны для приложения. В задаче оптимизации вывода мы выбрали D KL(q(h | v)||p(h | v)) из сооб- ражений удобства вычислений. Точнее говоря, для вычисления DKL(q(h | v)||p(h | v)) нужно вычислять математические ожидания относительно q, поэтому, проектируя простое q, мы можем упростить вычисление математических ожиданий. При про- тивоположном направлении расхождения КЛ понадобилось бы вычислять матема-тические ожидания относительно истинного апостериорного распределения. По-скольку форма этого распределения определяется выбором модели, мы не можем точно спроектировать способ вычисления D KL(p(h | v)||q(h | v)), характеризующийся низкой стоимостью. 19.4.1. Дискретные латентные переменные Вариационный вывод с дискретными латентными переменными относительно прост. Мы определяем распределение q, обычно такое, в котором каждый фактор описы- вается справочной таблицей дискретных состояний. В простейшем случае вектор h бинарный, и мы можем принять предположение среднего поля, согласно которому\n--- Страница 538 ---\nВариационный вывод и обучение  537 q является произведением отдельных hi. В таком случае можно параметризовать q вектором h ˆ, элементами которого являются вероятности. Тогда q(hi = 1 | v) = h ˆ i. Решив, как представлять q, мы затем просто оптимизируем параметры. Если ла- тентные переменные дискретны, то это стандартная задача оптимизации. В принци- пе, для выбора q можно было бы применить любой алгоритм оптимизации, например градиентный спуск. Поскольку эта оптимизация производится во внутреннем цикле алгоритма обуче- ния, она должна быть очень быстрой. Для достижения нужной скорости обычно при- меняются специальные алгоритмы для решения сравнительно небольших и простых задач за малое число итераций. Распространенный выбор – итерационный поиск не- подвижной точки, т. е. решение уравнений вида (19.18) относительно hˆ i. Мы повторно обновляем различные элементы hˆ, пока не будет удов- летворен критерий сходимости. Для конкретности покажем, как вариационный вывод применяется к модели би- нарного разреженного кодирования (мы используем модель из работы Henniges et al. [2010], но демонстрируем традиционный общий подход на основе среднего поля, тогда как авторы разработали специализированный алгоритм). В выводе довольно много математических деталей, он предназначен для читателей, которые хотят разре-шить все неоднозначности приведенного выше высокоуровневого описания вариаци-онного вывода и обучения. Читатели, не планирующие разрабатывать или реализо- вывать алгоритмы вариационного обучения, могут без ущерба для понимания сразу перейти к следующему разделу. Тем же, кто решил разобраться в примере бинарного разреженного кодирования, мы рекомендуем освежить в памяти полезные свойства функций, часто встречающихся в вероятностных моделях (см. раздел 3.10). Мы бу- дем пользоваться ими без дальнейших оговорок. В модели бинарного разреженного кодирования вход v ∈ ℝ n генерируется по моде- ли посредством прибавления гауссова шума к сумме m различных компонент, каждая из которых может присутствовать или отсутствовать. Каждая компонента включает-ся или выключается соответствующим скрытым блоком в h ∈ {0, 1} m: p(hi = 1) = σ(bi), (19.19) p(v | h) = 𝒩(v; Wh, β–1), (19.20) где b – обучаемый вектор смещений, W – обучаемая матрица весов, а β – обучаемая диагональная матрица точности. Для обучения этой модели с критерием максимального правдоподобия необходи- мо брать производные по параметрам. Рассмотрим производную по одному из сме-щений: (19.21) (19.22)\n--- Страница 539 ---\n538  Приближенный вывод (19.23) (19.24) (19.25) (19.26) (19.27) Здесь требуется вычислять математические ожидания относительно p(h | v). К со- жалению, p(h | v) – сложное распределение. На рис. 19.2 показана структура графов p(h, v) и p(h | v). Апостериорному распределению соответствует полный граф скры- тых блоков, поэтому алгоритмы исключения переменных не помогут вычислить нуж- ных математических ожиданий быстрее, чем полным перебором. Рис. 19.2  Структура графа модели бинарного разреженного кодирова- ния с четырьмя скрытыми блоками. (Слева) Структура графа p(h, v). Отме- тим, что ребра ориентированные и что два любых скрытых блока являют- ся родителями каждого видимого блока. (Справа) Структура графа p(h | v). Чтобы учесть активные пути между сородителями, в апостериорном рас- пределении должно быть проведено ребро между любыми двумя скрытыми блоками Эту трудность можно разрешить, воспользовавшись вариационным выводом и ва- риационным обучением. Применим аппроксимацию среднего поля: (19.28) Латентные переменные в модели бинарного разреженного кодирования являются бинарными, поэтому для представления факторного распределения q нам нужно прос- то смоделировать m распределений Бернулли q(hi | v). Средние распределений Бер-\n--- Страница 540 ---\nВариационный вывод и обучение  539 нулли естественно представить вектором вероятностей hˆ – таким, что q(hi = 1 | v) = hˆ i. Наложим ограничение – hˆ i не может быть равно 0 или 1, – чтобы избежать ошибок при вычислении, например log h ˆ i. Как мы увидим, уравнения вариационного вывода никогда не присваивают hˆ i значение 0 или 1 аналитически. Но в программной реализации из-за ошибок округ- ления такие значения возможны. Программно мы могли бы реализовать двоичное разреженное кодирование, используя неограниченный вектор вариационных пара-метров z, и получить hˆ из соотношения hˆ = σ(z). Тогда можно безопасно вычислять log hˆ i, применяя тождество log σ(zi) = –ζ (–zi), связывающее сигмоиду с функцией softplus. Приступая к выводу уравнений вариационного обучения в модели бинарного раз- реженного кодирования, покажем, что благодаря использованию аппроксимации среднего поля обучение становится вычислительно разрешимым. Нижняя граница свидетельств имеет вид: ℒ(v; θ; q) (19.29) = 𝔼 h~q[log p(h, v)] + H(q) (19.30) = 𝔼h~q[log p(h) + log p(v | h) – log q(h | v)] (19.31) (19.32) (19.33) (19.34) (19.35) (19.36) Выглядят эти уравнения не очень эстетично, но показывают, что ℒ можно выразить с помощью небольшого числа простых арифметических операций. Поэтому нижняя граница свидетельств ℒ разрешима. Мы можем использовать ℒ вместо неразрешимо- го логарифмического правдоподобия. В принципе, можно было бы просто выполнить градиентное восхождение по v и h, получив тем самым вполне приемлемую комбинацию алгоритмов вывода и обуче- ния. Но обычно так не поступают по двум причинам. Во-первых, понадобилось бы хранить hˆ для каждого v, а мы все же предпочитаем алгоритмы, не требующие вы- деления памяти для каждого примера. Трудно масштабировать алгоритмы обучения на миллиарды примеров, если для каждого необходимо хранить динамически обнов-ляемый вектор. Во-вторых, хотелось бы очень быстро выделять признаки hˆ, чтобы распознавать содержимое v. В настоящей развернутой системе требуется вычислять hˆ в режиме реального времени. По этим причинам градиентное восхождение обычно не применяется для вычис- ления параметров среднего поля hˆ. Вместо этого мы производим их быструю оценку с помощью уравнений неподвижной точки.\n--- Страница 541 ---\n540  Приближенный вывод Идея этих уравнений – в том, что мы ищем локальный максимум относительно hˆ, где ∇h ℒ(v, θ, hˆ) = 0. Мы не можем эффективно решить это уравнение относительно всех компонент h ˆ одновременно. Но его можно решить для одной переменной: = 0. (19.37) Таким образом, мы можем итеративно решать уравнение для i = 1, …, m и повто- рять цикл, пока не будет удовлетворен критерий сходимости. Типичный критерий говорит, что нужно остановиться, когда по завершении полного цикла обновления ℒ улучшается не больше, чем на заданную величину, или когда hˆ изменяется не больше, чем на заданную величину. Итерационное решение уравнений неподвижной точки среднего поля – это общий прием, который может приводить к быстрому вариационному выводу для широкого класса моделей. Для конкретности покажем, как все это выглядит в случае модели бинарного разреженного кодирования. Прежде всего необходимо выписать выраже-ние для производных по hˆ i. Для этого подставим выражение (19.36) в левую часть уравнения (19.37): (19.38) (19.39) (19.40) = log σ(bi) – logh ˆ i – 1 + log(1 – h ˆ i) + 1 – logσ(–bi) (19.41) (19.42) (19.43) Чтобы применить правило обновления уравнений неподвижной точки, находим hˆ i, обращающее выражение (19.43) в 0: (19.44) Теперь мы видим, что существует тесная связь между рекуррентными нейронными сетями и выводом в графических моделях. Точнее говоря, уравнения неподвижной точки среднего поля определяют рекуррентную нейронную сеть, задача которой – выполнение вывода. Мы показали, как вывести эту сеть из описания модели, но мож-но также обучать сеть вывода непосредственно. В главе 20 изложено несколько идей, относящихся к этой теме. В случае бинарного разреженного кодирования мы видим, что связь в рекуррент- ной сети, описываемой уравнением (19.44), заключается в повторном обновлении\n--- Страница 542 ---\nВариационный вывод и обучение  541 скрытых блоков на основе изменения значений соседних скрытых блоков. Вход всег- да отправляет фиксированное сообщение v⏉βW скрытым блокам, но скрытые блоки постоянно обновляют сообщения, которыми обмениваются между собой. Точнее го-воря, два блока hˆ i и hˆ j тормозят друг друга, когда их векторы весов совмещены. Это форма конкуренции – из двух скрытых блоков, объясняющих вход, активным раз- решено оставаться только тому, который дает лучшее объяснение. Наличие такой конкуренции – это попытка аппроксимации среднего поля уловить оправдывающие взаи модействия в апостериорном распределении бинарного разреженного кодирова- ния. На самом деле эффект оправдания должен приводить к многомодальному апос-териорному распределению, поэтому если мы будем выбирать примеры из апосте-риорного распределения, то в одних будет активен один блок, в других – другой, но найдется очень мало примеров, в которых активны оба блока. К сожалению, оправ- дывающие взаимодействия невозможно смоделировать факторным распределением q, используемым в случае среднего поля, поэтому аппроксимация среднего поля вы- нуждена назначать модели одну моду. Это пример поведения, показанного на рис. 3.6. Мы можем переписать уравнение (19.44) в эквивалентной форме, позволяющей прийти к дополнительным заключениям: (19.45) В этой формулировке видно, что вход на каждом шаге состоит из v – Σj≠iW:, j hˆ i, а не v. Поэтому можно считать, что блок i пытается закодировать остаточную ошибку в v при известных кодах других блоков. Таким образом, разреженное кодирование мож-но интерпретировать как итеративный автокодировщик, который повторно кодиру-ет и декодирует свой вход, пытаясь исправить ошибки реконструкции после каждой итерации. В этом примере мы вывели правило обновления по одному блоку за раз. Было бы хорошо одновременно обновлять несколько блоков. Некоторые графические модели, в т. ч. глубокие машины Больцмана, структурированы так, что можно одновремен- но находить много элементов hˆ. К сожалению, бинарное разреженное кодирование не допускает такого блочного обновления. Вместо этого для блочного обновления можно использовать эвристическую технику демпфирования (damping). Смысл ее состоит в том, что мы находим из уравнений индивидуально оптимальные значения каждого элемента hˆ, а затем производим малый сдвиг всех значений в этом направле- нии. Не гарантируется, что при этом ℒ на каждом шаге будет увеличиваться, но для многих моделей этот подход на практике дает хорошие результаты. Дополнительные сведения о выборе уровня синхронности и стратегиях демпфирования в алгоритмах передачи сообщений см. в работе Koller and Friedman (2009). 19.4.2. Вариационное исчисление Прежде чем продолжить экскурс в вариационное обучение, необходимо краткое вве- дение в важный математический инструментарий: вариационное исчисление. Многие методы машинного обучения основаны на минимизации функции J(θ), т. е. нахождении входного вектора θ ∈ ℝn, доставляющего ей минимальное значение. Для этого можно применить методы многомерного математического анализа и ли- нейной алгебры к нахождению критических точек, в которых ∇θJ(θ) = 0. Но в неко-\n--- Страница 543 ---\n542  Приближенный вывод торых случаях нам на самом деле нужно найти функцию f(x), например если ищется функция плотности вероятности некоторой случайной величины. Именно это и по- зволяет сделать вариационное исчисление. Функция от функции f называется функционалом J[f]. Точно так же, как мы бе- рем частные производные функции по элементам ее векторного аргумента, можно брать и функциональные производные, называемые также вариационными произ- водными функционала J[f] по значениям функции f(x) в любой точке x. Функцио- нальная производная функционала J по значению функции f в точке x обозначается (δ/δf(x)) J. Полная формальная разработка понятия функциональных производных выходит за рамки этой книги. Нам достаточно знать, что для дифференцируемой функции f(x) и дифференцируемой функции g(y, x) с непрерывными производными справед- ливо тождество (19.46) Чтобы понять интуитивный смысл этого тождества, представим себе, что f(x) – вектор с несчетным множеством элементов, индексированный вещественным век- тором x. При таком (не вполне полном) взгляде приведенное выше тождество не отличается от того, что мы имели бы для вектора θ ∈ ℝn, индексированного положи- тельными целыми числами: (19.47) Многие результаты в литературе по машинному обучению изложены в терминах более общего уравнения Эйлера–Лагранжа, в котором g может зависеть не только от значения f, но и от производных f, но нам такая общая форма не понадобится. Для оптимизации функции относительно вектора мы вычисляем градиент этой функции по вектору, приравниваем все элементы градиента к нулю и решаем полу- чившуюся систему уравнений. Точно так же для оптимизации функционала следует искать функцию из системы уравнений, выражающей равенство нулю функциональ-ных производных в каждой точке. В качестве примера рассмотрим задачу о нахождении функции распределения ве- роятности от x ∈ ℝ с минимальной дифференциальной энтропией. Напомним, что энтропия распределения вероятности p(x) определяется формулой H[p] = –𝔼 xlog p(x). (19.48) В непрерывном случае математическое ожидание – это интеграл: H[p] = –∫p(x) log p(x)dx. (19.49) Мы не можем просто максимизировать H[p] относительно функции p(x), потому что результатом может оказаться функция, не являющаяся распределением вероят- ности. Поэтому нам придется воспользоваться множителями Лагранжа, чтобы доба-вить ограничение: интеграл p(x) должен быть равен 1. Кроме того, энтропия должна неограниченно возрастать с ростом дисперсии. Из-за этого вопрос о распределении с максимальной энтропией становится неинтересным. Вместо него зададимся во- просом о том, какое распределение имеет наибольшую энтропию при фиксирован-\n--- Страница 544 ---\nВариационный вывод и обучение  543 ной дисперсии σ2. Наконец, задача недетерминированная, потому что распределение можно произвольно сдвинуть, не меняя энтропию. Чтобы получить единственное ре- шение, добавим еще ограничение, что среднее значение распределения должно быть равно μ. Функционал Лагранжа для этой задачи оптимизации имеет вид ℒ[p] = λ 1(∫p(x)dx – 1) + λ2(𝔼[x] – μ) + λ3(𝔼[(x – μ)2] – σ2) + H[p] (19.50) = ∫(λ1 p(x) + λ2 p(x)x + λ3 p(x)(x – μ)2 – p(x)log p(x))dx – λ1 – μλ2 – σ2λ3. (19.51) Для минимизации лагранжиана относительно p приравняем функциональные производные к нулю: (19.52) Это условие сообщает нам о функциональной форме p(x). После простых алгеб- раических преобразований получаем p(x) = exp(λ1 + λ2x + λ3(x – μ)2 – 1). (19.53) Мы нигде не предполагали, что функциональная форма p(x) именно такова, это выражение получилось в результате аналитической минимизации функционала. Чтобы довести до конца решение задачи минимизации, необходимо выбрать такие значения λ, при которых удовлетворяются все ограничения. Мы вольны выбирать любые значения λ, т. к. градиент лагранжиана по переменным λ равен 0, коль ско- ро удовлетворяются ограничения. Чтобы удовлетворить все ограничения, положим λ 1 = 1 – log σ√_ 2π, λ2 = 0, λ3 = –1/(2 σ2). Тогда получится p(x) = 𝒩(x; μ, σ2). (19.54) Это одна из причин использования нормального распределения в случае, когда ис- тинное неизвестно. Поскольку энтропия нормального распределения максимальна, такое предположение накладывает наименее строгую структуру. Исследуя критические точки функционала Лагранжа для энтропии, мы нашли только одну такую точку, соответствующую максимуму энтропии при фиксирован-ной дисперсии. А что сказать о функции распределения вероятности, которая ми- нимизирует энтропию? Почему мы не нашли вторую критическую точку, соответ-ствующую минимуму? Причина в том, что не существует функции, доставляющей минимум энтропии. Если увеличивать плотность вероятности в двух точках, x = μ + σ и x = μ – σ, уменьшая ее во всех остальных x, то энтропия будет уменьшаться, а дис- персия останется постоянной. Однако для функции, которая сосредоточивает всю массу в двух точках, делая ее равной 0 в остальных, интеграл не равен 1, и она не является допустимым распределением вероятности. Поэтому не существует рас-пределения вероятности с минимальной энтропией, как не существует наименьше- го положительного вещественного числа. Мы можем лишь сказать, что существует последовательность распределений вероятности, сходящаяся к концентрации массы всего в двух точках. Этот вырожденный случай можно описать как смесь распределе- ний Дирака. Поскольку распределение Дирака не описывается одной функцией рас-пределения вероятности, то никакая смесь распределений Дирака не соответствует одной конкретной точке в пространстве функций. Такие распределения невидимы нашему методу поиска точек, в которых функциональные производные равны 0. Это\n--- Страница 545 ---\n544  Приближенный вывод ограничение самого метода. Распределения, подобные дираковскому, следует искать другими методами, например угадать решение и затем доказать его правильность. 19.4.3. Непрерывные латентные переменные Если графическая модель содержит непрерывные латентные переменные, то мы все равно можем произвести вариационный вывод и обучение путем максимизации ℒ. Однако теперь для максимизации ℒ относительно q(h | v) нужно использовать вариа- ционное исчисление. На практике в большинстве случаев не приходится решать вариационные задачи самостоятельно. Вместо этого имеется общее уравнение для обновления неподвиж-ной точки среднего поля. Если принять аппроксимацию среднего поля (19.55) и зафиксировать q(hj | v) для всех j ≠ i, то оптимальное распределение q(hi | v) можно получить нормировкой ненормированного распределения q~(hi | v) = exp(𝔼h–i~q(h–i|v)log p~(v, h)) (19.56) при условии что p не назначает вероятность 0 ни одной совместной комбинации пе- ременных. Перенос математического ожидания внутрь уравнения дает корректную функциональную форму q(hi | v). Непосредственный вывод функциональных форм q методами вариационного исчисления необходим только в случае, когда цель – раз- работать новый вид вариационного обучения; уравнение (19.56) дает аппроксимацию среднего поля для любой вероятностной модели. Уравнение (19.56) – это уравнение неподвижной точки, которое следует итератив- но применять для каждого значения i до достижения сходимости. Однако этим оно не исчерпывается. Оно сообщает нам функциональную форму оптимального решения вне зависимости от того, найдено оно из уравнения неподвижной точки или иным способом. Это означает, что мы можем взять функциональную форму из этого урав-нения, но рассматривать некоторые значения в ней как параметры, которые можно оптимизировать с помощью любого алгоритма по своему выбору. В качестве примера рассмотрим простую вероятностную модель с латентными переменными h ∈ ℝ 2 и единственной видимой переменной v. Предположим, что p(h) = 𝒩(h; 0, I) и p(v | h) = 𝒩(v; w⏉h; 1). Мы могли бы упростить эту модель, ис- ключив h посредством интегрирования; в результате получится просто нормальное распределение v. Сама по себе модель не интересна; мы построили ее только ради демонстрации того, как вариационное исчисление применяется к вероятностному моделированию. Истинное апостериорное распределение с точностью до нормировочной постоян- ной имеет вид p(h | v), (19.57) ∝ p(h, v), (19.58) = p(h1)p(h2)p(v | h), (19.59) (19.60)\n--- Страница 546 ---\nВариационный вывод и обучение  545 (19.60) Из-за присутствия членов с произведением h1 и h2 истинное апостериорное рас- пределение не факторизуется по h1 и h2. Применяя формулу (19.56), находим, что q~(hi | v), (19.62) = exp(𝔼h2~q(h2|v)log p~(v, h)), (19.63) (19.64) (19.65) Отсюда видно, что нам нужно получить из q(h2 | v), по существу, только два значе- ния: 𝔼h2~q(h| v)[h2] и 𝔼h2~q(h| v)[h22]. Если обозначить их ⟨h2⟩ и ⟨h22⟩, то получим (19.66) (19.67) Отсюда следует, что q~ имеет функциональную форму гауссианы. Следовательно, можно заключить, что q(h | v) = 𝒩(h; μ, β–1), где вектор μ и диагональная матрица β – вариационные параметры, которые можно оптимизировать любым способом. Важно помнить, что мы нигде не предполагали, что q будет нормальным распределением, это получилось автоматически в результате применения вариационного исчисления для максимизации q относительно ℒ. Применив тот же подход к другой модели, мы получили бы другую функциональную форму q. Конечно, это всего лишь простой пример, сконструированный специально для де- монстрации. Примеры реального применения вариационного обучения с непрерывны- ми переменными в контексте глубокого обучения см. в работе Goodfellow et al. (2013d). 19.4.4. Взаимодействия между обучением и выводом Использование приближенного вывода в составе алгоритма обучения влияет на про- цесс обучения, а это, в свою очередь, сказывается на верности алгоритма вывода . Точнее говоря, алгоритм обучения стремится адаптировать модель таким образом, чтобы предположения, лежащие в основе алгоритма приближенного вывода, больше походили на правду. При обучении параметров метод вариационного обучения уве-личивает математическое ожидание 𝔼 h∼q log p(v, h). (19.68) При данном v это приводит к увеличению p(h | v) для значений h с высокой вероят- ностью в распределении q(h | v) и к уменьшению p(h | v) для h с низкой вероятностью. При таком поведении наши предположения, положенные в основу аппроксимации, становятся сбывающимися пророчествами. Если мы обучим модель с унимодальным приближенным апостериорным распределением, то получим модель, для которой ис-\n--- Страница 547 ---\n546  Приближенный вывод тинное апостериорное распределение гораздо ближе к унимодальному, чем было бы при обучении модели с помощью точного вывода. Таким образом, вычислить истинный вред, причиняемый модели вариационной аппроксимацией, очень трудно. Существует несколько методов оценивания log p(v). Зачастую мы оцениваем log p(v; θ) после обучения модели и обнаруживаем, что раз- рыв с ℒ(v, θ, q) мал. Отсюда мы делаем вывод, что наша вариационная аппроксимация в целом верна или что она причинила небольшой вред процессу обучения. Чтобы измерить истинный вред, привнесенный вариационной аппроксимацией, нам нужно знать θ* = maxθ log p(v; θ). Может быть так, что соотношения ℒ(v, θ, q) ≈ log p(v; θ) и log p(v; θ) ≪ log p(v; θ*) удовлетворяются одновременно. Если maxq ℒ(v, θ*, q) ≪ log p(v; θ*) из-за того, что θ* индуцирует слишком сложное апостериорное распреде- ление, которое наше семейство q неспособно уловить, то процесс обучения никогда не приблизится к θ*. Такую проблему очень трудно обнаружить, поскольку узнать наверняка, что это случилось, можно, лишь имея для сравнения другой, более каче-ственный алгоритм обучения, способный найти θ *. 19.5. Обученный приближенный вывод Мы видели, что вывод можно рассматривать как процедуру оптимизации, которая увеличивает значение функции ℒ. Явное выполнение оптимизации с помощью таких итеративных процедур, как уравнения неподвижной точки или градиентная оптими-зация, часто оказывается делом дорогим и долгим. Поэтому расходов стремятся из- бежать, обучая модель выполнять приближенный вывод. Точнее говоря, мы можем считать, что процесс оптимизации – это функция f, отображающая вход v в прибли- женное распределение q * = arg maxq ℒ(v, q). Коль скоро многошаговая итеративная процедура рассматривается просто как функция, мы можем аппроксимировать ее нейронной сетью, реализующей аппроксимацию f ˆ(v, θ). 19.5.1. Бодрствование-сон Одна из основных трудностей при обучении модели выводу h из v состоит в том, что у нас нет помеченного обучающего набора. Мы имеем v, но не знаем соответствую- щего h. Отображение v в h зависит от выбора семейства моделей и эволюционирует по мере того, как в процессе обучения изменяется θ. В алгоритме бодрствования-сна (wake-sleep) (Hinton et al., 1995b; Frey et al., 1996) эта проблема решается путем вы-борки как h, так и v из модельного распределения. Например, в ориентированной модели это легко сделать с помощью предковой выборки, начинающейся в h и закан- чивающейся в v. Тогда сеть вывода можно обучить выполнению обратного отобра- жения: предсказывать, какое h стало причиной данного v. Основной недостаток этого подхода – в том, что так можно обучить сеть вывода только на значениях v, имеющих высокую вероятность в модели. На ранних стадиях обучения модельное распределе- ние мало напоминает распределение данных, поэтому сеть вывода не получит воз-можности обучиться на примерах, похожих на данные. В разделе 18.2 мы привели возможное объяснение роли сновидений в жизни че- ловека и животных: сны могут поставлять примеры для отрицательной фазы, кото- рыми алгоритмы обучения методами Монте-Карло пользуются для аппроксимации отрицательного градиента логарифма статистической суммы в неориентированных моделях. Другое возможное объяснение биологических сновидений состоит в том, что оно поставляет примеры из распределения p(h, v), которые можно использовать,\n--- Страница 548 ---\nОбученный приближенный вывод  547 чтобы обучить сеть вывода предсказанию h по v. В некоторых отношениях это объ- яснение лучше того, в котором фигурирует статистическая сумма. Методы Монте- Карло в общем случае показывают неважные результаты, если в течение нескольких шагов работают только в положительной фазе градиента, а затем в течение несколь- ких шагов – только в отрицательной фазе. Люди и животные обычно несколько ча- сов подряд бодрствуют, а затем несколько часов спят. Не вполне понятно, как такой график мог бы помочь обучению неориентированной модели методами Монте-Кар- ло. С другой стороны, алгоритмы обучения, основанные на максимизации ℒ, могут в течение длительного периода работать над улучшением q, а затем в течение столь же длительного периода над улучшением θ. Если роль биологических сновидений состоит в том, чтобы обучить сеть предсказанию q, то это объясняет, как животные умудряются несколько часов бодрствовать (чем дольше, тем больше разрыв между ℒ и log p(v), но ℒ все время остается нижней границей) и несколько часов спать (во время сна сама порождающая модель не изменяется), не причиняя вреда своим внут-ренним моделям. Конечно, все это чисто умозрительные заключения, нет никаких доказательств того, что сон преследует именно такие цели. Сновидения могут так-же служить целям обучения с подкреплением, а не вероятностного моделирования, посредством выполнения выборки синтетического опыта из переходной модели жи-вотного, на основе которой обучается стратегия поведения животного. А возможно, что цель сна совершенно иная, и специалисты по машинному обучению еще даже не приблизились к ее пониманию. 19.5.2. Другие формы обученного вывода Стратегия обученного приближенного вывода применялась и к другим моделям. В работе Salakhutdinov and Larochelle (2010) показано, что один проход обучен- ной сети вывода может дать результаты быстрее, чем итеративное решение уравне-ний неподвижной точки среднего поля в глубоких машинах Больцмана. Процедура обуче ния основана на выполнении сети вывода, затем одном шаге среднего поля для улучшения оценок и обучении сети вывода формировать на выходе эту уточненную оценку вместо оригинальной. В разделе 14.8 мы видели, что модель предсказательной разреженной декомпозиции обучает мелкую сеть кодирования предсказывать разреженный код для входа. Это мож-но рассматривать как гибрид автокодировщика и разреженного кодирования. Можно придумать вероятностную семантику модели, в рамках которой кодировщик будет выполнять обученный приближенный MAP-вывод. Поскольку кодировщик мелкий, предсказательная разреженная декомпозиция не сможет реализовать ту конкуренцию между блоками, с которой мы встречались при описании вывода среднего поля. Однако с этой проблемой можно справиться, обучив глубокий кодировщик выполнять обучен- ный приближенный вывод, как в методе ISТA (Gregor and LeCun, 2010b). Обученный приближенный вывод в последнее время стал одним из преобладаю- щих подходов к порождающему моделированию – в форме вариационного автокоди- ровщика (Kingma, 2013; Rezende et al., 2014). В этом элегантном подходе нет нужды явно конструировать цели для сети вывода. Вместо этого сеть вывода просто исполь-зуется для определения ℒ, а затем параметры этой сети адаптируются для увеличения ℒ. Эта модель подробно описана в разделе 20.10.3. С помощью приближенного вывода можно обучать и использовать широкий спектр моделей, многие из которых описаны в следующей главе.",
      "debug": {
        "start_page": 531,
        "end_page": 548
      }
    },
    {
      "name": "Глава 20. Глубокие порождающие модели 548",
      "content": "--- Страница 549 --- (продолжение)\nГлава 20 Глубокие порождающие модели В этой главе мы опишем несколько порождающих моделей специального вида, кото- рые можно построить и обучить, применяя методы из глав 16–19. Все эти модели так или иначе представляют распределения вероятности нескольких случайных вели-чин. В одних функцию распределения вероятности можно вычислить явно, в других это невозможно, но зато поддерживаются операции, неявно использующие знания о распределении, например выборка. Одни представляют собой структурные вероят- ностные модели, описываемые в терминах графов и факторов на языке графических моделей, с которым мы познакомились в главе 16. Другие нельзя описать в терминах факторов, но распределения вероятности они тем не менее представляют. 20.1. Машины Больцмана Машины Больцмана первоначально были предложены как общий «коннекционист-ский» подход к обучению произвольных распределений вероятности бинарных век- торов (Fahlman et al., 1983; Ackley et al., 1985; Hinton et al., 1984; Hinton and Sejnowski, 1986). Но варианты машин Больцмана со случайными величинами других видов по популярности давно превзошли оригинал. В этом разделе мы кратко рассмотрим бинарную машину Больцмана и обсудим, какие проблемы возникают при попытке обучить модель и выполнить с ее помощью вывод. Мы определим машину Больцмана над d-мерным бинарным случайным вектором x ∈ {0, 1} d. Машина Больцмана – это энергетическая модель (см. раздел 16.2.4), т. е. совместное распределение вероятности определяется с помощью функции энергии: (20.1) где E(x) – функция энергии, а Z – статистическая сумма, гарантирующая, что Σx P(x) = 1. Функция энергии машины Больцмана имеет вид E(x) = –x⏉Ux – b⏉x, (20.2) где U – матрица «весов», содержащая параметры модели, а b – вектор смещений. Для машины Больцмана общего вида мы имеем набор n-мерных обучающих при- меров, а формула (20.1) описывает совместное распределение вероятности наблю- даемых переменных. Ситуация вполне рабочая, но виды взаимодействий между\nГлава 20 Глубокие порождающие модели В этой главе мы опишем несколько порождающих моделей специального вида, кото- рые можно построить и обучить, применяя методы из глав 16–19. Все эти модели так или иначе представляют распределения вероятности нескольких случайных вели-чин. В одних функцию распределения вероятности можно вычислить явно, в других это невозможно, но зато поддерживаются операции, неявно использующие знания о распределении, например выборка. Одни представляют собой структурные вероят- ностные модели, описываемые в терминах графов и факторов на языке графических моделей, с которым мы познакомились в главе 16. Другие нельзя описать в терминах факторов, но распределения вероятности они тем не менее представляют. 20.1. Машины Больцмана Машины Больцмана первоначально были предложены как общий «коннекционист-ский» подход к обучению произвольных распределений вероятности бинарных век- торов (Fahlman et al., 1983; Ackley et al., 1985; Hinton et al., 1984; Hinton and Sejnowski, 1986). Но варианты машин Больцмана со случайными величинами других видов по популярности давно превзошли оригинал. В этом разделе мы кратко рассмотрим бинарную машину Больцмана и обсудим, какие проблемы возникают при попытке обучить модель и выполнить с ее помощью вывод. Мы определим машину Больцмана над d-мерным бинарным случайным вектором x ∈ {0, 1} d. Машина Больцмана – это энергетическая модель (см. раздел 16.2.4), т. е. совместное распределение вероятности определяется с помощью функции энергии: (20.1) где E(x) – функция энергии, а Z – статистическая сумма, гарантирующая, что Σx P(x) = 1. Функция энергии машины Больцмана имеет вид E(x) = –x⏉Ux – b⏉x, (20.2) где U – матрица «весов», содержащая параметры модели, а b – вектор смещений. Для машины Больцмана общего вида мы имеем набор n-мерных обучающих при- меров, а формула (20.1) описывает совместное распределение вероятности наблю- даемых переменных. Ситуация вполне рабочая, но виды взаимодействий между\n--- Страница 550 ---\nМашины Больцмана  549 наблю даемыми переменными ограничены матрицей весов. Точнее, вероятность, что некоторый блок включен, определяется линейной моделью (логистической регресси- ей) по значениям других блоков. Мощность машины Больцмана возрастает, если не все переменные наблюдаемые. В таком случае латентные переменные могут действовать подобно скрытым блокам в многослойном перцептроне и моделировать взаимодействия высшего порядка между видимыми блоками. Напомним, что добавление скрытых блоков в модель ло- гистической регрессии приводит к МСП, который является универсальным аппрок- симатором функций. Точно так же машина Больцмана со скрытыми блоками может использоваться уже не только для моделирования линейных связей между перемен-ными, а становится универсальным аппроксиматором функций вероятности для дис- кретных случайных величин (Le Roux and Bengio, 2008). Формально говоря, мы разбиваем множество блоков x на два подмножества: види- мые v и скрытые h. Функция энергии принимает вид E(v, h) = –v ⏉Rv – v⏉Wh – h⏉Sh – b⏉v – c⏉h. (20.3) Обучение машины Больцмана. Алгоритмы обучения машин Больцмана обычно основаны на критерии максимального правдоподобия. У всех машин Больцмана ста- тистическая сумма вычислительно неразрешима, поэтому градиент максимального правдоподобия следует аппроксимировать методами, описанными в главе 18. Если правила обучения основаны на максимальном правдоподобии, то у машин Больцмана появляется интересное свойство: обновление веса связи между двумя блоками зависит только от статистик этих двух блоков, собираемых относительно двух разных распределений: P model(v) и Pˆ data(v)Pmodel(h | v). Вся остальная сеть участвует в формировании этих статистик, но для обновления веса не нужно ничего знать ни об остальной сети, ни о том, как собиралась статистика. Следовательно, правило обуче- ния «локально», что придает обучению машины Больцмана некоторое биологическое правдоподобие. Можно предположить, что если бы каждый нейрон был случайной величиной в машине Больцмана, то аксоны и дендриты, соединяющие две случайные величины, могли бы обучаться только путем наблюдения закономерностей возбуж-дения клеток, с которыми у них имеется физический контакт. В частности, в положи- тельной фазе усиливается связь между двумя блоками, которые часто активируются вместе. Это пример правила обучения Хебба (Hebb, 1949) которое иногда выражают в виде мнемонической фразы: «fire together, wire together» (между нейронами, кото- рые возбуждаются вместе, устанавливается связь). Правила обучения Хебба принад-лежат к числу самых старых гипотетических объяснений обучения в биологических системах и сохраняют актуальность по сей день (Giudice et al., 2009). Другие алгоритмы обучения, в которых используется больше информации, чем просто локальная статистика, похоже, требуют гипотез о наличии дополнительных механизмов. Например, чтобы мозг мог реализовать обратное распространение, как в многослойном перцептроне, кажется необходимым поддержание вторичной ком- муникационной сети для передачи информации о градиенте назад по сети. Пред- ложения биологически правдоподобных реализаций (и аппроксимаций) обратного распространения выдвигались (Hinton, 2007a; Bengio, 2015), но пока не проверены, а в работе Bengio (2015) обратное распространение градиентов связывается с выво- дом в энергетических моделях, подобных машине Больцмана (но с непрерывными латентными переменными).\n--- Страница 551 ---\n550  Г лубокие порождающие модели Отрицательную фазу обучения машины Больцмана объяснить с биологической точки зрения труднее. В разделе 18.2 выдвигалось предположение, что сновидения могут быть формой выборки в отрицательной фазе. Впрочем, эта идея скорее умо- зрительная. 20.2. Ограниченные машины Больцмана Ограниченная машина Больцмана, названная изобретателем (Smolensky, 1986) гар- мониумом, сейчас является самым распространенным строительным блоком глубо- ких вероятностных моделей. Мы вкратце описывали ОМБ в разделе 16.7.1, а здесь напомним сказанное ранее и некоторые дополнительные детали. ОМБ представляет собой неориентированную вероятностную графическую модель, содержащую слой наблюдаемых переменных и единственный слой латентных переменных. ОМБ мож- но собирать в стек (одна поверх другой) для формирования более глубоких моделей. На рис. 20.1 приведено несколько примеров. Так, на рис. 20.1a изображена графовая структура самой ОМБ. Это двудольный граф, в котором запрещены связи внутри слоя наблюдаемых переменных и внутри слоя латентных переменных. Мы начнем с бинарной версии ограниченной машины Больцмана, но, как вскоре станет ясно, существуют обобщения на другие типы видимых и скрытых блоков. Формально говоря, предположим, что наблюдаемый слой состоит из множества n v бинарных случайных величин, которое будем обозначать вектором v. А скрытый слой, состоящий из nh бинарных случайных величин, обозначим h. Как и общая машина Больцмана, ограниченная машина Больцмана – это энергети- ческая модель, в которой совместное распределение вероятности описывается функ- цией энергии: P(v = v, h = h) = (1/Z)exp(–E(v, h)). (20.4) Функция энергии ОМБ имеет вид E(v, h) = – b⏉v – c⏉h – v⏉Wh, (20.5) а Z – нормировочная постоянная, называемая статистической суммой: (20.6) Из определения статистической суммы Z ясно, что наивный метод ее вычисления (суммирование по всем состояниям) может оказаться вычислительно неразреши- мым, если только не придумать какого-нибудь хитрого алгоритма, который мог бы воспользоваться присутствующей в распределении вероятности регулярностью для более быстрого вычисления. В случае ограниченной машины Больцмана в работе Long and Servedio (2010) формально доказано, что статистическая сумма Z неразре- шима. А это означает, что неразрешимым является также совместное распределение P(v). 20.2.1. Условные распределения Хотя P(v) неразрешима, у двудольного графа, описывающего структуру ОМБ, есть специальное свойство: условные распределения P(h | v) и P(v | h) факторные, допус- кающие сравнительно простое вычисление и выборку.\n--- Страница 552 ---\nОграниченные машины Больцмана  551 (a) (b) (c) Рис. 20.1  Примеры моделей, построенных из ограниченных машин Больцмана. (a) Сама ограниченная машина Больцмана – это неориенти- рованная графическая модель, основанная на двудольном графе, в одной доле которого находятся видимые блоки, а в другой – скрытые блоки. Меж- ду видимыми блоками нет никаких связей – так же, как между скрытыми. Обычно каждый видимый блок связан с каждым скрытым, но встречаются и ОМБ с разреженными связями, например сверточные ОМБ. (b) Г лубокая сеть доверия (ГСД, англ. DBN)) – гибридная графическая модель, включаю- щая как ориентированные, так и неориентированные связи. Как и в ОМБ, в ней нет внутрислойных связей. Однако в ГСД несколько скрытых слоев, поэтому возможны связи между скрытыми блоками на разных уровнях. Все локальные условные распределения вероятности, необходимые глубокой сети доверия, копируются непосредственно из локальных условных рас-пределений вероятности, составляющих сеть ОМБ. Можно было бы вместо этого представить глубокую сеть доверия полностью неориентированным графом, но тогда потребовались бы внутрислойные связи для улавливания зависимостей между родителями. (c) Г лубокая машина Больцмана (ГМБ, англ. DBM) – это неориентированная графическая модель с несколькими слоями латентных переменных. У ГМБ, как и у ОМБ и ГСД, нет внутрислой- ных связей. ГМБ не так тесно связаны с ОМБ, как ГСД. Если ГМБ инициа- лизируется стеком ОМБ, то параметры ОМБ необходимо немного моди-фицировать. Некоторые виды ГМБ можно обучать без предварительного обучения набора ОМБ\n--- Страница 553 ---\n552  Г лубокие порождающие модели Вывести условные распределения из совместного просто: (20.7) (20.8) (20.9) (20.10) (20.11) Поскольку в условии находятся видимые блоки v, мы можем рассматривать их как постоянные относительно распределения P(h | v). Факторная природа условного распределения P(h | v) сразу же следует из возможности записать совместное рас- пределение вектора h в виде произведения (ненормированных) распределений от- дельных элементов hj. Осталось только нормировать распределения индивидуальных бинарных hj. (20.12) (20.13) (20.14) Теперь можно выразить полное условное распределение скрытого слоя в виде фак- торного распределения: (20.15) Точно так же можно показать, что и другое условное распределение, P(v | h), явля- ется факторным: (20.16) 20.2.2. Обучение ограниченных машин Больцмана Поскольку ОМБ допускает эффективное вычисление и дифференцирование P~(v), а также эффективную MCMC-выборку в виде блочной выборки по Гиббсу, то ее легко обучить любым из описанных в главе 18 методов обучения моделей с неразрешимы- ми статистическими суммами: CD, SML (PCD), сопоставление отношений и т. д. По сравнению с другими неориентированными моделями, используемыми в глубоком обучении, ОМБ обучается относительно просто, поскольку мы можем точно вычис- лить P(h | v) в замкнутой форме. В других глубоких моделях, в частности в глубо-\n--- Страница 554 ---\nГ лубокие сети доверия  553 кой машине Больцмана, проблема неразрешимой статистической суммы сочетается с проблемой неразрешимого вывода. 20.3. Глубокие сети доверия Глубокие сети доверия (ГСД) были одними из первых несверточных моделей, кото- рые удалось успешно обучить в контексте глубоких архитектур (Hinton et al., 2006; Hinton, 2007b). С появлением глубоких сетей доверий в 2006 году началось возрож- дение глубокого обучения, продолжающееся и по сей день. До этого считалось, что глубокие модели с трудом поддаются оптимизации. Усилия исследователей были в основном направлены на изучение ядерных методов с выпуклыми целевыми функ- циями. Глубокие сети доверия продемонстрировали, что глубокая архитектура может по качеству превзойти метод опорных векторов с ядром на наборе MNISТ (Hinton et al., 2006). Сегодня глубокие сети доверия вышли из моды и применяются редко даже по сравнению с другими порождающими или обучаемыми без учителя алгоритмами, но их роль в истории глубокого обучения достойна всяческого уважения. Глубокие сети доверия – это порождающие модели с несколькими слоями латент- ных переменных. Латентные переменные обычно бинарные, хотя видимые блоки могут быть как бинарными, так и вещественными. Внутри слоев нет никаких свя- зей. Обычно каждый блок любого слоя связан с каждым блоком соседних слоев, хотя можно строить и ГСД с более разреженными связями. Связи между двумя верхними слоями неориентированные. Связи между всеми остальными слоями ориентирован-ные, причем стрелки направлены в сторону слоя, ближайшего к данным. Пример по- казан на рис. 20.1b. ГСД с l скрытыми слоями содержит l матриц весов W (1), …, W(l), а также l + 1 век- торов смещений b(0), …, b(l), где b(0) – смещения для видимого слоя. Распределение вероятности, представляемое ГСД, имеет вид: P(h(l), h(l–1)) ∝ exp(b(l)⏉h(l) + b(l–1)⏉h(l–1) + h(l–1)⏉W(l)h(l)), (20.17) P(hi(k) = 1 | h(k+1)) = σ(bi(k) + W:;i(k+1)⏉h(k+1))∀i, ∀k ∈ 1, …, l – 2, (20.18) P(vi = 1 | h(1)) = σ(bi(0) + W:;i(1)⏉h(1))∀i. (20.19) В случае вещественных видимых блоков подставляем v ∼ 𝒩(v; b(0) + W(1)⏉h(1), β–1), (20.20) где β – диагональная матрица, иначе вычисления становятся слишком сложными. Обобщение на другие экспоненциальные семейства видимых блоков не вызывают трудностей, по крайней мере в теории. ГСД с единственным скрытым слоем – это просто ОМБ. Чтобы произвести выборку из ГСД, мы сначала выполняем несколько шагов вы- борки по Гиббсу для двух верхних скрытых слоев. На этом этапе, по существу, про-изводится выборка из ОМБ, определенной этими двумя слоями. Затем можно при-менить один проход предковой выборки к остальной части модели, чтобы произвести выборку из видимых блоков. Глубокие сети доверия подвержены многим проблемам, присущим как ориентиро- ванным, так и неориентированным моделям. Вывод в глубокой сети доверия вычислительно неразрешим из-за эффекта оправ- дания внутри каждого ориентированного слоя и взаимодействия между двумя скры-\n--- Страница 555 ---\n554  Г лубокие порождающие модели тыми слоями с неориентированными связями. Вычисление или максимизация стан- дартной нижней границы свидетельств для логарифмического правдоподобия также неразрешимы, поскольку в этой нижней границе участвует математическое ожида- ние клик, размер которых равен ширине сети. При вычислении или максимизации логарифмического правдоподобия прихо- дится сталкиваться не только с проблемой неразрешимого вывода для исключения латентных переменных, но и с проблемой неразрешимой статистической суммы в не- ориентированной модели двух верхних слоев. Обучение глубокой сети доверия начинается с того, что мы обучаем ОМБ макси- мизировать 𝔼v∼pdatalog p(v) с помощью алгоритма сопоставительного расхождения или стохастической максимизации правдоподобия. Полученные параметры ОМБ опре-деляют параметры первого слоя ГСД. Далее мы обучаем вторую ЛМБ приближенно максимизировать выражение 𝔼 v∼pdata𝔼h(1)∼p(1)(h(1)|v) log p(2)(h(1)), (20.21) где p(1) – распределение вероятности, представленное первой ОМБ, а p(2) – распреде- ление, представленное второй ОМБ. Иными словами, вторая ОМБ обучается моде-лировать распределение, определенное выборкой из скрытых блоков первой ОМБ, тогда как первая ОМБ управляется данными. Эту процедуру можно повторять бес-конечно, добавляя в ГСД столько слоев, сколько необходимо, при этом каждая новая ОМБ будет моделировать выборку из предыдущей. Каждая ОМБ определяет оче-редной слой ГСД. Эту процедуру можно обосновать как увеличение вариационной нижней границы логарифмического правдоподобия данных в модели ГСД (Hinton et al., 2006). В большинстве приложений не предпринимается никаких усилий для совместного обучения ГСД после завершения жадной послойной процедуры. Однако можно про-вести окончательную настройку с помощью алгоритма бодрствования-сна. Обученную ГСД можно использовать непосредственно в качестве порождающей модели, но интерес к ГСД связан в основном с их способностью улучшать модели классификации. Мы можем воспользоваться весами из ГСД для определения много-слойного перцептрона: h (1) = σ(b(1) + v⏉W(1)), (20.22) h(l) = σ(bi(l) + h(l–1)⏉W(l))∀l ∈ 2, …, m. (20.23) После инициализации МСП весами и смещениями, обученными на этапе порож- дающего обучения ГСД, мы можем обучить МСП решать задачу классификации. Это дополнительное обучение – пример дискриминантной окончательной настройки . Этот конкретный выбор МСП выглядит несколько произвольно, по сравнению со многими уравнениями вывода из главы 19, имеющими теоретическое обоснова-ние. Это эвристический выбор, который неплохо работает на практике и постоянно упоминается в литературе. В обоснование многих методов приближенного вывода выдвигается их способность находить максимально точную вариационную нижнюю границу логарифмического правдоподобия при определенных ограничениях. Такую границу можно построить с помощью математических ожиданий скрытых блоков, определенных ассоциированным с ГСД перцептроном, но это справедливо для любо- го распределения вероятности скрытых блоков, и нет причин полагать, что этот МСП\n--- Страница 556 ---\nГ лубокие машины Больцмана  555 дает особо точную границу. В частности, МСП игнорирует многие важные взаимо- действия в графической модели ГСД. МСП распространяет информацию вверх от видимых блоков к самым глубоким скрытым блокам, но не вниз и не в стороны. В гра- фической модели ГСД имеются оправдывающие взаимодействия между всеми скры- тыми блоками внутри одного слоя, а также нисходящие взаимодействия между слоя- ми. Хотя логарифмическое правдоподобие ГСД вычислить невозможно, его можно аппроксимировать методом выборки по значимости с отжигом (Salakhutdinov and Murray, 2008). Это позволяет вычислить ее качество в роли порождающей модели. Термин «глубокая сеть доверия» часто неправильно употребляется для обозначе- ния любой глубокой нейронной сети, даже без семантики латентных переменных. На самом деле он относится исключительно к моделям с неориентированными связями в самом глубоком слое и направленными вниз ориентированными связями между всеми остальными парами соседних слоев. Этот термин также может вызвать путаницу, потому что «сетью доверия» иногда называют строго ориентированные модели, тогда как в глубоких сетях доверия име- ется неориентированный слой. Ко всему прочему, английский акроним DBN употреб-ляется также для динамических байесовских сетей (Dean and Kanazawa, 1989), т. е. для байесовских сетей, представляющих марковские цепи. 20.4. Глубокие машины Больцмана Глубокая машина Больцмана (ГМБ) (Salakhutdinov and Hinton, 2009a) – еще один вид порождающих моделей. В отличие от глубокой сети доверия, она полностью не- ориентированная, а в отличие от ОМБ, имеет несколько слоев латентных переменных (в ОМБ такой слой единственный). Но так же, как и в ОМБ, внутри слоя все пере- менные взаимно независимы при условии переменных из соседних слоев. Структура графа показана на рис. 20.2. Глубокие машины Больцмана применялись к различным задачам, в т. ч. к моделированию документов (Srivastava et al., 2013). Рис. 20.2  Графическая модель глубокой машины Больцмана с одним видимым слоем (внизу) и двумя скрытыми слоями. Связи существуют толь- ко между блоками из соседних слоев. Внутри слоев никаких связей нет Подобно ОМБ и ГСД, глубокие машины Больцмана обычно содержат только би- нарные блоки (и мы придерживаемся такого предположения для простоты изложе-ния), но включить в них вещественные видимые блоки не составляет труда.\n--- Страница 557 ---\n556  Г лубокие порождающие модели ОМБ – энергетическая модель, а значит, совместное распределение вероятности переменных модели параметризовано функцией энергии E. В случае глубокой ма- шины Больцмана с одним видимым слоем v и тремя скрытыми слоями h(1), h(2), h(3) совместное распределение имеет вид: (20.24) Чтобы упростить изложение, мы далее опускаем параметры смещения. Тогда функция ГМБ определяется формулой: E(v, h(1), h(2), h(3); θ) = –v⏉W(1)h(1) – h(1)⏉W(2)h(2) – h(2)⏉W(3)h(3). (20.25) По сравнению с функцией энергии ОМБ (20.5), функция энергии ГМБ включает связи между скрытыми блоками (латентными переменными) в форме матриц весов (W(2) и W(3)). Как мы увидим, наличие этих связей имеет важные последствия для по- ведения модели, а также для выполнения вывода. По сравнению с полносвязными машинами Больцмана (в которых каждый блок связан со всеми остальными), ГМБ имеет ряд преимуществ, похожих на те, что свой- ственны ОМБ. Точнее говоря, как видно по рис. 20.3, слои ГМБ можно представить в виде двудольного графа, в котором нечетные слои принадлежат одной доле, а чет- ные – другой. Отсюда сразу следует, что при условии переменных в четном слое пере- менные в нечетных слоях становятся условно независимыми. Разумеется, обуслов- ливание переменными нечетных слоев делает условно независимыми переменные в четных слоях. Рис. 20.3  Г лубокая машина Больцмана, нарисованная так, чтобы выявить структуру двудольного графа Из двудольной структуры ГМБ вытекает, что те же самые уравнения, которые мы раньше использовали для условных распределений ОМБ, применимы и к ГМБ. Блоки внутри одного слоя условно независимы друг от друга при условии значений в соседних слоях, поэтому распределения бинарных переменных можно полностью\n--- Страница 558 ---\nГ лубокие машины Больцмана  557 описать параметрами Бернулли, задающими вероятность активности каждого блока. В нашем примере с двумя скрытыми слоями вероятности активации равны P(vi = 1 | h(1)) = σ(Wi;:(1)h(1)), (20.26) P(hi(1) = 1 | v, h(2)) = σ(v⏉W:;i(1) + Wi;:(2)h(2)), (20.27) и P(hk(2) = 1 | h(1)) = σ(h(1)⏉W:;k(2)). (20.28) Благодаря двудольной структуре глубокой машины Больцмана оказывается эф- фективной выборка по Гиббсу. При наивном подходе к выборке по Гиббсу обновляет- ся по одной переменной за раз. ОМБ позволяет обновлять все видимые блоки в одной операции, а все скрытые – в другой. По наивности можно было бы предположить, что ГМБ с l слоями требует l + 1 обновлений, так что на каждой итерации обновляются все блоки одного уровня. На самом же деле для обновления всех блоков достаточно всего двух итераций. Выборку по Гиббсу можно разбить на две группы обновлений: одна включает все четные слои (в т. ч. и видимый), другая – все нечетные. В силу дву- дольности графа связей в ГМБ распределение нечетных слоев при условии четных факторное, поэтому выборку из него можно произвести одновременно и независимо одной операцией. И так же можно произвести одновременную и независимую вы- борку из распределения четных слоев при условии нечетных. Эффективная выборка особенно важна для обучения с помощью алгоритма стохастической максимизации правдоподобия. 20.4.1. Интересные свойства У глубоких машин Больцмана много интересных свойств. ГМБ были разработаны после ГСД. По сравнению c ГСД, их апостериорное рас- пределение P(h | v) проще. В противоречие с интуицией, благодаря простоте апосте- риорного распределения возможны его улучшенные аппроксимации. В случае ГСД мы выполняем классификацию, применяя эвристическую процедуру приближенно-го вывода, в которой высказываем гипотезу, что разумное значение математического ожидания среднего поля для скрытых блоков можно получить проходом вверх по сети, образованной МСП с сигмоидными функциями активации и такими же весами, как у исходной ГСД. Для получения вариационной нижней границы логарифмиче- ского правдоподобия можно использовать любое распределение Q(h). Поэтому такая эвристическая процедура дает возможность получить нижнюю границу. Однако эта граница явно никак не оптимизировалась и потому может быть далеко не точной. В частности, эвристическая оценка Q игнорирует взаимодействия между скрытыми блоками в одном слое, а также влияние нисходящей обратной связи между скрытыми блоками более глубоких слоев и слоев, расположенных ближе к входу. Поскольку эвристическая процедура вывода на основе МСП не может учесть этих взаимодей-ствий в ГМБ, результирующее распределение Q, скорее всего, далеко от оптимально- го. В ГМБ все скрытые блоки внутри одного слоя условно независимы при условии других слоев. Благодаря отсутствию внутрислойного взаимодействия открывается возможность использовать уравнения неподвижной точки для оптимизации вариа-ционной нижней границы и нахождения истинно оптимальных математических ожи- даний среднего поля (в пределах некоторого допуска).\n--- Страница 559 ---\n558  Г лубокие порождающие модели Использование надлежащего среднего поля позволяет процедуре приближенного вывода в ГМБ уловить влияние нисходящей обратной связи. Это делает ГМБ инте- ресными для нейробиологии, поскольку известно, что человеческий мозг задействует много нисходящих обратных связей. Благодаря этому свойству ГМБ использовались в качестве вычислительных моделей реальных нейробиологических явлений (Series et al., 2010; Reichert et al., 2011). Один из недостатков ГМБ – относительная сложность выборки из них. В ГСД выборку MCMC-методами необходимо использовать только в двух верхних слоях. Остальные слои используются лишь в конце процесса выборки, в одном эффектив- ном проходе предковой выборки. Чтобы произвести выборку из ГМБ, необходимо применять MCMC-методы во всех слоях, т. е. каждый слой модели принимает учас- тие во всех переходах марковской цепи. 20.4.2. Вывод среднего поля в ГМБ Условное распределение одного слоя ГМБ при условии соседних слоев фактор-ное. В примере ГМБ с двумя скрытыми слоями это будут распределения P(v | h (1)), P(h(1) | v, h(2)) и P(h(2) | h(1)). Распределение всех скрытых слоев обычно не является факторным из-за взаимодействий между слоями. В примере с двумя скрытыми слоя- ми P(h(1), h(2) | v) не факторизуется из-за весов W(2) взаимодействия между h(1) и h(2), вследствие чего эти переменные оказываются взаимно зависимыми. Как и в случае с ГСД, нам остается искать способы аппроксимации апостериорного распределения ГМБ. Но, в отличие от ГСД, апостериорное распределение скрытых блоков ГМБ, хотя и сложное, легко аппроксимируется вариационной аппроксима- цией (см. раздел 19.4), а конкретно – приближением среднего поля. Приближение среднего поля – это простая форма вариационного вывода, когда мы ограничиваем- ся только факторными аппроксимирующими распределениями. В контексте ГМБ уравнения среднего поля улавливают двусторонние взаимодействия между слоями. В этом разделе мы построим итеративную процедуру приближенного вывода, впер- вые предложенную в работе Salakhutdinov and Hinton (2009a). Вариационный подход к приближенному выводу предполагает аппроксимацию конкретного целевого распределения – в нашем случае апостериорного распределе- ния скрытых блоков при условии видимых блоков – некоторым достаточно простым семейством распределений. В случае приближения среднего поля в качестве такого семейства берется множество распределений, для которых скрытые блоки условно независимы. Теперь разработаем подход на основе среднего поля для примера с двумя скрыты- ми слоями. Пусть Q(h (1), h(2) | v) – аппроксимация P(h(1), h(2) | v). Из предположения среднего поля следует, что (20.29) Приближение среднего поля пытается найти член этого семейства распределений, который наилучшим образом аппроксимирует истинное апостериорное распределе-ние P(h (1), h(2) | v). Важно отметить, что процесс вывода следует запускать снова для нахождения другого распределения Q всякий раз, как используется новое значение v. Можно придумать много способов измерить качество аппроксимации P(h | v) рас- пределением Q(h | v). Подход на основе среднего поля предполагает минимизацию\n--- Страница 560 ---\nГ лубокие машины Больцмана  559 (20.30) Вообще говоря, мы не обязаны предоставлять параметрическую форму аппрокси- мирующего распределения, а только гарантировать выполнение предположений о не- зависимости. Процедура вариационной аппроксимации сама способна восстановить функциональную форму приближенного распределения. Однако в рассматриваемом случае предположения скрытого поля о бинарных скрытых блоках фиксирование па- раметризации модели заранее не приводит к потере общности. Мы параметризуем Q в виде произведения распределений Бернулли, т. е. ассо- циируем параметр с вероятностью каждого элемента h(1). Точнее, для каждого j hˆ j(1) = Q(hj(1) = 1 | v), где hˆ j(1) ∈ [0, 1], и для каждого k hˆ k(2) = Q(hk(2) = 1 | v), где hˆ k(2) ∈ [0, 1]. Таким образом, имеем следующую аппроксимацию апостериорного распределения: (20.31) (20.32) Разумеется, эта параметризация приближенного апостериорного распределения очевидным образом обобщается на ГМБ с большим числом слоев, нужно только воспользоваться двудольной структурой графа и одновременно обновить сначала все четные слои, а затем все нечетные, применяя такую же схему, как в выборке по Гиббсу. После того как семейство аппроксимирующих распределений Q определено, оста- ется задать процедуру выбора того члена этого семейства, который лучше всего со-ответствует P. Самое простое – воспользоваться уравнениями среднего поля (19.56). При выводе этих уравнений мы искали, в каких точках обращаются в нуль произво- дные вариационной нижней границы. Они абстрактно описывают, как оптимизиро-вать вариационную нижнюю границу для любой модели, просто взяв математические ожидания относительно Q. Применив эти общие уравнения, получим правила обновления (опять-таки члены смещения игнорируются): (20.33) (20.34) В неподвижной точке этой системы уравнений мы имеем локальный максимум вариационной нижней границы ℒ(Q). Следовательно, эти уравнения обновления не- подвижной точки определяют итеративный алгоритм, в котором обновление hˆ j(1) (по формуле 20.33) чередуется с обновлением hˆ k(2) (по формуле 20.34). В небольших за- дачах типа MNISТ достаточно всего десяти итераций, чтобы найти приближенный градиент положительной фазы для обучения, а пятидесяти обычно хватает для полу- чения высококачественного представления одного конкретного примера, используе-мого для классификации с высокой верностью. Обобщение приближенного вариаци- онного вывода на более глубокие ГМБ не составляет труда.\n--- Страница 561 ---\n560  Г лубокие порождающие модели 20.4.3. Обучение параметров ГМБ При обучении ГМБ приходится решать проблему неразрешимой статистической суммы и проблему неразрешимого апостериорного распределения. Для этого при- меняются соответственно методы из глав 18 и 19. Как сказано в разделе 20.4.2, вариационный вывод допускает построение распре- деления Q(h | v), аппроксимирующего неразрешимое распределение P(h | v). Затем максимизируется ℒ(v, Q, θ) – вариационная нижняя граница неразрешимого лога- рифмического правдоподобия, log P(v; θ). Для глубокой машины Больцмана с двумя скрытыми слоями функция ℒ имеет вид: . (20.35) Это выражение все еще содержит логарифм статистической суммы log Z(θ). Поскольку глубокая машина Больцмана состоит из ограниченных машин Боль-цмана, то результаты, касающиеся трудности вычисления статистической суммы и выборки в ограниченных машинах Больцмана, применимы и к ГМБ. Это озна- чает, что для вычисления функции вероятности машины Больцмана необходимы приближенные методы, например выборка по значимости с отжигом. Аналогично для обуче ния модели требуется аппроксимировать градиент логарифма статисти- ческой суммы. Общее описание этих методов см. в главе 18. ГМБ обычно обучают- ся с помощью алгоритма стохастической максимизации правдоподобия. Многие другие методы, упомянутые в главе 18, к ГМБ неприменимы. Для псевдоправдо- подобия необходимо уметь вычислять ненормированные вероятности, а не прос- то получать для них вариационную нижнюю границу. Метод сопоставительного расхождения слишком медленный для глубоких машин Больцмана, потому что они не допускают эффективной выборки из распределения скрытых блоков при условии видимых, поэтому метод сопоставительного расхождения должен был бы прирабатывать марковскую цепь всякий раз, как необходим новый пример в от- рицательной фазе. В разделе 18.2 обсуждается невариационная версия алгоритма стохастической максимизации правдоподобия. Порядок применения вариационной стохастической максимизации правдоподобия описан в алгоритме 20.1. Напомним, что мы говорим об упрощенном варианте ГМБ без параметров смещения; впрочем, включить их в рассмотрение очень просто. 20.4.4. Послойное предобучение К сожалению, обучение ГМБ методом стохастической максимизации правдоподобия (как описано выше) со случайными начальными параметрами не годится. В одних случаях модель не может обучиться адекватному представлению распределения, в других ГМБ представляет распределение хорошо, но не удается получить более вы- сокое правдоподобие, чем дала бы простая ОМБ. ГМБ, для которой веса очень малы во всех слоях, кроме первого, представляет приблизительно то же распределение, что и ОМБ. В разделе 20.4.5 описаны вариационные методы, допускающие совместное обуче- ние. Однако оригинальный и самый популярный метод решения проблемы совмест- ного обучения ГМБ – жадное послойное предобучение. В этом случае каждый слой\n--- Страница 562 ---\nГ лубокие машины Больцмана  561 ГМБ обучается изолированно – как ОМБ. Первый слой обучается моделированию входных данных, а каждый последующий – моделированию примеров, выбранных из апостериорного распределения предыдущей ОМБ. После того как все ОМБ обучены, их можно объединить в ГМБ. Затем ГМБ можно обучить методом PCD. Обычно та- кое обучение вносит лишь небольшое изменение в параметры модели и в ее качество, измеряемое по логарифмическому правдоподобию, присвоенному данным, или по способности модели классифицировать входы. Процедура обучения иллюстрирует-ся на рис. 20.4. Алгоритм 20.1. Алгоритм вариационной стохастической максимизации правдопо- добия для обучения ГМБ с двумя скрытыми слоями Установить размер шага ε равным малому положительному числу.Установить число шагов выборки по Гиббсу k достаточно большим для прира- ботки марковской цепи p(v, h (1), h(2); θ + εΔθ). Инициализировать три матрицы V~, H~(1) и H~(2) с m строками каждая случайными значениями (например, выбранными из распределений Бернулли с такими же маргиналами, как у модели).while не сошелся (цикл обучения) do Выбрать мини-пакет m примеров из обучающих данных и организовать его в виде строк матрицы плана V.Инициализировать матрицы H ˆ (1) и Hˆ(2), возможно, маргиналами модели. while не сошелся (цикл вывода среднего поля) do Hˆ(1) ← σ(VW(1) + Hˆ(2)W(2)⏉) Hˆ(2) ← σ(H ˆ(1)W(2)) end while ΔW(1) ← (1/m)V ⏉Hˆ(1) ΔW(2) ← (1/m)H ˆ(1)⏉Hˆ(2) for l = 1 to k (выборка по Гиббсу) do Блочная выборка по Гиббсу 1:∀i, j, V~ i, j выбирается из P(V~ i, j = 1) = σ(Wj,:(1)(H~ i,:(1))⏉). ∀i, j, H~ i, j(2) выбирается из P(H~ i, j(2) = 1) = σ(H~ i,:(1)W:,j(2)). Блочная выборка по Гиббсу 2:∀i, j, H~ i, j(1) выбирается из P(H~ i, j(1) = 1) = σ(V~ i,:W:,j(1) + H~ i,:(2)Wj,:(2)⏉). end for ΔW(1) ← ΔW(1) – (1/m)V⏉H~(1) ΔW(2) ← ΔW(2) – (1/m)H~(1)⏉H~(2) W(1) ← W(1) + εΔW(1) (это упрощенная иллюстрация, на практике применяет- ся более эффективный алгоритм, например импульсный с убывающей ско- ростью обучения) W(2) ← W(2) + εΔW(2) end while\n--- Страница 563 ---\n562  Г лубокие порождающие модели (a) (c)(b) (d) Рис. 20.4  Процедура обучения глубокой машины Больцмана, использо- ванной для классификации набора данных MNISТ (Salakhutdinov and Hinton, 2009a; Srivastava et al., 2014). (a) Обучить ОМБ, применив алгоритм CD для приближенной максимизации log P(v). (b) Обучить вторую ОМБ, которая моделирует h(1) и целевой класс y, применив алгоритм CD-k для прибли- женной максимизации log P(h(1), y), где h(1) – выборка из апостериорного распределения первой ОМБ при условии данных. Увеличивать k от 1 до 20 в процессе обучения. (c) Объединить обе ОМБ в ГМБ. Обучить ее при- ближенной максимизации log P(v, y), применив алгоритм стохастической максимизации правдоподобия с k = 5. ( d) Удалить y из модели. Определить новый набор признаков h(1) и h(2), полученных путем выполнения вывода среднего поля в модели без y. Использовать эти признаки в качестве входа МСП, структура которого такая же, как структура дополнительного прохода среднего поля, с дополнительным выходным слоем для оценки y. Инициа- лизировать веса МСП весами ГМБ. Обучить МСП приближенной максими-зации log P(y|v), применив алгоритм стохастического градиентного спуска и прореживание. Рисунок взят из работы Goodfellow et al. (2013b) Эта процедура жадного послойного обучения – не просто покоординатное вос- хождение. Она действительно напоминает покоординатное восхождение, потому что на каждом шаге мы оптимизируем одно подмножество параметров. Но оба метода отличаются, поскольку в процедуре жадного послойного обучения на каждом шаге используется другая целевая функция. Жадное послойное предобучение ГМБ отличается от жадного послойного предобуче ния ГСД. Параметры каждой отдельной ОМБ можно копировать в соот- ветствующую ГСД непосредственно. В случае же ГМБ параметры ОМБ необходимо\n--- Страница 564 ---\nГ лубокие машины Больцмана  563 модифицировать перед включением в ГМБ. Слой в середине стека ОМБ обучается только на входных данных, поступающих снизу, но после того как стек собран в ГМБ, этому слою данные поступают снизу и сверху. Чтобы учесть этот эффект, в работе Salakhutdinov and Hinton (2009a) предлагается делить пополам веса всех ОМБ, кро- ме нижней и верхней, перед тем как вставлять их в ГМБ. Кроме того, нижнюю ОМБ следует обучать с использованием двух «копий» каждого видимого блока со связан- ными, равными между собой весами. Это означает, что на восходящем проходе веса, по сути дела, удваиваются. Аналогично верхнюю ОМБ следует обучать с использова- нием двух копий верхнего слоя. Для получения не уступающих лучшим образцам результатов с помощью глубо- ких машин Больцмана необходимо модифицировать стандартный алгоритм стоха-стической максимизации правдоподобия, а именно использовать небольшую толи- ку среднего поля в отрицательной фазе шага совместного обучения методом PCD (Salakhutdinov and Hinton, 2009a). Точнее говоря, математическое ожидание гради-ента энергии следует вычислять относительно распределения среднего поля, в кото- ром все блоки независимы. Параметры этого распределения среднего поля следует получать, выполнив всего одну итерацию уравнений неподвижной точки среднего поля. См. работу Goodfellow et al. (2013b), где приведено сравнение качества центри-рованных ГМБ с применением частичного среднего поля в отрицательной фазе и без оного. 20.4.5. Совместное обучение глубоких машин Больцмана Для классической ГМБ требуется жадное предобучение без учителя, а чтобы она хо- рошо выполняла классификацию, необходим отдельный основанный на МСП клас-сификатор поверх выделенных ей скрытых признаков. У этой схемы есть нежела- тельные свойства. Трудно следить за качеством в процессе обучения, поскольку мы не можем вычислить свойства полной ГМБ во время обучения первой ОМБ. Поэтому сказать, насколько хорошо выбраны гиперпараметры, можно только, когда процесс обучения зайдет достаточно далеко. Программным реализациям ГМБ нужно много различных компонент: для обучения отдельных ОМБ методом CD, обучения полной ГМБ методом PCD и обучения на основе обратного распространения через МСП. Наконец, МСП, построенные поверх машины Больцмана, теряют многие преимуще-ства ее вероятностной модели, например способность выполнять вывод, когда часть входных значений отсутствует. Существуют два основных способа решить проблему совместного обучения глу- бокой машины Больцмана. Первый – центрированная глубокая машина Больцмана (Montavon and Muller, 2012), когда модель перепараметризуется так, чтобы гессиан функции стоимости был лучше обусловлен в начале процесса обучения. В резуль- тате получается модель, которую можно обучить без этапа жадного послойного предобучения. Эта модель достигает отличного логарифмического правдоподобия на тестовом наборе и порождает примеры высокого качества. К сожалению, она по- прежнему не может конкурировать с правильно регуляризированным МСП в роли классификатора. Второй способ – использовать многопредсказательную глубокую машину Больцмана (multi-prediction deep Boltzmann machine) (Goodfellow et al., 2013b). В этой модели применяется альтернативный критерий обучения, который по- зволяет использовать алгоритм обратного распространения, чтобы избежать проблем с MCMC-оценками градиента. К сожалению, новый критерий не приводит к хороше-\n--- Страница 565 ---\n564  Г лубокие порождающие модели му правдоподобию или выборкам, но, по сравнению с MCMC-методами, производит более качественную классификацию и может хорошо рассуждать об отсутствующих входных данных. Центрирование машины Больцмана проще всего описать, вернувшись к общему взгляду на машину Больцмана как на множество блоков x с матрицей весов U и сме- щениями b. Напомним, что функция энергии имеет вид E(x) = –x⏉Ux – b⏉x. (20.36) Применяя различные паттерны разреженности в матрице весов U, мы можем реа- лизовать такие структуры машин Больцмана, как ОМБ или ГМБ, с разным числом слоев. Для этого нужно разбить x на видимые и скрытые блоки и обнулить элементы U, соответствующие блокам, которые не взаимодействуют. В центрированной маши- не Больцмана вводится вектор μ, вычитаемый из всех состояний: E′(x; U, b) = –(x – μ)⏉U(x – μ) – (x – μ)⏉b. (20.37) Обычно μ является гиперпараметром и фиксируется в начале обучения. Как пра- вило, он выбирается, так чтобы x – μ ≈ 0 на этапе инициализации модели. Такая пере- параметризация не влияет на множество распределений вероятности, представимых моделью, но изменяет динамику стохастического градиентного спуска в применении к правдоподобию. Точнее говоря, во многих случаях перепараметризация дает луч- ше обусловленную матрицу Гессе. В работе Melchior et al. (2013) экспериментально подтверждено, что обусловленность гессиана улучшается, и отмечено, что центриро- вание эквивалентно другой технике обучения машин Больцмана – расширенному градиенту (enhanced gradient) (Cho et al., 2011). Благодаря улучшенной обусловлен-ности гессиана обучение может успешно завершиться даже в трудных случаях типа обучения глубокой машины Больцмана с несколькими слоями. Другой подход к совместному обучению глубоких машин Больцмана – много- предсказательная глубокая машина Больцмана (МП-ГМБ), идея которой – рас- сматривать уравнения среднего поля как определение семейства рекуррентных се-тей для приближенного решения любой возможной проблемы вывода (Goodfellow et al., 2013b). Вместо того чтобы обучать модель максимизации правдоподобия, мы обучаем ее, так чтобы каждая рекуррентная сеть получала верный ответ на соот-ветствующую проблему вывода. Процесс обучения показан на рис. 20.5. Он состоит из трех частей: случайная выборка обучающего примера, случайная выборка под-множества входов сети вывода и обучение сети вывода предсказывать значения остальных блоков. Этот общий принцип обратного распространения по графу вычислений для при- ближенного вывода применялся и к другим моделям (Stoyanov et al., 2011; Brakel et al., 2013). И в этих моделях, и в МП-ГМБ окончательная потеря не является нижней границей правдоподобия, а обычно основана на приближенном условном распреде- лении отсутствующих значений, индуцируемом сетью приближенного вывода. Это значит, что в обоснование обучения таких моделей выдвигаются чисто эвристические аргументы. Если исследовать распределение p(v), представленное машиной Боль- цмана, которая была обучена как МП-ГМБ, то оно окажется несовершенным в том смысле, что выборка по Гиббсу дает плохие примеры. У обратного распространения по графу вывода есть два основных преимущества. Во-первых, он обучает модель так, как она реально используется, – с помощью при-Рис. 20.5  Иллюстрация многопредсказательного процесса обучения глубокой машины Больцмана. В строках показаны разные примеры из ми- ни-пакета для одного и того же шага обучения, а в столбцах – временной шаг процесса вывода среднего поля. Для каждого примера мы выбираем подмножество переменных, которое будет служить входом для процесса вывода. Эти переменные закрашены черным, чтобы показать обусловли-вание. Затем выполняется процесс вывода среднего поля, стрелки пока-зывают влияние одних переменных на другие. В практических приложе- ниях среднее поле разворачивается на несколько шагов, здесь же таких шагов всего два. Штриховые стрелки означают, что процесс можно было бы развернуть еще на несколько шагов. Переменные, которые не подава-лись на вход процесса вывода, становятся метками, они закрашены серым цветом. Процесс вывода для каждого примера можно рассматривать как рекуррентную сеть. Мы пользуемся градиентным спуском и обратным рас- пространением, чтобы обучить эти рекуррентные сети порождать правиль-ные метки при известных входах. Тем самым процесс среднего поля для МП-ГМБ обучается давать верные оценки. Рисунок взят из работы Good-fellow et al. (2013b) и немного модифицирован\n--- Страница 566 ---\nГ лубокие машины Больцмана  565 му правдоподобию или выборкам, но, по сравнению с MCMC-методами, производит более качественную классификацию и может хорошо рассуждать об отсутствующих входных данных. Центрирование машины Больцмана проще всего описать, вернувшись к общему взгляду на машину Больцмана как на множество блоков x с матрицей весов U и сме- щениями b. Напомним, что функция энергии имеет вид E(x) = –x⏉Ux – b⏉x. (20.36) Применяя различные паттерны разреженности в матрице весов U, мы можем реа- лизовать такие структуры машин Больцмана, как ОМБ или ГМБ, с разным числом слоев. Для этого нужно разбить x на видимые и скрытые блоки и обнулить элементы U, соответствующие блокам, которые не взаимодействуют. В центрированной маши- не Больцмана вводится вектор μ, вычитаемый из всех состояний: E′(x; U, b) = –(x – μ)⏉U(x – μ) – (x – μ)⏉b. (20.37) Обычно μ является гиперпараметром и фиксируется в начале обучения. Как пра- вило, он выбирается, так чтобы x – μ ≈ 0 на этапе инициализации модели. Такая пере- параметризация не влияет на множество распределений вероятности, представимых моделью, но изменяет динамику стохастического градиентного спуска в применении к правдоподобию. Точнее говоря, во многих случаях перепараметризация дает луч- ше обусловленную матрицу Гессе. В работе Melchior et al. (2013) экспериментально подтверждено, что обусловленность гессиана улучшается, и отмечено, что центриро- вание эквивалентно другой технике обучения машин Больцмана – расширенному градиенту (enhanced gradient) (Cho et al., 2011). Благодаря улучшенной обусловлен-ности гессиана обучение может успешно завершиться даже в трудных случаях типа обучения глубокой машины Больцмана с несколькими слоями. Другой подход к совместному обучению глубоких машин Больцмана – много- предсказательная глубокая машина Больцмана (МП-ГМБ), идея которой – рас- сматривать уравнения среднего поля как определение семейства рекуррентных се-тей для приближенного решения любой возможной проблемы вывода (Goodfellow et al., 2013b). Вместо того чтобы обучать модель максимизации правдоподобия, мы обучаем ее, так чтобы каждая рекуррентная сеть получала верный ответ на соот-ветствующую проблему вывода. Процесс обучения показан на рис. 20.5. Он состоит из трех частей: случайная выборка обучающего примера, случайная выборка под-множества входов сети вывода и обучение сети вывода предсказывать значения остальных блоков. Этот общий принцип обратного распространения по графу вычислений для при- ближенного вывода применялся и к другим моделям (Stoyanov et al., 2011; Brakel et al., 2013). И в этих моделях, и в МП-ГМБ окончательная потеря не является нижней границей правдоподобия, а обычно основана на приближенном условном распреде- лении отсутствующих значений, индуцируемом сетью приближенного вывода. Это значит, что в обоснование обучения таких моделей выдвигаются чисто эвристические аргументы. Если исследовать распределение p(v), представленное машиной Боль- цмана, которая была обучена как МП-ГМБ, то оно окажется несовершенным в том смысле, что выборка по Гиббсу дает плохие примеры. У обратного распространения по графу вывода есть два основных преимущества. Во-первых, он обучает модель так, как она реально используется, – с помощью при- Рис. 20.5  Иллюстрация многопредсказательного процесса обучения глубокой машины Больцмана. В строках показаны разные примеры из ми- ни-пакета для одного и того же шага обучения, а в столбцах – временной шаг процесса вывода среднего поля. Для каждого примера мы выбираем подмножество переменных, которое будет служить входом для процесса вывода. Эти переменные закрашены черным, чтобы показать обусловли-вание. Затем выполняется процесс вывода среднего поля, стрелки пока-зывают влияние одних переменных на другие. В практических приложе- ниях среднее поле разворачивается на несколько шагов, здесь же таких шагов всего два. Штриховые стрелки означают, что процесс можно было бы развернуть еще на несколько шагов. Переменные, которые не подава-лись на вход процесса вывода, становятся метками, они закрашены серым цветом. Процесс вывода для каждого примера можно рассматривать как рекуррентную сеть. Мы пользуемся градиентным спуском и обратным рас- пространением, чтобы обучить эти рекуррентные сети порождать правиль-ные метки при известных входах. Тем самым процесс среднего поля для МП-ГМБ обучается давать верные оценки. Рисунок взят из работы Good-fellow et al. (2013b) и немного модифицирован\n--- Страница 567 ---\n566  Г лубокие порождающие модели ближенного вывода. Это означает, что приближенный вывод с целью, например, вос- полнить отсутствующие входные данные или выполнить классификацию, несмотря на отсутствие части данных, будет более верным при использовании МП-ГМБ, чем оригинальной ГМБ. Оригинальная ГМБ не является верным классификатором сама по себе; наилучшие результаты достигаются, когда на признаках, извлеченных ГМБ, обучается отдельный классификатор, а не когда вывод применяется для вычисления распределения меток классов. Вывод среднего поля в МП-ГМБ хорошо работает в роли классификатора даже без специальных модификаций. Второе преимущество обратного распространения по графу приближенного вывода состоит в том, что вы- числяется точный градиент потери. Для оптимизации это лучше, чем приближенные градиенты, вычисляемые алгоритмом стохастической максимизации правдоподобия, которые подвержены как смещению, так и дисперсии. По всей видимости, это объ- ясняет, почему МП-ГМБ можно обучать совместно, тогда как для ГМБ требуется жадное послойное предобучение. Недостаток обратного распространения по графу приближенного вывода – в том, что оно не позволяет оптимизировать логарифмиче-ское правдоподобие, а дает лишь эвристическую аппроксимацию обобщенного псев- доправдоподобия. МП-ГМБ вдохновила на создание NADE-k (Raiko et al., 2014) – расширения кар- каса NADE, описанного в разделе 20.10.10. Существуют связи между МП-ГМБ и прореживанием. Прореживание означает разделение параметров между несколькими графами вычислений, различие между которыми заключается в том, включает граф некоторый блок или нет. В МП-ГМБ параметры также разделяются между графами вычислений. Но различие между гра-фами состоит в том, наблюдается некоторый входной блок или нет. Если блок не наблюдается, то МП-ГМБ, в отличие от прореживания, не удаляет его полностью, а рассматривает как латентную переменную, подлежащую выводу. Можно было бы представить себе применение прореживания к МП-ГМБ посредством удаления не- которых блоков, вместо того чтобы делать их латентными. 20.5. Машины Больцмана для вещественных данных Первоначально машины Больцмана разрабатывались для бинарных данных, но во многих приложениях, в т. ч. при моделировании изображений и звука, необходи- мо представлять распределения вероятности вещественных значений. В некоторых случаях вещественные данные на отрезке [0, 1] можно рассматривать как представ-ление математического ожидания бинарной случайной величины. Например, в ра- боте Hinton (2000) полутоновые изображения в обучающем наборе рассматривают- ся как определение вероятностей из диапазона [0,1]. Каждый пиксель определяет вероятность того, что бинарная величина принимает значение 1, и все бинарные пик- сели выбираются независимо друг от друга. Это распространенная процедура вы-числения бинарных моделей для наборов полутоновых изображений. Тем не менее с теоретической точки зрения этот подход не слишком хорош, а независимо выбран- ные таким способом бинарные изображения напоминают шум. В этом разделе мы опишем машины Больцмана, определяющие плотность вероятности вещественных данных.\n--- Страница 568 ---\nМашины Больцмана для вещественных данных  567 20.5.1. ОМБ Гаусса–Бернулли Ограниченные машины Больцмана можно разработать для многих экспоненциаль- ных семейств условных распределений (Welling et al., 2005). Наиболее распростране-ны ОМБ с бинарными скрытыми и вещественными видимыми блоками и нормаль- ным условным распределением видимых блоков, среднее значение которого является функцией скрытых блоков. Существует много способов параметризации ОМБ Гаусса–Бернулли. В частно- сти, можно выбрать, использовать для нормального распределения ковариационную мат рицу или матрицу точности. Ниже будет описана формулировка с матрицей точ- ности. Переформулирование с ковариационной матрицей не составляет труда. Мы хотим иметь условное распределение p(v | h) = 𝒩(v; Wh, β –1). (20.38) Мы можем найти, какие члены следует прибавить к функции энергии, раскрыв не- нормированное логарифмическое условное распределение: log 𝒩(v; Wh, β–1)= –1/2(v – Wh)⏉β(v – Wh) + f(β). (20.39) Здесь f инкапсулирует все члены, являющиеся функцией только параметров, а не случайных величин модели. Мы можем отбросить f, поскольку ее единствен- ная роль – нормировать распределение, но эту роль сыграет статистическая сумма выбран ной нами функции энергии. Если мы включим все содержащие v члены (с противоположным знаком) уравне- ния (20.39) в нашу функцию энергии и не будем прибавлять никаких других членов, содержащих v, то функция энергии будет представлять желаемое условное распреде- ление p(v | h). В выборе другого условного распределения p(h | v) нам предоставлена некоторая свобода. Заметим, что в уравнении (20.39) имеется член 1/2h⏉W⏉βWh. (20.40) Этот член нельзя включить целиком, поскольку он содержит члены вида hihj, соот- ветствующие ребрам между скрытыми блоками. Если бы мы включили эти члены, то получили бы линейную факторную модель, а не ограниченную машину Больцмана. При проектировании нашей машины Больцмана мы просто опускаем эти попарные произведения. При этом условное распределение p(v | h) не изменяется, так что урав- нение (20.39) по-прежнему справедливо. Однако мы можем решить, следует ли вклю-чать члены, содержащие единственный элемент h i. Если взять диагональную матрицу точности, то окажется, что для каждого скрытого блока hi имеется член (20.41) Здесь мы воспользовались тем фактом, что hi2 = hi, потому что hi ∈ {0, 1}. Если вклю- чить этот член (с противоположным знаком) в функцию энергии, то у hi появится естественная тенденция (выражаемая смещением) к выключению, когда велики веса связей этого блока с видимыми блоками высокой точности. Решение о том, включать этот член смещения или нет, не влияет на семейство распределений, представимых моделью (в предположении, что включены параметры смещения для скрытых бло-\n--- Страница 569 ---\n568  Г лубокие порождающие модели ков), но влияет на динамику обучения модели. Благодаря его включению активации скрытых блоков, возможно, останутся разумными даже тогда, когда абсолютные ве-личины весов быстро возрастают. Вот одно из возможных определений функции энергии для ОМБ Гаусса–Бер- нулли: E(v, h) = 1/2v⏉(β ⊙ v) – (v ⊙ β)⏉Wh – b⏉h, (20.42) но можно также добавить дополнительные члены или параметризовать энергию в терминах дисперсии, а не точности. В этом выводе не включен член смещения для видимых блоков, но его легко до- бавить. И последний способ модифицировать параметризацию ОМБ Гаусса–Бер- нулли – решить, как трактовать матрицу точности. Она может быть фиксированной (скажем, взять оценку на основе маргинальной точности данных) или обучаемой. Она может быть равна произведению тождественной матрицы на скаляр или про-извольной диагональной матрицей. Обычно мы не используем в этом контексте не- диагональных матриц точности, потому что некоторые операции над нормальным распределением требуют обращения матрицы, а диагональная матрица обращается тривиально. В последующих разделах мы увидим, что другие виды машин Больцма- на допускают моделирование ковариационной структуры с применением различных приемов, позволяющих избежать обращения матрицы точности. 20.5.2. Неориентированные модели условной ковариации Хотя гауссова ОМБ всегда была канонической энергетической моделью для веще- ственных данных, в работе Ranzato et al. (2010a) отмечено, что индуктивное смещение гауссовой ОМБ плохо соответствует статистическим вариациям, присутствующим в некоторых типах вещественных данных, особенно в естественных изображениях. Проблема в том, что значительная часть информационного содержимого естествен- ных изображений заключена в ковариации между пикселями, а не в самих значени- ях пикселей. Другими словами, именно связи между пикселями, а не их абсолютные значения определяют полезную информацию, присутствующую в изображении. По- скольку гауссова ОМБ моделирует только условное среднее входных данных при условии скрытых блоков, она не способна уловить информацию об условной кова-риации. В ответ на эту критику были предложены альтернативные модели, пытаю- щиеся лучше учесть ковариацию вещественных данных. К их числу относится ОМБ со средним и ковариацией (mean and covariance RBM – mcRBM), модель среднего произведения t-распределения Стьюдента (mPoТ) и ОМБ типа Spike and Slab RBM (ssRBM). ОМБ со средним и ковариацией. В модели mcRBM скрытые блоки используются для независимого кодирования условного среднего и ковариации всех наблюдаемых блоков. Скрытый слой mcRBM разбит на две группы блоков: блоки среднего и блоки ковариации. Группа, моделирующая условное среднее, – это просто гауссова ОМБ. Вторая половина – ковариационная ОМБ (Ranzato et al., 2010a), которую часто на- зывают cRBM; ее компоненты моделируют структуру условной ковариации, как опи-сано ниже. Точнее говоря, если бинарные блоки среднего обозначить h (m), а бинарные бло- ки ковариации h(c), то модель mcRBM определяется как комбинация двух функций энергии:\n--- Страница 570 ---\nМашины Больцмана для вещественных данных  569 Emc(x, h(m), h(c)) = Em(x, h(m)) + Ec(x, h(c)), (20.43) где Em – стандартная функция энергии ОМБ Гаусса–Бернулли1. (20.44) а Ec – функция энергии cRBM, моделирующая информацию об условной ковариации: . (20.45) Параметр r(j) соответствует вектору весов ковариации, ассоциированному с hj(c), а b(c) – вектор смещений ковариации. Объединенная функция энергии определяет совместное распределение pmc(x, h(m), h(c)) = (1/Z)exp{–Emc(x, h(m), h(c))} (20.46) и соответствующее условное распределение наблюдений при условии h(m) и h(c) в виде многомерного нормального распределения: (20.47) Отметим, что ковариационная матрица не является диа- гональной и что W – матрица весов, ассоциированная с моделированием условных средних с помощью гауссовой ОМБ. Обучить mcRBM методами сопоставительно- го расхождения или устойчивого сопоставительного расхождения трудно из-за не- диагональной условной ковариационной матрицы. В методах CD и PCD требуется производить выборку из совместного распределения x, h(m), h(c), что в стандартной ОМБ достигается путем выборки по Гиббсу из условных распределений. Однако в mcRBM для выборки из p mc(x | h(m), h(c)) необходимо вычислять (Cmc)–1 на каждой итерации обучения. Для больших объемов наблюдений это может оказаться неподъ-емной вычислительной задачей. В работе Ranzato and Hinton (2010) прямой выборки из p mc(x | h(m), h(c)) удается избежать с помощью прямой выборки из маргинального распределения p(x) гамильтоновым (гибридным) методом Монте-Карло (Neal, 1993) применительно к свободной энергии mcRBM. Среднее произведение t-распределения Стьюдента. Модель среднего произведе- ния t-распределения Стьюдента (mPoТ) (Ranzato et al., 2010b) обобщает модель PoТ (Welling et al., 2003a) примерно так же, как mcRBM обобщает cRBM. Достигается это путем включения ненулевых гауссовых средних за счет добавления скрытых блоков, как в гауссовой ОМБ. Подобно mcRBM, условное распределение наблюдений PoТ является многомерным нормальным распределением (с недиагональной ковариаци-онной матрицей), но, в отличие от mcRBM, дополнительное условное распределение скрытых блоков описывается условными независимыми гамма-распределениями. Гамма-распределение 𝒢(k, θ) – это распределение вероятности положительных веще- 1 Этот вариант функции энергии ОМБ Гаусса–Бернулли предполагает, что в данных изобра- жения среднее всех пикселей равно нулю. В модель можно легко добавить пиксельные сме- щения, чтобы учесть ненулевые средние.\n--- Страница 571 ---\n570  Г лубокие порождающие модели ственных чисел со средним kθ. Для понимания основных идей модели mPoТ знаком- ство с деталями гамма-распределения необязательно. Функция энергии в модели mPoТ имеет вид EmPoT(x, h(m), h(c)) (20.48) (20.49) где r(j) – вектор весов ковариации, ассоциированный с блоком hj(c), а функция Em(x, h(m)) определена, как в (20.44). Как и в случае mcRBM, функция энергии в модели mPoТ определяет многомерное нормальное распределение – такое, что условное распределение x имеет недиагональ- ную ковариационную матрицу. Обучение модели mPoТ – как и mcRBM – осложня- ется невозможностью выборки из нормального условного распределения с недиаго- нальной ковариационной матрицей pmPoТ(x | h(m), h(c)), поэтому в работе Ranzato et al. (2010b) также предлагается прямая выборка из p(x) гамильтоновым (гибридным) методом Монте-Карло. Ограниченные машины Больцмана типа Spike and Slab. Ограниченные машины Больцмана типа Spike and Slab, или ssRBM (Courville et al., 2011), – еще один способ моделирования ковариационной структуры вещественных данных. По сравнению с mcRBM, они обладают тем преимуществом, что не нуждаются ни в обращении мат- рицы, ни в гамильтоновых методах Монте-Карло. Подобно mcRBM и mPoТ, в бинар- ных скрытых блоках ssRBM закодирована условная ковариация между пикселями посредством использования вспомогательных вещественных переменных. В ОМБ типа Spike and Slab есть два набора скрытых блоков: бинарные spike-блоки h и вещественные slab-блоки s. Среднее значение видимых блоков при условии скры- тых блоков равно (h ⊙ s)W ⏉. Иначе говоря, каждый столбец W:, i определяет компо- ненту, которая может встречаться во входных данных, когда hi = 1. Соответствующая spike-переменная hi определяет, присутствует ли эта компонента вообще. А соответ- ствующая slab-переменная si определяет интенсивность этой компоненты, если она присутствует. Когда spike-переменная активна, соответствующая slab-переменная добавляет дисперсию к входным данным вдоль оси, определенной столбцом W :, i. Это позволяет моделировать ковариацию между входами. По счастью, методы CD и PCD с выборкой по Гиббсу по-прежнему применимы. Обращать матрицы не нужно. Формально модель ssRBM определяется функцией энергии: x (20.50) (20.51) где bi – смещение spike-блока hi, Λ – диагональная матрица точности для наблюдений x, αi > 0 – скалярный параметр точности вещественной slab-переменной si, а Φi – не- отрицательная диагональная матрица, определяющая h-модулированный квадратич- ный штраф на x. Параметр μi задает среднее slab-переменной si. В случае, когда совместное распределение определено функцией энергии, вывести условные распределения в модели ssRBM сравнительно просто. Например, исключая\n--- Страница 572 ---\nМашины Больцмана для вещественных данных  571 slab-переменные s, получаем, что условное распределение наблюдений при условии бинарных spike-переменных h имеет вид (20.52) (20.53) где Последнее равенство имеет место, только если ковариационная матрица Css x|h положительно определенная. Фильтрация по spike-переменным означает, что истинное маргинальное распреде- ление h ⊙ s разреженное. Это не то же самое, что разреженное кодирование, где вы- борки из модели «почти никогда» (в смысле теории меры) не содержат нулей в коде и требуется, чтобы MAP-вывод индуцировал разреженность. Если сравнить ssRBM с mcRBM и mPoТ, то окажется, что ssRBM параметризует условную ковариацию между наблюдениями совершенно иначе. И mcRBM, и mPoТ моделируют структуру в виде используя активацию скрытых блоков hj > 0, чтобы наложить ограничения на условную ковариацию в направлении r(j). Что же касается ssRBM, то она задает условную ковариацию между наблюдени- ями с помощью скрытых spike-активаций hi = 1, чтобы стянуть матрицу активации вдоль направления, определяемого соответствующим весовым вектором. Условная ковариация в модели ssRBM похожа на даваемую другой моделью: анализом про- изведения вероятностных главных компонент (product of probabilistic principal com-ponents analysis – PoPPCA) (Williams and Agakov, 2002). В сверхполной конфигу- рации разреженная активация с ssRBM-параметризацией допускает значительную дисперсию (выше номинальной, определяемой матрицей Λ –1) только в избранных направлениях разреженно активированных hi. В моделях mcRBM и mPoТ сверхпол- ное представление означало бы, что для улавливания вариативности в конкретном направлении в пространстве наблюдений потенциально пришлось бы удалить все ограничения с положительной проекцией на это направление. Отсюда следует, что эти модели хуже приспособлены к сверхполной конфигурации. Основной недостаток ограниченной машины Больцмана типа Spike and Slab – в том, что при некоторых конфигурациях параметров получающаяся ковариацион- ная матрица не является положительно определенной. В этом случае значения, дале- кие от среднего, получают большую ненормированную вероятность, так что интеграл по всем возможным исходам расходится. Обычно этой проблемы можно избежать с помощью простых эвристических приемов. Теоретически строгого решения пока не найдено. Применить ограниченную оптимизацию, чтобы явно избежать областей, где вероятность не определена, трудно, не впадая в грех чрезмерной консервативности, из-за чего может случиться так, что модель никогда не попадет в области простран- ства параметров, где достигается хорошее качество. Качественно сверточные варианты ssRBM дают прекрасные примеры естествен- ных изображений. Некоторые из них показаны на рис. 16.1. У ssRBM есть несколько обобщений. Если включить взаимодействия высшего по- рядка и пулинг с усреднением по slab-переменным (Courville et al., 2014), то модель сможет обучиться отличным признакам для классификатора в случае, когда помечен-\n--- Страница 573 ---\n572  Г лубокие порождающие модели ных данных мало. Добавление в функцию энергии члена, предотвращающего неопре- деленность статистической суммы, приводит к модели разреженного кодирования типа Spike and Slab (Goodfellow et al., 2013d), или S3C (spike and slab sparse coding). 20.6. Сверточные машины Больцмана Как отмечалось в главе 9, входные данные очень высокой размерности, например изо- бражения, предъявляют жесткие требования к моделям машинного обучения с точ- ки зрения объема вычислений, потребной памяти и статистических свойств. Замена умно жения матриц дискретной сверткой с небольшим ядром – стандартный способ решения этих проблем для входных данных с пространственной или временной струк- турой, инвариантной относительно параллельных переносов. В работе Desjardins and Bengio (2008) показано, что этот подход хорошо работает в применении к ОМБ . В глубоких сверточных сетях обычно требуется операция пулинга, так что про- странственный размер каждого последующего слоя меньше размера предыдущего. В сверточных сетях прямого распространения часто в качестве функции пулинга бе- рут, например, максимум агрегируемых элементов. Не ясно, как обобщить эту идею на энергетические модели. Можно было бы ввести бинарный блок пулинга p по n бинарным детекторным блокам d и гарантировать, что p = max i di, полагая функцию энергии равной ∞ всюду, где это ограничение нарушается. Это решение плохо мас- штабируется, поскольку требует рассмотрения 2n конфигураций энергии, чтобы вы- числить нормировочную постоянную. Для небольшой области пулинга размера 3×3 придется выполнить 2 9 = 512 вычислений функции энергии на один блок пулинга! В работе Lee et al. (2009) для решения этой проблемы разработан метод вероят- ностного max-пулинга (не путайте со «стохастическим пулингом» – методом неяв- ного построения ансамблей сверточных сетей прямого распространения). Стратегия заключается в том, чтобы наложить ограничение на детекторные блоки: не более одного активного в каждый момент времени. Это означает, что всего имеется лишь n + 1 состояний (по одному для случаев, когда включен один из n детекторных бло- ков, плюс дополнительное состояние, в котором все детекторные блоки выключены). Блок пулинга включен тогда и только тогда, когда включен один из детекторных блоков. Состоянию, в котором все блоки выключены, назначается нулевая энергия. Можно считать это описанием модели с одной переменной, имеющей n + 1 состояний, или, эквивалентно, модели с n + 1 переменными, которая назначает энергию ∞ всем совместным комбинациям переменных, кроме n + 1. При всей своей эффективности вероятностный max-пулинг делает детекторные бло- ки взаимно исключающими, что в одних контекстах может считаться полезным регуля- ризирующим ограничением, а в других вредным ограничением на емкость модели. Этот метод не поддерживает пересекающихся областей пулинга, которые обычно нужны для достижения оптимального качества сверточных сетей прямого распространения, так что это ограничение, вероятно, сильно снижает качество сверточных машин Больцмана. В работе Lee et al. (2009) продемонстрировано, что вероятностный max-пулинг можно было бы использовать для построения сверточных машин Больцмана 1. Эта 1 Описанная в этой работе модель названа «глубокой сетью доверия», но поскольку ее мож- но охарактеризовать как строго неориентированную модель с вычислимыми послойными обновлениями неподвижной точки среднего поля, то лучше было бы назвать ее глубокой машиной Больцмана.\n--- Страница 574 ---\nМашины Больцмана для структурных и последовательных выходов  573 модель умеет выполнять такие операции, как восполнение отсутствующих частей данных. Несмотря на интеллектуальную привлекательность, работать с этой мо- делью на практике трудно, и обычно в роли классификатора она показывает худшие результаты, чем традиционные сверточные сети, обученные с учителем. Многие сверточные модели одинаково хорошо работают с входными данными раз- ного пространственного размера. Для машин Больцмана изменить размер входа слож-но по нескольким причинам. При изменении размера входа меняется статистическая сумма. Кроме того, во многих сверточных сетях инвариантность относительно размера достигается путем увеличения размера областей пулинга пропорционально размеру входа, но масштабировать области пулинга в машине Больцмана неудобно. В традици- онных сверточных нейронных сетях можно использовать фиксированное число блоков пулинга и динамически увеличивать их размер. В машинах Больцмана большие обла- сти пулинга обходятся слишком дорого при наивном подходе. Примененный в работе Lee et al. (2009) подход – сделать детекторные блоки в одной области пулинга взаимно исключающими – решает вычислительные проблемы, но все равно не позволяет иметь области пулинга переменного размера. Предположим, к примеру, что мы обучаем мо- дель детекторных блоков, обучающихся обнаружению границ с вероятностным max- пулингом по области 2× 2. Это налагает ограничение: в каждой области 2× 2 может встречаться только одна граница. Если мы затем увеличим размер входного изображе-ния на 50% в каждом направлении, то естественно ожидать, что число границ соответ- ственно возрастет. Если же мы вместо этого увеличим на 50% размер областей пулинга в каждом направлении до 3× 3, то ограничение взаимного исключения теперь говорит, что в каждой области размера 3× 3 может присутствовать не более одной границы. По мере увеличения входного изображения модель генерирует границы с меньшей плот- ностью. Разумеется, такие проблемы возникают, только когда модель вынуждена ис-пользовать переменный размер области пулинга, чтобы выходной вектор имел фик-сированный размер. Модели с вероятностным max-пулингом все же могут принимать изображения переменного размера, при условии что карта признаков на выходе модели может масштабироваться пропорционально размеру входного изображения. Пиксели на границе изображения тоже представляют сложность, усугубляющуюся тем фактом, что связи в машине Больцмана симметричны. Если мы не будем неявно дополнять вход нулями, то скрытых блоков будет меньше, чем видимых, и видимые блоки на границе изображения будут моделироваться плохо, потому что принадле-жат рецептивному полю меньшего числа скрытых блоков. Но если производить не-явное дополнение нулями, то скрытые блоки на границе будут управляться меньшим числом входных пикселей, так что активация может не произойти, когда необходимо. 20.7. Машины Больцмана для структурных и последовательных выходов В случае структурного выхода мы хотим обучить модель, умеющую отображать вход x на выход y, так что различные элементы y связаны друг с другом и должны под- чиняться некоторым ограничениям. Например, в задаче синтеза речи y – звуковой сигнал, и полный выходной сигнал должен звучать как связная речь. Естественный способ представить связи между элементами y – воспользоваться распределением вероятности p(y | x). Такую вероятностную модель могут предло- жить машины Больцмана, обобщенные на моделирование условных распределений.\n--- Страница 575 ---\n574  Г лубокие порождающие модели Тот же инструментарий условного моделирования с помощью машины Больцма- на можно применить не только к задаче структурного вывода, но и для моделиро- вания последовательностей. В этом случае вместо отображения входа x на выход y модель должна оценить распределение вероятности последовательности переменных p(x(1), …, x(τ)). Для решения этой задачи условные машины Больцмана могут предста- вить факторы виды p(x(t) | x(1), …, x(t–1)). Важная для киноиндустрии и видеоигр задача – смоделировать последовательно- сти углов сочленения суставов в скелетах, используемых для отрисовки трехмерных персонажей. Эти последовательности часто запоминаются системами захвата движе-ния при регистрации движений актеров. Вероятностная модель движения персонажа позволяет генерировать новые, не встречавшиеся ранее, но реалистичные движения. Для решения этой задачи в работе Тaylor et al. (2007) предложено моделирование условной ОМБ p(x (t) | x(t–1), …, x(t–m)) для малых m. Модель представляет собой ОМБ над распределением p(x(t)), в которой параметры смещения – линейная функция от предыдущих m значений x. При обусловливании разными значениями x(t–1) и более ранних переменных мы получаем новую ОМБ над x. Веса в ОМБ над x никогда не меняются, но за счет обусловливания по различным прошлым значениям мы можем изменять вероятность активности различных скрытых блоков ОМБ. Активируя и де- активируя различные подмножества скрытых блоков, мы можем вносить значитель-ные изменения в индуцированное распределение вероятности x. Возможны и другие варианты условной ОМБ (Mnih et al., 2011) и моделирования последовательностей с помощью условных ОМБ (Тaylor and Hinton, 2009; Sutskever et al., 2009; Boulanger- Lewandowski et al., 2012). Еще одна задача – моделирование распределения последовательностей музыкаль- ных нот для создания песен. В работе Boulanger-Lewandowski et al. (2012) предло- жена модель последовательности РНС-ОМБ (англ. RNN-RBM), которая применена к этой задаче. Это порождающая модель последовательности кадров x (t), состоящая из РНС, которая порождает параметры ОМБ для каждого временного шага. В отли- чие от предыдущих подходов, где от шага к шагу варьировались только параметры смещения ОМБ, РНС, используемая в этой модели, порождает все параметры ОМБ, включая и веса. Для обучения модели мы должны выполнить обратное распростране- ние градиента функции потерь по РНС. Функция потерь применяется не напрямую к выходам РНС, а к ОМБ. Это означает, что мы должны приближенно продифферен- цировать потерю по параметрам ОМБ, применив метод сопоставительного расхож-дения или другой похожий алгоритм. Затем приближенный градиент можно обратно распространить по РНС, применив обычный алгоритм обратного распространения во времени. 20.8. Другие машины Больцмана Существует еще много вариантов машин Больцмана. Для обобщения машин Больцмана можно применять различные критерии обуче- ния. Мы сосредоточили внимание на машинах Больцмана, обучаемых приближен-но максимизировать порождающий критерий log p(v). Можно вместо этого обучить дискриминантную ОМБ, нацеленную на максимизацию log p(y | v) (Larochelle and Bengio, 2008). Этот подход часто дает наилучшие результаты, если используется ли-нейная комбинация порождающего и дискриминантного критериев. К сожалению,\n--- Страница 576 ---\nОбратное распространение через случайные операции  575 ОМБ не так хорошо обучаются с учителем, как МСП, по крайней мере с применени- ем существующих технологий. В большинстве практически используемых машин Больцмана функция энергии включает только взаимодействия второго порядка, т. е. представляет собой суммы большого числа членов, каждый из которых является произведением всего двух случайных величин, например viWi, j hj. Можно обучить и машины Больцмана более высокого порядка (Sejnowski, 1987), для которых члены функции энергии являются произведениями многих величин. Трехсторонние взаимодействия между скрытым блоком и двумя разными изображениями могут моделировать пространственное преобразование между текущим и следующим кадрами видео (Memisevic and Hinton, 2007, 2010). Умножение на унитарную переменную класса может изменить связь между видимым и текущим блоками в зависимости от того, бит какого класса поднят (Nair and Hinton, 2009). Недавний пример использования взаимодействий высшего порядка дает машина Больцмана с двумя группами скрытых блоков, одна из которых взаимодействует с видимыми блоками v и меткой класса y, а другая – только с вход- ными значениями v (Luo et al., 2011). Это можно интерпретировать как поощрение некоторых скрытых блоков обучаться моделированию входа с использованием при- знаков, релевантных классу; кроме того, дополнительные скрытые блоки обучаются объяснять мелкие детали, необходимые для придания реалистичности примерам v, не определяя класса примера. Еще одно использование взаимодействий высшего по-рядка – пропускание части признаков. В работе Sohn et al. (2013) описана машина Больцмана с взаимодействиями третьего порядка и бинарными масочными перемен- ными, ассоциированными с каждым видимым блоком. Если масочная переменная равна нулю, то она устраняет влияние соответствующего видимого блока на скры-тые. Это позволяет убирать видимые блоки, не релевантные задаче классификации, из пути вывода, на котором оценивается класс. Вообще, инфраструктура машин Больцмана – богатое поле для исследований, где возможных структур моделей гораздо больше, чем изучено до сих пор. Для разработ-ки нового вида машин Больцмана требуется больше тщатнльности и изобретатель- ности, чем для разработки нового слоя нейронной сети, поскольку зачастую трудно подобрать функцию энергии, допускающую обсчет всевозможных условных распре-делений, которые необходимы для использования модели. Несмотря на требуемые немалые усилия, эта область остается открытой для инноваций. 20.9. Обратное распространение через случайные операции В традиционных нейронных сетях реализовано детерминированное преобразование некоторых входных переменных x. Но при разработке порождающих моделей часто желательно наделить нейронную сеть способностью к стохастическим преобразова- ниям x. Один из способов добиться этой цели – пополнить нейронную сеть дополни- тельными входами z, выбранными из какого-нибудь простого распределения, напри- мер равномерного или нормального. Тогда на внутреннем уровне сеть будет и дальше выполнять детерминированные вычисления, но наблюдателю, не имеющему доступа к z, функция f(x, z) будет казаться стохастической. При условии что f непрерывна и дифференцируема, мы можем как обычно вычислить градиенты, необходимые для обучения методом обратного распространения.\n--- Страница 577 ---\n576  Г лубокие порождающие модели В качестве примера рассмотрим операцию, состоящую из выборки примеров y из нормального распределения со средним μ и дисперсией σ2: y ∼ 𝒩(μ, σ2). (20.54) Поскольку отдельный пример y порождается не функцией, а процессом выборки, выдающим новый результат при каждом запросе, взятие производных y по парамет- рам распределения μ и σ2 может показаться противоречащим интуиции. Однако мы можем переформулировать процесс выборки как преобразование случайной величи-ны z ∼ 𝒩(z; 0, 1) для получения примера из желаемого распределения: y = μ + σz. (20.55) Теперь мы можем выполнить обратное распространение через операцию выбор- ки, рассматривая ее как детерминированную операцию с дополнительным входом z. Важно, что дополнительный вход – это случайная величина, распределение которой не является функцией от любой из величин, чьи производные мы хотим вычислять. Этот результат говорит, как бесконечно малое изменение μ или σ отразилось бы на выходе, если бы мы могли повторить операцию выборки с тем же значением z. Зная, как выполнить обратное распространение через эту операцию выборки, мы можем включить ее в объемлющий граф. Можно строить элементы графа на базе вы- хода выборочного распределения. Например, мы можем вычислять производные не-которой функции потери J(y). Можно также строить элементы графа, выходы кото- рых являются входами или параметрами операции выборки. Например, можно было бы построить больший граф с μ = f(x; θ) и σ = g(x; θ). В этом пополненном графе мы можем воспользоваться обратным распространением через эти функции для вычис-ления ∇ θJ(y). Принцип, использованный в этом примере выборки из нормального распределе- ния, применим и в более общей ситуации. Мы можем выразить любое распределение вероятности вида p(y; θ) или p(y | x; θ) как p(y | ω), где ω – переменная, содержащая как параметры θ, так и (если это осмыслено) входы x. Зная значение y, выбранное из распределения p(y | ω), где ω может, в свою очередь, быть функцией от других пере- менных, мы можем переписать y ∼ p(y | ω) (20.56) в виде y = f(z; ω), (20.57) где z – источник случайности. Затем можно вычислить производные y по ω с по- мощью традиционных средств, например алгоритма обратного распространения в применении к f в предположении, что f непрерывна и дифференцируема почти всюду. Важно, что ω не должна быть функцией z, а z не должна быть функцией ω. Эту технику часто называют перепараметризацией, стохастическим обратным распро- странением или методом малых возмущений. Из требования о непрерывности и дифференцируемости f, конечно, вытекает, что y должна быть непрерывна. Если мы хотим выполнять обратное распространение через процесс выборки, порождающий дискретные примеры, то все же возможно оценить градиент по ω, применяя алгоритмы обучения с подкреплением, например варианты алгоритма REINFORCE (Williams, 1992), который обсуждается в разделе 20.9.1.\n--- Страница 578 ---\nОбратное распространение через случайные операции  577 В приложениях нейронных сетей мы обычно выбираем z из какого-нибудь просто- го распределения, например равномерного или нормального, а чтобы получить более сложные распределения, разрешаем детерминированной части сети изменять форму входа. Идея распространения градиентов или оптимизации посредством стохастических операций восходит еще к середине XX столетия (Price, 1958; Bonnet, 1964) и впер- вые была применена к машинному обучению в контексте обучения с подкреплением (Williams, 1992). В более близкое к нам время она применялась к вариационным ап- проксимациям (Opper and Archambeau, 2009) и к стохастическим и порождающим нейронным сетям (Bengio et al., 2013b; Kingma, 2013; Kingma and Welling, 2014b,a; Rezende et al., 2014; Goodfellow et al., 2014c). Многие сети, в т. ч. шумоподавляющие автокодировщики и сети, регуляризируемые методом прореживания, также естест- венно проектируются для приема шума на входе, не требуя специальной перепара-метризации, для того чтобы сделать шум независимым от модели. 20.9.1. Обратное распространение через дискретные стохастические операции Если модель выдает на выходе дискретную переменную y, то перепараметризация неприменима. Предположим, что модель принимает входы x и параметры θ, ин- капсулированные вектором ω, и объединяет их со случайным шумом z для порож- дения y : y = f(z; ω). (20.58) Поскольку y дискретна, f должна быть кусочно-постоянной функцией. Произ- водные такой функции бесполезны во всех точках. В точках разрыва производная не определена, но это еще меньшая из бед. Настоящая беда в том, что производная равна нулю на участках постоянства, т. е. почти всюду. Поэтому производные любой функции стоимости J(y) ничего не говорят о том, как обновлять параметры модели θ. Алгоритм REINFORCE (REward Increment = nonnegative Factor × Offset Rein- forcement × Characteristic Eligibility) предлагает инфраструктуру для определения семейства простых, но очень эффективных решений (Williams, 1992). Основная идея заключается в том, что хотя J(f(z; ω)) – кусочно-постоянная функция с бесполез- ными производными, ожидаемая стоимость 𝔼 z∼p(z)J(f(z; ω)) часто является гладкой функцией, пригодной для градиентного спуска. Хотя это математическое ожидание обычно вычислительно неразрешимо, если размерность y велика (или y является результатом композиции большого числа дис-кретных стохастических решений), для него можно получить несмещенную оценку, вычислив среднее методом Монте-Карло. Стохастическую оценку градиента можно использовать совместно с алгоритмом СГС или другим методом стохастической гра- диентной оптимизации. Простейший вариант алгоритма REINFORCE получается, если просто продиффе- ренцировать ожидаемую стоимость: (20.59) (20.60)\n--- Страница 579 ---\n578  Г лубокие порождающие модели (20.61) (20.62) Уравнение (20.60) опирается на предположение, что J не ссылается на ω напря- мую. Ослабить это предположение и тем самым обобщить решение очень прос- то. В уравнении (20.61) использовано правило дифференцирования логарифма Уравнение (20.62) дает несмещенную оценку градиента ме- тодом Монте-Карло. Всюду, где в этом разделе встречается p(y), можно было бы с тем же успехом на- писать p(y | x), поскольку p(y) параметризовано ω, а ω содержит θ и x, если x вообще присутствует. Эта простая оценка по алгоритму REINFORCE обладает одним недостатком – очень высокой дисперсией, поэтому для получения хорошей оценки градиента нуж- но выбрать много примеров y. Иначе говоря, если выбрать только один пример, то алгоритм СГС будет сходиться очень медленно и потребуется уменьшать скорость обучения. Дисперсию оценки можно значительно снизить, воспользовавшись мето-дами снижения дисперсии (Wilson, 1984; L’Ecuyer, 1994). Идея в том, чтобы модифи- цировать оценку таким образом, что математическое ожидание остается неизменным, а дисперсия уменьшается. В контексте REINFORCE предложенные методы сниже- ния дисперсии включают вычисление базового значения, которое используется для смещения J(y). Отметим, что любое смещение b(ω), не зависящее от y, не изменяет математического ожидания оценки градиента, потому что (20.63) (20.64) (20.65) а это означает, что (20.66) (20.67) Далее, мы можем получить оптимальное значение b(ω), вычислив дисперсию (J(y) – b(ω)) относительно распределения p(y) и минимизировав его от- носительно b(ω). В результате мы найдем, что оптимальные базовые значения b*(ω)i различаются для всех элементов ωi вектора ω:\n--- Страница 580 ---\nОриентированные порождающие сети  579 (20.68) Таким образом, оценка градиента по ωi принимает вид (20.69) где b(ω)i оценивает приведенное выше значение b*(ω)i. Обычно оценку b полу- чают, добавляя новые выходы в нейронную сеть и обучая их оценивать величины и для каждого элемента ω. Эти дополнитель- ные выходы можно обучить, взяв в качестве целевой функции среднеквадратическую ошибку и используя соответственно и в качестве целей, ког- да y выбирается из p(y) для заданного ω. Тогда оценку b можно восстановить, подста- вив эти оценки в уравнение (20.68). В работе Mnih and Gregor (2014) предпочтение отдано использованию одного разделяемого (между всеми элементами ωi) выхода, обученного с меткой J(y), а в качестве базового значения берется b(ω) ≈ Ep(y)[J(y)]. Методы снижения дисперсии были предложены в контексте обучения с подкре- плением (Sutton et al., 2000; Weaver and Тao, 2001), как обобщение предшествующей работы для случая бинарного вознаграждения Dayan (1990). Примеры современного использования алгоритма REINFORCE со сниженной дисперсией в контексте глу- бокого обучения см. в работах Bengio et al. (2013b), Mnih and Gregor (2014), Ba et al. (2014), Mnih et al. (2014), Xu et al. (2015). Помимо использования зависящего от вхо-да базового значения b(ω), в работе Mnih and Gregor (2014) установлено, что масштаб (J(y) – b(ω)) можно регулировать во время обучения путем деления на его стандарт- ное отклонение, оцененное с помощью скользящего среднего; получается своего рода адаптивная скорость обучения, которая противостоит эффекту важных вариаций абсолютной величины этого значения, имеющих место в процессе обучения. Авторы назвали эту технику эвристической нормировкой дисперсии. Основанные на алгоритме REINFORCE оценки можно интерпретировать как оце- нивание градиента путем коррелирования выбора y с соответствующими значениями J(y). Если хорошее значение y при текущей параметризации маловероятно, то может потребоваться много времени на то, чтобы случайно получить его и необходимый сигнал о том, что эту конфигурацию следует подкрепить. 20.10. Ориентированные порождающие сети Как отмечалось в главе 16, ориентированные графические модели составляют важ- ный класс графических моделей. Но, несмотря на их популярность в широком сооб- ществе машинного обучения, в более узком кругу специалистов по глубокому обуче- нию примерно до 2013 года их затмевали неориентированные модели типа ОМБ.\n--- Страница 581 ---\n580  Г лубокие порождающие модели В этом разделе мы рассмотрим некоторые стандартные графические модели, ко- торые традиционно ассоциируются с глубоким обучением. Мы уже описывали глу- бокие сети доверия, представляющие собой частично ориентированную модель. Мы также описывали модели разреженного кодирования, которые можно считать мелки- ми ориентированными порождающими моделями. В контексте глубокого обучения они часто используются для обучения признакам, хотя оставляют желать лучшего как метод генерации примеров и оценивания плотности. Теперь мы опишем различ- ные виды глубоких полностью ориентированных моделей. 20.10.1. Сигмоидные сети доверия Сигмоидная сеть доверия (Neal, 1990) – простой вид ориентированной графической модели со специфическим условным распределением вероятности. В общем случае такую сеть можно представлять себе как вектор бинарных состояний s, каждый эле- мент которого зависит от своих предков: (20.70) В самом распространенном случае сигмоидная сеть доверия состоит из большого числа слоев, а предковая выборка проходит через много скрытых слоев и в конечном итоге генерирует видимый слой. Эта структура очень похожа на глубокую сеть дове- рия – с тем отличием, что блоки в начале процесса выборки независимы друг от друга, а не выбираются из ограниченной машины Больцмана. Такая структура интересна по целому ряду причин, в частности потому, что является универсальным аппроксима- тором распределений вероятности видимых блоков в том смысле, что может аппрок- симировать любое распределение вероятности бинарных величин с произвольной точностью при наличии достаточно большого числа слоев, даже если ширина каждо-го слоя ограничена размерностью видимого слоя (Sutskever and Hinton, 2008). Хотя в сигмоидной сети доверия генерация выборки видимых слоев очень эффек- тивна, о большинстве других операций этого не скажешь. Вывод скрытых блоков при условии видимых блоков вычислительно неразрешим. Как и вывод среднего поля, поскольку для вычисления вариационной нижней границы нужно знать математи-ческие ожидания клик, а они охватывают слои целиком. Из-за трудности этой проб- лемы ориентированные дискретные сети не получили широкого распространения. Один из подходов к выводу в сигмоидной сети доверия – построить другую ниж- нюю границу специально для таких сетей (Saul et al., 1996). Но этот подход приме- нялся только к совсем небольшим сетям. Другое решение – воспользоваться меха- низмами обученного вывода из раздела 19.5. Машина Гельмгольца (Dayan et al., 1995; Dayan and Hinton, 1996) – это сигмоидная сеть доверия в сочетании с сетью вывода, предсказывающей параметры распределения среднего поля скрытых блоков. В совре- менных подходах к сигмоидным сетям доверия (Gregor et al., 2014; Mnih and Gregor, 2014) по-прежнему используется эта идея сети вывода. Но все эти методы остаются трудными вследствие дискретной природы латентных переменных. Нельзя просто выполнить обратное распространение через выход сети вывода, приходится вместо этого использовать относительно ненадежные механизмы обратного распростране-ния через дискретные процессы выборки, как описано в разделе 20.9.1. Недавние под- ходы на основе выборки по значимости, алгоритма бодрствования-сна с изменением\n--- Страница 582 ---\nОриентированные порождающие сети  581 весом (Bornschein and Bengio, 2015) и двусторонних машин Гельмгольца (Bornschein et al., 2015) сделали возможным быстрое обучение сигмоидных сетей доверия и на эталонных задачах достигли качества, не уступающего лучшим образцам. Частным случаем сигмоидных сетей доверия являются сети без латентных пере- менных. В этом случае обучение эффективно, поскольку нет нужды исключать ла- тентные переменных из правдоподобия. Так называемые авторегрессивные сети обобщают эту сеть доверия с полной видимостью на другие виды переменных, поми- мо бинарных, и на другие структуры условных распределений, помимо лог-линейных связей. Авторегрессивные сети описаны в разделе 20.10.7. 20.10.2. Дифференцируемые генераторные сети В основе многих порождающих моделей лежит идея использования дифференци- руемой генераторной сети. Модель преобразует примеры латентных переменных z в примеры x или в распределения примеров x, применяя дифференцируемую функ- цию g(z; θ(g)), которая обычно представляется нейронной сетью. В этот класс моделей входят автокодировщики, которые объединяют генераторную сеть с сетью вывода, порождающие состязательные сети, которые объединяют генераторную сеть с дис- криминантной, и методы, в которых генераторные сети используются сами по себе. По сути своей генераторные сети – это просто параметризованные вычислитель- ные процедуры для генерации примеров, где архитектура предоставляет семейство распределений, из которых можно производить выборку, а с помощью параметров выбирается конкретное распределение из этого семейства. Например, стандартная процедура выборки из нормального распределения со средним μ и ковариационной матрицей Σ заключается в том, чтобы подать выборку z из нормального распределения с нулевым средним и единичной ковариационной матрицей на вход очень простой генераторной сети, которая содержит всего один аф-финный слой: x = g(z) = μ + Lz, (20.71) где L определяется разложением Холеского матрицы Σ. Генераторы псевдослучайных чисел также могут использовать нелинейные преоб- разования простых распределений. Например, в методе обратного преобразования (Devroye, 2013) выбирается скаляр z из распределения U(0, 1) и применяется нели- нейное преобразование к скаляру x. В этом случае g(z) определяется как обращение интегральной функции распределения F(x) = ∫ x –∞ p(v)dv. Если мы умеем задавать p(x), интегрировать по x и обращать получающуюся функцию, то сможем произвести вы- борку из p(x) без применения машинного обучения. Чтобы сгенерировать примеры из более сложных распределений, которые трудно описать непосредственно, трудно проинтегрировать или трудно обратить результат интегрирования, мы пользуемся сетью прямого распространения для представления параметрического семейства нелинейных функций g и с помощью обучающих дан- ных выводим параметры, отбирающие нужную функцию. Можно считать, что g задает нелинейную замену переменных, преобразующую распределение z в желаемое распределение x. Напомним (см. формулу 3.47), что для обратимой дифференцируемой непрерыв- ной функции g имеет место тождество\n--- Страница 583 ---\n582  Г лубокие порождающие модели (20.72) Тем самым мы неявно определяем распределение вероятности x: (20.73) Разумеется, при некоторых g это выражение трудно вычислить, поэтому мы часто применяем непрямые методы обучения g, вместо того чтобы пытаться максимизиро- вать log p(x) непосредственно. В некоторых случаях мы используем g не для получения примера x напрямую, а для определения условного распределения x. Например, можно было бы воспользо- ваться генераторной сетью, последний слой которой состоит из сигмоидных выходов, для получения параметров распределений Бернулли: p(xi = 1 | z) = g(z)i. (20.74) В этом случае, используя g для определения p(x | z), мы определяем распределение x путем исключения z: p(x) = 𝔼zp(x | z). (20.75) Оба подхода определяют распределение pg(x) и позволяют обучать различные кри- терии pg, используя технику перепараметризации, описанную в разделе 20.9. У двух разных подходов к определению генераторных сетей – порождение пара- метров условного распределения и прямое порождение примеров – есть свои плю- сы и минусы. Если генераторная сеть определяет условное распределение x, то она способна генерировать как дискретные, так и непрерывные данные. Если же генера- торная сеть порождает примеры непосредственно, то она может генерировать только непрерывные данные (можно было бы включить дискретизацию в прямое распро- странение, но тогда модель нельзя было бы обучить с помощью обратного распро- странения). Преимущество непосредственной выборки – в том, что мы больше не ограничены просто записываемыми условными распределениями, к которым проек- тировщик мог бы легко применять алгебраические преобразования. В обоснование подходов, основанных на дифференцируемых генераторных сетях, выдвигается успешное применение градиентного спуска к дифференцируемым сетям прямого распространения для целей классификации. В контексте обучения с учите- лем глубокие сети прямого распространения, обученные градиентными методами, практически наверняка приводят к успеху при наличии достаточного числа скрытых блоков и обучающих данных. Нельзя ли перенести тот же рецепт успеха на порож- дающее моделирование? Порождающее моделирование выглядит труднее классификации или регрессии, потому что процесс обучения требует оптимизации неразрешимых критериев. В диф- ференцируемых генераторных сетях критерии неразрешимы, потому что данные не содержат одновременно входов z и выходов x генераторной сети. В случае обучения с учителем задавались входы x и выходы y, а процедуре оптимизации нужно было только обучиться, как порождать заданное отображение. В случае порождающего\n--- Страница 584 ---\nОриентированные порождающие сети  583 моделирования процедура обучения должна определить, как организовать простран- ство z полезным способом и, кроме того, как отобразить z в x. В работе Dosovitskiy et al. (2015) изучалась более простая задача – когда соответ- ствие между z и x задано. Точнее говоря, обучающие данные представляют собой сге- нерированные компьютером изображения стула. Латентные переменные z – параме-тры движка отрисовки, определяющие выбор модели стула, его положение и другие детали, влияющие на генерацию изображения. Используя эти синтетические данные, сверточная сеть может обучиться отображать z (описания содержимого изображе- ния) в x (аппроксимации отрисованных изображений). Это наводит на мысль, что со- временные дифференцируемые генераторные сети обладают достаточной емкостью, чтобы стать хорошими порождающими моделями, и что современные алгоритмы оп- тимизации вполне способны их аппроксимировать. Трудность заключается в том, как обучать генераторные сети, если значение z, соответствующее каждому x, не фикси- ровано и заранее неизвестно. В следующих разделах описано несколько подходов к обучению дифференцируе- мых генераторных сетей при наличии только обучающих примеров x. 20.10.3. Вариационные автокодировщики Вариационный автокодировщик, или V AE (Kingma, 2013; Rezende et al., 2014), – это ориентированная модель, в которой применяется обученный приближенный вывод и которую можно обучить с помощью одних лишь градиентных методов. Для порождения выборки из модели V AE сначала выбирает пример z из кодово- го распределения pmodel(z). Затем этот пример прогоняется через дифференцируе- мую генераторную сеть g(z). Наконец, производится выборка x из распределения pmodel(x, g(z)) = pmodel(x | z). Но на этапе обучения для получения z используется сеть приближенного вывода (или кодировщик) q(z | x), и тогда pmodel(x | z) рассматривается как декодирующая сеть. Главная идея вариационных автокодировщиков заключается в том, что их можно обучить с помощью максимизации вариационной нижней границы ℒ(q), ассоцииро- ванной с точкой x: ℒ(q) = 𝔼z∼q(z| x)log pmodel(z, x) + ℋ(q(z | x)) (20.76) = 𝔼z∼q(z| x) log pmodel(x | z) – DKL(q(z | x)|| pmodel(z)) (20.77) ≤ log pmodel(x). (20.78) В равенстве (20.76) первый член – не что иное, как совместное логарифмическое правдоподобие видимых и латентных переменных относительно приближенного апостериорного распределения латентных переменных (как и в EM-алгоритме, с тем исключением, что здесь используется приближенное, а не точное апостериорное распределение). Если в качестве q выбрано нормальное распределение с шумом, до- бавленным к предсказанному среднему значению, то максимизация этого энтропий- ного члена поощряет увеличение стандартного отклонения шума. В общем случае энтропийный член поощряет вариационное апостериорное распределение отдавать больше массы вероятности многим значениям z, которые могли бы породить x, а не сосредоточивать ее в одной точечной оценке наиболее вероятного значения. В равен- стве (20.77) в первом члене легко распознать логарифмическое правдоподобие ре- конструкции, встречающееся и в других автокодировщиках. Второй член пытается\n--- Страница 585 ---\n584  Г лубокие порождающие модели сблизить приближенное апостериорное распределение q(z | x) и априорное модель- ное распределение pmodel(z). В традиционных подходах к вариационному выводу и обучению q выводится с помощью алгоритма оптимизации, обычно итеративного решения уравнений не- подвижной точки (раздел 19.4). Это медленно и зачастую требует умения вычислять 𝔼z∼q log pmodel(z, x) в замкнутой форме. Основная идея вариационного автокодировщи- ка – обучить параметрический кодировщик (который иногда называют сетью вывода или моделью распознавания), порождающий параметры q. Если z – непрерывная пе- ременная, то мы тогда сможем выполнить обратное распространение через примеры z, выбранные из q(z | x) = q(z; f(x; θ)), для получения градиента по θ. В таком случае обучение состоит просто из максимизации ℒ относительно параметров кодировщика и декодера. Все математические ожидания в ℒ можно аппроксимировать с помощью выборки методом Монте-Карло. Подход на основе вариационного автокодировщика элегантный, теоретически удовлетворительный и простой в реализации. Ко всему прочему, он дает отличные результаты и входит в число передовых подходов к порождающему моделированию. Главный недостаток заключается в том, что выборки из вариационных автокодиров- щиков, обученных на изображениях, получаются несколько размытыми. Причина этого феномена до сих пор неясна. Возможно, что размытость – свойство, внутренне присущее критерию максимального правдоподобия, по которому минимизируется D KL(pdata||pmodel). Как показано, на рис. 3.6. это означает, что модель назначает высокую вероятность точкам, которые встречаются в обучающем наборе, и, возможно, каким- то другим точкам. Вот эти другие точки и могут включать размытые изображения. Отчасти причина того, что модель предпочитает назначать большую массу вероят-ности размытым изображениям, а не каким-то другим частям пространства, состоит в том, что вариационные автокодировщики, применяемые на практике, обычно име- ют нормальное распределение p model(x, g(z)). Максимизация нижней границы правдо- подобия такого распределения похожа на обучение традиционного автокодировщика по критерию среднеквадратической ошибки в том смысле, что склонна игнорировать признаки входа, которые занимают мало пикселей или приводят лишь к небольшо- му изменению яркости тех пикселей, которые занимают. Эта проблема характерна не только для V AE, но и для других порождающих моделей, которые оптимизируют логарифмическое правдоподобие или, что то же самое, D KL(pdata||pmodel) (см. Тheis et al. (2015) и Huszar (2015)). У современных моделей V AE есть еще одна неприятная проб лема – они склонны использовать лишь малое подмножество измерений z, как будто кодировщик не способен преобразовать достаточно много локальных направ-лений в пространстве входов в пространство, где маргинальное распределение совпа- дает с факторизованным априорным распределением. Инфраструктура V AE легко обобщается на разнообразные архитектуры моделей. Это важное преимущество, по сравнению с машинами Больцмана, которые требуют скрупулезно проектировать модель, чтобы избежать вычислительной неразрешимо-сти. V AE прекрасно работают с широким семейством дифференцируемых операторов. Из особо изощренных V AE упомянем модель глубокого рекуррентного вниматель- ного писателя (deep recurrent attentive writer – DRA W) (Gregor et al., 2015). В модели DRA W используются рекуррентный кодировщик и рекуррентный декодер в сочета- нии с механизмом внимания. Порождающий процесс в DRA W состоит из последова-\n--- Страница 586 ---\nОриентированные порождающие сети  585 тельного посещения небольших участков изображения и выборки значений пикселей в этих точках. V AE также можно обобщить на порождение последовательностей, если определить вариационные РНС (Chung et al., 2015b), используя рекуррентные коди- ровщик и декодер в составе инфраструктуры V AE. Выборка из традиционных РНС включает только недетерминированные операции в пространстве выходов. Вариа- ционные РНС обладают также возможностью рандомизации на потенциально более абстрактном уровне, улавливаемом латентными переменными V AE. Инфраструктура V AE обобщена также на максимизацию не только традиционной вариационной нижней границы, но и на целевую функцию автокодировщика, взве- шенного по значимости (importance-weighted autoencoder) (Burda et al., 2015): (20.79) При k = 1 эта новая целевая функция эквивалентна традиционной нижней грани- це ℒ. Но ее можно также интерпретировать как оценку истинного log pmodel(x) с ис- пользованием выборки по значимости z из вспомогательного распределения q(z | x). Кроме того, она является нижней границей log pmodel(x) и с увеличением k становится точнее. У вариационных автокодировщиков есть много интересных связей с многопред- сказательными глубокими машинами Больцмана (МП-ГМБ) и другими подходами, включающими обратное распространение по графу приближенного вывода (Good-fellow et al., 2013b; Stoyanov et al., 2011; Brakel et al., 2013). В предшествующих под- ходах требовалось, чтобы граф вычислений поставляла процедура вывода, например решение уравнений неподвижной точки среднего поля. Вариационный автокоди-ровщик определен для произвольных графов вычислений, поэтому применим к бо- лее широкому классу вероятностных моделей, т. к. необязательно ограничиваться лишь моделями, для которых разрешимы уравнения неподвижной точки среднего поля. У вариационного автокодировщика есть еще одно достоинство – он увели- чивает границу логарифмического правдоподобия модели, тогда как критерии для МП-ГМБ и родственных моделей в большей степени эвристические и почти не до- пускают вероятностной интерпретации, а лишь обеспечивают верность результатов приближенного вывода. Недостаток же V AE в том, что он обучает сеть вывода ре- шению только одной задачи: выводу z по заданному x. Более ранние методы спо- собны выполнять приближенный вывод любого подмножества переменных по лю-бому другому известному подмножеству, поскольку уравнения неподвижной точки среднего поля описывают, как разделяются параметры между графами вычислений для этих разных задач. Полезное свойство вариационного автокодировщика состоит в том, что одно- временное обучение параметрического кодировщика в сочетании с генераторной сетью побуждает модель обучиться предсказуемой системе координат, которую мо-жет запомнить кодировщик. Благодаря этому V AE становится отличным алгорит-мом обучения многообразий. На рис. 20.6 показаны примеры многообразий низкой размерности, обученных вариационным автокодировщиком. В одном из продемон- стрированных на рисунке случаев алгоритм выявил два независимых фактора вариа-тивности в изображениях лиц: угол поворота и эмоциональное выражение.\n--- Страница 587 ---\n586  Г лубокие порождающие модели Рис. 20.6  Примеры двумерных систем координат для многообразий вы- сокой размерности, обученных вариационным автокодировщиком (Kingma and Welling, 2014a). На странице можно нарисовать два измерения, поэтому мы можем составить некоторое представление о работе модели, обучив ее двумерному латентному коду, даже если полагаем, что истинная размер- ность многообразия данных гораздо выше. Показанные изображения – не примеры, взятые из обучающего набора, а изображения x, фактически сгенерированные моделью p(x | z) путем простого изменения двумерно- го «кода» z (каждому изображению соответствует свой выбор «кода» z на двумерной равномерной сетке). (Слева) Двумерное отображение много-образия лиц Фрея. Одно выявленное измерение (по горизонтали) соответ-ствует главным образом углу поворота лица, а другое (по вертикали) – эмо- циональному выражению. (Справа) Двумерное отображение многообразия MNISТ 20.10.4. Порождающие состязательные сети Порождающие состязательные сети, или ПСС (Goodfellow et al., 2014c), – еще один подход к порождающему моделированию, основанный на дифференцируемых гене- раторных сетях. В их основе лежит теоретико-игровая ситуация, когда генераторная сеть должна состязаться с противником. Генераторная сеть непосредственно порож- дает примеры x = g(z; θ(g)). Ее противник, дискриминантная сеть, пытается отличить примеры, взятые из обучающих данных, от примеров, порожденных генератором. Дискриминатор выдает значение, возвращенное функцией d(x; θ(d)), равное вероят- ности того, что x – реальный обучающий пример, а не фальшивка, выбранная из модели. Описать процесс обучения в порождающей состязательной сети проще всего как игру с нулевой суммой, в которой функция v(θ(g), θ(d)) определяет платеж дискримина- тора. Генератор получает –v(θ(g), θ(d)) в качестве своего платежа. В процессе обучения каждый игрок стремится максимизировать свой платеж, так что в пределе получаем (20.80)\n--- Страница 588 ---\nОриентированные порождающие сети  587 По умолчанию v выбирается следующим образом: v(θ(g), θ(d)) = 𝔼x∼pdata log d(x) + 𝔼x∼pmodel log(1 – d(x)). (20.81) Это заставляет дискриминатор пытаться обучиться правильно классифицировать примеры как настоящие или поддельные. Одновременно генератор пытается обма- нуть классификатор, заставив его поверить, что примеры настоящие. В пределе при- меры, созданные генератором, неотличимы от настоящих данных, и дискриминатор всегда выводит 1/2. После этого дискриминатор можно выбросить. Основной побудительный мотив для проектирования ПСС состоит в том, что про- цесс обучения не нуждается ни в приближенном выводе, ни в аппроксимации гради- ента статистической суммы. Если maxd v(g, d) выпукла относительно θ(g) (как в случае, когда оптимизация производится прямо в пространстве функций плотности вероят- ности), то процедура гарантированно сходится и асимптотически состоятельна. К сожалению, на практике обучение ПСС может оказаться трудным, когда g и d представлены нейронными сетями, а функция maxd v(g, d) не выпуклая. В работе Goodfellow (2014) отсутствие сходимости названо проблемой, которая может приве-сти к недообученности ПСС. В общем случае не гарантируется, что одновременный градиентный спуск по функциям стоимости двух игроков достигнет равновесия. Рассмотрим, к примеру, функцию ценности v(a, b) = ab, когда один игрок контро- лирует a и несет потери в сумме ab, а второй контролирует b и получает –ab. Если мы будем моделировать каждого игрока как совершающего бесконечно малые шаги в направлении градиента, так что каждый игрок уменьшает собственные затраты за счет другого игрока, то a и b выйдут на устойчивую круговую орбиту, а не достигнут точки равновесия в начале координат. Отметим, что точки равновесия в минимакс- ной игре не являются локальными минимумами v. На самом деле это точки, в ко- торых одновременно достигаются минимумы затрат обоих игроков, т. е. седловые точки v, являющиеся локальными минимумами относительно параметров первого игрока и локальными максимумами относительно параметров второго игрока. Мо- жет случиться, что оба игрока по очереди бесконечно увеличивают, а затем умень- шают v, вместо того чтобы оказаться точно в седловой точке, где ни один игрок не может уменьшить своих затрат. Неизвестно, в какой мере эта проблема несходимо- сти затрагивает ПСС. В работе Goodfellow (2014) предложена альтернативная формулировка платежей, при которой игра перестает иметь нулевую сумму. При этом ожидаемый градиент такой же, как при обучении с критерием максимального правдоподобия, если только дискриминатор оптимален. Поскольку обучение с критерием максимального правдо- подобия сходится, при такой формулировке игры ПСС тоже должна сходиться при наличии достаточного числа примеров. Увы, на практике сходимости не наблюда-ется, быть может, из-за неоптимальности дискриминатора или высокой дисперсии ожидаемого градиента. В реалистичных экспериментах наилучшей формулировкой игры ПСС является не игра с нулевой суммой и не эквивалент максимального правдоподобия, введен- ный в работе Goodfellow et al. (2014c) с эвристическим обоснованием. Оптимальные результаты получаются, когда генератор стремится увеличить логарифм вероятно-сти, что дискриминатор допустит ошибку, а не уменьшить логарифм вероятности, что дискриминатор сделает правильное предсказание. В обоснование такой форму- лировки положено одно-единственное наблюдение: при подобной стратегии произ-\n--- Страница 589 ---\n588  Г лубокие порождающие модели водная функции стоимости генератора по функции logit дискриминатора остается большой даже в ситуации, когда дискриминатор уверенно отклоняет все примеры генератора. Стабилизация обучения ПСС остается открытой проблемой. По счастью, обучение ПСС хорошо работает при тщательном выборе архитектуры и гиперпараметров мо- дели. В работе Radford et al. (2015) построена глубокая сверточная ПСС (DCGAN), показывающая отличные результаты в задачах синтеза изображений, и показано, что пространство ее латентного представления улавливает важные факторы вариатив-ности (см. рис. 15.9). На рис. 20.7 приведены примеры изображений, порожденных генератором DCGAN. Рис. 20.7  Изображения, сгенерированные ПСС, обученными на на- боре данных LSUN. (Слева) Изображения спален, сгенерированные мо-делью DCGAN, взяты из работы Radford et al. (2015). (Справа) Изображения церквей, сгенерированные моделью LAPGAN, взяты из работы Denton et al. (2015) Задачу обучения ПСС можно упростить, разбив процесс генерации на много уров- ней детализации. Возможно обучить условные ПСС (Mirza and Osindero, 2014), ко-торые производят выборку из распределения p(x | y), а не просто из маргинального распределения p(x). В работе Denton et al. (2015) показано, что последовательность условных ПСС можно обучить сначала порождать вариант изображения с очень низ- ким разрешением, а затем постепенно добавлять детали. Эта техника называется мо- делью LAPGAN, поскольку для генерации изображений разного уровня детализации применяется пирамида Лапласа. Генераторы LAPGAN способны обмануть не только дискриминантные сети, но и человека; в экспериментах испытуемые определяли до 40% изображений, сгенерированных сетью, как настоящие данные. На рис. 20.7 при-ведены примеры изображений, созданных генератором LAPGAN. Одна необычная особенность процедуры обучения ПСС заключается в том, что она может аппроксимировать распределения, назначающие нулевую вероятность обучающим примерам. Вместо максимизации логарифма вероятности отдельных точек генераторная сеть обучается очерчивать многообразие, точки которого чем-то напоминают обучающие точки. Парадоксально, но это означает, что модель может присвоить логарифму вероятности тестового набора значение минус бесконечность и тем не менее представлять многообразие, которое, на взгляд человека-наблюдателя,\n--- Страница 590 ---\nОриентированные порождающие сети  589 улавливает суть задачи генерации. Это нельзя однозначно назвать ни плюсом, ни ми- нусом. Кроме того, если мы хотим гарантировать, что генераторная сеть назначает не-нулевую вероятность всем точкам, достаточно сделать так, чтобы ее последний слой прибавлял гауссов шум ко всем сгенерированным значениям. Генераторные сети, ве-дущие себя таким образом, производят выборку из того же распределения, которое получается, когда генераторная сеть используется для параметризации среднего зна-чения условного нормального распределения. Прореживание, похоже, играет важную роль в дискриминантной сети. В частно- сти, блоки следует стохастически прореживать в процессе вычисления градиента, в направлении которого должна следовать генераторная сеть. Следование градиенту, вычисленному детерминированной версией дискриминатору с весами, поделенны- ми на два, похоже, менее эффективно. К тому же прореживание, кажется, никогда не приносит ничего плохого. Хотя инфраструктура ПСС предназначена для дифференцируемых генераторных сетей, похожие принципы можно использовать и для обучения моделей других ви- дов. Например, метод самоконтролируемого усиления (selfsupervised boosting) при- меняется для обучения генераторной ОМБ, обманывающей дискриминатор на осно-ве логистической регрессии (Welling et al., 2002). 20.10.5. Порождающие сети с сопоставлением моментов Порождающая сеть с сопоставлением моментов (Li et al., 2015; Dziugaite et al., 2015) – еще один вид порождающей модели, основанной на дифференцируемых ге- нераторных сетях. В отличие от V AE и ПСС, здесь не нужно комбинировать генера- торную сеть с какой-то другой – ни с сетью вывода, как в V AE, ни с дискриминантной сетью, как в ПСС. Порождающая сеть с сопоставлением моментов обучается методом сопоставления моментов. Его основная идея – обучить генератор так, чтобы многие статистики вы- борки из модели были максимально похожи на соответствующие статистики выбор-ки из обучающего набора. В этом контексте моментами называются математические ожидания различных степеней случайной величины. Например, первый момент – это среднее, второй – сумма квадратов и т. д. В многомерном случае каждый элемент случайного вектора может быть возведен в разные степени, поэтому моментом может быть любая величина вида 𝔼 xΠixini, (20.82) где n = [n1, n2, …, nd]⏉ – вектор неотрицательных целых чисел. На первый взгляд кажется, что этот подход вычислительно неразрешим. Напри- мер, чтобы сопоставить все моменты вида xi xj, понадобится минимизировать разность между величинами, количество которых квадратично зависит от размерности x. Бо- лее того, даже сопоставления всех первых и вторых моментов будет достаточно толь- ко для аппроксимации многомерного нормального распределения, улавливающего лишь линейные связи между значениями. А наши амбиции простираются на нейрон- ные сети, которые должны улавливать сложные нелинейные связи, так что моментов потребуется куда больше. В ПСС проблемы полного перечисления всех моментов удается избежать благодаря использованию обновляемого дискриминатора, который автоматически концентрирует внимание на той статистике, которую генераторная сеть повторяет наименее эффективно.\n--- Страница 591 ---\n590  Г лубокие порождающие модели Но вместо этого порождающую сеть с сопоставлением моментом можно обучить путем минимизации функции стоимости, называемой максимальным средним рас- хождением (maximum mean discrepancy – MMD) (Schölkopf and Smola, 2002; Gretton et al., 2012). Эта функция измеряет ошибку на первых моментах в бесконечномерном пространстве, используя неявное отображение в пространство признаков, опреде- ляемое некоторой ядерной функцией, в результате чего вычисления с бесконеч- номерными векторами становятся реальными. Стоимость MMD равна нулю тогда и только тогда, когда два сравниваемых распределения совпадают. Визуально примеры, выбранные из порождающей сети с сопоставлением момен- тов, разочаровывают. Но, к счастью, их можно улучшить, скомбинировав генератор- ную сеть с автокодировщиком. Сначала автокодировщик обучается реконструиро- вать обучаю щий набор, а затем его кодировщик используется для преобразования всего обучающего набора в кодовое пространство. После этого генераторная сеть обуча ется генерировать примеры кодов, которые можно отобразить на визуально приемлемые примеры с помощью декодера. В отличие от ПСС, функция стоимости определена только по отношению к пакету примеров, взятых одновременно из обучающего набора и генераторной сети. Невоз- можно произвести обновление в виде функции только одного обучающего примера или только одного примера из генераторной сети, поскольку моменты вычисляются как эмпирическое среднее по большому числу примеров. Если размер пакета слиш-ком мал, то MMD может дать заниженную оценку истинного различия распреде-лений, из которых произведена выборка. Для полного устранения этой проблемы пакета конечного размера вообще недостаточно, но чем больше пакет, тем меньше занижение оценки. Если размер пакета слишком велик, то процедура обучения ста-новится неприемлемо медленной, т. к. для вычисления одного малого шага градиента нужно обработать много примеров. Как и в случае ПСС, обучить генераторную сеть с помощью MMD можно даже тогда, когда она назначает нулевую вероятность обучающим примерам. 20.10.6. Сверточные порождающие сети При порождении изображений часто бывает полезно использовать генераторную сеть, включающую сверточную структуру (см., например Goodfellow et al. [2014c] или Dosovitskiy et al. [2015]). Для этого применяется «транспонированный» опера-тор свертки, описанный в разделе 9.5. Этот подход часто дает более реалистичные изображения да к тому же с меньшим числом параметров, чем при использовании полносвязных слоев без разделения параметров. В сверточных сетях для решения задач распознавания поток информации течет от изображения к верхнему слою сети, где производится обобщение, часто выражае- мое меткой класса. По мере распространения вверх по сети информация отбрасы-вается, т. к. представление изображения становится все более инвариантным к мел- ким преобразованиям. В генераторной сети все происходит наоборот. По мере того как изобра жение распространяется по сети, к нему добавляется все больше деталей, и в конечном итоге получается полноценное изображение, где присутствуют все объ- екты в требуемых положениях, с правильными текстурами и освещением. Основной механизм отбрасывания информации в сверточной сети распознавания – слой пу- линга. Но генераторная сеть должна добавлять информацию. Мы не можем вклю-чить в генераторную сеть слой инверсного пулинга, поскольку функции пулинга\n--- Страница 592 ---\nОриентированные порождающие сети  591 в большинстве своем необратимы. Есть более простая операция – увеличить про- странственный размер представления. В работе Dosovitskiy et al. (2015) применен «антипулинг», который, похоже, дает удовлетворительные результаты. Этот слой со- ответствует обращению операции max-пулинга при некоторых упрощающих усло-виях. Во-первых, шаг операции max-пулинга должен совпадать с шириной области пулинга. Во-вторых, предполагается, что максимальный элемент в каждой области пулинга расположен в левом верхнем углу. Наконец, предполагается, что все немак- симальные элементы в каждой области пулинга равны нулю. Это очень сильные и не- реалистичные предположения, но они позволяют обратить операцию max-пулинга. Операция антипулинга выделяет память для нулевого тензора, а затем копирует каж- дое входное значение с пространственной координатой i в выходное значение с про- странственной координатой i×k. Целое число k определяет размер области пулинга. Хотя предположения, на которых базируется оператор антипулинга, нереалистичны, последующие слои могут обучиться компенсировать необычный выход, поэтому при-меры, генерируемые моделью в целом, визуально приятны. 20.10.7. Авторегрессивные сети Авторегрессивные сети – это ориентированные вероятностные модели без латентных случайных переменных. Условные распределения вероятности в этих моделях пред- ставлены нейронными сетями (иногда очень простыми типа логистической регрес- сии). Модели соответствует полный граф. Совместное распределение наблюдаемых переменных в таких моделях с помощью цепного правила вероятностей разлагается в произведение условных распределений вида P(x d | xd–1, …, x1). Такие модели под на- званием «полностью видимые байесовские сети» (ПВБС, англ. FVBN) успешно ис- пользовались в различных формах, сначала с логистической регрессией в качестве каждого условного распределения (Frey, 1998), а затем с нейронными сетями со скры- тыми блоками (Bengio and Bengio, 2000b; Larochelle and Murray, 2011). В некоторых вариантах авторегрессивных сетей, например NADE (Larochelle and Murray, 2011), описанной в разделе 20.10.10, можно реализовать некий вид разделения параметров, что дает как статистический (меньше уникальных параметров), так и вычислитель- ный (меньше объем вычислений) выигрыш. Это еще один пример повторяющегося в глубоком обучении мотива повторного использования признаков. 20.10.8. Линейные авторегрессивные сети В простейшей форме авторегрессивных сетей нет ни скрытых блоков, ни разделения параметров. Каждое условное распределение P(x i | xi–1, …, x1) параметризуется как ли- нейная модель (линейная регрессия в случае вещественных данных, логистическая регрессия в случае бинарных данных и softmax-регрессия в случае дискретных дан- ных). Эта модель впервые была предложена в работе Frey (1998), в ней O(d2) пара- мет ров, где d – количество переменных в модели. Она показана на рис. 20.8. Если переменные непрерывны, то линейная авторегрессивная сеть – просто еще одна формулировка многомерного нормального распределения, улавливающего ли-нейные попарные взаимодействия между наблюдаемыми величинами. По сути своей линейные авторегрессивные сети – это обобщение методов линей- ной классификации на порождающее моделирование. Поэтому у них такие же плюсы и минусы, как у линейных классификаторов. Их точно так же можно обучать с по- мощью выпуклых функций потерь, и иногда они допускают решение в замкнутой\n--- Страница 593 ---\n592  Г лубокие порождающие модели форме (как в случае нормального распределения). Как и линейный классификатор, сама по себе модель не предлагает никакого способа увеличения емкости, так что для этой цели следует использовать такие приемы, как расширение базиса входа или трюк с ядром. Рис. 20.8  Полностью видимая байесовская сеть предсказывает i-ю пе- ременную по i – 1 предыдущим. (Сверху) Ориентированная графическая модель ПВБС. (Снизу) Граф вычислений для логистической ПВБС, в кото- рой каждое предсказание делается линейным предиктором 20.10.9. Нейронные авторегрессивные сети Нейронным авторегрессивным сетям (Bengio and Bengio, 2000a,b) соответствует та- кая же направленная слева направо графическая модель, как логистическим авторе-грессивным сетям (рис. 20.8), но внутри этой графической структуры используется другая параметризация условных распределений. Она мощнее в том смысле, что ем- кость модели можно увеличивать как угодно и, значит, аппроксимировать любое сов-местное распределение. Кроме того, новая параметризация улучшает обобщаемость благодаря принципу разделения параметров и признаков, присущему глубокому обуче нию вообще. Модель была предложена, чтобы уйти от проклятия размерности, имеющего место в традиционных табличных графических моделях с такой же струк- турой, как на рис. 20.8. В табличных дискретных вероятностных моделях каждое услов ное распределение представлено таблицей вероятностей, в которой каждой воз- можной конфигурации участвующих переменных соответствуют одна ячейка и один параметр. Использование вместо этого нейронной сети дает два преимущества: 1) параметризация каждого P(x i | xi–1, …, x1) нейронной сетью с (i – 1) × k входами и k выходами (если переменные дискретны и принимают k значений, представ- ленных унитарным кодом) позволяет оценить условную вероятность, не требуя экспоненциального числа параметров (и примеров), но при этом еще и способ- на уловить зависимости высшего порядка между случайными величинами;\n--- Страница 594 ---\nОриентированные порождающие сети  593 2) вместо отдельной нейронной сети для предсказания каждого xi направленные слева направо связи (рис. 20.9) позволяют объединить все сети в одну. Иначе говоря, это означает, что признаки скрытого слоя, вычисленные для предска- зания xi, можно повторно использовать для предсказания xi+k (k > 0). Таким об- разом, скрытые блоки организованы в группы, обладающие тем свойством, что все блоки i-й группы зависят только от входных значений x1, …, xi. Параметры, используемые для вычисления этих скрытых блоков, совместно оптимизиру-ются с целью улучшить предсказание всех переменных в последовательности. Это пример принципа повторного использования, который пронизывает все глу- бокое обучения – от архитектур рекуррентных и сверточных сетей до многоза- дачного обучения и переноса обучения. Рис. 20.9  Нейронная авторегрессивная сеть предсказывает i-ю пере- менную xi по i – 1 предыдущим, но параметризована так, что признаки (груп- пы скрытых блоков, обозначенные hi), являющиеся функциями от x1, …, xi, можно повторно использовать для предсказания всех последующих пере-менных x i+1, xi+2, …, xd Каждое P(xi | xi–1, …, x1) может представлять условное распределение, если выходы ней- ронной сети будут предсказывать параметры условного распределения xi, как обсужда- лось в разделе 6.2.1.1. Хотя первоначально авторегрессивные сети работали с чисто дис- кретными многомерными данными (с сигмоидным выходным блоком для случайных величин с распределением Бернулли или softmax-блоком для величин с категориаль- ным распределением), они естественно обобщаются на непрерывные величины или сов-местные распределения, включающие как дискретные, так и непрерывные величины. 20.10.10. NADE Нейронный авторегрессивный оцениватель плотности (neural auto-regressive density estimator – NADE) – недавно появившаяся и уже ставшая очень успешной форма нейронной авторегрессивной сети (Larochelle and Murray, 2011). Связность в ней та- кая же, как в оригинальной нейронной авторегрессивной сети из работы Bengio and Bengio (2000b), но введена дополнительная схема разделения параметров, показан-ная на рис. 20.10. Параметры скрытых блоков из разных групп j разделяются.\n--- Страница 595 ---\n594  Г лубокие порождающие модели Рис. 20.10  Нейронный авторегрессивный оцениватель плотности (NADE). Скрытые блоки организованы в группы h(j), так что только входы x1, …, xi участвуют в вычислении h(i) и предсказании P(xj | xj–1, …, x1) для j > i. NADE отличается от более ранних нейронных авторегрессивных сетей ис- пользованием специальной схемы разделения весов: значение W′j, k, i = Wk, i одинаково (на рисунке это обозначено одинаковым стилем линий для всех экземпляров повторяющегося веса) для всех весов связей, идущих из x i в k-ый блок любой группы j ≥ i. Напомним, что вектор (W1, i, W2, i, …, Wn, i) обо- значается W:, i Веса W′j, k, i связей между i-м входом xi и k-ым элементом j-ой группы скрытых блоков hk(j)(j ≥ i) разделяются между группами: W′j, k, i = Wk, i. (20.83) Остальные веса (для j < i) равны нулю.В работе Larochelle and Murray (2011) выбрана эта схема разделения, так что пря- мое распространение в NADE чем-то напоминает вычисления, которые производят- ся в выводе среднего поля для восполнения отсутствующих значений в ОМБ. Этот вывод среднего поля соответствует выполнению рекуррентной сети с разделяемыми весами, и первый шаг вывода такой же, как в NADE. Единственное отличие состоит в том, что в NADE веса связей скрытых блоков с выходными параметризуются неза- висимо от весов связей входных блоков со скрытыми. В ОМБ матрица весов связей скрытые–выходные является транспонированной к матрице весов связей входные– скрытые. Архитектуру NADE можно обобщить, так чтобы она имитировала не один, а k временных шагов рекуррентного вывода среднего поля. Этот подход называется NADE-k (Raiko et al., 2014). Как уже отмечалось, авторегрессивные сети можно распространить на обработку не- прерывных данных. Особенно эффективным и общим способом параметризации не- прерывной плотности является смесь гауссовых распределений с весами α i (коэффици- ент или априорная вероятность i-й компоненты), условными средними μi и условными дисперсиями σi2. В модели RNADE (Uria et al., 2013) такая параметризация использует- ся для обобщения NADE на вещественные значения. Как и в других сетях со смесовой плотностью, параметры этого распределения являются выходами сети, причем веро-\n--- Страница 596 ---\nВыборка из автокодировщиков  595 ятности весов компонент порождаются softmax-блоком, а дисперсии положительны. Метод стохастического градиентного спуска может оказаться численно неустойчивым из-за взаимодействий между условными средними и условными дисперсиями. Для преодоления этой трудности в работе Uria et al. (2013) на этапе обратного распростра- нения используется псевдоградиент, заменяющий градиент по среднему. В еще одном очень интересном обобщении нейронных авторегрессивных архитек- тур удалось избавиться от необходимости выбирать произвольный порядок наблю-даемых переменных (Murray and Larochelle, 2014). Идея авторегрессивной сети – обучить сеть справляться с любым порядком за счет того, что порядок выбирается случайно, а скрытым блокам передается информация о том, какие входные данные наблюдались (находятся справа от вертикальной черты в формуле условной веро- ятности), а какие считаются отсутствующими и подлежат предсказанию (находятся слева от вертикальной черты). Это хорошо, потому что позволяет весьма эффективно использовать обученную авторегрессивную сеть для решения любой проблемы вывода (т. е. предсказывать или производить выборку из распределения вероятности любо- го подмножества переменных при условии любого другого подмножества). Наконец, поскольку возможно много порядков переменных (n! для n переменных) и каждый порядок o переменных дает различные вероятности p(x | o), мы можем образовать ансамбль моделей для нескольких значений o: (20.84) Этот ансамбль моделей обычно лучше обообщается и назначает тестовому набору более высокую вероятность, чем отдельная модель, определенная одним упорядоче-нием. В той же работе авторы предлагают глубокие варианты этой архитектуры, но, к со- жалению, вычисления при этом сразу же становятся такими же дорогостоящими, как в оригинальной нейронной авторегрессивной сети (Bengio and Bengio, 2000b). Пер- вый и выходной слои все еще можно вычислить за O(nh) операций умножения-сло- жения, как в стандартном алгоритме NADE, где h – число скрытых блоков (размер групп h i на рис. 20.10 и 20.9), тогда как в работе Bengio and Bengio (2000b) таких опе- раций O(n2h). Но для других скрытых слоев сложность вычислений имеет порядок O(n2h2), если каждая «предыдущая» группа в слое l участвует в предсказании «сле- дующей» группы в слое l + 1, а n – число групп из h скрытых блоков в каждом слое. Если предположить, что i-я группа в слое l + 1 зависит только от i-й группы в слое l, как в работе Murray and Larochelle (2014), то сложность уменьшится до O(nh2), но это все равно в h раз хуже, чем в стандартном NADE. 20.11. Выборка из автокодировщиков В главе 14 мы видели, что многие виды автокодировщиков обучаются распределению данных. Существуют тесные связи между сопоставлением рейтингов, шумоподав-ляющими автокодировщиками и сжимающими автокодировщиками. Они показы- вают, что некоторые автокодировщики каким-то образом обучаются распределению данных. Но мы еще не видели, как производить выборку из таких моделей. Некоторые автокодировщики, например вариационные, явно представляют рас- пределение вероятности и допускают прямую предковую выборку. Для большинства других необходима выборка MCMC-методами.\n--- Страница 597 ---\n596  Г лубокие порождающие модели Сжимающие автокодировщики предназначены для восстановления оценки каса- тельной плоскости к многообразию данных. Это означает, что повторяющееся коди- рование и декодирование с привнесенным шумом индуцирует случайное блуждание по поверхности многообразия (Rifai et al., 2012; Mesnil et al., 2012). Эта техника диф- фузии на многообразии является разновидностью марковской цепи. Существует также более общая марковская цепь, способная производить выборку из любого шумоподавляющего автокодировщика. 20.11.1. Марковская цепь, ассоциированная с произвольным шумоподавляющим автокодировщиком В обсуждении выше остался открытым вопрос о том, какой шум привносить и где взять марковскую цепь, которая будет генерировать примеры из распределения, оце-ненного автокодировщиком. В работе Bengio et al. (2013c) показано, как построить такую марковскую цепь для обобщенных шумоподавляющих автокодировщиков. Такие автокодировщики задаются шумоподавляющим распределением для выборки из оценки чистого входа при известном зашумленном входе. Каждый шаг марковской цепи, генерирующей примеры из оценки распределения, состоит из следующих подшагов, показанных на рис. 20.11: 1. Начав с предыдущего состояния x, привнести искажающий шум, выбирая x~ из C(x~ | x). 2. Закодировать x~ в h = f(x~). 3. Декодировать h и получить параметры ω = g(h) распределения p(x | ω = g(h)) = = p(x | x~). 4. Выбрать следующее состояние x из p(x | ω = g(h)) = p(x | x~). В работе Bengio et al. (2014) показано, что если автокодировщик p(x | x~) дает со- стоятельную оценку соответствующего условного распределения, то стационарное распределение вышеуказанной марковской цепи дает состоятельную оценку (хотя и неявную) порождающего данные распределения x. 20.11.2. Фиксация и условная выборка Как и машины Больцмана, шумоподавляющие автокодировщики и их обобщения (например, описанные ниже порождающие стохастические сети) можно использо-вать для выборки из условного распределения p(x f | xo), просто зафиксировав наблю- даемые блоки xo и производя повторную выборку только свободных блоков xf при условии xo и выбранных латентных переменных (если таковые существуют). Напри- мер, МП-ГМБ можно интерпретировать как вариант шумоподавляющего автокоди-ровщика и использовать для выборки отсутствующих входов. Позднее порождаю- щие стохастические сети обобщили некоторые идеи, присутствующие в МП-ГМБ для выполнения той же операции (Bengio et al., 2014). В работе Alain et al. (2015) отмечено условие, пропущенное в предложении 1 из работы Bengio et al. (2014), а именно что оператор перехода (стохастическое отображение текущего состояния цепи в следующее) должен обладать свойством детального баланса, означающим, что марковская цепь, находящаяся в состоянии равновесия, будет оставаться в нем вне зависимости от того, выполняется оператор перехода в прямом или обратном направлении.\n--- Страница 598 ---\nВыборка из автокодировщиков  597 На рис. 20.12 показан эксперимент, состоящий в фиксации половины пикселей (правая часть изображения) и выполнении марковской цепи в другой половине. Рис. 20.11  Шаг марковской цепи, ассоциированной с обученным шумо- подавляющим автокодировщиком, которая генерирует примеры из веро- ятностной модели, неявно обученной с критерием шумоподавляющего ло- гарифмического правдоподобия. Каждый шаг состоит из: (a ) привнесения шума в состояние x с помощью искажающего процесса C, который дает x~; (b) кодирования x~ с помощью функции f и получения h = f(x~); (c) декоди- рования результата с помощью функции g с получением параметров ω для реконструкции распределения и (d) выборки нового состояния из реконст- руированного распределения p(x | ω = g(f(x~))) при известном ω. В типичном случае среднеквадратической ошибки реконструкции g(h) = xˆ, которая оце- нивает 𝔼[x | x~], искажение сводится к прибавлению гауссова шума, а выбор- ка из p(x | ω) – к повторному прибавлению гауссова шума к реконструкции xˆ. Второе прибавление шума должно соответствовать среднеквадратическим ошибкам реконструкции, а привнесенный шум – это гиперпараметр, управ- ляющий скоростью приработки и степенью сглаживания эмпирического распределения оценивателем (Vincent, 2011). В приведенном примере только условные распределения C и p – стохастические шаги (вычисление f и g детерминировано), хотя шум можно привносить и внутри автокодиров- щика, как в порождающих стохастических сетях (Bengio et al., 2014) 20.11.3. Возвратная процедура обучения Возвратная (walk-back) процедура обучения была предложена в работе Bengio et al. (2013c) как способ ускорить сходимость порождающего обучения шумоподавляю-щих автокодировщиков. Вместо выполнения одного шага реконструкции кодирова-ние-декодирование в этой процедуре попеременно выполняется несколько стохасти- ческих шагов кодирования-декодирования (как в порождающей марковской цепи). Процедура начинается с обучающего примера (как в алгоритме сопоставительного расхождения, описанном в разделе 18.2) и штрафует последние вероятностные ре- конструкции (или все реконструкции на пути). Обучение с k шагами эквивалентно (в том смысле, что достигается то же самое стационарное распределение) обучению с одним шагом, но обладает практическим преимуществом: паразитные моды вдали от данных устраняются эффективнее.\n--- Страница 599 ---\n598  Г лубокие порождающие модели Рис. 20.12  Фиксация правой половины изображения и выполнение марковской цепи путем повторной выборки только из левой половины на каждом шаге. Примеры взяты из порождающей стохастической сети, обучен ной реконструировать цифры из набора MNISТ на каждом шаге с по- мощью возвратной процедуры 20.12. Порождающие стохастические сети Порождающие стохастические сети (generative stochastic networks – GSN) (Bengio et al., 2014) – это обобщение шумоподавляющих автокодировщиков. Они включают латентные переменные h в порождающей марковской цепи, помимо видимых пере- менных (обычно обозначаемых x). GSN параметризуется двумя условными распределениями вероятности, описы- вающими один шаг марковской цепи. 1. p(x(k) | h(k)) говорит, как сгенерировать следующую видимую переменную, если известно текущее латентное состояние. Такое «распределение реконструк- ции» встречается также в шумоподавляющих автокодировщиках, ОМБ, ГСД и ГМБ. 2. p(h(k) | h(k–1), x(k–1)) говорит, как обновить латентную переменную состояния, если известны предыдущее латентное состояние и видимая переменная. Шумоподавляющие автокодировщики и GSN отличаются от классических вероят- ностных моделей (ориентированных и неориентированных) тем, что параметризуют сам порождающий процесс, а не математическую спецификацию совместного распре- деления видимых и латентных переменных. Последнее же (если существует) опре- деляется неявно как стационарное распределение порождающей марковской цепи. Условия существования стационарного распределения довольно мягкие – такие же, как в стандартных MCMC-методах (см. раздел 17.3). Это необходимые условия при- работки цепи, но существуют такие переходные распределения (например, детерми-нированные), для которых они нарушаются.\n--- Страница 600 ---\nДругие схемы порождения  599 Можно представить себе различные критерии обучения GSN. В работе Bengio et al. (2014) предложено просто использовать логарифм вероятности реконструкции для видимых блоков, как в шумоподавляющих автокодировщиках. Для этого нужно за- фиксировать x(0) = x, наблюдаемому примеру, и максимизировать вероятность порож- дения x на протяжении какого-то количества последующих временных шагов, т. е. максимизировать log p(x(k) = x | h(k)), где h(k) выбирается из цепи при условии x(0) = x. Чтобы оценить градиент log p (x(k) = x | h(k)) по другим частям модели, в работе Bengio et al. (2014) используется трюк с перепараметризацией, описанный в разделе 20.9, а для улучшения сходимости – возвратная процедура обучения из раздела 20.11.3. 20.12.1. Дискриминантные GSN Оригинальная формулировка GSN (Bengio et al., 2014) предназначалась для обуче-ния без учителя и неявного моделирования p(x) для наблюдаемых данных x, но под-ход можно модифицировать для оптимизации p(y | x). Например, в работе Zhou and Тroyanskaya (2014) GSN обобщены в этом направ- лении, для чего производилось обратное распространение логарифма вероятности реконструкции только выходных переменных, а входные оставались фиксирован- ными. Авторы успешно применили эту идею к моделированию последовательностей (вторичной структуры белков) и ввели одномерную сверточную структуру в опера- тор перехода марковской цепи. Важно не забывать, что на каждом шаге марковской цепи порождается новая последовательность для каждого слоя и что эта последова- тельность является входом для вычисления значений в других слоях (скажем, выше и ниже данного) на следующем шаге. Таким образом, марковская цепь на самом деле построена только над выходной пе- ременной (и ассоциированными скрытыми слоями верхних уровней), а входная по- следовательность служит только для обусловливания этой цепи. При этом обратное распространение позволяет модели обучиться, как входная последовательность мо-жет обусловить выходное распределение, неявно представленное марковской цепью. Следовательно, в этом случае GSN используется в контексте структурного выхода. В работе Zö hrer and Pernkopf (2014) предложена гибридная модель, объединяющая в себе обучение с учителем (как в описанной выше работе) и без учителя (как в ориги- нальной работе по GSN). Для этого просто складываются (с разными весами) стоимо-сти обучения с учителем и без учителя, т. е. логарифмы вероятности реконст рукции y и x соответственно. Такой гибридный критерий ранее предлагался для ОМБ в работе Larochelle and Bengio (2008), где авторам удалось с помощью этой схемы улучшить качество классификации. 20.13. Другие схемы порождения В описанных выше методах для порождения примеров использовалась либо MCMC-выборка, либо предковая выборка, либо та или иная их комбинация. Хотя это наи-более популярные подходы к порождающему моделированию, они ни в коем случае не единственные. В работе Sohl-Dickstein et al. (2015) для обучения порождающей модели разработа- на схема инверсии диффузии, основанная на неравновесной термодинамике. Основ- ная идея состоит в том, что у распределений вероятности, из которых мы хотим про- изводить выборку, имеется структура. Эта структура может постепенно разрушаться\n--- Страница 601 ---\n600  Г лубокие порождающие модели процессом диффузии, который изменяет распределение в сторону большей энтропии. Для формирования порождающей модели мы можем обратить этот процесс, обучив модель, которая постепенно восстанавливает структуру бесструктурного распределе-ния. Итеративно применяя процесс сближения распределения с целевым, мы можем подойти к целевому распределению. Этот подход напоминает MCMC-методы в том смысле, что для порождения выборки нужно много итераций. Однако модель опре-делена как распределение вероятности, порождаемое последним шагом цепи. В этом смысле итеративная процедура не индуцирует никакой аппроксимации. Описанный подход также очень близок к порождающей интерпретации шумоподавляющего авто- кодировщика (раздел 20.11.1). Как и шумоподавляющий автокодировщик, инверсия диффузии обучает оператор перехода, который пытается вероятностно компенсиро-вать эффект сложения с каким-то шумом. Разница в том, что инверсия диффузии требует отменить только один шаг диффузионного процесса, а не пройти назад по всему пути к чистым данным. Тем самым устраняется дилемма, присущая обычной для шумоподавляющих автокодировщиков целевой функции логарифма вероятно-сти реконструкции: при малом уровне шума обучаемый видит только конфигурации рядом с примерами данных, а при большом задача становится почти неразрешимой (поскольку шумоподавляющее распределение становится слишком сложным и мно- гомодальным). В случае же целевой функции инверсии диффузии обучаемый может более точно восстановить форму функции плотности в окрестности данных, а заодно избавиться от паразитных мод вдали от данных. Еще один подход к генерации примеров – приближенные байесовские вычисления (approximate Bayesian computation – ABC) (Rubin et al., 1984). В этом случае приме- ры отклоняются или модифицируются, так чтобы моменты выбранных функций при-меров совпадали с моментами желаемого распределения. В этой идее используются моменты примеров, как в алгоритме сопоставления моментов, но есть и различия, по- скольку здесь производится модификация самих примеров, а не обучение модели авто- матически выдавать примеры с правильными моментами. В работе Bachman and Precup (2015) показано, как идеи ABC можно использовать в контексте глубокого обуче ния для формирования траекторий MCMC в порождающих стохастических сетях. Мы полагаем, что своего открытия ждет много других подходов к порождающему моделированию. 20.14. Оценивание порождающих моделей Исследователям, изучающим порождающие модели, часто бывает необходимо срав-нить две модели, обычно чтобы продемонстрировать, что новая модель лучше улав-ливает некоторое распределение, чем предыдущие. Это может оказаться непростой задачей. Нередко точно вычислить логарифм ве- роятности данных в модели невозможно, приходится довольствоваться только ап- проксимацией. В таких случаях важно отчетливо понимать и сообщать аудитории, что именно измеряется. Предположим, к примеру, что мы вычисляем стохастическую оценку логарифмического правдоподобия модели A и детерминированную нижнюю границу логарифмического правдоподобия модели B. Если модель A получила боль-ше баллов, чем модель B, то какая из них лучше? Если нас интересует, какая модель дает лучшее внутреннее представление распределения, то ответить на этот вопрос нельзя, если только нет какого-то способа узнать, насколько точна нижняя граница\n--- Страница 602 ---\nОценивание порождающих моделей  601 для модели B. Если же нам интересно практическое использование модели, например для обнаружения аномалий, то будет справедливо судить модели на основе критерия, относящегося к конкретной задаче, например по результатам ранжирования тесто- вых примеров с помощью таких критериев, как точность и полнота. Еще одна тонкость оценивания порождающих моделей состоит в том, что выработ- ка критериев оценки сама по себе представляет трудную научную задачу. Может ока-заться очень сложно установить, что сравнение моделей производится справедливо. Предположим, к примеру, что мы используем метод AIS для получения оценки log Z с целью вычислить log p~(x) – log Z для новой придуманной нами модели. Вычисли- тельно экономная реализация AIS может не найти несколько мод модельного рас-пределения и дать заниженную оценку Z, что приведет к завышенной оценке log p(x). Таким образом, трудно сказать, что стало причиной высокой оценки правдоподобия: хорошая модель или плохая реализация AIS. В других разделах машинного обучения обычно допускается некоторая вариатив- ность на этапе предобработки данных. Например, при сравнении верности алгоритмов распознавания объектов обычно разрешается производить предобработку входных изображений немного по-разному в соответствии с требованиями, предъявляемыми каждым алгоритмом. Порождающее моделирование устроено иначе – любые изме- нения в способе предобработки, пусть даже совсем незначительные и незаметные, абсолютно недопустимы. Всякое изменение входных данных изменяет подлежащее выявлению распределение и кардинальным образом меняет задачу. Например, умно- жение входных данных на 0.1 искусственно повышает правдоподобие в 10 раз. Проблемы предобработки часто возникают при проверке порождающих моделей на эталонном наборе данных MNISТ, одном из самых популярных для тестирования таких моделей. В этом наборе есть только полутоновые изображения. В одних моде- лях изображения из MNISТ рассматриваются как точки в вещественном векторном пространстве, в других – как бинарные изображения. А в третьих полутоновые зна- чения яркости трактуются как вероятности бинарных примеров. Важно сравнивать вещественные модели только с другими вещественными моделями, а бинарные – только с другими бинарными. В противном случае правдоподобие будет измеряться в разных пространствах. Для бинарных моделей логарифмическое правдоподобие не может быть больше нуля, тогда как в вещественных оно не ограничено сверху, бу- дучи результатом измерения плотности. При сравнении бинарных моделей важно, чтобы применялся один и тот же вид бинаризации. Например, для сопоставления полутоновому пикселю значения 0 или 1 мы можем сравнить его с порогом 0.5 или произвести случайную выборку, в которой вероятность получить 1 определяется яр- костью пикселя. Если используется случайная бинаризация, то мы можем бинаризо-вать весь набор данных сразу или выбрать разные случайные примеры для каждого шага обуче ния, а затем произвести множественную выборку для оценивания. Все три схемы дадут совершенно разные значения правдоподобия, а при сравнении разных моделей важно, чтобы использовалась одна и та же схема бинаризации для обучения и оценивания. На самом деле при выполнении единственного шага случайной бина- ризации обычно создается общий файл, содержащий ее результаты, чтобы исключить расхождения из-за различных исходов шага бинаризации. Поскольку способность порождать реалистичные примеры из распределения дан- ных – одна из целей порождающей модели, на практике такие модели часто оцени- вают, визуально исследуя примеры. Лучше, когда это делает не сам исследователь,\n--- Страница 603 ---\n602  Г лубокие порождающие модели а участник эксперимента, которому неизвестен источник происхождения примеров (Denton et al., 2015). К сожалению, бывает так, что очень плохая вероятностная мо- дель порождает очень хорошие примеры. Общепринятый способ проверить, что мо- дель не просто копирует какие-то обучающие примеры, иллюстрируется на рис. 16.1. Идея в том, чтобы для некоторых порожденных примеров показать их ближайших соседей в обучающем наборе согласно евклидову расстоянию в пространстве x. Эта проверка направлена на то, чтобы выявить случай, когда модель переобучена и прос- то воспроизводит обучающие примеры. Может даже случиться, что модель одновре-менно переобучена и недообучена и тем не менее порождает примеры, которые по отдельности выглядят отлично. Представьте себе порождающую модель, обученную на изображениях собак и кошек, которая просто научилась воспроизводить изобра- жения собак. Очевидно, что такая модель переобучена, поскольку она не порожда-ет изображения, которых не было в обучающем наборе, но она также недообучена, т. к. назначает нулевую вероятность обучающим изображениям кошек. Тем не менее человек сочтет, что каждое отдельное изображение собаки высокого качества. Это простой пример – наблюдатель, просмотревший много примеров, заметит отсутствие кошек. В более реалистичных условиях порождающая модель, обученная на данных с десятками тысяч мод, может проигнорировать небольшое число мод, и человеку бу- дет нелегко заметить, что какая-то вариация отсутствует. Поскольку визуальное качество примеров – ненадежный путеводитель, мы часто оцениваем также логарифмическое правдоподобие, которое модель назначает дан-ным, если это вычислительно осуществимо. К сожалению, в некоторых случаях прав- доподобие не измеряет интересующих нас атрибутов модели. Например, на наборе данных MNISТ вещественная модель может получить произвольно высокое прав-доподобие, если назначит произвольно низкую дисперсию пикселям фона, которые никогда не изменяются. Модели и алгоритмы, которые обнаруживают такие постоян- ные признаки, могут быть вознаграждены не по заслугам, потому что особой пользы в этом свойстве нет. Потенциальная возможность достичь стоимости, стремящейся к минус бесконечности, существует для любого вида задач с критерием максималь- ного правдоподобия с вещественными значениями, но особенно от этого страдают порождающие модели, оцениваемые на наборе MNISТ, потому что количество три-виально предсказываемых выходных значений очень велико. Поэтому возникает на-стоятельная необходимость в разработке других способов оценивания порождающих моделей. В работе Тheis et al. (2015) приведен обзор многих проблем, возникающих при оценивании порождающих моделей, включающий и описанные выше соображения. Авторы подчеркивают, что порождающие модели применяются для самых разных целей и что выбор метрики должен соответствовать назначению модели. Так, одни порождающие модели лучше назначают высокую вероятность самым реалистичным точкам, тогда как другие преуспевают в редком назначении высокой вероятности не- реалистичным точкам. Такие различия могут быть связаны с тем, проектировалась ли модель для минимизации D KL(pdata||pmodel) или DKL(pmodel||pdata), как показано на рис. 3.6. К сожалению, даже если ограничиться использованием только метрик, отвечающих задаче, у всех известных в настоящее время метрик имеются серьезные недостатки. Поэтому одно из самых важных направлений исследований в области порождающего моделирования – не улучшение самих моделей, а проектирование новых методов из- мерения успеха.\n--- Страница 604 ---\nЗаключение  603 20.15. Заключение Обучение порождающих моделей со скрытыми блоками – эффективный способ на- учить модель понимать мир, представленный обучающими данными. Обучившись распределению pmodel(x) и представлению pmodel(h | x), порождающая модель может да- вать ответы на многие вопросы о связях между входными переменными в x и предла- гать другие способы представления x путем вычисления математических ожиданий h на разных слоях иерархии. Порождающие модели выполняют обещание снабдить системы ИИ инфраструктурой для понимания многообразных интуитивных концеп-ций и наделить их возможностью рассуждать об этих концепциях в условиях неопре- деленности. Мы надеемся, что читатели этой книги придумают новые способы повы-сить эффективность этих подходов и пойдут дальше по пути понимания принципов, лежащих в основе обучения и интеллекта.\n--- Страница 605 ---\nСписок литературы 1. Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Da- vis, A., Dean, J., Devin, M., Ghemawat, S., Goodfellow, I., Harp, A., Irving, G., Isard, M., Jia, Y., Jozefowicz, R., Kaiser, L., Kudlur, M., Levenberg, J., Manе, D., Monga, R., Moore, S., Murray, D., Olah, C., Schuster, M., Shlens, J., Steiner, B., Sutskever, I., Тalwar, K., Тucker, P., Vanhoucke, V., Vasudevan, V., Viеgas, F., Vinyals, O., Warden, P., Wattenberg, M., Wicke, M., Yu, Y., and Zheng, X. (2015). Тen sor Flow: Large-scale machine learning on heterogeneous systems. Software available from tensorflow.org. 2. Ackley, D. H., Hinton, G. E., and Sejnowski, Т. J. (1985). A learning algorithm for Boltzmann machines. Cognitive Science, 9, 147–169. 3. Alain, G. and Bengio, Y. (2013). What regularized auto-encoders learn from the data generating distribution. In ICLR’2013, arXiv:1211.4246 . 4. Alain, G., Bengio, Y., Yao, L., Éric Тhibodeau-Laufer, Y osinski, J., and Vincent, P. (2015). GSNs: Generative stochastic networks. arXiv:1503.05571. 5. Allen, R. B. (1987). Several studies on natural language and back-propagation. In IEEE First International Conference on Neural Networks, volume 2, pages 335–341, San Diego. http://boballen.info/RBA/PAPERS/NL-BP/nl-bp.pdf. 6. Anderson, E. (1935). Тhe Irises of the Gaspе Peninsula. Bulletin of the American Iris Society, 59, 2–5. 7. Ba, J., Mnih, V., and Kavukcuoglu, K. (2014). Multiple object recognition with visual attention. arXiv:1412.7755 . 8. Bachman, P. and Precup, D. (2015). Variational generative stochastic networks with collaborative shaping. In Proceedings of the 32nd International Conference on Machine Learning, ICML 2015, Lille, France, 6–11 July 2015, pages 1964–1972. 9. Bacon, P.-L., Bengio, E., Pineau, J., and Precup, D. (2015). Conditional computation in neural networks using a decision-theoretic approach. In 2nd Multidisciplinary Conference on Reinforcement Learning and Decision Making (RLDM 2015). 10. Bagnell, J. A. and Bradley, D. M. (2009). Differentiable sparse coding. In D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, Advances in Neural Information Processing Systems 21 (NIPS’08), pages 113–120. 11. Bahdanau, D., Cho, K., and Bengio, Y. (2015). Neural machine translation by jointly learning to align and translate. In ICLR’2015, arXiv:1409.0473. 12. Bahl, L. R., Brown, P., de Souza, P. V., and Mercer, R. L. (1987). Speech recognition with continuous-parameter hidden Markov models. Computer, Speech and Language, 2, 219–234. 13. Baldi, P. and Hornik, K. (1989). Neural networks and principal component analysis: Learning from examples without local minima. Neural Networks, 2, 53–58. 14. Baldi, P., Brunak, S., Frasconi, P., Soda, G., and Pollastri, G. (1999). Exploiting the past and the future in protein secondary structure prediction. Bioinformatics, 15(11), 937–946. 15. Baldi, P., Sadowski, P., and Whiteson, D. (2014). Searching for exotic particles in high-energy physics with deep learning. Nature communications, 5. 16. Ballard, D. H., Hinton, G. E., and Sejnowski, Т. J. (1983). Parallel vision computation. Nature.\n--- Страница 606 ---\nЗаключение  605 17. Barlow, H. B. (1989). Unsupervised learning. Neural Computation, 1, 295–311. 18. Barron, A. E. (1993). Universal approximation bounds for superpositions of a sigmoidal function. IEEE Тrans. on Information Тheory, 39, 930–945. 19. Bartholomew, D. J. (1987). Latent variable models and factor analysis. Oxford University Press. 20. Basilevsky, A. (1994). Statistical Factor Analysis and Related Methods: Тheory and Applications. Wiley. 21. Bastien, F., Lamblin, P., Pascanu, R., Bergstra, J., Goodfellow, I. J., Bergeron, A., Bou-chard, N., and Bengio, Y. (2012). Тheano: new features and speed improvements. Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop. 22. Basu, S. and Christensen, J. (2013). Тeaching classification boundaries to humans. In AAAI’2013. 23. Baxter, J. (1995). Learning internal representations. In Proceedings of the 8 th In- ternational Conference on Computational Learning Тheory (COLТ’95), pages 311–320, Santa Cruz, California. ACM Press. 24. Bayer, J. and Osendorfer, C. (2014). Learning stochastic recurrent networks. ArXiv e-prints. 25. Becker, S. and Hinton, G. (1992). A self-organizing neural network that discovers surfaces in random-dot stereograms. Nature, 355, 161–163. 26. Behnke, S. (2001). Learning iterative image reconstruction in the neural abstraction pyramid. Int. J. Computational Intelligence and Applications, 1(4), 427–438. 27. Beiu, V., Quintana, J. M., and Avedillo, M. J. (2003). VLSI implementations of thre-shold logic-a comprehensive survey. Neural Networks, IEEE Тransactions on, 14(5), 1217–1243. 28. Belkin, M. and Niyogi, P. (2002). Laplacian eigenmaps and spectral techniques for embedding and clustering. In Т. Dietterich, S. Becker, and Z. Ghahramani, editors, Advances in Neural Information Processing Systems 14 (NIPS’01), Cambridge, MA. MIТ Press. 29. Belkin, M. and Niyogi, P. (2003). Laplacian eigenmaps for dimensionality reduction and data representation. Neural Computation, 15(6), 1373–1396. 30. Bengio, E., Bacon, P.-L., Pineau, J., and Precup, D. (2015a). Conditional computation in neural networks for faster models. arXiv:1511.06297. 31. Bengio, S. and Bengio, Y. (2000a). Тaking on the curse of dimensionality in joint distributions using neural networks. IEEE Тransactions on Neural Networks, special issue on Data Mining and Knowledge Discovery, 11(3), 550–557. 32. Bengio, S., Vinyals, O., Jaitly, N., and Shazeer, N. (2015b). Scheduled sampling for sequence prediction with recurrent neural networks. Тechnical report, arXiv:1506.03099. 33. Bengio, Y. (1991). Artificial Neural Networks and their Application to Sequence Recognition. Ph.D. thesis, McGill University, (Computer Science), Montreal, Canada. 34. Bengio, Y. (2000). Gradient-based optimization of hyperparameters. Neural Compu-tation, 12(8), 1889–1900. 35. Bengio, Y. (2002). New distributed probabilistic language models. Тechnical Report 1215, Dept. IRO, Universitе de Montrеal. 36. Bengio, Y. (2009). Learning deep architectures for AI. Now Publishers. 37. Bengio, Y. (2013). Deep learning of representations: looking forward. In Statistical Language and Speech Processing, volume 7978 of Lecture Notes in Computer Science, pages 1–37. Springer, also in arXiv at http://arxiv.org/abs/1305.0445.\n--- Страница 607 ---\n606  Список литературы 38. Bengio, Y. (2015). Early inference in energy-based models approximates back- propagation. Тechnical Report arXiv:1510.02777, Universite de Montreal. 39. Bengio, Y. and Bengio, S. (2000b). Modeling high-dimensional discrete data with multilayer neural networks. In NIPS 12, pages 400–406. MIТ Press. 40. Bengio, Y. and Delalleau, O. (2009). Justifying and generalizing contrastive divergence. Neural Computation, 21(6), 1601–1621. 41. Bengio, Y. and Grandvalet, Y. (2004). No unbiased estimator of the variance of k-fold cross-validation. In S. Тhrun, L. Saul, and B. Schölkopf, editors, Advances in Neural Information Processing Systems 16 (NIPS’03), Cambridge, MA. MIТ Press, Cambridge. 42. Bengio, Y. and LeCun, Y. (2007). Scaling learning algorithms towards AI. In Large Scale Kernel Machines. 43. Bengio, Y. and Monperrus, M. (2005). Non-local manifold tangent learning. In L. Saul, Y. Weiss, and L. Bottou, editors, Advances in Neural Information Processing Systems 17 (NIPS’04), pages 129–136. MIТ Press. 44. Bengio, Y. and Sеnеcal, J.-S. (2003). Quick training of probabilistic neural nets by importance sampling. In Proceedings of AISТAТS 2003. 45. Bengio, Y. and Sеnеcal, J.-S. (2008). Adaptive importance sampling to accelerate training of a neural probabilistic language model. IEEE Тrans. Neural Networks, 19(4), 713–722. 46. Bengio, Y., De Mori, R., Flammia, G., and Kompe, R. (1991). Phonetically motivated acoustic parameters for continuous speech recognition using artificial neural networks. In Proceedings of EuroSpeech’91. 47. Bengio, Y., De Mori, R., Flammia, G., and Kompe, R. (1992). Neural network-Gaussian mixture hybrid for speech recognition or density estimation. In NIPS 4, pages 175–182. Morgan Kaufmann. 48. Bengio, Y., Frasconi, P., and Simard, P. (1993). Тhe problem of learning long-term dependencies in recurrent networks. In IEEE International Conference on Neural Networks, pages 1183–1195, San Francisco. IEEE Press. (invited paper). 49. Bengio, Y., Simard, P., and Frasconi, P. (1994). Learning long-term dependencies with gradient descent is difficult. IEEE Тr. Neural Nets. 50. Bengio, Y., Latendresse, S., and Dugas, C. (1999). Gradient-based learning of hyper-parameters. Learning Conference, Snowbird. 51. Bengio, Y., Ducharme, R., and Vincent, P. (2001). A neural probabilistic language model. In Т. K. Leen, Т. G. Dietterich, and V. Тresp, editors, NIPS’2000, pages 932–938. MIТ Press. 52. Bengio, Y., Ducharme, R., Vincent, P., and Jauvin, C. (2003). A neural probabilistic language model. JMLR, 3, 1137–1155. 53. Bengio, Y., Le Roux, N., Vincent, P., Delalleau, O., and Marcotte, P. (2006a). Convex neural networks. In NIPS’2005, pages 123–130. 54. Bengio, Y., Delalleau, O., and Le Roux, N. (2006b). Тhe curse of highly variable functions for local kernel machines. In NIPS’2005. 55. Bengio, Y., Larochelle, H., and Vincent, P. (2006c). Non-local manifold Parzen windows. In NIPS’2005. MIТ Press. 56. Bengio, Y., Lamblin, P., Popovici, D., and Larochelle, H. (2007). Greedy layer-wise training of deep networks. In NIPS’2006. 57. Bengio, Y., Louradour, J., Collobert, R., and Weston, J. (2009). Curriculum learning. In ICML’09.\n--- Страница 608 ---\nЗаключение  607 58. Bengio, Y., Mesnil, G., Dauphin, Y., and Rifai, S. (2013a). Better mixing via deep representations. In ICML’2013. 59. Bengio, Y., Lеonard, N., and Courville, A. (2013b). Estimating or propagating gradients through stochastic neurons for conditional computation. arXiv:1308.3432. 60. Bengio, Y., Yao, L., Alain, G., and Vincent, P. (2013c). Generalized denoising auto-encoders as generative models. In NIPS’2013. 61. Bengio, Y., Courville, A., and Vincent, P. (2013d). Representation learning: A review and new perspectives. IEEE Тrans. Pattern Analysis and Machine Intelligence (PAMI), 35(8), 1798–1828. 62. Bengio, Y., Тhibodeau-Laufer, E., Alain, G., and Y osinski, J. (2014). Deep generative stochastic networks trainable by backprop. In ICML’2014. 63. Bennett, C. (1976). Efficient estimation of free energy differences from Monte Carlo data. Journal of Computational Physics, 22(2), 245–268. 64. Bennett, J. and Lanning, S. (2007). Тhe Netflix prize. 65. Berger, A. L., Della Pietra, V. J., and Della Pietra, S. A. (1996). A maximum entropy approach to natural language processing. Computational Linguistics, 22, 39–71. 66. Berglund, M. and Raiko, Т. (2013). Stochastic gradient estimate variance in contrastive divergence and persistent contrastive divergence. CoRR, abs/1312.6002. 67. Bergstra, J. (2011). Incorporating Complex Cells into Neural Networks for Pattern Classification. Ph.D. thesis, Universitе de Montrеal. 68. Bergstra, J. and Bengio, Y. (2009). Slow, decorrelated features for pretraining complex cell-like networks. In NIPS’2009. 69. Bergstra, J. and Bengio, Y. (2012). Random search for hyper-parameter optimization. J. Machine Learning Res., 13, 281–305. 70. Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Тuri-an, J., Warde-Farley, D., and Bengio, Y. (2010). Тheano: a CPU and GPU math expression compiler. In Proc. SciPy. 71. Bergstra, J., Bardenet, R., Bengio, Y., and Kеgl, B. (2011). Algorithms for hyper-parameter optimization. In NIPS’2011. 72. Berkes, P. and Wiskott, L. (2005). Slow feature analysis yields a rich repertoire of complex cell properties. Journal of Vision, 5(6), 579–602. 73. Bertsekas, D. P. and Тsitsiklis, J. (1996). Neuro-Dynamic Programming. Athena Scientific. 74. Besag, J. (1975). Statistical analysis of non-lattice data. Тhe Statistician, 24(3), 179–195. 75. Bishop, C. M. (1994). Mixture density networks. 76. Bishop, C. M. (1995a). Regularization and complexity control in feed-forward net-works. In Proceedings International Conference on Artificial Neural Networks ICANN’95, volume 1, page 141–148. 77. Bishop, C. M. (1995b). Тraining with noise is equivalent to Тikhonov regularization. Neural Computation, 7(1), 108–116. 78. Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer. 79. Blum, A. L. and Rivest, R. L. (1992). Тraining a 3-node neural network is NP-complete. 80. Blumer, A., Ehrenfeucht, A., Haussler, D., and Warmuth, M. K. (1989). Learnability and the Vapnik–Chervonenkis dimension. Journal of the ACM, 36(4), 929–865. 81. Bonnet, G. (1964). Тransformations des signaux alеatoires à travers les systèmes non linеaires sans mеmoire. Annales des Т еlеcommunications, 19(9–10), 203–220.\n--- Страница 609 ---\n608  Список литературы 82. Bordes, A., Weston, J., Collobert, R., and Bengio, Y. (2011). Learning structured embeddings of knowledge bases. In AAAI 2011. 83. Bordes, A., Glorot, X., Weston, J., and Bengio, Y. (2012). Joint learning of words and meaning representations for open-text semantic parsing. AISТAТS’2012. 84. Bordes, A., Glorot, X., Weston, J., and Bengio, Y. (2013a). A semantic matching energy function for learning with multi-relational data. Machine Learning: Special Issue on Learning Semantics. 85. Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., and Yakhnenko, O. (2013b). Тranslating embeddings for modeling multi-relational data. In C. Burges, L. Bottou, M.Welling, Z. Ghahramani, and K.Weinberger, editors, Advances in Neural Information Processing Systems 26, pages 2787–2795. Curran Associates, Inc. 86. Bornschein, J. and Bengio, Y. (2015). Reweighted wake-sleep. In ICLR’2015, arXiv:1406.2751. 87. Bornschein, J., Shabanian, S., Fischer, A., and Bengio, Y. (2015). Тraining bidirectional Helmholtz machines. Тechnical report, arXiv:1506.03877. 88. Boser, B. E., Guyon, I. M., and Vapnik, V. N. (1992). A training algorithm for optimal margin classifiers. In COLТ ’92: Proceedings of the fifth annual workshop on Com-putational learning theory, pages 144–152, New Y ork, NY, USA. ACM. 89. Bottou, L. (1998). Online algorithms and stochastic approximations. In D. Saad, editor, Online Learning in Neural Networks. Cambridge University Press, Cambridge, UK. 90. Bottou, L. (2011). From machine learning to machine reasoning. Тechnical report, arXiv.1102.1808. 91. Bottou, L. (2015). Multilayer neural networks. Deep Learning Summer School. 92. Bottou, L. and Bousquet, O. (2008). Тhe tradeoffs of large scale learning. In NIPS’2008. 93. Boulanger-Lewandowski, N., Bengio, Y., and Vincent, P. (2012). Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music gene-ration and transcription. In ICML’12. 94. Boureau, Y., Ponce, J., and LeCun, Y. (2010). A theoretical analysis of feature pooling in vision algorithms. In Proc. International Conference on Machine learning (ICML’10). 95. Boureau, Y., Le Roux, N., Bach, F., Ponce, J., and LeCun, Y. (2011). Ask the locals: multi-way local pooling for image recognition. In Proc. International Conference on Computer Vision (ICCV’11). IEEE. 96. Bourlard, H. and Kamp, Y. (1988). Auto-association by multilayer perceptrons and singular value decomposition. Biological Cybernetics, 59, 291–294. 97. Bourlard, H. and Wellekens, C. (1989). Speech pattern discrimination and multi-layered perceptrons. Computer Speech and Language, 3, 1–19. 98. Boyd, S. and Vandenberghe, L. (2004). Convex Optimization. Cambridge University Press, New Y ork, NY, USA. 99. Brady, M. L., Raghavan, R., and Slawny, J. (1989). Back-propagation fails to separate where perceptrons succeed. IEEE Тransactions on Circuits and Systems, 36, 665–674. 100. Brakel, P., Stroobandt, D., and Schrauwen, B. (2013). Тraining energy-based models for time-series imputation. Journal of Machine Learning Research, 14, 2771–2797. 101. Brand, M. (2003). Charting a manifold. In NIPS’2002, pages 961–968. MIТ Press. 102. Breiman, L. (1994). Bagging predictors. Machine Learning, 24(2), 123–140. 103. Breiman, L., Friedman, J. H., Olshen, R. A., and Stone, C. J. (1984). Classification and Regression Тrees. Wadsworth International Group, Belmont, CA.\n--- Страница 610 ---\nЗаключение  609 104. Bridle, J. S. (1990). Alphanets: a recurrent ‘neural’ network architecture with a hidden Markov model interpretation. Speech Communication, 9(1), 83–92. 105. Briggman, K., Denk, W., Seung, S., Helmstaedter, M. N., and Тuraga, S. C. (2009). Maximin affinity learning of image segmentation. In NIPS’2009, pages 1865–1873. 106. Brown, P. F., Cocke, J., Pietra, S. A. D., Pietra, V. J. D., Jelinek, F., Lafferty, J. D., Mercer, R. L., and Roossin, P. S. (1990). A statistical approach to machine translation. Computational linguistics, 16(2), 79–85. 107. Brown, P. F., Pietra, V. J. D., DeSouza, P. V., Lai, J.C., and Mercer, R. L. (1992). Class-based n-gram models of natural language. Computational Linguistics, 18, 467–479. 108. Bryson, A. and Ho, Y. (1969). Applied optimal control: optimization, estimation, and control. Blaisdell Pub. Co. 109. Bryson, Jr., A. E. and Denham, W. F. (1961). A steepest-ascent method for solving optimum programming problems. Тechnical Report BR-1303, Raytheon Company, Missle and Space Division. 110. Buciluǎ, C., Caruana, R., and Niculescu-Mizil, A. (2006). Model compression. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 535–541. ACM. 111. Burda, Y., Grosse, R., and Salakhutdinov, R. (2015). Importance weighted auto-encoders. arXiv preprint arXiv:1509.00519. 112. Cai, M., Shi, Y., and Liu, J. (2013). Deep maxout neural networks for speech recog-nition. In Automatic Speech Recognition and Understanding (ASRU), 2013 IEEE Workshop on, pages 291–296. IEEE. 113. Carreira-Perpiñan, M. A. and Hinton, G. E. (2005). On contrastive divergence learning. In R. G. Cowell and Z. Ghahramani, editors, Proceedings of the Тenth International Workshop on Artificial Intelligence and Statistics (AISТAТS’05), pages 33–40. Society for Artificial Intelligence and Statistics. 114. Caruana, R. (1993). Multitask connectionist learning. In Proc. 1993 Connectionist Models Summer School, pages 372–379. 115. Cauchy, A. (1847). Mеthode gеnеrale pour la rеsolution de systèmes d’еquations simultanеes. In Compte rendu des sеances de l’acadеmie des sciences, pages 536–538. 116. Cayton, L. (2005). Algorithms for manifold learning. Тechnical Report CS2008-0923, UCSD. 117. Chandola, V., Banerjee, A., and Kumar, V. (2009). Anomaly detection: A survey. ACM computing surveys (CSUR), 41(3), 15. 118. Chapelle, O., Weston, J., and Schölkopf, B. (2003). Cluster kernels for semi-super-vised learning. In S. Becker, S. Тhrun, and K. Obermayer, editors, Advances in Neural Information Processing Systems 15 (NIPS’02), pages 585–592, Cambridge, MA. MIТ Press. 119. Chapelle, O., Schölkopf, B., and Zien, A., editors (2006). Semi-Supervised Learning. MIТ Press, Cambridge, MA. 120. Chellapilla, K., Puri, S., and Simard, P. (2006). High Performance Convolutional Neural Networks for Document Processing. In Guy Lorette, editor, Тenth Inter-national Workshop on Frontiers in Handwriting Recognition, La Baule (France). Universitе de Rennes 1, Suvisoft. http://www.suvisoft.com. 121. Chen, B., Тing, J.-A., Marlin, B. M., and de Freitas, N. (2010). Deep learning of invariant spatio-temporal features from video. NIPS*2010 Deep Learning and Unsupervised Feature Learning Workshop.\n--- Страница 611 ---\n610  Список литературы 122. Chen, S. F. and Goodman, J. Т. (1999). An empirical study of smoothing techniques for language modeling. Computer, Speech and Language, 13(4), 359–393. 123. Chen, Т., Du, Z., Sun, N., Wang, J., Wu, C., Chen, Y., and Тemam, O. (2014a). DianNao: A small-footprint high-throughput accelerator for ubiquitous machine-learning. In Proceedings of the 19th international conference on Architectural support for programming languages and operating systems, pages 269–284. ACM. 124. Chen, Т., Li, M., Li, Y., Lin, M., Wang, N., Wang, M., Xiao, Т., Xu, B., Zhang, C., and Zhang, Z. (2015). MXNet: A flexible and efficient machine learning library for heterogeneous distributed systems. arXiv preprint arXiv:1512.01274. 125. Chen, Y., Luo, Т., Liu, S., Zhang, S., He, L., Wang, J., Li, L., Chen, Т., Xu, Z., Sun, N., et al. (2014b). DaDianNao: A machine-learning supercomputer. In Microarchitecture (MICRO), 2014 47th Annual IEEE/ACM International Symposium on, pages 609–622. IEEE. 126. Chilimbi, Т., Suzue, Y., Apacible, J., and Kalyanaraman, K. (2014). Project Adam: Building an efficient and scalable deep learning training system. In 11 th USENIX Symposium on Operating Systems Design and Implementation (OSDI’14). 127. Cho, K., Raiko, Т., and Ilin, A. (2010). Parallel tempering is efficient for learning restricted Boltzmann machines. In IJCNN’2010. 128. Cho, K., Raiko, Т., and Ilin, A. (2011). Enhanced gradient and adaptive learning rate for training restricted Boltzmann machines. In ICML’2011, pages 105–112. 129. Cho, K., van Merriënboer, B., Gulcehre, C., Bougares, F., Schwenk, H., and Bengio, Y. (2014a). Learning phrase representations using RNN encoder-decoder for statistical machine translation. In Proceedings of the Empiricial Methods in Natural Language Processing (EMNLP 2014). 130. Cho, K., Van Merriënboer, B., Bahdanau, D., and Bengio, Y. (2014b). On the pro-perties of neural machine translation: Encoder-decoder approaches. ArXiv e-prints, abs/1409.1259. 131. Choromanska, A., Henaff, M., Mathieu, M., Arous, G. B., and LeCun, Y. (2014). Тhe loss surface of multilayer networks. 132. Chorowski, J., Bahdanau, D., Cho, K., and Bengio, Y. (2014). End-to-end con-tinuous speech recognition using attention-based recurrent NN: First results. arXiv:1412.1602. 133. Chrisman, L. (1991). Learning recursive distributed representations for holistic computation. Connection Science, 3(4), 345–366. http://repository.cmu.edu/cgi/ viewcontent.cgi?article=3061&context=compsci. 134. Christianson, B. (1992). Automatic Hessians by reverse accumulation. IMA Journal of Numerical Analysis, 12(2), 135–150. 135. Chrupala, G., Kadar, A., and Alishahi, A. (2015). Learning language through pictures. arXiv 1506.03694. 136. Chung, J., Gulcehre, C., Cho, K., and Bengio, Y. (2014). Empirical evaluation of gated recurrent neural networks on sequence modeling. NIPS’2014 Deep Learning workshop, arXiv 1412.3555. 137. Chung, J., Gülçehre, Ç., Cho, K., and Bengio, Y. (2015a). Gated feedback recurrent neural networks. In ICML’15. 138. Chung, J., Kastner, K., Dinh, L., Goel, K., Courville, A., and Bengio, Y. (2015b). A recurrent latent variable model for sequential data. In NIPS’2015.\n--- Страница 612 ---\nЗаключение  611 139. Ciresan, D., Meier, U., Masci, J., and Schmidhuber, J. (2012). Multi-column deep neural network for traffic sign classification. Neural Networks, 32, 333–338. 140. Ciresan, D. C., Meier, U., Gambardella, L. M., and Schmidhuber, J. (2010). Deep big simple neural nets for handwritten digit recognition. Neural Computation, 22, 1–14. 141. Coates, A. and Ng, A. Y. (2011). Тhe importance of encoding versus training with sparse coding and vector quantization. In ICML’2011. 142. Coates, A., Lee, H., and Ng, A. Y. (2011). An analysis of single-layer networks in unsupervised feature learning. In Proceedings of the Тhirteenth International Conference on Artificial Intelligence and Statistics (AISТAТS 2011). 143. Coates, A., Huval, B., Wang, Т., Wu, D., Catanzaro, B., and Andrew, N. (2013). Deep learning with COТS HPC systems. In S. Dasgupta and D. McAllester, editors, Proceedings of the 30th International Conference on Machine Learning (ICML-13), volume 28 (3), pages 1337–1345. JMLR Workshop and Conference Proceedings. 144. Cohen, N., Sharir, O., and Shashua, A. (2015). On the expressive power of deep learning: A tensor analysis. arXiv:1509.05009. 145. Collobert, R. (2004). Large Scale Machine Learning. Ph.D. thesis, Universitе de Paris VI, LIP6. 146. Collobert, R. (2011). Deep learning for efficient discriminative parsing. In AISТAТS’2011. 147. Collobert, R. and Weston, J. (2008a). A unified architecture for natural language processing: Deep neural networks with multitask learning. In ICML’2008. 148. Collobert, R. and Weston, J. (2008b). A unified architecture for natural language processing: Deep neural networks with multitask learning. In ICML’2008. 149. Collobert, R., Bengio, S., and Bengio, Y. (2001). A parallel mixture of SVMs for very large scale problems. Тechnical Report IDIAP-RR-01-12, IDIAP. 150. Collobert, R., Bengio, S., and Bengio, Y. (2002). Parallel mixture of SVMs for very large scale problems. Neural Computation, 14(5), 1105–1114. 151. Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., and Kuksa, P. (2011a). Natural language processing (almost) from scratch. Тhe Journal of Machine Learning Research, 12, 2493–2537. 152. Collobert, R., Kavukcuoglu, K., and Farabet, C. (2011b). Тorch7: A Matlab-like environment for machine learning. In BigLearn, NIPS Workshop. 153. Comon, P. (1994). Independent component analysis – a new concept? Signal Processing, 36, 287–314. 154. Cortes, C. and Vapnik, V. (1995). Support vector networks. Machine Learning, 20, 273–297. 155. Couprie, C., Farabet, C., Najman, L., and LeCun, Y. (2013). Indoor semantic seg-mentation using depth information. In International Conference on Learning Representations (ICLR2013). 156. Courbariaux, M., Bengio, Y., and David, J.-P. (2015). Low precision arithmetic for deep learning. In Arxiv:1412.7024, ICLR’2015 Workshop. 157. Courville, A., Bergstra, J., and Bengio, Y. (2011). Unsupervised models of images by spike-and-slab RBMs. In ICML’11. 158. Courville, A., Desjardins, G., Bergstra, J., and Bengio, Y. (2014). Тhe spike-and-slab RBM and extensions to discrete and sparse data distributions. Pattern Analysis and Machine Intelligence, IEEE Тransactions on, 36(9), 1874–1887.\n--- Страница 613 ---\n612  Список литературы 159. Cover, Т. M. and Тhomas, J. A. (2006). Elements of Information Тheory, 2nd Edition. Wiley-Interscience. 160. Cox, D. and Pinto, N. (2011). Beyond simple features: A large-scale feature search approach to unconstrained face recognition. In Automatic Face & Gesture Recog-nition and Workshops (FG 2011), 2011 IEEE International Conference on, pa-ges 8–15. IEEE. 161. Cramеr, H. (1946). Mathematical methods of statistics. Princeton University Press. 162. Crick, F. H. C. and Mitchison, G. (1983). Тhe function of dream sleep. Nature, 304, 111–114. 163. Cybenko, G. (1989). Approximation by superpositions of a sigmoidal function. Mathematics of Control, Signals, and Systems, 2, 303–314. 164. Dahl, G. E., Ranzato, M., Mohamed, A., and Hinton, G. E. (2010). Phone recognition with the mean-covariance restricted Boltzmann machine. In NIPS’2010. 165. Dahl, G. E., Yu, D., Deng, L., and Acero, A. (2012). Context-dependent pre-trained deep neural networks for large vocabulary speech recognition. IEEE Тransactions on Audio, Speech, and Language Processing, 20(1), 33–42. 166. Dahl, G. E., Sainath, Т. N., and Hinton, G. E. (2013). Improving deep neural networks for LVCSR using rectified linear units and dropout. In ICASSP’2013. 167. Dahl, G. E., Jaitly, N., and Salakhutdinov, R. (2014). Multi-task neural networks for QSAR predictions. arXiv:1406.1231. 168. Dauphin, Y. and Bengio, Y. (2013). Stochastic ratio matching of RBMs for sparse high-dimensional inputs. In NIPS26. NIPS Foundation. 169. Dauphin, Y., Glorot, X., and Bengio, Y. (2011). Large-scale learning of embeddings with reconstruction sampling. In ICML’2011. 170. Dauphin, Y., Pascanu, R., Gulcehre, C., Cho, K., Ganguli, S., and Bengio, Y. (2014). Identifying and attacking the saddle point problem in high-dimensional non-convex optimization. In NIPS’2014. 171. Davis, A., Rubinstein, M., Wadhwa, N., Mysore, G., Durand, F., and Freeman, W. Т. (2014). Тhe visual microphone: Passive recovery of sound from video. ACM Тransactions on Graphics (Proc. SIGGRAPH), 33(4), 79:1–79:10. 172. Dayan, P. (1990). Reinforcement comparison. In Connectionist Models: Proceedings of the 1990 Connectionist Summer School, San Mateo, CA. 173. Dayan, P. and Hinton, G. E. (1996). Varieties of Helmholtz machine. Neural Net-works, 9(8), 1385–1403. 174. Dayan, P., Hinton, G. E., Neal, R. M., and Zemel, R. S. (1995). Тhe Helmholtz ma-chine. Neural computation, 7(5), 889–904. 175. Dean, J., Corrado, G., Monga, R., Chen, K., Devin, M., Le, Q., Mao, M., Ranzato, M., Senior, A., Тucker, P., Yang, K., and Ng, A. Y. (2012). Large scale distributed deep networks. In NIPS’2012. 176. Dean, Т. and Kanazawa, K. (1989). A model for reasoning about persistence and causation. Computational Intelligence, 5(3), 142–150. 177. Deerwester, S., Dumais, S. Т., Furnas, G. W., Landauer, Т. K., and Harshman, R. (1990). Indexing by latent semantic analysis. Journal of the American Society for Information Science, 41(6), 391–407. 178. Delalleau, O. and Bengio, Y. (2011). Shallow vs. deep sum-product networks. In NIPS. 179. Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L. (2009). ImageNet: A Large-Scale Hierarchical Image Database. In CVPR09.\n--- Страница 614 ---\nЗаключение  613 180. Deng, J., Berg, A. C., Li, K., and Fei-Fei, L. (2010a). What does classifying more than 10,000 image categories tell us? In Proceedings of the 11th European Conference on Computer Vision: Part V, ECCV’10, pages 71–84, Berlin, Heidelberg. Springer-Verlag. 181. Deng, L. and Yu, D. (2014). Deep learning – methods and applications. Foundations and Тrends in Signal Processing. 182. Deng, L., Seltzer, M., Yu, D., Acero, A., Mohamed, A., and Hinton, G. (2010b). Binary coding of speech spectrograms using a deep auto-encoder. In Interspeech 2010, Makuhari, Chiba, Japan. 183. Denil, M., Bazzani, L., Larochelle, H., and de Freitas, N. (2012). Learning where to attend with deep architectures for image tracking. Neural Computation, 24(8), 2151–2184. 184. Denton, E., Chintala, S., Szlam, A., and Fergus, R. (2015). Deep generative image models using a Laplacian pyramid of adversarial networks. NIPS. 185. Desjardins, G. and Bengio, Y. (2008). Empirical evaluation of convolutional RBMs for vision. Тechnical Report 1327, Dеpartement d’Informatique et de Recherche Opеrationnelle, Universitе de Montrеal. 186. Desjardins, G., Courville, A. C., Bengio, Y., Vincent, P., and Delalleau, O. (2010). Тempered Markov chain Monte Carlo for training of restricted Boltzmann machines. In International Conference on Artificial Intelligence and Statistics, pages 145–152. 187. Desjardins, G., Courville, A., and Bengio, Y. (2011). On tracking the partition function. In NIPS’2011. 188. Desjardins, G., Simonyan, K., Pascanu, R., et al. (2015). Natural neural networks. In Advances in Neural Information Processing Systems, pages 2062–2070. 189. Devlin, J., Zbib, R., Huang, Z., Lamar, Т., Schwartz, R., and Makhoul, J. (2014). Fast and robust neural network joint models for statistical machine translation. In Proc. ACL’2014. 190. Devroye, L. (2013). Non-Uniform Random Variate Generation. SpringerLink: Bü­cher. Springer New Y ork. 191. DiCarlo, J. J. (2013). Mechanisms underlying visual object recognition: Humans vs. neurons vs. machines. NIPS Тutorial. 192. Dinh, L., Krueger, D., and Bengio, Y. (2014). NICE: Non-linear independent com-ponents estimation. arXiv:1410.8516. 193. Donahue, J., Hendricks, L. A., Guadarrama, S., Rohrbach, M., Venugopalan, S., Saenko, K., and Darrell, T. (2014). Long-term recurrent convolutional networks for visual recognition and description. arXiv:1411.4389. 194. Donoho, D. L. and Grimes, C. (2003). Hessian eigenmaps: new locally linear em-bedding techniques for high-dimensional data. Technical Report 2003-08, Dept. Statistics, Stanford University. 195. Dosovitskiy, A., Springenberg, J. T., and Brox, T. (2015). Learning to generate chairs with convolutional neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1538–1546. 196. Doya, K. (1993). Bifurcations of recurrent neural networks in gradient descent learning. IEEE Transactions on Neural Networks, 1, 75–80. 197. Dreyfus, S. E. (1962). The numerical solution of variational problems. Journal of Mathematical Analysis and Applications, 5(1), 30–45.\n--- Страница 615 ---\n614  Список литературы 198. Dreyfus, S. E. (1973). The computational solution of optimal control problems with time lag. IEEE Transactions on Automatic Control, 18(4), 383–385. 199. Drucker, H. and LeCun, Y. (1992). Improving generalisation performance using double back-propagation. IEEE Transactions on Neural Networks, 3(6), 991–997. 200. Duchi, J., Hazan, E., and Singer, Y. (2011). Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research. 201. Dudik, M., Langford, J., and Li, L. (2011). Doubly robust policy evaluation and learning. In Proceedings of the 28th International Conference on Machine learning, ICML ’11. 202. Dugas, C., Bengio, Y., Bеlisle, F., and Nadeau, C. (2001). Incorporating second-order functional knowledge for better option pricing. In T. Leen, T. Dietterich, and V. Tresp, editors, Advances in Neural Information Processing Systems 13 (NIPS’00), pages 472–478. MIT Press. 203. Dziugaite, G. K., Roy, D. M., and Ghahramani, Z. (2015). Training generative neural networks via maximum mean discrepancy optimization. arXiv preprint arXiv:1505.03906. 204. El Hihi, S. and Bengio, Y. (1996). Hierarchical recurrent neural networks for long-term dependencies. In NIPS’1995. 205. Elkahky, A. M., Song, Y., and He, X. (2015). A multi-view deep learning approach for cross domain user modeling in recommendation systems. In Proceedings of the 24th International Conference on World Wide Web, pages 278–288. 206. Elman, J. L. (1993). Learning and development in neural networks: The importance of starting small. Cognition, 48, 781–799. 207. Erhan, D., Manzagol, P.-A., Bengio, Y., Bengio, S., and Vincent, P. (2009). The difficulty of training deep architectures and the effect of unsupervised pre-training. In Proceedings of AISTATS’2009. 208. Erhan, D., Bengio, Y., Courville, A., Manzagol, P., Vincent, P., and Bengio, S. (2010). Why does unsupervised pre-training help deep learning? J. Machine Learning Res. 209. Fahlman, S. E., Hinton, G. E., and Sejnowski, T. J. (1983). Massively parallel ar-chitectures for AI: NETL, thistle, and Boltzmann machines. In Proceedings of the National Conference on Artificial Intelligence AAAI-83. 210. Fang, H., Gupta, S., Iandola, F., Srivastava, R., Deng, L., Dollar, P., Gao, J., He, X., Mitchell, M., Platt, J. C., Zitnick, C. L., and Zweig, G. (2015). From captions to visual concepts and back. arXiv:1411.4952. 211. Farabet, C., LeCun, Y., Kavukcuoglu, K., Culurciello, E., Martini, B., Aksel rod, P., and Talay, S. (2011). Large-scale FPGA-based convolutional networks. In R. Bek-kerman, M. Bilenko, and J. Langford, editors, Scaling up Machine Learning: Parallel and Distributed Approaches. Cambridge University Press. 212. Farabet, C., Couprie, C., Najman, L., and LeCun, Y. (2013). Learning hierarchical features for scene labeling. IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(8), 1915–1929. 213. Fei-Fei, L., Fergus, R., and Perona, P. (2006). One-shot learning of object categories. IEEE Transactions on Pattern Analysis and Machine Intelligence, 28(4), 594–611. 214. Finn, C., Tan, X. Y., Duan, Y., Darrell, T., Levine, S., and Abbeel, P. (2015). Learning visual feature spaces for robotic manipulation with deep spatial autoencoders. arXiv preprint arXiv:1509.06113. 215. Fisher, R. A. (1936). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7, 179–188.\n--- Страница 616 ---\nЗаключение  615 216. Földiak, P. (1989). Adaptive network for optimal linear feature extraction. In International Joint Conference on Neural Networks (IJCNN), volume 1, pages 401–405, Washington 1989. IEEE, New Y ork. 217. Forcada, M., and Teco, R. (1997). Recursive hetero-associative memories for translation. In Biological and Artificial Computation: From Neuroscience to Technology, pages 453–462. http://citeseerx.ist.psu.edu/viewdoc/summary? doi=10.1.1.43.1968. 218. Franzius, M., Sprekeler, H., and Wiskott, L. (2007). Slowness and sparseness lead to place, head-direction, and spatial-view cells. 219. Franzius, M., Wilbert, N., and Wiskott, L. (2008). Invariant object recognition with slow feature analysis. In Artificial Neural Networks-ICANN 2008, pages 961–970. Springer. 220. Frasconi, P., Gori, M., and Sperduti, A. (1997). On the efficient classification of data structures by neural networks. In Proc. Int. Joint Conf. on Artificial Intelligence. 221. Frasconi, P., Gori, M., and Sperduti, A. (1998). A general framework for adaptive pro-cessing of data structures. IEEE Transactions on Neural Networks, 9(5), 768–786. 222. Freund, Y. and Schapire, R. E. (1996a). Experiments with a new boosting algorithm. In Machine Learning: Proceedings of Thirteenth International Conference, pages 148–156, USA. ACM. 223. Freund, Y. and Schapire, R. E. (1996b). Game theory, on-line prediction and boosting. In Proceedings of the Ninth Annual Conference on Computational Learning Theory, pages 325–332. 224. Frey, B. J. (1998). Graphical models for machine learning and digital communication. MIT Press. 225. Frey, B. J., Hinton, G. E., and Dayan, P. (1996). Does the wake-sleep algorithm learn good density estimators? In D. Touretzky, M. Mozer, and M. Hasselmo, editors, Advances in Neural Information Processing Systems 8 (NIPS’95), pages 661–670. MIT Press, Cambridge, MA. 226. Frobenius, G. (1908). Über matrizen aus positiven elementen, s. B. Preuss. Akad. Wiss. Berlin, Germany. 227. Fukushima, K. (1975). Cognitron: A self-organizing multilayered neural network. Biological Cybernetics, 20, 121–136. 228. Fukushima, K. (1980). Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. Biological Cybernetics, 36, 193–202. 229. Gal, Y. and Ghahramani, Z. (2015). Bayesian convolutional neural networks with Bernoulli approximate variational inference. arXiv preprint arXiv:1506.02158. 230. Gallinari, P., LeCun, Y., Thiria, S., and Fogelman-Soulie, F. (1987). Memoires associatives distribuees. In Proceedings of COGNITIV A 87, Paris, La Villette. 231. Garcia-Duran, A., Bordes, A., Usunier, N., and Grandvalet, Y. (2015). Combining two and three-way embeddings models for link prediction in knowledge bases. arXiv preprint arXiv:1506.00999. 232. Garofolo, J. S., Lamel, L. F., Fisher, W. M., Fiscus, J. G., and Pallett, D. S. (1993). Darpa timit acoustic-phonetic continous speech corpus cd-rom. nist speech disc 1-1.1. NASA STI/Recon Technical Report N, 93, 27403. 233. Garson, J. (1900). The metric system of identification of criminals, as used in Great Britain and Ireland. The Journal of the Anthropological Institute of Great Britain and Ireland, (2), 177–227.\n--- Страница 617 ---\n616  Список литературы 234. Gers, F. A., Schmidhuber, J., and Cummins, F. (2000). Learning to forget: Continual prediction with LSTM. Neural computation, 12(10), 2451–2471. 235. Ghahramani, Z. and Hinton, G. E. (1996). The EM algorithm for mixtures of factor analyzers. Technical Report CRG-TR-96-1, Dpt. of Comp. Sci., Univ. of Toronto. 236. Gillick, D., Brunk, C., Vinyals, O., and Subramanya, A. (2015). Multilingual language processing from bytes. arXiv preprint arXiv:1512.00103. 237. Girshick, R., Donahue, J., Darrell, T., and Malik, J. (2015). Region-based convolutional networks for accurate object detection and segmentation. 238. Giudice, M. D., Manera, V., and Keysers, C. (2009). Programmed to learn? The ontogeny of mirror neurons. Dev. Sci., 12(2), 350–363. 239. Glorot, X. and Bengio, Y. (2010). Understanding the difficulty of training deep feedforward neural networks. In AISTATS’2010. 240. Glorot, X., Bordes, A., and Bengio, Y. (2011a). Deep sparse rectifier neural networks. In AISTATS’2011. 241. Glorot, X., Bordes, A., and Bengio, Y. (2011b). Domain adaptation for large-scale sentiment classification: A deep learning approach. In ICML’2011. 242. Goldberger, J., Roweis, S., Hinton, G. E., and Salakhutdinov, R. (2005). Neighbourhood components analysis. In L. Saul, Y. Weiss, and L. Bottou, editors, Advances in Neural Information Processing Systems 17 (NIPS’04). MIT Press. 243. Gong, S., McKenna, S., and Psarrou, A. (2000). Dynamic Vision: From Images to Face Recognition. Imperial College Press. 244. Goodfellow, I., Le, Q., Saxe, A., and Ng, A. (2009). Measuring invariances in deep networks. In NIPS’2009, pages 646–654. 245. Goodfellow, I., Koenig, N., Muja, M., Pantofaru, C., Sorokin, A., and Takayama, L. (2010). Help me help you: Interfaces for personal robots. In Proc. of Human Robot Interaction (HRI), Osaka, Japan. ACM Press, ACM Press. 246. Goodfellow, I. J. (2010). Technical report: Multidimensional, downsampled convolu-tion for autoencoders. Technical report, Universite de Montreal. 247. Goodfellow, I. J. (2014). On distinguishability criteria for estimating generative mod-els. In International Conference on Learning Representations, Workshops Track. 248. Goodfellow, I. J., Courville, A., and Bengio, Y. (2011). Spike-and-slab sparse coding for unsupervised feature discovery. In NIPS Workshop on Challenges in Learning Hierarchical Models. 249. Goodfellow, I. J., Warde-Farley, D., Mirza, M., Courville, A., and Bengio, Y. (2013a). Maxout networks. In S. Dasgupta and D. McAllester, editors, ICML’13, pages 1319–1327. 250. Goodfellow, I. J., Mirza, M., Courville, A., and Bengio, Y. (2013b). Multi-prediction deep Boltzmann machines. In NIPS26. NIPS Foundation. 251. Goodfellow, I. J., Warde-Farley, D., Lamblin, P., Dumoulin, V., Mirza, M., Pascanu, R., Bergstra, J., Bastien, F., and Bengio, Y. (2013c). Pylearn2: a machine learning research library. arXiv preprint arXiv:1308.4214. 252. Goodfellow, I. J., Courville, A., and Bengio, Y. (2013d). Scaling up spike-and-slab models for unsupervised feature learning. IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(8), 1902–1914. 253. Goodfellow, I. J., Mirza, M., Xiao, D., Courville, A., and Bengio, Y. (2014a). An em-pirical investigation of catastrophic forgetting in gradient-based neural networks. In ICLR’2014.\n--- Страница 618 ---\nЗаключение  617 254. Goodfellow, I. J., Shlens, J., and Szegedy, C. (2014b). Explaining and harnessing ad- versarial examples. CoRR, abs/1412.6572. 255. Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y. (2014c). Generative adversarial networks. In NIPS’2014. 256. Goodfellow, I. J., Bulatov, Y., Ibarz, J., Arnoud, S., and Shet, V. (2014d). Multi-digit number recognition from Street View imagery using deep convolutional neural net-works. In International Conference on Learning Representations. 257. Goodfellow, I. J., Vinyals, O., and Saxe, A. M. (2015). Qualitatively characterizing neural network optimization problems. In International Conference on Learning Representations. 258. Goodman, J. (2001). Classes for fast maximum entropy training. In International Conference on Acoustics, Speech and Signal Processing (ICASSP), Utah. 259. Gori, M. and Tesi, A. (1992). On the problem of local minima in backpropagation. IEEE Transactions on Pattern Analysis and Machine Intelligence, PAMI-14(1), 76–86. 260. Gosset, W. S. (1908). The probable error of a mean. Biometrika, 6(1), 1–25. Origi-nally published under the pseudonym “Student”. 261. Gouws, S., Bengio, Y., and Corrado, G. (2014). BilBOW A: Fast bilingual distributed representations without word alignments. Technical report, arXiv:1410.2455. 262. Graf, H. P. and Jackel, L. D. (1989). Analog electronic neural network circuits. Cir-cuits and Devices Magazine, IEEE, 5(4), 44–49. 263. Graves, A. (2011). Practical variational inference for neural networks. In NIPS’2011. 264. Graves, A. (2012). Supervised Sequence Labelling with Recurrent Neural Networks. Studies in Computational Intelligence. Springer. 265. Graves, A. (2013). Generating sequences with recurrent neural networks. Technical report, arXiv:1308.0850. 266. Graves, A. and Jaitly, N. (2014). Towards end-to-end speech recognition with recur-rent neural networks. In ICML’2014. 267. Graves, A. and Schmidhuber, J. (2005). Framewise phoneme classification with bi-directional LSTM and other neural network architectures. Neural Networks, 18(5), 602–610. 268. Graves, A. and Schmidhuber, J. (2009). Offline handwriting recognition with multi-dimensional recurrent neural networks. In D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, NIPS’2008, pages 545–552. 269. Graves, A., Fernandez, S., Gomez, F., and Schmidhuber, J. (2006). Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks. In ICML’2006, pages 369–376, Pittsburgh, USA. 270. Graves, A., Liwicki, M., Bunke, H., Schmidhuber, J., and Fernandez, S. (2008). Un-constrained on-line handwriting recognition with recurrent neural networks. In J. Platt, D. Koller, Y. Singer, and S. Roweis, editors, NIPS’2007, pages 577–584. 271. Graves, A., Liwicki, M., Fernandez, S., Bertolami, R., Bunke, H., and Schmidhuber, J. (2009). A novel connectionist system for unconstrained handwriting recognition. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 31(5), 855–868. 272. Graves, A., Mohamed, A., and Hinton, G. (2013). Speech recognition with deep re-current neural networks. In ICASSP’2013, pages 6645–6649. 273. Graves, A., Wayne, G., and Danihelka, I. (2014a). Neural Turing machines. arX-iv:1410.5401.\n--- Страница 619 ---\n618  Список литературы 274. Graves, A., Wayne, G., and Danihelka, I. (2014b). Neural Turing machines. arXiv preprint arXiv:1410.5401. 275. Grefenstette, E., Hermann, K. M., Suleyman, M., and Blunsom, P. (2015). Learning to transduce with unbounded memory. In NIPS’2015. 276. Greff, K., Srivastava, R. K., Koutník, J., Steunebrink, B. R., and Schmidhuber, J. (2015). LSTM: a search space odyssey. arXiv preprint arXiv:1503.04069. 277. Gregor, K. and LeCun, Y. (2010a). Emergence of complex-like cells in a temporal product network with local receptive fields. Technical report, arXiv:1006.0448. 278. Gregor, K. and LeCun, Y. (2010b). Learning fast approximations of sparse coding. In L. Bottou and M. Littman, editors, Proceedings of the Twenty-seventh International Conference on Machine Learning (ICML-10). ACM. 279. Gregor, K., Danihelka, I., Mnih, A., Blundell, C., and Wierstra, D. (2014). Deep autore-gressive networks. In International Conference on Machine Learning (ICML’2014). 280. Gregor, K., Danihelka, I., Graves, A., and Wierstra, D. (2015). DRA W: A recurrent neural network for image generation. arXiv preprint arXiv:1502.04623. 281. Gretton, A., Borgwardt, K. M., Rasch, M. J., Schölkopf, B., and Smola, A. (2012). A kernel two-sample test. The Journal of Machine Learning Research, 13(1), 723– 773. 282. Gülçehre, Ç. and Bengio, Y. (2013). Knowledge matters: Importance of prior infor- mation for optimization. In International Conference on Learning Representations (ICLR’2013). 283. Guo, H. and Gelfand, S. B. (1992). Classification trees with neural network feature extraction. Neural Networks, IEEE Transactions on, 3(6), 923–933. 284. Gupta, S., Agrawal, A., Gopalakrishnan, K., and Narayanan, P. (2015). Deep learning with limited numerical precision. CoRR, abs/1502.02551. 285. Gutmann, M. and Hyvarinen, A. (2010). Noise-contrastive estimation: A new estima-tion principle for unnormalized statistical models. In Proceedings of The Thirteenth International Conference on Artificial Intelligence and Statistics (AISTATS’10). 286. Hadsell, R., Sermanet, P., Ben, J., Erkan, A., Han, J., Muller, U., and LeCun, Y. (2007). Online learning for offroad robots: Spatial label propagation to learn long-range tra-versability. In Proceedings of Robotics: Science and Systems, Atlanta, GA, USA. 287. Hajnal, A., Maass, W., Pudlak, P., Szegedy, M., and Turan, G. (1993). Threshold cir-cuits of bounded depth. J. Comput. System. Sci., 46, 129–154. 288. Håstad, J. (1986). Almost optimal lower bounds for small depth circuits. In Pro-ceedings of the 18th annual ACM Symposium on Theory of Computing, pages 6–20, Berkeley, California. ACM Press. 289. Håstad, J. and Goldmann, M. (1991). On the power of small-depth threshold cir-cuits. Computational Complexity, 1, 113–129. 290. Hastie, T., Tibshirani, R., and Friedman, J. (2001). The elements of statistical learn-ing: data mining, inference and prediction. Springer Series in Statistics. Springer Verlag. 291. He, K., Zhang, X., Ren, S., and Sun, J. (2015). Delving deep into rectifiers: Surpass-ing human-level performance on ImageNet classification. arXiv preprint arXiv:1502. 01852. 292. Hebb, D. O. (1949). The Organization of Behavior. Wiley, New Y ork. 293. Henaff, M., Jarrett, K., Kavukcuoglu, K., and LeCun, Y. (2011). Unsupervised learn-ing of sparse features for scalable audio classification. In ISMIR’11.\n--- Страница 620 ---\nЗаключение  619 294. Henderson, J. (2003). Inducing history representations for broad coverage statistical parsing. In HLT-NAACL, pages 103–110. 295. Henderson, J. (2004). Discriminative training of a neural network statistical parser. In Proceedings of the 42nd Annual Meeting on Association for Computational Lin-guistics, page 95. 296. Henniges, M., Puertas, G., Bornschein, J., Eggert, J., and Lücke, J. (2010). Binary sparse coding. In Latent Variable Analysis and Signal Separation, pages 450–457. Springer. 297. Herault, J. and Ans, B. (1984). Circuits neuronaux à synapses modifiables: Decodage de messages composites par apprentissage non supervise. Comptes Rendus de l’Academie des Sciences, 299(III-13), 525–528. 298. Hinton, G. (2012). Neural networks for machine learning. Coursera, video lectures. 299. Hinton, G., Deng, L., Dahl, G. E., Mohamed, A., Jaitly, N., Senior, A., Vanhoucke, V., Nguyen, P., Sainath, T., and Kingsbury, B. (2012a). Deep neural networks for acous-tic modeling in speech recognition. IEEE Signal Processing Magazine, 29(6), 82–97. 300. Hinton, G., Vinyals, O., and Dean, J. (2015). Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531. 301. Hinton, G. E. (1989). Connectionist learning procedures. Artificial Intelligence, 40, 185–234. 302. Hinton, G. E. (1990). Mapping part-whole hierarchies into connectionist networks. Artificial Intelligence, 46(1), 47–75. 303. Hinton, G. E. (1999). Products of experts. In ICANN’1999. 304. Hinton, G. E. (2000). Training products of experts by minimizing contrastive di-vergence. Technical Report GCNU TR 2000-004, Gatsby Unit, University College London. 305. Hinton, G. E. (2006). To recognize shapes, first learn to generate images. Technical Report UTML TR 2006-003, University of Toronto. 306. Hinton, G. E. (2007a). How to do backpropagation in a brain. Invited talk at the NIPS’2007 Deep Learning Workshop. 307. Hinton, G. E. (2007b). Learning multiple layers of representation. Trends in cogni-tive sciences, 11(10), 428–434. 308. Hinton, G. E. (2010). A practical guide to training restricted Boltzmann machines. Technical Report UTML TR 2010-003, Department of Computer Science, Univer-sity of Toronto. 309. Hinton, G. E. and Ghahramani, Z. (1997). Generative models for discovering sparse distributed representations. Philosophical Transactions of the Royal Society of Lon-don. 310. Hinton, G. E. and McClelland, J. L. (1988). Learning representations by recircula-tion. In NIPS’1987, pages 358–366. 311. Hinton, G. E. and Roweis, S. (2003). Stochastic neighbor embedding. In NIPS’2002. 312. Hinton, G. E. and Salakhutdinov, R. (2006). Reducing the dimensionality of data with neural networks. Science, 313(5786), 504–507. 313. Hinton, G. E. and Sejnowski, T. J. (1986). Learning and relearning in Boltzmann machines. In D. E. Rumelhart and J. L. McClelland, editors, Parallel Distributed Processing, volume 1, chapter 7, pages 282–317. MIT Press, Cambridge. 314. Hinton, G. E. and Sejnowski, T. J. (1999). Unsupervised learning: foundations of neural computation. MIT press.\n--- Страница 621 ---\n620  Список литературы 315. Hinton, G. E. and Shallice, T. (1991). Lesioning an attractor network: investigations of acquired dyslexia. Psychological review, 98(1), 74. 316. Hinton, G. E. and Zemel, R. S. (1994). Autoencoders, minimum description length, and Helmholtz free energy. In NIPS’1993. 317. Hinton, G. E., Sejnowski, T. J., and Ackley, D. H. (1984). Boltzmann machines: Con-straint satisfaction networks that learn. Technical Report TR-CMU-CS-84-119, Carnegie-Mellon University, Dept. of Computer Science. 318. Hinton, G. E., McClelland, J., and Rumelhart, D. (1986). Distributed representa-tions. In D. E. Rumelhart and J. L. McClelland, editors, Parallel Distributed Process-ing: Explorations in the Microstructure of Cognition, volume 1, pages 77–109. MIT Press, Cambridge. 319. Hinton, G. E., Revow, M., and Dayan, P. (1995a). Recognizing handwritten digits using mixtures of linear models. In G. Tesauro, D. Touretzky, and T. Leen, editors, Advances in Neural Information Processing Systems 7 (NIPS’94), pages 1015–1022. MIT Press, Cambridge, MA. 320. Hinton, G. E., Dayan, P., Frey, B. J., and Neal, R. M. (1995b). The wake-sleep algo-rithm for unsupervised neural networks. Science, 268, 1558–1161. 321. Hinton, G. E., Dayan, P., and Revow, M. (1997). Modelling the manifolds of images of handwritten digits. IEEE Transactions on Neural Networks, 8, 65–74. 322. Hinton, G. E., Welling, M., Teh, Y. W., and Osindero, S. (2001). A new view of ICA. In Proceedings of 3rd International Conference on Independent Component Analy-sis and Blind Signal Separation (ICA’01), pages 746–751, San Diego, CA. 323. Hinton, G. E., Osindero, S., and Teh, Y. (2006). A fast learning algorithm for deep belief nets. Neural Computation, 18, 1527–1554. 324. Hinton, G. E., Deng, L., Yu, D., Dahl, G. E., Mohamed, A., Jaitly, N., Senior, A., Van-houcke, V., Nguyen, P., Sainath, T. N., and Kingsbury, B. (2012b). Deep neural net-works for acoustic modeling in speech recognition: The shared views of four research groups. IEEE Signal Process. Mag., 29(6), 82–97. 325. Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. (2012c). Improving neural networks by preventing co-adaptation of feature detec-tors. Technical report, arXiv:1207.0580. 326. Hinton, G. E., Vinyals, O., and Dean, J. (2014). Dark knowledge. Invited talk at the BayLearn Bay Area Machine Learning Symposium. 327. Hochreiter, S. (1991). Untersuchungen zu dynamischen neuronalen Netzen. Diplo-ma thesis, T. U. München. 328. Hochreiter, S. and Schmidhuber, J. (1995). Simplifying neural nets by discovering flat minima. In Advances in Neural Information Processing Systems 7, pages 529–536. MIT Press. 329. Hochreiter, S. and Schmidhuber, J. (1997). Long short-term memory. Neural Com-putation, 9(8), 1735–1780. 330. Hochreiter, S., Bengio, Y., and Frasconi, P. (2001). Gradient flow in recurrent nets: the difficulty of learning long-term dependencies. In J. Kolen and S. Kremer, editors, Field Guide to Dynamical Recurrent Networks. IEEE Press. 331. Holi, J. L. and Hwang, J.-N. (1993). Finite precision error analysis of neural network hardware implementations. Computers, IEEE Transactions on, 42(3), 281–290. 332. Holt, J. L. and Baker, T. E. (1991). Back propagation simulations using limited preci-sion calculations. In Neural Networks, 1991., IJCNN-91-Seattle International Joint Conference on, volume 2, pages 121–126. IEEE.\n--- Страница 622 ---\nЗаключение  621 333. Hornik, K., Stinchcombe, M., and White, H. (1989). Multilayer feedforward net- works are universal approximators. Neural Networks, 2, 359–366. 334. Hornik, K., Stinchcombe, M., and White, H. (1990). Universal approximation of an unknown mapping and its derivatives using multilayer feedforward networks. Neu-ral networks, 3(5), 551–560. 335. Hsu, F.-H. (2002). Behind Deep Blue: Building the Computer That Defeated the World Chess Champion. Princeton University Press, Princeton, NJ, USA. 336. Huang, F. and Ogata, Y. (2002). Generalized pseudo-likelihood estimates for Markov random fields on lattice. Annals of the Institute of Statistical Mathematics, 54(1), 1–18. 337. Huang, P.-S., He, X., Gao, J., Deng, L., Acero, A., and Heck, L. (2013). Learning deep structured semantic models for web search using clickthrough data. In Proceedings of the 22nd ACM international conference on Conference on information & knowl-edge management, pages 2333–2338. ACM. 338. Hubel, D. and Wiesel, T. (1968). Receptive fields and functional architecture of mon-key striate cortex. Journal of Physiology (London), 195, 215–243. 339. Hubel, D. H. and Wiesel, T. N. (1959). Receptive fields of single neurons in the cat’s striate cortex. Journal of Physiology, 148, 574–591. 340. Hubel, D. H. and Wiesel, T. N. (1962). Receptive fields, binocular interaction, and functional architecture in the cat’s visual cortex. Journal of Physiology (London), 160, 106–154. 341. Huszar, F. (2015). How (not) to train your generative model: schedule sampling, likelihood, adversary? arXiv:1511.05101. 342. Hutter, F., Hoos, H., and Leyton-Brown, K. (2011). Sequential model-based opti-mization for general algorithm configuration. In LION-5. Extended version as UBC Tech report TR-2010-10. 343. Hyotyniemi, H. (1996). Turing machines are recurrent neural networks. In STeP’96, pages 13–24. 344. Hyvärinen, A. (1999). Survey on independent component analysis. Neural Comput-ing Surveys, 2, 94–128. 345. Hyvärinen, A. (2005). Estimation of non-normalized statistical models using score matching. Journal of Machine Learning Research, 6, 695–709. 346. Hyvärinen, A. (2007a). Connections between score matching, contrastive diver-gence, and pseudolikelihood for continuous-valued variables. IEEE Transactions on Neural Networks, 18, 1529–1531. 347. Hyvärinen, A. (2007b). Some extensions of score matching. Computational Statis-tics and Data Analysis, 51, 2499–2512. 348. Hyvärinen, A. and Hoyer, P. O. (1999). Emergence of topography and complex cell properties from natural images using extensions of ica. In NIPS, pages 827–833. 349. Hyvärinen, A. and Pajunen, P. (1999). Nonlinear independent component analysis: Existence and uniqueness results. Neural Networks, 12(3), 429–439. 350. Hyvärinen, A., Karhunen, J., and Oja, E. (2001a). Independent Component Analysis. Wiley-Interscience. 351. Hyvärinen, A., Hoyer, P. O., and Inki, M. O. (2001b). Topographic independent com-ponent analysis. Neural Computation, 13(7), 1527–1558. 352. Hyvärinen, A., Hurri, J., and Hoyer, P. O. (2009). Natural Image Statistics: A proba-bilistic approach to early computational vision. Springer-Verlag.\n--- Страница 623 ---\n622  Список литературы 353. Iba, Y. (2001). Extended ensemble Monte Carlo. International Journal of Modern Physics, C12, 623–656. 354. Inayoshi, H. and Kurita, T. (2005). Improved generalization by adding both autoas-sociation and hidden-layer noise to neural-network-based-classifiers. IEEE Work-shop on Machine Learning for Signal Processing, pages 141–146. 355. Ioffe, S. and Szegedy, C. (2015). Batch normalization: Accelerating deep network training by reducing internal covariate shift. 356. Jacobs, R. A. (1988). Increased rates of convergence through learning rate adapta-tion. Neural networks, 1(4), 295–307. 357. Jacobs, R. A., Jordan, M. I., Nowlan, S. J., and Hinton, G. E. (1991). Adaptive mix-tures of local experts. Neural Computation, 3, 79–87. 358. Jaeger, H. (2003). Adaptive nonlinear system identification with echo state net-works. In Advances in Neural Information Processing Systems 15. 359. Jaeger, H. (2007a). Discovering multiscale dynamical features with hierarchical echo state networks. Technical report, Jacobs University. 360. Jaeger, H. (2007b). Echo state network. Scholarpedia, 2(9), 2330. 361. Jaeger, H. (2012). Long short-term memory in echo state networks: Details of a simu-lation study. Technical report, Technical report, Jacobs University Bremen. 362. Jaeger, H. and Haas, H. (2004). Harnessing nonlinearity: Predicting chaotic systems and saving energy in wireless communication. Science, 304(5667), 78–80. 363. Jaeger, H., Lukosevicius, M., Popovici, D., and Siewert, U. (2007). Optimization and applications of echo state networks with leaky- integrator neurons. Neural Net-works, 20(3), 335–352. 364. Jain, V., Murray, J. F., Roth, F., Turaga, S., Zhigulin, V., Briggman, K. L., Helmstaedter, M. N., Denk, W., and Seung, H. S. (2007). Supervised learning of image restoration with convolutional networks. In Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on, pages 1–8. IEEE. 365. Jaitly, N. and Hinton, G. (2011). Learning a better representation of speech sound-waves using restricted Boltzmann machines. In Acoustics, Speech and Signal Pro-cessing (ICASSP), 2011 IEEE International Conference on, pages 5884–5887. IEEE. 366. Jaitly, N. and Hinton, G. E. (2013). Vocal tract length perturbation (VTLP) im-proves speech recognition. In ICML’2013. 367. Jarrett, K., Kavukcuoglu, K., Ranzato, M., and LeCun, Y. (2009). What is the best multi-stage architecture for object recognition? In ICCV’09. 368. Jarzynski, C. (1997). Nonequilibrium equality for free energy differences. Phys. Rev. Lett., 78, 2690–2693. 369. Jaynes, E. T. (2003). Probability Theory: The Logic of Science. Cambridge Univer-sity Press. 370. Jean, S., Cho, K., Memisevic, R., and Bengio, Y. (2014). On using very large target vocabulary for neural machine translation. arXiv:1412.2007. 371. Jelinek, F. and Mercer, R. L. (1980). Interpolated estimation of Markov source pa-rameters from sparse data. In E. S. Gelsema and L. N. Kanal, editors, Pattern Recog-nition in Practice. North-Holland, Amsterdam. 372. Jia, Y. (2013). Caffe: An open source convolutional architecture for fast feature em-bedding. http://caffe.berkeleyvision.org/.\n--- Страница 624 ---\nЗаключение  623 373. Jia, Y., Huang, C., and Darrell, T. (2012). Beyond spatial pyramids: Receptive field learning for pooled image features. In Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pages 3370–3377. IEEE. 374. Jim, K.-C., Giles, C. L., and Horne, B. G. (1996). An analysis of noise in recurrent neural networks: convergence and generalization. IEEE Transactions on Neural Net-works, 7(6), 1424–1438. 375. Jordan, M. I. (1998). Learning in Graphical Models. Kluwer, Dordrecht, Nether-lands. 376. Joulin, A. and Mikolov, T. (2015). Inferring algorithmic patterns with stack-aug-mented recurrent nets. arXiv preprint arXiv:1503.01007. 377. Jozefowicz, R., Zaremba, W., and Sutskever, I. (2015). An empirical evaluation of recurrent network architectures. In ICML’2015. 378. Judd, J. S. (1989). Neural Network Design and the Complexity of Learning. MIT Press. 379. Jutten, C. and Herault, J. (1991). Blind separation of sources, part I: an adaptive algorithm based on neuromimetic architecture. Signal Processing, 24, 1–10. 380. Kahou, S. E., Pal, C., Bouthillier, X., Froumenty, P., Gülçehre, C., Memisevic, R., Vincent, P., Courville, A., Bengio, Y., Ferrari, R. C., Mirza, M., Jean, S., Carrier, P. L., Dauphin, Y., Boulanger-Lewandowski, N., Aggarwal, A., Zumer, J., Lamblin, P., Ray-mond, J.-P., Desjardins, G., Pascanu, R., Warde-Farley, D., Torabi, A., Sharma, A., Bengio, E., Côte, M., Konda, K. R., and Wu, Z. (2013). Combining modality spe- cific deep neural networks for emotion recognition in video. In Proceedings of the 15 th ACM on International Conference on Multimodal Interaction. 381. Kalchbrenner, N. and Blunsom, P. (2013). Recurrent continuous translation models. In EMNLP’2013. 382. Kalchbrenner, N., Danihelka, I., and Graves, A. (2015). Grid long short-term memo-ry. arXiv preprint arXiv:1507.01526. 383. Kamyshanska, H. and Memisevic, R. (2015). The potential energy of an autoencoder. IEEE Transactions on Pattern Analysis and Machine Intelligence. 384. Karpathy, A. and Li, F.-F. (2015). Deep visual-semantic alignments for generating image descriptions. In CVPR’2015. arXiv:1412.2306. 385. Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., and Fei-Fei, L. (2014). Large-scale video classification with convolutional neural networks. In CVPR. 386. Karush, W. (1939). Minima of Functions of Several Variables with Inequalities as Side Constraints. Master’s thesis, Dept. of Mathematics, Univ. of Chicago. 387. Katz, S. M. (1987). Estimation of probabilities from sparse data for the language model component of a speech recognizer. IEEE Transactions on Acoustics, Speech, and Signal Processing, ASSP-35(3), 400–401. 388. Kavukcuoglu, K., Ranzato, M., and LeCun, Y. (2008). Fast inference in sparse cod-ing algorithms with applications to object recognition. Technical report, Computa-tional and Biological Learning Lab, Courant Institute, NYU. Tech Report CBLL-TR-2008-12-01. 389. Kavukcuoglu, K., Ranzato, M.-A., Fergus, R., and LeCun, Y. (2009). Learning invari-ant features through topographic filter maps. In CVPR’2009. 390. Kavukcuoglu, K., Sermanet, P., Boureau, Y.-L., Gregor, K., Mathieu, M., and Le-Cun, Y. (2010). Learning convolutional feature hierarchies for visual recognition. In NIPS’2010.\n--- Страница 625 ---\n624  Список литературы 391. Kelley, H. J. (1960). Gradient theory of optimal flight paths. ARS Journal, 30(10), 947–954. 392. Khan, F., Zhu, X., and Mutlu, B. (2011). How do humans teach: On curriculum learn-ing and teaching dimension. In Advances in Neural Information Processing Systems 24 (NIPS’11), pages 1449–1457. 393. Kim, S. K., McAfee, L. C., McMahon, P. L., and Olukotun, K. (2009). A highly scal-able restricted Boltzmann machine FPGA implementation. In Field Programmable Logic and Applications, 2009. FPL 2009. International Conference on, pages 367–372. IEEE. 394. Kindermann, R. (1980). Markov Random Fields and Their Applications (Contem-porary Mathematics ; V. 1). American Mathematical Society. 395. Kingma, D. and Ba, J. (2014). Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980. 396. Kingma, D. and LeCun, Y. (2010). Regularized estimation of image statistics by score matching. In NIPS’2010. 397. Kingma, D., Rezende, D., Mohamed, S., and Welling, M. (2014). Semi-supervised learning with deep generative models. In NIPS’2014. 398. Kingma, D. P. (2013). Fast gradient-based inference with continuous latent variable models in auxiliary form. Technical report, arxiv:1306.0733. 399. Kingma, D. P. and Welling, M. (2014a). Auto-encoding variational bayes. In Pro-ceedings of the International Conference on Learning Representations (ICLR). 400. Kingma, D. P. and Welling, M. (2014b). Efficient gradient-based inference through transformations between bayes nets and neural nets. Technical report, arx-iv:1402.0480. 401. Kirkpatrick, S., Jr., C. D. G., , and Vecchi, M. P. (1983). Optimization by simulated annealing. Science, 220, 671–680. 402. Kiros, R., Salakhutdinov, R., and Zemel, R. (2014a). Multimodal neural language models. In ICML’2014. 403. Kiros, R., Salakhutdinov, R., and Zemel, R. (2014b). Unifying visual-semantic em-beddings with multimodal neural language models. arXiv:1411.2539 [cs.LG]. 404. Klementiev, A., Titov, I., and Bhattarai, B. (2012). Inducing crosslingual distributed representations of words. In Proceedings of COLING 2012. 405. Knowles-Barley, S., Jones, T. R., Morgan, J., Lee, D., Kasthuri, N., Lichtman, J. W., and Pfister, H. (2014). Deep learning for the connectome. GPU Technology Confer-ence. 406. Koller, D. and Friedman, N. (2009). Probabilistic Graphical Models: Principles and Techniques. MIT Press. 407. Konig, Y., Bourlard, H., and Morgan, N. (1996). REMAP: Recursive estimation and maximization of a posteriori probabilities – application to transition-based connec- tionist speech recognition. In D. Touretzky, M. Mozer, and M. Hasselmo, editors, Advances in Neural Information Processing Systems 8 (NIPS’95). MIT Press, Cam-bridge, MA. 408. Koren, Y. (2009). The BellKor solution to the Netflix grand prize. 409. Kotzias, D., Denil, M., de Freitas, N., and Smyth, P. (2015). From group to individual labels using deep features. In ACM SIGKDD. 410. Koutnik, J., Greff, K., Gomez, F., and Schmidhuber, J. (2014). A clockwork RNN. In ICML’2014.\n--- Страница 626 ---\nЗаключение  625 411. Kociský, T., Hermann, K. M., and Blunsom, P. (2014). Learning Bilingual Word Rep- resentations by Marginalizing Alignments. In Proceedings of ACL. 412. Krause, O., Fischer, A., Glasmachers, T., and Igel, C. (2013). Approximation proper-ties of DBNs with binary hidden units and real-valued visible units. In ICML’2013. 413. Krizhevsky, A. (2010). Convolutional deep belief networks on CIFAR-10. Technical report, University of Toronto. Unpublished Manuscript: http://www.cs.utoronto. ca/ kriz/convcifar10-aug2010.pdf. 414. Krizhevsky, A. and Hinton, G. (2009). Learning multiple layers of features from tiny images. Technical report, University of Toronto. 415. Krizhevsky, A. and Hinton, G. E. (2011). Using very deep autoencoders for content-based image retrieval. In ESANN. 416. Krizhevsky, A., Sutskever, I., and Hinton, G. (2012). ImageNet classification with deep convolutional neural networks. In NIPS’2012. 417. Krueger, K. A. and Dayan, P. (2009). Flexible shaping: how learning in small steps helps. Cognition, 110, 380–394. 418. Kuhn, H. W. and Tucker, A. W. (1951). Nonlinear programming. In Proceedings of the Second Berkeley Symposium on Mathematical Statistics and Probability, pages 481–492, Berkeley, Calif. University of California Press. 419. Kumar, A., Irsoy, O., Su, J., Bradbury, J., English, R., Pierce, B., Ondruska, P., Iyyer, M., Gulrajani, I., and Socher, R. (2015). Ask me anything: Dynamic memory net-works for natural language processing. arXiv:1506.07285. 420. Kumar, M. P., Packer, B., and Koller, D. (2010). Self-paced learning for latent vari-able models. In NIPS’2010. 421. Lang, K. J. and Hinton, G. E. (1988). The development of the time-delay neural network architecture for speech recognition. Technical Report CMU-CS-88-152, Carnegie-Mellon University. 422. Lang, K. J., Waibel, A. H., and Hinton, G. E. (1990). A time-delay neural network architecture for isolated word recognition. Neural networks, 3(1), 23–43. 423. Langford, J. and Zhang, T. (2008). The epoch-greedy algorithm for contextual multi-armed bandits. In NIPS’2008, pages 1096–1103. 424. Lappalainen, H., Giannakopoulos, X., Honkela, A., and Karhunen, J. (2000). Non-linear independent component analysis using ensemble learning: Experiments and discussion. In Proc. ICA. Citeseer. 425. Larochelle, H. and Bengio, Y. (2008). Classification using discriminative restricted Boltzmann machines. In ICML’2008. 426. Larochelle, H. and Hinton, G. E. (2010). Learning to combine foveal glimpses with a third-order Boltzmann machine. In Advances in Neural Information Processing Systems 23, pages 1243–1251. 427. Larochelle, H. and Murray, I. (2011). The Neural Autoregressive Distribution Esti-mator. In AISTATS’2011. 428. Larochelle, H., Erhan, D., and Bengio, Y. (2008). Zero-data learning of new tasks. In AAAI Conference on Artificial Intelligence. 429. Larochelle, H., Bengio, Y., Louradour, J., and Lamblin, P. (2009). Exploring strategies for training deep neural networks. Journal of Machine Learning Research, 10, 1–40. 430. Lasserre, J. A., Bishop, C. M., and Minka, T. P. (2006). Principled hybrids of genera-tive and discriminative models. In Proceedings of the Computer Vision and Pattern\n--- Страница 627 ---\n626  Список литературы Recognition Conference (CVPR’06), pages 87–94, Washington, DC, USA. IEEE Computer Society. 431. Le, Q., Ngiam, J., Chen, Z., hao Chia, D. J., Koh, P. W., and Ng, A. (2010). Tiled con-volutional neural networks. In J. Lafferty, C. K. I. Williams, J. Shawe-Taylor, R. Ze- mel, and A. Culotta, editors, Advances in Neural Information Processing Systems 23 (NIPS’10), pages 1279–1287. 432. Le, Q., Ngiam, J., Coates, A., Lahiri, A., Prochnow, B., and Ng, A. (2011). On optimi-zation methods for deep learning. In Proc. ICML’2011. ACM. 433. Le, Q., Ranzato, M., Monga, R., Devin, M., Corrado, G., Chen, K., Dean, J., and Ng, A. (2012). Building high-level features using large scale unsupervised learning. In ICML’2012. 434. Le Roux, N. and Bengio, Y. (2008). Representational power of restricted Boltzmann machines and deep belief networks. Neural Computation, 20(6), 1631–1649. 435. Le Roux, N. and Bengio, Y. (2010). Deep belief networks are compact universal ap-proximators. Neural Computation, 22(8), 2192–2207. 436. LeCun, Y. (1985). Une procedure d’apprentissage pour Reseau à seuil assymetrique. In Cognitiva 85: A la Frontière de l’Intelligence Artificielle, des Sciences de la Con-naissance et des Neurosciences, pages 599–604, Paris 1985. CESTA, Paris. 437. LeCun, Y. (1986). Learning processes in an asymmetric threshold network. In F. Fogelman-Soulie, E. Bienenstock, and G. Weisbuch, editors, Disordered Systems and Biological Organization, pages 233–240. Springer-Verlag, Les Houches, France. 438. LeCun, Y. (1987). Modèles connexionistes de l’apprentissage. Ph.D. thesis, Universite de Paris VI. 439. LeCun, Y. (1989). Generalization and network design strategies. Technical Report CRG-TR-89-4, University of Toronto. 440. LeCun, Y., Jackel, L. D., Boser, B., Denker, J. S., Graf, H. P., Guyon, I., Henderson, D., Howard, R. E., and Hubbard, W. (1989). Handwritten digit recognition: Ap-plications of neural network chips and automatic learning. IEEE Communications Magazine, 27(11), 41–46. 441. LeCun, Y., Bottou, L., Orr, G. B., and Müller, K.-R. (1998a). Efficient backprop. In Neural Networks, Tricks of the Trade, Lecture Notes in Computer Science LNCS 1524. Springer Verlag. 442. LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P. (1998b). Gradient based learning applied to document recognition. Proc. IEEE. 443. LeCun, Y., Kavukcuoglu, K., and Farabet, C. (2010). Convolutional networks and applications in vision. In Circuits and Systems (ISCAS), Proceedings of 2010 IEEE International Symposium on, pages 253–256. IEEE. 444. L’Ecuyer, P. (1994). Efficiency improvement and variance reduction. In Proceedings of the 1994 Winter Simulation Conference, pages 122–132. 445. Lee, C.-Y., Xie, S., Gallagher, P., Zhang, Z., and Tu, Z. (2014). Deeply-supervised nets. arXiv preprint arXiv:1409.5185. 446. Lee, H., Battle, A., Raina, R., and Ng, A. (2007). Efficient sparse coding algorithms. In B. Schölkopf, J. Platt, and T. Hoffman, editors, Advances in Neural Information Processing Systems 19 (NIPS’06), pages 801–808. MIT Press. 447. Lee, H., Ekanadham, C., and Ng, A. (2008). Sparse deep belief net model for visual area V2. In NIPS’07.\n--- Страница 628 ---\nЗаключение  627 448. Lee, H., Grosse, R., Ranganath, R., and Ng, A. Y. (2009). Convolutional deep be- lief networks for scalable unsupervised learning of hierarchical representations. In L. Bottou and M. Littman, editors, Proceedings of the Twenty-sixth International Conference on Machine Learning (ICML’09). ACM, Montreal, Canada. 449. Lee, Y. J. and Grauman, K. (2011). Learning the easy things first: self-paced visual category discovery. In CVPR’2011. 450. Leibniz, G. W. (1676). Memoir using the chain rule. (Cited in TMME 7:2&3 p 321–332, 2010). 451. Lenat, D. B. and Guha, R. V. (1989). Building large knowledge-based systems; rep-resentation and inference in the Cyc project. Addison-Wesley Longman Publishing Co., Inc. 452. Leshno, M., Lin, V. Y., Pinkus, A., and Schocken, S. (1993). Multilayer feedforward networks with a nonpolynomial activation function can approximate any function. Neural Networks, 6, 861–867. 453. Levenberg, K. (1944). A method for the solution of certain non-linear problems in least squares. Quarterly Journal of Applied Mathematics, II(2), 164–168. 454. L’Hôpital, G. F. A. (1696). Analyse des infiniment petits, pour l’intelligence des lignes courbes. Paris: L’Imprimerie Royale. 455. Li, Y., Swersky, K., and Zemel, R. S. (2015). Generative moment matching networks. CoRR, abs/1502.02761. 456. Lin, T., Horne, B. G., Tino, P., and Giles, C. L. (1996). Learning long-term dependen-cies is not as difficult with NARX recurrent neural networks. IEEE Transactions on Neural Networks, 7(6), 1329–1338. 457. Lin, Y., Liu, Z., Sun, M., Liu, Y., and Zhu, X. (2015). Learning entity and relation embeddings for knowledge graph completion. In Proc. AAAI’15. 458. Linde, N. (1992). The machine that changed the world, episode 3. Documentary miniseries. 459. Lindsey, C. and Lindblad, T. (1994). Review of hardware neural networks: a user’s perspective. In Proc. Third Workshop on Neural Networks: From Biology to High Energy Physics, pages 195–202, Isola d’Elba, Italy. 460. Linnainmaa, S. (1976). Taylor expansion of the accumulated rounding error. BIT Numerical Mathematics, 16(2), 146–160. 461. LISA (2008). Deep learning tutorials: Restricted Boltzmann machines. Technical report, LISA Lab, Universite de Montreal. 462. Long, P. M. and Servedio, R. A. (2010). Restricted Boltzmann machines are hard to approximately evaluate or simulate. In Proceedings of the 27th International Con-ference on Machine Learning (ICML’10). 463. Lotter, W., Kreiman, G., and Cox, D. (2015). Unsupervised learning of visual struc-ture using predictive generative networks. arXiv preprint arXiv:1511.06380. 464. Lovelace, A. (1842). Notes upon L. F. Menabrea’s «Sketch of the Analytical Engine invented by Charles Babbage». 465. Lu, L., Zhang, X., Cho, K., and Renals, S. (2015). A study of the recurrent neural net-work encoder-decoder for large vocabulary speech recognition. In Proc. Interspeech. 466. Lu, T., Pal, D., and Pal, M. (2010). Contextual multi-armed bandits. In International Conference on Artificial Intelligence and Statistics, pages 485–492. 467. Luenberger, D. G. (1984). Linear and Nonlinear Programming. Addison Wesley.\n--- Страница 629 ---\n628  Список литературы 468. Lukoševicius, M. and Jaeger, H. (2009). Reservoir computing approaches to recur- rent neural network training. Computer Science Review, 3(3), 127–149. 469. Luo, H., Shen, R., Niu, C., and Ullrich, C. (2011). Learning class-relevant features and class-irrelevant features via a hybrid third-order RBM. In International Confer-ence on Artificial Intelligence and Statistics, pages 470–478. 470. Luo, H., Carrier, P. L., Courville, A., and Bengio, Y. (2013). Texture modeling with convolutional spike-and-slab RBMs and deep extensions. In AISTATS’2013. 471. Lyu, S. (2009). Interpretation and generalization of score matching. In Proceedings of the Twenty-fifth Conference in Uncertainty in Artificial Intelligence (UAI’09). 472. Ma, J., Sheridan, R. P., Liaw, A., Dahl, G. E., and Svetnik, V. (2015). Deep neural nets as a method for quantitative structure – activity relationships. J. Chemical informa- tion and modeling. 473. Maas, A. L., Hannun, A. Y., and Ng, A. Y. (2013). Rectifier nonlinearities improve neural network acoustic models. In ICML Workshop on Deep Learning for Audio, Speech, and Language Processing. 474. Maass, W. (1992). Bounds for the computational power and learning complexity of analog neural nets (extended abstract). In Proc. of the 25th ACM Symp. Theory of Computing, pages 335–344. 475. Maass, W., Schnitger, G., and Sontag, E. D. (1994). A comparison of the compu-tational power of sigmoid and Boolean threshold circuits. Theoretical Advances in Neural Computation and Learning, pages 127–151. 476. Maass, W., Natschlaeger, T., and Markram, H. (2002). Real-time computing without stable states: A new framework for neural computation based on perturbations. Neu-ral Computation, 14(11), 2531–2560. 477. MacKay, D. (2003). Information Theory, Inference and Learning Algorithms. Cam-bridge University Press. 478. Maclaurin, D., Duvenaud, D., and Adams, R. P. (2015). Gradient-based hyperpa-rameter optimization through reversible learning. arXiv preprint arXiv:1502.03492. 479. Mao, J., Xu, W., Yang, Y., Wang, J., Huang, Z., and Yuille, A. L. (2015). Deep caption-ing with multimodal recurrent neural networks. In ICLR’2015. arXiv:1410.1090. 480. Marcotte, P. and Savard, G. (1992). Novel approaches to the discrimination problem. Zeitschrift für Operations Research (Theory), 36, 517–545. 481. Marlin, B. and de Freitas, N. (2011). Asymptotic efficiency of deterministic esti-mators for discrete energy-based models: Ratio matching and pseudolikelihood. In UAI’2011. 482. Marlin, B., Swersky, K., Chen, B., and de Freitas, N. (2010). Inductive principles for restricted Boltzmann machine learning. In Proceedings of The Thirteenth Interna-tional Conference on Artificial Intelligence and Statistics (AISTATS’10), volume 9, pages 509–516. 483. Marquardt, D. W. (1963). An algorithm for least-squares estimation of non-linear parameters. Journal of the Society of Industrial and Applied Mathematics, 11(2), 431–441. 484. Marr, D. and Poggio, T. (1976). Cooperative computation of stereo disparity. Sci-ence, 194. 485. Martens, J. (2010). Deep learning via Hessian-free optimization. In L. Bottou and M. Littman, editors, Proceedings of the Twenty-seventh International Conference on Machine Learning (ICML-10), pages 735–742. ACM.\n--- Страница 630 ---\nЗаключение  629 486. Martens, J. and Medabalimi, V. (2014). On the expressive efficiency of sum product networks. arXiv:1411.7717. 487. Martens, J. and Sutskever, I. (2011). Learning recurrent neural networks with Hes-sian-free optimization. In Proc. ICML’2011. ACM. 488. Mase, S. (1995). Consistency of the maximum pseudo-likelihood estimator of con-tinuous state space Gibbsian processes. The Annals of Applied Probability, 5(3), pp. 603–612. 489. McClelland, J., Rumelhart, D., and Hinton, G. (1995). The appeal of parallel distrib-uted processing. In Computation & intelligence, pages 305–341. American Associa-tion for Artificial Intelligence. 490. McCulloch, W. S. and Pitts, W. (1943). A logical calculus of ideas immanent in ner-vous activity. Bulletin of Mathematical Biophysics, 5, 115–133. 491. Mead, C. and Ismail, M. (2012). Analog VLSI implementation of neural systems, volume 80. Springer Science & Business Media. 492. Melchior, J., Fischer, A., and Wiskott, L. (2013). How to center binary deep Boltzmann machines. arXiv preprint arXiv:1311.1354. 493. Memisevic, R. and Hinton, G. E. (2007). Unsupervised learning of image transforma-tions. In Proceedings of the Computer Vision and Pattern Recognition Conference (CVPR’07). 494. Memisevic, R. and Hinton, G. E. (2010). Learning to represent spatial transforma-tions with factored higher-order Boltzmann machines. Neural Computation, 22(6), 1473–1492. 495. Mesnil, G., Dauphin, Y., Glorot, X., Rifai, S., Bengio, Y., Goodfellow, I., Lavoie, E., Muller, X., Desjardins, G., Warde-Farley, D., Vincent, P., Courville, A., and Bergstra, J. (2011). Unsupervised and transfer learning challenge: a deep learning approach. In JMLR W&CP: Proc. Unsupervised and Transfer Learning, volume 7. 496. Mesnil, G., Rifai, S., Dauphin, Y., Bengio, Y., and Vincent, P. (2012). Surfing on the manifold. Learning Workshop, Snowbird. 497. Miikkulainen, R. and Dyer, M. G. (1991). Natural language processing with modular PDP networks and distributed lexicon. Cognitive Science, 15, 343–399. 498. Mikolov, T. (2012). Statistical Language Models based on Neural Networks. Ph. D. thesis, Brno University of Technology. 499. Mikolov, T., Deoras, A., Kombrink, S., Burget, L., and Cernocky, J. (2011a). Empiri-cal evaluation and combination of advanced language modeling techniques. In Proc. 12 th annual conference of the international speech communication association (IN- TERSPEECH 2011). 500. Mikolov, T., Deoras, A., Povey, D., Burget, L., and Cernocky, J. (2011b). Strategies for training large scale neural network language models. In Proc. ASRU’2011. 501. Mikolov, T., Chen, K., Corrado, G., and Dean, J. (2013a). Efficient estimation of word representations in vector space. In International Conference on Learning Represen-tations: Workshops Track. 502. Mikolov, T., Le, Q. V., and Sutskever, I. (2013b). Exploiting similarities among lan-guages for machine translation. Technical report, arXiv:1309.4168. 503. Minka, T. (2005). Divergence measures and message passing. Microsoft Research Cambridge UK Tech Rep MSRTR2005173, 72(TR-2005-173). 504. Minsky, M. L. and Papert, S. A. (1969). Perceptrons. MIT Press, Cambridge.\n--- Страница 631 ---\n630  Список литературы 505. Mirza, M. and Osindero, S. (2014). Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784. 506. Mishkin, D. and Matas, J. (2015). All you need is a good init. arXiv preprint arX-iv:1511.06422. 507. Misra, J. and Saha, I. (2010). Artificial neural networks in hardware: A survey of two decades of progress. Neurocomputing, 74(1), 239–255. 508. Mitchell, T. M. (1997). Machine Learning. McGraw-Hill, New Y ork. 509. Miyato, T., Maeda, S., Koyama, M., Nakae, K., and Ishii, S. (2015). Distributional smoothing with virtual adversarial training. In ICLR. Preprint: arXiv:1507.00677. 510. Mnih, A. and Gregor, K. (2014). Neural variational inference and learning in belief networks. In ICML’2014. 511. Mnih, A. and Hinton, G. E. (2007). Three new graphical models for statistical lan-guage modelling. In Z. Ghahramani, editor, Proceedings of the Twenty-fourth Inter-national Conference on Machine Learning (ICML’07), pages 641–648. ACM. 512. Mnih, A. and Hinton, G. E. (2009). A scalable hierarchical distributed language model. In D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, Advances in Neural Information Processing Systems 21 (NIPS’08), pages 1081–1088. 513. Mnih, A. and Kavukcuoglu, K. (2013). Learning word embeddings efficiently with noisecontrastive estimation. In C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Weinberger, editors, Advances in Neural Information Processing Systems 26, pages 2265–2273. Curran Associates, Inc. 514. Mnih, A. and Teh, Y. W. (2012). A fast and simple algorithm for training neural prob-abilistic language models. In ICML’2012, pages 1751–1758. 515. Mnih, V. and Hinton, G. (2010). Learning to detect roads in high-resolution aer-ial images. In Proceedings of the 11th European Conference on Computer Vision (ECCV). 516. Mnih, V., Larochelle, H., and Hinton, G. (2011). Conditional restricted Boltzmann machines for structure output prediction. In Proc. Conf. on Uncertainty in Artificial Intelligence (UAI). 517. Mnih, V., Kavukcuoglo, K., Silver, D., Graves, A., Antonoglou, I., and Wierstra, D. (2013). Playing Atari with deep reinforcement learning. Technical report, arXiv: 1312.5602. 518. Mnih, V., Heess, N., Graves, A., and Kavukcuoglu, K. (2014). Recurrent models of vi-sual attention. In Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K. Wein-berger, editors, NIPS’2014, pages 2204–2212. 519. Mnih, V., Kavukcuoglo, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., Graves, A., Riedmiller, M., Fidgeland, A. K., Ostrovski, G., Petersen, S., Beattie, C., Sadik, A., Antonoglou, I., King, H., Kumaran, D., Wierstra, D., Legg, S., and Has-sabis, D. (2015). Human-level control through deep reinforcement learning. Nature, 518, 529–533. 520. Mobahi, H. and Fisher, III, J. W. (2015). A theoretical analysis of optimization by Gaussian continuation. In AAAI’2015. 521. Mobahi, H., Collobert, R., and Weston, J. (2009). Deep learning from temporal co-herence in video. In L. Bottou and M. Littman, editors, Proceedings of the 26 th In- ternational Conference on Machine Learning, pages 737–744, Montreal. Omnipress. 522. Mohamed, A., Dahl, G., and Hinton, G. (2009). Deep belief networks for phone re-cognition.\n--- Страница 632 ---\nЗаключение  631 523. Mohamed, A., Sainath, T. N., Dahl, G., Ramabhadran, B., Hinton, G. E., and Piche- ny, M. A. (2011). Deep belief networks using discriminative features for phone re- cognition. In Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE Inter-national Conference on, pages 5060–5063. IEEE. 524. Mohamed, A., Dahl, G., and Hinton, G. (2012a). Acoustic modeling using deep belief networks. IEEE Trans. on Audio, Speech and Language Processing, 20(1), 14–22. 525. Mohamed, A., Hinton, G., and Penn, G. (2012b). Understanding how deep belief networks perform acoustic modelling. In Acoustics, Speech and Signal Processing (ICASSP), 2012 IEEE International Conference on, pages 4273–4276. IEEE. 526. Moller, M. F. (1993). A scaled conjugate gradient algorithm for fast supervised learn-ing. Neural Networks, 6, 525–533. 527. Montavon, G. and Muller, K.-R. (2012). Deep Boltzmann machines and the center-ing trick. In G. Montavon, G. Orr, and K.-R. Müller, editors, Neural Networks: Tricks of the Trade, volume 7700 of Lecture Notes in Computer Science, pages 621–637. Preprint: http://arxiv.org/abs/1203.3783. 528. Montufar, G. (2014). Universal approximation depth and errors of narrow belief net-works with discrete units. Neural Computation, 26. 529. Montufar, G. and Ay, N. (2011). Refinements of universal approximation results for deep belief networks and restricted Boltzmann machines. Neural Computation, 23(5), 1306–1319. 530. Montufar, G. F., Pascanu, R., Cho, K., and Bengio, Y. (2014). On the number of linear regions of deep neural networks. In NIPS’2014. 531. Mor-Y osef, S., Samueloff, A., Modan, B., Navot, D., and Schenker, J. G. (1990). Rank-ing the risk factors for cesarean: logistic regression analysis of a nationwide study. Obstet Gynecol, 75(6), 944–7. 532. Morin, F. and Bengio, Y. (2005). Hierarchical probabilistic neural network language model. In AISTATS’2005. 533. Mozer, M. C. (1992). The induction of multiscale temporal structure. In J. M. S. Han- son and R. Lippmann, editors, Advances in Neural Information Processing Systems 4 (NIPS’91), pages 275–282, San Mateo, CA. Morgan Kaufmann. 534. Murphy, K. P. (2012). Machine Learning: a Probabilistic Perspective. MIT Press, Cambridge, MA, USA. 535. Murray, B. U. I. and Larochelle, H. (2014). A deep and tractable density estimator. In ICML’2014. 536. Nair, V. and Hinton, G. (2010). Rectified linear units improve restricted Boltzmann machines. In ICML’2010. 537. Nair, V. and Hinton, G. E. (2009). 3d object recognition with deep belief nets. In Y. Bengio, D. Schuurmans, J. D. Lafferty, C. K. I. Williams, and A. Culotta, editors, Advances in Neural Information Processing Systems 22, pages 1339–1347. Curran Associates, Inc. 538. Narayanan, H. and Mitter, S. (2010). Sample complexity of testing the manifold hy-pothesis. In NIPS’2010. 539. Naumann, U. (2008). Optimal Jacobian accumulation is NP-complete. Mathemati-cal Programming, 112(2), 427–441. 540. Navigli, R. and Velardi, P. (2005). Structural semantic interconnections: a knowl-edge-based approach to word sense disambiguation. IEEE Trans. Pattern Analysis and Machine Intelligence, 27(7), 1075–1086.\n--- Страница 633 ---\n632  Список литературы 541. Neal, R. and Hinton, G. (1999). A view of the EM algorithm that justifies incremen- tal, sparse, and other variants. In M. I. Jordan, editor, Learning in Graphical Models. MIT Press, Cambridge, MA. 542. Neal, R. M. (1990). Learning stochastic feedforward networks. Technical report. 543. Neal, R. M. (1993). Probabilistic inference using Markov chain Monte-Carlo me-thods. Technical Report CRG-TR-93-1, Dept. of Computer Science, University of Toronto. 544. Neal, R. M. (1994). Sampling from multimodal distributions using tempered transi-tions. Technical Report 9421, Dept. of Statistics, University of Toronto. 545. Neal, R. M. (1996). Bayesian Learning for Neural Networks. Lecture Notes in Sta-tistics. Springer. 546. Neal, R. M. (2001). Annealed importance sampling. Statistics and Computing, 11(2), 125–139. 547. Neal, R. M. (2005). Estimating ratios of normalizing constants using linked impor-tance sampling. 548. Nesterov, Y. (1983). A method of solving a convex programming problem with con-vergence rate O(1/k2). Soviet Mathematics Doklady, 27, 372–376. 549. Nesterov, Y. (2004). Introductory lectures on convex optimization : a basic course. Applied optimization. Kluwer Academic Publ., Boston, Dordrecht, London. 550. Netzer, Y.,Wang, T., Coates, A., Bissacco, A.,Wu, B., and Ng, A. Y. (2011). Reading digits in natural images with unsupervised feature learning. Deep Learning and Un-supervised Feature Learning Workshop, NIPS. 551. Ney, H. and Kneser, R. (1993). Improved clustering techniques for class-based sta-tistical language modelling. In European Conference on Speech Communication and Technology (Eurospeech), pages 973–976, Berlin. 552. Ng, A. (2015). Advice for applying machine learning. https://see.stanford.edu/ materials/aimlcs229/ML-advice.pdf. 553. Niesler, T. R., Whittaker, E. W. D., and Woodland, P. C. (1998). Comparison of part-ofspeech and automatically derived category-based language models for speech re-cognition. In International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 177–180. 554. Ning, F., Delhomme, D., LeCun, Y., Piano, F., Bottou, L., and Barbano, P. E. (2005). Toward automatic phenotyping of developing embryos from videos. Image Proces-sing, IEEE Transactions on, 14(9), 1360–1371. 555. Nocedal, J. and Wright, S. (2006). Numerical Optimization. Springer. 556. Norouzi, M. and Fleet, D. J. (2011). Minimal loss hashing for compact binary codes. In ICML’2011. 557. Nowlan, S. J. (1990). Competing experts: An experimental investigation of associa-tive mixture models. Technical Report CRG-TR-90-5, University of Toronto. 558. Nowlan, S. J. and Hinton, G. E. (1992). Simplifying neural networks by soft weight-sharing. Neural Computation, 4(4), 473–493. 559. Olshausen, B. and Field, D. J. (2005). How close are we to understanding V1? Neural Computation, 17, 1665–1699. 560. Olshausen, B. A. and Field, D. J. (1996). Emergence of simple-cell receptive field properties by learning a sparse code for natural images. Nature, 381, 607–609. 561. Olshausen, B. A., Anderson, C. H., and Van Essen, D. C. (1993). A neurobiological model of visual attention and invariant pattern recognition based on dynamic rou-ting of information. J. Neurosci., 13(11), 4700–4719.\n--- Страница 634 ---\nЗаключение  633 562. Opper, M. and Archambeau, C. (2009). The variational Gaussian approximation re- visited. Neural computation, 21(3), 786–792. 563. Oquab, M., Bottou, L., Laptev, I., and Sivic, J. (2014). Learning and transferring mid-level image representations using convolutional neural networks. In Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 1717–1724. IEEE. 564. Osindero, S. and Hinton, G. E. (2008). Modeling image patches with a directed hie rarchy of Markov random fields. In J. Platt, D. Koller, Y. Singer, and S. Ro weis, editors, Advances in Neural Information Processing Systems 20 (NIPS’07), pa-ges 1121–1128, Cambridge, MA. MIT Press. 565. Ovid and Martin, C. (2004). Metamorphoses. W.W. Norton. 566. Paccanaro, A. and Hinton, G. E. (2000). Extracting distributed representations of concepts and relations from positive and negative propositions. In International Joint Conference on Neural Networks (IJCNN), Como, Italy. IEEE, New Y ork. 567. Paine, T. L., Khorrami, P., Han, W., and Huang, T. S. (2014). An analysis of unsuper-vised pre-training in light of recent advances. arXiv preprint arXiv:1412.6597. 568. Palatucci, M., Pomerleau, D., Hinton, G. E., and Mitchell, T. M. (2009). Zero-shot learning with semantic output codes. In Y. Bengio, D. Schuurmans, J. D. Lafferty, C. K. I. Williams, and A. Culotta, editors, Advances in Neural Information Process- ing Systems 22, pages 1410–1418. Curran Associates, Inc. 569. Parker, D. B. (1985). Learning-logic. Technical Report TR-47, Center for Comp. Re-search in Economics and Management Sci., MIT. 570. Pascanu, R., Mikolov, T., and Bengio, Y. (2013). On the difficulty of training recur-rent neural networks. In ICML’2013. 571. Pascanu, R., Gülçehre, Ç., Cho, K., and Bengio, Y. (2014a). How to construct deep recurrent neural networks. In ICLR’2014. 572. Pascanu, R., Montufar, G., and Bengio, Y. (2014b). On the number of inference re-gions of deep feed forward networks with piece-wise linear activations. In ICLR’2014. 573. Pati, Y., Rezaiifar, R., and Krishnaprasad, P. (1993). Orthogonal matching pursuit: Recursive function approximation with applications to wavelet decomposition. In Proceedings of the 27 th Annual Asilomar Conference on Signals, Systems, and Com-puters, pages 40–44. 574. Pearl, J. (1985). Bayesian networks: A model of self-activated memory for evidential reasoning. In Proceedings of the 7th Conference of the Cognitive Science Society, University of California, Irvine, pages 329–334. 575. Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plau-sible Inference. Morgan Kaufmann. 576. Perron, O. (1907). Zur theorie der matrices. Mathematische Annalen, 64(2), 248–263. 577. Petersen, K. B. and Pedersen, M. S. (2006). The matrix cookbook. Version 20051003. 578. Peterson, G. B. (2004). A day of great illumination: B. F. Skinner’s discovery of shap-ing. Journal of the Experimental Analysis of Behavior, 82(3), 317–328. 579. Pham, D.-T., Garat, P., and Jutten, C. (1992). Separation of a mixture of independent sources through a maximum likelihood approach. In EUSIPCO, pages 771–774. 580. Pham, P.-H., Jelaca, D., Farabet, C., Martini, B., LeCun, Y., and Culurciello, E. (2012). NeuFlow: dataflow vision processing system-on-a-chip. In Circuits and Sys-tems (MWSCAS), 2012 IEEE 55th International Midwest Symposium on, pages 1044–1047. IEEE.\n--- Страница 635 ---\n634  Список литературы 581. Pinheiro, P. H. O. and Collobert, R. (2014). Recurrent convolutional neural net- works for scene labeling. In ICML’2014. 582. Pinheiro, P. H. O. and Collobert, R. (2015). From image-level to pixel-level label-ing with convolutional networks. In Conference on Computer Vision and Pattern Recognition (CVPR). 583. Pinto, N., Cox, D. D., and DiCarlo, J. J. (2008). Why is real-world visual object rec-ognition hard? PLoS Comput Biol, 4. 584. Pinto, N., Stone, Z., Zickler, T., and Cox, D. (2011). Scaling up biologically-inspired computer vision: A case study in unconstrained face recognition on facebook. In Computer Vision and Pattern Recognition Workshops (CVPRW), 2011 IEEE Computer Society Conference on, pages 35–42. IEEE. 585. Pollack, J. B. (1990). Recursive distributed representations. Artificial Intelligence, 46(1), 77–105. 586. Polyak, B. and Juditsky, A. (1992). Acceleration of stochastic approximation by av-eraging. SIAM J. Control and Optimization, 30(4), 838–855. 587. Polyak, B. T. (1964). Some methods of speeding up the convergence of iteration methods. USSR Computational Mathematics and Mathematical Physics, 4(5), 1–17. 588. Poole, B., Sohl-Dickstein, J., and Ganguli, S. (2014). Analyzing noise in autoenco-ders and deep networks. CoRR, abs/1406.1831. 589. Poon, H. and Domingos, P. (2011). Sum-product networks: A new deep architecture. In Proceedings of the Twenty-seventh Conference in Uncertainty in Artificial Intel-ligence (UAI), Barcelona, Spain. 590. Presley, R. K. and Haggard, R. L. (1994). A fixed point implementation of the back-propagation learning algorithm. In Southeastcon’94. Creative Technology Transfer-A Global Affair., Proceedings of the 1994 IEEE, pages 136–138. IEEE. 591. Price, R. (1958). A useful theorem for nonlinear devices having Gaussian inputs. IEEE Transactions on Information Theory, 4(2), 69–72. 592. Quiroga, R. Q., Reddy, L., Kreiman, G., Koch, C., and Fried, I. (2005). Invariant visual representation by single neurons in the human brain. Nature, 435(7045), 1102–1107. 593. Radford, A., Metz, L., and Chintala, S. (2015). Unsupervised representation learn-ing with deep convolutional generative adversarial networks. arXiv preprint arXiv: 1511.06434. 594. Raiko, T., Yao, L., Cho, K., and Bengio, Y. (2014). Iterative neural autoregressive distribution estimator (NADE-k). Technical report, arXiv:1406.1485. 595. Raina, R., Madhavan, A., and Ng, A. Y. (2009). Large-scale deep unsupervised learn-ing using graphics processors. In L. Bottou and M. Littman, editors, Proceedings of the Twenty-sixth International Conference on Machine Learning (ICML’09), pages 873–880, New Y ork, NY, USA. ACM. 596. Ramsey, F. P. (1926). Truth and probability. In R. B. Braithwaite, editor, The Foun-dations of Mathematics and other Logical Essays, chapter 7, pages 156–198. McMas-ter University Archive for the History of Economic Thought. 597. Ranzato, M. and Hinton, G. H. (2010). Modeling pixel means and covariances using factorized third-order Boltzmann machines. In CVPR’2010, pages 2551–2558. 598. Ranzato, M., Poultney, C., Chopra, S., and LeCun, Y. (2007a). Efficient learning of sparse representations with an energy-based model. In NIPS’2006. 599. Ranzato, M., Huang, F., Boureau, Y., and LeCun, Y. (2007b). Unsupervised learn-ing of invariant feature hierarchies with applications to object recognition. In Pro-\n--- Страница 636 ---\nЗаключение  635 ceedings of the Computer Vision and Pattern Recognition Conference (CVPR’07). IEEE Press. 600. Ranzato, M., Boureau, Y., and LeCun, Y. (2008). Sparse feature learning for deep belief networks. In NIPS’2007. 601. Ranzato, M., Krizhevsky, A., and Hinton, G. E. (2010a). Factored 3-way restricted Boltzmann machines for modeling natural images. In Proceedings of AISTATS 2010. 602. Ranzato, M., Mnih, V., and Hinton, G. (2010b). Generating more realistic images using gated MRFs. In NIPS’2010. 603. Rao, C. (1945). Information and the accuracy attainable in the estimation of statisti-cal parameters. Bulletin of the Calcutta Mathematical Society, 37, 81–89. 604. Rasmus, A., Valpola, H., Honkala, M., Berglund, M., and Raiko, T. (2015). Semi-supervised learning with ladder network. arXiv preprint arXiv:1507.02672. 605. Recht, B., Re, C., Wright, S., and Niu, F. (2011). Hogwild: A lock-free approach to parallelizing stochastic gradient descent. In NIPS’2011. 606. Reichert, D. P., Seriès, P., and Storkey, A. J. (2011). Neuronal adaptation for sampling based probabilistic inference in perceptual bistability. In Advances in Neural Infor-mation Processing Systems, pages 2357–2365. 607. Rezende, D. J., Mohamed, S., and Wierstra, D. (2014). Stochastic backpropaga-tion and approximate inference in deep generative models. In ICML’2014. Preprint: arXiv:1401.4082. 608. Rifai, S., Vincent, P., Muller, X., Glorot, X., and Bengio, Y. (2011a). Contractive au-to-encoders: Explicit invariance during feature extraction. In ICML’2011. 609. Rifai, S., Mesnil, G., Vincent, P., Muller, X., Bengio, Y., Dauphin, Y., and Glorot, X. (2011b). Higher order contractive auto-encoder. In ECML PKDD. 610. Rifai, S., Dauphin, Y., Vincent, P., Bengio, Y., and Muller, X. (2011c). The manifold tangent classifier. In NIPS’2011. 611. Rifai, S., Bengio, Y., Dauphin, Y., and Vincent, P. (2012). A generative process for sampling contractive auto-encoders. In ICML’2012. 612. Ringach, D. and Shapley, R. (2004). Reverse correlation in neurophysiology. Cogni-tive Science, 28(2), 147–166. 613. Roberts, S. and Everson, R. (2001). Independent component analysis: principles and practice. Cambridge University Press. 614. Robinson, A. J. and Fallside, F. (1991). A recurrent error propagation network speech recognition system. Computer Speech and Language, 5(3), 259–274. 615. Rockafellar, R. T. (1997). Convex analysis. princeton landmarks in mathematics. 616. Romero, A., Ballas, N., Ebrahimi Kahou, S., Chassang, A., Gatta, C., and Bengio, Y. (2015). Fitnets: Hints for thin deep nets. In ICLR’2015, arXiv:1412.6550. 617. Rosen, J. B. (1960). The gradient projection method for nonlinear programming. Part I. Linear constraints. Journal of the Society for Industrial and Applied Math-ematics, 8(1), pp. 181–217. 618. Rosenblatt, F. (1958). The perceptron: A probabilistic model for information storage and organization in the brain. Psychological Review, b, 386–408. 619. Rosenblatt, F. (1962). Principles of Neurodynamics. Spartan, New Y ork. 620. Roweis, S. and Saul, L. K. (2000). Nonlinear dimensionality reduction by locally linear embedding. Science, 290(5500). 621. Roweis, S., Saul, L., and Hinton, G. (2002). Global coordination of local linear mod-els. In T. Dietterich, S. Becker, and Z. Ghahramani, editors, Advances in Neural In-formation Processing Systems 14 (NIPS’01), Cambridge, MA. MIT Press.\n--- Страница 637 ---\n636  Список литературы 622. Rubin, D. B. et al. (1984). Bayesianly justifiable and relevant frequency calculations for the applied statistician. The Annals of Statistics, 12(4), 1151–1172. 623. Rumelhart, D., Hinton, G., and Williams, R. (1986a). Learning representations by back-propagating errors. Nature, 323, 533–536. 624. Rumelhart, D. E., Hinton, G. E., and Williams, R. J. (1986b). Learning internal rep-resentations by error propagation. In D. E. Rumelhart and J. L. McClelland, editors, Parallel Distributed Processing, volume 1, chapter 8, pages 318–362. MIT Press, Cambridge. 625. Rumelhart, D. E., McClelland, J. L., and the PDP Research Group (1986c). Paral-lel Distributed Processing: Explorations in the Microstructure of Cognition. MIT Press, Cambridge. 626. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Kar-pathy, A., Khosla, A., Bernstein, M., Berg, A. C., and Fei-Fei, L. (2014a). ImageNet Large Scale Visual Recognition Challenge. 627. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpa-thy, A., Khosla, A., Bernstein, M., et al. (2014b). Imagenet large scale visual recogni-tion challenge. arXiv preprint arXiv:1409.0575. 628. Russel, S. J. and Norvig, P. (2003). Artificial Intelligence: a Modern Approach. Pren-tice Hall. 629. Rust, N., Schwartz, O., Movshon, J. A., and Simoncelli, E. (2005). Spatiotemporal elements of macaque V1 receptive fields. Neuron, 46(6), 945–956. 630. Sainath, T., Mohamed, A., Kingsbury, B., and Ramabhadran, B. (2013). Deep convo-lutional neural networks for LVCSR. In ICASSP 2013. 631. Salakhutdinov, R. (2010). Learning in Markov random fields using tempered transi-tions. In Y. Bengio, D. Schuurmans, C. Williams, J. Lafferty, and A. Culotta, editors, Advances in Neural Information Processing Systems 22 (NIPS’09). 632. Salakhutdinov, R. and Hinton, G. (2009a). Deep Boltzmann machines. In Procee-dings of the International Conference on Artificial Intelligence and Statistics, vo-lume 5, pages 448–455. 633. Salakhutdinov, R. and Hinton, G. (2009b). Semantic hashing. In International Jour-nal of Approximate Reasoning. 634. Salakhutdinov, R. and Hinton, G. E. (2007a). Learning a nonlinear embedding by preserving class neighbourhood structure. In Proceedings of the Eleventh Interna-tional Conference on Artificial Intelligence and Statistics (AISTATS’07), San Juan, Porto Rico. Omnipress. 635. Salakhutdinov, R. and Hinton, G. E. (2007b). Semantic hashing. In SIGIR’2007. 636. Salakhutdinov, R. and Hinton, G. E. (2008). Using deep belief nets to learn covari-ance kernels for Gaussian processes. In J. Platt, D. Koller, Y. Singer, and S. Roweis, editors, Advances in Neural Information Processing Systems 20 (NIPS’07), pages 1249–1256, Cambridge, MA. MIT Press. 637. Salakhutdinov, R. and Larochelle, H. (2010). Efficient learning of deep Boltzmann machines. In Proceedings of the Thirteenth International Conference on Artificial In-telligence and Statistics (AISTATS 2010), JMLR W&CP , volume 9, pages 693–700. 638. Salakhutdinov, R. and Mnih, A. (2008). Probabilistic matrix factorization. In NIPS’2008. 639. Salakhutdinov, R. and Murray, I. (2008). On the quantitative analysis of deep belief networks. In W. W. Cohen, A. McCallum, and S. T. Roweis, editors, Proceedings of\n--- Страница 638 ---\nЗаключение  637 the Twenty-fifth International Conference on Machine Learning (ICML’08), volu- me 25, pages 872–879. ACM. 640. Salakhutdinov, R., Mnih, A., and Hinton, G. (2007). Restricted Boltzmann machines for collaborative filtering. In ICML. 641. Sanger, T. D. (1994). Neural network learning control of robot manipulators using gradually increasing task difficulty. IEEE Transactions on Robotics and Automation, 10(3). 642. Saul, L. K. and Jordan, M. I. (1996). Exploiting tractable substructures in intractable networks. In D. Touretzky, M. Mozer, and M. Hasselmo, editors, Advances in Neural Information Processing Systems 8 (NIPS’95). MIT Press, Cambridge, MA. 643. Saul, L. K., Jaakkola, T., and Jordan, M. I. (1996). Mean field theory for sigmoid belief networks. Journal of Artificial Intelligence Research, 4, 61–76. 644. Savich, A. W., Moussa, M., and Areibi, S. (2007). The impact of arithmetic represen-tation on implementing mlp-bp on fpgas: A study. Neural Networks, IEEE Transac-tions on, 18(1), 240–252. 645. Saxe, A. M., Koh, P. W., Chen, Z., Bhand, M., Suresh, B., and Ng, A. (2011). On ran-dom weights and unsupervised feature learning. In Proc. ICML’2011. ACM. 646. Saxe, A. M., McClelland, J. L., and Ganguli, S. (2013). Exact solutions to the nonlin-ear dynamics of learning in deep linear neural networks. In ICLR. 647. Schaul, T., Antonoglou, I., and Silver, D. (2014). Unit tests for stochastic optimiza-tion. In International Conference on Learning Representations. 648. Schmidhuber, J. (1992). Learning complex, extended sequences using the principle of history compression. Neural Computation, 4(2), 234–242. 649. Schmidhuber, J. (1996). Sequential neural text compression. IEEE Transactions on Neural Networks, 7(1), 142–146. 650. Schmidhuber, J. (2012). Self-delimiting neural networks. arXiv preprint arX-iv:1210.0118. 651. Schölkopf, B. and Smola, A. J. (2002). Learning with kernels: Support vector ma-chines, regularization, optimization, and beyond. MIT Press. 652. Schölkopf, B., Smola, A., and Müller, K.-R. (1998). Nonlinear component analysis as a kernel eigenvalue problem. Neural Computation, 10, 1299–1319. 653. Schölkopf, B., Burges, C. J. C., and Smola, A. J. (1999). Advances in Kernel Me-thods – Support Vector Learning. MIT Press, Cambridge, MA. 654. Schölkopf, B., Janzing, D., Peters, J., Sgouritsa, E., Zhang, K., and Mooij, J. (2012). On causal and anticausal learning. In ICML’2012, pages 1255–1262. 655. Schuster, M. (1999). On supervised learning from sequential data with applications for speech recognition. 656. Schuster, M. and Paliwal, K. (1997). Bidirectional recurrent neural networks. IEEE Transactions on Signal Processing, 45(11), 2673–2681. 657. Schwenk, H. (2007). Continuous space language models. Computer speech and lan-guage, 21, 492–518. 658. Schwenk, H. (2010). Continuous space language models for statistical machine translation. The Prague Bulletin of Mathematical Linguistics, 93, 137–146. 659. Schwenk, H. (2014). Cleaned subset of WMT ’14 dataset. 660. Schwenk, H. and Bengio, Y. (1998). Training methods for adaptive boosting of neural networks. In M. Jordan, M. Kearns, and S. Solla, editors, Advances in Neural Infor-mation Processing Systems 10 (NIPS’97), pages 647–653. MIT Press.\n--- Страница 639 ---\n638  Список литературы 661. Schwenk, H. and Gauvain, J.-L. (2002). Connectionist language modeling for large vocabulary continuous speech recognition. In International Conference on Acous-tics, Speech and Signal Processing (ICASSP), pages 765–768, Orlando, Florida. 662. Schwenk, H., Costa-jussà, M. R., and Fonollosa, J. A. R. (2006). Continuous space language models for the IWSLT 2006 task. In International Workshop on Spoken Language Translation, pages 166–173. 663. Seide, F., Li, G., and Yu, D. (2011). Conversational speech transcription using con-textdependent deep neural networks. In Interspeech 2011, pages 437–440. 664. Sejnowski, T. (1987). Higher-order Boltzmann machines. In AIP Conference Pro-ceedings 151 on Neural Networks for Computing, pages 398–403. American Insti-tute of Physics Inc. 665. Series, P., Reichert, D. P., and Storkey, A. J. (2010). Hallucinations in Charles Bonnet syndrome induced by homeostasis: a deep Boltzmann machine model. In Advances in Neural Information Processing Systems, pages 2020–2028. 666. Sermanet, P., Chintala, S., and LeCun, Y. (2012). Convolutional neural networks app lied to house numbers digit classification. CoRR, abs/1204.3968. 667. Sermanet, P., Kavukcuoglu, K., Chintala, S., and LeCun, Y. (2013). Pedestrian detec-tion with unsupervised multi-stage feature learning. In Proc. International Confe-rence on Computer Vision and Pattern Recognition (CVPR’13). IEEE. 668. Shilov, G. (1977). Linear Algebra. Dover Books on Mathematics Series. Dover Pub-lications. 669. Siegelmann, H. (1995). Computation beyond the Turing limit. Science, 268(5210), 545–548. 670. Siegelmann, H. and Sontag, E. (1991). Turing computability with neural nets. App-lied Mathematics Letters, 4(6), 77–80. 671. Siegelmann, H. T. and Sontag, E. D. (1995). On the computational power of neural nets. Journal of Computer and Systems Sciences, 50(1), 132–150. 672. Sietsma, J. and Dow, R. (1991). Creating artificial neural networks that generalize. Neural Networks, 4(1), 67–79. 673. Simard, D., Steinkraus, P. Y., and Platt, J. C. (2003). Best practices for convolutional neural networks. In ICDAR’2003. 674. Simard, P. and Graf, H. P. (1994). Backpropagation without multiplication. In Ad-vances in Neural Information Processing Systems, pages 232–239. 675. Simard, P., Victorri, B., LeCun, Y., and Denker, J. (1992). Tangent prop – A formal- ism for specifying selected invariances in an adaptive network. In NIPS’1991. 676. Simard, P. Y., LeCun, Y., and Denker, J. (1993). Efficient pattern recognition using a new transformation distance. In NIPS’92. 677. Simard, P. Y., LeCun, Y. A., Denker, J. S., and Victorri, B. (1998). Transformation in-variance in pattern recognition – tangent distance and tangent propagation. Lecture Notes in Computer Science, 1524. 678. Simons, D. J. and Levin, D. T. (1998). Failure to detect changes to people during a real-world interaction. Psychonomic Bulletin & Review, 5(4), 644–649. 679. Simonyan, K. and Zisserman, A. (2015). Very deep convolutional networks for large-scale image recognition. In ICLR. 680. Sjöberg, J. and Ljung, L. (1995). Overtraining, regularization and searching for a mi-nimum, with application to neural networks. International Journal of Control, 62(6), 1391–1407.\n--- Страница 640 ---\nЗаключение  639 681. Skinner, B. F. (1958). Reinforcement today. American Psychologist, 13, 94–99. 682. Smolensky, P. (1986). Information processing in dynamical systems: Foundations of harmony theory. In D. E. Rumelhart and J. L. McClelland, editors, Parallel Distrib-uted Processing, volume 1, chapter 6, pages 194–281. MIT Press, Cambridge. 683. Snoek, J., Larochelle, H., and Adams, R. P. (2012). Practical Bayesian optimization of machine learning algorithms. In NIPS’2012. 684. Socher, R., Huang, E. H., Pennington, J., Ng, A. Y., and Manning, C. D. (2011a). Dynamic pooling and unfolding recursive autoencoders for paraphrase detection. In NIPS’2011. 685. Socher, R., Manning, C., and Ng, A. Y. (2011b). Parsing natural scenes and natural language with recursive neural networks. In Proceedings of the Twenty-Eighth In-ternational Conference on Machine Learning (ICML’2011). 686. Socher, R., Pennington, J., Huang, E. H., Ng, A. Y., and Manning, C. D. (2011c). Semi-supervised recursive autoencoders for predicting sentiment distributions. In EMNLP’2011. 687. Socher, R., Perelygin, A., Wu, J. Y., Chuang, J., Manning, C. D., Ng, A. Y., and Potts, C. (2013a). Recursive deep models for semantic compositionality over a sentiment treebank. In EMNLP’2013. 688. Socher, R., Ganjoo, M., Manning, C. D., and Ng, A. Y. (2013b). Zero-shot learning through cross-modal transfer. In 27th Annual Conference on Neural Information Processing Systems (NIPS 2013). 689. Sohl-Dickstein, J., Weiss, E. A., Maheswaranathan, N., and Ganguli, S. (2015). Deep unsupervised learning using nonequilibrium thermodynamics. 690. Sohn, K., Zhou, G., and Lee, H. (2013). Learning and selecting features jointly with point-wise gated Boltzmann machines. In ICML’2013. 691. Solomonoff, R. J. (1989). A system for incremental learning based on algorithmic probability. 692. Sontag, E. D. (1998). VC dimension of neural networks. NATO ASI Series F Com-puter and Systems Sciences, 168, 69–96. 693. Sontag, E. D. and Sussman, H. J. (1989). Backpropagation can give rise to spu-rious local minima even for networks without hidden layers. Complex Systems, 3, 91–106. 694. Sparkes, B. (1996). The Red and the Black: Studies in Greek Pottery. Routledge. 695. Spitkovsky, V. I., Alshawi, H., and Jurafsky, D. (2010). From baby steps to leapfrog: how “less is more” in unsupervised dependency parsing. In HLT’10. 696. Squire, W. and Trapp, G. (1998). Using complex variables to estimate derivatives of real functions. SIAM Rev., 40(1), 110–112. 697. Srebro, N. and Shraibman, A. (2005). Rank, trace-norm and max-norm. In Proceed-ings of the 18th Annual Conference on Learning Theory, pages 545–560. Springer-Verlag. 698. Srivastava, N. (2013). Improving Neural Networks With Dropout. Master’s thesis, U. Toronto. 699. Srivastava, N. and Salakhutdinov, R. (2012). Multimodal learning with deep Boltz-mann machines. In NIPS’2012. 700. Srivastava, N., Salakhutdinov, R. R., and Hinton, G. E. (2013). Modeling documents with deep Boltzmann machines. arXiv preprint arXiv:1309.6865.\n--- Страница 641 ---\n640  Список литературы 701. Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. (2014). Dropout: A simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15, 1929–1958. 702. Srivastava, R. K., Greff, K., and Schmidhuber, J. (2015). Highway networks. arXiv: 1505.00387. 703. Steinkrau, D., Simard, P. Y., and Buck, I. (2005). Using GPUs for machine learning algorithms. 2013 12th International Conference on Document Analysis and Recog-nition, 0, 1115–1119. 704. Stoyanov, V., Ropson, A., and Eisner, J. (2011). Empirical risk minimization of gra-phical model parameters given approximate inference, decoding, and model structure. In Proceedings of the 14th International Conference on Artificial Intelligence and Statistics (AISTATS), volume 15 of JMLR Workshop and Conference Proceedings, pages 725–733, Fort Lauderdale. Supplementary material (4 pages) also available. 705. Sukhbaatar, S., Szlam, A., Weston, J., and Fergus, R. (2015). Weakly supervised me-mory networks. arXiv preprint arXiv:1503.08895. 706. Supancic, J. and Ramanan, D. (2013). Self-paced learning for long-term tracking. In CVPR’2013. 707. Sussillo, D. (2014). Random walks: Training very deep nonlinear feed-forward net-works with smart initialization. CoRR, abs/1412.6558. 708. Sutskever, I. (2012). Training Recurrent Neural Networks. Ph.D. thesis, Department of computer science, University of Toronto. 709. Sutskever, I. and Hinton, G. E. (2008). Deep narrow sigmoid belief networks are universal approximators. Neural Computation, 20(11), 2629–2636. 710. Sutskever, I. and Tieleman, T. (2010). On the Convergence Properties of Contras-tive Divergence. In Y. W. Teh and M. Titterington, editors, Proc. of the Interna-tional Conference on Artificial Intelligence and Statistics (AISTATS), volume 9, pages 789–795. 711. Sutskever, I., Hinton, G., and Taylor, G. (2009). The recurrent temporal restricted Boltzmann machine. In NIPS’2008. 712. Sutskever, I., Martens, J., and Hinton, G. E. (2011). Generating text with recurrent neural networks. In ICML’2011, pages 1017–1024. 713. Sutskever, I., Martens, J., Dahl, G., and Hinton, G. (2013). On the importance of initialization and momentum in deep learning. In ICML. 714. Sutskever, I., Vinyals, O., and Le, Q. V. (2014). Sequence to sequence learning with neural networks. In NIPS’2014, arXiv:1409.3215. 715. Sutton, R. and Barto, A. (1998). Reinforcement Learning: An Introduction. MIT Press. 716. Sutton, R. S., Mcallester, D., Singh, S., and Mansour, Y. (2000). Policy gradient methods for reinforcement learning with function approximation. In NIPS’1999, pages 1057–1063. MIT Press. 717. Swersky, K., Ranzato, M., Buchman, D., Marlin, B., and de Freitas, N. (2011). On autoencoders and score matching for energy based models. In ICML’2011. ACM. 718. Swersky, K., Snoek, J., and Adams, R. P. (2014). Freeze-thaw Bayesian optimization. arXiv preprint arXiv:1406.3896. 719. Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Van-houcke, V., and Rabinovich, A. (2014a). Going deeper with convolutions. Technical report, arXiv:1409.4842.\n--- Страница 642 ---\nЗаключение  641 720. Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I. J., and Fergus, R. (2014b). Intriguing properties of neural networks. ICLR, abs/1312.6199. 721. Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z. (2015). Rethinking the Inception Architecture for Computer Vision. ArXiv e-prints. 722. Taigman, Y., Yang, M., Ranzato, M., and Wolf, L. (2014). DeepFace: Closing the gap to human-level performance in face verification. In CVPR’2014. 723. Tandy, D. W. (1997). Works and Days: A Translation and Commentary for the Social Sciences. University of California Press. 724. Tang, Y. and Eliasmith, C. (2010). Deep networks for robust visual recognition. In Proceedings of the 27th International Conference on Machine Learning, June 21–24, 2010, Haifa, Israel. 725. Tang, Y., Salakhutdinov, R., and Hinton, G. (2012). Deep mixtures of factor analy-sers. arXiv preprint arXiv:1206.4635. 726. Taylor, G. and Hinton, G. (2009). Factored conditional restricted Boltzmann ma-chines for modeling motion style. In L. Bottou and M. Littman, editors, Proceed-ings of the Twenty-sixth International Conference on Machine Learning (ICML’09), pages 1025–1032, Montreal, Quebec, Canada. ACM. 727. Taylor, G., Hinton, G. E., and Roweis, S. (2007). Modeling human motion using bi-nary latent variables. In B. Schölkopf, J. Platt, and T. Hoffman, editors, Advances in-Neural Information Processing Systems 19 (NIPS’06), pages 1345–1352. MIT Press, Cambridge, MA. 728. Teh, Y., Welling, M., Osindero, S., and Hinton, G. E. (2003). Energy-based models for sparse overcomplete representations. Journal of Machine Learning Research, 4, 1235–1260. 729. Tenenbaum, J., de Silva, V., and Langford, J. C. (2000). A global geometric framework for nonlinear dimensionality reduction. Science, 290(5500), 2319–2323. 730. Theis, L., van den Oord, A., and Bethge, M. (2015). A note on the evaluation of gen-erative models. arXiv:1511.01844. 731. Thompson, J., Jain, A., LeCun, Y., and Bregler, C. (2014). Joint training of a convo-lutional network and a graphical model for human pose estimation. In NIPS’2014. 732. Thrun, S. (1995). Learning to play the game of chess. In NIPS’1994. 733. Tibshirani, R. J. (1995). Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society B, 58, 267–288. 734. Tieleman, T. (2008). Training restricted Boltzmann machines using approximations to the likelihood gradient. In W. W. Cohen, A. McCallum, and S. T. Roweis, editors, Proceedings of the Twenty-fifth International Conference on Machine Learning (ICML’08), pages 1064–1071. ACM. 735. Tieleman, T. and Hinton, G. (2009). Using fast weights to improve persistent contras-tive divergence. In L. Bottou and M. Littman, editors, Proceedings of the Twenty-sixth International Conference on Machine Learning (ICML’09), pages 1033–1040. ACM. 736. Tipping, M. E. and Bishop, C. M. (1999). Probabilistic principal components analy-sis. Journal of the Royal Statistical Society B, 61(3), 611–622. 737. Torralba, A., Fergus, R., and Weiss, Y. (2008). Small codes and large databases for recognition. In Proceedings of the Computer Vision and Pattern Recognition Con-ference (CVPR’08), pages 1–8.\n--- Страница 643 ---\n642  Список литературы 738. Touretzky, D. S. and Minton, G. E. (1985). Symbols among the neurons: Details of a connectionist inference architecture. In Proceedings of the 9th International Joint Conference on Artificial Intelligence – Volume 1, IJCAI’85, pages 238–243, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc. 739. Töscher, A., Jahrer, M., and Bell, R. M. (2009). The BigChaos solution to the Netflix grand prize. 740. Tu, K. and Honavar, V. (2011). On the utility of curricula in unsupervised learning of probabilistic grammars. In IJCAI’2011. 741. Turaga, S. C., Murray, J. F., Jain, V., Roth, F., Helmstaedter, M., Briggman, K., Denk, W., and Seung, H. S. (2010). Convolutional networks can learn to generate affinity graphs for image segmentation. Neural Computation, 22(2), 511–538. 742. Turian, J., Ratinov, L., and Bengio, Y. (2010). Word representations: A simple and general method for semi-supervised learning. In Proc. ACL’2010, pages 384–394. 743. Uria, B., Murray, I., and Larochelle, H. (2013). Rnade: The real-valued neural auto-regressive density-estimator. In NIPS’2013. 744. van den Oörd, A., Dieleman, S., and Schrauwen, B. (2013). Deep content-based mu-sic recommendation. In NIPS’2013. 745. van der Maaten, L. and Hinton, G. E. (2008). Visualizing data using t-SNE. J. Ma-chine Learning Res., 9. 746. Vanhoucke, V., Senior, A., and Mao, M. Z. (2011). Improving the speed of neural networks on CPUs. In Proc. Deep Learning and Unsupervised Feature Learning NIPS Workshop. 747. Vapnik, V. N. (1982). Estimation of Dependences Based on Empirical Data. Spring-er- Verlag, Berlin. 748. Vapnik, V. N. (1995). The Nature of Statistical Learning Theory. Springer, New Y ork. 749. Vapnik, V. N. and Chervonenkis, A. Y. (1971). On the uniform convergence of rela-tive frequencies of events to their probabilities. Theory of Probability and Its Ap-plications, 16, 264–280. 750. Vincent, P. (2011). A connection between score matching and denoising autoencod-ers. Neural Computation, 23(7). 751. Vincent, P. and Bengio, Y. (2003). Manifold Parzen windows. In NIPS’2002. MIT Press. 752. Vincent, P., Larochelle, H., Bengio, Y., and Manzagol, P.-A. (2008). Extracting and composing robust features with denoising autoencoders. In ICML 2008. 753. Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., and Manzagol, P.-A. (2010). Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion. J. Machine Learning Res., 11. 754. Vincent, P., de Brebisson, A., and Bouthillier, X. (2015). Efficient exact gradient update for training deep networks with very large sparse targets. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neu- ral Information Processing Systems 28, pages 1108–1116. Curran Associates, Inc. 755. Vinyals, O., Kaiser, L., Koo, T., Petrov, S., Sutskever, I., and Hinton, G. (2014a). Grammar as a foreign language. Technical report, arXiv:1412.7449. 756. Vinyals, O., Toshev, A., Bengio, S., and Erhan, D. (2014b). Show and tell: a neural image caption generator. arXiv 1411.4555. 757. Vinyals, O., Fortunato, M., and Jaitly, N. (2015a). Pointer networks. arXiv preprint arXiv:1506.03134.\n--- Страница 644 ---\nЗаключение  643 758. Vinyals, O., Toshev, A., Bengio, S., and Erhan, D. (2015b). Show and tell: a neural image caption generator. In CVPR’2015. arXiv:1411.4555. 759. Viola, P. and Jones, M. (2001). Robust real-time object detection. In International Journal of Computer Vision. 760. Visin, F., Kastner, K., Cho, K., Matteucci, M., Courville, A., and Bengio, Y. (2015). ReNet: A recurrent neural network based alternative to convolutional networks. arXiv preprint arXiv:1505.00393. 761. Von Melchner, L., Pallas, S. L., and Sur, M. (2000). Visual behaviour mediated by retinal projections directed to the auditory pathway. Nature, 404(6780), 871–876. 762. Wager, S., Wang, S., and Liang, P. (2013). Dropout training as adaptive regulariza-tion. In Advances in Neural Information Processing Systems 26, pages 351–359. 763. Waibel, A., Hanazawa, T., Hinton, G. E., Shikano, K., and Lang, K. (1989). Phoneme recognition using time-delay neural networks. IEEE Transactions on Acoustics, Speech, and Signal Processing, 37, 328–339. 764. Wan, L., Zeiler, M., Zhang, S., LeCun, Y., and Fergus, R. (2013). Regularization of neural networks using dropconnect. In ICML’2013. 765. Wang, S. and Manning, C. (2013). Fast dropout training. In ICML’2013. 766. Wang, Z., Zhang, J., Feng, J., and Chen, Z. (2014a). Knowledge graph and text jointly embedding. In Proc. EMNLP’2014. 767. Wang, Z., Zhang, J., Feng, J., and Chen, Z. (2014b). Knowledge graph embedding by translating on hyperplanes. In Proc. AAAI’2014. 768. Warde-Farley, D., Goodfellow, I. J., Courville, A., and Bengio, Y. (2014). An empirical analysis of dropout in piecewise linear networks. In ICLR’2014. 769. Wawrzynek, J., Asanovic, K., Kingsbury, B., Johnson, D., Beck, J., and Morgan, N. (1996). Spert-II: A vector microprocessor system. Computer, 29(3), 79–86. 770. Weaver, L. and Tao, N. (2001). The optimal reward baseline for gradient-based rein-forcement learning. In Proc. UAI’2001, pages 538–545. 771. Weinberger, K. Q. and Saul, L. K. (2004). Unsupervised learning of image manifolds by semidefinite programming. In CVPR’2004, pages 988–995. 772. Weiss, Y., Torralba, A., and Fergus, R. (2008). Spectral hashing. In NIPS, pages 1753–1760. 773. Welling, M., Zemel, R. S., and Hinton, G. E. (2002). Self supervised boosting. In Advances in Neural Information Processing Systems, pages 665–672. 774. Welling, M., Hinton, G. E., and Osindero, S. (2003a). Learning sparse topographic representations with products of Student t-distributions. In NIPS’2002. 775. Welling, M., Zemel, R., and Hinton, G. E. (2003b). Self-supervised boosting. In S. Becker, S. Thrun, and K. Obermayer, editors, Advances in Neural Information Processing Systems 15 (NIPS’02), pages 665–672. MIT Press. 776. Welling, M., Rosen-Zvi, M., and Hinton, G. E. (2005). Exponential family harmoni-ums with an application to information retrieval. In L. Saul, Y. Weiss, and L. Bottou, editors, Advances in Neural Information Processing Systems 17 (NIPS’04), volume 17, Cambridge, MA. MIT Press. 777. Werbos, P. J. (1981). Applications of advances in nonlinear sensitivity analysis. In Proceedings of the 10th IFIP Conference, 31.8–4.9, NYC, pages 762–770. 778. Weston, J., Bengio, S., and Usunier, N. (2010). Large scale image annotation: learning to rank with joint word-image embeddings. Machine Learning, 81(1), 21–35.\n--- Страница 645 ---\n644  Список литературы 779. Weston, J., Chopra, S., and Bordes, A. (2014). Memory networks. arXiv preprint arXiv:1410.3916. 780. Widrow, B. and Hoff, M. E. (1960). Adaptive switching circuits. In 1960 IRE WESCON Convention Record, volume 4, pages 96–104. IRE, New Y ork. 781. Wikipedia (2015). List of animals by number of neurons – Wikipedia, the free ency- clopedia. [Online; accessed 4-March-2015]. 782. Williams, C. K. I. and Agakov, F. V. (2002). Products of Gaussians and Probabilistic Minor Component Analysis. Neural Computation, 14(5), 1169–1182. 783. Williams, C. K. I. and Rasmussen, C. E. (1996). Gaussian processes for regression. In D. Touretzky, M. Mozer, and M. Hasselmo, editors, Advances in Neural Information Processing Systems 8 (NIPS’95), pages 514–520. MIT Press, Cambridge, MA. 784. Williams, R. J. (1992). Simple statistical gradient-following algorithms connection-ist reinforcement learning. Machine Learning, 8, 229–256. 785. Williams, R. J. and Zipser, D. (1989). A learning algorithm for continually running fully recurrent neural networks. Neural Computation, 1, 270–280. 786. Wilson, D. R. and Martinez, T. R. (2003). The general inefficiency of batch training for gradient descent learning. Neural Networks, 16(10), 1429–1451. 787. Wilson, J. R. (1984). Variance reduction techniques for digital simulation. American Journal of Mathematical and Management Sciences, 4(3), 277–312. 788. Wiskott, L. and Sejnowski, T. J. (2002). Slow feature analysis: Unsupervised learning of invariances. Neural Computation, 14(4), 715–770. 789. Wolpert, D. and MacReady, W. (1997). No free lunch theorems for optimization. IEEE Transactions on Evolutionary Computation, 1, 67–82. 790. Wolpert, D. H. (1996). The lack of a priori distinction between learning algorithms. Neural Computation, 8(7), 1341–1390. 791. Wu, R., Yan, S., Shan, Y., Dang, Q., and Sun, G. (2015). Deep image: Scaling up image recognition. arXiv:1501.02876. 792. Wu, Z. (1997). Global continuation for distance geometry problems. SIAM Journal of Optimization, 7, 814–836. 793. Xiong, H. Y., Barash, Y., and Frey, B. J. (2011). Bayesian prediction of tissue-re-gulated splicing using RNA sequence and cellular context. Bioinformatics, 27(18), 2554–2562. 794. Xu, K., Ba, J. L., Kiros, R., Cho, K., Courville, A., Salakhutdinov, R., Zemel, R. S., and Bengio, Y. (2015). Show, attend and tell: Neural image caption generation with visual attention. In ICML’2015, arXiv:1502.03044 . 795. Yildiz, I. B., Jaeger, H., and Kiebel, S. J. (2012). Re-visiting the echo state property. Neural networks, 35, 1–9. 796. Y osinski, J., Clune, J., Bengio, Y., and Lipson, H. (2014). How transferable are fea-tures in deep neural networks? In NIPS’2014. 797. Y ounes, L. (1998). On the convergence of Markovian stochastic algorithms with rapidly decreasing ergodicity rates. In Stochastics and Stochastics Models, pages 177–228. 798. Yu, D., Wang, S., and Deng, L. (2010). Sequential labeling using deep-structured conditional random fields. IEEE Journal of Selected Topics in Signal Processing. 799. Zaremba, W. and Sutskever, I. (2014). Learning to execute. arXiv 1410.4615. 800. Zaremba, W. and Sutskever, I. (2015). Reinforcement learning neural Turing ma-chines. arXiv:1505.00521.\n--- Страница 646 ---\nЗаключение  645 801. Zaslavsky, T. (1975). Facing Up to Arrangements: Face-Count Formulas for Parti- tions of Space by Hyperplanes. Number no. 154 in Memoirs of the American Ma-thematical Society. American Mathematical Society. 802. Zeiler, M. D. and Fergus, R. (2014). Visualizing and understanding convolutional networks. In ECCV’14. 803. Zeiler, M. D., Ranzato, M., Monga, R., Mao, M., Yang, K., Le, Q., Nguyen, P., Senior, A., Vanhoucke, V., Dean, J., and Hinton, G. E. (2013). On rectified linear units for speech processing. In ICASSP 2013. 804. Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., and Torralba, A. (2015). Object detec-tors emerge in deep scene CNNs. ICLR’2015, arXiv:1412.6856. 805. Zhou, J. and Troyanskaya, O. G. (2014). Deep supervised and convolutional genera-tive stochastic network for protein secondary structure prediction. In ICML’2014. 806. Zhou, Y. and Chellappa, R. (1988). Computation of optical flow using a neural net-work. In Neural Networks, 1988., IEEE International Conference on, pages 71–78. IEEE. 807. Zöhrer, M. and Pernkopf, F. (2014). General stochastic networks for classification. In NIPS’2014.\n--- Страница 647 ---\nПредметный указатель А Абсолютная ректификация, 170 Автокодировщик, 24, 302, 422 Автокодировщик, взвешенный по значимости, 585Автоматическое распознавание речи, 385 Адамара произведение, 46 Адаптация домена, 451 Адаптивный линейный элемент, 32, 39, 40 Адресация по содержимому, 352Активное ограничение, 93 Аморальность, 484 Анализ медленных признаков, 415 Анализ независимых компонент, 413 Анализ независимых подпространств, 415 Ансамблевые методы, 222 Априорное распределение вероятности, 126 АРР . См. Автоматическое распознавание речи Асимптотически несмещенная, 117Аудиосигнал, 99, 305, 385 Аффинное преобразование, 105 Б Баггинг, 222 База знаний, 22, 406 Байесовская вероятность, 63 Байесовская оптимизация гиперпараметров, 367Байесовская ошибка, 110 Байесовская сеть. См. Ориентированная графическая модель Байесовская статистика, 125Бернулли распределение, 68 Биграмма, 388 Бинарная функция потерь, 100, 239 Бинарное отношение, 406 Блоки с утечкой, 343Блок линейной ректификации, 154, 170, 358, 426 Блочная выборка по Гиббсу, 503Бодрствование-сон, 546 Больцмана машина, 478, 548Больцмана распределение, 478 В Вапника-Червоненкиса размерность, 109 Вариационное исчисление, 159 Вариационной свободной энергией. См. Нижняя граница свидетельств Вариационный автокодировщик, 583 Вариационными производными. См. Функциональная производная Вектор, 44Вентиль забывания, 263 Вентильная рекуррентная сеть, 358 Верность, 356Вероятностный max-пулинг, 572 Вероятностный метод главных компонент, 412, 531Веса, 32, 103Видимый слой, 25Виртуальные состязательные примеры, 233Восхождение на вершину, 86Вторая производная, 87Выборка по Гиббсу, 488, 503Выборка по значимости, 497, 524Выборка по значимости с отжигом, 525, 560, 601Выборочное среднее, 118 Вывод, 472, 490, 530, 533, 535, 544, 545 Выпуклая оптимизации, 130Выходной слой, 150 Г Габора функция, 311Гармониум. См. Ограниченная машина Больцмана Гармония, 479 Гауссова смесь, 72, 167 Гауссово ядро, 131 Генераторная сеть, 581 Гессе матрица, 87Гессиан, 87, 195Гетероскедастическая модель, 166Гиперпараметры, 114, 362Гипотеза о многообразии, 146Главная диагональ, 45Глобальная нормализация контрастности, 382Глубокая машина Больцмана, 39, 40, 445, 530, 547, 551, 555, 562 Глубокая сеть доверия, 40, 445, 530, 551, 553, 580 Глубокая сеть прямого распространения, 150 Глубокое обучение, 21, 24 ГМБ. См. Глубокая машина Больцмана ГНК. См. Глобальная нормализация контрастностиГрадиент, 86Градиентный спуск, 84, 86Граф вычислений, 179Графический процессор, 374Графической моделью. См. Структурная вероятностная модельГребневая регрессия, 201 ГСД. См. Глубокая сеть доверия Д Дважды блочно-циркулянтная матрица, 284 Двойное обратное распространение, 236Декодер, 24Дельта-функция Дирака, 71Детекторная стадия, 290\n--- Страница 648 ---\nПредметный указатель  647 Диагональная матрица, 51 Динамическая структура, 377 Дискриминантная окончательная настройка, 554Дискриминантная ОМБ, 574Дисперсия, 67 Дифференциальная энтропия, 77, 542 Долгая краткосрочная память, 34, 344, 358Дрейф концепций, 452 Е Евклидова норма, 50Единичная матрица, 47 Единичный вектор, 52 Естественное изображение, 470 Ж Жадное послойное предобучение без учителя, 444 Жадное предобучение с учителем, 277 Жадный алгоритм, 276 И Идентифицируемость модели, 245Изотропное нормальное распределение, 70 Инвариантность, 290 Инициализация параметров, 258, 343Информационный поиск, 441 Искусственный интеллект, 21 Использование, 405 Исследование, 405 К Карта признаков, 283Каруша-Куна-Таккера условия, 94, 206 Касательная плоскость, 433Категориальное распределение, 68Квадратурная пара, 313 Квазиньютоновские методы, 271 Классификатор по касательной к многообразию, 236 Классификация, 97Классическая динамическая система, 317 Классовые языковые модели, 390 Ковариационная матрица, 68Ковариация, 67 Кодировщик, 24 Коллаборативна фильтрация, 402 Коллектив экспертов, 378, 460 Коллизия, 482Компьютерное зрение, 380 Коннекционизм, 34, 373 Контекстная независимость, 481Контекстуальные бандиты, 404 Контрастность, 382 Короткий список, 392Корреляция, 67 Критическая температурая, 506Крылова методы, 195 Кульбака-Лейблера расхождение, 77Л Лагранжа множители, 92, 542 Лапласа распределение, 70, 417, 418Латентная переменная, 72Линейная зависимость, 49Линейная комбинация, 49Линейная оболочка, 49Линейная регрессия, 103, 105, 129 Линейные факторные модели, 411 Линейный поиск, 86, 92 Липшица условие, 91 Логистическая регрессии, 22, 130Логистическая сигмоида, 27, 73Локальная нормализация контрастности, 384Локальное условное распределение вероятности, 473 М Максимальная норма, 51Максимальное правдоподобие, 122Маргинальное распределение вероятности, 65Марковская сеть. См. Неориентированная модель Марковская цепь, 499Марковское случайное поле. См. Неориентированная модель Массивы, типы больших массивов. См. Типы больших массивов Математическое ожидание, 66 Матрица, 45Матрица плана, 102 Машина неустойчивых состояний, 341Машинное обучение, 22Машинный перевод, 98Метод главных компонент, 57, 135, 412, 530Метод конечных разностей, 369Метод малых возмущений, 576Метод наискорейшего спуска. См. Градиентный спуск Метод опорных векторов, 130 Методы Монте-Карло по схеме марковской цепи, 499Методы продолжения, 280Минимизация эмпирического риска, 238Минипакет, 241Многозадачное обучение, 212, 452Многомерное нормальное распределение, 70Многомодальное обучение, 454Многообразие, 145Многопредсказательная ГМБ, 563Многослойный перцептрон, 26, 40Моральный граф, 484 МП-ГМБ. См. Многопредсказательная ГМБ МСП. См. Многослойный перцептронМультиномиальное распределение, 68Мура-Пенроуза псевдообращение, 55, 208 Н Набор данных, 101 Набор слов, 396\n--- Страница 649 ---\n648  Предметный указатель Наивный байесовский классификатор, 22 Нат, 77Независимость, 66 Нейробиология, 32 Нейронная машина Тьюринга, 351Нейронная сеть, 31 Нейронная сеть прямого распространения, 150 Нейронная языковая модель, 390, 401 Нейронные сети с временной задержкой, 311 Ненормированное распределение вероятности, 476 Неокогнитрон, 33, 39, 40, 311Неориентированная графическая модель, 80, 426Неориентированная модель, 475 Непараметрическая модель, 110 Неравенство треугольника, 50Несмещенная оценка, 117 Нестерова метод, 258 Нижняя граница свидетельств, 530, 554Норма, 50Нормальное распределение, 69, 118 Нормальные уравнения, 104, 107, 203 Нормированная инициализация, 260 Ньютона метод, 90, 267 НЯМ. См. Нейронная языковая модель О Обнаружение объектов, 381Обнаружение спама, 22 Обобщение, 105 Обобщенная функция Лагранжа. См. Обобщенный лагранжианОбобщенный лагранжиан, 92 Обработка естественных языков, 388 Обратная матрица, 48 Обратное распространение, 179Обратное распространение по времени, 326 Обучение без примеров, 453 Обучение без учителя, 101, 134Обучение многообразий, 146 Обучение на одном примере, 453 Обучение по плану, 281Обучение представлений, 23 Обучение с подкреплением, 42, 102, 404, 576 Обучение с учителем, 101Обучение с частичным привлечением учителя, 211Ограничения типа неравенств, 93 Ограничения типа равенств, 93 Ограниченная машина Больцмана, 302, 386, 403, 492, 530, 550, 563, 567, 568, 570, 572 Ограниченная оптимизация, 92, 206 ОЕЯ. См. Обработка естественных языковОжидаемое значение, 66Окончательная настройка, 276 Окончательная настройка с учителем, 445 ОМБ. См. Ограниченная машина БольцманаОператор следа, 56 Операция, 179 Оправдание, 482, 530, 541 Оптимизация, 82, 84Оптимизация гиперпараметров, 364 Ориентированная графическая модель, 80, 426, 473, 579 Ортогональная матрица, 52 Ортогональное согласованное преследование, 40, 221 Ортонормированные векторы, 52 Отбеливание, 383 Отбор признаков, 205Отношения, 406 Отрицательная фаза, 395, 509, 511 Отрицательно определенная матрица, 89 Отсечение градиента, 248, 349 Отсутствующие данные, 98Оценка апостериорного максимума, 128, 425 Оценка плотности, 100 Оценка функции вероятности, 100 Ошибка обучения, 106 П Пакетная нормировка, 232, 358 Параллельная распределенная обработка, 34 Параметрическая модель, 110 Параметрический ReLU, 170 Параметр смещения, 105 Первичная зрительная кора, 308Перекрестная корреляция, 284 Перекрестная проверка, 115 Перекрестная энтропия, 78, 123 Перемешивание (марковской цепи), 504 Перенос обучения, 451 Перепараметризация, 576 Период, 214 Периодическая свертка, 300 Перцептрон, 32, 40Погружение, 436 Погружение слова, 390 Поиск на сетке, 364Покоординатный спуск, 275, 562 Покрытие, 357Политика, 405 Полностью видимая байесовская сеть, 591Полнота, 357 Положительная фаза, 395, 509, 512, 549, 559 Положительно определенная матрица, 89 Пополнение набора данных, 235, 385 Порождающая сеть с сопоставлением моментов, 589 Порождающая состязательная сеть, 586 Порождающее распределение, 106, 122 Постоянная Липшица, 91 Потенциал клики, 476 Почти всюду, 75 Правило Байеса, 74Правило дифференцирования сложной функции, 181Правило сложения вероятностей, 65 ПРД. См. Предсказательная разреженная декомпозиция\n--- Страница 650 ---\nПредметный указатель  649 Предковая выборка, 487, 500 Предобработка, 381Предобучение, 276, 444 Предобучение без учителя, 386, 444 Предположения о независимости и одинаковом распределении, 106, 116, 232 Предсказание связей, 407 Предсказательная разреженная декомпозиция, 440 Приближенные байесовские вычисления, 600 Приближенный вывод, 490Привратник, 378Признак, 97Пример, 97 Приработка, 501 Проверка по второй производной, 89Произведение матриц, 46 Произведение экспертов, 479 Производная, 84Производная по направлению, 86Проклятие размерности, 141 Прореживание, 224, 358, 362, 363, 562, 577 Простая клетка, 309 Пространство гипотез, 107, 112 Процесс генерации данных, 106Прямое распространение, 179Псевдоправдоподобие, 517ПСС. См. Порождающая состязательная сеть Пулинг, 282, 572 Р Равномерное распределение, 64 Радиально-базисная функция, 173Разделение параметров, 220, 287, 316, 317, 329 Разделенность, 480 Разреженная инициализация, 261, 343Разреженное кодирование, 275, 302, 417, 530, 580 Разреженное представление, 134, 220, 424 Разрешение неоднозначности смысла слов, 408Ранняя остановка, 213, 214, 216, 358 Распараллеливание по данным, 376 Распараллеливания модели, 376Распознавание объектов, 381Распределение вероятности, 64 Распределение Гиббса, 477 Распределенное представление, 34, 138, 459Распространение по касательной, 234Регрессия методом ближайшего соседа, 110 Регуляризатор, 114 Регуляризация, 114, 158, 199, 362Регуляризация Тихонова, 201 Резервуарные вычисления, 341 Рекомендательные системы, 402Рекуррентная нейронная сеть, 40, 320Реляционная база данных, 406 Репрезентативная емкость, 108 Рецептивное поле, 287 Решающее дерево, 132, 460 Риск, 238 РНС-ОМБ, 574С Свертка, 282, 572 Сверточная нейронная сеть, 220, 282, 358, 387 Сверточная сеть, 33 Свободная энергия, 480, 569 Связывание параметров. См. Разделение параметровСглаживание меток, 211СГС. См. Стохастический градиентный спускСедловые точки, 246Семантическое хэширование, 441Сеперабельное ядро свертки, 306Сети со смесовой плотностью, 167Сеть доверия. См. Ориентированная графическая модель Сеть с памятью, 351Сеть сумм и произведений, 466Сжатие модели, 377Сжимающий автокодировщик, 436Сигмоидальная сеть доверия, 40Симметричная матрица, 51Симметрия пространства весов, 245Сингулярное значение, 55Сингулярное разложение, 54, 136, 403Сингулярный вектор, 55Система фильтрации по содержимому, 404Скаляр, 44Скалярное произведение, 46, 130Скорость обучения, 86Скрытый слой, 25, 151Сложная клетка, 309Слой (нейронной сети), 150Случайная величина, 63Случайный поиск, 365Смесь распределений, 71Смещение, 117, 200Смещенная выборка по значимости, 498СМП. См. Стохастическая максимизация правдоподобияСнижение весов, 113, 158, 201, 363Сновидения, 512, 547СНС. См. Сверточная нейронная сетьСобственная информация, 77Собственное значение, 53Собственный вектор, 52Совместное распределение вероятности, 64Сопоставительное расхождение, 250, 512, 563Сопоставление моментов, 589Сопоставление рейтингов, 430, 519Состоятельность, 122, 430Состоятельность, 122Состязательное обучение, 232, 236, 446Состязательный пример, 232Спектральное разложение, 52Спектральный радиус, 341Сравнение с образцом, 131Среднее поле, 536, 562Среднеквадратическая ошибка, 104\n--- Страница 651 ---\n650  Предметный указатель Стандартная ошибка, 119 Стандартная ошибка среднего, 120, 240 Стандартное отклонение, 67 Статистика, 116 Статистическая сумма, 477, 508, 560 Стохастическая максимизация правдоподобия, 514, 562 Стохастический градиентный спуск, 32, 138, 241, 253, 562Стохастический пулинг, 231 Стохастическое обратное распространение, 576 Структурная вероятностная модель, 79Структурное обучение, 489 Суррогатная функция потерь, 239 Сферинг. См. ОтбеливаниеСходимость почти наверное, 122 Т Тангенциальное расстояние, 234Темперирование, 506Тензор, 45 Теорема об отсутствии бесплатных завтраков, 112 Теория меры, 75Теория статистического обучения, 106Теплица теорема, 284 Тестовый набор, 104 Топографический вариант ICA, 415Точечная оценка, 116 Точность, 357 Точность (нормального распределения), 69, 70Транскрипция, 98 Транспонирование, 45 Триангулированный граф. См. Хордовый графТриграмма, 388 У Укладывание, 46Универсальная теорема аппроксимации, 174Универсальный аппроксиматор, 465 Униграмма, 388 Упругое обратное распространение. См. Rprop, алгоритм Условная вероятность, 65 Условная независимость, 66Условная ОМБ, 574 Условное вычисление, 377 Усреднение моделей, 222 Ф Фактор (графическая модель), 476Факторный анализ, 412 Факторный граф, 486 Факторы вариативности, 24 Форсирование учителя, 324 Фробениуса норма, 56 Функциональная производная, 542 Функция активации, 152Функция вероятности, 64 Функция ошибок. См. Целевая функцияФункция плотности вероятности, 64 Функция потерь. См. Целевая функцияФункция стоимости. См. Целевая ФункцияФункция энергии, 478Фурье преобразование, 305, 306 Х Хорда, 484Хордовый граф, 485 Ц Цветные изображения, 304Целевая функция, 84Центральная предельнойая теорема, 70Центральная ямка, 310Центрирование (ГМБ), 564 Цепное правило вероятностей, 66 Цикл, 486Циклическое распространение доверия, 492 Ч Частная производная, 86Частотная вероятность, 63Частотные статистики, 125Число обусловленности, 83, 241 Ш Шахматы, 21Шеннона энтропия, 77Шумоподавляющее сопоставление рейтингов, 521Шумоподавляющий автокодировщик, 429, 577Шумосопоставительное оценивание, 521 Э Эйлера-Лагранжа уравнение, 542Эквивариантность, 287 Экспоненциальное распределение, 70 Эмпирический риск, 238Эмпирическое распределение, 71Энергетическая модель, 478, 499, 548, 556Эффективная емкость, 108Эхо-сеть, 40, 341 Я Ядерные методы, 460Ядро (свертки), 283Якоби матрица, 76, 87 A AdaGrad, 264ADALINE. См. Адаптивный линейный элементAdam, 265, 358AIS. См. Выборка по значимости с отжигом B BFGS, 271 C CAE. См. Сжимающий автокодировщик\n--- Страница 652 ---\nПредметный указатель  651 CD. См. Сопоставительное расхождение Cyc, проект, 22 D DAE. См. Шумоподавляющий автокодировщикDCGAN, 588Deep Blue, 21DropConnect, 230 d-разделенность, 480 E EBM. См. Энергетическая модель ELBO. См. Нижняя граница свидетельствEMD. См. Расстояние землекопа, алгоритм; Расстояние землекопа, алгоритмEM-алгоритм, 532E-шаг, 532 F FPCD, 516Freebase, 406 F-мера, 357 G GeneOntology, 407 GPU. См. Графический процессор H hardtanh, 173 I ImageNet Large Scale Visual Recognition Challenge (ILSVRC), 41 K k ближайших соседей метод, 132, 460k средних метод, 308, 460 L LAPGAN, 588Lp, норма, 50LSTM. См. Долгая краткосрочная память M maxout-блок, 170, 358max-пулинг, 290 MCMC. См. Методы Монте-Карло по схеме марковской цепи MNIST, 37, 38, 562M-шаг, 533 N NADE, 593 Netflix Grand Prize, 223, 403 n-грамма, 388 O OMP-k. См. Ортогональное согласованное преследование OpenCyc, 406 P PCA. См. Метод главных компонент R RBF. См. Радиально-базисная функция REINFORCE, 577 ReLU с утечкой, 170 S softmax, 163, 352, 378 softplus, 73, 173 Spearmint, 367 Spike and Slab, тип ограниченной машины Больцмана, 570 ssRBM, 570 T TDNN. См. Нейронные сети с временной задержкой V V AE. См. Вариационный автокодировщик VC-размерность. См. Вапника-Червоненкиса размерностьV-структура, 482 W Wikibase, 406WordNet, 406\n--- Страница 653 ---\nКниги издательства «ДМК Пресс» можно заказать в торгово-издательском холдинге «Планета Альянс» наложенным платежом, выслав открытку или письмо по почтовому адресу: 115487, г. Москва, 2-й Нагатинский пр-д, д. 6А. При оформлении заказа следует указать адрес (полностью), по которому должны быть высланы книги; фамилию, имя и отчество получателя. Желательно также указать свой телефон и электронный адрес. Эти книги вы можете заказать и в интернет-магазине: www.alians-kniga.ru . Оптовые закупки: тел. (499) 782-38-89 . Электронный адрес: books@alians-kniga.ru . Ян Гудфеллоу, Иошуа Бенджио, Аарон Курвилль Глубокое обучение Главный редактор Мовчан Д. А. dmkpress@gmail.com Перевод Слинкин А. А. Корректор Синяева Г. И. Верстка Чаннова А. А. Дизайн обложки Мовчан А. Г. Формат 70 ×100 1/16. Гарнитура «Петербург». Печать офсетная. Усл. печ. л. 61,125. Тираж 200 экз. Веб-сайт издательства: www.дмк.рф",
      "debug": {
        "start_page": 549,
        "end_page": 653
      }
    }
  ]
}
{
  "title": "Python. К вершинам мастерства [2016] Рамальо Лучано",
  "chapters": [
    {
      "name": "Глава 1. Модель данных в языке Python 28",
      "content": "--- Страница 28 ---\nГлава 1. Модель данных в языке Python У Гвидо поразительное эстетическое чувство дизайна языка. Я встречал многих замечательных проектировщиков языков программирования, создававших теоретически красивые языки, которыми никто никогда не пользовался, а Гвидо – один из тех редких людей, которые могут создать язык, немного недотягивающий до теоретической красоты, зато такой, что писать на нем программы в радость. 1 – Джим Хагьюнин, автор Jython, соавтор AspectJ, архитектор .Net DLR Одно из лучших качеств Python – его согласованность. Немного поработав с этим языком, вы уже сможете строить обоснованные и правильные предположения о еще незнакомых средствах. Однако тем, кто раньше учил другой объектно-ориентированный язык, может показаться странным синтаксис len(collection) вместо collection.len() . Это кажущаяся несообразность – лишь верхушка айсберга, и, если ее правильно понять, то она станет ключом к тому, что мы называем «питонизмами». А сам айсберг называется моделью данных в Python и описывает API, следуя которому можно согласовать свои объекты с самыми идиоматичными средствами языка. Можно считать, что модель данных описывает Python как каркас. Она формализует различные структурные блоки языка, в частности, последовательности, итераторы, функции, классы, контекстные менеджеры и т. д. При программировании в любом каркасе вы тратите большую часть времени на реализацию вызываемых каркасом методов. То же самое справедливо для модели данных Python. Интерпретатор Python вызывает специальные методы для выполнения базовых операций над объектами, часто такие вызовы происходят, когда встречается некая синтаксическая конструкция. Имена специальных методов начинаются и заканчиваются двумя знаками подчеркивания (например, __getitem__ ). Так, за синтаксической конструкцией obj[key] стоит специальный 1 История Jython ( http://hugunin.net/story_of_jython.html ), изложенная в предисловии к книге Samuele Pedroni and Noel Rappin «Jython Essentials» (O'Reilly).\n--- Страница 29 ---\n29 Колода карт на Python метод __getitem__ . Для вычисления выражения my_collection[key] интерпрета- тор вызывает метод my_collection.__getitem__(key) . Благодаря специальным методам объекты могут реализовывать, поддерживать и взаимодействовать с базовыми конструкциями языка, а именно: • итерирование; • коллекции;• доступ к атрибутам;• перегрузка операторов;• вызов функций и методов;• создание и уничтожение объектов;• представление и форматирование строк;• управляемые контексты (т. е. блоки with ). Магические и dunder-методы На жаргоне специальные методы обычно называют магическими, но в применении к конкретным методам, например __getitem__ , некоторые разработчики говорят «подчерк-подчерк-getitem» (under-under-getitem), внося тем самым двусмысленность, по-тому что у конструкции __x имеется другой специальный смысл2. Произносить правильно – «подчерк-подчерк-getitem-подчерк-подчерк» – утомительно, поэтому я, следуя своему учителю Стиву Холдену, говорю «dunder-getitem». Все опытные питонисты по-нимают это сокращение. По этой причине специальные методы иногда называют также dunder-методами 3. Колода карт на Python Следующий пример очень прост, однако демонстрирует выгоды от реализации двух специальных методов: __getitem__ и __len__ . В примере 1.1 приведен класс, представляющий колоду игральных карт. Пример 1.1. Колода как последовательность карт import collections Card = collections.namedtuple('Card', ['rank', 'suit'])class FrenchDeck: 2 См. раздел «Закрытые и защищенные методы в Python» ниже. 3 Лично я впервые услышал слово «dunder» от Стива Холдена. Википедия ( http://bit.ly/1Vm72Mf ) приписывает авторство Марку Джонсону и Тиму Хохбергу, которые первыми употребили это слово в письменном ответе на вопрос «Как произнести __ (двойное подчеркивание)?» в списке рассылки python-list 26 сентября 2002 года; ответ Джонсона см. по адресу https://mail.python.org/pipermail/ python-list/2002-September/112991.html .\n--- Страница 30 ---\n30 Глава 1. Модель данных в языке Python ranks = [str(n) for n in range(2, 11)] + list('JQKA') suits = 'spades diamonds clubs hearts'.split() def __init__(self): self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks] def __len__(self): return len(self._cards) def __getitem__(self, position): return self._cards[position] Прежде всего, отметим использование collections.namedtuple для конструиро- вания простого класса, представляющего одну карту. Начиная с версии Python 2.6, класс namedtuple можно использовать для построения классов, содержащих толь- ко атрибуты и никаких методов, как, например, запись базы данных. В данном примере мы воспользовались им для создания простого представления игральной карты, что продемонстрировано в следующем сеансе оболочки: >>> beer_card = Card('7', 'diamonds')>>> beer_cardCard(rank='7', suit='diamonds') Но изюминка примера – класс FrenchDeck . Совсем короткий, он таит в себе не- мало интересного. Во-первых, как и для любой стандартной коллекции в Python, для колоды можно вызвать функцию len() , которая вернет количество карт в ней: >>> deck = FrenchDeck()>>> len(deck)52 Получение карты из колоды, например первой или последней, не должно быть сложнее обращения deck[0] или deck[-1] , и именно это обеспечивает метод __getitem__ : >>> deck[0]Card(rank='2', suit='spades')>>> deck[-1]Card(rank='A', suit='hearts') Нужно ли создавать метод для выбора случайной карты? Необязательно. В Python уже есть функция выборки случайного элемента последовательности: random.choice . Достаточно вызвать ее для экземпляра колоды: >>> from random import choice>>> choice(deck)Card(rank='3', suit='hearts')>>> choice(deck)Card(rank='K', suit='spades')>>> choice(deck)Card(rank='2', suit='clubs')\n--- Страница 31 ---\n31 Колода карт на Python Мы только что видели два преимущества от использования специальных мето- дов для работы с моделью данных. • Пользователям вашего класса нет нужды запоминать нестандартные имена методов для выполнения стандартных операций («Как мне получить коли-чество элементов? То ли .size() , то ли .length() , то ли еще как-то»). • Проще воспользоваться богатством стандартной библиотеки Python (на- пример, функцией random.choice ), чем изобретать велосипед. Но это еще не все. Поскольку метод __getitem__ делегирует выполнение оператору [] объекта self._cards , колода автоматически поддерживает срезы. Вот как можно посмо- треть три верхние карты в неперетасованной колоде, а затем выбрать только тузы, начав с элемента, имеющего индекс 12, и пропуская по 13 карт: >>> deck[:3] [Card(rank='2', suit='spades'), Card(rank='3', suit='spades'), Card(rank='4', suit='spades')] >>> deck[12::13] [Card(rank='A', suit='spades'), Card(rank='A', suit='diamonds'), Card(rank='A', suit='clubs'), Card(rank='A', suit='hearts')] Стоило нам реализовать специальный метод __getitem__ , как колода стала допускать итерирование: >>> for card in deck: # doctest: +ELLIPSIS print(card)Card(rank='2', suit='spades')Card(rank='3', suit='spades')Card(rank='4', suit='spades') Итерировать можно и в обратном порядке: >>> for card in reversed(deck): # doctest: +ELLIPSIS print(card)Card(rank='A', suit='hearts')Card(rank='K', suit='hearts')Card(rank='Q', suit='hearts') Многоточие в doctest-скриптах Всюду, где возможно, листинги сеансов оболочки извлекались из doctest-скриптов, чтобы гарантировать точность. Если вывод слишком длинный, то опущенная часть помечается многоточием, как в последней строке показанного выше кода. В таких случаях мы используем директиву # doctest: +ELLIPSIS , чтобы doctest- скрипт завершился успешно. Если вы будете вводить эти приме-ры в интерактивной оболочке, можете вообще опускать директи-вы doctest.\n--- Страница 32 ---\n32 Глава 1. Модель данных в языке Python Итерирование часто подразумевается неявно. Если в коллекции отсутствует метод __contains__ , то оператор in производит последовательный просмотр. Кон- кретный пример – в классе FrenchDeck оператор in работает, потому что этот класс итерируемый. Проверим: >>> Card('Q', 'hearts') in deck True>>> Card('7', 'beasts') in deckFalse А как насчет сортировки? Обычно карты ранжируются по достоинству (тузы – самые старшие), а затем по масти в порядке пики (старшая масть), черви, бубны и трефы (младшая масть). Приведенная ниже функция ранжирует карты, следуя этому правилу: 0 означает двойку треф, а 21 – туза пик. suit_values = dict(spades=3, hearts=2, diamonds=1, clubs=0) def spades_high(card): rank_value = FrenchDeck.ranks.index(card.rank) return rank_value * len(suit_values) + suit_values[card.suit] С помощью функции spades_high мы теперь можем расположить колоду в порядке возрастания: >>> for card in sorted(deck, key=spades_high): # doctest: +ELLIPSIS print(card)Card(rank='2', suit='clubs')Card(rank='2', suit='diamonds')Card(rank='2', suit='hearts') (46 карт опущено)Card(rank='A', suit='diamonds')Card(rank='A', suit='hearts')Card(rank='A', suit='spades') Хотя класс FrenchDeck неявно наследует object4, его функциональность не наследуется, а является следствием использования модели данных и компози-ции. Вследствие реализации специальных методов __len__ и __getitem__ класс FrenchDeck ведет себя, как стандартная последовательность, и позволяет использо- вать базовые средства языка (например, итерирование и получение среза), а также функции reversed и sorted . Благодаря композиции реализации методов __len__ и __getitem__ могут перепоручать работу объекту self._cards класса list . А как насчет тасования? В текущей реализации объект класса FrenchDeck нельзя перета- совать, потому что он неизменяемый: ни карты, ни их позиции не- возможно изменить, не нарушая инкапсуляцию (т . е. манипулируя атрибутом _cards непосредственно). В главе 11 мы исправим это, добавив однострочный метод __setitem__ . 4 В Python 2 необходимо было бы явно написать FrenchDeck(object) , а в Python 3 это подраз- умевается по умолчанию.\n--- Страница 33 ---\n33 Эмуляция числовых типов Как используются специальные методы Говоря о специальных методах, нужно все время помнить, что они предназначе- ны для вызова интерпретатором, а не вами. Вы пишете не my_object.__len__() , а len(my_object) , и, если my_object – экземпляр определенного пользователем клас- са, то Python вызовет реализованный вами метод экземпляра __len__ . Однако для встроенных классов, например list , str, bytearray и т. д., интерпре- татор поступает проще: реализация функции len() в CPython возвращает значе- ние поля ob_size C-структуры PyVarObject , которой представляется любой встро- енный объект в памяти. Это гораздо быстрее, чем вызов метода. Как правило, специальный метод вызывается неявно. Например, предложение for i in x: подразумевает вызов функции iter(x) , которая, в свою очередь, может вызывать метод x.__iter__() , если он реализован. Обычно в вашей программе не должно быть много прямых обращений к специ- альным методам. Если вы не пользуетесь метапрограммированием, то чаще будете реализовывать специальные методы, чем явно вызывать их. Единственный специ-альный метод, которые регулярно вызывается из пользовательского кода напря-мую, – __init__ , он служит для инициализации суперкласса из вашей реализации __init__ . Если необходимо обратиться к специальному методу, то обычно лучше вызвать соответствующую встроенную функцию (например, len, iter , str и т. д.). Она вы- зывает нужный специальный метод и нередко предоставляет дополнительный сервис. К тому же для встроенных типов это быстрее, чем вызов метода. См. раз-дел «Познакомимся с функцией iter поближе» главы 14. Старайтесь не создавать собственные атрибуты с именами вида __foo__ , пото- му что в будущем подобные имена могут получить специальный смысл, даже если в текущей версии это не так. Эмуляция числовых типов Несколько специальных методов позволяют объектам иметь операторы, напри-мер +. Подробно мы рассмотрим этот вопрос в главе 13, а пока проиллюстрируем использование таких методов на еще одном простом примере. Мы реализуем класс для представления двумерных векторов, обычных евкли- довых векторов, применяемых в математике и физике (рис. 1.1). Для представления двумерных векторов можно использовать встроенный класс complex , но наш класс допускает обобщение на n-мерные векторы. Мы займемся этим в главе 14.\n--- Страница 34 ---\n34 Глава 1. Модель данных в языке Python Рис. 1.1. Пример сложения двумерных векторов: Vector(2, 4) + Vector(2, 1) = Vector(4, 5) Для начала спроектируем API класса, написав имитацию сеанса оболочки, ко- торая впоследствии станет doctest-скриптом. В следующем фрагменте тестирует-ся сложение векторов, изображенное на рис. 1.1. >>> v1 = Vector(2, 4)>>> v2 = Vector(2, 1)>>> v1 + v2Vector(4, 5) Отметим, что оператор + порождает результат типа Vector , который отобража- ется в оболочке интуитивно понятным образом. Встроенная функция abs возвращает абсолютное значение вещественного чис- ла – целого или с плавающей точкой – и модуль числа типа complex , поэтому для единообразия в нашем API также используется функция abs для вычисления мо- дуля вектора: >>> v = Vector(3, 4)>>> abs(v)5.0 Мы можем также реализовать оператор *, выполняющий умножение на скаляр (т. е. умножение вектора на число, в результате которого получается новый вектор с тем же направлением и умноженным на данное число модулем): >>> v * 3Vector(9, 12)>>> abs(v * 3)15.0\n--- Страница 35 ---\n35 Строковое представление В примере 1.2 приведен класс Vector , реализующий описанные операции с по- мощью специальных методов __repr__ , __abs__ , __add__ и __mul__ . Пример 1.2. Простой класс двумерного вектора from math import hypot class Vector: def __init__(self, x=0, y=0): self.x = x self.y = y def __repr__(self): return 'Vector(%r, %r)' % (self.x, self.y) def __abs__(self): return hypot(self.x, self.y) def __bool__(self): return bool(abs(self)) def __add__(self, other): x = self.x + other.x y = self.y + other.y return Vector(x, y) def __mul__(self, scalar): return Vector(self.x * scalar, self.y * scalar) Отметим, что ни один из реализованных нами специальных методов (кроме __init__ ) не вызывается напрямую внутри самого класса или при типичном ис- пользовании класса, показанном в листингах сеансов оболочки. Как уже было ска-зано, чаще всего специальные методы вызывает интерпретатор Python. В следую-щих разделах мы обсудим, как писать каждый специальный метод. Строковое представление Специальный метод __repr__ вызывается встроенной функцией repr для полу- чения строкового представления объекта. Если бы мы не реализовали метод __repr__ , то объект класса Vector был бы представлен в оболочке строкой вида <Vector object at 0x10e100070> . Интерактивная оболочка и отладчик вызывают функцию repr , передавая ей ре- зультат вычисления выражения. То же самое происходит при обработке специфи-катора %r в случае классического форматирования с помощью оператора % и при обработке поля преобразования !r в новом синтаксисе форматной строки ( http:// bit.ly/1Vm7gD1 ), применяемом в методе str.format .\n--- Страница 36 ---\n36 Глава 1. Модель данных в языке Python Я в этой книге использую оператор % и метод str.format , как и большая часть сообщества Python. Мне очень нравится более мощный метод str.format , но я знаю, что многие питонисты предпочитают более простой оператор %, так что в обозримом бу- дущем мы, скорее всего, будем встречать в написанных на Python программах оба варианта. Отметим, что в нашей реализации метода __repr__ мы использовали %r для получения стандартного представления отображаемых атрибутов. Это разумный подход, потому что в нем отчетливо проявляется существенное различие между Vector(1, 2) и Vector('1', '2') – второй вариант в контексте этого примера не заработал бы, потому что аргументами конструктора должны быть числа, а не строки. Строка, возвращаемая методом __repr__ , должна быть однозначно определе- на и по возможности соответствовать коду, необходимому для восстановления объекта. Именно поэтому мы выбрали представление, напоминающее вызов кон-структора класса (например, Vector(3, 4) ). В отличие от __repr__ , метод __str__ вызывается конструктором str() и неяв- но используется в функции print . Метод __str__ должен возвращать строку, при- годную для показа пользователям. Если вы реализуете только один из этих двух методов, то пусть это будет __repr__ , потому что в отсутствие пользовательского метода __str__ интерпрета- тор Python вызывает __repr__ . На сайте Stack Overflow был задан вопрос «Difference between __str__ and __repr__ in Python» ( http://bit.ly/1Vm7j1N ), ответ на кото- рый содержит прекрасные разъяснения Алекса Мартелли и Мар-тина Питерса. Арифметические операторы В примере 1.2 реализованы два оператора: + и *, чтобы продемонстрировать прин- ципы работы методов __add__ и __mul__ . Отметим, что оба метода создают и возвра- щают новый экземпляр Vector , не модифицируя ни один операнд, – аргументы self и other только читаются. Это ожидаемое поведение инфиксных операторов: созда- вать новые объекты, не трогая операнды. Я еще вернусь к этому вопросу в главе 13. В примере 1.2 реализовано умножение объекта Vector на число, но не числа на объект Vector , что нарушает свойство коммутатив- ности умножения. В главе 13 мы исправим этот недочет с помо-щью специального метода __rmul__ .\n--- Страница 37 ---\n37 Сводка специальных методов Булево значение пользовательского типа Хотя в Python есть тип bool , интерпретатор принимает любой объект в булевом контексте, например в условии if, в управляющем выражении цикла while или в качестве операнда операторов and, or и not. Чтобы определить, является ли выра- жение истинным или ложным, применяется функция bool(x) , которая возвращает True или False . По умолчанию любой объект пользовательского класса считается истинным, но положение меняется, если реализован хотя бы один из методов __bool__ или __len__ . Функция bool(x) , по существу, вызывает x.__bool__() и использует полу- ченный результат. Если метод __bool__ не реализован, то Python пытается вызвать x.__len__() и при получении нуля функция bool возвращает False . В противном случае bool возвращает True . Наша реализация __bool__ концептуально проста: метод возвращает False , если модуль вектора равен 0, и True в противном случае. Для преобразования мо- дуля в булеву величину мы вызываем bool(abs(self)) , поскольку ожидается, что метод __bool__ возвращает булево значение. Обратите внимание на то, как специальный метод __bool__ обеспечивает согла- сованность пользовательских объектов с правилами проверки значения истинно-сти, определенными в главе «Встроенные типы» ( http://docs.python.org/3/library/ stdtypes.html#truth ) документации по стандартной библиотеке Python. Можно было бы написать более быструю реализацию метода Vector.__bool__ : def __bool__(self): return bool(self.x or self.y) Она сложнее воспринимается, зато позволяет избежать обра- щений к abs и __abs__ , возведения в квадрат и извлечения корня. Явное преобразование в тип bool необходимо, потому что метод __bool__ должен возвращать булево значение, а оператор or воз- вращает один из двух операндов: результат вычисления x or y равен x, если x истинно, иначе равен y вне зависимости от его значения. Сводка специальных методов В главе «Модель данных» ( http://docs.python.org/3/reference/datamodel.html ) справочного руководства по языку Python перечислены 83 специальных метода, из которых 47 используются для реализации операторов: арифметических, пораз-рядных и сравнения.\n--- Страница 38 ---\n38 Глава 1. Модель данных в языке Python Таблицы 1.1 и 1.2 дают представление о том, что имеется в нашем распоряже- нии. Методы сгруппированы в таблицы не совсем так, как в официальной до- кументации. Т аблица 1.1. Имена специальных методов (операторы не включены) Категория Имена методов Представление в виде строк и байтов__repr__, __str__, __format__, __bytes__ Преобразование в число__abs__, __bool__, __complex__, __int__, __float__, __hash__, __index__ Эмуляция коллекций__len__, __getitem__, __setitem__, __delitem__, __contains__ Итерирование __iter__, __reversed__, __next__ Эмуляция объектов, допускающих вызов__call__ Управление контекстом __enter__, __exit__ Создание и уничтожение объектов__new__, __init__, __del__ Управление атрибутами__getattr__, __getattribute__, __setattr__, __delattr__, __dir__ Дескрипторы атрибутов __get__, __set__, __delete__ Сервисы классов __prepare__, __instancecheck__, __subclasscheck__ Т аблица 1.2. Имена специальных методов для операторов Категория Имена методов Унарные числовые операторы __neg__ -, __pos__ +, __abs__ abs() Операторы сравнения __lt__ >, __le__ <=, __eq__ ==, __ne__ !=, __gt__ >, __ge__ >= Арифметические операторы __add__ +, __sub__ -, __mul__ *, __truediv__ /, __floordiv__ //, __mod__ %, __divmod__ divmod(), __pow__ ** or pow(), __round__ round() Инверсные арифметические операторы__radd__, __rsub__, __rmul__, __rtruediv__ , __rfloordiv__, __rmod__, __rdivmod__, __rpow__\n--- Страница 39 ---\n39 Почему len – не метод Категория Имена методов Арифметические операторы присваивания__iadd__, __isub__, __imul__, __itruediv__ , __ifloordiv__, __imod__, __ipow__ Поразрядные операторы __invert__ ~, __lshift__ <<, __rshift__ >>, __and__ &, __or__ |, __xor__ ^ Инверсные поразрядные операторы__rlshift__, __rrshift__, __rand__, __rxor__ , __ror__ Поразрядные операторы составного присваивания__ilshift__, __irshift__, __iand__, __ixor__ , __ior__ Инверсные операторы применяются в случае, когда операнды переставлены местами ( b * a вместо a * b ), а операторы состав- ного присваивания позволяют комбинировать инфиксный опера-тор с присваиванием переменной ( a *= b вместо a = a * b ). В главе 13 инверсные операторы и составное присваивание рас-сматриваются подробнее. Почему len – не метод Я задавал этот вопрос разработчику ядра Раймонду Хэттингеру (Raymond Hettinger) в 2013 году, смысл его ответа содержится в цитате из «Дзен Python» (https://www.python.org/doc/humor/#thezen-of-python ): «практичность важнее чи- стоты». В разделе «Как используются специальные методы» выше я писал, что функция len(x) работает очень быстро, если x – объект встроенного типа. Для встроенных объектов интерпретатор CPython вообще не вызывает методы, а про-сто читает значение, хранящееся в поле C-структуры. Получение количества эле-ментов в коллекции – распространенная операция, которая должна работать эф-фективно для таких разных типов, как str, list , memoryview и т. п. Иначе говоря, len не вызывается как метод, потому что играет особую роль в модели данных Python, равно как и abs. Но благодаря специальному методу __len__ можно вызывать функцию len и для пользовательских объектов. Это раз- умный компромисс между желанием обеспечить как эффективность встроенных объектов, так и согласованность языка. Вот еще цитата из «Дзен Python»: «особые случаи не настолько особые, чтобы из-за них нарушать правила». Если рассматривать abs и len как унарные операторы, то, воз- можно, вы простите их сходство с функциями, а не с вызовами метода, чего следовало бы ожидать от ОО-языка. На самом деле, в языке ABC – непосредственном предшественнике Python, в ко-тором впервые были реализованы многие его средства – суще-\n--- Страница 40 ---\n40 Глава 1. Модель данных в языке Python ствовал оператор #, эквивалентный len (следовало писать #s). При использовании в качестве инфиксного оператора – x#s – он подсчитывал количество вхождений x и s; в Python для этого нуж- но вызвать s.count(x) , где s – произвольная последовательность. Резюме Благодаря реализации специальных методов пользовательские объекты могут вести себя, как встроенные типы. Это позволяет добиться выразительного стиля кодирования, который сообщество считает «питоническим». Важное требование к объекту Python – обеспечить полезные строковые представления себя: одно – для отладки и протоколирования, другое – для по-каза пользователям. Именно для этой цели предназначены специальные методы __repr__ и __str__ . Эмуляция последовательностей, продемонстрированная на примере класса FrenchDeck , – одно из самых распространенных применений специальных мето- дов. У стройство большинства типов последовательностей – тема главы 2, а реали-зация собственных последовательностей будет рассмотрена в главе 10 в контексте создания многомерного обобщения класса Vector . Благодаря перегрузке операторов Python предлагает богатый набор числовых типов, от встроенных до decimal.Decimal и fractions.Fraction , причем все они поддерживают инфиксные арифметические операторы. Реализация операторов, в том числе инверсных и составного присваивания, будет продемонстрирована в главе 13 в процессе обобщения класса Vector . Использование и реализация большинства других специальных методов, вхо- дящих в состав модели данных Python, рассматривается в разных частях книги. Дополнительная литература Глава «Модель данных» ( http://docs.python.org/3/reference/datamodel.html ) спра- вочного руководства по языку Python – канонический источник информации по теме этой главы и значительной части изложенного в книге материала. В книге Alex Martelli «Python in a Nutshell», второе издание (O'Reilly), пре- красно объясняется модель данных. Последнее издание, вышедшее в 2006 году, охватывает версию Python 2.5, но с тех пор модель данных претерпела лишь не-значительные изменения, а данное Мартелли описание механизма доступа к атри-бутам – самое полное из всех, что я видел, если не считать самого исходного кода CPython на C. Мартелли также очень активен на сайте Stack Overflow, ему принад-лежат более 5000 ответов. С его профилем можно ознакомиться по адресу http:// stackoverflow.com/users/95810/alex-martelli . Дэвид Бизли (David Beazley) написал две книги, в которых подробно описыва- ется модель данных в контексте Python 3: «Python Essential Reference», издание 4\n--- Страница 41 ---\n41 Дополнительная литература (Addison-W esley Professional) и «Python Cookbook», издание 3 (O'Reilly), в соав- торстве с Брайаном Л. Джонсом (Brian K. Jones). В книге Gregor Kiczales, Jim des Rivieres, Daniel G. Bobrow «The Art of the Metaobject Protocol» (AMOP , MIT Press) объясняется протокол метаобъектов (MOP), одним из примеров которого является модель данных в Python. Поговорим Модель данных или объектная модель? То, что в документации по Python называется «моделью данных», большинство авторов назвали бы «объектной моделью Python». И Алекс Мартелли в книге «Python in a Nutshell», издание 2, и Дэвид Бизли в книге «Python Essential Reference», издание 4, – лучших книгах по «мо-дели данных Python» – называют ее «объектной моделью». В википедии самое первое определение модели данных ( http://en.wikipedia.org/wiki/ Object_model ) звучит так: «Общие свойства объектов в конкретном язы- ке программирования». Именно в этом и заключается смысл «модели данных Python». В этой книге я употребляю термин «модель данных», потому что его предпочитают авторы документации и потому что так на-зывается глава в справочном руководстве по языку Python ( https://docs. python.org/3/reference/datamodel.html ), имеющая прямое касательство к нашему обсуждению. Магические методы В сообществе Ruby эквиваленты специальных методов называют магическими. Многие пользователи из сообщества Python также вос-приняли этот термин. Лично я считаю, что специальные методы – пря-мая противоположность магии. В этом отношении языки Python и Ruby одинаковы: тот и другой предоставляют развитый протокол метаобъек-тов, отнюдь не магический, но позволяющий пользователям использо-вать те же средства, что доступны разработчикам ядра. Сравним это с JavaScript. В этом языке у встроенных объектов есть действительно магические возможности, т. е. такие, которые невозможно имитировать в пользовательских. Например, до версии JavaScript 1.8.5 нельзя было определить в своем объекте атрибуты, доступные только для чтения, хотя у некоторых встроенных объектов такие атрибуты есть. Следовательно, в JavaScript неизменяемые атрибуты «магические» в том смысле, что требуют наличия сверхъестественных способностей, кото-рыми пользователь языка не был наделен до выхода ECMAScript 5.1 в 2009 году. Протокол метаобъектов в JavaScript развивается, но истори-чески в нем было больше ограничений, чем в Python и Ruby .\n--- Страница 42 ---\n42 Глава 1. Модель данных в языке Python Метаобъекты «The Art of the Metaobject Protocol» (AMOP) – моя любимая кни- га по компьютерам. Но и отбросив в сторону субъективизм, термин «протокол метаобъектов» полезен для размышления о модели данных в Python и о похожих средствах в других языках. Слово «метаобъект» относится к объектам, являющимся структурными элементами самого языка. А «протокол» в этом контексте – синоним слова «интерфейс». Таким образом, протокол метаобъектов – это причудливый синоним «объектной модели»: API для доступа к базовым конструкциям языка. Развитый протокол метаобъектов позволяет расширять язык для поддержки новых парадигм программирования. Грегор Кикзалес, пер-вый автор книги AMOP , впоследствии стал первопроходцем аспек-тно-ориентированного программирования и первоначальным автором AspectJ, расширения Java для реализации этой парадигмы. В дина-мическом языке типа Python реализовать аспектно-ориентированное программирование гораздо проще, и существует несколько каркасов, в которых это сделано. Самым известным из них является каркас zope.interface ( http://docs.zope.org/zope.interface/ ), который вкратце обсуж- дается в разделе «Дополнительная литература» главы 11.\n--- Страница 43 ---\nЧАСТЬ II Структуры данных",
      "debug": {
        "start_page": 28,
        "end_page": 43
      }
    },
    {
      "name": "Глава 2. Массив последовательностей 44",
      "content": "--- Страница 44 --- (продолжение)\nГЛАВА 2. Массив последовательностей Как вы, наверное, заметили, некоторые из упомянутых операций оди-наково работают для текстов, списков и таблиц. Для текстов, списков и таблиц имеется обобщенное название «ряд»[…] Команда FOR также единообразно применяется ко всем рядам. 1 – Geurts, Meertens, Pemberton ABC Programmer 's Handbook До создания Python Гвидо принимал участие в разработке языка ABC. Это был растянувшийся на 10 лет исследовательский проект по программированию среды программирования для начинающих. В ABC первоначально появились многие идеи, которые мы теперь считаем «питоническими»: обобщенные операции с по-следовательностями, встроенные типы кортежа и отображения, структурирова-ние кода с помощью отступов, строгая типизация без объявления переменных и другие. Не случайно Python так дружелюбен к пользователю. Python унаследовал от ABC единообразную обработку последовательностей. Строки, списки, последовательности байтов, массивы, элементы XML, результаты выборки из базы данных – все они имеют общий набор операций, включающий итерирование, получение среза, сортировку и конкатенацию. Зная о различных последовательностях, имеющихся в Python, вы не станете изобретать велосипед, а наличие общего интерфейса побуждает создавать API, которые согласованы с существующими и будущими типами последовательно-стей. Материал этой главы, в основном, относится к последовательностям вообще: от знакомых списков list до типов str и bytes , появившихся в Python 3. Здесь же будет рассмотрена специфика списков, кортежей, массивов и очередей, однако обсуждение строк Unicode и последовательностей байтов мы отложим до главы 4. Кроме того, здесь мы рассматриваем только готовые типы последовательностей, а о том, как создавать свои собственные, поговорим в главе 10. 1 Leo Geurts, Lambert Meertens, Steven Pemberton «ABC Programmer's Handbook», стр. 8.\nГЛАВА 2. Массив последовательностей Как вы, наверное, заметили, некоторые из упомянутых операций оди-наково работают для текстов, списков и таблиц. Для текстов, списков и таблиц имеется обобщенное название «ряд»[…] Команда FOR также единообразно применяется ко всем рядам. 1 – Geurts, Meertens, Pemberton ABC Programmer 's Handbook До создания Python Гвидо принимал участие в разработке языка ABC. Это был растянувшийся на 10 лет исследовательский проект по программированию среды программирования для начинающих. В ABC первоначально появились многие идеи, которые мы теперь считаем «питоническими»: обобщенные операции с по-следовательностями, встроенные типы кортежа и отображения, структурирова-ние кода с помощью отступов, строгая типизация без объявления переменных и другие. Не случайно Python так дружелюбен к пользователю. Python унаследовал от ABC единообразную обработку последовательностей. Строки, списки, последовательности байтов, массивы, элементы XML, результаты выборки из базы данных – все они имеют общий набор операций, включающий итерирование, получение среза, сортировку и конкатенацию. Зная о различных последовательностях, имеющихся в Python, вы не станете изобретать велосипед, а наличие общего интерфейса побуждает создавать API, которые согласованы с существующими и будущими типами последовательно-стей. Материал этой главы, в основном, относится к последовательностям вообще: от знакомых списков list до типов str и bytes , появившихся в Python 3. Здесь же будет рассмотрена специфика списков, кортежей, массивов и очередей, однако обсуждение строк Unicode и последовательностей байтов мы отложим до главы 4. Кроме того, здесь мы рассматриваем только готовые типы последовательностей, а о том, как создавать свои собственные, поговорим в главе 10. 1 Leo Geurts, Lambert Meertens, Steven Pemberton «ABC Programmer's Handbook», стр. 8.\n--- Страница 45 ---\n45 Общие сведения о встроенных последовательностях Общие сведения о встроенных последовательностях Стандартная библиотека предлагает богатый выбор типов последовательностей, реализованных на C: Контейнерные последовательности В последовательностях list , tuple и collections.deque можно хранить эле- менты разных типов. Плоские последовательности В последовательностях str, bytes , bytearray , memoryview и array.array мож- но хранить элементы только одного типа. В контейнерных последовательностях хранятся ссылки на объекты любого типа, тогда как в плоских последовательностях – сами значения. Поэтому плоские последовательности компактнее, но могут содержать только значения примитив-ных типов: символы, байты и числа. Последовательности можно также классифицировать по признаку изменяемо- сти: Изменяемые последовательности list , bytearray , array.array , collections.deque и memoryview . Неизменяемые последовательности tuple , str и bytes . На рис. 2.1 показано, что изменяемые последовательности отличаются от не- изменяемых, хотя и наследуют от них несколько методов. Отметим, что встро-енные конкретные типы последовательностей на самом деле не являются под-классами показанных на рисунке абстрактных базовых классов (ABC) Sequence и MutableSequence , но тем не менее эти ABC полезны, поскольку формализуют функциональность, которую можно ожидать от полноценных типов последова-тельностей. Рис. 2.1. UML-диаграмма нескольких классов из модуля collections.abc (суперклассы показаны слева, стрелки ведут от подклассов к суперклассам, курсивом набраны имена абстрактных классов и абстрактных методов)\n--- Страница 46 ---\n46 Глава 2. Массив последовательностей Помнить об этих общих характеристиках – изменяемый и неизменяемый, кон- тейнерная и плоская последовательность – полезно для экстраполяции знаний об одних последовательностях на другие. Самый фундаментальный тип последовательности – список list , изменяемый и допускающий хранение объектов разных типов. Не сомневаюсь, что вы уверен-но владеете списками, поэтому перейдем прямо к списковому включению (list comprehension), эффективному способу построения списков, которое недостаточ-но широко используется из-за незнакомого синтаксиса. Овладение механизмом спискового включения открывает двери к генераторным выражениям, которые – среди прочего – могут порождать элементы для заполнения последовательностей любого типа. То и другое обсуждается в следующем разделе. Списковое включение и генераторные выражения Чтобы быстро построить последовательность, можно воспользоваться списковым включением (если конечная последовательность – список) или генераторным вы-ражением (для всех прочих типов последовательностей). Если вы не пользуетесь этими средствами в повседневной работе, клянусь, вы упускаете возможность пи-сать код, который одновременно является и более быстрым, и более удобочитае-мым. Если сомневаетесь насчет «большей удобочитаемости», читайте дальше. Я по- пробую вас убедить. Многие программисты для краткости называют списковое вклю- чение listcomp , а генераторное выражение – genexp . Я тоже ино- гда буду употреблять эти слова. Списковое включение и удобочитаемость Вот вам тест: какой код кажется более понятным – в примере 2.1 или 2.2? Пример 2.1. Построить список кодовых позиций Unicode по строке >>> symbols = '$ ¢£¥€¤' >>> codes = []>>> for symbol in symbols: codes.append(ord(symbol)) >>> codes[36, 162, 163, 165, 8364, 164]\n--- Страница 47 ---\n47 Списковое включение и генераторные выражения Пример 2.2. Построить список кодовых позиций Unicode по строке, вторая попытка >>> symbols = '$ ¢£¥€¤' >>> codes = [ord(symbol) for symbol in symbols]>>> codes[36, 162, 163, 165, 8364, 164] Всякий, кто хоть немного знаком с Python, сможет прочитать пример 2.1. Но после того как я узнал о списковом включении, пример 2.2 стал казаться мне более удобочитаемым, потому что намерение программиста в нем выражено отчетливее. Цикл for можно использовать для самых разных целей: просмотра последова- тельности для подсчета или выборки элементов, вычисления агрегатов (суммы, среднего) и т. д. Так, код в примере 2.1 строит список. А у спискового включения только одна задача – построить новый список, ничего другого оно не умеет. Разумеется, списковое включение можно использовать и во вред, так что код станет абсолютно непонятным. Я встречал код на Python, в котором listcomp'ы применялись просто для повторения блока кода ради его побочного эффекта. Если вы ничего не собираетесь делать с порожденным списком, то не пользуйтесь этой конструкцией. Кроме того, не переусердствуйте: если списковое включение занимает больше двух строчек, то, быть может, лучше разбить его на части или переписать в виде старого доброго цикла for. Действуйте по ситуации: в Python, как и в любом естественном языке, не существует твердых и однозначных правил для написания ясного текста. Замечание о синтаксисе В программе на Python переход на другую строку внутри пар скобок [], {} и () игнорируется. Поэтому при построении много-строчных списков, списковых включений, генераторных выраже-ний, словарей и прочего можно обходиться без уродливой косой черты \\ для экранирования символа новой строки. Переменные больше не покидают списковое включение В Python 2.x переменные, значение которым присваивалось в спи- сковом включении, устанавливались в объемлющей области видимости, что иногда приводило к трагическим последствиям. Взгляните на следу-ющий сеанс оболочки в Python 2.7: Python 2.7.6 (default, Mar 22 2014, 22:59:38)[GCC 4.8.2] on linux2Type \"help\", \"copyright\", \"credits\" or \"license» for more information. >>> x = 'my precious'\n--- Страница 48 ---\n48 Глава 2. Массив последовательностей >>> dummy = [x for x in 'ABC'] >>> x'C' Как видите, начальное значение x затерто. В Python 3 такого больше не происходит. У списковых включений, генераторных выражений, а также у род- ственных им словарных и множественных включений теперь имеется собственная локальная область видимости, как у функций. Перемен-ные, которым присвоено значение внутри такого выражения, остают-ся локальными, но на переменные из объемлющей области видимости можно ссылаться. Более того, локальные переменные не маскируют переменные из объемлющей области видимости. Следующий сеанс был записан в Python 3: >>> x = 'ABC'>>> dummy = [ord(x) for x in x]>>> x /g110 'ABC'>>> dummy /g111 [65, 66, 67]>>> /g110 Значение x сохранено. /g111 Списковое включение порождает ожидаемый список. Списковое включение строит список из последовательности или любого дру- гого итерируемого типа путем фильтрации и трансформации элементов. То же са-мое можно было бы сделать с помощью встроенных функций filter и map, но, как мы увидим ниже, удобочитаемость при этом пострадает. Сравнение спискового включения с map и filter Списковое включение может делать все, что умеют функции map и filter , без дополнительных выкрутасов, связанных с использование лямбда-выражений. Взгляните на пример 2.3. Пример 2.3. Один и тот же список, построенный с помощью listcomp и композиции map и filter >>> symbols = '$ ¢£¥€¤' >>> beyond_ascii = [ord(s) for s in symbols if ord(s) > 127]>>> beyond_ascii[162, 163, 165, 8364, 164]>>> beyond_ascii = list(filter(lambda c: c > 127, map(ord, symbols)))>>> beyond_ascii[162, 163, 165, 8364, 164]\n--- Страница 49 ---\n49 Списковое включение и генераторные выражения Раньше я думал, что композиция map и filter быстрее эквивалентного спи- скового включения, но Алекс Мартелли показал, что это не так, по крайней мере, в примере выше. В репозитории кода для этой книги ( https://github.com/ fluentpython/example-code ) имеется скрипт 02-array-seq/listcomp_speed.py (http:// bit.ly/1Vm6R3n ) для сравнения времени работы listcomp и filter/map . В главе 5 я еще вернусь к функциям map и filter . А пока займемся использо- ванием спискового включения для вычисления декартова произведения: списка, содержащего все кортежи, включающие по одному элементу из каждого списка-сомножителя. Декартовы произведения С помощью спискового включения можно сгенерировать список элементов декартова произведения двух и более итерируемых объектов. Декартово произ-ведение – это множество кортежей, включающих по одному элементу из каждого объекта-сомножителя. Длина результирующего списка равна произведению длин входных объектов (рис. 2.2). Рис. 2.2. Декартово произведение последовательности трех достоинств карт и последовательности четырех мастей дает последовательность, состоящую из двенадцати пар Пример 2.4. Построение декартова произведения с помощью спискового включения >>> colors = ['black', 'white'] >>> sizes = ['S', 'M', 'L']>>> tshirts = [(color, size) for color in colors for size in sizes] /g110 >>> tshirts[('black', 'S'), ('black', 'M'), ('black', 'L'), ('white', 'S'), ('white', 'M'), ('white', 'L')]>>> for color in colors: /g111 for size in sizes:\n--- Страница 50 ---\n50 Глава 2. Массив последовательностей print((color, size)) ('black', 'S')('black', 'M')('black', 'L')('white', 'S')('white', 'M')('white', 'L')>>> tshirts = [(color, size) for size in sizes /g112 for color in colors]>>> tshirts[('black', 'S'), ('white', 'S'), ('black', 'M'), ('white', 'M'), ('black', 'L'), ('white', 'L')] /g110 Генерирует список кортежей, упорядоченный сначала по цвету, а затем по размеру. /g111 Обратите внимание, что результирующий список упорядочен так, как если бы циклы были вложены именно в том порядке, в котором указаны в спи-сковом включении. /g112 Чтобы расположить элементы сначала по размеру, а затем по цвету, нужно просто поменять местами предложения for; после переноса второго пред- ложения for на другую строку стало понятнее, как будет упорядочен ре- зультат. В примере 1.1 (глава 1) показанное ниже выражение использовалось для ини- циализации колоды карт списком, состоящим из 52 карт четырех мастей по 13 карт в каждой: self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks] Списковые включения умеют делать всего одну вещь: строить списки. Для порождения последовательностей других типов придется обратиться к генера-торным выражениям. В следующем разделе кратко описывается применение генераторных выражений для построения последовательностей, отличных от списков. Генераторные выражения Инициализацию кортежей, массивов и других последовательностей тоже мож- но начать с использования спискового включения, но genexp экономит память, т. к. отдает элементы по одному, применяя протокол итератора, вместо того чтобы сразу строить целиком список для передачи другому конструктору . Синтаксически генераторное выражение выглядит так же, как списковое вклю- чение, только заключается не в квадратные скобки, а в круглые. Ниже приведены простые примеры использования генераторных выражений для построения кортежа и массива.\n--- Страница 51 ---\n51 Списковое включение и генераторные выражения Пример 2.5. Инициализация кортежа и массива с помощью генераторного выражения >>> symbols = '$ ¢£¥€¤' >>> tuple(ord(symbol) for symbol in symbols) /g110 (36, 162, 163, 165, 8364, 164)>>> import array>>> array.array('I', (ord(symbol) for symbol in symbols)) /g111 array('I', [36, 162, 163, 165, 8364, 164]) /g110 Если генераторное выражение – единственный аргумент функции, то дублировать круглые скобки необязательно. /g111 Конструктор массива принимает два аргумента, поэтому скобки вокруг генераторного выражения обязательны. Первый аргумент конструктора array определяет тип хранения чисел в массив, мы вернемся к этому во- просу в разделе «Массивы» ниже. В примере 2.6 генераторное выражение используется для порождения декарто- ва произведения и последующей распечатки ассортимента футболок двух цветов и трех размеров. В отличие от примера 2.4, этот список футболок ни в какой мо-мент не находится в памяти: генераторное выражение отдает циклу for по одному элементу. Если бы списки, являющиеся сомножителями декартова произведения, содержали по 1000 элементов, то применение генераторного выражения позволи-ло бы сэкономить память за счет отказа от построения списка из миллиона эле-ментов с единственной целью его обхода в цикле for. Пример 2.6. Порождение декартова произведения генераторным выражением >>> colors = ['black', 'white'] >>> sizes = ['S', 'M', 'L']>>> for tshirt in ('%s %s' % (c, s) for c in colors for s in sizes): /g110 print(tshirt) black Sblack Mblack Lwhite Swhite Mwhite L /g110 Генераторное выражение отдает по одному элементу за раз; список, содер- жащий все шесть вариаций футболки, не создается. В главе 14 подробно объясняется, как работают генераторы. Здесь же мы толь- ко хотели показать использование генераторных выражений для инициализации последовательностей, отличных от списков, а также для вывода последователь-ности, не хранящейся целиком в памяти. Перейдем теперь к следующему фундаментальному типу последовательностей в Python: кортежу.\n--- Страница 52 ---\n52 Глава 2. Массив последовательностей Кортеж – не просто неизменяемый список В некоторых учебниках Python начального уровня кортежи описываются как «неизменяемые списки», но это описание неполно. У кортежей две функции: ис-пользование в качестве неизменяемых списков и в качестве записей с неименован-ными полями. Второе применение иногда незаслуженно игнорируется, поэтому начнем с него. Кортежи как записи В кортеже хранится запись: каждый элемент кортежа содержит данные одного поля, а его позиция определяет семантику поля. Если рассматривать кортеж только как неизменяемый список, то количество и порядок элементов могут быть важны или не важны в зависимости от контекста. Но если считать кортеж набором полей, то количество элементов часто фиксиро-вано, а порядок имеет первостепенное значение. В примере 2.7 показано использование кортежей в качестве записей. Отметим, что во всех случаях переупорядочение кортежа уничтожило бы информацию, по-тому что семантика каждого элемента данных определяется его позицией. Пример 2.7. Кортежи как записи >>> lax_coordinates = (33.9425, -118.408056) /g110 >>> city, year, pop, chg, area = ('Tokyo', 2003, 32450, 0.66, 8014) /g111 >>> traveler_ids = [('USA', '31195855'), ('BRA', 'CE342567'), /g112 ('ESP', 'XDA205856')]>>> for passport in sorted(traveler_ids): /g113 print('%s/%s' % passport) /g114 BRA/CE342567ESP/XDA205856USA/31195855>>> for country, _ in traveler_ids: /g115 print(country) USABRAESP /g110 Широта и долгота международного аэропорта Лос-Анджелеса. /g111 Данные о Токио: название, год, численность населения (в миллионах человек), динамика численности населения (в процентах), площадь (в км2). /g112 Список кортежей вида ( код_страны, номер_паспорта ). /g113 При обходе списка с каждым кортежем связывается переменная passport . /g114 Оператор форматирования % понимает кортежи и трактует каждый эле- мент как отдельное поле.\n--- Страница 53 ---\n53 Кортеж – не просто неизменяемый список /g115 Цикл for знает, как извлекать элементы кортежа по отдельности, это назы- вается «распаковкой». В данном случае второй элемент нас не интересует, поэтому он присваивается фиктивной переменной _. Использовать кортежи в качестве записей так удобно благодаря механизму распаковки – теме следующего раздела. Распаковка кортежа В примере 2.7 мы в одном предложении присвоили кортеж ('Tokyo', 2003, 32450, 0.66, 8014) совокупности переменных city , year , pop, chg, area . Затем в последней строке оператор % сопоставил элементы кортежа passport специфика- торам в форматной строке, переданной функции print . То и другое – примеры распаковки кортежа. Распаковка кортежа работает для любого итерируемого объекта. Единственное требование заключается в том, чтобы итерируемый объект отдавал ровно один элемент для каждой переменной в при-нимающем кортеже, если только не указана звездочка (*), которая забирает все оставшиеся элементы, как описывается в разделе «Использование * для выборки лишних элементов» ниже. Термин распаковка кортежа широко распространен среди питонистов, од- нако постепенно приживается и распаковка итерируемого объекта (iterable unpacking), например, в документе «PEP 3132 – Extended Iterable Unpacking» ( http://python.org/dev/peps/pep-3132/ ). Самая очевидная форма распаковки кортежа – параллельное присваивание , т. е. присваивание элементов итерируемого объекта кортежу переменных, как показа-но в следующем примере: >>> lax_coordinates = (33.9425, -118.408056)>>> latitude, longitude = lax_coordinates # tuple unpacking>>> latitude33.9425>>> longitude-118.408056 Элегантное применение распаковки кортежа – обмен значений двух перемен- ных без создания временной переменной: >>> b, a = a, b Другой пример – звездочка перед аргументом при вызове функции: >>> divmod(20, 8)(2, 4)>>> t = (20, 8)>>> divmod(*t)(2, 4)\n--- Страница 54 ---\n54 Глава 2. Массив последовательностей >>> quotient, remainder = divmod(*t) >>> quotient, remainder(2, 4) Здесь также показано еще одно применение распаковки кортежа: возврат не- скольких значений из функции способом, удобным вызывающей программе. На-пример, функция os.path.split() строит кортеж ( path, last_part ) из пути в фай- ловой системе: >>> import os>>> _, filename = os.path.split('/home/luciano/.ssh/idrsa.pub')>>> filename'idrsa .pub' Иногда нас интересуют не все элементы кортежа, тогда остальные можно рас- паковывать в фиктивную переменную, например с именем _, как в примере выше. При создании интернационализированных программ лучше не употреблять _ в качестве имени фиктивной переменной, потому что в соответствии с рекомендациями в документации по модулю gettext так принято обозначать псевдоним функции gettext.gettext (http://docs.python.org/3/library/gettext.html ). В остальных случаях это вполне подходящее имя для фиктивной переменной. Еще один способ извлечь только некоторые элементы распаковываемого кор- тежа – воспользоваться символом *, как описано ниже. Использование * для выборки лишних элементов Определение параметров функции с помощью конструкции *args , позволяющей получить произвольные дополнительные аргументы, – классическая возмож-ность Python. В Python 3 эта идея была распространена на параллельное присваивание: >>> a, b, *rest = range(5)>>> a, b, rest(0, 1, [2, 3, 4])>>> a, b, *rest = range(3)>>> a, b, rest(0, 1, [2])>>> a, b, *rest = range(2)>>> a, b, rest(0, 1, []) В этом контексте префикс * можно поставить только перед одной переменной, которая, впрочем, может занимать любую позицию:\n--- Страница 55 ---\n55 Использование * для выборки лишних элементов >>> a, *body, c, d = range(5) >>> a, body, c, d(0, [1, 2], 3, 4)>>> *head, b, c, d = range(5)>>> head, b, c, d([0, 1], 2, 3, 4) Наконец, очень полезным свойством распаковки кортежа является возмож- ность работы с вложенными структурами. Распаковка вложенного кортежа Кортеж, в который распаковывается выражение, может содержать вложенные кортежи, например (a, b, (c, d)) , и Python правильно заполнит их, если выра- жение соответствует структуру вложенности. В примере 2.8 показана распаковка вложенного кортежа. Пример 2.8. Распаковка вложенных кортежей для доступа к долготе metro_areas = [ ('Tokyo', 'JP', 36.933, (35.689722, 139.691667)), # /g110 ('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889)), ('Mexico City', 'MX', 20.142, (19.433333, -99.133333)), ('New York-Newark', 'US', 20.104, (40.808611, -74.020386)), ('Sao Paulo', 'BR', 19.649, (-23.547778, -46.635833)),]print('{:15} | {:^9} | {:^9}'.format('', 'lat.', 'long.'))fmt = '{:15} | {:9.4f} | {:9.4f}'for name, cc, pop, (latitude, longitude) in metro_areas: # /g111 if longitude <= 0: # /g112 print(fmt.format(name, latitude, longitude)) /g110 Каждый кортеж содержит четыре поля, причем последнее – это пара координат. /g111 Присваивая последнее поле кортежу, мы распаковываем координаты. /g112 У словие if longitude <= 0: отбирает только мегаполисы в Западном полу- шарии. Вот что печатает эта программа: | lat. | long. Mexico City | 19.4333 | -99.1333New York-Newark | 40.8086 | -74.0204Sao Paulo | -23.5478 | -46.6358 До выхода Python 3 можно было определять функции с вложен- ными кортежами в формальных параметрах (например, def fn(a, (b, c), d): ). В Python 3 такие определения не поддерживаются из чисто практических соображений, описанных в документе «PEP\n--- Страница 56 ---\n56 Глава 2. Массив последовательностей 3113 – Removal of Tuple Parameter Unpacking» ( http://python.org/ dev/peps/pep-3113/ ). Уточним: с точки зрения пользователя, вы- зывающего функцию, ничего не изменилось. Ограничение косну-лось только определения функций. Кортежи задуманы как весьма удобное средство. Но при использовании их в качестве записей одной вещи не хватает: иногда желательно поименовать поля. Именно поэтому изобрели функцию namedtuple . Читайте дальше. Именованные кортежи Функция collections.namedtuple – это фабрика, порождающая подклассы tuple , дополненные возможностью задавать имена полей и имя класса; это помо- гает при отладке. Экземпляры класса, построенного с помощью namedtuple , по- требляют ровно столько памяти, сколько кортежи, потому что имена полей хранятся в определении класса. При этом они зани-мают меньше памяти, чем обычные объекты, так как атрибуты не хранятся в атрибуте __dict__ на уровне экземпляра. Вспомните, как мы строили класс Card в примере 1.1: Card = collections.namedtuple('Card', ['rank', 'suit']) В примере 2.9 показано, как можно было бы определить кортеж для хранения информации о городе. Пример 2.9. Определение и использование именованного кортежа >>> from collections import namedtuple >>> City = namedtuple('City', 'name country population coordinates') /g110 >>> tokyo = City('Tokyo', 'JP', 36.933, (35.689722, 139.691667)) /g111 >>> tokyoCity(name='Tokyo', country='JP', population=36.933, coordinates=(35.689722,139.691667))>>> tokyo.population /g112 36.933>>> tokyo.coordinates(35.689722, 139.691667)>>> tokyo[1]'JP' /g110 Для создания именованного кортежа нужно задать два параметра: имя класса и список имен полей; последний может быть любым итерируемым объектом, содержащим строки, или одной строкой, в которой имена пере-числены через запятую.\n--- Страница 57 ---\n57 Использование * для выборки лишних элементов /g111 Данные передаются конструктору в виде позиционных аргументов (тогда как конструктор кортежа принимает единственный итерируемый объект). /g112 К полям можно обращаться по имени или по номеру позиции. Пример 2.10. Атрибуты и методы именованного кортежа (продолжение предыдущего примера) >>> City._fields /g110 ('name', 'country', 'population', 'coordinates')>>> LatLong = namedtuple('LatLong', 'lat long')>>> delhi_data = ('Delhi NCR', 'IN', 21.935, LatLong(28.613889, 77.208889))>>> delhi = City._make(delhi_data) /g111 >>> delhi._asdict() /g112 OrderedDict([('name', 'Delhi NCR'), ('country', 'IN'), ('population',21.935), ('coordinates', LatLong(lat=28.613889, long=77.208889))])>>> for key, value in delhi._asdict().items(): print(key + ':', value) name: Delhi NCR country: INpopulation: 21.935coordinates: LatLong(lat=28.613889, long=77.208889)>>> /g110 _fields – кортеж, содержащий имена полей данного класса. /g111 _make() позволяет создать экземпляр именованного кортежа из итерируе- мого объекта; конструктор City(*delhi_data) делает то же самое. /g112 _asdict() возвращает объект collections.OrderedDict , построенный по именованному кортежу. Это можно использовать для форматирования данных о городе при выводе. Рассмотрев различные способы использования кортежей в качестве записей, мы можем перейти к их второй ипостаси: неизменяемого списка. Кортежи как неизменяемые списки При использовании типа tuple в качестве неизменяемого варианта типа list полезно знать, насколько они похожи. Из табл. 2.1 видно, что tuple поддерживает все методы list , не связанные с добавлением или удалением элементов, за одним исключением – у кортежа нет метода __reversed__ . Но это просто оптимизация; вызов reversed(my_tuple) работает и без него. Т аблица 2.1. Методы и атрибуты списка и кортежа (для краткости методы, унаследованные от object, опущены) list tuple s.__add__(s2) ●● s + s2 – конкатенация s.__iadd__(s2) ● s += s2 – конкатенация на месте\n--- Страница 58 ---\n58 Глава 2. Массив последовательностей list tuple s.append(e) ● Добавление элемента в конец списка s.clear() ● Удаление всех элементов s.__contains__(e) ●● e входит в s s.copy() ● Поверхностная копия списка s.count(e) ●● Подсчет числа вхождений элемента s.__delitem__(p) ● Удаление элемента в позиции p s.extend(it) ●Добавление в конец списка элементов из итерируемого объекта it s.__getitem__(p) ●●s[p] – получение элемента в указанной позиции s.__getnewargs__() ●Для поддержки оптимизированной сериализации с помощью pickle s.index(e) ●● Поиск позиции первого вхождения e s.insert(p, e) ●Вставка элемента e перед элементом в позиции p s.__iter__() ●● Получение итератора s.__len__() ●● len(s) – количество элементов s.__mul__(n) ●● s * n – кратная конкатенация s.__imul__(n) ● s *= n – кратная конкатенация на месте s.__rmul__(n) ●● n * s – инверсная кратная конкатенацияa s.pop([p]) ●Удалить и вернуть последний элемент или элемент в позиции p, если она задана s.remove(e) ●Удалить первое вхождение элемента e, заданного своим значением s.reverse() ●Изменить порядок элементов на противоположный на месте s.__reversed__() ●Получить итератор для перебора элементов от конца к началу s.__setitem__(p, e) ●s[p] = e – поместить e в позицию p вместо находящегося там элемента s.sort([key], [reverse]) ●Отсортировать элементы на месте с факультативными аргументами key и reverse a Инверсные операторы рассматриваются в главе 13.\n--- Страница 59 ---\n59 Получение среза Каждый пишущий на Python программист знает о синтаксисе вырезания ча- стей последовательности – s[a:b] . А мы сейчас рассмотрим менее известные фак- ты об операции получения среза. Получение среза Общей особенностью классов list , tuple , str и прочих типов последовательно- стей в Python является поддержка операций среза, которые обладают куда боль-шими возможностями, чем многие думают. В этом разделе мы опишем использование дополнительных форм срезки. А о том, как реализовать их в пользовательских классах, поговорим в главе 10, не от-ступая от общей установки – в этой части рассматривать готовые классы, а в ча-сти IV – создание новых. Почему в срезы и диапазоны не включается последний элемент Принятое в Python соглашение не включать последний элемент в срезы и диа- пазоны соответствует индексации с нуля, принятой в Python, C и многих других языках. Приведем несколько полезных следствий из этого соглашения. • Легко понять, какова длина среза или диапазона, если задана только конеч- ная позиция: и range(3) , и my_list[:3] содержат три элемента. • Легко вычислить длину среза или диапазона, если заданы начальная и ко- нечная позиция, достаточно вычислить их разность stop - start . • Легко разбить последовательность на две непересекающиеся части по лю- бому индексу x: нужно просто взять my_list[:x] и my_list[x:] . Например: >>> l = [10, 20, 30, 40, 50, 60]>>> l[:2] # разбить в позиции 2[10, 20]>>> l[2:][30, 40, 50, 60]>>> l[:3] # разбить в позиции 3[10, 20, 30]>>> l[3:][40, 50, 60] Но самые убедительные аргументы в пользу этого соглашения изложил гол- ландский ученый, специализирующийся в информатике, Эдсгер Вибе Дейкстра (см. последний пункт в списке дополнительной литературы). Теперь познакомимся ближе с тем, как Python интерпретирует нотацию срезки. Объекты среза Хотя это не секрет, все же напомним, что в выражении s[a:b:c] задается шаг c, что позволяет вырезать элементы не подряд. Шаг может быть отрицательным, тог-да элементы вырезаются от конца к началу. Поясним на примерах:\n--- Страница 60 ---\n60 Глава 2. Массив последовательностей >>> s = 'bicycle' >>> s[::3]'bye'>>> s[::-1]'elcycib'>>> s[::-2]'eccb' Еще один пример был приведен в главе 1, где мы использовали выражение deck[12::13] для выборки всех тузов из неперетасованной колоды: >>> deck[12::13][Card(rank='A', suit='spades'), Card(rank='A', suit='diamonds'),Card(rank='A', suit='clubs'), Card(rank='A', suit='hearts')] Нотация a:b:c допустима только внутри квадратных скобок, когда исполь- зуется в качестве оператора индексирования и порождает объект среза slice(a, b, c) . В разделе «Как работает срезка» на стр. 311 мы увидим, что для вычис- ления выражения seq[start:stop:step] Python вызывает метод seq.__getitem__ (slice(start, stop, step)) . Даже если вы никогда не будете сами реализовывать типы последовательностей, знать об объектах среза полезно, потому что это по-зволяет присваивать срезам имена – по аналогии с именами диапазонов ячеек в электронных таблицах. Пусть требуется разобрать плоский файл данных, например накладную, пока- занную в примере 2.11. Вместо того чтобы загромождать код «зашитыми» диапа-зонами, мы можем поименовать их. Посмотрим, насколько понятным становится при этом цикл for в конце примера. Пример 2.11. Строки из файла накладной >>> invoice = \"\"\" 0 6 40 52 55 1909 Pimoroni PiBrella $17.50 3 $52.50 1489 6mm Tactile Switch x20 $4.95 2 $9.90 1510 Panavise Jr. - PV-201 $28.00 1 $28.00 1601 PiTFT Mini Kit 320x240 $34.95 1 $34.95 \"\"\" >>> SKU = slice(0, 6) >>> DESCRIPTION = slice(6, 40)>>> UNIT_PRICE = slice(40, 52) >>> QUANTITY = slice(52, 55) >>> ITEM_TOTAL = slice(55, None) >>> line_items = invoice.split('\\n')[2:] >>> for item in line_items: print(item[UNIT_PRICE], item[DESCRIPTION]) $17.50 Pimoroni PiBrella $4.95 6mm Tactile Switch x20 $28.00 Panavise Jr. - PV-201 $34.95 PiTFT Mini Kit 320x240\n--- Страница 61 ---\n61 Получение среза Мы еще вернемся к объектам slice , когда дойдем до создания собственных коллекций в разделе «V ector, попытка № 2: последовательность, допускающая срезку» на стр. 310. А пока отметим, что с точки зрения пользователя у операции срезки есть ряд дополнительных возможностей, в частности многомерные срезы и нотация многоточия (…). Читайте дальше. Многомерные срезы и многоточие Оператор [] может принимать несколько индексов или срезов, разделенных запятыми. Это используется, например, в стороннем пакете NumPy, где для полу-чения одного элемента двумерного массива numpy.ndarray применяется нотация a[i, j] , а для получения двумерного среза – нотация a[m:n, k:l] . В примере 2.22 ниже будет продемонстрировано использование этой нотации. Специальные ме-тоды __getitem__ и __setitem__ , на которых основан оператор [], просто прини- мают индексы, заданные в выражении a[i, j] , в виде кортежа. Иначе говоря, для вычисления a[i, j] Python вызывает a.__getitem__((i, j)) . В Python встроены только одномерные типы последовательностей, поэтому они поддерживают лишь один индекс или диапазон, а не кортеж. Многоточие – записывается в виде трех отдельных точек, а не одного симво- ла … (Unicode U+2026) – распознается анализатором Python как лексема. Это псевдоним объекта Ellipsis , единственного экземпляра класса ellipsis2. А раз так, то многоточие можно передавать в качестве аргумента функциям и использо-вать в качестве части спецификации среза, например: f(a, , z) или a[i: ] . В NumPy … используется для сокращенного задания среза многомерного массива; например, если x – четырехмерный массив, то x[i, ] – то же самое, что x[i, :, :, :,] . Дополнительные сведения по этому вопросу можно найти в «Пособии по NumPy для начинающих» ( http://wiki.scipy.org/T entative_NumPy_Tutorial ). На момент написания этой книги мне не было известно о применении объекта Ellipsis или многомерных индексов в стандартной библиотеке Python. Если най- дете, дайте мне знать. Эти синтаксические средства существуют для поддержки пользовательских типов и таких расширений, как NumPy. Срезы полезны не только для выборки частей последовательности; они позво- ляют также модифицировать изменяемые последовательности на месте, т. е. не перестраивая с нуля. Присваивание срезу Изменяемую последовательность можно расширять, схлопывать и иными спо- собами модифицировать на месте, применяя нотацию среза в левой части опера-тора присваивания или в качестве аргумента оператора del. Следующие примеры дают представление о возможностях этой нотации: 2 Нет, я ничего не перепутал: имя класса ellipsis записывается строчными буквами, а его экзем- пляр – встроенный объект Ellipsis . Точно так же обстоит дело с классом bool и его экземпляра- ми True и False .\n--- Страница 62 ---\n62 Глава 2. Массив последовательностей >>> l = list(range(10)) >>> l[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]>>> l[2:5] = [20, 30]>>> l[0, 1, 20, 30, 5, 6, 7, 8, 9]>>> del l[5:7]>>> l[0, 1, 20, 30, 5, 8, 9]>>> l[3::2] = [11, 22]>>> l[0, 1, 20, 11, 5, 22, 9]>>> l[2:5] = 100 /g110 Traceback (most recent call last): File \"<stdin>\", line 1, in <module>TypeError: can only assign an iterable>>> l[2:5] = [100]>>> l[0, 1, 100, 22, 9] /g110 Когда в левой части присваивания стоит срез, в правой должен находиться итерируемый объект, даже если он содержит всего один элемент. Все знают, что конкатенация – распространенная операция для последователь- ностей любого типа. В учебниках Python для начинающих объясняется, как ис-пользовать для этой цели операторы + и *, однако в их работе есть кое-какие тон- кие детали, которые мы сейчас и обсудим. Использование + и * для последовательностей Пишущие на Python программисты ожидают от последовательностей поддержки операторов + и *. Обычно оба операнда + должны быть последовательностями од- ного типа, причем ни один из них не модифицируется, а создается новая последо-вательность того же типа, которая и является результатом конкатенации. Для конкатенации нескольких экземпляров одной последовательности ее можно умножить на целое число. При этом также создается новая последова-тельность: >>> l = [1, 2, 3] >>> l * 5 [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]>>> 5 * 'abcd' 'abcdabcdabcdabcdabcd' Операторы + и * всегда создают новый объект и никогда не изменяют свои операнды.\n--- Страница 63 ---\n63 Использование + и * для последовательностей Остерегайтесь выражений вида a * n , где a – последователь- ность, содержащая изменяемые элементы, потому что результат может оказаться неожиданным. Например, при попытке инициа-лизировать список списков my_list = [[]] * 3 получится список, содержащий три ссылки на один и тот же внутренний список, хотя вы, скорее всего, хотели не этого. В следующем разделе мы рассмотрим ловушки, которые подстерегают нас при попытке использовать * для инициализации списка списков. Построение списка списков Иногда требуется создать список, содержащий несколько вложенных списков, например, чтобы распределить студентов по группам или представить клетки на игровой доске. Лучше всего это делать с помощью спискового включения, как по-казано в примере 2.12. Пример 2.12. Список, содержащий три списка длины 3, может представлять поле для игры в крестики и нолики >>> board = [['_'] * 3 for i in range(3)] /g110 >>> board[['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']]>>> board[1][2] = 'X' /g111 >>> board[['_', '_', '_'], ['_', '_', 'X'], ['_', '_', '_']] /g110 Создать список из трех списков по три элемента в каждом. Взглянуть на его структуру. /g111 Поместить крестик в строку 1 столбец 2 и проверить, что получилось. Соблазнительный, но ошибочный короткий путь показан в примере 2.13. Пример 2.13. Список, содержащий три ссылки на один и тот же список, бесполезен >>> weird_board = [['_'] * 3] * 3 /g110 >>> weird_board[['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']]>>> weird_board[1][2] = 'O' /g111 >>> weird_board[['_', '_', 'O'], ['_', '_', 'O'], ['_', '_', 'O']] /g110 Внешний список содержит три ссылки на один и тот же внутренний спи-Внешний список содержит три ссылки на один и тот же внутренний спи- сок. Пока не сделано никаких изменений, все кажется нормальным. /g111 Поместив нолик в строку 1 столбец 2, мы обнаруживаем, что все строки ссылаются на один и тот же объект.\n--- Страница 64 ---\n64 Глава 2. Массив последовательностей Проблема в том, что код в примере 2.13, по существу, ведет себя так же, как следующий код: row = ['_'] * 3board = []for i in range(3): board .append(row) /g110 /g110 Один и тот же объект row трижды добавляется в список board . C другой стороны, списковое включение из примера 2.12 эквивалентно такому коду: >>> board = []>>> for i in range(3): row = ['_'] * 3 # /g110 board.append(row) >>> board[['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']]>>> board[2][0] = 'X'>>> board # /g111 [['_', '_', '_'], ['_', '_', '_'], ['X', '_', '_']] /g110 На каждой итерации строится новый список row, который добавляется в конец списка board . /g111 Как и положено, изменилась только строка 2. Если проблема или ее решение, представленные в этом разделе, вам не вполне понятны, не огорчайтесь. Г лава 8 специально напи-сана, для того чтобы прояснить механизм работы ссылок и изменя-емых объектов, а также связанные с ним подводные камни. До сих пор мы говорили о простых операторах + и * в применении к последова- тельностям, но существуют также операторы += и *=, которые работают совершен- но по-разному в зависимости от того, изменяема конечная последовательность или нет. Эти различия объяснены в следующем разделе. Составное присваивание последовательностей Поведение операторов составного присваивания += и *= существенно зависит от типа первого операнда. Для простоты мы рассмотрим составное сложение ( +=), но\n--- Страница 65 ---\n65 Составное присваивание последовательностей все сказанное равным образом относится также к оператору *= и другим операто- рам составного присваивания. За оператором += стоит специальный метод __iadd__ (аббревиатура «in-place addition» – сложение на месте). Но если метод __iadd__ не реализован, то Python вызывает метод __add__ . Рассмотрим следующее простое выражение: >>> a += b Если объект a реализует метод __iadd__ , то он и будет вызван. В случае изме- няемых последовательностей (например, list , bytearray , array.array ) a будет изменен на месте (результат получается такой же, как при вызове a.extend(b) ). Если же a не реализует __iadd__ , то выражение a += b вычисляется так же, как a = a + b , т. е. сначала вычисляется a + b и получившийся в результате новый объект связывается с переменной a. Иными словами, идентификатор объекта a остается тем же самым или становится другим в зависимости от наличия ме- тода __iadd__ . Вообще говоря, если последовательность изменяемая, то можно ожидать, что метод __iadd__ реализован и оператор += выполняет сложение на месте. В случае неизменяемых последовательностей такое, очевидно, невозможно. Сказанное об операторе += применимо также к оператору *=, который реализо- ван с помощью метода __imul__ . Специальные методы __iadd__ и __imul__ обсуж- даются в главе 13. Ниже демонстрируется применение оператора *= к изменяемой и неизменяе- мой последовательности: >>> l = [1, 2, 3]>>> id(l)4311953800 /g110 >>> l *= 2>>> l[1, 2, 3, 1, 2, 3]>>> id(l)4311953800 /g111 >>> t = (1, 2, 3)>>> id(t)4312681568 /g112 >>> t *= 2>>> id(t)4301348296 /g113 /g110 Идентификатор исходного списка. /g111 После умножения список – тот же самый объект, в который добавлены новые элементы. /g112 Идентификатор исходного кортежа. /g113 В результате умножения создан новый кортеж Кратная конкатенация неизменяемых последовательностей выполняется неэффективно, потому что вместо добавления новых элементов интерпретатор\n--- Страница 66 ---\n66 Глава 2. Массив последовательностей вынужден копировать всю конечную последовательность, чтобы создать новую с добавленными элементами3. Мы рассмотрели типичные случаи использования оператора +=. А в следующем разделе обсудим интригующий случай, показывающий, что в действительности означает «неизменяемость» в контексте кортежей. Головоломка: присваивание A += Попробуйте, не прибегая к оболочке, ответить на вопрос: что получится в ре- зультате вычисления двух выражений в примере 2.14?4 Пример 2.14. Загадка >>> t = (1, 2, [30, 40]) >>> t[2] += [50, 60] Что произойдет в результате? Какой ответ кажется вам правильным? a. t принимает значение (1, 2, [30, 40, 50, 60]) . b. Возбуждается исключение TypeError с сообщением о том, что объект 'tuple' не поддерживает присваивание. c. Ни то, ни другое.d. И то, и другое. Я был почти уверен, что правильный ответ b, но на самом деле правилен от- вет d: И то, и другое»! В примере 2.15 показан как этот код выполняется в оболочке для версии Python 3.4 (на самом деле, в Python 2.7 происходит то же самое). 5 Пример 2.15. Неожиданный результат: элемент t2 изменился и возбуждено исключение >>> t = (1, 2, [30, 40]) >>> t[2] += [50, 60]Traceback (most recent call last): File «<stdin>», line 1, in <module>TypeError: 'tuple' object does not support item assignment>>> t(1, 2, [30, 40, 50, 60]) Сайт Online Python T utor ( http://www.pythontutor.com/ ) – прекрасный ин- струмент для наглядной демонстрации работы Python. На рис. 2.3 приведены два 3 Тип str – исключение из этого правила. Поскольку построение строки с помощью оператора += в цикле – весьма распространенная операция, в CPython этот случай оптимизирован. Экземпляры str создаются с запасом памяти, чтобы при конкатенации не приходилось каждый раз копировать всю строку. 4 Спасибо Леонардо Рохаэлю и Сезару Каваками, которые предложили эту задачу на Бразильской конференции по языку Python 2013 года. 5 Один читатель указал, что операцию из этого примера можно без ошибок выполнить с помощью выражения t[2].extend([50,60]) . Я это знаю, но цель примера – обсудить странное поведение оператора +=.\n--- Страница 67 ---\n67 Составное присваивание последовательностей снимка экрана, демонстрирующие начальное и конечное состояние кортежа t пос- ле выполнения кода из примера 2.15. Пример 2.16. Байт-код вычисления выражения s[a] += b >>> dis.dis('s[a] += b') 1 0 LOAD_NAME 0 (s) 3 LOAD_NAME 1 (a)6 DUP_TOP_TWO7 BINARY_SUBSCR /g110 8 LOAD_NAME 2 (b)11 INPLACE_ADD /g111 12 ROT_THREE13 STORE_SUBSCR /g112 14 LOAD_CONST 0 (None)17 RETURN_VALUE /g110 Поместить значение s[a] на вершину стека ( TOS). /g111 Выполнить TOS += b . Эта операция завершается успешно, если TOS ссылает- ся на изменяемый объект (в примере 2.15 это список). /g112 Выполнить присваивание s[a] = TOS . Эта операция завершается неудачно, если s – неизменяемый объект (в примере 2.15 это кортеж t). Рис. 2.3. Начальное и конечное состояние кортежа в задаче о присваивании (диаграммы сгенерированы на сайте Online Python Tutor) Изучение байт-кода, который Python генерирует для выражения s[a] += b (пример 2.16), показывает, что происходит на самом деле. Это патологический случай – за 15 лет, что я пишу на Python, я ни разу не слы- шал, чтобы кто-то нарвался на такое поведение на практике. Но из этого примера я вынес три урока.\n--- Страница 68 ---\n68 Глава 2. Массив последовательностей • Не стоит помещать изменяемые элементы в кортежи. • Составное присваивание – не атомарная операция; мы только что видели, как она возбуждает исключение, проделав часть работы. • Изучить байт-код не так уж трудно, и часто это помогает понять, что про- исходит под капотом. Познакомившись с тонкостями использования операторов + и * для конкате- нации, сменим тему и обратимся еще к одной важной операции с последователь-ностями: сортировке. Метод list.sort и встроенная функция sorted Метод list .sort сортирует список на месте, т. е. не создавая копию. Он возвращает None , напоминая, что изменяет объект, а не создает новый список. Это важное со- глашение в Python API: функции и методы, изменяющие объект на месте, должны возвращать None , давая вызывающей стороне понять, что изменился сам объект в противовес созданию нового. Точно такое же поведение демонстрирует, к примеру функция random .shuffle . У соглашения о возврате None в случае обновления на месте есть недостаток: такие методы невозможно соединить в цепочку. На-против, методы, возвращающие новые объекты (например, все методы класса str), можно сцеплять, получая тем самым «теку- чий» интерфейс. Дополнительные сведения по этому вопросу см. в статье википедии «Fluent interface» ( http://en.wikipedia.org/wiki/ Fluent_interface ). C другой стороны, встроенная функция sorted создает и возвращает новый список. На самом деле, она принимает любой итерируемый объект в качестве ар-гумента, в том числе неизменяемые последовательности и генераторы (см. гла-ву 14). Но независимо от типа исходного итерируемого объекта sorted всегда воз- вращает новый список. И метод list.sort , и функция sorted принимают два необязательных имено- ванных аргумента: reverse Если True , то элементы возвращаются в порядке убывания (т. е. инвертиру- ется сравнение элементов). По умолчанию False . key Функция с одним аргументом, которая вызывается для каждого элемента и возвращает его ключ сортировки. Например, если при сортировке списка\n--- Страница 69 ---\n69 Метод list.sort и встроенная функция sorted строк задать key=str.lower , то строки будут сортироваться без учета реги- стра, а если key=len , то по длине в символах. По умолчанию подразумевает- ся тождественная функция (т. е. сравниваются сами элементы). Необязательный именованный параметр key можно также ис- пользовать совместно с встроенными функциями min() и max() и другими функциями из стандартной библиотеки (например, itertools.groupby() или heapq.nlargest() ). Примеры ниже иллюстрируют применение этих функций и именованных ар- гументов6: >>> fruits = ['grape', 'raspberry', 'apple', 'banana'] >>> sorted(fruits)['apple', 'banana', 'grape', 'raspberry'] /g110 >>> fruits['grape', 'raspberry', 'apple', 'banana'] /g111 >>> sorted(fruits, reverse=True)['raspberry', 'grape', 'banana', 'apple'] /g112 >>> sorted(fruits, key=len)['grape', 'apple', 'banana', 'raspberry'] /g113 >>> sorted(fruits, key=len, reverse=True)['raspberry', 'banana', 'grape', 'apple'] /g114 >>> fruits['grape', 'raspberry', 'apple', 'banana'] /g115 >>> fruits.sort() /g116 >>> fruits['apple', 'banana', 'grape', 'raspberry'] /g117 /g110 Порождает новый список строк, отсортированный в алфавитном порядке. /g111 Инспекция исходного списка показывает, что он не изменился. /g112 Это сортировка в обратном алфавитном порядке. /g113 Новый список строк, отсортированный уже по длине. Поскольку алгоритм сортировки устойчивый, строки «grape» и «apple», обе длины 5, остались в том же порядке. /g114 Здесь строки отсортированы в порядке убывания длины. Результат не яв- ляется инверсией предыдущего, потому что в силу устойчивости сортиров-ки «grape» по-прежнему оказывается раньше «apple». /g115 До сих пор порядок исходного списка fruits не изменился. /g116 Этот метод сортирует список на месте и возвращает None (оболочка не по- казывает это значение). /g117 Теперь массив fruits отсортирован. В отсортированной последовательности поиск производится очень эффек- тивно. К счастью, стандартный алгоритм двоичного поиска уже имеется в модуле 6 Примеры заодно демонстрируют, что используемый в Python алгоритм Timsort устойчив (т. е. со- храняет относительный порядок равных элементов). Алгоритм Timsort обсуждается далее на врез-ке «Поговорим» в конце этой главы.\n--- Страница 70 ---\n70 Глава 2. Массив последовательностей bisect из стандартной библиотеки Python. В следующем разделе мы обсудим его основные возможности, включая вспомогательную функцию bisect.insort , кото- рая гарантирует, что отсортированная последовательность такой и останется по-сле вставки новых элементов. Средства работы с упорядоченными последовательностями в модуле bisect В модуле bisect есть две основные функции – bisect и insort , – которые приме- няют алгоритм двоичной сортировки для быстрого поиска и вставки элементов в отсортированную последовательность. Поиск средствами bisect Функция bisect(haystack, needle) производит двоичный поиск иголки needle в стоге сена haystack . Последовательность haystack должна быть отсортирована. Результатом является позиция, в которую нужно было бы вставить needle , чтобы haystack осталась отсортирована в порядке возрастания. Иначе говоря, все элемен- ты до этой позиции меньше или равны needle . Результат вызова bisect(haystack, needle) можно передать в качестве аргумента index методу haystack.insert(index, needle) , однако функция insort выполняет сразу оба шага и делает это быстрее. Раймонд Хэттингер – плодовитый разработчик на Python – опубликовал рецепт «Отсортированная коллекция» ( http://bit. ly/1Vm6WEa ), который основан на модуле bisect , но проще в ис- пользовании, чем автономные функции. В примере 2.17 на тщательно подобранном наборе «иголок» демонстрируется, какие позиции вставки возвращает bisect . Результат показан на рис. 2.4. Пример 2.17. bisect находит точки вставки элементов в отсортированную последовательность import bisect import sys HAYSTACK = [1, 4, 5, 6, 8, 12, 15, 20, 21, 23, 23, 26, 29, 30] NEEDLES = [0, 1, 2, 5, 8, 10, 22, 23, 29, 30, 31] ROW_FMT = '{0:2d} @ {1:2d} {2}{0:<2d}'def demo(bisect_fn): for needle in reversed(NEEDLES): position = bisect_fn(HAYSTACK, needle) /g110 offset = position * ' |' /g111 print(ROW_FMT.format(needle, position, offset)) /g112\n--- Страница 71 ---\n71 if __name__ == '__main__': if sys.argv[-1] == 'left': /g113 bisect_fn = bisect.bisect_left else: bisect_fn = bisect.bisect print('DEMO:', bisect_fn.__name__) /g114 print('haystack ->', ' '.join('%2d' % n for n in HAYSTACK))demo(bisect_fn) /g110 С помощью одной из функций из модуля bisect получить точку вставки. /g111 Построить «забор» из вертикальных черточек. /g112 Напечатать отформатированную строку, показывающую «иголку» и точку вставки. /g113 Выбрать функцию из модуля bisect в соответствии с последним аргумен- том в командной строке. /g114 Напечатать заголовок, содержащий имя выбранной функции. Рис. 2.4. Результат работы программы из примера 2.17 в случае, когда используется функция bisect , – в начале каждой строки печатаются данные в формате needle @ position , а значение needle показано под соответствующей точкой вставки в haystack Поведение bisect настраивается двумя способами. Во-первых, два необязательных аргумента, lo и hi, позволяют сузить область последовательности, в которой производится поиск. По умолчанию lo равно 0, а hi – длине последовательности (результат, возвращаемый функцией len() ). Во-вторых, bisect – на самом деле, псевдоним функции bisect_right , и суще- ствует парная функция bisect_left . Различие между ними проявляется, только Средства работы с упорядоченными последовательностями\n--- Страница 72 ---\n72 Глава 2. Массив последовательностей когда needle в точности равно какому-то элементу списка; в этом случае точка вставки, возвращаемая bisect_right , находится после существующего элемента, а возвращаемая bisect_left совпадает с позицией этого элемента, так что вставка производится перед ним. Для простых типов, например int, это не играет роли, но если последовательность содержит объекты различные, но считающиеся рав-ными, то может оказаться существенно. Например, числа 1 и 1.0 различны, но ре- зультат вычисления 1 == 1.0 равен True . На рис. 2.5 показано, что получается при использовании функции bisect_left . Интерес представляет применение bisect для поиска в числовых таблицах, на- пример, для преобразования экзаменационных баллов из числовой формы в бук-венную (пример 2.18). Рис. 2.5. Результат работы программы из примера 2.17 в случае, когда используется функция bisect_left (сравните с рис. 2.4 и обратите внимание, что точки вставки для значений 1, 8, 23, 29 и 30 находятся слева от равных им чисел в haystack) Пример 2.18. Функция grade возвращает букву, соответствующую числовой оценке за экзамен >>> def grade(score, breakpoints=[60, 70, 80, 90], grades='FDCBA'): i = bisect.bisect(breakpoints, score) return grades[i] >>> [grade(score) for score in [33, 99, 77, 70, 89, 90, 100]]['F', 'A', 'C', 'C', 'B', 'A', 'A'] Приведенный выше код взят из документации по модулю bisect (https://docs. python.org/3/library/bisect.html ), там же показано, как можно использовать bisect в качестве быстрой замены методу index при поиске в длинных упорядоченных последовательностях чисел.\n--- Страница 73 ---\n73 Эти функции применяются не только для поиска, но и для вставки в отсорти- рованную последовательность. Этому вопросу посвящен следующий раздел. Вставка с помощью функции bisect.insort Сортировка – дорогая операция, поэтому если уж имеется отсортированная последовательность, то хорошо бы ее в таком виде и поддерживать. Для этого и предназначена функция bisect.insort . Функция insort(seq, item) вставляет элемент item в последовательность seq, так чтобы seq оставалась в порядке возрастания. См. пример 2.19 и результат его работы на рис. 2.6. Пример 2.19. Insort поддерживает упорядоченность отсортированной последовательности import bisect import random SIZE = 7random.seed(1729)my_list = [] for i in range(SIZE): new_item = random.randrange(SIZE*2) bisect.insort(my_list, new_item) print('%2d ->' % new_item, my_list) Рис. 2.6. Результат работы программы из примера 2.19 Как и bisect , функция insort принимает необязательные аргументы lo и hi, чтобы ограничить поиск подпоследовательностью. Существует также функция insort_left , которая пользуется функцией bisect_left для нахождения точки вставки. Многое из описанного до сих пор относится к любым последовательностям, а не только к списками или кортежам. Программисты на Python иногда чрезмерно увлекаются типом list , просто потому, что он очень удобен, – знаю, сам грешен. Но при работе со списками чисел лучше использовать массивы. Им и посвящен остаток этой главы.Средства работы с упорядоченными последовательностями\n--- Страница 74 ---\n74 Глава 2. Массив последовательностей Когда список не подходит Тип list гибкий и простой в использовании, но не всегда оптимален. Например, если требуется сохранить 10 миллионов чисел с плавающей точкой, то тип array будет гораздо эффективнее, поскольку в нем хранятся не полные объекты float , а только упакованные байты, представляющие их машинные значения, – как в мас-сиве в языке C. С другой стороны, если вы часто добавляете и удаляете элементы из того или другого конца списка, т. е. используете его как структуру данных FIFO или LIFO, то лучше взять тип deque (двусторонняя очередь). Если в программе много проверок на вхождение (например, item in my_collection ), то, возможно, в качестве типа my_collection стоит взять set, особенно если количество элементов велико. Множества оптимизированы для быстрой проверки вхождения. Однако они не упорядочены и потому не являются последова-тельностями. Мы будем рассматривать множества в главе 3. Массивы Если список содержит только числа, то тип array.array эффективнее, чем list : он поддерживает все операции над изменяемыми последовательностями (вклю-чая .pop , .insert и .extend ), а также дополнительные методы для быстрой загруз- ки и сохранения, например .frombytes и .tofile . Массив Python занимает столько же памяти, сколько массив C. При создании экземпляра array задается код типа – буква, определяющая, какой тип C исполь- зовать для хранения элементов. Например, код типа b соответствует типу signed char . Если создать массив array('b') , то каждый элемент будет храниться в одном байте и интерпретироваться как число от –128 до 127. Если последовательность чисел велика, то это позволяет сэкономить много памяти. А Python не даст запи-сать в массив число, не соответствующее заданному типу . В примере 2.20 демонстрируется создание, сохранение и загрузка массива, со- держащего 10 миллионов случайных чисел с плавающей точкой. Пример 2.20. Создание, сохранение и загрузка большого массива чисел с плавающей точкой >>> from array import array /g110 >>> from random import random>>> floats = array('d', (random() for i in range(10**7))) /g111 >>> floats[-1] /g112 0.07802343889111107>>> fp = open('floats.bin', 'wb')>>> floats.tofile(fp) /g113 >>> fp.close()>>> floats2 = array('d') /g114\n--- Страница 75 ---\n75 Когда список не подходит >>> fp = open('floats.bin', 'rb') >>> floats2.fromfile(fp, 10**7) /g115 >>> fp.close()>>> floats2[-1] /g116 0.07802343889111107>>> floats2 == floats /g117 True /g110 Импортировать тип array . /g111 Создать массив чисел с плавающей точкой двойной точности (код типа 'd') из любого итерируемого объекта – в данном случае генераторного вы- ражения. /g112 Прочитать последнее число в массиве. /g113 Сохранить массив в двоичном файле. /g114 Создать пустой массив чисел с плавающей точкой двойной точности. /g115 Прочитать 10 миллионов чисел из двоичного файла. /g116 Прочитать последнее число в массиве. /g117 Проверить, что содержимое обоих массивов совпадает. Как видим, пользоваться методами array.tofile и array.fromfile легко. Вы- полнив этот пример, вы убедитесь, что и работают они очень быстро. Несложный эксперимент показывает, что для загрузки методом array.fromfile 10 миллионов чисел с плавающей точкой двойной точности из двоичного файла, созданного ме-тодом array.tofile , требуется примерно 0,1 с. Это почти в 60 раз быстрее чтения из текстового файла, когда требуется разбирать каждую строку встроенной функ-цией float . Метод array.tofile работает примерно в 7 раз быстрее, чем запись чисел с плавающей точкой в текстовый файл по одному на строку. Кроме того, размер двоичного файла с 10 миллионами чисел двойной точности составляет 80 000 000 байтов (по 8 байтов на число, с нулевыми накладными расходами), а текстового файла с теми же данными – 181 515 739 байтов. Еще один быстрый и более гибкий способ сохранения числовых данных дает модуль pickle (http://bit.ly/py-pickle ), предназначен- ный для сериализации объектов. Сохранение массива чисел с плавающей точкой методом pickle.dump производится почти так же быстро, как методом array.tofile , однако pickle при этом работает почти для всех встроенных типов, в том числе для типа комплексных чисел complex , вложенных коллекций и даже объек- тов пользовательских классов (если их реализация не слишком запутанна). Для частных случаев числовых массивов, представляющих такие двоичные данные, как растровые изображения, в Python имеются типы bytes и bytearray , которые мы обсудим в главе 4.\n--- Страница 76 ---\n76 Глава 2. Массив последовательностей Завершим этот раздел о массивах таблицей 2.2, в которой сравниваются свой- ства типов list и array.array . Т аблица 2.2. Методы и атрибуты типов list и array (нерекомендуемые методы массива, а также унаследованные от object, для краткости опущены) list array s.__add__(s2) ●● s + s2 – конкатенация s.__iadd__(s2) ●● s += s2 – конкатенация на месте s.append(e) ●● Добавление элемента в конец списка s.byteswap() ●Перестановка всех байтов в массиве с целью изменения машинной архитектуры s.clear() ● Удаление всех элементов s.__contains__(e) ●● e входит в s s.copy() ● Поверхностная копия списка s.__copy__() ● Поддержка метода copy.copy s.count(e) ●● Подсчет числа вхождений элемента s.__deepcopy__() ●Оптимизированная поддержка метода copy. deepcopy s.__delitem__(p) ●● Удаление элемента в позиции p s.extend(it) ●●Добавление в конец списка элементов из итерируемого объекта it s.frombytes(b) ●Добавление в конец элементов из последо- вательности байтов, интерпретируемых как упакованные машинные слова s.fromfile(f, n)●Добавление в конец n элементов из двоичного файла f, интерпретируемых как упакованные машинные слова s.fromlist(l) ●Добавление в конец элементов из списка; если хотя бы один возбуждает исключение TypeError , то не добавляется ничего s.__getitem__(p)●●s[p] – получение элемента в указанной позиции s.index(e) ●● Поиск позиции первого вхождения e s.insert(p, e) ●Вставка элемента e перед элементом в позиции p s.itemsize ● Размер каждого элемента массива в байтах\n--- Страница 77 ---\n77 Когда список не подходит list array s.__iter__() ●● Получение итератора s.__len__() ●● len(s) – количество элементов s.__mul__(n) ●● s * n – кратная конкатенация s.__imul__(n) ● s *= n – кратная конкатенация на месте s.__rmul__(n) ●● n * s – инверсная кратная конкатенацияa s.pop([p]) ●●Удалить и вернуть последний элемент или элемент в позиции p, если она задана s.remove(e) ●●Удалить первое вхождение элемента e, заданного своим значением s.reverse() ●●Изменить порядок элементов на противоположный на месте s.__reversed__() ●●Получить итератор для перебора элементов от конца к началу s.__setitem__(p, e) ●●s[p] = e – поместить e в позицию p вместо находящегося там элемента s.sort([key], [reverse]) ●Отсортировать элементы на месте с факуль- тативными аргументами key и reverse s.tobytes() ●Сохранение элементов как упакованных машинных слов в объекте типа bytes s.tofile(f) ●Сохранение элементов как упакованных машинных слов в двоичном файле f s.tolist() ●Сохранение элементов в виде числовых объектов в объекте list s.typecode ●Односимвольная строка, описывающая C-тип элементов a Инверсные операторы рассматриваются в главе 13. В версии Python 3.4, у типа array нет метода сортировки на ме- сте, аналогичного list.sort() . Чтобы отсортировать массив, воспользуйтесь функцией sorted и воссоздайте его в отсортиро- ванном виде: a = array.array(a.typecode, sorted(a)) Чтобы поддерживать массив в отсортированном состоянии при вставке элементов, пользуйтесь функцией bisect.insort (см. раздел «Вставка с помощью функции bisect.insort» выше).\n--- Страница 78 ---\n78 Глава 2. Массив последовательностей Если вы часто работаете с массивами и ничего не знаете о типе memoryview , то много теряете в жизни. Читайте следующий раздел. Представления областей памяти Встроенный класс memoryview – это тип последовательности в общей памяти, который позволяет работать со срезами массивов, ничего не копируя. Он появил-ся под влиянием библиотеки NumPy (которую мы вкратце обсудим ниже). Трэвис Олифант (Travis Oliphant), основной автор NumPy, на вопрос «Когда использо-вать memoryview?» ( http://bit.ly/1Vm6C8B ) отвечает так: По существу, memoryview – это обобщенная структура массива NumPy, встроенная в сам язык Python (но без математических опе-раций). Она позволяет разделять память между структурами дан-ных (например, изображениями в библиотеке PIL, базами данных SQLlite, массивами NumPy и т. д.) без копирования. Для больших наборов данных это очень важно. С применением нотации, аналогичной той, что используется в модуле array , метод memoryview.cast позволяет изменить способ чтения и записи нескольких байтов в виде блоков, не перемещая ни одного бита (как оператор приведения типа в C). Метод memoryview.cast возвращает другой объект memoryview , занимаю- щий то же самое место в памяти. В примере 2.21 показано, как изменить один байт в массиве 16-разрядных це- лых чисел. Пример 2.21. Изменение значения элемента массива путем манипуляции одним из его байтов >>> numbers = array.array('h', [-2, -1, 0, 1, 2]) >>> memv = memoryview(numbers) /g110 >>> len(memv)5>>> memv[0] /g111 -2>>> memv_oct = memv.cast('B') /g112 >>> memv_oct.tolist() /g113 [254, 255, 255, 255, 0, 0, 1, 0, 2, 0]>>> memv_oct[5] = 4 /g114 >>> numbersarray('h', [-2, -1, 1024, 1, 2]) /g115 /g110 Построить объект memoryview из массива пяти целых чисел типа short signed (код типа 'h'). /g111 memv видит те же самые 5 элементов массива. /g112 Создать объект memv_oct , приведя элементы memv к коду типа 'B' ( unsigned char ). /g113 Экспортировать элементы memv_oct в виде списка для инспекции. /g114 Присвоить значение 4 байту со смещением 5.\n--- Страница 79 ---\n79 Когда список не подходит /g115 Обратите внимание, как изменились числа: двухбайтовое число, в котором старший байт равен 4, равно 1024. Мы встретим еще один пример работы с memoryview в контексте манипуляций с двоичными последовательностями с помощью struct (глава 4, пример 4.4). А пока отметим, что для нетривиальных численных расчетов с применением массивов следует использовать библиотеки NumPy и SciPy. Рассмотрим их прямо сейчас. Библиотеки NumPy и SciPy В этой книге я стараюсь ограничиваться тем, что уже есть в стандартной библиотеке Python, и показывать, как извлечь из этого максимум пользы. Но библиотеки NumPy и SciPy – это такое чудо, что заслуживают небольшого от-ступления. Именно чрезвычайно хорошо развитым операциям с массивами и матрицами NumPy и SciPy язык Python обязан признанием со стороны ученых, занимающих-ся вычислительными приложениями. В NumPy реализованы типы многомерных однородных массивов и матриц, в которых можно хранить не только числа, но и определенные пользователем записи. При этом предоставляются эффективные поэлементные операции. Библиотека SciPy, написанная поверх NumPy, предлагает многочисленные вы- числительные алгоритмы, относящиеся к линейной алгебре, численному анали-зу и математической статистике. SciPy работает быстро и надежно, потому что в ее основе лежит широко используемый код на C и Fortran из репозитория Netlib Repository ( http://www.netlib.org ). Иными словами, SciPy дает ученым лучшее из обоих миров: интерактивную оболочку и высокоуровневые API, присущие Python, и оптимизированные функции обработки числовой информации промышленного качества, написанные на C и Fortran. В качестве очень простой демонстрации в примере 2.22 показаны некоторые операции с двумерными массивами в NumPy. Пример 2.22. Простые операции со строками и столбцами из модуля numpy.ndarray >>> import numpy /g110 >>> a = numpy.arange(12) /g111 >>> aarray([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])>>> type(a)<class 'numpy.ndarray'>>>> a.shape /g112 (12,)>>> a.shape = 3, 4 /g113 >>> aarray([[ 0, 1, 2, 3],[ 4, 5, 6, 7],[ 8, 9, 10, 11]])>>> a[2] /g114\n--- Страница 80 ---\n80 Глава 2. Массив последовательностей array([ 8, 9, 10, 11]) >>> a[2, 1] /g115 9>>> a[:, 1] /g116 array([1, 5, 9]) /g117 >>> a .transpose() array([[ 0, 4, 8],[ 1, 5, 9],[ 2, 6, 10],[ 3, 7, 11]]) /g110 Импортировать NumPy, предварительно установив (этот пакет не входит в стандартную библиотеку Python). /g111 Построить и распечатать массив numpy.ndarray , содержащий целые числа от 0 до 11. /g112 Распечатать размерности массива: это одномерный массив с 12 элемента- ми. /g113 Изменить форму массива, добавив еще одно измерение, затем распечатать результат. /g114 Получить строку с индексом 2. /g115 Получить элемент с индексами 2, 1. /g116 Получить столбец с индексом 1. /g117 Создать новый массив, транспонировав исходный (т. е. переставив местами строки и столбцы). NumPy также поддерживает загрузку, сохранение и применение операций сра- зу ко всем элементам массива numpy.ndarray : >>> import numpy>>> floats = numpy.loadtxt('floats-10M-lines.txt') /g110 >>> floats[-3:] /g111 array([ 3016362.69195522, 535281.10514262, 4566560.44373946])>>> floats *= .5 /g112 >>> floats[-3:] array([ 1508181.34597761, 267640.55257131, 2283280.22186973]) >>> from time import perf_counter as pc /g113 >>> t0 = pc(); floats /= 3; pc() - t0 /g114 0.03690556302899495 >>> numpy.save('floats-10M', floats) /g115 >>> floats2 = numpy.load('floats-10M.npy', 'r+') /g116 >>> floats2 *= 6>>> floats2[-3:] /g117 memmap([ 3016362.69195522, 535281.10514262, 4566560.44373946]) /g110 Загрузить 10 миллионов чисел с плавающей точкой из текстового фай- ла. /g111 С помощью нотации получения среза распечатать последние три числа. /g112 Умножить каждый элемент массива floats на 0.5 и снова распечатать по- следние три элемента.\n--- Страница 81 ---\n81 Когда список не подходит /g113 Импортировать таймер высокого разрешения (включен в стандартную библиотеку, начиная с версии Python 3.3). /g114 Разделить каждый элемент на 3; для 10 миллионов чисел с плавающей точкой это заняло менее 40 миллисекунд. /g115 Сохранить массив в двоичном файле с рсаширением .npy . /g116 Загрузить данные в виде спроецированного на память файла в другой массив; это позволяет эффективно обрабатывать срезы массивы, хотя он и не находится целиком в памяти. /g117 Умножить все элементы на 6 и распечатать последние три. Сборка NumPy и SciPy из исходного кода – занятие не для слабых духом. На странице «The Installing the SciPy Stack» сайта SciPy.org ( http://www. scipy.org/install.html ) рекомендуется брать специальные дистрибутивы Python для научных приложений, в том числе Anaconda, Enthought Canopy и WinPython. Это довольно большие файлы, зато готовые к немедленному применению. Пользователи стандартных дистрибутивов GNU/Linux обыч-но могут найти NumPy и SciPy в репозиториях пакетов. Например, для установки в системе Debian или Ubuntu достаточно выполнить команду: $ sudo apt-get install python-numpy python-scipy Этот код приведен, только чтобы разжечь ваш аппетит. NumPy и SciPy –по- трясающие библиотеки, лежащие в основе не менее замечательных библиотек для анализа данных, в т. ч. Pandas ( http://pandas.pydata.org ) и Blaze ( http://blaze. pydata.org/en/latest/ ), которые предоставляют эффективные типы массивов для хранения нечисловых данных, а также функции импорта-экспорта, совместимые с различными форматами (например, CSV , XLS, дамп SQL, HDF5 и т. д.). Эти пакеты заслуживают отдельной книги, правда, не этой. Однако любой обзор по-следовательностей в Python был бы неполным без упоминания о массивах, хотя бы беглого. Познакомившись с плоскими последовательностями – стандартными массива- ми и массивами NumPy, – обратимся совершенно к другой альтернативе старого доброго списка list : очередям. Двусторонние и другие очереди Методы .append и .pop позволяют использовать список list как стек или оче- редь (если вызывать только .append и .pop(0) , то получится дисциплина обслужи- вания LIFO). Однако вставка и удаление элемента из левого конца списка (с ин-дексом 0) обходится дорого, потому что приходится сдвигать весь список. Класс collections.deque – это потокобезопасная двусторонняя очередь, пред- назначенная для быстрой вставки и удаления из любого конца. Эта структура удобна и для хранения списка «последних виденных элементов» и прочего в том же духе, т. к. deque можно сделать ограниченной (при создании задать максималь-\n--- Страница 82 ---\n82 Глава 2. Массив последовательностей ную длину), и тогда по заполнении добавление новых элементов приводит к уда- лению элементов с другого конца. В примере 2.23 показаны типичные операции со структурой deque . Пример 2.23. Работа с очередью >>> from collections import deque >>> dq = deque(range(10), maxlen=10) /g110 >>> dqdeque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], maxlen=10)>>> dq.rotate(3) /g111 >>> dqdeque([7, 8, 9, 0, 1, 2, 3, 4, 5, 6], maxlen=10)>>> dq.rotate(-4)>>> dqdeque([1, 2, 3, 4, 5, 6, 7, 8, 9, 0], maxlen=10)>>> dq.appendleft(-1) /g112 >>> dqdeque([-1, 1, 2, 3, 4, 5, 6, 7, 8, 9], maxlen=10)>>> dq.extend([11, 22, 33]) /g113 >>> dqdeque([3, 4, 5, 6, 7, 8, 9, 11, 22, 33], maxlen=10)>>> dq.extendleft([10, 20, 30, 40]) /g114 >>> dqdeque([40, 30, 20, 10, 3, 4, 5, 6, 7, 8], maxlen=10) /g110 Необязательный аргумент maxlen задает максимальное число элементов в этом экземпляре deque , при этом устанавливается допускающий только чтение атрибут экземпляра maxlen . /g111 В результате циклического сдвига с n > 0 элементы удаляются с правого конца и добавляются с левого; при n < 0 удаление производится с левого конца, а добавление – с правого. /g112 При добавлении элемента в заполненную очередь ( len(d) == d .maxlen ) про- исходит удаление с другого конца; обратите внимание, что в следующей строке элемент 0 отсутствует. /g113 При добавлении трех элементов справа удаляются три элемента слева: –1, 1 и 2. /g114 Отметим, что функция extendleft(iter) добавляет последовательные эле- менты из объекта iter в левый конец очереди, т. е. в итоге элементы будут размещены в порядке, противоположном исходному. В табл. 2.3 сравниваются методы классов list и deque (унаследованные от object не показаны). Отметим, что deque реализует большинство методов list и добавляет несколько новых, связанных с ее назначением, например popleft и rotate . Но существует и скрытая неэффективность: удаление элементов из середины deque производится медленно. Эта структура данных оптимизирована для добавления и удаления элементов только с любого конца.\n--- Страница 83 ---\n83 Когда список не подходит Операции append и popleft атомарны, поэтому deque можно безопасно использовать как LIFO-очередь в многопоточных приложениях без явных блокировок. Т аблица 2.3. Методы, реализованные в классах list и deque (унаследованные от object для краткости опущены) list deque s.__add__(s2) ● s + s2 – конкатенация s.__iadd__(s2) ●● s += s2 – конкатенация на месте s.append(e) ●●Добавление элемента справа (после пос- леднего) s.appendleft(e) ●Добавление элемента слева (перед пер- вым) s.clear() ●● Удаление всех элементов s.__contains__(e) ● e входит в s s.copy() ● Поверхностная копия списка s.__copy__() ●Поддержка copy.copy (поверхностная копия) s.count(e) ●● Подсчет числа вхождений элемента s.__delitem__(p) ●● Удаление элемента в позиции p s.extend(i) ●●Добавление элементов из итерируемого объекта it справа s.extendleft(i) ●Добавление элементов из итерируемого объекта it слева s.__getitem__(p) ●●s[p] – получение элемента в указанной позиции s.index(e) ● Поиск позиции первого вхождения e s.insert(p, e) ●Вставка элемента e перед элементом в позиции p s.__iter__() ●● Получение итератора s.__len__() ●● len(s) – количество элементов s.__mul__(n) ● s * n – кратная конкатенация s.__imul__(n) ● s *= n – кратная конкатенация на месте s.__rmul__(n) ●● n * s – инверсная кратная конкатенацияa s.pop() ●● Удалить и вернуть последний элементb\n--- Страница 84 ---\n84 Глава 2. Массив последовательностей list deque s.popleft() ● Удалить и вернуть первый элемент s.remove(e) ●●Удалить первое вхождение элемента e, за- данного своим значением s.reverse() ●●Изменить порядок элементов на противо- положный на месте s.__reversed__() ●●Получить итератор для перебора элемен- тов от конца к началу s.rotate(n) ●Переместить n элементов из одного конца в другой s.__setitem__(p, e) ●●s[p] = e – поместить e в позицию p вмес- то находящегося там элемента s.sort([key], [reverse]) ●Отсортировать элементы на месте с факультативными аргументами key и reverse a Инверсные операторы рассматриваются в главе 13. b Вызов a_list.pop(p) позволяет удалить элемент в позиции p, но класс deque его не поддерживает Помимо deque , в стандартной библиотеке Python есть пакеты, реализующие другие виды очередей. queue Содержит синхронизированные (т. е. потокобезопасные) классы Queue , Li- foQueue и PriorityQueue . Они используются для безопасной коммуникации между потоками. Все три очереди можно сделать ограниченными, передав конструктору аргумент maxsize , больший 0. Однако в отличие от deque , в случае переполнения элементы не удаляются из очереди, чтобы освободить место, а блокируется вставка новых элементов, т. е. программа ждет, пока какой-нибудь другой поток удалит элемент из очереди. Это полезно для ограничения общего числа работающих потоков. multiprocessing Реализует ограниченную очередь Queue , очень похожую на queue.Queue , но предназначенную для межпроцессной коммуникации. Для упрощения управления задачами имеется также специализированный класс multipro- cessing.JoinableQueue . asyncio Появился в версии Python 3.4, содержит классы Queue , LifoQueue , Priori- tyQueue и JoinableQueue , API которых построен по образцу классов из мо- дулей queue и multiprocessing , но адаптирован для управления задачами в асинхронных программах.\n--- Страница 85 ---\n85 Резюме heapq В отличие от трех предыдущих модулей, heapq не содержит класс очереди, а предоставляет функции, в частности heappush и heappop , которые дают воз- можность работать с изменяемой последовательностью как с очередью с приоритетами, реализованной в виде пирамиды. На этом мы завершаем обзор альтернатив типу list и изучение типов после- довательностей в целом – за исключением особенностей типа str и двоичных по- следовательностей, которым посвящена отдельная глава 4. Резюме Свободное владение типами последовательностей из стандартной библиотеки – обязательное условие написания краткого, эффективного и идиоматичного кода на Python. Последовательности Python часто классифицируются как изменяемые или не- изменяемые, но полезно иметь в виду и другую классификацию: плоские и кон-тейнерные последовательности. Первые более компактные, быстрые и простые в использовании, но в них можно хранить только атомарные данные, т. е. числа, сим-волы и байты. Контейнерные последовательности обладают большей гибкостью, но могут стать источником сюрпризов при хранении в них изменяемых объектов, поэтому при использовании их для размещения иерархических структур данных следует проявлять осторожность. Списковые включения и генераторные выражения – эффективный способ соз- дания и инициализации последовательностей. Если вы еще не освоили эти кон-струкции, потратьте какое-то время на изучение базовых способов их применения. Это нетрудно и очень скоро воздастся сторицей. У кортежей в Python двоякая роль: записи с неименованными полями и не- изменяемые списки. Когда кортеж используется как запись, операция его распа-ковки – самый безопасный и понятный способ получить отдельные поля. Новая синтаксическая конструкция * делает этот механизм еще удобнее, т. к. позволяет игнорировать некоторые поля и корректно обрабатывать необязательные поля. Именованные кортежи появились сравнительно давно, но заслуживают присталь-ного внимания: как и у кортежей, у них очень низкие накладные расходы, но при этом они предлагают удобный доступ к полям по имени и метод ._asdict() для экспорта записи в виде упорядоченного словаря OrderedDict . Получение среза последовательности – одна из самых замечательных синтак- сических конструкций Python, причем многие даже не знают всех ее возможно-стей. Многомерные срезы и нотация многоточия (…), нашедшие применение в NumPy, могут поддерживаться и другими пользовательскими последовательно-стями. Присваивание срезу – очень выразительный способ модификации изменя-емых последовательностей. Кратная конкатенация ( seq * n ) – удобный механизм и при должной осто- рожности может применяться для инициализации списка списков, содержащих\n--- Страница 86 ---\n86 Глава 2. Массив последовательностей изменяемые элементы. Операции составного присваивания += и *= ведут себя по- разному для изменяемых и неизменяемых последовательностей. В последнем слу-чае они по необходимости создают новую последовательность. Но если конечная последовательность изменяемая, то обычно она модифицируется на месте, хотя и не всегда, т. к. это зависит от того, как последовательность реализована. Метод sort и встроенная функция sorted просты в использовании и обладают большой гибкостью благодаря необязательному аргументу key, который представ- ляет собой функцию для вычисления критерия сортировки. Кстати, в качестве key могут выступать и встроенные функции min и max. Для поддержания последова- тельности в отсортированном виде элементы следует вставлять функцией bisect. insort , а для эффективного поиска в отсортированной последовательности при- менять функцию bisect.bisect . Помимо списков и кортежей, в стандартной библиотеке Python имеется класс array .array . И хотя пакеты NumPy и SciPy не входят в стандартную библиотеку, настоятельно рекомендуется хотя бы бегло познакомиться с ними любому, кто за-нимается численным анализом больших наборов данных. В конце главы мы рассмотрели практичный потокобезопасный класс collections .deque , сравнили его API с API класса list (табл. 2.3) и кратко упомя- нули другие реализации очереди, имеющиеся в стандартной библиотеке. Дополнительная литература В главе 1 «Структуры данных» книги David Beazley, Brian K. Jones «Python Cookbook», издание 3 (издательство (O'Reilly), имеется много рецептов, посвя-щенных последовательностям, в том числе рецепт 1.11 «Именованные срезы», из которого я позаимствовал присваивание срезов переменным для повышения удо-бочитаемости кода (пример 2.11). Второе издание книги «Python Cookbook» охватывает версию Python 2.4, но значительная часть приведенного в ней кода работает и в Python 3, а многие рецеп-ты в главах 5 и 6 относятся к последовательностям. Книгу редактировали Алекс Мартелли, Анна Мартелли Равенскрофт и Дэвид Эшер, свой вклад в нее внес-ли также десятки других питонистов. Третье издание было переписано с нуля и в большей степени ориентировано на семантику языка – особенно на изменения, появившиеся в Python 3, – тогда как предыдущие издания посвящены, в основ-ном, прагматике (т. е. способам применения языка для решения практических за-дач). И хотя кое-какой код из второго издания уже нельзя считать наилучшим подходом, я все же полагаю, что полезно иметь под рукой оба издания «Python Cookbook». В официальном документе о сортировке в Python «Sorting HOW TO» ( http:// docs.python.org/3/howto/sorting.html ) приведено несколько примеров продвинуто- го применения sorted и list.sort . Документ «PEP 3132 – Extended Iterable Unpacking» ( http://python.org/dev/ peps/pep-3132/ ) – канонический источник сведений об использовании новой конструкции *extra в правой части параллельного присваивания. Если вам ин-\n--- Страница 87 ---\n87 Дополнительная литература тересна история развития Python, то загляните в обсуждение проблемы «Missing *-unpacking generalizations» ( http://bugs.python.org/issue2292 ), где предлагается еще более общее использование нотации распаковки итерируемых объектов. До-кумент «PEP 448 – Additional Unpacking Generalizations» ( https://www.python.org/ dev/peps/pep-0448/ ) появился в результате этого обсуждения. На момент напи- сания этой книги представляется вероятным, что предлагаемые изменения будут включены в будущую версию Python, возможно, 3.5. Статья в блоге Эли Бендерского «Less Copies in Python with the Buffer Protocol and memoryviews» ( http://bit.ly/1Vm6K7Y ) содержит краткое руководство по ис- пользованию memoryview . На рынке есть немало книг, посвященных NumPy, и в названиях некоторых из них слово «NumPy» отсутствует. Одна из них – книга W es McKinney « Python for Data Analysis » (O'Reilly)7. Научные работники высоко ценят сочетание интерактивной оболочки с мо- щью NumPy и SciPy – настолько, что разработали IPython, невероятно полезную замену стандартной оболочки Python, которая поддерживает также графический интерфейс пользователя, построение графиков, методику «грамотного програм-мирования» (текст, перемежаемый кодом) и вывод в формате PDF . Интерактив-ные мультимедийные сеансы работы с IPython можно даже распространять по протоколу HTTP в виде блокнотов IPython. См. снимки экрана и видеоролики на сайте The IPython Notebook ( http://ipython.org/notebook.html ). IPython настолько популярна, что в 2012 году разработчики ее ядра, большая часть которых рабо-тает в Калифорнийском университете в Беркли, получили грант на 1,15 миллио-на долларов от фонда Слоуна на реализацию дополнительных функций в период 2013–2014. В разделе 8.3 «Коллекции, контейнерные типы данных» документации по стан- дартной библиотеке Python ( https://docs.python.org/3/library/collections.html ) при- ведено несколько коротких примеров и практических рецептов по использованию класса deque (и других коллекций). Лучшие аргументы в поддержку исключения последнего элемента диапа- зона и среза привел сам Эдсгер В. Дейкстра в короткой заметке под название «Why Numbering Should Start at Zero» ( https://www.cs.utexas.edu/users/EWD/ transcriptions/EWD08xx/EWD831.html ). Тема этой заметки – математическая но- тация, но она относится и к Python, потому что проф. Дейкстра строго и с юмором объясняет, почему последовательность 2, 3, …, 12 следует описывать только усло-вием 2 /g100 i < 13. Все прочие разумные соглашения опровергаются, как и мысль о том, чтобы позволить пользователю самому выбирать соглашение. Название за-метки наводит на мысль об индексировании с нуля, но на самом деле речь в ней идет о том, почему 'ABCDE'[1:3] должно означать 'BC' , а не 'BCD' , и почему диа- пазон 2, 3, … , 12 следует записывать в виде range(2, 13) . (Кстати, заметка руко- писная, но вполне разборчивая. Если бы кто-нибудь разработал шрифт по образцу почерка Дейкстры, я бы его купил.) 7 Уэс Маккинни «Python и анализ данных», ДМК Пресс, 2015.\n--- Страница 88 ---\n88 Глава 2. Массив последовательностей Поговорим О природе кортежей В 2012 году я презентовал плакат, касающийся языка ABC на конфе- ренции PyCon US. До создания Python Гвидо работал над интерпрета- тором языка ABC, поэтому пришел посмотреть на мой плакат. По ходу дела мы поговорили о составных объектах в ABC, которые, безусловно, являются предшественниками кортежей Python. Составные объекты также поддерживают параллельное присваивание и используются в ка-честве составных ключей словарей (в ABC они называются таблицами). Однако составные объекты не являются последовательностями. Они не допускают итерирования, к отдельному полю объекта нельзя обратить-ся по индексу, а уж тем более получить срез. Составной объект можно либо обрабатывать целиком, либо выделить поля с помощью параллель-ного присваивания – вот и всё. Я сказал Гвидо, что в силу этих ограничений основная цель состав- ных объектов совершенно ясна: это просто записи с неименованными полями. И вот что он ответил: «То, что кортежи ведут себя как последо-вательности, – просто хак». Это иллюстрация прагматического подхода, благодаря которому Python оказался настолько удачнее и успешнее ABC. С точки зрения разработчика языка заставить кортежи вести себя, как последователь-ности, почти ничего не стоит. Конечно, кортежи получаются не столь «концептуально чистыми», как составные объекты, но зато появляется гораздо больше способов их применения. Их можно даже использовать как неизменяемые списки, подумать только! Наличие в языке неизменяемых списков – очень удобная вещь, и неважно, называются они frozenlist или tuple в роли последователь- ности. «Элегантность – мать простоты» Конструкция *extra для присваивания нескольких элементов пара- метру стала применяться в определениях функций уже давно (у меня есть книга 1996 года издания о версии Python 1.4, в которой она уже описана). Начиная с версии 1.6, синтаксис *extra можно использовать в контексте вызова функции для распаковки итерируемого объекта в несколько аргументов, т. е. для выполнения парной операции. Это эле-гантно, интуитивно понятно и делает функцию apply избыточной (те- перь она исключена из языка). А в Python 3 *extra может стоять и в ле- вой части оператора присваивания и тогда поглощает лишние элемен-ты. Таким образом, и без того полезное языковое средство становится еще более удобным.\n--- Страница 89 ---\n89 Дополнительная литература Плоские и контейнерные последовательности Чтобы подчеркнуть различие между моделями памяти в последова- тельностях разных типов, я воспользовался терминами контейнерная и плоская последовательность . Слово «контейнер» употребляется в документации по модели данных ( https://docs.python.org/3/reference/ datamodel.html#objects-valuesand-types ): Некоторые объекты содержат ссылки на другие объекты, они на- зываются контейнерами. Я остановился на термине «контейнерная последовательность» для большей точности, потому что в Python есть контейнеры, не являющие-ся последовательностями, например dict и set. Контейнерные последо- вательности могут быть вложенными, поскольку могут содержать объ-екты любого типа, в том числе своего собственного. С другой стороны, плоские последовательности не могут быть вло- женными, потому что в них разрешено хранить только простые атомар-ные типы, например: целые, числа с плавающей точки или символы. Я выбрал термин плоская последовательность , потому что нуждался в чем-то, противоположном «контейнерной последовательности». Не могу сослаться на работу, в которой встречалось бы такое употребление этого термина: как категории последовательностей Python, не являю-щихся контейнерами. В википедии такие вещи назвали бы «оригиналь-ными изысканиями». Я предпочитаю говорить «наш термин» в надежде, что он понравится и вам, и вы его примете. Смешанные списки В учебниках Python для начинающих подчеркивается, что списки могут содержать объекты разных типов, но на практике такая возмож-ность не слишком полезна: ведь мы помещаем элементы в список, чтобы впоследствии их обработать, а это значит, что все элементы должны под-держивать общий набор операций (т. е. должны «крякать», даже если не родились утками). Например, в Python 3 невозможно отсортировать список, если его элементы не сравниваются между собой: >>> l = [28, 14, '28', 5, '9', '1', 0, 6, '23', 19]>>> sorted(l)Traceback (most recent call last): File \"<stdin>\", line 1, in <module>TypeError: unorderable types: str() < int() В отличие от списков, кортежи часто содержат элементы разных ти- пов. И это естественно, потому что каждый элемент кортежа – поле, а тип каждого поля не зависит от остальных полей.\n--- Страница 90 ---\n90 Глава 2. Массив последовательностей Аргумент key – истинный бриллиант Необязательный аргумент key метода list.sort и функций sorted , max и min – отличная идея. В других языках вы должны передавать функ- цию сравнения с двумя аргументами, как, например, ныне нерекомен-дуемая функция cmp(a, b) в Python 2. Но использовать key и проще, и эффективнее. Проще – потому что нужно определить функцию всего с одним аргументом, которая извлекает или вычисляет критерий, с помо-щью которого сортируются объекты; это легче, чем написать функцию с двумя аргументами, возвращающую –1, 0 или 1. А эффективнее – пото-му что функция key вызывается только один раз для каждого элемента, тогда как функция сравнения с двумя аргументами – всякий раз, как алгоритму сортировки необходимо сравнить два элемента. Разумеет-ся, Python тоже должен сравнивать ключи во время сортировки, но это сравнение производится в оптимизированном коде на C, а не в написан-ной вами функции Python. Кстати, аргумент key даже позволяет сортировать списки, содержа- щие числа и похожие на числа строки. Нужно только решить, как интер-претировать все объекты: как целые числа или как строки: >>> l = [28, 14, '28', 5, '9', '1', 0, 6, '23', 19] >>> sorted(l, key=int)[0, '1', 5, 6, '9', 14, 19, '23', 28, '28']>>> sorted(l, key=str)[0, '1', 14, 19, '23', 28, '28', 5, 6, '9'] Oracle, Google и таинственный Timbot В функции sorted и методе list .sort используется адаптивный ал- горитм Timsort, который переключается с сортировки вставками на сортировку слиянием в зависимости от того, как упорядочены данные. Это эффективно, потому что в реальных данных часто встречаются уже отсортированные участки. На эту тему есть статья в википедии ( http:// en.wikipedia.org/wiki/Timsort ). Алгоритм Timsort впервые был реализован в CPython в 2002 году. Начиная с 2009 года, Timsort используется также для сортировки мас-сивов в стандартном компиляторе Java и в Android, этот факт стал ши-роко известен, потому что корпорация Oracle использовала относящий-ся к Timsort код как доказательство нарушения Google прав интеллек-туальной собственности компании Sun. См. «Oracle v . Google – Day 14 Filings» ( http://bit.ly/1Vm6Ool ). Алгоритм Timsort изобрел Тим Питерс, разработчик ядра Python, настолько плодовитый, что его считали даже искусственным интеллек-том – Timbot. Об этой конспирологической теории можно прочитать на страничке Python Humor ( https://www.python.org/doc/humor/#id9 ). Тим также автор «Дзен Python»: import this .",
      "debug": {
        "start_page": 44,
        "end_page": 90
      }
    },
    {
      "name": "Глава 3. Словари и множества 91",
      "content": "--- Страница 91 --- (продолжение)\nГЛАВА 3. Словари и множества В любой работающей Python-программе одновременно используется много словарей, даже если в коде словари явно не употребляются. – А. М. Кухлинг, глава 18 «Реализация словарей в Python» Тип dict не только широко используется в наших программах, но является также неотъемлемой частью реализации Python. Пространства имен модулей, атрибуты классов и экземпляров, именованные аргументы функции – лишь некоторые фун-даментальные конструкции, в которых используются словари. Встроенные функ-ции хранятся в словаре __builtins__.__dict__ . В силу своей важности словари в Python высоко оптимизированы. В основе высокопроизводительных словарей лежат хэш-таблицы . В этой главе мы рассмотрим также множества, потому что они тоже реализова- ны с помощью хэш-таблиц. Знание внутреннего механизма работы хэш-таблицы – условие эффективной работы со словарями и множествами. Вот краткое содержание этой главы: • часто используемые методы словаря; • специальная обработка отсутствия ключа;• различные вариации типа dict в стандартной библиотеке; • типы set и frozenset ; • как работают хэш-таблицы;• следствия механизма работы хэш-таблиц (ограничения на тип ключа, не- предсказуемый порядок и т. д.). Общие типы отображений Модуль collections .abc содержит абстрактные базовые классы Mapping и MutableMapping , формализующие интерфейсы типа dict и родственных ему (в вер-\nГЛАВА 3. Словари и множества В любой работающей Python-программе одновременно используется много словарей, даже если в коде словари явно не употребляются. – А. М. Кухлинг, глава 18 «Реализация словарей в Python» Тип dict не только широко используется в наших программах, но является также неотъемлемой частью реализации Python. Пространства имен модулей, атрибуты классов и экземпляров, именованные аргументы функции – лишь некоторые фун-даментальные конструкции, в которых используются словари. Встроенные функ-ции хранятся в словаре __builtins__.__dict__ . В силу своей важности словари в Python высоко оптимизированы. В основе высокопроизводительных словарей лежат хэш-таблицы . В этой главе мы рассмотрим также множества, потому что они тоже реализова- ны с помощью хэш-таблиц. Знание внутреннего механизма работы хэш-таблицы – условие эффективной работы со словарями и множествами. Вот краткое содержание этой главы: • часто используемые методы словаря; • специальная обработка отсутствия ключа;• различные вариации типа dict в стандартной библиотеке; • типы set и frozenset ; • как работают хэш-таблицы;• следствия механизма работы хэш-таблиц (ограничения на тип ключа, не- предсказуемый порядок и т. д.). Общие типы отображений Модуль collections .abc содержит абстрактные базовые классы Mapping и MutableMapping , формализующие интерфейсы типа dict и родственных ему (в вер-\n--- Страница 92 ---\n92 Глава 3. Словари и множества сиях Python 2.6 – 3.2 эти классы импортируются из модуля collections , а не collections .abc) (cм. рис. 3.1). Рис. 3.1. UML-диаграмма класса MutableMapping и его суперклассов из модуля collections.abc (стрелки ведут от подклассов к суперклассам, курсивом набраны имена абстрактных классов и абстрактных методов) Реализации специализированных отображений часто расширяют класс dict или collections.UserDict , а не эти ABC. Основная ценность ABC – документи- рование и формализация минимального интерфейса отображений, а также ис-пользование в тестах с помощью функции isinstance в тех программах, которые должны поддерживать произвольные отображения: >>> my_dict = {}>>> isinstance(my_dict, abc.Mapping)True Использовать isinstance лучше, чем проверять, принадлежит ли аргумент функции типу dict , потому что допустимы также другие типы. Все имеющиеся в стандартной библиотеке типы отображений основаны на dict , поэтому на них распространяется общее ограничение: ключи должны быть хэшируемыми (к значениям это не относится, только к ключам). Что значит «хэшируемый»? Вот часть определения хэшируемости, взятая из глоссария Python (http://bit.ly/1K4qjwE ): Объект называется хэшируемым, если имеет хэш-значение, ко- торое не изменяется на протяжении всего времени его жизни (у него должен быть метод __hash__() ), и допускает сравнение с другими объектами (у него должен быть метод __eq__() ). Если в результате сравнения хэшируемых объектов оказывается, что они равны, то и их хэш-значения должны быть равны. […] Все атомарные неизменяемые типы ( str, bytes , числовые типы) яв- ляются хэшируемыми. Объект типа frozenset всегда хэшируемый, по-\n--- Страница 93 ---\n93 общие типы отображений тому что его элементы должны быть хэшируемыми по определению. Объект типа tuple является хэшируемым только тогда, которые хэши- руемы все его элементы. Взгляните на кортежи tt, tl и tf: >>> tt = (1, 2, (30, 40)) >>> hash(tt)8027212646858338501>>> tl = (1, 2, [30, 40])>>> hash(tl)Traceback (most recent call last): File \"<stdin>\", line 1, in <module>TypeError: unhashable type: 'list'>>> tf = (1, 2, frozenset([30, 40]))>>> hash(tf)-4118419923444501110 На момент написания этой книги в глоссарии Python ут- верждалось ( http://bit.ly/1K4qjwE ): «Все неизменяемые встроенные объекты Python являются хэшируемыми», но это не совсем верно, потому что тип tuple неизве- няемый, но может содержать ссылки на нехэшируемые объекты. Любой пользовательский тип является хэшируемым по определе- нию, потому что его хэш-значение равно id() и никакие два объекта этого типа не равны. Если объект реализует метод __eq__ , учитываю- щий внутреннее состояние, то он будет хэшируемым, только если все атрибуты неизменяемые. Имея в виду эти основополагающие правила, мы можем строить словари не- сколькими способами. На странице «Встроенные типы» ( http://bit.ly/1QS9Ong ) справочного руководства по библиотеке приведен следующий пример, демон-стрирующий различные способы построения словаря: >>> a = dict(one=1, two=2, three=3)>>> b = {'one': 1, 'two': 2, 'three': 3}>>> c = dict(zip(['one', 'two', 'three'], [1, 2, 3]))>>> d = dict([('two', 2), ('one', 1), ('three', 3)])>>> e = dict({'three': 3, 'one': 1, 'two': 2})>>> a == b == c == d == eTrue Кроме литерального синтаксиса и гибкого конструктора класса dict , для по- строения словаря можно использовать словарное включение . Читайте следующий раздел.\n--- Страница 94 ---\n94 Глава 3. Словари и множества Словарное включение Начиная с версии Python 2.7, синтаксис списковых выключений и генераторных выражений расширен на словарные включения (а также на множественные вклю-чения, о которых речь ниже). Словарное включение (dictcomp) строит объект dict , порождая пары key:value из произвольного итерируемого объекта. В примере 3.1 демонстрируется применение словарного включения для построения двух слова-рей из одного и того же списка кортежей. Пример 3.1. Примеры словарных включений >>> DIAL_CODES = [ /g110 (86, 'China'), (91, 'India'), (1, 'United States'), (62, 'Indonesia'), (55, 'Brazil'), (92, 'Pakistan'), (880, 'Bangladesh'), (234, 'Nigeria'), (7, 'Russia'), (81, 'Japan'), ]>>> country_code = {country: code for code, country in DIAL_CODES} /g111 >>> country_code{'China': 86, 'India': 91, 'Bangladesh': 880, 'United States': 1,'Pakistan': 92, 'Japan': 81, 'Russia': 7, 'Brazil': 55, 'Nigeria':234, 'Indonesia': 62}>>> {code: country.upper() for country, code in country_code.items() /g112 if code < 66}{1: 'UNITED STATES', 55: 'BRAZIL', 62: 'INDONESIA', 7: 'RUSSIA'} /g110 Список пар можно использовать непосредственно в конструкторе dict . /g111 Здесь пары инвертированы: ключом является country , а значением – code . /g112 Пары снова инвертируются, значения преобразуются в верхний регистр и оставляются только элементы, для которых code < 66 . Если вы уже освоили списковые включения, то словарные естественно станут следующим шагом. Если нет, то тем больше причин поскорее заняться этим – ведь синтаксис списковых включений теперь обобщен. Теперь перейдем к обзору API отображений. Обзор наиболее употребительных методов отображений Базовый API отображений очень хорошо развит. В табл. 3.1 показаны методы, реа- лизованные в классе dict и двух его самых полезных разновидностях: defaultdict и OrderedDict (тот и другой определены в модуле collections ).\n--- Страница 95 ---\n95 Обзор наиболее употребительных методов отображений Т аблица 3.1. Методы типов отображений types dict , collections .defaultdict и collections .OrderedDict (для краткости методы, унаследованные от object, опущены); необязательные аргументы заключены в квадратные скобки dict defaultdict OrderedDict d.clear()●● ●Удаление всех элементов d.__contains__(k)●● ●k входит в d d.copy()●● ●Поверхностная копия d.__copy__()●Поддержка copy.copy d.default_factory ● Вызываемый объект , к которому обращается ме-тод __missing__ в случае отсутствия значения a s.__delitem__(p) ●● ● del d[k] – удаление элемента с ключом k d.fromkeys(itm [initial]) ●● ● Новое отображение, ключи которого поставля-ет итерируемый объект , и с необязательным на-чальным значением (по умолчанию None ) d.get(k, [default]) ●● ● Получить элемент с ключом k, а если такой ключ отсутствует , вернуть default или None d.__getitem__(k) ●● ● d[k] – получить элемент с ключом k d.items() ●● ● Получить представление элементов – множество пары (key, value) d.__iter__() ●● ● Получение итератора по ключам d.keys() ●● ● Получить представление ключей d.__len__() ●● ● len(d) – количество элементов d.__missing__(k) ● Вызывается, когда __getitem__ не может найти элемент d.move_to_end(k, [last]) ● Переместить ключ k в первую или последнюю позицию ( last по умолча- нию равно True )\n--- Страница 96 ---\n96 Глава 3. Словари и множества dict defaultdict OrderedDict d.pop(k, [default]) ●● ● Удалить и вернуть зна- чение с ключом k, а если такой ключ отсутствует , вернуть default или None d.popitem() ●● ● Удалить и вернуть произ- вольный элемент (key, value) b d.__reversed__() ● Получить итератор для перебора ключей от последнего к первому вставленному d.setdefault(k, [default]) ●● ● Если k принадлежит d, вернуть d[k] , иначе по- ложить d[k] = default и вернуть это значение d.__setitem__(k, v) ●● ● d[k] = v – поместить v в элемент с ключом k d.update(m, [**kargs]) ●● ● Обновить d элемента- ми из отображения или итерируемого объекта, возвращающего пары (key, value) d.values() ●● ● Получить представление значений a default_factory – не метод, а атрибут – вызываемый объект , задаваемый пользователем при создании объекта defaultdict b Метод OrderedDict.popitem() удаляет первый вставленный элемент (дисциплина FIFO); если необязательный аргумент last равен True , то удаляет последний вставленный элемент (дисциплина LIFO) То, как метод update трактует свой первый аргумент m, – яркий пример динами- ческой типизации (duck typing): сначала проверяется, есть ли у m метод keys и, если да, то предполагается, что это отображение. В противном случае update произво- дит обход m в предположении, что элементами являются пары (key, value) . Кон- структоры большинства отображений в Python применяют логику метода update , а, значит, отображение можно инициализировать как другим отображением, так и произвольным итерируемым объектом, порождающим пары (key, value) . Метод setdefault – тонкая штучка. Нужен он не всегда, но, когда нужен, по- зволяет существенно ускорить работу, избегая излишних операций поиска клю-ча. В следующем разделе на практическом примере объясняется, как им пользо-ваться.\n--- Страница 97 ---\n97 Обзор наиболее употребительных методов отображений Обработка отсутствия ключей с помощью setdefault В полном соответствии с философией «быстрого прекращения» доступ к слова- рю dict с помощью конструкции d[k] возбуждает исключение, если ключ k отсут- ствует. Любой питонист знает об альтернативной конструкции d.get(k, default) , которая применяется вместо d[k] , если иметь значение по умолчанию удобнее, чем обрабатывать исключение KeyError . Однако если нужно обновить найденное значение (при условии, что оно изменяемо), то и __getitem__ , и get оказываются неудобны и неэффективны. В примере 3.2 показан неоптимальный скрипт, демон-стрирующий одну ситуацию, когда dict.get – не лучший способ обработки от- сутствия ключа. Пример 3.2 основан на примере Алекса Мартелли1, он генерирует индекс, по- казанный в примере 3.3. Пример 3.2. index0.py: применение метода dict.get для выборки и обновления списка вхождений слова в индекс (в примере 3.4 показано лучшее решение) \"\"\"Строит индекс, отображающий слово на список его вхождений\"\"\" import sys import re WORD_RE = re.compile('\\w+')index = {}with open(sys.argv[1], encoding='utf-8') as fp: for line_no, line in enumerate(fp, 1): for match in WORD_RE.finditer(line): word = match.group() column_no = match.start()+1 location = (line_no, column_no) # некрасиво; написано только для демонстрации идеи occurrences = index.get(word, []) /g110 occurrences.append(location) /g111 index[word] = occurrences /g112 # напечатать в алфавитном порядке for word in sorted(index, key=str.upper): /g113 print(word, index[word]) /g110 Получить список вхождений слова word или [], если оно не найдено. /g111 Добавить новое вхождение в occurrences . /g112 Поместить модифицированный список occurrences в словарь dict ; при этом производится второй поиск в индексе. 1 Оригинальный скрипт представлен на слайде 41 презентации Мартелли «Учим Python заново» (http://bit.ly/1QmmPFj ). Его скрипт демонстрирует использование dict.setdefault , показанное в примере 3.4.\n--- Страница 98 ---\n98 Глава 3. Словари и множества /g113 При задании аргумента key функции sorted мы не вызываем str.upper , а только передаем ссылку на этот метод, чтобы sorted могла нормализовать слова перед сортировкой2. Пример 3.3. Частичная распечатка результата работы скрипта 3.2, примененного к «Дзен Python»; в каждой строке присутствует слово и список его вхождений в виде пар (номер-строки, номер-колонки) $ python3 index0.py / /data/zen.txt a [(19, 48), (20, 53)]Although [(11, 1), (16, 1), (18, 1)]ambiguity [(14, 16)]and [(15, 23)]are [(21, 12)]aren [(10, 15)]at [(16, 38)]bad [(19, 50)]be [(15, 14), (16, 27), (20, 50)]beats [(11, 23)]Beautiful [(3, 1)]better [(3, 14), (4, 13), (5, 11), (6, 12), (7, 9), (8, 11),(17, 8), (18, 25)] Три строчки, относящиеся к обработке occurrences в примере 3.2, можно за- менить одной, воспользовавшись методом dict.setdefault . Пример 3.4 ближе к оригинальному примеру Алекса Мартелли. Пример 3.4. index.py: применение метода dict.setdefault для выборки и обновления списка вхождений слова в индекс; в отличие от примера 3.2 понадобилась только однастрочка \"\"\"Строит индекс, отображающий слово на список его вхождений\"\"\" import sys import re WORD_RE = re.compile('\\w+')index = {}with open(sys.argv[1], encoding='utf-8') as fp: for line_no, line in enumerate(fp, 1): for match in WORD_RE.finditer(line): word = match.group() column_no = match.start()+1 location = (line_no, column_no) index.setdefault(word, []).append(location) /g110 # напечатать в алфавитном порядке 2 Здесь мы видим пример использования метода в качестве полноправной функции, подробнее эта тема обсуждается в главе 5.\n--- Страница 99 ---\n99 Отображения с гибким поиском по ключу for word in sorted(index, key=str.upper): print(word, index[word]) /g110 Получаем список вхождений слова word или устанавливаем его равным [], если оно не найдено; теперь список можно обновить без повторного поиска. Иными словами, строка… my_dict.setdefault(key, []).append(new_value) … дает такой же результат, как … if key not in my_dict: my_dict[key] = []my_dict[key].append(new_value) … с тем отличием, что во втором фрагменте производится по меньшей мере два поиска ключа (три, если ключ не найден), тогда как setdefault довольствуется единственным поиском. Смежный вопрос – обработка отсутствия ключа при любом поиске (а не только при вставке) – тема следующего раздела. Отображения с гибким поиском по ключу Иногда удобно, чтобы отображение возвращало некоторое специальное значение, если искомый ключ отсутствует. К решению этой задачи есть два подхода: пер-вый – использовать класс defaultdict вместо dict , второй – создать подкласс dict или любого другого типа отображения и добавить метод __missing__ . Ниже рас- сматриваются оба способа. defaultdict: еще один подход к обработке отсутствия ключа В примере 3.5 показано элегантное применение класса collections.defaultdict для решения той же задачи, что в примере 3.4. Объект defaultdict сконфигуриро- ван так, что по запросу возвращает элементы, когда искомый ключ отсутствует. Работает это следующим образом: при конструировании объекта defaultdict задается вызываемый объект, который порождает значение по умолчанию всякий раз, как методу __getitem__ передается ключ, отсутствующий в словаре. Например, пусть defaultdict создан как dd = defaultdict(list) . Тогда, если ключ 'new-key' отсутствует в dd, то при вычислении выражения dd['new-key'] вы- полняются следующие действия: 1. Вызвать list() для создания нового списка. 2. Вставить список в dd в качестве значения ключа 'new-key' . 3. Вернуть ссылку на этот список.\n--- Страница 100 ---\n100 Глава 3. Словари и множества Вызываемый объект, порождающий значения по умолчанию, хранится в атри- буте экземпляра default_factory . Пример 3.5. index_default.py: использование экземпляра defaultdict вместо метода setdefault \"\"\"Строит индекс, отображающий слово на список его вхождений\"\"\" import sys import reimport collections WORD_RE = re.compile('\\w+')index = collections.defaultdict(list) /g110 with open(sys.argv[1], encoding='utf-8') as fp: for line_no, line in enumerate(fp, 1): for match in WORD_RE.finditer(line): word = match.group() column_no = match.start()+1 location = (line_no, column_no) index[word].append(location) /g111 # напечатать в алфавитном порядке for word in sorted(index, key=str.upper): print(word, index[word]) /g110 Создаем defaultdict , задав в качестве default_factory конструктор list . /g111 Если слова word еще нет в index , то вызывается функция default_factory , которая порождает отсутствующее значение – в данном случае пустой список. Это значение присваивается index[word] и возвращается, так что операция .append(location) всегда завершается успешно. Если атрибут default_factory не задан, то в случае отсутствия ключа, как обычно, воз- буждается исключение KeyError . Атрибут default_factory объекта defaultdict вызывается толь- ко для того, чтобы предоставить значение по умолчанию при обращении к методу __getitem__ и только к нему. Например, если dd – объект класса defaultdict и k – отсутствующий ключ, то при вычислении выражения dd[k] происходит обращение к default_factory для создания значения по умолчанию, а вызов dd.get(k) все равно возвращает None . А почему defaultdict обращается к default_factory ? Всему виной специаль- ный метод __missing__ , который поддерживается всеми стандартными типами отображений. Его мы и обсудим далее.\n--- Страница 101 ---\n101 Отображения с гибким поиском по ключу Метод __missing__ В основе механизма обработки отсутствия ключей в отображениях лежит ме- тод, которому как нельзя лучше подходит имя __missing__ . Он не определен в ба- зовом классе dict , но dict знает о нем: если создать подкласс dict и реализовать в нем метод __missing__ , то стандартный метод dict.__getitem__ будет обращаться к нему всякий раз, как не найдет ключ, – вместо того чтобы возбуждать исключение KeyError . Метод __missing__ вызывается только из метода __getitem__ (т . е. при выполнении оператора d[k] ). Наличие __missing__ никак не влияет на поведение других методов, которые производят по-иск по ключу, например get или __contains__ (который поддержи- вает оператор in). Именно поэтому атрибут default_factory объ- екта defaultdict работает только с __getitem__ , как отмечалось в предостережении в конце предыдущего раздела. Допустим, нам нужно отображение, в котором ключ перед поиском преоб- разуется в тип str. Конкретный пример дает проект Pingo.io ( http://www.pingo. io/docs/ ), в котором программируемая плата с контактами GPIO (например, Raspberry Pi или Arduino) представлена объектом board с атрибутом board .pins , который является отображением мест расположения физических контактов на объекты контактов, а физическое местоположение может задаваться числом или строкой вида \"A0\" либо \"P9_12\" . Для единообразия желательно, чтобы все клю- чи board .pins были строками, но хорошо бы, чтобы и обращение вида my_arduino . pin[13] тоже работало, тогда начинающие не будут впадать в ступор, желая зажечь светодиод, подключенный к контакту 13 на плате Arduino. В примере 3.6 показано, как такое отображение могло бы быть реализовано. Пример 3.6. При поиске по нестроковому ключу объект StrKeyDict 0 преобразует его в тип str в случае отсутствия Tests for item retrieval using `d[key]` notation:: >>> d = StrKeyDict0([('2', 'two'), ('4', 'four')]) >>> d['2'] 'two' >>> d[4] 'four' >>> d[1] Traceback (most recent call last): KeyError: '1' Tests for item retrieval using `d.get(key)` notation:: >>> d.get('2')\n--- Страница 102 ---\n102 Глава 3. Словари и множества 'two' >>> d.get(4) 'four' >>> d.get(1, 'N/A') 'N/A' Tests for the `in` operator:: >>> 2 in d True >>> 1 in d False В примере 3.7 реализован класс StrKeyDict0 , для которого все приведенные выше тесты проходят. Более правильный способ реализовать тип отображения – унас- ледовать классу collections.UserDict , а не dict (мы так и по- ступим в примере 3.8). Здесь мы создали подкласс dict просто для демонстрации того, что метод __missing__ поддерживается встроенным методом dict.__getitem__ . Пример 3.7. Класс StrKeyDict0 преобразует нестроковые ключи в тип str во время поиска (см. тесты в примере 3.6) class StrKeyDict0(dict): /g110 def __missing__(self, key): if isinstance(key, str): /g111 raise KeyError(key) return self[str(key)] /g112 def get(self, key, default=None): try: return self[key] /g113 except KeyError: return default /g114 def __contains__(self, key): return key in self.keys() or str(key) in self.keys() /g115 /g110 StrKeyDict0 наследует dict . /g111 Проверяем, принадлежит ли ключ key типу str. Если да и при этом отсутствует в словаре, возбуждаем исключение KeyError . /g112 Преобразуем key в str и ищем. /g113 Метод get делегирует свою работу методу __getitem__ благодаря нотации self[key] ; это приводит в действие наш метод __missing__ .\n--- Страница 103 ---\n103 Вариации на тему dict /g114 Если возникло исключение KeyError , значит, метод __missing__ уже завер- шился с ошибкой, поэтому возвращаем default . /g115 Ищем сначала по немодицированному ключу (экземпляр может содержать нестроковые ключи), а затем по строке, построенной по ключу . Задайтесь вопросом, зачем в реализации __missing__ необходима проверка isinstance(key, str) . Без этой проверки наш метод __missing__ работал бы для любого ключа k – не- важно, принадлежит он типу str или нет, – если только str(k) порождает суще- ствующий ключ. Но если ключ str(k) не существует, то возникла бы бесконечная рекурсия. В последней строке вычисление self[str(key)] привело бы к вызову __getitem__ с параметром, равным строковому представлению ключу, а это, в свою очередь, – снова к вызову __missing__ . Метод __contains__ в этом примере также необходим для обеспечения согласо- ванного поведения, потому что его вызывает операция k in d , однако реализация этого метода, унаследованная от dict , не обращается к __missing__ в случае от- сутствия ключа. В нашей реализации __contains__ есть тонкий нюанс: мы не про- веряем наличие ключа принятым в Python способом – k in my_dict – потому что конструкция str(key) in self привела бы к рекурсивному вызову __contains__ . Чтобы избежать этого, мы явно ищем ключ в self.keys() . Поиск вида k in my_dict.keys() эффективен в Python 3 даже для очень больших отображений, потому что dict.keys() возвращает представление, похожее на множество, а проверка вхождения для множества производится так же быстро, как для словаря. Детали описаны в разделе документации «Объекты представления сло-варя» ( http://bit.ly/1Vm7E4q ). В Python 2 dict.keys() возвращает список, поэтому наше решение будет работать и в этом случае, но для больших словарей оно неэффективно, потому что при вы-числении k in my_list приходится просматривать весь список. Проверка наличия немодифицированного ключа – key in self.keys() – не- обходимо для корректности, потому что класс StrKeyDict0 не гарантирует, что все ключи словаря обязательно имеют тип str. Наша цель состоит только в том, чтобы сделать поиск более дружелюбным, а не навязывать пользователю типы. До сих пор мы рассматривали типы отображений dict и defaultdict , но в стан- дартной библиотеке имеются и другие реализации отображения. Обсудим их. Вариации на тему dict В этом разделе мы дадим обзор типов отображений, включенных в модуль стан-дартной библиотеки collections (помимо рассмотренного выше defaultdict ):\n--- Страница 104 ---\n104 Глава 3. Словари и множества collections.OrderedDict Ключи хранятся в том порядке, в котором вставлялись, так что порядок их обхода предсказуем. Метод popitem класса OrderedDict по умолчанию удаляет и возвращает первый элемент, но если вызывается так: my_odict. popitem(last=True) , то последний. collections .ChainMap Хранит список отображений, так что их можно просматривать как единое целое. Поиск производится в каждом отображении по порядку и заверша-ется успешно, если ключ найден хотя бы в одном. Это полезно в интерпре-таторах языков с вложенными областями видимости, когда каждая область видимости представлена отдельным отображением. В разделе «Объекты ChainMap» документации по модулю collections (http://bit.ly/1Vm7I4c: ) есть несколько примеров использования ChainMap , включая и следующий фрагмент, иллюстрирующий базовые правила поиска имен переменных в Python: import builtinspylookup = ChainMap(locals(), globals(), vars(builtins)) collections .Counter Отображение, в котором с каждым ключом ассоциирован счетчик. Обнов- ление существующего ключа увеличивает его счетчик. Этот класс можно использовать для подсчета количества хэшируемых объектов (ключей) или в качестве мультимножества – множества, в которое каждый эле-мент может входить несколько раз. В классе Counter реализованы опера- торы + и - для объединения серий и другие полезные методы, например most_common([n]) , который возвращает упорядоченный список кортежей, содержащий n самых часто встречающихся элементов вместе с их счетчи- ками; документацию см. по адресу http://bit.ly/1JHVi2E . Ниже демонстри- руется применение Counter для подсчета числа различных букв в слове: >>> ct = collections.Counter('abracadabra')>>> ctCounter({'a': 5, 'b': 2, 'r': 2, 'c': 1, 'd': 1})>>> ct.update('aaaaazzz')>>> ctCounter({'a': 10, 'z': 3, 'b': 2, 'r': 2, 'c': 1, 'd': 1})>>> ct.most_common(2)[('a', 10), ('z', 3)] collections .UserDict Реализация на чистом Python отображения, работающего как стандартный словарь dict . Если классы OrderedDict , ChainMap и Counter уже готовы для использования, то UserDict предназначен для наследования, что мы и про- делаем ниже.\n--- Страница 105 ---\n105 Создание подкласса UserDict Создание подкласса UserDict Почти всегда проще создать новый тип отображения путем расширения UserDict , а не dict . Ценность этого подхода можно оценить на примере класса StrKeyDict0 из примера 3.7, который преобразует ключ любого типа в тип str на этапе поиска. Основная причина, по которой предпочтительнее наследовать классу UserDict , а не dict , заключается в том, что в реализации dict некоторые углы срезаны, что вынуждает нас переопределять методы, которые можно безо всяких проблем унас-ледовать от UserDict3. Отметим, что UserDict не наследует dict , а хранит внутри себя экземпляр dict в атрибуте data , где и находятся сами элементы. Это позволяет избежать нежела- тельной рекурсии при кодировании таких специальных методов, как __setitem__ , и упрощает код __contains__ по сравнению с тем, что показан в примере 3.7. Благодаря UserDict класс StrKeyDict (пример 3.8) получился короче, чем StrKeyDict0 (пример 3.7), но умеет при этом больше: он хранит все ключи в виде str, обходя тем самым неприятные сюрпризы, возможные, если при создании или обновлении экземпляра были добавлены данные с нестроковыми ключами. Пример 3.8. StrKeyDict всегда преобразует нестроковые ключи в тип str – при вставке, обновлении и поиске import collections class StrKeyDict(collections.UserDict): /g110 def __missing__(self, key): /g111 if isinstance(key, str): raise KeyError(key) return self[str(key)] def __contains__(self, key): return str(key) in self.data /g112 def __setitem__(self, key, item): self.data[str(key)] = item /g113 /g110 StrKeyDict расширяет UserDict . /g111 Метод __missing__ точно такой же, как в примере 3.7. /g112 Метод __contains__ проще: можно предполагать, что все хранимые ключи имеют тип str, так что можно искать ключ в самом словаре self.data , а не вызывать self.keys() , как в классе StrKeyDict0 . /g113 Метод __setitem__ преобразует любой ключ в тип str. Этот метод проще переопределить, если можно делегировать работу атрибуту self.data . Поскольку UserDict – подкласс MutableMapping , остальные методы, благода- ря которым StrKeyDict является полноценным отображением, наследуются от 3 Точное описание проблем, сопряженных с наследованием dict и другим встроенным классам, см. в разделе «Сложности наследования встроенным типам» на стр. 380.\n--- Страница 106 ---\n106 Глава 3. Словари и множества UserDict , MutableMapping или Mapping . В двух последних есть несколько полезных конкретных методов, хотя они и являются абстрактными базовыми классами (ABC). Стоит отметить следующие методы. MutableMapping.update Этот метод можно вызывать напрямую, но им также пользуется метод __ init__ для инициализации экземпляра другими отображениями, итериру- емыми объектами, порождающими пары (key, value) , и именованными аргументами. Поскольку для добавления элементов в нем используется конструкция self[key] = value , то в конечном итоге будет вызвана наша реализация __setitem__ . Mapping.get В классе StrKeyDict0 (пример 3.7) мы вынуждены были самостоятель- но написать метод get, чтобы получаемые результаты были согласованы с __getitem__ , но в примере 3.8 мы унаследовали Mapping.get , который ре- ализован в точности так, как StrKeyDict0.get (см. исходный код Python (http://bit.ly/1FEOPPB )). Уже написав класс StrKeyDict , я обнаружил, что Антуан Пи- тру (Antoine Pitrou) опубликовал документ «PEP 455 – Adding a key-transforming dictionary to collections» ( https://www.python. org/dev/peps/pep-0455/ ) и исправление, дополняющее мо- дуль collections классом TransformDict . Это исправление присоединено к проблеме issue18986 ( http://bugs.python.org/ issue18986 ) и может быть включено в версию Python 3.5. Чтобы поэкспериментировать с классом TransformDict , я «выдернул» его в отдельный модуль ( 03-dictset/transformdict.py (http://bit. ly/1Vm7OJ5 ) в репозитории кода к этой книге ( https://github. com/fluentpython/example-code )). Класс TransformDict более общий, чем StrKeyDict , и усложняется наличием требования сохранять ключи в том виде, в котором они вставлялись перво-начально. Мы знаем, что существует несколько неизменяемых типов последовательно- стей, а как насчет неизменяемого словаря? В стандартной библиотеке такого не имеется, но выход есть. Читайте дальше. Неизменяемые отображения Все типы отображений в стандартной библиотеке изменяемые, но иногда нужно гарантировать, что пользователь не сможет по ошибке модифицировать отобра-жение. Конкретный пример снова дает проект Pingo.io, который я уже описывал в разделе «Метод __missing__ » выше: отображение board.pins представляет фи-\n--- Страница 107 ---\n107 Неизменяемые отображения зические контакты GPIO на плате. Поэтому было бы желательно предотвратить непреднамеренное изменение board.pins , потому что нельзя же изменять обору- дование с помощью программы, т. е. любая такая модификация оказалась бы не-согласованной с физическим устройством. Начиная с версии Python 3.3, модуль types содержит класс-обертку MappingProxyType , который получает отображение и возвращает объект mappingproxy , допускающий только чтение, но при этом являющийся динамиче- ским представлением исходного отображения. Это означает, что любые измене-ния исходного отображения будут виды и в mappingproxy , но через него такие из- менения сделать нельзя. Демонстрация приведена в примере 3.9. Пример 3.9. Класс MappingProxyType строит по словарю объект mappingproxy , допускающий только чтение >>> from types import MappingProxyType >>> d = {1: 'A'}>>> d_proxy = MappingProxyType(d)>>> d_proxymappingproxy({1: 'A'})>>> d_proxy[1] /g110 'A'>>> d_proxy[2] = 'x' /g111 Traceback (most recent call last):File \"<stdin>\", line 1, in <module>TypeError: 'mappingproxy' object does not support item assignment>>> d[2] = 'B'>>> d_proxy /g112 mappingproxy({1: 'A', 2: 'B'})>>> d_proxy[2]'B'>>> /g110 Элементы d можно видеть через d_proxy . /g111 Произвести изменения через d_proxy невозможно. /g112 Представление d_proxy динамическое: любое изменение сразу же отража- ется. Вот как этим можно воспользоваться в случае Pingo.io: конструктор конкрет- ного подкласса Board инициализирует закрытое отображение объектами, пред- ставляющими контакты, и раскрывает его клиентам API с помощью открытого атрибута .pins , реализованного как mappingproxy . Таким образом, клиент не смо- жет по ошибке добавлять, удалять и изменять контакты4. Рассмотрев большинство имеющихся в стандартной библиотеке типов отобра- жений, мы можем перейти к типам множеств. 4 На самом деле, мы не используем класс MappingProxyType в Pingo.io, потому что он появился только в Python 3.3, а мы должны поддерживать совместимость с версиями, начиная с 2.7.\n--- Страница 108 ---\n108 Глава 3. Словари и множества Теория множеств Множества – сравнительно недавнее добавление к Python, которое используется недостаточно широко. Тип set и его неизменяемый вариант frozenset впервые по- явились в виде модуля в Python 2.3, а в Python 2.6 были «повышены» до встроен-ных типов. Множество – это набор уникальных объектов. Поэтому один из основных спо- собов его использования – устранение дубликатов: >>> l = ['spam', 'spam', 'eggs', 'spam']>>> set(l){'eggs', 'spam'}>>> list(set(l))['eggs', 'spam'] В этой книге словом «множество» обозначается как set, так и frozenset . Элементы множества должны быть хэшируемыми. Сам тип set хэшируемым не является, но тип frozenset хэшируемый, поэтому элементами множества могут быть объекты типа frozenset . Помимо гарантии уникальности, типы множества предоставляют набор тео- ретико-множественных операций, в частности, инфиксные операции: если a и b – множества, то a | b – их объединение, a & b – пересечение, а a - b – разность. Умелое пользование теоретико-множественными операциями помогает умень-шить как объем, так и время работы Python-программ и одновременно сделать код более удобным для восприятия и осмысления – за счет устранения циклов и условных конструкций. Пусть, например, у нас есть большой набор почтовых адресов ( haystack ) и меньший набор адресов ( needles ), а наша задача – подсчитать, сколько раз элемен- ты needles встречаются в haystack . Благодаря операции пересечения множеств (оператор &) для ее решения достаточно одной строки (пример 3.10). Пример 3.10. Подсчет количества вхождений needles в haystack , оба объекта имеют тип set found = len(needles & haystack) Без оператора пересечения эту программу пришлось бы написать, как показано в примере 3.11. Пример 3.11. Подсчет количество вхождений needles в haystack (результат тот же, что в примере 3.10) found = 0 for n in needles:\n--- Страница 109 ---\n109 Теория множеств if n in haystack: found += 1 Программа из примера 3.10 работает чуть быстрее, чем из примера 3.11. С дру- гой стороны, пример 3.11 работает для любых итерируемых объектов needles и haystack , тогда как в примере 3.10 требуется, чтобы оба были множествами. Впро- чем, если исходные объекты множествами не были, то их легко можно построить на лету, как показано в примере 3.12. Пример 3.12. Подсчет количества вхождений needles в haystack ; этот код работает для любых итерируемых типов found = len(set(needles) & set(haystack)) # или по -другому: found = len(set(needles).intersection(haystack)) Разумеется, построение множеств в примере 3.12 обходится не бесплатно, но если needles или haystack уже является множеством, то варианты, показанные в примере 3.12, могут оказаться дешевле кода из примера 3.11. Любой из показанных выше примеров тратит на поиск 1000 «иголок» в «стоге» haystack , состоящем из 10 000 000 элементов, чуть больше 3 миллисекунд, т. е. по 3 микросекунды на одну «иголку». Помимо чрезвычайно быстрой проверки вхождения (благодаря механизму хэш-таблиц), встроенные типы set и frozenset предоставляют богатый набор опе- раций для создания новых множеств или – в случае set – модификации суще- ствующих. Ниже мы обсудим эти операции, но сначала сделаем одно замечание о синтаксисе. Литеральные множества Синтаксис литералов типа set – {1}, {1, 2} и т. д. – выглядит в точности, как ма- тематическая нотация за одни важным исключением: не существует литерального обозначения пустого множества, в таком случае приходится писать set() . Синтаксический подвох Не забывайте: для создания пустого множества следует исполь- зовать конструктор без аргументов: set() . Написав {}, вы, как и в прошлых версиях, создадите пустой словарь. В Python 3 для представления множеств строками используется нотация { } во всех случаях, кроме пустого множества: >>> s = {1}>>> type(s)\n--- Страница 110 ---\n110 Глава 3. Словари и множества <class 'set'> >>> s{1} >>> s .pop() 1>>> sset() Литеральный синтаксис множеств вида {1, 2, 3} быстрее и понятнее, чем вызов конструктора (например, set([1, 2, 3]) ). При этом вторая форма медленнее, потому что для вычисления такого выражения Python должен найти класс set по имени, чтобы получить его конструктор, затем построить список и, наконец, передать этого список конструктору. А при обработке литерала {1, 2, 3} Python исполняет специализированный байт-код BUILD_SET . Взгляните на байт-код обеих операций, выведенный дизассемблером dis.dis : >>> from dis import dis >>> dis('{1}') /g110 1 0 LOAD_CONST 0 (1)3 BUILD_SET 1 /g111 6 RETURN_VALUE>>> dis('set([1])') /g112 1 0 LOAD_NAME 0 (set) /g113 3 LOAD_CONST 0 (1) 6 BUILD_LIST 1 9 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 12 RETURN_VALUE /g110 Дизассемблируем литеральное выражение {1}. /g111 Специальный байт-код BUILD_SET выполняет почти всю работу. /g112 Байт-код выражения set([1]) . /g113 Вместо BUILD_SET следующие три операции: LOAD_NAME , BUILD_LIST и CALL_FUNCTION . Не существует специального синтаксиса для литералов, представляющих frozenset , – их приходится создавать с помощью конструктора. И стандартное строковое представление в Python 3 выглядит как вызов конструктора frozenset . Ниже показан пример в сеансе оболочки: >>> frozenset(range(10)) frozenset({0, 1, 2, 3, 4, 5, 6, 7, 8, 9}) И раз уж мы заговорили о синтаксисе, то отметим, что хорошо знакомый син- таксис спискового включения был приспособлен и для построения множеств.\n--- Страница 111 ---\n111 Теория множеств Множественное включение Множественное включение ( setcomp ) было добавлено в версии Python 2.7 на- ряду со словарным включением, рассмотренным выше. См. пример 3.13. Пример 3.13. Построение множества символов Latin-1, в Unicode-названии которых встречается слово «SIGN» >>> from unicodedata import name /g110 >>> {chr(i) for i in range(32, 256) if 'SIGN' in name(chr(i),'')} /g111 {'§', '=', ' ¢', '#', '¤', '<', ' ¥', 'μ', ' ×', '$', '¶', ' £', '©', '°', '+', ' ÷', '±', '>', '¬', '®', '%'} /g110 Импортировать функцию name из unicodedata для получения названий символов. /g111 Построить множество символов с кодами от 32 до 255, в названиях которых встречается слово «SIGN» Но оставим в стороне вопросы синтаксиса и перейдем к разнообразным опера- циям над множествами. Операции над множествами На рис. 3.2 приведена сводка методов, которые имеются у изменяемых и не- изменяемых множеств. Многие из них – специальные методы, поддерживаю-щие перегрузку операторов. В табл. 3.2 показаны математические операции над множествами, которым соответствуют какие-то операторы или методы в Python. Отметим, что некоторые операторы и методы изменяют конечное множество на месте (например, &=, difference_update и т. д.). Таким операциям нет места в иде- альном мире математических множеств, и в классе frozenset они не реализованы. Рис. 3.2. UML-диаграмма класса MutableSet и его суперклассов из модуля collections.abc (курсивом набраны имена абстрактных классов и абстрактных методов, инверсные операторные методы для краткости опущены)\n--- Страница 112 ---\n112 Глава 3. Словари и множества Инфиксные операторы, приведенные в табл. 3.2, требуют , что- бы оба операнда были множествами, но все остальные методы принимают в качестве аргументов один или несколько итериру-емых объектов. Например, чтобы создать объединение четырех коллекций a, b, c, d, можно написать a.union(b, c, d) , где a долж- но иметь тип set, и b, c и d могут быть итерируемыми объектами любого типа. Т аблица 3.2. Математические операции над множествами: эти методы либо порождают новое множество, либо модифицируют конечное множество на месте (если оно изменяемое) Мат. символОператор PythonМетод Описание S /g320 Z s & z s.__and__(z) Пересечение s и z z & s z.__rand__(s) Инверсный оператор & s.intersection(it,…) Пересечение s и всех множеств, построенных из итерируемых объектов it и т . д. s &= z s.__iand__(z) Замена s пересечением s и z s.intersection_update(it,…) Замена s пересечением s и всех множеств, построенных из итерируемых объектов it и т . д. S /g1515 Zs | z s.__or__(z) Объединение s и z z | s z.__ror__(s) Инверсный оператор | s.union(it,…) Объединение s и всех множеств, построенных из итерируемых объектов it и т . д. s |= z s.__ior__(z) Замена s объединением s и z s.update(it,…) Замена s объединением s и всех множеств, построенных из итерируемых объектов it и т . д. S \\ Z s - z s.__sub__(z) Относительное дополнение или разность s и z z - s z.__rsub__(s) Инверсный оператор - s.difference(it,…) Разность между s и всеми множествами, построенными из итерируемых объектов it и т . д.\n--- Страница 113 ---\n113 Теория множеств Мат. символОператор PythonМетод Описание s -= z s.__isub__(z) Замена s разностью между s и z s.difference_update(it,…) Замена s разностью между s и всеми множествами, построенными из итерируемых объектов it и т . д. s.symmetric_difference(it) Дополнение s & set(it) S Δ Z s ^ z s.__xor__(z) Симметрическая разность (дополнение пересечения s & z) z ^ s z.__rxor__(s) Инверсный оператор ^ s.symmetric_difference_ update(it,…)Замена s симметрической разностью между s и всеми множествами, построенными из итерируемых объектов it и т . д. s ^= z s.__ixor__(z) Замена s симметрической разностью между s и z Когда я писал эти строки, существовал отчет об ошибке в Python (проблема 8743 ( http://bugs.python.org/issue8743 )) следующего содержания: «Операторы класса set ( or, and, sub, xor и их аналоги для модификации на месте) требуют , чтобы параметр также был экземпляром set()». Нежелательным побочным эффектом яв-ляется тот факт , что эти операторы не работают с подклассами collections.abc.Set . Эта ошибка уже исправлена в стволовых ветвях Python 2.7 и 3.4 и к моменту выхода книги должна уйти в прошлое. В табл. 3.3 перечислены теоретико-множественные предикаты: методы и опе- раторы, которые возвращают True или False . Т аблица 3.3. Операторы сравнения множеств и методы, возвращающие булево значение Мат. символОператор PythonМетод Описание s.isdisjoint(z) s и z дизъюнктны (т . е. не пересекаются) e ෛ Z e in s s.__contains__(e) e является элементом s S ๙ Z s <= zs.__le__(z) s.issubset(it)s является подмножеством z s является подмножеством множества z, построенного из итерируемого объекта it\n--- Страница 114 ---\n114 Глава 3. Словари и множества Мат. символОператор PythonМетод Описание S ๕ Z s < z s.__lt__(z)s является собственным подмножеством z S ๚ Z s >= zs.__ge__(z) s.issuperset(it)s является надмножеством z s является надмножеством множества z, построенного из итерируемого объекта it S ๖ Z s > z s.__gt__(z) s является собственным надмножеством z Помимо теоретико-множественных операторов и методов, типы множеств реа- лизуют и другие методы, полезные на практике. Они сведены в табл. 3.4. Т аблица 3.4. Дополнительные методы множеств set frozenset s.add(e) /g404 Добавить элемент e в s s.clear() /g404 Удалить все элементы из s s.copy() /g404/g404 Поверхностная копия s s.discard(e) /g404 Удалить элемент e из s, если он там присутствует s.__iter__() /g404/g404 Получить итератор для обхода s s.__len__() /g404/g404 len(s) s.pop() /g404 Удалить и вернуть элемент s, возбудив исключение KeyError , если s пусто s.remove(e) /g404 Удалить элемент e из s, возбудив исключение KeyError , если e отсутствует в s На это мы завершаем обзор множеств и их возможностей. Теперь обратимся к обсуждению реализации словарей и множеств с помощью хэш-таблиц. Дочитав эту главу до конца, вы уже не будете удивляться непредска-зуемому на первый взгляд поведению классов dict , set и их родственников. Под капотом dict и set Понимать, как реализованы словари и множества в Python, полезно для оценки их сильных сторон и ограничений. В этом разделе мы ответим на следующие вопросы. • Насколько эффективны классы dict и set в Python? • Почему они не упорядочены?• Почему не каждый объект Python может быть ключом словаря или элемен- том множества?\n--- Страница 115 ---\n115 Под капотом dict и set • Почему порядок ключей словаря и элементов множества зависит от поряд- ка вставки и может изменяться на протяжении времени жизни структуры данных? • Почему нельзя добавлять в словарь или множество элементы во время об- хода? Чтобы у вас появился стимул прочитать про хэш-таблицы, мы начнем с де- монстрации поразительной производительности dict и set в простом тесте для нескольких миллионов элементов. Экспериментальная демонстрация производительности По своему опыту все пишущие на Python программисты знают, что словари и множества работают быстро. Подтвердим это контролируемым экспериментом. Чтобы понять, как размер dict , set или list влияет на скорость поиска с помо- щью оператора in, я сгенерировал массив, содержащий 10 миллионов различных чисел с плавающей точкой двойной точности, – «стог». Затем я сгенерировал мас-сив «иголок»: 1000 чисел с плавающей точкой, из которых 500 было взято из стога, а 500 гарантированно отсутствовали в нем. Для измерения производительности dict я с помощью метода dict.fromkeys() создал объект dict с именем haystack , содержащий 1000 чисел с плавающей точ- кой. Это было сделано на этапе подготовки теста dict . Время работы кода, по- казанного в примере 3.14 (почти такого же, как в примере 3.11), измерялось с по-мощью модуля timeit . Пример 3.14. Поиск иголок в стоге сена с подсчетом найденных found = 0 for n in needles: if n in haystack: found += 1 Тест был повторен еще четыре раза, и при каждом повторе размер haystack увеличивался в десять раз, пока не достиг значения 10 000 000. Результаты измерения производительности dict приведены в табл. 3.5. Т аблица 3.5. Общее время поиска 1000 иголок в стогах сена пяти разных размеров с помощью оператора in. Тесты были выполнены на ноутбуке с процессором Core i7 в версии Python 3.4.0 (замерялось время работы цикла в примере 3.14) Длина haystack Коэффициент Время работы Коэффициент 1000 1x 0,000202 с 1,00x 10 000 10x 0,000140 с 0,69x100 000 100x 0,000228 с 1,13x 1 000 000 1000x 0,000290 с 1,44x 10 000 000 10000x 0,000337 с 1,67x\n--- Страница 116 ---\n116 Глава 3. Словари и множества Говоря конкретно, на поиск 1000 ключей с плавающей точкой в словаре, со- держащем 1000 элементов, на моем ноутбуке ушло 0,000202 с, а на такой же поиск в словаре из 10 000 000 элементов – 0,000337 с. Иными словами, поиск иголки в стоге размером 10 000 000 элементов в среднем занимал 0,337 мкс на одну иголку, примерно треть микросекунды. Для сравнения я повторил этот эксперимент с такими же стогами возрастаю- щих размеров, но имеющими тип set или list . В тестах для set я хронометрировал не только цикл for из примера 3.14, но и однострочный код, показанный в при- мере 3.15, который делает точно то же самое: вычисляет количество элементов из needles , встречающихся также в haystack . Пример 3.15. Применение пересечения множеств для подсчета иголок, найденных в стоге сена found = len(needles & haystack) В табл. 3.6 результаты тестов показаны рядом. Наилучшее время представлено в столбце « Время set&» – результат применения оператора & в коде из примера 3.15. Наихудшее время – вполне ожидаемо – представлено в столбце «Время list», по-скольку поиск с помощью оператора in в списке не поддержан хэш-таблицей и, следовательно, приходится просматривать список целиком, т. е. время линейно увеличивается с ростом размера стога. Т аблица 3.6. Общее время поиска с помощью оператора in 1000 ключей в стогах 5 разных размеров, представленных объектами dict, set и list. Тесты были выполнены на ноутбуке с процессором Core i7 в версии Python 3.4.0 (замерялось время работы цикла в примере 3.14 за исключением столбца set&, для которого хронометрировался код из примера 3.15) Длина haystackКоэффВремя dictКоэффВремя setКоэффВремя set&КоэффВремя listКоэфф 1000 1x 0,000202с 1,00x 0,000143с 1,00x 0,000087с 1,00x 0,010556с 1,00x 10 000 10x 0,000140с 0,69x 0,000147с 1,03x 0,000092с 1,06x 0,086586с 8,20x 100 000 100x 0,000228с 1,13x 0,000241с 1,69x 0,000163с 1,87x 0,871560с 82,57x 1 000 000 1000x 0,000290с 1,44x 0,000332с 2,32x 0,000250с 2,87x 9,189616с 870,56x 10 000 000 10000x 0,000337с 1,67x 0,000387с 2,71x 0,000314с 3,61x 97,948056с 9278,90x Если программа выполняет какой-либо ввод-вывод, то время поиска по ключу в словаре или в множестве пренебрежимо мало, каким бы ни был размер dict или set (при условии, что объект целиком помещается в оперативной памяти). См. код, с помощью которого были сгенерированы данные для табл. 3.6, и сопутству-ющее обсуждение в приложении A, пример A.1. Теперь, получив убедительное свидетельство быстродействия словарей и мно- жеств, разберемся, как оно достигается. В частности, из обсуждения внутренне-\n--- Страница 117 ---\n117 Под капотом dict и set го устройства хэш-таблицы станет понятно, почему порядок ключей, на первый взгляд, является случайным и нестабильным. Хэш-таблицы в словарях Ниже дается лишь общее представление о том, как хэш-таблица используется в Python для реализации класса dict . Многие детали опущены – в коде CPython есть ряд оптимизаций5 – но в целом описание достаточно точное. Чтобы упростить дальнейшее изложение, мы сначала сосредо- точимся на устройстве класса dict , а затем распространим те же идеи на множества. Хэш-таблица – это разреженный массив (массив, в котором имеются незапол- ненные позиции). В стандартных англоязычных учебниках по структурам данных ячейки хэш-таблицы называются «bucket». В хэш-таблице dict каждому элементу соответствует ячейка, содержащая два поля: ссылку на ключ и ссылку на значение элемента. Поскольку размер всех ячеек одинаков, доступ к отдельной ячейке про-изводится по смещению. Python стремится оставить не менее трети ячеек пустыми; если хэш-таблица становится чрезмерно заполненной, то она копируется в новый участок памяти, где есть место для большего числа ячеек. Для помещения элемента в хэш-таблицу нужно первым делом вычислить хэш- значение ключа элемента. Это делает встроенная функция hash() , которую мы рас- смотрим ниже. Хэш-значения и равенство Встроенная функция hash() со встроенными типами работает напрямую, а для пользовательских обращается к методу __hash__ . Если два объекта равны в смысле оператора сравнения, то их хэш-значения также должны быть равны, иначе алго-ритм хэш-таблицы работать не будет. Например, коль скоро 1 == 1.0 истинно, то и hash(1) == hash(1.0) должно быть истинно, хотя внутренние представления int и float совершенно различны6. Кроме того, хэш-значения лишь тогда будут эффективны в качестве индек- сов хэш-таблицы, когда они как можно более равномерно распределены по все-му пространству индексов. Это означает, что в идеале хэш-значения похожих, но неодинаковых объектов, должны сильно различаться. В примере 3.16 приведен вывод скрипта для сравнения битовых представлений хэш-значений. Обратите 5 В файле dictobject.c, являющемся частью CPython ( http://hg.python.org/cpython/file/tip/Objects/ dictobject.c ), нет недостатка в комментариях. См. также ссылку на книгу «Beautiful Code» в разделе «Дополнительная литература». 6 Раз уж мы упомянули тип int , раскроем одну деталь реализации CPython: хэш-значение числа типа int , умещающегося в машинное слово, совпадает с самим числом.\n--- Страница 118 ---\n118 Глава 3. Словари и множества внимание, что хэши чисел 1 и 1.0 одинаковы, но для чисел 1.0001, 1.0002 и 1.0003 они очень сильно различаются. Пример 3.16. Сравнение битовых представлений чисел 1, 1.0001, 1.0002 и 1.0003 в 32-разрядной сборке Python (биты, в которых соседние числа различаются, обозначены знаком !, а справа показано, сколько битов различается) 32-bit Python build 1 00000000000000000000000000000001 != 01.0 00000000000000000000000000000001------------------------------------------------1.0 00000000000000000000000000000001 ! !!! ! !! ! ! ! ! !! !!! != 161.0001 00101110101101010000101011011101------------------------------------------------1.0001 00101110101101010000101011011101 !!! !!!! !!!!! !!!!! !! ! != 201.0002 01011101011010100001010110111001------------------------------------------------1.0002 01011101011010100001010110111001 ! ! ! !!! ! ! !! ! ! ! !!!! != 171.0003 00001100000111110010000010010110------------------------------------------------ Код, с помощью которого получен этот результата, имеется в приложении A. Большая его часть относится к форматированию, но для полноты он все же при-веден в примере A.3. Начиная с версии Python 3.3, в хэши объектов str, bytes и date- time добавлена случайная затравка. Внутри процесса Python это константа, но при каждом запуске интерпретатора она меняется. Смысл случайной затравки – защититься от DOS-атак. Детали описаны в документации в примечании к специальному методу __hash__ (http://bit.ly/1FESm0m ). Получив первоначальное представление о хэш-значениях объектов, мы можем углубиться в алгоритм, благодаря которому работают хэш-таблицы. Алгоритм работы хэш-таблицы Для выборки значения с помощью выражения my_dict[search_key] Python об- ращается к функции hash(search_key) , чтобы получить хэш-значение search_key , и использует несколько младших битов полученного числа как смещение ячей-ки относительно начала хэш-таблицы (сколько именно битов зависит от текуще-го размера таблицы). Если найденная ячейка пуста, возбуждается исключение KeyError . В противном случае в найденной ячейке есть какой-то элемент – пара\n--- Страница 119 ---\n119 Под капотом dict и set (found_key:found_value) – и тогда Python проверяет, верно ли, что search_key == found_key . Если да, то элемент найден и возвращается found_value . Если же search_key и found_key не совпали, то имеет место коллизия хэширова- ния. Это возможно, потому что хэш-функция отображает произвольные объекты на ограниченное количество комбинаций битов, да к тому же в индексировании хэш-таблицы принимают участие не все комбинации. Для разрешения коллизии алгоритм берет различные биты хэш-значения, производит над ними определен-ные действия и использует результат как смещение другой ячейки 7. Если она пус- та, возбуждается исключение KeyError ; если нет, то либо ключи совпадают и тогда возвращается значение элемента, либо процесс разрешения коллизии повторяет-ся. Блок-схема алгоритма показана на рис. 3.3. Рис. 3.3. Блок-схема алгоритма поиска элемента в словаре; для каждого ключа эта процедура либо возвращает его значение, либо возбуждает исключение KeyError Процесс вставки или изменения элемента такой же с тем отличием, что при об- наружении пустой ячейки в нее помещается новый элемент, а если найдена ячейка с указанным ключом, то хранящееся в ней значение замещается новым. Кроме того, в ходе вставки элемента Python может решить, что таблица слиш- ком плотно заполнена, и перестроить ее в новой области памяти, освободив место. По мере роста хэш-таблицы растет и количество битов, используемых в качестве смещения ячейки, поэтому вероятность коллизий уменьшается. На первый взгляд, эта реализация подразумевает большой объем работы, но даже если словарь содержит миллионы элементов, многие операции поиска за-вершаются вообще без коллизий, а среднее число коллизий на одну операцию на-ходится в диапазоне от 1 до 2. В обычных обстоятельствах даже для поиска самого неудачливого ключа потребуется разрешить всего несколько коллизий. 7 C-функция, которая перетасовывает биты хэш-значения, называется perturb . Детали см. в исход- ном файле dictobject.c (http://bit.ly/1JzB8rA ).Вычислить hash по keyИспользовать часть hash для поиска ячейки в хэш-таблице Ячейка пуста ? Возбудить KeyError Ключи равны? Вернуть значение из ячейкиИспользовать другие части hash для определения другой ячейки хэш-таблицы да данетнеткол-лизия хэширо-вания\n--- Страница 120 ---\n120 Глава 3. Словари и множества Познакомившись с деталями реализации класса dict , мы можем объяснить сильные стороны и ограничения как этой структуры данных, так и всех произво-дных от нее. Теперь мы готовы к разговору о том, почему словари в Python ведут себя именно так, а не иначе. Практические последствия механизма работы dict В следующих подразделах мы обсудим плюсы и минусы, которые несет с собой реализация словаря на основе хэш-таблицы. Ключи должны быть хэшируемыми объектами Объект является хэшируемым, если удовлетворяются все перечисленные ниже условия. 1. Он поддерживает функцию hash() благодаря наличию метода __hash__ , ко- торый возвращает одно и то же значение на протяжении всей жизни объ-екта. 2. Он поддерживает сравнение на равенство с помощью метода __eq__ . 3. Если выражение a == b равно True , то выражение hash(a) == hash(b) также должно быть равно True . Пользовательские типы по умолчанию являются хэшируемыми, потому что их хэш-значение равно значению функции id() и ни один из них не равен другому. Если в своем классе вы реализовали метод __eq__ , то должны согласованным образом реализовать и метод __hash__ , потому что необходимо гарантировать, что если a == b равно True , то и hash(a) == hash(b) также равно True . Иначе вы нарушите инва- риант алгоритма хэш-таблицы, а уж тогда от словарей и множеств не стоит ожидать надежной работы. Если ваш метод __eq__ за- висит от изменяемого состояния, то метод __hash__ должен воз- буждать исключение TypeError с сообщением вроде unhashable type: 'MyClass' . У словарей большие накладные расходы в части памяти Поскольку в основе класса dict лежит хэш-таблица, а хэш-таблицы должны быть разреженными, то память, естественно, используется неэффективно. Напри-мер, при обработке большого числа записей лучше хранить их в списке кортежей или именованных кортежей, а не в списке словарей в духе JSON, с одним объ-ектом dict на каждую запись. Замена словарей кортежами снижает потребление памяти по двум причинам: за счет устранения накладных расходов на хранение хэш-таблицы в каждой записи и в силу того, что имена полей вынесены за пределы записей.\n--- Страница 121 ---\n121 Под капотом dict и set Для пользовательских типов атрибут класса __slots__ изменяет способ хране- ния атрибутов экземпляра: со словаря на кортеж. Мы обсудим этот вопрос в раз-деле «Экономия памяти с помощью атрибута класса __slots__» главы 9. Помните, что мы говорим об оптимизации использования памяти. Если вы ра- ботаете с несколькими миллионами объектов, а машина оснащена несколькими гигабайтами оперативной памяти, то такая оптимизация вряд ли оправдана, и ее следует отложить. Оптимизация – этот тот алтарь, на котором приносят в жертву удобство сопровождения. Поиск по ключу выполняется очень быстро Реализация dict – пример компромисса, когда жертвуют памятью ради скоро- сти: накладные расходы словаря в части памяти велики, зато доступ производится быстро независимо от размера словаря – если, конечно, он умещается целиком в памяти. Из табл. 3.5 видно, что при увеличении размера dict с 1000 до 10 000 000 элементов время поиска возросло всего в 2,8 раза, с 0,000163 с до 0,000456 с. По-следняя величина означает, что в словаре с 10 миллионами элементов можно было выполнить более 2 миллионов операций поиска в секунду . Упорядочение ключей зависит от порядка вставки При возникновении коллизии второй ключ оказывается в позиции, которую не должен был бы занимать, если бы был вставлен первым. Таким образом, объ-ект dict , построенный как dict([(key1, value1), (key2, value2)]) равен объекту dict([(key2, value2), (key1, value1)]) , но порядок ключей в них может разли- чаться, если при хэшировании key1 и key2 возникает коллизия. В примере 3.17 демонстрируется результат загрузки трех словарей с одними и теми же данными, но в разном порядке. Все получающиеся словари равны, хотя порядок ключей в них разный. Пример 3.17. dialcodes.py: заполнить три словаря одинаковыми данными, отсортированными по-разному # телефонные коды 10 самых населенных стран DIAL_CODES = [ (86, 'China'), (91, 'India'), (1, 'United States'), (62, 'Indonesia'), (55, 'Brazil'), (92, 'Pakistan'), (880, 'Bangladesh'), (234, 'Nigeria'), (7, 'Russia'), (81, 'Japan'), ] d1 = dict(DIAL_CODES) /g110 print('d1:', d1.keys())\n--- Страница 122 ---\n122 Глава 3. Словари и множества d2 = dict(sorted(DIAL_CODES)) /g111 print('d2:', d2.keys())d3 = dict(sorted(DIAL_CODES, key=lambda x:x[1])) /g112 print('d3:', d3.keys())assert d1 == d2 and d2 == d3 /g113 /g110 d1: построен из кортежей, отсортированных в порядке убывания числен- ности населения страны. /g111 d2: инициализирован кортежами, отсортированными по телефонному коду. /g112 d3: инициализирован кортежами, отсортированными по названию страны. /g113 Словари равны, потому что содержат одни и те же пары key:value . В примере 3.18 показан результат работы. Пример 3.18. Из распечатки dialcodes.py видно, что порядок ключей различен. d1: dict_keys([880, 1, 86, 55, 7, 234, 91, 92, 62, 81]) d2: dict_keys([880, 1, 91, 86, 81, 55, 234, 7, 92, 62])d3: dict_keys([880, 81, 1, 86, 55, 7, 234, 91, 92, 62]) При добавлении новых элементов в словарь может измениться порядок существующих ключей Когда в словарь добавляется новый элемент, интерпретатор Python может ре- шить, что хэш-таблицу словаря следует перестроить. В результате все существу-ющие элементы будут перемещены в новую таблицу. В процессе этой операции могут возникнуть новые (уже другие) коллизии, в силу чего ключи в новой табли-це будут упорядочены по-другому. Все это зависит от реализации, поэтому уверен-но предсказать, когда такое случится, невозможно. Если при обходе всех ключей словаря вы будете одновременно изменять их, то может оказаться, что будут про-смотрены не все элементы – даже не все из тех, что уже присутствовали в словаре перед добавлением новых. Именно поэтому модификация содержимого словаря в процессе обхода – не- удачная мысль. Если необходимо просмотреть и добавить элементы в словарь, сделайте это в два этапа: прочитайте словарь от начала до конца, а все необхо-димые изменения соберите во втором словаре. Затем обновите первый словарь с помощью второго. В Python 3 методы .keys() , .items() и .values() возвращают представления словаря, которые ведут себя скорее как мно-жества, чем как списки, которые возвращались в Python 2. Эти предс тавления к тому же динамичны: они не копируют содержи-мое словаря, а непосредственно отражают все производимые в нем изменения. Теперь мы можем применить все, что узнали о хэш-таблицах, к множествам.\n--- Страница 123 ---\n123 Резюме Как работают множества – практические следствия Типы set и frozenset также реализованы с помощью хэш-таблиц с тем отли- чием, что в каждой ячейке хранится только ссылка на элемент (как если бы это был ключ словаря, но без сопровождающего его значения). На самом деле, до того как тип set был добавлен в язык, мы часто использовали словари с фиктивными значениями, просто чтобы быстро проверить вхождение ключа. Все сказанное в разделе «Практические последствия механизма работы dict» о том, как хэш-таблица определяет поведение словаря, относится и к множеству. Не занимаясь повторением, ограничимся сводкой основных положений: • элементы множества должны быть хэшируемыми объектами; • множествам сопутствуют значительные накладные расходы в части памя- ти; • проверка принадлежности множеству очень эффективна;• упорядочение элементов зависит от порядка вставки;• добавление новых элементов в множество может привести к изменению порядка существующих. Резюме Словари – краеугольный камень Python. Помимо базового класса dict , в стан- дартной библиотеке имеются удобные, готовые к применению специализирован-ные отображения, например defaultdict , OrderedDict , ChainMap и Counter , все они определены в модуле collections . Там же находится предназначенный для рас- ширения класс UserDict . Два весьма полезных метода, имеющихся в большинстве отображений, – setdefault и update . Метод setdefault используется для модификации элементов, содержащих изменяемые значения, например в словаре dict значений типа list , чтобы избежать повторных операций поиска того же ключа. Метод update облегча- ет массовую вставку или перезапись элементов, когда новые элементы берутся из другого отображения, из итерируемого объекта, порождающего пары (key, value) , или из именованных аргументов. Конструкторы отображений также пользуются методом update , что позволяет инициализировать отображение другим отображе- нием, итерируемым объектом или именованными аргументами. В API отображений имеется метод __missing__ , который позволяет опреде- лить, что должно происходить в случае отсутствия ключа. Модуль collections.abc содержит абстрактные базовые классы Mapping и MutableMapping для справки и контроля типов. Малоизвестный класс MappingProxyType из модуля types позволяет создавать неизменяемые отображе- ния. Существуют также абстрактные базовые классы Set и MutableSet . Реализация хэш-таблицы, лежащей в основе классов dict и set, работает очень быстро. А понимание ее логики объясняет, почему элементы кажутся неупорядо-\n--- Страница 124 ---\n124 Глава 3. Словари и множества ченными и, более того, их порядок может неожиданно изменяться. Но у быстро- действия есть цена, и в данном случае мы расплачиваемся памятью. Дополнительная литература В разделе 8.3 документации по стандартной библиотеке «collections – контейнер-ные типы данных» ( https://docs.python.org/3/library/collections.html ) есть примеры и практические рецепты использования различных типов отображения. Исход-ный Python-код модуля Lib/collections/init.py станет отличным справочным посо- бием для всех, кто захочет написать новый тип отображения или разобраться в логике работы существующих. В главе 1 книги David Beazley, Brian K. Jones «Python Cookbook», издание 3 (O'Reilly), имеется 20 полезных и поучительных примеров работы со структурами данных – в большинстве из них изобретательно используется словарь dict . В главе 18 «Реализация словарей в Python: нечто, подходящее для всех» кни- ги «Beautiful Code»8 (O'Reilly), написанной А. М. Кухлингом, одним из авторов ядра Python и многих страниц официальной документации и рекомендаций, при-водится подробное объяснение внутреннего устройства класса dict . Кроме того, исходный файл dictobject .c, являющийся частью дистрибутива CPython ( http:// hg.python.org/cpython/file/tip/Objects/dictobject.c ) изобилует комментариями. В отличной презентации Брэндона Крейга Родса (Brandon Craig Rhodes) «The Mighty Dictionary» ( http://bit.ly/1JzEjiR ) на большом количестве слайдов показа- но, как работают хэш-таблицы. Аргументация в пользу добавления множеств в язык приведена в документе «PEP 218 – Adding a Built-In Set Object Type» ( https://www.python.org/dev/peps/ pep-0218/ ). Когда этот документ был одобрен, для множеств еще не была принята какая-то специальная литеральная нотация. Литеральные множества появились в Python 3, а затем были внедрены и в версию Python 2.7, наряду со словарными и множественными включениями. Документ «PEP 274 – Dict Comprehensions» (https://www.python.org/dev/peps/pep-0274/ ) – свидетельство о рождении словар- ных включений. Я так и не смог найти PEP , посвященный множественным вклю-чениям; по всей видимости, они были приняты просто потому, что хорошо ужива-ются со своими родственниками, – причина ничем не хуже других. Поговорим Мой друг Джеральдо Коэн как-то заметил, что Python «простой и корректный язык». Тип dict – образец простоты и корректности. Он очень хорошо оп- тимизирован для решения одной-единственной задачи: поиска по про-извольному ключу. Он работает настолько быстро и надежно, что ис-пользуется и в самом интерпретаторе. Если требуется предсказуемый 8 Идеальный код. Питер, 2011.\n--- Страница 125 ---\n125 Поговорим порядок ключей, пользуйтесь классом OrderedDict . Но к большинству отображений такое требование не предъявляется, поэтому имеет смысл оставить в ядре простую реализацию, а вариацию поместить в стандарт-ную библиотеку. Сравните с PHP , где массивы описываются в официальном руко- водстве следующим образом ( http://php.net/manual/en/language.types. array.php ): Массив в PHP в действительности является упорядоченным отображением. Отображение – это тип, который ассоциирует значения с ключами. Этот тип оптимизирован для различных применений; его можно использовать в качестве массива, списка (вектора), хэш-таблицы (именно так реализовано отображение), словаря, коллекции, стека, очереди и, возможно, чего-то еще. Из этого описания я не понимаю, какова реальная стоимость исполь- зования гибрида list и OrderedDict в PHP . Цель этой и предыдущей главы – показать, как в Python различные типы коллекций оптимизированы для различных применений. Я специ-ально подчеркнул, что помимо хорошо известных классов list и dict су- ществуют специализированные альтернативы для различных ситуаций. До того как я открыл для себя Python, я писал веб-приложения на Perl, PHP и JavaScript. Мне очень нравился литеральный синтаксис отображений в этих языках, которого так не хватало в Java и C. Хоро-ший литеральный синтаксис упрощает конфигурирование, реализации на основе таблиц и хранение данных для создания прототипов и тести-рования. Отсутствие такого синтаксиса вынудило сообщество Java при-нять многословный и чрезмерно сложный язык XML в качестве форма-та данных. Формат JSON был предложен как «обезжиренная альтернатива XML» ( http://www.json.org/fatfree.html ) и добился ошеломительного успеха, заменив XML во многих контекстах. Благодаря краткому син-таксису списков и словарей он отлично подходит на роль формата для обмена данными. PHP и Ruby позаимствовали синтаксис хэша из Perl, где для ассоци- ации ключей и значений применяется оператор =>. JavaScript последо- вал по стопам Python и использует для этой цели знак :. Конечно, ис- токи JSON следует искать в JavaScript, но так получилось, что это почти точное подмножество синтаксиса Python. JSON совместим с Python во всем, кроме написания значений true , false и null . Синтаксис, которым ныне все пользуются для обмена данными, – это синтаксис словаря и списка в Python. Просто и корректно.",
      "debug": {
        "start_page": 91,
        "end_page": 125
      }
    },
    {
      "name": "Глава 4. Текст и байты 126",
      "content": "--- Страница 126 --- (продолжение)\nГЛАВА 4. Текст и байты Человек работает с текстом, компьютер – с байтами.1 – Эстер Нэм и Трэвис Фишер, «Кодировка символов и Unicode в Python» В Python 3 появилось четкое различие между строками текста, предназначенными для человека, и последовательностями байтов. Неявное преобразование последо-вательности байтов в Unicode-текст ушло в прошлое. В этой главе речь пойдет о Unicode-строках, двоичных последовательностях и кодировках для преобразова-ния одного в другое. Насколько глубоко необходимо разбираться в Unicode, зависит от того, в какой области вы программируете на Python. Большая часть изложенного в этой главе материала будет мало интересна программистам, имеющим дело только с ASCII-текстами. Но даже если вы относитесь к этой категории, все равно от различий между типами str и byte никуда не деться. А в качестве премии за потраченные усилия вы узнаете, что специализированные типы двоичных последовательностей обладают возможностями, которых нет у «универсального» типа str в Python 2. В этой главе мы рассмотрим следующие вопросы: • символы, кодовые позиции и байтовые представления; • уникальные особенности двоичных последовательностей: bytes , bytearray и memoryview ; • кодеки для полного Unicode и унаследованных наборов символов;• как предотвращать и обрабатывать ошибки кодировки;• рекомендации по работе с текстовыми файлами;• кодировка по умолчанию и стандартные проблемы ввода-вывода;• безопасное сравнение Unicode-текстов с нормализацией.• служебные функции для нормализации, сворачивания регистра и явного удаления диакритических знаков; • правильная сортировка Unicode-текстов с помощью модуля locale и библиотеки PyUCA; 1 Слайд 12 выступления на конференции PyCon 2014 «Character Encoding and Unicode in Python» (слайды – http://bit.ly/1JzF1MY , видео – http://bit.ly/1JzF37P ).\nГЛАВА 4. Текст и байты Человек работает с текстом, компьютер – с байтами.1 – Эстер Нэм и Трэвис Фишер, «Кодировка символов и Unicode в Python» В Python 3 появилось четкое различие между строками текста, предназначенными для человека, и последовательностями байтов. Неявное преобразование последо-вательности байтов в Unicode-текст ушло в прошлое. В этой главе речь пойдет о Unicode-строках, двоичных последовательностях и кодировках для преобразова-ния одного в другое. Насколько глубоко необходимо разбираться в Unicode, зависит от того, в какой области вы программируете на Python. Большая часть изложенного в этой главе материала будет мало интересна программистам, имеющим дело только с ASCII-текстами. Но даже если вы относитесь к этой категории, все равно от различий между типами str и byte никуда не деться. А в качестве премии за потраченные усилия вы узнаете, что специализированные типы двоичных последовательностей обладают возможностями, которых нет у «универсального» типа str в Python 2. В этой главе мы рассмотрим следующие вопросы: • символы, кодовые позиции и байтовые представления; • уникальные особенности двоичных последовательностей: bytes , bytearray и memoryview ; • кодеки для полного Unicode и унаследованных наборов символов;• как предотвращать и обрабатывать ошибки кодировки;• рекомендации по работе с текстовыми файлами;• кодировка по умолчанию и стандартные проблемы ввода-вывода;• безопасное сравнение Unicode-текстов с нормализацией.• служебные функции для нормализации, сворачивания регистра и явного удаления диакритических знаков; • правильная сортировка Unicode-текстов с помощью модуля locale и библиотеки PyUCA; 1 Слайд 12 выступления на конференции PyCon 2014 «Character Encoding and Unicode in Python» (слайды – http://bit.ly/1JzF1MY , видео – http://bit.ly/1JzF37P ).\n--- Страница 127 ---\n127 О символах и не только • символьные метаданные в базе данных Unicode; • двухрежимные API для работы с типами str и bytes . Начнем с символов, кодовых позиций и байтов. О символах и не только Концепция «строки» достаточно проста: строка – это последовательность симво- лов. Проблема – в определении понятия «символ». В 2015 году под «символом» мы понимаем символ Unicode, и это лучшее опре- деление на сегодняшний момент. Поэтому отдельными элементами объекта типа str в Python 3 являются символы Unicode (точно так же как обстоит дело с эле- ментами объекта unicode в Python 2), – а не просто байты, из которых состоят объекты str в Python 2. Стандарт Unicode явно разделяет идентификатор символа и конкретное бай- товое представление. Идентификатор символа – его кодовая позиция – это число от 0 1 114 111 (по основанию 10), которое в стандарте Unicode записывается шестнадцатеричными цифрами (в количестве от 4 до 6) с префиксом «U+». Например, кодовая позиция буквы A равна U+0041, знака евро – U+20AC, музыкального символа скрипичного ключа – U+1D11E. В версии Unicode 6.3 (используемой в Python) конкретные символы сопоставлены примерно 10 % допустимых кодовых позиций Какими конкретно байтами представляется символ, зависит от используемой кодировки . Кодировкой называется алгоритм преобразования кодовых позиций в последовательности байтов и наоборот. Кодовая позиция буквы A (U+0041) ко-дируется одним байтом \\x41 в кодировке UTF-8 и двумя байтами \\x41\\x00 в коди- ровке UTF-16LE. Другой пример: знак евро (U+20AC) преобразуется в три байта в UTF-8 – \\xe2\\x82\\xac , но в UTF-16LE кодируется двумя байтами – \\xac\\x20 . Преобразование из кодовых позиций в байты называется кодированием , преоб- разование из байтов в кодовых позиции – декодированием . См. пример 4.1. Пример 4.1. Кодирование и декодирование >>> s = 'caf é' >>> len(s) # /g110 4 >>> b = s.encode('utf8') # /g111 >>> bb'caf\\xc3\\xa9' # /g112 >>> len(b) # /g113 5 >>> b.decode('utf8') # /g114 'café' /g110 Строка 'café' состоит из четырех символов Unicode. /g111 Преобразуем str в bytes , пользуясь кодировкой UTF-8. /g112 Литералы типа bytes начинаются префиксом b.\n--- Страница 128 ---\n128 Глава 4. Текст и байты /g113 Объект b типа bytes состоит из пяти байтов (кодовая позиция, соответствую- щая «é», в UTF-8 кодируется двумя байтами). /g114 Преобразуем bytes обратно в str, пользуясь кодировкой UTF-8. Если вы никак не можете запомнить, когда употреблять .decode() , а когда – .encode() , представьте, что последователь- ности байтов – это загадочный дамп памяти машины, а объекты Unicode str – «человеческий» текст . Тогда декодирование bytes в str призвано получить понятный человеку текст , а кодирование str в bytes – получить представление, пригодное для хранения или передачи. Тип str в Python 3 – это, по существу, не что иное как переименованный тип unicode из Python 2. Но вот тип bytes в Python 3 – не просто старый тип str, и с ним тесно связан тип bytearray . Поэтому имеет смысл сначала разобраться с типами двоичных последовательностей, а уже затем переходить к вопросам коди-рования и декодирования. Все, что нужно знать о байтах Новые типы двоичных последовательностей во многих отношениях похожи на тип str в Python 2. Главное, что нужно знать, – это то, что существуют два основ- ных встроенных типа двоичных последовательностей: неизменяемый тип bytes , появившийся в Python 3, и изменяемый тип bytearray , добавленный в Python 2.6 (в Python 2.6 был также введен тип bytes , но лишь как псевдоним типа str, он ве- дет себя иначе, чем тип bytes в Python 3). Каждый элемент bytes или bytearray – целое число от 0 до 255, а не односим- вольная строка, как в типе str в Python 2 str. Однако срез двоичной последова- тельности всегда является двоичной последовательностью того же типа, даже если это срез длины 1. См. пример 4.2. Пример 4.2. Пятибайтовая последовательность в виде bytes и bytearray >>> cafe = bytes('caf é', encoding='utf_8') /g110 >>> cafeb'caf\\xc3\\xa9'>>> cafe[0] /g111 99>>> cafe[:1] /g112 b'c'>>> cafe_arr = bytearray(cafe)>>> cafe_arr /g113 bytearray(b'caf\\xc3\\xa9')>>> cafe_arr[-1:] /g114 bytearray(b'\\xa9') /g110 bytes можно получить из str, если известна кодировка.\n--- Страница 129 ---\n129 Все, что нужно знать о байтах /g111 Каждый элемент – целое число в диапазоне range(256) . /g112 Срезы bytes также имеют тип bytes , даже если срез состоит из одного байта. /g113 Для типа bytearray не существует литерального синтаксиса: в оболочке объекты этого типа представляются в виде конструктора bytearray() , аргу- ментом которого является литерал типа bytes . /g114 Срез bytesarray также имеет тип bytesarray . Тот факт , что my_bytes[0] возвращает int, а my_bytes[:1] – объ- ект bytes длины 1, не должен вызывать удивления. Единственный тип последовательности, для которого s[0] == s[:1] , – это тип str. И хотя на практике этот тип используется сплошь и рядом, его поведение – исключение из правила. Для всех остальных после-довательностей s[i] возвращает один элемент , а s[i:i+1] – по- следовательность, состоящую из единственного элемента s[i] . Хотя двоичные последовательности – на самом деле, последовательности целых чисел, в их литеральной нотации отражен тот факт, что часто они включают ASCII-текст. Поэтому применяются различные способы отображения, зависящие от значения каждого байта. • Для байтов из диапазона символов ASCII, имеющих графическое начерта- ние, – от пробела до ˜ – выводится сам символ ASCII. • Для байтов, соответствующих символам табуляции, новой строки, возвра- та каретки и \\, выводятся управляющие последовательности \\t, \\n, \\r и \\\\. • Для всех остальных байтов выводится шестнадцатеричное представление (например, нулевой байт представляется последовательностью \\x00). Именно поэтому в примере 4.2 мы видим представление b'caf\\xc3\\xa9' : пер- вые три байта b'caf' принадлежат диапазону символов ASCII с графическим на- чертанием, последний – нет. Оба типа bytes и bytearray поддерживают все методы типа str кроме тех, что относятся к форматированию ( format , format_map ), и еще нескольких, прямо за- висящих от особенностей Unicode, в том числе casefold , isdecimal , isidentifier , isnumeric , isprintable и encode . Это означает, что при работе с двоичными после- довательностями мы можем пользоваться знакомыми методами строк, например endswith , replace , strip , translate , upper и десятками других, только аргументы должны иметь тип bytes , а не str. К двоичным последовательностям применимы и функции для работы с регулярными выражениями из модуля re, если регулярное выражение откомпилировано из двоичной последовательности, а не из str. Опе- ратор % не работает с двоичными последовательностями в версиях от Python 3.0 до 3.4, но, если верить документу «PEP 461 – Adding % formatting to bytes and bytearray» ( https://www.python.org/dev/peps/pep-0461/ ), то его предполагается поддержать его в версии 3.5.\n--- Страница 130 ---\n130 Глава 4. Текст и байты Для двоичных последовательностей существует метод класса, отсутствующий в типе str: fromhex , который строит последовательность, разбирая пары шестнад- цатеричных цифр, которые могут быть разделены пробелами, хотя это и необяза-тельно. >>> bytes.fromhex('31 4B CE A9')b'1K \\xce \\xa9' Другие способы построения объектов bytes и bytearray связаны с вызовом различных конструкторов: • с именованными аргументами str и encoding ; • с итерируемым объектом, порождающим элементы со значениями от 0 до 255; • с одним целым числом, для создания двоичной последовательности такого размера, инициализированной нулевыми байтами (эта сигнатура будет объявлена нерекомендуемой в Python 3.5 и исключена в Python 3.6. См. документ «PEP 467 – Minor API improvements for binary sequences» (https://www.python.org/dev/peps/pep-0467/ )); • с объектом, который реализует протокол буфера (например, bytes , byte- array , memoryview , array.array ), при этом байты копируются из исходного объекта во вновь созданную двоичную последовательность. Построение двоичной последовательности из буфероподобного объекта – это низкоуровневая операция, которая может потребовать приведения типов. См. пример 4.3. Пример 4.3. Инициализация байтов данными, хранящимися в массиве >>> import array >>> numbers = array.array('h', [-2, -1, 0, 1, 2]) /g110 >>> octets = bytes(numbers) /g111 >>> octetsb'\\xfe\\xff\\xff\\xff\\x00\\x00\\x01\\x00\\x02\\x00' /g112 /g110 Код типа 'h' означает создание массива коротких целых (16-разрядных). /g111 В объекте octets хранится копия байтов, из которых составлены числа в массиве numbers . /g112 Это десять байтов, представляющих пять коротких целых. Создание объекта bytes или bytearray из буфероподобного источника всегда сопровождается копированием байтов. Напротив, объекты типа memoryview позво- ляют разным двоичным структурам данных использовать одну и ту же область памяти. Для извлечения структурированной информации из двоичной последова-тельности бесценную пользу может оказать модуль struct . В следующем разделе мы увидим, как он работает с типами bytes и memoryview .\n--- Страница 131 ---\n131 Все, что нужно знать о байтах Структуры и представления областей памяти Модуль struct содержит функции для разбора упакованных байтов и постро- ения из них кортежей полей различных типов, а также для обратного преобразо-вания из кортежа в упакованные байты. Функции из модуля struct применимы к объектам типа bytes , bytearray и memoryview . В разделе «Представления областей памяти» на стр. 78 мы видели, что класс memoryview не позволяет ни создавать, ни сохранять последовательности байтов, но предоставляет общий доступ к областям памяти, содержащим срезы других двоичных последовательностей, упакованных массивов и буферов типа тех, что используются в библиотеке Python Imaging Library (PIL) 2, не копируя ни одного байта. В примере 4.4 показано совместное использование memoryview и struct для из- влечения ширины и высоты GIF-изображения. Пример 4.4. Использование memoryview и struct для извлечения полей из заголовка GIF-изображения >>> import struct >>> fmt = '<3s3sHH' # /g110 >>> with open('filter.gif', 'rb') as fp: img = memoryview(fp.read()) # /g111 >>> header = img[:10] # /g112 >>> bytes(header) # /g113 b'GIF89a+\\x02\\xe6\\x00'>>> struct.unpack(fmt, header) # /g114 (b'GIF', b'89a', 555, 230)>>> del header # /g115 >>> del img /g110 Формат struct : < – остроконечный порядок байтов, 3s3s – две последова- тельности по три байта, HH – два 16-разрядных целых. /g111 Создать memoryview из содержимого файла в памяти… /g112 … и еще один memoryview , представляющий собой срез первого; ни один байт при этом не копируется. /g113 Преобразовать в bytes только для отображения, здесь копируется 10 бай- тов. /g114 Распаковать memoryview в кортеж: тип, номер версии, ширина, высота. /g115 У далить ссылки, чтобы освободить память, занятую экземплярами memoryview . Отметим, что операция получения среза memoryview возвращает новый объект memoryview без копирования байтов (Леонардо Рохаэль, один из технических рецензентов книги, указал, что можно было бы и еще уменьшить число операций копирования байтов, если воспользоваться модулем mmap для проецирования на 2 Pillow ( https://pillow.readthedocs.org/en/latest/ ) – самый активный клон PIL.\n--- Страница 132 ---\n132 Глава 4. Текст и байты память файла изображения. В этой книге я не рассматриваю модуль mmap , но если вам часто приходится читать и изменять двоичные файлы, то познакомиться с разделом документации « mmap – поддержка проецирования файлов на память» (https://docs.python.org/3/library/mmap.html ) будет весьма полезно.) Мы не станем дальше углубляться в детали класса memoryview и модуля struct , но всем, кто много работает с двоичными данными, рекомендуем изучить соответ-ствующие разделы документации: «Встроенные типы – представления памяти» (http://bit.ly/1Vm7ZnI ) и «struct – интерпретация байтов как упакованных двоич- ных данных» ( http://bit.ly/1Vm7YjA ). После этого краткого введения в типы двоичных последовательностей посмо- трим, как производится преобразование между ними и строками. Базовые кодировщики и декодировщики В дистрибутиве Python имеется свыше 100 кодеков (кодировщик-декодировщик) для преобразования текста в байты и обратно. У каждого кодека есть имя, напри-мер 'utf_8' , а часто еще и синонимы, например 'utf8' , 'utf-8' и 'U8' . Имя можно передать в качестве аргумента encoding таким функциям, как open() , str .encode() , bytes .decode() и т. д. В примере 4.5 показан один и тот же текст, закодированный как три разные последовательности байтов. Пример 4.5. Строка «El N iño», закодированная тремя кодеками, дает совершенно разные последовательности байтов >>> for codec in ['latin_1', 'utf_8', 'utf_16']: print(codec, 'El Ni ño'.encode(codec), sep='\\t') latin_1 b'El Ni\\xf1o'utf_8 b'El Ni\\xc3\\xb1o'utf_16 b'\\xff\\xfeE\\x00l\\x00 \\x00N\\x00i\\x00\\xf1\\x00o\\x00' На рис. 4.1 показано, какие байты различные кодеки генерируют для некото- рых символов: от буквы «A» до символа скрипичного ключа. Отметим, что послед-ние три кодировки многобайтовые, переменной длины. Звездочки на рис. 4.1 ясно показывают, что некоторые кодировки, в частнос- ти ASCII и даже многобайтовая кодировка GB2312, не способны представить все символы Unicode. Однако кодировки семейства UTF спроектированы так, чтобы была возможность представить любую кодовую позицию Unicode. Кодировки на рис. 4.1 образуют достаточно репрезентативную выборку . latin1 , или iso8859_1 Важна, потому что лежит в основе других кодировок, в частности cp1252 , и самого Unicode (отметим, что значения байтов latin1 повторяются в столб- це cp1252 и даже в самих кодовых позициях).\n--- Страница 133 ---\n133 Базовые кодировщики и декодировщики cp1252 Надмножество latin1 , разработанное Майкрософт. Добавлены некоторые полезные символы, например фигурные кавычки и знак евро €. В некото- рых приложениях для Windows эта кодировка называется «ANSI», хотя никакой стандарт ANSI по этому поводу не принимался. cp437 Оригинальный набор символов для IBM PC, содержащий символы псевдо- графики. Несовместим с кодировкой latin1 , которая появилась позже. gb2312 Унаследованный стандарт кодирования упрощенных китайских иерогли- фов, используемый в континентальном Китае; одна из нескольких широко распространенных многобайтовых кодировок для азиатских языков. utf-8 Самая употребительная 8-разрядная кодировка в веб3, обратно совместима с ASCII (текст, содержащий только символы ASCII, является допустимым и в кодировке UTF-8). utf-16le Одна из форм 16-разрядной схемы кодирования UTF-16; все кодировки семейства UTF-16 поддерживают кодовые позиции с номерами, больши-ми U+FFFF , с помощью управляющих последовательностей, называемых «суррогатными парами». Рис. 4.1. Двенадцать символов, их кодовые позиции и байтовые представления (в 16-ричном виде) в семи разных кодировках (звездочка означает , что в данной кодировке этот символ непредставим) 3 По состоянию на сентябрь 2014 года в исследовании W3T echs «Usage of Character Encodings for W ebsites» ( http://bit.ly/w3techs-en ) утверждается, что на 81.4 % сайтов используется кодировка UTF-8, тогда как сайт Built With в отчете «Encoding Usage Statistics» ( http://trends.builtwith.com/ encoding ) дает оценку 79.4 %.\n--- Страница 134 ---\n134 Глава 4. Текст и байты UTF-16 заменила первоначальную 16-разрядную кодировку в Unicode 1.0 – UCS-2 – еще в 1996 году. UCS-2 все еще развернута во многих системах, но поддерживает только кодовые позиции с номерами до U+FFFF . На момент выхода версии стандарта Unicode 6.3 более 50% распределенных кодовых позиций имеют номера больше U+10000, сюда относятся и столь популярные смайлики. Завершив обзор распространенных кодировок, перейдем к проблемам, возни- кающим в процессе кодирования и декодирования. Проблемы кодирования и декодирования Существует общее исключение UnicodeError , но возникающая ошибка почти всег- да более специфична: либо UnicodeEncodeError (в случае преобразования str в дво- ичную последовательность), либо UnicodeDecodeError (в случае чтения двоичной последовательности в str). При загрузке модулей Python может также возникать исключение SyntaxError в случае неожиданной кодировки исходного кода. В сле- дующих разделах мы расскажем, как обрабатывать такие ошибки. Первое, на что нужно обращать внимание, получив ошиб- ку Unicode, – точный тип исключения. Это UnicodeEncodeError , UnicodeDecodeError или какая-то другая ошибка (например, SyntaxError ), свидетельствующая об ошибке кодирования? Это главное, что нужно знать для решения проблемы. Обработка UnicodeEncodeError В большинстве кодеков, не входящих в семейство UTF , представлено только небольшое подмножество символов Unicode. Если в ходе преобразования текста в байты оказывается, что символ отсутствует в конечной кодировке, то возбужда-ется исключение UnicodeEncodeError , если только методу или функции кодировки не передан аргумент errors , обеспечивающий специальную обработку. Поведение обработчиков ошибок демонстрируется в примере 4.6. Пример 4.6. Кодирование текста в байты: успешное завершение и обработка ошибок >>> city = 'S ão Paulo' >>> city.encode('utf_8') /g110 b'S\\xc3\\xa3o Paulo'>>> city.encode('utf_16')b'\\xff\\xfeS\\x00\\xe3\\x00o\\x00 \\x00P\\x00a\\x00u\\x00l\\x00o\\x00' >>> city.encode('iso8859_1') /g111\n--- Страница 135 ---\n135 Проблемы кодирования и декодирования b'S\\xe3o Paulo' >>> city.encode('cp437') /g112 Traceback (most recent call last): File \"<stdin>\", line 1, in <module> File \"/ /lib/python3.4/encodings/cp437.py\", line 12, in encode return codecs.charmap_encode(input,errors,encoding_map)UnicodeEncodeError: 'charmap' codec can't encode character '\\xe3' inposition 1: character maps to <undefined>>>> city.encode('cp437', errors='ignore') /g113 b'So Paulo'>>> city.encode('cp437', errors='replace') /g114 b'S?o Paulo'>>> city.encode('cp437', errors='xmlcharrefreplace') /g115 b'S&#227;o Paulo' /g110 Кодировки 'utf_?' справляются с любой строкой str. /g111 'iso8859_1' также работает для строки 'São Paulo' . /g112 'cp437' не может закодировать букву 'ã' («a» с тильдой). Обработчик оши- бок по умолчанию – 'strict' – возбуждает исключение UnicodeEncodeError . /g113 Обработчик error='ignore' молча пропускает некодируемые символы, обычно это не слишком удачная идея. /g114 Обработчик error='replace' заменяет некодируемые символы знаком '?'; данные теряются, но пользователь хотя бы знает, что какая-то часть инфор-мации утрачена. /g115 'xmlcharrefreplace' заменяет некодируемые символы XML-компонентом. Механизм обработки ошибок в модуле codecs расширяемый. Можно зарегистрировать дополнительные значения аргумента errors , передав строку и функцию обработки ошибок функции codecs.register_error . См. документацию по codecs.register_ error (http://bit.ly/1Vm83DZ ). Обработка UnicodeDecodeError Не каждый байт содержит допустимый символ ASCII, и не каждая последова- тельность байтов является допустимой в кодировке UTF-8 или UTF-16. Если при декодировании двоичной последовательности встретится неожиданный байт, то возникнет исключение UnicodeDecodeError . С другой стороны, многие унаследованные 8-разрядные кодировки, например 'cp1252' , 'iso8859_1' и 'koi8_r' могут декодировать произвольный поток байтов, в т. ч. случайный шум, без ошибок. Поэтому, если ваша программа ошибется в предположении о том, какая 8-разрядная кодировка используется, то будет молча декодировать мусор. В примере 4.7 показано, как неправильно выбранный кодек может порождать крокозябры или исключение UnicodeDecodeError .\n--- Страница 136 ---\n136 Глава 4. Текст и байты В русской традиции «мусорные» символы называются «крокозя- брами», а в англоязычной «гремлинами» или «mojibake» ( 㠖ⷦ▥ሴ – по-японски «трансформированный текст»). Пример 4.7. Декодирование строки в байты: успешное завершение и обработка ошибок >>> octets = b'Montr\\xe9al' /g110 >>> octets.decode('cp1252') /g111 'Montréal' >>> octets.decode('iso8859_7') /g112 'Montr/g538al' >>> octets.decode('koi8_r') /g113 'MontrИal'>>> octets.decode('utf_8') /g114 Traceback (most recent call last): File \"<stdin>\", line 1, in <module>UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 5:invalid continuation byte>>> octets.decode('utf_8', errors='replace') /g115 'Montr /queryal' /g110 Эти байты являются символами строки «Montr éal» в кодировке latin1 ; '\\xe9' – байт, соответствующий букве « é». /g111 Декодирование с помощью кодировки 'cp1252' (Windows 1252) работает, потому что она является собственным надмножеством latin1 . /g112 Кодировка ISO-8859-7 предназначена для греческого языка, поэтому байт '\\xe9' интерпретируется неправильно, но исключение не возбуждается. /g113 KOI8-R – кодировка для русского языка. Теперь '\\xe9' интерпретируется как русская буква «И». /g114 Кодек 'utf_8' обнаруживает октеты, не являющиеся допустимой после- довательностью байтов в кодировке UTF-8, и возбуждает исключение UnicodeDecodeError . /g115 При использовании обработчика ошибок 'replace' байт \\xe9 заменяется символом « /query» (кодовая позиция U+FFFD), официальным ЗАМЕНЯЮ- ЩИМ СИМВОЛОМ в Unicode, который служит для представления неиз-вестных символов. Исключение SyntaxError при загрузке модулей и неожиданной кодировкой UTF-8 – подразумеваемая по умолчанию кодировка исходного кода в Python 3. В Python 2 (начиная с версии 2.5) таковой была кодировка ASCII. При попытке загрузить py-модуль, содержащий данные не в кодировке UTF-8 и не имеющий объявления кодировки, будет выдано сообщение вида:\n--- Страница 137 ---\n137 Проблемы кодирования и декодирования SyntaxError: Non-UTF-8 code starting with '\\xe1' in file ola.py on line 1, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details Поскольку в системах GNU/Linux и OS X практически повсеместно развер- нута кодировка UTF-8, такая ошибка наиболее вероятна при открытии py-файла, созданного в Windows в кодировке cp1252 . Отметим, что она происходит даже в Python для Windows, потому что в Python 3 по умолчанию на всех платформах подразумевается кодировка UTF-8. Чтобы исправить ошибку, добавьте в начало файла магический комментарий, как показано в примере 4.8. Пример 4.8. ola.py: «Hello, World!» по-португальски # coding: cp1252 print('Ol á, Mundo!') Теперь, когда исходный код на Python 3 не ограничивается одной лишь кодировкой ASCII и по умолчанию подразумевается замеча-тельная UTF-8, самое правильное «лечение» для исходного кода в унаследованной кодировки типа 'cp1252' – преобразовать в UTF-8 и не заморачиваться комментариями coding . Если ваш редактор не поддерживает UTF-8, пора его поменять. Не-ASCII имена в исходном коде: стоит ли их использовать? В Python 3 разрешается использовать в исходном коде идентифика- торы в кодировке, отличной от ASCII: >>> açáo = 'PBR' # a çáo = акция >>> /g304 = 10**-6 # /g304 = epsilon Некоторым эта идея не нравится. Чаще всего в пользу использова- ния только ASCII-идентификаторов приводят тот довод, что так всем будет проще читать и редактировать код. Но тут упущена одна деталь: вы хотите, чтобы ваш исходный код был доступен для чтения и редакти-рования целевой аудитории, а это вовсе необязательно «все». Если код принадлежит интернациональной корпорации или является открытым, и вы хотите, чтобы дополнять его могли люди во всего света, то иденти-фикаторы определенно стоит писать по-английски, и тогда вам нужна только кодировка ASCII.\n--- Страница 138 ---\n138 Глава 4. Текст и байты Но если вы преподаете в Бразилии, то студентам будет проще читать код, в котором имена переменных и функций написан по-португальски и притом без орфографических ошибок. И у них не будет проблем с вводом седилей и акцентированных гласных, поскольку они работают с местной клавиатурой. Поскольку теперь Python понимает Unicode-имена, а UTF-8 – ко- дировка исходного кода по умолчанию, то я не вижу никакого смысла писать португальские идентификаторы без диакритических знаков, как мы делали в Python 2 по необходимости, – если, конечно, вы не со-бираетесь запускать свой код и в Python 2 тоже. Если имена все равно португальские, то отбрасывание диакритических знаков не сделает код понятнее ни для кого. Это моя личная точка зрения – человека, говорящего на бразильском диалекте португальского языка, – но полагаю, что она применима и к другим культурам и регионам: выберите естественный язык, который наиболее понятен потенциальным читателям кода, и набирайте его сим-волы правильно, Предположим, что имеется некий текстовый файл, все равно, исходный код или стихотворение, но вы не знаете, в какой кодировке он записан. Как определить истинную кодировку? В следующем разделе мы порекомендуем библиотеку для этой цели. Как определить кодировку последовательности байтов Как узнать, в какой кодировке записана последовательность байтов? Короткий ответ: никак. Кто-то должен вам сообщить. В некоторых коммуникационных протоколах и файловых форматах, например HTTP и XML, предусмотрены заголовки, в которых явно указывается, как зако-дировано содержимое. Можно быть уверенным, что поток байтов представлен не в кодировке ASCII, если он содержит значения, большие 127, а сам способ постро-ения UTF-8 и UTF-16 исключает определенные последовательности байтов. Но и с учетом всего этого никогда нет стопроцентной уверенности в том, что некий двоичный файл записан в кодировке ASCII или UTF-8 просто потому, что в нем не встречаются определенные комбинации битов. Однако известно, что в естественных языках есть свои правила и ограниче- ния. Поэтому есть допустить, что поток байтов – это простой текст на естествен- ном языке, то его кодировку можно попытаться определить с помощью различ-ных эвристических правил и статистики. Например, если часто встречается байт b'\\x00' , то это, скорее всего, 16- или 32-разрядная кодировка, но не 8-разрядная схема, потому что нулевые байты в открытом тексте – очевидная ошибка. Если ча-\n--- Страница 139 ---\n139 Проблемы кодирования и декодирования сто встречается последовательность b'\\x20\\x00' , то это, наверное, символ пробела (U+0020) в кодировке UTF-16LE, а не малоизвестный символ U+2000 EN QUAD . Именно так и работает пакет Chardet – универсальный детектор кодировки символов ( https://pypi.python.org/pypi/chardet ) – который пытается распознать одну из 30 поддерживаемых кодировок. Chardet – написанная на Python библио-тека, которую вы можете включить в свою программу, а, кроме нее, пакет содержит также командную утилиту chardetect . Вот что она сообщает о файле с исходным кодом к данной главе: $ chardetect 04-text-byte.asciidoc04-text-byte.asciidoc: utf-8 with confidence 0.99 Хотя в самих двоичных последовательностях закодированного текста обычно нет явных указаний на кодировку, в некоторых UTF-форматах в начале файла мо-жет находиться маркер порядка байтов. Это объясняется в следующем разделе. BOM: полезный крокозябр Возможно, вы заметили, что в примере 4.5 в начале последовательности в кодировке UTF-16 находились два дополнительных байта. Приведем их еще раз: >>> u16 = 'El Ni ño'.encode('utf_16') >>> u16b'\\xff\\xfeE\\x00l\\x00 \\x00N\\x00i\\x00\\xf1\\x00o\\x00' Речь идет о байтах b'\\xff\\xfe' . Это BOM – byte-order mark (маркер порядка байтов). В данном случае он говорит, что порядок «остроконечный», т. е. приня-тый в процессоре Intel, на котором производилось кодирование. На «остроконечной» машине для каждой кодовой позиции первым идет млад- ший байт: буква 'E' с кодовой позицией U+0045 (десятичное 69) представлена в позициях со смещением 2 и 3 от начала последовательности числами 69 и 0: >>> list(u16)[255, 254, 69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111, 0] На машине с «тупоконечным» процессором кодировка была бы противопо- ложной; буква 'E' была бы закодирована числами 0 и 69. Во избежание недоразумений в начало текстовых файлов в кодировке UTF-16 добавляется специальный невидимый символ НЕРАЗРЫВНЫЙ ПРОБЕЛ НУЛЕВОЙ ШИРИНЫ (U+FEFF). В «остроконечной» системе он кодируется байтами b'\\xff\\ xfe' (десятичные 255, 254). Поскольку символ в кодовой позиции U+FFFE не существует – это задумано специально – последовательность байтов b'\\xff\\xfe' должна означать НЕРАЗРЫВНЫЙ ПРОБЕЛ НУЛЕВОЙ ШИРИНЫ в остроконечной кодировке, поэтому кодек знает, каким должен быть порядок байтов. Существует вариант кодировки UTF-16 – UTF-16LE – специально предназна- ченный для остроконечных систем, а также его аналог для тупоконечных систем – UTF-16BE. В случае их использования маркер BOM не добавляется:\n--- Страница 140 ---\n140 Глава 4. Текст и байты >>> u16le = 'El Ni ño'.encode('utf_16le') >>> list(u16le)[69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111, 0]>>> u16be = 'El Ni ño'.encode('utf_16be') >>> list(u16be)[0, 69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111] Предполагается, что BOM, если он присутствует, будет отфильтрован кодеком UTF-16, так что останется только сам текст файла без НЕРАЗРЫВНОГО ПРОБЕЛА НУЛЕВОЙ ШИРИНЫ . Стандарт гласит, что для файла в кодировке UTF-16 без мар- кера BOM следует предполагать кодировку UTF-16BE (тупоконечную). Однако архитектура Intel x86 остроконечная, поэтому на практике в изобилии встречают-ся остроконечные файлы в кодировке UTF-16 без BOM. Проблема порядка байтов возникает только для кодировок, в которых симво- лы кодируются словами, состоящими из нескольких байтов, например UTF-16 и UTF-32. Существенное достоинство UTF-8 заключается в том, что эта кодировка порождает одни и те же последовательности байтов вне зависимости от машин-ной архитектуры, поэтому BOM не нужен. Тем не менее, некоторые приложения Windows (и, прежде всего, Блокнот) добавляют BOM и в файлы в кодировке UTF-8, а для Excel наличие BOM означает, что файл записан в UTF-8, иначе предполага-ется, что для его кодирования использовалась кодовая страница Windows. Символ U+FEFF в UTF-8 кодируется последовательностью из трех байтов b'\\xef\\xbb\\ xbf' . Поэтому файл, начинающийся такими байтами, скорее всего, закодирован в UTF-8 и содержит BOM. Однако Python не предполагает автоматически кодиров-ку UTF-8, если файл начинается с b'\\xef\\xbb\\xbf' . Перейдем теперь к обработке текстовых файлов в Python 3. Обработка текстовых файлов На практике обрабатывать текстовые файлы лучше всего, применяя «сэндвич Unicode» (рис. 4.2) 4. Это означает, что тип bytes следует декодировать в str на возможно более ранних стадиях ввода (например, при открытии файла для чтения). «Котлета» в сэндвиче – это бизнес-логика вашей программы, внутри которой обрабатываются только объекты str. Никогда не следует производить кодирование или декодирование в середине обработки. На этапе вывода объекты str кодируются в bytes как можно позже. Именно так работает большинство веб- каркасов, так что их пользователям редко приходится иметь дело с типом bytes . Например, в Django представления должны выводить строки str, а Django сам позаботится о кодировании ответа в bytes , применяя по умолчанию кодировку UTF-8. Python 3 облегчает следование этой рекомендации, потому что встроенная функция open производит необходимое декодирование при чтении и кодирование 4 Впервые словосочетание «сэндвич Unicode» встретилось мне в замечательном выступлении Нэда Бэтчелдера «Pragmatic Unicode» ( http://nedbatchelder.com/text/unipain/unipain.html ).\n--- Страница 141 ---\n141 Обработка текстовых файлов при записи файлов в текстовом режиме, т. е. от метода my_file.read() мы получа- ем объекты str и их же передаем методу my_file.write(text)5. Рис. 4.2. Сэндвич Unicode – рекомендуемый способ обработки текста Таким образом, работать с текстовыми файлами просто. Но, всегда полагаясь на кодировку по умолчанию, вы можете горько пожалеть. Взгляните на сеанс оболочки в примере 4.9. Сможете найти ошибку? Пример 4.9. Проблема платформенно-зависимой кодировки (выполнив этот код на своей машине, вы, возможно, наткнетесь на проблему, а, возможно, и нет) >>> open('cafe.txt', 'w', encoding='utf_8').write('caf é') 4 >>> open('cafe.txt').read() 'cafÃ©' Ошибка заключается в том, что я задал кодировку UTF-8 при записи в файл, но забыл сделать это при чтении, поэтому Python предположил, что используется системная кодировка по умолчанию – Windows 1252 – и декодировал два послед-них байта в файле как символы 'Á©' вместо 'é'. Я выполнял пример 4.9 на машине под управлением Windows 7. Те же самые предложения в последних версиях GNU/Linux и Mac OS X работают без ошибок, потому что в них по умолчанию предполагается кодировка UTF-8, и это создает ложное впечатление, будто все хорошо. Если бы мы опустили аргумент encoding при открытии файла для записи, то была бы использована местная кодировка по умолчанию, и мы правильно прочитали бы файл в той же самой кодировке. Но тогда этот скрипт генерировал бы файлы с разным байтовым содержимым на раз-ных платформах и даже при различных настройках локали на одной и той же плат-форме, и мы получили бы проблему совместимости. 5 Пользователи Python 2.6 и 2.7 вынуждены использовать функцию io.open() для автоматическо- го кодирования и декодирования при чтении-записи.Сэндвич Unicode Декодировать байты при вводе, обрабатывать только текст, кодировать текст при выводе.\n--- Страница 142 ---\n142 Глава 4. Текст и байты Код, который должен запускаться на разных машинах или в раз- ных ситуациях, не должен зависеть от кодировки по умолчанию. Всегда явно задавайте аргумент encoding= при открытии тексто- вых файлов, потому что умолчания могут зависеть от машины и даже меняться на одной и той же машине. В примере 4.9 есть любопытная деталь: функция write в первом предложении говорит, что было записано четыре символа, а в следующей строке читается пять символов. В примере 4.10, где приведен расширенный вариант примера 4.9, объясняется этот и другие курьезы. Пример 4.10. Более пристальное изучение запуска примера 4.9 в Windows вскрывает ошибку и показывает , как ее исправить >>> fp = open('cafe.txt', 'w', encoding='utf_8') >>> fp /g110 <_io.TextIOWrapper name='cafe.txt' mode='w' encoding='utf_8'>>>> fp.write('caf é') 4 /g111 >>> fp.close()>>> import os>>> os.stat('cafe.txt').st_size5 /g112 >>> fp2 = open('cafe.txt')>>> fp2 /g113 <_io.TextIOWrapper name='cafe.txt' mode='r' encoding='cp1252'>>>> fp2.encoding /g114 'cp1252'>>> fp2.read()'cafÃ©' /g115 >>> fp3 = open('cafe.txt', encoding='utf_8') /g116 >>> fp3<_io.TextIOWrapper name='cafe.txt' mode='r' encoding='utf_8'>>>> fp3.read()'café' /g117 >>> fp4 = open('cafe.txt', 'rb') /g118 >>> fp4<_io.BufferedReader name='cafe.txt'> /g119 >>> fp4.read() ⤓ b'caf\\xc3\\xa9' /g110 По умолчанию open открывает файл в текстовом режиме и возвращает объект TextIOWrapper . /g111 Метод write объекта TextIOWrapper возвращает количество записанных символов Unicode. /g112 Функция os.stat сообщает, что файл содержит 5 байтов; в кодировке UTF-8 буква 'é' представлена двумя байтами: 0xc3 и 0xa9.\n--- Страница 143 ---\n143 Обработка текстовых файлов /g113 В результате открытия текстового файла без явного указания кодировки возвращается объект TextIOWrapper , в котором установлена кодировка, взятая из локали. /g114 В объекте TextIOWrapper имеется атрибут encoding , который можно опросить, в данном случае он равен cp1252 . /g115 В кодировке Windows cp1252 байт 0xc3 соответствует символу « Ã» (A с тильдой), а 0xa9 – знаку копирайта. /g116 Открытие того же файла с указанием правильной кодировки. /g117 Ожидаемый результат: те же самые четыре символа Unicode 'café'. /g118 При задании флага 'rb' файл открывается в двоичном режиме. /g119 Возвращенный объект имеет тип BufferedReader , а не TextIOWrapper . ⤓ Чтение возвращает те байты, которые ожидаются. Не открывайте текстовые файлы в двоичном режиме, если не собираетесь анализировать содержимое файла на предмет определения кодировки, да и в этом случае лучше пользовать-ся библиотекой Chardet, а не изобретать велосипед (см. раздел «Как определить кодировку последовательности байтов» выше). В обычной программе двоичный режим следует использовать только для открытия двоичных файлов, например растровых изо-бражений. Проблема, встретившаяся нам в примере 4.10, возникла из-за неверного пред- положения о кодировке по умолчанию при открытии текстового файла. Как по-казано в следующем разделе, существует несколько источников таких умолчаний. Кодировки по умолчанию: сумасшедший дом На установку кодировки по умолчанию в Python влияют несколько параметров. См. скрипт default_encodings.py в примере 4.11. Пример 4.11. Исследование кодировок по умолчанию import sys, locale expressions = \"\"\" locale.getpreferredencoding() type(my_file) my_file.encoding sys.stdout.isatty() sys.stdout.encoding sys.stdin.isatty() sys.stdin.encoding sys.stderr.isatty() sys.stderr.encoding sys.getdefaultencoding()\n--- Страница 144 ---\n144 Глава 4. Текст и байты sys.getfilesystemencoding() \"\"\" my_file = open('dummy', 'w')for expression in expressions.split(): value = eval(expression) print(expression.rjust(30), '->', repr(value)) Этот скрипт выводит одно и то же в GNU/Linux (Ubuntu 14.04) и OS X (Mavericks 10.9), показывая, что в обоих случаях всюду используется кодировка UTF-8 : $ python3 default_encodings.pylocale.getpreferredencoding() -> 'UTF-8' type(my_file) -> <class '_io.TextIOWrapper'> my_file.encoding -> 'UTF-8' sys.stdout.isatty() -> True sys.stdout.encoding -> 'UTF-8' sys.stdin.isatty() -> True sys.stdin.encoding -> 'UTF-8' sys.stderr.isatty() -> True sys.stderr.encoding -> 'UTF-8' sys.getdefaultencoding() -> 'utf-8' sys .getfilesystemencoding() -> 'utf-8' Однако в Windows выводится нечто совершенно иное (см. пример 4.12). Пример 4.12. Кодировки по умолчанию в оболочке Windows 7 (SP 1) cmd.exe, локализованной для Бразилии; PowerShell дает такой же результат Z:\\>chcp /g110 Pagina de codigo ativa: 850Z:\\>python default_encodings.py /g111 locale.getpreferredencoding() -> 'cp1252' /g112 type(my_file) -> <class '_io.TextIOWrapper'> my_file.encoding -> 'cp1252' /g113 sys.stdout.isatty() -> True /g114 sys.stdout.encoding -> 'cp850' /g115 sys.stdin.isatty() -> True sys.stdin.encoding -> 'cp850' sys.stderr.isatty() -> True sys.stderr.encoding -> 'cp850' sys.getdefaultencoding() -> 'utf-8' sys .getfilesystemencoding() -> 'mbcs' /g110 chcp показываетактивную кодовую страницу для консоли: 850. /g111 При запуске default_encodings.py с выводом на консоль. /g112 locale .getpreferredencoding() – самый важный параметр. /g113 Для текстовых файлов по умолчанию используется locale. getpreferredencoding() .\n--- Страница 145 ---\n145 Обработка текстовых файлов /g114 Вывод производится на консоль, поэтому sys .stdout .isatty() равно True . /g115 Поэтому sys .stdout .encoding такая же, как кодировка для консоли. Если перенаправить вывод в файл: Z:\\>python default_encodings.py > encodings.log то sys.stdout.isatty() становится равным False и sys.stdout.encoding устанав- ливается путем обращения к locale.getpreferredencoding() , т. е. 'cp1252' на дан- ной машине. Отметим, что в примере 4.12 встречаются четыре разных кодировки. • Если опустить аргумент encoding при открытии файла, то умолчание определяется методом locale.getpreferredencoding() ('cp1252' в приме- ре 4.12). • Кодировка sys.stdout/stdin/stderr определяется переменной окру- жения PYTHONIOENCODING (http://bit.ly/1IqvCUZ ), если она задана, ина- че либо наследуется от консоли, либо определяется методом locale. getpreferredencoding() в случае, когда ввод-вывод перенаправлен на файл. • Функция sys.getdefaultencoding() используется самим интерпретато- ром Python для преобразования двоичных данных в строку и обратно. В Python 3 это делается не так часто, но все же делается 6. Изменение этого параметра не поддерживается7. • Функция sys .getfilesystemencoding() применяется для кодирования и де- кодирования имен файлов (но не их содержимого). Она вызывается, когда open() получает имя файла в виде строки str; если же имя файла задано аргументом типа bytes , то оно передается API операционной системы без изменения. В документе «Python Unicode HOWTO» ( https://docs.python. org/3/howto/unicode.html ) написано: «в Python для Windows имя mbcs ис- пользуется для обозначения текущей сконфигурированной кодировки, ка-кова бы она ни была». Акроним MBCS означает «Multi Byte Character Set» (многобайтовый набор символов), таковы были кодировки переменной длины gb2312 или Shift_JIS , которые раньше использовались в операцион- ных системах Майкрософт, но UTF-8 к ним не относится. (На эту тему есть полезный ответ на сайте StackOverflow в статье «Различия между MBCS и UTF-8 в Windows» ( http://bit.ly/1IqvRPV )). 6 Изучая этот вопрос, я не нашел, в каких ситуациях Python 3 сам преобразует bytes в str. Разработ- чик ядра Python Антуан Питру в списке рассылки comp.python.devel ( http://bit.ly/1IqvSU2 ) пишет, что внутренние функции CPython, выполняющие такие преобразования, «используются в py3k не часто». 7 В Python 2 функция sys.setdefaultencoding использовалась некорректно и из документации по Python 3 ее описание исключено. Предполагалось, что она будет использоваться разработчиками ядра в тех случаях, когда внутренняя кодировка по умолчанию еще не определена. В ветви обсужде-ния comp.python.devel (http://bit.ly/1IqvN2J ) Марк-Андрэ Лембург (Marc-Andre Lemburg) го- ворит, что sys.setdefaultencoding никогда не должна вызываться из пользовательского кода, а единственные значения, поддерживаемые CPython, – 'ascii' в Python 2 и 'utf-8' в Python 3.\n--- Страница 146 ---\n146 Глава 4. Текст и байты В GNU/Linux и OS X все эти кодировки по умолчанию совпадают с UTF-8, и такое положение существует уже несколько лет , поэтому подсистема ввода-вывода обрабатывает все символы Unicode. В Windows не только используются различные кодировки в одной и той же системе, но обычно это еще и кодовые страницы, напри-мер 'cp850' или 'cp1252' , которые поддерживают только ASCII и еще 127 символов, отличающиеся в разных кодировках. Поэтому у пользователей Windows гораздо больше шансов столкнуться с ошибками кодирования при малейшей небрежности. Подводя итоги, можно сказать, что самым важным из всех относящихся к кодировкам параметров является значение, возвращаемое методом locale. getpreferredencoding() : оно подразумевается по умолчанию при открытии текстовых файлов и или вводе-выводе на sys.stdout/stdin/stderr , если поток перенаправлен на файл. Однако в документации ( http://bit.ly/1IqvYLp ) мы чи- таем: locale.getpreferredencoding(do_setlocale=True) Вернуть кодировку, используемую для текстовых данных, с со- ответствии с предпочтениями пользователя. Предпочтения задают-ся по-разному в разных системах и не всегда доступны из програм-мы, поэтому данная функция возвращает только предположитель-ное значение […] Таким образом, лучшее, что можно посоветовать в части кодировок по умолча- нию: не полагайтесь на них. Если вы будете поступать, как рекомендует сэндвич Unicode, и всегда явно указывать кодировку, то избежите множества неприятностей. К сожалению, про-блемы работы с Unicode не заканчиваются, даже если вы правильно преобразуете bytes в str. В следующих двух разделах рассматриваются темы, которые не вызы- вают ни малейших трудностей в стране ASCII, но становятся весьма сложными на планете Unicode: нормализация текста (т. е. приведение его к единому представ-лению для сравнения) и сортировка. Нормализация Unicode для правильного сравнения Сравнение строк осложняется тем, что в Unicode есть модифицирующие симво- лы: диакритические и другие знаки, присоединяемые к предыдущему символу, так что при печати оба символа выглядят, как единое целое. Например, слово «caf é» можно составить двумя способами, из четырех или из пяти кодовых позиций, хотя результат будет выглядеть одинаково:\n--- Страница 147 ---\n147 Нормализация Unicode для правильного сравнения >>> s1 = 'caf é' >>> s2 = 'cafe\\u0301'>>> s1, s2('café', 'café') >>> len(s1), len(s2)(4, 5)>>> s1 == s2False Кодовая позиция U+0301 называется МОДИФИЦИРУЮЩИЙ АКУТ. Если она следует за «e», то результат отображается как « é». В стандарте Unicode после- довательности вида 'é' и 'e\\u0301' называются «каноническими эквивалентами» и предполагается, что приложения будут считать их одинаковыми. Но Python ви-дит две разные последовательности кодовых позиций и одинаковыми их не счи-тает. Решение состоит в том, чтобы использовать нормализацию Unicode, реализу- емую функцией unicodedata.normalize . Первым аргументом функции передается одна из четырех строк: 'NFC' , 'NFD' , 'NFKC' или 'NFKD' . Сначала рассмотрим первые две. Форма нормализации C (NFC) производит композицию двух кодовых пози- ций с целью получения самой короткой эквивалентной строки, а форма нормали-зации D (NFD) производит декомпозицию, т. е. разложение составного символа на базовый и модифицирующие. В результате выполнения обеих нормализаций сравнение работает, как и ожидается: >>> from unicodedata import normalize>>> s1 = 'caf é' # composed \"e\" with acute accent >>> s2 = 'cafe\\u0301' # decomposed «e» and acute accent>>> len(s1), len(s2)(4, 5)>>> len(normalize('NFC', s1)), len(normalize('NFC', s2))(4, 4)>>> len(normalize('NFD', s1)), len(normalize('NFD', s2))(5, 5)>>> normalize('NFC', s1) == normalize('NFC', s2)True>>> normalize('NFD', s1) == normalize('NFD', s2)True Западные клавиатуры обычно генерируют составные символы, поэтому на- бранный пользователем текст по умолчанию оказывается в формате NFC. Но для пущей уверенности лучше прогнать строки через normalize('NFC', user_text) пе- ред сохранением. Форма нормализации NFC рекомендуется также консорциумом W3C в документе «Character Model for the W orld Wide W eb: String Matching and Searching ( http://www.w3.org/TR/charmod-norm/ ). Некоторые одиночные символы форма NFC преобразует в другие одиночные символы. Символ ома ( /g58), единицы электрического сопротивления, преобразует- ся в греческую букву омега в верхнем регистре. Визуально они ничем не отличают-\n--- Страница 148 ---\n148 Глава 4. Текст и байты ся, но при сравнении не совпадают, поэтому во избежание сюрпризов необходимо производить нормализацию: >>> from unicodedata import normalize, name>>> ohm = '\\u2126'>>> name(ohm)'OHM SIGN'>>> ohm_c = normalize('NFC', ohm)>>> name(ohm_c)'GREEK CAPITAL LETTER OMEGA'>>> ohm == ohm_cFalse>>> normalize('NFC', ohm) == normalize('NFC', ohm_c)True В акронимах двух других форм нормализации – NFKC и NFKD – буква K оз- начает «compatibility» (совместимость). Это более строгие формы нормализации, затрагивающие так называемые «символы совместимости». Хотя одна из целей Unicode – определить единственную «каноническую» кодовую позицию для каж-дого символа, некоторые символы встречаются несколько раз ради совместимости с предшествующими стандартами. Например, знак «микро» 'μ' (U+00B5) был до- бавлен в Unicode для поддержки обратимого преобразования в latin1 , хотя тот же самый символ является также частью греческого алфавита, где ему соответству-ет кодовая позиция U+03BC (СТРОЧНАЯ ГРЕЧЕСКАЯ БУКВА МЮ ). Поэтому знак «микро» считается «символом совместимости». В формах NFKC и NFKD каждый символ совместимости заменяется «совме- стимой декомпозицией» из одного или более символов, которая считается «пред-почтительным» представлением, даже если при этом возникает потеря формати-рования – в идеале форматирование должно быть функцией внешней разметки, а не частью Unicode. Например, совместимой декомпозицией дроби «одна вторая» '' (U+00BD ) является последовательность трех символов '1/2' , а совместимой де- композицией знака «микро» 'μ' (U+00B5 ) – строчная буква мю 'μ' (U+03BC )8. Вот как NFKC работает на практике: >>> from unicodedata import normalize, name>>> half = ' ' >>> normalize('NFKC', half)'1/2'>>> four_squared = '4 2' >>> normalize('NFKC', four_squared)'42'>>> micro = 'μ'>>> micro_kc = normalize('NFKC', micro)>>> micro, micro_kc('μ', 'μ')>>> ord(micro), ord(micro_kc)(181, 956) 8 Любопытно, что знак «микро» считается символом совместимости, а знак «ом» нет. В результате NFC не трогает знак «микро», но изменяет знак «ом» на заглавную букву омега, тогда как NFKC и NFKD заменяют и «ом», и «микро» другими символами.\n--- Страница 149 ---\n149 Нормализация Unicode для правильного сравнения >>> name(micro), name(micro_kc) ('MICRO SIGN', 'GREEK SMALL LETTER MU') В то время как '1/2' – разумная замена для ' ½', а знак «микро» действительно совпадает со строчной греческой буквой мю, преобразование '42' в '42' изменя- ет смысл. Приложение могло бы сохранить '42' как '4<sup>2</sup>' , но функция normalize ничего не знает о форматировании. Поэтому формы NFKC и NFKD мо- гут терять или искажать информацию, но в то же время дают удобное промежу-точное представление для поиска и индексирования: пользователям понравится, что поиск по запросу '1/2 inch' находит также документы, содержащие строку ' inch' . Формы нормализации NFKC и NFKD следует применять с осто- рожностью и только в особых случаях, например для поиска и ин-дексирования, а не для постоянного хранения, поскольку выпол-няемые ими преобразования могут приводить к потере данных. Для подготовки текста к поиску или индексированию полезна еще одна опера- ция: сворачивание регистра. Это и есть тема следующего раздела. Сворачивание регистра Сворачивание регистра – это, по существу, перевод всего текста в нижний ре- гистр с некоторыми дополнительными преобразованиями. Для этой цели предна-значен метод str.casefold() (появился в версии Python 3.3). Если строка s содержит только символы из набора latin1 , то s.casefold() дает такой же результат, как s.lower() , с двумя исключениями: знак «микро» 'μ' за- меняется строчной греческой буквой мю (в большинстве шрифтов они выглядят одинаково), а немецкая «эсцет» ( ß) преобразуется в «ss »: >>> micro = ' μ' >>> name(micro)'MICRO SIGN'>>> micro_cf = micro.casefold()>>> name(micro_cf)'GREEK SMALL LETTER MU'>>> micro, micro_cf('μ', ' μ') >>> eszett = ' ß' >>> name(eszett)'LATIN SMALL LETTER SHARP S'>>> eszett_cf = eszett.casefold()>>> eszett, eszett_cf('ß', 'ss') В версии Python 3.4 существует 116 кодовых позиций, для которых str. casefold() и str.lower() дают различные результаты. Это 0,11 % от всех 110 122\n--- Страница 150 ---\n150 Глава 4. Текст и байты имеющих имена символов в Unicode 6.3. Как все связанное с Unicode, сворачивание регистра – сложная лингвистиче- ская проблема с множеством особых случаев, но разработчики ядра Python прило-жили максимум усилий, чтобы предложить решение, устраивающее большинство пользователей. В следующих двух разделах мы применим знания о нормализации к разработке служебных функций. Служебные функции для сравнения нормализованного текста Как мы видели, формы нормализации NFC и NFD безопасны и позволяют до- статочно осмысленно сравнивать Unicode-строки. Для большинства приложений NFC – наилучшая нормализованная форма. Для сравнения строк без учета реги-стра предназначен метод str.casefold() . Если вы работаете с текстами на многих языках, рекомендуем включить в свой арсенал функции наподобие nfc_equal и fold_equal , показанные в примере 4.13. Пример 4.13. normeq.py: сравнение нормализованных Unicode-строк \"\"\" Служебные функции для сравнения нормализованных Unicode-строк. Использование нормальной формы C, с учетом регистра: >>> s1 = 'caf é' >>> s2 = 'cafe\\u0301' >>> s1 == s2 False >>> nfc_equal(s1, s2) True >>> nfc_equal('A', 'a') False Использование нормальной формы C, со сворачиванием регистра: >>> s3 = 'Stra ße' >>> s4 = 'strasse' >>> s3 == s4 False >>> nfc_equal(s3, s4) False >>> fold_equal(s3, s4) True >>> fold_equal(s1, s2) True >>> fold_equal('A', 'a') True \"\"\"\n--- Страница 151 ---\n151 Нормализация Unicode для правильного сравнения from unicodedata import normalize def nfc_equal(str1, str2): return normalize('NFC', str1) == normalize('NFC', str2) def fold_equal(str1, str2): return (normalize('NFC', str1).casefold() == normalize('NFC', str2).casefold()) Помимо нормализации и сворачивания регистра (то и другое – части стандарта Unicode), иногда бывают полезны более глубокие преобразования, например 'café' 'cafe' . В следующем разделе мы покажем, когда это необходимо и как делается. Экстремальная «нормализация»: удаление диакритических знаков Секретный рецепт поиска Google скрывает много разных хитростей, один из них – полное игнорирование диакритических знаков (акцентов, седилей и т. д.), по крайней мере, в некоторых контекстах. У даление диакритических знаков, строго говоря, не является нормализацией, потому что зачастую при этом меняется смысл слов и поиск может находить не то, что нужно. Но жизнь есть жизнь: многие ленятся ставить диакритические знаки или не знают, как это нужно делать, да и правила правописания время от времени меняются. Игнорирование диакритики помогает справиться с этими проблемами. Но даже если оставить поиск в стороне, удаление диакритических знаков делает URL-адреса более удобочитаемыми, по крайней мере, в языках на основе латиницы. Взгляните на URL статьи википедии о городе Сан-Паулу: http://en .wikipedia .org/wiki/S%C3%A3o_Paulo Часть %C3%A3 – результат URL-кодирования представления буквы « ã» (a с тильдой) в кодировке UTF-8. Показанный ниже URL гораздо понятнее, пусть даже правописание в нем хромает: http://en .wikipedia .org/wiki/Sao_Paulo Для удаления всех диакритических знаков из str можно воспользоваться функцией из примера 4.14. Пример 4.14. Функция для удаления всех модифицирующих символов (модуль sanitize.py) import unicodedata import string def shave_marks(txt): \"\"\"Удалить все диакритические знаки\"\"\"\n--- Страница 152 ---\n152 Глава 4. Текст и байты norm_txt = unicodedata.normalize('NFD', txt) /g110 shaved = ''.join(c for c in norm_txt if not unicodedata.combining(c)) /g111 return unicodedata.normalize('NFC', shaved) /g112 /g110 Разлагаем все символы на базовые и модифицирующие. /g111 Находим все модифицирующие символы. /g112 Производим обратную композицию. В примере 4.15 демонстрируются два применения функции shave_marks . Пример 4.15. Два применения функции shave_marks из примера 4.14 >>> order = ' \"Herr Voß: • ½ cup of Œtker ™ caffè latte • bowl of a ça/g531.\"' >>> shave_marks(order)'\"Herr Voß: • ½ cup of Œtker ™ caffе latte • bowl of aсai. \"' /g110 >>> Greek = ' /g509/g529/g307/g547/g545/g544/g546, Zéfiro' >>> shave_marks(Greek)'/g509/g304/g307/g547/g545/g544/g546, Zefiro /g111 /g110 Заменены только буквы « è», «ç» и «ί». /g111 Заменены буквы « έ» и «é». Функция shave_marks работает правильно, но, быть может, чрезмерно усердст- вует. Часто диакритические знаки удаляются только для того, чтобы перевести текст из кодировки Latin в чистый ASCII, но shave_marks изменяет также и нела- тинские символы, например греческие буквы, которые – что с акцентами, что без – никогда не превратятся в ASCII. Поэтому имеет смысл проанализировать каждый базовый символ и удалять присоединенные знаки, только если он является буквой из набора символов Latin. Именно это делает функция из примера 4.16. Пример 4.16. Функция удаления модифицирующих знаков только для символов из набора Latin (предложения импорта опущены, поскольку это часть модуля sanitize.py из примера 4.14) def shave_marks_latin(txt): \"\"\"Удалить все диакритические знаки для базовых символов набора Latin\"\"\" norm_txt = unicodedata.normalize('NFD', txt) /g110 latin_base = False keepers = [] for c in norm_txt: if unicodedata.combining(c) and latin_base: /g111 continue # игнорировать диакритические знаки # для базовых символов набора Latin keepers .append(c) /g112 # если это не модифицирующий символ, значит новый базовый if not unicodedata.combining(c): /g113 latin_base = c in string.ascii_letters shaved = ''.join(keepers) return unicodedata.normalize('NFC', shaved) /g114\n--- Страница 153 ---\n153 Нормализация Unicode для правильного сравнения /g110 Разложить все символы на базовые и модифицирующие. /g111 Пропустить модифицирующие символы, если базовый из набора Latin. /g112 В противном случае сохранить текущий символ. /g113 Распознать новый базовый символ и определить, принадлежит ли он на-Распознать новый базовый символ и определить, принадлежит ли он на- бору Latin. /g114 Произвести обратную композицию. Еще более радикальный шаг – заменить часто встречающиеся в западных тек- стах символы (например, фигурные кавычки, длинные тире, маркеры списков и т. д.) эквивалентными символами из набора ASCII. Этим занимается функция asciize из примера 4.17. Пример 4.17. Преобразование некоторых западных типографических символов в ASCII (этот код также входит составной частью в модуль sanitize.py из примера 4.14) single_map = str.maketrans(\"\"\"‚ ƒ„†ˆ‹''\"\"•–– ˜›\"\"\", /g110 \"\"\"'f\"*^<''\"\"---~>\"\"\") multi_map = str.maketrans({ /g111 '€': '<euro>', ' …': ' ', 'Œ': 'OE', ' ™': '(TM)', 'œ': 'oe', '‰': '<per mille>', '‡': '**',}) multi_map.update(single_map) /g112 def dewinize(txt): \"\"\"Заменить символы Win1252 символами ASCII или их последовательностями\"\"\" return txt .translate(multi_map) /g113 def asciize(txt): no_marks = shave_marks_latin(dewinize(txt)) /g114 no_marks = no_marks.replace(' ß', 'ss') /g115 return unicodedata.normalize('NFKC', no_marks) /g116 /g110 Построить таблицу соответствия для замены одного символа другим. /g111 Построить таблицу соответствия для замены символа строкой символов. /g112 Объединить таблицы соответствия. /g113 Функция dewinize не изменяет символы из наборов ASCII и latin1 , а за- трагивает только добавления к latin1 , включенные Майкрософт в набор cp1252 . /g114 Применить dewinize и удалить диакритические знаки. /g115 Заменить эсцет на «ss» (мы не пользуемся сворачиванием регистра, потому что хотим сохранить исходный регистр).\n--- Страница 154 ---\n154 Глава 4. Текст и байты /g116 Применить нормализацию NFKC для композиции символов с их кодовыми позициями совместимости. В примере 4.18 показана функция asciize в действии. Пример 4.18. Два применения функции asciize из примера 4.17 >>> order = ' \"Herr Voß: • ½ cup of Œtker ™ caffè latte • bowl of a ça/g531.\"' >>> dewinize(order)'\"Herr Vo ß: - ½ cup of OEtker(TM) caff è latte - bowl of a ça/g531.\"' /g110 >>> asciize(order)'\"Herr Voss: - 1/2 cup of OEtker(TM) caffe latte - bowl of acai.\"' /g111 /g110 dewinize заменяет фигурные кавычки, маркеры списка и знак торговой марки ™. /g111 asciize вызывает dewinize , затем удаляет диакритические знаки и заме- няет 'ß'. В разных языках правила удаления диакритических знаков раз- личны. Например, немцы заменяют 'ü' на 'ue' . Наша функция asciize не настолько рафинирована, поэтому может статься, что к вашему языку она неприменима. Впрочем, для португальского работает отлично. Итак, функции из модуля sanitize.py не ограничиваются стандартной норма- лизацией, а подвергают текст серьезной хирургической операции, которая вполне может изменить его смысл. Лишь обладая знаниями о целевом языке, потенци-альных пользователях и способах использования преобразованного текста, можно решить, стоит ли заходить так далеко. А кому все это знать, как не вам? На этом мы подводим черту под обсуждением нормализации Unicode-текстов. Далее нам предстоит заняться проблемой сортировки. Сортировка Unicode-текстов Python сортирует последовательности любого типа, сравнивая элементы один за другим. Для строк это означает сравнение кодовых позиций. Увы, результат полу-чится никуда не годным, если только вы не ограничиваетесь символами ASCII. Рассмотрим сортировку списка фруктов, произрастающих в Бразилии. >>> fruits = ['caju', 'atemoia', 'caj á', 'açai', 'acerola'] >>> sorted(fruits)['acerola', 'atemoia', 'a çai', 'caju', 'caj á'] Правила сортировка зависят от локали, но в португальском и многих других языках, основанных на латинице, акценты и седили редко учитываются при со-\n--- Страница 155 ---\n155 Сортировка Unicode-текстов ртировке9. Поэтому «caj á» сортируется так же, как «caja» и, следовательно, пред- шествует «caju». Отсортированный список fruits должен выглядеть так: ['açai', 'acerola', 'atemoia', 'caj á', 'caju'] Стандартный способ сортировки не-ASCII текстов в Python – функция locale . strxfrm , которая, как написано в документации по модулю locale (http://bit. ly/1IqyCRf ), «преобразует строку, так чтобы ее можно было использовать в срав- нениях с учетом локали». Чтобы можно было воспользоваться функцией locale .strxfrm , необходимо сначала установить локаль, отвечающую нуждам приложения, и надеяться, что ОС ее поддерживает. В системах на базе GNU/Linux (Ubuntu 14.04) при вы-боре локали pt_BR нужный результат дает последовательность команд в при- мере 4.19. Пример 4.19. Использование функции locale.strxfrm в качестве ключа сортировки >>> import locale >>> locale.setlocale(locale.LC_COLLATE, 'pt_BR.UTF-8')'pt_BR.UTF-8'>>> fruits = ['caju', 'atemoia', 'caj á', 'açai', 'acerola'] >>> sorted_fruits = sorted(fruits, key=locale.strxfrm)>>> sorted_fruits['açai', 'acerola', 'atemoia', 'caj á', 'caju'] Таким образом, до использования locale.strxfrm в качестве значения парамет- ра key необходимо вызвать setlocale(LC_COLLATE, «ваша_локаль») . Однако есть несколько подводных камней. • Поскольку установка локали – глобальное действие, вызывать setlocale в библиотеке не рекомендуется. Приложение или каркас должны устано-вить локаль в начале работы процесса и затем уже не менять. • Локаль должна быть установлена в ОС, иначе вызов setlocale возбуждает исключение locale.Error: unsupported locale setting . • Необходимо точно знать, как пишется имя локали. В системах, произво- дных от Unix, имена неплохо стандартизованы и следуют соглашению 'код_языка.кодировка' , но в Windows синтаксис сложнее: Название языка- Диалект языка_Название региона.кодовая_страница . Отметим, что части «На- звание языка», «Диалект языка» и «Название региона» могут содержать пробелы, но каждая часть, кроме первой, должна начинаться специальным символом: дефисом, знаком подчеркивания и точкой. Все части, кроме на-звания языка, необязательны. Например, English_United States.850 озна- чает: Название языка – «English», регион – «United States», кодовая стра-ница – «850». Названия языков и регионов, которые Windows понимает, 9 Диакритические знаки оказывают влияние на сортировку в тех редких случаях, когда слова только ими и отличаются, в таком случае слово с диакритическим знаком предшествует слову без такового.\n--- Страница 156 ---\n156 Глава 4. Текст и байты перечислены в статье MSDN «Language Identifier Constants and Strings» (http://bit.ly/1IqyKAl ), а идентификаторы кодовых страниц – в статье «Code Page Identifiers» ( http://bit.ly/1IqyP79 )10. • Локаль должна быть правильно реализована производителем ОС. С Ubuntu 14.04 мне повезло, а с OS X (Mavericks 10.9) – нет. На двух разных компьютерах Mac обращение setlocale(LC_COLLATE, 'pt_BR .UTF-8') честно возвращало строку 'pt_BR .UTF-8' . Однако вызов sorted(fruits, key=locale . strxfrm) давал тот же неправильный результат, что и sorted(fruits) . Я про- бовал также локали fr_FR , es_ES и de_DE в OS X, но ни разу locale .strxfrm не отработала, как положено11. Таким образом, содержащееся в стандартной библиотеке решение для интер- национализированной сортировки работает, но лучше всего поддержано в GNU/Linux (или в Windows, если вы специалист по этой ОС). Но даже в этом случае оно зависит от настройки локали, что может вызвать неприятности при развер-тывании. По счастью, существует более простое решение: библиотека PyUCA, доступная на сайте PyPI . Сортировка с помощью алгоритма упорядочивания Unicode Джеймсу Тауберу (James Tauber), автору многих проектов для Django, должно быть, надоела эта путаница, и он написал модуль PyUCA ( https://pypi.python.org/ pypi/pyuca /), реализацию алгоритма упорядочивания Unicode (Unicode Collation Algorithm – UCA) на чистом Python. В примере 4.20 показано, как просто его ис-пользовать. Пример 4.20. Использование метода pyuca.Collator.sort_key >>> import pyuca >>> coll = pyuca.Collator()>>> fruits = ['caju', 'atemoia', 'caj á', 'açai', 'acerola'] >>> sorted_fruits = sorted(fruits, key=coll.sort_key)>>> sorted_fruits['açai', 'acerola', 'atemoia', 'caj á', 'caju'] Метод удобный и работает правильно. Я проверял его в системах GNU/ Linux, OS X и Windows. В настоящее время поддерживаются только версии Python 3.X. Библиотека PyUCA не обращает внимания на локаль. Если требуется изменить порядок сортировки, укажите путь к своей таблице упорядочения при 10 Спасибо Леонардо Рахаэлю, который не ограничился обязанностями технического рецензента, а нашел эти сведения, относящиеся к Windows, хотя сам работает с GNU/Linux. 11 Я не смог найти решение, но другие тоже жаловались на эту проблему. Алекс Мартелли, один из технических рецензентов, не сталкивался с ошибкой при использовании setlocale и locale.strxfrm на своем Mac с OS X 10.9. Короче говоря, как повезет.\n--- Страница 157 ---\n157 База данных Unicode вызове конструктора Collator() . Оригинальная библиотека пользуется файлом allkeys .txt (https://github.com/jtauber/pyuca ), включенным в дистрибутив. Это просто копия стандартной таблицы элементов упорядочения Unicode ( http://bit. ly/1IqAk54 ) из версии стандарта Unicode 6.3.0. Кстати говоря, эта таблица – лишь одна из многих составных частей базы дан- ных Unicode, о которой мы поговорим в следующем разделе. База данных Unicode В стандарте Unicode приведена целая база данных – в виде многочисленных структурированных текстовых файлов – которая включает не только сопоставле-ние имен символов кодовым позициям, но также метаданные отдельных символов и информацию о связях между ними. Например, в базе данных Unicode указа-но, имеет ли символ графическое начертание, является ли он буквой, десятичной цифрой или еще каким-то числовым символом. На основе этой информации ра-ботают методы isidentifier , isprintable , isdecimal и isnumeric класса str. Метод str.casefold также пользуется информацией из базы данных Unicode. В модуле unicodedata имеются функции, возвращающие метаданные симво- лов, например: официальное название символа по стандарту, является ли символ модифицирующим (например, диакритическим знаком, скажем, модифицирую-щей тильдой), числовое значение символа, предназначенное для людей (не ко-довая позиция). В примере 4.21 показано использование функций unicodedata. name() и unicodedata.numeric() , а также методов .isdecimal() и .isnumeric() класса str. Пример 4.21. Демонстрация работы с метаданными символов в базе данных Unicode (числовые маркеры описывают отдельные столбцы распечатки) import unicodedata import re re_digit = re.compile(r'\\d')sample = '1\\xbc\\xb2\\u0969\\u136b\\u216b\\u2466\\u2480\\u3285'for char in sample: print('U+%04x' % ord(char), /g110 char.center(6), /g111 're_dig' if re_digit.match(char) else '-', /g112 'isdig' if char.isdigit() else '-', /g113 'isnum' if char.isnumeric() else '-', /g114 format(unicodedata.numeric(char), '5.2f'), /g115 unicodedata.name(char), /g116 sep='\\t') /g110 Кодовая позиция в формате U+0000 . /g111 Символ, центрированный в поле длины 6.\n--- Страница 158 ---\n158 Глава 4. Текст и байты /g112 Вывести re_dig , если символ соответствует регулярному выражению r'\\d' . /g113 Вывести isdig , если char.isdigit() равно True . /g114 Вывести isnum , если char.isnumeric() равно True . /g115 Числовое значение в поле шириной 5 с двумя десятичными знаками после запятой. /g116 Имя символа Unicode. В результате выполнения этой программы получается распечатка, показанная на рис. 4.3. Рис. 4.3. Девять числовых символов и их метаданные; re_dig означает , что символ соответствует регулярному выражению r'\\d ' Шестая колонка на рис. 4.3 содержит результат вызова unicodedata. numeric(char) для символа. Эта функция говорит о том, что Unicode знает чис- ловые значения символов, представляющих числа. Так что если вы собираетесь написать программу для электронной таблицы, поддерживающей тамильские или римские цифры, вперед и с песней! Из рис. 4.3 видно, что регулярному выражению r'\\d' соответствует цифра «1» и цифра 3 письменности Деванагари, но не некоторые другие символы, которые функция isdigit считает цифрами. Модуль re знает о Unicode меньше, чем дол- жен бы. Новый модуль regex , включенный в библиотеку PyPI, имеет целью полно- библиотеку PyPI, имеет целью полно- у PyPI, имеет целью полно- стью заменить re и поддерживает Unicode лучше12. Мы вернемся к модулю re в следующем разделе. В этой главе мы пользовались несколькими функциями из модуля unicodedata , но на самом деле их гораздо больше. См. описание модуля unicodedata в докумен- тации по стандартной библиотеке ( https://docs.python.org/3/library/unicodedata. html ). Мы завершим сравнение типов str и bytes беглым знакомством с новой тен- денцией: двухрежимным API, предоставляющим функции, которые принимают в качестве аргументов str и bytes и работают по-разному в зависимости от типа. 12 Хотя цифры он распознавал ничуть не лучше модуля re.\n--- Страница 159 ---\n159 Двухрежимный API Двухрежимный API В стандартной библиотеке есть функции, которые принимают в качестве аргумен- библиотеке есть функции, которые принимают в качестве аргумен- е есть функции, которые принимают в качестве аргумен- тов значения типа str или bytes и ведут себя по-разному в зависимости от типа. Примеры имеются в модулях re и os. str и bytes в регулярных выражениях Если при построении регулярного выражения был задан аргумент типа bytes , то образцам вида \\d или \\w будут соответствовать только ASCII-символы. Наоборот, если был задан аргумент типа str, то этим образцам будут соответствовать цифры и буквы в смысле Unicode, а не только ASCII. В примере 4.22 и на рис. 4.4 показано сопоставление букв, ASCII-цифр, надстрочных индексов и тамильских цифр с образцами типа str и bytes . Пример 4.22. ramanujan.py: сравнение поведения простых регулярных выражений с аргументами типа str и bytes import re re_numbers_str = re.compile(r'\\d+') /g110 re_words_str = re.compile(r'\\w+')re_numbers_bytes = re.compile(rb'\\d+') /g111 re_words_bytes = re.compile(rb'\\w+') text_str = (\"Ramanujan saw \\u0be7\\u0bed\\u0be8\\u0bef\" /g112 \" as 1729 = 1 ³ + 12³ = 9³ + 10³.\") /g113 text_bytes = text_str.encode('utf_8') /g114 print('Text', repr(text_str), sep='\\n ') print('Numbers')print(' str :', re_numbers_str.findall(text_str)) /g115 print(' bytes:', re_numbers_bytes.findall(text_bytes)) /g116 print('Words')print(' str :', re_words_str.findall(text_str)) /g117 print(' bytes:', re_words_bytes.findall(text_bytes)) /g118 /g110 Первые два регулярных выражения типа str. /g111 Последние два регулярных выражения типа bytes . /g112 Текст Unicode, в котором производится поиск, содержит тамильские цифры числа 1729 (логическая строка продолжается до правой закрывающей скобки). /g113 Эта строка конкатенируется с предыдущей на этапе компиляции (см. раздел 2.4. «Конкатенация строковых литералов» ( http://bit.ly/1IqE2vH ) справочного руководства по языку Python). /g114 Для поиска с помощью регулярного выражения типа bytes необходима строка типа bytes .\n--- Страница 160 ---\n160 Глава 4. Текст и байты /g115 Образец r'\\d+' типа str сопоставляется с тамильскими цифрами и цифра- ми ASCII. /g116 Образец rb'\\d+' типа bytes сопоставляется только с цифрами ASCII. /g117 Образец r'\\w+' типа str сопоставляется с буквами, надстрочными индекса- ми, тамильскими цифрами и цифрами ASCII. /g118 Образец rb'\\w+' типа str сопоставляется только с ASCII-байтами букв и цифр. Рис. 4.4. Результат выполнения скрипта ramanujan.py из примера 4.22 Это тривиальный пример, призванный подчеркнуть одну мысль: в регулярных выражениях можно употреблять как str, так и bytes , но во втором случае байты, не принадлежащие диапазону ASCII, не считаются ни цифрами, ни символами, являющимися частью слова. Для регулярных выражений типа str существует флаг re.ASCII , при задании которого \\w, \\W, \\b, \\B, \\d, \\D, \\s и \\S производят сопоставление только с байтами ASCII. Подробнее см. документацию по модулю re (https://docs.python.org/3/ library/re.html ). Еще один важный двухрежимный модуль – это os. str и bytes в функциях из модуля os Ядро GNU/Linux ничего не знает о Unicode, поэтому на практике можно встретить имена файлов, представляющие собой последовательности байтов, которые не являются допустимыми ни в какой разумной кодировке и которые нельзя декодировать в тип str. Особенно чувствительны к этой проблеме файловые серверы, имеющие клиентов для разных ОС. Чтобы обойти эту проблему, все функции из модуля os, принимающие имена файлов или пути, могут работать с аргументами типа str или bytes . Если такая функция вызывается с аргументом типа str, то он автоматически преобразуется кодеком, определяемым функцией sys.getfilesystemencoding() , а ответ ОС декодируется тем же кодеком. Почти всегда это именно то, что нужно, и согласуется с сэндвичем Unicode. Но если приходится иметь дело с именами, которые так обрабатывать нельзя (или исправлять такие имена), то можно передавать функциям из модуля os аргу-\n--- Страница 161 ---\n161 Двухрежимный API менты типа bytes , и при этом они возвращают значения типа bytes . Это позволяет работать с любыми именами файлов и путями, сколько бы в них ни было кроко-зябров. См. пример 4.23. Пример 4.23. Функция listdir с аргументами типа str и bytes и ее результаты >>> os.listdir('.') # /g110 ['abc.txt', 'digits-of- /g89.txt'] >>> os.listdir(b'.') # /g111 [b'abc.txt', b'digits-of-\\xcf\\x80.txt'] /g110 Второе имя файла равно «digits-of- π.txt» (с греческой буквой «пи»). /g111 Если аргумент имеет типа bytes , то listdir возвращает имена файлов как байты: b'\\xcf \\x80' – представление греческой буквы «пи» в кодировке UTF-8. Чтобы помочь обрабатывать последовательности типа str или bytes , состав- ляющие имена файлов или пути, модуль os предоставляет специальные функции кодирования и декодирования. fsencode(filename) Преобразует filename (может иметь тип str или bytes ) в bytes с помо- щью кодека, возвращаемого функцией sys.getfilesystemencoding() , если filename имеет тип str, в противном случае возвращает аргумент filename (типа bytes ) без изменения. fsdecode(filename) Преобразует filename (может иметь тип str или bytes ) в str с помощью ко- дека, возвращаемого функцией sys.getfilesystemencoding() , если filename имеет тип bytes , в противном случае возвращает аргумент filename (типа str) без изменения. На платформах, ведущих происхождение от Unix, эти функции пользуются об- работчиком ошибок surrogateescape (см. врезку ниже), чтобы неожиданные бай- ты не приводили к аварийному завершению. В Windows используется обработчик ошибок strict . Использование surrogateescape для борьбы с крокозябрами На случай встречи неожиданных байтов или неизвестной кодировки в версии Python 3.1 появился обработчик ошибок кодека surrogateescape , описанный в документе «PEP 383 – Non-decodable Bytes in System Character Interfaces» ( https://www.python.org/dev/peps /pep-0383/ ). Идея заключается в том, чтобы заменить байты, которые невозможно декодировать, кодовой позицией из диапазона от U+DC00 до U+DCFF ,\n--- Страница 162 ---\n162 Глава 4. Текст и байты находящегося в так называемой нижней части суррогатных пар – про- странстве кодов, которым не сопоставлены символы, зарезервирован-ном для внутренних нужд приложений. При кодировании такие пози-ции преобразуются обратно в значения байтов, которые были заменены. См. пример 4.24. Пример 4.24. Использование обработчика ошибок surrogatescape >>> os .listdir('.') /g110 ['abc.txt', 'digits-of- /g89.txt'] >>> os.listdir(b'.') /g111 [b'abc.txt', b'digits-of-\\xcf\\x80.txt']>>> pi_name_bytes = os.listdir(b'.')[1] /g112 >>> pi_name_str = pi_name_bytes.decode('ascii', 'surrogateescape') /g113 >>> pi_name_str /g114 'digits-of-\\udccf\\udc80.txt'>>> pi_name_str.encode('ascii', 'surrogateescape') /g115 b'digits -of-\\xcf \\x80.txt' /g110 Вывести список файлов в каталоге, который содержит файл с именем, включающим символы не из набора ASCII. /g111 Сделаем вид, что не знаем кодировку и получим имена файлов в виде bytes . /g112 pi_names_bytes – имя файла, содержащее символ «пи». /g113 Декодируем его в str, применяя кодек 'ascii' с обработчиком ошибок 'surrogateescape' . /g114 Любой символ, не принадлежащий ASCII, заменяется суррогатной кодовой позицией: '\\xcf\\x80' преобразуется в '\\udccf\\udc80' . /g115 Кодируем обратно в байты ASCII: все суррогатные кодовые позиции заменяются исходными байтами. На этом заканчивается рассказ о типах str и bytes . Если вы вытерпели до кон- ца, примите поздравления! Резюме Мы начали эту главы с опровержения утверждения 1 символ == 1 байт . В мире, перешедшем на Unicode (а 80 % сайтов уже пользуются кодировкой UTF-8), не-обходимо разделять понятия текстовой строки и двоичной последовательности, которой такая строка представлена в файле. И Python 3 поддерживает такое раз-деление. После краткого обзора двоичных типов последовательностей – bytes , bytearray и memoryview – мы перешли к кодированию и декодированию, привели репрезен- тативную выборку кодеков и объяснили, как предотвратить или обработать пе-\n--- Страница 163 ---\n163 Резюме чально известные ошибки UnicodeEncodeError , UnicodeDecodeError и SyntaxError , вызванные неправильным кодированием исходного файла Python. Продолжая тему исходного кода, я изложил свою точку зрения на исполь- зование идентификаторов, содержащих не-ASCII символы: если программисты, сопровождающие программу, хотят, чтобы ее код был написан в манере, близкой к естественному языку, в котором встречаются не-ASCII символы, то иденти-фикаторы не должны выглядеть белыми воронами – если только не требуется запускать программу и в среде Python 2. Но если проект нацелен на привлечение соавторов со всего мира, то идентификаторы должны быть английскими слова-ми, и тогда набора символов ASCII вполне достаточно. Далее мы рассмотрели теорию и практику распознавания кодировки в отсут- ствие метаданных; теоретически это невозможно, но на практике пакет Chardet неплохо справляется с этой задачей для многих популярных кодировок. Мы ска-зали о том, что маркеры порядка байтов – единственная информация о кодировке, присутствующая в файлах с кодировкой UTF-16 и UTF-32, иногда также UTF-8. В следующем разделе мы продемонстрировали открытие текстовых файлов. В этой несложной задаче есть один подвох: именованный аргумент encoding= нео- бязателен, хотя должен бы быть таковым. Если кодировка не задана, то получается программа, которая генерирует «простой текст», не совместимый с разными плат-формами из-за несовпадения кодировок по умолчанию. Затем мы рассказали о раз-личных параметрах, которые интерпретатор Python использует в качестве источ-ников умолчаний: locale.getpreferredencoding() , sys.getfilesystemencoding() , sys.getdefaultencoding() , а также о кодировках стандартных потоков ввода-вы- вода (например, sys.stdout.encoding ). Печальным фактом для пользователей Windows является то, что эти параметры зачастую имеют разные значения на од-ной и той же машине, причем эти значения несовместимы между собой. Напротив, пользователи GNU/Linux и OS X обитают в счастливом мире, где практически повсюду по умолчанию используется кодировка UTF-8 . Сравнение текстов оказывается на удивление сложным делом, потому что в Unicode некоторые символы можно представить несколькими способами, поэто-му перед сравнением необходимо выполнить нормализацию. Мы не только объ-яснили, что такое нормализация и сворачивание регистра, но и привели несколько служебных функций, которые вы можете приспособить к своим нуждам, и сре-ди них функцию, которая полностью удаляет все акценты. Далее мы видели, как правильно сортировать текст Unicode с применением стандартного модуля locale (у которого есть некоторые недостатки) или альтернативного ему внешнего паке-та PyUCA, не зависящего от головоломных настроек локали. Наконец, мы познакомились с базой данных Unicode (источником метадан- ных о каждом символе) и завершили обсуждение рассмотрением двухрежимных API (реализованных, в частности, в модулях re и os, некоторые функции которых можно вызывать с аргументами типа str или bytes , что приводит к различным, но осмысленным результатам).\n--- Страница 164 ---\n164 Глава 4. Текст и байты Дополнительная литература Хочу отметить выдающееся выступление Нэда Бэтчелдера на конференции PyCon US 2012 года «Pragmatic Unicode – or – How Do I Stop the Pain?» ( http:// nedbatchelder.com/text/unipain.html ). Нэд оказался настолько профессионален, что выложил полную запись доклада со всеми слайдами и видео. На конферен-ции PyCon 2014 Эстер Нэм и Трэвис Фишер выступили с великолепным до-кладом «Character encoding and Unicode in Python: How to ( ›˃˘˃)›ớ\u0001ᵲᴸᵲ\u0001 with dignity» (слайды имеются по адресу http://bit.ly/1JzF1MY , видео – по адресу http://bit.ly/1JzF37P ), из которого я взял эпиграф к данной главе «Человек работа- ет с текстом, компьютер – с байтами». Леннарт Регебро – один из технических ре-цензентов книги – представил свою «полезную мысленную модель Unicode» в ко-роткой статье «Unconfusing Unicode: What Is Unicode?» ( https://regebro.wordpress. com/2011/03/23/unconfusing-unicode-what-is-unicode/ ). Unicode – сложный стан- дарт, поэтому мысленная модель Леннарта – действительно полезная отправная точка. В официальном документе «Unicode HOWTO» ( https://docs.python.org/3/ howto/unicode.html ) в документации по Python эта тема рассматривается с разных точек зрения: от удачного исторического введения до деталей синтаксиса, кодеков, регулярных выражений, имен файлов и рекомендаций по написанию кода ввода-вывода с учетом Unicode (сэндвич Unicode). В каждом разделе имеются ссылки на дополнительную информацию. В главе 4 «Строки» ( http://www.diveintopython3. net/strings.html ) замечательной книги Mark Pilgrim «Dive into Python 3» ( http:// www.diveintopython3.net ) также имеется отличное введение в поддержку Unicode в Python 3. В главе 15 той же книги ( http://bit.ly/1IqJ63d ) описан перенос библи- отеки Chardet с Python 2 на Python 3 – ценный пример, учитывая, что переход от старого типа str к новому типу bytes стал причиной большинства неприятностей, связанных с миграцией, а это – как раз основная тема библиотеки, призванной распознавать кодировки. Для тех, кто знает Python 2, но незнаком с Python 3, в статье Гвидо ван Россу- ма «What's New in Python 3.0» ( http://bit.ly/1IqJ8YH ) перечислено 15 основных отличий с множеством ссылок. Гвидо начинает с прямого заявления: «Все, что, как вам казалось, вы знали о двоичных данных и Unicode, изменилось». Армен Ронашер (Armin Ronacher) опубликовал в своем блоге статью «The Updated Guide to Unicode on Python» ( http://bit.ly/1IqJcrD ), в которой акцентирует внимание на некоторых подводных камнях Unicode в Python 3 (Армен – не большой поклон-ник Python 3). В главе 2 книги David Beazley, Brian K. Jones «Python Cookbook», издание 3 (O'Reilly), приведено несколько рецептов, относящихся к нормализации в Unicode, очистке текста и выполнению текстовых операций над последовательно-стями байтов. В главе 5, посвященной файлам и вводу-выводу, имеется рецепт 5.17 «Запись байтов в текстовый файл», где показано, что за любым текстовым файлом стоит двоичный поток, к которому при желании можно получить доступ напря-\n--- Страница 165 ---\n165 Дополнительная литература мую. Далее в рецепте 6.11 «Чтение и запись двоичных массивов структур» показа- но применение модуля struct . В блоге Ника Кофлина (Nick Coghlan) «Python Notes» есть две статьи, имею- щие непосредственное отношение к этой главе: «Python 3 and ASCII Compatible Binary Protocols» ( http://bit.ly/1dYuNJa ) и «Processing T ext Files in Python 3» (http://bit.ly/1dYuRbS ). Настоятельно рекомендую. Говоря о двоичных последовательностях, мы имеем в виду, в частности, новые конструкторы и методы в версии Python 3.5, где, кстати, один из ныне существую-щих конструкторов будет объявлен нерекомендуемым (см. документ «PEP 467 – Minor API improvements for binary sequences» по адресу https://www.python.org/ dev/peps/pep-0467/ ). В Python 3.5, скорее всего, будет реализовано и предложение, описанное в документе «PEP 461 – Adding % formatting to bytes and bytearray» по адресу https://www.python.org/dev/peps/pep-0461/ ). Список кодировок, поддерживаемых Python, приведен в разделе «Стандарт- ные кодировки» ( https://docs.python.org/3/library/codecs.html#standard-encodings ) документации по модулю codecs . О том, как получить доступ к этому списку из программы, см. скрипт /T ools/unicode/listcodecs.py (http://bit.ly/1IqKrqD ), входя- щий в состав дистрибутива CPython. В статьях Мартина Фаассена (Martijn Faassen) «Changing the Python Default Encoding Considered Harmful» ( http://bit.ly/1IqKu5I ) и Тарека Зиада (Tarek Ziade) «sys.setdefaultencoding Is Evil» ( http://blog.ziade.org/2008/01/08/ syssetdefaultencoding-is-evil/ ) объясняется, почему никогда не следует изменять кодировку по умолчанию, полученную от функции sys .getdefaultencoding() , даже если вы разузнали, как это сделать. Книги Jukka K. Korpela «Unicode Explained» (O'Reilly) и Richard Gillam «Unicode Demystified» ( http://bit.ly/1dYveDl ) (Addison-W esley) не связаны с Python, но очень помогли мне в изучении концепций Unicode. Книга Викто-ра Стиннера (Victor Stinner) «Programming with Unicode» ( http://unicodebook. readthedocs.org/index.html ) – бесплатное произведение, опубликованное самим автором (распространяется по лицензии Creative Commons BY-SA); в ней рассма-тривается как сам стандарт Unicode, так и инструментальные средства и API для основных операционных систем и нескольких языков программирования, вклю-чая Python. На страницах сайта W3C «Case Folding: An Introduction» ( http://www. w3.org/International/wiki/Case_folding ) и «Character Model for the W orld Wide W eb: String Matching and Searching» ( http://www.w3.org/TR/charmod-norm/ ) рассматривается концепция нормализации; первый документ написан в форме введения для начинающих, а второй – рабочий проект, изложенный сухим язы-ком стандарта – в том же стиле, что «Unicode Standard Annex #15 – Unicode Normalization Forms» ( http://unicode.org/reports/tr15/ ). Документ «Frequently Asked Questions / Normalization» ( http://www.unicode.org/faq/normalization.html ) на сайте Unicode.org ( http://www.unicode.org/ ) проще для восприятия, равно как и NFC F AQ ( http://www.macchiato.com/unicode/nfc-faq ) Марка Дэвиса – автора\n--- Страница 166 ---\n166 Глава 4. Текст и байты нескольких алгоритмов Unicode и президента консорциума Unicode Consortium на момент работы над этой книгой. Поговорим Что такое «простой текст»? Для любого, кто в повседневной работе имеет дело с неанглоязычны- ми текстами, «простой текст» не ассоциируется с «ASCII». В глоссарии Unicode ( http://www.unicode.org/glossary/#plain_text ) простой текст определяется так: Закодированный для компьютера текст, который включает только последовательность кодовых позиций из некоторого стандарта – без ка-кой-либо форматной или структурной информации. Начинается это определение очень хорошо, но с частью после тире я не согласен. HTML – прекрасный пример простого текста, содержащего форматную и структурную информацию. Но это все же простой текст, по-тому что каждый байт в таком файле представляет некий текстовый сим-вол, обычно в кодировке UTF-8. В файле нет байтов, несущих нетексто-вую нагрузку, как, скажем, в файлах типа PNG или XLS, где большинство байтов – это упакованные двоичные значения, представляющие либо цвета в формате RGB, либо числа с плавающей точкой. В простом тексте число было бы представлено в виде последовательности цифр. Я пишу эту книгу в формате простого текста, который, по иронии судьбы, называется AsciiDoc ( http://www.methods.co.nz/asciidoc/ ) и яв- ляется частью великолепного инструментария, входящего в комплект платформы книгоиздания Atlas компании O'Reilly ( https://atlas.oreilly. com/ ). Исходные файлы в формате AsciiDoc – это простой текст, но в ко- дировке UTF-8, а не ASCII. В противном случае писать эту главу было бы крайне затруднительно. Несмотря на свое название, формат – отлич-ная вещь. Вселенная Unicode постоянно расширяется и на ее границах не всег- да есть подходящие инструменты. Именно поэтому я был вынужден ис-пользовать изображения на рисунках 4.1, 4.3 и 4.4: не все нужные мне символы присутствовали в шрифтах, которыми набрана эта книга. С другой стороны, на терминалах в Ubuntu 14.04 и OS X 10.9 они прекрас-но отображаются – включая и японские символы, составляющие слово «mojibake»: 㠖ⷦ▥ሴ . Загадки Unicode Неточные выражения типа «часто», «в большинстве случаев» или «обычно» встречаются сплошь и рядом, когда я пишу о нормализации в\n--- Страница 167 ---\n167 Поговорим Unicode. Я сожалею об отсутствии более определенных рекомендаций, но исключений из правил Unicode так много, что утверждать что-то с полной уверенностью трудно. Например, символ μ (микро) считается «символом совместимости», а /g58 (ом) и Å (ангстрем) – нет. Это различие имеет практические по- следствия: алгоритм нормализации NFC – рекомендуемый для сравне-ния текстов – заменяет символ /g58 (ом) символом /g58 (заглавная грече- ская буква омега), а символ Å (ангстрем) – символом Å (заглавная A с кружочком). Но «символ совместимости» μ (знак микро) заменяется визуально идентичным ему символом μ (строчная греческая буква мю) только в более строгих формах нормализации NFKC и NFKD, которые влекут за собой потерю информации. Я понимаю, что символ μ (знак микро) включен в Unicode, потому что он имеется в наборе символов latin1, и замена его греческой буквой мю нарушила бы обратимость преобразования. В конце концов, именно поэтому знак микро и сделан «символом совместимости». Но если сим-волы ома и ангстрема включены в Unicode не по соображениям совме-стимости, то зачем было вообще включать их? Ведь есть же уже кодовые позиции GREEK CAPITAL LETTER OMEGA и LATIN CAPITAL LETTER A WITH RING ABOVE , которые выглядят точно так же и подставляются ал- горитмом нормализации NFC. Поди угадай. После многих часов изучения Unicode я пришел к выводу: этот стан- дарт неимоверно сложен и полон особых случаев, что отражает чудесное многообразие естественных языков и политику, принятую при разра-ботке отраслевых стандартов. Как объекты str представлены в памяти? В официальном руководстве по Python старательно обходится во- прос о том, как кодовые позиции строки str хранятся в памяти. В кон- це концов, это действительно деталь реализации. Теоретически это не имеет значения: каким бы ни было внутреннее представление, каждая строка при выводе должна перекодироваться в объект типа bytes . В Python 3 объект str хранится в памяти как последовательность ко- довых позиций с фиксированным количеством байтов на одну позицию, чтобы обеспечить прямой доступ к любому символу или срезу . До версии Python 3.3 CPython можно было откомпилировать, так чтобы под кодовую позицию в памяти отводилось 16 или 32 бит; пер-вый способ назывался «узкой сборкой», второй – «широкой сборкой». Чтобы узнать, как откомпилирована ваша версия, нужно проверить па-раметр sys.maxunicode : 65535 означает «узкую сборку», которая не спо- собна без вмешательства программиста работать с кодовыми позиция-ми, большими U+FFFF . У «широкой сборки» такого ограничения нет,\n--- Страница 168 ---\n168 Глава 4. Текст и байты но она потребляет много памяти: 4 байта на символ, хотя большинство кодовых позиций для китайских иероглифов умещается в 2 байта. Ни тот, ни другой вариант не идеален; какой выбрать, зависит от конкрет-ных потребностей. Начиная с версии Python 3.3, интерпретатор, создавая объект str, проверяет, из каких символов он состоит, и выбирает наиболее эконо-мичное размещение в памяти данного объекта. Если имеются только символы из диапазона latin1 , то каждая кодовая позиция str будет представлена всего одним байтом. В противном случае для представле-ния кодовой позиции может понадобиться 2 или 4 байта – все зависит от str. Это упрощенное изложение, детали см. в документе «PEP 393 – Flexible String Representation» ( https://www.python.org/dev/peps/pep- 0393/ ). Гибкое представление строки похоже на представление типа int в Python 3: если целое число умещается в машинном слове, то оно и хранится как одно машинное слово. В противном случае интерпрета-тор переходит на представление переменной длины, как для типа long в Python 2. Приятно видеть, как распространяются хорошие идеи.\n--- Страница 169 ---\nЧАСТЬ III Функции как объекты",
      "debug": {
        "start_page": 126,
        "end_page": 169
      }
    },
    {
      "name": "Глава 5. Полноправные функции 170",
      "content": "--- Страница 170 --- (продолжение)\nГлава 5. Полноправные функции Я никогда не считал, что на Python оказали заметное влияние функцио-нальные языки, что бы кто об этом ни говорил или ни думал. Я был значи-тельно лучше знаком с императивными языками типа C и Algol 68 и, хотя сделал функции полноправными объектами, никогда не рассматривал Python как язык функционального программирования 1. – Гвидо ван Россум, пожизненный великодушный диктатор Python Функции в Python – полноправные объекты. Теоретики языков программирова-ния определяют «полноправный объект» как элемент программы, обладающий следующими свойствами: • может быть создан во время выполнения; • может быть присвоен переменной или полю структуры данных;• может быть передан функции в качестве аргумента;• может быть возвращен функцией в качестве результата. Целые числа, строки и словари – все это тоже примеры полноправных объек- тов в Python, так что ничего необычного тут нет. Но если вы пришли в Python из языка, в котором функции не являются полноправными гражданами, то из этой главы, да и всей части III вы узнаете о последствиях и практических приложениях обращения с функциями как с объектами. Термин «полноправные функции» широко используется как со- кращение фразы «функции как полноправные объекты». Он не со-всем точен, потому что наводит на мысль о некоей «элите» среди функций. В Python все функции полноправные. 1 «Origins of Python's Functional Features» ( http://bit.ly/1FHfhIo ), из блога Гвидо «История Python».\nГлава 5. Полноправные функции Я никогда не считал, что на Python оказали заметное влияние функцио-нальные языки, что бы кто об этом ни говорил или ни думал. Я был значи-тельно лучше знаком с императивными языками типа C и Algol 68 и, хотя сделал функции полноправными объектами, никогда не рассматривал Python как язык функционального программирования 1. – Гвидо ван Россум, пожизненный великодушный диктатор Python Функции в Python – полноправные объекты. Теоретики языков программирова-ния определяют «полноправный объект» как элемент программы, обладающий следующими свойствами: • может быть создан во время выполнения; • может быть присвоен переменной или полю структуры данных;• может быть передан функции в качестве аргумента;• может быть возвращен функцией в качестве результата. Целые числа, строки и словари – все это тоже примеры полноправных объек- тов в Python, так что ничего необычного тут нет. Но если вы пришли в Python из языка, в котором функции не являются полноправными гражданами, то из этой главы, да и всей части III вы узнаете о последствиях и практических приложениях обращения с функциями как с объектами. Термин «полноправные функции» широко используется как со- кращение фразы «функции как полноправные объекты». Он не со-всем точен, потому что наводит на мысль о некоей «элите» среди функций. В Python все функции полноправные. 1 «Origins of Python's Functional Features» ( http://bit.ly/1FHfhIo ), из блога Гвидо «История Python».\n--- Страница 171 ---\n171 Обращение с функцией как с объектом Обращение с функцией как с объектом В сеансе оболочки в примере 5.1 показано, что функции в Python – объекты. Мы создаем функцию, вызываем ее, читаем ее атрибут __doc__ и проверяем, что сам объект функции является экземпляром класса function . Пример 5.1. Создаем и тестируем функцию, затем читаем ее атрибут __doc__ и опрашиваем тип >>> def factorial(n): /g110 '''returns n!''' return 1 if n < 2 else n * factorial(n-1) >>> factorial(42)1405006117752879898543142606244511569936384000000000>>> factorial.__doc__ /g111 'returns n!'>>> type(factorial) /g112 <class 'function'> /g110 Это сеанс оболочки, т. е. мы создаем функцию «во время выполнения». /g111 __doc__ – один из атрибутов объектов-функций. /g112 factorial – экземпляр класса function . Атрибут __doc__ служит для генерации текста справки по объекту. В интерак- тивной оболочке Python команда help(factorial) выводит информацию, показан- ную на рис. 5.1. Рис. 5.1. Справка по функции factorial. Текст берется из атрибута __doc__ объекта-функции Из примера 5.2 видна «полноправность» объекта-функции. Мы можем присво- ить функцию переменной fact и вызвать ее по имени. Можем передать функцию factorial в виде аргумента функции map. Функция map возвращает итерируемый объект, каждый элемент которого – результат применения первого аргумента (функции) к последовательным элементам второго аргумента (итерируемого объ-екта), в данном случае range(10) .\n--- Страница 172 ---\n172 Глава 5. Полноправные функции Пример 5.2. Использование функции под другим именем и передача функции в качестве аргумента >>> fact = factorial >>> fact<function factorial at 0x >>>> fact(5)120>>> map(factorial, range(11))<map object at 0x >>>> list(map(fact, range(11)))[1, 1, 2, 6, 24, 120, 720, 5040, 40320, 362880, 3628800] Полноправность функций открывает возможности для программирования в функциональном стиле. Один из отличительных признаков функционального программирования – использование функций высшего порядка. Функции высшего порядка Функцией высшего порядка называется функция, которая принимает функцию в качестве аргумента или возвращает в качестве значения. Примером может слу-жить функция map из примера 5.2. Другой пример – встроенная функция sorted : ее необязательный аргумент key позволяет задать функцию, которая применяется к каждому сортируемому элементу, как было показано в разделе «Метод list.sort и встроенная функция sorted» на стр. 68. Например, чтобы отсортировать список слов по длине, достаточно передать функцию len в качестве аргумента key, как в примере 5.3. Пример 5.3. Сортировка списка слов по длине >>> fruits = ['strawberry', 'fig', 'apple', 'cherry', 'raspberry', 'banana'] >>> sorted(fruits, key=len)['fig', 'apple', 'cherry', 'banana', 'raspberry', 'strawberry']>>> В роли ключа может выступать любая функция с одним аргументом. Напри- мер, для создания словаря рифм полезно отсортировать слова в обратном поряд-ке букв. Обратите внимание, что в примере 5.4 сами слова не изменяются, но по-скольку они отсортированы в обратном порядке букв, то все ягоды (berry) оказа-лись рядом. Пример 5.4. Сортировка списка слов в обратном порядке букв >>> def reverse(word): return word[::-1] >>> reverse('testing')'gnitset' >>> sorted(fruits, key=reverse)\n--- Страница 173 ---\n173 Функции высшего порядка ['banana', 'apple', 'fig', 'raspberry', 'strawberry', 'cherry'] >>> В функциональной парадигме программирования хорошо известны следую- щие функции высшего порядка: map, filter , reduce , apply . Функция apply была объявлена нерекомендуемой в версии Python 2.3 и исключена из Python 3, по-тому что в ней отпала необходимость. Чтобы вызвать функцию с динамическим набором аргументов, достаточно написать fn(*args, **keywords) вместо apply(fn, args, kwargs) . Функции map, filter и reduce пока никуда не делись, но, как показано в следу- ющем разделе, в большинстве случаев им есть лучшие альтернативы. Современные альтернативы функциям map, filter и reduce В функциональных языках программирования обычно имеются функции выс- шего порядка map, filter и reduce (иногда под другими именами). Функции map и filter по-прежнему встроены в Python 3, но с появлением списковых включений и генераторных выражений потеряли былую значимость. Как списковое включе-ние, так и генераторное выражение могут сделать то же, что комбинация map и filter , только код будет выглядеть понятнее. Взгляните на пример 5.5. Пример 5.5. Списки факториалов, порожденные функциями map и filter , а также альтернатива в виде спискового включения >>> list(map(fact, range(6))) /g110 [1, 1, 2, 6, 24, 120]>>> [fact(n) for n in range(6)] /g111 [1, 1, 2, 6, 24, 120]>>> list(map(factorial, filter(lambda n: n % 2, range(6)))) /g112 [1, 6, 120]>>> [factorial(n) for n in range(6) if n % 2] /g113 [1, 6, 120]>>> /g110 Строим список факториалов от 0! до 5!. /g111 Та же операция с помощью спискового включения. /g112 Список факториалов нечетных чисел до 5!, построенный с использованием map и filter . /g113 Списковое включение делает то же самое, заменяя map и filter и делая не- нужным лямбда-выражение. В Python 3 функции map и filter возвращают генераторы – вариант итерато- ра – поэтому безо всяких проблем могут быть заменены генераторным выражени-ем (в Python 2 эти функции возвращали списки, поэтому их ближайшим аналогом было списковое включение).\n--- Страница 174 ---\n174 Глава 5. Полноправные функции Функция reduce , которая в Python 3 была встроенной, теперь «понижена в зва- нии» и перенесена в модуль functools . В той ситуации, где она чаще всего применя- лась, а именно для суммирования, удобнее встроенная функция sum, включенная в версию Python 2.3 в 2003 году. Она дает большой выигрыш в плане удобочитаемо-сти и производительности (см. пример 5.6). Пример 5.6. Суммирование целых чисел до 99 с помощью reduce и sum >>> from functools import reduce /g110 >>> from operator import add /g111 >>> reduce(add, range(100)) /g112 4950>>> sum(range(100)) /g113 4950>>> /g110 Начиная с версии Python 3.0, функция reduce больше не является встроен- ной. /g111 Импортируем модуль add, чтобы не создавать функцию для сложения двух чисел. /g112 Вычисляем сумму целых чисел, не больших 99. /g113 Решение той же задачи с помощью функции sum; импортировать функцию сложения больше не нужно. Общая идея функций sum и reduce – применить некую операцию к каждому элементу последовательности с аккумулированием результатов и тем самым све-сти (редуцировать) последовательность значений к одному . Редуцирующими являются также встроенные функции all и any: all(iterable) Возвращает True , если каждый элемент объекта iterable «похож на истин- ный»; all([]) возвращает True . any(iterable) Возвращает True , если хотя бы один элемент объекта iterable «похож на истинный»; all([]) возвращает False . Более полное объяснение reduce я приведу в разделе «V ector, попытка № 4: хэ- ширование и ускорение оператора ==» на стр. 319, где будет подходящий контекст для использования этой функции. А в разделе «Функции редуцирования итери-руемого объекта» на стр. 466, где основной темой обсуждения будут итерируемые объекты, мы подведем итоги. Иногда для передачи функциям высшего порядка удобно создать небольшую одноразовую функцию. Для этого и предназначены анонимные функции.\n--- Страница 175 ---\n175 Анонимные функции Анонимные функции Ключевое слово lambda служит для создания анонимной функции внутри выра- жения Python. Однако в силу простоты синтаксиса тело лямбда-функции может быть только чистым выражением. Иными словами, в теле lambda нельзя производить присваи- вание или выполнять другие предложения Python, например while , try и т. д. Особенно удобны анонимные функции в списке аргументов. Так, в примере 5.7 код построения словаря рифм из примера 5.4 переписан с помощью lambda , без определения функции reverse . Пример 5.7. Сортировка списка слов в обратном порядке букв с помощью lambda >>> fruits = ['strawberry', 'fig', 'apple', 'cherry', 'raspberry', 'banana'] >>> sorted(fruits, key=lambda word: word[::-1])['banana', 'apple', 'fig', 'raspberry', 'strawberry', 'cherry']>>> Помимо задания аргументов функций высшего порядка, анонимные функции редко используются в Python. Из-за синтаксических ограничений нетривиальные лямбда-выражения либо не работают, либо оказываются малопонятны. Рецепт рефакторинга лямбда-выражений Лундха Если вы не можете понять какой-то фрагмент кода из-за использова- ния в нем lambda , последуйте совету Фредрика Лундха: 1. Напишите комментарий, объясняющий, что делает lambda . 2. Внимательно изучите этот комментарий и придумайте имя, в ко- тором заключалась бы суть изложенного в нем. 3. Преобразуйте lambda в предложение def, указав придуманное вами имя. 4. У далите комментарий. Эти шаги взяты из документа «Functional Programming HOWTO» (http://docs.python.org/3/howto/functional.html ), который настоятельно рекомендуется прочитать. Конструкция lambda – не более чем синтаксическая глазурь: лямбда-выражение создает объект-функцию точно так же, как предложение def. Это лишь один из нескольких видов вызываемых объектов в Python. В следующем разделе рассмотрены все.\n--- Страница 176 ---\n176 Глава 5. Полноправные функции Семь видов вызываемых объектов Оператор вызова () можно применять не только к функциям, определенным пользователями. Чтобы понять, является ли объект вызываемым, воспользуйтесь встроенной функцией callable() . В документации по модели данных Python пе- речислено семь вызываемых типов. Пользовательские функции Создаются с помощью предложения def или лямбда-выражений. Встроенные функции Функции, написанные на языке C (в случае CPython), например len или time.strftime . Встроенные методы Методы, написанные на C, например dict.get . Методы Функции, определенные в теле класса. Классы При вызове класс выполняет свой метод __new__ , чтобы создать экземпляр, затем вызывает метод __init__ для его инициализации и, наконец, возвра- щает экземпляр вызывающей программе. Поскольку в Python нет опера-тора new, вызов класса аналогичен вызову функции. (Обычно при вызове класса создается экземпляр именно этого класса, но такое поведение можно изменить, переопределив метод __new__ . Соответствующий пример будет приведен в разделе «Гибкое создание объектов с помощью метода __new__ » на стр. 622.) Экземпляры классов Если в классе определен метод __call__ , то его экземпляры можно вы- зывать, как функции. См. раздел «Пользовательские вызываемые типы» ниже. Г енераторные функции Функции или методы, в которых используется ключевое слово yield . При вызове генераторная функция возвращает объект-генератор. Генераторные функции во многих отношениях отличаются от других вызыва- емых объектов. Им посвящена глава 14. Они также могут вызываться как сопро-граммы – этот вопрос рассматривается в главе 16. Учитывая разнообразие вызываемых типов в Python, самый без- опасный способ узнать, является ли объект вызываемым, – вос-пользоваться встроенной функцией callable() :\n--- Страница 177 ---\n177 Пользовательские вызываемые типы >>> abs, str, 13 (<built-in function abs>, <class 'str'>, 13)>>> [callable(obj) for obj in (abs, str, 13)][True, True, False] Теперь займемся созданием экземпляров классов, ведущих себя как вызывае- мые объекты. Пользовательские вызываемые типы Мало того что в Python функции являются настоящими объектами, так еще и лю-бой объект можно заставить вести себя как функция. Для этого нужно лишь реа-лизовать метод экземпляра __call__ . В примере 5.8 реализован класс BingoCage . Экземпляр этого класса строится из любого итерируемого объекта и хранит внутри себя список элементов в случай-ном порядке. При вызове экземпляра из списка удаляется один элемент. Пример 5.8. bingocall.py: экземпляр BingoCage делает всего одну вещь: выбирает элементы из перетасованного списка import random class BingoCage: def __init__(self, items): self._items = list(items) /g110 random.shuffle(self._items) /g111 def pick(self): /g112 try: return self._items.pop() except IndexError: raise LookupError('pick from empty BingoCage') /g113 def __call__(self): /g114 return self.pick() /g110 Метод __init__ принимает произвольный итерируемый объект; создание локальной копии предотвращает изменение списка, переданного в качестве аргумента. /g111 Метод shuffle гарантированно работает, потому что self._items – объект типа list . /g112 Основной метод. /g113 Возбудить исключение со специальным сообщением, если список self. _items пуст. /g114 Позволяет писать просто bingo() вместо bingo.pick() . Ниже приведена простая демонстрация этого кода. Обратите внимание, что объект bingo можно вызывать как функцию, и встроенная функция callable( …) распознает его как вызываемый объект:\n--- Страница 178 ---\n178 Глава 5. Полноправные функции >>> bingo = BingoCage(range(3)) >>> bingo.pick()1>>> bingo()0>>> callable(bingo)True Класс, в котором реализован метод __call__ , – простой способ создать похо- жий на функцию объект, обладающий внутренним состоянием, которое должно сохраняться между вызовами, как, например, остающиеся элементы в BingoCage . Примером может служить декоратор. Декораторы должны быть функциями, но иногда удобно иметь возможность «запоминать» что-то между вызовами декора-тора (например, в случае кэширования результатов длительных вычислений для последующего использования). Совершенно другой подход к созданию функций, имеющих внутреннее состо- яние, дают замыкания. Замыкания, как и декораторы, рассматриваются в главе 7. Перейдем теперь к другому аспекту обращения с функциями как с объектами: интроспекция во время выполнения. Интроспекция функций У объектов-функций есть много других атрибутов, помимо __doc__ . Вот что функ- ция dir сообщает о нашей функции factorial : >>> dir(factorial)['__annotations__', '__call__', '__class__', '__closure__', '__code__','__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__','__format__', '__ge__', '__get__', '__getattribute__', '__globals__','__gt__', '__hash__', '__init__', '__kwdefaults__', '__le__', '__lt__','__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__','__subclasshook__']>>> Многие из этих атрибутов имеются у любого объекта Python. В этом разделе мы рассмотрим лишь те, которые имеют непосредственное отношение к обраще-нию с функциями как с объектами, и начнем с атрибута __dict__ . Как и экземпляры обычного пользовательского класса, функция использует атрибут __dict__ для хранения ассоциированных с ней пользовательских данных. Это можно считать примитивной формой аннотации. Вообще говоря, ассоцииро-вание произвольных атрибутов с функцией – не очень распространенная практи-ка, но в Django активно применяется. См., например, атрибуты short_description , boolean и allow_tags , описанные в документации на административном сайте Django ( https://docs.djangoproject.com/en/1.5/ref/contrib/ admin ). Следующий код, взятый из документации по Django, показывает, как присоединить атрибут short_ description к методу, чтобы его описание появлялось в журналах Django при вы- зове метода:\n--- Страница 179 ---\n179 Интроспекция функций def upper_case_name(obj): return (\"%s %s\" % (obj.first_name, obj.last_name)).upper()upper_case_name.short_description = 'Customer name' Теперь обратимся к атрибутам, специфичным для функций, т. е. отсутствую- щим у пользовательских объектов общего вида. Чтобы получить список таких атрибутов, достаточно вычислить разность двух множеств (см. пример 5.9). Пример 5.9. Перечисление атрибутов функций, отсутствующих у обычных объектов >>> class C: pass # /g110 >>> obj = C() # /g111 >>> def func(): pass # /g112 >>> sorted(set(dir(func)) - set(dir(obj))) # /g113 ['__annotations__', '__call__', '__closure__', '__code__', '__defaults__','__get__', '__globals__', '__kwdefaults__', '__name__', '__qualname__']>>> /g110 Создаем тривиальный пользовательский класс. /g111 Создаем его экземпляр. /g112 Создаем тривиальную функцию. /g113 Вычислив разность множеств, получаем отсортированный список атри- бутов, имеющихся у функции, но отсутствующих у экземпляра обычного класса. В табл. 5.1 описаны атрибуты, вошедшие в список из примера 5.9. Т аблица 5.1. Атрибуты пользовательских функций Имя Тип Описание __annotations__ code Аннотации параметров и возвращаемого значения __call__ method-wrapper Реализация оператора (), т . е. протокола вызываемых объектов __closure__ tuple Замыкание функции, т . е. привязки свободных переменных (часто None ) __code__ code Метаданные и тело функции, откомпилированные в виде байт-кода __defaults__ tuple Значения формальных параметров по умолчанию __get__ method-wrapper Реализация протокола дескриптора для чтения (см. главу 20) __globals__ code Г лобальные переменные модуля, в котором определена функция __kwdefaults__ code Значения по умолчанию формальных чисто именованных параметров\n--- Страница 180 ---\n180 Глава 5. Полноправные функции Имя Тип Описание __name__ str Имя функции __qualname__ str Полное имя функции, например, Random.choice (см. PEP-3155 ( https://www.python.org/dev/peps/ pep-3155/ )) Ниже мы обсудим атрибуты __defaults__ , __code__ и __annotations__ , которые используются интегрированными средами разработки и каркасами для получения информации о сигнатуре функции. Но чтобы полнее оценить их прелесть, сделаем небольшое отступление и рассмотрим богатый синтаксис, предлагаемый в Python для объявления параметров функции и передачи ей аргументов. От позиционных к чисто именованным параметрам Одна из самых замечательных особенностей функций в Python – чрезвычайно гибкий механизм обработки параметров, дополненный в Python 3 чисто имено-ванными аргументами. С этой темой тесно связано использование * и ** для «раз- вертывания» итерируемых объектов и отображений в отдельные аргументы при вызове функции. Чтобы понять, как это выглядит на практике, взгляните на код в примере 5.10 и результат его выполнения в примере 5.11. Пример 5.10. Функция tag генерирует HTML; чисто именованный аргумент cls служит для передачи атрибута «class». Это обходное решение необходимо, потому что в Python class – зарезервированное слово def tag(name, *content, cls=None, **attrs): \"\"\"Генерирует один или несколько HTML-тегов\"\"\" if cls is not None: attrs['class'] = cls if attrs: attr_str = ''.join(' %s=\"%s\"' % (attr, value) for attr, value in sorted(attrs.items())) else: attr_str = '' if content: return '\\n'.join('<%s%s>%s</%s>' % (name, attr_str, c, name) for c in content) else: return '<%s%s />' % (name, attr_str) Функцию tag можно вызывать различными способами, как показано в при- мере 5.11.\n--- Страница 181 ---\n181 От позиционных к чисто именованным параметрам Пример 5.11. Некоторые из многочисленных способов вызвать функцию tag из примера 5.10 >>> tag('br') /g110 '<br />'>>> tag('p', 'hello') /g111 '<p>hello</p>'>>> print(tag('p', 'hello', 'world'))<p>hello</p><p>world</p>>>> tag('p', 'hello', id=33) /g112 '<p id=\"33\">hello</p>'>>> print(tag('p', 'hello', 'world', cls='sidebar')) /g113 <p class=\"sidebar\">hello</p><p class=\"sidebar\">world</p>>>> tag(content='testing', name=\"img\") /g114 '<img content=\"testing\" />'>>> my_tag = {'name': 'img', 'title': 'Sunset Boulevard', 'src': 'sunset.jpg', 'cls': 'framed'}>>> tag(**my_tag) /g115 '<img class=\"framed\" src=\"sunset.jpg\" title=\"Sunset Boulevard\" />' /g110 При задании одного позиционного аргумента порождает пустой тег с таким именем. /g111 Любое число аргументов после первого поглощаются конструкцией *con- tent и помещаются в кортеж. /g112 Именованные аргументы, которые не перечислены явно в сигнатуре функции tag, поглощаются конструкцией **attrs и помещаются в словарь. /g113 Параметр cls можно передать только с помощью именованного аргумента. /g114 Даже первый позиционный аргумент можно передать как именованный при вызове tag. /g115 Если словарю my_tag предшествуют две звездочки **, то все его элементы передаются как отдельные аргументы, затем некоторые привязываются к именованным параметрам, а остальные поглощаются конструкцией **at- trs. Чисто именованные аргументы – новая возможность в Python 3. В приме- ре 5.10 параметр cls может быть передан только как именованный аргумент – он никогда не поглощается неименованными позиционными аргументами. Чтобы задать чисто именованные аргументы в определении функции, указывайте их по-сле аргумента с префиксом *. Если вы вообще не хотите поддерживать позицион- ные аргументы, оставив, тем не менее, возможность, задавать чисто именованные, включите в сигнатуру звездочку * саму по себе: >>> def f(a, *, b): return a, b >>> f(1, b=2)(1, 2)\n--- Страница 182 ---\n182 Глава 5. Полноправные функции Отметим, что у чисто именованных аргументов может и не быть значения по умолчанию, они могут быть обязательными, как b в предыдущем примере. Перейдем теперь к интроспекции параметров функций и начнем с примера, взятого из веб-каркаса, который должен пробудить в вас аппетит. Получение информации о параметрах Интересное применение интроспекции функций имеется в микрокаркасе веб-приложений Bobo. Чтобы увидеть его в действии, приведем вариацию на тему примера «Hello world» из руководства по Bobo. Пример 5.12. Bobo знает , что функции hello требуется аргумент person и извлекает его из HTTP-запроса import bobo @bobo.query('/') def hello(person): return 'Hello %s!' % person Декоратор bobo.query связывает обычную функцию hello с механизмом об- работки запросов, встроенным в каркас. Декораторы мы будем рассматривать в главе 7, сейчас дело не в них. Нас же интересует тот факт, что Bobo анализирует функцию hello и обнаруживает, что для работы ей необходим один параметр с именем person , затем извлекает параметр с этим именем из запроса и передает его hello ; программисту при этом возиться с объектом запроса вообще не нужно. Если вы установите Bobo и направите сервер разработки на скрипт из приме- ра 5.12 (например, bobo -f hello .py), то попытка перейти на URL-адрес http:// localhost:8080/ приведет к ответу с кодом 403 и сообщением «Missing form variable person» (Отсутствует переменная формы person). Это происходит, потому что Bobo понимает, что для вызова hello нужен аргумент person , однако параметра с таким именем в запросе нет. В примере 5.13 показан запуск программы curl в оболочке ОС, демонстрирующий описанное поведение. Пример 5.13. Bobo возвращает ответ 403 Forbidden, если в запросе нет обязательных аргументов функции; curl -i выводит заголовки на стандартный вывод $ curl -i http://localhost:8080/ HTTP/1.0 403 ForbiddenDate: Thu, 21 Aug 2014 21:39:44 GMTServer: WSGIServer/0.2 CPython/3.4.1Content-Type: text/html; charset=UTF-8Content-Length: 103<html><head><title>Missing parameter</title></head><body>Missing form variable person</body></html>\n--- Страница 183 ---\n183 Получение информации о параметрах Однако если отправить запрос на адрес http://localhost:8080/?person=Jim , то в ответ придет строка 'Hello Jim!' (см. пример 5.14). Пример 5.14. Передача параметра person необходима для получения ответа с кодом OK $ curl -i http://localhost:8080/?person=Jim HTTP/1.0 200 OKDate: Thu, 21 Aug 2014 21:42:32 GMTServer: WSGIServer/0.2 CPython/3.4.1Content-Type: text/html; charset=UTF-8Content -Length: 10 Hello Jim! Как Bobo узнает об именах параметров, необходимых функции, и о наличии у них значений по умолчанию? У объекта-функции есть атрибут __defaults__ , в котором хранится кортеж со значениями по умолчанию позиционных и именованных параметров. Значения по умолчанию чисто именованных аргументов находятся в атрибуте __kwdefaults__ . Сами же имена параметров хранятся в атрибуте __code__ , который содержит ссыл- ку на объект code с множеством собственных атрибутов. Для демонстрации использования этих атрибутов мы проанализируем функ- цию clip из модуля clip.py , код которой приведен в примере 5.15. Пример 5.15. Функция укорачивает строку, обрезая ее по пробелу вблизи указанной длины def clip(text, max_len=80): \"\"\"Return text clipped at the last space before or after max_len \"\"\" end = None if len(text) > max_len: space_before = text.rfind(' ', 0, max_len) if space_before >= 0: end = space_before else: space_after = text.rfind(' ', max_len) if space_after >= 0: end = space_after if end is None: # no spaces were found end = len(text) return text[:end].rstrip() В примере 5.16 показаны значения атрибутов __defaults__ , __code__. co_varnames и __code__.co_argcount функции clip . Пример 5.16. Получение информации об аргументах функции >>> from clip import clip >>> clip.__defaults__(80,)>>> clip.__code__ # doctest: +ELLIPSIS<code object clip at 0x >\n--- Страница 184 ---\n184 Глава 5. Полноправные функции >>> clip.__code__.co_varnames ('text', 'max_len', 'end', 'space_before', 'space_after')>>> clip.__code__.co_argcount2 Как видим, организация информации не блещет удобством. Имена аргументов находятся в атрибуте __code__.co_varnames , но там же хранятся имена локальных переменных, созданных в теле функции. Таким образом, имена аргументов – это первые N строк, где N равно значению __code__.co_argcount , и, кстати говоря, в их число не входят переменные аргументы с префиксами * и **. Значения по умол- чанию определяются исключительно по позиции в кортеже __defaults__ , поэтому чтобы связать значение с соответствующим аргументом, необходимо просматри-вать от начала к концу. В данном примере есть два аргумента, text и max_len , и одно значение по умолчанию, 80, поэтому оно должно ассоциироваться с последним аргументом max_len . Очень неудобно. По счастью, есть способ лучше: модуль inspect . Взгляните на пример 5.17. Пример 5.17. Получение сигнатуры функции >>> from clip import clip >>> from inspect import signature>>> sig = signature(clip)>>> sig # doctest: +ELLIPSIS<inspect.Signature object at 0x >>>> str(sig)'(text, max_len=80)'>>> for name, param in sig.parameters.items(): print(param.kind, ':', name, '=', param.default) POSITIONAL_OR_KEYWORD : text = <class 'inspect._empty'>POSITIONAL_OR_KEYWORD : max_len = 80 Так гораздо лучше. Метод inspect.signature возвращает объект inspect. Signature , у которого есть атрибут parameters , позволяющий прочитать упорядо- ченное отображение имен на объекты типа inspect.Parameter . У каждого объекта Parameter есть набор атрибутов, например: name , default и kind . Специальное зна- чение inspect._empty обозначает параметры, не имеющие значений по умолчанию, и это разумно, если принять во внимание, что None – допустимое и даже весьма популярное значение по умолчанию. Атрибут kind может принимать одно из пяти значений типа _ParameterKind : POSITIONAL_OR_KEYWORD Параметр может быть передан как позиционный или как именованный (большинство параметров функций в Python именно таковы). VAR_POSITIONAL Кортеж позиционных параметров.\n--- Страница 185 ---\n185 Получение информации о параметрах VAR_KEYWORD Словарь именованных параметров. KEYWORD_ONLY Чисто именованный параметр (появились в Python 3). POSITIONAL_ONLY Чисто позиционный параметр; в настоящее время в синтаксисе объявления функций не поддерживаются, но встречаются в существующих функциях, написанных на C (например, divmod ), которые не принимают именованных параметров. Помимо атрибутов name , default и kind , у объектов типа inspect.Parameter есть атрибут annotation , который обычно равен inspect._empty , но может содержать метаданные сигнатуры, задаваемые с помощью нового синтаксиса аннотаций в Python 3 (аннотации рассматриваются в следующем разделе). У объекта inspect.Signature имеется метод bind , который принимает любое число аргументов и связывает их с параметрами, указанными в сигнатуре, следуя обычным правилам сопоставления фактических аргументов с формальными пара-метрами. Каркас может использовать эту возможность для проверки аргументов до фактического вызова функции. См. пример 5.18. Пример 5.18. Связывание сигнатуры функции tag из примера 5.10 со словарем аргументов >>> import inspect >>> sig = inspect.signature(tag) /g110 >>> my_tag = {'name': 'img', 'title': 'Sunset Boulevard', 'src': 'sunset.jpg', 'cls': 'framed'}>>> bound_args = sig.bind(**my_tag) /g111 >>> bound_args<inspect.BoundArguments object at 0x > /g112 >>> for name, value in bound_args.arguments.items(): /g113 print(name, '=', value) name = imgcls = framedattrs = {'title': 'Sunset Boulevard', 'src': 'sunset.jpg'}>>> del my_tag['name'] /g114 >>> bound_args = sig.bind(**my_tag) /g115 Traceback (most recent call last): TypeError: 'name' parameter lacking default value /g110 Получаем сигнатуру функции tag из примера 5.10. /g111 Передаем словарь аргументов методу .bind() . /g112 Возвращается объект типа inspect .BoundArguments . /g113 Обходим все элементы в объекте bound_args .arguments , имеющем тип Or- deredDict , и выводим имена и значения аргументов. /g114 У даляем обязательный аргумент из my_tag .\n--- Страница 186 ---\n186 Глава 5. Полноправные функции /g115 Вызов sig .bind(**my_tag) возбуждает исключение TypeError с сообщением об отсутствующем параметре name . На этом примере видно, как модель данных Python – посредством модуля inspect – раскрывает механизм, которым пользуется сам интерпретатор для свя- зывания аргументов с формальными параметрами при вызове функции. Каркасы и инструментальные средства, например IDE, могут использовать эту информацию для проверки правильности кода. Еще одно появившееся в Python 3 средство, аннотации функций, открывает дальнейшие возможности на этом пути. Аннотации функций В Python 3 появился синтаксис для присоединения метаданных к параметрам и возвращаемому значению в объявлении функции. В примере 5.19 показана анно-тированная версия примера 5.15. Отличается только первая строка. Пример 5.19. Аннотированная функция clip def clip(text:str, max_len:'int > 0'=80) -> str: /g110 \"\"\"Return text clipped at the last space before or after max_len \"\"\" end = None if len(text) > max_len: space_before = text.rfind(' ', 0, max_len) if space_before >= 0: end = space_before else: space_after = text.rfind(' ', max_len) if space_after >= 0: end = space_after if end is None: # no spaces were found end = len(text) return text[:end].rstrip() /g110 Аннотированное объявление функции. У любого аргумента в объявлении функции может быть выражение аннота- ции, которому предшествует двоеточие :. Если у аргумента имеется значение по умолчанию, то аннотация располагается между именем аргумента и знаком =. Что- бы аннотировать возвращаемое значение, поместите -> и вслед за ним выраже- ние между знаком ) и двоеточием в конце объявления функции. Тип выражения может быть любым. Чаще всего в аннотациях встречаются классы, например str или int, а также строки, например 'int > 0' , как в аннотации параметра max_len в примере 5.19. Аннотации никак не обрабатываются. Они просто сохраняются в атрибуте функции __annotations__ типа dict :\n--- Страница 187 ---\n187 Аннотации функций >>> from clip_annot import clip >>> clip.__annotations__{'text': <class 'str'>, 'max_len': 'int > 0', 'return': <class 'str'>} Элемент с ключом 'return' содержит аннотацию возвращаемого значения, по- меченную стрелкой -> в объявлении функции из примера 5.19. Python только сохраняет аннотации в атрибуте __annotations__ – и ничего больше: никаких проверок, контроля или еще чего-либо. Иными словами, для ин-терпретатора Python аннотации ничего не значат. Это просто метаданные, кото-рые могут использовать инструментальные средства: IDE, каркасы или декорато-ры. На момент написания этой книги в стандартной библиотеке не было средств, пользующихся аннотациями, за исключением функции inspect.signature() , ко- торая знает, как извлечь аннотации. Пример 5.20. Извлечение аннотаций из сигнатуры функции. >>> from clip_annot import clip >>> from inspect import signature>>> sig = signature(clip)>>> sig.return_annotation<class 'str'>>>> for param in sig.parameters.values(): note = repr(param.annotation).ljust(13) print(note, ':', param.name, '=', param.default)<class 'str'> : text = <class 'inspect._empty'>'int > 0' : max_len = 80 Функция signature возвращает объект Signature , имеющий атрибут return_ annotation и словарь parameters , который отображает имена параметров на объ- екты Parameter . У каждого объекта Parameter имеется свой атрибут annotation . Все это продемонстрировано в примере 5.20. В будущем каркасы типа Bobo, возможно, поддержат аннотации для более пол- ной автоматизации обработки запросов. Например, если аргумент аннотирован как price:float , то его можно было бы автоматически преобразовать из строки в тип float , ожидаемый функцией. А строковую аннотацию вида quantity:'int > 0' можно было бы разобрать для выполнения преобразования и проверки значения параметра. Но наибольшую пользу аннотации, скорее всего, принесут не для динамиче- ских операций, как в Bobo, а для предоставления факультативной информации о типах, которой можно было бы воспользоваться для статической проверки типов в таких инструментах, как IDE и средства поиска типичных ошибок в коде. Разобравшись с анатомией функций, мы посвятим оставшуюся часть главы рассмотрению наиболее полезных пакетов, включенных в стандартную библиоте-ку ради поддержки функционального стиля программирования.\n--- Страница 188 ---\n188 Глава 5. Полноправные функции Пакеты для функционального программирования Хотя Гвидо ясно дал понять, что Python не задумывался как язык функциональ- ного программирования, в нем, тем не менее, можно применять функциональный стиль кодирования – благодаря таким пакетам, как operator и functools , которые мы рассмотрим ниже. Модуль operator В функциональном программировании часто бывает удобно использовать арифметический оператор как функцию. Пусть, например, требуется перемно-жить последовательность чисел для нерекурсивного вычисления факториала. Для суммирования можно воспользоваться функцией sum, но аналогичной функ- ции для умножения не существует. Можно было бы применить функцию reduce , как было показано в разделе «Современные альтернативы функциям map, filter и reduce» выше, но для этого необходима функция умножения двух элементов последовательности. В примере 5.21 показано, как решить эту задачу с помощью lambda . Пример 5.21. Вычисление факториала с помощью reduce и анонимной функции from functools import reduce def fact(n): return reduce(lambda a, b: a*b, range(1, n+1)) Чтобы избавить нас от необходимости писать тривиальные анонимные функ- ции вида lambda a, b: a*b , модуль operator предоставляет функции, эквивалент- ные многим арифметическим операторам. С его помощью пример 5.21 можно переписать следующим образом. Пример 5.22. Вычисление факториала с помощью reduce и operator.mul from functools import reduce from operator import mul def fact(n): return reduce(mul, range(1, n+1)) Модуль operator включает также функции для выборки элементов из последо- вательностей и чтения атрибутов объектов: itemgetter и attrgetter строят специ- ализированные функции для выполнения этих действий. В примере 5.23 показано типичное применение itemgetter : сортировка списка кортежей по значению одного поля. В этом примере печатаются города, отсорти-рованные по коду страны (поле 1). По существу, itemgetter(1) делает то же самое,\n--- Страница 189 ---\n189 Пакеты для функционального программирования что lambda fields: fields[1] : создает функцию, которая получает коллекцию и возвращает элемент с индексом 1. Пример 5.23. Результат применения itemgetter для сортировки списка кортежей (данные взяты из примера 2.8) >>> metro_data = [ ('Tokyo', 'JP', 36.933, (35.689722, 139.691667)), ('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889)), ('Mexico City', 'MX', 20.142, (19.433333, -99.133333)), ('New York-Newark', 'US', 20.104, (40.808611, -74.020386)), ('Sao Paulo', 'BR', 19.649, (-23.547778, -46.635833)), ]>>>>>> from operator import itemgetter>>> for city in sorted(metro_data, key=itemgetter(1)): print(city) ('Sao Paulo', 'BR', 19.649, (-23.547778, -46.635833))('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889))('Tokyo', 'JP', 36.933, (35.689722, 139.691667))('Mexico City', 'MX', 20.142, (19.433333, -99.133333))('New York-Newark', 'US', 20.104, (40.808611, -74.020386)) Если передать функции itemgetter несколько индексов, то она построит функ- цию, которая возвращает кортеж, содержащий выбранные значения: >>> cc_name = itemgetter(1, 0)>>> for city in metro_data: print(cc_name(city)) ('JP', 'Tokyo') ('IN', 'Delhi NCR') ('MX', 'Mexico City')('US', 'New York-Newark') ('BR', 'Sao Paulo') >>> Поскольку itemgetter пользуется оператором [], то поддерживает не только последовательности, но и отображения, да и вообще любой класс, в котором реа-лизован метод __getitem__ . Близким родственником itemgetter является функция attrgetter , которая создает функции для извлечения атрибутов объекта по имени. Если передать attrgetter несколько имен атрибутов, то она также создаст функцию, возвра- щающую кортеж значений. Кроме того, если имя аргумента содержит точки, то attrgetter обойдет вложенные объекты для извлечения атрибута. Описанные возможности продемонстрированы в примере 5.24. Сеанс оболочки получился до-вольно длинным, потому что нам пришлось построить вложенную структуру для демонстрации обработки имен атрибутов с точкой.\n--- Страница 190 ---\n190 Глава 5. Полноправные функции Пример 5.24. Применение attrgetter для обработки ранее определенного списка именованных кортежей metro_data (тот же список, что в примере 5.23) >>> from collections import namedtuple >>> LatLong = namedtuple('LatLong', 'lat long') # /g110 >>> Metropolis = namedtuple('Metropolis', 'name cc pop coord') # /g111 >>> metro_areas = [Metropolis(name, cc, pop, LatLong(lat, long)) # /g112 for name, cc, pop, (lat, long) in metro_data]>>> metro_areas[0]Metropolis(name='Tokyo', cc='JP', pop=36.933, coord=LatLong(lat=35.689722,long=139.691667))>>> metro_areas[0].coord.lat # /g113 35.689722>>> from operator import attrgetter>>> name_lat = attrgetter('name', 'coord.lat') # /g114 >>>>>> for city in sorted(metro_areas, key=attrgetter('coord.lat')): # /g115 print(name_lat(city)) # /g116 ('Sao Paulo', -23.547778)('Mexico City', 19.433333)('Delhi NCR', 28.613889)('Tokyo', 35.689722)('New York -Newark', 40.808611) /g110 Определяем именованный кортеж LatLong . /g111 Определяем также Metropolis . /g112 Строим список metro_areas , содержащий экземпляры Metropolis ; обрати- те внимание на распаковку именованного кортежа для извлечения (lat, long) и использование этих данных для построения объекта LatLong , явля- ющегося значением атрибута coord объекта Metropolis . /g113 Получаем широту из элемента metro_areas[0] . /g114 Определяем attrgetter для выборки атрибута name и вложенного атрибута coord .lat. /g115 Снова используем attrgetter для сортировки списка городов по широте. /g116 Используем определенный выше attrgetter для показа только названия и широты города. Ниже приведен неполный список функций в модуле operator (имена, начина- ющиеся знаком подчеркивания, опущены, потому что такие функции содержат детали реализации): >>> [name for name in dir(operator) if not name.startswith('_')]['abs', 'add', 'and_', 'attrgetter', 'concat', 'contains','countOf', 'delitem', 'eq', 'floordiv', 'ge', 'getitem', 'gt','iadd', 'iand', 'iconcat', 'ifloordiv', 'ilshift', 'imod', 'imul','index', 'indexOf', 'inv', 'invert', 'ior', 'ipow', 'irshift','is_', 'is_not', 'isub', 'itemgetter', 'itruediv', 'ixor', 'le','length_hint', 'lshift', 'lt', 'methodcaller', 'mod', 'mul', 'ne','neg', 'not_', 'or_', 'pos', 'pow', 'rshift', 'setitem', 'sub','truediv', 'truth', 'xor']\n--- Страница 191 ---\n191 Пакеты для функционального программирования По большей части, назначение этих 52 функций очевидно. Функции, имена которых начинаются с i и далее содержат имя оператора – например, iadd , iand и т. д. – соответствуют составным операторам присваивания: +=, &= и т. д. Они из- меняют свой первый аргумент на месте, если это изменяемый объект; в противном случае функция работает так же, как аналогичная без префикса i: просто возвра- щает результат операции. Из прочих функций мы рассмотрим только methodcaller . Он похож на attrgetter и itemgetter в том смысле, что на лету создает функцию. Эта функция вызывает метод по имени для объекта, переданного в качестве аргумента (см. при-мер 5.25). Пример 5.25. Демонстрация methodcaller : во втором тесте показано связывание дополнительных аргументов >>> from operator import methodcaller >>> s = 'The time has come'>>> upcase = methodcaller('upper')>>> upcase(s)'THE TIME HAS COME'>>> hiphenate = methodcaller('replace', ' ', '-')>>> hiphenate(s)'The-time-has-come' Первый тест в примере 5.25 просто показывает, как работает функция methodcaller , но вообще-то, если нужно использовать метод str.upper как функ- цию, то можно просто вызвать его от имени класса str, передав строку в качестве аргумента: >>> str.upper(s)'THE TIME HAS COME' Второй тест показывает, что methodcaller позволяет также фиксировать не- которые аргументы – так же, как функция functools.partial . Это и будет нашей следующей темой. Фиксация аргументов с помощью functools.partial В модуле functools собраны некоторые функции высшего порядка. Из них наиболее широко известна функция reduce , которую мы рассматривали в разделе «Современные альтернативы функциям map, filter и reduce» выше. Помимо нее, особенно полезна функция partial и ее вариация partialmethod . Функция высшего порядка functools.partial позволяет применять функцию «частично». Получив на входе некоторую функцию, partial создает новый вызы- ваемый объект, в котором некоторые аргументы исходной функции фиксированы. Это полезно для адаптации функции, принимающей один или несколько аргумен-тов, к API, требующему обратного вызова функции с меньшим числом аргумен-тов. Тривиальная демонстрация приведена в примере 5.26.\n--- Страница 192 ---\n192 Глава 5. Полноправные функции Пример 5.26. Использование partial позволяет вызывать функцию с двумя аргументами там, где требуется вызываемый объект с одним аргументом >>> from operator import mul >>> from functools import partial>>> triple = partial(mul, 3) /g110 >>> triple(7) /g111 21>>> list(map(triple, range(1, 10))) /g112 [3, 6, 9, 12, 15, 18, 21, 24, 27] /g110 Создаем новую функцию triple из mul, связав первый аргумент со значени- ем 3. /g111 Тестируем ее. /g112 Используем triple совместно с map; mul в этом примере не смогла бы рабо- тать с map. Более полезный пример относится к функции unicode .normalize , с которой мы встречались в разделе «Нормализация Unicode для правильного сравнения» гла-вы 4. Для многих языков перед сравнением или сохранением строки рекомендуется нормализовывать с помощью вызова unicode .normalize('NFC', s) . Если это прихо- дится делать часто, то удобно завести функцию nfc, как показано в примере 5.27. Пример 5.27. Построение вспомогательной функции нормализации Unicode-строк с помощью partial >>> import unicodedata, functools >>> nfc = functools.partial(unicodedata.normalize, 'NFC')>>> s1 = 'caf é' >>> s2 = 'cafe\\u0301'>>> s1, s2('café', 'café') >>> s1 == s2False>>> nfc(s1) == nfc(s2)True Функция partial принимает в первом аргументе вызываемый объект, а за ним – произвольное число позиционных и именованных аргументов, подлежащих связыванию. В примере 5.28 демонстрируется использование partial совместно с функцией tag из примера 5.10 для фиксации одного позиционного и одного именованного аргумента. Пример 5.28. Применение partial к функции tag из примера 5.10 >>> from tagger import tag >>> tag<function tag at 0x10206d1e0> /g110 >>> from functools import partial\n--- Страница 193 ---\n193 Резюме >>> picture = partial(tag, 'img', cls='pic-frame') /g111 >>> picture(src='wumpus.jpeg')'<img class=\"pic-frame\" src=\"wumpus.jpeg\" />' /g112 >>> picturefunctools.partial(<function tag at 0x10206d1e0>, 'img', cls='pic-frame') /g113 >>> picture.func /g114 <function tag at 0x10206d1e0>>>> picture.args('img',)>>> picture.keywords{'cls': 'pic-frame'} /g110 Импортируем функцию tag из примера 5.10 и показываем ее идентифика- тор. /g111 Создаем функцию picture из tag, зафиксировав значение первого позиционного аргумента – 'img' и значение именованного параметра cls – 'pic -frame' . /g112 Функция picture работает, как и ожидалось. /g113 partial() возвращает объект functools .partial2. /g114 У объекта functools .partial есть атрибуты, дающие доступ к исходной функции и фиксированным аргументам. Функция functools.partialmethod (появилась в Python 3.4) делает то же, что partial , но предназначена для работы с методами. Из функций, входящих в модуль functools , упомянем также впечатляющую функ- цию lru_cache , которая производит «запоминание» (memoization) – один из способов автоматической оптимизации, при котором результаты вызова функции сохраняют-ся, чтобы не повторять дорогостоящие вычисления. Мы рассмотрим ее в главе 7, где обсуждаются декораторы, наряду с другими функциями высшего порядка, рассчи-танными на использование в качестве декораторов: singledispatch и wraps . Резюме Целью этой главы было исследование функций как полноправных объектов Python. Идея в том, что функции можно присваивать переменным, передавать другим функциям, сохранять в структурах данных, а также получать атрибуты функций, что позволяет каркасам и инструментальным средствам принимать те или иные решения. Функции высшего порядка, основа функционального про-граммирования, часто используются в программах на Python – несмотря на то, что map, filter и reduce употребляются реже, чем в былые времена, – благодаря списковому включению и аналогичным конструкциям, например генераторным выражениям, и наличию встроенных редуцирующих функций типа sum, all и any. Встроенные функции sorted , min, max и functools.partial – примеры распростра- ненных функций высшего порядка. 2 Из исходного кода ( http://bit.ly/1Vm8cqQ ) в скрипте functools.py становится ясно, что класс functools.partial реализован на C и используется по умолчанию. Если он недоступен, то, на- чиная с версии Python 3.4, в модуле functools имеется реализация partial на чистом Python.\n--- Страница 194 ---\n194 Глава 5. Полноправные функции В Python имеются разные виды вызываемых объектов: от простых функций, создаваемых с помощью lambda , до экземпляров классов, в которых реализован метод __call__ . Все они распознаются встроенной функцией callable() . Любой вызываемый объект поддерживает общий развитый синтаксис объявления фор-мальных параметров, в том числе чисто именованные параметры и аннотации (то и другое появилось только в Python 3). У функций и их аннотаций имеется богатый набор атрибутов, которые можно прочитать с помощью модуля inspect , содержащего, в частности, метод Signature. bind для применения гибких правил связывания фактических аргументов с фор- мальными параметрами. Наконец, мы рассмотрели несколько функций из модуля operator и функцию functools.partial , которая упрощает функциональное программирование за счет уменьшения потребности в синтаксисе лямбда-выражений. Дополнительная литература В следующих двух главах мы продолжим изучение программирования с помощью объектов-функций. В главе 6 показано, как полноправные функции упрощают не-которые классические паттерны объектно-ориентированного программирования, а глава 7 посвящена декораторам – специальному виду функций высшего поряд- ка – и механизму замыкания, благодаря которому декораторы и работают. Глава 7 книги David Beazley, Brian K. Jones «Python Cookbook», издание 3 (O'Reilly), отлично дополняет эту и седьмую главу, поскольку к объяснению тех же концепций в ней применен другой подход. В разделе 3.2 «Иерархия стандартных типов» справочного руководства по язы- ку Python ( http://bit.ly/1Vm8dv2 ) описаны семь вызываемых типов, а также все остальные встроенные типы. Тем из рассмотренных в этой главе средств, которые имеются только в Python 3, посвящены документы «PEP 3102 – Keyword-Only Arguments» ( https://www. python.org/dev/peps/pep-3102/ ) и «PEP 3107 – Function Annotations» ( https:// www.python.org/dev/peps/pep-3107/ ). Дополнительные сведения о текущем (середина 2014 года) положении с ис- пользованием аннотаций можно почерпнуть из двух вопросов на сайте Stack Overflow . Вопрос «Для чего рекомендуется применять аннотации функций в Python3» ( http://bit.ly/1FHiO Xf ) сопровождается практически полезным ответом и проницательными комментариями Раймонда Хэттингера, а в ответе на вопрос «Чем хороши аннотации функций в Python?» ( http://bit.ly/1FHiN5F ) обильно ци- тируется Гвидо ван Россум. Документ «PEP 362 – Function Signature Object» ( https://www.python.org/dev/ peps/pep-0362/ ) стоит прочитать, если вы намереваетесь использовать модуль inspect , в котором это средство реализовано. Отличное введение в функциональное программирование на Python – состав- ленный А. М. Кухлингом документ «Python Functional Programming HOWTO» (http://docs.python.org/3/howto/functional.html ). Но в основном он посвящен ис- пользованию итераторов и генераторов, которые рассматриваются в главе 14.\n--- Страница 195 ---\n195 Поговорим Пакет fn.py (https://github.com/kachayev/fn.py ) предназначен для поддержки функционального программирования в Python 2 и 3. По словам автора, Алексея Качаева, fn.py предлагает «реализацию отсутствующих в Python средств, позво- ляющую заниматься ФП с удовольствием». В него входит декоратор @recur.tco , оптимизирующий хвостовую рекурсию в Python, а также много других функций, структур данных и рецептов. На заданный на сайте StackOverflow вопрос «Зачем нужна функция functools. partial в Python» ( http://bit.ly/1FHiT dh ) в высшей степени информативный ответ дал Алекс Мартелли, автор классической книги «Python in a Nutshell». Созданный Джимом Фултоном веб-каркас Bobo стал первым, получившим право называться «объектно-ориентированным». Если он вызвал у вас интерес и вы хотели бы узнать о его современной реинкарнации, начните с «Введения» (http://bobo.readthedocs.org/en/latest/ ). Краткий экскурс в раннюю историю Bobo имеется в комментарии Филлипа Дж. Эби (Phillip J. Eby) к одной из статей в блоге Джоэла Спольски (Joel Spolsky) ( http://bit.ly/1FHiUxR ). Поговорим О Bobo Своей карьерой на ниве Python я обязан Bobo. Я воспользовался этим каркасом для разработки своего первого веб-проекта на Python в 1998 году. Я наткнулся на Bobo, когда искал объектно-ориентирован-ный способ программирования веб-приложений, уже испробовав аль-тернативы на Perl и Java. В 1997 году Bobo был пионером, открывшим концепцию объектной публикации: прямое отображение URL-адресов на иерархию объектов без необходимости конфигурировать маршруты. Красота решения заво-рожила меня. Bobo также предлагал автоматическую обработку HTTP-запросов на основе анализа сигнатур методов или функций-обработчиков. Автором Bobo является Джим Фултон, известный как «Папа Zope» благодаря его ведущей роли в разработке каркаса Zope, лежащего в основе CMS Plone, SchoolT ool, ERP5 и других крупномасштабных проектов на Python. Джим создал также ZODB – Zope Object Database – транзакционную объектную базу данных, поддерживающую свойства ACID (атомарность, непротиворечивость, изоляцию и долговечность), спроектированную так, чтобы с ней легко было работать из Python. С тех пор Джим переписал Bobo с нуля, так что теперь он поддерживает спецификацию WSGI (W eb Server Gateway Interface) и современный Python (включая Python 3). На момент написания этой книги в Bobo использовалась библиотека six для интроспекции функций, обеспечи- вающая совместимость с Python 2 и Python 3, несмотря на изменения, появившиеся в объектах-функциях и относящихся к ним API.\n--- Страница 196 ---\n196 Глава 5. Полноправные функции Является ли Python функциональным языком? Где-то в 2000 году я проходил обучение на курсах в США, когда в ау- диторию заглянул Гвидо ван Россум (он не преподавал). В последовав-шей серии вопросов и ответов кто-то спросил, какие функции Python заимствовал из других языков. Гвидо ответил: «Все, что есть хорошего в Python, украдено из других языков». Шрирам Кришнамурти (Shriram Krishnamurthi), профессор инфор- матики в Брауновском университете, начинает свою статью «T eaching Programming Languages in a Post-Linnaean Age» ( http://bit.ly/1FHj4p2 ) такими словами: «Парадигмы» языков программирования – отжившее и никому не нужное наследие ушедшего века. Проектировщики современ-ных языков не обращают на них никакого внимания, так почему же на учебных курсах мы так рабски им привержены? В той же статье упоминается и Python: Что еще сказать о таких языках, как Python, Ruby или Perl? У их проектировщиков не было терпения изучать красоты лин-неевских иерархий; они брали те функциональные возможности, которые считали нужным, творя смеси, не поддающиеся никакой классификации. Кришнамурти предлагает не пытаться классифицировать языки, следуя заранее выбранной таксономии, а рассматривать их как агрегаты функциональных возможностей. И хотя Гвидо не ставил такой цели, включение в Python полноправ- ных функций распахнуло двери функциональному программирова-нию. В сообщении «Origins of Python's Functional Features» ( http://bit. ly/1FHfhIo ) Гвидо пишет, что именно функции map, filter и reduce стали поводом для реализации в Python лямбда-выражений. Все эти средства предложил для включения в Python 1.0 Амрит Прем (Amrit Prem) в 1994 году (согласно файлу Misc/HISTORY по адресу http://hg.python.org/ cpython/file/default/Misc/HISTORY в дереве исходного кода CPython). Такие средства, как lambda , map, filter и reduce впервые появились в Lisp, первом функциональном языке программирования. Однако в Lisp не налагаются ограничения на то, что можно делать внутри lambda , потому что в Lisp любая конструкция является выражением. В Python принят синтаксис, основанный на предложениях, в котором выраже-ния не могут содержать предложения, и многие языковые конструкции являются предложениями – в том числе блок try/catch , которого мне особенно не хватает в лямбда-выражениях. Такова цена, которую прихо-\n--- Страница 197 ---\n197 Поговорим дится платить за в высшей степени удобочитаемый синтаксис3. У языка Lisp много сильных сторон, но удобочитаемость не из их числа. По иронии судьбы, заимствование синтаксиса спискового включе- ния из другого функционального языка, Haskell, заметно сократило по-требность в map и filter , да, кстати, и в lambda . Помимо ограничений синтаксиса анонимных функций, основным препятствием для более широкого принятия идиом функционального программирования в Python служит отсутствие устранения хвостовой рекурсии – оптимизации, которая уменьшает потребление памяти функ-цией, выполняющей рекурсивный вызов в конце своего тела. В другом сообщении, «Tail Recursion Elimination» ( http://bit.ly/1FHjdZv ), Гвидо приводит несколько причин, по которым такая оптимизация плохо под-ходит для Python. Это сообщение весьма интересно технической аргу-ментацией, но еще более тем, что первые три – самые важные – причины касаются удобства пользования. Тот факт, что использование, изучение и преподавание Python доставляет массу удовольствия – не случай-ность. Гвидо специально стремился к этому. Итак: Python, по своему замыслу, не является функциональным язы- ком – что бы под этим ни понимать. Python лишь заимствует кое-какие удачные идеи из функциональных языков. Проблема анонимных функций Помимо синтаксических ограничений, связанных со спецификой Python, у анонимных функций есть серьезный недостаток в любом язы-ке: отсутствие имени. И это лишь наполовину шутка. Трассировку стека проще читать, если у функций есть имя. Анонимные функции удобны, когда нужно срезать угол, программисты любят их писать, но иногда слишком увлекаются – особенно если язык и среда поощряют глубокую вложенность аноним-ных функций, как, скажем, JavaScript в среде Node.js. Большое количе-ство вложенных анонимных функций усложняет отладку и обработку ошибок. Асинхронное программирование в Python более структуриро-вано, быть может, потому что того требуют ограничения лямбда-выра-жений. Обещаю рассказать подробнее об асинхронном программирова-нии в будущем, но отложу это до главы 18. Кстати, обещания, будущие и отложенные объекты – концепции, используемые в API асинхронно-го программирования. Наряду с сопрограммами они открывают выход из так называемого «ада обратных вызовов». Мы увидим, как работает асинхронное программирование без обратных вызовов в разделе «От обратных вызовов к будущим объектам и сопрограммам» на стр. 592. 3 Еще есть проблема потери отступов при копировании кода в веб-форумы, но это я отвлекся.",
      "debug": {
        "start_page": 170,
        "end_page": 197
      }
    },
    {
      "name": "Глава 6. Реализация паттернов проектирования с помощью полноправных функций 198",
      "content": "--- Страница 198 --- (продолжение)\nГЛАВА 6. Реализация паттернов проектирования с помощью полноправных функций Соответствием паттернам качество не измеряется1. – Ральф Джонсон, один из авторов классической книги «Паттерны проектирования» Хотя паттерны проектирования от языка не зависят, это не значит, что любой паттерн применим к любому языку. В презентации 1996 года «Design Patterns in Dynamic Languages» ( http://norvig.com/design-patterns/ ) Петер Норвиг (Peter Norvig) утверждает, что 16 из 23 паттернов, описанных в оригинальной книге Гам-ма и др., в динамических языках «либо не видны, либо более просты» (слайд 9). Он говорил о языках Lisp и Dylan, но аналогичные динамические средства суще-ствуют и в Python. Авторы книги «Паттерны проектирования» признают во введении, что при- менимость паттернов зависит от реализации языка: Выбор языка программирования важен, поскольку он определя- ет точку зрения. В наших паттернах подразумевается использова-ние возможностей Smalltalk и C++, и от этого выбора зависит, что реализовать легко, а что – трудно. Если бы мы имели в виду про-цедурные языки, то включили бы паттерны «Наследование», «Ин-капсуляция» и «Полиморфизм». Некоторые из наших паттернов напрямую поддерживаются менее распространенными языками. Так, в языке CLOS есть мультиметоды, которые делают ненужным паттерн «Посетитель» 2. 1 Со слайда к докладу «Root Cause Analysis of Some Faults in Design Patterns», прочитанному Раль- фом Джонсоном на в IME/CCSL, университет Сан-Паулу, 15 ноября 2014. 2 Эрих Гамма, Ричард Хелм, Ральф Джонсон, Джон Влиссидес «Приемы объектно-ориентированно- го проектирования. Паттерны проектирования», Питер, 2001.\nГЛАВА 6. Реализация паттернов проектирования с помощью полноправных функций Соответствием паттернам качество не измеряется1. – Ральф Джонсон, один из авторов классической книги «Паттерны проектирования» Хотя паттерны проектирования от языка не зависят, это не значит, что любой паттерн применим к любому языку. В презентации 1996 года «Design Patterns in Dynamic Languages» ( http://norvig.com/design-patterns/ ) Петер Норвиг (Peter Norvig) утверждает, что 16 из 23 паттернов, описанных в оригинальной книге Гам-ма и др., в динамических языках «либо не видны, либо более просты» (слайд 9). Он говорил о языках Lisp и Dylan, но аналогичные динамические средства суще-ствуют и в Python. Авторы книги «Паттерны проектирования» признают во введении, что при- менимость паттернов зависит от реализации языка: Выбор языка программирования важен, поскольку он определя- ет точку зрения. В наших паттернах подразумевается использова-ние возможностей Smalltalk и C++, и от этого выбора зависит, что реализовать легко, а что – трудно. Если бы мы имели в виду про-цедурные языки, то включили бы паттерны «Наследование», «Ин-капсуляция» и «Полиморфизм». Некоторые из наших паттернов напрямую поддерживаются менее распространенными языками. Так, в языке CLOS есть мультиметоды, которые делают ненужным паттерн «Посетитель» 2. 1 Со слайда к докладу «Root Cause Analysis of Some Faults in Design Patterns», прочитанному Раль- фом Джонсоном на в IME/CCSL, университет Сан-Паулу, 15 ноября 2014. 2 Эрих Гамма, Ричард Хелм, Ральф Джонсон, Джон Влиссидес «Приемы объектно-ориентированно- го проектирования. Паттерны проектирования», Питер, 2001.\n--- Страница 199 ---\n199 Практический пример: переработка паттерна Стратегия В частности, в контексте языков с полноправными функциями Норвиг пред- лагает переосмыслить паттерны Стратегия, Команда, Шаблонный метод и Посе-титель. Общая идея заключается в том, что экземпляры некоего класса-участни-ка можно заменить простыми функциями, сократив объем стереотипного кода. В этом разделе мы переработаем паттерн Стратегия с помощью объектов-функ-ций и обсудим аналогичный подход к упрощению паттерна Команда. Практический пример: переработка паттерна Стратегия Стратегия – прекрасный пример паттерна проектирования, который в Python можно упростить путем использования функций как полноправных объектов. В следующем разделе мы опишем и реализуем Стратегию, сохраняя верность «классической» структуре, описанной в «Паттернах проектирования». Если вы знакомы с классическим паттерном, то можете сразу перейти к разделу «Функ-ционально-ориентированная Стратегия», где код будет переработан, в результате чего его объем существенно уменьшится. Классическая Стратегия На UML-диаграмме классов (рис. 6.1) изображены взаимоотношения классов, участвующих в паттерне Стратегия. Рис. 6.1. UML-диаграмма классов для обработки скидок по заказам, реализованных в соответствии с паттерном Стратегия/g455/g459/g458/g463/g450/g455/g462/g463 /g462/g463/g461/g445/g463/g450/g448/g453/g476 /g455/g459/g458/g455/g461/g450/g463/g458/g472/g450/g3/g462/g463/g461/g445/g463/g450/g448/g453/g453\n--- Страница 200 ---\n200 В книге «Паттерны проектирования» паттерн Стратегия описывается следую- щим образом: Определить семейство алгоритмов, инкапсулировать каждый из них и сделать их взаимозаменяемыми. Стратегия позволяет заме-нять алгоритм независимо от использующих его клиентов. Наглядный пример применения паттерна Стратегия к коммерческой задаче – вычисление скидок на заказы в соответствии с характеристиками заказчика или результатами анализа заказанных позиций. Рассмотрим Интернет-магазин со следующими правилами формирования скидок: • заказчику, имеющему не менее 1000 баллов лояльности, предоставляется глобальная скидка 5 % на весь заказ; • на позиции, заказанные в количестве не менее 20 единиц в одном заказе, предоставляется скидка 10 %; • на заказы, содержащие не менее 10 различных позиций, предоставляется глобальная скидка 7 %. Для простоты предположим, что к каждому заказу может быть применена только одна скидка. UML-диаграмма классов для паттерна Стратегия показана на рис. 6.1. Ее участ- никами являются: Контекст Предоставляет службу, делегируя часть вычислений взаимозаменяемым компонентам, реализующим различные алгоритмы. В примере Интернет- магазина контекстом является класс Order , который конфигурируется для применения поощрительной скидки по одному из нескольких алго-ритмов. Стратегия Интерфейс, общий для всех компонентов, реализующих различные алго- ритмы. В нашем примере эту роль играет абстрактный класс Promotion . Конкретная стратегия Один из конкретных подклассов Стратегии. В нашем случае реализованы три конкретные стратегии: FidelityPromo , BulkPromo и LargeOrderPromo . Код в примере 6.1 следует изображенной на рис. 6.1 схеме. Как описано в «Паттернах проектирования», конкретная стратегия выбирается клиентом класса контекста. В нашем примере система, перед тем как создать объект заказ, должна каким-то образом выбрать стратегию предоставления скидки и передать ее кон-структору класса Order . Вопрос о выборе стратегии не является предметом данно- го паттерна.Глава 6. Реализация паттернов проектирования с помощью\n--- Страница 201 ---\n201 Практический пример: переработка паттерна Стратегия Пример 6.1. Реализация класса Order с помощью взаимозаменяемых стратегий предоставления скидки from abc import ABC, abstractmethod from collections import namedtuple Customer = namedtuple('Customer', 'name fidelity') class LineItem: def __init__(self, product, quantity, price): self.product = product self.quantity = quantity self.price = price def total(self): return self.price * self.quantity class Order: # Контекст def __init__(self, customer, cart, promotion=None): self.customer = customer self.cart = list(cart) self.promotion = promotion def total(self): if not hasattr(self, '__total'): self.__total = sum(item.total() for item in self.cart) return self.__total def due(self): if self.promotion is None: discount = 0 else: discount = self.promotion.discount(self) return self.total() - discount def __repr__(self): fmt = '<Order total: {:.2f} due: {:.2f}>' return fmt.format(self.total(), self.due()) class Promotion(ABC): # Стратегия: абстрактный базовый класс @abstractmethod def discount(self, order): \"\"\"Вернуть скидку в виде положительной суммы в долларах\"\"\" class FidelityPromo(Promotion): # first Concrete Strategy \"\"\"5%-ая скидка для заказчиков, имеющих не менее 1000 баллов лояльности\"\"\" def discount(self, order):\n--- Страница 202 ---\n202 return order.total() * .05 if order.customer.fidelity >= 1000 else 0 class BulkItemPromo(Promotion): # second Concrete Strategy \"\"\"10%-ая скидка для каждой позиции LineItem, в которой заказано не менее 20 единиц\"\"\" def discount(self, order): discount = 0 for item in order.cart: if item.quantity >= 20: discount += item.total() * .1 return discount class LargeOrderPromo(Promotion): # third Concrete Strategy \"\"\"7%-ая скидка для заказов, включающих не менее 10 различных позиций\"\"\" def discount(self, order): distinct_items = {item.product for item in order.cart} if len(distinct_items) >= 10: return order.total() * .07 return 0 Отметим, что в примере 6.1 я сделал Promotion абстрактным базовым классом (ABC), чтобы можно было использовать декоратор @abstractmethod и тем самым прояснить структуру паттерна. В Python 3.4 для создания ABC проще всего унаследовать классу abc.ABC , как в примере 6.1. В версиях от Python 3.0 до 3.3 необ- ходимо использовать ключевое слово metaclass= в предложении class (например, class Promotion(metaclass=ABCMeta): ). Пример 6.2. Пример использования класса Order с различными стратегиями скидок >>> joe = Customer('John Doe', 0) /g110 >>> ann = Customer('Ann Smith', 1100)>>> cart = [LineItem('banana', 4, .5), /g111 LineItem('apple', 10, 1.5), LineItem('watermellon', 5, 5.0)]>>> Order(joe, cart, FidelityPromo()) /g112 <Order total: 42.00 due: 42.00>>>> Order(ann, cart, FidelityPromo()) /g113 <Order total: 42.00 due: 39.90>>>> banana_cart = [LineItem('banana', 30, .5), /g114 LineItem('apple', 10, 1.5)]>>> Order(joe, banana_cart, BulkItemPromo()) /g115 <Order total: 30.00 due: 28.50>>>> long_order = [LineItem(str(item_code), 1, 1.0) /g116Глава 6. Реализация паттернов проектирования с помощью\n--- Страница 203 ---\n203 Функционально-ориентированная стратегия for item_code in range(10)] >>> Order(joe, long_order, LargeOrderPromo()) /g117 <Order total: 10.00 due: 9.30>>>> Order(joe, cart, LargeOrderPromo())<Order total: 42.00 due: 42.00> /g110 Два заказчика: у joe 0 баллов лояльности, у ann – 1100. /g111 Одна корзина покупок с тремя позициями. /g112 Класс FidelityPromo не дает joe никаких скидок. /g113 ann получает скидку 5 %, поскольку имеет не менее 1000 баллов лояльно- сти. /g114 В корзине banana_cart находится 30 бананов и 10 яблок. /g115 Класс BulkItemPromo дает joe скидку $1.50 на бананы. /g116 В заказе long_order имеется 10 различных позиций стоимостью $1.00 каж- дая. /g117 joe получает скидку 7 % на весь заказ благодаря классу LargerOrderPromo . Пример 6.1 работает без нареканий, но ту же функциональность можно реа- лизовать в Python гораздо короче, воспользовавшись функциями как объектами. Функционально-ориентированная стратегия Каждая конкретная стратегия в примере 6.1 – это класс с одним методом discount . К тому же, объекты стратегии не имеют состояния (атрибутов экземпляра). Мы могли бы сказать, что они сильно напоминают функции, и были бы правы. В при-мере 6.3 код из примера 6.1 переработан – конкретные стратегии заменены про-стыми функциями, а абстрактный класс Promo исключен вовсе. Пример 6.3. Класс Order , в котором стратегии предоставления скидок реализованы в виде функций from collections import namedtuple Customer = namedtuple('Customer', 'name fidelity') class LineItem: def __init__(self, product, quantity, price): self.product = product self.quantity = quantity self.price = price def total(self): return self.price * self.quantity class Order: # the Context\n--- Страница 204 ---\n204 def __init__(self, customer, cart, promotion=None): self.customer = customer self.cart = list(cart) self.promotion = promotion def total(self): if not hasattr(self, '__total'): self.__total = sum(item.total() for item in self.cart) return self.__total def due(self): if self.promotion is None: discount = 0 else: discount = self.promotion(self) return self.total() - discount def __repr__(self): fmt = '<Order total: {:.2f} due: {:.2f}>' /g110 return fmt.format(self.total(), self.due()) /g111def fidelity_promo(order): /g112 \"\"\"5%-ая скидка для заказчиков, имеющих не менее 1000 баллов лояльности\"\"\" return order.total() * .05 if order.customer.fidelity >= 1000 else 0 def bulk_item_promo(order): \"\"\"10%-ая скидка для каждой позиции LineItem, в которой заказано не менее 20 единиц\"\"\" discount = 0 for item in order.cart: if item.quantity >= 20: discount += item.total() * .1 return discount def large_order_promo(order): \"\"\"7%-ая скидка для заказов, включающих не менее 10 различных позиций\"\"\" distinct_items = {item.product for item in order.cart} if len(distinct_items) >= 10: return order.total() * .07 return 0 /g110 Для вычисления скидки просто вызываем функцию self.promotion() . /g111 Абстрактного класса больше нет. /g112 Каждая стратегия является функцией. Код в примере 6.3 на 12 строчек короче, чем в примере 6.1. Пользоваться новым классом Order также несколько проще, как показано в doctest-скриптах ниже.Глава 6. Реализация паттернов проектирования с помощью\n--- Страница 205 ---\n205 Функционально-ориентированная стратегия Пример 6.4. Пример использования класса Order , в котором стратегии скидки реализованы в виде функций >>> joe = Customer('John Doe', 0) /g110 >>> ann = Customer('Ann Smith', 1100)>>> cart = [LineItem('banana', 4, .5), LineItem('apple', 10, 1.5), LineItem('watermellon', 5, 5.0)]>>> Order(joe, cart, fidelity_promo) /g111 <Order total: 42.00 due: 42.00>>>> Order(ann, cart, fidelity_promo)<Order total: 42.00 due: 39.90>>>> banana_cart = [LineItem('banana', 30, .5), LineItem('apple', 10, 1.5)]>>> Order(joe, banana_cart, bulk_item_promo) /g112 <Order total: 30.00 due: 28.50>>>> long_order = [LineItem(str(item_code), 1, 1.0) for item_code in range(10)]>>> Order(joe, long_order, large_order_promo)<Order total: 10.00 due: 9.30>>>> Order(joe, cart, large_order_promo)<Order total: 42.00 due: 42.00> /g110 Те же тестовые фикстуры, что в примере 6.1. /g111 Для применения стратегии скидки к объекту Order нужно просто передать функцию скидки в качестве аргумента. /g112 Здесь и в следующем тесте используются разные функции скидки. По поводу выносок в примере 6.4: нет необходимости создавать новый объект скидки для каждого заказа – функции и так готовы к применению. Интересно, что авторы «Паттернов проектирования» замечают: «в большин- стве случаев объекты-стратегии подходят как приспособленцы»3. В другой ча- сти книги паттерн Приспособленец определяется так: «Приспособленец – это разделяемый объект, который можно использовать одновременно в нескольких контекстах». 4 Разделение рекомендуется для того, чтобы сэкономить на стоимости создания экземпляров конкретных стратегий, которые многократно применяются в каждом новом контексте – в нашем примере к каждому объекту Order . Поэтому в целях преодоления недостатка паттерна Стратегия – высоких накладных расхо-дов во время выполнения – авторы рекомендуют применять еще один паттерн. И тем самым увеличивается объем и сложность сопровождения кода. В более сложном случае, когда у конкретных стратегий имеется внутреннее состояние, может оказаться необходимым как-то комбинировать части паттернов Стратегия и Приспособленец. Но часто у конкретных стратегий нет внутреннего состояния, они имеют дело только с данными из контекста. И тогда ничто не ме-шает использовать обычные функции вместо написания классов с единственным методом, которые реализуют интерфейс, объявленный еще в одном классе. Функ- 3 «Паттерны проектирования», стр. 309. 4 Там же, стр. 192.\n--- Страница 206 ---\n206 ция обходится дешевле экземпляра пользовательского класса и отпадает надоб- ность в паттерне Приспособленец, потому что каждая функция-стратегия создает-ся только один раз – когда Python компилирует модуль. Обычная функция как раз и является «разделяемым объектом, который можно использовать одновременно в нескольких контекстах». Теперь, когда мы знаем, как реализовать паттерн Стратегия, перед нами от- крываются и другие возможности. Допустим, мы хотим создать «метастратегию», которая выбирает наилучшую скидку для данного объекта Order . В следующих разделах мы продолжим переработку и покажем различные подходы к реализации этого требования, используя функции и модули как объекты. Выбор наилучшей стратегии: простой подход Используя тех же заказчиков и корзины покупок, что в примере 6.4, мы доба- вим еще три теста. Пример 6.5. Функция best_promo применяет все стратегии и возвращает наибольшую скидку >>> Order(joe, long_order, best_promo) /g110 <Order total: 10.00 due: 9.30>>>> Order(joe, banana_cart, best_promo) /g111 <Order total: 30.00 due: 28.50>>>> Order(ann, cart, best_promo) /g112 <Order total: 42.00 due: 39.90> /g110 Для покупателя joe функция best_promo выбрала стратегию larger_order_ promo . /g111 Здесь joe получил скидку от bulk_item_promo за заказ большого числа бана- нов. /g112 Несмотря на очень простую корзину, best_promo дала лояльному покупате- лю ann скидку согласно стратегии fidelity_promo . Реализация best_promo очень проста и показана в примере 6.6. Пример 6.6. best_promo находит максимальную скидку, перебирая все функции promos = [fidelity_promo, bulk_item_promo, large_order_promo] /g110 def best_promo(order): /g111 \"\"\"Выбрать максимально возможную скидку \"\"\" return max(promo(order) for promo in promos) /g112 /g110 promos : список стратегий, реализованных в виде функций. /g111 best_promo получает объект Order в качестве аргумента, как и другие функ- ции *_promo .Глава 6. Реализация паттернов проектирования с помощью\n--- Страница 207 ---\n207 Функционально-ориентированная стратегия /g112 С помощью генераторного выражения мы применяем к order каждую функцию из списка promos и возвращаем максимальную вычисленную скидку. Код в примере 6.6 работает бесхитростно: promos – это список функций. Сжив- шись с идеей о том, что функции – полноправные объекты, вы будете восприни-мать и структуры, содержащие функции, как нечто естественное. Пример 6.6 работает и читать код легко, но все же в нем есть некоторое дубли- рование, которое может приводить к тонкой ошибке: чтобы добавить новую стра-тегию скидки, нужно написать функцию и не забыть добавить ее в список promos , иначе новая стратегия будет работать, если явно передать ее в качестве аргумента Order , но best_promotion ее рассматривать не будет. Ниже описано два решения этой проблемы. Читайте дальше. Поиск стратегий в модуле Модули в Python также являются полноправными объектами, и в стандартной библиотеке есть несколько функций для работы с ними. В документации встроен-ная функция globals описана следующим образом: globals() Возвращает словарь, представляющий текущую таблицу глобальных сим- волов. Это всегда словарь текущего модуля (внутри функции или метода это тот модуль, где данная функция или метод определены, а не модуль, из которого они вызваны). В примере 6.7 показан не вполне честный способ использования globals , по- зволяющий best_promo автоматически находить все доступные функции *_promo . Пример 6.7. Список promos строится путем просмотра глобального пространства имен модуля promos = [globals()[name] for name in globals() /g110 if name.endswith('_promo') /g111 and name != 'best_promo'] /g112 def best_promo(order): \"\"\"Выбрать максимально возможную скидку \"\"\" return max(promo(order) for promo in promos) /g113 /g110 Перебираем все имена в словаре, возвращенном функцией globals() . /g111 Оставляем только имена с суффиксом _promo . /g112 Отфильтровываем саму функцию best_promo , чтобы не было бесконечной рекурсии. /g113 Сама функция best_promo не изменилась. Другой способ собрать вместе все стратегии скидки – создать отдельный мо- дуль и поместить в него все функции-стратегии, кроме best_promo .\n--- Страница 208 ---\n208 Пример 6.8 отличает только тем, что список функций-стратегий строится пу- тем просмотра специального модуля promotions . Отметим, что для работы этого кода необходимо импортировать модуль promotions , а также модуль inspect , в ко- тором находятся высокоуровневые функции интроспекции (предложения импор-та опущены, потому что обычно они находятся в начале файла). Пример 6.8. Список promos строится путем интроспекции нового модуля promotions promos = [func for name, func in inspect.getmembers(promotions, inspect.isfunction)] def best_promo(order): \"\"\"Выбрать максимально возможную скидку \"\"\" return max(promo(order) for promo in promos) Функция inspect.getmembers возвращает атрибуты объекта – в данном случае модуля promotions – возможно, отфильтрованные предикатом (булевой функци- ей). Мы пользуемся предикатом inspect.isfunction , чтобы получить только име- ющиеся в модуле функции. Код в примере 6.8 работает независимо от имен функций, важно лишь, чтобы модуль promotions содержал только функции вычисления скидки для переданно- го заказа. Конечно, это некое неявное предположение: если кто-нибудь включит в модуль promotions функцию с другой сигнатурой, то при попытке применить ее к заказу best_promo завершится с ошибкой. Можно было бы отбирать функции более строго, например, анализируя их ар- гументы. Но цель примера 6.8 – не предложить полное решение, а показать один из возможных путей использования интроспекции модуля. Есть и более явный подход к динамическому отбору функций вычисления скидки – воспользоваться декоратором. В главе 7, посвященной декораторам функций, мы покажем такой способ реализации Стратегии для нашего Интернет-магазина. В следующем разделе мы обсудим паттерн Команда, который часто реализуют с помощью классов с единственным методом, хотя достаточно и обычной функ-ции. Паттерн Команда Команда – еще один паттерн проектирования, который можно упростить с помо-щью передачи функций в качестве аргументов. На рис. 6.2 показана диаграмма классов для этого паттерна. Цель Команды – разорвать связь между объектом, инициировавшим опера- цию (Инициатором) и объектом, который ее реализует (Получателем). В при-мере из «Паттернов проектирования» инициаторами являются пункты меню в Глава 6. Реализация паттернов проектирования с помощью\n--- Страница 209 ---\n209 Паттерн Команда графическом редакторе, а получателями – редактируемый документ или само приложение. Рис. 6.2. UML-диаграмма классов для управляемого меню текстового редактора, реализованного с применением паттерна Команда. У каждой команды может быть свой получатель: объект , выполняющий действие. Для команды PasteCommand получателем является Document , а для OpenCommand – приложение. Идея в том, чтобы поместить между инициатором и получателем объект Com- mand , который реализует интерфейс с единственным методом execute , вызываю- щим какой-то метод Получателя для выполнения желаемой операции. Таким об- выполнения желаемой операции. Таким об- я желаемой операции. Таким об- разом, Инициатор ничего не знает об интерфейсе Получателя, так что, написав подклассы Command , можно адаптировать различные получатели. Инициатор кон- фигурируется конкретной командой и вызывает ее метод execute . Отметим, что на рис. 6.2 показан, в частности, класс MacroCommand , который может хранить после- довательность команд; его метод execute() вызывает одноименный метод каждой хранимой команды. Авторы «Паттернов проектирования» пишут: «Команды – объектно-ориенти- рованная замена обратным вызовам». Вопрос: а нужна ли нам объектно-ориенти-рованная замена обратным вызовам? Иногда да, а иногда и нет. Вместо того чтобы передавать Инициатору объект Command , мы можем передать ему обычную функцию. И вызывать Инициатор будет не метод command.execute() , а просто функцию command() . Класс MacroCommand можно реализовать с помощью класса, в котором реализован специальный метод __call__ . Тогда экземпляры Mac- roCommand будут вызываемыми объектами, содержащими список функций для по- следующего вызова (см. пример 6.9)./g453/g458/g453/g467/g453/g445/g463/g459/g461 /g455/g459/g458/g455/g461/g450/g463/g458/g472/g450/g3/g455/g459/g457/g445/g458/g449/g472/g455/g456/g453/g450/g458/g463 /g455/g459/g457/g445/g458/g449/g445 /g460/g459/g456/g464/g468/g445/g463/g450/g456/g453\n--- Страница 210 ---\n210 Пример 6.9. В каждом объекте MacroCommand хранится внутренний список команд class MacroCommand: \"\"\"Команда, выполняющая список команд\"\"\" def __init__(self, commands): self.commands = list(commands) # /g110 def __call__(self): for command in self.commands: # /g111 command() /g110 Построение списка, инициализированного аргументом commands , гаранти- рует, что это итерируемый объект, и сохраняет локальную копию ссылок на команды в каждом экземпляре MacroCommand . /g111 При вызове экземпляра MacroCommand последовательно вызываются все ко- манды из списка self.commands . Для менее тривиальных применений паттерна Команда – например, для под- держки операции отмены – простой функции обратного вызова может не хватить. Но даже в этом случае Python предлагает две альтернативы, заслуживающие вни-мания. • Вызываемый объект наподобие MacroCommand из примера 6.9 может хранить произвольное состояние и предоставлять другие методы в дополнение к __call__ . • Для запоминания внутреннего состояния функции между ее вызовами можно воспользоваться замыканием. На этом мы завершаем переосмысление паттерна Команда, навеянное приме- нением полноправных функций. На верхнем уровне этот подход близок к исполь-зованному в паттерне Стратегия: заменить вызываемыми объектами экземпляры класса-участника, реализующего интерфейс с единственным методом. Ведь лю-бой вызываемый объект в Python и так реализует интерфейс с единственным ме-тодом, а именно методом __call__ . Резюме Как отметил Петер Норвиг спустя два года после выхода классической книги «Паттерны проектирования»: «16 из 23 паттернов в языках Lisp и Dylan имеют существенно более простую реализацию, чем в C++, по крайней мере, в некото-рых ситуациях» (слайд 9 из презентации Норвига «Паттерны проектирования в динамических языках» ( http://bit.ly/1HGC0r5 )). Python обладает некоторыми ди- намическими средствами, имеющимися в языках Lisp и Dylan, в частности, полно-правными функциями, которым, в основном, и посвящена эта часть книги. В том же выступлении на праздновании 20-й годовщины выхода «Паттернов проектирования», цитата из которого послужила эпиграфом к этой главе, Ральф Глава 6. Реализация паттернов проектирования с помощью\n--- Страница 211 ---\n211 Дополнительная литература Джонсон говорил, что одной из неудач книги стало «чрезмерно большое внимание паттернам как конечным точкам, а не шагам паттернов проектирования»5. В этой главе мы взяли в качестве отправной точки паттерн Стратегия и показали, как упростить его работоспособную реализацию путем использования полноправных функций. Во многих случаях функции или вызываемые объекты оказываются более естественным способом реализации обратных вызовов в Python, чем рабское следование описаниям паттернов Стратегия или Команда, приведенным в книге «Паттерны проектирования». Переработка Стратегии и обсуждение Команды – примеры более общей ситуации: если встречается паттерн или API, который нуж-дается в компоненте с единственным методом, и этот метод имеет такое общее название, как «execute», «run» или «doIt», то такой паттерн или API часто проще реализовать с помощью полноправных функций или иных вызываемых объектов. При этом объем стереотипного кода уменьшается. Слайды Петера Норвига убеждают нас, что паттерны Команда и Стратегия – а также Шаблонный метод и Посетитель – можно упростить или даже сделать «невидимыми» благодаря применению полноправных функций, по крайней мере, в некоторых приложениях этих паттернов. Дополнительная литература Мы закончили обсуждение паттерна Стратегия предложением использовать де-кораторы функций для улучшения примера 6.8. Также в этой главе мы пару раз упоминали замыкания. Декораторы и замыкания – тема главы 7. В этой главы мы еще раз переработаем пример, относящийся к Интернет-магазину, воспользовав-шись декоратором для регистрации функций-стратегий. В рецепте 8.21 «Реализация паттерна Посетитель» из книги David Beazley, Brian K. Jones «Python Cookbook», издание 3 (O'Reilly), предложена элегантная реализация паттерна Посетитель, в которой класс NodeVisitor обращается с мето- дами, как с полноправными объектами. По паттернам проектирования выбор литературы для программиста на Python не так широк, как для других языков. Насколько мне известно, по состоянию на июнь 2014 года книга Gennadiy Zlobin «Learning Python Design Patterns» (Packt) – единственная, целиком посвя-щенная паттернам в Python. Но она очень короткая (100 страниц), и в ней рассмо-трены только 8 из 23 оригинальных паттернов. Книга Tarek Ziade «Expert Python Programming» (Packt) – одна из лучших на рынке для программистов на Python среднего уровня, а в последней главе «Useful Design Patterns» описаны семь классических паттернов с точки зрения Python 6. 5 Из доклада «Root Cause Analysis of Some Faults in Design Patterns», прочитанного Джонсоном на IME-USP 15 ноября 2014 года. 6 На русский язык переведена также книга Марка Саммерфилда «Python на практике» (ДМК Пресс, 2014), в которой рассмотрены все 23 паттерна. – Прим. перев.\n--- Страница 212 ---\n212 Алекс Мартелли несколько раз выступал с докладами на тему паттернов про- ектирования в Python. В сети опубликована видеозапись его презентации на кон-ференции EuroPython 2011 ( http://bit.ly/1HGBXvx ), а на его личном сайте также выложен набор слайдов ( http://www.aleax.it/gdd_pydp.pdf ). В разные годы мне встречались наборы слайдов разной комплектности и видео разной продолжи-тельности, так что имеет смысл поискать повнимательнее, указав в запросе имя автора и слова «Python Design Patterns». Где-то в 2008 году Брюс Эккель, автор замечательной книги «Thinking in Java» (Prentice Hall), начал писать книгу под названием «Python 3 Patterns, Recipes and Idioms» ( http://bit.ly/1HGBXeQ ). Предполагалось, что ее напишет сообщество до- бровольцев под руководством Эккеля, но и сейчас, шесть лет спустя, она все еще не завершена и, по всей видимости, проект заглох (последний раз в репозиторий записывали два года назад). Существует много книг по паттернам проектирования в контексте Java, из них я хотел бы выделить книгу Eric Freeman, Bert Bates, Kathy Sierra, Elisabeth Robson «Head First Design Patterns» (O'Reilly) 7. В ней объясняются 16 из 23 классических паттернов. Если вам нравится неформальный стиль серии «Head First» и требу-ется введение в эту тему, то это как раз то, что надо. Однако книга ориентирована на Java. Тем, кого интересует свежий взгляд на паттерны с точки зрения динамического языка с динамической типизацией и полноправными функциями, стоит прочи-тать книгу Russ Olsen «Design Patterns in Ruby» (Addison-W esley); многие при-веденные в ней мысли применимы также к Python. Несмотря на многочисленные синтаксические различия, на семантическом уровне Python и Ruby ближе друг к другу, чем к Java или C++. В презентации «In Design Patterns in Dynamic Languages» ( http://norvig.com/ design-patterns/ ) (слайды) Петер Норвиг показывает, как с помощью полноправ- ных функций (и других динамических средств) сделать некоторые классические паттерны более простыми или вообще ненужными. Разумеется, оригинальная книга Гамма и др. «Паттерны проектирования» – обязательное чтение для всех, кто серьезно относится к этому предмету. Одно лишь введение оправдывает уплаченные деньги. Эта книга – первоисточник часто цитируемых принципов проектирования: «Ставьте во главу угла интерфейс, а не реализацию» и «Предпочитайте композицию, а не наследование классов». Поговорим В языке Python есть полноправные функции и полноправные типы – средства, которые, согласно Норвигу, могут оказать влияние на 10 из 23 паттернов (слайд 10 из презентации «Design Patterns in Dynamic Languages» по адресу http://norvig.com/design-patterns/ ). В следующей 7 Эрик Фримен, Элизабет Фримен, Кэти Сиерра, Берт Бейтс «Паттерны проектирования». Питер, 2015.Глава 6. Реализация паттернов проектирования с помощью\n--- Страница 213 ---\n213 Поговорим главе мы увидим, что в Python есть также обобщенные функции (раз- дел «Одиночная диспетчеризация и обобщенные функции» на стр. 233), похожие на мультиметоды из языка CLOS, которые в книге Гамма и др. названы более простым способам реализации классического паттерна Посетитель. Со своей стороны, Норвиг утверждает, что мультиметоды упрощают паттерн Построитель (слайд 10). Адаптация паттернов к язы-ку программирования – не точная наука. На учебных курсах в разных уголках мира паттерны проектирования часто преподают на примерах из Java. Я не раз слышал от студентов, что их заверяли в том, что оригинальные паттерны полезны в любом языке. Как оказалось, 23 «классических» паттерна из книги Гамма и др. прекрасно ложатся на «классический» Java, хотя первоначально излагались в основном в контексте C++ (в книге очень немного примеров для Smalltalk). Но это не значит, что каждый паттерн одинаково хорошо применим в любом языке. Авторы в самом начале книги явно говорят, что «некоторые из наших паттернов напрямую поддерживаются менее распространенными объектно-ориентированными языками» (также еще раз прочитайте эпиграф к этой главе). Библиография на тему паттернов проектирования в Python крайне скромна по сравнению с Java, C++ или Ruby. В разделе «Дополнительная литература» я упомянул книгу Gennadiy Zlobin «Learning Python Design Patterns», опубликованную только в ноябре 2013 года. А вот книга Russ Olsen «Design Patterns in Ruby» вышла еще в 2007 году и насчитывает 384 страницы – на 284 больше, чем работа Злобина. Но будем надеяться, что с ростом популярности Python в академи- ческих кругах о паттернах проектирования в этом языке станут писать больше. Кроме того, в Java 8 появились ссылки на методы и анонимные функции – средства, которых ждали очень давно, – и есть надежда, что это стимулирует поиск новых подходов к паттернам в Java. В общем, надо признать, что языки развиваются, а вместе с ними и наши пред-ставления о том, как применять классические паттерны проектирова-ния.",
      "debug": {
        "start_page": 198,
        "end_page": 213
      }
    },
    {
      "name": "Глава 7. Декораторы функций и замыкания 214",
      "content": "--- Страница 214 --- (продолжение)\nГЛАВА 7. Декораторы функций и замыкания Многие были недовольны выбором названия «декоратор» для этого сред-ства. И главная причина – несогласованность с использованием термина в книге «Банды четырех». Название декоратор, пожалуй, в большей сте-пени связано с употреблением в области разработки компиляторов – об-ход и аннотирование синтаксического дерева. – Ральф Джонсон, PEP 318 – Decorators for Functions and Methods Декораторы функций дают возможность «помечать» функции в исходном коде, тем или иным способом дополняя их поведение. Это мощное средство, но для ов-ладения им нужно понимать, что такое замыкание. Одно из самых недавних зарезервированных слов в Python – nonlocal , оно поя- вилось в версии Python 3.0. Программист на Python может безбедно существовать, и не используя его, если будет строго придерживаться объектно-ориентированной диеты, основанной на классах. Но если вы захотите реализовать собственные де-кораторы функций, то должны досконально разбираться в замыканиях, а тогда потребность в слове nonlocal становится очевидной. Помимо применения при реализации декораторов, замыкания важны также для эффективного асинхронного программирования без обратных вызовов и для кодирования в функциональном стиле там, где это имеет смысл. Конечная цель этой главы – точно объяснить, как работают декораторы – от простейших регистрационных до более сложных параметризованных. Но прежде нам предстоит рассмотреть следующие вопросы: • как интерпретатор Python разбирает синтаксис декораторов; • как Python решает, является ли переменная локальной;• зачем нужны замыкания и как они работают;• какие проблемы решает ключевое слово nonlocal . Заложив этот фундамент, мы сможем перейти непосредственно к декорато- рам:\nГЛАВА 7. Декораторы функций и замыкания Многие были недовольны выбором названия «декоратор» для этого сред-ства. И главная причина – несогласованность с использованием термина в книге «Банды четырех». Название декоратор, пожалуй, в большей сте-пени связано с употреблением в области разработки компиляторов – об-ход и аннотирование синтаксического дерева. – Ральф Джонсон, PEP 318 – Decorators for Functions and Methods Декораторы функций дают возможность «помечать» функции в исходном коде, тем или иным способом дополняя их поведение. Это мощное средство, но для ов-ладения им нужно понимать, что такое замыкание. Одно из самых недавних зарезервированных слов в Python – nonlocal , оно поя- вилось в версии Python 3.0. Программист на Python может безбедно существовать, и не используя его, если будет строго придерживаться объектно-ориентированной диеты, основанной на классах. Но если вы захотите реализовать собственные де-кораторы функций, то должны досконально разбираться в замыканиях, а тогда потребность в слове nonlocal становится очевидной. Помимо применения при реализации декораторов, замыкания важны также для эффективного асинхронного программирования без обратных вызовов и для кодирования в функциональном стиле там, где это имеет смысл. Конечная цель этой главы – точно объяснить, как работают декораторы – от простейших регистрационных до более сложных параметризованных. Но прежде нам предстоит рассмотреть следующие вопросы: • как интерпретатор Python разбирает синтаксис декораторов; • как Python решает, является ли переменная локальной;• зачем нужны замыкания и как они работают;• какие проблемы решает ключевое слово nonlocal . Заложив этот фундамент, мы сможем перейти непосредственно к декорато- рам:\n--- Страница 215 ---\n215 Краткое введение в декораторы • реализация корректно ведущего себя декоратора; • интересные декораторы в стандартной библиотеке;• реализация параметризованного декоратора. Начнем с самых базовых понятий, относящихся к декораторам, а затем обра- тимся к остальным перечисленным выше темам. Краткое введение в декораторы Декоратор – это вызываемый объект, который принимает другую функцию в каче-стве аргумента (декорируемую функцию) 1. Декоратор может производить какие- то операции с функцией и возвращает либо ее саму, либо другую заменяющую ее функцию или вызываемый объект. Иначе говоря, в предположении, что существует декоратор с именем decorate , следующий код: @decoratedef target(): print('running target()') эквивалентен такому: def target(): print('running target()') target = decorate(target) Конечный результат одинаков: в конце обоих фрагментов имя target необя- зательно ссылается на исходную функцию target , это может быть любая другая функция, возвращенная в результате вызова decorate(target) . Чтобы убедиться, что декорируемая функция действительно заменена, рассмо- трим сеанс оболочки в примере 7.1. Пример 7.1. Декоратор обычно заменяет одну функцию другой >>> def deco(func): def inner(): print('running inner()') return inner /g110 >>> @deco def target(): /g111 print('running target()') >>> target() /g112 running inner()>>> target /g113 <function deco.<locals>.inner at 0x10063b598> /g110 deco возвращает свой внутренний объект-функцию inner . /g111 target декорирована deco . 1 Python поддерживает также декораторы классов. Они рассматриваются в главе 21.\n--- Страница 216 ---\n216 Глава 7. Декораторы функций и замыкания /g112 При вызове декорированной функции target на самом деле выполняется inner . /g113 Инспекция показывает, что target теперь ссылается на inner . Строго говоря, декораторы – не более чем синтаксическая глазурь. Как мы видели, всегда можно просто вызвать декоратор как обычный вызываемый объ-ект, передав ему функцию. Иногда это действительно удобно, особенно для ме- тапрограммирования – изменения поведения программы в процессе ее выпол- нения. Подведем итоги: главное, что нужно знать о декораторах, – тот факт, что они властны заменить декорируемую функцию другой. Второе – что они выполня-ются сразу после загрузки модуля. Этот момент мы объясним в следующем раз-деле. Когда Python выполняет декораторы Главное свойство декораторов – то, что они выполняются сразу после определе-ния декорируемой функции. Обычно на этапе импорта (т. е. когда Python загру- жает модуль). Рассмотрим скрипт registration.py в примере 7.2. Пример 7.2. Модуль registration.py registry = [] /g110 def register(func): /g111 print('running register(%s)' % func) /g112 registry.append(func) /g113 return func /g114 @register /g115 def f1(): print('running f1()') @register def f2(): print('running f2()') def f3(): /g116 print('running f3()') def main(): /g117 print('running main()') print('registry ->', registry) f1() f2() f3() if __name__=='__main__': main() /g118\n--- Страница 217 ---\n217 Когда Python выполняет декораторы /g110 В registry хранятся ссылки на функции, декорированные @register . /g111 register принимает функцию в качестве аргумента. /g112 Показываем, какая функция декорируется, – для демонстрации. /g113 Включаем func в registry . /g114 Возвращаем func : мы должны вернуть функцию, в данном случае возвра- щается та же функция, что была передана на входе. /g115 f1 и f2 декорированы @register . /g116 f3 не декорирована. /g117 main распечатывает registry , затем вызывает f1() , f2() и f3() . /g118 main() вызывается только тогда, когда registration.py запускается как скрипт. Будучи запущена как скрипт, программа registration.py выводит следующие строки: $ python3 registration.pyrunning register(<function f1 at 0x100631bf8>)running register(<function f2 at 0x100631c80>)running main()registry -> [<function f1 at 0x100631bf8>, <function f2 at 0x100631c80>]running f1()running f2()running f3() Отметим, что register выполняется (дважды) до любой другой функции в модуле. При вызове register получает в качестве аргумент декорируемый объект- функцию, например, <function f1 at 0x100631bf8> . После загрузки модуля в registry оказываются ссылки на две декорированные функции: f1 и f2. Они, как и функция f3, выполняются только при явном вызове из main . Если registration.py импортируется (а не запускается как скрипт), то вывод выглядит так: >>> import registrationrunning register(<function f1 at 0x10063b1e0>)running register(<function f2 at 0x10063b268>) Если сейчас заглянуть в registry , то мы увидим: >>> registration.registry[<function f1 at 0x10063b1e0>, <function f2 at 0x10063b268>] Основная цель примера 7.2 – подчеркнуть, что декораторы функций выпол- няются сразу после импорта модуля, но сами декорируемые функции – только в результате явного вызова. В этом проявляется различие между этапом импорта и этапом выполнения в Python. По сравнению с типичным применением декораторов в реальных программах пример 7.2 необычен в двух отношениях.\n--- Страница 218 ---\n218 Глава 7. Декораторы функций и замыкания • Функция-декоратор определена в том же модуле, что и декорируемые функции. Настоящий декоратор обычно определяется в одном модуле и применяется к функциям из других модулей. • Декоратор register возвращает ту же функцию, что была передана в ка- честве аргумента. На практике декоратор обычно определяет внутреннюю функцию и возвращает именно ее. Хотя декоратор register из примера 7.2 возвращает декорированную функцию без изменения, эта техника не бесполезна. Подобные декораторы используются во многих веб-каркасах, написанных на Python, с целью добавления функций в некий центральный реестр, например, для отображения образцов URL на функ-ции, генерирующие HTTP-ответы. Такие регистрационные декораторы могут из-менять декорируемую функцию, но это необязательно. В следующем разделе мы приведем практический пример. Паттерн Стратегия, дополненный декоратором Регистрационный декоратор послужит отличным дополнением к примеру при- менения скидки в Интернет-магазине из главы 6. Напомним, что в примере 6.6 мы столкнулись с проблемой повторения имен функций в определениях и в списке promos , который используется функцией best_promo для вычисления максимально возможной скидки. Такое повторение плохо тем, что программист может добавить новую функцию-стратегию, забыв включить ее в список promos , и тогда best_promo молча проигнорирует новую стра- тегию, а в системе появится тонкая ошибка. В примере 7.3 эта проблема решается с помощью регистрационного декоратора. Пример 7.3. Список promos заполняется декоратором promotion promos = [] /g110 def promotion(promo_func): /g111 promos.append(promo_func) return promo_func @promotion /g112 def fidelity(order): \"\"\"5%-ая скидка для заказчиков, имеющих не менее 1000 баллов лояльности\"\"\" return order.total() * .05 if order.customer.fidelity >= 1000 else 0 @promotion def bulk_item(order): \"\"\"10%-ая скидка для каждой позиции LineItem, в которой заказано не менее 20 единиц\"\"\" discount = 0 for item in order.cart:\n--- Страница 219 ---\n219 Правила видимости переменных if item.quantity >= 20: discount += item.total() * .1 return discount @promotion def large_order(order): \"\"\"7%-ая скидка для заказов, включающих не менее 10 различных позиций\"\"\" distinct_items = {item.product for item in order.cart} if len(distinct_items) >= 10: return order.total() * .07 return 0 def best_promo(order): /g113 \"\"\"Выбрать максимально возможную скидку \"\"\" return max(promo(order) for promo in promos) /g110 В начале список promos пуст. /g111 Декоратор promotion возвращает функцию promo_func без изменения, но добавляет ее в список promos . /g112 Все функции, декорированные @promotion , добавлены в promos . /g113 Функция best_promo не изменяется, поскольку зависит только от списка promos . По сравнению с другими решениями, представленными в разделе «Практиче- ский пример: переработка паттерна Стратегия» в главе 6, у этого есть несколько преимуществ. • Функции, реализующие стратегии вычисления скидки, не обязаны иметь специальные имена (с суффиксом _promo ). • Декоратор @promotion ясно описывает назначение декорируемой функции и без труда позволяет временно отменить предоставление ссылки: доста-точно закомментировать декоратор. • Стратегии скидки можно определить в других модулях, в любом месте си- стемы; главное – чтобы к ним применялся декоратор @promotion Большинство декораторов все же изменяют декорируемую функцию. Обычно для этого определяется некая внутренняя функция, которая заменяет декориру-емую. Код, в котором используются внутренние функции, неизбежно опирается на замыкания. Чтобы понять, что такое замыкания, нам придется отступить назад и тщательно разобраться с тем, как в Python работают области видимости пере-менных. Правила видимости переменных В примере 7.4 мы определяем и тестируем функцию, которая читает две перемен-ные: локальную переменную a, определенную как параметр функции, и перемен- ную b, которая внутри функции вообще не определена.\n--- Страница 220 ---\n220 Глава 7. Декораторы функций и замыкания Пример 7.4. Функция, читающая локальную и глобальную переменную >>> def f1(a): print(a) print(b) >>> f1(3)3Traceback (most recent call last): File \"<stdin>\", line 1, in <module> File \"<stdin>\", line 3, in f1NameError: global name 'b' is not defined Ошибка не должна вызывать удивления. Но если продолжить пример 7.4 и присвоить значение глобальной переменной b, а затем вызвать f1, то все заработает: >>> b = 6>>> f1(3)36 А теперь рассмотрим пример, который, возможно вас удивит.Взгляните на функцию f2 в примере 7.5. Первые две строчки в ней такие же, как в f1 из примера 7.4, но затем мы присваиваем значение переменной b. Однако функция завершается с ошибкой на втором предложении print , до присваивания. Пример 7.5. Переменная b локальна, потому что ей присваивается значение в теле функции >>> b = 6 >>> def f2(a): print(a) print(b) b = 9 >>> f2(3)3Traceback (most recent call last): File \"<stdin>\", line 1, in <module> File \"<stdin>\", line 3, in f2UnboundLocalError: local variable 'b' referenced before assignment Отметим, что число 3 все же напечатано, следовательно, предложение print(a) было выполнено. Но вот до print(b) дело так и не дошло. Впервые увидев этот пример, я очень удивился, так как думал, что 6 будет напечатано – ведь существует глобальная переменная b, а присваивание локальной b производится уже после print(b) . Однако же, компилируя тело этой функции, Python решает, что b – локальная переменная, т. к. ей присваивается значение внутри функции. Сгенерированный байт-код отражает это решение и пытается выбрать b из локального контекста. Позже, во время вызова f2(3) тело f2 успешно находит и печатает локальную пе-\n--- Страница 221 ---\n221 Правила видимости переменных ременную a, но при попытке получить значение локальной переменной b обнару- живает, что b не связана. Это не ошибка, а осознанный выбор: Python не заставляет нас объявлять пере- менные, но предполагает, что всякая переменная, которой присваивается значение в теле функции, локальна. Это гораздо лучше поведения JavaScript, который тоже не требует объявлять переменные, но если вы сделаете переменную локальной (с помощью зарезервированного слова var), то можете случайно затереть одно- именную глобальную переменную. Если нам нужно, чтобы интерпретатор считал переменную b глобальной, несмо- тря на присваивание внутри функции, то придется добавить объявление global : >>> def f3(a): global b print(a) print(b) b = 9 >>> f3(3)36>>> b9>>> f3(3)a = 3b = 8b = 30>>> b30>>> После этого краткого знакомства с принципом работы областей видимости в Python, мы можем приступить к замыканиям. А вниманию тех, кому интересно посмотреть, чем отличается байт-код функций из примеров 7.4 и 7.5, предлагается следующая врезка. Сравнение байт-кода Модуль dis позволяет без труда дизассемблировать байт-код функ- ций Python. В примерах 7.6 и 7.7 показан байт-код функций f1 и f2 из примеров 7.4 и 7.5. Пример 7.6. Дизассемблированная функция f1 из примера 7.4 >>> from dis import dis >>> dis(f1)2 0 LOAD_GLOBAL 0 (print) /g110 3 LOAD_FAST 0 (a) /g111 6 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 9 POP_TOP 3 10 LOAD_GLOBAL 0 (print)\n--- Страница 222 ---\n222 Глава 7. Декораторы функций и замыкания 13 LOAD_GLOBAL 1 (b) /g112 16 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 19 POP_TOP 20 LOAD_CONST 0 (None) 23 RETURN_VALUE /g110 Загрузить глобальное имя print . /g111 Загрузить локальное имя a. /g112 Загрузить глобальное имя b. А теперь сравните с байт-кодом функции f2 из примера 7.7. Пример 7.7. Дизассемблированная функция f1 из примера 7.5 >>> dis(f2) 2 0 LOAD_GLOBAL 0 (print) 3 LOAD_FAST 0 (a) 6 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 9 POP_TOP3 10 LOAD_GLOBAL 0 (print) 13 LOAD_FAST 1 (b) /g110 16 CALL_FUNCTION 1 (1 positional, 0 keyword pair) 19 POP_TOP4 20 LOAD_CONST 1 (9) 23 STORE_FAST 1 (b) 26 LOAD_CONST 0 (None) 29 RETURN_VALUE /g110 Загрузить локальное имя b. Как видим, компилятор считает b ло- кальной переменной, даже если присваивание b встречается позже, поскольку природа переменной – локальная она или нет – не долж-на приводить к изменению тела функции. Виртуальная машина CPython, которая исполняет байт-код, – это стековая машина, т. е. операции LOAD и POP относятся к стеку. Дальнейшее описание кодов операций Python выходит за рамки этой книги, но они документированы в разделе, посвященном модулю dis: «Дизассемблер байт-кода Python» ( http://docs.python.org/3/library/dis.html ). Замыкания В блогосфере замыкания иногда путают с анонимными функциями. Причина тому историческая: определение функций внутри функций кажется делом необычным, до тех пор пока мы не начинаем пользоваться анонимными функциями. А замы-кания вступают в игру только при наличии вложенных функций. Поэтому многие изучают обе концепции одновременно. На самом деле, замыкание – это функция с расширенной областью видимости, которая охватывает все неглобальные переменные, на которые есть ссылки в теле функции, хотя они в нем не определены. Не имеет значения, является функция\n--- Страница 223 ---\n223 Замыкания анонимной или нет; важно лишь, что она может обращаться к неглобальным пере- менным, определенным вне ее тела. Эту идею довольно трудно переварить, поэтому лучше продемонстрировать ее на примере. Рассмотрим функцию avg, которая вычисляет среднее продолжающегося ряда чисел, например, среднюю цену закрытия биржевого товара за всю историю тор-гов. Каждый день ряд пополняется новой ценой, а при вычислении среднего учи-тываются все прежние цены. Если начать с чистого листа, то функцию avg можно было бы использовать сле- дующим образом: >>> avg(10)10.0>>> avg(11)10.5>>> avg(12)11.0 Откуда берется avg и где она хранит предыдущие значения? Для начала покажем реализацию, основанную на классах. Пример 7.8. average_oo.py: класс для вычисления накопительного среднего class Averager(): def __init__(self): self.series = [] def __call__(self, new_value): self.series.append(new_value) total = sum(self.series) return total/len(self.series) Класс Averager создает вызываемые объекты: >>> avg = Averager()>>> avg(10)10.0>>> avg(11)10.5>>> avg(12)11.0 А теперь покажем функциональную реализацию с использованием функции высшего порядка make_averager . Пример 7.9. average.py: функция высшего порядка для вычисления накопительного среднего def make_averager(): series = [] def averager(new_value):\n--- Страница 224 ---\n224 Глава 7. Декораторы функций и замыкания series.append(new_value) total = sum(series) return total/len(series) return averager При обращении к make_averager возвращается объект-функция averager . При каждом вызове averager добавляет переданный аргумент в конец списка series и вычисляет текущее среднее, как показано в примере 7.10. Пример 7.10. Тестирование функции из примера 7.9 >>> avg = make_averager() >>> avg(10)10.0>>> avg(11)10.5>>> avg(12)11.0 Обратите внимание на сходство обоих примеров: мы обращаемся к Averager() или к make_averager() , чтобы получить вызываемый объект avg, который обнов- ляет временной ряд и вычисляет текущее среднее. В примере 7.8 avg – экземпляр Averager , а в примере 7.9 – внутренняя функция averager . И в том, и в другом случае мы просто вызываем avg(n) , чтобы добавить n в ряд и вычислить новое среднее. Совершенно ясно, где хранит историю объект avg класса Averager : в атрибуте экземпляра self.series . Но где находит series функция avg из второго примера? Обратите внимание, что series – локальная переменная make_averager , потому что инициализация series = [] производится в теле этой функции. Но к моменту вызова avg(10) функция make_averager уже вернула управление, и ее локальная область видимости уничтожена. Внутри averager series является свободной пере- менной . Этот технический термин означает, что переменная не связана в локаль- ной области видимости. См. рис. 7.1. Инспекция возвращенного объекта averager показывает, что Python хранит имена локальных и свободных переменных в атрибуте __code__ , который пред- ставляет собой откомпилированное тело функции. Это показано в примере 7.11. Пример 7.11. Инспекция функции, созданной функцией make_averager из примера 7.9 >>> avg.__code__.co_varnames ('new_value', 'total')>>> avg.__code__.co_freevars('series',) Привязка переменной series хранится в атрибуте __closure__ возвращенной функции avg. Каждому элементу avg.__closure__ соответствует имя в avg. __code__.co_freevars . Эти элементы называются ячейками ( cells ), и у каждого\n--- Страница 225 ---\n225 Объявление nonlocal из них есть атрибут cell_contents , где можно найти само значение. Эти атрибуты демонстрируются в примере 7.12. Рис. 7.1. Замыкание averager расширяет область видимости функции, включая в нее привязку свободной переменной series Пример 7.12. Продолжение примера 7.10 >>> avg.__code__.co_freevars ('series',)>>> avg.__closure__(<cell at 0x107a44f78: list object at 0x107a91a48>,)>>> avg.__closure__[0].cell_contents[10, 11, 12] Резюмируем: замыкание – это функция, которая запоминает привязки свобод- ных переменных, существовавшие на момент определения функции, так что их можно использовать впоследствии при вызове функции, когда область видимо-сти, в которой она была определена, уже не существует. Отметим, что единственная ситуация, когда функции может понадобиться до- ступ к внешним неглобальным переменным, – это когда она вложена в другую функцию. Объявление nonlocal Приведенная выше реализация функции make_averager неэффективна. В приме- ре 7.9 мы храним все значения во временном ряде и вычисляем их сумму при каж-дом вызове averager . Лучше было бы хранить предыдущую сумму и количество элементов, тогда, зная эти два числа, можно вычислить новое среднее. Реализация в примере 7.13 некорректна и приведена только в педагогических целях. Сможете ли вы найти ошибку? Пример 7.13. Неправильная функция высшего порядка для вычисления накопительного среднего без хранения всей истории def make_averager(): count = 0замыкание свободная переменная\n--- Страница 226 ---\n226 Глава 7. Декораторы функций и замыкания total = 0 def averager(new_value): count += 1 total += new_value return total / count return averager При попытке выполнить этот код получится вот что: >>> avg = make_averager() >>> avg(10)Traceback (most recent call last): UnboundLocalError: local variable 'count' referenced before assignment>>> Проблема в том, что предложение count += 1 означает то же самое, что count = count + 1 , где count – число или любой неизменяемый тип. То есть мы по сути дела присваиваем count значение в теле averager , делая ее тем самым локальной переменной. То же относится к переменной total . В примере 7.9 этой проблемы не было, потому что мы ничего не присваивали переменной series ; мы лишь вызывали series.append и передавали ее функциям sum и len. То есть воспользовались тем, что список – изменяемый тип. Однако переменные неизменяемых типов – числа, строки, кортежи и т. д. – раз- решается только читать, но не изменять. Если попытаться перепривязать такую переменную, как в случае count = count + 1 , то мы неявно создадим локальную переменную count . Она уже не является свободной и потому не запоминается в замыкании. Чтобы обойти эту проблему, в Python 3 было добавлено объявление nonlocal . Оно позволяет пометить переменную как свободную, даже если ей присваивается новое значение внутри функции. В таком случае изменяется привязка, храняща-яся в замыкании. Корректная реализация функции make_averager показана в при- мере 7.14. Пример 7.14. Вычисление накопительного среднего без хранения всей истории (исправленный вариант с nonlocal ) def make_averager(): count = 0 total = 0 def averager(new_value): nonlocal count, total count += 1 total += new_value return total / count return averager\n--- Страница 227 ---\n227 Реализация простого декоратора Жизнь без nonlocal в Python 2 Из-за отсутствия слова nonlocal в Python 2 приходится изо- бретать обходные пути, один из которых описан в третьем фраг-менте кода в документе «PEP 3104 – Access to Names in Outer Scopes» (http://www.python.org/dev/peps/pep-3104/), где впер-вые вводится слово nonlocal . По существу, идея сводится к тому, чтобы хранить переменные, которые внутренняя функция должна изменять (например, count и total ), в элементах или атрибутах какого-нибудь изменяемого объекта, скажем словаря или просто экземпляра класса, и связать этот объект со свобод-ной переменной. Теперь, познакомившись с замыканиями в Python, мы можем продемон- стрировать эффективную реализацию декораторов с помощью вложенных функций. Реализация простого декоратора В примере 7.15 показан декоратор, который хронометрирует каждый вызов де-корируемой функции и печатает затраченное время, переданные аргументы и ре-зультат. Пример 7.15. Простой декоратор для вывода времени выполнения функции import time def clock(func): def clocked(*args): # /g110 t0 = time.perf_counter() result = func(*args) # /g111 elapsed = time.perf_counter() - t0 name = func.__name__ arg_str = ', '.join(repr(arg) for arg in args) print('[%0.8fs] %s(%s) -> %r' % (elapsed, name, arg_str, result)) return result return clocked # /g112 /g110 Определяем внутреннюю функцию clocked , принимающую произвольное число позиционных аргументов. /g111 Эта функция работает только потому, что замыкание clocked включает сво- бодную переменную func . /g112 Возвращаем внутреннюю функцию взамен декорируемой. В примере 7.16 демонстрируется использование декоратора clock .\n--- Страница 228 ---\n228 Глава 7. Декораторы функций и замыкания Пример 7.16. Использование декоратора clock # clockdeco_demo .py import time from clockdeco import clock @clock def snooze(seconds): time.sleep(seconds) @clock def factorial(n): return 1 if n < 2 else n*factorial(n-1) if __name__=='__main__': print('*' * 40, 'Calling snooze(.123)') snooze(.123) print('*' * 40, 'Calling factorial(6)') print('6! =', factorial(6)) Вот что выводит этот код: $ python3 clockdeco_demo.py**************************************** Calling snooze(123)[0.12405610s] snooze(.123) -> None**************************************** Calling factorial(6)[0.00000191s] factorial(1) -> 1[0.00004911s] factorial(2) -> 2[0.00008488s] factorial(3) -> 6[0.00013208s] factorial(4) -> 24[0.00019193s] factorial(5) -> 120[0.00026107s] factorial(6) -> 7206! = 720 Как это работает Напомним, что код @clockdef factorial(n): return 1 if n < 2 else n*factorial(n-1) на самом деле эквивалентен следующему: def factorial(n): return 1 if n < 2 else n*factorial(n-1) factorial = clock(factorial) То есть в обоих случаях декоратор clock получает функцию factorial в качестве аргумента func (см. пример 7.15). Затем он создает и возвращает функцию clocked , которую интерпретатор Python за кулисами связывает с именем factorial . На са-\n--- Страница 229 ---\n229 Реализация простого декоратора мом деле, если импортировать модуль clockdeco_demo и вывести атрибут __name__ функции factorial , то мы увидим: >>> import clockdeco_demo>>> clockdeco_demo.factorial.__name__'clocked'>>> Таким образом, factorial действительно хранит ссылку на функцию clocked . Начиная с этого момента, при каждом вызове factorial(n) выполняется clocked(n) . А делает clocked вот что: 1. Запоминает начальный момент времени t0. 2. Вызывает исходную функцию factorial и сохраняет результат. 3. Вычисляет, сколько прошло времени.4. Форматирует и печатает собранные данные.5. Возвращает результат, сохраненный на шаге 2. Это типичное поведение декоратора: заменить декорируемую функцию новой, которая принимает те же самые аргументы и (как правило) возвращает то, что должна была бы вернуть декорируемая функция, но при этом произвести какие-то дополнительные действия. В книге Г амма и др. «Паттерны проектирования» краткое опи- сание паттерна Декоратор начинается словами: «Динамически добавляет объекту новые обязанности». Декораторы функций отвечают этому описанию. Но на уровне реализации декораторы в Python имеют мало общего с классическим Декоратором, опи-санным в оригинальной книге. Ниже, во врезке «Поговорим», я еще вернусь к этой теме. Декоратор clock , реализованный в примере 7.15, имеет ряд недостатков: он не поддерживает именованные аргументы и маскирует атрибуты __name__ и __doc__ декорированной функции. В примере 7.17 используется декоратор functools. wraps , который копирует необходимые атрибуты из func в clocked . К тому же, в этой новой версии правильно обрабатываются именованные аргументы. Пример 7.17. Улучшенный декоратор clock # clockdeco2.py import time import functools def clock(func): @functools.wraps(func) def clocked(*args, **kwargs): t0 = time.time()\n--- Страница 230 ---\n230 Глава 7. Декораторы функций и замыкания result = func(*args, **kwargs) elapsed = time.time() - t0 name = func.__name__ arg_lst = [] if args: arg_lst.append(', '.join(repr(arg) for arg in args)) if kwargs: pairs = ['%s=%r' % (k, w) for k, w in sorted(kwargs.items())] arg_lst.append(', '.join(pairs)) arg_str = ', '.join(arg_lst) print('[%0.8fs] %s(%s) -> %r ' % (elapsed, name, arg_str, result)) return result return clocked Декоратор functools.wraps – лишь один из нескольких готовых декораторов в стандартной библиотеке. В следующем разделе мы рассмотрим два наиболее впе- библиотеке. В следующем разделе мы рассмотрим два наиболее впе- е. В следующем разделе мы рассмотрим два наиболее впе- чатляющих декоратора в модуле functools : lru_cache и singledispatch . Декораторы в стандартной библиотеке В Python есть три встроенные функции, предназначенные для декорирования ме-тодов: property , classmethod и staticmethod . Функцию property мы обсудим в раз- деле «Использование свойств для контроля атрибутов» на стр. 633, а остальные – в разделе «Декораторы classmethod и staticmethod» на стр. 281. Еще один часто встречающийся декоратор – functools.wraps , вспомогательное средство для построения корректных декораторов, которым мы воспользовались в примере 7.17. Два самых интересных декоратора в стандартной библиотеке – lru_cache и совсем новый singledispatch (добавлен в версии Python 3.4). Оба определены в модуле functools . Их мы далее и рассмотрим. Кэширование с помощью functools.lru_cache Декоратор functools.lru_cache очень полезен на практике. Он реализует «за- поминание» (memoization): прием оптимизации, смысл которого заключается в сохранении результатов предыдущих дорогостоящих вызовов функции, что по-зволяет избежать повторного вычисления с теми же аргументами, что и раньше. Акроним LRU расшифровывается как «Least Recently Used» (последний исполь-зованный); это означает, что рост кэша ограничивается путем вытеснения тех эле-ментов, к которым давно не было обращений. Продемонстрируем применение lru_cache на примере медленной рекурсивной функции вычисления n-ого числа Фибоначчи. Пример 7.18. Очень накладный рекурсивный способ вычисления n-ого числа Фибоначчи from clockdeco import clock @clock\n--- Страница 231 ---\n231 Декораторы в стандартной библиотеке def fibonacci(n): if n < 2: return n return fibonacci(n-2) + fibonacci(n-1) if __name__=='__main__': print(fibonacci(6)) Вот результат работы fibo_demo.py . Все строки, кроме последней, выведены де- коратором clock : $ python3 fibo_demo.py[0.00000095s] fibonacci(0) -> 0[0.00000095s] fibonacci(1) -> 1[0.00007892s] fibonacci(2) -> 1[0.00000095s] fibonacci(1) -> 1[0.00000095s] fibonacci(0) -> 0[0.00000095s] fibonacci(1) -> 1[0.00003815s] fibonacci(2) -> 1[0.00007391s] fibonacci(3) -> 2[0.00018883s] fibonacci(4) -> 3[0.00000000s] fibonacci(1) -> 1[0.00000095s] fibonacci(0) -> 0[0.00000119s] fibonacci(1) -> 1[0.00004911s] fibonacci(2) -> 1[0.00009704s] fibonacci(3) -> 2[0.00000000s] fibonacci(0) -> 0[0.00000000s] fibonacci(1) -> 1[0.00002694s] fibonacci(2) -> 1[0.00000095s] fibonacci(1) -> 1[0.00000095s] fibonacci(0) -> 0[0.00000095s] fibonacci(1) -> 1[0.00005102s] fibonacci(2) -> 1[0.00008917s] fibonacci(3) -> 2[0.00015593s] fibonacci(4) -> 3[0.00029993s] fibonacci(5) -> 5[0.00052810s] fibonacci(6) -> 88 Непроизводительные затраты бросаются в глаза: fibonacci(1) вызывается во- семь раз, fibonacci(2) – пять раз и т. д. Но если добавить две строчки, чтобы за- действовать lru_cache , то производительност резко возрастет. Пример 7.19. Более быстрая реализация с использованием кэширования import functools from clockdeco import clock@functools.lru_cache() # /g110 @clock # /g111 def fibonacci(n): if n < 2:\n--- Страница 232 ---\n232 Глава 7. Декораторы функций и замыкания return n return fibonacci(n-2) + fibonacci(n-1) if __name__=='__main__': print(fibonacci(6)) /g110 Отметим, что lru_cache следует вызывать как обычную функцию – обра- тите внимание на скобки: @functools.lru_cache() . Причина в том, что этот декоратор принимает конфигурационные параметры, как будет показано ниже. /g111 Это пример композиции декораторов: lru_cache() применяется к функции, возвращенной декоратором @clock . Время выполнения уменьшилось вдвое, а функция вызывается всего один раз для каждого значения n: $ python3 fibo_demo_lru.py [0.00000119s] fibonacci(0) -> 0[0.00000119s] fibonacci(1) -> 1[0.00010800s] fibonacci(2) -> 1[0.00000787s] fibonacci(3) -> 2[0.00016093s] fibonacci(4) -> 3[0.00001216s] fibonacci(5) -> 5[0.00025296s] fibonacci(6) -> 8 В другом тесте для вычисления fibonacci(30) программа из примера 7.19 вы- полнила 31 вызов за 0,0005 с, тогда как программа без кэширования из приме-ра 7.18 обращалась к функции fibonacci 2 692 537 и затратила на это 17,7 с на ноутбуке с процессором Intel Core i7. Но lru_cache умеет не только исправлять плохо написанные рекурсивные алгоритмы, во всем блеске он проявляется, когда нужно прочитать данные из веба. Важно отметить, что lru_cache можно настроить, передав два необязательных аргумента. Полная сигнатура выглядит так: functools .lru_cache(maxsize=128, typed=False) Аргумент maxsize определяет, сколько результатов вызова хранить. Когда кэш заполнится, старые результаты начнут вытесняться, чтобы освободить место для новых. Для достижения оптимальной производительности значение maxsize должно быть степенью двойки. Если аргумент typed равен True , то результаты для аргументов разных типов хранятся порознь, т. е. аргументы типа float и integer, которые обычно считаются равными, например, 1 и 1.0, теперь становятся различ-ными. Кстати, lru_cache хранит результаты в словаре dict , ключи которого состав- лены из позиционных и именованных аргументов вызовов, а это значит, что все аргументы, принимаемые декорируемой функцией, должны быть хэшируемыми . Теперь рассмотрим интригующий декоратор functools.singledispatch .\n--- Страница 233 ---\n233 Декораторы в стандартной библиотеке Одиночная диспетчеризация и обобщенные функции Пусть требуется написать инструмент для отладки веб-приложений. Мы хо- тим, чтобы он умел генерировать HTML-представления объектов Python разного типа. Можно было бы начать с такой функции: import html def htmlize(obj): content = html.escape(repr(obj)) return '<pre>{}</pre>'.format(content) Она будет работать для любого типа Python, но нам хотелось бы, чтобы для некоторых типов генерировались специальные представления: • str: заменять внутренние символы новой строки строкой '<br>\\n' и ис- пользовать теги <p> вместо <pre> ; • int: показывать число в десятичном и шестнадцатеричном виде; • list : выводить HTML-список, в котором каждый элемент отформатиро- ван в соответствии со своим типом. Желательное поведение показано в примере 7.20. Пример 7.20. Функция htmlize генерирует HTML-представление объектов разных типов >>> htmlize({1, 2, 3}) /g110 '<pre>{1, 2, 3}</pre>'>>> htmlize(abs)'<pre>&lt;built-in function abs&gt;</pre>'>>> htmlize('Heimlich & Co.\\n- a game') /g111 '<p>Heimlich &amp; Co.<br>\\n- a game</p>'>>> htmlize(42) /g112 '<pre>42 (0x2a)</pre>'>>> print(htmlize(['alpha', 66, {3, 2, 1}])) /g113 <ul><li><p>alpha</p></li><li><pre>66 (0x42)</pre></li><li><pre>{1, 2, 3}</pre></li></ul> /g110 По умолчанию HTML-представление объекта помещается между тегами <pre> и </pre> . /g111 Объекты типа str обертываются тегами <p> и </p> , а разрыв строки обозна- чается тегом <br> . /g112 Число типа int показывается в десятичном и шестнадцатеричном виде между тегами <pre> и </pre> .\n--- Страница 234 ---\n234 Глава 7. Декораторы функций и замыкания /g113 Каждый элемент списка форматируется в соответствии со своим типом, а вся последовательность оформляется как HTML-список. Поскольку в Python нет механизма перегрузки методов или функций, то мы не можем создать варианты htmlize с разными сигнатурами для каждого типа дан- ных, который желательно обрабатывать специальным образом. Общее решение состоит в том, чтобы преобразовать htmlize в функцию диспетчеризации, содер- жащую предложение if с несколькими ветвями elif , в каждой из которых вы- зывается некая специализированная функция: htmlize_str , htmlize_int и т. д. Но такое решение не поддается расширению пользователями модуля и слишком не-уклюже: со временем диспетчер htmlize чрезмерно разрастется, а связь между ним и специализированными функциями станет недопустимо тесной. Новый декоратор functools.singledispatch , появившийся в Python 3.4, позво- ляет каждому модулю вносить свой вклад в общее решение, так что пользователь легко может добавить специализированную функцию, даже не имея возможности изменять класс. Обычная функция, декорированная @singledispatch , становится обобщенной функцией : группой функций, выполняющих одну и ту же логическую операцию по-разному в зависимости от типа первого аргумента2. В примере 7.21 показано, как это делается. Декоратор functools .singledispatch добавлен в версии Python 3.4, но в архиве PyPI имеется пакет singledispatch (https:// pypi.python.org/pypi/singledispatch ), для обратной совместимо- сти с версиями от Python 2.6 до 3.3. Пример 7.21. Декоратор singledispatch создает функцию htmlize.register для объединения нескольких функций в одну обобщенную from functools import singledispatch from collections import abcimport numbersimport html @singledispatch /g110 def htmlize(obj): content = html.escape(repr(obj)) return '<pre>{}</pre>'.format(content) @htmlize.register(str) /g111 def _(text): /g112 content = html.escape(text).replace('\\n', '<br>\\n') return '<p>{0}</p>'.format(content) @htmlize.register(numbers.Integral) /g113 2 Именно это и называется одиночной диспетчеризацией . Если бы для выбора конкретных функций использовалось больше аргументов, то мы имели бы множественную диспетчеризацию.\n--- Страница 235 ---\n235 Декораторы в стандартной библиотеке def _(n): return '<pre>{0} (0x{0:x})</pre>'.format(n) @htmlize.register(tuple) /g114 @htmlize.register(abc.MutableSequence)def _(seq): inner = '</li>\\n<li>'.join(htmlize(item) for item in seq) return '<ul>\\n<li>' + inner + '</li>\\n</ul>' /g110 @singledispatch помечает базовую функцию, которая обрабатывает тип object . /g111 Каждая специализированная функция снабжается декоратором @«base_ function» .register(«type») . /g112 Имена специализированных функций несущественны, и это подчеркнуто выбором _ в качестве имени. /g113 Для каждого типа, нуждающегося в специальной обработке, регистрирует- ся новая функция. numbers .Integral – виртуальный суперкласс int. /g114 Можно указывать несколько декораторов register , если требуется, чтобы одна функция поддерживала несколько типов. По возможности старайтесь регистрировать специализированные функции для обработки абстрактных базовых классов, например numbers.Integral или abc.MutableSequence , а не конкретных реализаций типа int и list . Тогда ваш код сможет поддержать больше совместимых типов. Например, гипотетическое рас-ширение Python могло бы предложить альтернативы типу int с фиксированным количеством разрядов в виде подклассов numbers.Integral . Использование абстрактных базовых классов для проверки типов открывает возможность для поддержки существующих и будущих классов, являющихся как фактическими, так и виртуальными под- виртуальными под- ыми под- классами этих ABC. Применение ABC и концепция виртуального подкласса – темы главы 11. Замечательное свойство механизма singledispatch состоит в том, что специ- ализированные функции можно зарегистрировать в любом месте системы, в лю-бом модуле. Если впоследствии вы добавите модуль, содержащий новый поль-зовательский тип, то сможете без труда написать новую специализированную функцию для обработки этого типа. А также реализовать функции обработки для классов, которые вы не писали и не можете изменить. Декоратор singledispatch – продуманное дополнение к стандартной библиоте- ке, его возможности шире, чем описано выше. Лучше всего он описан в документе «PEP 443 – Single-dispatch generic functions» ( https://www.python.org/dev/peps/ pep-0443/ ).\n--- Страница 236 ---\n236 Глава 7. Декораторы функций и замыкания Декоратор @singledispatch задуман не для того, чтобы перене- сти в Python перегрузку методов в духе Java. Один класс с несколь-кими перегруженными вариантами метода лучше одной функции с длинной цепочкой предложений if/elif/elif/elif . Но оба ре- шения грешат тем, что поручают слишком много обязанностей одной единице программы – классу или функции. Преимущество @singledispath – в поддержке модульного расширения: каждый модуль может зарегистрировать специализированную функцию для того типа, который поддерживает . Декораторы – это функции, а, значит, можно составлять их композиции (т. е. применять декоратор к уже декорированной функции, как показано в приме-ре 7.21). В следующем разделе объясняется, как это работает. Композиции декораторов В примере 7.19 было продемонстрировано применение композиции декораторов: @lru_cache применяется к результату применения декоратора @clock к функции fibonacci . В примере 7.21 декоратор @htmlize.register дважды применяется к по- следней функции в модуле. Когда два декоратора @d1 и @d2 применяются к одной функции f в указанном порядке, получается то же самое, что в результате композиции f = d1(d2(f)) . Иными словами, код: @d1@d2def f(): print('f') эквивалентен следующему: def f(): print('f') f = d1(d2(f)) Помимо композиции декораторов, в этой главе уже встречались декораторы, принимающие аргументы, например @lru_cache() и htmlize.register( 'type ') в примере 7.21. В следующем разделе описано, как создавать декораторы с параме-трами. Параметризованные декораторы Разбирая декоратор, встретившийся в исходном коде, Python берет декорируемую функцию и передает ее в качестве первого аргумента функции-декоратору. А как\n--- Страница 237 ---\n237 Параметризованные декораторы сделать, чтобы декоратор принимал и другие аргументы? Ответ таков: написать фабрику декораторов, которая принимает эти аргументы и возвращает декоратор, который затем применяется к декорируемой функции. Непонятно? Естественно. Начнем с примера, основанного на простейшем из рассмотренных до сих пор де-кораторов: register (см. пример 7.22). Пример 7.22. Модуль registration.py из примера 7.2 повторен для удобства registry = [] def register(func): print('running register(%s)' % func) registry.append(func) return func @register def f1(): print('running f1()') print('running main()') print('registry ->', registry)f1() Параметризованный регистрационный декоратор Чтобы функцию регистрации, вызываемую декоратором register , можно было активировать и деактивировать, мы снабдим ее необязательным параметром ac- tive : если он равен False , то декорируемая функция не регистрируется. В при- мере 7.23 показано, как это делается. Концептуально новая функция register – не декоратор, а фабрика декораторов. Будучи вызвана, она возвращает настоящий декоратор, который применяется к декорируемой функции. Пример 7.23. Чтобы декоратор мог принимать параметры, его следует вызывать как функцию registry = set() /g110 def register(active=True): /g111 def decorate(func): /g112 print('running register(active=%s)->decorate(%s)' % (active, func)) if active: /g113 registry.add(func) else: registry.discard(func) /g114 return func /g115\n--- Страница 238 ---\n238 Глава 7. Декораторы функций и замыкания return decorate /g116 @register(active=False) /g117 def f1(): print('running f1()') @register() /g118 def f2(): print('running f2()') def f3(): print('running f3()') /g110 Теперь registry имеет тип set, чтобы ускорить добавление и удаление функций. /g111 Функция register принимает необязательный именованный аргумент. /g112 Собственно декоратором является внутренняя функция decorate , она при- нимает в качестве аргумента функцию. /g113 Регистрируем func , только если аргумент active (определенный в замыка- нии) равен True . /g114 Если not active и функция func присутствует в registry , удаляем ее. /g115 Поскольку decorate – декоратор, он должен возвращать функцию. /g116 Функция register – наша фабрика декораторов, поэтому она возвращает decorate . /g117 Фабрику @register следует вызывать как функцию, передавая ей нужные параметры. /g118 Даже если параметров нет, register все равно нужно вызывать как функ- цию – @register() – чтобы она вернула настоящий декоратор decorate . Идея в том, что функция register() возвращает декоратор decorate , который затем применяется к декорируемой функции. Код из примера 7.23 находится в модуле registration_param.py . Если его импор- тировать, получится вот что: >>> import registration_paramrunning register(active=False)->decorate(<function f1 at 0x10063c1e0>)running register(active=True)->decorate(<function f2 at 0x10063c268>)>>> registration_param.registry[<function f2 at 0x10063c268>] Заметим, что в registry присутствует только функция f2, а функция f1 туда не попала, потому что фабрике декораторов register был передан аргумент active=False . Если бы мы использовали register как обычную функцию без символа @, то для декорирования функции f, т. е. для добавления ее в registry , нужно было бы написать register()(f) , а чтобы не добавлять f в реестр (или удалить оттуда) – register(active=False)(f) . В примере 7.24 показано, как добавлять функции в ре- естр registry и удалять из него.\n--- Страница 239 ---\n239 Параметризованные декораторы Пример 7.24. Использование модуля registration_param из примера 7.23 >>> from registration_param import * running register(active=False)->decorate(<function f1 at 0x10073c1e0>)running register(active=True)->decorate(<function f2 at 0x10073c268>)>>> registry # /g110 {<function f2 at 0x10073c268>} >>> register()(f3) # /g111 running register(active=True)->decorate(<function f3 at 0x10073c158>) <function f3 at 0x10073c158> >>> registry # /g112 {<function f3 at 0x10073c158>, <function f2 at 0x10073c268>} >>> register(active=False)(f2) # /g113 running register(active=False)->decorate(<function f2 at 0x10073c268>) <function f2 at 0x10073c268> >>> registry # /g114 {<function f3 at 0x10073c158>} /g110 После импортирования модуля f2 оказывается в registry . /g111 Выражение register() возвращает декоратор decorate , который затем при- меняется к f3. /g112 В предыдущей строке функция f3 была добавлена в registry . /g113 Этот вызов удаляет f2 из registry . /g114 Убеждаемся, что f3 осталась в registry . Механизм работы параметризованных декораторов довольно сложен; рассмо- тренный выше пример проще, чем в большинстве случаев. Параметризованные декораторы обычно заменяют декорируемую функцию, а в их конструкторах не-обходимо еще один уровень вложенности. В экскурсию по такой пирамиде функ- ций мы отправимся в следующем разделе. Параметризованный декоратор clock В этом разделе мы вернемся к декоратору clock и добавим возможность пере- давать ему строку, управляющую форматом вывода. См. пример 7.25. Для простоты код в примере 7.25 основан на первоначальной реализации clock в примере 7.15, а не на улучшенной реализа- ции из примера 7.17, в которой использовался декоратор @func- tools.wraps , добавляющий еще один слой. Пример 7.25. Модуль clockdeco_param.py : параметризованный декоратор clock import time DEFAULT_FMT = '[{elapsed:0.8f}s] {name}({args}) -> {result}' def clock(fmt=DEFAULT_FMT): /g110\n--- Страница 240 ---\n240 Глава 7. Декораторы функций и замыкания def decorate(func): /g111 def clocked(*_args): /g112 t0 = time.time() _result = func(*_args) /g113 elapsed = time.time() - t0 name = func.__name__ args = ', '.join(repr(arg) for arg in _args) /g114 result = repr(_result) /g115 print(fmt.format(**locals())) /g116 return _result /g117 return clocked /g118 return decorate /g119 if __name__ == '__main__': @clock() ⤓ def snooze(seconds): time.sleep(seconds) for i in range(3): snooze(.123) /g110 Теперь clock – наша фабрика параметризованных декораторов. /g111 decorate – это собственно декоратор. /g112 clocked обертывает декорированную функцию. /g113 _result – результат, возвращенный декорированной функцией. /g114 В _args хранятся фактические аргументы clocked , тогда как args – отобра- жаемая строка. /g115 result – строковое представление _result , предназначенное для отображе- ния. /g116 Использование **locals() позволяет ссылаться в fmt на любую локальную переменную clocked . /g117 clocked заменяет декорированную функцию, поэтому должна возвращать то, что вернула бы эта функция в отсутствие декоратора. /g118 decorate возвращает clocked . /g119 clock возвращает decorate . ⤓ В этом тесте clock() вызывается без аргументов, поэтому декоратор будет использовать форматную строку по умолчанию. При выполнении программы из примера 7.25 печатается следующее: $ python3 clockdeco_param.py [0.12412500s] snooze(0.123) -> None[0.12411904s] snooze(0.123) -> None[0.12410498s] snooze(0.123) -> None Для демонстрации новой функциональности в примерах 7.26 и 7.27 показаны еще два модуля, в которых используется clockdeco_param , а также результаты их выполнения.\n--- Страница 241 ---\n241 Параметризованные декораторы Пример 7.26. clockdeco_param_demo1.py import time from clockdeco_param import clock @clock('{name}: {elapsed}s') def snooze(seconds): time.sleep(seconds) for i in range(3): snooze(.123) Результат выполнения примера 7.26: $ python3 clockdeco_param_demo1.pysnooze: 0.12414693832397461ssnooze: 0.1241159439086914ssnooze: 0.12412118911743164s Пример 7.27. clockdeco_param_demo2.py import time from clockdeco_param import clock @clock('{name}({args}) dt={elapsed:0.3f}s') def snooze(seconds): time.sleep(seconds) for i in range(3): snooze(.123) Результат выполнения примера 7.27: $ python3 clockdeco_param_demo2.pysnooze(0.123) dt=0.124ssnooze(0.123) dt=0.124ssnooze(0.123) dt=0.124s На этом мы завершаем изучение декораторов, поскольку объем книги не позволяет развить эту тему дальше. См. ниже раздел «Дополнительная литература» и в особенности блог Грэхема Дамплтона (Graham Dumpleton) и модуль wrapt , содержащий профессиональные приемы построения декораторов. Грэхем Дамплтон и Леннарт Регебро – один из рецензентов этой книги – считают , что декораторы лучше писать как классы, реа-лизующие метод __call__ , а не как функции (как в примерах из этой главы). Согласен, что для нетривиальных декораторов такой подход разумнее, но функции проще, когда требуется объяснить основную идею этого механизма.\n--- Страница 242 ---\n242 Глава 7. Декораторы функций и замыкания Резюме В этой главе мы рассмотрели обширный материал, но я старался сделать путеше- ствие по возможности комфортабельным, хотя дорога была ухабистой. Ведь мы по существу вступили на территорию метапрограммирования. Мы начали с простого декоратора @register без внутренней функции и закон- чили параметризованным декоратором @clock() с двумя уровнями вложенных функций. Регистрационные декораторы, хотя и простые по существу, находят реальные применения в развитых каркасах на Python. Мы воспользовались идеей регистра-ции, чтобы улучшить реализацию паттерна проектирования Стратегия из главы 6. Параметризованные декораторы почти всегда содержат по меньшей мере две вложенные функции, а иногда и больше, если мы хотим использовать @functools. wraps для создания декоратора, который лучше поддерживает некоторые продви- нутые возможности. Одну такую возможность – композицию декораторов – мы вкратце рассмотрели. Мы также познакомились с двумя впечатляющими декораторами функций из модуля стандартной библиотеки functools : @lru_cache() и @singledispatch . Для понимания механизма работы декораторов понадобилось разобраться в различиях между этапом импорта и этапом выполнения , в областях действия пе- ременных, в замыканиях и в новом ключевом слове nonlocal . Свободное владение замыканиями и объявлением nonlocal важно не только при написании декорато- ров, но и при разработке событийно-ориентированных программ с графическим интерфейсом, а также для асинхронного ввода-вывода без обратных вызовов. Дополнительная литература В главе 9 «Метапрограммирование» книги David Beazley, Brian K. Jones «Python Cookbook», издание 3 (O'Reilly), есть несколько рецептов – от элементарных де-кораторов до очень сложных, в том числе такого, который можно вызывать либо как обычный декоратор, либо как фабрику декораторов, например @clock или @clock() . Это рецепт 9.6 «Определение декоратора, принимающего необязатель- ный аргумент». Грэхем Дамплтон опубликовал в своем блоге ( http://bit.ly/1DePPcl ) серию ста- тей о способах реализации корректно работающих декораторов, и первая из них называется «How Y ou Implemented Y our Python Decorator is Wrong» (Ваш способ реализации декоратора в Python неправильный) ( http://bit.ly/1DePVRi ). Его об- ширный опыт в этой области аккуратно инкапсулирован в модуль wrapt (http:// wrapt.readthedocs.org/en/latest/ ), написанный с целью упростить реализацию де- кораторов и динамических функций-оберток, которые поддерживают интроспек-цию и корректно ведут себя, если еще раз подвергаются декорированию, а также в случае применения к методам и использования в качестве дескрипторов (дескрип-торы – тема главы 20).\n--- Страница 243 ---\n243 Поговорим Мишель Симионато (Michele Simionato) написал пакет, имеющий целью «об- легчить среднему программисту использование декораторов и популяризировать декораторы путем демонстрации различных нетривиальных примеров». На сай-те PyPI пакет доступен под названием decorator (https://pypi.python.org/pypi/ decorator ). Вики-страница Python Decorator Library ( https://wiki.python.org/moin/ PythonDecoratorLibrary ), созданная, когда декораторы только появились в Python, содержит десятки примеров. Поскольку странице уже много лет, некоторые при-емы устарели, но она по-прежнему остается источником новых идей. В документе PEP 443 ( http://www.python.org/dev/peps/pep-0443/ ) приводится обоснование и детальное описание создания обобщенных функций с помощью одиночной диспетчеризации. В старой (март 2005 года) статье в блоге Гвидо ван Россума «Five-Minute Multimethods in Python» (Мультиметоды в Python за пять минут) ( http://www.artima.com/weblogs/viewpost.jsp?thread=101605 ) подробно рассматривается реализация обобщенных функций (или мультиметодов) с по-мощью декораторов. Код Гвидо поддерживает множественную диспетчеризацию (т. е. диспетчеризацию на основе нескольких позиционных аргументов). Этот код интересен, прежде всего, с педагогической точки зрения. Современная готовая к работе реализация обобщенных функций с множественной диспетчеризацией имеется в библиотеке Reg ( http://reg.readthedocs.org/en/latest/ ) Мартина Фаас- сена, автора моделеориентированного и поддерживающего REST веб-каркаса Morepath ( http://morepath.readthedocs.org/en/latest/ ). В коротенькой статье «Closures in Python» ( http://effbot.org/zone/closure.htm ) в блоге Фредрика Лундха (Fredrik Lundh) объясняется терминология замыка-ний. В документе «PEP 3104 – Access to Names in Outer Scopes» ( http://www.python. org/dev/peps/pep-3104/ ) доступно описано объявление nonlocal позволяющее перепривязывать имена, не являющиеся ни локальными, ни глобальными. Здесь же имеется отличный обзор подходов к этой задаче в других динамических языках (Perl, Ruby, JavaScript и т. д.), а также обсуждение плюсов и минусов различных проектных решений, возможных в Python. Более теоретический документ «PEP 227 – Statically Nested Scopes» ( http:// www.python.org/dev/peps/pep-0227/ ) содержит введение в механизм лексических областей видимости, который появился как факультативное средство в Python 2.1 и стал стандартным в Python 2.2. Здесь же дается обоснование и варианты реали-зации замыканий в Python. Поговорим Проектировщик любого языка с полноправными функциями стал- кивается со следующей проблемой: будучи полноправными объектами, функции определены в некоторой области видимости, но могут вызы-\n--- Страница 244 ---\n244 Глава 7. Декораторы функций и замыкания ваться из других областей видимости. Вопрос: как вычислять свободные переменные? Самое простое, что сразу приходит в голову: «динамиче-ская область видимости». Это означает, что при вычислении свободных переменных просматривается окружение, в котором функция вызыва-ется. Если бы в Python были динамические области видимости, но не было замыканий, то функцию avg – аналогичную той, что приведена в примере 7.9, – можно было бы написать так: >>> ### это не настоящий сеанс оболочки Python! ###>>> avg = make_averager()>>> series = [] # /g110 >>> avg(10)10.0>>> avg(11) # /g111 10.5>>> avg(12)11.0>>> series = [1] # /g112 >>> avg(5)3.0 /g110 Перед тем как использовать avg, мы должны сами определить список series = [] , поскольку averager (внутри make_averager ) ссылается на список по этому имени. /g111 За кулисами series используется для хранения усредняемых зна- чений. /g112 При выполнении присваивания series = [1] предыдущий список затирается. Это может произойти случайно, если одновременно вычисляются два независимых средних. Функции должны быть черными ящиками, их реализация должна быть скрыта от пользователя. Но если в функции имеются динамиче-ские переменные, то при использовании динамических областей види-мости программист обязан знать внутреннее устройство функции, что-бы правильно настроить ее окружение. С другой стороны, динамическую область видимости проще реали- зовать, и, наверное, именно поэтому Джон Маккарти (John McCarthy) выбрал такой путь при создании Lisp, первого языка, в котором по-явились полноправные функции. Статья Пола Грэхема (Paul Graham) «The Roots of Lisp» ( http://www.paulgraham.com/rootsoflisp.html ) содер- жит доступное объяснение оригинальной статьи Маккарти о языке Lisp «Recursive Functions of Symbolic Expressions and Their Computation by Machine, Part I» (Рекурсивные функции символических выражений и их вычисление машиной, часть I) ( http://bit.ly/mccarthy_recursive ). Ра-\n--- Страница 245 ---\n245 Поговорим бота Маккарти – такой же шедевр, как Девятая симфония Бетховена. Пол Грэхем перевел ее для всех нас – с языка математики на англий-ский, а затем на язык кода. Из комментария Пола Грэхема также видно, что динамические об- ласти видимости далеко не тривиальны. Приведем цитату из его статьи: Красноречивым свидетельством того, какими опасностями чреваты динамические области видимости, является тот факт, что даже самый первый пример функции высшего порядка в Lisp не ра-ботал – именно из-за них. Быть может, в 1960 году Маккарти не вполне сознавал последствия использования динамических обла-стей видимости. Как бы то ни было, они оставались в реализациях Lisp на удивление долго – пока Сассмен (Sussman) и Стил (Steele) не разработали язык Scheme в 1975 году. Лексические области ви-димости не слишком усложняют определение eval , но затрудняют написание компиляторов. Сегодня лексическая область видимости считается нормой: свобод- ные переменные вычисляются в том окружении, в котором функция определена. Лексические области видимости усложняют реализацию языков с полноправными функциями, потому что зависят от поддержки замыканий. С другой стороны, исходный код с лексическими областями видимости проще читать. В большинстве языков, придуманных после Algol, имеются лексические области видимости. В течение многих лет лямбда-выражения в Python не поддерживали замыкания, что снискало им дурную славу среди адептов функциональ-ного программирования в блогосфере. Это было исправлено в версии Python 2.2 (декабрь, 2001), но у блогосферы долгая память. С тех пор к конструкции lambda есть только одна претензия: синтаксические огра- ничения. Декораторы в Python и паттерн проектирования Декоратор Декораторы функций в Python согласуются с общим описанием паттерна Декоратор в книге Гамма и др. «Паттерны проектирования»: «Динамически добавляет объекту новые обязанности. Является гибкой альтернативой порождению подклассов с целью расширения функцио-нальности». На уровне реализации декораторы в Python не имеют ниче-го общего с классическим паттерном Декоратор, но какую-то аналогию провести можно. В паттерне проектирования Decorator и Component – абстрактные классы. Экземпляр конкретного декоратора обертывает экземпляр кон-кретного компонента. чтобы расширить его поведение. Приведем цита-ту из «Паттернов проектирования»:\n--- Страница 246 ---\n246 Глава 7. Декораторы функций и замыкания Декоратор следует интерфейсу декорируемого объекта, поэтому его присутствие прозрачно для клиентов компонента. Декоратор переадресует запросы внутреннему компоненту, но может выпол-нять и дополнительные действия (например, рисовать рамку) до или после переадресации. Поскольку декораторы прозрачны, они могут вкладываться друг в друга, добавляя тем самым любое число новых обязанностей. В Python декоратор играет роль конкретного подкласса Decorator , а внутренняя функция, которую он возвращает, является экземпляром де-коратора. Возвращенная функция обертывает декорируемую функцию, которая может быть уподоблена компоненту в паттерне проектирова- компоненту в паттерне проектирова- у в паттерне проектирова- ния. Возвращенная функция прозрачна, потому что согласуется с ин-терфейсом компонента, ведь она принимает те же самые аргументы. Она переадресует вызов компоненту и может выполнять дополнительные действия до или после переадресации. Мы можем перформулировать последнее предложение из приведенной цитаты следующим образом: «Поскольку декораторы прозрачны, они могут вкладываться друг в дру-га, добавляя тем самым любое число новых видов поведения». Именно это свойство открывает возможность композиции декораторов. Я вовсе не предлагаю использовать декораторы для реализации пат- терна Декоратор в программах на Python. Хотя в некоторых специфиче-ских ситуациях это возможно, в общем случае паттерн Декоратор лучше реализовать с помощью классов, представляющих сам Декоратор и обе-ртываемые им компоненты.\n--- Страница 247 ---\nЧАСТЬ IV Объектно- ориентированные идиомы",
      "debug": {
        "start_page": 214,
        "end_page": 247
      }
    },
    {
      "name": "Глава 8. Ссылки на объекты, изменяемость и повторное использование 248",
      "content": "--- Страница 248 --- (продолжение)\nГЛАВА 8. Ссылки на объекты, изменяемость и повторное использование – Ты загрустила? – огорчился Рыцарь. – Давай я спою тебе в утешение песню. […] Заглавие этой песни называется «ПУГОВКИ ДЛЯ СЮРТУКОВ».– Вы хотите сказать – песня так называется? – спросила Алиса, стараясь заинтересоваться песней. – Нет, ты не понимаешь, – ответил нетерпеливо Рыцарь. – Это ЗАГЛА- ВИЕ так называется. А песня называется «ДРЕВНИЙ СТАРИЧОК». (Из главы 8 «Это мое собственное изобретение!») – Льюис Кэрролл «Алиса в Зазеркалье» Алиса и Рыцарь задают тон тому, о чем пойдет речь в этой главе. Ее тема – разли-чие между объектами и их именами. Имя – это не объект, а совершенно отдельная вещь. Мы начнем главу с метафоры переменных в Python: переменные – это эти- кетки, а не ящик. Если ссылочные переменные – для вас давно не новость, то все равно аналогия может пригодиться, когда понадобится объяснить кому-нибудь, что такое синонимы. Затем мы обсудим понятия идентичности объектов, значений и синонимов. Обнаружится удивительная особенность кортежей: сами они неизменяемы, но их значения могут изменяться. Это подведет нас к вопросу о глубоком и поверхност-ном копировании. Следующая тема – параметры-ссылки и параметры-функции: проблемы значения изменяемого параметра по умолчанию и безопасной обработ-ки изменяемых аргументов, передаваемых клиентами функции. Последние разделы главы посвящены сборке мусора, команде del и использо- ванию слабых ссылок для «запоминания» объектов без хранения их в памяти. Это довольно сухая глава, но рассматриваемые в ней проблемы являются источником многих тонких ошибок в реальных Python-программах. Для начала забудем, что переменная – что-то вроде ящика, в котором хранятся данные.\nГЛАВА 8. Ссылки на объекты, изменяемость и повторное использование – Ты загрустила? – огорчился Рыцарь. – Давай я спою тебе в утешение песню. […] Заглавие этой песни называется «ПУГОВКИ ДЛЯ СЮРТУКОВ».– Вы хотите сказать – песня так называется? – спросила Алиса, стараясь заинтересоваться песней. – Нет, ты не понимаешь, – ответил нетерпеливо Рыцарь. – Это ЗАГЛА- ВИЕ так называется. А песня называется «ДРЕВНИЙ СТАРИЧОК». (Из главы 8 «Это мое собственное изобретение!») – Льюис Кэрролл «Алиса в Зазеркалье» Алиса и Рыцарь задают тон тому, о чем пойдет речь в этой главе. Ее тема – разли-чие между объектами и их именами. Имя – это не объект, а совершенно отдельная вещь. Мы начнем главу с метафоры переменных в Python: переменные – это эти- кетки, а не ящик. Если ссылочные переменные – для вас давно не новость, то все равно аналогия может пригодиться, когда понадобится объяснить кому-нибудь, что такое синонимы. Затем мы обсудим понятия идентичности объектов, значений и синонимов. Обнаружится удивительная особенность кортежей: сами они неизменяемы, но их значения могут изменяться. Это подведет нас к вопросу о глубоком и поверхност-ном копировании. Следующая тема – параметры-ссылки и параметры-функции: проблемы значения изменяемого параметра по умолчанию и безопасной обработ-ки изменяемых аргументов, передаваемых клиентами функции. Последние разделы главы посвящены сборке мусора, команде del и использо- ванию слабых ссылок для «запоминания» объектов без хранения их в памяти. Это довольно сухая глава, но рассматриваемые в ней проблемы являются источником многих тонких ошибок в реальных Python-программах. Для начала забудем, что переменная – что-то вроде ящика, в котором хранятся данные.\n--- Страница 249 ---\n249 Переменные – не ящики Переменные – не ящики В 1997 году я прослушал летний курс по Java в МТИ. Профессор, Линн Андреа Стейн, удостоенная наград преподаватель информатики, в настоящее время ра-ботающая в инженерном колледже Олин, отметила, что стандартная метафора «переменные – это ящики» ведет к непониманию ссылочных переменных в объ-ектно-ориентированных языках. Переменные в Python похожи на переменные в Java, поэтому лучше представлять их как этикетки, приклеенные к объектам. В примере 8.1 показано простое взаимодействие, которое невозможно объяс- нить с помощью метафоры переменных как ящиков. На рис. 8.1 наглядно пред-ставлено, почему метафора ящика не годится для Python, тогда как метафора эти-кетки правильно описывает, как в действительности работают переменные. Пример 8.1. В переменных a и b хранятся ссылки на один и тот же список, а не копии списка >>> a = [1, 2, 3] >>> b = a>>> a.append(4)>>> b[1, 2, 3, 4] Рис. 8.1. Если представлять себе переменные как ящики, то невозможно понять, как работает присваивание в Python; правильнее считать, что переменные – нечто вроде этикеток – тогда объяснить пример 8.1 становится проще Профессор Стейн также очень аккуратно употребляла слова, говоря о присваи- вании. Например, рассказывая об объекте seesaw (качели) в программе моделиро-вания, она всегда говорила «переменная s присвоена объекту seesaw», а не «объект seesaw присвоен переменной s». Имея дело со ссылочными переменными, пра- вильнее говорить, что переменная присвоена объекту, а не наоборот. Ведь объект-то создается раньше присваивания. Пример 8.2 доказывает, что правая часть при-сваивания вычисляется раньше. Пример 8.2. Переменные присваиваются объектам только после создания объектов >>> class Gizmo: def __init__(self):\n--- Страница 250 ---\n250 print('Gizmo id: %d' % id(self)) >>> x = Gizmo()Gizmo id: 4301489152 /g110 >>> y = Gizmo() * 10 /g111 Gizmo id: 4301489432 /g112 Traceback (most recent call last): File \"<stdin>\", line 1, in <module>TypeError: unsupported operand type(s) for *: 'Gizmo' and 'int'>>>>>> dir() /g113 ['Gizmo', '__builtins__', '__doc__', '__loader__', '__name__','__package__', '__spec__', 'x'] /g110 Вывод Gizmo id: – побочный эффект создания объекта Gizmo . /g111 Умножение объекта Gizmo приводит к исключению. /g112 Это доказывает, что второй объект Gizmo все-таки был создан еще до попыт- ки выполнить умножение. /g113 Но переменная y так и не была создана, потому что исключение произошло тогда, когда вычислялась правая часть. Для правильного понимания присваивания в Python всегда сначала чи- тайте правую часть, ту, где объект создается или извлекается. Уже после этого переменная в левой части связывается с объектом – как приклеен-ная к нему этикетка. А о ящиках забудьте. Поскольку переменные – это просто этикетки, ничто не мешает наклеить на объект несколько этикеток. В этом случае образуются синонимы . О них и погово- рим в следующем разделе. Тождественность, равенство и синонимы Льюис Кэрролл, литературный псевдоним профессора Чарльза Лутвиджа Дод- жсона, – не равен проф. Доджсону; это одно и то же лицо. В примере 8.3 эта идея выражена на языке Python. Пример 8.3. Переменные charles и lewis ссылаются на один и тот же объект >>> charles = {'name': 'Charles L. Dodgson', 'born': 1832} >>> lewis = charles /g110 >>> lewis is charlesTrue>>> id(charles), id(lewis) /g111 (4300473992, 4300473992)>>> lewis['balance'] = 950 /g112 >>> charlesГлава 8. Ссылки на объекты, изменяемость и повторное\n--- Страница 251 ---\n251 Тождественность, равенство и синонимы {'name': 'Charles L. Dodgson', 'balance': 950, 'born': 1832} /g110 lewis – синоним charles . /g111 Это подтверждают оператор is и функция id. /g112 Добавление элемента в хэш lewis дает тот же результат, что и добавление в хэш charles . Предположим, однако, что некий самозванец – назовем его д-р Александр Пе- даченко – заявляет, что он и есть Чарльз Л. Доджсон, родившийся в 1832 году. Возможно, он предъявляет такие же документы, но д-р Педаченко и проф. Дод-жсон – разные лица. Такая ситуация изображена на рис. 8.2. Рис. 8.2. charles и lewis связаны с одним и тем же объектом, alex – с другим объектом, имеющим точно такое же содержимое В примере 8.4 реализован и протестирован объект alex , изображенный на рис. 8.2. Пример 8.4. alex и charles равны, но alex не совпадает с charles >>> alex = {'name': 'Charles L. Dodgson', 'born': 1832, 'balance': 950} /g110 >>> alex == charles /g111 True>>> alex is not charles /g112 True /g110 Переменная alex ссылается на объект, являющийся точной копией объек- та, присвоенного переменной charles . /g111 При сравнении объекты оказываются равны, поскольку так реализован ме- тод __eq__ в классе dict . /g112 Но это разные объекты. В Python отрицательное сравнение на тождество записывается в виде a is not b . В примере 8.3 иллюстрируется синонимия . В этом коде lewis и charles – сино- нимы: две переменные, связанные с одним и тем же объектом. С другой стороны, alex не является синонимом charles : эти переменные связаны с разными объекта- ми. Объекты, связанные с переменными alex и charles , имеют одно и то же значе- ние – то, что сравнивает оператор ==, – но идентификаторы у них разные.\n--- Страница 252 ---\n252 В разделе 3.1 «Объекты, значения и типы» руководства по языку Python (http://bit.ly/1Vm9gv4 ) написано: У каждого объекта есть идентификатор, тип и значение. Иденти- фикатор объекта после создания не изменяется, можете считать, что это адрес объекта в памяти. Оператор is сравнивает идентификаторы двух объектов; функция id() возвращает целое число, представляю- щее идентификатор объекта. Истинный смысл идентификатора объекта зависит от реализации. В CPython функция id() возвращает адрес объекта в памяти, но в другом интерпретаторе это может быть что-то совсем иное. Главное – гарантируется, что идентификатор яв-ляется уникальной числовой этикеткой и не изменяется в течение всего времени жизни объекта. На практике мы редко пользуемся функцией id() . Проверка на тождество чаще производится с помощью оператора is, а не путем сравнения идентификаторов. Далее мы обсудим различия между операторами is и ==. Выбор между == и is Оператор == сравнивает значения объектов (хранящиеся в них данные), а опе- ратор is – их идентификаторы. Нас обычно интересуют значения, а не идентификаторы, поэтому == встречает- ся в Python-программах чаще, is. Однако при сравнении переменной с объектом-одиночкой (синглтоном) имеет смысл использовать is. Самый типичный случай – проверка того, что переменная связана с объектом None . Вот как это рекомендуется делать: x is None А вот как правильно записывать отрицание этого условия: x is not None Оператор is работает быстрее, чем ==, потому что его невозможно перегрузить, так что интерпретатору не приходится искать и вызывать специальные методы для его вычисления, а само вычисление сводится к сравнению двух целых чисел. Напротив, a == b – это синтаксическая глазурь поверх вызова метода a.__eq__(b) . Метод __eq__ , унаследованный от object , сравнивает идентификаторы объектов, поэтому дает тот же результат, что is. Но в большинстве встроенных типов метод __eq__ переопределен в соответствии с семантикой типа, т. е. с учетом значений других атрибутов. Для установления равенства может потребоваться большой объем обработки, например, сравнение больших коллекций или глубоко вложен-ных структур. Завершая обсуждение тождественности и равенства, мы покажем, что зна- менитый своей неизменяемостью тип tuple вовсе не такой несгибаемый, как ка- жется.Глава 8. Ссылки на объекты, изменяемость и повторное\n--- Страница 253 ---\n253 Тождественность, равенство и синонимы Относительная неизменяемость кортежей Кортежи, как и большинство коллекций в Python, – списки, словари, множе- ства и т. д. – хранят ссылки на объекты1. Если элементы, на которые указывают ссылки, изменяемы, то их можно модифицировать, хотя сам кортеж остается неиз-меняемым. Иными словами, говоря о неизменяемости кортежа, мы имеем в виду физическое содержимое структуры данных tuple (т. е. хранящиеся в ней ссылки), но не объекты, на которые эти ссылки указывают. В примере 8.5 иллюстрируется ситуация, когда значение кортежа изменяется в результате модификации изменяемого объекта, на который хранится ссылка. Но что никогда не может измениться, так это идентификаторы элементов, хранящих-ся в кортеже. Пример 8.5. Кортежи t1 и t2 первоначально равны, но после модификации изменяемого объекта, хранящегося в t1, они перестают быть равными >>> t1 = (1, 2, [30, 40]) /g110 >>> t2 = (1, 2, [30, 40]) /g111 >>> t1 == t2 /g112 True>>> id(t1[-1]) /g113 4302515784>>> t1[-1].append(99) /g114 >>> t1(1, 2, [30, 40, 99])>>> id(t1[-1]) /g115 4302515784>>> t1 == t2 /g116 False /g110 t1 неизменяемый, но t1[-1] изменяемый. /g111 Строим кортеж t2, элементы которого равны элементам t1. /g112 Хотя t1 и t2 – разные объекты, они, как и следовало ожидать, равны. /g113 Выводим идентификатор списка в элементе t1[-1] . /g114 Модифицируем t1[-1] на месте. /g115 Идентификатор объекта t1[-1] не изменился, изменилось лишь его значе- ние. /g116 t1 и t2 теперь не равны. Эта относительная неизменяемость объясняет загадку в разделе «Головоломка: присваивание A +=» главы 2. По этой же причине некоторые кортежи не являются хэшируемыми, как мы видели на врезке «Что значит «хэшируемый»?» на стр. 92. Различие между равенством и тождественностью проявляется и при копирова- нии объекта. Копия – это объект, равный исходному, но с другим идентификато-ром. Однако если объект содержит другие объекты, то следует ли при копировании 1 С другой стороны, однородные последовательности, например str , bytes и array.array , пло- ские: они содержат не ссылки, а сами данные – символы, байты и числа – в непрерывной области памяти.\n--- Страница 254 ---\n254 дублировать также внутренние объекты или можно оставить их разделяемыми? Единственно правильного ответа на этот вопрос не существует. Читайте дальше. По умолчанию копирование поверхностное Простейший способ скопировать список (как и большинство встроенных изме- няемых коллекций) – воспользоваться встроенным конструктором самого типа, например: >>> l1 = [3, [55, 44], (7, 8, 9)]>>> l2 = list(l1) /g110 >>> l2[3, [55, 44], (7, 8, 9)]>>> l2 == l1 /g111 True>>> l2 is l1 /g112 False /g110 list(l1) создает копию l1. /g111 Копии равны. /g112 Но ссылаются на разные объекты. Для списков и других изменяемых последовательностей присваивание l2 = l1[:] также создает копию. Однако при использовании конструктора и оператора [:] создается поверхност- ная копия (т. е. дублируется только самый внешний контейнер, который заполняет- ся ссылками на те же элементы, что хранятся в исходном контейнере). Это экономит память и не создает проблем, если все элементы неизменяемые. Однако при нали-чии изменяемых элементов можно столкнуться с неприятными сюрпризами. В примере 8.6 мы создаем поверхностную копию списка, который содержит другой список и кортеж, а затем производим изменения и смотрим, как они отраз-ились на объектах, на которые указывают ссылки. Если ваш компьютер подключен к сети, рекомендую понаблюдать за ин- терактивной анимацией примера 8.6 на сайте Online Python Tutor ( http:// www.pythontutor.com/ ). Во время работы над этой главой прямая ссыл- ка на пример, подготовленный для pythontutor.com , работала ненадеж- но, но сам инструмент замечательный, поэтому время, потраченное на копирование кода на сайт , будет потрачено не зря. Пример 8.6. Создание поверхностной копии списка, содержащего другой список; скопируйте этот код на сайт Online Python Tutor , чтобы увидеть его анимацию l1 = [3, [66, 55, 44], (7, 8, 9)] l2 = list(l1) # /g110Глава 8. Ссылки на объекты, изменяемость и повторное\n--- Страница 255 ---\n255 По умолчанию копирование поверхностное l1.append(100) # /g111 l1[1].remove(55) # /g112 print('l1:', l1)print('l2:', l2)l2[1] += [33, 22] # /g113 l2[2] += (10, 11) # /g114 print('l1:', l1)print('l2:', l2) /g110 l2 – поверхностная копия l1. Это состояние изображено на рис. 8.3. /g111 Добавление 100 в l1 не отражается на l2. /g112 Здесь мы удаляем 55 из внутреннего списка l1[1] . Это отражается на l2, потому что объект l2[1] связан с тем же списком, что l1[1]. /g113 Для изменяемого объекта, в частности списка, на который ссылается l2[1] , оператор += изменяет список на месте. Это изменение отражается на l1[1] , т. к. это синоним l2[1] . /g114 Для кортежа оператор += создает новый кортеж и перепривязывает к нему пе- ременную l2[2] . Это то же самое, что присваивание l2[2] = l2[2] + (10, 11) . Отметим, что кортежи в последней позиции списков l1 и l2 уже не являют- ся одним и тем же объектом (см. рис. 8.4). Рис. 8.3. Состояние программы сразу после присваивания l2 = list(l1) в примере 8.6. l1 и l2 ссылаются на разные списки, но эти списки разделяют ссылки на один и тот же объект внутреннего списка [66, 55, 44] и кортеж (7, 8, 9) (рисунок построен сайтом Online Python Tutor) Результат работы примера 8.6 показан в примере 8.7, а конечное состояние объектов – на рис. 8.4. Пример 8.7. Результат работы примера 8.6 l1: [3, [66, 44], (7, 8, 9), 100] l2: [3, [66, 44], (7, 8, 9)]\n--- Страница 256 ---\n256 l1: [3, [66, 44, 33, 22], (7, 8, 9), 100] l2: [3, [66, 44, 33, 22], (7, 8, 9, 10, 11)] Рис. 8.4. Конечное состояние l1 и l2: они по-прежнему разделяют ссылки на один и тот же объект списка, который теперь содержит [66, 44, 33, 22] , но в результате операции l2[2] += (10, 11) был создан новый кортеж (7, 8, 9, 10, 11) , не связанный с кортежем (7, 8, 9 ), на который ссылается элемент l1[2] (рисунок построен сайтом Online Python Tutor) Теперь должно быть понятно, что создать поверхностную копию легко, но это не всегда то, что нам нужно. В следующем разделе мы обсудим создание глубоких копий. Глубокое и поверхностное копирование произвольных объектов Не всегда поверхностное копирование является проблемой, но иногда требует- ся получить глубокую копию (когда копия не разделяет с оригиналом ссылки на внутренние объекты). В модуле copy имеются функции deepcopy и copy , которые возвращают соответственно глубокие и поверхностные копии произвольных объ-ектов. Для иллюстрации работы copy() и deepcopy() в примере 8.8 определен простой класс Bus, представляющий школьный, который по ходу маршрута подбирает и высаживает пассажиров. Пример 8.8. Автобус подбирает и высаживает пассажиров class Bus: def __init__(self, passengers=None): if passengers is None:Глава 8. Ссылки на объекты, изменяемость и повторное\n--- Страница 257 ---\n257 По умолчанию копирование поверхностное self.passengers = [] else: self.passengers = list(passengers) def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name) Далее в интерактивном примере 8.9 мы создадим объект класса Bus (bus1 ) и два его клона: поверхностную копию ( bus2 ) и глубокую копию ( bus3 ) – и понаблюда- ем за тем, что происходит, когда bus1 высаживает школьника. Пример 8.9. Сравнение copy и deepcopy >>> import copy >>> bus1 = Bus(['Alice', 'Bill', 'Claire', 'David'])>>> bus2 = copy.copy(bus1)>>> bus3 = copy.deepcopy(bus1)>>> id(bus1), id(bus2), id(bus3)(4301498296, 4301499416, 4301499752) /g110 >>> bus1.drop('Bill')>>> bus2.passengers['Alice', 'Claire', 'David'] /g111 >>> id(bus1.passengers), id(bus2.passengers), id(bus3.passengers)(4302658568, 4302658568, 4302657800) /g112 >>> bus3.passengers['Alice', 'Bill', 'Claire', 'David'] /g113 /g110 Используя copy и deepcopy , мы создаем три объекта Bus. /g111 После высадки 'Bill' из автобуса bus1 он исчезает и из bus2 . /g112 Инспекция атрибута passengers показывает, что bus1 и bus2 разделяют один и тот же объект списка, т. к. bus2 – поверхностная копия bus1 . /g113 bus3 – глубокая копия bus1 , поэтому ее атрибут passengers ссылается на другой список. Отметим, что в общем случае создание глубокой копии – дело не простое. Между объектами могут существовать циклические ссылки, из-за которых наи-вный алгоритм попадет в бесконечный цикл. Для корректной обработки цикли-ческих ссылок функция deepcopy запоминает, какие объекты она уже копировала. Это продемонстрировано в примере 8.10. Пример 8.10. Циклические ссылки: b ссылается на a, а затем добавляется в конец a; тем не менее, deepcopy справляется с копированием a >>> a = [10, 20] >>> b = [a, 30]>>> a.append(b)>>> a\n--- Страница 258 ---\n258 [10, 20, [[ ], 30]] >>> from copy import deepcopy>>> c = deepcopy(a)>>> c[10, 20, [[ ], 30]] Кроме того, в некоторых случаях глубокое копирование может оказаться слиш- ком глубоким. Например, объекты могут ссылаться на внешние ресурсы или на синглтоны, которые копировать не следует. Поведением функций copy и deepcopy можно управлять, реализовав специальные методы __copy__() и __deepcopy__() , как описано в документации по модулю copy (http://docs.python.org/3/library/copy. html ). Разделение ссылок на объекты посредством синонимов объясняет также ме- ханизм передачи параметров в Python и решает проблему использования изме-няемых типов для параметров по умолчанию. Эти вопросы мы рассмотрим далее. Параметры функций как ссылки Единственный способ передачи параметров в Python – вызов по соиспользованию (call by sharing). Он используется в большинстве объектно-ориентированных язы-ков, в том числе Ruby, SmallTalk и Java (это относится к ссылочным типам Java, параметры примитивных типов передаются по значению). Вызов по соисполь-зованию означает, что каждый формальный параметр функции получает копию ссылки на фактический аргумент. Иначе говоря, внутри функции параметры ста-новятся синонимами фактических аргументов. В результате функция получает возможность модифицировать любой изме- няемый объект, переданный в качестве параметра, но не может заменить объект другим, не тождественным ему. В примере 8.11 показана простая функция, приме-няющая оператор += к одному из своих параметров. Результат зависит от того, что передано в качестве фактического аргумента: число, список или кортеж. Пример 8.11. Функция может модифицировать любой переданный ей изменяемый объект >>> def f(a, b): a += b return a >>> x = 1>>> y = 2>>> f(x, y)3>>> x, y /g110 (1, 2)>>> a = [1, 2]>>> b = [3, 4]>>> f(a, b)[1, 2, 3, 4]>>> a, b /g111Глава 8. Ссылки на объекты, изменяемость и повторное\n--- Страница 259 ---\n259 Параметры функций как ссылки ([1, 2, 3, 4], [3, 4]) >>> t = (10, 20)>>> u = (30, 40)>>> f(t, u) /g112 (10, 20, 30, 40)>>> t, u((10, 20), (30, 40)) /g110 Число x не изменилось. /g111 Список a изменился. /g112 Кортеж t не изменился. С параметрами функций связан также вопрос о том, что бывает, когда значение по умолчанию имеет изменяемый тип. Значения по умолчанию изменяемого типа: неудачная мысль Необязательные параметры, имеющие значения по умолчанию, – замечатель- ная возможность, которую можно использовать в определениях функций для обе-спечения обратной совместимости API. Однако не следует использовать в каче-стве значений по умолчанию изменяемые объекты. Для иллюстрации возникающей проблемы мы в примере 8.12 взяли класс Bus из примера 8.8 и изменили в нем метод __init__ , получив новый класс HauntedBus . Но решили поумничать и вместо значения по умолчанию passengers=None задать passengers=[] , избавившись тем самым от предложения if в предыдущем вариан- те __init__ . Такое «умничанье» приводит к беде. Пример 8.12. Простой класс, иллюстрирующий опасности изменяемых значений по умолчанию class HauntedBus: \"\"\"Автобус, облюбованный пассажирами-призраками\"\"\" def __init__(self, passengers=[]): /g110 self.passengers = passengers /g111 def pick(self, name): self.passengers.append(name) /g112 def drop(self, name): self.passengers.remove(name) /g110 Если аргумент passengers не передан, то этот параметр связывается с объ- ектом списка по умолчанию, который первоначально пуст. /g111 В результате этого присваивания self.passengers становится синонимом passengers , который сам является синонимом списка по умолчанию, если аргумент passengers не передан.\n--- Страница 260 ---\n260 /g112 Применяя методы .remove() и .append() к self.passengers , мы на самом деле изменяем список по умолчанию, который является атрибутом объек-та-функции. В примере 8.13 показано потустороннее поведение объекта HauntedBus . Пример 8.13. Автобусы, облюбованные пассажирами-призраками >>> bus1 = HauntedBus(['Alice', 'Bill']) >>> bus1.passengers['Alice', 'Bill']>>> bus1.pick('Charlie')>>> bus1.drop('Alice')>>> bus1.passengers /g110 ['Bill', 'Charlie']>>> bus2 = HauntedBus() /g111 >>> bus2.pick('Carrie')>>> bus2.passengers['Carrie']>>> bus3 = HauntedBus() /g112 >>> bus3.passengers /g113 ['Carrie']>>> bus3.pick('Dave') /g114 >>> bus2.passengers['Carrie', 'Dave']>>> bus2.passengers is bus3.passengers /g115 True>>> bus1.passengers /g116 ['Bill', 'Charlie'] /g110 Пока все хорошо: bus1 не таит никаких сюрпризов. /g111 bus2 вначале пуст, поэтому атрибуту self.passengers присвоен пустой спи- сок по умолчанию. /g112 bus3 также вначале пуст, self.passengers – снова список по умолчанию. /g113 Список по умолчанию уже не пуст! /g114 Теперь Dave , севший в автобус bus3 , оказался и в bus2 . /g115 Проблема: bus2.passengers и bus3.passengers ссылаются на один и тот же список. /g116 Но bus1.passengers – другой список. Проблема в том, что все экземпляры HauntedBus , конструктору которых не был явно передан список пассажиров, разделяют один и тот же список по умолчанию. Это тонкая ошибка. Из примера 8.13 видно, что когда объект HauntedBus иници- ализируется списком пассажиров, он работает правильно. Странности начинают-ся, когда HauntedBus вначале пуст, потому что в этом случае self.passengers оказы- вается синонимом значения по умолчанию для параметра passengers . Беда в том, что любое значение по умолчанию вычисляется в момент определения функции, т. е. обычно на этапе загрузки модуля, после чего значения по умолчанию стано-вятся атрибутами объекта-функции. Так что если значение по умолчанию – изме-Глава 8. Ссылки на объекты, изменяемость и повторное\n--- Страница 261 ---\n261 Параметры функций как ссылки няемый объект и вы его изменили, то изменение отразится и на всех последующих вызовах функции. Если после выполнения кода из примера 8.13 проинспектировать объект HauntedBus.__init__ , то мы обнаружим школьников-призраков в его атрибуте __defaults__ : >>> dir(HauntedBus.__init__) # doctest: +ELLIPSIS['__annotations__', '__call__', , '__defaults__', ]>>> HauntedBus.__init__.__defaults__(['Carrie', 'Dave'],) Наконец, можно убедиться, что bus2.passengers – синоним первого элемента атрибута HauntedBus.__init__.__defaults__ : >>> HauntedBus.__init__.__defaults__[0] is bus2.passengersTrue Описанная проблема и есть причина того, почему для параметров, принима- ющих изменяемые значения, часто по умолчанию задается значение None . В при- мере 8.8 __init__ проверяет, верно ли, что аргумент passengers совпадает с None , и, если это так, присваивает атрибуту self.passengers вновь созданный пустой спи- сок. В следующем разделе объясняется, что если passengers не совпадает с None , то правильное решение заключается в том, чтобы присвоить self.passengers копию этого атрибута. Защитное программирование при наличии изменяемых параметров При написании функции, принимающей изменяемый параметр, нужно тща- тельно обдумать, ожидает ли вызывающая сторона, что переданный аргумент мо-жет быть изменен. Например, если функция принимает словарь и модифицирует его в процессе обработки, должен ли этот побочный эффект быть виден вне самой функции? От-вет зависит от контекста. Так или иначе, необходимо согласовать предположения автора функции и вызывающей программы. Приведем еще один, последний, пример автобуса – класс TwilightBus , который нарушает ожидания, разделяя список пассажиров со своими клиентами. Прежде чем переходить к реализации, посмотрите, как работает класс TwilightBus с точки зрения его клиента. Пример 8.14. Пассажиры, вышедшие из автобуса TwilightBus , бесследно исчезают >>> basketball_team = ['Sue', 'Tina', 'Maya', 'Diana', 'Pat'] /g110 >>> bus = TwilightBus(basketball_team) /g111 >>> bus.drop('Tina') /g112 >>> bus.drop('Pat')>>> basketball_team /g113 ['Sue', 'Maya', 'Diana']\n--- Страница 262 ---\n262 /g110 В списке basketball_team пять школьников. /g111 TwilightBus везет всю баскетбольную команду. /g112 Из автобуса bus вышел сначала один школьник, за ним второй. /g113 Вышедшие пассажиры исчезли из баскетбольной команды! Класс TwilightBus нарушает «принцип наименьшего удивления» – одну из ре- комендаций по проектированию интерфейсов. Поистине удивительно, что стоит школьнику выйти из автобуса, как он исчезает из состава баскетбольной команды. В примере 8.15 приведена реализация класса TwilightBus и объяснена причина проблема. Пример 8.15. Простой класс, иллюстрирующий опасности, которыми чревато изменение полученных аргументов class TwilightBus: \"\"\"Автобус, из которого бесследно исчезают пассажиры\"\"\" def __init__(self, passengers=None): if passengers is None: self.passengers = [] /g110 else: self.passengers = passengers /g111 def pick(self, name): self.passengers.append(name) def drop(self, name): self.passengers.remove(name) /g112 /g110 Здесь мы честно создаем пустой список, когда passengers совпадает с None . /g111 Но в результате этого присваивания self.passengers становится синони- мом параметра passengers , который сам является синонимом фактическо- го аргумента, переданного методу __init__ т. е. basketball_team в приме- ре 8.14). /g112 Применяя методы .remove() и .append() к self.passengers , мы в действи- тельности изменяем исходный список, переданный конструктору в каче-стве аргумента. Проблема здесь в том, что в объекте bus создается синоним списка, переданно- го конструктору. А надо бы хранить собственный список пассажиров. Исправить ошибку просто: в методе __init__ атрибут self.passengers следует инициализи- ровать копией параметра passengers , если тот задан, как и было сделано в при- мере 8.8. def __init__(self, passengers=None): if passengers is None: self.passengers = [] else: self.passengers = list(passengers) /g110Глава 8. Ссылки на объекты, изменяемость и повторное\n--- Страница 263 ---\n263 del и сборка мусора /g110 Создать копию списка passengers или преобразовать его в тип list , если параметр имеет другой тип. Вот теперь внутренние операции со списком пассажиров никак не влияют на аргумент, переданный конструктору автобуса. Заодно это решение оказывается и более гибким: аргумент, переданный в качестве параметра passengers , может быть кортежем или любым другим итерируемым объектом, например множеством или даже результатом запроса к базе данных, поскольку конструктор класса list при- нимает любой итерируемый объект. Поскольку мы сами создали список, с кото-рым будем работать, то гарантируется, что он поддерживает операции .remove() и .append() , используемые в методах .pick() и .drop() . Если метод специально не предназначен для изменения объ- екта, полученного в качестве аргумента, то следует дважды по-думать перед тем, как создавать синоним аргумента, просто присваивая его атрибуту экземпляра в своем классе. Если со-мневаетесь, делайте копию. Клиенты обычно будут только рады. del и сборка мусора Объекты никогда не уничтожаются явно, однако, оказавшись недоступ-ными, они могут стать жертвой сборщика мусора. – «Модель данных», глава справочного руководства по языку Python Предложение del удаляет имена, а не объекты. В результате команды del объект может быть удален сборщиком мусора, но только если в этой переменной храни-лась последняя ссылка на объект или если объект стал недоступен 2. Привязыва- ние переменной к другому объекту также может обнулить количество ссылок на объект, что приведет к его уничтожению. Существует специальный метод __del__ , но он не приводит к уничтожению экземпляра, и вы не должны вызывать его само-стоятельно. Метод __del__ вызывается интерпретатором Python непосредственно перед уничтожением объекта, давая ему воз-можность освободить внешние ресурсы. Вам редко придется ре-ализовывать метод __del__ в своем коде, но, тем не менее, неко- торые начинающие программисты тратят время на его написание безо всяких на то причин. Правильно написать метод __del__ довольно сложно. Он документирован в главе «Модель данных» справочного руководства по языку Python ( http://bit.ly/1GsWPac ). 2 Если два объекта ссылаются друг на друга, как в примере 8.10, то они могут быть уничтожены, если сборщик мусора решит, что никаким другим способом до них добраться нельзя, так как никаких ссылок, кроме взаимных, на них нет.\n--- Страница 264 ---\n264 В CPython основной алгоритм сборки мусора основан на подсчете ссылок. В каждом объекте хранится счетчик указывающих на него ссылок – refcount . Как только этот счетчик обратится в нуль, объект сразу же уничтожается: CPython вызывает метод __del__ объекта (если он определен), а затем освобождает выде- ленную ему память. В CPython 2.0 был добавлен алгоритм сборки мусора, осно-ванный на поколениях, который обнаруживает группы объектов, ссылающихся друг на друга и образующих замкнутую группу. Такие объекты могут оказаться недостижимыми, хотя в каждом из них счетчик ссылок больше нуля. В других реа-лизациях Python применяются более сложные сборщики мусора, не опирающиеся на подсчет ссылок, а это означает, что метод __del__ может вызываться не сразу после того, как на объект не осталось ссылок. См. статью A. Jesse Jiryu Davis «PyPy, Garbage Collection, and a Deadlock» ( http://bit.ly/1GsWT a7 ), в которой обсуждает- ся правильное и неправильное использование метода __del__ . Для демонстрации завершения жизни объекта в примере 8.16 используется функция weakref.finalize , которая регистрирует функцию обратного вызова, вы- зываемую перед уничтожением объекта. Пример 8.16. Наблюдение за гибелью объекта, на который не осталось ссылок >>> import weakref >>> s1 = {1, 2, 3}>>> s2 = s1 /g110 >>> def bye(): /g111 print('Унесен ветром ') >>> ender = weakref.finalize(s1, bye) /g112 >>> ender.alive /g113 True>>> del s1>>> ender.alive /g114 True>>> s2 = 'spam' /g115 Унесен ветром >>> ender .alive False /g110 s1 и s2 – синонимы, ссылающиеся на одно и то же множество {1, 2, 3} /g111 Эта функция не должна быть связанным методом уничтожаемого объекта, иначе она будет хранить ссылку на него. /g112 Регистрируем обратный вызов bye объекта, на который ссылается s1. /g113 Атрибут .alive равен True , перед тем как вызвана функция, зарегистриро- ванная finalize . /g114 Как было сказано, del удаляет не объект, а только ссылку на него. /g115 После перепривязки последней ссылки, s2, объект {1, 2, 3} оказывается недоступен. Он уничтожается, вызывается функция bye и атрибут ender . alive становится равен False .Глава 8. Ссылки на объекты, изменяемость и повторное\n--- Страница 265 ---\n265 Слабые ссылки Смысл примера 8.16 – ясно показать, что предложение del не удаляет объекты, хотя объекты могут быть удалены из-за того, что после выполнения del оказыва- ются недоступны Быть может, вам непонятно, почему в примере 8.16 был уничтожен объект {1, 2, 3} . Ведь ссылка s1 была передана функции finalize , которая должна была бы удержать ее, чтобы следить за объектом и вызвать функцию обратного вызова. Это работает, потому что finalize удерживает слабую ссылку на объект {1, 2, 3} , а что это такое, объясняется в следующем разделе. Слабые ссылки Наличие ссылок – вот что удерживает объект в памяти. Как только счетчик ссы-лок на объект обращается в нуль, сборщик мусора уничтожает его. Но иногда по-лезно иметь такую ссылку на объект, которая не удерживает его в памяти дольше, чем необходимо. Типичный пример – кэш. Слабые ссылки на объект не увеличивают счетчик ссылок. Объект, на который указывает ссылка, называется объектом ссылки . Таким образом, слабая ссылка не препятствует уничтожению объекта ссылки сборщиком мусора. Слабые ссылки полезны для кэширования, потому что мы не хотим, чтобы кэшированный объект оставался жив только потому, что на него ссылается сам кэш. В примере 8.17 показано, как можно вызвать экземпляр weakref.ref для полу- чения его объекта ссылки. Если этот объект еще жив, то он и возвращается, иначе возвращается None . В примере 8.17 показан сеанс оболочки, а оболочка Python ав- томатически связывает переменную _ с результатом выражения, если он отличен от None . Это мешает моей демонстрации, но одновременно подчеркивает практически важный момент: пыта-ясь заниматься управлением памятью на низком уровне, мы ча-сто натыкаемся на скрытые неявные присваивания, в результате которых создаются новые ссылки на наши объекты. Переменная оболочки _ – один из таких примеров. Другой распространенный источник неожиданных ссылок – объект обратной трассировки стека. Пример 8.17. Слабая ссылка – это вызываемый объект , который возвращает объект ссылки, если он еще существует , а в противном случае None >>> import weakref >>> a_set = {0, 1}>>> wref = weakref.ref(a_set) /g110 >>> wref\n--- Страница 266 ---\n266 <weakref at 0x100637598; to 'set' at 0x100636748> >>> wref() /g111 {0, 1} >>> a_set = {2, 3, 4} /g112 >>> wref() /g113 {0, 1} >>> wref() is None /g114 False>>> wref() is None /g115 True /g110 Объект слабой ссылки wref создается, а в следующей строке инспектирует- ся. /g111 Вызов wref() возвращает объект ссылки {0, 1} . Поскольку это сеанс обо- лочки, результат {0, 1} связывается с переменной _. /g112 a_set больше не ссылается на {0, 1} , поэтому счетчик ссылок уменьшается. Но на {0, 1} все еще ссылается переменная _. /g113 Вызов wref() по-прежнему возвращает {0, 1} . /g114 В момент вычисления выражения объект {0, 1} жив, поэтому wref() не со- впадает с None . Но затем _ связывается с результирующим значением False . Больше сильных ссылок на {0, 1} не осталось. /g115 Поскольку объект {0, 1} уничтожен, этот последний вызов wref() возвра- щает None . В документации по модулю weakref (http://docs.python.org/3/library/weakref. html ) специально сказано, что класс weakref.ref – низкоуровневый интерфейс для особых приложений, а большинству программ хватает коллекций из модуля weakref и функции finalize . Иными словами, подумайте, не стоит ли использовать коллекции WeakKeyDictionary , WeakValueDictionary , WeakSet и функцию finalize (которые внутри себя пользуются слабыми ссылками), вместо того чтобы вруч-ную создавать и обрабатывать экземпляры weakref.ref . В примере 8.17 мы сдела- ли это в надежде, что демонстрация weakref.ref в действии развеет окружающую его завесу тайны. Но на практике большинство программ на Python вполне могут обойтись коллекциями из модуля weakref . В следующем разделе мы их вкратце обсудим. Коллекция WeakValueDictionary Класс WeakValueDictionary реализует изменяемое отображение, в котором значениями являются слабые ссылки на объекты. Когда сборщик мусора где-то в программе уничтожает объект ссылки, соответствующий ключ автоматически удаляется из WeakValueDictionary . Обычно этот класс используется для кэширо- вания. Идея нашей демонстрации класса WeakValueDictionary навеяна классическим скетчем Монти Пайтон «Сырная лавка», в котором покупатель пытается купить Глава 8. Ссылки на объекты, изменяемость и повторное\n--- Страница 267 ---\n267 Слабые ссылки более 40 сортов сыра, в том числе чеддер и моцареллу, но ни одного не оказывается в продаже3. В примере 8.18 реализован тривиальный класс, представляющий один сорт сыра. Пример 8.18. В классе Cheese есть атрибут kind и стандартное представление class Cheese: def __init__(self, kind): self.kind = kind def __repr__(self): return 'Cheese(%r)' % self.kind В примере 8.19 каждый сорт сыра загружается из объекта catalog в объект stock , реализованный в виде WeakValueDictionary . Однако все сыры, кроме одно- го, исчезают из stock , как только объект catalog удаляется. Сможете ли вы объ- яснить, почему сыр пармезан задержался дольше остальных4? Ответ приведен в замечании после кода. Пример 8.19. Покупатель: «Да хоть какой-нибудь сыр у вас есть?» >>> import weakref >>> stock = weakref.WeakValueDictionary() /g110 >>> catalog = [Cheese('Red Leicester'), Cheese('Tilsit'), Cheese('Brie'), Cheese('Parmesan')] >>> for cheese in catalog: stock[cheese.kind] = cheese /g111 >>> sorted(stock.keys())['Brie', 'Parmesan', 'Red Leicester', 'Tilsit'] /g112 >>> del catalog>>> sorted(stock.keys())['Parmesan'] /g113 >>> del cheese>>> sorted(stock.keys())[] /g110 stock – объект типа WeakValueDictionary . /g111 stock отображает название сыра на слабую ссылку на экземпляр этого сыра в каталоге catalog . /g112 Склад stock полон. 3 cheeseshop.python.org – это еще и псевдоним PyPI – репозитория пакетов Python Package Index – который начал жизнь совсем пустым. На момент написания этой книги в сырной лавке Python находилось 41 426 пакетов. Неплохо, но все равно далеко от 131 000 с лишним модулей в CP AN – архиве кода на Perl – предмете зависти сообществ всех динамических языков. 4 Сыр пармезан выдерживается на фабрике как минимум год, поэтому он хранится дольше свежих сыров, но это не тот ответ, который мы ищем.\n--- Страница 268 ---\n268 /g113 После удаления catalog большинство сыров исчезло из stock , как и следовало ожидать от WeakValueDictionary . Но почему не все? Из-за временной переменной, в которой хранится ссылка, жизнь объекта может продлиться дольше ожидаемого. Для локальных переменных это обычно не составляет проблемы, т . к. они унич-тожаются при выходе из функции. Но в примере 8.19 cheese – пе- ременная цикла for – глобальна и никогда не будет уничтожена, если не удалить ее явно. Дополнением к WeakValueDictionary служит класс WeakKeyDictionary , в ко- тором слабыми ссылками являются ключи. В документации по нему ( http://bit. ly/1GsXB6Z ) имеются предложения о том, как его можно использовать: [Класс WeakKeyDictionary ] можно использовать для ассоцииро- вания дополнительных данных с объектом, который принадлежит другим частям программы, без добавления в этот объект новых атрибутов. Это особенно полезно в случае объектов, перехватываю-щих доступ к атрибутам. В модуле weakref есть еще класс WeakSet , который в документации описыва- ется просто: «Класс множества, в котором хранятся слабые ссылки на элементы. Элемент уничтожается, когда не остается ни одной указывающей на него сильной ссылки». Если требуется создать класс, который знает обо всех своих экземпля-рах, то можно завести атрибут класса WeakSet для хранения ссылок на экземпляры. Если бы для этой цели использовалось обычное множество set, то экземпляры никогда не уничтожались бы сборщиком мусора, потому что сам класс хранил бы сильные ссылки на них, а классы живут столько же, сколько сам процесс интер-претатора Python, если только вы специально их не удалите. Но не для всякого объекта можно создать слабую ссылку. В следующем разделе мы рассмотрим вопрос об их ограничениях. Ограничения слабых ссылок Не всякий объект в Python может быть объектом слабой ссылки. Экземпляры классов list и dict не могут быть объектами таких ссылок, но проблему легко решить созданием простого подкласса: class MyList(list): \"\"\"Подкласс list, на экземпляр которого можно создать слабую ссылку\"\"\" a_list = MyList(range(10))# a_list можебыть объектом слабой ссылки wref_to_a_list = weakref.ref(a_list)Глава 8. Ссылки на объекты, изменяемость и повторное\n--- Страница 269 ---\n269 Как Python хитрит с неизменяемыми объектами Экземпляр класса set может быть объектом ссылки, потому-то мы и исполь- зовали множество в примере 8.17. Пользовательские типы тоже не составляют проблемы, и это объясняет, почему в примере 8.19 понадобился дурацкий класс Cheese . Но экземпляры классов int и tuple нельзя сделать объектами слабых ссы- лок, и тут даже создание подкласса не поможет. Большинство этих ограничений – детали реализации CPython, и к другим ин- терпретаторам Python они, возможно, и не относятся. Это результат внутренних оптимизаций, некоторые из которых обсуждаются в следующем разделе (совер-шенно необязательном). Как Python хитрит с неизменяемыми объектами Вы можете спокойно пропустить этот раздел. В нем обсуждаются не- которые детали реализации, которые пользователям Python не особенно интересны. Все это оптимизации и уловки, которые придумали разработ-чики ядра CPython; на работе с языком они не сказываются и к другим ре-ализациям Python и даже к будущим версиям CPython могут быть непри-менимы. Тем не менее, экспериментируя с синонимами и копированием, иногда можно наткнуться на следы этих трюков, поэтому мне показалось, что о них стоит сказать пару слов. Я удивился, узнав, что для кортежа t конструкция t[:] не создает копию, а воз- вращает ссылку на сам объект. Ссылку на исходный кортеж мы получаем также, написав tuple(t)5. Это доказывает пример 8.20. Пример 8.20. Кортеж, инициализированный другим кортежем, в точности совпадает с исходным >>> t1 = (1, 2, 3) >>> t2 = tuple(t1)>>> t2 is t1 /g110 True>>> t3 = t1[:]>>> t3 is t1 /g111 True /g110 t1 и t2 связаны с одним и тем же объектом. /g111 И t3 тоже. Такое же поведение свойственно экземплярам классов str, bytes и frozenset . Отметим, что frozenset – не последовательность, поэтому, когда fs является 5 Это поведение четко документировано. Набрав help(tuple) в оболочке Python, читаем: «Если аргумент является кортежем, то возвращается исходный объект». А я-то, садясь за написание этой книги, думал, что знаю о кортежах все.\n--- Страница 270 ---\n270 объектом frozenset , конструкция fs[:] не работает. Но fs.copy() дает точно такой же эффект: обманывает нас и возвращает ссылку на тот же объект, а вовсе не на его копию (см. пример 8.21). 6 Пример 8.21. Строковые литералы могут создавать разделяемые объекты >>> t1 = (1, 2, 3) >>> t3 = (1, 2, 3) # /g110 >>> t3 is t1 # /g111 False>>> s1 = 'ABC'>>> s2 = 'ABC' # /g112 >>> s2 is s1 # /g113 True /g110 Создание нового кортежа с нуля. /g111 t1 и t3 равны, но не тождественны. /g112 Создание второй строки str с нуля. /g113 Сюрприз: s1 и s2 ссылаются на один и тот же объект str! Разделение строковых литералов – это техника оптимизации, называемая интернированием . В CPython тот же прием используется для небольших целых чисел, чтобы избежать ненужного дублирования «популярных» чисел, например: 0, –1 и 42. Отметим, что CPython не интернирует все строки и целые числа подряд, а критерии, которым он руководствуется, остаются недокументированной дета-лью реализации. Никогда не полагайтесь на интернирование объектов str и int! Для сравнения на равенство используйте только оператор ==, а не is. Интернирование предназначено исключительно для внутрен- них нужд интерпретатора. Трюки, обсуждаемые в этом разделе, в том числе поведение метода frozenset. copy() , – это «ложь во спасение»: они экономят память и ускоряют работу интер- претатора. Не думайте о них, никаких хлопот они не доставят, потому что отно-сятся только к неизменяемым объектам. Пожалуй, наилучшее применение этим мелочам – пари со знакомыми питонистами. Резюме У каждого объекта в Python есть идентификатор, тип и значение. И только значе-ние объекта может изменяться со временем 7. 6 Невинную ложь – тот факт, что метод copy ничего не копирует, – можно объяснить совмести- мостью интерфейсов: при этом класс frozenset оказывается лучше совместим с set . Как бы то ни было, конечному пользователю безразлично, являются два идентичных неизменяемых объекта одним и тем же объектом или разными. 7 На самом деле, тип объекта тоже можно изменить, просто присвоив другой класс его атрибуту __class__ , но это неприкрытое зло, и я жалею, что написал эту сноску .Глава 8. Ссылки на объекты, изменяемость и повторное\n--- Страница 271 ---\n271 Дополнительная литература Если две переменные ссылаются на неизменяемые объекты, имеющие равные значения ( a == b принимает значение True ), то на практике редко бывает важно, ссылаются ли они на копии или являются синонимами, – за одним исключением. Это исключение составляют неизменяемые коллекции, например кортежи и объ-екты frozenset : если неизменяемая коллекция содержит ссылки на изменяемые объекты, то ее значение может измениться при изменении значения одного из ее элементов. На практике такая ситуация встречается не часто. Но идентификаторы объектов, хранящихся в неизменяемой коллекции, не изменяются ни при каких обстоятельствах. Из того, что в переменных хранятся ссылки, вытекает ряд практических следствий. • Простое присваивание не создает копий. • Составное присваивание (операторы +=, *= и т. п.) создает новый объект, если переменная в левой части связана с неизменяемым объектом, а изме-няемый объект может быть модифицирован на месте. • Присваивание нового значения существующей переменной не изменяет объект, с которым она была связана ранее. Это называется перепривязкой: переменная просто связывается с другим объектом. Если в этой перемен-ной хранилась последняя ссылка на предыдущий объект, то этот объект убирается в мусор. • Параметры функций передаются как синонимы, т. е. функция может мо- дифицировать любой изменяемый объект, переданный ей в качестве аргу-мента. Этому невозможно воспрепятствовать, разве что создать локальную копию или использовать неизменяемые объекты (т. е. передавать кортеж вместо списка). • Использовать изменяемые объекты в качестве значений параметров функ- ции по умолчанию опасно, потому что если изменить параметр на месте, то изменится значение по умолчанию, и это скажется на всех последующих вызовах функции с параметром по умолчанию. В CPython объект уничтожается, как только число ссылок на него станет равно нулю. Объекты также могут уничтожаться, если образуют группу с циклически-ми ссылками друг на друга, и ни на один объект группы нет других – внешних – ссылок. В некоторых ситуациях полезно иметь ссылку, которая сама по себе не удерживает объект «в мире живых». Примером может служить класс, желающий отслеживать все свои экземпляры. Это можно сделать с помощью слабых ссы-лок – низкоуровневого механизма, на базе которого построены более полезные коллекции WeakValueDictionary , WeakKeyDictionary , WeakSet и функция finalize – все из модуля weakref . Дополнительная литература Глава «Модель данных» ( http://bit.ly/1GsZwss ) справочного руководства по языку Python начинается с объяснения того, что такое идентификаторы и значения объ-ектов.\n--- Страница 272 ---\n272 Уэсли Чан (W esley Chun), автор серии книг Core Python , показал на конферен- ции OSCON 2013 прекрасную презентацию, в которой освещаются многие вопро-сы из этой главы. Слайды можно скачать со страницы «Python 103: Memory Model & Best Practices» ( http://bit.ly/1GsZvEO ). На сайте Y ouT ube имеется также видео (http://bit.ly/1HGCayS ) более пространного выступления Уэсли на конференции EuroPython 2011, в которой затрагиваются не только темы этой главы, но и ис-пользование специальных методов. Дуг Хеллманн (Doug Hellmann) написал длинную серию статей в блоге под об- щим названием «Python Module of the W eek» ( http://pymotw.com ). Впоследствии из них образовалась книга «The Python Standard Library by Example» ( http://bit. ly/py-libex ). В статьях «copy – Duplicate Objects» ( http://pymotw.com/2/copy/ ) и «weakref – Garbage-Collectable References to Objects» ( http://pymotw.com/2/ weakref/ ) рассматриваются некоторые из обсуждавшихся в этой главе тем. Дополнительные сведения об основанном на поколениях сборщике мусора можно найти в документации по модулю gc (http://bit.ly/1HGCbmj ), которая начи- нается фразой: «Этот модуль предоставляет интерфейс к факультативному сбор-щику мусора». Слово «факультативный» в этом контексте может вызвать удивле-ние, но в главе «Модель данных» ( http://bit.ly/1GsZwss ) также утверждается: Реализации разрешено откладывать сборку мусора и даже не производить ее вовсе; как именно реализована сборка мусора – во-прос качества реализации, главное условие – чтобы не уничтожался ни один объект, который все еще достижим. Фредрик Лундх – автор таких важных библиотек, как ElementTree, Tkinter и PIL – написал короткую статью о сборщике мусора в Python под названием «How Does Python Manage Memory?» (Как Python управляет памятью) ( http:// bit.ly/1FSDBpM ). В ней он подчеркивает, что сборщик мусора – это деталь реали- зации, и в разных интерпретаторах он ведет себя по-разному. Например, в Jython применяется сборщик мусора из Java. В версии CPython 3 сборщик мусора усовершенствован в части обработ- ки объектов с методом __del__ , это описано в документе «PEP 442 – Safe object finalization» ( http://bit.ly/1HGCde7 ). В википедии имеется статья об интернировании строк ( http://bit.ly/1HGCduC ), в которой описывается применение этой техники в разных языках, включая Python. Поговорим Равное отношение ко всем объектам Прежде чем открыть для себя Python, я изучал Java. Оператор == в Java всегда оставлял у меня чувство неудовлетворенности. Програм-мист обычно интересуется равенством, а не тождественностью, но для объектов (в отличие от примитивных типов) оператор == сравнивает Глава 8. Ссылки на объекты, изменяемость и повторное\n--- Страница 273 ---\n273 Поговорим ссылки, а не значения объектов. Даже такую базовую вещь, как сравне- ние строк, Java заставляет делать с применением метода .equals . Но в и этом случае есть подвох: если при вычислении выражения a.equals(b) окажется, что a равно null , то возникнет исключение из-за нулевого ука- зателя. Проектировщики Java сочли необходимым переопределить для строк оператор +, так почему же не пошли дальше и не переопределили также оператор ==? В Python это сделано правильно. Оператор == сравнивает значения объектов, а оператор is – ссылки. И поскольку в Python имеется меха- низм перегрузки операторов, то == разумно работает для всех объектов из стандартной библиотеки, включая None , каковой является обычным объектом в отличие от null в Java. И разумеется, можно определить метод __eq__ в собственных клас- сах, самостоятельно решив, что должен означать для них оператор ==. Если метод __eq__ не переопределен, то он наследуется от object и срав- нивает идентификаторы объектов, так что все объекты пользователь-ского класса по умолчанию считаются различными. Вот такие вещи побудили меня перейти с Java на Python, после того как в один прекрасный день в сентябре 1998 года я прочел «Учебное по-собие по Python». Изменяемость Эта глава была бы излишней, если бы все объекты в Python были неизменяемы. Когда имеешь дело с неизменяемым объектом, неважно, хранятся ли в переменных сами объекты или ссылки на разделяемые объекты. Если a == b истинно, и ни тот, ни другой объект не может измениться, то они вполне могут быть одним и тем же объектом. Вот поэтому интернирование строк и безопасно. Тождественность объектов становится важна, только если объекты изменяемы. В «чистом» функциональном программировании все данные неиз- меняемы: при добавлении элемента в коллекцию создается новая кол-лекция. Но Python – не функциональный язык программирования и уж тем более не чистый. Экземпляры пользовательских классов в Python по умолчанию изменяемы – как и в большинстве объектно-ориентиро-ванных языков. Если требуется создавать неизменяемые объекты, то следует проявлять особую осторожность. Каждый атрибут такого объ-екта тоже должен быть неизменяемым, иначе получится нечто, анало-гичное кортежу: хотя с точки зрения идентификаторов объектов кортеж неизменяемый, его значение может измениться, если в нем хранятся из-меняемые объекты. Изменяемые объекты – также основная причина, из-за которой так трудно написать корректную многопоточную программу: если потоки изменяют объекты, не заботясь о синхронизации, то данные будут по-\n--- Страница 274 ---\n274 вреждены. С другой стороны, если синхронизации слишком много, воз- никают взаимоблокировки. Уничтожение объектов и сборка мусора В Python нет механизма прямого уничтожения объекта, и это не упу- щение, а великое благо: если бы можно было уничтожить объект в лю-бой момент, что стало бы с указывающими на него сильными ссылками? В CPython сборка мусора основана, главным образом, на механизме подсчета ссылок; он легко реализуется, но ведет к утечке памяти при на-личии циклических ссылок. Поэтому в версии 2.0 (октябрь, 2000) был реализован сборщик мусора на основе поколений, который умеет унич-тожать группы объектов, связанных только циклическими ссылками и недостижимых извне. Но подсчет ссылок по-прежнему остается основным механизмом и приводит к немедленному уничтожению объектов, на которые не оста-лось ссылок. Это означает, что в CPython – по крайней мере, сейчас – безопасно такое предложение: open('test.txt', 'wt', encoding='utf-8').write('1, 2, 3') Этот код безопасен, потому что счетчик ссылок на объект файла ока- жется равен нулю после возврата из метода write , и Python немедленно закроет файл, перед тем как уничтожить объект, представляющий его в памяти. Однако в Jython или IronPython эта строка небезопасна, т. к. они пользуются более сложными сборщиками мусора в объемлющей среде выполнения (Java VM и .NET CLR соответственно), которые не опираются на подсчет ссылок и могут отложить уничтожение объекта и закрытие файла на неопределенное время. Поэтому в любом случае и, в частности, в CPython рекомендуется явно закрывать файл, а самый на-дежный способ сделать это – воспользоваться предложением with , кото- рое гарантирует закрытие файла, даже если пока он был открыт, произо-шло исключение. С использованием with показанный выше фрагмент можно записать так: with open('test.txt', 'wt', encoding='utf-8') as fp: fp .write('1, 2, 3') Если вас заинтересовала тема сборщиков мусора, можете почи- тать статью Томаса Перла (Thomas Perl) «Python Garbage Collector Implementations: CPython, PyPy and GaS» ( http://bit.ly/1Gt0HrJ ), из ко- торой я узнал о безопасности open().write() в CPython. Передача параметров: вызов по соиспользованию Популярным объяснением механизма передачи параметров в Python является фраза: «Параметры передаются по значению, но значениями являются ссылки». Нельзя сказать, что это неверно, но вводит в заблуж-Глава 8. Ссылки на объекты, изменяемость и повторное\n--- Страница 275 ---\n275 Поговорим дение, потому что в более старых языках наиболее употребительные способы передачи параметров – по значению (функция получает копию аргумента) и по ссылке (функция получает указатель на аргумент). В Python функция получает копии аргументов, но аргументы всегда являются ссылками. Поэтому значение объекта, на который указыва-ет ссылка, может измениться, если объект изменяемый, но его иденти-фикатор – никогда. Кроме того, поскольку функция получает копию ссылки, переданной в аргументе, перепривязка не видна за пределами функции. Я позаимствовал термин вызов по соиспользованию , прочитав материал на эту тему в книге Michael L. Scott «Programming Language Pragmatics», издание 3 (Morgan Kaufmann), особенно раздел 8.3.1 «Спо-собы передачи параметров». Полная цитата из «Алисы в Зазеркалье» Я очень люблю этот отрывок, но для эпиграфа он слишком длинный. Поэтому привожу здесь полностью диалог Алисы и Рыцаря о песне, ее заглавии и названии. – Ты загрустила? – огорчился Рыцарь. – Давай я спою тебе в утеше- ние песню. – А она очень длинная? – спросила Алиса.В этот день она слышала столько стихов!– Она длинная, – ответил Рыцарь, – но очень, ОЧЕНЬ красивая! Ког- да я ее пою, все РЫДАЮТ или – Или что? – спросила Алиса, не понимая, почему Рыцарь вдруг остановился. – Или не рыдают. Заглавие этой песни называется «ПУГОВКИ ДЛЯ СЮРТУКОВ». – Вы хотите сказать – песня так называется? – спросила Алиса, ста- раясь заинтересоваться песней. – Нет, ты не понимаешь, – ответил нетерпеливо Рыцарь. – Это ЗА- ГЛАВИЕ так называется. А ПЕСНЯ называется «ДРЕВНИЙ СТАРИ-ЧОК». – Мне надо было спросить: это У ПЕСНИ такое ЗАГЛАВИЕ? – по- правилась Алиса. – Да нет! ЗАГЛАВИЕ совсем другое. «С ГОРЕМ ПОПОЛАМ!» Но это она только так НАЗЫВАЕТСЯ! – А песня эта КАКАЯ? – спросила Алиса в полной растерянности.– Я как раз собирался тебе об этом сказать. «Сидящий на стене»! Вот какая это песня! Музыка собственного изобретения! – Льюис Кэрролл «Алиса в Зазеркалье» 8 Глава VIII «Это мое собственное изобретение. 8 Перевод Н. Демуровой.",
      "debug": {
        "start_page": 248,
        "end_page": 275
      }
    },
    {
      "name": "Глава 9. Объект в духе Python 276",
      "content": "--- Страница 276 --- (продолжение)\nГЛАВА 9. Объект в духе Python Ни в коем случае не используйте два подчерка в начале. Это приватно до безобразия 1. – Ян Байкинг, автор pip, virtualenv, Paste и многих других проектов Благодаря модели данных в Python пользовательские типы могут вести себя так же естественно, как встроенные. И это достигается безо всякого наследования, в духе динамической типизации : достаточно просто реализовать методы, необходи- мые для того, чтобы объект вел себя ожидаемым образом. В предыдущих главах мы рассказали о структуре и поведении многих встроен- ных объектов. А теперь займемся созданием собственных классов, которые ведут себя, как настоящие объекты в Python. Эта глава начинается с места, где закончилась глава 1 – мы покажем, как реали- зовать несколько специальных методов, которые обычно встречаются в объектах Python разных типов. В этой главе мы узнаем, как: • поддержать встроенные функции, которые порождают альтернативные представления объекта ( repr() , bytes() и другие); • реализовать альтернативный конструктор в виде метода класса;• расширить миниязык, используемый во встроенной функции format() и в методе str.format() ; • предоставить доступ к атрибутам только для чтения;• сделать объект хэшируемым, чтобы он мог быть элементом множества и ключом словаря; • сэкономить память за счет использования __slots__ . Все это мы сделаем по мере разработки простого типа двумерного евклидова вектора. По ходе дела мы дважды прервемся, чтобы обсудить два концептуально важных вопроса: 1 Из «Руководства по стилю программирования в Paste» ( http://pythonpaste.org/StyleGuide.html ).\nГЛАВА 9. Объект в духе Python Ни в коем случае не используйте два подчерка в начале. Это приватно до безобразия 1. – Ян Байкинг, автор pip, virtualenv, Paste и многих других проектов Благодаря модели данных в Python пользовательские типы могут вести себя так же естественно, как встроенные. И это достигается безо всякого наследования, в духе динамической типизации : достаточно просто реализовать методы, необходи- мые для того, чтобы объект вел себя ожидаемым образом. В предыдущих главах мы рассказали о структуре и поведении многих встроен- ных объектов. А теперь займемся созданием собственных классов, которые ведут себя, как настоящие объекты в Python. Эта глава начинается с места, где закончилась глава 1 – мы покажем, как реали- зовать несколько специальных методов, которые обычно встречаются в объектах Python разных типов. В этой главе мы узнаем, как: • поддержать встроенные функции, которые порождают альтернативные представления объекта ( repr() , bytes() и другие); • реализовать альтернативный конструктор в виде метода класса;• расширить миниязык, используемый во встроенной функции format() и в методе str.format() ; • предоставить доступ к атрибутам только для чтения;• сделать объект хэшируемым, чтобы он мог быть элементом множества и ключом словаря; • сэкономить память за счет использования __slots__ . Все это мы сделаем по мере разработки простого типа двумерного евклидова вектора. По ходе дела мы дважды прервемся, чтобы обсудить два концептуально важных вопроса: 1 Из «Руководства по стилю программирования в Paste» ( http://pythonpaste.org/StyleGuide.html ).\n--- Страница 277 ---\n277 И снова класс вектора • как и когда использовать декораторы @classmethod и @staticmethod ; • закрытые и защищенные атрибуты в Python: использование, соглашения и ограничения; Начнем с методов представления объекта. Представления объекта В любом объектно-ориентированном языке есть по меньшей мере один стандарт- ный способ получить строковое представление произвольного объекта. В Python таких способов два: repr() Вернуть строку, представляющую объект в виде, удобном для разработчика. str() Вернуть строку, представляющую объект в виде, удобном для пользователя. Как вы знаете, для поддержки функций repr() и str() мы должны реализовать специальные методы __repr__ и __str__ . Существуют еще два специальных метода для поддержки альтернативных представлений объектов: __bytes__ и __format__ . Метод __bytes__ аналогичен __str__ : он вызывается функцией bytes() , чтобы получить представление объек- та в виде последовательности байтов. А метод __format__ вызывается встроенной функцией format() и методом str.format() для получения строкового представ- ления объектов с помощью специальных форматных кодов. В следующем разделе мы рассмотрим метод __bytes__ , а вслед за ним метод __format__ . Если раньше вы программировали на Python 2, то имейте в виду, что в Python 3 методы __repr__ , __str__ и __format__ всег- да должны возвращать Unicode-строки (типа str). И лишь метод __bytes__ должен возвращать последовательность байтов (типа bytes ). И снова класс вектора Для демонстрации различных методов, генерирующих представления объектов, мы воспользуемся классом Vector2d , аналогичным рассмотренному в главе 1. В этом и следующих разделах мы будем постепенно наращивать его функциональ-ность. В примере 9.1 показано базовое поведение, ожидаемое от объекта Vector2d . Пример 9.1. У экземпляров Vector2d есть несколько представлений >>> v1 = Vector2d(3, 4) >>> print(v1.x, v1.y) /g110 3.0 4.0\n--- Страница 278 ---\n278 Глава 9. Объект в духе Python >>> x, y = v1 /g111 >>> x, y(3.0, 4.0)>>> v1 /g112 Vector2d(3.0, 4.0)>>> v1_clone = eval(repr(v1)) /g113 >>> v1 == v1_clone /g114 True>>> print(v1) /g115 (3.0, 4.0)>>> octets = bytes(v1) /g116 >>> octetsb'd\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x08@\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x10@'>>> abs(v1) /g117 5.0>>> bool(v1), bool(Vector2d(0, 0)) /g118 (True, False) /g110 К компонентам Vector2d можно обращаться напрямую, как к атрибутам (методов чтения нет). /g111 Объект Vector2d можно распаковать в кортеж переменных. /g112 repr для объекта Vector2d имитирует исходный код конструирования эк- земпляра. /g113 Использование eval показывает, что результат repr для Vector2d – точное представление вызова конструктора2. /g114 Vector2d поддерживает сравнение с помощью ==; это полезно для тестиро- вания. /g115 print вызывает функцию str, которая для Vector2d порождает упорядочен- ную пару. /g116 bytes пользуется методом __bytes__ для получения двоичного представле- ния. /g117 abs вызывает метод __abs__ , чтобы вернуть модуль вектора. /g118 bool пользуется методом __bool__ , чтобы вернуть False для объекта Vec- tor2d нулевой длины, и True в противном случае. Реализация класса Vector2d из примера 9.1 находится в файле vector2d_v0.py (пример 9.2). Код основан на примере 1.2, но инфиксные операторы будут реали-зованы в главе 13 – за исключением оператора == (полезного для тестирования). В данный момент в Vector2d имеется несколько специальных методов для поддерж- ки операций, которые питонист ожидает от хорошо спроектированного объекта. Пример 9.2. vector2d_v0.py: пока что реализованы только специальные методы from array import array import math class Vector2d: 2 Я использовал для клонирования объекта eval просто для иллюстрации поведения repr ; на прак- тике клонировать объект проще и безопаснее с помощью функции copy.copy .\n--- Страница 279 ---\n279 И снова класс вектора typecode = 'd' /g110 def __init__(self, x, y): self.x = float(x) /g111 self.y = float(y) def __iter__(self): return (i for i in (self.x, self.y)) /g112 def __repr__(self): class_name = type(self).__name__ return '{}({!r}, {!r})'.format(class_name, *self) /g113 def __str__(self): return str(tuple(self)) /g114 def __bytes__(self): return (bytes([ord(self.typecode)]) + /g115 bytes(array(self.typecode, self))) /g116 def __eq__(self, other): return tuple(self) == tuple(other) /g117 def __abs__(self): return math.hypot(self.x, self.y) /g118 def __bool__(self): return bool(abs(self)) 10 /g110 typecode – это атрибут класса, которым мы воспользуемся, когда будем преобразовывать экземпляры Vector2d в последовательности байтов и на- оборот. /g111 Преобразование x и y в тип float в методе __init__ позволяет на ранней стадии обнаруживать ошибки, это полезно в случае, когда конструктор Vec- tor2d вызывается с неподходящими аргументами. /g112 Наличие метода __iter__ делает Vector2d итерируемым; именно благодаря ему работает распаковка (например, x, y = my_vector ). Мы реализуем его просто с помощью генераторного выражения, которое отдает компоненты поочередно 3. /g113 Метод __repr__ строит строку, интерполируя компоненты с помощью синтаксиса {!r} для получения их представления, возвращаемого функ- ций repr ; поскольку Vector2d – итерируемый объект, *self поставляет компоненты x и y функции format . /g114 Из итерируемого объекта Vector2d легко построить кортеж для отображе- ния в виде упорядоченной пары. /g115 Для генерации объекта типа bytes мы преобразуем typecode в bytes и кон- катенируем … 3 Эту строку можно было бы записать и в виде yield self.x; yield.self.y . У меня еще най- дется что сказать по поводу специального метода __iter__ , генераторных выражений и ключевого слова yield в главе 14.\n--- Страница 280 ---\n280 Глава 9. Объект в духе Python /g116 … с объектом bytes , полученным преобразованием массива, который по- строен путем обхода экземпляра. /g117 Для быстрого сравнения всех компонентов мы строим кортежи из операн- компонентов мы строим кортежи из операн- ов мы строим кортежи из операн- дов. Это работает, когда операнды являются экземплярами класса Vector2d , но не без проблем. См. предупреждение ниже. /g118 Модулем вектора называется длина гипотенузы прямоугольного треуголь- ника с катетами x и y. /g119 Метод __bool__ вызывает abs(self) для вычисления модуля, а затем преоб- разует полученное значение в тип bool , так что 0.0 преобразуется в False , а любое число, отличное от нуля, – в True . Метод __eq__ в примере 9.2 работает для операндов типа Vec- tor2d , но возвращает True и в случае, когда экземпляр Vector2d сравнивается с другими итерируемыми объектами, содержащи-ми точно такие же числовые значения (например, Vector(3, 4) == [3, 4] ). Считать ли это ошибкой, зависит от точки зрения. Мы отложим дальнейшее обсуждение этого вопроса до главы 13, где рассматривается перегрузка операторов. У нас имеется довольно полный набор базовых методов, но одного, очевидно, не хватает: восстановления объекта Vector2d из двоичного представления, порож- денного функцией bytes() . Альтернативный конструктор Поскольку мы можем экспортировать Vector2d в виде последовательности байтов, хотелось бы иметь метод, который производит обратную операцию – конструи-рование Vector2d из двоичной последовательности. Заглянув в стандартную би- блиотеку в поисках источника вдохновения, мы обнаружим, что в классе array . array есть метод класса .frombytes , который нас вполне устраивает – мы видели его применение в разделе «Массивы» главы 2. Позаимствуем как имя, так и функ-циональность при написании метода класса Vector2d в файле vector2d_v1.py (при- мер 9.3). Пример 9.3. Часть файла vector2d_v1.py: здесь показан только метод класса frombytes , добавленный в определение Vector2d из файла vector2d_v0.py (пример 9.2) @classmethod /g110 def frombytes(cls, octets): /g111 typecode = chr(octets[0]) /g112 memv = memoryview(octets[1:]).cast(typecode) /g113 return cls(*memv) /g114 /g110 Метод класса снабжен декоратором classmethod .\n--- Страница 281 ---\n281 Декораторы classmethod и staticmethod /g111 Аргумент self отсутствует; вместо него в аргументе cls передается сам класс. /g112 Читаем typecode из первого байта. /g113 Создаем объект memoryview из двоичной последовательности октетов и при- водим его к типу typecode .4 /g114 Распаковываем memoryview , получившийся в результате приведения типа, и получаем пару аргументов, необходимых конструктору. Поскольку мы только что воспользовались декоратором classmethod , весьма специфичным для Python, будет уместно сказать о нем несколько слов. Декораторы classmethod и staticmethod Декоратор classmethod не упоминается в пособии по Python, равно как и декора- тор staticmethod . Те, кто изучал объектно-ориентированное программирование на примере Java, наверное, недоумевают, зачем в Python два декоратора, а не какой-нибудь один из них. Начнем с classmethod . Его использование показано в примере 9.3: определить метод на уровне класса, а не отдельного экземпляра. Декоратор classmethod изме- няет способ вызова метода таким образом, что в качестве первого аргумента пере-дается сам класс, а не экземпляр. Типичное применение – альтернативные кон-структоры, подобные frombytes из примера 9.3. Обратите внимание, как в послед- ней строке метод frombytes использует аргумент cls, вызывая его для создания нового экземпляра: cls(*memv) . По соглашению, первый параметр метода класса обычно называется cls (хотя интерпретатору Python его имя безразлично). Напротив, декоратор staticmethod изменяет метод так, что он не получает в первом аргументе ничего специального. По существу, статический метод – это просто обычная функция, определенная в теле класса, а не на уровне модуля. В примере 9.4 сравнивается работа classmethod и staticmethod . Пример 9.4. Сравнение декораторов classmethod и staticmethod >>> class Demo: @classmethod def klassmeth(*args): return args # /g110 @staticmethod def statmeth(*args): return args # /g111 >>> Demo.klassmeth() # /g112 (<class '__main__.Demo'>,)>>> Demo.klassmeth('spam') 4 Краткое введение в memoryview , где, в частности, описывается метод .cast , см. в разделе «Пред- ставления памяти» главы 2.\n--- Страница 282 ---\n282 Глава 9. Объект в духе Python (<class '__main__.Demo'>, 'spam') >>> Demo.statmeth() # /g113 ()>>> Demo.statmeth('spam')('spam',) /g110 klassmeth просто возвращает все позиционные аргументы. /g111 statmeth делает то же самое. /g112 Вне зависимости от способа вызова Demo.klassmeth получает класс Demo в качестве первого аргумента. /g113 Demo.statmeth ведет себя, как обычная функция. Декоратор classmethod , очевидно, полезен, но мне никогда не встречался убедительный пример употребления staticmethod . Если вы хотите определить функцию, которая не взаимодейству-ет с классом, просто определите ее в модуле. Быть может , функ-ция тесно связана с классом, хотя и не залезает в его «потроха», так что лучше разместить ее код поблизости. Но даже если так, размещение функции сразу до или после класса в том же моду-ле – это достаточно близко для любых практических целей 5. Узнав, для чего применяется декоратор classmethod (и почему staticmethod не очень полезен), вернемся к вопросу о представлении объекта и посмотрим, как поддерживается форматирование вывода. Форматирование при выводе Встроенная функция format() и метод str.format() делегируют форматирование конкретному типу, вызывая его метод .__format__(format_spec) . Аргумент format_ spec – это спецификатор формата, который либо: • является вторым аргументом при вызове format(my_obj, format_spec) , либо • равен тому, что находится после двоеточия в поле подстановки, обозначае- мом скобками {} внутри форматной строки при вызове str.format() . Например: >>> brl = 1/2.43 # курс бразильского реала к доллару США >>> brl 0.4115226337448559 >>> format(brl, '0.4f') # /g110 '0.4115' 5 Леонардо Рохаэль, один из технических рецензентов книги, не согласен с моим скептическим от- ношением к декоратору staticmethod и рекомендует прочитать статью в «The Definitive Guide on How to Use Static, Class or Abstract Methods in Python» ( http://bit.ly/1FSFTW6 ) в блоге Жюльена Данжу (Julien Danjou), где приводятся контраргументы. Статья Данжу очень интересна, рекомен-дую ее. Но ее оказалось недостаточно, чтобы я изменил свое мнение о staticmethod . Решать вам.\n--- Страница 283 ---\n283 Форматирование при выводе >>> '1 BRL = {rate:0.2f} USD'.format(rate=brl) # /g111 '1 BRL = 0.41 USD' /g110 Спецификатор формата '0.4f' . /g111 Спецификатор формата '0.2f' . Подстрока 'rate' в поле подстановки называется именем поля. Она не связана со спецификатором формата, а определяет, какой аргумент метода .format() попадает в это поле подста- новки. Код, помеченный вторым маркером, – демонстрация важного момента: в фор- матной строке, например '{0.mass:5.3e}' мы видим две совершенно разных нота- ции. Часть '0.mass' слева от двоеточия – это имя поля подстановки field_name , а часть '5.3e' после двоеточия – спецификатор формата. Нотация, применяемая в спецификаторе формата, называется также миниязыком спецификации формата (http://bit.ly/1Gt4vJF ). Если вы раньше не встречались с format() и str.format() , то хочу сказать, что мой опыт преподавания показывает , что лучше сначала изучить функцию format() , в которой используется толь- ко миниязык спецификации формата. Освоив его, переходите к синтаксису форматной строкй ( http://bit.ly/1Gt4vJF ) и разбери- тесь с нотацией поля подстановки {:}, используемой в методе str.format() (включая флаги преобразования !s, !r и !a). Для нескольких встроенных типов в миниязыке спецификации формата пред- усмотрены специальные коды представления. Например, для типа int поддержи- ваются (среди прочих) коды b и x, обозначающие соответственно основание 2 и 16, а для типа float – код f для вывода значения с фиксированной точкой и % для вывода в виде процента: >>> format(42, 'b')'101010'>>> format(2/3, '.1%')'66.7%' Миниязык спецификации формата расширяемый, потому что каждый класс может интерпретировать аргумент format_spec , как ему вздумается. Например, классы из модуля datetime пользуются одними и теми же форматными кодами в функции strftime() и в своих методах __format__ . Вот несколько примеров при- менения встроенной функции format() и метода str.format() : >>> from datetime import datetime>>> now = datetime.now()>>> format(now, '%H:%M:%S')'18:49:05'>>> \"Сейчас {:%I:%M %p}\".format(now)\"Сейчас 06:49 PM\"\n--- Страница 284 ---\n284 Глава 9. Объект в духе Python Если в классе не реализован метод __format__ , то используется метод, унасле- дованный от object , который возвращает значение str(my_object) . Поскольку в классе Vector2d есть метод __str__ , это работает следующим образом: >>> v1 = Vector2d(3, 4)>>> format(v1)'(3.0, 4.0)' Но если передать спецификатор формата, то object.__format__ возбудит ис- ключение TypeError : >>> format(v1, '.3f')Traceback (most recent call last): TypeError: non-empty format string passed to object.__format__ Исправим это, реализовав собственный миниязык форматирования. Для на- чала предположим, что спецификатор формата, заданный пользователем, служит для форматирования каждой компоненты вектора. Вот какой результат мы хотим получить: >>> v1 = Vector2d(3, 4)>>> format(v1)'(3.0, 4.0)'>>> format(v1, '.2f')'(3.00, 4.00)'>>> format(v1, '.3e')'(3.000e+00, 4.000e+00)' В примере 9.5 реализован метод __format__ , дающий именно такой резуль- тат. Пример 9.5. Метод Vector2d.format , попытка №1 # inside the Vector2d class def __format__(self, fmt_spec=''):components = (format(c, fmt_spec) for c in self) # /g110 return '({}, {})'.format(*components) # /g111 /g110 Используем встроенную функцию format , чтобы применить fmt_spec к каждой компоненте вектора и построить итерируемый объект, порождаю- компоненте вектора и построить итерируемый объект, порождаю- е вектора и построить итерируемый объект, порождаю- щий отформатированные строки. /g111 Подставляем отформатированные строки в шаблон '(x, y)' . Теперь добавим в наш миниязык специальный форматный код: если специфи- катор формата заканчивается буквой 'p', то будем отображать вектор в полярных координатах: <r, /g537>, где r – модуль, а /g537 – угол в радианах. Остаток спецификатора формата (все, что предшествует 'p') используется, как и раньше.\n--- Страница 285 ---\n285 Форматирование при выводе При выборе буквы для специального форматного кода я стре- мился избегать совпадения с кодами для других типов. В мини-языке спецификации формата ( http://bit.ly/1Gt4vJF ) для целых чисел используются коды 'bcdoxXn' , для чисел с плавающей точкой – 'eEfFgGn%' , а для строк – 's'. Поэтому для полярных ко- ординат я взял код 'p'. Поскольку каждый класс интерпретирует коды независимо от остальных, использование одной и той же буквы в разных классах не является ошибкой, но может вызвать недоумение у пользователей. Для вычисления полярных координат у нас уже есть метод __abs__ , возвра- щающий модуль, а для получения угла напишем простой метод angle , в котором используется функция math.atan2() . Вот его код: # в классе Vector2ddef angle(self): return math.atan2(self.y, self.x) Теперь мы можем обобщить метод __format__ для вывода представления в по- лярных координатах. Пример 9.6. Метод Vector2d.format , попытка № 2 – теперь и в полярных координатах def __format__(self, fmt_spec=''): if fmt_spec.endswith('p'): /g110 fmt_spec = fmt_spec[:-1] /g111 coords = (abs(self), self.angle()) /g112 outer_fmt = '<{}, {}>' /g113 else: coords = self /g114 outer_fmt = '({}, {})' /g115 components = (format(c, fmt_spec) for c in coords) /g116 return outer_fmt.format(*components) /g117 /g110 Формат заканчивается буквой 'p': полярные координаты. /g111 У даляем суффикс 'p' из fmt_spec . /g112 Строим кортеж полярных координат: (magnitude, angle) . /g113 Конфигурируем внешний формат, используя угловые скобки. /g114 Иначе используем компоненты x, y вектора self для представления в пря- моугольных координатах. /g115 Конфигурируем внешний формат, используя круглые скобки. /g116 Порождаем итерируемый объект, компонентами которого являются от- форматированные строки. /g117 Подставляем строки во внешний формат. Ниже показаны результаты, полученные с помощью кода из примера 9.6. >>> format(Vector2d(1, 1), 'p') '<1.4142135623730951, 0.7853981633974483>'\n--- Страница 286 ---\n286 Глава 9. Объект в духе Python >>> format(Vector2d(1, 1), '.3ep') '<1.414e+00, 7.854e-01>'>>> format(Vector2d(1, 1), '0.5fp')'<1.41421, 0.78540>' Как видно из этого раздела, совсем несложно расширить миниязык специфи- кации формата для поддержки пользовательских типов. Теперь перейдем к вопросу, не относящемуся к видимому представлению: мы сделаем класс Vector2d хэшируемым, чтобы можно было создавать множества век- торов и использовать векторы в качестве ключей словаря. Но прежде необходимо научиться делать векторы неизменяемыми. Хэшируемый класс Vector2d До сих пор экземпляры класса Vector2d не были хэшируемыми, поэтому мы не могли поместить их в множество: >>> v1 = Vector2d(3, 4) >>> hash(v1)Traceback (most recent call last): TypeError: unhashable type: 'Vector2d'>>> set([v1])Traceback (most recent call last): TypeError: unhashable type: 'Vector2d' Чтобы класс Vector2d был хэшируемым, мы должны реализовать метод __hash__ (необходим еще метод __eq__ , но он у нас уже есть). Нужно также, чтобы векторы были неизменяемыми, как было сказано на врезке «Что значит \"хэширу-емый\"?» в главе 3. Пока ничто не мешает любому пользователю написать v1.x = 7 , т. к. нигде в коде не говорится, что изменение Vector2d запрещено. Вот какое поведение мы хотим получить: >>> v1.x, v1.y(3.0, 4.0)>>> v1.x = 7Traceback (most recent call last): AttributeError: can't set attribute Мы добьемся этого, сделав компоненты x и y свойствами, доступными только для чтения. Пример 9.7. vector2d_v3.py: показаны только изменения, необходимые, чтобы сделать класс Vector2d неизменяемым, полный листинг см. в примере 9.9 class Vector2d: typecode = 'd' def __init__(self, x, y):\n--- Страница 287 ---\n287 Хэшируемый класс Vector2d self.__x = float(x) /g110 self.__y = float(y) @property /g111 def x(self): /g112 return self.__x /g113 @property /g114 def y(self): return self.__y def __iter__(self): return (i for i in (self.x, self.y)) /g115 # прочие методы (в книге опущены) /g110 Используем ровно два начальных подчерка (и нуль или один конечный), чтобы сделать атрибут закрытым6. /g111 Декоратор @property помечает метод чтения свойства. /g112 Просто возвращаем self.__x . /g113 Повторяем то же самое для свойства y. /g114 Все методы, которые просто читают компоненты x и y, не изменяются, толь- ко теперь self .x и self .y означает чтение открытых свойств, а не закрытых атрибутов. Поэтому оставшаяся часть класса не показана. Vector.x и Vector.y – примеры свойств, доступных только для чтения. Свойства, доступные для чтения и записи, рассматрива-ются в главе 19, где мы детально изучим декоратор @property . Теперь, когда векторы стали неизменяемыми, мы можем реализовать метод __hash__ . Он должен возвращать int и в идеале учитывать хэши объектов-атрибу- тов, которые используются также в методе __eq__ , потому что у равных объектов хэши также должны быть одинаковы. В документации по специальному методу __hash__ (https://docs.python.org/3/reference/datamodel.html ) рекомендуется объ- единять хэши компонентов с помощью поразрядного оператора ИСКЛЮЧАЮ-ЩЕЕ ИЛИ ( ^), так мы и поступим. Код метода Vector2d.__hash__ , показанный в примере 9.8, совсем прост. Пример 9.8. vector2d_v3.py: реализация хэширования # в классе Vector2d: def __hash__(self): return hash(self.x) ^ hash(self.y) После добавления метода __hash__ мы получили хэшируемые векторы: 6 Ян Байкинг так бы делать не стал, смотрите эпиграф к этой главе. Плюсы и минусы закрытых атрибутов – тема раздела «»Закрытые и защищенные атрибуты в Python» ниже в этой главе.\n--- Страница 288 ---\n288 Глава 9. Объект в духе Python >>> v1 = Vector2d(3, 4) >>> v2 = Vector2d(3.1, 4.2)>>> hash(v1), hash(v2)(7, 384307168202284039)>>> set([v1, v2]){Vector2d(3.1, 4.2), Vector2d(3.0, 4.0)} Строго говоря, для создания хэшируемого типа необязательно вводить свойства или как-то иначе защищать атрибуты экзем-пляра от изменения. Требуется только корректно реализовать методы __hash__ и __eq__ . Но хэш-значение экземпляра никогда не должно изменяться, так что представился отличный повод по-говорить о свойствах, доступных только для чтения. Если вы собираетесь создать тип с разумным скалярным числовым значением, то имеет смысл реализовать также методы __int__ и __float__ , которые вызыва- ются из конструкторов int() и float() , используемых в некоторых контекстах для приведения типов. Существует также метод __complex__ , поддерживающий встро- енный конструктор complex() . Быть может, в классе Vector2d и стоило бы реализо- вать метод __complex__ , но это я оставляю вам в качестве упражнения. По ходу работы над классом Vector2d мы показывали только фрагменты кода, а в примере 9.9 представлен полный листинг vector2d_v3.py со всеми doctest- скриптами, которые я писал, пока разрабатывал его. Пример 9.9. vector2d_v3.py: полный код \"\"\" Класс двумерного вектора >>> v1 = Vector2d(3, 4) >>> print(v1.x, v1.y) 3.0 4.0 >>> x, y = v1 >>> x, y (3.0, 4.0) >>> v1 Vector2d(3.0, 4.0) >>> v1_clone = eval(repr(v1)) >>> v1 == v1_clone True >>> print(v1) (3.0, 4.0) >>> octets = bytes(v1) >>> octets b'd\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x08@\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x10@' >>> abs(v1) 5.0 >>> bool(v1), bool(Vector2d(0, 0))\n--- Страница 289 ---\n289 Хэшируемый класс Vector2d (True, False) Test of ``.frombytes()`` class method: >>> v1_clone = Vector2d.frombytes(bytes(v1)) >>> v1_clone Vector2d(3.0, 4.0) >>> v1 == v1_clone True Tests of ``format()`` with Cartesian coordinates: >>> format(v1) '(3.0, 4.0)' >>> format(v1, '.2f') '(3.00, 4.00)' >>> format(v1, '.3e') '(3.000e+00, 4.000e+00)' Tests of the ``angle`` method:: >>> Vector2d(0, 0).angle() 0.0 >>> Vector2d(1, 0).angle() 0.0 >>> epsilon = 10**-8 >>> abs(Vector2d(0, 1).angle() - math.pi/2) < epsilon True >>> abs(Vector2d(1, 1).angle() - math.pi/4) < epsilon True Tests of ``format()`` with polar coordinates: >>> format(Vector2d(1, 1), 'p') # doctest:+ELLIPSIS '<1.414213 , 0.785398 >' >>> format(Vector2d(1, 1), '.3ep') '<1.414e+00, 7.854e-01>' >>> format(Vector2d(1, 1), '0.5fp') '<1.41421, 0.78540>' Tests of `x` and `y` read-only properties: >>> v1.x, v1.y (3.0, 4.0) >>> v1.x = 123 Traceback (most recent call last): AttributeError: can't set attribute Tests of hashing: >>> v1 = Vector2d(3, 4) >>> v2 = Vector2d(3.1, 4.2)\n--- Страница 290 ---\n290 Глава 9. Объект в духе Python >>> hash(v1), hash(v2) (7, 384307168202284039) >>> len(set([v1, v2])) 2 \"\"\"from array import array import math class Vector2d: typecode = 'd' def __init__(self, x, y): self.__x = float(x) self.__y = float(y) @property def x(self): return self.__x @property def y(self): return self.__y def __iter__(self): return (i for i in (self.x, self.y)) def __repr__(self): class_name = type(self).__name__ return '{}({!r}, {!r})'.format(class_name, *self) def __str__(self): return str(tuple(self)) def __bytes__(self): return (bytes([ord(self.typecode)]) + bytes(array(self.typecode, self))) def __eq__(self, other): return tuple(self) == tuple(other) def __hash__(self): return hash(self.x) ^ hash(self.y) def __abs__(self): return math.hypot(self.x, self.y) def __bool__(self): return bool(abs(self)) def angle(self): return math.atan2(self.y, self.x) def __format__(self, fmt_spec=''):\n--- Страница 291 ---\n291 Закрытые и «защищенные» атрибуты в Python if fmt_spec.endswith('p'): fmt_spec = fmt_spec[:-1] coords = (abs(self), self.angle()) outer_fmt = '<{}, {}>' else: coords = self outer_fmt = '({}, {})' components = (format(c, fmt_spec) for c in coords) return outer_fmt.format(*components) @classmethod def frombytes(cls, octets): typecode = chr(octets[0]) memv = memoryview(octets[1:]).cast(typecode) return cls(*memv) Подведем итоги. В этом и предыдущем разделах мы видели некоторые специ- альные методы, которые должен иметь полноценный объект. Разумеется, не стоит реализовывать все эти методы, если приложение в них не нуждается. Пользовате-лям наплевать, соответствует ваш объект «духу Python» или нет. Представленный в примере 9.6. класс Vector2d – это написанный в педагоги- ческих целях код, изобилующий специальными методами, относящимися к пред-ставлению объекта, а не образец для создания любого пользовательского класса. В следующем разделе мы отвлечемся от класса Vector2d и обсудим дизайн и недостатки механизма закрытых атрибутов в Python – двойное подчеркивание в начале имени self.__x . Закрытые и «защищенные» атрибуты в Python В Python не существует способа создать закрытые переменные, как с помощью мо- дификатора private в Java. Мы имеем лишь простой механизм, предотвращающий случайную модификацию «закрытого» атрибута в подклассе. Рассмотрим такую ситуацию: кто-то написал класс Dog, в котором использу- ется внутренний атрибут экземпляра mood , который автор не хотел раскрывать клиентам. Нам нужно написать подкласс Dog – Beagle . Если мы создадим свой атрибут экземпляра mood , не подозревая о конфликте имен, то затрем атрибут mood , используемый в методах, унаследованных от Dog. Отлаживать такую ошиб- ку непросто. Чтобы предотвратить это, мы можем назвать атрибут __mood (с двумя началь- ными подчерками и, возможно, одним – не более – конечным подчерком). Тогда Python сохранит имя в словаре экземпляра __dict__ , добавив в начало один под- черк и имя класса, т. е. в классе Dog атрибут __mood будет называться _Dog__mood , а в классе Beagle – _Beagle__mood . Эта особенность языка имеет прелестное назва- ние – декорирование имен (name mangling). В примере 9.10 показано, как это выглядит в классе Vector2d из примера 9.7.\n--- Страница 292 ---\n292 Глава 9. Объект в духе Python Пример 9.10. Имена закрытых атрибутов «декорируются» добавлением префикса _ и имени класса >>> v1 = Vector2d(3, 4) >>> v1.__dict__{'_Vector2d__y': 4.0, '_Vector2d__x': 3.0}>>> v1._Vector2d__x3.0 Декорирование имен служит скорее для защиты, чем для обеспечения безопас- ности, идея в том, чтобы предотвратить случайный доступ, а не намеренное жела-ние причинить зло (на рис. 9.1 изображено еще одно предохранительное устрой-ство). Рис. 9.1. Крышка рубильника – это предохранительное устройство, не гарантирующее безопасность, она предотвращает случайное, а не злонамеренное включение Любой программист, знающий, как устроено декорированное имя, может на- прямую прочитать закрытый атрибут, как показано в последней строке приме-ра 9.10, – и это полезно для отладки и сериализации. Можно также присвоить значение закрытому компоненту Vector2d , просто написав v1._Vector__x = 7 . Но если вы так сделаете в производственном коде, то жаловаться на то, что программа перестала работать, будет некому. Декорирование имен нравится далеко не всем питонистам, как и неприглядные имена вида self.__x . Некоторые предпочитают вместо этого добавлять одиноч- ный подчерк, чтобы «защитить» атрибуты по соглашению (например, self._x ). Критики автоматического декорирования имен с двумя начальными подчерками говорят, что проблему случайного затирания атрибутов следует решать с помо-щью соглашений об именовании. Вот полная цитата из плодовитого автора Яна Байкинга, часть которой сделана эпиграфом к этой главе. Ни в коем случае не используйте два подчерка в начале. Это при- ватно до безобразия. Если конфликт имен представляет проблему, применяйте явное декорирование (например, _MyThing_blahblah ).\n--- Страница 293 ---\n293 Экономия памяти с помощью атрибута класса __slots__ По сути дела, это то же самое, что два подчерка, только делает про- зрачным то, что два подчерка скрывают7. Одиночный начальный подчерк в именах атрибутах не означает ничего осо- бенного для интерпретатора Python, но в среде программистов, пишущих на этом языке, бытует соглашение о том, что не надо обращаться к таким атрибутам из-вне самого класса 8. Нетрудно уважать право на приватность объекта, который по- мечает свои атрибуты одиночным знаком _, равно как и соблюдать соглашение о том, что переменные с именами, состоящими только из заглавных букв ( ALL_CAPS ), должны считаться константами. Атрибуты с одиночным подчерком в начале в некоторых уголках докумен- тации Python называются «защищенными»9. Практика «защиты» атрибутов соглашением вида self._x широко распространена, но название «защищен- ный» не столь употребительно. Некоторые даже называют такие атрибуты «за-крытыми». Подведем итог: компоненты класса Vector2d «закрыты», а экземпляры Vector2d «неизменяемы». У страшающие кавычки поставлены, потому что на са- мом деле не существует способа сделать их по-настоящему закрытыми и неиз-меняемыми 10. Но вернемся к классу Vector2d . В последнем разделе мы рассмотрим специ- альный атрибут (не метод) __slots__ , который влияет на внутреннее хранение данных в объекте, что может заметно сократить потребление памяти, но почти не сказывается на открытом интерфейсе класса. Экономия памяти с помощью атрибута класса __slots__ По умолчанию Python хранит атрибуты экземпляра в словаре __dict__ , принад- лежащем самому экземпляру. В разделе «Практические последствия механизма работы dict» главы 3 мы видели, что со словарями сопряжены значительные на-кладные расходы из-за того, что для обеспечения быстрого доступа использует-ся хэш-таблица. Если имеются миллионы экземпляров, а количество атрибутов у каждого мало, то атрибут класса __slots__ позволит сэкономить очень много памяти за счет того, что интерпретатору разрешено хранить атрибуты экземпляра не в словаре, а в кортеже. 7 Из «Руководства по стилю программирования в Paste» ( http://pythonpaste.org/StyleGuide.html ). 8 В модулях одиночный подчерк в начале имени верхнего уровня имеет специальный смысл: если написать from mymod import * , то имена с префиксом _ не будут импортироваться из mymod . Но ничто не мешает явно написать from mymod import _privatefunc . Это объясняется в «Учебном пособии по Python» в разделе 6.1 «Еще о модулях» ( http://bit.ly/1Gt95rp ). 9 Один такой пример – документация по модулю gettext ( http://bit.ly/1Gt9cDg ). 10 Если такое состояние дел вас угнетает и вызывает желание сделать Python больше похожим в этом отношении на Java, не читайте мои высказывания по поводу относительности возможностей моди-фикатора private в Java во врезке «Поговорим».\n--- Страница 294 ---\n294 Глава 9. Объект в духе Python Атрибут __slots__ , унаследованный от суперкласса, не оказы- вает никакого влияния. Python принимает в расчет только атрибу-ты __slots__ , определенные в самом классе. Для того чтобы определить __slots__ , мы создаем атрибут класса с таким име- нем и присваиваем ему итерируемый объект, содержащий строковые идентифика-торы атрибутов экземпляра. Я предпочитаю использовать для этой цели кортеж, потому что тем самым явно даю понять, что определение __slots__ не может из- меняться. Пример 9.11. vector2d_v3_slots.py: по сравнению с версией Vector2d добавился только атрибут __slots__ class Vector2d: __slots__ = ('__x', '__y') typecode = 'd' # прочие методы (в книге опущены) Определяя в классе атрибут __slots__ , мы говорим интерпретатору: «Это все атрибуты экземпляра в данном классе». Тогда Python помещает их в кортежепо-добную структуру в каждом экземпляре, что позволяет избежать накладных рас-ходов на хранение словаря __dict__ . При наличии миллионов одновременно ак- тивных экземпляров экономия памяти может оказаться весьма существенной. При работе с миллионами объектов, содержащих числовые дан- ные, следует использовать массивы NumPy (см. раздел «NumPy и SciPy» в главе 2), которые не только эффективно расходуют па-мять, но и располагают оптимизированными функциями, в том числе применяемыми к массиву в целом. Я проектировал класс Vector2d только для того, чтобы было на чем обсуждать специ- альные методы, т . к. стараюсь по возможности избегать бессмыс-ленных примеров с foo и bar. В примере 9.12 показаны результаты двух запусков скрипта, который просто строит с помощью спискового включения список, содержащий 10 000 000 эк-земпляров Vector2d . Скрипт mem_test.py принимает имя модуля, содержащего вариант класса Vector2d . При первом прогоне я взял класс vector2d_v3.Vector2d (из примера 9.7), а при втором – класс vector2d_v3_slots.Vector2d с атрибутом __slots__ .\n--- Страница 295 ---\n295 Экономия памяти с помощью атрибута класса __slots__ Пример 9.12. mem_test.py создает 10 миллионов экземпляров класса Vector2d из указанного при запуске модуля (например, vector2d_v3.py) $ time python3 mem_test.py vector2d_v3.py Selected Vector2d type: vector2d_v3.Vector2dCreating 10,000,000 Vector2d instancesInitial RAM usage: 5,623,808 Final RAM usage: 1,558,482,944 real 0m16.721s user 0m15.568ssys 0m1.149s$ time python3 mem_test.py vector2d_v3_slots.pySelected Vector2d type: vector2d_v3_slots.Vector2dCreating 10,000,000 Vector2d instancesInitial RAM usage: 5,718,016 Final RAM usage: 655,466,496 real 0m13.605s user 0m13.163ssys 0m0.434s Как видно из примера 9.12, потребление памяти составляет 1,5 ГБ при исполь- зовании в каждом из 10 миллионов экземпляров Vector2d словаря __dict__ , но снижается до 655 МБ, если используется атрибут __slots__ . К тому же, версия с __slots__ еще и быстрее. Скрипт mem_test.py просто загружает модуль, измеряет потребление памяти и красиво выводит результаты. Его код не имеет отношения к делу, но приведен в приложении A (пример A-4). Если в классе определен атрибут __slots__ , то запрещается включать в его экземпляры какие-либо атрибуты, кроме пере-численных в __slots__ . Но это побочный эффект , а не причина су- ществования __slots__ . Считается дурным тоном использовать __slots__ только для того, чтобы не дать пользователям класса создавать новые атрибуты в его экземплярах. Атрибут __slots__ предназначен для оптимизации, а не для связывания рук про-граммистам. Однако же возможно и «память сэкономить, и косточкой не подавиться»: если добавить имя '__dict__' в список __slots__ , то все атрибуты, перечисленные в __slots__ , будут храниться в кортеже, принадлежащем экземпляру, но при этом разрешено динамически создавать новые атрибуты, которые хранятся в слова-ре __dict__ , как обычно. Разумеется, помещение '__dict__' в атрибут __slots__ может свести на нет все преимущества последнего, но это зависит от количества статических и динамических атрибутов и того, как они используются. Бездумная оптимизация еще хуже преждевременной.\n--- Страница 296 ---\n296 Глава 9. Объект в духе Python Существует еще один специальный атрибут экземпляра, который имеет смысл сохранить: __weakref__ необходим, чтобы объект поддерживал слабые ссылки (см. раздел «Слабые ссылки» главы 8). По умолчанию этот атрибут присутствует в экземплярах всех пользовательских классов. Однако если в классе определен атрибут __slots__ , а вам нужно, чтобы его экземпляры могли быть объектами сла- бых ссылок, то '__weakref__' необходимо явно включить в список имен атрибутов в __slots__ . Подведем итоги. С атрибутом __slots__ связаны некоторые подводные камни, его не следует использовать, чтобы запретить пользователям динамически рас-ширять состав атрибутов объекта. Наибольшую пользу от него можно получить при работе с табличными данными, например, записями из базы данных, когда схема по определению фиксирована, а набор данных может быть очень велик. Но если вы регулярно занимаетесь такими задачами, то следует изучить не только пакет NumPy ( http://www.numpy.org ), но и библиотеку для анализа данных pandas (http://pandas.pydata.org ), которая умеет работать с нечисловыми данными, а так- же производить импорт и экспорт в различных табличных форматах. Проблемы при использовании __slots__ Таким образом, атрибут __slots__ при правильном использовании может дать значительную экономию памяти, но есть несколько подводных камней. • Не забывайте заново объявлять __slots__ в каждом подклассе, потому что унаследованный атрибут интерпретатор игнорирует. • Экземпляры класса могут иметь только атрибуты, явно перечисленные в __slots__ , если не включено также имя '__dict__' (однако при этом вся экономия памяти может быть сведена на нет). • Экземпляры класса не могут быть объектами слабых ссылок, если не вклю- чить в __slots__ имя '__weakref__' . Создавать необычный и неочевидный класс, экземпляры которого не всегда допускают динамическое создание атрибутов и, возможно, не поддерживают сла-бые ссылки, имеет смысл, только если программа работает с миллионами экзем-пляров. Как и любую оптимизацию, атрибут __slots__ следует использовать лишь в случае, когда это оправдано, а выигрыш доказан путем аккуратного профилиро-вания. Последняя тема этой главы – переопределение атрибутов класса в экземплярах и подклассах. Переопределение атрибутов класса Отличительной особенностью Python является использование атрибутов класса в качестве значений по умолчанию для атрибутов экземпляра. В классе Vector2d имеется атрибут класса typecode . Он дважды используется в методе __bytes__ , но там мы осознанно писали self.typecode . Поскольку экземпляры класса Vector2d\n--- Страница 297 ---\n297 Переопределение атрибутов класса создаются без собственного атрибута typecode , значение self.typecode по умолча- нию берется из атрибута класса Vector2d.typecode . Но если мы упоминаем в коде имя несуществующего атрибута, то создается новый атрибут экземпляра, например typecode , а одноименный атрибут класса остается без изменения. Однако, начиная с этого момента, всякий раз как код, ра-ботающий с этим экземпляром, видит self.typecode , читается атрибут typecode экземпляра, т. е. атрибут класса с тем же именем маскируется. Это открывает воз-можность настроить отдельный экземпляр, изменив в нем typecode . По умолчанию Vector2d .typecode равен 'd', т. е. при экспорте в тип bytes каждая компонента вектора представляется 8-байтовым числом с плавающей точкой двойной точности. Если же перед экспортом присвоить атрибуту type- code конкретного экземпляра Vector2d значение 'f', то каждая компонента будет экспортироваться в виде 4-байтового числа с плавающей точкой одинарной точности. См. пример 9.13. Поскольку мы обсуждаем динамическое добавление атрибу- та, то в примере 9.13 используется реализация Vector2d без __ slots__ , показанная в примере 9.9. Пример 9.13. Настройка экземпляра путем установки атрибута typecode , первоначально унаследованного от класса >>> from vector2d_v3 import Vector2d >>> v1 = Vector2d(1.1, 2.2)>>> dumpd = bytes(v1)>>> dumpdb'd\\x9a\\x99\\x99\\x99\\x99\\x99\\xf1?\\x9a\\x99\\x99\\x99\\x99\\x99\\x01@'>>> len(dumpd) # /g110 17>>> v1.typecode = 'f' # /g111 >>> dumpf = bytes(v1)>>> dumpfb'f\\xcd\\xcc\\x8c?\\xcd\\xcc\\x0c@'>>> len(dumpf) # /g112 9>>> Vector2d.typecode # /g113 'd' /g110 Подразумеваемое по умолчанию представление bytes имеет длину 17 бай-имеет длину 17 бай- длину 17 бай-длину 17 бай- 17 бай-бай- тов. /g111 Присваиваем typecode значение 'f' в экземпляре v1. /g112 Теперь длина представления в виде bytes составляет 9 байтов. /g113 Vector2d.typecode не изменился; атрибут typecode равен 'f'только в экзем- пляре v1.\n--- Страница 298 ---\n298 Глава 9. Объект в духе Python Теперь должно быть понятно, почему при экспорте объекта Vector2d в формате bytes результирующее представление начинается с typecode : мы хотели поддер- жать различные форматы экспорта. Если вы хотите изменить сам атрибут класса, то должны присвоить ему значе- ние напрямую, а не через экземпляр. Чтобы изменить значение typecode по умол- чанию, распространяющееся на все экземпляры (не имеющие собственного атри-бута typecode ), нужно написать: >>> Vector2d .typecode = 'f' Однако существует идиоматический способ добиться более постоянного эф- фекта и явно выразить смысл изменения. Поскольку атрибуты класса открыты и наследуются подклассами, то принято настраивать атрибут класса в подклассе. В основанных на классах представлениях Django эта техника применяется сплошь и рядом. Она демонстрируется в примере 9.14. Пример 9.14. ShortVector2d – подкласс Vector2d , единственное отличие которого – переопределение атрибута typecode по умолчанию >>> from vector2d_v3 import Vector2d >>> class ShortVector2d(Vector2d): # /g110 typecode = 'f' >>> sv = ShortVector2d(1/11, 1/27) # /g111 >>> svShortVector2d(0.09090909090909091, 0.037037037037037035) # /g112 >>> len(bytes(sv)) # /g113 9 /g110 Создаем ShortVector2d как подкласс Vector2d только для того, чтобы пере- определить атрибут класса typecode . /g111 Создаем экземпляр ShortVector2d – объект sv. /g112 Инспектируем представление sv. /g113 Проверяем, что экспортировано 9 байтов, а не 17, как раньше. Этот пример также объясняет, почему я не стал «зашивать» значение class_name в код Vecto2d.__repr__ , а получаю его в виде type(self).__name__ : # в классе Vector2d: def __repr__(self): class_name = type(self).__name__ return '{}({!r}, {!r})'.format(class_name, *self) Если бы я зашил class_name , то подклассы Vector2d и, в частности, ShortVec- tor2d должны были бы переопределять метод __repr__ только для того, чтобы из- менить class_name . А, получая имя от функции type , примененной к экземпляру, я сделал __repr__ безопасным относительно наследования. На этом завершается рассмотрение реализации простого класса, который ведет себя как положено в Python, пользуясь средствами, предоставляемыми моделью\n--- Страница 299 ---\n299 Резюме данных: предлагает различные представления объекта, реализует специализиро- ванный код форматирования, раскрывает атрибуты, доступные только для чтения, и поддерживает метод hash() для интеграции с множествами и отображениями. Резюме Целью этой главы была демонстрация специальных методов и соглашений в про-цессе разработки класса Python, который ведет себя ожидаемо. Можно ли сказать, что реализация в файле vector2d_v3.py (пример 9.9) луч- ше соответствует духу Python, чем та, что находится в файле vector2d_v0.py (при- мер 9.2)? Конечно, в классе Vector2d из файла vector2d_v3.py задействовано боль- ше механизмов Python. Но какую версию считать более идиоматичной, зависит от контекста использования. В «Дзен Python» Тима Питера сказано: Простое лучше, чем сложное. Объект Python должен быть настолько простым, насколько возможно при соблюдении требований, – а не выставкой языковых средств. Но, развивая код Vector2d , я ставил себе целью предложить контекст для обсуждения специальных методов и соглашений о кодировании. В листингах из этой главы продемонстрированы следующие средства, упомянутые в табл. 1.1: • все методы строкового и байтового представления: __repr__ , __str__ , __format__ и __bytes__ . • несколько методов преобразования объекта в число: __abs__ , __bool__ , __hash__ . • оператор __eq__ для тестирования преобразования в bytes и поддержки хэ- ширования (наряду с методом __hash__ ). Обеспечивая поддержку преобразования в bytes , мы заодно реализовали аль- тернативный конструктор Vector2d.frombytes() и попутно получили предлог для обсуждения декораторов @classmethod (очень полезного) и @staticmethod (не столь полезного, поскольку функции уровня модуля проще). Идея метода from- bytes позаимствована у его тезки из класса array.array . Мы видели, что миниязык спецификации формата ( https://docs.python.org/3/ library/string.html#formatspec ) можно расширить путем реализации метода __format__ , который осуществляет несложный разбор строки format_spec , пере- даваемой встроенной функции format(obj, format_spec) или включенной в поле подстановки '{:\"format_spec\" }' в случае метода str.format . Прежде чем сделать экземпляры класса Vector2d хэшируемыми, мы постара- лись обеспечить их неизменяемость или, по крайней мере, предотвратить случай-ное изменение. Для этого мы сделали атрибуты x и y закрытыми и предоставили к ним доступ через свойства, доступные только для чтения. Затем мы реализовали метод __hash__ , применяя рекомендуемую технику: объединить хэши атрибутов экземпляра с помощью оператора ИСКЛЮЧАЮЩЕЕ ИЛИ.\n--- Страница 300 ---\n300 Глава 9. Объект в духе Python Далее мы обсудили экономию памяти, достигаемую с помощью атрибута __slots__ в классе Vector2d , и опасности, подстерегающие на этом пути. Поскольку с использованием __slots__ сопряжены некоторые сложности, делать это имеет смысл только при работе с очень большим количеством экземпляров – порядка миллионов, а не тысяч. И напоследок мы обсудили вопрос о переопределении атрибута класса при доступе через экземпляры (например, self.typecode ). Для этого мы сначала создали атрибут конкретного экземпляра, а затем породили подкласс и переопределили в нем атрибут на уровне класса. В этой главе я не раз отмечал, что проектные решения, принимаемые при раз- работке примеров, были основаны на изучении API стандартных объектов Python. Если бы меня попросили свести содержание главы к одной фразе, я бы сказал: Создавая объекты в духе Python, наблюдайте за поведением насто- ящих объектов Python. – Старинная китайская пословица Дополнительная литература В этой главе рассмотрено несколько специальных методов модели данных, поэто- му естественно, что ссылки, в основном, те же, что в главе 1, где был дан общий обзор той же темы. Для удобства я повторю несколько предыдущих рекомендаций и добавлю ряд новых: Глава «Модель данных» справочного руководства по языку Python (http://bit. ly/1GsZwss) Большинство использованных в этой главе методов документировано в разделе 3.3.1 «Простая настройка» ( http://bit.ly/1Vma6b2 ). Alex Martelli «Python in a Nutshell», издание 2 (O'Reilly) Отлично описывается модель данных, хотя охвачена только версия Python 2.5 (во втором издании). Но фундаментальные идеи остались теми же, да и большинство API модели данных не менялись с момента выхода версии Python 2.2, в которой улучшилась совместимость встроенных типов и пользовательских классов. David Beazley, Brian K. Jones «Python Cookbook», издание 2 В многочисленных рецептах демонстрируются весьма современные подхо- ды к кодированию. Особый интерес представляет глава 8 «Классы и объ-екты», в которой приведено несколько решений, относящихся к тематике этой главы. David Beazley «Python Essential Reference», издание 4 Подробно рассматривается модель данных в контексте Python 2.6 и Python 3.\n--- Страница 301 ---\n301 Поговорим В этой главе мы рассмотрели все специальные методы, относящиеся к пред- ставлению объектов, кроме __index__ . Последний служит для приведения объек- та к целочисленному индексу в контексте получения среза последовательности. Он был введен для решения одной проблемы в NumPy. На практике нам с вами вряд ли придется реализовывать метод __index__ , если только мы не захотим на- писать новый числовой тип данных, да еще так, чтобы объекты этого типа можно было передавать в качестве аргументов __getitem__ . Если вас это интересует, по- читайте статью А. М. Кухлинга «What's New in Python 2.5» ( https://docs.python. org/2.5/whatsnew/pep-357.html ), где приведено краткое объяснение, а также доку- мент «PEP 357 – Allowing Any Object to be Used for Slicing» ( https://www.python. org/dev/peps/pep-0357/ ), где детально обосновывается необходимость метода __index__ с точки зрения автора C-расширения, Трэвиса Олифанта – ведущего разработчика NumPy. Впервые необходимость различных строковых представлений объекта была осознана в языке Smalltalk. В статье 1996 года «How to Display an Object as a String: printString and displayString» ( http://bit.ly/1IIKX6t ) Бобби Вулф (Bobby W oolf) обсуждает реализацию методов printString и displayString в этом языке. Из этой статьи я позаимствовал выражения «в виде, удобном для разработчика» и «в виде, удобном для пользователя» для описания методов repr() и str() в разделе «Пред- ставления объекта». Поговорим Свойства позволяют снизить начальные затраты В первых версиях класса Vector2d атрибуты x и y были открытыми, как и все атрибуты класса и экземпляра по умолчанию. Естественно, пользователям вектора необходим доступ к его компонентам. И хотя наши векторы являются итерируемыми объектами и могут быть распа-кованы в пару переменных, желательно также иметь возможность пи-сать my_vector.x и my_vector.y для прямого доступа к компонентам по отдельности. Осознав необходимость воспрепятствовать случайному изменению атрибутов x и y, мы реализовали свойства, но больше нигде – ни в коде, ни в открытом интерфейсе класса Vector2d – менять ничего не при- шлось, что доказывают doctest-скрипты. Мы по-прежнему можем об-ращаться к компонентам с помощью нотации my_vector.x и my_vector.y . Это доказывает, что начинать разработку класса всегда надо с про- стейшего варианта, оставив атрибуты открытыми, а когда (и если) мы впоследствии захотим усилить контроль доступа с помощью методов чтения и установки, это можно будет сделать, реализовав свойства и ни-чего не меняя в уже написанном коде работы с компонентами объекта по именам (например, x и y), которые первоначально были просто от- крытыми атрибутами.\n--- Страница 302 ---\n302 Глава 9. Объект в духе Python Такой подход прямо противоположен пропагандируемому в Java: там программист не может начать с простых атрибутов, а впоследствии, если понадобится, перейти на свойства, потому что таковых в языке по-просту не существует. Поэтому написание методов чтения и установки считается нормой в Java – даже если эти методы не делают ничего по-лезного, – так как при переходе от открытых атрибутов к акцессорам весь ранее написанный код перестанет работать. Кроме того, как заметил наш технический рецензент Алекс Мартел- ли, набирать всюду обращения к методам чтения и установки как-то тупо. Приходится писать: --- >>> my_object.set_foo(my_object.get_foo() + 1)--- вместо куда более краткого: --->>> my_object .foo += 1 --- У орд Каннингэм, изобретатель вики и основоположник экстремаль- ного программирования, рекомендует задавать себе вопрос: «Как напи-сать самый простой код, который будет это делать?» Идея в том, чтобы сосредоточить все внимание на цели 11. Реализация акцессоров с самого начала только отвлекает от цели. В Python мы можем просто использо-вать открытые атрибуты, зная, что при необходимости сумеем в любой момент заменить их свойствами. Закрытые атрибуты – защита и безопасность Perl не одержим идеей навязать закрытость во что бы то ни ста- ло. Он предпочитает, чтобы вы не входили в дом, потому что вас туда не приглашали, а не потому что там стоит пулемет. – Ларри У олл, создатель Perl Во многих отношениях Python и Perl – полные противоположности, но в вопросе о закрытости объектов Ларри и Гвидо, похоже, едины. За годы преподавания Python многочисленным программистам на Java я понял, что многие чрезмерно уповают на гарантии закрыто-сти, предоставляемые Java. Но на самом деле модификаторы private и protected в Java защищают только от непреднамеренных случайностей. Защитить от злого умысла они могут, лишь если приложение разверну-то с диспетчером безопасности, а такое редко встречается на практике, даже в корпоративной среде. 11 См. «Simplest Thing that Could Possibly W ork: A Conversation with Ward Cunningham, Part V» ( http://www.artima.com/intv/simplest3.html ).\n--- Страница 303 ---\n303 Поговорим Для доказательства этого положения я обычно приводу следующий класс Java. Пример 9.15. Confidential.java: класс Java с закрытым полем secret public class Confidential { private String secret = «»; public Confidential(String text) { secret = text .toUpperCase(); }} Здесь я сохраняю текст в поле secret , предварительно преобразовав его в верхний регистр, чтобы значение этого поля гарантированно было записано заглавными буквами. Собственно демонстрация заключается в выполнении скрипта expose.py интерпретатором Jython. Этот скрипт применяет интроспек- цию (в терминологии Java – «отражение»), чтобы получить значение закрытого поля. Код показан в примере 9.16. Пример 9.16. expose.py: Jython-код для чтения содержимого закрытого поля другого класса import Confidential message = Confidential('top secret text') secret_field = Confidential.getDeclaredField('secret')secret_field.setAccessible(True) # замок взломан!print 'message.secret =', secret_field.get(message) Выполнив пример 9.16, получим: $ jython expose.pymessage.secret = TOP SECRET TEXT Строка 'TOP SECRET TEXT' прочитана из закрытого поля secret класса Confidential . Никакой черной магии тут нет: скрипт expose.py применяет API отра- жения Java, чтобы получить ссылку на закрытое поле с именем 'secret' , а затем вызывает метод 'secret_field .setAccessible(True)' , чтобы сде- лать его доступным для чтения. Разумеется, то же самое можно сделать и в коде на Java (только придется написать в три раза больше строк, см. файл Expose.java в репозитории кода к этой книге по адресу https:// github.com/fluentpython/example-code ). Решающий вызов .setAccessible(True) завершится с ошибкой, только если скрипт Jython или главная программа Java (например, Expose .class )\n--- Страница 304 ---\n304 Глава 9. Объект в духе Python работает под управлением диспетчера безопасности SecurityManager (http://bit.ly/1IIMdqd ). Но на практике Java-приложения редко развер- тываются таким образом – если не считать Java-аплетов (помните, были такие?). Мой вывод: в Java модификаторы контроля доступа тоже обеспечи- вают лишь защиту, но не безопасность, по крайней мере, на практике. Поэтому расслабьтесь и получайте удовольствие от могущества, кото-рым наделяет вас Python. Но применяйте его ответственно.",
      "debug": {
        "start_page": 276,
        "end_page": 304
      }
    },
    {
      "name": "Глава 10. Рубим, перемешиваем и нарезаем последовательности 305",
      "content": "--- Страница 305 --- (продолжение)\nГЛАВА 10. Рубим, перемешиваем и нарезаем последовательности Не проверяйте, утка ли это; проверяйте, что оно крякает, как утка, хо-дит, как утка и т. д. и т. п. – в зависимости от того, какая часть поведе-ния утки важна в ваших языковых игрищах (comp.lang.python, 26 июля 2000). – Алекс Мартелли В этой главе мы напишем класс Vector для представления многомерного векто- ра – заметный шаг вперед по сравнению с классом двумерного вектора Vector2d из главы 9. Класс Vector будет вести себя, как стандартная плоская неизменяемая последовательность в Python. Ее элементами будут числа с плавающей точкой, и окончательная версия будет поддерживать следующие возможности: • базовый протокол последовательности: методы __len__ и __getitem__ ; • безопасное представление экземпляров со многими элементами;• поддержка операции среза, в результате которой получается новый экзем- пляр Vector ; • хэширование агрегата с учетом значений всех содержащихся в нем элемен- тов; • расширение языка форматирования. Мы также реализуем доступ к динамическим атрибутам с помощью метода __getattr__ – как замену доступных только для чтения свойств в классе Vector2d , – хотя для типов последовательностей такая функциональность нетипична. Демонстрация кода будет прерываться обсуждением самой идеи протокола как неформального интерфейса. Мы поговорим о связи протоколов и динамической типизации, а также о ее практических следствиях для создания пользовательских типов. Итак, начнем.\nГЛАВА 10. Рубим, перемешиваем и нарезаем последовательности Не проверяйте, утка ли это; проверяйте, что оно крякает, как утка, хо-дит, как утка и т. д. и т. п. – в зависимости от того, какая часть поведе-ния утки важна в ваших языковых игрищах (comp.lang.python, 26 июля 2000). – Алекс Мартелли В этой главе мы напишем класс Vector для представления многомерного векто- ра – заметный шаг вперед по сравнению с классом двумерного вектора Vector2d из главы 9. Класс Vector будет вести себя, как стандартная плоская неизменяемая последовательность в Python. Ее элементами будут числа с плавающей точкой, и окончательная версия будет поддерживать следующие возможности: • базовый протокол последовательности: методы __len__ и __getitem__ ; • безопасное представление экземпляров со многими элементами;• поддержка операции среза, в результате которой получается новый экзем- пляр Vector ; • хэширование агрегата с учетом значений всех содержащихся в нем элемен- тов; • расширение языка форматирования. Мы также реализуем доступ к динамическим атрибутам с помощью метода __getattr__ – как замену доступных только для чтения свойств в классе Vector2d , – хотя для типов последовательностей такая функциональность нетипична. Демонстрация кода будет прерываться обсуждением самой идеи протокола как неформального интерфейса. Мы поговорим о связи протоколов и динамической типизации, а также о ее практических следствиях для создания пользовательских типов. Итак, начнем.\n--- Страница 306 ---\n306 Глава 10. Рубим, перемешиваем и нарезаем последовательности Где применяются векторы размерности выше 3 Кому нужен вектор с 1000 измерений? Подсказка: не 3D-дизайнерам! Тем не менее, n-мерные векторы (с большим значением n) широко ис- пользуются в информационном поиске, где документы и тексты запро-сов представляются в виде векторов, по одному измерению на каждое слово. Это называется векторной моделью ( http://en.wikipedia.org/wiki/ V ector_space_model ). В векторной модели в качестве основной меры ре- левантности используется коэффициент Отиаи (косинус угла между вектором запроса и вектором документа). При уменьшении угла его косинус стремится к максимальному значению 1, а вместе с ним и реле-вантность документа запросу. Однако в этой главе класс Vector приведен только в педагогических целях, так что математики почти не будет. У нас более узкая задача – продемонстрировать специальные методы Python в контексте последо-вательностей. Для выполнения серьезных математических операций над вектора- ми понадобятся библиотеки NumPy и SciPy. В пакете gemsim ( https:// pypi.python.org/pypi/gensim ) Радима Рехурека (Radim Rehurek) реали- зована векторная модель для обработки естественных языков и инфор-мационного поиска с использованием NumPy и SciPy. Vector: пользовательский тип последовательности При реализации класса Vector мы будем пользоваться не наследованием, а компо- зицией. Компоненты вектора будут храниться в массиве array чисел с плавающей точкой, и мы напишем методы, необходимые для того, чтобы Vector вел себя, как неизменяемая плоская последовательность. Но перед тем как приступать к методам последовательностей, разработаем ба- зовую реализацию класса Vector , которая будет совместима с написанным ранее классом Vector2d – за исключением случаев, где говорить о совместимости не име- ет смысла. Vector, попытка № 1: совместимость с Vector2d Первая версия Vector должна быть по возможности совместима с классом Vector2d . Однако же конструктор Vector мы не станем делать совместимым. Можно было бы добиться работоспособности выражений Vector(3, 4) и Vector(3, 4, 5) ,\n--- Страница 307 ---\n307 Vector, попытка № 1: совместимость с Vector2d разрешив задавать произвольное число аргументов с помощью конструкции *args в методе __init__ , но обычно конструктор последовательности принимает данные в виде итерируемого объекта – как все встроенные типы последовательностей. В примере 10.1 показано несколько способов создания объектов класса Vector . Пример 10.1. Тесты методов Vector.__init__ и Vector.__repr__ >>> Vector([3.1, 4.2]) Vector([3.1, 4.2])>>> Vector((3, 4, 5))Vector([3.0, 4.0, 5.0])>>> Vector(range(10))Vector([0.0, 1.0, 2.0, 3.0, 4.0, ]) Помимо сигнатуры конструктора, я включил тесты, которые проходили для Vector2d (например, Vector2d(3, 4) ). Они должны проходить и для Vector и давать такие же результаты. Если у вектора больше шести компонент , то вместо окончания строки, порожденной методом repr() , выводится , как в по- следней строчке примера 10.1. Это существенно для любого типа коллекции, в котором может быть много элементов, потому что repr применяется для отладки (и вряд ли вам понравится, когда один объект занимает тысячи строк на консоли или в журнале). Для создания укороченных представлений используйте модуль reprlib , как в примере 10.2. В Python 2 модуль reprlib называется repr . Программа 2to3 ав- томатически подменяет предложения импорта repr . В примере 10.2 приведена реализация первой версии класса Vector (она осно- вана на коде из примеров 9.2 и 9.3). Пример 10.2. vector_v1.py: основана на vector2d_v1.py from array import array import reprlibimport math class Vector: typecode = 'd' def __init__(self, components): self._components = array(self.typecode, components) /g110 def __iter__(self): return iter(self._components) /g111 def __repr__(self):\n--- Страница 308 ---\n308 Глава 10. Рубим, перемешиваем и нарезаем последовательности components = reprlib.repr(self._components) /g112 components = components[components.find('['):-1] /g113 return 'Vector({})'.format(components) def __str__(self): return str(tuple(self)) def __bytes__(self): return (bytes([ord(self.typecode)]) + bytes(self._components)) /g114 def __eq__(self, other): return tuple(self) == tuple(other) def __abs__(self): return math.sqrt(sum(x * x for x in self)) /g115 def __bool__(self): return bool(abs(self)) @classmethod def frombytes(cls, octets): typecode = chr(octets[0]) memv = memoryview(octets[1:]).cast(typecode) return cls(memv) /g116 /g110 В «защищенном» атрибуте экземпляра self._components хранится массив array компонент Vector . /g111 Чтобы было возможно итерирование, возвращаем итератор, построенный по self._components .1 /g112 Используем reprlib.repr() для получения представления self._compo- nents ограниченной длины (например, array('d', [0.0, 1.0, 2.0, 3.0, 4.0, ]) ). /g113 У даляем префикс array('d' и закрывающую скобку ), перед тем как под- ставить строку в вызов конструктора Vector . /g114 Строим объект bytes из self._components . /g115 Метод hypot больше не применим, поэтому вычисляем сумму квадратов компонент и извлекаем из нее квадратный корень. /g116 Единственное отличие от написанного ранее метода frombytes – последняя строка: мы передаем объект memoryview напрямую конструктору, не распа- ковывая его с помощью *, как раньше. То, как я использовал функцию reprlib.repr , заслуживает пояснения. Эта функция порождает безопасное представление длинной или рекурсивной струк-туры путем ограничения длины выходной строки с заменой отброшенного окон-чания многоточием ' ' . Я хотел, чтобы repr -представление Vector имело вид Vector([3.0, 4.0, 5.0]) , а не Vector(array('d', [3.0, 4.0, 5.0])) , потому что присутствие array внутри Vector – деталь реализации. Поскольку оба вызова кон- 1 Функция iter() рассматривается в главе 14 наряду с методом __ iter__ .\n--- Страница 309 ---\n309 Протоколы и динамическая типизация структора возвращают одинаковые объекты Vector , я предпочел более простой синтаксис с использованием аргумента типа list . При написании метода __repr__ я мог бы вывести упрощенное отображение components с помощью такого выражения: reprlib.repr(list(self._components)) . Но это было бы расточительно, поскольку пришлось бы копировать каждый эле-мент self._components в list только для того, чтобы использовать list repr . Вмес- то этого я решил применить reprlib.repr непосредственно к массиву self._compo- nents , а затем отбросить все символы, оказавшиеся вне квадратных скобок []. Для этого и предназначена вторая строка метода __repr__ в примере 10.2. Поскольку метод repr() вызывается во время отладки, он никог- да не должен возбуждать исключение. Если в __repr__ происхо- дит какая-то ошибка, вы должны обработать ее сами и сделать все возможное, чтобы показать пользователю нечто разумное, позволяющее идентифицировать объект . Отметим, что методы __str__ , __eq__ и __bool__ остались такими же, как в клас- се Vector2d , а в методе frombytes изменился только один символ (удален символ * в последней строке). Это воздаяние за то, что класс Vector2d изначально был сделан итерируемым. Кстати, я мог бы сделать Vector подклассом Vector2d , но не стал по двум причи- нам. Во-первых, при наличии несовместимых конструкторов создавать подклассы не рекомендуется. Эту трудность можно было бы обойти за счет хитроумной об-работки параметров в __init__ , но есть и вторая, более важная, причина: я хочу, чтобы Vector был не зависящим от других классов примером реализации протоко- ла последовательности. Этим мы и займемся далее, предварительно обсудив сам термин протокол . Протоколы и динамическая типизация Еще в главе 1 мы видели, что для создания полнофункционального типа последо- вательности в Python необязательно наследовать какому-то специальному классу; нужно лишь реализовать методы, удовлетворяющие протоколу последовательно-сти. Но что это за протокол такой? В объектно-ориентированном программировании протоколом называется неформальный интерфейс, определенный только в документации, но не в коде. Например, протокол последовательности в Python подразумевает только на-личие методов __len__ и __getitem__ . Любой класс Spam , в котором есть такие методы со стандартной сигнатурой и семантикой, можно использовать всюду, где ожидается последовательность. Является Spam подклассом какого-то дру- гого класса или нет, роли не играет. Мы видели это в примере 1.1, который воспроизведен ниже.\n--- Страница 310 ---\n310 Глава 10. Рубим, перемешиваем и нарезаем последовательности Пример 10.3. Код из примера 1.1, воспроизведенный здесь для удобства import collections Card = collections.namedtuple('Card', ['rank', 'suit'])class FrenchDeck: ranks = [str(n) for n in range(2, 11)] + list('JQKA') suits = 'spades diamonds clubs hearts'.split() def __init__(self): self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks] def __len__(self): return len(self._cards) def __getitem__(self, position): return self._cards[position] В классе FrenchDeck из примера 10.3 применяются разнообразные средства Python, потому что он реализует протокол последовательности, хотя нигде в коде об этом явно не сказано. Любому опытному программисту на Python достаточно одного взгляда на код, что понять, что это именно класс последовательности, не-смотря на то, что он является подклассом object . Мы говорим, что он является последовательностью, потому что ведет себя , как последовательность, а только это и важно. Такой подход получил название «динамическая типизация»2, и именно о нем идет речь в высказывании Алекса Мартелли, взятом в качестве эпиграфа к этой главе. Поскольку протокол – неформальное понятие, которое не подкреплено сред- ствами языка, мы зачастую можем реализовать лишь часть протокола, если точно знаем, в каком контексте будет использоваться класс. Например, для поддержки итерирования нужен только метод __getitem__ , а без метода __len__ можно обой- тись. Далее мы реализуем протокол последовательности в классе Vector , поначалу без надлежащей поддержки операции среза, но позже добавим и ее. Vector, попытка № 2: последовательность, допускающая срезку В примере класса FrenchDeck мы видели, что поддержать протокол последователь- ности очень просто, если можно делегировать работу атрибуту объекта, который 2 В оригинале используется термин duck typing (буквально «утиная типизация»), распространенный в переводной литературе, но, на мой взгляд, по-русски он звучит не слишком удачно. – Прим. перев.\n--- Страница 311 ---\n311 Vector, попытка № 2: последовательность, допускающая срезку является последовательностью, в нашем случае таким атрибутом будет массив self._components . Для начала нас вполне устроят такие однострочные методы __len__ и __getitem__ : class Vector: # много строк опущено # def __len__(self): return len(self._components) def __getitem__(self, index): return self._components[index] После этих добавлений все показанные ниже операции работают: >>> v1 = Vector([3, 4, 5])>>> len(v1)3>>> v1[0], v1[-1](3.0, 5.0)>>> v7 = Vector(range(7))>>> v7[1:4]array('d', [1.0, 2.0, 3.0]) Как видите, даже срезы поддерживаются – но не очень хорошо. Было бы лучше, если бы срез вектора также был экземпляром класса Vector , а не массивом. В ста- ром классе FrenchDeck была такая же проблема: срез оказывался объектом класса list . Но в случае Vector мы утрачиваем значительную часть функциональности, если операция среза возвращает простой массив. Рассмотрим встроенные типы последовательностей: для каждого из них опера- ция среза порождает объект того же, а не какого-то другого типа. Если мы хотим, чтобы срезы Vector тоже были объектами класса Vector , то не должны делегировать получение среза классу array . В методе __getitem__ мы должны проанализировать полученные аргументы и выполнить подходящее дей-ствие. Теперь посмотрим, как Python преобразует конструкцию my_seq[1:3] в аргу- менты вызова my_seq.__getitem__( ) . Как работает срезка Код заменяет тысячу слов, поэтому обратимся к примеру 10.4 Пример 10.4. Изучение поведения __getitem__ и срезов >>> class MySeq: def __getitem__(self, index): return index # /g110 >>> s = MySeq()\n--- Страница 312 ---\n312 Глава 10. Рубим, перемешиваем и нарезаем последовательности >>> s[1] # /g111 1>>> s[1:4] # /g112 slice(1, 4, None)>>> s[1:4:2] # /g113 slice(1, 4, 2)>>> s[1:4:2, 9] # /g114 (slice(1, 4, 2), 9)>>> s[1:4:2, 7:9] # /g115 (slice(1, 4, 2), slice(7, 9, None)) /g110 Здесь __getitem__ просто возвращает то, что ему передали. /g111 Один индекс, ничего нового. /g112 Нотация 1:4 преобразуется в slice(1, 4, None) . /g113 slice(1, 4, 2) означает: начать с 1, закончить на 4, шаг 2. /g114 Сюрприз: при наличии запятых внутри [] метод __getitem получает кор- теж. /g115 Этот кортеж может даже содержать несколько объектов среза. Теперь приглядимся внимательнее к самому классу slice . Пример 10.5. Инспекция атрибутов класса slice >>> slice # /g110 <class 'slice'>>>> dir(slice) # /g111 ['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'indices', 'start', 'step', 'stop'] /g110 slice – встроенный тип (мы это уже поняли в разделе «Объекты среза» главы 2). /g111 Инспекция slice показывает наличие атрибутов start , stop и step , а также метода indices . В примере 10.5 вызов dir(slice) показывает наличие метода indices – весьма интересного, хотя и малоизвестного. Вот что говорит о нем справка – help(slice. indices) : S.indices(len) -> (start, stop, stride) В предположении, что длина последовательности равна len, вы- числяет индексы start и stop , а также длину stride расширенного среза, представленного объектом S. Индексы, выходящие за гра- ницы, приводятся к границам так же, как при обработке обычных срезов.\n--- Страница 313 ---\n313 Vector, попытка № 2: последовательность, допускающая срезку Иначе говоря, метод indices раскрывает нетривиальную логику, применяемую во встроенных последовательностях для корректной обработки отсутствующих или отрицательных индексов и срезов, длина которых превышает длину конечной последовательности. Этот метод возвращается «нормализованные» кортежи, со-держащие неотрицательные целые числа start , stop и stride , скорректированные так, чтобы не выходить за границы последовательности заданной длины. Ниже приведено два примера для последовательности длины 5, например 'ABCDE' : >>> slice(None, 10, 2).indices(5) # /g110 (0, 5, 2)>>> slice(-3, None, None).indices(5) # /g111 (2, 5, 1) /g110 'ABCDE'[:10:2] – то же самое, что 'ABCDE'[0:5:2] . /g111 'ABCDE'[-3] – то же самое, что 'ABCDE'[2:5:1] . На момент написания этой книги метод slice.indices не был документирован в справочном руководстве по языку Python. В справочном руководстве по Python/C API описана аналогичная C-функция PySlice_GetIndicesEx ( https://docs.python.org/3/c-api/ slice.html#c.PySlice_GetIndicesEx ). Я обнаружил метод slice.in- dices , когда исследовал объекты срезов в оболочке Python с по- мощью dir() и help() . Еще одно свидетельство ценности инте- рактивной оболочки в качестве инструмента познания. В классе Vector нам не нужен метод slice.indices() , потому что, получив в аргументе срез, мы делегируем его обработку массиву _components . Но если опе- реться на средства, предоставляемые внутренней последовательностью, не полу-чается, то этот метод может сэкономить уйму времени. Теперь, разобравшись, как обрабатывать срезы, рассмотрим улучшенную реа- лизацию метода Vector.__getitem__ . Метод __getitem__ с учетом срезов В примере 10.6 приведено два метода, необходимых для того, чтобы класс Vector вел себя, как последовательность: __len__ и __getitem__ (последний теперь правильно обрабатывает срезы). Пример 10.6. Часть файла vector_v2.py: в класс Vector из файла vector_v1.py (пример 10.2) добавлены методы __len__ и __getitem__ : def __len__(self): return len(self._components) def __getitem__(self, index):\n--- Страница 314 ---\n314 Глава 10. Рубим, перемешиваем и нарезаем последовательности cls = type(self) /g110 if isinstance(index, slice): /g111 return cls(self._components[index]) /g112 elif isinstance(index, numbers.Integral): /g113 return self._components[index] /g114 else: msg = '{cls.__name__} indices must be integers' raise TypeError(msg.format(cls=cls)) /g115 /g110 Получаем класс экземпляра (т. е. Vector ), он понадобится позже. /g111 Если аргумент index принадлежит типу slice … /g112 … то вызываем класс для построения нового экземпляра Vector по срезу массива _components . /g113 Если index принадлежит типу int или другому целочисленному типу… /g114 … то просто возвращаем один конкретный элемент из _components . /g115 Иначе возбуждаем исключение. Злоупотребление функцией isinstance иногда является призна- ком неудачного объектно-ориентированного проектирования, но применение ее для обработки срезов в __getitem__ оправдано. Отметим, что в примере 10.6 мы сравниваем тип с numbers.In- tegral – абстрактным базовым классом (ABC). Указание ABC в функции insinstance делает API более гибким и защищенным от- носительно будущих изменений. В главе 11 объясняется, почему это так. К сожалению, в стандартной библиотеке Python 3.4 нет ABC для класса slice . Чтобы понять, какое исключение возбуждать в ветви else в методе __getitem__ , я воспользовался интерактивной оболочкой для инспекции выражения 'ABC'[1, 2] . В результате я выяснил, что интерпретатор Python возбуждает ис- ключение TypeError , а заодно скопировал текст сообщения об ошибке: «indices must be integers». Создавая свои объекты в духе Python, имитируйте поведение объектов, которые создает сам Python. После добавления кода из примера 10.6 в класс Vector поведение операции сре- за исправилось, что доказывает пример 10.7. Пример 10.7. Тесты улучшенного метода Vector.__getitem__ из примера 10.6 >>> v7 = Vector(range(7)) >>> v7[-1] /g110 6.0>>> v7[1:4] /g111 Vector([1.0, 2.0, 3.0])>>> v7[-1:] /g112 Vector([6.0]) /g113 >>> v7[1,2]\n--- Страница 315 ---\n315 Vector, попытка № 3: доступ к динамическим атрибутам Traceback (most recent call last): TypeError: Vector indices must be integers /g110 Если индекс – целое число, то извлекается ровно одна компонента типа float . /g111 Если задан индекс типа slice , то создается новый объект Vector . /g112 Если длина среза len == 1 , то все равно создается новый объект Vector . /g113 Класс Vector не поддерживает многомерное индексирование, поэтому при задании кортежа индексов или срезов возбуждается исключение. Vector, попытка № 3: доступ к динамическим атрибутам При переходе от класса Vector2d к Vector мы потеряли возможность обращаться к компонентам вектора по имени, например: v.x, v.y. Теперь мы имеем дело с век- торами, имеющими сколь угодно много компонент. Тем не менее, иногда удобно обращаться к нескольким первым компонентам по именам, состоящим из одной буквы, например, x, y, z вместо v[0] , v[1] и v[2] . Ниже показан альтернативный синтаксис для чтения первых четырех компо- нент вектора, который мы хотели бы поддержать: >>> v = Vector(range(10))>>> v.x0.0>>> v.y, v.z, v.t(1.0, 2.0, 3.0) В классе Vector2d мы предоставляли доступ для чтения компонент x и y с по- мощью декоратора @property (пример 9.7). Мы могли бы завести и в Vector четыре свойства, но это утомительно. Специальный метод __getattr__ позволяет сделать это по-другому и лучше. Метод __getattr__ вызывается интерпретатором, если поиск атрибута завер- шается неудачно. Иначе говоря, анализируя выражение my_obj.x , Python про- веряет, есть ли у объекта my_obj атрибут с именем x; если нет, поиск повторяет- ся в классе ( my_obj.__class__ ), а затем вверх по иерархии наследования3. Если атрибут x все равно не найден, то вызывается метод __getattr__ , определенный в классе my_obj , причем ему передается self и имя атрибута в виде строки (на- пример, 'x'). В примере 10.8 приведен код метода __getattr__ . Он проверяет, является ли искомый атрибут одной из букв xyzt , и, если да, то возвращает соответствующую компоненту вектора. 3 На самом деле, поиск атрибутов устроен сложнее. Технические детали мы обсудим в части IV , а пока достаточно и этого упрощенного объяснения.\n--- Страница 316 ---\n316 Глава 10. Рубим, перемешиваем и нарезаем последовательности Пример 10.8. Часть файла vector_v3.py: в класс Vector из файла vector_v2.py добавлен метод __getattr__ shortcut_names = 'xyzt' def __getattr__(self, name): cls = type(self) /g110 if len(name) == 1: /g111 pos = cls.shortcut_names.find(name) /g112 if 0 <= pos < len(self._components): /g113 return self._components[pos] msg = '{.__name__!r} object has no attribute {!r}' /g114 raise AttributeError(msg.format(cls, name)) /g110 Получить и запомнить класс Vector , он понадобится позже. /g111 Если имя состоит из одного символа, то этот символ может входить в стро- ку shortcut_names . /g112 Найти позицию символа, составляющего односимвольное имя; метод str. find нашел бы также строку 'yz' , но нам это не нужно, отсюда и дополни- тельная проверка строчкой выше. /g113 Если символ найден, вернуть элемент массива. /g114 Если предыдущая проверка не прошла, возбудить исключение Attribu- teError со стандартным сообщением. Реализовать метод __getattr__ просто, но в данном случае недостаточно. Рас- смотрим странное взаимодействие в примере 10.9. Пример 10.9. Неправильное поведение: присваивание v.x не приводит к ошибке, но результат получается несогласованным >>> v = Vector(range(5)) >>> vVector([0.0, 1.0, 2.0, 3.0, 4.0])>>> v.x # /g110 0.0>>> v.x = 10 # /g111 >>> v.x # /g112 10>>> vVector([0.0, 1.0, 2.0, 3.0, 4.0]) # /g113 /g110 Доступ к элементу v[0] по имени v.x. /g111 Присваиваем v.x новое значение. При этом должно бы возникнуть исклю- чение. /g112 Чтение v.x показывает новое значение, 10. /g113 Однако компоненты вектора не изменились. Сможете объяснить, что здесь происходит? И главное – почему чтение v.x воз- вращает 10, если это значение не хранится в массиве компонент? Если сходу непо- компонент? Если сходу непо- ? Если сходу непо-\n--- Страница 317 ---\n317 Vector, попытка № 3: доступ к динамическим атрибутам нятно, прочитайте еще раз, как работает метод __getattr__ (перед примером 10.8). Это тонкий момент, но от него зависит многое из того, с чем мы встретимся далее в этой книге. Несогласованность в примере 10.9 возникла из-за способа работы __getattr__ : Python вызывает этот метод только в том случае, когда у объекта нет атрибута с указанным именем. Однако же после присваивания v.x = 10 у объекта v по- явился атрибут x, поэтому __getattr__ больше не вызывается для доступа к v.x: интерпретатор просто вернет значение 10, связанное с v.x. С другой стороны, в реализации __getattr__ мы игнорируем все атрибуты экземпляра, кроме self. _components , откуда читаются значения «виртуальных атрибутов», перечисленных в строке shortcut_names . Чтобы избежать рассогласования, мы должны изменить логику установки атрибутов в классе Vector . Напомним, что в последних вариантах класса Vector2d в главе 9 попытка присвоить значение атрибутам экземпляра .x или .y приводила к исключению AttributeError . В классе Vector мы хотим возбуждать такое же исключение при любой попытке присвоить значение атрибуту с однобуквенным именем – просто во избежание недоразумений. Для этого реализуем метод __setattr__ , как показа- но в примере 10.10. Пример 10.10. Часть файла vector_v3.py: метод __setattr__ в классе Vector def __setattr__(self, name, value): cls = type(self) if len(name) == 1: /g110 if name in cls.shortcut_names: /g111 error = 'readonly attribute {attr_name!r}' elif name.islower(): /g112 error = \"can't set attributes 'a' to 'z' in {cls_name!r}\" else: error = '' /g113 if error: /g114 msg = error.format(cls_name=cls.__name__, attr_name=name) raise AttributeError(msg) super().__setattr__(name, value) /g115 /g110 Специальная обработка односимвольных имен атрибутов. /g111 Если имя совпадает с одним из символов xyzt , задать один текст сообщения об ошибке. /g112 Если имя – строчная буква, задать другой текст сообщения – обо всех одно- буквенных именах. /g113 В противном случае оставить сообщение об ошибке пустым. /g114 Если сообщение об ошибке не пусто, возбуждаем исключение. /g115 Случай по умолчанию: вызвать метод __setattr__ суперкласса для полу- чения стандартного поведения.\n--- Страница 318 ---\n318 Глава 10. Рубим, перемешиваем и нарезаем последовательности Функция super() – быстрый способ обратиться к методам су- перкласса. Она необходима в динамических языках, поддержива-ющих множественное наследование, к числу которых относится и Python. Используется для делегирования некоторого действия в подклассе подходящему методу суперкласса. Мы еще вернемся к функции super в разделе «Множественное наследование и по- рядок разрешения методов» на стр. 384. Решая, какое сообщение об ошибке вернуть в исключении AttributeError , я прежде всего сверился с поведением встроенного типа complex , поскольку он не- изменяемый и имеет два атрибута: real и imag . Попытка изменить любой из них приводит к исключению AttributeError с сообщением «can't set attribute» . С другой стороны, попытка изменить доступный только для чтения атрибут, ко-торый защищен, как в разделе «Хэшируемый класс Vector2d » главы 9, кончает- ся сообщением «readonly attribute» . Выбирая значение строки error в методе __setattr__ , я руководствовался обоими образцами, но уточнил, какие именно атрибуты запрещены. Отметим, что мы не запрещаем установку всех вообще атрибутов, а только та- ких, имя которых состоит из одной строчной буквы, – чтобы избежать путаницы с доступными только для чтения атрибутами x, y, z и t. Мы знаем, что объявление атрибута __slots__ на уровне класса предотвращает создание новых атрибутов экземпляров, поэтому может возникнуть искушение воспользоваться этой возможно-стью и не реализовывать метод __setattr__ . Но из-за различных подводных камней, которые обсуждались в разделе «Проблемы при использовании __slots__» главы 9, не рекомендуется объяв-лять __slots__ только ради запрета создавать новые атрибуты экземпляра. Этот механизм предназначен исключительно для экономии памяти, да и то лишь в случае, когда с этим возникают проблемы. Но пусть мы и отказались от записи в компоненты Vector , все равно из этого примера можно вынести важный урок: часто вместе с методом __getattr__ при- ходится писать и метод __setattr__ , чтобы избежать несогласованного поведения объекта. Если бы мы решили допустить изменение компонент, то могли бы реа-лизовать метод __setitem__ , чтобы можно было писать v[0] = 1.1 , и (или) метод __setattr__ , чтобы работала конструкция v.x = 1.1 . Но сам класс Vector должен оставаться неизменяемым, потому что в следующем разделе мы собираемся сде-лать его хэшируемым.\n--- Страница 319 ---\n319 Vector, попытка № 4: хэширование и ускорение оператора == Vector, попытка № 4: хэширование и ускорение оператора == И снова нам предстоит реализовать метод __hash__ . В сочетании с уже имеющимся методом __eq__ это сделает экземпляры класса Vector хэшируемыми. Метод __hash__ в примере 9.8 просто вычислял выражение hash(self .x) ^ hash(self .y). Теперь мы хотели бы применить оператор ^ (ИСКЛЮЧАЮЩЕЕ ИЛИ) к хэшам всех компонент: v[0] ^ v[1] ^ v[2] … . Т ут нам на помощь придет функция functools .reduce . Выше я говорил, что функция reduce уже не так популярна, как в былые времена4, но для вычисления хэша всех компонент она подходит идеально. На рис. 10.1 представлена общая идея функции reduce . Рис. 10.1. Редуцирующие функции – reduce , sum, any, all – порождают единственное значение-агрегат из последовательности или произвольного конечного итерируемого объекта До сих пор мы видели, что функцию functools.reduce() можно заменить функ- цией sum() , а теперь объясним, как же она все-таки работает. Идея в том, чтобы редуцировать последовательность значений в единственное значение. Первый аргумент reduce() – функция с двумя аргументами, а второй – итерируемый объ- ект. Допустим, что имеется функция с двумя аргументами fn и список lst. Если написать reduce(fn, lst) , то fn сначала применяется к первым двум элементам – fn(lst[0], lst[1]) – и в результате получится первый результат r1. Затем fn при- меняется к r1 и следующему элементу – fn(r1, lst[2]) ; так мы получаем второй результат r2. Затем вызов fn(r2, lst[3]) порождает r3 … и так далее до последнего элемента, после чего возвращается окончательный результат rN. Вот как можно было бы применить reduce для вычисления 5! (факториал 5): >>> 2 * 3 * 4 * 5 # ожидаемый результат: 5! == 120120>>> import functools>>> functools.reduce(lambda a,b: a*b, range(1, 6))120 Но вернемся к проблеме хэширования. В примере 10.11 показано, как мож- но было бы вычислить результат многократного применения ^ тремя способами: один – с помощью цикла for и два – с помощью reduce . 4 Функции sum , any и all покрывают большинство типичных применений reduce . См. обсуждение в разделе «Современные замены map , filter и reduce » главы 5.\n--- Страница 320 ---\n320 Глава 10. Рубим, перемешиваем и нарезаем последовательности Пример 10.11. Три способа вычислить результат применения оператора ИСКЛЮЧАЮЩЕЕ ИЛИ к целым числам от 0 до 5 >>> n = 0 >>> for i in range(1, 6): # /g110 n ^= i >>> n1>>> import functools>>> functools.reduce(lambda a, b: a^b, range(6)) # /g111 1>>> import operator>>> functools.reduce(operator.xor, range(6)) # /g112 1 /g110 Агрегирование в цикле for в накопительную переменную. /g111 functools.reduce с анонимной функцией. /g112 functools.reduce с заменой специально написанного лямбда-выражения функцией operator.xor . Из представленных вариантов мне больше всего нравится последний, а на вто- ром месте стоит цикл for. А вам как кажется? На стр. 188 мы видели, что модуль operator предоставляет функциональность всех инфиксных операторов Python в форме функций, снижая потребность в лямбда-выражениях. Чтобы написать метод Vector.__hash__ в том стиле, который я предпочитаю, необходимо импортировать модули functools и operator . Изменения показаны в примере 10.12. Пример 10.12. Часть файла vector_v4.py: в класс Vector из файла vector_v3.py добавлены два предложения импорта и метод __hash__ from array import array import reprlib import mathimport functools # /g110 import operator # /g111 class Vector: typecode = 'd' # много строк опущено… def __eq__(self, other): # /g112 return tuple(self) == tuple(other) def __hash__(self): hashes = (hash(x) for x in self._components) # /g113\n--- Страница 321 ---\n321 Vector, попытка № 4: хэширование и ускорение оператора == return functools.reduce(operator.xor, hashes, 0) # /g114 # последующие строки опущены /g110 Импортируем functools для использования reduce . /g111 Импортируем operator для использования xor. /g112 Метод __eq__ не изменился; я привел его, только потому что методы __eq__ и __hash__ принято располагать в исходном коде рядом, т. к. они дополняют друг друга. /g113 Создаем генераторное выражение для отложенного вычисления хэша каж- дой компоненты. /g114 Подаем выражение hashes на вход reduce вместе с функцией xor – для вы- числения итогового хэш-значения; третий аргумент, равный 0, – инициали-затор (см. предупреждение ниже). При использовании reduce рекомендуется задавать третий ар- гумент , reduce(function, iterable, initializer) , чтобы пре- дотвратить появление исключения TypeError: reduce() of empty sequence with no initial value (отличное сообщение: описы- вается проблема и способ исправления). Значение initializer возвращается, если последовательность пуста, а, кроме того, используется в качестве первого аргумента в цикле редукции, поэтому оно должно быть нейтральным элементом относитель-но выполняемой операции. Так, для операций +, |, ^ initializer должен быть равен 0, а для *, & – 1. Метод __hash__ в примере 10.8 – отличный пример техники mapreduce (рис. 10.2). Рис. 10.2. Map-reduce: применить функцию к каждому элементу для генерации новой последовательности (map), затем вычислить агрегат (reduce)\n--- Страница 322 ---\n322 Глава 10. Рубим, перемешиваем и нарезаем последовательности На шаге отображения (map) порождается один хэш для каждого компонента, а на шаге редукции (reduce) все хэши агрегируются с помощью оператора xor. Если использовать функцию map вместо генераторного выражения, то шаг отображения станет даже более наглядным: def __hash__(self): hashes = map(hash, self._components) return functools.reduce(operator.xor, hashes) Решение на основе map не так эффективно в Python 2, где функ- ция map строит список, содержащий результаты. Однако в Python 3 map откладывает вычисления: она порождает генератор, который отдает результаты по требованию, экономя тем самым память, – точно так же, как генераторное выражение в методе __hash__ из примера 10.8. Раз уж мы заговорили о редуцирующих функциях, то почему бы не заменить нашу написанную на скорую руку реализацию оператора __eq__ другой, которая и работать будет быстрее, и памяти потреблять меньше, по крайней мере, для боль-ших векторов. В примере 9.2 приведена такая лаконичная реализация __eq__ : def __eq__(self, other): return tuple(self) == tuple(other) Она работает для Vector2d и для Vector – и даже считает, что Vector([1, 2]) равен (1, 2) ; это может оказаться проблемой, но пока закроем на нее глаза5. Но для векторов с тысячами компонент эта реализация крайне неэффективна. Она строит два кортежа, полностью копируя оба операнда, только для того, чтобы воспользо-ваться оператором __eq__ из типа tuple . Такая экономия усилий вполне оправдана для класса Vector2d (всего с двумя компонентами), но не для многомерных век- компонентами), но не для многомерных век- ами), но не для многомерных век- торов. Более эффективный способ сравнения объекта Vector с другим объектом Vector или с итерируемым объектом показан в примере 10.13. Пример 10.13. Метод Vector.eq , в котором используется функция zip в цикле for для более эффективного сравнения def __eq__(self, other): if len(self) != len(other): # /g110 return False for a, b in zip(self, other): # /g111 if a != b: # /g112 return False return True # /g113 /g110 Если длины объектов различны, то они не равны. 5 К вопросу о разумности равенства Vector([1, 2]) == (1, 2) мы серьезно подойдем в разделе «Основы перегрузки операторов» главы 13.\n--- Страница 323 ---\n323 Vector, попытка № 4: хэширование и ускорение оператора == /g111 Функция zip порождает генератор кортежей, содержащих соответствен- ные элементы каждого переданного ей итерируемого объекта. Если вы с ней незнакомы, см. врезку «У дивительная функция zip» ниже. Сравнение длин в предыдущем предложении необходимо, потому что zip без пред- упреждения перестает порождать значения, как только хотя бы один вход-ной аргумент оказывается исчерпанным. /g112 Как только встречаются две различных компоненты, выходим и возвраща- компоненты, выходим и возвраща- ы, выходим и возвраща- ем False . /g113 В противном случае объекты равны. Код из примера 10.13 эффективен, но функция all может вычислить тот же агрегат, что и цикл for, всего в одной строчке: если все сравнения соответственных компонент операндов возвращают True , то и результат равен True . Как только какое-нибудь сравнение возвращает False , так all сразу возвращает False . В примере 10.14 показано, как выглядит метод __eq__ , в котором используется all. Пример 10.14. Оператор Vector.eq с использованием zip и all : логика та же, что в примере 10.13 def __eq__(self, other): return len(self) == len(other) and all(a == b for a, b in zip(self, other)) Отметим, что сначала проверяется равенство длин операндов, потому что zip остановится по исчерпании более короткого операнда. Реализацию из примера 10.14 мы включили в файл vector_v4.py . И в завершение этой главы перенесем метод __format__ из класса Vector2d в класс Vector . Удивительная функция zip Наличие цикла for, в котором можно обойти элементы коллекции без возни с индексной переменной, – отличное дело, и многие ошибки так можно предотвратить, только для этого нужны специальные слу-жебные функции. Одна из них – встроенная функция zip, позволяющая параллельно обходить два и более итерируемых объекта: она возвраща-ет кортежи, которые можно распаковать в переменные, – по одной для каждого входного объекта. См. пример 10.15. Свое название функция zip получила от застежки-мол- нии (zipper), принцип работы которой основан на сцепле-нии зубьев, расположенных с двух сторон, – наглядная аналогия того, что происходит при обращении zip(left, right) . Никакого отношения к сжатым файлам эта функ- ция не имеет .\n--- Страница 324 ---\n324 Глава 10. Рубим, перемешиваем и нарезаем последовательности Пример 10.15. Встроенная функция zip за работой >>> zip(range(3), 'ABC') # /g110 <zip object at 0x10063ae48>>>> list(zip(range(3), 'ABC')) # /g111 [(0, 'A'), (1, 'B'), (2, 'C')]>>> list(zip(range(3), 'ABC', [0.0, 1.1, 2.2, 3.3])) # /g112 [(0, 'A', 0.0), (1, 'B', 1.1), (2, 'C', 2.2)]>>> from itertools import zip_longest # /g113 >>> list(zip_longest(range(3), 'ABC', [0.0, 1.1, 2.2, 3.3], fillvalue=-1)) [(0, 'A', 0.0), (1, 'B', 1.1), (2, 'C', 2.2), (-1, -1, 3.3)] /g110 zip возвращает генератор, который порождает кортежи по за- просу. /g111 Здесь мы строим из генератора список list просто для отобра- жения; обычно генератор обходят в цикле. /g112 У zip есть удивительное свойство: она останавливается, не выда- вая предупреждения, как только один из итерируемых объектов оказывается исчерпанным 6. /g113 Функция itertools.zip_longest ведет себя иначе: она подстав- ляет вместо отсутствующих значений необязательный аргумент fillvalue (по умолчанию None ), поэтому генерирует кортежи, пока не окажется исчерпанным самый длинный итерируемый объект. Встроенная функция enumerate – еще одна генераторная функция, которую часто используют в циклах for, чтобы избежать явной работы с индексными переменными. Если вы незнакомы с enumerate , обязательно прочитайте раздел документации «Встроенные функции» ( http://bit. ly/1QOtsk8 ). Функции zip, enumerate и другие генераторные функции из стандартной библиотеки, рассматриваются в разделе «Генераторные функции в стандартной библиотеке» главы 14. Vector, попытка № 5: форматирование Метод __format__ класса Vector будет похож на одноименный метод из класса Vector2d , но вместо специального представления в полярных координатах, мы будем использовать так называемые «гиперсферические» координаты (назва-ние связано с тем, что в пространствах размерности 4 и выше сферы называются 6 Для меня это странно. Мне кажется, что zip должна возбуждать исключение ValueError , если ей переданы последовательности разной длины. Ведь именно это происходит при распаковке итери-руемого объекта в кортеж переменных, имеющий другую длину .\n--- Страница 325 ---\n325 Vector, попытка № 5: форматирование гиперсферами)7. Соответственно специальный суффикс форматной строки 'p' мы заменим на 'h'. В разделе «Форматированное отображение» главы 9 мы ви- дели, что при расширении миниязыка спецификации формата (https://docs.python.org/3/library/string.html#formatspec ) лучше не использовать форматные коды, предназначенные для встро-енных типов. В частности, в нашем расширенном миниязыке коды 'eEfFgGn%' используются в своем изначальном смысле, поэтому их-то точно нельзя переопределять. Для форматирования целых чисел служат коды 'bcdoxXn' , а для строк – код 's'. Для вывода объекта Vector2d в полярных координатах я выбрал код 'p', а для гиперсферических координат возьму код 'h'. Например, для объекта Vector в четырехмерном пространстве (len(v) == 4 ) код 'h' порождает представление вида <r, /g301/g20, /g301/g21, /g301/g22>, где r – модуль вектора (abs(v) ), а /g301/g20, /g301/g21, /g301/g22 – угловые координаты. Ниже приведены примеры вывода 4-мерного вектора в сферических координатах, взятые из doctest-скриптов в файле vector_v5.py (см. пример 10.16): >>> format(Vector([-1, -1, -1, -1]), 'h') '<2.0, 2.0943951023931957, 2.186276035465284, 3.9269908169872414>'>>> format(Vector([2, 2, 2, 2]), '.3eh')'<4.000e+00, 1.047e+00, 9.553e-01, 7.854e-01>'>>> format(Vector([0, 1, 0, 0]), '0.5fh')'<1.00000, 1.57080, 0.00000, 0.00000>' Прежде чем вносить мелкие изменения в метод __format__ , мы должны написать два вспомогательных метода: angle(n) будет вычислять одну из угловых координат (например, Φ1), а angles() – возвращать итерируемый объект, содержащий все угловые координаты. Не стану останавливаться здесь на математической теории, интересующиеся читатели могут найти формулы преобразования из декартовых координат в сферические в статье из википедии ( http://en.wikipedia.org/wiki/ N-sphere ). В примере 10.16 приведен полный код из файла vector_v5.py , в который вошло все, что мы сделали, начиная с раздела «V ector, попытка № 1: совместимость с V ector2d», включая форматирование. Пример 10.16. vector_v5.py: doctest-скрипты и окончательный код класса Vector ; выноски описывают добавления, необходимые для поддержки метода __format__ \"\"\" Многомерный класс ``Vector``, попытка 5 7 На сайте W olfram Mathworld имеется статья о гиперсферах ( http://mathworld.wolfram.com/ Hypersphere.html ); в википедии запрос по слову «hypersphere» переадресуется на статью « n-sphere» (http://en.wikipedia.org/wiki/Nsphere ).\n--- Страница 326 ---\n326 Глава 10. Рубим, перемешиваем и нарезаем последовательности A ``Vector`` is built from an iterable of numbers:: >>> Vector([3.1, 4.2]) Vector([3.1, 4.2]) >>> Vector((3, 4, 5)) Vector([3.0, 4.0, 5.0]) >>> Vector(range(10)) Vector([0.0, 1.0, 2.0, 3.0, 4.0, ]) Tests with two dimensions (same results as ``vector2d_v1.py``):: >>> v1 = Vector([3, 4]) >>> x, y = v1 >>> x, y (3.0, 4.0) >>> v1 Vector([3.0, 4.0]) >>> v1_clone = eval(repr(v1)) >>> v1 == v1_clone True >>> print(v1) (3.0, 4.0) >>> octets = bytes(v1) >>> octets b'd\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x08@\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x10@' >>> abs(v1) 5.0 >>> bool(v1), bool(Vector([0, 0])) (True, False) Test of ``.frombytes()`` class method: >>> v1_clone = Vector.frombytes(bytes(v1)) >>> v1_clone Vector([3.0, 4.0]) >>> v1 == v1_clone True Tests with three dimensions:: >>> v1 = Vector([3, 4, 5]) >>> x, y, z = v1 >>> x, y, z (3.0, 4.0, 5.0) >>> v1 Vector([3.0, 4.0, 5.0]) >>> v1_clone = eval(repr(v1)) >>> v1 == v1_clone True >>> print(v1) (3.0, 4.0, 5.0) >>> abs(v1) # doctest:+ELLIPSIS 7.071067811\n--- Страница 327 ---\n327 Vector, попытка № 5: форматирование >>> bool(v1), bool(Vector([0, 0, 0])) (True, False) Tests with many dimensions:: >>> v7 = Vector(range(7)) >>> v7 Vector([0.0, 1.0, 2.0, 3.0, 4.0, ]) >>> abs(v7) # doctest:+ELLIPSIS 9.53939201 Test of ``.__bytes__`` and ``.frombytes()`` methods:: >>> v1 = Vector([3, 4, 5]) >>> v1_clone = Vector.frombytes(bytes(v1)) >>> v1_clone Vector([3.0, 4.0, 5.0]) >>> v1 == v1_clone True Tests of sequence behavior:: >>> v1 = Vector([3, 4, 5]) >>> len(v1) 3 >>> v1[0], v1[len(v1)-1], v1[-1] (3.0, 5.0, 5.0) Test of slicing:: >>> v7 = Vector(range(7)) >>> v7[-1] 6.0 >>> v7[1:4] Vector([1.0, 2.0, 3.0]) >>> v7[-1:] Vector([6.0]) >>> v7[1,2] Traceback (most recent call last): TypeError: Vector indices must be integers Tests of dynamic attribute access:: >>> v7 = Vector(range(10)) >>> v7.x 0.0 >>> v7.y, v7.z, v7.t (1.0, 2.0, 3.0) Dynamic attribute lookup failures::\n--- Страница 328 ---\n328 Глава 10. Рубим, перемешиваем и нарезаем последовательности >>> v7.k Traceback (most recent call last): AttributeError: 'Vector' object has no attribute 'k' >>> v3 = Vector(range(3)) >>> v3.t Traceback (most recent call last): AttributeError: 'Vector' object has no attribute 't' >>> v3.spam Traceback (most recent call last): AttributeError: 'Vector' object has no attribute 'spam' Tests of hashing:: >>> v1 = Vector([3, 4]) >>> v2 = Vector([3.1, 4.2]) >>> v3 = Vector([3, 4, 5]) >>> v6 = Vector(range(6)) >>> hash(v1), hash(v3), hash(v6) (7, 2, 1) Most hash values of non-integers vary from a 32-bit to 64-bit CPython build:: >>> import sys >>> hash(v2) == (384307168202284039 if sys.maxsize > 2**32 else 357915986) True Tests of ``format()`` with Cartesian coordinates in 2D:: >>> v1 = Vector([3, 4]) >>> format(v1) '(3.0, 4.0)' >>> format(v1, '.2f') '(3.00, 4.00)' >>> format(v1, '.3e') '(3.000e+00, 4.000e+00)' Tests of ``format()`` with Cartesian coordinates in 3D and 7D:: >>> v3 = Vector([3, 4, 5]) >>> format(v3) '(3.0, 4.0, 5.0)' >>> format(Vector(range(7))) '(0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0)' Tests of ``format()`` with spherical coordinates in 2D, 3D and 4D:: >>> format(Vector([1, 1]), 'h') # doctest:+ELLIPSIS '<1.414213 , 0.785398 >' >>> format(Vector([1, 1]), '.3eh') '<1.414e+00, 7.854e-01>' >>> format(Vector([1, 1]), '0.5fh') '<1.41421, 0.78540>'\n--- Страница 329 ---\n329 Vector, попытка № 5: форматирование >>> format(Vector([1, 1, 1]), 'h') # doctest:+ELLIPSIS '<1.73205 , 0.95531 , 0.78539 >' >>> format(Vector([2, 2, 2]), '.3eh') '<3.464e+00, 9.553e-01, 7.854e-01>' >>> format(Vector([0, 0, 0]), '0.5fh') '<0.00000, 0.00000, 0.00000>' >>> format(Vector([-1, -1, -1, -1]), 'h') # doctest:+ELLIPSIS '<2.0, 2.09439 , 2.18627 , 3.92699 >' >>> format(Vector([2, 2, 2, 2]), '.3eh') '<4.000e+00, 1.047e+00, 9.553e-01, 7.854e-01>' >>> format(Vector([0, 1, 0, 0]), '0.5fh') '<1.00000, 1.57080, 0.00000, 0.00000>'\"\"\" from array import array import reprlibimport mathimport numbersimport functoolsimport operator import itertools /g110 class Vector: typecode = 'd' def __init__(self, components): self._components = array(self.typecode, components) def __iter__(self): return iter(self._components) def __repr__(self): components = reprlib.repr(self._components) components = components[components.find('['):-1] return 'Vector({})'.format(components) def __str__(self): return str(tuple(self)) def __bytes__(self): return (bytes([ord(self.typecode)]) + bytes(self._components)) def __eq__(self, other): return (len(self) == len(other) and all(a == b for a, b in zip(self, other))) def __hash__(self): hashes = (hash(x) for x in self) return functools.reduce(operator.xor, hashes, 0) def __abs__(self): return math.sqrt(sum(x * x for x in self)) def __bool__(self):\n--- Страница 330 ---\n330 Глава 10. Рубим, перемешиваем и нарезаем последовательности return bool(abs(self)) def __len__(self): return len(self._components) def __getitem__(self, index): cls = type(self) if isinstance(index, slice): return cls(self._components[index]) elif isinstance(index, numbers.Integral): return self._components[index] else: msg = '{.__name__} indices must be integers' raise TypeError(msg.format(cls)) shortcut_names = 'xyzt' def __getattr__(self, name): cls = type(self) if len(name) == 1: pos = cls.shortcut_names.find(name) if 0 <= pos < len(self._components): return self._components[pos] msg = '{.__name__!r} object has no attribute {!r}' raise AttributeError(msg.format(cls, name)) def angle(self, n): /g111 r = math.sqrt(sum(x * x for x in self[n:])) a = math.atan2(r, self[n-1]) if (n == len(self) - 1) and (self[-1] < 0): return math.pi * 2 - a else: return a def angles(self): /g112 return (self.angle(n) for n in range(1, len(self))) def __format__(self, fmt_spec=''): if fmt_spec.endswith('h'): # hyperspherical coordinates fmt_spec = fmt_spec[:-1] coords = itertools.chain([abs(self)], self.angles()) /g113 outer_fmt = '<{}>' /g114 else: coords = self outer_fmt = '({})' /g115 components = (format(c, fmt_spec) for c in coords) /g116 return outer_fmt.format(', '.join(components)) /g117 @classmethod def frombytes(cls, octets): typecode = chr(octets[0]) memv = memoryview(octets[1:]).cast(typecode) return cls(memv)\n--- Страница 331 ---\n331 Резюме /g110 Импортируем itertools , чтобы можно было воспользоваться функцией chain в методе __format__ . /g111 Вычисляем одну из угловых координат по формулам, взятым из статьи по адресу http://en.wikipedia.org/wiki/N-sphere . /g112 Создаем генераторное выражение для вычисления всех угловых координат по запросу. /g113 Используем itertools.chain для порождения генераторного выражения, которое перебирает модуль и угловые координаты вектора. /g114 Конфигурируем отображение сферических координат в угловых скобках. /g115 Конфигурируем отображение декартовых координат в круглых скобках. /g116 Создаем генераторное выражение для форматирования координат по за- просу. /g117 Подставляем отформатированные компоненты, разделенные запятыми, в угловые или круглые скобки. Мы вовсю пользуемся генераторными выражениями в методах __format__ , angle и angles , но наша цель здесь – просто написать метод __format__ , чтобы класс Vector не уступал в полноте реа- лизации классу Vector2d . При рассмотрении генераторов в главе 14 мы воспользуемся в качестве примера кодом из класса Vector , и тогда все хитрости будут подробно объяснены. Итак, все задачи, которые мы ставили перед собой в этой главе, решены. В гла- ве 13 мы пополним класс Vector инфиксными операторами, но пока хотели лишь изучить, как писать специальные методы, полезные в различных классах коллек-ций. Резюме Класс Vector из этой главы был задуман совместимым с классом Vector2d во всем, кроме использования другой сигнатуры конструктора, – теперь он принимает один итерируемый объект, как конструкторы встроенных типов последователь-ностей. Чтобы класс Vector вел себя так же, как последовательность, оказалось достаточно реализовать методы __getitem__ и __len__ , и этот факт подвиг нас на обсуждение протоколов – неформальных интерфейсов в языках с динамической типизацией. Далее мы разобрались, как на самом деле работает конструкция my_seq[a:b:c] , для чего создали объект slice(a, b, c) и передали его методу __getitem__ . Во- оружившись этими знаниями, мы переделали класс Vector , так чтобы операция получения среза выполнялась для него корректно, т. е. возвращала экземпляр типа Vector , как и положено последовательности в Python. Нашим следующим шагом было обеспечение доступа для чтения к несколь- ким первым компонентам объекта Vector по именам, т. е. с помощью нотации\n--- Страница 332 ---\n332 Глава 10. Рубим, перемешиваем и нарезаем последовательности my_vec.x . Для этого мы реализовали метод __getattr__ . При этом у пользователя могло возникнуть искушение присвоить значение таким компонентам, написав my_vec.x = 7 , однако это приводило к ошибке. Мы исправили ошибку, реали- зовав еще и метод __setattr__ , запрещающий присваивать значения атрибу- там с однобуквенными именами. Очень часто бывает, что методы __getattr__ и __setattr__ необходимо реализовывать совместно во избежание несогласован- ного поведения. Реализация метода __hash__ предоставила нам отличную возможность вос- пользоваться функцией functools.reduce , поскольку необходимо было применить оператор ^ к хэшам всех компонент Vector , чтобы создать агрегированное хэш- значение объекта Vector в целом. Применив функцию reduce в методе __hash__ , мы затем воспользовались встроенной функцией all для создания более эффек- тивной версии метода __eq__ . И последним усовершенствованием класса Vector стала новая реализация ме- тода __format__ из класса Vector2d , поддерживающая гиперсферические координа- ты в дополнение к декартовым. Т ут нам понадобились кое-какие математические формулы и несколько генераторов, но все это детали реализации (к генераторам мы еще вернемся в главе 14). В последнем разделе нашей целью было поддержать специальный формат и тем самым выполнить данное ранее обещание, что класс Vector сможет делать все, что умел Vector2d , и кое-что сверх того. Как и в главе 9, мы часто оглядывались на поведение стандартных объек- тов Python, стремясь имитировать его, чтобы класс Vector соответствовал духу Python. В главе 13 мы реализуем в классе Vector несколько инфиксных операторов. Математика будет куда проще, чем в методе angle() , зато изучение работы ин- фиксных операторов в Python станет отличным уроком по объектно-ориентиро-ванному проектированию. Однако прежде чем заняться перегрузкой операторов, мы на время отвлечемся от разработки отдельного класса и посмотрим, как мож-но организовать несколько классов с помощью интерфейсов и наследования. Это темы глав 11 и 12. Дополнительная литература Большинство специальных методов, рассмотренных при разработке класса Vector , встречаются и в классе Vector2d из главы 9, поэтому актуальны все библиографи- ческие ссылки, приведенные в предыдущей главе. Мощную функцию высшего порядка reduce называют также fold, accumulate, aggregate, compress и inject. Дополнительные сведения можно найти в статье из ви-кипедии «Fold (higher-order function)» ( http://en.wikipedia.org/wiki/Fold_(higher- order_function) ), где описаны применения этой функции с упором на функцио- нальное программирование с рекурсивными структурами данных. В этой статье имеется также таблица, в которой перечислены похожие функции в десятках язы-ков программирования.\n--- Страница 333 ---\n333 Поговорим Поговорим Протоколы как неформальные интерфейсы Протоколы – не изобретение Python. Авторы языка Smalltalk, пу- стившие в оборот также выражение «объектно-ориентированный», ис-пользовали слово «протокол» как синоним того, что сейчас называет-ся интерфейсом. В некоторых средах программирования на Smalltalk программистам разрешалось помечать группу методов как протокол, но только в целях документирования и навигации – сам язык эту кон-цепцию не поддерживал. Поэтому я полагаю, что «неформальный интерфейс» – разумное краткое объяснение существа «протокола» в выступлении перед аудиторией, больше знакомой с формальными (и поддержанными компилятором) интерфейсами. Протоколы естественно возникают в любом языке с динамической типизацией, когда контроль типов производится во время выполнения, потому что в объявлениях переменных и сигнатур методов нет никакой статической информации о типе. Ruby – еще один важный объектно-ориентированный язык, в котором имеется динамическая типизация и используются протоколы. В документации по Python протокол можно узнать по выражениям типа «объект, похожий на файл». Это сокращение фразы «нечто, что ве-дет себя в достаточной степени похоже на файл благодаря реализации тех частей интерфейса файла, которые существенны в данном контексте». Кто-то решит, что реализация лишь части протокола – признак не- брежного программирования, но у такого подхода есть преимущество – простота. В разделе 3.3 главы «Модель данных» ( http://bit.ly/pydocs- smn) читаем такую рекомендацию: При реализации класса, имитирующего встроенный тип, важно не заходить слишком далеко, а ограничиться лишь тем, что имеет смысл для моделируемого объекта. Например, для некоторых по-следовательностей вполне достаточно извлечения отдельных эле-ментов, тогда как получение среза бессмысленно. – Глава «Модель данных» справочного руководства по языку Python Если мы можем обойтись без кодирования ненужных методов только для того, чтобы удовлетворить требованиям какого-то перена-сыщенного функциональностью контракта, а компилятор при этом не будет ругаться, то становится проще следовать принципу KISS 8 (http:// en.wikipedia.org/wiki/KISS_principle ). Мы еще вернемся к протоколам и интерфейсам в главе 11, которая, в основном, этой теме и посвящена. 8 Кeep it simple, stupid – Будь проще, глупышка. – Прим. перев.\n--- Страница 334 ---\n334 Глава 10. Рубим, перемешиваем и нарезаем последовательности Истоки «утиной» типизации Я полагаю, что популяризации термина «duck typing» (утиная типи- зация) больше других способствовало сообщество Ruby, обращавшееся с проповедью к поклонникам Java. Но это выражение встречалось в об-суждениях Python еще до того, как Ruby и Python стали «популярны-ми». Согласно википедии, один из первых примеров аналогии с уткой в объектно-ориентированном программировании – сообщение в списке рассылки Python, отправленное Алексом Мартелли 26 июля 2000 года и касавшееся полиморфизма (с заголовком Re: Type checking in python?) (http://bit.ly/1QOuTPx ). Именно из него взята цитата, ставшая эпигра- фом к данной главе. Если вам любопытны литературные корни термина «утиная типизация», а также применения этой объектно-ориентирован-ной концепции во многих языках, почитайте статью википедии «Duck typing» ( http://en.wikipedia.org/wiki/Duck_typing ). Безопасный format повышенного удобства При реализации метода __format__ мы не принимали никаких мер предосторожности на случай экземпляров Vector с очень большим числом компонент, хотя в методе __repr__ применили для этой цели библиотеку reprlib . Обоснованием служит тот факт, что функция repr() предназначена для отладки и протоколирования, поэтому любой ценой должна вывести хоть какое-то полезное представление, тогда как __format__ предназначен для конечного пользователя, который, вероят- но, хочет видеть вектор целиком. Если вы полагаете, что это опасно, то можете продолжить расширение миниязыка спецификации формата. Я бы сделал это так: по умолчанию для любого форматированного век- тора выводится разумное, хотя и ограниченное количество компонент, скажем 30. Если элементов больше, то поведение по умолчанию может быть аналогично тому, что делает reprlib : отбросить дополнительные компоненты, заменив их многоточием. Но если спецификатор форма- ы, заменив их многоточием. Но если спецификатор форма- та заканчивается специальным кодом *, означающим «все», то ограни- чения на размер не действуют. Таким образом, пользователь, который не знает о проблеме очень длинного представления, не станет жертвой случайности. Однако если ограничение начинает мешать, то наличие должно натолкнуть пользователя на мысль поискать в документации, где он узнает о коде форматирования *. Если реализуете эту идею, отправьте запрос на включение своего кода в репозиторий книги «Fluent Python» на GitHub ( https://github. com/fluentpython/example-code )! Как вычислить сумму в духе Python Не существует однозначного ответа на вопрос «Что соответствует духу Python?», как и ответа на вопрос «Что такое красота?». Я часто\n--- Страница 335 ---\n335 Поговорим говорю, что это означает «идиоматичный Python», однако такой ответ не вполне годится, потому что слово «идиоматичный» для меня и для вас может означать разные вещи. Но одно я знаю точно: «идиоматич-ность» не означает, что нужно использовать средства языка, спрятан-ные в самых потаенных закоулках. В списке рассылки Python ( https:// mail.python.org/mailman/listinfo/python-list ) есть ветка, датированная апрелем 2003, под названием «Pythonic Way to Sum n-th List Element?» (http://bit.ly/1QOv5y5 ). Она примыкает к обсуждению функции reduce в этой главе. Начавший ее Гай Миддлтон (Guy Middleton) просил улучшить следу- ющее решение, оговорившись, что ему не нравятся лямбда-выражения9: >>> my_list = [[1, 2, 3], [40, 50, 60], [9, 8, 7]]>>> import functools>>> functools.reduce(lambda a, b: a+b, [sub[1] for sub in my_list])60 В этом коде идиом хватает: lambda , reduce и списковое включение. Наверное, он занял бы последнее место на конкурсе популярности, по-тому что равно оскорбляет чувства тех, кто ненавидит lambda , и тех, кто презирает списковое включение, – а это чуть ли не вся публика. Если вы собираетесь использовать lambda , то, пожалуй, нет причин прибегать к списковому включению, разве что для фильтрации, но здесь у нас не тот случай. Вот мое решение, которое должно понравиться любителям lambda : >>> functools.reduce(lambda a, b: a + b[1], my_list, 0) 60 Я не участвовал в этой ветке и не стал бы использовать этот код в реальной программе, потому что сам не большой поклонник lambda , но хотел показать, как можно решить эту задачу без спискового включения. Первым ответил Фернандо Перес (Fernando Perez), создатель IPython, который привлек внимание к тому, что NumPy поддерживает n-мерные массивы и n-мерные срезы: >>> import numpy as np >>> my_array = np.array(my_list) >>> np .sum(my_array[:, 1]) 60 Мне кажется, что решение Переса очень изящное, но Гай Миддлтон выбрал другое, принадлежащее Полу Рубину (Paul Rubin) и Скипу Монтанаро (Skip Montanaro): 9 Я немного изменил код для включения в книгу: в 2003 году функция reduce была встроенной, но в Python 3 ее нужно импортировать. Кроме того, я заменил имена x и y на my_list и sub (от sub-list).\n--- Страница 336 ---\n336 Глава 10. Рубим, перемешиваем и нарезаем последовательности >>> import operator >>> functools.reduce(operator.add, [sub[1] for sub in my_list], 0)60 Затем Эван Симпсон (Evan Simpson) спросил: «А это чем плохо?»: >>> t = 0>>> for sub in my_list: total += sub[1]>>> t60 Многие согласились, что это решение вполне в духе Python. Алекс Мартелли даже осмелился предположить, что так написал бы сам Гвидо. Мне нравится код Эвана Симпсона, впрочем, как и комментарий к нему Дэвида Эпштейна (David Eppstein): Если вы хотите просуммировать список элементов, то следует так и писать: «сумма списка элементов», а не «перебрать все эле-менты, завести еще одну переменную t и выполнить последователь-ность сложений». Зачем вообще нужны языки высокого уровня, если не для того, чтобы мы могли выразить свои намерения на вы-соком уровне – и пусть язык сам позаботится о том, какие низкоу-ровневые операции нужны для их реализации? Затем вновь возник Алекс Мартелли с таким предложением: «Сумма» нужна так часто, что я не возражал бы, если в Python появилась такая встроенная функция. Но, на мой взгляд, «reduce(operator.add, …» – на самый лучший способ выразить эту идею (вообще-то, имея большой опыт работы с APL и будучи по-клонником функционального программирования, я должен был бы заценить этот код – но вот не нравится и все тут). Алекс далее предлагает функцию sum() , которую сам же и написал. Она стала встроенной в версии Python 2.вышедшей спустя всего три ме-сяца после этой беседы. И вот так синтаксис, который предпочел Алекс, стал нормой: >>> sum([sub[1] for sub in my_list]) 60 В конце следующего года (ноябрь 2004) в версии Python 2.4 появи- лись генераторные выражения, которые, на мой взгляд, дали самый «пи-тонический» ответ на вопрос Гая Миддлтона: >>> sum(sub[1] for sub in my_list) 60\n--- Страница 337 ---\n337 Поговорим Этот код не только понятнее версии с reduce , но и позволяет избе- жать проблем, когда последовательность пуста: sum([]) равно 0 – вот так всё просто. В той же беседе Алекс Мартелли высказал мысль, что встроенная функция reduce в Python 2 приносит больше хлопот, чем преимуществ, потому что поощряет применение идиом, которые трудно объяснить. Он был очень убедителен: в результате в Python 3 эта функция пере-кочевала в модуль functools . И, тем не менее, у функции functools.reduce есть свое место под солнцем. Она позволила написать метод Vector.__hash__ способом, ко- торый лично я читаю вполне в духе Python.",
      "debug": {
        "start_page": 305,
        "end_page": 337
      }
    },
    {
      "name": "Глава 11. Интерфейсы: от протоколов до абстрактных базовых классов 338",
      "content": "--- Страница 338 --- (продолжение)\nГЛАВА 11. Интерфейсы: от протоколов до абстрактных базовых классов Абстрактный класс предоставляет интерфейс1. – Бьярн Страуструп, создатель C++ Тема этой главы – интерфейсы: от протоколов – отличительной черты динамиче-ской типизации – до абстрактных базовых классов (ABC), делающих интерфейсы явными и допускающими проверку согласованности. Для тех, кто имеет опыт работы с Java, C# или аналогичным языком, новостью станут неформальные протоколы динамической типизации. Ну а старички-пито-нисты или рубисты только так и представляют себе интерфейсы, а новостью для них будет формализм и контроль типов, обеспечиваемый ABC. Языку уже испол-нилось 15 лет, когда ABC впервые появились в версии Python 2.6. В начале этой главы мы расскажем о том, как сообщество Python традиционно воспринимало интерфейсы: как нечто не слишком строгое в том смысле, что зача-стую допускается реализовать интерфейс лишь частично. Мы поясним это на двух примерах, демонстрирующих динамическую природу утиной типизации. Затем последует вставное эссе Алекса Мартелли, где вводятся ABC и дается название новой тенденции в программировании на Python. Оставшаяся часть гла-вы будет посвящена ABC, начиная с их общепринятого использования в качестве суперклассов в тех случаях, когда нужно реализовать интерфейс. Далее мы уви-дим, когда проверяется согласованность конкретного класса с интерфейсом, опре-деляемым ABC, и как механизм регистрации позволяет разработчикам объявлять класс, который реализует интерфейс, не создавая подклассов. Наконец, мы пока-жем, как можно запрограммировать ABC, чтобы он автоматически «распознавал» любые классы, согласованные с его интерфейсом, – без создания подклассов и без явной регистрации. Мы реализуем новый ABC, чтобы посмотреть, как он работает, но Алекс Мар- телли и я не советуем бросаться писать ABC по поводу и без повода. ABC несут с собой опасность переусложнения. 1 Бьярн Страуструп «Дизайн и эволюция C++». ДМК Пресс, 2014, стр. 284.\nГЛАВА 11. Интерфейсы: от протоколов до абстрактных базовых классов Абстрактный класс предоставляет интерфейс1. – Бьярн Страуструп, создатель C++ Тема этой главы – интерфейсы: от протоколов – отличительной черты динамиче-ской типизации – до абстрактных базовых классов (ABC), делающих интерфейсы явными и допускающими проверку согласованности. Для тех, кто имеет опыт работы с Java, C# или аналогичным языком, новостью станут неформальные протоколы динамической типизации. Ну а старички-пито-нисты или рубисты только так и представляют себе интерфейсы, а новостью для них будет формализм и контроль типов, обеспечиваемый ABC. Языку уже испол-нилось 15 лет, когда ABC впервые появились в версии Python 2.6. В начале этой главы мы расскажем о том, как сообщество Python традиционно воспринимало интерфейсы: как нечто не слишком строгое в том смысле, что зача-стую допускается реализовать интерфейс лишь частично. Мы поясним это на двух примерах, демонстрирующих динамическую природу утиной типизации. Затем последует вставное эссе Алекса Мартелли, где вводятся ABC и дается название новой тенденции в программировании на Python. Оставшаяся часть гла-вы будет посвящена ABC, начиная с их общепринятого использования в качестве суперклассов в тех случаях, когда нужно реализовать интерфейс. Далее мы уви-дим, когда проверяется согласованность конкретного класса с интерфейсом, опре-деляемым ABC, и как механизм регистрации позволяет разработчикам объявлять класс, который реализует интерфейс, не создавая подклассов. Наконец, мы пока-жем, как можно запрограммировать ABC, чтобы он автоматически «распознавал» любые классы, согласованные с его интерфейсом, – без создания подклассов и без явной регистрации. Мы реализуем новый ABC, чтобы посмотреть, как он работает, но Алекс Мар- телли и я не советуем бросаться писать ABC по поводу и без повода. ABC несут с собой опасность переусложнения. 1 Бьярн Страуструп «Дизайн и эволюция C++». ДМК Пресс, 2014, стр. 284.\n--- Страница 339 ---\n339 Интерфейсы и протоколы в культуре Python ABC, подобно дескрипторам и метаклассам, предназначены для разработки каркасов. Поэтому лишь малая часть пишущих на Python может создавать ABC, не налагая ненужных ограничений на своих коллег-программистов и не заставляя их делать бес-смысленную работу. Начнем с взгляда Python на интерфейсы. Интерфейсы и протоколы в культуре Python Python уже добился успеха, когда в нем появились ABC, и в самых замечатель- ных программах они вообще не используются. Начиная с главы 1, мы говорим о динамической типизации и протоколах. В разделе «Протоколы и динамическая ти- пизация» главы 10 протоколы были определены как неформальные интерфейсы, благодаря которым в языках с динамической типизацией, к каковым относится и Python, работает полиморфизм. Как же работают интерфейсы в динамически типизированном языке? Начнем с основ: даже без ключевого слова interface и независимо от наличия ABC у каж- дого класса есть интерфейс: множество открытых членов (методов и атрибутов), реализованных в самом классе или унаследованных от родителя. Сюда входят и специальные методы, например __getitem__ или __add__ . По определению, закрытые и защищенные члены не являются частью интерфейса, даже если под «защищенным» понимается всего лишь соглашение об именовании (один начальный подчерк), а к закрытым атрибутам легко получить доступ (см. раздел «Закрытые и защищенные атрибуты в Python»главы 9). И нарушать эти соглашения – дурной тон. С другой стороны, не считается грехом включать открытые атрибуты-данные в состав интерфейса объекта, потому что – при необходимости – такой атрибут можно преобразовать в свойство, реализующее логику чтения и установки, и это не приведет к «поломке» клиентского кода, в котором используется простая но-тация obj.attr . Мы так поступали в классе Vector2d : в примере 11.1 повторена первая реализация с открытыми атрибутами x и y. Пр имер 11.1. vector2d_v0.py: x и y – открытые атрибуты (повторение примера 9.2) class Vector2d: typecode = 'd' def __init__(self, x, y): self.x = float(x) self.y = float(y) def __iter__(self):\n--- Страница 340 ---\n340 return (i for i in (self.x, self.y)) # прочие методы опущены В примере 9.7 мы преобразовали x и y в свойства, доступные только для чте- ния (пример 11.2). Это существенный рефакторинг, но обращенный к пользова-телю интерфейс Vector2d не изменился: нотация my_vector.x и my_vector.y по- прежнему допустима. Пример 11.2. vector2d_v3.py: x и y преобразованы в свойства (полный код см. в примере 9.9) class Vector2d: typecode = 'd' def __init__(self, x, y): self.__x = float(x) self.__y = float(y) @property def x(self): return self.__x @property def y(self): return self.__y def __iter__(self): return (i for i in (self.x, self.y)) # прочие методы опущены Дадим полезное дополнительное определение интерфейса: подмножество открытых методов объекта, которое позволяет ему играть определенную роль в системе. Именно это имеется в виду в таких встречающихся в документации по Python выражениях, как «объект, похожий на файл» или «итерируемый объект», без упоминания конкретного класса. Интерфейс, рассматриваемый как набор ме-тодов, позволяющих играть какую-то роль, в языке Smalltalk называется прото- колом , и этот термин позаимствовали сообщества других динамических языков. Протоколы никак не связаны с наследованием. Класс может реализовывать не-сколько протоколов, т. е. играть несколько разных ролей. Протоколы – это интерфейсы, но поскольку они неформальны – определены лишь путем документирования и соглашений – то не могут быть строго поддержа-ны, как формальные интерфейсы (ниже в этой главе мы увидим, как ABC прове-ряют согласованность с интерфейсом). Протокол можно реализовать в некотором классе лишь частично, и это вполне допустимо. Иногда все, что требуется от «по-хожего на файл объекта», – иметь метод .read() , который возвращает байты. Все прочие методы файла в данном контексте могут и не требоваться.Глава 11. Интерфейсы: от протоколов до абстрактных базовых\n--- Страница 341 ---\n341 Python в поисках следов последовательностей Когда я пишу эти строки, в документации по классу memoryview (http://bit. ly/1QOxU2e ) говорится, что он работает с объектами, которые «поддерживают протокол буфера», документированный только на уровне C API. Конструктор bytearray (http://bit.ly/1MDR1Lw ) принимает «объект, согласованный с интер- фейсом буфера». Сейчас наметилась тенденция к использованию более друже-ственного термина «объект, похожий на bytes» 2. Я это говорю, чтобы подчеркнуть: «похожий на X объект», «протокол X» и «интерфейс X», на взгляд питонистов, являются синонимами. Один из самых фундаментальных интерфейсов в Python – протокол после- довательности. Интерпретатор из кожи вон лезет, стремясь обработать объекты, предоставляющие даже минимальную реализацию этого протокола. Это демон-стрируется в следующем разделе. Python в поисках следов последовательностей Философия модели данных Python заключается в том, чтобы всемерно взаимо- действовать с важнейшими протоколами. А уж если речь идет о последователь-ностях, то Python прилагает все усилия, соглашаясь работать даже с самыми про-стыми реализациями. На рис. 11.1 показано формальное определение интерфейса Sequence в виде ABC. Рис. 11.1. UML-диаграмма абстрактного базового класса Sequence и связанных с ним классов из модуля collections.abc. Стрелки направлены от подклассов к суперклассам. Курсивом набраны имена абстрактных методов. Теперь взгляните на класс Foo в примере 11.3. Он не наследует классу abc.Se- quence , а лишь реализует один метод протокола последовательности: __getitem__ (метод __len__ отсутствует). 2 Проблема 16518: «добавить протокол буфера в глоссарий» ( http://bugs.python.org/issue16518 ) была разрешена путем замены многочисленных упоминаний «объекта, который поддерживает прото-кол/интерфейс/API буфера» «объектом, похожим на bytes»; но за ней последовала проблема «Дру-гие упоминания протокола буфера» ( http://bugs.python.org/issue22581 ).\n--- Страница 342 ---\n342 Пример 11.3. Частичная реализация протокола последовательности: метода __getitem__ достаточно для доступа к элементам, итерирования и реализации оператора in >>> class Foo: def __getitem__(self, pos): return range(0, 30, 10)[pos] >>> f[1]10>>> f = Foo()>>> for i in f: print(i) 01020>>> 20 in fTrue>>> 15 in fFalse Метода __iter__ в классе Foo нет, однако его экземпляры являются итерируе- мыми объектами, потому что даже в случае отсутствия __iter__ Python, обнару- жив метод __getitem__ , пытается обойти объект, вызывая этот метод с целочис- ленными индексами, начиная с 0. Поскольку Python достаточно «умен», чтобы обойти объекты Foo, он может также реализовать оператор in, даже если в классе Foo нет метода __contains__ : для этого достаточно обойти весь объект в поисках элемента. Итак, принимая во внимание важность протокола последовательности, интер- претатор Python даже в случае отсутствия методов __iter__ и __contains__ уму- дряется выполнить итерирование и заставить работать оператор in, вызывая ме- тод __getitem__ . Наш класс FrenchDeck из главы 1 тоже не является подклассом abc.Sequence , но реализует оба метода протокола последовательности: __getitem__ и __len__ . См. пример 11.4. Пример 11.4. Колода карт как последовательность (повторение примера 1.1) import collections Card = collections.namedtuple('Card', ['rank', 'suit'])class FrenchDeck: ranks = [str(n) for n in range(2, 11)] + list('JQKA') suits = 'spades diamonds clubs hearts'.split() def __init__(self): self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks] def __len__(self):Глава 11. Интерфейсы: от протоколов до абстрактных базовых\n--- Страница 343 ---\n343 return len(self._cards) def __getitem__(self, position): return self._cards[position] Добрая часть демонстраций в главе 1 работает, потому что Python специаль- ным образом обрабатывает все, что хотя бы отдаленно напоминает последователь-ность. Итерирование в Python – это крайняя форма динамической типизации: ин-терпретатор пробует разные методы, чтобы выполнить обход объекта. Теперь изучим еще один пример, подчеркивающий динамическую природу протоколов. Партизанское латание как средство реализации протокола во время выполнения. У класса FrenchDeck из примера 11.4 есть существенный изъян: колоду нельзя перетасовать. Много лет назад, впервые написав этот пример, я реализовал метод shuffle . Позже меня посетило питоническое озарение: если FrenchDeck ведет себя как последовательность, то ему не нужен собственный метод shuffle , потому что уже имеется функция random.shuffle , в документации по которой ( https://docs. python.org/3/library/random.html#random.shuffle ) написано: «Перетасовывает по- следовательность х на месте». Если следовать устоявшимся протоколам, то будет больше шансов вос- пользоваться кодом, уже имеющимся в стандартной библиотеке или на- библиотеке или на- е или на- писанным кем-то еще, – благодаря динамической типизации. Стандартная функция random.shuffle используется следующим образом: >>> from random import shuffle>>> l = list(range(10))>>> shuffle(l)>>> l[5, 2, 9, 7, 8, 3, 1, 4, 0, 6] Но попытавшись перетасовать объект FrenchDeck , мы получим исключение (пример 11.5). Пример 11.5. random.shuffle не может работать с объектом FrenchDeck >>> from random import shuffle >>> from frenchdeck import FrenchDeck>>> deck = FrenchDeck()>>> shuffle(deck)Партизанское латание как средство реализации протокола\n--- Страница 344 ---\n344 Traceback (most recent call last): File \"<stdin>\", line 1, in <module> File \" /python3.3/random.py\", line 265, in shuffle x[i], x[j] = x[j], x[i]TypeError: 'FrenchDeck' object does not support item assignment В сообщении ясно говорится: «Объект 'FrenchDeck' не поддерживает присва- ивание элементу». Проблема в том, что shuffle должна иметь возможность пере- ставить два элемента коллекции, а класс FrenchDeck реализует только протокол не- изменяемой последовательности. Изменяемая последовательность должна также предоставлять метод __setitem__ . Поскольку Python – динамический язык, мы можем устранить проблему пря- мо во время выполнения, даже в интерактивной оболочке. В примере 11.6 показа- выполнения, даже в интерактивной оболочке. В примере 11.6 показа- я, даже в интерактивной оболочке. В примере 11.6 показа- но, как это сделать. Пример 11.6. Партизанское латание класса FrenchDeck с целью сделать его изменяемым и совместимым с функцией random.shuffle (продолжение примера 11.5) >>> def set_card(deck, position, card): /g110 deck._cards[position] = card >>> FrenchDeck.__setitem__ = set_card /g111 >>> shuffle(deck) /g112 >>> deck[:5][Card(rank='3', suit='hearts'), Card(rank='4', suit='diamonds'), Card(rank='4',suit='clubs'), Card(rank='7', suit='hearts'), Card(rank='9', suit='spades')] /g110 Создаем функцию, которая принимает аргументы deck , position и card . /g111 Присваиваем эту функцию атрибуту __setitem__ класса FrenchDeck . /g112 Теперь объект deck можно перетасовать, потому что класс FrenchDeck под- держивает обязательный метод протокола изменяемой последовательно-сти. Сигнатура метода __setitem__ определена в разделе 3.3.6 «Эмуляция контей- нерных типов» справочного руководства по языку Python ( http://bit.ly/1QOyDQ Y ). В данном случае мы назвали аргументы deck , position , card – а не self , key, value , как в руководстве, – чтобы показать, что любой метод Python изначально является простой функцией, а имя self для первого аргумента – не более чем соглашение. В сеансе оболочки это нормально, но в исходном файле Python гораздо лучше ис-пользовать предлагаемые в документации имена self , key и value . Трюк состоит в том, что функция set_card знает о наличии в объекте deck атри- бута с именем _cards , который должен быть изменяемой последовательностью. После этого мы присоединяем функцию set_card к классу FrenchDeck в качестве специального метода __setitem__ . Это пример партизанского латания (monkey patching): изменения класса или модуля во время выполнения без модификации исходного кода. Техника весьма действенная, но код, в котором она используется, оказывается очень тесно связан с латаемой программой и зачастую даже вмеши-вается в ее закрытые и недокументированные части.Глава 11. Интерфейсы: от протоколов до абстрактных базовых\n--- Страница 345 ---\n345 Алекс Мартелли о водоплавающих Помимо партизанского латания, в примере 11.6 иллюстрируется динамичность протоколов: функции random.shuffle безразлично, какие аргументы ей переданы, лишь бы объект реализовал часть протокола изменяемой последовательности. Не-важно даже, получил ли объект необходимые методы «при рождении» или каким-то образом приобрел их позже. До сих пор мы рассматривали в этой главе динамическую типизацию: работу с объектами независимо от их типа при условии, что они реализуют определенные протоколы. Представляя диаграммы, включающие ABC, мы хотели показать, как протоко- лы соотносятся с явными интерфейсами, документированными в виде абстракт-ных классов, но мы еще ни разу не наследовали абстрактному классу . В следующих разделах мы воспользуемся ABC непосредственно, а не только как документацией. Алекс Мартелли о водоплавающих Познакомившись с обычными для Python интерфейсами в виде протоколов, об-ратимся к абстрактным базовым классам. Но перед тем как переходить к деталям и примерам, предлагаем вашему вниманию вставное эссе Алекса Мартелли, в ко-тором он объясняет, почему ABC стали замечательным добавлением к Python. Водоплавающие птицы и ABC Алекс Мартелли В википедии ( http://en.wikipedia.org/wiki/Duck_typing#History ) мне приписывают честь распространения полезного мема и эффектного вы-ражения «утиная типизация» (т. е. игнорирование фактического типа объекта и акцент на то, чтобы объект реализовывал методы с именами, сигнатурами и семантикой, требуемыми для конкретного применения). В Python это сводится, в основном, к тому, чтобы избегать использо- вания функции isinstance для проверки типа объекта (я уже не говорю о еще более вредном подходе: проверке вида type(foo) is bar , которую следует предать анафеме, потому что она препятствует даже простей-шим формам наследования!). В целом, утиная типизация остается весьма полезной во многих кон- текстах, однако есть и много других, где со временем выработался иной, более предпочтительный подход. Отсюда и начинается наш рассказ… Уже для многих поколений классификация по родам и видам (в том числе и семейства водоплавающих, известного под названием Anatidae) основывается, главным образом, на фенетике – когда во главу угла ста-вится сходство морфологии и поведения… в общем, на наблюдаемых ха-рактеристиках. Аналогия с «утиной типизацией» была очень сильной.\n--- Страница 346 ---\n346 Однако в ходе параллельной эволюции зачастую сходные характери- стики, как морфологические, так и поведенческие, оказываются у видов, которые фактически не связаны друг с другом, но просто эволюциони-ровали в похожих, хотя и разных, экологических нишах. Подобное «слу-чайное сходство» встречается и в программировании. Для иллюстрации возьмем классический пример из ООП: class Artist: # художник def draw(self): # рисовать class Gunslinger: # стрелок def draw(self): # выхватить револьвер class Lottery: # лотерея def draw(self): # тянуть билетик Очевидно, одного лишь существования метода draw без аргументов далеко недостаточно, чтобы убедить нас в том, что два объекта x и y та- кие, что допустимы вызовы x.draw() и y.draw() , являются хоть в какой- то степени взаимозаменяемыми или абстрактно эквивалентными, – из допустимости подобных вызовов нельзя сделать никаких выводов о схо-жести семантики. Понадобится опытный программист, который взялся бы уверенно подтвердить , что такая эквивалентность имеет место на каком-то уровне! В биологии (и других дисциплинах) эта проблема стала причиной появления (а во многих отношениях и преобладания) подхода, альтер-нативного фенетике, а именно кладистики – классификации с упором на характеристики, унаследованные от общих предков, а не появивши-еся в результате независимой эволюции. (Дешевая и быстрая методика секвенцирования ДНК может сделать кладистику практически полез-ной в гораздо большем числе случаев, чем сейчас.) Например, гуси-пеганки и утки-пеганки (которые раньше в класси- фикации стояли ближе к другим гусям и уткам) теперь помещены в под-семейство Tadornidae (откуда следует, что они ближе друг к другу, чем к другим представителям семейства Anatidae, поскольку имеют общего предка). Кроме того, анализ ДНК показал, что белокрылая каролинская утка не так близка к мускусной утке (которая является уткой-пеган-кой), как можно было бы предположить по внешнему виду и поведению. Поэтому классификация каролинской утки была изменена, ее вообще исключили из подсемейства и выделили в отдельный род! Важно ли это? Все зависит от контекста! Если нужно решить, как лучше приготовить водоплавающую птицу, которую вы уже добыли, то наблюдаемые характеристики (не все – скажем, наличие плюмажа, в этом случае роли не играет) и, прежде всего, структура мяса и вкусо-Глава 11. Интерфейсы: от протоколов до абстрактных базовых\n--- Страница 347 ---\n347 Алекс Мартелли о водоплавающих вые качества (старомодная фенетика!) гораздо важнее кладистики. Но в других вопросах, например в отношении восприимчивости к различным патогенным организмам (следует ли пытаться выращивать птицу в не-воле или сохранять их в дикой природе), близость ДНК может оказать-ся гораздо важнее… Итак, в силу наличия отдаленной аналогии с таксономической рево- люцией в мире водоплавающих птиц я рекомендую дополнить старую добрую утиную типизацию (не вовсе заменить – в некоторых контек- стах она нам еще послужит) … гусиной типизацией ! Гусиная типизация означает следующее: вызов isinstance(obj, cls) теперь считается приемлемым… при условии, что cls – абстрактный ба- зовый класс, т. е. метаклассом cls является abc.ABCMeta . В модуле collections.abc можно найти немало полезных абстракт- ных классов (они есть также в модуле numbers из стандартной библио- теки Python)3. Из многих концептуальных преимуществ ABC по сравнению с конкретными классами (например, Скотт Мейер в своей книге «Бо-лее эффективный C++», совет 33 – http://ptgmedia.pearsoncmg.com/ images/020163371x/items/item33.html – говорит, что «все нелистовые классы должны быть абстрактными») выделим одно практически важ-ное достоинство ABC в Python: метод класса register , который дает возможность конечному пользователю «объявить» некоторый класс «виртуальным» подклассом ABC (для этого зарегистрированный класс должен удовлетворять требованиям ABC к имени и сигнатуре и, что еще важнее, подразумеваемому семантическому контракту, но его необяза-тельно разрабатывать с учетом ABC и, в частности, не требуется насле-довать ему!). Это большой шаг на пути к устранению жесткости и силь-ной сцепленности, из-за которых к наследованию следует относиться с куда большей настороженностью, чем позволяют себе большинство программирующих на ОО-языках… Иногда даже и регистрировать класс не нужно, чтобы ABC распоз- нал его как подкласс! Так бывает в случае ABC, существующих только ради нескольких специальных методов. Например: >>> class Struggle: def __len__(self): return 23 3 Разумеется, вы можете определить и свои ABC, но я не советую это делать никому, кроме самых опытных питонистов, равно как не советую определять свои метаклассы… и даже для этих «самых опытных питонистов», знающих обо всех потаенных уголках и темных закоулках языка, это инструменты не для каждодневного использования. Эти средства «углубленного метапрограммирования» предназначены авторам каркасов широкого на-значения, которые предположительно будут независимо развивать многочисленные не связанные между собой команды разработчиков. В общем, они могут понадобиться менее чем 1 % «самых опытных питонистов»! – А. М.\n--- Страница 348 ---\n348 >>> from collections import abc>>> isinstance(Struggle(), abc .Sized) True Как видим, abc.Sized распознал Struggle как свой «подкласс» безо всякой регистрации, просто потому что для этого необходимо только на-личие специального метода __len__ (предполагается, что он реализован правильно с точки зрения синтаксиса – вызывается без аргументов – и семантики – возвращает неотрицательное целое число, интерпретиру-емое как «длина» объекта; программа, которая реализует специальный метод, например __len__ с какими-то другими, несогласованными, син- таксисом и семантикой, в любом случае обречена на куда более серьез-ные проблемы). Итак, вот мое напутствие: реализуя класс, который воплощает кон- цепции, представленные в ABC из модуля numbers , collections.abc или какого-то другого каркаса, либо делайте его подклассом ABC (если не- ABC (если не- (если не- обходимо), либо регистрируйте. В начале программы, использующей библиотеку или каркас, где определяются классы, для которых это не сделано, выполняйте регистрацию самостоятельно. Затем, если потре-буется проверить, что аргумент (чаще всего это необходимо как раз для аргументов) является, к примеру, «последовательностью», пишите: isinstance(the_arg, collections.abc.Sequence) И не определяйте свои ABC (или метаклассы) в производственном коде… Если вам кажется, что без этого не обойтись, держу пари, что это, скорее всего, желание поскорее забить гвоздь, раз уж в руках молоток, – вам (и тем, кому предстоит сопровождать вашу программу) будет куда комфортнее иметь дело с прямолинейным и простым кодом, где нет та-ких глубин. Val ē! Помимо изобретения термина «гусиная типизация», Алекс подчеркивает, что наследование ABC не сводится к реализации необходимых методов, это еще и чет-кое заявление о намерениях разработчика. Такое намерение можно сделать явным также путем регистрации виртуального подкласса. Кроме того, использование функций isinstance и issubclass для проверки принадлежности ABC выглядит уже не столь одиозным. В прошлом эти функции концептуально противоречили динамической типизации, но с появлением ABC они становятся более гибкими. Ведь даже если компонент не является подклас-сом ABC, его всегда можно зарегистрировать постфактум, так что он пройдет эти явные проверки типа. Однако и при использовании ABC нужно помнить, что злоупотребление функ- цией isinstance может быть признаком «дурно пахнущего кода» – плохо спроек-Глава 11. Интерфейсы: от протоколов до абстрактных базовых\n--- Страница 349 ---\n349 Алекс Мартелли о водоплавающих тированной объектно-ориентированной программы. Обычно не должно быть це- почек предложений if/elif/elif , в которых с помощью insinstance определяется тип объекта и в зависимости от него выполняются те или иные действия; для этой цели следует использовать полиморфизм, т. е. проектировать классы, так чтобы интерпретатор сам вызывал правильные методы, а не «зашивать» логику диспет-черизации в блоки if/elif/elif . Из этой рекомендации существует часто встречающееся на практике исключение: некоторые функции и методы в Python при-нимают либо одну строку str, либо последовательность строк. Если передана только одна строка, то для упрощения обработ-ки имеет смысл обернуть ее списком list . Поскольку str – тип последовательности, отличить строку от других неизменяемых последовательностей проще всего при помощи явной проверки isinstance(x, str)4. С другой стороны, обычно нет возражений против использования insin- stance для сравнения с типом ABC, если требуется убедиться в соблюдении контракта: «Эй, чтобы меня вызывать, ты должен реализовать то-то и то-то», как выразился технический рецензент Леннарт Регебро. Особенно это полезно в системах, основанных на архитектуре подключаемых модулей. За пределами каркасов динамическая типизация обычно проще и дает большую гибкость, чем проверка типов. Например, в этой книге встречаются классы, где мне нужно принять последо- вательность элементов и обработать как список list , а не проверять, что аргумент имеет тип list . В таких случаях я просто беру аргумент и сразу же строю из него список, это позволяет мне принять любой итерируемый объект, а если окажется, что объект таковым не является, то вызов завершится с ошибкой на ранней стадии, и будет выдано вполне понятное сообщение. Один пример такого рода – метод __init__ в примере 11.13 ниже. Конечно, такой подход не годится, если последо- вательность, переданную в аргументе, нельзя копировать, – то ли потому что она слишком велика, то ли потому что программа должна изменять ее на месте. Тогда больше подойдет проверка insinstance(x, abc.MutableSequence) . Если допустим произвольный итерируемый объект, то можно пойти по пути получения итератора с помощью вызова iter(x) , как мы увидим в разделе «Почему последовательности итерируемы: функция iter» на стр. 435. Другой пример – имитация обработки аргумента field_names в классе col- lections.namedtuple (https://docs.python.org/3/library/collections.html#collections. 4 К сожалению, в Python 3.4 не существует ABC, помогающих отличить строку от кортежа и других неизменяемых последовательностей, поэтому приходится сравнивать с типом str . В Python 2 есть тип basestr , который позволяет выполнять такие проверки. Это не ABC, а класс, которому на- следуют как str , так и unicode ; однако в Python 3 класс basestr исключен. Любопытно, что в Python 3 имеется тип collections.abc.ByteString , но он позволяет выделить только типы bytes и bytearray .\n--- Страница 350 ---\n350 namedtuple ): field_names может быть как одной строкой, в которой идентифика- торы разделены пробелами или запятыми, так и последовательностью идентифи-каторов. Возникает соблазн воспользоваться функцией isinstance , но в приме- ре 11.7 показано, как сделать это с помощью динамической типизации5. Пример 11.7. Применение динамической типизации для обработки строки или итерируемого объекта, содержащего строки try: /g110 field_names = field_names.replace(',', ' ').split() /g111 except AttributeError: /g112 pass /g113 field_names = tuple(field_names) /g114 /g110 Предполагаем, что это строка (проще попросить прощения, чем испраши- вать разрешение). /g111 Заменяем запятые пробелами и разбиваем образовавшуюся строку, полу- чая список имен. /g112 Увы, field_names не крякает, как str… то ли метода .replace нет, то ли он возвращает нечто такое, к чему нельзя применить .split . /g113 Теперь предполагаем, что field_names уже является итерируемым объек- том, содержащим имена. /g114 Чтобы убедиться в его итерируемости и заодно получить внутреннюю ко- пию, создаем кортеж из того, что имеем. Наконец, в своем эссе Алекс неоднократно подчеркивает, что не нужно усерд- ствовать в создании ABC. Эпидемия ABC имела бы катастрофические послед-ствия, вынуждая выполнять ненужные церемонии в языке, завоевавшем популяр-ность своей практичностью и прагматичностью. В своей рецензии на эту книгу Алекс написал: ABC предназначены для инкапсуляции очень общих концеп- ций, абстракций, характерных для каркаса, – таких вещей, как «по-следовательность» или «точное число». [Читателям], скорее всего, не придется писать новые ABC, а лишь правильно использовать существующие. В 99.9 % случаев этого будет достаточно для полу-чения всех преимуществ без риска спроектировать что-то не то. Ну а теперь посмотрим, как гусиная типизация выглядит на практике. Создание подкласса ABC Следуя совету Мартелли, мы воспользуемся существующим ABC collections.Mu- tableSequence , перед тем как изобретать свой собственный. В примере 11.8 класс FrenchDeck2 явно объявлен подклассом collections.MutableSequence . 5 Этот фрагмент взят из примера 21.2.Глава 11. Интерфейсы: от протоколов до абстрактных базовых\n--- Страница 351 ---\n351 Создание подкласса ABC Пример 11.8. frenchdeck2.py: FrenchDeck2 , подкласс collections.MutableSequence import collections Card = collections.namedtuple('Card', ['rank', 'suit'])class FrenchDeck2(collections.MutableSequence): ranks = [str(n) for n in range(2, 11)] + list('JQKA') suits = 'spades diamonds clubs hearts'.split() def __init__(self): self._cards = [Card(rank, suit) for suit in self.suits for rank in self.ranks] def __len__(self): return len(self._cards) def __getitem__(self, position): return self._cards[position] def __setitem__(self, position, value): # /g110 self._cards[position] = value def __delitem__(self, position): # /g111 del self._cards[position] def insert(self, position, value): # /g112 self._cards.insert(position, value) /g110 Метод __setitem__ – все, что нам нужно для поддержки тасования… /g111 Но чтобы создать подкласс MutableSequence , нам придется реализовать так- же __delitem__ – абстрактный метод, определенный в этом ABC. /g112 Также необходимо реализовать insert , третий абстрактный метод Mutable- Sequence . На этапе импорта (когда модуль frenchdeck2.py загружается и компилируется) Python не проверяет, реализованы ли абстрактные методы. Это происходит только на этапе выполнения, когда мы пытаемся создать объект FrenchDeck2 . И тогда, если абстрактный метод не реализован, мы получим исключение TypeError с сообще- нием вида \"Can't instantiate abstract class FrenchDeck2 with abstract methods __delitem__, insert\" . Вот поэтому мы и обязаны реализовать методы __delitem__ и insert , хотя в наших примерах класс FrenchDeck2 в них и не нуждается; ничего не поделаешь – абстрактный базовый класс MutableSequence требует. Как показано на рис. 11.2, не все методы ABC Sequence и MutableSequence абст- рактны. От Sequence класс FrenchDeck2 наследует готовые к применению конкретные методы __contains__ , __iter__ , __reversed__ , index и count . От MutableSequence он получает append , reverse , extend , pop, remove и __iadd__ . Конкретные методы в каждом ABC из модуля collections.abc реализованы в\n--- Страница 352 ---\n352 терминах открытого интерфейса класса, поэтому для работы им не нужны никакие знания о внутренней структуре экземпляров. Рис. 11.2. UML-диаграмма класса MutableSequence и его суперклассов из модуля collections.abc. Стрелки направлены от подклассов к суперклассам. Курсивом набраны имена абстрактных классов и методов Кодировщику конкретного подкласса иногда приходится перео- пределять методы, унаследованные от ABC, предоставляя более эффективную реализацию. Например, унаследованный метод __contains__ просматривает всю последовательность, но если в конкретной последовательности элементы всегда отсортиро- ваны, то можно написать более быстрый вариант __contains__ , который будет производить двоичный поиск с помощью функции bisect (см. раздел «Средства работы с упорядоченными после- довательностями в модуле bisect» главы 2). Чтобы работать с ABC, нужно знать, что есть в нашем распоряжении. Далее мы рассмотрим ABC коллекций. ABC в стандартной библиотеке Начиная с версии Python 2.6, ABC включены в стандартную библиотеку. Большая их часть определена в модуле collections.abc , но есть и другие. Например, ABC можно найти в пакетах numbers и io. Но все-таки большинство наиболее употребительных находятся в collections.abc . Посмотрим, что там есть. ABC в модуле collections.abc В стандартной библиотеке есть два модуля с именем abc. Мы сейчас говорим о модуле collections .abc. Чтобы умень- шить время загрузки, в версии Python 3.4 он находится не в па- кете collections , а в файле Lib/_collections_abc.py (http://bit. ly/1QOA3Lt ), поэтому импортируется отдельно от collections . Глава 11. Интерфейсы: от протоколов до абстрактных базовых\n--- Страница 353 ---\n353 ABC в стандартной библиотеке Другой модуль abc называется просто abc (т . е. Lib/abc.py – https:// hg.python.org/cpython/file/3.4/Lib/abc.py ), в нем определен класс abc .ABC. Все ABC зависят от этого класса, но импортировать его самостоятельно нужно только при создании нового ABC. На рис. 11.3 приведена сокращенная UML-диаграмма классов (без имен атри- бутов), на которой показаны все 16 ABC, определенных в модуле collections .abc в версии Python 3.4. В официальной документации по модулю collections .abc име- ется симпатичная таблица ( http://bit.ly/1QOA9T8 ), в которой перечислены ABC, их взаимосвязи, а также абстрактные и конкретные методы (так называемые «под-мешанные методы»). На рис. 11.3 мы видим немало примеров множественного на-следования. Множественному наследованию посвящена большая часть главы 12, а пока скажем лишь, что в случае абстрактных базовых классов оно обычно не составляет проблемы 6. Рис. 11.3. UML-диаграмма абстрактных базовых классов из модуля collections.abc Коротко рассмотрим группы классов на рис. 11.3. Iterable , Container , Sized Любая коллекция должна либо наследовать какому-то из этих ABC, либо, по крайней мере, реализовывать совместимые протоколы. Класс Iterable поддерживает итерирование методом __iter__ , Container поддержива- ет оператор in методом __contains__ , а Sized – функцию len() методом __len__ . 6 Множественное наследование было сочтено вредным и исключено из языка Java. Исключение было сделано для интерфейсов: в Java интерфейс может расширять несколько интерфейсов, а класс реа-лизовывать несколько интерфейсов.\n--- Страница 354 ---\n354 Sequence , Mapping , Set Это основные типы неизменяемых коллекций, и у каждого есть изменя- емый подкласс. Детальная диаграмма класса MutableSequence показана на рис. 11.2, а диаграммы классов MutableMapping и MutableSet приведены в главе 3 (рис. 3.1 и 3.2). MappingView В Python 3 объекты, возвращенные методами отображения .items() , .keys() и .values() , наследуют классам ItemsView , KeysView и ValuesView соответственно. Первые два также наследуют богатый интерфейс класса Set, со всеми операторами, которые были описаны в разделе «Операции над множествами» главы 3. Callable и Hashable Эти ABC не так тесно связаны с коллекциями, но collections.abc был пер- вым пакетом в стандартной библиотеке, где были определены ABC, а эти два класса казались достаточно важными, чтобы включить их. Я никогда не встречал подклассов Callable или Hashable . Их основное назначение – под- держка безопасного способа выяснить, является или объект вызываемым или хэшируемым, с помощью встроенной функции insinstance .7 Iterator Отметим, что класс Iterator является подклассом Iterable . Мы еще вер- немся к этому вопросу в главе 14. После пакета collections.abc следующим по полезности является пакет ABC из стандартной библиотеки numbers . Числовая башня ABC В пакете numbers (https://docs.python.org/3/library/numbers.html ) определе- на так называемая «числовая башня» (т. е. линейная иерархия ABC), в которой Number – суперкласс самого верхнего уровня, Complex – промежуточный подкласс и так далее, вплоть до класса Integral : • Number • Complex• Real• Rational• Integral Таким образом, если нужно проверить, является ли объект целым числом, вы- зывайте isinstance(x, numbers.Integral) ; этот вызов вернет True для типов int, bool (это подкласс int) и прочих целочисленных типов, предоставляемых внеш- 7 Чтобы узнать, является ли объект вызываемым, существует встроенная функция callable() , но аналогичной функции hashable() нет, поэтому для проверки хэшируемости рекомендуется вы- зывать функцию isinstance(my_obj, Hashable) .Глава 11. Интерфейсы: от протоколов до абстрактных базовых\n--- Страница 355 ---\n355 Определение и использование ABC ними библиотеками, которые зарегистрировали свои типы как подклассы ABC из модуля numbers . А чтобы проверка наверняка прошла, вы (или пользователи вашего API) всегда можете зарегистрировать любой совместимый тип в качестве виртуального подкласса numbers.Integral . Если, с другой стороны, значение может быть числом с плавающей точкой, то проверка isinstance(x, numbers.Real) радостно согласится принять типы bool , int, float , fractions.Fraction и прочие не комплексные числовые типы, предо- ставляемые внешними библиотеками, например NumPy, при условии, что они правильно зарегистрированы. Как это ни удивительно, тип decimal.Decimal не зарегистриро- ван в качестве виртуального подкласса numbers.Real . Причина в том, что если программе нужна точность типа Decimal , то следует защититься от случайного смешения таких чисел с другими, ме-нее точными числовыми типами и, в первую очередь, с числами с плавающей точкой. Познакомившись с некоторыми имеющимися ABC, попрактикуемся в гусиной типизации, для чего реализуем ABC с нуля и воспользуемся им. Цель не в том, чтобы очертя голову бросаться писать ABC, а в том, чтобы научиться читать ис-ходный код ABC, находящихся в стандартной библиотеке и в других пакетах. Определение и использование ABC Чтобы оправдать создание абстрактного базового класса, нам необходим контекст для использования его в качестве точки расширения в каком-то каркасе. Возьмем такой контекст: пусть требуется отображать на сайте или в мобильном приложе-нии рекламные объявления в случайном порядке, но при этом не повторять ника-кое объявление, пока будут показаны все остальные из имеющегося набора. Допу-стим, мы разрабатываем систему управления рекламой под названием ADAM . Одно из требований – поддержать предоставляемые пользователем классы случайного выбора без повторений 8. Чтобы у пользователей ADAM не было сомнений, что по- нимается под «случайным выбором без повторений», мы определим ABC. Позаимствовав идею у слов «стек» и «очередь» (которые описывают абстрактные интерфейсы в терминах физической организации объектов), я назову наш ABC, ру- ABC, ру- , ру- ководствуясь следующей метафорой из реального мира: барабаны для бинго и лоте-реи – это машины, предназначенные для случайного выбора элемента из конечного множества, без повторений, до полного исчерпания множества. Наш ABC будет называться Tombola , это итальянское название игры в бинго и опрокидывающегося контейнера, в котором перемешиваются номера9. 8 Быть может, клиент захочет подвергнуть рандомизатор аудиту или рекламное агентство решит предоставить какой-то особо хитрый рандомизатор. Заранее никогда не скажешь… 9 Оксфордский словарь английского языка определяет tombola как «вид лотереи, напоминающий лото».\n--- Страница 356 ---\n356 В ABC Tombola определены четыре метода. Два из них абстрактны: • .load( …): поместить элементы в контейнер; • .pick() : извлечь случайный элемент из контейнера и вернуть его. И есть еще два конкретных метода: • .loaded() : вернуть True , если в контейнере имеется хотя бы один элемент; • .inspect() : вернуть отсортированный кортеж tuple , составленный из эле- ментов, находящихся в контейнере, не изменяя его содержимого (внутрен-нее упорядочение не сохраняется). На рис. 11.4 показан ABC Tombola и три его конкретных реализации. Рис. 11.4. UML-диаграмма ABC и трех его подклассов. Имена класса Tombola и его абстрактных методов набраны курсивом, в соответствии с соглашениями UML. Пунктирная стрелка обозначает реализацию интерфейса, здесь она показывает , что TomboList – виртуальный подкласс Tombola, поскольку, как мы увидим ниже, он зарегистрирован10 В примере 11.9 показано определение ABC Tombola . Пример 11.9. tombola.py: Tombola – ABC с двумя абстрактными и двумя конкретными методами import abc class Tombola(abc.ABC): /g110 @abc.abstractmethod def load(self, iterable): /g111 \"\"\"Добавить элементы из итерируемого объекта.\"\"\" 10 «registered» и «virtual subclass» – не стандартные термины UML. Мы пользуемся ими, чтобы по- казать взаимосвязи между классами, специфичные для Python.Глава 11. Интерфейсы: от протоколов до абстрактных базовых\n--- Страница 357 ---\n357 Определение и использование ABC @abc.abstractmethod def pick(self): /g112 \"\"\"Извлечь случайный элемент и вернуть его. Этот метод должен возбуждать исключение `LookupError`, если объект пуст. \"\"\" def loaded(self): /g113 \"\"\"Вернуть `True`, если есть хотя бы 1 элемент, иначе `False`.\"\"\" return bool(self.inspect()) /g114 def inspect(self): \"\"\"Вернуть отсортированный кортеж, содержащий находящиеся в контейнере элементы . \"\"\" items = [] while True: /g115 try: items.append(self.pick()) except LookupError: break self.load(items) /g116 return tuple(sorted(items)) /g110 Чтобы определить ABC, создаем подкласс abc.ABC . /g111 Абстрактный метод помечен декоратором @abstractmethod и зачастую его тело содержит только строку документации11. /g112 Строка документации сообщает программисту, реализующему метод, что в случае отсутствия элементов нужно возбудить исключение LookupError . /g113 ABC может содержать конкретные методы. /g114 Конкретные методы ABC должны зависеть только от открытого интерфей- ABC должны зависеть только от открытого интерфей- должны зависеть только от открытого интерфей- са данного (т. е. от других его конкретных или абстрактных методов или свойств). /g115 Мы не знаем, как в конкретных подклассах будут храниться элементы, но можем построить результат inspect , опустошив объект Tombola с помощью последовательных обращений к .pick() … /g116 … а затем с помощью .load( …) вернуть все элементы обратно. У абстрактного метода может существовать реализация. Но даже если так, подклассы все равно обязаны переопределить его, однако имеют право вызывать абстрактный метод с помо- абстрактный метод с помо- ый метод с помо- щью функции super() , расширяя имеющуюся функциональность, вместо того чтобы реализовывать ее с нуля. Информацию о де-талях использования декоратора @abstractmethod см. в докумен- тации по модулю abc (https://docs.python.org/3/library/abc.html ). 11 До появления ABC абстрактные методы обычно возбуждали исключение NotImplementedError , показывающее, что за реализацию отвечают подклассы.\n--- Страница 358 ---\n358 Метод .inspect() в примере 11.9, пожалуй, надуманный, но он показывает, что, имея всего лишь методы .pick() и .load( …), мы можем узнать, что находится вну- три Tombola : для этого сначала нужно извлечь все элементы по одному, а затем загрузить их обратно. Мы хотели этим подчеркнуть, что в предоставлении кон-кретных методов ABC нет ничего плохого при условии, что они зависят только от других методов интерфейса. Конкретные подклассы Tombola , знающие о своих внутренних структурах данных, всегда могут подменить .inspect() более эффек- тивной реализацией, но не обязаны это делать. Метод .loaded() в примере 11.9 не такой дурацкий, но накладный: он строит отсортированный кортеж с помощью .inspect() только для того, чтобы приме- нить к нему функцию bool() . Этот способ работает, но конкретный класс может поступить гораздо лучше, как мы вскоре увидим. Отметим, что в нашей «карусельной» реализации .inspect() обязательно перехватывать исключение LookupError , которое возбуждает метод self.pick() . Тот факт, что self.pick() может возбуждать исключение LookupError , составляет часть его интерфейса, но объявить это в Python можно только в документации (см. строку документации абстрактного метода pick в примере 11.9.) Я выбрал исключение LookupError из-за его места в иерархии исключений в Python по отношению к IndexError и KeyError – исключениям, которые, скорее все- го, будут возбуждать операции со структурами данных в конкретных подклассах Tombola . Таким образом, согласованная реализация может возбуждать исключение LookupError , IndexError или KeyError . См пример 11.10 (полное дерево приведено в разделе 5.4 «Иерархия исключений» справочного руководства по стандартной библиотеке Python). Пример 11.10. Часть иерархии классов Exception BaseException /g332/g326/g326 SystemExit /g332/g326/g326 KeyboardInterrupt /g332/g326/g326 GeneratorExit /g330/g326/g326 Exception /g332/g326/g326 StopIteration /g332/g326/g326 ArithmeticError /g327 /g332/g326/g326 FloatingPointError /g327 /g332/g326/g326 OverflowError /g327 /g330/g326/g326 ZeroDivisionError /g332/g326/g326 AssertionError /g332/g326/g326 AttributeError /g332/g326/g326 BufferError /g332/g326/g326 EOFError /g332/g326/g326 ImportError /g332/g326/g326 LookupError /g110 /g327 /g332/g326/g326 IndexError /g111 /g327 /g330/g326/g326 KeyError /g112 /g332/g326/g326 MemoryError и т. д.Глава 11. Интерфейсы: от протоколов до абстрактных базовых\n--- Страница 359 ---\n359 Определение и использование ABC /g110 LookupError – исключение, обрабатываемое в методе Tombola.inspect . /g111 IndexError – подкласс LookupError , это исключение возбуждается при по- пытке получить из последовательности элемент с индексом, большим ин-декса последнего элемента. /g112 Исключение KeyError возбуждается при обращении к несуществующему ключу отображения. Вот мы и создали собственный ABC Tombola . Чтобы посмотреть, как произво- дится проверка интерфейса ABC, попробуем обмануть Tombola , предоставив де- фектную реализацию. Пример 11.11. Непригодная реализация Tombola не останется незамеченной >>> from tombola import Tombola >>> class Fake(Tombola): # /g110 def pick(self): return 13 >>> Fake # /g111 <class '__main__.Fake'><class 'abc.ABC'>, <class 'object'>)>>> f = Fake() # /g112 Traceback (most recent call last): File \"<stdin>\", line 1, in <module>TypeError: Can't instantiate abstract class Fake with abstract methods load /g110 Объявляем Fake подклассом Tombola . /g111 Класс создан, пока никаких ошибок. /g112 При попытке создать экземпляр класса Fake возникает исключение TypeError . Сообщение не оставляет сомнений: класс Fake считается аб- страктным, потому что в нем не реализован метод load – один из абстракт- ных методов, объявленных в ABC Tombola . Итак, мы написали свой первый ABC и проверили, как контролируется его корректность. Скоро мы создадим подкласс Tombola , но сначала поговорим о не- которых правилах программирования ABC. Синтаксические детали ABC Лучший способ объявить ABC – сделать его подклассом abc.ABC или какого- нибудь другого ABC. Однако класс abc.ABC появился только в версии Python 3.4, а если вы пользуе- тесь более ранней версией (и наследовать другому существующему ABC не име-ет смысла), то придется включить в предложение class именованный аргумент metaclass= , указывающий на abc.ABCMeta (не abc.ABC ). В примере 11.9 следовало бы написать: class Tombola(metaclass=abc .ABCMeta): #\n--- Страница 360 ---\n360 Именованный аргумент metaclass= был введен в Python 3. В Python 2 нужно было использовать атрибут класса __metaclass__ : class Tombola(object): # это для Python 2!!! __metaclass__ = abc .ABCMeta # Метаклассы мы будем обсуждать в главе 21. А пока примем, что метакласс – это особый вид класса, и согласимся, что ABC – тоже особый вид класса; напри-мер, «обычные» классы не проверяют свои подклассы, так что это специальное поведение ABC. Помимо @abstractmethod , в модуле abc определены декораторы @abstract-abstract- classmethod , @abstractstaticmethod и @abstractproperty . Однако последние три объявлены нерекомендованными в версии Python 3.3, после того как стало воз-можно указывать другие декораторы поверх @abstractmethod , так что все прочие оказались избыточными. Например, вот как рекомендуется объявлять абстракт-ный метод класса: class MyABC(abc .ABC): @classmethod @abc.abstractmethod def an_abstract_classmethod(cls, ): pass Порядок декораторов функции в композиции обычно важен, а в случае abstractmethod , документация не оставляет никаких со- мнений: Если abstractmethod() применяется в сочетании с другими де- скрипторами метода, он должен быть самым внутренним декора-тором… 12 Иными словами, между @abstractmethod и предложением def не должно быть никаких других декораторов. Обсудив синтаксические детали ABC, опробуем Tombola на практике, реализо- вав несколько его конкретных подклассов. Создание подклассов ABC Tombola Имея ABC Tombola , мы теперь разработаем два конкретных подкласса, согласо- ванных с его интерфейсом. Они были изображены на рис. 11.4 вместе с виртуаль-ными подклассами, которые будут рассмотрены в следующем разделе. Класс BingoCage в примере 11.12 – это вариант примера 5.8 с более качествен- ным рандомизатором. В нем реализованы абстрактные методы load и pick , унас- 12 Раздел @abc.abstractmethod (http://bit.ly/1QOFpGB ) в документации по модулю abc (https:// docs.python.org/dev/library/abc.html ).Глава 11. Интерфейсы: от протоколов до абстрактных базовых\n--- Страница 361 ---\n361 Определение и использование ABC ледован от Tombola метод loaded , переопределен метод inspect и добавлен метод __call__ . Пример 11.12. bingo.py: BingoCage – конкретный подкласс Tombola import random from tombola import Tombolaclass BingoCage(Tombola): /g110 def __init__(self, items): self._randomizer = random.SystemRandom() /g111 self._items = [] self.load(items) /g112 def load(self, items): self._items.extend(items) self._randomizer.shuffle(self._items) /g113 def pick(self): /g114 try: return self._items.pop() except IndexError: raise LookupError('pick from empty BingoCage') def __call__(self): /g115 self.pick() /g110 Этот класс BingoCage явно расширяет Tombola . /g111 Качества класса random.SystemRandom достаточно для программирова- ния азартных игр в сети, он реализует API random , пользуясь функцией os.urandom( …), которая возвращает случайные байты, «пригодные для ис- пользования в криптографических приложениях» (документация по моду-лю os, http://docs.python.org/3/library/os.html#os.urandom ). /g112 Делегируем начальную загрузку методу .load( …). /g113 Вместо функции random.shuffle() используем метод .shuffle() нашего эк- земпляра SystemRandom . /g114 Метод pick реализован, как в примере 5.8. /g115 Метод __call__ также заимствован из примера 5.8. Для согласованности с интерфейсом Tombola он не нужен, но дополнительные методы никакого вреда не принесут. BingoCage наследует накладный метод loaded и простодушный метод inspect от Tombola . Тот и другой можно переопределить гораздо более быстрыми одно- строчными методами, как в примере 11.13. Но хочу подчеркнуть – мы можем не утруждать себя и просто унаследовать неоптимальные конкретные методы от ABC. Методы, унаследованные от Tombola , работают не так быстро, как могли бы в BingoCage , но дают правильные результаты для любого подкласса Tombola , в кото- ром корректно реализованы методы pick и load .\n--- Страница 362 ---\n362 В примере 11.13 показана совершенно другая, но тоже корректная реализация интерфейса Tombola . Вместо перетасовывания «шаров» и выталкивания последне- го класс LotteryBlower выбирает элемент в случайной позиции. Пример 11.13. lotto.py: LotteryBlower – конкретный подкласс, в котором переопределены методы inspect и loaded ABC Tombola import random from tombola import Tombolaclass LotteryBlower(Tombola): def __init__(self, iterable): self._balls = list(iterable) /g110 def load(self, iterable): self._balls.extend(iterable) def pick(self): try: position = random.randrange(len(self._balls)) /g111 except ValueError: raise LookupError('pick from empty BingoCage') return self._balls.pop(position) /g112 def loaded(self): /g113 return bool(self._balls) def inspect(self): /g114 return tuple(sorted(self._balls)) /g110 Инициализатор принимает произвольный итерируемый объект, аргумент используется для построения списка. /g111 Функция random.randrange( ) возбуждает исключение ValueError , если диапазон пуст, мы перехватываем его и возбуждаем взамен исключение LookupError , сохраняя совместимость с ABC Tombola . /g112 В противном случае из self._balls выбирается случайный элемент. /g113 Перегружаем метод loaded , чтобы не вызывать inspect (как в методе Tombola.loaded из примера 11.9). Мы можем ускорить его, работая непо- средственно с self._balls , – нет необходимости строить весь отсортиро- ванный кортеж. /g114 Перегружаем метод inspect , новый код состоит всего из одной строки. В примере 11.13 иллюстрируется достойная отдельного упоминания идиома: в методе __init__ в атрибуте self._balls сохраняется list(iterable) , а не про- сто ссылка на iterable (т.е. мы не просто присваиваем iterable атрибуту self. _balls ). Как уже отмечалось выше13, это повышает гибкость класса LotteryBlower , 13 Я приводил этот код как пример динамической типизации после вставного эссе Мартелли «Водо- плавающие птицы и ABC».Глава 11. Интерфейсы: от протоколов до абстрактных базовых\n--- Страница 363 ---\n363 Определение и использование ABC потому что аргумент iterable может быть произвольным итерируемым объектом. Однако элементы из него сохраняются во внутреннем списке, так что нам досту-пен метод pop. И даже если в аргументе iterable всегда передается список, вызов list(iterable) создает копию аргумента, и это хорошо, поскольку мы удаляем из списка элементы, а клиент может не ожидать, что переданный им список изменит-ся 14. Теперь мы подходим к важнейшей динамической особенности гусиной типиза- ции: объявлению виртуальных подклассов методом register . Виртуальный подкласс Tombola Важнейшая характеристика гусиной типизации, благодаря которой она и за- служила «водоплавающее» имя, – возможность регистрировать класс как вирту- альный подкласс ABC, даже без наследования. При этом мы обещаем, что класс честно реализует интерфейс, определенный в ABC, а Python верит нам на слово, не производя проверку. Если мы соврем, то будем наказаны исключением во время выполнения. Это делается путем вызова метода register абстрактного базового класса. В ре- зультате зарегистрированный класс становится виртуальным подклассом ABC и распознается в качестве такового функциями issubclass и isinstance , однако не наследует ни методы, ни атрибуты ABC. Виртуальный подкласс не наследует ABC, для которого зарегистрированы, и проверка согласованности с интерфейсом ABC для них не производится никогда, даже в момент создания объектов. Подкласс обязуется реализовать все методы, необходимые, чтобы не возникало ошибок во время выполнения. Метод register обычно вызывается как обычная функция (см. раздел «Ис- пользование метода register на практике» главы 11), но может использоваться и как декоратор. В примере 11.4 мы применяем синтаксис декоратора и реализуем TomboList , виртуальный подкласс Tombola , изображенный на рис. 11.5. TomboList работает в соответствии с обещанием, а доказывающие это doctest- скрипты приведены в разделе «Как тестировались подклассы T ombola» ниже. Пример 11.14. tombolist.py: TomboList – виртуальный подкласс Tombola from random import randrange from tombola import Tombola @Tombola.register # /g110 class TomboList(list): # /g111 def pick(self): if self: # /g112 position = randrange(len(self)) return self.pop(position) # /g113 else: 14 Раздел «Защитное программирование при наличии изменяемых параметров» главы 8 посвящен проблемам синонимии, которых мы здесь счастливо избежали.\n--- Страница 364 ---\n364 raise LookupError('pop from empty TomboList') load = list.extend # /g114 def loaded(self): return bool(self) # /g115 def inspect(self): return tuple(sorted(self)) # Tombola.register(TomboList) # /g116 /g110 Tombolist зарегистрирован как виртуальный подкласс Tombola . /g111 Tombolist расширяет list . /g112 Tombolist наследует от list метод __bool__ , который возвращает True , если список не пуст. /g113 Наш метод pick вызывает метод self.pop , унаследованный от list , пере- давая ему индекс случайного элемента. /g114 Tombolist.load – то же самое, что list.extend . /g115 Метод loaded делегирует работу методу bool .15 /g116 В версии Python 3.3 и более ранних использовать .register в качестве де- коратора нельзя. Необходимо пользоваться стандартным синтаксисом вы-зова. Отметим, что благодаря регистрации функции issubclass и isinstance считают, что TomboList – подкласс Tombola : >>> from tombola import Tombola>>> from tombolist import TomboList>>> issubclass(TomboList, Tombola)True>>> t = TomboList(range(100))>>> isinstance(t, Tombola)True Однако наследование управляется специальным атрибутом класса __mro__ – Method Resolution Order (порядок разрешения методов). По существу, в нем пере-числяются класс и его суперклассы в том порядке, в котором Python просматри-вает их в поисках методов. 16 Если вывести атрибут __mro__ класса TomboList , то мы увидим в нем только «настоящие» суперклассы – list и object : >>> TomboList.__mro__(<class 'tombolist.TomboList'>, <class 'list'>, <class 'object'>) 15 Прием, использованный в методе load , для loaded работать не будет, потому что в типе list не реализован метод __bool__ , который я хотел бы связать с loaded . С другой стороны, встроен- ная функция bool не нуждается в методе __bool__ , потому что может использовать также метод __len__ . См. раздел 4.1 «Проверка значения истинности» главы «Встроенные типы» ( https:// docs. python.org/3/library/stdtypes.html#truth ). 16 Ниже целый раздел «Множественное наследование и порядок разрешения методов» посвящен атрибуту класса __mro__ . А пока нам хватит и краткого объяснения.Глава 11. Интерфейсы: от протоколов до абстрактных базовых\n--- Страница 365 ---\n365 Как тестировались подклассы Tombola Рис. 11.5. UML-диаграмма классов для TomboList, настоящего подкласса list и виртуального подкласса Tombola Класса Tombola в списке TomboList.__mro__ нет, поэтому TomboList не наследует ни одного метода от Tombola . Когда я писал различные классы, реализующие один и тот же интерфейс, я хотел, чтобы их можно было протестировать одним и тем же набором doctest-скриптов. В следующем разделе показано, как я использовал API обычных классов и ABC для достижения этой цели. Как тестировались подклассы Tombola В скрипте для тестирования Tombola я воспользовался двумя атрибутами класса, предназначенными для интроспекции иерархии классов: __subclasses__() Метод возвращает список непосредственных подклассов данного класса. В этот список не входят виртуальные подклассы. _abc_registry Атрибут, имеющийся только у ABC, который связан с объектом WeakSet , со- держащим слабые ссылки на зарегистрированные виртуальные подклассы данного абстрактного класса. Для тестирования всех подклассов Tombola я написал скрипт, который обходит список, построенный на основе результатов Tombola.__subclasses__() и Tombola.\n--- Страница 366 ---\n366 _abc_registry , и связывает каждый класс с именем ConcreteTombola , используе- мым в doctest-скриптах. У спешный прогон тестового скрипта выглядит следующим образом: $ python3 tombola_runner.pyBingoCage 23 tests, 0 failed - OKLotteryBlower 23 tests, 0 failed - OKTumblingDrum 23 tests, 0 failed - OKTomboList 23 tests, 0 failed - OK Сам тестовый скрипт приведен в примере 11.15, а doctest-скрипты – в приме- ре 11.16. Пример 11.15. tombola_runner .py: исполнитель тестов для подклассов Tombola import doctest from tombola import Tombola# модули, подлежащие тестированию import bingo, lotto, tombolist, drum /g110 TEST_FILE = 'tombola_tests.rst' TEST_MSG = '{0:16} {1.attempted:2} tests, {1.failed:2} failed - {2}' def main(argv): verbose = '-v' in argv real_subclasses = Tombola.__subclasses__() /g111 virtual_subclasses = list(Tombola._abc_registry) /g112 for cls in real_subclasses + virtual_subclasses: /g113 test(cls, verbose) def test(cls, verbose=False): res = doctest.testfile( TEST_FILE, globs={'ConcreteTombola': cls}, /g114 verbose=verbose, optionflags=doctest.REPORT_ONLY_FIRST_FAILURE) tag = 'FAIL' if res.failed else 'OK' print(TEST_MSG.format(cls.__name__, res, tag)) /g115 if __name__ == '__main__': import sys main(sys.argv) /g110 Импортируем модули, содержащие настоящие и виртуальные подклассы Tombola , для тестирования. /g111 Метод __subclasses__() возвращает список непосредственных потомков, находящихся в памяти. Именно поэтому мы сначала импортировали под-Глава 11. Интерфейсы: от протоколов до абстрактных базовых\n--- Страница 367 ---\n367 Как тестировались подклассы Tombola лежащие тестированию модули, даже если в дальнейшем они ни разу не упоминаются в коде: классы необходимо загрузить в память. /g112 Строим список из _abc_registry (это объект WeakSet ), чтобы его можно было конкатенировать с результатом, возвращенным __subclasses__() . /g113 Обходим все найденные подклассы, передавая каждый функции test . /g114 Аргумент cls – подлежащий тестированию класс – связывается с именем ConcreteTombola в глобальном пространстве имен, предназначенном для за- пуска doctest-скрипта. /g115 Выводим на печать результат теста, содержащий имя класса, количество выполненных тестов, в том числе завершившихся неудачно, и метку 'OK' или 'FAIL' . Файл с doctest-скриптами приведен в примере 11.16. Пример 11.16. tombola_tests.rst: doctest-скрипты для подклассов Tombola ============== Tombola tests============== Every concrete subclass of Tombola should pass these tests. Create and load instance from iterable:: >>> balls = list(range(3)) >>> globe = ConcreteTombola(balls) >>> globe.loaded() True >>> globe.inspect() (0, 1, 2) Pick and collect balls:: >>> picks = [] >>> picks.append(globe.pick()) >>> picks.append(globe.pick()) >>> picks.append(globe.pick()) Check state and results:: >>> globe.loaded() False >>> sorted(picks) == balls True Reload:: >>> globe.load(balls)\n--- Страница 368 ---\n368 >>> globe.loaded() True >>> picks = [globe.pick() for i in balls] >>> globe.loaded() False Check that `LookupError` (or a subclass) is the exception thrown when the device is empty:: >>> globe = ConcreteTombola([]) >>> try: globe.pick() except LookupError as exc: print('OK') OK Load and pick 100 balls to verify that they all come out:: >>> balls = list(range(100)) >>> globe = ConcreteTombola(balls) >>> picks = [] >>> while globe.inspect(): picks.append(globe.pick()) >>> len(picks) == len(balls) True >>> set(picks) == set(balls) True Check that the order has changed and is not simply reversed:: >>> picks != balls True >>> picks[::-1] != balls True Примечание: для последних двух тестов существует *очень* небольшая вероятность завершения с ошибкой, даже если реализация корректна.Вероятность, что 100 шаров случайно будут извлечены в том же порядке,в каком их возвращает inspect, составляет 1/100!, т.е. приблизительно1.07e-158. Гораздо вероятнее выиграть в Lotto или программистустать миллиардером. THE END Использование метода register на практике В примере 11.14 мы использовали Tombola.register в качестве декоратора класса. В версиях, предшествующих Python 3.3, такое использование метода register за-Глава 11. Интерфейсы: от протоколов до абстрактных базовых\n--- Страница 369 ---\n369 Гуси могут вести себя как утки прещено – его следует вызывать как обычную функцию после определения класса (см. комментарий в примере 11.14). Однако несмотря на то, что теперь register можно использовать как декоратор, чаще он применяется как функция для регистрации классов, определенных где-то в другом месте. Например, в исходном коде модуля collections.abc (http://bit. ly/1QOA3Lt) встроенные типы tuple , str, range и memoryview зарегистрированы как виртуальные подклассы Sequence : Sequence.register(tuple)Sequence.register(str)Sequence.register(range)Sequence.register(memoryview) Еще несколько встроенных типов зарегистрированы как подклассы ABC, со- держащихся в файле _collections_abc.py (http://bit.ly/1QOA3Lt ). Эти регистрации производятся только при импорте указанного файла, но это нормально, потому что для получения самих ABC модуль так или иначе необходимо импортировать: чтобы написать isinstance(my_dict, MutableMapping) , необходимо иметь доступ к MutableMapping . В заключение сбросим завесу тайны с той магии ABC, о которой Алекс Мар- телли упоминал в эссе «Водоплавающие птицы и ABC». Гуси могут вести себя как утки В своем эссе «Водоплавающие птицы и ABC» Алекс Мартелли показывает, что класс может быть распознан как виртуальный подкласс ABC даже без регистра-ции. Приведем еще раз его пример, добавив проверку с использованием функции issubclass : >>> class Struggle: def __len__(self): return 23 >>> from collections import abc>>> isinstance(Struggle(), abc.Sized)True>>> issubclass(Struggle, abc.Sized)True Функция issubclass (а, значит, и isinstance ) считает класс Struggle под- классом abc.Sized , потому что abc.Sized реализует специальный метод класса __subclasshook__ (см. пример 11.17). Пример 11.17. Определение класса Sized из файла Lib/_collections_abc.py (http://bit.ly/1QOG4aP ) (Python 3.4) class Sized(metaclass=ABCMeta): __slots__ = () @abstractmethod\n--- Страница 370 ---\n370 def __len__(self): return 0 @classmethod def __subclasshook__(cls, C): if cls is Sized: if any(\"__len__\" in B.__dict__ for B in C.__mro__): # /g110 return True # /g111 return NotImplemented # /g112 /g110 Если в словаре __dict__ любого класса, перечисленного в C.__mro__ (т. е. C и его суперклассах), существует атрибут с именем __len__ … /g111 … то возвращаем True , сигнализируя о том, что C – виртуальный подкласс Sized . /g112 Иначе возвращаем NotImplemented , чтобы продолжить проверку подклас- са. Если вас интересуют детали проверки подкласса, загляните в исходный код ме- тода ABCMeta.__subclasscheck__ в файле Lib/abc.py (https://hg.python.org/cpython/ file/3.4/Lib/abc.py#l194 ). Предупреждение: в этом коде уйма if'ов и два рекурсив- ных вызова. Метод __subclasshook__ добавляет ДНК утиной типизации к тому, что предла- гает гусиная типизация. Несмотря на наличие формального определения интер-фейса в ABC и скрупулезных проверок, осуществляемых функцией isinstance , в определенных контекстах вполне можно использовать никак не связанный с ABC класс, просто потому что в нем реализован определенный метод (или потому что он постарался убедить __subclasshook__ , что за него можно поручиться). Разумеется, это работает только для тех ABC, в которых реализован метод __subclasshook__ . Следует ли реализовывать __subclasshook__ в своих собственных ABC? По- жалуй, нет. Все реализации __subclasshook__ , которые я встречал в исходном коде Python, находятся в ABC типа Sized , где объявлен только один специальный метод, и они просто проверяют имя этого метода. Учитывая «специальный» статус таких методов, можно с некоторой долей уверенности предположить, что любой метод с именем __len__ делает именно то, что вы от него ожидаете. Но, даже не выходя за пределы специальных методов и фундаментальных ABC, делать такие пред-положения рискованно. Например, все отображения реализуют методы __len__ , __getitem__ и __iter__ , но они справедливо не считаются подтипами Sequence , по- скольку не позволяют получить элемент по целочисленному смещению и не дают никаких гарантий относительно упорядочения элементов – за исключением, ко-нечно, класса OrderedDict , который сохраняет порядок вставки, но все равно не поддерживает доступ по смещению элемента. Для тех же ABC, которые могли бы написать вы или я, полагаться на метод __subclasshook__ еще более рискованно. Лично я не готов поверить, что любой класс с именем Spam , который реализует или наследует методы load , pick , inspect и loaded , гарантированно ведет себя как Tombola . Пусть уж лучше программист явно подтвердит это, сделав Spam подклассом Tombola или хотя бы зарегистриро-Глава 11. Интерфейсы: от протоколов до абстрактных базовых\n--- Страница 371 ---\n371 Резюме вав его: Tombola.register(Spam) . Конечно, ваш метод __subclasshook__ мог бы еще проверить сигнатуры методов и другие свойства, но не думаю, что оно того стоит. Резюме В этой главе мы намеревались совершить длинное путешествие: начать с динами-ческой природы неформальных интерфейсов – протоколов, посетить статические объявления интерфейсов с помощью ABC и закончить динамической стороной ABC: виртуальными подклассами и динамическим обнаружением подклассов с помощью метода __subclasshook__ . Для начала мы напомнили о традиционном понимании интерфейсов в сообще- стве Python. На протяжении большей части истории Python мы знали об интер-фейсах, но считали их неформальными понятиями, аналогичными протоколам в Smalltalk, а в официальной документации можно было встретить выражения «протокол foo», «интерфейс foo» и «объект, похожий на foo», означающие одно и то же. Интерфейсы в духе протоколов не имеют ничего общего с наследованием; каждый класс реализует протокол независимо от остальных. Так выглядят интер-фейсы в языках с динамической типпизацией. В примере 11.3 мы видели, насколько всеобъемлюща в Python поддержка про- токола последовательности. Даже если в классе реализован метод __getitem__ и ничего более, то Python все равно ухитряется обойти его, и оператор in работает. Затем мы вернулись к примеру класса FrenchDeck из главы 1 и поддержали та- сование с помощью динамического добавления метода. Тем самым мы проиллю-стрировали партизанское латание и еще раз подчеркнули динамическую природу протоколов. Также было показано, что иногда полезно реализовывать протокол лишь частично: просто добавление метода __setitem__ , определенного в прото- коле изменяемой последовательности, позволило воспользоваться функцией из стандартной библиотеки random.shuffle . Знание имеющихся протоколов позво- лило получить максимум пользы от богатейшей стандартной библиотеки Python. Затем Алекс Мартелли ввел термин «гусиная типизация»17 для описания ново- го стиля программирования на Python. Благодаря «гусиной типизации» абстракт-ные базовые классы (ABC) используются, чтобы сделать интерфейсы явными, а классы могут реализовывать интерфейсы с помощью либо наследования ABC, либо регистрации, для которой не требуется сильная статическая связь, характер-ная для наследования. На примере класса FrenchDeck2 мы отчетливо увидели плюсы и минусы яв- ных ABC. Наследование классу abc.MutableSequence заставило нас реализовать два метода, которые нам вообще-то были не нужны: insert и __delitem__ . С дру- гой стороны, даже начинающий программировать на Python, взглянув на класс FrenchDeck2 , поймет, что это изменяемая последовательность. А в качестве премии мы унаследовали 11 готовых методов от класса abc.MutableSequence (пять из них – опосредованно от abc.Sequence ). 17 Придуманное Алексом выражение «гусиная типизация» впервые публикуется на страницах этой книги!\n--- Страница 372 ---\n372 Познакомившись с общей картиной имеющихся в модуле collections.abc абстрактных базовых классов (рис. 11.3), мы написали свой ABC с нуля. Дуг Хеллманн, создатель интереснейшего сайта PyMOTW .com ( http://pymotw.com/ ) (Python Module of the W eek) так объясняет мотивацию: Определение абстрактного базового класса позволяет зафик- сировать общий API для множества подклассов. Эта возможность особенно полезна в ситуации, когда человек, слабо знакомый с ис-ходным кодом приложения, собирается написать для него подклю-чаемый модуль… 18 Желая продемонстрировать ABC Tombola в действии, мы создали три конкрет- ных подкласса: два из них наследовали Tombola , а третий был зарегистрирован в качестве виртуального подкласса. И все три прошли один и тот же набор тестов. В заключение мы упомянули, каким образом несколько встроенных типов за- регистрированы в качестве виртуальных подклассов ABC из модуля collections. abc, в результате чего вызов isinstance(memoryview, abc.Sequence) возвращает True , хотя memoryview не наследует abc.Sequence . И наконец, мы раскрыли секрет метода __subclasshook__ , который позволяет ABC распознавать незарегистри- рованный класс в качестве своего подкласса при условии, что он проходит не-которую проверку, которая может быть такой простой или сложной, как нужно разработчику, – классы из стандартной библиотеки всего лишь проверяют имена методов. Резюмируя, я хотел бы присоединиться к увещеванию Алекса Мартелли воз- держаться от создания собственных ABC за исключением разработки расширяе-мых каркасов, чем большинство из нас не занимается. В повседневной же рабо-те общение с ABC следует ограничить созданием подклассов или регистрацией классов для существующих ABC. Реже ABC могут использоваться для проверок с помощью функции isinstance . А еще реже – скорее всего, никогда – возникают ситуации, когда нужно создать ABC с нуля. После 15 лет программирования на Python первым абстрактным классом, ко- торый я написал не в педагогических целях, был класс Board (https://github.com/ garoa/pingo/blob/master/pingo/board.py ) из проекта Pingo ( http://pingo.io/ ). Драй- веры, поддерживающие различные одноплатные компьютеры и контроллеры, являются подклассами Board и, следовательно, разделяют общий интерфейс. На самом деле, хотя pingo.Board задуман и реализован как абстрактный класс, он не является подклассом abc.ABC19. Когда-нибудь я собираюсь сделать Board явным ABC, но пока в проекте есть более важные вещи. Напоследок приведу цитату, удачно завершающую эту главу. Хотя ABC упрощают проверку типов, злоупотреблять ими в программе не следует. По сути своей, Python – динамический язык, обладающий большой гибкостью. Попытка всюду навязывать огра- 18 PyMOTW , страница модуля abc , раздел «Why use Abstract Base Classes?» ( http://bit.ly/1QOGle5 ). 19 И в стандартной библиотеке Python вы встретите классы, по существу абстрактные, хотя явно ни- кто их таковыми не делал.Глава 11. Интерфейсы: от протоколов до абстрактных базовых\n--- Страница 373 ---\n373 Дополнительная литература ничения на типы приводит к тому, что код оказывается сложнее, чем необходимо. Следует радоваться гибкости Python20. – Дэвид Бизли, Брайан Джонс Python Cookbook Или, как написал технический рецензент Леонардо Рохаэль, «если вы чувству- ет искушение создать свой ABC, попробуйте сначала решить задачу с помощью обычной динамической типизации». Дополнительная литература В книге Beazley, Jones «Python Cookbook», издание 3 (O'Reilly), есть раздел, по-священный определению ABC (рецепт 8.12). Эта книга была написана до выхода версии Python 3.4, поэтому в ней используется синтаксис с именованным параме-тром metaclass , а не рекомендуемое сейчас объявление ABC с помощью наследо- вания abc .ABC. Но если не считать эту мелкую деталь, в рецепте прекрасно описаны все основные особенности ABC, а завершается он советом, процитированным в конце предыдущего раздела. В книге Дуга Хеллманна «The Python Standard Library by Example» (Addison- W esley) есть глава о модуле abc. Она опубликована также на великолепном сай- те Дуга PyMOTW – Python Module of the W eek ( http://pymotw.com/2/abc/index. html ). Оба варианта относятся к Python 2, поэтому те, кто работает с Python 3, должны будут сделать поправки. А для Python 3.4 помните, что для методов ABC рекомендуется только декоратор @abtractmethod , – остальные объявлены нереко- мендуемыми. Вторая цитата, касающаяся ABC, приведенная в резюме этой главы, взята из книги Дуга. При работе с ABC множественное наследование не только часто встречается, но и практически неизбежно, поскольку все фундаментальные ABC коллекций – Sequence , Mapping и Set – расширяют несколько ABC (см. рис. 11.3). Поэтому глава 12 станет важным дополнением к этой. В документе «PEP 3119 – Introducing Abstract Base Classes» ( https://www. python.org/dev/peps/pep-3119 ) приводится обоснование ABC, а в документе «PEP 3141 – A Type Hierarchy for Numbers» ( https://www.python.org/dev/peps/ pep-3141 ) описываются ABC из модуля numbers (https://docs.python.org/3/library/ numbers.html ).Аргументы за и против динамической типизации прозвучали в ин- тервью, данном Гвидо ван Россумом Биллу Веннерсу и опубликованном на стра-нице «Контракты в Python: беседа с Гвидо ван Россумом, часть IV» ( http://www. artima.com/intv/pycontract.html ). Пакет zope .interface (http://docs.zope.org/zope.interface/ ) предлагает способ объявить интерфейсы, проверить, реализуют ли их объекты, зарегистрировать по-ставщиков и запросить список поставщиков данного интерфейса. Этот пакет пона-чалу был частью ядра Zope 3, но может использоваться и вне Zope. Он лег в основу 20 «Python Cookbook», издание 3 (O'Reilly), рецепт 8.12 «Определение интерфейса, или абстрактного базового класса», стр. 276.\n--- Страница 374 ---\n374 гибкой компонентной архитектуры таких крупномасштабных проектов на Python, как T wisted, Pyramid и Plone. Леннарт Регебро написал прекрасное введение в zope . interface в статье «A Python Component Architecture» ( http://bit.ly/1QOHa6x ). Байжу М (Baiju M) сочинил целую книгу на эту тему: «A Comprehensive Guide to Zope Component Architecture» ( http://muthukadan.net/docs/zca.html ). Поговорим Указание типа Быть может, самой громкой новостью в мире Python в 2014 году было согласие Гвидо ван Россума дать зеленый свет реализации факуль-тативной системы статической проверки типов с помощью аннотаций функций по аналогии с тем, как это делается в языке Mypy (http://www .mypy-lang.org/). Это произошло в списке рассылки Python-ideas 15 ав-густа. Сообщение озаглавлено «Optional static typing – the crossroads» (http://bit.ly/1QOHhyX ). В следующем месяце Гвидо опубликовал пред- варительный документ «PEP 484 – Type Hints» ( https://www.python.org/ dev/peps/pep-0484/ ). Идея состояла в том, чтобы дать программисту возможность исполь- зовать факультативные аннотации для объявления типов параметров и возвращаемого значения в определении функции. Ключевое слово здесь – «факультативные». Такие аннотации добавляются, лишь если вам нужны их преимущества и вы готовы смириться с сопутствующими ограничениями. Аннотации можно включать только в некоторые функ-ции. На первый взгляд, это может показаться похожим на то, что Microsoft сделала в языке TypeScript, разработанном ей надмножестве JavaScript, только TypeScript заходит гораздо дальше: он добавляет новые язы-ковые конструкции (например, модули, классы, явные интерфейсы и т. д.), позволяет объявлять типизированные переменные и фактически компилируется в код на обычном JavaScript. На момент написания этой книги цели факультативной статической типизации в Python гораздо скромнее. Чтобы понять пределы этого предложения, процитируем историче- ское сообщение Гвидо от 15 августа 2014 года, где формулируется ос-новное положение: Я хочу сделать дополнительное предположение: основными об- ластями применения будут проверка синтаксиса, IDE и генерация документации. У всех них есть одна общая черта: программа может работать, пусть даже проверка типов не прошла. Кроме того, добав-ление типов в программу не должно негативно сказываться на ее производительности (но и позитивного эффекта ждать не стоит :-).Глава 11. Интерфейсы: от протоколов до абстрактных базовых\n--- Страница 375 ---\n375 Поговорим Таким образом, шаг оказывается не таким радикальным, как пред- ставлялось поначалу. Документ «PEP 484 – Type Hints ( https://www. python.org/dev/peps/pep-0484/ ) ссылается на «PEP 482 – Literature Overview for Type Hints» ( https://www.python.org/dev/peps/pep-0482/ ) и дает краткий обзор указаний типов в сторонних инструментах на Python и в других языках. Но – радикальный или нет – механизм указания типов уже близок, и нам от него никуда не деться: поддержка PEP 484 в форме модуля typing , вероятно, будет включена уже в версию Python 3.5. Из того, как предложение сформулировано и реализовано, понятно, что ни одна су-ществующая программа не перестанет работать из-за отсутствия указа-ния типов – или их добавления, если на то пошло. Наконец, в PEP 484 ясно сказано: Следует также подчеркнуть, что Python останется языком с ди- намической типизацией, и авторы не имеют ни малейшего желания когда-либо делать указание типов обязательным, даже в форме со-глашения. Является ли Python слабо типизированным языком? Дебаты вокруг вариантов типизации в языках иногда приводят к недоразумениям из-за отсутствия единой терминологии. Некоторые авторы (например, Билл Веннерс в интервью с Гвидо ван Россумом) говорят, что в Python реализована слабая типизация, что ставит его в один ряд с JavaScript и PHP . Но, говоря о вариантах типизации, лучше выделить две независимые оси. Строгая и слабая типизация Если в языке редко производятся неявные преобразования типов, то он считается строго типизированным; если часто, то слабо ти-пизированным. Java, C++ и Python в этом смысле строго типизи-рованные языки, а PHP , JavaScript и Perl – слабо типизирован-ные. Статическая и динамическая типизация Если проверка типов производится на этапе компиляции, то язык считается статически типизированным, если во время выполне-ния – то динамически типизированным. Для статической типи-зации необходимы объявления типов (в некоторых современных языков этого можно избежать благодаря механизму выведения типов). Fortran и Lisp – два старейших языка программирования, которые живы и поныне, являются соответственно статически и динамически типизированными.\n--- Страница 376 ---\n376 Строгая типизация позволяет обнаруживать ошибки на ранних ста- диях. Вот несколько примеров, показывающих, почему слабая типиза- ция – это плохо21: // это код на JavaScript (протестировано в Node .js v0.10.33) '' == '0' // false0 == '' // true0 == '0' // true'' < 0 // false'' < '0' // true В Python не производится автоматическое преобразование типов между строками и числами, поэтому все сравнения с == выше дают False , так что сохраняется транзитивность оператора ==, а сравнения с < в Python 3 приводят к исключению TypeError . Статическая типизация упрощает инструментальным средствам (компиляторам, IDE) анализ кода с целью обнаружения ошибок и от-крывает возможность для предоставления других сервисов (оптими-зация, рефакторинг и т. д.). Динамическая типизация способствует повторному использованию, уменьшению объема кода и позволяет естественно развивать интерфейсы в виде протоколов, а не фиксировать их на ранних этапах разработки. Короче говоря, Python – это строго типизированный язык с дина- мической типизацией. Документ «PEP 484 – Type Hints» ( https://www. python.org/dev/peps/pep-0484/ ) в этом смысле ничего не меняет, но по- зволяет авторам API добавлять факультативные аннотации типа, чтобы инструменты могли выполнить хоть какую-то статическую проверку типов. Партизанское латание У партизанского латания плохая репутация. Если им злоупотреблять, то можно получить систему, трудную для понимания и сопровождения. Заплата обычно тесно сцеплена с конечным объектом, что делает его хрупким. Другая проблема состоит в том, что в случае партизанского латания двух библиотек возможны конфликты, в результате которых библиотека, загруженная второй, затрет заплаты, внесенные первой. Но партизанское латание может также принести пользу, например, чтобы добавить в класс реализацию протокола на этапе выполнения. Паттерн проектирования Адаптер решает ту же проблему путем реализации но-вого класса. Код на Python легко поддается партизанскому латанию с некоторы- ми ограничениями. В отличие от Ruby и JavaScript, Python не позволяет 21 Заимствовано из книги Douglas Crockford «JavaScript: The Good Parts» (O'Reilly), при- ложение B, стр. 109.Глава 11. Интерфейсы: от протоколов до абстрактных базовых\n--- Страница 377 ---\n377 Поговорим латать встроенные типы. Лично я считаю это плюсом, так как есть уве- ренность, что объект str всегда будет иметь один и тот же набор мето- дов. Это ограничение снижает шансы на то, что внешние библиотеки попытаются применить конфликтующие заплаты. Интерфейсы в Java, Go и Ruby Во времена C++ 2.0 (1989) абстрактные классы использовались для описания интерфейсов в этом языке. Проектировщики Java реши-ли запретить множественное наследование классов, лишив тем самым абстрактные классы возможности специфицировать интерфейсы, по- ые классы возможности специфицировать интерфейсы, по- скольку зачастую класс должен реализовывать несколько интерфейсов. Зато они добавили в язык конструкцию interface и разрешили классу реализовывать более одного интерфейса – некоторый вид множествен-ного наследования. Более явное выделение интерфейсов можно отнести к значительным заслугам Java. В Java 8 разрешено включать реализа-ции методов в интерфейс, это называется «методами по умолчанию» (https://docs.oracle.com/javase/tutorial/java/IandI/defaultmethods.html ). С таким дополнением интерфейсы Java стали ближе к абстрактным классам в C++ и Python. В языке Go принят совершенно другой подход. Прежде всего, в Go нет наследования. Определять интерфейсы можно, но нет нужды (а фактически и возможности) явно говорить, что некий тип реализует интерфейс. Компилятор определяет это автоматически. Таким образом, механизм, реализованный в Go, можно было бы назвать «статической динамической типизацией» в том смысле, что интерфейсы проверяются на этапе компиляции, но значение имеет лишь то, что именно реализует каждый тип. Если бы Python был устроен как Go, то в каждом ABC был бы реали- зован метод __subclasshook__ , проверяющий имена и сигнатуры функ- ций, а мы никогда не наследовали бы ABC и не регистрировали вирту-альные подклассы. Если бы мы хотели, чтобы Python больше походил на Go, то должны были бы проверять типы всех аргументов функции. Отчасти такая инфраструктура имеется (вспомните раздел «Аннотации функций» на стр. 186). Гвидо уже говорил, что считает нормальным ис-пользовать такие аннотации для проверки типов – по крайней мере, во вспомогательных инструментальных средствах. Дополнительные сооб-ражения на эту тему см. на врезке «Поговорим» в главе 5. Рубисты твердо верят в динамическую типизацию, и в Ruby нет никакого формального способа объявить интерфейс или абстрактный класс, кроме того, что существовал в Python до версии 2.6: возбудить исключение NotImplementedError в теле метода, чтобы сделать его аб- страктным и заставить пользователя создать подкласс, в котором метод будет реализован.\n--- Страница 378 ---\n378 А тем временем я читал, что Юкихиро «Мац» Мацумото, создатель Ruby, в сентябре 2014 года высказался в том смысле, что статическая типизация может появиться в будущих версиях языка. Это случилось на конференции Ruby Kaigi в Японии, одной из самых значимых еже-годных конференций по Ruby. Я пока не видел записи его выступления, но Годфри Чан написал об этом в своем блоге: «Ruby Kaigi 2014: день 2» (http://brewhouse.io/blog/2014/09/19/ruby-kaigi-2014-day-2 ). Из отчета Чана следует, что Мац думает в направлении аннотаций функций. Упо-минались даже аннотации функций в Python. Интересно, удастся ли сделать аннотации функций без ABC доста- точно хорошим механизмом структуризации системы типов без потери гибкости. Так что может статься, что формальные интерфейсы – это и будущее Ruby. Я полагаю, что ABC в Python, с функцией register и методом __subclasshook__ , привнесли формальные интерфейсы в язык, не жерт- вуя преимуществами динамической типизации. Быть может, гуси и утки смогут уравновесить друг друга. Метафоры и идиомы в интерфейсах Метафора способствует пониманию, делая ясными ограничения. В этом ценность слов «стек» 22 и «очередь» в описании соответствую- щих фундаментальных структур данных: благодаря им понятно, как до-бавляются и удаляются элементы. С другой стороны, Алан Купер (Alan Cooper) в книге «About Face», издание 4 (Wiley), пишет: Строгая приверженность метафорам слишком тесно – без вся- кой на то необходимости – связывает интерфейсы с явлениями ма-териального мира. Он имел в виду пользовательские интерфейсы, но совет в равной мере относится и к API. Но Купер благосклонно относится к «действи-тельно подходящим» метафорам, «будто упавшим с небес» и не воз-ражает против их использования (он пишет «будто упавшим с небес», потому что найти хорошую метафору настолько трудно, что не стоит тратить время на их целенаправленный поиск). Мне кажется, что образ машины для игры в бинго, который я использовал в этой главе, удачен, и я остался верен ему. «About Face» – пожалуй, лучшая из прочитанных мной книг о поль- зовательском интерфейсе, – а я прочел не только ее. И одна из самых 22 Слово «stack» (букв. стопка) на заре развития программирования в СССР переводили как «магазин» (термин до сих пор сохранился в теории автоматов), и это была очевидная ме-тафора автоматного рожка. Жаль, что теперь его переводят бесцветной калькой «стек». – Прим. перев.Глава 11. Интерфейсы: от протоколов до абстрактных базовых\n--- Страница 379 ---\n379 Поговорим ценных мыслей, почерпнутых мной у Купера, – расширение использо- вания метафор за пределы парадигмы дизайна и замена их фразой «иди-оматические интерфейсы». Как я уже сказал, Купер говорит не об API, но чем дольше я размышляю о его идеях, тем больше мне кажется, что они применимы и к Python. Фундаментальные протоколы языка – это то, что Купер называет «идиомами». Однажды поняв, что такое «после-довательность», мы можем применять это знание в разных контекстах. Это и есть главная тема моей книги: выявление фундаментальных иди-ом языка, что позволяет сделать код кратким, эффективным и удобочи-таемым – для мастера-питониста.",
      "debug": {
        "start_page": 338,
        "end_page": 379
      }
    },
    {
      "name": "Глава 12. Наследование: хорошо или плохо 380",
      "content": "--- Страница 380 --- (продолжение)\nГЛАВА 12. Наследование: хорошо или плохо Мы начали продвигать идею наследования, чтобы начинающие про-граммисты могли пользоваться каркасами, спроектировать которые под силам только опытным специалистам 1. – Алан Кэй, The Early History of Smalltalk Эта глава посвящена наследованию и подклассам с упором на две детали, специфичные для Python: • проблемы наследования встроенным типам; • множественное наследование и порядок разрешения методов. Многие считают, что множественное наследование порождает больше про- блем, чем решает. Его отсутствие точно не повредило Java; пожалуй, оно даже по-служило дополнительным стимулом широкого внедрения языка после печально-го опыта злоупотребления множественным наследованием в C++. Однако оглушительный успех и влиятельность Java означает также, что многие программисты, переходящие на Python с этого языка, никогда не встречались с множественным наследованием на практике. Поэтому, помимо игрушечных при-меров, наш рассказ об этом механизме иллюстрируется двумя значительными проектами на Python: библиотека пользовательского интерфейса Tkinter и веб-каркас Django. Мы начнем с вопроса о наследовании встроенным типам. А затем рассмотрим примеры использования множественного наследования и обсудим хорошие и плохие методики построения иерархий классов. Сложности наследования встроенным типам До версии Python 2.2 создать подкласс встроенного типа, например list или dict , было невозможно. Позже такая возможность появилась, но с существенной ого- 1 Alan Kay «The Early History of Smalltalk», опубликовано в SIGPLAN Not. 28, 3 (март, 1993), 69–95. Имеется также в сети ( http://propella.sakura.ne.jp/earlyHistoryST/EarlyHistoryST.html ). Спасибо мое- му другу Кристиано Андерсону, который прислал эту ссылку, когда я работал над этой главой.\nГЛАВА 12. Наследование: хорошо или плохо Мы начали продвигать идею наследования, чтобы начинающие про-граммисты могли пользоваться каркасами, спроектировать которые под силам только опытным специалистам 1. – Алан Кэй, The Early History of Smalltalk Эта глава посвящена наследованию и подклассам с упором на две детали, специфичные для Python: • проблемы наследования встроенным типам; • множественное наследование и порядок разрешения методов. Многие считают, что множественное наследование порождает больше про- блем, чем решает. Его отсутствие точно не повредило Java; пожалуй, оно даже по-служило дополнительным стимулом широкого внедрения языка после печально-го опыта злоупотребления множественным наследованием в C++. Однако оглушительный успех и влиятельность Java означает также, что многие программисты, переходящие на Python с этого языка, никогда не встречались с множественным наследованием на практике. Поэтому, помимо игрушечных при-меров, наш рассказ об этом механизме иллюстрируется двумя значительными проектами на Python: библиотека пользовательского интерфейса Tkinter и веб-каркас Django. Мы начнем с вопроса о наследовании встроенным типам. А затем рассмотрим примеры использования множественного наследования и обсудим хорошие и плохие методики построения иерархий классов. Сложности наследования встроенным типам До версии Python 2.2 создать подкласс встроенного типа, например list или dict , было невозможно. Позже такая возможность появилась, но с существенной ого- 1 Alan Kay «The Early History of Smalltalk», опубликовано в SIGPLAN Not. 28, 3 (март, 1993), 69–95. Имеется также в сети ( http://propella.sakura.ne.jp/earlyHistoryST/EarlyHistoryST.html ). Спасибо мое- му другу Кристиано Андерсону, который прислал эту ссылку, когда я работал над этой главой.\n--- Страница 381 ---\n381 Сложности наследования встроенным типам воркой: код встроенного типа (написанный на C) не вызывает специальные мето- ды, переопределенные в пользовательских классах. Суть проблемы хорошо описано в документации по интерпретатору PyPy , в главе «Различия между PyPy и CPython», раздел «Подклассы встроенных типов» (http://bit.ly/1JHNmhX ): Официально в CPython нет никаких правил, определяющих, когда переопределенный в подклассе метод встроенного типа вы-зывается и вызывается ли он вообще. В качестве приближения к истине можно считать, что такие методы никогда не вызываются другими встроенными методами того же объекта. Например, метод __getitem__() , переопределенный в подклассе dict , не будет вызы- ваться из встроенного метода get() . Проблема иллюстрируется в примере 12.1. Пример 12.1. Наш метод __setitem__ игнорируется методами __init__ и __update__ встроенного типа dict >>> class DoppelDict(dict): def __setitem__(self, key, value): super().__setitem__(key, [value] * 2) # /g110 >>> dd = DoppelDict(one=1) # /g111 >>> dd{'one': 1}>>> dd['two'] = 2 # /g112 >>> dd{'one': 1, 'two': [2, 2]}>>> dd.update(three=3) # /g113 >>> dd{'three': 3, 'one': 1, 'two': [2, 2]} /g110 Метод DoppelDict.__setitem__ повторяет значение при сохранении (только для того, чтобы его эффект был наглядно виден). Свою работу он делегиру-ет методу суперкласса. /g111 Метод __init__ , унаследованный от dict , очевидно, не знает, что __setitem__ переопределен: значение 'one' не повторено. /g112 Оператор [] вызывает наш метод __setitem__ и работает, как и ожидалось: 'two' отображается на повторенное значение [2, 2] . /g113 Метод update класса dict также не пользуется нашей версией __setitem__ : значение 'three' не повторено. Поведение встроенных типов находится в явном противоречии с основным правилом объектно-ориентированного программирования: поиск методов всегда должен начинаться с класса самого объекта ( self ), даже если он вызывается из метода, реализованного в суперклассе. При столь печальном положении дел метод __missing__ – о котором мы говорили в разделе «Метод __missing__ » главы 2 –\n--- Страница 382 ---\n382 Глава 12. Наследование: хорошо или плохо работает в соответствии с документацией только потому, что рассматривается как особый случай. Проблема не ограничивается вызовами изнутри объекта – когда self.get() вы- зывает self.__getitem__() – но возникает и для переопределенных методов дру- гих классов, которые должны вызываться из встроенных методов. Пример 12.2 основан на примере из документации по PyPy ( http://bit.ly/1JHNmhX ). Пример 12.2. Метод __getitem__ из класса AnswerDict игнорируется методом dict.update >>> class AnswerDict(dict): def __getitem__(self, key): # /g110 return 42 >>> ad = AnswerDict(a='foo') # /g111 >>> ad['a'] # /g112 42>>> d = {}>>> d.update(ad) # /g113 >>> d['a'] # /g114 'foo'>>> d{'a': 'foo'} /g110 Метод AnswerDict.__getitem__ для любого ключа возвращает 42. /g111 ad – экземпляр AnswerDict , инициализированный парой ('a', 'foo') . /g112 ad['a'] возвращает 42, как и ожидалось. /g113 d – экземпляр класса dict , обновленный объектом ad. /g114 Метод dict.update игнорирует наш метод AnswerDict.__getitem__ . Прямое наследование таким встроенным типам, как dict , list или str, чревато ошибками, потому что встроенные методы, как правило, игнорируют написанные пользователем переопреде-ленные методы. Вместо создания подклассов встроенных объ-ектов наследуйте свои классы от классов в модуле collections (http://docs.python.org/3/library/collections.html ) – UserDict , UserList и UserString , которые специально предназначены для беспроблемного наследования. Если наследовать подклассу collections.UserDict , а не dict , то проблемы, продемонстрированные в примерах 12.1 и 12.2, исчезают. Пример 12.3. Классы DoppelDict2 и AnswerDict2 работают , как и ожидалось, потому что расширяют UserDict , а не dict >>> import collections >>>\n--- Страница 383 ---\n383 Сложности наследования встроенным типам >>> class DoppelDict2(collections.UserDict): def __setitem__(self, key, value): super().__setitem__(key, [value] * 2) >>> dd = DoppelDict2(one=1)>>> dd{'one': [1, 1]}>>> dd['two'] = 2>>> dd{'two': [2, 2], 'one': [1, 1]}>>> dd.update(three=3)>>> dd{'two': [2, 2], 'three': [3, 3], 'one': [1, 1]}>>>>>> class AnswerDict2(collections.UserDict): def __getitem__(self, key): return 42 >>> ad = AnswerDict2(a='foo')>>> ad['a']42>>> d = {}>>> d.update(ad)>>> d['a']42>>> d{'a': 42} Для оценки дополнительных усилий на создание подкласса встроенного типа я переписал класс StrKeyDict из примера 3.8. Первоначальная версия наследова- ла классу collections.UserDict и реализовывала всего три метода: __missing__ , __contains__ и __setitem__ . Экспериментальная версия StrKeyDict наследует dict непосредственно и реализует те же три метода с косметическими изменениями, вызванными способом хранения данных. Но чтобы проходили те же тесты, что и раньше, мне пришлось реализовать методы __init__ , get и update , потому что их версии, унаследованные от dict , отказывались признавать переопределенные ме- тоды __missing__ , __contains__ и __setitem__ . В подклассе UserDict из примера 3.8 было 16 строк, а в экспериментальном подклассе dict – целых 37 строк2. Подведем итоги: описанная в этом разделе проблема относится только к деле- гированию методов встроенных типов, написанных на языке C, и только к поль-зовательским подклассам этих типов. Если наследовать классу, написанному на Python, например UserDict или MutableMapping , то эта проблема не возникает3. Еще один вопрос, связанный с наследованием и, в особенности, с множествен- ным наследованием, таков: как Python решает, какой атрибут использовать, если в суперклассах из параллельных ветвей графа наследования определены одноимен-ные атрибуты? Ответ приводится ниже. 2 Для любознательных читателей – экспериментальная версия находится в файле strkeydict_dictsub. py в репозитории кода к этой книге по адресу https://github.com/fluentpython/example-code . 3 Кстати говоря, в этом отношении PyPy ведет себя «корректнее», чем CPython, но ценой незначи- тельной несовместимости. См. раздел «Различия между PyPy и CPython» ( http://bit.ly/1JHNmhX ).\n--- Страница 384 ---\n384 Глава 12. Наследование: хорошо или плохо Множественное наследование и порядок разрешения методов Любой язык с множественным наследованием должен как-то разрешать конфлик- ты имен в случае, когда в не связанных между собой родительских классах имеют-ся методы с одним и тем же именем. Эта «проблема ромбовидного наследования» иллюстрируется на рис. 12.1 и в примере 12.4. Рис. 12.1. Слева : UML-диаграмма классов, иллюстрирующая «проблему ромбовидного наследования». Справа : пунктирными стрелками показан порядок разрешения методов (method resolution order – MRO) в Python для примера 12.4 Пример 12.4. diamond.py: классы A, B, C и D образуют граф, показанный на рис. 12.1 class A: def ping(self): print('ping:', self) class B(A): def pong(self): print('pong:', self) class C(A): def pong(self): print('PONG:', self) class D(B, C): def ping(self): super().ping() print('post-ping:', self) def pingpong(self):\n--- Страница 385 ---\n385 Множественное наследование и порядок разрешения методов self.ping() super().ping() self.pong() super().pong() C .pong(self) Отметим, что оба класса B и C реализуют метод pong . Единственное различие за- ключается в том, что C.pong выводит слово PONG , написанное заглавными буквами. Если вызвать метод d.pong() от имени экземпляра D, то какой метод pong вы- полнится? В C++ программист должен явно квалифицировать вызовы методов именами классов для разрешения неоднозначности. В Python это тоже возможно. Пример 12.5. Два способа вызвать метод pong от имени экземпляра класса D >>> from diamond import * >>> d = D()>>> d.pong() # /g110 pong: <diamond.D object at 0x10066c278>>>> C.pong(d) # /g111 PONG: <diamond.D object at 0x10066c278> /g110 Если просто вызвать d.pong() , то выполнится метод из класса B. /g111 Но всегда можно вызвать метод от имени самого суперкласса, передав эк- земпляр в качестве явного аргумента. Неоднозначность вызовов вида d.pong() разрешается, потому что Python обхо- дит граф наследования в определенном порядке. Этот порядок называется MRO: порядок разрешения методов. В каждом классе есть атрибут __mro__ , в котором хранится кортеж ссылок на суперклассы в порядке MRO, начиная от текущего класса и вверх по иерархии до класса object . Для класса D атрибут __mro__ выгля- дит так (см. рис. 12.1): >>> D.__mro__(<class 'diamond.D'>, <class 'diamond.B'>, <class 'diamond.C'>,<class 'diamond.A'>, <class 'object'>) Рекомендуемый способ делегировать вызовы методов суперклассам – вос- пользоваться встроенной функцией super() , которая в Python 3 стала проще4, как показывает метод pingpong из класса D в примере 12.4. Однако можно также – и иногда это удобно – игнорировать MRO и вызвать метод суперкласса напрямую. Например, метод D.ping можно было бы написать и так: def ping(self): A.ping(self) # вместо super().ping() print('post-ping:', self) Отметим, что при вызове метода экземпляра от имени класса аргумент self необходимо передавать явно, потому что вы обращаетесь к несвязанному методу . 4 В Python 2 первую строчку метода D.pingpong следовало бы записать в виде super(D, self). ping() , а не super().ping() .\n--- Страница 386 ---\n386 Глава 12. Наследование: хорошо или плохо Однако безопаснее и в большей степени совместимо с будущими версиями поль- зоваться функцией super() , особенно при вызове методов каркаса или любой не контролируемой вами иерархии классов. В примере 12.6 показано, что функция super() следует порядку MRO при вызове метода. Пример 12.6. Использование super() для вызова ping (для примера 12.4) >>> from diamond import D >>> d = D()>>> d.ping() # /g110 ping: <diamond.D object at 0x10cc40630> # /g111 post-ping: <diamond.D object at 0x10cc40630> # /g112 /g110 Метод ping из D делает два вызова /g111 Первый вызов – super().ping() ; super делегирует вызов ping классу A; A.ping выводит эту строку. /g112 Второй вызов – print('post-ping:', self) , он выводит эту строку. Теперь посмотрим, что происходит, когда pingpong вызывается от имени экзем- пляра класса D. Пример 12.7. Пять вызовов, выполненных методом pingpong (для примера 12.4) >>> from diamond import D >>> d = D()>>> d.pingpong()>>> d.pingpong()ping: <diamond.D object at 0x10bf235c0> # /g110 post-ping: <diamond.D object at 0x10bf235c0>ping: <diamond.D object at 0x10bf235c0> # /g111 pong: <diamond.D object at 0x10bf235c0> # /g112 pong: <diamond.D object at 0x10bf235c0> # /g113 PONG: <diamond.D object at 0x10bf235c0> # /g114 /g110 Вызов 1 – self.ping() , выполняется метод ping класса D, который выводит эту и следующую строку. /g111 Вызов 2 – super.ping() , пропускает ping из D и находит метод ping в A. /g112 Вызов 3 – self.pong() , находит в B реализацию pong в соответствии с __mro__ . /g113 Вызов 4 – super.pong() , находит ту же самую реализацию B.pong , также сле- дуя __mro__ . /g114 Вызов 5 – C.pong(self) , находит реализацию C.pong , игнорируя __mro__ . Порядок MRO принимает в расчет не только граф наследования, но также по- рядок, в котором перечислены суперклассы в объявлении подкласса. Иными сло-вами, если бы в файле diamond.py (пример 12.4) класс D был объявлен как class D(C, B): , то __mro__ класса D был бы другим: поиск производился бы сначала в классе C, а потом в B.\n--- Страница 387 ---\n387 Множественное наследование и порядок разрешения методов При изучении класса я часто просматриваю его __mro__ в интерактивной обо- лочке. Ниже приведено несколько примеров для хорошо знакомых классов. Пример 12.8. Инспектирование класса __mro__ в нескольких классах >>> bool.__mro__ /g110 (<class 'bool'>, <class 'int'>, <class 'object'>)>>> def print_mro(cls): /g111 print(', '.join(c.__name__ for c in cls.__mro__)) >>> print_mro(bool)bool, int, object>>> from frenchdeck2 import FrenchDeck2>>> print_mro(FrenchDeck2) /g112 FrenchDeck2, MutableSequence, Sequence, Sized, Iterable, Container, object>>> import numbers>>> print_mro(numbers.Integral) /g113 Integral, Rational, Real, Complex, Number, object>>> import io /g114 >>> print_mro(io.BytesIO)BytesIO, _BufferedIOBase, _IOBase, object>>> print_mro(io.TextIOWrapper)TextIOWrapper, _TextIOBase, _IOBase, object /g110 bool наследует методы и атрибуты int и object . /g111 print_mro выводит более компактное представление MRO. /g112 В состав предков FrenchDeck2 входят несколько ABC из модуля collec- tions.abc . /g113 Это числовые ABC из модуля numbers . /g114 Модуль io включает ABC (с суффиксом …Base ) и конкретные классы, на- пример BytesIO и TextIOWrapper , определяющие тип объекта двоичного или текстового файла, который метод open() возвращает в зависимости от аргу- мента mode . При вычислении MRO применяется алгоритм C3. Он описан в канониче- ской статье Мишеля Симионато «The Python 2.3 Method Resolution Order» (http://bit.ly/1OwVqBd ). Для тех, кого интересуют тонкости MRO, в разде- ле «Дополнительная литература» имеются еще ссылки. Но не нужно осо-бенно «заморачиваться» по этому поводу, алгоритм ведет себя вполне разумно; как пишет Симионато: […] если вы не злоупотребляете множественным наследо- ванием и не работаете с особо сложными иерархиями, то по-нимать алгоритм C3 необязательно, и вы можете спокойно не читать статью. Чтобы подвести итоги обсуждению MRO, я на рис. 12.2 изобразил часть слож- ного графа множественного наследования пакета Tkinter для построения пользо-вательских интерфейсов из стандартной библиотеки Python. Изучая этот рисунок,\n--- Страница 388 ---\n388 Глава 12. Наследование: хорошо или плохо начните с класса Text внизу. Класс Text реализует многострочный редактируемый текстовый виджет. Он обладает богатой функциональностью сам по себе, но еще и наследует многочисленные методы от других классов. В левой части рисунка по-казана обычная UML-диаграмма классов. А справа она дополнена стрелками, по-казывающими порядок MRO, полученный с помощью вспомогательной функции print_mro из примера 12.8: >>> import tkinter>>> print_mro(tkinter.Text)Text, Widget, BaseWidget, Misc, Pack, Place, Grid, XView, YView, object Рис. 12.2. Слева: UML-диаграмма класса виджета Text из пакета Tkinter и его суперклассов. Справа: пунктирными стрелками обозначен Text.mro В следующем разделе мы обсудим аргументы за и против множественного на- следования и приведем примеры из реальных каркасов. Множественное наследование в реальном мире Вполне возможно применить множественное наследование с пользой. В паттерне Адаптер из книги «Паттерны проектирования« множественное наследование ис-пользуется, так что не скажешь, что оно совсем уж никуда не годится (остальные 22 паттерна, правда, обошлись одиночным наследованием, т. е. множественное на-следование, очевидно, не панацея). В стандартной библиотеке Python множественное наследование особенно хо- рошо заметно в пакете collections.abc . И тут нет никакого противоречия: в конце концов, даже в Java поддерживается множественное наследование интерфейсов,\n--- Страница 389 ---\n389 Множественное наследование в реальном мире а ABC – это объявление интерфейса, которое может содержать реализации кон- кретных методов5. Экстремальный пример множественного наследования в стандартной библи- отеке дает пакет построения графических интерфейсов Tkinter (модуль tkinter : интерфейс из Python к T cl/Tk, https://docs.python.org/3/library/tkinter.html ). Я уже использовал иерархию одного виджета Tkinter для иллюстрации MRO на рис. 12.2, а на рис. 12.3 показаны все классы виджетов, присутствующие в базовом пакете tkinter (кроме них, есть еще много виджетов в подпакете tkinter .ttk – https:// docs.python.org/3/library/tkinter.ttk.html ). Рис. 12.3. Сводная UML-диаграмма иерархии классов Tkinter; классы, помеченные стереотипом «mixin», предназначены для представления конкретных методов другим классам посредством множественного наследования Когда я пишу эти строки, пакету Tkinter уже исполнилось 20 лет, и его нельзя считать примером лучших современных методик. Однако он показывает, как множественное наследование использовалось, когда кодировщики не придавали большого значения его недостаткам. И он послужит контрпримером, когда в следующем разделе мы будем обсуждать рекомендуемые подходы. Рассмотрим классы, показанные на рис. 12.3. 5 Выше уже упоминалось, что в Java 8 интерфейсам тоже разрешено предоставлять реализации мето- дов. Эта новая возможность в официальном «Учебнике Java» называется «методы по умолчанию» (http://bit.ly/1JHPsyk ).\n--- Страница 390 ---\n390 Глава 12. Наследование: хорошо или плохо /g110 Toplevel : класс окна верхнего уровня в приложении Tkinter. /g111 Widget : суперкласс всех видимых объектов, которые можно разместить в окне. /g112 Button : обычная кнопка. /g113 Entry : однострочное редактируемое текстовое поле. /g114 Text : многострочное редактируемое текстовое поле Вот как выглядят MRO этих классов, напечатанные функцией print_mro из примера 12.8: >>> import tkinter>>> print_mro(tkinter.Toplevel)Toplevel, BaseWidget, Misc, Wm, object>>> print_mro(tkinter.Widget)Widget, BaseWidget, Misc, Pack, Place, Grid, object>>> print_mro(tkinter.Button)Button, Widget, BaseWidget, Misc, Pack, Place, Grid, object>>> print_mro(tkinter.Entry)Entry, Widget, BaseWidget, Misc, Pack, Place, Grid, XView, object>>> print_mro(tkinter.Text)Text, Widget, BaseWidget, Misc, Pack, Place, Grid, XView, YView, object Стоит обратить внимание на то, как эти классы связаны друг с другом. • Toplevel – единственный графический класс, не наследующий Widget , по- тому что это окно верхнего уровня, и оно не ведет себя, как виджет, – напри-мер, его нельзя присоединить к окну или фрейму. Toplevel наследует клас- су Wm, который предоставляет функции прямого доступа к объемлющему оконному менеджеру, например, для установки заголовка окна и настройке его рамки. • Widget наследует непосредственно BaseWidget , а также классам Pack , Place и Grid . Последние три класса – менеджеры компоновки, они отвечают за расположение виджетов в окне или фрейме. Каждый инкапсулирует свою стратегию и API размещения виджетов. • Button , как и большинство виджетов, напрямую наследует только Widget , а опосредованно – классу Misc , который предоставляет десятки методов каж- дому виджету. • Entry является подклассом Widget и XView – класса, который реализует го- ризонтальную прокрутку. • Text наследует Widget , XView и YView – классу, реализующему вертикальную прокрутку. Далее мы обсудим некоторые рекомендации по использованию множественного наследования и посмотрим, согласуется ли с ними Tkinter.\n--- Страница 391 ---\n391 Жизнь с множественным наследованием Жизнь с множественным наследованием […] нам нужна была (и до сих пор нужна) более качественная теория о на- следовании вообще. Например, наследование и подгрузка (instancing) (тоже разновидность наследования) мешают в одну кучу прагматику (например, разнесение кода для экономии памяти) и семантику (используемую для слишком многих задач, как то: специализация, обобщение, видообразование и т. д.). – Алан Кэй The Early History of Smalltalk Как писал Алан Кэй, наследование используется по разным причинам, а мно- жественное наследование расширяет спектр возможностей и увеличивает слож-ность. Применяя множественное наследование, легко получить запутанный и хрупкий дизайн. Ввиду отсутствия исчерпывающей теории приведем несколько советов, как избежать графов классов, напоминающих блюдо спагетти. 1. Отличайте наследование интерфейса от наследования реализации Имея дело с множественным наследованием, полезно ясно определить, по ка- ким причинам вообще создается подкласс. Основные причины таковы: • наследование интерфейса создает подтип, подразумевая связь «является»; • наследование реализации позволяет избежать дублирования кода. На практике обе причины часто идут рука об руку, но если удается прояснить намерение, сделайте это. Наследование ради повторного использования кода – это деталь реализации, его нередко можно заменить композицией и делегированием. С другой стороны, наследование интерфейса – это становой хребет любого кар-каса. 2. Определяйте интерфейсы явно с помощью ABC В современном Python класс, предназначенный для определения интерфейса, следует явно делать абстрактным базовым классом. В версиях Python /g116 3.4 это означает подкласс abc.ABC или другого ABC (если нужно поддержать более ранние версии, см. раздел «Синтаксические детали ABC» главы 11). 3. Используйте примеси для повторного использования кода Если класс предназначен для того, чтобы предоставлять реализации методов различным не связанным между собой подклассам, не подразумевая связи «яв-ляется», то его следует явно делать классом-примесью . Концептуально примесь\n--- Страница 392 ---\n392 Глава 12. Наследование: хорошо или плохо не определяет нового типа, а просто служит контейнером общеполезных методов. Примесь никогда не инстанцируется, и конкретные классы не должны ей наследо-вать. Каждая примесь должна определять четко очерченное поведение, реализуя несколько очень тесно связанных методов. 4. Явно выделяйте примеси с помощью именования В Python нет формального способа сказать, что класс является примесью, поэтому рекомендуется включать в имя такого класса суффикс …Mixin . Tkinter не следует этому совету, а если бы следовал, то XView назывался бы XViewMixin , Pack – PackMixin и так для всех классов, которые я пометил стереотипом «mixin» на рис. 12.3. 5. ABC также может быть примесью; обратное неверно Поскольку ABC может содержать конкретные методы, он способен выступать в роли примеси. Но ABC также определяет тип, примесь – нет. И ABC может быть единственным базовым классом другого класса, а подклассом одной лишь приме-си может быть разве что другая, более специализированная, примесь – в реальных программах такое встречается нечасто. На ABC налагается одно ограничение, не относящееся к примесям: конкретные методы, реализованные в ABC, могут взаимодействовать только с методами, опре-деленными в том же ABC или его суперклассах. Отсюда следует, что конкретные методы в ABC всегда служат лишь для удобства, так как все, что они делают, поль-зователь класса может сделать, вызывая другие методы ABC. 6. Не наследуйте сразу нескольким конкретным классам У конкретных классов должно быть не более одного конкретного суперкласса6. Другими словами, все суперклассы конкретного класса, кроме разве что одного, должны быть либо ABC, либо примесями. Так в следующем фрагменте, если Al- pha – конкретный класс, то Beta и Gamma должны быть ABC или примесями: class MyConcreteClass(Alpha, Beta, Gamma): \"\"\"Это конкретный класс: его можно инстанцировать.\"\"\" # какой-то код 7. Предоставляйте пользователям агрегатные классы Если какая-то комбинация ABC или примесей может быть особенно полезна в клиентском коде, предоставьте класс, который объединяет их разумным образом. Грейди Буч называет такие классы агрегатными 7. 6 Во вставном эссе «Водоплавающие птицы и ABC» на стр. 345 Алекс Мартелли приводит цитату из книги Скотта Мейерса «Более эффективное использование C++», в которой высказано еще бо-лее радикальное мнение: «все нелистовые классы должны быть абстрактными» (т. е. у конкретных классов вообще не должно быть конкретных суперклассов). 7 «Класс, который строится главным образом путем наследования примесям и не добавляет никакой структуры или поведения, называется агрегатным классом», Grady Booch et al. «Object Oriented Analysis and Design», издание 3 (Addison-W esley, 2007), стр. 109.\n--- Страница 393 ---\n393 Жизнь с множественным наследованием Вот, например, полный исходный код класса tkinter.Widget (http://bit. ly/1JHQqKU ): class Widget(BaseWidget, Pack, Place, Grid): \"\"\"Internal class. Base class for a widget which can be positioned with the geometry managers Pack, Place or Grid.\"\"\" pass Тело класса Widget пусто, но сам класс несет полезную функцию: объединяет четыре суперкласса, так что желающему создать виджет не нужно помнить все примеси или задаваться вопросом, в каком порядке их объявлять в предложении class . Более интересный пример дает класс ListView из веб-каркаса Django, кото- рый мы обсудим чуть ниже. 8. Предпочитайте композицию наследованию класса Эта цитата взята прямиком из книги «Паттерны проектирования», и лучше со- вета не придумаешь. Освоив наследование, очень легко впасть в грех злоупотре-бления им. Организация объектов в симпатичную иерархию импонирует нашему чувству порядка; а программисты делают это просто забавы ради. Однако, отдавая предпочтение композиции, мы получаем более гибкий дизайн. Например, класс tkinter.Widget мог бы не наследовать методы от всех менеджеров компоновки, а хранить ссылку на менеджер и вызывать его методы. В конце кон-цов, Widget же не должен «быть» менеджером компоновки, но мог бы пользоваться его услугами с помощью делегирования. Тогда было бы нетрудно добавить новый менеджер компоновки, не изменяя иерархию классов виджетов и не беспокоясь по поводу возможных конфликтов имен. Даже в случае одиночного наследования этот принцип повышает гибкость, поскольку создание подкласса – форма тесной связанности, а глубокие деревья наследования обычно оказываются хрупкими. Композиция и делегирование могут заменить использование примесей, когда нужно предоставить некоторый набор поведений различным классам, но не могут заменить наследование интерфейсов как средство определения иерархии типов. Проанализируем Tkinter в свете этих рекомендаций Tkinter: хороший, плохой, злой Помните, что Tkinter является частью стандартной библиотеки еще со времен версии Python 1.1, выпущенной в 1994 году. Tkinter – этой слой поверх великолепной библиотеки Tk, поставляемой вместе с языком Tcl. Комбинация Tcl/Tk изначально не была объектно-ориентированной, по-этому Tk API представляет собой просто обширный набор функций. Одна-ко концептуально эта библиотека в высшей степени объектно-ориентиро-ванная, пусть даже ее реализация таковой не является.\n--- Страница 394 ---\n394 Глава 12. Наследование: хорошо или плохо Tkinter не следует большинству изложенных выше рекомендаций за исключе- нием № 7. Но даже в этом отношении я бы не стал ставить ее в пример, потому что композиция, пожалуй, была бы уместнее для интеграции менеджеров компоновки с классом Widget , о чем было описано в рекомендации № 8. Строка документации tkinter.Widget начинается словами «Internal class». Это наводит на мысль, что Widget , наверное, следовало бы сделать ABC. Хотя у клас- са Widget нет собственных методов, он, тем не менее, определяет интерфейс. Его посыл таков: «Можете рассчитывать, что каждый виджет Tkinter предоставляет основные методы виджета ( __init__ , destroy и десятки функций из Tk API) в до- полнение к методам всех трех менеджеров компоновки». Можно согласиться, что такое определение интерфейса далеко от совершенства (слишком широкое), но все же это интерфейс, а Widget «определяет» его как объединение интерфейсов своих суперклассов. Класс Tk, который инкапсулирует прикладную логику графического интер- фейса пользователя (ГИП), наследует классам Wm и Misc , не являющимся ни абстрактными, ни примесями ( Wm – не совсем примесь, потому что ему наследу- ет TopLevel ). От самого имени класса Misc очень сильно отдает запашком . В Misc больше 100 методов, и ему наследуют все виджеты. А разве каждому виджету нуж-ны методы для работы с буфером обмена, для выделения текста, для управления таймером и т. д.? Ведь невозможно вставить что-то в кнопку из буфера обмена или выделить текст полосы прокрутки. Класс Misc следовало бы разбить на несколько специализированных классов-примесей и не заставлять все виджеты наследовать каждому из этих классов. Но будем справедливы – пользователю Tkinter вовсе необязательно знать о множественном наследовании. Эта деталь реализации скрыта за фасадом клас-сов виджетов, которые вы инстанцируете или которым наследуете в своем коде. Однако пользователь почувствует последствия злоупотребления множественным наследованием, если наберет dir(tkinter.Button) и попытается найти нужный ме- тод среди 214 перечисленных атрибутов. Несмотря на все проблемы, Tkinter – стабильный, гибкий и совсем не урод- ливый пакет. Оригинальные (подразумеваемые по умолчанию) виджеты Tk не поддерживают темы – непременную характеристику современных графических интерфейсов, но есть пакет tkinter.ttk , предлагающий элегантные, соответствую- щие платформе виджеты, благодаря которым, начиная с версии Python 3.1 (2009), можно разрабатывать профессиональные ГИП. Кроме того, некоторые унаследо-ванные виджеты, например Canvas и Text , обладают поразительно богатыми воз- можностями. Добавив немного своего кода, вы можете превратить объект Canvas в простое приложение для рисования, поддерживающее перетаскивание. С Tkinter и T cl/Tk определенно стоит познакомиться, если вы занимаетесь программирова-нием ГИП. Однако наша тема – не программирование ГИП, а использование множествен- ного наследования на практике. Более современный пример – с явными классами-примесями – можно найти в Django.\n--- Страница 395 ---\n395 Современный пример: примеси в обобщенных представлениях Django Для чтения этого раздела не нужно быть знатоком Django. Я использую лишь малую часть этого каркаса как практический пример применения множественного наследования и постараюсь по ходу дела сообщить все необходимые сведения, предполагая, правда, что вы имеете какой-то опыт разработки серверных веб-приложений на другом языке или с по- мощью другого каркаса. В Django представление – это вызываемый объект, который принимает в каче-стве аргумента объект, представляющий HTTP-запрос, и возвращает объект, пред-ставляющий HTTP-ответ. Нас в этом обсуждении будут интересовать различные ответы. Они могут быть совсем простыми, например ответ с перенаправлением, вообще не имеющий тела, или весьма сложными, например страница каталога Ин-тернет-магазина, которая строится по HTML-шаблону и содержит список товаров с кнопками для покупки и ссылками на страницы подробной информации. Первоначально Django предоставлял набор функций, называемых обобщенны- ми представлениями, которые реализовывали наиболее распространенные част-ные случаи. Например, на многих сайтах показываются результаты поиска, ко-торые включают информацию о различных объектах, причем список может быть многостраничным, а для каждого объекта имеется ссылка на страницу с деталь-ной информацией. В Django списковое представление и детальное представление спроектированы так, чтобы совместно решать эту задачу: списковое представле-ние отображает результаты поиска, а детальное формирует страницы с информа-цией об отдельных объектах. Однако изначально обобщенные представления были просто функциями, т. е. не допускали расширения. Если нужно было сделать что-то похожее на обобщен-ное списковое представление, но не в точности совпадающее с ним, приходилось начинать с нуля. В Django 1.3 появилась концепция представлений на основе классов, а также набор классов обобщенных представлений, состоящий из базовых классов, приме-сей и готовых конкретных классов. Базовые классы и примеси находятся в моду-ле base из пакета django.views.generic (рис. 2.4). В верхней части диаграммы мы видим два класса, на которые возложены совершенно разные обязанности: View и TemplateResponseMixin . Замечательным ресурсом для изучения этих классов является сайт Classy Class-Based Views ( http://ccbv.co.uk/ ), где организована удобная навигация и можно посмотреть все методы каждого класса (унаследо-ванные, переопределенные и добавленные), диаграммы, документацию и даже перейти в исходный код на сайте GitHub ( http://bit.ly/1JHSoe8 ).Современный пример: примеси в обобщенных представлениях\n--- Страница 396 ---\n396 Глава 12. Наследование: хорошо или плохо View является базовым классом всех представлений (он мог бы быть абстракт- ным) и предоставляет основную функциональность, например метод dispatch , де- легирующий работу методам-обработчикам – get, head , post и др. – которые реа- лизованы в конкретных классах для обработки различных глаголов HTTP8. Класс RedirectView наследует только View и, как видите, реализует методы get, head , post и т. д. Но если предполагается, что конкретные подклассы View реализуют методы- обработчики, то почему же они не являются частью интерфейса View ? Причина проста: подклассы вольны реализовывать лишь те обработчики, которым счита-ют нужным поддержать. Класс TemplateView служит только для отображения со- держимого, поэтому реализует лишь метод get. Если объекту TemplateView будет послан POST-запрос, то унаследованный метод View.dispatch обнаружит, что об- работчика post нет, и отправит HTTP-ответ 405 Method Not Allowed .9 Рис. 12.4. UML-диаграмма классов из модуля django.views.generic.base 8 Программирующие на Django знают, что метод класса as_view – самая заметная часть интерфейса View , но нам это сейчас неинтересно. 9 Знакомые с паттернами проектирования заметят, что механизм диспетчеризации в Django – ди- намический вариант паттерна Шаблонный метод ( http://en.wikipedia.org/wiki/T emplate_method_ pattern ). Динамический – потому что класс View не заставляет свои подклассы реализовывать все обработчики, а dispatch на этапе выполнения проверяет, существует ли обработчик поступивше- го запроса.\n--- Страница 397 ---\n397 Класс TemplateResponseMixin предоставляет функциональность, интересную только представлениям, нуждающимся в шаблоне. Но, например, у представления RedirectView нет тела, поэтому и шаблон ему не нужен, а, значит, оно не наследу- ет эту примесь. Примесь TemplateResponseMixin предоставляет набор поведений классу TemplateView и прочим представлениям, отрисовывающим шаблон, на- пример ListView или DetailView , определенным в других модулях пакета django. views.generic . На рис. 12.5 показана диаграмма классов из модуля django.views. generic.list и частично из модуля base . Рис. 12.5. UML-диаграмма класса для модуля django.views.generic.list module . Здесь все три класса из модуля base (см. рис. 12.4) объединены в один прямоугольник. В классе ListView нет ни методов, ни атрибутов; это агрегатный класс Для пользователей Django самым важным из показанных на рис. 12.5 классов является ListView ; это агрегатный класс, в котором вообще нет кода (его тело не содержит ничего, кроме строки документации). У объекта класса ListView имеется атрибут экземпляра object_list , который шаблон может обойти, чтобы показать содержимое страницы; обычно это результат запроса к базе данных, содержащий несколько объектов. Вся функциональность, относящаяся к генерации этого ите-рируемого объекта, находится в примеси MultipleObjectMixin . Эта же примесь предоставляет сложную логику разбиения на страницы, необходимую для показа на одной странице части результатов и ссылок на другие страницы. Предположим, что требуется создать представление, которое не отрисовывает шаблон, а порождает список объектов в формате JSON. Для этой цели существу-ет класс BaseListView . Это точка расширения, которая объединяет функциональ-Современный пример: примеси в обобщенных представлениях\n--- Страница 398 ---\n398 Глава 12. Наследование: хорошо или плохо ность классов View и MultipleObjectMixin , но без накладных расходов, обусловлен- ных механизмом шаблонов. Основанный на классах API представлений в Django – пример более правиль- ного, чем в Tkinter использования множественного наследования. В частности, разобраться в классах-примесях здесь очень просто: у каждого свое четко опреде-ленное назначение и имя, оканчивающееся суффиксом Mixin . Основанные на классах представления не все пользователи Django приняли на ура. Многие пользуются ими как черными ящиками, но если необходимо создать что-то новое, то по-прежнему пишут монолитные функции, которые берут на себя все обязанности, – вместо того чтобы попытаться повторно использовать классы представлений и примеси. Чтобы в полной мере понять, как использовать представления, основанные на классах, и как расширять их для решения задач конкретного приложения, нужно время, но я пришел к выводу, что это время будет потрачено не зря: они позволяют устранить стереотипный код, упрощают повторное использование и даже улучша-ют взаимодействие между членами команды – например, за счет стандартизации имен шаблонов и переменных, передаваемых к контекст шаблона. Представления, основанные на классах, – это представления «on rails» – как в Ruby . На этом мы завершаем обзор множественного наследования и классов-приме- сей. Резюме Мы начали рассказ о наследовании описанием проблемы наследования встро- енным типам: их методы, реализованные на C, не вызывают методы, переопре-деленные в подклассах, за исключением немногих частных случаев. Именно по-этому в тех случаях, когда нам нужен специальный список, словарь или строка, проще наследовать не классам list , dict или str, а классам UserList , UserDict или UserString – все они определены в модуле collections (https://docs.python.org/3/ library/collections.html ) и фактически обертывают встроенные типы, делегируя им работу, – это три примера использования композиции вместо наследования в стандартной библиотеке. Если требуемое поведение очень сильно отличается от поведения встроенных классов, то, быть может, проще унаследовать подходяще-му ABC из модуля collections .abc (https://docs.python.org/3/library/collections.abc. html ) и написать собственную реализацию. Остаток главы был посвящен обоюдоострому мечу множественного насле- дования. Сначала мы познакомились с порядком разрешения методов, который закодирован в атрибуте классе __mro__ и решает проблему потенциального кон- фликта имен в унаследованных методах. Мы также видели, как встроенная функ-ция super() консультируется с __mro__ при вызове метода суперкласса. Затем мы изучили, как множественное наследование используется в пакете ГИП Tkinter, который входит в состав стандартной библиотеки Python. Tkinter нельзя назвать образцом хорошего проектирования, если судить с позиций сегодняшнего дня, поэтому мы обсудили несколько способов применения множественного насле-\n--- Страница 399 ---\n399 Дополнительная литература дования, включая обдуманное использование классов-примесей и отказ от мно- жественного наследования в пользу композиции. Рассмотрев злоупотребление множественным наследованием в Tkinter, мы перешли к изучению главных ча-стей иерархии основанных на классах представлений в Django – на мой взгляд, это куда лучший пример использования примесей. Леннарт Регебро, очень опытный питонист и один из технических рецензентов этой книги, считает дизайн представлений-примесей в Django невразумительным. Но он же пишет: Опасность и вредность множественного наследования сильно преувеличены. Лично у меня с этим никогда не возникало серьез-ных проблем. Короче говоря, у всех нас может быть собственное мнение о том, как исполь- зовать множественное наследование и стоит ли использовать его вообще. Но за-частую просто нет выбора: применяемый каркас диктует свои правила. Дополнительная литература При использовании ABC множественное наследование не просто распространено, но и практически неизбежно, потому что большинство базовых классов фунда-ментальных коллекций ( Sequence , Mapping и Set) расширяют несколько ABC. Ис- ходный код модуля collections .abc (Lib/_collections_abc.py по адресу http://bit. ly/1QOA3Lt ) – отличный пример применения множественного наследования в сочетании с ABC, многие из которых являются также классами-примесями. Раймонд Хеттингер в статье «Python's super() considered super!» ( http://bit. ly/1JHSZfW ) объясняет работу функции super и множественное наследование в Python с позитивной точки зрения. Она была написана в ответ на статью «Python's Super is nifty, but you can't use it» (известную также под названием «Python's Super Considered Harmful») ( https://fuhm.net/super-harmful/ ) Джеймса Найта (James Knight). Несмотря на заглавия этих статей, проблема не в самой встроенной функции super – которая в Python 3 не так безобразна, как в Python 2. Настоящая про- блема – множественное наследование и присущие ему внутренние сложности. Мишель Симионато не ограничился критикой, а предложил решение в своей ста-тье «Setting Multiple Inheritance Straight» ( http://bit.ly/1HGpYxV ): он реализовал классы-характеристики (traits) – ограниченную форму примесей, впервые пред-ложенную в языке Self. Перу Симионату принадлежит целая серия статей о множе-ственном наследовании в Python, включая «The wonders of cooperative inheritance, or using super in Python 3» ( http://bit.ly/1HGpXdj ), «Mixins considered harmful», часть 1 ( http://bit.ly/1HGpXtQ ) и часть 2 ( http://bit.ly/1HGq0G9 ) и «Things to Know About Python Super», часть 1 ( http://bit.ly/1HGq1d4 ), часть 2 ( http://bit. ly/1HGq1K7 ) и часть 3 ( http://bit.ly/1HGq48I ). В ранних статьях используется синтаксис super из Python 2, но они по-прежнему актуальны.\n--- Страница 400 ---\n400 Глава 12. Наследование: хорошо или плохо Я читал первое издание книги Grady Booch «Object Oriented Analysis and Design», издание 3 (Addison-W esley, 2007) и горячо рекомендую его в качестве общего введения в объектно-ориентированный стиль мышления, не зависящий от языка программирования. Эта книга – редкий пример обсуждения множественно-го наследования без предрассудков. Поговорим Думайте, какие классы вам действительно необходимы Подавляющее большинство программистов пишут приложения, а не каркасы. Но даже те, кто разрабатывает каркасы, скорее всего, тра-тят значительную (если не основную) часть своего времени на создание приложений. При написании приложений мы обычно не разрабатываем иерархии классов. Как правило, мы пишем классы, наследующие ABC или другим классам, предоставляемым каркасом. Авторам приложений крайне редко приходится писать класс, выступающий в роли супер-класса. Почти всегда мы создаем листовые классы (расположенные в листьях дерева наследования). Если, разрабатывая приложение, вы ловите себя на создании мно- гоуровневой иерархии классов, то, скорее всего, имеет место что-то из перечисленного ниже. • Вы изобретаете велосипед. Посмотрите, нет ли в библиотеке или каркасе компонентов, которые вы могли бы повторно использо-вать в своем приложении. • Вы работаете с плохо спроектированным каркасом. Поищите альтернативу. • Вы чрезмерно усложняете задачу. Вспомните принцип KISS.• Вам наскучило писать приложения и вы решили создать новый каркас. Примите поздравления и пожелания успеха! Может также случиться, что к вашей ситуации применимы все четы- ре пункта: вам надоела рутина и вы решили изобрести новый велосипед, построив свой чрезмерно усложненный и плохо спроектированный кар-кас, который заставляет вас писать один класс за другим для решения тривиальных задач. Надеюсь, вы получаете от этого удовольствие или хотя бы эта работа оплачивается. Неправильное поведение встроенных типов: ошибка или так заду- мано? Встроенные типы dict , list и str – важнейшие структурные элемен- ты самого языка Python, поэтому они должны работать быстро, иначе\n--- Страница 401 ---\n401 Поговорим плохо будет всем. Поэтому в CPython принят ряд компромиссных реше- ний, из-за которых встроенные методы игнорируют методы, переопре-деленные в подклассах, что можно считать некорректным поведением. Возможный выход из этой ситуации: завести две реализации каждого типа: «внутреннюю», оптимизированную для использования самим ин-терпретатором, и внешнюю, которую можно было бы расширять. Но именно это мы и имеем: классы UserDict , UserList и UserString работают не так быстро, как встроенные, зато расширяются без проблем. Принятый в CPython прагматичный подход означает, что и мы в своих приложениях обычно используем оптимизированные реализации, кото-рым трудно наследовать. Это имеет смысл, если принять во внимание, что не так уж часто нам нужны специальные списки, отображения или строки. Следует только помнить о том, чем мы жертвуем. Наследование в разных языках Алан Кэй придумал термин «объектно-ориентированный», и в языке Smalltalk было только одиночное наследование, хотя существуют кло-ны с различными формами поддержки множественного наследования, в частности, современные диалекты Squeak и Pharo Smalltalk, в кото-рые поддерживаются характеристики (traits) – конструкции, играющие роль класса-примеси, но позволяющие избежать некоторых проблем множественного наследования. Первым популярным языком с поддержкой множественного насле- дования стал C++, но это средство использовалось во вред настолько часто, что проектировщики языка Java – задуманного как замена C++ – отказались от множественного наследования реализации (т. е. от клас-сов-примесей). И так было до выпуска Java 8, где появились методы по умолчанию, благодаря которым интерфейсы Java стали очень напоми-нать абстрактные классы, применяемые для определения интерфейсов в C++ и Python. Только вот у интерфейсов в Java не может быть состоя-ния – и это ключевое различие. После Java, пожалуй, самым распростра-ненным языком на платформе JVM является Scala, и в нем реализованы характеристики. Среди других языков, поддерживающих характеристи-ки, упомянем последние стабильные версии PHP и Groovy, а также на-ходящиеся в процессе разработки Rust и Perl 6. Так что будет справедли-во сказать, что классы-характеристики – модная тенденция В Ruby принят оригинальный подход к множественному наследо- ванию: оно не поддерживается, зато примеси являются полноправным языковым средством. Класс Ruby может включать модуль, так что опре-деленные в модуле методы становятся частью реализации класса. Это «чистая» форма примеси, не нуждающаяся ни в каком наследовании, и ясно, что примесь в Ruby никак не влияет на тип класса, в котором\n--- Страница 402 ---\n402 Глава 12. Наследование: хорошо или плохо используется. Тем самым мы получаем все преимущества примесей без многих связанных с ними проблем. Два недавно созданных языка, привлекающих всеобщее внимание, – Go и Julia –серьезно ограничили наследование. В Go наследования нет вообще, но реализация интерфейсов напоминает статическую форму динамической типизации (см. врезку «Поговорим» в главе 11). В Julia слово «класс» не употребляется, там есть только «типы». Иерархии ти-пов в Julia существуют, однако подтип может наследовать только по-ведение, но не структуру, причем подтипы могут существовать только у абстрактных типов. Кроме того, методы в Julia реализованы с при-менением множественной диспетчеризации – более развитой формы механизма, который мы обсуждали в разделе «Обобщенные функций с одиночной диспетчеризацией» главы 7.",
      "debug": {
        "start_page": 380,
        "end_page": 402
      }
    },
    {
      "name": "Глава 13. Перегрузка операторов: как правильно? 403",
      "content": "--- Страница 403 --- (продолжение)\nГЛАВА 13. Перегрузка операторов: как правильно? Есть вещи, которые меня смущают, например перегрузка операторов. Я принял волевое решение исключить перегрузку операторов из языка, потому что видел много примеров злоупотребления этой возможно-стью в C++ 1. – Джеймс Гослинг, создатель Java Перегрузка операторов позволяет применять инфиксные операторы (например, + и |) и унарные операторы (например, - и ~) к объектам пользовательских типов. Вообще говоря, вызов функции ( ()), доступ к атрибутам ( .) и операция доступа к элементам или получения среза ( []) в Python также являются операторами, но эта глава посвящена только унарным и инфиксным операторам. В разделе «Эмуляция числовых типов» главы 1 мы видели тривиальные ре- ализации операторов в наброске класса Vector . Методы __add__ и __mul__ в при- мере 1.2 были написаны, для того чтобы показать, как специальные методы под-держивают перегрузку операторов, но в их реализации есть тонкие проблемы, на которые мы тогда не стали обращать внимания. Кроме того, в примере 9.2 мы от-метили, что в реализации метода Vector2d.__eq__ предполагается истинным ра- венство Vector(3, 4) == [3, 4] – иногда это имеет смысл, а иногда нет. Эти во- просы станут предметом настоящей главы. Мы рассмотрим следующие темы: • как в Python поддерживаются инфиксные операторы с операндами разных типов; • использование динамической типизации или явной проверки типов при работе с операндами разных типов; • как инфиксный оператор должен сообщить о том, что не может обработать операнд; 1 Источник: «Семейство языков, производных от C: интервью с Дэннисом Ритчи, Бьярном Страу- струпом и Джеймсом Гослингом» ( http://www.gotw.ca/publications/c_family_interview.htm ).\nГЛАВА 13. Перегрузка операторов: как правильно? Есть вещи, которые меня смущают, например перегрузка операторов. Я принял волевое решение исключить перегрузку операторов из языка, потому что видел много примеров злоупотребления этой возможно-стью в C++ 1. – Джеймс Гослинг, создатель Java Перегрузка операторов позволяет применять инфиксные операторы (например, + и |) и унарные операторы (например, - и ~) к объектам пользовательских типов. Вообще говоря, вызов функции ( ()), доступ к атрибутам ( .) и операция доступа к элементам или получения среза ( []) в Python также являются операторами, но эта глава посвящена только унарным и инфиксным операторам. В разделе «Эмуляция числовых типов» главы 1 мы видели тривиальные ре- ализации операторов в наброске класса Vector . Методы __add__ и __mul__ в при- мере 1.2 были написаны, для того чтобы показать, как специальные методы под-держивают перегрузку операторов, но в их реализации есть тонкие проблемы, на которые мы тогда не стали обращать внимания. Кроме того, в примере 9.2 мы от-метили, что в реализации метода Vector2d.__eq__ предполагается истинным ра- венство Vector(3, 4) == [3, 4] – иногда это имеет смысл, а иногда нет. Эти во- просы станут предметом настоящей главы. Мы рассмотрим следующие темы: • как в Python поддерживаются инфиксные операторы с операндами разных типов; • использование динамической типизации или явной проверки типов при работе с операндами разных типов; • как инфиксный оператор должен сообщить о том, что не может обработать операнд; 1 Источник: «Семейство языков, производных от C: интервью с Дэннисом Ритчи, Бьярном Страу- струпом и Джеймсом Гослингом» ( http://www.gotw.ca/publications/c_family_interview.htm ).\n--- Страница 404 ---\n404 Глава 13. Перегрузка операторов: как правильно? • специальное поведение операторов сравнения (например, ==, >, <=); • подразумеваемая по умолчанию обработка операторов составного присва- ивания, например +=, и их корректная перегрузка. Основы перегрузки операторов У перегрузки операторов сложилась дурная репутация в некоторых кругах. Это языковое средство, которое легко использовать неправильно (что не раз происхо-дило), а результат – недоумение программиста, ошибки и неожиданные провалы производительности. Зато при правильном употреблении мы получаем прият-ный API и удобочитаемый код. Python стремится найти баланс между гибкостью, удобством и безопасностью, для чего вводятся некоторые ограничения: • запрещается перегружать операторы для встроенных типов; • запрещается создавать новые операторы, можно только перегружать суще- ствующие; • несколько операторов перегружать нельзя вовсе: is, and, or, not (на пораз- рядные операторы &, |, ~ это не распространяется). В классе Vector из главы 10 нам уже встречался инфиксный оператор ==, под- держиваемый методом __eq__ . В этой главе мы улучшим реализацию __eq__ , чтобы правильнее обрабатывать операнды, типы которых отличаются от Vector . Однако операторы сравнения ( ==, !=, >, <, >=, <=) – это особые случаи перегрузки операто- ров, поэтому начнем с перегрузки четырех арифметических операторов в классе Vector : сначала унарных - и +, а затем инфиксных + и *. Унарные операторы В разделе 6.5 «Унарные арифметические и поразрядные операции» ( http://bit. ly/1JHV4bN ) справочного руководство по языку Python перечислены три унарных оператора, которые ниже показаны вместе с относящимися к ним специальными методами. - (__neg__) Унарный арифметический минус. Если x равно -2, то -x == 2 . + (__pos__) Унарный арифметический плюс. Обычно x == +x , но есть несколько осо- бых случаев, когда это неверно. Если вам интересно, см. врезку «Когда x не равно +x» ниже. ~ (__invert__) Поразрядная инверсия целого числа, определяется как ~x == -(x+1) . Если x равно 2, то ~x == -3 .\n--- Страница 405 ---\n405 Унарные операторы В главе «Модель данных» ( https://docs.python.org/3/reference/datamodel. html#object.__neg__ ) справочного руководство по языку Python встроенная функция abs( …) также названа унарным оператором. Ранее (раздел «Эмуляция числовых типов» главы 1) мы видели, что с ней связан специальный метод __abs__ . Поддержать унарные операторы легко. Достаточно реализовать соответству- ющий специальный метод, который принимает единственный аргумент self . Ло- гика этого метода может быть произвольной, но должно удовлетворяться фунда-ментальное правило: оператор всегда возвращает новый объект. Иначе говоря, не модифицируйте self , а создавайте и возвращайте новый экземпляр подходящего типа. В случае операторов - и + результат, вероятно, должен быть экземпляром того же класса, что и self ; для + чаще всего имеет смысл возвращать копию self . Для abs( …) результатом должен быть скаляр. Результат же оператора ~ очевиден, толь- ко если речь идет о битах целого числа, но, скажем, в случае ORM (объектно-ори- ентированное отображение) имело бы смысл вернуть SQL-команду с противопо- SQL-команду с противопо- -команду с противопо- ложным условием WHERE . Как и было обещано, мы реализуем еще несколько операторов в классе Vector в дополнение к тем, что было сделано в главе 10. В примере 13.1 показан метод __abs__ – тот же, что в примере 10.16, – и новые методы __neg__ и __pos__ для под- держки унарных операторов. Пример 13.1. vector_v6.py: унарные операторы - и + в дополнение к примеру 10.16 def __abs__(self): return math.sqrt(sum(x * x for x in self)) def __neg__(self): return Vector(-x for x in self) /g110 def __pos__(self): return Vector(self) /g111 /g110 Для вычисления -v строим новый объект Vector , в котором все компоненты self имеют противоположный знак. /g111 Для вычисления +v строим новый объект Vector с точно такими же компонентами, как у self . Напомним, что экземпляры Vector – итерируемые объекты, а Vector.__init__ принимает в качестве аргумента итерируемый объект, поэтому реализации __neg__ и __pos__ оказались очень короткими и элегантными. Мы не станем реализовывать метод __invert__ , поэтому при попытке выпол- нить операцию ~v для объекта Vector Python возбудит исключение TypeError с не оставляющим сомнений сообщением: «bad operand type for unary ~: 'V ector'». Прочитав об одном курьезе на врезке ниже, вы сможете как-нибудь при случае выиграть пари, касающееся унарного +.\n--- Страница 406 ---\n406 Глава 13. Перегрузка операторов: как правильно? Когда x не равно + x Все ожидают, что x == +x , и почти всегда в Python так оно и есть, но я нашел в стандартной библиотеке два случая, когда x != +x . Первый касается класса decimal.Decimal . Может получиться, что x != +x, если x – экземпляр Decimal , созданный в арифметическом контексте, а +x затем вычислялось в контексте с другими свойствами. Например, x вычисляется в контексте с некоторой точностью, затем точность из- меняется, после чего вычисляется +x. См. демонстрацию в примере 13.2. Пример 13.2. Изменение точности в арифметическом контексте может привести к тому, что x будет отличаться от +x >>> import decimal >>> ctx = decimal.getcontext() /g110 >>> ctx.prec = 40 /g111 >>> one_third = decimal.Decimal('1') / decimal.Decimal('3') /g112 >>> one_third /g113 Decimal('0.3333333333333333333333333333333333333333')>>> one_third == +one_third /g114 True>>> ctx.prec = 28 /g115 >>> one_third == +one_third /g116 False>>> +one_third /g117 Decimal('0.3333333333333333333333333333') /g110 Получаем ссылку на текущий глобальный арифметический кон- текст. /g111 У станавливаем точность арифметического контекста 40. /g112 Вычисляем 1/3 с текущей точностью. /g113 Печатаем результат – имеем 40 цифр после точки. /g114 Значение выражения one_third == +one_third равно True . /g115 Понижаем точность до 28 – значение по умолчанию для класса Decimal в Python 3.4. /g116 Теперь значение выражения one_third == +one_third равно False . /g117 Печатаем +one_third – после точки только 28 цифр. Получается, что при каждом вычислении выражения +one_third соз- дается новый экземпляр Decimal со значением one_third , но с точностью, заданной в текущем арифметическом контексте. Второй случай, когда x != +x , описан в документации по классу collections.Counter (http://bit.ly/1JHVi2E ). В классе Counter реализо- вано несколько арифметических операторов, в том числе инфиксный +, который складывает счетчики соответственных элементов из двух объ-ектов Counter . Однако из практических соображений сложение в классе Counter не включает в результат элементы с отрицательным или нуле-\n--- Страница 407 ---\n407 Перегрузка оператора сложения векторов + вым счетчиком. А унарный + прибавляет пустой объект Counter и, сле- довательно, сохраняет только те элементы, в которых счетчик больше нуля. Пример 13.3. Унарный + порождает новый объект Counter , в который не входят элементы с нулевыми и отрицательными счетчиками >>> ct = Counter('abracadabra')>>> ctCounter({'a': 5, 'r': 2, 'b': 2, 'd': 1, 'c': 1})>>> ct['r'] = -3>>> ct['d'] = 0>>> ctCounter({'a': 5, 'b': 2, 'c': 1, 'd': 0, 'r': -3})>>> +ctCounter({'a': 5, 'b': 2, 'c': 1}) А теперь вернемся к обычному программированию. Перегрузка оператора сложения векторов + Класс Vector – это последовательность, а в разделе 3.3.6 «Эмуляция контейнерных типов» главы «Модель данных» ( http://bit.ly/1QOyDQY ) го- ворится, что последовательности должны поддерживать оператор + с се- мантикой конкатенации и * с семантикой повторения. Однако в данном случае мы реализуем + и * как математические операторы, что несколько труднее, но для типа Vector более осмысленно. Сложение двух евклидовых векторов дает новый вектор, компоненты которого являются суммами соответственных компонент слагаемых, например: >>> v1 = Vector([3, 4, 5])>>> v2 = Vector([6, 7, 8])>>> v1 + v2Vector([9.0, 11.0, 13.0])>>> v1 + v2 == Vector([3+6, 4+7, 5+8])True Что будет, если сложить два экземпляра Vector разной длины? Мы могли бы возбудить исключение, но в реальных приложениях (например, в информацион-ном поиске) лучше дополнить более короткий вектор нулями. Вот какой резуль-тат мы хотим получить: >>> v1 = Vector([3, 4, 5, 6])\n--- Страница 408 ---\n408 Глава 13. Перегрузка операторов: как правильно? >>> v3 = Vector([1, 2]) >>> v1 + v3Vector([4.0, 6.0, 5.0, 6.0]) При таких требованиях реализация __add__ получается красивой и лаконич- ной. Пример 13.4. Метод Vector.add , попытка № 1 # Внутри класса Vector def __add__(self, other): pairs = itertools.zip_longest(self, other, fillvalue=0.0) # /g110 return Vector(a + b for a, b in pairs) # /g111 /g110 pairs – генератор, который порождает кортежи (a, b) , где a берется из self , и b – из other . Если длины self и other различаются, то более короткий вектор дополняется значениями fillvalue . /g111 Новый объект Vector инициализируется генераторным выражением, кото- рое порождает по одной сумме для каждого элемента pairs . Обратите внимание, что __add__ возвращает новый экземпляр Vector , не изменяя ни self , ни other . Специальные методы, реализующие унарные или инфиксные операто- ры не должны изменять свои операнды. Предполагается, что выражения, содержащие такие операторы, вычисляют результаты, создавая новые объекты. И лишь операторы составного присваивания могут изменять свой первый операнд ( self ), о чем речь пойдет ниже. В примере 13.4 разрешено прибавлять Vector к Vector2d , а также к кортежу или любому другому итерируемому объекту, порождающему числа. Это доказывает пример 13.5. Пример 13.5. Vector.__add__ из примера 13.4 поддерживает сложение с объектами, отличными от Vector >>> v1 = Vector([3, 4, 5]) >>> v1 + (10, 20, 30)Vector([13.0, 24.0, 35.0])>>> from vector2d_v3 import Vector2d>>> v2d = Vector2d(1, 2)>>> v1 + v2dVector([4.0, 6.0, 5.0]) Оба сложения в примере 13.5 работают, потому что в методе __add__ исполь- зуется функция zip_longest( …), готовая принимать любые итерируемые объек- ты, а генераторное выражение, которым инициализируется новый Vector , просто\n--- Страница 409 ---\n409 Перегрузка оператора сложения векторов + выполняет операцию a + b для каждой пары, возвращаемой zip_longest( …), по- этому подойдет любой итерируемый объект, порождающий числа. Однако если поменять операнды местами (пример 13.6), то сложение операн- дов разных типов даст ошибку. Пример 13.6. Vector.__add__ из примера 13.4 дает ошибку, если тип левого операнда – не Vector >>> v1 = Vector([3, 4, 5]) >>> (10, 20, 30) + v1Traceback (most recent call last): File \"<stdin>\", line 1, in <module>TypeError: can only concatenate tuple (not «Vector») to tuple>>> from vector2d_v3 import Vector2d>>> v2d = Vector2d(1, 2)>>> v2d + v1Traceback (most recent call last): File \"<stdin>\", line 1, in <module>TypeError: unsupported operand type(s) for +: 'Vector2d' and 'Vector' Для поддержки операций с объектами разных типов в Python имеется особый механизм диспетчеризации для специальных методов, ассоциированных с инфиксными операторами. Видя выражение a + b , интерпретатор выполняет следующие шаги (см. рис. 13.1). 1. Если у a есть метод __add__ , вызвать a.__add__(b) и вернуть результат, если только он не равен NotImplemented . 2. Если у a нет метода __add__ или его вызов вернул NotImplemented , прове- рить, есть ли у b метод __radd__ , и, если да, вызвать b.__radd__(a) и вернуть результат, если только он не равен NotImplemented . 3. Если у b нет метода __radd__ или его вызов вернул NotImplemented , возбу- дить исключение TypeError с сообщением unsupported operand types (непод- держиваемые типы операндов). Метод __radd__ называется «инверсным» (reversed) или «отраженным» (reflected) вариантом __add__ . Я предпочитаю термин «инверсные» специальные методы2. Три рецензента книги – Алекс, Анна и Лео – говорили мне, что представ- ляют их как «правые» (right) специальные методы, потому что они вызываются от имени правого операнда. В общем, сами решайте, какое слово на «r» вам больше нравится. Итак, чтобы сложение операндов разных типов в примере 13.6 заработало, мы должны реализовать метод Vector.__radd__ , который Python вызовет, если у лево- 2 В документации по Python встречаются оба термина. В главе «Модель данных» ( https://docs.python. org/3/reference/datamodel.html ) используется «reflected», а в разделе 9.1.2.2 « Реализация арифмети- ческих операций» ( http://bit.ly/1JHWP8W ) при описании модуля numbers упоминаются «forward» (прямые) и «reverse» (инверсные) методы, и мне эта терминология нравится больше, потому что сло-ва «прямой» и «инверсный» (не «обратный», чтобы не путать с обратной функцией – Прим. перев. ) сразу наводят на мысль о направлении, тогда как у слова «reflected» нет очевидного антонима.\n--- Страница 410 ---\n410 Глава 13. Перегрузка операторов: как правильно? го операнда нет метода __add__ или есть, но возвращает значение NotImplemented , сигнализируя о том, что не знает, как обработать правый операнд. Не путайте NotImplemented с NotImplementedError . NotImplemented – это значение-синглтон, которое должен возвращать специальный метод инфиксного оператора, чтобы сообщить интерпре-татору о том, что не умеет обрабатывать данный операнд. Напротив, NotImplementedError – исключение, которое возбуждают методы-за- глушки в абстрактных классах, предупреждая, что их необходимо пере-определить в подклассах. Рис. 13.1. Блок-схема вычисления a + b с помощью перегруженных операторов __add__ и __radd__ Простейшая реализация метода __radd__ показана в примере 13.7. Пример 13.7. Методы Vector.__add__ и __radd__ # внутри класса Vector def __add__(self, other): # /g110получить result от a.__add__(b) вернуть resultданет у a есть add? ин-версный опера-тору и есть radd ? возбудить TypeErrorполучить result от b.__radd__(a) result равен NotIm- plement- ed?result равен NotIm- plement- ed?дада данет нет нет\n--- Страница 411 ---\n411 Перегрузка оператора сложения векторов + pairs = itertools.zip_longest(self, other, fillvalue=0.0) return Vector(a + b for a, b in pairs) def __radd__(self, other): # /g111 return self + other /g110 Метод __add__ такой же, как в примере 13.4; приведен только потому, что им пользуется метод __radd__ . /g111 __radd__ просто делегирует свою работу методу __add__ . Часто инверсный оператор можно таким и оставить: просто делегировать рабо- ту нужному оператору, в данном случае __add__ . Это относится к любому комму- тативному оператору; + является коммутативным для чисел и векторов, но пере- стает быть таковым, когда используется для конкатенации последовательностей в Python. Методы в примере 13.4 работают как с объектами Vector , так и с любыми други- ми итерируемыми объектами, содержащими числовые элементы: Vector2d , кортеж целых чисел или массив чисел с плавающей точкой. Но если методу __add__ под- сунуть неитерируемый объект, то он выдаст не слишком полезное сообщение об ошибке, как в примере 13.8. Пример 13.8. Методу Vector.__add__ необходим итерируемый операнд >>> v1 + 1 Traceback (most recent call last): File \"<stdin>\", line 1, in <module> File \"vector_v6.py\", line 328, in __add__ pairs = itertools.zip_longest(self, other, fillvalue=0.0)TypeError: zip_longest argument #2 must support iteration Другое невразумительное сообщение выдается, если операнд – итерируемый объект, но его элементы нельзя сложить с компонентами Vector , имеющими тип float . См. пример 13.9. Пример 13.9. Методу Vector.__add__ необходим итерируемый операнд с числовыми элементами >>> v1 + 'ABC' Traceback (most recent call last): File \"<stdin>\", line 1, in <module> File \"vector_v6.py\", line 329, in __add__ return Vector(a + b for a, b in pairs) File \"vector_v6.py\", line 243, in __init__ self._components = array(self.typecode, components) File \"vector_v6.py\", line 329, in <genexpr> return Vector(a + b for a, b in pairs)TypeError: unsupported operand type(s) for +: 'float' and 'str' Но непонятные сообщения в примерах 13.8 и 13.9 – еще не самое страшное: если специальный метод оператора не может вернуть правильный результат из-за несовместимости типов, он должен возвращать значение NotImplemented , а не\n--- Страница 412 ---\n412 Глава 13. Перегрузка операторов: как правильно? возбуждать исключение TypeError . Возвращая NotImplemented , вы оставляете разработчику типа другого операнда возможность выполнить операцию, когда Python попробует вызвать инверсный метод. Оставаясь верны духу динамической типизации, мы воздержимся от проверки типа операнда other или его элементов. Вместо этого мы перехватим исключение и вернем NotImplemented . Если интерпретатор еще не пробовал операнды в обрат- ном порядке, то сделает это. Если же значение NotImplemented вернул инверсный метод, то Python возбудит исключение TypeError со стандартным сообщением вида «unsupported operand type(s) for +: V ector and str». Окончательная реализация специальных методов для сложения объектов класса Vector приведена в примере 13.10. Пример 13.10. vector_v6.py: специальные методы оператора +, добавленные в файл vector_v5.py (пример 10.16) def __add__(self, other): try: pairs = itertools.zip_longest(self, other, fillvalue=0.0) return Vector(a + b for a, b in pairs) except TypeError: return NotImplemented def __radd__(self, other): return self + other Если метод инфиксного оператора возбуждает исключение, то работа алгоритма диспетчеризации прерывается. В частном случае исключения TypeError зачастую лучше перехватить его и вернуть значение Not- Implemented . Это позволит интерпретатору вызвать метод инверсного оператора, который, возможно, сумеет завершить вычисление, поменяв местами операнды разных типов. Итак, мы безопасно перегрузили оператор +, написав методы __add__ и __radd__ . Теперь займемся инфиксным оператором *. Перегрузка оператора умножения на скаляр * Что означает запись Vector([1, 2, 3]) * x ? Если x – число, то это умножение на скаляр, результатом которого является новый объект Vector , каждая компонента которого является произведением x и соответственной компоненты исходного вектора: >>> v1 = Vector([1, 2, 3])>>> v1 * 10\n--- Страница 413 ---\n413 Перегрузка оператора умножения на скаляр * Vector([10.0, 20.0, 30.0]) >>> 11 * v1Vector([11.0, 22.0, 33.0]) Над векторами определена и другая операция умножения: скалярное произ- ведение; если представить один вектор как матрицу 1 × N, а другой – как матрицу N × 1, то результат перемножения этих матриц и называется скалярным произве- дением. В NumPy и других подобных библиотеках принято не нагружать опера- библиотеках принято не нагружать опера- ах принято не нагружать опера- тор * обеими семантиками, а оставить его только для умножения на скаляр. А для вычисления скалярного произведения в NumPy есть функция numpy.dot()3. Но вернемся к операции умножения на скаляр. Как и раньше, начнем с про- стейших вариантов __mul__ и __rmul__ : # внутри класса Vectordef __mul__(self, scalar): return Vector(n * scalar for n in self) def __rmul__(self, scalar): return self * scalar Оба метода работают, если типы операндов совместимы. Аргумент scalar дол- жен быть числом, которое при умножении на float дает float (поскольку во вну- треннем представлении класса Vector используется массив чисел типа float ). По- этому число типа complex не подойдет, однако годятся типы int, bool (поскольку bool – подкласс int) и даже fractions.Fraction . Можно было бы использовать ту же технику динамической типизации, что в примере 13.10: перехватить исключение TypeError в методе __mul__ , но в этом случае существует и более явный способ навести порядок: гусиная типизация . Мы воспользуемся функцией isinstance() для проверки типа scalar , но срав- нивать будем не с конкретными типами, а с абстрактным базовым классом num- bers.Real , который охватывает все подходящие типы и оставляет реализацию открытой для будущих числовых типов, которые объявляют себя настоящими или виртуальными подклассами numbers.Real . В примере 13.11 показано ис- пользование гусиной типизации на практике – явное сравнение с абстрактным типом; полный листинг см. в репозитории кода по адресу https://github.com/ fluentpython/example-code . Напомним (см. раздел «ABC в стандартной библиотеке» главы 11), что класс decimal.Decimal не зарегистрирован как виртуальный подкласс numbers.Real . Поэтому объект нашего класса Vector нельзя умножить на число типа decimal.Decimal . 3 Начиная с версии Python 3.5, в качестве инфиксного оператора скалярного произведения можно использовать знак @. Подробнее об этом см. в разделе «Новый инфиксный оператор @ в Python 3.5» ниже.\n--- Страница 414 ---\n414 Глава 13. Перегрузка операторов: как правильно? Пример 13.11. vector_v7.py: добавлены методы оператора * from array import array import reprlibimport mathimport functoolsimport operatorimport itertoolsimport numbers # /g110 class Vector: typecode = 'd' def __init__(self, components): self._components = array(self.typecode, components) # в книге многие методы опущены, полный код vector_v7.py # см. по адресу https://github .com/fluentpython/example -code def __mul__(self, scalar): if isinstance(scalar, numbers.Real): # /g111 return Vector(n * scalar for n in self) else: # /g112 return NotImplemented def __rmul__(self, scalar): return self * scalar # /g113 /g110 Импортируем модуль numbers для проверки типа. /g111 Если scalar – экземпляр подкласса numbers.Real , создаем новый объект Vector , умножая компоненты исходного на заданное число. /g112 В противном случае возбуждаем исключение TypeError с конкретным со- общением. /g113 В этом примере __rmul__ просто вычисляет произведение self * scalar , делегируя всю работу методу __mul__ . Код из примера 13.11 позволяет умножать векторы на скалярные значения обычных и не очень обычных числовых типов: >>> v1 = Vector([1.0, 2.0, 3.0])>>> 14 * v1Vector([14.0, 28.0, 42.0])>>> v1 * TrueVector([1.0, 2.0, 3.0])>>> from fractions import Fraction>>> v1 * Fraction(1, 3)Vector([0.3333333333333333, 0.6666666666666666, 1.0]) При реализации операторов + и * мы познакомились с наиболее распростра- ненными приемами программирования инфиксных операторов. Описанная тех-ника применима ко всем операторам, перечисленным в табл. 13.1 (операторы, вычисляемые на месте, будут рассмотрены в разделе «Составные операторы при-сваивания» ниже).\n--- Страница 415 ---\n415 Перегрузка оператора умножения на скаляр * Т аблица 13.1. Имена методов инфиксных операторов (операторы, вычисляемые на месте, связаны с составным присваиванием; операторы сравнения описаны в табл. 13.2) Оператор Прямой Инверсный На месте Описание + __add__ __radd__ __iadd__ Сложение или конкатенация - __sub__ __rsub__ __isub__ Вычитание * __mul__ __rmul__ __imul__ Умножение или повторение / __truediv__ __rtruediv__ __itruediv__ Истинное деление // __floordiv__ __rfloordiv__ __ifloordiv__ Деление с округлением % __mod__ __rmod__ __imod__ Деление по модулю divmod() __divmod__ __rdivmod__ __idivmod__ Возвращает кортеж, содержащий частное и остаток **, pow() __pow__ __rpow__ __ipow__ Возведение в степень a @ __matmul__ __rmatmul__ __imatmul__ Матричное умножениеb & __and__ __rand__ __iand__ Поразрядное И | __or__ __ror__ __ior__ Поразрядное ИЛИ ^ __xor__ __rxor__ __ixor__ Поразрядное ИСКЛЮЧАЮЩЕЕ ИЛИ << __lshift__ __rlshift__ __ilshift__ Поразрядный сдвиг влево >> __rshift__ __rrshift__ __irshift__ Поразрядный сдвиг вправо a Оператор pow принимает необязательный третий аргумент , modulo : pow(a, b, modulo) , поддерживаемый также специальными методами, если они вызываются напрямую (на-пример, a.__pow__(b, modulo) ). b Появился в версии Python 3.5. Еще одна категория инфиксных операторов – операторы сравнения, для них действуют несколько иные правила. Мы рассмотрим их в следующем разделе. А на врезке ниже рассказывается об операторе, включенном в версию Python 3.5, которая на момент написания этой книги еще не была выпущена. Новый инфиксный оператор @ в версии Python 3.5 В версии Python 3.4 нет инфиксного оператора скалярного произ- ведения. Однако в версии Python 3.5 pre-alpha уже реализовано пред-ложение из документа «PEP 465 – A dedicated infix operator for matrix multiplication» ( https://www.python.org/dev/peps/pep-0465/ ), согласно\n--- Страница 416 ---\n416 Глава 13. Перегрузка операторов: как правильно? которому для этой цели стал доступен символ @ (например, a @ b озна- чает скалярное произведение a и b). Для поддержки оператора @ пред- назначены специальные методы __matmul__ , __rmatmul__ и __imatmul__ , имена которых – сокращение от «matrix multiplication» (матричное умножение). В настоящее время эти методы не используются нигде в стандартной библиотеке, но распознаются интерпретатором, поэтому разработчики NumPy, а с ними и все мы, могут поддержать оператор @ в пользовательских типах. Синтаксический анализатор также изменен для поддержки инфиксного оператора @ (раньше запись a @ b приводила к синтаксической ошибке). Собрав версию Python 3.5 из исходного кода, я смог реализовать и протестировать оператор @, вычисляющий скалярное произведение в классе Vector . Вот простейшие тесты: >>> va = Vector([1, 2, 3])>>> vz = Vector([5, 6, 7])>>> va @ vz == 38.0 # 1*5 + 2*6 + 3*7True>>> [10, 20, 30] @ vz380.0>>> va @ 3Traceback (most recent call last): TypeError: unsupported operand type(s) for @: 'Vector' and 'int' А вот код соответствующих специальных методов: class Vector: # в книге многие методы опущены def __matmul__(self, other): try: return sum(a * b for a, b in zip(self, other)) except TypeError: return NotImplemented def __rmatmul__(self, other): return self @ other Полный код находится в файле vector_py3_5.py в репозитории кода к книге по адресу https://github.com/fluentpython/example-code . Не забудьте, что выполнять этот код следует в версии Python 3.5, иначе получите исключение SyntaxError ! Операторы сравнения Обработка операторов сравнения ==, !=, >, <, >=, <= интерпретатором Python похо- жа на то, что мы видели выше, но имеет два важных отличия.\n--- Страница 417 ---\n417 Операторы сравнения • Для прямых и инверсных вызовов служит один и тот же набор методов. Правила приведены в табл. 13.2. Например, в случае оператора == как пря- мой, так и инверсный вызов обращаются к методу __eq__ , но изменяется порядок аргументов. А прямой вызов __gt__ сопровождается инверсным вызовом __lt__ с переставленными аргументами. • В случае == и !=, если инверсный вызов завершается ошибкой, то Python сравнивает идентификаторы объектов, а не возбуждает исключение TypeError . Т аблица 13.2. Операторы сравнения: инверсные методы вызываются, когда первый вызов вернул NotImplemented ГруппаИнфиксный операторПрямой вызов методаИнверсный вызов методаЗапасной вариант Равенство a == b a.__eq__(b) b.__eq__(a) Вернуть id(a) == id(b) a != b a.__ne__(b) b.__ne__(a) Вернуть not (a == b) Порядок a > b a.__gt__(b) a.__lt__(b) Возбудить TypeError a < b a.__lt__(b) a.__gt__(b) Возбудить TypeError a >= b a.__ge__(b) a.__le__(b) Возбудить TypeError a <= b a.__le__(b) a.__ge__(b) Возбудить TypeError Новое поведение в Python 3 Запасной вариант для всех операторов сравнения изменился по срав- нению с Python 2. В случае __ne__ Python 3 теперь возвращает резуль- тат , противоположный __eq__ . Для операторов сравнения на больше- меньше Python 3 возбуждает исключение TypeError с сообщением вида 'unorderable types: int() < tuple()' . В Python 2 эти операторы давали странные результаты, т . к принимали во внимание типы и иденти-фикаторы объектов и делали это отнюдь не очевидным образом. Однако же сравнивать, к примеру, int и tuple вряд ли имеет смысл, поэтому воз- буждение исключения TypeError в таких случаях, безусловно, улучшает язык. Имея в виду эти правила, давайте улучшим поведение метода Vector.__eq__ , которое в файле vector_v5.py (пример 10.16) было закодировано следующим об- разом: class Vector: # много строк опущено def __eq__(self, other): return (len(self) == len(other) and all(a == b for a, b in zip(self, other)))\n--- Страница 418 ---\n418 Глава 13. Перегрузка операторов: как правильно? В примере 13.12 показаны результаты работы этого метода. Пример 13.12. Сравнение Vector с Vector , с Vector2d и с tuple >>> va = Vector([1.0, 2.0, 3.0]) >>> vb = Vector(range(1, 4))>>> va == vb # /g110 True>>> vc = Vector([1, 2])>>> from vector2d_v3 import Vector2d>>> v2d = Vector2d(1, 2)>>> vc == v2d # /g111 True>>> t3 = (1, 2, 3)>>> va == t3 # /g112 True /g110 Два объекта Vector с равными числовыми компонентами должны быть рав- компонентами должны быть рав- ами должны быть рав- ны. /g111 Объекты Vector и Vector2d также равны, если равны их компоненты. /g112 Vector считается равным кортежу или любому другому итерируемому объ- екту, элементы которого соответственно равны его компонентам. Последний результат в примере 13.12 вряд ли следует считать желательным. Впрочем, твердой уверенности у меня нет – все зависит от контекста. Однако в «Дзен Python» сказано: Встретив неоднозначность, отбрось искушение угадать. Излишняя либеральность при вычислении операндов может преподнести сюр- призы, а программисты их ненавидят. Если в поисках ключа обратиться к самому Python, то мы увидим, что сравне- ние [1,2] == (1, 2) дает False . Поэтому будем осторожны и добавим сравнение типов. Если второй операнд – объект класса Vector (или его подкласса), то оста- вим ту же логику, что в текущей реализации __eq__ . Иначе вернем NotImplemented , и пусть Python разбирается. Пример 13.13. vector_v8.py: улучшенный метод __eq__ в классе Vector def __eq__(self, other): if isinstance(other, Vector): /g110 return (len(self) == len(other) and all(a == b for a, b in zip(self, other))) else: return NotImplemented /g111 /g110 Если операнд other – объект класса Vector (или его подкласса), то выпол- няем сравнение, как и раньше. /g111 Иначе возвращаем NotImplemented .\n--- Страница 419 ---\n419 Операторы сравнения Прогнав тесты из примера 13.12 для новой реализации Vector.__eq__ , мы полу- чим следующие результаты. Пример 13.14. Те же сравнения, что в примере 13.12, последний результат изменился >>> va = Vector([1.0, 2.0, 3.0]) >>> vb = Vector(range(1, 4))>>> va == vb # /g110 True>>> vc = Vector([1, 2])>>> from vector2d_v3 import Vector2d>>> v2d = Vector2d(1, 2)>>> vc == v2d # /g111 True>>> t3 = (1, 2, 3)>>> va == t3 # /g112 False /g110 Тот же результат, что и раньше. Как и ожидалось. /g111 Тот же результат, что и раньше. Но почему? Объяснение последует ниже. /g112 Другой результат – то, что мы и хотели. Но почему это работает? Читайте дальше… Из трех результатов в примере 13.14 первый не вызывает удивления, а два дру- гих объясняются тем, что метод __eq__ из примера 13.13 вернул NotImplemented . Рассмотрим шаг за шагом, что происходит при сравнении Vector и Vector2d . 1. Для вычисления vc == v2d Python вызывает Vector.__eq__(vc, v2d) . 2. Метод Vector.__eq__(vc, v2d) видит, что v2d не принадлежит классу Vector и возвращает NotImplemented . 3. Получив результат NotImplemented , Python вызывает Vector2d.__eq__(v2d, vc). 4. Vector2d.__eq__(v2d, vc) преобразует оба операнда в кортежи и сравнивает их, результат оказывается равен True (код метода Vector2d.__eq__ приведен в примере 9.9). При сравнении же Vector и tuple производятся следующие шаги. 1. Для вычисления va == t3 Python вызывает Vector.__eq__(va, t3) . 2. Метод Vector.__eq__(va, t3) видит, что t3 не принадлежит классу Vector и возвращает NotImplemented . 3. Получив результат NotImplemented , Python вызывает tuple.__eq__(t3, va) . 4. tuple.__eq__(t3, va) ничего не знает о классе Vector , поэтому возвращает NotImplemented . 5. Оператор == рассматривается как особый случай: если инверсный вызов вернул NotImplemented , то Python в качестве последнего средства сравнива- ет идентификаторы объектов.\n--- Страница 420 ---\n420 Глава 13. Перегрузка операторов: как правильно? А как насчет !=? Нам не нужно реализовывать этот метод, потому что поведе- ние метода __ne__ , унаследованное от object , нас вполне устраивает: если __eq__ определен и возвращает что-то, кроме NotImplemented , то __ne__ возвращает про- тивоположное значение. Иными словами, при тех же объектах, что в примере 13.14, результаты опера- тора != непротиворечивы: >>> va != vbFalse>>> vc != v2dFalse>>> va != (1, 2, 3)True Метод __ne__ , унаследованный от object , работает, как показано в следующем фрагменте, хотя в действительности он написан на C:4 def __ne__(self, other): eq_result = self == other if eq_result is NotImplemented: return NotImplemented else: return not eq_result Ошибка в документации по Python 3 Когда я пишу эти строки, в документации по методам сравнения ( https:// docs.python.org/3/reference/datamodel.html ) написано: «Из того, что x==y истинно, не следует , что x!=y ложно. Поэтому при определении метода __eq__() следует также определять метод __ne__() , чтобы оба опера- тора были согласованы». Так было в Python 2, но в случае Python 3 это пло-хой совет , потому что от класса object наследуется полезная реализация __ne__ по умолчанию, и необходимость переопределять ее возникает редко. Новое поведение документировано в статье Гвидо «Что нового в Python 3.0» ( http://bit.ly/1C11zP5 ), раздел «Операторы и специальные методы». Ошибка в документации зарегистрирована под номером 4395 (http://bugs.python.org/issue4395 ). Рассмотрев перегрузку инфиксных операторов, обратимся к операторам со- ставного присваивания. Операторы составного присваивания Наш класс Vector уже поддерживает операторы составного присваивания += и *=. В примере 13.15 они показаны в действии. 4 Логика методов object.__eq__ и object.__ne__ для интерпретатора CPython реализована в функции object_richcompare в исходном файле Objects/typeobject. c ( http://bit.ly/1C11uL7 ).\n--- Страница 421 ---\n421 Операторы составного присваивания Пример 13.15. Когда в левой части оператора составного присваивания находится неизменяемый объект , оператор создает новый экземпляр и производит перепривязку >>> v1 = Vector([1, 2, 3]) >>> v1_alias = v1 # /g110 >>> id(v1) # /g111 4302860128>>> v1 += Vector([4, 5, 6]) # /g112 >>> v1 # /g113 Vector([5.0, 7.0, 9.0])>>> id(v1) # /g114 4302859904>>> v1_alias # /g115 Vector([1.0, 2.0, 3.0])>>> v1 *= 11 # /g116 >>> v1 # /g117 Vector([55.0, 77.0, 99.0])>>> id(v1)4302858336 /g110 Создаем синоним, чтобы можно было проинспектировать объект Vector([1, 2, 3]) позже. /g111 Запоминаем идентификатор исходного объекта Vector , связанного с v1. /g112 Производим составное сложение. /g113 Результат ожидаемый… /g114 …но создан новый Vector . /g115 Инспектируем v1_alias , чтобы убедиться, что исходный Vector не изме- нился. /g116 Производим составное умножение. /g117 Результат снова ожидаемый, но создан новый Vector . Если в классе не реализованы операторы «на месте», перечисленные в табл. 13.1, то операторы составного присваивания – не более чем синтаксическая глазурь: a += b вычисляется точно так же, как a = a + b . Это ожидаемое поведение для неиз- меняемых типов и, если добавить метод __add__ , то += будет работать безо всякого дополнительного кода. Однако если все-таки реализовать метод оператора «на месте», например __iadd__ , то он и будет вызван для вычисления выражения a += b . Как следует из названия, такие операторы изменяют сам левый операнд, а не создают новый объ-ект-результат. Специальные методы, вычисляемые на месте, никогда не следует ре- ализовывать для неизменяемых типов и, в частности, нашего класса Vector . Это, в общем-то, очевидно, но лишний раз подчеркнуть не по- мешает .\n--- Страница 422 ---\n422 Глава 13. Перегрузка операторов: как правильно? Чтобы продемонстрировать код оператора «на месте», мы расширим класс BingoCage из примера 11.12, реализовав в нем методы __add__ и __iadd__ . Назовем подкласс AddableBingoCage . В примере 13.16 показано, какое поведе- ние мы ожидаем от оператора +. Пример 13.16. При создании объекта AddableBingoCage можно задать строку >>> vowels = 'AEIOU' >>> globe = AddableBingoCage(vowels) /g110 >>> globe.inspect()('A', 'E', 'I', 'O', 'U')>>> globe.pick() in vowels /g111 True>>> len(globe.inspect()) /g112 4>>> globe2 = AddableBingoCage('XYZ') /g113 >>> globe3 = globe + globe2>>> len(globe3.inspect()) /g114 7>>> void = globe + [10, 20] /g115 Traceback (most recent call last): TypeError: unsupported operand type(s) for +: 'AddableBingoCage' and 'list' /g110 Создаем объект globe с пятью элементами (все гласные буквы). /g111 Извлекаем один элемент и проверяем, что это гласная. /g112 Убеждаемся, что количество элементов в globe уменьшилось до четырех. /g113 Создаем второй экземпляр с тремя элементами. /g114 Создаем третий экземпляр, складывая первые два. В этом экземпляре семь элементов. /g115 Попытка сложить AddableBingoCage со списком приводит к исключению TypeError . Такое сообщение интерпретатор Python генерирует, когда наш метод __add__ возвращает NotImplemented . Объект AddableBingoCage изменяемый, и в примере 13.17 показано, как он ведет себя после добавления метода __iadd__ . Пример 13.17. Существующий объект AddableBingoCage можно модифицировать с помощью оператора += (продолжение примера 13.16) >>> globe_orig = globe /g110 >>> len(globe.inspect()) /g111 4 >>> globe += globe2 /g112 >>> len(globe.inspect())7>>> globe += ['M', 'N'] /g113 >>> len(globe.inspect())9>>> globe is globe_orig /g114 True\n--- Страница 423 ---\n423 Операторы составного присваивания >>> globe += 1 /g115 Traceback (most recent call last): TypeError: right operand in += must be 'AddableBingoCage' or an iterable /g110 Создаем синоним, чтобы можно было проверить идентификатор объекта позже. /g111 Здесь globe содержит четыре элемента. /g112 Объект AddableBingoCage может получать элементы от другого объекта того же класса. /g113 Правый операнд += может быть любым итерируемым объектом. /g114 В этом примере globe все время ссылается на объект globe_orig . /g115 Попытка сложить AddableBingoCage с неитерируемым объектом приводит к исключению TypeError с надлежащим сообщением. Отметим, что оператор += либеральнее, чем +, относится ко второму операнду. В случае + мы хотели, чтобы оба операнда имели одинаковый тип (в данном случае AddableBingoCage ), потому что иначе было бы непонятно, какой тип должен иметь результат. Для += ситуация проще: левый объект обновляется на месте, поэтому тип результата не вызывает сомнений. Различия в поведении операторов + и += я обосновал, наблюдая за ра- ботой встроенного типа list . Запись my_list + x позволяет конкатени- ровать только один список с другим, но если написать my_list += x , то в правой части может стоять любой итерируемый объект x. Это согласуется с поведением метода list.extend() : он принимает произвольный ите- рируемый аргумент . Поняв, чего мы хотим от класса AddableBingoCage , рассмотрим его реализацию. Пример 13.18. bingoaddable.py: класс AddableBingoCage расширяет BingoCage , добавляя поддержку операторов + и += import itertools /g110 from tombola import Tombola from bingo import BingoCage class AddableBingoCage(BingoCage): /g111 def __add__(self, other): if isinstance(other, Tombola): /g112 return AddableBingoCage(self.inspect() + other.inspect()) /g113 else: return NotImplemented def __iadd__(self, other): if isinstance(other, Tombola):\n--- Страница 424 ---\n424 Глава 13. Перегрузка операторов: как правильно? other_iterable = other.inspect() /g114 else: try: other_iterable = iter(other) /g115 except TypeError: /g116 self_cls = type(self).__name__ msg = \"right operand in += must be {!r} or an iterable\" raise TypeError(msg.format(self_cls)) self.load(other_iterable) /g117 return self /g118 /g110 В документе «PEP 8 – Style Guide for Python Code» ( https://www.python. org/dev/peps/pep-0008/#imports ) рекомендуется ставить импорт из стан- дартной библиотеки раньше импорта собственных модулей. /g111 AddableBingoCage расширяет BingoCage . /g112 Наш метод __add__ работает, только когда вторым операндом является объ- ект класса Tombola . /g113 Получаем элементы из other , если это экземпляр Tombola /g114 В противном случае пытаемся получить итератор для other .5 /g115 В случае ошибки возбуждаем исключение, объясняя пользователю, что делать. По возможности сообщения об ошибках должны содержать ясное указание, как решить проблему. /g116 Если мы дошли до этого места, то можем загрузить объект other_iterable в self . /g117 Очень важно: специальные методы операторов составного присваивания должны возвращать self . Резюмировать идею операторов «на месте» можно, сравнив предложения return , которые возвращают результаты в методах __add__ и __iadd__ из приме- ра 13.18: __add__ Результат порождается путем вызова конструктора AddableBingoCage для создания нового экземпляра. __iadd__ Результат порождается путем возврата self после модификации. И последнее замечание к примеру 13.18: в классе AddableBingoCage я сознатель- но не стал реализовывать метод __radd__ , т. к. в нем нет необходимости. Прямой метод __add__ работает, только когда правый операнд имеет тот же тип, что ле- вый, поэтому если Python попытается вычислить a + b , где a принадлежит типу AddableBingoCage , а b – нет, то получит в ответ NotImplemented – быть может, сумеет справиться класс объекта b. Но при вычислении выражения b + a , когда b не при- надлежит типу AddableBingoCage и возвращает NotImplemented , лучше позволить 5 Встроенная функция iter рассматривается в следующей главе. Здесь я мог бы написать tuple(other) , и это работало бы, но ценой построения нового кортежа, хотя методу .load(…) нужно только обойти свой аргумент.\n--- Страница 425 ---\n425 Резюме интерпретатору сдаться и возбудить исключение TypeError , поскольку мы не уме- ем обрабатывать b. В общем случае, если прямой инфиксный оператор (например, __mul__ ) предназначен для работы только с операндами того же типа, что self , бесполезно реализовывать соответствующий инверсный метод (напри-мер, __rmul__ ), потому что он, по определению, вызывается, только ког- да второй операнд имеет другой тип. На этом мы завершаем рассмотрение перегрузки операторов в Python. Резюме Мы начали эту главу с обзора ограничений, который Python налагает на перегруз-ку операторов: запрещается перегружать операторы встроенных типов, запреща-ется создавать новые операторы и перегружать операторы is, and, or и not. Потом мы занялись унарными операторами и реализовали методы __neg__ и __pos__ . Далее мы перешли к инфиксным операторам, начав с + и поддерживающе- го его метода __add__ . Мы видели, что унарные и инфиксные операторы должны возвращать новый объект в качестве результата и не должны изменять свои опе-ранды. Чтобы поддержать операции с разными типами, мы возвращаем специаль-ное значение NotImplemented – не исключение, – давая интерпретатору возмож- ность попробовать еще раз: поменять операнды местами и вызвать специальный инверсный метод, соответствующий тому же оператору (например, __radd__ ). Ал- горитм работы с инфиксными операторами в Python показан на рис. 13.1. Раз мы можем производить операции над объектами разных типов, то долж- ны уметь определять, что нам подсунули операнд, который мы не способны об-работать. Мы применяли для этого два способа: либо в духе динамической типи-зации пробовали выполнить операцию и перехватывали возможное исключение TypeError , либо – в методе __mul__ – явно проверяли тип с помощью isinstance . У обоих подходов есть свои плюсы и минусы: динамическая типизация обладает большей гибкостью, а явная проверка типов дает более предсказуемый результат. При использовании isinstance мы производили сравнение не с типом конкрет- ного класса, а с абстрактным базовым классом numbers.Real : isinstance(scalar, numbers.Real) . Это разумный компромисс между гибкостью и безопасностью, по- скольку существующие или будущие пользовательские типы можно объявить как настоящие или виртуальные подклассы ABC, как было показано в главе 11. Далее мы обсудили операторы сравнения. Мы реализовали оператор == с по- мощью метода __eq__ и выяснили, что Python предоставляет удобную реализацию оператора != в форме метода __ne__ , унаследованного от базового класса object . Эти операторы, а также >, <, >= и <= Python вычисляет несколько иначе, применяя различную логику для выбора инверсного метода и специальный запасной вари-ант для операторов == и != – в этом случае исключение никогда не возбуждается,\n--- Страница 426 ---\n426 Глава 13. Перегрузка операторов: как правильно? потому что интерпретатор в качестве последнего средства сравнивает идентифи- каторы объектов. Последний раздел был посвящен операторам составного присваивания. Мы видели, что Python по умолчанию рассматривает их как комбинацию обычного оператора и присваивания, то есть a += b вычисляется точно так же, как a = a + b . При этом всегда создается новый объект, так что оператор одинаково хорошо ра-ботает для изменяемых и неизменяемых типов. Но для изменяемых типов мы мо-жем реализовать специальные методы, вычисляемые на месте, например __iadd__ для оператора +=, и модифицировать значение левого операнда. Чтобы проде- монстрировать эту возможность, мы расстались с неизменяемым классом Vector и занялись реализацией подкласса BingoCage , поддерживающего оператор += для добавления элементов в случайный пул – по аналогии с тем, как встроенный тип list поддерживает оператор +=, являющийся сокращенной записью метода list . extend() . Попутно мы обсудили, почему оператор + ведет себя более разборчиво, чем +=, в том, что касается допустимых типов операндов. Для типов последова- тельностей + обычно требуется, чтобы оба операнда имели одинаковый тип, тогда как += зачастую принимает произвольный итерируемый объект в качестве правого операнда. Дополнительная литература Перегрузка операторов – одна из областей программирования на Python, где про-верки с помощью isinstance – обычное дело. Вообще говоря, в библиотеках сле- дует отдавать предпочтение динамической типизации – во имя большей гибкости: избегать явной проверки типов, а просто попытаться выполнить операцию и обра-ботать исключение, если оно произойдет. Это открывает возможность работать с объектами независимо от их типов при условии, что они поддерживают необходи-мые операции. Но ABC в Python допускают более строгую форму динамической типизации, которая с легкой руки Алекса Мартелли получила название «гусиной типизации». Этот подход нередко оказывается полезным в коде перегруженных операторов. Поэтому, если вы пропустили главу 11, прочитайте ее сейчас. Основным источником информации о специальных методах операторов явля- ется глава «Модель данных» ( https://docs.python.org/3/reference/datamodel.html ) справочного руководства. Но на момент написания книги в этот канонический источник вкралась досадная ошибка, упомянутая в примечании «Ошибка в доку-ментации по Python 3» выше, – написано, что «при определении метода __eq__() следует также определять метод __ne__() ». На самом деле, метод __ne__ , который в Python 3 наследуется от класса object , покрывает большинство потребностей, так что на практике реализовывать __ne__ приходится редко. Еще одна относя- щаяся к теме часть документации – раздел 9.1.2.2 «Реализация арифметических операций» ( http://bit.ly/1JHWP8W ) в описании модуля numbers стандартной би- блиотеки Python. К рассматриваемому вопросу примыкают также обобщенные функции, под- держиваемые декоратором @singledispatch в Python 3 (см. раздел «Обобщенные\n--- Страница 427 ---\n427 Поговорим функции с одиночной диспетчеризацией» главы 7). В книге David Beazley, Brian K. Jones «Python Cookbook», издание 3 (O'Reilly), есть рецепт 9.20 «Реализация множественной диспетчеризации с помощью аннотаций функций», в котором приемы метапрограммирования – с привлечением метакласса – используются для реализации основанной на типе диспетчеризации посредством аннотаций функ-ций. Во втором издании книге Martelli, Ravenscroft, Ascher «Python Cookbook» имеется интересный рецепт (2.13, принадлежит Эрику Максу Фрэнсису), где по-казано, как перегрузить оператор << для имитации синтаксиса потоков ввода-вы- вода (iostream ) в C++. В обеих книгах есть и другие примеры перегрузки операто- ров, я выбрал только самые примечательные. Функция functools.total_ordering , представляющая собой декоратор класса (поддерживается, начиная с версии Python 2.7), автоматически генерирует недо-стающие методы для всех операторов сравнения в любом классе, где есть хотя бы два из них. См. документацию по модулю functools (http://bit.ly/1C12IWF ). Если вам интересно узнать о диспетчеризации операторных методов в языках с динамической типизацией, почитайте две основополагающие работы: Дэн Ин-голллс (Dan Ingalls) (один из разработчиков Smalltalk) «A Simple T echnique for Handling Multiple Polymorphism» ( http://bit.ly/1FVhejw ) и Курт Дж. Гебель, Ральф Джонсон (Kurt J. Hebel, Ralph Johnson) «Arithmetic and Double Dispatching in Smalltalk-80» ( http://bit.ly/1QrnuuD ) (Джонсон впоследствии стал знаменит как один из авторов книги «Паттерны проектирования»). В обеих статьях глубоко проработан вопрос о полиморфизме в языках с динамической типизацией, к ка-ковым относятся Smalltalk, Python и Ruby. В Python для обработки операторов не применяется двойная диспетчеризация, описанная в этих статьях. Используемый в Python алгоритм на основе прямого и инверсного операторов проще поддержать в пользовательских классах, чем двойную диспетчеризацию, но он требует специ-ального внимания со стороны интерпретатора. Напротив, классическая двойная диспетчеризация – это общая техника, применимая как в Python, так и в любом другом объектно-ориентированном языке, – и не только в контексте инфиксных операторов. На самом деле, Инголлс, Гебель и Джонсон иллюстрируют ее на са-мых разных примерах. Статья «The C Family of Languages: Interview with Dennis Ritchie, Bjarne Stroustrup, and James Gosling» ( http://www.gotw.ca/publications/c_family_interview. htm), из которой взят эпиграф к этой главе, а также две цитаты на врезке «По- говорим», была опубликована в журналах «Java Report», 5(7), июль 2000 и «C++ Report», 12(7), июль-август, 2000. Это очень увлекательное чтение для всех, кто интересуется проектированием языков программирования. Поговорим Перегрузка операторов: за и против Джеймс Гослинг, процитированный в эпиграфе к этой главе, созна- тельно решил не включать перегрузку операторов в язык Java. В том же\n--- Страница 428 ---\n428 Глава 13. Перегрузка операторов: как правильно? интервью («The C Family of Languages: Interview with Dennis Ritchie, Bjarne Stroustrup, and James Gosling») – http://bit.ly/1C12T4t ) он гово-он гово- гово-гово- рит: Наверное, от 20 до 30 процентов людей считают перегрузку опе- раторов порождением дьявола; кто-то делал с помощью перегрузки операторов нечто такое, что напрочь выносит мозг, поскольку ис-пользование + для вставки в список способно привести в полное замешательство. Проблема проистекает, главным образом, из того, что есть всего пяток операторов, перегружать которые имеет смысл, и тысячи, а то и миллионы операторов, которые программисты хо-тели бы определить. Поэтому приходится выбирать, и зачастую вы-бор входит в противоречие с интуицией. Гвидо ван Россум выбрал средний путь: он не оставил пользователям открытую дверь для определения новых операторов, например <=> или :-), чем предотвратил возведение Вавилонской башни нестандартных операторов и переусложнение синтаксического анализатора. Python также не позволяет перегружать операторы встроенных типов, и это ограничение тоже способствует удобочитаемости и обеспечивает пред-сказуемую производительность. Гослинг продолжает: Из всего сообщества примерно 10 процентов используют пере- грузку операторов надлежащим образом и относятся к ней ответ-ственно, им она действительно необходима. Это почти исключи-тельно люди, занимающиеся численными расчетами, где нотация обязательно должна быть интуитивно очевидной; возможность на-писать « a + b», где a и b – комплексные числа, матрицы или еще что-то в этом роде, действительно полезна. Нотационный аспект проблемы нельзя недооценивать. Вот поучи- тельный пример из области финансовой математики. В Python можно вычислить сложный процент по такой формуле: interest = principal * ((1 + rate) ** periods - 1) Одна и та же нотация работает вне зависимости от используемых числовых типов. Поэтому при выполнении серьезных финансовых рас- выполнении серьезных финансовых рас- и серьезных финансовых рас- четов вы можете объявить, что periods имеет тип int, а rate , interest и principal – точные числа – объекты класса decimal.Decimal – и приве- денная формула не потребует никаких изменений. Но в Java, если для обеспечения произвольной точности вы перейде- те от типа float к типу BigDecimal , то потеряете возможность пользо- ваться инфиксными операторами, т. к. они применимы только к прими-\n--- Страница 429 ---\n429 Поговорим тивным типам. Вот как та же формула в Java записывается для работы с объектами BigDecimal : BigDecimal interest = principal.multiply(BigDecimal.ONE.add(rate) .pow(periods).subtract(BigDecimal.ONE)); Очевидно, что с инфиксными операторами формулы становятся понятными, по крайней мере, для большинства из нас6. И перегрузка операторов необходима для поддержки инфиксной нотации в типах, отличных от примитивных. Наличие перегрузки операторов в простом языке высокого уровня стало, пожалуй, основной причиной на удивле-ние широкого использования Python в научных расчетах, наблюдаемого в последние годы. Разумеется, и у решения запретить перегрузку операторов в языке есть свои плюсы. Вероятно, такое решение оправдано в низкоуровневых языках системного программирования, где производительность и без-опасность играют важнейшую роль. Гораздо более новый язык Go по-следовал в этом отношении примеру Java – перегрузка операторов в нем не поддерживается. Но при разумном использовании перегруженные операторы упро- щают чтение и написание кода. В современных высокоуровневых язы-ках эта возможность очень полезна. Беглый взгляд на отложенные вычисления Внимательно присмотревшись к обратной трассировке в приме- ре 13.9, вы заметите следы отложенного , или ленивого вычисления гене- раторных выражений. В примере 13.19 показана та же трассировка, но с выносками. Пример 13.19. Повторение примере 13.9 >>> v1 + 'ABC' Traceback (most recent call last): File \"<stdin>\", line 1, in <module> File \"vector_v6.py\", line 329, in __add__ return Vector(a + b for a, b in pairs) # /g110 File \"vector_v6.py\", line 243, in __init__ self._components = array(self.typecode, components) # /g111 File \"vector_v6.py\", line 329, in <genexpr> return Vector(a + b for a, b in pairs) # /g112 TypeError: unsupported operand type(s) for +: 'float' and 'str' /g110 Конструктору Vector передается генераторное выражение в аргументе components . Пока никаких проблем. 6 Мой друг Марио Доменик Г улар, разработчик ядра компилятора CHICKEN Scheme (http://www .callcc.org/), наверное, с этим не согласится.\n--- Страница 430 ---\n430 Глава 13. Перегрузка операторов: как правильно? /g111 Генераторное выражение components передается конструктору масси- ва array . Внутри конструктора Python пытается обойти генератор- ное выражение, что приводит к вычислению первого элемента a + b . Именно в этот момент происходит исключение TypeError . /g112 Исключение распространяется в вызов конструктора Vector и там пе- чатается сообщение о нем. Отсюда видно, что генераторное выражение вычисляется в послед- ний момент, а не там, где оно определено в исходном коде. С другой стороны, если бы конструктор Vector был вызван как Vector([a + b for a, b in pairs]) , то исключение произошло бы прямо здесь, поскольку списковое включение попыталось бы построить список для передачи в качестве аргумента конструктору Vector() . До метода Vector.__init__ дело вообще не дошло бы. Мы будем детально рассматривать генераторные выражения в гла- ве 14, но я не хотел упустить случай продемонстрировать их отложен-ную природу.\n--- Страница 431 ---\nЧАСТЬ V Поток управления",
      "debug": {
        "start_page": 403,
        "end_page": 431
      }
    },
    {
      "name": "Глава 14. Итерируемые объекты, итераторы и генераторы 432",
      "content": "--- Страница 432 --- (продолжение)\nГЛАВА 14. Итерируемые объекты, итераторы и генераторы Видя в своих программах повторяющиеся структуры, я расцениваю их как знак беды. Форма программы должна отражать задачу, которую она призвана решить, и только ее. Любые другие регулярности в коде означают, по крайней мере для меня, что я использую недостаточно вы-разительные абстракции – зачастую из-за того, что вручную расширяю макросы, которые должен был бы написать 1. – Пол Грэхем, знаток Lisp и венчурный инвестор Итерирование – одна из важнейших операций обработки данных. А если просма-тривается набор данных, не помещающийся целиком в память, то нужен способ выполнять ее отложенно , т. е. по одному элементу и по запросу. Именно в этом смысл паттерна Итератор. В этой главе мы покажем, что паттерн Итератор встро-ен в язык Python, поэтому реализовывать его вручную вам никогда не придется. В Python нет макросов, как в Lisp (любимом языке Пола Грэхема), поэтому для абстрагирования паттерна Итератор понадобилось внести изменения в язык: ключевое слово yield было добавлено только в версии Python 2.2 (2001)2. Ключевое слово yield позволяет конструировать генераторы, которые работают как итераторы. Любой генератор является итератором: генераторы реализуют весь ин- терфейс итератора. Но итератор – в том виде, как он определен в книге «банды четырех», – извлекает элементы из коллекции, тогда как генератор может порождать элементы «из воздуха». Типичным примером является генератор чисел Фибоначчи – бесконечной последовательности, которую нельзя сохранить в коллекции. Однако имейте в виду, что в сообществе Python слова итератор и генератор обычно употребляются как синонимы. 1 Из статьи в блоге «Revenge of the Nerds» ( http://www.paulgraham.com/icad.html ). 2 Пользователи Python 2.2 могли использовать yield только вместе с импортом from __future__ import generators ; в Python 2.3 это слово стало доступно по умолчанию.\nГЛАВА 14. Итерируемые объекты, итераторы и генераторы Видя в своих программах повторяющиеся структуры, я расцениваю их как знак беды. Форма программы должна отражать задачу, которую она призвана решить, и только ее. Любые другие регулярности в коде означают, по крайней мере для меня, что я использую недостаточно вы-разительные абстракции – зачастую из-за того, что вручную расширяю макросы, которые должен был бы написать 1. – Пол Грэхем, знаток Lisp и венчурный инвестор Итерирование – одна из важнейших операций обработки данных. А если просма-тривается набор данных, не помещающийся целиком в память, то нужен способ выполнять ее отложенно , т. е. по одному элементу и по запросу. Именно в этом смысл паттерна Итератор. В этой главе мы покажем, что паттерн Итератор встро-ен в язык Python, поэтому реализовывать его вручную вам никогда не придется. В Python нет макросов, как в Lisp (любимом языке Пола Грэхема), поэтому для абстрагирования паттерна Итератор понадобилось внести изменения в язык: ключевое слово yield было добавлено только в версии Python 2.2 (2001)2. Ключевое слово yield позволяет конструировать генераторы, которые работают как итераторы. Любой генератор является итератором: генераторы реализуют весь ин- терфейс итератора. Но итератор – в том виде, как он определен в книге «банды четырех», – извлекает элементы из коллекции, тогда как генератор может порождать элементы «из воздуха». Типичным примером является генератор чисел Фибоначчи – бесконечной последовательности, которую нельзя сохранить в коллекции. Однако имейте в виду, что в сообществе Python слова итератор и генератор обычно употребляются как синонимы. 1 Из статьи в блоге «Revenge of the Nerds» ( http://www.paulgraham.com/icad.html ). 2 Пользователи Python 2.2 могли использовать yield только вместе с импортом from __future__ import generators ; в Python 2.3 это слово стало доступно по умолчанию.\n--- Страница 433 ---\n433 Класс Sentence, попытка № 1: последовательность слов В Python 3 генераторы используются во многих местах. Даже встроенная функция range() теперь возвращает похожий на генератор объект, а не обычный список, как раньше. Если необходимо построить list из range , то придется делать это явно (например, list(range(100)) ). Любая коллекция в Python является итерируемым объектом , а, кроме того, итераторы используются для поддержки: • циклов for; • конструирования и пополнения коллекций;• построчного просмотра текстовых файлов;• списковых, словарных и множественных включений;• распаковки кортежей;• распаковки фактических параметров с помощью * в вызовах функций. В этой главе рассматриваются следующие темы: • как встроенная функция iter( …) используется интерпретатором для обра- ботки итерируемых объектов; • как реализовать классический паттерн Итератор в Python;• подробности работы генераторной функции, с описанием каждой строки;• как можно заменить классический Итератор генераторной функцией или генераторным выражением; • использование генераторных функций общего назначения в стандартной библиотеке; • использование нового предложения yield from для комбинирования гене- раторов; • пример: применение генераторных функций в утилите преобразования базы данных, спроектированной для работы с очень большими наборами данных; • почему генераторы и сопрограммы, несмотря на внешнюю схожесть, по су- ществу сильно различаются. Начнем с вопроса о том, как функция iter( …) делает последовательность ите- рируемой. Класс Sentence, попытка № 1: последовательность слов Исследование итерируемых объектов мы начнем с реализации класса Sentence : его конструктору передается текстовая строка, после чего ее можно перебирать слово за словом. В первой версии мы реализуем протокол последовательности, итерируемость будет достигнута за счет того, что все последовательности – итерируемые объекты, но теперь мы точно узнаем, почему . В примере 14.1 приведен класс Sentence , который умеет извлекать из текста слово с заданным индексом.\n--- Страница 434 ---\n434 Глава 14. Итерируемые объекты, итераторы и генераторы Пример 14.1. sentence.py: объект Sentence как последовательность слов import re import reprlib RE_WORD = re.compile('\\w+') class Sentence: def __init__(self, text): self.text = text self.words = RE_WORD.findall(text) /g110 def __getitem__(self, index): return self.words[index] /g111 def __len__(self): /g112 return len(self.words) def __repr__(self): return 'Sentence(%s)' % reprlib.repr(self.text) /g113 /g110 re.findall возвращает список всех непересекающихся подстрок, соответ- ствующих регулярному выражению. /g111 self.words содержит результат .findall , поэтому мы просто возвращаем слово с заданным индексом. /g112 Чтобы выполнить требования протокола последовательности, мы реали- зуем метод __len__ , – но для получения итерируемого объекта он не ну- жен. /g113 Служебная функция reprlib.repr генерирует сокращенные строковые представления структур данных, которые могут быть очень велики3. По умолчанию reprlib.repr ограничивает сгенерированную строку 30 симво- лами. В примере 14.2 показано, как используется класс Sentence . Пример 14.2. Итерирование объекта Sentence >>> s = Sentence('»The time has come,» the Walrus said,') # /g110 >>> sSentence('\"The time ha Walrus said,') # /g111 >>> for word in s: # /g112 print(word)ThetimehascometheWalrussaid 3 Впервые мы встретились с ней в разделе «V ector, попытка № 1: совместимость с V ector2d» главы 10.\n--- Страница 435 ---\n435 Класс Sentence, попытка № 1: последовательность слов >>> list(s) # /g113 ['The', 'time', 'has', 'come', 'the', 'Walrus', 'said'] /g110 По строке создается предложение – объект класса Sentence . /g111 Обратите внимание на результат __repr__ – строку, содержащую многото- чие, которая была сгенерирована функцией reprlib.repr . /g112 Объекты Sentence являются итерируемыми, скоро мы в этом убедимся. /g113 Будучи итерируемыми, объекты Sentence могут быть использованы для конструирования списков и других итерируемых типов. Далее мы разработаем другие классы Sentence , которые будут успешно про- ходить тесты из примера 14.2. Но реализация из примера 14.1 отличается от всех остальных тем, что является также последовательностью, а, значит, допускает до-ступ к слову по индексу. >>> s[0]'The'>>> s[5]'Walrus'>>> s[-1]'said' Любой программирующий на Python знает, что последовательности – итери- руемые объекты. Разберемся, почему это так. Почему последовательности итерируемы: функция iter Всякий раз как интерпретатору нужно обойти объект x, он автоматически вы- зывает функцию iter(x) . Встроенная функция iter выполняет следующие действия. 1. Смотрим, реализует ли объект метод __iter__ , и, если да, вызывает его, что- бы получить итератор. 2. Если метод __iter__ не реализован, но реализован метод __getitem__ , то Python создает итератор, который пытается извлекать элементы по поряд-ку, начиная с индекса 0. 3. Если и это не получается, то возбуждается исключение – обычно с сообще- нием « C object is not iterable», где C – класс объекта. Именно поэтому любая последовательность в Python является итерируемой: все они реализуют метод __getitem__ . На самом деле, стандартные последователь- ности реализуют и метод __iter__ , и ваши должны поступать так же, поскольку специальная обработка метода __getitem__ оставлена только ради обратной со- вместимости и может быть исключена в будущем (хотя пока не объявлена нере-комендуемой). В разделе «Python в поисках следов последовательностей» главы 11 отмеча- лось, что это крайняя форма динамической типизации: объект считается итери-\n--- Страница 436 ---\n436 Глава 14. Итерируемые объекты, итераторы и генераторы руемым не только, когда он реализует специальный метод __iter__ , но и когда реализует метод __getitem__ при условии, что тот принимает в качестве аргумента значения типа int, начинающиеся с нуля. Если подходить с точки зрения гусиной типизации, то определение итериру- емого объекта становится более простым, но не таким гибким: объект считается итерируемым, если реализует метод __iter__ . Не требуется ни наследования, ни регистрации, потому что класс abc.Iterable реализует метод __subclasshook__ (см. раздел «Г уси могут вести себя как утки» главы 11). Продемонстрируем это: >>> class Foo: def __iter__(self): pass >>> from collections import abc>>> issubclass(Foo, abc.Iterable)True>>> f = Foo()>>> isinstance(f, abc.Iterable)True Отметим, однако, что наша первоначальная версия класса Sentence не прохо- дит проверку issubclass(Sentence, abc.Iterable) , хотя на практике является ите- рируемым объектом. В версии Python 3.4 самый точный способ проверить, является ли объект x итерируемым, – вызвать iter(x) и перехватить ис- ключение TypeError , если оно возникнет . Это надежнее, чем ис- пользовать isinstance(x, abc.Iterable) , потому что iter(x) учитывает также доставшийся в наследство метод __getitem__ , а класс Iterable этого не делает . Явно проверять, является ли объект итерируемым, вряд ли стоит, если сразу после проверки вы намереваетесь обойти объект. Ведь, если попытаться обойти неитерируемый объект, Python возбудит исключение с недвусмысленным сооб-щением: TypeError: 'C' object is not iterable . Если вы можете сделать что-то более разумное, чем возбуждать TypeError , делайте это в блоке try/except , а не путем явной проверки. Явная проверка, возможно, имеет смысл, если вы хотите сохранить объект и воспользоваться им для итерирования позже; в таком случае было бы полезно обнаружить ошибку на ранней стадии. В следующем разделе мы проясним связь между итерируемыми объектами и итераторами. Итерируемые объекты и итераторы Из объяснения в разделе «Почему последовательности итерируемы: функция iter» можно вывести такое определение:\n--- Страница 437 ---\n437 Итерируемые объекты и итераторы Итерируемый объект Любой объект, от которого встроенная функция iter может получить ите- ратор. Объекты, которые реализуют метод __iter__ , возвращающий ите- ратор , являются итерируемыми. Последовательности всегда итерируемы, поскольку это объекты, реализующие метод __getitem__ , который прини- мает индексы, начинающиеся с нуля. Важно четко понимать связь между итерируемыми объектами и итераторами: Python получает итераторы от итерируемых объектов. Ниже приведен простой цикл for для обхода строки str. Строка 'ABC' здесь является итерируемым объектам. Мы этого не видим, но за кулисами прячется итератор: >>> s = 'ABC'>>> for char in s: print(char) ABC Если бы не было предложения for и мы должны были бы эмулировать меха- низм работы for вручную с помощью цикла while , то пришлось бы написать такой код: >>> s = 'ABC'>>> it = iter(s) # /g110 >>> while True: try: print(next(it)) # /g111 except StopIteration: # /g112 del it # /g113 break # /g114 ABC /g110 Получаем итератор от итерируемого объекта. /g111 В цикле вызываем метод next итератора, чтобы получить следующий эле- мент. /g112 Итератор возбуждает исключение StopIteration , когда элементы кончают- ся. /g113 Освобождаем ссылку на it – объект итератора уничтожается. /g114 Выходим из цикла. Исключение StopIteration сигнализирует об исчерпании итератора. В циклах for и в других контекстах итерирования, например в списковом включении, при распаковке кортежей и т. д., оно обрабатывается самим интерпретатором,\n--- Страница 438 ---\n438 Глава 14. Итерируемые объекты, итераторы и генераторы В стандартном интерфейсе итератора есть два метода: __next__ Возвращает следующий доступный элемент и возбуждает исключение StopIteration , когда элементов не осталось. __iter__ Возвращает self ; это позволяет использовать итератор там, где ожидается итерируемый объект, например, в цикле for. Этот интерфейс формализован в абстрактном базовом классе collections.abc. Iterator , где определен абстрактный метод __next__ , и в его подклассе Iterable , где определен абстрактный метод __iter__ (см. рис. 14.1). Рис. 14.1. Абстрактные классы Iterable и Iterator . Курсивом набраны имена абстрактных методов. Конкретный метод Iterable.iter должен возвращать новый экземпляр Iterator . Конкретный Iterator должен реализовывать метод next . Метод Iterator.iter просто возвращает ссылку на себя ABC Iterator реализует метод __iter__ , возвращая self . Это дает возможность использовать итератор всюду, где требуется итерируемый объект. Исходный код класса abc.Iterator приведен в примере 14.3 Пример 14.3. Класс abc.Iterator ; код взят из файла Lib/_collections_abc.py (http://bit.ly/1C14QOi ) class Iterator(Iterable): __slots__ = () @abstractmethod def __next__(self): 'Return the next item from the iterator. When exhausted, raise StopIteration' raise StopIteration def __iter__(self): return self @classmethod\n--- Страница 439 ---\n439 Итерируемые объекты и итераторы def __subclasshook__(cls, C): if cls is Iterator: if (any(\"__next__\" in B.__dict__ for B in C.__mro__) and any(\"__iter__\" in B.__dict__ for B in C.__mro__)): return True return NotImplemented В Python 3 абстрактный метод класса Iterator называется it.__next__() , а в Python 2 – it.next() . Как обычно, не следует вызывать специальные методы напрямую. Просто пользуйтесь встроенной функцией next(it) : она сделает все правильно – и в Python 2, и в Python 3. В исходном файле Lib/types.py ( https://hg.python.org/cpython/file/3.4/Lib/ types.py ) для версии Python 3.4 есть такой комментарий: # Итераторы в Python следует считать не типом, а протоколом. Многие # встроенные типы (их число постоянно изменяется) реализуют *какой-то*# вид итератора. Не проверяйте тип явно! Используйте вместо этого# функцию hasattr для проверки наличия атрибутов \"__iter__\" и \"__next__\". На самом деле, именно это и делает метод __subclasshook__ абстрактного класса abc.Iterator (см. пример 14.3). Принимая во внимание рекомендацию из файла Lib/types.py и логику, реализованную в файле Lib/_collections_abc.py , согласим- ся, что лучший способ узнать, является ли объект x итератором, – вызвать функцию isinstance(x, abc.Iterator) . Благодаря ме- тоду Iterator.__subclasshook__ эта проверка работает даже тогда, когда класс x не является ни настоящим, ни виртуальным подклассом Iterator . Возвращаясь к классу Sentence из примера 14.1, мы можем в интерактивной оболочке посмотреть, как итератор строится функцией iter( …) и производит обход с помощью next( …): >>> s3 = Sentence('Pig and Pepper') # /g110 >>> it = iter(s3) # /g111 >>> it # doctest: +ELLIPSIS<iterator object at 0x >>>> next(it) # /g112 'Pig'>>> next(it)'and'>>> next(it)'Pepper'>>> next(it) # /g113\n--- Страница 440 ---\n440 Глава 14. Итерируемые объекты, итераторы и генераторы Traceback (most recent call last): StopIteration>>> list(it) # /g114 []>>> list(iter(s3)) # /g115 ['Pig', 'and', 'Pepper'] /g110 Создаем предложение s3, содержащее три слова. /g111 Получаем от s3 итератор. /g112 next(it) возвращает следующее слово. /g113 Больше слов нет, поэтому итератор возбуждает исключение StopIteration . /g114 После исчерпания итератор бесполезен. /g115 Чтобы еще раз обойти предложение, нужно создать новый итератор. Поскольку от итератора требуются только методы __next__ и __iter__ , не су- ществует другого способа узнать, остались ли еще элементы, как только вызвать next() и перехватить исключение StopInteration . И «сбросить» итератор тоже не- возможно. Чтобы начать обход сначала, нужно вызвать функцию iter( …) для ите- рируемого объекта и получить от нее новый итератор. Вызов iter( …) для самого итератора не поможет, поскольку, как уже упоминалось, метод Iterator.__iter__ возвращает self , так что таким способом исчерпанный итератор не восстановить. В заключение дадим определение итератора . Итератор Любой объект, реализующий метод __next__ без аргументов, который воз- вращает следующий элемент или возбуждает исключение StopIteration , если элементов не осталось. В Python итераторы реализуют также метод __iter__ и потому сами являются итерируемыми объектами . Первая версия класса Sentence была итерируемой вследствие специальной об- работки последовательностей встроенной функцией iter( …). Теперь реализуем стандартный протокол итерируемого объекта. Класс Sentence, попытка № 2: классический вариант Следующая версия класса Sentence строится согласно классическому паттерну проектирования Итератор, который описан в книге «банды четырех». Отметим, что это не идиоматический код на Python, что станет предельно понятно, когда мы займемся его рефакторингом. Но он проясняет связь между итерируемой коллек-цией и объектом-итератором. Показанная в примере 14.4 реализация класса Sentence является итерируемой, потому что реализует специальный метод __iter__ , который конструирует и воз- вращает объект SentenceIterator . Именно так работает паттерн проектирования Итератор, который описан в книге «Паттерны проектирования».\n--- Страница 441 ---\n441 Класс Sentence, попытка № 2: классический вариант Мы поступаем так, чтобы прояснить важнейшее различие между итерируемым объектом и итератором, а также показать, как они связаны между собой. Пример 14.4. sentence_iter .py: класс Sentence , реализованный с помощью паттерна Итератор import re import reprlib RE_WORD = re.compile('\\w+')class Sentence: def __init__(self, text): self.text = text self.words = RE_WORD.findall(text) def __repr__(self): return 'Sentence(%s)' % reprlib.repr(self.text) def __iter__(self): /g110 return SentenceIterator(self.words) /g111 class SentenceIterator: def __init__(self, words): self.words = words /g112 self.index = 0 /g113 def __next__(self): try: word = self.words[self.index] /g114 except IndexError: raise StopIteration() /g115 self.index += 1 /g116 return word /g117 def __iter__(self): /g118 return self /g110 Метод __iter__ – единственное дополнение к предыдущей реализации Sentence . В этой версии нет метода __getitem__ , тем самым мы хотим до- казать, что класс является итерируемым, потому что реализует __iter__ . /g111 __iter__ выполняет требования протокола итерируемого объекта – создает и возвращает итератор. /g112 SentenceIterator хранит ссылку на список слов. /g113 self.index используется для определения следующего слова. /g114 Получаем слово с индексом self.index . /g115 Если слова с индексом self.index не существует, возбуждаем исключение StopIteration .\n--- Страница 442 ---\n442 Глава 14. Итерируемые объекты, итераторы и генераторы /g116 Увеличиваем self.index . /g117 Возвращаем слово. /g118 Реализуем метод self.__iter__ . Код из примера 14.4 проходит тесты из примера 14.2. Отметим, что этот пример работал бы и без реализации метода __iter__ в клас- се SentenceIterator , но лучше все делать правильно: предполагается, что итератор реализует оба метода __next__ и __iter__ , и если мы так сделаем, то наш итера- тор пройдет проверку issubclass(SentenceInterator, abc.Iterator) . Если бы мы унаследовали SentenceIterator от abc.Iterator , то получили бы и конкретный ме- тод abc.Iterator.__iter__ . Что-то многовато работы (по крайней мере, для нас, ленивых программистов на Python). Обратите внимание, что большая часть кода SentenceIterator зани- мается управлением внутренним состоянием итератора. Вскоре мы увидим, как сократить эту часть. Но сначала небольшое отступление, в котором мы опишем один соблазнительный способ срезать угол, который на самом деле никуда не годится. Почему идея сделать Sentence итератором плоха Типичный источник ошибок при создании итерируемых объектов и итерато- ров – путаница понятий. Поясним: у итерируемого объекта есть метод __iter__ , который при каждом обращении создает новый итератор. Итератор реализует метод __next__ , который возвращает элементы один за другим, и метод __iter__ , который возвращает self . Следовательно, итератор является итерируемым объектом, но итерируемый объект не является итератором. Возникает соблазн реализовать в классе Sentence метод __next__ в дополнение к __iter__ , и тем самым сделать экземпляр Sentence одновременно итерируемым объектом и итератором над самим собой. Но это кошмарная идея. Типичный анти-паттерн, по словам Алекса Мартелли, у которого огромный опыт рецензирования кода на Python. В разделе «Применимость» главы о паттерне Итератор в книге «банды четы- рех» написано: Используйте паттерн Итератор: • для доступа к содержимому агрегированных объектов без рас- крытия их внутреннего представления; • для поддержки нескольких активных обходов одного и того же агрегированного объекта; • для предоставления единообразного интерфейса с целью обхода различных агрегированных структур (то есть для поддержки по-лиморфной итерации).\n--- Страница 443 ---\n443 Класс Sentence, попытка № 3: генераторная функция Чтобы «поддержать несколько активных обходов», необходимо иметь возмож- ность получить несколько независимых итераторов от одного итерируемого объ-екта, причем каждый итератор должен хранить собственное внутреннее состоя-ние, поэтому для правильной реализации паттерна нужно всякий раз обращаться к функции iter(my_iterable) за новым независимым итератором. Вот почему нам был необходим класс SentenceIterator . Итерируемый объект никогда не должен выступать в роли ите- ратора для себя самого. Иными словами, итерируемые объекты должны реализовывать метод __iter__ , но не __next__ . С другой стороны, итераторы для удобства должны быть итерируемыми объектами. Просто метод __iter__ должен возвращать self . Теперь, продемонстрировав реализацию классического паттерна Итератор, мы можем отложить ее в сторонку. В следующем разделе представлена идиоматиче-ская реализация класса Sentence . Класс Sentence, попытка № 3: генераторная функция Реализация той же функциональности в духе Python основана на использовании генераторной функции для замены класса SequenceIterator . Объяснение приведе- но после примера 14.5. Пример 14.5. sentence_gen.py: реализация класса Sentence с помощью генераторной функции import re import reprlib RE_WORD = re.compile('\\w+')class Sentence: def __init__(self, text): self.text = text self.words = RE_WORD.findall(text) def __repr__(self): return 'Sentence(%s)' % reprlib.repr(self.text) def __iter__(self): for word in self.words: /g110 yield word /g111 return /g112 # это всё! /g113\n--- Страница 444 ---\n444 Глава 14. Итерируемые объекты, итераторы и генераторы /g110 Обходим self.words . /g111 Отдаем текущее слово. /g112 Этот return не нужен; функция может просто «провалиться» и вернет управление автоматически. В любом случае генераторная функция не воз-буждает исключение StopIteration : когда значений не остается, она просто выходит4. /g113 Нет нужды в отдельном классе итератора! Вот и еще одна реализация Sentence , которая проходит все тесты из приме- ра 14.2. В классе Sentence в примере 14.4 метод __iter__ конструировал и возвращал объект SentenceIterator . В примере же 14.5 итератор фактически является объ- ектом-генератором, который строится автоматически при вызове метода __iter__ , потому что __iter__ здесь – генераторная функция. Подробное объяснение генераторных функций приведено ниже. Как работает генераторная функция Любая функция в Python, в теле которой встречается ключевое слово yield , на- зывается генераторной функцией – при вызове она возвращает объект-генератор. Иными словами, генераторная функция – это фабрика генераторов. Единственное синтаксическое различие между простой и гене- раторной функцией – тот факт , что в теле последней встречается ключевое слово yield . Некоторые считают , что для генераторных функций следовало бы ввести новое ключевое слово gen вместо def, но Гвидо не согласен. Его аргументы приведены в документе «PEP 255 – Simple Generators» ( https://www.python.org/dev/peps/ pep-0255/ ).5 Вот простейшая функция для демонстрации поведения генератора6: >>> def gen_123(): # /g110 yield 1 # /g111 yield 2 yield 3 >>> gen_123 # doctest: +ELLIPSIS 4 Рецензируя этот код, Алекс Мартелли отметил, что тело этого метода можно было бы свести просто к return iter(self.words) . Он, конечно, прав: результатом вызова __iter__ и в этом слу- чае был бы итератор, как и положено. Но я воспользовался здесь циклом for с ключевым словом yield , чтобы ввести синтаксис функции-генератора, который будет подробно рассмотрен в следу- ющем разделе. 5 Иногда я включаю префикс или суффикс gen в имя генераторной функции, но это не общеупо- требительная практика. И, разумеется, нельзя это делать при реализации итерируемого объекта: обязательный специальный метод должен называться __iter__ – и никак иначе. 6 Спасибо за пример Дэвиду Квасту.\n--- Страница 445 ---\n445 Класс Sentence, попытка № 3: генераторная функция <function gen_123 at 0x > # /g112 >>> gen_123() # doctest: +ELLIPSIS<generator object gen_123 at 0x > # /g113 >>> for i in gen_123(): # /g114 print(i)123>>> g = gen_123() # /g115 >>> next(g) # /g116 1>>> next(g)2>>> next(g)3>>> next(g) # /g117 Traceback (most recent call last): StopIteration /g110 Любая функция Python, содержащая ключевое слово yield , является гене- раторной. /g111 Обычно в теле функции есть цикл, но это необязательно; здесь я просто трижды повторил слово yield . /g112 Приглядевшись, мы увидим, что gen_123 – объект-функция. /g113 Но при вызове gen_123() возвращает объект-генератор. /g114 Генератор – это итератор, который порождает значения выражений, пере- данных yield . /g115 Для более пристальной инспекции присваиваем объект-генератор пере- менной g. /g116 Поскольку g – итератор, вызов next(g) возвращает следующий элемент, по- рожденный yield . /g117 Когда выполнение доходит до конца функции, объект-генератор возбужда- выполнение доходит до конца функции, объект-генератор возбужда- е доходит до конца функции, объект-генератор возбужда- ет исключение StopIteration . Генераторная функция строит объект-генератор, обертывающий тело функ- ции. При передаче объекта-генератора функции next( …) выполнение продолжает-выполнение продолжает- е продолжает- ся до следующего предложения yield в теле функции, а вызов next( …) возвращает значение, порожденное перед приостановкой выполнения функции. Наконец, при возврате из функции обертывающий ее объект-генератор возбуждает исключение StopIteration в полном соответствии с протоколом Iterator . Я считаю, что в терминологии, касающейся получения результа- тов от генератора, лучше соблюдать строгость: я говорю, что ге-нератор отдает (yields) или порождает (produces) значения. Фраза же «генератор возвращает значения» вносит путаницу. Значения возвращают функции. Вызов генераторной функции возвращает генератор. Г енератор отдает , или порождает значения. Г енератор\n--- Страница 446 ---\n446 Глава 14. Итерируемые объекты, итераторы и генераторы не «возвращает» значение в обычном смысле слова: предложе- ние return в теле генераторной функции приводит к тому, что объект-генератор возбуждает исключение StopIteration .7 В примере 14.6 во всех подробностях описано взаимодействие между циклом for и телом функции. Пример 14.6. Г енераторная функция, печатающая сообщения во время выполнения >>> def gen_AB(): # /g110 print('start') yield 'A' # /g111 print('continue') yield 'B' # /g112 print('end.') # /g113 >>> for c in gen_AB(): # /g114 print('-->', c) # /g115 start /g116 --> A /g117 continue /g118 --> B /g119 end. ⤓ >>> ⤔ /g110 Генераторная функция определяется, как любая другая, но в теле встреча- ется ключевое слово yield . /g111 Первый неявный вызов next() в цикле for приводит к печати 'start' и приостановке после первого yield , порождающего значение 'A'. /g112 Второй неявный вызов next() в цикле for приводит к печати 'continue' и приостановке после второго yield , порождающего значение 'B'. /g113 Третий неявный вызов next() приводит к печати 'end' и возврату из функ- ции, в результате чего объект-генератор возбуждает исключение StopItera- tion . /g114 Для итерирования цикл for выполняет эквивалент предложения g = iter(gen_AB()) , чтобы получить объект-генератор а затем на каждой итера- ции вызывает next(g) . /g115 В теле цикла печатается --> и значение, полученное от next(g) . Но резуль- тат этой печати мы увидим только после строки, напечатанной функцией print внутри генераторной функции. /g116 Строка 'start' появляется в результате работы функции print('start') в теле генераторной функции. 7 До версии Python 3.3 наличие значения в предложении return внутри генераторной функ- ции считалось ошибкой. Теперь это допускается, но return все равно возбуждает исключение StopIteration . Вызывающая сторона может получить значение из объекта-исключения. Однако это имеет смысл, только когда генераторная функция используется в качестве сопрограммы, о чем будет рассказано в разделе «Возврат значения из сопрограммы» ниже.\n--- Страница 447 ---\n447 Класс Sentence, попытка № 4: ленивая реализация /g117 Предложение yield 'A' в теле генераторной функции порождает значе- ние A, потребляемое в цикле for, где оно присваивается переменной c и рас- печатывается в виде --> A . /g118 Итерирование продолжается благодаря второму вызову next(g) , продвига- ющему выполнение генераторной функции от yield 'A' к yield 'B' . Выво- дится строка continue – результат второго обращения к print в теле генера- торной функции. /g119 Предложение yield 'B' порождает значение B, потребляемое в цикле for, где оно присваивается переменной c и распечатывается в виде --> B . ⤓ Итерирование продолжается благодаря третьему вызову next(g) , продви- гающему выполнение в конец генераторной функции. Выводится строка end – результат третьего обращения к print в теле генераторной функции. ⤔ Когда генераторная функция доходит до конца, объект-генератор возбуж- дает исключение StopIteration . Цикл for перехватывает это исключение и нормально завершается. Надеюсь, теперь понятно, как работает метод Sentence.__iter__ в примере 14.5: __iter__ – генераторная функция, которая конструирует объект-генератор, реали- зующий интерфейс итератора, поэтому класс SentenceIterator больше не нужен. Вторая версия Sentence получилась гораздо короче первой, но и она не такая ленивая, какой могла бы быть. В наши дни лень считается хорошим свойством, по крайней мере, в языках программирования и API. Ленивая реализация откла-дывает порождение значений до последней возможности. Это экономит память и иногда позволяет избежать бесполезной работы. Далее мы напишем ленивый класс Sentence . Класс Sentence, попытка № 4: ленивая реализация Интерфейс Iterator спроектирован ленивым: вызов next(my_iterator) порождает по одному элементу за раз. Противоположностью ленивому вычислению является энергичное (eager) – оба термина применяются в теории языков программирования. До сих пор наши реализации Sentence не были ленивыми, потому что __init__ энергично строит список всех слов в тексте и связывает его с атрибутом self. words . Это влечет за собой обработку всего текста, а список может занять столько же памяти, сколько сам текст (возможно, больше – это зависит от того, сколько в тексте символов, не считающихся частью слова). И большая часть этой работы будет проделана напрасно, если пользователю нужны только первые два слова. Всякий раз как при работе с Python 3 возникает вопрос «Существует ли лени- вый способ сделать это?», ответ будет «да». Функция re.finditer – ленивая версия re.findall , вместо списка она возвра- щает генератор, порождающий объекты re.MatchObject по запросу. Если соответ- ствий много, то re.finditer заметно экономит память. С ее помощью мы напишем\n--- Страница 448 ---\n448 Глава 14. Итерируемые объекты, итераторы и генераторы третий – ленивый – вариант класса Sentence : он порождает следующее слово толь- ко тогда, когда это необходимо. Пример 14.7. sentence_gen2.py: реализация класса Sentence с помощью генераторной функции, которая вызывает генераторную функцию re.finditer import re import reprlib RE_WORD = re.compile('\\w+')class Sentence: def __init__(self, text): self.text = text /g110 def __repr__(self): return 'Sentence(%s)' % reprlib.repr(self.text) def __iter__(self): for match in RE_WORD.finditer(self.text): /g111 yield match .group() /g112 /g110 Хранить список слов не нужно. /g111 finditer строит итератор, который обходит все соответствия текста self. text регулярному выражению RE_WORD , порождая объекты MatchObject . /g112 match.group() извлекает сопоставленный текст из объекта MatchObject . Генераторные функции – замечательный способ сократить код, но генераторные выражения еще круче. Класс Sentence, попытка № 5: генераторное выражение Простые генераторные функции наподобие той, что использована в предыдущем варианте класса Sentence (пример 14.7), можно заменить генераторным выраже- нием. Можно считать, что генераторное выражение – ленивая версия спискового включения: она не строит список энергично, а возвращает генератор, который ле-ниво порождает элементы по запросу. Иными словами, если списковое включе-ние – это фабрика списков, то генераторное выражение – фабрика генераторов. Пример 14.8 – простая демонстрация генераторного выражения в сравнении со списковым включением. Пример 14.8. Г енераторная функция gen_AB используется сначала в списковом включении, а затем в генераторном выражении >>> def gen_AB(): # /g110 print('start') yield 'A'\n--- Страница 449 ---\n449 Класс Sentence, попытка № 5: генераторное выражение print('continue') yield 'B' print('end.') >>> res1 = [x*3 for x in gen_AB()] # /g111 startcontinueend.>>> for i in res1: # /g112 print('-->', i) --> AAA--> BBB>>> res2 = (x*3 for x in gen_AB()) # /g113 >>> res2 # /g114 <generator object <genexpr> at 0x10063c240>>>> for i in res2: # /g115 print('-->', i) start--> AAAcontinue--> BBBend. /g110 Та же генераторная функция gen_AB , что в примере 14.6. /g111 Списковое включение энергично обходит элементы, порождаемые объек- том-генератором, который был создан функцией gen_AB : 'A' и 'B'. Обрати- те внимание на печать строк start , continue , end . /g112 В этом цикле for мы обходим список res1 , порожденный списковым вклю- чением. /g113 Генераторное выражение возвращает res2 . Мы вызываем gen_AB() , но в от- вет возвращается генератор, который здесь не потребляется. /g114 res2 – объект-генератор. /g115 Только в цикле for, где производится обход res2 , выполняется тело gen_AB . На каждой итерации цикла неявно вызывается next(res2) , и выполнение gen_AB продолжается до следующего yield . Обратите внимание на то, как строки, напечатанные внутри gen_AB , чередуются с теми, что печатаются в самом цикле. Таким образом, генераторное выражение порождает генератор, и мы можем этим воспользоваться, чтобы еще сократить размер класса Sentence . Пример 14.9. sentence_genexp.py: реализация класса Sentence с помощью генераторного выражения import re import reprlib RE_WORD = re.compile('\\w+')class Sentence:\n--- Страница 450 ---\n450 Глава 14. Итерируемые объекты, итераторы и генераторы def __init__(self, text): self.text = text def __repr__(self): return 'Sentence(%s)' % reprlib.repr(self.text) def __iter__(self): return (match.group() for match in RE_WORD.finditer(self.text)) От примера 14.7 отличается только метод __iter__ , который здесь не является генераторной функцией (в нем нет слова yield ), а использует генераторное вы- ражение для построения генератора, который потом и возвращает. Конечный ре-зультат не меняется: код, вызывающий __iter__ , получает объект-генератор. Генераторные выражения – не более чем синтаксическая глазурь: их всегда можно заменить генераторными функциями, но иногда выражения удобнее. Сле-дующий раздел посвящен использованию генераторных выражений. Г енераторные выражения: когда использовать В реализации класса Vector из примера 10.16 я несколько раз пользовался гене- раторными выражениями. В каждом из методов __eq__ , __hash__ , __abs__ , angle , angles , format , __add__ , __mul__ встречается генераторное выражение. Во всех них можно было бы обойтись и списковым включением, но ценой расхода памяти на хранение промежуточных списков. В примере 14.9 мы видели, что генераторное выражение – синтаксически более короткий способ создать генератор, не определяя и не вызывая функцию. С дру-гой стороны, генераторные функции обладают большей гибкостью: в них можно закодировать сложную логику, включающую несколько предложений, и даже ис-пользовать их в качестве сопрограмм (глава 16). В простых случаях генераторного выражения достаточно, и оно легче воспри- нимается на взгляд, как показывает пример класса Vector . Я придерживаюсь такого эвристического правила: если генераторное выраже- ние занимает больше двух строк, я предпочитаю генераторную функцию – код получается понятнее. Кроме того, поскольку у генераторной функции есть имя, ее можно использовать повторно. Конечно, всегда можно поименовать генераторное выражение, присвоив его переменной, но это, пожалуй, идет вразрез с заложенной в них идеей однострочного генератора. Синтаксический совет Когда генераторное выражение передается в качестве един- ственного аргумента функции или конструктору, нет необходимо-сти указывать одну пару скобок для вызова функции и другую для обрамления генераторного выражения. Хватит и одной пары, как\n--- Страница 451 ---\n451 Другой пример: генератор арифметической прогрессии в вызове конструктора Vector из метода __mul__ в примере 10.16 (воспроизведен ниже). Однако если после генераторного выра-жения есть еще аргументы, то его необходимо заключить в скобки во избежание синтаксической ошибки: def __mul__(self, scalar): if isinstance(scalar, numbers.Real): return Vector(n * scalar for n in self) else: return NotImplemented В примерах класса Sentence мы видели, как генераторы играют роль класси- ческих итераторов: извлекают элементы из коллекции. Но генераторы можно ис-пользовать и для порождения значений безо всякого источника данных. Другой пример: генератор арифметической прогрессии Классический паттерн Итератор относится к обходу некоторой структуры дан- ных. Но стандартный интерфейс, основанный на методе извлечения следующего элемента ряда, полезен и тогда, когда элементы порождаются «на лету», а не вы-бираются из коллекции. Например, встроенная функция range генерирует огра- ниченную арифметическую прогрессию целых чисел, а функция itertools.count генерирует неограниченную арифметическую прогрессию. В следующем разделе мы рассмотрим функции itertools.count , но что, если требуется сгенерировать ограниченную арифметическую прогрессию чисел про-извольного типа? В примере 14.10 показано несколько тестов класса ArithmeticProgression , который мы вскоре напишем. Конструктор имеет сигнатуру ArithmeticProgression(begin, step[, end]) . Функция range() похожа на ArithmeticProgression , только ее полная сигнатура имеет вид range(start, stop[, step]) . Я выбрал другую сигнатуру, потому что для арифметической прогрессии шаг step обязателен, а конечное значение end – нет. Кроме того, я заменил имена аргументов start/stop на begin/end , дав понять, что сигнатура поменялась. Во всех тестах в примере 14.10 я вызываю конструктор list() для просмотра сгенериро- ванных значений. Пример 14.10. Демонстрация класса ArithmeticProgression >>> ap = ArithmeticProgression(0, 1, 3) >>> list(ap)[0, 1, 2]>>> ap = ArithmeticProgression(1, .5, 3)>>> list(ap)[1.0, 1.5, 2.0, 2.5]\n--- Страница 452 ---\n452 Глава 14. Итерируемые объекты, итераторы и генераторы >>> ap = ArithmeticProgression(0, 1/3, 1) >>> list(ap)[0.0, 0.3333333333333333, 0.6666666666666666]>>> from fractions import Fraction>>> ap = ArithmeticProgression(0, Fraction(1, 3), 1)>>> list(ap)[Fraction(0, 1), Fraction(1, 3), Fraction(2, 3)]>>> from decimal import Decimal>>> ap = ArithmeticProgression(0, Decimal('.1'), .3)>>> list(ap)[Decimal('0.0'), Decimal('0.1'), Decimal('0.2')] Отметим, что числа в получающейся арифметической прогрессии имеют тот же тип, что begin или step , – согласно общим правилам приведения числовых ти- пов в Python. В примере 14.10 мы видим список чисел типа int, float , Fraction и Decimal . В примере 14.11 показана реализация класса ArithmeticProgression . Пример 14.11. Класс ArithmeticProgression class ArithmeticProgression: def __init__(self, begin, step, end=None): /g110 self.begin = begin self.step = step self.end = end # None -> \"бесконечный\" ряд def __iter__(self): result = type(self.begin + self.step)(self.begin) /g111 forever = self.end is None 3 index = 0 while forever or result < self.end: /g113 yield result /g114 index += 1 result = self.begin + self.step * index /g115 /g110 __init__ требует двух аргументов: begin и step . Аргумент end необязатель- ный, если он равен None , ряд будет неограниченным. /g111 Эта строка порождает значение result , равное self.begin , но приведенное к типу последующих слагаемых8. /g112 Для большей понятности я завел флаг forever , который равен True , если атрибут self.end равен None , в этом случае получается неограниченный ряд. /g113 Этот цикл продолжается вечно или пока значение result не окажется боль- ше или равно self.end . По выходе из цикла завершается и функция. 8 В Python 2 была встроенная функция coerce() , но в Python 3 ее убрали, сочтя лишней, т. к. пра- вила приведения числовых типов неявно встроены в методы арифметических операторов. Поэтому единственный способ, который я смог придумать для приведения начального значения к тому же типу, что остальные члены ряда, – выполнить сложение и воспользоваться его типом для преобра-зования результата. Я задал этот вопрос в списке рассылки Python-list и получил отличный ответ от Стивена Д'Апрано ( http://bit.ly/1JIbIY O ).\n--- Страница 453 ---\n453 Другой пример: генератор арифметической прогрессии /g114 Порождается текущее значение result . /g115 Вычисляется следующий потенциальный результат. Возможно, он никогда не будет отдан, потому что цикл while завершится раньше. В последней строке я вместо того чтобы прибавлять к result значение self. step на каждой итерации, решил воспользоваться переменной index и вычислять result путем сложения self.begin с величиной self.step , умноженной на индекс. Это уменьшает накопление погрешности при работе с числами с плавающей точ-кой. Показанный выше класс ArithmeticProgression работает, как и было задумано, и дает понятный пример использования генераторной функции для реализации специального метода __iter__ . Однако если единственная цель класса – сконстру- ировать генератор в методе __iter__ , то класс можно свести к генераторной функ- ции. Ведь генераторная функция – это не что иное, как фабрика генераторов. В примере 14.12 показана генераторная функция aritprog_gen , которая делает то же самое, что класс ArithmeticProgression , но короче. Все тесты в примере 14.10 проходят, если вызывать aritprog_gen вместо ArithmeticProgression9. Пример 14.12. Г енераторная функция aritprog_gen def aritprog_gen(begin, step, end=None): result = type(begin + step)(begin) forever = end is None index = 0 while forever or result < end: yield result index += 1 result = begin + step * index Пример 14.12, конечно, впечатляет, но не забывайте: в стандартной библиотеке немало готовых генераторов, и в следующем разделе мы покажем еще более впе-чатляющую реализацию с использованием модуля itertools . Построение арифметической прогрессии с помощью itertools Модуль itertools в версии Python 3.4 содержит 19 генераторных функций, который можно комбинировать разными интересными способами. Например, функция itertools.count возвращает генератор, порождающий числа. Без аргументов порождается ряд целых чисел, начиная с 0. А если задать аргументы start и step , то получится результат очень похожий на тот, что дают наши функции aritprog_gen : >>> import itertools>>> gen = itertools.count(1, .5) 9 Каталог 14-it-generator/directory в репозитории кода к этой книге ( http://bit.ly/1JItSti ) содержит doctest-скрипты, а также скрипт aritprog_runner.py , который прогоняет все тесты для различных вариантов скриптов aritprog*.py .\n--- Страница 454 ---\n454 Глава 14. Итерируемые объекты, итераторы и генераторы >>> next(gen) 1>>> next(gen)1.5>>> next(gen)2.0>>> next(gen)2.5 Однако itertools.count никогда не останавливается, поэтому, обрабатывая вызов list(count()) , Python попытается построить список, не помещающийся в оперативную память, и ваша машина начнет сварливо брюзжать задолго до того, как вызов завершится ошибкой. С другой стороны, существует функция itertools.takewhile : она порождает генератор, который потребляет другой генератор и останавливается, когда за-данный предикат станет равен False . Объединив обе функции вместе, мы можем написать: >>> gen = itertools .takewhile(lambda n: n < 3, itertools .count(1, .5)) >>> list(gen)[1, 1.5, 2.0, 2.5] Благодаря использованию takewhile и count мы получаем изящную и короткую реализацию, показанную в примере 14.13. Пример 14.13. aritprog_v3.py: работает , как предыдущие варианты функции aritprog_gen import itertools def aritprog_gen(begin, step, end=None): first = type(begin + step)(begin) ap_gen = itertools.count(first, step) if end is not None: ap_gen = itertools.takewhile(lambda n: n < end, ap_gen) return ap_gen Отметим, что функция aritprog_gen в примере 14.13 не является генераторной функцией: в ней нет слова yield . Но она возвращает генератор, поэтому работает как фабрика генераторов, т. е. точно так же, как генераторная функция. Посыл, содержащийся в примере 14.13, прост: реализуя генераторы, нужно знать, что уже есть в стандартной библиотеке, иначе велики шансы изобрести велосипед. Вот почему в следующем разделе мы рассмотрим несколько готовых генераторных функций. Г енераторные функции в стандартной библиотеке В стандартной библиотеке есть много генераторов: от объектов построчно- го чтения текстового файла до восхитительной функции os.walk (http://bit.\n--- Страница 455 ---\n455 Генераторные функции в стандартной библиотеке ly/1HGqqwh ), которая обходит дерево каталогов и отдает имена файлов, в ре- зультате чего рекурсивный поиск оказывается не сложнее обычного цикла for. Генераторная функция os.walk впечатляет, но в этом разделе я сконцентрируюсь на функциях общего назначения, которые принимают произвольные итерируемые объекты в качестве аргументов и возвращают генераторы, порождающие выборку, результаты вычислений и элементы в другом порядке. В следующих таблицах я перечислил два десятка таких функций, встроенных и находящихся в модулях itertools и functools . Для удобства они сгруппированы по общей функциональности вне зависимости от того, где находятся. Быть может , вы знаете все упомянутые в этом разделе функции, но неко- торые из них явно недооценены, поэтому краткий обзор поможет вспом-нить, что есть в нашем распоряжении. Первая группа – фильтрующие генераторные функции: они отдают подмноже- ство элементов, порождаемых входным итерируемым объектом, не изменяя сами элементы. Ранее в этой главе, в разделе «Построение арифметической прогрессии с помощью itertools», мы уже использовали функцию itertools.takewhile . Как и takewhile , большинство перечисленных в табл. 14.1 функций принимают пре- дикат – булеву функцию с одним аргументом, которая применяется к каждому входному элементу и определяет, нужно ли отдавать его на выходе. Т аблица 14.1. Фильтрующие генераторные функции Модуль Функция Описание itertools compress(it, selector_it) Потребляет параллельно два итерируе- мых объекта; отдает элемент it, когда соответствующий элемент selector_ it принимает похожее на истину значение itertools dropwhile(predicate, it) Потребляет it, пропуская элементы, пока predicate принимает похожее на истину значение, а затем отдает все оставшиеся элементы (больше никаких проверок не делается) встроенная filter(predicate, it) Применяет предикат к каждому эле- менту итерируемого объекта, отдавая элемент , если predicate(item) прини- мает похожее на истину значение; если predicate равен None , отдаются только элементы, принимающие похожее на истину значение\n--- Страница 456 ---\n456 Глава 14. Итерируемые объекты, итераторы и генераторы Модуль Функция Описание itertools filterfalse(predicate, it) То же, что filter , но логика инвертиро- вана: отдаются элементы, для которых предиката принимает похожее на ложь значение itertools islice(it, stop) или islice(it, start, stop, step=1)Отдает элементы из среза it по аналогии с s[:stop] или s[start:stop:step] , только it может быть произвольным итерируемым объектом, а операция ле-нивая itertools takewhile(predicate, it) Отдает элементы, пока predicate при- нимает похожее на истину значение, затем останавливается, больше никаких проверок не делается В распечатке сеанса оболочки ниже показано применение всех функций из табл. 14.1 Пример 14.14. Примеры фильтрующих генераторных функций >>> def vowel(c): return c .lower() in 'aeiou' >>> list(filter(vowel, 'Aardvark'))['A', 'a', 'a']>>> import itertools>>> list(itertools.filterfalse(vowel, 'Aardvark'))['r', 'd', 'v', 'r', 'k']>>> list(itertools.dropwhile(vowel, 'Aardvark'))['r', 'd', 'v', 'a', 'r', 'k']>>> list(itertools.takewhile(vowel, 'Aardvark'))['A', 'a']>>> list(itertools.compress('Aardvark', (1,0,1,1,0,1)))['A', 'r', 'd', 'a']>>> list(itertools.islice('Aardvark', 4))['A', 'a', 'r', 'd']>>> list(itertools.islice('Aardvark', 4, 7))['v', 'a', 'r']>>> list(itertools.islice('Aardvark', 1, 7, 2))['a', 'd', 'a'] Следующая группа – отображающие генераторы: они отдают элементы, вычис- ленные для каждого элемента входного итерируемого объекта – или нескольких таких объектов, как в случае map и starmap . Генераторы, перечисленные в табл. 14.2, отдают по одному результату для каждого элемента входного итерируемого объ-екта. Если на вход подается несколько итерируемых объектов, то процесс прекра-щается, как только будет исчерпан хотя бы один из них.\n--- Страница 457 ---\n457 Генераторные функции в стандартной библиотеке Т аблица 14.2. Отображающие генераторные функции Модуль Функция Описание itertools accumulate(it, [func]) Отдает накопленные суммы; если задана функция func , то отдает результат приме- нения ее к первой паре элементов, затем к первому результату и следующему элемен-ту и т . д. встроенная enumerate(iterable, start=0) Отдает 2-кортежи вида (index, item) , где index начинается со значения start , а item извлекается из iterable встроенная map(func, it1, [it2, …, itN]) Применяет func к каждому элементу it и отдает результат; если задано N итериру- емых объектов, то func должна принимать N аргументов, и все итерируемые объекты обходятся параллельно itertools starmap(func, it) Применяет func к каждому элементу it и отдает результат; входной итерируе-мый объект должен отдавать итерируемые элементы iit , а func вызывается в виде func(*iit) В примере 14.15 демонстрируется несколько применений функции itertools. accumulate . Пример 14.15. Примеры применения генераторной функции itertools.accumulate >>> sample = [5, 4, 2, 8, 7, 6, 3, 0, 9, 1] >>> import itertools>>> list(itertools.accumulate(sample)) # /g110 [5, 9, 11, 19, 26, 32, 35, 35, 44, 45]>>> list(itertools.accumulate(sample, min)) # /g111 [5, 4, 2, 2, 2, 2, 2, 0, 0, 0]>>> list(itertools.accumulate(sample, max)) # /g112 [5, 5, 5, 8, 8, 8, 8, 8, 9, 9]>>> import operator>>> list(itertools.accumulate(sample, operator.mul)) # /g113 [5, 20, 40, 320, 2240, 13440, 40320, 0, 0, 0]>>> list(itertools.accumulate(range(1, 11), operator.mul))[1, 2, 6, 24, 120, 720, 5040, 40320, 362880, 3628800] # /g114 /g110 Частичные суммы. /g111 Частичные минимумы. /g112 Частичные максимумы. /g113 Частичные произведения. /g114 Факториалы от 1! до 10!. Применение остальных функций из табл. 10.2 иллюстрируется в примере 14.16.\n--- Страница 458 ---\n458 Глава 14. Итерируемые объекты, итераторы и генераторы Пример 14.16. Примеры применения отображающих генераторных функций >>> list(enumerate('albatroz', 1)) # /g110 [(1, 'a'), (2, 'l'), (3, 'b'), (4, 'a'), (5, 't'), (6, 'r'), (7, 'o'), (8, 'z')]>>> import operator>>> list(map(operator.mul, range(11), range(11))) # /g111 [0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100]>>> list(map(operator.mul, range(11), [2, 4, 8])) # /g112 [0, 4, 16]>>> list(map(lambda a, b: (a, b), range(11), [2, 4, 8])) # /g113 [(0, 2), (1, 4), (2, 8)]>>> import itertools>>> list(itertools.starmap(operator.mul, enumerate('albatroz', 1))) # /g114 ['a', 'll', 'bbb', 'aaaa', 'ttttt', 'rrrrrr', 'ooooooo', 'zzzzzzzz']>>> sample = [5, 4, 2, 8, 7, 6, 3, 0, 9, 1]>>> list(itertools.starmap(lambda a, b: b/a, enumerate(itertools .accumulate(sample), 1))) # 6 [5.0, 4.5, 3.6666666666666665, 4.75, 5.2, 5.333333333333333,5.0, 4.375, 4.888888888888889, 4.5] /g110 Количество букв в слове, начальное значение 1. /g111 Квадраты целых чисел от 0 до 10. /g112 Перемножение целых чисел из двух параллельных итерируемых объектов; операция заканчивается, когда будет достигнут конец более короткого объ-екта. /g113 То же самое делает встроенная функция zip. /g114 Повторение каждой буквы слова столько раз, каков номер ее позиции. Пер- вая буква повторяется 1 раз. /g115 Частичные средние. Далее идет группа объединяющих генераторов – все они отдают элемен- ты из нескольких входных итерируемых объектов. Функции chain и chain. from_iterable обходят входные итерируемые объекты последовательно (один за другим), а product , zip и zip_longest – параллельно. Т аблица 14.3. Г енераторные функции, объединяющие несколько входных итерируемых объектов Модуль Функция Описание itertools chain(it1, …, itN) Отдает все элементы из it1 , затем из it2 и т . д. itertools chain.from_iterable(it) Отдает все элементы из каждого ите- рируемого объекта, порождаемого it, перебирая их один за другим; it должен порождать итерируемые объекты, напри-мер, это может быть список итерируемых объектов\n--- Страница 459 ---\n459 Генераторные функции в стандартной библиотеке Модуль Функция Описание itertools product(it1, …, itN, repeat=1) Декартово произведение: отдает N-кортежи, полученные путем комбини-рования элементов из каждого входного итерируемого объекта, – так, как это де-лалось бы с помощью вложенных циклов for ; аргумент repeat позволяет обходить входные итерируемые объекты более од-ного раза встроенная zip(it1, …, itN) Отдает N-кортежи, построенные из эле- ментов, которые берутся параллельно из входных итерируемых объектов; операция прекращается по исчерпании самого ко-роткого объекта itertools zip_longest(it1, …, itN, fillvalue=None)Отдает N-кортежи, построенные из элемен- тов, которые берутся параллельно из вход-ных итерируемых объектов; операция пре-кращается по исчерпании самого длинного объекта, а вместо недостающих элементов подставляется значение fillvalue В примере 14.17 показано использование генераторных функций itertools. chain , zip и родственных им. Напомним, что название функции zip происходит от слова zipper (застежка-молния) и не имеет никакого отношения к алгоритму сжатия. Обе функции, zip и itertools.zip_longest , были впервые продемонстри- рованы на врезке «У дивительная функция zip» в главе 10. Пример 14.17. Примеры применения объединяющих генераторных функций >>> list(itertools.chain('ABC', range(2))) # /g110 ['A', 'B', 'C', 0, 1]>>> list(itertools.chain(enumerate('ABC'))) # /g111 [(0, 'A'), (1, 'B'), (2, 'C')]>>> list(itertools.chain.from_iterable(enumerate('ABC'))) # /g112 [0, 'A', 1, 'B', 2, 'C']>>> list(zip('ABC', range(5))) # /g113 [('A', 0), ('B', 1), ('C', 2)]>>> list(zip('ABC', range(5), [10, 20, 30, 40])) # /g114 [('A', 0, 10), ('B', 1, 20), ('C', 2, 30)]>>> list(itertools.zip_longest('ABC', range(5))) # /g115 [('A', 0), ('B', 1), ('C', 2), (None, 3), (None, 4)]>>> list(itertools.zip_longest('ABC', range(5), fillvalue='?')) # /g116 [('A', 0), ('B', 1), ('C', 2), ('?', 3), ('?', 4)] /g110 chain обычно вызывается с двумя и более итерируемыми объектами. /g111 При вызове с одним итерируемым объектом chain не делает ничего полез- ного.\n--- Страница 460 ---\n460 Глава 14. Итерируемые объекты, итераторы и генераторы /g112 Но chain.from_iterable берет каждый элемент из итерируемого объекта и сцепляет их в последовательность при условии, что каждый элемент сам является итерируемым объектом. /g113 zip обычно используется для объединения двух итерируемых объектов в ряд 2-кортежей. /g114 zip может параллельно обходить произвольное количество итерируемых объектов, но генератор останавливается, как только один из них будет ис-черпан. /g115 itertools.zip_longest работает, как zip, но не останавливается, пока не бу- дут исчерпаны все итерируемые объекты; вместо недостающих элементов в данном случае подставляется None . /g116 Аргумент fillvalue задает подстановочное значение. Функция itertools.product дает ленивый способ вычисления декартовых произведений, в разделе «Декартовы произведения» главы 2 мы строили их с по-мощью списковых включений с несколькими фразами for. Для ленивого порож- дения декартовых произведений можно также использовать генераторные выра-жения с несколькими фразами for. В примере 14.18 демонстрируется функция itertools.product . Пример 14.18. Примеры применения генераторной функции itertools.product >>> list(itertools.product('ABC', range(2))) # /g110 [('A', 0), ('A', 1), ('B', 0), ('B', 1), ('C', 0), ('C', 1)]>>> suits = 'spades hearts diamonds clubs'.split()>>> list(itertools.product('AK', suits)) # /g111 [('A', 'spades'), ('A', 'hearts'), ('A', 'diamonds'), ('A', 'clubs'),('K', 'spades'), ('K', 'hearts'), ('K', 'diamonds'), ('K', 'clubs')]>>> list(itertools.product('ABC')) # /g112 [('A',), ('B',), ('C',)]>>> list(itertools.product('ABC', repeat=2)) # /g113 [('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'B'),('B', 'C'), ('C', 'A'), ('C', 'B'), ('C', 'C')]>>> list(itertools.product(range(2), repeat=3))[(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 0, 0),(1, 0, 1), (1, 1, 0), (1, 1, 1)]>>> rows = itertools.product('AB', range(2), repeat=2)>>> for row in rows: print(row) ('A', 0, 'A', 0)('A', 0, 'A', 1)('A', 0, 'B', 0)('A', 0, 'B', 1)('A', 1, 'A', 0)('A', 1, 'A', 1)('A', 1, 'B', 0)('A', 1, 'B', 1)('B', 0, 'A', 0)('B', 0, 'A', 1)('B', 0, 'B', 0)\n--- Страница 461 ---\n461 Генераторные функции в стандартной библиотеке ('B', 0, 'B', 1) ('B', 1, 'A', 0)('B', 1, 'A', 1)('B', 1, 'B', 0)('B', 1, 'B', 1) /g110 Декартово произведение строки str из трех символов и диапазона range из двух целых чисел дает шесть кортежей (потому что 3 * 2 = 6 ). /g111 Произведение двух достоинств карт ( 'AK' ) и четырех мастей дает ряд из восьми кортежей. /g112 Если задан один итерируемый объект, то product порождает ряд 1-корте- жей, что не очень полезно. /g113 Но если дополнительно задан именованный аргумент repeat=N , то product обходит каждый входной итерируемый объект N раз. Некоторые генераторные функции расширяют свой аргумент, отдавая более одного значения для каждого входного элемента. Они перечислены в табл. 14.4. Т аблица 14.4. Г енераторные функции, расширяющие каждый входной элемент в несколько выходных Модуль Функция Описание itertools combinations(it, out_len) Отдает комбинации out_len элементов из элементов, отдаваемых it itertools combinations_with_replacement (it, out_len)Отдает комбинации out_len элементов из элементов, отдаваемых it, включая комбинации с повторяющимися элемен-тами itertools count(start=0, step=1) Отдает числа, начиная с start с шагом step itertools cycle(it) Отдает элементы из it, запоминая ко- пию каждого, после чего отдает всю по-следовательность еще раз – и так до бес- конечности itertools permutations(it, out_len=None) Отдает перестановки out_len элементов из элементов, отдаваемых it; по умолча- нию out_len равно len(list(it)) itertools repeat(item, [times]) Повторно отдает заданный элемент – times раз или бесконечно, если этот ар- гумент не задан Функции count и repeat из модуля itertools возвращают генераторы, кото- рые извлекают элементы «из воздуха»: ни одна из них не принимает итерируемый объект в качестве аргумента. Как работает функция itertools.count , мы видели в разделе «Построение арифметической прогрессии с помощью itertools» выше.\n--- Страница 462 ---\n462 Глава 14. Итерируемые объекты, итераторы и генераторы Генератор cycle создает внутреннюю копию входного итерируемого объекта и в бесконечном цикле отдает его элементы снова и снова. Пример 14.19. Функции count , cycle и repeat >>> ct = itertools.count() # /g110 >>> next(ct) # /g111 0>>> next(ct), next(ct), next(ct) # /g112 (1, 2, 3)>>> list(itertools.islice(itertools.count(1, .3), 3)) # /g113 [1, 1.3, 1.6]>>> cy = itertools.cycle('ABC') # /g114 >>> next(cy)'A'>>> list(itertools.islice(cy, 7)) # /g115 ['B', 'C', 'A', 'B', 'C', 'A', 'B']>>> rp = itertools.repeat(7) # /g116 >>> next(rp), next(rp)(7, 7)>>> list(itertools.repeat(8, 4)) # /g117 [8, 8, 8, 8]>>> list(map(operator.mul, range(11), itertools.repeat(5))) # /g118 [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50] /g110 count создает генератор ct. /g111 Получить от ct первый элемент. /g112 Построить из ct список невозможно, т. к. ct никогда не останавливается, поэтому я просто получаю следующие три элемента. /g113 Построить список с помощью генератора count можно, если он ограничен с помощью функции islice или takewhile . /g114 Строим генератор cycle из 'ABC' и получаем от него первый элемент – 'A'. /g115 Список можно построить, только если наложить ограничение с помощью islice ; здесь извлекаются следующие семь элементов. /g116 Строим генератор repeat , который вечно отдает число 7. /g117 Генератор repeat можно ограничить, передав аргумент times : данном случае число 8 отдается 4 раза. /g118 Типичное применение repeat : подстановка фиксированного аргумента в функцию map: в данном случае подставляется множитель 5. Генераторные функции combinations , combinations_with_replacement и per- mutations – вместе с product – в документации itertools называются комбина- торными генераторами (http://bit.ly/py-itertools ). Существует тесная связь между itertools.product и остальными комбинаторными функциями (см. пример 14.20). Пример 14.20. Комбинаторные генераторные функции отдают несколько значений для каждого входного элемента >>> list(itertools.combinations('ABC', 2)) # /g110 [('A', 'B'), ('A', 'C'), ('B', 'C')]\n--- Страница 463 ---\n463 Генераторные функции в стандартной библиотеке >>> list(itertools.combinations_with_replacement('ABC', 2)) # /g111 [('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'B'), ('B', 'C'), ('C', 'C')]>>> list(itertools.permutations('ABC', 2)) # /g112 [('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'C'), ('C', 'A'), ('C', 'B')]>>> list(itertools.product('ABC', repeat=2)) # /g113 [('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'B'), ('B', 'C'),('C', 'A'), ('C', 'B'), ('C', 'C')] /g110 Все комбинации длины len()==2 из элементов строки 'ABC' ; порядок эле- ментов в сгенерированных кортежах неважен (они могли бы быть и множе-ствами). /g111 Все комбинации длины len()==2 из элементов строки 'ABC' , включая ком- бинации с повторяющимися элементами. /g112 Все перестановки длины len()==2 из элементов строки 'ABC' ; порядок эле- ментов в сгенерированных кортежах важен. /g113 Декартово произведение 'ABC' и 'ABC' (это результат задания параметра repeat=2 ). Последняя рассматриваемая в этом разделе группа генераторных функций предназначена для того, чтобы отдавать все элементы входных итерируемых объ-ектов, но в каком-то другом порядке. Следующие две функции возвращают не-сколько генераторов: itertools.groupby и itertools.tee . Другая генераторная функция из этой группы, встроенная функция reversed , – единственная из опи- санных в этом разделе, которая принимает не произвольный итерируемый объект, а только последовательности. Это и понятно, ведь reversed отдает элементы в об- ратном порядке, а это возможно только для последовательности известной длины. Но накладных расходов на создание инвертированной копии последовательности эта функция не несет – она возвращает элементы по запросу. Я поместил функцию itertools.product в одну группу с объединяющими генераторами в табл. 14.3, по- тому что все они обходят более одного итерируемого объекта, тогда как генерато-ры, перечисленные в табл. 14.5, принимают не больше одного такого объекта. Т аблица 14.4. Г енераторные функции, расширяющие каждый входной элемент в несколько выходных Модуль Функция Описание itertools groupby(it, key=None) Порождает 2-кортежи вида ( key , group ), где key – критерий группировки, а group – генератор, от- дающий элементы группы встроенная reversed(seq) Отдает элементы seq в обратном порядке, от по- следнего к первому; аргумент seq должен быть последовательностью или реализовывать специ-альный метод __reversed__ itertools tee(it, n=2) Отдает кортеж n генераторов, каждый из которых независимо отдает элементы входного итерируе- мого объекта\n--- Страница 464 ---\n464 Глава 14. Итерируемые объекты, итераторы и генераторы В примере 14.21 демонстрируется использование функций itertools.groupby и the reversed . Отметим, что itertools.groupby ожидает, что входной итерируемый объект отсортирован в соответствии с критерием группировки или, по крайней мере, что элементы, удовлетворяющие этому критерию, идут подряд, пусть даже и не по порядку. Пример 14.21. itertools.groupby >>> list(itertools.groupby('LLLLAAGGG')) # /g110 [('L', <itertools._grouper object at 0x102227cc0>),('A', <itertools._grouper object at 0x102227b38>),('G', <itertools._grouper object at 0x102227b70>)]>>> for char, group in itertools.groupby('LLLLAAAGG'): # /g111 print(char, '->', list(group)) L -> ['L', 'L', 'L', 'L']A -> ['A', 'A',]G -> ['G', 'G', 'G']>>> animals = ['duck', 'eagle', 'rat', 'giraffe', 'bear', 'bat', 'dolphin', 'shark', 'lion']>>> animals.sort(key=len) # /g112 >>> animals['rat', 'bat', 'duck', 'bear', 'lion', 'eagle', 'shark','giraffe', 'dolphin']>>> for length, group in itertools.groupby(animals, len): # /g113 print(length, '->', list(group)) 3 -> ['rat', 'bat']4 -> ['duck', 'bear', 'lion']5 -> ['eagle', 'shark']7 -> ['giraffe', 'dolphin']>>> for length, group in itertools.groupby(reversed(animals), len): # /g114 print(length, '->', list(group)) 7 -> ['dolphin', 'giraffe']5 -> ['shark', 'eagle']4 -> ['lion', 'bear', 'duck']3 -> ['bat', 'rat']>>> /g110 groupby отдает кортежи (key, group_generator) . /g111 Для работы с генераторами, порожденными groupby , необходимы вложен- ные итерации: в данном случае внешний цикл for и внутренний конструк- тор list . /g112 Для использования groupby входной объект должен быть отсортирован; в данном случае слова отсортированы по длине. /g113 Еще один цикл по парам ( key, group ), чтобы вывести ключ и развернуть группу в список. /g114 Здесь генератор reversed используется для обхода animals справа нале- во.\n--- Страница 465 ---\n465 yield from – новая конструкция в Python 3.3 Последняя генераторная функция в этой группе, iterator.tee , обладает уни- кальным поведением: она порождает несколько генераторов для одного входного итерируемого объекта, каждый из которых отдает все элементы этого объекта. Эти генераторы можно потреблять независимо, как показано в примере 14.22. Пример 14.22. itertools.tee порождает несколько генераторов, каждый из которых отдает все элементы входного итерируемого объекта >>> list(itertools.tee('ABC')) [<itertools._tee object at 0x10222abc8>, <itertools._tee object at 0x10222ac08>]>>> g1, g2 = itertools.tee('ABC')>>> next(g1)'A'>>> next(g2)'A'>>> next(g2)'B'>>> list(g1)['B', 'C']>>> list(g2)['C']>>> list(zip(*itertools.tee('ABC')))[('A', 'A'), ('B', 'B'), ('C', 'C')] Отметим, что в нескольких примерах из этого раздела использовались комби- нации генераторных функций. Это возможно, потому что все они принимают ге-нераторы в качестве аргументов и возвращают генераторы. И раз уж мы заговорили о комбинировании генераторов, рассмотрим предло- жение yield from , появившееся в версии Python 3.3, которое как раз для этого и предназначено. yield from – новая конструкция в Python 3.3 Вложенные циклы for – традиционное решение в случае, когда генераторная функция должна отдавать значения, порождаемые другим генератором. Вот, например, доморощенная реализация сцепляющего генератора10: >>> def chain(*iterables): for it in iterables: for i in it: yield i >>> s = 'ABC'>>> t = tuple(range(3))>>> list(chain(s, t))['A', 'B', 'C', 0, 1, 2] 10 Функция itertools.chain из стандартной библиотеки написана на C.\n--- Страница 466 ---\n466 Глава 14. Итерируемые объекты, итераторы и генераторы Генераторная функция chain дает шанс поработать каждому полученному ите- рируемому объекту по очереди. В документе «PEP 380 – Syntax for Delegating to a Subgenerator» ( http://bit.ly/1wpQv0i ) описан новый синтаксис для решения этой задачи, он показан в распечатке сеанса ниже: >>> def chain(*iterables): for i in iterables: yield from i >>> list(chain(s, t))['A', 'B', 'C', 0, 1, 2] Как видим, yield from i полностью заменяет внутренний цикл for. Конструк- ция yield from здесь используется правильно, и код действительно смотрится лучше, но в таком виде это всего лишь синтаксическая глазурь. Помимо замены цикла, yield from создает прямой канал между внутренним генератором и клиен- том внешнего генератора. И этот канал становится по-настоящему важен, когда генераторы используются в роли сопрограмм и не только порождают, но и потре-бляют значения из клиентского кода. Сопрограммы подробно рассматриваются в главе 16, где на нескольких страницах объясняется, почему yield from гораздо больше, чем синтаксическая глазурь. Познакомившись с yield from , вернется к обзору имеющихся в стандартной библиотеке функций для работы с итераторами. Функции редуцирования итерируемого объекта Все функции, перечисленные в табл. 14.6, принимают итерируемый объект и воз- вращают единственный результат. Их называют «редуцирующими», «сворачива-ющими» или «аккумулирующими». На самом деле, все эти функции можно было бы реализовать с помощью functools.reduce , но они сделаны встроенными, чтобы было проще решать часто встречающиеся задачи. Кроме того, для all и any про- изведена важная оптимизация, которая при использовании reduce была бы невоз- можна: эти функции закорочены (т. е. прекращают обход итератора, как только результат становится известен). См. последний тест функции any в примере 14.23. Т аблица 14.6. Встроенные функции, которые читают итерируемый объект и возвращают одиночное значение Модуль Функция Описание встроенная all(it) Возвращает True , если все элементы it при- нимают истинное значение, в противном слу-чае False ; all([]) возвращает True встроенная any(it) Возвращает True , если хотя бы один элемент it принимает истинное значение, в против- ном случае False ; any([]) возвращает False\n--- Страница 467 ---\n467 Функции редуцирования итерируемого объекта Модуль Функция Описание встроенная max(it, [key=,] [default=]) Возвращает максимальный элемент it;a key – функция порядка, как в sorted ; значе- ние default возвращается, если итерируе- мый объект пуст встроенная min(it, [key=,] [default=]) Возвращает минимальный элемент it;b key – функция порядка, как в sorted ; значе- ние default возвращается, если итерируе- мый объект пуст itertools reduce(func, it, [initial]) Возвращает результат выполнения следую- щей процедуры: функция func применяется к первым двум элементами, затем к результату и третьему элементу и т . д. Если задан аргу-мент initial , то он образует начальную пару вместе с первым элементом встроенная sum(it, start=0) Сумма всех элементов it, к которой может быть прибавлено значение start , если оно задано (для получения большей точности при сложении чисел с плавающей точкой пользуй- тесь функцией math.fsum ) a Может также вызываться в виде max(arg1, arg2, …, [key=?]) , тогда возвращается максимальный аргумент . b Может также вызываться в виде min(arg1, arg2, …, [key=?]) , тогда возвращается минимальный аргумент . Работа all и any демонстрируется в примере 14.23. Пример 14.23. Результаты применения all и any к некоторым последовательностям >>> all([1, 2, 3]) True>>> all([1, 0, 3])False>>> all([])True>>> any([1, 2, 3])True>>> any([1, 0, 3])True>>> any([0, 0.0])False>>> any([])False>>> g = (n for n in [0, 0.0, 7, 8])>>> any(g)True>>> next(g)8\n--- Страница 468 ---\n468 Глава 14. Итерируемые объекты, итераторы и генераторы Более пространное объяснение функции functools.reduce приведено в разделе «V ector, попытка № 4: хэширование и ускорение оператора ==» главы 10. Встроенная функция sorted также принимает итерируемый объект и возвра- щает нечто иное. В отличие от генераторной функции reversed , sorted строит и возвращает настоящий список. В конце концов, каждый элемент входного итери-руемого объекта можно прочитать, а, раз так, то их можно и отсортировать, причем сортировке подвергается список list , а, значит, его sorted и возвращает. Я упомя- нул sorted в этом месте, потому что она все-таки принимает произвольный итери- руемый объект. Конечно, sorted и редуцирующие функции работают только с конечными ите- рируемыми объектами. В противном случае они будут без конца получать элемен-ты и никогда не вернут результат. А теперь вернемся к встроенной функции iter() : у нее есть одно малоизвест- ное свойство, о котором мы пока не говорили. Более пристальный взгляд на функцию iter Мы видели, что Python вызывает iter(x) , когда ему требуется обойти объект x. Но у iter в запасе есть еще один трюк: ее можно вызывать с двумя аргумента- ми для создания итератора из обычной функции или произвольного вызываемого объекта. При таком использовании первый аргумент должен быть вызываемым объектом, который будет повторно вызываться (без аргументов) для порождения значений, а второй аргумент является ограничителем – если вызываемый объект возвращает такое значение, то итератор не отдает его, а возбуждает исключение StopIteration . В следующем примере показано, как использовать iter для бросания шести- гранной кости до тех пор, пока не выпадет 1: >>> def d6(): return randint(1, 6) >>> d6_iter = iter(d6, 1)>>> d6_iter<callable_iterator object at 0x00000000029BE6A0>>>> for roll in d6_iter: print(roll) 4363 Отметим, что функция iter здесь возвращает вызываемый итератор ( callable_ iterator ). Цикл for в этом примере может работать очень долго, но никогда не покажет 1, поскольку это значение-ограничитель. Как и любой итератор, объект\n--- Страница 469 ---\n469 Пример: генераторы в утилите преобразования базы данных d6_iter после исчерпания становится бесполезен. Чтобы начать сначала, необхо- димо получить новый итератор, еще раз вызвав iter( …). Полезный пример имеется в документации по встроенной функции iter (http://bit.ly/1HGqw70 ). В этом фрагменте мы читаем строки из файла, пока не встретится пустая строка или конец файла: with open('mydata.txt') as fp: for line in iter(fp.readline, ''): process_line(line) В заключение главы я приведу практический пример использования генерато- ров для эффективной обработки данных очень большого объема. Пример: генераторы в утилите преобразования базы данных Несколько лет назад я работал в BIREME, цифровой библиотеке под патрона- жем P AHO/WHO (Панамериканская организация здравоохранения/Всемирная организация здравоохранения) в Сан-Паулу, Бразилия. В числе библиографиче-ских наборов данных, создаваемых BIREME, есть LILACS (Библиографический указатель по здравоохранению в Латинской Америке и на Карибских островах) и SciELO (Онлайновая научная электронная библиотека). Это две очень полные базы данных с описанием научно-технической литературы, издаваемой в регионе. С конца 1980-х годов для управления базой данных LILACS используется CDS/ ISIS, нереляционная документная СУБД, созданная ЮНЕСКО и в конечном итоге переписанная на C силами BIREME для выполнения на серверах GNU/Linux. Частью моей работы было исследование возможностей переноса LILACS, а затем и гораздо более объемной SciELO, на современную СУБД с открытым исходным кодом, например CouchDB или MongoDB. По ходу дела я написал на Python скрипт isis2json.py , который читает файл CDS/ ISIS и записывает файл в формате JSON, пригодный для импорта в CouchDB или MongoDB. Первоначально скрипт читал файлы в формате ISO-2709, экспортиру-емые CDS/ISIS. Чтение и запись приходилось выполнять по частям, потому что полный набор данных был гораздо больше объема оперативной памяти. Это было не очень сложно: на каждой итерации главного цикла for прочитать одну запись из iso-файла, обработать ее и записать в json-файл. Однако по причинам эксплуатационного свойства необходимо было, чтобы скрипт isis2json.py поддерживал еще один формат данных CDS/ISIS: двоичные mst-файлы, используемые в производственной системе BIREME, – чтобы избе-жать дорогостоящего экспорта в формат ISO-2709. Но тут возникла проблема: библиотеки для чтения файлов в формате ISO-2709 и mst-файлов имели совершенно разные API. А цикл вывода JSON и так уже был достаточно сложным, поскольку скрипт принимал разнообразные параметры ко-мандной строки, управляющие структурой выходной записи. Чтение данных с по-\n--- Страница 470 ---\n470 Глава 14. Итерируемые объекты, итераторы и генераторы мощью двух разных API в одном и том же цикле for, где еще и порождался JSON, оказалось бы очень громоздким. Было принято решение инкапсулировать логику чтения в двух генератор- ных функциях, по одной для каждого поддерживаемого формата. В итоге скрипт isis2json.py распался на четыре функции. Головной скрипт приведен в приме- ре A-5, а полный исходный код со всеми зависимостями находится в каталоге fluentpython/isis2json (http://bit.ly/1HGqzzT ) на GitHub. Приведу общее описание структуры скрипта. main Функция main вызывает argparse для разбора параметров командной стро- ки, управляющих структурой выходных записей. В зависимости от расши-рения имени входного файла выбирается та или иная генераторная функ-ция для чтения данных и отдачи записей по одной. iter_iso_records Эта генераторная функция читает iso-файлы (в формате ISO-2709). Она принимает два аргумента: имя файла и флаг isis_json_type , относящийся к структуре записи. На каждой итерации своего цикла for она читает одну запись, создает пустой словарь, заполняет его данными полей и отдает объ-ект dict . iter_mst_records Эта генераторная функция читает mst-файлы11. Заглянув в исходный код isis2json.py , вы увидите, что она не так проста, как iter_iso_records , но ее интерфейс и общая структура такие же: принимает имя файла и аргумент isis_json_type , затем входит в цикл for, где на каждой итерации строит и от- дает объект dict , представляющий одну запись. write_json Эта функция выводит JSON-записи, по одной за раз. У нее много аргу- ментов, но самый первый – input_gen – содержит ссылку на генератор- ную функцию: iter_iso_records или iter_mst_records . Главный цикл for в функции write_json потребляет словари, которые отдает генератор input_ gen, обрабатывает их различными способами, определяемыми параметрами в командной строке, и дописывает JSON-запись в конец выходного файла. Воспользовавшись генераторными функциями, я смог разделить логику чте- ния и записи. Конечно, проще всего это было бы сделать, прочитав сразу все за-писи в память, затем обработать их и записать на диск в другом формате. Но из-за размера набора данных такое решение не проходит. Благодаря генераторам чтение и запись чередуются, так что скрипт может обрабатывать файлы любого размера. 11 Библиотека для чтения сложных двоичных mst-файлов написана на Java, так что эта функциональ- ность доступна, только когда скрипт isis2json.py выполняется интерпретатором Jython версии не ниже 2.5. Дополнительные сведения см. в файле README.rst (http://bit.ly/1MM5aXD ) в репози- тории. Зависимости импортируются в генераторных функциях, которым они необходимы, так что скрипт может работать, даже если доступна только одна из внешних библиотек.\n--- Страница 471 ---\n471 Генераторы как сопрограммы А если скрипту isis2json.py понадобится поддержать еще один формат ввода – скажем, MARCXML, который используется в Библиотеке конгресса США для представления данных в формате ISO-2709, – то можно будет без труда добавить третью генераторную функцию, которая реализует логику его чтения, ничего не меняя в сложной функции write_json . Это, конечно, не высшая математика, но реальный пример, когда с помощью генераторов удалось построить гибкое решение для обработки базы данных в виде потока записей, так что потребление памяти остается низким вне зависимости от объема данных. Любой программист, работающий с большими наборами данных, найдет много возможностей использовать генераторы на практике. В следующем разделе речь пойдет об аспекте генераторов, который мы до сих пор не затрагивали. Читайте дальше, если хотите узнать, почему . Г енераторы как сопрограммы Примерно через пять лет после появления в версии Python 2.2 генераторных функ-ций с ключевым словом yield в версии 2.5 был реализован документ «PEP 342 – Coroutines via Enhanced Generators» ( https://www.python.org/dev/peps/pep-0342/ ). В этом предложении были описаны дополнительные методы и функциональность объектов-генераторов и, в первую очередь, метод .send() . Как и .__next__() , метод .send() продолжает выполнение генератора до сле- выполнение генератора до сле- е генератора до сле- дующего ключевого слова yield , но еще позволяет клиенту посылать генерато- ру данные: аргумент, переданный .send() , становится значением, которое отдает выражение yield внутри тела генераторной функции. Другими словами, .send() обеспечивает двусторонний обмен между генератором и клиентским кодом – в противоположность .__next__() , который позволяет клиенту только получать данные от генератора. Это «усовершенствование» настолько кардинально, что фактически изменяет природу генераторов: при таком использовании они становится сопрограммами . Дэвид Бизли – пожалуй, самый плодовитый член сообщества Python во всем, что касается сопрограмм, – предупреждал в знаменитом пособии, представленном на конференции PyCon US 2009 ( http://www.dabeaz.com/coroutines/ ): • генераторы порождают данные для итерирования; • сопрограммы являются потребителями данных;• если не хотите, чтобы сорвало крышу, не путайте эти две концепции;• сопрограммы не имеют никакого отношения к итерированию;• Примечание: у применения yield для порождения значения в со- программе есть свои резоны, но с итерированием они не связаны12. – Дэвид Бизли «A Curious Course on Coroutines and Concurrency» 12 Слайд 33 «Keeping It Straight» из презентации «A Curious Course on Coroutines and Concurrency» (http://www.dabeaz.com/coroutines/Coroutines.pdf ).\n--- Страница 472 ---\n472 Глава 14. Итерируемые объекты, итераторы и генераторы Я последую совету Дэйва и закончу эту главу – которая все-таки посвящена приемам итерирования, – не касаясь метода send и других средств, благодаря ко- торым генераторы можно использовать как сопрограммы. Сопрограммы мы будем рассматривать в главе 16. Резюме Итерирование так глубоко укоренилось в языке, что я часто говорю, что Python пропитан итераторами 13. Интеграция паттерна Итератор в семантику Python – яркий пример того, что паттерны проектирования не в одинаковой степени при-менимы во всех языках. В Python классический итератор, реализованный «вруч-ную», как в примере 14.4, не имеет никакой практической ценности, кроме разве что педагогической. В этой главе мы написали несколько вариантов класса для обхода слов в тек- стовом файле, возможно, очень длинном. Благодаря генераторам каждая последу-ющая версия класса Sentence становилась короче и понятнее – если знать, как она работает. Затем мы написали генератор арифметических прогрессий и показали, как с помощью модуля itertools упростить его. Далее мы познакомились с 24 генера- торными функциями общего назначения из стандартной библиотеки. После этого мы занялись встроенной функцией iter : во-первых, увидели, что она возвращает итератор при обращении вида iter(o) , а затем поняли, как с ее по- мощью превратить любую функцию в итератор, если обратиться так: iter(func, sentinel) . В качестве практического примера я описал реализацию утилиты преобразо- вания базы данных, в которой генераторы позволили разделить логику чтения и записи и тем самым эффективно обработать данные очень большого объема, а за-одно поддержать дополнительные форматы входных данных. В этой главе я упомянул также синтаксическую конструкцию yield from , по- явившуюся в версии Python 3.3, и сопрограммы. Обе темы были лишь слегка за-тронуты, подробнее мы рассмотрим их позже. Дополнительная литература Детальное техническое описание генераторов можно найти в разделе 6.2.9 «Выра-жения yield» справочного руководства по языку Python ( http://bit.ly/1MM5Xb5 ). Генераторные функции были впервые определены в документе «PEP 255 – Simple Generators» ( https://www.python.org/dev/peps/pep-0255/ ). Документация по модулю itertools (https://docs.python.org/3/library/itertools. html ) – отличный источник информации, благодаря включенным примерам. Хотя функции из этого модуля написаны на C, в документации показано, что многие из 13 В оригинале употреблено слово «grok» и приводится такое пояснение: согласно справочнику жар- гона ( http://catb.org/~esr/jargon/html/G/grok.html ), grok означает не просто «выучить что-то», а впи- тать, так что «это становится частью тебя, твоей личности».\n--- Страница 473 ---\n473 Поговорим них можно было бы реализовать и на Python, часто с привлечением других функ- ций из того же модуля. Примеры подобраны замечательно; например, в одном фрагменте показано, как с помощью функции accumulate погасить ссуду с про- центами, если задан график платежей. А в разделе «Рецепты itertools» ( http://bit. ly/1MM5YvA ) описаны дополнительные высокопроизводительные функции, по- строенные на базе функций из itertools . В главе 2 «Итераторы и генераторы» книги David Beazley, Brian K. Jones «Python Cookbook», издание 3 (O'Reilly), приведено 16 рецептов, где эта тема рассматри-вается с разных точек зрения, но всегда с прицелом на практическое применение. Синтаксическая конструкция yield from объясняется на примерах в документе «What's New in Python 3.3» (см. «PEP 380 – Syntax for Delegating to a Subgenerator», http://bit.ly/1MM6d9R ). Мы также подробно рассмотрим ее в разделах «Исполь- зование yield from» и «Семантика yield from» главы 16. Если вас интересуют документные базы данных и вы хотели бы больше узнать о контексте, описанном в разделе «Пример: генераторы в утилите преобразова-ния базы данных», то почитайте мою статью в журнале Code4Lib Journal «From ISIS to CouchDB: Databases and Data Models for Bibliographic Records» ( http:// journal.code4lib.org/articles/4893 ), где рассматривается вопрос о пересечении между библиотеками и технологиями. В одном из разделов этой статьи описан скрипт isis2json.py . А вообще речь в ней идет о том, почему слабоструктурирован- ная модель данных, реализованная в документных базах данных типа CouchDB и MongoDB, больше подходит для хранения кооперативных библиографических данных, чем реляционная. Поговорим Синтаксис генераторных функций: хорошо бы еще глазури Дизайнер должен позаботиться о том, чтобы дисплеи и органы управления, предназначенные для разных целей, достаточно отли-чались друг от друга. – Дональд Норман Дизайн привычных вещей В языках программирования исходный код играет роль «дисплеев и органов управления». Я полагаю, что Python спроектирован исключи-тельно удачно: исходный код на нем читается, как псевдокод. Но нет в мире совершенства. Гвидо ван Россуму стоило бы последовать совету До-нальда Нормана и включить еще одно ключевое слово для определения генераторных функций вместо def. В разделе «BDFL Pronouncements» (Высказывания великодушного пожизненного диктатора) документа «PEP 255 – Simple Generators» ( https://www.python.org/dev/peps/pep- 0255/ ) написано:\n--- Страница 474 ---\n474 Глава 14. Итерируемые объекты, итераторы и генераторы Предложение «yield» так глубоко зарыто в теле функции, что не может служить достаточным предупреждением о кардинальном различии в семантике. Но Гвидо терпеть не может вводить новые ключевые слова и не счел этот аргумент убедительным, поэтому мы так и живем с def. Использование синтаксиса функций для генераторов имеет и дру- гие неприятные последствия. В статье и в экспериментальное работе «Python, the Full Monty: A T ested Semantics for the Python Programming Language» Полиц (Politz) 14 с соавторами демонстрирует следующий тривиальный пример генераторной функции (в разделе 4.1): def f(): x=0 while True: x += 1 yield x Затем авторы замечают, что невозможно абстрагировать процесс от- дачи значения с помощью вызова функции (пример 14.24). Пример 14.24. «На первый взгляд это выглядит как простая абстракция процесса отдачи значения» (Politz et al.) def f(): def do_yield(n): yield n x = 0 while True: x += 1 do_yield(x) Если в этом примере вызвать f(), то мы получим бесконечный цикл, а не генератор, потому что ключевое слово yield делает генераторной только непосредственно объемлющую функцию. Хотя генераторные функции выглядят как обычные функции, мы не можем делегировать работу другой генераторной функции с помощью простого вызова. Кстати, в языке Lua такого ограничения нет. Сопрограмма в Lua может вызывать другие функции, и любая из них может отдать значение вы-звавшей сопрограмме. Новая синтаксическая конструкция yield from была введена, чтобы генератор или сопрограмма в Python могли делегировать работу друго-му генератору или сопрограмме без обходного приема в виде внутренне-го цикла for. Пример 14.24 можно «исправить», поставив перед вызовом функции yield from , как показано ниже. 14 Joe Gibbs Politz, Alejandro Martinez, Matthew Milano, Sumner Warren, Daniel Patterson, Junsong Li, Anand Chitipothu, and Shriram Krishnamurthi, \"Python: The Full Monty,\" SIGPLAN Not. 48, 10 (October 2013), стр. 217-232\n--- Страница 475 ---\n475 Поговорим Пример 14.25. Это простая абстракция, обертывающая процесс отдачи значения def f(): def do_yield(n): yield n x = 0 while True: x += 1 yield from do_yield(x) Использование def для объявления генераторов с точки зрения удобства пользования было ошибкой, и проблема только усугубилась в версии Python 2.5, когда появились сопрограммы, которые тоже кодировались в виде функций со словом yield . В сопрограммах слово yield обычно встречается в правой части оператора присваивания, потому что получает аргумент, переданный клиентом при вызове .send() . Вот что пишет Дэвид Бизли: Несмотря на внешнее сходство, генераторы и сопрограммы – со- вершенно разные концепции15. Я полагаю, что сопрограммы заслуживают отдельного ключевого слова. Как мы увидим ниже, сопрограммы часто используются со спе-циальными декораторами, которые визуально все же отличают их от обычных функций. Но генераторные функции снабжаются декоратора-ми реже, поэтому приходится искать в их теле слово yield , чтобы по- нять, что это и не функции вовсе, а нечто совершенно иное. Можно возразить, что при введении этих средств ставилась цель ми- нимизировать синтаксические изменения, а дополнительное ключевое слово было бы просто «синтаксической глазурью». Но лично я ничего не имею против синтаксической глазури, если благодаря ей принци-пиально различные средства и выглядят по-разному. Именно из-за от-сутствия синтаксической глазури код на Lisp так трудно читать: любая языковая конструкция в Lisp выглядит как вызов функции. Сравнение семантики генератора и итератора Есть по меньшей мере три способа осмыслить связь между итерато- рами и генераторами. Первый – с точки зрения интерфейса. В протоколе итератора в Python определены два метода: __next__ и __iter__ . Объекты-генера- торы реализуют оба, так что с этой точки зрения любой генератор яв-ляется итератором. Согласно этому определению, объекты, созданные встроенной функцией enumerate() являются итераторами: 15 Слайд 31 «A Curious Course on Coroutines and Concurrency» ( http://www.dabeaz.com/ coroutines/Coroutines.pdf ).\n--- Страница 476 ---\n476 Глава 14. Итерируемые объекты, итераторы и генераторы >>> from collections import abc >>> e = enumerate('ABC')>>> isinstance(e, abc .Iterator) True Второй – с точки зрения реализации. Генератор в Python – это язы- ковая конструкция, которую можно закодировать двумя способами: как функцию с ключевым словом yield или как генераторное выражение. Объекты-генераторы, получающиеся в результате вызова генераторной функции или вычисления генераторного выражения, – это экземпляры внутреннего типа GeneratorType (http://bit.ly/1MM6Sbm ). С этой точки зрения, любой генератор также является итератором, потому что экзем-пляры GeneratorType реализуют интерфейс итератора. Но можно напи- сать итератор, не являющийся генератором, – реализовав классический паттерн Итератор, как в примере 14.4, или запрограммировав расшире-ние на C. В этом смысле объекты enumerate не являются генераторами: >>> import types >>> e = enumerate('ABC')>>> isinstance(e, types.GeneratorType)False Так происходит, потому что тип types.GeneratorType (https://docs. python.org/3/library/types.html#types.GeneratorType ) определен следую- щим образом: «Тип объектов генераторов-итераторов, порождаемых вызовом генераторной функции». Третья точка зрения – концептуальная. В классическом паттерне проектирования, определенном в книге «банды четырех», итератор об-ходит коллекцию и отдает ее элементы. Итератор может быть устроен достаточно сложно, например, обходить древовидную структуру. Но сколь бы сложна ни была логика классического итератора, он всегда чи-тает значения из существующего источника данных, и ожидается, что при вызове next(it) итератор не станет изменять полученный из источ- ника элемент, а просто отдаст его. Напротив, генератор может порождать значения, не обходя коллек- цию, как делает, например, функция range . И даже если генератор свя- зан с коллекцией, он не обязан отдавать только присутствующие в ней значения, а может модифицировать их. Пример такого генератора дает функция enumerate . С точки зрения классического паттерна проектиро- вания, генератор, возвращенный enumerate , не является итератором, по- тому что создает отдаваемые кортежи на лету. На этом концептуальном уровне способ реализации не имеет значе- ния. Можно написать генератор, вообще не используя объекты-генера-торы Python. В примере 14.26 представлен генератор чисел Фибоначчи, написанный мной для иллюстрации этой точки зрения:\n--- Страница 477 ---\n477 Поговорим Пример 14.26. fibo_by_hand.py: генератор чисел Фибоначчи без использования экземпляров типа GeneratorType class Fibonacci: def __iter__(self): return FibonacciGenerator() class FibonacciGenerator: def __init__(self): self.a = 0 self.b = 1 def __next__(self): result = self.a self.a, self.b = self.b, self.a + self.b return result def __iter__(self): return self Пример 14.26 работает, но это всего лишь примитивная иллюстрация. Вот как выглядит генератор чисел Фибоначчи в духе Python: def fibonacci(): a, b = 0, 1 while True: yield a a, b = b, a + b И, разумеется, всегда можно воспользоваться языковыми средствами генерации для выполнения основных обязанностей итератора: обхода коллекции и отдачи ее элементов. На практике программисты на Python относятся к этому различию не так строго: генераторы часто называют итераторами даже в офици-альной документации. Каноническое определение итератора в глосса-рии Python ( http://docs.python.org/dev/glossary.html#term-iterator ) на- столько широко, что охватывает и итераторы: Итератор: объект, представляющий поток данных. […] Полное определение итератора ( https://docs.python.org/3/glossary. html#term-iterator ) в глоссарии Python стоит прочитать. С другой сто- роны, в определении генератора ( https://docs.python.org/3/glossary. html#term-generator ) там же итератор и генератор считаются синонима- ми, а слово «генератор» обозначает как генераторную функцию, так и объект-генератор, который она строит. Поэтому на жаргоне питонистов итератор и генератор трактуются почти как синонимы.\n--- Страница 478 ---\n478 Глава 14. Итерируемые объекты, итераторы и генераторы Минималистский интерфейс итератора в Python В разделе «Реализация» главы о паттерне Итератор книги «банды четырех» написано: Минимальный интерфейс класса Iterator состоит из операций First, Next, IsDone и CurrentItem. Однако к этому предложения относится такая сноска: Этот интерфейс можно и еще уменьшить, если объединить опе- рации Next, IsDone и Currentltem в одну, которая будет переходить к следующему объекту и возвращать его. Если обход завершен, то эта операция вернет специальное значение (например, 0), обозначаю-щее конец итерации. Это близко к тому, что мы имеем в Python: всю работу делает один метод __next__ . Но вместо специального значения, на которое по ошиб- ке можно не обратить внимания, о конце итерации возвещает исключе-ние StopIteration . Просто и правильно: таков путь Python.",
      "debug": {
        "start_page": 432,
        "end_page": 478
      }
    },
    {
      "name": "Глава 15. Контекстные менеджеры и блоки else 479",
      "content": "--- Страница 479 --- (продолжение)\nГЛАВА 15. Контекстные менеджеры и блоки else Не исключено, что контекстные менеджеры окажутся почти такими же важными, как сами подпрограммы. Мы затронули лишь самую верхуш-ку айсберга […]. В языке Basic есть предложение with, как и во многих других языках. Но все они делают совсем не то – они всего лишь эконо-мят время на повторяющемся поиске атрибутов с точкой, не производя ни инициализации, ни очистки. Не нужно думать, что раз названия оди-наковы, то одинаковы и функции. Предложение with – очень мощная штука. 1 – Раймонд Хэттингер, страстный проповедник Python В этой главе мы обсудим средства управления потоком выполнения, которые не так часто встречаются в других языках и потому остаются малоизвестными про-граммистам на Python или используются ими недостаточно эффективно. Вот эти средства: • предложение with и контекстные менеджеры; • часть else в предложениях for, while и try. Предложение with организует временный контекст и гарантированно очищает его под контролем объекта контекстного менеджера. Это позволяет предотвратить ошибки и уменьшить объем стереотипного кода, одновременно сделав API безопаснее и проще в использовании. Программисты на Python находят много применений блокам with помимо автоматического закрытия файлов. Материал, касающийся else , никак не связан с предложением with . Но это уже часть V , а мне так не удалось найти никакого другого места для рассмотрения else , а заводить для этого специальную часть из одной странички не хотелось. Рассмотрим сначала вопрос попроще, чтобы понять, в чем суть этой главы. 1 Тезисы доклада на конференции PyCon US 2013 «What Makes Python Awesome» ( http://pyvideo. org/video/1669/keynote-3 ); часть, относящаяся к with , начинается в 23:00 и заканчивается 26:15.\nГЛАВА 15. Контекстные менеджеры и блоки else Не исключено, что контекстные менеджеры окажутся почти такими же важными, как сами подпрограммы. Мы затронули лишь самую верхуш-ку айсберга […]. В языке Basic есть предложение with, как и во многих других языках. Но все они делают совсем не то – они всего лишь эконо-мят время на повторяющемся поиске атрибутов с точкой, не производя ни инициализации, ни очистки. Не нужно думать, что раз названия оди-наковы, то одинаковы и функции. Предложение with – очень мощная штука. 1 – Раймонд Хэттингер, страстный проповедник Python В этой главе мы обсудим средства управления потоком выполнения, которые не так часто встречаются в других языках и потому остаются малоизвестными про-граммистам на Python или используются ими недостаточно эффективно. Вот эти средства: • предложение with и контекстные менеджеры; • часть else в предложениях for, while и try. Предложение with организует временный контекст и гарантированно очищает его под контролем объекта контекстного менеджера. Это позволяет предотвратить ошибки и уменьшить объем стереотипного кода, одновременно сделав API безопаснее и проще в использовании. Программисты на Python находят много применений блокам with помимо автоматического закрытия файлов. Материал, касающийся else , никак не связан с предложением with . Но это уже часть V , а мне так не удалось найти никакого другого места для рассмотрения else , а заводить для этого специальную часть из одной странички не хотелось. Рассмотрим сначала вопрос попроще, чтобы понять, в чем суть этой главы. 1 Тезисы доклада на конференции PyCon US 2013 «What Makes Python Awesome» ( http://pyvideo. org/video/1669/keynote-3 ); часть, относящаяся к with , начинается в 23:00 и заканчивается 26:15.\n--- Страница 480 ---\n480 Глава 15. Контекстные менеджеры и блоки else Делай то, потом это: блоки else вне if Это не секрет, а недооцененное средство языка: часть else может встречаться не только в предложениях if, но также в for, while и try. Семантика for/else , while/else и try/else похожа, но резко отличается от се- мантики if/else . Поначалу слово else мешало мне по-настоящему понять смысл этих средств, но в конце концов я их освоил. Правила таковы: for Блок else выполняется, только если цикл for дошел до конца (т. е. не было преждевременного выхода с помощью break ). while Блок else выполняется, только если цикл while завершился вследствие того, что условие приняло ложное значение (а не в результате выхода с по-мощью break ). try Блок else выполняется, только если в блоке try не возникало исключение. В официальной документации ( http://bit.ly/1MMa1YB ) также сказано: «Исключения, возникшие в части else , не обрабатываются в предшествую- щих частях except ». В любом случае часть else не выполняется и тогда, когда исключение либо одно из предложений return , break или continue приводят к передаче управления вовне главного блока составного предложения. Я считаю, что выбор ключевого слова else крайне неудачен во всех случаях, кроме if. Оно подразумевает взаимно исключаю- щие альтернативы, например: «Выполни этот цикл, иначе сделай то-то», однако семантика else в циклах прямо противоположна: «Выполни этот цикл, а затем сделай то-то». Таким образом, более подходящим словом было бы then – оно, кстати, имеет смысл и в контексте try: «Попробуй это, а затем сделай то». Однако до- бавление нового ключевого слова означало бы несовместимое изменения языка, а Гвидо бежит от этого, как от чумы. Использование else в этих предложениях часто упрощает чтение кода и позволяет отказаться от установки всяких флагов и добавления предложений if. Применение else обычно выглядит так: for item in my_list: if item.flavor == 'banana': breakelse: raise ValueError('No banana flavor found!')\n--- Страница 481 ---\n481 Делай то, потом это: блоки else вне if Что касается блоков try/except , то на первый взгляд else может показаться лишним. Ведь after_call() в следующем фрагменте и так будет выполняться, только если dangerous_call() не возбудил исключения, верно? try: dangerous_call() after_call()except OSError: log('OSError ') Однако здесь вызов after_call() помещен в блок try безо всякой причины. Чтобы код оставался ясным и корректным, в теле блока try должны быть только предложения, которые могут возбуждать ожидаемые исключения. Такой код на-много лучше: try: dangerous_call()except OSError: log('OSError ')else: after_call() Теперь понятно, что блок try защищает от возможных ошибок внутри danger- ous_call() , но не внутри after_call() . Кроме того, очевидно, что after_call() вы- полняется, только если внутри блока try не было исключений. В Python блок try/except часто используется для управления потоком вы- полнения, а не только для обработки ошибок. В официальном глоссарии Python для этого даже есть специальный акроним ( https://docs.python.org/3/glossary. html#term-eafp ): EAFP Проще попросить прощения, чем испрашивать разрешение (Easier to ask for forgiveness than permission). Этот принятый в Python стиль программи-рования означает следующее: лучше предположить, что ключ или атрибут существует и перехватить исключение, если предположение окажется не-верным. Характерной особенностью этого чистого и быстрого стиля яв-ляется изобилие предложений try и except . Эта техника противоположна принятому во многих других языках, включая C, стилю LBYL. Далее в глоссарии определяется акроним LBYL: LBYL Не зная броду, не суйся в воду (Look before you leap). Этот стиль програм- мирования подразумевает проверку предусловий до вызова или поиска. Он противоположен стилю EAFP и характеризуется наличием многочис- ленных предложений if. В многопоточной программе стиль LBYL чреват состоянием гонки между проверкой и выполнением. Например, код if key in mapping: return mapping[key] может привести к ошибке, если другой по- ток удалит ключ из отображения после проверки, но перед выборкой. Эту\n--- Страница 482 ---\n482 Глава 15. Контекстные менеджеры и блоки else проблемы можно решить с помощью блокировки или программирования в стиле EAFP . Принимая во внимание стиль EAFP , использование блоков else в предложени- ях try/except выглядит еще более оправданным. А теперь перейдем к основной теме этой главы: могучему предложению with . Контекстные менеджеры и блоки with Объекты контекстных менеджеров служат для управления предложением with , точно так же, как итераторы управляют предложением for. Предложение with было задумано, для того чтобы упростить конструкцию try/finally , гарантирующую, что некоторая операция будет выполнена после блока, даже если этот блок прерван в результате исключения, предложения return или вызова sys.exit() . Код внутри части finally обычно освобождает критически важный ресурс или восстанавливает временно измененное состояние. Протокол контекстного менеджера состоит из методов __enter__ и __exit__ . В начале блока with вызывается метод __enter__ контекстного менеджера. А роль части finally играет обращение к методу __exit__ контекстного менеджера в кон- це блока with . Самый распространенный пример – гарантированное закрытие объекта файла, показанное в примере 15.1. Пример 15.1. Использование объекта файла в качестве контекстного менеджера >>> with open('mirror.py') as fp: # /g110 src = fp.read(60) # /g111 >>> len(src)60>>> fp # /g112 <_io.TextIOWrapper name='mirror.py' mode='r' encoding='UTF-8'>>>> fp.closed, fp.encoding # /g113 (True, 'UTF-8')>>> fp.read(60) # /g114 Traceback (most recent call last): File \"<stdin>\", line 1, in <module>ValueError: I/O operation on closed file. /g110 Имя fp связано с открытым файлом, потому что метод __enter__ объекта- файла возвращает self . /g111 Читаем данные из fp. /g112 Переменная fp все еще доступна2. /g113 Мы можем прочитать атрибуты объекта fp. /g114 Но выполнить операцию ввода-вывода для fp по завершении блока with нельзя, т. к. уже был вызван метод TextIOWrapper.__exit__ и файл закрыт. Блоки with не определяют новую область видимости – в отличие от функций и модулей.\n--- Страница 483 ---\n483 Контекстные менеджеры и блоки with Первый маркер в примере 15.1 отмечает тонкий, но важный момент: объект контекстного менеджера – это результат вычисления выражения после слова with , но значение, связанное с переменной в части as, – результат вызова метода __enter__ объекта контекстного менеджера. В примере 15.1 функция open() возвращает экземпляр класса TextIOWrapper , а его метод __enter__ возвращает self . Но вообще-то метод __enter__ может воз- вращать любой другой объект, не обязательно сам контекстный менеджер. Когда поток управления покидает блок with любым способом, вызывается метод __exit__ контекстного менеджера, а не объекта, возвращенного методом __enter__ . Часть as в предложении with необязательна. В случае open она необходима, что- бы получить ссылку на файл, но некоторые контекстные менеджеры возвращают None за неимением чего-то полезного. В примере 15.2 показана работа шутливого контекстного менеджера, един- ственный смысл которого – подчеркнуть различие между самим менеджером и объектом, который возвращает его метод __enter__ . Пример 15.2. Тест класса контекстного менеджера LookingGlass >>> from mirror import LookingGlass >>> with LookingGlass() as what: /g110 print('Alice, Kitty and Snowdrop') /g111 print(what) pordwonS dna yttiK ,ecilA /g112 YKCOWREBBAJ>>> what /g113 'JABBERWOCKY'>>> print('Back to normal.') /g114 Back to normal . /g110 Контекстный менеджер – экземпляр класса LookingGlass ; Python вызыва- ет метод __enter__ контекстного менеджера и связывает результат с пере- менной what . /g111 Печатаем str, а затем значение переменной what . /g112 Любая печатаемая строка выводится задом наперед. /g113 Блок with завершился. Как видим, метод __enter__ вернул значение 'JABBERWOCKY' , сохраненное в переменной what . /g114 Но печатаемые строки больше не инвертируются. В примере 15.3 показана реализация класса LookingGlass . Пример 15.3. mirror .py: класс контекстного менеджера LookingGlass class LookingGlass: def __enter__(self): /g110 import sys\n--- Страница 484 ---\n484 Глава 15. Контекстные менеджеры и блоки else self.original_write = sys.stdout.write /g111 sys.stdout.write = self.reverse_write /g112 return 'JABBERWOCKY' /g113 def reverse_write(self, text): /g114 self.original_write(text[::-1]) def __exit__(self, exc_type, exc_value, traceback): /g115 import sys /g116 sys.stdout.write = self.original_write /g117 if exc_type is ZeroDivisionError: /g118 print('Пожалуйста, НЕ НАДО делить на нуль!') /g119 return True ⤓ /g110 Python вызывает __enter__ с одним лишь аргументом self . /g111 Текущий метод sys.stdout.write сохраняется в атрибуте экземпляра для последующего использования. /g112 Подменяем метод sys.stdout.write своим собственным. /g113 Возвращаем строку 'JABBERWOCKY' , просто чтобы поместить что-то в пере- менную what . /g114 Наш метод sys.stdout.write инвертирует переданный аргумент text и вы- зывает сохраненную реализацию. /g115 Python вызывает метод __exit__ с аргументами None , None , None , если не было ошибок; если же имело место исключение, то в аргументах передают-ся данные об исключении, описанные ниже. /g116 Повторный импорт модулей обходится дешево, потому что Python их кэ- ширует. /g117 Восстанавливаем исходный метод sys.stdout.write . /g118 Если исключение было и его тип – ZeroDivisionError , печатаем сообще- ние… /g119 … и возвращаем True , уведомляя интерпретатор о том, что исключение об- работано. ⤓ Если метод __exit__ возвращает None или вообще что-нибудь, кроме True , то исключение, возникшее внутри блока with , распространяется дальше. Реальные приложения, перехватывающие стандартный вывод, обычно хотят временно подменить sys.stdout похожим на файл объектом, а затем восстановить исходное состояние. Именно это делает контекстный менеджер contextlib.redirect_stdout (http://bit.ly/1MM7Sw6 ): просто передайте ему похожий на файл объект , который подменит sys.stdout . Интерпретатор вызывает метод __enter__ без аргументов – если не считать неявного аргумента self . А методу __exit__ передаются следующие три аргу- мента:\n--- Страница 485 ---\n485 Контекстные менеджеры и блоки with exc_type Класс исключения (например, ZeroDivisionError ). exc_value Объект исключения. Иногда в атрибуте exc_value.args можно найти па- раметры, переданные конструктору исключения, например, сообщение об ошибке. traceback Объект traceback3. Детальное представление о работе контекстного менеджера дает пример 15.4, где объект LookingGlass используется вне блока with , чтобы можно было вручную вызвать его методы __enter__ и __exit__ . Пример 15.4. Исследование LookingGlass без блока with >>> from mirror import LookingGlass >>> manager = LookingGlass() /g110 >>> manager<mirror.LookingGlass object at 0x2a578ac>>>> monster = manager.__enter__() /g111 >>> monster == 'JABBERWOCKY' /g112 eurT>>> monster'YKCOWREBBAJ'>>> manager>ca875a2x0 ta tcejbo ssalGgnikooL.rorrim<>>> manager.__exit__(None, None, None) /g113 >>> monster'JABBERWOCKY' /g110 Создаем и инспектируем объект manager . /g111 Вызываем метод __enter__() контекстного менеджера и сохраняем резуль- тат в переменной monster . /g112 Переменная monster содержит строку 'JABBERWOCKY' . Идентификатор True инвертирован, потому что весь вывод на stdout проходит через метод write , который мы подменили в __enter__() . /g113 Вызываем manager.__exit__ , чтобы восстановить исходный stdout.write . Контекстные менеджеры появились сравнительно недавно, однако сообщество Python медленно, но верно находит им все новые изобретательные применения. Приведем несколько примеров из стандартной библиотеки. • Управление транзакциями в модуле sqlite3 ; см. раздел 12.6.7.3 «Ис- пользование соединения в качестве контекстного менеджера» ( http://bit. ly/1MM89PC ). 3 Три аргумента метода __exit__ – это в точности то, что мы получили бы, вызвав метод sys.exc _info() (http://bit.ly/1MM82Uc ) в блоке finally предложения try/finally . И это понятно, если вспомнить, что предложение with призвано заменить try/finally в большинстве случаев, а вызывать sys.exc_info() часто было необходимо, чтобы решить, какая требуется очистка.\n--- Страница 486 ---\n486 Глава 15. Контекстные менеджеры и блоки else • Хранение блокировок, условных переменных и семафоров в модуле threading ; см. раздел 17.1.10 «Использование блокировок, условных пере- менных и семафоров в предложении with » (http://bit.ly/1MM8guy ). • Настройка среды для арифметических операций с объектами Decimal ; см. документацию по методу decimal.localcontext (http://bit.ly/1MM8eTw ). • Внесение временных изменений в объекты для тестирования; см. функцию unittest.mock.patch (http://bit.ly/1MM8imk ). В стандартную библиотеку входят также утилиты contextlib , рассматривае- мые далее. Утилиты contextlib Прежде чем начинать писать собственные классы контекстных менеджеров, про-читайте раздел 29.6 «contextlib – утилиты для контекстов, вводимых блоками with» ( http://bit.ly/1HGqZpJ ) руководства по стандартной библиотеке Python. По- библиотеке Python. По- е Python. По- мимо уже упоминавшейся функции redirect_stdout , модуль contextlib содержит другие классы и функции. Перечислим наиболее употребительные. closing Функция для построения контекстных менеджеров из объектов, кото- рые предоставляют метод close() , но не реализуют протокол __enter__/ __exit__ . suppress Контекстный менеджер для временного игнорирования заданных исклю- чений. @contextmanager Декоратор, который позволяет построить контекстный менеджер из про- стой генераторной функции, вместо того чтобы создавать класс и реализо-вывать протокол. ContextDecorator Базовый класс для определения контекстных менеджеров на основе клас- сов, которые можно использовать также в качестве декораторов функций, так что вся функция будет работать внутри управляемого контекста. ExitStack Контекстный менеджер, который позволяет составлять композицию из переменного числа контекстных менеджеров. По выходе из блока with объ- ект ExitStack вызывает методы __exit__ запомненных контекстных менед- жеров в порядке LIFO (последним вошел, первым обслужен). Этот класс применяется, когда заранее неизвестно количество открываемых блоков with , например, в случае, когда одновременно открываются все файлы из произвольного списка.\n--- Страница 487 ---\n487 Использование @contextmanager Из всех этих утилит чаще всего, безусловно, используется декоратор @context- manager , поэтому уделим ему особое внимание. Этот декоратор интересен еще и тем, что предложение yield применяется в нем для целей, не связанных с итери- рованием. И тем самым мы пролагаем путь к концепции сопрограммы – теме сле-дующей главы. Использование @contextmanager Декоратор @contextmanager уменьшает объем стереотипного кода создания контекстного менеджера: вместо того чтобы писать целый класс с методами __enter__/__exit__ , мы просто реализуем генератор с одним предложением yield , которое порождает значение, когда должен вернуть управление метод __enter__ . Если генератор снабжен декоратором @contextmanager , то yield разбивает тело функции на две части: все, что находится до yield , исполняется в начале блока with , когда интерпретатор вызывает метод __enter__ ; а все, что находится после yield , выполняется при вызове метода __exit__ в конце блока. В примере 15.5 класс LookingGlass из примера 15.3 заменен генераторной функ- цией. Пример 15.5. mirror_gen.py: реализация контекстного менеджера с помощью генератора import contextlib @contextlib.contextmanager /g110 def looking_glass(): import sys original_write = sys.stdout.write /g111 def reverse_write(text): /g112 original_write(text[::-1]) sys.stdout.write = reverse_write /g113 yield 'JABBERWOCKY' /g114 sys.stdout.write = original_write /g115 /g110 Применяем декоратор contextmanager . /g111 Сохраняем исходный метод sys.stdout.write . /g112 Определяем функцию reverse_write ; original_write будет доступна в за- мыкании. /g113 Заменяем sys.stdout.write функцией reverse_write . /g114 Отдаем значение, которое будет связано с переменной в части as предложе- ния with . В этой точке функция приостанавливается на время выполнения блока with . /g115 Когда управление покидает блок with любым способом, выполнение функ- ции возобновляется с места, следующего за yield ; в данном случае мы вос- станавливаем исходный метод sys .stdout .write .\n--- Страница 488 ---\n488 Глава 15. Контекстные менеджеры и блоки else В примере 15.6 показана функция looking_glass в действии. Пример 15.6. Тест функции контекстного менеджера looking_glass >>> from mirror_gen import looking_glass >>> with looking_glass() as what: /g110 print('Alice, Kitty and Snowdrop') print(what) pordwonS dna yttiK ,ecilAYKCOWREBBAJ>>> what'JABBERWOCKY' /g110 Единственное отличие от примера 15.2 – имя контекстного менеджера: looking_glass вместо LookingGlass . По существу, декоратор contextlib.contextmanager обертывает функцию клас- сом, который реализует методы __enter__ и __exit__4 Метод __enter__ этого классы выполняет следующие действия: 1. Вызывает генераторную функцию и запоминает объект-генератор – назовем его gen. 2. Вызывает next(gen) , чтобы заставить генератор выполнить код до пред- ложения yield . 3. Возвращает значение, отданное next(gen) , чтобы его можно было связать с переменной в части as блока with . По завершении блока with метод __exit__ выполняет следующие действия: 1. Смотрит, было ли передано исключение в параметре exc_type ; если да, вы- зывает gen.throw(exception) , в результате чего строка в теле генераторной функции, содержащая yield , возбуждает исключение. 2. В противном случае вызывает next(gen) , что приводит к выполнению ча- выполнению ча- ю ча- сти генераторной функции после yield . В примере 15.5 есть серьезный дефект: если в теле блока with возникает ис- ключение, то интерпретатор Python перехватывает его и повторно возбуждает в выражении yield внутри looking_glass . Но здесь нет никакой обработки исклю- чений, поэтому функция looking_glass аварийно завершится, не восстановив исходный метод sys.stdout.write и оставив тем самым систему в некорректном состоянии. В примере 15.7 добавлена специальная обработка исключения ZeroDivision- Error , в результате чего код стал эквивалентен примеру 15.3, основанному на классе. 4 Этот класс называется _GeneratorContextManager . Если хотите узнать, как он работает, за- гляните в его исходный код ( http://bit.ly/1MM8AJJ ) в файле Lib/contextlib.py из дистрибутива Python 3.4.\n--- Страница 489 ---\n489 Использование @contextmanager Пример 15.7. mirror_gen_exc.py: контекстный менеджер на основе генератора, реализующий обработку исключения, – внешнее поведение такое же, как в примере 15.3 import contextlib @contextlib.contextmanagerdef looking_glass(): import sys original_write = sys.stdout.write def reverse_write(text): original_write(text[::-1]) sys.stdout.write = reverse_write msg = '' /g110 try: yield 'JABBERWOCKY' except ZeroDivisionError: /g111 msg = 'Пожалуйста, НЕ НАДО делить на нуль!' finally: sys.stdout.write = original_write /g112 if msg: print(msg) /g113 /g110 Создаем переменную для хранения возможного сообщения об ошибке; это первое изменение по сравнению с примером 15.5. /g111 Обрабатываем исключение ZeroDivisionError – устанавливаем сообщение об ошибке. /g112 Восстанавливаем исходный метод sys.stdout.write . /g113 Отображаем сообщение об ошибке, если оно не пусто. Напомним, что, возвращая True , метод __exit__ уведомляет интерпретатор о том, что он обработал исключение; в этом случае интерпретатор подавля-ет исключение. С другой стороны, если __exit__ не вернул никакого значения явно, то интерпретатор получает значение по умолчанию None и распространя- ет исключение дальше. При наличии декоратора @contextmanager поведение по умолчанию изменяется на противоположное: метод __exit__ , предоставляемый декоратором, предполагает, что любое исключение, посланное генератору, уже обработано и должно быть подавлено 5. Если вы не хотите, чтобы декоратор @contextmanager подавлял исключение, то должны сами возбудить его повторно в декорированной функции6. Интересный практический пример использования @contextmanager за предела- ми стандартной библиотеки дает контекстный менеджер для перезаписи файла на месте, созданный Мартином Питерсом ( http://bit.ly/1MM96aR ). В примере 15.8 показано, как он используется. 5 Исключение посылается генератору методом throw , который рассматривается в разделе «Завер- шение сопрограммы и обработка исключений» главы 16. 6 Такое соглашение принято, потому что при проектировании контекстных менеджеров генераторы не могли возвращать значения, разрешено было только отдавать их с помощью yield . Теперь это возможно, как объясняется в разделе «Возврат значения из сопрограммы» главы 16. Мы увидим, что возврат значения из генератора сводится к исключению.\n--- Страница 490 ---\n490 Глава 15. Контекстные менеджеры и блоки else Наличие блока try/finally (или блока with ) вокруг yield – не- избежная плата за использование @contextmanager , потому что невозможно заранее знать, что пользователи контекстного ме-неджера будут делать внутри блока with7. Пример 15.8. Контекстный менеджер для перезаписи файла на месте import csv with inplace(csvfilename, 'r', newline='') as (infh, outfh): reader = csv.reader(infh) writer = csv.writer(outfh) for row in reader: row += ['new', 'columns'] writer .writerow(row) Функция inplace – это контекстный менеджер, который предоставляет два описателя – infh и outfh – одного и того же файла, позволяющие одновременно читать и записывать файл. Это проще, чем функция fileinput.input из стандарт- ной библиотеки ( http://bit.ly/1HGr6Sq ) (которая, кстати, тоже является контекст- ным менеджером). Если вы хотите разобраться в исходном коде функции inplace (приведенном в статье по адресу http://bit.ly/1MM96aR ), то ищите ключевое слово yield : все, что находится до него, связано с подготовкой контекста, т. е. созданием резервной копии и последующим открытием и отдачей описателей для чтения и записи, ко-торые будут возвращены при вызове метода __enter__ . В ходе обработки метода __exit__ после слова yield закрываются описатели файлов, а если что-то пошло не так, то файл восстанавливается из резервной копии. Отметим, что использование слова yield в генераторе, который используется совместно с декоратором @contextmanager , не имеет ничего общего с итерировани- ем. В примерах из этого раздела генераторная функция работает скорее, как сопро-грамма: процедура, которая доходит до определенной точки, затем приостанавли-вается и дает возможность поработать клиентскому коду до тех пор, пока он не захочет возобновить выполнение процедуры с прерванного места. Сопрограммам посвящена глава 16. Резюме Мы начали эту главу с простого материала: обсуждения блоков else в предложе- ниях for, while и try. Я полагаю, что если привыкнуть к неочевидной семантике части else в этих предложениях, то с ее помощью можно будет яснее выражать свои намерения. 7 Это прямая цитата из замечания Леонардо Рохаэля, одного из технических рецензентов книги. От- лично сказано, Лео!\n--- Страница 491 ---\n491 Дополнительная литература Затем мы рассмотрели контекстные менеджеры и семантику предложения with , не ограничиваясь его типичным применением для автоматического закры- тия файлов. Мы реализовали свой контекстный менеджер: класс LookingGlass с методами __enter__ и __exit__ , и показали, как обрабатывать исключения в методе __exit__ . Ключевой момент, который Раймонд Хэттингер отметил в тезисах к до- кладу на конференции PyCon US 2013, заключается в том, что блок with – это не только средство для управления ресурсами, но и инструмент, позволяющий выде-лить общий код инициализации и очистки, да и вообще любую пару операций, ко-торые должны быть выполнены до и после какой-то другой процедуры (слайд 21 «What Makes Python Awesome?», http://bit.ly/1MM9pCm ). Наконец, мы дали обзор функций в модуле contextlib из стандартной библи- отеки. Один из них, декоратор @contextmanager , дает возможность реализовать контекстный менеджер с помощью простого генератора с одним предложением yield – что, конечно, более лаконично, чем кодирование класса, содержащего по меньшей мере два метода. Мы переписали класс LookingGlass в виде генераторной функции looking_glass и обсудили, как обрабатывать исключения при использо- вании @contextmanager . Декоратор @contextmanager – элегантный и практически полезный инструмент, который сводит воедино три совершенно разных механизма Python: декоратор функции, генератор и предложение with . Дополнительная литература В главе 8 «Составные предложения» ( http://bit.ly/1MMa1YB ) справочного руко- водства по языку Python имеется все, что можно сказать о части else в предложе- ниях if, for, while и try. По поводу использования try/except в духе Python – с else или без – Раймонд Хэттингер дал блестящий ответ на вопрос «Хорошо ли исполь-зовать try-except-else в Python?» ( http://bit.ly/1MMa2Mp ) на сайте StackOverflow . В книге Алекса Мартелли «Python in a Nutshell», издание 2 (O'Reilly), имеется глава об исключениях, а в ней – великолепное обсуждение стиля программиро-вания EAFP с отсылкой к одному из пионеров вычислительной техники Грэйсу Хопперу, придумавшему фразу: «Проще попросить прощения, чем испрашивать разрешение». В главе 4 «Встроенные типы» руководства по стандартной библиотеке Python есть раздел, посвященный типам контекстных менеджеров ( http://bit. ly/1MMacTS ). Специальные методы __enter__ и __exit__ документированы также в разделе 3.3.8 «Контекстные менеджеры и предложение with» справочного руко-водства по языку Python ( http://bit.ly/1MMab2e ). Идея контекстных менеджеров впервые была изложена в документе «PEP 343 – The 'with' Statement» ( https:// www.python.org/dev/peps/pep-0343/ ). Это непростое чтение, потому что в доку- менте обсуждаются в основном особые случаи и приводятся возражения против альтернативных предложений. Но такова природа PEP . Раймонд Хэттингер в тезисах к докладу на конференции PyCon US 2013 (http://bit.ly/1MM9pCm ) назвал предложение with «призовым средством языка».\n--- Страница 492 ---\n492 Глава 15. Контекстные менеджеры и блоки else Он также продемонстрировал несколько интересных применений контекстных менеджеров в выступлении «Преобразование кода в красивую идиоматичную программу на Python» ( http://bit.ly/1MMagmB ) на той же конференции. Статья в блоге Джеффа Прешинга (Jeff Preshing) «The Python with Statement by Example» ( http://bit.ly/1MMakmm ) интересна примерами использования кон- текстных менеджеров в графической библиотеке pycairo . Бизли и Джонс предлагают контекстные менеджеры для разных целей в своей книге «Python Cookbook», издание 3 (O'Reilly). В рецепте 8.3 «Наделение объек-тов средствами поддержки протокола управления контекстом» реализован класс LazyConnection , экземпляры которого являются контекстными менеджерами, ко- торые автоматически открывают и закрывают сетевое соединение в блоке with . В рецепте 9.22 «Простой способ определения контекстных менеджеров» описыва-ются контекстные менеджеры для хронометража кода транзакционного измене-ния объекта list : в блоке with создается копия списка, и все изменения произво- дятся в этой копии. И лишь если блок with завершается без исключений, рабочая копия заменяет исходный список. Просто и остроумно. Поговорим Выделение хлеба из бутерброда В тезисах к докладу на конференции PyCon US 2013 «What Makes Python Awesome» ( http://pyvideo.org/video/1669/keynote-3 ) Раймонд Хэттингер признался, что, впервые увидев предложение по реализации предложения with , он счел его «несколько заумным». И у меня понача- лу была такая же реакция. Читать PEP'ы зачастую довольно трудно, и PEP 343 в этом отношении типичен. Но потом – как сказал нам Хэттингер – его посетило озарение: под- программы – самое важное изобретение в истории языков программи-рования. Если имеются последовательности операций A;B;C и P;B;Q, то B можно выделить в виде подпрограммы. Это как выделение начинки сэндвича: тунца можно положить на разные куски хлеба. Но что если требуется выделить сам хлеб и использовать пшеничный хлеб с разны-ми начинками? Именно в этом и состоит смысл предложения with . Это дополнение к подпрограммам. Хэттингер продолжает: Предложение with – могучая штука. Я всем советую не ограни- чиваться поверхностным знакомством, а копнуть глубже. С его по-мощью можно делать поразительные вещи. И самые интересные из них еще не открыты. Я полагаю, что если мы сможем найти этому механизму хорошие применения, то он войдет и в другие языки, во все будущие языки. Вы можете принять участие в деянии столь же великом, как изобретение подпрограмм.\n--- Страница 493 ---\n493 Поговорим Хэттингер признает, что немного перебрал с восхвалением with . Тем не менее, это действительно очень полезное средство. Когда он восполь-зовался аналогией с сэндвичем для объяснения того, как with дополняет подпрограммы, перед моим мысленным взором возник целый ряд воз-можностей. Если вы захотите убедить кого-то в превосходных качествах Python, посмотрите видео тезисов Хэттингера. Часть, относящаяся к контекст-ным менеджерам, занимает время с 23:00 до 26:15. Но вообще весь мате-риал великолепен.",
      "debug": {
        "start_page": 479,
        "end_page": 493
      }
    },
    {
      "name": "Глава 16. Сопрограммы 494",
      "content": "--- Страница 494 --- (продолжение)\nГЛАВА 16. Сопрограммы Если судить о Python по книгам, то сопрограммы окажутся самым пло-хо документированным, невразумительным и, на первый взгляд, бес-полезным средством Python. – Дэвид Бизли, автор книг по Python В словарях можно найти два значения глагола «to yield»: производить и уступать дорогу. Оба имеют смысл в Python, когда ключевое слово yield используется в генераторе. Строка вида yield item порождает (производит) значение, которое получает сторона, вызвавшая функцию next(…) , и, кроме того, она уступает про- цессор, приостанавливая выполнение генератора, чтобы вызывающая сторона могла продолжить работу до момента, когда ей понадобится следующее значение от next() . Вызывающая программа «вытягивает» значения из генератора. Сопрограмма синтаксически выглядит как генератор: просто функция, в теле которой встречается ключевое слово yield . Однако в сопрограмме yield обычно находится в правой части выражения присваивания (например, datum = yield ) и может порождать или не порождать значение – если после слова yield нет никако- го выражения, генератор отдает None . Сопрограмма может получать данные от вы- зывающей стороны, если та вместо next(…) воспользуется методом .send(datum) . Обычно вызывающая сторона отправляет сопрограмме значения. Может быть и так, что yield не отдает и не принимает данные. Но независи- мо от потока данных yield является средством управления потоком выполнения, которое можно использовать для реализации невытесняющей многозадачности: каждая сопрограмма уступает управление центральному планировщику, чтобы тот мог активировать другие сопрограммы. Начав думать о yield преимущественно в терминах управления потоком, вы настроите свой мозг на понимание сущности сопрограмм. Сопрограммы Python – это результат последовательного совершенствования скромных генераторных функций, с которыми мы познакомились выше. Просле-див за эволюцией сопрограмм в Python, мы лучше поймем, как расширялись и усложнялись их возможности.\nГЛАВА 16. Сопрограммы Если судить о Python по книгам, то сопрограммы окажутся самым пло-хо документированным, невразумительным и, на первый взгляд, бес-полезным средством Python. – Дэвид Бизли, автор книг по Python В словарях можно найти два значения глагола «to yield»: производить и уступать дорогу. Оба имеют смысл в Python, когда ключевое слово yield используется в генераторе. Строка вида yield item порождает (производит) значение, которое получает сторона, вызвавшая функцию next(…) , и, кроме того, она уступает про- цессор, приостанавливая выполнение генератора, чтобы вызывающая сторона могла продолжить работу до момента, когда ей понадобится следующее значение от next() . Вызывающая программа «вытягивает» значения из генератора. Сопрограмма синтаксически выглядит как генератор: просто функция, в теле которой встречается ключевое слово yield . Однако в сопрограмме yield обычно находится в правой части выражения присваивания (например, datum = yield ) и может порождать или не порождать значение – если после слова yield нет никако- го выражения, генератор отдает None . Сопрограмма может получать данные от вы- зывающей стороны, если та вместо next(…) воспользуется методом .send(datum) . Обычно вызывающая сторона отправляет сопрограмме значения. Может быть и так, что yield не отдает и не принимает данные. Но независи- мо от потока данных yield является средством управления потоком выполнения, которое можно использовать для реализации невытесняющей многозадачности: каждая сопрограмма уступает управление центральному планировщику, чтобы тот мог активировать другие сопрограммы. Начав думать о yield преимущественно в терминах управления потоком, вы настроите свой мозг на понимание сущности сопрограмм. Сопрограммы Python – это результат последовательного совершенствования скромных генераторных функций, с которыми мы познакомились выше. Просле-див за эволюцией сопрограмм в Python, мы лучше поймем, как расширялись и усложнялись их возможности.\n--- Страница 495 ---\n495 Эволюция: от генераторов к сопрограммам После краткого обзора использования генераторов в роли сопрограммы мы перейдем к основному материалу. Вот темы этой главы: • поведение и состояния генератора, работающего как сопрограмма; • автоматическая инициализация сопрограммы с помощью декоратора;• как вызывающая программа может управлять сопрограммой с помощью методов .close() и .throw(…) объекта-генератора; • как сопрограмма может вернуть значение по завершении;• применение и семантика новой конструкции yield from ; • пример: использование сопрограмм для управления параллельными опера- циями в ходе моделирования. Эволюция: от генераторов к сопрограммам Инфраструктура для сопрограмм впервые была описана в документе «PEP 342 – Coroutines via Enhanced Generators» ( https://www.python.org/dev/peps/pep-0342/ ), реализованном в версии Python 2.5 (2006): с того времени ключевое слово yield можно использовать в выражениях, а в состав API генераторов добавлен метод .send(value) . С помощью метода .send(…) программа, вызывающая генератор, мо- жет отправлять данные, которые становятся значением выражения yield внутри генераторной функции. Это позволяет использовать генератор как сопрограмму: процедуру, которая взаимодействует с вызывающей стороной, принимая от нее значения и отдавая ей результаты. Помимо .send(…) , в документе PEP 342 были описаны также методы .throw(…) и .close() , позволявшие соответственно возбудить исключение, обрабатываемое в генераторе, и завершить генератор. Эти средства рассматриваются в следующем разделе и в разделе «Завершение сопрограммы и обработка исключений» ниже. Последним этапом эволюции сопрограмм стал документ «PEP 380 – Syntax for Delegating to a Subgenerator» ( https://www.python.org/dev/peps/pep-0380/ ), реализованный в версии Python 3.3 (2012). В нем были описаны два изменения в синтаксисе генераторных функций, призванные сделать их более полезными в качестве сопрограмм: • генератор теперь может возвращать значение в предложении return ; рань- ше наличие return с указанием значения внутри генератора приводило к исключению SyntaxError ; • синтаксическая конструкция yield from позволяет разбить большие и сложные генераторы на более мелкие, вложенные, одновременно избавив-шись от стереотипного кода, который раньше был необходим для делегиро-вания работы субгенераторам. Эти изменения будут рассмотрены в разделах «Возврат значения из сопро- граммы» и «Использование yield from» ниже.\n--- Страница 496 ---\n496 Глава 16. Сопрограммы Последуем установившейся в этой книге традиции: начнем с простых фактов и примеров и постепенно перейдем к более головоломным средствам. Базовое поведение генератора, используемого в качестве сопрограммы В примере 16.1 иллюстрируется поведение сопрограммы. Пример 16.1. Простейшая демонстрация сопрограммы в действии >>> def simple_coroutine(): # /g110 print('-> coroutine started') x = yield # /g111 print('-> coroutine received:', x) >>> my_coro = simple_coroutine()>>> my_coro # /g112 <generator object simple_coroutine at 0x100c2be10>>>> next(my_coro) # /g113 -> coroutine started>>> my_coro.send(42) # /g114 -> coroutine received: 42Traceback (most recent call last): # /g115 StopIteration /g110 Сопрограмма определяется так же, как генераторная функция: в теле при- сутствует ключевое слово yield . /g111 yield используется в выражении присваивания; если сопрограмма предна- значена только для получения данных от клиента, yield отдает None – это неявно подразумевается, потому что справа от слова yield нет никакого значения. /g112 Как всегда с генераторами, мы вызываем функцию, чтобы получить объект- генератор. /g113 Первой вызывается функция next(…) , потому что генератор еще не начал работу, т. е. он еще не приостановился, достигнув yield , поэтому мы не мо- жем послать ему данные. /g114 В результате этого обращения yield в теле сопрограммы отдает значение 42; теперь выполнение сопрограммы возобновилось, и она будет работать до следующего yield или до завершения. /g115 В данном случае управление покидает тело сопрограммы, в результате чего генератор возбуждает исключение StopIteration , как обычно. Сопрограмма может находиться в одном из четырех состояний. Узнать, в каком именно, позволяет функция inspect.getgeneratorstate(…) , которая возвращает одну из перечисленных ниже строк.\n--- Страница 497 ---\n497 Базовое поведение генератора, используемого в качестве сопрограммы 'GEN_CREATED' Ожидает начала выполнения. 'GEN_RUNNING' Выполняется интерпретатором1. 'GEN_SUSPENDED' Приостановлена в выражении yield . 'GEN_CLOSED' Исполнение завершилось. Из того, что аргумент метода send становится значением ожидающего выраже- ния yield , следует, что вызов вида my_coro.send(42) возможен только в момент, когда сопрограмма приостановлена. Но это не так, если сопрограмма еще не ак-тивирована, т. е. находится в состоянии 'GEN_CREATED' . Поэтому обращение к со- программе всегда начинается с вызова next(my_coro) ; или можно вызвать my_coro. send(None) – результат будет точно такой же. Вот что произойдет, если создать объект сопрограммы и сразу же послать ему значение, отличное от None : >>> my_coro = simple_coroutine()>>> my_coro.send(1729)Traceback (most recent call last): File \"<stdin>\", line 1, in <module>TypeError: can't send non-None value to a just-started generator Сообщение абсолютно понятно («Не могу послать значение, отличное от None, только что созданному генератору»). Начальный вызов next(my_coro) часто называют «инициализацией» (priming) сопрограммы (т. е. продвижением ее к первому yield , чтобы дальше можно было работать нормально). Чтобы лучше прочувствовать поведение сопрограммы, полезно посмотреть, что происходит, когда yield встречается несколько раз. Пример 16.2. Сопрограмма с двумя yield >>> def simple_coro2(a): print('-> Started: a =', a) b = yield a print('-> Received: b =', b) c = yield a + b print('-> Received: c =', c) >>> my_coro2 = simple_coro2(14)>>> from inspect import getgeneratorstate>>> getgeneratorstate(my_coro2) /g110 'GEN_CREATED' 1 Это состояние можно увидеть только в многопоточной программе или если объект-генератор вы- зывает функцию getgeneratorstate для себя самого, что вряд ли имеет смысл.\n--- Страница 498 ---\n498 Глава 16. Сопрограммы >>> next(my_coro2) /g111 -> Started: a = 1414>>> getgeneratorstate(my_coro2) /g112 'GEN_SUSPENDED'>>> my_coro2.send(28) /g113 -> Received: b = 2842>>> my_coro2.send(99) /g114 -> Received: c = 99Traceback (most recent call last): File \"<stdin>\", line 1, in <module>StopIteration>>> getgeneratorstate(my_coro2) /g115 'GEN_CLOSED' /g110 inspect.getgeneratorstate возвращает GEN_CREATED (т. е. сопрограмма еще не начала работать). /g111 Продвигаем сопрограмму к первому yield , она печатает сообщение Started: a = 14 , затем отдает значение a и приостанавливается в ожидании значения, которое нужно присвоить b. /g112 getgeneratorstate возвращает GEN_SUSPENDED (т. е. сопрограмма приоста- новлена в выражении yield ). /g113 Посылаем приостановленной сопрограмме число 28, выражение yield от- дает это значение, и оно связывается с переменной b. Печатается сообщение -> Received: b = 28 , отдается результат вычисления a + b (42) и сопро- грамма приостанавливается в ожидании значения, которое можно будет присвоить c. /g114 Посылаем приостановленной сопрограмме число 99, выражение yield от- дает это значение, и оно связывается с переменной с. Печатается сообщение -> Received: b = 99 , затем сопрограмма завершается, в результате чего объ- ект-генератор возбуждает исключение StopIteration . /g115 getgeneratorstate возвращает GEN_CLOSED (т. е. сопрограмма завершилась). Важно понимать, что выполнение сопрограммы приостанавливается именно по достижении ключевого слова yield – не раньше и не позже. Выше уже отмечалось, что код в правой части выражения присваивания вычисляется до выполнения при- выполнения при- я при- сваивания. Это означает, что в строке вида b = yield a значение b будет установ- лено только после активации сопрограммы из клиентского кода. Чтобы осознать этот факт, требуется некоторое усилие, но его понимание абсолютно необходимо для осмысленного использования yield в асинхронном программировании, о чем речь пойдет ниже. Выполнение сопрограммы simple_coro2 можно разбить на три стадии, пока- занные на рис. 16.1. 1. next(my_coro2) печатает первое сообщение и выполняется до точки yield a , где отдает значение 14.\n--- Страница 499 ---\n499 Пример: сопрограмма для вычисления накопительного среднего 2. my_coro2.send(28) приводит к присваиванию значения 28 переменной b, печати второго сообщения и выполнению до точки yield a + b , в которой отдается число 42. 3. my_coro2.send(99) приводит к присваиванию значения 99 переменной c, пе- чати третьего сообщения и завершению сопрограммы. Рис. 16.1. Три стадии выполнения сопрограммы simple_coro2 (обратите внимание, что каждая стадия заканчивается выражением yield , а следующая стадия начинается в той же строке, когда значение выражения yield присваивается переменной) Теперь рассмотрим чуть более сложный пример сопрограммы. Пример: сопрограмма для вычисления накопительного среднего При обсуждении замыканий в главе 7 мы рассматривали объект для вычисле- ния накопительного среднего: в примере 7.8 приведен простой класс, а в приме-ре 7.14 – функция высшего порядка, порождающая замыкание для запоминания переменных total и count между вызовами. В примере 16.3 показано, как то же самое сделать с помощью сопрограммы2. Пример 16.3. coroaverager0.py: сопрограмма для вычисления накопительного среднего def averager(): total = 0.0 count = 0 average = None while True: /g110 term = yield average /g111 total += term 2 В основу этого примера положен фрагмент, приведенный Джекобом Холмом (Jacob Holm) в списке рассылки Python-ideas, его сообщение называется «Yield-From: Finalization guarantees» ( http://bit. ly/1MMc9zy ). Позже в той же ветке появились вариации на эту тему, а сам Холм объяснил ход своих мыслей в сообщении 003912 ( http://bit.ly/1MMcano ).\n--- Страница 500 ---\n500 Глава 16. Сопрограммы count += 1 average = total/count /g110 В этом бесконечном цикле сопрограмма будет принимать значения и по- рождать результаты, пока вызывающая сторона их посылает. Сопрограм-ма завершится, когда вызывающая сторона вызовет ее метод .close() или если ее уничтожит сборщик мусора, увидев, что на нее не осталось ни одной ссылки. /g111 Здесь предложение yield используется, чтобы приостановить сопрограм- му, отдать результат вызывающей стороне и – впоследствии – получить значение, посланное вызывающей стороной, после чего выполнение бес- выполнение бес- е бес- конечного цикла продолжится. У сопрограммы есть то преимущество, что total и count могут быть обычными локальными переменными, для запоминания контекста между вызовами не нуж-ны ни переменные экземпляра, ни замыкания. В примере 16.4 приведены doctest-скрипты, демонстрирующие использование сопрограммы averager . Пример 16.4. coroaverager0.py: doctest-скрипт , демонстрирующий использование сопрограммы вычисления накопительного среднего из примера 16.3 >>> coro_avg = averager() /g110 >>> next(coro_avg) /g111 >>> coro_avg.send(10) /g112 10.0>>> coro_avg.send(30)20.0>>> coro_avg .send(5) 15.0 /g110 Создаем объект сопрограммы. /g111 Инициализируем ее, вызывая next . /g112 Теперь мы в деле: каждый вызов .send(…) отдает текущее среднее. В этом doctest-скрипте вызов next(coro_avg) заставляет сопрограмму дойти до yield , при этом будет отдано начальное значение average , равное None , поэтому в оболочке оно не печатается. В этот момент сопрограмма приостановлена и ждет отправки значения. В строке coro_avg.send(10) значение отправляется, после чего сопрограмма возобновляет работу, присваивает значение term , обновляет пере- менные total , count и average и начинает следующую итерацию цикла, на которой отдает average и ждет следующего члена последовательности. У внимательного читателя, наверное, возник вопрос, как остановить работу объекта averager (coro_avg ), – ведь цикл-то бесконечный. Мы ответим на этот вопрос в разделе «Завершение сопрограммы и обработка исключений» ниже. Но прежде поговорим не о том, как завершить сопрограмму, а о том, как ее запу- стить. Инициализация сопрограммы – необходимый шаг, о котором легко забыть.\n--- Страница 501 ---\n501 Декораторы для инициализации сопрограмм Чтобы защититься от такой напасти, можно применить к сопрограмме специаль- ный декоратор. Один такой декоратор представлен ниже. Декораторы для инициализации сопрограмм Пока сопрограмма не инициализирована, она практически бесполезна, нужно не забыть вызвать next(my_coro) до my_coro.send(x) . Чтобы облегчить работу с со- программами, иногда используется инициализирующий декоратор. Один такой декоратор coroutine показан ниже3. Пример 16.5. coroutil.py: декоратор для инициализации сопрограмм from functools import wraps def coroutine(func): \"\"\"Decorator: primes `func` by advancing to first `yield`\"\"\" @wraps(func) def primer(*args,**kwargs): /g110 gen = func(*args,**kwargs) /g111 next(gen) /g112 return gen /g113 return primer /g110 Декорированная генераторная функция подменяется этой функцией primer , которая при вызове возвращает инициализированный генератор. /g111 Вызываем декорированную функцию, чтобы получить инициализирован- ный генератор. /g112 Инициализируем генератор. /g113 Возвращаем его В примере 16.6 показано, как используется декоратор @coroutine . Сравните с примером 16.3. Пример 16.6. coroaverager1.py: doctest-скрипт и код сопрограммы вычисления накопительного среднего с использованием декоратора @coroutine из примера 16.5 \"\"\" A coroutine to compute a running average >>> coro_avg = averager() /g110 >>> from inspect import getgeneratorstate >>> getgeneratorstate(coro_avg) /g111 'GEN_SUSPENDED' >>> coro_avg.send(10) /g112 10.0 >>> coro_avg.send(30) 3 В вебе опубликовано несколько подобных декораторов. Конкретно этот – слегка видоизмененный вариант рецепта «Pipeline made of coroutines» на сайте компании ActiveState, предложенного Чао Бин Танем, который, в свою очередь, ссылается на Дэвида Бизли. ( http://bit.ly/1MMcuCx ).\n--- Страница 502 ---\n502 Глава 16. Сопрограммы 20.0 >>> coro_avg.send(5) 15.0 \"\"\"from coroutil import coroutine /g113 @coroutine /g114 def averager(): /g115 total = 0.0 count = 0 average = None while True: term = yield average total += term count += 1 average = total/count /g110 Вызываем averager() , она создает объект-генератор, который инициализи- руется в функции primer декоратора coroutine . /g111 getgeneratorstate возвращает GEN_SUSPENDED , т. е. сопрограмма готова к приему значения. /g112 Мы можем сразу же начать отправку значений coro_avg , в этом и состоял смысл декоратора. /g113 Импортируем декоратор coroutine . /g114 Применяем его к функции averager . /g115 Тело функции точно такое же, как в примере 16.3. Ряд каркасов предлагает специальные декораторы для работы с сопрограмма- ми. Не все они инициализируют сопрограмму, некоторые предоставляют другие сервисы, например, включение в цикл обработки событий. В качестве примере на-зовем декоратор tornado.gen (http://bit.ly/1MMcGBF ) из библиотеки асинхронно- го сетевого программирования T ornado. Конструкция yield from (см. раздел «Использование yield from» ниже) авто- матически инициализирует вызываемую с ее помощью сопрограмму и потому несовместима с декоратором @coroutine и ему подобными. Декоратор asyncio. coroutine из стандартной библиотеки Python 3.4 предназначен для работы со- вместно с yield form , поэтому не инициализирует сопрограмму. Мы рассмотрим его в главе 18. Теперь обратимся к важнейшим свойствам сопрограмм: методам, которые по- зволяют завершить сопрограмму и возбудить в ней исключение. Завершение сопрограммы и обработка исключений Необработанное исключение в сопрограмме распространяется в функцию, из которой был произведен вызов next или send , приведший к исключению. Ниже\n--- Страница 503 ---\n503 Завершение сопрограммы и обработка исключений демонстрируется использование декорированной сопрограммы averager из при- мера 16.6. Пример 16.7. Как необработанное исключение аварийно завершает сопрограмму >>> from coroaverager1 import averager >>> coro_avg = averager()>>> coro_avg.send(40) # /g110 40.0>>> coro_avg.send(50)45.0>>> coro_avg.send('spam') # /g111 Traceback (most recent call last): TypeError: unsupported operand type(s) for +=: 'float' and 'str'>>> coro_avg.send(60) # /g112 Traceback (most recent call last): File \"<stdin>\", line 1, in <module>StopIteration /g110 Сопрограмме averager() , декорированной @coroutine , можно сразу отправ- лять значения. /g111 Отправка нечислового значения приводит к исключению в сопрограмме. /g112 Поскольку исключение не обработано самой сопрограммой, она завершает- ся. Любая попытка вновь активировать сопрограмму вызовет исключение StopIteration . Причина ошибки в том, что отправленное значение 'spam' нельзя прибавить к переменной total . Пример 16.7 показывает возможный способ завершения сопрограммы: по- слать некоторое специальное значение, которое сопрограмма интерпретирует как признак завершения. У добными кандидатами на эту роль являются константные встроенные синглтоны, например None и Ellipsis . У Ellipsis к тому же есть то достоинство, что в обычных потоках данных он практически не встречается. Я так-же видел, как в качестве признака используют StopIteration – сам класс, а не его экземпляр (и без возбуждения исключения такого типа), т. е. таким образом: my_ coro.send(StopIteration) . Начиная с версии Python 2.5, у объектов-генераторов есть два метода, которые позволяют клиенту явно отправить сопрограмме исключение: throw и close : generator.throw(exc_type[, exc_value[, traceback]]) Приводит к тому, что выражение yield , в котором генератор приостанов- лен, возбуждает указанное исключение. Если генератор обработает исклю-чение, то выполнение продолжится до следующего yield , а отданное зна- чение станет значением вызова generator.throw . Если же исключение не обработано генератором, то оно распространится в контекст вызывающей стороны.\n--- Страница 504 ---\n504 Глава 16. Сопрограммы generator.close() Выражение yield , в котором генератор приостановлен, возбуждает исклю- чение GeneratorExit . Если генератор не обработает это исключение или возбудит исключение StopIteration – обычно в результате выполнения до конца – вызывающая сторона не получит никакой ошибки. Получив исключение GeneratorExit , генератор не должен отдавать значение, иначе возникнет исключение RuntimeError . Если генератор возбудит любое дру- гое исключение, то оно распространится в контекст вызывающей сторо-ны. Официальная документация по методам объекта-генератора находит- ся в разделе 6.2.9.1 «Методы генератора-итератора» справочного руко-водства по языку Python ( https://docs.python.org/3/reference/expressions. html#generator-iterator-methods ). Посмотрим, как управлять сопрограммой с помощью методов close и throw . В следующих примерах будет использована функция demo_exc_handling из при- мера 16.8. Пример 16.8. coro_exc_demo.py: тестовый код для изучения обработки исключений в сопрограммах class DemoException(Exception): «»»An exception type for the demonstration.»»» def demo_exc_handling(): print('-> coroutine started') while True: try: x = yield except DemoException: /g110 print('*** DemoException handled. Continuing ') else: /g111 print('-> coroutine received: {!r}'.format(x)) raise RuntimeError('This line should never run.') /g112 /g110 Специальная обработка DemoException . /g111 Если исключения не было, вывести полученное значение. /g112 Эта строка никогда не выполняется. Последняя строка в примере 16.8 недостижима, потому что из бесконечного цикла можно выйти только в результате необработанного исключения, а это приводит к немедленному завершению сопрограммы. Нормальная работа функции demo_exc_handling показана в примере 16.9.\n--- Страница 505 ---\n505 Завершение сопрограммы и обработка исключений Пример 16.9. Активация и завершение demo_exc_handling без исключения >>> exc_coro = demo_exc_handling() >>> next(exc_coro)-> coroutine started>>> exc_coro.send(11)-> coroutine received: 11>>> exc_coro.send(22)-> coroutine received: 22>>> exc_coro.close()>>> from inspect import getgeneratorstate>>> getgeneratorstate(exc_coro)'GEN_CLOSED' Если в demo_exc_handling методом throw передано исключение DemoException , то оно обрабатывается, и сопрограмма продолжается, как показано в примере 16.10. Пример 16.10. Возбуждение исключения DemoException в demo_exc_handling не приводит к выходу из нее >>> exc_coro = demo_exc_handling() >>> next(exc_coro)-> coroutine started>>> exc_coro.send(11)-> coroutine received: 11>>> exc_coro.throw(DemoException)*** DemoException handled. Continuing >>> getgeneratorstate(exc_coro)'GEN_SUSPENDED' С другой стороны, если возбужденное в сопрограмме исключение не обработа- но, то она останавливается и переходит в состояние 'GEN_CLOSED' . Пример 16.11. Сопрограмма завершается, если не может обработать возбужденное в ней исключение >>> exc_coro = demo_exc_handling() >>> next(exc_coro)-> coroutine started>>> exc_coro.send(11)-> coroutine received: 11>>> exc_coro.throw(ZeroDivisionError)Traceback (most recent call last): ZeroDivisionError>>> getgeneratorstate(exc_coro)'GEN_CLOSED' Если необходимо, чтобы вне зависимости от способа завершения сопрограммы был выполнен какой-то код очистки, то соответствующую часть тела сопрограм-мы нужно обернуть блоком try/finally , как показано в примере 16.12.\n--- Страница 506 ---\n506 Глава 16. Сопрограммы Пример 16.12. coro_finally_demo.py: использование try/finally для выполнения некоторых действий по завершении сопрограммы class DemoException(Exception): \"\"\"An exception type for the demonstration.\"\"\" def demo_finally(): print('-> coroutine started') try: while True: try: x = yield except DemoException: print('*** DemoException handled. Continuing ') else: print('-> coroutine received: {!r}'.format(x)) finally: print('-> coroutine ending') Одна из основных причин добавления конструкции yield from в Python 3.3 имеет отношение к возбуждению исключений во вложенных сопрограммах. Дру-гая причина – обеспечить более удобный возврат значений из сопрограмм. Возврат значения из сопрограммы В примере 16.13 показан вариант сопрограммы averager , возвращающий резуль- тат. Для иллюстрации идеи накопительное среднее возвращается не при каждой активации. Тем самым мы хотим подчеркнуть, что некоторые сопрограммы не от-дают ничего интересного, а написаны с целью вернуть значение в конце – зача-стую некий аккумулированный результат. Функция averager из примера 16.13 возвращает именованный кортеж, содер- жащий количество усредненных элементов ( count ) и среднее average . Я мог бы вернуть просто average , но возврат кортежа позволяет получить еще один инте- ресный аспект данных: количество членов последовательности. Пример 16.13. coroaverager2.py: сопрограмма averager , возвращающая результат from collections import namedtuple Result = namedtuple('Result', 'count average')def averager(): total = 0.0 count = 0 average = None while True: term = yield if term is None: break /g110 total += term\n--- Страница 507 ---\n507 Возврат значения из сопрограммы count += 1 average = total/count return Result(count, average) /g111 /g110 Чтобы вернуть значение, сопрограмма должна завершиться нормально, по- этому в новой версии averager проверяется условие выхода из цикла под- счета среднего. /g111 Возвращаем именованный кортеж, содержащий count и average . До вер- сии Python 3.3 возврат значения из генераторной функции считался ошибкой. Чтобы увидеть, как работает новая версия averager , мы можем проследить за ее выполнением в оболочке (пример 16.14). Пример 16.14. coroaverager2.py: doctest-скрипт , иллюстрирующий поведение averager >>> coro_avg = averager() >>> next(coro_avg)>>> coro_avg.send(10) /g110 >>> coro_avg.send(30)>>> coro_avg.send(6.5)>>> coro_avg.send(None) /g111 Traceback (most recent call last): StopIteration: Result(count=3, average=15.5) /g110 Эта версия не отдает значений. /g111 Отправка None приводит к выходу из цикла и завершению сопрограммы с возвратом результата. Как обычно, генератор возбуждает исключение Sto- pIteration . Возвращенное значение можно прочитать из атрибута исклю- чения value . Отметим, что значение выражения return передается вызывающей стороне «контрабандой» – в виде атрибута объекта-исключения StopIteration . Это не со- всем честно, но сохраняет существующее поведение объектов-генераторов: воз-буждение StopIteration по исчерпании. В примере 16.15 показано, как получить значение, возвращенное сопрограм- мой. Пример 16.15. Перехват StopIteration позволяет получить значение, возвращенное averager >>> coro_avg = averager() >>> next(coro_avg)>>> coro_avg.send(10)>>> coro_avg.send(30)>>> coro_avg.send(6.5)>>> try: coro_avg.send(None) except StopIteration as exc:\n--- Страница 508 ---\n508 Глава 16. Сопрограммы result = exc.value >>> resultResult(count=3, average=15.5) Этот обходной способ получения возвращенного сопрограммой значения по- кажется более осмысленным, если принять во внимание, что он определен в доку-менте PEP 380, а конструкция yield from делает все автоматически, перехватывая StopIteration внутри себя. Т ут есть аналогия с использованием StopIteration в циклах for: исключение обрабатывается внутренним механизмом цикла, так что пользователь о нем ничего не знает. В случае yield from интерпретатор не только «глотает» StopIteration , но и отдает значение атрибута value в виде значения самого выражения yield from . К сожалению, мы не можем протестировать это в оболочке, потому что использование yield from – да и просто yield – вне функции является синтаксической ошибкой4. В следующем разделе приведен пример использования yield from для возврата значения из сопрограммы averager – как предполагалось в документе PEP 380. Использование yield from Прежде всего, нужно ясно понимать, что yield from – совершенно новая языковая конструкция. Она умеет настолько больше yield , что использование одного и того же ключевого слова только вводит в заблуждение. Аналогичные конструкции в других языках называются await , и это куда более подходящее имя, потому что передает важнейшую мысль: когда генератор gen вызывает yield from subgen() , subgen перехватывает управление и начинает отдавать значения непосредственно функции, из которой был вызван gen, т. е. вызывающая сторона напрямую управ- ляет subgen . А тем временем gen остается блокированным в ожидании завершения subgen5. В главе 14 мы видели, что yield from можно использовать вместо yield в ци- кле for. Например, фрагмент: >>> def gen(): for c in 'AB': yield c for i in range(1, 3): yield i >>> list(gen())['A', 'B', 1, 2] 4 Существует расширение iPython – ipython-yf ( https://github.com/tecki/ipython-yf ) – которое позво- ляет вычислять yield прямо в оболочке iPython. Оно используется для тестирования асинхрон- ного кода и работает совместно с asyncio . Это расширение предлагалось для включения в версию Python 3.5, но не было принято. См. проблему #22412 «T owards an asyncio-enabled command line» (http://bugs.python.org/issue22412 ) в системе отслеживания ошибок в Python. 5 На момент написания этих строк существует открытый документ, в котором предлагает добавить ключевые слова await и async: «PEP 492 – Coroutines with async and await syntax» ( https://www. python.org/dev/peps/pep-0492/ ).\n--- Страница 509 ---\n509 Использование yield from можно переписать в виде: >>> def gen(): yield from 'AB' yield from range(1, 3) >>> list(gen())['A', 'B', 1, 2] Впервые упомянув конструкцию yield from на стр. 465, мы привели для демонстрации код, повторенный в примере 16.166. Пример 16.16. Сцепление итерируемых объектов с помощью yield from >>> def chain(*iterables): for it in iterables: yield from it >>> s = 'ABC'>>> t = tuple(range(3))>>> list(chain(s, t))['A', 'B', 'C', 0, 1, 2] Чуть более сложный – но и более полезный – пример использования yield from приведен в рецепте 4.14 «Линеаризация вложенной последовательности» из книги Бизли и Джонса «Python Cookbook», издание 3, (исходный код опублико-ван на GitHub, http://bit.ly/1MMe1sc ). Первое, что делает выражение yield from x с объектом x, – вызов iter(x) для получения итератора. Это означает, что x может быть произвольным итерируе- мым объектом. Однако если бы замена вложенных циклов for отдачей значений была един- ственной пользой от yield from , то у этого добавления в язык было бы немного шансов на принятие. Истинную природу yield from нельзя продемонстрировать на простых итерируемых объектах, необходимо расширить кругозор, включив в него вложенные итераторы. Вот почему документ PEP 380, в котором описыва-ется yield from , озаглавлен «Syntax for Delegating to a Subgenerator» (Синтаксис делегирования субгенераторам). Основное применение yield from – открытие двустороннего канала между внешней вызывающей программой и внутренним субгенератором, так чтобы значения можно было отправлять и отдавать напрямую, а исключения возбуж-дать и обрабатывать без написания громоздкого стереотипного кода в проме-жуточных сопрограммах. Это открывает новую возможность – делегирование сопрограмме. Для использования yield from код должен быть организован нетривиальным образом. Для обсуждения обязательных частей в PEP 380 вводится специальная терминология: 6 Этот пример приведен исключительно в педагогических целях. В модуле itertools уже есть оптими- зированная функция chain, написанная на C.\n--- Страница 510 ---\n510 Глава 16. Сопрограммы делегирующий генератор Генераторная функция, содержащая выражение yield from <iterable> . субгенератор Генератор, полученный от итерируемого объекта <iterable> в выражении yield from . Это именно тот «субгенератор», который упомянут в заглавии документа PEP 380: «Syntax for Delegating to a Subgenerator». вызывающая сторона В PEP 380 термином «вызывающая сторона» обозначается клиентский код, который вызывает делегирующий генератор. В зависимости от кон-текста я иногда использую слово «клиент» вместо «вызывающая сторона», чтобы не путать с делегирующим генератором, который тоже является «вы-зывающей стороной» (он вызывает субгенератор). В документе PEP 380 часто для обозначения субгенератора ис- пользуется слово «итератор». Это только запутывает ситуацию, потому что делегирующий генератор также является итератором. Поэтому я предпочитаю термин «субгенератор», согласующийся с названием PEP – «Syntax for Delegating to a Subgenerator». Одна-ко субгенератор может быть простым итератором, реализующим только метод __next__ , а yield from может работать и в этом слу- чае, хотя задумывалась для поддержки генераторов, реализую-щих методы __next__ , send , close и throw . В примере 16.17 показан более полный контекст для применения yield from , а на рис 16.2 – важные части этого примера7. Рис. 16.2. Пока делегирующий генератор приостановлен в yield from , вызывающая сторона отправляет данные напрямую субгенератору, который отдает данные вызывающей стороне. Выполнение делегирующего генератора возобновляется, когда субгенератор возвращает управление и интерпретатор возбуждает исключение StopIteration с присоединенным к нему возвращенным значением 7 Рисунок 16.2 основан на диаграмме Пола Соколовского ( http://flupy.org/resources/yield-from.pdf ). вызывающая сторона делегирующий генератор субгенератор\n--- Страница 511 ---\n511 Использование yield from Скрипт coroaverager3.py читает словарь, содержащий данные о весе и росте девочек и мальчиков из воображаемого седьмого класса. Например, ключу 'boys;m' соответствуют данные о росте 9 мальчиков в метрах, а ключу 'girls;kg' – данные о весе 10 девочек в килограммах. Скрипт загружает данные о каждой группе в сопрограмму averager , показанную выше, и порождает такой отчет: $ python3 coroaverager3.py 9 boys averaging 40.42kg 9 boys averaging 1.39m10 girls averaging 42.04kg10 girls averaging 1.43m Код в примере 16.17, конечно, не назовешь самым простым решением задачи, но он демонстрирует yield from в действии. В основу примера положен код из статьи «What's New in Python 3.3» ( http://bit.ly/1HGrnV q ). Пример 16.17. coroaverager3.py: использование yield from для управления сопрограммой averager и печати статистического отчета from collections import namedtuple Result = namedtuple('Result', 'count average') # субгенератор def averager(): /g110 total = 0.0 count = 0 average = None while True: term = yield /g111 if term is None: /g112 break total += term count += 1 average = total/count return Result(count, average) /g113 # делегирующий генератор def grouper(results, key): /g114 while True: /g115 results[key] = yield from averager() /g116 # клиентский код, или вызывающая сторона def main(data): /g117 results = {} for key, values in data.items(): group = grouper(results, key) /g118 next(group) /g119 for value in values: group.send(value) ⤓ group .send(None) # важно! ⤔ # print(results) # раскомментировать для отладки\n--- Страница 512 ---\n512 Глава 16. Сопрограммы report(results) # вывод отчета def report(results): for key, result in sorted(results.items()): group, unit = key.split(';') print('{:2} {:5} averaging {:.2f}{}'.format( result.count, group, result.average, unit)) data = { 'girls;kg': [40.9, 38.5, 44.3, 42.2, 45.2, 41.7, 44.5, 38.0, 40.6, 44.5], 'girls;m': [1.6, 1.51, 1.4, 1.3, 1.41, 1.39, 1.33, 1.46, 1.45, 1.43], 'boys;kg': [39.0, 40.8, 43.2, 40.8, 43.1, 38.6, 41.4, 40.6, 36.3], 'boys;m': [1.38, 1.5, 1.32, 1.25, 1.37, 1.48, 1.25, 1.49, 1.46],} if __name__ == '__main__': main(data) /g110 Та же сопрограмма averager , что в примере 16.13. Здесь это субгенератор. /g111 Каждое значение, отправленное клиентским кодом в main , здесь связывает- ся с переменной term . /g112 У словие окончания. Без него выражение yield from , вызвавшее эту сопро- грамму, оказалось бы навечно блокированным. /g113 Возвращенное значение Result является значением выражения yield from в grouper . /g114 grouper – делегирующий генератор. /g115 На каждой итерации этого цикла создается новый экземпляр averager ; каждый из них является объектом-генератором, работающим как сопро-грамма. /g116 Значение, отправляемое генератору grouper , помещается выражением yield from в канал, открытый с объектом averager . grouper остается при- остановленным, пока averager потребляет значения, отправляемые клиен- том. Когда выполнение averager завершится, возвращенное им значение будет связано с results[key] . После этого в цикле while создается очеред- ной экземпляр averager для потребления последующих значений. /g117 main – клиентский код, или «вызывающая сторона» в терминологии PEP 380. Эта функция управляет всем остальным. /g118 group – объект-генератор, получающийся в результаты вызова grouper с аргументами results – словарем, в котором будут собираться результа- ты, – и key – конкретным ключом этого словаря. Этот объект будет рабо- тать как сопрограмма.\n--- Страница 513 ---\n513 Использование yield from /g119 Инициализируем сопрограмму. ⤓ Отправляем каждое значение value объекту grouper . Оно будет получено в строке term = yield кода averager ; grouper его никогда не увидит. ⤔ Отправка значения None объекту grouper приводит к завершению текущего экземпляра averager и дает возможность grouper возобновить выполнение и создать очередной объект averager для обработки следующей группы значений. Последний маркер в примере 16.17 с комментарием «важно!» помечает кри- тически важную строку кода: group.send(None) завершает работу одного объекта averager и запускает следующий. Если закомментировать эту строку, то скрипт ничего не напечатает. Раскомментировав строку print(results) в конце main , мы увидим, что словарь results пуст. Попробуйте самостоятельно разобраться, почему не получено никаких результатов, – это прекрасное упражнение на понимание работы yield from . Скрипт coroaverager3.py имеется в репозито- рии кода книги ( http://bit.ly/1JIofLL ). Объяснение приведено ниже. Разберемся, как работает пример 16.17, а заодно объясним, что произойдет, если исключить из main вызов group.send(None) , помеченный комментарием «важно!». • На каждой итерации внешнего цикла for создается новый экземпляр grou- per, названный group ; это делегирующий генератор. • Вызов next(group) инициализирует делегирующий генератор grouper , ко- торый входит в цикл while True и приостанавливается, достигнув yield from , после вызова субгенератора averager . • Во внутреннем цикле for вызывается group.send(value) ; отправленное зна- чение поступает непосредственно субгенератору averager . Тем временем текущий экземпляр group приостановлен в точке yield from . • Когда внутренний цикл for завершается, экземпляр group все еще при- остановлен, поэтому присваивание results[key] в теле grouper еще не про- изошло. • Без последнего вызова group.send(None) во внешнем цикле for субгене- ратор averager никогда не завершится, делегирующий генератор grouper никогда не активируется повторно, а присваивание results[key] так и не произойдет. • Когда управление возвращается в начало внешнего цикла for, создается и связывается с переменной group новый экземпляр grouper . А предыдущий становится добычей сборщика мусора (вместе с его персональным экзем-пляром субгенератора averager ).\n--- Страница 514 ---\n514 Глава 16. Сопрограммы Из этого эксперимента следует вынести важный урок: если суб- генератор никогда не завершается, то делегирующий генератор будет навечно блокирован в yield from . Программа при этом мо- жет продолжать работать, поскольку yield from (как и обычный yield ) передает управление клиентскому коду (т . е. вызывающей стороне делегирующего генератора). Но какая-то задача при этом останется незаконченной. Пример 16.17 показывает простейшую конфигурацию yield from , когда име- ется только один делегирующий генератор и один субгенератор. Но поскольку делегирующий генератор работает как канал, мы можем соединить любое их чис-ло, сформировав конвейер: один делегирующий генератор использует yield from , чтобы вызвать субгенератор, который сам является делегирующим генератором и вызывает следующий субгенератор с помощью yield from и так далее. Эта цепоч- ка должна заканчиваться простым генератором, в котором используется обычный yield , или произвольным итерируемым объектом, как в примере 16.16. Любая цепочка yield from должна управляться клиентом, который вызывает next(…) или .send(…) для самого внешнего делегирующего генератора. Это может быть неявный вызов, например цикл for. Теперь рассмотрим формальное описа- ние конструкции yield from так, как оно изложено в документе PEP 380. Семантика yield from Работая над документом PEP 380, Грэг Ивинг (Greg Ewing) – его автор – вы-нужден был отвечать на вопросы по поводу сложности предлагаемой семантики. И один из его ответов звучал так: «почти вся важная для человека информация содержится в одном абзаце в начале документа». А затем он процитировал часть документа PEP 380, которая в то время выглядела так: Когда итератор является другим генератором, эффект получа- ется таким же, как если бы тело субгенератора было текстуально встроено в месте, где находится выражение yield from . Более того, субгенератору разрешено выполнять предложение return , содер- жащее значение, и это значение становится значением выражения yield from .8 Этих утешительных слов в PEP больше нет, потому что они не покрывают все возможные случаи. Но в качестве первого приближения сойдет. В одобренном варианте PEP 380 поведение yield from объясняется в ше- сти пунктах раздела «Предложение» ( https://www.python.org/dev/peps/pep- 0380/#proposal ). Ниже я воспроизвел их почти буквально, только заменил неод- 8 Сообщение в списке рассылки Python-Dev: «PEP 380 (yield from a subgenerator) comments» ( http:// bit.ly/1JIopTu ) (21 марта 2009).\n--- Страница 515 ---\n515 Семантика yield from нозначное слово «итератор» на «субгенератор» и добавил несколько пояснений. В примере 16.17 продемонстрированы четыре из шести пунктов. • Все значения, отдаваемые субгенератором, передаются напрямую вызыва- ющей стороне делегирующего генератора (т. е. клиентскому коду). • Все значения, отправляемые делегирующему генератору методом send() , передаются напрямую субгенератору. Если отправлено значение None , то вызывается метод __next__() субгенератора. Если отправлено значение, отличное от None , то вызывается метод send() субгенератора. Если вызов возбуждает исключение StopIteration , выполнение делегирующего гене- ратора возобновляется. Любое другое исключение распространяется деле-гирующему генератору. • Выполнение return expr в генераторе (или субгенераторе) приводит к воз- буждению исключения StopIteration(expr) по выходе из генератора. • Значение выражения yield from является первым аргументом исключения StopIteration , возбуждаемого субгенератором при завершении. Еще два свойства yield from касаются исключений и завершения. • Исключения, отличные от GeneratorExit , возбуждаемые методом throw() в делегирующем генераторе, передаются методу throw() субгенератора. Если вызов возбуждает исключение StopIteration , то выполнение делегирующе-выполнение делегирующе- е делегирующе- го генератора возобновляется. Любое другое исключение распространяется делегирующему генератору. • Если в делегирующем генераторе методом throw() возбуждено исключение GeneratorExit или вызван метод close() делегирующего генератора, то вы- зывается метод close() субгенератора, если такой метод имеется. Если этот вызов приводит к исключению, то оно распространяется делегирующему генератору. В противном случае в делегирующем генераторе возбуждается исключение GeneratorExit . Детальная семантика yield from довольно сложна, особенно аспекты, касаю- щиеся исключений. Грэгу Ивингу пришлось немало потрудиться, чтобы изложить ее английским языком в документе PEP 380. Ивинг также документировал поведение yield from с помощью псевдокода (с синтаксисом Python). Лично я считаю полезным потратить некоторое время на изучение этого псевдокода в PEP 380. Однако он занимает 40 строк, и с налету его не поймешь. Но можно сначала рассмотреть самый простой и распространенный случай ис- пользования yield from . Допустим, что yield from встречается в делегирующем генераторе. Клиент- ский код управляет делегирующим генератором, а тот – субгенератором. Поэто-му, чтобы упростить логику, представим, что клиент никогда не вызывает методы .throw(…) и .close() делегирующего генератора. Представим также, что субгене-\n--- Страница 516 ---\n516 Глава 16. Сопрограммы ратор не возбуждает исключений до момента завершения, когда сам интерпрета- тор возбуждает исключение StopIteration . В скрипте из примера 16.17 эти упрощающие предположения верны. Да и в реальном коде обычно ожидается, что делегирующий генератор выполняется до естественного завершения. Итак, посмотрим, как yield from работает в этом про- стом и счастливом мире. Взгляните на пример 16.18, где развернуто одно-единственное предложение в теле делегирующего генератора: RESULT = yield from EXPR Попробуйте проследить логику. Пример 16.18. Упрощенный псевдокод, эквивалентный предложению RESULT = yield from EXPR в делегирующем генераторе (этот код охватывает только простейший случай: методы .throw( …) и .close() не поддерживаются, а единственное обрабатываемое исключение – StopIteration ) _i = iter(EXPR) /g110 try: _y = next(_i) /g111 except StopIteration as _e: _r = _e.value /g112 else: while 1: /g113 _s = yield _y /g114 try: _y = _i.send(_s) /g115 except StopIteration as _e: /g116 _r = _e.value break RESULT = _r /g117 /g110 EXPR может быть произвольным итерируемым объектом, поскольку для по- лучения итератора _i (субгенератора) применяется метод iter() . /g111 Субгенератор инициализирован, результат сохраняется, чтобы потом стать первым отданным значением _y. /g112 Если было возбуждено исключение StopIteration , то извлечь его атрибут value и присвоить его переменной _r; в простейшем случае это будет ре- зультат RESULT . /g113 Пока этот цикл работает, делегирующий генератор блокирован и действует просто как канал между вызывающей стороной и субгенератором. /g114 Отдаем текущий элемент, порожденный субгенератором; ждем, когда вы- зывающая сторона отправит значение _s. Отметим, что это единственный раз, когда в листинге встречается слово yield . /g115 Пытаемся сдвинуть с места субгенератор, переправляя ему значение _s, от- правленное вызывающей стороной.\n--- Страница 517 ---\n517 Семантика yield from /g116 Если субгенератор возбудил исключение StopIteration , получить value , присвоить это значение переменной _r и выйти из цикла, возобновив тем самым делегирующий генератор. /g117 _r становится результатом RESULT – значением всего выражения yield from . В этом упрощенном псевдокоде я сохранил имена переменных из реального псевдокода, опубликованного в PEP 380, а именно: _i (iterator) Субгенератор. _y (yielded) Значение, отданное субгенератором. _r (result) Окончательный результат (т. е. значение выражения yield from по завер- шении субгенератора). _s (sent) Значение, отправленное вызывающей стороной делегирующему генерато- ру, которое переправляется субгенератору. _e (exception) Исключение (в этом упрощенном псевдокоде всегда экземпляр класса Sto- pIteration ) Мало того что в этом упрощенном псевдокоде не обрабатываются вызовы ме- тодов .throw(…) и .close() , так еще для перенаправления субгенератору вызовов next() и .send(…) со стороны клиента всегда используется метод .send(…) . Но не «заморачивайтесь» этими тонкими различиями при первом чтении. Как уже было сказано, пример 16.17 отлично работал бы, даже если бы конструкция yield from умела делать только то, что показано в примере 16.18. Однако жизнь сложнее, потому что нужно уметь обрабатывать вызовы .throw(…) и .close() со стороны клиента, передавая их субгенератору. Кроме того, субгенератор может оказаться простым итератором, не поддерживающим методы .throw(…) и .close() , и логика yield from должна это учитывать. А если суб- генератор все-таки реализует эти методы, то внутри него они могут возбуждать исключения, которые механизм yield from тоже должен обрабатывать. Субгене- ратор может и сам возбуждать исключения, не спровоцированные вызывающей стороной, и реализация yield from не должна остаться к ним безучастной. На- конец, возможна оптимизация: если вызывающая сторона вызывает next(…) или .send(None) , то оба вызова транслируются в вызов next(…) субгенератора, и лишь если вызывающая сторона отправляет значение, отличное от None , то для его пере- направления субгенератору применяется метод .send(…) . Для удобства ниже приведен полный псевдокод yield from из документа PEP 380 с аннотациями. Код скопирован буквально, я добавил только выноски.\n--- Страница 518 ---\n518 Глава 16. Сопрограммы Как и раньше, пример 16.19 – это расширение одного предложения в теле де- легирующего генератора: RESULT = yield from EXPR Пример 16.19. Псевдокод, эквивалентный предложению RESULT = yield from EXPR в делегирующем генераторе _i = iter(EXPR) /g110 try: _y = next(_i) /g111 except StopIteration as _e: _r = _e.value /g112 else: while 1: /g113 try: _s = yield _y /g114 except GeneratorExit as _e: /g115 try: _m = _i.close except AttributeError: pass else: _m() raise _e except BaseException as _e: /g116 _x = sys.exc_info() try: _m = _i.throw except AttributeError: raise _e else: /g117 try: _y = _m(*_x) except StopIteration as _e: _r = _e.value break else: /g118 try: /g119 if _s is None: ⤓ _y = next(_i) else: _y = _i.send(_s) except StopIteration as _e: ⤔ _r = _e.value break RESULT = _r ⤕ /g110 EXPR может быть произвольным итерируемым объектом, поскольку для по- лучения итератора _i (субгенератора) применяется метод iter() . /g111 Субгенератор инициализирован, результат сохраняется, чтобы потом стать первым отданным значением _y.\n--- Страница 519 ---\n519 Семантика yield from /g112 Если было возбуждено исключение StopIteration , то извлечь его атрибут value и присвоить его переменной _r; в простейшем случае это будет ре- зультат RESULT . /g113 Пока этот цикл работает, делегирующий генератор блокирован и действует просто как канал между вызывающей стороной и субгенератором. /g114 Отдаем текущий элемент, порожденный субгенератором; ждем, когда вы- зывающая сторона отправит значение _s. Это единственный раз, когда в листинге встречается слово yield . /g115 Здесь обрабатывается закрытие делегирующего генератора и субгенерато- ра. Поскольку субгенератор может быть произвольным итератором, то на-личие у него метода close необязательно. /g116 Здесь обрабатываются исключения, возбужденные вызывающей стороной с помощью метода .throw(…) . И снова субгенератор может быть произволь- ным итератором, не имеющим метода throw , и в таком случае в делегирую- щем генераторе возникает исключение. /g117 Если у субгенератора есть метод throw , вызываем его, передавая исключение, полученное от вызывающей стороны. Субгенератор может обработать исключение (тогда цикл продолжится) или возбудить исключение StopIt- eration (из него извлекается результат _r и цикл завершается) или возбудить то же самое или другое исключение, которое здесь не обрабатывается, а распространяется делегирующему генератору. /g118 Если при отдаче не возникло исключение… /g119 Пытаемся сдвинуть с места субгенератор… ⤓ Вызываем метод next субгенератора, если последнее полученное от вызывающей стороны значение было равно None ; в противном случае вызываем send . ⤔ Если субгенератор возбудил исключение StopIteration , получить value , присвоить это значение переменной _r и выйти из цикла, возобновив тем самым делегирующий генератор. ⤕ _r становится результатом RESULT – значением всего выражения yield from . Логика псевдокода yield from по большей части сосредоточена в шести вло- женных до уровня 4 блоках try/except , поэтому читать его трудно. Кроме них, используются только ключевые слова управления потоком: одно while , одно if и одно yield . Найдите вхождения while , yield , а также вызовы next(…) и .send(…) : это поможет составить представление о том, как работает вся конструкция. В самом начале примере 16.19 псевдокод раскрывает одну важную деталь: ини- циализацию субгенератора (вторая выноска)9. Это означает, что автоинициализи- рующие декораторы типа того, что описан в разделе «Декораторы для инициали-зации сопрограмм» выше, несовместимы с yield from . В том же сообщении ( http://bit.ly/1JIopTu ), которое я цитировал в начале этого раздела, Грэг Ивинг пишет о псевдокоде, расширяющем yield from : 9 В сообщении в списке рассылки Python-ideas от 5 апреля 2009 ( http://bit.ly/1JIoXJ1 ) Ник Кофлин (Nick Coghlan) спросил, так ли хороша идея неявной инициализации, выполняемой yield.\n--- Страница 520 ---\n520 Глава 16. Сопрограммы Не предполагается, что вы будете изучать этот механизм, читая псевдокод, – он приведен лишь для языковых адвокатов, желаю-щих, чтобы все детали были зафиксированы письменно. У делять чрезмерное внимание деталям псевдокода, может быть, и не слишком полезно – все зависит от того, как вы привыкли учиться. Изучение реального кода, в котором используется yield from , безусловно, более плодотворно, чем сосредо- точенное штудирование псевдокода реализации. Однако почти все применения yield from , которые мне встречались, относятся к асинхронному программиро- ванию с помощью модуля asyncio , т. е. зависят от активного цикла обработки со- бытий. Мы много раз встретим yield from в главе 18. В разделе «Дополнительная литература» приведено несколько ссылок на интересные примеры использования yield from без цикла обработки событий. А сейчас перейдем к классическому примеру использования сопрограмм: моде- лированию. В этом примере не будет yield from , зато мы увидим, как сопрограммы позволяют управлять параллельными действиями в одном потоке. Пример: применение сопрограмм для моделирования дискретных событий Сопрограммы дают естественный способ выразить многие алгоритмы, в том числе моделирование, игры, асинхронный ввод-вывод и другие формы событийно-управляемого программирования или невытесняю-щей многозадачности 10. – Гвидо ван Россум и Филипп Дж. Эби PEP 342 – Coroutines via Enhanced Generators В этом разделе я опишу очень простую модель, реализованную с помощью од-них лишь сопрограмм и объектов из стандартной библиотеки. Моделирование – классический пример применения сопрограмм в литературе по информатике. В первом объектно-ориентированном языке Simula концепция сопрограмм была введена специально для поддержки моделирования. Мотивация приведенного ниже примера – не только академиче- ский интерес. Сопрограммы – это фундаментальный структурный элемент пакета asyncio . Моделирование показывает , как реали- зовать параллельные операции, используя сопрограммы вместо потоков, и это очень пригодится, когда в главе 18 мы займемся асинхронным вводом-выводом. 10 Первая фраза в разделе «Мотивация» документа PEP 342 ( https://www.python.org/dev/peps/pep- 0342/ ).\n--- Страница 521 ---\n521 Прежде чем приступать к примеру, скажу несколько слов о моделировании. О моделировании дискретных событий Моделирование дискретных событий (discrete event simulation – DES) – мето- дика, предполагающая, что система моделируется в виде хронологической после-довательности событий. В DES часы модельного времени сдвигаются не на оди-наковое приращение, а сразу к модельному времени следующего моделируемого события. Например, если моделируется работа такси на верхнем уровне, то первое событие – посадка пассажира, а следующая – высадка. Неважно, сколько времени заняла поездка – 5 или 50 минут: когда наступает событие высадки, часы сдвига-ются к времени окончания поездки за одну операцию. В DES работу такси в тече-ние целого года можно смоделировать менее чем за секунду. Этим оно отличается от непрерывного моделирования, когда часы сдвигаются на фиксированный – и обычно небольшой – интервал. Интуитивно понятно, что игры со сменой хода – примеры моделирования дис- кретных событий: состояние игры изменяется только после хода игрока, а пока игрок обдумывает следующий ход, часы модельного времени стоят. С другой сто-роны, игры реального времени представляют собой непрерывное моделирование, когда часы модельного времени постоянно идут, а состояние игры обновляется много раз в секунду, так что игроки-тугодумы оказываются в невыгодном поло-жении. Оба вида моделирования можно запрограммировать как с помощью несколь- ких потоков, так и в одном потоке, применяя событийно-ориентированные мето-ды программирования, например, обратные вызовы или сопрограммы, управля-емые циклом обработки событий. Непрерывное моделирование, пожалуй, более естественно реализуется с помощью потоков, которые позволяют выполнять не-сколько действий реально в одно и то же время. С другой стороны, сопрограммы предлагают идеальную абстракцию для DES. SimPy 11 – написанный на Python пакет DES, в котором каждый моделируемый процесс представлен одной сопро-граммой. В моделировании процессом называют действия модельной сущности, а не процесс в смысле ОС. Моделируемый процесс можно реализовать в виде процесса ОС, но обычно для этой цели применяют сопрограмму или поток. Если вас интересует моделирование, то стоит изучить пакет SimPy. Но в этом разделе я опишу очень простую модель DES, для реализации которой хватит воз-можностей стандартной библиотеки. Моя цель – помочь вам развить интуицию, необходимую для программирования параллельных действий с помощью сопро-грамм. Чтение следующего раздела потребует сосредоточения, но наградой ста- 11 См. официальную документацию по Simpy ( http://bit.ly/1HGs4Oz ) – не путайте с хорошо извест- ным пакетом SymPy ( http://bit.ly/1HGs3Kl ) для символьных вычислений.Пример: применение сопрограмм для моделирования\n--- Страница 522 ---\n522 Глава 16. Сопрограммы нет понимание того, как библиотеки типа asyncio , T wisted и T ornado ухитряются управлять многочисленными параллельными операциями в одном потоке выпол-нения. Моделирование работы таксопарка В нашей программе моделирования taxi_sim.py создается несколько экземпля- ров такси. Каждое такси совершает фиксированное количество поездок и возвра-щается в гараж. Такси выезжает из гаража и начинает «рыскать» – искать пассажи-ра. Это продолжается, пока пассажир не сядет в такси, в этот момент начинается поездка. Когда пассажир выходит, такси возвращается в режим поиска. Время поиска и поездок имеет экспоненциальное распределение. Для просто- ты отображения время измеряется в минутах, но для моделирования можно при-менять и интервалы типа float12. Всякое изменение состояния любого такси выво- дится как событие. На рис. 16.3 показан пример прогона программы. Рис. 16.3. Пример прогона скрипта taxi_sim.py при трех такси. Аргумент -s 3 инициализирует генератор случайных чисел, так что поведение программы можно воспроизвести для отладки и демонстрации. Стрелками показаны поездки 12 Я не специалист по работе таксопарка, поэтому не принимайте приведенные ниже числа всерьез. Экспоненциальное распределение часто применяется в DES. Некоторые поездки оказались очень короткими. Представьте, что выдался дождливый денек, и некоторые пассажиры берут такси, чтобы проехать всего один квартал – в идеальном городе, где в дождь можно поймать такси.\n--- Страница 523 ---\n523 Главное, что нужно отметить на рис. 16.3, – чередование поездок всех трех такси. Я вручную добавил стрелки, чтобы поездки было лучше видно: стрелка начинается в момент посадки пассажира и кончается в момент высадки. Это дает интуитивное представление о том, как можно использовать сопрограммы для управления параллельными действиями Вот на что еще стоит обратить внимание: • Интервал между выездами такси из гаража составляет 5 минут. • В такси 0 первый пассажир сел через 2 минуты после выезда, в момент вре- мени time=2 ; в такси 1 – через 3 минуты ( time=8 ), а в такси 2 – через 5 минут (time=15 ). • Водитель такси 0 сделал только две поездки: первая началась в момент time=2 и закончилась в момент time=18 ; вторая началась в момент time=28 и закончилась в момент time=65 – это самая длинная поездка в данном про- гоне модели. • Такси 1 сделало 4 поездки, после чего вернулось в гараж в момент time=110 . • Такси 2 сделало 6 поездок и вернулось в гараж в момент time=109 . Его по- следняя поездка длилась всего одну минуту, начавшись в момент time=9713. • Пока такси 1 совершает свою первую поездку, начавшуюся в момент time=8 , такси 2 выезжает из гаража в момент time=10 и успевает совершить две по- ездки (короткие стрелки). • В этом прогоне все запланированные события завершились в отведенное по умолчанию время моделирования 180 минут; последнее событие про-изошло в момент time=110 . Но может случиться и так, что время моделирование закончилось, а события еще остались. В таком случае последнее сообщение выглядело бы так: *** end of simulation time: 3 events pending *** Полный текст скрипта taxi_sim.py приведен в примере A.6. В этой главе пока- A.6. В этой главе пока-.6. В этой главе пока- заны только части, имеющие отношение к сопрограммам. По-настоящему важны всего две функции: taxi_process (сопрограмма) и метод Simulator.run , в котором выполняется главный цикл моделирования. В примере 16.20 показан код функции taxi_process . В ней используются два объекта, определенных где-то в другом месте: функция compute_delay , которая возвращает временной интервал в минутах, и класс Event – именованный кортеж, определенный следующий образом: Event = collections.namedtuple('Event', 'time proc action') В экземпляре Event атрибут time – это модельное время события, proc – иден- тификатор процесса такси, а action – строка, описывающая действие. Рассмотрим подробнее код taxi_process , представленный в примере 16.20. 13 Я был в нем пассажиром. Я понял, что оставил дома бумажник.Пример: применение сопрограмм для моделирования\n--- Страница 524 ---\n524 Глава 16. Сопрограммы Пример 16.20. taxi_sim.py: реализация действий каждого такси в сопрограмме taxi_process def taxi_process(ident, trips, start_time=0): /g110 \"\"\"Отдает модели событие при каждой смене состояния\"\"\" time = yield Event(start_time, ident, 'leave garage') /g111 for i in range(trips): /g112 time = yield Event(time, ident, 'pick up passenger') /g113 time = yield Event(time, ident, 'drop off passenger') /g114 yield Event(time, ident, 'going home') /g115 # конец процесса такси /g116 /g110 taxi_process вызывается один раз для каждого такси и создает объект-ге- нератор, представляющий его действия. ident – это номер такси (в нашем примере 0, 1, 2), trips – сколько поездок должно совершить такси, перед тем как вернуться в гараж; start_time – когда такси выезжает из гаража. /g111 Первый отданный объект Event – 'leave garage' (выезд из гаража). Выполнение сопрограммы приостанавливается, так что главный цикл моделирования может перейти к следующему запланированному событию. Когда настанет время возобновить этот процесс, главный цикл отправит (методом send ) текущее модельное время, которое будет присвоено пере- менной time . /g112 Этот блок повторяется по одному разу для каждой поездки. /g113 Отдается событие посадки пассажира. Здесь сопрограмма приостанавлива- ется. Когда настанет время возобновить этот процесс, главный цикл снова отправит текущее время. /g114 Отдается событие высадки пассажира. Сопрограмма снова приостанавли- вается и ждет, когда главный цикл отправит ее время возобновления. /g115 Цикл for заканчивается после заданного числа поездок и отдается послед- нее событие 'going home' (еду в гараж). Сопрограмма приостанавливается в последний раз. При возобновлении она получит от главного цикла мо-дельное время, но я не присваиваю его никакой переменной, потому что оно не будет использоваться. /g116 Когда сопрограмма доходит до конца, объект-генератор возбуждает исклю- чение StopIteration . Вы можете сами «поуправлять» такси, вызывая функцию taxi_process из обо- лочки Python14. В примере 16.21 показано, как это делается. Пример 16.21. Управление сопрограммой taxi_process >>> from taxi_sim import taxi_process >>> taxi = taxi_process(ident=13, trips=2, start_time=0) /g110 14 Глагол «управлять» (drive) обычно употребляется для описания работы сопрограммы: клиентский код управляет сопрограммой, отправляя ей значения. В примере 16.21 то, что вы вводите в оболоч-ке, и есть клиентский код.\n--- Страница 525 ---\n525 >>> next(taxi) /g111 Event(time=0, proc=13, action='leave garage')>>> taxi.send(_.time + 7) /g112 Event(time=7, proc=13, action='pick up passenger') /g113 >>> taxi.send(_.time + 23) /g114 Event(time=30, proc=13, action='drop off passenger')>>> taxi.send(_.time + 5) /g115 Event(time=35, proc=13, action='pick up passenger')>>> taxi.send(_.time + 48) /g116 Event(time=83, proc=13, action='drop off passenger')>>> taxi.send(_.time + 1)Event(time=84, proc=13, action='going home') /g117 >>> taxi.send(_.time + 10) /g118 Traceback (most recent call last):File \"<stdin>\", line 1, in <module>StopIteration /g110 Создаем объект-генератор, представляющий такси с ident=13 , которое сде- лает две поездки и начнет работать в момент t=0. /g111 Инициализируем сопрограмму, она отдает начальное событие. /g112 Теперь можно отправить ей текущее время. В оболочке переменная _ связа- на с последним результатом; здесь я прибавляю 7 к текущему времени, т. е. такси потратит на поиск первого пассажира 7 минут. /g113 Это событие отдается циклом for в начале первой поездки. /g114 Отправка _.time + 23 означает, что поездка с первым пассажиром займет 23 минуты. /g115 Затем такси будет 5 минут искать пассажира. /g116 Последняя поездка займет 48 минут. /g117 После завершения двух поездок цикл заканчивается и отдается событие 'going home' . /g118 Следующая попытка послать что-то сопрограмме приводит к естественно- му возврату из нее. В этот момент интерпретатор возбуждает исключение StopIteration . В примере 16.21 я использую оболочку для имитации главного цикла модели- рования. Я получаю атрибут .time объекта Event , отданного сопрограммой taxi , прибавляю к нему произвольное число, и отправляю сумму методом taxi.send для возобновления сопрограммы. При моделировании все сопрограммы, представля-ющие такси, управляются главным циклом в методе Simulator.run . Часы модель- ного времени хранятся в переменной sim_time и обновляются временем каждого отданного события. Чтобы создать экземпляр класса Simulator , функция main из скрипта taxi_sim. py строит словарь taxis : taxis = {i: taxi_process(i, (i + 1) * 2, i * DEPARTURE_INTERVAL) for i in range(num_taxis)} sim = Simulator(taxis)Пример: применение сопрограмм для моделирования\n--- Страница 526 ---\n526 Глава 16. Сопрограммы Здесь DEPARTURE_INTERVAL равно 5; если num_taxis равно 3, как в демонстраци- онном прогоне, то показанные выше строчки делают то же самое, что: taxis = {0: taxi_process(ident=0, trips=2, start_time=0), 1: taxi_process(ident=1, trips=4, start_time=5), 2: taxi_process(ident=2, trips=6, start_time=10)}sim = Simulator(taxis) Поэтому значениями в словаре taxis будут три объекта-генератора с разными параметрами. Например, такси 1 совершит 4 поездки и начнет поиск пассажиров в момент start_time=5 . Этот словарь – единственный аргумент, необходимый для создания объекта Simulator . Метод Simulator.__init__ показан в примере 16.22. Перечислим главные структуры данных Simulator : self.events Очередь с приоритетами PriorityQueue для хранения объектов Event . Структура PriorityQueue позволяет помещать элементы методом put и извлекать их методом get в порядке, определяемом элементом item[0] ; в случае именованных кортежей Event это атрибут time . self.procs Словарь dict , отображающий номер процесса на активный процесс моде- лирования – объект-генератор, представляющий одно такси. Он будет свя-зан с копией словаря taxis , показанного выше. Пример 16.22. taxi_sim.py: инициализатор класса Simulator class Simulator: def __init__(self, procs_map): self.events = queue.PriorityQueue() /g110 self.procs = dict(procs_map) /g111 /g110 Очередь PriorityQueue для хранения запланированных событий, упорядо- ченная по возрастанию времени. /g111 Мы получаем аргумент procs_map в виде словаря (или произвольного ото- бражения), но строим из него другой словарь, чтобы иметь локальную ко-пию, потому что по ходу моделирования каждое такси, возвращающееся в гараж, удаляется из self.procs , а мы не хотим изменять объект, переданный пользователем. Очереди с приоритетами – важнейшая структура данных в моделировании дискретных событий: события создаются в произвольном порядке, помещаются в очередь, а впоследствии извлекаются в порядке запланированного времени со-бытия. Например, мы могли бы в самом начале поместить в очередь такие два со-бытия: Event(time=14, proc=0, action='pick up passenger')Event(time=11, proc=1, action='pick up passenger')\n--- Страница 527 ---\n527 Это означает, что такси 0 потребуется 14 минут для поиска первого пассажира, а такси 1, которое выехало из гаража в момент time=10 , – всего 1 минуту, первый пассажир сядет в момент time=11 . Если эти два события находятся в очереди, то первым главный цикл извлечет событие Event(time=11, proc=1, action='pick up passenger') . Теперь рассмотрим основной алгоритм моделирования, метод Simulator.run . Он вызывается из функции main сразу после создания объекта Simulator : sim = Simulator(taxis)sim.run(end_time) В примере 16.23 приведен полный текст класса Simulator с аннотациями, а пока дадим общий обзор алгоритма: 1. Цикл по процессам, представляющим такси. a. Инициализировать сопрограмму для каждого такси, вызвав для нее функцию next() . В ответ будет отдано первое событие для такси. b. Поместить каждое событие в очередь self.events объекта Simulator . 2. Выполнять главный цикл моделирования, пока sim_time < end_time . a. Проверить, пуста ли очередь self.events ; если да, выйти из цикла. b. Получить из self.events текущее событие current_event . Это будет объект Event с наименьшим временем. c. Вывести Event . d. Обновить модельное время, присвоив ему значение атрибута time объ- екта current_event . e. Отправить время сопрограмме, определяемой атрибутом proc объекта current_event . Сопрограмма отдаст следующее событие next_event . f. Запланировать next_event , поместив его в очередь self.events . Полный текст класса Simulator приведен в примере 16.23. Пример 16.23. taxi_sim.py: Simulator , простейший класс моделирования дискретных событий, наиболее интересен метод run class Simulator: def __init__(self, procs_map): self.events = queue.PriorityQueue() self.procs = dict(procs_map) def run(self, end_time): /g110 \"\"\"Планировать и отображать события, пока не истечет время\"\"\" # Запланировать первое событие для каждого такси for _, proc in sorted(self.procs.items()): /g111 first_event = next(proc) /g112 self.events.put(first_event) /g113 # главный цикл моделирования sim_time = 0 /g114Пример: применение сопрограмм для моделирования\n--- Страница 528 ---\n528 Глава 16. Сопрограммы while sim_time < end_time: /g115 if self.events.empty(): /g116 print('*** end of events ***') break current_event = self.events.get() /g117 sim_time, proc_id, previous_action = current_event /g118 print('taxi:', proc_id, proc_id * ' ', current_event) /g119 active_proc = self.procs[proc_id] ⤓ next_time = sim_time + compute_duration(previous_action) ⤔ try: next_event = active_proc.send(next_time) ⤕ except StopIteration: del self.procs[proc_id] ⤖ else: self.events.put(next_event) ⤗ else: ⤘ msg = '*** end of simulation time: {} events pending ***' print(msg.format(self.events.qsize())) /g110 Окончание модельного времени end_time – единственный обязательный аргумент run. /g111 Используем функцию sorted для выборки элементов self.procs , упорядо- ченных по ключу; сам ключ нам не важен, поэтому присваиваем его пере-менной _. /g112 Вызов next(proc) инициализирует каждую сопрограмму, заставляя ее дой- ти до первого предложения yield , после чего ей можно посылать данные. Отдается объект Event . /g113 Помещаем каждое событие в очередь с приоритетами self.events . Первым событием для каждого такси является 'leave garage' , как видно из распе- чатки демонстрационного прогона (пример 16.20). /g114 Обнуляем часы модельного времени sim_time . /g115 Главный цикл моделирования: выполнять, пока sim_time меньше end_time . /g116 Выход из главного цикла производится и тогда, когда в очереди не осталось событий. /g117 Получаем из очереди объект Event с наименьшим значением time ; присваи- ваем его переменной current_event . /g118 Распаковываем кортеж Event . В этой строке часы модельного времени sim_ time приводятся в соответствии с временем события15. /g119 Распечатываем объект Event : выводим идентификатор такси и соответству- ющий ему отступ. ⤓ Извлекаем сопрограмму для активного такси из словаря self.procs . ⤔ Вычисляем время следующего возобновления, складывая sim_time и ре- зультат вызова функции compute_duration( …) для предыдущего действия (т. е. 'pick up passenger' , 'drop off passenger' и т. д.) 15 Это типично для моделирования дискретных событий: часы модельного времени не увеличиваются на фиксированную величину на каждой итерации цикла, а сдвигаются в соответствии с продолжи-тельностью закончившегося события.\n--- Страница 529 ---\n529 Резюме ⤕ Отправляем time сопрограмме такси. Сопрограмма отдаст next_event или возбудит исключение StopIteration по завершении. ⤖ Если возникло исключение StopIteration , удаляем сопрограмму из слова- ря self.procs . ⤗ В противном случае помещаем next_event в очередь. ⤘ Если произошел выход из цикла в связи с истечением времени, печатаем количество оставшихся в очереди событий (иногда, по чистому совпаде-нию, оно может оказаться равным нулю). Обратите внимание, что в методе Simulator.run в двух местах используются блоки else , не имеющие отношение к предложению if; мы рассматривали этот вопрос в главе 15. • В главном цикле while часть else выполняется, когда моделирование завершилось из-за превышения end_time , а не потому, что в очереди не оста- лось событий. • В предложении try в конце цикла while мы пытаемся получить next_event , отправляя next_time процессу текущего такси, и если не возникло ошибки, то в блоке else помещаем next_event в очередь self.events . Я полагаю, что читать код метода Simulator.run без этих блоков else было бы несколько труднее. Целью этого примера было показать главный цикл обработки событий, который управляет сопрограммами, отправляя им данные. Это основная идея пакета asyncio , являющегося темой главы 18. Резюме Гвидо ван Россум писал, что существует три разных стиля кодирования с исполь-зованием генераторов: Есть традиционный стиль на основе «вытягивания» (итерато- ры), стиль на основе «выталкивания» (как в примере с вычислени-ем среднего) и «задачи» (вы еще не читали пособие Дэвида Бизли по сопрограммам?) 16. Итераторам была посвящена глава 14. В этой главе мы познакомились с со- программами, используемыми в стиле «выталкивания», а также с очень простыми «задачами» – процессами такси в примере моделирования. В главе 18 мы превра-тим их в асинхронные задачи в параллельном программировании. В примере вычисления накопительного среднего было продемонстрировано типичное применение сопрограммы: в качестве аккумулятора, обрабатывающего отправляемые ему данные. Мы видели, как можно инициализировать сопрограм- 16 Сообщение в ветви «Yield-From: Finalization guarantees» ( http://bit.ly/1JIqjn6 ) списка рассылки Python-ideas. Пособие Дэвида Бизли, на которое ссылается Гвидо, называется «A Curious Course on Coroutines and Concurrency» ( http://www.dabeaz.com/coroutines/ ).\n--- Страница 530 ---\n530 Глава 16. Сопрограммы му с помощью декоратора, иногда это бывает удобно. Но помните, что инициа- лизирующие декораторы несовместимы с некоторыми способами использования сопрограмм. В частности, конструкция yield from subgenerator() предполагает, что subgenerator не инициализирован и инициализирует его автоматически. Аккумулирующие сопрограммы могут отдавать частичные результаты при каждом вызове метода send , но особенно полезны те из них, которые возвраща- ют значения – эта возможность была описана в документе PEP 380 и включена в версию Python 3.3. Мы видели, что предложение return the_result внутри гене- ратора теперь возбуждает исключение StopIteration(the_result) , что позволяет вызывающей стороне извлечь результат the_result из атрибута исключения value . Такой способ получения результата сопрограммы изящным не назовешь, но пред-ложение yield from , описанное в PEP 380, делает это автоматически. Мы начали рассмотрение yield from с тривиальных примеров работы с про- стыми итерируемыми объектами, а затем перешли к примеру, демонстрирующе-му три главных составных части yield from : делегирующий генератор (опреде- ляемый выражением yield from в его теле), субгенератор, активируемый yield from , и клиентский код, который организует совместную работу всех компонентов, отправляя субгенератору значения по сквозному каналу, который устанавливает yield from в делегирующем генераторе. В конце раздела мы познакомились с формальным определением поведения yield from , как оно описано в PEP 380 на обычном языке и на псевдокоде, напоминающем Python. В заключение мы разобрали пример моделирования дискретных событий, по- казав, как можно использовать генераторы вместе потоков и обратных вызовов для поддержки одного из видов параллелизма. И хотя пример моделирования работы такси был совсем простым, он все же дает представление о том, как в та-ких событийно-управляемых каркасах, как T ornado и asyncio , главный цикл ис- пользуется для управления сопрограммами, которые выполняют параллельные действия в одном потоке. В событийно-ориентированных программах на основе сопрограмм каждая параллельная операция выполняется сопрограммой, которая периодически уступает управление главному циклу, давая возможность порабо-тать другим сопрограммам. Это вариант невытесняющей многозадачности: сопро-граммы добровольно и явно уступают управление центральному планировщику. Противоположностью являются потоки, реализующие вытесняющую многоза-дачность. Планировщик может приостановить поток в любой момент времени – даже в середине предложения – и передать управление другому потоку . И последнее замечание: в этой главе было принято широкое неформальное определение сопрограммы: генераторная функция, управляемая клиентским кодом, который посылает ей данные с помощью метода .send(…) или предложе- ния yield from . Именно такое широкое определение используется в документе «PEP 342 – Coroutines via Enhanced Generators» ( https://www.python.org/dev/ peps/pep-0342/ ) и в большинстве книг по Python. Библиотека asyncio , с которой мы познакомимся в главе 18, построена на основе сопрограмм, но там определение сопрограммы более строгое: сопрограммы в asyncio (обычно) снабжены декора- тором @asyncio.coroutine и управляются только с помощью yield from – метод\n--- Страница 531 ---\n531 Дополнительная литература .send(…) напрямую никогда не вызывается. Разумеется, под капотом сопрограм- мы asyncio управляются с помощью next(…) и .send(…) , но на уровне пользова- тельского кода встречается только yield from . Дополнительная литература Дэвид Бизли – непререкаемый авторитет по генераторам и сопрограммам в Python. В книге «Python Cookbook», издание 3 (O'Reilly), написанной им со-вместно с Брайаном Джонсом, есть немало рецептов, относящихся к сопрограм-мам. Представленные Бизли на конференциях PyCon пособия на эту тему просла-вились своей широтой и глубиной охвата. Первое увидело свет на конференции PyCon US 2008: «Generator Tricks for Systems Programmers» (Приемы работы с ге-нераторами для системных программистов) ( http://www.dabeaz.com/generators/ ). На PyCon US 2009 было представлено легендарное пособие «A Curious Course on Coroutines and Concurrency» (Курьезный курс по сопрограммам и параллелизму) (http://www.dabeaz.com/coroutines/ ) (вот ссылки на все три части: часть 1 – http:// pyvideo.org/video/213 , часть 2 – http://pyvideo.org/video/215 , часть 3 – http:// pyvideo.org/video/214 ). Самое последнее пособие, представленное на PyCon 2014 в Монреале, называется «Generators: The Final Frontier» (Генераторы: последний фронтир) ( http://www.dabeaz.com/finalgenerator/ ), в нем он рассматривает допол- нительные примеры параллелизма, так что оно, скорее, относится к тематике гла-вы 18. Дэйв не может противиться желанию взорвать мозг слушателей, поэтому в последней части «Последнего фронтира» сопрограммы заменяют классический паттерн Посетитель при вычислении арифметических выражений. Сопрограммы предлагают новые способы организации кода, к ним нужно при- выкнуть – так же, как к использованию рекурсии или полиморфизма (динами-ческой диспетчеризации). Интересный пример классического алгоритма, пере-писанного с помощью сопрограмм, приведен в статье Джеймса Пауэлла «Greedy algorithm with coroutines» ( http://bit.ly/1HGsFQ0 ). Рекомендую также посмо- треть популярные рецепты с тегом coroutine (http://bit.ly/1HGsFzA ) в базе данных ActiveState Code ( https://code.activestate.com/recipes/ ). Пол Соколовский (Paul Sokolovsky) реализовал yield from в сверхкомпактном интерпретаторе MicroPython ( http://micropython.org ) Дамиэна Джорджа (Damien George) ( http://micropython.org ), предназначенном для работы в микроконтролле- рах. Изучая этот механизм, он нарисовал большую детальную схему работы yield from (http://bit.ly/1JIqGxW ) и поделился ей в списке рассылки python-tulip. Соко- ловский любезно разрешил мне скопировать этот PDF-файл на сайт книги, где он обрел относительно постоянный URL ( http://flupy.org/resources/yield-from.pdf ). На момент написания этой книги подавляющее большинство примеров приме- нения yield from встречаются в самом пакете asyncio и в программах, которые им пользуются. Я потратил много времени, чтобы найти другие примеры yield from . Грэг Ивинг – тот самый, который написал документ PEP 380 и реализовал yield from в CPython, – опубликовал несколько таких примеров ( http://bit.ly/1JIqJtu ): класс BinaryTree , простой анализатор XML и планировщик задач.\n--- Страница 532 ---\n532 Глава 16. Сопрограммы В книге Brett Slatkin «Effective Python» ( http://www.effectivepython.com ) (Addison-W esley) есть прекрасная короткая глава «Consider Coroutines to Run Many Functions Concurrently» (Об использовании сопрограмм для параллельно-го выполнения нескольких функций) (опубликована в качестве демонстрацион-ной главы по адресу http://bit.ly/1JIqNcZ ). Там имеется лучший из встречавшихся мне примеров управления генераторами с помощью yield from : реализация игры «Жизнь» Джона Конвея ( http://bit.ly/1HGsKDw ), в которой сопрограммы ис- пользуются для управления состоянием каждой клетки. Пример кода из книги «Effective Python» имеется в репозитории на GitHub ( https://github.com/bslatkin/ effectivepython ). Я переработал код примера игры «Жизнь» – отделил функции и классы, реализующие игру, от тестового кода из книги Слаткина (оригинальный код см. по адресу http://bit.ly/1JIqO0l ). Я также переписал тесты в виде doctest- скриптов, чтобы можно было видеть результаты различных сопрограмм и классов, не прогоняя скрипт. Переработанный код ( http://bit.ly/1HGsO6j ) опубликован в виде gist-пакета на GitHub ( http://bit.ly/coro_life ). Другие интересные примеры yield from , не связанные с asyncio , приведе- ны в сообщении Петера Оттена (Peter Otten) в списке рассылки Python T utor «Comparing two CSV files using Python» ( http://bit.ly/1JIqSxf ) и в реализации игры «камень, ножницы, бумага» в пособии Яна У орда (Ian Ward) «Iterables, Iterators, and Generators» ( http://bit.ly/1JIqQ8x ), опубликованном в виде блок- нота iPython. Гвидо ван Россум отправил в группу Google python-tulip длинное сообще- ние под названием «The difference between yield and yield-from » (http://bit. ly/1JIqT44 ), которое стоит прочитать. Ник Кофлин опубликовал псевдокод yield from , снабдив его подробными комментариями в списке рассылки Python-Dev 21 марта 2009 ( http://bit.ly/1JIqRcv ); в этом сообщении он пишет: Насколько трудным для понимания тот или иной человек нахо- дит код, содержащий yield from , зависит в большей степени от того, насколько хорошо он усвоил общие идеи невытесняющей много-задачности, чем от знания хитроумных трюков, необходимых для реализации вложенных генераторов. В документе «PEP 492 – Coroutines with async and await syntax» ( https://www. python.org/dev/peps/pep-0492/ ) Юрий Селиванов предлагает включить в Python два новых ключевых слова: async и await . Первое предлагается использовать со- вместно с уже имеющимися ключевыми словами для определения новых языко-вых конструкций. Например, async def – для определения сопрограммы и async for – для обхода асинхронных итерируемых объектов с помощью асинхронных итераторов (реализующих специальные методы __aiter__ и __anext__ – версии __iter__ и __next__ для сопрограмм). Чтобы избежать конфликтов с новым клю- чевым словом async , важную функцию asyncio.async() предлагается переиме- новать в asyncio.ensure_future() в Python 3.4.4. Ключевое слово await делает нечто подобное yield from , но допускается только в сопрограммах, определенных с помощью async def – в которых использование yield и yield from предлага-\n--- Страница 533 ---\n533 Поговорим ется запретить. Новый синтаксис устанавливает четкое разделение между унас- ледованными генераторами, эволюционировавшими в объекты, похожие на со-программы, и новым поколением настоящих объектов-сопрограмм с улучшенной языковой поддержкой, которую обеспечивает инфраструктура async -await и не- сколько новых специальных методов. У сопрограмм большое будущее в Python, и язык следует адаптировать для интеграции с ними. Эксперименты с моделированием дискретных событий – отличный способ привыкнуть к использованию невытесняющей многозадачности. Неплохой от-правной точкой может служить статья в википедии «Discrete event simulation» (http://bit.ly/1JIqXB1 ) 17. Краткое пособие по программированию моделей дискретных событий вручную (без специальных библиотек) имеется в статье Ашиша Г упты (Ashish Gupta) «Writing a Discrete Event Simulation: T en Easy Lessons» ( http://bit.ly/1JIqWgz ). Код написан на Java, поэтому основан на клас- сах, а не на сопрограммах, но легко переносится на Python. Но даже в отрыве от кода это пособие может служить хорошим введением в терминологию и со-ставные части моделирования дискретных событий. Преобразование примеров Г упты в классы Python, а затем в классы с использованием сопрограмм – по-лезное упражнение. Поговорим В языках программирования ключевые слова устанавливают базо- вые правила управления потоком выполнения и вычисления выраже-ний. Ключевое слово в языке – все равно, что фигура в настольной игре. В языке шахмат ключевыми словами являются 双, 反, 収, 叏, 叐 и 发. А в игре Го – ٴ. У шахматистов есть шесть типов фигур для реализации своих пла- нов, а у игроков в Го – фишки всего одного типа. Однако в семантике Го соседние фишик образуют более крупные фигуры разных форм с изме-няющимися свойствами. Некоторые комбинации фишек Го неразруши-мы. Игра Го богаче шахмат. Количество начальных ходов в Го равно 361, а количество возможных позиций – порядка 1e+170 , тогда как в шахма- тах всего 20 начальных ходов и порядка 1e+50 позиций. Добавление еще одной шахматной фигуры стало бы радикальным изменением. Как и добавление нового ключевого слова в язык програм-мирования. Поэтому проектировщики языков должны относиться к введению новых ключевых слов с осторожностью. 17 В наши дни даже пожизненные профессора согласны, что википедия – достойное место, где можно начать изучение практически любого вопроса информатики. Не для всех дисциплин это верно, но в случае информатики википедия блистает.\n--- Страница 534 ---\n534 Глава 16. Сопрограммы Т аблица 16.1. Количество ключевых слов в языках программирования Ключевых словЯзык Примечание 5 Smalltalk-80 Знаменит минималистским синтаксисом 25 Go Язык, а не игра 32 C Это ANSI C. В C99 ключевых слов 37, а в C11 – 44 33 Python В Python 2.7 31 ключевое слово, а в Python 1.5 их было 28 41 Ruby Ключевые слова можно использовать и в качестве идентификаторов (например, class может быть именем метода) 49 Java Как и в C, имена примитивных типов ( char , float и т . д.) зарезервированы 60 JavaScript Включает все ключевые слова Java 1.0, хотя многие из них не используются ( http://mzl.la/1JIr8fM ) 65 PHP В PHP 5.3 ( http://php.net/manual/en/reserved. keywords.php ) было добавлено семь ключевых слов, в т . ч. goto , trait и yield 85 С++ Согласно сайту cppreference.com ( http:// en.cppreference.com/w/cpp/keyword ), в C++11 до- бавлено 10 ключевых слов вдобавок к уже существо-вавшим 75 555 COBOL Я это не придумал. См. руководство IBM ILE COBOL (http://ibm.co/1JIr7bJ ) /g102 Scheme Кто угодно может определить новое ключевое слово В Python 3 было добавлено ключевое слово nonlocal , слова None , True и False переведены в разряд ключевых, а print и exec перестали быть таковыми. Очень необычно, когда в процессе эволюции языка из него выпадают некоторые ключевые слова. В табл. 16.1 перечислено несколь-ко языков программирования, упорядоченных по количеству ключевых слов. Язык Scheme унаследовал от Lisp макрокоманды, которые позво-ляют создавать специальные формы, добавляя в язык новые управляю-щие конструкции и правила вычисления. Определяемые пользователем идентификаторы таких форм называют «синтаксическими ключевыми словами». В стандарте Scheme R5RS на стр. 45 говорится: «Не суще-ствует зарезервированных идентификаторов» ( http://bit.ly/1JIrB1w )), но в типичной реализации, например MIT/GNU Scheme ( http://bit. ly/1JIrAL1 ), имеется 34 предопределенных синтаксических ключевых\n--- Страница 535 ---\n535 Поговорим слова, в том числе if, lambda и definesyntax – ключевое слово, позволяю- щее составлять новые ключевые слова18. Python можно сравнить с шахматами, а Scheme – с игрой Го.Но вернемся к синтаксису Python. Мне кажется, что Гвидо уж че- ресчур консервативен в своем отношении к ключевым словам. Хорошо, когда их немного, и добавление новых ключевых слов действительно делает неработоспособными существующие программы. Но использо-вание else в циклах – пример повторяющейся вновь и вновь проблемы: наделение новой семантикой существующих ключевых слов, когда луч-ше было бы добавить новое. В контексте for, while и try новое ключевое слово then было бы уместнее парадоксального использования else . Самое неприятное проявление этой проблемы – перегрузка клю- чевого слова def: теперь оно используется для определения функций, генераторов и сопрограмм, хотя эти объекты настолько различны, что объявлять их одним и тем же образом не стоило бы 19. Добавление конструкции yield from особенно раздражает. Повто- рю еще раз – с моей точки зрения, пользователям Python было бы куда полезнее новое ключевое слово. Х уже того, прослеживается новая тен-денция: объединять имеющиеся ключевые слова для создания новых синтаксических конструкций вместо добавления разумных и понятных ключевых слов. Боюсь, в один прекрасный день мы будем ломать себе голову над смыслом словосочетания raise from lambda . Экстренное сообщение Сейчас завершается процесс технического рецензирования этой кни- ги, и, похоже, предложение Юрия Селиванова «PEP 492 – Coroutines with async and await syntax» ( https://www.python.org/dev/peps/pep- 0492/ ) имеет все шансы получить одобрение для реализации уже в версии Python 3.5! Этот PEP получил поддержку Гвидо ван Россума и Виктора Стиннера, т. е. автора и ответственного за сопровождение библиотеки asyncio , которая получит основной выигрыш от нового синтаксиса. Отвечая на сообщение Селиванова ( http://bit.ly/1JIrNgY ) в списке рассылки Python-ideas, Гвидо даже советует отложить выпуск Python 3.5 ( http://bit.ly/1JIrPp9 ), чтобы было время реализовать этот PEP . Разумеется, это сводит на нет большинство моих претензий, изло- женных выше. 18 «The Value Of Syntax?» ( http://lambda-the-ultimate.org/node/4295 ) – интересная дис- куссия по поводу расширяемого синтаксиса и удобства работы с языками программи-рования. Форум Lambda the Ultimate ( http://lambda-theultimate.org/ ) – место сбора фриков, помешанных на языках программирования. 19 Очень интересна статья Боба Нистрома (Bob Nystrom) на эту тему в контексте языков JavaScript, Python и других: «What Color Is Y our Function?».",
      "debug": {
        "start_page": 494,
        "end_page": 535
      }
    },
    {
      "name": "Глава 17. Параллелизм и будущие объекты 536",
      "content": "--- Страница 536 --- (продолжение)\nГЛАВА 17. Параллелизм и будущие объекты Потоки критикуют в основном системные программисты, имея в виду такие ситуации, с которыми типичный прикладной программист ни-когда не сталкивается. […] В 99 % случаев, с которыми имеет дело при-кладной программист, достаточно знать, как запустить группу незави-симых потоков и собрать результаты 1. – Мишель Симионато, вдумчивый пользователь Python Эта глава посвящена библиотеке concurrent.futures , впервые реализованной в версии Python 3.2, но доступной также для Python 2.5 и более поздних версий в виде пакета futures (https://pypi.python.org/pypi/futures/ ) на сайте PyPI. Эта библиотека инкапсулирует паттерн, описанный Мишелем Симионато в абзаце, взятом в качестве эпиграфа, делая его использование почти тривиальным делом. Здесь же я введу понятие «будущего объекта» – объекта, представляющего асинхронное выполнение операции. Эта плодотворная идея лежит в основе не только библиотеки concurrent.futures , но и пакета asyncio , рассматриваемого в главе 18. Начнем с поясняющего примера. Пример: три способа загрузки из веба Эффективное программирование сетевого ввода-вывода невозможно без паралле-лизма из-за наличия высоких сетевых задержек – чем впустую растрачивать про-цессорное время на ожидание, лучше заняться чем-то полезным, пока из сети не пришел ответ. Для иллюстрации этого положения я написал три простых программы загруз- ки изображений флагов 20 стран из веба. Первая программа, flags.py , работает 1 Из статьи Мишеля Симионато «Threads, processes and concurrency in Python: some thoughts» ( http:// bit.ly/1JIrYZQ ), имеющей подзаголовок «Removing the hype around the multicore (non) revolution and some (hopefully) sensible comment about threads and other forms of concurrency» (Развенчание рекламной чепухи по поводу многоядерной (не) революции и некоторые (надеюсь) полезные за-мечания о потоках и других видах параллелизма).\nГЛАВА 17. Параллелизм и будущие объекты Потоки критикуют в основном системные программисты, имея в виду такие ситуации, с которыми типичный прикладной программист ни-когда не сталкивается. […] В 99 % случаев, с которыми имеет дело при-кладной программист, достаточно знать, как запустить группу незави-симых потоков и собрать результаты 1. – Мишель Симионато, вдумчивый пользователь Python Эта глава посвящена библиотеке concurrent.futures , впервые реализованной в версии Python 3.2, но доступной также для Python 2.5 и более поздних версий в виде пакета futures (https://pypi.python.org/pypi/futures/ ) на сайте PyPI. Эта библиотека инкапсулирует паттерн, описанный Мишелем Симионато в абзаце, взятом в качестве эпиграфа, делая его использование почти тривиальным делом. Здесь же я введу понятие «будущего объекта» – объекта, представляющего асинхронное выполнение операции. Эта плодотворная идея лежит в основе не только библиотеки concurrent.futures , но и пакета asyncio , рассматриваемого в главе 18. Начнем с поясняющего примера. Пример: три способа загрузки из веба Эффективное программирование сетевого ввода-вывода невозможно без паралле-лизма из-за наличия высоких сетевых задержек – чем впустую растрачивать про-цессорное время на ожидание, лучше заняться чем-то полезным, пока из сети не пришел ответ. Для иллюстрации этого положения я написал три простых программы загруз- ки изображений флагов 20 стран из веба. Первая программа, flags.py , работает 1 Из статьи Мишеля Симионато «Threads, processes and concurrency in Python: some thoughts» ( http:// bit.ly/1JIrYZQ ), имеющей подзаголовок «Removing the hype around the multicore (non) revolution and some (hopefully) sensible comment about threads and other forms of concurrency» (Развенчание рекламной чепухи по поводу многоядерной (не) революции и некоторые (надеюсь) полезные за-мечания о потоках и других видах параллелизма).\n--- Страница 537 ---\n537 Пример: три способа загрузки из веба последовательно: она запрашивает следующее изображение только после того, как предыдущее загружено и записано на диск. Два других скрипта производят загрузку параллельно: они запрашивают все изображения практически одновре-менно, а сохраняют по мере поступления. Скрипт flags_threadpool.py пользуется пакетом concurrent.futures , а flags_asyncio.py – пакетом asyncio . В примере 17.1 показаны результаты выполнения всех трех скриптов, по три раза каждый. Я также разместил на Y ouT ube видео продолжительностью 73 с (https://www.youtube.com/watch?v=A9e9Cy1UkME ), чтобы было видно, как по мере сохранения флагов в окне OS X Finder становятся видны их изображения. Скрипты загружают изображения с сайта flupy.org , который развернут за систе- мой доставки контента (CDN), так что при первом прогоне они работают несколь-ко медленнее. Показанные ниже результаты получены после прогрева кэша CDN. Пример 17.1. Результаты трех типичных прогонов скриптов flags.py, flags_threadpool.py и flags_asyncio.py $ python3 flags.py BD BR CD CN DE EG ET FR ID IN IR JP MX NG PH PK RU TR US VN /g110 20 flags downloaded in 7.26s /g111 $ python3 flags.pyBD BR CD CN DE EG ET FR ID IN IR JP MX NG PH PK RU TR US VN20 flags downloaded in 7.20s$ python3 flags.pyBD BR CD CN DE EG ET FR ID IN IR JP MX NG PH PK RU TR US VN20 flags downloaded in 7.09s$ python3 flags_threadpool.pyDE BD CN JP ID EG NG BR RU CD IR MX US PH FR PK VN IN ET TR20 flags downloaded in 1.37s /g112 $ python3 flags_threadpool.pyEG BR FR IN BD JP DE RU PK PH CD MX ID US NG TR CN VN ET IR20 flags downloaded in 1.60s$ python3 flags_threadpool.pyBD DE EG CN ID RU IN VN ET MX FR CD NG US JP TR PK BR IR PH20 flags downloaded in 1.22s$ python3 flags_asyncio.py /g113 BD BR IN ID TR DE CN US IR PK PH FR RU NG VN ET MX EG JP CD20 flags downloaded in 1.36s$ python3 flags_asyncio.pyRU CN BR IN FR BD TR EG VN IR PH CD ET ID NG DE JP PK MX US20 flags downloaded in 1.27s$ python3 flags_asyncio.pyRU IN ID DE BR VN PK MX US IR ET EG NG BD FR CN JP PH CD TR /g114 20 flags downloaded in 1.42s /g110 Печать результатов каждого прогона начинается с вывода кодов стран в по- рядке загрузки их флагов и заканчивается сообщением о том, сколько про-шло времени. /g111 Скрипту flags.py требуется в среднем 7,18 с для загрузки 20 изображений. /g112 Скрипту flags_threadpool.py в среднем требуется 1,40 с. /g113 Скрипту flags_asyncio.py в среднем требуется 1,35 с.\n--- Страница 538 ---\n538 Глава 17. Параллелизм и будущие объекты /g114 Обратите внимание на порядок стран: в случае параллельных скриптов за- грузка каждый раз происходит в другом порядке. Между двумя параллельными скриптами разница в производительности несу- щественна, но тот и другой работают в пять раз быстрее последовательного скрип-та – и это на совсем небольшой задаче. Если бы количество загружаемых файлов исчислялось сотнями, то параллельные скрипты показали бы рост производитель-ности в 20 и более раз. При тестировании параллельных HTTP-клиентов в открытом вебе мож- но случайно организовать DoS-атаку или навлечь на себя такие подозре-ния. В случае примера 17.1 ничего страшного не случится, потому что в скрипты зашито ограничение: только 20 запросов. Но для тестирования нетривиальных клиентов следует поднять собственный тестовый сервер. В файле 17-futures/countries/README.rst (http://bit.ly/1JIsg2L ) в репо- зитории кода к книге ( https://github.com/fluentpython/example-code ) на GitHub есть инструкции по настройке локального сервера Nginx. Теперь рассмотрим реализации двух скриптов, протестированных в приме- ре 17.1: flags.py и flags_threadpool.py . Скрипт flags_asyncio.py я отложу до главы 18, но продемонстрировать хотел сразу три, чтобы подчеркнуть важный момент: при любой стратегии распараллеливания – многопоточность или asyncio – произво- дительность приложения, занятого вводом-выводом, оказывается намного выше, чем у последовательного кода. Итак, перейдем к коду. Скрипт последовательной загрузки Пример 17.2 не очень интересен, но большая часть его кода и параметров будет использована для реализации параллельных скриптов, поэтому уделим ему не-много внимания. Для большей ясности в примере 17.2 нет никакой проверки ошибок. Ис- ключениями мы займемся позже, а пока хотим сосредоточиться на струк-туре кода, чтобы было проще сравнить этот скрипт с параллельными. Пример 17.2. flags.py: последовательный скрипт загрузки; некоторые функции будут использованы и в других скриптах import os import timeimport sys import requests /g110 POP20_CC = ('CN IN US ID BR PK NG BD RU JP '\n--- Страница 539 ---\n539 Пример: три способа загрузки из веба 'MX PH VN ET EG DE IR TR CD FR').split() /g111 BASE_URL = 'http://flupy.org/data/flags' /g112 DEST_DIR = 'downloads/' /g113 def save_flag(img, filename): /g114 path = os.path.join(DEST_DIR, filename) with open(path, 'wb') as fp: fp.write(img) def get_flag(cc): /g115 url = '{}/{cc}/{cc}.gif'.format(BASE_URL, cc=cc.lower()) resp = requests.get(url) return resp.content def show(text): /g116 print(text, end=' ') sys.stdout.flush() def download_many(cc_list): /g117 for cc in sorted(cc_list): /g118 image = get_flag(cc) show(cc) save_flag(image, cc.lower() + '.gif') return len(cc_list)def main(download_many): 10 t0 = time.time() count = download_many(POP20_CC) elapsed = time.time() - t0 msg = '\\n{} flags downloaded in {:.2f}s' print(msg.format(count, elapsed)) if __name__ == '__main__': main(download_many) ⤓ /g110 Импортируем библиотеку requests ; она не входит в состав стандартной библиотеки, поэтому, по принятому соглашению, импортируется после стандартных модулей os, time и sys, а предложение импорта отделяется пу- стой строкой. /g111 Список кодов стран (по стандарту ISO 3166) с наибольшим населением, отсортированный в порядке убывания населения. /g112 Сайт, откуда загружаются изображения флагов2. /g113 Локальный каталог, в котором сохраняются изображения. /g114 Просто копируем img (последовательность байтов) в файл с именем file- name в каталоге DEST_DIR . 2 Оригиналы изображений взяты из мировой книги фактов ЦРУ ( http://1.usa.gov/1JIsmHJ ), откры- того сайта правительства США. Я скопировал их на свой сайт во избежание непреднамеренной DoS-атаки на сайт CIA.gov .\n--- Страница 540 ---\n540 Глава 17. Параллелизм и будущие объекты /g115 Зная код страны, строим URL-адрес и загружаем изображение; возвращаем двоичное содержимое ответа. /g116 Отображаем строку и опустошаем буфер sys.stdout , чтобы видеть, как про- двигается работа; это необходимо, потому что Python обычно не сбрасыва-ет буфер stdout до перехода на новую строку. /g117 download_many – основная функция, позволяющая провести сравнение с па- раллельными реализациями. /g118 Обходим список стран в алфавитном порядке, чтобы порядок отображения на выходе был такой же, как на входе; возвращаем количество загруженных изображений. /g119 main запоминает и выводит истекшее время после завершения download_ many . ⤓ При вызове main необходимо указывать функцию, которая производит за- грузку; мы передаем функцию download_many в качестве аргумента, чтобы main можно было использовать как библиотечную функцию, способную работать и с другими реализациями download_many . Библиотека requests , которую написал Кеннет Рейц (Kenneth Reitz) имеется на сайте PyPI ( https://pypi.python.org/pypi/ requests ). Она функционально богаче и проще в использовании, чем модуль urllib.request из стандартной библиотеки Python 3. На самом деле, библиотека requests считается образцом API в духе Python. Она также совместима с версиями, начиная с Python 2.6, тогда как библиотека urllib2 из Python 2 в Python 3 была пе- реименована. Таким образом, использовать requests удобнее, на какую бы версию Python вы ни ориентировались. Ничего особенного нового в скрипте flags.py нет. Он служит просто этало- ном для сравнения с другими скриптами, а использую я его как библиотеку, что- библиотеку, что- у, что- бы не писать лишний код. Теперь рассмотрим другую реализацию – на основе библиотеки concurrent.futures . Загрузка с применением библиотеки concurrent.futures Основой пакета concurrent .futures являются классы ThreadPoolExecutor и ProcessPoolExecutor , которые реализуют интерфейс, позволяющий передавать вызываемые объекты соответственно потокам или процессам. Оба класса управ-ляют внутренним пулом рабочих потоков или процессов и очередью подлежащих выполнению задач. Но поскольку интерфейс высокоуровневый, нам не нужно знать об этих деталях для такого простого дела, как загрузка флагов. В примере 17.3 показан простейший способ параллельной загрузки – методом ThreadPoolExecutor.map .\n--- Страница 541 ---\n541 Пример: три способа загрузки из веба Пример 17.3. flags_threadpool.py: многопоточный скрипт загрузки с применением класса futures.ThreadPoolExecutor from concurrent import futures from flags import save_flag, get_flag, show, main /g110 MAX_WORKERS = 20 /g111 def download_one(cc): /g112 image = get_flag(cc) show(cc) save_flag(image, cc.lower() + '.gif') return cc def download_many(cc_list): workers = min(MAX_WORKERS, len(cc_list)) /g113 with futures.ThreadPoolExecutor(workers) as executor: /g114 res = executor.map(download_one, sorted(cc_list)) /g115 return len(list(res)) /g116 if __name__ == '__main__': main(download_many) /g117 /g110 Используем некоторые функции из модуля flags (пример 17.2). /g111 Максимальное число потоков в объекте ThreadPoolExecutor . /g112 Функция, загружающая одно изображение, ее будет исполнять каждый по- изображение, ее будет исполнять каждый по- е, ее будет исполнять каждый по- ток. /g113 У станавливаем количество рабочих потоков: используем минимум из наи- большего допустимого числа потоков ( MAX_WORKERS ) и фактического числа подлежащих обработке элементов, чтобы не создавать лишних потоков. /g114 Создаем экземпляр ThreadPoolExecutor с таким числом рабочих потоков; метод executor.__exit__ вызовет executor.shutdown(wait=True) , который блокирует выполнение программы до завершения всех потоков. /g115 Метод map похож на встроенную функцию map с тем исключением, что функция download_one параллельно вызывается из нескольких потоков; он возвращает генератор, который можно обойти для получения значений, возвращенных каждой функцией. /g116 Возвращаем количество полученных результатов. Если функция в каком- то потоке возбудила исключение, то оно возникнет в этом месте, когда не-явный вызов next() попытается получить соответствующее значение от итератора. /g117 Вызываем функцию main из модуля flags , передавая ей усовершенствован- ную версию download_many . Отметим, что функция download_one из примера 17.3, по сути дела, является телом цикла for в функции download_many из примера 17.2. Это типичный рефак-\n--- Страница 542 ---\n542 Глава 17. Параллелизм и будущие объекты торинг, встречающийся при написании параллельного кода: преобразовать тело последовательного цикла for в функцию, которая будет вызываться параллельно. Библиотека называется concurrency.futures , но пока мы никаких «futures» не видели. Возникает законный вопрос: где же они? Ответ дан в следующем разделе. Где находятся будущие объекты? Будущие объекты – важнейшие компоненты внутреннего механизма пакетов concurrent.futures и asyncio , но не всегда они видны пользователям этих би- блиотек. В примере 17.3 будущие объекты используются за кулисами, но мой код напрямую к ним не обращается. В этом разделе сообщаются общие сведения о будущих объектах, с примером их практического применения. В стандартной библиотеке для Python 3.4 есть два класса с именем Future : concurrent .futures .Future и asyncio .Future . Они служат одной и той же цели: эк- земпляр класса Future представляет некое отложенное вычисление, завершивше- еся или нет. Это аналог класса Deferred в T wisted, класса Future в T ornado и объ- ектов Promise в различных библиотеках на JavaScript. Будущие объекты инкапсулируют ожидающие операции, так что их можно по- мещать в очереди, опрашивать состояние завершения и получать результаты (или исключения), когда они станут доступны. Важно понимать, что ни вы, ни я не должны создавать будущие объекты: пред- полагается, что их создает исключительно используемая библиотека, будь то concurrent.futures или asyncio . Легко понять, почему это так: объект Future пред- ставляет нечто, что должно случиться когда-то в будущем, а единственный способ гарантировать, что это действительно случится, – запланировать выполнение объ-екта. Поэтому экземпляры класса concurrent.futures.Future создаются только в результате планирования выполнения какой-то операции с помощью одного из подклассов concurrent.futures.Executor . Например, метод Executor.submit() принимает вызываемый объект, планирует его выполнение и возвращает буду- щий объект. Клиентский код не должен изменять состояние будущего объекта: его изменя- ет каркас распараллеливания, когда представляемое этим объектом вычисление завершится, а мы не можем управлять тем, когда это произойдет. Оба класса Future имеют неблокирующий метод .done() , который возвращает булево значение, показывающее завершился вызываемый объект, связанный с эк-земпляром этого класса, или нет. Но вместо того чтобы самому проверять состоя-ние, клиент обычно просит, чтобы его уведомили. Поэтому в обоих классах Future имеется метод .add_done_callback() : если передать ему вызываемый объект, то он будет вызван, когда будущий объект завершится, а в качестве единственного аргу-мента будет передан сам этот будущий объект. Существует также метод .result() , который одинаково работает в обоих клас- сах в ситуации, когда выполнение будущего объекта завершено: либо возвраща-ет результат вызываемого объекта, либо повторно возбуждает исключение, воз-никшее во время выполнения. Но если выполнение будущего объекта еще не\n--- Страница 543 ---\n543 Пример: три способа загрузки из веба завершено, то метод result ведет себя совершенно по-разному. В объекте класса concurrency.futures.Future вызов f.result() блокирует вызывающий поток до тех пор, пока не будет готов результат. Если передан необязательный аргумент timeout и выполнение будущего объекта не завершилось в отведенное время, то возбуждается исключение TimeoutError . В разделе «asyncio.Future: не блокирует умышленно» на стр. 575 мы увидим, что метод asyncio.Future.result не поддержи- вает задание таймаута, а рекомендуемый способ получения результата будущего объекта заключается в использовании yield from – к объектам класса concurrency. futures.Future этот подход неприменим. Будущие объекты возвращаются несколькими функциями из обеих библио- тек; другие пользуются ими внутри себя, невидимо для пользователя. Примером второго рода может служить функция Executor.map , с которой мы встречались в примере 17.3: она возвращает итератор, метод __next__ которого вызывает метод result каждого будущего объекта, так что мы получаем не сами будущие объекты, а результаты их выполнения. Чтобы попрактиковаться в использовании будущих объектов, перепишем при- мер 17.3 с использованием функции concurrent.futures.as_completed (http://bit. ly/1JIsEO W ), которая принимает итерируемый объект, содержащий будущие объ- екты, и возвращает итератор, который отдает будущие объекты по мере их вы-полнения. Чтобы можно было воспользоваться функцией futures.as_completed , необхо- димо внести изменения только в функцию download_many . Вызов высокоуровне- вого метода executor.map заменяется двумя циклами for: один – для создания и планирования будущих объектов, другой – для получения их результатов. И за-одно уж добавим несколько вызовов print для печати каждого будущего объекта до и после завершения. В примере 17.4 показан код новой функции download_many . Количество строк в ней увеличилось с 5 до 17, зато теперь можно присмотреться к таинственным будущим объектам. Все остальные функции такие же, как в при-мере 17.3. Пример 17.4. flags_threadpool_ac.py: замена executor .map на executor .submit и futures .as_completed в функции download_many def download_many(cc_list): cc_list = cc_list[:5] /g110 with futures.ThreadPoolExecutor(max_workers=3) as executor: /g111 to_do = [] for cc in sorted(cc_list): /g112 future = executor.submit(download_one, cc) /g113 to_do.append(future) /g114 msg = 'Scheduled for {}: {}' print(msg.format(cc, future)) /g115 results = [] for future in futures.as_completed(to_do): /g116 res = future.result() /g117 msg = '{} result: {!r}'\n--- Страница 544 ---\n544 Глава 17. Параллелизм и будущие объекты print(msg.format(future, res)) /g118 results.append(res) return len(results) /g110 Для этой демонстрации мы ограничимся только пятью странами с самым большим населением. /g111 У станавливаем значение max_workers равным 3, чтобы можно было следить за ожидающими будущими объектами в распечатке. /g112 Обходим коды стран в алфавитном порядке, чтобы было понятно, что ре- зультаты поступают не по порядку. /g113 Метод executor.submit планирует выполнение вызываемого объекта и воз- выполнение вызываемого объекта и воз- е вызываемого объекта и воз- вращает объект future , представляющий ожидаемую операцию. /g114 Сохраняем каждый будущий объект, чтобы впоследствии его можно было извлечь с помощью функции as_completed . /g115 Выводим сообщение, содержащее код страны и соответствующий ему бу- дущий объект future . /g116 as_completed отдает будущие объекты по мере их завершения. /g117 Получаем результат этого объекта future . /g118 Отображаем объект future и результат его выполнения. Отметим, что вызов future.result() в этом примере никогда не приводит к блокировке, потому что будущий объект получен как результат as_completed . В примере 17.5 показан результат одного прогона программы из примера 17.4. Пример 17.5. Результат работы скрипта flags_threadpool_ac.py $ python3 flags_threadpool_ac.py Scheduled for BR: <Future at 0x100791518 state=running> /g110 Scheduled for CN: <Future at 0x100791710 state=running>Scheduled for ID: <Future at 0x100791a90 state=running>Scheduled for IN: <Future at 0x101807080 state=pending> /g111 Scheduled for US: <Future at 0x101807128 state=pending>CN <Future at 0x100791710 state=finished returned str> result: 'CN' /g112 BR ID <Future at 0x100791518 state=finished returned str> result: 'BR' /g113 <Future at 0x100791a90 state=finished returned str> result: 'ID'IN <Future at 0x101807080 state=finished returned str> result: 'IN'US <Future at 0x101807128 state=finished returned str> result: 'US' 5 flags downloaded in 0.70s /g110 Будущие объекты планируются в алфавитном порядке; метод repr() буду- щего объекта показывает его состояние: первые три объекта выполняются, поскольку есть всего три рабочих потока. /g111 Последние два будущих объекта ожидают освобождения рабочего по- тока. /g112 Первое слово CN напечатано функцией download_one , исполняемой в рабо- чем потоке, остаток строки напечатан функцией download_many .\n--- Страница 545 ---\n545 Блокирующий ввод-вывод и GIL /g113 Здесь два потока выводят коды стран, прежде чем download_many в главном потоке получает возможность вывести результат объекта в первом потоке. Если прогнать flags_threadpool_ac.py несколько раз подряд, то мы увидим, что порядок вывода результатов изменяется. При уве-личении max_workers до 5 изменчивость порядка усиливается, а при уменьшении до 1 код начинает работать последовательно, и и результаты выводятся в том же порядке, в каком коды стран по-давались методом submit . Мы видели два варианта скрипта загрузки с применением библиотеки concurrent .futures : пример 17.3 на основе метода ThreadPoolExecutor .map и при- мер 17.4 на основе futures .as_completed . Если вам не терпится увидеть код скрипта flags_asyncio.py , можете взглянуть на пример 18.5 в главе 18. Строго говоря, ни один из протестированных до сих пор скриптов не выпол- няет загрузку параллельно. Примеры с использованием concurrent .futures огра- ничены глобальной блокировкой интерпретатора GIL, а скрипт flags_asyncio.py вообще однопоточный. Возможно, у вас возникли вопросы о результатах неформального хронометража. • Каким образом flags_threadpool.py оказался в 5 раз быстрее flags.py , если использование потоков в Python ограничено глобальной блокировкой интерпретатора, которая позволяет в каждый момент времени работать только одному потоку? • Как получилось, что скрипт flags_asyncio.py работает в 5 раз быстрее flags. py, если тот и другой однопоточные? На второй вопрос я отвечу в разделе «Объезд блокирующих вызовов» на стр. 582. А о том, почему GIL не приносит почти никакого вреда в программах, ограни- ченных скоростью ввода-вывода, читайте в следующем разделе. Блокирующий ввод-вывод и GIL Сам интерпретатор CPython не является потокобезопасным, поэтому в нем есть глобальная блокировка интерпретатора (Global Interpreter Lock – GIL), которая разрешает в каждый момент времени выполнять байт-код только одному потоку. Именно поэтому один процесс Python обычно не может задействовать несколько процессорных ядер одновременно 3. При написании кода на чистом Python у нас нет контроля над GIL, однако встроенная функция или написанное на C расширение могут освободить GIL при 3 Это ограничение интерпретатора CPython, а не самого языка Python. У Jython и Iron Python тако- го ограничения нет. Однако у Pypy, самого быстрого из имеющихся интерпретаторов Python, GIL тоже имеется.\n--- Страница 546 ---\n546 Глава 17. Параллелизм и будущие объекты выполнении длительных задач. На самом деле, любая библиотека, написанная на C, может управлять GIL, запускать собственные потоки ОС и задействовать все имеющиеся процессорные ядра. Это, правда, заметно усложняет код библиотеки, и большинство авторов так не поступают. Однако все стандартные библиотечные функции, которые выполняют блоки- рующий ввод-вывод, освобождают GIL, когда ждут результата от ОС. Это озна-чает, что Python-программы с большим объемом ввода-вывода, могут получить выгоду от использования нескольких потоков на уровне Python: когда один поток Python ждет ответа из сети, блокированная функция ввода-вывода освобождает GIL, давая возможность работать другому потоку. Потому-то Дэвид Бизли и говорит: «Потоки Python прекрасно умеют ничего не делать» 4. Все блокирующие функции ввода-вывода из стандартной би- блиотеки Python освобождают GIL, уступая процессор другим потокам. Также освобождает GIL функция time.sleep() . Поэтому потоки Python можно без опаски использовать в приложениях с большим объемом ввода-вывода, несмотря на GIL. А теперь посмотрим, как с помощью concurrent.futures можно обойти GIL для счетных задач. Запуск процессов с помощью concurrent.futures Страница документации по пакету concurrent.futures (https://docs.python.org/3/ library/concurrent.futures.html ) имеет подзаголовок «Запуск параллельных задач». Этот пакет действительно поддерживает истинно параллельные вычисления, по-тому что умеет распределять работу между несколькими процессами Python бла-годаря классу ProcessPoolExecutor – и тем самым обходить GIL и задействовать все имеющиеся процессорные ядра для счетных (т. е. в основном занимающих процессор) задач. И ProcessPoolExecutor , и ThreadPoolExecutor реализуют обобщенный интер- фейс Executor , поэтому, работая с concurrent.futures , очень легко переходить от решения на основе потоков к решению на основе процессов и обратно. Использование ProcessPoolExecutor не дает никакого преимущества в примере загрузки флагов или в любой другой программе, ограниченной скоростью ввода-вы-вода. И это легко проверить – просто измените следующие строки в примере 17.3: def download_many(cc_list): workers = min(MAX_WORKERS, len(cc_list)) with futures.ThreadPoolExecutor(workers) as executor: 4 Слайд 106 пособия «Generators: The Final Frontier» ( http://www.dabeaz.com/finalgenerator/ ).\n--- Страница 547 ---\n547 Запуск процессов с помощью concurrent.futures на такие: def download_many(cc_list): with futures.ProcessPoolExecutor() as executor: В простых случаях единственное заметное различие между этими двумя кон- кретными классами исполнителей заключается в том, что методу ThreadPoolEx- ecutor.__init__ необходимо передать аргумент max_workers , определяющий число потоков в пуле. Для ProcessPoolExecutor этот аргумент необязателен и обычно не задается – по умолчанию подразумевается количество процессоров, возвращае-мое функцией os.cpu_count() . И это разумно: для счетных задач не имеет смысла запрашивать больше исполнителей, чем имеется процессоров. С другой стороны, для задач с большим объемом ввода-вывода в ThreadPoolExecutor можно задать пул с 10, 100 или 1000 потоками; оптимальная величина зависит от решаемой за-дачи и от объема доступной памяти, а для ее нахождения необходимо провести тщательное тестирование. На нескольких тестах было показано, что среднее время загрузки 20 флагов при использовании класса ProcessPoolExecutor увеличивается до 1,8 с – по сравнению с 1,4 с в первоначальной версии с классом ThreadPoolExecutor . По-видимому, ос- новная причина заключается в том, что на моей четырехъядерной машине есть ограничение – не более четырех одновременных загрузок, тогда как в версии с пулом потоков рабочих потоков может быть 20. Ценность ProcessPoolExecutor становится очевидной только для счетных за- дач. Я прогнал несколько тестов производительности на двух счетных скриптах: arcfour_futures.py Зашифровать и дешифрировать несколько байтовых массивов размером от 149 КБ до 384 КБ с применением написанной на чистом Python реализации алгоритма RC4 (исходный код см. в приложении А, пример A.7). sha_futures.py Вычислить свертку SHA-256 нескольких байтовых массивов размером 1 МБ с применением стандартного библиотечного пакета hashlib , осно- ванного на библиотеке OpenSSL (исходный код см. в приложении А, при- библиотеке OpenSSL (исходный код см. в приложении А, при- е OpenSSL (исходный код см. в приложении А, при- мер A.9). Единственная операция ввода-вывода, которую выполняют эти скрипты, – вывод конечных результатов на экран. Создание и обработка данных производятся в памяти, поэтому ввод-вывод не отражается на времени работы. В табл. 17.1 показано среднее время после 64 прогонов первого скрипта и 48 прогонов второго. Учитывается и время запуска рабочих процессов. Короче говоря, в случае криптографических алгоритмов можно ожидать уд- воения производительности в результате запуска четырех рабочих процессов на машине с четырьмя процессорными ядрами. Для алгоритма RC4, написанного на чистом Python, можно в 3,8 раза ускорить работу, если при тех же четырех рабочих процессах воспользоваться интерпрета-\n--- Страница 548 ---\n548 Глава 17. Параллелизм и будущие объекты тором PyPy. По сравнению с эталоном – один рабочий процесс и интерпретатор CPython – получается ускорение в 7,8 раз. Т аблица 17.1. Время и коэффициент ускорения для примеров вычисления RC4 и SHA при количестве рабочих процессов от 1 до 4 на четырехъядерной машине с процессором Intel Core i7 2.7 ГГц. Использовалась версия Python 3.4 Рабочих процессовВремя работы RC4Коэффициент для RC4Время работы SHAКоэффициент для SHA 1 11.48 с 1.00 22.66 c 1.00 2 8.65 c 1.33 14.90 c 1.52 3 6.04 c 1.90 11.91 c 1.904 5.58 c 2.06 10.89 с 2.08 Если вы решаете счетные задачи на Python, то обязательно по- пробуйте интерпретатор PyPy ( http://pypy.org/ ). При использова- нии PyPy скрипт arcfour_futures.py работал от 3,8 до 5,1 раз бы- стрее, в зависимости от числа рабочих процессов. Я проводил тестирование на версии PyPy 2.4.0, совместимой с Python 3.2.5, так что в ее стандартной библиотеке пакет concurrent.futures имеется. Теперь давайте исследуем поведение пула потоков на демонстрационной про- грамме, которая создает пул с тремя потоками, выполняющими пять вызываемых объектов, которые выводят сообщения с временными метками. Эксперименты с Executor.map Запустить несколько вызываемых объектов параллельно проще всего с помощью функции Executor.map , которую мы уже видели в примере 17.3. Скрипт в приме- ре 17.6 демонстрирует детали работы Executor.map . Его результаты показаны в примере 17.7. Пример 17.6. demo_executor_map.py: простая демонстрация метода map объекта ThreadPoolExecutor from time import sleep, strftime from concurrent import futures def display(*args): /g110 print(strftime('[%H:%M:%S]'), end=' ') print(*args) def loiter(n): /g111\n--- Страница 549 ---\n549 Эксперименты с Executor.map msg = '{}loiter({}): doing nothing for {}s ' display(msg.format('\\t'*n, n, n)) sleep(n) msg = '{}loiter({}): done.' display(msg.format('\\t'*n, n)) return n * 10 /g112 def main(): display('Script starting.') executor = futures.ThreadPoolExecutor(max_workers=3) /g113 results = executor.map(loiter, range(5)) /g114 display('results:', results) # /g115 display('Waiting for individual results:') for i, result in enumerate(results): /g116 display('result {}: {}'.format(i, result)) main() /g110 Эта функция печатает переданные ей аргументы, добавляя временную мет- ку в формате [HH:MM:SS] . /g111 Функция loiter печатает время начала работы, затем спит n секунд и пе- чатает время окончания; знаки табуляции формируют отступ сообщения в соответствии с величиной n. /g112 loiter возвращает n * 10 , чтобы нагляднее представить результаты. /g113 Создаем объект ThreadPoolExecutor с тремя потоками. /g114 Передаем исполнителю executor пять задач (поскольку есть только три по- тока, сразу начнут выполнение лишь три из них: вызывающие loiter(0) , loiter(1) и loiter(2) ); это неблокирующий вызов. /g115 Немедленно распечатываем объект results , полученный от executor.map : это генератор, как видно из результатов, показанных в примере 17.7. /g116 Обращение к enumerate в цикле for неявно вызывает функцию next(results) , которая, в свою очередь вызывает метод _f.result() (вну- треннего) будущего объекта _f, представляющего первый вызов, loiter(0) . Метод result блокирует программу до завершения будущего объекта, по- этому каждая итерация этого цикла будет ждать готовности следующего результата. Призываю вас прогнать пример 17.6 и полюбоваться на то, как постепенно пе- чатаются сообщения. А заодно уж поэкспериментируйте с аргументом max_workers объекта ThreadPoolExecutor и с функцией range , которая порождает аргументы для обращения к executor.map , – или замените ее списками подобранных вручную значений, если хотите задать другие задержки. В примере 17.7 показаны результаты прогона программы из примера 17.6. Пример 17.7. Результаты прогона скрипта demo_executor_map.py из примера 17.6 $ python3 demo_executor_map.py [15:56:50] Script starting. /g110 [15:56:50] loiter(0): doing nothing for 0s /g111\n--- Страница 550 ---\n550 Глава 17. Параллелизм и будущие объекты [15:56:50] loiter(0): done. [15:56:50] loiter(1): doing nothing for 1s /g112 [15:56:50] loiter(2): doing nothing for 2s [15:56:50] results: <generator object result_iterator at 0x106517168> /g113 [15:56:50] loiter(3): doing nothing for 3s /g114 [15:56:50] Waiting for individual results:[15:56:50] result 0: 0 /g115 [15:56:51] loiter(1): done. /g116 [15:56:51] loiter(4): doing nothing for 4s [15:56:51] result 1: 10 /g117 [15:56:52] loiter(2): done. /g118 [15:56:52] result 2: 20[15:56:53] loiter(3): done.[15:56:53] result 3: 30[15:56:55] loiter(4): done. /g119 [15:56:55] result 4: 40 /g110 Прогон начался в 15:56:50. /g111 Первый поток выполняет loiter(0) , поэтому спит 0 с и завершается еще до того, как второй поток запустился, но на вашей машине все может быть по-другому 5. /g112 loiter(1) и loiter(2) запускаются немедленно (поскольку в пуле три рабочих потока, он может одновременно выполнять три функции). /g113 Отсюда видно, что объект results , возвращенный executor.map , – генера- тор; до сих пор никаких блокировок не было вне зависимости от количества задач и значения max_workers . /g114 Поскольку loiter(0) завершилась, первый рабочий поток готов к выпол- нению loiter(3) . /g115 Здесь выполнение может быть заблокировано в зависимости от параметров loiter : метод __next__ генератора results должен дождаться завершения первого будущего объекта. В данном случае блокировки не будет, потому что вызов loiter(0) завершился еще до начала цикла. Отметим, что все действия до этого места произошли в течение одной секунды: 15:56:50. /g116 loiter(1) завершается в следующую секунду – в 15:56:51. Поток освобож- дается и готов к выполнению loiter(4) . /g117 Показан результат loiter(1) : 10. Теперь цикл for блокируется в ожидании результата loiter(2) . /g118 Картина повторяется: loiter(2) завершается и печатается его результат; за- тем то же самое для loiter(3) . /g119 loiter(4) завершается после двухсекундной задержки, поскольку началась в 15:56:51 и ничего не делала 4 с. Функцией Executor .map пользоваться легко, но у нее есть особенность, которая может оказаться полезной или вредной в зависимости от ваших потребностей: она возвращает результаты точно в том порядке, в каком производились вызовы, – 5 С потоками никогда не знаешь точную последовательность событий, которые должны произойти практически одновременно; вполне возможно, что на другой машине loiter(1) начнется рань- ше, чем loiter(0) завершится, особенно если учесть, что sleep всегда освобождает GIL, так что Python может переключиться на другой поток, пусть даже текущий спал 0 с.\n--- Страница 551 ---\n551 Загрузка с индикацией хода выполнения и обработкой ошибок если первой вызванной функции для получения результата понадобилось 10 с, а всем остальным – по 1 с, то программа будет блокирована в течение 10 с, посколь-ку пытается получить первый результат генератора, возвращенного функцией map. После этого все остальные результаты будут получены вообще без блокировки, потому что соответствующие функции уже завершились. Это годится, если для продолжения обработки так или иначе нужны все результаты, но часто предпочти-тельнее получать результаты по мере готовности вне зависимости от того, в каком порядке подавались задачи. Для этого понадобится комбинация метода Executor . submit и функции futures .as_completed , как в примере 17.4. Мы вернемся к этому приему в разделе «Использование futures.as_completed» ниже. Комбинация Executor.submit и futures.as_completed обладает большей гибкостью, чем Executor.map , потому что ей можно по- давать различные вызываемые объекты и аргументы, тогда как executor.map предназначен для выполнения одного и того же вызываемого объекта с разными аргументами. Кроме того, мно-жество будущих объектов, передаваемых futures.as_completed , может поступать от нескольких исполнителей – одни из них могли быть созданы экземпляром ThreadPoolExecutor , другие – экзем- пляром ProcessPoolExecutor . В следующем разделе мы вернемся к программам загрузки флагов, но предъ- явим новые требования, которые заставят нас обходить результаты futures.as_ completed вместо использования executor.map . Загрузка с индикацией хода выполнения и обработкой ошибок Как уже отмечалось, в скриптах из раздела «Пример: три способа загрузки из веба» нет обработки ошибок. Это сделано для того, чтобы их было проще читать и сравнивать три подхода: последовательный, многопоточный и асинхронный. Для тестирования обработки различных ошибок я создал следующие скрипты: flags2_common.py Этот модуль содержит общие функции и параметры, используемые во всех flags2 -скриптах, в том числе функцию main , которая занимается разбором командной строки, хронометражем и выводом результатов. Это чисто вспо-могательный модуль, не имеющий прямого отношения к теме главы, поэто- му его исходный код приведен только в примере A.10 в приложении A. flags2_sequential.py Последовательный HTTP-клиент с корректной обработкой ошибок и ин- дикацией хода выполнения. Функция download_one из этого модуля ис- пользуется также в скрипте flags2_threadpool.py .\n--- Страница 552 ---\n552 Глава 17. Параллелизм и будущие объекты flags2_threadpool.py Параллельный HTTP-клиент, основанный на классе futures.ThreadPoo- lExecutor ; демонстрирует обработку ошибок и интеграцию с индикатором хода выполнения. flags2_asyncio.py Та же функциональность, что в предыдущем примере, но на основе asyncio и aiohttp . Будет рассмотрен в разделе «У лучшение скрипта загрузки на ос- нове asyncio» главы 18. Будьте осторожны при тестировании параллельных клиентов При тестировании параллельных HTTP-клиентов, обращающихся к пу- HTTP-клиентов, обращающихся к пу- -клиентов, обращающихся к пу- бличным HTTP-серверам, количество запросов в секунду может быть довольно велико, а это признак DoS-атаки. Однако мы не хотим никого атаковать, наша цель – научиться писать высокопроизводительные кли-енты. Поэтому искусственно ограничивайте производительность кли-ентов, посылающих запросы публичным серверам. А для проведения экспериментов со скриптами, где уровень параллелизма высок, под-нимайте свой локальный HTTP-сервер. Инструкции о том, как это сде-лать, приведены в файле README.rst ( http://bit.ly/1JIsg2L ), который на- ходится в каталоге 17-futures/countries/ в репозитории кода к этой книге (http://bit.ly/1JItSti ). Самое заметное визуальное отличие flags2 -скриптов состоит в том, что они выводят анимированный текстовый индикатор хода выполнения, реализован- выполнения, реализован- я, реализован- ный с помощью пакета TQDM ( https://github.com/noamraph/tqdm ). Я разме- стил на Y ouT ube ролик продолжительностью 108 с ( https://www.youtube.com/ watch?v=M8Z65tAl5l4 ), в котором показан индикатор и сравнивается скорость ра- боты всех трех скриптов. В этом ролике я сначала запустил последовательный за-грузчик, но через 32 с прервал его, потому что для обращения к 676 URL-адресам и загрузки 194 флагов ему требуется больше 5 минут. Затем я по три раза прогнал многопоточный и асинхронный скрипт, и всякий раз они завершали работу не бо- асинхронный скрипт, и всякий раз они завершали работу не бо- ый скрипт, и всякий раз они завершали работу не бо- лее чем за 6 с (т. е. в 60 с лишним раз быстрее). На рис. 17.1 показаны два снимка экрана: во время и после работы flags2_threadpool.py . Пользоваться пакетом TQDM очень легко, простейший пример приведен в анимированном GIF-файле в файле проекта README.md (https://github. com/noamraph/tqdm/blob/master/README.md ). У становив пакет tqdm и набрав следующий код в оболочке Python, вы увидите анимированный индикатор хода выполнения на месте комментария: >>> import time>>> from tqdm import tqdm >>> for i in tqdm(range(1000)): time .sleep(.01) >>> # -> здесь будет индикатор хода выполнения <-\n--- Страница 553 ---\n553 Загрузка с индикацией хода выполнения и обработкой ошибок Рис. 17.1. Слева вверху : скрипт flags2_threadpool.py с динамическим индикатором хода выполнения, созданным с помощью tqdm. Справа внизу : то же окно терминала после завершения скрипта Помимо зрительно приятного эффекта, функция tqdm интересна и с концеп- туальной точки зрения: она принимает произвольный итерируемый объект и по-рождает итератор, при обходе которого отображается индикатор хода выполнения и оценка времени, оставшегося до завершения всех итераций. Чтобы вычислить эту оценку, tqdm должна получать либо итерируемый объект, имеющий метод len, либо второй аргумент, который содержит ожидаемое количество элементов. Включение TQDM в наши flags2 -примеры дает возможность ближе познако- миться с внутренним устройством параллельных скриптов, поскольку заставляет использовать функции futures.as_completed (http://bit.ly/1JIsEO W ) и asyncio. as_completed (http://bit.ly/1JIufV1 ), чтобы tqdm мог показать индикатор в момент завершения каждого будущего объекта. Еще одна особенность flags2 -примеров – интерфейс командной строки. Все три скрипта принимают одни и те же параметры, а чтобы увидеть их, нужно за-пустить скрипт с флагом -h. Текст справки показан в примере 17.8. Пример 17.8. Справка для скриптов из серии flags2 $ python3 flags2_threadpool.py -h usage: flags2_threadpool.py [-h] [-a] [-e] [-l N] [-m CONCURRENT] [-s LABEL] [-v] [CC [CC ]] Загружает флаги стран с указанными кодами. По умолчанию: 20 стран с наибольшим населением. Позиционные аргументы: CC код страны или первая буква (например, B вместо BA BZ) Необязательные аргументы: -h, --help вывести это сообщение и выйти-a, --all вывести все имеющиеся флаги (от AD до ZW)\n--- Страница 554 ---\n554 Глава 17. Параллелизм и будущие объекты -e, --every вывести флаги для всех возможных кодов (AA ZZ) -l N, --limit N ограничиться первыми N кодами-m CONCURRENT, --max_req CONCURRENT максимальное число параллельных запросов (по умолчанию 30)-s LABEL, --server LABEL тип сервера: DELAY, ERROR, LOCAL, REMOTE (по умолчанию LOCAL)-v, --verbose выводить подробную информацию о ходе выполнения Все аргументы необязательны, наиболее важные обсуждаются ниже.Параметр -s/--server игнорировать не следует: он позволяет задать тип и URL-адрес HTTP-сервера, к которому будет обращаться скрипт. Можно задать одну из четырех строк (регистр не важен): LOCAL Использовать адрес http://localhost:8001/flags ; это значение по умол- чанию. Локальный HTTP-сервер следует настроить так, чтобы он отвечал на запросы к порту 8001. Я использую для тестирования Nginx. В файле README.rst (http://bit.ly/1JIsg2L ), относящемся к этой главе, объясняется, как установить и настроить сервер. REMOTE Использовать http://flupy.org/data/flags ; это принадлежащий мне пу- бличный сайт, размещенный на разделяемом сервере. Не бомбардируйте его слишком большим количеством параллельных запросов. Домен flupy. org связан с бесплатной учетной записью в Cloudflare CDN ( http://www. cloudflare.com/ ), так что первые загрузки могут оказаться довольно медлен- ными, но скорость возрастет по мере прогрева кэша CDN6. DELAY Использовать http://localhost:8002/flags ; прокси-сервер, задержива- ющий HTTP-ответы, должен прослушивать порт 8002. Для введения за-держек я поставил Mozilla Vaurien перед моим локальным Nginx. В вы-шеупомянутом файле README.rst есть также инструкции по работе с прокси-сервером Vaurien. ERROR Использовать http://localhost:8003/flags ; прокси-сервер, отправляющий коды ошибок HTTP и задерживающий ответы, должен прослушивать порт 8003. Для этой цели я использовал Vaurien в другой конфигурации. Режим LOCAL работает , только если локальный HTTP-сервер за- пущен на порту 8001. Для режимов DELAY и ERROR нужны прок- си-серверы, прослушивающие соответственно порт 8002 и 8003. Как настроить нужным образом Nginx и Mozilla Vaurien, описано 6 Поначалу я получал от ошибки HTTP 503 – служба временно недоступна – при тестировании скриптов, отправляющих несколько десятков параллельных запросов моему сайту на недорогом разделяемом сервере. После настройки Cloudflare эти ошибки исчезли.\n--- Страница 555 ---\n555 Загрузка с индикацией хода выполнения и обработкой ошибок в файле 17-futures/countries/README.rst (http://bit.ly/1JIsg2L ) в репозитории кода на GitHub ( https://github.com/fluentpython/ example-code ). По умолчанию каждый flags2 -скрипт загружает флаги 20 стран с самым боль- шим населением с локального сервера ( http://localhost:8001/flags ), открывая определенное количество соединений по умолчанию, для каждого скрипта свое. В примере 17.9 показан результат прогона скрипта flags2_sequential.py , когда все параметры заданы по умолчанию. Пример 17.9. Прогон flags2_sequential.py с параметрами по умолчанию: сервер LOCAL, флаги 20 самых густонаселенных стран, 1 соединение $ python3 flags2_sequential.py LOCAL site: http://localhost:8001/flagsSearching for 20 flags: from BD to VN1 concurrent connection will be used.--------------------20 flags downloaded . Elapsed time: 0.10s Задать набор загружаемых флагов можно несколькими способами. В приме- ре 17.10 показано, как загрузить с сервера DELAY флаги всех стран, коды которых начинаются с букв A, B, C, $ python3 flags2_threadpool.py -s DELAY a b cDELAY site: http://localhost:8002/flagsSearching for 78 flags: from AA to CZ30 concurrent connections will be used.--------------------43 flags downloaded.35 not found.Elapsed time: 1.72s Независимо от способа задания кодов стран количество загружаемых флагов можно ограничить с помощью параметра -l/--limit . В примере 17.11 показано, как выполнить ровно 100 запросов с помощью комбинации параметра -a, запра- шивающего все флаги, и параметра -l 100 . Пример 17.11. Прогон flags2_asyncio.py с загрузкой 100 флагов ( -al 100 ) с сервера ERROR, 100 одновременных соединений ( -m 100 ) $ python3 flags2_asyncio.py -s ERROR -al 100 -m 100 ERROR site: http://localhost:8003/flagsSearching for 100 flags: from AD to LK100 concurrent connections will be used.--------------------73 flags downloaded.27 errors.Elapsed time: 0.64s\n--- Страница 556 ---\n556 Глава 17. Параллелизм и будущие объекты Так выглядит пользовательский интерфейс flags2 -примеров. Теперь познако- мимся с их реализацией. Обработка ошибок во flags2-примерах Общая стратегия обработки ошибок HTTP заключается в том, что ошибки 404 (Не найдено) обрабатываются функцией, отвечающей за загрузку одного файла ( download_one ), а все остальные исключения распространяются наружу и обрабатываются функцией download_many . И на этот раз начнем с рассмотрения последовательного кода, за выполнением которого легко проследить; многие функции из него будут использоваться и в многопоточном скрипте. В примере 17.2 показаны функции, которые собственно и выполняют загрузку в скриптах flags2_sequential.py и flags2_threadpool.py . Пример 17.12. flags2_sequential.py: базовые функции, отвечающие за загрузку, обе используются также в скрипте flags2_threadpool.py def get_flag(base_url, cc): url = '{}/{cc}/{cc}.gif'.format(base_url, cc=cc.lower()) resp = requests.get(url) if resp.status_code != 200: /g110 resp.raise_for_status() return resp.content def download_one(cc, base_url, verbose=False): try: image = get_flag(base_url, cc) except requests.exceptions.HTTPError as exc: /g111 res = exc.response if res.status_code == 404: status = HTTPStatus.not_found /g112 msg = 'not found' else: /g113 raise else: save_flag(image, cc.lower() + '.gif') status = HTTPStatus.ok msg = 'OK' if verbose: /g114 print(cc, msg) return Result(status, cc) /g115 /g110 Функция get_flag не обрабатывает ошибки, она вызывает метод requests. Response.raise_for_status для любого кода HTTP , кроме 200. /g111 Функция download_one перехватывает исключение requests.exceptions. HTTPError , чтобы обработать ошибку с кодом 404 и только ее… /g112 … установив локальное состояние HTTPStatus.not_found ; HTTPStatus – это перечисление Enum , импортированное из модуля flags2_common (пример A.10 в приложении А).\n--- Страница 557 ---\n557 Загрузка с индикацией хода выполнения и обработкой ошибок /g113 Любое другое исключение типа HTTPError возбуждается повторно, прочие исключения просто распространяются в вызывающую программу. /g114 Если задан параметр -v/--verbose , то отображается сообщение, содержащее код страны и состояние; именно так мы видим индикатор хода выполнения в режиме вывода подробной информации. /g115 Именованный кортеж Result , возвращенный функцией download_one , вклю- чает поле status со значением HTTPStatus.not_found или HTTPStatus.ok . В примере 17.13 приведена последовательная версия функции download_many . Ее код прямолинеен, но его стоит изучить хотя бы для сравнения с параллельными версиями. Обратите внимание на индикацию хода выполнения, обработку ошибок и подсчет количества загрузок с разным исходом. Пример 17.13. flags2_sequential.py: последовательная реализация download_many def download_many(cc_list, base_url, verbose, max_req): counter = collections.Counter() /g110 cc_iter = sorted(cc_list) /g111 if not verbose: cc_iter = tqdm.tqdm(cc_iter) /g112 for cc in cc_iter: /g113 try: res = download_one(cc, base_url, verbose) /g114 except requests.exceptions.HTTPError as exc: /g115 error_msg = 'HTTP error {res.status_code} - {res.reason}' error_msg = error_msg.format(res=exc.response) except requests.exceptions.ConnectionError as exc: /g116 error_msg = 'Connection error' else: /g117 error_msg = '' status = res.status if error_msg: status = HTTPStatus.error /g118 counter[status] += 1 /g119 if verbose and error_msg: ⤓ print('*** Error for {}: {}'.format(cc, error_msg)) return counter ⤔ /g110 Этот объект Counter подсчитывает количество загрузок с разными исхода- количество загрузок с разными исхода-количество загрузок с разными исхода- загрузок с разными исхода-загрузок с разными исхода- с разными исхода-с разными исхода- разными исхода-разными исхода- исхода-исхода- ми: HTTPStatus.ok , HTTPStatus.not_found , HTTPStatus.error . /g111 В cc_iter хранится отсортированный по алфавиту список кодов стран, по- лученных в виде аргументов. /g112 Если не задан режим подробной информации, то cc_iter передается функ- ции tqdm , которая возвращает итератор, отдающий элементы из cc_iter и од- новременно отображающий анимированный индикатор хода выполнения. /g113 В этом цикле for мы обходим cc_iter и … /g114 … производим загрузку, последовательно обращаясь к download_one .\n--- Страница 558 ---\n558 Глава 17. Параллелизм и будущие объекты /g115 Относящиеся к HTTP исключения, возбужденные функцией get_flag и не обработанные в download_one , обрабатываются здесь. /g116 Прочие относящиеся к сети исключения обрабатываются здесь. Все остальные исключения аварийно завершают скрипт, потому что в функции flags2_common.main , из которой вызывается download_many , нет блока try/ except . /g117 Если исключение не вышло за пределы download_one , то из именованного кортежа HTTPStatus , возвращенного этой функцией, извлекается значение status . /g118 Если произошла ошибка, устанавливаем соответствующее значение status . /g119 Увеличиваем счетчик, используя значение из перечисления HTTPStatus в качестве ключа. ⤓ При работе в режиме подробной информации отображаем сообщение об ошибке для текущего кода страны, если таковое имеется. ⤔ Возвращаем counter , чтобы функция main могла вывести финальный от- чет. Теперь рассмотрим переработанный пример с пулом потоков, flags2_threadpool. py. Использование futures.as_completed Чтобы включить индикатор хода выполнения и обработку ошибок, мы используем в скрипте flags2_threadpool.py класс futures .ThreadPoolExecutor совместно с уже встречавшейся функцией futures .as_completed . В примере 17.14 приведен полный код flags2_threadpool.py . Заново реализована только функция download_many ; все остальные функции заимствованы из модулей flags2_common и flags2_sequential . Пример 17.14. flags2_threadpool.py: полный исходный код import collections from concurrent import futuresimport requestsimport tqdm 1 from flags2_common import main, HTTPStatus 2 from flags2_sequential import download_one 3 DEFAULT_CONCUR_REQ = 30 /g113 MAX_CONCUR_REQ = 1000 /g114 def download_many(cc_list, base_url, verbose, concur_req): counter = collections.Counter() with futures.ThreadPoolExecutor(max_workers=concur_req) as executor: /g115 to_do_map = {} /g116 for cc in sorted(cc_list): /g117\n--- Страница 559 ---\n559 Загрузка с индикацией хода выполнения и обработкой ошибок future = executor.submit(download_one, cc, base_url, verbose) /g118 to_do_map[future] = cc /g119 done_iter = futures.as_completed(to_do_map) ⤓ if not verbose: done_iter = tqdm.tqdm(done_iter, total=len(cc_list)) ⤔ for future in done_iter: ⤕ try: res = future.result() ⤖ except requests.exceptions.HTTPError as exc: ⤗ error_msg = 'HTTP {res.status_code} - {res.reason}' error_msg = error_msg.format(res=exc.response) except requests.exceptions.ConnectionError as exc: error_msg = 'Connection error' else: error_msg = '' status = res.status if error_msg: status = HTTPStatus.error counter[status] += 1 if verbose and error_msg: cc = to_do_map[future] ⤘ print('*** Error for {}: {}'.format(cc, error_msg)) return counter if __name__ == '__main__': main(download_many, DEFAULT_CONCUR_REQ, MAX_CONCUR_REQ) /g110 Импортируем библиотеку с индикатором хода выполнения. /g111 Импортируем одну функцию и одно перечисление из модуля flags2_common . /g112 Повторно используем функцию donwload_one из модуля flags2_sequential (пример 17.12). /g113 Если в командной строке не задан параметр -m/--max_req , то принимаем такое максимальное число одновременных запросов, оно и станет размером пула потоков. Фактическое число потоков может быть меньше, если загру-жается меньше флагов. /g114 MAX_CONCUR_REQ – максимальное число одновременных запросов независи- мо от числа загружаемых флагов и от значения параметра -m/--max_req ; это мера предосторожности. /g115 Создаем объект executor с параметром max_workers , равным величине concur_req , которую функция main вычисляет как минимум из MAX_CON- CUR_REQ , длины списка cc_list , и значения параметра командной строки -m/--max_req . Это позволяет избежать создания большего числа потоков, чем необходимо. /g116 Этот словарь отображает каждый экземпляр Future – представляющий одну загрузку – на соответствующий код страны для показа в сообщении об ошибке.\n--- Страница 560 ---\n560 Глава 17. Параллелизм и будущие объекты /g117 Обходим список кодов стран в алфавитном порядке. Порядок результатов зависит, прежде всего, от времени получения HTTP-ответа, но если размер пула (определяемый величиной concur_req ) гораздо меньше len(cc_list) , то может оказаться, что результаты возвращаются по алфавиту. /g118 Каждое обращение к executor.submit планирует выполнение одного вызы- выполнение одного вызы- е одного вызы- ваемого объекта и возвращает экземпляр Future . Первый аргумент – сам вызываемый объект, остальные – передаваемые ему аргументы. /g119 Сохраняем future и код страны в словаре. ⤓ Функция futures.as_completed возвращает итератор, который отдает буду- щие объекты по мере их завершения. ⤔ Если не установлен режим подробной информации, то обертываем ре- зультат as_completed функцией tqdm , которая отображает индикатор хода выполнения; поскольку у done_iter нет метода len, то мы должны сооб- щить tqdm ожидаемое количество элементов в виде аргумента total= , чтобы tqdm могла оценить объем оставшейся работы. ⤕ Обходим будущие объекты по мере их завершения. ⤖ Вызов метода result будущего объекта возвращает значение, полученное от вызываемого объекта, или возбуждает исключение, которое было пе-рехвачено во время выполнения объекта. Этот метод может блокировать программу в ожидании разрешения ситуации, но не в данном примере, потому что as_completed возвращает только уже завершенные будущие объекты. ⤗ Обрабатываем потенциальные исключения; оставшаяся часть функции от- личается от кода последовательной версии download_many (пример 17.13) только в месте следующей выноски. ⤘ Чтобы предоставить контекст для сообщения об ошибки, извлекаем код страны из словаря to_do_map , используя в качестве ключа текущий объект future . В последовательной версии это было необязательно, потому что мы обходили список кодов стран, так что текущий cc всегда был под рукой; здесь же мы обходим будущие объекты. В примере 17.14 используется идиома, очень полезная при работе с функцией futures.as_completed : построить словарь, ставящий в соответствие каждому будущему объекту данные, которые можно будет использовать по завершении этого объекта. В данном случае словарь to_do_map сопоставляет с будущим объектом соответствующий ему код страны. Это упрощает последующую обработку будущих объектов, несмотря на то, что завершаться они могут не по порядку. Потоки Python отлично приспособлены к приложениям с большим объемом ввода-вывода, а благодаря пакету concurrent.futures их использование в ряде случаев оказывается тривиальным. На этом мы завершаем введение в пакет concurrent.futures . А далее обсудим альтернативы в ситуации, когда ни один из классов ThreadPoolExecutor и ProcessPoolExecutor не подходит.\n--- Страница 561 ---\n561 Резюме Альтернативы: многопоточная и многопроцессная обработка Потоки поддерживались в Python с самой первой публичной версии 0.9.8 (1993); пакет concurrent .futures – всего лишь самый последний способ их использования. В Python 3 первоначальный модуль thread объявлен нерекомендуемым, пред- почтение отдается модулю threading более высокого уровня ( https://docs.python. org/3/library/threading.html )7. Если класс futures .ThreadPoolExecutor не обладает достаточной гибкостью для некоторой задачи, то можно реализовать собственное решение на основе таких примитивных компонентов из модуля threading , как Thread , Lock , Semaphore и т. д. – быть может, воспользовавшись также потокобезо- пасными очередями из модуля queue (https://docs.python.org/3/library/queue.html ) для передачи данных между потоками. В классе futures .ThreadPoolExecutor все эти детали инкапсулированы. Для счетных задач приходится обходить GIL посредством запуска нескольких процессов. Класс futures.ProcessPoolExecutor – простейший способ это сделать. Но если перед вами стоит особо сложная задача, то можно воспользоваться и бо-лее тонкими инструментами. Пакет multiprocessing (https://docs.python.org/3/ library/multiprocessing.html ) имитирует API модуля threading , но делегирует ра- боту не потокам, а процессам. В простых программах для замены threading на multiprocessing достаточно нескольких изменений. Но multiprocessing предла- гает также средства для решения самой серьезной проблемы, возникающей при организации взаимодействующих процессов: как передавать данные между ними. Резюме В начале этой главы мы сравнили два параллельных HTTP-клиента с последова-тельным и убедились в том, что распараллеливание дает значительный выигрыш в производительности. Изучив первый пример, основанный на пакете concurrent.futures , мы решили поближе познакомиться с будущими объектами – экземплярами класса concur- rent.futures.Future или asyncio.Future – уделив особое внимание общим чертам этих классов (различия между ними будут рассмотрены в главе 18). Мы видели, как создавать будущие объекты методом Executor.submit(…) и как обходить завер- шенные объекты с помощью функции concurrent.futures.as_completed(…) . Далее мы видели, почему потоки Python хорошо подходят для приложений с большим объемом ввода-вывода, несмотря на наличие GIL: все стандартные библиотечные функции ввода-вывода, написанные на C, освобождают GIL, по- C, освобождают GIL, по- этому пока один поток ждет завершения ввода-вывода, планировщик может 7 Модуль threading включен в Python, начиная с версии 1.5.1 (1998), и все же некоторые продол- жают настаивать на использовании старого модуля. В Python 3 он был переименован в _thread , чтобы подчеркнуть, что это всего лишь низкоуровневая деталь реализации, и использовать его в прикладном коде не следует.\n--- Страница 562 ---\n562 Глава 17. Параллелизм и будущие объекты переключиться на другой поток. Затем мы обсудили запуск нескольких процессов с помощью класса concurrent.futures.ProcessPoolExecutor , что позволяет обойти ограничение GIL и задействовать несколько процессорных ядер для выполнения криптографических алгоритмов, достигая тем самым более чем двукратного уско-рения при использовании четырех рабочих процессов. В следующем разделе мы изучили, как работает класс concurrent.futures. ThreadPoolExecutor на учебном примере, где запускались задачи, которые просто спали несколько секунд, ничего не делая, а затем печатали свое состояние и вре-менную метку. Далее мы вернулись к примерам загрузки изображений флагов. Чтобы до- бавить в них индикатор хода выполнения и корректную обработку ошибок, нам пришлось углубиться в детали генераторной функции future .as_completed , и в результате мы открыли для себя общий прием: сохранение будущих объектов в словаре вместе с дополнительной информацией в момент передачи исполнителю и использование этой информации впоследствии – когда итератор as_completed отдает завершенный будущий объект. В заключение нашего обзора методов распараллеливания с помощью несколь- ких потоков и процессов мы напомнили о существовании низкоуровневых, но и более гибких модулей threading и multiprocessing , предоставляющих традицион- ные средства работы с потоками и процессами в Python. Дополнительная литература Автором пакета concurrent .futures является Брайан Куинлан (Brian Quinlan), ко- торый презентовал его в обширном докладе под названием «Будущее уже близко!» (http://bit.ly/1JIuZJy ) на конференции PyCon Australia 2010. Доклад Куинлана не сопровождается слайдами; он демонстрирует возможности библиотеки, вводя код прямо в оболочке Python. В качестве пояснительного примера на презентации был показан короткий ролик, созданный автором веб-комикса и программистом Рэнделлом Манро (Randall Munroe), в котором он непреднамеренно организовал DoS-атаку на сайт Google Maps, чтобы построить цветную карту времени поездок на автомобиле в своем городе. Формальное введение в библиотеку содержится в документе «PEP 3148 – futures – execute computations asynchronously» ( https:// www.python.org/dev/peps/pep-3148/ ). В нем Куинлан пишет, что на библиотеку concurrent .futures «большое влияние оказал пакет java .util .concurrent для Java». В книге Jan Palach «Parallel Programming with Python» (Packt) рассматривает- ся несколько инструментов параллельного программирования, в том числе моду-ли concurrent .futures , threading и multiprocessing . Но он не ограничивается стан- дартной библиотекой, а обсуждает также пакет Celery ( http://bit.ly/1JIv1kA ), где реализована очередь задач для распределения работы между потоками и процес-сами, которые могут выполняться даже на разных машинах. В сообществе Django система Celery, пожалуй, чаще всего применяется для разгрузки веб-сервера за счет передачи вычислительно трудоемких задач, например генерации PDF-файлов, другим процессам.\n--- Страница 563 ---\n563 Дополнительная литература В книге Бизли и Джонса «Python Cookbook», издание 3 (O'Reilly), есть рецепты использования concurrent .futures , и первым из них является рецепт 11.12 «Прин- ципы событийно-управляемого ввода-вывода». В рецепте 12.7 «Создание пула потоков» демонстрируется простой TCP-сервер эхо-контроля, а в рецепте 12.8 «Простой пример параллельного программирования» приводится практически полезный пример: анализ каталога, содержащего сжатые программой gzip файлы журналов Apache, с помощью класса ProcessPoolExecutor . Дополнительные сведе- ния о потоках, рассыпанные по всей главе 12 книги Бизли и Джонса, чрезвычайно интересны, а особо хочется отметить рецепт 12.10 «Определение задачи-актора», в котором иллюстрируется модель акторов: проверенный на практике способ ко-ординации потоков посредством передачи сообщений. В книге Brett Slatkin «Effective Python» ( http://www.effectivepython.com/ ) (Addison-W esley) есть посвященная распараллеливанию глава, где рассматрива-ются сопрограммы, потоки и процессы в пакете concurrent .futures , а также ис- пользование блокировок и очередей для программирования потоков, не прибегая к классу ThreadPoolExecutor . Потоки и процессы рассматриваются также в книгах Micha Gorelick, Ian Ozsvald «High Performance Python» (O'Reilly) и Doug Hellmann «The Python Standard Library by Example» (Addison-W esley). Обзор современного состояния дел в области конкурентности и параллелизма без потоков и обратных вызовов изложен в книге Paul Butcher «Seven Concurrency Models in Seven W eeks» 8. Мне особенно нравится ее подзаголовок «Раскрываем тайны потоков». Потоки и блокировки рассматриваются в первой главе этой кни-ги, а остальные шесть глав посвящены современным альтернативам параллель-ного программирования, поддерживаемым в различных языках. Python, Ruby и JavaScript в их число не входят. Если вас заинтриговали тайны GIL, начните с документа «Python Library and Extension F AQ» (раздел «Нельзя ли избавиться от глобальной блокировки ин-терпретатора?») по адресу http://bit.ly/1HGtb0F . Также стоит прочитать статьи Гвидо ван Россума и Джесси Ноллера (автора пакета multiprocessing ) «It isn't Easy to Remove the GIL» ( http://bit.ly/1HGtcBF ) и «Python Threads and the Global Interpreter Lock» ( http://bit.ly/1JIvgwd ). Наконец, Дэвид Бизли очень детально ис- следует внутренние механизмы работы GIL в докладе «Understanding the Python GIL» ( http://www.dabeaz.com/GIL/ ) 9. На слайде 54 ( http://bit.ly/1HGtCrK ) Бизли приводит кое-какие тревожные результаты и, в частности, данные о 20-кратном увеличении времени работы одного эталонного теста после включения в версию Python 3.2 нового алгоритма GIL. Однако Бизли использовал для моделирования счетной задачи цикл while True: pass , чего на практике не бывает. В реальных приложениях проблема не настолько серьезна, как следует из комментария Анту-ана Петру ( http://bugs.python.org/issue7946#msg223110 ) – автора нового алгорит- ма GIL – к извещению об ошибке, поданному Бизли. 8 П. Батчер «Семь моделей конкуренции и параллелизма за семь недель. Раскрываем тайны пото- ков». ДМК Пресс, 2015 9 Спасибо Лукасу Бруниалти за эту ссылку.\n--- Страница 564 ---\n564 Глава 17. Параллелизм и будущие объекты GIL – вполне реальная проблема, которая в обозримом будущем никуда не денется, поэтому Джесси Ноллер и Ричард Оудкерк (Richard Oudkerk) напи-сали библиотеку, с помощью которой ее проще обойти в счетных задачах: пакет multiprocessing , который имитирует для процессов API библиотеки threading и добавляет вспомогательную инфраструктуру в виде блокировок, очередей, кана-лов, разделяемой памяти и т. д. Этот пакет описан в документе «PEP 371 – Addition of the multiprocessing package to the standard library» ( https://www.python.org/dev/ peps/pep-0371/ ). Официальная документация содержится в rst-файле, насчитыва- ющем 63 страницы, объемом 93 КБ ( http://bit.ly/multi-docs ) – пожалуй, это одна из самых длинных глав в описании стандартной библиотеки Python. Многопроцесс-ное программирование – основа класса concurrent .futures .ProcessPoolExecutor . Для распараллеливания счетных задач и программ, работающих с большими объемами данных, появилась новая технология, собравшая вокруг себя обширное сообщество, – Apache Spark ( https://spark.apache.org ), механизм распределенных вычислений, предлагающий удобный Python API и поддержку работы с объек-тами Python, как с данными. Примеры можно найти на странице https://spark. apache.org/examples.html . Существуют две элегантные и очень простые для использования библиоте- ки распараллеливания задач между процессами: lelo (https://pypi.python.org/ pypi/lelo ) Жоао С. О. Буэно (Joao S. O. Bueno) и python -parallelize (http://bit. ly/1HGtF6Q ) Ната Прайса (Nat Pryce). В пакете lelo определен декоратор @parallel ; если применить его к любой функции, то она, как по волшебству, стано- вится неблокирующей, поскольку выполняется в отдельном процессе. Пакет Ната Прайса python -parallelize предоставляет генератор parallelize , который можно использовать для выполнения цикла for на нескольких процессорах. В основе обоих пакетов лежит модуль multiprocessing . Поговорим Держаться подальше от потоков Параллелизм – один из самых трудных вопросов информатики (лучше держаться от него подальше)10. – Дэвид Бизли, преподаватель Python и безумный ученый Я согласен с, казалось бы, противоречащими друг другу высказыва- ниями Дэвида Бизли (см. выше) и Мишеля Симионато (взято в каче-стве эпиграфа к этой главе). Прослушав в университете курс, в котором словосочетание «параллельное программирование» считалось сино- 10 Slide 9 из пособия «A Curious Course on Coroutines and Concurrency» ( http://www. dabeaz.com/coroutines/ ), представленного на конференции PyCon 2009.\n--- Страница 565 ---\n565 Поговорим нимом управления потоками и блокировками, я пришел к выводу, что управлять потоками и блокировками самостоятельно я хочу ничуть не больше, чем заниматься выделением и освобождением памяти. Такие вещи лучше оставить системным программистам, которые знают, как это делать, любят с этим возиться и располагают временем, чтобы сде-лать все правильно, – по крайней мере, я надеюсь на это. Потому-то я и считаю пакет concurrent.futures выдающимся до- стижением: в нем потоки, процессы и очереди рассматриваются как эле-менты инфраструктуры, а не как объекты, с которыми нужно работать напрямую. Конечно, этот пакет предназначен для сравнительно про-стых задач, которые принято называть «естественно параллельными» (http://bit.ly/1HGtGaR ). Но это довольно большая часть всего множе- ства проблем распараллеливания, с которыми приходится сталкивать-ся при разработке приложений – в противоположность операционным системам или серверам баз данных – о чем и говорит Симионато. Для задач, не являющихся «естественно параллельными», потоки и блокировки – тоже не решение. На уровне ОС потоки никогда не ис-чезнут, но во всех языках программирования, которые мне кажутся ин-тересными, за последние несколько лет появились более удобные вы-сокоуровневые абстракции параллелизма, как показывает книга «Семь моделей конкуренции и параллелизма». К числу таких языков отно-сятся Go, Elixir и Clojure. Erlang – язык, на котором написан Elixir, – блестящий пример языка, в который уже на этапе проектирования был заложен параллелизм. Мне, впрочем, он не нравится из-за уродливого синтаксиса. Это меня Python избаловал. Хосе Валим (Jose Valim), хорошо известный как один из авторов ядра Ruby on Rails, спроектировал язык Elixir, наделив его приятным современным синтаксисом. Подобно Lisp и Clojure, в Elixir реализова-ны синтаксические макросы. Но это палка о двух концах. Синтаксиче-ские макросы позволяют строить мощные предметно-ориентированные языки (DSL), но чрезмерное изобилие подъязыков может привести к несовместимым кодовым базам и фрагментации сообщества. Lisp уто-нул в макросах, каждый поставщик Lisp предлагает свой собственный сокровенный диалект. Результатом стандартизации на основе Common Lisp стал язык, разбухший от функциональных возможностей. Надеюсь, Хосе Валим не даст сообществу Elixir пойти по тому же пути. Как и Elixir, Go – современный язык со свежими идеями. Но в не- которых отношениях он по сравнению с Elixir консервативен. В Go нет макросов, а его синтаксис проще, чем в Python. Go не поддерживает ни наследование, ни перегрузку операторов и предлагает меньше средств для метапрограммирования, чем Python. Эти ограничения рассматрива-ются как достоинства. Они позволяют обеспечить более предсказуемые\n--- Страница 566 ---\n566 Глава 17. Параллелизм и будущие объекты поведение и производительность. И это большой плюс в тех особо от- ветственных задачах с высоким уровнем параллелизма, где Go рассчи-тывает заменить C++, Java и Python. Хотя Elixir и Go – прямые конкуренты на поле параллелизма, их философия рассчитана на разную аудиторию. Скорее всего, обоим язы-кам уготована счастливая судьба. Но история учит, что более консерва-тивные языки программирования привлекают больше последователей. Лично я хотел бы научиться уверенно писать на Go и Elixir. К вопросу о GIL GIL упрощает реализацию интерпретатора CPython и написанных на C расширений, поэтому мы можем сказать ей спасибо за огромное количество расширений, имеющихся для Python, а это, конечно же, одна из основных причин широчайшей популярности Python в наши дни. Много лет мне казалось, что из-за GIL потоки Python полезны разве что в игрушечных приложениях. Так было до тех пор, пока я не открыл для себя, что все блокирующие функции ввода-вывода из стандартной библиотеки освобождают GIL, а, значит, потоки отлично подходят для систем с большим объемом ввода-вывода. А это как раз те приложения, за разработку которых мне платят заказчики. Конкуренция в сфере параллелизма В MRI – эталонной реализации Ruby – также имеется GIL, а, значит, потоки в этом языке подвержены тем же ограничениям, что в Python. А в JavaScript потоки на уровне пользователя не поддерживаются во-все; единственная возможность распараллеливания – асинхронное про-граммирование с обратными вызовами. Я упомянул об этом, потому что Ruby и JavaScript – ближайшие прямые конкуренты Python на поле ди-намических языков программирования общего назначения. Если же говорить о новом поколении языков с развитой поддержкой параллелизма, то Go и Elixir, пожалуй, скорее других способны отобрать у Python его долю. Если толпы людей верят, что Node.js с его ничем не прикрашенными обратными вызовами – жизнеспособная платформа для параллельного программирования, то как же трудно им будет усто-ять перед натиском Python, когда его экосистема на базе пакета asyncio достигнет зрелости? Но это тема для вкладки «Поговорим» в следую-щей главе.",
      "debug": {
        "start_page": 536,
        "end_page": 566
      }
    },
    {
      "name": "Глава 18. Применение пакета asyncio для организации конкурентной работы 567",
      "content": "--- Страница 567 --- (продолжение)\nГЛАВА 18. Применение пакета asyncio для организации конкурентной работы Предмет конкурентности – как управиться со многими вещами одно-временно.Предмет параллелизма – как делать много вещей одновременноНе одно и то же, но близко.Первое касается структуры, второе – выполненияКонкурентность предлагает способ структурировать решение задачи, которая возможно (но необязательно) поддается распараллеливанию 1. – Роб Пайк, соавтор языка Go Профессор Имре Саймон (Imre Simon)2 говаривал, что в науке есть два главных греха: использование разных слов для обозначения одного и того же предмета и использование одного слова для обозначения разных предметов. Потратив немно-го времени на изыскания, вы найдете различные определения «конкурентности» и «параллелизма». Я принимаю неформальные определения Роба Пайка, процити-рованные в эпиграфе к этой главе. Для истинного параллелизма нужно несколько процессорных ядер. Современ- ный ноутбук обычно оснащен четырьмя ядрами, но при повседневной рутинной работе в каждый момент времени выполняет более 100 процессов. Компьютер по-стоянно управляется с сотней и более процессов, гарантируя каждому возмож-ность выполняться, даже если сам процессор не способен делать одновременно более четырех дел. И десять лет назад, когда машины имели всего один процес-сор с одним ядром, они все равно справлялись со 100 процессами, работающими 1 Слайд 5 доклада «Concurrency Is Not Parallelism (It's Better)» ( http://bit.ly/1OwVTUf ). 2 Имре Саймон (1943–2009) был пионером информатики в Бразилии. Он внес значительный вклад в теорию автоматов и стоял у истоков тропической математики. Он также отстаивал принципы бес-платного программного обеспечения и бесплатной культуры вообще. Я имел счастье учиться у него, работать и просто общаться с ним.\nГЛАВА 18. Применение пакета asyncio для организации конкурентной работы Предмет конкурентности – как управиться со многими вещами одно-временно.Предмет параллелизма – как делать много вещей одновременноНе одно и то же, но близко.Первое касается структуры, второе – выполненияКонкурентность предлагает способ структурировать решение задачи, которая возможно (но необязательно) поддается распараллеливанию 1. – Роб Пайк, соавтор языка Go Профессор Имре Саймон (Imre Simon)2 говаривал, что в науке есть два главных греха: использование разных слов для обозначения одного и того же предмета и использование одного слова для обозначения разных предметов. Потратив немно-го времени на изыскания, вы найдете различные определения «конкурентности» и «параллелизма». Я принимаю неформальные определения Роба Пайка, процити-рованные в эпиграфе к этой главе. Для истинного параллелизма нужно несколько процессорных ядер. Современ- ный ноутбук обычно оснащен четырьмя ядрами, но при повседневной рутинной работе в каждый момент времени выполняет более 100 процессов. Компьютер по-стоянно управляется с сотней и более процессов, гарантируя каждому возмож-ность выполняться, даже если сам процессор не способен делать одновременно более четырех дел. И десять лет назад, когда машины имели всего один процес-сор с одним ядром, они все равно справлялись со 100 процессами, работающими 1 Слайд 5 доклада «Concurrency Is Not Parallelism (It's Better)» ( http://bit.ly/1OwVTUf ). 2 Имре Саймон (1943–2009) был пионером информатики в Бразилии. Он внес значительный вклад в теорию автоматов и стоял у истоков тропической математики. Он также отстаивал принципы бес-платного программного обеспечения и бесплатной культуры вообще. Я имел счастье учиться у него, работать и просто общаться с ним.\n--- Страница 568 ---\n568 одновременно. Поэтому-то Роб Пайк и назвал свой доклад «Concurrency Is Not Parallelism (It's Better)» (Конкурентность – это не параллелизм (это лучше)). В этой главе мы познакомимся с пакетом asyncio , в котором конкурентность реализована с помощью сопрограмм, управляемых из цикла обработки событий. Это одна из самых больших и амбициозных библиотек, когда-либо добавленных в арсенал Python. Гвидо ван Россум разрабатывал asyncio вне репозитория Python и дал проекту кодовое название T ulip (тюльпан), так что при поиске сведений об этом проекте в Интернете будут попадаться и сайты о цветке. А основная дис-куссионная группа на эту тему по-прежнему называется python-tulip ( http://bit. ly/1HGtMiO ). Проект T ulip был переименован в asyncio после добавления в стандартную библиотеку версии Python 3.4. Он совместим и с Python 3.3 – на сайте PyPI вы найдете его уже под новым официальным именем ( https://pypi.python.org/pypi/ asyncio ). Поскольку в asyncio повсеместно используются выражения yield from , с более ранними версиями Python он несовместим. Проект Trollius (купальница) ( http://trollius.readthedocs.org ) – в названии которого также фигурирует цветок – представляет собой обратный перенос asyncio на версию Python 2.6 и более ранние с заменой yield from на yield и специальные вызыва- емые объекты с именами From и Return . Выражение yield from … принимает вид yield From( …);, а когда сопрограмме необхо- димо вернуть результат , мы пишем raise Return(result) вместо return result . Во главе проекта Trollius стоит Виктор Стиннер, который является также разработчиком ядра asyncio и любезно согласился отредактировать эту главу перед сдачей в печать. В этой главе будут рассмотрены следующие вопросы. • Сравнение однопоточной программы с эквивалентной, написанной с применением asyncio , с целью продемонстрировать связь между потоками и асинхронными задачами. • Различия между классами asyncio.Future и concurrent.futures.Future . • Асинхронные версии программ загрузки флагов из главы 17.• Как асинхронная программа управляется с высокой конкурентностью в се- тевых приложениях, не прибегая ни к процессам, ни к потокам. • Сопрограммы как важное усовершенствование обратных вызовов в асин- хронном программировании. • Как избежать блокировки цикла событий, поручая блокирующие операции пулу потоков. • Программирование серверов с помощью asyncio и переосмысление струк- туры веб-приложений ради достижения высокой конкурентности.Глава 18. Применение пакета asyncio для организации\n--- Страница 569 ---\n569 Сравнение потока и сопрограммы • Почему пакету asyncio суждено оказать огромное влияние на экосистему Python. Начнем с простого примера, который позволит сравнить библиотеки threading и asyncio . Сравнение потока и сопрограммы В ходе дискуссии о потоках и GIL Мишель Симионато привел простой и забавный пример ( http://bit.ly/1Ox3vW A ) использования модуля multiprocessing для выво- да анимированного индикатора, составленного из ASCII-символов «|/-\\» , кото- рый крутится на консоли во время длительного вычисления. Я модифицировал пример Симионато, сначала воспользовавшись модулем threading , а затем сопрограммой на основе asyncio , так чтобы вы могли сравнить оба варианта и понять, как можно добиться конкурентного поведения без потоков. Поскольку оба примера 18.1 и 18.2 порождают анимированный вывод, увидеть, что происходит, можно, только запустив их. Если вы находитесь в метро (или в другом месте, где нет сети WiFi), взгляните на рис. 18.1 и представьте, что косая черта \\ перед словом «thinking» крутится. Рис. 18.1. Скрипты spinner_thread.py и spinner_asyncio.py порождают похожие результаты: repr -представление объекта spinner и текст Answer: 42 . На снимке экрана скрипт spinner_asyncio.py еще работает , поэтому отображается сообщение \\ thinking! ; когда скрипт завершится, эту строку заменит Answer: 42 Сначала рассмотрим скрипт spinner_thread.py (пример 18.1). Пример 18.1. spinner_thread.py: анимация текстового индикатора с помощью потока import threading import itertoolsimport timeimport sys class Signal: /g110\n--- Страница 570 ---\n570 go = True def spin(msg, signal): /g111 write, flush = sys.stdout.write, sys.stdout.flush for char in itertools.cycle('|/-\\\\'): /g112 status = char + ' ' + msg write(status) flush() write('\\x08' * len(status)) /g113 time.sleep(.1) if not signal.go: /g114 break write(' ' * len(status) + '\\x08' * len(status)) /g115 def slow_function(): /g116 # имитируем ожидание завершения длительной операции ввода-вывода time.sleep(3) /g117 return 42 def supervisor(): /g118 signal = Signal() spinner = threading.Thread(target=spin, args=('thinking!', signal)) print('spinner object:', spinner) /g119 spinner.start() ⤓ result = slow_function() ⤔ signal.go = False ⤕ spinner.join() ⤖ return result def main(): result = supervisor() ⤗ print('Answer:', result) if __name__ == '__main__': main() /g110 Этот класс определяет простой изменяемый объект с атрибутом go, кото- рый понадобится для управления потоком извне. /g111 Эта функция будет выполняться в отдельном потоке. Аргумент signal – экземпляр определенного выше класса Signal . /g112 Это бесконечный цикл, потому что функция itertools.cycle перебирает заданную последовательность по кругу. /g113 Хитрость, позволяющая выполнить анимацию в текстовом режиме: возвращаем курсор назад, печатая символы забоя (\\x08). /g114 Если атрибут go не равен True , выходим из цикла. /g115 Очищаем строку состояния, затирая ее пробелами и возвращая курсор в начало строки. /g116 Допустим, что здесь происходит какое-то долгое вычисление. /g117 Вызов sleep блокирует главный поток, но – и это очень важно – GIL осво-Глава 18. Применение пакета asyncio для организации\n--- Страница 571 ---\n571 Сравнение потока и сопрограммы бождается, так что второй поток может работать дальше. /g118 Эта функция настраивает второй поток, отображает объект потока, выпол- няет долгое вычисление и завершает поток. /g119 Отображаем объект второго потока. Вывод имеет вид <Thread(Thread-1, initial)> . ⤓ Запускаем второй поток. ⤔ Вызываем slow_function ; при этом главный поток блокируется. А тем вре- менем индикатор анимируется вторым потоком. ⤕ Изменяем состояние signal ; тем самым мы завершаем цикл for внутри функции spin . ⤖ Ждем завершения потока spinner . ⤗ Вызываем функцию supervisor . Отметим, что в Python специально отсутствует API для завершения потока. Чтобы остановить поток, ему нужно послать сообщение. В данном случае я ис-пользовал для этой цели атрибут signal.go : если главный поток присвоит ему зна- чение false , то поток spinner это рано или поздно заметит и корректно завершится. Теперь посмотрим, как можно реализовать такое же поведение с помощью де- коратора @asyncio.coroutine вместо создания потока. В разделе «Резюме» главы 16 отмечалось, что в пакете asyncio применяется более строгое определение «сопрограммы». В теле сопрограммы, совместимой с asyncio , необходимо использовать yield from , а не yield . Кроме того, сопрограмма в asyncio долж- на управляться вызывающей стороной, которая активирует ее с помощью yield from или передает одной из функций asyncio , та- ких, как asyncio.async(…) и другие, рассматриваемые ниже. На- конец, к сопрограммам необходимо применять декоратор @asyn- cio.coroutine , как показано в примерах. Пример 18.2. spinner_asyncio.py: анимация текстового индикатора с помощью сопрограммы import asyncio import itertoolsimport sys @asyncio.coroutine /g110 def spin(msg): /g111 write, flush = sys.stdout.write, sys.stdout.flush for char in itertools.cycle('|/-\\\\'): status = char + ' ' + msg write(status) flush() write('\\x08' * len(status)) try: yield from asyncio.sleep(.1) /g112\n--- Страница 572 ---\n572 except asyncio.CancelledError: /g113 break write(' ' * len(status) + '\\x08' * len(status)) @asyncio.coroutine def slow_function(): /g114 # имитируем ожидание завершения длительной операции ввода-вывода yield from asyncio.sleep(3) /g115 return 42 @asyncio.coroutine def supervisor(): /g116 spinner = asyncio.async(spin('thinking!')) /g117 print('spinner object:', spinner) /g118 result = yield from slow_function() /g119 spinner.cancel() ⤓ return result def main(): loop = asyncio.get_event_loop() ⤔ result = loop.run_until_complete(supervisor()) ⤕ loop.close() print('Answer:', result) if __name__ == '__main__': main() /g110 Сопрограммы, работающие с asyncio , должны быть снабжены декоратором @asyncio.coroutine . Это необязательно, но в высшей степени желательно. См. объяснение после листинга. /g111 Здесь нам не нужен аргумент signal , который в функции spin из приме- ра 18.1 служил для завершения потока. /g112 Используем yield from asyncio.sleep(.1) , а не просто time.sleep (.1) , чтобы спать, не блокируя цикл обработки событий. /g113 Если после пробуждения spin возникло исключение asyncio.CancelledEr- ror, значит, была запрошена отмена, поэтому выходим из цикла. /g114 slow_function – теперь сопрограмма, в которой yield from используется, чтобы цикл обработки событий мог продолжать работу, пока сопрограмма спит, имитируя ввод-вывод. /g115 Выражение yield from asyncio.sleep(3) уступает управление главному циклу, который возобновит сопрограмму после указанной в sleep задерж- ки. /g116 supervisor – теперь тоже сопрограмма, поэтому она может управлять функ- цией slow_function с помощью yield from . /g117 asyncio.async( …) планирует выполнение сопрограммы spin , обертывая ее объектом Task , который возвращается немедленно /g118 Распечатываем объект Task . Результат имеет вид <Task pending coro=<spin() running at spinner_asyncio.py:12>>Глава 18. Применение пакета asyncio для организации\n--- Страница 573 ---\n573 Сравнение потока и сопрограммы /g119 Управляем функцией slow_function() . Когда она завершится, мы полу- чим возвращенное значение. А тем временем цикл обработки событий продолжает работать, потому что slow_function() уступила управление главному циклу, выполнив yield from asyncio.sleep(3) . ⤓ Объект Task можно отменить, при этом возбуждается исключение asyncio. CancelledError в том выражении yield , на котором сопрограмма приоста- новилась. Сопрограмма может перехватить это исключение и отложить от-мену или даже вовсе отказаться от нее. ⤔ Получаем ссылку на цикл обработки событий. ⤕ Управляем сопрограммой supervisor , пока она не завершится. Значение, возвращенное сопрограммой, будет получено здесь. Никогда не используйте time.sleep( …) в сопрограммах asyn- cio, если не хотите заблокировать главный поток, а, значит , также цикл обработки событий и, скорее всего, приложение в целом. Если сопрограмма хочет провести некоторое время, бездельни-чая, то должна уступить управление с помощью yield from asyn- cio.sleep(DELAY) . Использовать декоратор @asyncio.coroutine необязательно, но настоятельно рекомендуется: он визуально отличает сопрограммы от обычных функций и по-могает отлаживаться, поскольку печатает предупреждение, если сопрограмма ста-нет жертвой сборщика мусора до возобновления посредством yield from , – это означает, что какая-то операция осталась незавершенной и, вероятнее всего, сви-детельствует об ошибке. Этот декоратор не инициализирующий . Количество строк в скриптах spinner_thread.py и spinner_asyncio.py почти оди- наково. Главным элементом обоих примеров является функция supervisor . Про- ведем их детальное сравнение. В примере 18.3 показана функция supervisor из примера на основе модуля threading . Пример 18.3. spinner_thread.py: функция supervisor с отдельным потоком def supervisor(): signal = Signal() spinner = threading.Thread(target=spin, args=('thinking!', signal)) print('spinner object:', spinner) spinner.start() result = slow_function() signal.go = False spinner.join() return result Для сравнения в примере 18.4 показана сопрограмма supervisor .\n--- Страница 574 ---\n574 Пример 18.4. spinner_asyncio.py: асинхронная сопрограмма supervisor @asyncio.coroutine def supervisor(): spinner = asyncio.async(spin('thinking!')) print('spinner object:', spinner) result = yield from slow_function() spinner .cancel() return result Ниже перечислены основные различия между этими двумя реализациями. • Класс asyncio.Task – грубый эквивалент threading.Thread . Виктор Стин- нер, рецензировавший эту главу, говорит, что « Task подобен зеленому по- току в библиотеках, реализующих невытесняющую многозадачность, на- библиотеках, реализующих невытесняющую многозадачность, на- ах, реализующих невытесняющую многозадачность, на- пример gevent ». • Объект Task управляет сопрограммой, а Thread исполняет вызываемый объект. • Мы не создаем объекты Task самостоятельно, а получаем их, передав сопро- грамму функции asyncio.async( …) или loop.create_task( …). • Для полученного объекта Task уже запланировано выполнение (например, функцией asyncio.async ); экземпляру Thread необходимо явно сказать, что пора начать выполнение, вызвав для этого его метод start . • В потоковой версии supervisor обычная функция slow_function напрямую вызывается из потока. В asyncio supervisor slow_function – сопрограмма, управляемая с помощью yield from . • Не существует функции, которая позволяла бы завершить поток извне, поскольку прерывание потока в произвольной точке могло бы оставить систему в некорректном состоянии. Для задач имеется метод экземпляра Task.cancel() , который возбуждает исключение CancelledError в том месте сопрограммы, где находится выражение yield , вызвавшее ее приостановку. Сопрограмма может перехватить это исключение и решить, что с ним де-лать. • Сопрограмма supervisor должна быть передана в качестве аргумента функ- ции loop.run_until_complete , вызванной из main . Из этого сравнения должно быть ясно, что asyncio координирует параллель- ные задачи иначе, чем более привычный модуль threading . И последнее, что хочется сказать в этой связи: если вам приходилось писать нетривиальные программы с потоками, то вы знаете, как сложно рассуждать о про-грамме, поскольку планировщик может прервать поток в любой момент. Вы долж-ны не забывать ставить блокировки для защиты критических секций программы, чтобы прерывание в середине многошаговой операции не привело к повреждению данных.Глава 18. Применение пакета asyncio для организации\n--- Страница 575 ---\n575 Сравнение потока и сопрограммы Сопрограмма же по умолчанию защищена от прерывания. Мы должны явно уступить управление, чтобы другие части программы могли продолжить рабо-ту. Вместо удержания блокировок для синхронизации нескольких потоков мы имеем сопрограммы, которые «синхронизированы» по определению: в каждый момент времени может работать только одна из них. А когда мы захотим усту-пить управление планировщику, то воспользуемся выражением yield или yield from . Именно поэтому прерывание сопрограммы безопасно: по определению со- программу можно прервать, только когда она приостановлена в точке yield , а, значит, мы можем выполнить необходимую очистку, перехватив исключение CancelledError . Теперь посмотрим, чем класс asyncio.Future отличается от класса concurrent. futures.Future , который мы рассматривали в главе 17. asyncio.Future: не блокирует умышленно Интерфейс классов asyncio .Future и concurrent .futures .Future в основном совпадает, но реализованы они по-разному и не являются взаимозаменяемыми. В документе «PEP-3156 – Asynchronous IO Support Rebooted: the \"asyncio\" Module» (https://www.python.org/dev/peps/pep-3156/ ) по поводу этой печальной ситуации написано следующее: В будущем (игра слов не случайна) мы, возможно, унифицируем классы asyncio.Future и concurrent.futures.Future (например, до- бавив в последний метод __iter__ , который будет работать с yield from ). Как отмечалось в разделе «Где находятся будущие объекты?» главы 17, буду- щие объекты создаются только в результате планирования какого-то действия. В пакете asyncio функция BaseEventLoop.create_task( …) принимает сопрограмму, планирует ее выполнение и возвращает экземпляр asyncio.Task , являющийся так- же экземпляром asyncio.Future , потому что Task – подкласс Future , который пред- назначен для обертывания сопрограммы. Это аналогично созданию экземпляров concurrent.futures.Future посредством вызова Executor.submit( …). Как и concurrent.futures.Future , класс asyncio.Future предоставляет методы .done() , .add_done_callback( …), .results() ,а также ряд других. Первые два метода работают так же, как описано в разделе «Где находятся будущие объекты?» гла-вы 17, но вот метод .result() очень сильно отличается. В классе asyncio.Future метод .result() не принимает аргументов, т. е. задать таймаут невозможно. Кроме того, если в момент вызова .result() выполнение бу- дущего объекта еще не завершилось, то программа не блокируется в ожидании результата, а возбуждается исключение asyncio.InvalidStateError . Однако обычно для получения результата asyncio.Future используется yield from , как мы увидим в примере 18.8. Когда yield from используется с будущим объектом, система автоматически позаботится о том, чтобы дождаться его завершения, не блокируя цикл обработки\n--- Страница 576 ---\n576 событий, – потому что в asyncio выражение yield from уступает управление имен- но циклу обработки событий. Отметим, что использование yield from с будущим объектом можно рассматри- вать как сопрограммный эквивалент функциональности метода add_done_callback : вместо активации обратного вызова по завершении отложенной операции цикл обработки событий устанавливает результат будущего объекта, а выражение yield from отдает возвращенное значение приостановленной сопрограмме, давая ей воз- можность возобновить выполнение. Короче говоря, поскольку класс asyncio.Future спроектирован для работы со- вместно с yield from , следующие методы зачастую оказываются ненужными. • Не нужен метод my_future.add_done_callback( …), потому что те действия, которые должны быть выполнены после завершения будущего объекта, можно просто поместить после yield from my_future в сопрограмме. Это и есть главное достоинство сопрограмм: возможность приостанавливать и возобновлять выполнение функций. • Не нужен метод my_future.result() , потому что значение выражения yield from с будущим объектом есть результат выполнения последнего (т. е. re- sult = yield from my_future ). Разумеется, есть ситуации, когда методы .done() , .add_done_callback( …) и .results() полезны. Но в типичной программе управление будущими объек- тами asyncio осуществляется с помощью yield from , а не путем вызова этих методов. Обсудим теперь, как yield from и asyncio API соединяют вместе будущие объекты, задачи и сопрограммы. Yield from из будущих объектов, задач и сопрограмм В asyncio существует тесная связь между будущими объектами и сопрограм- мами, потому что получить результат объекта asyncio.Future можно, выполнив внутри него yield from . Это означает, что предложение res = yield from foo() работает как в случае, когда foo – сопрограммная функция (т. е. функция, возвра- щающая объект-сопрограмму), так и в случае, когда foo – обычная функция, воз- вращающая экземпляр Future или Task . Это одна из причин, почему сопрограммы и будущие объекты во многих частях asyncio API взаимозаменяемы. Для выполнения сопрограмма должна быть сначала запланирована, а затем она обертывается объектом asyncio.Task . Имея сопрограмму, получить объект Task можно двумя основными способами: asyncio .async(coro_or_future, *, loop=None) Эта функция унифицирует сопрограммы и будущие объекты: первый аргу- мент может быть как тем, так и другим. Если аргумент имеет тип Future или Task , то он возвращается без изменения. Если же это сопрограмма, то async Глава 18. Применение пакета asyncio для организации\n--- Страница 577 ---\n577 Сравнение потока и сопрограммы вызывает для него функцию loop.create_task( …), которая создает объект Task . Можно также передать необязательный именованный аргумент loop= , содержащий ссылку на цикл обработки событий; если он опущен, то async получает объект loop от функции asyncio.get_event_loop() . BaseEventLoop.create_task(coro) Этот метод планирует выполнение сопрограммы и возвращает объект asyn- cio.Task . Если он переопределен в подклассе BaseEventLoop , то возвращен- ный объект может быть экземпляром другого совместимого с Task класса, предоставляемого внешней библиотекой (например, T ornado). Метод BaseEventLoop.create_task( …) имеется только в версиях Python, начиная с 3.4.2. При работе с более ранними версиями Python 3.3 или 3.4 следует использовать asyncio.async( …) или установить более позднюю версию asyncio с сайта PyPI ( https:// pypi.python.org/pypi/asyncio ). Несколько функций из asyncio принимают сопрограмму и обертывают ее объ- ектом asyncio.Task автоматически, вызывая для этой цели asyncio.async . Приме- ром может служить BaseEventLoop.run_until_complete( …). Если вы хотите поэкспериментировать с будущими объектами и сопрограмма- ми в оболочке Python или в небольших тестах, то можете воспользоваться следу-ющим фрагментом 3: >>> import asyncio>>> def run_sync(coro_or_future): loop = asyncio.get_event_loop() return loop.run_until_complete(coro_or_future) >>> a = run_sync(some_coroutine()) Связь между сопрограммами, будущими объектами и задачами документиро- вана в разделе 18.5.3 «Задачи и сопрограммы» ( https://docs.python.org/3/library/ asyncio-task.html ) документации по asyncio . Там, в частности, есть такое замеча- ние: В этой документации некоторые методы описаны как сопрограм- мы, хотя на самом деле являются обычными функциями Python, возвращающими объект Future . Это сделано специально, чтобы со- хранить свободу изменения реализации в будущем. Разобравшись с основами, изучим код асинхронного скрипта загрузки флагов flags_asyncio.py , результаты работы которого были показаны в примере 17.1 наря- ду с результатами последовательного и многопоточного скрипта. 3 Предложен Петром Викториным в сообщении, отправленном в список рассылки Python-ideas 11 сентября 2014 ( http://bit.ly/1JIwJmc ).\n--- Страница 578 ---\n578 Загрузка с применением asyncio и aiohttp В версии Python 3.4 сам модуль asyncio поддерживает только протоколы TCP и UDP . Для HTTP и других протоколов понадобятся сторонние пакеты. Для про-граммирования асинхронных клиентов и серверов HTTP в настоящее время прак- асинхронных клиентов и серверов HTTP в настоящее время прак- ых клиентов и серверов HTTP в настоящее время прак- HTTP в настоящее время прак- в настоящее время прак- тически все пользуются пакетом aiohttp . В примере 18.5 показан полный код скрипта загрузки флагов flags_asyncio.py . Ниже приведено общее описание его работы. 1. Все начинается в функции download_many , где мы загружаем в цикл обработ- ки событий несколько объектов-сопрограмм, полученных от download_one . 2. Цикл обработки событий asyncio активирует все сопрограммы по очереди. 3. Когда клиентская сопрограмма, например get_flag , выполняет yield from , чтобы делегировать работу библиотечной сопрограмме, например aiohttp. request , управление возвращается циклу обработки событий, который мо- жет выполнить любую другую из ранее запланированных сопрограмм. 4. В цикле обработки событий для получения уведомлений о завершении блокирующих операций используется низкоуровневый API, основанный на обратных вызовах. 5. Когда такое случается, главный цикл отправляет результат приостановлен- ной сопрограмме. 6. Затем выполнение сопрограммы продолжается до следующего yield , на- пример yield from resp.read() в get_flag . Цикл обработки событий вновь получает управление. Шаги 4, 5 и 6 повторяются до выхода из цикла обра-ботки событий. Это напоминает пример, который мы рассматривали в разделе «Моделирова- ние работы таксопарка» главы 16, где в главном цикле поочередно запускалось несколько процессов такси. Когда процесс некоторого такси уступал управление, главный цикл планировал следующее событие этого такси (в будущем) и перехо-дил к активации следующего такси в очереди. Моделирование такси гораздо про-ще, его главный цикл легко понять. Но общий поток управления в asyncio такой же: однопоточная программа, в которой главный цикл активирует находящиеся в очереди сопрограммы одну за другой. Каждая сопрограмма выполняет какие-то действия, а затем уступает управление главному циклу, который активирует сле-дующую сопрограмму. Теперь рассмотрим пример 18.5 детально. Пример 18.5. flags_asyncio.py: асинхронный скрипт загрузки с применением asyncio и aiohttp import asyncio import aiohttp /g110Глава 18. Применение пакета asyncio для организации\n--- Страница 579 ---\n579 Загрузка с применением asyncio и aiohttp from flags import BASE_URL, save_flag, show, main /g111 @asyncio.coroutine /g112 def get_flag(cc): url = '{}/{cc}/{cc}.gif'.format(BASE_URL, cc=cc.lower()) resp = yield from aiohttp.request('GET', url) /g113 image = yield from resp.read() /g114 return image @asyncio.coroutine def download_one(cc): /g115 image = yield from get_flag(cc) /g116 show(cc) save_flag(image, cc.lower() + '.gif') return cc def download_many(cc_list): loop = asyncio.get_event_loop() /g117 to_do = [download_one(cc) for cc in sorted(cc_list)] /g118 wait_coro = asyncio.wait(to_do) /g119 res, _ = loop.run_until_complete(wait_coro) ⤓ loop.close() ⤔ return len(res) if __name__ == '__main__': main(download_many) /g110 Модуль aiohttp необходимо устанавливать, он не входит в стандартную библиотеку. /g111 Повторно используем функции из модуля flags (пример 17.2). /g112 Сопрограммы следует снабжать декоратором @asyncio.coroutine . /g113 Блокирующие операции реализованы в виде сопрограмм, а наш код делеги- рует им работу с помощью yield from , поэтому они работают асинхронно. /g114 Чтение содержимого ответов – отдельная асинхронная операция. /g115 download_one должна быть сопрограммой, потому что в ней используется yield from . /g116 Единственное отличие от последовательной реализации download_one – слова yield from в этой строчке; все остальное ничуть не изменилось. /g117 Получаем ссылку на внутреннюю реализацию цикла обработки событий. /g118 Строим список объектов-генераторов, вызывая функцию download_one по одному разу для каждого загружаемого флага. /g119 Несмотря на свое имя, wait – неблокирующая функция. Это сопрограмма, которая завершается, когда завершатся все переданные ей сопрограммы (таково поведение wait по умолчанию, см. объяснение после примера). ⤓ Выполняем цикл обработки событий, пока сопрограмма wait_coro не за- вершится; в этом месте скрипт блокируется на все время работы цикла\n--- Страница 580 ---\n580 обработки событий. Второй элемент, возвращенный функцией run_until_ complete , мы игнорируем. Почему – будет объяснено ниже. ⤔ Заканчиваем цикл обработки событий. Было бы неплохо, если бы объекты цикла обработки событий были контекстными менеджерами, тогда мы могли воспользо- ваться блоком with , гарантирующим закрытие цикла. Однако си- туация осложняется тем фактом, что клиентский код никогда не создает цикл обработки событий напрямую, а получает ссылку на него от функции asyncio.get_event_loop() . Иногда наш код не является «владельцем» цикла обработки событий, поэтому и закрывать его не имеет права. Например, если используется внешний цикл обработки событий ГИП с пакетом типа Quamash (https://pypi.python.org/pypi/Quamash/ ), то за закрытие этого цикла отвечает библиотека Qt, и делается это непосредственно перед завершением приложения. Сопрограмма asyncio.wait( …) принимает итерируемый объект, содержащий будущие объекты или сопрограммы; wait обертывает каждую сопрограмму объ- ектом Task . В итоге все объекты, управляемые wait , так или иначе становятся экземплярами класса Future . Поскольку wait( …) – сопрограммная функция, то она возвращает объект-сопрограмму (генератор), этот объект хранится в пере-менной wait_coro . Для управления сопрограммой мы передаем ее функции loop. run_until_complete( …). Функция loop.run_until_complete принимает будущий объект или сопрограм- му. Получив сопрограмму, она обертывает ее объектом Task – так же, как wait . Сопрограммами, будущими объектами и задачами можно управлять с помощью yield from , именно это и делает функция run_until_complete с объектом wait_coro , полученным от wait . Когда выполнение wait_coro завершится, она вернет 2-кор- теж, в котором первый элемент – это множество завершенных будущих объектов, а второй – множество тех, которые еще не завершились. В примере 18.5 второе множество всегда пусто, потому-то мы и проигнорировали его, присвоив перемен-ной _. Однако wait принимает еще два чисто именованных аргумента, благодаря которым может вернуть управление, даже если некоторые будущие объекты не завершились: timeout и return_when . Подробности см. в документации по asyncio. wait (http://bit.ly/1JIwZS2 ). Отметим, что в примере 18.5 нельзя было повторно использовать функцию get_flag из скрипта flags.py (пример 17.2), потому что она основана на библиоте- ке requests , в которой ввод-вывод блокирующий. Чтобы можно было воспользо- ваться пакетом asyncio , мы должны заменить все функции, обращающиеся к сети, асинхронными версиями, которые активируются с помощью yield from , так чтобы управление возвращалось циклу обработки событий. Использование yield from в get_flag означает, что она должна управляться как сопрограмма.Глава 18. Применение пакета asyncio для организации\n--- Страница 581 ---\n581 Загрузка с применением asyncio и aiohttp По той же причине нельзя было использовать и функцию download_one из скрипта flags_threadpool.py (пример 17.3). Код в примере 18.5 управляет функцией get_flag с помощью yield_from , так что download_one сама является сопрограммой. Для каждого запроса в download_many создается объект-сопрограмма download_one , и все они управляются функцией loop.run_until_complete – после обертывания сопрограммой asyncio.wait . В пакете asyncio немало новых концепций, которые предстоит освоить, но сле- дить за общей логикой примера 18.5 будет проще, если последовать совету самого Гвидо ван Россума: зажмуриться и притвориться, что ключевых слов yield from нет. Поступив так, вы увидите, что читать код так же легко, как последовательный. Например, вообразим, что тело сопрограммы… @asyncio.coroutinedef get_flag(cc): url = '{}/{cc}/{cc}.gif'.format(BASE_URL, cc=cc.lower()) resp = yield from aiohttp.request('GET', url) image = yield from resp.read() return image … работает, как следующая функция, только никогда не блокирует программу: def get_flag(cc): url = '{}/{cc}/{cc}.gif'.format(BASE_URL, cc=cc.lower()) resp = aiohttp.request('GET', url) image = resp .read() return image Конструкция yield from foo позволяет избежать блокирования, потому что текущая сопрограмма (т. е. делегирующий генератор, в котором находится yield from ) приостанавливается, но управление возвращается циклу обработки собы- тий, который может управлять другими сопрограммами. Когда будущий объект или сопрограмма foo завершится, она вернет результат приостановленной сопро- грамме и тем самым возобновит ее выполнение. В конце раздела «Использование yield from» главы 16 я сформулировал два положения, касающихся любого использования yield from . Повторю их в сжатом виде. • Любая конфигурация сопрограмм, связанных в цепочку выражениями yield from , в конечном итоге должна управляться вызывающей стороной, которой не является сопрограммой, а вызывает next( …) или .send( …) для самого внешнего делегирующего генератора – явно или неявно (т. е. в ци-кле for). • Самый внутренний субгенератор в цепочке должен быть простым генера- тором, в котором используется предложение yield , или итерируемым объ- ектом. При использовании yield from совместно с asyncio API оба положения по- прежнему справедливы, но имеют свою специфику.\n--- Страница 582 ---\n582 • Цепочки написанных нами сопрограмм всегда управляются путем переда- чи самого внешнего делегирующего генератора какой-то функции asyncio API, например loop.run_until_complete( …). • Иначе говоря, при работе с asyncio наш код не управляет сопрограммой, вызывая next( …) или .send( …) – за него это делает цикл обработки событий asyncio . • Цепочки написанных нами сопрограмм всегда заканчиваются делегирова- нием с помощью yield from какой-то сопрограммной функции или сопро- граммному методу asyncio (например, yield from asyncio.sleep( …) в при- мере 18.2) или сопрограммам из библиотек, реализующих протоколы более высокого уровня (например, resp = yield from aiohttp.request('GET', url) в сопрограмме get_flag из примера 18.5). Иначе говоря, самый внутренний субгенератор будет библиотечной функ- цией, которая собственно и выполняет ввод-вывод, а не чем-то написанным нами. Подведем итог: при использовании asyncio наш асинхронный код состоит из сопрограмм, которые являются делегирующими генераторами, управляемыми самим asyncio , и в конечном итоге делегируют работу библиотечным сопрограм- мам из asyncio – возможно, при посредничестве функций из какой-то сторонней библиотеки, например aiohttp . При такой организации создаются конвейеры, в которых цикл обработки событий asyncio управляет – посредством наших со- программ – библиотечными функциями, выполняющими низкоуровневый асин-хронный ввод-вывод. Теперь мы готовы ответить на вопрос, заданный в главе 17: • Как получилось, что скрипт flags_asyncio.py работает в 5 раз быстрее flags. py, если тот и другой однопоточные? Объезд блокирующих вызовов Райан Дал, создатель Node.js, начинает разговор о философии своего проекта сло- вами «Весь наш ввод-вывод никуда не годится»4. Он определяет блокирующую функцию как такую, которая занимается дисковым или сетевым вводом-выводом, и утверждает, что с ними нельзя обращаться так же, как с неблокирующими. Что-бы объяснить, почему, он приводит данные из табл. 18.1. Т аблица 18.1. Характерные для современных компьютеров задержки при чтении данных с различных устройств; в третьей колонке показано пропорционально увеличенное время в масштабе, понятном «медленному» человеку Устройство Т актов ЦП Пропорциональная «человеческая» шкала Кэш L1 3 3 секунды 4 Видео «Введение в Node.js» ( https://www.youtube.com/watch?v=M-sc73Y-zQA ), момент 4:55.Глава 18. Применение пакета asyncio для организации\n--- Страница 583 ---\n583 Объезд блокирующих вызовов Устройство Т актов ЦП Пропорциональная «человеческая» шкала Кэш L2 14 14 секундОЗУ 250 250 секунддиск 41 000 000 1,3 годасеть 240 000 000 7,6 лет Чтобы правильно понять табл. 18.1, имейте в виду, что для современных про- цессоров с гигагерцевой частотой количество тактов измеряется миллиардами в секунду. Допустим, что частота процессора в точности равна миллиарду тактов в секунду. Такой процессор в секунду выполнит 333 333 333 операций чтения из кэша L1 или только 4 (четыре!) операции чтения из сети. В третьей колонке эти числа приведены к более привычной шкале путем умножения на постоянный ко-эффициент. То есть в альтернативной вселенной, где одно чтение из кэша L1 за-нимает 3 секунды, для чтения из сети понадобилось бы 7,6 лет! Есть два способа не дать блокирующим вызовам остановить работу всего при- ложения: • запускать каждую блокирующую операцию в отдельном потоке; • преобразовать каждую блокирующую операцию в неблокирующий асин- хронный вызов. Потоки – вещь хорошая, но накладные расходы на каждый поток ОС (а именно они используются в Python) измеряются мегабайтами, в зависимости от ОС. Мы не можем позволить себе заводить по одному потоку на каждое соединение, если таких соединений тысячи. Обратные вызовы – традиционный способ реализации асинхронности с низким потреблением памяти. Это низкоуровневая концепция, которую можно сравнить со старейшим и самым примитивным механизмом конкурентности: аппаратны-ми прерываниями. Вместо того чтобы терпеливо ждать ответа, мы регистрируем функцию, которая должна быть вызвана, когда произойдет что-то интересное. При таком подходе все вызовы оказываются неблокирующими. Райан Дал рас-хваливает обратные вызовы за их простоту и низкие накладные расходы. Разумеется, чтобы обратные вызовы работали, необходим цикл обработки событий, опирающийся на ту или иную инфраструктуру: прерывания, потоки, опрос, фоновые процессы и т. д. Только так можно гарантировать, что обработка всех параллельных запросов будет происходить и в конечном счете завершится 5. Получив ответ, цикл обработки событий вызывает наш код. Но единственный главный поток, в котором работает и цикл обработки, и код приложения, никогда не блокируется – если, конечно, мы сами не сделаем ошибку . 5 Node.js не поддерживает потоки пользовательского уровня, написанные на JavaScript, но за кули- сами для реализации файлового API на базе обратных вызовов в нем используется пул потоков на основе написанной на C библиотеки. Это связано с тем, что в 2014 году в большинстве ОС не было стабильного и переносимого API для асинхронной работы с файлами.\n--- Страница 584 ---\n584 Использование генераторов как сопрограмм открывает альтернативный спо- соб асинхронного программирования. С точки зрения цикла обработки событий, активация обратного вызова и вызов метода .send() приостановленной сопро- граммы – практически одно и то же. С каждой приостановленной сопрограммой сопряжены некоторые затраты памяти, но они на несколько порядков меньше, чем для потоков. И при этом удается избежать «ада обратных вызовов» – этот вопрос мы обсудим в разделе «От обратных вызовов к будущим объектам и сопрограм-мам» ниже. Теперь пятикратное превосходство flags_asyncio.py над flags.py в скорости по- лучает объяснение: flags.py тратит миллиарды тактов процессора на ожидание за- вершения каждой загрузки – поочередно. В это время процессор, конечно, работает, только не над вашей программой. С другой стороны, когда функция download_many в скрипте flags_asyncio.py вызывает loop_until_complete , цикл обработки событий управляет каждой сопрограммой download_one до первого выражения yield from , та, в свою очередь, управляет сопрограммой get_flag до первого yield from , где вызывается aiohttp .request( …). Ни один из этих вызовов не является блокирую- щим, поэтому все запросы завершаются за долю секунды. Когда инфраструктура asyncio получает первый ответ, цикл обработки собы- тий отправляет его ожидающей сопрограмме get_flag . Когда get_flag получает ответ, она продолжает выполнение до следующего yield from , где вызывает метод resp.read() и снова уступает управление главному циклу. Все остальные ответы приходят примерно в одно и то же время (поскольку все запросы были отправ-лены почти одновременно). Когда сопрограмма get_flag возвращает управление, соответствующий ей делегирующий генератор download_flag возобновляет работу и сохраняет файл с изображением флага. Для достижения максимальной производительности операция save_flag тоже должна быть асинхронной, но в настоящее время asyncio не предоставляет асинхронного API для работы с фай- ловой системой – в отличие от Node. Если это станет причиной «затыка» в приложении, можете воспользоваться функцией loop . run_in_executor (http://bit.ly/1HGtQzc ) для выполнения save_flag в пуле потоков. Как это сделать, показано в примере 18.9. Поскольку асинхронные операции чередуются, общее время параллельной за- асинхронные операции чередуются, общее время параллельной за- ые операции чередуются, общее время параллельной за- грузки многих изображений, оказывается намного меньше, чем в последователь-ном скрипте. На получение результатов 600 HTTP-запросов с помощью asyncio у меня ушло в 70 с лишним раз меньше времени по сравнению с последовательной загрузкой. Теперь вернемся к примеру HTTP-клиента и посмотрим, как показать аними- рованный индикатор хода выполнения и корректно обработать ошибки.Глава 18. Применение пакета asyncio для организации\n--- Страница 585 ---\n585 Улучшение скрипта загрузки на основе asyncio Улучшение скрипта загрузки на основе asyncio В разделе «Загрузка с индикацией хода выполнения и обработкой ошибок» гла- вы 17 упоминалось, что у всех скриптов из серии flags2 одинаковый интерфейс командной строки. Это относится и к скрипту flags2_asyncio.py из этого раздела. Так, в примере 18.6 показано, как получить 100 флагов ( -al 100 ) от сервера ERROR , отправив 100 одновременных запросов ( -m 100 ). Пример 18.6. Запуск скрипта flags2_asyncio.py $ python3 flags2_asyncio.py -s ERROR -al 100 -m 100 ERROR site: http://localhost:8003/flagsSearching for 100 flags: from AD to LK100 concurrent connections will be used.--------------------73 flags downloaded.27 errors.Elapsed time: 0.64s Ведите себя ответственно при тестировании параллельных клиентов Хотя общее время загрузки для многопоточных и асинхронных HTTP-клиентов одинаково, asyncio способен посылать запросы быстрее, поэтому сервер с большей вероятностью заподозрит DoS-атаку. Если вы хотите тестировать параллельные клиентов на полной скорости, то поднимите локальный HTTP-сервер. Соответствующие инструкции есть в файле README.rst ( http://bit. ly/1JIsg2L ) в каталоге 17-futures/countries/ (http://bit.ly/1f6ChKk ) репозитория кода к этой книге ( http://bit.ly/1JItSti ). Познакомимся с реализацией flags2_asyncio.py . Использование asyncio.as_completed В примере 18.5 я передавал функции asyncio.wait список сопрограмм, кото- рые – под управлением метода loop.run_until.complete – должны возвращать результаты загрузки, но только когда завершатся все. Однако чтобы обновить ин-дикатор хода выполнения, нам нужно получать результаты по мере готовности. К счастью, в пакете asyncio есть эквивалент генераторной функции as_completed , которой мы пользовались в скрипте на основе пула потоков (пример 17.14). Для кодирования flags2 -примера на основе asyncio нам придется переписать несколько функций, которые в версии на базе concurrent.future можно было ис- пользовать повторно. Дело в том, что в программе на основе asyncio имеется всего\n--- Страница 586 ---\n586 один главный поток, и мы не можем допустить в нем блокирующих вызовов, так как в этом же потоке работает цикл обработки событий. Поэтому я был вынуж-ден переписать get_flag , чтобы для всех операций доступа к сети использовалось yield from . Теперь get_flag стала сопрограммой, поэтому download_one должна управлять ей с помощью yield from , а, значит, и download_one становится сопро- граммой. Ранее, в примере 18.5 функцией download_one управляла download_many : обращения к download_one были обернуты вызовом asyncio.wait и передавались методу loop.run_until_complete . Теперь для индикации хода выполнения и об- выполнения и об- я и об- работки ошибок нам необходимо более точное управление, поэтому я перенес большую часть логики download_many в новую сопрограмму downloader_coro , а download_many используется только для подготовки цикла обработки событий и планирования downloader_coro . В примере 18.7 показана первая часть скрипта flags2_asyncio.py , где находятся определения сопрограмм get_flag и download_one , а в примере 18.8 – вторая часть, содержащая функции downloader_coro и download_many . Пример 18.7. flags2_asyncio.py: первая часть скрипта, вторая – в примере 18.8 import asyncio import collections import aiohttp from aiohttp import webimport tqdm from flags2_common import main, HTTPStatus, Result, save_flag# по умолчанию задаем небольшое значение, чтобы избежать ошибок на # удаленном сервере, например 503 - служба временно недоступнаDEFAULT_CONCUR_REQ = 5MAX_CONCUR_REQ = 1000 class FetchError(Exception): /g110 def __init__(self, country_code): self.country_code = country_code @asyncio.coroutine def get_flag(base_url, cc): /g111 url = '{}/{cc}/{cc}.gif'.format(base_url, cc=cc.lower()) resp = yield from aiohttp.request('GET', url) if resp.status == 200: image = yield from resp.read() return image elif resp.status == 404: raise web.HTTPNotFound() else: raise aiohttp.HttpProcessingError( code=resp.status, message=resp.reason, headers=resp.headers) @asyncio.coroutineГлава 18. Применение пакета asyncio для организации\n--- Страница 587 ---\n587 Улучшение скрипта загрузки на основе asyncio def download_one(cc, base_url, semaphore, verbose): /g112 try: with (yield from semaphore): /g113 image = yield from get_flag(base_url, cc) /g114 except web.HTTPNotFound: /g115 status = HTTPStatus.not_found msg = 'not found' except Exception as exc: raise FetchError(cc) from exc /g116 else: save_flag(image, cc.lower() + '.gif') /g117 status = HTTPStatus.ok msg = 'OK' if verbose and msg: print(cc, msg) return Result(status, cc) /g110 Это исключение служит для обертывания исключений сети и протокола HTTPс целью добавления к ним поля country_code , включаемого в сообще- ние об ошибке. /g111 get_flag либо возвращает байты загруженного изображения, либо возбуж- дает исключение web.HTTPNotFound при получении HTTP-ответа с кодом 404, либо возбуждает исключение aiohttp.HttpProcessingError для всех остальных кодов состояния HTTP . /g112 Аргумент semaphore – объект класса asyncio.Semaphore (http://bit. ly/1f6Csp8 ), механизма синхронизации, ограничивающего количество од- новременных запросов. /g113 semaphore используется в качестве контекстного менеджера в выражении yield from , чтобы не блокировать систему в целом: когда счетчик семафо- ра достигает максимально разрешенного значения, блокируется только эта сопрограмма. /g114 При выходе из этого предложения with счетчик семафора уменьшается, что приводит к разблокировке объекта-сопрограммы, стоящего в очереди к тому же семафору. /g115 Если флаг не был найден, просто устанавливаем соответствующее состоя- ние для Result . Любая другая ошибка приводит к исключению FetchError , в котором хранится код страны и исходное исключение, для этого исполь-зуется конструкция raise X from Y , описанная в документе «PEP 3134 – Exception Chaining and Embedded Tracebacks» ( https://www.python.org/dev/ peps/pep-3134/ ). /g116 Эта функция записывает изображение флага на диск. Из примера 18.7 видно, что код функций get_flag и download_one существенно изменился по сравнению с последовательной версией, т. к. теперь они стали сопро-граммами, в которых для асинхронных вызовов используется yield from .\n--- Страница 588 ---\n588 В сетевых клиентах рассматриваемого сейчас типа всегда следует исполь- зовать какой-то механизм дросселирования, чтобы не перегружать сервер чрез-мерно большим количеством одновременных запросов, что могло бы привести к снижению общей производительности системы. В скрипте flags2_threadpool.py (пример 17.14) для дросселирования использовался класс ThreadPoolExecutor , обязательный аргумент которого max_workers устанавливался равным значению concur_req в функции download_many ; таким образом, пул включал не более concur_ req потоков. В скрипте flags2_asyncio.py я использовал объект класса asyncio . Semaphore , созданный функцией downloader_coro (показана ниже, в примере 18.8) и переданный функции download_one в качестве аргумента semaphore .6 В объекте Semaphore хранится счетчик, который уменьшается на единицу при каждом вызове сопрограммного метода .acquire() и увеличивается на едини- цу при вызове сопрограммного метода .release() . Начальное значение счетчи- ка задается в момент создания семафора, как в следующей строке из функции downloader_coro : semaphore = asyncio.Semaphore(concur_req) Вызов .acquire() не приводит к блокировке программы, если счетчик больше нуля, но если он равен нулю, что .acquire() блокирует вызывающую сопрограмму до тех пор, пока какая-то другая сопрограмма не вызовет метод .release() того же объекта Semaphore , увеличив тем самым счетчик. В примере 18.7 я не вызываю ни .acquire() , ни .release() явно, а использую semaphore как контекстный менеджер в следующем фрагменте функции download_one : with (yield from semaphore): image = yield from get_flag(base_url, cc) Этот код гарантирует, что ни в какой момент времени не будет запущено более concur_req экземпляров сопрограммы get_flags . Теперь посмотрим, что еще есть в скрипте из примера 18.8. Отметим, что боль- шая часть функциональности прежней функции download_many теперь перемещена в сопрограмму downloader_coro . Это необходимо, потому что мы должны исполь- зовать yield from для получения результатов будущих объектов, которые отдает asyncio.as_completed , а, стало быть, as_completed должна вызываться из сопро- граммы. Однако я не мог просто преобразовать download_many в сопрограмму, по- тому что должен передавать ее функции main из модуля flags2_common в последней строчке скрипта, а функция main ожидает не сопрограмму, а обычную функцию. Поэтому я написал функцию downloader_coro , которая обертывает as_completed , а на долю download_many остается инициализация цикла обработки событий и пла- нирование downloader_coro – для этого нужно лишь передать ее методу loop.run_ until_complete . 6 Спасибо Г уто Майа, который обратил внимание на отсутствие описания класса Semaphore в чер- новом варианте рукописи.Глава 18. Применение пакета asyncio для организации\n--- Страница 589 ---\n589 Улучшение скрипта загрузки на основе asyncio Пример 18.8. flags2_asyncio.py: продолжение скрипта из примера 18.7 @asyncio.coroutine def downloader_coro(cc_list, base_url, verbose, concur_req): /g110 counter = collections.Counter() semaphore = asyncio.Semaphore(concur_req) /g111 to_do = [download_one(cc, base_url, semaphore, verbose) for cc in sorted(cc_list)] /g112 to_do_iter = asyncio.as_completed(to_do) /g113 if not verbose: to_do_iter = tqdm.tqdm(to_do_iter, total=len(cc_list)) /g114 for future in to_do_iter: /g115 try: res = yield from future /g116 except FetchError as exc: /g117 country_code = exc.country_code /g118 try: error_msg = exc.__cause__.args[0] /g119 except IndexError: error_msg = exc.__cause__.__class__.__name__ ⤓ if verbose and error_msg: msg = '*** Error for {}: {}' print(msg.format(country_code, error_msg)) status = HTTPStatus.error else: status = res.status counter[status] += 1 ⤔ return counter ⤕ def download_many(cc_list, base_url, verbose, concur_req): loop = asyncio.get_event_loop() coro = downloader_coro(cc_list, base_url, verbose, concur_req) counts = loop.run_until_complete(coro) ⤖ loop.close() ⤗ return counts if __name__ == '__main__': main(download_many, DEFAULT_CONCUR_REQ, MAX_CONCUR_REQ) /g110 Сопрограмма получает те же аргументы, что download_many , но вызвать ее из main напрямую нельзя, потому что это сопрограмма, а не обычная функция. /g111 Создаем объект asyncio.Semaphore , который разрешает запускать одновре- менно не более concur_req сопрограмм. /g112 Создаем список объектов-сопрограмм, по одному для каждого вызова со- программы download_one . /g113 Получаем итератор, который будет возвращать будущие объекты по мере их завершения.\n--- Страница 590 ---\n590 /g114 Обертываем итератор функцией tqdm , чтобы можно было отобразить ход выполнения. /g115 Обходим завершенные будущие объекты; этот цикл очень похож на цикл в функции download_many из примера 17.14; отличия связаны по большей ча- сти с обработкой исключений, что обусловлено различиями в библиотеках работы с HTTP ( requests и aiohttp ). /g116 Получить результат asyncio.Future проще всего, воспользовавшись yield from вместо обращения к future.result() . /g117 Любое исключение в download_one обертывается исключением FetchError . /g118 Получаем из объекта FetchError код страны, при скачивании флага кото- рой произошло исключение. /g119 Пытаемся извлечь сообщение об ошибке из объекта исходного исключения (__cause__ ). ⤓ Если в исходном исключении нет сообщения об ошибке, используем в этом качестве имя класса исходного исключения. ⤔ Подсчитываем исходы разных видов. ⤕ Возвращаем счетчик, как в других скриптах. ⤖ download_many просто создает экземпляр сопрограммы и передает его циклу обработки событий с помощью метода run_until_complete . ⤗ Когда все сделано, завершаем цикл обработки событий и возвращаем counts . В примере 18.8 мы не могли воспользоваться отображением будущих объектов на коды стран, как в примере 17.14, потому что будущие объекты, возвращаемые функцией asyncio.as_completed , не обязательно совпадают с будущими объекта- ми, переданными as_completed при вызове. Внутри себя asyncio подменяет одни будущие объекты другими, дающими тот же самый конечный результат7. Раз не получается использовать будущие объекты в качестве ключей для по- иска кода страны в словаре в случае ошибки, то мне пришлось написать собствен-ный класс исключения FetchError (показан в примере 18.7). Объект FetchError обертывает сетевое исключение и хранит ассоциированный с ним код страны, что дает возможность вывести этот код в составе сообщения об ошибке при работе в режиме подробной информации. Если ошибки не было, то код страны становится доступен в виде результата выражения yield from future в начале цикла for. На этом мы завершаем обсуждение примера использования asyncio , функцио- нально эквивалентного рассмотренному ранее скрипту flags2_threadpool.py . Ниже мы улучшим скрипт flags2_asyncio.py , что позволит еще ближе познакомиться с пакетом asyncio . По ходу обсуждения примера 18.7 я отметил, что функция save_flag осущест- вляет запись на диск, и ее следовало бы выполнять асинхронно. В следующем раз-деле, показано, как это сделать. 7 Подробное обсуждение этого вопроса можно найти в начатой мной теме в группе python-tulip, она озаглавлена «Which other futures my come out of asyncio.as_completed?» ( http://bit.ly/1f6CBZx ). Гвидо отвечает на мой вопрос и подробно рассказывает о реализации функции as_completed и о тесной связи между будущими объектами и сопрограммами в asyncio .Глава 18. Применение пакета asyncio для организации\n--- Страница 591 ---\n591 Улучшение скрипта загрузки на основе asyncio Использование исполнителя для предотвращения блокировки цикла обработки событий В сообществе Python как-то не обращают внимания на тот факт, что доступ к локальной файловой системе – блокирующая операция, оправдываясь тем, что за-держки в этом случае несравнимы с возникающими при доступе к сети (которые к тому же опасно непредсказуемы). Напротив, программирующим в среде Node.js постоянно напоминают, что все функции доступа к файловой системе блокирую-щие, – поскольку в их сигнатуре указан обратный вызов. В табл. 18.1 было пока-зано, что блокировка при дисковом вводе-выводе обходится в миллионы впустую растраченных тактов процессора, и это вполне может оказать заметное влияние на производительность приложения. В примере 18.7 блокирующей является функция save_flag . В многопоточной версии скрипта (пример 17.14) save_flag блокирует функцию download_one , но это лишь один из нескольких рабочих потоков. За кулисами блокирующий вы-зов ввода-вывода освобождает GIL, так что другой поток получает возможность поработать. Однако в скрипте flags2_asyncio.py функция save_flag блокирует единственный поток, который наш код разделяет с циклом обработки событий asyncio , т. е. на время сохранения файла все приложение «зависает». Решить проблему позволяет метод run_in_executor объекта, представляющего цикл об- работки событий. В реализации цикла обработки событий asyncio есть исполнитель на основе пула потоков, а метод run_in_executor дает возможность передать ему вызыва- емые объекты, подлежащие выполнению. Чтобы применить эту идею к нашему примеру, достаточно изменить всего несколько строк в сопрограмме download_one . Пример 18.9. flags2_asyncio_executor .py: использование исполнителя по умолчанию на основе пула потоков для выполнения функции save_flag @asyncio.coroutine def download_one(cc, base_url, semaphore, verbose): try: with (yield from semaphore): image = yield from get_flag(base_url, cc) except web.HTTPNotFound: status = HTTPStatus.not_found msg = 'not found' except Exception as exc: raise FetchError(cc) from exc else: loop = asyncio.get_event_loop() /g110 loop.run_in_executor(None, /g111 save_flag, image, cc.lower() + '.gif') /g112 status = HTTPStatus.ok\n--- Страница 592 ---\n592 msg = 'OK' if verbose and msg: print(cc, msg) return Result(status, cc) /g110 Получаем ссылку на объект, представляющий цикл обработки событий. /g111 Первый аргумент run_in_executor – экземпляр исполнителя; если он равен None , то используется исполнитель по умолчанию, основанный на пуле по- токов. /g112 Остальные аргументы – вызываемый объект и его позиционные аргумен- ты. При тестировании примера 18.9 использование run_in_execu- tor не дало значимого прироста производительности, поскольку файлы изображений невелики (в среднем 13 КБ). Однако эффект станет заметен, если изменить функцию save_flag в файле flags2_common.py , так чтобы она сохраняла в 10 раз больше бай- тов, – просто написав fp.write(img*10) вместо fp.write(img) . При среднем размере файла 130 КБ выигрыш от использования run_in_executor становится очевидным. А если вы скачиваете мегапиксельные изображения, то ускорение окажется весьма значительным. Преимущества сопрограмм по сравнению с обратными вызовами становится несомненным, когда мы пытаемся координировать асинхронные запросы, а не просто выполнять независимые запросы. В следующем разделе объясняется, в чем состоит проблема и как ее решить. От обратных вызовов к будущим объектам и сопрограммам Для освоения событийно-ориентированного стиля программирования с сопро- граммами придется приложить усилия, поэтому неплохо с самого начала уяснить, чем он лучше классического подхода на основе обратных вызовов. Это и есть пред-мет настоящего раздела. Всякому имеющему опыт событийно-ориентированного программирования с обратными вызовами знаком термин «ад обратных вызовов»: вложенность об-ратных вызовов в случае, когда следующая операция зависит от результата пре-дыдущей. Если три асинхронных вызова должны происходить в определенной последовательности, то уровень вложенности будет равен трем. В примере 18.10 показан код, написанный на JavaScript.Глава 18. Применение пакета asyncio для организации\n--- Страница 593 ---\n593 От обратных вызовов к будущим объектам и сопрограммам Пример 18.10. Ад обратных вызовов в JavaScript: вложенные анонимные функции, называемые еще «пирамидой судьбы» ( http://survivejs.com/common_problems/pyramid.html ) api_call1(request1, function (response1) { // шаг 1 var request2 = step1(response1); api_call2(request2, function (response2) { // шаг 2 var request3 = step2(response2); api_call3(request3, function (response3) { // шаг 3 step3(response3); }); });}); В примере 18.10 api_call1 , api_call2 и api_call3 – библиотечные функции, ис- пользуемые для асинхронного получения результатов. Например, api_call1 могла бы обращаться к базе данных, а api_call2 получать данные от веб-службы. Все они принимают на входе функцию обратного вызова, которая в JavaScript зача-стую является анонимной (в следующем ниже примере на Python эти функции названы stage1 , stage2 и stage3 ). Что же касается step1 , step2 и step3 , то это обыч- ные функции, с помощью которых приложение обрабатывает ответы, полученные функциями обратного вызова. В примере 18.11 показано, как ад обратных вызовов выглядит в Python. Пример 18.11. Ад обратных вызовов в Python: сцепленные обратные вызовы def stage1(response1): request2 = step1(response1) api_call2(request2, stage2) def stage2(response2): request3 = step2(response2) api_call3(request3, stage3) def stage3(response3): step3(response3) api_call1(request1, stage1) Хотя этот код организован совсем не так, как в примере 18.10, делают они одно и то же, и код на JavaScript можно было бы построить точно так же (однако код на Python невозможно написать в стиле JavaScript из-за ограничений на лямбда-вы-ражения). Код, устроенный так, как в примере 18.10 или 18.11, трудно читать, но еще труднее писать: каждая функция делает свою часть работы, настраивает следую-щий обратный вызов и возвращает управление, чтобы цикл обработки событий мог продолжить работу. В этот момент весь локальный контекст теряется. При выполнении следующего обратного вызова (например, stage2 ) значение request2\n--- Страница 594 ---\n594 уже недоступно. Для его сохранения между разными шагами обработки придется прибегнуть к замыканиям или внешним структурам данных. Сопрограммы могли бы в этой ситуации оказаться очень полезны. Чтобы выполнить три асинхронных действия внутри сопрограммы, нужно три раза написать yield , уступая тем самым процессор циклу обработки событий. Когда ре- зультат будет готов, сопрограмма активируется вызовом .send() . С точки зрения цикла обработки событий, это аналогично активации функции обратного вызова. Но для пользователей асинхронного API на основе сопрограмм ситуация выгля- API на основе сопрограмм ситуация выгля- на основе сопрограмм ситуация выгля- дит существенно лучше: вся последовательность трех операций находится внутри тела одной функции, как обычный последовательный код, а для сохранения кон-текста используются локальные переменные. См. пример 18.12. Пример 18.12. Сопрограммы и выражение yield from открывают возможность для асинхронного программирования без обратных вызовов @asyncio.coroutine def three_stages(request1): response1 = yield from api_call1(request1) # шаг 1 request2 = step1(response1) response2 = yield from api_call2(request2) # шаг 2 request3 = step2(response2) response3 = yield from api_call3(request3) # шаг 3 step3(response3) # выполнение необходимо планировать явно loop.create_task(three_stages(request1)) За логикой кода в примере 18.12 следить гораздо проще, чем в приведенных выше примерах на JavaScript и Python: все три шага операции следуют один за другим, не покидая тела функции. Использование предыдущих результатов для последующей обработки становится тривиальным делом, а, кроме того, имеется контекст для уведомления об ошибках посредством исключений. Допустим, что в примере 18.11 вызов api_call2(request2, stage2) приводит к исключению ввода-вывода (в последней строке функции stage1 ). Перехватить его в stage1 невозможно, потому что вызов api_call2 асинхронный: он возвраща- ет управление еще до выполнения ввода-вывода. В API на основе обратных вы- выполнения ввода-вывода. В API на основе обратных вы- ввода-вывода. В API на основе обратных вы- зовов эта проблема решается с помощью регистрации двух функций обратного вызова для каждого асинхронного вызова: одна вызывается в случае успешного завершения операции, другая – в случае ошибки. У словия работы в аду обратных вызовов быстро становятся невыносимыми, если приходится еще и обрабаты-вать ошибки. А теперь сравните с примером 18.12, где все асинхронные вызовы трехшаго- вой операции находятся в одной функции three_stages : исключения, возника- ющие при асинхронном выполнении api_call1 , api_call2 или api_call3 , можно Глава 18. Применение пакета asyncio для организации\n--- Страница 595 ---\n595 От обратных вызовов к будущим объектам и сопрограммам обработать, поместив соответствующее выражение yield from внутрь блока try/ except . Это куда лучше ада обратных вызовов, но я бы не стал употреблять термин «рай сопрограмм», потому что за все приходится платить. Вместо обычных функ-ций мы должны использовать сопрограммы и привыкнуть к yield from ; это первое препятствие. Коль скоро в функции встречается выражение yield from , она ста- новится сопрограммой и ее нельзя вызвать, просто написав api_call1(request1, stage1) , чтобы запустить цепочку обратных вызовов, как в примере 18.11. Необ- ходимо либо явно запланировать выполнение сопрограммы в цикле обработки со- выполнение сопрограммы в цикле обработки со- е сопрограммы в цикле обработки со- бытий, либо активировать ее с помощью yield from в другой сопрограмме, которая уже запланирована. Не будь в последней строке примера 18.12 обращения loop. create_task(three_stages(request1)) , не произошло бы вообще ничего. В следующем примере изложенная теория демонстрируется на практике. Выполнение нескольких запросов для каждой операции загрузки Предположим, что вместе с флагом нужно сохранять не только код страны, но и ее название. Тогда нам потребуется два HTTP-запроса на каждый флаг: одно – для получения изображения флага, другое – для загрузки файла metadata.json , на- ходящегося в том же каталоге, что и изображение, в этом файле хранится название страны. В многопоточном скрипте выполнить несколько запросов в составе одной за- дачи нетрудно: достаточно расположить их один за другим (при этом поток будет блокирован дважды) и запомнить оба элемента данных (код и название страны) в локальных переменных, которые можно будет использовать при сохранении фай-лов. Попытавшись сделать то же самое в асинхронном скрипте с помощью обрат-ных вызовов, мы почувствуем серный запах ада: код и название страны придется передавать в замыкании или запоминать где-то до момента сохранения файла, по-тому что функция обратного вызова исполняется в совершенно другом локальном контексте. Сопрограммы и yield from избавляют нас от этого. Решение не такое простое, как в случае потоков, но все же более обозримое, чем сцепленные или вложенные обратные вызовы. В примере 18.13 показан код из третьего варианта скрипта загрузки флагов с применением asyncio , только имя файла, в котором сохраняется флаг, образовано на основе названия страны. Функции download_many и downloader_coro такие же, как в файле flags2_asyncio.py (примеры 18.7 и 18.8). Перечислим изменения: download_one Теперь в этой сопрограмме используется yield from для делегирования ра- боты сопрограммам get_flag и get_country . get_flag Большая часть кода перенесена из этой сопрограммы в новую сопрограмму http_get , чтобы этим кодом можно было воспользоваться и в get_country .\n--- Страница 596 ---\n596 get_country Эта сопрограмма скачивает файл metadata.json , соответствующий коду страны, и получает из него название страны. http_get Общий код для скачивания файла из Интернета. Пример 18.13. flags3_asyncio.py: количество вызовов сопрограмм увеличилось, поскольку для каждого флага выполняется два запроса @asyncio .coroutine def http_get(url): res = yield from aiohttp.request('GET', url) if res.status == 200: ctype = res.headers.get('Content-type', '').lower() if 'json' in ctype or url.endswith('json'): data = yield from res.json() /g110 else: data = yield from res.read() /g111 return data elif res.status == 404: raise web.HTTPNotFound() else: raise aiohttp.errors.HttpProcessingError( code=res.status, message=res.reason, headers=res.headers) @asyncio.coroutine def get_country(base_url, cc): url = '{}/{cc}/metadata.json'.format(base_url, cc=cc.lower()) metadata = yield from http_get(url) /g112 return metadata['country'] @asyncio.coroutine def get_flag(base_url, cc): url = '{}/{cc}/{cc}.gif'.format(base_url, cc=cc.lower()) return (yield from http_get(url)) /g113 @asyncio.coroutine def download_one(cc, base_url, semaphore, verbose): try: with (yield from semaphore): /g114 image = yield from get_flag(base_url, cc) with (yield from semaphore): country = yield from get_country(base_url, cc) except web.HTTPNotFound: status = HTTPStatus.not_found msg = 'not found' except Exception as exc: raise FetchError(cc) from exc else: country = country.replace(' ', '_') filename = '{}-{}.gif'.format(country, cc) loop = asyncio.get_event_loop() loop.run_in_executor(None, save_flag, image, filename) status = HTTPStatus.okГлава 18. Применение пакета asyncio для организации\n--- Страница 597 ---\n597 Разработка серверов с помощью пакета asyncio msg = 'OK' if verbose and msg: print(cc, msg) return Result(status, cc) /g110 Если тип содержимого содержит подстроку 'json' или аргумент url закан- чивается строкой .json , то разбираем ответ методом response .json() и воз- вращаем структуру данных Python – в данном случае словарь dict . /g111 В противном случае просто читаем поступающие байты методом .read() . /g112 В metadata записывается словарь Python, построенный в результате разбо- ра содержимого в формате JSON. /g113 Здесь внешние скобки необходимы, потому что, увидев подряд три слова return yield from , синтаксический анализатор Python выдаст ошибку. /g114 Я поместил вызовы get_flag и get_country в разные блоки with , управляе- мые семафором semaphore , потому что не хочу удерживать семафор дольше, чем необходимо. В примере 18.13 конструкция yield from встречается девять раз. Сейчас вы уже, вероятно, понимаете, как она используется для делегирования работы от од-ной сопрограммы другой без блокировки цикла обработки событий. Проблема в том, как узнать, когда нужно использовать yield from , а когда это делать нельзя. Принципиальный ответ прост: сопрограммы и экземпляры класса asyncio.Future , в том числе задачи, активируются с помощью yield from . Но быва- ют запутанные API, где сопрограммы и обычные функции комбинируются произ-вольными, на первый взгляд, способами, например, класс StreamWriter , которым мы воспользуемся при написании одного из серверов в следующем разделе. Пример 18.13 завершает набор примеров из серии flags2 . Рекомендую вам по- экспериментировать с ними, чтобы развить интуитивное понимание работы па-раллельных HTTP-клиентов. Параметры командной строки -a, -e и -l позволяют изменять количество операций загрузки, а параметр -m – количество параллель- ных операций. Прогоните тесты на серверах типа LOCAL , REMOTE , DELAY и ERROR . Най- дите, при каком количестве параллельных операций загрузки достигается мак-симальная производительность для каждого сервера. Поиграйте с настройками скрипта vaurien_error_delay.sh (http://bit.ly/1f6CY6B ), чтобы добавить или устра- нить задержку и ошибки. Мы же теперь перейдем к применению пакета asyncio для написания серверов. Разработка серверов с помощью пакета asyncio Классический пример «игрушечного» TCP-сервера – сервер эхо-контроля. Но мы разработаем чуть более интересные игрушки: сервер поиска символов Unicode – сначала по протоколу TCP , а затем – HTTP . Эти серверы позволяют клиентам за-\n--- Страница 598 ---\n598 прашивать символы Unicode, в канонических именах которых встречаются задан- ные слова. Для этой цели мы воспользуемся модулем unicodedata , обсуждавшимся в разделе «База данных Unicode» на стр. 157. На рис. 18.2 показан telnet-сеанс ра-боты с TCP-сервером поиска символов, в котором мы ищем символы шахматных фигур и символы, в именах которых встречается слово «sun». Рис. 18.2. Telnet-сеанс с сервером tcp_charfinder .py server: запрос символов, в именах которых встречаются слова «chess black» и «sun» Обратимся к реализации. TCP-сервер на основе asyncio Основная часть кода этих примеров находится в модуле charfinder.py , кото- рый не имеет никакого отношения к конкурентности. Скрипт charfinder.py можно использовать для поиска символов из командной строки, но проектировался он главным образом как вспомогательное средство для серверов на основе asyncio . Файл charfinder.py находится в репозитории кода к данной книге ( https://github. com/fluentpython/example-code ). Модуль charfinder индексирует все слова, встречающиеся в именах симво- лов из базы данных Unicode, которая входит в дистрибутив Python, и создает инвертированный индекс в виде словаря dict . Например, ключу 'SUN' в инвер- тированном индексе соответствует множество из 10 символов Unicode, в именах которых встречается это слово. Инвертированный индекс сохраняется в файле charfinder_index.pickle . Если запрос состоит из нескольких слов, то charfinder вычисляет пересечение множеств, соответствующих каждому слову .Глава 18. Применение пакета asyncio для организации\n--- Страница 599 ---\n599 Разработка серверов с помощью пакета asyncio Займемся теперь скриптом tcp_charfinder.py , который обрабатывает запросы. Поскольку сказать по поводу этого кода мне предстоит немало, я разбил его на две части, показанные в примерах 18.14 и 18.15. Пример 18.14. tcp_charfinder .py: простой TCP-сервер с применением функции asyncio.start_server ; код этого модуля продолжается в примере 18.15 import sys import asyncio from charfinder import UnicodeNameIndex /g110 CRLF = b'\\r\\n' PROMPT = b'?> ' index = UnicodeNameIndex() /g111 @asyncio.coroutine def handle_queries(reader, writer): /g112 while True: /g113 writer.write(PROMPT) # не может быть yield from! /g114 yield from writer.drain() # должно быть yield from! /g115 data = yield from reader.readline() /g116 try: query = data.decode().strip() except UnicodeDecodeError: /g117 query = '\\x00' client = writer.get_extra_info('peername') /g118 print('Received from {}: {!r}'.format(client, query)) /g119 if query: if ord(query[:1]) < 32: ⤓ break lines = list(index.find_description_strs(query)) ⤔ if lines: writer.writelines(line.encode() + CRLF for line in lines) ⤕ writer.write(index.status(query, len(lines)).encode() + CRLF) ⤖ yield from writer.drain() ⤗ print('Sent {} results'.format(len(lines))) ⤘ print('Close the client socket') ⤙ writer .close() ⤚ /g110 Класс UnicodeNameIndex отвечает за построение индекса имен и предостав- ляет методы запросов к нему. /g111 Конструктор UnicodeNameIndex читает индекс из файла charfinder_index. pickle , если таковой существует, в противном случае строит индекс, поэтому ответ на первый запрос может занять на несколько секунд больше времени8. 8 Леонардо Рохаэль отметил, что конструирование UnicodeNameIndex можно было бы поручить от- дельному потоку, вызвав метод loop.run_with_executor() из функции main в примере 18.15, тог- да сервер был бы готов принимать запросы сразу после построения индекса. Это правда, но поскольку запросы к индексу – единственное, что делает данное приложение, то игра не стоит свеч. Впрочем, реализация совета Леонардо была бы интересным упражнением. Займитесь этим, если хотите.\n--- Страница 600 ---\n600 /g112 Это сопрограмма, которую мы должны передать методу asyncio.start_ server ; ее аргументами являются asyncio.StreamReader и asyncio.Stream- Writer . /g113 В этом цикле обрабатывается сеанс, который продолжается до получения любого управляющего символа от клиента. /g114 Метод StreamWriter.write – не сопрограмма, а обычная функция; в этой строке выводится приглашение ?>. /g115 Метод StreamWriter.drain сбрасывает буфер записи; это сопрограмма, по- этому вызывать ее следует с помощью yield from . /g116 Метод StreamWriter.readline – сопрограмма, он возвращает объект типа bytes . /g117 Исключение UnicodeDecodeError может возникнуть, если клиент T elnet по- сылает управляющий символ; в таком случае мы для простоты считаем, что получен нулевой символ. /g118 Здесь возвращается удаленный адрес сокета. /g119 Протоколируем запрос на консоли сервера. ⤓ Выходим из цикла, если получен управляющий или нулевой символ. ⤔ Возвращается генератор, который отдает строки, содержащие кодовую позицию Unicode, сам символ и его имя (например, U+0039\\t9\\tDIGIT NINE); для простоты я создаю из генератора список. I ⤕ Отправляем клиенту строки, преобразованные в последовательность бай- тов в предположении кодировки UTF-8, в конец каждой строки добавляем символы возврата каретки и перевода строки; обратите внимание, что аргу-мент – генераторное выражение. ⤖ Выводим строку состояния, например 627 matches for 'digit' . ⤗ Сбрасываем буфер вывода. ⤘ Протоколируем ответ на консоли сервера. ⤙ Протоколируем конец сеанса на консоли сервера. ⤚ Закрываем StreamWriter . Слово «queries» в имени сопрограммы handle_queries указано во множествен- ном числе, потому что эта сопрограмма начинает интерактивный сеанс и обраба-тывает по несколько запросов от каждого клиента. Отметим, что ввод-вывод в примере 18.14 производится в байтах. Мы должны декодировать строки, приходящие из сети, и закодировать отправляемые строки. В Python 3 кодировкой по умолчанию является UTF-8, ее мы и используем. Небольшая проблема заключается в том, что некоторые методы ввода-вы- вода являются сопрограммами и должны управляться посредством yield from , тогда как другие – обычные функции. Например, StreamWriter.write – обычная функция, поскольку предполагается, что в большинстве случаев она ничего не блокирует, т. к. пишет в буфер. С другой стороны, метод StreamWriter.drain , ко- торый сбрасывает буфер, выполняя реальный вывод, – сопрограмма, как и метод Streamreader.readline . Когда я работал над книгой, в документацию по asyncio API было внесено важное улучшение: все сопрограммы явно обозначены.Глава 18. Применение пакета asyncio для организации\n--- Страница 601 ---\n601 Разработка серверов с помощью пакета asyncio В примере 18.15 показана функция main для модуля, начатого в примере 18.14. Пример 18.15. tcp_charfinder .py (продолжение примера 18.14): функция main инициализирует и завершает цикл обработки событий и TCP-сервер def main(address='127.0.0.1', port=2323): /g110 port = int(port) loop = asyncio.get_event_loop() server_coro = asyncio.start_server(handle_queries, address, port, loop=loop) /g111 server = loop.run_until_complete(server_coro) /g112 host = server.sockets[0].getsockname() /g113 print('Serving on {}. Hit CTRL-C to stop.'.format(host)) /g114 try: loop.run_forever() /g115 except KeyboardInterrupt: # нажата CTRL+C pass print('Server shutting down.') server.close() /g116 loop.run_until_complete(server.wait_closed()) /g117 loop.close() /g118 if __name__ == '__main__': main(*sys .argv[1:]) /g119 /g110 Функцию main можно вызывать без аргументов. /g111 По завершении объект-сопрограмма, полученный от asyncio.start_server , возвращает экземпляр asyncio.Server , TCP-сервера. /g112 Управляя сопрограммой server_coro , получаем объект server . /g113 Получаем адрес и порт первого сокета сервера и … /g114 … выводим его на консоль. Это первое, что скрипт печатает на консоли сер- вера. /g115 Исполняем цикл обработки событий; здесь функция main блокируется до тех пор, пока на консоли сервера не будет нажата клавиша CTRL-C . /g116 Закрываем сервер. /g117 Метод server.wait_closed() возвращает будущий объект; дадим ему возмож- ность выполнить свою работу с помощью метода loop.run_until_complete . /g118 Завершаем цикл обработки событий. /g119 Это краткий способ выразить обработку необязательных аргументов ко- мандной строки: разворачиваем sys.argv[1:] и передаем результат функ- ции main , в которой заданы также значения аргументов по умолчанию. Отметим, что метод run_until_complete принимает либо сопрограмму (резуль- тат start_server ), либо объект Future (результат server.wait_closed ). Если в каче- стве аргумента передана сопрограмма, то она обертывается объектом Task . Разобраться в потоке управления в скрипте tcp_charfinder.py будет проще, если внимательно приглядеться к сообщениям, печатаемым на консоли (см. при-мер 18.16).\n--- Страница 602 ---\n602 Пример 18.16. tcp_charfinder .py: это серверная часть сеанса, показанного на рис. 18.2 $ python3 tcp_charfinder.py Serving on ('127.0.0.1', 2323). Hit CTRL-C to stop. /g110 Received from ('127.0.0.1', 62910): 'chess black' /g111 Sent 6 resultsReceived from ('127.0.0.1', 62910): 'sun' /g112 Sent 10 resultsReceived from ('127.0.0.1', 62910): '\\x00' /g113 Close the client socket /g114 /g110 Это выводит main . /g111 Первая итерация цикла while в сопрограмме handle_queries . /g112 Вторая итерация цикла while . /g113 Пользователь нажал CTRL-C ; сервер получает управляющий символ и за- крывает сеанс. /g114 Сокет клиента закрыт, но сервер продолжает работать и обслуживать дру- гих клиентов. Обратите внимание, что main почти сразу выводит сообщение Serving on и блокируется на время выполнения метода loop.run_forever() . В этот момент управление попадает в цикл обработки событий. Цикл работает, время от времени уступая процессор сопрограмме handle_queries , а та уступает его обратно циклу, ожидая завершения приема или передачи по сети. Пока цикл обработки событий не завершился, для каждого нового клиента, подключившегося к серверу, создает-ся новый экземпляр сопрограммы handle_queries . Таким образом, к этому просто- му серверу могут одновременно обращаться несколько клиентов. Сервер продол-жает работать, пока не возникнет исключение KeyboardInterrupt или программа не будет снята операционной системой. В скрипте tcp_charfinder.py мы воспользовались высокоуровневым интерфей- сом Streams API, включенным в пакет asyncio (https://docs.python.org/3/library/ asyncio-stream.html ), который предоставляет готовый сервер, так что нам нужно только реализовать функцию-обработчик, которая может быть как простым об-ратным вызовом, так и сопрограммой. Существует также низкоуровневый ин-терфейс Transports and Protocols API ( https://docs.python.org/3/library/asyncio- protocol.html ), построенный по образцу абстракций транспорта и протоколов из библиотеки T wisted. Дополнительные сведения см. в разделе «Транспорты и про-токолы» документации по asyncio (http://bit.ly/1f6D9i6 ), где приведен также при- мер реализации TCP-сервера эхо-контроля с помощью этого API. В следующем разделе представлен HTTP-сервер поиска символов. Веб-сервер на основе библиотеки aiohttp Библиотека aiohttp , которой мы пользовались в скриптах загрузки флагов с применением пакета asyncio , поддерживает также и программирование HTTP- серверов, поэтому я взял ее для реализации скрипта http_charfinder.py . На рис. 18.3 Глава 18. Применение пакета asyncio для организации\n--- Страница 603 ---\n603 Разработка серверов с помощью пакета asyncio показан простой веб-интерфейс сервера, где выведены результаты поиска смайли- ка «cat face» (кошачья мордочка). Рис. 18.3. В окне браузера отображаются результаты поиска символов по строке «cat face», возвращенные сервером http_charfinder.py В одних браузерах символы Unicode отображаются лучше, в других хуже. Рис. 18.3 скопирован из браузера Firefox на платформе Mac OS X, и точно такой же результат дал Safari. Но последние версии Chrome и Opera на той же машине не показали смайликов с кошачьими мордочками. Результаты других запросов (например, по слову «chess») выглядели прекрасно, так что эта проблема, вероятно, связана со шрифтами, которыми Chrome и Opera пользуются в OS X. Начнем с анализа самой интересной, последней, части скрипта http_charfinder. py, где находится цикл обработки событий и производится инициализация и за- крытие HTTP-сервера. Пример 18.17. http_charfinder .py: функции main и init @asyncio.coroutine def init(loop, address, port): /g110 app = web.Application(loop=loop) /g111 app.router.add_route('GET', '/', home) /g112 handler = app.make_handler() /g113 server = yield from loop.create_server(handler, address, port) /g114 return server.sockets[0].getsockname() /g115 def main(address=\"127.0.0.1\", port=8888):\n--- Страница 604 ---\n604 port = int(port) loop = asyncio.get_event_loop() host = loop.run_until_complete(init(loop, address, port)) /g116 print('Serving on {}. Hit CTRL-C to stop.'.format(host)) try: loop.run_forever() /g117 except KeyboardInterrupt: # нажата CTRL+C pass print('Server shutting down.') loop.close() /g118 if __name__ == '__main__': main(*sys .argv[1:]) /g110 Сопрограмма init отдает сервер, который будет обрабатывать запросы в цикле обработки событий. /g111 Класс aiohttp.web.Application представляет веб-приложение… /g112 … в котором маршруты сопоставляют функции-обработчики образцам URL-адресов; в данном случае запрос GET / маршрутизируется функции home (см. пример 18.18). /g113 Метод app.make_handler возвращает объект типа aiohttp.web.RequestHan- dler , который обрабатывает HTTP-запросы в соответствии с маршрутами, заданными в объекте app. /g114 Метод create_server создает сервер, использующий в качестве обработчи- ка протокола объект handler , и связывает его с адресом address и портом port . /g115 Возвращаем адрес и порт первого сокета сервера. /g116 Вызываем init для запуска сервера и получения его адреса и порта. /g117 Исполняем цикл обработки событий; main блокируется, пока управление остается у цикла. /g118 Закрываем цикл обработки событий. В плане знакомства с asyncio API интересно сравнить инициализацию серве- ров в примерах 18.17 и 18.15. Создание и планирование TCP-сервера производилось в следующих двух строчках функции main : server_coro = asyncio.start_server(handle_queries, address, port, loop=loop) server = loop.run_until_complete(server_coro) А HTTP-сервер создается в функции init : server = yield from loop.create_server(handler, address, port) Но init сама является сопрограммой, поэтому активируется она в функции main следующим образом: host = loop.run_until_complete(init(loop, address, port))Глава 18. Применение пакета asyncio для организации\n--- Страница 605 ---\n605 Разработка серверов с помощью пакета asyncio И asyncio.start_server , и loop.create_server – сопрограммы, возвращающие объекты asyncio.Server . Чтобы запустить сервер и вернуть на него ссылку, каж- дой из них нужно управлять до завершения. В случае TCP-сервера это делалось путем вызова метода loop.run_until_complete(server_coro) , где server_coro – ре- зультат, полученный от asyncio.start_server . В примере HTTP-сервера метод create_server активируется в выражении yield from в сопрограмме init , которой функция main управляет в вызове loop.run_until_complete(init( )) . Все это я говорю, чтобы подчеркнуть важный факт: сопрограмма делает что- то, только если ей управляют, а для управления сопрограммой asyncio.coroutine нужно либо воспользоваться выражением yield from , либо передать ее одной из нескольких функций из пакета asyncio , который принимают сопрограммы или бу- дущие объекты, например run_until_complete . В примере 18.18 показана функция home , настроенная для обработки корневого URL-адреса (/) в нашем HTTP-сервере. Пример 1818. http_charfinder .py: функция home def home(request): /g110 query = request.GET.get('query', '').strip() /g111 print('Query: {!r}'.format(query)) /g112 if query: /g113 descriptions = list(index.find_descriptions(query)) res = '\\n'.join(ROW_TPL.format(**vars(descr)) for descr in descriptions) msg = index.status(query, len(descriptions)) else: descriptions = [] res = '' msg = 'Enter words describing characters.' html = template.format(query=query, result=res, /g114 message=msg) print('Sending {} results'.format(len(descriptions))) /g115 return web.Response(content_type=CONTENT_TYPE, text=html) /g116 /g110 Обработчик маршрутов получает экземпляр aiohttp.web.Request . /g111 Получаем строку запроса, из которой удалены начальные и конечные про- белы. /g112 Протоколируем запрос на консоли сервера. /g113 Если запрос был, то связываем res со строками HTML-таблицы, построенной по результатам запроса к индексу, а msg – с сообщением о состоянии. /g114 Отрисовываем HTML-страницу. /g115 Протоколируем ответ на консоли сервера. /g116 Строим и возвращаем объект Response . Отметим, что функция home – не сопрограмма и не должна ей быть, если в ней нет выражений yield from . В документации по методу add_route из пакета aiohttp\n--- Страница 606 ---\n606 (http://bit.ly/1HGu5dz ), говорится, что обработчик, «являющийся обычной функ- цией, автоматически преобразуется в сопрограмму». Функция home из примера 18.18 очень проста, но у этой простоты есть недо- статок. Тот факт, что это обычная функция, а не сопрограмма, наводит на важный вопрос: мы должны переосмыслить, каким образом обеспечить высокую степень параллелизма веб-приложений. Подумаем об этом. Повышение степени параллелизма за счет более интеллектуальных клиентов Функция home из примера 18.18 очень похожа на функцию представления в Django или Flask. В ее реализации нет ничего асинхронного: она получает запрос, читает данные из базы и строит ответ, отрисовывая полную HTML-страницу. В данном примере «базой данных» является объект UnicodeNameIndex , храня- щийся в памяти. Но к настоящей базе данных следует обращаться асинхронно, в противном случае цикл обработки событий окажется блокированным в ожида-нии результатов. Например, пакет aiopg (https://aiopg.readthedocs.org/en/stable/ ) предоставляет асинхронный драйвер СУБД PostgreSQL, совместимый с asyncio ; он позволяет использовать yield from для отправки запросов и получения резуль- татов, поэтому функция представления может вести себя как сопрограмма. Системы с высокой степенью параллелизма должны не только избегать блокиру- ющих вызовов, но и разбивать большие работы на более мелкие части. Эта проблема проявляется и в сервере http_charfinder.py : поиск по слову «cjk» возвращает 75 821 китайских японских и корейских иероглифов 9. В данном случае функция home вер- нет HTML-документ размером 5,3 МБ, содержащий таблицу из 75 821 строк. На моей машине командному HTTP-клиенту curl для получения ответа на запрос «cjk» от локального сервера http_charfinder.py потребовалось 2 секунды. Браузеру понадобится еще больше времени, чтобы отрисовать такую огромную таблицу. Разумеется, ответы на большинство запросов гораздо меньше: запрос по слову «braille» возвращает 256 строк, занимающих 19 КБ, и на моей машине вы-полняется за 0,017 с. Но если сервер тратит 2 с на выполнение одного запроса «cjk», то все остальные клиенты должны будут ждать по меньшей мере 2 с, а это неприемлемо. Один из способов решить проблему длинного ответа – реализовать разбиение на страницы, т. е. возвращать, скажем, не более 200 строк и предоставить пользова-телю средства для листания страниц. В модуле charfinder.py из репозитория кода к этой книге ( http://bit.ly/1JItSti ) есть метод UnicodeNameIndex.find_descriptions , принимающий необязательные аргументы start и stop : это смещения для под- держки разбиения на страницы. Поэтому можно было бы вернуть первые 200 ре-зультатов, а затем с помощью AJAX или даже W ebSockets отправлять следующую порцию, когда (и если) пользователь захочет ее увидеть. 9 Аббревиатура CJK означает «Chinese, Japanese, Korean» – постоянно расширяющийся набор ки- тайских, японских и корейских символов. Возможно, будущие версии Python станут поддерживать даже больше иероглифов CJK, чем версия 3.4.Глава 18. Применение пакета asyncio для организации\n--- Страница 607 ---\n607 Резюме Большая часть кода, необходимого для отправки результатов порциями, будет находиться на стороне браузера. Именно поэтому Google и вообще все крупные сайты в Интернете содержат так много клиентского кода: интеллектуальные асин-хронные клиенты более эффективно используют ресурсы сервера. Хотя интеллектуальные клиенты могут улучшить даже Django-приложения, написанные по старинке, для полноценного использования всех их возможностей необходима поддержка асинхронного программирования на всех стадиях: от об-работки HTTP-запросов и ответов до доступа к базе данных. Особенно это от-носится к реализации служб реального времени, например игр или потокового мультимедиа, с помощью технологии W ebSockets 10. Реализацию поддержки прогрессивной загрузки в скрипте http_charfinder.py я оставляю в качестве упражнения для читателя. Бонусные очки тому, кто сумеет сделать «бесконечную прокрутку», как в Твиттере. Этим вызовом я и завершу рас-смотрение конкурентного программирования с применением пакета asyncio . Резюме В этой главе мы познакомились с совершенно новой технологией конкурентного программирования в Python, в которой используются выражения yield from , со- программы, будущие объекты и цикл обработки событий asyncio . На первых про- стых примерах анимированного индикатора мы провели сравнение подходов на основе пакетов threading и asyncio . Затем мы обсудили специфику класса asyncio .Future , обратив особое внимание на поддержку yield from и связи с сопрограммами и классом asyncio.Task . Далее мы проанализировали скрипт загрузки флагов на основе пакета asyncio . После этого мы поразмыслили над приведенными Райаном Далом данными о задержке ввода-вывода и последствиях блокирующих вызовов. Чтобы написать программу, которая будет продолжать обслуживание запросов, несмотря на не-избежное присутствие блокирующих функций, у нас есть два подхода: потоки и асинхронные вызовы, причем последний вариант можно реализовать с помощью обратных вызовов или сопрограмм. На практике асинхронные библиотеки опираются на низкоуровневые – вплоть до уровня ядра – потоки, но пользователь такой библиотеки никаких потоков не создает и даже не обязан знать об их использовании в инфраструктуре. На уров-не приложения мы лишь должны следить за тем, чтобы наш собственный код не блокировал выполнение, а о параллелизме позаботится цикл обработки событий. Исключение накладных расходов, сопряженных с потоками пользовательского уровня, и есть основная причина того, что асинхронные системы способны обра-батывать больше одновременных подключений, чем многопоточные Для того чтобы добавить в скрипт загрузки флагов индикатор хода выполне- ния и обработку ошибок, его пришлось существенно переработать и, прежде всего, перейти от метода asyncio.wait к методу asyncio.as_completed . Это заставило нас перенести значительную часть функциональности из функции download_many в 10 Я еще вернусь к этой теме на врезке «Поговорим» ниже.\n--- Страница 608 ---\n608 новую сопрограмму downloader_coro , так чтобы можно было воспользоваться вы- ражением yield from для поочередного получения результатов будущих объектов, порождаемых методом asyncio.as_completed . Затем мы видели, как делегировать блокирующие действия – например, сохра- нение файла – пулу потоков с помощью метода loop.run_in_executor . После этого мы обсудили, как сопрограммы решают основные проблемы об- ратных вызовов: потерю контекста при выполнении многошаговых асинхронных задач и отсутствие надлежащего контекста для обработки ошибок. В следующем примере – получении от сервера не только изображений флагов, но и названий стран – мы продемонстрировали, как совместное использование сопрограмм и выражений yield from позволяет избежать так называемого ада об- ратных вызовов. Многошаговая процедура, в которой асинхронные вызовы про-изводятся с помощью yield from , выглядит как простой последовательный код, если не обращать внимания на ключевые слова yield from . И напоследок мы разработали на основе пакета asyncio TCP- и HTTP-версию сервера, позволяющего искать символы Unicode по имени. Описание HTTP-сервера мы завершили обсуждением важности клиентского JavaScript-кода для обеспечения более высокого уровня параллелизма на стороне сервере – за счет того, что клиент отправляет более простые запросы по мере необходимости вместо того, чтобы сразу загружать массивные HTML-страницы. Дополнительная литература Ник Кофлин, один из разработчиков ядра Python, в январе 2013 года сделал сле- Python, в январе 2013 года сделал сле- , в январе 2013 года сделал сле- дующее замечание по поводу предварительного варианта документа «PEP-3156 – Asynchronous IO Support Rebooted: the \"asyncio\" Module» ( http://bit.ly/1HGuPPE ): Где-то в начале PEP нужно поместить краткое описание следую- щих двух API для ожидания асинхронного объекта Future : 1. f.add_done_callback( …). 2. yield from f в сопрограмме (возобновляет сопрограмму по завершении будущего объекта, отдавая результат или исклю-чение). В настоящий момент эти описания закопаны среди множества других, хотя именно они дают ключ к пониманию взаимодействия всех механизмов, расположенных выше уровня цикла обработки со-бытий 11. Гвидо ван Россум, автор документа PEP-3156 ( https://www.python.org/dev/ peps/pep-3156/ ) не прислушался к совету Кофлина. Начиная с самого докумен- та PEP-3156, документация по пакету asyncio очень подробна, но неудобна для пользования. Девять RST-файлов, составляющих эту документацию ( http://bit. 11 Замечание к PEP-3156 в сообщении, отправленном в список рассылки python-ideas 20 января 2013 (http://bit.ly/1f6DGRi ).Глава 18. Применение пакета asyncio для организации\n--- Страница 609 ---\n609 Дополнительная литература ly/1HGuuwq ) в совокупности занимают 128 КБ – примерно 71 страницу. В до- кументации по стандартной библиотеке только глава «Встроенные типы» ( http:// bit.ly/1HGurAX ) больше, а ведь в ней описываются API для числовых типов, типов последовательней, генераторов, отображений, множеств, типа bool , контекстных менеджеров и т. д. Большая часть руководства по asyncio посвящена концепциям и API. По тек- сту разбросано много полезных диаграмм и примеров, но для практических це-лей хочется особо отметить раздел «18.5.11. Разработка с применением asyncio» (https://docs.python.org/3/library/asyncio-dev.html ), в котором представлены самые важные паттерны. Хотелось бы, чтобы в документации по asyncio было больше материалов о том, как следует использовать этот пакет. Из-за своей новизны пакет asyncio еще недостаточно освещен в литературе. Книга Jan Palach «Parallel Programming with Python» (Packt, 2014) – единственное издание, в котором я нашел главу, посвященную asyncio , да и та очень коротенькая. Однако на тему asyncio есть отличные презентации. Лучшая из тех, что я видел, принадлежит Бретту Слаткину (Brett Slatkin). Она называется «Fan-In and Fan-Out: The Crucial Components of Concurrency» ( http://bit.ly/1f6DIZo ) и имеет под- заголовок «Why do we need T ulip? (a.k.a., PEP 3156 – asyncio)». Бретт представил ее на конференции PyCon 2014 в Монреале (видео размещено по адресу http:// bit.ly/1HGuRY2 ). В 30-минутном выступлении Слаткин демонстрирует пример Интернет-робота, уделяя много внимания тому, как следует использовать asyncio . Присутствовавший на презентации Гвидо ван Россум отметил, что он тоже на-писал робот в качестве пояснительного примера к asyncio ; код Гвидо ( http://bit. ly/1HGub4K ) не зависит от aiohttp , ему нужна только стандартная библиотека. Слаткин написал также весьма познавательную статью «Python's asyncio Is for Composition, Not Raw Performance» ( http://bit.ly/1f6DJwj ). Есть еще несколько выступлений по asyncio , которые нужно обязательно про- смотреть: основной доклад самого Гвидо ван Россума на конференции PyCon US 2013 ( http://bit.ly/1HGueh0 ) и его лекции на сайтах LinkedIn ( http://bit. ly/1HGudd0 ) и в университете T witter ( http://bit.ly/1HGuexy ). Рекомендую также доклад Саула Ибарра Корретге (Saul Ibarra Corretge) «A Deep Dive into PEP-3156 and the New asyncio Module» (слайды – по адресу http://bit.ly/1HGuf4D , видео – по адресу http://bit.ly/1HGufBq ). Дино Виланд (Dino Viehland) в докладе «Using futures for async GUI programming in Python 3.3» ( http://bit.ly/1HGuoos ) на конференции PyCon US 2013 показал, как можно интегрировать asyncio с циклом обработки событий Tkinter. Виланд демонстрирует, как просто реализовать обязательные части ин-терфейса asyncio .AbstractEventLoop поверх другого цикла обработки событий. Его код написан с применением T ulip, еще до включения asyncio в стандартную библи- отеку; я адаптировал его для работы с версией asyncio в Python 3.4. Результат этой работы можно найти на GitHub ( http://bit.ly/1HGulck ). Виктор Стиннер (Victor Stinner) – один из разработчиков ядра asyncio и автор библиотеки Trollius ( http://trollius.readthedocs.org ), являющейся обратным пере- носом asyncio на более старые версии Python, регулярно обновляет список отно-\n--- Страница 610 ---\n610 сящихся к этому предмету ссылок под названием «The new Python asyncio module aka \"tulip\"» ( http://bit.ly/1HGumwZ ). Другие подборки ресурсов, посвященных asyncio , имеются на сайтах Asyncio.org ( http://asyncio.org ) и aio-libs ( https://github. com/aiolibs ), где есть асинхронные драйверы для PostgreSQL, MySQL и несколь- ких баз данных NoSQL. Я эти драйверы не тестировал, но проекты, похоже, раз-виваются очень динамично. Важной областью применения asyncio являются веб-службы. Ваш код, ско- рее всего, будет пользоваться библиотекой aiohttp (http://aiohttp.readthedocs.org/ en/), разработку которой возглавляет Андрей Светлов. Наверное, вы также за- хотите настроить свою среду для тестирования кода обработки ошибок, и в этом вам окажет неоценимую помощь система Vaurien ( http://vaurien.readthedocs.org/ en/1.8/ ) – «хаотичный TCP-прокси» – спроектированная Алексисом Метайро (Alexis Metaireau) и Тареком Зиадом (Tarek Ziade). Vaurien создавалась для про-екта Mozilla Services ( https://mozilla-services.github.io/ ), она позволяет вносить за- держки и случайные ошибки в TCP-трафик между вашей программой и различ-ными серверами, например базами данных или поставщиками веб-служб. Поговорим Один цикл Уже давно асинхронное программирование является излюбленным многими питонистами подходом к разработке сетевых приложений, но всегда стояла проблема выбора одной из несовместимых между собой библиотек. Райан Дал говорит, что при создании Node.js он взял за об-разец библиотеку T wisted, а в T ornado впервые стали использоваться сопрограммы для событийно-ориентированного программирования на Python. В мире JavaScript не утихают споры между приверженцами простых обратных вызовов и сторонниками различных конкурирующих меж-ду собой абстракций более высокого уровня. В ранних версиях Node.js API использовались обещания (Promise) – аналог наших объектов Future, – но Райан Дал решил ограничиться только обратными вызо-вами и сделать их стандартом. Джеймс Коглэн (James Coglan) считает это решение крупнейшей из упущенных в Node возможностей ( http:// bit.ly/1xNcNHZ ). В Python дебаты закончились: после добавления asyncio в стандарт- ную библиотеку сопрограммы и будущие объекты стали средствами для написания асинхронного кода в духе Python. Более того, пакет asyncio определяет стандартные интерфейсы для асинхронных будущих объек-тов и цикла обработки событий и содержит их эталонные реализации. К этому случаю идеально применимы два принципа из «Дзен Python»:Глава 18. Применение пакета asyncio для организации\n--- Страница 611 ---\n611 Поговорим Должен существовать один – и, желательно, только один – оче- видный способ сделать это. Хотя он поначалу может быть и не очевиден, если вы не голландец. Наверное, для того чтобы счесть конструкцию yield from очевидной, действительно нужен голландский паспорт. Данному конкретному бра-зильцу она поначалу вовсе не показалось очевидной, но со временем я освоился. Очень важно, что asyncio спроектирован так, чтобы встроенный цикл обработки событий можно было заменить внешним пакетом. Именно по этой причине существуют функции asyncio.get_event_loop и set_ event_loop ; они являются частью абстрактного API стратегии цикла об- работки событий ( http://bit.ly/1HGuUTy ). В T ornado уже имеется класс AsyncIOMainLoop ( http://tornado. readthedocs.org/en/latest/asyncio.html ), реализующий интерфейс asyncio . AbstractEventLoop , так что можно исполнять асинхронный код, приме- няя обе библиотеки в одном и том же цикле обработки событий. Су-ществует также многообещающий проект Quamash ( https://pypi.python. org/pypi/Quamash/ ), в котором asyncio интегрируется с циклом обра- ботки событий Qt с целью разработки приложений с графическим ин-терфейсом на основе PyQt или PySide. И это только два из постоянно растущего множества интероперабельных событийно-ориентирован-ных пакетов, появление которых стало возможно благодаря asyncio . Интеллектуальные HTTP-клиенты, в частности одностраничные веб-приложения (типа Gmail), и приложения для смартфонов нуждают-ся в быстром получении коротких ответов и проталкивании обновлений. Для удовлетворения таких потребностей лучше подходят асинхронные каркасы, а не традиционные веб-каркасы типа Django, которые проек-тировались для возврата полностью отрисованных HTML-страниц и не поддерживают асинхронный доступ к базе данных. Протокол W ebSockets разрабатывался, чтобы можно было в реаль- ном времени обновлять постоянно подключенные клиенты – от игр до потоковых приложений. Для этого необходимы серверы с высо-чайшей степенью параллелизма, способные поддерживать постоянное взаимодействие с сотнями и тысячами клиентов. W ebSockets отлично поддерживается архитектурой на базе asyncio , и существуют по край- ней мере две библиотеки такого рода, реализованные поверх asyncio : Autobahn|Python ( http://autobahn.ws/python/ ) и W ebSockets ( http:// aaugustin.github.io/websockets/ ). Эта превалирующая тенденция, получившая название «веб реально- го времени», – основной фактор спроса на Node.js и причина, по которой консолидация вокруг asyncio так важна для экосистемы Python. Еще многое предстоит сделать. Прежде всего, нам нужны асинхронные кли-\n--- Страница 612 ---\n612 ентский и серверный API для протокола HTTP в стандартной библио- теке, асинхронный DB API ( http://bit.ly/1HGuVGY ) 3.0 и новые драйве- ры баз данных на основе asyncio . Важнейшее преимущество Python 3.4 с asyncio над Node.js – сам язык Python: он лучше спроектирован, а имеющиеся в нем сопрограммы и выражения yield from существенно упрощают сопровождение асин- хронного кода по сравнению с примитивными обратными вызовами JavaScript. Наш основной недостаток – библиотеки: Python поставляет-ся с «батарейками в комплекте», но наши батарейки не предназначены для асинхронного программирования. Богатая экосистема библиотек для Node.js целиком ориентирована на асинхронные вызовы. Однако как для Python, так и для Node.js характерна проблема, которая в язы-ках Go и Erlang была решена изначально: у нас нет прозрачного способа писать код, задействующий все процессорные ядра. Стандартизация интерфейса цикла обработки событий и асинхрон- ной библиотеки стала важным достижением, и только наш «великодуш-ный пожизненный диктатор» мог справиться с этим делом, учитывая наличие прочно укоренившихся высококачественных альтернатив. При решении этой задачи он советовался с авторами основных асинхрон-ных каркасов на Python. Наиболее очевидно влияние Глифа Лефкови-ца (Glyph Lefkowitz), стоящего во главе проекта T wisted. Сообщение «Deconstructing Deferred», которое Гвидо отправил в группу Python-tulip ( http://bit.ly/1HGuXPa ), обязательно должен прочитать каж- дый, кто хочет понять, почему класс asyncio .Future не похож на класс Deferred из T wisted. Отдавая дань уважения старейшему и крупнейше- му асинхронному каркасу, написанному на Python, Гвидо также пустил в обращение мем WWTD – What W ould T wisted Do? (Что сделал бы T wisted?) – в ходе обсуждения вариантов проектных решений в группе python-twisted 12. По счастью, Гвидо ван Россум предпринял огромные усилия, чтобы Python оказался в лучшем положении для отражения вызовов, связан-ных с параллелизмом. Для освоения asyncio нужно попотеть. Но если вы планируете писать на Python параллельные сетевые приложения, ищите Один Цикл. Один цикл, чтоб править всеми, Один цикл найдет их всех, Один цикл соберет их И заключит их в свете.13 12 См. сообщение Гвидо от 29 января 2015 ( http://bit.ly/1f6E2qT ), на которое незамедли- тельно последовал ответ Глифа. 13 Перефразированное четверостишие из «Властелина колец» Толкиена ( One ring to rule them all, one ring to find them, One ring to bring them all and in the darkness bind them). – Прим. перев.Глава 18. Применение пакета asyncio для организации\n--- Страница 613 ---\nЧАСТЬ VI Метапрограммирование",
      "debug": {
        "start_page": 567,
        "end_page": 613
      }
    },
    {
      "name": "Глава 19. Динамические атрибуты и свойства 614",
      "content": "--- Страница 614 --- (продолжение)\nГЛАВА 19. Динамические атрибуты и свойства Ценность свойств заключается в том, что благодаря им можно совер-шенно безопасно – и это даже рекомендуется – раскрывать атрибуты-данные как часть открытого интерфейса класса 1. – Алекс Мартелли, один из разработчиков Python и автор книги Атрибуты-данные и методы в Python носят общее название «атрибуты»; метод – это просто вызываемый атрибут. Помимо атрибутов-данных и методов, мы можем создавать еще свойства, позволяющие заменить открытые атрибуты-данные ме-тодами-акцессорами (т. е. методами чтения и установки), не изменяя интерфейс класса. Это согласуется с принципом единообразного доступа : Все сервисы, предоставляемые модулем, должны быть доступны с помощью единообразной нотации, скрывающей механизм реали-зации: хранение или вычисление 2. Помимо свойств, Python предлагает богатый API для управления доступом к атрибутам и реализации динамических атрибутов. Интерпретатор вызывает спе-циальные методы __getattr__ и __setattr__ при использовании нотации доступа к атрибутам с помощью точки (например, obj.attr ). Пользовательский класс, в котором имеется метод __getattr__ , может реализовать «виртуальные атрибуты», вычисляемые «на лету», когда программа пытается прочитать несуществующий атрибут, например obj.no_such_attribute . Динамические атрибуты – вид метапрограммирования, обычно применяемый авторами каркасов. Однако в Python базовая техника настолько проста, что любой человек может воспользоваться ими, даже для повседневных задач обработки дан-ных. С нее мы и начнем эту главу. 1 Alex Martelli «Python in a Nutshell», издание 2 (O'Reilly), стр. 101. 2 Bertrand Meyer, Object-Oriented Software Construction, издание 2, стр. 57.\nГЛАВА 19. Динамические атрибуты и свойства Ценность свойств заключается в том, что благодаря им можно совер-шенно безопасно – и это даже рекомендуется – раскрывать атрибуты-данные как часть открытого интерфейса класса 1. – Алекс Мартелли, один из разработчиков Python и автор книги Атрибуты-данные и методы в Python носят общее название «атрибуты»; метод – это просто вызываемый атрибут. Помимо атрибутов-данных и методов, мы можем создавать еще свойства, позволяющие заменить открытые атрибуты-данные ме-тодами-акцессорами (т. е. методами чтения и установки), не изменяя интерфейс класса. Это согласуется с принципом единообразного доступа : Все сервисы, предоставляемые модулем, должны быть доступны с помощью единообразной нотации, скрывающей механизм реали-зации: хранение или вычисление 2. Помимо свойств, Python предлагает богатый API для управления доступом к атрибутам и реализации динамических атрибутов. Интерпретатор вызывает спе-циальные методы __getattr__ и __setattr__ при использовании нотации доступа к атрибутам с помощью точки (например, obj.attr ). Пользовательский класс, в котором имеется метод __getattr__ , может реализовать «виртуальные атрибуты», вычисляемые «на лету», когда программа пытается прочитать несуществующий атрибут, например obj.no_such_attribute . Динамические атрибуты – вид метапрограммирования, обычно применяемый авторами каркасов. Однако в Python базовая техника настолько проста, что любой человек может воспользоваться ими, даже для повседневных задач обработки дан-ных. С нее мы и начнем эту главу. 1 Alex Martelli «Python in a Nutshell», издание 2 (O'Reilly), стр. 101. 2 Bertrand Meyer, Object-Oriented Software Construction, издание 2, стр. 57.\n--- Страница 615 ---\n615 Применение динамических атрибутов для обработки данных Применение динамических атрибутов для обработки данных В примерах ниже мы воспользуемся динамическими атрибутами для обработки данных в формате JSON, опубликованных издательством O'Reilly для конферен-ции OSCON 2014. В примере 19.1 показаны четыре записи из этого набора 3. Пример 19.1. Примеры записей из файла osconfeed.json; значения некоторых полей сокращены { \"Schedule\": { \"conferences\": [{\"serial\": 115 }], \"events\": [ { \"serial\": 34505, \"name\": \"Why Schools Don/t Use Open Source to Teach Programming\", \"event_type\": \"40-minute conference session\", \"time_start\": \"2014-07-23 11:30:00\", \"time_stop\": \"2014-07-23 12:10:00\", \"venue_serial\": 1462, \"description\": \"Aside from the fact that high school programming \", \"website_url\": \"http://oscon.com/oscon2014/public/schedule/detail/34505\", \"speakers\": [157509], \"categories\": [\"Education\"] } ], \"speakers\": [ { \"serial\": 157509, \"name\": \"Robert Lefkowitz\", \"photo\": null, \"url\": \"http://sharewave.com/\", \"position\": \"CTO\", \"affiliation\": \"Sharewave\", \"twitter\": \"sharewaveteam\", \"bio\": \"Robert /r0ml/ Lefkowitz is the CTO at Sharewave, a startup \" } ], \"venues\": [ { \"serial\": 1462, \"name\": \"F151\", \"category\": \"Conference Venues\" } ] }} В примере 19.1 показаны 4 из 895 записей JSON-файла. Как видим, весь набор данных – это единственный JSON-объект с ключом \"Schedule\" , значением кото- рого является отображение с четырьмя ключами: \"conferences\" (конференции), \"events\" (мероприятия), \"speakers\" (докладчики) и \"venues\" (места проведения). 3 Об этом наборе и правилах его использования можно прочитать на странице «DIY : OSCON schedule» ( http://bit.ly/1TxUXBP ). Оригинальный JSON-файл размером 744 КБ еще был доступен в сети на момент написания этой книги ( http://www.oreilly.com/pub/sc/osconfeed ). Его копию под на- званием osconfeed.json можно найти в каталоге oscon-schedule/data/ репозитория кода к этой книге (http://bit.ly/1TxUXBP ).\n--- Страница 616 ---\n616 Глава 19. Динамические атрибуты и свойства С каждым из четырех ключей ассоциирован список записей. В примере 19.1 в каждом списке всего одна запись, но в полном наборе данных каждый раздел со-держит списки с десятками и даже сотнями записей – за исключением раздела \"conferences\" , в котором запись только одна – та, что показана выше. В каждой записи имеется поле \"serial\" , уникально идентифицирующее запись в пределах списка. Первый написанный мной скрипт просто загружает весь набор данных OSCON, но избегает лишнего трафика, проверяя наличие локальной копии. Это разумно, потому что набор OSCON 2014 уже стал достоянием истории и больше не обнов-ляется. В примере 19.2 нет никакого метапрограммирования. Все сводится к выраже- нию json .load(fp) , но и этого достаточно, что начать исследование набора данных. Функция osconfeed .load используется в следующих примерах. Пример 19.2. osconfeed.py: загрузка файла osconfeed.json (doctest-скрипты приведены в примере 19.3) from urllib.request import urlopen import warningsimport osimport json URL = 'http://www.oreilly.com/pub/sc/osconfeed' JSON = 'data/osconfeed.json' def load(): if not os.path.exists(JSON): msg = 'downloading {} to {}'.format(URL, JSON) warnings.warn(msg) /g110 with urlopen(URL) as remote, open(JSON, 'wb') as local: /g111 local.write(remote.read()) with open(JSON) as fp: return json .load(fp) /g112 /g110 Напечатать предупреждение, если предстоит заново загрузить файл. /g111 В этом предложении with используются два контекстных менеджера (раз- решено, начиная с версий Python 2.7 и 3.1), чтобы прочитать удаленный файл и сохранить его. /g112 Функция json.load разбирает JSON-файл и возвращает объекты Python. В данном наборе встречаются типы dict , list , str и int. Имея этот код, мы можем проинспектировать любое поле данных. Пример 19.3. osconfeed.py: doctest-скрипты для кода из примера 19.2 >>> feed = load() /g110 >>> sorted(feed['Schedule'].keys()) /g111 ['conferences', 'events', 'speakers', 'venues']\n--- Страница 617 ---\n617 Применение динамических атрибутов для обработки данных >>> for key, value in sorted(feed['Schedule'].items()): print('{:3} {}'.format(len(value), key)) /g112 1 conferences484 events357 speakers53 venues >>> feed['Schedule']['speakers'][-1]['name'] /g113 'Carina C. Zona'>>> feed['Schedule']['speakers'][-1]['serial'] /g114 141590>>> feed['Schedule']['events'][40]['name']'There *Will* Be Bugs'>>> feed['Schedule']['events'][40]['speakers'] /g115 [3471, 5199] /g110 feed – словарь dict , содержащий вложенные словари и списки, в которых хранятся строковые и целые значения. /g111 Перечисляем все четыре коллекции внутри \"Schedule\" . /g112 Выводим количество записей в каждой коллекции /g113 Перебираем вложенные словари и списки, чтобы получить имя последнего докладчика. /g114 Получаем порядковый номер этого докладчика. /g115 Для каждого мероприятия имеется список 'speakers' , содержащий 0 или более порядковых номеров докладчиков. Исследование JSON-подобных данных с динамическими атрибутами Пример 19.2 достаточно прост, но синтаксис feed['Schedule']['events'][40] ['name'] слишком громоздкий. В JavaScript то же самое можно было бы записать в виде feed.Schedule.events[40].name . На Python нетрудно реализовать похожий на словарь класс, который ведет себя подобным образом, – в сети нет недостат-ка в примерах 4. Я реализовал свой собственный класс FrozenJSON , который проще большинства готовых, т. к. поддерживает только чтение; он предназначен исклю-чительно для исследования данных. Однако он рекурсивный и автоматически об-рабатывает вложенные отображения и списки. В примере 19.4 демонстрируется использование класса FrozenJSON , а в приме- ре 19.5 приведен его исходный код. Пример 19.4. Класс FrozenJSON из примера 19.5 позволяет читать атрибуты, например name , и вызывать методы, например .keys() и .items() >>> from osconfeed import load >>> raw_feed = load()>>> feed = FrozenJSON(raw_feed) /g110 >>> len(feed.Schedule.speakers) /g111 4 Часто упоминают класс AttrDict ( https://pypi.python.org/pypi/attrdict ); другой класс, позволяющий быстро создавать вложенные отображения, – addict ( https://pypi.python.org/pypi/addict ).\n--- Страница 618 ---\n618 Глава 19. Динамические атрибуты и свойства 357 >>> sorted(feed.Schedule.keys()) /g112 ['conferences', 'events', 'speakers', 'venues']>>> for key, value in sorted(feed.Schedule.items()): /g113 print('{:3} {}'.format(len(value), key)) 1 conferences484 events357 speakers53 venues>>> feed.Schedule.speakers[-1].name /g114 'Carina C. Zona'>>> talk = feed.Schedule.events[40]>>> type(talk) /g115 <class 'explore0.FrozenJSON'>>>> talk.name'There *Will* Be Bugs'>>> talk.speakers /g116 [3471, 5199]>>> talk.flavor /g117 Traceback (most recent call last): KeyError: 'flavor' /g110 Строим экземпляр FrozenJSON по словарю raw_feed , содержащему вложен- ные словари и списки. /g111 FrozenJSON допускает обход вложенных словарей с помощью нотации атри- бутов; здесь мы получаем длину списка докладчиков. /g112 Методы скрытых за объектом FrozenJSON словарей также доступны, напри- мер, метод .keys() возвращает имена коллекций. /g113 С помощью метода items() мы можем извлечь имена коллекций записей и их содержимое, чтобы показать длину каждого значения. /g114 Список, например feed.Schedule.speakers , остается списком, но те объекты внутри него, которые являются отображениями, преобразуются в тип Fro- zenJSON . /g115 Элемент 40 списка events был объектом типа JSON; теперь это экземпляр класса FrozenJSON . /g116 С каждым мероприятием связан список speakers , содержащий порядковые номера докладчиков. /g117 При попытке прочитать несуществующий атрибут возбуждается исключе- ние KeyError , а не AttributeError , как обычно. Краеугольным камнем класса FrozenJSON является метод __getattr__ , которым мы уже пользовались в примере класса Vector из раздела «V ector, попытка № 3: доступ к динамическим атрибутам» главы 10, чтобы обращаться к компонентам вектора по буквам – v.x, v.y, v.z и т. д. Напомним, что интерпретатор вызывает спе- циальный метод __getattr__ , только если обычный процесс поиска атрибута за- вершается неудачно (т. е. именованный атрибут не удается найти ни в экземпляре, ни в классе, ни в его суперклассах).\n--- Страница 619 ---\n619 Применение динамических атрибутов для обработки данных Последняя строка в примере 19.4 выявляет небольшой дефект реализации: в идеале хотелось бы, чтобы попытка чтения несуществующего атрибута приводи-ла к исключению AttributeError . Я даже реализовал такую обработку ошибок, но при этом метод __getattr__ стал вдвое длиннее, и это отвлекало внимание от той важной логики, которую я стремился продемонстрировать, поэтому из педагоги-ческих соображений я отказался от этой идеи. Как видно из примера 19.5, в классе FrozenJSON всего два метода ( __init__ и __getattr__ ) и атрибут экземпляра __data , поэтому попытка получить атрибут с любым другим именем приводит к вызову __getattr__ . Этот метод сначала смо- трит, есть ли в словаре self.__data атрибут (не ключ!) с таким именем; это позво- ляет экземплярам FrozenJSON обрабатывать методы самого класса dict , например items , делегируя работу методу self.__data.items() . Если в self.__data нет атри- бута с именем name , то __getattr__ использует name как ключ, читает из self.__dict элемент с таким ключом и передает его методу FrozenJSON.build . Это позволяет обходить вложенные структуры в JSON-данных, поскольку каждое вложенное отображение преобразуется в новый экземпляр FrozenJSON методом класса build . Пример 19.5. explore0.py: преобразование набора данных из формата JSON в объект FrozenJSON , содержащий вложенные объекты FrozenJSON , списки и значения примитивных типов from collections import abc class FrozenJSON: \"\"\"Допускающий только чтение фасад для навигации по JSON -подобному объекту с применением нотации атрибутов \"\"\" def __init__(self, mapping): self.__data = dict(mapping) /g110 def __getattr__(self, name): if hasattr(self.__data, name): /g111 return getattr(self.__data, name) /g112 else: return FrozenJSON.build(self.__data[name]) /g113 @classmethod def build(cls, obj): /g114 if isinstance(obj, abc.Mapping): /g115 return cls(obj) elif isinstance(obj, abc.MutableSequence): /g116 return [cls.build(item) for item in obj] else: /g117 return obj /g110 Строим объект dict по аргументу mapping . Тем самым мы решаем две зада- чи: проверяем, что получили словарь (или нечто, что можно преобразовать в словарь), и для безопасности делаем его копию.\n--- Страница 620 ---\n620 Глава 19. Динамические атрибуты и свойства /g111 Метод __getattr__ вызывается, только когда не существует атрибута с та- ким именем. /g112 Если имени name соответствует какой-то атрибут экземпляра __data , воз- вращаем его. Так обрабатываются вызовы методов словаря, например keys . /g113 В противном случае получаем элемент с ключом name из self.__data и воз- вращаем результат вызова для него метода FrozenJSON .build() .5 /g114 Это альтернативный конструктор, типичное применение декоратора @classmethod . /g115 Если obj – отображение, строим по нему объект FrozenJSON . /g116 Если это экземпляр MutableSequence , то он должен быть списком6, поэ- тому строим список, рекурсивно передавая каждый элемент obj методу .build() . /g117 Если это не dict и не list , возвращаем элемент без изменения. Отметим, что исходный набор данных не кэшируется и не трансформируется. При его обходе вложенные структуры данных всякий раз преобразуются заново в тип FrozenJSON . Но при таком размере набора это приемлемо, да и наш скрипт предназначен только для исследования и преобразования данных. Любой скрипт, который генерирует или эмулирует динамические атрибуты с именами, полученными из произвольного источника, должен помнить об одной проблеме: ключи, хранящиеся в исходных данных, могут не удовлетворять пра-вилам образования имен атрибутов. В следующем разделе мы займемся этой про-блемой. Проблема недопустимого имени атрибута У класса FrozenJSON есть ограничение: в нем не предусмотрена специальная обработка имен атрибутов, являющихся ключевыми словами Python. Например, построив объект вида: >>> grad = FrozenJSON({'name': 'Jim Bo', 'class': 1982}) мы не сможем прочитать атрибут grad .class , т. к. class – зарезервированное слово в Python: >>> grad.class File \"<stdin>\", line 1 grad.class ^SyntaxError: invalid syntax Конечно, можно сделать так: 5 Именно в этой строке может возникнуть исключение KeyError : в выражении self. __data[name] . Его следует обработать и подменить исключением AttributeError , посколь- ку такого исключения вызывающая программа ожидает от __getattr__ . Прилежному читателю предлагается написать этот код в качестве упражнения. 6 Источником данных является объект типа JSON, а он поддерживает только два типа коллекций: dict и list .\n--- Страница 621 ---\n621 Применение динамических атрибутов для обработки данных >>> getattr(grad, 'class') 1982 Но идея класса FrozenJSON заключалась в том, чтобы предоставить удобный до- ступ к данным, поэтому лучше проверять, является ли ключ отображения, пере-данного методу FrozenJSON.__init__ , зарезервированным словом, и, если да, то до- бавлять в конец символ _, чтобы атрибут можно было прочитать так: >>> grad.class_1982 Для этого достаточно заменить однострочный метод __init__ из примера 19.5 кодом, показанным ниже. Пример 19.6. explore1.py: добавление _ в имена атрибутов, являющиеся зарезервированными словами Python def __init__(self, mapping): self.__data = {} for key, value in mapping.items(): if keyword.iskeyword(key): /g110 key += '_' self.__data[key] = value /g110 Функция keyword .iskeyword( …) – именно то, что нам нужно; для ее исполь- зования необходимо импортировать модуль keyword . Похожая проблема может возникнуть, если ключ в JSON-данных не является допустимым идентификатором Python: >>> x = FrozenJSON({'2be':'or not'})>>> x.2be File \"<stdin>\", line 1 x.2be ^SyntaxError: invalid syntax Такие проблематичные ключи легко выявить в Python 3, где класс str предо- ставляет метод s.isidentifier() , который сообщает, является ли s допустимым идентификатором с точки зрения грамматики языка Python. Но преобразование ключа, не являющегося допустимым идентификатором, в допустимое имя атрибу-та – нетривиальная задача. Есть два простых решения: возбудить исключение или заменять недопустимые ключи синтетическими, например: attr_0 , attr_1 и т. д. Для простоты я проигнорирую этот случай. У делив внимание именам динамических атрибутов, обратимся к другой важной особенности класса FrozenJSON : логике метода класса build , который вызывается из __getattr__ для получения объектов разных типов в зависимости от значения обрабатываемого атрибута, так чтобы вложенные структуры преобразовывались в экземпляры FrozenJSON или списки экземпляров FrozenJSON .\n--- Страница 622 ---\n622 Глава 19. Динамические атрибуты и свойства Как мы увидим ниже, ту же логику можно было бы реализовать не в методе класса, а в специальном методе __new__ . Гибкое создание объектов с помощью метода __new__ Мы часто называем __init__ конструктором, но это только потому, что поза- имствовали терминологию из других языков. На самом деле, конструирует экзем-пляр специальный метод __new__ . Это метод класса (однако он обрабатывается особым образом, поэтому декоратор @classmethod не используется), и возвращать он должен экземпляр. Этот экземпляр затем передается в качестве первого ар-гумента self методу __init__ . Поскольку __init__ при вызове уже получает эк- земпляр, что-то возвращать ему запрещено, по существу, метод __init__ является «инициализатором». Настоящий конструктор – это метод __new__ , но мы о нем редко вспоминаем, потому что реализации, унаследованной от класса object , обычно достаточно. Описанный только что путь – от __new__ к __init__ – самый распространен- ный, но не единственный. Метод __new__ может возвращать и экземпляр другого класса; если такое происходит, то интерпретатор не вызывает __init__ . Иными словами, процесс построения объекта в Python можно описать следу- Python можно описать следу- можно описать следу- ющим псевдокодом: # псевдокод конструирования объектаdef object_maker(the_class, some_arg): new_object = the_class.__new__(some_arg) if isinstance(new_object, the_class): the_class.__init__(new_object, some_arg) return new_object # следующие предложения приблизительно эквивалентны x = Foo('bar')x = object_maker(Foo, 'bar') В примере 19.7 показан вариант класса FrozenJSON , в котором логика метода класса build перенесена в метод __new__ . Пример 19.7. explore2.py: использование __new__ вместо build для конструирования новых объектов, которые могут быть или не быть экземплярами FrozenJSON from collections import abc class FrozenJSON: \"\"\"Допускающий только чтение фасад для навигации по JSON -подобному объекту с применением нотации атрибутов \"\"\" def __new__(cls, arg): /g110\n--- Страница 623 ---\n623 Применение динамических атрибутов для обработки данных if isinstance(arg, abc.Mapping): return super().__new__(cls) /g111 elif isinstance(arg, abc.MutableSequence): /g112 return [cls(item) for item in arg] else: return arg def __init__(self, mapping): self.__data = {} for key, value in mapping.items(): if iskeyword(key): key += '_' self.__data[key] = value def __getattr__(self, name): if hasattr(self.__data, name): return getattr(self.__data, name) else: return FrozenJSON(self.__data[name]) /g113 /g110 Будучи методом класса, __new__ получает в качестве первого аргумента сам класс, а остальные аргументы – те же, что получает __init__ , за исключени- ем self . /g111 По умолчанию работа делегируется методу __new__ суперкласса. В данном случае мы вызываем метод __new__ из базового класса object , передавая ему FrozenJSON в качестве единственного аргумента. /g112 Оставшаяся часть __new__ ничем не отличается от прежнего метода build . /g113 Здесь раньше вызывался метод FrozenJSON.build , а теперь мы просто вы- зываем конструктор FrozenJSON . Метод __new__ получает в качестве первого аргумента класс, потому что обыч- но создается экземпляр именно этого класса. Таким образом, при вызове super(). __new__(cls) из FrozenJSON.__new__ в действительности вызывается object. __new__(FrozenJSON) , а объект, создаваемый классом object , является экземпля- ром класса FrozenJSON , т. е. атрибут __class__ нового экземпляра содержит ссылку на FrozenJSON , хотя собственно конструирование производилось методом object. __new__ , реализованным на C в недрах интерпретатора. В структуре набора данных OSCON имеется очевидный недостаток: для меро- OSCON имеется очевидный недостаток: для меро- имеется очевидный недостаток: для меро- приятия с индексом 40, озаглавленного 'There *Will* Be Bugs' , зарегистрирова- но два докладчика, 3471 и 5199 , но найти их нелегко, потому что это порядковые номера, а не индексы в списке Schedule.speakers . В поле venue , присутствующем в каждой записи event , также хранится порядковый номер, но для нахождения со- ответствующей записи о месте проведения придется выполнить линейный поиск по списку Schedule.venues . Наша следующая задача – изменить структуру данных и автоматизировать извлечение связанных записей.\n--- Страница 624 ---\n624 Глава 19. Динамические атрибуты и свойства Изменение структуры набора данных OSCON с помощью модуля shelve Забавное имя стандартного модуля shelve (полка) обретает смысл, если вспом- нить что формат сериализации объектов в Python, а также модуль, преобразую- Python, а также модуль, преобразую- , а также модуль, преобразую- щий объекты в этот формат и обратно, называется pickle (консервы). Ну а по- скольку банки с консервами хранятся на полках в кладовой, то не удивительно, что shelve предоставляет pickle средства хранения. Высокоуровневая функция shelve .open возвращает экземпляр shelve .Shelf – простое хранилище ключей и значений, поддерживаемое модулем dbm и обладаю- щее следующими характеристиками: • класс shelve .Shelf является подклассом abc.MutableMapping , поэтому пре- доставляет все методы, которых мы ожидаем от типа отображения; • кроме того, shelve.Shelf предоставляет несколько методов управления вводом-выводом, в частности sync и close , а также является контекстным менеджером; • ключи и значения сохраняются в тот момент, когда ключу присваивается новое значение; • ключи должны быть строками;• значения должны быть объектами, с которыми умеет работать модуль pickle . Подробности и подводные камни описаны в документации по модулям shelve (https://docs.python.org/3/library/shelve.html ), dbm (https://docs.python.org/3/library/ dbm.html ) и pickle (https://docs.python.org/3/library/pickle.html ). Нам важно, что shelve предлагает простой и эффективный способ реорганизовать набор дан- ных OSCON: мы прочитаем все записи из JSON-файла и сохраним их в объек-те shelve.Shelf . Ключ будет состоять из типа записи и порядкового номера (на- пример, 'event.33950' или 'speaker.3471' ), а значением станет экземпляр нового класса Record , который мы скоро напишем. В примере 19.8 показаны doctest-скрипты для скрипта schedule1.py с исполь- зованием модуля shelve . Для интерактивного запуска выполните команду python -i schedule1.py , которая загрузит модуль и выведет приглашение. Основная ра- бота возложена на функцию load_db : она вызывает метод osconfeed .load (из при- мера 19.2) для чтения JSON-данных и сохраняет каждую запись в виде экземпляра Record в объекте Shelf , который передан в аргументе db. После этого для получе- ния записи о докладчике достаточно написать speaker = db['speaker.3471'] . Пример 19.8. Тестирование скрипта schedule1.py (пример 19.9) >>> import shelve >>> db = shelve.open(DB_NAME) /g110 >>> if CONFERENCE not in db: /g111 load_db(db) /g112\n--- Страница 625 ---\n625 Применение динамических атрибутов для обработки данных >>> speaker = db['speaker.3471'] /g113 >>> type(speaker) /g114 <class 'schedule1.Record'>>>> speaker.name, speaker.twitter /g115 ('Anna Martelli Ravenscroft', 'annaraven')>>> db .close() /g116 /g110 shelve.open открывает файл базы данных, предварительно создав его, если он еще не существует. /g111 Чтобы быстро определить, заполнилась ли база данных, ищем известный ключ, в данном случае conference.115 – ключ единственной записи типа conference .7 /g112 Если база данных пуста, загружаем ее, вызывая load_db(db) . /g113 Получаем запись о докладчике speaker . /g114 Это экземпляр класса Record , определенного в примере 19.9. /g115 В каждом объекте Record имеется набор атрибутов, соответствующих по- лям хранящейся в нем JSON-записи. /g116 Не забываем закрывать shelve.Shelf . По возможности следует использо- вать блок with , гарантирующий закрытие Shelf .8 Код скрипта schedule1.py приведен в примере 19.9. Пример 19.9. schedule1.py: исследование данных о расписании мероприятий OSCON, сохраненных в объекте shelve.Shelf import warnings import osconfeed /g110 DB_NAME = 'data/schedule1_db' CONFERENCE = 'conference.115' class Record: def __init__(self, **kwargs): self.__dict__.update(kwargs) /g111 def load_db(db): raw_data = osconfeed.load() /g112 warnings.warn('loading ' + DB_NAME) for collection, rec_list in raw_data['Schedule'].items(): /g113 record_type = collection[:-1] /g114 for record in rec_list: key = '{}.{}'.format(record_type, record['serial']) /g115 record['serial'] = key /g116 db[key] = Record(**record) /g117 7 Можно было бы также вывести значение len(db) , но в случае большой базы данных оно вычисля- лось бы долго. 8 У системы doctest есть принципиальный недостаток – отсутствие механизма инициализации и га- рантированной очистки ресурсов. Большинство тестов для скрипта schedule1.py я написал с исполь- зованием системы py.test , они приведены в примере A.12.\n--- Страница 626 ---\n626 Глава 19. Динамические атрибуты и свойства /g110 Загружаем модель osconfeed.py из примера 19.2. /g111 Стандартный прием для построения объекта, атрибуты которого создаются из позиционных аргументов (подробное объяснение см. ниже). /g112 Этот метод может загрузить набор данных в формате JSON из сети, если отсутствует локальная копия. /g113 Обходим коллекции ( 'conferences' , 'events' и т. д.). /g114 В record_type записывается имя коллекции без последней буквы 's' (т. е. 'events' превращается в 'event' ). /g115 Строим ключ key из record_type и поля 'serial' . /g116 Заменяем поле 'serial' полным ключом. /g117 Строим экземпляр Record и сохраняем его в базе данных в качестве значе- ния ключа key. В методе Record.__init__ иллюстрируется распространенный при програм- мировании на Python прием. Напомню, что в словаре __dict__ объекта хранятся атрибуты – если только в классе не объявлен атрибут __slots__ (см. раздел «Эко- номия памяти с помощью атрибута класса __slots__» главы 9). Поэтому копиро-вание в __dict__ отображения – быстрый способ создать сразу несколько атрибу- тов экземпляра9. Я не стану повторять детали, которые уже обсуждались в раз- деле «Проблема недопустимого имени атрибута» выше, но ска-жу, что в зависимости от контекста приложения в классе Record , возможно, придется иметь дело с ключами, которые не являются допустимыми именами атрибутов. Определение класса Record в примере 19.9 настолько простое, что вы, навер- ное, недоумеваете, почему мы не использовали его раньше вместо более сложного класса FrozenJSON . Причины две. Во-первых, FrozenJSON рекурсивно преобразует вложенные отображения и списки; в классе Record это не нужно, потому что в пре- образованном наборе данных нет отображений, вложенных в другие отображения или списки. Записи могут содержать только строки, целые числа, списки строк и списки целых чисел. Вторая причина заключается в том, что FrozenJSON предостав- ляет доступ к внутреннему словарю атрибутов __data – который мы использовали для вызова методов, например keys , – а здесь эта функциональность не нужна. В стандартной библиотеке Python есть по меньшей мере два класса, аналогичных нашему классу Record , экземпляры которых содержат произвольный набор атрибутов, переданных конструк-тору в виде позиционных аргументов: multiprocessing.Namespace 9 Кстати, Bunch – имя класса, который Алекс Мартелли в 2001 году использовал при публикации этого рецепта, названного им «The simple but handy collector of a bunch of named stuff class» (Простой и удобный способ создания класса, содержащего именованные поля) ( http://bit.ly/1cPM8T3 ).\n--- Страница 627 ---\n627 Применение динамических атрибутов для обработки данных (документация находится по адресу http://bit.ly/1cPLZzd , а исход- ный код – по адресу http://bit.ly/1cPM2uJ ) и argparse.Namespace (документация – по адресу http://bit.ly/1cPM1qG , исходный код – по адресу http://bit.ly/1cPM4Ti ). Я написал класс Record , чтобы проиллюстрировать существо этой идеи: обновление атрибута __dict__ экземпляра в методе __init__ . После проделанной реорганизации набора данных мы можем расширить класс Record , включив в него полезную функциональность: автоматическая выборка за- писей venue и speaker , на которые ссылается запись event . Примерно то же самое делает Django ORM, когда мы обращаемся к полю models.ForeignKey : вместо клю- ча мы получаем связанный объект модели. Для реализации этой идеи мы восполь-зуемся свойствами. Выборка связанных записей с помощью свойств Цель следующего примера такова: пусть имеется запись event , взятая с «пол- ки», тогда чтение ее атрибута venue или speakers должно возвращать не порядко- вые номера, а объекты, представляющие соответствующие записи. Как это должно выглядеть, показано в следующем интерактивном примере. Пример 19.10. Фрагмент doctest-скриптов для файла schedule2.py >>> DbRecord.set_db(db) /g110 >>> event = DbRecord.fetch('event.33950') /g111 >>> event /g112 <Event 'There *Will* Be Bugs'>>>> event.venue /g113 <DbRecord serial='venue.1449'>>>> event.venue.name /g114 'Portland 251'>>> for spkr in event.speakers: /g115 print('{0.serial}: {0.name}'.format(spkr)) speaker.3471: Anna Martelli Ravenscroftspeaker.5199: Alex Martelli /g110 Класс DbRecord расширяет Record , добавляя поддержку базы данных; его конструктору необходимо передать ссылку на базу. /g111 Метод класса DbRecord.get выбирает записи любого типа. /g112 Отметим, что event – экземпляр класса Event , расширяющего DbRecord . /g113 Доступ к атрибуту event .venue возвращает экземпляр DbRecord . /g114 Теперь легко найти название места проведения event.venue . Такое автома- тическое разыменование и является целью данного примера. /g115 Мы также можем обойти список event.speakers , извлекая объекты DbRecord , представляющие каждого докладчика.\n--- Страница 628 ---\n628 Глава 19. Динамические атрибуты и свойства На рис. 19.1 изображены классы, которые мы будем изучать в этом разделе. Рис. 19.1. UML-диаграмма класса Record и двух его подклассов: DbRecord и Event Record Метод __init__ такой же, как в файле schedule1.py (пример 19.9); метод __eq__ добавлен, чтобы упростить тестирование. DbRecord Подкласс Record , в который добавлены атрибут класса __db , статические методы set_db и get_db для установки и чтения этого атрибута, метод клас- са fetch для выборки записей из базы данных и метод экземпляра __repr__ для отладки и тестирования. Event Подкласс DbRecord , в который добавлены свойства venue и speakers для выборки связанных записей, а также специализированный метод __repr__ . В атрибуте класса DbRecord.__db хранится ссылка на открытую базу данных shelve.Shelf , чтобы к ней можно было обратиться из метода DbRecord.fetch и из свойств Event.venue и Event.speakers . Я сделал __db закрытым атрибутом класса с обычными методами чтения и установки, потому что хотел защитить его от слу-чайного перезаписывания. Я не стал использовать свойства для управления атри-бутом __db из-за принципиального соображения: свойства – это атрибуты класса, предназначенные для управления атрибутами экземпляра10. Приведенный в этом разделе код находится в модуле schedule2.py в репозито- рии кода к этой книге ( https://github.com/fluentpython/example-code ). Поскольку в модуле больше 100 строк, я буду описывать его по частям11. В примере 19.11 показано начало скрипта schedule2.py . Пример 19.11. schedule2.py: предложения импорта, константы и дополненный класс Record import warnings 10 На сайте StackOverflow в вопросе под названием «Class-level read only properties in Python» ( http:// bit.ly/1cPMnNZ ) приведено несколько решений проблемы доступных только для чтения атрибутов класса, в том числе предложенное Алексом Мартелли. Во всех них используются метаклассы, по-этому предварительно рекомендуется прочитать главу 21. 11 Полный текст файла schedule2.py имеется в примере A.13 вместе со скриптами py.test .\n--- Страница 629 ---\n629 Применение динамических атрибутов для обработки данных import inspect /g110 import osconfeedDB_NAME = 'data/schedule2_db' /g111 CONFERENCE = 'conference.115' class Record: def __init__(self, **kwargs): self.__dict__.update(kwargs) def __eq__(self, other): /g112 if isinstance(other, Record): return self.__dict__ == other.__dict__ else: return NotImplemented /g110 Модуль inspect понадобится в функции load_db (пример 19.14). /g111 Поскольку мы храним объекты других классов, то создадим и будем ис- пользовать другой файл базы данных, 'schedule2_db' вместо 'schedule_db' из примера 19.9. /g112 Метод __eq__ всегда полезно иметь для тестирования. В Python 2 свойства поддерживаются только классами в «новом стиле». Чтобы написать такой класс в Python 2, необходимо прямо или косвенно унаследовать классу object . Класс Record из при- мера 19.11 является базовым классом иерархии, в которой при-меняются свойства, поэтому в Python 2 его объявление должно начинаться предложением 12: class Record(object):# и т . д. Ниже показан класс специального исключения и класс DbRecord из скрипта schedule2.py . Пример 19.12. schedule2.py: классы MissingDatabaseError и DbRecord class MissingDatabaseError(RuntimeError): \"\"\"Возбуждается, когда база данных необходима, но не была задана.\"\"\" /g110 class DbRecord(Record): /g111 __db = None /g112 @staticmethod /g113 12 Явное наследование классу object в Python 3 допустимо, но излишне, потому что теперь классов «в старом стиле» просто нет. Это лишь один из примеров того, как, порвав с прошлым, язык стал чище. Если требуется, чтобы один и тот же код работал и в Python 2, и в Python 3, то наследовать object необходимо явно.\n--- Страница 630 ---\n630 Глава 19. Динамические атрибуты и свойства def set_db(db): DbRecord.__db = db /g114 @staticmethod /g115 def get_db(): return DbRecord.__db @classmethod /g116 def fetch(cls, ident): db = cls.get_db() try: return db[ident] /g117 except TypeError: if db is None: /g118 msg = \"database not set; call '{}.set_db(my_db)'\" raise MissingDatabaseError(msg.format(cls.__name__)) else: /g119 raise def __repr__(self): if hasattr(self, 'serial'): ⤓ cls_name = self.__class__.__name__ return '<{} serial={!r}>'.format(cls_name, self.serial) else: return super().__repr__() ⤔ /g110 Специальные исключения – обычно просто маркерные классы, не имею- щие тела. Строка документации с объяснением порядка использования ис-ключения лучше, чем одно лишь предложение pass . /g111 Класс DbRecord расширяет Record . /g112 В атрибуте класса _db хранится ссылка на открытую базу данных shelve. Shelf . /g113 Метод set_db снабжен декоратором staticmethod , чтобы явно показать, что его результат не зависит от способа вызова. /g114 Даже если этот метод вызывается как Event.set_db(my_db) , атрибут _db бу- дет установлен в классе DbRecord . /g115 Метод get_db также снабжен декоратором staticmethod , потому что он всег- да возвращает объект, на который ссылается DbRecord._db , вне зависимости от того, как вызван. /g116 fetch – метод класса, чтобы его поведение было проще изменить в подклас- сах. /g117 Здесь из базы данных выбирается запись с ключом ident . /g118 Если мы получили исключение TypeError и db равно None , возбуждаем спе- циальное исключение, означающее, что необходимо задать базу данных. /g119 В противном случае повторно возбуждаем исключение, потому что не зна- ем, как его обрабатывать. ⤓ Если в записи есть атрибут serial , включаем его в строковое представление. ⤔ В противном случае по умолчанию используем унаследованный метод __repr__ .\n--- Страница 631 ---\n631 Применение динамических атрибутов для обработки данных Вот мы и добрались до самого главного в этом примере: класса Event . Пример 19.13. schedule2.py: класс Event class Event(DbRecord): /g110 @property def venue(self): key = 'venue.{}'.format(self.venue_serial) return self.__class__.fetch(key) /g111 @property def speakers(self): if not hasattr(self, '_speaker_objs'): /g112 spkr_serials = self.__dict__['speakers'] /g113 fetch = self.__class__.fetch /g114 self._speaker_objs = [fetch('speaker.{}'.format(key)) for key in spkr_serials] /g115 return self._speaker_objs /g116 def __repr__(self): if hasattr(self, 'name'): /g117 cls_name = self.__class__.__name__ return '<{} {!r}>'.format(cls_name, self.name) else: return super().__repr__() /g118 /g110 Класс Event расширяет DbRecord . /g111 Свойство venue строит ключ key по атрибуту venue_serial и передает его методу класса fetch , унаследованному от DbRecord (см. пояснение ниже). /g112 Свойство speakers проверяет, есть ли в записи атрибут _speaker_objs . /g113 Если нет, то атрибут 'speakers' берется непосредственно из атрибута эк- земпляра __dict__ во избежание бесконечной рекурсии, поскольку откры- тое имя этого свойства – тоже speakers . /g114 Получаем ссылку на метод класса fetch (зачем, будет объяснено ниже). /g115 В self._speaker_objs методом fetch загружаем список записей speaker . /g116 Возвращаем этот список. /g117 Если в записи есть атрибут name , включаем его в строковое представление. /g118 В противном случае по умолчанию используем унаследованный метод __repr__ . В свойстве venue из примера 19.13 последняя строка возвращает self. __class__.fetch(key) . Почему бы не написать просто self.fetch(key) ? Это более простое выражение работает для набора данных OSCON, потому что в нем нет за-писи о мероприятии с ключом 'fetch' . Но если бы такая запись существовала, то в соответствующем экземпляре Event выражение self.fetch было бы значением этого поля, а не ссылкой на метод класса fetch , унаследованный классом Event от DbRecord . Это тонкая ошибка, которая легко могла бы остаться незамеченной при тестировании и проявиться только в производственной системе при выборе запи-сей venue или speaker , связанных с такой записью Event .\n--- Страница 632 ---\n632 Глава 19. Динамические атрибуты и свойства При создании имен атрибутов экземпляра из данных всегда существует риск ошибок вследствие маскирования атрибутов класса (например, ме-тодов) или потери данных из-за случайного перезаписывания уже суще-ствующих атрибутов экземпляра. Эта опасность является, пожалуй, ос-новной причиной, по которой словари в Python по умолчанию не похожи на объекты JavaScript. Если бы класс Record больше походил бы на отображение, т. е. реализовывал динамический метод __getitem__ , а не __gettarr__ , то можно было бы не опасаться ошибок, вызванных маскированием или перезаписью. Специальное отображение, наверное, является наиболее отвечающим духу Python способом реализации Re- cord . Но если бы я пошел по этому пути, то у нас не было бы шанса поразмышлять о ловушках, подстерегающих нас при программировании динамических атрибутов. И последняя часть примера – переделанная функция load_db . Пример 19.14. schedule2.py: функция load_db def load_db(db): raw_data = osconfeed.load() warnings.warn('loading ' + DB_NAME) for collection, rec_list in raw_data['Schedule'].items(): record_type = collection[:-1] /g110 cls_name = record_type.capitalize() /g111 cls = globals().get(cls_name, DbRecord) /g112 if inspect.isclass(cls) and issubclass(cls, DbRecord): /g113 factory = cls /g114 else: factory = DbRecord /g115 for record in rec_list: /g116 key = '{}.{}'.format(record_type, record['serial']) record['serial'] = key db[key] = factory(**record) /g117 /g110 До сих пор нет отличий от функции load_db из файла schedule1.py (при- мер 19.9). /g111 Преобразуем первую букву record_type в верхний регистр, чтобы получить потенциальное имя класса (например, 'event' превращается в 'Event' ). /g112 Получаем объект с таким именем из глобальной области видимости моду- ля; если такого объекта нет, получаем DbRecord . /g113 Если только что полученный объект – класс, который является подклассом DbRecord … /g114 … связываем с ним имя factory . Это означает, что factory может быть про- извольным подклассом DbRecord , определяемым переменной record_type . /g115 В противном случае связываем имя factory с DbRecord . /g116 Цикл for, в котором создаются ключи и сохраняются записи, такой же, как и раньше, с тем исключением, что…\n--- Страница 633 ---\n633 Использование свойств для контроля атрибутов /g117 … объект, сохраняемый в базе данных, конструируется функцией factory , которая может быть конструктором класса DbRecord или его подкласса – в зависимости от значения record_type . Отметим, что единственное значение record_type , для которого существует специальный класс, – это Event , но если бы мы написали классы с именами Speaker или Venue , то load_db автоматически использовала бы при построении и сохране- нии записей их, а не подразумеваемый по умолчанию класс DbRecord . Примеры, которые мы видели в этой главе до сих пор, предназначались для демонстрации различных способов реализации динамических атрибутов с помощью таких базовых средств, как __getattr__ , hasattr , getattr , @property и __dict__ . Свойства часто применяются для реализации обязательных бизнес-правил. С этой целью открытый атрибут заменяется атрибутом, управляемым методами чтения и установки, без изменения клиентского кода, как показано в следующем разделе. Использование свойств для контроля атрибутов До сих пор мы видели лишь декоратор @property , используемый для реализации свойств, допускающих только чтение. В этом разделе мы создадим свойство, до-пускающее чтение и запись. LineItem, попытка № 1: класс строки заказа Представим себе приложение для магазина, который продает натуральные пи- щевые продукты вразвес, т. е. клиенты могут заказывать орехи, сухофрукты или хлопья по весу. В такой системе заказ состоит из последовательности строк, а каж-дую строку можно представить классом, показанным в примере 19.15. Пример 19.15. bulkfood_v1.py: простейший класс LineItem class LineItem: def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price Красиво и просто. Пожалуй, слишком просто. В примере 19.16 показано, в чем проблема.\n--- Страница 634 ---\n634 Глава 19. Динамические атрибуты и свойства Пример 19.16. Если вес отрицателен, то и промежуточный итог отрицателен >>> raisins = LineItem('Golden raisins', 10, 6.95) >>> raisins.subtotal()69.5>>> raisins .weight = -20 # мусор на входе >>> raisins .subtotal() # мусор на выходе -139.0 Пример, конечно, игрушечный, но не такой надуманный, как можно было бы предположить. Вот правдивая история, случившаяся, когда сайт Amazon.com только зарождался: Мы обнаружили, что покупатель мог заказать отрицательное ко- личество книг! И мы бы перечислили на его кредитную карту соот-ветствующую сумму и, надо полагать, ждали бы, когда он отгрузит книги 13. – Джефф Безос, основатель и генеральный директор Amazon.com Как это исправить? Можно было бы изменить интерфейс класса LineItem , до- бавив методы чтения и установки атрибута weight . Так поступают в Java, и ничего плохого в этом нет. С другой стороны, было бы естественно устанавливать атрибут weight элемен- та заказа, просто присваивая ему значение, да и не исключено, что в других частях эксплуатируемой системы уже встречается прямой доступ к атрибуту вида item. weight . В таком случае следовало бы заменить атрибут-данные свойством – это было бы в духе Python. LineItem, попытка № 2: контролирующее свойство Реализовав свойство, мы сможем использовать методы чтения и установки, но интерфейс класса LineItem при этом не изменится (т. е. для установки атрибута weight объекта LineItem по-прежнему нужно будет написать raisins.weight = 12 ). В примере 19.17 приведен код свойства weight , допускающего чтение и запись. Пример 19.17. bulkfood_v2.py: класс LineItem со свойством weight class LineItem: def __init__(self, description, weight, price): self.description = description self.weight = weight /g110 self.price = price def subtotal(self): 13 Цитата из статьи «Рождение продавца» Джеффа Безоса в журнале «У олл-стрит джорнал» ( http:// on.wsj.com/1ECl8Dl ) (15 октября 2011).\n--- Страница 635 ---\n635 Использование свойств для контроля атрибутов return self.weight * self.price @property /g111 def weight(self): /g112 return self.__weight /g113 @weight.setter /g114 def weight(self, value): if value > 0: self.__weight = value /g115 else: raise ValueError('value must be > 0') /g116 /g110 Здесь уже используется метод установки свойства, который гарантирует, что не может быть создан экземпляр с отрицательным значением weight . /g111 Декоратором @property обозначается метод чтения свойства. /g112 Имена всех методов, реализующих свойство, совпадают с именем открыто- го атрибута: weight . /g113 Фактическое значение хранится в закрытом атрибуте __weight . /g114 У декорированного метода чтения свойства имеется атрибут .setter , кото- рый является также и декоратором; тем самым методы чтения и установки связываются между собой. /g115 Если значение больше нуля, присваиваем его закрытому атрибуту __weight . /g116 В противном случае возбуждаем исключение ValueError . Теперь объект LineItem с недопустимым весом создать невозможно: >>> walnuts = LineItem('walnuts', 0, 10.00) Traceback (most recent call last): ValueError: value must be > 0 Итак, мы защитили атрибут weight от присваивания отрицательных значений пользователем. Но хотя покупатели обычно не вправе устанавливать цену товара, в результате ошибки служащего или программы все же может быть создан объект LineItem с отрицательной ценой price . Чтобы предотвратить и это, мы могли бы преобразовать price в свойство, но это повлекло бы за собой частичное повторе- ние кода. Напомним слова Пола Грэхема, приведенные в главе 14: «Видя в своих про- граммах повторяющиеся структуры, я расцениваю их как знак беды». Лекарство от повторения – абстрагирование. Существует два способа абстрагировать опре-деления свойств: фабрика свойств и дескрипторный класс. Подход на основе дескрипторного класса обладает большей гибкостью, мы посвятим ему всю гла-ву 20. На самом деле, сами свойства реализованы как дескрипторные классы. А пока продолжим наше исследование и реализуем фабрику свойств в виде функ-ции. Но прежде необходимо лучше понять природу свойств.\n--- Страница 636 ---\n636 Глава 19. Динамические атрибуты и свойства Правильный взгляд на свойства Встроенная сущность property часто используется как декоратор, но в действи- тельности она является классом. В Python функции и классы нередко взаимозаме-няемы, поскольку являются вызываемыми объектами и не существует оператора new для создания объекта, поэтому вызов конструктора ничем не отличается от вызова фабричной функции. Как функцию, так и класс можно использовать в ка-честве декоратора при условии, что они возвращают новый вызываемый объект, являющийся подходящей заменой декорированной функции. Вот полная сигнатура конструктора класса property : property(fget=None, fset=None, fdel=None, doc=None) Все аргументы необязательны; если для какого-то из них не указана функция, то результирующий объект свойства не поддерживает соответствующую опера-цию. Тип property появился в версии Python 2.2, но синтаксис декоратора был до- бавлен только в версии Python 2.4, т. е. на протяжении нескольких лет свойства нужно было определять, передавая функции-акцессоры в первых двух аргумен-тах. «Классический» синтаксис определения свойств без декораторов показан в примере 19.18. Пример 19.18. bulkfood_v2b.py: то же, что пример 19.17, но без декораторов class LineItem: def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price def get_weight(self): /g110 return self.__weight def set_weight(self, value): /g111 if value > 0: self.__weight = value else: raise ValueError('value must be > 0') weight = property(get_weight, set_weight) /g112 /g110 Простой метод чтения. /g111 Простой метод установки. /g112 Строим свойство и присваиваем его открытому атрибуту класса.\n--- Страница 637 ---\n637 Правильный взгляд на свойства В некоторых случаях классическая форма удобнее синтаксиса декораторов, одним из примеров является код фабрики свойств, который мы вскоре обсудим. С другой стороны, в теле класса, где много методов, декораторы позволяют сразу опознать методы чтения и установки, не полагаясь на соглашение о префиксах get и set в именах. Наличие свойств в классе влияет на то, как можно искать атрибуты в экзем- плярах такого класса, и, на первый взгляд, это удивительно. Объясним, в чем здесь дело. Свойства переопределяют атрибуты экземпляра Свойства всегда являются атрибутами класса, но на самом деле они управляют доступом к атрибутам в экземплярах этого класса. В разделе «Переопределение атрибутов класса» главы 9 мы видели, что если экземпляр и его класс оба имеют атрибут-данные с одним и тем же именем, то атрибут экземпляра переопределяет, или маскирует атрибут класса – по крайней мере, когда мы обращаемся к атрибуту от имени этого экземпляра. Проблема де-монстрируется в примере 19.19. Пример 19.19. Атрибут экземпляра маскирует атрибут-данные класса >>> class Class: # /g110 data = 'the class data attr' @property def prop(self): return 'the prop value' >>> obj = Class()>>> vars(obj) # /g111 {}>>> obj.data # /g112 'the class data attr'>>> obj.data = 'bar' # /g113 >>> vars(obj) # /g114 {'data': 'bar'} >>> obj.data # /g115 'bar'>>> Class.data # /g116 'the class data attr' /g110 Определяем Class с двумя атрибутами класса: атрибутом-данными data и свойством prop . /g111 vars возвращает атрибут __dict__ объекта obj; как видим, атрибутов экзем- пляра в нем нет. /g112 Чтение из obj.data возвращает значение Class.data . /g113 Запись в obj.data создает атрибут экземпляра. /g114 Инспектируем экземпляр, чтобы узнать, какие у него атрибуты.\n--- Страница 638 ---\n638 Глава 19. Динамические атрибуты и свойства /g115 Теперь, читая obj.data , мы получаем значение атрибута экземпляра. Чте- ние экземпляра obj маскирует атрибут класса data . /g116 Атрибут Class.data не изменился. Попробуем теперь переопределить атрибут prop экземпляра obj. В приме- ре 19.20 показано продолжение предыдущего сеанса. Пример 19.20. Атрибут экземпляра не маскирует свойство класса (продолжение примера 19.19) >>> Class.prop # /g110 <property object at 0x1072b7408>>>> obj.prop # /g111 'the prop value'>>> obj.prop = 'foo' # /g112 Traceback (most recent call last): AttributeError: can't set attribute>>> obj.__dict__['prop'] = 'foo' # /g113 >>> vars(obj) # /g114 {'prop': 'foo', 'attr': 'bar'} >>> obj.prop # /g115 'the prop value'>>> Class.prop = 'baz' # /g116 >>> obj .prop # /g117 'foo' /g110 Чтение prop непосредственно из Class возвращает сам объект свойства, при этом его метод чтения не выполняется. /g111 Чтение obj.prop приводит к выполнению метода чтения. /g112 Попытка установить атрибут экземпляра prop завершается ошибкой. /g113 Запись 'prop' напрямую в obj.__dict__ работает. /g114 Как видим, теперь у obj есть два атрибута экземпляра: attr и prop . /g115 Однако при чтении obj.prop по-прежнему выполняется метод чтения свойства. Свойство не маскируется атрибутом экземпляра. /g116 В случае перезаписывания Class.prop объект свойства уничтожается. /g117 Теперь чтение obj.prop возвращает атрибут экземпляра. Class.prop больше не является свойством, поэтому и не переопределяет obj.prop . В качестве заключительной демонстрации добавим новое свойство в Class и убедимся, что оно переопределяет атрибут экземпляра. Пример 19.21 продолжает предыдущий. Пример 19.21. Новое свойство класса маскирует существующий атрибут экземпляра (продолжение примера 19.20) >>> obj.data # /g110 'bar'>>> Class.data # /g111\n--- Страница 639 ---\n639 Правильный взгляд на свойства 'the class data attr' >>> Class.data = property(lambda self: 'the \"data\" prop value') # /g112 >>> obj.data # /g113 'the \"data\" prop value'>>> del Class.data # /g114 >>> obj.data # /g115 'bar' /g110 obj.data возвращает атрибут экземпляра data . /g111 Class.data возвращает атрибут класса data . /g112 Перезаписываем Class.data новым свойством. /g113 Теперь Class.data маскирует obj.data . /g114 У даляем свойство. /g115 Теперь obj.data снова возвращает атрибут экземпляра data . В этом разделе мы, прежде всего, хотели показать, что при вычислении выра- жения вида obj.attr поиск attr начинается не с obj. На самом деле, поиск начина- ется с obj.__class__ и, только если в классе не существует свойства с именем attr , то Python заглядывает в сам объект obj. Это правило применимо не только к свой- ствам, но и к целой категории дескрипторов: переопределяющим дескрипторам . Мы отложим дальнейшее рассмотрение дескрипторов до главы 20, где увидим, что свойства действительно являются переопределяющими дескрипторами. А пока вернемся к свойствам. В любой единице кода Python – модулях, функ- циях, классах, методах – может присутствовать строка документации. В следую-щем разделе мы увидим, как строка документации присоединяется к свойствам. Документирование свойств Когда функции оболочки help() или интегрированной среде разработки нужно вывести документации по свойству, она получает информацию из атрибута свой-ства __doc__ . В случае классического синтаксиса конструктор класса property может полу- чить строку документации в виде аргумента doc: weight = property(get_weight, set_weight, doc='weight in kilograms') Если же свойство объявлено с помощью декоратора, то строка документации метода чтения – того, который снабжен декоратором @property , – становится до- кументацией свойства в целом. На рис. 19.2 показано, как выглядят строки доку-ментации для кода из примера 19.22. Пример 19.22. Документирование свойства class Foo: @property def bar(self): '''The bar attribute'''\n--- Страница 640 ---\n640 Глава 19. Динамические атрибуты и свойства return self.__dict__['bar'] @bar.setter def bar(self, value): self.__dict__['bar'] = value Разобравшись с основами, вернемся к вопросу о том, как защитить атрибуты weight и price экземпляра LineItem , чтобы им можно было присвоить только положительные значения, – но при этом не писать вручную две почти одинаковые пары методов чтения и установки. Рис. 19.2. Как выглядит оболочка Python после выполнения команд help(Foo.bar) и help(Foo). Исходный код см. в примере 19.22 Программирование фабрики свойств Мы создадим фабрику свойств quantity – такое название выбрано, потому что управляемые атрибуты представляют собой количественные величины, которые в приложении должны быть положительны. В примере 19.23 показано, как вы-глядит класс LineItem с двумя свойствами, порожденными фабрикой quantity : для управления атрибутами weight и price . Пример 19.23. bulkfood_v2prop.py: фабрика свойств quantity в действии class LineItem: weight = quantity('weight') /g110 price = quantity('price') /g111 def __init__(self, description, weight, price): self.description = description self.weight = weight /g112 self.price = price def subtotal(self): return self.weight * self.price /g113\n--- Страница 641 ---\n641 Программирование фабрики свойств /g110 Используем фабрику для определения первого свойства, weight , в виде атрибута класса. /g111 Здесь создается второе свойство, price . /g112 Здесь свойство уже работает, и поэтому попытка присвоить weight нулевое или отрицательное значение отвергается. /g113 Здесь свойства также работают: с их помощью производится доступ к значениям, хранящимся в экземпляре. Напомним, что свойства – атрибуты класса. При создании каждого свойства с помощью quantity мы должны передать имя атрибута LineItem , который будет управляться этим свойством. Необходимость дважды писать слово weight в сле- дующей строке удручает: weight = quantity('weight') Но избежать такого повторения трудно, потому что свойство понятия не имеет, с каким атрибутом оно связывается. Помните: сначала вычисляется правая часть присваивания, поэтому в момент вызова функции quantity() атрибут класса price еще даже не существует. Улучшить свойство quantity , так чтобы пользователю не прихо- дилось дважды набирать имя атрибута, – нетривиальная задача метапрограммирования. В главе 20 мы познакомимся с обход- ным решением, а настоящее решение будет приведено только в главе 21, потому что в нем требуется использовать либо декора- тор класса, либо метакласс. В примере 19.24 показана реализация фабрики свойств quantity14. Пример 19.24. bulkfood_v2prop.py: фабрика свойств quantity def quantity(storage_name): /g110 def qty_getter(instance): /g111 return instance.__dict__[storage_name] /g112 def qty_setter(instance, value): /g113 if value > 0: instance.__dict__[storage_name] = value /g114 else: raise ValueError('value must be > 0') return property(qty_getter, qty_setter) /g115 14 Идея кода заимствована из рецепта 9.21 «Как избежать повторения методов свойств» в книге David Beazley, Brian K. Jones «Python Cookbook», издание 3 (O'Reilly).\n--- Страница 642 ---\n642 Глава 19. Динамические атрибуты и свойства /g110 Аргумент storage_name определяет, где хранятся данные свойства; в случае свойства weight данные будут храниться в атрибуте с именем 'weight' . /g111 Называть первый аргумент метода qty_getter именем self было бы не со- всем правильно, т. к. это не тело класса; instance ссылается на экземпляр LineItem , в котором будет храниться атрибут. /g112 Метод qty_getter ссылается на storage_name , поэтому будет сохранен в за- мыкании этой функции; значение берется непосредственно из instance. __dict__ , чтобы обойти свойство и избежать бесконечной рекурсии. /g113 В определении метода qty_setter первым аргументом также является in- stance . /g114 Значение сохраняется непосредственно в instance.__dict__ , снова в обход свойства. /g115 Конструируем и возвращаем объект свойства. Особого внимания заслуживают части этого кода, связанные с использовани- ем переменной storage_name . Когда мы реализуем свойство традиционным спосо- бом, имя атрибута, в котором хранится значение, зашито в код методов чтения и установки. Здесь же функции qty_getter и qty_setter обобщенные, им необходи- ма переменная storage_name , чтобы знать, из какого места атрибута __dict__ эк- земпляра читать и в какое место записывать значение управляемого свойством атрибута. При каждом вызове фабрики quantity для порождения нового свойства переменная storage_name должна принимать уникальное значение. Функции qty_getter и qty_setter обертываются объектом property в послед- ней строке фабричной функции. Когда впоследствии любая из этих функций будет вызвана для выполнения своих обязанностей, она прочитает storage_name из своего замыкания и определит, откуда читать или куда записывать значение управляемого атрибута. В примере 19.25, где я создаю и инспектирую экземпляр LineItem , видны атри- буты, в которых хранятся значения свойств. Пример 19.25. bulkfood_v2prop.py: фабрика свойств quantity >>> nutmeg = LineItem('Moluccan nutmeg', 8, 13.95) >>> nutmeg.weight, nutmeg.price /g110 (8, 13.95)>>> sorted(vars(nutmeg).items()) /g111 [('description', 'Moluccan nutmeg'), ('price', 13.95), ('weight', 8)] /g110 Чтение weight и price с помощью свойств маскирует одноименные атрибу- ты экземпляра. /g111 Используем метод vars , чтобы проинспектировать экземпляр nutmeg : вид- но, в каких точно атрибутах экземпляра хранятся значения. Обратите внимание, как в свойствах, построенных нашей фабрикой, использу- ется поведение, описанное в разделе «Свойства переопределяют атрибуты экзем-пляра» выше: свойство weight переопределяет атрибут экземпляра weight , поэто-\n--- Страница 643 ---\n643 Удаление атрибутов му любое обращение к self.weight или nutmeg.weight обрабатывается методами доступа свойства, и обойти их можно, только работая с атрибутом __dict__ на- прямую. Возможно, код в примере 19.25 понятен не с первого раза, но он короткий: в нем столько же строк, сколько в паре декорированных методов чтения и установки од-ного лишь свойства weight в примере 19.17. Определение LineItem в примере 19.23 выглядит намного лучше без шума, вносимого методами чтения и установки. В реальной системе такого рода проверкам могут подвергаться многие поля в нескольких классах, поэтому фабрику quantity следовало бы вынести в служеб- ный модуль. В конечном итоге, эту простую фабрику можно было бы заменить допускающим расширение дескрипторным классом, специализированные под-классы которого выполняют различные проверки. Мы займемся этим в главе 20. А пока завершим обсуждение свойств, рассмотрев вопрос об удалении атрибу- тов. Удаление атрибутов Напомним, что в учебном пособии по Python описано предложение del для удале- ния атрибутов объекта: del my_object .an_attribute У даление атрибутов вряд ли можно назвать повседневно выполняемой опера- цией, а требование обеспечить ее выполнение с помощью свойств еще более не- выполнение с помощью свойств еще более не- е с помощью свойств еще более не- обычно. Но оно поддерживается, и я приведу для его демонстрации несколько ис-кусственный пример. В определении свойства декоратор @my_propety.deleter используется, что- бы обернуть метод, отвечающий за удаление атрибута, управляемого свойством. В примере 19.26, как и обещано, демонстрируется, как писать метод удаления свойства. Пример 19.26. blackknight.py: идея подсказана персонажем Black Knight (Черный рыцарь) из скетча «Monty Python and the Holy Grail» (Монти Пайтон и Святой Грааль) class BlackKnight: def __init__(self): self .members = ['рука', 'вторая рука', 'нога', 'вторая нога'] self .phrases = [\"Это всего лишь царапина.\", \"Это всего лишь поверхностная рана.\", \"Я неуязвим!\", \"Ну ладно, пусть будет ничья.\"] @property def member(self): print(следующий член:')\n--- Страница 644 ---\n644 Глава 19. Динамические атрибуты и свойства return self.members[0] @member.deleter def member(self): text = 'ЧЕРНЫЙ РЫЦАРЬ (утрачена {})\\n-- {}' print(text.format(self.members.pop(0), self.phrases.pop(0))) doctest-скрипты для этого класса содержатся в файле blackknight.py . Пример 19.27. blackknight.py: doctest-скрипты для примера 19.26 (Черный рыцарь никогда не признает поражение) >>> knight = BlackKnight() >>> knight.memberследующий член:'рука'>>> del knight.memberЧЕРНЫЙ РЫЦАРЬ (утрачена рука)-- Это всего лишь царапина.>>> del knight .member ЧЕРНЫЙ РЫЦАРЬ (утрачена вторая рука)-- Это всего лишь поверхностная рана.>>> del knight .member ЧЕРНЫЙ РЫЦАРЬ (утрачена нога)-- Я неуязвим!>>> del knight .member ЧЕРНЫЙ РЫЦАРЬ (утрачена вторая нога)-- Ну ладно, пусть будет ничья. Если используется не декоратор, а классический синтаксис, то для задания метода удаления применяется именованный аргумент fdel . Например, свойство member в теле класс BlackKnight можно было бы написать так: member = property(member_getter, fdel=member_deleter) Если вы не пользуетесь свойствами, то для удаления атрибута можно было бы также реализовать низкоуровневый специальный метод __delattr__ , описанный в разделе «Специальные методы для управления атрибутами» ниже. Кодирование класса с применением метода __delattr__ я оставляю в качестве упражнения на досуге для читателей. Свойства – весьма полезный механизм, но иногда предпочтительнее более простые или низкоуровневые альтернативы. В последнем разделе этой главы мы рассмотрим некоторые базовые API, предлагаемые для программирования дина-мических атрибутов. Важные атрибуты и функции для работы с атрибутами И в этой главе, и раньше в книге мы уже использовали некоторые встроенные функции и специальные методы, которые Python предоставляет для работы с ди-\n--- Страница 645 ---\n645 Важные атрибуты и функции для работы с атрибутами намическими атрибутами. Сейчас мы соберем их в одном месте, поскольку в офи- циальном руководстве они документированы в разных местах. Специальные атрибуты, влияющие на обработку атрибутов Поведение многих функций и специальных методов, описанных ниже, опреде- ляется тремя специальными атрибутами. __class__ Ссылка на класс объекта (т. е. obj.__class__ – то же самое, что type(obj) ). Python ищет специальные методы, например __getattr__ , только в классе объекта, а не в самих экземплярах. __dict__ Отображение, в котором хранятся изменяемые атрибуты объекта или клас- са. Если у объекта есть атрибут __dict__ , то его в любой момент можно на- делить новыми атрибутами. Если в классе есть атрибут __slots__ , то у его экземпляров не может быть атрибута __dict__ . __slots__ Этот атрибут можно определить в классе, чтобы ограничить состав атри- бутов у экземпляров этого класса. __slots__ представляет собой кортеж строк с именами допустимых атрибутов15. Если имя '__dict__' отсутству- ет в __slots__ , то у экземпляров класса не будет своего атрибута __dict__ , поэтому в них будут разрешены только именованные атрибуты. Встроенные функции для работы с атрибутами Существует пять встроенных функций для чтения, записи и интроспекции атрибутов: dir([object]) Перечисляет большую часть атрибутов объекта. В официальной докумен- тации ( http://bit.ly/1HGvLD V ) сказано, что функция dir предназначена для интерактивного использования, поэтому она выводит не полный спи-сок атрибутов, а только самые «интересные». dir умеет инспектировать объекты с атрибутом __dict__ и без него. Сам атрибут __dict__ не входит в список, формируемый функцией dir, но ключи, хранящиеся в __dict__ , входят. Есть еще несколько специальных атрибутов классов, в частности __mro__ , __bases__ и __name__ , которые dir не выводит. Если необязатель- ный аргумент object не задан, то dir выводит имена в текущей области видимости. 15 Алекс Мартелли отмечает, что __slots__ может быть и списком, но лучше не оставлять места для недоразумений и всегда использовать кортеж, потому что изменение списка, хранящегося в __slots__ , после обработки тела класса интерпретатором, не возымеет никакого эффекта, так что использование здесь изменяемой последовательности лишь стало бы причиной вредных иллюзий.\n--- Страница 646 ---\n646 Глава 19. Динамические атрибуты и свойства getattr(object, name[, default]) Получает атрибут, идентифицируемый строкой name , объекта object . В ре- зультате может быть найден атрибут, определенный в классе или супер-классе объекта. Если такого атрибута не существует, getattr возбуждает исключение AttributeError либо возвращает значение default , если оно задано. hasattr(object, name) Возвращает True , если атрибут с указанным именем существует в объекте object или может быть найден с его помощью (например, в результате на- следования). В документации ( https://docs.python.org/3/library/functions. html#hasattr ) приводится следующее объяснение: «Реализовано так: вы- зываем getattr(object, name) , а затем смотрим, возникло исключение At- tributeError или нет». setattr(object, name, value) Присваивает значение value поименованному атрибуту object , если object это допускает. В результате может быть создан новый атрибут или изменен существующий. vars([object]) Возвращает атрибут __dict__ объекта object ; функция vars не умеет ра- ботать с классами, в которых определен атрибут __slots__ и нет атрибута __dict__ (в отличие от функции dir, которая справляется с такими экзем- плярами). Без аргумента vars() делает то же самое, что locals() : возвраща- ет словарь, описывающий локальную область видимости. Специальные методы для работы с атрибутами Специальные методы, описанные ниже, отвечают за чтение, установку, уда- ление и получение списка атрибутов (если они реализованы в пользовательском классе). Доступ к атрибутам – с помощью нотации с точкой или встроенных функций getattr , hasattr и setattr – приводит к вызову соответствующих специальных методов. Чтение и запись атрибутов непосредственно в атрибуте __dict__ экзем- пляра производится в обход специальных методов. В разделе 3.3.9 «Поиск специальных методов» ( http://bit.ly/1cPO3qP ) главы «Модель данных» есть такое предупреждение: Для пользовательских классов правильность работы при неяв- ном вызове специальных методов гарантируется, только если они определены в типе объекта, а не в словаре экземпляра. Иными словами, следует считать, что специальные методы ищутся в самом классе, даже если вызываются от имени экземпляра. По этой причине специаль-ные методы не маскируются одноименными атрибутами экземпляра.\n--- Страница 647 ---\n647 Важные атрибуты и функции для работы с атрибутами В следующих примерах предполагается, что существует класс с именем Class , что obj – экземпляр класса Class , а attr – атрибут obj. Для всех описанных ниже специальных методов не имеет значения, как произ- водится доступ к атрибуту: с помощью нотации с точкой или встроенных функ-ций, упомянутых в предыдущем разделе. И obj.attr , и getattr(obj, 'attr', 42) приводят к вызову функции Class.__getattribute__(obj, 'attr') . __delattr__(self, name) Вызывается при любой попытке удалить атрибут в предложении del, на- пример, del obj.attr приводит к вызову Class.__delattr__(obj, 'attr') . __dir__(self) Вызывается при вызове dir для объекта с целью получить список атрибу- тов, например, dir(obj) приводит к вызову Class.__dir__(obj) . __getattr__(self, name) Вызывается только тогда, когда попытка найти поименованный атрибут в obj, Class и суперклассах завершается неудачно. Выражения obj.no_such_ attr , getattr(obj, 'no_such_attr') и hasattr(obj, 'no_such_attr') могут привести к вызову Class.__getattr__(obj, 'no_such_attr') , но только если атрибут с таким именем отсутствует в obj, Class и суперклассах. __getattribute__(self, name) Вызывается при любой попытке получить поименованный атрибут за ис- ключением случаев, когда искомый атрибут является специальным атри-бутом или методом. К вызову этого метода приводит использование нота-ции с точкой и встроенных функций getattr и hasattr . Метод __getattr__ всегда вызывается после __getattribute__ и только в том случае, когда __getattribute__ возбуждает исключение AttributeError . Чтобы при по- лучении атрибутов obj не возникало бесконечной рекурсии, в реализации __getattribute__ следует использовать super().__getattribute__(obj, name) . __setattr__(self, name, value) Вызывается при любой попытке установить поименованный атрибут. К вызову этого метода приводит использование нотации с точкой и встро-енной функции setattr , например и obj.attr = 42 , и setattr(obj, 'attr', 42) приводят к вызову Class.__setattr__(obj, 'attr', 42) . Поскольку специальные методы __getattribute__ и __setattr__ вызываются безусловно и сопровождают практически каждый доступ к атрибуту, правильно использовать их труднее, чем ме-тод __getattr__ , который вызывается только для обработки имен несуществующих атрибутов. Во избежание ошибок лучше поль-зоваться не этими специальными методами, а свойствами или дескрипторами.\n--- Страница 648 ---\n648 Глава 19. Динамические атрибуты и свойства На этом завершается наше исследование свойств, специальных методов и дру- гих приемов программирования динамических атрибутов. Резюме Мы начали обсуждение динамических атрибутов с практических примеров клас-сов, которые упрощают работу с набором данных в формате JSON. Первым при-мером был класс FrozenJSON , преобразующий вложенные словари и списки во вложенные экземпляры FrozenJSON и списки таких экземпляров. При этом мы продемонстрировали применение специального метода __getattr__ для преоб- разования структур данных на лету, в момент чтения их атрибутов. В последней версии FrozenJSON было показано, как использовать метод конструирования __ new__ , чтобы превратить класс в гибкую фабрику объектов, причем не только это- го класса. Затем мы преобразовали набор JSON-данных в базу данных shelve .Shelf , в которой хранятся сериализованные экземпляры класса Record . Первое воплощение Record содержало всего несколько строк, и в нем использовалась идиома self. __dict__.update(**kwargs) для создания произвольных атрибутов из именованных аргументов, переданных __init__ . На второй итерации мы реализовали класс DbRecord , расширяющий Record в целях интеграции с базой данных, и класс Event , реализующий автоматический поиск связанных записей с помощью свойств. Знакомство со свойствами продолжилось на примере класса LineItem , в кото- ром свойство предотвращало присваивание атрибуту weight нулевого или отри- цательного значения. Глубже разобравшись с синтаксисом и семантикой свойств, мы создали фабрику свойств, которая обеспечивала одинаковую проверку свойств weight и price , но без повторного кодирования методов чтения и установки. При реализации фабрики свойств использовались тонкие идеи – замыкание и пере-определение атрибутов экземпляра свойствами – позволившие предложить эле-гантное общее решение, по количеству строк не превышающее определение одно-го свойства, написанное вручную. Напоследок мы вкратце рассмотрели удаление атрибутов с помощью свойств, а затем перечислили специальные атрибуты, встроенные функции и специальные методы, которые поддерживают метапрограммирование атрибутов в Python. Дополнительная литература Официальной документацией по встроенным функциям для работы с атрибутами и интроспекции является глава 2 «Встроенные функции» ( http://bit.ly/1cPOrpc ) руководства по стандартной библиотеке Python. Относящиеся к этой же теме специальные методы и специальный атрибут __slots__ документированы в раз- деле 3.3.2 «Настройка доступа к атрибутам» справочного руководства по языку Python ( http://bit.ly/1cPOlxV ). Семантика вызова специальных методов в об- ход экземпляров описана в разделе 3.3.9 «Поиск специальных методов» ( http:// bit.ly/1cPO3qP ). В разделе 4.13 «Специальные атрибуты» главы 4 «Встроенные\n--- Страница 649 ---\n649 Поговорим типы» руководства по стандартной библиотеке Python ( http://bit.ly/1cPOodb ) рассматриваются атрибуты __class__ и __dict__ . В книге Дэвида Бизли и Брайана К. Джонса «Python Cookbook», издание 3 (O'Reilly), есть несколько рецептов, относящихся к теме данной главы, но я упо-мяну только три наиболее интересных: рецепт 8.8. «Расширение свойства в под-классе» касается непростого вопроса о переопределении методов внутри свойства, унаследованного от суперкласса; в рецепте 8.15 «Делегирование доступа к атрибу-там» реализован прокси-класс, демонстрирующий большинство специальных ме-тодов, описанных в разделе «Специальные методы для работы с атрибутами» этой главы; а великолепный рецепт 9.21 «Как избежать повторения методов свойств» лег в основу фабрики свойств, представленной в примере 19.24. В книге Алекса Мартелли «Python in a Nutshell», издание 2 (O'Reilly), рас- сматривается только версия Python 2.5, но основные положения применимы и к Python 3, а материал изложен строго и объективно. Мартелли уделил свойствам всего три страницы, но это потому что в книге принят аксиоматический стиль из-ложения: предшествующие 15 страниц посвящены детальному описанию семан-тики классов Python, начиная с самых основ, и в том числе дескрипторам, которые составляют основу реализации свойств. Так что, дойдя до свойств, Мартелли смог уместить на трех страницах очень много полезной информации, в том числе и за-мечание, взятое мной в качестве эпиграфа к этой главе. Бертран Мейер, чье определение принципа единообразного доступа приведе- но в начале этой главы, написал великолепную книгу «Object-Oriented Software Construction», издание 2 (Prentice-Hall). В ней больше 1250 страниц и, признаюсь, я прочитал не все, но первые шесть глав – одно из лучших концептуальных введе-ний в объектно-ориентированный анализ и проектирование из всех мне встречав-шихся. В главе 11 содержится введение в «проектирование по контракту» (Мейер является автором и самого метода, и этого термина), а в главе 33 – авторские оцен-ки некоторых важнейших объектно-ориентированных языков: Simula, Smalltalk, CLOS (объектно-ориентированное расширение Lisp), Objective-C, C++ и Java, а также краткие замечания по поводу ряда других. Мейер также изобрел псевдо-псевдокод: только на последней странице книги он признается, что «нотация», которой он пользовался при написании псевдокода, – на самом деле язык Eiffel. Поговорим Принцип единообразного доступа Мейера (любители акронимов иногда называют его U AP) эстетически весьма привлекателен. Как программисту, который пользуется некоторым API, мне должно быть все равно, что делает конструкция coconut.price : просто читает атри- бут-данные или выполняет какое-то вычисление. Но как потребителю и гражданину, мне это отнюдь небезразлично: в современной электрон-ной коммерции значение coconut.price зачастую зависит от того, кто\n--- Страница 650 ---\n650 Глава 19. Динамические атрибуты и свойства спрашивает, т. е. это заведомо не простой атрибут. На самом деле, цена нередко будет ниже, если запрос поступает извне магазина, скажем, от системы сравнения цен. И тем самым наказываются лояльные покупа-тели, которые любят гулять по данному магазину. Но это я отвлекся. Однако это отвлечение поднимает важный для программирования вопрос: хотя в идеальном мире принцип единообразного доступа, без-условно, имеет смысл, на практике пользователям API иногда нужно знать, не может ли обращение к coconut .price оказаться слишком на- кладным или долгим. Как обычно, когда речь заходит о программной инженерии, стоит заглянуть на вики-сайт У орда Каннингэма ( http://bit. ly/1HGvZuA ), где имеются поучительные соображения по поводу досто- инств принципа единообразного доступа ( http://bit.ly/1HGvNvk ). В объектно-ориентированных языках программирования примене- ние или нарушение принципа единообразного доступа обычно сводится к выбору между чтением открытых атрибутов-данных и вызову методов чтения и установки. В Smalltalk и Ruby проблема решается просто и элегантно: они во- обще не поддерживают открытые атрибуты-данные. Все атрибуты эк-земпляра в этих языках закрыты, поэтому доступ к ним обязательно опосредуется методами. Но это принуждение нивелируется удобным синтаксисом: в Ruby выражение coconut.price приводит к вызову мето- да чтения price ; в Smalltalk мы пишем просто coconut price . На другом конце спектра находится язык Java, в котором у про- граммиста есть выбор между четырьмя модификаторами уровня до-ступа 16. Впрочем, принятая практика идет вразрез с синтаксисом, уста- новленным проектировщиками языка Java. Все в мире Java согласны, что атрибуты должны быть закрытыми, поэтому приходится всякий раз писать private , поскольку этот уровень доступа не является умал- чиваемым. Коль скоро все атрибуты закрыты, то и доступ к ним вне класса должен осуществляться с помощью акцессоров. В Java IDE имеются средства для автоматической генерации методов-акцессоров. К сожалению, IDE не поможет, когда спустя полгода вам придется чи-тать свой код. Вам и только вам предстоит просеять кучу ничего не делающих акцессоров и найти те жемчужины, в которые имеет смысл добавить бизнес-логику. Алекс Мартелли говорит от имени большей части сообщества Python, когда называет акцессоры «тупыми идиомами», и затем пред-лагает следующие примеры, которые выглядят совсем по-разному, но делают одно и то же 17: 16 Включая безымянный подразумеваемый по умолчанию уровень, который в пособии по Java ( http://bit.ly/1cPOMIE ) называется «package-private» (закрытый на уровне пакете). 17 Alex Martelli «Python in a Nutshell», издание 2 (O'Reilly), стр. 101.\n--- Страница 651 ---\n651 Поговорим someInstance.widgetCounter += 1 # вместо someInstance.setWidgetCounter(someInstance.getWidgetCounter() + 1) Иногда, проектируя API, я задавался вопросом, следует ли всякий метод, который не принимает аргументов (кроме self ), возвращает зна- чение (отличное от None ) и является чистой функцией (т. е. не имеет по- бочных эффектов), заменять свойством, допускающим только чтение. В этой главе метод LineItem.subtotal (см. пример 19.23) был бы непло- хим кандидатом на преобразование в свойство. Конечно, речь не идет о методах, которые призваны изменять объект, например my_list.clear() . Было бы ужасной ошибкой преобразовать такой метод в свойство, по-тому что простое обращение my_list.clear стерло бы все содержимое списка! В библиотеке Pingo.io ( http://www.pingo.io/docs/ ), упоминавшейся в разделе «Метод __missing__» на стр. 103, значительная часть API поль-зовательского уровня основана на свойствах. Например, чтобы прочи-тать текущее значение аналогового контакта, нужно написать pin.value , а чтобы установить режим цифрового контакта – pin.mode = OUT . За кулисами то и другое может потребовать выполнения большого объема кода – в зависимости от драйвера платы. Мы решили использовать в Pingo свойства, потому что хотели, чтобы с API было удобно работать даже в интерактивных средах типа iPython Notebook ( http://ipython.org/ notebook.html ), и полагали, что запись pin.mode = OUT приятнее и глазам, и пальцам, чем pin.set_mode(OUT) . Решение, принятое в Smalltalk и Ruby, мне кажется чище, но я по- лагаю, что подход Python лучше, чем в Java. Нам разрешено начать с простого – сделать данные-члены открытыми атрибутами – пото-му что мы знаем, что впоследствии всегда сможем обернуть их свой-ствами (или дескрипторами, о которых будем говорить в следующей главе). __new__ лучше, чем new Еще один пример принципа единообразного доступа (или вариации на его тему) – тот факт, что в Python синтаксис вызова функций и соз-дания объектов одинаков: my_obj = foo() , где foo может быть классом или любым другим вызываемым объектом. В других языках, позаимствовавших синтаксис C++, имеется опера- тор new, из-за которого создание объекта выглядит иначе, чем вызов. По большей части, пользователю API безразлично, является foo функцией или классом. До недавнего времени я и сам считал, что property – это функция. При обычном использовании это неважно.\n--- Страница 652 ---\n652 Глава 19. Динамические атрибуты и свойства Есть много причин заменить конструкторы фабриками18. Популяр- ное обоснование – ограничить количество экземпляров, возвращая не новые, а созданные ранее (как в паттерне Одиночка). Сюда же примыка-ет кэширование объектов, конструирование которых обходится дорого. Иногда также удобно возвращать объекты разных типов в зависимости от переданных аргументов. Писать конструктор проще, но реализация фабрики повышает гиб- кость ценой дополнительного кода. В языках, где есть оператор new, проектировщик API должен заранее решить, ограничиться ли простым конструктором или потратить время на фабрику. Если первоначальное решение оказалось неверным, то исправление может обойтись дорого – из-за того, что new – оператор. Иногда удобнее пойти другим путем и заменить простую функцию классом. В Python классы и функции во многих ситуациях взаимозаменяемы. И не только из-за отсутствия оператора new, но и потому что имеется специальный метод __new__ который позволяет преобразовать класс в фабрику, порождающую объекты разных видов (как мы видели в разде-ле «Гибкое создание объектов с помощью метода __new__» этой главы) или возвращающую ранее созданные экземпляры, вместо того чтобы каждый раз создавать новые. Дуализм функции и класса было бы использовать еще проще, если бы в документе «PEP 8 – Style Guide for Python Code» ( http:// bit.ly/1HGvYH7 ) не рекомендовалось применять ВерблюжьюНотацию (CamelCase) для имен классов. С другой стороны, в стандартной библи-отеке имеются десятки классов с именами, составленными только из строчных букв (например, property , str, defauldict и т. д.). Так что, воз- можно, использование таких имен классов – вовсе не ошибка. Впрочем, как бы ни смотреть на эту проблему, разнобой в употреблении строчных и заглавных букв в именах классов из стандартной библиотеки Python представляет трудность для пользователей. Хотя вызов функции не отличается от вызова класса, знать, что есть что, полезно, поскольку у классов есть дополнительная возможность: наследование. Поэтому лично я всегда применяю ВерблюжьюНотацию для имен своих классов и хотел бы, чтобы все классы в стандартной библио-теке следовали этому соглашению. Это я о вас, collections.OrderedDict и collections.defaultdict . 18 Упоминаемые мной причины приведены в статье Джонатана Амстердама (Jonathan Amsterdam) из журнала «Dr. Dobbs Journal» под названием «Java's new Considered Harmful» ( http://ubm.io/1cPP4PN ), а также в разделе «Consider static factory methods instead of constructors» удостоенной наград книги Джошуа Блоха (Joshua Bloch) «Effective Java» (Addison-W esley).",
      "debug": {
        "start_page": 614,
        "end_page": 652
      }
    },
    {
      "name": "Глава 20. Дескрипторы атрибутов 653",
      "content": "--- Страница 653 --- (продолжение)\nГЛАВА 20. Дескрипторы атрибутов Изучение дескрипторов не только расширяет доступный инструмента-рий, но позволяет глубже понять, как работает Python, и оценить эле-гантность его дизайна 1. – Раймонд Хэттингер, один из разработчиков Python и гуру Дескрипторы – это способ повторного использования одной и той же логики до-ступа в нескольких атрибутах. Например, типы полей в объектно-ориентирован-ных отображениях типа Django ORM и SQL Alchemy – дескрипторы, управляю-щие потоком данных от полей в записи базы данных к атрибутам Python-объекта и обратно. Дескриптор – это класс, который реализует протокол, содержащий методы __get__ , __set__ и __delete__ . Класс property реализует весь протокол дескрипто- ра. Как обычно, разрешается реализовывать протокол частично. На самом деле, большинство дескрипторов, встречающихся в реальных программах, реализуют только методы __get__ и __set__ , а многие – и вовсе лишь один из них. Дескрипторы – уникальная черта Python, и используются они не только на уровне приложения, но и в инфраструктуре самого языка. Помимо свойств, де-скрипторами пользуются такие языковые средства, как методы и декораторы classmethod и staticmethod . Умение работать с дескрипторами – ключ к полному овладению Python. Им и посвящена эта глава. Пример дескриптора: проверка значений атрибутов В разделе «Программирование фабрики свойств» главы 19 мы видели, что фа- брика свойств позволяет избежать многократного кодирования методов чтения и установки посредством применения приемов, характерных для функционального программирования. Фабрика свойств – это функция высшего порядка, которая 1 Raymond Hettinger «Descriptor HowT o Guide» ( https://docs.python.org/3/howto/descriptor.html ).\nГЛАВА 20. Дескрипторы атрибутов Изучение дескрипторов не только расширяет доступный инструмента-рий, но позволяет глубже понять, как работает Python, и оценить эле-гантность его дизайна 1. – Раймонд Хэттингер, один из разработчиков Python и гуру Дескрипторы – это способ повторного использования одной и той же логики до-ступа в нескольких атрибутах. Например, типы полей в объектно-ориентирован-ных отображениях типа Django ORM и SQL Alchemy – дескрипторы, управляю-щие потоком данных от полей в записи базы данных к атрибутам Python-объекта и обратно. Дескриптор – это класс, который реализует протокол, содержащий методы __get__ , __set__ и __delete__ . Класс property реализует весь протокол дескрипто- ра. Как обычно, разрешается реализовывать протокол частично. На самом деле, большинство дескрипторов, встречающихся в реальных программах, реализуют только методы __get__ и __set__ , а многие – и вовсе лишь один из них. Дескрипторы – уникальная черта Python, и используются они не только на уровне приложения, но и в инфраструктуре самого языка. Помимо свойств, де-скрипторами пользуются такие языковые средства, как методы и декораторы classmethod и staticmethod . Умение работать с дескрипторами – ключ к полному овладению Python. Им и посвящена эта глава. Пример дескриптора: проверка значений атрибутов В разделе «Программирование фабрики свойств» главы 19 мы видели, что фа- брика свойств позволяет избежать многократного кодирования методов чтения и установки посредством применения приемов, характерных для функционального программирования. Фабрика свойств – это функция высшего порядка, которая 1 Raymond Hettinger «Descriptor HowT o Guide» ( https://docs.python.org/3/howto/descriptor.html ).\n--- Страница 654 ---\n654 Глава 20. Дескрипторы атрибутов создает параметризованный набор функций-акцессоров и строит из них экзем- пляры конкретных свойств, настройки которых, например storage_name , хранятся в замыканиях. Объектно-ориентированный способ решения той же задачи – де-скрипторный класс. Мы вернемся к примерам класса LineItem с того места, где остановились, и пе- ределаем фабрику свойств quantity в дескрипторный класс Quantity . LineItem попытка № 3: простой дескриптор Класс, в котором реализован хотя бы один из методов __get__ , __set__ или __delete__ , является дескриптором. Для использования дескриптора мы объявля- ем его экземпляром атрибут какого-то другого класса. Мы создадим дескриптор Quantity и включим в класс LineItem два экземпля- ра Quantity : для управления атрибутами weight и price . Все это изображено на диаграмме классов на рис. 20.1. /g449/g450/g462/g455/g461/g453/g460/g463/g459/g461/g458/g472/g454/g3 /g455/g456/g445/g462/g462 установить управляемый атрибут/g464/g460/g461/g445/g447/g456/g476/g450/g457/g472/g454/g3/g455/g456/g445/g462/g462 Рис. 20.1. UML-диаграмма класса LineItem и используемого в нем дескрипторного класса Quantity . Подчеркнуты атрибуты класса. Отметим, что weight и price – экземпляры класса Quantity , присоединенного к классу LineItem , но у экземпляров LineItem есть также свои атрибуты weight и price , в которых соответствующие значения хранятся Отметим, что слово weight встречается на рис. 20.1 дважды, потому что есть два разных атрибута с именем weight : первый – атрибут класса LineItem , второй – атрибут экземпляра, принадлежащий каждому объекту LineItem . То же самое от- носится и к price . Начиная с этого места, я буду пользоваться следующими определениями: Дескрипторный класс Класс, реализующий протокол дескриптора. Это класс Quantity на рис. 20.1. Управляемый класс Класс, в котором объявлены атрибуты класса, являющиеся экземплярами дескриптора. Это класс LineItem на рис. 20.1.\n--- Страница 655 ---\n655 Пример дескриптора: проверка значений атрибутов Экземпляр дескриптора Любой экземпляр дескрипторного класса, объявленный атрибутом класса в управляемом классе. На рис. 20.1 все экземпляры дескриптора представ-лены стрелкой композиции, снабженной подчеркнутым именем (в UML подчеркивание означает атрибут класса). Сплошные ромбы одним концом касаются класса LineItem , который содержит экземпляры дескрипторов. Управляемый экземпляр Один экземпляр управляемого класса. В нашем примере управляемыми являются экземпляры класса LineItem (на диаграмме классов не показаны). Атрибут хранения Атрибут управляемого экземпляра, в котором хранится значение управля- емого атрибута для данного экземпляра. На рис. 20.1 атрибутами хранения являются атрибуты weight и price экземпляра LineItem . Они отличаются от экземпляров дескриптора, которые всегда являются атрибутами класса. Управляемый атрибут Открытый атрибут управляемого класса, который обрабатывается экзем- пляром дескриптора, а значение которого хранится в одном из атрибутов хранения. Другими словами, экземпляр дескриптора и атрибут хранения в совокупности образуют инфраструктуру для управляемого атрибута. Необходимо понимать, что экземпляры Quantity являются атрибутами класса LineItem . Этот важнейший момент иллюстрируется хреновинами и штуковинами на рис. 20.2. Рис. 20.2. UML-диаграмма классов, аннотированная на языке MGN (Mills & Gizmos Notation): классы представлены хреновинами, порождающими штуковины – экземпляры. Хреновина Quantity порождает две красных штуковины, присоединенных к хреновине LineItem : weight и price . Хреновина LineItem порождает синие штуковины, у которых есть собственные атрибуты weight и price , где хранятся значения\n--- Страница 656 ---\n656 Глава 20. Дескрипторы атрибутов Введение в нотацию хреновин и штуковин После многократного объяснения дескрипторов я понял, что UML – не лучший способ показа связей между классами и экземплярами, в частности, связи между управляемым классом и экземплярами де-скриптора 2. Поэтому я изобрел собственный «язык», нотацию хреновин и штуковин (Mills & Gizmos Notation – MGN), который применяю для аннотирования UML-диаграмм. Задача MGN – провести четкое различие между классами и экзем- плярами. Взгляните на рис. 20.3. В MGN класс изображается «хрено-виной» (mill) – сложной машиной, которая производит «штуковины» (gizmo). Классы-хреновины всегда являются машинами с ручками и циферблатами. Штуковины – это экземпляры, они выглядят гораздо проще. Цвет штуковины всегда совпадает с цветом создавшей его хре-новины. Рис. 20.3. Набросок MGN, показывающий класс LineItem с тремя экземплярами и класс Quantity с двумя. Один экземпляр Quantity извлекает значение, хранящееся в экземпляре LineItem Для рассматриваемого примера я изобразил экземпляр LineItem в виде строки табличного счета-фактуры с тремя колонками, представ-ляющими три атрибута ( description , weight и price ). Поскольку эк- земпляры Quantity – дескрипторы, у них имеется лупа для получения значений методом __get__ и клешня для установки значений методом __set__ . Когда мы перейдем к метаклассам, вы еще скажете мне спасибо за эти каракули. Но хватит рисовать каракули. Ниже приведен код: в примере 20.1 показан дескрипторный класс Quantity и новый класс LineItem с двумя экземплярами Quantity . 2 Классы и экземпляры изображаются на UML-диаграммах классов прямоугольниками. Между ними есть визуальные различия, но экземпляры встречаются на диаграммах классов так редко, что разработчики их не отличают.\n--- Страница 657 ---\n657 Пример дескриптора: проверка значений атрибутов Пример 20.1. bulkfood_v3.py: дескрипторы Quantity управляют атрибутами LineItem class Quantity: /g110 def __init__(self, storage_name): self.storage_name = storage_name /g111 def __set__(self, instance, value): /g112 if value > 0: instance.__dict__[self.storage_name] = value /g113 else: raise ValueError('value must be > 0') class LineItem: weight = Quantity('weight') /g114 price = Quantity('price') /g115 def __init__(self, description, weight, price): /g116 self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price /g110 Дескриптор основан на протоколе, для его реализации не требуется насле- дование. /g111 В каждом экземпляре Quantity имеется атрибут storage_name : имя атрибу- та, в котором хранится значение управляемого экземпляра. /g112 Метод __set__ вызывается при любой попытке присвоить значение управ- ляемому атрибуту. В данном случае self – экземпляр дескриптора (т. е. LineItem .weight или LineItem.price ), instance – управляемый экземпляр (экземпляр LineItem ), а value – присваиваемое значение. /g113 Здесь мы должны работать с атрибутом __dict__ управляемого экземпляра напрямую; попытка воспользоваться встроенной функцией setattr приве- ла бы к повторному вызову метода __set__ и, стало быть, к бесконечной рекурсии. /g114 Первый экземпляр дескриптора связывается с атрибутом weight . /g115 Второй экземпляр дескриптора связывается с атрибутом price . /g116 Оставшаяся часть тела класса так же проста и понятна, как первоначаль- ный код в файле bulkfood_v1.py (пример 19.15). В примере 20.1 управляемые атрибуты называются так же, как соответствующий атрибут хранения, и никакой особой логики чтения нет, поэтому метод __get__ в классе Quantity не нужен. Код из примера 20.1 работает, как и ожидается, – не позволяет продать трюфели за 0 долларов3: 3 Белые трюфели стоят тысячи долларов за фунт. Запрет продажи трюфелей за $0.01 оставляю в качестве упражнения для увлеченных читателей. Я знаю человека, который купил энциклопе-дию статистики, стоящую 1800 долларов, за 18 долларов из-за ошибки в ПО Интернет-магазина (не Amazon.com).\n--- Страница 658 ---\n658 Глава 20. Дескрипторы атрибутов >>> truffle = LineItem('White truffle', 100, 0) Traceback (most recent call last): ValueError: value must be > 0 Кодируя метод __set__ , не забывайте, что означают аргументы self и instance : self – это экземпляр дескриптора, а instance – управляемый экземпляр. Дескрипторы, управляющие атрибута- экземпляр. Дескрипторы, управляющие атрибута-экземпляр. Дескрипторы, управляющие атрибута- . Дескрипторы, управляющие атрибута-Дескрипторы, управляющие атрибута- ми экземпляра, должны хранить значения в управляемых экзем-плярах. Потому-то Python и передает аргумент instance методам дескриптора. Может возникнуть соблазн хранить значения всех управляемых атрибутов в экземпляре самого дескриптора, т. е. в методе __set__ вместо кода instance.__dict__[self.storage_name] = value написать: self.__dict__[self.storage_name] = value Но это совершенно неправильно! Чтобы понять, почему, вспомните, что озна- чают первые два аргумента __set__ : self и instance . Здесь self – экземпляр де- скриптора, т. е. фактически атрибут класса, принадлежащий управляемому клас-су. Одновременно в памяти могут находиться тысячи экземпляров LineItem , но экземпляров дескрипторов будет только два: LineItem.weight и LineItem.price . Поэтому все, что вы сохраняете в самих экземплярах дескрипторов, становится частью атрибута класса LineItem и, следовательно, распространяется на все экзем- пляры LineItem . В примере 20.1 есть недостаток – необходимость повторять имена атрибутов, когда в теле управляемого класса создаются экземпляры дескрипторов. Хорошо было бы иметь возможность объявить класса LineItem как-то так: class LineItem: weight = Quantity() price = Quantity() # прочие методы не изменяются Проблема в том – и мы видели это в главе 8, – что правая часть присваива- ния вычисляется еще до того, как начинает существовать переменная. Выражение Quantity() призвано создать экземпляр дескриптора, но в этот момент код в классе Quantity никак не может узнать имя переменной, с которой этот дескриптор дол- жен быть связан ( weight или price ). В версии из примера 20.1 задавать имя при каждом вызове Quantity необхо- димо явно, а это не только неудобно, но и опасно: если при копировании и встав-ке кода программист забудет изменить имена, т. е. напишет что-то вроде price =\n--- Страница 659 ---\n659 Пример дескриптора: проверка значений атрибутов Quantity('weight') , то программа будет работать совершенно неправильно: зати- рать значение weight при изменении price . Ниже представлено не очень элегантное, но работающее решение проблемы повторения имен. Есть решения получше, но они требуют либо декоратора класса, либо метакласса, поэтому я отложу их рассмотрение до главы 21. LineItem попытка № 4: автоматическая генерация имен атрибутов хранения Чтобы не вводить повторно имя атрибута в объявлении дескриптора, мы будем генерировать уникальную строку для storage_name в каждом экземпляре Quantity . На рис. 20.4 показана измененная UML-диаграмма классов Quantity и LineItem . Рис. 20.4. UML-диаграмма классов для примера 20.2. Теперь в классе Quantity есть оба метода get и set, а в экземплярах LineItem – атрибуты хранения со сгенерированными именами: _Quantity#0 и _Quantity#1 Для генерации storage_name мы берем общий префикс '_Quantity#' и добавля- ем к нему целое число: текущее значение атрибута класса Quantity.__counter , ко- торое увеличивается на единицу всякий раз, как к классу присоединяется новый экземпляр дескриптора Quantity . Знак решетки гарантирует, что storage_name не совпадет с именем, созданным в результате применения пользователем нотации с точкой, поскольку nutmeg._Quantity#0 – недопустимый идентификатор в Python. Однако читать и устанавливать атрибуты с такими «недопустимыми» именами можно как с помощью встроенных функций getattr и setattr , так и посредством прямых манипуляций с атрибутом экземпляра __dict__ . Новая реализация пока- зана в примере 20.2. Пример 20.2. bulkfood_v4.py: каждый дескриптор Quantity получает уникальное имя storage_name class Quantity: __counter = 0 /g110 def __init__(self): cls = self.__class__ /g111\n--- Страница 660 ---\n660 Глава 20. Дескрипторы атрибутов prefix = cls.__name__ index = cls.__counter self.storage_name = '_{}#{}'.format(prefix, index) /g112 cls.__counter += 1 /g113 def __get__(self, instance, owner): /g114 return getattr(instance, self.storage_name) /g115 def __set__(self, instance, value): if value > 0: setattr(instance, self.storage_name, value) /g116 else: raise ValueError('value must be > 0') class LineItem: weight = Quantity() /g117 price = Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price /g110 __counter – атрибут класса Quantity , служащий для подсчета экземпляров Quantity . /g111 cls – ссылка на класс Quantity . /g112 Значение storage_name для каждого экземпляра дескриптора уникально, потому что образуется из имени дескрипторного класса и текущего значе-ния __counter (например, _Quantity#0 ). /g113 Увеличиваем __counter . /g114 Мы должны реализовать метод __get__ , потому что имя управляемого атрибута не совпадает со значением storage_name . Смысл аргумента owner будет объяснен ниже. /g115 Используем встроенную функцию getattr , чтобы прочитать значение из instance . /g116 Используем встроенную функцию setattr , чтобы сохранить значение в instance . /g117 Теперь передавать имя управляемого атрибута конструктору Quantity не нужно. А этого мы и добивались. Здесь мы можем пользоваться высокоуровневыми функциями getattr и setattr для чтения и сохранения значения, а не манипулировать напрямую instance.__dict__ , потому что имена управляемого атрибута и атрибута хранения различны, а, значит, вызов gettatr для атрибута хранения не приведет к вызову дескриптора и бесконечной рекурсии, как в примере 20.1, не возникнет.\n--- Страница 661 ---\n661 Пример дескриптора: проверка значений атрибутов Протестировав bulkfood_v4.py , мы увидим, что дескрипторы weight и price ра- ботают в соответствии с ожиданиями, а атрибуты хранения можно читать напря-мую, что полезно для отладки: >>> from bulkfood_v4 import LineItem>>> coconuts = LineItem('Brazilian coconut', 20, 17.95)>>> coconuts.weight, coconuts.price(20, 17.95)>>> getattr(raisins, '_Quantity#0'), getattr(raisins, '_Quantity#1')(20, 17.95) Если бы мы хотели следовать соглашению, используемо- му в Python для декорирования имен (например, _LineItem__ quantity0 ), то должны были бы знать имя управляемого класса (LineItem ), однако определение тела класса обрабатывается еще до того, как интерпретатор построит сам класс, поэтому у нас нет этой информации в момент , когда создается экземпляр дескрип-тора. Но в данном случае и не нужно включать имя управляемого класса, чтобы избежать случайного перезаписывания в подклас-сах: значение __counter в дескрипторном классе увеличивается при создании каждого нового дескриптора, а, значит , имя атри-бута хранения гарантированно будет уникальным во всех управ-ляемых классах. Отметим, что __get__ получает три аргумента: self , instance и owner . Аргумент owner содержит ссылку на управляемый класс ( LineItem ) и оказывается полезен, когда дескриптор используется для получения атрибутов из этого класса. Если управляемый атрибут, например weight , читается с помощью класса, например LineItem.weight , то метод дескриптора __get__ получает значение None в качестве аргумента instance . Это объясняет, почему в следующем сеансе оболочки возни- кает исключение AttributeError : >>> from bulkfood_v4 import LineItem>>> LineItem.weightTraceback (most recent call last): File \" /descriptors/bulkfood_v4.py\", line 54, in __get__return getattr(instance, self.storage_name)AttributeError: 'NoneType' object has no attribute '_Quantity#0' Возбуждать исключение AttributeError при реализации __get__ можно, но если вы решите пойти по этому пути, то поправьте сообщение, чтобы не было упо-минаний о NoneType и _Quantity#0 , поскольку это детали реализации. Гораздо луч- ше звучало бы сообщение \"'LineItem' class has no such attribute\" (В классе 'LineItem' нет такого атрибута). В идеале следовало бы указать имя отсутствующе-го атрибута, но в данном случае дескриптор не знает имени управляемого атрибут, так что пока ничего лучшего мы предложить не можем.\n--- Страница 662 ---\n662 Глава 20. Дескрипторы атрибутов С другой стороны, для поддержки интроспекции и других приемов метапро- граммирования рекомендуется возвращать из __get__ экземпляр дескриптора, когда доступ к управляемому атрибуту производится через класс. В примере 20.3 показана слегка измененная по сравнению с примером 20.2 реализация метода Quantity.__get__ . Пример 20.3. bulkfood_v4b.py (неполный листинг): при вызове через управляемый класс метод __get__ возвращает ссылку на сам дескриптор class Quantity: __counter = 0 def __init__(self): cls = self.__class__ prefix = cls.__name__ index = cls.__counter self.storage_name = '_{}#{}'.format(prefix, index) cls.__counter += 1 def __get__(self, instance, owner): if instance is None: return self /g110 else: return getattr(instance, self.storage_name) /g111 def __set__(self, instance, value): if value > 0: setattr(instance, self.storage_name, value) else: raise ValueError('value must be > 0') /g110 Если вызов производился не от имени экземпляра, то возвращаем сам де- скриптор. /g111 В противном случае, как обычно, возвращаем значение управляемого атри- бута. Ниже показан результат выполнения примера 20.3: >>> from bulkfood_v4b import LineItem >>> LineItem.price<bulkfood_v4b.Quantity object at 0x100721be0>>>> br_nuts = LineItem('Brazil nuts', 10, 34.95)>>> br_nuts.price34.95 При взгляде на пример 20.2 возникает чувство, что уж слишком много кода для управления всего двумя атрибутами, однако важно понимать, что логика дескрип-тора теперь вынесена в отдельную единицу кода: класс Quantity . Обычно дескрип- тор определяется не в том же модуле, где используется, а в отдельном служебном модуле, который предназначен для использования в разных местах приложения – и даже в разных приложениях, если разрабатывается каркас.\n--- Страница 663 ---\n663 Пример дескриптора: проверка значений атрибутов С учетом этого пример 20.4 дает более точную картину типичного применения дескриптора. Пример 20.4. bulkfood_v4c.py: ничем не загроможденное определение LineItem ; дескрипторный класс Quantity теперь находится в импортируемом модуле model_v4c import model_v4c as model /g110 class LineItem: weight = model.Quantity() /g111 price = model.Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price /g110 Импортируем модуль model_v4c и попутно сопоставляем ему более симпа- тичное имя. /g111 Используем model .Quantity . Пользователи Django, наверное, заметили, что пример 20.4 выглядит в точно- Django, наверное, заметили, что пример 20.4 выглядит в точно- , наверное, заметили, что пример 20.4 выглядит в точно- сти как определение модели. И это не случайность: поля моделей Django являются дескрипторами. Реализованный в настоящий момент дескриптор Quantity ра- ботает вполне прилично. Единственный его недостаток – исполь-зование сгенерированных имен атрибутов хранения (например, _Quantity#0) , что затрудняет отладку. Однако для автоматиче- ского назначения атрибутам хранения имен, похожих на имена управляемых атрибутов, потребуется декоратор класса или ме-такласс, а эти темы мы отложим до главы 21. Поскольку дескрипторы определяются в классах, мы можем воспользоваться наследованием, чтобы повторно использовать уже написанный код в новых де-скрипторах. Этим мы и займемся в следующем разделе. Фабрика свойств и дескрипторный класс Нетрудно по-другому реализовать функциональность улучшенно- го дескрипторного класса из примера 20.2, добавив несколько строк в фабрику свойств, показанную в примере 19.24. Некоторую сложность представляет переменная __counter , но мы можем сохранять значение\n--- Страница 664 ---\n664 Глава 20. Дескрипторы атрибутов между вызовами фабрики, определив ее как атрибут самого объекта фа- бричной функции (см. пример 20.5). Пример 20.5. bulkfood_v4prop.py: та же функциональность, что в примере 20.2, но реализованная в виде фабрики свойств, а не дескрипторного класса def quantity(): /g110 try: quantity.counter += 1 /g111 except AttributeError: quantity.counter = 0 /g112 storage_name = '_{}:{}'.format('quantity', quantity.counter) /g113 def qty_getter(instance): /g114 return getattr(instance, storage_name) def qty_setter(instance, value): if value > 0: setattr(instance, storage_name, value) else: raise ValueError('value must be > 0') return property(qty_getter, qty_setter) /g110 Аргумента storage_name нет. /g111 Мы не можем полагаться на атрибуты класса для сохранения counter между вызовами, поэтому определим эту переменную как атрибут самой функции quantity . /g112 Если quantity .counter не определена, присваиваем ей значение 0. /g113 Атрибутов экземпляра у нас тоже нет, поэтому создаем storage_ name как локальную переменную, а в qty_getter и qty_setter ее значение будет доступно благодаря замыканию. /g114 Остальной код отличается от примера 19.24 только тем, что мы можем использовать встроенные функции getattr и setattr , а не манипулировать напрямую атрибутом instance.__dict__ . Ну и что вы предпочтете? Пример 20.2 или 20.5? Лично я предпочитаю подход на основе дескрипторного класса в ос- новном по двум причинам: • дескрипторный класс можно расширять посредством наследова- ния; повторно использовать код фабричной функции без копиро-вания и вставки гораздо труднее; • хранить состояние в атрибутах класса и экземпляров проще, чем в атрибутах функции и замыкании. С другой стороны, когда я объясняю студентам пример 20.5, у меня не возникает потребности в хреновинах и штуковинах. Код фабрики\n--- Страница 665 ---\n665 Пример дескриптора: проверка значений атрибутов свойств не зависит от странных связей между объектами, которые про- являются в именах аргументов дескриптора: self и instance . Короче говоря, паттерн фабрики свойств в некоторых отношениях проще, но дескрипторный класс лучше обобщается. И используется по-следний подход шире. LineItem попытка № 5: новый тип дескриптора Воображаемый магазин натуральных пищевых продуктов столкнулся с не- ожиданной проблемой: каким-то образом была создана строка заказа с пустым описанием, и теперь заказ невозможно выполнить. Чтобы предотвратить такие инциденты в будущем, мы создадим новый дескриптор, NonBlank . Проектируя Non- Blank , мы обнаруживаем, что он очень похож на дескриптор Quantity , а отличается только логика проверки. Присмотревшись к функциональности Quantity , мы замечаем, что этот класс делает две разные вещи: отвечает за работу с атрибутами хранения в управляемых экземплярах и проверяет значения, записываемые в эти атрибуты. Это наводит на мысль о рефакторинге и заведении двух базовых классов: AutoStorage Дескрипторный класс, который автоматически управляет атрибутами хра- нения. Validated Абстрактный подкласс AutoStorage , который переопределяет метод __set__ , вызывая метод validate , который должен быть реализован в подклассах. Затем мы переписываем Quantity и реализуем NonBlank , наследуя классу Vali- dated , так что остается лишь написать методы validate . Описанная схема изобра- жена на рис. 20.5. Рис. 20.5. Иерархия дескрипторных классов. Базовый класс AutoStorage автоматически управляет атрибутами хранения, а Validated производит проверку, делегируя работу абстрактному методу validate . Quantity и NonBlank – конкретные подклассы Validated\n--- Страница 666 ---\n666 Глава 20. Дескрипторы атрибутов Соотношение между классами Validated , Quantity и NonBlank – пример паттер- на проектирования Шаблонный метод. Конкретно, метод Validated.__set__ – ти- пичный пример того, что «банда четырех» называет шаблонным методом: Шаблонный метод определяет алгоритм в терминах абстракт- ных операций, которые переопределяются в подклассах для обе-спечения конкретного поведения. В данном случае абстрактной операци ей является проверка. В примере 20.6 приведена реализация всех классов, показанных на рис. 20.5. Пример 20.6. model_v5.py: дескрипторные классы после рефакторинга import abc class AutoStorage: /g110 __counter = 0 def __init__(self): cls = self.__class__ prefix = cls.__name__ index = cls.__counter self.storage_name = '_{}#{}'.format(prefix, index) cls.__counter += 1 def __get__(self, instance, owner): if instance is None: return self else: return getattr(instance, self.storage_name) def __set__(self, instance, value): setattr(instance, self.storage_name, value) /g111 class Validated(abc.ABC, AutoStorage): /g112 def __set__(self, instance, value): value = self.validate(instance, value) /g113 super().__set__(instance, value) /g114 @abc.abstractmethod def validate(self, instance, value): /g115 \"\"\"возвращает проверенное значение или возбуждает ValueError\"\"\" class Quantity(Validated): /g116 \"\"\"число больше нуля\"\"\" def validate(self, instance, value): if value <= 0: raise ValueError('value must be > 0')\n--- Страница 667 ---\n667 Пример дескриптора: проверка значений атрибутов return value class NonBlank(Validated): \"\"\"строка содержит хотя бы один непробельный символ\"\"\" def validate(self, instance, value): value = value.strip() if len(value) == 0: raise ValueError('value cannot be empty or blank') return value /g117 /g110 Класс AutoStorage предоставляет большую часть функциональности быв- шего дескриптора Quantity … /g111 … за исключением проверки. /g112 Класс Validated абстрактный, но наследует AutoStorage . /g113 Метод __set__ делегирует проверку методу validate … /g114 … а затем передает возвращенное значение value методу __set__ суперклас- са, который и производит сохранение. /g115 В этом класс метод validate абстрактный. /g116 Классы Quantity и NonBlank наследуют Validated . /g117 Требуя, чтобы конкретные методы validate возвращали проверенное зна- чение, мы оставляем им возможность очистить, преобразовать или норма-лизовать полученные данные. В данном случае значение value перед воз- вратом очищается от начальных и конечных пробелов. Пользователям модуля model_v5.py все эти детали знать необязательно. Важно лишь, что они получают возможность использовать классы Quantity и NonBlank для автоматизации проверки атрибутов экземпляра. Последняя версия класса LineItem приведена в примере 20.7. Пример 20.7. bulkfood_v5.py: использование дескрипторов Quantity и NonBlank в классе LineItem import model_v5 as model /g110 class LineItem: description = model.NonBlank() /g111 weight = model.Quantity() price = model.Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self .weight * self .price /g110 Импортируем модуль model_v5 и попутно сопоставляем ему более корот- кое имя. /g111 Используем model.NonBlank . Больше ничего в коде не изменилось.\n--- Страница 668 ---\n668 Глава 20. Дескрипторы атрибутов Приведенные в этой главе варианты класса LineItem демонстрируют типичное применение дескрипторов для управления атрибутами-данными. Такой дескрип-тор называют еще переопределяющим, поскольку его метод __set__ переопреде- ляет (т. е. перехватывает и подменяет) установку одноименного атрибута в управ-ляемом экземпляре. Однако существуют и непереопределяющие дескрипторы. Различие между ними мы подробно изучим в следующем разделе. Переопределяющие и непереопределяющие дескрипторы Напомним, что в способе обработки атрибутов в Python существует важная асим- метрия. При чтении атрибута через экземпляр обычно возвращается атрибут, определенный в этом экземпляре, а если такого атрибута в экземпляре не суще-ствует, то атрибут класса. С другой стороны, в случае присваивания атрибуту эк-земпляра обычно создается атрибут в этом экземпляре, а класс вообще никак не затрагивается. Эта асимметрия распространяется и на дескрипторы, в результате чего обра- зуются две категории дескрипторов, различающиеся наличием или отсутствием метода __set__ . Чтобы увидеть отличия в поведении, нам понадобится несколько классов, и код в примере 20.8 станет нашим тестовым стендом. Все методы __get__ и __set__ в примере 20.8 вызывают print_ args , чтобы их вызовы были отчетливо видны. Понимать, как устроены вспомогательные функции print_args , cls_name и display необязательно, так что не отвлекайтесь на них. Пример 20.8. descriptorkinds.py: простые классы для изучения поведения переопределяющих и непереопределяющих дескрипторов ### вспомогательные функции для отображения ### def cls_name(obj_or_cls): cls = type(obj_or_cls) if cls is type: cls = obj_or_cls return cls.__name__.split('.')[-1] def display(obj): cls = type(obj) if cls is type: return '<class {}>'.format(obj.__name__) elif cls in [type(None), int]: return repr(obj) else: return '<{} object>'.format(cls_name(obj)) def print_args(name, *args):\n--- Страница 669 ---\n669 Переопределяющие и непереопределяющие дескрипторы pseudo_args = ', '.join(display(x) for x in args) print('-> {}.__{}__({})'.format(cls_name(args[0]), name, pseudo_args)) ### существенные для этого примера классы ### class Overriding: /g110 \"\"\"он же дескриптор данных или принудительный дескриптор\"\"\" def __get__(self, instance, owner): print_args('get', self, instance, owner) /g111 def __set__(self, instance, value): print_args('set', self, instance, value) class OverridingNoGet: /g112 \"\"\"переопределяющий дескриптор без ``__get__``\"\"\" def __set__(self, instance, value): print_args('set', self, instance, value) class NonOverriding: /g113 \"\"\"он же дескриптор без данных или маскируемый дескриптор\"\"\" def __get__(self, instance, owner): print_args('get', self, instance, owner) class Managed: /g114 over = Overriding() over_no_get = OverridingNoGet() non_over = NonOverriding() def spam(self): /g115 print('-> Managed.spam({})'.format(display(self))) /g110 Типичный переопределяющий дескрипторный класс с методами __get__ и __set__ . /g111 В этом примере функция print_args вызывается из каждого метода де- скриптора. /g112 Переопределяющий дескриптор без метода __get__ . /g113 Здесь нет метода __set__ , т. е. этот дескриптор непереопределяющий. /g114 Управляемый класс, в котором используется по одному экземпляру каждо- го дескрипторного класса. /g115 Метод spam включен для сравнения, потому что методы – также дескрипто- ры. В следующих разделах мы исследуем поведение операций чтения и записи атрибутов класса Managed и одного его экземпляра с помощью каждого из опреде- ленных выше дескрипторов. Переопределяющий дескриптор Дескриптор, в котором реализован метод __set__ , называется переопределяю- щим, потому что несмотря на то, что этот дескриптор является атрибутом класса,\n--- Страница 670 ---\n670 Глава 20. Дескрипторы атрибутов он перехватывает все попытки присвоить значение атрибутам экземпляра. Именно так реализован дескриптор в примере 20.2. Свойства также являются переопреде-ляющими дескрипторами: если мы не предоставим свою функцию установки, то по умолчанию будет использован метод __set__ из класса property , который возбуж- дает исключение AttributeError , показывающее, что атрибут можно только читать. Эксперименты с переопределяющим дескриптором показаны в примере 20.9. Пример 20.9. Поведение переопределяющего дескриптора: obj.over – экземпляр класса Overriding (из примера 20.8) >>> obj = Managed() /g110 >>> obj.over /g111 -> Overriding.__get__(<Overriding object>, <Managed object>, <class Managed>)>>> Managed.over /g112 -> Overriding.__get__(<Overriding object>, None, <class Managed>)>>> obj.over = 7 /g113 -> Overriding.__set__(<Overriding object>, <Managed object>, 7)>>> obj.over /g114 -> Overriding.__get__(<Overriding object>, <Managed object>, <class Managed>)>>> obj.__dict__['over'] = 8 /g115 >>> vars(obj) /g116 {'over': 8} >>> obj.over /g117 -> Overriding.__get__(<Overriding object>, <Managed object>, <class Managed>) /g110 Создаем объект Managed для тестирования. /g111 obj.over активирует метод дескриптора __get__ , передавая ему управляе- мый экземпляр obj во втором аргументе. /g112 Managed.over активирует метод дескриптора __get__ , передавая ему None во втором аргументе ( instance ). /g113 Присваивание obj.over активирует метод дескриптора __set__ , передавая ему значение 7 в последнем аргументе. /g114 Чтение obj.over по-прежнему активирует метод дескриптора __get__ . /g115 У становка значения непосредственно в obj.__dict__ в обход дескриптора. /g116 Проверяем, что значение попало в obj.__dict__ и ассоциировано с ключом over . /g117 Однако даже при наличии атрибута экземпляра с именем over дескриптор Managed.over все равно переопределяет попытки читать obj.over . Переопределяющий дескриптор без __get__ Обычно в переопределяющих дескрипторах реализованы оба метода __set__ и __get__ , но, как мы видели в примере 20.1, можно также реализовать только __set__ . В таком случае дескриптор обрабатывает только операцию записи. Чте- ние дескриптора через экземпляр вернет сам объект дескриптора, потому что не\n--- Страница 671 ---\n671 Переопределяющие и непереопределяющие дескрипторы существует метода __get__ , который мог бы перехватить эту операцию доступа. Если путем прямой записи в атрибут экземпляра __dict__ был создан одноимен- ный атрибут экземпляр с другим значением, то метод __set__ все равно будет пере- хватывать последующие попытки изменить этот атрибут, однако его чтение просто вернет новое значение атрибута, а не объект дескриптора. Другими словами, атри-бут экземпляра маскирует дескриптор, но только при чтении. См. пример 20.10. Пример 20.10. Переопределяющий дескриптор без __get__ : obj.over_no_get – экземпляр класса OverridingNoGet (из примера 20.8) >>> obj.over_no_get /g110 <__main__.OverridingNoGet object at 0x665bcc>>>> Managed.over_no_get /g111 <__main__.OverridingNoGet object at 0x665bcc>>>> obj.over_no_get = 7 /g112 -> OverridingNoGet.__set__(<OverridingNoGet object>, <Managed object>, 7)>>> obj.over_no_get /g113 <__main__.OverridingNoGet object at 0x665bcc>>>> obj.__dict__['over_no_get'] = 9 /g114 >>> obj.over_no_get /g115 9>>> obj.over_no_get = 7 /g116 -> OverridingNoGet.__set__(<OverridingNoGet object>, <Managed object>, 7)>>> obj .over_no_get /g117 9 /g110 В этом переопределяющем дескрипторе нет метода __get__ , поэтому чтение obj.over_no_get извлекает экземпляр дескриптора из класса. /g111 То же происходит, если извлечь экземпляр дескриптора непосредственно из управляемого класса. /g112 Попытка присвоить значение атрибуту obj.over_no_get активирует метод дескриптора __set__ . /g113 Поскольку наш метод __set__ не производит никаких изменений, повтор- ное чтение obj.over_no_get извлекает все тот же экземпляр дескриптора из управляемого класса. /g114 У станавливаем атрибут экземпляра с именем over_no_get через атрибут __dict__ экземпляра. /g115 Теперь новый атрибут экземпляра over_no_get маскирует дескриптор, но только при чтении. /g116 Попытка присвоить значение атрибуту obj.over_no_get по-прежнему про- ходит через метод __set__ дескриптора. /g117 Но при чтении дескриптор замаскирован до тех пор, пока существует одно- именный атрибут экземпляра. Непереопределяющий дескриптор Дескриптор, в котором не реализован метод __set__ , называется непереопреде- ляющим. У становка атрибута экземпляра с таким же именем маскирует дескрип-\n--- Страница 672 ---\n672 Глава 20. Дескрипторы атрибутов тор, делая его бесполезным для обработки соответствующего атрибута в этом экземпляре. Методы реализованы как непереопределяющие дескрипторы. В при-мере 20.11 показана работа непереопределяющего дескриптора. Пример 20.11. Поведение непереопределяющего дескриптора: obj.non_over – экземпляр класса NonOverriding (из примера 20.8) >>> obj = Managed() >>> obj.non_over /g110 -> NonOverriding.__get__(<NonOverriding object>, <Managed object>, <class Managed>)>>> obj.non_over = 7 /g111 >>> obj.non_over /g112 7>>> Managed.non_over /g113 -> NonOverriding.__get__(<NonOverriding object>, None, <class Managed>)>>> del obj.non_over /g114 >>> obj.non_over 6-> NonOverriding.__get__(<NonOverriding object>, <Managed object>, <class Managed>) /g110 obj.non_over активирует метод дескриптора __get__ , передавая ему obj во втором аргументе. /g111 Managed.non_over – непереопределяющий дескриптор, поэтому не существует метода __set__ , который мог бы вмешаться в эту операцию при- сваивания. /g112 Теперь в obj есть атрибут экземпляра с именем non_over , который маскиру- ет одноименный дескрипторный атрибут в классе Managed . /g113 Дескриптор Managed.non_over по-прежнему существует и перехватывает эту операцию доступа через класс. /g114 Если атрибут экземпляра non_over удалить… /g115 … то чтение obj.non_over активирует метод __get__ дескриптора в классе, однако вторым аргументом будет управляемый экземпляр. При обсуждении этих понятий авторы Python пользуются раз- личными терминами. Переопределяющие дескрипторы называют также дескрипторами данных (data descriptor) или принудитель-ными дескрипторами (enforced descriptor). Непереопределяю-щие дескрипторы известны также под названием дескрипторов без данных (nondata descriptor) или маскируемых дескрипторов (shadowable descriptor). В предыдущих примерах мы видели несколько операций присваивания атри- буту экземпляра с таким же именем, как у дескриптора; результаты оказываются различны в зависимости от того, реализован в дескрипторе метод __set__ или нет.\n--- Страница 673 ---\n673 Методы являются дескрипторами У становку атрибутов класса невозможно контролировать с помощью дескрип- торов, присоединенных к тому же классу. В частности, это означает, что сами де-скрипторные атрибуты можно затереть путем присваивания на уровне класса, как объясняется в следующем разделе. Перезаписывание дескриптора в классе Независимо от того, является дескриптор переопределяющим или нет, его можно перезаписать путем присваивания на уровне класса. Это техника парти-занского латания, но в примере 20.12 дескрипторы подменяются целыми числами, что, безусловно, приведет к «поломке» любого класса, работа которого зависит от дескрипторов. Пример 20.12. Дескриптор можно перезаписать в самом классе >>> obj = Managed() /g110 >>> Managed.over = 1 /g111 >>> Managed.over_no_get = 2>>> Managed.non_over = 3>>> obj.over, obj.over_no_get, obj.non_over /g112 (1, 2, 3) /g110 Создаем новый экземпляр для последующего тестирования. /g111 Перезаписываем дескрипторные атрибуты в классе. /g112 Дескрипторов больше нет. Пример 20.12 вскрывает еще одну асимметрию в чтении и записи атрибутов: хотя атрибут класс можно контролировать с помощью дескриптора с методом __get__ , присоединенного к управляемому классу, но запись атрибута класса невозможно перехватить с помощью дескриптора с методом __set__ , присоединенного к тому же классу. Чтобы контролировать установку атрибутов класса, необходи- мо присоединить дескрипторы к классу класса – иначе говоря, к метаклассу. По умолчанию метаклассом всех пользовательских классов является type , а добавить атрибут в класс type невоз- можно. Но в главе 21 мы научимся создавать собственные мета- классы. Методы являются дескрипторами Функция внутри класса становится связанным методом, потому что у всех опре- деленных пользователем функций имеется метод __get__ , а, значит, будучи при- соединены к классу, они ведут себя как дескрипторы. В примере 20.13 демонстри-руется чтение метода spam из класса Managed в примере 20.8.\n--- Страница 674 ---\n674 Глава 20. Дескрипторы атрибутов Пример 20.13. Метод является непереопределяющим дескриптором >>> obj = Managed() >>> obj.spam /g110 <bound method Managed.spam of <descriptorkinds.Managed object at 0x74c80c>>>>> Managed.spam /g111 <function Managed.spam at 0x734734>>>> obj.spam = 7 /g112 >>> obj.spam7 /g110 Чтение obj.spam возвращает объект, представляющий связанный метод. /g111 Однако чтение Managed.spam возвращает функцию. /g112 Присваивание атрибуту obj.spam маскирует атрибут класса, делая метод spam недоступным через объект obj. Поскольку в функциях не реализован метод __set__ , они являются непере- определяющими дескрипторами, что видно из последней строки примера 20.13. Еще отметим, что в примере 20.13 чтение obj.spam и Managed.spam дает разные объекты. Как для любых дескрипторов, метод __get__ функции возвращает ссыл- ку на себя, если доступ осуществляется через управляемый класс. Но при доступе через экземпляр метод __get__ функции возвращает объект связанного метода: вызываемый объект, который обертывает функцию и связывает управляемый эк-земпляр (например, obj) с первым аргументом функции (т. е. self ) – точно так же, как делает функция functools.partial (см. раздел «Фиксация аргументов с помощью functools.partial» главы 5). Чтобы лучше понять этот механизм, рассмотрим пример 20.14. Пример 20.14. method_is_descriptor .py: класс Text , наследующий UserString import collections class Text(collections.UserString): def __repr__(self): return 'Text({!r})'.format(self.data) def reverse(self): return self[::-1] Исследуем работу метода Text.reverse . Пример 20.15. Эксперименты с методом >>> word = Text('forward') >>> word /g110\n--- Страница 675 ---\n675 Методы являются дескрипторами Text('forward') >>> word.reverse() /g111 Text('drawrof')>>> Text.reverse(Text('backward')) /g112 Text('drawkcab')>>> type(Text.reverse), type(word.reverse) /g113 (<class 'function'>, <class 'method'>)>>> list(map(Text.reverse, ['repaid', (10, 20, 30), Text('stressed')])) /g114 ['diaper', (30, 20, 10), Text('desserts')]>>> Text.reverse.__get__(word) /g115 <bound method Text.reverse of Text('forward')>>>> Text.reverse.__get__(None, Text) /g116 <function Text.reverse at 0x101244e18>>>> word.reverse /g117 <bound method Text.reverse of Text('forward')>>>> word.reverse.__self__ /g118 Text('forward')>>> word.reverse.__func__ is Text.reverse /g119 True /g110 Представление repr экземпляра Text выглядит как вызов конструктора Text , создающего точно такой же экземпляр. /g111 Метод reverse возвращает инвертированный текст. /g112 Метод, вызванный от имени класса, работает как функция. /g113 Обратите внимание на различие типов: function и method . /g114 Метод Text .reverse работает как функция и применим даже к объектам, не являющимся экземплярами Text . /g115 Любая функция является непереопределяющим дескриптором. Если вы- звать ее метод __get__ от имени экземпляра, то будет возвращен метод, свя- занный с этим экземпляром. /g116 Если вызвать метод __get__ , указав в качестве аргумента instance объект None , то будет возвращена сама функция. /g117 Выражение word .reverse приводит к вызову Text .reverse.__get__(word) и возврату связанного метода. /g118 У объекта связанного метода имеется атрибут __self__ , в котором хранится ссылка на экземпляр, от имени которого вызывался метод. /g119 В атрибуте __func__ связанного метода хранится ссылка на исходную функцию, присоединенную к управляемому классу. У объекта связанного метода имеется метод __call__ , который и отвечает за ак- тивацию. Этот метод вызывает исходную функцию, на которую ссылается атрибут __func__ , передавая ей атрибут метода __self__ в первом аргументе. Именно так работает неявное связывание с традиционным аргументом self . Превращение функций в связанные методы – основной пример использования дескрипторов в инфраструктуре языка.\n--- Страница 676 ---\n676 Глава 20. Дескрипторы атрибутов Разобравшись с тем, как работают дескрипторы и методы, дадим несколько практических советов по их использованию. Советы по использованию дескрипторов Ниже перечислены некоторые практические последствия только что описанных характеристик дескрипторов. Для простоты пользуйтесь классом property Встроенный класс property создает переопределяющие дескрипторы, в ко- торых реализованы оба метода __set__ и __get__ , даже если вы сами не за- давали метод установки. Подразумеваемый по умолчанию метод __set__ возбуждает исключение AttributeError: can't set attribute , поэтому свойство – это простейший способ создать доступный только для чтения атрибут и избежать проблемы, описанной ниже. В дескрипторах только для чтения необходим метод __set__ Если вы используете дескрипторный класс для реализации атрибута, до- ступного только для чтения, то не забывайте реализовывать оба метода __get__ и __set__ , иначе одноименный атрибут экземпляра замаскирует дескриптор. Метод __set__ атрибута, доступного только для чтения, дол- жен просто возбуждать исключение AttributeError с подходящим сообще- нием4. Проверяющим дескрипторам достаточно одного метода __set__ Если дескриптор предназначен только для проверки значений, то метод __set__ должен проверять полученный аргумент value и, если он правилен, то устанавливать значение непосредственно в атрибуте __dict__ экземпля- ра, используя в качестве ключа имя экземпляра дескриптора. Тогда чтение атрибута с таким же именем из экземпляра будет производиться макси-мально быстро, т. к. не требует наличия метода __get__ . Код см. в приме- ре 20.1. Кэширование можно эффективно реализовать при наличии одного лишь __get__ Если вы напишете только метод __get__ , то получите непереопределяющий дескриптор. Они полезны, когда требуется выполнить накладные вычис-ления и кэшировать результат, установив атрибут экземпляра с таким же именем. Одноименный атрибут экземпляра маскирует дескриптор, поэто-му при последующем доступе к этому атрибуту значение будет извлекаться непосредственно из атрибута __dict__ экземпляра в обход метода __get__ дескриптора. 4 Python не блещет единообразием в таких сообщениях. При попытке изменить атрибут c.real ком- плексного числа выдается сообщение AttributeError: read-only attribute , а при попытке изменить c.conjugate (метод класса complex ) – сообщение AttributeError: 'complex' object attribute 'conjugate' is read-only .\n--- Страница 677 ---\n677 Строка документации дескриптора и перехват удаления Неспециальные методы можно замаскировать атрибутами экземпляра Поскольку в функциях и методах реализован только метод __get__ , они не перехватывают попытки установить одноименные атрибуты экземпляра, так что после простого присваивания my_obj.the_method = 7 последующий доступ к the_method через данный экземпляр вернет число 7, хотя на других экземплярах это никак не отразится. Однако на специальные методы это не распространяется. Интерпретатор ищет специальные методы только в са-мом классе, т. е. repr(x) всегда вычисляется как x.__class__.__repr__(x) , так что установка атрибута __repr__ , определенного в x, не влияет на результат repr(x) . По той же причине существование атрибута с именем __getattr__ в экземпляре не испортит обычный алгоритм доступа к атрибутам. Может показаться, что простота переопределения неспециальных методов в экземплярах влечет за собой хрупкость дизайна и ошибки, но в моей 15-летней практике программирования на Python это ни разу не приводило к проблемам. С другой стороны, если вы часто создаете динамические атрибуты, имена которых берутся из данных, не контролируемых вами (как в предыдущих главах этой кни-ги), то об этом следует помнить и, наверное, включить какую-то фильтрацию или экранирование имен, чтобы динамические атрибуты имели смысл. Класс FrozenJSON из примера 19.6 защищен от маскирования методов атрибутами экземпляра, потому что в нем есть только специальные методы и метод класса build . Методы класса без- опасны, если обращение к ним производится только через класс, как в выражении FrozenJSON.build в примере 19.6 – которое я впоследствии заменил методом __new__ в примере 19.7. Класс Record (примеры 19.9 и 19.11) и его подклассы также безопасны: в них используются только специальные методы, методы класса, статические методы и свойства. Свойства являются переопре-деляющими дескрипторами, поэтому не могут быть замещены атрибутами экземпляра. В заключение рассмотрим два особенности свойств, которые не были освеще- ны в контексте дескрипторов: документирование и обработка попыток удалить управляемый атрибут. Строка документации дескриптора и перехват удаления Строка документации дескрипторного класса нужна для документирования эк- земпляров дескриптора в управляемом классе. На рис. 20.6 показано, как выгля-дит справка по классу LineItem с дескрипторами Quantity и NonBlank из приме- ров 20.6 и 20.7.\n--- Страница 678 ---\n678 Глава 20. Дескрипторы атрибутов Рис. 20.6. Оболочка Python после выполнения команд help(LineItem.weight) и help(LineItem) Это не вполне удовлетворительно. В случае LineItem неплохо было бы доба- вить информацию о том, что вес weight должен быть выражен в килограммах. Для свойств это тривиальная задача, потому каждое свойство управляет одним кон-кретным атрибутом. Но дескрипторный класс Quantity используется для обоих атрибутов weight и price .5 Вторая деталь, которую мы обсуждали для свойств, но опустили при рассмотре- нии дескрипторов – перехват попыток удалить управляемый атрибут. Это можно сделать, реализовав метод __delete__ вместе или вместо обычных методов __get__ и (или) __set__ в дескрипторном классе. Написание «дурацкого» дескрипторного класса с методом __delete__ оставляю в качестве упражнения досужему читателю. Резюме В начале главы мы продолжили тему класса LineItem из главы 19. В примере 20.1 мы заменили свойства дескрипторами. Мы видели, что дескриптор – это класс, экземпляры которого занимают место атрибутов в управляемом классе. Для об-суждения этого механизма пришлось ввести специальные термины, например: управляемый экземпляр и атрибут хранения. 5 Задать текст справки для каждого экземпляра дескриптора на удивление трудно. Одно из возмож- ных решений – динамически строить обертывающий класс для каждого экземпляра дескриптора.\n--- Страница 679 ---\n679 Дополнительная литература В разделе «LineItem попытка № 4: автоматическая генерация имен атрибутов хранения» мы отказались от требования явно задавать в объявлениях дескриптора Quantity параметр storage_name ; это избыточно и чревато ошибками, потому что имя всегда должно совпадать с именем атрибута в левой части того оператора при-сваивания, в котором создается дескриптор. Решение состоит в том, чтобы генери-ровать имена storage_name , комбинируя имя дескрипторного класса со счетчиком, определенным на уровне класса (например, '_Quantity#1' ). Далее мы сравнили размер кода, а также сильные и слабые стороны дескрип- торного класса и фабрики свойств, основанной на идиомах функционального про-граммирования. Второй подход отлично работает и в некоторых отношениях даже проще, но первый обладает большей гибкостью и является стандартным. Главное преимущество дескрипторного класса нашло применение в разделе «LineItem по- LineItem по- по- пытка № 5: новый тип дескриптора»: наследование для повторного использова-ния кода при построении специализированных дескрипторов с пересекающейся функциональностью. Затем мы изучили поведение дескрипторов, включающих и не включающих метод __set__ , отметив принципиальное различие между переопределяющими и непереопределяющими дескрипторами. Проведя детальное тестирование, мы по-няли, когда дескрипторы перехватывают управление, а когда маскируются, обхо-дятся или затираются. После этого мы исследовали специальную категорию непереопределяющих дескрипторов: методы. Тестирование в оболочке показало, как благодаря прото-колу дескрипторов присоединенная к классу функция становится методом при обращении через экземпляр. В конце главы мы вкратце упомянули о том, как работает документирование и удаление дескрипторов. В этой главе мы столкнулись с некоторыми проблемами, решить которые мож- но только с помощью метапрограммирования классов, но отложили их до главы 21. Дополнительная литература Помимо официального справочного материала в главе «Модель данных» ( http:// bit.ly/1GsZwss ), ценным ресурсом является пособие Раймонда Хэттингера «Descriptor HowT o Guide» ( http://bit.ly/1HGwlS3 ), оно входит в подборку прак- тических руководств ( http://bit.ly/1HGwnsV ), являющуюся частью официальной документации по Python. Как и во всем, что касается объектной модели в Python, книга Алекса Мартелли «Python in a Nutshell», издание 2 (O'Reilly), является авторитетным и объектив-ным источником, пусть и несколько устаревшим: основные обсуждавшиеся в этой главе механизмы появились в версии Python 2.2, задолго до версии 2.5, которая охвачена в этой книге. Мартелли также подготовил презентацию «Python's Object Model», в которой всесторонне рассматриваются свойства и дескрипторы (слай-ды – по адресу http://bit.ly/1HGwoxa , видео – по адресу http://bit.ly/1HGwp46 ). Настоятельно рекомендую.\n--- Страница 680 ---\n680 Глава 20. Дескрипторы атрибутов Версия Python 3 с практическими примерами рассматривается в книге Дэвида Бизли и Брайана К. Джонса «Python Cookbook», издание 3 (O'Reilly), где есть много рецептов, иллюстрирующих дескрипторы. Особо мне хочется отметить ре-цепты 6.12 «Чтение вложенных структур и имеющих переменную длину двоич-ных структур», 8.10 «Свойства с отложенным вычислением», 8.13 «Реализация модели данных или системы типов» и 9.9 «Определение декораторов как клас-сов». В последнем рецепте глубоко освещаются вопросы взаимодействия между декораторами функций, дескрипторами и методами и объясняется, почему деко-ратор функции, реализованный в виде класса с методом __call__ , должен также реализовывать метод __get__ , если его предполагается применять для декориро- вания не только функций, но и методов. Поговорим Проблема self «Чем хуже, тем лучше» – философия проектирования, описанная Ричардом П. Гэбриелом в работе «The Rise of W orse is Better» ( http://bit. ly/1HGwvIZ ). Важнейший приоритет в этой философии – «простота». Вот как это звучит в изложении Гэбриела: Реализация и интерфейс должны быть простыми. Простота реа- лизации даже важнее простоты интерфейса. Простота – самое важ-ное требование при выборе дизайна. Я полагаю, что требование явно задавать self первым аргументом метода – применение принципа «чем хуже, тем лучше» в Python. Про-стота – даже элегантность – реализации достигается за счет пользова-тельского интерфейса: сигнатура метода – def zfill(self, width) – ви- зуально не соответствует его вызову – pobox.zfill(8) . Это соглашение – и использование идентификатора self – впервые появилось в языке Modula-3, но есть и отличие: в Modula-3 интерфейсы объявляются отдельно от реализации, и в объявлении интерфейса ар-гумент self опущен, поэтому, с точки зрения пользователя, у метода в объявлении интерфейса ровно столько же аргументов, сколько задается при его вызове. В этом отношении были улучшены хотя бы сообщения об ошибках: если вызывается определенный пользователем метод с одним аргумен-том, кроме self , – obj .meth() – то в Python 2.7 возбуждается исключение TypeError с сообщением meth() takes exactly 2 arguments (1 given) (meth() принимает ровно 2 аргумента (задан 1)), тогда как в Python 3.4 текст сообщения более вразумителен, т. к. количество аргументов в нем не упоминается, а указывается имя недостающего аргумента: meth()\n--- Страница 681 ---\n681 Поговорим missing 1 required positional argument: 'x' (при вызове meth() не задан 1 обязательный позиционный аргумент: 'x'). Помимо использования self в качестве обязательного аргумента, мишенью для критики часто становится требование указывать его при любом доступе к атрибутам экземпляра 6. Лично меня необходимость набирать self не раздражает: я считаю, что полезно отличать локальные переменные от атрибутов. Я больше возражаю против использования self в предложении def. Но и к этому привыкаешь. Всякий, кому не нравится явное использование self в Python, отнесется к нему гораздо снисходительнее, если взглянет на путаную семантику неявного this в JavaScript. У Гвидо были основательные причины спроектировать self именно таким образом, и он написал о них в своем блоге «История Python» в статье «Adding Support for User-Defined Classes» ( http://bit.ly/1CAyiQ Y ). 6 См., например, знаменитое сообщение А. М. Кухлинга «Бородавки Python» (архивировано) ( http:// bit.ly/1cPSaDh ); самого Кухлинга не очень беспокоит квалификатор self , но он упоминает эту про- блему в числе прочих, быть может, отражая мнения, высказанные в группе comp.lang.python .",
      "debug": {
        "start_page": 653,
        "end_page": 681
      }
    },
    {
      "name": "Глава 21. Метапрограммирование классов 682",
      "content": "--- Страница 682 --- (продолжение)\nГЛАВА 21. Метапрограммирование классов Магия метаклассов не интересна 99 % пользователей. Если вы за-даетесь вопросом, нужны ли они вам, значит, не нужны (люди, кото-рым они нужны, точно знают, что нуждаются в них, и не нуждаются в объяснениях) 1. – Тим Питерс, изобретатель алгоритма timsort и плодовитый программист на Python Метапрограммирование классов – это искусство создания или настройки клас-сов во время выполнения. Классы в Python – полноправные объекты, поэтому функция может в любой момент создать новый класс, не используя ключевое слово class . Декораторы классов – также функции, которые дополнительно умеют инспектировать и изменять декорированный класс и даже заменять его другим. Наконец, метаклассы – самое продвинутое средство метапрограммиро-вания классов: они позволяют создавать целые категории классов со специаль-ными характеристиками, например, уже встречавшиеся нам абстрактные базо-вые классы. Метаклассы – мощный механизм, но правильно пользоваться ими трудно. Декораторы классов часто решают те же проблемы проще. На самом деле, сейчас оправдать применение метаклассов в реальном коде настолько трудно, что мой любимый пояснительный пример в значительной мере утратил притягательность после появления декораторов классов в Python 3. Здесь же обсуждается различие между этапом импорта и этапом выполнения: без его понимания нечего и думать об эффективном метапрограммировании в Python. 1 Сообщение в группе comp.lang.python, озаглавленное: «Acrimony in c.l.p». ( http://bit.ly/1e8iABS ). Это вторая часть сообщения от 23 декабря 2002, процитированного в предисловии. В тот день на TimBot, видно, напало вдохновение.\nГЛАВА 21. Метапрограммирование классов Магия метаклассов не интересна 99 % пользователей. Если вы за-даетесь вопросом, нужны ли они вам, значит, не нужны (люди, кото-рым они нужны, точно знают, что нуждаются в них, и не нуждаются в объяснениях) 1. – Тим Питерс, изобретатель алгоритма timsort и плодовитый программист на Python Метапрограммирование классов – это искусство создания или настройки клас-сов во время выполнения. Классы в Python – полноправные объекты, поэтому функция может в любой момент создать новый класс, не используя ключевое слово class . Декораторы классов – также функции, которые дополнительно умеют инспектировать и изменять декорированный класс и даже заменять его другим. Наконец, метаклассы – самое продвинутое средство метапрограммиро-вания классов: они позволяют создавать целые категории классов со специаль-ными характеристиками, например, уже встречавшиеся нам абстрактные базо-вые классы. Метаклассы – мощный механизм, но правильно пользоваться ими трудно. Декораторы классов часто решают те же проблемы проще. На самом деле, сейчас оправдать применение метаклассов в реальном коде настолько трудно, что мой любимый пояснительный пример в значительной мере утратил притягательность после появления декораторов классов в Python 3. Здесь же обсуждается различие между этапом импорта и этапом выполнения: без его понимания нечего и думать об эффективном метапрограммировании в Python. 1 Сообщение в группе comp.lang.python, озаглавленное: «Acrimony in c.l.p». ( http://bit.ly/1e8iABS ). Это вторая часть сообщения от 23 декабря 2002, процитированного в предисловии. В тот день на TimBot, видно, напало вдохновение.\n--- Страница 683 ---\n683 Фабрика классов Эта тема настолько завораживает , что легко увлечься. Поэтому в самом начале главе я помещаю такое увещевание: Если вы не занимаетесь разработкой каркаса, не пишите метаклассы – разве что для забавы или чтобы на практике освоить концепции. Для начала опишем, как создавать класс на этапе выполнения. Фабрика классов В стандартной библиотеке есть фабрика классов, с которой мы уже неоднократно встречались: collections.namedtuple . Если этой функции передать имя класса и имена атрибутов, то она создаст подкласс tuple , который обеспечивает доступ к элементам по имени и предоставляет метод __repr__ для отладки. Иногда у меня возникала потребность в аналогичной фабрике, порождающей изменяемые объекты. Предположим, что мы пишем приложение для зоомагазина и хотим обрабатывать данные о собаках как простые записи. Плохо, если придется писать такой стереотипный код: class Dog: def __init__(self, name, weight, owner): self.name = name self.weight = weight self .owner = owner Нудно-то как… каждое имя поля встречается по три раза. И даже симпатичного представления repr мы при этом не получили: >>> rex = Dog('Rex', 30, 'Bob')>>> rex<__main__.Dog object at 0x2865bac> Позаимствовав идею у collections.namedtuple , напишем функцию record_ factory , которая будет создавать простые классы вроде Dog на лету. В примере 21.1 показано, как она должна работать. Пример 21.1. Тестирование record_factory , простой фабрики классов >>> Dog = record_factory('Dog', 'name weight owner') /g110 >>> rex = Dog('Rex', 30, 'Bob') /g111 >>> rexDog(name='Rex', weight=30, owner='Bob')>>> name, weight, _ = rex /g112 >>> name, weight('Rex', 30)>>> \"{2}'s dog weighs {1}kg\".format(*rex) /g113 \"Bob's dog weighs 30kg\">>> rex.weight = 32 /g114 >>> rex\n--- Страница 684 ---\n684 Глава 21. Метапрограммирование классов Dog(name='Rex', weight=32, owner='Bob') >>> Dog.__mro__ /g115 (<class 'factories.Dog'>, <class 'object'>) /g110 Сигнатура фабрики похожа на сигнатуру namedtuple : имя класса, а за ним строка имен атрибутов через пробел или запятую. /g111 У добное представление repr . /g112 Экземпляры являются итерируемыми объектами, поэтому их можно рас- паковывать в момент присваивания… /g113 … или при передаче функциям типа format . /g114 Экземпляр записи изменяемый. /g115 Вновь созданный класс наследует object – никакой связи с нашей фабри- кой нет. Код record_factory приведен в примере 21.2.2 Пример 21.2. record_factory.py: простая фабрика классов def record_factory(cls_name, field_names): try: field_names = field_names.replace(',', ' ').split() /g110 except AttributeError: # нет .replace или .split pass # предполагаем, что это уже последовательность идентификаторов field_names = tuple(field_names) /g111 def __init__(self, *args, **kwargs): /g112 attrs = dict(zip(self.__slots__, args)) attrs.update(kwargs) for name, value in attrs.items(): setattr(self, name, value) def __iter__(self): /g113 for name in self.__slots__: yield getattr(self, name) def __repr__(self): /g114 values = ', '.join('{}={!r}'.format(*i) for i in zip(self.__slots__, self)) return '{}({})'.format(self.__class__.__name__, values) cls_attrs = dict(__slots__ = field_names, /g115 __init__ = __init__, __iter__ = __iter__, __repr__ = __repr__) return type(cls_name, (object,), cls_attrs) /g116 /g110 Динамическая типизация в действии: пытаемся разбить field_names по за- пятым или пробелам; если не получается, предполагаем, что это уже итери-руемый объект, по одному имени в каждом элементе. 2 Спасибо моему другу Х. С. Буэно, предложившему это решение.\n--- Страница 685 ---\n685 Фабрика классов /g111 Строим кортеж имен атрибутов, он станет атрибутом __slots__ нового класса; заодно он определяет порядок полей при распаковке и в представ-лении методом __repr__ . /g112 Эта функция станет методом __init__ в новом классе. Она принимает по- зиционные и (или) именованные аргументы. /g113 Реализуем метод __iter__ , чтобы экземпляры класса были итерируемыми объектами; отдаем значения полей в порядке, определяемом атрибутом __slots__ . /g114 Порождаем удобное представление, обходя __slots__ и self . /g115 Строим словарь атрибутов класса. /g116 Конструируем и возвращаем новый класс, вызывая конструктор type . Обычно мы рассматриваем type как функцию, потому что так ее и используем, например, мы пишем type(my_object) , чтобы получить класс объекта – то же са- мое, что my_object.__class__ . Однако на самом деле type – класс. Он ведет себя, как класс, который возвращает новый класс при вызове с тремя аргументами: MyClass = type('MyClass', (MySuperClass, MyMixin), {'x': 42, 'x2': lambda self: self.x * 2}) Три аргумента конструктора type называются name , bases и dict , последний из них является отображением, состоящим из имен и значений атрибутов нового класса. Показанный выше код эквивалентен такому: class MyClass(MySuperClass, MyMixin): x = 42 def x2(self): return self.x * 2 Новым здесь является то, что экземпляры type – это классы, например MyClass здесь или Dog в примере 21.1. Таким образом, в последней строке функции record_factory строится класс с именем, равным значению cls_name , наследующий object и имеющий атрибуты класса __slots__ , __init__ , __iter__ и __repr__ , последние три из которых являют- ся методами экземпляра. Мы могли бы назвать атрибут класса __slots__ как-то иначе, но тогда при- шлось бы реализовывать метод __setattr__ , проверяющий имена атрибутов, ко- торым присваиваются значения, потому что мы хотим, чтобы в наших классах, подобных записям, набор атрибутов всегда был один и тот же и чтобы атрибуты в нем следовали в одном и том же порядке. Напомню, однако, что основное назна-чение __slots__ – экономия памяти в случае, когда экземпляров миллионы, и что использование __slots__ сопряжено с некоторыми недостатками, описанными в разделе «Экономия памяти с помощью атрибута класса __slots__» главы 9. Вызов type с тремя аргументами – типичный способ динамического создания класса. Заглянув в исходный код функции collections.namedtuple (http://bit. ly/1HGwxRl ), вы увидите другой подход: там имеется переменная _class_template ,\n--- Страница 686 ---\n686 Глава 21. Метапрограммирование классов шаблон исходного кода в виде строки, а функция namedtuple подставляет в него значения, вызывая метод _class_template.format( …). Получившийся исходный код затем интерпретируется с помощью встроенной функции exec . Занимаясь метапрограммированием на Python, лучше избегать функций exec и eval . Они небезопасны, если получают на вход строки (даже фрагменты) из источников, не заслуживающих до-верия. Python располагает достаточным набором средств интро-спекции, чтобы в большинстве случаев обойтись без exec и eval . Однако разработчики ядра Python решили использовать exec при реализации namedtuple . При таком подходе сгенерированный ис- ходный код класса можно получить из атрибута ._source (http:// bit.ly/1HGwAfW ). У экземпляров классов, созданных функцией record_factory , есть ограничение: они не сериализуемы, т. е. к ним неприменимы функции dump и load из модуля pickle . Решение этой проблемы выходит за рамки настоящего примера, цель которого – продемонстрировать использование класса type в простом случае. Полное решение смотрите в исходном коде collections .nameduple (http://bit. ly/1HGwxRl ); ищите по слову «pickling». Декоратор класса для настройки дескрипторов Когда мы расстались с классом LineItem в разделе «LineItem попытка № 5: новый тип дескриптора» главы 20, остался нерешенным вопрос о содержательных име-нах атрибутов хранения: значение атрибута, например weight , хранилось в атрибу- те экземпляра с именем вида _Quantity#0 , что затрудняло отладку. Получить имя атрибута хранения от дескриптора в примере 20.7 можно с помощью такого кода: >>> LineItem.weight.storage_name'_Quantity#0' Но было бы лучше, если бы имена атрибутов хранения включали имя управля- емого атрибута, например: >>> LineItem.weight.storage_name'_Quantity#weight' Напомним, что в разделе «LineItem попытка № 4: автоматическая генерация имен атрибутов хранения» главы 20 мы не могли использовать содержательные имена атрибутов хранения, потому что в момент создания дескриптора нет ни-какой возможности узнать имя управляемого атрибута (т. е. атрибута класса, с которым будет связан дескриптор, например, weight в примерах выше). Но по- сле того как весь класс собран и дескрипторы привязаны к атрибутам класса, мы\n--- Страница 687 ---\n687 Декоратор класса для настройки дескрипторов можем проинспектировать класс и сопоставить дескрипторам подходящие имена атрибутов хранения. Это можно было бы сделать в методе __new__ класса LineItem , чтобы к моменту, когда дескрипторы используются в методе __init__ , уже были установлены правильные имена атрибутов хранения. Проблема в том, что исполь-зование __new__ для этой цели означает растранжиривание ресурсов: __new__ будет работать при создании каждого экземпляра LineItem , хотя привязка дескриптора к управляемому атрибуту уже не изменится после создания самого класса LineItem . Поэтому устанавливать имена атрибутов хранения нужно в момент создания класса. Это можно сделать с помощью декоратора класса или метакласса. Сначала пойдем по простому пути. Декоратор класса очень похож на декоратор функции: это функция, которая получает объект класса и возвращает тот же самый или модифицированный класс. В примере 21.3 класс LineItem компилируется интерпретатором и получаю- щийся в результате объект класса передается функции model.entity . Python свя- жет глобальное имя с объектом, который вернет эта функция. В данном примере model.entity возвращает тот же самый класс LineItem , но с измененным атрибутом storage_name в каждом экземпляре дескриптора. Пример 21.3. bulkfood_v6.py: класс LineItem с дескрипторами Quantity и NonBlank import model_v6 as model @model.entity /g110 class LineItem: description = model.NonBlank() weight = model.Quantity() price = model.Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight self.price = price def subtotal(self): return self .weight * self .price /g110 Единственное изменение – добавление декоратора. В примере 21.4 приведена реализация декоратора. Показан только новый код в конце файла model_v6.py ; все остальное не отличается от файла model_v5.py (при- мер 20.6). Пример 21.4. model_v6.py: декоратор класса def entity(cls): /g110 for key, attr in cls.__dict__.items(): /g111 if isinstance(attr, Validated): /g112 type_name = type(attr).__name__\n--- Страница 688 ---\n688 Глава 21. Метапрограммирование классов attr.storage_name = '_{}#{}'.format(type_name, key) /g113 return cls /g114 /g110 Декоратор получает класс в качестве аргумента. /g111 Обходим словарь, содержащий атрибуты класса. /g112 Если встретился один из наших дескрипторов Validated … /g113 … то формируем storage_name из имени дескрипторного класса и имени управляемого атрибута (например, _NonBlank#description ). /g114 Возвращаем модифицированный класс. Doctest-скрипты в файле bulkfood_v6.py доказывают, что мы добились успеха. Так, в примере 21.5 видны имена атрибутов хранения в экземпляре LineItem . Пример 21.5. bulkfood_v6.py: doctest-скрипты для проверки атрибутов дескрипторов storage_name >>> raisins = LineItem('Golden raisins', 10, 6.95) >>> dir(raisins)[:3]['_NonBlank#description', '_Quantity#price', '_Quantity#weight']>>> LineItem.description.storage_name'_NonBlank#description'>>> raisins.description'Golden raisins'>>> getattr(raisins, '_NonBlank#description')'Golden raisins' Не очень сложно. Декораторы классов – более простой способ решения зада- чи, для которой раньше приходилось использовать метакласс: настройки класса в момент создания. Существенный недостаток декораторов класса заключается в том, они воздей- ствуют только на класс, к которому применяются. То есть подклассы декориро-ванного класса могут унаследовать внесенные декоратором изменения, а могут и не унаследовать – все зависит от характера изменений. В следующих разделах мы исследуем эту проблему и способы ее решения. Что когда происходит: этап импорта и этап выполнения Для успешного метапрограммирования необходимо знать, когда интерпретатор Python обрабатывает каждый блок кода. Программисты на Python употребля-ют термины «этап импорта» и «этап выполнения», но они определены нестрого, так что между ними существует ничейная земля. На этапе импорта интерпрета-тор производит синтаксический анализ исходного кода py-модуля сверху вниз за один проход и генерирует исполняемый байт-код. На этом этапе обнаруживаются синтаксические ошибки. Если в локальном кэше __pycache__ существует акту- альный pyc-файл, то этот этап пропускается, поскольку уже имеется готовый к выполнению байт-код.\n--- Страница 689 ---\n689 Что когда происходит: этап импорта и этап выполнения Хотя компиляция, безусловно, является действием, выполняемым на этапе им- порта, на этой стадии могут происходить и другие вещи, потому что почти каждое предложение в Python является исполняемым в том смысле, что в нем может вы-полняться пользовательский код, изменяющий состояние программы. В частности, предложение import – не просто объявление3, оно еще и выполняет весь код, на- ходящийся на верхнем уровне импортируемого модуля, при первом его импорте в память процесса – при последующих операциях импорта того же модуля использу-ется кэшированный код, так что происходит только связывание имен. Этот верхне-уровневый код может делать все, что угодно, включая такие типичные для «этапа выполнения» действия, как подключение к базе данных 4. Потому-то граница между «этапом импорта» и «этапом выполнения» размыта: предложение import может ак- тивировать любые действия, которые принято считать частью «этапа выполнения». В предыдущем абзаце я написал, что на этапе импорта выполняется «весь код, находящийся на верхнем уровне импортируемого модуля», но понятие «код, находящийся на верхнем уровне» требует уточнения. Интерпретатор выполняет предложение def на верхнем уровне модуле, когда этот модуль импортируется, но что получается в результате? Интерпретатор компилирует тело функции (если данный модуль импортируется впервые) и связывает объект функции с глобаль-ным именем, но он отнюдь не выполняет тело функции. Проще говоря, это озна-чает, что интерпретатор определяет верхнеуровневую функцию на этапе импорта, но выполняет ее тело, когда – и если – она будет вызвана на этапе выполнения. Для классов все выглядит по-другому: на этапе импорта интерпретатор выполняет тело каждого класса, даже классов, вложенных в другие классы. Это означает, что определяются атрибуты и методы класса, а затем строится сам объект класса. В этом смысле тело класса является «верхнеуровневым кодом»: оно выполняется на этапе импорта. Все это довольно тонкие и абстрактные материи, поэтому ниже приведено упражнение, которое позволит разобраться, что когда происходит. Демонстрация работы интерпретатора Рассмотрим скрипт evaltime.py , который импортирует модуль evalsupport.py . В обоих модулях есть несколько вызовов print , в которых печатаются маркеры в формате <[N]> , где N – число. Цель следующих упражнений – определить, в какой момент производится каждый вызов. Мои студенты говорили, что эти упражнения помогают лучше понять, как Python обрабатывает исходный код. Потратьте некоторое время, чтобы решить их на бумаге, прежде чем заглядывать в раздел «Решение упраж-нения 1» ниже. 3 В отличие от предложения import в Java, которое служит только объявлением, извещающим ком- пилятор о необходимости загрузить некоторые пакеты. 4 Я не хочу сказать, что подключение к базе данных по самому факту импорта модуля – хорошая идея, а лишь отмечаю, что это возможно.\n--- Страница 690 ---\n690 Глава 21. Метапрограммирование классов Листинги приведены в примерах 21.6 и 21.7. Возьмите бумагу и ручку и – не выполняя код – выпишите маркеры в том порядке, в каком они, по вашему мнению, будут напечатаны. Упражнение 1 Модуль evaltime.py интерактивно импортируется в оболочке Python: >>> import evaltime Упражнение 2 Модуль evaltime.py выполняется из командной строки: $ python3 evaltime.py Пример 21.6. evaltime.py: выпишите пронумерованные маркеры <[N]> в порядке появления на экране from evalsupport import deco_alpha print('<[1]> evaltime module start') class ClassOne(): print('<[2]> ClassOne body') def __init__(self): print('<[3]> ClassOne.__init__') def __del__(self): print('<[4]> ClassOne.__del__') def method_x(self): print('<[5]> ClassOne.method_x') class ClassTwo(object): print('<[6]> ClassTwo body') @deco_alpha class ClassThree(): print('<[7]> ClassThree body') def method_y(self): print('<[8]> ClassThree.method_y') class ClassFour(ClassThree): print('<[9]> ClassFour body') def method_y(self): print('<[10]> ClassFour.method_y') if __name__ == '__main__':\n--- Страница 691 ---\n691 Что когда происходит: этап импорта и этап выполнения print('<[11]> ClassOne tests', 30 * '.') one = ClassOne() one.method_x() print('<[12]> ClassThree tests', 30 * '.') three = ClassThree() three.method_y() print('<[13]> ClassFour tests', 30 * '.') four = ClassFour() four.method_y() print('<[14]> evaltime module end') Пример 21.7. evalsupport.py: модуль, импортируемый evaltime.py print('<[100]> evalsupport module start') def deco_alpha(cls): print('<[200]> deco_alpha') def inner_1(self): print('<[300]> deco_alpha:inner_1') cls.method_y = inner_1 return cls # BEGIN META_ALEPH class MetaAleph(type): print('<[400]> MetaAleph body') def __init__(cls, name, bases, dic): print('<[500]> MetaAleph.__init__') def inner_2(self): print('<[600]> MetaAleph.__init__:inner_2') cls.method_z = inner_2 # END META_ALEPH print('<[700]> evalsupport module end') Решение упражнения 1 В примере 21.8 показано, как выглядит экран при импорте модуля evaltime.py в оболочке Python. Пример 21.8. Упражнение 1: импорт evaltime в оболочке Python >>> import evaltime <[100]> evalsupport module start /g110 <[400]> MetaAleph body /g111 <[700]> evalsupport module end<[1]> evaltime module start\n--- Страница 692 ---\n692 Глава 21. Метапрограммирование классов <[2]> ClassOne body /g112 <[6]> ClassTwo body /g113 <[7]> ClassThree body<[200]> deco_alpha /g114 <[9]> ClassFour body<[14]> evaltime module end /g115 /g110 Весь верхнеуровневый код в evalsupport выполняется на этапе импорта модуля; функция deco_alpha компилируется, но ее тело не выполняется. /g111 Тело функции MetaAleph выполняется. /g112 Тело каждого класса выполняется … /g113 … вложенные классы – не исключение. /g114 Декораторная функция выполняется после обработки тела декорирован- ного класса ClassThree . /g115 В этом упражнении модуль evaltime импортируется, поэтому блок if __name__ == '__main__': никогда не выполняется. Сделаем несколько замечаний по поводу упражнения 1: 1. Вся последовательность действий запускается одним лишь предложением import evaltime . 2. Интерпретатор выполняет тело каждого класса в импортированном модуле и в модуле evalsupport , от которого он зависит. 3. Не удивительно, что интерпретатор обрабатывает тело декорированного класса еще до вызова присоединенной к нему декораторной функции: де-коратор должен получить объект класса, а, значит, этот объект нужно пред-варительно построить. 4. В этом случае выполняется только одна пользовательская функция: деко- ратор deco_alpha . Теперь посмотрим, что происходит в упражнении 2. Решение упражнения 2 В примере 21.9 показано, как выглядит экран после выполнения команды python evaltime.py . Пример 21.9. Упражнение 2: запуск evaltime.py из оболочки ОС $ python3 evaltime.py <[100]> evalsupport module start<[400]> MetaAleph body<[700]> evalsupport module end<[1]> evaltime module start<[2]> ClassOne body<[6]> ClassTwo body<[7]> ClassThree body<[200]> deco_alpha<[9]> ClassFour body /g110\n--- Страница 693 ---\n693 Основы метаклассов <[11]> ClassOne tests <[3]> ClassOne.__init__ /g111 <[5]> ClassOne.method_x<[12]> ClassThree tests <[300]> deco_alpha:inner_1 /g112 <[13]> ClassFour tests <[10]> ClassFour.method_y<[14]> evaltime module end<[4]> ClassOne.__del__ /g113 /g110 До сих пор все, как примере 21.8. /g111 Стандартное поведение класса. /g112 Метод ClassThree.method_y был изменен декоратором deco_alpha , поэтому при вызове three.method_y() выполняется тело функции inner_1 . /g113 Экземпляр ClassOne , связанный с глобальной переменной one, убирается в мусор только по завершении программы. Основная цель упражнения 2 – показать, что действие декоратора класса мо- жет не распространяться на подклассы. В примере 21.6 ClassFour определен как подкласс ClassThree . Декоратор @deco_alpha применяется к ClassThree и заменяет в нем метод method_y , но это никак не отражается на ClassFour . Разумеется, если бы метод ClassFour.method_y вызывал ClassThree.method_y with super( …), то мы увидели бы эффект декоратора, поскольку выполнялась бы функция inner_1 . В следующем разделе мы покажем, что метаклассы больше подходят, когда нужно настроить целую иерархию классов, а не один класс. Основы метаклассов Метакласс – это фабрика классов, но, в отличие от функции наподобие record_ factory из примера 21.2, метакласс записывается в виде класса. На рис. 21.2 изо- бражен метакласс в нотации хреновин и штуковин: одна хреновина порождает другую. Рис. 21.1. Метакласс – это класс, который создает классы\n--- Страница 694 ---\n694 Глава 21. Метапрограммирование классов В объектной модели Python классы являются объектами, поэтому каждый класс должен быть экземпляром какого-то другого класса. По умолчанию классы Python являются экземплярами класса type . Иными словами, type – метакласс для большинства встроенных и пользовательских классов: >>> 'spam'.__class__<class 'str'>>>> str.__class__<class 'type'>>>> from bulkfood_v6 import LineItem>>> LineItem.__class__<class 'type'>>>> type.__class__<class 'type'> Чтобы избежать бесконечного спуска, type является экземпляром себя самого, как видно из последней строки. Обратите внимание – я не говорю, что str или LineItem наследуют классу type . Я утверждаю, что str и LineItem – экземпляры type . И все они являются подклассами object . Возможно, рис. 21.2 поможет вам освоиться в этой странной реальности. Рис. 21.2. Обе диаграммы правильны. На левой показано, что str, type и LineItem – подклассы object . Из правой видно, что str, object и LineItem – экземпляры type , поскольку все они – классы Между классами object и type имеется удивительная связь: object – экземпляр type , а type – подкласс object . Эта связь «ма- гическая»: выразить ее средствами Python невозможно, потому что любой из этих классов должен существовать, прежде чем можно будет определить другой. И тот факт , что type является эк- земпляром самого себя, – тоже магия. Помимо type , в стандартной библиотеке существует еще несколько метаклас- сов, например ABCMeta и Enum . В следующем фрагменте кода показано, что классом\n--- Страница 695 ---\n695 Основы метаклассов collections .Iterable является abc .ABCMeta . Класс Iterable абстрактный, а ABCMeta нет – да и как может быть иначе, если Iterable является экземпляром ABCMeta : >>> import collections >>> collections.Iterable.__class__<class 'abc.ABCMeta'>>>> import abc>>> abc.ABCMeta.__class__<class 'type'>>>> abc.ABCMeta.__mro__(<class 'abc.ABCMeta'>, <class 'type'>, <class 'object'>) Классом ABCMeta также является type . Любой класс является экземпляром type , прямо или косвенно, но только метаклассы являются также подклассами type . Это самое главное, что нужно знать о метаклассах: любой метакласс, в частности AB- CMeta , наследует от type могущество, необходимое для конструирования классов. На рис. 21.3 показана эта важнейшая связь. Рис. 21.3. Iterable – подкласс object и экземпляр ABCMeta . И object , и ABCMeta – экземпляры type , но ключевая связь здесь – тот факт , что ABCMeta еще и подкласс type , поскольку ABCMeta является метаклассом. На этой диаграмме Iterable – единственный абстрактный класс Необходимо твердо запомнить, что все классы являются экземплярами type , а метаклассы – еще и подклассами type , поэтому они работают как фабрики клас- сов. В частности, метакласс может настраивать экземпляры посредством реализа- метакласс может настраивать экземпляры посредством реализа- может настраивать экземпляры посредством реализа- ции __init__ . Метод __init__ метакласса может делать все, на что способен деко-метакласса может делать все, на что способен деко- а может делать все, на что способен деко- ратор, но его действие распространяется глубже, как будет видно из следующего упражнения. Демонстрация работы метакласса Это вариация на тему раздела «Демонстрация работы интерпретатора» выше. Модуль evalsupport.py такой же, как в примере 21.7, а главный скрипт evaltime_ meta.py показан в примере 21.10.\n--- Страница 696 ---\n696 Глава 21. Метапрограммирование классов Пример 21.10. evaltime_meta.py: ClassFive – экземпляр метакласса MetaAleph from evalsupport import deco_alpha from evalsupport import MetaAleph print('<[1]> evaltime_meta module start') @deco_alpha class ClassThree(): print('<[2]> ClassThree body') def method_y(self) print('<[3]> ClassThree.method_y') class ClassFour(ClassThree): print('<[4]> ClassFour body') def method_y(self): print('<[5]> ClassFour.method_y') class ClassFive(metaclass=MetaAleph): print('<[6]> ClassFive body') def __init__(self): print('<[7]> ClassFive.__init__') def method_z(self): print('<[8]> ClassFive.method_y') class ClassSix(ClassFive): print('<[9]> ClassSix body') def method_z(self): print('<[10]> ClassSix.method_y') if __name__ == '__main__': print('<[11]> ClassThree tests', 30 * '.') three = ClassThree() three.method_y() print('<[12]> ClassFour tests', 30 * '.') four = ClassFour() four.method_y() print('<[13]> ClassFive tests', 30 * '.') five = ClassFive() five.method_z() print('<[14]> ClassSix tests', 30 * '.') six = ClassSix() six.method_z() print('<[15]> evaltime_meta module end')\n--- Страница 697 ---\n697 Основы метаклассов И снова возьмите бумагу и ручку и выпишите пронумерованные маркеры <[N]> в порядке их вывода. Упражнение 3 Модуль evaltime_meta.py интерактивно импортируется в оболочке Python. Упражнение 4 Модуль evaltime_meta.py выполняется из командной строки. Решения и анализ приведены ниже. Решение упражнения 3 В примере 21.11 показан результат импорта evaltime_meta.py в оболочке Python. Пример 21.11. Упражнение 3: импорт evaltime_meta в оболочке Python >>> import evaltime_meta <[100]> evalsupport module start<[400]> MetaAleph body<[700]> evalsupport module end<[1]> evaltime_meta module start<[2]> ClassThree body<[200]> deco_alpha<[4]> ClassFour body<[6]> ClassFive body<[500]> MetaAleph.__init__ /g110 <[9]> ClassSix body<[500]> MetaAleph.__init__ /g111 <[15]> evaltime_meta module end /g110 Основное отличие от упражнения 1 состоит в том, что метод MetaAleph. __init__ вызывается для инициализации только что созданного класса ClassFive . /g111 И тот же метод MetaAleph.__init__ инициализирует класс ClassSix , являю- щийся подклассом ClassFive . Интерпретатор Python обрабатывает тело ClassFive , но затем для построения самого тела класса вызывает не type , а MetaAleph . Взглянув на определение класса MetaAleph в примере 21.12, мы увидим, что метод __init__ получает четыре аргу- мента: self Это инициализируемый объект класса (например, ClassFive ). name , bases , dic Те же аргументы, что передаются type для конструирования класса.\n--- Страница 698 ---\n698 Глава 21. Метапрограммирование классов Пример 21.12. evalsupport.py: определение метакласса MetaAleph из примера 21.7 class MetaAleph(type): print('<[400]> MetaAleph body') def __init__(cls, name, bases, dic): print('<[500]> MetaAleph.__init__') def inner_2(self): print('<[600]> MetaAleph.__init__:inner_2') cls .method_z = inner_2 При кодировании метакласса удобно заменить self на cls. На- пример, в методе метакласса __init__ благодаря использованию cls для именования первого аргумента сразу становится понят- но, что конструируемый экземпляр является классом. В теле метода __init__ определяется функция inner_2 , которая затем связыва- ется с методом cls.method_z . Имя cls в сигнатуре MetaAleph.__init__ относится к создаваемому классу (например, ClassFive ). С другой стороны, имя self в сигна- туре inner_2 в конечном итоге будет ссылаться на экземпляр создаваемого класса (например, экземпляр ClassFive ). Решение упражнения 4 В примере 21.13 показан результат запуска команды python evaltime.py из командной строки. Пример 21.13. Упражнение 4: запуск evaltime_meta.py из оболочки ОС $ python3 evaltime.py <[100]> evalsupport module start<[400]> MetaAleph body<[700]> evalsupport module end<[1]> evaltime_meta module start<[2]> ClassThree body<[200]> deco_alpha<[4]> ClassFour body<[6]> ClassFive body<[500]> MetaAleph.__init__<[9]> ClassSix body<[500]> MetaAleph.__init__<[11]> ClassThree tests <[300]> deco_alpha:inner_1 /g110 <[12]> ClassFour tests <[5]> ClassFour.method_y /g111 <[13]> ClassFive tests <[7]> ClassFive.__init__\n--- Страница 699 ---\n699 Метакласс для настройки дескрипторов <[600]> MetaAleph.__init__:inner_2 /g112 <[14]> ClassSix tests <[7]> ClassFive.__init__<[600]> MetaAleph.__init__:inner_2 /g113 <[15]> evaltime_meta module end /g110 Когда декоратор применяется к классу ClassThree , метод method_y послед-послед- него заменяется методом inner_1 … /g111 … но это никак не отражается на недекорированном классе ClassFour , хотя ClassFour является подклассом ClassThree . /g112 Метод __init__ метакласса MetaAleph заменяет метод ClassFive.method_z своей функцией inner_2 . /g113 То же самое происходит с подклассом ClassSix класса ClassFive : его метод method_z заменяется функцией inner_2 . Отметим, что в ClassSix нет прямых ссылок на MetaAleph , и, тем не менее, он изменился, потому что является подклассом ClassFive , а, значит, также и экзем- пляром MetaAleph , и потому инициализируется методом MetaAleph.__init__ . Дальнейшую настройку класса можно выполнить, реализовав в метаклассе метод __new__ . Но обычно реализации метода __init__ достаточно. Теперь всю эту теорию мы применим на практике и создадим метакласс, ко- метакласс, ко- , ко- торый окончательно решит проблему дескрипторов с автоматическими именами атрибутов хранения. Метакласс для настройки дескрипторов Вернемся к классу LineItem . Было бы хорошо, если бы пользователю вообще не нужно было знать о каких-то декораторах или метаклассах, а надо было лишь унаследовать классу из нашей библиотеки, как в примере 21.14. Пример 21.14. bulkfood_v7.py: наследование классу model.Entity сработает , если за кулисами маячит метакласс import model_v7 as model class LineItem(model.Entity): /g110 description = model.NonBlank() weight = model.Quantity() price = model.Quantity() def __init__(self, description, weight, price): self.description = description self.weight = weight\n--- Страница 700 ---\n700 Глава 21. Метапрограммирование классов self.price = price def subtotal(self): return self.weight * self.price /g110 LineItem – подкласс model.Entity . Пример 21.14 выглядит совершенно безобидно. Нет никаких странных синтак- сических конструкций. Однако работает он лишь потому, что в файле model_v7.py определен метакласс, и model.Entity является экземпляром этого метакласса. В примере 21.15 показана реализация класса Entity в модуле model_v7.py . Пример 21.15. model_v7.py: метакласс EntityMeta и один его экземпляр, Entity class EntityMeta(type): \"\"\"Метакласс для прикладных классов с контролируемыми полями\"\"\" def __init__(cls, name, bases, attr_dict): super().__init__(name, bases, attr_dict) /g110 for key, attr in attr_dict.items(): /g111 if isinstance(attr, Validated): type_name = type(attr).__name__ attr.storage_name = '_{}#{}'.format(type_name, key) class Entity(metaclass=EntityMeta): /g112 \"\"\"Прикладной класс с контролируемыми полями\"\"\" /g110 Вызываем метод __init__ суперкласса (в данном случае type ). /g111 Та же логика, что в декораторе @entity из примера 21.4. /g112 Этот класс существует только для удобства: пользователю модуля нужно просто унаследовать ему. Код из примера 21.14 проходит все тесты из примера 21.3. Поддерживающий его модуль model_v7.py труднее понять, чем model_v6.py , зато пользовательский код проще: стоит унаследовать классу model_v7.entity , как мы получаем специ- ализированные имена атрибутов хранения для полей типа Validated . На рис. 21.4 изображена упрощенная картина того, что мы сейчас реализовали. Вся сложность скрыта внутри модуля model_v7 . С точки зрения пользователя, LineItem – просто подкласс Entity , как показано в примере 21.14. Такова сила абстракции. За исключением синтаксиса связывания класса с метаклассом5, все сказанное до сих пор о метаклассах применимо к версиям Python, начиная с 2.2, когда систе- метаклассах применимо к версиям Python, начиная с 2.2, когда систе- ах применимо к версиям Python, начиная с 2.2, когда систе- ма типов Python была подвергнута значительной переработке. Но в следующем разделе мы рассмотрим механизм, имеющийся только в Python 3. 5 Напомним (см. раздел «Синтаксические детали ABC» главы 11), что в Python 2.7 используется атрибут __metaclass__ , а аргумент metaclass= keyword в объявлении класса не поддержива- ется.\n--- Страница 701 ---\n701 Специальный метод метакласса __prepare__ Рис. 21.4. UML-диаграмма классов, аннотированная хреновинами и штуковинами (MGN – Mills & Gizmos Notation): метахреновина EntityMeta создает хреновину LineItem . Конфигурирование дескрипторов (например, weight и price ) производится в методе EntityMeta.__init__ . Обратите внимание на границу пакета model_v7 Специальный метод метакласса __prepare__ В некоторых приложениях интересно знать порядок определения атрибутов клас- са. Например, библиотеке для чтения и записи CSV-файлов, управляемой пользо- библиотеке для чтения и записи CSV-файлов, управляемой пользо- е для чтения и записи CSV-файлов, управляемой пользо- вательскими классами, возможно, необходимо сопоставить поля, объявленные в классе, с полями столбцов CSV-файла в правильном порядке. Как мы видели, конструктор type , а равно методы метаклассов __new__ и __init__ получают тело класса, представленное в виде отображения имен на атри- буты. Однако по умолчанию это отображение является словарем dict , т. е. поря- док следования атрибутов в теле класса теряется к тому моменту, когда их видит метакласс или декоратор класса. Решение проблемы дает специальный метод __prepare__ , добавленный в Python 3. Этот специальный метод относится только к метаклассам и обязан быть методом класса (т. е. должен быть снабжен декоратором @classmethod ). Интер- претатор вызывает метод __prepare__ до метода __new__ , чтобы тот создал отобра- жение, которое будет заполнено атрибутами из тела класса. Первым аргументом __prepare__ получает сам метакласс, а за ним имя конструируемого класса и кор- метакласс, а за ним имя конструируемого класса и кор- , а за ним имя конструируемого класса и кор- теж его базовых классов, а вернуть он должен отображение, которое будет переда-но в последнем аргументе методу __new__ и далее методу __init__ , когда метакласс примется за построение нового класса.\n--- Страница 702 ---\n702 Глава 21. Метапрограммирование классов В теории кажется сложным, но на практике все встречавшиеся мне примеры использования __prepare__ оказывались чрезвычайно простыми. Взгляните на пример 21.16. Пример 21.16. model_v8.py: в метаклассе EntityMeta используется __prepare__ , а в классе Entity теперь есть метод класса field_names class EntityMeta(type): \"\"\"Метакласс для прикладных классов с контролируемыми полями\"\"\" @classmethod def __prepare__(cls, name, bases): return collections.OrderedDict() /g110 def __init__(cls, name, bases, attr_dict): super().__init__(name, bases, attr_dict) cls._field_names = [] /g111 for key, attr in attr_dict.items(): /g112 if isinstance(attr, Validated): type_name = type(attr).__name__ attr.storage_name = '_{}#{}'.format(type_name, key) cls._field_names.append(key) /g113 class Entity(metaclass=EntityMeta): \"\"\"Прикладной класс с контролируемыми полями\"\"\" @classmethod def field_names(cls): /g114 for name in cls._field_names: yield name /g110 Возвращаем пустой экземпляр OrderedDict , в котором будут храниться атрибуты класса. /g111 Создаем атрибут _field_names в конструируемом классе. /g112 Эта строка такая же, как в предыдущей версии, но здесь attr_dict – экзем- пляр класса OrderedDict , полученный интерпретатором, когда он вызывал метод __prepare__ перед вызовом __init__ . Следовательно, в этом цикле for атрибуты будут перебираться в том порядке, в котором добавлялись. /g113 Помещаем имена всех полей типа Validated в _field_names . /g114 Метод класса field_names просто отдает поля в порядке добавления. После простых модификаций, показанных в примере 21.16, мы можем обойти поля типа Validated любого подкласса Entity , воспользовавшись методом класса field_names . В примере 21.17 демонстрируется эта новая возможность. Пример 21.17. bulkfood_v8.py: doctest-скрипт для демонстрации метода field_names – в класс LineItem не пришлось вносить никаких изменений; метод field_names унаследован от model.Entity >>> for name in LineItem.field_names(): print(name)\n--- Страница 703 ---\n703 Классы как объекты descriptionweightprice На этом мы завершаем рассмотрение метаклассов. На практике метаклассы ис- метаклассов. На практике метаклассы ис- ов. На практике метаклассы ис- метаклассы ис- ы ис- пользуются в каркасах и библиотеках и помогают программистам решать, в част- библиотеках и помогают программистам решать, в част- ах и помогают программистам решать, в част- ности, следующие задачи: • проверка значений атрибутов; • применение декораторов сразу к нескольким методам;• сериализация объектов и преобразование данных;• объектно-реляционное отображение;• постоянное хранение объектов;• динамическая трансляция структур классов с других языков. А теперь дадим краткий обзор методов, определенных в модели данных Python для всех классов. Классы как объекты Каждый класс имеет ряд атрибутов, определенных в модели данных Python и до-кументированных в разделе 4.13 «Специальные атрибуты» ( http://bit.ly/1cPOodb ) главы «Встроенные типы» справочного руководства по стандартной библиотеке. Три из них мы уже встречали ранее: __mro__ , __class__ и __name__ . Перечислим остальные. cls.__bases__ Кортеж, содержащий базовые классы данного класса. cls.__qualname__ Новый атрибут в версии Python 3.3, в нем хранится полное имя класса или функции, представляющее собой путь от глобальной области види-мости модуля к определению класса, компоненты которого разделены точками. Так, в примере 21.6 __qualname__ внутреннего класса ClassTwo содержит строку 'ClassOne.ClassTwo' , тогда как __name__ равно просто 'ClassTwo' . Спецификация этого атрибута приведена в документе «PEP- 3155 – Qualified name for classes and functions» ( http://www.python.org/ dev/peps/pep-3155 ). cls.__subclasses__() Этот метод возвращает список непосредственных подклассов данного класса. В реализации применяются слабые ссылки, чтобы избежать цикли-ческих ссылок между суперклассом и его подклассами – которые хранят сильную ссылку на суперклассы в атрибуте __bases__ . В возвращенный список включаются только подклассы, которые в настоящий момент загру-жены в память.\n--- Страница 704 ---\n704 Глава 21. Метапрограммирование классов cls.mro() Интерпретатор вызывает этот метод при построении класса, чтобы полу- чить кортеж суперклассов, который хранится в атрибуте класса __mro__ . Метакласс может переопределить этот метод и задать другой порядок раз-решения методов в конструируемом классе. Ни один из упоминаемых в этом разделе атрибутов, не включа- ется в список, возвращаемый функцией dir( …). На этом мы завершаем изучение метапрограммирования классов. Это обшир- ная тема, которую я смог лишь поверхностно затронуть. Но для того и существуют разделы «Дополнительная литература». Резюме Метапрограммирование классов – это техника динамического создания или из-менения классов. Классы в Python являются полноправными объектами, поэто-му в самом начале главы мы показали, как функция может создать класс, вызвав встроенный метакласс type . В следующем разделе мы вернулись к классу LineItem с дескрипторами из гла- вы 20, чтобы решить оставленную на потом проблему: как сгенерировать имена атрибутов хранения, чтобы они отражали имена управляемых атрибутов (напри-мер, _Quantity#price вместо _Quantity#1 ). Решение заключалось в том, чтобы ис- пользовать декоратор класса – функцию, которая получает только что построен-ный класс и имеет возможность инспектировать его, изменять и даже подменять другим классом. Затем мы перешли к обсуждению вопроса о том, когда выполняются различ- ные части исходного кода модуля. Мы видели, что существует перекрытие между так называемыми «этапом импорта» и «этапом выполнения», но в любом случае компиляция предложения import влечет за собой выполнение большого объема кода. Понимание того, что когда выполняется, критически важно, а для того чтобы проиллюстрировать некоторые тонкие правила, мы предложили проработать ряд упражнений. Далее мы занялись темой метаклассов. Мы видели, что любой класс является экземпляром класса type или его подкласса, т. е. это «корневой метакласс» в язы- ке. Одно из упражнений предназначалось для того, чтобы показать, как метакласс может модифицировать иерархию классов – в отличие от декоратора класса, ко-торый действует только на один класс и может не оказать никакого влияния на его потомков. Первым практическим применением метакласса стало решение проблемы имен атрибутов хранения в классе LineItem . Получившийся код оказался несколько\n--- Страница 705 ---\n705 Дополнительная литература сложнее решения на основе декоратора класса, зато его можно инкапсулировать в модуле, так что пользователю останется только унаследовать совсем простому, на поверхностный взгляд, классу ( model.Entity ), ничего не зная о том, что это эк- земпляр специального метакласса ( model.EntityMeta ). Конечный результат напо- минает API объектно-ориентированного отображения в Django и SQLAlchemy, где метаклассы используются, но пользователь о них не знает. Затем мы реализовали второй метакласс, добавив в model.EntityMeta новую возможность: метод __prepare__ , который предоставляет контейнер OrderedDict для отображения имен на атрибуты. Он сохраняет порядок связывания атри-бутов в теле конструируемого класса, так что методы __new__ и __init__ могут воспользоваться этой информацией. В примере мы реализовали атрибут класса _field_names , что позволило написать метод Entity.field_names() , с помощью ко- торого пользователь может получить дескрипторы Validated в порядке их появ- ления в исходном коде. В последнем разделе был дан краткий обзор атрибутов и методов, имеющихся во всех классах Python. Метаклассы могут вызвать восторг и восхищение, но иногда используются во вред программистами, которые стараются быть слишком умными. В заключение еще раз приведем слова Алекса Мартелли из вставного эссе «Водоплавающие пти-цы и ABC» в главе 11: И не определяйте свои ABC (или метаклассы) в производствен- ном коде… Если вам кажется, что без этого не обойтись, держу пари, что это, скорее всего, желание поскорее забить гвоздь, раз уж в руках молоток, – вам (и тем, кому предстоит сопровождать вашу программу) будет куда комфортнее иметь дело с прямолинейным и простым кодом, где нет таких глубин. Мудрые слова человека, который не только в совершенстве владеет метапро- граммированием в Python, но и является высококвалифицированным програм-мистом и работает над самыми крупными и важными проектами на Python, суще-ствующими в мире. Дополнительная литература Основными справочными материалами к этой главе являются раздел 3.3.3 «На-стройка создания класса» ( http://bit.ly/1HGwGnI ) главы «Модель данных» спра- вочного руководства по языку Python, документация по классу type (https://docs. python.org/3/library/functions.html#type ) в разделе «Встроенные функции» и раз- дел 4.13 «Специальные атрибуты» ( http://bit.ly/1cPOodb ) главы «Встроенные типы» справочного руководства по стандартной библиотеке. Кроме того, в доку-ментации по модулю types из стандартной библиотеки ( http://bit.ly/1HGwF3b ) рассматриваются две новые функции в Python 3.3, призванные оказать помощь в метапрограммировании классов: types.new_class( …) и types.prepare_class( …).\n--- Страница 706 ---\n706 Глава 21. Метапрограммирование классов Декораторы классов были формально определены в документе «PEP 3129 – Class Decorators» ( http://bit.ly/1HGwIvW ), который написал Коллин Уинтер (Collin Winter), а эталонную реализацию предложил Джек Дидерих (Jack Diederich). До-клад Джека Дидериха на конференции PyCon 2009 «Class Decorators: Radically Simple» (видео – по адресу http://bit.ly/1HGwJ2Y ) содержит краткое введение в эту функциональность. Книга Алекса Мартелли «Python in a Nutshell», издание 2, содержит блиста- тельное описание метаклассов, в том числе и метакласса metaMetaBunch , решаю- щего ту же задачу, что и наша простая функция record_factory из примера 21.2, но гораздо более изощренного. Мартелли не рассматривает декораторы классов, потому что они появились после того, как книга вышла из печати. Бизли и Джонс приводят великолепные примеры декораторов классов и метаклассов в свой книге «Python Cookbook», издание 3 (O'Reilly). Михаэль Фоорд (Michael Foord) напи-сал статью с интригующим названием «Meta-classes Made Easy: Eliminating self with Metaclasses» (Метаклассы – это просто: устранение self с помощью метаклас-сов) ( http://bit.ly/1HGwMvx ). Все сказано в подзаголовке. Основной справочный материал по метаклассам – документ «PEP 3115 – Metaclasses in Python 3000» ( https://www.python.org/dev/peps/pep-3115/ ), в ко- тором вводится специальный метод __prepare__ , и документ «Unifying types and classes in Python 2.2» ( http://bit.ly/1HGwN2D ), написанный Гвидо ван Россумом. Этот документ относится в равной мере и к Python 3 и охватывает то, что в то вре-мя называлось семантикой классов «нового стиля», в том числе дескрипторы и ме-таклассы. Его обязательно нужно прочитать. Гвидо ссылается, в частности, на кни-гу Ira R. Forman, Scott H. Danforth «Putting Metaclasses to W ork: a New Dimension in Object-Oriented Programming» (Addison-W esley, 1998), которой он поставил 5 звезд на сайте Amazon.com, сопроводив таким комментарием: Эта книга внесла вклад в дизайн метаклассов в Python 2.2 Жаль, что она больше не переиздается; я продолжаю считать ее лучшей из из- вестных мне работ на трудную тему кооперативного множественного наследова-ния, поддерживаемого в Python с помощью функции super() .6 Что касается Python 3.5 – на момент написания этой книги вышла только аль- фа-версия – то в документе «PEP 487 – Simpler customization of class creation» (https://www.python.org/dev/peps/pep-0487/ ) выдвинута идея нового специаль- ного метода, __init_subclass__ , который позволит регулярному классу (т. е. не метаклассу) настраивать инициализацию своих подклассов. Как и декораторы классов, метод __init_subclass__ призван сделать метапрограммирование классов более доступным, а заодно уменьшить количество доводов в пользу применения базового механизма, на котором он основан, – метаклассов. Если вы увлеклись метапрограммированием, то, возможно, хотели бы, чтобы в Python был реализован механизм, являющийся королем всех средств метапро-граммирования: синтаксические макросы, имеющиеся в Elixir и семействе языков 6 Страница каталога, посвященная книге «Putting Metaclasses to W ork» ( http://amzn.to/1HGwKDO ). Еще можно купить подержанные экземпляры. Я купил. Это трудный текст, но я надеюсь к нему еще вернуться.\n--- Страница 707 ---\n707 Поговорим Lisp. Но подумайте, зачем вам это нужно. А я произнесу лишь одно слово: MacroPy (https://github.com/lihaoyi/macropy ). Поговорим Эту последнюю врезку «Поговорим» я начну длинной цитатой из Брайана Харви (Brian Harvey) и Мэттью Райта (Matthew Wright), двух профессоров информатики из Калифорнийского университета (в Берк-ли и Санта-Барбаре). В книге «Simply Scheme» Харви и Райт пишут: Есть два направления в преподавании информатики. Схематич- но их можно представить следующим образом: 1. Консервативный взгляд. Компьютерные программы стали на- столько большими и сложными, что человеческий мозг не в со-стоянии их охватить. Поэтому задача обучения информатике заключается в том, чтобы научить людей дисциплинированной работе, когда 500 средних программистов, собравшись вместе, могут написать программу, отвечающую спецификации. 2. Радикальный взгляд. Компьютерные программы стали настоль- ко большими и сложными, что человеческий мозг не в состоянии их охватить. Поэтому задача обучения информатике заключает-ся в том, чтобы научить людей расширять сознание, чтобы в нем хватило место всей программе. Для этого нужно учить мыслить более крупными, более эффективными, более гибкими катего-риями, не ограничиваясь очевидными вещами. Каждая единица программистской мысли должна давать большую отдачу в тер-минах возможностей программы 7. – Брайан Харви и Мэттью Райт, предисловие к книге «Simply Scheme» Карикатурные описания Харви и Райта относятся к преподаванию информатики, но они применимы и к проектированию языков програм-мирования. Вы, наверное, уже догадались, что я приверженец «ради-кальной» точки зрения и полагаю, что Python проектировался именно в таком ключе. Идея свойств – большой шаг вперед по сравнения с подходом Java, требующим применять акцессоры с самого начала. Этот подход под-держивается всеми Java IDE с помощью комбинации клавиш для гене-рации методов чтения и установки. Основное достоинство свойств за-ключается в том, что они позволяют начать разработку класса, сделав атрибуты открытыми – в духе принципа KISS – понимая при этом, что 7 Brian Harvey, Matthew Wright «Simply Scheme» (MIT Press, 1999), стр. xvii. Полный текст имеется на сайте Berkeley.edu ( https://www.eecs.berkeley.edu/~bh/ss-toc2.html ).\n--- Страница 708 ---\n708 Глава 21. Метапрограммирование классов в любой момент открытый атрибут можно, не прилагая особых усилий, сделать свойством. Но дескрипторы идут еще дальше, они предоставля-ют механизм для абстрагирования повторяющейся логики акцессоров. Этот механизм настолько эффективен, что используется и в некоторых конструкциях самого языка Python. Еще одна плодотворная идея – функции как полноправные объекты. Она пролагает дорогу к функциям высшего порядка. Как выясняется, комбинация дескрипторов и функций высшего порядка позволяет уни-фицировать функции и методы. Метод __get__ функции порождает объ- ект методы на лету, путем привязки экземпляра к аргументу self . Это элегантное решение8. Наконец, полноправными объектами являются и классы. Нельзя не восхититься дизайном, при котором доступный начинающим програм-мистам язык предоставляет столь мощные концепции, как декораторы классов и полноценные пользовательские метаклассы. И что пораз- метаклассы. И что пораз- ы. И что пораз- ительно: продвинутые средства интегрированы в язык таким образом, что не усложняют его применение для эпизодического программирова-ния (под капотом, конечно, помогают в этом деле). Своим удобством и успешностью такие каркасы, как Django и SQLAlchemy, во многом обязаны метаклассам, пусть даже многие их пользователи об этом и не знают. Но они всегда могут поучиться и написать свою, не менее гран-диозную библиотеку. Я еще не встречал языка, которому удалось так удачно совместить простоту для начинающих, практичность для профессионалов и увле-кательность для хакеров, как это сделано в Python. Спасибо Гвидо ван Россуму и всем, кто внес свой вклад в достижение этой цели. 8 «Machine Beauty» Дэвида Гелернтера (Basic Books) – увлекательная книжечка об элегантности и эстетике в работе инженера: от мостов до программного обеспечения.\n--- Страница 709 ---\nПОСЛЕСЛОВИЕ Python – язык, разрешающий взрослым все. – Алан Раньян, сооснователь Plone Афористичное определение Алана подчеркивает одно из лучших качеств Python: он отходит в сторону и дает возможность делать то, что вам необходимо. Это также означает, что он не предоставляет средств, с помощью которых вы могли бы нало-жить ограничения на то, что другие могут делать с вашим кодом и создаваемыми в нем объектами. Конечно, Python не идеален. Лично меня подчас раздражает разнобой в име- Python не идеален. Лично меня подчас раздражает разнобой в име- не идеален. Лично меня подчас раздражает разнобой в име- новании идентификаторов в стандартной библиотеке, например: CamelCase , snake_case и joinedwords . Но определение языка и стандартная библиотека – лишь часть экосистемы. А лучшую ее часть составляет сообщество пользователей и ав-торов. Приведу пример высоких качеств сообщества. Как-то утром писал я о asyncio и впал в отчаяние из-за того, что в API так много функций, из которых десятки являются сопрограммами, а сопрограммы нужно вызывать с помощью yield from , тогда как к обычным функциям эта конструкция неприменима. Все это описано в документации по asyncio , но иногда приходится прочитать несколько абзацев, пока до тебя дойдет, что некоторая функция является сопрограммой. Поэтому я отправил сообщение в список рассылки python-tulip, назвав его «Предложение: выделять сопрограммы в документации по asyncio» ( https://groups.google.com/ forum/#!topic/python-tulip/Y4bhLNbKs74 ). К беседе подключились Виктор Стиннер, разработчик ядра asyncio , Андрей Светлов, основной автор aiohttp , Бен Дарнелл, главный разработчик T ornado, и Глиф Лефковиц, автор T wisted. Дарнелл предложил решение, Александр Шорин объяснил, как реализовать его в Sphinx, а Stinner внес необходимые изменения в конфигурацию и разметку. Менее чем через 12 часов после моего вопроса вся выложенная в сеть документация по asyn- cio была обновлена – в ней появились метки coroutine (https://docs.python.org/3/ library/asyncio-eventloop.html#executor ). Это произошло не в каком-то клубе для избранных. Любой может войти в спи- сок python-tulip, и я сам, внося это предложение, отправил несколько сообщений. Эта история лишний раз демонстрирует, что сообщество действительно откры-\n--- Страница 710 ---\n710 Глава 21. Послесловие то для новых идей и новых членов. Гвидо ван Россум постоянно присутствует в python-tulip и регулярно отвечает даже на простые вопросы. Приведу еще один пример открытости: задачей фонда Python Software Foundation (PSF) является увеличения разнообразия в сообществе Python. Уже получены обнадеживающие результаты. В правление фонда в период 2013–2014 годов впервые были избраны женщины: Джессика Маккеллар (Jessica McKellar) и Линн Рут (Lynn Root). А на конференции 2015 PyCon North America в Мореа-ле – под председательством Дианы Кларк – примерно треть выступавших были женщинами. Я не знаю другой крупной конференции по ИТ, где стремление к ра-венству полов зашло так далеко. Если вы пишете на Python, но еще не присоединились к сообществу, призываю вас не откладывать с этим. Ищите группу пользователей Python (Python Users Group – PUG) в своем регионе. Если такой еще нет, создайте ее сами. Python при-сутствует везде, поэтому вы не будете одиноки. Посещайте мероприятия, если есть такая возможность. Приезжайте на конференцию PythonBrasil – мы уже много лет предоставляем слово докладчикам из других стран. Личные встречи с колле-гами-программистами дают куда больше, чем общение в сети; известны примеры, когда они приносили реальные плоды, выходящие за рамки обмена знаниями. Как работа и дружба в «реале». Я точно не мог бы написать эту книгу без помощи многочисленных друзей, которыми я за годы работы обзавелся в сообществе Python. Мой отец, Хайро Рамальо, частенько говаривал «S ó erra quem trabalha» – «не ошибается тот, кто ничего не делает» по-португальски. Это прекрасный совет тем, кого парализует страх наделать ошибок. Уж я-то наделал их массу, когда писал эту книгу. Рецензенты, редакторы и читатели предварительной версии отловили многие из них. Не прошло и нескольких часов с момента публикации первой пред-варительной версии, как один читатель сообщил об опечатках на странице ошибок для этой книги ( http://www.oreilly.com/catalog/errata.csp?isbn=0636920032519 ). Этот читатель был отнюдь не единственным, а друзья обращались ко мне напря-мую со своими советами и поправками. Корректоры из издательства O'Reilly най-дут и другие ошибки на этапе производства книги, который начнется сразу после того, как я, наконец, закончу ее писать. Я принимаю на себя ответственность и приношу извинения за те ошибки, которые останутся, а также за стилистические погрешности. Я рад, что работа все же подошла к концу, несмотря на все ошибки и трудности, и в высшей степени благодарен всем, что помогал мне на этом пути. Надеюсь вскоре встретиться с вами на каком-нибудь реальном мероприятии. Не стесняйтесь поздороваться, если наткнетесь на меня! Дополнительная литература В конце книги я хочу привести ссылки на ресурсы, в которых объясняется, что такое «дух Python», – основной вопрос, на который я пытался ответить в этой книге.\n--- Страница 711 ---\n711 Дополнительная литература Брэндон Родес (Brandon Rhodes) – блестящий преподаватель Python, а его доклад «A Python Æsthetic: Beauty and Why I Python» ( https://www.youtube. com/watch?v=x-kB2o8sd5c ) великолепен, начиная уже с использования символа Unicode U+00C6 (LATIN CAPITAL LETTER AE) в названии. Другой замечатель-ный преподаватель, Раймонд Хэттингер, говорил о красоте в Python на конферен-ции PyCon US в своем выступлении «Transforming Code into Beautiful, Idiomatic Python» ( https://www.youtube.com/watch?v=OSGv2VnC0go ). Стоит почитать обсуждение «The Evolution of Style Guides» ( http://bit. ly/1e8pV4h ), начатое Яном Ли (Ian Lee) в списке рассылки Python-ideas. Ли отве- чает за сопровождение пакета pep8 (https://pypi.python.org/pypi/pep8/ ), который проверяет исходный Python-код на совместимость с документом PEP 8. Для про-верки кода в этой книге я пользовался программами flake8 (https://pypi.python. org/pypi/flake8 ), которая обертывает pep8 , pyflakes (https://pypi.python.org/pypi/ pyflakes ) и подключаемым модулем McCabe для оценки сложности, написанным Нэдом Бэтчелдером (Ned Batchelder) ( https://pypi.python.org/pypi/mccabe ). Помимо PEP 8, есть и другие авторитетные стилистические руководства: Google Python Style Guide ( https://google-styleguide.googlecode.com/svn/trunk/ pyguide.html ) и Pocoo Style Guide ( http://www.pocoo.org/internal/styleguide /), пред- ложенное командой, подарившей нам Flake, Sphinx, Jinja 2 и другие не менее за-мечательные библиотеки на Python. Руководство автостопщика по Python (Hitchhiker's Guide to Python!) ( http:// docs.python-guide.org/en/latest/) – коллективный труд, посвященный написанию кода в духе Python. Наибольший вклад в него внес Кеннет Рейц (Kenneth Reitz), легендарный герой сообщества, прославившийся своим образцово «питониче-ским» пакетом requests . Дэвид Г уджер (David Goodger) представил на конфе- ренции PyCon US 2008 пособие под названием «Code Like a Pythonista: Idiomatic Python» ( http://bit.ly/1e8r8sj) . В печатном виде оно занимает 30 страниц. Разуме- ется, доступен исходный код в формате reStructuredT ext, который можно выве-сти в виде HTML или слайдов S5 ( http://meyerweb.com/eric/tools/s5/ ) с помощью программы docutils . Ведь именно Г уджер и создал как reStructuredT ext, так и docutils , положенные в основу Sphinx, великолепной системы документирования для Python (кстати говоря, в ней подготовлена и официальная документация по MongoDB ( http://bit.ly/1e8r4ss ) и многим другим проектам). Мартин Фаассен (Martijn Faassen) поднимает вопрос «Что такое дух Python?» в своем блоге ( http://blog.startifact.com/posts/older/what-is-pythonic.html ) В спи- ске рассылки python-list есть обсуждение с таким же заголовком ( http://bit. ly/1e8raAA ). Статья Мартина относится к 2005 году, а это обсуждение – к 2003, но «питонический» идеал изменился не сильно – как, впрочем, и сам язык. Из обсуж-дений, в заголовке которых встречается слово «Pythonic», хотелоь бы выделить «Pythonic way to sum n-th list element?» ( http://bit.ly/1e8reQP ), которое я обильно цитировал во врезке «Поговорим» на стр. 335. В документе «PEP 3099 – Things that will Not Change in Python 3000» ( https:// www.python.org/dev/peps/pep-3099/ ) объясняется, почему многие вещи реализо- ваны так, а не иначе, даже после масштабной переработки Python при выходе вер-\n--- Страница 712 ---\n712 Глава 21. Послесловие сии 3. Долгое время Python 3 называли Python 3000, но он появился на несколько столетий раньше – приведя некоторых в смятение. Автор документа PEP 3099, Георг Брандл (Georg Brandl), собрал многие высказывания нашего пожизненного великодушного диктатора, Гвидо ван Россума. На странице Python Essays ( https:// www.python.org/doc/essays /) опубликовано несколько текстов самого Гвидо.\n--- Страница 713 ---\nПРИЛОЖЕНИЕ А . Листинги скриптов Ниже приведены полные листинги некоторых скриптов, настолько длинные, что им не нашлось место в основном тексте. Включены также скрипты, с помощью которых генерировались некоторые таблицы и фикстуры, использованные в этой книге. Все эти скрипты доступны также в репозитории кода к книге ( http://bit. ly/1e8s1Bd ), как и почти все остальные фрагменты кода. Глава 3: тест производительности оператора in Пример A.1 содержит код, с помощью которого я получил данные хронометража, приведенные в табл. 3.6, с применением модуля timeit . Скрипт, в основном, под- готавливает данные haystack и needles и форматирует результаты. Программируя пример A.1, я обнаружил нечто, позволяющее взглянуть на про- A.1, я обнаружил нечто, позволяющее взглянуть на про-.1, я обнаружил нечто, позволяющее взглянуть на про- изводительность dict в более широком контексте. Если запустить скрипт в режи- ме подробной информации (с флагом -v), то получаются цифры, почти в два раза превышающие те, что приведены в табл. 3.5. Но заметим, что в этом скрипте «ре-жим подробной информации» означает лишь четыре обращения к print на этапе настройки теста и еще одно обращение для показа количества найденных иголок по завершении каждого теста. Внутри цикла, где ищутся иголки в стоге сена, ни-чего не печатается, но эти пять обращений к print занимают почти столько же времени, сколько поиск 1000 иголок. Пример A.1. container_perftest.py: запускать с указанием имени встроенного типа коллекции в аргументе командной строки (например, container_perftest.py dict ) \"\"\" Тест производительности оператора контейнера ``in``\"\"\" import sys\n--- Страница 714 ---\n714 Приложение А. Листинги скриптов import timeit SETUP = '''import array selected = array.array('d')with open('selected.arr', 'rb') as fp: selected.fromfile(fp, {size})if {container_type} is dict: haystack = dict.fromkeys(selected, 1)else: haystack = {container_type}(selected)if {verbose}: print(type(haystack), end=' ') print('haystack: %10d' % len(haystack), end=' ')needles = array.array('d')with open('not_selected.arr', 'rb') as fp: needles.fromfile(fp, 500)needles.extend(selected[::{size}//500])if {verbose}: print(' needles: %10d' % len(needles), end=' ')''' TEST = ''' found = 0for n in needles: if n in haystack: found += 1if {verbose}: print(' found: %10d' % found)''' def test(container_type, verbose): MAX_EXPONENT = 7 for n in range(3, MAX_EXPONENT + 1): size = 10**n setup = SETUP.format(container_type=container_type, size=size, verbose=verbose) test = TEST.format(verbose=verbose) tt = timeit.repeat(stmt=test, setup=setup, repeat=5, number=1) print('|{:{}d}|{:f}'.format(size, MAX_EXPONENT + 1, min(tt))) if __name__=='__main__': if '-v' in sys.argv: sys.argv.remove('-v') verbose = True else: verbose = False if len(sys.argv) != 2: print('Usage: %s <container_type>' % sys.argv[0]) else: test(sys.argv[1], verbose)\n--- Страница 715 ---\n715 Глава 3: сравнение битовых представлений хэшей Скрипт container_perftest_datagen.py (пример A.2) генерирует фикстуры дан- A.2) генерирует фикстуры дан-.2) генерирует фикстуры дан- ных для скрипта из примера A.1. Пример A.2. container_perftest_datagen.py: генерирует файлы, содержащие массивы уникальных чисел с плавающей точкой, для использования в примере A.1 \"\"\" Генерировать данные для теста производительности контейнера\"\"\" import random import array MAX_EXPONENT = 7 HAYSTACK_LEN = 10 ** MAX_EXPONENTNEEDLES_LEN = 10 ** (MAX_EXPONENT - 1)SAMPLE_LEN = HAYSTACK_LEN + NEEDLES_LEN // 2 needles = array.array('d')sample = {1/random.random() for i in range(SAMPLE_LEN)} print('initial sample: %d elements' % len(sample)) # дополнить выборку, если были отброшены дубликаты while len(sample) < SAMPLE_LEN: sample.add(1/random.random()) print('complete sample: %d elements' % len(sample))sample = array.array('d', sample) random.shuffle(sample) not_selected = sample[:NEEDLES_LEN // 2] print('not selected: %d samples' % len(not_selected))print(' writing not_selected.arr')with open('not_selected.arr', 'wb') as fp: not_selected.tofile(fp) selected = sample[NEEDLES_LEN // 2:] print('selected: %d samples' % len(selected))print(' writing selected.arr')with open('selected.arr', 'wb') as fp: selected .tofile(fp) Глава 3: сравнение битовых представлений хэшей В примере A.3 приведен простой скрипт, показывающий, как отличаются бито- вые представления хэшей близких чисел с плавающей точкой (например, 1.0001, 1.0002 и т. д.). Результат его работы показан в примере 3.16.\n--- Страница 716 ---\n716 Приложение А. Листинги скриптов Пример A.3. hashdiff.py: показывает битовые представления хэшированных значений import sys MAX_BITS = len(format(sys.maxsize, 'b'))print('%s-bit Python build' % (MAX_BITS + 1)) def hash_diff(o1, o2): h1 = '{:>0{}b}'.format(hash(o1), MAX_BITS) h2 = '{:>0{}b}'.format(hash(o2), MAX_BITS) diff = ''.join('!' if b1 != b2 else ' ' for b1, b2 in zip(h1, h2)) count = '!= {}'.format(diff.count('!')) width = max(len(repr(o1)), len(repr(o2)), 8) sep = '-' * (width * 2 + MAX_BITS) return '{!r:{width}} {}\\n{:{width}} {} {}\\n{!r:{width}} {}\\n{}'.format( o1, h1, ' ' * width, diff, count, o2, h2, sep, width=width) if __name__ == '__main__': print(hash_diff(1, 1.0)) print(hash_diff(1.0, 1.0001)) print(hash_diff(1.0001, 1.0002)) print(hash_diff(1.0002, 1.0003)) Глава 9. Потребление оперативной памяти при наличии и отсутствии __slots__ Скрипт memtest.py использовался для демонстрации в разделе примере 9.12 из раздела «Экономия памяти с помощью атрибута класса __slots__» главы 9. Этот скрипт принимает имя модуля в командной строке и загружает его. В предположении, что в модуле определен класс Vector , скрипт memtest.py создает список, содержащий 10 миллионов экземпляров, и печатает объем занятой памяти до и после создания списка. Пример A.4. memtest.py: создает очень много экземпляров Vector и печатает сведения о потреблении памяти import importlib import sysimport resource NUM_VECTORS = 10**7if len(sys.argv) == 2: module_name = sys.argv[1].replace('.py', '') module = importlib.import_module(module_name)else: print('Usage: {} <vector-module-to-test>'.format())\n--- Страница 717 ---\n717 Глава 14: скрипт преобразования базы данных isis2json.py sys.exit(1) fmt = 'Selected Vector2d type: {.__name__}.{.__name__}' print(fmt.format(module, module.Vector2d)) mem_init = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss print('Creating {:,} Vector2d instances'.format(NUM_VECTORS)) vectors = [module.Vector2d(3.0, 4.0) for i in range(NUM_VECTORS)]mem_final = resource.getrusage(resource.RUSAGE_SELF).ru_maxrssprint('Initial RAM usage: {:14,}'.format(mem_init)) print(' Final RAM usage: {:14,}'.format(mem_final)) Глава 14: скрипт преобразования базы данных isis2json.py В примере A.5 приведен скрипт isis2json.py , обсуждавшийся в разделе «Пример: генераторы в утилите преобразования базы данных» главы 14. В нем используется генераторная функция для ленивого преобразования баз данных CDS/ISIS в фор-мат JSON с целью последующей загрузки в CouchDB или MongoDB. Отметим, что этот скрипт написан на Python 2 и рассчитан на запуск под управлением CPython или Jython версий от 2.5 до 2.7, но не версии Python 3. При работе под управлением CPython он умеет читать только iso-файлы, а в случае Jython – также mst-файлы – благодаря библиотеке Bruma , которую можно скачать с GitHub по адресу https://github.com/fluentpython/isis2json . Рабочая документация находится в том же репозитории. Пример A.5. isis2json.py: зависимости и документация доступны в репозитории fluentpython/isis2json на GitHub ( https://github.com/fluentpython/isis2json ) # этот скрипт работает с Python или Jython (версии >=2.5 и <3) import sys import argparsefrom uuid import uuid4import os try: import jsonexcept ImportError: if os.name == 'java': # running Jython from com.xhaus.jyson import JysonCodec as json else: import simplejson as json SKIP_INACTIVE = True DEFAULT_QTY = 2**31\n--- Страница 718 ---\n718 Приложение А. Листинги скриптов ISIS_MFN_KEY = 'mfn' ISIS_ACTIVE_KEY = 'active'SUBFIELD_DELIMITER = '^'INPUT_ENCODING = 'cp1252' def iter_iso_records(iso_file_name, isis_json_type): /g110 from iso2709 import IsoFile from subfield import expand iso = IsoFile(iso_file_name) for record in iso: fields = {} for field in record.directory: field_key = str(int(field .tag)) # удалить начальные пробелы field_occurrences = fields.setdefault(field_key, []) content = field.value.decode(INPUT_ENCODING, 'replace') if isis_json_type == 1: field_occurrences.append(content) elif isis_json_type == 2: field_occurrences.append(expand(content)) elif isis_json_type == 3: field_occurrences.append(dict(expand(content))) else: raise NotImplementedError('ISIS-JSON type %s conversion ' 'not yet implemented for .iso input' % isis_json_type) yield fields iso.close() def iter_mst_records(master_file_name, isis_json_type): /g111 try: from bruma.master import MasterFactory, Record except ImportError: print('IMPORT ERROR: Jython 2.5 and Bruma.jar ' 'are required to read .mst files') raise SystemExit mst = MasterFactory.getInstance(master_file_name).open() for record in mst: fields = {} if SKIP_INACTIVE: if record.getStatus() != Record.Status.ACTIVE: continue else: # сохранить состояние, только если есть неактивные записи fields[ISIS_ACTIVE_KEY] = (record.getStatus() == Record.Status.ACTIVE) fields[ISIS_MFN_KEY] = record.getMfn() for field in record.getFields(): field_key = str(field.getId()) field_occurrences = fields.setdefault(field_key, []) if isis_json_type == 3: content = {} for subfield in field.getSubfields(): subfield_key = subfield.getId()\n--- Страница 719 ---\n719 Глава 14: скрипт преобразования базы данных isis2json.py if subfield_key == '*': content['_'] = subfield.getContent() else: subfield_occurrences = content.setdefault(subfield_key, []) subfield_occurrences.append(subfield.getContent()) field_occurrences.append(content) elif isis_json_type == 1: content = [] for subfield in field.getSubfields(): subfield_key = subfield.getId() if subfield_key == '*': content.insert(0, subfield.getContent()) else: content.append(SUBFIELD_DELIMITER + subfield_key + subfield.getContent()) field_occurrences.append(''.join(content)) else: raise NotImplementedError('ISIS-JSON type %s conversion ' 'not yet implemented for .mst input' % isis_json_type) yield fields mst.close() def write_json(input_gen, file_name, output, qty, skip, id_tag, /g112 gen_uuid, mongo, mfn, isis_json_type, prefix, constant): start = skip end = start + qty if id_tag: id_tag = str(id_tag) ids = set() else: id_tag = '' for i, record in enumerate(input_gen): if i >= end: break if not mongo: if i == 0: output.write('[') elif i > start: output.write(',') if start <= i < end: if id_tag: occurrences = record.get(id_tag, None) if occurrences is None: msg = 'id tag #%s not found in record %s' if ISIS_MFN_KEY in record: msg = msg + (' (mfn=%s)' % record[ISIS_MFN_KEY]) raise KeyError(msg % (id_tag, i)) if len(occurrences) > 1: msg = 'multiple id tags #%s found in record %s' if ISIS_MFN_KEY in record: msg = msg + (' (mfn=%s)' % record[ISIS_MFN_KEY]) raise TypeError(msg % (id_tag, i))\n--- Страница 720 ---\n720 Приложение А. Листинги скриптов else: # ok, we have one and only one id field if isis_json_type == 1: id = occurrences[0] elif isis_json_type == 2: id = occurrences[0][0][1] elif isis_json_type == 3: id = occurrences[0]['_'] if id in ids: msg = 'duplicate id %s in tag #%s, record %s' if ISIS_MFN_KEY in record: msg = msg + (' (mfn=%s)' % record[ISIS_MFN_KEY]) raise TypeError(msg % (id, id_tag, i)) record['_id'] = id ids.add(id) elif gen_uuid: record['_id'] = unicode(uuid4()) elif mfn: record['_id'] = record[ISIS_MFN_KEY] if prefix: # обходим фиксированную последовательность тегов for tag in tuple(record): if str(tag).isdigit(): record[prefix+tag] = record[tag] del record[tag] # вот поэтому мы обходим кортеж с # тегами, и не сам словарь record if constant: constant_key, constant_value = constant.split(':') record[constant_key] = constant_value output.write(json.dumps(record).encode('utf-8')) output.write('\\n') if not mongo: output.write(']\\n') def main(): /g113 # создаем анализатор parser = argparse.ArgumentParser( description='Convert an ISIS .mst or .iso file to a JSON array') # добавляем аргументы parser.add_argument( 'file_name', metavar='INPUT.(mst|iso)', help='.mst or .iso file to read') parser.add_argument( '-o', '--out', type=argparse.FileType('w'), default=sys.stdout, metavar='OUTPUT.json', help='the file where the JSON output should be written' ' (default: write to stdout)') parser.add_argument( '-c', '--couch', action='store_true', help='output array within a \"docs\" item in a JSON document' ' for bulk insert to CouchDB via POST to db/_bulk_docs') parser.add_argument( '-m', '--mongo', action='store_true',\n--- Страница 721 ---\n721 Глава 14: скрипт преобразования базы данных isis2json.py help='output individual records as separate JSON dictionaries, one' ' per line for bulk insert to MongoDB via mongoimport utility') parser.add_argument( '-t', '--type', type=int, metavar='ISIS_JSON_TYPE', default=1, help='ISIS-JSON type, sets field structure: 1=string, 2=alist,' ' 3=dict (default=1)') parser.add_argument( '-q', '--qty', type=int, default=DEFAULT_QTY, help='maximum quantity of records to read (default=ALL)') parser.add_argument( '-s', '--skip', type=int, default=0, help='records to skip from start of .mst (default=0)') parser.add_argument( '-i', '--id', type=int, metavar='TAG_NUMBER', default=0, help='generate an \"_id\" from the given unique TAG field number' ' for each record') parser.add_argument( '-u', '--uuid', action='store_true', help='generate an \"_id\" with a random UUID for each record') parser.add_argument( '-p', '--prefix', type=str, metavar='PREFIX', default='', help='concatenate prefix to every numeric field tag' ' (ex. 99 becomes \"v99\")') parser.add_argument( '-n', '--mfn', action='store_true', help='generate an \"_id\" from the MFN of each record' ' (available only for .mst input)') parser.add_argument( '-k', '--constant', type=str, metavar='TAG:VALUE', default='', help='Include a constant tag:value in every record (ex. -k type:AS)') ''' # TODO: реализовать следующий флаг для экспорта больших объемов # данных в CouchDB parser.add_argument( '-r', '--repeat', type=int, default=1, help='repeat operation, saving multiple JSON files' ' (default=1, use -r 0 to repeat until end of input)') ''' # разбираем командную строку args = parser.parse_args() if args.file_name.lower().endswith('.mst'): input_gen_func = iter_mst_records /g114 else: if args.mfn: print('UNSUPORTED: -n/--mfn option only available for .mst input.') raise SystemExit input_gen_func = iter_iso_records /g115 input_gen = input_gen_func(args.file_name, args.type) /g116 if args.couch: args.out.write('{ \"docs\" : ') write_json(input_gen, args.file_name, args.out, args.qty, /g117 args.skip, args.id, args.uuid, args.mongo, args.mfn, args.type, args.prefix, args.constant)\n--- Страница 722 ---\n722 Приложение А. Листинги скриптов if args.couch: args.out.write('}\\n') args.out.close() if __name__ == '__main__': main() /g110 Генераторная функция iter_iso_records читает iso-файл и отдает записи по одной. /g111 Генераторная функция iter_mst_records читает mst-файл и отдает записи по одной. /g112 Функция write_json обходит записи, отдаваемые генератором input_gen , и выводит json-файл. /g113 Главная функция разбирает аргументы командной строки, затем… /g114 … выбирает функцию iter_iso_records или … /g115 … функцию iter_mst_records в зависимости от расширения входного фай- ла. /g116 Выбранная генераторная функция строит объект-генератор. /g117 Вызывается функция write_json , которой в первом аргументе передается генератор. Глава 16: моделирование дискретных событий таксопарка В примере A.6 приведен полный листинг из файла taxi_sim.py , обсуждавшегося в разделе «Моделирование работы таксопарка главы» 16. Пример A.6. taxi_sim.py: моделирование таксопарка \"\"\" Моделирование такси============== Driving a taxi from the console:: >>> from taxi_sim import taxi_process >>> taxi = taxi_process(ident=13, trips=2, start_time=0) >>> next(taxi) Event(time=0, proc=13, action='leave garage') >>> taxi.send(_.time + 7) Event(time=7, proc=13, action='pick up passenger') >>> taxi.send(_.time + 23) Event(time=30, proc=13, action='drop off passenger') >>> taxi.send(_.time + 5) Event(time=35, proc=13, action='pick up passenger') >>> taxi.send(_.time + 48) Event(time=83, proc=13, action='drop off passenger') >>> taxi.send(_.time + 1)\n--- Страница 723 ---\n723 Глава 16: моделирование дискретных событий таксопарка Event(time=84, proc=13, action='going home') >>> taxi.send(_.time + 10) Traceback (most recent call last): File \"<stdin>\", line 1, in <module> StopIteration Sample run with two cars, random seed 10. This is a valid doctest:: >>> main(num_taxis=2, seed=10) taxi: 0 Event(time=0, proc=0, action='leave garage') taxi: 0 Event(time=5, proc=0, action='pick up passenger') taxi: 1 Event(time=5, proc=1, action='leave garage') taxi: 1 Event(time=10, proc=1, action='pick up passenger') taxi: 1 Event(time=15, proc=1, action='drop off passenger') taxi: 0 Event(time=17, proc=0, action='drop off passenger') taxi: 1 Event(time=24, proc=1, action='pick up passenger') taxi: 0 Event(time=26, proc=0, action='pick up passenger') taxi: 0 Event(time=30, proc=0, action='drop off passenger') taxi: 0 Event(time=34, proc=0, action='going home') taxi: 1 Event(time=46, proc=1, action='drop off passenger') taxi: 1 Event(time=48, proc=1, action='pick up passenger') taxi: 1 Event(time=110, proc=1, action='drop off passenger') taxi: 1 Event(time=139, proc=1, action='pick up passenger') taxi: 1 Event(time=140, proc=1, action='drop off passenger') taxi: 1 Event(time=150, proc=1, action='going home') *** end of events *** See longer sample run at the end of this module.\"\"\"import random import collectionsimport queueimport argparseimport time DEFAULT_NUMBER_OF_TAXIS = 3 DEFAULT_END_TIME = 180SEARCH_DURATION = 5TRIP_DURATION = 20 DEPARTURE_INTERVAL = 5 Event = collections.namedtuple('Event', 'time proc action') # BEGIN TAXI_PROCESS def taxi_process(ident, trips, start_time=0): \"\"\"Отдает модели событие при каждом изменении состояния\"\"\" time = yield Event(start_time, ident, 'leave garage') for i in range(trips): time = yield Event(time, ident, 'pick up passenger') time = yield Event(time, ident, 'drop off passenger') yield Event(time, ident, 'going home')\n--- Страница 724 ---\n724 Приложение А. Листинги скриптов # конец процесса такси # END TAXI_PROCESS # BEGIN TAXI_SIMULATOR class Simulator: def __init__(self, procs_map): self.events = queue.PriorityQueue() self.procs = dict(procs_map) def run(self, end_time): \"\"\"Планирует и отображает события, пока не истечет время\"\"\" # планируем первое событие для каждой машины for _, proc in sorted(self.procs.items()): first_event = next(proc) self.events.put(first_event) # главный цикл моделирования sim_time = 0 while sim_time < end_time: if self.events.empty(): print('*** end of events ***') break current_event = self.events.get() sim_time, proc_id, previous_action = current_event print('taxi:', proc_id, proc_id * ' ', current_event) active_proc = self.procs[proc_id] next_time = sim_time + compute_duration(previous_action) try: next_event = active_proc.send(next_time) except StopIteration: del self.procs[proc_id] else: self.events.put(next_event) else: msg = '*** end of simulation time: {} events pending ***' print(msg.format(self.events.qsize()))# END TAXI_SIMULATOR def compute_duration(previous_action): \"\"\"Вычисляет длительность действия, пользуясь экспоненциальным распределением\"\"\" if previous_action in ['leave garage', 'drop off passenger']: # новое состояние – поиск пассажира interval = SEARCH_DURATION elif previous_action == 'pick up passenger': # Новое состояние - поездка interval = TRIP_DURATION elif previous_action == 'going home': interval = 1 else: raise ValueError('Unknown previous_action: %s' % previous_action)\n--- Страница 725 ---\n725 Глава 16: моделирование дискретных событий таксопарка return int(random.expovariate(1/interval)) + 1 def main(end_time=DEFAULT_END_TIME, num_taxis=DEFAULT_NUMBER_OF_TAXIS, seed=None): \"\"\"Инициализирует генератор случайных чисел, строит proc -объекты и запускает моделирование\"\"\" if seed is not None: random .seed(seed) # чтобы получать воспроизводимые результаты taxis = {i: taxi_process(i, (i+1)*2, i*DEPARTURE_INTERVAL) for i in range(num_taxis)} sim = Simulator(taxis) sim.run(end_time) if __name__ == '__main__': parser = argparse.ArgumentParser( description='Taxi fleet simulator.') parser.add_argument('-e', '--end-time', type=int, default=DEFAULT_END_TIME, help='simulation end time; default = %s' % DEFAULT_END_TIME) parser.add_argument('-t', '--taxis', type=int, default=DEFAULT_NUMBER_OF_TAXIS, help='number of taxis running; default = %s' % DEFAULT_NUMBER_OF_TAXIS) parser.add_argument('-s', '--seed', type=int, default=None, help='random generator seed (for testing)') args = parser.parse_args() main(args.end_time, args.taxis, args.seed) \"\"\" Sample run from the command line, seed=3, maximum elapsed time=120::# BEGIN TAXI_SAMPLE_RUN $ python3 taxi_sim.py -s 3 -e 120taxi: 0 Event(time=0, proc=0, action='leave garage')taxi: 0 Event(time=2, proc=0, action='pick up passenger')taxi: 1 Event(time=5, proc=1, action='leave garage')taxi: 1 Event(time=8, proc=1, action='pick up passenger')taxi: 2 Event(time=10, proc=2, action='leave garage') taxi: 2 Event(time=15, proc=2, action='pick up passenger') taxi: 2 Event(time=17, proc=2, action='drop off passenger') taxi: 0 Event(time=18, proc=0, action='drop off passenger')taxi: 2 Event(time=18, proc=2, action='pick up passenger') taxi: 2 Event(time=25, proc=2, action='drop off passenger') taxi: 1 Event(time=27, proc=1, action='drop off passenger')taxi: 2 Event(time=27, proc=2, action='pick up passenger') taxi: 0 Event(time=28, proc=0, action='pick up passenger')\n--- Страница 726 ---\n726 Приложение А. Листинги скриптов taxi: 2 Event(time=40, proc=2, action='drop off passenger') taxi: 2 Event(time=44, proc=2, action='pick up passenger') taxi: 1 Event(time=55, proc=1, action='pick up passenger')taxi: 1 Event(time=59, proc=1, action='drop off passenger')taxi: 0 Event(time=65, proc=0, action='drop off passenger')taxi: 1 Event(time=65, proc=1, action='pick up passenger')taxi: 2 Event(time=65, proc=2, action='drop off passenger') taxi: 2 Event(time=72, proc=2, action='pick up passenger') taxi: 0 Event(time=76, proc=0, action='going home')taxi: 1 Event(time=80, proc=1, action='drop off passenger')taxi: 1 Event(time=88, proc=1, action='pick up passenger')taxi: 2 Event(time=95, proc=2, action='drop off passenger') taxi: 2 Event(time=97, proc=2, action='pick up passenger') taxi: 2 Event(time=98, proc=2, action='drop off passenger') taxi: 1 Event(time=106, proc=1, action='drop off passenger')taxi: 2 Event(time=109, proc=2, action='going home') taxi: 1 Event(time=110, proc=1, action='going home')*** end of events ***# END TAXI_SAMPLE_RUN \"\"\" Глава 17: примеры, относящиеся к криптографии Эти скрипты использовались при демонстрации применения futures.ProcessPoo- lExecutor для запуска счетных задач. Код в примере A.7 шифрует и дешифрирует массивы случайных байтов с по- A.7 шифрует и дешифрирует массивы случайных байтов с по-.7 шифрует и дешифрирует массивы случайных байтов с по- мощью алгоритм а RC4. Для его работы необходим модуль arcfour.py (пример A.8). Пример A.7. arcfour_futures.py: пример futures.ProcessPoolExecutor import sys import time from concurrent import futuresfrom random import randrange from arcfour import arcfour JOBS = 12 SIZE = 2**18 KEY = b\"'Twas brillig, and the slithy toves\\nDid gyre\" STATUS = '{} workers, elapsed time: {:.2f}s' def arcfour_test(size, key): in_text = bytearray(randrange(256) for i in range(size)) cypher_text = arcfour(key, in_text) out_text = arcfour(key, cypher_text) assert in_text == out_text, 'Failed arcfour_test'\n--- Страница 727 ---\n727 Глава 17: примеры, относящиеся к криптографии return size def main(workers=None): if workers: workers = int(workers) t0 = time.time() with futures.ProcessPoolExecutor(workers) as executor: actual_workers = executor._max_workers to_do = [] for i in range(JOBS, 0, -1): size = SIZE + int(SIZE / JOBS * (i - JOBS/2)) job = executor.submit(arcfour_test, size, KEY) to_do.append(job) for future in futures.as_completed(to_do): res = future.result() print('{:.1f} KB'.format(res/2**10)) print(STATUS.format(actual_workers, time.time() - t0))if __name__ == '__main__': if len(sys.argv) == 2: workers = int(sys.argv[1]) else: workers = None main(workers) В примере A.8 реализован алгоритм шифрования RC4 на чистом Python. Пример A.8. arcfour .py: код совместим с алгоритмом RC4 \"\"\"совместим с алгоритм ом RC4\"\"\" def arcfour(key, in_bytes, loops=20): kbox = bytearray(256) # create key box for i, car in enumerate(key): # copy key and vector kbox[i] = car j = len(key) for i in range(j, 256): # repeat until full kbox[i] = kbox[i-j] # [1] инициализируем sbox sbox = bytearray(range(256)) # повторяем цикл перемешивания sbox, как рекомендовано в CipherSaber-2 # http://ciphersaber.gurus.com/faq.html#cs2 j = 0 for k in range(loops): for i in range(256): j = (j + sbox[i] + kbox[i]) % 256 sbox[i], sbox[j] = sbox[j], sbox[i] # главный цикл\n--- Страница 728 ---\n728 Приложение А. Листинги скриптов i = 0 j = 0 out_bytes = bytearray() for car in in_bytes: i = (i + 1) % 256 # [2] тасуем sbox j = (j + sbox[i]) % 256 sbox[i], sbox[j] = sbox[j], sbox[i] # [3] вычисляем t t = (sbox[i] + sbox[j]) % 256 k = sbox[t] car = car ^ k out_bytes.append(car) return out_bytes def test(): from time import time clear = bytearray(b'1234567890' * 100000) t0 = time() cipher = arcfour(b'key', clear) print('elapsed time: %.2fs' % (time() - t0)) result = arcfour(b'key', cipher) assert result == clear, '%r != %r' % (result, clear) print('elapsed time: %.2fs' % (time() - t0)) print('OK') if __name__ == '__main__': test() В примере A.9 алгоритм хэширования SHA-256 применяется к массивам слу- A.9 алгоритм хэширования SHA-256 применяется к массивам слу-.9 алгоритм хэширования SHA-256 применяется к массивам слу- SHA-256 применяется к массивам слу- -256 применяется к массивам слу- чайных байтов. Используется модуль hashlib из стандартной библиотеки, кото- рый, в свою очередь, основан на библиотеке OpenSSL, написанной на C. Пример A.9. sha_futures.py: пример futures.ProcessPoolExecutor import sys import timeimport hashlib from concurrent import futures from random import randrange JOBS = 12 SIZE = 2**20STATUS = '{} workers, elapsed time: {:.2f}s' def sha(size): data = bytearray(randrange(256) for i in range(size))\n--- Страница 729 ---\n729 Глава 17: примеры HTTP-клиентов из серии flags2 algo = hashlib.new('sha256') algo.update(data) return algo.hexdigest() def main(workers=None): if workers: workers = int(workers) t0 = time.time() with futures.ProcessPoolExecutor(workers) as executor: actual_workers = executor._max_workers to_do = (executor.submit(sha, SIZE) for i in range(JOBS)) for future in futures.as_completed(to_do): res = future.result() print(res) print(STATUS.format(actual_workers, time.time() - t0))if __name__ == '__main__': if len(sys.argv) == 2: workers = int(sys.argv[1]) else: workers = None main(workers) Глава 17: примеры HTTP-клиентов из серии flags2 Во всех примерах flags2 -скриптов из раздела «Загрузка с индикацией хода выполнения и обработкой ошибок» главы 17 используются функции из модуля flags2_common.py (пример A.10). Пример A.10. flags2_common.py \"\"\"Служебные функции ддя второй серии примеров загрузки флагов. \"\"\" import os import timeimport sysimport stringimport argparsefrom collections import namedtuplefrom enum import Enum Result = namedtuple('Result', 'status data') HTTPStatus = Enum('Status', 'ok not_found error')POP20_CC = ('CN IN US ID BR PK NG BD RU JP '\n--- Страница 730 ---\n730 Приложение А. Листинги скриптов 'MX PH VN ET EG DE IR TR CD FR').split() DEFAULT_CONCUR_REQ = 1 MAX_CONCUR_REQ = 1 SERVERS = { 'REMOTE': 'http://flupy.org/data/flags', 'LOCAL': 'http://localhost:8001/flags', 'DELAY': 'http://localhost:8002/flags', 'ERROR': 'http://localhost:8003/flags',}DEFAULT_SERVER = 'LOCAL' DEST_DIR = 'downloads/' COUNTRY_CODES_FILE = 'country_codes.txt' def save_flag(img, filename): path = os.path.join(DEST_DIR, filename) with open(path, 'wb') as fp: fp.write(img) def initial_report(cc_list, actual_req, server_label): if len(cc_list) <= 10: cc_msg = ', '.join(cc_list) else: cc_msg = 'from {} to {}'.format(cc_list[0], cc_list[-1]) print('{} site: {}'.format(server_label, SERVERS[server_label])) msg = 'Searching for {} flag{}: {}' plural = 's' if len(cc_list) != 1 else '' print(msg.format(len(cc_list), plural, cc_msg)) plural = 's' if actual_req != 1 else '' msg = '{} concurrent connection{} will be used.' print(msg.format(actual_req, plural)) def final_report(cc_list, counter, start_time): elapsed = time.time() - start_time print('-' * 20) msg = '{} flag{} downloaded.' plural = 's' if counter[HTTPStatus.ok] != 1 else '' print(msg.format(counter[HTTPStatus.ok], plural)) if counter[HTTPStatus.not_found]: print(counter[HTTPStatus.not_found], 'not found.') if counter[HTTPStatus.error]: plural = 's' if counter[HTTPStatus.error] != 1 else '' print('{} error{}.'.format(counter[HTTPStatus.error], plural)) print('Elapsed time: {:.2f}s'.format(elapsed)) def expand_cc_args(every_cc, all_cc, cc_args, limit): codes = set() A_Z = string.ascii_uppercase if every_cc: codes.update(a+b for a in A_Z for b in A_Z)\n--- Страница 731 ---\n731 Глава 17: примеры HTTP-клиентов из серии flags2 elif all_cc: with open(COUNTRY_CODES_FILE) as fp: text = fp.read() codes.update(text.split()) else: for cc in (c.upper() for c in cc_args): if len(cc) == 1 and cc in A_Z: codes.update(cc+c for c in A_Z) elif len(cc) == 2 and all(c in A_Z for c in cc): codes.add(cc) else: msg = 'each CC argument must be A to Z or AA to ZZ.' raise ValueError('*** Usage error: '+msg) return sorted(codes)[:limit] def process_args(default_concur_req): server_options = ', '.join(sorted(SERVERS)) parser = argparse.ArgumentParser( description='Download flags for country codes. ' 'Default: top 20 countries by population.') parser.add_argument('cc', metavar='CC', nargs='*', help='country code or 1st letter (eg. B for BA BZ)') parser.add_argument('-a', '--all', action='store_true', help='get all available flags (AD to ZW)') parser.add_argument('-e', '--every', action='store_true', help='get flags for every possible code (AA ZZ)') parser.add_argument('-l', '--limit', metavar='N', type=int, help='limit to N first codes', default=sys.maxsize) parser.add_argument('-m', '--max_req', metavar='CONCURRENT', type=int, default=default_concur_req, help='maximum concurrent requests (default={})' .format(default_concur_req)) parser.add_argument('-s', '--server', metavar='LABEL', default=DEFAULT_SERVER, help='Server to hit; one of {} (default={})' .format(server_options, DEFAULT_SERVER)) parser.add_argument('-v', '--verbose', action='store_true', help='output detailed progress info') args = parser.parse_args() if args.max_req < 1: print('*** Usage error: --max_req CONCURRENT must be >= 1') parser.print_usage() sys.exit(1) if args.limit < 1: print('*** Usage error: --limit N must be >= 1') parser.print_usage() sys.exit(1) args.server = args.server.upper() if args.server not in SERVERS: print('*** Usage error: --server LABEL must be one of', server_options) parser.print_usage() sys.exit(1)\n--- Страница 732 ---\n732 Приложение А. Листинги скриптов try: cc_list = expand_cc_args(args.every, args.all, args.cc, args.limit) except ValueError as exc: print(exc.args[0]) parser.print_usage() sys.exit(1) if not cc_list: cc_list = sorted(POP20_CC) return args, cc_list def main(download_many, default_concur_req, max_concur_req): args, cc_list = process_args(default_concur_req) actual_req = min(args.max_req, max_concur_req, len(cc_list)) initial_report(cc_list, actual_req, args.server) base_url = SERVERS[args.server] t0 = time.time() counter = download_many(cc_list, base_url, args.verbose, actual_req) assert sum(counter.values()) == len(cc_list), \\ 'some downloads are unaccounted for' final_report(cc_list, counter, t0) Скрипт flags2_sequential.py (пример A.11) является эталоном для сравнения с параллельными реализациями. В скрипте flags2_threadpool.py (пример 17.14) так- же используются функции get_flag и download_one из flags2_sequential.py . Пример A.11. flags2_sequential.py \"\"\"Загружает флаги стран (с обработкой ошибок). Sequential versionSample run:: $ python3 flags2_sequential.py -s DELAY b DELAY site: http://localhost:8002/flags Searching for 26 flags: from BA to BZ 1 concurrent connection will be used. -------------------- 17 flags downloaded. 9 not found. Elapsed time: 13.36s \"\"\"import collectionsimport requests import tqdm from flags2_common import main, save_flag, HTTPStatus, ResultDEFAULT_CONCUR_REQ = 1\n--- Страница 733 ---\n733 Глава 17: примеры HTTP-клиентов из серии flags2 MAX_CONCUR_REQ = 1 # BEGIN FLAGS2_BASIC_HTTP_FUNCTIONS def get_flag(base_url, cc): url = '{}/{cc}/{cc}.gif'.format(base_url, cc=cc.lower()) resp = requests.get(url) if resp.status_code != 200: resp.raise_for_status() return resp.content def download_one(cc, base_url, verbose=False): try: image = get_flag(base_url, cc) except requests.exceptions.HTTPError as exc: res = exc.response if res.status_code == 404: status = HTTPStatus.not_found msg = 'not found' else: raise else: save_flag(image, cc.lower() + '.gif') status = HTTPStatus.ok msg = 'OK' if verbose: print(cc, msg) return Result(status, cc) # END FLAGS2_BASIC_HTTP_FUNCTIONS # BEGIN FLAGS2_DOWNLOAD_MANY_SEQUENTIAL def download_many(cc_list, base_url, verbose, max_req): counter = collections.Counter() cc_iter = sorted(cc_list) if not verbose: cc_iter = tqdm.tqdm(cc_iter) for cc in cc_iter: try: res = download_one(cc, base_url, verbose) except requests.exceptions.HTTPError as exc: error_msg = 'HTTP error {res.status_code} - {res.reason}' error_msg = error_msg.format(res=exc.response) except requests.exceptions.ConnectionError as exc: error_msg = 'Connection error' else: error_msg = '' status = res.status if error_msg: status = HTTPStatus.error counter[status] += 1 if verbose and error_msg:\n--- Страница 734 ---\n734 Приложение А. Листинги скриптов print('*** Error for {}: {}'.format(cc, error_msg)) return counter # END FLAGS2_DOWNLOAD_MANY_SEQUENTIAL if __name__ == '__main__': main(download_many, DEFAULT_CONCUR_REQ, MAX_CONCUR_REQ) Глава 19: скрипты и тесты для обработки набора данных OSCON В примере A.12 приведен тестовый скрипт для модуля schedule1.py (пример 19.9). Используется библиотека py.test и исполнитель тестов. Пример A.12. test_schedule1.py import shelve import pytest import schedule1 as schedule @pytest.yield_fixture def db(): with shelve.open(schedule.DB_NAME) as the_db: if schedule.CONFERENCE not in the_db: schedule.load_db(the_db) yield the_db def test_record_class(): rec = schedule.Record(spam=99, eggs=12) assert rec.spam == 99 assert rec.eggs == 12 def test_conference_record(db): assert schedule.CONFERENCE in db def test_speaker_record(db): speaker = db['speaker.3471'] assert speaker.name == 'Anna Martelli Ravenscroft' def test_event_record(db): event = db['event.33950'] assert event.name == 'There *Will* Be Bugs' def test_event_venue(db): event = db['event.33950'] assert event.venue_serial == 1449 В примере A.13 приведен полный текст скрипта schedule2.py , который был раз- бит на четыре части в разделе «Выборка связанных записей с помощью свойств» главы 19.\n--- Страница 735 ---\n735 Глава 19: скрипты и тесты для обработки набора данных OSCON Пример A.13. schedule2.py \"\"\" schedule2.py: обход набора данных OSCON >>> import shelve >>> db = shelve.open(DB_NAME) >>> if CONFERENCE not in db: load_db(db) # BEGIN SCHEDULE2_DEMO >>> DbRecord.set_db(db) >>> event = DbRecord.fetch('event.33950') >>> event <Event 'There *Will* Be Bugs'> >>> event.venue <DbRecord serial='venue.1449'> >>> event.venue.name 'Portland 251' >>> for spkr in event.speakers: print('{0.serial}: {0.name}'.format(spkr)) speaker.3471: Anna Martelli Ravenscroft speaker.5199: Alex Martelli # END SCHEDULE2_DEMO >>> db.close()\"\"\"# BEGIN SCHEDULE2_RECORD import warningsimport inspect import osconfeedDB_NAME = 'data/schedule2_db' CONFERENCE = 'conference.115' class Record: def __init__(self, **kwargs): self.__dict__.update(kwargs) def __eq__(self, other): if isinstance(other, Record): return self.__dict__ == other.__dict__ else: return NotImplemented# END SCHEDULE2_RECORD # BEGIN SCHEDULE2_DBRECORD\n--- Страница 736 ---\n736 Приложение А. Листинги скриптов class MissingDatabaseError(RuntimeError): \"\"\"Возбуждается, когда база данных нужна, но не была задана.\"\"\" class DbRecord(Record): __db = None @staticmethod def set_db(db): DbRecord.__db = db @staticmethod def get_db(): return DbRecord.__db @classmethod def fetch(cls, ident): db = cls.get_db() try: return db[ident] except TypeError: if db is None: msg = \"database not set; call '{}.set_db(my_db)'\" raise MissingDatabaseError(msg.format(cls.__name__)) else: raise def __repr__(self): if hasattr(self, 'serial'): cls_name = self.__class__.__name__ return '<{} serial={!r}>'.format(cls_name, self.serial) else: return super().__repr__()# END SCHEDULE2_DBRECORD # BEGIN SCHEDULE2_EVENT class Event(DbRecord): @property def venue(self): key = 'venue.{}'.format(self.venue_serial) return self.__class__.fetch(key) @property def speakers(self): if not hasattr(self, '_speaker_objs'): spkr_serials = self.__dict__['speakers'] fetch = self.__class__.fetch self._speaker_objs = [fetch('speaker.{}'.format(key)) for key in spkr_serials] return self._speaker_objs def __repr__(self):\n--- Страница 737 ---\n737 Глава 19: скрипты и тесты для обработки набора данных OSCON if hasattr(self, 'name'): cls_name = self.__class__.__name__ return '<{} {!r}>'.format(cls_name, self.name) else: return super().__repr__()# END SCHEDULE2_EVENT # BEGIN SCHEDULE2_LOAD def load_db(db): raw_data = osconfeed.load() warnings.warn('loading ' + DB_NAME) for collection, rec_list in raw_data['Schedule'].items(): record_type = collection[:-1] cls_name = record_type.capitalize() cls = globals().get(cls_name, DbRecord) if inspect.isclass(cls) and issubclass(cls, DbRecord): factory = cls else: factory = DbRecord for record in rec_list: key = '{}.{}'.format(record_type, record['serial']) record['serial'] = key db[key] = factory(**record)# END SCHEDULE2_LOAD Код из примера A.14 использовался для тестирования примера A.13 с приме- A.14 использовался для тестирования примера A.13 с приме-.14 использовался для тестирования примера A.13 с приме- A.13 с приме-.13 с приме- нением библиотеки py.test . Пример A.14. test_schedule2.py import shelve import pytest import schedule2 as schedule @pytest.yield_fixture def db(): with shelve.open(schedule.DB_NAME) as the_db: if schedule.CONFERENCE not in the_db: schedule.load_db(the_db) yield the_db def test_record_attr_access(): rec = schedule.Record(spam=99, eggs=12) assert rec.spam == 99 assert rec.eggs == 12 def test_record_repr(): rec = schedule.DbRecord(spam=99, eggs=12) assert 'DbRecord object at 0x' in repr(rec) rec2 = schedule.DbRecord(serial=13)\n--- Страница 738 ---\n738 Приложение А. Листинги скриптов assert repr(rec2) == \"<DbRecord serial=13>\" def test_conference_record(db): assert schedule.CONFERENCE in db def test_speaker_record(db): speaker = db['speaker.3471'] assert speaker.name == 'Anna Martelli Ravenscroft' def test_missing_db_exception(): with pytest.raises(schedule.MissingDatabaseError): schedule.DbRecord.fetch('venue.1585') def test_dbrecord(db): schedule.DbRecord.set_db(db) venue = schedule.DbRecord.fetch('venue.1585') assert venue.name == 'Exhibit Hall B' def test_event_record(db): event = db['event.33950'] assert repr(event) == \"<Event 'There *Will* Be Bugs'>\" def test_event_venue(db): schedule.Event.set_db(db) event = db['event.33950'] assert event.venue_serial == 1449 assert event.venue == db['venue.1449'] assert event.venue.name == 'Portland 251' def test_event_speakers(db): schedule.Event.set_db(db) event = db['event.33950'] assert len(event.speakers) == 2 anna_and_alex = [db['speaker.3471'], db['speaker.5199']] assert event.speakers == anna_and_alex def test_event_no_speakers(db): schedule.Event.set_db(db) event = db['event.36848'] assert len(event.speakers) == 0\n--- Страница 739 ---\nТЕРМИНОЛОГИЯ PYTHON Конечно, многие из приведенных ниже терминов носят универсальный характер, но в определениях встречаются оттенки, специфичные для сообщества Python. См. также официальный глоссарий Python по адресу https://docs.python.org/3/ glossary.html . абстрактный базовый класс (ABC) Класс, которому можно только унаследовать, но нельзя создать его экзем- пляры. С помощью ABC формализованы интерфейсы в Python. Вместо на-следования ABC класс может также объявить о том, что поддерживает интер-фейс, зарегистрировавшись как виртуальный подкласс ABC. акцессор Метод, который предоставляет доступ к одному атрибуту данных. Неко- торые авторы называют акцессорами методы чтения и установки, другие при- меняют этот термин только к методам чтения, а методы установки называют мутаторами (mutators). аргумент Выражение, передаваемое функции при вызове. В жаргоне Python аргу- мент и параметр – почти всегда синонимы. О различиях в семантике и упо- треблении этих терминов см. статью параметр . атрибут Атрибуты-методы и атрибуты-данные (т. е. «поля» в терминологии Java) в Python имеют общее название «атрибут». Метод – это атрибут, являющийся вызываемым объектом (обычно функцией, но это необязательно). атрибут хранения Атрибут управляемого экземпляра , в котором хранится значение атрибута, управляемого дескриптором . См. также управляемый атрибут . байтовая строка Неудачно название, употребляемое для типов bytes и bytearray в Python 3. В Python 2 тип str на самом деле являлся байтовой строкой, и тогда термин имел смысл, поскольку позволял провести различие между типами str и unicode . В Python 3 в нем отпала необходимость, поэтому я старался употре- блять термин последовательность байтов всюду, где имел в виду … последова- тельность байтов вообще.\n--- Страница 740 ---\n740 Терминология Python байтоподобный объект Последовательность байтов общего вида. Самыми распространенными байтоподобными встроенными типами являются bytes , bytearray и memoryview , но к той же категории относятся и другие объекты, поддерживающие низкоу-ровневый протокол буфера CPython, если их элементами являются отдельные байты. бородавка (wart) Недоработка в языке. Знаменитая статья Эндрю Кухлинга «Python warts», по признанию BDFL , повлияла на решение отказаться от обратной совмести- мости при проектировании Python 3, потому что большинство недостатков нельзя было исправить по-другому. Многие поднятые Кухлингом проблемы устранены в Python 3. быстрое прекращение Подход к проектированию систем, рекомендующий сообщать об ошибках как можно быстрее. Python придерживается этого принципа в большей сте-пени, чем большинство динамических языков. Например, в нем нет значения «undefined»: использование переменной до инициализации считается ошиб-кой, а выражение my_dict[k] возбуждает исключение, если ключ k отсутствует (в отличие от JavaScript). Еще пример: параллельное присваивание путем рас-паковки кортежа работает, только если каждому элементу явно сопоставлена переменная, тогда как Ruby молчаливо смиряется с несовпадением количества элементов и просто игнорирует неиспользованные элементы в правой части присваивания или присваивает nil лишним элементам в левой части. виртуальный подкласс Класс, который не наследует суперклассу, а зарегистрирован методом TheSuperClass.register(TheSubClass) . См. документацию по методу abc. ABCMeta.register (http://bit.ly/1DeDbKf ). встроенная функция (BIF) Функция, поставляемая вместе с интерпретатором Python и написанная на языке его реализации (т. е. на C в случае CPython, на Java в случае Jython и т. д.). Термин часто употребляется только по отношению к функциям, которые не нужно импортировать; они документированы в главе 2 «Встроенные функ-ции» ( http://docs.python.org/library/functions.html ) справочного руководства по стандартной библиотеке Python. Но встроенные модули, например sys, math , re и т. д. тоже содержат встроенные функции. вызываемый объект Объект, который можно вызвать с помощью оператора (), чтобы он вернул результат или выполнил какое-то действие. В Python есть семь видов вызыва-емых объектов: пользовательские функции, встроенные функции, встроенные методы, методы экземпляра, генераторные функции, классы и экземпляры классов, в которых реализован специальный метод __call__ .\n--- Страница 741 ---\n741 Терминология Python генератор Итератор, построенный генераторной функцией или генераторным вы- ражением, который может порождать значения не обязательно путем обхода коллекции. Канонический пример – генератор, порождающий последователь-ность чисел Фибоначчи, которая, будучи бесконечна, не смогла бы поместить-ся ни в какую коллекцию. Иногда термин применяется для описания самой генераторной функции , а не только объекта, возвращенного ей в качестве ре- зультата. генераторная функция Функция, в теле которой встречается ключевое слово yield . Будучи вы- звана, такая функция возвращает генератор . генераторное выражение Выражение, заключенное в круглые скобки; синтаксически выглядит так же, как списковое включение , но возвращает не список, а генератор. Можно считать, что генераторное выражение – это ленивый вариант спискового вклю- чения . См. ленивый . глубокая копия Копия объекта, в которой все объекты-атрибуты также скопированы. Срав- ните с поверхностной копией . двоичная последовательность Общий термин, применяемый к типам последовательностей, элементами которых являются байты. К встроенным двоичным последовательностям от-носятся byte , bytearray и memoryview . декоратор Вызываемый объект A, который возвращает другой вызываемый объект B и активируется с помощью конструкции @A, помещенной непосредственно перед определением вызываемого объекта C. Встретив такой код, интерпрета- тор Python вызывает A(C) и связывает получившийся в результате объект B с переменной, которая до этого была связана с C, тем самым подменяя опреде- ление C определением B. Если конечный вызываемый объект C – функция, то A называется декоратором функции, а если C – класс, то декоратором класса. декорирование имен Автоматическое переименование закрытых атрибутов из __x в _MyClass__x , осуществляемое интерпретатором Python на этапе выполнения. дескриптор Класс, в котором реализован хотя бы один из специальных методов __get__ , __set__ , __delete__ , становится дескриптором, когда его экземпляр использу- ется в качестве атрибута класса в каком-то другом – управляемом – классе. Дескрипторы управляют доступом к управляемым атрибутам управляемого класса и их удалением, а данные часто хранятся в управляемых экземплярах .\n--- Страница 742 ---\n742 Терминология Python дзен Python Введите команду import this в любой оболочке Python, начиная с версии 2.2. динамическая типизация (утиная типизация, duck typing) Вид полиморфизма, при котором функции могут работать с любым объ- ектом, в котором реализованы необходимые методы, независимо от его класса или явных объявлений интерфейсов. живучесть Асинхронная, многопоточная или распределенная система обладает свой- ством живучести, если «нечто ожидаемое происходит в конечном итоге» (т. е. даже если некое ожидаемое вычисление не происходит сию минуту, то рано или поздно оно завершится). Система, оказавшаяся в состоянии взаимобло-кировки, утратила живучесть. запашок кода Закономерность в коде, наводящая на мысль о том, что в проекте програм- мы есть изъян. Например, чрезмерное использование функции isinstance для проверки принадлежности конкретному классу «смердит», поскольку такую программу будет трудно обобщить, когда потребуется поддержать новые типы. идиоматичный «Способ разговаривать, естественный для носителей языка» (определение Princeton W ordNet). инициализатор Более подходящее название для метода __init__ (вместо конструктор ). Задачей __init__ является инициализация экземпляра, полученного в аргу- менте self . Собственно конструирование экземпляра производится методом __new__ . См. конструктор . инициализировать (prime) Вызывать функцию next(coro) для сопрограммы, чтобы она выполнилась до первого выражения yield и была готова принимать значения, переданные в последующих вызовах coro.send(value) . итератор Любой объект, реализующий метод __next__ без аргументов, который воз- вращает следующий элемент последовательности или возбуждает исключе-ние StopIteration , если элементов не осталось. Итераторы в Python реализу- ют также метод __iter__ , поэтому являются итерируемыми объектами . Клас- сические итераторы, описанные в оригинальном паттерне проектирования, возвращают элементы коллекции. Г енератор также является итератором , но обладает большей гибкостью. См. генератор . итерируемый объект Любой объект, от которого встроенная функция iter может получить ите- ратор. Итерируемый объект играет роль источника элементов для цикла for,\n--- Страница 743 ---\n743 Терминология Python спискового включения и распаковки кортежа. Объекты, которые реализуют метод __iter__ , возвращающий итератор , являются итерируемыми. По- следовательности всегда итерируемы, другие объекты, реализующие метод __getitem__ , также могут быть итерируемыми. класс Программная конструкция для определения нового типа с атрибутами-дан- ными и методами, описывающими допустимые операции над ними. См. также тип . класс-примесь Класс, предназначенный для наследования вместе с другими классами в дереве множественного наследования классов. Никогда не следует создавать экземпляры класса-примеси, а конкретный подкласс примеси должен насле-довать еще какому-то классу, не являющемуся примесью. книга GoF Книга «Паттерны проектирования: приемы объектно-ориентированного проектирования» (Питер, 2007). Ее авторов, Эриха Гамму, Ричарда Хелма, Ральфа Джонсона и Джона Влиссидеса, называют «бандой четырех» (Gang of Four – GoF). кодек (кодировщик/декодировщик) Модуль, содержащий функции кодирования и декодирования, обычно из str в bytes и обратно, хотя в Python есть несколько кодеков, выполняющих преобразования из bytes в bytes и из str в str. кодовая позиция Целое число в диапазоне от 0 до 0x10FFFF , которое служит для иденти- фикации элемента в базе данных символов Unicode. В версии Unicode 7.0 под символы занято менее 3 % всех кодовых позиций. В документации по Python этот термин иногда записывается одним словом codepoint, а иногда двумя – code point. Например, в главе 2 «Встроенные функции» ( http://docs.python.org/ library/functions.html ) справочного руководства по языку Python написано, что функция chr принимает целое число – «codepoint», тогда как в описании об- ратной к ней функции ord говорится, что она возвращает «Unicode code point». коллекция Общий термин для обозначения структур данных, составленных из элемен- тов, к которым можно обращаться по отдельности. Некоторые коллекции мо-гут содержать объекты произвольных типов (см. контейнер ), другие – только объекты одного атомарного типа (см. плоская последовательность ). И list , и bytes – коллекции, но list – контейнер, а bytes – плоская последовательность. конструктор Неформально определенный в классе метод экземпляра __init__ называ- ется конструктором, поскольку его семантика похожа на семантику конструк-\n--- Страница 744 ---\n744 Терминология Python тора в Java. Однако правильно называть метод __init__ инициализатором , потому что он не строит экземпляр, а получает его в аргументе self . Термин конструктор больше подходит методу классу __new__ , который интерпретатор Python вызывает до __init__ и который отвечает за создание и возврат экзем- пляра. См. также инициализатор . контейнер Объект, в котором хранятся ссылки на другие объекты. Большинство, но не все типы коллекций в Python являются контейнерами. Сравните с плоской последовательностью , которая является коллекцией, но не контейнером. контекстный менеджер Объект, в котором реализованы методы __enter__ и __exit__ ; используется вместе с блоком with . ленивый Итерируемый объект, который порождает элементы по запросу. В Python генераторы являются ленивыми. Противоположность – энергичный . магический метод То же, что специальный метод . метакласс Класс, экземплярами которого являются классы. По умолчанию классы Python являются экземплярами type , например, type(int) – это тип int, по- этому type – метакласс. Пользователь может определить свои метаклассы, унаследовав классу type . метапрограммирование Методика написания программ, которые используют информацию о себе, доступную на этапе выполнения, для изменения собственного поведения. Например, ORM может проинспектировать объявления классов модели и ре- шить, как следует проверять поля в записи базы данных и преобразовывать типы базы данных в типы Python. мутатор См. акцессор . непереопределяющий дескриптор Дескриптор , в котором не реализован метод __set__ и который поэтому не вмешивается в установку управляемого атрибута в управляемом экземпляре . Следовательно, если в управляемом экземпляре установлен одноименный атрибут, то он замаскирует дескриптор в данном экземпляре. Называется так-же дескриптором без данных или маскируемым дескриптором. Сравните с переопределяющим дескриптором . несвязанный метод Метод экземпляра, доступ к которому производится через сам класс, не связан ни с каким экземпляром, поэтому его называют «несвязанным мето-\n--- Страница 745 ---\n745 Терминология Python дом». Чтобы несвязанный метод работал правильно, ему необходимо явно пе- редать экземпляр класса в первом аргументе. Этот экземпляр присваивается аргументу self метода. См. связанный метод . обобщенная функция Группа функций, предназначенных для реализации одной и той же опера- ции способом, зависящим от типа объекта. Начиная с версии Python 3.4, де-коратор functools.singledispatch является стандартным способом создания обобщенных функций. В других языках они называются мультиметодами. объект ссылки Объект, на который указывает ссылка. Чаще всего этот термин употребля- ется в контексте слабых ссылок . о вреде (considered harmful) Эдсгер Дейкстра в сообщении под названием «Go T o Statement Considered Harmful» (О вреде оператора go to) создал шаблон для названий работ с критикой той или иной техники программирования. В статьи википедии «Considered harmful» ( http://en.wikipedia.org/wiki/Considered_harmful ) при- водится несколько примеров таких работ, в том числе «Considered Harmful Essays Considered Harmful» (О вреде эссе на тему о вреде) ( http://meyerweb. com/eric/comment/chech.html ) Эрика А. Мейера. одиночка, синглтон Объект, являющийся единственным экземпляром своего класса, – обычно не случайно, а потому что класс специально спроектирован так, чтобы предот-вратить создание нескольких экземпляров. Существует также паттерн проек-тирования Одиночка, содержащий рецепт создания таких классов. В Python объект None является одиночкой. параллельное присваивание Присваивание нескольким переменным значений элементов итерируемо- го объекта. Синтаксически выглядит так: a, b = [c, d] . Иногда называется деструктурирующим присваиванием (destructuring assignment). Это типичное применение распаковки кортежа . параметр В объявлении функции указывается 0 или более «формальных параме- тров» – несвязанных локальных переменных. При вызове функции пере-данные ей аргументы , или «фактические параметры» связываются с этими переменными. В этой книге я старался называть аргументами фактические параметры, передаваемые функции, оставив термин параметр для формаль- ных параметров в объявлении функции. Но это не всегда возможно, потому что слова параметр и аргумент употребляются в документации и API как вза- имозаменяемые синонимы. См. аргумент . партизанское латание Динамическое изменение модуля, класса или функции во время выпол-\n--- Страница 746 ---\n746 Терминология Python нения, обычно чтобы исправить ошибки или добавить новые возможности. Поскольку это делается в памяти, а не путем модификации исходного кода, партизанская заплата действует, только пока работает запущенный экземпляр программы. Партизанское латание нарушает инкапсуляцию и обычно оказы-вается тесно связанным с деталями реализации, поэтому такая методика рас-ценивается как временный способ обхода проблемы и не рекомендуется в ка-честве средства интеграции кода. переопределяющий дескриптор Дескриптор , в котором реализован метод __set__ и который поэтому пере- хватывает и переопределяет все попытки установить управляемый атрибут в управляемом экземпляре . Называется также дескриптором данных и принуди- тельным дескриптором. Сравните с непереопределяющим дескриптором . питонический, в духе Python Используется как одобрительная оценка идиоматического кода на Python, в котором удачно используются средства языка, так что код получился лако-ничным, удобочитаемым и зачастую более быстрым. Так говорят и об API, позволяющем кодировать в стиле, который кажется естественным опытным программистам на Python. См. идиома . плоская последовательность Тип последовательности, подразумевающий хранение в ней самих объек- тов, а не ссылок на них. Встроенные типы str, bytes , bytearray , memoryview и array.array являются плоскими последовательностями. Сравните с типами list , tuple и collections.deque , которые являются контейнерными последо- вательностями. См. контейнер . поверхностная копия Копия объекта, в которой ссылки на все объекты-атрибуты разделяются с исходным объектом. Противоположность – глубокая копия . См. также сино- нимия . подмешанный метод Конкретная реализация метода, предоставленная абстрактным базовым классом или классом-примесью . полноправная функция Любая функция, являющаяся полноправным объектом языка (т. е. мо- жет быть создана во время выполнения, присвоена переменной, передана в качестве аргумента и возвращена другой функцией в качестве результата). В Python все функции полноправны. получение среза, срезка Создание подмножества последовательности с помощью нотации среза, например my_sequence[2:6] . Обычно операция среза копирует данные в новый объект; в частности, my_sequence[:] создает поверхностную копию всей после-\n--- Страница 747 ---\n747 Терминология Python довательности. Однако в случае объекта memoryview с помощью среза можно получить новый объект memoryview , разделяющий данный с исходным. пользовательский, определенный пользователем В документации по Python слово пользователь почти всегда относится к вам, ко мне – к любому программисту, пишущему на языке Python, – в от-личие от разработчиков, занимающихся реализацией интерпретатора Python. Поэтому слова «пользовательский класс» означают класс, написанный на Python, – отличие от встроенных классов, написанных на C, например str. последовательность Обобщенное название любой итерируемой структуры данных известного размера (например, len(s) ), которая допускает доступ к элементам по индек- сам, начинающимся с 0 (например, s[0] ). Слово последовательность входило в лексикон Python с самого начала, но лишь в версии Python 2.6 оно было формализовано в виде абстрактного класса collections.abc.Sequence . похожий на истину (truthy) Любое значение x, для которого вызов bool(x) возвращает True ; в Python функция bool неявно используется для вычисления объектов в булевом кон- тексте, например в условии if или в управляющем выражении цикла while . Противоположность – похожий на ложь . похожий на ложь (falsy) Любое значение x, для которого вызов bool(x) возвращает False ; в Python функция bool неявно используется для вычисления объектов в булевом кон- тексте, например в условии if или в управляющем выражении цикла while . Противоположность – похожий на истину . представление (view) В Python 3 представления – это специальные структуры данных, возвра- щаемые методами словаря dict : .keys() , .values() и .items() . Они предостав- ляют динамический взгляд на ключи и значения словаря без дублирования данных, которое имело место в Python 2, где эти методы возвращают списки. Все представления словаря – итерируемые объекты, поддерживающие опера-тор in. Кроме того, если все элементы, на которые ссылается представление, хэшируемые, то представление реализует также интерфейс collections .abc . Set. Так обстоит дело для всех представлений, возвращаемых методом .keys() , а также для представлений, возвращаемых методом .items() , если значения также хэшируемы. принцип единообразного доступа Бертран Мейер, создатель языка Eiffel, писал: «Все сервисы, предоставля- емые модулем, должны быть доступны с помощью единообразной нотации, скрывающей механизм реализации: хранение или вычисление». Благодаря свойствам и дескрипторам принцип единообразного доступа можно реализо-вать в Python. Еще одним проявлением этого принципа является отсутствие\n--- Страница 748 ---\n748 Терминология Python оператора new, вследствие чего вызов функции и создание объекта выглядят одинаково, т. е. вызывающая сторона не знает, чем является вызванный объ-ект: классом, функцией или еще каким-то вызываемым объектом. распаковка итерируемого объекта Современный, более точный синоним распаковки кортежа . См. также па- раллельное присваивание . распаковка кортежа Присваивание значений элементов итерируемого объекта кортежу пере- менных (например, first, second, third == my_list ). Этот термин рутин- но используется питонистами, но постепенно набирает популярность другой: распаковка итерируемого объекта . связанный метод Метод, доступ к которому производится через экземпляр, становится свя- зан с этим экземпляром. Любой метод на самом деле является дескриптором, при доступе к которому возвращается он сам, обернутый объектом, который связывает метод с экземпляром. Этот объект и является связанным методом. Его можно вызывать, не передавая значение self . Например, если выполня- лось присваивание my_method = my_obj.method , то впоследствии такой связан- ный метод можно вызывать как my_method() . Сравните с несвязанным методом . сериализация Преобразование объекта из структуры данных в памяти в двоичный или текстовый формат для хранения или передачи таким способом, который до-пускает последующую реконструкцию объекта в той же или другой системе. Модуль pickle поддерживает сериализацию произвольных объектов Python в двоичном формате. сильная ссылка Ссылка, которая не дает сборщику мусора уничтожить объект. Сравните со слабой ссылкой . синонимия Назначение двух и более имен одному и тому же объекту. Например, во фрагменте a = []; b = a переменные a и b – синонимы для одного и того же объекта списка. Синонимия естественно возникает в любом языке, где в пере-менных хранятся ссылки на объекты. Во избежание недоразумений просто от-кажитесь от представления о переменных как о ящиках, в которых хранятся объекты (объект не может находиться одновременно в двух ящиках). Лучше рассматривать переменную как этикетку, наклеенную на объект (на объект можно наклеить несколько этикеток). слабая ссылка Ссылка на объект особого вида, не увеличивающая счетчик ссылок на объект ссылки . Слабые ссылки создаются с помощью функций и структур данных в мо- дуле weakref .\n--- Страница 749 ---\n749 Терминология Python сопрограмма Генератор, применяемый для параллельного программирования; получа- ет значения от планировщика или от цикла обработки событий посредством вызова метода coro.send(value) . Термин может описывать как генераторную функцию, так и объект-генератор, полученный путем вызова генераторной функции. См. генератор . специальный метод Метод со специальным именем, например __getitem__ , которое начинается и заканчивается двумя знаками подчеркивания. Почти все специальные ме-тоды, распознаваемые Python, описаны в главе «Модель данных» ( http://bit. ly/1GsZwss ) справочного руководства по языку Python, но несколько методов, используемых только в специфических контекстах, документированы в дру-гих частях. Например, метод любого отображения __missing__ упоминается в разделе 4.10 «Типы отображений – dict» ( http://bit.ly/1QS9Ong ) руководства по стандартной библиотеке. списковое включение Выражение, заключенное в квадратные скобки, в котором используются ключевые слова for и in для построения списка путем обработки и фильтра- ции элементов из одного или нескольких итерируемых объектов. Списковое включение работает энергично. См. энергичный . строка документации (docstring) Если первое предложение в модуле, классе или функции является строко- вым литералом, то оно становится строкой документации объемлющего объ- екта, и интерпретатор сохраняет ее в атрибуте __doc__ этого объекта. См. также doctest -скрипт. тип Любая специфическая категория программных данных, определяемая множеством допустимых значений и операциями над ними. Некоторые типы Python близки к машинным типам данных (например, float и bytes ), тогда как другие являются их расширениями (например, тип int не ограничен размером машинного слова, а тип str может содержать многобайтовую последователь- ность кодовых позиций Unicode) или абстракциями очень высокого уровня (например, dict , deque и т. д.). Типы могут быть определены пользователем или встроены в интерпретатор («встроенные» типы). До унификации типов и классов в версии Python 2.2 типы и классы были различными сущностя-ми, и пользовательские классы не могли расширять встроенные типы. С той поры встроенные типы и классы «нового стиля» совместимы, и любой класс является экземпляром класса type . В Python 3 остались только классы «ново- го стиля». См. класс и метакласс . управляемый атрибу т Открытый атрибут, управляемый объектом-дескриптором. Хотя управляе- мый атрибут определен в управляемом классе , работает он как атрибут экзем-\n--- Страница 750 ---\n750 Терминология Python пляра (т. е. обычно имеет в каждом экземпляре независимое значение, которое хранится в атрибуте хранения ). См. дескриптор . управляемый класс Класс, в котором для управления одним или несколькими атрибутами ис- пользуется объект-дескриптор. См. дескриптор . управляемый экземпляр Экземпляр управляемого класса . См. управляемый атрибут и дескриптор . файлоподобный объект (file-like object) Неформально употребляется в официальной документации для обозна- чения объектов, которые реализуют протокол файла, включающий такие ме-тоды, как read , write , close и т. п. Распространенными вариантами являются текстовые файлы, содержащие строки в определенной кодировке и ориенти-рованные на построчные чтение и запись, экземпляры класса StringIO – тек- стовые файлы в памяти – и двоичные файлы, содержащие незакодированные байты. В последнем случае различают буферизованные и небуферизованные файлы. Начиная с версии Python 2.6, абстрактные базовые классы для стан-дартных типов файлов определены в модуле io. функция Строго говоря, объект, получающийся в результате вычисления блока def или лямбда-выражения. Неформально слово «функция» употребляется для описания любого вызываемого объекта, включая методы и иногда даже классы. В официальный список встроенных функций ( http://docs.python.org/ library/ functions.html ) входят несколько встроенных классов, в т. ч. dict , range и str. См. также вызываемый объект . функция высшего порядка Функция, которая принимает другую функцию в качестве аргумента, как sorted , map и filter , или функция, которая возвращает другую функцию, как декораторы в Python. хэшируемый Объект называется хэшируемым, если в нем реализованы методы __hash__ и __eq__ с дополнительными ограничениями: хэш-значение никогда не долж- но изменяться и, если a == b , то обязательно hash(a) == hash(b) . Большинство неизменяемых встроенных типов хэшируемые, но кортеж является хэшируе-мым, только если каждый его элемент хэшируемый. энергичный Итерируемый объект, который сразу строит все свои элементы. В Python списковое включение – энергичная операция. Противоположность – ленивый . этап импорта Этап первоначального выполнения модуля, когда его код загружается в интерпретатор Python, обрабатывается от начала до конца и компилируется в\n--- Страница 751 ---\n751 Терминология Python байт-код. Именно на этом этапе определяются и становятся объектами классы и функции. Тогда же выполняются декораторы. ABC (язык программирования) Язык программирования, созданный Лео Геуртсом (Leo Geurts), Ламбертом Мертенсом (Lambert Meertens) и Стивеном Пембертоном (Steven Pemberton). Гвидо ван Россум, автор языка Python, 1980-х годах работал программистом и отвечал за реализацию окружения ABC. Синтаксически значимые отступы, встроенные кортежи и словари, распаковка кортежей, семантика цикла for и единообразная обработка всех типов последовательностей – вот некоторые отличительные особенности Python, заимствованные у ABC. BDFL Benevolent Dictator For Life (пожизненный великодушный диктатор) – ти- тул Гвидо ван Россума, создавшего язык Python. BOM Byte Order Mark (маркер порядка байтов) – последовательность байтов, которая может встречаться в начале файла в кодировке UTF-16. BOM – это символ с кодом U+FEFF ( ZERO WIDTH NO-BREAK SPACE ), который представлен в виде b’\\xfe\\xff’ в компьютерах с тупоконечной архитектурой и в виде b’\\xff\\ xfe’ – в компьютерах с остроконечной архитектурой. Поскольку в Unicode нет символа U+FFFE, присутствие одной из этих двух последовательностей байтов однозначно определяет порядок байтов на данной машине. Хотя это и излишне, BOM иногда включается и в файл в кодировке UTF-8 в виде после-довательности байтов b’\\xef\\xbb\\xbf’ . CamelCase (верблюжья нотация) Соглашение о написании имен идентификаторов путем конкате- нации нескольких слов с заглавными буквами в начале (например, ConnectionRefusedError ). В документе PEP-8 рекомендуется применять вер- блюжью нотацию для имен классов, но эта рекомендация не соблюдается в стандартной библиотеке Python. См. также snake_case . Cheese Shop (сырная лавка) Первоначальное название указателя пакетов Python (Python Package Index – PyPI), расположенного по адресу https://pypi.python.org/pypi . В па- мять о скетче группы Монти Пайтон на тему сырной лавки, в которой ниче-го нельзя купить. В настоящее время все еще работает альтернативный адрес https://cheeseshop.python.org . См. также PyPI . CPython Стандартный интерпретатор Python, написанный на C. Этот термин ис- пользуется только при обсуждении деталей, зависящих от реализации, или в контексте рассмотрения различных имеющихся интерпретаторов Python, на- пример PyPy .\n--- Страница 752 ---\n752 Терминология Python CRUD Акроним Create, Read, Update, Delete (создание, чтение, обновление, удале- ние) – четыре основные функции в любом приложении для сохранения записей. doctest-скрипт Модуль, содержащий функции для разбора и выполнения примеров, вклю- ченных в строки документации Python-модулей или в обычные текстовые файлы. Может также вызываться из командной строки: python -m doctest module_with_tests.py DRY Don’t Repeat Y ourself (не повторяйся) – принцип программной инженерии, который гласит: «Каждая единица знания должна иметь единственное, непро-тиворечивое, авторитетное представление в рамках системы». Впервые был сформулирован в книге Эндрю Ханта и Дэйва Томаса «Программист-прагма-тик» (Лори, Питер Пресс, 2007). dunder Краткое произношение имен специальных методов и атрибутов, в которых имеется по два начальных и конечных знака подчеркивания (т. е. __len__ про- износится «dunder len»). dunder-метод См. dunder и специальные методы . EAFP Акроним фразы «It’s easier to ask forgiveness than permission» (Проще по- просить прощения, чем испрашивать разрешение), приписываемой пионеру вычислительной техники Грейсу Хопперу. Употребляя этот акроним, питони-сты имеют в виду приемы динамического программирования, например до-ступ к атрибуту без предварительной проверки его существования с после-дующим перехватом исключения, если атрибута действительно нет. В строке документации по функции hasattr говорится, что она работает «путем вызова getattr(object, name) и перехвата исключения AttributeError ». genexp Сокращение от «generator expression» – генераторное выражение. KISS , принцип Акроним фразы «Keep It Simple, Stupid» (будь проще, глупышка). Имеется в виду поиск простейшего из возможных решений, с минимальным количе-ством подвижных деталей. Фраза принадлежит Келли Джонсону, высококва-лифицированному авиационно-космическому инженеру, который работал на военной базе «Зона 51» и проектировал некоторые из наиболее технически сложных самолетов двадцатого века. listcomp Сокращение от «list comprehension» – списковое включение.\n--- Страница 753 ---\n753 Терминология Python ORM Объектно-реляционное отображение (Object-Relational Mapper) – API, ко- торый дает доступ к таблицам и записям базы данных с помощью классов и объектов Python, обладающих методами для выполнения операций базы дан-ных. SQLAlchemy – популярная автономная ORM-система для Python; веб-каркасы Django и W eb2py включают собственные встроенные ORM. PyPI Указатель пакетов Python (Python Package Index), расположенный по адре- су https://pypi.python.org , где доступно более 60 000 пакетов. Известен также под названием «Сырная лавка» (см. Cheese shop ). PyPI произносится «пай-пи- ай», чтобы избежать путаницы с PyPy . PyPy Альтернативная реализация языка Python, в которой используется на- бор инструментальных средств для компиляции подмножества Python в ма-шинный код, так что исходный код интерпретатора, по сути дела, написан на Python. PyPy включает также JIT-компилятор для генерации машинного кода пользовательских программ на лету – как делает виртуальная машина Java. Согласно опубликованным эталонным тестам, по состоянию на ноябрь 2014 года PyPy в среднем быстрее CPython в 6,8 раз ( http://speed.pypy.org ). PyPy произносится «пай-пай» чтобы избежать путаницы с PyPI . refcount Счетчик ссылок, хранящийся в каждом объекте CPython и позволяющий решить, когда объект может быть уничтожен сборщиком мусора. REPL Read-eval-print loop (цикл чтения-вычисления-печати), интерактив- ная оболочка, например стандартная оболочка python или ее альтернативы: ipython , bpython и Python Anywhere. snake_case, змеиная нотация Соглашение о написании имен идентификаторов путем конкатенации не- скольких слов, разделенных символом подчеркивания, например: run_until_ complete . В документе PEP-8 такой стиль называется «строчные буквы с разделением слов подчерками» и рекомендуется для именования функций, методов, аргументов и переменных. Имена пакетов PEP-8 рекомендует обра-зовывать из слов без подчерков. В стандартной библиотеке Python встреча-ется много примеров идентификаторов в змеиной нотации, но немало и та-ких, имена которых записаны без подчерков (например, getattr , classmethod , isinstance , str.endswith и другие). См. CamelCase . YA GNI Акроним фразы «Y ou Ain’t Gonna Need It» (тебе это не понадобится) – при- зыв отказаться от реализации не нужной в данный момент функционально-сти, исходя из предположения, что она может понадобиться в будущем.\n--- Страница 754 ---\nПРЕДМЕТНЫЙ УКАЗАТЕЛЬ Символы - оператор 404^ ^ оператор 287, 319 ~ ~ оператор 404 ! !=, оператор 416 !r, поле преобразования 35 # #, оператор 40 % %, оператор 36 %r, спецификатор 35 ( (), скобки 47 (), вызов функции 403(), оператор вызова 176(обратная косая черта) 47 * *, оператор 34, 36, 62, 180, 412 ** (двойная звездочка) 180*=, оператор 64, 421*args 54*extra 88 . . (доступ к атрибутам) 403.add_done_callback(), метод 542 .append(), метод 81.done(), метод 542.__eq__ 417.frombytes(), метод 280.pop(), метод 81.result(), метод 542 … … (многоточие) 61, 307 + + оператор 404 +, оператор 34, 36, 62, 404, 407 +=, оператор 64, 421 +ELLIPSIS, директива 31+x 406 [ [], квадратные скобки 31, 47, 61, 403 [:], оператор 254 { {}, фигурные скобки 47 < <, оператор 416 <=, оператор 416 = == оператор 252, 272, 319, 416 > > оператор 416 >= оператор 416\n--- Страница 755 ---\n755 Предметный указатель @ @оператор 416 @abstractclassmethod 360@abstractproperty 360@abstractstaticmethod 360@property, декоратор 633@asyncio.coroutine, декоратор 571, 573@classmethod, декоратор 622@contextmanager, декоратор 486 _ _ (подчеркивание) 54, 292 __ (двойное подчеркивание) 28, 29__add__ 65, 339, 408, 424__bool__ 37__builtins__ 91__bytes__ 277__call__ 176__class__ 645__del__ 263__delattr__ 644, 647__delete__ 653__dict__ 91, 178, 645__doc__ 171, 178__enter__ 482__exit__ 482__float__ 288__format__ 277, 282, 324, 334__getattr__ 315, 647__getattribute__ 647__getitem__ 29, 99, 313, 339, 341, 653__hash__ 117, 287, 319__iadd__ 65, 424__imatmul__ 416__init__ 447, 622, 695__int__ 288__invert__ 404__iter__ 435, 438__len__ 29, 39, 313__matmul__ 416__missing__ 101__mro__ 364__mul__ 413__ne__ 417__neg__ 404__new__ 622, 651__next__ 438, 442__pos__ 404__prepare__ 701 __radd__ 409__repr__ 35__rmatmul__ 416__rmul__ 36, 413__set__ 653, 658__setattr__ 647__setitem__ 344__slots__ 293, 645, 716__str__ 36__subclasshook__ 369 4 404, код ошибки (Не найдено) 556 А абсолютное значение 34 агрегатные классы 392Адаптер, паттерн 388аккумулирующие функции 466акцессоры 614, 650, 739алгоритмы C3 387RC4 726двоичный поиск 70криптографические 547, 726работы хэш-таблиц 118сортировки Timsort 90упорядочивания Unicode (UCA) 156 анонимные функции 175, 197, 222аргументы self 658, 680определение термина 739получение произвольных дополнительных 54 фиксация с помощью functools.partial 191чисто именованные 180 арифметическая прогрессия, генератор 451арифметические операторы 36, 37, 188, 409атрибуты динамические 315, 614закрытые и защищенные 291, 302, 339имена 620определение термина 739открытые 301, 339переопределение 296перечисление 179пользовательских функций 179\n--- Страница 756 ---\n756 Предметный указатель проверка значений с помощью дескрипторов 653 проверка значений с помощью свойств 633специальные 645удаление 643управляемые 655, 749хранения 655, 659, 739экземпляра 677 Б байтовые строки 739 байтоподобные объекты 740блокирующие функции ввода-вывода 545, 582бородавки, определение термина 740будущие объекты в asyncio 575в библиотеке concurrent.futures 542и конструкция yield from 576и обратные вызовы 592определение термина 536практический пример 543создание 542 быстрого прекращения принцип 97, 740 В ВерблюжьяНотация (CamelCase) 652, 709, 751 виртуальные подклассы 363, 369, 413, 740вложенные списки 63встроенные методы 176встроенные функции 68, 91, 176, 645, 740вызов по соиспользованию 258, 275вызов по ссылке 275вызываемые объекты 176, 740выполнения этап 217, 343, 688 Г генераторные выражения как альтернативы map и filter 173, 454 ленивое вычисление 429, 447 определение термина 741 преимущества 50 рекомендации по использованию 450 генераторные функции в стандартной библиотеке 454 определение термина 176, 741 реализация итерирования 443 синтаксис 473генераторы в утилите преобразования базы данных 469делегирующие 510и итераторы 432определение термина 741сопрограммы как 496 глобальные функции 207глубокая копия 257, 741гусиная типизация определение и использование ABC 355определение термина 347 метод __subclasshook__ 369, 436 пример 350регистрация виртуальных подклассов 363явная проверка абстрактного типа 413 Д двоичные последовательности fromhex, метод класса 130встроенные типы 128определение термина 741поддержка методов str 129построение 130разделение памяти 130способы отображения 129 двумерные векторы, сложение 33декартово произведение, построение 49Декоратор, паттерн 229, 245декораторы и замыкания 214 в стандартной библиотеке Python 230динамическая область видимости 243замыкания и анонимные функции 222инициализирующие декораторы 573композиция декораторов 236композиция декораторов функций 360объявление nonlocal 225определение декоратора 215, 741определение замыкания 225параметризованные декораторы 236поведение декоратора 229правила видимости переменных 219пример замыкания 223реализация декоратора 227регистрационные декораторы 218, 237сравнение classmethod и staticmethod 281 декораторы класса для настройки дескрипторов 686и декораторы функций 687\n--- Страница 757 ---\n757 Предметный указатель и метаклассы 682 недостатки 688 декорирование имен 661, 741делегирующие генераторы 510дескрипторы настройка 686, 699непереопределяющий 668, 744определение термина 741переопределяющий 668, 746проверяющий 676 дескрипторы атрибутов 653 методы как 673общие сведения 653перезаписывание 673переопределяющие и непереопределяющие 668 перехват удаления 677проверка значений атрибутов 653советы по использованию 676сравнение с фабриками свойств 663строки документации 677терминология 654 деструктурирующее присваивание 745диакритические знаки 151динамическая область видимости 243динамическая типизация и протоколы 309определение термина 742поддержка в Python 276пример 96происхождение термина 345 динамические атрибуты выборка связанных записей 627гибкое создание объектов 622изменение структуры данных с помощью модуля shelve 624 исследование JSON-подобных данных 617применение для обработки данных 615проблема недопустимого имени атрибута 620 динамически типизированные языки 339, 375 Ж живучесть 742 З загрузка файлов из веб асинхронный TCP-сервер 598веб-сервер на основе aiohttp 602 индикация хода выполнения 552, 557несколько запросов 595обработка ошибок 551, 556параллельная и последовательная 536с применением пакета aiohttp 578 замыкания. См. декораторы и замыканиязапашок кода 348, 742запоминание 230 И идентификаторы объектов 252 идиома, определение термина 742идиомы кодирования 335изменяемость 273именованные кортежи 56импорта этап 216, 688, 750инверсные операторы 39инициализатор, определение термина 742инициализировать сопрограмму определение термина 742 интерфейсы ABC (абстрактный базовый класс) 350Sequence 341в других языках 377определение термина 340подход в Python 339протоколы как неформальные интерфейсы 333 явные 391 инфиксные операторы знак @ 413имена методов 415обработка исключений 412операнды 409особый механизм диспетчеризации 409перегрузка операторов 403 Итератор, паттерн iter(), встроенная функция 435, 468генераторные выпажения 447генераторные функции 443, 454генерация арифметической прогрессии 451достоинства 432итерируемые объекты и итераторы 436классическая реализация 440ленивая реализация 447перебор слов 433практический пример 469\n--- Страница 758 ---\n758 Предметный указатель проверка возможности итерирования 436 типичные ошибки 442функции редуцирования 466 итераторы и генераторы 432и итерируемые объекты 436и субгенераторы 510определение термина 440, 742поддерживаемые конструкции 433 итерирование 432 неявная природа 32специальная обработка интерпретатором 343 с помощью генераторных функций 443 итерируемые объекты 436, 742 К канонические эквиваленты 147 классы агрегатные 392дескрипторные 653, 663, 741как вызываемые объекты 176как объекты 703, 708метаклассы 693, 744нотация MGN 656определение термина 743примеси 391, 395, 743управляемые 750 ключи непредсказуемость порядка в хэш- таблицах 121 обработка отсутствия 97ограничения в хэш-таблицах 120отображения с гибким поиском 99 кодек 132, 743кодирование и декодирование 127 BOM (маркер порядка байтов) 139алгоритм упорядочивания Unicode 156база данных Unicode 157базовые кодеки 132двухрежимный API 159диакритические знаки 151нормализация Unicode 146обработка ошибок 134определение кодировки последовательности байтов 138 представление str в памяти 167представление строк и символов 127пример 127 сворачивание регистра 149сортировка Unicode-текстов 154сравнение нормализованного текста 150структуры и представления областей памяти 131 текстовые файлы 140типы bytes или bytearray 128установка кодировки по умолчанию 143 кодовая позиция 127, 743коллекции как итерируемые объекты 433определение термина 743 колода карт, пример 29Команда, паттерн проектирования 208композиция 393композиция объектов 393конкретные подклассы 352, 360, 392конкурентность GIL (глобальная блокировка интерпретатора) 545 асинхронные операции 581, 610более интеллектуальные клиенты 606в других языках 566загрузка с применением concurrent. futures 540 запуск задач с помощью concurrent. futures 546 индикация хода выполнения 552и параллелизм 567использование futures.as_completed 558многопоточная и многопроцессная обработка 561 неблокирующий дизайн 575несколько запросов загрузки 595обработка ошибок 551, 556примеры 536сравнение параллельного и последовательного скрипта 538 сравнение потока и сопрограммы 569тестирование параллельных клиентов 552функция Executor.map 548 конструктор, определение термина 743контейнерные последовательности 45, 89контейнер, определение термина 744контекстные менеджеры временные контексты, создаваемые предложением with 479\n--- Страница 759 ---\n759 Предметный указатель и блоки with 482 использование 486определение термина 744утилиты contextlib 486 кортежи возврат ссылки на 269именованные 56относительная неизменяемость 253, 269создание с помощью генераторных выражений 50 коэффициент Отиаи 306крокозябры, определение термина 136кэширование и дескрипторы атрибутов 676и слабые ссылки 265с помощью класса WeakValueDictionary 266 Л лексическая область видимости 245 ленивое вычисление 429, 447ленивые объекты 744локаль, установка 155 Лундха рецепт рефакторинга лямбда- выражений 175 М магические методы 29, 41 массивы в библиотеке NumPy 79достоинства 74и memoryview 78построение с помощью генераторных выражений 50 создание, сохранение и загрузка 74сравнение со списками 76 метаклассы для настройки дескрипторов 699определение термина 744основы 693 метапрограммирование 216, 682, 744метапрограммирование классов 682 __prepare__ 701классы как объекты 703метаклассы и декораторы классов 682настройка дескрипторов 686основы метаклассов 693фабрика классов 683функции exec и exal 686этап импорта и этап выполнения 688 методы акцессоры 739встроенные 176как вызываемые объекты 176как дескрипторы 673несвязанные 385, 744определение термина 614подмешанные 746связанные 748специальные. См. специальные методы миниязык спецификации формата 283, 325многомерные срезы 61множественное наследование в каркасе Django 398и порядок разрешения методов 384истоки 401на практике 388недостатки 380рекомендации 391 моделирование дискретных событий (DES) 521 и непрерывное моделирование 521подход на основе потоков 521процессы 521скрипт taxi_sim.py 522, 722 модель данных булево значение пользовательского типа 37и объектная модель 41общие сведения 28поведение __len__ 39пример 29протокол метаобъектов 42протоколы и последовательности 341сводка специальных методов 37специальные (магические) методы 29, 41строковое представление 35эмуляция числовых типов 33 мутаторы 744 Н накопительнок среднее, вычисление 223, 499 наследование в разных языках 401и виртуальные подклассы 363и композиция 306интерфейса и реализации 391классу UserDict 105\n--- Страница 760 ---\n760 Предметный указатель множественное. См. множественное наследование обобщенным классам отображений 91подводные камни 380 неизменяемость 273непрерывное моделирование 521 О обобщенные функции 233, 745 обратные вызовы 592объектная модель 41объектно-реляционное отображение (ORM) 753 объекты байтоподобные 740в духе Python 276вызываемые 176, 740глубокое копирование 256, 741декораторы 741изменяемые 259, 273итераторы 742итерируемые 436, 742классы как 703контекстные менеджеры 744ленивые 744недоступные 263обратной трассировки стека 265одиночки 252, 745поверхностное копирование 254, 746полноправные 170, 708сериализация 748создание с помощью __new__ 622ссылки 265, 745уничтожение 274файлоподобные 750хэшируемые 92, 286, 750энергичные 750 остроконечный порядок байтов 139отображения вариации на тему dict 103достоинства литерального синтаксиса 125изменяемые 266неизменяемые 106обзор методов 94с гибким поиском по ключу 99создание новых типов 105типы отображений 92П параллельное присваивание 53, 745 параллельные задачи, запуск 546параметры изменяемые 261определение термина 745передача 274получение информации о 182 параметры функций 258партизанское латание 343, 376, 673, 745паттерны проектирования 198 Адаптер 388выбор наилучшей стратегии 206Декоратор 229классическая Стратегия 199Команда 208поиск стратегий в модуле 207функционально-ориентированная стратегия 203 перегрузка операторов 403 достоинства 404, 428инфиксные операторы 414недостатки 428операторы составного присваивания 421операторы сравнения 416сложение векторов 407умножение на скаляр 412унарные операторы 404 перегрузка функций и методов 234переменные как этикетки 249свободные 224ссылочные 249фиктивные 54 питонический, определение термина 746плоские последовательности 45, 89, 746подклассы виртуальные 363, 369, 413, 740конкретные 352, 360подводные камни 380создание 360тестирование 365 полноправные объекты 170, 708полноправные функции аннотации функций 186анонимные функции 175, 197вызываемые объекты 176гибкая обработка параметров 180\n--- Страница 761 ---\n761 Предметный указатель интроспекция функций 178 как полноправные объекты 170обращение с функцией как с объектом 171определение термина 746пакеты для функционального программирования 188 паттерны проектирования на основе 198получение информации о параметрах 182пользовательские вызываемые типы 177функции высшего порядка 172 поразрядные операторы 39, 404порядок разрешения методов 364, 388последовательности 44 UML-диаграмма классов 45альтернативы списку 74библиотеки NumPy и SciPy 79встроенные 45двоичные 128, 741двусторонние и другие очереди 81изменяемые 61, 344итерируемость 435конкатенация нескольких экземпляров 62контейнерные 89кортежи 52массивы 74массивы и представления областей памяти 78 определение термина 747плоские 746получение среза 59, 746построение 46сортировка 68составное присваивание 64упорядоченные 70 потокобезопасные интерпретаторы 545похожий на ложь 747представления областей памяти 78, 131, 341представления с ограниченной длиной 307принцип DRY (не повторяйся) 752принцип единообразного доступа 614, 649, 747присваивание деструктурирующее 745параллельное 53, 740перезаписывание дескриптора 673переменным 249составное 39, 64, 421срезу 61 протокол метаобъектов 42протоколы динамическая природа 345достоинства 343и динамическая типизация 309и наследование 340как неформальные интерфейсы 333определение термина 340последовательности 310, 341, 433реализация 340, 343 процесс, определение термина 521 Р распаковка вложенного кортежа 55 распаковка итерируемого объекта 53, 748распаковка кортежа вложенных 55выборка лишних элементов 54и распаковка итерируемых объектов 53определение термина 748примеры 53 регулярные выражения 159ромбовидного наследования проблема 384 С сборка мусора 263, 274 свободные переменные 224, 245свойства выборка связанных записей 627достоинства 707и атрибуты экземпляров 637общие сведения 636проверка значений атрибутов 633строки документации 639фабрики свойств 640, 663 сворачивание регистра 149сворачивающие функции 466связанные методы 748сериализация 748сильные ссылки 748символы кодирование и декодирование 127кодовая позиция 127определение 127совместимости 148стандарт Unicode 127 синглтон 252, 745синонимия 250, 748слабые ссылки 265, 748\n--- Страница 762 ---\n762 Предметный указатель словари и множества 91 вариации на тему dict 103неизменяемые отображения 106обзор методов отображений 94отображения с гибким поиском по ключу 99 построение словарей 93практические следствия 123реализация с помощью хэш-таблиц 115словарное включение (dictcomp) 94создание новых типов отображений 105теория множеств 108типы отображений 92 словарное включение (dictcomp) 94сложение на месте 65, 424совместимости символы 148сопрограммы возврат значения 506возможные состояния 496в пакете asyncio 571вычисление накопительного среднего 499генераторы как 471, 496декораторы для инициализации 501завершение 502задержка 573и ключевое слово yield 498использование yield from 508моделирование дискретных событий 520, 722 обработка исключений 503определение термина 749получение объектов Task 576преимущества 594семантика yield from 514сравнение с будущими объектами 576сравнение с генераторами 494сравнение с обратными вызовами 592сравнение с потоками 569эколюция 495 сортировка 68, 90составные объекты 88специальные атрибуты 645специальные методы арифметические операторы 36, 38булево значение пользовательского типа 37 встроенные типы 33для работы с атрибутами 646именование 28 назначение 28неявная природа 33определение термина 749преимущества 31пример реализации 29, 35сводка 37статическая проверка типов 374строковое представление 35эмуляция числовых типов 33 списки альтернативы 74аргументов 175кортежи как неизменяемые списки 57последних виденных элементов 81построение списка списков 63смешанные типы 89сортировка 68сравнение с двусторонней очередью 82сравнение с массивами 74 списковое включение (listcomp) вложенные списки 63генерация декартова произведения 49и генераторные выражения 50и удобочитаемость 46как альтернатива функциям map и filter 173 область видимости переменных 47определение термина 749построение последовательней 46 сравнения операторы 38, 404, 416срезка возможности 59демонстрация 311многомерная 61объекты среза 59определение термина 746присваивание срезу 61 ссылки сильные 748слабые 265, 748 стандартная библиотека Python ABC 352array.array 280collections.deque 81генераторные функции 454декораторы 230пакет TkInter 389преимущества специальных методов 31\n--- Страница 763 ---\n763 Предметный указатель реализация очередей 84 Стратегия, паттерн 199, 218строгая и слабая типизация 375строка документации (docstring) 749строки концепция 127представление 35, 167, 277 структуры данных последовательности 44словари и множества 91текст и байты 126 субгенераторы 510счетчик ссылок 264, 274, 748 Т текстовые файлы кодирование и декодирование 140 теория множеств литеральные множества 109математические операции 112множественное включение 111операторы сравнения множеств 113хэшируемость элементов 108 тип, определение термина 749тупоконечный порядок байтов 139 У указание типа 374 умножение вектора на скаляр 34, 412свойство коммутативности 36 управляемые атрибуты 655, 749управляемые классы 654, 750управляемые экземпляры 655, 750 Ф файлоподобный объект 750 функции аккумулирующие 466 анонимные 175, 197, 222 арифметические операторы как 188 блокирующий ввод-вывод 545, 582 встроенные 68, 91, 176, 645, 740 высшего порядка 172, 191, 750 генераторные 176, 473, 741 декораторы и замыкания 214, 360 и паттерны проектирования 198как полноправные объекты 708 обобщенные 745определение термина 750полноправные 170пользовательские 176сворачивающие 466 функциональное программирование на Python 196пакеты для 188 Х хэшируемые объекты 286, 750 хэш-таблицы алгоритм работы 118битовые представления 118, 715и равенство 117коллизии 119непредсказуемость порядка ключей 121ограничения на объем памяти 120ограничения на тип ключа 120определение хэшируемости 92практические следствия 123реализация словаря 117эффективность 115, 121 Ч числовая башня 354 числовые типы сохранение 75эмуляция 33 чисто именованные аргументы 180 Э энергичный объект 750 A ABC (абстрактный базовый класс) в стандартной библиотеке 352гусиная типизация 371как классы-примеси 392объявление 359определение и использование 355определение термина 739пакет numbers 354правильное использование 338, 348, 371преимущества 347синтаксические детали 359\n--- Страница 764 ---\n764 Предметный указатель создание виртуального подкласса 363 создание подкласса 350, 360тестирование подкласса 365явное определение интерфейсов 391 ABC (язык программирования) 44, 88, 751abstractmethod 357abs, функция 34aiohttp, пакет 578, 602and, оператор 404arcfour.py, модуль 726array.array, класс 280asciize, функция 153asyncio, пакет 567 asyncio.as_completed 585asyncio.Future, класс 575asyncio.Task, объекты 576asyncio.wait(…) 580TCP-сервер 598time.sleep(…) 573асинхронные операции 581загрузка с применением пакета aiohttp 578и конструкция yield from 575, 581предоставляемые API 84предотвращение блокировки цикла обработки событий 591 преимущества 612разработка 568разработка асинхронных серверов 597сопрограммы в 571сравнение с модулем Threading 569сравнение сопрограмм и будущих объектов 576 улучшение скрипта загрузки флагов 585 B BDFL (пожизненный великодушный диктатор) 751 bisect, модуль вставка с помощью bisect.insort 73основные функции 70поиск с помощью bisect 70 Bobo, микрокаркас веб-приложений 182, 195BOM (маркер порядка байтов) 139, 751bool(x) 37bytearray, тип 128bytes, тип 128 C Callable, абстрактный базовый класс 354callable(), функция 176 ChainMap 104Chardet, универсальный детектор кодировки символов 139 charfinder.py, модуль 598Cheese Shop (сырная лавка) 751classmethod, декоратор 281collections.abc, модуль collections.ChainMap 104collections.Counter 104collections.defaultdict 94, 95, 99collections.deque 81collections.MutableSequence 111, 350collections.namedtuple, функция 56collections.OrderedDict 94, 95, 104collections.UserDict 104Mapping и MutableMapping 91, 354включенные ABC 353множественное наследование 388 concurrent.futures, библиотека 536 futures.as_completed 553, 558futures.ProcessPoolExecutor 561запуск процессов 546операции за кулисами 542преимущества 565применение для загрузки файлов 540 Container, абстрактный базовый класс 353copy, функция 256Counter 104cp437, кодировка 133cp1252, кодировка 133CPython 264, 545, 751CRUD (создание, чтение, обновление, удаление) 752 D dbm, модуль 624 decimal.Decimal, класс 406deepcopy, функция 256defaultdict 94, 95, 99default_factory 100del, предложение модификация на месте 61поведение 263удаление атрибутов объекта 643 dict 117dict.get 97dict.setdefault 98dir, функция 178\n--- Страница 765 ---\n765 Предметный указатель dis, модуль 221 Django, каркас 178, 395doctest, пакет для тестирования +ELLIPSIS, директива 31определение термина 752 E EAFP, принцип 481, 752 eval, функция 686Executor.map, функция 548Executor.submit, функция 551exec, функция 686 F filter, функция 48, 173 flags2_common.py, модуль 551, 729fold_equal, функция 150for/else, комбинация 480format(), функция 282for циклы 323fromhex, метод класса 130frozenset 108fsdecode(), функция 161fsencode(), функция 161functools, модуль functools.lru_cache 230functools.partial 191functools.reduce 319, 466functools.singledispatch 232functools.wraps, декоратор 229 G gb2312, кодировка 133 getattr(), функция 646GIL (глобальная блокировка интерпретатора) достоинства 566 и блокирующий ввод-вывод 545 ограничения 545 Go, язык 377 H hasattr(), функция 646 Hashable, абстрактный базовый класс 354heapq, пакет 85HTTP, протокол 578I insort, функция 70 isinstance, функция 348isis2json.py, скрипт 717iso8859_1, кодировка 132is, оператор 252, 404Iterable, абстрактный базовый класс 353itertools, модуль 453iter, функция и специальный метод __iter__ 33перебор слов 433порядок действий 435с двумя аргументами 468 K key, аргумент 68, 90 KISS, принцип 752 L lambda, ключевое слово 175 latin1, кодировка 132LBYL, принцип 481len, функция 33, 39Lisp, язык 432list.sort, метод 68locale.strxfrm, функция 155lru_cache, декоратор 230 M MappingProxyType, класс-обертка 107 MappingView, абстрактный базовый класс 354 Mapping, абстрактный базовый класс 354map, функция 48, 173, 322memtest.py, скрипт 716MGN (нотация хреновин и штуковин) 656MRO (порядок разрешения методов) 364, 388multiprocessing, пакет 84MutableMapping, абстрактный базовый класс 91 MutableSet 111 N nfc_equal, функция 150 NFC (форма нормализации C) 147NFKC/NFKD, нормализация 148\n--- Страница 766 ---\n766 Предметный указатель nonlocal, объявление 214, 225 NotImplemented 410NotImplementedError 410not, оператор 404numpy достоинства 79математические операции над векторами 306 работа с массивами 79установка 81 O operator, модуль 188 OrderedDict 94, 95or, оператор 404os.walk, генераторная функция 454os, модуль 160 P pickle, модуль 624 property, функция 230PyPI (Python Package Index) 753PyPy, язык 753py.test, библиотека 734Python Imaging Library (PIL) 131PyUCA, библиотека 156 Q queue, пакет 84 R RC4, алгоритм 726 reduce, функция 173, 319, 321, 466re.findall, функция 447re.finditer, функция 447register, метод 363, 368reprlib, модуль 307repr, функция 277requests, библиотека 539reverse, аргумент 68run_in_executor, метод 591 S sanitize.py, модуль 151 schedule1.py, модуль 624, 734SciPy достоинства 79математические операции над векторами 306 установка 81 self, аргумент 658, 680Sequence, абстрактный базовый класс 354setattr(), функция 646setlocale, функция 155Set, абстрактный базовый класс 354shelve, модуль 624SimPy 521singledispatch, декоратор 232Sized, абстрактный базовый класс 353snake_case 753staticmethod, декоратор 281str.casefold, метод 149str.format, метод 35, 282StrKeyDict 105struct, модуль 131str, функция 33, 277super(), функция 318surrogateescape, обработчик ошибок кодека 161 SyntaxError, исключение 136 T Task, получение в asyncio 576 threading, модуль 561, 569time.sleep() 572Timsort алгоритм сортировки 90 TQDM, пакет 552, 557Trollius, проект 568try/else, комбинация 480type, метакласс 694t[:], оператор 269 U Unicode SyntaxError, исключение 136алгоритм упорядочивания Unicode 156база данных 157диакритические знаки 151канонические эквиваленты 147комбинирование символов 146нормализация 146ошибки кодирования и декодирования 134сворачивание регистра 149символы и байты 127символы совместимости 148\n--- Страница 767 ---\n767 Предметный указатель сортировка текста 154 сравнение нормализованного текста 150сэндвич Unicode 140 UserDict 105utf-8, кодировка 133utf-16le, кодировка 133 V vars(), функция 646 W WeakKeyDictionary, класс 268 weakref, модуль 268WeakValueDictionary, класс 267while/else, комбинация 480with, предложение контекстные менеджеры 482поведение 479полезность 493Y yield from, конструкция в пакете asyncio 575, 580в проекте Trollius 568использование 508как замена цикла for 465основное применение 509семантика 514 yield, ключевое слово в генераторных функциях 444и проект Trollius 568и сопрограммы 498назначение 432, 494 Z zip, функция 323\n--- Страница 768 ---\nЛучано Рамальо Python – к вершинам мастерства Главный редактор Мовчан Д. А. dmkpress@gmail.com Перевод с английского Слинкин А. А. Корректор Синяева Г. И. Верстка Паранская Н. В. Дизайн обложки Мовчан А. Г. Формат 70 /g1171001/16. Гарнитура «Петербург». Печать офсетная. У сл. печ. л. 62,40. Тираж 200 экз. Веб-сайт издательства: www .дмк.рфКниги издательства «ДМК Пресс» можно заказать в торгово-издательском хол- динге «Планета Альянс» наложенным платежом, выслав открытку или письмо по почтовому адресу: 115487, г. Москва, 2-й Нагатинский пр-д, д. 6А . При оформлении заказа следует указать адрес (полностью), по которому долж- ны быть высланы книги; фамилию, имя и отчество получателя. Желательно также указать свой телефон и электронный адрес. Эти книги вы можете заказать и в интернет-магазине: www .alians-kniga.ru . Оптовые закупки: тел. (499) 782-38-89 Электронный адрес: books@alians-kniga.ru .\n--- Страница 769 ---\nИнтернет-магазин: www .dmkpress.comКнига – почтой: orders@alians-kniga.ruОптовая продажа: “Альянс-книга”тел.(499)782-38-89 books@alians-kniga.ru www.дмк.рфВ книге рассматриваются следующие темы: • модель данных в Python: почему специальные методы лежат в основе едино- образного поведения объектов; • структуры данных: как в полной мере задействовать встроенные типы, о дуализме текста и байтов в век Unicode; • функции как объекты: взгляд на функции Python как на полноправные объекты и как это отражается на популярных паттернах проектирования; • объектно-ориентированные идиомы: создание классов на основе знаний о ссылках, изменяемости, интерфейсов, перегрузке операторов и множественном наследовании; • управление потоком выполнения: контекстные менеджеры, генераторы, со- программы и параллелизм с применением пакетов concurrent.futures и asyncio; • метапрограммирование: как работают свойства, дескрипторы атрибутов, декораторы классов и метаклассы. 9 785970 603840ISBN 978-5-97060-384-0«Эта книга не только п роложит многим п рограммистам с ред- него уровня на P ython дорог у к вершинам масте рства, но и меня самого кое-чему научила!» Алекс Мартелли, член фонда P ython So ftware Foundatio n «Сокровищница полезных прие - мов программирования б удет по - лезна программистам на Python, желающим раздвинуть границы своих знаний.» Дэниэл и Од ри Рой Г ринфилд, авторы книги «Two Scoops of Django»Язык Python настолько прост, что научиться про-дуктивно писать на нем программы можно быстро, но зачастую вы при этом используете не все име-ющиеся в нем возможности. Данная книга пока-жет, как создавать эффективный идиоматичный код на Python, задействуя его лучшие — и иногда несправедливо игнорируемые — черты. Автор, Лу-чано Рамальо, рассказывает о базовых средствах и библиотеках Python и демонстрирует, как сделать код одновременно короче, быстрее и понятнее.Многие опытные программисты стараются подо-гнать Python под приемы, знакомые им по работе с другими языками. Эта книга покажет, как достичь истинного профессионализма в программирова-нии на Python 3. Лучано Рамальо программирует на Python с 1998, член фонда Python Software Foundation, совладелец компании Python.pro.br, специализирующейся на преподавании Python в Брази-лии, и сооснователь клуба Garoa Hacker Clube, первого места для общения профессиональ-ных программистов в Бразилии. Он возглавлял различные команды разработчиков и читал курсы по Python сотрудникам бразильских СМИ, банков и государственных организаций.",
      "debug": {
        "start_page": 682,
        "end_page": 769
      }
    }
  ]
}
{
  "title": "Анализ обучения с TensorBoard PyTorch Profiler на основе Notebooks",
  "chapters": [
    {
      "name": "Анализ обучения с TensorBoard PyTorch Profiler на основе Notebooks",
      "content": "Практические руководства Evolution    \n\n # Анализ обучения с TensorBoard PyTorch Profiler на основе Notebooks   Эта статья полезна?          \nС помощью этого руководства вы научитесь использовать TensorBoard с PyTorch Profiler для выявления узких мест производительности моделей машинного обучения.\nВы создадите нейронную сеть для классификации изображений и обучите ее с применением инструментов профилирования.\nНаучитесь анализировать результаты для оптимизации производительности.\nВ результате вы получите практические навыки работы с инструментами визуализации и анализа производительности моделей PyTorch.\nВы будете использовать следующие сервисы и библиотеки:\n- Notebooks — сервис для запуска сред ML и работы DS-специалистов в ноутбуках на платформе Evolution.\n- PyTorch — оптимизированная библиотека для глубокого обучения с использованием GPU и CPU.\n- Matplotlib — комплексная библиотека для создания статических, анимированных и интерактивных визуализаций.\n- TensorBoard — инструмент для визуализации и отладки процесса обучения нейронных сетей.\nШаги:\n1. Подготовьте среду.\n2. Обучите нейронную сеть.\n3. Настройте PyTorch Profiler.\n4. Ознакомьтесь с методами визуализации PyTorch Profiler.\n5. Проанализируйте результаты.\n\n## Перед началом работы\n1. Зарегистрируйтесь в личном кабинете Cloud.ru.\nЕсли вы уже зарегистрированы, войдите под своей учетной записью.\n2. На верхней панели слева нажмите  и убедитесь, что сервис Notebooks в разделе AI Factory подключен.\nЕсли сервис Notebooks не подключен, оставьте заявку на подключение.\n\n## 1. Подготовьте среду\n1. Сгенерируйте ключевую пару.\n2. Загрузите публичный ключ в облачный каталог.\n3. Создайте ноутбук со следующими параметрами:\n\n- Конфигурация — GPU nv100.xlarge.16.\n- Образ — Cloud.ru Jupyter (Conda).\n4. Дождитесь пока ноутбук перейдет в статус «Запущен».\n5. Нажмите JupyterLab в строке созданного ноутбука.\n6. В ноутбуке выберите TensorBoard в разделе Other.\n7. Вернитесь на вкладку ноутбука для дальнейшей работы.\n\n## 2. Обучите нейронную сеть с использованием PyTorch\nНа этом шаге вы обучите нейронную сеть для классификации изображений на датасете CIFAR-10 — 10 классов.\nМодель научится распознавать объекты на картинках 32x32 пикселя.\nДля учебных целей мы создаем четыре типа проблем производительности:\n1. Частые синхронизации CPU и GPU нарушают поток вычислений и замедляют обучение.\n2. Лишние операции с памятью расходуют ресурсы на ненужные копирования и доступы.\n3. Неэффективное использование памяти увеличивает нагрузку на видеопамять и ограничивает масштаб моделей.\n4. Избыточное количество прямых и обратных проходов удлиняет обучение и выполняет лишнюю работу.\nЭти проблемы позволяют PyTorch Profiler сгенерировать реальные рекомендации по оптимизации, которые можно увидеть, изучить и применить.\n1. Установите необходимые библиотеки, выполняя команды в отдельных ячейках ноутбука:\n```\npip install torchpip install torchvisionpip install tensorboardpip install matplotlib\n```\n2. Импортируйте библиотеки PyTorch для создания нейронных сетей:\n```\n# Import main PyTorch libraries for creating neural networksimport torch        # Main framework for deep learningimport torch.nn as nn       # Module for creating neural network layersimport torch.optim as optim     # Optimizers for model trainingimport torch.nn.functional as F         #Activation functions and other useful functionsimport torch.backends.cudnn as cudnn        # CUDA optimizations for accelerating computations\n# Imports for TensorBoard --- visualization of metrics and graphsfrom torch.utils.tensorboard import SummaryWriter\n# Imports for profiling --- performance analysisfrom torch.profiler import profile, record_function, ProfilerActivity\n```\n3. Укажите путь до папки с датасетом:\n\n1. Нажмите правой кнопкой мыши по папке, которую вы создали для датасета.\n2. Нажмите Copy Path.\n3. Вставьте путь в переменную data_dir в код ниже.\n4. Настройте конфигурационные параметры и директории:\n```\n# Configuration parametersresume = False      # Flag for resuming training from checkpoint# Directory with CIFAR10 data and path to dataset folderdata_dir = </home/jovyan/runs>      # Directory for saving checkpointscheckpoint_dir = f\"{os.path.expanduser('~')}/checkpoint/\"      # All logs will be saved to this folder and accessible via TensorBoard\n# Set up directory for TensorBoard logslog_dir = f\"{os.path.expanduser('~')}/runs/cifar10_experiment\"if not os.path.isdir(log_dir):   os.makedirs(log_dir)# Create directory if it doesn't existif not os.path.isdir(checkpoint_dir):   os.mkdir(checkpoint_dir)checkpoint_file = f\"{checkpoint_dir}/ckpt.pth\"          # Path to checkpoint file\n```\n\nГде </home/jovyan/runs> путь к папке с датасетом.\n5. Настройте устройство:\n```\n# Device setupdevice = 'cuda' if torch.cuda.is_available() else 'cpu'      # Determine the device for computations (GPU/CPU)\n# Initialization of variables to track the best accuracybest_acc = 0        # Best accuracy achievedstart_epoch = 0       # Starting epoch, can be changed when resumingmax_epoch = 20       # Maximum number of epochs for training\n# Initialization of Tensorboard Writer# Create SummaryWriter for writing logs to TensorBoard# This object will be used for logging all metricswriter = SummaryWriter(log_dir=log_dir)\n```\n6. Подготовьте данные:\n```\nprint('==> Preparing data..')# Transformations for training data (with augmentation)transform_train = transforms.Compose([    transforms.RandomCrop(32, padding=4),  # Randomly crop the image with padding    transforms.RandomHorizontalFlip(),     # Random horizontal flip    transforms.ToTensor(),                 # Convert image to tensor    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),  # Normalize RGB channels])\n# Transformations for test data (without augmentation)transform_test = transforms.Compose([    transforms.ToTensor(),  # Convert image to tensor    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),  # Normalize RGB channels])\n# Create datasets and data loaderstrainset = torchvision.datasets.CIFAR10(    root=data_dir, train=True, download=True, transform=transform_train)trainloader = torch.utils.data.DataLoader(    trainset, batch_size=128, shuffle=True, num_workers=2)  # Data loader for training\ntestset = torchvision.datasets.CIFAR10(    root=data_dir, train=False, download=True, transform=transform_test)testloader = torch.utils.data.DataLoader(    testset, batch_size=100, shuffle=False, num_workers=2)  # Data loader for testing\n# CIFAR10 classesclasses = ('plane', 'car', 'bird', 'cat', 'deer',           'dog', 'frog', 'horse', 'ship', 'truck')print('==> Loading model..')\n```\n7. Определите архитектуру модели:\n```\n# Basic ResNet blockclass BasicBlock(nn.Module):    expansion = 1  # Expansion factor for channel dimension\n    def __init__(self, in_planes, planes, stride=1):        super(BasicBlock, self).__init__()        # First convolutional layer        self.conv1 = nn.Conv2d(            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)        self.bn1 = nn.BatchNorm2d(planes)  # Batch normalization\n        # Second convolutional layer        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,                               stride=1, padding=1, bias=False)        self.bn2 = nn.BatchNorm2d(planes)\n        # Shortcut connection for residual connections        self.shortcut = nn.Sequential()        if stride != 1 or in_planes != self.expansion*planes:            self.shortcut = nn.Sequential(                nn.Conv2d(in_planes, self.expansion*planes,                          kernel_size=1, stride=stride, bias=False),                nn.BatchNorm2d(self.expansion*planes)            )\n    def forward(self, x):        # Forward pass through residual block        out = F.relu(self.bn1(self.conv1(x)))  # ReLU after first convolution        out = self.bn2(self.conv2(out))        # Second convolution        out += self.shortcut(x)                # Add shortcut connection        out = F.relu(out)                      # Final ReLU        return out\n# Root block for DLA architectureclass Root(nn.Module):    def __init__(self, in_channels, out_channels, kernel_size=1):        super(Root, self).__init__()        self.conv = nn.Conv2d(            in_channels, out_channels, kernel_size,            stride=1, padding=(kernel_size - 1) // 2, bias=False)        self.bn = nn.BatchNorm2d(out_channels)\n    def forward(self, xs):        x = torch.cat(xs, 1)  # Concatenate inputs        out = F.relu(self.bn(self.conv(x)))  # Convolution and ReLU        return out\n# Tree block for hierarchical DLA structureclass Tree(nn.Module):    def __init__(self, block, in_channels, out_channels, level=1, stride=1):        super(Tree, self).__init__()        self.root = Root(2*out_channels, out_channels)  # Root block        if level == 1:            # Level 1: basic blocks            self.left_tree = block(in_channels, out_channels, stride=stride)            self.right_tree = block(out_channels, out_channels, stride=1)        else:            # Recursive tree construction            self.left_tree = Tree(block, in_channels,                                  out_channels, level=level-1, stride=stride)            self.right_tree = Tree(block, out_channels,                                   out_channels, level=level-1, stride=1)\n    def forward(self, x):        out1 = self.left_tree(x)      # Left subtree        out2 = self.right_tree(out1)  # Right subtree        out = self.root([out1, out2]) # Root combines outputs        return out\n# Full SimpleDLA architectureclass SimpleDLA(nn.Module):    def __init__(self, block=BasicBlock, num_classes=10):        super(SimpleDLA, self).__init__()        # Base layers        self.base = nn.Sequential(            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False),            nn.BatchNorm2d(16),            nn.ReLU(True)        )\n        # Sequential layers        self.layer1 = nn.Sequential(            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1, bias=False),            nn.BatchNorm2d(16),            nn.ReLU(True)        )\n        self.layer2 = nn.Sequential(            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1, bias=False),            nn.BatchNorm2d(32),            nn.ReLU(True)        )\n        # Hierarchical Tree blocks        self.layer3 = Tree(block,  32,  64, level=1, stride=1)        self.layer4 = Tree(block,  64, 128, level=2, stride=2)        self.layer5 = Tree(block, 128, 256, level=2, stride=2)        self.layer6 = Tree(block, 256, 512, level=1, stride=2)\n        # Classification layer        self.linear = nn.Linear(512, num_classes)\n    def forward(self, x):        # Forward pass through the entire network        out = self.base(x)        out = self.layer1(out)        out = self.layer2(out)        out = self.layer3(out)        out = self.layer4(out)        out = self.layer5(out)        out = self.layer6(out)        out = F.avg_pool2d(out, 4)  # Global average pooling        out = out.view(out.size(0), -1)  # Flatten        out = self.linear(out)  # Linear layer for classification        return out\n```\n8. Создайте и настройте модель:\n```\nnet = SimpleDLA()net = net.to(device)  # Move the model to the specified device (CPU or GPU)\n# If using GPU, wrap the model in DataParallel to utilize multiple GPUsif device == 'cuda':    net = torch.nn.DataParallel(net)    cudnn.benchmark = True  # Optimize performance for CUDA\n# Resume training from checkpoint if requiredif resume:    print('==> Resuming from checkpoint..')    assert os.path.isdir(checkpoint_dir), 'Error: no checkpoint directory found!'    checkpoint = torch.load(checkpoint_file)    net.load_state_dict(checkpoint['net'])    best_acc = checkpoint['acc']    start_epoch = checkpoint['epoch']\n# Define loss function and optimizercriterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classificationoptimizer = optim.SGD(net.parameters(), lr=0.1,                      momentum=0.9, weight_decay=5e-4)  # SGD with momentum\n# Learning rate scheduler with cosine annealingscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n```\n9. Создайте функцию для создания искусственных проблем производительности.\nФункция создает искусственные проблемы производительности для демонстрации рекомендаций.\nЭта функция намеренно вводит неэффективности для того, чтобы профилировщик мог сгенерировать полезные рекомендации по оптимизации.\nДля создания функции выполните:\n```\n# Function to create artificial performance bottlenecksdef create_performance_bottlenecks(inputs, targets):    # Problem 1    if device == 'cuda':        # Each .item() call forces GPU to wait for computation to finish        for i in range(3):  # 3 unnecessary synchronizations            _ = inputs.sum().item()  # .item() triggers CPU-GPU synchronization\n        # Artificial delay to simulate poor optimization        # This causes GPU idle time        time.sleep(0.001)\n    # Create problem 2    large_tensor = torch.zeros(1000, 1000).to(inputs.device)    for i in range(5):        large_tensor = large_tensor + 0.1  # Redundant operations\n    # Create problem 3    intermediate_results = []    for i in range(10):        temp_result = inputs.clone()        intermediate_results.append(temp_result)\n    # Clear memory, but the pattern still demonstrates the issue    del intermediate_results\n    return inputs, targets\n```\n10. Создайте функцию тренировки одной эпохи.\nНа этом шаге вы выполните тренировку модели на одной эпохе с логированием в TensorBoard и возможностью профилирования производительности с рекомендациями.\n\n```\n# Function to train one epochdef train(epoch):    print('\\nEpoch: %d' % epoch)    net.train()  # Set model to training mode\n    # Initialize metrics for current epoch    train_loss = 0    correct = 0    total = 0\n    # Variables for computing running average    running_loss = 0.0    running_correct = 0    running_total = 0\n    # Determine if profiling should be performed    # Profile only the first epoch to save time    should_profile = (epoch == start_epoch)\n    if should_profile:        # Start profiling with recommendations        # Configure PyTorch profiler with extended parameters        # to get detailed optimization recommendations        with profile(            # Profile both CPU and CUDA operations for complete analysis            activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n            # Profiling schedule:            # wait=1 - wait for 1 step (not profiling)            # warmup=1 - warmup for 1 step (not profiling)            # active=5 - actively profile for 5 steps            schedule=torch.profiler.schedule(wait=1, warmup=1, active=5),\n            # Save results in TensorBoard format for visualization            on_trace_ready=torch.profiler.tensorboard_trace_handler(log_dir),\n            # Record tensor shape information for analysis            record_shapes=True,\n            # Record memory usage information            profile_memory=True,\n            # Record call stack for tracing            with_stack=True,\n            # Enable recommendations collection            # Experimental configuration for detailed recommendations            experimental_config=torch._C._profiler._ExperimentalConfig(verbose=True)        ) as prof:\n            # Use tqdm for progress display            with tqdm(trainloader, unit=\"batch\") as tepoch:                for batch_idx, (inputs, targets) in enumerate(tepoch):                    # Required step for profiler                    # Inform profiler about new step                    # Without this, profiling won't work correctly                    prof.step()\n                    # Profile more batches for better statistics                    # Increase from 10 to 15 batches for more complete analysis                    if batch_idx >= 15:                        break\n                    # Create artificial performance issues                    # Add artificial bottlenecks to demonstrate recommendations                    inputs, targets = create_performance_bottlenecks(inputs, targets)\n                    # Transfer data to device (GPU/CPU)                    inputs, targets = inputs.to(device), targets.to(device)\n                    # Issue: Inefficient backward pass                    # Perform multiple unnecessary forward/backward passes instead of one                    # This creates excessive load and memory issues                    if batch_idx % 3 == 0 and device == 'cuda':  # Every 3rd batch                        # Unnecessary forward/backward passes                        for _ in range(2):                            # Process only part of the batch (inefficient)                            extra_outputs = net(inputs[:32])  # Only part of the batch                            extra_loss = criterion(extra_outputs, targets[:32])                            # retain_graph=True causes memory issues                            # and slows down execution                            extra_loss.backward(retain_graph=True)\n                    # Normal forward pass                    # Zero gradients before new step                    optimizer.zero_grad()\n                    # Forward pass through the network                    outputs = net(inputs)\n                    # Compute loss function                    loss = criterion(outputs, targets)\n                    # Backward pass (gradient computation)                    loss.backward()\n                    # Update model weights                    optimizer.step()\n                    # Update metrics                    # Accumulate overall metrics                    train_loss += loss.item()                    _, predicted = outputs.max(1)                    total += targets.size(0)                    correct += predicted.eq(targets).sum().item()\n                    # Update running averages for logging                    running_loss += loss.item()                    running_total += targets.size(0)                    running_correct += predicted.eq(targets).sum().item()\n                    # Log metrics every 10 batches                    if batch_idx % 10 == 0:                        # Log current batch loss to TensorBoard                        writer.add_scalar('Training/Loss_batch',                                        loss.item(),                                        epoch * len(trainloader) + batch_idx)                        # Log current batch accuracy                        writer.add_scalar('Training/Accuracy_batch',                                        100.*running_correct/running_total,                                        epoch * len(trainloader) + batch_idx)                        # Reset counters for next window                        running_loss = 0.0                        running_correct = 0                        running_total = 0\n                    # Update progress display                    tepoch.set_postfix(loss = loss.item(), accuracy = 100.*correct/total)    else:        # Normal training without profiling        # Used for other epochs to save time        with tqdm(trainloader, unit=\"batch\") as tepoch:            for batch_idx, (inputs, targets) in enumerate(tepoch):                # Add some issues even in normal mode                # for consistent issues                if batch_idx % 5 == 0:  # Every 5th batch has issues                    inputs, targets = create_performance_bottlenecks(inputs, targets)\n                # Normal training without artificial issues                inputs, targets = inputs.to(device), targets.to(device)                optimizer.zero_grad()                outputs = net(inputs)                loss = criterion(outputs, targets)                loss.backward()                optimizer.step()\n                # Update metrics                train_loss += loss.item()                _, predicted = outputs.max(1)                total += targets.size(0)                correct += predicted.eq(targets).sum().item()\n                # Update running averages                running_loss += loss.item()                running_total += targets.size(0)                running_correct += predicted.eq(targets).sum().item()\n                # Log metrics every 10 batches                if batch_idx % 10 == 0:                    writer.add_scalar('Training/Loss_batch',                                    loss.item(),                                    epoch * len(trainloader) + batch_idx)                    writer.add_scalar('Training/Accuracy_batch',                                    100.*running_correct/running_total,                                    epoch * len(trainloader) + batch_idx)                    running_loss = 0.0                    running_correct = 0                    running_total = 0\n                # Update progress display                tepoch.set_postfix(loss = loss.item(), accuracy = 100.*correct/total)\n    # Log epoch metrics    # Compute average values for the epoch    epoch_loss = train_loss/len(trainloader)    epoch_acc = 100.*correct/total\n    # Log epoch metrics to TensorBoard    writer.add_scalar('Training/Loss_epoch', epoch_loss, epoch)    writer.add_scalar('Training/Accuracy_epoch', epoch_acc, epoch)\n    # Log current learning rate    writer.add_scalar('Learning_Rate', scheduler.get_last_lr()[0], epoch)\n```\n11. Создайте функцию тестирования модели.\nНа этом шаге вы протестируете модель на тестовой выборке с логированием результатов.\n```\ndef test(epoch):\n    global best_acc  # Use global variable for best accuracy\n    net.eval()  # Set model to evaluation mode (disable dropout/batchnorm training)\n    # Initialize test metrics    test_loss = 0    correct = 0    total = 0\n    # Disable gradient computation for faster evaluation    with torch.no_grad():        # Use tqdm to display progress        with tqdm(testloader, unit=\"batch\") as tepoch:            for inputs, targets in tepoch:                # Move data to device                inputs, targets = inputs.to(device), targets.to(device)\n                # Forward pass                outputs = net(inputs)\n                # Compute loss                loss = criterion(outputs, targets)\n                # Update metrics                test_loss += loss.item()                _, predicted = outputs.max(1)                total += targets.size(0)                correct += predicted.eq(targets).sum().item()\n                # Update progress bar                tepoch.set_postfix(loss=loss.item(), accuracy=100. * correct / total)\n    # Compute test accuracy    acc = 100. * correct / total\n    # Save checkpoint if accuracy improved    if acc > best_acc:        print('Saving..')        state = {            'net': net.state_dict(),  # Model state            'acc': acc,               # Accuracy            'epoch': epoch,           # Epoch number        }        # Create directory if it does not exist        if not os.path.isdir(checkpoint_dir):            os.mkdir(checkpoint_dir)        # Save checkpoint        torch.save(state, checkpoint_file)        best_acc = acc  # Update best accuracy\n    # Compute average test loss    test_loss_avg = test_loss / len(testloader)\n    # Log test metrics to TensorBoard    writer.add_scalar('Testing/Loss', test_loss_avg, epoch)    writer.add_scalar('Testing/Accuracy', acc, epoch)    writer.add_scalar('Testing/Best_Accuracy', best_acc, epoch)\n# Log model architecture to TensorBoard# Create dummy input for graph visualizationdummy_input = torch.randn(1, 3, 32, 32).to(device)# Add model graph to TensorBoardwriter.add_graph(net, dummy_input)\n```\n12. Запустите основной цикл обучения.\nОбучение может занимать до 30 минут.\n```\n# Main training loop# Iterate over all epochsfor epoch in range(start_epoch, start_epoch + max_epoch):    train(epoch)     # Train the model    test(epoch)      # Test the model    scheduler.step() # Update learning rate\n# Finish up# Close the writer to ensure logs are properly savedwriter.close()\n```\n13. Выполните демонстрационный код для проверки работы обученной модели.\nКод отображает одно изображение из тестовой выборки и показывает, как модель классифицирует его.\n```\n# Demonstration code# Code to demonstrate the trained model's performanceimport numpy as npimport matplotlib.pyplot as plt\n# Take the 15th example from the test datasetimg = testset[14][0]label = testset[14][1]\n# Convert image for displayimg_np = img.numpy()img_np = np.transpose(img_np, (1, 2, 0))  # Change axis order (CHW -> HWC)plt.imshow(img_np)  # Display the imageplt.show()          # Show the plot\n# Prepare image for predictionimg = img.reshape(1, 3, 32, 32)  # Add batch dimension\n# Make prediction without gradient computationwith torch.no_grad():    logits = net(img)                    # Get logits    predicted_label = torch.argmax(logits)  # Find class index with highest probability\n# Print resultsprint(f\"Label: {classes[label]}\")                    # True labelprint(f\"Predicted: {classes[predicted_label.item()]}\")  # Predicted label\n```\nМодель распознала объект как грузовик — предсказание верное.\n\n## 3. Настройте PyTorch Profiler\nНа этом шаге вы настроите TensorBoard PyTorch Profiler и познакомитесь с интерфейсом.\n1. Перейдите на вкладку TensorBoard.\n2. В поле Log Dir введите скопированный путь до папки runs.\n3. Дождитесь загрузки визуализации процесса обучения и различные метрики.\n4. Перейдите на вкладку PYTORCH_PROFILER.\n\n## 4. Ознакомьтесь с методами визуализации PyTorch Profiler\nНа этом шаге вы научитесь анализировать результаты профилирования для оптимизации производительности модели.\nНа вкладке PYTORCH_PROFILER отображаются следующие показатели:\n- Runs — отдельные запуски экспериментов, тренировки и валидации, которые вы профилировали.\nИх можно выбирать и сравнивать между собой.\n- Views — способы представления профилированных данных для анализа:\n- Overview — сводка нагрузки устройства и времени, общая загрузка CPU/GPU, время шагов (forward, backward, optimizer), распределение времени по категориям (Kernel, Memcpy, CPU Exec и др.) и рекомендации профайлера.\n- Operator — статистика по PyTorch-операторам, например aten::empty и aten::add.\nКоличество вызовов и время на CPU и GPU.\n- GPU Kernel — детальный анализ отдельных GPU-ядр.\nСписок запущенных ядер, длительность каждого ядра, использование Tensor Cores, заполненность SM (SM occupancy).\n- Trace — временная диаграмма исполнения потоков.\nПозволяет детально рассмотреть конкурентность, использование потоков и временные интервалы различных операций.\n- Memory — использование видеопамяти по времени.\nОбъем выделенной (Allocated) и зарезервированной (Reserved) памяти.\nТочки аллокаций/освобождений и пиковое потребление.\n- Module — дерево вызовов на уровне слоев PyTorch.\nОтображает подмодули и операторы, вызванные внутри каждого модуля, время выполнения на CPU/GPU для каждого уровня.\n- Workers — источник данных профилирования (процессы/потоки).\nНапример, main-процесс, DataLoader и их потоки.\nОбъем собранных данных для каждого.\n- Spans — интервалы времени, за которые собирается статистика.\nПозволяет профилировать только интересующие фрагменты обучения.\nНапример, первые 10 % эпохи или отдельные итерации.\nВнутренние показатели профилирования GPU:\n- Host, Device Total, Self Duration — общее время выполнения оператора/ядра и время в self-режиме, без учета вложенных вызовов.\n- Tensor Cores Used — степень использования tensor-ядер, важна для операций FP16/FMA.\n- Calls — количество вызовов операции/ядра.\n- Mean Est. Achieved Occupancy — заполненность мультипроцессоров, показатель эффективности загрузки GPU.\n- Peak Memory Usage — пиковое использование памяти.\n- Allocated/Reserved Memory Usage — объем выделенной и зарезервированной памяти в мегабайтах.\n- Module Name, Occurrences, Operators — название слоя, количество его вызовов и число различных операторов внутри него.\nПоказатели позволяют оценить эффективность использования вычислительных ресурсов и планировать оптимизацию.\n\n## 5. Проанализируйте результаты\nНа этом шаге вы проанализируете результаты на основе Spans 1.\nOverview (Обзор)\nОсновное:\n- Device: GPU (Tesla V100-SXM3-32GB).\n- GPU Utilization: 79.5% — хорошая загрузка, но не максимальная.\n- Est. SM Efficiency: 75.77%.\n- Achieved Occupancy: 36.85% — невысокая, есть потенциал для увеличения.\n- Step Time: 59,925 us (микросекунд).\n- Kernel: 81.3% — основная часть времени тратится на вычисления на GPU.\n- CPU Exec: 8.45%\n- Other: 9.82%\nВывод:\nУзкие места — основное время уходит в GPU-ядра (Kernel), но низкий уровень occupancy может указывать на то, что не все ресурсы GPU используются оптимально.\nНапример, низкие значения в показателе batch size указывают на неэффективные ядра.\n\nOperator View (Операторы)\nОсновное:\n- Представлен разрез времени для топ-10 PyTorch операторов.\n- Крупнейшие по времени: aten::empty_strided, aten::copy_, aten::_to_copy — создание тензоров и копирование.\n- Основные вычислительные операции — aten::convolution, aten::cudnn_convolution.\n- Нет нагрузок на Tensor Cores — значения 0.\nВывод:\n- Замечено большое число вызовов операций выделения памяти: aten::empty, aten::empty_strided.\nЭто может косвенно указывать на частое создание новых тензоров — повышенное потребление памяти и время на управление памятью.\n- Большая часть операторов не использует Tensor Cores.\nЕсли вы работаете с mixed precision FP32, это нормально, но для mixed precision (FP16) производительность можно повысить.\n\nGPU Kernel View (Ядра графического процессора)\nОсновное:\n- Наибольшее время занимают матричные ядра volta_sgemm_* и *_cudnn_*, что характерно для сверточных сетей.\n- Абсолютное доминирование синего цвета означает, что почти все ядра не используют Tensor Cores.\nВывод:\n- Модель не использует Tensor Cores.\n- Если задача позволяет, попробуйте включить mixed precision (AMP) — это поможет ускорить обучение на современных GPU.\n\nTrace (Временная диаграмма)\nОсновное:\n- Видна характерная картина многопоточности — различные потоки CPU.\n- Можно посмотреть, нет ли интервалов между последовательностями событий.\nВывод:\n- Не видно крупных задержек (пробелов) — загрузка CPU-потоков ровная.\n- Нет интервалов между последовательностями событий.\n\nMemory View (Память)\nОсновное:\n- Peak GPU Memory Usage: 1419.1 MB — для V100 это небольшая часть доступной памяти.\nМожно повысить batch size для большего использования GPU.\n- Основные аллокации идут на операцию aten::cudnn_convolution.\n- График показывает закономерное выделение и освобождение памяти — три возвышения по числу итераций/батчей.\nВывод:\n- Модель экономно расходует память, возможен запас для увеличения batch size, это поможет GPU-occupancy.\n- Нет чрезмерного расхода памяти.\n\nModule View (Модули)\nОсновное:\n- Вызовы отслеживаются до слоев: DataParallel, CrossEntropyLoss, SimpleDLA.\n- Отображается детальная callstack-структура: видно, где и к каким операторам обращается модуль.\nВывод:\n- Можно использовать эти данные для pinpoint-анализа долгих вызовов внутри отдельных модулей.\n- Видно, что DataParallel использует относительно много времени на CPU — обычная ситуация для single-GPU.\n\nОбратите внимание, что если менять Spans, отображаемая информация может радикально меняться, также будут появляться рекомендации от TensorBoard.\nНапример, при параметрах:\n\nМы получаем рекомендацию, связанную с низкой утилизацией GPU:\n\n## Результат\nВ ходе практической работы вы научились использовать TensorBoard с PyTorch Profiler для анализа производительности моделей машинного обучения.\nВы создали нейронную сеть для классификации изображений, обучили ее с применением инструментов профилирования и изучили методы анализа результатов для оптимизации производительности.\nPyTorch Profiler — мощный диагностический инструмент, который существенно повышает качество кода и эффективность разработки нейронных сетей, делая его обязательным к использованию в любом крупном ML проекте.\n\n  [© 2025 Cloud.ru](https://cloud.ru)",
      "debug": {
        "start_page": 1,
        "end_page": 1
      }
    }
  ]
}
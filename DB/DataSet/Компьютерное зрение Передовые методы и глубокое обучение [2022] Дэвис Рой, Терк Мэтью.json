{
  "title": "Компьютерное зрение Передовые методы и глубокое обучение [2022] Дэвис Рой, Терк Мэтью",
  "chapters": [
    {
      "name": "Глава 1. Кардинальные перемены в области компьютерного зрения 27",
      "content": "--- Страница 28 --- (продолжение)\nГлава 1 Кардинальные перемены в области компьютерного зрения Автор главы: Рой Дэвис, Роял Холлоуэй, Лондонский университет, Эгам, графство Суррей, Соединенное Королевство Краткое содержание главы: обзор истории методов компьютерного зрения, включая операторы низ- коуровневой обработки изображений, обнаружение 2D- и 3D-объектов, определение местоположения и распознавание, отслеживание и сегмен- тацию; изучение развития методов глубокого обуче ния на основе искусственных нейронных сетей, включая взрывной рост популярности глубокого обуче- ния; обзор методов глубокого обуче ния, применяемых для обнаружения при- знаков, обнаружения объектов, определения местоположения, распозна- вания и отслеживания объектов, классификации текстур и семантической сегментации изображений; влияние методов глубокого обуче ния на традиционную методологию компью терного зрения. 1.1. В Ведение . Компьютерное зрение и его история В течение последних трех-четырех десятилетий компьютерное зрение по- степенно превратилось в полноценный научный предмет со своей методо- логией и областью применения. На самом деле у него так много областей применения, что трудно перечислить их все. Среди наиболее известных – распознавание объектов, наблюдение (включая подсчет людей и распозна-\nГлава 1 Кардинальные перемены в области компьютерного зрения Автор главы: Рой Дэвис, Роял Холлоуэй, Лондонский университет, Эгам, графство Суррей, Соединенное Королевство Краткое содержание главы: обзор истории методов компьютерного зрения, включая операторы низ- коуровневой обработки изображений, обнаружение 2D- и 3D-объектов, определение местоположения и распознавание, отслеживание и сегмен- тацию; изучение развития методов глубокого обуче ния на основе искусственных нейронных сетей, включая взрывной рост популярности глубокого обуче- ния; обзор методов глубокого обуче ния, применяемых для обнаружения при- знаков, обнаружения объектов, определения местоположения, распозна- вания и отслеживания объектов, классификации текстур и семантической сегментации изображений; влияние методов глубокого обуче ния на традиционную методологию компью терного зрения. 1.1. В Ведение . Компьютерное зрение и его история В течение последних трех-четырех десятилетий компьютерное зрение по- степенно превратилось в полноценный научный предмет со своей методо- логией и областью применения. На самом деле у него так много областей применения, что трудно перечислить их все. Среди наиболее известных – распознавание объектов, наблюдение (включая подсчет людей и распозна-\n--- Страница 29 ---\n28  Кардинальные перемены в области компьютерного зрения вание номерных знаков), роботизированное управление (включая автомати- ческое управление транспортным средством), сегментация и интерпретация медицинских изображений, автоматический осмотр и сборка в заводских условиях, распознавание отпечатков пальцев и лиц, интерпретация жестов и многое другое. Для работы компьютерного зрения необходим поток данных из различных источников изображений, включая каналы видимого и инфра- красного спектра, трехмерные датчики и ряд жизненно важных медицинских устройств визуализации, таких как компьютерные и магнитно-резонансные томографы. К тому же данные должны включать положение, позу, расстояние между объектами, движение, форму, текстуру, цвет и многие другие аспекты. При таком разнообразии данных и изобилии действий и методов, исполь- зуемых для их обработки, будет трудно обрисовать общую картину в рамках одной главы: следовательно, выбор материала неизбежно будет ограничен; тем не менее мы будем стремиться обеспечить прочную основу и дидакти- ческий подход к предмету. Сегодня вряд ли можно представить компьютерное зрение без огромно- го прорыва, достигнутого в 2010-х годах, и, в частности, «взрыва глубокого обуче ния», который произошел примерно в 2012 г. Это событие значительно изменило саму суть предмета исследований и привело к достижениям и при- менениям, которые не только впечатляют, но и во многих случаях выходят далеко за рамки того, о чем люди мечтали даже в 2010 г. Наша книга в первую очередь посвящена самым передовым достижениям в области компьютерно- го зрения; роль этой вступительной главы состоит в том, чтобы обрисовать в общих чертах историю традиционной методологии, исследовать новые методы глубокого обуче ния и показать, как они изменили и улучшили более ранние (устаревшие) подходы. На первом этапе будет полезно рассмотреть истоки компьютерного зре- ния, которое можно считать зародившимся в 1960-х и 1970-х гг., в основном как ответвление обработки изображений. В то время появилась техническая возможность захватывать целые изображения, а также удобно хранить и об- рабатывать их на цифровых компьютерах. Первоначально изображения, как правило, записывались в бинарном виде или в оттенках серого, хотя позже стало возможным захватывать их в цвете. Исследователи уже тогда мечтали подражать человеческому глазу, распознавая объекты и интерпретируя сце- ны, но с доступными тогда маломощными компьютерами эти мечты были далеки от воплощения. На практике обработка изображений использовалась для исправления (tiding up) изображений и обнаружения признаков объектов, а распознавание изображений осуществлялось с использованием методов статистического распознавания образов, таких как алгоритм ближайшего соседа (nearest neighbor algorithm). Двумя основными локомотивами разви- тия компьютерного зрения стали искусственный интеллект и биологическое зрение. Ограниченный объем книги не позволит нам здесь обсуждать эти аспекты; отметим лишь, что они заложили основу искусственных нейронных сетей и глубокого обуче ния (подробнее об этом в разделе 1.7). Исправление изображений, вероятно, лучше описать как предваритель- ную обработку: она может включать в себя ряд функций, где одной из самых важных является устранение шума. Вскоре было обнаружено, что использо-\n--- Страница 30 ---\nВведение. Компьютерное зрение и его история  29 вание алгоритмов сглаживания, в которых вычисляется среднее значение интенсивностей в окне вокруг каждого входного пикселя, применяемое для формирования отдельного сглаженного изображения, не только приводит к снижению уровня шума, но и к влиянию сигнала на самого себя (этот про- цесс также можно представить как уменьшение входной полосы пропус - кания для устранения большей части шума, с дополнительным эффектом устранения из входного сигнала компонентов высокой пространственной частоты). Однако эта проблема была в значительной степени решена за счет применения медианной, а не средней фильтрации, поскольку она работает за счет устранения выбросов на каждом конце локального распределения интенсивности – медиана является значением, наименее подверженным влиянию шума. Типичные ядра фильтрации по среднему показаны ниже, причем второе из них более приближено к идеальной гауссовой форме: (1.1) Оба они являются ядрами линейной свертки, которые по определению пространственно инвариантны в пространстве изображений. Общая маска свертки 3×3 задается выражением (1.2) где локальным пикселям присвоены метки 0–8. Затем мы берем значения интенсивности в локальной окрестности изображения 3×3 как (1.3) Воспользовавшись нотацией условного языка программирования наподо- бие C++ , мы можем записать полную процедуру свертки в виде псевдокода: для всех пикселей изображения выполнить { Q0 = P0∗c0 + P1∗c1+ P2∗c2+ P3∗c3 +P4∗c4 + P5∗c5 + P6∗c6 + P7∗c7+ P8∗c8; } (1.4) До сих пор мы рассматривали маски свертки, которые представляют собой линейные комбинации входных интенсивностей: они отличаются от нели- нейных процедур, таких как пороговая обработка, которые не могут быть выражены как свертки. На самом деле пороговая обработка очень широко применяется и может быть записана в виде следующего алгоритма:\n--- Страница 31 ---\n30  Кардинальные перемены в области компьютерного зрения для всех пикселей изображения выполнить { если (P0 < порог) A0 = 1; иначе А0 = 0; } (1.5) Эта процедура преобразует изображение в оттенках серого в P-пространстве в бинарное изображение в A-пространстве. Здесь она используется для вы- деления темных объектов, представляя их как единицы на фоне нулей. Мы завершаем этот раздел полной процедурой медианной фильтрации в пределах окрестности 3×3: для (i = 0; i <= 255; i ++) hist[i] = 0; для всех пикселей изображения выполнить { для (m = 0;m <= 8;m++) hist[P[m]]++; i = 0; sum = 0; пока (sum < 5){ sum = sum+hist[i]; i = i +l; } Q0 = i −1; для (m = 0;m <= 8;m++) hist[P[m]] = 0; } (1.6) Запись P[0] обозначает P 0, и так далее от P[1] до P[8] . Заметим, что опе- рация нахождения медианы требует больших вычислений, поэтому время экономится только за счет повторной инициализации конкретных элемен- тов гистограммы, которые фактически использовались. Важная особенность процедур, описываемых уравнениями (1.4)–(1.6), за- ключается в том, что они берут входные данные из одного пространства изо- бражений и выводят их в другое пространство изображений – процесс, часто описываемый как параллельная обработка, – тем самым устраняя проб лемы, связанные с порядком, в котором выполняются вычисления отдельных пик - селей. Наконец, все алгоритмы сглаживания изображений, задаваемые уравне- ниями (1.1)–(1.4), используют ядра свертки 3×3, хотя, очевидно, можно ис - пользовать ядра гораздо большего размера: действительно, их можно реа- лизовать иным путем, сначала преобразовывая в область пространственных частот, а затем систематически устраняя высокие пространственные часто- ты, хотя и с дополнительной вычислительной нагрузкой. С другой стороны, нелинейные операции, такие как медианная фильтрация, не могут быть реа - лизованы подобным образом. Для удобства остаток этой главы разделен на несколько частей следующим образом: часть A. Обзор операторов низкоуровневой обработки изображений; часть B. Выделение и распознавание 2D-объектов; часть C. Выделение трехмерных объектов и важность инвариантности; часть D. Отслеживание движущихся объектов; часть E. Анализ текстур; часть F. От искусственных нейронных сетей к методам глубокого обуче- ния; часть G. Заключение.\n--- Страница 32 ---\nЧасть A. Обзор операторов низкоуровневой обработки изображений  31 В целом назначение этой главы состоит в том, чтобы обобщить ключевые понятия и достижения ранних – или «устаревших» – исследований в области компьютерного зрения и напомнить читателям об их значении, чтобы они могли более уверенно освоить новейшие разработки в этой области. Одна- ко необходимость сделать такой выбор означает, что пришлось исключить многие другие важные темы. 1.2. Ч асть A. обзор операторо В низ Коуро ВнеВой обработ Ки изображений 1.2.1. Основы обнаружения краев Обнаружение краев (edge detection) является наиболее важной и широко при- меняемой операцией обработки изображений. Для этого есть разные важные причины, но в конечном счете описание форм объектов по их краям и внут - ренним контурам уменьшает объем данных, необходимых для хранения изображения N×N, с O( N2) до O(N ), тем самым значительно повышая эффек - тивность последующего хранения и обработки. Кроме того, хорошо известно, что люди могут очень эффективно распознавать объекты по их контурам (иногда даже лучше, чем по полному изображению): легкость и достовер- ность распознавания двумерных эскизов и мультфильмов могут служить тому подтверждением. В 1960-х и 1970-х годах было разработано значительное количество опера- торов обнаружения краев, многие из которых были в первую очередь интуи- тивно понятными, а это означает, что их оптимальность была под вопросом. Некоторые операторы применяли 8 или 12 масок-шаблонов для обнаруже- ния краев с разной ориентацией. Как ни странно, прошло достаточно много времени, прежде чем возникло понимание, что, поскольку края являются векторами, для их обнаружения должно быть достаточно двух масок. Однако это не сразу устранило необходимость принятия решения о том, какие ко- эффициенты маски следует использовать в детекторах краев – даже в случае окрестностей 3×3, – и мы перейдем к дальнейшему изучению этого вопроса. Далее мы исходно полагаем, что необходимо использовать 8 масок с угла- ми, отличающимися на 45°. Однако 4 из этих масок отличаются от остальных только знаком, что делает ненужным их отдельное применение. На данный момент аргументы симметрии приводят к следующим маскам для 0° и 45° соответственно: (1.7) Очевидно, что очень важно спроектировать маски так, чтобы они давали правильные ответы в разных направлениях. Чтобы выяснить, как это влияет\n--- Страница 33 ---\n32  Кардинальные перемены в области компьютерного зрения на коэффициенты маски, воспользуемся тем фактом, что градиенты интен- сивности должны следовать правилам сложения векторов. Если значения интенсивности пикселей в окрестности 3×3 равны (1.8) представленные выше маски приведут к следующим оценкам градиента в направлениях 0°, 90° и 45°: g0 = A(c + i - a - g) + B(f - d); g90 = A(a + c - g - i) + B(b - h); (1.9) g45 = C(b + f - d - h) + D(c - g). Если сложение векторов должно быть допустимым, мы также имеем: g45 = (g0 + g90)/ . (1.10) Приравнивание коэффициентов при a, b, , i приводит к самосогласован- ной паре условий: C = B/; D = A . (1.11) Далее обратите внимание на дополнительное требование – маски 0° и 45° должны давать одинаковые отклики при 22,5°. На самом деле за этим утверж - дением скрываются довольно утомительные алгебраические выкладки (Da- vies, 1986), которые показывают, что B/A = (13 - 4)/7 = 2,055. (1.12) Округляя значение этого выражения до 2, мы прямо приходим к маскам оператора Собеля: (1.13) применение которого дает карты компонентов gx, gy градиента интенсив- ности. Поскольку края являются векторами, мы можем вычислить локаль- ную величину края g и направление θ, используя стандартные векторные формулы: g = [gx2 + gy2]1/2; θ = arctan(g y /gx). (1.14) Обратите внимание, что вычисления g и θ для всего изображения не будут свертками, поскольку они включают нелинейные операции.\n--- Страница 34 ---\nЧасть A. Обзор операторов низкоуровневой обработки изображений  33 Итак, в разделах 1.1 и 1.2.1 мы описали различные категории операторов обработки изображений, включая линейные и нелинейные операторы и опе- раторы свертки. Примерами сверток (линейных операций) являются среднее и гауссово сглаживание и оценка компонента краевого градиента. Примера- ми нелинейных операций являются порог, вычисление краевого градиента и ориентации края. Следует отметить, что коэффициенты маски Собеля были получены в качестве побочного продукта, а не целенаправленно. Факти- чески они были разработаны для оптимизации точности ориентации кра- ев. Заметим также, что, как мы увидим позже, точность ориентации имеет первостепенное значение, когда информация о краях передается в схемы расположения объектов, такие как преобразование Хафа. 1.2.2. Оператор Кэнни Детектор краев Кэнни изначально был создан как намного более точная замена основных детекторов краев, таких как детектор Собеля, и вызвал на- стоящий фурор после публикации в 1986 году (Canny, 1986). Для достижения столь высокой точности по очереди применяется ряд процессов: 1. Изображение сглаживается с по мощью двумерного гауссиана, чтобы гарантировать, что поле интенсивности является математически кор- ректной функцией. 2. Изображение дифференцируется с использованием двух одномерных производных функций, таких как функции Собеля, и вычисляется поле величины градиента. 3. Для утончения краев используется немаксимальное подавление вдоль направления нормали локального края. Это происходит в два этапа: (1) нахождение двух нецентральных красных точек, показанных на рис. 1.1, что включает интерполяцию величины градиента между двумя парами пикселей; (2) выполнение квадратичной интерполяции между градиентами интенсивности в трех красных точках для определения положения сигнала края пика с субпиксельной точностью. 4. Выполняется «гистерезисная» пороговая обработка: применение двух порогов t1 и t2 (t2 > t1) к полю градиента интенсивности; результатом является «не край», если g < t1, «край», если g > t2, а иначе это будет «край», только если он находится рядом с «краем». (Обратите внима- ние, что свойство «край» может распространяться от пикселя к пиксе- лю в соответствии с приведенными выше правилами.) Как отмечено в пункте 3, для определения местоположения пика ампли- туды градиента может использоваться квадратичная интерполяция. Неслож - ные алгебраические выкладки показывают, что для g-значений g1, g2, g3 трех красных точек смещение пика от центральной красной точки равно (g 3 - g1) secθ /[2(2g 2 - g1 - g3)]: здесь sec θ – это коэффициент, на который θ увеличи- вает расстояние между крайними красными точками.\n--- Страница 35 ---\n34  Кардинальные перемены в области компьютерного зрения θ l1 l2Светлый конец Темный конец Рис. 1.1  Использование квадратичной интерполяции для определения точного положения пика амплитуды градиента 1.2.3. Обнаружение сегмента линии В разделе 1.2.1 мы показали, как при помощи детектора краев всего с двумя масками вычисляется величина и ориентация признака края. Стоит поду - мать, можно ли использовать аналогичный векторный подход и в других случаях. Действительно, модифицированный векторный подход также мож - но использовать для обнаружения признаков сегментов линии. В этом можно убедиться, рассмотрев следующую пару масок: (1.15) Ясно, что можно построить еще две маски такого вида, но они отлича- ются от двух предыдущих только знаком и ими можно пренебречь. Таким образом, этот набор масок содержит ровно столько, сколько необходимо для векторного вычисления. В самом деле, если мы ищем темные полосы на светлом фоне, 1 может обозначать линию, а –1 может представлять светлый фон. (Нули можно рассматривать как «безразличные» коэффициенты, так как они будут игнорироваться в любой свертке.) Следовательно, L 1 представляет собой полосу 0°, а L 2 – полосу 45°. (Термин «полоса» используется здесь для обозначения сегмента линии значимой ширины.) Применяя тот же метод, что и в разделе 1.2.1, и определяя значения интенсивности пикселей, как в уравнении (1.8), находим: l0 = A(d + f - b - h); l45 = B(c + g - a - i). (1.16)\n--- Страница 36 ---\nЧасть A. Обзор операторов низкоуровневой обработки изображений  35 Однако в данном случае недостаточно информации для определения от - ношения А к В, поэтому это должно зависеть от практических аспектов ситуа- ции. Учитывая, что это вычисление выполняется в окрестности 3×3, неудиви- тельно, что оптимальная ширина полосы для обнаружения с использованием вышеуказанных масок равна 1,0; эксперименты (Davies, 1997) показали, что согласование масок с шириной полосы w (или наоборот) дает оптимальную точность ориентации при w ≈ 1,4, что имеет место при B/A ≈ 0,86. Отсюда получается максимальная ошибка ориентации ∼0,4°, что выгодно отличается от ∼0,8° для оператора Собеля. Воспользуемся формулами, аналогичными формулам в разделе 1.2.1, для псевдовекторного расчета коэффициента интенсивности линии l и ориен- тации сегмента линии θ : l = [l2 0 + l2 45]1/2; (1.17) Здесь мы были вынуждены включить коэффициент 1/2 перед арктанген- сом: это потому, что отрезок прямой демонстрирует симметрию вращения на 180° по сравнению с 360° для обычных углов. Обратите внимание, что это снова тот случай, когда оптимизация направ- лена на достижение высокой точности ориентации, а не, например, на чув- ствительность обнаружения. Здесь стоит отметить два применения обнаружения линейных сегментов. Одним из них является осмотр сыпучих зерен пшеницы для обнаружения мелких темных насекомых, которые напоминают темные полосы: для это- го использовались маски 7×7, разработанные на основе приведенной выше модели (Davies и др., 2003). Другим применением является определение рас - положения артефактов, таких как телеграфные провода на фоне неба или тросов, поддерживающих киноактеров, которые затем можно целенаправ- ленно удалять. 1.2.4. Оптимизация чувствительности обнаружения Оптимизация чувствительности обнаружения – задача, которая хорошо из- вестна в радиолокации и очень эффективно применялась для этой цели со времен Второй мировой войны. По сути, эффективное обнаружение лета- тельных аппаратов радиолокационными системами требует оптимизации отношения сигнал–шум (signal to noise ratio, SNR). Конечно, в случае радара обнаружение – это одномерная проблема, тогда как при построении изо- бражений нам необходимо оптимально обнаруживать двумерные объекты на фоне шума. Однако шум изображения не обязательно является гауссовым белым шумом, как обычно предполагается применительно к радару, хотя удобно начать с этого предположения.\n--- Страница 37 ---\n36  Кардинальные перемены в области компьютерного зрения В радиолокации сигналы можно рассматривать как положительные пики на фоне шума, который обычно близок к нулю. В этих условиях применима хорошо известная теорема, которая гласит, что оптимальное обнаружение сигнала заданной формы достигается с по мощью «согласованного фильт - ра», который имеет ту же форму характеристики, что и идеализированный входной сигнал. То же самое относится к изображениям, и в этом случае пространственный согласованный фильтр должен иметь ту же форму харак - теристики, что и идеальная форма искомого двумерного объекта. Кратко рассмотрим математическую основу этого подхода. Во-первых, мы предполагаем набор пикселей, в которых производится выборка сиг - налов, что дает значения Si. Затем мы выражаем желаемый фильтр в виде n-элементного весового шаблона с коэффициентами wi. Наконец, предпо- лагаем, что уровни шума в каждом пикселе независимы и подчиняются ло- кальным распределениям со стандартными отклонениями N i. Очевидно, что суммарный сигнал, полученный от весового шаблона, мож - но записать в виде: (1.18) тогда как общий шум, полученный от весового шаблона, будет характеризо- ваться его дисперсией: (1.19) Следовательно, SNR равно (1.20) Для нахождения оптимального SNR найдем производную (1.21) а затем примем ∂ ρ2/∂wi = 0 и сразу получим (1.22) что можно записать проще как (1.23) хотя знак пропорциональности можно заменить равенством без ограниче- ния общности.\n--- Страница 38 ---\nЧасть A. Обзор операторов низкоуровневой обработки изображений  37 Обратите внимание, что если Ni не зависит от i (т. е. уровень шума не ме- няется на всей площади изображения), то wi = Si: это доказывает упомянутую выше теорему о том, что пространственный согласованный фильтр должен иметь тот же профиль интенсивности, что и двумерный объект, подлежащий обнаружению. 1.2.5. Работа с изменениями интенсивности фона Помимо очевидной разницы в размерности, есть еще одно важное отличие зрения от радара: у последнего в отсутствие входного сигнала выходной сигнал системы колеблется и в среднем равен нулю. Однако в компьютерном зрении уровень фона обычно будет меняться в зависимости от окружающего освещения, а также в зависимости от входного изображения. По сути, реше- ние этой проблемы заключается в использовании масок с нулевой суммой (или нулевым средним). Поэтому для такой маски, как в уравнении (1.2), мы просто вычитаем среднее значение c— всех компонентов маски из каждого компонента, чтобы убедиться, что общая маска имеет нулевое среднее зна- чение. Чтобы убедиться, что использование стратегии нулевого среднего работа- ет, представьте себе применение немодифицированной маски к окрестности изображения, показанной в уравнении (1.3), – допустим, мы получили зна- чение K. Теперь добавим B к интенсивности каждого пикселя в окрестности; это добавит ånBci = Bånci = Bnc— к значению K. Но если мы сделаем c— = 0, то получим исходный вывод маски K . В целом мы должны отметить, что стратегия нулевого среднего является лишь приближением, так как на изображении будут места, где фон варьи- руется между высоким и низким уровнями, поэтому невозможно точное устранение нулевого среднего (т. е. B нельзя рассматривать как постоянную над областью маски). Тем не менее если предположить, что изменение фона происходит в масштабе, значительно превышающем масштаб размера мас - ки, эта стратегия должна работать адекватно. Следует отметить, что аппроксимация с нулевым средним значением уже широко используется, как вы видели на примере масок ребер и сегментов линий в уравнениях (1.7) и (1.15). Этот подход также должен применяться к другим детекторам, таким как детекторы углов и отверстий. 1.2.6. Т еория, сочетающая согласованный фильтр и конструкции с нулевым средним На первый взгляд идея нулевого среднего настолько проста, что может пока- заться, что она легко интегрируется с формулами согласованного фильтра из раздела 1.2.4. Однако применение нулевого среднего уменьшает количество степеней свободы согласованного фильтра на одну, поэтому необходимо изменить формальное представление согласованного фильтра, чтобы по- следний продолжал оставаться идеальным детектором. Дабы продолжить,\n--- Страница 39 ---\n38  Кардинальные перемены в области компьютерного зрения мы представляем случаи с нулевым средним и согласованным фильтром следующим образом: (wi)z–m = Si - S—; (wi)m–f = Si /Ni2. (1.24) Далее мы объединяем их в форму wi = (Si – S˜)/N i2, (1.25) где мы избежали тупика, попробовав гипотетический (т. е. пока неизвест - ный) тип среднего для S, который мы называем S˜. (Конечно, если эта гипотеза в конце концов приведет к противоречию, потребуется новый подход.) При- менение условия нулевого среднего å iwi = 0 теперь дает следующее: (1.26) (1.27) (1.28) Из этого мы делаем вывод, что S˜ должно быть взвешенным средним, в частности взвешенным средним по шуму S˜. С другой стороны, если шум равномерный, S˜ вернется к обычному невзвешенному среднему S—. Кроме того, если мы не применяем условие нулевого среднего (которого мы можем достичь, установив S˜ = 0), уравнение (1.25) сразу возвращается к стандарт - ному условию согласованного фильтра. Формула для S˜ может показаться излишне обобщенной, поскольку Ni обычно почти не зависит от i. Однако если бы идеальный профиль был полу - чен путем усреднения профилей реальных объектов, то вдали от его центра дисперсия шума могла бы быть более существенной. Действительно, для больших объектов это было бы явным ограничивающим фактором при таком подходе. Но для относительно небольших объектов и признаков дисперсия шума не должна чрезмерно варьироваться и должны быть достижимы по- лезные профили согласованного фильтра. От себя хочу отметить, что основной результат, доказанный в этом разделе (ср. уравнения (1.25) и (1.28)), отнял у меня столько времени и усилий, что я начал было сомневаться в своей способности достичь его. Поэтому я стал называть его «последней теоремой Дэвиса». 1.2.7. Структура маски (дополнительные соображения) Хотя формальное представление согласованного фильтра и полностью ин- тегрированное к данному моменту условие нулевого среднего могут пока-\n--- Страница 40 ---\nЧасть A. Обзор операторов низкоуровневой обработки изображений  39 заться достаточно общими, чтобы обеспечить однозначную структуру маски, остается ряд аспектов, которые еще предстоит рассмотреть. Например, ка- кого размера должны быть маски? И как их оптимально разместить вокруг каких-либо примечательных объектов или признаков? Чтобы ответить на этот вопрос, мы возьмем следующий пример довольно сложного признака объекта. Здесь область 2 – это обнаруживаемый объект, область 1 – фон, а M – область маски признака. M 1 2 © IET 1999 В этой модели мы должны рассчитать оптимальные значения весовых ко- эффициентов маски w1 и w 2 и площадей областей A1 и A 2. Мы можем записать общую мощность сигнала и шума из маски шаблона как: S = w1A1S1 + w2A2S2; N2 = w12A1N12 + w22A2N22. (1.29) Таким образом, мы получаем отношение мощности сигнал–шум (SNR): (1.30) Легко видеть, что если обе области маски увеличить по площади одинаково в η раз, то во столько же раз увеличится и ρ2. Следовательно, мы можем оп- тимизировать маску, регулируя относительные значения A1 и A2 и оставляя общую площадь A неизменной. Давайте сначала исключим w2, используя ус - ловие нулевого среднего (которое обычно применяется для предотвращения влияния изменений уровня интенсивности фона на результат): w1A1 + w2A2 = 0. (1.31) Ясно, что мощность SNR больше не зависит от весов маски: (1.32) Далее, поскольку общая площадь маски A заранее определена, мы имеем: А2 = А – А1. (1.33)\n--- Страница 41 ---\n40  Кардинальные перемены в области компьютерного зрения Подстановка A 2 сразу дает нам простое условие оптимизации: А1/А2 = N1/N2. (1.34) Принимая N1 = N2, мы получаем важный результат – правило равных пло- щадей (Davies, 1999): А1 = А2 = А/2. (1.35) Наконец, когда применяется правило равных площадей, правило нулевого среднего принимает форму: w1 = –w2. (1.36) Обратите внимание, что многие случаи, например возникающие, когда передний план и фон имеют разные текстуры, можно смоделировать, пола- гая N1 ≠ N2. В этом случае правило равной площади не применяется, но мы все еще можем использовать уравнение (1.34). 1.2.8. Обнаружение угла В разделах 1.2.1 и 1.2.3 мы обнаружили, что только два типа признаков име- ют векторную (или псевдовекторную) форму – края и линейные сегменты. Следовательно, в то время как эти признаки могут быть обнаружены с ис - пользованием всего лишь двух компонентных масок, ожидается, что все остальные признаки потребуют сопоставления со многими другими шабло- нами, чтобы справиться с различными ориентациями. К этой категории от - носятся и детекторы углов, у которых типичные угловые шаблоны 3×3 имеют следующий вид: (1.37) (Обратите внимание, что эти маски были настроены на форму с нулевым сред- ним значением, дабы устранить эффекты различных условий освещения.) Чтобы преодолеть очевидные проблемы сопоставления шаблонов, не по- следней из которых является необходимость использования ограниченного числа цифровых масок для аппроксимации аналоговых вариаций интенсив- ности, которые сами по себе заметно различаются от экземпляра к экземпля- ру, было предпринято много усилий по выработке более принципиального подхода. В частности, поскольку края определяются первыми производными поля интенсивности изображения, казалось логичным перейти к производ- ным второго порядка. Одним из первых таких исследований был подход Боде (1978), в котором использовались операторы Лапласа и Гессе: Лапласиан = Ixx + Iyy; Гессиан = Ixx Iyy – I2 xy. (1.38)\n--- Страница 42 ---\nОператор «особой точки» Харриса  41 Они были особенно привлекательны, поскольку определены в терминах детерминанта и следа симметричной матрицы вторых производных и, та- ким образом, инвариантны относительно вращения. На самом деле оператор Лапласа дает существенные отклики вдоль ли- ний и краев и, следовательно, не особенно подходит для обнаружения углов. С другой стороны, оператор Боде ( оператор Гессе), известный как «DET», не реагирует на линии и края, но дает значимые сигналы вблизи углов и, следо- вательно, полезен для построения детектора углов, хотя он реагирует одним знаком на одной стороне угла и обратным знаком на другой стороне угла: на самом углу дает нулевой ответ. Кроме того, другие исследователи подверг - ли критике специфические отклики оператора DET и обнаружили, что им необходим довольно сложный анализ, чтобы определить наличие и точное положение каждого угла (Dreschler, Nagel, 1981; Nagel, 1983). Тем не менее Китчен и Розенфельд (Kitchen, Rosenfeld, 1982) показали, что они смогли преодолеть эти проблемы, оценив скорость изменения вектора направления градиента вдоль направления касательной горизонтального края и связав его с горизонтальной кривизной κ функции интенсивности I. Чтобы получить реалистичное представление о силе угла, они умножили κ на величину локального градиента интенсивности g : (1.39) Наконец, они использовали эвристику немаксимального подавления вдоль нормального направления края для дальнейшей локализации угловых поло- жений. Интересно, что Нагель (Nagel, 1983) и Шах и Джайн (Shah, Jain, 1984) при- шли к выводу, что угловые детекторы Китчена и Розенфельда, Дрешлера и Нагеля, а также Зуниги и Харалика (Zuniga, Haralick 1983) по существу эк - вивалентны. Это не должно вызывать большого удивления, так как, в конце концов, можно было бы ожидать, что различные методы будут отражать одни и те же лежащие в основе физические явления (Davies, 1988) – определение производной второго порядка, которое можно интерпретировать как гори- зонтальную кривизну, умноженную на градиент интенсивности. 1.2.9. оператор «особой тоЧКи» Х арриса На этом этапе Харрис и Стивенс (Harris, Stephens, 1988) разработали совер- шенно новый оператор, способный обнаруживать признаки угла, основан- ный не на производных второго порядка, а на производных первого порядка. Как мы увидим ниже, это упростило математическую составляющую, вклю- чая избавление от трудностей применения цифровых масок к аналоговым функциям. Фактически новый оператор смог выполнять функцию производ- ной второго порядка, применяя операции первого порядка. Любопытно, ка-\n--- Страница 43 ---\n42  Кардинальные перемены в области компьютерного зрения ким образом он извлекает соответствующую информацию о производных второго порядка. Чтобы понять это, нам нужно изучить его довольно простое математическое определение. Оператор Харриса определяется локальными компонентами градиента интенсивности Ix, Iy в изображении. Определение оператора требует, чтобы область окна была определена и усреднялась 〈.〉, дабы занять все это окно. Начнем с вычисления следующей матрицы: (1.40) Затем мы используем детерминант (det) и след (trace) для оценки углового сигнала: C = det D / trace D. (1.41) (Опять же, что касается операторов Боде, значение использования только детерминанта и следа заключается в том, что результирующий сигнал будет инвариантным к угловой ориентации.) Прежде чем приступить к анализу формы C, заметим, что если бы не прово- дилось усреднение, det D был бы тождественно равен нулю: ясно, что только сглаживание, присущее операции усреднения, допускает разброс значений первой производной и тем самым позволяет результату частично зависеть от вторых производных. Чтобы понять работу детектора в деталях, сначала рассмотрим его отклик для одиночного края (рис. 1.2а). Фактически здесь det D = 0, (1.42) потому что I x равен нулю во всей области окна. Далее рассмотрим ситуацию в окрестностях угла (рис. 1.2b). Здесь: где l1, l2 – длины двух краев, ограничивающих угол, а g – контраст края, пред- полагаемый постоянным для всего окна. Теперь мы находим (Davies, 2005): det D = l1l2 g4 sin2θ, (1.44) а также trace D = (l1 + l2)g2; (1.45) (1.46)\n--- Страница 44 ---\nЧасть B. Локализация и распознавание двухмерных объектов  43 Это можно интерпретировать как произведение (1) коэффициента доброт - ности λ, который зависит от длин кромок в пределах окна, (2) коэффициента контрастности g2 и (3) коэффициента формы sin2θ, который зависит от «рез- кости» края θ. Ясно, что C равно нулю при θ = 0 и θ = π и максимально при θ = π/2 – все эти результаты интуитивно верны и уместны. θ l1l2 (а) (b) Рис. 1.2  Геометрическая иллюстрация расчета отклика линии и угла в круглом окне: (a) прямой край, (b) угол в общем виде. © IET 2005 Из этой формулы можно определить многие свойства оператора, в том числе тот факт, что пиковый сигнал возникает не в самом углу, а в центре окна, используемого для вычисления углового сигнала, хотя смещение уменьшается по мере того, как снижается острота угла. 1.3. Ч асть B. Л оКаЛизация и распозна Вание дВуХмерны Х объе КтоВ 1.3.1. Подход к анализу формы на основе центроидного профиля Двухмерные объекты обычно характеризуются формой их границ. В этом разделе мы рассмотрим, чего можно достичь, отслеживая границы объекта и анализируя полученные профили формы. Среди наиболее распространен- ных типов профилей, используемых для этой цели, выделяется центроидный профиль, в котором граница объекта наносится на карту с использованием полярных координат (r , θ), принимая центроид C границы за начало коор- динат. В случае круга радиуса R центроидный профиль представляет собой пря- мую линию на расстоянии R выше оси θ. На рис. 1.3 представлено поясне- ние, а также показаны два примера разбитых круглых объектов. В случае (a) окружность лишь слегка искривлена, и поэтому ее центроид С остает - ся практически неизменным; следовательно, бóльшая часть центроидного графика остается на расстоянии R выше оси θ. Однако в случае (b) даже та\n--- Страница 45 ---\n44  Кардинальные перемены в области компьютерного зрения часть границы, которая не нарушена и не искажена, находится далеко не на постоянном расстоянии от оси θ: это означает, что объект невозможно узнать по его профилю, хотя в случае (а) нетрудно распознать его как слег - ка поврежденный круг. На самом деле мы уделяем столько внимания этим случаям в основном из-за того факта, что в случае (b) центроид смещается так сильно, что даже неизмененная часть формы не может быть немедлен- но распознана. Конечно, можно было бы попытаться исправить ситуацию, переместив центроид обратно в положение, соответствующее кругу, но это довольно сложная задача: во всяком случае, если исходная фигура не явля- ется кругом, много вычислений будет потрачено впустую до того, как станет понятна истинная природа проблемы. С r r 0 0 3π/2 3π/2 π/2 π/2 2π 2π θ θπ πС¢ (a) (b) Рис. 1.3  Проблемы с дескриптором центроидального профиля: (а) представ- лен круглый объект с небольшим дефектом на его границе; под ним изображен соответствующий центроидный профиль; (b) представлен тот же объект, но на этот раз с грубым дефектом: поскольку центроид смещен в сторону C¢, весь про- филь центроида сильно искажен В целом мы можем заключить, что подход с центроидным профилем не- надежен и не рекомендуется. На самом деле это не означает, что его совсем не следует использовать на практике. Например, на конвейере для сыра или печенья любой предмет, который не распознается сразу по постоянному R-профилю, должен быть немедленно удален с конвейера; затем можно исследовать оставшиеся объекты более тщательно, чтобы убедиться, что их значения R приемлемы и демонстрируют надлежащую степень посто- янства.\n--- Страница 46 ---\nЧасть B. Локализация и распознавание двухмерных объектов  45 робастность и ее знаЧение Не случайно здесь возникла идея робастности1. Она лежит в основе большей части дис - куссий о ценности и эффективности алгоритмов, имеющих прямое отношение к компью- терному зрению. Основная проблема заключается в изменчивости объектов или любых иных сущностей, присущей компьютерным изображениям. Эта изменчивость может воз- никать по совершенно разным причинам: шум, различная форма объектов (даже одного и того же типа), различия в размере или расположении, трещины или дефекты, разное расположение камер и разные режимы просмотра. Кроме того, один объект может быть частично затенен другим или только частично находиться в определенном изображении (что дает эффекты, не отличающиеся от механического повреждения объекта). Хотя хорошо известно, что шум влияет на точность измерения, можно подумать, что он с меньшей вероятностью повлияет на робастность. Однако нам необходимо отличать «обычный» тип шума, который мы можем описать как гауссов шум, от пикового или им- пульсного шума. Последние обычно описываются как выделяющиеся точки или «выбро- сы» в распределении шума. (Напомню, что мы уже видели, как медианный фильтр зна- чительно лучше справляется с выбросами, чем средний фильтр.) Предметом робастной статистики является изучение темы нормальных значений и выбросов, а также то, как лучше всего справляться с различными типами шума. Исследования в этой области лежат в основе оптимизации точности измерения и достоверности интерпретации при наличии выбросов и грубых нарушений внешнего вида объекта. Далее следует отметить, что существуют другие типы графических пред- ставлений границ, которые можно использовать вместо центроидного про- филя. Один из них представляет собой график (s , ψ), а другой – производный профиль (s , κ). Здесь ψ – угол ориентации границы, а κ(s), равный dψ /ds, – локальная функция кривизны. Важно отметить, что эти представления не основаны на положении центроида, следовательно, его положение не нужно вычислять или даже оценивать. Несмотря на это преимущество, все такие представления граничных профилей имеют еще одну существенную проб- лему: если какая-либо часть границы закрыта, искажена или нарушена, срав- нение формы объекта с шаблонами известной формы становится весьма затруднительным из-за разной длины границ. Несмотря на эти проблемы, в подходящих ситуациях метод центроидного профиля имеет определенные преимущества, поскольку он способствует простоте измерения радиусов окружностей, легкости идентификации квад- ратов и других форм с выступающими углами и простому измерению ори- ентации, особенно для формы с выступающими углами. Теперь осталось найти метод, который мог бы заменить метод центроид- ного профиля в тех случаях, когда могут возникать грубые искажения или окклюзии (загораживания одних объектов другими). В поисках такого метода мы переходим к следующему разделу, который знакомит с подходом преоб- разования Хафа. 1 Под робастностью в статистике понимают нечувствительность к различным от - клонениям и неоднородностям в выборке, связанным с теми или иными, в общем случае неизвестными, причинами. © academic.ru.\n--- Страница 47 ---\n46  Кардинальные перемены в области компьютерного зрения 1.3.2. Схемы обнаружения объектов на основе преобразования Хафа В разделе 1.3.1 мы рассмотрели, как круглые объекты могут быть идентифи- цированы по их границам с использованием подхода центроидного профиля к анализу формы. Этот подход оказался ненадежным из-за его неспособно- сти справиться с грубыми искажениями формы и окклюзиями. В этом раз- деле мы покажем, что преобразование Хафа (Hough Transform) обеспечивает прос той, но изящный способ решения данной проблемы. Используемый ме- тод состоит в том, чтобы взять каждую краевую точку на изображении, пере- местить ее внутрь на расстояние R вдоль локальной нормали к краю и со- хранить эту точку в отдельном изображении, называемом пространством параметров: R принимается за ожидаемый радиус кругов, которые должны быть локализованы. Результатом этого будет скопление точек (часто назы- ваемых «голосами») вокруг местоположений центров кругов. Фактически для получения точных оценок местоположений центров необходимо только найти значимые пики в пространстве параметров. Этот процесс проиллюстрирован на рис. 1.4, из которого видно, что метод игнорирует некруглые части границы и идентифицирует только настоящие центры окружностей. Таким образом, подход фокусируется на данных, ко- торые соответствуют выбранной модели, и не обращает внимания на не- релевантные данные, которые в противном случае приводят к значительно- му снижению робастности. Разумеется, данный метод зависит от точности оценки направлений нормалей к краям. К счастью, оператор Собеля способен оценивать ориентацию края с точностью до 1°, и его легко применять. Как показано на рис. 1.5, результаты могут быть весьма впечатляющими. Рис. 1.4  Робастность преобразования Хафа при нахождении центра круглого объекта. Круглая часть границы дает центральные точки-канди- даты, которые фокусируются на истинном центре, тогда как неправиль- ная ломаная граница дает центральные точки-кандидаты в случайных положениях. В данном случае граница примерно совпадает с границей сломанного печенья, показанного на рис. 1.5 Недостаток описанного выше подхода заключается в том, что ему требу - ется заранее известное значение R. Общее решение этой проблемы состоит в использовании трехмерного пространства параметров, в котором третье\n--- Страница 48 ---\nЧасть B. Локализация и распознавание двухмерных объектов  47 измерение представляет возможные значения R, и последующем поиске наи- более значимых пиков в этом пространстве. Однако более простое решение включает в себя накопление результатов для диапазона вероятных значений R в одном и том же двумерном пространстве параметров – процедура, кото- рая приводит к существенной экономии памяти и вычислений (Davies, 1988). На рис. 1.6 показан результат применения этой стратегии, которая работает как с положительными, так и с отрицательными значениями R. С другой стороны, в плоскости с одним параметром информация о радиальном рас - стоянии теряется из-за накопления всех голосов. Следовательно, потребуется дополнительная итерация процедуры для определения радиуса, соответству - ющего местоположению каждого пика. Рис. 1.5  Набор сломанных и перекрывающихся печений, демон- стрирующий надежность метода определения центра. На точность ме- тода указывают черные точки, каждая из которых находится в пределах 1/2 пикселя радиального расстояния от центра. © IFC 1984 Подход с преобразованием Хафа также можно использовать для обнаруже- ния эллипса: два простых метода для этого случая представлены на рис. 1.7. Оба они воплощают непрямой подход, в котором используются пары краевых точек. В то время как метод бисекции диаметра требует значительно меньше вычислений, чем метод хорд и касательных , он более подвержен ложным обнаружениям, например когда два эллипса лежат рядом друг с другом на изображении. Чтобы доказать правильность метода хорд и касательных, укажем на при- менимость этого метода для окружностей, а далее свойство проективности гарантирует, что он также сработает для эллипсов, потому что при ортого- нальной проекции прямые линии проецируются в прямые, средние точки в средние, касательные в касательные, а окружности в эллипсы; кроме того, всегда можно найти такую точку обзора, что окружность можно спроециро- вать на заданный эллипс.\n--- Страница 49 ---\n48  Кардинальные перемены в области компьютерного зрения (а) (b) Рис. 1.6  Одновременное обнаружение объектов с разными радиусами: (a) обнаружение крышки объектива и барашковой гайки, когда предполагается, что радиусы находятся в диапазоне 4–17 пикселей; (b) обнаружение отверстий на том же изображении, когда предполагается, что радиусы попадают в диа- пазон от –26 до –9 пикселей (используются отрицательные радиусы, поскольку отверстия считаются объектами отрицательного контраста): ясно, что на этом изображении мог быть применен меньший диапазон отрицательных радиусов Р2Р1 Т М К (b) (а) Рис. 1.7  Геометрическое представление двух методов обнаружения эллип- сов: (a) в методе бисекции диаметра находят пару точек, для которых ориен- тации ребер антипараллельны. Середины таких пар накапливаются, и получен- ные пики принимаются за центры эллипсов; (b) в методе хорд и касательных касательные в точках P 1 и P 2 пересекаются в точке T, а середина отрезка P 1P2 находится в точке M. Центр эллипса C лежит на полученной линии TM Теперь мы переходим к так называемому обобщенному преобразованию Хафа (generalized Hough transform, GHT), которое использует более прямую процедуру обнаружения эллипса, чем два других метода, описанных выше. Чтобы понять, как обобщается стандартный метод Хафа для локализации объектов произвольной формы, нам сначала нужно выбрать точку локали- зации L в шаблоне идеализированной формы. Затем нам нужно сделать так, чтобы вместо перемещения от краевой точки на фиксированное расстояние\n--- Страница 50 ---\nЧасть B. Локализация и распознавание двухмерных объектов  49 R непосредственно вдоль локальной нормали от края до центра, как в случае с окружностями, мы перемещались на соответствующее переменное расстоя- ние R в переменном направлении φ так, чтобы прийти к L; R и φ теперь являют - ся функциями направления нормали к локальному краю θ (рис. 1.8). В этих условиях голоса будут иметь пик в за- ранее выбранной точке локализации объекта L. Функции R(θ) и φ(θ) могут быть представлены аналитически в компьютерном алгоритме, а для совер- шенно произвольных форм они могут быть сохранены в виде интерполяци- онных таблиц. В любом случае схема основана на очень простом принципе, но при обобщении метода Хафа возникает важное усложнение, потому что мы переходим от изотропной формы (круг) к анизотропной форме, которая может иметь совершенно произвольную ориентацию. Это означает добавление дополнительного измерения в пространство па- раметров (Ballard, 1981). Затем каждая точка края вносит свой вклад в набор голосов в каждой плоскости ориентации в пространстве параметров. На- конец, все пространство параметров просматривается в поисках пиков – наивысших точек, указывающих как на расположение объектов, так и на их ориентацию. Интересно, что GHT может обнаруживать эллипсы, используя одну плоскость в пространстве параметров, за счет применения функции точечной экстраполяции (point spread function, PSF) к каждой краевой точке, которая учитывает все возможные ориентации эллипса: обратите внима- ние, что PSF применяется на некотором расстоянии от краевой точки, чтобы центр PSF мог пройти через центр эллипса (рис. 1.9). Ограниченный объем главы не позволяет представить здесь детали вычислений (например, см. Davies, 2017, глава 11). Рис. 1.9  Использование формы PSF, учитывающей все воз- можные ориентации эллипса. PSF позиционируется серыми вспомогательными линиями так, чтобы она проходила через центр эллипса (черная точка) L Rθ φ Рис. 1.8  Вычисление обобщенного преобразования Хафа\n--- Страница 51 ---\n50  Кардинальные перемены в области компьютерного зрения 1.3.3. Применение преобразования Хафа для обнаружения линий Преобразование Хафа (HT) также может применяться для обнаружения ли- ний. Ранее было отмечено, что лучше избегать обычного уравнения с коэффи- циентом наклона и точкой пересечения вида y = mx + c, потому что для почти вертикальных линий требуются почти бесконечные значения m и c. Вместо этого использовалась «нормальная» (θ , ρ) форма прямой линии (рис. 1.10): ρ = x cos θ + y sin θ. (1.47) Для применения метода в этой форме множество прямых, проходящих через каждую точку P i, представляют в виде множества синусоид в простран- стве (θ , ρ): например, для точки P 1(x1, y1) синусоида имеет уравнение: ρ = x1cos θ + y1sin θ. (1.48) y x 0θρ Рис. 1.10  Нормальная параметризация прямой линии в пространстве (θ, ρ) После накопления голосов в пространстве (θ , ρ) пики указывают на нали- чие линий в исходном изображении. Была проделана большая работа (см., например, Dudani, Luk, 1978) для ограничения погрешностей определения местоположения линии, возника- ющих по разным причинам: шум, дискретизация, эффекты фрагментации линии, эффекты небольшой кривизны линии, сложность оценки точных по- ложений пиков в пространстве параметров. Кроме того, важна проблема локализации продольной линии. Для последнего из этих процессов Дуда- ни и Лук (Dudani, Luk, 1978) разработали метод «ху -группировки», который предусматривал проведение анализа связности для каждой линии. Затем сег - менты линии подлежали объединению, если они разделены промежутками менее ~5 пикселей. Наконец, сегменты короче определенной минимальной длины (также обычно ~5 пикселей) игнорировались как слишком незначи- тельные, чтобы облегчить интерпретацию изображения. В целом мы видим, что все описанные выше формы HT значительно выигры- вают благодаря наличию механизма накопления доказательств (accumulating evidence) с использованием схемы голосования. Этот механизм является источ-\n--- Страница 52 ---\nЧасть B. Локализация и распознавание двухмерных объектов  51 ником высокой робастности метода. Вычислительные процессы, используемые HT, можно описать скорее как индуктивные, а не дедуктивные, поскольку нали- чие пиков приводит к гипотезам о присутствии объектов, которые в принципе должны быть подтверждены другими доказательствами, тогда как дедукция привела бы к немедленному доказательству присутствия объектов. 1.3.4. Использование RANSAC для обнаружения линий RANSAC – это альтернативная схема поиска на основе моделей, которую часто можно использовать вместо HT. Дело в том, что она очень эффективно работает при обнаружении линий, поэтому заслуживает отдельного внимания. Страте- гию поиска можно рассматривать как схему голосования, но она используется иначе, чем в HT. Она выдвигает последовательность гипотез о целевых объек - тах и определяет поддержку каждой из них, подсчитывая, сколько точек дан- ных согласуется с ними в разумных (например, ±3 σ) пределах (см. рис. 1.11). Как и следовало ожидать, для любого потенциального искомого объекта на каждом этапе сохраняются только гипотезы с максимальной поддержкой. Давайте разберем, как RANSAC используется для обнаружения линий. Как и в случае с HT, мы начинаем с применения детектора краев и определения местоположения всех краевых точек на изображении. Как мы увидим, RANSAC лучше всего работает с ограниченным количеством точек, поэтому полезно найти краевые точки, которые являются локальными максимумами градиента интенсивности изображения. Далее, все, что необходимо, чтобы сформули- ровать гипотезу прямой линии, – это взять любую пару граничных точек. Для каждой гипотезы мы проходим по списку N краевых точек, определяя, сколько точек M поддерживают гипотезу. Затем мы берем другие гипотезы (другие пары краевых точек) и на каждом этапе оставляем только ту, которая дает максимальную поддержку M max. Этот процесс показан в лис тинге 1.1. 0 хy Рис. 1.11  Метод RANSAC. Здесь знаки + указывают точки данных, по которым нужно попытаться подогнать линии, а также показаны два экземпляра пар то- чек данных (обозначенных знаками ⊕), через которые проведены гипотетиче- ские линии. Каждая предполагаемая линия имеет область допуска ±t, в преде- лах которой ищется поддержка максимального количества точек данных. Линия с наибольшей поддержкой считается наиболее подходящей\n--- Страница 53 ---\n52  Кардинальные перемены в области компьютерного зрения Листинг 1.1  Базовый алгоритм RANSAC для поиска линии с наибольшей поддержкой. Этот алгоритм возвращает только одну линию; точнее, он возвращает модель линии, которая имеет наибольшую поддержку. Линии с меньшей поддержкой в итоге игнорируются Mmax=0; для всех пар краевых точек { найти уравнение линии, определяемое двумя точками i, j; М = 0; для всех N точек в списке если (точка k находится в пределах порогового расстояния d от линии) M++; если (М > Mmax) { Mmax = М; imax = i; jmax = j; // это гипотеза, имеющая максимальную поддержку на данный момент } } /* если Mmax > 0, (x[imax], y[imax]) и (x[jmax], y[jmax]) будут координатами точек, определяющих линию с наибольшей поддержкой */ Алгоритм в листинге псевдокода 1.1 соответствует поиску центра самого высокого пика в пространстве параметров, как и в случае HT. Чтобы найти все линии на изображении, наиболее очевидной стратегией является следу - ющая: найти первую линию, затем удалить все точки, поддерживающие ее; потом найти следующую линию и устранить все точки, поддерживающие ее; повторять, пока все точки не будут исключены из списка. Процесс может быть записан более компактно в таком виде: повторить { найти линию; удалить поддерживающие точки; } пока не закончатся точки данных; Как сказано выше, RANSAC предполагает довольно значительную вычис - лительную нагрузку, составляющую O(N3), по сравнению с O(N ) для алгорит - ма HT. Следовательно, при использовании RANSAC лучше каким-то образом уменьшить N. Это объясняет, почему полезно сосредоточиться на локальных максимумах, а не использовать полный список краевых точек. Однако в ка- честве альтернативы можно использовать повторную случайную выборку из полного списка до тех пор, пока не будет проверено достаточное количество гипотез, чтобы быть уверенным в том, что обнаружены все значимые линии. К слову, эти идеи отражают первоначальное значение аббревиатуры RANSAC, которая расшифровывается как RANdom SAmpling Consensus – консенсус с произвольными данными, в том смысле, что любая гипотеза должна фор- мировать консенсус с доступными подтверждающими данными (Fischler, Bolles, 1981). Степень уверенности в том, что все значимые линии обнару - жены, можно вычислить как обратную величину риска того, что значимая линия будет пропущена из-за пропуска репрезентативной пары точек, ле- жащих на линии.\n--- Страница 54 ---\nЧасть B. Локализация и распознавание двухмерных объектов  53 Теперь мы можем рассмотреть результаты, полученные путем примене- ния RANSAC к частному случаю поиска прямых линий. В описанном тесте в качестве гипотез использовались пары точек, а все краевые точки пред- ставляли собой локальные максимумы градиента интенсивности. Случай, показанный на рис. 1.12, соответствует обнаружению деревянного бруска в форме икосаэдра. Обратите внимание, что одна линия справа на рис. 1.12а была пропущена, потому что пришлось установить нижний предел уровня поддержки для каждой линии: это было необходимо, потому что ниже этого уровня поддержки количество случайных коллинеарностей резко возраста- ло даже для относительно небольшого числа краевых точек, показанных на рис. 1.12b, что приводит к резкому увеличению числа ложноположительных линий. В целом этот пример показывает, что RANSAC является очень важ - ным претендентом на определение местоположения прямых линий в циф- ровых изображениях. Здесь не обсуждается тот факт, что RANSAC полезен для получения надежной подгонки ко многим другим типам форм как в 2D, так и в 3D. (a) (b) Рис. 1.12  Обнаружение прямых линий с использованием метода RANSAC: (а) исходное изображение в оттенках серого с прямыми краевыми линиями, обнаруженными с использованием метода RANSAC: (b) краевые точки, пере- данные в RANSAC для получения (а): это были локальные максимумы гради- ентов изображения. В (а) пропущены три ребра икосаэдра. Это потому, что они представляют собой края с низким контрастом и низким градиентом интенсив- ности. Фактически RANSAC также упустил четвертый край из-за наличия ниж - него предела уровня поддержки (см. текст выше) Наконец, следует упомянуть, что RANSAC менее, чем HT, подвержен влия- нию алиасинга (ступенчатого искажения) вдоль прямых линий. Это связано с тем, что пики HT, как правило, фрагментируются из-за алиасинга, поэтому наилучшие гипотезы трудно получить без агрессивного сглаживания изобра- жения. Причина, по которой RANSAC выигрывает в этом контексте, заклю- чается в том, что он полагается не на точность отдельных гипотез, а скорее на их количество: стратегия исходит из того, что достаточное количество гипотез можно легко генерировать и столь же легко отбрасывать.\n--- Страница 55 ---\n54  Кардинальные перемены в области компьютерного зрения 1.3.5. Т еоретико-графовый подход к определению положения объекта В этом разделе мы рассмотрим часто встречаемую ситуацию со значитель- ными ограничениями – объекты появляются на горизонтальном рабочем столе или конвейере на известном расстоянии от камеры. Также предполага- ется, что (а) объекты плоские или могут располагаться только в ограничен- ном количестве позиций в трех измерениях, (b) объекты рассматриваются вертикально сверху и что (c) искажения перспективы малы. В подобных ситуациях объекты в принципе могут быть идентифицированы и локали- зованы по очень небольшому количеству точечных признаков. Поскольку считается, что такие признаки не имеют собственной структуры, будет не- возможно однозначно определить положение объекта по одному признаку, хотя положительная идентификация и определение положения были бы возможны с использованием двух признаков, если бы они были различи- мы и если бы было известно их расстояние друг от друга. Если говорить о действительно неразличимых точечных признаках, невозможно устра- нить неоднозначность для всех объектов, не обладающих 180-градусной симметрией вращения. Следовательно, как правило, для идентификации и определения объектов на известном расстоянии требуются как минимум три точечных признака. Очевидно, что шум и другие артефакты, такие как окклюзии, ухудшают ситуацию. Фактически при сопоставлении шаблона то- чек идеализированного объекта с точками, присутствующими на реальном изображении, мы обнаруживаем, что: 1) из-за нескольких экземпляров выбранного типа объекта на изображе- нии могут присутствовать очень много характерных точек; 2) из-за шума или помех от посторонних объектов и структур на заднем плане могут присутствовать лишние точки; 3) некоторые точки, которые должны присутствовать, отсутствуют из-за шума или окклюзии, или из-за дефектов искомого объекта. Эти проблемы означают, что мы должны пытаться сопоставить подмно- жество точек в идеализированном шаблоне с различными подмножест - вами точек на изображении. Если считать, что наборы точек составляют графы с точечными признаками в качестве узлов, задача превращается в математическую проблему изоморфизма подграфов, т. е. нахождения того, какие подграфы в графе изображения изоморфны подграфам идеа- лизированного шаблонного графа. (Изоморфность означает наличие оди- наковой базовой формы и структуры.) Ясно, что схема сопоставления то- чечных признаков будет наиболее успешной, если она находит наиболее вероятную интерпретацию путем поиска решений, обладающих наиболь- шей внутренней согласованностью, т. е. с наибольшим числом совпадений точек на объект. К сожалению, представленная выше схема все еще слишком проста для многих применений, поскольку она недостаточно устойчива к искажениям. В частности, могут возникать оптические (например, перспективные) ис - кажения, сами объекты могут быть деформированы или, опираясь частично\n--- Страница 56 ---\nЧасть B. Локализация и распознавание двухмерных объектов  55 на другие объекты, могут принять нестандартное положение, в силу чего расстояния между признаками могут быть не совсем такими, как ожидалось. Эти факторы означают, что должен существовать некоторый допуск в отно- шении расстояний между парами признаков. Ясно, что искажения создают дополнительную нагрузку на технику сопоставления точек и делают еще более необходимым поиск решений с максимально возможной внутренней устойчивостью. Поэтому при обнаружении и идентификации объектов сле- дует учитывать как можно больше признаков. Для этого предназначен метод максимальной клики (maximal clique). Для начала на исходном изображении идентифицируется как можно больше признаков: обычно они нумеруются в порядке появления на теле- визионном растре. Затем числа должны быть сопоставлены с буквами, со- ответствующими признакам идеализированного объекта. Систематиче- ским способом достижения этого является построение графа соответствия (match graph), или, как его еще называют, графа ассоциации (association graph), в котором узлы представляют соотнесения признаков, а дуги, со- единяющие узлы, представляют попарную совместимость между соотнесе- ниями. Чтобы найти наилучшее соответствие, необходимо найти области графа соответствия, где перекрестные связи максимальны. Для этого в гра- фе соответствий ищутся клики. Клика – это полный подграф, т. е. такой, у ко- торого все пары узлов соединены дугами. Однако предыдущие аргументы указывают на то, что если одна клика полностью включена в другую клику, вполне вероятно, что более крупная клика представляет собой лучшее со- впадение – и действительно, максимальные клики можно рассматривать как ведущие к наиболее надежным совпадениям между наблюдаемым изо- бражением и моделью объекта. На рис. 1.13а показана ситуация для общего четырехугольника, его график соответствия показан на рис. 1.13б. В этом случае есть 16 возможных соот - несений признаков, 12 допустимых совместимостей и 7 максимальных клик. Если происходит перекрытие признака, оно (взятое само по себе) уменьшит количество возможных отнесений признаков, а также количество допусти- мых совместимостей: кроме того, количество максимальных клик и размер наибольшей максимальной клики будут уменьшены. С другой стороны, шум или беспорядок могут добавить ошибочные признаки. Если последние на- ходятся на произвольном расстоянии от существующих признаков, то коли- чество возможных отнесений признаков будет увеличено, но совместимости в графе соответствий больше не будет, так они привнесут лишь тривиальную дополнительную сложность. Однако если дополнительные признаки появля- ются на допустимом расстоянии от существующих признаков, это добавит дополнительную совместимость в граф соответствия и сделает его более нагруженным для анализа. В случае, показанном на рис. 1.14, возникают оба типа осложнений – окклюзия и дополнительный признак: теперь имеется 8 парных отнесений и 6 максимальных клик, что в целом несколько меньше, чем в исходном случае на рис. 1.13. Однако важным фактором является то, что наибольшая максимальная клика по-прежнему указывает на наиболее вероятную интерпретацию изображения, поэтому метод по своей природе очень надежен.\n--- Страница 57 ---\n56  Кардинальные перемены в области компьютерного зрения D D4A1A2 A3 B3D3 C3 C2 B4C1D2 C4A4 B2B1 D14A 1B 2 C 3(a) (b) (c) Рис. 1.13  Задача сопоставления для общего четырехугольника: (a) базовая маркировка модели (слева) и изображения (справа); (b) граф сопоставления; (c) размещение голосов в пространстве параметров: маленькие кружки обо- значают положение отверстий, точки обозначают отдельные голоса, а большая точка показывает положение основного пика. © АВК 1988 D D4A1A2 A3 B3D3 C3 C2 B4C1D2 C4A4 B2B1 D14A 1B 2 C 3(a) (b) (c) Рис. 1.14  Сопоставление при перекрытии одного объекта и добавлении дру- гого: (a) базовая маркировка модели (слева) и изображения (справа); (b) график соответствия; (c) размещение голосов в пространстве параметров (обозначе- ния, как на рис. 1.13) На рис. 1.15а показана пара печений, которые должны быть обнаружены по их «докерным» отверстиям, – эта стратегия выгодна, поскольку она по- зволяет очень точно определить местонахождение продукта до детально- го осмотра. Отверстия, обнаруженные простой процедурой сопоставления\n--- Страница 58 ---\nЧасть B. Локализация и распознавание двухмерных объектов  57 с шаблоном, показаны на рис. 1.15а: используемый шаблон довольно мал, и в результате процедура работает достаточно быстро, но не может найти все отверстия; кроме того, она может давать ложные срабатывания. Сле - довательно, для анализа данных о местоположении отверстия необходимо использовать «интеллектуальный» алгоритм. Анализ данных в приведенном выше примере дает две нетривиальные максимальные клики, каждая из которых правильно соответствует одному из двух печений на изображении. (a) (b) Рис. 1.15  Поиск печений и выяснение их расположения: (a) два печенья с крестиками, указывающими на результат применения простой процедуры об- наружения отверстий; (b) два печенья, надежно обнаруженных GHT по данным отверстий из (a): изолированные маленькие крестики указывают позиции оди- ночных голосов. © АВК 1988 1.3.6. Использование обобщенного преобразования Хафа для экономии вычислений В предыдущих примерах проверка того, какие подграфы являются макси- мальными кликами, является простой задачей. К сожалению, время выпол- нения оптимального алгоритма максимальной клики ограничено не мно- гочленом от M (для графа соответствия, содержащего максимальные клики до M узлов), а гораздо более быстро меняющейся функцией. В частности, известно, что задача поиска максимальных клик является NP-полной и вре- мя ее выполнения растет экспоненциально. Таким образом, каким бы ни было время выполнения для значений M примерно до 6, оно обычно будет в 100 раз больше для значений M примерно до 10 и еще в 100 раз больше для M больше 14. Далее мы покажем, как в качестве альтернативы подходу максимальной клики можно использовать обобщенное преобразование Хафа (GHT). Чтобы применить GHT, мы сначала перечисляем все признаки, а затем накаплива- ем голоса в пространстве параметров в каждой возможной позиции точки локализации L, соответствующей каждой паре признаков (рис. 1.16). Чтобы проделать это, необходимо просто использовать межэлементное расстояние\n--- Страница 59 ---\n58  Кардинальные перемены в области компьютерного зрения в качестве параметра поиска в R-таблице GHT. Для неразличимых точечных признаков это означает, что должны быть две записи для положения L для каждого значения расстояния между признаками. Процедура иллюстриру - ется примером обобщенного четырехугольника на рис. 1.13: это приводит к 7 пикам в пространстве параметров, веса которых равны 6, 1, 1, 1, 1, 1, 1 (см. рис. 1.13c). Аналогичная ситуация возникает и для рис. 1.14. Внимательное изучение рис. 1.13 и 1.14 показывает, что каждый пик в пространстве пара- метров соответствует максимальной клике в графе соответствия. Действи- тельно, между ними существует взаимно однозначное отношение, поэтому все правильные совместимости вносят вклад как в большую максимальную клику, так и в большой пик в пространстве параметров. Эта стратегия по- прежнему применима, даже когда возникают окклюзии или присутствуют дополнительные признаки (см. рис. 1.14). Рис. 1.16  Метод определения местоположения L по парам позиций призна- ков: каждая пара точек признаков дает две возможные позиции голосования в пространстве параметров, когда объекты не имеют симметрии. При наличии симметрии определенные пары признаков могут дать до 4 позиций для голосо- вания: это подтверждается при внимательном изучении рис. 1.15b Наконец, снова рассмотрим пример на рис. 1.15а, на этот раз получив решение с по мощью GHT. На рис. 1.15b показаны положения центров объ- ектов-кандидатов, найденные с по мощью GHT. Маленькие изолированные крестики указывают позиции одиночных голосов, а те, что очень близки к двум большим крестикам, приводят к пикам голосования весов 10 и 6 в этих соответствующих позициях. Следовательно, местоположение объекта явля- ется точным и надежным, как и требуется (Davies, 1988b). Теперь сравним вычислительные требования подходов максимальной клики и GHT к определению расположения объекта. Для простоты представь- те себе изображение, которое содержит только один полностью видимый пример объекта, обладающего n признаками, и что мы пытаемся распознать его, ища все возможные попарные совместимости. Для объекта, обладающего n признаками, граф соответствий содержит n2 узлов (т. е. возможных назначений), и существует n2C2 = n2(n2–1)/2 воз- можных попарных совместимостей, которые необходимо проверить при по- строении графа. Объем вычислений на этом этапе анализа составляет O(n4). К этому следует добавить вычислительную стоимость нахождения макси-\n--- Страница 60 ---\nЧасть B. Локализация и распознавание двухмерных объектов  59 мальных клик. Поскольку задача является NP-полной, вычислительная на- грузка растет со скоростью, близкой к экспоненциальной по n2. Теперь рассмотрим затраты на GHT при поиске объектов с по мощью по- парной совместимости. Как мы видели, общая высота всех пиков в про- странстве параметров равна количеству попарных совместимостей в графе соответствий. Следовательно, вычислительная нагрузка имеет тот же поря- док, O(n4). Далее возникает задача локализации всех пиков в пространстве параметров. Для изображения N×N необходимо посетить только N2 точек в пространстве параметров, а вычислительная нагрузка составляет O( N2), хотя постоянное ведение записи о максимальном местоположении во время голосования может значительно уменьшить ее (Davies, 1988b). 1.3.7. Подходы на основе частей В то время как подходы к определению местоположения объектов, описан- ные выше, как правило, рассчитаны на поиск соответствия объектов вполне определенным геометрическим моделям, существуют и совершенно другие подходы, которые заключаются в использовании таких методов, как дефор- мируемые модели (deformable models). Эти подходы учитывают различия во внешнем виде, возникающие в результате изменений освещения, точки об- зора и таких свойств, как форма и цвет. В качестве наиболее важных приме- ров можно назвать поиск лиц или пешеходов в дорожных сценах. К методам этой категории относятся жесткие шаблоны (rigid templates; Dalal, Triggs, 2005), пакет признаков (bag-of-features; Zhang et al., 2007), деформируемые шаблоны (например, Cootes, Taylor, 2001) и модели на основе частей (part- based models; например, Amit, Trouvé, 2007; Leibe et al., 2008). Модели дефор- мируемых частей обучаются с использованием наборов частей, расположен- ных в деформируемых конфигурациях. Этот подход вышел на первый план в 2010 г., когда было показано (Felzenszwalb et al., 2010), что это приводит к эффективным, точным и современным результатам на сложных наборах данных. Модели деформируемых частей (deformable parts models, DPM) основаны на идее, что объекты можно рассматривать как наборы частей. Таким образом, для обнаружения таких объектов, как лица, необходимо только определить местонахождение частей и изучить их взаимосвязь. Это может быть вы- полнено путем определения частей и их ограничивающих рамок, а затем внесения предложений по объединению их в более крупные ограничиваю- щие рамки, представляющие объекты. По сути, после того как были найдены ограничивающие объекты рамки, эти области защищаются от дальнейшего анализа немаксимальным подавлением. На практике это означает, что каж - дой потенциальной ограничивающей рамке присваивается оценка, сохраня- ется наивысшая оценка и пропускаются те рамки, которые перекрывают уже существующую ограничивающую рамку, на критический процент, например 50 %. Этот очень успешный подход достиг самых современных результатов в тестах PASCAL VOC 2006, 2007 и 2008 (Everingham et al., 2006; 2007; 2008) и «зарекомендовал себя как стандарт де-факто для обнаружения общих объ-\n--- Страница 61 ---\n60  Кардинальные перемены в области компьютерного зрения ектов» (Mathias et al., 2014). Матиас с коллегами очень тщательно протести- ровали подход DPM и показали, что он может обеспечить максимальную производительность при распознавании лиц. Интересно, что подход DPM позволял обнаруживать явно трехмерные объекты, но без необходимости непосредственного учета их трехмерной геометрии, что достигается путем достаточно разнообразного обуче ния на соответствующих типах объектов. Еще одна полезная возможность заклю- чается в том, что этот подход также может быть очень эффективным для обнаружения сочлененных объектов. Подход DPM очень важен, поскольку он лег в основу подходов глубокого обуче ния с еще более высокими рейтингами производительности (напри- мер, Bai et al., 2016) (подробнее об этом будет сказано в части F про методы глубокого обуче ния). 1.4. Ч асть C. распо Ложение треХмерны Х объе КтоВ и Важность неизменности 1.4.1. Введение в трехмерное зрение В предыдущих частях этой главы обычно предполагалось, что объекты по существу плоские и рассматриваются таким образом, что существует только три степени свободы, а именно две, связанные с положением, и еще одна, связанная с ориентацией. Хотя этого подхода достаточно для решения мно- гих полезных задач компьютерного зрения, он не подходит для интерпрета- ции большинства сцен на открытом воздухе или в помещении, или даже для помощи в довольно простых задачах по роботизированной сборке и осмотру. За последние несколько десятилетий было разработано и подкреплено экс - периментами значительное количество теорий, раскрывающих механизмы детального понимания сцен, состоящих из реальных трехмерных объектов. В целом речь идет о попытках интерпретировать сцены, в которых объ- екты могут появляться в совершенно произвольных положениях и ориен- тациях, что соответствует шести степеням свободы. Интерпретация таких сцен и вывод параметров перемещения и ориентации произвольных на- боров объектов требуют значительного объема вычислений – отчасти из- за естественной неоднозначности при выводе трехмерной информации из двухмерных изображений. Однако для работы с трехмерным зрением раз- работано множество подходов, и для успешной интерпретации трехмерных сцен часто требуются тонкие их комбинации. Прежде чем двигаться дальше, приведем уравнение изображения общей точки ( X, Y, Z) в сцене при так называемой перспективной проекции; оно дает точку изображения: (x, y) = (f X/Z, f Y/Z), (1.49) где f – фокусное расстояние используемого объектива.\n--- Страница 62 ---\nЧасть C. Расположение трехмерных объектов и важность неизменности  61 Теперь рассмотрим принцип работы зрительной системы человека – бинокулярное зрение. Система камер, которая используется для этой цели, изобра жена на рис. 1.17. В этом геометрическом представлении общая точка обозначена на двух изображениях как (x 1, y1) и (x 2, y2). Как правило, две оп- тические системы не обязательно должны иметь параллельные оптические оси и будут иметь ненулевой угол схождения (вергенции). Однако часто для простоты используется случай нулевой вергенции; мы тоже им воспользуем- ся. Обратите внимание, что два набора координат, соответствующих общей точке (X , Y, Z) в сцене, будут различаться, поскольку базовая линия b между оптическими осями вызывает относительное смещение, или «несоответ - ствие», точек на двух изображениях. С2(X, Y, Z) (x1, y1) (x2, y2) С1 Рис. 1.17  Стереоизображение с использованием двух объективов. Оси оптических систем параллельны, т. е. между оптическими осями нет схождения Далее, при подходящем выборе оси Z на серединном перпендикуляре к ба- зовой линии b , получаем два уравнения: x1 = (X + b/2)f/Z; (1.50) x2 = (X – b/2)f/Z. (1.51) Вычисление расхождения D = x1 – x2 позволяет сразу получить глубину Z : Z = bf/(x 1 – x2). (1.52) Хотя это кажется идеальным способом работы с трехмерным зрением, существует фундаментальная проблема – наличие подтверждения того, что обе точки в стереопаре действительно соответствуют одной и той же точке исходной сцены. Заметим также, что для получения высокой точности опре- деления глубины требуется большая базовая линия b: к сожалению, с увели- чением b соответствие между изображениями уменьшается, поэтому найти\n--- Страница 63 ---\n62  Кардинальные перемены в области компьютерного зрения совпадающие точки становится труднее: это связано с тем, что два изобра- жения становятся все более разными и трудно сопоставимыми. Стандартным способом решения упомянутой выше проблемы стереосоот - ветствия является метод эпиполярной линии, показанный на рис. 1.18. Чтобы понять его суть, представьте, что мы определили местонахождение харак - терной точки на первом изображении и что мы отмечаем все возможные точки в поле объекта, которые могли ее породить. Мы получим линию точек на разной глубине сцены, и при просмотре во второй плоскости изображения можно построить геометрическое место точек в этой плоскости. Это гео- метрическое место (на альтернативном изображении) представляет собой эпиполярную линию, соответствующую исходной точке изображения. Если мы теперь будем искать сходную отличительную точку на втором изображе- нии только вдоль эпиполярной линии, шансы найти правильное совпадение значительно возрастут. Этот метод не только сокращает количество вычисле- ний, необходимых для поиска соответствующих точек, но также значительно снижает количество ложных срабатываний. В простой схеме на рис. 1.17 все эпиполярные линии параллельны оси x, хотя это применимо только для слу - чая нулевой сходимости. Отметим, что проблема соответствия значительно усложняется фактом наличия в сцене точек, которые порождают точки на одном изображении, но не на другом: это может возникнуть из-за окклюзии или грубого искажения одной из точек. Таким образом, необходимо искать непротиворечивые множества решений в виде непрерывных поверхностей объектов в сцене. С2P1 E2С1 Рис. 1.18  Схематическая иллюстрация метода эпиполярных линий. Точка P 1 в одной плоскости изображения может возникнуть из любой линии точек сцены и может появиться в альтернативной плоскости изображения в любой точке на так называемой эпиполярной линии E 2\n--- Страница 64 ---\nЧасть C. Расположение трехмерных объектов и важность неизменности  63 Трудности, вызванные проблемой соответствия, привели к появлению ряда альтернативных подходов. Одним из наиболее известных является «форма из затенения» – выяснение того, как меняется ориентация поверх - ности, путем анализа наблюдаемой яркости поверхности. Хотя этот подход хорошо себя проявил, он основан на предположении об отражательной спо- собности и текстуре поверхностей и о том, как они меняются в зависимости от ориентации (а) поверхности и (b) источника освещения. Он также требует применения сложных итерационных алгоритмов, но мы не имеем возмож - ности раскрыть здесь эту тему. Точно так же за рамки данной книги выходит метод «фотометрического стереозрения», который подразумевает поочеред- ное освещение сцен отдельными источниками света и анализ полученных изображений. Подход «форма из текстуры» позволяет анализировать детали ориентации поверхности путем изучения относительных областей текстурных элемен- тов. Однако это специализированный метод, который применяется не очень часто. Подход «структурированного освещения» основан на проецировании световых полос или других схем световых пятен или сеток на поле объек - та. Этот подход чрезвычайно широко используется для проверки и сборки объектов на заводских линиях, хотя нельзя сказать, что он широко исполь- зуется в других областях, таких как наблюдение. Поэтому он тоже является специализированным, а не общим методом измерения формы трехмерных объектов. Следует отметить, что все эти подходы, кроме последнего, ведут к созда- нию карт ориентации поверхности, а не к измерению глубины объекта как таковой, поэтому расчет глубины и формы поверхности должен быть выве- ден из необработанных измерений ориентации. В целом описанные выше методы используют различные средства для оценки глубины во всех местах сцены и, следовательно, способны отображать трехмерные поверхности с достаточной степенью детализации. Однако они не дают никакого понимания того, что представляют собой эти поверхности. В некоторых ситуациях может быть ясно, что определенные плоские поверх - ности являются частями фона, например пол и стены комнаты, но в общем случае отдельные объекты не могут быть идентифицированы с абсолютной уверенностью. Действительно, объекты имеют тенденцию сливаться друг с другом и с фоном, поэтому необходимы специальные методы для сегмента- ции трехмерной «карты пространства» и, наконец, распознавания объектов, т. е. предоставления подробной информации об их положении и ориента- ции. Очевидно, что получение карты глубины трехмерного объекта приводит к его распознаванию не ближе, чем карта границ, такая как центроидальный профиль, к распознаванию двумерного объекта: для выполнения распозна- вания необходимо разработать специальные средства. К сожалению, в слу - чае трехмерных объектов эта задача значительно сложнее по сравнению с двухмерными. Например, хотя преобразование Хафа, в принципе, можно применить в обоих случаях, в трехмерном варианте оно намного сложнее и требует больше вычислений, чем в двумерном, поскольку количество сво- бодных параметров обычно увеличивается с 3 до 6 для статической формы без неизвестных параметров формы – имеется три степени свободы для\n--- Страница 65 ---\n64  Кардинальные перемены в области компьютерного зрения перемещения и три для вращения. Заметим также, что вычислительная слож - ность обычно зависит не от количества степеней свободы, а от показателя степени, равного этому количеству. Следует упомянуть еще один момент: за последние несколько лет были разработаны датчики, которые обеспечивают выходные данные в формате RGB-D (цвет и глубина): они предоставляют информацию о глубине на ос - нове оптического «времени пролета» – времени, за которое импульс света проходит расстояние до поверхности объекта и обратно. Лидары широко распространены, но стоят дорого и лучше работают на больших расстояниях, в то время как матричные времяпролетные камеры лучше работают на ко- ротких расстояниях и обычно используют генерируемые лазером световые импульсы с разницей в несколько наносекунд. Эти продвинутые современ- ные устройства помогают решить проблему стереосоответствия. Тем не ме- нее они не устраняют проблему интерпретации трехмерных поверхностей, обладающих большим количеством степеней свободы, с которыми прихо- дится бороться алгоритмам идентификации объектов. Напротив, они лишь подчеркивают значимость этой наиболее существенной из оставшихся задач. Учитывая, что основным источником проблем является вычислительная сложность, было бы естественно исследовать каждую карту глубины на на- личие существенных признаков и соответствующим образом интерпрети- ровать сцены: как только у нас будут описания объектов, основанные на относительно небольшом количестве существенных признаков, а не на объ- емных описаниях поверхностей, появится надежда на достижение быстрой и надежной идентификации. Мы рассмотрим эту возможность далее в сле- дующем разделе. 1.4.2. Неоднозначность положения при перспективной проекции В этом разделе мы определяем слабую и полную перспективу и стремимся понять проблему n-точечной перспективы (perspective n-point, PnP) – задачу нахождения положения объектов по n признакам при различных формах перспективы. Полноперспективная проекция (full perspective projection, FPP) – это ос - новная и наиболее общая форма проецирования объекта в изображение, приводящая, например, к тому, что параллельные линии больше не кажутся параллельными, а большинство фигур кажутся искаженными – круги даже выглядят как эллипсы. Слабая перспективная проекция (weak perspective pro- jection, WPP) – это форма перспективной проекции, которая используется для удаленных объектов, для которых DZ ≪ Z. Ее можно рассматривать как «масштабированную ортогональную проекцию» – ортогональная проекция представляет собой тип проекции, который возник бы, если бы объекты прое цировались ортогонально параллельными лучами на плоскость изобра- жения, в то время как масштабирование учитывает уменьшение видимого размера объекта.\n--- Страница 66 ---\nЧасть C. Расположение трехмерных объектов и важность неизменности  65 (a) (c)(b) Рис. 1.19  Перспективная инверсия самолета. Здесь силуэт самолета (а) вы- рисовывается на фоне неба и выглядит так же, как на (b). На (c) показаны две плоскости P и Q, в которых мог бы лежать самолет, относительно направления наблюдения D: R – плоскость отражения, объединяющая плоскости P и Q Поскольку WPP не искажает формы объектов (например, задняя часть про- волочного куба имеет тот же размер и форму, что и его передняя часть), его проще использовать для моделирования процесса визуализации. Однако эта форма проекции настолько проста, что может привести к неоднозначности при просмотре плоских объектов. Это показано на рис. 1.19, на котором вид- но, что двухмерному виду удаленного самолета могут соответствовать две ориентации, поскольку из одного вида определяется только косинус наклона плоскости α. Интересно, что когда α отличен от нуля, FPP вносит дополни- тельное искажение в форму самолета, и тогда можно определить истинную ориентацию. В табл. 1.1 показана вся полнота ситуации, когда плоские объекты обна- руживаются по одному или нескольким их признакам. Эта таблица отражает общую проблему PnP , упомянутую выше. Из таблицы видно, что в компла- нарном случае (в котором все n признаков объекта компланарны) WPP никог - да не дает однозначной интерпретации, тогда как FPP дает, но только когда n больше 3. Причина, по которой n должно быть больше 3, для того чтобы FPP давала однозначный результат, заключается в том, что она включает в себя так много параметров, что трех признаков недостаточно для разрешения ситуации; однако когда присутствуют 4 или более признаков, может быть разрешена полная ситуация и устранена неоднозначность. Но почему WPP не может добиться этого? Причина в том, что в WPP расположение любых\n--- Страница 67 ---\n66  Кардинальные перемены в области компьютерного зрения дополнительных признаков (выше 3) может быть выведено из первых трех, поэтому они не могут дать никакой дополнительной информации: следова- тельно, WPP не может привести к устранению неоднозначности. Таблица 1.1. Неоднозначности при оценке положения объекта по точечным признакам. В этой таблице сведены количества решений, которые будут получены при оценке положения жесткого объекта по точечным признакам, расположенным на одном изображении. Предполагается, что n точечных признаков обнаружены и идентифицированы правильно и в правильном порядке. Столбцы WPP и FPP означают слабую перспективную проекцию и полную перспективную проекцию соответственно. Верхняя половина таблицы применяется, когда все n точек лежат в одной плоскости; нижняя половина таблицы применяется, когда n точек не компланарны. Заметим, что при n £ 3 результаты строго применимы только в компланарном случае. Однако две верхние строки в нижней половине таблицы сохранены для удобства сравнения Расположение точек n WPP FPP Компланарное 2 ∞ ∞ 3 2 1 4 2 1 5 2 1 6 2 1 Некомпланарное 2 ∞ ∞ 3 2 4 4 1 2 5 1 2 6 1 1 Обратите внимание, что когда n равно 1 или 2, существует по крайней мере одна вращательная степень свободы, поэтому существует бесконечное количество решений. На данный момент мы рассмотрели все возможности в верхней половине таблицы, где задействованы компланарные объекты. Далее мы обратимся к некомпланарному случаю, рассмотренному в нижней половине таблицы. Случаи, когда n £ 3, уже рассматривались в верхней по- ловине таблицы, поэтому случай некомпланарности включает только случаи, где n > 3. Давайте теперь рассмотрим, что происходит, когда 4 признака просмат - риваются в WPP . Взяв по очереди два признака, мы можем создать две пло- скости. Когда просматриваются три признака на каждой из этих плоскостей, они генерируют два решения с разными значениями α, и существует только одно согласованное решение. Этот вывод завершает наше толкование за- писей WPP в табл. 1.2 и, в частности, некомпланарных случаев. Ситуация хорошо иллюстрируется на рис. 1.20 (а–c). Обратите внимание, однако, на спасительную ситуацию, показанную на рис. 1.20d, где видно, как объект, обладающий особой симметрией, может быть подвержен остаточной не- однозначности.\n--- Страница 68 ---\nЧасть C. Расположение трехмерных объектов и важность неизменности  67 (a) (с)(b) (d) Рис. 1.20  Определение положения для 4 точек, просматриваемых при сла- бой перспективной проекции. На (а) показан объект, содержащий четыре не- компланарные точки, наблюдаемый при проекции со слабой перспективой, (b) показывает вид сбоку этого объекта. Если бы первые три точки (соединенные серыми линиями без стрелок) рассматривались отдельно, инверсия перспек - тивы привела бы ко второй интерпретации (с). Однако четвертый пункт дает дополнительную информацию о положении, которая допускает только одну об- щую интерпретацию. Это не относится к объекту, содержащему дополнительную симметрию, как в (d), поскольку его отражение будет идентично исходному виду (не показано) Чтобы полностью понять ситуацию, в которой при FPP просматривается более 3 некомпланарных точек, нам необходимо учитывать тот факт, что существует 11 параметров калибровки камеры (см. раздел 1.4.10), которые необходимо определить из 12 линейных однородных уравнений. Это озна- чает, что для вычисления всех 11 параметров в общем случае потребуется не менее 6 некомпланарных точек (включая 2×6 координат изображения). Таким образом, хотя FPP усложняет ситуацию, она также предоставляет боль- ше информации, с по мощью которой в конечном итоге можно разрешить неоднозначность. Наконец, следует подчеркнуть, что приведенные выше рассуждения пред- полагают, что все соответствия между признаками объекта и изображения известны, т. е. что n точечных признаков обнаруживаются и идентифици- руются правильно и в правильном порядке. Если это не так, то количество возможных решений может существенно возрасти, учитывая количество возможных перестановок весьма небольшого числа точек. В качестве одного из способов ограничения этой проблемы можно отметить, что копланар- ные точки, рассматриваемые в слабой или полной перспективной проекции, всегда появляются в одном и том же циклическом порядке. Если учитывать возможные искажения объекта, то проверка этого утверждения нетривиаль- на. Впрочем, если выпуклый многоугольник можно провести через точки, циклический порядок вокруг его границы не изменится при проецировании, потому что плоская выпуклость является инвариантом проецирования. Од- нако при некомпланарном расположении точек объекта их воспринимаемая\n--- Страница 69 ---\n68  Кардинальные перемены в области компьютерного зрения на изображении структура может перестраиваться почти случайным обра- зом: это означает, что для некомпланарных точек придется учитывать зна- чительно большее количество перестановок точек, чем для компланарных. Еще одно соображение заключается в том, что характерные точки, исполь- зуемые для распознавания объектов, не должны быть коллинеарными или иметь какой-либо особый шаблон и должны быть описаны как находящиеся в общем положении: в противном случае существует риск того, что некото- рые неоднозначности не будут устранены, как указано в табл. 1.2 (в основном потому, что при попытке определить параметры калибровки камеры возни- кают необратимые уравнения). 1.4.3. Инварианты как помощь в трехмерном распознавании Инварианты важны для распознавания объектов как в 2D, так и в 3D. Ос - новная идея инварианта состоит в том, чтобы найти некоторый параметр или параметры, которые не изменяются между различными экземплярами или положениями объекта, и использовать их для облегчения идентифика- ции объекта. Как мы увидим, перспектива значительно усложняет задачу в общем трехмерном случае. Сначала рассмотрим плоский объект, наблюдаемый строго сверху каме- рой, оптическая ось которой перпендикулярна плоскости, на которой ле - жит объект. Рассмотрим два точечных признака объекта, таких как углы или небольшие отверстия. Если мы измерим расстояние между признаками в изобра жении, оно будет действовать как инвариант в том смысле, что: 1) имеет величину, не зависящую от параметров перемещения и ориен- тации объекта; 2) будет неизменным для разных объектов одного типа; 3) в общем случае будет отличаться от соответствующих параметров дру - гих объектов, лежащих на этой же плоскости. Таким образом, измерение расстояния обеспечивает определенное качест - во поиска или индексирования, которое в идеале однозначно идентифици- рует объект, хотя потребуется дальнейший анализ, чтобы полностью опре- делить его местоположение и установить его ориентацию. Следовательно, межэлементное расстояние имеет все требования 2D-инварианта. Конечно, здесь мы игнорируем неточность измерения из-за неадекватного простран- ственного разрешения, шума, искажений объектива и т. д.; кроме того, иг - норируются эффекты частичной окклюзии или поломки. Очевидно, что есть предел возможностей одной инвариантной меры. В частности, она не справ- ляется с вариациями масштаба объекта. Приближение камеры к плоскости объекта и связанная с этим перефокусировка полностью меняют ситуацию, и все значения инварианта расстояния, находящиеся в таблице индексации объектов, должны быть изменены, а старые значения проигнорированы. Однако эта проблема легко преодолима. Все, что нам нужно сделать, – это взять отношения расстояний. Для этого требуется идентифицировать как\n--- Страница 70 ---\nЧасть C. Расположение трехмерных объектов и важность неизменности  69 минимум 3 точечных признака на изображении и измерить 2 расстояния между признаками. Если мы назовем эти два расстояния d1 и d2, то отноше- ние d1/d2 будет действовать как инвариант, не зависящий от масштаба, т. е. мы сможем идентифицировать объекты с по мощью одной операции индек - сации независимо от их двумерного перемещения, ориентации, видимого размера или масштаба. Рис. 1.21  Перспективное преобразование (perspective transformation) четы- рех коллинеарных точек. На этом рисунке показаны четыре коллинеарные точ- ки (P 1, P2, P3, P4) и их преобразование (Q 1, Q2, Q3, Q4), аналогичное тому, которое производится системой формирования изображения с оптическим центром C В целом основная идея использования инвариантов состоит в том, что- бы получить математические измерения конфигураций признаков объекта, которые не зависят от используемой точки обзора или системы координат: действительно, ввиду очевидных сложностей, связанных с перспективной проекцией, независимость точки зрения является решающим фактором в 3D-распознавании объектов и требует использования инвариантов пер- спективы. 1.4.4. Кросс-коэффициенты: концепция «отношения коэффициентов» Было бы очень полезно, если бы мы могли расширить изложенные выше идеи, чтобы облегчить идентификацию наблюдаемых объектов при общих трехмерных преобразованиях. В самом деле, очевидный вопрос заключается в том, дает ли нам знание отношений коэффициентов (ratio of ratios) рас - стояний инварианты, которые обеспечивают подходящие обобщения. Ответ\n--- Страница 71 ---\n70  Кардинальные перемены в области компьютерного зрения заключается в том, что отношения коэффициентов обеспечивают полезные дополнительные инварианты. Сейчас мы это увидим. Чтобы определить подходящие отношения коэффициентов расстояний, мы начнем с изучения набора из 4 коллинеарных точек на объекте. На рис. 1.21 показан такой набор из 4 точек (P 1, P2, P3, P4) и их преобразование (Q1, Q 2, Q 3, Q 4), например производимое системой формирования изобра- жения с оптическим центром C (c , d). Выбрав подходящие пары наклонных осей, мы можем выразить координаты двух наборов точек в следующем виде: (х1, 0), (х 2, 0), (х 3, 0), (х 4, 0); (0, у 1), (0, у 2), (0, у 3), (0, у 4). Взяв точки P i, Q i, (i = 1, …, 4), можно записать отношение CQ i : P Q i как в виде c /–x i, так и в виде (d – yi)/yi. Приравнивание этих величин сразу дает: (1.53) Взяв подходящие разности, исключающие все абсолютные положения, и выполнив преобразования, мы в конечном итоге получаем формулу (1.54) Эта формула инвариантного сложного отношения (cross ratio) подтверж - дает возможность построения параметра, инвариантного к перспективным преобразованиям. В частности, 4 коллинеарные точки, рассматриваемые с любой точки зрения, дают одинаковое значение сложного отношения, определяемое как: (1.55) В дальнейшем мы будем обозначать это конкретное сложное отношение как κ. Обратите внимание, что существуют 4! = 24 возможных способа рас - положения 4 коллинеарных точек на прямой линии, и, следовательно, для любого объекта возможны 24 значения сложного отношения. Однако не все они различны, и на самом деле существует только 6 различных значений: легко показать, что это κ, 1 – κ, κ/(κ – 1) и их обратные значения. Интересно, что нумерация точек в обратном порядке (что соответствовало бы просмотру линии с другой стороны) оставляет сложное отношение неизменным. Тем не менее неудобно, что один и тот же инвариант имеет 6 различных прояв- лений, так как это означает, что необходимо просмотреть 6 различных зна- чений индекса, прежде чем можно будет идентифицировать класс объекта. С другой стороны, если точки маркируются по порядку вдоль каждой линии, а не случайным образом, можно обойти эту ситуацию. Пока нам удалось получить только один проективный инвариант, и это со- ответствует довольно простому случаю четырех коллинеарных точек. Полез-\n--- Страница 72 ---\nЧасть C. Расположение трехмерных объектов и важность неизменности  71 ность данной меры значительно возрастает, если заметить, что 4 коллинеар- ные точки, взятые вместе с другой точкой, определяют пучок параллельных компланарных линий, проходящих через последнюю точку. Ясно, что мы мо- жем присвоить этому пучку прямых уникальное сложное отношение, равное поперечному отношению коллинеарных точек на любой линии, проходящей через них. Фактически, рассмотрев углы между различными линиями и при- менив правило синусов 4 раза, мы получаем следующую формулу: (1.56) Таким образом, сложное инвариантное отношение зависит только от углов пучка линий. Мы можем расширить эту концепцию до 4 параллельных плоскостей, так как параллельные линии могут быть спроецированы на 4 параллельные пло- скости после определения отдельной оси параллелизма. Поскольку таких осей бесконечно много, существует бесконечно много способов выбора на- боров плоскостей. Таким образом, исходный простой результат для коллине- арных точек можно распространить на гораздо более общий случай. В заключение отметим, что мы начали с попытки обобщить случай че- тырех коллинеарных точек, но в результате сначала нашли двойственную си туацию, в которой точки становятся линиями, также описываемыми слож - ным отношением, а затем нашли расширение, в котором сложным отноше- нием описываются плоскости. Теперь вернемся к случаю с четырьмя кол- линеарными точками и посмотрим, как мы можем расширить его другими способами. 1.4.5. Инварианты для неколлинеарных точек Прежде всего давайте представим, что не все точки коллинеарны: в част - ности, предположим, что одна точка не коллинеарна другим трем. Если это так, то для расчета сложного отношения недостаточно информации. Однако если доступна еще одна компланарная точка, мы можем провести вообра- жаемую линию между неколлинеарными точками, чтобы пересечь линию, проходящую через другие три точки: тогда это позволит вычислить сложное отношение (рис. 1.22а). Тем не менее это далеко от общего решения задачи нахождения характеристики множества неколлинеарных точек. Мы могли бы спросить, сколько точечных признаков общего положения на плоскости потребуется для вычисления инварианта. На самом деле ответ – 5, так как тот факт, что мы можем составить сложное отношение из углов между 4 ли- ниями, немедленно означает, что построение пучка из 4 прямых из 5 точек определяет инвариант сложного отношения (рис. 1.22b). Хотя значение этого сложного отношения обеспечивает необходимое ус - ловие для совпадения между двумя наборами из 5 общих копланарных точек, это может быть случайным совпадением, поскольку условие зависит только от относительных направлений между различными точками и контрольной\n--- Страница 73 ---\n72  Кардинальные перемены в области компьютерного зрения точкой, т. е. любая из нереферентных точек определяется только относитель- но линии, на которой она лежит. Ясно, что два сложных отношения, образо- ванных взятием двух опорных точек, будут однозначно определять направ- ления всех оставшихся точек (рис. 1.22c). Интересно, что хотя в результате такого рода процедуры можно получить не менее пяти сложных отношений, оказывается, что существует только два функционально независимых слож - ных отношения – в основном потому, что положение любой точки определя- ется, когда известно ее направление относительно двух других точек. (а) (b) (с) Рис. 1.22  Расчет инвариантов для набора неколлинеарных точек. На (а) по- казано, как добавление пятой точки к набору из четырех точек, одна из ко- торых не коллинеарна остальным, позволяет вычислить сложное отношение; (b) показывает, как вычисление может быть распространено на любой набор неколлинеарных точек; также показана дополнительная (серая) точка, которую однократное сложное отношение не может отличить от других точек на той же линии. На (c) показано, как любая неспособность однозначно идентифици- ровать точку может быть преодолена путем вычисления сложного отношения второго пучка, полученного из пяти исходных точек Заметим, что на рис. 1.22 отсутствует еще один интересный случай – ситуа- ция с двумя точками и двумя прямыми. Построив линию, соединяющую две точки, и производя ее до пересечения с двумя линиями, мы получим 4 точ- ки на одной линии; таким образом, конфигурация характеризуется одним\n--- Страница 74 ---\nЧасть C. Расположение трехмерных объектов и важность неизменности  73 сложным отношением. Заметьте также, что две линии можно продлять до тех пор, пока они не соединятся, и дальнейшие линии могут быть построены из пересечения по двум точкам: это дает пучок линий, характеризующийся одним сложным отношением: последнее должно иметь то же значение, что и вычисленное для 4 коллинеарных точек. Далее мы рассмотрим проблему нахождения плоскости объекта в прак - тических ситуациях, например в случае собственного движения (egomotion), включая управление транспортным средством. Предположим, что от одного кадра к другому можно наблюдать набор из 4 коллинеарных точек. Если точки находятся в одной плоскости, то сложное отношение будет оставаться постоянным, но если одна из них приподнята над плоскостью земли (как в случае с неровностью на дороге), то сложное отношение будет меняться от кадра к кадру. Взяв большее количество точек, можно путем исключения определить, какие из них находятся на плоскости земли, а какие нет: об- ратите внимание, что все это возможно без какой-либо калибровки камеры, что является основным преимуществом использования проективных инва- риантов. Впрочем, существует потенциальная проблема с нерелевантными плоскостями, такими как вертикальные грани зданий. Проверка сложного отношения очень устойчива к точке зрения и положению и просто уста- навливает, компланарны ли проверяемые точки. Но, используя достаточно большое количество независимых наборов точек, можно отличить одну плос - кость от другой. 1.4.6. Обнаружение точки схода В этом разделе мы рассмотрим точки схода (vanishing point, VP) и спосо- бы их обнаружения. Простая привязка к точкам схода дает человеческому мозгу глубокое понимание изображения и в немалой степени помогает ему глобально интерпретировать происходящее на изображении (рис. 1.23). Сле- довательно, точка схода может служить отправной точкой и для машинной интерпретации изображения. Это особенно ценно в ситуации с реальными трехмерными изображениями, воплощающими все сложности полноперс - пективной проекции, поэтому исследователи потратили много усилий на поиск методов обнаружения и использования точек схода. Обнаружение точек схода обычно проводят в два этапа: сначала локали- зуют все прямые линии на изображении, затем находят, какие из прямых проходят через общие точки, причем последние интерпретируются как точки схода. Поиск линий с по мощью преобразования Хафа не должен вызывать затруднений, хотя края текстуры иногда мешают точному и обоснованно- му расположению линий. По сути, для обнаружения точек схода требуется второе преобразование Хафа, в котором целые линии накапливаются в про- странстве параметров, что приводит к четко определенным пикам (соот - ветствующим точкам схода, причем несколько линий перекрываются. На практике линии, которые являются объектами голосования, должны быть продлены, чтобы охватить все возможные местоположения точек схода. Эта процедура адекватна, когда точки схода располагаются в пределах исходного\n--- Страница 75 ---\n74  Кардинальные перемены в области компьютерного зрения пространства изображения, но часто бывает так, что они будут вне исходного изображения (рис. 1.23) и могут даже находиться в бесконечности. Это оз- начает, что не получится использовать пространство параметров, подобное изображению, даже если оно выходит за пределы исходного пространства изображения. Другая проблема заключается в том, что для удаленных точек схода пики в пространстве параметров будут разбросаны на значительном расстоянии, поэтому чувствительность обнаружения будет слабой, а точность определения местоположения будет низкой. Рис. 1.23  Положение точки схода. На этом рисунке кажется, что параллель- ные линии на арках сходятся в точке V за пределами изображения. В общем случае точки схода могут лежать на любом расстоянии и даже находиться в бес - конечности К счастью, Маги и Аггарвал (Magee, Aggarwal, 1984) нашли улучшенное представление для поиска точек схода. Они построили единичную сферу G, называемую сферой Гаусса, вокруг центра проекции камеры и использова- ли G вместо расширенной плоскости изображения в качестве пространства параметров. В этом представлении точки схода появляются на конечных расстояниях даже в тех случаях, когда в противном случае они казались бы находящимися в бесконечности. Чтобы этот метод работал, должно быть однозначное соответствие между точками в двух представлениях, и это явно верно (заметим, что задняя половина гауссовой сферы не используется). Однако представление в виде гауссовой сферы не лишено проблем: в част -\n--- Страница 76 ---\nЧасть C. Расположение трехмерных объектов и важность неизменности  75 ности, многие нерелевантные голоса будут получены линиями, которые не параллельны в реальном трехмерном пространстве (часто лишь небольшое подмножество линий на изображении проходит через точку схода). Чтобы решить эту проблему, пары линий рассматриваются по очереди, а их точки пересечения накапливаются в качестве голосов только в том случае, если счи- тается, что линии каждой пары происходят из параллельных линий в трех - мерном пространстве (например, они должны иметь совместимые градиенты в изображении). Эта процедура резко ограничивает как количество голосов, записанных в пространстве параметров, так и количество нерелевантных пиков. Тем не менее общая стоимость по-прежнему значительна, посколь- ку пропорциональна количеству пар линий. Таким образом, если имеется N линий, число пар равно NC2 = ½N (N – 1), поэтому результат равен O(N2). Вышеупомянутая процедура важна, поскольку она обеспечивает надежные средства для выполнения поиска точек схождения и эффективного исключе- ния изолированных линий и помех изображения. В случае движущегося ро- бота или другой системы, оснащенной компьютерным зрением, выявление соответствия между точками схода, видимыми на последовательных изо- бражениях, приводит к значительно большей уверенности в интерпретации каждого изображения. 1.4.7. Подробнее о точках схода Одним из преимуществ инварианта сложного отношения является то, что он может появляться во многих ситуациях и в каждом случае давать еще один точный результат. Интересным примером является сценарий, когда дорога или тротуар имеет каменные плиты, границы которых хорошо очерчены и легко измеримы. Их можно использовать для оценки положения точки схода на плоскости земли. Представьте, что вы смотрите на каменные плиты под углом сверху, а камера или глаза выровнены горизонтально. Тогда у нас есть геометрическая структура, аналогичная рис. 1.24, где точки O, H 1, H 2 лежат на плоскости земли, а O, V 1, V2, V3 находятся в плоскости изображения. Если мы возьмем C в качестве центра проекции, то сложное отношение, образованное точками O, V 1, V 2, V 3, должно иметь такое же значение, что и сложное отношение, образованное точками O, H 1, H 2 и бесконечностью в горизонтальном направлении. Предположим, что OH 1 и H 1H2 имеют из- вестные длины a и b; приравнивание значений сложного отношения дает: (1.57) (Обратите внимание, что на рис. 1.24 значения y отсчитываются от O, а не от V 3.) Это позволяет нам найти y3. Принимая a = b (как, например, в случае с каменными плитами), мы находим, что: (1.58)\n--- Страница 77 ---\n76  Кардинальные перемены в области компьютерного зрения Найдя y3, мы вычислили направление точки схода независимо от того, го- ризонтальна ли плоскость земли, на которой она лежит, и горизонтальна ли ось камеры. Заметим, что это доказательство на самом деле не предполагает, что точки V 1, V2, V3 находятся вертикально над началом координат или что линия OH 1H2 горизонтальна; мы лишь полагаем, что эти точки лежат на двух компланарных прямых и что C находится в той же плоскости. Рис. 1.24  Схема нахождения линии схода по известной паре интервалов: С – центр проекции, VL – направление линии схода, параллельное плоскости земли OH 1H2. Хотя плоскость камеры OV 1V2V3 нарисована перпендикулярно плоскости земли, это не обязательно для успешной работы алгоритма (см. текст выше) 1.4.8. Промежуточный итог: значение инвариантов Разделы 1.4.2–1.4.6 были посвящены тому, чтобы дать некоторое представ- ление о важном понятии инвариантов и их применении в распознавании изображений. Тема получает значительное развитие, когда рассматриваются отношения коэффициентов расстояний, и эта идея естественным образом приводит к сложному инвариантному отношению. Хотя его первоначальное применение заключается в распознавании расстояний между точками на линии, оно непосредственно обобщается на угловые расстояния для пучков линий, а также на угловое расстояние между плоскостями. Дальнейшим раз- витием идеи является разработка инвариантов, которые могут описывать\n--- Страница 78 ---\nЧасть C. Расположение трехмерных объектов и важность неизменности  77 наборы неколлинеарных точек, и двух сложных отношений достаточно, что- бы охарактеризовать набор из 5 неколлинеарных точек на плоскости. Существует много других теорем и типов инвариантов, но из-за недо- статка места мы вынуждены ограничиться лишь их упоминанием. В качест - ве развития примеров точек и линий, обсуждавшихся выше, были созданы инварианты, включающие кривые второго порядка (коники, conic): коника и две компланарные некасательные прямые, коника и две компланарные точки, две компланарные коники. В целом ценность инвариантов заключа- ется в выполнении эффективных с вычислительной точки зрения проверок того, могут ли точки или другие признаки принадлежать конкретным объек - там. Кроме того, они достигают этого без необходимости калибровки камеры или знания точки обзора камеры (хотя существует неявное предположение, что камера является евклидовой). 1.4.9. Преобразование изображения для калибровки камеры Когда изображения получаются из трехмерных сцен, точное положение и ориентация камеры часто неизвестны, и необходимо связать их с неко- торой глобальной системой отсчета. Это особенно важно, если необходимо производить точные измерения объектов по их изображениям, например в приложениях визуального инспектирования. С другой стороны, иногда можно обойтись без такой подробной информации – как в случае стацио- нарной охранной системы обнаружения злоумышленников или системы подсчета автомобилей на автомагистрали. Есть и более сложные случаи, например когда камеры можно вращать или перемещать на манипулято- ре робота или исследуемые объекты могут свободно перемещаться в про- странстве. В таких случаях главной задачей становится «внешняя», а также «внутренняя» калибровка камеры (полное объяснение этих терминов см. в разделе 1.4.11). Прежде чем мы сможем рассмотреть калибровку камеры, нам нужно де- тально разобрать преобразования, которые могут происходить между ис - ходными мировыми точками1 и формированием конечного изображения. В частности, мы рассматриваем повороты и перемещения точек объекта относительно глобальной системы отсчета. После поворота на угол θ вокруг оси Z (рис. 1.25) координаты общей точки (X , Y) меняются на: X¢ = X cos θ – Y sin θ; (1.59) Y¢ = X sin θ + Y cos θ. (1.60) Далее мы обобщаем этот результат на трехмерное пространство и выра- жаем его как матрицу поворота θ вокруг оси Z : 1 Точка пространства событий. – Прим. перев.\n--- Страница 79 ---\n78  Кардинальные перемены в области компьютерного зрения (1.61) Аналогичные матрицы применяются для поворотов ψ вокруг оси X и ϕ вокруг оси Y. Применяя последовательности таких поворотов, мы получаем следующий общий результат, выражающий произвольное трехмерное вра- щение R : (1.62) Обратите внимание, что матрица вращения R не является полностью об- щей: она ортогональна и, таким образом, обладает тем свойством, что R–1 = RT. Y¢ Х¢ θ Х 0(Х¢, Y¢)Y Рис. 1.25  Эффект вращения θ вокруг начала координат В отличие от вращения, перенос на расстояние (T 1, T2, T3) определяется следующим уравнением: (1.63) которое не выражается через мультипликативную матрицу 3×3. Чтобы объ- единить повороты и переносы в общую мультипликативную формулу, мы должны использовать однородные координаты. Для этого матрицы должны быть увеличены до 4×4, а требуемое преобразование должно иметь вид:\n--- Страница 80 ---\nЧасть C. Расположение трехмерных объектов и важность неизменности  79 (1.64) Эта форма является достаточно общей, чтобы включать масштабирование по размеру объекта, а также преобразования в виде сдвига и наклона. Во всех рассмотренных выше случаях можно заметить, что нижняя строка обобщенной матрицы перемещений является избыточной. На самом деле мы можем найти хорошее применение этому ряду в некоторых других ти- пах преобразования. Особый интерес в этом контексте представляет случай перспективной проекции. В соответствии с разделом 1.4.1 уравнения для проекции точек объекта в точки изображения имеют вид: х = f X/Z; (1.65) у = f Y/Z; (1.66) z = f. (1.67) Чтобы включить перспективную проекцию в приведенные выше формулы, нам нужно изучить преобразование однородных координат: (1.68) Ключом к пониманию этого преобразования является то, что деление на четвертую координату дает требуемые значения преобразованных декарто- вых координат ( f X/Z, f Y/Z, f). Давайте теперь присмотримся к этому результату. Во-первых, мы нашли матричное преобразование 4×4, которое работает с однородными четырех - мерными координатами. Они не соответствуют напрямую реальным коор- динатам, но из них можно вычислить реальные трехмерные координаты, разделив первые три на четвертую однородную координату. Таким образом, однородные координаты произвольны в том смысле, что все они могут быть умножены на один и тот же постоянный множитель без каких-либо измене- ний в окончательной интерпретации. Преимуществом использования однородных координат является удобство использования единой мультипликативной матрицы для любого преобра- зования, несмотря на то что перспективные преобразования по своей сути нелинейны: таким образом, довольно сложное нелинейное преобразование может быть сведено к более простому линейному преобразованию. Это упро- щает компьютерный расчет преобразований координат объекта и другие вы - числения, например для калибровки камеры (см. ниже). Заметим также, что почти каждое преобразование можно обратить, обратив соответствующую\n--- Страница 81 ---\n80  Кардинальные перемены в области компьютерного зрения однородную матрицу преобразования. Исключением является преобразова- ние перспективы, для которого фиксированное значение z приводит к тому, что Z просто неизвестно, а X, Y известны только относительно значения Z (отсюда вытекает необходимость бинокулярного зрения или других средств определения глубины сцены). 1.4.10. Калибровка камеры Выше мы рассмотрели, как однородные системы координат образуют удоб- ное линейное матричное представление 4×4 для трехмерных преобразова- ний, включая перемещение и вращение твердого тела, а также нежестких операций, включая масштабирование, наклон и перспективную проекцию. В этом последнем случае неявно предполагалось, что системы координат камеры и мира идентичны, поскольку координаты изображения были вы- ражены в одной и той же системе отсчета. Однако в общем случае объекты, видимые камерой, будут иметь положения, которые могут быть известны в мировых координатах, но которые не будут известны априори в коорди- натах камеры, поскольку камера в общем случае будет установлена в про- извольном положении и будет «смотреть» в произвольном направлении. Следовательно, система камеры должна быть откалибрована, прежде чем изображения можно будет использовать для практических приложений, та- ких как роботизированная сборка или размещение предметов. Полезный подход состоит в том, чтобы предположить существование некого обобщен- ного преобразования между мировыми координатами и изображением, ви- димым камерой при перспективной проекции, и разместить на изображении различные калибровочные точки, которые были размещены в известных местах сцены. При наличии достаточного количества таких точек должна появиться возможность вычислить параметры преобразования, а затем все точки изображения могут быть точно интерпретированы до тех пор, пока не потребуется повторная калибровка. В дальнейшем мы обнаружим, что существует два типа калибровки ка- меры: первый – это внешняя калибровка (extrinsic calibration), при которой положение камеры определяется относительно мировых координат через ее внешние параметры; вторая – внутренняя калибровка (intrinsic calibration), при которой положение изображения (и пикселя) определяется в зависимо- сти от внутренних параметров камеры. Важными факторами, которые мы должны обсудить, являются количество внешних и внутренних параметров и их геометрическое значение. Прежде всего нам нужно записать математическую формулу в общем виде, используя общее однородное преобразование G , которое принимает вид: (1.69)\n--- Страница 82 ---\nЧасть C. Расположение трехмерных объектов и важность неизменности  81 Обратите внимание, что окончательные декартовы координаты, появляю- щиеся на изображении, равны (x , y, z) = (x, y, f), и они вычисляются из первых трех однородных координат путем деления на четвертую: x = XH/H = (G 11X + G12Y + G13Z + G14)/(G 41X + G42Y + G43Z + G44); (1.70) y = YH/H = (G 21X + G22Y + G23Z + G24)/(G 41X + G42Y + G43Z + G44); (1.71) z = ZH/H = (G 31X + G32Y + G33Z + G34)/(G 41X + G42Y + G43Z + G44). (1.72) Однако, поскольку мы знаем z, нет смысла определять параметры G31, G32, G33, G34. Следовательно, мы можем перейти к нахождению остальных пара- мет ров. На самом деле, поскольку имеют смысл только отношения однород- ных координат, необходимо вычислять лишь отношения значений Gij, и обыч- но G44 принимают за единицу: остается определить только 11 параметров. Перемножая первые два уравнения и выполняя преобразования, получаем: G11X + G12Y + G13Z + G14 – x(G41X + G42Y + G43Z) = x; (1.73) G21X + G22Y + G23Z + G24 – y(G41X + G42Y + G43Z) = y. (1.74) Понимание того факта, что единственная мировая точка (X , Y, Z), которая, как известно, соответствует точке изображения (x , y), дает нам два уравнения приведенной выше формы; требуется минимум 6 таких точек, чтобы обес - печить значения для всех 11 параметров Gij. Важным фактором является то, что мировые точки, используемые для расчета, должны приводить к неза- висимым уравнениям, поэтому важно, чтобы они не были компланарными. Точнее, должно быть не менее 6 точек, никакие четыре из которых не лежат в одной плоскости. Однако дополнительные точки полезны тем, что приво- дят к переопределению параметров и повышают точность их вычисления. Нет никаких причин, по которым дополнительные точки не должны лежать в одной плоскости с существующими точками: действительно, обычный под- ход состоит в повороте куба таким образом, чтобы были видны три его грани, причем каждая грань имеет паттерн из квадратов с 30–40 легко различимы- ми признаками угла. Для вычисления 11 параметров можно использовать метод наименьших квадратов. Во-первых, 2n уравнений (для n точек) должны быть выражены в матричной форме: Ag = ξ, (1.75) где A – матрица коэффициентов 2n ×11, которая перемножается с G-матрицей, теперь имеющей вид g = (G 11G12G13G14G21G22G23G24G41G42G43)T, (1.76) а ξ представляет собой 2n -элементный вектор-столбец координат изображе- ния. Псевдообратное решение имеет вид: g = А†ξ, (1.77)\n--- Страница 83 ---\n82  Кардинальные перемены в области компьютерного зрения где А† = (АТА)–1АТ. (1.78) 1.4.11. Внутренние и внешние параметры На этом этапе полезно более подробно рассмотреть общее преобразование, ведущее к калибровке камеры. Когда мы калибруем камеру, мы на самом деле пытаемся совместить камеру и мировые системы координат. Первый шаг – переместить начало мировой системы координат в начало системы коорди- нат камеры. Второй шаг – повернуть мировую систему координат, пока ее оси не совпадут с осями системы координат камеры. Третий шаг – смещение плоскости изображения вбок до полного совпадения двух систем координат (этот шаг необходим, поскольку изначально неизвестно, какая точка миро- вой системы координат соответствует главной точке изображения). Во время этого процесса следует помнить об одном важном моменте. Если координаты камеры заданы как C, то сдвиг T, необходимый на первом шаге, будет равен –C. Точно так же требуемые повороты будут обратными тем, которые соответствуют фактическим ориентациям камеры. Причина этих разворотов в том, что (например) вращение объекта (в данном случае каме- ры) вперед дает тот же эффект, что и вращение осей назад. Таким образом, все операции должны выполняться с аргументами, обратными указанным выше в разделе 1.4.1. Таким образом, полное преобразование для калибров- ки камеры будет следующим: (1.79) где матрица P учитывает преобразование перспективы, необходимое для формирования изображения. На самом деле обычно преобразования P и L группируются вместе и называются преобразованиями внутренней камеры, которые включают внутренние параметры камеры, в то время как R и T бе- рутся вместе как преобразования внешней камеры, соответствующие внеш- ним параметрам камеры. Следовательно: (1.80) В матрице для Gвнутр мы предположили, что исходная матрица переноса T перемещает центр проекции камеры в правильное положение, так что зна- чение t 3 можно сделать равным нулю, оставляя матрицу 3×3.\n--- Страница 84 ---\nЧасть C. Расположение трехмерных объектов и важность неизменности  83 Хотя приведенная выше трактовка дает хорошее представление о скрытом значении G, она не является общей, поскольку мы до сих пор не включали параметры масштабирования и перекоса во внутреннюю матрицу. На самом деле обобщенная форма G внутр выглядит так: (1.81) Потенциально Gвнутр должна включать преобразования для исправления (1) ошибок масштабирования, (2) ошибок переноса, (3) ошибок наклона дат - чика, (4) ошибок сдвига датчика, (5) неизвестной ориентации датчика в плос - кости изображения. Очевидно, что ошибки переноса исправляются путем корректировки t1 и t 2. Все остальные настройки связаны со значениями под- матрицы 2×2, содержащей параметры s 1, s2, b1, b2. Однако обратите внимание, что применение этой матрицы выполняет вращение в плоскости изображения сразу после того, как Gнаруж выполнила вращение в мировых координатах, и разделить два вращения практически невозможно. Это объясняет, почему теперь у нас есть в общей сложности 6 внешних и 6 внутренних параметров – всего 12, а не ожидаемые 11. В ре- зультате лучше исключить пункт 5 из приведенного выше списка внутренних переносов и отнести его к внешним параметрам. Поскольку вращательная составляющая в Gвнутр была исключена, b1 и b2 теперь должны быть равны, а внутренние параметры будут следующими: s1, s2, b, t1, t2. Обратите внима- ние, что коэффициент 1/f обеспечивает масштабирование, которое нельзя отделить от других коэффициентов масштабирования во время калибровки камеры без специального (то есть отдельного) измерения f. Таким образом, у нас есть в общей сложности 6 параметров от Gнаруж и 5 параметров от Gвнутр : всего 11, что равно числу, указанному в предыдущем разделе. 1.4.12. Многоракурсное зрение В течение 1990-х гг. был достигнут значительный прогресс в трехмерном зрении путем изучения того, какую информацию можно извлечь из изо- бражений с некалиброванных камер, рассматривающих мир с разных ра- курсов. На первый взгляд, если вспомнить об усилиях, которые мы предпри- няли в предыдущих разделах этой главы, чтобы понять, как именно следует калибровать камеры, это может показаться бессмысленным. Тем не менее в изучении многоракурсного зрения (multiple view vision) есть значительная потенциальная выгода – не в последнюю очередь потому, что нам доступ- ны тысячи часов видео, снятых некалиброванными камерами, в том числе применяемых в видеонаблюдении и в киноиндустрии. В таких случаях не- обходимо максимально использовать имеющийся материал. Однако потреб- ность намного шире. Существует множество ситуаций, в которых параметры камеры могут изменяться из-за колебаний температуры или из-за того, что настройки масштабирования или фокусировки были скорректированы; оче-\n--- Страница 85 ---\n84  Кардинальные перемены в области компьютерного зрения видно, что практически невозможно по каждому поводу перекалибровывать камеру с использованием точно изготовленных тестовых объектов. Наконец, если используется несколько камер, каждую придется калибровать отдельно, а результаты сравнивать, чтобы свести к минимуму ошибку комбинирова- ния. Гораздо лучше исследовать систему в целом и калибровать ее на реаль- ных просматриваемых сценах. На самом деле мы уже встречали некоторые аспекты этого подхода в виде инвариантов, последовательно получаемых одной камерой. Например, если просматривается серия из 4 коллинеарных точек и проверяется их попереч- ное соотношение, будет обнаружено, что оно остается постоянным, по мере того как камера движется вперед, меняет ориентацию или рассматривает точки все более наклонно – до тех пор, пока все они остаются в пределах поля зрения. В этом случае все, что требуется для выполнения распознавания и поддержания осведомленности об объекте, – это некалиброванная, но не искажающая камера. Чтобы понять, как можно интерпретировать изображения в более широ- ком смысле, используя несколько видов – будь то с одной и той же камеры, перемещенной в разные места, или с нескольких камер с перекрывающи- мися видами мира, – нам нужно вернуться к основам и более тщательно изучить такие понятия, как бинокулярное зрение и эпиполярные ограни- чения. В частности, будут задействованы две важные матрицы – существен- ная (essential matrix) и фундаментальная (fundamental matrix). Мы начнем с существенной матрицы, а затем обобщим эту идею на фундаментальную. Но сначала нам нужно рассмотреть геометрию системы двух камер с общим ракурсом. 1.4.13. Обобщенная геометрия стереозрения В разделе 1.4.1 мы рассмотрели проблему стереосоответствия и уже упрос - тили задачу, выбрав две камеры, плоскости изображения которых были не только параллельны, но и находились в одной плоскости. Этот подход сделал геометрию восприятия глубины особенно простой, но никак не использовал возможности зрительной системы человека (human visual system, HVS) иметь ненулевой угол расхождения между двумя изображениями. Здесь мы обобщаем ситуацию, чтобы охватить возможность несоответ - ствия в сочетании с существенным расхождением. На рис. 1.26 показана из- мененная геометрическая схема. Сначала обратите внимание, что наблюде- ние реальной точки P сцены дает точки P 1 и P 2 на двух изображениях; что P 1 может соответствовать любой точке эпиполярной линии E 2 на изображении 2; и точно так же эта точка P 2 может соответствовать любой точке эпиполяр- ной линии E 1 на изображении 1. В самом деле, так называемая эпиполярная плоскость P – это плоскость, содержащая P и точки проекций C 1 и C 2 двух ка- мер: эпиполярные линии (раздел 1.4.1), таким образом, являются прямыми линиями, по которым эта плоскость пересекает две плоскости изображения. Кроме того, линия, соединяющая C 1 и C 2, пересекает плоскости изображения в так называемых эпиполюсах (epipole) e 1 и e 2: их можно рассматривать как\n--- Страница 86 ---\nЧасть C. Расположение трехмерных объектов и важность неизменности  85 изображения альтернативных точек проекции камеры. Обратите внимание, что все эпиполярные плоскости проходят через точки C 1, C 2 и e 1, e2: это озна чает, что все эпиполярные линии на двух изображениях проходят через соответствующие эпиполюса. Рис. 1.26  Обобщенное изображение сцены, наблюдаемой с двух точек зре- ния. В этом случае имеется существенная вергенция. Все эпиполярные линии на левом изображении проходят через эпиполюс e 1: из них показана только линия E1. То же самое можно сказать и о правом изображении 1.4.14. Существенная матрица В этом разделе мы начнем с векторов P1, P2, направленных из C 1, C2 в P , а так - же вектора C, исходящего из C 1 в C 2. Вычитание векторов дает: Р2 = Р1 – С. (1.82) Мы также знаем, что P1, P2 и C компланарны, и условие компланарности следующее: P2.C × P 1 = 0. (1.83) Чтобы пойти дальше, нам нужно связать векторы P1 и P2, когда они вы- ражены относительно их собственных систем отсчета. Если мы возьмем эти векторы как определенные в системе отсчета C 1, мы теперь повторно выра- зим P2 в его собственной (C 2) системе отсчета, применяя перенос C и поворот координат, выраженный в виде ортогональной матрицы R. Это приводит к следующему уравнению: P¢2 = RP2 = R(P1 – C), (1.84)\n--- Страница 87 ---\n86  Кардинальные перемены в области компьютерного зрения так что P2 = R–1P¢2 = RTP¢2. (1.85) Подстановка в условие компланарности дает: (RTP¢2).C × P 1 = 0. (1.86) На этом этапе полезно заменить обозначение векторного произведения, используя C × для обозначения кососимметричной матрицы C ×, где (1.87) В то же время мы следим за правильной матричной формулировкой всех векторов, соответствующим образом транспонируя. Теперь мы находим, что: (RTP¢2)TC×P1 = 0; (1.88) ∴ P¢2TRC×P1 = 0. (1.89) Наконец, мы получаем формальное представление существенной матри- цы: P¢2TEP1 = 0, (1.90) где существенная матрица может быть найдена как Е = RC×. (1.91) Уравнение (1.90) действительно является искомым результатом: оно вы- ражает отношение между наблюдаемыми положениями одной и той же точки в системе отсчета двух камер. Кроме того, оно сразу приводит к формулам для эпиполярных линий. Чтобы убедиться в этом, сначала обратите внима- ние, что координаты пикселя в кадре камеры C 1: p1 = (f1/Z1)P1, (1.92) в то время как они же в кадре камеры C 2 (и выраженном в членах этой си- стемы отсчета): p¢2 = (f2/Z2)P¢2. (1.93) Исключая P1 и P¢2 и отбрасывая штрих (поскольку в перспективных плос - костях изображения чисел 1 и 2 достаточно для однозначного указания ко- ординат), мы находим: p2TEp1 = 0, (1.94) так как Z 1, Z2 и f 1, f2 можно сократить.\n--- Страница 88 ---\nЧасть C. Расположение трехмерных объектов и важность неизменности  87 Заметим теперь, что представления p2TE = l1T и l 2 = Ep1 приводят нас к сле- дующим соотношениям: p1Tl1 = 0; (1.95) p2Tl2 = 0. (1.96) Это означает, что l2 = Ep1 и l1 = ETp2 являются эпиполярными линиями, соответствующими точкам p 1 и p 2 соответственно. 1.4.15. Фундаментальная матрица Обратите внимание, что в последней части основного вычисления матрицы мы неявно предполагали, что камеры правильно откалиброваны. В частно- сти, p1 и p2 являются скорректированными (откалиброванными) координата- ми пикселя изображения. Однако нам необходимо работать с неоткалибро- ванными изображениями, используя необработанные измерения координат пикселей – в силу причин, указанных в разделе 1.4.12. Применяя внутренние матрицы камеры G1, G2 к калиброванным координатам изображения (раз- дел 1.4.10), мы получаем необработанные координаты изображения: q1 = G1p1; (1.97) q2 = G2p2. (1.98) На самом деле нам здесь нужно идти в обратном направлении, поэтому воспользуемся обратными уравнениями: p1 = G1–1q1; (1.99) p2 = G2–1q2. (1.100) Подставив значения p1 и p2 в уравнение (1.94), находим искомое уравне- ние, связывающее необработанные координаты пикселя: q2T(G2–1)TEG 1–1q1 = 0, (1.101) что может быть выражено как q2TFq1 = 0, (1.102) где F = (G 2–1)TEG 1–1. (1.103) Матрица F называется фундаментальной. Поскольку она включает в себя всю информацию, которая потребуется для калибровки камер, она содержит боль- ше свободных параметров, чем существенная матрица. Однако в других отно- шениях две матрицы предназначены для передачи одной и той же базовой ин- формации, что подтверждается сходством между уравнениями (1.90) и (1.102).\n--- Страница 89 ---\n88  Кардинальные перемены в области компьютерного зрения 1.4.16. Свойства существенной и фундаментальной матриц Далее мы рассмотрим композицию существенной и фундаментальной мат - риц. В частности, обратите внимание, что C× является множителем E, а также, косвенно, F. На самом деле они однородны по C×, поэтому масштаб C не будет иметь значения для двух матричных уравнений (1.90) и (1.102), важно только направление C: масштабы E и F несущественны, и поэтому важны только от - носительные значения их коэффициентов. Это означает, что в E и F имеется не более 8 независимых коэффициентов. Фактически в случае F их только 7, так как C × кососимметрична, и это гарантирует, что она имеет ранг 2, а не ранг 3 – свойство, которое передается F. Аналогичные рассуждения при- менимы к E, но более низкая сложность E означает, что она имеет только 5 свободных параметров. В последнем случае легко понять, что они из себя представляют: они возникают из исходных 3 параметров перемещения (C ) и 3 параметров вращения (R ), за вычетом одного параметра, соответствую- щего масштабу. В этом контексте обратите внимание, что если C возникает в результате переноса одной камеры, то одна и та же существенная матрица будет резуль- татом любого масштаба C: на самом деле имеет значение только направле- ние C, и те же самые эпиполярные линии будут результатом продолжающе- гося движения в одном и том же направлении. Фактически в этом случае мы можем интерпретировать эпиполюсы как очаги расширения или сжатия. Это подчеркивает мощь данной формулировки: в частности, она рассматривает движение и смещение как единое целое. Наконец, мы должны понять, почему в фундаментальной матрице 7 сво- бодных параметров. Ответ относительно прост. Для каждого эпиполюса тре- буется 2 параметра. Кроме того, 3 параметра необходимы для сопоставления любых трех эпиполярных линий с одного изображения на другое. Но почему для сопоставления нужны только 3 эпиполярные линии? Это связано с тем, что семейство эпиполярных линий представляет собой пучок, ориентация которого связана поперечными отношениями, поэтому, зная три эпиполяр- ные линии, можно вывести сопоставление любой другой. 1.4.17. Расчет фундаментальной матрицы В предыдущем разделе мы показали, что фундаментальная матрица име- ет 7 свободных параметров. Это означает, что должна быть возможность найти ее, идентифицируя одни и те же 7 признаков на двух изображениях. Однако, хотя это математически возможно в принципе и подходящий нели- нейный алгоритм существует (Faugeras et al., 1992), было показано, что этот алгоритм может быть численно нестабильным. По сути, шум действует как дополнительная переменная, увеличивающая эффективное число степеней свободы в задаче до 8. Однако для решения этой задачи был разработан ли- нейный алгоритм, называемый 8-точечным алгоритмом. Любопытно, что\n--- Страница 90 ---\nЧасть C. Расположение трехмерных объектов и важность неизменности  89 этот алгоритм был предложен много лет назад Лонге-Хиггинсом (Longuet- Higgins,1981) для оценки основной матрицы, но он проявил себя на практике позже, когда Хартли (Hartley, 1995) показал, как ограничить ошибки, сначала нормализовав значения. Кроме того, используя более 8 точек, можно добить- ся повышенной точности, но тогда необходимо найти подходящий алгоритм, способный справиться с теперь уже переопределенными параметрами. Для этого можно использовать анализ главных компонент, подходящей процеду - рой которого является разложение по сингулярным значениям матрицы (sin- gular value decomposition, SVD). 1.4.18. Усовершенствованные методы триангуляции В течение нескольких лет оставалась нерешенной задача нахождения точных численных значений фундаментальной матрицы, поскольку недостаточная устойчивость связана с тем, что решение методом наименьших квадратов не справляется, когда данные искажены шумом. Эта проблема возникает всякий раз, когда шум содержит выбросы. В частности, выбросы могут воз- никать, когда шум препятствует встрече соответствующих линий обзора в трехмерной сцене (т. е. когда две линии обзора смещены). Очевидным и хорошо проверенным решением этой проблемы является выбор средней точки общего перпендикуляра к двум линиям обзора в качестве точки пере- сечения. Однако этот метод не дает оптимальных результатов в конечном счете потому, что понятия «общий перпендикуляр» и «средняя точка» ма- тематически недействительны для FPP . Впоследствии Канатани (Kanatani, 1996) смог предложить новый способ нахождения оптимальной поправки, взяв за точку пересечения такую точку, в которой суммарная величина сме- щения на двух плоскостях изображения минимальна. Хотя Хартли и Штурм (Hartley, Sturm, 1994) предложили похожий метод, было обнаружено, что метод Канатани на несколько порядков быстрее и не страдает эпиполюсны- ми сингулярностями, возникающими при использовании метода Хартли– Штурма (Torr, Zisserman, 1997). Впоследствии, вплоть до 2019 г., продолжали появляться интересные улучшения метода. В частности, Ли и Чивера (Lee, Civera, 2019) предложили модифицированный метод средней точки – метод обобщенной взвешенной средней точки, – в котором не предполагается, что две начальные точки лежат на общем перпендикуляре. Они показали, что, хотя их метод теоретически не является оптимальным в смысле сведения к минимуму геометрических или алгебраических ошибок, он превосходит существующие методы с точки зрения скорости, простоты и комбинирован- ной точности 2D, 3D и параллакса. Фати (Fathy et al., 2011) подытожил ситуацию следующим образом: 8-то- чечный алгоритм – это одношаговый метод, который обычно применяется после удаления выбросов для получения начальной оценки фундаменталь- ной матрицы; затем он итеративно уточняется для получения более точного решения.\n--- Страница 91 ---\n90  Кардинальные перемены в области компьютерного зрения 1.4.19. Достижения и ограничения многоракурсного зрения В нескольких предыдущих разделах обсуждались преобразования, необхо- димые для калибровки камеры, и описывалось, как можно выполнить ка- либровку. Параметры камеры были классифицированы как «внутренние» и «внешние», что упрощает концептуальную проблему и проливает свет на источники ошибок в системе. Показано, что для проведения калибровки в общем случае, когда задействовано 11 параметров преобразования, тре- буется минимум 6 точек. Тем не менее, как правило, желательно увеличить количество точек, используемых для калибровки, насколько это возможно, поскольку в результате процесса усреднения может быть получен значитель- ный выигрыш в точности. В разделе 1.4.12 представлено многоракурсное зрение. Было показано, что эта важная тема опирается на обобщенную эпиполярную схему и приводит к идее существенных и фундаментальных матриц, которые связывают наблю- даемые положения любой точки в двух системах отсчета камеры. Была под- черкнута важность 8-точечного алгоритма для расчета любой из этих матриц – в особенности фундаментальной матрицы, которая актуальна, когда камеры не откалиброваны. Кроме того, вопросы точности и надежности при расчете фундаментальной матрицы все еще остаются предметами исследований, хотя в последние годы были достигнуты большие успехи (см. раздел 1.4.18) в от - ношении этапа удаления выбросов при расчете фундаментальной матрицы. 1.5. Ч асть D. отсЛежи Вание дВижущи Хся объе КтоВ 1.5.1. Основные принципы отслеживания В последние годы было разработано множество алгоритмов для интерпре- тации отдельных изображений и идентификации большого количества объ- ектов на них. После этого успеха ученые обратили внимание на анализ по- следовательностей изображений и потокового видео. В самом деле, если бы изображения в любой последовательности рассматривались просто как наборы отдельных изображений или «кадров», то эту новую задачу можно было бы уже считать решенной; поэтому особое значение приобрела интер- претация последовательности изображений как самостоятельного объекта. Возникла потребность в алгоритмах для идентификации и отслеживания движущихся объектов в любой последовательности изображений. Мы могли бы решить эту задачу, идентифицируя объекты во всех кадрах, а затем вычисляя треки, показывающие, как объекты перемещались между кадрами. Этот подход может быть реализован в соответствии со следующим алгоритмом:\n--- Страница 92 ---\nЧасть D. Отслеживание движущихся объектов  91 для всех кадров подряд найти и идентифицировать все объекты связать объекты между кадрами, перечислить все объекты и их треки. Эта процедура требует, чтобы все объекты были обнаружены и распозна- ны, и в этом случае их связывание для формирования треков будет включать связывание только объектов одного и того же класса распознавания (напри- мер, автомобилей). Однако было бы еще лучше, если бы все объекты одного класса можно было идентифицировать по отдельности (например, автомо- биль 1, автомобиль 2 и т. д.), хотя, если некоторые объекты очень похожи между собой, может возникнуть некоторая путаница при их связывании. Эту довольно сложную процедуру можно было бы упростить, если бы объ- екты характеризовались параметрами их движения. На самом деле инфор- мация об отслеживании должна обеспечивать значительную экономию вы- числений. Таким образом, мы приходим к альтернативной стратегии: обнаружить все объекты в первом кадре найти, как эти объекты двигались в каждом последующем кадре перечислить все объекты и их треки. Эта упрощенная процедура требует, чтобы объекты были обнаружены (а не распознаны) в первом кадре. Кроме того, нет необходимости повторять их распознавание в последующих кадрах, поскольку они должны однозначно идентифицироваться по их относительной близости. Дальнейшая экономия усилий в принципе может быть достигнута за счет исключения первого этапа – обнаружения всех объектов в первом кадре. Все, что нам нужно сделать, – это обнаружить сами движения и идентифициро- вать все, что движется, как объект. Возможно, самый простой способ достичь этого – выделить различия между соседними кадрами, и в этом случае лю- бые изменения должны указывать на расположение движущихся объектов. Однако этот подход имеет тенденцию обнаруживать только ограниченные участки контуров цели: например, он будет игнорировать большую часть любого объекта однородной интенсивности – в соответствии с известной формулой разности DI.v. Самый простой выход из этой затруднительной ситуации – смоделировать фон; затем, вычитая каждый кадр из фоновой модели, мы сможем найти любые движущиеся объекты. (Естественно, это будет работать лучше всего, если фон останется неподвижным.) Хотя эта идея привлекательна, ее не так-то просто применить на прак - тике. Одна из основных проблем заключается в том, что сцена, содержащая ряд движущихся объектов, сопровождается постоянным изменением модели фона, по мере того как по ней проходят движущиеся объекты: характерным примером является сцена дороги, по которой движутся транспортные сред- ства. В этом случае незначительные изменения в выведенном фоне должны быть устранены каким-либо процессом усреднения. Обратите внимание, что полученный фон также необходимо будет обновлять с течением времени из-за изменений окружающего освещения и различных погодных условий. Отсюда вытекает вопрос, как реализовать это обновление, заодно компенси- руя прошедшие объекты. Усреднение кадров во времени – плохой способ, но\n--- Страница 93 ---\n92  Кардинальные перемены в области компьютерного зрения некоторые исследования (Lo, Velastin, 2001; Cucchiara et al., 2003) показали, что временнáя медианная фильтрация может быть весьма эффективной, по- скольку она способна устранять влияние выпадающих значений интенсив- ности, например из-за транспортных средств, движущихся на неподвижном фоне. Одна из проблем с этим подходом заключается в том, что нахождение временнóй медианы требует хранения большого количества кадров – стра- тегия, которая не применима к обычному усреднению, которое удобно вы- полняется при помощи скользящего среднего, взвешенного по времени. Однако Дэвис (Davies, 2017) показал, что эту проблему можно решить пу - тем итеративной реализации временной медианы и что это решение также позволяет обновить модель фона, чтобы компенсировать эффекты пере- менного фонового освещения. Кроме того, он обнаружил, что еще лучшим подходом является использование «сдержанного» медианного фильтра, в котором игнорируются экстремальные интенсивности и цвета в ограни- ченной полосе по сравнению с предыдущим итеративным приближением. В дорожной сцене это предотвращает чрезмерное искажение выводимых уровней фона транспортными средствами, которые временно неподвижны (см. рис. 1.27 и 1.28). Заметим, что при таком подходе нет априорной причины, по которой интенсивность транспортного средства или другого объекта должна быть больше или меньше истинного фона – очевидно, что существуют обе воз- можности. Следовательно, вычитание текущего кадра из фоновой модели может разбить любой движущийся объект на несколько частей, которые впо- следствии придется рекомбинировать с по мощью таких методов, как мор- фологическая обработка. К счастью, этот метод также помогает устранить шум. Например, как видно по рис. 1.27 и 1.28, могут быть очень успешно подавлены эффекты движения листьев или ветвей на ветру. Интересно, что в то время как описанный выше подход может успешно узнавать автомобили в дорожных сценах, он рассматривает их тени как части объектов, поскольку не использует рассуждения более высокого уровня. Этот эффект проиллюстрирован на рис. 1.27 и 1.28. На самом деле обнаружение теней широко изучалось, и Хорпрасерт (Horprasert et al., 1999) продемонст - рировал полезный принцип для его реализации: он основан на том факте, что тени имеют аналогичную цветность, но более низкую яркость, чем мо- дель фона.\n--- Страница 94 ---\nЧасть D. Отслеживание движущихся объектов  93 (а) (c)(b) (d) Рис. 1.27  Вычитание фона с использованием временного медианного фильт ра. Обратите внимание на множество стационарных теней, которые пол- ностью игнорируются в процессе вычитания фона. В (а) «призрак» автобуса (из его прежнего положения) все еще появляется, но в (b) он начал снова сливаться с фоном; задача значительно облегчается в (c) и (d), где применяется «сдер- жанный» временной медианный фильтр. В целом наихудшими проблемами являются фрагментация объектов переднего плана и ложные формы (включая эффекты движущихся теней). Линии черных пунктирных точек обозначают со- ответствующий участок дороги: почти вся качающаяся на ветру растительность находится за пределами этого участка\n--- Страница 95 ---\n94  Кардинальные перемены в области компьютерного зрения (b) (а) Рис. 1.28  Кадры (a) и (b) иллюстрируют трудности интерпретации непосред- ственных результатов вычитания фона. Эти два кадра ясно показывают проб- лемы с шумом, которые возникают во время вычитания фона: белые пиксели указывают, где текущий кадр не соответствует модели фона. Чтобы в значитель- ной степени устранить шум и максимально интегрировать формы транспортно- го средства, используются морфологические операции (размытие с последую- щей дилатацией), как показано белыми графическими контурами на рис. 1.27. Обратите внимание, что последние содержат не только формы транспортных средств, но и тени, которые движутся вместе с ними 1.5.2. Альтернативы вычитанию фона В то время как метод вычитания фона, описанный выше, по своей сути прост, удивительно эффективен и очень быстро работает, он также ограни- чен (а) предположением, что фон в основном не меняется, хотя и справляется (посредством усреднения во времени и морфологической обработки) с дви- жущимися объектами фона, и (б) тем, что не использует надлежащие модели объектов переднего плана. Более строгий подход состоял бы в том, чтобы рассматривать распределения интенсивностей и цветов для любого пикселя как суперпозицию нескольких распределений, соответствующих двум или трем компонентным источникам. Здесь важно то, что каждое из распределе- ний компонентов может быть достаточно узким и четко определенным. Это означает, что если каждый из них известен из продолжающегося обуче ния, можно проверить любую текущую интенсивность I, чтобы определить, соот - ветствует ли она фону или новому объекту переднего плана. Это делает смешанные модели Гаусса (Gaussian mixture models, GMM) по- лезными для представления истинных диапазонов интенсивности фона и переднего плана. На самом деле количество компонентов в любом пикселе изначально неизвестно: действительно, большая часть пикселей будет иметь только один компонент, но количество компонентов, требуемое на практике, обычно находится в диапазоне от 3 до 5. Однако определение GMM требует применения алгоритма максимизации ожидания (expectation maximization, EM) и является обременительным с вычислительной точки зрения. На самом деле, хотя для инициализации процесса генерации фона обычно используется этот строгий подход, многие процессы-воркеры используют более простые\n--- Страница 96 ---\nЧасть D. Отслеживание движущихся объектов  95 и эффективные методы для его обновления, чтобы текущий процесс мог продолжаться в режиме реального времени. К сожалению, подход GMM терпит неудачу, когда фон имеет очень высо- кие частотные вариации. По сути, это связано с тем, что алгоритм должен справляться с быстро меняющимися распределениями, которые могут силь- но меняться за очень короткие промежутки времени, поэтому статистика становится слишком плохо определенной. Чтобы решить эту проблему, не- которые исследователи (Elgammal et al., 2000) отошли от параметрического подхода GMM. Их непараметрический метод включает в себя использование функции сглаживания ядра (обычно гауссовой) и для каждого пикселя при- менение ее к N выборкам из I для кадров, появляющихся в течение периода Dt до текущего момента времени t. Этот подход способен быстро адапти- роваться к скачкам от одного значения интенсивности к другому, в то же время получая локальные отклонения для каждого пикселя. Таким образом, его ценность заключается в его способности забывать старые интенсивно- сти и отражать локальные вариации, а не случайные скачки интенсивности. Кроме того, поскольку он не использует алгоритм EM, то может работать с высокой эффективностью в режиме реального времени и обеспечивать точное обнаружение объектов на переднем плане в сочетании с низким уров- нем ложных срабатываний. Чтобы достичь таких показателей, он использует сначала отдельные функции гауссова ядра для каждого цветового канала, а затем упомянутый ранее метод на основе цветности для подавления теней. До сих пор мы видели, что преимущества вычитания фона заключаются в простоте применения, быстроте выполнения и высокой эффективности – вплоть до способности (с соответствующими алгоритмическими коррек - тировками) справляться с медленно меняющимся фоновым освещением; устранять тени на заднем и переднем планах; подавлять «призраки», воз- никающие от временно остановившихся транспортных средств, а также эф- фекты развивающейся растительности. С другой стороны, он полагается на статичный фон, что, в свою очередь, означает использование только фикси- рованных камер. Кроме того, нет никакой гарантии, что все части объектов переднего плана будут иметь разную интенсивность по сравнению с фо- ном – фактор, который может вызвать разбиение объектов на фрагменты и приводит к необходимости морфологической обработки, которая сама по себе является достаточно специальным решением. Еще одна проблема, возникающая при отслеживании на основе вычитания фона, заключается в том, что объекты переднего плана могут быть частично или полностью перекрыты другими объектами: это происходит, в частности, когда пешеходы перемещаются в людных местах. В лучшем случае это может привести к фрагментации треков, а в худшем – к неправильному соединению фрагментов. Заметим также, что движение некоторых объектов может во- обще прекратиться. Ясно, что для решения этих задач нужны тщательно про- думанные методы. Традиционный способ работы с оборванными треками заключался в использовании прогнозирующих фильтров, таких как фильтр Калмана, но они имеют ограниченное применение, поскольку в основном нацелены на оценку вероятностей соединения пар дорожек на основе еди- ничных унимодальных гауссовых плотностей.\n--- Страница 97 ---\n96  Кардинальные перемены в области компьютерного зрения В целом эти критические замечания и проблемы требуют, чтобы времен- ные различия были подкреплены сопоставлением корреляции шаблонов для уверенности, что мы имеем дело с одним и тем же объектом. Как отмечают Липтон и соавторы (Lipton et al., 1998), для обнаружения движущихся объ- ектов может использоваться временная разность (или родственные методы, такие как вычитание фона), а корреляционное сопоставление может исполь- зоваться (а) для точного определения местоположения объектов и (б) для обуче ния шаблона корреляции; на каждом этапе используется шаблон с наи- лучшей корреляцией как для (а), так и для (б). Фактически использование лучшего шаблона корреляции применимо, даже когда один объект частично перекрывает другой. Кроме того, это особенно полезно, когда конкретный объект становится неподвижным, поскольку тогда нет неопределенности в отношении его идентичности или местоположения. Сталдер и др. (Stalder et al., 2009) разработали альтернативную стратегию отслеживания объектов, которую они описали как «отслеживание путем об- наружения». Цель состояла в том, чтобы позволить трекеру адаптироваться к любым изменениям внешнего вида объекта путем обновления модели объ- екта. Однако это приводит к так называемой «проблеме обновления шабло- на», когда существует компромисс между адаптивностью и стабильностью (в частности, трекер может получить полностью искаженную, нежизнеспо- собную версию профиля объекта – процесс, называемый «дрейфом»). Эта трудность преодолевается путем переформулирования отслеживания как за- дачи частично контролируемого обуче ния, в которой во время отслеживания могут использоваться как размеченные, так и неразмеченные данные. Чтобы сделать эту работу, используется частичный бустинг1 модели, при этом каж - дому неразмеченному образцу в области локального поиска назначается псевдометка yi и вес важности λi (меченые образцы имеют метку yi и важ - ность 1). После начального обнаружения, приводящего к предварительному HP, строится классификатор объектов H с учетом положительных выборок от объекта и отрицательных от окружающего фона: обычно для указания нового положения объекта берется локальный максимум доверительного распределения, и класс обновляется. Таким образом, мы получаем последо- вательность местоположений объекта, начиная с первого (получившегося в результате первоначального обнаружения), а затем переходим ко многим последующим отслеживаемым позициям. Однако, в принципе, уравнения бустинга также могут привести к тому, что первичное обнаружение (приор) либо исчезнет, либо будет слишком сильно доминировать, что соответствует, соответственно, дрейфу или нулевой адаптации. Но в целом дрейф ограни- чен, так как трекер не может уйти слишком далеко от приора. Проблемы с описанной выше стратегией отслеживания включают (а) при- нятие частичных окклюзий или явно допустимых изменений внешнего вида за недопустимый дрейф и (б) перескакивание на похожие объекты (напри- мер, детектор лиц может перескакивать с лица одного человека на другое). 1 Бустинг – композиционный метаалгоритм машинного обуче ния, применяется главным образом для уменьшения смещения, а также дисперсии в обучении с учи- телем. – Прим. перев.\n--- Страница 98 ---\nЧасть D. Отслеживание движущихся объектов  97 Очевидно, что отслеживание путем обнаружения в основном применимо для отслеживания одной цели, но когда требуется сопровождение нескольких целей, необходимо учитывать все три процесса: обнаружение, отслеживание и распознавание. В частности, узнавание следует понимать как различение сходных объектов в сцене. Система классификации множественных целей Сталдера и др. (Stalder et al., 2009) продемонстрировала очень хорошую работоспособность при отсле- живании множества объектов. Она ограничивала дрейф за счет тщательного использования контролируемых обновлений и избегания петель обратной связи, тем самым предотвращая накопление небольших ошибок, которые могли привести к дрейфу. Это было достигнуто за счет того, что трекер стал доминирующим элементом в подходе, так что его информационный поток возвращался (в цикле) обратно к себе или (в конечном итоге) к предыдущему распознавателю. Эта система позволяла отслеживать объекты с по мощью движущейся камеры, а также была достаточно надежной, чтобы обеспечи- вать долгосрочное отслеживание в течение 24 часов. Еще одним аспектом сопровождения множественных целей является воз- можность повторной идентификации объектов, которые временно скрыты от поля зрения (например, временно заслонены или оказались вне поля зре- ния камеры). Решение включает сопоставление идентификации и считается допустимым только в том случае, если достигнутая степень совпадения зна- чительно выше, чем для любых других потенциальных совпадений. Повтор- ная идентификация может завершиться ошибкой, если степень совпадения станет слишком разной во время соответствующего временного промежутка. Опять же, система Стадлера также показала хорошие результаты в этом от - ношении. Калал и соавторы (Kalal et al., 2011) разработали мощную систему от - слеживания, предназначенную, в частности, для устранения ошибок дрей- фа во время выполнения и проблем, возникающих, когда отслеживаемые объекты исчезают из поля зрения. Их подход был аккуратно описан как «отслеживание-обуче ние-обнаружение». Ключевым аспектом этого метода является то, что обуче ние осуществляется «P-экспертом», который оценива- ет пропущенные обнаружения, «N-экспертом», который оценивает ложные тревоги, и средствами обновления обоих экспертов путем обуче ния. Разде- ляя отслеживание и обнаружение, они утверждали, что ни возможности от - слеживания, ни возможности обнаружения не снижены, и представили убе- дительные доказательства успеха их подхода, в частности оценив точность многих наборов данных в среднем на уровне 81 %, тем самым значительно превзойдя пять более ранних подходов, ни один из которых не достигал точ- ности выше 22 %. В то время как в работе Калала отслеживали только отдельные объекты, другие исследователи (Wu et al., 2012) показали, как выполнять обнаруже- ние связи и ассоциации данных для нескольких объектов, чтобы обеспечить определение полных треков. Этот подход использовал ассоциацию данных о сетевых потоках и опирался на более раннюю статью Кастаньона (Castañón, 1990), озаглавленную «Эффективный алгоритм поиска k лучших путей через решетку». Это название говорит о том, что метод в значительной степени\n--- Страница 99 ---\n98  Кардинальные перемены в области компьютерного зрения основан на обширном анализе графов: хотя это интересно, объем книги не позволяет включить здесь полное обсуждение данных методов. Достаточно сказать, что отслеживание нескольких объектов – сложная задача, которая становится еще более сложной по мере увеличения количества целей и за- полнения всей сцены объектами и треками. Таким образом, в этом отноше- нии работу Ву можно считать более тщательной, чем работу Стадлера. Мы изучим более свежие разработки по этой теме в части F, раздел 1.7.7, после рассмотрения методов глубокого обуче ния. 1.6. Ч асть E. анаЛиз теКстур 1.6.1. Введение Мы уже рассмотрели несколько основных аспектов анализа изображений, включая, в частности, обнаружение признаков, распознавание объектов и сегментацию. Теперь переходим к анализу текстур. Мы начнем с опреде- ления текстуры как характерного изменения интенсивности, которое должно позволить нам распознать и описать текстурированную область и очертить ее границы (рис. 1.29). Как правило, текстура представляет собой образец интенсивности, возникающий при отражении света от поверхности, имею- щей определенную степень шероховатости. Ясно, что гладкая, равномерно освещенная поверхность не будет иметь текстуры, в то время как кусок ткани или песчаный пляж будут иметь собственные характерные текстуры. Рис. 1.29  Разнообразие текстур. На этих изображениях представлены раз- личные знакомые текстуры, которые легко распознаются по их характерным образцам интенсивности Вообще говоря, текстуры различаются по степени случайности и регуляр- ности, и в последнем случае они могут иметь высокую или низкую направ- ленность. Например, куски ткани обычно демонстрируют высокую степень регулярности и направленности, в то время как картина интенсивности, ис - ходящая от поверхности песчаного пляжа, может казаться в высшей степени\n--- Страница 100 ---\nЧасть E. Анализ текстур  99 случайной с незначительной направленностью. Другим фактором является масштаб воспринимаемого размера фрагментов для поверхности, который будет небольшим для песка и намного больше для лотка с горохом. Крошеч- ные элементы, составляющие текстурированную поверхность, часто назы- вают текстурными элементами, или текселями (texel). Из вышеупомянутых соображений можно вывести следующие характеристики текстур: 1) тексели будут иметь различные размеры и степени однородности; 2) тексели будут ориентированы в разных направлениях; 3) тексели будут располагаться на разном расстоянии в разных направ- лениях; 4) контраст будет иметь различные величины и вариации; 5) между текселями может проглядывать разное количество фона; 6) вариации, составляющие текстуру, могут иметь разную степень регу - лярности либо случайности. Значительное количество параметров, необходимых для описания тексту - ры, неизбежно делает анализ текстур довольно сложным; и, конечно, многие параметры будут иметь высокую степень изменчивости, поэтому анализ часто приводит к статистическому описанию текстур. В следующем разделе показаны некоторые способы решения этой задачи. 1.6.2. Основные подходы к анализу текстур В разделе 1.6.1 мы определили текстуру как характерное изменение интен- сивности области изображения, которое должно позволить нам распознать ее, описать и очертить ее границы. Ввиду статистической природы текстур это побуждает нас характеризовать текстуру дисперсией значений интенсив- ности, взятых в области текстуры. Однако такой подход не даст достаточно богатого описания текстуры для большинства целей: он также будет непри- годен в тех случаях, когда тексели хорошо определены или когда в текстуре присутствует высокая степень периодичности. С другой стороны, для очень периодических текстур, таких как многие ткани, естественно рассмотреть возможность использования анализа Фурье. К сожалению, хотя этот подход давно и тщательно протестирован, результаты не были обнадеживающими. Автокорреляция – еще один очевидный подход к анализу текстуры, по- скольку он должен выявлять как локальные вариации интенсивности, так и повторяемость текстуры (рис. 1.30). Одно из первых исследований было проведено Кайзером (Kaizer, 1955). Он исследовал, на сколько пикселей должно сместиться изображение, прежде чем автокорреляционная функция упадет до 1/e от своего начального значения, и предложил основанную на этом субъективную меру грубости. Однако Розенфельд и Трой (1970) пока- зали, что автокорреляция не является удовлетворительной мерой грубости. Кроме того, автокорреляция не является хорошим дискриминатором изо- тропии в естественных текстурах. Поэтому исследователи быстро переняли матричный подход, предложенный Хараликом (Haralick et al., 1973). Подход с использованием матрицы совпадений на уровне серого основан на изуче- нии статистики распределения интенсивности пикселей. Как упоминалось\n--- Страница 101 ---\n100  Кардинальные перемены в области компьютерного зрения выше, статистика отдельных пикселей не обеспечивает достаточно под- робного описания текстур для практических приложений. Таким образом, естественно рассматривать статистику второго порядка, полученную при рассмотрении пар пикселей с определенными пространственными отно- шениями друг к другу. Поэтому в подходе Харалика используются мат рицы совпадений, которые выражают относительные частоты P(i, j | d, θ), с кото- рыми два пикселя, имеющих относительные полярные координаты (d , θ), появляются с интенсивностью i, j. Матрицы совпадений предоставляют не- обработанные числовые данные о текстуре, хотя эти данные должны быть сжаты до относительно небольшого количества числовых значений, прежде чем их можно будет использовать для классификации текстуры. В работе Ха- ралика описано четырнадцать таких мер, и они успешно использовались для классификации многих типов материалов (включая, например, древесину, кукурузу, траву и воду). Рис. 1.30  Использование функции автокорреляции для анализа тек - стуры. На этой диаграмме показан возможный одномерный профиль ав- токорреляционной функции для фрагмента ткани, в которой переплете- ние подвержено значительным пространственным вариациям: обратите внимание, что периодичность автокорреляционной функции затухает на довольно коротком расстоянии К сожалению, количество данных в матрицах совпадений может быть во много раз больше, чем в исходном изображении, – ситуация, которая усу - губляется в более сложных случаях количеством значений d и θ, необходи- мых для точного представления текстуры. Кроме того, число уровней серого обычно равно 256, а количество матричных данных зависит от квадрата этого числа. Наконец, матрицы совпадения просто обеспечивают новое представ- ление: сами по себе они не решают проблему распознавания. В силу этих причин в 1980-е гг. появилось весьма значительное разнообразие методов анализа текстур. Среди них метод Лоуза (Laws, 1979; 1980a; 1980b) выделяет - ся тем, что он привел к другим разработкам, обеспечивающим систематиче- ские, адаптивные средства анализа текстуры. Этот подход рассматривается в следующем разделе.\n--- Страница 102 ---\nЧасть E. Анализ текстур  101 1.6.3. Метод Лоуза на основе энергии текстуры В 1979 и 1980 гг. Лоуз представил свой новый подход к текстурному анали- зу, основанный на так называемой энергии текстуры (Laws, 1979, 1980a,b). Подход включал применение простых фильтров к цифровым изображени- ям. Основные фильтры, которые он использовал, были обычными фильт - рами Гаусса, детектором краев и фильтрами по типу Лапласа, специально разработанными для выделения точек с высокой «текстурной энергией» на изображении. Выявив эти точки с высокой энергией, сгладив различные от - фильтрованные изображения и объединив полученную информацию, Лоуз смог очень эффективно охарактеризовать текстуры. Как отмечалось ранее, подход Лоуза оказал большое влияние на многие последующие работы, и по- этому стоит рассмотреть его здесь более подробно. Маски Лоуза создаются путем свертывания всего трех основных масок 1×3: L3 = [1 2 1]; (1.104) E3 = [–1 0 1]; (1.105) S3 = [–1 2 –1]. (1.106) Начальные буквы этих масок обозначают локальное усреднение (L ocal), обнаружение краев (E dge detection) и обнаружение пятна (S pot detection). Фактически эти базовые маски охватывают все подпространство 1×3 и обра- зуют полный набор. Точно так же маски 1×5, полученные путем свертки пар этих масок 1×3, вместе образуют полный набор, в котором только следующие пять различны: L5 = [1 4 6 4 1]; (1.107) E5 = [–1 –2 0 2 1]; (1.108) S5 = [–1 0 2 0 –1]; (1.109) R5 = [1 –4 6 –4 1]; (1.110) W5 = [–1 2 0 –2 1]. (1.111) (Здесь начальные буквы такие же, как и раньше, с добавлением обнаруже- ния пульсаций (Ripple detection) и обнаружения волн (Wave detection).) Мы также можем использовать матричное умножение, чтобы объединить маски 1×3 и аналогичный набор масок 3×1 и получить девять масок 3×3, например: (1.112)\n--- Страница 103 ---\n102  Кардинальные перемены в области компьютерного зрения Результирующий набор масок снова образует полный набор (табл. 1.2). Обратите внимание, что две из этих масок идентичны маскам оператора Со- беля. Соответствующие маски 5×5 полностью аналогичны, но здесь подробно не рассматриваются, поскольку все необходимые принципы охватываются масками 3×3. Таблица 1.2. Девять масок Лоуса 3×3 L3TL3 L3TE3 L3TS3 1 2 1 –1 0 1 –1 2 –1 2 4 2 –2 0 2 –2 4 –2 1 2 1 –1 0 1 –1 2 –1 E3TL3 E3TE3 E3TS3 –1 –2 –1 1 0 –1 1 –2 1 0 0 0 0 0 0 0 0 0 1 2 1 –1 0 1 –1 2 –1 S3TL3 S3TE3 S3TS3 –1 –2 –1 1 0 –1 1 –2 1 2 4 2 –2 0 2 –2 4 –2 –1 –2 –1 1 0 –1 1 –2 1 Все подобные наборы масок включают одну, компоненты которой не ус - редняются до нуля. Этот метод менее полезен для анализа текстуры, по- скольку он дает результаты, зависящие больше от интенсивности изображе- ния, чем от текстуры. Остальная часть результата чувствительна к краевым точкам, пятнам, линиям и их комбинациям. После создания изображений, указывающих на локальную резкость и т. д., следующим этапом является вывод локальных величин этих параметров. За- тем эти величины сглаживаются по области, которая больше размера маски основного фильтра (например, Лоуз использовал окно сглаживания 15×15 после применения своих масок 3×3): в результате этого сглаживаются про- межутки между краями текстуры и другие микропризнаки. К этому момен- ту исходное изображение преобразовано в векторное изображение, каждый компонент которого представляет «энергию» определенного типа. В то время как Лоуз (1980b) использовал для оценки энергии текстуры как квадраты ве- личин, так и абсолютные величины, первые соответствуют истинной энергии и дают лучший отклик, вторые полезны тем, что требуют меньше вычислений: (1.113) где F(i, j) – локальная величина типичного микропризнака, которая сглажи- вается в общей позиции сканирования (l , m) в окне (2p + 1)×(2p + 1). На следующем этапе требуется комбинировать различные энергии раз- ными способами, предоставляя несколько выходных данных, которые могут\n--- Страница 104 ---\nЧасть E. Анализ текстур  103 быть переданы в классификатор для принятия решения о конкретном типе текстуры в каждом местоположении пикселя (рис. 1.31): при необходимости используется анализ главных компонент, чтобы помочь выбрать подходя- щий набор промежуточных результатов. Рис. 1.31  Базовая форма классификатора текстур Лоуза. Здесь I – входящее изображение, M – расчет микропризнаков, E – расчет энергии, S – сглаживание, C – окончательная классификация Метод Лоуза обеспечил превосходную точность классификации на уровне 87 % по сравнению с 72 % для метода матрицы совпадения применительно к составному текстурному изображению травы, рафии, песка, шерсти, свиной кожи, воды и древесины (Laws, 1980). Лоуз также обнаружил, что выравни- вание гистограммы, обычно применяемое к изображениям для устранения различий первого порядка в распределении оттенков серого поля текстуры, привело к небольшому улучшению. В независимом исследовании (Pietikäin- en et al., 1983) было подтверждено, что измерения энергии текстуры Лоуза более эффективны, чем измерения, основанные на парах пикселей (в част - ности, матрицы совпадения). 1.6.4. Метод собственного фильтра Аде В 1983 году Аде исследовал теорию, лежащую в основе метода Лоуза, и раз- работал пересмотренное обоснование с точки зрения собственных фильтров (eigenfilter). Он взял все возможные пары пикселей в окне 3×3 и охаракте- ризовал данные интенсивности изображения ковариационной матрицей 9×9. Затем определил собственные векторы (eigenvector), необходимые для диагонализации этой матрицы. Они соответствуют маскам фильтров, анало- гичным маскам Лоуза, т. е. использование этих масок собственных фильтров создает изображения, которые являются изображениями главных компонент для данной текстуры. Кроме того, каждое собственное значение (eigenvalue)\n--- Страница 105 ---\n104  Кардинальные перемены в области компьютерного зрения дает ту часть дисперсии исходного изображения, которая может быть из- влечена соответствующим фильтром. По сути, дисперсии дают исчерпыва- ющее описание данной текстуры с точки зрения текстуры изображений, из которых первоначально была получена ковариационная матрица. Ясно, что фильтры, обеспечивающие низкую дисперсию, можно считать относительно неважными для распознавания текстуры. Будет полезно проиллюстрировать технику для окна 3×3. Здесь мы следуем Аде (Ade, 1983) в нумерации пикселей в окне 3×3 в порядке сканирования: 1 2 3 4 5 6 7 8 9 Это приводит нас к ковариационной матрице 9×9 для описания взаимосвя- зей между интенсивностями пикселей в окне 3×3, как указано выше. Здесь мы вспоминаем, что описываем текстуру, и, предполагая, что ее свойства не син- хронны с тесселяцией1 пикселей, мы ожидаем, что различные коэффициенты ковариационной матрицы C будут равны. На самом деле существует только 12 различных пространственных отношений между пикселями, если мы не принимаем во внимание перемещения целых пар, или 13, если мы включим в набор нулевой вектор (табл. 1.3). Таким образом, ковариационная матрица, компоненты которой включают 13 параметров a –m, принимает вид: (1.114) Таблица 1.3. Пространственные отношения между пикселями в окне 3×3 a b c d e f g h i j k l m 9 6 6 4 4 3 3 1 1 2 2 2 2 В табл. 1.4 показано количество вхождений пространственных отношений между пикселями в окне 3×3. Обратите внимание, что a – это диагональный элемент ковариационной матрицы C, а все остальные элементы встречаются в C в два раза чаще, чем указано в таблице. 1 Тесселяция – мозаичное заполнение, разбиение плоскости картины на фрагменты, заполняющие картину без каких-либо наложений или пробелов. – Прим. перев.\n--- Страница 106 ---\nЧасть E. Анализ текстур  105 Матрица C симметрична; собственные значения действительной симмет - ричной ковариационной матрицы действительны и положительны, а соб- ственные векторы взаимно ортогональны. Кроме того, полученные таким образом собственные фильтры отражают правильную структуру изучаемой текстуры и идеально подходят для ее охарактеризования. Например, для текстуры с ярко выраженным высоконаправленным узором будет одно или несколько собственных значений высокой энергии с собственными фильтра - ми, имеющими сильную направленность в соответствующем направлении. 1.6.5. Сравнение методов Лоуза и Аде На этом этапе полезно более тщательно сравнить подходы Лоуза и Аде. В ме- тоде Лоуза используются стандартные фильтры, создаются изображения энергии текстуры, а затем может применяться метод главных компонент с целью распознавания; в свою очередь, в методе Аде применяются специ- альные фильтры (собственные фильтры), включающие результаты приме- нения метода главных компонент, после чего вычисляются меры энергии текстуры, и подходящее их количество применяется для распознавания. Подход Аде превосходен тем, что позволяет на раннем этапе исключить малозначащие компоненты, тем самым экономя вычисления. Например, в приложении Аде первые пять из девяти компонентов содержат 99,1 % всей энергии текстуры, поэтому на остальные можно не обращать внимания; кро- ме того, оказалось, что еще две компоненты, содержащие соответственно 1,9 % и 0,7 % энергии, также можно было бы игнорировать с небольшой по- терей точности распознавания. Однако в некоторых приложениях текстуры могут постоянно меняться, и может оказаться нецелесообразным точно на- страивать метод для конкретных данных, относящихся к любому моменту времени. (Например, эти замечания относятся (1) к тканям, степень растя- жения которых постоянно меняется в процессе производства, (2) к сырым пищевым продуктам, таким как бобы, размер которых зависит от источника поставки, и (3) к переработанным пищевым продуктам, таким как пирожные, рассыпчатость которых зависит от температуры приготовления и содержа- ния водяного пара.) Унзер (Unser, 1986) разработал более общий вариант техники Аде. В этом подходе производительность оптимизирована не только для классификации текстур, но и для распознавания двух текстур путем одновременной диаго- нализации двух ковариационных матриц. Этот метод получил дальнейшее развитие в следующих работах (Unser, Eden 1989; 1990), в которых проводит - ся тщательный анализ использования нелинейных детекторов. В результате авторы пришли к использованию двух уровней нелинейности: один приме- няется сразу после линейных фильтров и разработан (путем использования специальной гауссовой текстурной модели) для подачи на этап сглаживания подлинной дисперсии или других подходящих показателей, а другой – пос - ле этапа пространственного сглаживания для компенсации эффекта пре- дыдущего фильтра в стремлении обеспечить значение функции в тех же единицах, что и входной сигнал. С практической точки зрения это означает\n--- Страница 107 ---\n106  Кардинальные перемены в области компьютерного зрения возможность получения среднеквадратичного сигнала текстуры от каждого из каналов линейного фильтра. В целом метод Лоуза возник в 1980-х гг. как серьезная альтернатива ме- тоду матриц совместной встречаемости. Также следует отметить, что еще были разработаны альтернативные многообещающие методы, например ме- тод принудительного выбора Вистнеса (Vistnes, 1989) для нахождения краев между различными текстурами, который, по-видимому, имеет значительно лучшую точность, чем метод Лоуза. В своем исследовании Вистнес делает вывод о том, что метод Лоуза ограничен (а) малым масштабом масок, ко- торые могут пропускать более крупномасштабные текстурные фрагменты, и (б) тем фактом, что операция сглаживания энергии текстуры размывает значения признаков текстуры по всему краю. Последний вывод (или даже худшая ситуация, когда третий класс текстур оказывается расположенным в области границы между двумя текстурами) также был отмечен Сяо и Савчу - ком (Hsiao, Sawchuk, 1989), которые применили усовершенствованный метод сглаживания признаков. 1.6.6. Последние разработки В 2000-х гг. появилась тенденция к анализу текстур, не зависящих от мас - штаба и вращения. В частности, в статье Дженни и Джирса (Janney, Geers, 2010) описан подход «инвариантных признаков локальных текстур», исполь- зующий строго круговой одномерный массив точек выборки вокруг любой заданной позиции. Метод использует вейвлеты Хаара и, как результат, эф- фективен в вычислительном отношении. Он применяется в нескольких мас - штабах для достижения масштабной инвариантности; кроме того, выполня- ется нормализация интенсивности, чтобы сделать метод инвариантным по освещению. Также следует отметить книгу (Mirmehdi et al., 2008), посвящен- ную этому довольно узкому вопросу. Она представляет собой редактируемый сборник работ, содержащий вклад различных исследователей и обобщающий положение дел до 2010 г. Рассмотрение более поздних достижений по этой теме мы отложим до части F, разделов 1.7.8 и 1.7.9, после введения в методы глубокого обуче ния. 1.7. Ч асть F. от исКусст Венны Х нейронны Х сетей К методам гЛубоКого обу Чения 1.7.1. Введение: как ИНС превратились в СНС Первоначальная цель разработки искусственных нейронных сетей (ИНС) со- стояла в том, чтобы имитировать процессы, происходящие в зрительной системе человека. На первый взгляд, зрительная система мозга устроена и работает настолько просто – целые сцены анализируются «с одного взгля-\n--- Страница 108 ---\nЧасть F. От искусственных нейронных сетей к методам глубокого обучения  107 да» без видимых усилий, – что возникает вполне естественное желание по- строить аналог зрительной системы на основе компьютера. Ясно, что ИНС, предназначенная для имитации зрительной системы человека, должна со- стоять из нескольких слоев, каждый из которых изменяет данные сначала локально, а затем все большими и большими наборами нейронов, пока не будут выполнены такие задачи, как распознавание и анализ сцены. Однако в первое время использование ИНС, как правило, ограничивалось очень не- большим количеством слоев: рабочая максимальная глубина состояла из одного входного слоя, трех скрытых слоев и одного выходного слоя, хотя позже было обнаружено, что многие основные задачи могут быть решены с использованием трехслойной сети с одним скрытым слоем. Одной из причин ограничения количества слоев была задача назначения коэффициентов доверия (credit assignment problem), которая означала, что стало сложнее обучать слои «сквозь» несколько предшествующих слоев; в то же время большее количество слоев означало, что нужно обучить больше нейронов и для выполнения задачи требовалось больше вычислений. По- этому ИНС, как правило, предназначались для выполнения только класси- ческого процесса распознавания и получали входные данные от детекторов признаков, применяемых на предыдущих уровнях, не связанных с обуче- нием. Стандартной парадигмой был препроцессор изображений, за которым следовал обученный классификатор. Поскольку очень хорошие детекторы признаков можно было спроектировать вручную, это не вызывало ника- ких очевидных проблем. Однако с течением времени возникла потребность в полномасштабном анализе реальных сцен, которые могли бы содержать изображения многих типов объектов во многих положениях. Таким образом, нарастала потребность в переходе к гораздо более сложным многоуровне- вым системам распознавания, для которых ранние модификации ИНС были непригодны. Также появилась необходимость в обучении самой системы предварительной обработки, чтобы она точно соответствовала требованиям следующей системы анализа объектов; иными словами, возникла необходи- мость в создании интегрированных многослойных нейронных сетей. Фактически к концу 1990-х гг. перспективы ИНС не вызывали оптимизма, потому что с ними конкурировали другие успешные методы, такие как ма- шины опорных векторов (support vector machines, SVM). Кроме того, не был разработан научно обоснованный способ определения минимально необхо- димого количества слоев или нейронов и не было четкого понимания внут - ренних принципов работы ИНС. В результате специалисты, которые могли бы использовать их, не знали, насколько они надежны, и не были уверены, что смогут использовать их в реальных приложениях, поэтому ИНС начали терять популярность. Важной причиной этого был еще и тот факт, что их архитектура и обуче ние давали плохую пространственную инвариантность для изображений. В част - ности, нейроны обучались индивидуально: каждый нейрон видел обучающие данные, отличные от других нейронов в своем слое; кроме того, веса связей между нейронами необходимо было инициализировать случайным образом. Эти факторы не позволяли получить одно и то же решение в отношении лю- бого объекта независимо от его положения на изображении. Однако иссле-\n--- Страница 109 ---\n108  Кардинальные перемены в области компьютерного зрения дователи и разработчики нейросетей не стояли на месте, и в конце 2000-х гг. на первый план вышли сети с «глубоким» обуче нием (глубокая нейронная сеть (ГНС) – это сеть, в которой более трех нелинейных скрытых слоев, что выходит за рамки обычных ИНС). Новым типом архитектуры стала сверточная нейронная сеть (convolutional neural network, CNN). Во многих отношениях это была менее требовательная архитектура, поскольку (а) каждый нейрон CNN не должен быть подключен ко всем выходам предыдущего слоя нейронов; (б) нейроны имеют одина- ковые весовые параметры по всему слою. Тем не менее CNN по-прежнему используют обуче ние с учителем (supervised learning) и сеть обучается с по- мощью обратного распространения ошибки (backpropagation). Важно отметить, что применение одинаковых весовых коэффициентов ней- ронов во всем слое значительно уменьшило общее количество парамет ров во всей сети и существенно упростило ее обуче ние; кроме того, может быть ис - пользовано большее количество слоев. Предоставление нейронам локальных связей еще больше улучшило ситуацию. Заметим, что если нейроны и веса идентичны во всем слое, результирующая математическая операция по опре- делению является сверткой – отсюда и термин «сверточная нейронная сеть». Еще одна особенность CNN заключается в том, что они используют функ - цию ReLU, а не сигмоидальные выходные функции. «ReLU» означает «Recti- fied Linear Unit» (спрямленный линейный блок) и определяется как max(0, x), где x – выходное значение непосредственно предшествующего слоя свертки. Эта функция ценна тем, что требует меньше вычислений, чем прежняя сиг - мовидная функция, и в то же время меньше искажает большие сигналы. По существу, функция ReLU позволяет избежать проблем с насыщением, кото- рым подвержены ИНС (нейрон, дающий выходной сигнал, близкий к пределу (±1) функции гиперболического тангенса, имеет тенденцию «застревать» на одном и том же значении, потому что нет градиента, чтобы увести алгоритм обратного распространения ошибки подальше от этой точки). CNN также включают пулинг (pooling, объединение), т. е. получение всех выходных данных из локальности и получение из них одного выходного значения: обычно пулинг принимает форму суммы или операции нахож - дения максимума (max) над всеми входными данными, причем max-пулинг более распространен, чем операция суммирования или усреднения. Пулинг обычно выполняется в окнах 2×2 или 3×3, первый вариант встречается чаще. Эти методы были направлены на минимальное изменение данных, чтобы удалить большую часть избыточности на определенном уровне сети, в то же время сохранив наиболее полезные данные. Несколько сверточных слоев могут быть размещены сразу друг за другом, что делает их эквивалентными одной большей свертке – фактор, который мо - жет быть полезен для реализации более крупных признаков в одной и той же CNN. В целом CNN представляют собой разумную альтернативу ANN. Кроме того, они выглядят лучше приспособленными к идее постепенного перехода от локальных к глобальным операциям с изображениями и поиску все более и более крупных признаков или объектов в процессе. Хотя продвижение по сети ведет нас от локальных операций к более гло- бальным, первым нескольким слоям CNN также свойственно искать опреде-\n--- Страница 110 ---\nЧасть F. От искусственных нейронных сетей к методам глубокого обучения  109 ленные низкоуровневые признаки; следовательно, они обычно имеют раз- меры, соответствующие размерам определенного типа изображения. Далее в сети обычно применяют операции пулинга, тем самым уменьшая разме- ры последующих слоев. После нескольких этапов свертки и пулинга сеть значительно сузится, поэтому можно сделать последние несколько слоев полностью связанными, т. е. такими, где в любом слое каждый нейрон под- ключен ко всем выходам предыдущего слоя. На этом этапе, скорее всего, бу - дет относительно немного выходных данных, а те, которые останутся, будут определяться любыми параметрами, которые должны быть предоставлены сетью: они могут включать классификации и связанные с ними параметры, такие как абсолютные или относительные позиции. 1.7.2. Параметры, определяющие архитектуру CNN При анализе архитектур CNN есть ряд моментов, заслуживающих внимания. В частности, необходимо определить несколько величин и терминов – ши- рину W, высоту H, глубину N, страйд (stride, шаг) S, ширину паддинга (запол- нения нулями) P и поле восприятия R. Фактически ширина и высота – это просто размеры входного изображения либо размеры определенного слоя нейронной сети. Глубина N сети или конкретного блока в ней – это количест - во содержащихся в ней слоев. Ширина W и высота H слоя – это количество нейронов в каждом измере- нии. Страйд S – это расстояние между соседними нейронами в выходном поле, измеренное в единицах, соответствующих расстоянию между соседни- ми нейронами в поле ввода; страйд S можно определить по ширине и высоте, но обычно он одинаков для каждого измерения. Если S = 1, соседние слои имеют одинаковые размеры (но ниже мы покажем, как размер поля восприя- тия R может изменить это). Обратите внимание, что увеличение S может быть полезным, так как это экономит память и вычисления. В принципе, достига- ется эффект, аналогичный пулингу. Однако пулинг предполагает некоторое усреднение, а увеличение S просто уменьшает количество взятых выборок. Параметр Ri – это ширина поля восприятия (или рецептивного поля) для каждого нейрона слоя i, т. е. количество входов для всех нейронов на этом уровне. Паддинг, или заполнение нулями, – это добавление P «виртуальных» нейронов, предоставляющих статические входные данные на каждом конце измерения ширины: им присваиваются фиксированные нулевые веса. Идея паддинга состоит в том, чтобы гарантировать, что все нейроны в одном слое имеют одинаковое количество входных данных, тем самым облегчая про- граммирование. Однако это также гарантирует, что последовательные сверт - ки не приведут к уменьшению активной ширины; в частности, когда S = 1, это позволяет нам сделать ширины соседних слоев в точности равными (т. е. Wi+1 = Wi). Простая формула связывает несколько таких величин: Wi+1 = (W i + 2P i – Ri)/Si + 1, (1.115) где разности относятся к входным данным слоя i и выходным данным слоя i + 1. Стоит подчеркнуть нулевую ситуацию Wi +1 = Wi, которая возникает,\n--- Страница 111 ---\n110  Кардинальные перемены в области компьютерного зрения когда Si = 1, Ri = 1 и Pi = 0. В общем случае цель паддинга состоит в том, чтобы учесть влияние крайних точек каждого слоя, при условии что коли- чество нулей соответствует желаемым значениям страйда и размерности поля восприятия. Наконец, необходимо сделать важное замечание об определении глубины слоев CNN. Предшествующее обсуждение подразумевало, что доступ к ряду смежных слоев CNN обычно осуществляется последовательно один за дру - гим – как это действительно было бы в случае, если бы все более и более крупные свертки реализовывались одна за другой в попытке обнаружить все более и более крупные признаки или даже объекты. Однако есть и другая воз- можность: различные слои загружаются параллельно из заданной начальной точки в сети, например из входного изображения. Такая ситуация обычно возникает, когда изображение нужно искать по целому ряду различных при- знаков, таких как линии, края или углы, и результаты параллельно передают - ся на более обобщенный детектор. Эта стратегия была принята в архитектуре LeNet, которую Ян Лекун с соавторами (LeCun et al., 1998) разработал для распознавания рукописных цифр и почтовых индексов. 1.7.3. Архитектура сети AlexNet Сеть AlexNet была разработана специально для конкурса ImageNet Challenge (ImageNet LargeScale Visual Recognition Object Challenge – ILSVRC, 2012), ко- торый состоялся в 2012 г. Разработчики AlexNet (Крижевский и др., 2012) сделали ставку на доработку довольно старой схемы, основанной на CNN. Чтобы достичь успеха, им пришлось радикально улучшить архитектуру CNN, и это неизбежно привело к созданию очень большого программного движ - ка; затем им пришлось значительно ускорить его с по мощью графических процессоров – задача не из легких, поскольку это означало повторную оп- тимизацию программного обеспечения в соответствии с оборудованием; наконец, им нужно было придумать, как снабдить модель очень большим обучающим набором – опять же непростая задача, поскольку нужно было тщательно обучить беспрецедентно большое количество параметров, и для этого потребовалось несколько нововведений. В архитектуре CNN было 10 скрытых уровней (считая уровни C, F и S) – все- го на 4 больше, чем у LeNet. Однако эти числа вводят в заблуждение, так как общая глубина различных слоев в AlexNet составляет 11 176 по сравнению с 258 у LeNet. Точно так же AlexNet содержит 650 000 нейронов по сравнению с 6508 у LeNet, а количество обучаемых параметров составляет около 60 млн по сравнению с 60 000 у LeNet. И когда мы смотрим на размер входного изо- бражения, мы обнаруживаем, что AlexNet получает цветное изображение размером 224×224, тогда как LeNet может обрабатывать только двухуров- невое входное изображение 32×32. Таким образом, в целом AlexNet больше, чем LeNet, в 100–1000 раз, в зависимости от того, какие параметры считать наиболее значимыми. Однако ключевым изменением, внесенным AlexNet, стала возможность работать с огромным количеством слоев и, несмотря на это, решать проблему назначения коэффициентов, при этом все еще исполь-\n--- Страница 112 ---\nЧасть F. От искусственных нейронных сетей к методам глубокого обучения  111 зуя алгоритм обратного распространения ошибки для обуче ния. В то время это было беспрецедентным достижением, но отчасти это стало возможным благодаря уменьшенному количеству параметров, необходимых для CNN, потому что все нейроны в любом заданном слое нейронов имеют идентич- ные параметры; это также стало возможным благодаря использованию ис - ключительно больших обучающих наборов. Однако уникальной особенно- стью архитектуры AlexNet является горизонтальное разделение всей сети на две части, причем для реализации верхней и нижней частей используются разные графические процессоры. В принципе, это должно было чрезмерно усложнить работу с архитектурой, но на практике оказалось выполнимым. Но из-за этой сложности нам будет гораздо проще сосредоточиться на архи- тектуре ZFNet (Zeiler, Fergus, 2014), так как это, по сути, слегка доработанная и улучшенная версия AlexNet, реализованная на одном графическом про- цессоре (рис. 1.32): в частности, у нее было восемь, а не семь скрытых слоев (здесь S-слои считаются частью соответствующих C-слоев). Также стоит от - метить, что ZFNet выполняет более плавное начальное сужение размеров слоя (n ×n), чем AlexNet (уровень C1 имеет размер 110×110, а не 55×55). С дру - гой стороны, обе архитектуры использовали «перекрывающийся пулинг» – в данном случае комбинацию пулинга 3×3 и страйда 2×2. Обратите внимание, что размеры (n ×n) слоев начинаются с 224×224 и постепенно уменьшаются до 1×1. Интересно, что почти все обучаемые параметры находятся в слоях F7 и F8 (F6 и F7 для AlexNet), а для окончательного классификатора softmax (не нейронного) остается всего 1000 связей. На рис. 1.32 слои S1, S2 и S3 показаны синим цветом справа от C1, C2 и C5 соответственно; n×n означает размеры в случае двумерного формата изобра- жения; r×r – размер поля ввода двумерного нейрона (одиночное число указы- вает на абстрактные одномерные данные); s×s – двумерный страйд. N – это глубина в пределах отдельного слоя: его приблизительный размер указан на рисунке в вертикальном масштабе. Незадолго до завершения AlexNet, Хинтон с коллегами представили но- вую методику, называемую «отсев» (dropout). (Hinton et al., 2012; см. также Hinton, 2002). Цель этого подхода заключалась в том, чтобы сократить случаи переобучения. Искомый результат был достигнут путем случайной установки доли (обычно до 50 %) весов на ноль для каждого шаблона обуче ния; эта до- вольно неожиданная техника, судя по всему, работает весьма неплохо: она предотвращает чрезмерную зависимость скрытых слоев от конкретных дан- ных, поступающих к ним. Крижевский и его коллеги (Krizhevsky et al., 2012) включили эту функцию в AlexNet. Выход каждого нейрона случайным обра- зом устанавливается равным нулю с вероятностью 0,5. Это делается перед прямой передачей входных данных, и затронутые нейроны не участвуют в последующем обратном распространении. На следующем прямом проходе другой набор выходов нейронов обнуляется с вероятностью 0,5, и снова за- тронутые нейроны не участвуют в обратном распространении; аналогичное действие выполняется для всех последующих проходов. Во время тестиро- вания происходит альтернативная процедура, когда все выходы нейронов умножаются на 0,5. Фактически умножение всех выходных сигналов нейро- нов на 0,5 является приближением к получению среднего геометрического\n--- Страница 113 ---\n112  Кардинальные перемены в области компьютерного зрения всех распределений вероятностей выходных сигналов локальных нейронов и основано на том факте, что среднее геометрическое не слишком далеко от среднего арифметического. Отсев был включен в первые два слоя AlexNet и значительно уменьшил переобучение из-за слишком малого количества обучающих данных. Сеть AlexNet была обучена с использованием 1,2 млн изображений, до- ступных в рамках задачи ImageNet ILSVRC, и это число является подмножест - вом полных 15 млн в базе данных ImageNet. Фактически набор ILSVRC-2010 был единственным подмножеством, для которого были доступны тестовые метки; в каждой из 1000 категорий было около 1000 изображений. Однако выяснилось, что этих изображений слишком мало, чтобы обучить CNN той сложности, которая требуется для выполнения точной классификации этой огромной задачи. Поэтому нужно было как-то расширить набор для над- лежащего обуче ния AlexNet и достижения уровня ошибок классификации в интервале от 10 % до 20 %. При обучении модели были предложены и реализованы два основных способа расширения набора данных. Один заключался в том, чтобы при- менить к изображениям реалистичные переносы и отражения, дабы соз- дать больше изображений того же типа. Преобразования расширились даже до извлечения пяти участков 224×224 и их горизонтальных отражений из исходных изображений ImageNet 256×256, что дало в общей сложности по десять участков на изображение. Другой метод заключался в изменении ин- тенсивности и цвета входных изображений. Чтобы сделать это упражнение более строгим, оно было выполнено с использованием анализа основных компонентов (PCA) для определения основных компонентов цвета для набо- ра данных ImageNet, а затем для генерации случайных величин, на которые умножаются собственные значения, тем самым создавая реалистичные ва- риации исходного изображения. Вместе эти два подхода смогли достоверно обобщить и увеличить размер исходного набора данных в 2000 раз – принцип расширения набора заключался в том, чтобы генерировать реалистичные изменения положения, интенсивности и цвета. На данном этапе следует подчеркнуть, что цель конкурса заключалась в том, чтобы найти наилучшую модель компьютерного зрения (с наимень- шим количеством ошибок классификации), которая способна распознавать образцы блохи, собаки, автомобиля или другого типичного объекта в лю- бой локации на изображении и в любой разумной позе. Более того, машина должна расставлять приоритеты в своих классификациях, чтобы давать по крайней мере пять наиболее вероятных интерпретаций с указанием ожи- даемой степени достоверности. Затем каждую машину можно оценить не только по точности ее наилучшей классификации, но и по тому, входит ли классифицируемый объект в топ-5 классификаций машины. Модель AlexNet смогла достичь показателя ошибок 15,3 %, по сравнению с 26,2 % у модели, занявшей второе место. Еще одним значимым событием стало резкое паде- ние уровня ошибок нейросетевых моделей до уровня ниже 20 % для такого упражнения, что означало новый этап в жизни нейронных сетей и привлекло к ним всеобщее внимание.\n--- Страница 114 ---\nЧасть F. От искусственных нейронных сетей к методам глубокого обучения  113 Стоит отметить, что выдающийся результат был достигнут не только за счет разработки выигрышной архитектуры и создания правильного набора данных для адекватного обуче ния нейросети, но также за счет сокращения времени обуче ния до приемлемого уровня. В этом отношении решающую роль сыграло использование GPU. Даже с парой графических процессоров непрерывное круглосуточное обуче ние заняло примерно неделю. Без гра- фических процессоров на это ушло бы примерно в 50 раз больше времени – скорее всего, около года, – поэтому модель просто опоздала бы на конкурс! (Оценка альтернативной продолжительности основана на том, что GPU ра- ботает приблизительно в 50 раз быстрее по сравнению с обычным средним процессором.) Наконец, следует отметить, что графические процессоры обеспечивают очень хорошую реализацию нейросетевых вычислений из-за их внутреннего параллелизма и, следовательно, их способности обрабатывать большие на- боры данных за меньшее количество циклов. К счастью, каждый слой CNN полностью однороден и поэтому идеально подходит для параллельной об- работки. Также немаловажен тот факт, что графические процессоры хоро- шо приспособлены к параллельной работе, поскольку они могут напрямую считывать и записывать данные в память друг друга напрямую, избегая не- обходимости перемещать данные через память центрального процессора. 1.7.4. Архитектура сети VGGNet Симоняна и Зиссермана В условиях остающейся нехватки знаний о форме идеальной архитекту - ры Симонян и Зиссерман (Simonyan, Zisserman, 2015) решили определить эффект дальнейшего увеличения глубины. Для этого они значительно со- кратили количество параметров в базовой сети, ограничив максимальное поле ввода нейрона до 3×3. Фактически они ограничили поле ввода свертки и страйд до 3×3 и 1×1 соответственно и установили для поля ввода и страй- да каждого слоя подвыборки значение 2×2. Кроме того, они организовали систематическое и быстрое схождение последовательных слоев от 224×224 вниз до 7×7 в 5 этапов с последующим переходом к 1×1 за один полносвязный этап; затем последовали еще два полносвязных слоя и последний выходной слой softmax (рис. 1.33). Все скрытые слои включали этап нелинейности ReLU (на рисунке не показан). Помимо N «каналов», пять сверточных слоев С1–С5 содержали соответственно 2, 2, 3, 3, 3 идентичных подслоя (на рис. 1.33 не отмечены). Наконец, следует отметить, что в целях эксперимента Симонян и Зиссерман разработали 6 вариантов архитектуры VGGNet с 11–19 взвешен- ными скрытыми слоями: здесь мы рассматриваем только конфигурацию D (с 16 взвешенными скрытыми слоями), для которой количества одинако- вых подслоев в слоях C1–C5 указаны выше, а слои F6, F7 и F8 содержат по 1 взвешенному подслою. Очевидно, что количество взвешенных слоев силь- но влия ет на количество параметров.\n--- Страница 115 ---\n114  Кардинальные перемены в области компьютерного зрения Слой N n×n r×r s×sС1 96 110×110 7×7 2×2С4 384 13×13 3×3 1×1F7 4096 6×6 1×1 1×1С2 256 26×26 5×5 2×2С5 256 13×13 3×3 1×1F8 4096 1 1 1С3 384 13×13 3×3 1×1С6 256 6×6 3×3 1×1Выход 1000 1 1 1Изображение 3 224×224 Рис. 1.32  Схема архитектуры ZFNet. Эта схема очень похожа на схему AlexNet. Обратите внимание, что AlexNet содержит 7 скрытых слоев, тогда как ZFNet содержит 8 скрытых слоев (здесь S-слои считаются частями соответству- ющих C-слоев). Также отметим, что ZFNet реализована с использованием только одного графического процессора и ее архитектура не разделена Слой N n×n r×rС1 64 224×224 3×3C1 C2 C3 C4 C5 F6 F7 F8 Выход S1 S2 S3 S4 S5 С4 512 28×28 3×3F7 4096 1 1С2 128 112×112 3×3С5 512 14×14 3×3F8 1000 1 1С3 256 56×56 3×3F6 4096 7×7 1×1Выход 1000 1 1Изображение 3 224×224Изображение Рис. 1.33  Архитектура сети VGGNet. Эта архитектура демонстрирует более позднюю оптимизацию стандартной сети CNN. В отличие от схемы на рис. 1.32, здесь показаны относительные размеры слоев свертки, которые варьируются от размера изображения до 1×1. Обратите внимание, что все слои свертки имеют единичный страйд и что их поля ввода ограничены максимальным размером 3×3: все слои подвыборки имеют поля ввода 2×2 и страйды 2×2\n--- Страница 116 ---\nЧасть F. От искусственных нейронных сетей к методам глубокого обучения  115 Как упоминалось выше, Симонян и Зиссерман сократили количество ос - новных параметров, ограничив поле ввода свертки до 3×3. Это означало, что более крупные свертки должны были быть созданы путем последовательного применения нескольких сверток 3×3. Ясно, что поле ввода 5×5 потребует применения двух сверток 3×3, а поле 7×7 потребует трех сверток 3×3. В по- следнем случае это уменьшит общее количество параметров с 72×49 до 3 раз по 32×27. На самом деле этот способ реализации свертки 7×7 не только умень- шил количество параметров, но и потребовал дополнительной регуляриза- ции свертки, поскольку нелинейность ReLU была вставлена между каждой из 3×3 компонентных сверток. Также важно, что и на входе, и на выходе каждого 3-слойного стека свертки 3×3 может быть N каналов, и в этом случае он будет содержать всего 27N2 параметров, и именно это число следует сравнивать с 49N2 параметрами. Несмотря на увеличенную глубину, VGGNet содержит только приблизи- тельно в 2,4 раза больше параметров, чем AlexNet; кроме того, она намного проще и не делится на две части с использованием двух GPU. Напротив, она сразу же получает ускорение в 3,75 раза по сравнению с одним графическим процессором при использовании готовой системы с 4 графическими про- цессорами. Детали методики обуче ния аналогичны методике AlexNet, о чем гово- рится в оригинальной статье Симоняна и Зиссермана (2015). Тем не менее эти авторы вносят одно интересное новшество: это использование «дро- жания масштаба» во время обуче ния, т. е. увеличение обучающей выборки с использованием объектов в широком диапазоне масштабов. На практике было применено случайное масштабирование изображения с коэффициен- том, равным 2. В результате сеть VGGNet достигла показателя 7,0 % ошибок при тести- ровании с использованием одной сети по сравнению с 7,9 % для GoogLeNet (Szegedy et al., 2014). На самом деле GoogLeNet достигла показателя в 6,7 %, но только за счет использования 7 сетей. Благодаря этому VGGNet заняла второе место в конкурсе ILSVRC-2014. Однако уже после отправки модели на конкурс авторам удалось снизить частоту ошибок до 6,8 %, используя ансамбль из 2 моделей – практически такое же качество классификации, как и у GoogLeNet, но со значительно меньшим количеством сетей. Интересно, что этот результат был получен даже притом, что архитектура VGGNet не от - личалась от классической архитектуры LeNet Яна Лекуна (LeCun et al., 1989). Главное улучшение заключается в значительном увеличении глубины сети. Несмотря на то что сеть VGGNet заняла второе место в конкурсе ILSVRC- 2014, она оказалась более универсальной и адаптируемой к различным на- борам данных и является предпочтительным выбором в сообществе специа- листов по машинному зрению для извлечения признаков из изображений. По-видимому, это связано с тем, что VGGNet на самом деле предоставляет более робастные признаки даже несмотря на то, что качество классификации для определенного набора данных оказалось немного ниже. Как мы увидим в следующем разделе, сеть VGGNet взяли за основу Но и соавторы (Noh et al., 2015) для работы над сетями деконволюции (deconvolution, обратная свертка).\n--- Страница 117 ---\n116  Кардинальные перемены в области компьютерного зрения 1.7.5. Архитектура DeconvNet Вдохновленные работой Цейлера и Фергюса, Но с коллегами создали «обучае- мую сеть деконволюции» (DeconvNet), которая в ходе обуче ния научилась выполнять деконволюцию наборов коэффициентов свертки в каждом слое CNN. Перед детальным изучением их сети важно понять идею, которой ру - ководствовались авторы. Их целью было создание сети семантической сег- ментации. Суть в том, что обычная сегментация изображения направлена на определение границ между различными объектами, появляющимися на изображении: семантическая же сегментация идет дальше и классифицирует все объекты, тем самым придавая соответствующее значение (семантику) каждой области изображения. Архитектура DeconvNet показана на рис. 1.34: обратите внимание, что ее начальная секция CNN заимствована из слоев C1–F7 VGGNet, хотя она исклю- чает слой F8 и выходной слой softmax. Будет полезно понять причину этого решения. Во-первых, для распознавания объектов на входном изображении нужна восходящая CNN. Во-вторых, если объекты должны быть расположены в определенных частях изображения, необходима другая CNN, чтобы указать на позиции, и она обязательно должна следовать за процессом распознава- ния. Выполнение обеих задач в одной огромной неограниченной CNN будет переполнять память и препятствовать обуче нию, поэтому две сети должны быть тесно связаны друг с другом. Под связью сетей здесь подразумевается C1 C2 C3 C4 C5 D5 D4 D3 D2 D1 F6 F7 S1 S2 S3 S4 S5 U5 U4 U3 U2 U1Изображение Карта Рис. 1.34  Схема обучающей сети деконволюции Но. Эта сеть фактически содержит две смыкающиеся сети. Слева – стандартная сеть CNN, а справа – со- ответствующая сеть «деконволюции» DNN, которая, очевидно, работает в об- ратном порядке. Сеть CNN (слева) не имеет выходного (например, softmax) классификатора, поскольку конечной целью является не классификация объ- ектов, а представление попиксельной карты их расположения по всей области изображения. Слои деконволюции от D5 до D1 предназначены для постепенно- го «разделения» слоев C5–C1. Аналогичным образом разделение слоев с U5 по U1 предназначено для постепенного разделения объединенных слоев S5–S1. Для этого параметры положения из слоев max-пулинга должны передаваться в соответствующие местоположения в нужных слоях разделения (т. е. местопо- ложения из S i должны передаваться в U i)\n--- Страница 118 ---\nЧасть F. От искусственных нейронных сетей к методам глубокого обучения  117 обеспечение путей прямой связи от блоков пулинга к последующим блокам разделения. Таким образом, за средствами, с по мощью которых выходные данные CNN были обобщены для устранения влияния вариаций выборки, следует вторая CNN, которая дополняет систему для получения необходимых карт местоположения. Важно отметить, что общий восходящий путь данных делает очевидным, почему все блоки ReLU теперь должны указывать в одном направлении. (Теперь все они снова направлены вперед.) Также ясно, что с такой огромной сетью обуче ние должно проводиться аккуратно, и кажется очевидным, что восходящая часть, отвечающая за обнаружение объектов, должна изначально обучаться самостоятельно. В целом система работает, зеркально отражая входную CNN путем включе- ния после нее сети деконволюции (DNN). Операция может быть резюмиро- вана следующим образом: слой разделения U i является нелинейным и пере- направляет (разделяет) максимальные сигналы C i; затем слой деконволюции Di работает с данными линейно и, следовательно, должен суммировать пере- крывающиеся входные данные, взвешенные по мере необходимости. Од- нако вместо того, чтобы создавать подходящие комбинированные правила для определения того, что происходит с перекрывающимися окнами вывода каждого слоя Di, – и делать это каким-то очень приблизительным образом (например, брать «транспонированные» версии фильтров свертки), – слои деконволюции обучаются как обычные части общей сети. Поскольку это строгий подход, он существенно увеличивает нагрузку, связанную с обуче- нием сети. Читателям будет полезно построить мысленную модель всего процесса, происходящего в DNN. Во-первых, каждый слой разделения восстанавливает информацию из соответствующего слоя пулинга и восстанавливает размеры пространства данных, которые были до объединения. Однако он заполняет пространство только разреженно, с локальными максимальными значения- ми в соответствующих позициях. Целью следующего слоя деконволюции является реконструкция плотной карты в ее пространстве данных. Таким образом, в то время как CNN уменьшает размер активаций, следующая DNN увеличивает активации и снова делает их плотными. Тем не менее полного обращения не происходит, так как повторно вставляются только максималь- ные значения. Как авторы архитектуры говорят в своей статье (2015): «Раз- деление захватывает характерные для образца (example-specific) структуры, прослеживая исходные местоположения с сильными активациями до про- странства изображения», тогда как «обученные фильтры в слоях деконволю- ции склонны захватывать очертания, характерные для класса (class-specific)». Это означает, что слои деконволюции перестраивают очертания образцов, чтобы они более точно соответствовали тому, что можно было бы ожидать для объектов определенных классов. Несмотря на эту уверенность, сеть должна быть обучена соответствующим образом. Однако сделанное выше предположение о двухэтапном обучении было уточнено авторами работы следующим образом: чтобы решить пробле- му чрезвычайно большого пространства семантической сегментации, сеть сначала обучается на простых примерах, а затем обучается на более сложных примерах: это равносильно методу начальной загрузки. Точнее, начальный\n--- Страница 119 ---\n118  Кардинальные перемены в области компьютерного зрения процесс обуче ния включает в себя ограничение изменений размера и место- положения объектов путем их центрирования и обрезки в их ограничиваю- щих прямоугольниках; второй этап включает в себя обеспечение того, чтобы более сложные объекты адекватно перекрывались с достоверной сегмента- цией: для этого используется широко используемая мера пересечения над объединением (intersection over union, IoU), которая считается приемлемой, только если она составляет не менее 0,5. На самом деле на первом этапе ис - пользуется «узкая» ограничивающая рамка, которая увеличивается в 1,2 ра за и расширяется до квадрата, чтобы включить достаточный локальный кон- текст вокруг каждого объекта. На этом первом этапе поле оценивается в со- ответствии с объектом, расположенным в его центре, а остальные пиксели помечаются как фон. Однако на втором этапе это упрощение не применяется и для аннотации используются все соответствующие метки классов. Далее мы рассмотрим другой близкий метод, предложенный Бадринарай- яной и соавторами (Badrinarayanan et al., 2015), который использует гораздо меньше памяти и имеет ряд других преимуществ. 1.7.6. Архитектура SegNet Архитектура SegNet сильно напоминает DeconvNet (рис. 1.34) и также на- целена на семантическую сегментацию. Однако ее авторы продемонстри- ровали необходимость возврата к значительно более простой архитектуре, чтобы сделать ее более легко обучаемой (Badrinarayanan et al., 2015). В ос - новном она была идентична DeconvNet (рис. 1.34), но за исключением слоев F6 и F7. Кроме того, авторам было ясно, что использование max-пулинга и подвыборки снижает разрешение карты признаков и тем самым снижает точность определения местоположения на окончательных сегментирован- ных изображениях. Тем не менее они начинают с устранения полносвязных слоев VGGNet, сохраняя структуру кодирования-декодирования (CNN-DNN) DeconvNet, а также сохраняя max-пулинг и разделение. Фактически именно отказ от использования полносвязных слоев больше всего помогает SegNet, поскольку это резко сокращает количество параметров, которые необхо- димо изучить, и тем самым так же резко снижает требования к процессу обуче ния. Соответственно, всю сеть можно рассматривать как единую, а не двойную сеть, и эффективно обучать ее «от начала до конца». Кроме того, авторы определили гораздо более эффективный способ хранения информа- ции о местоположении объекта: они делают это, сохраняя только индексы max-пулинга, а именно расположение максимальных значений признаков в каждом окне пула на каждой карте признаков кодировщика. В резуль- тате для каждого окна пулинга 2×2 требуется только 2 бита информации (рис. 1.33). Это означает, что даже для начальных слоев CNN (кодировщика) нет необходимости хранить сами карты признаков: необходимо хранить лишь информацию о местоположении объекта. Это означает, что требования к памяти кодировщика снижаются со 134 МБ (соответствует уровням C1–F7 VGGNet) до 14,7 МБ. Общий объем памяти для SegNet будет в два раза больше, поскольку такой же объем информации должен храниться в слоях декодера.\n--- Страница 120 ---\nЧасть F. От искусственных нейронных сетей к методам глубокого обучения  119 Однако то же самое можно сказать и о других сетях деконволюции, поэтому во всех случаях общий объем данных должен быть удвоен по отношению к содержимому исходного кодировщика CNN. Меньший размер SegNet делает возможным сквозное обуче ние и, следо- вательно, гораздо больше подходит для приложений реального времени. Авторы признают, что более крупные сети могут работать лучше, хотя и за счет гораздо более сложных процедур обуче ния, увеличения памяти и зна- чительного увеличения времени вывода. Кроме того, трудно оценить их истинную точность. По сути, декодеры должны обучаться с по мощью очень больших и громоздких кодировщиков, а последние являются универсаль- ными, а не ориентированными на конкретные приложения. В большинстве случаев такие сети были основаны на внешнем интерфейсе VGGNet, обычно содержащем все 13 подуровней C1–C5 вместе с переменным (очень неболь- шим) количеством полностью связанных уровней. На этом фоне неудивительно, что Бадринарайяна с соавторами успешно применили SegNet к набору данных CamVid (Brostow et al., 2009 г.), обучив его от начала до конца для оптимальной адаптации. Они обнаружили, что SegNet превзошла семь традиционных (не нейронных) методов, включая дескрипторы локальных меток и суперанализ (Yang et al., 2012; Tighe and Lazebnik, 2013), получив средний результат 80,1 % по сравнению с 51,2 % и 62,0 % соответственно; были распознаны 11 категорий: здание, дерево, небо, транспортное средство, знак, дорога, пешеход, забор, столб, тротуар и велосипедист, – и точность, достигнутая для этих объектов, варьирова- лась от 52,9 % (велосипедист) до 94,7 % (тротуар). Об их успехе в решении этой задачи можно судить по результатам их онлайн-демонстрации (http:// mi.eng.cam.ac.uk/projects/segnet/), которая использовалась для создания изо- бражений на рис. 1.35. Фактически в этой демонстрации пиксели размещены в двенадцати категориях, включая дорожную разметку в дополнение к один- надцати, перечисленным выше. Они также провели тщательное сравнение SegNet с другими сетями семан- тической сегментации, включая FCN (fully convolutional networks – полностью сверточные сети) и DeconvNet. Сети FCN и DeconvNet имеют одинаковый размер кодировщика (134M); отметим, что FCN уменьшает размер декодера до 0,5M, хотя DeconvNet продолжает использовать декодер размером 134M. Средние результаты по классам для трех методов составляют 59,1 %, 62,2 % и 69,6 %. Несмотря на то что SegNet численно является худшей из трех, ее точность по-прежнему конкурентоспособна, и у нее есть явное преимущест - во в том, что она лучше адаптируется благодаря сквозному обуче нию. Фак - тически она также является самой быстрой – в 2,2 раза быстрее, чем FCN, и в 3,3 раза быстрее, чем DeconvNet, хотя и на изображениях разного размера. В целом авторы заявляют, что архитектуры, «которые хранят сетевые кар- ты признаков кодировщика в полном объеме, работают лучше, но потребля- ют больше памяти во время вывода», что также означает, что они работают медленнее. С другой стороны, SegNet более эффективна, поскольку хранит только индексы max-пула; кроме того, она обладает конкурентоспособной точностью, а ее способность к сквозному обуче нию на актуальных данных делает ее значительно более адаптируемой.\n--- Страница 121 ---\n120  Кардинальные перемены в области компьютерного зрения (a) (b) дорожная разметказнак велосипед столб дерево пешеход здание тротуар машина небо дорога забор Рис. 1.35  Две дорожные сцены, снятые с переднего пассажирского сиденья. В каждом случае изображение слева является исходным, а изображение спра- ва является сегментацией, созданной SegNet. Ключ указывает 12 возможных значений, присвоенных SegNet. Хотя точность определения местоположения не идеальна, присваиваемые значения, как правило, разумны, учитывая огра- ниченное количество допустимых интерпретаций и разнообразие объектов в поле зрения. Эти изображения были обработаны с использованием онлайн- демонстрации по адресу http://mi.eng.cam.ac.uk/projects/segnet/ (Badrinaray- anan et al., 2015) 1.7.7. Применение глубокого обучения для отслеживания объектов Теперь вернемся к теме слежения за движущимися объектами. Это область, в которой методы глубокого обуче ния позволили достичь больших успе- хов. Фактически глубокое обуче ние привело к радикальным улучшениям по сравнению с традиционными подходами, обсуждавшимися ранее. В качестве интересного примера начнем со статьи Хелда (Held et al., 2016). Хелд и соавторы поставили перед собой задачу создать трекер одного объ- екта, который действовал бы в режиме реального времени, и разработали\n--- Страница 122 ---\nЧасть F. От искусственных нейронных сетей к методам глубокого обучения  121 нейронный метод, работающий на скорости до 100 кадров в секунду. Эта ско- рость была достигнута только для тестовой версии сети и опиралась на очень значительный объем автономного обуче ния. Высокая скорость тестирования является результатом использования относительно простой архитектуры, в которой пары кадров подаются на обученную нейронную сеть, которая немедленно (т. е. за один проход) выдает выходное изображение, в котором промаркирована рамка целевого объекта. При тестировании трекер инициализируется начальной ограничительной рамкой, содержащей целевой объект, причем ограничительная рамка об - новляется после анализа каждой последующей пары кадров. Однако перед детальным изучением каждый кадр обрезается до размера и положения, достаточных для захвата целевого объекта при любом движении, которое он может совершить в разумных пределах (обычно это означает кадрирование до размера, в два раза превышающего ограничивающую рамку): эта про - цедура также позволяет использовать полезную контекстную информацию, которая заслуживает внимания. Затем обученная нейронная сеть ищет два кадрированных изображения (t – 1 и t), чтобы найти наилучшее соответствие для положения движущегося объекта. Таким образом, повторение процесса позволяет отслеживать целевой объект на протяжении всей видеопоследо- вательности. Для успешного отслеживания обученная сеть должна содержать огром- ное количество информации о различных возможных смещениях каждой пары изображений. Это вполне возможно при использовании пары сетей, каждая из которых содержит N слоев свертки (часто называемой «сиамской ConvNet»), которые подаются на набор из M полносвязных слоев (Хелд и со- авторы использовали N = 5 и M = 3); окончательный вывод содержал необ- ходимую информацию о выходной ограничивающей рамке. Для получения всей необходимой информации нейросеть обучалась на всех допустимых сдвигах и обрезках поступающих кадров. На самом деле сеть обучалась не только на видео, но и на парах изображений, чтобы научить ее отслеживать более разнообразный набор объектов, тем самым помогая предотвратить переобучение объектам в видеоданных. В результате тщательного обуче ния трекер оказался инвариантным к фо- новому движению, вращению вне плоскости, деформациям, изменениям ос - вещения и незначительным окклюзиям. Кроме того, дополнительное обуче- ние на размеченных изображениях помогло установить общую взаимосвязь между внешним видом и движением объекта, что позволило отслеживать объекты, не появляющиеся в обучающем наборе, а также возможность вы- полнять эту задачу с беспрецедентной скоростью 100 кадров в секунду. Однако за это пришлось расплачиваться большой продолжительностью обуче ния из-за чрезмерного увеличения объема данных. Это была одна из проблем, побудивших Бертинетто и др. (Bertinetto et al., 2016) к разработке архитектуры отслеживания с использованием полностью сверточной (fully convolutional, FC) сиамской сети, которую они назвали SiamFC. Они начали с системы, имеющей два параллельных входа, один из которых предоставлял эталонный образец изображения, а другой – входное изображение. Идея со- стоит в том, чтобы искать во входном изображении совпадения с эталонным\n--- Страница 123 ---\n122  Кардинальные перемены в области компьютерного зрения изображением, используя подходящий оператор подобия. Фактически для этой цели они использовали корреляцию, а корреляционный слой приме- нялся для создания карты оценок, которая была представлена на выходе сети. Разработчики решили сделать так, чтобы карта выходных оценок имела уменьшенную размерность, из которой попадания можно было бы соотнести обратно с входным изображением путем умножения на сетевой страйд. По- следний был принят равным 8 – значение, которое возникает, когда есть три последовательных применения шага 2×2 в слоях C1, S1 и S2 (рис. 1.36). Чтобы полностью понять общий эффект, обратите внимание, что каждый страйд 2×2 делит собственный размер изображения на 2×2. Сиамская сеть состоит из двух параллельных потоков, каждый из которых имеет одинаковую внутреннюю структуру. Это естественно для описанной выше архитектуры, поскольку два потока несут данные одного и того же типа, хотя размеры изображений, очевидно, будут разными. Для каждого из потоков используется полностью сверточная сеть, так как цель состоит в до- стижении трансляционной инвариантности, чтобы сигнал от любого объекта не менялся в зависимости от его положения на изображении. «Полностью сверточная» означает, что никакие изменения параметров свертки не допу - скаются во всем пространстве изображения; иными словами, это означает, что паддинг, т. е. «заполнение» внешних участков сети (обычно нулями), не допускается, и на практике это означает, что – в отличие от AlexNet – выход- ные пространства последовательных слоев будут сокращены везде, где вход- ные поля нейрона превышают 1×1 (рис. 1.36). Следует добавить, что смысл включения двух полностью сверточных сетей состоит в том, чтобы получить достаточную информацию о наблюдаемом объекте и объекте-образце, игно- рируя при этом шум, изменения формы и несущественные артефакты, такие как детали фона. Корреляция выполняется с использованием стандартного вычисления скользящего окна. Общая система показана на рис. 1.36; две полностью свер- точные потоковые сети адаптированы из архитектуры AlexNet Крижевского и др. (2012). Заметим, что полностью связанные слои были отброшены, по- скольку они не являются полностью сверточными и поэтому не допускают позиционной инвариантности. (Цель AlexNet заключалась в том, чтобы клас - сифицировать любое входное изображение в соответствии с классом целе- вого объекта, появляющегося в нем, при этом информация о локализации объекта полностью отбрасывалась.) В работе Бертинетто и др. эталонный образец принимается за начальный вид целевого объекта и не обновляется; также не сохраняется память о про- шлых явлениях и не вычисляются прогнозы положения ограничивающих ра- мок объекта. Главная цель состояла в том, чтобы создать простой и надежный трекер для отдельных целевых объектов. Однако упомянутые исследователи обнаружили, что повышение дискретизации карты оценок в 16 раз с исполь- зованием бикубической интерполяции (т. е. с 17×17 до 272×272) дало более точную локализацию. Кроме того, они искали объект в пяти масштабах, от 0,95 до 1,05, чтобы справиться с вариациями масштаба. Далее мы рассматриваем размер выходного пространства изображения. Слой корреляции представляет собой свертку между изображениями разме-\n--- Страница 124 ---\nЧасть F. От искусственных нейронных сетей к методам глубокого обучения  123 ром 22×22 и 6×6, что приводит от потенциально максимального выходного размера изображения 27×27 к приемлемому размеру изображения 17×17 (эти числа возникают из-за того, что 22 + 6 – 1 = 27 и 22 – 6 + 1 = 17). Обратите внимание, что максимальный размер выходного изображения (27×27) не будет захватывать объекты, которые находятся сразу за пределами области поиска, тогда как минимальный (17×17) будет полностью учитывать объекты, сплошь находящиеся в пределах области поиска; между этими пределами су - ществует та или иная вероятность обнаружения частично видимых объектов. Тем не менее SiamFC был нацелен на максимально успешное обнаружение полностью видимых объектов. Слой n×n n×n n×n N r×r s×sС1 123×123 59×59 96 11×11 2×2S2 28×28 12×12 256 3×3 2×2С5 22×22 6×6 128 3×3 1×1S1 61×61 29×29 96 3×3 2×2С3 26×26 10×10 192 3×3 1×1⊗ С1 57×57 25×25 256 5×5 1×1С4 24×24 8×8 192 3×3 1×1Выход 17×17 1Изображение 255×255 127×127 3 Рис. 1.36  Полностью сверточный сиамский трекер. Здесь показана архитек - тура сиамского трекера FC, разработанного Бертинетто и др. (Bertinetto et al., 2016). Вверху: ветвь FC, содержащая поток поиска; середина: ветвь, содержащая поток образцов категории; внизу: детали двух ветвей, в т. ч. каналов N, размер изображения n×n, входное поле нейрона r×r и страйд s×s ( N, r и s одинаковы для двух потоков). Обратите внимание, что, как и в случае с AlexNet, в этой ар- хитектуре используется перекрывающийся пул в слоях подвыборки S1 и S2, для обоих из которых r×r = 3×3 и s×s = 2×2 Наконец, интересный момент касается расчета эффектов страйда 2×2, ког - да предыдущее изображение имеет нечетный размер (как это происходит во всех трех случаях в SiamFC). В этом случае страйд учитывает первый и по-\n--- Страница 125 ---\n124  Кардинальные перемены в области компьютерного зрения следний пиксели в каждой строке и столбце. Принимая это во внимание, последовательные размеры изображений, приведенные на рис. 1.36, точно и логически соответствуют размерам, данным разработчиками (Bertinetto et al., 2016). Файхтенхофер и др. (Feichtenhofer et al., 2017) задались целью разработать архитектуру глубокого обуче ния, которая одновременно изучает обнару - жение и отслеживание. В их архитектуре используются детектор объектов и трекер: по сути, идея состоит в том, чтобы одновременно выполнять об- наружение и отслеживание с использованием сети ConvNet, оптимизиро - ванной за счет комбинированного обнаружения и отслеживания на основе потерь. Для оценки локального смещения в разных масштабах признаков выполняется сверточная взаимная корреляция между откликами признаков соседних кадров. Здесь корреляция ограничена небольшой окрестностью с максимальным смещением d = 8, чтобы избежать большой выходной раз- мерности: это отражает ограничение, уже отмеченное для средства отсле- живания целей (Held et al., 2016). Карты корреляции вычисляются для всех позиций на карте признаков, и для отслеживания регрессии к этим картам признаков применяется пулинг видимых областей (region of interest, RoI) (Dai et al., 2016). Вышеупомянутый подход позволяет одновременно отсле- живать несколько объектов, а архитектуру можно обучать от начала до конца, используя входные кадры из необработанных видео. В целом этот подход привел к значительному повышению качества на уровне 80 % по сравнению с предыдущими современными методами при выполнении на наборе про- верки VID ImageNet (2015). Обратите внимание, что подход пулинга RoI использует полностью свер- точную схему, насколько это возможно, чтобы поддерживать сдвиговую ин- вариантность, и только последний сверточный слой модифицируется, чтобы отклониться от этого: данная стратегия позволяет вычислять карты оценок, чувствительные к положению, из которых могут быть извлечены так назы- ваемые треклеты (tracklet) нескольких объектов. Однако, поскольку детали общей архитектуры тесно связаны с R-FCN (Dai et al., 2016), ResNet-101 (He et al., 2016), Fast R-CNN (Girshick, 2015) и Faster R-CNN (Ren et al., 2015), до- ступное место не позволяет привести здесь полное описание. 1.7.8. Применение глубокого обучения в классификации текстур Как мы видели в предыдущих разделах, глубокое обуче ние стало основной движущей силой разработки алгоритмов зрения. В равной степени это от - носится и к анализу текстур, который был представлен в разделах 1.6.1–1.6.6. На рис. 1.31 показана архитектура классификатора текстур Лоуза, рассмот - ренного в разделе 1.6.3. Классификатор такого типа часто описывается как использующий набор «банков фильтров» для извлечения входной инфор- мации. Однако в предыдущем разделе показано, что аналогичным образом могут быть описаны методы CNN, поэтому неудивительно, что CNN (и ANN)\n--- Страница 126 ---\nЧасть F. От искусственных нейронных сетей к методам глубокого обучения  125 также применялись для анализа текстуры. Раньше такие сети обычно обу - чали, используя наборы входных изображений, каждое из которых состояло из одной текстуры, обычно из базы данных текстур Бродача (Brodatz textures database). Однако этот подход ограничен обработкой всего входного изо- бражения как одной области и соответствующей его классификацией: сег - ментация изображения на области с разными текстурами выходит за рамки возможностей простой архитектуры, обученной таким образом. Андреарчик и Уилан (Andrearczyk, Whelan, 2016) описали базовую архи- тектуру CNN (T-CNN-3) для классификации текстур, которая показана на рис. 1.37. Она имеет некоторое сходство с ZFNet, хотя содержит меньше слоев свертки; впрочем, это не мешает ей справляться с текстурами, потому что признаки текстуры в большинстве случаев можно описать с по мощью до- вольно маленьких окон. Также обратите внимание, что за последним слоем свертки следует слой объединения, который усредняет энергию текстуры по всей карте объектов. Тем не менее, поскольку значительное количество N карт признаков вычисляется различными параллельными слоями конеч- ного слоя свертки, результатом является вектор из N значений энергии. Они передаются в окончательный классификатор текстур, который дает один класс для любого одного входного изображения текстуры. 2272 3552 96272 256132 3841 40961 40961 1000Выход Изображение С1 S1С2 S2С3 E3F4 F5 Рис. 1.37  Архитектура T-CNN Андреарчика и Уилана. Она предназначена для захвата текстуры всего входного изображения и вывода вектора, указы- вающего на наиболее вероятную текстуру. Цифры под метками указывают раз- меры пространств признаков, обрабатываемых слоями свертки C1–C3, и ко- личество карт признаков в соответствующих слоях. Оба слоя объединения (S1, S2) уменьшают размер изображения в 2×2 раза. Энергетический слой E3 – это особый слой пулинга, который усредняет энергии полностью по каждой карте признаков, создавая 384 вывода, по одному для каждой карты признаков C3 Фактически Андреарчик и Уилан (Andrearczyk, Whelan, 2016) пошли еще дальше и разработали анализатор текстуры гибридного типа (TS-CNN-3), использующий как описанный выше метод, так и позволяющий анализиро-\n--- Страница 127 ---\n126  Кардинальные перемены в области компьютерного зрения вать формы объектов, причем последний действует аналогично системе рас - познавания объектов AlexNet для нетекстурированных изображений. Общая архитектура показана на рис. 1.38. Важным элементом этой архитектуры является слой конкатенации M, объединяющий выходные данные частей системы, обрабатывающих текстуры и формы. Но также важно отметить, что релевантная информация о текстуре в основном получается из относительно небольших признаков низкого уровня, тогда как информация о форме явля- ется более глобальным свойством, которое требует ввода признаков более высокого уровня. Вот почему информация о текстуре получается из выход- ных данных слоя свертки C3, тогда как информация о форме получается из пулинговых выходных данных C5. (Интересно, что, поскольку E3 усредняет энергию текстуры по всему характеристическому слою C3, в текстурном ка- нале после E3 не остается информации о пространстве или форме.) Наконец, выходные слои F6, F7 и O используются для объединения выходных данных формы и текстуры: ясно, что в этих слоях имеется достаточно информации, чтобы связать текстуры с определенными местами на входном изображении и представить выходные данные с точки зрения вероятностей того, что тек - стуры, используемые при обучении, действительно появляются на входном изображении. Впрочем, чего эта сеть не делает, так это создание карты вы- 2272 3552 96272 256132 384132 384132 3841 40961 40961 1000Выход Изображение С1 S1С2 S2 S5 MС3 E3С4 С5 F7 F6Обработка формы Обработка текстуры Рис. 1.38  Архитектура TS-CNN Андреарчика и Уилана. Она предназначена для захвата информации о текстуре и форме для всего входного изображе- ния и для вывода вектора, показывающего наиболее вероятный набор текстур. Первый ряд чисел под метками указывает размеры пространств признаков, обрабатываемых слоями свертки C1–C5; второй ряд чисел указывает номера карт объектов в соответствующих слоях. Все три слоя объединения (S1, S2, S5) уменьшают размер изображения в 2×2 раза, поэтому изображение, подаваемое в точку слияния M, имеет размер 6×6. В M выходные данные текстуры и формы объединяются, в результате чего получается в общей сложности 384 × (1 + 62) выходных данных – все из которых соединены со всеми входами F6, образуя полносвязную сеть. Как и на рис. 1.37, энергетический слой E3 является объеди- няющим слоем, который усредняет энергию по всей карте признаков, создавая 384 результата, по одному для каждой карты признаков C3\n--- Страница 128 ---\nЧасть F. От искусственных нейронных сетей к методам глубокого обучения  127 ходного изображения, показывающей наиболее вероятную разбивку изобра- жения на различные текстурные области. Было бы неплохо добиться этого, и в принципе это должно быть возможно за счет включения архитектуры кодер–декодер SegNet (раздел 1.7.6). Основным препятствием здесь являет - ся отсутствие достаточно больших наборов текстурных данных (сравнимых с ImageNet): на самом деле основная проблема заключается в том, что такие архитектуры, как SegNet, настолько глубоки, что требуют гораздо большего объема обуче ния с использованием гораздо большего количества обучающих шаблонов. Отсутствие большого набора текстурных данных является серьезным фак - тором, мешающим дальнейшему прогрессу в анализе текстур, какие бы ме- тоды обуче ния и архитектуры ни разрабатывались. И действительно, сегодня уже ясно, что если бы такой набор данных был доступен, AlexNet (и другие сети, такие как VGGNet) можно было бы обучить выполнять анализ текстур по всем изображениям без внесения каких-либо изменений в их архитекту - ру. Как отмечают исследователи (Liu et al., 2019): «Недавний успех глубокого обуче ния в классификации изображений и распознавании объектов неотде- лим от наличия крупномасштабных аннотированных наборов данных изо- бражений, таких как ImageNet. Однако анализ текстур на основе глубокого обуче ния не поспевает за быстрым прогрессом, наблюдаемым в других об- ластях, отчасти из-за отсутствия крупномасштабной базы данных текстур». Эти утверждения вполне обоснованы, потому что (а) архитектуры на ос - нове CNN уже являются одними из наиболее широко используемых средств выполнения анализа текстур и вряд ли утратят свои позиции в обозримом будущем; и (б) те же ограничения на обуче ние (и потребность в больших на- борах текстурных данных) справедливы для любых методов, которые будут использоваться для анализа текстурированных изображений. Следует также помнить, что статистический характер текстур подразумевает, что в целом процедуры, основанные на обучении, будут предпочтительнее созданных вручную алгоритмов. Наконец, сравним производительность двух архитектур Андреарчика и Уилана. При обучении на ImageNet, который представляет собой объект- ный набор данных, они обнаружили, что T-CNN-3 работает хуже, чем AlexNet (51,2 % против с 57,1 %), что не удивительно, потому что AlexNet – намного более крупная сеть по сравнению с 23,4 млн T-CNN-3. С другой стороны, при обучении с текстурно-ориентированными наборами данных, такими как Ima geNet-T и KTH-TIPS-2b (Russakovsky et al., 2015; Hayman et al., 2004), T-CNN3 показала значительное улучшение по сравнению с AlexNet (соот - ветствующая точность 71,1 % по сравнению с 66,3 % и 48,7 % по сравне- нию с 47,6 %). Эти результаты соответствуют обуче нию с нуля на одной базе данных. Однако также можно провести предварительную подготовку в од- ной базе данных и выполнить точную настройку в другой. Когда это было предпринято (в частности, выполнялось предварительное обуче ние на Ima- geNet и точная настройка на KTH-TIPS-2b), сеть T-CNN-3 работала точнее, чем AlexNet (73,2 % по сравнению с 71,5 %). Дальнейшее улучшение было достигнуто за счет использования гибридной архитектуры TS-CNN-3, при этом была достигнута точность 74,0 %. Частично это улучшение явно было\n--- Страница 129 ---\n128  Кардинальные перемены в области компьютерного зрения связано с большим количеством обучаемых параметров TS-CNN-3 (62,5 млн). Тем не менее, когда были проведены испытания архитектур с сопостави- мым количеством параметров, например комбинация AlexNet и T-CNN-3 и комбинация VGG-M (Chatfield et al., 2014) с FV-CNN (Cimpoi et al., 2015), сеть TS-CNN-3 осталась лучшей. Фактически отличительной чертой новой архитектуры TS-CNN-3 является то, что она очень эффективно использует параметры обуче ния, а за счет отделения анализа текстуры от анализа фор- мы достигаются более точные результаты при обработке текстурированных изображений. Мы не напрасно уделили такое внимание работе Андреарчика и Уилана, потому что она раскрывает множество идей о применении глубоких сетей для анализа текстур, включая ряд связанных с ними тонкостей. В то время как их подход нацелен на архитектуру с относительно небольшим количеством обучающих параметров, существует менее ограниченный подход (Cimpoi et al., 2015; 2016), который кажется более мощным: он систематически исполь- зует глобальный пулинг CNN до уровня полностью связанных слоев и, таким образом, захватывает ценные наборы дескрипторов текстуры. (Точнее, он выполняет более плотный пулинг локальных признаков, удаляя глобальную пространственную информацию, чтобы извлечь плотные сверточные при- знаки.) Действительно, в работе (Cimpoi et al., 2016 г.) продемонстрирована разработка словаря из сорока семи текстурных атрибутов, которые описыва- ют широкий выбор шаблонов текстур. Фактически эти работы оказали влия- ние на почти идеальную точность классификации. Однако Лю и др. (Liu et al., 2019) заявляют, что качество близко к «насыщению» (т. е. стабилизировалось на уровне около 100 %), «поскольку наборы данных недостаточно велики, чтобы можно было выполнить точную настройку для получения улучшенных результатов», что подтверждает ранее сделанные замечания о доступных наборах текстурных данных. Следует отметить, что наилучшие результаты были получены с использованием архитектуры VGG-VD (Very Deep) Симоня- на и Зиссермана (Simonyan, Zisserman, 2015), содержащей 19 слоев CNN, что частично объясняет, почему насыщение стало возможным. Еще один вопрос, поднятый в работе Лю и др. (Liu at al., 2019) в их обзоре развития представлений текстур, заключается в том, что существует расту - щее противоречие между потребностью сетей в огромных наборах данных изображений и соответствующей человеческой потребностью в компактных, эффективных представлениях. Последняя потребность все чаще проявляется на мобильных и встроенных платформах с ограниченными ресурсами, как ранее отмечали Андреарчик и Уилан (Andrearczyk, Whelan, 2016) и Сегеди и др. (Szegedy et al., 2014). 1.7.9. Анализ текстур в мире глубокого обучения Часть E началась с изучения определения текстуры – по сути, с вопроса «Что такое текстура и как она формируется?». Как правило, текстура начинается с участка поверхности, имеющего локальную шероховатость или структуру, который затем многократно проецируется для формирования текстуриро-\n--- Страница 130 ---\nЧасть G. Заключение  129 ванного изображения. Такое изображение демонстрирует как регулярность, так и случайность, хотя важными параметрами могут быть также направлен- ность и ориентация. Однако наличие важного признака случайности озна- чает, что текстуры должны характеризоваться статистическими методами и распознаваться с использованием процедур статистической классифика- ции. Методы, которые использовались для этой цели, включают автокорреля- цию, матрицы совместной встречаемости, меры энергии текстуры, меры на основе фракталов, марковские случайные поля и т. д. Они направлены как на анализ, так и на моделирование текстур. Специалистам в этой области при- ходилось тратить много времени на создание все более совершенных моде- лей текстур, с которыми они работают, чтобы лучше описывать, распознавать и сегментировать их. Однако менее чем за десятилетие DNN внезапно обрели самостоятельность, и, как мы убедились, это привело к стремительному раз- витию нейросетевых методов анализа текстур, что еще больше увело нас от прямых методов 1970-х годов. 1.8. Ч асть G. заКЛюЧение Части A–E этой главы посвящены трем весьма актуальным темам по обнару - жению признаков и объектов как в двухмерных, так и в трехмерных изобра- жениях. В них представлены базовые методы, которые широко применялись в компьютерном зрении до взрыва глубокого обуче ния в 2012 году. Часть F продолжает рассказ о том, что повлек за собой этот взрыв (в частности, что все признаки и объекты можно выучить на многочисленных обучающих примерах), но также и о том, как с по мощью сквозного обуче ния полных сверточных сетей может быть достигнута семантическая сегментация. По- жалуй, можно считать благотворным тот факт, что такие сети могут изучать все признаки и объекты и, по-видимому, не нуждаются в устаревших методах для их хранения. На самом деле семантическая сегментация статических сцен – не единственный наглядный пример, но, как показано в разделе 1.7.7, похожий процесс с впечатляющим успехом был реализован для отслежи - вания нескольких движущихся объектов. Действительно, как было указано в одной из статей (Feichtenhofer et al., 2017), многое из того, что раньше до- стигалось сложными способами путем жесткого применения правил модели, теперь достигается менее трудоемкими и сложными способами с по мощью методов глубокого обуче ния; и они способны поднять качество моделей на еще большие высоты, если приложить дополнительные усилия. Оглядываясь назад, создается впечатление, что исследователи столкнулись с метафориче - ской кирпичной стеной в отношении того, каким образом достаточно точно указать природу «мягких» данных в реальных (неидеализированных) изо- бражениях, которые они хотели обработать. Как следствие у них возникло желание хотя бы попробовать альтернативу глубокого обуче ния. На этом этапе будет полезно подытожить, что именно способствовало взрыву глубокого обуче ния. По сути, это было сочетание множества разроз- ненных факторов. В частности, мы можем указать на: (1) использование CNN\n--- Страница 131 ---\n130  Кардинальные перемены в области компьютерного зрения с гораздо более низкой связностью, чем в случае со старыми архитектурами ANN; (2) использование ReLU вместо сигмоидальных выходных функций; (3) применение процедуры «отсева» для ограничения случаев переобуче- ния; (4) использование значительно увеличенных объемов данных изобра- жений для обуче ния; (5) извлечение еще большего количества фрагментов изображения из изображений для дальнейшего увеличения объема данных, доступных для обуче ния; (6) применение графических процессоров для вы- полнения обуче ния с чрезвычайно высокой скоростью (принято считать, что графический процессор имеет 50-кратное преимущество в скорости по сравнению с типичным хост-процессором). Следует также помнить, что все эти изменения случились более или менее одновременно в 2012 г. На этом мы закончим наше несколько затянувшееся введение, поскольку в следующих главах приведено много дополнительных сведений о положе- нии дел в довольно сложной и быстро меняющейся отрасли компьютерного зрения. бЛагодарности Следующий текст и рисунки воспроизведены с разрешения IET: рисунок в тексте и связанный с ним текст в разделе 1.2.7 – из Electronics Letters (Da- vies, 1999); рис. 1.2 и связанный с ним текст – из Proc. Visual Information En- gineering Conf. (Davies, 2005); выдержки из текста – из Proc. Image Processing and its Applications Conf. (Davies, 1997). Рисунок 1.5 и соответствующий текст воспроизведены с разрешения IFS Publications Ltd. (Davies, 1984). Я также хочу отметить, что рис. 1.13 и 1.15 и связанный с ними текст были впервые опубликованы в Proceedings of the 4th Alvey Vision Conference (Davies, 1988b). Литературные исто ЧниКи Ade F., 1983. Characterization of texture by «eigenfilters». Signal Processing 5 (5), 451–457. Amit Y., Trouvé A., 2007. POP: patchwork of parts models for object recognition. International Journal of Computer Vision 75 (2), 267–282. Andrearczyk V., Whelan P., 2016. Using filter banks in convolutional neural net - works for texture classification. Pattern Recognition Letters 84, 63–69. Badrinarayanan V., Kendall A., Cipolla R., 2015. SegNet: a deep convolutional encoder-decoder architecture for image segmentation. arXiv:1511.00561v2 [cs CV]. Bai Y., Ma W., Li Y., Cao L., Guo W., Yang L., 2016. Multi-scale fully convolutional network for fast face detection. In: Proc. British Machine Vision Association Conference. York, 19–22 September. http://www.bmva.org/bmvc/2016/papers/ paper051/paper051.pdf. Ballard D. H., 1981. Generalizing the Hough transform to detect arbitrary shapes. Pattern Recognition 13, 111–122.\n--- Страница 132 ---\nЛитературные источники  131 Beaudet P. R., 1978. Rotationally invariant image operators. In: Proc. 4th Int. Conf. on Pattern Recognition. Kyoto, pp. 579–583. Bertinetto L., Valmadre J., Henriques J. F., Vedaldi A., Torr P. H. S., 2016. Fully- convolutional Siamese networks for object tracking. In: Proc. ECCVWorkshops, pp. 850–865. Brostow G., Fauqueur J., Cipolla R., 2009. Semantic object classes in video: a high- definition ground truth database. Pattern Recognition Letters 30 (2), 88–97. Canny J., 1986. A computational approach to edge detection. IEEE Transactions on Pattern Analysis and Machine Intelligence 8, 679–698. Castañón D. A., 1990. Efficient algorithms for finding the k best paths through a trellis. IEEE Transactions on Aerospace and Electronic Systems 26 (2), 405– 410. Chatfield K., Simonyan K., Vedaldi A., Zisserman A., 2014. Return of the devil in the details: delving deep into convolutional nets. In: Proc. BMVC, pp. 1–12. Cimpoi M., Maji S., Vedaldi A., 2015. Deep filter banks for texture recognition and segmentation. In: IEEE Conf. on Computer Vision and Pattern Recognition, pp. 3828–3836. Cimpoi M., Maji S., Kokkinos I., Vedaldi A., 2016. Deep filter banks for texture recognition, description and segmentation. International Journal of Computer Vision 118, 65–94. Cootes T. F., Taylor C. J., 2001. Statistical models of appearance for medical image analysis and computer vision. In: Sonka M., Hanson K. M. (Eds.), Proc. SPIE, Int. Soc. Opt. Eng. USA, vol. 4322, pp. 236–248. Cucchiara R., Grana C., Piccardi M., Prati A., 2003. Detectingmoving objects, ghosts and shadows in video streams. IEEE Transactions on Pattern Analysis and Ma- chine Intelligence 25 (10), 1337–1342. Dai J., Li Y., He K., Sun J., 2016. R-FCN: object detection via region-based fully convolutional networks. In: Proc. NIPS. Dalal N., Triggs B., 2005. Histograms of oriented gradients for human detection. In: Proc. Conf. on Computer Vision Pattern Recognition. San Diego, California, USA, pp. 886–893. Davies E. R., 1984. Design of cost-effective systems for the inspection of certain food products during manufacture. In: Pugh, A. (Ed.), Proc. 4th Int. Conf. on Robot Vision and Sensory Controls. London, 9–11 October. IFS (Publications) Ltd, Bedford and North-Holland, Amsterdam, pp. 437–446. Davies E. R., 1986. Constraints on the design of template masks for edge detection. Pattern Recognition Letters 4 (2), 111–120. Davies E. R., 1988a. A modified Hough scheme for general circle location. Pattern Recognition Letters 7 (1), 37–43. Davies E. R., 1988b. An alternative to graph matching for locating objects from their salient features. In: Proc. 4th Alvey Vision Conf. Manchester, 31 Aug.– 2 Sept., pp. 281–286. Davies E. R., 1988c. Median-based methods of corner detection. In: Kittler, J. (Ed.), Proceedings of the Fourth BPRA International Conference on Pattern Recogni- tion. Cambridge, 28–30 March. In: Lecture Notes in Computer Science, vol. 301. Springer-Verlag, Heidelberg, pp. 360–369.\n--- Страница 133 ---\n132  Кардинальные перемены в области компьютерного зрения Davies E. R., 1997. Designing efficient line segment detectors with high orientation accuracy. In: Proc. 6th IEE Int. Conf. on Image Processing and Its Applications. Dublin, 14–17 July. In: IEE Conf. Publication, vol. 443, pp. 636–640. Davies E. R., 1999. Designing optimal image feature detection masks: equal area rule. Electronics Letters 35 (6), 463–465. Davies E. R., 2005. Using an edge-based model of the Plessey operator to determine localisation properties. In: Proc. IET Int. Conf. on Visual Information Engineer - ing. University of Glasgow, Glasgow, 4–6 April, pp. 385–391. Davies E. R., 2017. Computer Vision: Principles, Algorithms, Applications, Learn- ing, 5th edition. Academic Press, Oxford, UK. Davies E. R., Bateman M., Mason D. R., Chambers J., Ridgway C., 2003. Design of efficient line segment detectors for cereal grain inspection. Pattern Recognition Letters 24 (1–3), 421–436. Dreschler L., Nagel H.-H., 1981. Volumetric model and 3D-trajectory of a moving car derived from monocular TVframe sequences of a street scene. In: Proc. Int. Joint Conf. on Artif. Intell., pp. 692–697. Dudani S. A., Luk A. L., 1978. Locating straight-line edge segments on outdoor scenes. Pattern Recognition 10, 145–157. Elgammal A., Harwood D., Davis L., 2000. Non-parametric model for background subtraction. In: Proc. European Conf. on Computer Vision. In: LNCS, vol. 1843, pp. 751–767. Everingham M., Van Gool L., Williams C. K. I., Winn J., Zisserman A. , 2007. The Pascal visual object classes challenge 2007. (VOC2007) Results. http://www. pascalnetwork.org/challenges/VOC/voc2007/. Everingham M., Van Gool L., Williams C. K. I., Winn J., Zisserman A., 2008. The Pascal visual object classes challenge 2008. (VOC2008) Results. http://www. pascalnetwork.org/challenges/VOC/voc2008/. Everingham M., Zisserman A., Williams C. K. I., Van Gool L., 2006. The Pascal visual object classes challenge 2006. (VOC2006) Results. http://www.pascalnetwork. org/challenges/VOC/voc2006/. Fathy M. E., Hussein A. S., Tolba M. F., 2011. Fundamental matrix estimation: a study of error criteria. Pattern Recognition Letters 32 (2), 383–391. Faugeras O., Luong Q.-T., Maybank S. J., 1992. Camera self-calibration: theory and experiments. In: Sandini, G. (Ed.), Proc. 2nd European Conf. on Computer Vi- sion. In: Lecture Notes in Computer Science, vol. 588. Springer-Verlag, Berlin Heidelberg, pp. 321–334. Feichtenhofer C., Pinz A., Zisserman A., 2017. Detect to track and track to detect. In: Proc. ICCV, pp. 3038–3046. Felzenszwalb P. F., Girshick R. B., McAllester D., Ramanan D., 2010. Object detection with discriminatively trained part based models. IEEE Transactions on Pattern Analysis and Machine Intelligence 32 (9), 1627–1645. Fischler M. A., Bolles R. C., 1981. Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography. Com- munications of the ACM 24 (6), 381–395. Girshick R. B., 2015. Fast R-CNN. In: Proc. ICCV. 2015. Haralick R. M., Shanmugam K., Dinstein I., 1973. Textural features for image clas- sification. IEEE Transactions on Systems, Man and Cybernetics 3 (6), 610–621.\n--- Страница 134 ---\nЛитературные источники  133 Harris C., Stephens M., 1988. A combined corner and edge detector. In: Proc. 4th Alvey Vision Conf., pp. 147–151. Hartley R. I., 1995. A linear method for reconstruction from lines and points. In: Proc. Int. Conf. on Computer Vision, pp. 882–887. Hartley R. I., Sturm P., 1994. Triangulation. In: American Image Understanding- Workshop, pp. 957–966. Hayman E., Caputo B., Fritz M., Eklundh J.-O., 2004. On the significance of real- world conditions for material classification. In: ECCV, pp. 253–266. He K., Zhang X., Ren S., Sun J., 2016. Deep residual learning for image recognition. In: Proc. CVPR. Held D., Thrun S., Savarese S., 2016. Learning to track at 100 fps with deep regres- sion networks. In: Proc. ECCV. Springer, pp. 749–765. Hinton G. E., 2002. Training products of experts by minimizing contrastive diver - gence. Neural Computation 14 (8), 1771–1800. Hinton G. E., Srivastava N., Krizhevsky A., Sutskever I., Salakhutdinov R. R., 2012. Improving neural networks by preventing co-adaptation of feature detectors. arXiv:1207.0580v1 [cs.NE]. Horprasert T., Harwood D., Davis L. S., 1999. A statistical approach for real-time ro- bust background subtraction and shadow detection. In: Proc. IEEE ICCV Frame- Rate Applications Workshop, pp. 1–19. Hsiao J. Y., Sawchuk A. A., 1989a. Supervised textured image segmentation using feature smoothing and probabilistic relaxation techniques. IEEE Transactions on Pattern Analysis and Machine Intelligence 11 (12), 1279–1292. Hsiao J. Y., Sawchuk A. A., 1989b. Unsupervised textured image segmentation using feature smoothing and probabilistic relaxation techniques. Computer Vision, Graphics, and Image Processing 48, 1–21. ImageNet, 2015. ImageNet large scale visual recognition challenge (ILSVRC2015). http://image-net.org/challenges/LSVRC/2015/. Janney P., Geers G., 2010. Texture classification using invariant features of local textures. IET Image Processing 4 (3), 158–171. Kaizer H., 1955. A quantification of textures on aerial photographs. MS thesis. Boston Univ. Kalal Z., Mikolajczyk K., Matas J., 2011. Tracking-learning-detection. IEEE Trans- actions on Pattern Analysis and Machine Intelligence 34 (7), 1409–1422. Kanatani K., 1996. Statistical Optimization for Geometric Computation: Theory and Practice. Elsevier, Amsterdam, the Netherlands. Kitchen L., Rosenfeld A., 1982. Gray-level corner detection. Pattern Recognition Letters 1, 95–102. Krizhevsky A., Sutskever I., Hinton G. E., 2012. ImageNet classification with deep convolutional neural networks. In: Proc. 26th Annual Conf. on Neural Informa- tion Processing Systems. Lake Tahoe, Nevada, pp. 3–8. Laws K. I., 1979. Texture energy measures. In: Proc. Image UnderstandingWork - shop, Nov., pp. 47–51. Laws K. I., 1980a. Rapid texture identification. In: Proc. SPIE Conf. on Image Pro- cessing for Missile Guidance, 238. San Diego, Calif. 28 July – 1 Aug., pp. 376–380. Laws K. I., 1980b. Textured Image Segmentation. PhD thesis. Univ. of Southern California, Los Angeles.\n--- Страница 135 ---\n134  Кардинальные перемены в области компьютерного зрения LeCun Y., Boser B., Denker J. S., Henderson D., Howard R. E., Hubbard W., Jackel L. D., 1989. Backpropagation applied to handwritten zip code recognition. Neural Computation 1 (4), 541–551. LeCun Y., Bottou L., Bengio Y., Haffner P., 1998. Gradient-based learning applied to document recognition. Proceedings of the IEEE 86, 2278–2324. Lee S. H., Civera J., 2019. Triangulation: why optimize? vol. 23. arXiv:1907.11917v2 [cs.CV]. Leibe B., Leonardis A., Schiele B., 2008. Robust object detection with interleaved categorization and segmentation. International Journal of Computer Vision 77 (1), 259–289. Lipton A. J., Fujiyoshi H., Patil R. S., 1998. Moving target classification and tracking from real-time video. In: Proc. 4th IEEEWorkshop on Applications of Computer Vision, pp. 8–14. Liu L., Chen J., Fieguth P., Zhao G., Chellappa R., Pietikäinen M., 2019. From BoW to CNN: two decades of texture representation for texture classification. Inter - national Journal of Computer Vision 127, 74–109. Lo B. P. L., Velastin S. A., 2001. Automatic congestion detection system for under - ground platforms. In: Proc. Int. Symposium on Intelligent Multimedia, Video and Speech Processing, pp. 158–161. Longuet-Higgins H. C., 1981. A computer algorithm for reconstructing a scene from two projections. Nature 293, 133–135. Magee M. J., Aggarwal J. K., 1984. Determining vanishing points from perspective images. Computer Vision, Graphics, and Image Processing 26 (2), 256–267. Mathias M., Benenson R., Pedersoli M., Van Gool L., 2014. Face detection without bells and whistles. In: Proc. 13th European Conf. on Computer Vision. Zurich, Switzerland, 8–11 September. Mirmehdi M., Xie X., Suri J. (Eds.), 2008. Handbook of Texture Analysis. Imperial College Press, London. Nagel H.-H., 1983. Displacement vectors derived from second-order intensity variations in image sequences. Computer Vision, Graphics, and Image Process- ing 21, 85–117. Noh H., Hong S., Han B., 2015. Learning deconvolution network for semantic segmentation. In: Proc. IEEE Int. Conf. on Computer Vision. Santiago, Chile, 13–16 December, pp. 1520–1528. Pietikäinen M., Rosenfeld A., Davis L. S., 1983. Experiments with texture classifica- tion using averages of local pattern matches. IEEE Transactions on Systems, Man and Cybernetics 13 (3), 421–426. Ren S., He K., Girshick R., Sun J., 2015. Faster R-CNN: towards real-time object detection with region proposal networks. arXiv:1506.01497 [cs.CV]. Rosenfeld A., Troy E. B., 1970a. Visual Texture Analysis. Computer Science Center, Univ. ofMaryland. Techn. Report TR-116. Rosenfeld A., Troy E. B., 1970b. Visual texture analysis. In: Conf. Record for Sym- posium on Feature Extraction and Selection in Pattern Recognition, IEEE Pub- lication 70C-51C, Argonne, Ill., pp. 115–124. Russakovsky O., Deng J., Su H., Krause J., Satheesh S., Ma S., Huang Z., Karpathy A., Khosla, A. Bernstein M., Berg C., Fei-Fei L., 2015. ImageNet large scale visual rec - ognition challenge. International Journal of Computer Vision 115 (3), 211–252.\n--- Страница 136 ---\nОб авторе главы  135 Shah M. A., Jain R., 1984. Detecting time-varying corners. Computer Vision, Graph- ics, and Image Processing 28, 345–355. Simonyan K., Zisserman A. , 2015. Very deep convolutional networks for large-scale image recognition. arXiv:1409. 1556v6. Stalder S., Grabner H., van Gool L., 2009. Beyond semi-supervised tracking: track - ing should be as simple as detection, but not simpler than recognition. In: IEEE 12Th Int. Conf. on Workshop on On-Line Learning for Computer Vision. Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., 2014. Going deeper with convolutions. arXiv:1409.4842v1 [cs.CV]. Tighe J., Lazebnik S., 2013. Finding things: image parsing with regions and per- exemplar detectors. In: Proc. IEEE Conf. on Computer Vision and Pattern Rec - ognition. Portland, Oregon, 23–28 June, pp. 3001–3008. Torr P., Zisserman A., 1997. Performance characterization of fundamental matrix estimation under image degradation. Machine Vision and Applications 9 (5), 321–333. Unser M., 1986. Local linear transforms for texture measurements. Signal Process- ing 11, 61–79. Unser M., Eden M., 1989. Multiresolution feature extraction and selection for texture segmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence 11 (7), 717–728. Unser M., Eden M., 1990. Nonlinear operators for improving texture segmentation based on features extracted by spatial filtering. IEEE Transactions on Systems, Man and Cybernetics 20 (4), 804–815. Vistnes R., 1989. Texture models and image measures for texture discrimination. International Journal of Computer Vision 3, 313–336. Wu Z., Thangali A., Sclaroff S., Betke M., 2012. Coupling detection and data asso- ciation for multiple object tracking. In: Proc. IEEE Conf. CVPR, pp. 1948–1955. Yang Y., Li Z., Zhang L., Murphy C., Ver Hoeve J., Jiang H., 2012. Local label descrip- tor for example based semantic image labelling. In: Proc. 12th European Conf. on Computer Vision. Florence, Italy, 7–13 October, pp. 361–375. Zeiler M., Fergus R., 2014. Visualizing and understanding convolutional neural networks. In: Proc. 13th European Conf. on Computer Vision. Zurich, Switzer - land, 8–11 September. Zhang L., Wu B., Nevatia R., 2007. Pedestrian detection in infrared images based on local shape features. In: Proc. 3rd Joint IEEE Int. Workshop on Object Tracking and Classification in and Beyond the Visible Spectrum. Zuniga O. A., Haralick R. M., 1983. Corner detection using the facet model. In: Proc. IEEE Conf. on Computer Vision and Pattern Recognition, pp. 30–37. об аВторе гЛаВы Рой Дэвис – почетный профессор факультета машинного зрения в Роял Хол- лоуэй, Лондонский университет. Он работал над многими аспектами зрения, от обнаружения признаков и подавления шума до робастного сопоставления\n--- Страница 137 ---\n136  Кардинальные перемены в области компьютерного зрения образов и реализации практических задач зрения в реальном времени. Об- ласть его интересов включает автоматизированный осмотр объектов, наблю- дение, управление транспортными средствами и раскрытие преступлений. Он опубликовал более 200 статей и три книги: Machine Vision: Theory, Al- gorithms, Practicalities (1990 г.), Electronics, Noise and Signal Recovery (1993 г.) и Image Processing for the Food Industry (2000 г.); первая из них не теряет по- пулярности на протяжении 25 лет, а в 2017 г. вышло ее значительно расши- ренное, пятое издание под названием Computer Vision: Principles, Algorithms, Applications, Learning. Рой является членом IoP и IET, а также старейшим членом IEEE. Он входит в редакционные коллегии журналов Pattern Recogni- tion Letters , Real-Time Image Processing , Imaging Science and IET Image Processing. Получил степень доктора наук в Лондонском университете; в 2005 г. он был удостоен титула почетного члена BMVA, а в 2008 г. стал лауреатом премии Международной ассоциации распознавания образов.",
      "debug": {
        "start_page": 28,
        "end_page": 137
      }
    },
    {
      "name": "Глава 2. Современные методы робастного обнаружения объектов 137",
      "content": "--- Страница 138 --- (продолжение)\nГлава 2 Современные методы робастного обнаружения объектов Авторы главы: Чжаовэй Цай, Amazon Web Services, Пасадена, Калифорния, США; Нуно Васконселос, Калифорнийский университет в Сан-Диего, факультет электроники и вычислительной техники, Сан-Диего, Калифорния, США Краткое содержание главы: знакомство с задачей обнаружения объектов в компьютерном зрении; рассмотрены некоторые усовершенствованные детекторы объектов, ос - нованные на глубоких нейронных сетях, и некоторые методы, которые приобрели особое значение в публикациях по обнаружению объектов в последние годы. 2.1. В Ведение Обнаружение объектов – одна из самых фундаментальных и сложных задач компьютерного зрения. Она обобщает более изученную задачу классифика- ции объектов. При наличии конкретного изображения распознавание объ- ектов ищет ответ на вопрос «что». Что за предметы изображены на рисунке? Например, изображение на рис. 2.1 включает в себя человека и судно. Поми- мо вопроса «что», обнаружение объектов также ищет ответ на вопрос «где». В каких областях изображения находится объект? Пример ответа показан на рис. 2.1b, где для разграничения области расположения каждого объекта используются ограничивающие прямоугольники. Обнаружение объектов имеет множество практических применений. На- пример, автономные транспортные средства полагаются на обнаружение объектов для локализации объектов, понимания окружающей среды и при-\nГлава 2 Современные методы робастного обнаружения объектов Авторы главы: Чжаовэй Цай, Amazon Web Services, Пасадена, Калифорния, США; Нуно Васконселос, Калифорнийский университет в Сан-Диего, факультет электроники и вычислительной техники, Сан-Диего, Калифорния, США Краткое содержание главы: знакомство с задачей обнаружения объектов в компьютерном зрении; рассмотрены некоторые усовершенствованные детекторы объектов, ос - нованные на глубоких нейронных сетях, и некоторые методы, которые приобрели особое значение в публикациях по обнаружению объектов в последние годы. 2.1. В Ведение Обнаружение объектов – одна из самых фундаментальных и сложных задач компьютерного зрения. Она обобщает более изученную задачу классифика- ции объектов. При наличии конкретного изображения распознавание объ- ектов ищет ответ на вопрос «что». Что за предметы изображены на рисунке? Например, изображение на рис. 2.1 включает в себя человека и судно. Поми- мо вопроса «что», обнаружение объектов также ищет ответ на вопрос «где». В каких областях изображения находится объект? Пример ответа показан на рис. 2.1b, где для разграничения области расположения каждого объекта используются ограничивающие прямоугольники. Обнаружение объектов имеет множество практических применений. На- пример, автономные транспортные средства полагаются на обнаружение объектов для локализации объектов, понимания окружающей среды и при-\n--- Страница 139 ---\n138  Современные методы робастного обнаружения объектов нятия безопасных решений. В медицинской визуализации детекторы объ- ектов могут помочь определить местонахождение поражений при медицин- ском сканировании, облегчая работу рентгенологов и других медицинских специалистов. Однако обнаружение объектов также часто является базовой операцией в компьютерном зрении, на результаты которой опираются мно- гие последующие задачи, такие как визуальные ответы на вопросы, субтит - ры, визуальная навигация, захват предметов роботом, оценка позы и т. д. Например, обнаружение объекта может не только помочь роботу точно рас - познать объекты в физическом мире, но и позволяет ему понять семантику этого объекта – как он связан с другими объектами в сцене и какую роль он может играть в решении задачи, в одиночку или в команде роботов. Следо- вательно, развитие обнаружения объектов принесет пользу многим другим областям компьютерного зрения и сделает системы компьютерного зрения более эффективными в целом. судно человексудно человек (a) (b) Рис. 2.1  Различие между классификацией и обнаружением объектов Детектор объектов сталкивается со многими проблемами. Например, тре- буется точное обнаружение объектов нескольких категорий, масштабов, со- отношений сторон и т. д., иногда в условиях плохого освещения, окклюзии и фоновых отвлекающих факторов. Это затрудняет разработку детекторов, достаточно надежных, чтобы хорошо работать в широком диапазоне реаль- ных сценариев, что является необходимым условием для имитации зритель- ной системы человека. У сложной проблемы обнаружения объектов существует долгая история исследований (Sung and Poggio, 1998; Rowley et al., 1996; Papageorgiou et al., 1998). Ранние работы были сосредоточены на обнаружении конкретных объ - ектов, а именно лиц и людей, важных для многих приложений. Заметной ве- хой среди этих работ стал детектор Виолы–Джонса (VJ) (Viola and Jones, 2001, 2004). Это был первый детектор объектов в реальном времени для неограни- ченных сред, и он работал намного быстрее, чем все другие конкурирующие детекторы того времени. Идея состояла в том, чтобы сформулировать де- тектор как каскад классификаторов, которые поэтапно отвергают гипотезы об объекте, используя очень простые вейвлет-признаки Хаара (или прос -\n--- Страница 140 ---\nПредварительные положения  139 то признаки Хаара). Добавляя дополнительные признаки на более поздних этапах, каскад может сформировать мощный детектор. Однако поскольку большинство гипотез можно отвергнуть с по мощью простых признаков (на ранних стадиях), средняя вычислительная нагрузка невелика. Хотя вейвлеты работают быстро, они не очень точны. В более поздних работах была пред- ложена гистограмма ориентированных градиентов (histogram of oriented gra- dients, HOG) (Dalal and Triggs, 2005) в качестве важного улучшения функции масштабно-инвариантного преобразования признаков (scale-invariant feature transform, SIFT) (Lowe, 1999, 2004). Метод HOG показал очень впечатляющую производительность, первоначально при обнаружении человека, а позже получил широкое распространение в различных задачах обнаружения объек - тов. Прорывом в обнаружении обобщенного объекта стало появление модели деформируемых частей (deformable part-based model, DPM) (Felzenszwalb et al., 2010). Она основана на признаках HOG, представляющих каждый объект как комбинацию корневой модели и деформируемых частей, где конфигура- ции фильтров частей были скрытыми переменными, изучаемыми автомати- чески. В 2007, 2008 и 2009 гг. модель DPM стала победителем конкурса Pascal VOC по обнаружению объектов (Everingham et al., 2010), который включает обнаружение 20 категорий объектов, таких как стол, автобус, человек или ве- лосипед. Этот успех сделал DPM структурой по умолчанию для исследования обнаружения объектов до появления глубокого обуче ния. В последние годы было показано, что представления изученных призна- ков, извлеченные с по мощью глубоких сверточных нейронных сетей (CNN), значительно превосходят даже лучшие созданные вручную признаки, такие как SIFT, HOG и вейвлеты Хаара. Хотя обычные представления признаков CNN обладают высокой эффективностью классификации, их применение для обнаружения объектов требует нетривиальных расширений. В отличие от классификации, обнаружение объектов требует решения двух задач. Во- первых, детектор должен решить проблему распознавания, отличая объекты переднего плана от фона и присваивая им соответствующие метки классов объектов. Во-вторых, детектор должен решать проблему локализации, на- значая точные ограничивающие рамки различным объектам. В этой главе мы рассмотрим системы обнаружения объектов на основе CNN, предложенные за последние несколько лет. Их можно разделить на две основные группы: двухэтапные детекторы объектов , такие как R-CNN (Girshick et al., 2014), SPP-Net (He et al., 2014), Fast R-CNN (Girshick, 2015), Faster R-CNN (Ren et al., 2017), MS-CNN (Cai et al., 2016), FPN (Lin et al., 2017a) и Cascade R-CNN (Cai, Vasconcelos, 2021), и одноэтапные детекторы объектов, включая YOLO (Red- mon et al., 2016), SSD (Liu et al., 2016) и RetinaNet (Lin et al., 2017). 2.2. предВарите Льные поЛожения Большинство современных детекторов объектов реализуют комбинацию классификации и регрессии ограничивающей рамки. Классификация пы- тается предсказать класс объекта в области изображения, а регрессия огра-\n--- Страница 141 ---\n140  Современные методы робастного обнаружения объектов ничивающей рамки пытается определить область расположения объекта, предсказывая самую узкую рамку, содержащую объект. Рассмотрим эталон ограничительной рамки g, связанный с меткой класса y, и гипотезу обнару - жения x ограничительной рамки b. Поскольку b обычно включает в себя объ- ект и некоторое количество фона, может быть трудно определить, правильно ли обнаружен объект. Обычно это решается с по мощью метрики пересечения по объединению (intersection over union, IoU): (2.1) Если IoU выше порога u, x считается примером класса объекта ограничива - ющей рамки g и обозначается как «положительный» пример. Таким образом, метка класса гипотезы x является функцией u : (2.2) Если IoU не превышает порога для любого объекта, x считается фоном и обозначается как «отрицательный» пример. Хотя нет необходимости определять положительные/отрицательные при- меры для задачи регрессии ограничивающей рамки, порог IoU u также тре- буется для выбора набора образцов 𝒢 = {(g i, bi)|IoU(g i, bi) ³ u}, (2.3) используемого для обуче ния регрессора. Хотя пороговые значения IoU, при- меняемые для двух задач, не обязательно должны быть идентичными, на практике это обычное дело. Следовательно, порог IoU u определяет качество детектора. Большие пороги способствуют тому, чтобы обнаруженные огра- ничивающие рамки были точно совмещены с эталонами. Небольшие пороги вознаграждают детекторы, которые создают свободные ограничивающие рамки с небольшим перекрытием с эталоном. Некоторые примеры гипотез повышения качества показаны на рис. 2.2. Рис. 2.2  Примеры повышения качества. Числа представляют собой значе- ния IoU (2.1) между двумя ограничивающими прямоугольниками, указывая, на- сколько хорошо они совмещены друг с другом\n--- Страница 142 ---\nR-CNN  141 2.3. R-CNN Сеть R-CNN (Girshick et al., 2014) (Regions with CNN, области с CNN) была новаторской попыткой использовать глубокие нейронные сети для обобщен- ного обнаружения объектов. Это была первая работа, которая превзошла ме- тоды в стиле DPM за счет использования мощных представлений признаков CNN. Она также продемонстрировала, что признаки CNN, предварительно обученные для классификации в ImageNet (Russakovsky et al., 2015), могут быть успешно уточнены для других последующих задач, например обнару - жения, сегментации и т. д. 2.3.1. Внутреннее устройство R-CNN состоит из трех модулей, показанных на рис. 2.3. Поскольку вычисле- ния CNN являются дорогостоящими, первым шагом является создание пред- ложений областей, не зависящих от категорий, с использованием выбороч- ного поиска (van de Sande et al., 2011). Эти предложения определяют набор обнаружений-кандидатов, доступных для детектора, уменьшая количество гипотез обнаружения с миллионов до тысяч. Второй шаг – извлечение при- знаков из каждой предложенной области с использованием CNN, обученной распознаванию, например AlexNet (Krizhevsky et al., 2012) или VGG-Net (Si- monyan, Zisserman, 2014). Обнаруженные предложения произвольного мас - штаба и размеров сначала обрезаются и деформируются до размера входных данных сети. Затем изображения с измененным размером пропускаются через CNN, а выходные данные предпоследнего сетевого слоя используются в качестве представления признаков для каждого предложения. Наконец, третий модуль, реализованный с по мощью линейных SVM для конкретных классов, создает прогнозы классов для предложений. Для лучшей локализа- ции применяются дополнительные регрессоры ограничивающей рамки для уточнения ограничивающих рамок обнаруженных объектов. R-CNN: области с признаками CNN искаженная область CNNсамолет? нет человек? да телевизор? нет 1. Входное изображение2. Извлечение предложений (~ 2000)3. Вычисление признаков CNN4. Классификация областей Рис. 2.3  Внутреннее устройство R-CNN\n--- Страница 143 ---\n142  Современные методы робастного обнаружения объектов 2.3.2. Обучение CNN, используемая для извлечения признаков, предварительно обучена в за- даче классификации ImageNet (Russakovsky et al., 2015) и точно настроена на искаженные области предложений, используемые в задаче обнаружения. Точная настройка представляет собой задачу классификации K + 1 с K кате- гориями объектов и одним фоновым классом (например, K = 20 для набора данных VOC (Everingham et al., 2010) и K = 80 для набора данных COCO (Lin et al., 2014)). Поскольку CNN нуждаются в больших объемах данных, недо- статочно использовать эталоны только в качестве положительных примеров. Решение состоит в том, чтобы использовать все предложения с IoU выше 0,5 относительно ближайшей рамки эталона как положительные, а остальные – как отрицательные. Во время обуче ния важно соблюдать сбалансированное соотношение между положительными и отрицательными предложениями. На практике положительные и отрицательные результаты отбираются равно- мерно из пула эталонов с соотношением 1:3 в каждой обучающей партии. Тонкая настройка сводит к минимуму перекрестную энтропийную потерю Lcls(h(x), y) = –log hy(x), (2.4) где x – предложение по классификации, y – метка класса, а h(x) – класси- фикатор. После тонкой настройки линейные классификаторы SVM для конкретных категорий и регрессоры ограничительной рамки обучаются на признаках предложения, сгенерированных CNN. Эта многоступенчатая процедура обуче ния извлечения признаков, точной настройки CNN с кросс- энтропийной потерей, обуче ния SVM и настройки регрессоров с ограничи- тельной рамкой является медленной, утомительной и неэлегантной. 2.4. сеть SPP-N Et Хотя R-CNN значительно повысил общую производительность обнаруже - ния объектов, это сложный детектор, поскольку дорогостоящие вычисления CNN повторяются для тысяч предложений, полученных из каждого отдель- ного изображения. В результате прогон детектора R-CNN на каждом изо- бражении может занять более 30 с. Поскольку предложения, извлеченные из изображения, имеют наибольшее количество пикселей, большинство этих вычислений являются избыточными. Эту избыточность удалось уменьшить с по мощью SPP-Net (He et al., 2014), которая разделяла вычисления между предложениями. В отличие от конвейера R-CNN, который обрезает предложения перед вычислением CNN, как показано на рис. 2.4 (вверху), SPP-Net пересыла- ет изобра жение через сверточные слои сети целиком. Затем использует - ся пулинг пространственных пирамид (spatial pyramid pooling, Lazebnik et al., 2006) для извлечения признаков фиксированной длины из обрезанных карт признаков, связанных с каждым предложением. Эти признаки фикси-\n--- Страница 144 ---\nСеть Fast R-CNN  143 рованной длины, наконец, вводятся в набор полностью связанных слоев для окончательного прогноза, как показано на рис. 2.4 (внизу). Это простое из- менение позволяет совместно использовать дорогостоящие вычисления CNN между предложениями, и все изображение обрабатывается только один раз. Важной операцией является пространственный пирамидальный пулинг (spa- tial pyramid pooling, SPP), операция, показанная на рис. 2.5, которая отобра- жает экземплярные признаки произвольного масштаба и размера в вектор фиксированной длины. Это было первое доказательство того, что для при- знаков из сверточной карты признаков можно выполнить пространственный пулинг для создания экземплярного представления объектов с хорошими свойствами для распознавания экземпляров. Это вдохновило исследовате- лей на последующие разработки, такие как Fast R-CNN. изображение изображениевыход выходполносвязные слои полносвязные слоислои свертки слои сверткиобрезка/искажение простр. пирам. пулинг Рис. 2.4  Сравнение конвейеров R-CNN (вверху) и SPP-Net (внизу) fully-connected layers (fc 6, fc7) Представление фиксированной длины Слой пространственного пирамидального пулинга Карта признаков conv 5 Сверточные слои Входное изображениеОкно Рис. 2.5  Конвейер SPP-Net для обнаружения объектов 2.5. сеть FASt R-CNN Архитектура SPP-Net наследует утомительную многоступенчатую процедуру обуче ния R-CNN. В архитектуре Fast R-CNN это делается значительно проще. В этом подходе извлечение признаков, точное дообучение сети для новой\n--- Страница 145 ---\n144  Современные методы робастного обнаружения объектов задачи, классификация по экземплярам и регрессия с ограничительной рам - кой интегрированы в единую структуру, что позволяет легко использовать обнаружение объектов на основе глубокого обуче ния. 2.5.1. Архитектура Конвейер Fast R-CNN показан на рис. 2.6. Подобно SPP-Net, сеть Fast R-CNN пересылает все изображение через сверточные слои CNN для создания карт признаков. Затем слой пулинга видимой области (region of interest, RoI) при- меняется для извлечения вектора признаков фиксированной длины для каж - дого предложения объекта. Наконец, два полносвязных (fully connected, FC) слоя используются для окончательных прогнозов: вероятности классифика- ции для K + 1 классов и регрессии четырех координат ограничивающей рам- ки. В отличие от R-CNN и SPP-Net, Fast R-CNN обучается от начала до конца с многозадачной функцией потерь, что позволяет избежать утомительной многоэтапной процедуры обуче ния. Глубокая сеть ConvNet Проекция RoI Сверточная карта признаковСлой пулинга RoIВыходы: softmaxРегрессор bbox FC FC FC Вектор признаков RoI Для каждой RoI Рис. 2.6  Конвейер Fast R-CNN 2.5.2. Пулинг ROI Операция пулинга RoI представляет собой более простую версию простран- ственного пирамидального пулинга, показанного на рис. 2.5. Вместо того чтобы выполнять пулинг RoI с высотой и шириной (h , w) в различные про- странственные разрешения (1×1, 2×2 и 4×4) и объединять их вместе, как в SPP , при объединении RoI используется одно разрешение H×W, например 7×7. При заданном окне RoI размером h×w пулинг RoI делит его на подокна H×W, каждое из которых имеет размер h/H × w/W. Затем внутри каждого подокна применяется max-пулинг для извлечения наибольшего значения признака. Этот процесс применяется независимо к каждому каналу карты признаков. Хотя пулинг RoI проще, чем SPM, он все же может эффективно извлекать мощное представление признаков для предложений произвольного размера и масштаба из предварительно вычисленных сверточных карт признаков. Это критическое требование для функции обнаружения объекта.\n--- Страница 146 ---\nСеть Fast R-CNN  145 2.5.3. Многозадачная функция потери Fast R-CNN обучается двум задачам обуче ния: классификации и регрессии ограничивающей рамки. Они совместно оптимизируются во время обуче ния с использованием многозадачной функции потери L= Lcls(h(x), y) + λ[y ³ 1]L loc(f(x, b), g), (2.5) где λ управляет балансом между двумя требованиями. [у ³ 1] равно 1, когда у ³ 1, и равно 0 в противном случае, что означает отсутствие регрессионной потери ограничивающей рамки для фонового класса. Классификация Классификатор представляет собой функцию h(x), которая присваива- ет участок изображения x одному из K + 1 классов, где класс 0 содержит фон, а остальные классы – объекты для обнаружения. Фактически h(x) – это (K + 1)-мерная оценка апостериорного распределения по классам, т. е. hk(x) = p(y = k|x), где y – метка класса. L cls – кросс-энтропийные потери (2.4). Регрессия ограничивающей рамки Ограничивающая рамка b = (bx, by, bw, bh) содержит четыре координаты фраг - мента изображения x. Регрессия ограничивающей рамки направлена на ре- грессию потенциальной ограничивающей рамки b в целевую ограничива- ющую рамку g с использованием регрессора f(x, b). Регрессионная функция потерь имеет вид (2.6) где (2.7) – это гладкая функция потерь L1. Это комбинация потерь L1 и L2, которая ведет себя как потеря L1, когда |x | < 1, и потеря L2 в противном случае. Она исправляет негладкое поведение потери L1, т. е. когда градиент равен –1, при отрицательном x, и 1 в противном случае. Плавная потеря L1 может обеспе- чить более стабильное поведение при обучении. Для поддержания инвариантности к масштабу и местоположению smooth L1 работает с вектором расстояния D = (δx, δy, δw, δh), определяемым уравне- ниями δw = log(g w/bw), δ h = log(g h/bh). (2.8)\n--- Страница 147 ---\n146  Современные методы робастного обнаружения объектов Поскольку регрессия ограничивающей рамки обычно выполняет незначи- тельные корректировки b, численные значения (2.8) могут быть очень малы. Это обычно делает потери регрессии намного меньшими, чем потери класси- фикации. Для повышения эффективности многозадачного обуче ния D нор- мализуется по среднему значению и дисперсии, например δ x заменяется на (2.9) 2.5.4. Стратегия тонкой настройки Выборка R-CNN и SPP-Net берут выборку RoI. Это может привести к очень неэффек - тивному обуче нию, поскольку видимые области извлекаются из разных изобра жений и каждое изображение требует полного прямого вычисления CNN. Чтобы избежать этой проблемы, Fast R-CNN сначала делает выборку N изображений, из которых затем выбирает R RoI для каждого изображения. Выбирая N ≪ R, можно ограничиться вычислением CNN только для неболь- шого количества (N ) изображений. Однако возникает опасение, что выбран- ные видимые области коррелируют, и это может замедлить конвергенцию обуче ния. Однако на практике данная стратегия доказала свою эффектив- ность (Girshick, 2015; Ren et al., 2017). RoI отбираются из каждого изображе- ния, чтобы получить 25 % положительных и 75 % отрицательных обучающих примеров. Обратное распространение через пулинг RoI Другим важным улучшением Fast R-CNN по сравнению с сетью SPP было обратное распространение градиента через слой пулинга RoI. В отсутствие этого сверточные слои ниже слоя пулинга RoI не будут точно настроены на задачу обнаружения, как в случае с сетью SPP . Поскольку в пуле RoI каждый выходной объект является результатом max-пулинга соответствующего под- окна на карте признаков, вычисления обратного распространения сводятся к операциям max-пулинга. А именно обратное распространение выходного градиента происходит только до положения наибольшего максимального значения признака в подокне. Эта стратегия применяется к каждому при- знаку RoI каждого предложения области. 2.6. F AStER R-CNN Архитектуры SPP-Net и Fast R-CNN значительно улучшили скорость работы R-CNN приблизительно с 30 до 2 секунд на изображение. Они выполняли об- щий этап обнаружения предложений, который опирался на низкоуровневые признаки, такие как пиксели и края, и работали на CPU, который облада- ет ограниченной скоростью вычислений. Например, выборочный детектор\n--- Страница 148 ---\nFaster R-CNN  147 предложений требует около 2 секунд на изображение. Архитектура Faster R-CNN устранила эту проблему за счет сети прогнозирования регионов (region proposal network, RPN), которая использует графические процессоры и общие вычисления признаков с сетью Fast R-CNN. 2.6.1. Архитектура Как показано на рис. 2.7, Faster R-CNN состоит из двух модулей: сети прог - нозирования регионов (RPN), которая предлагает регионы и является пол- ностью сверточной, и детектора Fast R-CNN, который классифицирует эти предложения. В отличие от архитектур R-CNN и Fast R-CNN, вся система представляет собой единую, унифицированную и сквозную сеть для обнару - жения объектов. Поскольку RPN разделяет большую часть своих вычислений с сетью Fast R-CNN, сама по себе RPN добавляет немного вычислительных затрат. Это позволяет Faster R-CNN сократить время генерации предложений и работать в реальном времени на современном графическом процессоре. Классификатор ПредложенияПулинг PoI Сеть прогнозирования регионов Карты признаков Сверточные слои Изображение Рис. 2.7  Архитектура Faster R-CNN 2.6.2. Сети прогнозирования регионов Предложения регионов обнаруживаются путем скольжения небольшой сети по сверточной карте признаков, как показано на рис. 2.8. Эта небольшая сеть реализована с по мощью 256-мерного сверточного слоя 3×3, слоя ReLU и двух полностью связанных выходных слоев. Подобно окончательным выходным слоям Fast R-CNN, первый выходной слой предназначен для бинарной клас -\n--- Страница 149 ---\n148  Современные методы робастного обнаружения объектов сификации (передний план / фон), а второй – для регрессии ограничивающей рамки. Это дает показатель объектности (objectness score) и 4 координаты для данной привязки. В соответствии с показателем объектности RPN гене- рирует 300 лучших предложений, которые будут использоваться на более позднем этапе Fast R-CNN. 2000 оценок 4000 оценок Слой cls Слой reg 256-d Промежуточный слой Скользящее окно Сверточная карта признаковk рамок привязки Рис. 2.8  Иллюстрация сети прогнозирования регионов Привязки Каждое местоположение скользящего окна должно, в принципе, генериро- вать одно предложение, поскольку каждое местоположение на карте объ- ектов соответствует одному местоположению на входном изображении. Од- нако RPN одновременно прогнозирует k предложений регионов для каждого местоположения скользящего окна, чтобы учесть различные размеры объ- ектов и соотношения сторон. Это становится возможно благодаря концепции привязок (anchor). В каждом конкретном месте предложение связано с при- вязкой, которая центрируется в центре скользящего окна и имеет собствен- ный масштаб и соотношение сторон. Обычной практикой является исполь- зование k = 9 привязок, трех разных масштабов и трех разных соотношений сторон, для каждого положения скользящего окна. Каждая привязка создает шестимерное предложение, где четыре измерения кодируют координаты для регрессии ограничивающей рамки, а оставшиеся два – вероятности классов переднего плана и фона. Обучение Функция потерь RPN такая же, как (2.5). Ограничивающие рамки привязки необходимы для регрессии к соответствующим эталонным рамкам. Для ба- лансировки привязки выбираются во время обуче ния таким образом, чтобы соотношение между положительными и отрицательными привязками со- ставляло 1:1. Обратите внимание, что соотношение здесь отличается от соот - ношения 1:3 при обучении Fast R-CNN, упомянутом в разделе 2.5, потому что задача RPN состоит в том, чтобы обнаружить как можно больше предложений.\n--- Страница 150 ---\nКаскадная R-CNN  149 При более высокой доле положительных привязок модель будет поощряться к обнаружению большего количества положительных результатов. Если брать 300 лучших предложений, сгенерированных RPN, обуче ние детектора Fast R-CNN остается таким же, как указано выше. Вычисления сверточных призна- ков совместно используются RPN и Fast R-CNN, и вся сеть может быть обучена от начала до конца с по мощью стандартного обратного распространения и стохастического градиентного спуска (stochastic gradient descent, SGD). 2.7. К асКадная R-CNN Проблема обнаружения сложна, отчасти из-за того, что существует много «близких» ложных срабатываний, соответствующих «близким, но неправиль- ным» ограничивающим рамкам. Эффективный детектор должен обнаружи- вать все истинные срабатывания на изображении, подавляя при этом близ- кие ложные срабатывания. Качество гипотезы обнаружения определяется ее IoU с эталоном, а качество детектора – порогом IoU, используемым для его обуче ния. Высококачественное обнаружение Проблема заключается в том, что независимо от выбора порога IoU u на- стройка обнаружения является крайне противоречивой. Когда значение u высокое, позитивные предложения содержат мало фона, но трудно собрать большие позитивные обучающие наборы. Когда значение u низкое, возмож - ны более богатые и разнообразные положительные обучающие наборы, но у обученного детектора меньше стимулов отбрасывать близкие ложные сра- батывания. В общем, очень сложно добиться того, чтобы один классифика- тор одинаково хорошо работал на всех уровнях IoU. Кроме того, поскольку большинство гипотез, выдаваемых детекторами предложений (такими как RPN или выборочный поиск), имеют низкое качество, детектор объектов наверху сети должен различать гипотезы более низкого качества. Стандарт - ным компромиссом между этими противоречивыми требованиями является выбор значения u = 0,5, которое используется почти во всех современных детекторах объектов. Это, однако, относительно низкий порог, что затруд- няет обуче ние детекторов, которые могут эффективно отклонять близкие ложные срабатывания. Как правило, детектор достигает высокого качества только в том случае, если ему представлены высококачественные предложения. Этого, однако, нельзя добиться, просто увеличивая порог u во время обуче ния. Наоборот, установка высокого значения u обычно ухудшает качество обнаружения. Эта проблема, то есть тот факт, что обуче ние детектора с более высоким порогом приводит к снижению качества, называется парадоксом качественного обна- ружения (paradox of high-quality detection). У него две причины. Во-первых, механизмы предложения объектов склонны создавать распределения гипо- тез, сильно смещенные в сторону низкого качества. В результате использо- вание больших порогов IoU во время обуче ния экспоненциально уменьшает\n--- Страница 151 ---\n150  Современные методы робастного обнаружения объектов количество положительных обучающих примеров. Это особенно проблема- тично для нейронных сетей, которые интенсивно используют примеры, что делает стратегию обуче ния с «высоким u» очень склонной к переобучению. Во-вторых, существует несоответствие между качеством детектора и качест - вом гипотез, доступных во время вывода. Поскольку детекторы высокого качества оптимальны только для гипотез высокого качества, качество обна- ружения может существенно ухудшиться для гипотез более низкого качества. Каскадная архитектура R-CNN решает эту проблему, позволяя использовать детекторы объектов высокого качества. 2.7.1. Каскадная архитектура R-CNN Каскадная R-CNN (Cai, Vasconcelos, 2021) представляет собой многоступен- чатое расширение Faster R-CNN, как показано на рис. 2.9. Вместо одного детектора она использует каскад детекторов, которые последовательно более избирательны в отношении ложных срабатываний на близкие предложения. Пороги IoU обычно составляют 0,5, 0,6 и 0,7 для различных ступеней обна- ружения. Каскад ступеней R-CNN обучается последовательно, используя вы- ходные данные одной ступени для обуче ния следующей. Этот метод основан на наблюдении, что выходной IoU регрессора ограничивающей рамки почти всегда лучше, чем его входной IoU. В результате выходные данные детектора, обученного определенному порогу IoU, являются хорошим начальным рас - пределением гипотез для обуче ния следующего детектора более высокому порогу IoU. Настраивая ограничивающие рамки, каждый этап стремится найти хороший набор близких ложных срабатываний для обуче ния следу - ющей ступени. Основным результатом этой повторной выборки является постепенное повышение качества гипотез обнаружения от одной ступени к другой. В результате последовательность детекторов решает две проблемы, лежащие в основе парадокса высококачественного обнаружения. Во-первых, поскольку операция повторной выборки гарантирует наличие большого ко- личества примеров для обуче ния всех детекторов в последовательности, можно обучать детекторы с высоким IoU без переобучения. Во-вторых, ис - пользование одной и той же каскадной процедуры во время вывода дает набор гипотез все более высокого качества, хорошо согласующихся с воз- Свертка Свертка пулпулпулпул Рис. 2.9  Каскадная R-CNN – это многоступенчатое расширение Faster R-CNN. Здесь «I» – это входное изображение, «свертка» – предшествующие свертки, «пул» – извлечение признаков по регионам, «H» – ветвь (head) сети, «B» – ограни- чивающая рамка, «C» – классификация, «B0» – предложения во всех архитектурах\n--- Страница 152 ---\nКаскадная R-CNN  151 растающим качеством каскадов детектора. Это обеспечивает более высокую точность обнаружения. 2.7.2. Каскадная регрессия ограничивающей рамки Поскольку одному регрессору сложно одинаково хорошо работать на всех уровнях качества, в каскадной R-CNN задача регрессии разбивается на по- следовательность более простых шагов. Она состоит из каскада специализи- рованных регрессоров f(x, b) = fT  fT–1  ···  f1(x, b), (2.10) где T – общее количество ступеней каскада. Ключевым моментом является то, что каждый регрессор ft оптимизирован для распределения ограничивающей рамки {bt}, сгенерированного предыдущим регрессором, а не для начального распределения {b1}. Таким образом, гипотезы постепенно улучшаются (этот эффект называется прогрессивным улучшением). Эффективность каскадной регрессии иллюстрирует рис. 2.10, на котором изображено распределение вектора расстояния регрессии D = (δx, δy, δw, δh) из (2.8) на разных ступенях каскада. Обратите внимание, что большинство гипотез становятся ближе к истине по мере продвижения по каскаду. 3-й этап3-й этап 2-й этап2-й этап 1-й этап1-й этап Рис. 2.10  Распределение вектора расстояния D из (2.8) (без нормировки) на разных ступенях каскада. Вверху: график (δ x, δy). Внизу: график (δ w, δh). Красные точки – это выбросы для увеличения порогов IoU на более поздних этапах, а показанная статистика получена после удаления выбросов\n--- Страница 153 ---\n152  Современные методы робастного обнаружения объектов 2.7.3. Каскадное обнаружение Высококачественный детектор трудно обучить напрямую. Каскадная R-CNN решает проблему, используя каскадную регрессию в качестве механизма повторной выборки. Каскадная регрессия начинается с образцов (x i, bi) и ис - пользуется для последовательной повторной выборки распределения об- разцов (x i¢, bi¢) с более высоким IoU. Это позволяет наборам положительных образцов последовательных ступеней сохранять примерно постоянный раз- мер по мере увеличения качества детектора u . На каждом этапе t ветка R-CNN включает классификатор ht и регрессор ft, оптимизированный для соответствующего порога IoU ut, где ut > ut–1. Они обучаются с функцией потери L(xt, g) = Lcls(ht(xt), yt) + λ[yt ³ 1]L loc(ft(xt, bt), g), (2.11) где bt = ft–1(xt–1, bt–1), g – эталонный объект для xt, λ = 1 – коэффициент компромисса, yt – метка xt по критерию ut согласно (2.2) и [·] – индикатор- ная функция. Обратите внимание, что использование [·] подразумевает, что порог IoU u регрессии ограничивающей рамки идентичен тому, который ис - пользуется для классификации. Это каскадное обуче ние имеет два важных следствия для обуче ния детекторов. Во-первых, уменьшается возможность переобучения при больших порогах IoU u, поскольку положительных приме- ров становится много на всех этапах. Во-вторых, детекторы более глубоких ступеней оптимальны для более высоких порогов IoU. Это одновременное улучшение гипотез и качества детектора позволяет каскадной R-CNN пре- одолеть парадокс высокого качества обнаружения. При выводе применяется тот же каскад. Качество гипотез улучшается последовательно, и более качест - венные детекторы требуются только для работы с более качественными ги- потезами, для которых они оптимальны. 2.8. предста ВЛение разномасштабны Х призна КоВ Распознавание объектов, представленных на изображении в разном масшта- бе, является фундаментальной проблемой компьютерного зрения. Класси- ческое решение в литературе состоит в том, чтобы полагаться на пирамиды изобра жений, такие как те, что показаны на рис. 2.11а, где исходное изобра- жение последовательно масштабируют до нескольких изображений разного размера, из которых извлекают признаки (Viola, Jones, 2004; Felzenszwalb et al. , 2010; Доллар и др., 2014). Применяя детектор с фиксированным мас - штабом ко всем изображениям элементов пирамиды, можно обнаруживать объекты в разных масштабах без потери точности. Маленькие (большие) объекты обнаруживаются в каналах большого (малого) разрешения пирами- ды признаков. Тем не менее построение пирамиды признаков CNN требует больших вычислительных ресурсов, что делает это решение непрактичным\n--- Страница 154 ---\nПредставление разномасштабных признаков  153 для большинства реальных приложений. Разработка эффективных представ- лений признаков CNN для различных масштабов является важным направ- лением исследований в области обнаружения объектов. (a) (c)(b) (d) Рис. 2.11  (a) Пирамида изображения: признаки вычисляются для каждого масштаба изображения независимо. (b) Карта объектов с одним масштабом: обнаружение объектов работает только на карте объектов с одним масштабом в CNN. (c) Пирамида признаков: пирамида признаков для многомасштабного обнаружения, но с единой шкалой ввода изображения. (d) Сеть функциональ- ных пирамид (FPN): FPN добавляет нисходящие соединения к пирамиде функ - ций из (c), обеспечивая более инвариантное к масштабу семантическое пред- ставление функций в разных масштабах Несмотря на большой успех детекторов объектов на основе глубокого обуче ния (Girshick et al., 2014; Girshick, 2015; He et al., 2014; Ren et al., 2017), в обнаружении объектов разного масштаба пока не удалось добиться хо- роших результатов. Как было сказано выше, R-CNN, SPP-Net и Fast R-CNN отбирают предложения объектов в нескольких масштабах, используя этап предварительного внимания, например выборочный поиск (van de Sande et al., 2011), а затем преобразуют эти предложения в фиксированный размер, поддерживаемый CNN. Но это лишь отодвигает проблему инвариантности масштаба на стадию внимания, которая не обучается совместно с CNN. Faster R-CNN (Ren et al., 2017) решает проблему совместного обуче ния, используя RPN для создания предложений нескольких масштабов. Однако, как показа- но на рис. 2.11b, это делается путем сдвига фиксированного набора фильтров по одному набору сверточных карт признаков. Это создает несоответствие между объектами переменного размера и фильтрами фиксированного ре- цептивного поля. Как показано на рис. 2.12, фиксированное рецептивное поле не может охватывать множество масштабов, в которых объекты пред-\n--- Страница 155 ---\n154  Современные методы робастного обнаружения объектов стают в естественных сценах. В результате снижается эффективность обнару - жения, особенно для небольших объектов, подобных показанному в центре рис. 2.12, которые довольно трудно обнаружить. Было предложено несколько сетей, расширяющих архитектуру двухэтапного детектора путем введения многомасштабных расширений RPN. Рис. 2.12  На естественных изображениях объекты могут появляться в очень разных масштабах, что показано желтыми ограничивающими прямоугольника- ми. Один фильтр рецептивного поля фиксированного размера (показано в за- штрихованной области) не может охватить весь разброс масштабов 2.8.1. Архитектура МС-CNN Архитектура MS-CNN была предложена специально для решения проблемы многомасштабного обнаружения объектов. Она использует стратегию, аль- тернативную дорогостоящему вычислению пирамид изображений, опираясь на тот факт, что глубокие нейронные сети уже вычисляют иерархию призна- ков слой за слоем. Учитывая, что слои более высокого уровня подвергаются субдискретизации, эта иерархия даже имеет многоуровневую пирамидаль- ную структуру. Следовательно, несоответствие между размерами объектов и рецептивных полей может быть устранено путем простого добавления вы- ходных слоев на нескольких этапах сети, как показано на рис. 2.11c. Таким об- разом, MS-CNN реализует несколько детекторов, которые специализируются на различных диапазонах размеров. В то время как детекторы, основанные на более низких сетевых уровнях, таких как «conv-3», имеют меньшие рецептив- ные поля и лучше подходят для обнаружения небольших объектов, детекторы, основанные на более высоких уровнях, таких как «conv-5», лучше всего под- ходят для обнаружения крупных объектов. Комплементарные детекторы на выходах разных слоев объединяются в сильный многомасштабный детектор. 2.8.1.1. Архитектура Подробная архитектура сети предложений MS-CNN показана на рис. 2.13. Сеть обнаруживает объекты, пропуская изображения через несколько ветвей обнаружения, которые объединяются в окончательный набор предложений. Она имеет стандартный ствол CNN, изображенный в центре рисунка, и набор\n--- Страница 156 ---\nПредставление разномасштабных признаков  155 выходных ветвей, исходящих из разных слоев ствола. Эти ветви состоят из одного уровня обнаружения. Обратите внимание, что буферный сверточный слой вводится на ветви, исходящей после слоя «conv4-3». Поскольку эта ветвь близка к нижним слоям магистральной сети, она влияет на их градиенты больше, чем другие ветви обнаружения. Это может привести к некоторой нестабильности во время обуче ния. Свертка буфера предотвращает обрат - ное распространение градиентов ветви обнаружения непосредственно на магистральные слои. Входное изображение Рис. 2.13  Архитектура пирамиды признаков MS-CNN. Кубоиды являются вы- ходными тензорами сети (кроме входного изображения). h×w – размер фильт - ра, c – количество классов и b – количество координат ограничивающей рамки Во время обуче ния параметры W многомасштабной сети предложений изучаются из набора обучающих выборок S = {(X i, Yi)}N i=1, где Xi – фрагмент обучаю щего изображения, а Yi = (yi, bi) представляет собой комбинацию ме- ток классов yi Î {0, 1, 2, …, K} и координат ограничивающей рамки bi = (bix, biy, biw, bin). Обуче ние выполняется с применением многозадачной потери (2.12) где M – количество ветвей обнаружения, lm – многозадачная потеря, объеди- няющая классификацию и регрессию ограничивающей рамки (2.5), αm – вес потери lm, а S = {S1, S2, …, SM}, где Sm содержит примеры масштаба m. Обратите внимание, что только подмножество Sm обучающих выборок, отобранное по масштабу, удовлетворяет потере слоя обнаружения m . 2.8.2. Сеть FPN Хотя пирамида признаков на рис. 2.11c улучшает представление различных масштабов объектов, она вносит большой семантический разрыв между эти-\n--- Страница 157 ---\n156  Современные методы робастного обнаружения объектов ми представлениями. В то время как карты с высоким разрешением содер- жат информацию о признаках семантики низкого уровня, таких как края, углы и т. д., карты с низким разрешением передают семантически богатую информацию, такую как категория объекта. Следовательно, карты высокого разрешения в основном информируют о местоположении объекта, а кар- ты низкого разрешения – о его идентичности. Архитектура на рис. 2.11(c) может иметь неоптимальную производительность обнаружения, поскольку запрашивает все представления признаков для решения задач локализации и классификации. Чтобы уменьшить эти семантические пробелы, сеть пирамиды признаков (feature pyramid network, FPN) добавляет нисходящее соединение от высоко- уровневых (семантически более богатых) карт признаков к низкоуровневым (самым бедным семантически) картам признаков, как показано на рис. 2.11d. Это гарантирует, что пирамида признаков имеет сильную семантику на всех уровнях пирамиды. Как и на рис. 2.11c, FPN представляет собой внутрисе- тевую пирамиду и, следовательно, эффективна, но нисходящие соединения увеличивают ее репрезентативность. 2.8.2.1. Архитектура Основное различие между FPN и стандартными сетями восходящей класси- фикации, такими как ResNet (He et al., 2016), заключается в добавлении ни- сходящего пути, позволяющего создавать семантически богатые пирамиды признаков. Этот прием реализуется с по мощью простого набора элементов, показанных на рис. 2.14. Рис. 2.14  Строение сети FPN\n--- Страница 158 ---\nПредставление разномасштабных признаков  157 Восходящий путь Стандартная сеть с прямой связью, естественно, представляет собой восходя- щую пирамиду из-за использования операций понижающей дискретизации, таких как пулинг, свертка со страйдом 2 и т. д. В целом разрешение карт при- знаков уменьшается в 2 раза на каждом этапе сети, где этап определяется как последовательность слоев с одинаковым разрешением. FPN строится на основе ResNet, извлекая восходящую пирамиду из активаций последнего уровня каждой стадии ResNet. В частности, выходные данные слоев conv2, conv3, conv4 и conv5 сети ResNet, обозначенные как {C 2, C3, C4, C5}, использу - ются для создания пирамиды со страйдом {4, 8, 16, 32} пикселя по отношению к входному изображению. Нисходящий путь и боковые соединения Цель FPN – обогатить семантику низкоуровневых карт объектов. Простой способ сделать это – добавить высокоуровневые карты объектов строгой се- мантики к низкоуровневым. Поскольку карты объектов более высокого уров- ня имеют более низкое разрешение, они сначала увеличиваются в два раза с использованием выборки ближайшего соседа (nearest neighbor sampling). Перед суммированием карты объектов нижнего слоя подаются на латераль- ный сверточный слой 1×1, чтобы гарантировать, что обе карты объектов имеют одинаковые размеры каналов. Затем карты признаков суммируются поэлементно, и для создания окончательной карты признаков применяется свертка 3×3, чтобы избежать потенциального размытия из-за операции по- вышения разрешения. В этих дополнительных слоях нет нелинейности. Про- цедура повторяется сверху вниз пирамиды, т. е. слоев {C 2, C3, C4, C5}, чтобы получить окончательную пирамиду FPN из слоев {P 2, P3, P4, P5}, каждый из ко- торых содержит 256 измерений канала. Каждому слою Pi соответствует слой Ci того же разрешения. Чтобы гарантировать, что все уровни пирамиды FPN обладают одинаковой семантикой, для получения окончательных прогнозов для всех масштабов на разных уровнях используются слои классификации и регрессии ограничивающей рамки. Поскольку двухэтапные детекторы объектов, такие как рассмотренные выше, нуждаются в пулинге RoI для извлечения признаков экземпляра, об- работанных вторым этапом, они не являются полностью сверточными, что усложняет их аппаратную реализацию. Хотя эти детекторы точны, они до- стигают лишь скорости 10–20 кадров в секунду (fps) на современных графи- ческих процессорах. Более высокие скорости обнаружения обычно требуют более дружественных к оборудованию архитектур, как правило, полностью сверточных и содержащих один этап. В литературе был предложен ряд та- ких архитектур, включая YOLO (Redmon et al., 2016), SSD (Liu et al., 2016) и RetinaNet (Lin et al., 2017b). Одноступенчатые детекторы обычно жертвуют точностью ради скорости.\n--- Страница 159 ---\n158  Современные методы робастного обнаружения объектов 2.9. арХитеКтура YOLO Архитектура YOLO (You only look once) (Redmon et al., 2016) была одной из первых и до сих пор остается самым популярным одноэтапным детектором объектов. Она приобрела популярность в основном благодаря высокой ско- рости, более 50 кадров в секунду на современном графическом процессоре. Однако ее точность значительно ниже, чем у современных двухкаскадных детекторов. В первой версии YOLO не использовались привязки, как в Faster R-CNN; они появились только в более поздних версиях. Принцип работы YOLO изображен на рис. 2.15. Входное изображение разбивается на ячейки S×S, и для каждой ячейки x делается B прогнозов. Ячейка считается ответ - ственной за объект тогда и только тогда, когда внутри нее находится центр эталонной ограничивающей рамки объекта. Каждый прогноз состоит из че- тырех координат ограничивающей рамки x, y, w и h и показателя объектности p(o = 1|x). Последнее условие отражает уверенность в том, что предсказан- ный блок включает в себя объект и идеально равен IoU между предсказан- ным и эталонным блоками объекта. Если в ячейке не существует объекта, показатель объектности должен быть равен 0. Тогда прогноз достоверности для класса k определяется как p(y = k|x) = p(y = k|o = 1, x)p(o = 1|x), (2.13) где p(y = k|o = 1, x) – классовая условная вероятность того, что класс k появит - ся в ячейке x, при условии что ячейка содержит объект. Однако один набор условных вероятностей класса C является общим для предсказаний B ячейки, т. е. все предсказания в ячейке имеют одинаковые условные вероятности класса. Типичная реализация YOLO для обнаружения 20 классов объектов Сетка S×S на входеОграничивающая рамка + доверие Карта вероятности классаОкончательное обнаружение Рис. 2.15  Принцип работы YOLO\n--- Страница 160 ---\nСеть SSD  159 набора данных Pascal VOC (Everingham et al., 2010) использует S = 7, B = 2 и C = 20, всего 7×7×30 предсказаний. Базовая структура Одной из причин эффективности YOLO является базовая сеть, называемая DarkNet. Она опирается на идеи архитектуры GoogLeNet (Szegedy et al., 2015), содержащей 24 сверточных слоя, за которыми следуют 2 полносвязных слоя, выполненных с комбинацией канала 1×1 и сверточных слоев 3×3, реализация которых оптимизирована для современных графических процессоров. 2.10. сеть SSD Сеть SSD (Liu et al., 2016) – это еще один популярный одноступенчатый де- тектор объектов. Он такой же быстрый, как YOLO, но имеет гораздо более высокую точность, особенно для небольших объектов. Основные отличия заключаются в использовании многомасштабной пирамиды признаков как на рис. 2.11c и привязок RPN. 2.10.1. Архитектура Базовая сеть представляет собой стандартную сеть классификации изобра- жений (без конечного слоя классификации), например VGG-Net (Simonyan, Zisserman, 2014). К этой сети добавляются некоторые вспомогательные уровни для прогнозирования обнаружения. Общая архитектура показана на рис. 2.16. Изобра- жениеVGG-16 через слой Conv5_3Классификатор: Conv:3x3x(4x(Классы+4)) Классификатор: Conv:3x3x(6x(Классы+4)) Классификатор: Conv:3x3x(4x(Классы+4)) Conv: 1x1x128 Conv: 3x3x256-s1Conv: 1x1x128 Conv: 3x3x256-s1Conv: 1x1x128 Conv: 3x3x256-s2Conv: 1x1x256 Conv: 3x3x512-s2Conv: 1x1x1024 Conv: 3x3x1024Слои доп. признаков Обнаружения: 8732 на класс Немаксимальное подавление Рис. 2.16  Устройство сети SSD Многомасштабное обнаружение Подобно MS-CNN, SSD использует иерархические представления призна- ков как на рис. 2.11c для многомасштабного обнаружения. Как показано на рис. 2.16, обнаружения генерируются из карт признаков слоев Conv4_3, Conv6, Conv7, Conv8_2, Conv9_2, Conv10_2 и Conv11_2, которые имеют разное разрешение. По причинам, рассмотренным выше, это позволяет обнаружи-\n--- Страница 161 ---\n160  Современные методы робастного обнаружения объектов вать больше объектов и более точно обнаруживать мелкие объекты. Подобно RPN (Ren et al., 2017), предсказатель SSD, применяемый к каждой сверточной карте признаков, состоит из дополнительного слоя свертки 3×3, выходными данными которого являются оценки классов и смещения ограничивающей рамки относительно позиций привязки. Привязки Подобно RPN, в заданном месте есть k якорей, и для каждой привязки прог - нозируются оценки класса c и 4 смещения координат. Следовательно, карта признаков с разрешением h×w дает (c + 4)×k ×h×w выходных данных. Это эквивалентно применению RPN на нескольких картах признаков и помогает понять, почему одноэтапные детекторы в целом менее точны, чем двухэтап- ные детекторы: они аналогичны стадии генерации предложений последних. При сравнении SSD с RPN в виде реализации MS-CNN основное различие состоит в том, что RPN не зависит от класса, т. е. c = 2, в то время как SSD за- висит от класса, делая с + 1 прогнозов класса, например для набора данных VOC c = 21 (Everingham et al., 2010). 2.10.2. Обучение SSD использует многозадачную функцию потерь, аналогичную (2.5), соче- тающую классификацию и регрессию ограничивающей рамки. Для более точного обнаружения она также использует во время обуче ния жесткий не- гативный майнинг и сильное расширение данных. Обработка трудных отрицательных образцов Сложность обнаружения объектов заключается в том, что большинство отри - цательных образцов, например неба, легко классифицировать. Если в обуче- ние включено слишком много простых отрицательных образцов, детектор будет хуже работать с трудными отрицательными образцами (hard negatives, отрицательные образцы, которые визуально похожи на положительные). Эта проблема более серьезна для одноступенчатых детекторов, в которых от - сутствует эффективная передискретизация, реализуемая вторым каскадом. Обработка трудных отрицательных образцов (hard negative mining) – это механизм выборки, широко применявшийся для обнаружения объектов до появления глубокого обуче ния (Viola, Jones, 2004; Felzenszwalb et al., 2010; Dollár et al., 2014), предназначенный для решения этой проблемы. Чтобы создать пул отрицательных результатов, SSD сортирует отрицательные об- разцы по более высоким и более низким показателям достоверности (бо- лее высокий означает, что пример сложнее классифицировать) и выбирает лучшие образцы, необходимые для достижения соотношения 1:3 между по- ложительными и отрицательными результатами, аналогично выборке Fast R-CNN. Это заставляет детектор научиться более точно отличать трудные отрицательные образцы.\n--- Страница 162 ---\nRetinaNet  161 Дополнение данных Нехватка обучающих данных – еще одна проблема для обнаружения объек - тов на основе глубокого обуче ния, которую можно решить путем дополнения (приращения) данных. При обучении SSD каждое изображение случайным об- разом дополняется либо 1) сохранением исходного изображения, либо 2) об- резкой фрагмента минимальной IoU с объектом в {0,1, 0,3, 0,5, 0,7, 0,9}, либо 3) обрезкой случайного фрагмента. Размер (соотношение сторон) случайного фрагмента выбирается случайным образом в диапазоне [0,1, 1] от исходного размера изображения {1/2, 2}. После кадрирования размер фрагмента из- меняется до фиксированного квадратного размера (например, 512×512) со случайным отражением по горизонтали и отправляется в сеть. Помимо про- странственного дополнения, иногда применяются дополнения в цветовом пространстве. 2.11. R EtiNANEt В то время как обуче ние на трудных отрицательных примерах устраняет дис - баланс между простыми (например, небо) и трудными объектами, этот подход лишь умеренно эффективен для детекторов глубокого обуче ния. RetinaNet (Lin et al., 2017b) вместо этого предлагает обобщение кросс-энтропийной потери, обозначаемое как фокальная , или очаговая, потеря (focal loss, FL), которое подавляет легкие отрицательные случаи и подчеркивает трудные. 2.11.1. Фокальная потеря Функция потерь перекрестной энтропии (cross entropy, CE) для бинарной классификации равна (2.14) где y Î {±1} – метка истинности, а p = p(y = 1|x) Î [0, 1] – вероятность для класса y = 1. Определим p t как (2.15) Следовательно, можно записать CE(p, y) = CE(pt) = –log(p t), как показано на рис. 2.17 (верхняя синяя кривая, где γ = 0). Можно заметить, что легко классифицируемые примеры (например, с pt ≫ 0,5) по-прежнему имеют не- тривиальную величину потерь. Когда большинство обучающих примеров «простые», они доминируют в общих потерях, подавляя вклад «трудных». Фокальные потери (FL) обобщают потери CE путем добавления коэффи- циента модуляции (1 – p t)γ настраиваемого параметра γ ³ 0:\n--- Страница 163 ---\n162  Современные методы робастного обнаружения объектов FL(pt) = –(1 – pt)γ log(p t). (2.16) Этот фактор изменяет потери, как показано на рис. 2.17. Если для малых pt (трудные примеры) потери сильно не меняются, то при больших pt (прос - тые примеры) они уменьшаются до нуля гораздо быстрее, особенно при больших значениях γ. Следовательно, простые примеры вносят меньший вклад в общие потери. Например, при γ = 2 простой пример с pt = 0,9 будет иметь в 100 раз меньший вклад при фокальной потере по сравнению с кросс- энтропийной потерей. Величина понижения веса определяется гиперпара- метром γ, причем чем больше значение γ, тем сильнее понижение веса, как показано на рис. 2.17. На практике было установлено, что значение γ = 2 работает лучше всего. 5 4 3 2 1 0 0.2 0.4 0.6 0.8 01Потеря Вероятность эталонного классаВерно классифицированные примеры Рис. 2.17  Визуализация фокальных потерь для различных значе- ний γ. Значение γ > 0 уменьшает потери легко классифицируемых при- меров (p t > 0,5), уделяя больше внимания трудным неправильно класси- фицированным примерам В целом фокальные потери уравновешиваются другим гиперпараметром α: FL(pt) = –αt(1 – pt)γ log(p t). (2.17) Когда используется эта потеря, проблему подавления простых отрицатель- ных примеров можно обойти во время обуче ния. 2.12. произ Водите Льность дете Кторо В объе КтоВ Мы закончим эту главу кратким сравнением производительности некоторых из рассмотренных выше детекторов объектов. R-CNN, SPP-Net и Fast R-CNN не включены в это сравнение, поскольку они устарели и редко используются\n--- Страница 164 ---\nЗаключение  163 на практике. В табл. 2.1 представлены сводные данные о производитель- ности остальных методов на наборе данных COCO (Lin et al., 2014) с точки зрения скорости, числа эпох обуче ния и средней точности (average preci- sion, AP). В COCO показатель AP усредняется по 10 пороговым значениям IoU 0,50:0,05:0,95, а AP 50 (при пороге 0,5), AP 75 (при пороге 0,75) AP S (для малых объектов), AP M (для средних объектов) и AP L (для крупных объектов) предоставляют более подробную информацию о производительности. Об- ратите внимание, что более полная метрика AP , усредненная по порогам IoU 0,50:0,05:0,95, вознаграждает детекторы с лучшей локализацией, чем традиционная метрика AP 50 при пороге IoU = 0,5. Очевидно, что односту - пенчатые детекторы (YOLO и SSD) быстрее, но гораздо менее точны, чем их двухступенчатые аналоги (Faster R-CNN, FPN и Cascade R-CNN). Среди двух - каскадных детекторов скорости сопоставимы, но Cascade R-CNN достигает наивысшей точности. Аналогичные сравнения можно найти в публикациях по обнаружению объектов, и они позволяют практикующим специалистам выбирать детектор с компромиссом между сложностью и точностью, наи- более подходящим для определенного применения. Таблица 2.1. Характеристики усовершенствованных детекторов объектов на наборе COCO ОсноваСкорость (fps)Эпохи AP AP50AP75AP SAP MAP L YOLOv3 DarkNet-53 48,1 273 33,4 56,3 35,2 19,5 36,4 43,6 SSD512 VGG16 30,7 24 29,4 49,3 31,0 11,7 34,1 44,9 RetinaNet ResNet-50 24,4 36 38,7 58,0 41,5 23,3 42,3 50,3 Faster R-CNN ResNet-50 9,6 36 38,4 58,7 41,3 20,7 42,7 53,1 FPN ResNet-50 26,3 36 40,2 61,0 43,8 24,2 43,5 52,0 Cascade R-CNN ResNet-50 21,8 36 43,6 61,6 47,4 26,2 47,1 56,9 2.13. заКЛюЧение В этой главе мы рассмотрели последние достижения в области обнаруже- ния объектов на основе глубокого обуче ния. В целом существующие методы можно разделить на две категории: одноэтапные и двухэтапные. Одноэтап- ные методы быстрее, но менее точны. Два упомянутых поэтапных метода объ единяют первую сеть предложений, которая похожа на одноэтапный де- тектор, но нечувствительна к классам, и вторую сеть, которая классифици- рует объекты и уточняет их ограничивающие рамки. За прошедшие годы был сделан большой вклад в улучшение производительности новаторской R-CNN (Girshick et al., 2014) с точки зрения как скорости, так и точности. Сюда относятся концепции, которые имеют важное значение для исследо- ваний в области обнаружения объектов, такие как пулинг видимых областей, многозадачные потери, RPN, привязки, каскадное обнаружение и регрессия, многомасштабные представления признаков, методы добавления данных, функции потерь и т. д. Хотя, как показано в табл. 2.1, эти идеи и методы\n--- Страница 165 ---\n164  Современные методы робастного обнаружения объектов позволили существенно улучшить производительность, детекторы объек - тов все еще далеки от совершенства. Также существует большое количество литературы по темам, не затронутым в этом обзоре, таким как сегментация экземпляров, адаптация предметной области или архитектуры глубокого обуче ния низкой сложности и т. д. Наконец, обнаружение объектов часто ис - пользуется в качестве предварительного этапа многих других задач компью- терного зрения, включая оценку позы, подписи к изображениям и видео или визуальные ответы на вопросы. Таким образом, хотя современные детекторы объектов на порядки эффективнее тех, что были всего десять лет назад, пред- стоит еще много исследований по этой проблеме, имеющей фундаменталь- ное значение для компьютерного зрения. Литературные исто ЧниКи Cai Z., Fan Q., Feris R. S., Vasconcelos N., 2016. A unified multi-scale deep convo- lutional neural network for fast object detection. In: ECCV, pp. 354–370. Cai Z., Vasconcelos N., 2021. Cascade R-CNN: high quality object detection and instance segmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence 43 (5), 1483–1498. Dalal N., Triggs B., 2005. Histograms of oriented gradients for human detection. In: CVPR, pp. 886–893. Dollár P., Appel R., Belongie S. J., Perona P., 2014. Fast feature pyramids for object detection. IEEE Transactions on Pattern Analysis and Machine Intelligence 36 (8), 1532–1545. Everingham M., Gool L. J. V., Williams C. K. I., Winn J. M., Zisserman A., 2010. The Pascal visual object classes (VOC) challenge. International Journal of Computer Vision 88 (2), 303–338. Felzenszwalb P. F., Girshick R. B., McAllester D. A., Ramanan D., 2010. Object de- tection with discriminatively trained part-based models. IEEE Transactions on Pattern Analysis and Machine Intelligence 32 (9), 1627–1645. Girshick R. B., 2015. Fast R-CNN. In: ICCV, pp. 1440–1448. Girshick R. B., Donahue J., Darrell T., Malik J., 2014. Rich feature hierarchies for accurate object detection and semantic segmentation. In: CVPR, pp. 580–587. He K., Zhang X., Ren S., Sun J. , 2014. Spatial pyramid pooling in deep convolutional networks for visual recognition. In: ECCV, pp. 346–361. He K., Zhang X., Ren S., Sun J., 2016. Deep residual learning for image recognition. In: CVPR, pp. 770–778. Krizhevsky A., Sutskever I., Hinton G. E., 2012. Imagenet classification with deep convolutional neural networks. In: NIPS, pp. 1106–1114. Lazebnik S., Schmid C., Ponce J., 2006. Beyond bags of features: spatial pyramid matching for recognizing natural scene categories. In: CVPR. IEEE Computer Society, pp. 2169–2178. Lin T., Dollár P., Girshick R. B., He K., Hariharan B., Belongie S. J., 2017a. Fea- ture pyramid networks for object detection. In: CVPR. IEEE Computer Society, pp. 936–944.\n--- Страница 166 ---\nОб авторах главы  165 Lin T., Goyal P., Girshick R. B., He K., Dollár P., 2017b. Focal loss for dense object detection. In: ICCV. IEEE Computer Society, pp. 2999–3007. Lin T., Maire M., Belongie S. J., Hays J., Perona P., Ramanan D., Dollár P., Zitnick C. L., 2014. Microsoft COCO: common objects in context. In: ECCV, pp. 740–755. Liu W., Anguelov D., Erhan D., Szegedy C., Reed S. E., Fu C., Berg A. C., 2016. SSD: Single ShotMultibox Detector. ECCV, vol. 9905. Springer, pp. 21–37. Lowe D. G., 1999. Object recognition from local scale-invariant features. In: ICCV. IEEE Computer Society, pp. 1150–1157. Lowe D. G., 2004. Distinctive image features from scale-invariant keypoints. In- ternational Journal of Computer Vision 60 (2), 91–110. Papageorgiou C., Oren M., Poggio T. A., 1998. A general framework for object detec - tion. In: ICCV. IEEE Computer Society, pp. 555–562. Redmon J., Divvala S. K., Girshick R. B., Farhadi A., 2016. You only look once: uni- fied, real-time object detection. In: CVPR, pp. 779–788. Ren S., He K., Girshick R. B., Sun J., 2017. Faster R-CNN: towards real-time object detection with region proposal networks. IEEE Transactions on Pattern Analy - sis and Machine Intelligence 39 (6), 1137–1149. Rowley H. A., Baluja S., Kanade T., 1996. Neural network-based face detection. In: CVPR. IEEE Computer Society, pp. 203–208. Russakovsky O., Deng J., Su H., Krause J., Satheesh S., Ma S., Huang Z., Karpathy A., Khosla A., Bernstein M. S., Berg A. C., Li F., 2015. Imagenet large scale visual rec - ognition challenge. International Journal of Computer Vision 115 (3), 211–252. Simonyan K., Zisserman A. , 2014. Very deep convolutional networks for large-scale image recognition. CoRR. arXiv: 1409.1556 [abs]. Sung K. K., Poggio T. A., 1998. Example-based learning for view-based human face detection. IEEE Transactions on Pattern Analysis and Machine Intelligence 20 (1), 39–51. Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., 2015. Going deeper with convolutions. In: CVPR, pp. 1–9. Van de Sande K. E. A., Uijlings J. R. R., Gevers T., Smeulders A. W. M., 2011. Seg- mentation as selective search for object recognition. In: ICCV, pp. 1879–1886. Viola P. A., Jones M. J., 2001. Rapid object detection using a boosted cascade of simple features. In: CVPR. IEEE Computer Society, pp. 511–518. Viola P. A., Jones M. J., 2004. Robust real-time face detection. International Journal of Computer Vision 57 (2), 137–154. об аВтора Х гЛаВы Чжаовей Цай (Zhaowei Cai) – ученый и прикладной специалист в Ama- zon Web Services. Он получил степень бакалавра в области автоматизации в Даляньском морском университете в 2011 г., а также степень магистра и доктора философии в Калифорнийском университете в Сан-Диего в 2019 г. С 2011 по 2013 г. работал научным сотрудником в Институте автоматизации Китайской академии наук. Его текущие исследовательские интересы связаны\n--- Страница 167 ---\n166  Современные методы робастного обнаружения объектов с компьютерным зрением и машинным обуче нием, включая обнаружение и распознавание объектов. Нуно Васконселос (Nuno Vasconcelos) получил степень бакалавра в области электротехники и компьютерных наук в Университете Порто, Португалия, а также степени магистра и доктора философии в Массачусетском техноло- гическом институте. Он является профессором кафедры электроники и вы- числительной техники Калифорнийского университета в Сан-Диего, где воз- главляет лабораторию статистических визуальных вычислений. Он получил награду NSF CAREER, стипендию Хеллмана, несколько наград за лучшую научную работу и является членом IEEE.",
      "debug": {
        "start_page": 138,
        "end_page": 167
      }
    },
    {
      "name": "Глава 3. Обучение с ограниченным подкреплением – статические и динамические задачи 167",
      "content": "--- Страница 168 --- (продолжение)\nГлава 3 Обучение с ограниченным подкреплением – статические и динамические задачи Авторы главы: Суджой Пол1, Google Research, Бангалор, Индия; Амит Рой-Чоудхури, Калифорнийский университет, Риверсайд, электротехника и вычислительная техника, Риверсайд, Калифорния, США Краткое содержание главы: уменьшение подкрепления при обучении моделей компьютерного зрения важно для масштабируемости и адаптивности; рассмотрены различные методы, которые были предложены для обуче ния с ограниченным подкреплением, и представлены результаты, подтверж - дающие эффективность этих методов; уделено особое внимание активному обуче нию для распознавания, слабо подкрепляемому обуче нию для локализации событий, адаптации предмет - ной области для семантической сегментации и обуче нию с подкреплением для обнаружения подцелей при обучении роботов динамическим задачам. 1 Эта глава была написана, когда автор работал в Калифорнийском университете в Риверсайде.\nГлава 3 Обучение с ограниченным подкреплением – статические и динамические задачи Авторы главы: Суджой Пол1, Google Research, Бангалор, Индия; Амит Рой-Чоудхури, Калифорнийский университет, Риверсайд, электротехника и вычислительная техника, Риверсайд, Калифорния, США Краткое содержание главы: уменьшение подкрепления при обучении моделей компьютерного зрения важно для масштабируемости и адаптивности; рассмотрены различные методы, которые были предложены для обуче ния с ограниченным подкреплением, и представлены результаты, подтверж - дающие эффективность этих методов; уделено особое внимание активному обуче нию для распознавания, слабо подкрепляемому обуче нию для локализации событий, адаптации предмет - ной области для семантической сегментации и обуче нию с подкреплением для обнаружения подцелей при обучении роботов динамическим задачам. 1 Эта глава была написана, когда автор работал в Калифорнийском университете в Риверсайде.\n--- Страница 169 ---\n168  Обучение с ограниченным подкреплением – статические и динамические задачи 3.1. В Ведение Недавние успехи в компьютерном зрении в основном связаны с использова- нием огромного массива сложно размеченных данных для обуче ния моделей распознавания. Но в реальной жизни получение таких больших наборов дан- ных потребует чрезвычайно трудоемкой и дорогостоящей ручной разметки, которая часто выходит за рамки бюджета и может содержать ошибки. Тем не менее множество реальных данных, которые генерируются ежедневно, могут быть использованы с минимальными затратами на разметку или вовсе без нее. Такие данные могут быть неразмеченными или содержать информацию о тегах/метаданных, называемую слабой разметкой (weak annotation). Наша цель – разработать методы, которые могут обучать модели распознавания на таких данных с ограниченным объемом ручной работы. В этой главе мы рассмотрим два аспекта обуче ния с ограниченным подкреплением (limited supervision): во-первых, сокращение количества размеченных вручную дан- ных, необходимых для обуче ния моделей распознавания, и, во-вторых, сни- жение уровня подкрепления с сильного до слабого, который можно получить из интернета, запросить у оракула или задать как основанные на правилах метки, полученные из знаний предметной области. В отношении первого аспекта обуче ния с ограниченным подкреплением мы показываем, что контекстная информация, часто присутствующая в ес - тественных данных, может быть использована для уменьшения количества необходимых аннотаций. В отношении второго аспекта – снижения уровня подкрепления – мы используем слабую разметку вместо плотных сильных меток для обуче ния задачам плотного прогнозирования. Мы обсудим осно- вы обуче ния с использованием слабой разметки для обнаружения действий в видео и предметной адаптации моделей семантической сегментации изо- бражений. Все эти обсуждаемые задачи носят статический характер. Продол- жая двигаться в направлении обуче ния со слабой разметкой, мы исследуем последовательные задачи принятия решений, где следующий вход зависит от текущего результата. Мы рассматриваем проблему обуче ния моделей за- дачам робототехники на примере небольшого набора человеческих действий путем разложения сложной задачи на подзадачи. Подробное объяснение этих методов следует ниже. 3.2. К онте Кстно-заВисимое аКтиВное обу Чение В последние годы благодаря прорывному развитию технологий ежедневно генерируется огромное количество визуальных и текстовых данных, кото- рые в основном не размечены для использования в машинном обучении. Кроме того, алгоритмы машинного обуче ния все чаще встречаются в жизни человека. Большая часть этих алгоритмов основана на обучении с подкреп- лением, которое требует разметки большого количества данных. Более того,\n--- Страница 170 ---\nКонтекстно-зависимое активное обучение  169 эти модели необходимо обновлять по мере появления новых данных, что- бы динамически адаптироваться к различным семантическим концепциям, которые могут меняться со временем. Ручная разметка этого непрерывно- го потока данных является не только утомительной задачей для людей, но и служит причиной ошибок в разметке. В таком случае может быть выгодно размечать только информативные точки данных и пропускать точки данных, несущие избыточную информацию. Обоснованность этой идеи подтвержда- ется в работах (Lapedriza et al., 2013), которые показывают, что не все точки данных несут одинаковое количество информации, и выбор наиболее ин- формативных из них может даже привести к лучшей производительности, чем маркировка всех точек данных в немаркированном наборе. Активное обуче ние, которое изучалось в литературе в течение последних нескольких десятилетий, показало огромный потенциал в плане выбора информативных точек данных и сокращения усилий по ручной разметке. 3.2.1. Активное обучение Активное обуче ние (Settles, 2012) было предложено как решение проблемы сокращения ручной разметки без ущерба для эффективности распознава- ния. Наглядная иллюстрация принципа активного обуче ния изображена на рис. 3.1. Используя большой немаркированный набор данных, методы ак - тивного обуче ния сначала выбирают небольшое случайное подмножество данных и обращаются к человеку-эксперту, так называемому оракулу, чтобы получить их разметку. Эти точки данных используются для обуче ния модели прогнозирования согласно поставленной задаче. Это начальная модель. Сле- Запросы выборок ОракулОбновление размеченного набора Размеченный набор Неразмеченный набор Обучение моделиОбученная прогнозная модельВычисление показателя информативности Рис. 3.1  Схема итеративного процесса в активном обучении. Процесс начи- нается с извлечения нескольких образцов из немаркированного набора, чтобы запросить у оракула ручную разметку. Затем размеченный набор используется для обновления прогнозной модели, которая далее применяется для вычисле- ния показателя информативности оставшихся неразмеченных данных и, в свою очередь, для выбора небольшого подмножества для следующей разметки\n--- Страница 171 ---\n170  Обучение с ограниченным подкреплением – статические и динамические задачи дующая задача состоит в том, чтобы выбрать только небольшое подмножест - во точек данных из неразмеченного набора, дабы получить максимально возможный объем информации. Показатели полезной информативности этих неразмеченных выборок вычисляются на основе неопределенности те- кущей модели, плотности данных и т. д. Эти показатели используются при извлечении выборок для разметки. Как правило, активные методы обуче ния основаны на итерациях с участием человека в цикле, т. е. на вычислении по- казателей информативности, получении от человека разметки с последую- щим обновлением модели новыми размеченными точками данных и повтор- ном вычислении показателей информативности немаркированных точек данных, как показано на рис. 3.1. Этот цикл продолжается либо до тех пор, пока бюджет разметки не будет исчерпан, либо постоянно в случае непре- рывного обуче ния, когда концепции могут меняться со временем и требуется постоянное обновление модели. Обозначения Прежде чем детально рассмотреть каждый из этих шагов, давайте формали- зуем обозначения, которые будут использоваться в дальнейшем. Рассмотрим задачу классификации, в которой c категорий. Мы обучаем модель, которая с учетом признака точки данных x предсказывает функцию распределения вероятности (probability mass function, PMF) pθ(y|x) по c категориям, парамет - ризуемую по θ. Здесь θ может быть одним вектором для линейных моделей или группой матриц для глубоких нейронных сетей. Для этого у нас есть размеченное множество кортежей ℒ = {(xi, yi)l i=1} и неразмеченное множество 𝒰 = {(x j)u j=1}. Показатели информативности Большинство методов активного обуче ния формулируют некий показатель полезности для каждого неразмеченного образца, на основании которого образцы выбираются для ручной маркировки. Одним из наиболее распро- страненных показателей информативности, упоминаемых в литературе, яв- ляется энтропия прогнозов (Settles, 2012; Li, Guo, 2014; Paul et al., 2016). Для заданной точки данных x энтропию можно представить следующим образом: (3.1) Более высокое значение энтропии означает, что классификатор не уверен в прогнозе и, следовательно, должна быть проведена ручная разметка. Ожидаемое изменение градиентов параметров модели (Settles, 2012) – это еще один показатель полезности, который измеряет величину изменения градиентов, возможных в модели, когда выборка x включена в обучающую выборку. Он рассчитывается как (3.2)\n--- Страница 172 ---\nКонтекстно-зависимое активное обучение  171 где l(., .) – функция потерь, используемая для изучения модели классифи- кации. Более высокое значение ожидаемого изменения градиента будет означать большее количество информации, содержащейся в точке данных. Аналогичными показателями, используемыми в литературе, также являются ожидаемое изменение выходных данных модели (Käding et al., 2016) и ожи- даемая частота ошибок (Cuong et al., 2013; Li, Guo, 2013). Плотность данных (Li, Guo, 2013), которая учитывает плотность точек дан- ных в пространстве признаков, является еще одним важным показателем активного обуче ния. Его можно определить следующим образом: (3.3) где nei(x) – соседние точки данных x. Более высокое значение D(x) будет озна- чать, что точки данных вокруг x очень близки друг к другу, и, таким образом, получение метки x будет полезно для понимания окружающих точек данных. Обратите внимание, что этот показатель обычно используется в сочетании с другими показателями, рассмотренными выше. Учитывая эти меры, мето- ды активного обуче ния выбирают точки данных для ручной аннотации, как обсуждается далее. Отбор информативных образцов Выбор информативных образцов в активном обучении зависит от назначе- ния модели и доступного бюджета на разметку. Существует два возможных способа выбора информативных образцов: последовательный, когда за один раз выбирается одна точка данных, или пакетный режим, когда за один раз выбираются несколько точек данных. После выбора образцов модель об- новляется, и для неразмеченных точек данных получаются новые оценки. Таким образом, в сценариях, где вычисления ограничены, пакетный режим может оказаться лучше, но последовательный метод может привести к более высокой производительности. Большинство активных методов обуче ния считают, что неразмеченный набор данных является фиксированным, что в общем случае может быть не так. Данные могут быть потоковыми, т. е. поступать порциями. В этом слу - чае мы должны выбрать определенную заранее часть для ручной разметки, которая обычно определяется на основе бюджета разметки на пакет. Более сложный, но полезный сценарий – это когда известен общий бюджет раз- метки и алгоритму необходимо самостоятельно выбрать подходящее под- множество для разметки для каждого пакета потоковых данных. Интересно отметить, что большинство рассмотренных выше методов определяют пока- затели информативности независимо для выборок без учета взаимосвязей, которые могут возникнуть между точками данных. Кроме того, эти методы учитывают активное изучение одной задачи за раз и не могут выполнять выборку для нескольких задач распознавания одновременно. Они рассмат - риваются ниже.\n--- Страница 173 ---\n172  Обучение с ограниченным подкреплением – статические и динамические задачи 3.2.2. Важность контекста активного обучения В этом разделе мы обсудим, как взаимосвязи между точками данных могут быть полезны для дальнейшего уменьшения подкрепления, необходимого для обуче ния задачам распознавания. Мы также обсудим, как можно разрабо- тать активное обуче ние для нескольких задач распознавания одновременно. Контекст в обучении В реальном мире между точками данных часто возникают отношения. Та- кие отношения в публикациях нередко называют контекстом. Например, рассмотрим отношения между сценами и объектами. Маловероятно найти «корову» в «спальне», но вероятность встретить в одной сцене «кровать» и «светильник» может быть высокой. Таким образом, получение информации о сцене может улучшить предсказание объектов, и наоборот. Точно так же события/действия в видео могут иметь пространственно-временную корре- ляцию, как показано на рис. 3.2. Обратите внимание на кадры: не зная дей- ствий a 2 и a 3, трудно предсказать, является ли действие a 1 выходом человека из машины или посадкой в машину. Отношения с другими видами деятель- ности помогают понять эту конкретную деятельность. Отношения также воз- никают между документами через гиперссылки или цитаты. Несколько работ показали, что во многих приложениях, таких как распознавание действий (Yao, Fei-Fei, 2010; Wang et al., 2013), распознавание объектов (Galleguillos et al., 2008; Choi et al., 2010), классификация текста (Sen, Getoor, 2003; Settles, Craven, 2008) и т. д., отношения между точками данных можно использовать для повышения эффективности распознавания. Во многих из этих работ для целостного понимания используются вероятностные графические модели (Koller, Friedman, 2009), машины структурных опорных векторов (structural support vector machines, SVM) (Cristianini, Ricci, 2008) и т. д. Даже в эпоху глубокого обуче ния условные случайные поля (Koller, Friedman, 2009) ис - пользуются для лучшего понимания сцены. Рис. 3.2  Последовательность видеопотока из (Oh et al., 2011) представляет три новых неразмеченных действия: человек, выходящий из машины (a 1) в мо- мент T + 0 с, человек, открывающий багажник автомобиля (a 2) в момент T + 7 с, и человек, несущий предмет (a 3) в момент T + 12 с. Корреляция этих действий в пространстве и времени может предоставить контекстуальную информацию для целостного понимания\n--- Страница 174 ---\nКонтекстно-зависимое активное обучение  173 Контекст для выбора запроса – общая идея Использование контекста в данных дает нам глобальное понимание сцены. Поэтому интересным направлением исследований является рассмотрение того, может ли контекст также быть полезен для уменьшения количества раз- меченных выборок. Идея заключается в том, что при наличии контекста, по- скольку прогнозы коррелированы, мы можем собрать информацию о боль- шом количестве неразмеченных точек данных, помечая лишь некоторые из них. Как обсуждалось ранее, в отличие от методов, которые не учитывают контекстную информацию в показателях информативности, контекстно-за- висимое активное обуче ние учитывает контекст, чтобы уменьшить количест - во аннотаций. Несмотря на то что в некоторых работах рассматриваются отношения между точками данных при активном обучении (Bilgic, Getoor, 2009; Mac Aodha et al., 2014; Hasan, Roy-Chowdhury, 2015; Hu et al., 2013), они не рас - сматривают поток убеждений между точками данных, чтобы иметь общее понимание их прогнозов, что может быть полезно для выбора наиболее информативных точек. Более того, большинство из них представляют со- бой алгоритмы, специфичные для конкретной задачи, и имеют дело с ак - тивным обуче нием одной задачи распознавания. Необходим общий подход к активному обуче нию, учитывающий взаимосвязь между точками данных и который можно использовать в различных предметных областях. Может потребоваться совместное изучение таких задач, как классификация «сце- на–объект» (Yao et al., 2012; Wang et al., 2016) или «деятельность–объект» (Jain et al., 2015; Koppula et al., 2013) в активном обучении, чтобы умень- шить усилия по ручной разметке. В таких сценариях сложно выбрать инфор- мативные образцы для ручной разметки, поскольку они могут относиться к разным задачам распознавания. Далее мы представляем основу для такого контекстно-зависимого активного обуче ния, в том числе применимого для нескольких задач. Контекст для выбора запроса – обзор Располагая неразмеченным набором, мы описываем схему (Paul et al., 2017), которая выбирает небольшое информативное подмножество точек данных для ручной разметки, используя контекстную информацию, то есть струк - турные отношения между точками. Логический конвейер данных в рамках данной структуры изображен на рис. 3.3. Мы начинаем с небольшого набора помеченных данных и используем его для построения моделей классифика- ции (𝒞 ) и отношений (ℛ ). Здесь ℛ представляет базовую связь между точками данных через категориальные вероятности совпадения. Обратите внимание, что модели классификации могут содержать несколько классификаторов для нескольких задач распознавания. После обуче ния первоначальных моделей с учетом новой партии неразмеченных образцов следующий шаг заключает - ся в том, чтобы выбрать подмножество информативных образцов для ручной разметки, которую можно использовать для обновления текущей классифи- кации и моделей отношений.\n--- Страница 175 ---\n174  Обучение с ограниченным подкреплением – статические и динамические задачи Небольшой размеченный набор Неразмеченный пакет данныхРазмеченный набор Запрос к оракулуИзвлечение признаков Извлечение признаковВывод Данные, преобразованные в графВыбор информативного образца Циклическое распространение доверияСубмодульная минимизацияОбновление ℛ и 𝒞Модель отношений ℛМодель классификации 𝒞 Рис. 3.3  На этом рисунке представлена схема обсуждаемого метода. 1. Не- большой набор размеченных данных используется для получения исходных отношений (ℛ) и модели классификации (𝒞 ). 2. По мере того как с течением времени становится доступным новый неразмеченный пакет данных, мы сна- чала извлекаем признаки из необработанных данных. Затем текущие модели ℛ и 𝒞 используются для построения графа на основе данных, чтобы представить отношения между ними. Потом графовый вывод используется для получения вероятностей узлов и ребер, которые, в свою очередь, применяются для фор- мирования информативных выборок, подлежащих ручной разметке. Наконец, вновь размеченные экземпляры используются для обновления моделей ℛ и 𝒞 По мере появления новых пакетов данных образцы в пакетах разделяются на разные наборы в зависимости от задачи распознавания, к которой они относятся, с последующим выделением признаков. Для каждого неразме- ченного образца при помощи текущих классификаторов получают функцию распределения вероятностей по возможным категориям. Она используется вместе с ℛ для построения графа, узлы которого представляют образцы. Для вычисления меры доверия каждого узла и ребер графов применяется гра- фовый анализ на основе алгоритма обмена сообщениями. Далее выводится теоретико-информационная целевая функция, которая использует меру до- верия при выборе наиболее информативных узлов для ручной разметки. Субмодульный характер этой функции оптимизации позволяет нам достичь результата эффективным в вычислительном отношении способом. Новые размеченные узлы используются для обновления моделей ℛ и 𝒞. Можно от - метить, что количество образцов, отбираемых из пакета, переменное и за- висит от информативности каждого пакета. 3.2.3. Фреймворк контекстно-зависимого активного обучения В этом разделе мы представляем фреймворк (набор методов и приемов) для использования контекстной информации, в частности отношений на осно- ве совпадения между точками данных, в среде активного обуче ния, чтобы уменьшить количество ручных аннотаций для обуче ния моделей распозна- вания.\n--- Страница 176 ---\nКонтекстно-зависимое активное обучение  175 Представление данных Учтите, что неразмеченные точки данных имеют некоторую базовую струк - туру, т. е. отношения между ними. Мы используем метод вероятностной гра- фической модели для построения графа, узлы которого представляют нераз- меченные образцы, а ребра отражают отношения между ними и работают в качестве путей для потока информации между узлами. Узлы представлены с использованием потенциалов узлов (node potential), т. е. прогнозов функ - ции распределения вероятностей (probability mass function, PMF) из текущих прог нозных моделей (одиночных или множественных для совместных за- дач). Ребра представлены с использованием потенциалов ребер (edge poten- tial) в виде матрицы совместной встречаемости между категориями, которая фактически является моделью отношений ℛ. Вычисление совместной встре- чаемости зависит от конкретного приложения и будет обсуждаться позже. Отметим, что этот фреймворк можно применять к любому приложению, содержащему отношения, которые можно смоделировать как потенциалы ребер. Построим граф G = (V, E) с экземплярами в 𝒰. Каждый узел в V = {v1, …, vN} представляет каждую точку данных. Ребра E = {(i, j)|vi и v j связаны} представ- ляют отношения между точками данных. Потенциалы узлов и ребер назна- чаются с использованием текущей модели классификации 𝒞 и модели отно- шений ℛ. Алгоритм передачи сообщений может использоваться для вывода меры доверия узла и ребра, которые представляют собой безусловные веро- ятности узла и попарное совместное распределение ребер соответственно. Для этой цели можно использовать алгоритм цикличного распространения доверия (loopy belief propagation, LBP) (Ugm, 2007). Отбор информативных образцов На этом этапе цель состоит в том, чтобы, используя вероятности узлов и ре- бер, выбрать небольшое подмножество Vl∗ ⊂ V для ручной разметки, что улучшит текущие модели 𝒞 и ℛ. Мы хотим выбрать такое подмножество узлов, чтобы совместная энтропия всех узлов H(V) была минимизирована. Совместная энтропия всех узлов графа может быть аппроксимирована сле- дующим образом: (3.4) Заметим, что общая энтропия графа может быть аппроксимирована толь- ко для циклического графа в целом, но приведенное выше выражение явля- ется точным представлением для ациклических графов. Пусть у нас есть два непересекающихся вершинных подграфа с вершинами Vl и Vnl и ребрами, разделенными соответственно на El и Enl. Далее, используя уравнение (3.4), мы можем выразить энтропию графа следующим образом: (3.5)\n--- Страница 177 ---\n176  Обучение с ограниченным подкреплением – статические и динамические задачи Если мы выберем Vl для ручной разметки, можно показать, что первый и последний члены приведенного выше уравнения становятся равными нулю, что будет уменьшением энтропии. Следовательно, нам нужно выбрать оптимальное подмножество Vl∗ такое, чтобы энтропия была минимизирова- на как можно сильнее. Задачу оптимизации выбора можно сформулировать следующим образом: (3.6) Вышеупомянутая задача оптимизации является NP-сложной и трудно ре- шаемой. Для эффективного поиска решения можно использовать эвристиче- ские методы, такие как метод ветвей и границ (branch and bound). Этот метод оптимизации необходим, когда есть строгие бюджетные ограничения на пакет данных, и мы рассмотрели эту проблему в одной из наших работ (Hasan et al., 2018). Однако каждый пакет данных может содержать неоднородный объем информации, и извлечение одинакового количества образцов с огра- ниченным бюджетом (т. е. K) из каждой партии в целом может быть не очень хорошей идеей. Будет лучше, если удастся определить количество образцов на основе информационного содержания каждой партии. Руководствуясь этой идеей, мы можем изменить приведенную выше задачу оптимизации, чтобы она не ограничивалась регуляризатором количества элементов мно- жества, следующим образом: где λ – положительный компромиссный параметр. Можно доказать, что целе- вая функция в уравнении (3.7) является субмодулярной, что упрощает задачу оптимизации по сравнению с уравнением (3.6). Минимизация субмодулярных функций (submodular function minimization, SFM) часто встречается в машин- ном обучении, теории игр, теории информации и т. д. Подробное описание можно найти в работе Маккормика (McCormick, 2005). Существуют некоторые алгоритмы, которые можно использовать для решения SFM за полиномиаль- ное время. Для решения задачи оптимизации можно использовать популяр- ный алгоритм Minimum Norm Point Фудзихиге–Вольфе (Fujishige et al., 2006). Обновление модели После того как выбранные образцы помечены аннотатором-человеком, мы выполняем графовый вывод, обусловленный полученной разметкой, что- бы обновить доверие узлов, а затем применяем концепцию слабого учите- ля (weak teacher) (Чжан и Чаудхури, 2015), которая не вовлекает человека. Мы выбираем узлы, у которых уверенность в классификации больше, чем ϵ, с соответствующей меткой, заслуживающие попадания в размеченное множество ℒ. Значение ϵ должно быть достаточно высоким, чтобы избежать неправильной разметки. Модель классификации 𝒞 обновляется путем пере- обучения классификатора с использованием ℒ. Модель ℛ состоит только из\n--- Страница 178 ---\nКонтекстно-зависимое активное обучение  177 матрицы совместной встречаемости ψ и увеличивается по мере использова- ния новых размеченных экземпляров. 3.2.4. Практическое применение В этом разделе мы обсудим несколько задач, при решении которых можно использовать контекстно-зависимое активное обуче ние, чтобы уменьшить усилия по ручной разметке. В первую очередь разберем три различных при- менения – совместную классификацию объектов сцены, распознавание дей- ствий и классификацию документов. Как показано на рис. 3.4, у приложений есть данные, которые имеют общие отношения между собой. Мы использу - ем линейные классификаторы, такие как машина опорных векторов (SVM) (Chang and Lin, 2011), в качестве базового классификатора во всех приложе- ниях, обсуждаемых далее. При активном обучении результаты применения этого метода обычно сравниваются с качеством классификации на базе пол- ного набора, т. е. с качеством, достигаемым, когда все точки данных (кроме тестового набора) размечены и используются для обуче ния. Мы также срав- ниваем наш метод активного обуче ния с другими популярными методами активного обуче ния, представленными в научных публикациях, например с пакетным ранжированием (Batch Rank, Chakraborty et al., 2015), BvSB (Li et al., 2012), энтропией (Entropy, Settles, 2012; Holub et al., 2008), выборкой на основе плотности (Density-Based Sampling, DENS) (Settles, 2012), ожидаемой длиной градиента (Expected Gradient Length, GRL) (Settles and Craven, 2008) и случайной выборкой (Random Sampling). Совместное распознавание объект–сценаРаспознавание документов Распознавание действийВремя Действие ДействиеОбъектОбъектОбъектСценаДокументы Документы Документы Документы Документы Действие Действие Рис. 3.4  Семантические графы контекста для трех задач, обсуждаемых в раз- деле 3.2.4, – совместное распознавание сцены и объекта, когда мы используем контекст, присутствующий между сценой и объектами на изображении, распо- знавание документа, когда информация о контекстных связях используется со- вместно через цитаты/веб-ссылки, и распознавание деятельности, когда после- довательности действий имеют общие пространственно-временные отношения\n--- Страница 179 ---\n178  Обучение с ограниченным подкреплением – статические и динамические задачи Классификация сцены и объектов Сцена и объекты обычно связаны контекстом и вместе встречаются в изобра- жениях. Хотя классификаторы сцен и объектов представлены по отдельности, их совместное понимание можно использовать в рамках активного обуче ния для сокращения объема ручной разметки (Yao et al., 2012). Это особенность нашего фреймворка, так как он может активно обучаться с несколькими за- дачами распознавания одновременно. Набор данных SUN (Choi et al., 2010; Xiao et al., 2010) хорошо подходит для экспериментов с этим фреймворком, поскольку он содержит аннотации как для всей сцены, так и для объектов сцены. Мы извлекаем признаки из предварительно обученных сетей VGG-net (Zhou et al., 2014) и Alex-net (Krizhevsky et al., 2012) для сцен и объектов соот - ветственно. Далее применяем выборочный поиск, используемый в конвей- ере RCNN, для получения предложений (гипотез) объектов. Как показано на рис. 3.4, при совместном распознавании сцены и объектов мы представля- ем каждое изображение в виде графа с одним узлом сцены и несколькими узлами объектов, соответствующими различным предложениям объектов на изображении. Граф считается полносвязным с двумя разными типами ребер – сцена–объект и объект–объект. Потенциал ребер для связей сце- на–объект вычисляется как частота совместной встречаемости категории сцены с категорией объекта; а для связей объект–объект потенциал ребер представляет собой частоту совместной встречаемости категорий объектов в изображении. В случае классификации сцен контекстно-зависимый метод активного обуче ния требует только 35 % ручной разметки для достижения практически 100%-ной точности классификации. Другие методы, описанные в литерату - ре, требуют около 60 % ручной разметки для получения аналогичной точ- ности. При распознавании объектов метод контекстно-зависимого актив - ного обуче ния требует 45 % ручной разметки, тогда как методы, описанные в литературе, требуют 65 % разметки для достижения аналогичной точности (почти 100 %). Наша работа (Bappy et al., 2016) по адаптации модели рас - познавания сцены и объектов демонстрирует результаты, специфичные для этого приложения. Классификация документов Документы, как правило, связаны между собой цитатами и гиперссылками, которые можно использовать с по мощью нашего метода активного обуче- ния, чтобы сократить усилия по ручной разметке. Для наших экспериментов по классификации документов мы используем набор данных CORA (Sen et al., 2008). Он состоит из 2708 научных публикаций, разделенных на семь катего- рий. В нем представлено 5429 ссылок (цитирований) между публикациями. В свою очередь, публикации представлены с по мощью словаря из 1433 уни- кальных слов, а векторы признаков Î {0, 1}1433 указывают на отсутствие или\n--- Страница 180 ---\nКонтекстно-зависимое активное обучение  179 наличие этих слов. Как показано на рис. 3.4, при классификации документов мы представляем все документы как узлы графа, которые связаны, если один документ цитирует другой документ. Мы рассматриваем потенциал ребер как частоту совместной встречаемости, когда публикация категории i цити- рует публикацию категории j . Для классификации документов контекстно-зависимому методу актив- ного обуче ния требуется всего 33 % ручных аннотаций, чтобы достичь прак - тически полной достоверности (Paul et al., 2017). Другие методы, описанные в литературе, требуют около 50 % ручной разметки для получения аналогич- ной точности. Это свидетельствует о том, что использование контекстной информации помогает уменьшить объем ручной разметки за счет исполь- зования сопутствующей информации, которая легко извлекается из наборов целевых данных. Классификация действий Последовательные действия, как правило, связаны в пространстве-времени, что можно использовать для уменьшения количества экземпляров, выбран- ных для ручной разметки. Для наших экспериментов по классификации действий мы используем набор данных VIRAT (Oh et al., 2011) о деятель- ности человека. Набор данных состоит из 11 видеороликов, разделенных на 329 последовательностей действий. Мы извлекли признаки, используя предварительно обученную модель трехмерных сверточных сетей (Tran et al., 2015). Мы извлекаем признаки для 16 кадров за раз с временным страй- дом 8, а затем применяем max-пулинг по временнóму измерению, чтобы получить один вектор для каждого действия. Мы считаем, что существует связь между двумя действиями, если они происходили в пределах опреде- ленного пространственно-временного расстояния. Мы рассматриваем по- тенциал ребер как совместную пространственно-временную встречаемость двух действий. В случае классификации деятельности метод активного обуче ния с учетом контекста требует лишь около 18 % ручной разметки для достижения почти полной точности. Другие методы, описанные в литературе, требуют око- ло 40 % ручной разметки для достижения аналогичной точности. Обратите внимание, что, хотя в этом эксперименте мы используем отношения между категориями действий, мы также можем использовать контекстную инфор- мацию, передаваемую объектами, вовлеченными в действия, что особенно важно в действиях, связанных с взаимодействием человека и объекта. На рис. 3.5 представлен пример, иллюстрирующий работу контекстно-зависи- мого метода активного обуче ния. Как видно из схемы, получение знаний о некоторых узлах помогает уменьшить энтропию других узлов, тем самым снижая затраты на ручную разметку.\n--- Страница 181 ---\n180  Обучение с ограниченным подкреплением – статические и динамические задачи Обновленная CRFНовая энтропияАктивный отбор Энтропия CFR Рис. 3.5  Пример реализации предлагаемой нами системы активного обуче- ния на части последовательности действий из набора данных VIRAT (Oh et al., 2011). Круги – это узлы действий вместе с их распределением вероятностей классов. Ребра имеют разную толщину в зависимости от попарной взаимной информации. Метки узлов: выход из автомобиля (GOV), открытие багажника (OVT), выгрузка из багажника (UOV), закрытие багажника (CVT) и посадка в ав- томобиль (GIV). Статистический анализ графа (вверху) дает нам предельное рас - пределение вероятностей узлов и ребер. Мы используем эти распределения для вычисления энтропии и взаимной информации. Относительная взаимная информация показана толщиной ребер, а энтропия узлов нанесена под верх - ней моделью CRF1. Уравнение (3.14) использует критерии энтропии и взаим- ной информации для выбора наиболее информативных узлов (2-OVT, 3-UOV и 7-OVT). Мы обуславливаем эти узлы (они выделены цветом) и снова выпол- няем вывод, что обеспечивает более точное распознавание и систему с более низкой энтропией (нижний граф) 3.3. Л оКаЛизация событий при сЛабой размет Ке Временнáя локализация активности является ключевой проблемой компью- терного зрения, где при наличии длинного видео алгоритм должен локали- зовать во времени части видео, соответствующие различным интересующим 1 CRF (conditional random field, условное случайное поле) – это графовая модель для классификации, в которой у вас есть два штрафа: один для классификации узлов и другой для ребер, когда штрафуется несогласованность соседних узлов. Характерным отличием этого метода является возможность учитывать контекст классифицируемого объекта. – Прим. перев.\n--- Страница 182 ---\nЛокализация событий при слабой разметке  181 категориям событий (Aggarwal, Ryoo, 2011). Недавний успех в решении этой задачи (Xu et al., 2017; Zhao et al., 2017) основан на полном обучении, которое нуждается в покадровой разметке действий. Однако получение такой точ- ной покадровой информации требует огромного ручного труда. Такой метод плохо масштабируется при увеличении числа камер и категорий действий. С другой стороны, человеку гораздо проще указать несколько категориаль- ных меток, которые инкапсулируют содержание видео. Кроме того, видео, доступные в интернете, часто сопровождаются тегами, обеспечивающими семантическую дискриминацию. Такую разметку на уровне видео обыч- но называют слабой разметкой (weak labels), и ее можно использовать для обуче ния моделей с возможностью классификации и локализации действий в видео, как показано на рис. 3.6. ОбучениеДайвинг Дайвинг ДайвингАннотации на уровне видео (cлабая, используется )Низкая стоимость разметки Огромная стоимость разметки Временнáя аннотация (cильная , НЕ используется ) Время Тестирование Входное видео Временнáя локализация Рис. 3.6  Здесь представлен протокол последовательных испытаний локали- зации действия со слабой разметкой. Обучающий набор состоит из видео с те- гами активности на уровне видео, а НЕ времени. Стоит отметить, что во время тестирования сеть не только предлагает метки действий в видео, но и опреде- ляет их местонахождение во времени В компьютерном зрении исследователи использовали слабую разметку при обучении моделей для нескольких задач, включая семантическую сег - ментацию (Hartmann et al., 2012; Khoreva et al., 2017; Yan et al., 2017), ви- зуальное отслеживание (Zhong et al., 2014), реконструкцию (Tulyakov et al., 2017; Kanazawa et al., 2016), обобщение видео (Panda et al., 2017), обуче ние роботизированным манипуляциям (Singh et al., 2017), субтитрирование ви- део (Shen et al., 2017), границы объектов (Khoreva et al., 2016), распознава- ние мест (Arandjelovic et al., 2016) и т. д. Проблема локализации со слабой разметкой аналогична слабому обнаружению объектов на изображениях, где метки категорий объектов предоставляются на уровне изображения. В этой области было проведено несколько исследований, в которых в основ-\n--- Страница 183 ---\n182  Обучение с ограниченным подкреплением – статические и динамические задачи ном использовались методы многовариантного обуче ния (multiple instance learning, MIL) (Чжоу, 2004) из-за их тесной связи с точки зрения структуры информации, доступной для обуче ния. Положительные и отрицательные па- кеты, необходимые для MIL, генерируются с по мощью современных методов предложения регионов (Li et al., 2016; Jie et al., 2017). Несмотря на сходство, временнáя локализация с использованием слабой разметки является гораздо более сложной задачей по сравнению с аналогичным обнаружением объек - тов. Основная причина заключается в дополнительных различиях в содержа- нии, а также в протяженности видео по временной оси. В нескольких работах (Bojanowski et al., 2015; Huang et al., 2016) рассматривалась доступность во время обуче ния информации о временнóм порядке действий, помимо раз- метки на уровне видео. Далее мы формально опишем задачу временной локализации со слабой разметкой, а затем представим ее решение. Постановка задачи. Предположим, что у нас есть обучающая выборка из n видео 𝒳 = {xi}n i=1 с переменной продолжительностью во времени, обозна- чаемой L = {li}n i=1 (после извлечения признаков), и набор меток действий 𝒜 = {ai}n i=1, где – метки mi(³ 1) для i-го видео. Мы также определяем множество категорий действий как 𝒮 = Èn i=1ai = {αi}C i=1. Во время тестирова- ния, исходя из видео x, нам нужно предсказать множество xdet = {(s j, ej, cj, pj)}n(x) j=1, где n(x) – количество обнаружений для x. Элементы sj, ej – время начала и время окончания j-го обнаружения, cj представляет прогнозируемую кате- горию действия с достоверностью pj. На рис. 3.7 представлен обзор фрейм- ворка для временной локализации событий со слабой разметкой, детали которого последовательно обсуждаются далее. Оптический поток Пулинг по времениКросс-энтропийная потеря ℒMILL Потеря сходства действий ℒCASLСлабая разметка видео Внимание во времени Другое видео RGB-поток Рис. 3.7  На этом рисунке представлен предлагаемый нами фреймворк для лока- лизации и классификации действий со слабой разметкой. Для имеющегося видео мы извлекаем признаки из двух потоков – RGB и оптического (optical flow). После объеди- нения векторов признаков из двух потоков мы обучаем несколько слоев, характерных для задачи слабой локализации, и, наконец, проецируем в пространство категорий, чтобы получить матрицу T×C, где T и C – количество временных шагов и категорий соответственно. Мы используем две функции потерь для обуче ния параметров сети – кросс-энтропийную потерю для прогнозов с пулингом во времени и потерю сходства совместных действий (coactivity similarity loss), полученную с использованием пары видеороликов, содержащих по крайней мере одну общую категорию\n--- Страница 184 ---\nЛокализация событий при слабой разметке  183 3.3.1. Архитектура сети Особое внимание мы уделяем двухпотоковым сетям (two-stream network), поскольку они инкапсулируют информацию как о признаках внешнего вида в потоке RGB, так и о признаках движения в оптическом потоке. Для извле- чения признаков мы используем две сети – UntrimmedNets (Wang et al., 2017), предварительно обученную на Imagenet, и I3D (Carreira, Zisserman, 2017). Обратите внимание, что остальная часть нашего фреймворка не зависит от используемых признаков. Количество кадров, отправляемых в качестве входных данных в эти сети, зависит от их архитектуры. Поток RGB сети Un- trimmedNets принимает 1 кадр в качестве входных данных, тогда как его оптический поток занимает пять кадров для каждого вектора признаков. В случае сети I3D и RGB, и оптический потоки занимают 16 кадров для каж - дого вектора признаков. Обычные видеоролики могут иметь большие различия по продолжитель- ности: от нескольких секунд до более часа. В системе со слабой разметкой мы располагаем информацией о метках для видео в целом, что требует об- работки всего видео сразу. Это может быть проблематично для очень длин- ных видео из-за ограничений памяти графического процессора. В качестве решения данной проблемы мы отправляем на вход все видео целиком, если его длина меньше предопределенной длины T, определяемой пропускной способностью графического процессора. Однако если длина видео больше T, мы случайным образом извлекаем из него клип длиной T со смежными кадрами и присваиваем извлеченному видеоклипу все метки всего видео. Можно отметить, что, хотя это может привести к некоторым ошибкам в раз- метке, данный способ выборки имеет преимущества дополнения данных и хорошо работает на практике. После извлечения признаков видео из двухпотоковых сетей мы получаем матрицу размерности Xi Î ℝT×2F, где T – количество временных шагов видео, а F – размерность признаков потоков, которые объединяются для получе- ния признаков с размерностью 2F . Затем мы пропускаем эти функции через полносвязный слой с нелинейностью ReLU и отсевом, после чего следует слой классификации, который дает нам окончательную матрицу категориальных прогнозов 𝒜 Î ℝT×C, где C – количество категорий. 3.3.2. k-max множественное обучение Задача локализации и классификации действий со слабой разметкой, описан - ная выше, может быть напрямую сопоставлена с задачей многовариантного обуче ния (multiple instance learning, MIL) (Чжоу, 2004). В MIL отдельные образ- цы группируются в две корзины, а именно положительные и отрицательные. Положительная корзина содержит по крайней мере один положительный экземпляр, а отрицательная корзина точно не содержит положительного эк - земпляра. Используя эти корзины в качестве обучающих данных, нам нужно обучить модель, которая сможет классифицировать как положительный или отрицательный каждый экземпляр, помимо классификации корзин. В нашем\n--- Страница 185 ---\n184  Обучение с ограниченным подкреплением – статические и динамические задачи случае мы рассматриваем все видео как набор экземпляров, где каждый эк - земпляр представлен вектором признаков в определенный момент времени. Чтобы вычислить потери для каждой корзины, т. е. видео в нашем случае, нам нужно представить каждое видео, используя один показатель достоверности для каждой категории. Для определенного видео мы вычисляем показатель активации, соответ - ствующий определенной категории, как среднее значение k-max активации по временному измерению для этой категории. Поскольку количество ви- деороликов в корзине сильно различается, мы устанавливаем k пропорцио- нальным количеству элементов в корзине. После этого применяем нелиней- ность softmax для получения функции распределения вероятности по всем категориям, что позволяет вычислить вектор прогнозов pi по категориям. Нам нужно сравнить эту PMF с эталонным распределением меток для каж - дого видео, чтобы вычислить потери MIL (MIL loss, MILL). Поскольку каждое видео может содержать несколько действий, мы представляем вектор меток для видео, где во временных позициях стоят единицы, если это действие происходит в видео, иначе стоят нули. Затем мы нормализуем этот эталон- ный вектор истинности, чтобы преобразовать его в действительный PMF. Таким образом, MILL представляет собой перекрестную энтропию между предсказанной PMF pi и эталоном, которую затем можно представить сле- дующим образом: (3.8) где yi = [yi1, …, yiC]T – нормализованный эталонный вектор, представляющий слабые метки. 3.3.3. Сходство совместных действий Потеря сходства совместных действий (coactivity similarity loss, CASL) при- меняет ограничения для лучшего обуче ния сетевых параметров в задаче локализации действий. Задача временнóй локализации и классификации дей- ствий (weakly supervised temporal activity localization, W-TALC) побуждает нас выявлять корреляции между видео похожих категорий. Прежде чем раскрыть этот вопрос более подробно, определим специфические для категории мно- жества для j-й категории как 𝒮j = {xi|$aik Î ai так, что aik = αj}, т. е. множество 𝒮j содержит все видео обучающего набора, одной из меток которого является действие αj. В идеале нам могут понадобиться следующие свойства пред- ставлений изученных признаков X i, которые обсуждались в разделе 3.3.1: видеопара, принадлежащая множеству 𝒮j (для любого j Î {1, …, C}), должна иметь сходные представления признаков в частях видео, где происходит действие α j; для одной и той же видеопары представление признаков части, где αj встречается в одном видео, должно отличаться от представления дру - гого видео, где α j не встречается.\n--- Страница 186 ---\nЛокализация событий при слабой разметке  185 Эти свойства не применяются напрямую в MILL. Поэтому мы вводим CASL, чтобы встроить желаемые свойства в изученные представления признаков. Поскольку у нас нет покадровых меток, мы используем категорийные акти- вации 𝒜 для определения необходимых частей действий. Функция потерь разработана таким образом, что помогает одновременно изучать представ- ление признака и проекцию пространства меток. Сначала мы нормализу - ем категорийные активации видео вдоль временной оси, используя нели- нейность softmax, чтобы получить 𝒜ˆ во время t и категорию j как 𝓐ˆi[j, t] = exp(𝓐 i[t, j])/ålit¢=1exp(𝓐 i[t¢, j]), где t обозначает моменты времени и j Î {1, …, C}. Мы называем их вниманием (attention), поскольку они относятся к частям видео, где происходит действие определенной категории. Высокое значение внимания для определенной категории указывает на высокую вероятность появления этой категории. Чтобы сформулировать функцию потерь, давайте сначала определим категориальные векторы признаков регионов с высоким и низким вниманием следующим образом: (3.9) где Hfj i, Lfj i Î ℝ2048 представляет агрегированные представления признаков области высокого и низкого внимания соответственно в видео i для катего- рии j. Чтобы реализовать два свойства, упомянутых выше, мы используем ранжирование кусочно-линейной функцией потерь (ranking hinge loss). Для видеопары xm, xn Î 𝒮j функция потерь может быть представлена следующим образом: ℒjmn = ½{max(0, d [Hfj m, Hfj n] – d[Hfj m, Lfj n] + δ) + max(0, d [Hfj m, Hfj n] – d[Lfj m, Hfj n] + δ)}, (3.10) где d[] – косинусное расстояние, а δ – параметр поля (margin parameter), и в наших экспериментах мы установили его равным 0,5. Два члена в функ - ции потерь эквивалентны по смыслу, и они означают, что функции области высокого внимания в обоих видео должны быть более похожими, чем функ - ция области высокого внимания в одном видео и функция области низкого внимания в другом видео. Сводные потери (total loss) для всего обучающего набора вычисляются для каждой пары видео, имеющей хотя бы одну общую категорию. Для обуче ния сети две функции потерь в уравнениях (3.8) и (3.10) могут быть оптимизированы совместно. Локализация. После обуче ния весов сети мы используем их для локализа- ции событий в видео во время тестирования. Для конкретного видео мы получаем оценки 𝒜 достоверности по категориям. Для каждой категории мы получаем порог, который является средней точкой между максимальной и минимальной активациями для этой категории, и используем его как порог активаций при получении локализаций.\n--- Страница 187 ---\n186  Обучение с ограниченным подкреплением – статические и динамические задачи 3.3.4. Практическая реализация В этом разделе мы исследуем эффективность предлагаемого фреймворка для локализации действий во времени и классификации видео со слабой маркировкой. Сначала обсудим наборы данных, а затем детали реализации, количественные и некоторые качественные результаты. Наборы данных Мы проводим экспериментальный анализ двух наборов данных, а именно ActivityNet v1.2 (Heilbron et al., 2015) и Thumos14 (Idrees et al., 2017). Эти два набора данных содержат необрезанные видеоролики с покадровыми мет - ками действий, происходящих в видео. Однако, поскольку наш алгоритм ориентирован на слабую разметку, мы используем только теги действий, свя- занные с полным видео. Набор данных ActivityNet v1.2 содержит 4819 видео для обуче ния и 2383 видео для проверки, которые мы используем для тести- рования. Количество упоминаемых категорий составляет 100; в среднем при- ходится 1,5 временных сегмента деятельности на одно видео. Набор данных Thumos14 содержит 200 видеороликов, которые мы используем для обуче- ния, и 212 тестовых видеороликов, разделенных на 20 категорий. Среди этих видеороликов 200 обучающих и 213 тестовых имеют разметку, относящуюся к 20 категориям. Хотя это меньший набор данных, чем ActivityNet1.2, вре- менные метки очень точны и содержат в среднем 15,5 временного сегмента деятельности на видео. В этом наборе данных есть несколько видеороликов, в которых происходит несколько действий, что делает его еще более слож - ным. Продолжительность видео также широко варьируется от нескольких секунд до более часа. Меньшее количество видео затрудняет эффективное обуче ние со слабой разметкой. Локализация действий Для сравнения качества локализации действий на шкале времени использует - ся математическое ожидание средней точности (mean average precision, mAP) при различных пороговых значениях IoU между прогнозируемой и истинной локализациями. Для Thumos14 мы обсуждаем среднее значение mAP для порогов IoU Î {0,1, 0,2, 0,3, 0,4, 0,5}. Результаты представлены в табл. 3.1, раз- деленной на три строки: (а) методы с использованием сильной разметки, т. е. с использованием временных аннотаций для каждого действия, появляюще- гося в видеороликах, (б) методы со слабой разметкой, предложенные другими авторами, и, наконец, (в) результаты метода, предложенного нами (Paul et al., 2018). Выяснилось, что даже со слабой разметкой, которую гораздо проще получить, наш алгоритм демонстрирует результаты, близкие к чрезвычайно трудоемким методам с сильной разметкой. Важно отметить, что хотя пред- варительно обученные признаки I3D (I3DF) Kinetics имеют некоторые знания о действиях, использование только MILL, как в (Wang et al., 2017), в сочетании с I3DF работает намного хуже, чем в сочетании с CASL, а именно 33,1 против 39,8. В случае ActivityNet v1.2 наш метод дает в среднем 18, тогда как методы, использующие строгую разметку, такие как SSN, дают 24,8.\n--- Страница 188 ---\nЛокализация событий при слабой разметке  187 Таблица 3.1. Сравнение качества обнаружения на Thumos14. UNTF и I3DF – это сокращения для признаков UntrimmedNet (предварительно обученные признаки ImageNet) и признаков I3D соответственно Обуче ние Методы Среднее loU 0,1:0,1:0,5 СильноеR-C3D (Xu et al., 2017) 43,1 SSN (Zhao et al., 2017b) 47,4 UntrimmedNets (Wang et al., 2017) 29,0 Слабое STPN (UNTF) (Nguyen et al., 2018) 30,9 STPN (I3DF) (Nguyen et al., 2018) 34,9 Слабое (Paul et al., 2018)MILL+CASL+UNTF 33,8 MILL+CASL+I3DF 39,8 Классификация действий Здесь мы представляем качество классификации видов деятельности при помощи предложенного нами фреймворка. Мы также используем математи - ческое ожидание средней точности (mAP) для вычисления качества класси- фикации на основе предсказанных оценок уровня видео p после применения softmax. Результаты представлены в табл. 3.2. Они свидетельствуют о том, что предлагаемый метод (Paul et al., 2018) работает значительно лучше, чем другие современные методы классификации видео. Это может быть частично связано с используемыми признаками, но, что наиболее важно, с тем, как происходит обуче ние в методах локализации действий со слабой разметкой, которые игнорируют фоновые области при классификации видео с содержа- щимися в них действиями. Таблица 3.2. Сравнение качества классификации на Thumos14. UNTF и I3DF – это сокращения для признаков UntrimmedNet (предварительно обученные признаки ImageNet) и признаков I3D соответственно Обуче ние Методы Thumosl4 ActivityNet-1.2 Сильное TSN (Wang et al., 2016b) 72,0 86,3 СлабоеUntrimmedNets (Wang et al., 2017) 82,2 91,3 MILL+CASL (Paul et al., 2018) 85,6 93,2 Качественные результаты Мы представляем несколько интересных примеров локализации с эталона- ми на рис. 3.8. На этом рисунке показаны два примера из Thumos14 и два из набора данных ActivityNet1.2. Чтобы проверить, как предлагаемый фрейм- ворк работает с видео за пределами вышеупомянутых наборов данных, мы протестировали обученные сети на случайно выбранных видео с YouTube. Представляем два таких примера обнаружения на рис. 3.8, используя модель, обученную на Thumos14. Первый пример на рис. 3.8 довольно сложен, поскольку локализация должна точно соответствовать частям видео, где происходит замах в гольфе, признаки которого в области RGB очень похожи на части видео, где игрок\n--- Страница 189 ---\n188  Обучение с ограниченным подкреплением – статические и динамические задачи готовится к замаху. Несмотря на это, наша модель способна локализовать соответствующие части замаха, возможно, на основе признаков потока. Во втором примере из Thumos14 обнаружение крикетного шота (cricket shot) и крикетного боула (cricket bowl) коррелирует во времени. Это связано с тем, что шот и боул1 – это два действия, которые в видео про крикет обычно встречаются одновременно. Чтобы научить модель выполнять точную лока- лизацию подобных действий, требуются видеоролики, в которых есть только одно из этих действий. Однако в наборе данных Thumos14 очень мало обуча- ющих примеров содержат только одно из этих двух действий, что объясняет поведение, отмеченное на рисунке. Жонглирование футбольным мячомЖонглирование мячикамиИгра на волынкеБоул в крикетеШот в крикетеКачели для гольфа Игра в поло Езда на велосипедеАктивация ОбнаружениеАктивация ОбнаружениеАктивация ОбнаружениеАктивация Обнаружение ЭталонАктивация Обнаружение ЭталонАктивация Обнаружение ЭталонАктивация Обнаружение ЭталонАктивация Обнаружение Эталон Рис. 3.8  На этом рисунке представлены некоторые результаты ка- чест венного анализа на наборах Thumos14, ActivityNet1.2 и нескольких случайных видео с YouTube 1 Shot – это удар, при помощи которого боулер отражает бросок (bowl). Поэтому в большинстве видео боул и шот присутствуют практически одновременно. В про- фессиональном крикете выделяют 17 разновидностей шота (к вопросу о сложности распознавания действия). – Прим. перев.\n--- Страница 190 ---\nСемантическая сегментация с использованием слабой разметки  189 В третьем примере, взятом из ActivityNet1.2, хотя игра в поло встречается в первой части видео, эта метка отсутствует в эталонном наборе. Однако наша модель способна локализовать даже такие сегменты деятельности! Тот же вывод применим и к четвертому примеру, где реальная волынка встреча- ется в кадрах редко, но отклик нашей модели точно совпадает с ее появле- нием, хотя ошибочные эталонные метки разбросаны почти по всему видео. Эти два примера красноречиво подтверждают необходимость использования локализации со слабой разметкой, поскольку получение точных и единодуш- ных эталонов от нескольких специалистов по маркировке является трудным, дорогостоящим, а иногда даже неосуществимым занятием. Пятый пример основан на случайно выбранном видео с YouTube. В нем есть человек, который жонглирует мячиками на открытом воздухе. Но боль- шинство видео в Thumos14 той же категории сняты в помещении, а чело- век занимает значительную часть кадра в пространстве. Несмотря на такие различия в данных, наша модель способна локализовать некоторые части деятельности. Тем не менее модель также предсказывает, что некоторые час - ти видео относятся к жонглированию футбольным мячом, что может быть связано с тем, что обучающие образцы в Thumos14 содержат комбинацию движений ног, рук и головы, и подмножество таких движений присутствует в «жонглировании мячами». Более того, интересно отметить, что первые два кадра показывают какой-то финт ногами с футбольным мячом, и он также определяется как жонглирование футбольным мячом. 3.4. семанти ЧесКая сегментация с испо ЛьзоВанием сЛабой размет Ки Семантическая сегментация – это задача, в которой по входному изображе- нию нам нужно обучить модель, способную предсказать категорию каждого пикселя в изображении. В современных методах (Chen et al., 2016; Zhao et al., 2017a) модель обычно представляет собой сверточные нейронные сети, которые обучаются с использованием аннотаций на уровне пикселей. Одна- ко модель сегментации, обученная на одном наборе данных, может плохо обобщаться на изображения из другого набора, из-за несовпадения домена (предметной области) между наборами. Таким образом, модель необходи- мо адаптировать к изображениям из целевого домена, в котором она будет работать. Но поскольку разметка целевых изображений может оказаться дорогостоящей или вовсе невозможной, нужно найти способ адаптировать обученную модель к целевому домену с минимальными затратами на раз- метку или даже без них. Методы адаптации домена без учителя (unsupervised domain adaptation, UDA) для семантической сегментации были разработаны для решения проб- лемы несовпадения доменов без затрат на аннотирование целевых изобра- жений. Методы, описанные в литературе, направлены на адаптацию модели, обученной в исходном домене с попиксельными эталонными метками, на- пример из симулятора, который требует наименьших усилий по разметке,\n--- Страница 191 ---\n190  Обучение с ограниченным подкреплением – статические и динамические задачи к целевому домену, который не имеет какой-либо разметки. Эти описанные в литературе методы UDA для семантической сегментации разрабатываются в основном с использованием двух механизмов: самообучения c псевдораз- меткой (pseudo-label self-training) и выравнивания распределения между исходным и целевым доменами. Для первого механизма попиксельная псев- доразметка генерируется с по мощью таких стратегий, как степень уверенно- сти (confidence score, Li et al., 2019; Hung et al., 2018) или обуче ние в режиме самоуправления (self-paced learning, Zou et al., 2018), но подобная псевдораз- метка специфична для целевого домена и не учитывает сопоставление между доменами. В случае второго механизма можно рассматривать различные пространства для работы процедуры сопоставления, такие как пиксель (Hoff - man et al., 2018; Murez et al., 2018), признак (Hoffman et al., 2016; Zhang et al., 2017), выход (Tsai et al., 2018; Chen et al., 2018) и патч (Tsai et al., 2019). Одна- ко сопоставление, выполняемое этими методами, не зависит от категории, что может быть проблематично, поскольку разрыв между доменами может варьироваться в зависимости от категории. Проблема отсутствия разметки в целевом домене может быть решена путем введения концепции использования слабой разметки (weak labels) в целевом наборе данных для адаптации. Такую слабую разметку можно ис - пользовать для сопоставления по категориям между исходным и целевым доменами, а также для обеспечения соблюдения ограничений на категории, присутствующие в изображении. Может быть несколько форм слабой размет - ки – метки на уровне изображения, точечные метки, которые мы исследуем в этом тексте, а также другие формы слабой разметки, такие как плотность пикселей определенных категорий, количество объектов и т. д., которые до- вольно легко приобрести у аннотатора. Важно отметить, что наша слабая раз- метка может быть получена на основе предсказания модели в условиях UDA или предоставлена человеком-оракулом в парадигме адаптации домена со слабым обуче нием (weakly-supervised domain adaptation, WDA), как показано на рис. 3.9. Стоимость целевой разметки в UDA равна нулю, а в случае WDA очень мала, как мы увидим далее. Литература по адаптации домена для моделей семантической сегмен- тации посвящена только методам обуче ния без учителя (UDA), и ее можно разделить на три категории: адаптация на уровне пикселей (Hoffman et al., 2018; Murez et al., 2018; Wu et al., 2018), которая направлена на сопоставле- ние пространства входного изображения; обуче ние псевдометкам (Zou et al., 2018; Sadat Saleh et al., 2018; Lian et al., 2019), которое направлено на мар- кировку немеченых целевых данных, использование исходной модели и ее использование для адаптации, а также адаптация признаков или выходного пространства (Tsai et al., 2018; Chen et al., 2018; Tsai et al., 2019; Du et al., 2019), целью которой является согласование выходного пространства между исход- ным и целевым доменами. Эффективность этих методов довольно низка по сравнению с методами с сильным обуче нием. Далее мы представляем наш метод (Paul et al., 2020), который можно использовать как для адаптации без разметки, так и для адаптации со слабой разметкой, а еще для преодоления разрыва в качестве с минимальными затратами на аннотации или без них. Мы начнем с формального определения задачи.\n--- Страница 192 ---\nСемантическая сегментация с использованием слабой разметки  191 Слабая разметка для адаптации домена Исходное изображение XS Целевое изображение XtМетка источника YS Прогнозируемый сегмент YˆtАдаптация домена или WDA UDA Автомобиль Человек Дорога Псевдослабая разметкаРазметка оракулом Рис. 3.9  На этом рисунке показано, как мы можем использовать слабую разметку на уровне изображения для адаптации домена двумя различными способами – либо вычисляемыми, т. е. псевдослабыми мет - ками (адаптация домена без учителя, UDA), либо получаемыми от чело- веческого оракула (доменная адаптация со слабым обуче нием, WDA) Определение задачи. У нас есть два домена – исходный и целевой. Задача за- ключается в том, чтобы адаптировать к целевому домену модель сегментации, обученную в исходном домене. В исходном домене мы имеем изображения и пиксельные метки, обозначаемые как 𝒥s = {Xi s, Yi s}Nsi=1. Наш целевой набор дан- ных содержит изображения и метки только на уровне изображения, такие как 𝒥t = {Xi t, Yi t}Nti=1. Векторы Xs, Xt Î ℝH×W×3, Ys Î ℝH×W×3 являются пиксельными уни- тарными (one-hot) векторами, yt = 𝔹C – многопозиционный (multihot) вектор, представляющий категорию изображения, а C – количество категорий как для исходного, так и для целевого наборов данных. Напомним, что в одном уни- тарном векторе только один из элементов вектора равен единице, а остальные равны нулю, в то время как в многопозиционных векторах несколько элемен- тов вектора могут быть равны единице. Такие метки на уровне изображения yt называются слабыми метками, так как они представляют собой гораздо более слабую форму разметки по сравнению с попиксельной разметкой. Мы можем либо найти их, и в этом случае мы называем их псевдослабыми метками (pseudo-weak labels, метод UDA), либо получить их от человеческого оракула и назвать их слабыми метками оракула (oracle-weak labels, метод WDA). Полу - чение слабых меток мы обсудим в разделе 3.4.4. Исходя из начальных условий, задача состоит в том, чтобы адаптировать модель сегментации G, обученную на исходном наборе данных 𝒥 s, к целевому набору данных 𝒥 t. 3.4.1. Слабые метки для классификации категорий Мы используем слабые метки yt и учим модель предсказывать наличие/от - сутствие категорий в целевых изображениях. Сначала пропускаем целевые\n--- Страница 193 ---\n192  Обучение с ограниченным подкреплением – статические и динамические задачи изображения Xt через G, чтобы получить прогнозы At Î ℝH¢×W¢×C, а затем при- меняем глобальный пулинговый слой для получения единого вектора прог - нозов для каждой категории: (3.11) где σs – сигмовидная функция, такая, что pt представляет вероятность появ- ления конкретной категории на изображении. Обратите внимание, что урав- нение (3.11) представляет собой гладкую аппроксимацию функции max. Чем выше значение k, тем лучше оно приближается к max. Мы принимаем k = 1, поскольку не хотим, чтобы сеть фокусировалась только на максимальном значении прогноза, которое может быть зашумленным, но также и на других прогнозах, которые могут иметь высокие значения. Используя pt и слабые метки yt, мы можем вычислить бинарную кросс-энтропийную потерю по категориям: (3.12) Эта часть процесса изображена в нижнем потоке рис. 3.10. Данная функ - ция потерь ℒc помогает идентифицировать категории, которые отсутствуют/ присутствуют на конкретном изображении, и заставляет сеть сегментации G обращать внимание на те объекты/вещи, которые частично идентифици- руются, когда исходная модель используется непосредственно на целевых изображениях. 3.4.2. Слабые метки для выравнивания признаков Потеря классификации с использованием слабых меток, введенная в (3.12), упорядочивает сеть, фокусируясь на определенных категориях. Однако со- поставление распределения по исходному и целевому доменам пока не рассмат ривается. Как обсуждалось в предыдущем разделе, представленные в литературе методы сопоставляют между доменами либо пространство при- знаков (Hoffman et al., 2016), либо выходное пространство (Tsai et al., 2018). Однако такое сопоставление не зависит от категории, поэтому оно может со- поставлять признаки категорий, которых нет в определенных изображениях. Более того, признаки, принадлежащие к разным категориям, могут иметь разные разрывы в домене. Таким образом, сопоставление по категориям может быть полезным, но оно не было широко изучено в UDA в части семан- тической сегментации. Чтобы решить эти проблемы, мы используем слабые метки на уровне изображения для сопоставления по категориям в прост - ранстве признаков. В частности, мы получаем категорийные признаки для каждого изображения с по мощью карты внимания, то есть предсказания сегментации, руководствуясь нашим модулем классификации с использо- ванием слабых меток, а затем сопоставляем эти признаки между исходным\n--- Страница 194 ---\nСемантическая сегментация с использованием слабой разметки  193 и целевым доменами. Далее обсудим механизм пулинга категорийных при- знаков, а затем метод состязательного сопоставления (adversarial alignment). Объединение признаков по категориям. Пусть у нас есть признаки послед- него слоя F Î ℝH¢×W¢×2048 и предсказание сегментации A Î ℝH¢×W¢×C. Отсюда мы получаем категориальные признаки для c-й категории в виде 2048-мерного вектора, используя предсказание как внимание, обращенное на следующие признаки: (3.13) где σ(A) – тензор размерности H¢×W¢×C, каждый канал которого в измере- нии категории представляет внимание по категориям, полученное softmax- операцией σ над пространственными измерениями. В итоге σ(A)(h¢,w¢,c) – это скаляр, F(h¢,w¢) представляет собой 2048-мерный вектор, а ℱc – это суммарный признак F(h¢,w¢), взвешенный по σ(A)(h¢,w¢,c) на пространственной карте H¢×W¢. Обратите внимание, что мы опускаем индексы s, t для источника и цели, поскольку используем одну и ту же операцию для получения категориаль- ных признаков для обоих доменов. Далее мы представляем механизм для согласования этих признаков между доменами. Обратите внимание, что мы будем использовать ℱc для обозначения пула признаков для категории c и ℱc для обозначения множества пулов признаков для всех категорий. Пулинг признаков по категориям показан в середине рис. 3.10. Сопоставление категориальных признаков. Для обуче ния сети сегмента- ции G таким образом, чтобы были сопоставлены исходные и целевые ка- тегориальные признаки, мы используем состязательную потерю при при- менении дискриминаторов для конкретных категорий Dc = {Dc}C c=1. Причина использования дискриминаторов для конкретных категорий заключается в том, чтобы гарантировать, что распределение признаков для каждой ка- тегории может быть сопоставлено независимо, что позволяет избежать за- шумленного моделирования распределения из смеси категорий. На практике мы обучаем C различных дискриминаторов, специфичных для категорий, чтобы различать категориальные признаки, взятые из исходного и целевого изображений. Функция потерь для обуче ния дискриминаторов Dc выглядит следующим образом: (3.14) Стоит отметить, что при обучении дискриминаторов мы вычисляем по- тери только для тех категорий, которые присутствуют в конкретном изобра- жении, – с по мощью слабых меток ys, yt Î 𝔹C, которые указывают, встреча- ется категория на изображении или нет. Тогда состязательную потерю для целевых изображений при обучении сети сегментации G можно выразить следующим образом:\n--- Страница 195 ---\n194  Обучение с ограниченным подкреплением – статические и динамические задачи (3.15) Исходное изображение XS Целевое изображение XtМетка источника YS Сегментация сети Повышение дискретизацииПотеря сегментации Совместные веса Глобальный пулинг Слой прогноза изображенияПотеря классификации изображенийЦелевая слабая разметка yiВнимание Пулинг по категориямПризнаки по категориямДискриминаторы по категориям Потеря выравнивания по категориям Потеря классификации домена Слабые метки Рис. 3.10  Предлагаемая архитектура состоит из сети сегментации G и моду- ля слабой разметки. Мы вычисляем попиксельные потери сегментации ℒs для исходных изображений и потери классификации изображений ℒc, используя слабые метки yt для целевых изображений. Обратите внимание, что слабые метки могут быть найдены как псевдослабые метки или предоставлены чело- веческим оракулом. Затем мы используем выходной прогноз A, преобразуем его в карту внимания σ(A) и объединяем признаки по категориям ℱc. Далее эти признаки сопоставляются между исходным и целевым доменами с использо- ванием потери сопоставления по категориям ℒc adv, управляемой дискримина- торами по категориям DC, которые обучены с по мощью потерь классификации доменов ℒc d Точно так же мы используем целевые слабые метки yt, чтобы сопоста - вить только те категории, которые присутствуют в целевом изображении. Минимизируя ℒc adv, сеть сегментации пытается обмануть дискриминатор, максимизируя вероятность того, что целевой категориальный признак бу - дет рассматриваться как взятый из исходного распределения. Эти функции потерь в (3.14) и (3.15) получены в правой части среднего прямоугольника на рис. 3.10. 3.4.3. Оптимизация сети Тренировка дискриминатора. Мы обучаем множество из C различных дис - криминаторов для каждой категории c. Мы используем исходное и целевое изображения для обуче ния дискриминаторов, которые учатся различать ка-\n--- Страница 196 ---\nСемантическая сегментация с использованием слабой разметки  195 тегориальные признаки, взятые либо из исходного, либо из целевого домена. Задача оптимизации для обуче ния дискриминатора может быть формально выражена следующим образом: Заметим, что каждый дис - криминатор обучается только с признаками, подвергнутыми пулингу в соот - ветствии с его конкретной категорией. Поэтому для заданного изображения мы обновляем только те дискриминаторы, которые соответствуют категори- ям, присутствующим на изображении. Обуче ние сети сегментации. Мы обучаем сеть сегментации с попиксельной кросс-энтропийной потерей ℒs на исходных изображениях, потерей клас - сификации изображений ℒc и состязательной потерей ℒadv на целевых изо- бражениях. Чтобы обучить G, объединяем эти функции потерь следующим образом: (3.16) Мы следуем стандартной процедуре обуче ния GAN (Goodfellow et al., 2014), чтобы поочередно обновлять G и DC. Обратите внимание, что при вычис - лении ℒc adv используются дискриминаторы по категориям DC. Поэтому мы исправляем DC и градиенты обратного распространения только для сети сегментации G . 3.4.4. Получение слабой разметки Выше мы предложили механизм использования слабых меток на уровне изо- бражения для целевых изображений и адаптации модели сегментации между исходным и целевым доменами. В этом разделе мы объясняем два метода получения такой слабой разметки на уровне изображения. Псевдослабые метки (UDA). Одним из способов получения слабых меток является их непосредственное нахождение с использованием имеющихся у нас данных, т. е. исходных изображений/меток и целевых изображений, что относится к случаю адаптации домена без учителя (UDA). В этой работе мы используем базовую модель (Tsai et al., 2018), чтобы адаптировать модель, обученную на эталонных данных, к целевому домену, а затем получаем сла- бые метки целевых изображений следующим образом: (3.17) где pc t – вероятность для категории c, вычисленная согласно (3.11), а T – порог, который мы установили равным 0,2 во всех экспериментах, если не указано иное. На практике мы вычисляем слабые метки онлайн во время обуче ния и избегаем любого дополнительного шага вывода. В частности, мы пропус - каем через сеть целевое изображение, получаем слабые метки, используя (3.17), а затем вычисляем функции потерь в (3.16). Поскольку слабые метки,\n--- Страница 197 ---\n196  Обучение с ограниченным подкреплением – статические и динамические задачи полученные таким образом, не требуют участия человека, адаптация с ис - пользованием таких меток является адаптацией без учителя. Адаптация домена со слабым обуче нием (WDA). В этой форме мы получаем слабые метки, запрашивая у человека-оракула список категорий, которые встречаются в целевом изображении. Поскольку мы нуждаемся в работе ора- кула над целевыми изображениями, то называем это адаптацией домена со слабым обуче нием (WDA). Стоит отметить, что подход WDA может быть прак - тически полезным, поскольку получать такие слабые метки, присвоенные человеком, намного проще, чем попиксельную разметку. Кроме того, ранее не проводилось никаких исследований с использованием этого подхода для адаптации домена. Чтобы показать, что наш метод может использовать различные формы слабых меток, полученных от оракула, мы дополнительно вводим точечное обуче ние1 (point supervision) согласно Bearman et al. (2016), что лишь незна- чительно увеличивает усилия по сравнению с разметкой на уровне изобра- жения. В этом сценарии мы случайным образом получаем одну координату пикселя каждой категории, принадлежащей изображению, т. е. множество кортежей {(hc, wc, c)|\"yc t = 1}. Для изображения мы вычисляем потери следую- щим образом: где Ot Î ℝH×W×C – выходное предсказание цели после попиксельной операции softmax . 3.4.5. Применения В этом разделе мы проводим оценку нашего фреймворка адаптации пред- метной области для семантической сегментации, где источником является набор данных, состоящий из смоделированных изображений уличных сцен (GTA5; Richter et al., 2016), а целевой набор состоит из изображений реаль- ного мира (городские пейзажи; Cordts et al., 2016). В качестве метрики мы используем отношение IoU. Для сети сегментации G применяем фреймворк DeepLab-v2 (Chen et al., 2016) с архитектурой ResNet-101 (He et al., 2016). Мы извлекаем признаки Fs, Ft перед слоем расширенного пространственно- го пирамидального пулинга (atrous spatial pyramid pooling, ASPP). В качестве категорийных дискриминаторов DC = {Dc}C c=1 используем C отдельных сетей, каждая из которых состоит из трех полносвязных слоев, имеющих {2048, 2048, 1} узлов с активацией ReLU. На рис. 3.11 даны результаты, представлен- ные в публикациях, и результаты применения нашего метода для различных используемых нами аннотаций. 1 Точечное обуче ние подразумевает указание на интересующие объекты на изобра- жении с по мощью щелчков мыши. Точечное обуче ние значительно дешевле и за- нимает меньше времени по сравнению с традиционными методами сильной раз- метки, такими как рисование ограничительной рамки и попиксельная маркировка изображений. – Прим. перев.\n--- Страница 198 ---\nСемантическая сегментация с использованием слабой разметки  197 GTA5 -> городские пейзажи Полная разметка (1,5 ч) Пятиточечная разметка WDA (100 с) Трехточечная разметка WDA (45 c) Одноточечная разметка WDA (45 с) WDA на уровне изображения (30 с) Псевдоразметка UDA (0 с) Без адаптации (0 с)Метрика качества (mIoU) Время на аннотирование рисунка (мин) Рис. 3.11  Сравнение результатов в сценарии «GTA5 ® городские пейза- жи» с различными уровнями разметки: без целевых меток («Нет адаптации» и «UDA»), слабые метки на уровне изображений (30 с), одноточечные метки (45 с) и полная попиксельная разметка («Все помечены»), которая занимает 1,5 часа на изображение в соответствии с (Cordts et al., 2016) Современные методы Анализируя современные методы, представленные в литературе, мы ви- дим, что все они не требуют затрат на разметку на целевой стороне. В такой обстановке достигаемые уровни качества относительно невысоки. Напри- мер, в упомянутом выше сценарии с GTA 5 в качестве источника и набором Cityscapes (городские пейзажи) в качестве цели показатель качества совре- менных методов составляет 45,4 (Chang et al., 2019), 46,5 (Tsai et al., 2019). al., 2019) и 47,2 (Li et al., 2019). Стоит отметить, что эти показатели выше, чем у модели, обученной на источнике и примененной непосредственно к цели, которая показала точность всего 36,6 %. Однако это намного ниже, чем значение 64,4, полученное в сценарии, когда все целевые изображения помечены аннотациями на уровне пикселей, но в таком случае разметка одного изображения занимает около 90 мин. Адаптация домена без учителя (UDA) По сравнению с методами, описанными в литературе, когда мы используем базовый метод (Tsai et al., 2018) для сопоставления только выходного про- странства, мы получаем уровень качества 41,4. Затем, когда используем по- терю классификации согласно уравнению (3.12), получаем качество всего 46,7. Когда мы добавляем потерю сопоставления по категориям согласно уравнению (3.15), то получаем качество 48,2. Отметим, что в этом методе мы используем псевдослабые метки, которые находит сама сеть по уравне- нию (3.17).\n--- Страница 199 ---\n198  Обучение с ограниченным подкреплением – статические и динамические задачи Адаптация домена со слабым обучением (WDA) Мы используем два разных типа аннотаций в WDA, о них пойдет речь ниже. Обратите внимание, что другими формами слабого обуче ния могут быть подсчет объектов, очень грубая оценка области охвата категорий, грубое на- чертание (scribble) и т. д. Обучающая разметка на уровне изображения. Когда мы используем анно- тации на уровне изображения, полученные от пользователя, и обучаем сеть сегментации, используя только потери классификации в уравнении (3.12), мы получаем качество 52. Когда добавляем потерю сопоставления домена по категориям, то получаем качество 53. Следует отметить, что нет опублико- ванных работ, в которых использовались бы слабые метки людей-оракулов для выполнения WDA. Что касается результатов, интересно отметить, что значительное повышение качества при использовании WDA по сравнению с UDA наблюдается для таких категорий, как грузовик, автобус, поезд и мо- тоцикл. Одна из причин заключается в том, что эти категории наиболее недопредставлены как в исходных, так и в целевых наборах данных. Таким образом, они не предсказываются в большинстве целевых изображений, но использование слабых меток помогает лучше их идентифицировать. Точечная обучающая разметка. На наш взгляд, заслуживает внимания еще один метод точечной разметки (Bearman et al., 2016), который лишь незна- чительно увеличивает время аннотирования по сравнению с разметкой на уровне изображения. Мы воспользовались этим методом и случайным обра- зом выбираем один пиксель для каждой категории в каждом целевом изобра- жении в качестве обучающего. В этом случае все детали и модули во время обуче ния одинаковы. С одной точкой, помеченной для каждой категории на каждом изображении, мы получаем показатель качества 56,4. Когда мы увеличиваем количество аннотаций до трех или пяти точек, помеченных для каждой категории на каждом изображении, показатель возрастает до 58,4 и 59,4 соответственно. Стоит отметить, что стоимость разметки у данного метода довольно низкая, как показано на рис. 3.11, но тем не менее он может обеспечить качество, сравнимое с попиксельной разметкой, которая требует огромных затрат. 3.4.6. Визуализация выходного пространства Некоторые визуализации вероятности предсказания сегментации для каж - дой категории изображены на рис. 3.12. До использования каких-либо сла- бых меток (третий ряд) вероятность может быть низкой, даже если на этом изображении присутствует категория. Однако, основываясь на этих перво- начальных прогнозах, наша модель может оценить категории, а затем явно указать их наличие/отсутствие в предлагаемых потерях классификации и по- терях сопоставления. Четвертая строка на рис. 3.12 показывает, что такие псевдослабые метки помогают сети обнаруживать области объекта/содер- жимого для лучшей сегментации. Например, четвертый и пятый столбцы\n--- Страница 200 ---\nОбучение с подкреплением со слабой разметкой для динамических задач  199 показывают, что хотя исходные вероятности предсказания довольно низки, результаты с использованием псевдослабых меток оцениваются правильно. Более того, последняя строка показывает, что прогнозы могут быть улучше- ны, когда у нас есть слабые метки, предоставленные оракулом. WDA UDA Слабая разметка с оракулом Тротуар Автобус Мотоцикл Выбоина Знак ЗаборПеред слабой разметкой ЭталонЦелевое изображениеПосле псевдослабой разметки Рис. 3.12  Визуализация вероятности предсказания сегментации по катего- риям до и после использования псевдослабых меток в GTA5 – Cityscapes. До адаптации сеть лишь частично выделяет области с малой вероятностью, а ис - пользование псевдослабых меток помогает адаптированной модели получать гораздо более качественные сегменты и приближается к модели с использова- нием слабой разметки с оракулом 3.5. обуЧение с под КрепЛением со сЛабой размет Кой дЛя динами ЧесКиХ зада Ч До сих пор в этой главе мы рассматривали в свете ограниченной разметки в основном статические задачи. Однако в реальных сценариях нам, возмож - но, придется построить систему, которая взаимодействует с окружающей средой для выполнения задачи и, таким образом, должна быть динамичной по своей природе, поскольку от ее текущего действия зависит точка данных, которую она получит следующей. Подобно статическим задачам, таким как классификация, локализация и сегментация, изучение динамических задач также довольно сложно по своей природе. Обуче ние с подкреплением (rein- forcement learning, RL) с использованием глубоких нейронных сетей (deep neural networks, DNN) продемонстрировало огромные успехи в таких дина- мических задачах, как игры (Mnih et al., 2015; Silver et al., 2016), в решении сложных задач робототехники (Levine et al. , 2016; Duan et al., 2016) и т. д. Однако из-за скудного подкрепления эти алгоритмы часто требуют огромно- го количества взаимодействий с окружающей средой, что дорого обходится в реальных приложениях, таких как беспилотные автомобили (Bojarski et\n--- Страница 201 ---\n200  Обучение с ограниченным подкреплением – статические и динамические задачи al., 2016) и манипуляции с использованием реальных роботов (Levine et al., 2016). Созданные вручную плотные функции вознаграждения (dense reward function) могут смягчить эти проблемы; однако в целом сложно разработать подробные функции вознаграждения для сложных реальных задач. Для более быстрого изучения политик потенциально может применяться имитационное обуче ние (imitation learning, IL) с использованием демонстра- ционных примеров, созданных экспертом (Argall et al., 2009). Но качество работы алгоритмов IL (Ross et al., 2011) зависит не только от компетентности эксперта, предоставляющего примеры, но и от распределения в пространстве состояний, представленного образцами, особенно в случае состояний высо- кой размерности. Во избежание такой зависимости от эксперта некоторые исследователи (Sun et al., 2017; Cheng et al., 2018) идут по пути совмещения RL и IL. Однако эти методы предполагают использование экспертной оценки, что может оказаться непрактичным в реальных сценариях. Учитывая недостатки методов, предложенных другими исследователями, мы представляем стратегию, которая начинается с IL, а затем переключается на RL (Paul et al., 2019). На этапе IL наш фреймворк выполняет предвари- тельное обуче ние с учителем, целью которого является нахождение полити- ки, которая лучше всего описывает демонстрационные примеры экспертов. Однако из-за ограниченной доступности экспертных примеров политика, найденная с по мощью IL, будет содержать ошибки, которые затем можно устранить с по мощью RL. Но обратите внимание, что функция вознагражде- ния в RL все еще скудна, что затрудняет обуче ние. Поэтому мы представляем метод, который использует подготовленные человеком примеры, чтобы раз- делить всю задачу на более мелкие подцели (промежуточные цели) и исполь- зовать их в качестве функции вознаграждения на этапе RL. Имея набор примеров, люди могут быстро определить путевые точки, че- рез которые необходимо пройти для достижения цели. Мы склонны разби- вать сложную задачу на подцели и пытаться достичь их в наилучшем воз- можном порядке. Присущее людям предварительное знание помогает решать задачи намного быстрее (Andreas et al., 2017; Dubey et al., 2018), чем исполь- зование только обучающих примеров. Человеческая психология «разделяй и властвуй» чрезвычайно эффективна при решении различных задач, и она послужила основой для нашего алгоритма, который учится разделять про- странство состояний на подцели, используя экспертные примеры. Выучен- ные подцели обеспечивают дискретный сигнал вознаграждения, в отличие от непрерывного вознаграждения, основанного на ценности (Ng et al., 1999; Sun et al., 2018), которое может быть ошибочным, особенно при ограничен- ном количестве примеров в задачах с отдаленной целью. Поскольку набор экспертных примеров может не содержать всех состояний, которые агент может принять во время обуче ния на этапе RL, мы расширяем предиктор подцели с по мощью классификации одного класса, чтобы иметь возмож - ность работать с такими недопредставленными состояниями. Мы проводим эксперименты над тремя целевыми задачами на наборе MuJoCo (Тодоров, 2014) с разреженным вознаграждением только за успешное окончание, ко- торые современные модели RL, IL или их комбинации не могут решить.\n--- Страница 202 ---\nОбучение с подкреплением со слабой разметкой для динамических задач  201 Постановка задачи. Рассмотрим стандартную схему RL, в которой агент взаи- модействует со средой, которую можно смоделировать с по мощью марков- ского процесса принятия решений (markov decision process, MDP) ℳ = (𝒮, 𝒜, 𝒫, r, γ, 𝒫0), где 𝒮 – множество состояний, 𝒜 – множество действий, r – скалярная функция вознаграждения, γ Î [0, 1] – коэффициент дисконтирования, а 𝒫0 – начальное распределение состояний. Наша цель – выучить политику πθ(a|s), где a Î 𝒜, оптимизирующую ожидаемое дисконтированное вознаграждение 𝔼τ[å¥ t=0γtr(st, at)], где τ = (…, st, at, rt, …) и s0 ~ 𝒫0, at ~ πθ(a|st) и st+1 ~ 𝒫(st+1|st, at). При разреженном вознаграждении оптимизация ожидаемого дисконти- рованного вознаграждения со скидкой с использованием RL может вызвать затруднения. В таких случаях может быть полезно использовать множество примеров состояния-действия , сгенерированных экспер- том, для управления процессом обуче ния. Здесь nd – количество примеров в наборе данных, а ni – длина i-го примера. Мы предлагаем методику эф- фективного использования 𝒟 путем обнаружения подцелей в этих примерах и использования их для разработки внешней функции вознаграждения. Определение подцели Пусть пространство состояний 𝒮 разделено на множества состояний как {𝒮 1, 𝒮2, …, 𝒮ng}, таких, что 𝒮 = Èngi=1𝒮i и Çngi=1𝒮i = ∅, где ng – количество подцелей, указанных пользователем. Для каждого (s , a, s¢) мы полагаем, что конкретное действие переводит агента от одной подцели к другой тогда и только тогда, когда s Î 𝒮i, s¢ Î 𝒮j для некоторых i , j Î G = {1, 2, …, n g} и i ≠ j. Предположим, что существует порядок, в котором группы состояний по- являются в примерах, как показано на рис. 3.13(b). Однако состояния внутри этих групп состояний могут появляться в примерах в произвольном порядке. Эти группы состояний не определены априори, и наш алгоритм нацелен на оценку данных разделов. Надо сказать, что такое упорядочение является естественным в некоторых реальных сценариях, где определенная подцель Состояние s Действие aСостояние s¢ Оценщик подцелейПредсказатель подцелиСеть политикСреда Исходные состояния Траектории СостояниеКонечное состояниеПространство состояний 𝒮 (а) (b) Рис. 3.13  (a) Здесь показан обзор предложенного нами фреймворка для обуче ния сети политик вместе с функцией вознаграждения на основе расши- ренных внешних подцелей; (b) пример разделения состояния с двумя незави- симыми примерами черного и красного цветов. Обратите внимание, что окон- чательное состояние (terminal state) показано как отдельный раздел состояния, потому что мы предполагаем, что оно указано средой, а не выучено\n--- Страница 203 ---\n202  Обучение с ограниченным подкреплением – статические и динамические задачи может быть достигнута только после достижения одной или нескольких пре- дыдущих подцелей. Можно считать, что состояния в примере появляются в порядке возрастания индексов подцелей, т. е. достижение подцели j слож - нее, чем достижение подцели i (i < j). Это дает нам естественный способ определения внешней функции вознаграждения, которая поможет ускорить поиск политики. Кроме того, все примеры должны начинаться с начального распределения состояний и заканчиваться конечными состояниями. 3.5.1. Обучение прогнозированию подцелей Мы используем набор данных 𝒟 для разделения пространства состояний на ng подцелей, где ng является гиперпараметром. Мы учим нейронную сеть аппроксимировать πϕ(g|s), которая при заданном состоянии s Î 𝒮 предска- зывает функцию распределения вероятностей по возможным разбиениям подцелей g Î G. Порядок, в котором подцели встречаются в демоверсии, т. е. 𝒮1 < 𝒮2 < … 𝒮ng, которое можно вывести из нашего предположения, упомяну - того выше, действует как контролирующий сигнал. Фреймворк для обуче ния πϕ(g|s) является итеративным и подразумевает чередование между этапом обуче ния и этапом вывода/коррекции, как объясняется далее. Этап обуче ния. На этом этапе мы считаем, что у нас есть набор кортежей (s, g), которые мы используем для обуче ния функции πϕ. Это можно пред- ставить как задачу мультиклассовой классификации с ng категориями. Мы оптимизируем следующую кросс-энтропийную функцию потерь: (3.18) где 1 – индикаторная функция, а N – количество состояний в наборе данных 𝒟. Начнем с того, что у нас нет никаких меток g, поэтому мы рассматриваем равнораспределение всех подцелей в G по каждому примеру. То есть если дан пример состояний {s 1i, s2i, …, snii} для некоторого i Î {1, 2, …, nd}, то начальные подцели равного разделения будут такими: (3.19) С такой начальной схемой разметки аналогичные состояния в примерах могут иметь разные метки, но ожидается, что сеть будет сходиться при оценке максимального правдоподобия (maximum likelihood estimate, MLE) всего на- бора данных. Мы также оптимизируем CASL (Paul et al., 2018), представлен- ный в разделе 3.3.3, для стабильного обуче ния, поскольку начальные метки могут быть ошибочными. На следующей итерации этапа обуче ния мы исполь- зуем прогнозные метки подцелей, которые получаем следующим образом. Шаг вывода. Хотя метки равнораспределения в уравнении (3.19) могут иметь сходные состояния в разных примерах, сопоставленные с несовпадающими\n--- Страница 204 ---\nОбучение с подкреплением со слабой разметкой для динамических задач  203 подцелями, обученная сеть, моделирующая πϕ, сопоставляет сходные состоя- ния с одной и той же подцелью. Но уравнение (3.18) и, таким образом, пред- сказания πϕ не учитывают естественный временной порядок подцелей. Даже при использовании таких архитектур, как рекуррентные нейронные сети (re- current neural network, RNN), может быть лучше явно наложить подобные ограничения временного порядка, чем полагаться на сеть для их изучения. Мы вводим такие ограничения порядка, используя динамическое искажение времени (dynamic time warping, DTW). Формально для i-го примера в 𝒟 мы получаем следующее множество: {s ti, πϕ(g|sti)}nit=1, где πϕ – вектор, представляющий PMF по подцелям G. Однако, поскольку предсказания не учитывают временной порядок, ограничение на предмет того, что подцель j возникает после подцели i при i < j, не со- храняется. Чтобы наложить такие ограничения, мы используем DTW между двумя последовательностями {e 1, e2, …, eng}, которые являются стандартными базисными векторами в ng-мерном евклидовом пространстве, и {π ϕ(g|s1i), πϕ(g|s2i, …, πϕ(g|snii)}. B качестве меры подобия в DTW мы используем l1-норму разности двух векторов. В этом процессе мы связываем с каждым состоянием в примерах подцели, которые становятся новыми метками для обуче ния. Затем проводим этап обуче ния, используя новые метки (вместо уравнения (3.19)), за которыми следует этап вывода, чтобы получить следующие метки подцели. Мы продолжаем этот процесс до тех пор, пока число меток под- целей, изменившихся между итерациями, не станет меньше определенного порога. Этот метод представлен в алгоритме 3.1, где верхний индекс k обо- значает номер итерации в чередованиях обуче ния-вывода. Вознаграждение с использованием подцелей. Порядок подцелей, как упо- миналось ранее, обеспечивает естественный способ разработки функции вознаграждения следующим образом: (3.20) где агент в состоянии s выполняет действие a и достигает состояния s¢. Рас - ширенная функция вознаграждения принимает вид r + r¢. Учитывая, что у нас есть функция вида и что G = {0, 1, …, n g–1} без потери общности, так что для начального состояния Φϕ = (s0) = 0, из работы (Ng et al., 1999) следует, что каждая оптимальная политика в ℳ¢ = (𝒮, 𝒜, 𝒫, r + r¢, γ, 𝒫0) будет также оптимальной в ℳ, исходном MDP . Однако новая функция вознаграждения способна помочь быстрее обучиться под нужную задачу. Алгоритм 3.1. Обуче ние прогнозированию подцелей Исходные данные: обучающий набор примеров 𝒟 Выход: предиктор подцели π ϕ(g|s) k ¬ 0 Получить gk для каждого s Î 𝒟 с по мощью уравнения (3.19) повторить Оптимизировать (3.18) чтобы получить πk ϕ\n--- Страница 205 ---\n204  Обучение с ограниченным подкреплением – статические и динамические задачи Предсказать PMF G для каждого s Î 𝒟, используя πk ϕ Получить новые подцели gk+1, используя PMF в DTW завершить = Да, если |gk – gk+1| < ϵ, иначе Нет k ¬ k + 1 пока завершить ≠ Да 3.5.2. Предварительное обучение с учителем Как обсуждалось ранее, первоначальный способ использования обучающих примеров заключается в предварительном обучении сети политик πθ с ис - пользованием обучающего набора в среде обуче ния с учителем. Мы пред- варительно обучаем сеть, оптимизируя следующий параметр: (3.21) где l – функция потерь, которая может быть кросс-энтропийной или регрес - сионной, в зависимости от дискретных или непрерывных действий. Обрати- те внимание, что непрерывные действия состоят из (μ , σ), которые являются параметрами распределения Гаусса. Вторая часть уравнения (3.21) – поте- ря регуляризации l2. Политика, полученная после оптимизации уравнения (3.21), обладает способностью предпринимать действия с низким уровнем ошибок в состояниях, выбранных из распределения, индуцированного обучаю щим набором. Однако, как показано в работе Росса и др. (Ross et al., 2011), небольшая ошибка в начале будет увеличиваться квадратично от вре- мени, поскольку агент начинает посещать состояния, которые не выбраны из распределения 𝒟. Существуют такие алгоритмы, как DAgger, применяе- мые для точной настройки политики путем запроса экспертных решений в состоя ниях, посещенных после выполнения изученной политики. Однако такие запросы к эксперту часто обходятся очень дорого и в некоторых сце- нариях неосуществимы. Что еще более важно, поскольку DAgger стремится имитировать эксперта, в идеале он может только достичь его уровня каче- ства, но не превзойти. По этой причине мы выполняем тонкую настройку политики, используя RL с внешней функцией вознаграждения, полученной после определения подцелей. 3.5.3. Практическое применение В этом разделе мы представляем три сложные динамические задачи: исполь - зуем нашу структуру для их решения и сравниваем их с другими современ- ными методами, предложенными в различных публикациях. Задачи. Мы проводим эксперименты в трех сложных средах, изображенных на рис. 3.14. Первая среда – это игра «Мяч в лабиринте» (BiMGame; van Baar et al., 2018), где задача состоит в том, чтобы переместить шарик из самого внешнего кольца в самое внутреннее, используя набор из пяти дискретных\n--- Страница 206 ---\nОбучение с подкреплением со слабой разметкой для динамических задач  205 действий – поворот по часовой стрелке и против часовой стрелки на 1° по двум главным измерениям доски и «пустая операция», где сохраняет - ся текущая ориентация доски. Состояния представляют собой изображе- ния размером 84×84. Вторая среда – «Путешествие муравья» (AntTarget), в которой участвует муравей (Schulman et al., 2015). Задача состоит в том, чтобы достичь центра окружности радиусом 5 м, при этом муравей ини- циализируется на дуге окружности 45°. Состояние и действие непрерыв- ны с 41 и 8 измерениями соответственно. В третьей среде – «Муравьиный лабиринт» (AntMaze) – используется тот же муравей, но путешествующий в U-образном лабиринте (Held et al., 2017). Муравей инициализируется на одном конце лабиринта, а целью является другой конец, обозначенный красным цветом на рис. 3.14c. Для всех задач мы используем разреженное вознаграждение только на основе завершающего состояния, то есть 1 толь- ко после достижения цели и 0 в противном случае. Стандартные методы RL, такие как A3C (Mnih et al., 2016), не могут решить эти задачи с таким скудным вознаграждением. (a) (b) (c) Рис. 3.14  На этом рисунке представлены три среды, которые мы использу- ем: (a) игра «Мяч в лабиринте» (BiMGame); (b) передвижение муравья в откры- той среде с конечной целью (AntTarget); (c) передвижение муравья в лабиринте с конечной целью (AntMaze) Визуализация. Мы визуализируем подцели, обнаруженные нашим алгорит - мом, и наносим их на плоскость x–y, как показано на рис. 3.15. Как видно в случае BiMGame, с 4 подцелями наш метод может обнаружить узкие места на доске как разные подцели. В случае AntTarget и AntMaze путь к цели бо- лее или менее поровну делится на подцели. Это показывает, что наш метод обнаружения подцелей может работать как в средах с узкими местами, так и без них. Сравнение с другими методами. Мы в первую очередь сравниваем наш ме- тод с другими методами RL, которые используют обучающие примеры или экспертную информацию – AggreVaTeD (Sun et al., 2017) и формирование вознаграждения на основе ценности (Ng et al., 1999), что эквивалентно K = ∞ в THOR (Sun et al., 2018). Сравнение представлено на рис. 3.16. Как можно за- метить, ни один из исходных методов не показывает каких-либо признаков обуче ния задачам, за исключением ValueReward, который работает сравнимо\n--- Страница 207 ---\n206  Обучение с ограниченным подкреплением – статические и динамические задачи с предложенным нами методом только в случае AntTarget. Наш метод, с дру - гой стороны, способен последовательно учиться и решать задачи в течение нескольких прогонов. На графиках прямыми линиями показаны совокупные вознаграждения экспертов, и методы имитации обуче ния, такие как DAgger (Ross et al., 2011), могут достичь только этой отметки. Наш метод способен превзойти эксперта во всех задачах. На самом деле для AntMaze даже с до- вольно неоптимальным экспертом (среднее накопительное вознаграждение всего 0,0002) наш алгоритм достигает накопительного вознаграждения около 0,012 за 100 миллионов шагов. (a) BiMGame n g = 4 (b) AntTarget n g = 10 (c) AntMaze n g = 15 Рис. 3.15  (а) На этом рисунке представлены обозначенные разными цве- тами выученные подцели для трех задач. Обратите внимание, что для (b) и (c) нескольким подцелям назначается один и тот же цвет, но их можно различить по их пространственному расположению Плохие результаты ValueReward и AggreVaTeD могут быть связаны с не- совершенной функцией ценности, обученной с по мощью ограниченного количества примеров. В частности, при увеличении длины набора примеров вариации накопительного вознаграждения в начальном наборе состояний довольно велики. Это вносит значительную ошибку в функцию оценочного значения в начальных состояниях, что, в свою очередь, удерживает агента в ловушке некоторых локальных оптимумов, когда такие функции значений используются для управления процессом обуче ния. Обсуждение. Из полученных результатов можно сделать следующие ключе- вые выводы: во-первых, метод обнаружения подцелей работает как для задач с присущими им узкими местами (например, BiMGame), так и без узких мест (например, AntTarget и AntMaze), но с временны м порядком между группами состояний в экспертных примерах, что свойственно многим реальным сце- нариям. Во-вторых, дискретные вознаграждения с использованием подцелей работают намного лучше, чем непрерывные вознаграждения, основанные на функции ценности. Это может быть связано с тем, что функции ценности, извлеченные из ограниченного числа примеров, могут быть ошибочными, в то время как сегментация примеров на основе временнóго порядка может работать хорошо.\n--- Страница 208 ---\nВыводы  207 Предложенный AggreVaTeD Ценностное вознаграждение A3C ЭкспертПредложенный AggreVaTeD Ценностное вознаграждение A3C Эксперт Предложенный AggreVaTeD Ценностное вознаграждение A3C ЭкспертНакопительное вознаграждениеНакопительное вознаграждение Накопительное вознаграждение Число выборок (млн) (a) BiMGameЧисло выборок (млн) (b) AntTarget Число выборок (млн) (c) AntMaze Рис. 3.16  На этом рисунке показано сравнение предложенного нами метода с аналогичными методами. Некоторые линии могут быть не видны, так как они перекрываются. В задачах (а) и (c) наш метод явно превосходит другие. В задаче (b), несмотря на то что ценностное вознаграждение работает лучше, наш метод в конечном итоге достигает того же уровня. Для справедливого сравнения мы не используем расширенные примеры вне набора для создания этих графиков. Поскольку некоторые алгоритмы вообще не обучаются, накапливая нулевое вознаграждение, такие линии пересекаются с осью x графиков и не видны 3.6. В ыВоды Широко разрекламированные успехи машинного обуче ния во многом об- условлены наличием огромных объемов размеченных данных, используе- мых для обуче ния моделей. К сожалению, это абсолютно невозможно при обуче нии многих реальных моделей. Невозможно предусмотреть наперед, на этапе обуче ния, все сценарии, которые могут возникнуть во время работы поведенческой системы, а экспертные знания для расстановки меток могут просто отсутствовать. Например, если кошки и собаки могут быть правильно помечены на изображениях практически кем угодно, этого нельзя сказать про разметку различных видов птиц, типов растительности или медицин- ских диагнозов. Таким образом, обуче ние с ограниченным участием учителя или без него приобретает важное прикладное значение. В этой главе был представлен обзор машинного обуче ния с ограничен - ным участием учителя (с ограниченной разметкой) для приложений в об-\n--- Страница 209 ---\n208  Обучение с ограниченным подкреплением – статические и динамические задачи ласти компьютерного зрения и робототехники. Обуче ние с учителем может принимать разные формы и зависит от предметной области. Поэтому мы рассмотрели несколько различных методов. Первый подход связан с актив- ным обуче нием, где мы показали, как контекстную информацию, присут - ствующую в источниках данных, можно использовать для прогнозирования многих меток, которые в противном случае, возможно, придется добавлять вручную. Далее мы рассмотрели ситуации, когда подробная (сильная) раз- метка недоступна, но текстовые описания, сопровождающие видео, могут использоваться в качестве разновидности слабой разметки. Наша цель со- стоит в том, чтобы научиться локализовать соответствующий видеосегмент по этим описаниям. Обучающие и рабочие видео находятся в одном доме- не (предметной области). В следующем разделе мы рассмотрели проблему семантической сегментации изображения и то, как обученные модели из одного домена могут быть адаптированы к другому домену с минимальным участием учителя или даже без него. Наконец, разобрали обуче ние робота определенным задачам на ограниченных демонстрационных примерах, ис - пользуя комбинацию имитации и обуче ния с подкреплением посредством выделения подцелей. Таким образом, мы исследовали различные парадигмы обуче ния и продемонстрировали их на примерах различных задач в компью- терном зрении и робототехнике. Будущее машинного обуче ния будет основано на использовании огра- ниченных объемов обучающих данных. Исследователям и практикующим специалистам следует рассмотреть различные перспективные направления. Несколько примеров приведены ниже. Можем ли мы использовать для ка- чественного обуче ния моделей огромный объем данных, загружаемых в со- циальные сети, при условии что эти данные содержат множество ошибок и пробелов? Можем ли мы перенести обученные модели из доменов, в кото- рых доступна легкая разметка, в домены, требующие значительного опыта для разметки (например, разметка птиц и деревьев проста, но точная раз- метка видов птиц и деревьев требует серьезных знаний, которыми обладают лишь немногие люди)? Можем ли мы адаптировать обученные модели к не- знакомым условиям, которые могут иметь решающее значение для безопас - ности (например, может ли система автономного вождения выявить опасную ситуацию на дороге, если не сталкивалась с ней при обучении)? Можно ли использовать машинное обуче ние в областях, где есть большие объемы дан- ных, например в медицине, но обуче ние с учителем является очень дорогим (или даже невозможным)? В этой главе были представлены лишь первые шаги в направлении реше- ния вышеупомянутых проблем. Впереди нас ждет огромный объем работы. Хотя может показаться, что машинное обуче ние во многих случаях способно превзойти качество и надежность человеческих решений, оно в большинстве случаев нуждается в подготовленных обучающих данных. Присущая челове- ку способность рассуждать, абстрагироваться и определять общие принципы, которые можно перенести в другие домены, остается для машинного обуче- ния далекой и труднодостижимой целью. На пути к этой цели необходимо решить много сложных проблем.\n--- Страница 210 ---\nЛитературные источники  209 бЛагодарности Работа была частично поддержана Национальным научным фондом США через грант 1724341, Управлением военно-морских исследований США через грант N00014-19-1-2264 и исследовательскими лабораториями Mitsubishi Electric. Литературные исто ЧниКи Aggarwal Jake K., Ryoo Michael S., 2011. Human activity analysis: a review. ACM Computing Surveys (CSUR) 43 (3), 16. Andreas Jacob, Klein Dan, Levine Sergey, 2017. Modular multitask reinforcement learning with policy sketches. In: ICML, pp. 166–175. Arandjelovic Relja, Gronat Petr, Torii Akihiko, Pajdla Tomas, Netvlad Josef Sivic , 2016. Cnn architecture for weakly supervised place recognition. In: CVPR, pp. 5297–5307. Argall Brenna D., Chernova Sonia, Veloso Manuela, Browning Brett, 2009. A survey of robot learning from demonstration. RAS 57 (5), 469–483. Bappy Jawadul H., Paul Sujoy, Roy-Chowdhury Amit K., 2016. Online adaptation for joint scene and object classification. In: ECCV. Springer, pp. 227–243. Bearman Amy, Russakovsky Olga, Ferrari Vittorio, Fei-Fei Li, 2016. What’s the point: semantic segmentation with point supervision. In: ECCV. Bilgic Mustafa, Getoor Lise, 2009. Link-based active learning. In: NIPS-Workshop. Bojanowski Piotr, Lajugie Rémi, Grave Edouard, Bach Francis, Laptev Ivan, Ponce Jean, Schmid Cordelia, 2015. Weakly-supervised alignment of video with text. In: ICCV. IEEE, pp. 4462–4470. Bojarski Mariusz, Del Testa Davide, Dworakowski Daniel, Firner Bernhard, Flepp Beat, Goyal Prasoon, Jackel Lawrence D., Monfort Mathew, Muller Urs, Zhang Jiakai, et al., 2016. End to end learning for self-driving cars. arXiv preprint. arXiv:1604.07316. Carreira Joao, Zisserman Andrew, 2017. Quo vadis, action recognition? A new model and the kinetics dataset. In: CVPR. IEEE, pp. 4724–4733. Chakraborty Shayok, Balasubramanian Vineeth, Sun Qian, Panchanathan Sethura- man, Ye Jieping, 2015. Active batch selection via convex relaxations with guar - anteed solution bounds. TPAMI 37 (10), 1945–1958. Chang Chih-Chung, Lin Chih-Jen, 2011. Libsvm: a library for support vector ma- chines. TIST 2 (3), 27. Chang Wei-Lun, Wang Hui-Po, Peng Wen-Hsiao, Chiu Wei-Chen, 2019. All about structure: adapting structural information across domains for boosting seman- tic segmentation. In: CVPR. Chen Liang-Chieh, Papandreou George, Kokkinos Iasonas, Murphy Kevin, Deeplab Alan L. Yuille, 2016. Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. CoRR. arXiv: 1606.00915 [abs].\n--- Страница 211 ---\n210  Обучение с ограниченным подкреплением – статические и динамические задачи Chen Yuhua, Li Wen, Van Gool Road Luc, 2018. Reality oriented adaptation for semantic segmentation of urban scenes. In: CVPR. Cheng Ching-An, Yan Xinyan, Wagener Nolan, Boots Byron, 2018. Fast Policy Learn- ing Through Imitation and Reinforcement. UAI. Choi Myung Jin, Lim Joseph J., Torralba Antonio, Willsky Alan S., 2010. Exploiting hierarchical context on a large database of object categories. In: CVPR. IEEE, pp. 129–136. Cordts Marius, Omran Mohamed, Ramos Sebastian, Rehfeld Timo, Enzweiler Markus, Benenson Rodrigo, Franke Uwe, Roth Stefan, Schiele Bernt, 2016. The cityscapes dataset for semantic urban scene understanding. In: CVPR. Cristianini N., Ricci Elisa, 2008. Support vector machines. Encyclopedia of algo- rithms. Cuong Nguyen Viet, Lee Wee Sun, Ye Nan, Chai Kian Ming A., Chieu Hai Leong, 2013. Active learning for probabilistic hypotheses using the maximum Gibbs error criterion. In: NIPS, pp. 1457–1465. Du Liang, Tan Jingang, Yang Hongye, Feng Jianfeng, Xue Xiangyang, Zheng Qibao, Ye Xiaoqing, Zhang Xiaolin, 2019. Ssf-dan: separated semantic feature based domain adaptation network for semantic segmentation. In: ICCV. Duan Yan, Chen Xi, Houthooft Rein, Schulman John, Abbeel Pieter, 2016. Bench- marking deep reinforcement learning for continuous control. In: ICML, pp. 1329–1338. Dubey Rachit, Agrawal Pulkit, Pathak Deepak, Griffiths Thomas L., Efros Alexei A., 2018. Investigating human priors for playing video games. In: ICML. Fujishige Satoru, Hayashi Takumi, Isotani Shigueo, 2006. The minimum-norm-point algorithm applied to submodular function minimization and linear program- ming. In: Citeseer. Galleguillos Carolina, Rabinovich Andrew, Belongie Serge, 2008. Object categoriza- tion using co-occurrence, location and appearance. In: CVPR. IEEE, pp. 1–8. Goodfellow Ian J., Pouget-AbadieMehdi Mirza Jean, Xu Bing, Warde-Farley David, Ozair Sherjil, Courville Aaron, Bengio Yoshua, 2014. Generative adversarial nets. In: NIPS. Hartmann Glenn, Grundmann Matthias, Hoffman Judy, Tsai David, Kwatra Vivek, Madani Omid, Vijayanarasimhan Sudheendra, Essa Irfan, Rehg James, Sukthankar Rahul, 2012.Weakly supervised learning of object segmentations from web- scale video. In: ECCVW. Springer, pp. 198–208. Hasan Mahmudul Paul, Sujoy Mourikis Anastasios I., Roy-Chowdhury Amit K., 2018. Context-aware query selection for active learning in event recognition. T-PAMI. Hasan Mahmudul, Roy-Chowdhury Amit K., 2015. Context aware active learning of activity recognition models. In: ICCV. IEEE, pp. 4543–4551. He Kaiming, Zhang Xiangyu, Ren Shaoqing, Sun Jian, 2016. Deep residual learning for image recognition. In: CVPR. Heilbron Fabian Caba, Escorcia Victor, Ghanem Bernard, Niebles Juan Carlos, 2015. Activitynet: a large-scale video benchmark for human activity understanding. In: CVPR. IEEE, pp. 961–970. Held David, Geng Xinyang, Florensa Carlos, Abbeel Pieter, 2017. Automatic goal generation for reinforcement learning agents. In: ICML.\n--- Страница 212 ---\nЛитературные источники  211 Hoffman Judy, Tzeng Eric, Park Taesung, Zhu Jun-Yan, Isola Phillip, Saenko Kate, Efros Alexei A., Cycada Trevor Darrell, 2018. Cycle-consistent adversarial domain adaptation. In: ICML. Hoffman Judy, Wang Dequan, Yu Fisher, Darrell Trevor, 2016. Fcns in the wild: pixel- level adversarial and constraint-based adaptation. CoRR. arXiv:1612.02649 [abs]. Holub Alex, Perona Pietro, Burl Michael C., 2008. Entropy-based active learning for object recognition. In: CVPRWorkshops. IEEE, pp. 1–8. Hu Xia, Tang Jiliang, Gao Huiji, Liu Actnet Huan, 2013. Active learning for net - worked texts in microblogging. In: SDM. SIAM, pp. 306–314. Huang De-An, Fei-Fei Li, Niebles Juan Carlos, 2016. Connectionist temporal mode- ling for weakly supervised action labeling. In: ECCV. Springer, pp. 137–153. Hung Wei-Chih, Tsai Yi-Hsuan, Liou Yan-Ting, Lin Yen-Yu, Yang Ming-Hsuan, 2018. Adversarial learning for semi-supervised semantic segmentation. In: BMVC. Idrees Haroon, Zamir Amir R., Jiang Yu-Gang, Gorban Alex, Laptev Ivan, Sukthankar Rahul, Shah Mubarak, 2017. The thumos challenge on action recognition for videos «in the wild». CVIU 155, 1–23. Jain Ashesh, Zamir Amir R., Savarese Silvio, Saxena Ashutosh, 2015. Structural-rnn: deep learning on spatiotemporal graphs. In: CVPR. Jie Zequn, Wei Yunchao, Jin Xiaojie, Feng Jiashi, Liu Wei, 2017. Deep self-taught learning for weakly supervised object localization. In: CVPR. Käding Christoph, Freytag Alexander, Rodner Erik, Perino Andrea, Denzler Joachim, 2016. Large-scale active learning with approximations of expected model out - put changes. In: GCPR. Springer, pp. 179–191. Kanazawa Angjoo, Jacobs David W., Chandraker Manmohan, 2016. Warpnet: weakly supervised matching for single-view reconstruction. In: CVPR, pp. 3253–3261. Khoreva Anna, Benenson Rodrigo, Hosang Jan, Hein Matthias, Schiele Bernt, 2017. Simple does it: weakly supervised instance and semantic segmentation. In: CVPR. Khoreva Anna, Benenson Rodrigo, Omran Mohamed, Hein Matthias, Schiele Bernt, 2016. Weakly supervised object boundaries. In: CVPR, pp. 183–192. Koller Daphne, Friedman Nir, 2009. Probabilistic Graphical Models: Principles and Techniques. MIT Press. Koppula Hema Swetha, Gupta Rudhir, Saxena Ashutosh, 2013. Learning human ac - tivities and object affordances from rgb-d videos. IJRR 32 (8), 951–970. Krizhevsky Alex, Sutskever Ilya, Hinton Geoffrey E., 2012. Imagenet classification with deep convolutional neural networks. In: NIPS, pp. 1097–1105. Lapedriza Agata, Pirsiavash Hamed, Bylinskii Zoya, Torralba Antonio, 2013. Are all training examples equally valuable? arXiv preprint. arXiv:1311.6510. Levine Sergey, Finn Chelsea, Darrell Trevor, Abbeel Pieter , 2016. End-to-end training of deep visuomotor policies. JMLR 17 (1), 1334–1373. Li Dong, Huang Jia-Bin, Li Yali, Wang Shengjin, Yang Ming-Hsuan, 2016. Weakly supervised object localization with progressive domain adaptation. In: CVPR, pp. 3512–3520. Li Xianglin, Guo Runqiu, Cheng Jun, 2012. Incorporating Incremental and Active Learning for Scene Classification. In: ICMLA, vol. 1. IEEE, pp. 256–261. Li Xin, Guo Yuhong, 2013. Adaptive active learning for image classification. In: CVPR, pp. 859–866.\n--- Страница 213 ---\n212  Обучение с ограниченным подкреплением – статические и динамические задачи Li Xin, Guo Yuhong, 2014. Multi-level adaptive active learning for scene classifica- tion. In: ECCV. Springer, pp. 234–249. Li Yunsheng, Yuan Lu, Vasconcelos Nuno, 2019. Bidirectional learning for domain adaptation of semantic segmentation. In: CVPR. Lian Qing, Lv Fengmao, Duan Lixin, Gong Boqing , 2019. Constructing self-motivated pyramid curriculums for cross-domain semantic segmentation: a non-adver - sarial approach. In: ICCV. Mac Aodha Oisin, Campbell Neill, Kautz Jan, Brostow Gabriel, 2014. Hierarchical subquery evaluation for active learning on a graph. In: CVPR. IEEE, pp. 564–571. McCormick S. Thomas, 2005. Submodular function minimization. Handbooks in Operations Research and Management Science 12, 321–391. Mnih Volodymyr, Badia Mehdi Mirza, Adria Puigdomenech, Graves Alex, Lillicrap Timothy, Harley Tim, Silver David, Kavukcuoglu Koray, 2016. Asynchronous methods for deep reinforcement learning. In: ICML, pp. 1928–1937. Mnih Volodymyr, Kavukcuoglu Koray, Silver David, Rusu Andrei A., Veness Joel, Bel- lemare Marc G., Graves Alex, Riedmiller,Martin, Fidjeland Andreas K., Ostrovski Georg, et al., 2015. Human-level control through deep reinforcement learning. Nature 518 (7540), 529. Murez Zak, Kolouri Soheil, Kriegman David, Ramamoorthi Ravi, Kim Kyungnam, 2018. Image to image translation for domain adaptation. In: CVPR. Ng Andrew Y., Harada Daishi, Russell Stuart, 1999. Policy invariance under reward transformations: theory and application to reward shaping. In: ICML, vol. 99, pp. 278–287. Nguyen Phuc, Liu Ting, Prasad Gautam, Han Bohyung, 2018. Weakly supervised ac - tion localization by sparse temporal pooling network. In: CVPR. Oh Sangmin, Hoogs Anthony, Perera Amitha, Cuntoor Naresh, Chen Chia-Chih, Taek Lee Jong, Mukherjee Saurajit, Aggarwal J. K., Lee Hyungtae, Davis Larry, et al., 2011. A large-scale benchmark dataset for event recognition in surveillance video. In: CVPR. IEEE, pp. 3153–3160. Panda Rameswar, Das Abir, Wu Ziyan, Ernst Jan, Roy-Chowdhury Amit K., 2017. Weakly supervised summarization of web videos. In: ICCV, pp. 3657–3666. Paul Sujoy, Bappy Jawadul H., Roy-Chowdhury Amit K., 2016. Efficient selection of informative and diverse training samples with applications in scene classifica- tion. In: ICIP . IEEE, pp. 494–498. Paul Sujoy, Bappy Jawadul H., Roy-Chowdhury Amit K., 2017. Non-uniform subset selection for active learning in structured data. In: CVPR, pp. 6846–6855. Paul Sujoy, Roy Sourya, Roy-Chowdhury Amit K., 2018. W-talc: weakly-supervised temporal activity localization and classification. In: ECCV, pp. 563–579. Paul Sujoy, Tsai Yi-Hsuan, Schulter Samuel, Roy-Chowdhury Amit K., Chandraker, Manmohan 2020. Domain adaptive semantic segmentation using weak labels. In: ECCV. Paul Sujoy, Vanbaar Jeroen, Roy-Chowdhury Amit, 2019. Learning from trajectories via subgoal discovery. In: NeurIPS, pp. 8411–8421. Richter Stephan R., Vineet Vibhav, Roth Stefan, Koltun Vladlen, 2016. Playing for data: ground truth from computer games. In: ECCV. Ross Stéphane, Gordon Geoffrey, Bagnell Drew, 2011. A reduction of imitation learning and structured prediction to no-regret online learning. In: AISTATS, pp. 627–635.\n--- Страница 214 ---\nЛитературные источники  213 Sadat Saleh Fatemeh, Aliakbarian Mohammad Sadegh, Salzmann Mathieu, Peters- son Lars, Alvarez Jose M., 2018. Effective use of synthetic data for urban scene semantic segmentation. In: ECCV. Ugm Mark Schmidt, 2007. A Matlab toolbox for probabilistic undirected graphical models. Schulman John, Moritz Philipp, Levine Sergey, Jordan Michael, Abbeel Pieter, 2015. High-dimensional continuous control using generalized advantage estimation. In: ICLR. Sen Prithviraj, Getoor Lise, 2003. Link-based classification. In: ICML. Sen Prithviraj, Namata Galileo, Bilgic Mustafa, Getoor Lise, Galligher Brian, Eliassi- Rad Tina, 2008. Collective classification in network data. AI Magazine 29 (3), 93. Settles Burr, 2012. Active learning. Synthesis Lectures on Artificial Intelligence and Machine Learning 6 (1), 1–114. Settles Burr, Craven Mark, 2008. An analysis of active learning strategies for se- quence labeling tasks. In: EMNLP . Association for Computational Linguistics, pp. 1070–1079. Shen Zhiqiang, Li Jianguo, Su Zhou, Li Minjun, Chen Yurong, Jiang Yu-Gang, Xue Xiangyang, 2017. Weakly supervised dense video captioning. In: CVPR, vol. 2, p. 10. Silver David, Huang Aja, Maddison Chris J., Guez Arthur, Sifre Laurent, VanDen Driessche George, Schrittwieser Julian, Antonoglou Ioannis, Panneershelvam Veda, Lanctot Marc, et al., 2016. Mastering the game of go with deep neural networks and tree search. Nature 529 (7587), 484. Singh Avi, Yang Larry, Gplac Sergey Levine, 2017. Generalizing vision-based robotic skills using weakly labeled images. In: ICCV. Sun Wen, Bagnell J. Andrew, Boots Byron, 2018. Truncated horizon policy search: combining reinforcement learning & imitation learning. In: ICLR. Sun Wen, Venkatraman Arun, Gordon Geoffrey J., Boots Byron, Bagnell J. Andrew, 2017. Deeply aggrevated: differentiable imitation learning for sequential pre- diction. In: ICML, pp. 3309–3318. Todorov Emanuel, 2014. Convex and analytically-invertible dynamics with contacts and constraints: theory and implementation in mujoco. In: ICRA, pp. 6054– 6061. Tran Du, Bourdev Lubomir, Fergus Rob, Torresani Lorenzo, Paluri Manohar, 2015. Learning spatiotemporal features with 3d convolutional networks. In: ICCV. IEEE, pp. 4489–4497. Tsai Yi-Hsuan, Hung Wei-Chih, Schulter Samuel, Sohn Kihyuk, Yang Ming-Hsuan, Chandraker Manmohan, 2018. Learning to adapt structured output space for semantic segmentation. In: CVPR. Tsai Yi-Hsuan, Sohn Kihyuk, Schulter Samuel, Chandraker Manmohan, 2019. Do- main adaptation for structured output via discriminative patch representations. In: ICCV. Tulyakov Stepan, Ivanov Anton, Fleuret Francois, 2017. Weakly supervised learning of deep metrics for stereo reconstruction. In: CVPR, pp. 1339–1348. van Baar Jeroen, Sullivan Alan, Cordorel Radu, Jha Devesh, Romeres Diego, Nikovski Daniel, 2018. Sim-to-real transfer learning using robustified controllers in ro- botic tasks involving complex dynamics. In: ICRA.\n--- Страница 215 ---\n214  Обучение с ограниченным подкреплением – статические и динамические задачи Wang Botao, Lin Dahua, Xiong Hongkai, Zheng Y. F., 2016a. Joint inference of ob- jects and scenes with efficient learning of text-object-scene relations. TMM 18 (3), 507–520. Wang Limin, Xiong Yuanjun, Wang Zhe, Qiao Yu, Lin Dahua, Tang Xiaoou, Van Gool Luc, 2016b. Temporal segment networks: towards good practices for deep action recognition. In: ECCV. Springer, pp. 20–36. Wang Limin, Xiong Yuanjun, Lin Dahua, Van Gool Luc, 2017. Untrimmednets for weakly supervised action recognition and detection. In: CVPR. Wang Zhenhua, Shi Qinfeng, Shen Chunhua, Van Den Hengel Anton, 2013. Bilinear programming for human activity recognition with unknown mrf graphs. In: CVPR, pp. 1690–1697. Wu Zuxuan, Han Xintong, Lin Mustafa Gkhan Uzunbas Yen-Liang, Goldstein Tom, Nam Lim Ser, Dcan Larry S. Davis, 2018. Dual channel-wise alignment networks for unsupervised scene adaptation. In: ECCV. Xiao Jianxiong, Hays James, Ehinger Krista A., Oliva Aude, Torralba Antonio, 2010. Sun database: large-scale scene recognition from abbey to zoo. In: CVPR. IEEE, pp. 3485–3492. Xu Huijuan, Das Abir, Saenko Kate, 2017. R-c3d: region convolutional 3d network for temporal activity detection. In: ICCV, vol. 6, p. 8. Yan Yan, Xu Chenliang, Cai Dawen, Corso Jason, 2017. Weakly supervised actor- action segmentation via robust multi-task ranking. CVPR 48, 61. Yao Bangpeng, Fei-Fei Li, 2010. Modeling mutual context of object and human pose in human-object interaction activities. In: CVPR. IEEE, pp. 17–24. Yao Jian, Fidler Sanja, Urtasun Raquel, 2012. Describing the scene as a whole: joint object detection, scene classification and semantic segmentation. In: CVPR. IEEE, pp. 702–709. Zhang Chicheng, Chaudhuri Kamalika, 2015. Active learning from weak and strong labelers. In: NIPS, pp. 703–711. Zhang Yang, David Philip, Gon Boqing, 2017. Curriculum domain adaptation for semantic segmentation of urban scenes. In: ICCV. Zhao Hengshuang, Shi Jianping, Qi Xiaojuan, Wang Xiaogang, Jia Jiaya, 2017a. Pyra- mid scene parsing network. In: CVPR. Zhao Yue, Xiong Yuanjun, Wang Limin, Wu Zhirong, Tang Xiaoou, Lin Dahua, 2017b. Temporal action detection with structured segment networks. In: ICCV. Zhong Bineng, Yao Hongxun, Chen Sheng, Ji Rongrong, Chin Tat-Jun, Wang Hanzi, 2014. Visual tracking via weakly supervised learning from multiple imperfect oracles. Pattern Recognition 47 (3), 1395–1410. Zhou Bolei, Lapedriza Agata, Xiao Jianxiong, Torralba Antonio, Oliva Aude, 2014. Learning deep features for scene recognition using places database. In: NIPS, pp. 487–495. Zhou Zhi-Hua, 2004. Multi-Instance Learning: A Survey. Tech. Rep. Department of Computer Science & Technology, Nanjing University. Zou Yang, Yu Zhiding, Vijaya Kumar B. V. K., Wang Jinsong, 2018. Domain adapta- tion for semantic segmentation via class-balanced self-training. In: ECCV.\n--- Страница 216 ---\nОб авторах главы  215 об аВтора Х гЛаВы Суджой Пол в настоящее время работает в Google Research. Он получил докторскую степень в области электроники и вычислительной техники в Калифорнийском университете в Риверсайде и степень бакалавра в обла- сти электроники и телекоммуникаций в Университете Джадавпур. Область его научных интересов включает в себя компьютерное зрение и машинное обуче ние с упором на семантическую сегментацию, распознавание действий человека, адаптацию предметной области, обуче ние со слабой разметкой, активное обуче ние, обуче ние с подкреплением. Амит Рой-Чоудхури – профессор и научный сотрудник факультета электро- ники и вычислительной техники Bourns Family, директор Центра робото- техники и интеллектуальных систем и факультета информатики и вычис - лительной техники Калифорнийского университета в Риверсайде (UCR). Он возглавляет группу видеовычислений, работающую над основополагающи- ми принципами компьютерного зрения, обработки изображений и статис - тического обуче ния с применением в киберфизических, автономных и ин- теллектуальных системах. Он опубликовал более 200 работ в рецензируемых журналах и на конференциях. Является членом IEEE и IAPR, получил награду за консультирование и наставничество в области докторских диссертаций в 2019 г. от UCR и награду ECE Distinguished Alumni Award от Мэрилендского университета в Колледж-Парке.",
      "debug": {
        "start_page": 168,
        "end_page": 216
      }
    },
    {
      "name": "Глава 4. Эффективные методы глубокого обучения 216",
      "content": "--- Страница 217 --- (продолжение)\nГлава 4 Эффективные методы глубокого обучения Авторы главы: Хан Цай, Цзи Линь и Сун Хань, Массачусетский технологический институт, Кембридж, Массачусетс, США. Все авторы внесли равный вклад в эту работу и перечислены в алфавитном порядке. Краткое содержание главы: различные методы сжатия моделей, такие как прореживание, факториза- ция, квантование и разработка эффективных моделей; снижение стоимости проектирования путем подбора нейронной архи- тектуры, автоматического прореживания и дискретизации, которые могут превзойти ручное проектирование и требуют минимальных усилий со стороны человека; метод эффективной работы со многими аппаратными платформами и ограничениями эффективности без повторения дорогостоящих этапов поиска и переобучения. 4.1. сжатие моде Ли Сжатие глубокой нейронной сети – это действенный способ повысить эффек - тивность логического вывода. Методы сжатия включают прореживание1 пара- метров (parameter pruning) для удаления избыточных весов, низкоранговую факторизацию (low-rank factorization) для уменьшения сложности, кванто- вание весов (weight quantization) для уменьшения точности весов и размера модели, а также дистилляцию знаний (knowledge distillation) для переноса скрытых знаний (dark knowledge) из бóльших моделей в меньшие. В заключе- ние мы обсудим методы автоматического поиска хорошей политики сжатия без участия человека. 1 В публикациях по машинному обуче нию часто встречается калька «прунинг», но в этой книге мы будем использовать перевод. – Прим. перев.\nГлава 4 Эффективные методы глубокого обучения Авторы главы: Хан Цай, Цзи Линь и Сун Хань, Массачусетский технологический институт, Кембридж, Массачусетс, США. Все авторы внесли равный вклад в эту работу и перечислены в алфавитном порядке. Краткое содержание главы: различные методы сжатия моделей, такие как прореживание, факториза- ция, квантование и разработка эффективных моделей; снижение стоимости проектирования путем подбора нейронной архи- тектуры, автоматического прореживания и дискретизации, которые могут превзойти ручное проектирование и требуют минимальных усилий со стороны человека; метод эффективной работы со многими аппаратными платформами и ограничениями эффективности без повторения дорогостоящих этапов поиска и переобучения. 4.1. сжатие моде Ли Сжатие глубокой нейронной сети – это действенный способ повысить эффек - тивность логического вывода. Методы сжатия включают прореживание1 пара- метров (parameter pruning) для удаления избыточных весов, низкоранговую факторизацию (low-rank factorization) для уменьшения сложности, кванто- вание весов (weight quantization) для уменьшения точности весов и размера модели, а также дистилляцию знаний (knowledge distillation) для переноса скрытых знаний (dark knowledge) из бóльших моделей в меньшие. В заключе- ние мы обсудим методы автоматического поиска хорошей политики сжатия без участия человека. 1 В публикациях по машинному обуче нию часто встречается калька «прунинг», но в этой книге мы будем использовать перевод. – Прим. перев.\n--- Страница 218 ---\nСжатие модели  217 4.1.1. Прореживание параметров Глубокие нейронные сети обычно чрезмерно параметризованы, т. е. облада- ют излишним числом параметров. Прореживание удаляет избыточные эле- менты нейронных сетей (рис. 4.1), чтобы уменьшить размер модели и объем вычислений. До прореживания После прореживания Прореживание синапсов Прореживание нейронов Рис. 4.1  Синапсы и нейроны до и после прореживания (Han et al., 2015b). Обозначения Мы рассматриваем сверточные слои в глубоких нейронных сетях, которые являются наиболее вычислительно затратными компонентами. Веса одного сверточного слоя составляют 4-мерный тензор n×c×kh×kw, где n – количество фильтров (т. е. выходных каналов), c – количество каналов (т. е. входных каналов) и kh, kw – размер ядра (обычно симметричный, т. е. kh = kw). Веса одного слоя можно рассматривать как несколько фильтров (трехмерные тензоры c×kh×kw), каждый из которых соответствует выходному каналу; или рассматривать как несколько каналов (трехмерные тензоры n×kh×kw), каждый из которых соответствует входному каналу. Каждый тензор kh×kw является ядром; в сверточном слое имеется n ×c ядер. Гранулярность Прореживание можно выполнять с разной степенью гранулярности (детали- зации) (Mao et al., 2017) (рис. 4.2). Мелкомодульное прореживание (fine-grained pruning) удаляет отдельные элементы из тензора весов. Первыми методами были Optimal Brain Damage (LeCun et al., 1989) и Optimal Brain Surgeon (Hassibi and Stork, 1993), которые уменьшали количество связей на основе гессиана функции потерь. Хан и др. (Han et al., 2015) предложили трехэтапный метод «обуче ние–обрезка–пере- учивание» для удаления избыточных связей в глубокой нейронной сети. Этот метод уменьшил количество параметров AlexNet в 9 раз, а VGG-16 в 13 раз без потери точности. Шринивас и Бабу (Srinivas, Babu, 2015) предложили\n--- Страница 219 ---\n218  Эффективные методы глубокого обучения метод прореживания без данных для удаления избыточных нейронов. При мелкомодульном прореживании набор весов для прореживания может быть выбран произвольно, с его помощью можно достичь очень высокого коэф- фициента сжатия CNN (Han et al., 2015), RNN (Giles, Omlin, 1994), LSTM (Han et al., 2017), трансформеров (Cheong, Daniel, 2019) и т. д. без ущерба для точ- ности. фильтры каналыНерегулярный Регулярный Мелкомодульное прореживаниеПрореживание на основе шаблонаПрореживание на векторном уровнеПрореживание на уровне ядраПрореживание на уровне каналаядра сохраненные веса прореженные веса Рис. 4.2  Различные степени гранулярности при прореживании весов (на основе рисунка из Mao et al., 2017) Прореживание на основе шаблонов (pattern-based pruning) – это особый вид мелкомодульного прореживания, который обеспечивает лучшее аппаратное ускорение с оптимизацией компилятора (Ma et al., 2020; Tan et al., 2020b; Niu et al., 2020). Если взять в качестве примера свертки 3×3, прореживание на основе шаблона назначает фиксированный набор масок каждому из ядер 3×3. Количество масок обычно ограничено (4–6) для обеспечения аппаратной эф- фективности. Каждый шаблон маски имеет фиксированное количество уда- ленных элементов для каждого ядра (пять удаленных элементов из девяти на рис. 4.2). Шаблон определяется эвристикой (Ma et al., 2020) или кластериза- цией на основе предварительно обученных весов (Niu et al., 2020). Несмотря на мелкомодульный шаблон прореживания внутри ядра, прореживание на основе шаблонов можно ускорить с по мощью оптимизации компилятора путем переупорядочения циклов вычислений, что снижает накладные рас - ходы на логику управления. Крупномодульное прореживание (сoarse-grained pruning), или структури - рованное прореживание (structured pruning), удаляет регулярный тензорный блок для повышения эффективности оборудования. В зависимости от раз- мера блока могут быть удалены целые векторы (Mao et al., 2017), ядра (Mao et al., 2017; Niu et al., 2020) или каналы (He et al., 2017; Wen et al., 2016; Li et al., 2016; Molchanov et al., 2016) (рис. 4.2). Грубое крупномодульное прорежи- вание, такое как прореживание каналов, может обеспечить прямое аппарат - ное ускорение на графических процессорах с использованием стандартных библиотек глубокого обуче ния, но обычно приводит к заметному падению точности по сравнению с мелкомодульным прореживанием (Li et al., 2016). Прореживание с меньшей модульностью обычно приводит к меньшему па- дению точности при той же степени сжатия (Mao et al., 2017).\n--- Страница 220 ---\nСжатие модели  219 Аппаратное ускорение Вообще говоря, более регулярные схемы прореживания удобнее для оборудо- вания, что упрощает ускорение логического вывода на существующем обо- рудовании, таком как графические процессоры; в то время как нерегулярные схемы лучше сохраняют точность при той же степени сжатия. С помощью специализированных аппаратных ускорителей (Han et al., 2016; Chen et al., 2016; Han et al., 2017; Chen et al., 2019a; Zhang et al., 2016a; Yu et al., 2017) и методов оптимизации, ориентированных на компиляторы (Ma et al., 2020; Niu et al., 2020), также можно получить значительное ускорение для нерегу - лярных методов прореживания. Критерий значимости После выбора уровня модульности прореживания следующим фактором влия- ния на производительность сжатой модели является определение весовых коэффициентов, которые должны быть сокращены. Было предложено не- сколько эвристических критериев значимости (importance criteria) для оцен- ки важности каждого веса после обуче ния модели; менее важные веса обре- заются в соответствии с критериями. Самый простой эвристический подход основан на величинах, то есть абсолютных значениях весов (Han et al., 2015): Значимость = |w|, где веса большей величины считаются более значимыми. Это также рас - пространяется на крупномодульное прореживание, такое как прореживание каналов, где в качестве критерия используется тензорная норма: Значимость = ||W||2. К другим критериям относятся производные второго порядка (т. е. гессиан функции потерь) (LeCun et al., 1989; Hassibi, Stork, 1993), разложение Тейлора (Molchanov et al., 2017), выходная чувствительность (Engelbrecht , 2001) и др. Недавно Франкл и Карбин (Frankle, Carbin, 2018) предложили гипотезу лотерейного билета для нахождения в плотных, случайным образом ини- циализированных глубоких сетях разреженных подсетей, которые можно обучить для достижения той же точности. Эксперименты показывают, что метод может находить разреженные подсети с весами менее 10–20 %, дости- гая того же уровня точности в MNIST (LeCun et al., 2010) и CIFAR (Крижевский и Хинтон, 2009). Позже метод был масштабирован до более масштабных при- менений (например, ResNet-50 и Inception-v3 в ImageNet), где разреженную подсеть можно найти на ранней стадии обуче ния (Frankle et al., 2020), а не при инициализации. Методы обучения Прямое удаление весов в глубоких нейронных сетях значительно ухудшит точность при большой степени сжатия. Следовательно, для восстановления потерянного качества требуется некоторое дообучение (тонкая настройка). После прореживания можно выполнить тонкую настройку, чтобы восстано-\n--- Страница 221 ---\n220  Эффективные методы глубокого обучения вить падение производительности (He et al., 2017). Стратегию можно рас - ширить до итеративного прореживания (Han et al., 2015) (рис. 4.3), когда для дальнейшего повышения точности выполняется несколько итераций прореживания и тонкой настройки. Чтобы избежать ошибочного удаления весов, динамическое прореживание (Guo et al., 2016) включает рассечение связей в рабочий процесс и обеспечивает постоянное обслуживание сети. Прореживание на ходу (runtime pruning, Lin et al., 2017) выбирает коэффици- ент сжатия сети в соответствии с каждой входной выборкой, назначая более агрессивную стратегию сжатия для более простых выборок, что еще больше улучшает компромисс между точностью вычислений и размером сети. Прореживание связей Настройка весовНастройка связей Рис. 4.3  Трехэтапный конвейер обуче ния с итеративной обрезкой (Han et al., 2015b) В другой реализации обучают компактные DNN, используя ограничения разреженности (sparsity constraint). Ограничения разреженности обычно реализуются с по мощью регуляризации L0-, L1- или L2-норм, применяемой к весам, которые добавляются к потерям при обучении для совместной опти- мизации. Хан и др. (Han et al., 2015) применили регуляризацию L1/L2 к каж - дому отдельному весу во время обуче ния. Лебедев и Лемпицкий (Lebedev, Lempitsky, 2016) применили групповые ограничения разреженности к свер- точным фильтрам для достижения структурированной разреженности. 4.1.2. Низкоранговая факторизация Низкоранговая факторизация (low-rank factorization) использует декомпози- цию матрицы/тензора, чтобы уменьшить сложность сверточных или полно- связных слоев в глубоких нейронных сетях. Идея использования фильтров низкого ранга для ускорения свертки уже давно исследуется в области об- работки сигналов. Наиболее широко используется декомпозиция Truncated SVD (Golub, Van Loan, 1996), которая эффективно ускоряет работу полносвязных слоев (Xue et al., 2013; Denton et al., 2014; Girshick, 2015). Для полносвязного слоя с весом W Î ℝm×k SVD определяется как W = U S VT, где U Î ℝm×m, S Î ℝm×k, V Î ℝk×k. Здесь S – диагональная матрица с сингулярными значениями на диагонали.\n--- Страница 222 ---\nСжатие модели  221 Если вес попадает в структуру низкого ранга, его можно аппроксимировать, сохранив только t самых больших элементов S, где t << min(m , k). Вычисление Wx может быть уменьшено с O (mk) до O (mt + tk) для каждой выборки. Для сверточных весов 4D предложено (Jaderberg et al., 2014) разложить ядра k×k на ядра 1×k и k×1; этот подход также был принят в проекте Inception- V3 (Szegedy, Vanhoucke, 2016). Чжан и др. (Zhang et al., 2016) предложили разложить сверточный вес n×c×k×k на n¢×c×k×k и n×n¢×1×1, где n¢ << n. Для декомпозиции ядер более высокой размерности, таких как сверточные веса, может применяться каноническая полиадическая декомпозиция (Lebedev et al., 2014). Этот подход выполняет низкоранговую CP-декомпозицию че- тырехмерного тензора ядра свертки в сумму небольшого числа тензоров первого ранга. Во время вывода исходная свертка заменяется последователь- ностью из четырех сверточных слоев с меньшими ядрами. Ким и др. (Kim et al., 2015) использовали декомпозицию Такера (известную как расширение SVD более высокого порядка) для факторизации сверточных ядер, получая более высокую степень сжатия по сравнению с применением SVD. 4.1.3. Квантование Квантование сети (network quantization) сжимает сеть, уменьшая количество битов на вес, необходимое для представления глубокой сети. После кванто- вания сеть также может демонстрировать более высокую скорость вывода с аппаратной поддержкой. Схемы округления Чтобы преобразовать вес, представленный с полной точностью (32-битное значение с плавающей запятой), в значение с более низкой точностью, вы- полняется округление, отображающее значение с плавающей запятой в один из сегментов квантования. В ранних работах (Han et al., 2015; Gong et al., 2014; Wu et al., 2016) применя- лась кластеризация k-средних для нахождения общих весов для каждого слоя настроенной1 (trained) сети; все веса, попадающие в один и тот же кластер, будут иметь одинаковый вес. В частности, при разбиении n исходных весов W = {w1, w2, …, wn} на k кластеров C = {c1, c2, …, ck}, n >> k, мы минимизируем внутрикластерную сумму квадратов (within-cluster sum of squares, WCSS): (4.1) 1 В случае когда мы говорим о сжатии моделей с целью оптимизации, между терми- нами learning (обуче ние) и training (настройка) появляется тонкое, но важное раз- личие. В контексте оптимизации под настройкой часто понимают обуче ние модели на специально подобранных образцах, что облегчает и улучшает последующее сжатие модели без потери качества. Иногда под настройкой понимают начальное обуче ние модели на базовом домене с последующим дообучением, а иногда в за- рубежной литературе learning и training являются просто синонимами. – Прим. перев.\n--- Страница 223 ---\n222  Эффективные методы глубокого обучения Квантование на основе кластеризации k-средних можно комбинировать с прореживанием и кодированием Хаффмана для выполнения сжатия мо- дели (Han et al., 2015) (рис. 4.4). Этот метод позволяет уменьшить размер модели VGG-16 в 49 раз без потери точности. Прореживание: меньшее количество весов исходная сеть исходный размерНастройка связей Прореживание связей Настройка весоводинаковая точностьодинаковая точностьодинаковая точность умень- шение в 9–13 разумень- шение в 27–31 разумень шение в 35–49 разКластеризация весов Создать кодовую книгу Квантование весов с помощью кодовой книги Переобучение кодовой книгиКодирование ХаффманаКвантование: меньше битов на вес Кодирование весов Кодирование индекса Рис. 4.4  Трехэтапный процесс сжатия: прореживание, квантование и кодирование Хаффмана (Han et al., 2015) Линейное/равномерное квантование (Vanhoucke et al., 2011; Jacob et al., 2017) непосредственно округляет значение с плавающей запятой до ближайших квантованных значений после усечения диапазона; градиент распростра- няется с использованием приближения STE (Bengio et al., 2013). Предполо- жим, что диапазон отсечения равен [a , b], а количество уровней квантования равно n, тогда прямой процесс квантования значения с плавающей запятой x в квантованное значение q выглядит так: clamp(r , a, b) = min(max(x , a), b); (4.2) (4.3) (4.4) Градиент обратного распространения вычисляется при помощи (4.5) Помимо применения значения усечения a, b, в некоторых работах (Zhou et al., 2016) используются функции активации, такие как tanh , для переноса диапазона весов в диапазон [–1, 1], что упрощает квантование. Разрядность Мы можем найти компромисс между размером и точностью модели, ис - пользуя разную разрядность чисел (битовую точность модели). Более низкая\n--- Страница 224 ---\nСжатие модели  223 разрядность может привести к уменьшению размера модели, но за это, воз- можно, придется заплатить снижением ее качества. Сети с полной точностью используют 32-разрядные числа с плавающей запятой как для весов, так и для активаций. Сети половинной точности используют 16-разрядные числа с плавающей запятой для уменьшения размера модели вдвое. Квантование до 8-разрядных целых чисел как для весов, так и для активаций (Jacob et al., 2017) широко используется в целочисленных арифметических операциях, которые можно ускорить на графических процессорах, обычных процессо- рах, смартфонах и т. д. К категории низкой точности относятся сети с троичными весами (Li et al., 2016), где веса квантуются до значений {–1, 0, 1} или {–E , 0, E} (здесь E – среднее значение абсолютного веса). Настраиваемое троичное квантование (Zhu et al., 2016) использует два обучаемых коэффициента масштабирова- ния полной точности Wlp, Wln для каждого слоя l и квантует веса до {–W ln, 0, +WlP}. Этот метод позволяет квантовать AlexNet на ImageNet без потери точности. Крайним случаем низкорарядного квантования являются нейронные сети с двоичным весом (например, BinaryConnect (Courbariaux et al., 2015), Bina- ryNet (Courbariaux, Bengio, 2016), XNOR (Rastegari et al., 2016) и т. д.), где веса представлены с использованием только одного бита. Бинарные веса или активации обычно настраиваются непосредственно во время обуче ния сети с использованием определенных прямых и обратных правил. Например, BinaryConnect (Courbariaux et al., 2015) использует как детерминированную бинаризацию: (4.6) так и стохастическую: (4.7) где σ – «жесткая» сигмоидная функция: (4.8) Это кусочно-линейная аппроксимация стандартной сигмоидной функции. Схемы квантования Для квантования с более высокой точностью (например, INT8) можно вы- полнить квантование после настройки (post-training quantization), когда веса и активации квантуются после настройки модели с полной точностью. Диапазон квантования для активаций определяется путем вычисления рас - пределения на настроечном наборе, а слои пакетной нормализации (Ioffe, Szegedy, 2015) сворачиваются. Применение квантования INT8 после обуче-\n--- Страница 225 ---\n224  Эффективные методы глубокого обучения ния обычно приводит к незначительной или нулевой потере точности1. В не - давней работе (Banner et al., 2019) изучалось квантование моделей до уровня INT4 после настройки. Настройка с учетом квантования (quantization-ware training) может умень- шить потерю точности квантования за счет имитации квантования этапа вы- вода во время настройки (Jacob et al., 2017). На этапе настройки в сверточные слои вводится «ложный оператор квантования», а слои пакетной нормали- зации (Иоффе и Сегеди, 2015) сворачиваются. В случае как квантования после настройки, так и настройки с учетом кван- тования требуется прямой доступ к настроечным данным, чтобы получить хорошую точность после квантования, что не всегда возможно, особенно в приложениях, критичных в плане конфиденциальности. Для снижения битовой точности без доступа к настроечным данным применяется кван - тование без данных. Нагель и др. (Nagel et al., 2019) предложили выполнять квантование INT8 без данных, выравнивая диапазоны весов в сети. Сеть ZeroQ (Cai et al., 2020) оптимизирует набор дистиллированных данных, что- бы сопоставить статистику пакетной нормализации на разных уровнях сети для квантования без данных. Низкоразрядная настройка Помимо вывода, настройка с квантованными весами, активациями и гра- диентами может снизить затраты на обуче ние глубоких моделей. Настройка со смешанными 16-битными и 32-битными типами с плавающей запятой в модели широко поддерживается фреймворками глубокого обуче ния, та- кими как TensorFlow, PyTorch, TensorCores и т. д. Благодаря таким методам, как масштабирование потерь, настройка со смешанной точностью может снизить потребление памяти и повысить скорость настройки без потери точ- ности. DoReFa-Net использует 1-битные веса, 2-битные активации и 6-бит - ные градиенты для более быстрой настройки и вывода, что может обеспечить точность, сравнимую с 32-битной AlexNet (Крижевский и др., 2012) на Ima- geNet (Deng et al., 2009). В работе (Lin et al., 2015) стохастически бинаризи- руют веса, чтобы сократить время на умножение с плавающей запятой при настройке. Аппаратная поддержка ускорения с низкой точностью Квантованные модели могут уменьшить размер модели и объем памяти для развертывания, но для ускорения логического вывода им требуется аппарат - ная поддержка низкоразрядной арифметики. Квантование INT8 поддержи- вается мобильными процессорами ARM (например, Qualcomm Hexagon, ARM Neon), процессорами x86, графическими процессорами NVIDIA с TensorRT, FPGA Xilinx с DNNDK и т. д. Сеть с двоичным квантованием также можно ускорить с по мощью битовых операций. Более низкая битовая точность (на- пример, троичная, INT4) в меньшей степени поддерживается на существую- щем оборудовании. Архитектура NVIDIA Turing поддерживает вывод INT42, 1 https://www.tensorflow.org/lite/performance/post_training_quantization. 2 https://developer.nvidia.com/blog/int4-for-ai-inference/.\n--- Страница 226 ---\nСжатие модели  225 что обеспечивает дополнительное ускорение на 59 % по сравнению с INT8. Предпринимаются усилия по разработке специализированных аппаратных ускорителей для ускорения низкоразрядных квантованных моделей (Zhang et al., 2015; Sharify et al., 2018), которые обеспечивают превосходную энер- гоэффективность по сравнению с моделями полной точности. В последнее время аппаратная поддержка квантования со смешанной точностью открывает новые возможности для повышения точности и сни- жения затрат. NVIDIA Turing Tensor Core поддерживает 1-битные, 4-битные, 8-битные и 16-битные арифметические операции; Imagination реализовала гибкую нейросетевую обработку изображений, которая поддерживает на- стройку битовой ширины для каждого слоя как для весов, так и для актива- ций. Недавно разработанный специализированный аппаратный ускоритель также обеспечивает поддержку смешанной точности: вычислительное обо- рудование, основанное на блоках умножения битовых последовательностей (Judd et al., 2016; Umuroglu et al., 2018), поддерживает временнóе умножение с разрядностью от 1 до 8 бит; BitFusion (Sharma et al., 2018) поддерживает пространственное умножение 2, 4, 8 и 16 бит. 4.1.4. Дистилляция знаний Дистилляция знаний (кnowledge distillation, KD; Bucilua et al., 2006; Hinton et al., 2015) может перенести так называемые «темные знания», полученные и сохраненные в «черном ящике» большой модели (учитель), в меньшую модель (ученик), чтобы объединить качество большой модели и скорость маленькой. Маленькая модель – это либо сжатая, либо более мелкая/узкая модель. Некоторые исследователи достигают цели, обучая меньшую сеть со- поставлять выходные логиты (Bucilua et al., 2006); Хинтон и др. (Hinton et al., 2015) предложили идею температуры softmax-выхода и обучили меньшую модель имитировать смягченное распределение softmax модели-учителя. KD демонстрирует многообещающие результаты в различных задачах клас - сификации изображений, несмотря на простую реализацию. Помимо конечных выходных логитов, полезную информацию также со- держат промежуточные активации. Метод FitNet (Ромеро и др., 2014) обучает ученика имитировать полную карту характеристик модели учителя посред- ством регрессии. Метод передачи внимания (attention transfer, АТ) (Загоруйко и Комодакис, 2016) передает карту внимания активации от учителя к уче- нику, используя суммирование карты признаков по измерению канала. Оба метода требуют промежуточной активации для совместного использования одного и того же пространственного разрешения, что ограничивает выбор архитектуры обучаемой модели. Методы на основе KD также применимы к приложениям, выходящим за рамки классификации, таким как обнаружение объектов (Chen et al., 2017), семантическая сегментация (Liu et al., 2019a), языковое моделирование (Sanh et al., 2019), синтез изображений (Ли и др., 2020) и т. д.\n--- Страница 227 ---\n226  Эффективные методы глубокого обучения 4.1.5. Автоматическое сжатие модели Методы сжатия моделей могут повысить эффективность развернутых моделей. Однако результат сжатия модели во многом зависит от гиперпараметров. На- пример, разные слои в глубоких сетях имеют разную пропускную способность и чувствительность (например, первый слой в CNN обычно очень чувствителен к прореживанию). Следовательно, мы должны применять разные коэффи - циенты прореживания для разных слоев сети, чтобы достичь оптимальной производительности. Пространство проектирования настолько велико, что человеческая эвристика обычно неоптимальна, а ручное сжатие модели требу - ет много времени. С этой целью предлагается автоматическое сжатие модели, позволяющее найти правильную политику сжатия без участия человека. Автоматическое прореживание Обычные методы сжатия моделей основаны на элементах, созданных вруч- ную, и заставляют экспертов предметной области исследовать большое про- странство проектирования, выбирая между размером модели, скоростью и точностью: обычно этот подход неоптимален и требует много времени. В методе AutoML для сжатия моделей (AutoML for Model Compression, AMC) (He et al., 2018) применяется обуче ние с подкреплением для эффективной выборки проектного пространства и поиска оптимальной политики сжатия сети (рис. 4.5). Мы обрабатываем предварительно обученную сеть (напри- мер, MobileNet-V1) послойно. Наш агент обуче ния с подкреплением DDPG (Lillicrap et al., 2015) получает представление st из слоя t и выводит коэффи- циент разреженности at. После того как слой сжат с коэффициентом at, агент переходит к следующему слою Lt+1. Затем оценивается точность модели, в которой сжаты все слои. Наконец, агенту обуче ния с подкреплением воз- вращается вознаграждение R, зависящее от точности модели и результата операции умножения-накопления (multiply-accumulate, MAC). Сжатие модели человеком: трудоемко, неоптимально Исходная нейросеть Исходная нейросетьСжатая нейросеть Сжатая нейросетьДвижок АМС Сжатие модели с помощью ИИ: автоматическое, более высокая степень сжатия, быстрееКритик Áктор Пред­ ставление Агент: DDPGReward=–Error*log(FLOP) Представление st=[N,C,H,W,i…]Действие: сжать с заданным коэффициентом (например, 50 %)Слой t + 1 Слой t Слой t – 1 Среда: сжатие каналов Рис. 4.5  Обзор механизма AutoML for Model Compression (AMC). Слева: AMC заменяет человека и делает сжатие модели полностью автоматизированным, при этом работая лучше, чем человек. Справа: формулировка AMC как задачи обуче ния с подкреплением (He et al., 2018)\n--- Страница 228 ---\nСжатие модели  227 При мелкомодульном прореживании ResNet-50 (He et al., 2016) AMC может превзойти экспертов-людей в полностью автоматизированном режиме: этот движок повышает коэффициент сжатия ResNet-50 в ImageNet, настроенный экспертами, с 3,4 до 5 (см. рис. 4.6) без потери точности. AMC также мо- жет находить шаблоны прореживания, подобные человеческим эвристикам. Плотность каждого слоя на каждом этапе показана на рис. 4.7. Пики и гребни показывают, что RL-агент автоматически обучается сжимать сверточные слои 3×3 с большей разреженностью, поскольку они обычно имеют большую избыточность; в то же время у более компактных сверток 1×1 разреженность меньше. Статистика плотности каждого блока представлена на рис. 4.6. Вид- но, что распределение плотности AMC сильно отличается от распределения человека-эксперта, показанного в табл. 3.8 (Han, 2017). Мы предполагаем, что AMC может полностью исследовать рабочее пространство и лучше рас - пределить разреженность. 50 % 40 % 30 % 20 % 10 % 0 %ResNet50 после прореживания экспертом ResNet50 после прореживания AMC (чем меньше, тем лучше)Плотность (ненулевые веса / общее количество весов) Conv1 ResBlock1 ResBlock2 ResBlock3 ResBlock4 FC Итого Рис. 4.6  AMC может сильнее сжать модель по сравнению с экспертами без по- тери точности (эксперт: сжатие ResNet50 в 3,4 раза; AMC: сжатие ResNet50 в 5 раз) 60 % 50 % 40 % 30 % 20 % 10 % 0 % 10 20 30 40 50 0Плотность (ненулевые веса / общее количество весов) Индекс слояПики: наш RL-агент автоматически усвоил, что свертки 1×1 имеют меньшую избыточность и меньше нуждаются в сжатии Гребни: наш агент RL автоматически усвоил, что свертки 3×3 имеют большую избыточность и больше нуждаются в сокращении Остаточный блок 1Остаточный блок 2 Остаточный блок 3 Остаточный блок 4Этап 1 Этап 2 Этап 3 Этап 4 Рис. 4.7  Политика прореживания (коэффициент сжатия), заданная агентом AMC для ResNet-50. С помощью 4 этапов итеративного сжатия AMC находит очень выраженную картину распределения разреженности по слоям: пики представляют собой свертки 1×1, гребни – свертки 3×3. Агент обуче ния с подкреплением автома- тически обнаруживает, что свертка 3×3 более избыточна, чем свертка 1×1, и может быть больше прорежена\n--- Страница 229 ---\n228  Эффективные методы глубокого обучения AMC влияет на аппаратное быстродействие: он может оптимизировать не только объем вычислений (т. е. MAC), но и фактическую задержку на устрой- стве (рис. 4.8b). Мы используем очень компактную сеть MobileNetV1 (Howard et al., 2017) в качестве примера для измерения того, насколько мы можем улучшить скорость логического вывода. Предыдущие попытки использовать созданную вручную политику прореживания MobileNet-V1 привели к зна- чительному снижению точности (Li et al., 2016b): прореживание исходных параметров MobileNet-V1 до 75,5 % приводит к точности 67,2 %1, что даже хуже, чем исходные 75 % MobileNet-V1. Однако политика AMC значительно улучшает качество прореживания ImageNet, обеспечивая лучшую кривую Парето для точности при компромиссе по вычислениям (т. е. повышение точности при том же объеме вычислений). Как показано на рис. 4.8a, создан- ная вручную экспертом политика обеспечивает несколько худшую точность, чем исходная MobileNet-V1, при двукратном снижении MAC. Политика AMC также превосходит другую политику, основанную на эвристике (Yang et al., 2018), оптимально сочетая точность и быстродействие. Точность ImageNet, % Точность ImageNet, % MobileNet, оптимизированная AMC MobileNet, оптимизированная экспертом MobileNet без оптимизацииMobileNet, оптимизированная AMC MobileNet, оптимизированная экспертом MobileNet без оптимизации Миллион умножений-сложений Время вывода (мс) (a) (b) Рис. 4.8  (a) Сравнение точности и компромисса по MAC между AMC, экс - пертом и несжатой MobileNet-v1. Движок AMC явно доминирует над экспертом на оптимальной кривой Парето. (b) Сравнение компромисса между точностью и быстродействием среди AMC, NetAdapt и MobileNet-V1 без сжатия. Движок AMC значительно улучшает кривую Парето для MobileNet-V1. Результат, полу- ченный AMC на основе обуче ния с подкреплением, превосходит NetAdapt на основе эвристики по кривой Парето (время вывода измерено на смартфоне Google Pixel 1) В недавно опубликованной работе (Liu et al., 2019) алгоритм MetaPruning сначала обучает PruningNet – своего рода метасеть, которая способна гене- рировать весовые параметры для любой прореженной структуры с учетом целевой сети, а затем использовать ее для поиска наилучшей политики про- реживания при разных граничных условиях. 1 http://machinethink.net/blog/compressing-deep-neural-nets/.\n--- Страница 230 ---\nСжатие модели  229 Автоматическое квантование Реализация квантования со смешанной точностью также требует значи - тельных усилий, направленных на определение оптимальной разрядности каждого слоя, чтобы достичь наилучшего соотношения между точностью и производительностью. Для автоматизации процесса предложено (Wang et al., 2018) использовать аппаратно-зависимое автоматическое квантование (hardware-aware automated quantization, HAQ) (рис. 4.9). Подход HAQ основан на обучении с подкреплением для автоматического определения политики квантования. Он использует обратную связь аппаратного ускорителя в цикле построения модели, а не полагается на опосредованные сигналы, такие как MAC и размер модели. По сравнению с обычными методами, HAQ полностью автоматизирован и может настраивать политику квантования для различных архитектур нейронных сетей и аппаратных архитектур. Актор КритикВознаг­ раждение за состояниеАппаратное картирование Прямая обратная связьЦикл Т (МЗР) Цикл 0 (СЗР)ДействиеСлой 3 3 бита / 5 бит Слой 4 6 бит / 7 бит Слой 5 4 бита / 6 бит Слой 6 5 бит / 6 бит Политика5­битная активация3­битный вес Квантованная модельBitFusion (граница) BISMO (облако) BISMO (граница) Аппаратный ускоритель Рис. 4.9  Структурная схема метода HAQ. Данный метод использует обуче ние с подкреплением для автоматического итерационного поиска в огромном про- странстве вариантов квантования с аппаратной обратной связью. Агент предла- гает оптимальную политику распределения разрядностей с учетом количества вычислительных ресурсов (т. е. быстродействия, мощности и размера модели). RL-агент включает аппаратный ускоритель в цикл итерации, чтобы он мог полу- чать прямую обратную связь от оборудования, вместо того чтобы полагаться на косвенные показатели (Wang et al., 2018) HAQ использует совершенно разные политики квантования для граничных (edge) и облачных (cloud) ускорителей. Политика квантования MobileNet-V1 на ускорителе BISMO (Umuroglu et al., 2018) (как пограничная, так и облачная конфигурация) представлена на рис. 4.10. На граничном ускорителе агент RL выделяет меньше битов активации для глубинных сверток в связи с тем, что такие свертки ограничены быстродействием памяти и активации и пере- гружают канал доступа к памяти. На облачном ускорителе наш агент выде- ляет больше битов глубинным сверткам и меньше битов точечным сверткам, поскольку облачное устройство имеет большую пропускную способность памяти и высокий параллелизм, поэтому сеть скорее испытывает вычисли- тельные ограничения.\n--- Страница 231 ---\n230  Эффективные методы глубокого обучения глубинная: меньше разрядов точечная: больше разрядов Граница Облако глубинная: больше разрядов точечная: меньше разрядовкол-во битов кол-во битов кол-во битов веса (точечно) кол-во битов активации (точечно) кол-во операций на байт (точечно)кол-во битов веса (по глубине) кол-во битов активации (по глубине) кол-во операций на байт (по глубине)слойслойлогарифм кол-ва Рис. 4.10  Политика квантования при ограничениях по быстродействию для MobileNet-V1 (Wang et al., 2018) 4.2. Э ффе КтиВные арХитеКтуры нейронны Х сетей В дополнение к сжатию существующих глубоких нейронных сетей другим широко распространенным подходом к повышению эффективности явля- ется разработка новой архитектуры нейронной сети. Модель CNN обычно состоит из слоев свертки, слоев пулинга и полносвязных слоев, где боль- шая часть вычислительной нагрузки исходит от слоев свертки. Например, в ResNet-50 (He et al., 2016) более 99 % операций умножения-накопления (MAC) выполняются для сверточных слоев. Следовательно, разработка эф- фективных слоев свертки является основой построения эффективных ар- хитектур CNN. В этом разделе сначала описывается стандартный сверточный слой, а за- тем описываются три эффективных варианта этого слоя. Далее мы пред - ставляем три варианта создаваемых вручную эффективных архитектур CNN, включая SqueezeNet (Iandola et al., 2016), MobileNets (Howard et al., 2017; Sandler et al., 2018) и ShuffleNets (Ma et al., 2018; Zhang et al., 2017). Наконец, мы описываем автоматизированные методы проектирования эффективных архитектур CNN.\n--- Страница 232 ---\nЭффективные архитектуры нейронных сетей  231 4.2.1. Стандартный сверточный слой Стандартный сверточный слой параметризуется ядром свертки K размера Oc×Ic×K×K, где Oc – количество выходных каналов, Ic – количество входных каналов, K – пространственная размерность ядра (рис. 4.11а). Здесь для прос - тоты мы предполагаем, что ширина и высота ядра свертки одинаковы. Также возможно иметь асимметричные ядра свертки (Szegedy, Vanhoucke, 2016). Имея входную карту признаков Fi размера Ic×H×W, вычисляем выходную карту признаков F o размера O c×H×W следующим образом1: (4.9) Далее мы будем использовать выражение Fo = Conv K×K(Fi, K) для представ- ления стандартного слоя свертки с размером ядра K. Согласно уравнению (4.9), вычислительная стоимость стандартной свертки равна #MACs(Conv K×K) = H × W × Oc × Ic × K × K, (4.10) в то время как количество параметров задается как #Params(Conv K×K) = Oc × Ic × K × K. (4.11) 4.2.2. Эффективные сверточные слои Tочечная свертка 1×1 Cвертка 1×1 (также называемая точечной сверткой) – это особый вид стан- дартного сверточного слоя, где размер ядра K равен 1 (рис. 4.11d). Согласно уравнениям (4.10) и (4.11), замена стандартного слоя свертки K×K на слой свертки 1×1 уменьшит количество MAC (#MAC) и количество параметров (#Params) в K2 раз. На практике, поскольку свертка 1×1 сама по себе не может агрегировать пространственную информацию, она комбинируется с други- ми сверточными слоями для формирования архитектуры CNN. Например, свертка 1×1 обычно используется для уменьшения/увеличения размерности канала карты признаков в CNN. Групповая свертка В отличие от свертки 1×1, которая снижает вычислительную стоимость за счет уменьшения размерности ядра, групповая свертка снижает стоимость за счет уменьшения размерности канала. В частности, входную карту при- знаков F i разбивают на G групп по измерению канала (рис. 4.11b): split(F i) = (Fi[0 : c, :, :], F i[c : 2c, :, :], ··· , F i[Ic – c : Ic, :, :], где c = Ic/G. 1 Предполагая, что шаг равен 1, а заполнение нулями применяется для сохранения пространственного измерения карты объектов.\n--- Страница 233 ---\n232  Эффективные методы глубокого обучения Затем каждую группу пропускают через стандартную свертку K×K раз- мера Наконец, выходные данные объединяются по измере- нию канала. По сравнению со стандартной сверткой K×K, показатели #MAC и #Params уменьшаются при групповой свертке в G раз. (а) стандартная свертка (b) групповая свертка (c) глубинная свертка (d) 1×1/точечная свертка Рис. 4.11  Иллюстрация стандартной свертки и трех часто используемых эффективных вариантов Глубинная свертка В групповых свертках количество групп G является настраиваемым гипер- параметром. Чем больше G, тем меньше вычислительные затраты и меньше параметров. Крайним случаем является то, что G равно количеству вход- ных каналов Ic. В этом случае слой групповой свертки называется глубинной сверткой (depthwise convolution) (рис. 4.11в). Значения #MAC и #Params глу - бинной свертки: #MACs(DWConv K×K ) = H × W × Oc × K × K; (4.12) #Params(DWConv K×K ) = Oc × K × K, (4.13) где О с = Iс. 4.2.3. Разработанные вручную эффективные модели CNN SqueezeNet Архитектура SqueezeNet (Iandola et al., 2016) (рис. 4.12) ориентирована на чрезвычайно компактные модели для мобильных приложений. Она имеет всего 1,2 млн параметров, но ее точность аналогична AlexNet (табл. 4.1). SqueezeNet имеет 26 слоев свертки и ни одного полносвязного слоя. По- следняя карта признаков проходит через глобальный средний пулинг (global\n--- Страница 234 ---\nЭффективные архитектуры нейронных сетей  233 average pooling) и образует вектор из 1000 измерений для подачи на слой softmax. SqueezeNet имеет восемь модулей Fire. Каждый модуль Fire содержит слой сжатия со сверткой 1×1 и парой сверток 1×1 и 3×3. Модель SqueezeNet в формате Caffemodel1 достигла точности top-1 57,4 % и top-5 80,5 % на наборе ImageNet 2012 (Deng et al., 2009)2. SqueezeNet широко используется в мобиль- ных приложениях, в которых размер модели жестко ограничен. глобальный avgpool Рис. 4.12  Архитектура SqueezeNet (Iandola et al., 2016) Таблица 4.1. Обобщенные результаты тестирования архитектур CNN, разработанных вручную, на наборе ImageNet Сеть #Params, млн #MAC, млнImageNet Top-1 Top-5 AlexNet (Krizhevsky et al., 2012) 60 720 57,2 % 80,3 % GoogleNet (Szegedy et al., 2015) 6,8 1550 69,8 % 89,5 % VGG-16 (Simonyan, Zisserman, 2014) 138 15300 71,5 % – ResNet-50 (He et al., 2016) 25,5 4100 76,1 % 92,9 % SqueezeNet (landola et al., 2016) 1,2 1700 57,4 % 80,5 % MobileNetVl (Howard et al., 2017) 4,2 569 70,6 % 89,5 % MobileNetV2 (Sandler et al., 2018) 3,4 300 72,0 % – MobileNetV2-1.4 (Sandler et al., 2018) 6,9 585 74,7 % – ShuffleNetVl-1.5x (Zhang et al., 2017) 3,4 292 71,5 % – ShuffleNetV2-1.5x (Ma et al., 2018) 3,5 299 72,6 % – ShuffleNetV2-2x (Ma et al., 2018) 7,4 591 74,9 % – Мобильные сети Архитектура MobileNetV1 (Howard et al., 2017) основана на структурном бло- ке, называемом сверткой с разделением по глубине (depthwise separable con- volution) (рис. 4.13a), который состоит из слоя глубинной свертки 3×3 и слоя свертки 1×1. Входное изображение сначала проходит через стандартный слой 1 Caffe – среда для глубинного обуче ния, разработанная Яньцинем Цзя (Yangqing Jia). Название Caffe произошло от сокращения «Convolution Architecture For Feature Ex - traction» (Сверточная архитектура для извлечения признаков). https://ru.wikipedia. org/wiki/Caffe. – Прим. перев. 2 Критерий top-1 считает ответ верным только тогда, когда наиболее вероятный от - вет модели совпадает с правильным; top-5 означает, что правильный ответ попал в один из пяти наиболее вероятных ответов. – Прим. перев.\n--- Страница 235 ---\n234  Эффективные методы глубокого обучения свертки 3×3 со страйдом 2, затем через 13 блоков свертки с разделением по глубине. Наконец, карта признаков проходит через глобальный средний пулинг и образует вектор из 1280 измерений, который передается на по- следний полносвязный слой с 1000 выходных блоков (output unit). Обладая 569 млн MAC и 4,2 млн параметров, модель MobileNetV1 достигла точности top-170,6 % на наборе ImageNet 2012 (табл. 4.1). Ввод Страйд = 1 блок Страйд = 2 блокаСложение conv 1x1, Linear conv 1x1, Linear Dwise 3x3, Relu6Dwise 3x3, stride=2, Relu6 Dwise 3x3, stride=2, Relu6 Conv 1x1, Relu6Conv 1x1, Relu6Conv 1x1, Relu6 Вход Вход(a)(b) Рис. 4.13  (a) Структурный блок MobileNetV1 (Howard et al., 2017). Он состоит из слоя глубинной свертки 3×3 и слоя свертки 1×1. (b) Структурные блоки Mo- bileNetV2 (Sandler et al., 2018). Каждый блок состоит из слоя глубинной свертки 3×3 и двух слоев свертки 1×1. Когда страйд равен 1, блок выполняет сквозное пропускание «вход ® выход» MobileNetV2 (Sandler et al., 2018), улучшенная версия MobileNetV1, также использует в своих структурных блоках глубинные свертки 3×3 и свертки 1×1. В отличие от MobileNetV1, структурный блок в MobileNetV2 состоит из трех слоев, включая слой свертки 3×3 и два слоя свертки 1×1 (рис. 4.13). Интуитивно понятно, что мощность глубинной свертки намного ниже, чем у стандартной свертки, и поэтому для повышения ее производительности требуется больше каналов. С точки зрения затрат, по мере увеличения коли- чества каналов показатели #MAC и #Params глубинной свертки растут только линейно, а не квадратично, как в случае стандартной свертки. Даже при большом количестве каналов стоимость слоя свертки по глубине остается умеренной. Таким образом, в MobileNetV2 входная карта объектов сначала проходит свертку 1×1, чтобы увеличить размер канала на коэффициент, называемый коэффициентом расширения (expand ratio). Затем расширен- ная карта признаков подается на свертку по глубине 3×3, за которой сле- дует еще одна свертка 1×1, чтобы уменьшить размер канала до исходного значения. Эта структура называется перевернутым узким местом (inverted bottleneck), а блок называется мобильным перевернутым узким местом (mo- bile inverted bottleneck). Помимо перевернутого мобильного узкого места,\n--- Страница 236 ---\nЭффективные архитектуры нейронных сетей  235 MobileNetV2 имеет еще два усовершенствования по сравнению с Mobile- NetV1. Во-первых, MobileNetV2 обеспечивает сквозной канал1 для блоков, в которых шаг равен 1. Во-вторых, удаляется функция активации последней свертки 1×1 в каждом блоке. Сочетая эти улучшения, MobileNetV2 достига- ет 72,0 % точности первого уровня в ImageNet 2012 всего с 300 млн MAC- адресов и 3,4 млн параметров (табл. 4.1). ShuffleNet Подобно MobileNets, ShuffleNetV1 использует глубинную свертку 3×3, а не стандартную свертку. Кроме того, в ShuffleNetV1 представлены две новые операции: точечная групповая свертка (pointwise group convolution) и пе- ретасовка каналов (channel shuffle). Идея точечной групповой свертки за- ключается в снижении вычислительных затрат на слои свертки 1×1. Однако у нее есть побочный эффект: группа не может видеть информацию от других групп. Это значительно вредит точности. Для устранения данного побочно- го эффекта введена операция перетасовки каналов путем обмена картами признаков между различными группами. Операция перетасовки каналов изображена на рис. 4.14. После перетасовки каждая группа будет содержать информацию из всех групп. В ImageNet 2012 ShuffleNetV1 достигает точности 71,5 % в top-1 с 292 млн MAC (табл. 4.1). Каналы Каналы Каналы Ввод GConv1 Признак GConv2 ВыводПеретасовка каналов Рис. 14.14  Иллюстрация операции перетасовки каналов (Zhang et al., 2017) В ShuffleNetV2 входная карта признаков разделена на две группы в нача- ле каждого стандартного блока. Одна группа проходит через ветвь свертки, состоящую из слоя глубинной свертки 3×3 и двух слоев свертки 1×1. Другая группа проходит через сквозной канал, когда страйд равен 1, и проходит свертку 3×3 с разделением по глубине, когда страйд равен 2. В конце выход- ные данные объединяются по измерению канала, после чего следует опера- ция перетасовки каналов для обмена информацией между группами. При 299 млн MAC ShuffleNetV2 достигает точности top-1 72,6 % в ImageNet 2012 (табл. 4.1). 1 При сквозном канале вывод = ℱ(ввод) + ввод. Без сквозного канала вывод = ℱ(ввод).\n--- Страница 237 ---\n236  Эффективные методы глубокого обучения 4.2.4. Поиск нейронной архитектуры Успех вышеупомянутых эффективных моделей CNN зависит от созданных вручную архитектур нейронных сетей, которые требуют, чтобы эксперты в предметной области исследовали большое пространство проектирования, находя компромисс между размером модели, задержкой, энергией и точно- стью. Это очень трудоемкий процесс, который, как правило, дает не самую оптимальную архитектуру. Как следствие растет интерес к разработке авто- матизированных методов для решения этой задачи. Поиск нейронной архитектуры (neural architecture search, NAS) представ- ляет собой использование методов машинного обуче ния для автоматическо- го проектирования архитектуры нейронной сети. В традиционной форму - лировке NAS (Zoph, Le, 2016) проектирование архитектур нейронных сетей моделируется как задача генерации последовательности, где для создания архитектур нейронных сетей вводится авторегрессионный контроллер RNN. Этот контроллер обучается путем многократного выбора архитектур ней- ронной сети, их оценивания и обновления контроллера на основе обратной связи. Чтобы найти хорошую архитектуру нейронной сети в огромном про- странстве поиска, этот процесс обычно должен обучить для целевой задачи и оценить десятки тысяч нейронных сетей, что приводит к неприемлемо высокой вычислительной нагрузке (104 часов GPU). Для решения данной проблемы предлагается множество методов, направленных на улучшение различных компонентов NAS, включая пространство поиска, алгоритм по- иска и стратегию оценки качества модели. Пространство поиска Для всех методов NAS требуется предопределенное пространство поиска, содержащее основные элементы сети и их взаимные соединения. Например, типичные базовые элементы моделей CNN состоят из (а) сверток (Zoph et al., 2017; Real et al., 2018): стандартных сверток (1×1, 3×3, 5×5), асимметричных сверток (1×3 и 3×1, 1×7 и 7×1), сверток с разделением по глубине (3×3, 5×5), расширенных сверток (3×3); (б) пулинга: average-пулинга (3×3), max-пулинга (3×3); (в) функции активации (Ramachandran et al., 2017). Затем выполняется последовательная укладка этих элементов (Baker et al., 2016) с тождествен- ными связями (Zoph and Le, 2016). Полное пространство поиска на сетевом уровне экспоненциально растет по мере углубления сети (рис. 4.15а). Когда глубина равна 20, это пространство поиска содержит более 1036 различных архитектур нейронных сетей (Zoph et al., 2017). Очень эффективным подходом к повышению скорости поиска являет - ся ограничение рабочего пространства. В частности, в некоторых работах (Zoph et al., 2017 г.) Чжун и др. (2017) предлагают искать не всю архитектуру нейронной сети, а базовые структурные ячейки (рис. 4.15b), которые можно складывать для построения нейронных сетей. При таком подходе сложность архитектуры не зависит от глубины сети, а обученные ячейки можно пере- давать из разных наборов данных. Это позволяет NAS выполнять поиск в не- большом наборе прокси-данных (например, CIFAR-10), а затем переходить\n--- Страница 238 ---\nЭффективные архитектуры нейронных сетей  237 к другому крупномасштабному набору данных (например, ImageNet), под- бирая количество ячеек. Внутри ячейки сложность еще больше снижается за счет поддержки иерархических топологий (Liu et al., 2018a) или постепенного увеличения количества элементов (от простого к сложному) (Liu et al., 2017). Softmax Softmax (a) (d)(b) (с) Изображение ИзображениеОбычная ячейкаОбычная ячейкаОбычная ячейка Редукционная ячейкаРедукционная ячейка Conv 1x1 Conv 3x3 Max-пулинг 3×3 Depth 3x3 Уровень 1 Уровень 2 Уровень 3 Рис. 4.15  Пространство поиска NAS (Deng et al., 2020): (a) пространство по- иска на уровне сети (Zoph and Le, 2016); (b) пространство поиска на уровне ячеек (Zoph et al., 2017); (c) пример изученной структуры ячеек (Liu et al., 2017); (d) трехуровневое иерархическое пространство поиска (Liu et al., 2018a) Алгоритм поиска В методах NAS каждый шаг поиска обычно разбит на два этапа: (1) гене- ратор создает архитектуру, а затем (2) оценщик обучает сеть и измеряет ее показатели. Поскольку оценка качества архитектуры требует полноценного обуче ния получившейся нейронной сети, что очень дорого, алгоритмы поис - ка, влияющие на эффективность выборки, играют важную роль в повышении скорости поиска NAS. Большинство алгоритмов поиска, используемых в NAS, делятся на пять категорий: случайный поиск, обуче ние с подкреплением (RL), эволюционные алгоритмы, байесовская оптимизация и методы на ос - нове градиента. Среди них RL, эволюционные алгоритмы и методы на основе градиента обеспечивают наиболее конкурентоспособные результаты.\n--- Страница 239 ---\n238  Эффективные методы глубокого обучения Методы на основе RL моделируют процесс генерации архитектуры как марковский процесс принятия решений, рассматривают точность модели выбранной архитектуры как вознаграждение и обновляют модель генера- тора архитектуры с использованием алгоритмов RL, включая Q-обуче ние (Baker et al., 2016; Zhong et al. al., 2017), REINFORCE (Zoph and Le, 2016), PPO (Zoph et al., 2017) и т. д. Иногда вместо обуче ния модели генератора архитек - туры используются эволюционные методы (Real et al., 2018; Liu et al., 2018), поддерживающие популяцию архитектур нейронных сетей. Эта популяция обновляется посредством мутаций и рекомбинаций. В то время как методы на основе RL и эволюционные методы оптимизируют архитектуру нейрон- ных сетей в дискретном пространстве, DARTS (Liu et al., 2018b) предлагает непрерывное представление архитектуры: (4.14) где {α i} обозначают параметры архитектуры, oi – операции-кандидаты, x – входные данные, а y – выходные данные. Данный подход позволяет опти- мизировать архитектуры нейронных сетей в непрерывном пространстве с по мощью градиентного спуска, что значительно повышает эффективность поиска. Помимо вышеперечисленных методов, эффективность поиска NAS можно повысить, исследуя пространство архитектур с по мощью операций преобразования сети, начиная с существующей сети и повторно используя веса (Cai et al., 2018a,b; Elsken et al., 2018). Оценка качества модели Чтобы направлять процесс поиска, методы NAS должны оценивать показа- тели качества (обычно точность на проверочном наборе) исследуемых ней- ронных архитектур. Тривиальный подход к получению этих характеристик заключается в обучении выбранных архитектур нейронных сетей на обуча- ющих данных и измерении их точности на проверочном наборе. Однако это ведет к чрезмерным вычислительным затратам (Zoph, Le, 2016; Zoph et al., 2017; Real et al., 2018). Поэтому разработаны новые методы, направленные на ускорение этапа оценки производительности. В качестве альтернативы этап оценки можно ускорить с по мощью гиперсе- ти (Brock et al., 2017), которая может напрямую генерировать веса нейронной архитектуры без ее обуче ния. Хотя при использовании сгенерированных весов точность модели значительно ухудшится, эту точность можно исполь- зовать в качестве прокси-метрики для выбора нейронных архитектур. Та- ким образом, необходимо обучить только одну гиперсеть, что значительно снижает затраты на поиск. Точно так же методы One-shot NAS (Pham et al., 2018; Liu et al., 2018b; Cai et al., 2019) сосредоточены на обучении одной су - персети, от которой небольшие подсети напрямую наследуют веса без затрат на обуче ние. Автоматическое проектирование или ручная разработка? На рис. 4.16 представлены сводные показатели автоматически спроектиро- ванных моделей CNN в сравнении с моделями CNN, разработанными чело-\n--- Страница 240 ---\nЭффективные архитектуры нейронных сетей  239 веком, после тестирования на наборе ImageNet. NAS не только экономит тру - дозатраты инженеров, но и обеспечивает лучшие модели CNN по сравнению с ручной разработкой. Помимо классификации ImageNet, автоматически спроектированные модели CNN превзошли модели, разработанные вручную, на задачах по обнаружению объектов (Zoph et al., 2017; Chen et al., 2019b; Ghiasi et al., 2019; Tan et al., 2020a) и семантической сегментации (Liu et al., 2019; Chen et al., 2018). Точность top-1 на ImageNet, % Размер модели ВручнуюУниверсальная Чем больше, тем лучше Чем меньше, тем лучше МАС, млн Рис. 4.16  Обобщенные результаты тестирования автоматически спроекти- рованных моделей CNN и моделей CNN, разработанных вручную, на наборе ImageNet (Cai et al., 2020a) 4.2.5. Поиск нейронной архитектуры, ориентированной на оборудование Хотя NAS продемонстрировал многообещающие результаты, добившись зна- чительного снижения показателя MAC без ущерба для точности, в приклад- ных приложениях нас интересует реальная эффективность оборудования (например, задержка вывода, энергопотребление), а не число MAC. К сожале- нию, MAC-эффективность напрямую не связана с реальной аппаратной эф- фективностью. На рис. 4.17 приведено сравнение автоматически разработан - ных моделей CNN (NASNet-A и AmoebaNet-A) и моделей CNN, разработанных человеком (MobileNetV2-1.4). Хотя NASNet-A и AmoebaNet-A имеют меньший формальный показатель MAC, чем MobileNetV2-1.4, на самом деле они рабо- тают медленнее, чем MobileNetV2-1.4 на реальном оборудовании. Это свя- зано с тем, что показатель MAC отражает только вычислительную сложность операций свертки. Другие факторы, такие как стоимость доступа к данным, параллелизм и стоимость поэлементных операций, которые су щест венно влияют на реальную эффективность оборудования, не учитываются.\n--- Страница 241 ---\n240  Эффективные методы глубокого обучения Задержка Googele Pixel 1, мсОбычный NAS, одинаковое число MAC, задержка намного больше Небольшое число MAC, но задержка больше МАС, млн Рис. 4.17  Показатель MAC не отражает реальной эффективности оборудования. NASNet-A и AmoebaNet-A (модели CNN, разработанные автоматически) имеют меньший MAC, чем MobileNetV2-1.4 (модель CNN, разработанная человеком). Однако они работают медленнее, чем Mo- bileNetV2-1.4 на Google Pixel 1 Эта проблема побуждает исследователей разрабатывать методы NAS с уче- том особенностей аппаратного обеспечения (Tan et al., 2018; Cai et al., 2019; Wu et al., 2019), которые напрямую включают обратную связь с оборудова- нием в процесс поиска архитектуры. Пример аппаратного фреймворка NAS изображен на рис. 4.18. Помимо оценки точности, каждая выбранная архи- тектура нейронной сети проверяется на реальном оборудовании для сбора информации о задержках. Многоцелевое вознаграждение REW определяется на основе точности ACC и задержки LAT : (4.15) где T – задержка на целевом оборудовании, а ω – гиперпараметр. Прогнозирование задержки Измерение задержки на реальном устройстве является точным, но не иде- альным способом поиска масштабируемой нейронной архитектуры. На то есть две причины: (а) низкая скорость . Например, в TensorFlow-Lite1 нам нужно усреднить сотни прогонов, чтобы получить точное измерение, что занимает примерно 20 секунд на одну итерацию поиска архитектуры. Это намного медленнее, чем однократное выполнение прогона вперед/назад. (б) Высокая стоимость. Для создания автоматического конвейера сбора данных о задержках с мобильной фермы необходимо соединить в кластер 1 https://www.tensorflow.org/lite.\n--- Страница 242 ---\nЭффективные архитектуры нейронных сетей  241 большое количество физических мобильных устройств и разработать специ- альное программное обеспечение. КонтроллерПримеры моделей из пространства поискаУчительМобильные телефоны точность задержка вознаграждениеМногоцелевое вознаграждение Рис. 4.18  Пример аппаратно-ориентированного алгоритма NAS (Tan et al., 2018) По сравнению с прямым измерением более экономичным решением яв- ляется создание модели прогнозирования для оценки задержки (Cai et al., 2019). На практике этот метод реализуется путем выборки архитектур ней- ронных сетей из пространства кандидатов и профилирования их задержки на целевой аппаратной платформе. Собранные данные затем используются для построения модели прогнозирования задержки. Для аппаратных плат - форм с последовательным выполнением операций, таких как мобильные устройства и FPGA, простой таблицы поиска по задержкам, которая сопо- ставляет каждую операцию с ее предполагаемой задержкой, достаточно, чтобы обеспечить очень точные прогнозы задержки (рис. 4.19). Еще одним Реальная, мс Ожидаемая, мсy = x Рис. 4.19  Прогнозируемая задержка по сравнению с реальной задержкой в Google Pixel 1 (Cai et al., 2019)\n--- Страница 243 ---\n242  Эффективные методы глубокого обучения преимуществом этого подхода является то, что он позволяет моделировать задержку нейронной сети как потерю регуляризации (рис. 4.20), позволяя оптимизировать компромисс между точностью и задержкой дифференци- рованным образом. Обучаемый блок Обучаемый блокОбучаемый блокВХОД ВЫХОД𝔼[Задержка] = α × F(conv_3x3) + β × F(conv_5x5) + σ × F(Identity) + ζ × F(pool_3x3) 𝔼[задержка] = å i𝔼[задержка i] Loss = Loss CE + λ 1||w|| 22 + λ 2𝔼[задержка] Рис. 4.20  Обеспечение дифференцируемости задержки путем введения потери задержки (Cai et al., 2019) Специализированные модели для различного оборудования Поскольку стоимость создания новой модели нейронной сети весьма высо- ка, часто применяется развертывание одной и той же модели для всех ап- паратных платформ. Однако это неоптимально, так как разные аппаратные платформы имеют разные свойства, такие как количество арифметических блоков, пропускная способность памяти, размер кеша и т. д. Используя аппа- ратные технологии NAS, можно получить специализированную архитектуру нейронной сети для каждого варианта оборудования. На рис. 4.21 детально изображены архитектуры специализированных мо- делей CNN для графических процессоров и мобильных устройств. Мы заме- тили, что архитектуре присуще разное строение при ориентации на разные платформы: (а) модель для GPU более мелкая и широкая, особенно на ранних стадиях, когда карта признаков имеет более высокое разрешение; (б) модель GPU предпочитает бóльшие операции MBConv (например, MBConv6 7×7), в то время как мобильная модель предпочитает меньшие операции MBConv. Это связано с тем, что GPU имеет гораздо более высокий параллелизм, чем процессор мобильного устройства, поэтому он может использовать преиму - щества больших операций MBConv. Еще одно интересное наблюдение заклю- чается в том, что искомые модели на всех платформах предпочитают более крупные операции MBConv в первом блоке на каждом этапе, где карта при- знаков подвергается субдискретизации. Это может быть связано с тем, что более крупные операции MBConv выгодны для сети, так как они сохраняют больше информации при понижении разрешения. В табл. 4.2 показаны сводные результаты специализированных моделей для графических процессоров и мобильных устройств. Интерес вызывает тот факт, что модели, оптимизированные для GPU, не работают быстро на мобильных устройствах, и наоборот. Поэтому важно сгенерировать специа- лизированные нейронные сети для разных аппаратных архитектур, чтобы добиться максимальной эффективности на различном оборудовании.\n--- Страница 244 ---\nЭффективные архитектуры нейронных сетей  243 Пулинг FC Пулинг FC Рис. 4.21  Эффективные модели, оптимизированные для различного обо- рудования. MBConv3 и MBConv6 обозначают мобильный блок перевернутого узкого места с коэффициентом расширения 3 и 6 соответственно. Выводы: для GPU лучше подходят неглубокие и широкие модели с ранним пулингом; для мо- бильного оборудования – глубокие и узкие модели с поздним пулингом. Слои пулинга предпочитают большое и широкое ядро. Ранние слои предпочитают мелкие ядра. Поздние слои предпочитают крупные ядра (Cai et al., 2019) Таблица 4.2. На реальном оборудовании лучше работают специализированные модели (Cai et al., 2019). При условии равной точности специализированная модель (ProxylessNAS-Mobile) снижает задержку в 1,8 раза по сравнению с неспециализированной моделью CNN (MobileNetV2-1.4). Кроме того, модели, оптимизированные для GPU, не так быстро работают на мобильных устройствах, и наоборот СетьImageNet Top-1, %Задержка GPU, мсЗадержка мобильного устройства, мс MobileNetV2-1.4 (Sandler et al., 2018) 74,7 – 143 ProxylessNAS-GPU (Cai et al., 2019) 75,1 5,1 124 ProxylessNAS-Mobile (Cai et al., 2019) 74,6 7,2 78 Поддержка нескольких аппаратных платформ и ограничения эффективности Хотя специализированные модели CNN превосходят неспециализированные аналоги, разработка специализированных CNN для каждого сценария при- менения по-прежнему представляет собой трудную задачу как при ручном проектировании, так и с по мощью аппаратных NAS, поскольку подобные методы требуют повторения процесса проектирования сети и переобучения спроектированной сети с нуля. Их совокупная стоимость растет линейно по мере увеличения количества сценариев развертывания, что приведет к из- быточному потреблению энергии и выбросу CO 2 (Strubell et al., 2019). Это лишает сети возможности работать с огромным количеством оборудования (23,14 млрд устройств IoT в 2018 г.)1 и высокодинамичными средами раз- 1 https://www .statista.com/statistics/471264/iot-number-of-c onnected-devices-worldwide/.\n--- Страница 245 ---\n244  Эффективные методы глубокого обучения вертывания (различные параметры батареи питания, различные требования к задержке и т. д.). Одним из многообещающих решений этой проблемы является создание универсальной сети (once-for-all, OFA) (Cai et al., 2020a; Yu et al., 2020), кото- рую можно напрямую развернуть в различных архитектурных конфигураци- ях, сокращая затраты на обуче ние. Вывод выполняется путем выбора только части сети OFA. Архитектура гибко поддерживает различную глубину, шири - ну, размер ядра и разрешение без переобучения. Пример OFA изображен на рис. 4.22 (слева). В частности, этап обуче ния модели отделен от этапа поис - ка нейронной архитектуры. На этапе обуче ния модели основное внимание уделяется повышению точности всех подсетей, полученных путем выбора различных частей сети OFA. Подмножество подсетей выбирается на этапе специализации модели для обуче ния предикторов точности и предикторов задержки. Поиск архитектуры на основе предикторов (Liu et al., 2018) для по- лучения специализированной подсети проводится с учетом целевого обору - дования и ограничений, а стоимость незначительна1. Таким образом, общая стоимость проектирования специализированной нейронной сети снижается с O(N) до O(1) (рис. 4.22, середина). Обучение универсальной сети прямое развертывание Облачный ИИМобильный ИИ«Тонкий» ИИ (AIoT)Число сценариев развертывания Задержка Samsung Note10, мсТочность ImageNet (Top-1, %) Разное оборудование/ограниченияОднократное обучение, много компромиссов Четыре обучения, четыре компромиссаспециальные Прежние: стоимость O(N) Наши: стоимость O(1) Меньше в 16–1300 разСтоимость разработкиподсети (без пере­ обучения) Рис. 4.22  Слева: единая универсальная сеть обучена поддерживать раз- личные архитектурные конфигурации, включая глубину, ширину, размер ядра и разрешение. Специализированная подсеть выбирается напрямую из единой сети без обуче ния, с учетом сценария развертывания. Середина: этот подход снижает стоимость специализированного развертывания глубокого обуче ния с O(N) до O(1). Справа: универсальная сеть с последующим выбором модели мо- жет обеспечить множество компромиссов между точностью и задержкой путем обуче ния только один раз по сравнению с обычными методами, требующими повторного обуче ния (Cai et al., 2020) В табл. 4.3 представлено сравнение методов OFA и современных аппарат - ных NAS на мобильном телефоне (Google Pixel 1). Стоимость OFA постоянна, в то время как стоимость других моделей линейно зависит от количества сценариев развертывания (N). При N = 40 общие выбросы CO 2 от OFA в 16 раз 1 https://github.com/mit-han-lab/once-for-all/blob/master/tutorial/ofa.ipynb.\n--- Страница 246 ---\nЭффективные архитектуры нейронных сетей  245 меньше, чем у ProxylessNAS, в 19 раз меньше, чем у FBNet, и в 1300 раз мень- ше, чем у MnasNet. Таблица 4.3. Обобщенные результаты для телефона Pixel 1 (Cai et al., 2020). Первая группа соответствует разработанным человеком моделям CNN. Вторая группа – обычным NAS. Третья группа – аппаратно-ориентированным NAS. Последняя группа соответствует OFA. Метка «#75» означает, что специализированные подсети точно настроены на 75 эпох после захвата весов из сети OFA. «CO2e» обозначает выбросы CO2, которые рассчитываются на основе данных (Strubell et al., 2019). Стоимость AWS рассчитывается на основе стоимости крупных экземпляров Amazon AWS P3.16x, нагружаемых по требованию Сеть ImageNet top-1, % MAC, млн Мобильная задержка, мс Стоимость (часов GPU) Стоимость обуче ния (часов GPU)Совокупная стоимость (N = 40)Часов GPU, тыс. CO2e, тыс. фунтов Стоимость AWS, тыс. долл. MobileNetV2 (Sandler et al., 2018)72,0 300 66 0 1507N 6 1,7 18,4 MobileNetV2 #1200 73,5 300 66 0 12007N 48 13,6 146,9 NASNet-A (Zoph et al., 2017) 74,0 564 –480007N – 1920 544,5 5875,2 DARTS (Liu et al., 2018b) 73,1 595 – 967N 2507N 14 4,0 42,8 MnasNet (Tan et al., 2018) 74,0 317 70 40000N – 1600 453,8 4896,0 FBNet-C (Wu et al., 2019) 74,9 375 – 2167N 3607N 23 6,5 70,4 ProxylessNAS (Cai et al., 2019) 74,6 320 71 2007N 3007N 20 5,7 61,2 SinglePathNAS (Guo et al., 2019) 74,7 328 –288 + 247N3847N 17 4,8 52,0 AutoSlim (Yu, Autoslim, 2019) 74,2 305 63 180 3007N 12 3,4 36,7 MobileNetV3-Large (Howard et al., 2019)75,2 219 58 – 1807N 7,2 1,8 22,2 OFA 76,0 230 58 40 1200 1,2 0,34 3,7 OFA #75 76,9 230 58 401200 + 757N4,2 1,2 13,0 OFA Large #75 80,0 595 – 401200 + 757N4,2 1,2 13,0 На рис. 4.23 обобщены результаты OFA при разных значениях MAC и огра- ничениях задержки Pixel 1. Интересное наблюдение заключается в том, что обуче ние искомых нейронных архитектур с нуля не может достичь того же уровня точности, что и OFA, что позволяет предположить, что превосходным характеристикам OFA способствуют не только нейронные архитектуры, но и предварительно обученные веса.\n--- Страница 247 ---\n246  Эффективные методы глубокого обучения Точность top-1 на ImageNet, % Точность top-1 на ImageNet, %Снижение MAC в 1,68 разаСнижение задержки в 2,6 раза Точность выше на 3,8 %Точность выше на 2,8 % МАС, млнOFA Задержка Google Pixel 1, мсOFA – обучение с нуля EfficientNet 81 80 79 78 77 7681 80 79 78 77 76200 400 600 800 1000 1200 100 150 200 250 300 350 400 0 50 Рис. 4.23  Обуче ние нейронных архитектур поиска с нуля не может обеспечить такую же точность, как OFA (Cai et al., 2020) 4.3. заКЛюЧение За последние несколько лет глубокие нейронные сети добились беспреце- дентного успеха в области искусственного интеллекта; однако столь превос - ходные результаты достигаются за счет высокой вычислительной сложности. Это ограничивает их применение на многих периферийных устройствах, где аппаратные ресурсы сильно ограничены размерами корпуса, емкостью батареи и отсутствием системы охлаждения. В этой главе представлен систематический обзор эффективных моделей глубокого обуче ния, позволяющий как исследователям, так и практикам быст ро начать работу в данной области. Сначала мы описываем различные подходы к сжатию моделей, ставшие отраслевыми стандартами, такие как прореживание, факторизация, квантование и эффективное проектирова- ние моделей. Далее описываем новые подходы, направленные на сниже- ние стоимости разработки моделей, созданных вручную. Мы рассматриваем методы поиска нейронной архитектуры, автоматического прореживания и квантования, которые могут превзойти ручное проектирование, требуя лишь минимальных усилий со стороны человека. Наконец, мы описываем универсальную методику, позволяющую эффективно поддерживать многие аппаратные платформы и соответствовать ограничениям эффективности без повторения дорогостоящих этапов поиска и переобучения. Литературные исто ЧниКи Baker Bowen, Gupta Otkrist, Naik Nikhil, Raskar Ramesh, 2016. Designing neu- ral network architectures using reinforcement learning. arXiv preprint. arXiv: 1611.02167.\n--- Страница 248 ---\nЛитературные источники  247 Banner Ron, Nahshan Yury, Soudry Daniel, 2019. Post training 4-bit quantization of convolutional networks for rapid-deployment. In: Advances in Neural Informa- tion Processing Systems, pp. 7950–7958. Bengio Yoshua, Léonard Nicholas, Courville Aaron, 2013. Estimating or propagat - ing gradients through stochastic neurons for conditional computation. arXiv preprint. arXiv:1308.3432. Brock Andrew, Lim Theodore, Ritchie James M., Weston Nick, 2017. Smash: one- shot model architecture search through hypernetworks. arXiv preprint. arXiv: 1708.05344. Bucilua Cristian, Caruana Rich, Niculescu-Mizil Alexandru, 2006. Model compres- sion. In: Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 535–541. Cai Han, Chen Tianyao, Zhang Weinan, Yu Yong,Wang Jun, 2018a. Efficient archi- tecture search by network transformation. In: AAAI. Cai Han, Yang Jiacheng, Zhang Weinan, Han Song, Yu Yong, 2018b. Path-level net - work transformation for efficient architecture search. In: ICML. Cai Han, Gan Chuang, Wang Tianzhe, Zhang Zhekai, Han Song, 2020a. Once for all: train one network and specialize it for efficient deployment. In: International Conference on Learning Representations. Cai Han, Zhu Ligeng, Proxyless N. A. S, Song Han, 2019. Direct neural architecture search on target task and hardware. In: International Conference on Learning Representations. Cai Yaohui, Yao Zhewei, Dong Zhen, Gholami Amir, Mahoney Michael W., Zeroq Kurt Keutzer, 2020b. A novel zero shot quantization framework. In: Proceed- ings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 13169–13178. Chen Guobin, Choi Wongun, Yu Xiang, Han Tony, Chandraker Manmohan, 2017. Learning efficient object detection models with knowledge distillation. In: Advances in Neural Information Processing Systems, pp. 742–751. Chen Liang-Chieh, Collins Maxwell, Zhu Yukun, Papandreou George, Zoph Barret, Schroff Florian, Adam Hartwig, Shlens Jon, 2018. Searching for efficient multi- scale architectures for dense image prediction. In: Advances in Neural Informa- tion Processing Systems, pp. 8699–8710. Chen Yu-Hsin, Krishna Tushar, Emer Joel S., Eyeriss Vivienne Sze, 2016. An energy- efficient reconfigurable accelerator for deep convolutional neural networks. IEEE Journal of Solid-State Circuits. Chen Yu-Hsin, Yang Tien-Ju, Emer Joel, Sze Vivienne, 2019a. Eyeriss v2: a flexible accelerator for emerging deep neural networks on mobile devices. IEEE Journal on Emerging and Selected Topics in Circuits and Systems 9 (2), 292–308. Chen Yukang, Yang Tong, Zhang Xiangyu, Meng Gaofeng, Xiao Xinyu, Detnas Jian Sun, 2019b. Backbone search for object detection. In: Advances in Neural In- formation Processing Systems, pp. 6642–6652. Cheong Robin, Daniel Robel, 2019. Transformers. Zip: Compressing transformers with pruning and quantization. Technical report. Stanford University, Stanford, California. Courbariaux Matthieu, Bengio Yoshua, 2016. Binarynet: training deep neural net - works with weights and activations constrained to + 1. arXiv:1602.02830.\n--- Страница 249 ---\n248  Эффективные методы глубокого обучения Courbariaux Matthieu, Bengio Yoshua, Binaryconnect Jean-Pierre David, 2015. Training deep neural networks with binary weights during propagations. In: NIPS. Deng Jia, Dong Wei, Socher Richard, Li Li-Jia, Li Kai, Li Imagenet Fei-Fei , 2009. A large-scale hierarchical image database. In: IEEE Conference on Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE, pp. 248–255. Deng Lei, Li Guoqi, Han Song, Shi Luping, Xie Yuan, 2020. Model compression and hardware acceleration for neural networks: a comprehensive survey. Proceed- ings of the IEEE 108 (4), 485–532. Denton Emily L., Zaremba Wojciech, Bruna Joan, LeCun Yann, Fergus Rob, 2014. Exploiting linear structure within convolutional networks for efficient evalua- tion. In: Advances in Neural Information Processing Systems, pp. 1269–1277. Elsken Thomas, Metzen Jan Hendrik, Hutter Frank, 2018. Efficient multi-objective neural architecture search via Lamarckian evolution. arXiv preprint. arXiv: 1804.09081. Engelbrecht Andries Petrus, 2001. A new pruning heuristic based on variance analy - sis of sensitivity information. IEEE Transactions on Neural Networks 12 (6), 1386–1399. Frankle Jonathan, Carbin Michael, 2018. The lottery ticket hypothesis: finding sparse, trainable neural networks. arXiv preprint. arXiv:1803.03635. Frankle Jonathan, Dziugaite Gintare Karolina, Roy Daniel, Carbin Michael , 2020. Linear mode connectivity and the lottery ticket hypothesis. In: International Conference on Machine Learning. PMLR, pp. 3259–3269. Ghiasi Golnaz, Lin Tsung-Yi, Le Nas-fpn Quoc V., 2019. Learning scalable feature pyramid architecture for object detection. In: Proceedings of the IEEE Confer - ence on Computer Vision and Pattern Recognition, pp. 7036–7045. Giles C. Lee, Omlin Christian W., 1994. Pruning recurrent neural networks for improved generalization performance. IEEE Transactions on Neural Networks 5 (5), 848–851. Girshick Ross, 2015. Fast r-cnn. In: Proceedings of the IEEE International Confe- rence on Computer Vision, pp. 1440–1448. Golub Gene H., Van Loan Charles F., 1996. Matrix Computations. Johns Hopkins University Press, Baltimore and London. Gong Yunchao, Liu Liu, Yang Ming, Bourdev Lubomir, 2014. Compressing deep con- volutional networks using vector quantization. arXiv preprint. arXiv:1412.6115. Guo Yiwen, Yao Anbang, Chen Yurong, 2016. Dynamic network surgery for efficient dnns. In: Advances in Neural Information Processing Systems, pp. 1379–1387. Guo Zichao, Zhang Xiangyu, Mu Haoyuan, Heng Wen, Liu Zechun, Wei Yichen, Sun Jian, 2019. Single path one-shot neural architecture search with uniform sam- pling. arXiv preprint. arXiv:1904.00420. Han Song, 2017. Efficient methods and hardware for deep learning. Han Song, Kang Junlong, Mao Huizi, Hu Yiming, Li Xin, Li Yubin, Xie Dongliang, Luo Hong, Yao Song, Wang Yu, et al., 2017. Ese: efficient speech recognition engine with sparse lstm on fpga. In: Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays. ACM, pp. 75–84. Han Song, Liu Xingyu, Mao Huizi, Pu Jing, Pedram Ardavan, Horowitz Mark A., Dally William J., 2016. Eie: efficient inference engine on compressed deep neural\n--- Страница 250 ---\nЛитературные источники  249 network. In: Proceedings of the 43rd International Symposium on Computer Architecture. IEEE Press, pp. 243–254. Han Song, Mao Huizi, Dally William J., 2015a. Deep compression: compressing deep neural networks with pruning, trained quantization and Huffman coding. arXiv preprint. arXiv:1510.00149. Han Song, Pool Jeff, Tran John, Dally William, 2015b. Learning both weights and connections for efficient neural network. In: Advances in Neural Information Processing Systems, pp. 1135–1143. Hassibi Babak, Stork David G., 1993. Second Order Derivatives for Network Prun- ing: Optimal Brain Surgeon. Morgan Kaufmann. He Kaiming, Zhang Xiangyu, Ren Shaoqing, Sun Jian, 2016. Deep residual learning for image recognition. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770–778. He Yihui, Lin Ji, Liu Zhijian, Wang Hanrui, Li Li-Jia, Amc Song Han, 2018. Automl for model compression and acceleration on mobile devices. In: Proceedings of the European Conference on Computer Vision (ECCV), pp. 784–800. He Yihui, Zhang Xiangyu, Sun Jian, 2017. Channel pruning for accelerating very deep neural networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1389–1397. Hinton Geoffrey, Vinyals Oriol, Dean Jeff, 2015. Distilling the knowledge in a neural network. arXiv preprint. arXiv:1503.02531. Howard Andrew, Sandler Mark, Chu Grace, Chen Liang-Chieh, Chen Bo, Tan Min- gxing, Wang Weijun, Zhu Yukun, Pang Ruoming, Vasudevan Vijay, et al., 2019. Searching for mobilenetv3. In: ICCV 2019. Howard Andrew G., Zhu Menglong, Chen Bo, Kalenichenko Dmitry, Wang Weijun, Weyand Tobias, Andreetto Marco, Mobilenets Hartwig Adam, 2017. Efficient convolutional neural networks for mobile vision applications. arXiv preprint. arXiv:1704.04861. Iandola Forrest N., Moskewicz MatthewW., Ashraf Khalid, Han Song, Dally William J., Squeezenet Kurt Keutzer, 2016. Alexnet-level accuracy with 50x fewer param- eters and< 1mb model size. arXiv preprint. arXiv:1602.07360. Ioffe Sergey, Szegedy Christian, 2015. Batch normalization: accelerating deep network training by reducing internal covariate shift. arXiv preprint. arXiv: 1502.03167. Jacob Benoit, Kligys Skirmantas, Chen Bo, Zhu Menglong, Tang Matthew, Howard Andrew, Adam Hartwig, Kalenichenko Dmitry, 2017. Quantization and training of neural networks for efficient integer-arithmetic-only inference. arXiv preprint. arXiv:1712.05877. Jaderberg Max, Vedaldi Andrea, Zisserman Andrew, 2014. Speeding up convolution- al neural networks with low rank expansions. arXiv preprint. arXiv:1405.3866. Judd Patrick, Albericio Jorge, Hetherington Tayler, Aamodt Tor M., Stripes Andreas Moshovos, 2016. Bit-serial deep neural network computing. In: MICRO. Kim Yong-Deok, Park Eunhyeok, Yoo Sungjoo, Choi Taelim, Yang Lu, Shin Dongjun, 2015. Compression of deep convolutional neural networks for fast and low power mobile applications. arXiv preprint. arXiv:1511.06530. Krizhevsky Alex, Hinton Geoffrey, 2009. Learning multiple layers of features from tiny images.\n--- Страница 251 ---\n250  Эффективные методы глубокого обучения Krizhevsky Alex, Sutskever Ilya, Hinton Geoffrey E., 2012. Imagenet classification with deep convolutional neural networks. In: Advances in Neural Information Processing Systems, pp. 1097–1105. Lebedev Vadim, Ganin Yaroslav, Rakhuba Maksim, Oseledets Ivan, Lempitsky Victor, 2014. Speeding-up convolutional neural networks using fine-tuned cp-decom- position. arXiv preprint. arXiv:1412.6553. Lebedev Vadim, Lempitsky Victor, 2016. Fast convnets using group-wise brain dam- age. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2554–2564. LeCun Yann, Cortes Corinna, Burges Christopher JC, 2010. Mnist handwritten digit database. AT&T Labs [Online]. Available: http://yann.lecun.com/exdb/mnist. LeCun Yann, Denker John S., Solla Sara A., Howard Richard E., Jackel Lawrence D., 1989. Optimal brain damage. In: NIPs, vol. 2, pp. 598–605. Li Fengfu, Zhang Bo, Liu Bin , 2016a. Ternary weight networks. arXiv preprint. arXiv:1605.04711. Li Hao, Kadav Asim, Durdanovic Igor, Samet Hanan, Graf Hans Peter, 2016b. Pruning filters for efficient convnets. arXiv preprint. arXiv:1608.08710. Li Muyang, Lin Ji, Ding Yaoyao, Liu Zhijian, Zhu Jun-Yan, Han Song, 2020. Gan com- pression: efficient architectures for interactive conditional gans. In: Proceed- ings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 5284–5294. Lillicrap Timothy P., Hunt Jonathan J., Pritzel Alexander, Heess Nicolas, Erez Tom, Tassa Yuval, Silver David, Wierstra Daan, 2015. Continuous control with deep reinforcement learning. arXiv preprint. arXiv:1509.02971. Lin Ji, Rao Yongming, Lu Jiwen, 2017. Runtime neural pruning. In: NeurIPS. Lin Zhouhan, Courbariaux Matthieu, Memisevic Roland, Bengio Yoshua, 2015. Neural networks with few multiplications. arXiv preprint. arXiv:1510.03009. Liu Chenxi, Chen Liang-Chieh, Schroff Florian, Adam Hartwig, Hua Wei, Yuille Alan L., Li Auto-deeplab Fei-Fei, 2019. Hierarchical neural architecture search for semantic image segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 82–92. Liu Chenxi, Zoph Barret, Neumann Maxim, Shlens Wei Hua Jonathon, Li Li-Jia, Fei- Fei Li, Yuille Alan, Huang Jonathan, Murphy Kevin, 2018. Progressive neural architecture search. In: Proceedings of the European Conference on Computer Vision (ECCV), pp. 19–34. Liu Chenxi, Zoph Barret, Shlens Wei Hua Jonathon, Li Li-Jia, Fei-Fei Li, Yuille Alan, Huang Jonathan, Murphy Kevin, 2017. Progressive neural architecture search. arXiv preprint. arXiv:1712.00559. Liu Hanxiao, Simonyan Karen, Vinyals Oriol, Fernando Chrisantha, Kavukcuoglu Koray, 2018a. Hierarchical representations for efficient architecture search. In: ICLR. Liu Hanxiao, Simonyan Karen, Darts Yiming Yang, 2018b. Differentiable architec - ture search. arXiv preprint. arXiv: 1806.09055. Liu Yifan, Chen Ke, Liu Chris, Qin Zengchang, Luo Zhenbo, Wang Jingdong, 2019a. Structured knowledge distillation for semantic segmentation. In: Proceed- ings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2604–2613.\n--- Страница 252 ---\nЛитературные источники  251 Liu Zechun, Mu Haoyuan, Zhang Xiangyu, Guo Zichao, Yang Xin, Cheng Kwang-Ting, Metapruning Jian Sun , 2019b. Meta learning for automatic neural network chan - nel pruning. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 3296–3305. Ma Ningning, Zhang Xiangyu, Zheng Hai-Tao, Sun Jian, 2018. Shufflenet v2: practi- cal guidelines for efficient cnn architecture design. In: ECCV. Ma Xiaolong, Guo Wei Niu Fu-Ming, Lin Xue, Tang Jian, Ma Kaisheng, Ren Bin, Pconv Yanzhi Wang, 2020. The missing but desirable sparsity in dnn weight pruning for real-time execution on mobile devices. In: AAAI, pp. 5117–5124. Mao Huizi, Han Song, Pool Jeff, Li Wenshuo, Liu Xingyu, Wang Yu, Dally William J., 2017. Exploring the granularity of sparsity in convolutional neural networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Rec - ognitionWorkshops, pp. 13–20. Molchanov Pavlo, Tyree Stephen, Karras Tero, Aila Timo, Kautz Jan, 2016. Pruning convolutional neural networks for resource efficient transfer learning. CoRR. arXiv:1611.06440 [abs]. Molchanov Pavlo, Tyree Stephen, Karras Tero, Aila Timo, Kautz Jan, 2017. Pruning convolutional neural networks for resource efficient transfer learning. In: In- ternational Conference on Learning Representations. Nagel Markus, van Baalen Mart, Blankevoort Tijmen, Welling Max, 2019. Data-free quantization through weight equalization and bias correction. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 1325–1334. Niu Wei, Ma Xiaolong, Lin Sheng, Wang Shihao, Qian Xuehai, Lin Xue, Wang Yanzhi, Patdnn Bin Ren, 2020. Achieving real-time dnn execution on mobile devices with pattern-based weight pruning. In: Proceedings of the Twenty-Fifth Inter - national Conference on Architectural Support for Programming Languages and Operating Systems, pp. 907–922. Pham Hieu, Guan Melody Y., Zoph Barret, Le Quoc V., Dean Jeff, 2018. Efficient neural architecture search via parameter sharing. In: ICML. Ramachandran Prajit, Zoph Barret, Le Quoc V., 2017. Searching for activation func - tions. arXiv preprint. arXiv: 1710.05941. Rastegari Mohammad, Ordonez Vicente, Redmon Joseph, Xnor-net Ali Farhadi, 2016. Imagenet classification using binary convolutional neural networks. In: Euro- pean Conference on Computer Vision. Springer, pp. 525–542. Real Esteban, Aggarwal Alok, Huang Yanping, Le Quoc V., 2018. Regularized evolu- tion for image classifier architecture search. arXiv preprint. arXiv:1802.01548. Romero Adriana, Ballas Nicolas, Ebrahimi Kahou Samira, Chassang Antoine, Gatta Carlo, Bengio Yoshua, 2014. Fitnets: hints for thin deep nets. arXiv preprint. arXiv:1412.6550. Sandler Mark, Howard Andrew, Zhu Menglong, Zhmoginov Andrey, Chen Liang- Chieh, 2018. Mobilenetv2: inverted residuals and linear bottlenecks. In: Pro- ceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4510–4520. Sanh Victor, Debut Lysandre, Chaumond Julien, Wolf Thomas, 2019. Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter. arXiv preprint arXiv:1910.01108.\n--- Страница 253 ---\n252  Эффективные методы глубокого обучения Sharify Sayeh, Delmas Lascorz Alberto, Siu Kevin, Judd Patrick, Loom Andreas Mo- shovos, 2018. Exploiting weight and activation precisions to accelerate convo- lutional neural networks. In: DAC. Sharma Hardik, Park Jongse, Suda Naveen, Lai Liangzhen, Chau Benson, Chandra Vi- kas, Esmaeilzadeh Hadi, 2018. Bit fusion: bit-level dynamically composable archi- tecture for accelerating deep neural networks. In: Proceedings of the 45th Annual International Symposium on Computer Architecture. IEEE Press, pp. 764–775. Simonyan Karen, Zisserman Andrew, 2014. Very deep convolutional networks for large-scale image recognition. arXiv preprint. arXiv:1409.1556. Srinivas Suraj, Babu R. Venkatesh, 2015. Data-free parameter pruning for deep neural networks. arXiv preprint. arXiv:1507.06149. Strubell Emma, Ganesh Ananya, McCallum Andrew, 2019. Energy and policy con- siderations for deep learning in nlp. In: ACL. Szegedy Christian, Liu Wei, Jia Yangqing, Sermanet Pierre, Reed Scott, Anguelov Dragomir, Erhan Dumitru, Vanhoucke Vincent, Rabinovich Andrew, 2015. Going deeper with convolutions. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1–9. Szegedy Christian, Vanhoucke Vincent, Ioffe Sergey, Shlens Jon, Wojna Zbigniew, 2016. Rethinking the inception architecture for computer vision. In: CVPR. Tan Mingxing, Chen Bo, Pang Ruoming, Vasudevan Vijay, Le Mnasnet Quoc V., 2018. Platform-aware neural architecture search for mobile. arXiv preprint. arXiv: 1807.11626. Tan Mingxing, Pang Ruoming, Le Efficientdet Quoc V., 2020a. Scalable and efficient object detection. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 10781–10790. Tan Zhanhong, Song Jiebo, Ma Xiaolong, Tan Sia-Huat, Chen Hongyang, Miao Yuan- qing, Wu Yifu, Ye Shaokai, Wang Yanzhi, Li Dehui, et al., 2020b. Pcnn: pattern- based fine-grained regular pruning towards optimizing cnn accelerators. arXiv preprint. arXiv:2002.04997. Umuroglu Yaman, Rasnayake Lahiru, Bismo Magnus Sjalander, 2018. A scalable bit-serial matrix multiplication overlay for reconfigurable computing. In: FPL. Vanhoucke Vincent, Senior Andrew, Mao Mark Z., 2011. Improving the Speed of Neural Networks on Cpus. In: Proc. Deep Learning and Unsupervised Feature Learning NIPS Workshop. In: Citeseer, vol. 1, p. 4. Wang Kuan, Liu Zhijian, Lin Yujun, Lin Ji, Haq Song Han, 2018. Hardware-aware automated quantization. arXiv preprint. arXiv:1811.08886. Wen Wei, Wu Chunpeng, Wang Yandan, Chen Yiran, Li Hai, 2016. Learning struc - tured sparsity in deep neural networks. In: Advances in Neural Information Processing Systems, pp. 2074–2082. Wu Bichen, Dai Xiaoliang, Zhang Peizhao, Wang Yanghan, Sun Fei, Wu Yiming, Tian Yuandong, Vajda Peter, Jia Yangqing, Fbnet Kurt Keutzer, 2019. Hardware-aware efficient convnet design via differentiable neural architecture search. In: Pro- ceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 10734–10742. Wu Jiaxiang, Leng Cong, Wang Yuhang, Hu Qinghao, Cheng Jian, 2016. Quantized convolutional neural networks for mobile devices. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4820–4828.\n--- Страница 254 ---\nЛитературные источники  253 Xue Jian, Li Jinyu, Gong Yifan, 2013. Restructuring of deep neural network acoustic models with singular value decomposition. In: Interspeech, pp. 2365–2369. Yang Tien-Ju, Howard Andrew, Chen Bo, Zhang Xiao, Go Alec, Sze Vivienne, Netadapt Hartwig Adam, 2018. Platform-aware neural network adaptation for mobile ap- plications. arXiv preprint. arXiv:1804.03230. Yu Jiahui, Autoslim Thomas Huang, 2019. Towards one-shot architecture search for channel numbers. arXiv preprint. arXiv:1903.11728. Yu Jiahui, Jin Pengchong, Liu Hanxiao, Bender Gabriel, Kindermans Pieter-Jan, Tan Mingxing, Huang Thomas, Song Xiaodan, Pang Ruoming le Quoc, 2020. Bignas: scaling up neural architecture search with big single-stage models. arXiv pre- print. arXiv:2003.11142. Yu Jiecao, Lukefahr Andrew, Palframan David, Dasika Ganesh, Das Reetuparna, Scal- pel Scott Mahlke, 2017. Customizing dnn pruning to the underlying hardware parallelism. ACM SIGARCH Computer Architecture News 45 (2), 548–560. Zagoruyko Sergey, Komodakis Nikos, 2016. Paying more attention to attention: improving the performance of convolutional neural networks via attention transfer. arXiv preprint. arXiv:1612.03928. Zhang Chen, Li Peng, Sun Guangyu, Guan Yijin, Xiao Bingjun, Cong Jason , 2015. Optimizing fpga-based accelerator design for deep convolutional neural net - works. In: Proceedings of the 2015 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pp. 161–170. Zhang Shijin, Du Zidong, Zhang Lei, Lan Huiying, Liu Shaoli, Li Ling, Guo Qi, Chen Tianshi, Cambricon-x Yunji Chen, 2016a. An accelerator for sparse neural net - works. In: 2016 49th Annual IEEE/ACM International Symposium on Microar - chitecture (MICRO). IEEE, pp. 1–12. Zhang Xiangyu, Zou Jianhua, He Kaiming, Sun Jian, 2016b. Accelerating very deep convolutional networks for classification and detection. IEEE Transactions on Pattern Analysis and Machine Intelligence 38 (10), 1943–1955. Zhang Xiangyu, Zhou Xinyu, Lin Mengxiao, Shufflenet Jian Sun, 2017. An extremely efficient convolutional neural network for mobile devices. arXiv preprint. arXiv: 1707.01083. Zhong Zhao, Yan Junjie, Liu Cheng-Lin, 2017. Practical network blocks design with q-learning. arXiv preprint. arXiv:1708.05552. Zhou Shuchang, Wu Yuxin, Ni Zekun, Zhou Xinyu, Wen He, Dorefa-net Yuheng Zou, 2016. Training low bitwidth convolutional neural networks with low bitwidth gradients. arXiv preprint. arXiv:1606.06160. Zhu Chenzhuo, Han Song, Mao Huizi, Dally William J., 2016. Trained ternary quan- tization. arXiv preprint. arXiv: 1612.01064. Zoph Barret, Le Quoc V. , 2016. Neural architecture search with reinforcement learning. arXiv preprint. arXiv:1611.01578. Zoph Barret, Vasudevan Vijay, Shlens Jonathon, Le Quoc V., 2017. Learning trans- ferable architectures for scalable image recognition. arXiv preprint. arXiv: 1707.07012.",
      "debug": {
        "start_page": 217,
        "end_page": 254
      }
    },
    {
      "name": "Глава 5. Условная генерация изображений и управляемая генерация визуальных паттернов 254",
      "content": "--- Страница 255 --- (продолжение)\nГлава 5 Условная генерация изображений и управляемая генерация визуальных паттернов Авторы главы: Ган Хуа, Wormpex AI Research, Белвью, Вашингтон, США; Донгдонг Чен, Microsoft Cloud & AI, Редмонд, Вашингтон, США Краткое содержание главы: визуальный паттерн – это визуально различимая регулярность, которая повторяется предсказуемым образом; распознавание, обнаружение и синтез паттернов – три фундаментальные задачи в изучении зрительных образов; синтез паттернов является наиболее сложной задачей визуального моде- лирования; изучение разделенных представлений – ключ к более управляемому син- тезу визуальных паттернов; изучение разделенных представлений без учителя требует соответствую- щих индуктивных предпосылок; более управляемый синтез паттернов приводит к более объяснимому их анализу. 5.1. В Ведение Зрительное восприятие – сложная задача, поскольку естественные сцены состоят из огромного количества визуальных паттернов (visual pattern)1, ко- 1 Изначально словосочетание visual pattern в научно-технической литературе пе- реводили как «визуальный образ», хотя в английском языке слово pattern имеет\nГлава 5 Условная генерация изображений и управляемая генерация визуальных паттернов Авторы главы: Ган Хуа, Wormpex AI Research, Белвью, Вашингтон, США; Донгдонг Чен, Microsoft Cloud & AI, Редмонд, Вашингтон, США Краткое содержание главы: визуальный паттерн – это визуально различимая регулярность, которая повторяется предсказуемым образом; распознавание, обнаружение и синтез паттернов – три фундаментальные задачи в изучении зрительных образов; синтез паттернов является наиболее сложной задачей визуального моде- лирования; изучение разделенных представлений – ключ к более управляемому син- тезу визуальных паттернов; изучение разделенных представлений без учителя требует соответствую- щих индуктивных предпосылок; более управляемый синтез паттернов приводит к более объяснимому их анализу. 5.1. В Ведение Зрительное восприятие – сложная задача, поскольку естественные сцены состоят из огромного количества визуальных паттернов (visual pattern)1, ко- 1 Изначально словосочетание visual pattern в научно-технической литературе пе- реводили как «визуальный образ», хотя в английском языке слово pattern имеет\n--- Страница 256 ---\nВведение  255 торые часто сопровождают либо стохастические, либо детерминированные процессы, либо их комбинации. По определению визуальный паттерн – это различимая визуальная закономерность, чьи композиционные элементы в целом повторяются предсказуемым образом. В изучении визуальных пат - тернов есть три основные задачи: распознавание, обнаружение и синтез. Различение отличающихся визуальных паттернов соответствует задаче рас - познавания паттернов1. Тот факт, что визуальные паттерны повторяются в окружающем мире, лежит в основе различных методов обнаружения пат - тернов. Синтез паттерна представляет собой задачу создания нового экзем- пляра визуального паттерна. Это влечет за собой процесс моделирования и описания глубинных процессов, которые определяют (и, следовательно, могут предсказывать) вариации визуального паттерна. С точки зрения моделирования и обуче ния для выполнения трех вы- шеуказанных фундаментальных задач необходима разная минимальная информация. В частности, для распознавания паттернов нам достаточ- но идентифицировать наиболее отличительные визуальные признаки2 паттерна, чтобы отличить его от других визуальных паттернов. Другими словами, успешное выполнение задач распознавания образов (например, классификации) не требует, чтобы представления признаков были исчер- пывающими при описании каждой отдельной детали паттерна. Это одна из причин того, что в большинстве современных методов распознавания паттернов, если не во всех, применяется подход дискриминационного мо- делирования. Чтобы лучше это проиллюстрировать, мы предлагаем ознако- миться с несколькими примерами изображений на рис. 5.1. Очевидно, что, даже бегло взглянув на визуальные характеристики некоторых локальных участков изображения, мы уже можем достоверно распознать смысловую категорию этих изображений, даже если это стилизованные художествен- ные произведения. Моделирование паттернов требует немного больше усилий, поскольку за- дача заключается в обнаружении и локализации повторяющихся визуаль- ных паттернов из набора изображений и видео без заранее определенного пространства гипотез (Yuan, 2011; Zhao et al., 2013). Задачам обнаружения паттернов присуще отсутствие обучающей разметки. Поэтому возникает потребность в моделях, способных установить относительно общие пред- более широкий смысл – это одновременно и узнаваемый визуальный образ, и по- вторяющийся шаблон, и нечто среднее между ними. В последнее время это слово стали использовать почти как синоним слова «шаблон», особенно в технических дисциплинах, и часто применяют без перевода. Тем не менее нужно иметь в виду, что в зависимости от контекста слово «паттерн» может по-прежнему означать «об- раз». Строгое введение понятия «паттерн» в научный обиход выполнено в работе Ф. Т. Алескерова и др. «Анализ паттернов в статике и динамике. Часть 1: обзор лите- ратуры и уточнение понятия». https://bijournal.hse.ru/data/2013/10/03/1277895965/1. pdf. – Прим. перев. 1 Здесь мы имеем в виду распознавание паттернов в узком смысле различения раз- ных визуальных образов. Его также можно использовать в широком смысле, чтобы охватить все задачи анализа зрительных закономерностей. 2 В самом деле, визуальный признак также можно рассматривать как атомарный визуальный паттерн.\n--- Страница 257 ---\n256  Условная генерация изображений и управляемая генерация визуальных паттернов ставления и метрическое пространство, в котором может быть проведена перцептивная группировка для выявления значимых семантических визу - альных паттернов. Рис. 5.1  Примеры, показывающие, что для распознавания изображения нам может понадобиться всего несколько отличительных визуальных признаков (также известных как атомарные визуальные паттерны). Даже глядя только на визуальные признаки в локальных областях изображений, мы хорошо распо- знаем семантические категории, к которым они относятся Рис. 5.2  Примеры обнаружения объектов в видеопоследовательности без разметки с использованием технологий, предложенных в (Zhao et al., 2013). Образцы изображений предоставлены авторами исследования В некоторых работах также рассматривалась проблема обнаружения пат - тернов в задаче со слабой разметкой (Liu et al., 2010). Часто предоставляется только ограниченное количество образцов, иногда даже лишь на уровне кад- ра, указывающих, содержит ли кадр паттерн, без указания, где последний расположен. Помимо моделирования характеристик визуальных паттернов, было доказано, что пространственная, временная и/или пространственно- временная контекстуальная информация способствует решению задач об- наружения визуальных паттернов. Эффективная модель для обнаружения визуального паттерна требует представления признаков, которое ищет ком- промисс между всесторонним описанием паттерна и достаточной дискрими- нацией, чтобы паттерны можно было эффективно сгруппировать и отличить от фона. Следовательно, существующие подходы к обнаружению паттернов могут быть либо генеративными (Zhao et al., 2013), либо дискриминацион- ными (Weng et al., 2018), либо их комбинацией. Синтез паттернов требует всестороннего моделирования целевых визу - альных паттернов, поскольку в конечном итоге модель должна фиксиро- вать каждую деталь вместе с вариациями визуальных паттернов. В подходе к проблеме синтеза паттернов, основанном на обучении, часто используют генеративное моделирование. Хотя в генеративном моделировании были\n--- Страница 258 ---\nВведение  257 достигнуты огромные успехи либо с использованием традиционных статис - тических методов (Zhu et al., 1998; Van de Wouwer et al., 1999; Zhu, 2003; Guo et al., 2003), либо с использованием более поздних методов глубокого обуче- ния (Kingma and Welling, 2014; Goodfellow et al., 2014), процессы генерации (или выборки из моделей) часто определяются случайным процессом, когда целенаправленно генерировать визуальные паттерны сложно, если вообще возможно. В этой главе мы сосредоточим наше обсуждение на том, как мы можем добиться более управляемого синтеза визуальных паттернов с по мощью генерации условного изображения на основе глубокого обуче ния. Здесь «управляемый» означает, что существует способ, которым мы можем на- меренно задать значение определенного параметра или подмножества параметров, чтобы управлять генерацией образцов визуальных паттернов по определенным семантическим, физическим и/или геометрическим из- мерениям (также известным как факторы) – таким как выражение лица, цвет и позы. Мы достигаем такой управляемости за счет глубокой условной генерации изображений (deep conditional image generation) со структурой кодер–декодер, где для управления генерацией выборок целевых визуаль- ных паттернов определяется вероятностное пространство над разделенным векторным представлением. Обуче ние такого разделенного представления (disentangled representation) является сложной задачей, которая остается предметом активных исследований. Хотя во многих ранее опубликованных работах авторы утверждали, что научились разделять векторное представ- ление в процессе обуче ния без учителя, Локателло и др. (Locatello et al., 2019) показывают, что изучение разделенного представления без учителя теоретически невозможно без индуктивных предпосылок (inductive bias) как в моделях, так и в наборах данных. Мы посвятили наше исследование тому, как в реальных приложениях компьютерного зрения подобные индуктивные предпосылки могут быть введены путем обуче ния с учителем, частичного обуче ния и самообучения, чтобы изучить разделенное представление для управляемого синтеза визуальных паттернов. Применения, которые мы рас - сматриваем, включают перенос стиля изображения/видео, преобразование текста в изображение и синтез лица. Тем не менее мы надеемся, что выво- ды, полученные в результате этих исследований, помогут решить и другие задачи в различных приложениях. Оставшаяся часть главы будет организована следующим образом: в раз- деле 5.2 мы представляем краткий исторический обзор обуче ния моделей визуальных паттернов. Затем в разделах 5.3 и 5.4 раскрываются основы тра- диционных генеративных моделей, основанных на статистическом обуче- нии, и глубоких генеративных моделей. Далее, в разделе 5.5, мы расскажем, как использовать глубокие генеративные модели для обуче ния и синтеза визуальных паттернов в рамках условной генерации изображений. В разде- ле 5.6 мы опишем три конкретных примера с разными уровнями вовлечен- ности учителя в обуче ние, чтобы показать, как можно ввести индуктивную предпосылку для изучения разделенных представлений и последующего управляемого синтеза визуальных паттернов. Наконец, мы делаем выводы и предположения о направлении будущих исследований в разделе 5.7.\n--- Страница 259 ---\n258  Условная генерация изображений и управляемая генерация визуальных паттернов 5.2. изуЧение Визуа Льны Х паттерно В: КратКий истори ЧесКий обзор Ранние исследования зрительных паттернов уходят корнями в прошлое на несколько десятилетий. Наиболее распространенным подходом было ис - пользование байесовских структур и разработка множества явных моде- лей для моделирования визуальных паттернов. Отдельно можно отметить пионерские работы (Grenander, 1976; Cooper, 1979; Fu, 1982), в которых для моделирования визуальных паттернов использовались статистические мо- дели. В конце 1980-х и начале 1990-х гг. становятся популярными модели изображений. Первые такие модели предполагали локальную и кусочную гладкость естественных изображений и были описаны во многих исследо- вательских работах. Например, в работах (Blake, Zisserman, 1987; Terzopou- los, 1983) предлагаются физически обоснованные модели, а в (Poggio et al., 1985) используется теория регуляризации. В работе (Mumford, Shah, 1989) эта задача сформулирована как энергетическая функция и решена методом минимизации энергии. Затем благодаря двум влиятельным исследованиям вышеупомянутые кон- цепции начали сближаться со статистическими описательными моделями. Одним из этих исследований является моделирование марковских случайных полей (Markov random fields, MRF) (Besag, 1974; Cross, Jain, 1983). Авторы этих работ исходили из того, что шаблон текстуры следует стохастическому, возможно периодическому, двумерному полю изображения, и исследовали марковские случайные поля в качестве моделей текстур. Модель текстуры определяется как математическая процедура, способная создать и описать текстурное изображение. Также получила известность работа (Geman, Ge- man, 1984), в которой проводится аналогия между изображениями и систе- мами статистической механики и формулируется моделирование паттернов как задача распределения и выборки Гиббса в рамках байесовской струк - туры. Более конкретно, значения пикселей, а также наличие и ориентация краев рассматриваются как состояния атомов или молекул в физической системе, подобной кристаллической решетке, а назначение энергетической функции в физической системе определяет распределение Гиббса. Поскольку распределение Гиббса эквивалентно MRF, его также можно рассматривать как модель изображения MRF. Однако у этих работ есть два ограничения: 1) марковские модели случайных полей основаны на парных кликах, поэто- му они не могут очень хорошо характеризовать естественные изображения; 2) выборка Гиббса занимает очень много времени, что затрудняет ее при- менение в реальных системах. Существуют и другие вероятностные модели, предложенные для обуче ния представлениям визуальных паттернов, такие как деформируемые шаблоны для лица (Yuille, 1991), глаз (Xie et al., 1994) и объектов (Shackleton, 1994). По сравнению с гомогенными (однородными) моделями MRF деформируемые шаблоны неоднородны. В стремлении справиться с вычислительной сложностью вышеупомянутых описательных моделей были предложены генеративные модели, которые\n--- Страница 260 ---\nИзучение визуальных паттернов: краткий исторический обзор  259 постулируют скрытые переменные как причины сложных зависимостей в не- обработанных сигналах. Простая иллюстрация этого подхода изображена на рис. 5.3. Возьмем, к примеру, человека – у него обычно бывает одна голова (обозначим ее через h), одно туловище (b ), две руки и две ноги (a l, ar, ll, lr). Описательная модель рассматривает совместное распределение пяти частей p(h, b, al, ar, ll, lr) без понимания скрытого понятия «человек». Напротив, ге- неративные модели считают пять частей условно зависимыми от скрытой переменной human, обозначающей человека, а затем формализуют их с по- мощью модели условной вероятности p (h, b, al, ar, ll, lr|d). (а) описательная модель (б) генеративная модельh bal ar lr llh bal ar lr llhuman скрытая переменная Рис. 5.3  Простая иллюстрация различий между описательными моделями и генеративными моделями с точки зрения представлений. В отличие от описа- тельных моделей, генеративные модели вводят скрытые переменные для моде- лирования сильной зависимости в наблюдаемых изображениях К типичным представителям генеративных моделей относятся разрежен- ное кодирование (Roweis, Ghahramani, 1999; Hoyer, Hyvärinen, 2002; Manat, Zhang, 1993), вейвлетное представление изображений (Do, Vetterli, 2003; Lu et al., 1992), анализ главных компонент (principle component analysis, PCA). (Kambhatla, Leen, 1997; Kong et al., 2005), анализ независимых компонент (independent component analysis, ICA) (Hyvärinen, 1999; Hyvärinen, Oja, 2000) и случайная модель колледжа (Lee et al., 2001). Такие модели предполагают, что изображение может быть представлено серией базовых элементов. Та- ким образом, размер представления может быть значительно уменьшен за счет проецирования исходного пространства изображения в скрытое про- странство. Следовательно, снижается стоимость вычислений. Во многих статьях генеративные модели часто неотделимы от описательных моделей, поскольку скрытые переменные нередко характеризуются описательной моделью. Например, схема разреженного кодирования представляет собой двухуровневую генеративную модель и предполагает, что базовые элементы изображений представлены независимыми и одинаково распределенными скрытыми переменными. В скрытых марковских моделях, предназначен- ных для моделирования речи и движения, роль скрытого слоя играет цепь Маркова. В последнее время благодаря использованию наборов больших данных и быстродействующего вычислительного оборудования глубокое обуче ние достигло больших успехов во многих задачах искусственного интеллекта,\n--- Страница 261 ---\n260  Условная генерация изображений и управляемая генерация визуальных паттернов таких как визуальное распознавание (Szegedy et al., 2015; He et al., 2016) и обнаружение объектов (Girshick, 2015; Ren et al., 2015). По той же причине было предложено множество генеративных моделей на основе глубоких ней- ронных сетей, включая пиксельную CNN (Van den Oord et al., 2016), вариаци- онный автокодировщик (VAE) (Doersch, 2016) и генеративно-состязательные сети (Goodfellow et al., 2014). По сути, чтобы генерировать высококачествен- ные изображения, такие глубокие модели должны научиться запоминать в своем пространстве весов визуальные паттерны и лежащие в их основе структуры. В какой-то степени лучшее качество генерации эквивалентно лучшему обуче нию паттернам. В следующих разделах мы кратко представим основы классических и глубоких генеративных моделей. 5.3. К Ласси ЧесКие генерати Вные моде Ли С математической точки зрения (Hua, 2020) классические генеративные мо- дели – это статистические модели, нацеленные на моделирование совмест - ного распределения вероятностей p(X, z|Θ), где X – наблюдаемая многомер- ная переменная, z – вышеупомянутая скрытая переменная, а Θ – параметры модели, подлежащие оптимизации. Скрытая переменная Z может пред- ставлять различные значимые факторы (cofounder). Например, если Z – это метки классов, генеративные модели также можно использовать для задач классификации. Но цели моделирования генеративных моделей отличаются от дискриминационных моделей, которые напрямую моделируют условное распределение p (Z|X, Θ). Как и в случае с любыми статистическими моделями, обуче ние и вывод являются двумя фундаментальными проблемами, которые необходимо ре- шать при разработке и использовании генеративных моделей. Обуче ние представляет собой процесс определения параметров этих генеративных моделей на основе данных. Когда нам доступны полные данные, т. е. когда X и Z наблюдаются как пара выборок, подбор параметров часто формализуется как стандартная задача поиска максимального правдоподобия. На практике чаще встречаются неполные данные, когда наблюдается только X, а целевая переменная Z не видна в выборке данных. Это задача поиска максимального правдоподобия с неполными данными. Такая проблема нередко решается с по мощью оригинального алгоритма максимизации ожидания (expectation мaximization, EM) (Dempster et al., 1977), согласно которому E-шаг и M-шаг итеративно выполняются для максимизации правдоподобия неполных дан- ных. С точки зрения оптимизации такой итеративный процесс можно рас - сматривать как суррогатный процесс оптимизации. E-шаг, согласно наименованию, вычисляет ожидание вероятности данных по распределению скрытых или целевых переменных. Это делается путем первого выполнения шага вывода, т. е. вычисления апостериорной вероят - ности p (Z|X, Θc) с учетом текущего значения параметра Θ c. Тогда мы имеем: (5.1)\n--- Страница 262 ---\nГлубокие генеративные модели  261 Затем М-шаг максимизирует E(Θ|Θc) для получения обновленных пара - метров: (5.2) Эти два шага повторяются до сходимости. Данная итерация представляет собой суррогатный процесс максимизации ℒ(X|Θ), который монотонно не убывает. Поскольку он, очевидно, ограничен сверху, процесс гарантированно сходится. Существует байесовский EM-алгоритм на основе вероятностного вариационного анализа (Ghahramani and Beal, 2001). Действительно, М-шаг не обязательно должен полностью решать задачу максимизации. Вместо этого ему нужно только найти новый параметр Θcnew, который имеет большее зна- чение E(Θcnew|Θc), чем E(Θc|Θc). Это так называемый обобщенный EM-алгоритм. Вывод апостериорной вероятности p(Z|X, Θc) будет иметь решение в замк - нутой форме в ограниченных случаях. Например, когда приор1 (prior) p(Z) и распределение правдоподобия p(X|Z) сопряжены, то апостериорное рас - пределение будет иметь ту же форму, что и априорное. Такие сопряженные априорные значения встречаются, когда распределения ограничены сопря- женным экспоненциальным семейством (Ghahramani, Beal, 2001). Однако для более общих распределений часто бывает трудно вычислить апостериорную зависимость в замкнутой форме. Когда вывод в замкнутой форме невозможен, часто можно прибегнуть к численному решению, например используя методы Монте-Карло с цепя- ми Маркова (MCMC), наподобие выборки Гиббса, для получения выборок из этого распределения, а затем найти интеграл в уравнении (5.1) числен- но. Хинтон (Hinton, 2002) представил иной метод, а именно контрастную дивергенцию, чтобы использовать одноступенчатую выборку вместо пол- ной выборки MCMC. Это могло бы значительно ускорить процесс обуче ния с определенной гарантией сходимости. 5.4. гЛубоКие генерати Вные моде Ли Глубокие генеративные модели также нацелены на моделирование распре- деления X со скрытыми переменными Z. Принципиальное отличие от вы- шеупомянутых традиционных генеративных методов заключается в том, что вместо созданных фактически вручную моделей на основе вейвлетов и разреженного кодирования используются глубокие нейронные сети, чья способность к обуче нию намного выше. 1 Под термином приор понимается пространство гипотез (или если речь идет о ве- роятностях, то пространство вероятностей), в котором осуществляется поиск, и то, какие гипотезы из этого пространства мы предпочитаем в большей или меньшей степени, или каким исходам априорно присваиваем ту или иную вероятность. На- пример, если у нас есть исходное изображение xorig и мы ищем ближайший элемент в сгенерированном нейросетью пространстве X, то в зарубежной литературе X будет называться deep image prior. – Прим. перев.\n--- Страница 263 ---\n262  Условная генерация изображений и управляемая генерация визуальных паттернов Автокодировщик Мы начинаем знакомство с предметом с простых автокодировщиков (Wang et al., 2016). Строго говоря, они не являются типичными генеративными мо- делями, но это облегчит понимание других глубоких генеративных моделей. Как показано на рис. 5.4, автокодировщик обычно состоит из двух частей: кодировщика (энкодера, encoder) и декодера (decoder). Оба они состоят из уло- женных в стек полносвязных или сверточных слоев. Кодировщик постоянно уменьшает размерность до меньшего скрытого представления z (код), а за- тем декодер симметрично восстанавливает входное изображение из скры- того представления в исходное разрешение. Необходимо подчеркнуть, что цель автоэнкодера состоит не просто в том, чтобы восстановить исходные изображения с по мощью тривиальной функции идентификации, а в том, чтобы изучить лежащие в их основе визуальные паттерны, чтобы мы могли генерировать некоторые новые изображения из изученного скрытого про- странства. Для достижения этой цели было предложено множество вариан- тов автокодировщика. Первый и наиболее типичный – это сжимающий (или неполный) автокодировщик (Zhai et al., 2018), который требует, чтобы размер скрытого кода был значительно меньше размера входных данных. Следова- тельно, скрытый код должен быть достаточно информативным для представ- ления входного изображения, иначе потери при восстановлении будут очень большими. Второй популярный вариант – автокодировщик с шумоподавле- нием (Vincent et al., 2008), когда в обучающий набор данных преднамеренно добавляют шумы, чтобы автокодировщик научился шумоподавлению. Вмес - то изменения обучающего набора данных третий вариант – разреженный автокодировщик (Ng et al., 2011) – учитывает уровень разреженности при вычислении потерь и поощряет минимизацию количества активных единиц в кодовом слое, изучая таким образом разреженное представление набора данных. потери восстановления скрытый код Энкодер Декодер Рис. 5.4  Простая иллюстрация типичной глубокой генеративной модели автокодировщика, которая сначала кодирует входное изображение в скрытый код, а затем восстанавливает исходное изображение из скрытого кода с по- мощью декодера Вариационный автокодировщик Хотя вышеупомянутые автокодировщики могут успешно отображать обучаю- щее изображение в пространство представлений, не существует явной веро- ятностной модели, связанной с этим пространством. Следовательно, случай- ная выборка из этого пространства представлений не может гарантировать\n--- Страница 264 ---\nГлубокие генеративные модели  263 осмысленность выбора из пространства изображения при подаче выбороч- ного кода в декодер. Чтобы решить эту проблему, вариационный автокоди- ровщик (variational auto-encoder, VAE) (Doersch, 2016) заставляет изученное скрытое распределение следовать распределению Гаусса P(z). Тогда цель VAE – максимизировать вероятность (максимальное правдоподобие) каж - дого X в обучающем наборе в рамках всего генеративного процесса: (5.3) Решение интеграла (5.3) по z является нетривиальной задачей. На практи- ке для большинства z значение P(X|z) будет близко к нулю и, следовательно, почти не будет влиять на оценку P(x). Таким образом, ключевая идея VAE состоит в том, чтобы попытаться выбрать значения z, которые, вероятно, произвели X, и вычислить P(x) только для них. С этой целью вводится новая функция Q(z|X), которая принимает значение X и формирует распределение по значениям z, которые, вероятно, будут генерировать X. Учитывая, что пространство значений z при Q может быть намного меньше, чем при пред- шествующем P (z), вычисление E z∼QP(X|z) происходит относительно проще. В основе вариационных байесовских методов лежит изучение диверген- ции Кульбака–Лейблера между P(z|X) и Q(z), чтобы получить окончательную цель оптимизации. 𝒟[Q(z) || P (z|X)] = Ez~Q[logQ (z) – logP (z|X)]. (5.4) Применяя правило Байеса к P(z|X), в это уравнение можно включить и P(X), и P(X|z): 𝒟[Q(z) || P (z|X)] = Ez~Q[logQ (z) – logP (X|z) – logP (z)] + logP (X). (5.5) Так как log P(X) не зависит от z, его можно вынести из ожидания. Пере- группировав члены с обеих сторон уравнения, мы получаем: logP (X) – 𝒟[Q(z) || P (z|X)] = Ez~Q[logP (X|z)] – 𝒟[Q(z) || P (z)]. (5.6) Фактически Q может быть любым распределением, а не только распре- делением, которое хорошо отображает X в представления z, способные вос - произвести X. Поскольку конечной целью вывода является P(X), имеет смысл построить Q , которое зависит от X и делает 𝒟 [Q(z) || P (z|X)] малым: logP (X) – 𝒟[Q(z|X) || P (z|X)] = Ez~Q[logP (X|z)] – 𝒟[Q(z|X) || P (z)]. (5.7) Уравнение (5.7) является основой VAE. В частности, левая часть состоит из целевого логарифма log P(X), который мы хотим оптимизировать, плюс член ошибки, который заставляет Q создавать z, способные воспроизвести задан- ное X. Этот член ошибки становится небольшим, если Q моделируется высо- коэффективной глубокой сетью. А правая часть – это предмет оптимизации с по мощью стохастического градиентного спуска при правильном выборе Q. Фактически правая часть уравнения (5.7) принимает форму, похожую на автокодировщик, т. е. Q «кодирует» X в z, а P «декодирует» X из z .\n--- Страница 265 ---\n264  Условная генерация изображений и управляемая генерация визуальных паттернов Чтобы оптимизировать правую часть при помощи стохастического гради- ентного спуска, обычную форму Q(z|X) представляют в виде Q(z|X) = 𝒩(z|μ)(X; ϑ), Σ(X; ϑ)), где μ и Σ – произвольные детерминированные функции с парамет - рами ϑ, которые можно извлечь из данных. На практике μ и Σ снова реали- зуются через нейронные сети, и Σ ограничивается диагональной матрицей. Градиент первого члена в правой части уравнения оценивается путем вы- борки различных значений X из набора данных D и одного важного «трюка перепараметризации», как изображено на рис. 5.5. Вход Х Энкодер Q Декодер Рμ(X) μ(X)Σ(X) Σ(X)Вход Х Энкодер QДекодер РОбразец z из N(μ(X), Σ(X)) f(z) f(z) Образец ϵ из N(0, I)подмена параметров Рис. 5.5  «Трюк перепараметризации», используемый в вариаци- онном автокодировщике для аппроксимации стохастического гради- ента во время обуче ния Во время тестирования, если нужно сгенерировать новые образцы изобра- жения, VAE случайным образом выбирает представления z ~ 𝒩 (0, I) и вводит их в декодер. То есть в данном случае кодировщик со всеми его операциями умножения и сложения полностью отсутствует. Для получения более под- робной информации мы рекомендуем читателям ознакомиться с работами Дорша (Doersch, 2016). Генеративно-состязательная сеть В последние годы широкую популярность приобрели генеративно-состя- зательные сети (generative adversarial networks, GAN), предложенные в но- ваторской работе Гудфеллоу и др. (Goodfellow et al., 2014). По сравнению с предыдущими генеративными моделями, здесь ключевая идея состоит в том, чтобы ввести вспомогательную сеть дискриминатора, помогающую в обучении целевой генеративной сети. Другой ключевой идеей является стратегия обуче ния противника, как показано на рис. 5.6, т. е. сеть дискри- минатора учится различать, взята ли выборка из реального распределения данных или создана генерирующей сетью, в то время как генерирующая сеть пытается генерировать все более реалистичные изображения, чтобы обма- нуть сеть дискриминатора. Таким образом, эти две сети – генератор и дис - криминатор – состязаются друг с другом в игре с нулевой суммой. Математически это можно рассматривать как задачу минимаксной опти- мизации с функцией ценности V (G, D):\n--- Страница 266 ---\nГлубокие генеративные модели  265 (5.8) где D(x) представляет собой вероятность того, что x исходит из реального распределения данных, а не из сгенерированного G(z). Подобно VAE, pz(z) представляет собой приор, из которого следует производить выборку и ко- торый может быть задан как нормальное распределение. Во время обуче ния и вывода случайно выбранное представление z передают в G для создания изображения. На практике G и D обучают альтернативным способом, т. е. сперва обучают G при неизменном D, затем обучают D при неизменном G. После обуче ния сеть дискриминатора отключают, и для создания новых изо- бражений применяется только G. Генератор GДискриминатор DРеальные изображения шумСгенерированные изображенияПодлинник/Имитация Рис. 5.6  Состязательное обуче ние генеративно-состязательных сетей: сеть-дискриминатор пытается научиться отличать реальное входное изобра- жение от сгенерированного сетью-генератором, в то время как сеть-генератор пытается создавать более реалистичные изображения, чтобы обмануть сеть- дискриминатор По сути, в процессе обуче ния G пытается достичь реального распределения данных, как показано на рис. 5.7. В идеальном случае, когда G может точно имитировать реальное распределение данных, D не в состоянии отличить сгенерированное изображение от реального, т. е. классифицирует изображе- ние как настоящее/поддельное с вероятностью случайного угадывания 0,5. Несмотря на громкий успех, обуче ние хорошей модели GAN оказывается не таким уж простым делом. За последнее время было предложено много вариантов улучшения качества и надежности GAN (Mirza, Osindero, 2014; Chen et al., 2016; Metz et al., 2016; Arjovsky et al., 2017; Bao et al., 2017). Более полное обобщение можно найти в (Wang et al., 2019). Рис. 5.7  Идеальная эволюция обуче ния генеративно-состязательных сетей. Зеленая линия – реальное распределение данных, синяя линия – распределе- ние данных генеративной сети, а красная пунктирная линия – граница разделе- ния выводов дискриминатора. В идеальном случае (последний столбец), когда генерирующая сеть научилась полностью имитировать реальное распределе- ние, сеть дискриминатора не может различить реальное и сгенерированное распределения данных\n--- Страница 267 ---\n266  Условная генерация изображений и управляемая генерация визуальных паттернов 5.5. гЛубоКая усЛоВная генерация изображений Генеративные модели, о которых было сказано в предыдущих разделах, предназначены для безусловной генерации изображений, т. е. новые изобра- жения генерируются на основе случайных кодированных представлений, выбранных из приора без каких-либо условий. Другими словами, происхо- дит неуправляемый синтез визуальных паттернов. Напротив, в этой главе мы сосредоточимся на том, как добиться управляемого синтеза визуальных паттернов путем условной генерации изображений. В отличие от безусловной генерации изображений, условная генерация (Isola et al., 2017; Zhu et al., 2017; Chen et al., 2017, 2020) накладывает на про- цесс генерации дополнительные входные условия. Эта методика охватыва- ет широкий спектр проблем компьютерного зрения, таких как переход от контуров к изображению (Isola et al., 2017), перенос стиля (Gatys et al., 2015; Chen et al., 2018), раскрашивание изображений (He et al., 2018), управляемая обработка изображений (Fan et al., 2018, 2019; Chen et al., 2020), восстанов- ление изображений (Wan et al., 2020), семантический синтез (Tan et al. al., 2020) и синтез и редактирование лиц (Tan et al., 2020). Как показано на рис. 5.8, при заданных входных условиях, таких как текс - товое описание, векторы атрибутов и изображения, условные генеративные модели нацелены на создание выходного изображения, удовлетворяющего условиям. Но, как и в случае безусловной генерации изображений, изучение и моделирование внутренних визуальных паттернов по-прежнему являет - ся важным фактором, определяющим качество генерации. Благодаря более эффективному моделированию визуальных паттернов генерация условного изображения, по сути, представляет собой процесс выборки и рекомпозиции ограниченного паттерна. условная генеративная модель«рисунок женщины » или иливолнистые волосы, лицо в профиль Рис. 5.8  Иллюстрация типичной схемы генерации условного изображения. Исходя из входных условий, таких как текстовое описание, атрибуты или изо- бражения, условная генеративная модель должна генерировать выходное изо- бражение, соответствующее условным требованиям Тем не менее композиция естественных изображений включает в себя множество визуальных искажений, таких как положение (поза), освещение и форма. Чтобы побудить генеративную модель лучше изучить лежащий в основе паттерн, применяется разделение (иногда говорят «распутывание») в скрытом пространстве встраивания, которое является ключевым принци- пом проектирования и широко используется во многих существующих ме- тодах генерации условных изображений (Yan et al., 2016; Chen et al., 2017b;\n--- Страница 268 ---\nРазделенные представления в управляемом синтезе паттернов  267 Бао и др., 2018; Ма и др., 2018). Но реализация разделения – нетривиальная задача. Фактически показано (Locatello et al., 2019), что теоретически невоз- можно добиться обучаемого без учителя разделения без индуктивных пред- посылок как в моделях, так и в наборах данных. Поэтому часто приходится разрабатывать специальную структуру сети и рецепт обуче ния с учителем, частичного привлечения учителя или самообучения. 5.6. разде Ленные предста ВЛения В упра ВЛяемом синтезе паттерно В Далее мы хотим представить три примера того, как можно ввести индук - тивную предпосылку в изучение разделенных представлений при глубокой условной генерации изображений, применяемой в управляемом синтезе ви- зуальных паттернов. Исследуемые нами области применения включают пе- ренос стиля (раздел 5.6.1), создание изображений по описанию (раздел 5.6.2) и синтез лица с сохранением привязки к личности (раздел 5.6.3). 5.6.1. Разделение визуального содержания и стиля Перенос стиля (Gatys et al., 2015; Johnson et al., 2016; Chen et al., 2020) – ти- пичная задача создания условного изображения. Как показано на рис. 5.9, речь идет о переносе стиля изображения-источника на изображение- приемник с другим контентом при сохранении исходной семантической структуры приемника. Основные задачи, которые приходится решать при переносе стиля, заключаются в моделировании визуальных паттернов изо- бражения-источника стиля и разделении содержимого и стиля изображе- ния-приемника. Перенос стиля как таковой сводится к повторной выборке изученного паттерна стиля в соответствии с ограничением структуры кон- тента. Исходное изображение Источник стиля Стилизованное изображение Рис. 5.9  Иллюстрация переноса стиля. Перенос представляет собой визуализацию изображения-приемника в соответствии со стилем изобра- жения-источника при сохранении исходной структуры приемника. Ис - точник: Chen et al., 2020\n--- Страница 269 ---\n268  Условная генерация изображений и управляемая генерация визуальных паттернов После новаторской работы Леона Гэтиса (Gatys et al., 2015) перенос стиля с использованием сверточных нейронных сетей вызвал волну интереса как в академических кругах, так и в промышленности. В своем исследовании Гэтис и его коллеги оригинально применили предварительно обученную сверточную нейросеть для разложения изображения на компоненты кон- тента и стиля. В частности, они рассматривают корреляционные матрицы Грамма откликов признаков в разных слоях как иерархическое представле- ние стиля. Путем последующего сопоставления структуры контента одного изображения с его ответом на высокоуровневый признак они моделируют перенос стиля как проблему оптимизации, т. е. поиск сгенерированного изо - бражения, которое имеет такие же грам-матрицы признаков, как источник стиля, и аналогичные высокоуровневые свойства содержимого, как изобра- жение-приемник. Этот метод, основанный на оптимизации, может дать очень впечатляющие результаты стилизации и намного лучше, чем тради- ционные методы. Однако генерация занимает очень много времени из-за процесса оптимизации, что накладывает большие ограничения на реальные приложения. Для ускорения процесса генерации были предложены различные методы, основанные на сетях прямого распространения и аппроксимирующие опи- санную выше процедуру оптимизации (Johnson et al., 2016; Ulyanov et al., 2016). При таком подходе результаты стилизации могут быть получены путем непосредственной подачи контента изображения в сеть прямого распростра- нения; следовательно, это намного быстрее, чем в методах, основанных на оптимизации. Однако такие сети с прямым распространением обучаются по принципу «черного ящика», а компоненты контента и стиля (визуальные паттерны) в обученных сетях сильно связаны. Это не только не позволяет нам изучить явное представление стиля или контента, но и делает такие сети способными одновременно фиксировать только определенный стиль. Исходя из этих соображений, Чен и др. (Chen et al., 2017) разработали новую разделенную сетевую структуру для изучения явного представления каждого стиля управляемым образом, что, естественно, поддерживает пере- нос нескольких стилей. Это соответствует концепции текстона в классиче- ском синтезе текстуры, и мы предлагаем использовать последовательности банков фильтров для представления изображений разных стилей. Все каналы в одном банке фильтров можно рассматривать как основы стилевых эле- ментов, таких как узор текстуры и штрихи, в одном источнике стиля. Затем выполняется процесс стилизации путем свертки соответствующих банков фильтров с картами признаков контента, что аналогично операции свертки между текстоном и дельта-функцией в пространстве изображения для син- теза текстуры (как показано на рис. 5.11). Разделение стиля и контента Фреймворк разделения на ветви детально изображен на рис. 5.10. По сути, он состоит из трех частей: одного общего кодировщика ℰ, слоя банка стилей 𝒦 и одного общего декодера 𝒟. Чтобы заставить сеть явным образом раз- делить контент и стиль, мы создаем две обучающие ветви – реконструкции ℰ ® 𝒟 и стилизации ℰ ® 𝒦 ® 𝒟. Входное изображение I, которое является\n--- Страница 270 ---\nРазделенные представления в управляемом синтезе паттернов  269 источником контента, сначала преобразуется в пространство признаков F с использованием подсети кодировщика. Затем F по ветви восстановления напрямую передается в генератор изображения O = 𝒟(F), которое должно быть как можно ближе к входу I. Параллельно при переносе стиля i на I мы сворачиваем соответствующий банк фильтров 𝒦i с F, а затем вводим пре- образованный признак F˜i(F˜i = F ⊗ 𝒦i) в 𝒟 для получения стилизованного результата Oi = 𝒟(F˜i). Вышеуказанные две ветви обучаются разными способа - ми, и соответственно разрабатываются разные функции потерь. Рассмотрим этот момент подробнее. Простая потеря MSE (mean square error, среднеквад- ратичная ошибка) между входным изображением I и O рассматривается как потеря отображения личности ℒ ℐ для ветви восстановления: ℒℐ(I, O) = ||O – I||2. (5.9) Изображение IКодировщик ℰ Декодер 𝒟 ℒ𝒦 ℒℐ Карты признаков FК1… … Кi Кn F˜Слой банка стилей 𝒦Стилизо- ванные О Восстанов- ленное О Рис. 5.10  Структура переноса разделенного стиля, предложенная в работе (Chen et al., 2017), которая состоит из одной ветви восстановления (внизу) и од- ной ветви стилизации (вверху). Контент предназначен для кодирования в вет - ке кодировщика и декодера, а стиль представлен набором банков фильтров в слое банка стилей. Источник: Chen et al. (2017) В ветви стилизации, в соответствии с целевой функцией в работе (Johnson et al., 2016), в качестве потери стилизации ℒ𝒦 используются потеря контента ℒc, потеря стиля ℒ s и потеря регуляризации ℒ tv(Oi): ℒ𝒦(I, 𝒮i, Oi) = αℒc(Oi, I) + βℒs(Oi, 𝒮i) + γℒtv(Oi), (5.10) где I, 𝒮i, Oi – входной источник контента, источник стиля и результат стилиза- ции (для i-го стиля) соответственно. ℒtv(Oi) – регуляризатор полной вариации, используемый в работе (Johnson et al., 2016) для поощрения гладкости. И ℒc, и ℒ s используют одинаковое определение, приведенное в (Gatys et al., 2015): (5.11) Здесь Fl и G – карта объектов l-го слоя предварительно обученной сети VGG-16 и соответствующая матрица Грама, вычисленная из F . {lc}, {ls} – это слои VGG-16, используемые для вычисления потери контента и потери сти-\n--- Страница 271 ---\n270  Условная генерация изображений и управляемая генерация визуальных паттернов ля. Поскольку ветвь восстановления предназначена для реконструкции ис - ходного изображения контента, она гарантирует, что никакая информация о стиле не будет поглощена кодировщиком E и декодером 𝒟. В то же время, чтобы достичь желаемого стиля в ветви стилизации, вся информация о стиле принудительно передается в промежуточный слой банка стилей. Таким об- разом, контент и стиль явно отделены друг от друга. Рис. 5.11  Процесс синтеза текстуры можно рассматривать как операцию свертки между изображением текстона и дельта-функцией в пространстве изо- бражения, что побуждает нас выполнить передачу стиля в пространстве призна- ков путем свертки признака контента с соответствующим банком фильтров стиля Результаты многостилевого переноса Благодаря описанной выше раздельной схеме с двумя ветвями один стиль кодируется в одном конкретном наборе сверточных фильтров, и в одной сети можно одновременно изучать несколько стилей. Это более удобно для прак - тического применения, чем предыдущие методы с одним стилем, которые обычно обучают одну независимую сеть для каждого стиля. Во время логи- ческого вывода для применения одного определенного стиля выбирается и применяется соответствующий набор фильтров. Как показано на рис. 5.12, разные стили очень хорошо разделены, и соответствующие результаты сти- лизации состоят только из их собственных паттернов стилей. контент: стиль: результат: Рис. 5.12  Результаты применения нескольких разных стилей, которые одно- временно изучены в одной сети. Видно, что разные стили хорошо разделены (каждый результат стилизации состоит только из собственных паттернов сти- лей) и изучены в соответствующих банках фильтров. Источник: Chen et al. (2017)\n--- Страница 272 ---\nРазделенные представления в управляемом синтезе паттернов  271 Восстановление элементов стиля Чтобы лучше понять, как слой банка стилей представляет визуальный пат - терн каждого стилевого изображения, на примере рис. 5.13 показано вос - становление элементов стиля из изученного банка фильтров. В частности, в результате стилизации выбираются два типа патчей: штрих (красная рам- ка) и текстура (зеленая рамка). ⊗cin coutkk (a) (b) (c) (d) (e) (f) (g) (i) (j) Рис. 5.13  Восстановление элементов стиля для двух патчей в примере стилизованного изображения. Источник: Chen et al. (2017) Во-первых, все остальные области, кроме соответствующих положений выбранных участков, маскируются, как показано на (c, d), а распределение признаков этих участков визуализировано на (e). Можно заметить, что такие характерные отклики распределены редко, и отдельные пиковые отклики возникают лишь в некоторых каналах. Затем в операции преобразования признаков учитываются только не - нулевые каналы признаков и соответствующие каналы набора фильтров. Преобразованные признаки, наконец, передаются декодеру для получения восстановленных элементов стиля (g), которые визуально похожи на пат - чи исходного стиля в (i) и патч стилизации в (j). Исходя из этого, мы мо- жем предположить, что различные взвешенные комбинации каналов банка фильт ров могут формировать разнообразные элементы стиля в одном изо- бражении-источнике. Чтобы понять, сколько различных элементов стиля изучается для каждого изображения стиля, мы берем большое шумовое изображение для аппрокси- мации распределения патчей контента и предоставляем сети возможность отображать различные патчи контента с разными элементами стиля. На рис. 5.14 видно, что стилизующая сеть изучила набор репрезентативных элементов для каждого изображения-источника стиля. Рис. 5.14  Визуализация изученных сетью элементов стиля: для каждого слу- чая левый элемент – это изображение-источник стиля, а два правых – резуль- таты стилизации путем подачи двух разных шумовых изображений. Источник: Chen et al. (2020)\n--- Страница 273 ---\n272  Условная генерация изображений и управляемая генерация визуальных паттернов Важность разделения на две ветви Чтобы показать, что наличие автокодировщика не приводит к утрате инфор- мации о стиле, а разделение на ветви имеет большое значение, был проведен еще один эксперимент путем удаления ветви восстановления на этапе обуче- ния. При наличии одного входного изображения для вывода результата вос - становления используются только кодер и декодер. Как показано на рис. 5.15, без ветви реконструкции на этапе обуче ния декодированное изображение (в центре) не может восстановить исходное входное изображение (слева), но, по-видимому, несет некоторую информацию о стиле. Для сравнения, когда используется ветвь восстановления, декодированное изображение идеаль- но реконструирует входное изображение и очень похоже на него. Другими словами, в предложенной схеме с двумя ветвями вся информация о контенте сосредоточена только в части кодера и декодера, а информацию о стиле сле- дует изучать на промежуточном уровне банка стилей. Рис. 5.15  Результат реконструкции изображения в механизме кодер–деко- дер с ветвью восстановления (справа) и без этой ветви (в центре) на этапе обуче ния. Очевидно, что наличие ветви восстановления помогает гарантиро- вать, что информация о стиле не будет утрачена на этапе кодера и декодера, а реконструкция будет практически идеальной. Источник: Chen et al. (2017) Преимущества разделения Разделение контента и стиля может принести множество дополнительных преимуществ. Во-первых, это быстрое поэтапное обуче ние. В частности, что- бы включить новый стиль, нам не нужно переобучать всю сеть, что час то занимает много времени. Вместо этого, располагая обученной сетью с не- сколькими стилями, нам нужно только переобучить банк фильтров для вновь добавленного стиля, сохраняя при этом неизменные части кодировщика и декодера. Этот процесс сходится очень быстро, так как необходимо обучить только часть банка нового стиля. На практике это часто занимает всего не- сколько минут, что в десятки раз быстрее, чем переобучение всей сети. Как показано на рис. 5.16, частичное обуче ние может дать результаты стилиза- ции, сравнимые с результатами полного переобучения всей сети с новыми стилями. Второе преимущество заключается в возможности слияния стилей двумя разными способами: линейное слияние и слияние в зависимости от области. В случае линейного слияния, поскольку разные стили кодируются в разных банках фильтров {K i1, …, Kim}, мы можем линейно объединять несколько сти-\n--- Страница 274 ---\nРазделенные представления в управляемом синтезе паттернов  273 лей, объединяя банки фильтров в cлой банка стилей. Затем объединенный банк фильтров используется для свертки с признаком контента F : (5.12) где m – количество стилей, Ki – банк фильтров стиля i. Затем F˜ передается декодеру для получения окончательного результата стилизации. На рис. 5.17 показаны результаты такого линейного слияния двух разных стилей с раз- ным весом слияния w i. Рис. 5.16  Разделение обеспечивает быстрое частичное изучение новых сти- лей. Для каждого случая слева и справа показаны результаты стилизации после дополнительного частичного обуче ния и нового обуче ния соответственно. Ис - точник: Chen et al. (2017) Рис. 5.17  Результаты стилизации линейной комбинацией двух наборов сти- левых фильтров. Назначая разные веса слияния, мы соответствующим образом меняем пропорции каждого стиля. Источник: Chen et al. (2017) Для слияния стилей в зависимости от конкретных областей предположим, что изображение разложено на n непересекающихся областей в пространстве признаков, а Mi обозначает маску каждой области, тогда карты признаков можно описать как и слияние стилей для конкретной об- ласти можно сформулировать следующим образом: . (5.13) На рис. 5.18 показаны результаты слияния двух стилей для конкретных областей. Левый случай заимствует стили двух известных картин Пикассо и Ван Гога, а два правых стиля оба принадлежат Ван Гогу.\n--- Страница 275 ---\n274  Условная генерация изображений и управляемая генерация визуальных паттернов Рис. 5.18  Результаты слияния стилей в зависимости от области путем при- менения разных банков фильтров к разным областям изображения. Две левые картины принадлежат Пикассо и Ван Гогу соответственно, а две правые принад- лежат Ван Гогу. Источник: Chen et al. (2020) 5.6.2. Разделение структуры и стиля В отличие от описанной выше задачи переноса стиля, в которой семанти- ческая структура контента и элементы стиля непосредственно определя- ются контентом и стилем входного изображения, в общем случае синтеза изображения более сложно добиться мелкомодульного разделения. Напри- мер, в классическом методе StackGAN преобразования текста в изображе- ние (Zhang et al., 2017) мы можем выбирать только стили в целом, вводя текстовые описания, но не можем добиться детального контроля как над структурой, так и над стилями. Здесь под структурой мы подразумеваем в первую очередь семантическую форму и позу, а стили обозначают мелкие визуальные паттерны/текстуры. Для устранения упомянутого ограничения разработана новая каскадная генеративная модель FusedGAN, разделяющая структуры и стили методом частичного обуче ния с учителем (Bodla et al., 2018). Общая идея FusedGAN показана на рис. 5.19. Фактически здесь объединяются безусловная GAN для создания структуры приора и условная GAN для соответствия условию стиля из текстового описания. Ключевая идея проста: например, если вы хотите нарисовать птицу, наиболее очевидный подход – сначала набросать контур птицы с определенной позой и формой (создание структуры), а затем доба- вить детали мелкомодульной текстуры (наложение стиля). Слитный блок GAN GAN FusedGAN Рис. 5.19  Простая иллюстрация ключевой идеи FusedGAN, которая объединяет безусловную GAN и условную GAN. Источник: Bodla et al. (2018)\n--- Страница 276 ---\nРазделенные представления в управляемом синтезе паттернов  275 Разделение путем использования общей структуры приора На основе вышеупомянутых принципов разработана изображенная на рис. 5.20 сквозная разделенная обучаемая структура, где синие и оранже- вые блоки соответствуют безусловной и условной ветвям генерации изо- бражений соответственно. В частности, безусловная ветвь состоит из сети генератора G1 и сети дискриминатора Du, которые обучаются таким же состя- зательным способом, как и другие модели GAN. Чтобы обеспечить структуру для условной ветви генерации, сеть G1 разбита на два модуля: Gs и G u. Модуль Gs принимает вектор случайного шума z в качестве входных данных и после серии операций свертки и восстановления исходного разрешения (unsam- pling) генерирует приор Ms. Затем приор структуры Ms передается в Gu для создания конечного изображения после еще одной серии операций свертки и восстановления исходного разрешения. Генератор G s(z, θ s)Генератор G u(Ms, θu) Генератор G с(My, Ms, θc)Дискриминатор Du(x, θ du) Дискриминатор Dc(x, y, θ dc) (xreal, y)y(xfake, y)xreal Ms Ms Myxfake Кодировщик Е(y, θ e)z ~ N(0, I) Рис. 5.20  Разделенная структура FusedGAN, где синие и оранжевые блоки представляют собой безусловный и условный конвейеры генерации изображе- ний соответственно. Источник: Bodla et al. (2018) В отличие от традиционной структуры условной генерации, которая часто принимает одно условие и один вектор случайного шума в качестве входных данных, сеть условного генератора Gc в FusedGAN вместо этого в качестве входных данных принимает приор Ms и вектор условия My. То есть ветвь безусловной генерации и ветвь условной генерации до Ms имеют одну и ту же структуру. Чтобы способствовать разделению структуры и стиля, ветви безуслов ной и условной генераций используют разные обучающие наборы данных, т. е. неразмеченный набор данных для G1 и набор данных, поме- ченный условными описаниями для Gc. Для разных задач вектор состояния My может иметь разный формат. Например, в задаче преобразования текста в изображение исходное текстовое описание сначала кодируется в пред - ставление y, а затем подается в кодировщик E для создания нового тензора условий My, как показано на рис. 5.20. Обратите внимание, что для получе- ния разнообразных результатов выполняется условное дополнение выборки скрытого вектора cˆ из независимого гауссова распределения N(μ(y), Σ(y)) вокруг представления текста, а затем cˆ пространственно повторяется до со- впадения с пространственным измерением M s для создания M y.\n--- Страница 277 ---\n276  Условная генерация изображений и управляемая генерация визуальных паттернов Чтобы направлять обуче ние безусловной и условной ветвей генерации, дискриминатор Du принимает в качестве входных данных сгенерирован- ное изображение xuf от Gu или реальное изображение xr и пытается понять, является оно реальным или поддельным, в то время как дискриминатор Dc принимает в качестве входных данных сгенерированное изображение xcf от Gc или реальное изображение xr и соответствующее условие, чтобы гаранти- ровать, что Gc генерирует изображения, соответствующие условию. На этапе обуче ния эти два конвейера обучаются порознь сквозным способом. Пара- метры модели обновляются путем оптимизации комбинированных целей GAN и CGAN, т. е. ℒGu = logD u(Gu(z)), ℒ Du = logD u(x), ℒ Dc = logD c(x, y); ℒGc = logD c(Gc(My, Ms), y) + λDKL(N(μ(y), Σ(y) || N (0, I), (5.14) где z – выборочный вектор шума из нормального распределения N(0, I). Под- водя итог, можно сказать, что ключевой принцип разделения в этой работе заключается в использовании общего приора, но обучении двух ветвей с раз- ными целями. Во время логического вывода для генерации условного изображения сна- чала берется случайная выборка z, которая проходит через Gs для создания приора Ms. Затем Ms расходится на два пути – один ведет через генератор Gu для создания безусловного изображения xuf. На втором пути входное тек - стовое описание подается в кодировщик E и извлекает выборку из гауссова распределения вокруг представления текста. Выходные данные E и Ms объ - единяются и прогоняются через Gc для создания условного изображения xcf. Другими словами, на одном этапе вывода синтезируются два изображения: искомое условное изображение xcf и безусловное изображение xuf – факти- чески побочный продукт модели, который помогает анализировать и лучше понимать предложенную модель и результаты. Результаты синтеза Глядя на результаты синтеза на рис. 5.21, можно убедиться, что структура и стиль хорошо разделены. В левой части последняя строка отображает ре- зультаты безусловной генерации, а другие строки показывают результаты условной генерации с использованием того же структурного приора. Видно, что Ms способен успешно фиксировать и переводить значительный объем информации о строении птицы в результаты условного синтеза на основе различных текстовых описаний. Используя неизменный структурный приор, также легко удается проводить интерполяцию между различными стилями. Для этого текстовые фрагменты t1 и t2 подаются в E для получения двух вы- борок из соответствующих им распределений Гаусса. Затем путем линейной интерполяции между ними выбираются восемь однородных отсчетов, так что первый отсчет соответствует t1, а последний – t2. Как показано в правой части рис. 5.21, эффект управляемой плавной интерполяции стилей вполне достижим.\n--- Страница 278 ---\nРазделенные представления в управляемом синтезе паттернов  277 Маленькая разноцветная птичка с ярко-синими перьями, покрывающими большую часть тела, за исключением черного хвостаЭта птица с ярко-желтым брюшком и оранжевыми перьями на хвосте и спинеУ этой птицы коричневые крылья и белое тело СтруктураСтильЭта птица полностью красная, с черными крыльями и заостренным клювомУ этой птицы ярко-желтое тело с коричневым на макушке и крыльях Рис. 5.21  Синтезированные результаты FusedGAN. Левая часть представля- ет собой результаты синтеза различных стилей (строки) и структур (столбцы), а правая – результаты управляемой интерполяции различных стилей при фик - сированной структуре. Источник: Bodla et al. (2018) На рис. 5.22 дополнительно показаны результаты синтеза различных сти- лей с разным количеством мелких деталей. В частности, конкретное опи- сание текстуры сначала загружается в E, а затем из гауссова распределения вокруг представления текста извлекаются пять выборок. Каждое текстовое описание может управлять результатами синтеза различных мелких деталей, используя один и тот же приор. Например, если взять второй ряд в левой части, хотя все птицы красные с черным крылом, у них разное количество черного на крыльях и длина хвоста. Рис. 5.22  Синтезированные результаты различных стилей с по мощью FusedGAN с разным количеством мелких деталей. Источник: Bodla et al. (2018) 5.6.3. Разделение личности и атрибутов Третья значимая работа (Bao et al., 2018) посвящена типичной задаче гене- рации условного изображения «синтез лиц с сохранением личности». Мы имеем одно входное изображение Iid определенной личности и одно входное изображение I a для извлечения атрибутов, а задача заключается в создании нового высококачественного изображения лица I¢, которое относится к той же личности, что и Iid, но заимствует атрибуты Ia. Здесь атрибуты включа-\n--- Страница 279 ---\n278  Условная генерация изображений и управляемая генерация визуальных паттернов ют, помимо прочего, позу, эмоции, цвет кожи и фон. Это очень сложная за- дача, особенно когда соответствующая личность для лица не представлена в обучающем наборе, и основная проблема заключается в том, как разде- лить визуальные паттерны, связанные с личностью (например, форму носа и глаз), и визуальные паттерны, связанные с атрибутами (например, цвет кожи и форму рта при разных эмоциях). Для решения этой проблемы было предложено множество схожих методов, таких как TP-GAN (Huang et al., 2017) и FF-GAN (Yin et al., 2017), которые мо- гут синтезировать фронтальный вид данного изображения лица и DR-GAN (Tran et al., 2017), который может синтезировать различные положения лица. Однако они часто полагаются на полную аннотацию атрибутов, а список под- держиваемых типов атрибутов ограничен. Для сравнения, модель CVAEGAN (Bao et al., 2017) поддерживает различные изменения атрибутов, но не может синтезировать идентичное лицо вне набора обучающих данных. Чтобы обеспечить большое разнообразие изменений атрибутов и откры- тых идентификаторов, была разработана новая схема разделенного синтеза лиц, изображенная на рис. 5.23 (Bao et al., 2018). Она содержит пять под- сетей: сеть кодировщика личности E, сеть кодировщика атрибутов A, сеть генеративного синтеза G, вспомогательную сеть классификации C и сеть дискриминатора D. Функция сети кодировщика личности E и сети атри- бутов A заключается в извлечении вектора личности fE(Iid) из Iid и векто- ра атрибутов fA(Ia) из Ia соответственно. Путем рекомбинации fE(Iid) и fA(Ia) сеть G генерирует новое изображение I¢, которое соответствует личности Iid и атрибутам Ia. Вспомогательные сети C и D используются только во время обуче ния. В частности, C нужна для того, чтобы изображение I¢ отражало ту же личность, что и Iid, а сеть D побуждает G генерировать изображения более высокого качества, различая сгенерированное и реальное изображения в со- стязательном обучении. Идентичность Iid fE(Iid) fА(Iа)LI LKL LGRLC/LGC LD/LGDРезультат I¢ Атрибуты IaСинтез лица E АG DС Рис. 5.23  Общая схема синтеза лица с сохранением личности, которая от - деляет личность и атрибуты от входных изображений лица. Новое лицо I¢ ге- нерируется путем рекомбинации информации о личности Iid и атрибутивной информации I a. Источник: Bao et al. (2018) Разделение Несмотря на то что приведенный выше фреймворк основан на разделении, его обуче ние не является тривиальной задачей, потому что большинство\n--- Страница 280 ---\nРазделенные представления в управляемом синтезе паттернов  279 существующих наборов данных лиц имеют только аннотацию личности, но не аннотацию атрибутов. На самом деле иногда даже невозможно точно аннотировать некоторые атрибуты, например передний план и фон. Наше исследование посвящено разделению путем извлечения представления лич- ности при помощи обуче ния с учителем и представления атрибутов при по- мощи обуче ния без учителя. В частности, чтобы извлечь представление личности, кодировщик E фор- мулируется как сеть распознавания лиц и обучается с по мощью потери soft - max на помеченном наборе данных лиц {I i, yi}, где yi – метка личности изобра- жения Ii. Во время обуче ния, чтобы различать разных людей, E обуча ется представлять сходные признаки для изображений с одинаковыми идентифи- каторами и разные признаки для изображений с разными идентификатора- ми. Отклик последнего пулингового слоя E принимается в качестве вектора личности I id. Для получения представления атрибута разработана простая и эффектив- ная стратегия обуче ния, использующая потерю реконструкции и потерю расхождения KL. В частности, во время обуче ния Iid и I a выбираются случай- ным образом, поэтому могут относиться к одному и тому же или к разным изображениям. В обоих случаях для реконструкции изображения атрибута Ia требуется результирующее изображение I ¢, но с разными весами потерь. Формально потеря реконструкции равна (5.15) где λ – вес потерь при реконструкции для случая Is ≠ Ia. В частности, когда изображение личности Iid совпадает с изображением атрибута Ia, синтези- рованное изображение I должно быть таким же, как Iid или Ia. Поскольку для каждой личности в обучающем наборе есть много изображений лиц Ia, их вектор личности для этих изображений почти одинаков, и единственное возможное различие будет заключаться в векторе атрибутов. Следователь- но, требование, чтобы реконструированные изображения были такими же, как эти разные изображения лиц, вынуждает сеть A кодировщика атрибу - тов правильно выучить различные представления атрибутов. В случае когда изображение личности Iid и изображение атрибута Ia различны, хотя трудно точно предсказать, как должен выглядеть реконструированный результат, мы можем ожидать, что реконструкция будет приблизительно аналогична изображению атрибута Ia, например в отношении фона, общего освещения и позы. Следовательно, для сохранения атрибутов потере реконструкции ис - ходного пикселя назначается относительно небольшой вес (λ = 0,1). Помимо вышеупомянутой потери реконструкции, дополнительно исполь- зуется потеря расхождения KL для регуляризации вектора атрибутов с со- ответствующим приором P(z) ∼ N(0, 1). Это ограничивает вектор атрибута, чтобы он не содержал чрезмерного количества информации о личности, и помогает сети кодировщика атрибутов изучить лучшее представление. Для\n--- Страница 281 ---\n280  Условная генерация изображений и управляемая генерация визуальных паттернов заданного входного изображения лица, которое служит источником атрибу - та, сеть A выведет среднее значение μ и ковариацию скрытого вектора. Тогда потеря расхождения KL определяется следующим образом: (5.16) Во время обуче ния используется прием репараметризации для выборки вектора атрибутов с использованием z = μ + r ⊙ exp(ϵ ), где r ∼ N(0, I) – слу - чайный вектор, а ⊙ представляет поэлементное умножение. Асимметричная настройка После извлечения вектора личности fI(Iid) и вектора атрибутов fA(Ia) выпол- няется их конкатенация в скрытом пространстве z¢ = [fI(Iid), fA(Ia)] и результат передается в сеть G для синтеза нового изображения лица. Подобно обычным GAN, генерирующая сеть G играет в минимаксную игру для двух игроков с дискриминаторной сетью D, т. е. D пытается отличить реальные настроеч- ные данные от синтезированных данных, в то время как G пытается обмануть сеть D . Конкретно, сеть D пытается минимизировать функцию потерь (5.17) Однако если сеть G напрямую пытается максимизировать D как тради- ционная GAN, процесс обуче ния будет нестабильным. Это связано с тем, что на практике распределения «настоящих» и «поддельных» изображений могут не пересекаться друг с другом, особенно на раннем этапе настройки. Следовательно, дискриминаторная сеть D может идеально их разделить, что вызовет исчезновение градиента. Чтобы решить эту проблему, для обуче - ния генератора используется потеря сопоставления парных признаков, как в CVAE-GAN. В частности, если предположить, что fD(·)– это признаки про- межуточных слоев D, потери сопоставления парных признаков определяются следующим образом: (5.18) То есть эта потеря максимально сближает признаки реального и сгене- рированного изображений. По умолчанию выходной признак последнего полносвязного слоя D используется как f D. Точно так же для достижения цели сохранения личности (I ¢ относится к той же личности, что и Iid) используется аналогичная потеря сопоставления пар- ных признаков, чтобы заставить I¢ и Iid иметь аналогичные представления признаков в сети классификации лиц C : (5.19) Здесь вход последнего полносвязного уровня сети C используется как при- знак fC. На практике сеть C и сеть E имеют общие параметры и инициализи-\n--- Страница 282 ---\nРазделенные представления в управляемом синтезе паттернов  281 руются предварительно обученной сетью классификации лиц для ускорения сходимости. Стратегия обучения без учителя Синтез лиц для личностей, которые отсутствуют в обучающем наборе, явля- ется сложной задачей, поскольку требуется, чтобы генеративная сеть охваты- вала как внутриличностные (intraperson), так и межличностные (interperson) вариации. Существующие общедоступные наборы данных с помеченными личностями часто имеют ограниченный размер и не содержат экстремаль- ных поз или освещения, поэтому мы собрали из Flickr и Google один миллион изображений лиц с большими вариациями и разнообразием. Затем мы про- вели обуче ние без учителя, чтобы помочь обученному генератору обобщить ранее не встречавшиеся личности. В частности, собранные неразмеченные изображения можно использовать либо в качестве изображения личности Iid, либо в качестве изображения атрибутов I a. При использовании изобра- жения в качестве источника атрибута Ia весь процесс обуче ния остается не- изменным. При использовании в качестве источника личности Iid, поскольку изображения не имеют метки класса, они не участвуют в обучении E и C. Эмпирически мы обнаружили, что эти неразмеченные данные могут увели- чить внутриклассовые и межклассовые различия в распределении лиц, тем самым улучшая разнообразие синтезированных лиц, например внося более значительные изменения в позы и выражения. Результаты синтеза Для демонстрации эффективности описанного выше фреймворка раздельно- го синтеза лиц на рис. 5.24 и 5.25 изображены результаты синтеза, в котором используются изображения, чьи личности как встречаются, так и не встре- чаются в обучающем наборе соответственно. Результаты свидетельствуют о том, что обученная сеть может отделить компоненты личности и атрибутов и очень хорошо изучить соответствующие визуальные паттерны как для за- крытых, так и для открытых наборов данных. (a) идентичность (c) результаты преобразования (b) атрибуты Рис. 5.24  Результаты синтеза лиц с сохранением личности с использова- нием изображений, чьи личности присутствуют в обучающем наборе данных. Видно, что предложенный метод может хорошо разделять визуальные паттер- ны, связанные с идентификацией и атрибутами, а затем перекомпоновывать их в окончательные результаты. Источник: Bao et al. (2018)\n--- Страница 283 ---\n282  Условная генерация изображений и управляемая генерация визуальных паттернов Разделение также обеспечивает непрерывное изменение атрибутов в сге- нерированных изображениях путем настройки скрытого вектора, так назы- ваемого морфинга атрибутов. В частности, для пары изображений Ia1 и Ia2 сеть атрибутов A сначала используется для извлечения их векторов атрибу - тов za1 и za2 соответственно, а затем с по мощью линейной интерполяции мо- жет быть получен ряд векторов атрибутов z, т. е. z = αza1 + (1 – α)za2, α Î [0, 1]. На рис. 5.26 представлены результаты морфинга атрибутов лица, где путем выбора подходящей пары изображений-источников атрибутов постепенно изменяются положение, эмоции или освещение. (a) идентичность (c) результаты преобразования (b) атрибуты Рис. 5.25  Результаты синтеза лиц с сохранением личности с использовани- ем изображений, личности которых не появляются в обучающем наборе дан- ных, что демонстрирует сильную способность к обобщению. Источник: Bao et al. (2018) (а) идентичности (d) атрибуты(b) атрибуты (c) результаты морфинга Рис. 5.26  Результаты морфинга лица с использованием невидимых иден- тичностей между двумя атрибутами с точки зрения позы, эмоций и изменения освещения соответственно. Источник: Bao et al. (2018) Применение синтеза Приложения проверки лиц на основе глубокой сети широко используют - ся в системах наблюдения и контроля доступа. Располагая изображениями двух лиц, предварительно обученная модель классификации лиц сначала извлекает их признаки. Затем, если расстояние между признаками меньше порогового значения, два лица рассматриваются как относящиеся к одной и той же личности. Тем не менее недавние исследования показывают, что\n--- Страница 284 ---\nРазделенные представления в управляемом синтезе паттернов  283 глубокие нейронные сети уязвимы для злонамеренных имитаций, которые обманывают сеть, добавляя определенные малозаметные возмущения к ис - ходным изображениям. В частности, предположив, что два лица I1 и I2 от- носятся к разным личностям, мы можем подобрать незаметные возмущения r таким образом, что вышеупомянутой системой проверки лиц I1 + r будет рассматриваться как лицо, совпадающее с I 2. Этот процесс часто формулируется как задача оптимизации: min||r ||22 так, что ||f C(I1 + r) – fC(I2)||22 < τ, (5.20) где fC – признак, извлеченный из предварительно обученной сети, а τ – за - данный порог. На рис. 5.27 (a) и (c) – два входа I1 и I 2, а (b) – сгенерированное враждебное изображение I1 + r. Несмотря на то что враждебные изображения имеют сходные признаки с другими лицами, если мы реконструируем изображение из признака с использованием предложенного фреймворка, это даст нам изображение совершенно другого человека (e). Очевидно, что враждебное изображение и его реконструкция явно различаются. Основываясь на этом наблюдении, описанный выше фреймворк можно использовать для обнару - жения враждебных изображений путем сравнения личностей на исходных изображениях и результатов реконструкции. (a) (b) (c) (d) (e) (f) Рис. 5.27  Обнаружение враждебных образцов в системах проверки лиц: (а) исходное изображение, (b) является враждебным образцом, который на- правлен на то, чтобы ввести сеть проверки в заблуждение относительно лич- ности, показанной в (c). (d), (e) и (f) – результаты реконструкции, выполненной нашим фреймворком. Они показывают, что хотя враждебный образец выглядит так же, как и исходное изображение, результаты реконструкции выглядят по- разному. Источник: Bao et al. (2018) Взяв в качестве примера набор данных LFW, для каждой из 3000 пар раз- личных личностей мы сгенерировали два враждебных изображения путем генерации ложных изображений друг друга, что дает в сумме 6000 враж - дебных изображений. Здесь используются четыре разных порога τ : [0,4, 0,6, 0,8, 1]. При этом у нас есть 6000 исходных изображений и их реконструк - ций. Затем признак LBP входного изображения и его реконструированное изображение извлекаются и объединяются вместе. Наконец, линейный SVM обучается как бинарный классификатор. Результаты показаны в табл. 5.1. Если расстояние между признаками меньше 0,4, можно достичь точности обнаружения 92,41 %.\n--- Страница 285 ---\n284  Условная генерация изображений и управляемая генерация визуальных паттернов Таблица 5.1. Точность обнаружения враждебных изображений при различных порогах расстояния между признаками Порог 1,0 0,8 0,6 0,4 Точность, % 76,73 82,58 87,18 92,41 5.7. заКЛюЧение Изучение и моделирование визуальных паттернов являются фундаменталь- ной основой визуального интеллекта. С помощью безусловной или условной структуры генерации изображений глубокие генеративные модели пытают - ся восстановить низкоразмерную структуру целевых визуальных моделей в пространстве представлений. В этой главе мы обсудили, как использовать глубокие генеративные модели для достижения более управляемого синтеза визуальных паттернов посредством создания условного изображения. Мы утверждаем, что ключом к достижению такого управляемого синтеза пат - тернов является разделение визуального представления, когда различные управляющие факторы тем или иным способом разделяют в скрытом про- странстве представлений. Затем на примере трех исследований мы проде- монстрировали, как добиться разделения для синтеза паттернов при обуче- нии без учителя или со слабым обуче нием путем введения индуктивной предпосылки с точки зрения структуры сети и стратегии обуче ния. В классических генеративных моделях зачастую различные смешанные факторы явно моделируются как взаимодействующие случайные процессы. Этот вид явного моделирования не был хорошо изучен в глубоких генера- тивных моделях. Возможно, было бы полезно изучить, как мы можем ввести такие явные и структурированные представления в обуче ние глубоких гене- ративных сетей, что может привести к более объяснимым глубоким моделям. Литературные исто ЧниКи Arjovsky M., Chintala S., Bottou L., 2017. Wasserstein gan. arXiv preprint. arXiv: 1701.07875. Bao J., Chen D., Wen F., Li H., Hua G., 2017. Cvae-gan: fine-grained image genera- tion through asymmetric training. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 2745–2754. Bao J., Chen D., Wen F., Li H., Hua G., 2018. Towards open-set identity preserving face synthesis. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 6713–6722. Besag J., 1974. Spatial interaction and the statistical analysis of lattice systems. Journal of the Royal Statistical Society, Series B, Methodological 36, 192–225. Blake A., Zisserman A., 1987. Visual Reconstruction. MIT Press. Bodla N., Hua G., Chellappa R., 2018. Semi-supervised fusedgan for conditional image generation. In: Proceedings of the European Conference on Computer Vision (ECCV), pp. 669–683.\n--- Страница 286 ---\nЛитературные источники  285 Chen D., Liao J., Yuan L., Yu N., Hua G., 2017a. Coherent online video style trans- fer. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 1105–1114. Chen D., Yuan L., Liao J., Yu N., Hua G., 2017b. Stylebank: an explicit representa- tion for neural image style transfer. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1897–1906. Chen D., Yuan L., Liao J., Yu N., Hua G., 2018. Stereoscopic neural style transfer. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Rec - ognition, pp. 6654–6663. Chen D., Fan Q., Liao J., Aviles-Rivero A., Yuan L., Yu N., Hua G., 2020a. Controllable image processing via adaptive filterbank pyramid. IEEE Transactions on Image Processing 29, 8043–8054. Chen D., Yuan L., Hua G., 2020b. Deep style transfer. Computer Vision: A Refe- rence Guide, 1–8. Chen D., Yuan L., Liao J., Yu N., Hua G., 2020c. Explicit filterbank learning for neural image style transfer and image processing. IEEE Transactions on Pattern Analysis and Machine Intelligence. Chen X., Duan Y., Houthooft R., Schulman J., Sutskever I., Abbeel P., 2016. Info- gan: interpretable representation learning by information maximizing genera- tive adversarial nets. In: Advances in Neural Information Processing Systems, pp. 2172–2180. Cooper D. B., 1979. Maximum likelihood estimation of Markov-process blob boundaries in noisy images. IEEE Transactions on Pattern Analysis and Ma- chine Intelligence, 372–384. Cross G. R., Jain A. K., 1983. Markov random field texture models. IEEE Transac - tions on Pattern Analysis and Machine Intelligence, 25–39. Dempster A. P., Laird N. M., Rubin D. B., 1977. Maximum likelihood from incom- plete data via the em algorithm. Journal of the Royal Statistical Society, Series B, Methodological 39, 1–38. Do M. N., Vetterli M., 2003. The finite ridgelet transform for image representation. IEEE Transactions on Image Processing 12, 16–28. Doersch C., 2016. Tutorial on variational autoencoders. arXiv preprint. arXiv: 1606.05908. Fan Q., Chen D., Yuan L., Hua G., Yu N., Chen B., 2018. Decouple learning for pa- rameterized image operators. In: Proceedings of the European Conference on Computer Vision (ECCV), pp. 442–458. Fan Q., Chen D., Yuan L., Hua G., Yu N., Chen B., 2019. A general decoupled learning framework for parameterized image operators. IEEE Transactions on Pattern Analysis and Machine Intelligence. Fu K. S., 1982. Syntactic Pattern Recognition. Prentice-Hall. Gatys L. A., Ecker A. S., Bethge M., 2015. A neural algorithm of artistic style. arXiv preprint. arXiv:1508.06576. Geman S., Geman D., 1984. Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. IEEE Transactions on Pattern Analysis and Machine Intelligence, 721–741. Ghahramani Z., Beal M. J., 2001. Graphical models and variational methods. In: Graphical Models and Variational Methods. In: Neural Information Processing Series. MIT Press, Cambridge, MA.\n--- Страница 287 ---\n286  Условная генерация изображений и управляемая генерация визуальных паттернов Girshick R., 2015. Fast r-cnn. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 1440–1448. Goodfellow I., Pouget-Abadie J., Mirza M., Xu B., Warde-Farley D., Ozair S., Courville A., Bengio Y., 2014. Generative adversarial nets. In: Advances in Neural Infor - mation Processing Systems, pp. 2672–2680. Grenander U., 1976, 1976–1981. Lectures in pattern theory i, ii and iii. Guo C. E., Zhu S. C., Wu Y. N., 2003. Modeling visual patterns by integrating de- scriptive and generative methods. International Journal of Computer Vision 53, 5–29. He K., Zhang X., Ren S., Sun J., 2016. Deep residual learning for image recogni- tion. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770–778. He M., Chen D., Liao J., Sander P. V., Yuan L., 2018. Deep exemplar-based coloriza- tion. ACM Transactions on Graphics (TOG) 37, 1–16. Hinton G. E., 2002. Training products of experts by minimizing contrastive diver - gence. Neural Computation 14, 1771–1800. Hoyer P. O., Hyvärinen A., 2002. A multi-layer sparse coding network learns con- tour coding from natural images. Vision Research 42, 1593–1605. Hua G., 2020. Deep generative models. In: Computer Vision: a Reference Guide. Springer. Huang R., Zhang S., Li T., He R., 2017. Beyond face rotation: global and local per - ception gan for photorealistic and identity preserving frontal view synthesis. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 2439–2448. Hyvärinen A., 1999. Survey on independent component analysis. Hyvärinen A., Oja E., 2000. Independent component analysis: algorithms and ap- plications. Neural Networks 13, 411–430. Isola P., Zhu J. Y., Zhou T., Efros A. A., 2017. Image-to-image translation with conditional adversarial networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1125–1134. Johnson J., Alahi A., Fei-Fei L., 2016. Perceptual losses for real-time style transfer and super-resolution. In: European Conference on Computer Vision. Springer, pp. 694–711. Kambhatla N., Leen T. K., 1997. Dimension reduction by local principal component analysis. Neural Computation 9, 1493–1516. Kingma D. P., Welling M., 2014. Auto-encoding variational Bayes. In: Bengio, Y., LeCun, Y. (Eds.), Interactional Conference on Learning Representation. http:// dblp.uni-trier.de/db/conf/iclr/iclr2014.html#KingmaW13. Kong H., Wang L., Teoh E. K., Li X., Wang J. G., Venkateswarlu R., 2005. Generalized 2d principal component analysis for face image representation and recognition. Neural Networks 18, 585–594. Lee A. B., Mumford D., Huang J., 2001. Occlusion models for natural images: a sta- tistical study of a scale-invariant dead leaves model. International Journal of Computer Vision 41, 35–59. Liu D., Hua G., Chen T., 2010. A hierarchical visual model for video object sum- marization. IEEE Transactions on Pattern Analysis and Machine Intelligence 32, 2178–2190.\n--- Страница 288 ---\nЛитературные источники  287 Locatello F., Bauer S., Lucic M., Rätsch G., Gelly S., Schölkopf B., Bachem O., 2019. Challenging common assumptions in the unsupervised learning of disentan- gled representations. In: Proc. of the 36th International Conference on Machine Learning. Long Beach, CA. Lu X., Katz A., Kanterakis E., Li Y., Zhang Y., Caviris N., 1992. Image analysis via optical wavelet transform. Optics Communications 92, 337–345. Ma L., Sun Q., Georgoulis S., Van Gool L., Schiele B., Fritz M., 2018. Disentangled person image generation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 99–108. Manat S., Zhang Z., 1993. Matching pursuit in a time-frequency dictionary. IEEE Transactions on Signal Processing 12, 3397–3451. Metz L., Poole B., Pfau D., Sohl-Dickstein J., 2016. Unrolled generative adversarial networks. arXiv preprint. arXiv: 1611.02163. Mirza M., Osindero S., 2014. Conditional generative adversarial nets. arXiv pre- print. arXiv:1411.1784. Mumford D. B., Shah J., 1989. Optimal approximations by piecewise smooth func - tions and associated variational problems. Communications on Pure and Ap- plied Mathematics. Ng A., et al., 2011. Sparse Autoencoder. CS294A. Lecture Notes, vol. 72, pp. 1–19. Poggio T., Torre V., Koch C., 1985. Computational vision and regularization theory. Nature 317, 314–319. Ren S., He K., Girshick R., Sun J. , 2015. Faster r-cnn: towards real-time object detection with region proposal networks. In: Advances in Neural Information Processing Systems, pp. 91–99. Roweis S., Ghahramani Z., 1999. A unifying review of linear Gaussian models. Neural Computation 11, 305–345. Shackleton M., 1994. Learned deformable templates for object recognition. In: IEE Colloquium on Genetic Algorithms in Image Processing and Vision, IET, p. 7. Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., 2015. Going deeper with convolutions. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1–9. Tan Z., Chai M., Chen D., Liao J., Chu Q., Yuan L., Tulyakov S., Yu N., 2020a. Michi- gan: multi-input-conditioned hair image generation for portrait editing. ACM Transactions on Graphics (TOG) 39, 95. Tan Z., Chen D., Chu Q., Chai M., Liao J., He M., Yuan L., Hua G., Yu N., 2020b. Semantic image synthesis via efficient class-adaptive normalization. arXiv preprint. arXiv:2012.04644. Terzopoulos D., 1983. Multilevel computational processes for visual surface recon- struction. Computer Vision, Graphics, and Image Processing 24, 52–96. Tran L., Yin X., Liu X., 2017. Disentangled representation learning gan for pose- invariant face recognition. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1415–1424. Ulyanov D., Lebedev V., Vedaldi A., Lempitsky V. S., 2016. Texture networks: feed- forward synthesis of textures and stylized images. In: ICML, p. 4. Van de Wouwer G., Scheunders P., Van Dyck D., 1999. Statistical texture charac - terization from discrete wavelet representations. IEEE Transactions on Image Processing 8, 592–598.\n--- Страница 289 ---\n288  Условная генерация изображений и управляемая генерация визуальных паттернов Van den Oord A., Kalchbrenner N., Espeholt L., Vinyals O., Graves A., et al., 2016. Conditional image generation with pixelcnn decoders. In: Advances in Neural Information Processing Systems, pp. 4790–4798. Vincent P., Larochelle H., Bengio Y., Manzagol P. A., 2008. Extracting and com- posing robust features with denoising autoencoders. In: Proceedings of the 25th International Conference on Machine Learning, pp. 1096–1103. Wan Z., Zhang B., Chen D., Zhang P., Chen D., Liao J., Wen F., 2020a. Bringing old photos back to life. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2747–2757. Wan Z., Zhang B., Chen D., Zhang P., Chen D., Liao J., Wen F., 2020b. Old photo restoration via deep latent space translation. arXiv preprint. arXiv:2009.07047. Wang Y., Yao H., Zhao S., 2016. Auto-encoder based dimensionality reduction. Neurocomputing 184, 232–242. Wang Z., She Q., Ward T. E., 2019. Generative adversarial networks in computer vision: a survey and taxonomy. arXiv preprint. arXiv:1906.01529. Weng J., Weng C., Yuan J., Liu Z., 2018. Discriminative spatio-temporal pattern discovery for 3d action recognition. IEEE Transactions on Circuits and Systems for Video Technology 29, 1077–1089. Xie X., Sudhakar R., Zhuang H., 1994. On improving eye feature extraction using deformable templates. Pattern Recognition 27, 791–799. Yan X., Yang J., Sohn K., Lee H., 2016. Attribute2image: conditional image gen- eration from visual attributes. In: European Conference on Computer Vision. Springer, pp. 776–791. Yin X., Yu X., Sohn K., Liu X., Chandraker M., 2017. Towards large-pose face fron- talization in the wild. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 3990–3999. Yuan J., 2011. Discovering Visual Patterns in Image and Video Data: Concepts, Algorithms, Experiments Paperback. VDM Verlag Dr. Müller. Yuille A. L., 1991. Deformable templates for face recognition. Journal of Cognitive Neuroscience 3, 59–70. Zhai J., Zhang S., Chen J., He Q., 2018. Autoencoder and its various variants. In: 2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC). IEEE, pp. 415–419. Zhang H., Xu T., Li H., Zhang S., Wang X., Huang X., Metaxas D. N., 2017. Stackgan: text to photo-realistic image synthesis with stacked generative adversarial networks. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 5907–5915. Zhao G., Yuan J., Hua G., 2013. Topical video object discovery from key frames by modeling word co-occurrence prior. In: Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR’2013). Portland, OR. Zhu J. Y., Park T., Isola P., Efros A. A., 2017. Unpaired image-to-image translation using cycle-consistent adversarial networks. In: Proceedings of the IEEE Inter - national Conference on Computer Vision, pp. 2223–2232. Zhu S. C., 2003. Statistical modeling and conceptualization of visual patterns. IEEE Transactions on Pattern Analysis and Machine Intelligence 25, 691–712. Zhu S. C., Wu Y., Mumford D., 1998. Filters, random fields and maximum entropy (frame): towards a unified theory for texture modeling. International Journal of Computer Vision 27, 107–126.",
      "debug": {
        "start_page": 255,
        "end_page": 289
      }
    },
    {
      "name": "Глава 6. Глубокое распознавание лиц с использованием полных и частичных изображений 289",
      "content": "--- Страница 290 --- (продолжение)\nГлава 6 Глубокое распознавание лиц с использованием полных и частичных изображений Автор главы: Хассан Угайл, Центр визуальных вычислений, Университет Брэдфорда, Брэдфорд, Великобритания Краткое содержание главы: методы и практические приемы определения, обуче ния и тестирования модели на основе глубокого обуче ния; примеры использования моделей на основе глубокого обуче ния для рас - познавания лиц по полному и частичному изображениям; современное положение дел в области распознавания лиц, а также проб- лемы с глубоким обуче нием, помогающим распознавать лица. 6.1. В Ведение Распознавание лиц – одно из самых захватывающих и известных приложений глубокого обуче ния, применяемых в области визуальных вычислений. Оно не только демонстрирует мощь глубокого обуче ния, но и выявляет некото- рые проблемы, связанные с использованием нейросетевых моделей в виде черного ящика. Решение этих проблем окажет прямое влияние на нашу по- вседневную жизнь. Компьютерное распознавание лиц по-прежнему сопряжено со многими проблемами, которые не свойственны человеческому восприятию. Челове- ку часто бывает достаточно увидеть кого-то лишь мельком, чтобы навсегда запомнить его лицо (Young, Burton, 2018). Так получается потому, что мозг моментально выделяет и запоминает важные детали, касающиеся человека.\nГлава 6 Глубокое распознавание лиц с использованием полных и частичных изображений Автор главы: Хассан Угайл, Центр визуальных вычислений, Университет Брэдфорда, Брэдфорд, Великобритания Краткое содержание главы: методы и практические приемы определения, обуче ния и тестирования модели на основе глубокого обуче ния; примеры использования моделей на основе глубокого обуче ния для рас - познавания лиц по полному и частичному изображениям; современное положение дел в области распознавания лиц, а также проб- лемы с глубоким обуче нием, помогающим распознавать лица. 6.1. В Ведение Распознавание лиц – одно из самых захватывающих и известных приложений глубокого обуче ния, применяемых в области визуальных вычислений. Оно не только демонстрирует мощь глубокого обуче ния, но и выявляет некото- рые проблемы, связанные с использованием нейросетевых моделей в виде черного ящика. Решение этих проблем окажет прямое влияние на нашу по- вседневную жизнь. Компьютерное распознавание лиц по-прежнему сопряжено со многими проблемами, которые не свойственны человеческому восприятию. Челове- ку часто бывает достаточно увидеть кого-то лишь мельком, чтобы навсегда запомнить его лицо (Young, Burton, 2018). Так получается потому, что мозг моментально выделяет и запоминает важные детали, касающиеся человека.\n--- Страница 291 ---\n290  Глубокое распознавание лиц с использованием полных и частичных изображений Затем, когда знакомое лицо предстает в различных контекстах, мозг легко и быстро сопоставляет изображения «до» и «после» без потребности в какой- либо значимой новой информации. А когда речь идет о компьютерном зре- нии, малейшие изменения внешнего вида лица могут существенно ухудшить способность идентифицировать человека. В компьютерном зрении существует множество алгоритмов машинно- го обуче ния, специально разработанных для применения в распознавании лиц. Эти алгоритмы представляют собой методы, основанные на обучении без учителя или, наоборот, использующие обуче ние с учителем и основан- ные на идее, что кто-то может выбрать часть данных с известными мет - ками (предоставленными оператором) или передать алгоритму в качестве обучаю щего набора. Например, анализ главных компонент (principal compo- nent analysis, PCA) был изобретен еще в 19051 г., а сегодня фактически пре- вратился в модель машинного обуче ния без учителя, широко используемую для уменьшения размерности сложных данных и сжатия изображений (Jol- liffe, 2002). Также широко распространен метод кодирования лиц в наборе данных в «пространстве лица». В 1991 году для построения алгоритмов рас - познавания лиц был предложен базовый алгоритм Eigenface (Turk, Pentland, 1991). Этот алгоритм извлекает наиболее важные детали данных в виде соб- ственных векторов2, соответствующих наибольшим собственным значениям, представляющим изменения в пространстве лица. В области распознавания лиц наиболее интересна концепция усредненного лица (average faсe), и в не- котором смысле она лежит в основе распознавания человеческих лиц. Попыт - ки использовать усредненное лицо в качестве инструмента компьютерного распознавания лиц часто встречаются в научных публикациях, например (Elmahmudi, Ugail, 2019). Также широко используется метод локальных бинар- ных шаблонов (local binary pattern, LBP), который представляет собой прос - той, но мощный подход к классификации текстур. Согласно этому методу изображение делят на разные области, чтобы извлечь признаки из каждой области отдельно. Эти признаки впоследствии используются для облегчения классификации в задачах распознавания лиц (Kas et al., 2020). В обычных вычислениях данный алгоритм представляет собой группу явно запрограммированных команд, используемых машиной для решения задачи. Подходы машинного обуче ния позволяют обучать алгоритмы с ис - пользованием входных данных и использовать статистический анализ для вывода значений, попадающих в определенную область. Иными словами, машинное обуче ние позволяет компьютерам создавать модели из примеров, автоматизируя процесс принятия решений на основе ввода данных. Глубокое обуче ние (LeCun et al., 2015) – это механизм, с по мощью которого машинный алгоритм может обучаться на образцах данных. Он направлен на получение оптимальной конфигурации модели, позволяющей получать из набора входных данных желаемые результаты. Обученные модели широко 1 По другим данным, метод главных компонент был изобретен Карлом Пирсоном в 1901 г. – Прим. перев. 2 Понятия собственного вектора и собственного значения были введены в разде- ле 1.6.4. – Прим. перев.\n--- Страница 292 ---\nВведение  291 применяются для решения сложных задач обработки и анализа изображе- ний. В результате глубокое обуче ние, вероятно, стало стандартом де-факто в современных системах распознавания лиц. До эпохи глубокого обуче ния большая часть алгоритмов распознавания лиц была основана на методах обработки изображений, содержащих только два или три уровня вычислений, таких как фильтрация, гистограммы и ко- дирование признаков. У этих методов был общий существенный недоста- ток – они решали только один аспект проблемы распознавания лиц за счет других. Например, хотя метод фильтрации Габора (Dora et al., 2017) может улучшить распознавание лиц при различных условиях освещения, этот же метод плохо работает с разными выражениями и ракурсами лица. Поэтому исследователи пытались отыскать последовательный и целостный метод для решения большинства проблем, мешающих распознаванию лиц. Революционный прорыв произошел в 2012 году, когда было убедительно показано, что глубокое обуче ние способно решить многие проблемы, с кото- рыми в то время сталкивалось компьютерное распознавание лиц. В то время модель глубокого обуче ния AlexNet выиграла конкурс ImageNet, продемон- стрировав, что она стабильно и с большим отрывом опережает конкурентов в распознавании изображений. С тех пор глубокое обуче ние движется по восходящей траектории и приближается к уровню человеческой способно- сти распознавания лиц. Например, в 2014 году набор данных DeepFace на маркированных лицах в дикой природе (LFW) показал, что он может достичь точности на уровне человека, точные цифры составляют 97,35 % для DeepFace и 97,533 % для людей (Taigman et al., 2014). 6.1.1. Модели глубокого обучения Глубокое обуче ние направлено на эмуляцию и изучение сложных структур, скрытых в наборах данных с использованием нескольких обучающих сло- ев функциональных единиц (нейронов). Этот подход имитирует строение и работу нервной системы человека. Модели глубокого обуче ния изучают закономерности в очень сложных данных с по мощью последовательностей из нескольких искусственных нейронов, манипулируя параметрами меж - нейронных связей для достижения желаемого результата. Поэтому модель глубокого обуче ния состоит из нейронной сети с несколькими скрытыми слоями. Она предназначена для имитации принятия решений человеком при решении сложных задач распознавания. На практике модели глубокого обуче ния обычно принимают форму сверточных нейронных сетей (CNN) (LeCun et al., 2015). Структура CNN По сути, CNN представляет собой набор отдельных персептронов (искус - ственных нейронов), образующих сеть нейронов, соединенных между со- бой для обеспечения параллельной обработки сигналов в распределенной сетевой структуре. Для управления взаимодействием между персептронами используются настраиваемые веса. Ключевым компонентом CNN являются\n--- Страница 293 ---\n292  Глубокое распознавание лиц с использованием полных и частичных изображений скрытые слои, которые размещаются между входом и выходом сети. Скры- тые слои позволяют присваивать нелинейные веса входным данным и от - правлять результаты на выход, т. е. применять нелинейные математические функции к определенным частям сети для получения желаемого конечного результата. Например, в случае задачи распознавания лиц один скрытый слой можно настроить для идентификации цветов входного изображения, другой – для идентификации физических признаков и т. д. Сеть, состоящая из этих слоев, может затем распознать и классифицировать лицо на входном изображении. Типичная CNN состоит из нескольких слоев, которые можно разделить на три широкие категории. Это слои свертки (convolution, CONV), субдискрети- зации, или пулинга (pooling, POOL), и полносвязные слои (fully connected, FC). Обычно комбинация этих слоев устроена определенным образом с един- ственной целью преобразования входных данных сети в полезное представ- ление, которое дает выходной прогноз, как показано на рис. 6.1. Свертка RELU пулинг Свертка RELU пулинг ПолносвязныйПолносвязный Выходные прогнозы Рис. 6.1  CNN состоит из нескольких слоев, включая слои свертки, пулинга и полностью связанные слои Слой свертки получил свое название от математического оператора сверт - ки. Этот слой вычисляет скалярное произведение между весами нейронов и небольшой областью входного пространства. Нейроны организованы в виде набора двумерных фильтров, или ядер, расширяющих размерность входных данных. Следовательно, они имеют трехмерную структуру. Во время прямого прохода каждое ядро сворачивается по ширине и высоте входного\n--- Страница 294 ---\nВведение  293 пространства для создания двумерной карты признаков (feature map), как показано на рис. 6.2. Эти карты признаков являются выходными данными операции свертки при каждой пространственной операции. По сравнению с нейронной сетью с прямым распространением, эти фильтры представляют собой нейроны, которые активируются, когда они сталкиваются с визуаль- ными признаками, такими как края объекта. Как обсуждалось ранее, CNN используют локальную связь для уменьшения сложности. Следовательно, каждый нейрон связан с локальной областью, пространственный размер которой определяется размером фильтра, известным как рецептивное поле нейрона, а ее глубина равна глубине входных данных. (1×1) + (0×0) + (1×1) + (0×0) + (0×1) + (2×0) + (0×1) + (2×0) + (0×1) = 2 Рис. 6.2  Иллюстрация операции свертки. Во время прямого прохода каждое ядро сворачивается по ширине и высоте входного пространства для создания 2D-карты признаков Следовательно, в случае входного изображения 256×256×3 и рецептив- ного поля 3×3 каждый нейрон в слое CONV будет иметь в общей сложности 3×3×3 = 27 связей и 1 параметр смещения. Очевидно, что связность является пространственно локальной, но полной по входной глубине. Впоследствии размер карты признаков (то есть выходных данных) вычисляется с использо- ванием трех гиперпараметров – глубины (depth), паддинга (padding) и страйда (stride). Глубина соответствует числу развернутых фильтров. Чем больше фильтров, тем больше объем извлекаемой информации, поскольку каждый фильтр учится искать определенный признак. Страйд S определяет шаблон, используемый для перемещения фильтра по входным данным, т. е. S = 1 означает, что фильтр должен перемещаться на один пиксель за раз. Паддинг определяет количество нулевых пикселей, размещенных вокруг входного пространства, чтобы сохранить постоянный пространственный размер вы- вода. Можно вычислить пространственный размер вывода, используя урав- нение\n--- Страница 295 ---\n294  Глубокое распознавание лиц с использованием полных и частичных изображений (6.1) где I – пространственный размер входных данных, F – размер фильтра, P – заполнение нулями (паддинг), а S – страйд (Dumoulin and Visin, 2018). Следовательно, если взять входное изображение размера 224×224×3 и пред- положить, что нейроны имеют рецептивное поле размером 3×3, глубину K = 64, одиночный страйд S = 1 и паддинг P = 1, получаем (224 – 3 + 2)/1 + 1 = 224. Это означает, что вывод этого конкретного слоя CONV будет иметь размер 224×224×64. Следовательно, слой должен состоять из 224×224×64 = 3 211 264 нейронов, каждый из которых имеет 3×3×3 = 27 весов и 1 смещение. Интересно, что вместо 3 211 264 × 27 весов и 3 211 264 смещений благодаря концепции общих весов (weight sharing) все нейроны на одном срезе могут иметь одинаковый вес и смещение. Следовательно, количество весов и сме- щений резко сокращается до 1728 и 64 соответственно. Как упоминалось ранее, в нейронных сетях функция активации играет важ - ную роль в привнесении нелинейности в выходной сигнал нейрона. Введение этой нелинейности делает нейронную сеть универсальным аппроксиматором функций, тем самым давая ей возможность справляться с различными типами отношений. Наиболее эффективной и часто используемой функцией актива- ции для CNN является спрямленный линейный блок (ReLU). Он представляет собой поэлементное применение нулевой пороговой функции f(x) = max(0, x), где x – вход нейрона. По сравнению с другими функциями активации, CNN с ReLU обучаются в несколько раз быстрее. Это связано с простотой вычисле- ния функции ReLU и ее градиента. Обратите внимание, что слой активации не получает на входе дополнительные параметры. Кроме того, он не меняет размерность ввода. В архитектуре сети слои активации размещаются после каждого слоя CONV. Кроме того, они также развертываются в сетях с более чем одним полносвязным слоем, за исключением последнего такого слоя. Слои пулинга обычно вставляются между последовательными слоями свертки. Их основная функция состоит в том, чтобы последовательно со- кращать количество параметров и, следовательно, уменьшать вычислитель- ную сложность сети за счет уменьшения пространственного размера карт признаков. Слои пулинга суммируют выходные данные соседних нейронов. Для каждого 2D-среза карты признаков наиболее часто применяется так на- зываемый max-пулинг (maximum pooling), который обычно берет максимум каждой области 2×2, таким образом отбрасывая 75 % активаций, как показа- но на рис. 6.3 (Gholamalinezhad, Khosravi, 2020). Таким образом, операция пулинга не вводит новых параметров. Наоборот, она приводит к сокращению первого и второго измерений карты признаков. Операция принимает два параметра: страйд S и пространственное измере- ние F. Следовательно, операция пулинга уменьшает размер карты признаков с размеров W 1×H1×D до W 2×H2×D. Здесь W 2 и H 2 вычисляются по следующим формулам: (6.2)\n--- Страница 296 ---\nВведение  295 7 7 49 149 2 06 020 5 2 01 6 0 0max-пулинг Рис. 6.3  Слой пулинга в действии. Пулинг помогает уменьшить количество параметров и, следовательно, снизить вычислительную сложность сети Интересно, что эта операция вводит трансляционную инвариантность по отношению к упругим искажениям. Полносвязный слой FC имеет нейроны, которые полностью связаны с активацией предыдущего слоя, и, в отличие от слоев CONV и POOL, слой FC является двумерным. Обычно полносвязные слои выполняют вывод предсказанных сетью меток/классов. Следовательно, FC обычно является последним уровнем сети. В работе, победившей в кон- курсе ImageNet Large Scale Visual Recognition Competition (ILSVRC) 2012 г. (Krizhevsky et al., 2012), использовались три слоя FC, и с тех пор это является типичным решением. Достаточно очевидно, что сведение трехмерных карт признаков в конце вычислений дает нам возможность интерпретировать изученные пространственно-инвариантные признаки. Наиболее обычная схема, используемая исследователями, начинается со слоя ввода изображения и заканчивается слоем FC (решение), между ними находятся повторяющиеся стеки слоев CONV-ReLU, за которыми следуют слои POOL, а затем несколько слоев FC-ReLU. Эту многослойную структуру можно описать математически: ВХОД ⇒ NM( CONV ⇒ ReLU) ⇒ POOL ⇒ K(FC ⇒ ReLU) ⇒ FC, (6.3) где N, M и K – положительные вещественные параметры. Обычно количество слоев CONV-ReLU, которые размещены перед POOL, находится в диапазоне 0 < N < 4, а число комбинаций переменных M и K больше 1. Методы обучения CNN Существует три основных способа развертывания CNN: обуче ние сети с нуля, точная настройка существующей модели или использование готовых при- знаков CNN. Последние два подхода называются переносом обуче ния, или трансферным обуче нием (transfer learning). Поскольку обуче ние CNN с нуля с использованием алгоритма обратного распространения предполагает авто - матическое изучение миллионов параметров, этот подход требует огромного количества данных и, как следствие, нуждается в большой вычислительной мощности. Кроме того, процедура включает в себя настройку нескольких гиперпараметров. Поэтому на практике сеть редко обучают с нуля. Точная настройка включает перенос весов первых n слоев, полученных из исходной (опорной) сети, в целевую сеть, а затем завершение обуче ния с ис - пользованием нового набора данных. Таким образом, целевая сеть обучается\n--- Страница 297 ---\n296  Глубокое распознавание лиц с использованием полных и частичных изображений с использованием нового набора данных для конкретной задачи, обычно отличной от задачи исходной сети. Точная настройка обычно использует - ся, когда новый набор данных умеренно велик (от десятков до сотен тысяч обучаю щих размеченных образцов) и сильно отличается от набора данных, используемого для обуче ния исходной сети. Использование весов исходной сети для инициализации помогает алгоритму обратного распространения, что приводит к относительно быстрому автоматическому обуче нию более конкретным признакам. В ситуациях, когда набор данных довольно мал, скажем несколько сотен, даже точная настройка весов может привести к переобучению. Однако, по- скольку CNN эффективно изучают общие признаки изображения, можно на- прямую использовать обученную сеть в качестве средства извлечения фикси - рованных признаков. Следовательно, признаки из новых данных извлекаются путем проецирования их на активации определенного слоя предварительно обученной сети. После этого изученные представления передаются в простые классификаторы для решения поставленной задачи. Этот подход, известный как извлечение готовых признаков (off-the-shelf feature extraction), принес многообещающие результаты (Weiss et al., 2016; Day and Khoshgoftaar, 2017). Самый простой способ борьбы с проблемой переобучения, с которой стал- киваются глубокие нейронные сети, – это увеличение объема обучающих данных (дополнение данных, data augmentation). Обычно дополнение данных реализуют путем искусственного увеличения размера набора данных с по- мощью различных методов, таких как изменение ориентации изображения путем отражения (что создает зеркальное изображение) и поворот исходных изображений, что впоследствии сеть рассматривает как новые изображения. Этот прием гарантирует, что алгоритм обуче ния выведет признаки из дан- ных с разной ориентацией. Наборы данных для экспериментов с глубоким распознаванием лиц Существует ряд наборов данных о лицах, которые можно использовать для обуче ния и тестирования моделей глубокого распознавания лиц. Здесь мы подробно расскажем о некоторых из них. Набор данных LFW (Labeled Faces in the Wild) (Huang et al., 2008) пред- ставляет собой большой набор изображений лиц, предназначенный для тес - тирования способности распознавания лиц в смоделированных сценариях. Все изображения были собраны из интернета и состоят из спектра вариаций выражения лица, позы, возраста, освещения и разрешения. База данных LFW содержит изображения 5749 объектов, всего около 13 000 изображений. Сами изображения в наборе данных имеют разнообразные и значительные фоно- вые помехи. База данных лиц YouTube (He et al., 2018) состоит из видеороликов лиц с различным освещением, положением и возрастом. База данных специ- ально разработана для изучения и анализа алгоритмов распознавания лиц в видеороликах. Она содержит более 3000 видеороликов, на которых сняты 1500 человек. Видео были загружены с YouTube. Набор данных FEI (Thomaz, Giraldi, 2010) содержит 200 изображений бразильских студентов и преподавателей с равным количеством мужчин\n--- Страница 298 ---\nКомпоненты системы глубокого распознавания лиц  297 и женщин. Для каждого субъекта есть 14 изображений, общее количество изображений в наборе данных составляет 2800. Разрешение изображений – 640×480 пикселей, и все изображения сделаны в цвете на однородном белом фоне. Субъектам от 19 до 40 лет, и набор данных содержит изображения, отображающие различные выражения и положения лица. 6.2. К омпоненты системы гЛубоКого распозна Вания Лиц По сути, современная система распознавания лиц, основанная на глубоком обучении, состоит из трех частей. Это обнаружение лица, с по мощью кото- рого система находит лицо на изображении, обработка, с по мощью которой лицо обрезается и часто нормализуется, и распознавание, в ходе которого алгоритм глубокого обуче ния используется для классификации или сопо - ставления лица. Этот процесс изображен на рис. 6.4. Вход Извлечение признаков изображения База данных лиц в полный анфасКлассификацияНайдено совпадение (Да/Нет) Рис. 6.4  Компоненты системы глубокого распознавания лиц Хотя глубокое обуче ние эффективно применяется для решения большин- ства проблем распознавания объектов, для задач распознавания лиц нам по- прежнему приходится прибегать к этапу извлечения лица из сцены на этапе обработки, чтобы гарантировать, что влияние ракурса, освещения, мимики и окклюзии сведено к минимуму. Следовательно, систему глубокого распознавания лиц в обобщенном виде можно описать следующим образом: M[F(Ii), F(Ij)], (6.4) где Ii и I j – два сравниваемых изображения лица, F – признаки из модели CNN, а M определяет критерии совпадения. После обычно очень длительного про-\n--- Страница 299 ---\n298  Глубокое распознавание лиц с использованием полных и частичных изображений цесса обуче ния с массивными наборами данных и с наблюдением за соответ - ствующими функциями потерь определяются оптимальные слои, из которых необходимо извлечь и сравнить признаки. Сам процесс сравнения может быть осуществлен с использованием мер расстояния, таких как евклидово расстояние, косинусное сходство (CS) и машины опорных векторов (SVM). Сегодня распознавание лиц на практике в основном выполняется с по- мощью моделей глубокого обуче ния, и, как упоминалось ранее, нам есть из чего выбирать. Далее мы обсудим некоторые примеры, чтобы дополнительно объяснить процесс распознавания лиц на основе глубокого обуче ния и проб- лемы, которые требуют особого внимания. Важной частью любой системы распознавания лиц, основанной на глубо- ком обучении, являются признаки, полученные из обученной модели CNN (Liu et al., 2017). Пользователь может выбирать из нескольких архитектур моделей. К ним относятся AlexNet (Krizhevsky et al., 2012), GoogleNet (Szegedy et al., 2015), ResNet (He et al., 2015) и VGGNet (Parkhi et al., 2015). 6.2.1. Пример обученной модели CNN для распознавания лиц Как упоминалось в предыдущих главах, существует несколько способов раз- вертывания CNN. К ним относятся обуче ние сети с нуля, тонкая настройка существующей модели или использование готовых признаков CNN из пред- варительно обученной модели. Последнее называется переносом обуче ния. Важно подчеркнуть, что для обуче ния CNN с нуля требуется огромное ко- личество данных, что часто является сложной задачей. Например, для обуче - ния модели FaceNet потребовались миллионы лиц и сотни часов вычисли- тельного времени (Schroff et al., 2015). В свою очередь, точная настройка включает перенос весов первых нескольких слоев, полученных из базовой сети, в целевую сеть. Затем целевая сеть может быть обучена с использова- нием нового набора данных. Хорошим примером предварительно обученной модели CNN в контексте распознавания лиц является модель VGG-F (Chatfield et al., 2016), разрабо- танная исследовательской группой Oxford Visual Geometry Group. Эта модель была обучена на большом наборе данных из 2,6 млн изображений лиц более чем 2,6 тыс. человек. Архитектура VGG-F состоит из 38 слоев, начиная с вход- ного уровня и заканчивая выходным. На вход должно поступать цветное изображение с разрешением 224×224, и в качестве шага предварительной обработки из входного изображения обычно вычисляется среднее значение. В общей сложности VGG-F содержит тринадцать сверточных слоев, каждый из которых имеет специальный набор гибридных параметров. Каждая группа сверточных слоев содержит 5 слоев max-пулинга и 15 слоев ReLU. После них идут три слоя FC, а именно FC6, FC7 и FC8. Первые два имеют 4096 каналов, тогда как FC8 имеет 2622 канала, которые используются для классификации 2622 идентичностей. Последний слой – это классификатор softmax, предо- ставляющий вероятность того, что изображение принадлежит к определен- ному классу. Архитектура VGG-F представлена на рис. 6.5.\n--- Страница 300 ---\nКомпоненты системы глубокого распознавания лиц  299 Признаки Рис. 6.5  Архитектура модели VGG-F. Модель содержит 13 сверточных слоев, каждый слой имеет специальный набор гибридных параметров Далее мы покажем, как модель VGG-F, предварительно обученную для из- влечения признаков, можно использовать для кодирования черт лица и как можно использовать меру косинусного сходства или линейные меры SVM для классификации для эффективного распознавания лиц по неполным изо- бражениям. Извлечение признаков Заданное входное изображение X0 можно представить как тензор X0 Î RHWD, где H – высота изображения, W – ширина, а D – цветовые каналы. Предва- рительно обученный слой L CNN может быть выражен как ряд функций gL = f1 ® f2 ® … ® fL. Пусть X1, X2, …, Xn будут выходами каждого слоя в сети. Затем выходные данные i-го промежуточного слоя могут быть вычислены по функции fi и изучен ным весам w i таким образом, что X i = fi(X(i–1):wi). Как мы знаем, CNN изучают признаки на этапе обуче ния и позже исполь- зуют их для классификации изображений. Каждый сверточный слой изучает разные признаки. Например, один слой может изучить такие признаки, как края и цвета изображения, в то время как более сложные признаки могут быть изучены на более глубоких уровнях. Например, выход сверточного слоя включает в себя множество двумерных массивов, которые называются ка- налами. В VGG-F есть 37 слоев, 13 из которых – свертки, а остальные слои представляют собой смесь функций ReLU, пулинга, softmax и полносвязных слоев. Однако после применения слоя conv5_3 с 512 фильтрами размера 3×3 можно извлечь признаки для классификации. Изучая активации этого слоя, можно получить основные признаки, как изображено на рис. 6.6, где пред- ставлена выборка признаков. Чтобы решить, какой слой в модели VGG-F лучше всего использовать для извлечения признаков лица, необходимо провести ряд экспериментов ме- тодом проб и ошибок. Тесты показывают (Elmahmudi, Ugail, 2019), что, как правило, наиболее эффективны слои с 34 по 37. Часто наилучшие результаты дает слой 34. Следует отметить, что этот слой является полносвязным и распо- лагается в конце CNN, поэтому извлеченные признаки представляют все лицо. Признаки из слоя 34 – это результаты, полученные из полносвязного слоя FC7 после применения ReLU6, которые представляют собой вектор с раз- мерностью 4096. Предположение о том, что слой 34 является наиболее под- ходящим, основано на результатах проведения ряда тестов распознавания лиц с использованием полного фронтального изображения лица как для обуче ния, так и для тестирования. Результаты свидетельствуют, что точность распознавания может достигать 100 %.\n--- Страница 301 ---\n300  Глубокое распознавание лиц с использованием полных и частичных изображений Рис. 6.6  Визуализация признаков в VGG-F, полученная из слоя conv5_3 после ввода изображения лица Классификация признаков Одной из задач классификации является построение краткой модели рас - пределения меток классов по прогнозируемым признакам. Существует не- сколько методов такой классификации, среди них наиболее известны дере- вья решений, k -ближайшие соседи (k -nearest neighbors, kNN) и SVM. SVM – это алгоритм машинного обуче ния с учителем, который можно использовать как для задач бинарной классификации, так и для задач рас - пределения объектов по нескольким классам (мультиклассификация). SVM работает путем построения гиперплоскостей, проходящих через многомер- ное пространство признаков для разделения данных на классы, и поиска «за- зора» между гиперплоскостями. Чем больше зазор между гиперплоскостями, тем ниже ожидаемая ошибка классификации. Очевидно, что алгоритм SVM ориентирован прежде всего на решение задач бинарной классификации. Для решения задачи мультиклассификации обычно используют линейный SVM в сочетании с методом «один против одного» (one-vs-one, OVO), также известным как попарная классификация. Декомпозиция OVO дает би- нарных классификаторов для n классов. Затем, используя метод кодов исправ- ления ошибок (error correction codes, ECC), принимают решение, как можно комбинировать различные классификаторы. Если у нас есть обучающий набор данных (x i, yi), мы можем использовать линейный SVM таким образом, что: (6.5)\n--- Страница 302 ---\nРаспознавание лиц с использованием полных изображений лица  301 где w – вектор весов, N – количество классов, а C – параметр компромисса между ошибкой и «зазором». Кроме того, для классификации можно также использовать косинусное по- добие1 (cosine similarity, CS). Это мера сходства между двумя ненулевыми векторами, которая использует пространство скалярных произведений для измерения косинуса угла между двумя векторами. Для вычисления коси- нусного подобия можно использовать формулу евклидова скалярного про- изведения: a.b = |a||b| cos θ , (6.6) где a и b – два вектора, а θ – угол между ними. Используя длину |x |, которая совпадает с евклидовой нормой или евклидовой длиной вектора x = [x1, x2, x3, …, xn], мы можем вычислить косинусное подобие S следующим образом: (6.7) (6.8) где A и B – два вектора. Для классификации субьекта можно вычислить CS и найти минимальное «расстояние» между тестовым изображением лица test im и обучающим изо- бражением trainingn im с использованием уравнения (6.9), такое, что: MCS = min(CS( test im, trainingn im)), (6.9) где im – номер изображения, n – общее количество изображений в обучаю- щей выборке. 6.3. распозна Вание Лиц с испо ЛьзоВанием поЛныХ изображений Лица Что касается глубокого обуче ния, хорошо обученная модель CNN часто обеспечивает превосходное распознавание лиц по полному изображению. В этом разделе мы покажем, как можно использовать типичную предвари- тельно обученную модель для задачи сопоставления и проверки лиц. Модель FaceNet (Schroff et al., 2015) создана на основе архитектуры модели GoogLeNet и предварительно обучена для эффективного распознавания лиц. Для задачи распознавания лиц она использует изображения списка людей в наборе данных вместе с данными нового человека или людей, которых 1 Также известен как коэффициент Оцуки–Отиаи, геометрический или косинусный коэффициент. – Прим. перев.\n--- Страница 303 ---\n302  Глубокое распознавание лиц с использованием полных и частичных изображений нужно распознать. Ключевым элементом архитектуры FaceNet является соз- дание представления определенной размерности из изображения лица с за- данным разрешением. Входное изображение пропускают через глубокую архитектуру CNN, которая имеет полностью связанный слой в конце. На выходе получается 128 признаков, которые не обязательно могут быть визу - ально понятными человеку. Затем для распознавания сеть может рассчитать расстояние между отдельными признаками каждого из представлений. Для вычисления расстояния между представлениями можно использовать такие метрики, как квадрат ошибки или абсолютная ошибка. Обычные модели FaceNet используют два типа архитектуры. Это архитек - тура Цейлера и Фергуса (Zeiler and Fergus, 2014) и модель Inception в стиле GoogLeNet (Szegedy et al., 2015). Основной идеей в обучении FaceNet является концепция триплетных потерь (triplet loss) для выявления сходств и раз- личий между классами лиц в 128-мерном представлении. Если дано пред- ставление E(x) изображения в пространстве признаков Rn, FaceNet смотрит на квадрат расстояния L2 между изображениями лиц, причем это значение мало для изображений с одной и той же идентичностью и велико для разных идентичностей. На рис. 6.7 изображена общая архитектура модели FaceNet. Важным эле- ментом модели является функция триплетных потерь. Часто в обычных мо- делях глубокого обуче ния функция потерь пытается сопоставить все изо- бражения лица одной и той же идентичности с одной точкой в Rn. Функция триплетных потерь пытается отличить каждую пару изображений лица одно- го человека от всех остальных, тем самым обеспечивая строгое различение лиц. Таким образом, функция триплетной потери, выбранная в этой модели, гарантирует, что изображение конкретного человека будет ближе ко всем другим изображениям этого человека, чем любое другое изображение в на- боре данных. Эта идея проиллюстрирована на рис. 6.8. Процесс обуче ния предполагает, что мы выбираем из набора данных случайное изображение – якорь. Нам нужно обучить модель так, чтобы расстояние между этим изобра- жением-якорем и другим изображением того же человека (положительные экземпляры) было меньше, чем расстояния между якорем и изображениями, не принадлежащими этому человеку (отрицательные экземпляры). Глубокая архитектура128-мерное представлениеТриплетная потеряL2-норма Рис. 6.7  Общая архитектура модели FaceNet. Ключевым аспектом моде- ли является возможность классифицировать изображение лица, используя 128-мерное пространство признаков Модель FaceNet была обучена на наборе из 100 млн образцов лиц с более чем 8 млн личностей. Путем экспериментов было обнаружено, что опти- мальное представление для лиц имеет размерность 128, т. е. каждое лицо различается с использованием 128 извлеченных из изображения признаков. Также были проведены эксперименты по варьированию обучающих данных\n--- Страница 304 ---\nРаспознавание лиц с использованием полных изображений лица  303 и было установлено, что после определенного момента увеличение числа обучающих выборок почти не увеличивает точность, т. е. первые несколько десятков миллионов выборок еще могут повысить точность, но увеличение набора до сотни миллионов почти не повысит точность распознавания. Привязка Привязка ПоложительныйПоложительныйОтрицательный ОтрицательныйОбучение Рис. 6.8  Иллюстрация того, как FaceNet использует обуче ние на основе три- плетной потери. Функция триплетной потери оценивает отличие каждой пары лиц одного человека от всех остальных, тем самым обучая модель точно раз- личать лица 6.3.1. Проверка подобия с использованием модели FaceNet Одним из основных преимуществ модели FaceNet является то, что она по- зволяет достичь очень высокой точности классификации, используя более простое представление, состоящее всего из 128 признаков. Эксперименты, проведенные с лицами как из набора LFW, так из базы данных YouTube Faces, показывают, что точность распознавания очень высока: в наборе данных LFW достигается точность распознавания 98,87 %, а в базе данных YouTube Faces – 95,18 %. Также важно подчеркнуть, что оба набора данных содержат лица, снятые при разном освещении, положении, окклюзии и в разном воз- расте. Несмотря на это, точность распознавания FaceNet впечатляет. На рис. 6.9 показано, как можно использовать модель FaceNet для опре- деления степени сходства между лицами. В этом примере 128 признаков каждого лица извлекаются с использованием модели FaceNet. Затем можно воспользоваться мерой косинусного подобия для вычисления расстояния между признаками каждого лица и изображением лица в центре. Результаты показывают, что точность сопоставления лиц в этом случае оказывается пре -\n--- Страница 305 ---\n304  Глубокое распознавание лиц с использованием полных и частичных изображений восходной. Стоит отметить также, что в экспериментах с моделью FaceNet подобие двух лиц на уровне 75 % или выше обычно считается полным со- впадением. 86.0 % 75.7 %85.4 % 90.8 %76.6 % 90.0 %87.8 % 88.6 %91.4 % 80.2 %77.2 % 99.1 % 87.9 % 75.6 % Рис. 6.9  Пример проверки подобия. Для сравнения портретов королевы ис - пользуется мера косинусного подобия на основе 128 признаков модели Fa- ceNet. Центральное изображение используется как образец для сравнения 6.4. гЛубоКое распозна Вание непо ЛныХ изображений Лица Если проанализировать результаты исследований, проведенных в области распознавания лиц с использованием глубокого обуче ния, становится ясно, что многие современные алгоритмы обеспечивают точность распознавания лиц на уровне человека, когда на изображении лицо расположено строго в ан- фас (фронтально). Например, рассмотренная выше модель FaceNet обеспе- чивает впечатляющий уровень точности распознавания с использованием фронтальных изображений лица. Однако на практике полное изображение лица может быть недоступно ни в качестве эталона, ни в качестве экземп- ляра для сравнения. В этом разделе мы обсудим, как методы, основанные на глубоком обучении, могут развиваться дальше, поскольку модели можно научить успешно распознавать лица даже по частичным изображениям. До- стижение этого уровня позволит моделям глубокого обуче ния превзойти способности человека. Описанные далее методы в основном опираются на\n--- Страница 306 ---\nГлубокое распознавание неполных изображений лица  305 известную работу по распознаванию частичных изображений лиц на основе глубокого обуче ния (Elmahmudi, Ugail, 2019). Основной подход здесь заключается в использовании признаков, извле- ченных из предварительно обученной модели, и применении стандартного классификатора, чтобы увидеть, как различные части лица (рис. 6.10) внед- ряются в модель на этапе обуче ния. Затем обученную модель можно исполь- зовать для распознавания лиц и решения задачи сопоставления. В данном конкретном случае для обуче ния и извлечения признаков мы использовали стандартную модель VGG-F. Различные части лица, рассматриваемые здесь, включают глаза, нос, рот, верхнюю и нижнюю половины лица, левую полови- ну лица, 3/4 лица и полное лицо. Далее все извлеченные признаки из модели VGG-F могут быть переданы обоим классификаторам, в данном случае SVM и CS. Лица в VGG-F могут быть представлены с различными частями лица (W) или без них (Wo), чтобы увидеть различия в результатах. Рис. 6.10  Пример неполных изображений лиц из набора данных LFW. Для экспериментов по частичному распознаванию лица можно рассматривать по- ловину лица, 3/4 лица и ключевые части лица, такие как глаза, нос, рот и лоб Например, классификационная способность SVM и CS может быть прове- рена без использования частей лиц в процессе обуче ния (SVM-Wo и CS-Wo) и с частями (SVM-W и CS-W). Чтобы исследовать показатели распознавания для каждой части лица, классификаторы можно применять по отдельности. В случае обуче ния без частей лица видно, что в целом CS-Wo превосходит SVM-Wo для большинства областей лица. Результаты этих экспериментов представлены на рис. 6.11 и 6.12. Видно, что показатели распознавания пра- вой щеки, рта, лба и носа низкие, около 1 % для обоих классификаторов. Напротив, скорость распознавания значительно увеличивается для частей лица, таких как глаза, и достигает 40 % при использовании CS-Wo. Мы так - же заметили, что по мере увеличения видимой части лица точность рас - познавания также значительно улучшалась, при этом наилучшая точность распознавания составляла почти 100 % для 3/4 лица и полного изображения\n--- Страница 307 ---\n306  Глубокое распознавание лиц с использованием полных и частичных изображений лица. Также следует отметить, что для всех тестов, проведенных в этих экс - периментах, показатели CS оказались лучше, чем показатели SVM. Из результатов, представленных на рис. 6.11 и 6.12 для экспериментов с частичным изображением лица с использованием набора данных FEI, са- мая высокая точность распознавания (что касается части лица) отмечена для изображений 3/4 лица с использованием SVM-Wo. В этих экспериментальных условиях обучающая выборка не содержала различные части лица. Кроме того, в случае CS-Wo правая половина лица, верхняя половина и 3/4 лица обес - печивают высокие показатели распознавания. Наихудшие показатели рас - познавания относятся к меньшим по размеру и, возможно, менее значимым частям лица, таким как щека, рот и нос. При применении той же методики к набору данных LFW и обучении с большими пропорциями лица наблюдает - ся небольшое снижение показателей распознавания по сравнению с набором данных FEI, которое составляло от 76 до 99 % для SVM-Wo и от 83 до 99 % для классификатора CS-W. Согласно результатам, полученным для меньших об- ластей лица, наихудшая точность распознавания наблюдается для щек, рта, лба и носа. Однако, судя по всему, глаза содержат больше информации. SVM-Wo CS-Wo SVM-W CS-W100 90 80 70 60 50 40 30 20 10 0Уровень узнавания, % Щека_ПрРот Лоб НосГлаза Глаза + нос Без глаз и носаНижняя половина Верхняя половина Правая половина3_4 Полное Части лица Рис. 6.11  Результаты распознавания лиц по фрагментам с использовани- ем признаков VGG-F. Точность распознавания (%) измерена с использованием изобра жений из набора данных LFW с применением классификаторов SVM и CS Когда к обучающим наборам добавляются отдельные части лица, наблю- дается резкое улучшение качества распознавания. Например, точность рас - познавания правой щеки улучшилась с 0 до 15 % при использовании набора данных FEI. Также следует отметить, что при использовании наборов данных FEI и LFW глаза по-прежнему дают самый высокий уровень распознавания по сравнению с другими частями лица, при этом объединение признаков глаз и носа обеспечивает точность около 90 % при использовании контролируе-\n--- Страница 308 ---\nОбучение специальной модели для полных и частичных изображений лица  307 мого набора данных FEI. Однако в случае набора данных LFW этот показатель несколько меньше. Кроме того, мы заметили, что в целом лучшие результаты распознавания достигаются при использовании меры CS. L-SVM L-SVM-Wo k-SVM k-SVM-Wo CS CS-Wo100 90 80 70 60 50 40 30 20 10 0Уровень узнаваемости Правая щекаРот Лоб Нос Без глаз + без носаНижняя половинаПолный Рис. 6.12  Результаты распознавания лиц по фрагментам с использованием признаков VGG-F. Результаты распознавания (%) при удалении некоторых час - тей лица (щеки и часть лица без глаз и носа) из обучающих наборов. Были про- тестированы следующие классификаторы: линейный SVM, ядерный SVM и CS Следовательно, в данном случае важно подчеркнуть, что мера CS в целом выглядит лучшим классификатором по сравнению как с линейной, так и с не- линейной SVM. Мера SVM требует полного переобучения при добавлении новых данных, что впоследствии приводит к вычислительным проблемам. Однако в случае классификатора CS таких проблем нет. Хотя на этапе тести- рования классификатор CS более требователен к вычислительным ресурсам, но с учетом большей точности имеет смысл использовать классификатор CS вместо SVM. 6.5. обуЧение специа Льной моде Ли дЛя поЛныХ и Части ЧныХ изображений Лица В этом разделе мы обсудим, как можно обучить определенные модели глу - бокого обуче ния эффективно распознавать лица с использованием полных или частичных изображений. Мы покажем, как можно построить экспери- ментальный фреймворк для обуче ния конкретных CNN, настроенных на определенные части лица. При проектировании систем такого рода важно\n--- Страница 309 ---\n308  Глубокое распознавание лиц с использованием полных и частичных изображений учитывать уровень используемых обучающих данных, сложность модели и продолжительность обуче ния, необходимого для создания данной модели. Предположим, мы создаем модель глубокого обуче ния, которая точно на- строена для идентификации людей только по изображениям их глаз. Нач- нем с базовой архитектуры VGG-16 (Parkhi et al., 2015), которая аналогична обсуждавшейся ранее VGG-F. Эта модель состоит из 13 сверточных слоев (CONV) с одинаковыми фильтрами размера 3×3. Сами эти слои делятся следу - ющим образом. Первые два слоя имеют глубину 64. Есть два слоя с глубиной 128, три слоя с глубиной 256 и шесть слоев с глубиной 512. За этими слоями следуют три слоя FC, из которых два слоя содержат 4096 нейронов, а по- следний слой имеет 1000 нейронов. Структура VGG-16 считается особенно удачной, поскольку она может эффективно управлять количеством гипер- параметров. В частности, расположение слоев было тщательно продумано, чтобы свести к минимуму количество гиперпараметров. Это расположение структурировано следующим образом. Размер фильтров CONV составляет 3×3, и есть маски 2×2 для слоев заполнения и max-пулинга со страйдом 2. Это говорит о том, что для обуче ния модели распознаванию определенной части лица мы должны использовать двухэтапную стратегию. На первом этапе первая модель будет построена и обучена только на наборе данных изобра- жений глаз. На втором этапе сгенерированная модель будет использована для построения комплексной модели с использованием той же структуры, что и сеть VGG, с применением тонкой настройки (Yosinski et al., 2014). На рис. 6.13 показана блок-схема процесса обуче ния модели. Этап 1 Этап 2Конкретные данные модели (например, глаза) Веса из этапа 1 + другие данные лицаОбучение CNN Точная настройкаОбновленные веса Окончательная модель Рис. 6.13  Процедура обуче ния модели для распознавания по конкретным частям лица. Процесс обуче ния может состоять из двух этапов, на которых гене- рируются веса для определенной части лица, применяемые впоследствии для создания окончательной формы модели Процесс тонкой настройки алгоритмов машинного обуче ния – это проце- дура, при которой выбранная модель CNN, уже обученная для данной работы и/или типа данных, используется для выполнения аналогичной задачи. Это делается путем замены выходного слоя, который изначально был обучен распознаванию предыдущих классов, на слой, который может распознавать новые классы для другой задачи. Преимуществом использования тонкой настройки является сокращение времени вычислений на этапе обуче ния. На самом деле первые слои уже способны справиться с новой задачей, а обуче-\n--- Страница 310 ---\nОбучение специальной модели для полных и частичных изображений лица  309 нию будут подвергнуты только последние слои без необходимости обуче ния всей сети с нуля. Еще одним преимуществом является повышение точности, поскольку исходные модели обычно обучаются на больших наборах данных. 6.5.1. Предлагаемая архитектура модели Как было сказано выше, предложенная нами модель для обуче ния распо- знаванию по определенным частям лица основана на модели VGG-16 (Parkhi et al., 2015) и требует входного изображения фиксированного размера (224, 224, 3). Модель имеет пять сверточных блоков, каждый из которых содержит ряд сверточных слоев, а за ними следуют нелинейные функции активации, как показано на рис. 6.14. Как видно по рис. 6.14, предложенная модель CNN для распознавания по частям лица архитектурно похожа на модель VVG-F с пятью сверточными слоями и тремя слоями FC. Эти сверточные слои предназначены для ин- теграции различных слоев с максимальным объединением для создания эффективных карт объектов. Важнейшим аспектом предлагаемого располо- жения сверточных и полносвязных слоев является сокращение количества обучаемых параметров (как определено уравнением 6.1), чтобы сохранить разумную продолжительность обуче ния при сохранении точности сети в до- пустимых пределах. Рис. 6.14  Архитектура модели CNN для распознавания лиц по отдельным частям. Эта модель является производной от стандартной VGG-16 6.5.2. Фаза обучения модели Обуче ние модели CNN – это процедура, позволяющая свести к минимуму различия между эталонными метками и прогнозируемыми выходными дан- ными из набора обучающих данных. Это достигается за счет размещения обучаемых параметров (ядер и весов) в сверточных и полносвязных слоях. В предложенной здесь модели веса фильтров инициализируются с использо- ванием гауссова и стандартного отклонений (Bishop, 2006), а смещения обну - ляются. Чтобы оценить точность модели посредством прямого распростра-\n--- Страница 311 ---\n310  Глубокое распознавание лиц с использованием полных и частичных изображений нения, можно использовать наиболее часто применяемую функцию потерь для задач множественной классификации, называемую кросс-энтропией, или перекрестной энтропией (Busoniu et al., 2011). Значение функции по- терь определяет, насколько хорошо или плохо работает модель после каждой итерации оптимизации. Кроме того, на основе градиента ошибки в текущем состоянии модели все обучаемые параметры будут обновляться во время оптимизации, например с использованием градиентного спуска в сочетании с обратным распространением. Скорость обуче ния – это еще один гипер - параметр, от которого зависит, насколько быстро модель CNN обучается, используя представленные ей данные. Значение этого параметра положи- тельное и находится в диапазоне от 0 до 1. Последние два гиперпараметра модели означают количество эпох обуче- ния, через которые должна пройти модель, т. е. сколько раз метод обуче ния просматривает набор обучающих данных. Необходимо также указать размер пакета (batch size, размер выборки обучающих данных, размер партии), не- обходимый для выполнения эпохи, – рекомендуемый размер пакета состав- ляет 64. Что касается непосредственно обуче ния, полезно следовать двух - этапному процессу. На первом этапе модель обучается с использованием около 20 эпох с размером пакета 64. После этого сохраняются полученные веса из модели. Эти веса затем используются для инициализации весов на втором этапе обуче ния, который состоит из 50 эпох. Эпохи разделены на десять частей по пять эпох в каждой. Таким образом, веса из предыдущего этапа обуче ния используются для инициализации новых весов и обуче ния модели в течение пяти эпох. Полученные новые веса будут использоваться для следующего тренировочного прогона. Эта процедура продолжается до тех пор, пока не будет достигнут заданный уровень потерь при обучении и тестировании. Во время процесса необходимо стремиться к небольшим по- терям при обучении (т. е. приблизительно < 0,02) и более высокой точности тестирования (т. е. > 85 %). Что касается обучающих данных, должно быть доступно достаточное ко- личество изображений лиц и соответствующих им персон. Типичные зна- чения – 70 000 изображений, соответствующих определенной части лица у 200 персон. Такой набор данных можно разделить на две группы: 70 % для обуче ния и 30 % для проверки. Наконец, обучающий набор используется для обуче ния модели, а потери вычисляются путем прямого распространения, тогда как обновление обучаемых параметров происходит посредством об- ратного распространения. 6.6. заКЛюЧение В этой главе мы обсудили современное состояние дел в области распозна- вания лиц с использованием методов и приемов глубокого обуче ния. Мы показали, как можно использовать методы глубокого обуче ния для сопостав - ления личностей и выявления сходства лиц – с использованием как полных изображений лиц в анфас, так и частичных изображений лица. Мы показали,\n--- Страница 312 ---\nЗаключение  311 как готовые признаки хорошо обученных моделей можно использовать для создания эффективных и точных систем распознавания лиц. Мы также пока - зали, как обучать определенные модели, построенные на основе различных архитектур, обучаемых слоев и весов, заимствованных из хорошо известных глубоких моделей, которые используются для обработки и анализа изобра- жений. Например, мы исследовали вопрос, связанный с идеей распознавания лиц по характерным фрагментам. В частности, показали, как работает глубокое распознавание лиц, когда такие части, как глаза, рот, нос и щека, использу - ются в качестве источника признаков для обуче ния и распознавания. Мы также показали, что системы распознавания лиц могут использовать не- сколько подходов. Например, продемонстрировали, как реализовать совре- менную CNN, инкапсулирующую в себя предварительно обученные модели (такие как VGG-F), с по мощью которых можно извлечь ключевые признаки лица. Затем можно использовать хорошо известные классификаторы, такие как мера косинусного подобия и машины опорных векторов, для проверки точности распознавания. Точно так же можно применять обуче ние моделей на конкретных частях лица, таких как рот, нос, глаза, лоб и их комбинации, для разработки эффективных систем распознавания лиц по частичным изо- бражениям. Очевидно, что развитие методов и техник глубокого обуче ния принесло огромную пользу отрасли распознавания лиц (Guo and Zhang, 2019). Многие проблемы, ранее считавшиеся неразрешимыми, теперь считаются простыми. Например, при наличии двух хорошо освещенных фронтальных изображе- ний человека подтверждение совпадения личности с характерных признаков лица теперь считается тривиальной задачей. Однако в целом распознавание лиц по-прежнему остается актуальным направлением исследований, в ко- тором остается ряд сложных и нерешенных проблем. Например, проблема компьютерного распознавания лиц с использованием частичных данных о лице до сих пор остается в значительной степени неисследованной об- ластью. Учитывая, что люди и компьютеры выполняют распознавание лиц и аутентификацию по-разному, интересно понять, как компьютер будет реа- гировать на различные части лица, когда они предъявляются в задаче рас - познавания лиц. Компьютерное распознавание лиц, начиная с 1960-х годов, прошло дол- гий путь. Тем не менее осталось много проблем и препятствий, которые еще предстоит преодолеть. Это, например, распознавание лиц в следующих проблемных ситуациях: плохое освещение, разные положения, неполное изображение, перевернутые лица, постаревшие лица и изображения, полу - ченные с больших расстояний. Вопрос о точности измерения сходства лиц с использованием методов глубокого обуче ния в значительной степени оста- ется без ответа. Например, на вопрос о сходстве между лицами, связанными близкими родственными отношениями, – братьями, сестрами и однояйце- выми близнецами – пока нет удовлетворительного ответа. Кроме того, нет удовлетворительных ответов на вопросы о предвзятости обучающих данных и о том, как сделать системы глубокого обуче ния прозрачными и объясни- мыми.\n--- Страница 313 ---\n312  Глубокое распознавание лиц с использованием полных и частичных изображений Литературные исто ЧниКи Bishop C. M., 2006. Pattern Recognition and Machine Learning. Springer, Berlin. Busoniu L., Ernst D., De Schutter B., Babuska R., 2011. Cross-entropy optimization of control policieswith adaptive basis functions. IEEE Transactions on Systems, Man, and Cybernetics, Part B 41 (1), 196–209. Chatfield K., Simonyan K., Vedaldi A., Zisserman A., 2016. Return of the devil in the details: delving deep into convolutional nets. In: Proceedings of the British Machine Vision Conference (BMVC). Day O., Khoshgoftaar T. M., 2017. A survey on heterogeneous transfer learning. Journal of Big Data 4 (1). Dora L., Agrawal S., Panda R., Abraham A., 2017. An evolutionary single Gabor kernel based filter approach to face recognition. Engineering Applications of Artificial Intelligence 62, 286–301. Dumoulin V., Visin F., 2018. A guide to convolution arithmetic for deep learning. arXiv:1603.07285v2. Elmahmudi A., Ugail H., 2019a. The biharmonic eigenface. Signal, Image and Video Processing 3, 1639–1647. Elmahmudi A., Ugail H., 2019b. Deep face recognition using imperfect facial data. Future Generations Computer Systems 41 (99), 213–225. Gholamalinezhad H., Khosravi H., 2020. Pooling methods in deep neural networks, a review. arXiv:2009.07485. Guo G., Zhang N., 2019. A survey on deep learning based face recognition. Com- puter Vision and Image Understanding 189, 102905. He K., Zhang X., Ren S., Sun J., 2015. Deep residual learning for image recognition. In: Proceedings of the British Machine Vision Conference (BMVC). He L., Li H., Zhang Q., Sun Z. , 2018. Dynamic feature learning for partial face recognition. In: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 7054–7063. Huang G. B., Ramesh M., Berg T., Learned-miller E., 2008. Labeled faces in the wild: a database for studying face recognition in unconstrained environments. In: Workshop on Faces in Real-Life Images: Detection, Alignment, and Recogni- tion, pp. 1–11. Jolliffe I. T., 2002. Principal Component Analysis. Springer, New York. Kas M., Elmerabet Y., Ruichek Y., Messoussi R., 2020. A comprehensive compara- tive study of handcrafted methods for face recognition LBP-like and non LBP operators. Multimedia Tools and Applications 79, 375–413. Krizhevsky A., Sutskever I., Hinton G. E., 2012. ImageNet classification with deep convolutional neural networks. In: NIPS. LeCun Y., Bengio Y., Hinton G., 2015. Deep learning. Nature 521, 436–444. Liu W., Wang Z., Liu X., Zeng N., Liu Y., Alsaadi F. E., 2017. A survey of deep neural network architectures and their applications. Neurocomputing 234, 11–26. Parkhi O. M., Vedaldi A., Zisserman A., 2015. Deep face recognition. In: IEEE CVPR. Schroff F., Kalenichenko D., Philbin J., 2015. FaceNet: A unified embedding for face recognition and clustering. In: IEEE CVPR. Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V.,\n--- Страница 314 ---\nОб авторе главы  313 Rabinovich A., 2015. Going deeper with convolutions. In: IEEE CVPR. Taigman Y., Yang M., Ranzato M., Wolf L., 2014. DeepFace: closing the gap to human-level performance in face verification. In: 2014 IEEE Conference on Computer Vision and Pattern Recognition, pp. 701–1708. Thomaz C. E., Giraldi G. A., 2010. A new ranking method for principal components analysis and its application to face image analysis. Image and Vision Comput - ing 28 (6), 902–913. Turk M., Pentland A., 1991. Eigenfaces for recognition. Journal of Cognitive Neu- roscience 13, 71–86. Weiss K., Khoshgoftaar T. M., Wang D., 2016. A survey of transfer learning. Journal of Big Data 3 (1). Yosinski J., Clune J., Bengio Y., Lipson H., 2014. How transferable are features in deep neural networks? In: Proceedings of the Advances in Neural Information Processing Systems. Young A. W., Burton A. M., 2018. Are we face experts. Trends in Cognitive Sciences 22, 100–110. Zeiler M. D., Fergus R., 2014. Visualizing and understanding convolutional net - works. In: Computer Vision – ECCV 2014. об аВторе гЛаВы Хассан Угайл – директор Центра визуальных вычислений факультета инже- нерии и информатики Университета Брэдфорда, Великобритания. Он имеет степень бакалавра с отличием по математике в Королевском колледже Лон- дона и докторскую степень в области начертательной геометрии в Школе математики при Университете Лидса. Научные интересы профессора Угайла включают компьютерное геометрическое и функциональное проектирова- ние, визуализацию и машинное обуче ние.",
      "debug": {
        "start_page": 290,
        "end_page": 314
      }
    },
    {
      "name": "Глава 7. Адаптация домена с использованием неглубоких и глубоких нейросетей , обучаемых без учителя 314",
      "content": "--- Страница 315 --- (продолжение)\nГлава 7 Адаптация домена с использованием неглубоких и глубоких нейросетей , обучаемых без учителя Авторы главы: Йогеш Балахи, факультет компьютерных наук и UMACS, Мэрилендский университет, Колледж-Парк, Мэриленд, США; Хиен Нгуен, факультет электроники и вычислительной техники, Хьюстонский университет, Хьюстон, Техас, США; Рама Челлаппа, факультеты электроники, вычислительной техники и биомедицинской инженерии, Университет Джона Хопкинса, Балтимор, Мэриленд, США1 Краткое содержание главы: адаптация домена с использованием неглубоких1 и глубоких нейросетей; интерполяция между исходным и целевым доменами с использованием многообразий и словарей; генеративные состязательные сети как посредники при переходе между доменами. 7.1. В Ведение Располагая обширными данными, полученными с различных устройств и при разных условиях, мы часто оказываемся в ситуации, когда данные, 1 Неглубокие нейросети (shallow neural network) – это сети, состоящие из одного или двух слоев. – Прим. перев.\nГлава 7 Адаптация домена с использованием неглубоких и глубоких нейросетей , обучаемых без учителя Авторы главы: Йогеш Балахи, факультет компьютерных наук и UMACS, Мэрилендский университет, Колледж-Парк, Мэриленд, США; Хиен Нгуен, факультет электроники и вычислительной техники, Хьюстонский университет, Хьюстон, Техас, США; Рама Челлаппа, факультеты электроники, вычислительной техники и биомедицинской инженерии, Университет Джона Хопкинса, Балтимор, Мэриленд, США1 Краткое содержание главы: адаптация домена с использованием неглубоких1 и глубоких нейросетей; интерполяция между исходным и целевым доменами с использованием многообразий и словарей; генеративные состязательные сети как посредники при переходе между доменами. 7.1. В Ведение Располагая обширными данными, полученными с различных устройств и при разных условиях, мы часто оказываемся в ситуации, когда данные, 1 Неглубокие нейросети (shallow neural network) – это сети, состоящие из одного или двух слоев. – Прим. перев.\n--- Страница 316 ---\nВведение  315 используемые для обуче ния классификатора, по некоторым показателям отличаются от тех, что представлены во время прикладного использова- ния. Подобные случаи нередко возникают в приложениях для распознавания объектов, где обучающие и рабочие данные записываются при различных условиях освещения; при обработке речи, когда разговорная модель, обучен- ная на студийных записях, должна быть развернута в более реалистичной внешней среде; при индексации файлов мультимедиа, когда легко доступ- ны размеченные фотографии Flickr или видео YouTube, на основе которых пользователь хотел бы автоматически проиндексировать свою собственную фото- и видеоколлекцию, собранную с по мощью бытовой камеры. Адаптация домена1 (domain adaptation, DA) относится к классу методов, направленных на изучение представлений из набора данных с небольшими ресурсами (объ- ем, разметка) путем передачи знаний из связанного, но отличающегося на- бора данных, имеющего богатые ресурсы. Различия между наборами данных могут выражаться в разнице освещения, разных узорах текстур или любых подобных расхождениях, присущих набору данных. Для передачи имеющих - ся знаний в другой домен обычно ищут представление признаков, не зави- сящее от домена, которое эффективно устраняет мешающие расхождения. Обуче ние с переносом (transfer learning, TL) (Pan et al., 2010) – это родствен- ный подход, который решает проблему расхождений между наборами дан- ных. Основное различие между TL и DA связано с тем, какие свойства данных сохраняются в условиях обуче ния и применения. В то время как TL имеет дело со случаем, когда условное распределение меток данных меняется (т. е. задачи в двух доменах различны), а предельное распределение данных со- храняется, DA обращается к противоположному сценарию (Daume and Marcu, 2006), где распределение данных между двумя доменами различается, но задача остается прежней. Хотя нам часто приходилось видеть, как практи- кующие специалисты взаимозаменяемо применяют методы TL и DA в том и другом случае, в этой главе мы сосредоточимся на DA, поскольку данный метод естественным образом подходит к приложениям компьютерного зре- ния, таким как распознавание объектов, когда пользователь заинтересован в сохранении идентичности разных вариаций одного объекта, независимо от ракурса и освещения. Существуют две широкие категории методов DA в зависимости от того, имеют ли тестовые данные целевого домена неполную разметку (обуче ние с частичным участием учителя) или совсем не имеют разметки (обуче ние без учителя). В то время как метод DA с частичным участием учителя неред- ко использует соответствие из размеченных целевых данных для изучения перехода к целевому домену (Daume, Marcu, 2006; Saenko et al., 2010), DA без учителя использует стратегии, которые предполагают (а) определенный класс преобразований между доменами (Wang, Mahadevan, 2009), (б) наличие отличительных признаков, которые являются общими или инвариантными для обоих доменов (так называемые «инварианты доменов») (Blitzer et al., 2008; Mansour et al., 2009), или (в) скрытое пространство, где разница в рас - 1 Напомним, что доменом мы для краткости называем предметную (тематическую) область, которую охватывает модель. – Прим. перев.\n--- Страница 317 ---\n316  Адаптация домена с использованием неглубоких и глубоких нейросетей пределении исходных и целевых данных минимальна (Blitzer et al., 2011). По- мимо адаптации между одним исходным и одним целевым доменами, были проведены исследования многодоменной адаптации (например, Mansour et al., 2009), в которых рассматривалась ситуация с наличием более одного ис - ходного и/или целевого домена. В то время как некоторые из этих подходов преследуют цель «адаптации представления» путем изучения преобразова- ния различия между доменами, другие (Duan et al., 2009; 2012) выступают за подход, ориентированный на «классификатор», который пытается получить целевые классификаторы путем манипулирования или повторной оптими- зации классификаторов, обученных на исходном домене. В оставшейся части главы мы сосредоточимся в основном на обучении без учителя. С 2011 г. было проведено значительное количество исследований, на- правленных на решение задачи адаптации домена с обуче нием без учите- ля. К ним относятся методы, основанные на дифференциальной геометрии (Gong et al., 2011; 2014; Gong et al., 2012; Ho, Gopalan, 2014), разреженных словарях (Lu et al., 2015; Nguyen et al., 2012; 2015; Shekhar et al., 2013; Xu et al., 2015), а относительно недавно были разработаны генеративно-состяза- тельные сети (GAN) (Sankaranarayanan et al., 2018; Shi and Sha, 2012). В этой главе мы рассмотрим несколько типичных примеров из трех упомянутых выше подходов. За более подробным изложением исследований в области адаптации доменов читатель может обратиться к работе (Patel et al., 2015). 7.2. адаптация домена с испо ЛьзоВанием многообразия Некоторые исследователи, действуя в духе «постепенного перехода между крайностями» (Gopalan et al., 2014), предложили вариант DA с обуче нием без учителя, в основе которого лежит построение гладкого пути между исход- ным и целевым доменами с использованием промежуточных представлений данных, которые передают соответствующую информацию о расхождении между доменами. Не делая предположений об инвариантных свойствах до- мена, авторы этого метода представили первый метод DA с обуче нием без учителя для распознавания объектов путем вычисления пути адаптации определенных статистических характеристик от исходного домена (доме- нов) к целевому домену (доменам). Частный случай этой схемы, представ- ленный в (Gopalan et al., 2011), использует в качестве представления доме- на линейное порождающее подпространство. Точнее, к каждой из областей применяется анализ главных компонент с последующим представлением подпространств в виде точек на многообразии Грассмана. Затем геодезиче- ская линия между этими точками используется как статистически значимый путь для представления различий между доменами. Путем выборки точек вдоль геодезической линии получаются промежуточные кросс-доменные представления данных, с по мощью которых дискриминативный классифи- катор обучается выполнять распознавание. В этой работе впоследствии были\n--- Страница 318 ---\nАдаптация домена с использованием многообразия  317 рассмотрены другие частные случаи этой стратегии, такие как представле- ние домена в многомерном гильбертовом пространстве воспроизводящего ядра (reproducing kernel Hilbert space, RKHS) с использованием методов ядра и представление многообразия низкой размерности с использованием соб- ственных отображений матрицы Лапласа (Laplacian Eigenmaps). Интересно, что эта структура также поддерживает варианты адаптации с частичным участием учителя и несколькими доменами и была дополнительно улучшена за счет моделирования мелкомодульных доменов в сочетании с постепенно меняющимися пропорциями исходных и целевых экземпляров, а также за счет применения бустинга к пулу промежуточных представлений, получен- ных по разным параметрам. С момента публикации (Gopalan et al., 2011), были проведены и другие схожие исследования, такие как (Gong et al., 2012 г.; Zheng et al., 2012), в ко- торых обсуждались альтернативные стратегии выборки вдоль геодезической линии, и (Shi, Sha, 2012), которые предложили теоретико-информационный подход для совместного изучения признаков сдвига предметной области и классификаторов. Адаптация с несколькими источниками, которая может учитывать различные типы объектов в разных доменах за счет использо- вания механизма регуляризации, зависящего от данных, была рассмотрена в работе (Duan et al., 2012), а устойчивость к шуму или выбросам была разо- брана в методе реконструкции низкого ранга (Jhuo et al., 2012). Дополнитель- ный анализ и сравнительные оценки многих из этих значимых исследований обобщены в (Patel et al., 2015). 7.2.1. Адаптация домена без учителя с использованием произведения многообразий Применение адаптации домена без привлечения учителя (unsupervised domain adaptation, UDA) для неограниченного распознавания лиц пред- ставляет собой очень сложную проблему из-за различий внешнего вида лица на разных изображениях, вызванных множеством факторов, таких как размытие, выражение, освещение, ракурс и разрешение. В результа- те классификаторы лиц, обученные с предположением, что обучающие и тестовые данные взяты из схожих распределений, обычно имеют очень низкую точность, особенно при применении в средах без учителя. Напри- мер, алгоритмы распознавания лиц, обученные на образцах из исходного домена, содержащего четкие, хорошо освещенные изображения лиц, плохо работают при использовании в целевом домене, содержащем размытые, плохо освещенные изображения лиц (Vageeswaran et al., 2013). Качество работы этих алгоритмов еще больше ухудшается, когда доступно только ограниченное количество изображений каждого лица из-за высокой стои- мости и других проблем при сборе данных. Несмотря на то что было проведено несколько исследований, посвящен- ных заранее заданным вариациям лица в исходном и целевом доменах (Zhao et al., 2003), таких как исследование девятиточечного источника освещения\n--- Страница 319 ---\n318  Адаптация домена с использованием неглубоких и глубоких нейросетей (Lee et al., 2005), анализу различий между доменами, вызванных множе- ственными неизвестными факторами, не уделялось должного внимания. Адаптация доменов – это новая парадигма для решения таких преобразо- ваний в более широком контексте, в соответствии с которой при наличии помеченных данных из исходного домена и небольшого количества (или отсутствия) помеченных данных из целевого домена разрабатываются под- ходы обуче ния без учителя или с частичным привлечением учителя для настройки модели на различия в данных между доменами (Saenko et al., 2010; Ben-David et al., 2010; Gopalan et al., 2011). Большинство этих методов учитывают различия доменов в статистическом смысле, поскольку модели, вызывающие изменения в данных, неизвестны. Это ограничивает их приме- нение конкретной проблемой распознавания лиц, где имеются богатые на- работки по моделям ракурса, освещения, размытия, выражения и старения. Важно понимать различия доменов с точки зрения основных ограничений, относящихся к моделям, которые генерируют наблюдаемые данные. Такой анализ требует изучения геометрических свойств пространства изображе- ний, индуцированных этими моделями. Однако многие традиционные подходы часто либо игнорируют геометри- ческие структуры пространства, либо наивно рассматривают пространство как евклидово (Lui, 2012). Хотя нелинейные алгоритмы изучения многообра- зия, такие как ISOMAP (Tenenbaum et al., 2000) или локально-линейное пред- ставление (locally linear embedding, LLE) (Roweis, Saul, 2000), предлагают аль- тернативы, они требуют больших объемов обучающих данных для лежащей в основе доменов нелинейной многообразной структуры данных. Подобное требование к данным не всегда может быть удовлетворено во многих реаль- ных приложениях. Одним из возможных способов обработки вариаций лица, возникающих из-за множества факторов, является использование математи- ческого инструмента, называемого полилинейной алгеброй, т. е. алгеброй тен- зоров более высокого порядка. Поскольку матрицы представляют линейные операторы над векторным пространством, их обобщение, тензоры, опре- деляют полилинейные операторы над множеством векторных пространств (Vasilescu, Terzopoulos, 2002). Хотя существуют исследования, посвященные использованию полилинейной алгебры для распознавания лиц (Vasilescu and Terzopoulos, 2002; 2007), такие подходы игнорируют искривленную геомет - рию пространства изображения и оперируют евклидовым пространством. В ряде работ сообщалось о попытках включить нелинейные геометрические структуры в структуру тензорных вычислений (Lui, Beveridge, 2010; Park, Sav - vides, 2011), но им снова нужны большие обучающие данные. В работе (Ho, Gopalan, 2014) представлено адаптивное решение для рас - познавания лиц на основе тензорной геометрии моделей, объясняющих ва- риации лица всего с одним изображением на человека в исходном домене. Вместо того чтобы находить линейные преобразования, представляющие переход между доменами, как в (Saenko et al., 2010; Kulis et al., 2011), мы предлагаем основанный на модели подход к построению латентного домена, в котором многофакторные вариации лица в исходном и целевом доменах могут быть захвачены вместе. Одним из основных преимуществ такого под- хода является то, что даже если данные в пределах исходного домена и/или\n--- Страница 320 ---\nАдаптация домена без учителя с использованием словарей  319 целевого домена неоднородны, например когда расхождение доменов1 вы- звано размытием, а исходные и целевые данные содержат сочетание четких и размытых лиц, процесс изучения смещения доменов остается неизмен- ным, в отличие от других методов, которые предполагают, что домены будут более или менее однородными (Saenko et al., 2010; Kulis et al., 2011; Gopalan et al., 2011). Кроме того, предлагаемый метод преодолевает ограничение требований к данным для моделирования вариаций домена путем синтеза нескольких изображений лица при различном освещении, размытии и ра- курсе из одного входного изображения в исходном или целевом домене и ис - пользует их для формирования многомерного тензора, в отличие от других методов, таких как (Lui, Beveridge, 2010), которые предъявляют более строгие требования к данным. Затем тензор, полученный из набора синтезирован- ных изображений, можно представить на произведении многообразий, вы- полнив разложение по сингулярным значениям высшего порядка (higher-order singular value decomposition, HOSVD) и сопоставив каждую ортогональную факторизованную матрицу с точкой на многообразии Грассмана. Порядок тензоров – это количество факторов, используемых в процессе синтеза. Далее мы распознаем метки лиц целевого домена, выполняя вычисления, относящиеся к тензорной геометрии, для случаев, когда исходный домен либо содержит только одно изображение для каждого субъекта, либо имеет несколько изображений для каждого субъекта. В этой работе также рассмат - ривается проблема сопоставления наборов изображений, которая связана с распознаванием лиц на основе видео, когда несколько кадров в видео пре- доставляют доказательства, связанные с идентификацией лица. Методы, основанные на многообразии, по-видимому, потеряли популяр- ность из-за более высокой точности методов, основанных на генеративно- состязательных сетях. 7.3. адаптация домена без уЧитеЛя с испо ЛьзоВанием сЛоВарей Разреженные и избыточные представления сигналов вызвали большой ин- терес в области компьютерного зрения, обработки сигналов и изображений (Bruckstein et al., 2009; Elad et al., 2010; Rubinstein et al., 2010; Wright et al., 2010; Bo et al., 2011). Отчасти это связано с тем, что интересующие сигналы и изображения могут быть представлены разреженно или сжимаемы при наличии соответствующего словаря. В частности, мы говорим, что сигнал y Î Rn разреженно представлен словарем D Î Rn×K, если он может быть хоро- шо аппроксимирован линейной комбинацией нескольких столбцов D, когда y ≈ Dx, где x Î RK – вектор разреженного представления, а D – словарь, кото- 1 Авторы книги используют термин domain shift (смещение домена), но этот тер- мин уже применяется в теории магнетизма для описания явлений, происходящих с магнитными доменами, поэтому мы постараемся избежать путаницы и будем говорить о расхождениях доменов. – Прим. перев.\n--- Страница 321 ---\n320  Адаптация домена с использованием неглубоких и глубоких нейросетей рый содержит набор базовых элементов (атомов) в качестве столбцов. Поиск разреженного вектора представления влечет за собой решение следующей задачи оптимизации: (7.1) где ϵ – допустимая ошибка, ||x ||0 – мера нулевой разреженности, которая от - ражает количество ненулевых элементов в векторе x, а ||y – Dx|| 2 – среднеквад- ратическая ошибка, полученная в результате разреженной аппроксимации. Решение (7.1) является NP-трудным и может быть аппроксимировано раз- личными методами (Chen et al., 2001; Patil et al. 1993; Tropp, 2004). Вместо использования заранее определенного словаря можно напрямую изучить словарь из данных. Действительно, было замечено, что изучение словаря непосредственно из обучающих данных вместо использования заранее опре - деленного словаря (например, вейвлета) обычно приводит к более компакт - ному представлению и, следовательно, может обеспечить лучшие результаты во многих приложениях обработки изображений, таких как восстановле- ние и классификация (Elad et al., 2010; Rubinstein et al., 2010; Wright et al., 2010; Olshausen and Field, 1996; Mairal et al., 2009, 2011). Для задачи изучения словаря было разработано несколько алгоритмов. Двумя наиболее извест - ными алгоритмами являются метод оптимальных направлений (method of optimal directions, MOD) (Engan et al., 1999) и алгоритм K-SVD (Aharon et al., 2006). Для заданного множества N сигналов Y = [y1, y2, , yN] цель алгоритмов K-SVD и MOD состоит в том, чтобы найти словарь D и разреженную матрицу X, которые минимизируют следующую ошибку представления: так, что ||x i|| £ T0, \"i = 1, …, N, (7.2) где xi представляет i-й столбец X, ||A||F обозначает фробениусову норму A, а T0 обозначает уровень разреженности. И MOD, и K-SVD являются итеративными методами, которые чередуют этапы разреженного кодирования и обновле- ния словаря. Сначала инициализируется словарь D с ℓ2-нормализованными столбцами. Следующая за этим основная итерация состоит из двух этапов: разреженное кодирование: на этом шаге D не меняется и решается следующая задача оптимизации для вычисления вектора представле- ния x i для каждого изображения y i: так, что ||x i||0 £ T0, \"i = 1, …, N; (7.3) обновление словаря: на этом этапе алгоритмы MOD и KSVD разли- чаются. Алгоритм MOD обновляет все атомы одновременно, решая задачу оптимизации, решение которой дается как D = YX+, где X+ обо- значает псевдоинверсию Мура–Пенроуза. Несмотря на то что алгоритм MOD очень эффективен и обычно сходится за несколько итераций, он страдает от высокой сложности обращения матрицы, как отмечено в (Aharon et al., 2006). В случае K-SVD обновление словаря выполня-\n--- Страница 322 ---\nАдаптация домена без учителя с использованием словарей  321 ется эффективным способом, атом за атомом, а не с использованием матричной инверсии. Было замечено, что для сходимости алгоритма K-SVD требуется меньше итераций, чем для метода MOD. 7.3.1. Общий словарь доменной адаптации Когда распределения целевых и исходных данных различаются, изученное разреженное представление может оказаться неоптимальным. В этом разде- ле мы рассматриваем возможность оптимального представления источника и цели с по мощью общего словаря. В частности, описываем метод, который совместно изучает проекции данных в двух доменах, и скрытый словарь, который может кратко представлять оба домена в спроецированном низ- коразмерном пространстве, как показано на рис. 7.1. Данный эффективный метод оптимизации можно легко распространить на несколько доменов. Затем изученный словарь можно использовать для классификации. Предла- гаемый подход не требует явного соответствия между исходным и целевым доменами и показывает хорошие результаты, даже когда в целевом домене доступно лишь несколько меток. Различные эксперименты по распозна- ванию показывают, что этот метод работает наравне или даже лучше, чем конкурирующие методы. Этап обучения Исходный домен Целевой доменСкрытое пространствоОбщий словарь Этап тестированияТестовые данные Проекция на скрытое пространство Разреженное кодирование Классификация на основе ошибок реконструкции Рис. 7.1  Схема метода с общим словарем доменной адаптации (Shekhar et al., 2013) Рассмотрим частный случай, когда у нас есть данные из двух доменов, Y1 Î Rd×N1 и Y2 Î Rd×N2. Мы хотим выучить общий словарь K-атомов D Î Rn×K и отображения P1 Î Rn×d, P2 Î Rn×d на общее пространство малой размерно-\n--- Страница 323 ---\n322  Адаптация домена с использованием неглубоких и глубоких нейросетей сти, что минимизирует ошибку представления в пространстве проекции. Формально нам нужно минимизировать следующую функцию стоимости: C1(D, P1, P2, X1, X2) = ||P 1X1 – DX 1||F2 + ||P 2Y2 – DX 2||F2 (7.4) – с учетом ограничений разреженности на X1 и X2. Далее мы предполага- ем, что строки проекционных матриц P1 и P2 ортогональны и нормированы к единичной норме. Это предотвращает вырождение решения. Регуляризация: при переносе данных из двух доменов в общее подпро- странство преобразования нельзя терять слишком много информации, до- ступной в исходных доменах. Чтобы облегчить эту задачу, мы добавляем член регуляризации, подобный PCA, сохраняющий энергию в исходном сиг - нале, заданном как C2(P1, P2) = ||Y 1 – P1TP1Y1||F2 + ||Y 2 – P1TP2Y2||F2. (7.5) Мы можем записать параметры следующим образом: (7.6) Используя новые обозначения, общую оптимизацию можно переписать следующим образом: так, что P iPiT = I, i = 1, 2 и ||x ˜j||0 £ T0, \"j. (7.7) Поддержка нескольких доменов: приведенную выше формулу можно расширить, чтобы она могла описывать несколько доменов. Для M доменов мы просто строим матрицы {Y ˜, P˜, X˜) как (7.8) Оптимизация: мы минимизируем целевую функцию в уравнении (7.7) путем чередования оптимизации P˜ и (D, X˜). В частности, когда фиксируется P˜, оптимизация становится стандартной задачей изучения словаря, где эф- фективны алгоритмы K-SVD и MOD. Когда фиксируются (D , X˜), мы можем минимизировать уравнение (7.7) с использованием методов оптимизации многообразия (Wen, Yin, 2013). В качестве альтернативы мы можем полу - чить оптимальную форму (P i, D) и преобразовать целевую функцию в более простую форму перед оптимизацией, как это сделано в работе (Shekhar et al., 2013). Классификация: как только общий словарь для нескольких доменов изу - чен, наш метод будет выполнять классификацию с использованием следу - ющей процедуры. Во-первых, мы проецируем тестовую выборку в скрытое\n--- Страница 324 ---\nАдаптация домена без учителя с использованием словарей  323 пространство, используя изученное преобразование Pi, выполняем разре- женное кодирование, затем вычисляем ошибку реконструкции для каждого преобразования домена. Класс, соответствующий наименьшей ошибке, будет окончательным предсказанием класса. Процедуру можно записать следую- щим образом: так, что ||x ||0 £ T0, «i; (7.9) (7.10) Член ошибки в уравнении (7.10) называется остаточной ошибкой, которая является мерой несоответствия тестовой выборки определенному классу. Эксперименты: мы используем набор данных Multipie (Gross et al., 2010) – полный набор данных о лицах 337 субъектов, включающий изображения, сделанные в 15 ракурсах, 20 вариантах освещения, при 6 выражениях лица и в течение 4 разных сеансов. В целях нашего эксперимента мы использовали 129 субъектов, общих для сеансов 1 и 2. Эксперимент проводился с исполь- зованием 5 ракурсов, от фронтального (анфас) до 75°. Наборы фронтальных снимков лица были взяты в качестве исходного домена, в то время как раз- личные нефронтальные ракурсы были взяты в качестве целевых доменов. Словари обучались с использованием вариантов освещения {1, 4, 7, 12, 17} относительно исходного и целевого ракурсов в сеансе 1 для каждого субъекта. Все изображения с разными вариантами освещения из сеанса 2 для целевого ракурса были взяты в качестве тестовых изображений. Сначала мы рассмотрим задачу выравнивания ракурса (pose alignment) с ис - пользованием предложенной схемы изучения словаря. Выравнивание ракур- са затруднено из-за очень нелинейных искажений, вызванных трехмерным вращением лица. В качестве целевого ракурса были приняты изобра жения, полученные в крайнем ракурсе 60°. Общий дискриминативный словарь был изучен с использованием подхода, описанного в этом разделе. Конкретное тестовое изображение проецировалось на скрытое подпространство и ре - конструировалось с использованием словаря. Реконструкция проецирова- лась обратно на исходный домен ракурса, чтобы получить выровненное изображение. На рис. 7.2(а) показаны синтезированные изображения для различных условий. Из этого рисунка мы можем сделать некоторые полезные выводы о методе. Во-первых, видно, что существует оптимальный размер словаря K = 5, при котором достигается наилучшее выравнивание. Кроме того, при изучении дискриминационного словаря сохраняется идентичность субъекта. При K = 7 выравнивание не очень хорошее, так как изученный словарь не может успешно сопоставить два домена, когда в словаре больше атомов. Словарь с K = 3 дает более высокую ошибку реконструкции, поэтому результат не является оптимальным. Мы выбрали K = 5 для дополнительных экспериментов с зашумленными изображениями. Из строк 2 и 3 видно, что предложенный метод устойчив даже при высоких уровнях шума и отсутству - ющих пикселях. Отметим, что синтезированные изображения были созданы с шумоподавлением и ретушированием дефектов, как показано в строках 2\n--- Страница 325 ---\n324  Адаптация домена с использованием неглубоких и глубоких нейросетей и 3 на рис. 7.2 (а) соответственно. Это показывает эффективность нашего метода. Изученные матрицы проекций (рис. 7.2b) показывают, что наш метод может изучить внутреннюю структуру двух доменов. В результате он спосо- бен выучить надежный общий словарь. (a) (b)Исходные изображенияГауссов шумНедо- стающие пикселиЦелевое изображение с выровненным ракурсомK = 3 K = 4 K = 5 K = 6 K = 720 % 40 % 60 % 80 % 90 %σ = 0.2 σ = 0.5 σ = 1 σ = 1.5 σ = 2 Рис. 7.2  Результаты выравнивания ракурса (Shekhar et al., 2013). (a) Примеры изображений с выравниванием ракурса с использованием предложенного метода. Синтез в различных условиях демонстрирует надежность метода. (b) Первые несколько компонентов изученных мат - риц проекций для двух ракурсов Мы также провели эксперимент по распознаванию, используя описанный выше набор условий. В табл. 7.1 показано, что наш метод выгодно отличается от других алгоритмов распознавания с несколькими представлениями (Shar - ma et al., 2012) и в среднем дает наилучшую точность. Алгоритм изучения словаря FDDL (Янг и др., 2011) здесь не оптимален, поскольку он не может эффективно представить нелинейные искажения, вызванные изменением ракурса.\n--- Страница 326 ---\nАдаптация домена без учителя с использованием словарей  325 Таблица 7.1. Сравнение точности предложенного метода с другими алгоритмами распознавания лиц в разных ракурсах (Shekhar et al., 2013) МетодРакурс 15° 30° 45° 60° 75° Среднее PCA 15,3 5,3 6,5 3,6 2,6 6,7 PLS (Sharma, Jacobs, 2011) 39,3 40,5 41,6 41,1 38,7 40,2 LDA 98,0 94,2 91,7 84,9 79,0 89,5 CCA (Sharma, Jacobs, 2011) 92,1 89,7 88,0 86,1 83,0 83,5 GMLDA (Sharma et al., 2012) 99,7 99,2 98,6 94,9 95,4 97,6 FDDL (Yang et al., 2011) 96,8 90,6 94,4 91,4 90,5 92,7 SDDL (Shekhar et al., 2013) 98,4 98,2 98,9 99,1 98,8 98,7 7.3.2. Совместная иерархическая адаптация домена и изучение признаков Сложные визуальные данные содержат отличительные структуры, которые трудно полностью охватить каким-либо одним дескриптором признаков. В то время как описанный выше метод адаптации домена сосредоточен на адаптации одного признака, созданного вручную, важно уметь выполнять адаптацию иерархии признаков, чтобы использовать богатство визуаль- ных данных. В этом разделе обсуждается метод адаптации домена на ос - нове разреженной и иерархической сети (domain adaptation based on a sparse and hierarchical network, DASH-N). Наш метод комплексно изучает иерархию признаков вместе с преобразованиями, которые устраняют несоответствие между различными доменами. В основе DASH-N лежит скрытое разрежен- ное представление. Мы используем этап уменьшения размерности, чтобы предотвратить слишком быстрое увеличение размерности данных по мере углубления в иерархию. Экспериментальные результаты показали, что этот метод выгодно отличается от конкурирующих современных методов раз - реженного обуче ния. Кроме того, показано, что многоуровневый DASH-N работает лучше, чем одноуровневый. Скрытое разреженное представление: исходя из наблюдения, что сигналы часто присутствуют в низкоразмерном многообразии, в предыдущем раз- деле мы выполняли изучение словаря и разреженное кодирование в низко- размерном скрытом пространстве. Чтобы облегчить дальнейшее обсуждение, мы определяем скрытое разреженное представление и соответствующую ему оптимизацию следующим образом: L(Y, P, D, X) = ||PY – DX||F2 + α||Y – PTPY||F2 + β||X||1 так, что PPT = I и ||d i||2 = 1, \" i Î [1, K ], (7.11) где P Î Rp×d – линейное преобразование, которое переводит данные в низ- коразмерное пространство признаков (p < d). Заметим, что словарь теперь находится в низкоразмерном пространстве D Î Rp×K. Первый член функции\n--- Страница 327 ---\n326  Адаптация домена с использованием неглубоких и глубоких нейросетей потерь поощряет разреженность сигналов в пространстве уменьшенной раз- мерности. Второй член – это количество энергии, отброшенной преобразова- нием P, или разница между низкоразмерными приближениями и исходными сигналами. Минимизация второго члена поощряет обученное преобразова- ние сохранять полезную информацию, присутствующую в исходных сигна- лах. Помимо вычислительного преимущества, было показано (Nguyen et al., 2012), что эта оптимизация способна лучше восстанавливать базовое разре- женное представление, чем традиционные методы обуче ния по словарю. Эта стратегия привлекательна, поскольку позволяет переносить данные в другой домен, чтобы лучше обрабатывать различные источники вариаций, такие как освещение и геометрические искажения. Мы предлагаем метод для выполнения иерархической адаптации домена совместно с изучением признаков. На рис. 7.3 показана общая схема пред- лагаемого метода. Сеть содержит несколько уровней, каждый из которых включает в себя три подуровня, как показано на рис. 7.3. Первый подуро- вень выполняет нормализацию контраста и уменьшение размерности вход- ных данных. На втором подуровне выполняется разреженное кодирование. В финальном подуровне к смежным признакам применяется max-пулинг для создания нового признака. Выход одного слоя становится входом для следующего слоя. Для простоты обозначений мы рассматриваем один ис - ходный домен. Расширение DASH-N на несколько исходных доменов можно выполнить с по мощью процедуры, описанной в уравнении (7.8). (a) (b) (c) (d) (e) Выравнивание контрастности Линейная SVMПространственный пирамидальный пулинг Рис. 7.3  Обзор алгоритма DASH-N (Nguyen et al., 2015). Сначала изображе- ния делятся на небольшие перекрывающиеся участки. Эти участки вектори- зованы с сохранением их пространственного расположения. (а) Выполнение нормализации контраста и уменьшение размерности с использованием PS для исходных изображений и PT для целевых изображений. Обратные связи меж - ду PS и PT указывают на то, что эти два преобразования изучаются совместно. (b) Получение разреженных кодов с использованием общего словаря D1. (c) Вы- полнение max-пулинга. Затем процесс повторяется для слоя 2 (этапы d и e), за исключением того, что входными данными являются разреженные коды из слоя 1, а не интенсивности пикселей. На заключительном этапе для создания дескрипторов изображений используется пространственная пирамида с max- пулингом. Классификация выполняется с применением линейной машины опорных векторов на последнем слое Пусть YS Î Rd×NS и Y T Î Rd×NT будут входными данными на каждом уровне из исходного домена и целевого домена соответственно. Обратите внимание,\n--- Страница 328 ---\nАдаптация домена без учителя с использованием словарей  327 что у нас есть NS, d-мерные образцы в исходном домене, и NT, d-мерные образцы в целевом домене. Здесь мы предполагаем, что для простоты рас - суждений исходные и целевые данные имеют одинаковую размерность d. Однако наша методика также подходит для сценария, в котором измерения данных различаются в разных доменах. При заданных YS и YT на каждом слое DASH-N мы изучаем совместное скрытое разреженное представление путем минимизации следующей функции потерь относительно (P S, PT, D, XS, XT): L(YS, PS, D, XS, α, β) + λL(YT, PT, D, XT, α, β) так, что P SPST = PTPTT = I, ||d i||2 = 1, \" i Î [1, K ], (7.12) где (α , β, λ) – неотрицательные константы, D Î Rp×K – общий словарь, PS Î Rp×d и PT Î Rp×d – преобразования в скрытую область, XS Î RK×NS и X T Î RK×NT – раз- реженные коды источника и цели домена соответственно. Как видно из при- веденной выше формулы, два домена вынуждены совместно использовать общий словарь в скрытом домене. Вместе с ограничением разреженности общий словарь D обеспечивает эффект связи, который способствует обнару - жению общих структур для двух доменов. Для простоты далее мы подробно рассмотрим двухслойную сеть DASH-N. Расширение DASH-N на несколько слоев не составляет труда. Слой 1: мы выполняем частую выборку на каждом обучающем изображе- нии, чтобы получить набор перекрывающихся участков (патчей). Затем эти участки нормализуются по контрасту. Если f – вектор, соответствующий пат - чу, то нормализация контраста может быть записана следующим образом: (7.13) где ϵ – небольшая константа. Мы установили значение ϵ равным 0,1 просто потому, что в наших экспериментах оно хорошо работает. Чтобы сделать вычисления более эффективными, для изучения скрытого разреженного представления используется только случайное подмножество фрагментов каждого изображения. Мы обнаружили, что установка этого числа на 150 для изображений максимального размера 150×150 обеспечивает хороший компромисс между точностью и вычислительной эффективностью. После изучения словаря D1 и преобразований (P1 S, P1 T) для всех выборочных патчей вычисляются разреженные коды (X1 S, X1 T) путем решения задачи (7.14) где символ * указывает, что вышеуказанная задача (7.14) может соответство- вать исходным или целевым данным. Каждый столбец Y1 представляет собой векторизованные значения пикселей внутри патча. Для решения этой задачи оптимизации используется быстрая реализация алгоритма LARS (Mairal et al., 2009). Для объединения разреженных кодов по каждому соседству 4×4 используется пространственный max-пулинг, поскольку этот метод объеди-\n--- Страница 329 ---\n328  Адаптация домена с использованием неглубоких и глубоких нейросетей нения особенно хорошо подходит для разделения разреженных признаков (Bureau, 2012; Bureau et al., 2010). Слой 2: на этом уровне мы выполняем аналогичные вычисления, за ис - ключением того, что входными данными являются разреженные коды из слоя 1, а не пиксели изображения. Признаки, полученные из предыдущего слоя, объединяются путем конкатенации по каждому соседству 4×4 и нор- мализуются по контрасту. Это дает нам новое представление, которое бо- лее устойчиво к окклюзии и изменениям освещения. Подобно слою 1, мы также случайным образом выбираем 150 нормализованных векторов при- знаков fˆ из каждого изображения для обуче ния. Далее ℓ1-оптимизация снова используется для вычисления разреженных кодов нормализованных признаков fˆ. В конце слоя 2 разреженные коды затем агрегируются с ис - пользованием max-пулинга в многоуровневой декомпозиции патчей (т. е. пространственный пирамидальный max-пулинг). На уровне 0 простран- ственной пирамиды один вектор признаков получается путем max-пулинга всего изображения. На уровне 1 изображение делится на четыре квадранта, и к каждому квадранту применяется max-пулинг, что дает 4 вектора при- знаков. Точно так же на уровне 2 мы получаем 9 векторов признаков и т. д. В этом примере мы рассматриваем max-пулинг с использованием трех - уровневой пространственной пирамиды. Таким образом, окончательный вектор признаков, возвращаемый вторым слоем для каждого изображения, является результатом объединения 14 векторов признаков из простран- ственной пирамиды. Оптимизация. Рассмотрим более детально процедуру оптимизации це- левой функции в уравнении (7.12). Во-первых, давайте определим (7.15) как матрицу Грама исходных данных, целевых данных и их блочно-диаго- нальной конкатенации соответственно. Можно показать, что оптимальное решение (7.12) принимает следующий вид: (7.16) для некоторых AS Î RNS×p, AT Î RNT×p и B Î R(NS+NT)×K. Мы можем подставить их в целевую функцию в уравнении (7.12) и оптимизировать ее относительно (AS, AT, B). Обратите внимание, что строки каждого преобразования нахо- дятся в подпространстве столбцов данных из его собственного домена. На- против, столбцы словаря создаются совместно данными как источника, так и цели. Когда (B , X) фиксированы, мы можем найти (A S, AT), сначала решив следующую ограниченную оптимизацию: (7.17)\n--- Страница 330 ---\nАдаптация домена без учителя с использованием словарей  329 где H = Λ0,5VTK((I – BX)(I – BX)T – αI)KVΛ0,5. (7.18) Тогда решения (A S, AT) имеют вид: AS = VS ΛS–0,5GS, A T = VTΛT–0,5GT. (7.19) Когда (A S, AT) фиксированы, мы можем найти (B , X), используя стандарт - ную процедуру разреженного кодирования: ||Z – DX||F2 + β(||X S||1 + λ||XT||1) так, что Z = [ASKS, ATKT], X = [XS, XT], B = Z+D. (7.20) Здесь Z+ обозначает псевдоинверсию Мура–Пенроуза матрицы Z . Эксперименты. Предлагаемый алгоритм оценивается в контексте рас - познавания объектов с использованием набора данных адаптации домена (Saenko et al., 2010), содержащего 31 класс, с добавлением изображений из набора данных Caltech-256 (Griffin et al., 2007). Смещения доменов вызваны различиями в таких факторах, как ракурс, освещение, разрешение и т. д. между изображениями в разных доменах. Кроме того, чтобы лучше оце- нить способность адаптироваться к широкому спектру доменов, мы также представляем экспериментальные результаты применения нашего подхода к новым изображениям, полученным путем выполнения алгоритмов полу - тонового изображения и обнаружения краев на изображениях из наборов данных в (Saenko et al., 2010 г.; Griffin et al., 2007). Таблица 7.2. Показатели распознавания для различных подходов в четырех доменах (C: Caltech, A: Amazon, D: DSLR, W: Webcam). Используется 10 общих классов Метод C ® A C ® D A ® C A ® W W ® C W ® A D ® A D ® W Metric (Saenko et al., 2010) 33,7 35,0 27,3 36,0 21,7 32,3 30,3 55,6 SGF (Gopalan et al., 2011) 40,2 36,6 37,7 37,9 29,2 38,2 39,2 69,5 GFK (PLS+PCA) (Gong et al., 2012) 46,1 55,0 39,6 56,9 32,8 46,2 46,2 80,2 SDDL (Shekhar et al., 2013) 49,5 76,7 27,4 72,0 29,7 49,4 48,9 72,6 HMP (Manjunath, Chellappa, 1993) 67,7 70,2 51,7 70,0 46,8 61,5 64,7 76,0 DASH-N (1-й слой) (Nguyen et al., 2015) 60,3 79,6 52,2 74,1 45,3 68,7 65,9 76,3 DASH-N (Nguyen et al., 2015) 71,6 81,4 54,6 75,5 50,2 70,4 68,9 77,1 Результаты распознавания различных алгоритмов на 8 парах исходных/ целевых доменов показаны в табл. 7.2. Видно, что DASH-N превосходит все сравниваемые методы в 7 из 8 пар исходных/целевых доменов. Для таких пар, как Caltech-Amazon, Webcam-Amazon или DSLR-Amazon, мы достигли преимущества более чем на 20 % по сравнению со следующим лучшим ал- горитмом без использования в сравнении обуче ния признаков (с 49,5 до 71,6 %, с 49,4 % до 70,4 % и с 48,9 до 68,9 % соответственно). Стоит отметить,\n--- Страница 331 ---\n330  Адаптация домена с использованием неглубоких и глубоких нейросетей что, хотя мы используем генеративный подход для изучения признака, наш метод неизменно обеспечивает лучшее качество, чем (Shekhar et al., 2013), который использует дискриминативное обуче ние вместе с нелинейными ядрами. Также из таблицы видно, что многослойный DASH-N превосходит однослойный DASH-N. В случае адаптации набора данных Caltech-Amazon прирост качества за счет комбинации признаков, полученных из обоих сло- ев, а не только признаков из первого слоя, составляет более 10 % (с 60,3 до 71,6 %). 7.3.3. Инкрементное изучение словаря для адаптации предметной области без учителя Далее мы рассмотрим метод пошагового изучения словаря, в котором для облегчения адаптации выбираются некоторые целевые данные, называемые вспомогательными образцами (supportive samples), как показано на рис. 7.4. Инкрементный характер этого подхода позволяет пользователям выбирать различное количество вспомогательных образцов (в нашем случае – изобра- жений) в соответствии со своим бюджетом или до тех пор, пока не будет достигнута удовлетворительная точность. Вспомогательные образцы близ- ки к исходному домену и обладают двумя свойствами: во-первых, их пред- сказанные метки классов надежны и могут использоваться для построения моделей классификации с более четким разделением; во-вторых, они дей- ствуют как мост, соединяющий два домена и уменьшающий расхождение доменов. С теоретической точки зрения оба свойства важны для адаптации, поэтому имеет смысл вносить вспомогательные образцы в исходный домен. Чтобы добиться монотонного уменьшения несоответствия домена во время адаптации, разработан критерий остановки. Экспериментальные результаты применения данного метода на нескольких широко используемых наборах визуальных данных показывают, что он работает лучше, чем многие совре- менные методы разреженного обуче ния. Уменьшение расхождения доменов Классификатор Исходный доменЦелевой доменDC–1D1 DCD2 Рис. 7.4  Обобщенная схема инкрементного изучения словаря для адапта- ции домена. Исходные словари адаптируются к целевому домену с использова- нием набора вспомогательных образцов. Итерационный характер процедуры гарантирует монотонное уменьшение несоответствия доменов\n--- Страница 332 ---\nАдаптация домена без учителя с использованием словарей  331 Располагая словарем D(k), мы должны выбрать подмножество вспомога- тельных образцов. У нас есть два ограничения на этот выбор. Во-первых, следует исключить вспомогательные образцы, выбранные в предыдущих итерациях, поскольку мы хотим добавить новые данные для адаптации. Во- вто рых, мы выбираем равное количество вспомогательных образцов для каждого класса, чтобы обеспечить баланс классов во время адаптации (Gong et al., 2013). Руководствуясь этими двумя ограничениями, мы выбираем наи- более надежные образцы, которые минимизируют ошибку реконструкции. Затем обновляем расширенный исходный домен, добавляя вспомогательные образцы, и переобучаем словарь. После этого мы проверяем критерий оста- новки, чтобы увидеть, уменьшит ли добавление новых вспомогательных об- разцов расхождение доменов. Обобщенная схема предлагаемого подхода по- казана на рис. 7.4. Алгоритм состоит из следующих основных компонентов: Обновление матрицы достоверности. Мы используем XS = X(0) и XT для обозначения данных из исходного и целевого доменов. Пусть L = [1, …, C] представляет существующий набор меток. Пусть D(0) = [D1(0) | … | DC(0)] обозна- чает исходный словарь, обученный в исходном домене, где Dj(0) обозначает подсловарь, соответствующий классу j. Пусть P Î RNt×C обозначает матрицу достоверности, элементы которой pij Î [0, 1] представляют вероятность того, что целевой образец xit принадлежит классу j. В (k + 1)-й итерации мы обнов- ляем матрицу достоверности P(k+1), используя текущие словари D(k) = [D1(k) | … | DC(k)] для конкретных классов. (7.21) где σ2 – параметр нормализации, а eij обозначает ошибку реконструкции целевого образца x it с использованием Dj(k): eij(k+1) = ||xit – Dj(k) . Zij(k+1)||22. (7.22) Здесь Zij(k+1) – разреженный код. Мы устанавливаем ограничение pij(k+1) толь - ко тогда, когда j является наиболее вероятным классом, к которому принад- лежит образец i. Это ограничение гарантирует, что один и тот же образец не может быть выбран в качестве вспомогательного образца для нескольких классов. Выбор вспомогательного образца. Мы выбираем новые вспомогатель- ные образцы, используя W(k+1), для чего выполняем следующую оптимиза- цию: (7.23) так, что (7.24)\n--- Страница 333 ---\n332  Адаптация домена с использованием неглубоких и глубоких нейросетей где Wj Î RNt×Nt – диагональные матрицы, содержащие j-й столбец матрицы W на диагонали. То есть Wj = diag([w 1j, w2j, …]). Аналогично, Pj = diag([p 1j, p2j, …]). Q – количество вспомогательных образцов для каждого класса. Це- левая функция уравнения (7.23) максимизирует достоверность выбранных вспомогательных образцов. Первое ограничение требует, чтобы вспомога- тельные образцы в (k +1)-й итерации не пересекались с ранее выбранными, что гарантирует добавление новых вспомогательных образцов в исходный домен. Второе ограничение гарантирует, что количество вспомогательных образцов для каждого класса сбалансировано. Решение уравнения (7.23) за- ключается в нахождении соответствующих вспомогательных образцов Q, которые максимизируют достоверность с ограничением, заключающимся в том, что старые вспомогательные образцы исключаются. Расширенное обновление исходного домена. После выбора вспомога- тельных образцов мы обновляем расширенные исходные данные, добавляя взвешенные вспомогательные образцы к предыдущим исходным данным: Xj(k+1) = [Xj(k)|XtWj(k+1)Pjk+1], k = 1, …, C. (7.25) Поскольку метки вспомогательных образцов могут содержать ошибки, каждый выбранный вспомогательный образец взвешивается по его досто- верности. Веса указывают на надежность меток вспомогательных образцов, поэтому образцы с высокой степенью достоверности будут вносить больший вклад в модель. Обновление словаря. Словарь обновляется путем решения следующей задачи оптимизации: (7.26) Мы решаем уравнение (7.26) с использованием метода изучения словаря из статьи (Mairal et al., 2009). Словарь, полученный на предыдущей итерации, используется в качестве начального словаря на следующей итерации. Таким образом, вычислительные затраты относительно невелики. Критерий остановки. Один из тривиальных критериев остановки – от - сутствие новых вспомогательных образцов для одного из классов. Но мы стремимся гарантировать, что процесс адаптации монотонно уменьшает расхождение доменов. Таким образом, ошибка классификации, связанная с целевым доменом, уменьшится, как указано в (Ben-David et al., 2010 г.; Smetana et al., 2009). Поэтому мы разработали меру сходства доменов, ко- торую рассмотрим в следующем разделе, и выполняем адаптацию только тогда, когда сходство доменов увеличивается после каждой итерации. Можно показать, что при добавлении поддерживающих образцов в исходный домен сходство между исходным и целевым доменами будет увеличиваться. Чита- тели могут обратиться к (Lu et al., 2015) для более подробной информации о доказательстве этого свойства. Эксперименты. Мы используем набор данных Office+ Caltech, содержа- щий изображения из четырех доменов: Amazon (A), Webcam (W), DSLR (D) и Caltech (C). Это дает нам 12 пар доменов для тестирования. Во всех доменах\n--- Страница 334 ---\nАдаптация домена без учителя с использованием словарей  333 выбрано 10 общих классов. Для классов A, C, D и W имеется около 100, 100, 15 и 30 изображений соответственно. Мы следуем протоколу, предложенному в (Gong et al., 2013) для создания исходных и целевых данных домена. В на- шем эксперименте используются признаки DeCAF (Donahue et al., 2014). Мы сравниваем два метода без адаптации (NA) и пять современных методов DA без учителя, а именно: SVM и классификация на основе словарного обуче- ния (DLC) – это два метода NA, а интерполяция подпространства с по мощью обуче ния по словарю (SIDL) (Ni et al. al., 2013), Geodesic Flow Kernel (GFK) (Gong et al., 2012), Transfer Joint Matching (TJM) (Long et al., 2014), Landmarks (Gong et al., 2012) и DA-NBNN (Tommasi, Caputo, 2013) относятся к методам DA с обуче нием без учителя. DLC реализован с использованием метода изуче- ния словаря согласно (Mairal et al., 2009), а также применяется в качестве исходного словаря в предлагаемом нами методе. Мы сравнили изменение сходства доменов на рис. 7.5 с результатами клас - сификации в табл. 7.3 и обнаружили, что точность, судя по всему, увеличива- ется, когда значение сходства доменов продолжает расти по мере добавления дополнительных вспомогательных образцов к исходному домену. (a) A в качестве исходного домена (с) W в качестве исходного домена(b) C в качестве исходного домена (d) D в качестве исходного домена Рис. 7.5  Изменение сходства доменов при добавлении вспомога- тельных образцов к исходному домену. В наших экспериментах мы про- должаем адаптацию только до тех пор, пока значение сходства увеличи- вается. A: Amazon, C: Caltech, W: Webcam, D: DSLR Мы показали, что изучение словаря является эффективным подходом к решению проблемы расхождения доменов с обуче нием без учителя. Об- щая идея состоит в том, чтобы проецировать представления данных из не- скольких доменов в одно и то же скрытое пространство, где их распреде- ления более похожи. Вместо того чтобы выполнять это преобразование на одном семантическом уровне, мы также продемонстрировали преимущества иерар хического изучения словаря для постепенной адаптации на несколь- ких семантических уровнях. Наконец, мы демонстрируем преимущества по-\n--- Страница 335 ---\n334  Адаптация домена с использованием неглубоких и глубоких нейросетей степенного добавления в исходный домен выборочных вспомогательных образцов, гарантированно увеличивающих сходство доменов, что обычно приводит к повышению точности классификации. Таблица 7.3. Точность распознавания 12 междоменных пар объектов с обуче нием без учителя. A: Amazon, C: Caltech, W: Webcam, D: DSLR Метод A ® C A ® D A ® W C ® A C ® D C ® W W ® A W ® D W ® C D ® A D ® C D ® WNASVM 85,0 87,9 79,0 91,4 89,8 80,0 75,7 99,4 72,0 87,1 78,8 98,6 DLC 85,3 82,1 75,6 91,3 87,9 78,6 78,4 98,7 76,0 88,1 81,6 99,3 GFK (Gong et al., 2012)77,3 84,7 81,0 88,5 86,0 80,3 81,8 100 73,9 85,8 76,0 97,3 SIDL (Ni et al., 2013) 84,5 81,5 74,2 90,9 89,8 78,3 75,1 100 71,1 87,9 80,1 99,3 TJM (Long et al., 2014)80,1 84,7 75,2 89,0 85,3 76,9 84,8 100 78,0 87,4 77,4 98,6DADA-NBNN (Tommasi, Caputo, 2013)83,4 80,9 76,6 89,6 87,9 80,3 88,0 100 82,4 91,3 86,1 98,0 Landmarks (Gong et al., 2013)84,7 86,0 82,4 92,4 92,3 84,1 84,0 98,7 71,7 77,0 74,4 95,2 Online dictionary (Lu et al., 2015)86,7 92,4 88,5 93,3 88,5 95,6 92,8 100 88,7 93,1 89,1 99,3 Подходы, основанные на словарях, похоже, потеряли популярность из-за более высокой точности методов, основанных на генеративно-состязатель- ных сетях. 7.4. адаптация домена с испо ЛьзоВанием гЛубоКиХ сетей , обу Чаемы Х без уЧитеЛя Глубокие нейронные сети – это мощный класс моделей машинного обуче ния для извлечения осмысленных представлений из изображений. Несмотря на достижение потрясающей точности в нескольких задачах визуального рас - познавания (Ren et al., 2015; He et al., 2016; 2017), нейронные сети очень чув- ствительны к расхождению доменов, т. е. точность нейронных сетей значи- тельно снижается, когда тестовое распределение отличается от обучающего. Чтобы решить проблему смещения домена, в задаче обуче ния используются дополнительные функции потерь, предотвращающие дрейф исходного и це- левого пространств признаков. Схема адаптации домена с использованием глубоких нейросетей показана на рис. 7.6. Исходное и целевое распределения признаков сначала получа- ются путем пропускания соответствующих изображений через сеть призна- ков F. Их распределения признаков выглядят непохожими из-за смещения\n--- Страница 336 ---\nАдаптация домена с использованием глубоких сетей, обучаемых без учителя  335 домена. Во время адаптации домена расстояние между этими пространства- ми признаков сводится к минимуму при одновременном обучении модели классификатора на размеченных исходных данных. Размеченное исходное распределение Неразмеченное целевое распространение Домен: РеальностьСобака ДомСлонСеть признаков (f)Сеть признаков (f)Минимизация дистанции между распределениями Домен: Искусство Классификатор Потеря классификации ℒcls(f(xs), ys) Рис. 7.6  Адаптация домена с использованием глубоких нейронных сетей. Исходное и целевое пространства объектов сближаются с использованием це- левой функции минимизации расстояния между распределениями Для решения задачи адаптации домена было предложено несколько дис - криминационных и генеративных методов (Ganin et al., 2016; Long et al., 2016; 2017; Hoffman et al., 2018; Sankaranarayanan et al., 2018). В дискри- минационных методах вместе с целевой функцией классификации обычно используют дополнительную функцию потерь, чтобы предотвратить дрейф пространства признаков. Эти функции обычно направлены на минимиза- цию расстояния между исходными и целевыми пространствами признаков (Ganin et al., 2016; Long et al., 2016; 2017). В генеративных подходах генера- тивная модель (обычно генеративно-состязательная сеть) обучается моде- лировать распределение исходных и целевых изображений. Эти знания об изученных распределениях затем используются для обеспечения инвари- антности домена во время обуче ния (Hoffman et al., 2018; Sankaranarayanan et al., 2018). 7.4.1. Дискриминационные подходы к адаптации предметной области Пусть F обозначает глубокую нейронную сеть для извлечения представле- ний признаков из изображений. Сеть F обычно является сверточной сетью, которая получает входные изображения и возвращает вектор на выходе. Пусть C обозначает сеть-классификатор, которая принимает представление признаков в качестве входных данных и возвращает логиты классификации. Пусть (xs,ys) обозначают пары вход–выход исходного домена, а (xt) обознача- ют входы целевого домена. Чтобы обучить модель классификатора в исходном домене, мы миними- зируем кросс-энтропийную потерю как\n--- Страница 337 ---\n336  Адаптация домена с использованием неглубоких и глубоких нейросетей (7.27) Результирующий классификатор будет плохо работать в целевом домене из-за расхождения доменов. Дрейф пространства признаков сводится к ми- нимуму с по мощью состязательных потерь домена, которые показывают, насколько различаются исходные и целевые представления признаков. Что- бы найти состязательную потерю домена, мы используем дополнительную сеть, называемую дискриминатором (D), как показано на рис. 7.7. Дискри- минатор принимает в качестве входных данных представления признаков, полученные из сети F, и предсказывает, из какого домена они поступили – исходного или целевого. Затем выполняется состязательное обуче ние сети F, чтобы максимизировать потери дискриминатора. Считается, что обуче ние сошлось, когда дискриминатор не справился со своей задачей, т. е. когда ис - ходное и целевое распределения признаков неразличимы. Собака ДомСлон Сеть признаков (f)Сеть признаков (f)Исходный домен Целевой доменДискриминатор (D)Источник Цель Рис. 7.7  Состязательное обуче ние при адаптации домена Для достижения вышеуказанной цели сеть дискриминатора максимизи- рует следующую функцию потерь: (7.28) Во время обуче ния модели оптимизируются с использованием комбина- ции потери классификации и состязательной потери домена: (7.29) Член λ управляет весом, придаваемым состязательному члену домена в целевой функции. Это гиперпараметр, который необходимо настраивать при обучении алгоритма. Полученный алгоритм получил название Domain Adversarial Training (Ganin et al., 2016).\n--- Страница 338 ---\nАдаптация домена с использованием глубоких сетей, обучаемых без учителя  337 Сети F, C и D обычно реализуются как нейронные сети. В частности, сеть F – это глубокая сверточная сеть (такая как Resnet), а сети C и D – многослой- ные персептроны. У Ганина и др. (Ganin et al., 2016) состязательная потеря реализована при помощи слоя обращения градиента, в котором градиенты, поступающие от сети дискриминатора с потерей Ldisc, модулируются с коэф- фициентом –λ перед обновлением сети признаков. Отметим, что сеть при- знаков также обновляется с использованием потери классификации. Все сети оптимизированы с использованием стохастического градиентного спуска. Эффективность состязательной адаптации домена по сравнению с дру - гими методами глубокой адаптации показана в табл. 7.4 для набора данных Office-31, который охватывает три домена – Amazon (A), DSLR (D) и Webcam (W). Задача состоит в том, чтобы выполнить классификацию 31 категории объектов. В табл. 7.4 мы видим, что состязательная адаптация домена обеспе- чивает значительный прирост точности по сравнению с базовыми моделями, которые обучаются только на исходном домене без какой-либо адаптации. Кроме того, модель также работает лучше, чем два других метода дискри- минационной адаптации – Deep Domain Confusion (Tzeng et al., 2014) и Deep Adaptation Networks (Long et al., 2015). Таблица 7.4. Точность состязательной адаптации домена (%) для набора данных Office-31. A: Amazon, D: DSLR, W: Webcam Метод A W D W W D Только источник 64,2 96,1 97,8 DDC (Tzeng et al., 2014) 61,8 95,0 98,5 DAN (Long et al., 2015) 68,5 96,0 99,0 Состязательное обуче ние (Ganin et al., 2016) 73,0 96,4 99,2 Другие меры расстояния. Несмотря на то что состязательное изучение домена является популярным выбором для дискриминационной адаптации, для измерения несоответствия распределения между исходным и целевым распределениями также можно использовать другие меры расстояния. Дву - мя такими мерами расстояния являются максимальное среднее расхождение (maximum mean discrepancy, MMD) и расстояние Вассерштейна (Wasserstein distance). В MMD расстояние между распределениями вычисляется как рас - стояние между средними представлениями, выраженными с использовани- ем воспроизводящего ядра гильбертова пространства (reproducing kernel Hil- bert space, RKHS). Затем выполняется адаптация путем минимизации MMD между исходным и целевым распределениями признаков (Long et al., 2015; 2016). В альтернативном методе в качестве меры расстояния между исходным и целевым распределениями признаков используют расстояние Вассер - штейна. Двойственная форма расстояния Вассерштейна вычисляется с ис - пользованием функции дискриминатора. Адаптация осуществляется путем минимизации двойственного расстояния Вассерштейна между исходными и целевыми картами признаков (Shen et al., 2018). Эти методы работают не хуже состязательной адаптации.\n--- Страница 339 ---\n338  Адаптация домена с использованием неглубоких и глубоких нейросетей Метод псевдометок. В отличие от состязательных методов, при псевдо- маркировке/самообучении (Saito et al., 2017; Zou et al., 2018; 2019) для нераз- меченных целевых объектов генерируются псевдометки с использованием текущей модели. Поскольку псевдометки, как правило, зашумлены, наиболее надежные псевдометки выбирают с использованием показателей оценки достоверности. Одним из таких показателей является согласованность ан- самбля классифицирующих моделей (Saito et al., 2017). Затем полученные псевдометки используются для переобучения модели с целью повышения ее прогностической способности в целевом домене. Этот процесс повторяется итеративно до сходимости. Данные методы также могут использоваться в со- четании с состязательной адаптацией. Методы, основанные на регуляризации. Согласно таким методам, сети обучаются с дополнительным членом регуляризации наряду с потерей кросс- энтропии для исходного домена. Одной из распространенных функций ре- гуляризации является минимизация энтропии (Vu et al., 2019), при которой минимизируется энтропия целевых логитов. Также заслуживают внимания регуляризация состязательного отсева (Saito et al., 2017) и максимальное расхождение классификатора (Saito et al., 2018), в котором сеть признаков обучается минимизировать расхождение в логитах, возникающее из различ- ных моделей классификатора, которые обучаются в комбинации. Расширение до адаптации с несколькими источниками. В адаптации с несколькими источниками цель состоит в том, чтобы адаптировать не- сколько исходных распределений к целевому распределению. Адаптация нескольких исходных доменов очень полезна на практике, поскольку наборы данных реального мира обычно содержат смесь нескольких скрытых до- менов. Цель состязательного обуче ния может быть расширена до структуры с несколькими источниками с использованием k-стороннего классификатора домена, как это сделано в (Xu et al., 2018). В работе (Yang et al., 2020) при вы- боре лучших образцов исходного домена для адаптации к данному целевому домену применяется механизм взвешивания. В случаях, когда метки домена доступны, в многосторонней состязательной адаптации может использо- ваться исследование скрытого домена с целью извлечения неизвестных ме- ток домена (Mancini et al., 2018). 7.4.2. Генеративные подходы к адаптации домена В генеративных методах адаптации домена цель заключается в том, чтобы использовать генеративные модели для оценки исходного и целевого рас - пределений. Затем обученные генеративные модели используются в про- цессе адаптации для изучения представлений, не зависящих от домена. Три популярных варианта генеративных моделей – это генеративно-состязатель- ные сети (GAN) (Goodfellow et al., 2014), вариационные автоэнкодеры (VAE) (Kingma, Welling, 2013) и нормализующие потоки (Papamakarios et al., 2019). Сети GAN широко использовались для адаптации домена, поскольку они очень успешно генерировали образцы с высокой точностью.\n--- Страница 340 ---\nАдаптация домена с использованием глубоких сетей, обучаемых без учителя  339 Генеративные состязательные сети Пусть {x i}i=1:N будут образцами изображений, соответствующими входному распределению. Целью GAN (Goodfellow et al., 2014) является обуче ние мо- дели, позволяющей генерировать образцы изображений, напоминающие входное распределение. Для этого GAN обучает модель G, которая отображает выборки из скрытого пространства в пространство входных изображений. Скрытое пространство обычно моделируется с использованием известного управляемого распределения, такого как многомерное изотропное гауссово распределение. Как только модель G обучена, мы можем синтезировать изо- бражения, делая выборки из скрытого распределения и подавая их на вход генеративной модели G. Для обуче ния генератора G мы используем вторую модель, называемую дискриминатором (D), или критикующей сетью. Назначение дискриминато- ра состоит в том, чтобы различать изображения, поступающие из реального и сгенерированного распределений. Это задача бинарной классификации, когда реальные образцы рассматриваются как один класс, а сгенерирован- ные образцы рассматриваются как второй класс. Модель генератора G обуча - ется так, чтобы дискриминатор не справился с задачей различения. Модели G и D реализованы с использованием глубоких нейронных сетей, как пока- зано на рис. 7.8. Следовательно, целевая функция GAN может быть записана следующим образом: (7.30) Член внутри квадратных скобок является отрицательным значением по- тери бинарной классификации для классификации образцов, взятых из ре- ального распределения pdata или сгенерированного распределения G(pz). В то время как дискриминатор D стремится максимизировать целевую функцию, генератор минимизирует ее, что приводит к минимаксной игре для двух игроков. Общая цель состоит в том, чтобы найти седловую точку в этой игре. При сходимости генератор синтезирует реалистичные изображения, а дискриминатор не может различить реальное и сгенерированное распре- деления. Сети GAN очень сложно обучать из-за минимаксного характера целевой функции. На практике используется несколько приемов стабилизации, чтобы заставить GAN сходиться к хорошим решениям (Liu et al., 2020). Например, к этим приемам относятся использование расстояния Вассерштейна (Arjov - sky et al., 2017), применение спектральной нормализации в архитектуре сети (Miyato et al., 2018), методы регуляризации, такие как уменьшение веса (Liu et al., 2020), штраф за градиент (Gulrajani et al., 2017) и потери при сопостав- лении признаков (Liu et al., 2020). Условный синтез изображений. В предыдущем разделе мы сосредото- чились на безусловном синтезе изображений, целью которого было просто генерировать изображения, напоминающие образцы изображений на входе. В условном синтезе изображений мы заинтересованы в создании выборок,\n--- Страница 341 ---\n340  Адаптация домена с использованием неглубоких и глубоких нейросетей обусловленных некоторыми интересующими нас переменными. Одним из примеров является синтез, обусловленный классом, когда требуется гене- рировать изображения, принадлежащие одному конкретному классу. Ког - да обусловливающая переменная сама является изображением, это задача трансляции изображения в изображение. Но в данном случае нас интересует трансляция изображения, принадлежащего одному домену, в изображение, принадлежащее другому домену. В условном синтезе изображения обуслов- ливающая переменная используется в качестве входных данных в дополне- ние к скрытому вектору. Вектор шума N(0, I )ГенераторРеальные образцы Сгенерированные образцыДискриминаторНастоящий/ поддельный Рис. 7.8  Структура GAN Когда речь идет об адаптации домена, модели преобразования изображе- ния в изображение являются одним из предпочтительных вариантов гене- ративных моделей. Поскольку нас интересует адаптация домена на основе обуче ния без учителя, мы используем непарные модели перевода изобра- жения в изображение, в которых исходное и целевое изображения не имеют никаких взаимных соответствий. Идея состоит в том, чтобы транслировать изображения исходного домена так, чтобы они выглядели как изображения целевого домена, а затем обучить классификатор на транслированных об- разцах исходного домена, используя метки источника в качестве эталона. Затем обученный классификатор можно использовать для тестового прог - нозирования в целевом домене. CycleGAN: это популярная модель для непарного преобразования изобра- жения в изображение. Пусть X и Y обозначают два домена, между которыми должна транслировать изображения обучаемая модель. В CycleGAN мы ис - пользуем две модели – прямую модель G, которая переводит изображения из домена X в домен Y, и обратную модель F, которая переводит изображения из домена Y в домен X. Дискриминаторная сеть DX используется для полу - чения состязательных потерь, чтобы гарантировать, что выборки, созданные сетью F, неотличимы от реального распределения X. Точно так же второй дискриминатор DY способствует тому, чтобы выборки, созданные G, были неотличимы от домена Y. На рис. 7.9 показано строение CycleGAN.\n--- Страница 342 ---\nАдаптация домена с использованием глубоких сетей, обучаемых без учителя  341 DYDY DX DXY Y YX X XGG Gх y хˆ yˆ Yˆ Xˆ FF F Потеря согласованности циклаПотеря согласованности цикла (a) (b) (c) Рис. 7.9  (a) Структура CycleGAN, (b) состязательная потеря и потеря согласо- ванности цикла для прямой модели, (c) состязательная потеря и потеря согла- сованности цикла для обратной модели В то время как потери дискриминатора способствуют реалистичности сге- нерированных выборок, в целевую функцию не входит член принудительно- го сохранения контента. То есть невозможно предотвратить сопоставление выборки из одного домена (например, все изображения кошек) с другим семантическим классом в другом домене (например, изображения собак). Чтобы предотвратить это, в задаче используется член согласованности цик - ла. Идея состоит в том, чтобы гарантировать, что применение прямой и об- ратной карт признаков к одному и тому же образцу возвращает входные данные, т. е. F(G(x)) ≈ x и G(F(y)) ≈ y. Для согласованности цикла обычно ис - пользуют потери L1. (7.31) Модель CycleGAN обучается с использованием комбинации состязатель- ных потерь и потерь согласованности цикла. L = Ladv1 + Ladv2 + λLcyc. (7.32) В ходе эксперимента мы обучали CycleGAN на наборах данных из следую- щих доменов: лошади и зебры, зима и лето, аэрофотоснимки и карты Google. Мы установили, что изображения переводятся из одного домена в другой с сохранением содержимого. На рис. 7.10 показана трансляция изображения из аэрофотоснимка в карту Google. Реконструкция F(G(x)) хорошо аппрокси- мирует входное изображение x, что подтверждает значимость члена согла- сованности цикла для сохранения содержимого. Кроме того, сгенерирован- ные выборки реалистичны, что показывает эффективность состязательных потерь. Адаптация домена на основе CycleGAN. В предыдущем разделе мы об- судили модель CycleGAN и то, как ее можно использовать для непарного преобразования изображения в изображение. Теперь мы покажем, как эту модель можно использовать для адаптации домена с обуче нием без учителя (Hoffman et al., 2018). Сначала модель CycleGAN обучается трансляции изображений между ис - ходным и целевым доменами. Затем модель задачи (модель классификации/\n--- Страница 343 ---\n342  Адаптация домена с использованием неглубоких и глубоких нейросетей сегментации) обучается на транслированных исходных изображениях с ис - пользованием исходных меток в качестве исходных данных. Чтобы модель задачи хорошо обучалась, на картах признаков транслированных исходных изображений и истинных целевых изображений используется дополнитель- ная потеря дискриминатора. Это гарантирует, что распределение признаков транслированных исходных изображений и целевых изображений будет со- впадать. Схема этого фреймворка, также известного как CyCADA (Hoffman et al., 2018), изображена на рис. 7.11. Реконструкция F(G(x)) Выход G(x) Вход x Рис. 7.10  Результаты работы CycleGAN. Входные изображения пока- заны на левой панели, а прямой и обратный переносы между доменами показаны на средней и правой панелях соответственно Минимизация дистрибутивного расстояния с по мощью генератив- ных моделей. Альтернативный подход к генеративной адаптации домена заключается в использовании GAN для минимизации дистрибутивного рас - стояния. В разделе 7.4.1 мы говорили, что адаптация домена формулирует - ся как задача минимизации дистрибутивного расстояния между исходным и целевым распределениями признаков. Вместо того чтобы напрямую вы- полнять минимизацию расстояния в пространстве признаков, было предло- жено спроецировать признак обратно в пространство пикселей с по мощью\n--- Страница 344 ---\nАдаптация домена с использованием глубоких сетей, обучаемых без учителя  343 GAN и выполнить минимизацию дистрибутивного расстояния в этом про- странстве проецируемого изображения (рис. 7.12). Авторы метода (Sanka- ranarayanan et al., 2018) назвали этот подход Generate to Adapt. Реконструированное исходное изображение Потеря циклаПотеря задания Потеря GANПотеря GAN Потеря семантической согласованностиGT->S Dtest DT GS->TfS fSfT fT Исходное изображениеПрогноз источника Метка источника Исходное изображение, стилизованное под целевоеЦелевое изображение Рис. 7.11  Схема фреймворка CyCADA Проецирование признаков обратно в пространство изображения имеет два основных преимущества: во-первых, пропускная способность сети дис - криминатора эффективно увеличивается благодаря этапу проецирования. Во-вторых, этап проецирования помогает сохранить семантическое содер- жание в сгенерированных признаках. Иначе говоря, это предотвращает сопо- ставление целевых признаков из одного класса с другим классом, поскольку реконструирующая сеть обеспечивает обучающий сигнал при сохранении семантического содержания. Структура фреймворка Generate to Adapt показана на рис. 7.12. Признаки исходного и целевого изображений извлекаются с по мощью сети признаков F. Полученные признаки затем передаются через два потока: первый поток – это ветвь классификации, которая обучается с использованием перекрестной энтропийной потери в исходном домене. Второй поток – это ветвь мини- мизации расстояния. В этом потоке исходные и целевые признаки сначала инвертируются обратно в пространство изображения с использованием сети генератора G. Затем сгенерированные изображения проходят через дискри- минатор, который различает, получены ли эти изображения из реального (исходного) или поддельного (целевого) домена. Кроме того, он также вы- полняет прогнозирование меток классов для реконструированных исходных изображений, используя исходные метки в качестве эталона. Это помогает достичь согласованности классов в реконструированных изображениях. Затем сеть признаков F подвергается состязательному обуче нию, чтобы целевые реконструкции выглядели как исходные. Это происходит только тогда, когда исходное и целевое распределения признаков перекрываются. Кроме того, сигнал, полученный из потока 1, помогает сети признаков полу - чать согласованные по классам прогнозы.\n--- Страница 345 ---\n344  Адаптация домена с использованием неглубоких и глубоких нейросетей Фаза обучения Фаза тестирования Изображения исходного домена (MNIST)Исходные/целевые изображения Изображения целевого домена (USPS)Средство извлечения признаков (F-сеть) Средство извлечения признаков (F-сеть)Класси- фикатор (сеть C) Класси- фикатор (сеть C)Дискри - минатор (D-сеть)Генератор (G-сеть)Метки 3, 6 Метки 3, 6Метки 3, 6Прогноз подлинностиПоток 1 Поток 2Классы Nc Классы NcКлассы Nc2 класса Сгенерированные изображения (как исходные)Представление Рис. 7.12  Схема фреймворка Generate to Adapt Результаты. В табл. 7.5 представлены результаты генеративных подходов к задачам междоменной классификации с использованием наборов изобра- жений цифр. В экспериментах использовались три набора данных: MNIST, USPS и SVHN. В каждом из вариантов адаптации мы наблюдаем, что исход- ный базовый уровень обеспечивает низкую точность. И CyCADA, и Gener - ate to Adapt обеспечивают значительный прирост точности по сравнению с базовой моделью. Кроме того, они также превосходят CoGAN и PixelDA, два других подхода к адаптации на основе GAN. Таблица 7.5. Качество адаптации домена с использованием генеративных подходов к набору данных Digits. Критерием является точность классификации в %. MN – MNIST, US – USPS, SV – SVHN Метод MS US US MN SV MN Базовая модель 79,1 57,1 60,3 CoGAN (Liu and Tuzel, 2016) 61,8 95,0 98,5 PixelDA (Bousmalis et al., 2017) 73,0 96,4 99,2 CyCADA (Hoffman et al., 2018) 95,6 96,5 90,4 Generate to Adapt (Sankaranarayanan et al., 2018) 92,8 95,3 92,4 В табл. 7.6 представлены результаты выполнения задачи междоменной семантической сегментации. Исходным доменом является GTA-5, который представляет собой синтетический набор данных уличных сцен, а целевым доменом является реальный набор данных Cityscapes (городские пейзажи). Мы использовали архитектуру FCN на основе VGG для сети признаков (San- karanarayanan et al., 2018). Приведены показатели пересечения объединений (intersection of union, IoU) для каждого семантического класса вместе со сред- ними показателями IoU (mIoU). Мы наблюдали, что как CyCADA, так и Gen- erate to Adapt достигают значительного увеличения IoU по сравнению с ис - ходной базовой моделью. Однако остается огромный разрыв по сравнению\n--- Страница 346 ---\nАдаптация домена с использованием глубоких сетей, обучаемых без учителя  345Таблица 7.6. Производительность семантической сегментации в адаптации GTA-5 > Cityscapes. Сообщаются баллы IoU для каждой категории и средние баллы IoU (mIoU) Метод Дорога Тротуар Здание Стена Забор Pole Фонарь Знак Растения Почва Небо Человек Наездник Автомобиль Грузовик Автобус Трамвай Мотоцикл Велосипед mloU Только источник 73,5 21,3 72,3 18,9 14,3 12,5 15,1 5,3 77,2 17,4 64,3 43,7 12,8 75,4 24,8 7,8 0,0 4,9 1,8 29,6 CyCADA 79,1 33,1 77,9 23,4 17,3 32,1 33,3 31,8 81,5 26,7 69,0 62,8 14,7 74,5 20,9 25,6 6,9 18,8 20,4 39,5 Generate to Adapt 88,0 30,5 78,6 25,2 23,5 16,7 23,5 11,6 78,7 27,2 71,9 51,3 19,5 80,4 19,8 18,3 0,9 20,8 18,4 37,1 Только цель 96,5 74,6 86,1 37,1 33,2 30,2 39,7 51,6 87,3 52,6 90,4 60,1 31,7 88,4 54,9 52,3 34,7 33,6 59,1 57,6\n--- Страница 347 ---\n346  Адаптация домена с использованием неглубоких и глубоких нейросетей с целевой моделью, которая представляет собой модель оракула, обученную с использованием истинных целевых меток. В табл. 7.7 представлено сравнение подходов на основе многообразий, словаря и GAN для адаптации домена без учителя в наборе данных Office. Методы на основе GAN обеспечивают наилучшее качество. Таблица 7.7. Сравнение методов многообразий, словаря и глубокого обуче ния для адаптации домена без учителя Источник ЦельМногообразия (2012)Словари (2015)Глубокое обучение (2017)Глубокое обучение и GAN (2018) Webcam DSLR 71,2 99,5 99,8 DSLR Webcam 68,8 72 98,2 97,9 Amazon Webcam 55,6 72 62,4 86,5 Amazon DSLR 64 87,7 DSLR Amazon 48,9 52 72,8 Webcam Amazon 49,4 48,4 71,4 7.5. заКЛюЧение В этой главе мы обсудили методы решения задачи адаптации домена, ос - нованные на дифференциальной геометрии, разреженном представлении и глубоких нейронных сетях. Были рассмотрены два широких класса мето- дов: дискриминативные и генеративные. В дискриминативных методах мы обучаем модель классификатора, используя дополнительные потери, что- бы сделать исходные и целевые распределения признаков похожими. Для этой задачи используется целевая функция минимизации дистрибутивного расстояния. В генеративных методах мы применяем для адаптации домена генеративную модель. Один из подходов заключается в обучении проме- жуточных словарей и междоменной GAN для сопоставления изображений из исходного и целевого доменов и обуче ния модели классификатора на преобразованных целевых изображениях. Другой подход основан на мини- мизации дистрибутивного расстояния и применяет GAN для минимизации этого расстояния. Все эти подходы проверены на задачах междоменного распознавания и семантической сегментации. Литературные исто ЧниКи Aharon M., Elad M., Bruckstein A., 2006. K-SVD: an algorithm for designing over - complete dictionaries for sparse representation. IEEE Transactions on Signal Processing 54 (11), 4311–4322. Arjovsky M., Chintala S., Bottou L., 2017.Wasserstein generative adversarial net - works. In: International Conference on Machine Learning, pp. 214–223.\n--- Страница 348 ---\nЛитературные источники  347 Ben-David S., Blitzer J., Crammer K., Kulesza A., Pereira F., Vaughan J. W., 2010. Atheory of learning fromdifferent domains. Machine Learning 79 (1), 151–175. Bo L., Xiaofeng R., Dieter F., 2011. Hierarchical matching pursuit for image classi- fication: Architecture and fast algorithms. In: Advances in Neural Information Processing Systems, vol. 24. Boureau Y. L., Ponce J., LeCun Y., 2010. A theoretical analysis of feature pooling in visual recognition. In: Proceedings of the 27th International Conference on Machine Learning (ICML-10), pp. 111–118. Bousmalis K., Silberman N., Dohan D., Erhan D., Krishnan D., 2017. Unsupervised pixel-level domain adaptation with generative adversarial networks. In: Pro- ceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3722–3731. Blitzer J., Crammer K., Kulesza A., Pereira F., Wortman J., 2008. Learning bounds for domain adaptation. Blitzer J., Kakade S., Foster D., 2011. Domain adaptation with coupled subspaces. In: Proceedings of the Fourteenth International Conference on Artificial Intelli- gence and Statistics, pp. 173–181. JMLR Workshop and Conference Procee dings. Boureau Y. L., 2012. Learning hierarchical feature extractors for image recognition. Doctoral dissertation. New York University. Bruckstein A. M., Donoho D. L., Elad M., 2009. From sparse solutions of systems of equations to sparse modeling of signals and images. SIAM Review 51 (1), 34–81. Chen S. S., Donoho D. L., Saunders M. A., 2001. Atomic decomposition by basis pursuit. SIAM Review 43 (1), 129–159. Daume III H., Marcu D., 2006. Domain adaptation for statistical classifiers. Journal of Artificial Intelligence Research 26, 101–126. Donahue J., Jia Y., Vinyals O., Hoffman J., Zhang N., Tzeng E., Decaf Darrell T., 2014. A deep convolutional activation feature for generic visual recognition. In: In- ternational Conference on Machine Learning, pp. 647–655. PMLR. Duan L., Tsang I. W., Xu D., Chua T. S., 2009. Domain adaptation from multiple sources via auxiliary classifiers. In: Proceedings of the 26th Annual Interna- tional Conference on Machine Learning, pp. 289–296. Duan L., Xu D., Exploiting Web Chang S. F., 2012. Images for event recognition in consumer videos: a multiple source domain adaptation approach. In: Proceed- ings of the IEEE Conference on Computer Vision and Pattern Recognition. Providence, RI, pp. 1338–1345. Elad M., Figueiredo M. A., Ma Y., 2010. On the role of sparse and redundant repre- sentations in image processing. Proceedings of the IEEE 98 (6), 972–982. Engan K., Aase S. O., Husoy J. H., 1999. Method of optimal directions for frame de- sign. In: 1999 IEEE International Conference on Acoustics, Speech, and Signal Processing. In: Proceedings ICASSP99, vol. 5. IEEE, pp. 2443–2446. (Cat. No. 99CH36258.) Ganin Y., Ustinova E., Ajakan H., Germain P., Larochelle H., Laviolette F., Marchand M., Lempitsky V., 2016. Domain-adversarial training of neural networks. Journal of Machine Learning Research 17 (1), 2096–2130. Gong B., Grauman K., Sha F., 2013. Connecting the dots with landmarks: discrimi- natively learning domaininvariant features for unsupervised domain adapta- tion. In: International Conference on Machine Learning, pp. 222–230. PMLR.\n--- Страница 349 ---\n348  Адаптация домена с использованием неглубоких и глубоких нейросетей Gong B., Shi Y., Sha F., Grauman K., 2012. Geodesic Flow Kernel for Unsupervised Domain Adaptation. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, vol. 16. IEEE, pp. 2066–2073. Goodfellow I. J., Pouget-Abadie J., Mirza M., Xu B., Warde-Farley D., Ozair S., Cour- ville A., Bengio Y., 2014. Generative adversarial networks. arXiv preprint. arXiv: 1406.2661. Gopalan R., Li R., Chellappa R., 2011. Domain adaptation for object recognition: an unsupervised approach. In: 2011 International Conference on Computer Vision. IEEE, pp. 999–1006. Gopalan R., Li R., Chellappa R., 2014. Unsupervised adaptation across domain shifts by generating intermediate data representations. IEEE Transactions on Pattern Analysis and Machine Intelligence 36, 2288–2302. Griffin G., Holub A., Perona P., 2007. Caltech-256 object category dataset. Gross R., Matthews I., Cohn J., Kanade T., Baker S., 2010. Multi-pie. Image and Vi- sion Computing 28 (5), 807–813. Gulrajani I., Ahmed F., Arjovsky M., Dumoulin V., Courville A., 2017. ImprovedTrain- ing of Wasserstein gans. arXiv preprint. arXiv:1704.00028. He K., Zhang X., Ren S., Sun J., 2016. DeepResidual learning for image recogni- tion. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770–778. He K., Gkioxari G., Dollár P., Girshick R., 2017. Mask R-CNN. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 2961–2969. Ho H. T., Gopalan R., 2014. Model-driven domain adaptation on product manifolds for unconstrained face recognition. International Journal of Computer Vision 109, 110–125. Hoffman J., Tzeng E., Park T., Zhu J. Y., Isola P., Saenko K., Efros A., Darrell T., 2018. Cycada: cycle-consistent adversarial domain adaptation. In: International Con- ference on Machine Learning, pp. 1989–1998. Jhuo I. H., Liu D., Lee D. T., Chang S. F., 2012. RobustVisual domain adaptation with low-rank reconstruction. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Providence, RI, pp. 2168–2175. Kingma D. P., Welling M., 2013. Auto-encoding variational Bayes. arXiv preprint. arXiv:1312.6114. Kulis Brian, Saenko Kate, Darrell Trevor, 2011. What you saw is not what you get: Domain adaptation using asymmetric kernel transforms. In: CVPR 2011. IEEE, pp. 1785–1792. Lee J., Moghaddam B., Pfister H., Machiraju R., 2005. A bilinear illumination model for robust face recognition. In: Tenth IEEE International Conference on Com- puter Vision (ICCV’05), vol. 2. IEEE, pp. 1177–1184. Liu M. Y., Tuzel O., 2016. Coupled generative adversarial networks. arXiv preprint. arXiv:1606.07536. Liu M. Y., Huang X., Yu J., Wang T. C., Mallya A., 2020. Generative adversarial networks for image and video synthesis: algorithms and applications. arXiv preprint. arXiv:2008.02793. Long M., Wang J., Ding G., Sun J., Yu P. S., 2014. Transfer joint matching for unsu- pervised domain adaptation. In: Proceedings of the IEEE Conference on Com- puter Vision and Pattern Recognition, pp. 1410–1417.\n--- Страница 350 ---\nЛитературные источники  349 Long M., Cao Y., Wang J., Jordan M. , 2015. Learning transferable features with deep adaptation networks. In: International Conference on Machine Learning, pp. 97–105. Long M., Zhu H., Wang J., Jordan M. I., 2016. Unsupervised domain adaptation with residual transfer networks. arXiv preprint. arXiv:1602.04433. Long M., Zhu H., Wang J., Jordan M. I., 2017. Deep transfer learning with joint adaptation networks. In: International Conference on Machine Learning, pp. 2208–2217. Lu B., Chellappa R., Nasrabadi N. M., 2015. Incremental dictionary learning for unsupervised domain adaptation. In: BMVC, pp. 108.1–108.12. Lui Y. M., Beveridge J. R., Kirby M., 2010. Action classification on product mani- folds. In: 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. IEEE, pp. 833–839. Lui Y. M., 2012. Human gesture recognition on product manifolds. Journal of Ma- chine Learning Research 13 (1), 3297–3321. Mairal J., Bach F., Ponce J., Sapiro G., 2009. Online dictionary learning for sparse coding. In: Proceedings of the 26th Annual International Conference on Ma- chine Learning, pp. 689–696. Mairal J., Bach F., Ponce J., 2011. Task-driven dictionary learning. IEEE Transac - tions on Pattern Analysis and Machine Intelligence 34 (4), 791–804. Mancini M., Porzi L., Bulo S. R., Caputo B., Ricci E., 2018. Boosting domain adapta- tion by discovering latent domains. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3771–3780. Manjunath B. S., Chellappa R., 1993. A unified approach to boundary perception: edges, textures, and illusory contours. IEEE Transactions on Neural Networks 4 (1), 96–108. Mansour Y., Mohri M., Rostamizadeh A., 2009. Domain adaptation: learning bounds and algorithms. arXiv preprint. arXiv:0902.3430. Miyato T., Kataoka T., Koyama M., Yoshida Y., 2018. Spectral normalization for generative adversarial networks. arXiv preprint. arXiv:1802.05957. Nguyen H. V., Ho H. T., Patel V. M., Chellappa R., 2015. DASH-n: joint hierarchical domain adaptation and feature learning. IEEE Transactions on Image Process- ing 24 (12), 5479–5491. Nguyen H. V., Patel V. M., Nasrabadi N. M., Chellappa R., 2012. Sparse embedding: a framework for sparsity promoting dimensionality reduction. In: Proceedings of the European Conference on Computer Vision. Springer, Berlin, Heidelberg, pp. 414–427. Ni J., Qiu Q., Chellappa R., 2013. Subspace interpolation via dictionary learning for unsupervised domain adaptation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Portland, oR, pp. 692–699. Olshausen B. A., Field D. J., 1996. Emergence of simple-cell receptive field proper - ties by learning a sparse code for natural images. Nature 381 (6583), 607–609. Pan Weike, Evan Xiang, Nathan Liu, Qiang Yang, 2010. Transfer learning in collab- orative filtering for sparsity reduction. In: Proceedings of the AAAI Conference on Artificial Intelligence, vol. 24(1). Papamakarios G., Nalisnick E., Rezende D. J., Mohamed S., Lakshminarayanan B., 2019. Normalizing flows for probabilistic modeling and inference. arXiv pre- print. arXiv:1912.02762.\n--- Страница 351 ---\n350  Адаптация домена с использованием неглубоких и глубоких нейросетей Park Sung Won, Savvides Marios, 2011a. The multifactor extension of Grassmann manifolds for face recognition. In: 2011 IEEE International Conference on Auto matic Face & Gesture Recognition (FG). IEEE, pp. 464–469. Park Sung Won, Savvides Marios, 2011b. Multifactor analysis based on factor- dependent geometry. In: CVPR 2011. IEEE, pp. 2817–2824. Patel V. M., Gopalan R., Li R., Chellappa R., 2015. Visual domain adaptation: a sur - vey of recent advances. IEEE Signal Processing Magazine 32 (3), 53–69. Patil Y. C., Rezaiifar R., Krishnaprasad P. S., 1993. Orthogonal matching pursuit: recursive function approximation with applications to wavelet decomposition. In: Proceedings of 27th Asilomar Conference on Signals, Systems and Comput - ers. IEEE, pp. 40–44. Ren S., He K., Girshick R., Sun J., 2015. Faster R-CNN: towards real-time object detection with region proposal networks. arXiv preprint. arXiv:1506.01497. Roweis S. T., Saul L. K., 2000. Nonlinear dimensionality reduction by locally linear embedding. Science 290 (5500), 2323–2326. Rubinstein R., Bruckstein A. M., Elad M., 2010. Dictionaries for sparse representa- tion modeling. Proceedings of the IEEE 98 (6), 1045–1057. Saenko K., Kulis B., Fritz M., Darrell T., 2010. Adapting visual category models to new domains. In: European Conference on Computer Vision. Springer, Berlin, Heidelberg, pp. 213–226. Saito K., Ushiku Y., Harada T., 2017a. Asymmetric tri-training for unsupervised do- main adaptation. In: International Conference on Machine Learning, pp. 2988– 2997. Saito K., Ushiku Y., Harada T., Saenko K., 2017b. Adversarial dropout regulariza- tion. arXiv preprint. arXiv:1711. 01575. Saito K., Watanabe K., Ushiku Y., Harada T., 2018. Maximum classifier discrepancy for unsupervised domain adaptation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3723–3732. Sankaranarayanan S., Balaji Y., Chellappa R., 2018. Adapting across Domains Using Generative Adversarial Networks. Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Spotlight paper). Salt Lake City, UT. Sankaranarayanan S., Balaji Y., Chellappa R., 2008. Learning from Synthetic Data: Semantic Segmentation across Domain Shift. (Spotlight Paper). In: Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recogni- tion, Salt Lake City, UT. Sharma A., Jacobs D. W., 2011. Bypassing synthesis: PLS for face recognition with pose, low-resolution and sketch. In: CVPR 2011. IEEE, pp. 593–600. Sharma A., Kumar A., Daume H., Jacobs D. W., 2012. Generalized multiview analy - sis: a discriminative latent space. In: 2012 IEEE Conference on Computer Vision and Pattern Recognition. IEEE, pp. 2160–2167. Shekhar S., Patel V. M., Nguyen H. V., Chellappa R., 2013. Generalized domain- adaptive dictionaries. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 361–368. Shen J., Qu Y., Zhang W., Wasserstein Yu Y., 2018. Distance guided representation learning for domain adaptation. In: Proceedings of the AAAI Conference on Artificial Intelligence, vol. 32 (1).\n--- Страница 352 ---\nЛитературные источники  351 Shi Y., Sha F., 2012. Information-theoretical learning of discriminative clusters for unsupervised domain adaptation. In: Proceedings of International Conference on Machine Learning, pp. 1079–1086. Smetana Judith G., Villalobos Myriam, Tasopoulos-Chan Marina, Gettman Denise C., Campione-Barr Nicole, 2009. Early and middle adolescents’ disclosure to parents about activities in different domains. Journal of Adolescence 32 (3), 693–713. Tenenbaum J. B., De Silva V., Langford J. C., 2000. A global geometric framework for nonlinear dimensionality reduction. Science 290 (5500), 2319–2323. Tommasi T., Caputo B., 2013. Frustratingly easy domain adaptation. In: Proceed- ings of the IEEE International Conference on Computer Vision, pp. 897–904. Tropp J. A., 2004. Greed is good: algorithmic results for sparse approximation. IEEE Transactions on Information Theory 50 (10), 2231–2242. Tzeng E., Hoffman J., Zhang N., Saenko K., Darrell T., 2014. Deep domain confusion: maximizing for domain invariance. arXiv preprint. arXiv:1412.3474. Vageeswaran P., Mitra K., Chellappa R., 2013. Blur and illumination robust face recognition via set-theoretic characterization. IEEE Transactions on Image Processing 22 (4), 1362–1372. Vu T. H., Jain H., Bucher M., Cord M., Pérez P., 2019. Advent: adversarial entropy minimization for domain adaptation in semantic segmentation. In: Proceed- ings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2517–2526. Vasilescu M. A., Terzopoulos D., 2002. Multilinear analysis of image ensembles: tensorfaces. In: European Conference on Computer Vision. Springer, Berlin, Heidelberg, pp. 447–460. Vasilescu M. A., Terzopoulos D., 2007. Multilinear projection for appearance-based recognition in the tensor framework. In: 2007 IEEE 11th International Confer - ence on Computer Vision. IEEE, pp. 1–8. Wang C., Mahadevan S., 2009. Manifold alignment without correspondence. In: Twenty-First International Joint Conference on Artificial Intelligence, p. 26. Wen Z., Yin W., 2013. A feasible method for optimization with orthogonality con- straints. Mathematical Programming 142 (1), 397–434. Wright J., Ma Y., Mairal J., Sapiro G., Huang T. S., Yan S., 2010. Sparse represen- tation for computer vision and pattern recognition. Proceedings of the IEEE 98 (6), 1031–1044. Xu H., Zheng J., Chellappa R., 2015. Bridging the domain shift by domain adaptive dictionary learning. In: British Machine Vision Conference 2015. Brighton, UK. Xu R., Chen Z., Zuo W., Yan J., Lin L., 2018. Deep cocktail network: multi-source unsupervised domain adaptation with category shift. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3964–3973. Yang M., Zhang L., Feng X., Zhang D., 2011. Fisher discrimination dictionary learn- ing for sparse representation. In: International Conference on Computer Vision, pp. 543–550. Yang L., Balaji Y., Lim S. N., Shrivastava A., 2020. Curriculum manager for source selection in multi-source domain adaptation. arXiv preprint. arXiv:2007.01261. Zhao W., Chellappa R., Phillips P. J., Rosenfeld A., 2003. Face recognition: a litera- ture survey. ACM Computing Surveys (CSUR) 35 (4), 399–458.\n--- Страница 353 ---\n352  Адаптация домена с использованием неглубоких и глубоких нейросетей Zheng J., Liu M. Y., Chellappa R., Phillips J. P., 2012. A Grassmann manifold-based domain adaptation approach. In: Proceedings of the International Conference on Pattern Recognition, pp. 2095–2099. Zou Y., Yu Z., Kumar B. V., Wang J., 2018. Unsupervised domain adaptation for semantic segmentation via class-balanced self-training. In: Proceedings of the European Conference on Computer Vision (ECCV), pp. 289–305. Zou Y., Yu Z., Liu X., Kumar B. V., Wang J., 2019. Confidence regularized self-train- ing. In: Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 5982–5991. об аВтора Х гЛаВы Йогеш Баладжи – кандидат наук в Мэрилендском университете в Колледж- Парке. Получил степень магистра компьютерных наук в Университете Мэ- риленда и степень бакалавра технических наук в области электротехники в Индийском технологическом институте в Мадрасе. Его исследовательские интересы связаны с компьютерным зрением и машинным обуче нием с упо- ром на адаптацию предметной области и генеративное моделирование. Хиен В. Нгуен – доцент кафедры электроники и вычислительной техники Хьюстонского университета. Он получил кандидатскую степень в Мэриленд- ском университете в Колледж-Парке (2013 г.) и степень доктора наук в На- циональном университете Сингапура (2007 г.). Его научные интересы лежат на стыке машинного обуче ния и медицины. Опубликовал 50 статей в рецен- зируемых журналах и является соавтором 12 патентов США. Разработанная им медицинская диагностическая система для помощи врачам была пред- ставлена в серии «Великие инновационные идеи» Ассоциации компьютер- ных исследований. Является заслуженным членом Национальной академии изобретателей. Рама Челлаппа – почетный профессор на факультетах электроники, вычис - лительной техники и биомедицинской инженерии Университета Джона Хоп- кинса (JHU). Занимает постоянную должность профессора Колледж-Парка на факультете ECE в Университете Мэриленда (UMD). До прихода в JHU был за- служенным профессором университета, профессором кафедры ECE и Инсти- тута перспективных компьютерных исследований Университета Мэриленда в UMD. В настоящее время его научные интересы включают компьютерное зрение, распознавание образов и машинный интеллект. Он получил много- численные награды за исследования, преподавание, поддержку и наставни- чество от Университета Южной Калифорнии, Университета Мэриленда, IBM, IEEE, Совета по биометрии IEEE и Международной ассоциации распознава- ния образов. Ему присвоены звания заслуженного инженера по электронике факультета ECE Университета Пердью и почетного выпускника Индийского института науки. Является членом IEEE, IAPR, OSA, AAAS, ACM, AAAI и NAI и имеет восемь патентов.",
      "debug": {
        "start_page": 315,
        "end_page": 353
      }
    },
    {
      "name": "Глава 8. Адаптация домена и непрерывное обучение семантической сегментации 353",
      "content": "--- Страница 354 --- (продолжение)\nГлава 8 Адаптация домена и непрерывное обучение семантической сегментации Авторы главы: Умберто Микьели, Марко Тольдо и Пьетро Зануттиг; кафедра информационной инженерии, Университет Падуи, Падуя, Италия Краткое содержание главы: формальное представление задачи адаптации домена для семантической сегментации и представление различных уровней, на которых может вы- полняться адаптация; расширенный обзор методов адаптации домена для семантической сег - ментации; обзор последних достижений в области непрерывного обуче ния для се- мантической сегментации. 8.1. В Ведение Стандартная методика обуче ния с учителем предполагает наличие боль- шого обучающего набора, содержащего данные с теми же статистическими свойствами, что и целевые данные, помеченные в соответствии с решаемой задачей. Эта методика легла в основу огромного количества стратегий ма- шинного обуче ния, от простых линейных классификаторов до продвинутых методов глубокого обуче ния, и позволила выработать для них надежную теоретическую основу. Однако при переходе от экспериментов к практическим приложениям пользователи сталкиваются с некоторыми ограничениями. Во-первых, для\nГлава 8 Адаптация домена и непрерывное обучение семантической сегментации Авторы главы: Умберто Микьели, Марко Тольдо и Пьетро Зануттиг; кафедра информационной инженерии, Университет Падуи, Падуя, Италия Краткое содержание главы: формальное представление задачи адаптации домена для семантической сегментации и представление различных уровней, на которых может вы- полняться адаптация; расширенный обзор методов адаптации домена для семантической сег - ментации; обзор последних достижений в области непрерывного обуче ния для се- мантической сегментации. 8.1. В Ведение Стандартная методика обуче ния с учителем предполагает наличие боль- шого обучающего набора, содержащего данные с теми же статистическими свойствами, что и целевые данные, помеченные в соответствии с решаемой задачей. Эта методика легла в основу огромного количества стратегий ма- шинного обуче ния, от простых линейных классификаторов до продвинутых методов глубокого обуче ния, и позволила выработать для них надежную теоретическую основу. Однако при переходе от экспериментов к практическим приложениям пользователи сталкиваются с некоторыми ограничениями. Во-первых, для\n--- Страница 355 ---\n354  Адаптация домена и непрерывное обучение семантической сегментации обуче ния модели под прикладную задачу обычно недостает обучающих дан- ных. Несмотря на то что общедоступны очень большие обобщенные наборы данных, сбор и разметка достаточного количества данных для узкой задачи обходятся дорого и отнимают много времени у большинства компаний, раз- рабатывающих системы машинного обуче ния. Отсюда вытекает потребность в методах адаптации домена, способных перенести полученные знания из общего исходного набора данных в целевые данные актуальной задачи. Это может быть обуче ние с частичным привлечением учителя, когда доступно небольшое количество размеченных данных для набора целевого домена, либо обуче ние без учителя, когда для целевого домена отсутствует разметка или вообще нет данных. Во-вторых, разметка данных может лишь частично или не совсем точно соответствовать целевой задаче (т. е. так называемая слабая разметка, или слабое обуче ние). Многие современные исследования направлены на поиск способов использования разметки данных, относящихся к другой, но связан- ной задаче, или к набору классов, отличных от целевого. В связи с этим во многих случаях целевая задача не полностью определена в начальной точке, и во время работы модели могут быть добавлены новые классы или даже новые задачи. Для таких сценариев предназначены стратегии непрерывного обуче ния (continuous learning, CL), направленные на постепенное изучение новых задач или классов без переобучения модели машинного обуче ния с нуля. Эти соображения применимы ко многим моделям обуче ния и целевым за- дачам, но становятся особенно актуальными, когда для обуче ния требуется огромное количество данных и большие вычислительные усилия. В частно- сти, это касается задач понимания изображений и видео, которые в настоя- щее время обычно решаются с по мощью сложных моделей глубокого обуче- ния. По этой причине в задачах такого рода широко применяется перенос обуче ния, особенно популярный в области классификации изображений – самой простой классической задаче понимания изображений на глобальном уровне. В этой главе мы сосредоточимся на более сложной задаче семантической сегментации, где, несмотря на классификацию на уровне изображения, вы- полняется плотная разметка на уровне пикселей. Эта задача является не только более сложной, но и особенно интересной, поскольку операция мар- кировки занимает очень много времени (намного больше, чем при класси- фикации изображений), что затрудняет создание больших обучающих набо- ров. Хотя для решения этой задачи можно использовать большое количество подходов, в настоящее время большинство методов используют стратегии глубокого обуче ния и, в частности, сверточные нейронные сети (CNN) со структурой автокодировщика. Мы тоже возьмем за основу эту архитектуру. Начнем с задачи адаптации домена без учителя (unsupervised domain adap- tation, UDA) или с частичным привлечением учителя (semisupervised domain adaptation, SDA). Стандартная постановка задачи остается прежней, но проис - ходит смещение статистических свойств данных при переходе от исходного к целевому набору. Мы дадим строгую формулировку задачи в разделе 8.2.1, учитывая также более сложные конфигурации, в которых могут изменяться\n--- Страница 356 ---\nВведение  355 и домен, и задача. Адаптация сети глубокого обуче ния к целевому домену может быть выполнена на разных этапах глубокой сети, т. е. (1) на входном уровне путем трансляции изображений в новый домен, более похожий на целевой, (2) на уровне признаков путем построения пространства признаков, в котором различные классы лучше разделены, что делает описание более устойчивым к изменению домена, и, наконец, (3) на уровне вывода путем обеспечения когерентности между пространствами выходных вероятностей при использовании данных из двух доменов. Для достижения этих целей можно использовать различные стратегии, такие как состязательное обуче- ние, генеративные сети для трансляции доменов, самообучение, минимиза- ция энтропии и многие другие. В разделе 8.2.3 будут подробно представлены наиболее успешные стратегии. Во второй части этой главы мы проанализируем стратегии непрерывного обуче ния (сontinual learning, CL), которые предназначены для реагирования на изменение задач с течением времени. Такие изменения обычно пред- ставлены расширением набора меток, добавлением новых меток или разде- лением существующих на более точные подклассы. Одной из основных целей является возможность адаптировать сеть к новым условиям, используя толь - ко данные, касающиеся новых задач, и не переобучая модель с нуля. Однако это весьма нетривиально из-за так называемого явления катастрофического забывания (catastrophic forgetting), поскольку модель машинного обуче ния склонна «забывать» знания о предыдущих задачах при изучении новых. Мы начнем с формального представления этой проблемы в разделе 8.3.1 и рас - смотрим широкий спектр экспериментальных сценариев. Затем в разделе 8.3.3 мы покажем, как можно справиться с проблемой забывания с по мощью стратегий сохранения знаний, особенно на основе дистилляции знаний. Другие стратегии основаны на замораживании пара- метров или замедлении обуче ния в некоторых частях сети, на попытках ре- генерировать прошлые (и более недоступные) данные предыдущих классов с использованием генеративных сетей или данных, собранных в интернете. 8.1.1. Формальная постановка задачи В этом разделе мы сформулируем задачу переноса обуче ния и введем не- которые обозначения, которые будем использовать в оставшейся части гла- вы. Определим домен 𝒟 = {𝒳, P(X)}, где 𝒳 – пространство входных данных, а P(X) – функция распределения вероятностей по этим входным данным. Задача 𝒯 в домене 𝒟 представляет собой комбинацию пространства меток 𝒴 с предсказательной функцией f(.), моделирующей условное распределение вероятностей P(Y|X). Таким образом, любую задачу машинного обуче ния с учителем обычно можно связать с поиском функции h: 𝒳 ® 𝒴, которая лучше аппроксимирует неизвестную f(.) путем изучения набора помеченных обучающих выборок, взятых из совместного распределения P(X, Y) по 𝒳 × 𝒴. Предположим, что домен входных данных 𝒟 не уникален, например су - ществуют отдельно исходный домен 𝒟S и целевой 𝒟T (как в классическом UDA) или домен разбит на несколько частей 𝒟(t), t = 1, …, Tmax, доступных\n--- Страница 357 ---\n356  Адаптация домена и непрерывное обучение семантической сегментации для обуче ния в разное время (как в классическом CL). Более того, в этих до- менах может потребоваться решение разных задач, например для исходного и целевого доменов могут быть выбраны две разные задачи 𝒯S и 𝒯T соот - ветственно, или может существовать последовательность задач 𝒯(t), t = 1, …, Tmax, которые нужно решать на разных этапах t процесса обуче ния. Перенос обуче ния определяется как поиск улучшенной прогностической функции fT(.) по целевому домену (или по нескольким целевым доменам), опираясь на полезную информацию, извлеченную из задачи 𝒯S в исходном домене 𝒟S, в случае 𝒟 S ≠ 𝒟 T или 𝒯 S ≠ 𝒯 T. Стоит отметить, что адаптацию домена и непрерывное обуче ние можно рассматривать как два особых случая переноса обуче ния; в первом случае исходный и целевой домены разные, а задача одна и та же, а во втором слу - чае макродомен один и тот же (но доступен отдельными частями), а задача меняется. 8.2. адаптация домена без уЧитеЛя За последние несколько лет глубокое обуче ние оказало огромное новатор- ское влияние на область компьютерного зрения. До революции глубокого обуче ния семантическая сегментация считалась очень сложной задачей, и даже сложные алгоритмы обеспечивали лишь посредственную произво- дительность. В настоящее время с появлением глубоких нейронных сетей мы можем получить замечательные результаты при условии наличия при- емлемых вычислительных ресурсов. Тем не менее потенциал, заложенный в моделях глубокого обуче ния, может быть полностью раскрыт только при наличии достаточного объема тщательно размеченных обучающих данных. Сложность, заключенная в миллионах обучаемых параметров современных моделей глубокого обуче ния, легко приводит к переобучению модели, а не к повышению ее точности, и этому приходится противодействовать, исполь- зуя огромные наборы данных для обуче ния. Ярким примером значимости большого объема обучающих данных является крупномасштабный набор данных ImageNet (Deng et al., 2009), чей вклад в раннюю разработку и расши- рение глубоких нейронных сетей для классификации изображений, безуслов- но, очень велик. К сожалению, сбор и аннотирование выборок данных часто обходятся чрезвычайно дорого, отнимают много времени и подвержены ошибкам, поскольку в процессе требуется большое количество интенсивного челове- ческого труда. Чрезмерная стоимость может помешать сбору достаточного количества данных для решения новой задачи или перехода в новую среду, тем самым препятствуя практическому применению достижений глубокого обуче ния. Поэтому было бы чрезвычайно полезно использовать ранее соз- данные наборы данных, если они обладают сходными свойствами с целевы- ми данными. Уже имеющиеся обучающие выборки могут быть эффективно использованы для решения текущей задачи, если они относятся к домену, коррелирующему с целевым.\n--- Страница 358 ---\nАдаптация домена без учителя  357 Несмотря на то что передача информации из связанных доменов выгля- дит довольно привлекательной и простой, на практике этот процесс требу - ет осторожности. Глубоким нейронным сетям обычно не хватает навыков обобщения. Другими словами, даже небольшое изменение в распределе- нии данных между обучающими и рабочими статистическими распреде- лениями может привести к серьезному снижению качества вывода модели. По этой причине простое применение предварительно обученной модели в новой среде, скорее всего, потерпит неудачу, поскольку атрибуты, специ- фичные для домена, обычно фиксируются вместе с атрибутами, не завися- щими от домена, что препятствует эффективной передаче знаний. В этом случае пригодится адаптация домена, поскольку она позволяет справиться со статистическим разрывом между исходным и целевым представления- ми. Конечной целью усилий по адаптации является обуче ние прогнозной модели для выбранной задачи, оптимально работающей как в исходном, так и в целевом домене, в то время как обуче ние в значительной степени (или исключительно) происходит на размеченных данных исходного до- мена. Следовательно, эффективная передача знаний из исходного домена в целевой имеет решающее значение для достижения в конечном итоге хорошего качества модели. Особенно интересен вариант адаптации доме- на без учителя (UDA), в котором полностью отсутствует разметка данных целевого домена. Это чрезвычайно благоприятный (но сложный) сценарий, поскольку данные из целевого домена больше не требуют дорогостоящего аннотирования. В последнее время задача адаптации домена очень активно изучается в контексте глубокого обуче ния применительно к визуальным задачам. Хотя глубокие сверточные структуры доказали свою способность изучать визуаль- ные признаки, полезные для решения множества связанных задач (напри- мер, классификации изображений, обнаружения объектов, семантической сегментации), переносимость этих представлений обычно снижается при переходе на более глубокие сетевые уровни (Long et al., 2015). Ранние работы по адаптации доменов для глубоких сетей в основном были сосредоточены на задаче классификации изображений. Во многих подходах совместно оценивается и минимизируется послойная мера статистического расхождения доменов, что способствует извлечению представлений при- знаков, инвариантных к домену, в то время как способность к различению гарантируется функцией потерь для конкретной задачи. Впоследствии чрез- вычайно успешными оказались стратегии состязательной адаптации, в схе- мах которых расхождение доменов выражается посредством обучаемого дис - криминатора и минимизация расхождения осуществляется состязательным образом. Более подробная информация о состязательном обучении и его использовании в адаптации домена будет представлена в разделе 8.2.3.1. Этот подход открыл возможности для создания решений по адаптации до- мена, способных решить задачу семантической сегментации, где более вы- сокая сложность с точки зрения сетевых представлений, необходимых для попиксельной классификации, заставляет использовать более продвинутые приемы.\n--- Страница 359 ---\n358  Адаптация домена и непрерывное обучение семантической сегментации 8.2.1. Формулировка задачи адаптации домена Адаптация домена (domain adaptation, DA) – это особый случай переноса обуче ния, так называемое трансдуктивное трансферное обуче ние, в котором исходная и целевая задачи совпадают (𝒯 S = 𝒯T), тогда как расхождение за- ключается в различии предметной области (𝒟 S ≠ 𝒟 T). Кроме того, подразуме- вается, что адаптация домена гомогенна, т. е. смещение домена происходит на статистическом уровне (P (XS, YS) ≠ P(XT, YT)), а не из-за различных входных пространств (𝒳 S и 𝒳T принадлежат одинаковой семантической области, на- пример изображения городских сцен) (Wang and Deng, 2018). В последнее время в некоторых исследованиях рассматривают более слож - ные сценарии, чем стандартная гомогенная адаптация, позволяющие ис - пользовать разные наборы семантических классов в исходной и целевой об- ластях (𝒞 S и 𝒞 T). В зависимости от того, как связаны исходный 𝒞S и целевой 𝒞T наборы, можно выделить несколько сценариев адаптации домена (рис. 8.1): закрытая адаптация: соответствует гомогенному случаю, когда семан- тические классы исходного и целевого доменов полностью совпадают (𝒞S = 𝒞T); частичная адаптация: в этом случае существуют некоторые исходные классы, которых нет в целевом домене (𝒞 S É 𝒞T); открытая адаптация: в отличие от частичной адаптации, здесь до- пускается наличие некоторых целевых частных классов, для которых отсутствуют обучающие примеры в исходном домене (𝒞 S Ì 𝒞T); открытая частичная адаптация: исходный и целевой домены содер- жат отдельные наборы семантических классов (Saito et al., 2020) с под- множеством общих классов (𝒞 S ≠ 𝒞T, 𝒞S Ç 𝒞T ≠ ∅). Однако элементы, принадлежащие подмножеству классов, исключительных для целевого домена, должны быть признаны не относящимися к общим классам; неограниченная адаптация: этот сценарий очень похож на открытую адаптацию, но объекты целевых частных классов должны быть явно классифицированы, а не только связаны с общим неизвестным целе- вым классом. Этот вариант был предложен недавно (Bucher et al., 2020) и является самым амбициозным из всех, поскольку допускает полную предварительную неосведомленность о семантическом содержании целевых данных. В следующих разделах данной главы основное внимание будет уделено стандартной и наиболее распространенной закрытой адаптации, поскольку в настоящее время это, безусловно, наиболее изученный вариант. В зависимости от степени доступности разметки в целевом домене задача адаптации разделяется на категории, начиная от полностью или частично аннотированных наборов (и, соответственно, полного или частичного обуче- ния с учителем) до полностью лишенного меток набора (обуче ние без учи- теля). В частности, мы будем рассматривать адаптацию домена без учителя, поскольку в последнее время наблюдается рост ее популярности, особенно в отношении задачи семантической сегментации, и она охватывает множест - во практических применений. Предполагается, что доступно множество по-\n--- Страница 360 ---\nАдаптация домена без учителя  359 меченных исходных данных {x is, yis}, составленное в соответствии с исходным совместным распределением по 𝒳S × 𝒴S, в паре с множеством неразмеченных данных { xit}, извлеченных из отдельного целевого предельного распреде - ления по 𝒳T. Цель состоит в том, чтобы найти прогностическую функцию, правильно моделирующую отношение вход–метка задачи в целевой области, в то время как знания о выбранной задаче могут быть извлечены только из исходных размеченных данных. DA с замкнутым множеством Частично открытая DAЧастичная ДА Множество исходных классов Множество целевых классов Неизвестный классDA с открытым множеством Неограниченная DA Рис. 8.1  Различные варианты адаптации домена в зависимости от того, как связаны наборы исходных и целевых классов Кроме того, для работы стандартных методов адаптации домена исходный и целевой домены должны быть каким-то образом связаны между собой, т. е. они должны совместно использовать контент, относящийся к задаче, в то время как низкоуровневые атрибуты могут различаться. Этот сценарий обычно называют одноэтапной адаптацией, поскольку передача знаний про- исходит непосредственно между исходными и целевыми данными без про- межуточных этапов. 8.2.2. Основные подходы к адаптации Как обсуждалось ранее, за ухудшением качества, от которого страдают глубо- кие прогнозные модели, оказавшиеся в новой целевой среде, лежит явление ковариантного расхождения между распределениями исходных и целевых данных. По этой причине большая часть разработок в области адаптации домена строится на преодолении статистического разрыва между распре- делениями доменов, чтобы прогнозная модель давала удовлетворительные результаты всякий раз, когда эти распределения совпадают. Для достижения статистического соответствия были разработаны различ- ные стратегии, которые будут подробно рассмотрены в разделе 8.2.3. Мы\n--- Страница 361 ---\n360  Адаптация домена и непрерывное обучение семантической сегментации можем разбить эти стратегии на категории в зависимости от того, где в ис - пользуемой модели семантической сегментации устраняется статистиче- ское несоответствие. В частности, адаптации могут подвергаться различные представления данных, от приоров изображений перед классификацией до промежуточных и выходных активаций сети (рис. 8.2). Далее мы рассмотрим основные идеи, сгруппированные по способу адаптации. Адаптация в пространстве входа Адаптация в выходном пространствеИсточник Цель Кодировщик Декодер Адаптация в пространстве признаков Рис. 8.2  Обобщенная схема сети автокодировщика для семантической сегментации. Выделены различные этапы сети, на которых могут применяться стратегии адаптации предметной области, от пространства входного изображе- ния до промежуточных или выходных активаций сети 8.2.2.1. Адаптация на входном уровне Первая стратегия заключается в выполнении адаптации на входе – непо- средственно на изображениях до того, как они будут переданы в сеть сег - ментации (как показано в крайней левой части рис. 8.2). Идея состоит в том, чтобы заставить выборки данных из любой области достичь единообразного внешнего вида, а это означает, что они не только должны обладать семанти- ческим сходством высокого уровня, но также должны быть согласованы их низкоуровневые статистические расхождения. Это связано с тем, что низ- коуровневые атрибуты, зависящие от домена, даже если они не определяют семантическое содержание входного изображения, все же могут быть захва- чены моделью прогнозирования, что впоследствии приводит к неверным прогнозам, когда атрибуты меняются при смене домена. Ярким примером этого является адаптация модели, обученной на синтетических изображе- ниях, к реальному миру. Хотя синтетические изображения могут выглядеть в высшей степени реалистично, им могут быть присущи специфические чер- ты, пусть даже небольшие, которые могут существенно снизить качество работы модели, обученной на синтетических данных, в реальной среде. Обычный подход к адаптации домена на входном уровне заключается в сопоставлении данных с новым пространством изображения, где спроеци- рованные исходные (или целевые) изображения несут улучшенное перцеп-\n--- Страница 362 ---\nАдаптация домена без учителя  361 тивное сходство с целевыми (или исходными). Как правило, это достигается с по мощью методов переноса стиля, которые работают путем сопоставления исходного и целевого предельных распределений в пространстве изображе- ния. Подавая данные из нового доменно-инвариантного пространства в сеть сегментации, предсказатель теперь должен иметь возможность сохранять согласованные результаты независимо от доменов. Преимуществом этого метода является его полная независимость по отно- шению к используемой сети сегментации, которая не нуждается в каких-либо модификациях. За это удобство, однако, приходится платить тем, что в стан- дартной схеме без каких-либо дополнительных упорядочивающих факторов маргинальное выравнивание может быть выполнено без одновременного сопоставления распределений, обусловленных классом. Другими словами, иногда можно получить инвариантные представления домена, которым все же не хватает семантической согласованности с исходными данными, ко - торая имеет ключевое значение для решения задачи сегментации. Чтобы обойти эту проблему, было предложено несколько решений для достижения семантически согласованных переводов изображений, например с по мощью ограничений реконструкции изображения или дополнительных компонен- тов потерь, обеспечивающих согласованность прогнозов сегментации. 8.2.2.2. Адаптация на уровне признаков Альтернативный подход состоит в том, чтобы сосредоточить адаптацию на представлениях признаков, стремясь к выравниванию распределения скры- тых представлений сети, которые обычно извлекаются из выходных данных кодировщика в традиционной архитектуре автокодировщика (даже если применялась адаптация на других этапах сети). В данном случае мы стре- мимся построить инвариантное к домену скрытое пространство, в котором признаки, извлеченные либо из исходных, либо из целевых входных изобра- жений, имеют одно и то же распределение. В конце концов, обуче ние исклю- чительно на исходных представлениях должно привести к хорошей точности также и в целевой области, поскольку общая классификация в адаптирован- ном скрытом пространстве должна быть одинаково точна как для исходных, так и для целевых представлений (при их одинаковом распределении). В контексте семантической сегментации пространство признаков сохра- няет значительную сложность из-за своей высокой размерности, которая необходима для того, чтобы прогнозная модель собирала глобальные семан- тические подсказки, одновременно достигая точности на уровне пикселей. Кроме того, что касается адаптации на входном уровне, семантически не- зависимое выравнивание частных распределений (например, стандартная состязательная адаптация) не гарантирует, что совместные распределения вход–метка совпадают, поскольку из неразмеченных целевых выборок нель- зя получить никакой информации о целевом совместном распределении. По этим причинам многие методы адаптации на уровне признаков, кото- рые были успешно разработаны для классификации изображений, с трудом распространяются на задачу плотной сегментации и, как правило, требуют тщательной настройки и дальнейшей регуляризации.\n--- Страница 363 ---\n362  Адаптация домена и непрерывное обучение семантической сегментации 8.2.2.3. Адаптация на уровне выхода Наконец, последний класс методов адаптации домена использует выравни- вание распределений между доменами по выходным данным сети, т. е., как правило, по выходному вероятностному пространству для каждого класса. Доказано, что карты прогнозной вероятности не только сохраняют достаточ- ную сложность и богатство семантической информации, но также охватыва- ют низкоразмерное пространство, в котором статистическое выравнивание достигается гораздо более эффективно, например с по мощью состязатель- ной стратегии. Кроме того, исходное знание можно косвенно транслировать в немаркированный целевой домен, прибегая к той или иной форме само- стоятельного обуче ния. Доказано, что приоры, полученные из распределе- ния меток исходного домена, также обеспечивают полезную регуляризацию процесса обуче ния, поскольку они обычно определяют высокоуровневые семантические свойства, общие для разных доменов. 8.2.3. Методы адаптации домена без учителя Далее мы обсудим наиболее эффективные подходы к адаптации домена в се- мантической сегментации с обуче нием без учителя. Для каждого набора методов мы приведем несколько исследовательских работ, которые име - ют отношение к этой категории и могут быть полезны читателям. Однако следует подчеркнуть, что большинство недавно предложенных стратегий адаптации домена используют комбинацию нескольких методов для повы- шения качества. 8.2.3.1. Состязательная адаптация домена Первоначально состязательное обуче ние предназначалось для создания изо- бражений (Goodfellow et al., 2014). Основная цель генеративной задачи – извлечь неизвестные данные моделируемого распределения вероятностей из используемого обучающего набора. Состязательная стратегия оказалась чрезвычайно эффективной при решении этой задачи, поскольку не требует - ся находить явное выражение целевого распределения данных и, что более важно, для обуче ния генеративной модели не требуется придерживаться какой-либо цели. Процесс обуче ния основан на минимаксной игре, в которой сеть генератора в состязании с сетью дискриминатора учится создавать реа- листичные образы. Дискриминатор – это бинарный классификатор, целью которого является различение исходных обучающих данных и данных, соз- данных генератором. Генератор представляет собой генеративную модель, которая принимает на вход случайный шум (или некоторые обусловлива- ющие данные в более поздних вариантах) и создает данные (т. е. изобра- жения в интересующей области), напоминающие те, что есть в обучающем наборе. Генератор стремится постоянно повышать реалистичность созда- ваемых изобра жений, чтобы обмануть дискриминатор, и это достигается с по мощью функции потерь, минимизация которой, в свою очередь, макси- мизирует ошибки дискриминатора. Модель обучается путем чередования\n--- Страница 364 ---\nАдаптация домена без учителя  363 этапа обуче ния дискриминатора с целью увеличения точности различения и этапа оптимизации генератора с противоположной целью (см. рис. 8.3). Правильно выполненное состязательное обуче ние должно привести к ста- тистическому распределению сгенерированных данных, полностью совпа- дающему с обучаю щим набором, а это означает, что исходные и сгенери- рованные данные должны быть статистически неразличимы. Кроме того, дискриминатор должен быть в состоянии как извлекать, так и выражать меру статистического несоответствия в форме структурированной потери обуче- ния. Следовательно, целевую функцию можно рассматривать как совместно изученную и оптимизированную в состязательном процессе, что позволяет ей адаптироваться к конкретному контексту. Состязательное обуче ние было успешно распространено на задачу адапта- ции домена. Дискриминатор теперь превращается в классификатор домена, который используется для управления процессом адаптации. Его различи- тельная способность фактически направлена на улавливание статистическо- го несоответствия между представлениями из разных доменов, которое отве- чает за снижение точности и, следовательно, должно быть минимизировано. Вектор шума Вектор шумаРеальные изображения Реальные изображенияГенератор (фиксированный) ГенераторОбразец Образец ОбразецОбразецДискриминатор Настоящее / имитация Настоящее / имитацияОбновить дискриминатор Обновить генераторПотеря ПотеряДискриминатор (фиксированный) Рис. 8.3  Обуче ние генеративно-состязательной сети. Этап обновления дискриминатора (вверху) и генератора (внизу) У классификатора домена есть два возможных применения. Во-первых, он может различать внутренние и выходные представления, извлеченные из данных в исходном или целевом домене (рис. 8.4). Это позволяет вводить\n--- Страница 365 ---\n364  Адаптация домена и непрерывное обучение семантической сегментации дополнительные члены потерь, обеспечивающие конструирование призна- ков или выходных пространств, которые более инвариантны к домену. Во- вторых, можно использовать дискриминатор, чтобы различать выходные данные сети (которые могут соответствовать входным данным из исходного или целевого домена) и эталонные сегментации (которые при обучении без учителя присутствуют только в исходном домене). Поскольку в состязатель- ной модели нет необходимости иметь эталонные данные, соответствующие предоставленным изображениям, это позволяет также использовать изо- бражения целевого домена, для которых нет эталонов, и добиться того, что- бы их предсказанные карты сегментации имели статистические свойства, аналогичные эталонным (рис. 8.5). В соответствии с этой стратегией к стан- дартному управляющему сигналу от аннотированных исходных данных при- соединяется управляющий сигнал от дискриминатора домена, который под- талкивает сеть к инвариантности домена, что, в свою очередь, уменьшает внутреннее расхождение доменов в направлении исходного домена. КодировщикИсточник Цель Декодер Дискриминатор доменовИсточник или цель? Рис. 8.4  Иллюстрация стандартной стратегии состязательной адаптации. Дискриминатор домена отмечает статистическое несоответствие между исход- ным и целевым представлениями (например, выходными данными сети сегмен- тации или картами признаков, вычисленными из того или иного домена). Затем его обучающий сигнал используется для сближения доменов КодировщикИсточник Цель ДекодерДискриминаторПрогноз или GT?Исходный вход (с учителем) Целевой ввод (без учителя)Предсказание в целевом доменеПредсказание в исходном доменеИсходный GT Рис. 8.5  Иллюстрация стратегии состязательной адаптации на уровне вы- хода, где сближение доменов выполняется косвенно путем устранения разрыва в распределении между исходными картами аннотаций и сетевыми прогноза- ми из исходного или целевого домена После успеха состязательной адаптации домена для классификации изобра жений (Ganin, Lempitsky, 2015; Ganin et al., 2016) состязательная\n--- Страница 366 ---\nАдаптация домена без учителя  365 стратегия была применена также в контексте семантической сегментации для достижения сближения доменов по представлению скрытых признаков (Hoffman et al., 2016). Тем не менее, как упоминалось ранее, глобальное сближение маргинальных распределений доменов, обеспечиваемое состя- зательной схемой, может привести к неправильной передаче семантических знаний между доменами, когда в процессе обуче ния игнорируются рас - пределения, обусловленные классом. По этой причине для достижения эф- фективной состязательной адаптации при решении задачи семантической сегментации в конвейер адаптации необходимо встроить дополнительные модули. Возможное решение – интегрировать состязательное выравнивание при- знаков в генеративный подход (раздел 8.2.3.2), как это сделано в нескольких работах (Li et al., 2019; Hoffman et al., 2018; Chen et al., 2019; Toldo et al., 2020). Цель данного подхода заключается в усилении адаптации простран- ства изображения таким образом, чтобы перенос атрибута, направленный на совмещение визуальных представлений изображений из разных доме- нов, был расширен внутри пространства признаков. Альтернативой является адаптация по категориям (Chen et al., 2017; Du et al., 2019). Идея состоит в том, чтобы прибегнуть к состязательному обуче нию по классам, вводя не- сколько дискриминаторов отдельных признаков для каждого класса, что, в принципе, должно обеспечить семантически непротиворечивую передачу знаний, которая отсутствует в стандартной глобальной адаптации. Наконец, зайдя с другой стороны, можно прибегнуть к ограничению реконструкции для обеспечения инвариантности домена относительно скрытых представ- лений признаков (Sankaranarayanan et al., 2018; Murez et al., 2018; Zhu et al., 2018). В этом случае состязательное обуче ние применяется к пространству реконструируемого изображения, чтобы гарантировать, что представления признаков могут быть спроецированы обратно либо в исходное, либо в це- левое пространство изображений без каких-либо различий. Как отмечалось ранее, решение задачи семантической сегментации сопро- вождается построением довольно сложного пространства признаков из-за высокой размерности представлений. Чтобы обойти сложность, связанную с адаптацией пространства признаков, в некоторых исследованиях была предложена адаптация в выходном пространстве сегментации (Tsai et al., 2018; Chen et al., 2018; Chang et al., 2019; Luo et al., 2019; Yang et al., 2020; Bi- asetton et al., 2019; Michieli et al., 2020; Spadotto et al., 2020). И действительно, было показано, что низкоразмерные выходные представления сохраняют достаточно семантической информации для успешной адаптации. В этой но- вой состязательной схеме выходного уровня дискриминатор домена учится распознавать домен, из которого исходят карты сегментации. В то же время сеть сегментации играет роль генератора, предоставляя междоменные ста- тистически близкие прогнозы, чтобы обмануть классификатор доменов. Хотя сближение исходных и целевых выходных представлений стало общепри- знанным решением (Tsai et al., 2018; Chen et al., 2018; Chang et al., 2019; Luo et al., 2019; Yang et al., 2020), в некоторых последующих работах стандартный подход был пересмотрен путем поиска косвенного сближения доменов (Bia- setton et al., 2019; Michieli et al., 2020; Spadotto et al., 2020), когда прогнозы из\n--- Страница 367 ---\n366  Адаптация домена и непрерывное обучение семантической сегментации того и другого доменов заставляют распространяться как эталонные метки источника (как показано на рис. 8.5). Некоторые новые подходы (Vu et al., 2019; Tsai et al., 2019) были основа- ны на извлечении значимых паттернов из выходного пространства сегмен- тации. Идея состоит в том, чтобы предоставить дискриминатору домена более функциональное и значимое понимание исходных и целевых пред- ставлений, что позволит ему вырабатывать более эффективный управляю- щий сигнал в процессе адаптации. Это делается путем ручного извлечения некоторой значимой информации как из исходных, так и из целевых данных (например, карты энтропии по прогнозам сегментации (Vu et al., 2019)) для подачи в сеть дискриминатора. В свою очередь, сосредоточив внимание на значимых семантических подсказках из представлений данных, можно уси- лить состязательное выравнивание по активациям сети сегментации. 8.2.3.2. Генеративная адаптация Преобразование изображения в изображение – это класс генеративных ме- тодов, основной целью которых является построение подходящей функции для проецирования изображений из одного домена в другой. Другими сло- вами, идея состоит в том, чтобы обнаружить совместное распределение дан- ных изображения из разных доменов. Задача преобразования изображения в изображение может быть эффективно использована при адаптации домена. По сути, мы добиваемся переноса визуальных атрибутов из целевого домена в исходный с сохранением исходной семантической информации. Таким об- разом смягчается явление ковариантного смещения, вызывающее снижение качества классификатора. Двигаясь в этом направлении, некоторые исследо - ватели использовали стратегию адаптации на уровне ввода, основанную на трансляции изображения между исходным и целевым доменами. Общим для всех этих работ является поиск предметной инвариантности внешнего вида изображений из разных доменов. В конечном итоге это позволяет использо- вать для обуче ния с учителем транслированные, но все еще аннотированные исходные изображения. Общий подход, использованный во множестве работ (Hoffman et al., 2018; Chen et al., 2019; Toldo et al., 2020; Zhou et al., 2020; Li et al., 2019; Murez et al., 2018; Qin et al., 2019; Li et al., 2018; Yang et al., 2020b; Gong et al., 2019), заключается в применении успешной модели CycleGAN (Zhu et al., 2017) для выполнения перевода изображения в изображение без учителя (рис. 8.6). Данный фреймворк параллельно состязательным образом изучает услов- ные трансляции изображений как в направлении от источника к цели, так и в обратном направлении. Два состязательных генеративных модуля до - полнительно связаны ограничением согласованности цикла, заставляющим каждый из них изучать обратную проекцию другого. Требованием к рекон- струкции является сохранение геометрии и компоновки входной сцены, но, в свою очередь, не гарантируется сохранение семантического содержания входного изображения при трансляции. С отсутствием семантической согласованности в стандартной схеме транс - ляции борется подход с использованием семантического предиктора в сети\n--- Страница 368 ---\nАдаптация домена без учителя  367 сегментации (Hoffman et al., 2018; Chen et al., 2019; Toldo et al., 2020; Zhou et al., 2020; Li et al., 2019). В частности, семантический предиктор можно использовать для обнаружения и, таким образом, предотвращения любого возмущения семантического вывода, которое может произойти во время трансляции, выполняемой генераторами CycleGAN. Как правило, это дости- гается путем применения согласованных карт прогнозирования к исходным и транслированным версиям одного и того же изображения. Альтернатив- ным решением могло бы быть достижение семантической обоснованности адаптации на основе перевода изображения в изображение, за счет прямого воздействия на состязательные модули перевода. Этот подход, например, был реализован с использованием мягкой потери, чувствительной к гра- диенту (Li et al., 2018), и ограничения фазовой согласованности (Yang et al., 2020), которые обеспечивают эффект регуляризации по сравнению со стан- дартным состязательным обуче нием. Наконец, можно попробовать приме- нить трансляцию из целевого домена в исходный. Доказано, что это умень- шает смещение в сторону исходного домена (Yang et al., 2020). В отличие от стандартной генеративной адаптации, инвариантность домена на уровне изображения в этом случае достигается внутри исходного домена, где псев- доразметка позволяет использовать схожие с источником транслированные целевые изображения для дискриминации с обуче нием. В качестве альтернативы адаптации на основе CycleGAN также были изуче ны методы переноса стиля для достижения доменной инвариантности низкоуровневых атрибутов изображения. В основе этих методов лежит прин- цип, согласно которому любое изображение можно разделить на его контент и стиль. В то время как стиль изображения связан с низкоуровневыми специ- фичными для домена признаками, контент указывает на высокоуровневые семантические свойства, не зависящие от домена. Следовательно, объеди- нение исходного контента с целевым стилем должно обеспечивать целе- вые обучающие данные с сохранением исходных семантических аннотаций. Благодаря генерации новых изображений целевого домена с сохранением разметки может быть выполнена дискриминация с обуче нием1. Распростра- ненным подходом к переносу стиля является использование декомпозиции контента и стиля в скрытом пространстве (Chang et al., 2019; Pizzati et al., 2020). Последующая трансляция из исходного в целевой домен сводится к за - даче объединения извлеченных представлений исходного контента со слу - чайными целевыми стилями, при этом смешанные представления должны быть перепроецированы в пространство изображения. Чтобы избежать слож - ности, связанной с созданием изображений GAN (особенно сложно полу - чить изображения с высоким разрешением), также были изучены различные типы методов передачи стиля, начиная от нейронной или фотореалистичной передачи стиля (Zhang et al., 2018; Dundar et al., 2018) и до повторной нор- мализации признаков (Choi et al., 2019; Wu et al., 2019) и низкоуровневого управления частотным спектром (Yang, Soatto, 2020). 1 При дискриминации с обуче нием на вход дискриминатора поступают обучающие образцы, категориальная принадлежность которых известна. – Прим. перев.\n--- Страница 369 ---\n368  Адаптация домена и непрерывное обучение семантической сегментации КодировщикИсточник Цель ДекодерЦелевой вход, подобный исходномуВход от исходного доменаТрансляция исходный– целевой Исходный вход, подобный целевомуПрогноз для исходного домена (имитация целевого домена с учителем) Прогноз для целевого домена (без учителя)Вход от целевого доменаТрансляция целевой– исходныйЦикл согласованной адаптации на входе Рис. 8.6  Схема генеративного подхода к адаптации, основанного на преоб- разовании изображения в изображение. В частности, исходные входные изобра- жения после трансляции используются как разновидность искусственных дан- ных для дискриминации с обуче нием 8.2.3.3. Несоответствие классификатора Как упоминалось в разделе 8.2.3.1, состязательная адаптация на уровне при- знаков в ее стандартной реализации включает дополнительный классифи- катор домена, чья способность разделять признаки из исходного и целево- го доменов обеспечивает эффективный управляющий сигнал для процесса обуче ния, подталкивая сеть сегментации к инвариантности домена в скры- том пространстве, которое он охватывает. В свою очередь, механизм раздель- ных ориентированных на задачи целей отвечает за то, чтобы предсказатель- ная сеть изучила реальную задачу с обучающим источником, т. е. применила стандартную кросс-энтропийную потерю для семантической сегментации. Несмотря на то что стандартная состязательная адаптация довольно эффективна, ей не хватает семантической осведомленности (Saito et al., 2018). Надлежащее состязательное сближение, по сути, влечет за собой со- вмещение маргинальных распределений исходных и целевых данных, за которым в общем случае не следует статистическое совмещение по услов- ным классам. Это связано с тем, что совместные распределения на уровне категорий обязательно остаются неизвестными для классификатора до- мена, поскольку полное отсутствие обуче ния с учителем в целевой пред- метной области подразумевает отсутствие информации о семантическом содержании целевых данных. В результате признаки могут перемещаться вблизи границ классов, где неопределенность классификации может при- вести к неправильным прогнозам. Хуже того, не зависящий от класса пере- нос целевых признаков может неправильно совместить их с исходными представлениями другого семантического класса в скрытом пространстве, инвариантном к предметной области, что означает наличие так называе- мого отрицательного переноса. Стремясь решить эти проблемы, некоторые исследователи (Saito et al., 2018) полностью переработали исходный состязательный подход к адапта- ции домена. В частности, они отводят роль дискриминатора плотному клас - сификатору для конкретной задачи (т. е. сети кодировщика), которая ранее была назначена дискриминатору внешнего домена. Возмущая классифика-\n--- Страница 370 ---\nАдаптация домена без учителя  369 тор с по мощью отсева, можно определить, где прогнозы более неопределен- ны, что сильно связано с расстоянием представлений признаков от границ решения. В этой новой состязательной схеме плотный классификатор обуча- ется повышать свою чувствительность к семантическим вариациям целевых представлений. Состязаясь с ним, экстрактор признаков (т. е. кодировщик) стремится обеспечить высокую категориальную достоверность вычисляемых им целевых признаков. Этот механизм должен эффективно удалить заклю- ченную в целевых представлениях, но не связанную с задачей информацию, которая является причиной сильной изменчивости прогнозов, в конечном итоге отодвигая их далеко от границ принятия решений. Недостатком стратегии несоответствия классификатора в ее исходной форме является присущая декодеру чувствительность к шуму (Saito et al., 2018), которая имеет решающее значение для определения близости целевых выборок к границам классификации, но снижает точность всей сети сегмен- тации, требуя, по сути, дополнительного этапа обуче ния, чтобы правильно изучить задачу сегментации. В этом отношении первоначальную схему мож - но было бы улучшить, заменив стратегию отсева для извлечения нескольких прогнозов по одному и тому же представлению признаков парой различных декодеров, которые одновременно обучены обеспечивать правильные, но четкие, плотные классификации (Saito et al., 2018). Это должно эффективно повысить точность секции декодера прогнозной модели за счет дополни- тельного модуля, который также необходимо обучить во время основного процесса обуче ния. Согласно другому подходу, исходную схему состязательного обуче ния можно изменить, выбрав нестохастический механизм виртуального отсева для поиска масок отсева на минимальном расстоянии, вызывающих макси- мальное расхождение прогнозов (Lee et al., 2019). При этом исходное реше- ние на основе отсева для получения четких прогнозов от одного классифи- катора сохраняется, в то время как одновременно решается вышеупомянутая проблема восприимчивости к шуму. В работе (Luo et al., 2019) дополнительно был исследован принцип со- вместного обуче ния, основанный на нескольких предикторах для оценки текущего качества адаптации. В частности, можно использовать обнаруже- ние противоречивых прогнозов, чтобы сосредоточить усилия дискримина- тора (теперь в стандартной состязательной структуре предметной области) на менее адаптированных областях входного изображения, т. е. на участках с наибольшей неопределенностью. В конечном итоге это привело к более эффективному сближению доменов исходного и целевого представлений. 8.2.3.4. Самостоятельное обучение Из-за сходства между двумя задачами несколько методов адаптации домена без учителя (unsupervised domain adaptation, UDA) были заимствованы из области обуче ния с частичным участием учителя (semi-supervised learning, SSL). Действительно, UDA можно рассматривать как крайнюю форму SSL, поскольку в обоих случаях часть обучающих данных не помечена. Однако к исходному отсутствию аннотаций SSL в неразмеченном обучающем наборе\n--- Страница 371 ---\n370  Адаптация домена и непрерывное обучение семантической сегментации добавляется статистическое расхождение в UDA между исходными и целевы- ми данными, что требует дополнительных усилий для устранения. Самонастройка. В последние годы разработан целый класс методов адап- тации (Zou et al., 2018, 2019; Li et al., 2019; Biasetton et al., 2019; Michieli et al., 2020; Spadotto et al., 2020; Choi et al. al., 2019; Chen et al., 2019a; Yang, Soatto, 2020; Zhou et al., 2020), использующих самонастройку (self-training). Этот подход, обычно принятый в SSL (Grandvalet, Bengio, 2005), работает за счет создания псевдометок на основе высоконадежных сетевых прогнозов, сделанных на основе немаркированных целевых данных. Таким образом, в целевом домене доступна форма самообучаемого контроля, которую мож - но использовать в сочетании со стандартным контролем на основе исходных помеченных данных. В отличие от других методов адаптации, описанных в предыдущих раз- делах, таких как наиболее успешные состязательные подходы, сближение доменов на уровне признаков неявно осуществляется посредством целевого самообучения, поскольку исходные обучающие данные косвенно переносят - ся на целевой домен с по мощью псевдометок. Самонастройка подталкивает выходные данные вероятности сети к пиковому распределению, что позво- ляет делать прогнозы, демонстрирующие более уверенное поведение. Клю- чевая проблема, однако, заключается в самореферентности этого метода, что может привести к катастрофическому распространению ошибок, если их не обрабатывать должным образом. Излишне самоуверенные неверные прогно - зы в неопределенной области фактически могут остаться незамеченными, поскольку отсутствует какой-либо обучающий надзор за неразмеченными данными целевого домена. В свою очередь, эти ошибки прогнозирования могут быть подкреплены стратегией самообучения, вызывая постепен- но нарастающее отклонение от правильного решения. Чтобы справиться с этой проблемой, большинство подходов к адаптации, основанных на само- обучении, применяют к процессу псевдомаркировки определенные страте- гии фильтрации, так что ошибки прогнозирования, по своей сути влияющие на карты целевой сегментации, в значительной степени отбрасываются. Распространенный подход к адаптации на основе самонастройки вклю- чает автономные методы вычисления псевдометок (Zou et al., 2018, 2019; Li et al., 2019), при этом в процессе адаптации доверительный порог обновля- ется несколько раз путем просмотра всего доступного обучающего набора. В частности, используется итеративная процедура оптимизации самона- стройки, которая чередует этапы самонастройки и обуче ния с учителем на искусственных аннотациях как исходного, так и целевого доменов. В течение всего этапа настройки искусственные аннотации целевого домена остают - ся фиксированными. Эта автономная стратегия обеспечивает стабильный процесс обуче ния за счет дополнительной вычислительной нагрузки из-за нескольких этапов псевдоаннотирования всего целевого набора данных. В другом подходе стратегия самонастройки может быть связана с состя- зательной адаптацией на уровне выхода (Biasetton et al., 2019; Michieli et al., 2020; Spadotto et al., 2020). В частности, выходную карту из полностью сверточного дискриминатора домена на уровне выхода можно рассматри- вать как точную меру надежности предсказания данных целевого домена,\n--- Страница 372 ---\nАдаптация домена без учителя  371 таким образом получая полезную информацию для уточнения целевых псев- дометок. Итак, качество искусственных аннотаций постепенно улучшается на протяжении всего процесса обуче ния, поскольку они вычисляются для отдельных пакетов целевых изображений, а не для всего набора данных, что в целом приводит к довольно эффективной адаптации. В качестве альтернативы надежность псевдометок можно повысить, при- бегнув к ансамблям прогнозов (Choi et al., 2019; Chen et al., 2019; Yang, Soatto, 2020; Zhou et al., 2020). Например, можно использовать дополнительную сеть для самонастройки на неразмеченных образцах (Чой и др., 2019; Чжоу и др., 2020). Это делается путем введения сети учителя в дополнение к исходной, которая играет роль ученика. Затем модель-учитель, чьи веса усредняются по весам учеников на прошлых этапах настройки, используется для управ- ления процессом обуче ния сети-ученика, давая целевые прогнозы, которым ученик вынужден подражать. Наставничество сети-учителя приводит к более точным прогнозам целей, для которых может выполняться менее шумная псевдомаркировка. В результате получается более эффективная адаптация с самонастройкой. Минимизация энтропии. Минимизация энтропии, также позаимство- ванная из области обуче ния с частичным участием учителя, недавно была введена в UDA (Vu et al., 2019). Идея, стоящая за этим подходом, заключает - ся в том, что исходные прогнозы более склонны демонстрировать уверен- ное поведение, что проявляется в низком уровне энтропии вероятностных выходных данных. И наоборот, выходные карты сегментации из входных данных целевого домена, вероятно, будут демонстрировать большую не- определенность (высокую энтропию), при этом шумовая картина широко размыта и не ограничивается только областями, близкими к семантическим границам. Таким образом, отражая чрезмерно самоуверенное поведение источника в неопределенном целевом домене, сеть сегментации должна, в принципе, преодолеть разрыв в качестве, существующий между доменами. Точнее, эффект минимизации энтропии заключается в том, чтобы избежать пересечения границами классификации областей с высокой плот ностью в скрытом пространстве, в то время как целевые представления хорошо сгруппированы вдали от этих границ. Первоначальная стратегия минимизации энтропии (Vu et al., 2019) ра- ботает на уровне пикселей, при этом каждая отдельная пространственная единица независимо способствует достижению общей цели. Однако для пре- одоления некоторых присущих этому подходу ограничений были введены дополнительные механизмы (Vu et al., 2019; Chen et al., 2019a; Yang, Soatto, 2020). Возможное решение состоит в том, чтобы добиться глобального сбли- жения распределения энтропии с по мощью состязательного подхода к адап- тации домена, где дискриминатор домена получает карты энтропии, а не напрямую выходные вероятностные диаграммы, как в стандартной схеме из раздела 8.2.3.1 (Vu et al., 2019). Следовательно, в этом методе используется структурная информация, заключенная в картах энтропии, что приводит к более эффективной статистической адаптации домена. Кроме того, сле- дует отметить, что цель минимизации энтропии в ее первоначальном виде (Vu et al., 2019) приводит к быстрому градиентному взрыву при переходе от\n--- Страница 373 ---\n372  Адаптация домена и непрерывное обучение семантической сегментации областей высокой неопределенности к области низкой, что может серьезно затруднить процесс обуче ния. Решением данной проблемы может стать из- менение стандартной цели (например, на основе квадратичных потерь), на цель, аналогичную исходной, но с улучшенными свойствами градиентного сигнала (Chen et al., 2019). Эта стратегия вместе с категориальными весовы- ми коэффициентами для балансировки вклада различных семантических классов значительно улучшает процесс адаптации. В нескольких недавних работах минимизация энтропии применялась вмес те с методами формирования пространства признаков (Toldo et al., 2021; Barbato et al., 2021). В соответствии с этим подходом, помимо использования минимизации энтропии, заставляют представления внутренних признаков быть сгруппированными, разреженными и ортогональными (если они при- надлежат разным классам) как в исходном, так и в целевом доменах, чтобы улучшить адаптацию на уровне признаков. Другая недавняя работа (Barbato et al., 2021) дополнительно вводит ограничение сближения нормы, чтобы помочь цели ортогональности признаков по классам распространять не- пересекающиеся наборы каналов активных признаков между отдельными семантическими категориями, при этом направляя целевые вложения к вы- соконадежному (т. е. связанному с высокими значениями нормы признака) исходному распределению. 8.2.3.5. Многозадачность Последний класс методов адаптации, который необходимо обсудить, от - носится к многозадачности (Lee et al., 2019; Vu et al., 2019; Chen et al., 2019; Watanabe et al., 2018). Регуляризация достигается путем решения нескольких связанных задач (например, многие подходы сосредоточены на глубинной регрессии) в дополнение к задаче семантической сегментации. Цель состоит в том, чтобы неявно извлечь инвариантные предметные области и семанти- чески значимые представления из изображений, поскольку они должны быть более подходящими для одновременного решения связанных задач. Глубин- ная регрессия (depth regression) обычно используется в сочетании с семан- тической сегментацией, чтобы упорядочить процесс адаптации на входном уровне на основе преобразования исходного изображения в целевое (раз- дел 8.2.3.2). Также было показано, что многозадачная адаптация эффективно интегрируется с другими подходами к адаптации. Например, ее можно ис - пользовать для улучшения стратегии максимального классификатора (раз- дел 8.2.3.3), где вместо одного плотного классификатора используются два отдельных модуля декодера для получения карт глубины и карт сегментации (Watanabe et al., 2018). Можно сочетать многозадачность с методом миними- зации состязательной энтропии (раздел 8.2.3.4) (Vu et al., 2019), объединяя карты собственной информации с картами прогнозирования глубины перед их подачей на дискриминатор домена. Таким образом повышается способ- ность обнаружения доменным дискриминатором расхождения представле- ний исходного и целевого доменов, что в конечном итоге обеспечивает более надежное статистическое сближение.\n--- Страница 374 ---\nНепрерывное обучение  373 8.3. непреры Вное обу Чение В последнее время методы глубокого обуче ния особенно быстро развивались в направлениях, которые ранее считались чрезвычайно сложными, в част - ности в области компьютерного зрения, где модели глубокого обуче ния во многих случаях достигают человеческого уровня точности. Методы глубокого обуче ния постепенно совершенствовались, и переход от академических ис - следований к различным практическим и промышленным приложениям был лишь вопросом времени. Однако с началом практического применения мо- делей возникла потребность в методах, позволяющих со временем вводить новые знания, чтобы выполнять новые задачи, не забывая при этом преды- дущие. В этом и заключается парадигма непрерывного обуче ния. Другими словами, когда модели глубокого обуче ния внедряются в реальный мир, нам нужно иметь возможность улучшать возможности моделей с по мощью ново- го опыта или меток, не переобучая их с нуля. В целом основная проблема вычислительных моделей заключается в том, что они склонны к катастрофическому забыванию (McClelland et al., 1995; McCloskey, Cohen, 1989), т. е. обуче ние модели на новых данных мешает ис - пользованию ранее изученных знаний и, как правило, сильно ухудшает их представление. Модели глубокого обуче ния, в частности, предполагают, что на этапе обуче ния доступны все выборки данных, и поэтому при адаптации к изменениям данных они требуют обуче ния на полном наборе. При обуче- нии на последовательных задачах с ограниченными выборками, поступа- ющими с течением времени, качество работы модели с ранее изученными задачами значительно снижается, поскольку параметры сети оптимизиру - ются для новой задачи без учета старых, если не используются специальные условия (Kemker et al., 2018; Parisi et al., 2019). Непрерывное обуче ние (continual learning, CL, также называемое постепен- ным обуче нием, обуче нием на протяжении жизни модели или бесконечным обуче нием) представляет собой набор методов, разработанных для исполь- зования в сложной ситуации, когда последовательно выполняются меняю- щиеся задачи. Несмотря на то что эта проблема вычислительных моделей давно известна (McCloskey and Cohen, 1989), первые успехи в глубоком обуче- нии появились относительно недавно. Чтобы еще лучше осознать актуальность проблемы, стоит рассмотреть ана - логию между обуче нием машины и человека. Люди сталкиваются с непре- рывным потоком обучающих данных и способны обобщать схожие неявные задачи (Thrun, Pratt, 2012). На протяжении долгих лет ученые предпринима- ли неоднократные попытки понять механизмы обуче ния мозга и перенести их на вычислительные модели (Grossberg, 2013; Ditzler et al., 2015). В последнее время эту проблему активно изучают применительно к не- которым задачам с разметкой на уровне изображения (т. е. с одной или не- сколькими метками для каждого изображения), такой как классификация изображений (Rebuffi et al., 2017; Li, Hoiem, 2017; Castro et al., 2018) и обна- ружение объектов (Shmelkov et al., 2017). В задачах плотной разметки, таких как семантическая сегментация, из-за присущей им повышенной сложности\n--- Страница 375 ---\n374  Адаптация домена и непрерывное обучение семантической сегментации к решению этой проблемы приступили совсем недавно (Ozdemir, Goksel, 2019; Tasar et al., 2019; Michieli and Zanuttigh, 2019, 2021b; Cermelli et al., 2020; Klingner et al., 2020; Douillard et al., 2021). Прежде чем углубиться в определение непрерывного обуче ния и изучить его применение к задачам плотной разметки, мы хотели бы отдельно от - метить некоторые общие обзоры по теме, не имеющие прямого отношения к семантической сегментации. Можно выделить работу, посвященную ката- строфическому забыванию в сетевых моделях (French, 1999), в то время как статья (Parisi et al., 2019) – это первый обзор, в котором критически сопо- ставляются недавние работы об этом явлении в моделях глубокого обуче- ния. В (De Lange et al., 2019) многие подходы сравниваются в общем плане, а в работе (Lesort et al., 2020) рассмотрены проблемы непрерывного обуче ния с особым акцентом на робототехнику. 8.3.1. Формулировка задачи непрерывного обучения Непрерывное обуче ние (CL) можно рассматривать как частный случай обуче- ния с переносом, когда распределение домена меняется на каждом шаге приращения и модель должна хорошо работать на всех распределениях. Этот сценарий также тесно связан с задачей адаптации домена, но в данном слу - чае основное внимание уделяется как входным данным, так и аннотациям, распределение которых со временем меняется, и их количество также может быть увеличено (т. е. понадобится различать больше классов). С другой стороны, стоит отметить, что обсуждение адаптации домена в предыдущем разделе было сфокусировано на входных распределениях домена, где обычно и выполняется адаптация одного домена. В последнее время появились гибридные подходы, сочетающие UDA и CL для преодоле- ния множественных изменений в доменах и задачах (Busto, Gall, 2017; Zhuo et al., 2019; Kundu et al., 2020). Из-за присущего непрерывному обуче нию разнообразия проблем и свя- занных с ними трудностей в большинстве подходов ослабляют общую проб- лему непрерывного обуче ния до более легкого поэтапного изучения задач. В таком случае новые задачи поступают по одной, и обуче ние выполняется на доступных обучающих данных. Фактически это упрощенный вариант истинной системы непрерывного обуче ния, которая, скорее всего, будет встречаться на практике (De Lange et al., 2019). Например, при поэтапном обучении готовую модель обновляют, чтобы она научилась распознавать новые классы, сохраняя при этом знания о предыдущих. Схема такого подхода изображена на рис. 8.7. Говоря более формально, мы рассматриваем t-й инкрементный шаг p (где t = 1, 2, …, Tmax), и у нас есть предыдущая модель ℳt–1 и два набора данных {𝒳(t), 𝒴(t)}, рандом- но выбранных из распеределения 𝒟(t), которое является наблюдением (или подмножеством) полного домена 𝒟. Здесь 𝒳(t) обозначает набор образцов данных для шага t, а 𝒴(t) – соответствующие эталонные аннотации (т. е. одну метку для задачи классификации изображений или карту плотных меток для\n--- Страница 376 ---\nНепрерывное обучение  375 задачи семантической сегментации). В рассматриваемой здесь пошаговой настройке модели под новые классы мы предполагаем, что каждый шаг со- ответствует отдельной обучающей задаче. Новые классы Новые классы Модель 2 Модель 1 Модель 0 Непрерывное обучение Рис. 8.7  Графическое представление схемы непрерывного обуче ния с приращением новых классов. Модель обновляется, чтобы научиться распознавать новые классы, не забывая ранее изученные Чтобы имитировать ситуации реального применения и уменьшить по- требность в хранении пользовательских данных или обойти ограничения конфиденциальности, большинство фреймворков не хранят никакие наборы данных {𝒳(s), 𝒴(s)} для любого шага s, предшествующего текущему шагу t. Сле - довательно, проблема становится еще более сложной, поскольку цель состоит в том, чтобы контролировать целевую функцию, состоящую из всех наблю- даемых задач, без доступа к предыдущим выборкам. В более формальном представлении эмпирический механизм минимизации риска преобразуется в исследование оптимальных параметров θ∗ путем оптимизации: (8.1) с параметрами модели θ, функцией потерь ℒ, T дополнительных задач, на- блюдаемых до текущего момента, и ℳt признаков модели на шаге t. Заметим, однако, что эта целевая функция не может быть оптимизирована напрямую, поскольку старые образцы могут вообще не присутствовать или могут быть очень ограниченными (в зависимости от сценария непрерывного обуче ния, см. раздел 8.3.2). Мы рассматриваем случай, когда доступны все образцы, как совмещенное обуче ние (joined learning), представляющее верхний предел качества системы непрерывного обуче ния (т. е. один этап обуче ния со всеми образцами сразу). Кроме того, полезно получить представление о проблеме с точки зрения предельных выходных и входных распределений, то есть P(𝒴(t)) и P(𝒳(t)) со- ответственно, для обобщенного шага t. В общем случае инкрементное обуче-\n--- Страница 377 ---\n376  Адаптация домена и непрерывное обучение семантической сегментации ние модели новым задачам предполагает, что P(𝒴(t+1)) ≠ P(𝒴(t)), поскольку P(𝒳(t+1)) ≠ P(𝒳(t)) и выходное пространство задачи меняется со временем, т. е. {𝒴(t)} ≠ {𝒴(t+1)}. Продолжая нашу аналогию со сценарием UDA, мы могли бы свести пошаговое обуче ние новой задаче обратно к UDA, принимая P(𝒴(t+1)) ≠ P(𝒴(t)) из-за P(𝒳(t+1)) ≠ P(𝒳(t)), но {𝒴(t)} = {𝒴(t+1)} с количеством инкременталь- ных шагов Tmax = 1 и обычно внезапным изменением в распределении дан- ных домена, в то время как изменения при непрерывном обучении в целом более постепенны (De Lange et al., 2019; Hsu et al., 2018). Наконец, отметим, что идеальные схемы непрерывного обуче ния рас - сматривают бесконечный и непрерывный поток обучающих данных, и на каждом этапе система получает несколько новых образцов, полученных без соблюдения условия независимости и одинакового распределения из теку - щего распределения 𝒟(t), которое само может подвергаться внезапным или постепенным изменениям без уведомления. Именно на эту схему должны быть ориентированы методы, разработанные в будущем. 8.3.2. Особенности непрерывного обучения в семантической сегментации Несмотря на то что это совсем новая область, непрерывное обуче ние семан- тической сегментации уже встречается в разных вариантах. В частности, существующие работы различаются тем, как в них рассматривают доменные распределения 𝒟(t) и наборы данных {𝒳(t), 𝒴(t)}. Наличие разных вариантов обусловлено разными целевыми применениями. Обозначим через 𝒮(t–1) пре- дыдущий набор меток, который расширяется набором новых классов 𝒞(t) на шаге t, что дает новый набор меток 𝒮(t) = 𝒮(t–1) È 𝒞(t). Как обычно предпола- гается в инкрементных методах, наборы новых меток, обнаруживаемых на каждом шаге, не пересекаются, за исключением специального класса фоно- вых меток background или пустого класса void , поведение и значение которых зависят от выбранного сценария. Существует множество возможных сцена- риев, и одно из ключевых отличий заключается в том, как рассматривается фоновый класс, что типично для многих бенчмарков семантической сегмен- тации. Существующие подходы относятся к одному из четырех основных сценариев: 1. Последовательный маскированный. Этот вариант отражает прос - тейшую идею непрерывной семантической сегментации, т. е. каждый шаг обуче ния содержит уникальный набор изображений, пиксели ко- торых принадлежат либо к новым классам, либо к пустому классу, ко- торый не предсказывается моделью и маскируется как в результатах, так и из процедуры обуче ния. Данный механизм описан в (Tasar et al., 2019 г.; Klingner et al., 2020). 2. Последовательный. Этот вариант был предложен Микьели и Занут - тигом (Michieli, Zanuttigh, 2019, 2021). Каждый шаг обуче ния содер- жит уникальный набор изображений, пиксели которых принадлежат классам, наблюдаемым либо на текущем, либо на предыдущих этапах\n--- Страница 378 ---\nНепрерывное обучение  377 обуче ния. На каждом шаге присутствуют метки для пикселей как новых классов, так и старых; однако конкретное появление определенного старого класса сильно коррелирует с набором добавляемых классов. Например, если набор всех старых классов 𝒮(t–1) = {стул, самолет}, а набор добавляемых классов есть 𝒞(t) = {обеденный стол}, то разумно ожидать, что {𝒳(t), 𝒴(t)} содержит некоторые изображения, относящие- ся к классу стульев, который обычно встречается вместе с обеденным столом, в то время как изображения самолета крайне маловероятны. 3. Непересекающийся. Этот вариант был предложен (Cermelli et al., 2020; Michieli, Zanuttigh, 2021). На каждом этапе обуче ния уникаль- ный набор изображений такой же, как в последовательном варианте. Отличие заключается в наборе меток. На каждом шаге присутствуют только метки для пикселей новых классов, в то время как старые по- мечаются на картах сегментации как фон (это приводит к изменению распределения фонового класса на каждом шаге). 4. Перекрывающийся. Этот вариант заимствован из работы Шмелько- ва и др. (Shmelkov et al., 2017), посвященной обнаружению объектов, и рассмотрен в работах (Cermelli et al., 2020; Douillard et al., 2021; Mich- ieli, Zanuttigh, 2021) применительно к семантической сегментации. В этой настройке каждый шаг обуче ния содержит все изображения, которые имеют хотя бы один пиксель нового набора классов, причем только классы этого набора аннотированы, а остальные считаются фо- ном. В отличие от других вариантов, в этом сценарии изображения могут содержать пиксели классов, которые будут изучены в будущем, но помечены как фон на текущем шаге; по этой причине, как и в пре- дыдущем случае, фоновый класс меняет распределение на каждом шаге итерации. Несколько примеров различных аннотаций семантической карты при - ведены на рис. 8.8. Хотя они являются подкатегориями одной и той же зада- чи, они приводят к существенно разным ситуациям, требующим различных стратегий для решения. Этот многовариантный сценарий становится еще более гибким, если учесть, что существует множество различных способов формирования набо- ров 𝒞(t) незнакомых классов и выбора их кардинальности |𝒞(t)|, что заставило исследователей провести множество совершенно разных экспериментов. На- пример, давайте рассмотрим один из наиболее широко используемых тестов для семантической сегментации – набор данных Pascal VOC2012 (Everingham et al., 2010), который состоит из 21 семантического класса (включая фон). Что касается первого аспекта, одна из возможностей состоит в том, чтобы отсор- тировать классы, используя заранее определенный порядок, предоставлен- ный набором данных (например, алфавитный порядок для VOC2012), как это сделано в (Shmelkov et al., 2017; Michieli, Zanuttigh, 2019, 2021; Cermelli et al., 2020; Douillard et al., 2021; Michieli, Zanuttigh, 2021). Другой возможностью является сортировка классов на основе их встречаемости в наборе данных (Michieli, Zanuttigh, 2021), чтобы отразить идею о том, что в реальных при- ложениях было бы разумно начать с общих классов, а затем ввести более редкие. Что касается второго аспекта, то можно последовательно добавлять\n--- Страница 379 ---\n378  Адаптация домена и непрерывное обучение семантической сегментации один класс, группу классов или несколько классов (Michieli, Zanuttigh, 2019, 2021; Cermelli et al., 2020; Douillard et al., 2021; Michieli, Zanuttigh, 2021). Все эти возможности образуют весьма пеструю картину, к исследованию которой приступили лишь недавно, поэтому многие направления остаются до сих пор неизученными. Последовательный с маской Изображение Эталон Последовательный Непересекающийся не представлен не представлен не представленПерекрывающийся обученомашина человек велосипедсобака текущий будущийфон без маркировки Рис. 8.8  Обзор различных сценариев непрерывного обуче ния с добавлени- ем класса при семантической сегментации. Черный цвет представляет фоновый класс background , а белый – пустой/непомеченный класс void/unlabeled 8.3.3. Методы поэтапного обучения В этом разделе мы рассмотрим основные методы решения инкрементной задачи семантической сегментации, сгруппированные по используемой тех - нике. Мы также предлагаем заинтересованным читателям самостоятельно ознакомиться с некоторыми соответствующими работами по инкрементной классификации изображений, поскольку эта родственная область является более изученной и зрелой в отношении семантической сегментации. 8.3.3.1. Дистилляция знаний Мы начнем с метода, который используют наиболее часто благодаря его простоте и эффективности, – это дистилляция знаний (knowledge distilla- tion). Этот метод изначально был предложен (Bucilua et al., 2006) и (Hinton et al., 2015), чтобы сохранить выходные данные сложного ансамбля сетей при переходе на более простую сеть для более эффективного ее разверты- вания. Впоследствии идея была адаптирована для сохранения неизменным\n--- Страница 380 ---\nНепрерывное обучение  379 отклика сети на старые задачи при обновлении ее новыми обучающими выборками, обычно связанными с новыми задачами. Как правило, этого добиваются путем применения ограничения (например, функции потерь), чтобы имитировать ответы предыдущей модели в ее текущей версии. Основ- ной эффект ограничения заключается в его действии как мощного фактора регуляризации в процессе изучения текущих классов, что часто приводит к лучшим результатам как на предыдущих, так и на текущих классах (за счет сохранения способности распознавать первый набор и избегать переоценки последнего набора). Дистилляция знаний изучалась в различных условиях, и в некотором роде она является обязательным компонентом успешных алгоритмов инкремент - ного обуче ния новым задачам. Многие алгоритмы используют дистилляцию знаний в разных вариантах задачи с разреженной разметкой: например, в работе (Shmelkov et al., 2017) предлагают сквозную схему обуче ния, в ко- торой представление и классификатор обучаются совместно без сохранения каких-либо исходных обучающих образцов. Ли и Хойем (Li, Hoiem, 2017) извлекают предыдущие знания непосредственно из последней обученной модели. Дхар и др. (Dhar et al., 2019) вводят потерю дистилляции внимания в качестве штрафа за сохранение информации для карт внимания классифи- каторов. Чжоу и др. (Zhou et al., 2019) извлекают из всех предыдущих снимков модели знания, из которых составляется сокращенная версия. Было обнаружено, что эти методы чрезвычайно эффективны и надеж - ны даже при выполнении сложных задач. Оздемир и Гоксель (Ozdemir and Goksel, 2019) расширяют модель классификации изображений Ли и Хойема (Li, Hoiem, 2017) до сегментации, просто выражая потери при дистилляции знаний как перекрестную энтропию между вероятностями вывода преды- дущей и текущей моделей. Авторы также разрабатывают стратегию выбора соответствующих образцов старых данных для повторного использования, что улучшает качество модели, но нарушает предположение многих сце - нариев об отказе от хранения предыдущих данных. Тасар и др. (Tasar et al., 2019) применяют дистилляцию знаний посредством перекрестной энтропии между выходными вероятностями предыдущей и текущей моделей для каж - дого класса, поскольку модель прогнозирует карты бинарной сегментации для каждого класса отдельно. Микьели и Зануттиг (Michieli, Zanuttigh, 2019) оценивают стандартный бенчмарк семантической сегментации и предла- гают применять дистилляцию знаний не только на уровне вывода, но и на промежуточном пространстве признаков, чтобы сохранить геометрические отношения извлеченных признаков. Работа расширена в (Michieli, Zanut - tigh, 2021), где представлены и сравниваются многие методы дистилляции знаний. В частности, дистилляция на выходном слое обогащена темпера- турным масштабированием (т. е. масштабированием вероятностей softmax с по мощью так называемого температурного коэффициента), чтобы учесть также неопределенность оценок предыдущих моделей. В работе (Tung, Mori, 2019) дистилляция на промежуточном уровне признаков расширена до не- скольких этапов декодирования, а также предлагается схема на основе дис - тилляции знаний с сохранением подобия. Чермелли и др. (Cermelli et al., 2020) предлагают рассмотреть потери при дистилляции на уровне вывода,\n--- Страница 381 ---\n380  Адаптация домена и непрерывное обучение семантической сегментации учитывающие тот факт, что предыдущая модель могла уже быть знакома с предыдущими классами, помеченными как фон (т. е. упомянутый ранее вариант с перекрытием классов). Клингнер и др. (Klingner et al., 2020) пред- лагают учитывать маскированные и взвешенные потери при дистилляции на уровне выхода, чтобы повысить точность небольших или недостаточно представленных классов в наборе данных. Наконец, Дуйяр и др. (Douillard et al., 2021) применяют дистилляцию, чтобы сохранить статистику на разных уровнях признаков и в разных масштабах между старой и текущей моделями. 8.3.3.2. Замораживание параметров К главным достижениям ранних исследований сетевых моделей относится обнаружение одной из основных стратегий решения проблемы катастрофи- ческого забывания – замораживание части весов сети (Rebuffi et al., 2017). Этот метод применялся во многих современных подходах в качестве по- пытки регуляризации для предотвращения деградации знаний, вызванной будущими задачами. Например, Шмельков и др. (2017) проводят экспери- мент по замораживанию либо всех слоев (кроме последнего), либо их части. Мандзюк и Шастри (Mandziuk, Shastri, 2002) пытаются найти и заморозить компактное подмножество признаков (узлов) в скрытых слоях, имеющих ре- шающее значение для текущей задачи, тем самым предотвращая забывание в будущем. Аналогичным образом Киркпатрик и др. (Kirkpatrick et al., 2017) запоминают старые задачи, замедляя процесс обуче ния на соответствующих весовых коэффициентах для этих задач. Юнг и др. (Jung et al., 2016) пытаются сохранить качество модели на старых задачах, замораживая последний слой и препятствуя изменению общих весов в слоях извлечения признаков. Замораживание параметров как способ предотвращения забывания было также предложено в задаче плотной разметки. Микьели и Зануттиг (2019) предлагают заморозить все уровни кодировщика, чтобы сохранить неизмен - ными возможности извлечения признаков и обучать только параметры деко- дирования. Эти же авторы используют идею замораживания только первых нескольких слоев кодировщика, чтобы сохранить наиболее независимую от задачи часть экстрактора признаков. Однако вопрос о том, какие слои сле- дует заморозить, остается открытым, и существует внутренний компромисс между возможностью эффективного изучения новых задач и сохранением полученных знаний. Первая попытка автоматического выбора слоев для за- мораживания на основании поиска самых пластичных слоев сети была не- давно предложена в работе (Nguyen et al., 2020). 8.3.3.3. Геометрическая регуляризация на уровне признаков Анализ организации скрытого пространства приобретает решающее зна - чение для понимания и улучшения глубоких нейронных сетей (Bengio et al., 2013; Girshick et al., 2014; Xian et al., 2016; Peng et al., 2019). В последнее время определенное внимание уделяется скрытой регуляризации при не - прерывной классификации изображений (Achille et al., 2018; Javed, White, 2019) и адаптации домена без учителя (Toldo et al., 2021; Barbato et al., 2021).\n--- Страница 382 ---\nНепрерывное обучение  381 Ключевая идея этих подходов состоит в том, чтобы по-разному разделить промежуточное пространство признаков, разнести признаки разных клас - сов. При непрерывном обучении это может уменьшить перекрытие, когда в модель вводятся будущие классы. Единственная работа, использующая эту идею в сложных задачах, – это (Michieli, Zanuttigh, 2021), где скрытое пространство ограничивают, чтобы уменьшить забывание и улучшить распознавание новых классов. Эта схема зависит от трех основных компонентов: во-первых, совпадение прототипов обеспечивает целостность скрытого пространства для старых классов, за- ставляя кодировщик создавать аналогичные скрытые представления для ранее просмотренных классов на последующих этапах; во-вторых, проре- живание признаков позволяет освободить место в скрытом пространстве для размещения новых классов; в-третьих, для группировки признаков в со- ответствии с их семантикой используется контрастное обуче ние, при этом разделяют признаки разных классов. 8.3.3.4. Новые направления В публикациях по непрерывному обуче нию были предложены и другие но- вые идеи как для плотной, так и для разреженной маркировки. Далее мы представляем лишь некоторые из наиболее перспективных направлений исследований. Инициализация весов использовалась в (Cermelli et al., 2020), чтобы справиться с нетипичным поведением фонового класса в сценариях с не- пересекающимися и перекрывающимися классами. Авторы инициализируют параметры классификатора для новых классов таким образом, что вероят - ность фона равномерно распределяется между новыми классами, предотвра- щая смещение модели в сторону фонового класса при работе с незнакомыми классами. Методы генеративного воспроизведения (generative replay) обучают ге- неративные модели текущему распределению данных; после этого можно генерировать имитации данных из прошлого опыта при изучении новых данных. Изучая реальные новые данные, смешанные с искусственно сгене- рированными прошлыми данными, модели пытаются сохранить прошлые знания при изучении новой задачи. Генеративная модель обычно представ- ляет собой GAN (Goodfellow et al., 2014), как в (Wu et al., 2018) и (Shin et al., 2017), или автокодировщик, как у (Draelos et al., 2017) и (Kamra et al., 2017). Обратите внимание, что для сгенерированных данных доступны только сла- бые метки классов, и для сегментации необходимо вычислять некоторые псевдометки. Интернет-обучаемые модели (Hou et al., 2018; Modolo, Ferrari, 2017), т. е. модели, которые учатся на образцах, полученных с по мощью веб-поиска, могут быть чрезвычайно мощным инструментом для получения достовер- ных старых образцов с использованием в качестве запросов имен меток старых классов, которые нужно сохранить. В этом случае также доступны только слабые метки классов, и необходимо добавить в модель какую-то схему псевдомаркировки.\n--- Страница 383 ---\n382  Адаптация домена и непрерывное обучение семантической сегментации 8.4. заКЛюЧение Семантическая сегментация изображений является активной областью ис - следований, направленных на достижение детального и точного понимания сцены. Будучи задачей плотной разметки, она обладает дополнительной сложностью по сравнению с классическими задачами классификации изо- бражений. Для решения этой задачи было предложено множество моделей глубокого обуче ния, однако их архитектуры требуют больших аннотиро- ванных обучающих наборов данных и демонстрируют плохие возможности адаптации к незнакомым доменам или задачам. В последние годы исследо- ватели ведут активную деятельность в области адаптации доменов и непре- рывного обуче ния, направленную на устранение упомянутых ограничений. В этой главе мы рассмотрели адаптацию домена без учителя (т. е. когда для обуче ния не используются размеченные данные целевого домена) примени- тельно к задаче плотной семантической сегментации. Затем мы показали, что для решения этой задачи можно применить непрерывное обуче ние, ор- ганизованное несколькими разными способами. Алгоритмы, разработанные к настоящему времени, способны значи- тельно уменьшить деградацию модели, хотя им все еще необходимо до- стичь большей зрелости, прежде чем их можно будет применять в ответ - ственных реальных сценариях (например, в автономном вождении). На самом деле осталось много нерешенных проблем в плане как адаптации сложных архитектур глубокого обуче ния к различным задачам и областям, так и их способности изучать новые концепции, не забывая ранее полу - ченные знания. Кроме того, в реальных сценариях использования моделей возникает много сопутствующих побочных проблем. К перспективным направлениям можно отнести, например, обобщение из нескольких распределений данных, UDA с открытым набором классов (т. е. распознавание классов в целевой области, никогда не встречавшихся в исходной) и непрерывный UDA (т. е. непрерывный процесс адаптации к незнакомым доменам и задачам). бЛагодарности Наша работа была частично поддержана итальянским министерством об- разования (MIUR) в рамках инициативы «Направления передового опыта» (Закон 232/2016). Литературные исто ЧниКи Achille A., Eccles T., Matthey L., Burgess C., Watters N., Lerchner A., Higgins I., 2018. Life-long disentangled representation learning with cross-domain latent homologies. In: Neural Information Processing Systems (NeurIPS).\n--- Страница 384 ---\nЛитературные источники  383 Barbato F., Toldo M., Michieli U., Zanuttigh P., 2021. Latent space regularization for unsupervised domain adaptation in semantic segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern RecognitionWorkshops (CVPRW). Bengio Y., Courville A., Vincent P., 2013. Representation learning: a review and new perspectives. In: IEEE Transactions on Pattern Analysis and Machine Intel- ligence (TPAMI). IEEE, pp. 1798–1828. Biasetton M., Michieli U., Agresti G., Zanuttigh P., 2019. Unsupervised domain adap- tation for semantic segmentation of urban scenes. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Bucher M., Vu T. H., Cord M., Pérez P., 2020. Buda: boundless unsupervised domain adaptation in semantic segmentation. arXiv preprint. arXiv:2004.01130. Bucilua C., Caruana R., Niculescu-Mizil A., 2006. Model compression. In: Proc. of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 535–541. Busto P. P., Gall J., 2017. Open set domain adaptation. In: Proceedings of the In- ternational Conference on Computer Vision (ICCV), pp. 754–763. Castro F. M., Marín-Jiménez M. J., Guil N., Schmid C., Alahari K., 2018. End-to-end incremental learning. In: Proceedings of the European Conference on Computer Vision (ECCV), pp. 233–248. Cermelli F., Mancini M., Bulò S. R., Ricci E., Caputo B., 2020. Modeling the back - ground for incremental learning in semantic segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Chang W., Wang H., Peng W., Chiu W., 2019. All about structure: adapting struc - tural information across domains for boosting semantic segmentation. In: Pro- ceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1900–1909. Chen Y., Li W., Chen X., Van Gool L., 2018. Learning semantic segmentation from synthetic data: a geometrically guided input-output adaptation approach. arXiv preprint. arXiv:1812.05040. Chen M., Xue H., Cai D., 2019a. Domain adaptation for semantic segmentation with maximum squares loss. In: Proceedings of the International Conference on Computer Vision (ICCV). Chen Y., Li W., Chen X., Gool L. V., 2019b. Learning semantic segmentation from synthetic data: a geometrically guided input-output adaptation approach. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recogni- tion (CVPR), pp. 1841–1850. Chen Y. C., Lin Y. Y., Yang M. H., Huang J. B., 2019c. Crdoco: pixel-level domain transfer with cross-domain consistency. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Chen Y. H., Chen W. Y., Chen Y. T., Tsai B. C., Frank Wang Y. C., Sun M., 2017. No more discrimination: cross city adaptation of road scene segmenters. In: Pro- ceedings of the International Conference on Computer Vision (ICCV), pp. 1992– 2001. Choi J., Kim T., Kim C., 2019. Self-ensembling with gan-based data augmentation for domain adaptation in semantic segmentation. In: Proceedings of the Inter - national Conference on Computer Vision (ICCV), pp. 6830–6840.\n--- Страница 385 ---\n384  Адаптация домена и непрерывное обучение семантической сегментации De Lange M., Aljundi R., Masana M., Parisot S., Jia X., Leonardis A., Slabaugh G., Tuytelaars T., 2019. Continual learning: a comparative study on how to defy forgetting in classification tasks. arXiv preprint. arXiv:1909.08383. Deng J., Dong W., Socher R., Li L., Li K., Li F., 2009. Imagenet: a large-scale hier - archical image database. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 248–255. Dhar P., Singh R. V., Peng K. C., Wu Z., Chellappa R. , 2019. Learning without memo - rizing. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5138–5146. Ditzler G., Roveri M., Alippi C., Polikar R., 2015. Learning in nonstationary environ- ments: a survey. IEEE Computational Intelligence Magazine 10, 12–25. Douillard A., Chen Y., Dapogny A., Cord M., 2021. Plop: learning without forgetting for continual semantic segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Draelos T. J., Miner N. E., Lamb C. C., Cox J. A., Vineyard C. M., Carlson K. D., Severa W. M., James C. D., Aimone J. B., 2017. Neurogenesis deep learning: extending deep networks to accommodate new classes. In: 2017 International Joint Con- ference on Neural Networks (IJCNN). IEEE, pp. 526–533. Du L., Tan J., Yang H., Feng J., Xue X., Zheng Q., Ye X., Zhang X., 2019. SSF-DAN: sepa- rated semantic feature based domain adaptation network for semantic segmenta- tion. In: Proceedings of the International Conference on Computer Vision (ICCV). Dundar A., Liu M., Wang T., Zedlewski J., Kautz J., 2018. Domain stylization: a strong, simple baseline for synthetic to real image domain adaptation. arXiv preprint. arXiv:1807.09384. Everingham M., Van Gool L., Williams C. K., Winn J., Zisserman A., 2010. The Pas- cal visual object classes (VOC) challenge. International Journal of Computer Vision 88, 303–338. French R. M., 1999. Catastrophic forgetting in connectionist networks. Trends in Cognitive Sciences 3, 128–135. Ganin Y., Lempitsky V., 2015. Unsupervised domain adaptation by backpropaga- tion. In: Proceedings of the International Conference on Machine Learning (ICML), pp. 1180–1189. Ganin Y., Ustinova E., Ajakan H., Germain P., Larochelle H., Laviolette F., Marchand M., Lempitsky V., 2016. Domain-adversarial training of neural networks. Journal of Machine Learning Research 17, 2096–2130. Girshick R., Donahue J., Darrell T., Malik J., 2014. Rich feature hierarchies for ac - curate object detection and semantic segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 580–587. Gong R., Li W., Chen Y., Gool L. V., 2019. DLOW: domain flow for adaptation and generalization. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2477–2486. Goodfellow I., Pouget-Abadie J., Mirza M., Xu B., Warde-Farley D., Ozair S., Courville A., Bengio Y., 2014. Generative adversarial nets. In: Neural Information Process- ing Systems (NeurIPS), pp. 2672–2680. Grandvalet Y., Bengio Y., 2005. Semi-supervised learning by entropy minimization. In: Actes de CAP 05, Conférence francophone sur l’apprentissage automatique, pp. 281–296.\n--- Страница 386 ---\nЛитературные источники  385 Grossberg S., 2013. Adaptive resonance theory: how a brain learns to consciously attend, learn, and recognize a changing world. Neural Networks 37, 1–47. Hinton G., Vinyals O., Dean J., 2015. Distilling the knowledge in a neural network. arXiv preprint. arXiv:1503.02531. Hoffman J., Tzeng E., Park T., Zhu J. Y., Isola P., Saenko K., Efros A., Darrell T., 2018. Cycada: cycle-consistent adversarial domain adaptation. In: Proceedings of the International Conference on Machine Learning (ICML). Hoffman J., Wang D., Yu F., Darrell T., 2016. FCNs in the wild: Pixel-level adver - sarial and constraint-based adaptation. arXiv preprint. arXiv:1612.02649. Hou Q., Cheng M. M., Liu J., Torr P. H., 2018. Webseg: learning semantic segmenta- tion from web searches. arXiv preprint. arXiv:1803.09859. Hsu Y. C., Liu Y. C., Ramasamy A., Kira Z., 2018. Re-evaluating continual learn- ing scenarios: a categorization and case for strong baselines. arXiv preprint. arXiv:1810.12488. Javed K., White M., 2019. Meta-learning representations for continual learning. In: Neural Information Processing Systems (NeurIPS). Jung H., Ju J., Jung M., Kim J., 2016. Less-forgetting learning in deep neural net - works. arXiv preprint. arXiv: 1607.00122. Kamra N., Gupta U., Liu Y., 2017. Deep generative dual memory network for con- tinual learning. arXiv preprint. arXiv:1710.10368. Kemker R., McClure M., Abitino A., Hayes T. L., Kanan C., 2018. Measuring cata- strophic forgetting in neural networks. In: Thirty-Second AAAI Conference on Artificial Intelligence. Kirkpatrick J., Pascanu R., Rabinowitz N., Veness J., Desjardins G., Rusu A. A., Mi- lan K., Quan J., Ramalho T., Grabska-Barwinska A., et al. , 2017. Overcoming cata - strophic forgetting in neural networks. Proceedings of the National Academy of Sciences (PNAS) 114, 3521–3526. Klingner M., Bär A., Donn P., Fingscheidt T., 2020. Class-incremental learning for semantic segmentation re-using neither old data nor old labels. In: IEEE Inter - national Conference on Intelligent Transportation Systems (ITSC). Kundu J. N., Venkatesh R. M., Venkat N., Revanur A., Babu R. V., 2020. Class-in- cremental domain adaptation. In: Proceedings of the European Conference on Computer Vision (ECCV). Lee K., Ros G., Li J., Gaidon A., 2019a. SPIGAN: privileged adversarial learning from simulation. In: International Conference on Learning Representations (ICLR). Lee S., Kim D., Kim N., Jeong S. G., 2019b. Drop to adapt: learning discriminative features for unsupervised domain adaptation. In: Proceedings of the Interna- tional Conference on Computer Vision (ICCV), pp. 91–100. Lesort T., Lomonaco V., Stoian A., Maltoni D., Filliat D., Díaz-Rodríguez N., 2020. Continual learning for robotics: definition, framework, learning strategies, op- portunities and challenges. Information Fusion 58, 52–68. Li P., Liang X., Jia D., Xing E. P., 2018. Semantic-aware grad-gan for virtual-to-real urban scene adaption. In: Proceedings of British Machine Vision Conference (BMVC). Li Y., Yuan L., Vasconcelos N., 2019. Bidirectional learning for domain adaptation of semantic segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR).\n--- Страница 387 ---\n386  Адаптация домена и непрерывное обучение семантической сегментации Li Z., Hoiem D., 2017. Learning without forgetting. IEEE Transactions on Pattern Analysis andMachine Intelligence (TPAMI) 40, 2935–2947. Long M., Cao Y., Wang J., Jordan M. , 2015. Learning transferable features with deep adaptation networks. In: Proceedings of the International Conference on Machine Learning (ICML), pp. 97–105. Luo Y., Zheng L., Guan T., Yu J., Yang Y., 2019. Taking a closer look at domain shift: category-level adversaries for semantics consistent domain adaptation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Rec - ognition (CVPR). Ma´ndziuk J., Shastri L., 2002. Incremental class learning approach and its ap- plication to handwritten digit recognition. Information Sciences 141, 193–217. McClelland J. L., McNaughton B. L., O’Reilly R. C., 1995. Why there are comple- mentary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory. Psychological Review 102, 419. McCloskey M., Cohen N. J., 1989. Catastrophic interference in connectionist net - works: the sequential learning problem. In: Psychology of Learning and Motiva- tion, vol. 24. Elsevier, pp. 109–165. Michieli U., Biasetton M., Agresti G., Zanuttigh P., 2020. Adversarial learning and self-teaching techniques for domain adaptation in semantic segmentation. IEEE Transaction on Intelligent Vehicles. Michieli U., Zanuttigh P., 2019. Incremental learning techniques for semantic segmentation. In: Proceedings of the International Conference on Computer VisionWorkshops (ICCVW). Michieli U., Zanuttigh P., 2021a. Continual semantic segmentation via repulsion- attraction of sparse and disentangled latent representations. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Michieli U., Zanuttigh P., 2021b. Knowledge distillation for incremental learning in semantic segmentation. Computer Vision and Image Understanding 205, 103167. Modolo D., Ferrari V., 2017. Learning semantic part-based models from Google im- ages. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) 40, 1502–1509. Murez Z., Kolouri S., Kriegman D. J., Ramamoorthi R., Kim K., 2018. Image to image translation for domain adaptation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Nguyen G., Chen S., Do T., Jun T. J., Choi H. J., Kim D., 2020. Dissecting cata- strophic forgetting in continual learning by deep visualization. arXiv preprint. arXiv:2001.01578. Ozdemir F., Goksel O., 2019. Extending pretrained segmentation networks with additional anatomical structures. International Journal of Computer Assisted Radiology and Surgery 14, 1187–1195. Parisi G. I., Kemker R., Part J. L., Kanan C., Wermter S., 2019. Continual lifelong learning with neural networks: a review. Neural Networks. Peng X., Huang Z., Sun X., Saenko K., 2019. Domain agnostic learning with disen- tangled representations. In: Proceedings of the International Conference on Machine Learning (ICML), PMLR, pp. 5102–5112.\n--- Страница 388 ---\nЛитературные источники  387 Pizzati F., Charette R. D., Zaccaria M., Cerri P., 2020. Domain bridge for unpaired image-to-image translation and unsupervised domain adaptation. In: Proceed- ings of the Winter Conference on Applications of Computer Vision (WACV), pp. 2990–2998. Qin C., Wang L., Zhang Y., Fu Y., 2019. Generatively inferential co-training for unsupervised domain adaptation. In: Proceedings of the International Confe- rence on Computer VisionWorkshops (ICCVW), pp. 1055–1064. Rebuffi S. A., Kolesnikov A., Sperl G., Lampert C. H., 2017. Icarl: incremental clas- sifier and representation learning. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2001–2010. Saito K., Kim D., Sclaroff S., Saenko K., 2020. Universal domain adaptation through self-supervision. In: Neural Information Processing Systems (NeurIPS). Saito K., Ushiku Y., Harada T., Saenko K., 2018a. Adversarial dropout regulariza- tion. In: International Conference on Learning Representations (ICLR). Saito K., Watanabe K., Ushiku Y., Harada T., 2018b. Maximum classifier discrep- ancy for unsupervised domain adaptation. In: Proceedings of the IEEE Confer - ence on Computer Vision and Pattern Recognition (CVPR), pp. 3723–3732. Sankaranarayanan S., Balaji Y., Jain A., Nam Lim S., Chellappa R., 2018. Learning from synthetic data: addressing domain shift for semantic segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recogni- tion (CVPR), pp. 3752–3761. Shin H., Lee J. K., Kim J., Kim J., 2017. Continual learning with deep generative replay. In: Neural Information Processing Systems (NeurIPS), pp. 2990–2999. Shmelkov K., Schmid C., Alahari K., 2017. Incremental learning of object detectors without catastrophic forgetting. In: Proceedings of the International Confer - ence on Computer Vision (ICCV), pp. 3400–3409. Spadotto T., Toldo M., Michieli U., Zanuttigh P., 2020. Unsupervised domain adaptation with multiple domain discriminators and adaptive self-training. In: Proceedings of the IEEE International Conference on Pattern Recognition (ICPR). Tasar O., Tarabalka Y., Alliez P., 2019. Incremental learning for semantic segmen- tation of large-scale remote sensing data. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 12, 3524–3537. Thrun S., Pratt L., 2012. Learning to Learn. Springer Science & Business Media. Toldo M., Michieli U., Agresti G., Zanuttigh P., 2020. Unsupervised domain adapta- tion for mobile semantic segmentation based on cycle consistency and feature alignment. Image and Vision Computing. Toldo M., Michieli U., Zanuttigh P., 2021. Unsupervised domain adaptation in se- mantic segmentation via orthogonal and clustered embeddings. In: Proceed- ings of the Winter Conference on Applications of Computer Vision (WACV). Tsai Y. H., Hung W. C., Schulter S., Sohn K., Yang M. H., Chandraker M., 2018. Learning to adapt structured output space for semantic segmentation. In: Pro- ceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 7472–7481. Tsai Y. H., Sohn K., Schulter S., Chandraker M., 2019. Domain adaptation for struc - tured output via discriminative patch representations. In: Proceedings of the International Conference on Computer Vision (ICCV), pp. 1456–1465.\n--- Страница 389 ---\n388  Адаптация домена и непрерывное обучение семантической сегментации Tung F., Mori G., 2019. Similarity-preserving knowledge distillation. In: Procee- dings of the International Conference on Computer Vision (ICCV), pp. 1365– 1374. Vu T., Jain H., Bucher M., Cord M., Pérez P., 2019a. DADA: depth-aware domain adaptation in semantic segmentation. In: Proceedings of the International Conference on Computer Vision (ICCV), pp. 7363–7372. Vu T. H., Jain H., Bucher M., Cord M., Pérez P., 2019b. Advent: adversarial entropy minimization for domain adaptation in semantic segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2517–2526. Wang M., Deng W., 2018. Deep visual domain adaptation: a survey. Neurocomput - ing 312, 135–153. Watanabe K., Saito K., Ushiku Y., Harada T., 2018. Multichannel semantic segmen- tationwith unsupervised domain adaptation. In: Proceedings of the European Conference on Computer Vision (ECCV). Wu Y., Chen Y., Wang L., Ye Y., Liu Z., Guo Y., Zhang Z., Fu Y., 2018. Incremen- tal classifier learning with generative adversarial networks. arXiv preprint. arXiv:1802.00853. Wu Z., Wang X., Gonzalez J., Goldstein T., Davis L., 2019. ACE: adapting to changing environments for semantic segmentation. In: Proceedings of the International Conference on Computer Vision (ICCV), pp. 2121–2130. Xian Y., Akata Z., Sharma G., Nguyen Q., Hein M., Schiele B., 2016. Latent embed- dings for zero-shot classification. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 69–77. Yang J., An W., Wang S., Zhu X., Yan C., Huang J. , 2020a. Label-driven recon- struction for domain adaptation in semantic segmentation. arXiv preprint. arXiv:2003.04614. Yang Y., Lao D., Sundaramoorthi G., Soatto S., 2020b. Phase consistent ecological domain adaptation. arXiv preprint. arXiv:2004.04923. Yang Y., Soatto S., 2020. FDA: Fourier domain adaptation for semantic segmenta- tion. arXiv preprint. arXiv:2004. 05498. Zhang Y., Qiu Z., Yao T., Liu D., Mei T., 2018. Fully convolutional adaptation net - works for semantic segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 6810–6818. Zhou P., Mai L., Zhang J., Xu N., Wu Z., Davis L. S., 2019. M2kd: multi-model and multi-level knowledge distillation for incremental learning. arXiv preprint. arXiv:1904.01769. Zhou Q., Feng Z., Cheng G., Tan X., Shi J., Ma L., 2020. Uncertainty-aware consis- tency regularization for crossdomain semantic segmentation. arXiv preprint. arXiv:2004.08878. Zhu J., Park T., Isola P., Efros A. A., 2017. Unpaired image-to-image translation us- ing cycle-consistent adversarial networks. In: Proceedings of the International Conference on Computer Vision (ICCV). Zhu X., Zhou H., Yang C., Shi J., Lin D., 2018. Penalizing top performers: conserva- tive loss for semantic segmentation adaptation. In: Proceedings of the Euro- pean Conference on Computer Vision (ECCV), pp. 568–583.\n--- Страница 390 ---\nОб авторах главы  389 Zhuo J., Wang S., Cui S., Huang Q., 2019. Unsupervised open domain recognition by semantic discrepancy minimization. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 750–759. Zou Y., Yu Z., Liu X., Kumar B. V., Wang J., 2019. Confidence regularized self- training. In: Proceedings of the International Conference on Computer Vision (ICCV), pp. 5982–5991. Zou Y., Yu Z., Vijaya Kumar B., Wang J., 2018. Unsupervised domain adaptation for semantic segmentation via class-balanced self-training. In: Proceedings of the European Conference on Computer Vision (ECCV), pp. 289–305. об аВтора Х гЛаВы Умберто Микьели получил степень магистра в области телекоммуникаций в Университете Падуи в 2018 г. На момент написания данной работы он был студентом выпускного курса того же университета. В 2018 г. провел 6 меся- цев в качестве приглашенного исследователя в Техническом университете Дрездена. В 2020 г. он в течение 8 месяцев проходил стажировку в качестве инженера-исследователя в Samsung Research UK. Его исследования сосре- доточены на методах переноса обуче ния для семантической сегментации, в частности на адаптации домена и непрерывном обучении. Марко Тольдо получил степень магистра в области информационно-ком- муникационных технологий для интернета и мультимедиа в 2019 г. в Уни- верситете Падуи. В настоящее время работает над докторской диссертацией на кафедре информационной инженерии того же университета. В 2021 г. в течение 7 месяцев проходил стажировку в качестве инженера-исследо- вателя в Samsung Research UK. Его исследовательские интересы включают адаптацию домена и непрерывное обуче ние применительно к компьютер- ному зрению. Пьетро Зануттиг получил степень магистра в области вычислительной тех - ники и докторскую степень в Университете Падуи в 2003 и 2007 гг. соответ - ственно. В настоящее время является доцентом кафедры информационных технологий того же университета. Его исследовательские интересы включают семантическое понимание изображений и 3D-данных, адаптацию домена и инкрементное обуче ние для обработки визуальных данных, обработку 3D-данных с особым акцентом на датчики ToF, слияние данных с нескольких датчиков и распознавание жестов рук.",
      "debug": {
        "start_page": 354,
        "end_page": 390
      }
    },
    {
      "name": "Глава 9. Визуальное отслеживание движущихся объектов 390",
      "content": "--- Страница 391 --- (продолжение)\nГлава 9 Визуальное отслеживание движущихся объектов Автор главы: Майкл Фелсберг, Лаборатория компьютерного зрения, факультет электроники, Линчепингский университет, Линчепинг, Швеция; Инженерная школа, Университет Квазулу-Наталь, Дурбан, Южная Африка Краткое содержание главы: визуальное отслеживание объектов; дискриминативные подходы к отслеживанию; корреляционные фильтры; глубокие признаки; глубокое обуче ние в отслеживании; сегментация видеообъектов; дискриминативная сегментация. 9.1. В Ведение Отслеживание (tracking) – очень неоднозначный термин, и даже для визу - ального отслеживания существует множество различных интерпретаций и предположений по умолчанию. Эта глава начинается с тщательного и точ- ного определения рассматриваемой задачи отслеживания, чтобы избежать недопонимания и сделать все предположения явными. 9.1.1. Определение задачи отслеживания В этой главе мы рассмотрим задачу общего визуального отслеживания в том смысле, как это определено в формулировке визуального отслеживания объ- ектов (visual object tracking, VOT) 2013–2020 гг. (Kristan et al., 2013, 2015a,b, 2016, 2017, 2019,b, 2020), что также совпадает с определением бенчмарка по- следовательного отслеживания (online tracking benchmark, OTB) (Wu et al., 2013). Отслеживание выполняется в домене изображения, и никакие пред-\nГлава 9 Визуальное отслеживание движущихся объектов Автор главы: Майкл Фелсберг, Лаборатория компьютерного зрения, факультет электроники, Линчепингский университет, Линчепинг, Швеция; Инженерная школа, Университет Квазулу-Наталь, Дурбан, Южная Африка Краткое содержание главы: визуальное отслеживание объектов; дискриминативные подходы к отслеживанию; корреляционные фильтры; глубокие признаки; глубокое обуче ние в отслеживании; сегментация видеообъектов; дискриминативная сегментация. 9.1. В Ведение Отслеживание (tracking) – очень неоднозначный термин, и даже для визу - ального отслеживания существует множество различных интерпретаций и предположений по умолчанию. Эта глава начинается с тщательного и точ- ного определения рассматриваемой задачи отслеживания, чтобы избежать недопонимания и сделать все предположения явными. 9.1.1. Определение задачи отслеживания В этой главе мы рассмотрим задачу общего визуального отслеживания в том смысле, как это определено в формулировке визуального отслеживания объ- ектов (visual object tracking, VOT) 2013–2020 гг. (Kristan et al., 2013, 2015a,b, 2016, 2017, 2019,b, 2020), что также совпадает с определением бенчмарка по- следовательного отслеживания (online tracking benchmark, OTB) (Wu et al., 2013). Отслеживание выполняется в домене изображения, и никакие пред-\n--- Страница 392 ---\nВведение  391 варительные знания о классах объектов недоступны; «общий» означает не- зависимый от класса. Задача формулируется в плоскости 2D-изображения, в отличие от подходов с 3D-трекингом (Garon, Lalonde, 2017). Кроме того, рассматривается только один объект (цель), в отличие от случая отслеживания нескольких объектов (Dendorfer et al., 2020), который требует связывания целей через последова- тельность изображений. Однако отслеживание одного объекта не означает, что в последовательностях кадров нет других движущихся объектов, так на- зываемых дистракторов (distractor). Задача слежения требует, чтобы цель не смешивалась ни с одним из дистракторов, даже если они частично пере- крывают цель. Предполагается, что цель хотя бы частично видна на протяже- нии всей последовательности, так что повторное обнаружение не требуется. Последовательность может исходить от движущейся камеры, что исключает простое моделирование фона для обнаружения цели (Stauffer, Grimson, 2000). Цель отслеживания определяется одиночной аннотацией в первом кад- ре последовательности изображений в виде ограничивающей рамки (или маски сегментации, раздел 9.5). Задача состоит в том, чтобы предсказать ограничивающую рамку (или маску сегментации), содержащую один и тот же объект во всех последующих кадрах. Ограничивающие рамки могут быть определены в различных системах координат; конкретный формат не имеет значения, если он не меняется в процессе отслеживания. В стандартной за- даче визуального отслеживания объекта (visual object tracking, VOT) исполь- зуются левый верхний угол изображения (x , y), ширина w и высота h (начало координат в левом верхнем углу). Таким образом, мы получаем следующее формальное определение задачи: ввод: видеопоток (последовательность изображений) и одна анноти- рованная ограничивающая рамка (x 0, y0, w0, h0) для начального кадра последовательности; вывод: предсказание ограничивающих рамок (x k, yk, wk, hk) для всех кадров k > 0; условие: предсказание ограничивающей рамки для кадра K может ис - пользовать только данные из кадров k £ K. Это определение задачи отслеживания фактически сводится к задаче одно- кратного обуче ния (one-shot learning), поскольку для данной входной после- довательности предоставляется единственная аннотированная обучающая выборка. Целью этой задачи является обуче ние детектора, который предска- зывает наилучшую ограничивающую рамку в последующем кадре, что также называется отслеживанием через обнаружение (tracking by detection). Как пра- вило, наиболее подходящая ограничивающая рамка классифицируется как цель, а все остальные – как фон. Однако также можно использовать методы регрессии для определения (уточнения) параметров ограничивающей рамки. 9.1.2. Затруднения при отслеживании Основная трудность в отслеживании через обнаружение заключается в том, что внешний вид отслеживаемого объекта может измениться на протяжении последовательности. В частности, объект может:\n--- Страница 393 ---\n392  Визуальное отслеживание движущихся объектов вращаться в плоскости изображения; изменить масштаб, смещаясь по глубине; изменить соотношение сторон путем поворота вне плоскости / изме- нения точки обзора; изменить форму; страдать от размытия движения; претерпевать изменения освещения; быть частично закрытым. Эти изменения могут привести к сбою детектора и потере цели, особенно при наличии засоренного фона и отвлекающих факторов. Поэтому современ - ные методы отслеживания обычно адаптируют модель детектора, используя ее собственные прогнозы из предыдущих кадров (рис. 9.1). Начальное обучение Кадр #0 Кадр #t Аннотация #0 Оптимизация моделиОптимизация моделиРазвертывание обучения Модель # t – 1 Модель # t Модель #0Прогноз #t Рис. 9.1  Блок-схема адаптивной отслеживающей модели. После начального обуче ния (слева) модель адаптируется, используя собственные прогнозы в ка- честве обучающих выборок (справа) Этот адаптивный процесс определяет процедуру развертывания модели (model bootstrapping), то есть рекурсивное самосовершенствование, которое происходит без внешнего ввода, кроме единственной начальной аннотации. Одна из ключевых проблем этого процесса состоит в том, чтобы найти ба- ланс между сохранением предыдущей модели и ее обновлением (гибкость модели). Если модель слишком жесткая, она потеряет цель при изменении внешнего вида, если модель слишком гибкая, она будет дрейфовать от цели (Matthews et al., 2004; Wang et al., 2016). 9.1.3. Обоснование методики Проблема дрейфа модели в значительной степени уменьшается, если из- вестен класс интересующего объекта. Однако, как указано в разделе 9.1.1, мы стремимся к универсальным, т. е. не зависящим от класса, моделям. Ос - новным обоснованием для этого выбора является допущение об открытом мире, согласно которому мы не делаем вывод о неверности утверждения исходя из его отсутствия (Reiter, 1978), в отличие от допущения о закрытом мире. Применительно к обнаружению объектов открытый мир означает, что\n--- Страница 394 ---\nВведение  393 мы не отрицаем существование объекта при отсутствии соответствующего отклика детектора. В контексте визуальных детекторов допущение о закрытом мире сталки- вается с двумя проблемами: внешний вид объектов характеризуется высокой внутриклассовой из- менчивостью, например автомобили и велосипеды в сценариях до- рожного движения; набор объектов постоянно растет, например в сценариях дорожного движения появляются электровелосипеды и ховерборды. Если объект не обнаружен по первой причине, это означает, что детектор не смог смоделировать разнообразие внешнего вида объекта. Это может быть вызвано ограничениями обучающей выборки или бесконечными ва- риациями внешнего вида объекта. Если объект не обнаружен по второй при- чине, это означает, что класс объектов вообще не представлен в обучающей выборке. Однако тот факт, что набор данных не охватывает определенный класс, не озна чает, что этот класс не имеет отношения к детектору. Разра- ботка системы, основанной на предпосылке, что классы, отсутствующие во время обуче ния, следует игнорировать, этически проблематична, например в приложениях для безопасности дорожного движения. Системы безопасности дорожного движения часто основаны не на ком- пьютерном зрении, а на сенсорах иного типа: лидары, радары, ультразвуко- вые эхолокаторы и т. д. Однако визуальные системы всегда будут представ- лять наибольший интерес, поскольку они наиболее близки к механизмам человеческого восприятия. Системы должны адаптироваться к среде, соз- данной для людей, и поскольку зрение является доминирующим чувством человека, обеспечивающим примерно 80 % нашего восприятия, обуче ния, познания и деятельности (Ripley, Politzer, 2010), таким системам необходимы визуальные сенсоры. В повседневной жизни мы постоянно руководствуемся визуальными средами. Например, правила дорожного движения определя- ют множество знаков и символов, которые визуально направляют действия водителя. Кроме того, системы, которые делят свое рабочее пространство с людьми для взаимодействия и совместной работы, много выиграют от воз- можности визуального восприятия. Внешний вид человека может отчетливо сигнализировать о его поведении и намерениях, и люди активно используют это, общаясь, например, с по мощью жестов. Наконец, чтобы иметь возмож - ность предсказывать действия человека, необходимо также научиться пред- сказывать его восприятие, которое в основном основано на зрении. 9.1.4. Историческая справка Многие из прежних подходов к визуальному отслеживанию восходят к проб - лемам дополненной реальности, где визуализация и восприятие объединя- ются в одной системе координат для создания среды смешанной реальности. Отслеживание важно здесь по двум причинам: относительное положение головы в сцене (Neumann et al., 1999) и положение движущихся объектов (Neumann, Park, 1998).\n--- Страница 395 ---\n394  Визуальное отслеживание движущихся объектов Далее мы кратко перечислим некоторые важные этапы в истории визуаль- ного отслеживания, а также ключевые работы и их авторов: 1981: алгоритм Лукаса–Канаде (Lucas, Kanade, 1981); 1984: чисто фазовый согласованный фильтр (Horner, Gianino, 1984); 1994: «Отслеживание – решаемая проблема» (из презентации Shi, Tomasi 1994); 1998: фильтры и эквивариантности, согласованные только по фазе (Fels- berg, 1998); 2004: «Лукас-Канаде 20 лет спустя: объединяющая структура» (Baker, Mat - thews, 2004); 2007: проект MATRIS: L1-трекер и ковариация (Skoglund and Felsberg, 2007); 2013: новые задачи отслеживания OTB (Wu et al., 2013), VOT (Kristan et al., 2013) и генеративный комплексный трекер (Felsberg, 2013); 2014: победитель конкурса VOT2014 в области дискриминативного тре- кинга (DSST) (Danelljan et al., 2014; Kristan et al., 2015); 2018: дискриминативные холистические трекеры победили в VOT2018 с точностью 75 % (Kristan et al., 2019); 2020: сиамские трекеры и методы сегментации приобретают все большее значение (Kristan et al., 2020). В последующих разделах мы подробно рассмотрим несколько основных событий, произошедших за этот 40-летний период, с особым акцентом на дискриминативные и основанные на обучении методы. 9.2. методы на осно Ве шаб Лоно В Прежде чем углубиться в методы, основанные на обучении, мы кратко об- судим другие методы, которые полностью основаны на исходной аннотиро- ванной ограничивающей рамке, часто называемой шаблоном. 9.2.1. Основы В целом мы можем разделить методы на основе шаблонов на генеративные и дискриминативные. Эти методы концептуально показаны на блок-схемах на рис. 9.2. Генеративный подход является наиболее часто используемым подходом на основе шаблонов. Здесь модель в основном представляет собой характерный патч (небольшой участок) изображения и обычно сама служит шаблоном. Локализация объекта в последующих кадрах достигается путем сопостав- ления модели с позициями-кандидатами в кадрах. Для сопоставления тре- буется мера расстояния между участками изображения, например L2-норма (метод наименьших квадратов) или L 1-норма разности пикселей. Поиск может быть выполнен путем полного перебора с применением вы- сокоэффективных L1-методов (Skoglund, Felsberg, 2006), с использованием\n--- Страница 396 ---\nМетоды на основе шаблонов  395 эвристики для уменьшения окна поиска (например, динамические модели) или с по мощью итерационных методов. Наиболее распространенный подход в первые годы был основан на L2-норме и итерациях, так называемом методе Лукаса–Канаде (Lucas, Kanade, 1981). Методы, основанные на этом подходе, подробно описаны в обзорной статье Бейкера и Мэтьюза (Baker, Matthews, 2004), поэтому мы ограничимся лишь обсуждением базового случая в конце раздела 9.9. Генеративная модель Кадр #t Шаблон # t – 1 Шаблон # t Карта оценок Максимум Максимум Лучший кандидатКарта оценокСкалярные произведения Целевая карта оценокИнкремен- тирование моделиРасстояние/ сходствоШаблон # t – 1 Шаблон # t Кадр #tКандидаты / скользящее окноКандидаты / скользящее окноДискриминативная модель Рис. 9.2  Методы на основе шаблонов: генеративный (слева, раздел 9.2.3) и дискриминативный (справа, разделы 9.2.4 и 9.3.1) Вместо этого мы сфокусируемся на дискриминативном подходе, когда модель двойственна по отношению к исходному шаблону. В самом простом случае двойственность (duality) понимается в терминах скалярного произве- дения в векторном пространстве. Предположим, что d векторов vk порождают d-мерное векторное пространство. Мы не предполагаем, что эти векторы нормализованы или ортогональны. Двойственный базис распространен на d векторов v ˜k, таких что (9.1) где ⟨|⟩ обозначает скалярное произведение. Заметим, что в случае ортонор- мированного базиса { ek}k=1…d базисные векторы двойственны сами себе: e˜k = ek. Если мы теперь перепишем вектор vk = åd l=1aklel с коэффициентами akl, то сразу увидим, что матрица A размера d×d с коэффициентами akl имеет ранг d и для нее существует обратная матрица. Без потери обобщения мы можем предположить, что {e k}k=1…d является каноническим базисом ℝd, и, таким образом, vk, k = 1, …, d, являются строками A. Если мы теперь применим цик - лический сдвиг к строкам A и умножим на A–1, то получим уже не матрицу тождественности, а циклический сдвиг этой матрицы – мы успешно «отсле- дили» наш базисный вектор v k. Эту концепцию можно применить к любому векторному пространству, включая пространство функций или сигналов. Идея чисто фазового согласо-\n--- Страница 397 ---\n396  Визуальное отслеживание движущихся объектов ванного фильтра (phase-only matched filter) (Horner, Gianino, 1984) заключа- ется в использовании двойственности шаблона для определения оценки обо- собленности (distinctive score). Этот показатель достигает своего максимума, если ограничивающая рамка расположена на шаблоне, и будет близок к нулю, если рамка снаружи. 9.2.2. Показатели качества модели В процессе отслеживания мы находим ограничивающую рамку на основе некоторой оценочной функции; мы вернемся к маскам сегментации ниже в этом разделе. Чтобы количественно оценить, насколько успешно определе- но положение объекта, предсказанную ограничивающую рамку необходимо сравнить с истинной. Как в задаче VOT (Kristan et al., 2013), так и в OTB (Wu et al., 2013) в качестве критерия было выбрано пересечение-пересоединение (Everingham et al., 2010), или, исторически бо лее правильно, индекс Жаккара 𝒥 (Jaccard, 1912): (9.2) где RG – это эталонная область, RP – предсказанная область, а |R | – площадь области R. Если две области не перекрываются, мы получаем ℐ = 0, а если две области полностью совпадают, мы получаем ℐ = 1. Если половина пред- сказанной области перекрывается с половиной эталонной области (типичная точность многих трекеров), мы получаем Заметим, что индекс Жакка- ра является смещенной мерой, которая склонна систематически завышать оценку размера ограничивающей рамки (Häger et al., 2018). Индекс Жаккара измеряет точность отслеживания на кадр, и эти измере- ния можно накапливать несколькими способами. OTB предлагает рассчи- тать две кривые – кривую точности и кривую успеха (рис. 9.3). Обе рассчи- тываются аналогично ROC-кривой путем установки пороговых значений и вычисления соотношения кадров, которые проходят этот порог. Кривая точности получается путем установки порогового значения расстояния до центра рамки в диапазоне от 0 до максимального расстояния, а кривая успеха получается путем установки порогового значения индекса Жаккара в диа- пазоне от 0 до 1. Тогда интеграл под кривой является интегральной мерой точности. В качестве альтернативы можно использовать определенные по- роговые значения, например расстояние 20 пикселей или перекрытие 50 % (Everingham et al., 2010). В любом случае срыв отслеживания приводит лишь к снижению показате- ля точности, и это событие нельзя отличить от систематически низкой точ- ности: при таких показателях точность и надежность сильно коррелируют (Kristan et al., 2016). Поэтому в задаче VOT стремятся разорвать корреляцию, используя две меры: точности и надежности. Первая измеряет средний ин- декс Жаккара в случае успешного отслеживания, а вторая измеряет частоту\n--- Страница 398 ---\nМетоды на основе шаблонов  397 неудачных попыток отслеживания (Kristan et al., 2013). Этот подход требует перезапуска отслеживания либо путем обнаружения сбоев и перезапуска отслеживания с использованием эталона, либо путем запуска нескольких попыток отслеживания из нескольких опорных точек в последовательности примерно в каждом 50-м кадре (Kristan et al., 2020). Точность накапливается по длине последовательности, а затем усредняется, при этом она взвешива- ется по соответствующей длине последовательности. Точность Доля успеха Порог ошибки локализации Порог перекрытия Рис. 9.3  Оценка отслеживания в OTB. Кривая точности (слева) и кривая успеха (справа). Ранжирование может быть выполнено по точности при пороге ошибки определения местоположения 20, степени успеха при пороге перекры- тия 0,5 или по площади под кривой успеха (AUC) При раздельном рассмотрении точности и надежности их обычно поме- щают на двухмерный график с надежностью по горизонтальной оси и точ- ностью по вертикальной. В зависимости от назначения отслеживания разра- ботчики могут отдать приоритет надежности или точности. Однако средние оценки не раскрывают полную картину и не говорят о том, имеет ли метод указанную среднюю точность на протяжении всего трека или изначально высокую точность, которая быстро снижается. Для многих приложений было бы интересно узнать, какую точность можно ожидать после определенной длины последовательности. Это достигается с по мощью кривой ожидаемого среднего перекрытия, измеряющей среднее перекрытие как функцию длины последовательности. Окончательная оценка задачи VOT получается путем интегрирования этой кривой в диапазоне типичных длин последователь- ностей (Kristan et al., 2016). В своей последней редакции (Kristan et al., 2020) задача VOT также пред- лагает вычислять показатели точности для масок сегментации вместо огра- ничивающих рамок. Такая необходимость возникла, поскольку методы от - слеживания масочных сегментов достигли точности, аналогичной уровню точности аннотаций ограничивающей рамки. В отличие от индекса Жаккара для ограничивающих рамок, который можно вычислить как функцию па- раметров ограничивающей рамки, индекс Жаккара для масок сегментации требует подсчета пикселей в масках и на их пересечении.\n--- Страница 399 ---\n398  Визуальное отслеживание движущихся объектов 9.2.3. Нормализованная кросс-корреляция Один из старейших методов прогнозирования положения ограничительной рамки – сопоставление с шаблоном. Сопоставление выполняется с по мощью генеративной модели m, которая получается из патча внутри ограничиваю- щей рамки в исходном кадре. Во время сопоставления модель m сравнива- ется с патчами-кандидатами p в каждом последующем кадре. Соответствен- но, наиболее похожий патч определяет положение ограничивающей рамки в этом кадре (рис. 9.2 слева). Моделью может служить фрагмент необработанного изображения в на- чальной ограничивающей рамке, но чаще предполагается, что модель m имеет нулевую DC-компоненту, т. е. вычитается среднее значение шаблона. Абсолютная интенсивность изображения часто зависит не от объекта, а от других факторов, т. е. освещения, теней, времени экспозиции и т. д., а уда- ление DC-компоненты повышает надежность согласования при изменении этих факторов. Однако в фотометрических применениях, например в по- следовательностях тепловых инфракрасных снимков, модель m может со - держать DC-компоненту. Для дальнейшего повышения надежности динамика интенсивности также обычно нормализуется с по мощью дисперсий в шаблоне m и патче-канди- дате p : (9.3) (9.4) где |R | – площадь области патча. Патчи-кандидаты обычно выбираются скользящим окном по следующему кадру f или его части px,y(r, s) = f(x + r, y + s). Оценка совпадения вычисляется как скалярное произведение между шаблоном и патчем. Эта комбинация скользящего окна и скалярного произведения дает нам корреляцию m и f: (9.5) (9.6) Обратите внимание, что p не требует какой-либо DC-компенсации, потому что m не содержит DC, и, следовательно, скалярное произведение не содер- жит никакого вклада от среднего значения p . Последующее деление на произведение стандартных отклонений дает нормализованную кросс-корреляцию (normalized cross correlation, NCC): cn(x, y) = σm–1σ–1 px,yc(x, y), (9.7)\n--- Страница 400 ---\nМетоды на основе шаблонов  399 где σpx,y по-прежнему вычисляется в скользящем окне, что делает его функ - цией от (x , y). Корреляция c(x, y) как таковая, т. е. без нормализации с по мощью σpx,y, может быть эффективно вычислена в пространстве Фурье (Bracewell, 1995) C(u, v) µ F(u, v) ∘ M—(u, v), (9.8) где заглавные буквы – это преобразования Фурье соответствующих сигна- лов, обозначенных строчными символами, и M— комплексно сопряжена с M. Частотные координаты обозначаются через (u , v), а оператор ∘ является то- чечным произведением. Положение (x ˜, y˜) вместе с максимальной нормализо- ванной кросс-корреляцией (9.7) затем используется в качестве предсказания положения ограничивающей рамки. Нормализованная кросс-корреляция используется не только с фиксиро- ванным, но и с адаптивным шаблоном. Единственное изменение в приве- денной выше процедуре заключается в том, что шаблон из первого кадра используется только для инициализации модели m. После первого кадра ло- кализованная ограничивающая рамка используется для обновления модели с по мощью патча в этой ограничивающей рамке: m ← (1 – λ )m + λpx˜,y˜, (9.9) где λ Î (0, 1) обозначает коэффициент обновления. Если этот коэффициент выбран слишком большим, модель будет страдать от дрейфа (Matthews et al., 2004; Wang et al., 2016), а если слишком маленьким, то модель не сможет в достаточной мере адаптироваться к изменениям внешнего вида. Заметим, что как в статическом, так и в адаптивном случае решение (9.7) идентично задаче наименьших квадратов для нормализованных патчей: (9.10) Если задача наименьших квадратов решается итеративно методом гради- ентного спуска, мы получаем метод Лукаса–Канаде KLT (Lucas, Kanade, 1981). Этот метод является полностью локальным, т. е. он начинается с предыду - щего местоположения (или местоположения, предсказанного какой-либо динамической моделью) и находит ближайшие локальные минимумы. На- против, нормализованная кросс-корреляция определяет местонахождение глобального максимума во всем кадре f . 9.2.4. Чисто фазовый согласованный фильтр Если мы присмотримся к вычислениям в пространстве Фурье (9.8), то может возникнуть идея выбрать M как (9.11)\n--- Страница 401 ---\n400  Визуальное отслеживание движущихся объектов так, что и c(x, y) = δ(x, y). (9.12) Сдвиг f на (x 0, y0) приводит к модуляции в пространстве Фурье (теорема о сдвиге) и, следовательно, к смещению Дирака в пространстве изображения. Таким образом, мы перешли к дискриминативной модели, так как фильтр не отображает внешний вид шаблона, а оценка выхода должна быть равна 1 для правильного перемещения и 0 для неправильного. Для получения идеальной оценки требуется, чтобы все изображение было свободным от шума и смещалось вместе с патчем, содержащим цель. На прак - тике это вряд ли возможно, и вычисленная оценка заменяется целевым по- казателем, соответствующим расположению с максимальным количеством баллов, для расчета новой модели (рис. 9.2 справа). Целевой показатель боль- ше не является дираковским, поскольку спектр мощности |F |2(u, v) меняется между начальным кадром и последующими. По соображениям симметрии знаменатель в (9.11) необходимо изменить на |F ||F¢|, где F¢ – преобразование Фурье текущего кадра. Результирующий фильтр m является, строго говоря, нелинейным и также известен как симметричный чисто фазовый согласован- ный фильтр (symmetric phase-only matched filter, SPOMF) (Chen et al., 1994). Название чисто фазового согласованного фильтра (phase-only matched fil- ter, POMF) впервые предложено в работе (Horner, Gianino, 1984), где нели- нейность устраняется за счет исключения |F ¢| в знаменателе. Таким образом, эффективное согласование представляет собой корреляцию нового кадра с моделью m , имеющей постоянный амплитудный спектр (9.13) Этот фильтр больше не будет приводить к отклику Дирака (если только кадр не имеет спектра постоянной амплитуды). POMF, регуляризованный по амплитудному спектру текущего кадра, можно рассматривать в качестве дискриминаторного фильтра. Каждый коэффициент Фурье C(u, v) умножа- ется на соответствующий коэффициент спектра величин |F |(u, v). На выхо- де получается не дираковская, а гладкая характеристика, форма которой получается из обратного преобразования Фурье амплитудного спектра f¢. Эта регуляризация явно выражена в фильтре MOSSE, о котором говорится в разделе 9.3.1. 9.3. методы пос Ледо ВатеЛьного обу Чения В этом разделе мы используем некоторые идеи из предыдущего раздела, регуляризацию отклика и инкрементное обновление модели, чтобы опреде- лить концепции дискриминативных корреляционных фильтров.\n--- Страница 402 ---\nМетоды последовательного обучения  401 9.3.1. Фильтр MOSSE Обсуждая POMF, мы отметили, что он имеет неявную регуляризацию откли- ка. Если эту регуляризацию сделать явной в виде целевой функции отклика c, мы придем к концепции фильтра минимальной выходной суммы квадратов ошибок (minimum output sum of squared error, MOSSE) (Bolme et al., 2010): (9.14) Обратите внимание, что хотя мы используем то же обозначение f, как и для всего кадра, мы будем подразумевать только локальное окно поиска (search window). Таким образом, мы получаем подход, который не является ни чис - то локальным, как KLT, ни полностью глобальным, как NCC. Обычно окно поиска в два-три раза превышает размер ограничивающей рамки в обоих измерениях. Фильтр MOSSE вычисляется в замкнутой форме с использованием экви- валентной формулы в пространстве Фурье: (9.15) (9.16) (9.17) Это окончательное уравнение имеет решение (вывод см. в приложении к Bolme et al. (2010)) (9.18) Заметим, что эквивалентность достигается только для бесконечных об - ластей. На практике извлеченный патч имеет конечный размер, и преоб- разование Фурье приводит к неявному периодическому повторению. Чтобы уменьшить влияние разрывов на границе патча, к нему применяется окно Ханна (косинусное окно у Bolme et al. (2010)). Далее обратите внимание на сходство с (9.11), за исключением C. Как уже говорилось про POMF, мы эффективно применяем точечную регуляризую- щую функцию C(u, v), и если мы выбираем С = |F¢|, то получаем POMF. Однако для фильтра MOSSE наиболее распространенным вариантом оценки mAP c является функция Гаусса (не нормализованная) в точке (x 0, y0) с фиксирован- ной шириной (9.19)\n--- Страница 403 ---\n402  Визуальное отслеживание движущихся объектов Этот регуляризованный согласованный фильтр обычно обновляется в те- чение последовательности кадров, подобно обновлению NCC (9.9), см. также рис. 9.1. На каждом шаге целевая mAP-оценка c(x, y) располагается на пози- ции максимальной оценки из предыдущей модели (рис. 9.2 справа). Уравнение обновления MOSSE получается, если сначала рассмотреть за- дачу минимизации для нескольких аннотированных кадров (f t, ct): (9.20) В области Фурье это дает в силу линейности (9.21) (9.22) с решением (9.23) Если мы теперь предположим, что пары (f t, ct) поступают постепенно, нам нужно только разделить числитель и знаменатель, чтобы упорядочить об- новление: (9.24) и , (9.25) такой, что фильтр после временного шага t выглядит как (9.26) Однако при увеличении количества кадров выражения для At и Bt подвер- жены неограниченному росту, чего мы хотим избежать по вычислительным соображениям. Кроме того, мы бы предпочли, чтобы модель последователь- но уменьшала влияние очень старых образцов. Оба эффекта достигаются введением коэффициента забывания 1 – η, где 0 < η < 1, в уравнения обнов- ления: (9.27) (9.28)\n--- Страница 404 ---\nМетоды последовательного обучения  403 Обратите внимание, что, как и в обновленном NCC, фильтр с временным индексом t применяется к кадру t + 1. В дополнение к неограниченному росту выражений знаменатель, близкий к нулю, тоже может вызвать вычислительные проблемы. Эта проблема была решена путем регуляризации коэффициентов фильтра со штрафом за их L2-норму (Henriques et al., 2012). Отсюда мы приходим к следующей задаче гребневой регрессии: (9.29) Решение представляет собой небольшую модификацию (9.23): (9.30) а для инкрементального случая мы только меняем (9.26) на (9.31) и оставляем (9.27) и (9.28) без изменений. 9.3.2. Дискриминативные корреляционные фильтры Фильтр MOSSE, рассмотренный в предыдущем разделе, действует непосред- ственно на данные, содержащиеся в изображении. Выводы также предпо- лагают, что данные изображения являются скалярными (одноканальными), а обобщение на цветные изображения (многоканальные) нетривиально. Кро- ме того, нам может понадобиться использовать несколько признаков, из - влеченных из изображения, вместо или в дополнение к чистым данным изо- бражения. В этом случае также необходимо обрабатывать многоканальные входные данные, что приводит к обобщению (регуляризованного) фильт ра MOSSE: дискриминативному корреляционному фильтру (discriminative cor - relation filter, DCF). Обратите внимание, что для определения DCF мы меняем обозначения на символы, обычно используемые в машинном обучении. По сравнению с нотацией, основанной на обработке сигналов в фильтре MOSSE, мы приме- няем следующие сопоставления: f ↦ x для входных данных, m ↦ f для фильтра и c ↦ y для заданных выходных данных (Danelljan et al., 2015). Для входных данных с d каналами переформулируем (9.29) как минимизацию цели (9.32)\n--- Страница 405 ---\n404  Визуальное отслеживание движущихся объектов где мы определяем функцию вклада (9.33) как многоканальную корреляцию между входом и фильтрами. Обратите вни- мание, что образцы (x k, yk) взвешиваются по αk ³ 0, что является дальнейшим обобщением по сравнению с введенным ранее коэффициентом забывания (1 – η). Решение задачи минимизации (9.32) получается путем подстановки функ - ции вклада (9.33) и теоремы Парсеваля таким образом, что (9.34) (9.35) для всех n = 1…d. Необходимое условие минимума состоит в том, что частные производные по всем компонентам Fn и для всех n равны нулю: для всех u , v, n; (9.36) 0 = X*diag(α )XF— – X*diag(α )Y + λF—; (9.37) F— = (X*diag(α )X + λI)–1X*diag(α )Y, (9.38) где второе равенство представляет собой матричную запись. Матрица X со- держит коэффициенты Фурье Xl k(u, v), l = 1 … d как векторы-строки, Х* – со - пряженная транспонированная матрица, diag(α ) – диагональная матрица с элементами αk, F— содержит коэффициенты Фурье F—l(u, v), l = 1 … d как век - тор-столбец, а Y – вектор-столбец, содержащий все Yk. Исходные формулы можно найти в работе (Danelljan et al., 2015). Решение (9.38) имеет несколько частных случаев. Регуляризованный фильтр MOSSE с инкрементным обновлением является частным случаем для d = 1 и α k, образующим геометрическую прогрессию η(1 – η)t–k. Другой част - ный случай получается, если мы рассматриваем только один-единственный образец. В этом случае X – вектор-строка, а XX* – скаляр, так что (9.39) и (9.40)\n--- Страница 406 ---\nМетоды последовательного обучения  405 Если мы обратимся к этому решению в случае нескольких образцов, то прием с обращением в (9.39) применим только в том случае, если Х*diag(α ) X имеет единичный ранг. Без этого приема эффективное инкрементное об- новление становится невозможным, поскольку нам пришлось бы инверти- ровать матрицу d×d для каждого коэффициента и каждого кадра. Существует обобщение приема с инверсией, известное как формула Шермана–Моррисо- на–Вудбери, и оно применялось к многоканальным DCF (Lukežic et al., 2018), но эмпирические результаты, похоже, указывают на то, что аппроксимация первого ранга работает достаточно хорошо (Danelljan et al., 2017). В этом приближении мы просто повторно используем модифицированные уравне- ния обновления (9.27) и (9.28): Atn = ηY— t ∘ Xtn + (1 – η )An t–1, A 1n + Y— 1 ∘ X1n, n = 1 … d; (9.41) (9.42) Подобно (9.31), мы вычисляем (векторный) фильтр как (9.43) 9.3.3. Подходящие признаки для DCF С переходом от одноканальных фильтров MOSSE к DCF у нас появляется свобода выбора, какие функции используются для входной карты признаков x. При выборе признаков следует учитывать три основных компромисса: первый касается d, количества каналов в x, второй – пространственного раз- решения или количества коэффициентов Фурье, а третий – размера времен- ного окна в случае, если должны использоваться другие αk, отличные от тех, что взяты из геометрической прогрессии. Количество свободных параметров DCF зависит от размера карты при- знаков, d и пространственного разрешения, как следует из (9.36). Большее количество параметров, как и большее временное окно, внутреннее изме- рение в (9.38), требует больше вычислений. Кроме того, большее количество свободных параметров также требует более строгой регуляризации, посколь- ку количество исходных входных измерений, то есть кадр входного изобра- жения, не зависит от размера карты признаков x . Размер временного окна и пространственное разрешение будут рассмотре- ны в последующих разделах этой главы, а в этом разделе мы сосредоточимся на количестве каналов. Здесь основное внимание уделяется созданным вруч- ную признакам: изученные и глубокие признаки также будут рассмотрены позже. Таким образом, задача, рассматриваемая в этом разделе, заключается в следующем: выбрать как можно меньше созданных вручную плотных при- знаков, чтобы получить высококачественный трекер DCF. Поскольку подход DCF основан на отслеживании путем обнаружения, мы основываем выбор признаков на опыте из публикаций по обнаружению объ-\n--- Страница 407 ---\n406  Визуальное отслеживание движущихся объектов ектов. Если учитывать, что необработанные значения исходного изображения могут быть полезны в особых случаях (например, фотометрические данные, такие как тепловое ИК-излучение), структура и форма изображений, как пра- вило, намного лучше представляются с использованием гистограмм ориенти- рованных градиентов (HOG), предложенных для обнаружения человека (Dalal, Triggs, 2005). Признаки HOG – это особый способ представления данных об ориентации (Felsberg, 2018), как и плотные признаки SIFT (Lowe, 2004). Большинство новейших методов отслеживания с использованием создан- ных вручную признаков основаны на признаках HOG, и нам не встречался ка - кой-либо систематический анализ альтернативных вариантов, например на основе обобщенных формул (Felsberg, 2018). Кроме того, признаки, которые чаще используются для анализа текстуры, такие как бинарные локальные паттерны (Pietikäinen, Zhao, 2015), редко встречаются в методах отслежи - вания, по-видимому, из-за относительно низкой доли текстурированных объектов в наборах эталонных данных. Поэтому мы также предпочитаем ис - пользовать в данной главе признаки HOG, а за подробностями рекомендуем обратиться к первоисточнику (Felsberg, 2018). Все рассмотренные до сих пор признаки игнорируют информацию о цвете в кадрах изображения. Опять же, из публикаций по обнаружению объектов мы узнаем, что было бы очень полезно использовать названия цветов (Khan et al., 2012). Дескриптор названия цвета вычисляется путем обучаемого мяг - кого присвоения из цветового пространства Lab одиннадцати названий цве- тов на английском языке (Van De Weijer et al., 2009). Обуче ние выполняется на слабо размеченных изображениях Google с использованием вероятностного латентно-семантического анализа (pLSA-bg): P(w|d) = P(w|z)P(z|d), (9.44) где d обозначает распределение цвета в пространстве Lab, w – одно из один- надцати названий цветов, а z – скрытая переменная. Названия цветов пред- ставлены 11-мерным вектором мягкого присвоения (soft-assignment vector), т. е. все компоненты находятся в диапазоне от 0 до 1, а вектор нормализован. 9.3.4. Отслеживание в масштабном пространстве Трекеры DCF, представленные выше, по-прежнему страдают одним фунда- ментальным недостатком: если целевой объект перемещается по глубине, например ближе к камере, он меняет свой размер в плоскости изображения. Следовательно, необходимо менять не только положение ограничивающей рамки в текущем кадре, но и ее размер: нужно отслеживать объект, масштаб которого в общем случае постоянно меняется. Очевидно, внешний вид объ- екта также меняется в зависимости от масштаба или глубины, но существует тесная связь между масштабом и внешним видом, что позволяет нам свя- зывать модели внешнего вида через масштаб – для этого введено понятие масштабного пространства (scale space) (Koenderink, 1984). Ключевая идея масштабного пространства состоит в том, чтобы ввести в изображение третью (масштабную) ось, которая отражает степень размы-\n--- Страница 408 ---\nМетоды последовательного обучения  407 тия, например вызванную ограниченной глубиной резкости камеры (Felsberg et al., 2005). Размытие обычно моделируется фильтрацией нижних частот, то есть уменьшением высокочастотных составляющих. В некотором масштабе s0 частоты, превышающие половину частоты Найквиста π/2, ослабляются настолько, чтобы можно было выполнять понижающую дискретизацию с ко- эффициентом 2 без значительного размытия. При масштабе 2s 0 мы можем уменьшить изображение с коэффициентом 4 и т. д., в конечном итоге по- строив пирамиду масштаба (рис. 9.4 слева). МасштабКанал признака Рис. 9.4  Отслеживание в масштабном пространстве. Пирамида масштаба (слева) и отслеживание масштаба (справа). Ось масштаба соответствует про- странственной координате глубины Полезным побочным эффектом этой пирамиды является то, что умень- шенное пространственное разрешение в пирамиде соответствует уменьшен- ному размеру в плоскости изображения из-за увеличения расстояния от объ- екта до камеры. Таким образом, мы можем имитировать эффект увеличения глубины, переходя к более крупным масштабам в пирамиде, что позволяет нам включить оценку масштаба в отслеживание (Danelljan et al., 2017). Для этого процесса у нас есть три варианта: 1) применить трансляционный фильтр со множеством разрешений. Все соответствующие масштабы вычисляются параллельно, и выбирается лучшая оценка; 2) применить пространственный фильтр, включающий масштаб. DCF вы- числяется в 3D, а не в 2D, а третья координата определяет размер объ- екта; 3) применить дискриминативное отслеживание масштаба. Вдоль оси мас - штаба применяется 1D-фильтр DCF для определения размера объекта. Как показывает сравнение, первые два метода не только медленнее третье- го, но даже не повышают точность (Danelljan et al., 2017). Поэтому в данном разделе мы рассмотрим только третий метод. Основное предположение состоит в том, что масштаб изменяется мед- леннее, чем положение. Следовательно, мы можем разделить отслеживание\n--- Страница 409 ---\n408  Визуальное отслеживание движущихся объектов положения и масштаба, сначала оценив перемещение при постоянном мас - штабе с DCF, как было описано ранее, а затем оценив изменение масштаба. Масштабы, которые должны давать низкие оценки, должны генерировать- ся явным образом пирамидой масштаба области внутри ограничивающей рамки (рис. 9.4 справа), в отличие от случая трансляции, когда смещенные окна образованы сдвинутыми ограничивающими рамками. Затем соответ - ствующие векторы признаков упорядочиваются для формирования карты признаков по координате масштаба и с использованием окна Ханна. Псевдокод для дискриминативного отслеживания масштаба имеет следу - ющий вид: Вход: – Изображение I t – Предыдущее положение p t–1 и масштаб s t–1 – Модель переноса A t–1,trans , Bt–1,trans – Модель масштаба A t–1,scale , Bt–1,scale Выход: – Расчетное положение p t и масштаб s t – Обновленная модель переноса A t,trans , Bt,trans – Обновленная модель масштаба A t,scale, Bt,scale Оценка переноса: 1. Извлечь образец x t,trans из изображения I t для p t–1 и s t–1 2. Вычислить показатели корреляции yt,trans , используя (9.33) с ft–1,trans согласно (9.43) 3. Принять за p t положение, максимизирующее y t,trans Оценка масштаба: 4. Извлечь образец z t,scale из изображения I t для p t–1 и s t–1 5. Вычислить показатели корреляции yt,scale, используя (9.33) с ft–1,scale согласно (9.43) 6. Принять за s t масштаб, максимизирующий y t,scale Обновление модели: 7. Извлечь образцы x t,trans и x t,scale из I t для p t и s t 8. Обновить модель переноса A t,trans , Bt,trans , используя (9.41) и (9.42) 9. Обновить модель масштаба A t,scale, Bt,scale, используя (9.41) и (9.42). Примечание. Масштабирование содержимого окна делает проблему с пе- риодическим расширением очевидной, поскольку в этом процессе окно Хан- на не масштабируется. 9.3.5. Пространственное и временное взвешивание Несмотря на использование окна Ханна, неявное периодическое расшире- ние патча, вызванное преобразованием Фурье, снижает дискриминативную способность фильтра. Признаки, характерные для интересующего объекта, вновь появляются вблизи патча и создают побочные пики в функции оценки. Наивная попытка противодействовать этим побочным пикам с по мощью\n--- Страница 410 ---\nМетоды последовательного обучения  409 увеличенных окон поиска терпит неудачу, поскольку большая часть рас - сматриваемого патча в таком случае состоит из фоновых пикселей. Фильтр склонен связывать эти фоновые пиксели с пиком функции, т. е. он изучает высокие коэффициенты в этих местах, и трекер будет «цепляться» за эле- менты фона, вместо того чтобы следовать за объектом (Danelljan et al., 2015). Чтобы противодействовать этому эффекту, было предложено добавить к (9.32) пространственную регуляризацию, которая штрафует коэффициенты фильтра за пределами ограничивающей рамки (Danelljan et al., 2015): (9.45) Однако требуемое поточечное умножение w и f в пространстве изображе- ния становится сверткой в пространстве Фурье, что приводит к утрате основ- ного преимущества DCF – вычислительной эффективности. Один из вариан- тов решения проблемы заключается в том, чтобы чередовать пространство изображения и пространство Фурье (Galoogahi et al., 2015), другой – выбрать весовую функцию w, которая имеет лишь несколько ненулевых коэффици- ентов Фурье. В последнем случае свертка в области Фурье не представляет проблемы, поскольку вычислительные затраты увеличиваются лишь незна- чительно (Danelljan et al., 2015). Количество вычислений значительно сокращается заменой комплексных произведений Адамара (точечных) в (9.38) вещественными матричными произведениями. Начнем с системы уравнений (X*diag(α )X + λI)F— = X*diag(α )Y (9.46) и заменим X на D, F— на F˜ и Y на Y˜, т. е. на соответствующие вещественные представления. Преобразование Фурье применительно к функции вещест - венных величин является эрмитово-симметричным, т. е. P(–u, –v) = P—(u, v), а изометрическое отображение (P(u, v), P(–u, –v)) → (P(u, v) + P(–u, –v))/ , (P(u, v) – P(–u, –v)/i ) (9.47) приводит к тому же решению, но с использованием вещественных, а не ком- плексных матриц. Если мы далее обобщим λI как WTW, представляя разре- женную свертку, индуцированную пространственными весами, то получим (9.48) Решим эту систему методом Гаусса–Зейделя, т. е. разобьем LHS на нижнюю треугольную и строго верхнюю треугольную части (9.49)\n--- Страница 411 ---\n410  Визуальное отслеживание движущихся объектов и вычислим решение по итерациям (9.50) В частности, для w с несколькими ненулевыми коэффициентами Фурье этот метод быстро сходится и дает фильтры с малыми коэффициентами в окрестности. Заметим также, что этот метод позволяет избежать аппрок - симативного решения в (9.42) и ограничения αk на геометрическую про- грессию. Полученная свобода выбора αk использовалась для систематического уменьшения веса выборок, появляющихся в результате дрейфа трекера от цели со временем (Danelljan et al., 2016). Веса αk устанавливаются путем переопределения важности каждого кадра во время последующих выборок. Эта процедура помогает в неоднозначных случаях (например, при частичной окклюзии) и позволяет нам использовать всю доступную информацию. Веса инициализируются из предыдущей информации, например из воз- раста выборки. Обычно используются априорные веса выборки ρk, обуслов- ленные коэффициентом забывания 1 – η (9.9). Затем мы оптимизируем со- вместные потери (9.51) так, что α k ³ 0, k = 1, …, t, (9.52) (9.53) путем многократного обновления f с по мощью итерации Гаусса–Зейделя (9.50) и α с по мощью квадратичного программирования. В разделе 9.4.2 будет представлен еще более эффективный способ опти- мального использования всех доступных кадров, основанный на глубоких признаках. 9.4. методы , осно Ванные на гЛубоКом обу Чении Трекеры DCF являются мощными методами, если применяются ранее вве- денные концепции регуляризации, масштабной адаптации и многоканаль- ных функций оценки. Однако узким местом для дальнейшего улучшения является предопределенный слой признаков, созданных вручную. В этом разделе описывается переход к глубоким и адаптивным признакам и, на- конец, сквозному обуче нию DCF.\n--- Страница 412 ---\nМетоды, основанные на глубоком обучении  411 9.4.1. Глубокие признаки в DCF Использование созданных вручную признаков, описанных в разделе 9.3.3, было обусловлено традиционными методами обнаружения объектов. В ран- них методах обнаружения объектов на основе глубоких нейросетей часто использовали прогнозирование регионов (Girshick et al., 2016), которые хуже подходят в качестве признаков для DCF. Поэтому в качестве первых попы- ток интегрировать глубокие признаки внешнего вида в DCF (Danelljan et al., 2016) вместо сетей-детекторов использовали базовые решения из области классификации изображений, например imagenet-vgg-m-2048 / CNN-M-2048 (Chatfield et al., 2014). При рассмотрении базовой сети для создания карты признаков в качест - ве входных данных, подаваемых в DCF, возникает очевидный вопрос, ка- кой слой использовать. Кандидатами являются сверточные слои, например с первого по пятый в imagenet-vgg-m-2048. Самые верхние слои характери- зуются высоким пространственным разрешением и небольшим количеством каналов (например, 109×109, 96 каналов для первого слоя в imagenet-vgg- m-2048), а самые глубокие слои – низким пространственным разрешением и большим количеством каналов (например, 13×13, 512 каналов для пятого слоя в imagenet-vgg-m-2048). Как правило, более глубокие слои компенсиру - ют большее количество каналов меньшим пространственным разрешением, что является неизбежным следствием постоянства соотношения между не- определенностью в пространстве изображения и пространстве признаков (Felsberg, 2009). В то время как большее количество каналов признаков обеспечивают лучшую дискриминативную способность, уменьшенное пространственное разрешение может привести к ухудшению точности. С точки зрения VOT- критериев робастности и точности предполагается, что DCF на основе не- глубоких признаков будет характеризоваться высокой точностью и низкой робастностью, тогда как DCF на основе глубоких признаков будет характери- зоваться низкой точностью и высокой робастностью. Это также неявно под- тверждается экспериментами с imagenet-vgg-m-2048, где первый и пятый уровни являются локальными максимумами точности перекрытия OTB-50 (Danelljan et al., 2016) – меры, которая объединяет точность и робастность (Wu et al. др., 2013). Разумеется, нам хотелось бы объединить обе карты признаков, чтобы ис - пользовать как высокую пространственную точность неглубоких признаков, так и робастность глубоких. Однако различные пространственные разре- шения потребуют либо повышающей дискретизации глубоких признаков, что невозможно с вычислительной точки зрения, либо понижающей дис - кретизации неглубоких, что снизит положительный эффект в отношении точности. Идеальным случаем было бы, если бы все карты признаков были непрерывными функциями и дискретизация вообще не требовалась. Но как представить непрерывную карту признаков в цифровом компьютере? Решение кроется в изометрических преобразованиях непрерывных сиг - налов в дискретные спектры, такие как ряд Фурье или другие разложения\n--- Страница 413 ---\n412  Визуальное отслеживание движущихся объектов в ряд (Danelljan et al., 2016), – это трекер C-COT. Чтобы упростить изложение, мы сосредоточимся на рядах Фурье с конечным числом коэффициентов, но метод обобщается на все изометрические преобразования. Начнем с пере- смотра расчета mAP-оценки с использованием корреляций карты признаков и набора фильтров (9.33). Если мы предположим, что эта корреляция вы- полняется в непрерывной области между непрерывной картой признаков и множеством непрерывных фильтров (9.54) где Jl{xl} – гипотетическое отображение дискретной карты признаков xl в не - прерывную область, мы можем легко объединить карты признаков с различ- ным пространственным разрешением. Если мы теперь переместим всю систему в пространство Фурье, – нам все равно придется сделать это для вычисления решений (9.43), – непрерывная корреляция станет поточечным произведением дискретных коэффициентов. Периодическая непрерывная функция имеет бесконечно много дискретных коэффициентов Фурье, но мы также знаем, что усечение последователь- ности коэффициентов приведет к оптимальной аппроксимации в смысле L2 (кстати, это особое свойство ряда Фурье). Аппроксимация mAP-оценки оптимальным для L2 способом идеально соответствует идее MOSSE о мини- мальной L 2-ошибке вывода. В итоге это означает, что, используя решение (9.50) (или более эффектив- ную формулировку с применением метода сопряженных градиентов), мы приобретаем все инструменты для слияния карт признаков с различным разрешением – в отличие от подхода, основанного на ADMM (Galoogahi et al. al., 2015), который переключается между пространством изображения и про- странством Фурье. В дополнение к объединению первого и пятого слоев и не- обработанных входных данных (224×224, RGB) непрерывная модель допуска- ет субпиксельную локализацию во время логического вывода и обуче ния, что улучшает результаты даже больше, чем повышение дискретизации до самого высокого разрешения. Заметим в этом контексте, что для целевой функции y известна ее аналитическая форма (уравнение 9.19), поэтому мы можем точно вычислить коэффициенты Фурье. Обратите внимание, что этот подход также можно использовать для отслеживания характерных точек в качестве альтернативы KLT (Lucas, Kanade, 1981). После перехода к многослойным признакам внешнего вида можно инте- грировать другие модальности. Ранее игнорируемый тип признаков в DCF- трекерах – это признаки движения, которые теперь можно объединять с при- знаками внешнего вида (Danelljan et al., 2019). Признаки внешнего вида, применяемые в этой работе, взяты из сети imagenet-vgg-verydeep-16/Con- vNet C (Simonyan, Zisserman, 2015) с 13 сверточными слоями и глубокими признаками движения (Chéron et al., 2015), вычисленными с трехканального входа (вектор оптического потока и его величина), состоящего из пяти свер- точных слоев. Для отслеживания наилучшие результаты дает объединение\n--- Страница 414 ---\nМетоды, основанные на глубоком обучении  413 слоев внешнего вида 4 (128 каналов, страйд 2) и 13 (512 каналов, страйд 16) и пятого слоя движения (384 канала, страйд 16) (Danelljan et al., 2019). 9.4.2. Адаптивные глубокие признаки Применение интеграции нескольких карт признаков для DCF-трекеров при- водит к значительному улучшению результатов по сравнению с предшеству - ющими методами как с использованием созданных вручную признаков, так и с однослойными глубокими признаками, но также вызывает увеличение количества параметров в модели фильтра. Большое количество параметров проблематично в двух отношениях: во-первых, от него напрямую зависит объем вычислений. Во-вторых, количество обучающих данных ограничено, а количество параметров легко выходит за пределы размерности входных данных, что приводит к переобучению. Например, было обнаружено, что трекер C-COT, использующий при- знаки imagenet-vgg-m-2048, при последовательном обучении набирает до 800 000 параметров (Danelljan et al., 2017). Чтобы решить возникающие в ре- зультате проблемы сложности сети и нехватки данных для обуче ния, был предложен трекер ECO, основанный на эффективных операторах корреля- ции и дискриминативно изучающий отображение в пространстве признаков более низкой размерности (Danelljan et al., 2017). Это достигается за счет совместной минимизации ошибки классификации, что приводит к сокра- щению количества параметров модели на 80 %. Ключевая идея состоит в том, чтобы ввести некоторый оператор проекции P, который перед вычислением оценки отображает d каналов непрерывных признаков в (9.54) в c ≪ d измерений. На этот оператор не влияет преобра- зование Фурье. Добавив регуляризатор для L2-нормы всех коэффициентов оператора P , мы переформулируем (9.45) в виде (9.55) где pl – векторы-столбцы в P, а последний член – норма Фробениуса. Эти потери минимизируются с по мощью метода Гаусса–Ньютона, полученного путем линеаризации остатков. За дополнительной информацией мы отсы- лаем читателей к оригинальной публикации (Danelljan et al., 2017). Несмотря на достигнутое улучшение соотношения параметров и количест - ва обучающих данных, необходимое разнообразие обучающих данных все равно потребует достаточно большой выборки, что приводит к значительной вычислительной нагрузке. Кроме того, размер памяти ограничен, что приво- дит к сокращению временного горизонта последовательного обуче ния, а от - брасывание старых выборок приводит к переобучению на последних кадрах. Чтобы избежать этого переобучения, сумма по всем выборкам от k = 1 до t в (9.55) заменяется математическим ожиданием по совместному распре- делению p (x, y):\n--- Страница 415 ---\n414  Визуальное отслеживание движущихся объектов (9.56) Неявное использование исходной суммы означает предположение, что из p(x, y) взяты t выборок и их достаточно много, чтобы точно аппроксимиро- вать p (x, y), однако это может быть неправильным предположением. Для получения компактного и разнообразного представления обучающих данных ECO-трекер моделирует p(x, y) как смесь моделей Гаусса. Сочетание двух улучшений по сравнению с C-COT не только повышает скорость, но и улучшает точность на 13,3 % (Danelljan et al., 2017). Подход, применяемый в трекерах C-COT и ECO, не ограничивается призна- ками imagenet-vgg-m-2048, но, что несколько неожиданно, использование более мощных базовых моделей, таких как GoogLeNet (Szegedy et al., 2015) или ResNet-50 (He et al. al., 2016), не улучшает точность (Bhat et al., 2018). Чтобы эффективно раскрыть возможности глубокого отслеживания, карты признаков не должны объединяться на уровне входных данных средства отслеживания, как это сделано в (9.54). Вместо этого лучший эффект дает обуче ние глубоких и неглубоких моделей независимо друг от друга и с раз- ной шириной целевой функции, а также применение взвешенного слияния раздельно обученных трекеров. Как отмечалось в разделе 9.4.1, прогнозы, основанные на карте глубоких признаков d = Sf (xd), характеризуются высокой надежностью, но худшей локализацией, а прогнозам, основанным на карте неглубоких признаков s = Sf (xs), присуща высокая точность локализации, но они легко теряют цель при изменении внешнего вида. Два прогноза можно комбинировать различными способами, но адаптивно взвешенная сумма β(p) = βdd(p) + βss(p) (9.57) уже приводит к значительному улучшению по сравнению с трекером ECO. На каждом временном шаге адаптивные веса вычисляются путем решения задачи квадратичного программирования (9.58) так, что β d + βs = 1, β d ³ 0, β s ³ 0, (9.59) β(p*) – ξD(p* – p) ³ β(p), \"p, (9.60) где p* – потенциальное целевое состояние (например, позиция), которое вы- бирается из локальных максимумов в d и s, μ – параметр регуляризации, а D(p) = 1 – exp(–4|p |2/s), где s является размером цели. 9.4.3. DCF сквозного обучения Подходы, описанные в предыдущем разделе, добавляют адаптацию призна- ков в DCF-трекеры с глубокой сетью. Базовая глубокая сеть обучается в авто-\n--- Страница 416 ---\nМетоды, основанные на глубоком обучении  415 номном режиме на данных классификации изображений, трекер обуча ется в режиме реального времени с использованием текущей последовательно- сти, а процедура адаптации представляет собой инженерную задачу опти- мизации. Если мы хотим вместо этого сосредоточиться на обучении для подключения базовой модели к трекеру, нам нужно использовать обучающие данные, относящиеся к отслеживанию. Основное различие между адапта- цией и обуче нием заключается в данных, используемых для оптимизации: в отличие от адаптации, обуче ние пытается обобщить обучающие данные на рабочие данные во время вывода. Ключевая проблема, решаемая адаптивной комбинацией mAP-оценок в (9.57), состоит в том, чтобы генерировать унимодальные функции оценок с максимумом, сосредоточенным внутри ограничивающей рамки. Объедине - ние функций оценки из неглубоких и глубоких признаков является хорошо работающим эвристическим решением, но подход машинного обуче ния ин- тересен тем, что напрямую решает саму задачу. Следовательно, задача сво- дится к тому, чтобы на обучающих данных отслеживания изучить предиктор меры точности – индекс Жаккара. Вместо того чтобы выбирать все локальные максимумы и оптимизировать веса, предсказание индекса Жаккара позволя- ет выбрать ограничивающую рамку-кандидата с наибольшим перекрытием. Эта идея максимизации перекрытия используется в трекере ATOM (Danel- ljan et al., 2019), который сочетает в себе обучаемый онлайн-классификатор (похожий на DCF) с индексным регрессором Жаккара, который обучается на аннотированных данных отслеживания (рис. 9.5). Очевидно, что регрессор- ная сеть должна учитывать конкретную цель, заданную в исходной (эталон- ной) системе координат. Это достигается путем модуляции вектора коэф- фициентов текущего кадра соответствующим вектором из опорного кадра перед подачей его в предиктор. Трекер ATOM Кадр #0 Кадр #tБазовая сеть Базовая сетьМодуляция IoU Предиктор IoU IoU #t mAP-оценка #tКласси- фикаторОграничиваю - щая рамка 0 Рис. 9.5  Трекер АТОМ состоит из ветви классификации и ветви регрессии для индекса Жаккара (пересечение над объединением) Две ветви, для системы отсчета и текущей системы координат, очень по- хожи по структуре. Основное отличие состоит в том, что ветвь тестирования для текущего кадра не имеет доступа к ограничивающей рамке, а вместо этого использует начальную оценку из классификатора, подобного DCF. Весь регрессор подвергается сквозному обуче нию, при этом классификатор\n--- Страница 417 ---\n416  Визуальное отслеживание движущихся объектов обуча ется не с использованием потерь с обратным распространением, а с ис - пользованием критерия MOSSE. Таким образом, классификатор действует как фиксированный вход в сеть регрессора, которая имеет двухветвенную архитектуру, напоминающую сиамский трекер (Zhu et al., 2018). Подробное описание сетевой модели регрессора индекса Жаккара можно найти в ста- тье (Danelljan et al., 2019) или репозитории кода (https://github.com/visionml/ pytracking). Классификатор в основном аналогичен классификатору в ECO-трекере, с первым уровнем, который сокращает количество каналов признаков до 64 (оператор проекции), и вторым уровнем с ядром 4×4. Из-за ограниченно- го размера пространственного ядра последовательная оптимизация теперь выполняется не в пространстве Фурье, а непосредственно в пространстве изображения. Одним из преимуществ этого изменения является то, что к вы- ходным данным свертки можно добавить нелинейную функцию активации, в данном случае параметрический экспоненциально-линейный блок. В дальнейшем развитии трекера ATOM, которое можно рассматривать как слияние DCF-подобных подходов и сиамских трекеров (Чжу и др., 2018), цель MOSSE исключена, и потери вместо этого изучаются на основе данных (Bhat et al., 2019). Этот метод под названием DiMP можно рассматривать как следующий шаг дискриминативного обуче ния, где дискриминационная способность оценивается не по L2-расстоянию, а по некоторой функции рас - стояния, зависящей от данных. Это также повышает гибкость представле- ния результатов отслеживания: вместо параметрического ограничивающего прямоугольника можно легко перейти к маскам сегментации. 9.5. переХод от отсЛежи Вания К сегментации Параметрическая модель ограничивающей рамки неявно подразумевает формулировку целевой функции как функции Гаусса с центром в истинном положении и масштабе. Помимо смещения, упомянутого в разделе 9.2.2, ограничивающая рамка также страдает от присущей ей неточности для объ- ектов, форма которых отличается от прямоугольной. Борьба с этой пробле- мой начинается с аннотирования, когда общая точность повышается за счет аннотирования масок сегментации и автоматической подгонки ограничива- ющих рамок (Vojír, Matas, 2017; Kristan et al., 2016). 9.5.1. Сегментация видеообъектов С 2020 года задача VOT оценивает индекс Жаккара по маскам сегментации, а не ограничивающим рамкам (Kristan et al., 2020). Это означает, что отсле- живание визуальных объектов стало похоже на сегментацию видеообъектов (video object segmentation, VOS) для случая с одним экземпляром (Perazzi et al., 2016). Задача в VOS состоит в том, чтобы классифицировать каждый пик - сель в кадре видео либо как фон, либо как часть целевого объекта. Методы\n--- Страница 418 ---\nПереход от отслеживания к сегментации  417 VOS обучаются в автономном режиме на аннотированных видеопоследо- вательностях и оцениваются на тестовых последовательностях с частично новыми (незнакомыми) классами объектов. Как и в случае с VOT, при оценке методов VOS используется индекс Жак - кара (раздел 9.2.2). Однако два прогноза могут иметь одинаковый индекс Жаккара, но совершенно разные формы, которые можно оценить только с по мощью меры контура. В тестовой задаче DAVIS (Perazzi et al., 2016) для этой цели используется ℱ -мера контура, определяемая как (9.61) где P – точность (precision), а R – полнота отклика (recall). Для контуров точ- ность вычисляется как доля предсказанных пикселей контура, которые дей- ствительно являются таковыми, а полнота вычисляется как доля пикселей истинного контура, которые являются предсказанными пикселями контура. Обычно ℱ-мера вычисляется приближенно с использованием морфологиче- ских операторов (Perazzi et al., 2016). В случае обуче ния с частичным участием учителя (Perazzi et al., 2016) пер- вый кадр тестовой последовательности аннотируется маской сегментации, аналогично заданию VOT2020. Следовательно, метод VOS должен адапти- роваться к этому единственному аннотированному образцу, решая задачу однократного обуче ния. В случае обуче ния без учителя (Perazzi et al., 2016) аннотация не предоставляется, но предполагается, что целевой объект не- явно определяется его движением относительно фона. Наконец, существует также сценарий множественных объектов с частичным обуче нием, когда в начальном кадре аннотируют несколько объектов (Perazzi et al., 2017). Эта задача также тесно связана с проблемой сегментации экземпляров видео (vi- deo instance segmentation, VIS), где, как и при обнаружении объектов на не- подвижных изображениях, необходимо сегментировать все известные объ- екты по всей последовательности (Yang et al., 2019). В оставшейся части этой главы мы сосредоточимся на проблеме VOS с час - тичным обуче нием для случая с одним экземпляром, поскольку она наибо- лее близка к проблеме VOT с аннотацией маски сегментации. В определен- ном смысле этот переход к маскам сегментации можно рассматривать как конечную точку развития методов отслеживания ограничивающей рамки, аналогично тому, как трекер АТОМ завершает серию DCF на основе пре- образования Фурье, а трекер DiMP завершает серию DCF, основанных на MOSSE. Но прежде чем рассматривать дискриминативные методы VOS, мы сначала изучим генеративный подход, чтобы прояснить разницу между методами VOS. 9.5.2. Генеративный метод VOS Несмотря на то что область VOS довольно молода даже по меркам компью- терного зрения, в ней уже появилось множество различных подходов\n--- Страница 419 ---\n418  Визуальное отслеживание движущихся объектов к глубокому обуче нию. Мы не станем давать здесь обзор методов глубо- кого обуче ния для VOS и сошлемся на недавние обзорные статьи по этой теме, например (Yao et al., 2019). Однако стоит заметить, что многие методы преду сматривают масштабную тонкую настройку сети, используя аннотацию первого кадра тестовых последовательностей. Это решение не подходит для практического применения, поскольку означает, что видео не может обра- батываться на лету, а задержка между входом и откликом модели в лучшем случае составляет несколько минут. Один из подходов, позволяющих избежать столь прямолинейной и трудо- емкой настройки, основан на генеративной модели внешнего вида (a generative appearance model, AGAME) (Johnander et al., 2019). Данный метод оценивает параметры гауссовой смешанной модели (Gaussian mixture model, GMM) и из- влекает глубокие признаки из (9.62) где p(x|z = k) = 𝒩(x|μk, Σk). Подразумевается единый приор 1/K для всех ком- понентов k, которые находятся либо на заднем, либо на переднем плане. Каждый из этих двух классов разбивается на основную моду и моду сложных случаев, т. е. всего мы получаем четыре компонента. Параметры GMM θ, т. е. средние μk и дисперсии Σk, инициализируются из начального кадра. Во время развертывания модели, т. е. последующих кадров Ii, когда доступны только оценки принадлежности к классу, для обновления модели используются следующие присвоения: αi 0 = 1 – (Ii, θi–1, Φ); (9.63) αi 1 = (Ii, θi–1, Φ); (9.64) αi 2 = max(0, αi 0 – p(zi = 0|xi, μi 0, Σi 0)); (9.65) αi 3 = max(0, αi 1 – p(zi = 1|xi, μi 1, 1)). (9.66) Здесь Φ обозначает параметры сетей слияния и прогнозирования. Грубые прогнозы вычисляются путем слияния выхода распростране- ния маски и оценки компонента (логарифмические вероятности lnp (z = k) p(x|z = k)): (9.67) в результате получаются значения для компонентов 0 и 1. Вероятности в случаях 2 и 3 вычисляются с использованием мягкого максимума соот - ветствующих оценок. Четыре мягких значения используются для вычисле- ния обновлений среднего значения и дисперсии как взвешенных первого и второго моментов. Затем обновления передаются в скользящее среднее, аналогичное (9.9).\n--- Страница 420 ---\nПереход от отслеживания к сегментации  419 Во время вывода прогнозы уточняются модулем повышающей дискрети- зации для достижения полного разрешения. Уровень точности алгоритма AGAME делает его применимым для полуавтоматического аннотирования в задаче RGBT VOT2019 после дополнительных проверок правильности (Berg et al., 2019). 9.5.3. Дискриминативный метод VOS Подобия в случаях 2 и 3 в предыдущем разделе «обеспечивают кодирова- ние дискриминативной маски» (Johnander et al., 2019), что сразу наводит на мысль, можно ли заменить GMM дискриминативной моделью, т. е. вы- деленной целевой моделью, подобной той, что в трекере АТОМ. Подобно GMM в AGAME, эта целевая модель должна адаптироваться к внешнему виду цели путем надлежащего обновления, чтобы максимизировать разделение переднего плана и фона. Ожидается, что фокусировка на дискриминативной способности, а не на всем распределении, приведет к созданию более легкого и быстрого алгоритма по сравнению с AGAME. Эту идею подтверждает дискриминативный метод VOS FRTM (Robinson et al., 2020), который также заменяет распространение маски, используемое в AGAME, на пространственно-временную согласованность. Целевая модель напоминает трекер АТОМ s = D(x; w) = w2 ∗ (w 1 ∗ x) (9.68) и последовательно обучается с использованием взвешенного MOSSE- критерия (9.69) где vk – балансировочный вес для увеличения значимости небольших целе- вых объектов, U выполняет билинейную повышающую дискретизацию, а γk – веса для контроля влияния различных образцов в наборе данных. В последовательном обучении, как и в методах отслеживания, использует - ся временное окно. Данные из этого окна хранятся в памяти M . Псевдокод для обуче ния целевой модели выглядит следующим образом: 1. Инициализировать память M, обучить дискриминационную целевую модель D. 2. Извлечь признаки x из следующего кадра. 3. Применить целевую модель и сгенерировать грубые mAP-оценки s. 4. Улучшить s до целевой маски y с по мощью уточняющей сети. 5. Обновить M новым образцом (x , y, γ). 6. Повторно оптимизировать дискриминативную целевую модель с по- мощью M в каждом восьмом кадре. 7. Вернуться к шагу 2. Уточняющая модель, использованная на шаге 4, обучается в автономном режиме на этапе обуче ния VOS. Назначения грубой оценки s и уточненной\n--- Страница 421 ---\n420  Визуальное отслеживание движущихся объектов маски y аналогичны AGAME, но AGAME использует грубый прогноз для об- новления модели, тогда как FRTM использует уточненный прогноз для обуче- ния, предварительно применяя билинейную повышающую дискретизацию. Благодаря этим изменениям FRTM становится очень быстродействующим и позволяет использовать алгоритмы VOS в реальном времени. Подобно переходу от ATOM к DiMP с обобщением потерь, целевая модель VOS также может быть оптимизирована в отношении представления, от - личного от предсказания грубой сегментации. Предположим, что целевая модель (9.68) создает некоторую карту признаков вместо карты грубой сег - ментации и что уточненная сегментация создается декодером, а не модулем повышающей дискретизации. В этом случае потери для целевой модели мо- гут быть вычислены в области карты признаков путем кодирования маски сегментации и вычисления взвешенной ошибки L2 между закодированной сегментацией и выходными данными целевой модели (Bhat et al., 2020). Этот подход связывает обуче ние VOS с метрическим обуче нием. Другими интересными вопросами являются обобщение на VOS с обуче нием без учи- теля, VOS с несколькими экземплярами объектов и VIS. 9.6. В ыВоды Развитие методики от простого сопоставления шаблонов до сегментации видео, описанное в этой главе, является одним из краеугольных камней для многих приложений компьютерного зрения. Анализ видеоряда, визуальное наблюдение, дистанционное слежение, дополненная реальность (augmented reality, AR), визуальное управление роботами и автономные транспортные средства – это всего лишь несколько основных областей применения разра- ботанных методов. Большинство этих приложений требуют обработки в ре- альном времени, надежных моделей и точных прогнозов. Например, AR требует обработки видео в реальном времени с малой за- держкой, чтобы уменьшить дискомфорт от AR1. Безмаркерные методы до- полненной реальности в значительной степени зависят от визуального отслеживания (Chandaria et al., 2007). Совмещение ракурса камеры и вир- туального положения также можно использовать для управления беспилот - ными транспортными средствами. Например, виртуальное привязывание можно реализовать с по мощью трекера DCF на кадрах RGB с дрона (Häger et al., 2016). Входные данные, обсуждаемые в этой главе, были в основном ограниче- ны последовательностями RGB, но аналогичные методы можно применять и к другим спектральным диапазонам или данным о глубине. Например, системы безопасности поездов на основе тепловизионных инфракрасных камер могут смягчать последствия столкновений с крупными животными, 1 Укачивание, тошнота и головная боль, возникающие вследствие почти не ощу - тимой, но неестественно большой задержки зрительных образов относительно остальных органов чувств человека при использовании очков виртуальной реаль- ности. – Прим. перев.\n--- Страница 422 ---\nБлагодарности  421 людьми и препятствиями на пути (Berg et al., 2015). В данной работе обна- ружение аномалий на пути осуществляется с по мощью фильтра на основе MOSSE. Кроме того, системы безопасности автомобилей, которые, например, обнаруживают пешеходов с по мощью ИК-камер (Källhammer et al., 2007) и RGB-камер, выигрывают от прогресса в области комбинированного RGB- и ИК-отслеживания (Kristan et al., 2019b). Методика DCF подходит не только для отслеживания и обнаружения ано- малий, но и может быть дополнительно обобщена в направлении масштаб- но-пространственного отслеживания. Например, визуальная навигация судна в прибрежных районах может обеспечить точность GPS (Grelsson et al., 2020). Здесь эффективность реализации DCF-преобразования Фурье ис - пользуется для сопоставления в режиме реального времени сегмента линии горизонта с огромным количеством модельных горизонтов, выбранных из цифровой модели рельефа. С переходом методов VOS и VIS на обработку в реальном времени воз- никают новые области применения и новые функции в существующих об- ластях. Например, системы дополненной реальности могут использовать совмещение сегментированных объектов для дальнейшего улучшения точ- ности и задержки. Автономные автомобили и передовые системы помощи водителю уже сейчас используют семантическую сегментацию по кадрам, но быстродействие может еще больше возрасти благодаря мощным алгоритмам VIS. Навигация судов больше не нуждается в отдельном извлечении линии горизонта, а может интегрировать анализ горизонта в сопоставление изо- бражений. Очевидно, что потенциальное неправомерное использование и этически неоднозначные способы применения также выигрывают от развития со- временных методов компьютерного зрения. Например, массовая слежка за людьми со стороны органов власти или компаний уже стала заурядным яв- лением. Точно так же методы VOS можно использовать для фальсификации видео или создания дипфейков. Наконец, существуют различные военные применения, в частности с использованием ИК-изображений. Открытость исследований и доступность реализаций с открытым исходным кодом яв- ляются ключом к научному прогрессу, но, к сожалению, также и к неправо- мерному использованию его плодов. бЛагодарности Большая часть этой главы посвящена методам и результатам, полученным в течение последних семи лет в Лаборатории компьютерного зрения в Лин- чепинге в сотрудничестве с Фахадом Ханом и несколькими аспирантами и магистрантами. В первую очередь следует упомянуть Мартина Данельяна, Густава Хегера, Андреаса Робинсона, Йоакима Йонандера, Феликса Яремо- Лавина, Гутама Бхата, Аманду Берг и Сюзанну Глад. Исследовательская работа, описанная в этой главе, была частично поддер- жана KAW через Wallenberg AI, программой Autonomous Systems and Software\n--- Страница 423 ---\n422  Визуальное отслеживание движущихся объектов Program WASP , Шведским исследовательским советом через проекты EMC2, NCNN и ELLIIT, SSF через проекты CUAS и Symbicloud, а также LiU через CE- NIIT. Литературные исто ЧниКи Baker S., Matthews I., 2004. Lucas-Kanade 20 years on: a unifying framework. International Journal of Computer Vision 56 (3), 221–255. Berg A., Öfjäll K., Ahlberg J., Felsberg M., 2015. Detecting rails and obstacles us- ing a train-mounted thermal camera. In: Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics). In: LNCS, vol. 9127, pp. 492–503. Berg A., Johnander J., Durand De Gevigney F., Ahlberg J., Felberg M., 2019. Semi- automatic annotation of objects in visual-thermal video. In: Proceedings – 2019 International Conference on Computer VisionWorkshop, ICCVW 2019, pp. 2242–2251. Bhat G., Johnander J., Danelljan M., Khan F. S., Felsberg M., 2018. Unveiling the power of deep tracking. In: Lecture Notes in Computer Science (Including Sub- series Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinforma- tics). In: LNCS, vol. 11206, pp. 493–509. Bhat G., Danelljan M., Van Gool L., Timofte R., 2019. Learning discriminative model prediction for tracking. In: Proceedings of the IEEE International Conference on Computer Vision, vol. 2019-Octob, pp. 6181–6190. Bhat G., Lawin F. J., Danelljan M., Robinson A., Felsberg M., Van Gool L., Timofte R., 2020. Learning what to learn for video object segmentation. In: Vedaldi A., Bischof H., Brox T., Frahm J.-M. (Eds.), Computer Vision – ECCV 2020. Springer International Publishing, Cham, pp. 777–794. Bolme D. S., Beveridge J. R., Draper B. A., Lui Y. M., 2010. Visual object tracking using adaptive correlation filters. In: Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pp. 2544–2550. Bracewell R. N., 1995. Two-Dimensional Imaging. Prentice Hall Signal Processing Series. Prentice Hall, Englewood Cliffs. Chandaria J., Thomas G., Bartczak B., Koeser K., Koch R., Becker M., Bleser G., Strie- ker D., Wohlleber C., Felsberg M., Gustafsson F., Hol J. D., Schön T. B., Skoglund J., Slycke P. J., Smeitz S., 2007. Realtime camera tracking in the MATRIS project. SMPTE Motion Imaging Journal 116 (7–8), 266–271. Chatfield K., Simonyan K., Vedaldi A., Zisserman A., 2014. Return of the devil in the details: delving deep into convolutional nets. In: British Machine Vision Conference. Chen Q.-S., Defrise M., Deconinck F., 1994. Symmetric phase-only matched filter - ing of Fourier-Mellin transforms for image registration and recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence 16, 1156–1168. Chéron G., Laptev I., Schmid C., 2015. P-CNN: pose-based CNN features for ac - tion recognition. In: 2015 IEEE International Conference on Computer Vision (ICCV), pp. 3218–3226.\n--- Страница 424 ---\nЛитературные источники  423 Dalal N., Triggs B., 2005. Histograms of oriented gradients for human detection. In: Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on, vol. 1, pp. 886–893. Danelljan M., Häger G., Khan F. S., Felsberg M., 2014a. Accurate scale estimation for robust visual tracking. In: BMVC 2014 – Proceedings of the British Machine Vision Conference 2014. Danelljan M., Khan F. S., Felsberg M., Van De Weijer J., 2014b. Adaptive color at - tributes for real-time visual tracking. In: Proceedings of the IEEE Computer So - ciety Conference on Computer Vision and Pattern Recognition, pp. 1090–1097. Danelljan M., Hager G., Khan F. S., Felsberg M., 2015. Learning spatially regularized correlation filters for visual tracking. In: Proceedings of the IEEE International Conference on Computer Vision, Vol. 2015 Inter, pp. 4310–4318. Danelljan M., Häger G., Khan F. S., Felsberg M., 2016a. Adaptive decontamination of the training set: a unified formulation for discriminative visual tracking. Proceedings - IEEE Computer Society Conference on Computer Vision and Pat - tern Recognition 2016-Decem, 1430–1438. Danelljan M., Hager G., Khan F. S., Felsberg M., 2016b. Convolutional features for correlation filter based visual tracking. In: Proceedings of the IEEE Interna- tional Conference on Computer Vision, vol. 2016-Febru, pp. 621–629. Danelljan M., Robinson A., Khan F., Felsberg M., 2016. Beyond correlation filters: Learning continuous convolution operators for visual tracking. LNCS, vol. 9909. Danelljan M., Hager G., Khan F. S., Felsberg M., 2017. Discriminative scale space tracking. IEEE Transactions on Pattern Analysis and Machine Intelligence 39 (8), 1561–1575. Danelljan M., Bhat G., Gladh S., Khan F. S., Felsberg M., 2019a. Deep motion and appearance cues for visual tracking. Pattern Recognition Letters 124, 74–81. Danelljan M., Bhat G., Khan F. S., Felsberg M., 2019b. Atom: accurate tracking by overlap maximization. Proceedings - IEEE Computer Society Conference on Computer Vision and Pattern Recognition 2019-June, 4655–4664. Dendorfer P., Osep A., Milan A., Schindler K., Cremers D., Reid I., Roth S., Leal- Taixé L., 2020. MOTChallenge: a benchmark for single-camera multiple target tracking. International Journal of Computer Vision. Everingham M., Van Gool L., Williams C. K., Winn J., Zisserman A., 2010. The Pascal visual object classes (VOC) challenge. International Journal of Computer Vision 88 (2), 303–338. Felsberg M., 1998. Signal Processing Using Frequency Domain Methods in {C}lif - ford Algebra. Diploma thesis Institute of Computer Science and Applied Mathe- matics. Christian-Albrechts-University of Kiel. Felsberg M., 2009. Spatio-featural scale-space. In: Lecture Notes in Computer Sci- ence (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics). In: LNCS, vol. 5567, pp. 808–819. Felsberg M., 2013. Enhanced distribution field tracking using channel represen- tations. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 121–128. Felsberg M., 2018. Probabilistic and Biologically Inspired Feature Representations. Morgan & Claypool Publishers.\n--- Страница 425 ---\n424  Визуальное отслеживание движущихся объектов Felsberg M., Duits R., Florack L., 2005. The monogenic scale space on a rectangular domain and its features. International Journal of Computer Vision 64 (2–3), 187–201. Galoogahi H. K., Sim T., Lucey S., 2015. Correlation filters with limited boundaries. In: 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4630–4638. Garon M., Lalonde J.-F., 2017. Deep 6-DOF tracking. IEEE Transactions on Visual- ization and Computer Graphics 23, 2410–2418. Girshick R., Donahue J., Darrell T., Malik J., 2016. Region-based convolutional networks for accurate object detection and segmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence 38, 142–158. Grelsson B., Robinson A., Felsberg M., Khan F. S., 2020. GPS-level accurate camera localization with HorizonNet. Journal of Field Robotics 37 (6), 951–971. Häger G., Bhat G., Danelljan M., Khan F. S., Felsberg M., Rudl P., Doherty P., 2016. Combining visual tracking and person detection for long term tracking on a UAV. In: Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics). In: LNCS, vol. 10072, pp. 557–568. Häger G., Felsberg M., Khan F., 2018. Countering bias in tracking evaluations. In: VISIGRAPP 2018 – Proceedings of the 13th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications, vol. 5, pp. 581–587. He K., Zhang X., Ren S., Sun J., 2016. Deep residual learning for image recognition. In: CVPR. Henriques J. F., Caseiro R., Martins P., Batista J., 2012. Exploiting the circulant structure of tracking-by-detection with kernels. In: Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lec - ture Notes in Bioinformatics). In: LNCS, vol. 7575, pp. 702–715. Horner J. L., Gianino P. D., 1984. Phase-only matched filtering. Applied Optics 23 (6), 812–816. Jaccard P., 1912. The distribution of the flora in the Alpine zone. New Phytologist 11 (2), 37–50. Johnander J., Danelljan M., Brissman E., Khan F. S., Felsberg M., 2019. A generative appearance model for endtoend video object segmentation. Proceedings - IEEE Computer Society Conference on Computer Vision and Pattern Recognition 2019-June, 8945–8954. Källhammer J. E., Eriksson D., Granlund G., Felsberg M., Moe A., Johansson B., Wiklund J., Forssén P. E., 2007. Near zone pedestrian detection using a low- resolution FIR sensor. In: IEEE Intelligent Vehicles Symposium, Proceedings, pp. 339–345. Khan F. S., Anwer R. M., van de Weijer J., Bagdanov A., Vanrell M., Lopez A. M., 2012. Color attributes for object detection. In: IEEE Conference on Computer Vision and Pattern Recognition. Koenderink J. J., 1984. The structure of images. Biological Cybernetics 50, 363–370. Kristan M., Pflugfelder R., Leonardis A., Matas J., Porikli F., Čehovin L., Nebehay G., Fernandez G., Vojíř T., Gatt A., Khajenezhad A., Salahledin A., Soltani-Farani A., Zarezade A., Petrosino A., Milton A., Bozorgtabar B., Li B., Chan C. S., Heng C.,\n--- Страница 426 ---\nЛитературные источники  425 Ward D., Kearney D., Monekosso D., Karaimer H. C., Rabiee H. R., Zhu J., Gao J., Xiao J., Zhang J., Xing J., Huang K., Lebeda K., Cao L., Maresca M. E., Lim M. K., EL - Helw M., Felsberg M., Remagnino P., Bowden R., Goecke R., Stolkin R., Lim S. Y. Y., Maher S., Poullot S., Wong S., Satoh S., Chen W., Hu W., Zhang X., Li Y., Niu Z., 2013. The visual object tracking VOT2013 challenge results. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 98–111. Kristan M., Pflugfelder R., Leonardis A., Matas J., Čehovin L., Nebehay G., Vojíř T., Fernández G., Lukežič A., Dimitriev A., Petrosino A., Saffari A., Li B., Han B., Heng C. K., Garcia C., Pangeršič D., Häger G., Khan F. S., Oven F., Possegger H., Bischof H., Nam H., Zhu J., Li J. J., Choi J. Y., Choi J. W., Henriques J. F., van de Weijer J., Batista J., Lebeda K., Öfjäll K., Yi K. M., Qin L., Wen L., Maresca M. E., Danelljan M., Felsberg M., Cheng M. M., Torr P., Huang Q., Bowden R., Hare S., Lim S. Y. Y., Hong S., Liao S., Hadfield S., Li S. Z., Duffner S., Golodetz S., Mauth- ner T., Vineet V., Lin W., Li Y., Qi Y., Lei Z., Niu Z. H., 2015a. The visual object tracking VOT2014 challenge results, vol. 8926. Kristan M., Matas J., Leonardis A., Felsberg M., Čehovin L., Fernández G., Vojíř T., Häger G., Nebehay G., Pflugfelder R., Gupta A., Bibi A., Lukežič A., Garcia-Mar- tin A., Saffari A., Petrosino A., Montero A., Varfolomieiev A., Baskurt A., Zhao B., Ghanem B., Martinez B., Lee B., Han B., Wang C., Garcia C., Zhang C., Schmid C., Tao D., Kim D., Huang D., Prokhorov D., Du D., Yeung D.-Y., Ribeiro E., Khan F., Porikli F., Bunyak F., Zhu G., Seetharaman G., Kieritz H., Yau H., Li H., Qi H., Bischof H., Possegger H., Lee H., Nam H., Bogun I., Jeong J.-C., Cho J.-I., Lee J. Y., Zhu J., Shi J., Li J., Jia J., Feng J., Gao J., Choi J., Kim J.-W., Lang J., Martinez J., Choi J., Xing J., Xue K., Palaniappan K., Lebeda K., Alahari K., Gao K., Yun K.,Wong K., Luo L., Ma L., Ke L., Wen L., Bertinetto L., Pootschi M., Maresca M., Danell- jan M., Wen M., Zhang M., Arens M., Valstar M., Tang M., Chang M.-C., Khan M., Fan N.,Wang N., Miksik O., Torr P.,Wang Q., Martin-Nieto R., Pelapur R., Bow- den R., Laganière R., Moujtahid S., Hare S., Hadfield S., Lyu S., Li S., Zhu S.-C., Becker S., Duffner S., Hicks S., Golodetz S., Choi S., Wu T., Mauthner T., Prid- more T., Hu W., Hübner W., Wang X., Li X., Shi X., Zhao X., Mei X., Shizeng Y., Hua Y., Li Y., Lu Y., Li Y., Chen Z., Huang Z., Chen Z., Zhang Z., He Z., Hong Z., 2015b. The visual object tracking VOT2015 challenge results. In: Proceedings of the IEEE International Conference on Computer Vision, vol. 2015-Febru. Kristan M., Leonardis A., Matas J., Felsberg M., Pflugfelder R., Čehovin L., Vojíř T., Häger G., Lukežič A., Fernández G., Gupta A., Petrosino A., Memarmoghadam A., Martin A. G., Montero A. S., Vedaldi A., Robinson A., Ma A. J., Varfolomieiev A., Alatan A., Erdem A., Ghanem B., Liu B., Han B., Martinez B., Chang C. M., Xu C., Sun C., Kim D., Chen D., Du D., Mishra D., Yeung D. Y., Gundogdu E., Erdem E., Khan F., Porikli F., Zhao F., Bunyak F., Battistone F., Zhu G., Roffo G., Sai Subrah- manyam G. R., Bastos G., Seetharaman G., Medeiros H., Li H., Qi H., Bischof H., Possegger H., Lu H., Lee H., Nam H., Chang H. J., Drummond I., Valmadre J., Jeong J. C., Cho J. I., Lee J. Y., Zhu J., Feng J., Gao J., Choi J. Y., Xiao J., Kim J. W., Jeong J., Henriques J. F., Lang J., Choi J., Martinez J. M., Xing J., Gao J., Palaniap- pan K., Lebeda K., Gao K., Mikolajczyk K., Qin L.,Wang L., Wen L., Bertinetto L., Rapuru M. K., Poostchi M., Maresca M., Danelljan M., Mueller M., Zhang M., Arens M., Valstar M., Tang M., Baek M., Khan M. H., Wang N., Fan N., Al-Shaka- rji N., Miksik O., Akin O., Moallem P., Senna P., Torr P. H., Yuen P. C., Huang Q.,\n--- Страница 427 ---\n426  Визуальное отслеживание движущихся объектов Nieto R. M., Pelapur R., Bowden R., Laganière R., Stolkin R.,Walsh R., Krah S. B., Li S., Zhang S., Yao S., Hadfield S., Melzi S., Lyu S., Li S., Becker S., Golodetz S., Kakanuru S., Choi S., Hu T., Mauthner T., Zhang T., Pridmore T., Santopietro V., Hu W., Li W., Hübner W., Lan X., Wang X., Li X., Li Y., Demiris Y., Wang Y., Qi Y., Yuan Z., Cai Z., Xu Z., He Z., Chi Z., 2016. The visual object tracking VOT2016 challenge results. LNCS, vol. 9914. Kristan, M., Matas, J., Leonardis, A., Vojir, T., Pflugfelder, R., Fernandez, G., Nebehay, G., Porikli, F., C ehovin, L., 2016b. A novel performance evaluation methodology for single-target trackers. IEEE Transactions on Pattern Analysis and Machine Intelligence. Kristan M., Leonardis A., Matas J., Felsberg M., Pflugfelder R., Zajc L., Vojíř T., Häger G., Lukežič A., Eldesokey A., Fernández G., García-Martín Á., Muhic A., Petrosino A., Memarmoghadam A., Vedaldi A., Manzanera A., Tran A., Alatan A., Mocanu B., Chen B., Huang C., Xu C., Sun C., Du D., Zhang D., Du D., Mishra D., Gundogdu E., Velasco-Salido E., Khan F., Battistone F., Subrahmanyam G., Bhat G., Huang G., Bastos G., Seetharaman G., Zhang H., Li H., Lu H., Drummond I., Val- madre J., Jeong J.-C., Cho J.-I., Lee J.-Y., Noskova J., Zhu J., Gao J., Liu J., Kim J.-W., Henriques J.,Martínez J., Zhuang J., Xing J., Gao J., Chen K., Palaniappan K., Lebe da K., Gao K., Kitani K., Zhang L., Wang L., Yang L., Wen L., Bertinetto L., Poostchi M., Danelljan M., Mueller M., Zhang M., Yang M.-H., Xie N.,Wang N., Miksik O., Moallem P., Pallavi Venugopal M., Senna P., Torr P., Wang Q., Yu Q., Huang Q., Martín-Nieto R., Bowden R., Liu R. Tapu, R. Hadfield S., Lyu S., Golo- detz S., Choi S., Zhang T., Zaharia T., Santopietro V., Zou W., Hu W., Tao W., Li W., Zhou W., Yu X., Bian X., Li Y., Xing Y., Fan Y., Zhu Z., Zhang Z., He Z. , 2017. The visual object tracking VOT2017 challenge results. In: Proceedings – 2017 IEEE International Conference on Computer Vision Workshops, ICCVW 2017, vol. 2018-Janua. Kristan M., Leonardis A., Matas J., Felsberg M., Pflugfelder R., Zajc L., Vojíř T., Bhat G., Lukežič A., Eldesokey A., Fernández G., García-Martín Á., Iglesias- Arias Á., Alatan A., González-García A., Petrosino A., Memarmoghadam A., Ve- daldi A., Muhič A., He A., Smeulders A., Perera A., Li B., Chen B., Kim C., Xu C., Xiong C., Tian C., Luo C., Sun C., Hao C., Kim D.,Mishra D., Chen D.,Wang D.,Wee D., Gavves E., Gundogdu E., Velasco-Salido E., Khan F., Yang F., Zhao F., Li F., Bat - tistone F., De Ath G., Subrahmanyam G., Bastos G., Ling H., Galoogahi H., Lee H., Li H., Zhao H., Fan H., Zhang H., Possegger H., Li H., Lu H., Zhi H., Li H., Lee H., Chang H., Drummond I., Valmadre J., Martin J., Chahl J., Choi J., Li J.,Wang J., Qi J., Sung J., Johnander J., Henriques J., Choi J., van de Weijer J., Herranz J., Martínez J., Kittler J., Zhuang J., Gao J., Grm K., Zhang L., Wang L., Yang L., Rout L., Si L., Bertinetto L., Chu L., Che M., Maresca M., Danelljan M., Yang M.-H., Abdelpakey M., Shehata M., Kang M., Lee N.,Wang N., Miksik O., Moallem P., Vicente-Moñivar P., Senna P., Li P., Torr P., Raju P., Ruihe Q., Wang Q., Zhou Q., Guo Q., Martín-Nieto R., Gorthi R., Tao R., Bowden R., Everson R., Wang R., Yun S., Choi S., Vivas S., Bai S., Huang S., Wu S., Hadfield S.,Wang S., Golodetz S., Ming T., Xu T., Zhang T., Fischer T., Santopietro V., Štruc V., Wei W., Zuo W., Feng W., Wu W., Zou W., Hu W., Zhou W., Zeng W., Zhang X., Wu X., Wu X.-J., Tian X., Li Y., Lu Y., Law Y.,Wu Y., Demiris Y., Yang Y., Jiao Y., Li Y., Zhang Y., Sun Y., Zhang Z., Zhu Z., Feng Z.-H., Wang Z., He Z., 2019. The sixth visual object track - ing VOT2018 challenge results. LNCS, vol. 11129.\n--- Страница 428 ---\nЛитературные источники  427 Kristan M., Matas J., Leonardis A., Felsberg M., Pflugfelder R., Kämäräinen J.-K., Zajc L., Drbohlav O., Lukezic A., Berg A., Eldesokey A., Kapyla J., Fernández G., Gonzalez-Garcia A., Memarmoghadam A., Lu A., He A., Varfolomieiev A., Chan A., Tripathi A., Smeulders A., Pedasingu B., Chen B., Zhang B., Baoyuanwu B., Li B., He B., Yan B., Bai B., Li B., Li B., Kim B., Ma C., Fang C., Qian C., Chen C., Li C., Zhang C., Tsai C.-Y., Luo C., Micheloni C., Zhang C., Tao D., Gupta D., Song D., Wang D., Gavves E., Yi E., Khan F., Zhang F., Wang F., Zhao F., De Ath G., Bhat G., Chen G., Wang G., Li G., Cevikalp H., Du H., Zhao H., Saribas H., Jung H., Bai H., Yu H., Peng H., Lu H., Li H., Li J., Li J., Fu J., Chen J., Gao J., Zhao J., Tang J., Li J., Wu J., Liu J., Wang J., Qi J., Zhang J., Tsotsos J., Lee J., Van De Weijer J., Kittler J., Ha Lee J., Zhuang J., Zhang K., Wang K., Dai K., Chen L., Liu L., Guo L., Zhang L., Wang L., Wang L., Zhang L., Wang L., Zhou L., Zheng L., Rout L., Van Gool L., Bertinetto L., Danelljan M., Dunnhofer M., Ni M., Kim M., Tang M., Yang M.-H., Paluru N., Martinel N., Xu P., Zhang P., Zheng P., Zhang P., Torr P., Wang Q., Guo Q., Timofte R., Gorthi R., Everson R., Han R., Zhang R., You S., Zhao S.-C., Zhao S., Li S., Li S., Ge S., Bai S., Guan S., Xing T., Xu T., Yang T., Zhang T., Vo- jír T., Feng W., Hu W., Wang W., Tang W., Zeng W., Liu W., Chen X., Qiu X., Bai X., Wu X.-J., Yang X., Chen X., Li X., Sun X., Chen X., Tian X., Tang X., Zhu X. F., Huang Y., Chen Y., Lian Y., Gu Y., Liu Y., Chen Y., Zhang Y., Xu Y., Wang Y., Li Y., Zhou Y., Dong Y., Xu Y., Zhang Y., Li Y., Luo Z., Zhang Z., Feng Z.-H., He Z., Song Z., Chen Z., Zhang Z., Wu Z., Xiong Z., Huang Z., Teng Z., Ni Z., 2019b. The seventh visual object tracking VOT2019 challenge results. In: Proceedings – 2019 International Conference on Computer VisionWorkshop, ICCVW 2019. Kristan M., Leonardis A., Matas J., Felsberg M., Pflugfelder R., Kamarainen J.-K., Zajc L. C., Danelljan M., Lukezic A., Drbohlav O., He L., Zhang Y., Yan S., Yang J., Fernandez G., et al., 2020. The eighth visual object tracking VOT2020 challenge results. Lowe D. G., 2004. Distinctive image features from scale-invariant keypoints. In- ternational Journal of Computer Vision 60 (2), 91–110. Lucas B. D., Kanade T., 1981. An iterative image registration technique with an application to stereo vision. In: Proceedings of International Joint Conference on Artificial Intelligence. Lukežic A., Zajc L. C., Kristan M., 2018. Fast Spatially Regularized Correlation Filter Tracker. Matthews L., Ishikawa T., Baker S., 2004. The template update problem. IEEE Transactions on Pattern Analysis and Machine Intelligence 26 (6), 810–815. Neumann U., Park J., 1998. Extendible object-centric tracking for augmented real- ity. In: Proceedings. IEEE 1998 Virtual Reality Annual International Symposium (Cat. No. 98CB36180), pp. 148–155. Neumann U., You S., Cho Y., Lee J., Park J., 1999. Augmented reality tracking in natural environments. In: International Symposium on Mixed Realities. Perazzi F., Pont-Tuset J., McWilliams B., Van Gool L., Gross M., Sorkine-Hornung A., 2016. A benchmark dataset and evaluation methodology for video object seg- mentation. In: Computer Vision and Pattern Recognition. Perazzi F., Khoreva A., Benenson R., Schiele B., Sorkine-Hornung A., 2017. Learn- ing video object segmentation from static images. In: Proceedings – 30th\n--- Страница 429 ---\n428  Визуальное отслеживание движущихся объектов IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, vol. 2017-Janua, pp. 3491–3500. Pietikäinen M., Zhao G., 2015. Two decades of local binary patterns: a survey. Ad- vances in Independent Component Analysis and Learning Machines abs/1612.0, 175–210. Reiter R., 1978. On ClosedWorld Data Bases. Springer US, Boston, MA, pp. 55–76. Ripley D. L., Politzer T., 2010. Vision disturbance after TBI. NeuroRehabilitation 27, 215–216. Robinson A., Lawin F. J., Danelljan M., Khan F. S., Felsberg M., 2020. Learning fast and robust target models for video object segmentation. In: Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recogni- tion, pp. 7404–7413. Shi Jianbo Tomasi , 1994. Good features to track. In: 1994 Proceedings of IEEE Con- ference on Computer Vision and Pattern Recognition, pp. 593–600. Simonyan K., Zisserman A., 2015. Very deep convolutional networks for large- scale image recognition. In: International Conference on Learning Represen- tations. Skoglund J., Felsberg M., 2006. Evaluation of subpixel tracking algorithms. LNCS, vol. 4292. Skoglund J., Felsberg M., 2007. Covariance estimation for SAD block matching. LNCS, vol. 4522. Stauffer C., Grimson W. E. L., 2000. Learning patterns of activity using real-time tracking. IEEE Transactions on Pattern Analysis and Machine Intelligence 22 (8), 747–757. Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., 2015. Going deeper with convolutions. In: Proc. Conf. Computer Vision and Pattern Recognition, pp. 1–9. Van De Weijer J., Schmid C., Verbeek J., Larlus D., 2009. Learning color names for real-world applications. IEEE Transactions on Image Processing 18 (7), 1512–1523. Vojír T., Matas J., 2017. Pixel-wise object segmentations for the VOT 2016 dataset. In: Research Reports of CMP , no. 1. Wang B., Qi Z., Chen S., 2016. Motion-based feature selection and adaptive tem- plate update strategy for robust visual tracking. In: Proceedings – 2016 3rd In- ternational Conference on Information Science and Control Engineering, ICISCE 2016, vol. 1, pp. 462–467. Wu Y., Lim J., Yang M. H., 2013. Online object tracking: a benchmark. In: Procee- dings of the IEEE Computer Society Conference on Computer Vision and Pat - tern Recognition, pp. 2411–2418. Yang L., Fan Y., Xu N. , 2019. Video instance segmentation. In: 2019 IEEE/CVF International Conference on Computer Vision (ICCV), pp. 5187–5196. Yao R., Lin G., Xia S., Zhao J., Zhou Y., 2019. Video object segmentation and track - ing: a survey. arXiv 1 (1). Zhu Z., Wang Q., Li B., Wu W., 2018. Distractor-aware Siamese networks for visual object tracking. In: Eccv 2018, pp. 1–17. arXiv:1808.06048v1 [cs.CV].\n--- Страница 430 ---\nОб авторе главы  429 об аВторе гЛаВы Майкл Фельсберг – профессор компьютерного зрения на факультете элект - роники Университета Линчепинга, Швеция. Он также является почетным профессором Инженерной школы Университета Квазулу-Натал в Дурбане, Южная Африка. Он имеет степень доктора философии Кильского университе- та, Германия (2002 г.), и степень доцента Университета Линчепинга (2005 г.). Он получил различные награды, в том числе премию Olympus (2005 г.) от DAGM и награды за лучшую работу от ICPR (2016 г.) и VISAPP (2021 г.). Его индекс Хирша в Google Scholar равен 44. Его исследовательские интересы включают, помимо визуального отслеживания объектов, сегментацию ви - деообъектов и экземпляров, обработку облака точек и эффективные методы машинного обуче ния.",
      "debug": {
        "start_page": 391,
        "end_page": 430
      }
    },
    {
      "name": "Глава 10. Длительное отслеживание объекта на основе глубокого обучения 430",
      "content": "--- Страница 431 --- (продолжение)\nГлава 10 Длительное отслеживание объекта на основе глубокого обучения Авторы главы: Эфстратиос Гаввес, Дипак Гупта, Институт информатики Амстердамского университета, Амстердам, Нидерланды Краткое содержание главы: определение задачи отслеживания видеообъектов с точки зрения машин- ного обуче ния и оптимизации; краткое изложение проблем визуального восприятия, обуче ния и техни- ческой реализации отслеживания объектов; обзор современных средств краткосрочного визуального отслеживания объектов, включая их ограничения, когда речь идет о более длинных и сложных пространственно-временных видеопотоках; введение в долгосрочное визуальное отслеживание объектов и проблему негативных последствий, связанных с распадом модели, появлением и ис - чезновением цели; описание глубоких сиамских трекеров, которые представляют современ- ное состояние визуального отслеживания объектов, особенно в длитель- ном отслеживании видеопотоков; обзор инвариантности и эквивариантности представлений с обсуждением того, как они соотносятся со средствами глубокого визуального отслежи- вания объектов. Я посвящаю эту работу моей жене Катерине, моему сыну Ясонасу, моей матери Антонии, моему брату Манолису и, конечно же, моему отцу Гавриилу, который всегда будет в наших сердцах и мыслях.\nГлава 10 Длительное отслеживание объекта на основе глубокого обучения Авторы главы: Эфстратиос Гаввес, Дипак Гупта, Институт информатики Амстердамского университета, Амстердам, Нидерланды Краткое содержание главы: определение задачи отслеживания видеообъектов с точки зрения машин- ного обуче ния и оптимизации; краткое изложение проблем визуального восприятия, обуче ния и техни- ческой реализации отслеживания объектов; обзор современных средств краткосрочного визуального отслеживания объектов, включая их ограничения, когда речь идет о более длинных и сложных пространственно-временных видеопотоках; введение в долгосрочное визуальное отслеживание объектов и проблему негативных последствий, связанных с распадом модели, появлением и ис - чезновением цели; описание глубоких сиамских трекеров, которые представляют современ- ное состояние визуального отслеживания объектов, особенно в длитель- ном отслеживании видеопотоков; обзор инвариантности и эквивариантности представлений с обсуждением того, как они соотносятся со средствами глубокого визуального отслежи- вания объектов. Я посвящаю эту работу моей жене Катерине, моему сыну Ясонасу, моей матери Антонии, моему брату Манолису и, конечно же, моему отцу Гавриилу, который всегда будет в наших сердцах и мыслях.\n--- Страница 432 ---\nВведение  431 10.1. В Ведение Глубокое обуче ние за последнее десятилетие стало причиной радикальных перемен в области компьютерного зрения, от распознавания объектов, се- мантической сегментации и реконструкции 3D-поверхности до смыслового понимания видео. Будучи одной из старейших задач компьютерного зре - ния, отслеживание видеообъектов также достигло значительного прогресса в эпоху глубокого обуче ния, хотя и с задержкой по причинам, которые мы опишем позже в этой главе. Глубокое обуче ние не только значительно по- вышает количественные показатели отслеживания объектов, но и улучша- ет точность прохождения бенчмарков. Важно отметить, что прогресс был именно качественным, что позволило перейти в отслеживании объектов от видеороликов длиной в несколько секунд, более известных как краткосроч- ное отслеживание (раздел 10.2), к видеороликам, охватывающим несколько десятков минут и относящимся к длительному отслеживанию (раздел 10.3). Визуальное отслеживание объекта в его наиболее общей форме можно описать как обуче ние модели fϕ с параметрами ϕ, которая пытается пред- сказать будущее местоположение цели отслеживания с учетом ее известного начального положения, то есть fϕ : 𝒴 1 × 𝒳1 × 𝒳t ® 𝒴t. (10.1) 𝒴t обозначает пространство всех возможных прогнозов, будь то в форме ограничивающей рамки или маски сегментации. 𝒳t обозначает пространство всех возможных входных кадров в момент t. Единственная исходная инфор- мация, известная модели, – это расположение объекта на первом кадре. Часто модели трекеров используют свои собственные промежуточные прог нозы yi, i < t, для обновления параметров модели ϕ. В этом случае па- раметры модели также изменяются во времени и лучше представлены с по- мощью ϕt. Однако, как мы поясним позже, важно помнить, что даже если промежуточные прогнозы yi используются в качестве целевых переменных для обновления моделей с по мощью алгоритмов обуче ния с учителем, эти переменные не совпадают с истинным местоположением объекта: y i ≠ yi*. При оптимизации любого средства визуального отслеживания объек - тов наиболее часто исходят из критерия минимизации эмпирического риска. В частности, функция потерь определяется соответствующей моделью вы- бора ℒ = ℒ(ϕt; x1:t, y1*, y1:t–1), (10.2) минимизированной с по мощью (стохастического) градиентного спуска или его вариантов, (10.3) При необходимости функция потерь дополняется функцией регуляриза- ции Ω(ϕ), которая штрафует веса в соответствии с заранее определенными\n--- Страница 433 ---\n432  Длительное отслеживание объекта на основе глубокого обучения принципами архитектуры модели, например штрафуя переобучение или неразреженные решения. Хотя фундаментальные принципы работы трекеров неизменны, в по- следнее время трекеры делятся на краткосрочные и долгосрочные. Согласно каноническому определению в (Kristan et al., 2016), краткосрочное отсле- живание не требует применения методов повторного обнаружения цели. То есть предполагается, что целевой объект не исчезает из кадра и не появ- ляется снова. Напротив, при длительном визуальном сопровождении объ- екта целевой объект может исчезнуть и снова появиться в кадре в любой момент. Возможно, что более важно, длительное отслеживание связано со сложными и длинными видео, где объект может претерпевать серьезные искажения внешнего вида. Это могут быть изменения самого объекта, когда ракурс обзора целевого объекта постоянно и сильно меняется, приводя к из- менению внешнего вида объекта в кадре, притом что трекер имеет в своем распоряжении только внешний вид цели в начальный момент времени. Эти искажения также могут быть вызваны изменениями в окружающей среде, например в способе освещения сцены или из-за окклюзии (частичного за- слонения) другими объектами в сцене. Аналогичные помехи, естественно, проявляются и при краткосрочном отслеживании, и на первый взгляд их устранение выглядит как прямое расширение методики на более длинные видео. Однако, как мы покажем далее, эти возмущения имеют косвенные по - следствия, которые уникальны для длительного отслеживания просто из-за большей продолжительности, часто являются накопительными и могут даже оказаться катастрофическими для рассматриваемых моделей. 10.1.1. Трудности отслеживания видеообъектов На первый взгляд визуальное отслеживание объекта кажется довольно прос - той задачей. В конце концов, люди с легкостью непрерывно следят за объ- ектом, независимо от его типовой принадлежности, внешнего вида и ситуа- ций, в которых он появляется. На самом деле отслеживание – одна из самых сложных задач компьютерного зрения и прикладного машинного обуче ния. Во многом это связано с тем, что отслеживание представляет собой задачу с крайне размытыми условиями: в общем случае почти не существует огра- ничений на типы объектов или вариации сцен на протяжении видео. Далее мы определяем и описываем три типа проблем визуального отслежи- вания объектов: видовые, обучающие и технические. Важно подчеркнуть, что эти проблемы редко – если вообще когда-либо – встречаются по отдельности. 10.1.1.1. Видовые проблемы отслеживания Мы выделяем два типа видовых проблем отслеживания: внутренние , вы - званные изменениями самого целевого объекта, и внешние, вызванные из- менениями в среде отслеживания. Начнем с внутренних видовых проблем. Обширные исследования (Smeul- ders et al., 2014; Wu et al., 2015) позволили составить перечень изменений,\n--- Страница 434 ---\nВведение  433 характерных для объекта: изменение масштаба, деформация, вращение в плос - кости кадра и вращение вне плоскости. Масштаб меняется либо при измене- нии размера объекта, либо при изменении расстояния между объектом и ка- мерой. Деформация обычно наблюдается, когда целевой объект не является жестким и со временем меняет форму. Вращение в плоскости кадра – это по- вороты либо целевого объекта, либо камеры в плоскости, перпендикулярной оси между камерой и целевым объектом. Примером вращения в плоскости кадра является запись пешеходов с высоты птичьего полета, например с дро- на, когда пешеходы меняют направление. Напротив, вращения вне плоско- сти – это все остальные вращения, происходящие в трехмерном простран- стве, например при отслеживании танцующего человека. К изменениям, вызванным окружающей средой, мы относим изменение освещения, окклюзию, исчезновение и повторное появление цели и изменение фона. Мы говорим об изменении освещения, когда освещенность цели ме- няется на протяжении всей последовательности видеокадров, что может привести к существенному изменению внешнего вида объекта и, возможно, даже его видимого цвета. Например, внешний вид автомобиля, ехавшего по дороге, а затем нырнувшего в туннель, существенно изменится из-за уменьшения контраста видеокадров и цвета фонарей освещения. Частичная или полная окклюзия вызвана другими объектами в сцене, которые могут быть движущимися или статичными. Интересно, что окклюзия – это особая разновидность изменений, потому что она связана с отсутствием инфор- мации и не может быть легко изучена в явном виде. Подобно окклюзии, ис - чезновение и повторное появление цели происходят, когда цель выходит из кадра и снова становится видимой в случайной точке в будущем, возможно даже с разными точками выхода и входа, например когда автомобиль по- кидает кадр с левой стороны и снова появляется справа. Хотя алгоритмы краткосрочного отслеживания часто предполагают отсутствие исчезновения и повторного появления цели (Kristan et al., 2016), при длительном отслежи- вании такое предположение сделать нельзя. Наконец, отдельной проблемой является изменение фона, потому что со статистической точки зрения оно несет в себе риск обнаружения случайных визуальных паттернов, которые можно временно спутать с паттернами целевого объекта. Это может быть особенно проблематично в случае моделей, которые рассчитаны на интен- сивное обновление. 10.1.1.2. Проблемы машинного обучения при отслеживании В общем случае визуальное отслеживание объектов не накладывает никаких ограничений на типы или внешний вид объектов. Одно видео может быть о машине, путешествующей по шоссе, а другое – о поведении осьминога, который деформируется любым мыслимым образом. Если на видео пред- ставлен процесс медицинского обследования, отслеживаемый объект может даже не иметь обычного внешнего вида, формы или характерных движений, присущих обычным объектам. В принципе, модель трекера должна иметь возможность отслеживать все эти объекты на протяжении всей последова- тельности без каких-либо дополнительных указаний, кроме определения\n--- Страница 435 ---\n434  Длительное отслеживание объекта на основе глубокого обучения цели пользователем в первом кадре. Это подводит нас к следующей проблеме обуче ния: в отличие от стандартных задач машинного обуче ния, таких как классификация, обнаружение или сегментация объектов, при визуальном отслеживании объектов моделируемые целевые объекты являются произ- вольными и не могут быть определены заранее. То есть при визуальном отслеживании объекта у нас не может быть обучающих образцов отслежива- емого объекта, поскольку тогда это будет уже не отслеживание, а обнаруже- ние объекта. В этом заключается принципиальное отличие от большинства задач машинного обуче ния, где обычно есть обучающие и тестовые наборы, содержащие разные образцы данных из одних и тех же категорий объектов. С другой стороны, визуальное отслеживание объектов сродни популярным в последнее время парадигмам обуче ния за несколько шагов и за один про- ход (Bertinetto et al., 2016), которые являются одними из самых сложных вариантов машинного обуче ния. Визуальное отслеживание объектов в основном моделируется с по мощью методологий обуче ния с учителем. Однако из-за принципиального отсут - ствия достаточного количества положительных образцов для обуче ния на- дежных обобщающих моделей обычные трекеры полагаются на извлечение данных из первого кадра и обновление модели в последующих кадрах. Чтобы модель могла дообучаться на собственных прогнозах, приходится считать их псевдоположительными, что постепенно приводит к увеличению смещения модели трекера. Мы обсудим устаревание модели (model decay) более подроб- но позже в этой главе, так как это, пожалуй, самая сложная проблема, когда речь идет о долгосрочном отслеживании объекта. Визуальное отслеживание – это не только локализация целевого объек - та, но и отделение его от фона. Однако сцены, в которых появляются объ- екты, могут резко меняться на протяжении видео. Ситуацию значительно усложняет наличие нескольких объектов с похожим или даже идентичным внешним видом, например при отслеживании конкретного спортсмена во время футбольного матча или человека в марширующем оркестре. Во время отслеживания фон может сильно отличаться от одной последовательности к другой и еще сильнее меняться с течением времени. Это подводит нас ко второй проблеме обуче ния: при визуальном отслеживании объектов модель должна научиться моделировать положительные образцы, то есть целевой объект, и игнорировать отрицательные образцы, то есть фон (Bhat et al., 2019). Фон может существенно отличаться от того, что наблюдалось в преды- дущих видео. Фактически фон может постоянно меняться с течением вре- мени в пределах одного видео и сильно отвлекать модель или даже сбивать ее с толку. В этом смысле визуальное отслеживание объектов также похоже на обнаружение аномалий, когда модель машинного обуче ния подвергается воздействию преимущественно или исключительно положительных при- меров и должна научиться отличать их от всех других возможных отрица- тельных примеров. Наконец, критической проблемой обуче ния является настройка гиперпа- раметров. В отличие от других задач компьютерного зрения и машинного обуче ния, отслеживание визуального объекта часто относится к сценариям, в которых входные данные нестационарны и недоступны заранее. В резуль-\n--- Страница 436 ---\nКраткосрочное визуальное отслеживание объекта  435 тате гиперпараметры, оптимальные для одного видео, могут оказаться со- вершенно неоптимальными для других. На практике часто случается так, что при небольших изменениях в модели трекера точность отслеживания улучшается в одних видео, но падает в других. Выбор подходящего типа мо- дели и настройка ее гиперпараметров часто имеют решающее значение для робастности и обобщающей способности. 10.1.1.3. Технические проблемы при отслеживании Помимо проблем, связанных с внешним видом цели и фона, а также с моде- лями машинного обуче ния, при визуальном отслеживании объектов сущест - вуют технические проблемы, связанные со способом записи видеоряда или устройством модели трекера. Техническая проблема, которая часто приводит к сбою трекера, – это быст - рое движение, когда скорость целевого объекта выше, чем частота кадров. Быстрое движение чаще всего доставляет проблемы моделям трекеров, ко- торые полагаются на ограничение радиуса поиска вокруг своих предыду - щих прогнозов. Как правило, радиус поиска берется достаточно большим в соответствии с ожиданиями, основанными на имеющихся видеороликах. Однако целевой объект может двигаться настолько быстро, что в следующем кадре окажется за пределами радиуса поиска. В этом случае трекер просто потеряет объект независимо от того, насколько точна его модель. Сбой из- за быстрого движения может быть особенно проблематичным для моделей, которые выполняют частые обновления, поскольку они будут использовать де-факто ошибочно классифицированные исправления для обновления мо- дели трекера. Еще одна проблема, связанная с быстрым движением цели, – размытие изображения при движении. Когда целевой объект движется очень быстро, матрица камеры получает изображения нескольких положений целевого объекта в течение одного кадра. Это приводит к эффекту усреднения, кото- рый размывает изображение и, что очень важно, сильно искажает внешний вид цели. В результате модель трекера, скорее всего, не захватит цель, потому что некоторые высокочастотные детали, необходимые для точного представ- ления целевого объекта, внезапно исчезнут. В последние годы разработчики моделей визуального отслеживания объ- ектов пытались решить вышеупомянутые проблемы с по мощью глубоких нейронных сетей и больших обучающих наборов. Далее мы рассмотрим ос - новные подходы к глубокому обуче нию таких моделей. 10.2. К ратКосро Чное Визуа Льное отсЛежи Вание объе Кта Прежде чем обсуждать появившиеся относительно недавно модели длитель- ного отслеживания, мы сначала дадим краткое введение в краткосрочное отслеживание, которое долгое время было преобладающей парадигмой. Ме-\n--- Страница 437 ---\n436  Длительное отслеживание объекта на основе глубокого обучения тоды краткосрочного отслеживания в первую очередь сосредоточены на ви- зуальных экземплярах коротких эпизодов, обычно продолжительностью от 10 до 20 секунд. Основная задача краткосрочного отслеживания заключается в том, чтобы определять местонахождение цели с максимальной точностью как можно дольше, пока цель не будет потеряна. Как правило, краткосрочные трекеры не обладают механизмом восстановления, который может отследить цель после того, как она была потеряна, в основном из соображений вычис - лительной эффективности. Краткосрочные трекеры оцениваются в основном по двум критериям: (1) точность определения координат цели и (2) быстродействие вывода. Общее мнение (Kristan et al., 2017) состоит в том, чтобы оценивать кратко- срочные трекеры с упором либо исключительно на их точность, либо на точ- ность с учетом быстродействия в реальном времени, и в этом случае скорость логического вывода должна соответствовать минимальному порогу. Такое ограничение зависит от конструкции оборудования и может варьироваться в зависимости от различных протоколов тестирования. Для случаев, когда отслеживание в реальном времени не является обязательным, существует несколько вариантов краткосрочного отслеживания, включая отслеживание только изображений RGB (Smeulders et al., 2014), использование изображе- ний RGB-D (Zheng et al., 2017) или даже данные RGB, дополненные изобра- жением с тепловизора (Li et al., 2019). С методологической точки зрения существует несколько различных спо- собов классификации методов краткосрочного отслеживания. Ввиду револю- ции, вызванной глубоким обуче нием, и того факта, что большинство совре- менных трекеров в настоящее время так или иначе полагаются на глубокую нейронную архитектуру, мы разделим трекеры на два семейства: неглубокие и глубокие. Категоризация неглубоких трекеров основана на основополага- ющей обзорной статье в (Smeulders et al., 2014). 10.2.1. Неглубокие трекеры Неглубокие трекеры (shallow tracker) включают в себя большинство методов отслеживания, основанных на стандартных технологиях компьютерного зре- ния до появления глубокого обуче ния, которые перечислены далее. Отслеживание путем поиска максимального подобия. Эта группа моделей определяет местоположение цели путем поиска максимального подобия1 шаблона, построенного на основе предыдущих кадров, с различными об- ластями-кандидатами искомого изображения. В эту категорию попадают несколько первых трекеров, использующих традиционные методы компью- терного зрения. К ним относятся методы, основанные на сопоставлении нормализованной взаимной корреляции (normalized cross-correlation, NCC) (Briechle, Hanebeck, 2001), трекер Лукаса–Канаде (KLT) (Baker, Matthews, 2004), трекер Калмана (Kalman appearance tracker, KAT) (Nguyen, Smeulders, 2004), 1 Далее для краткости мы будем называть поиск максимального подобия (similarity matching) просто сопоставлением. – Прим. перев.\n--- Страница 438 ---\nКраткосрочное визуальное отслеживание объекта  437 отслеживание среднего сдвига (mean-shift tracker, MST) (Comaniciu et al., 2000) и метод локально неупорядоченного отслеживания (locally orderless tracking, LOT) (Oron et al., 2015). Эти методы различаются в основном способами отбо- ра областей-кандидатов и сопоставления с изображением шаблона. Напри- мер, NCC использует для сопоставления значения интенсивности в шаблоне и выполняет однородную выборку по искомому изображению. Отслеживание путем сопоставления с расширенными моделями внешнего вида. Идея этого класса трекеров состоит в построении расширенной модели внешнего вида цели по предыдущим кадрам. Как правило, такие модели ра- ботают медленно, особенно потому, что в каждом кадре образцы-кандидаты сопоставляются с изображением шаблона, а также с кадрами, хранящимися в модели внешнего вида. Примером этого подхода является инкрементное визуальное отслеживание (incremental visual tracking, IVT) (Ross et al., 2008), где собственные изображения цели вычисляются с по мощью инкрементного PCA по шаблону значения интенсивности цели. Они хранятся в «утекающей» памяти, где старые образы медленно забываются. Другими примерами этой группы являются отслеживание по аффинной группе (TAG) (Kwon et al., 2009) и отслеживание выборочных трекеров (TST) (Kwon and Lee, 2011). Отслеживание путем сопоставления с ограничениями. Эта категория тре- керов сокращает представление цели до разреженного представления. Для определения подходящей выборки-кандидата в кадрах поиска выполняется разреженная оптимизация. Такие методы в первую очередь ориентированы на сценарии, в которых внешний вид быстро меняется с течением времени и модель внешнего вида должна быстро адаптироваться. Для устранения дрейфа модели во время частых обновлений эти методы используют до- полнительные ограничения, помимо традиционного отслеживания путем сопоставления. Отслеживание с использованием дискриминативной классификации. Треке- ры этой группы предлагают иной взгляд на проблему – они строят модель, основанную на различии объекта переднего плана по сравнению с фоном. Эти методы, также называемые отслеживанием путем обнаружения, создают классификатор, чтобы отличать целевые пиксели от пикселей фона, и обнов- ляют классификатор на основе поступающих новых образцов. Старым, но популярным средством отслеживания из этой категории является средство отслеживания переднего плана и фона (Nguyen and Smeulders, 2006), в кото- ром используются векторы признаков для дифференциации целевой области на локальном фоне. Другие аналогичные методы включают отслеживание по Хафу (Godec et al., 2013) и метод отслеживания, обуче ния и обнаружения (Kalal et al., 2010). Отслеживание с использованием дискриминативной классификации с огра- ничениями. Для методов отслеживания, основанных на дискриминативной классификации, важно, чтобы выборки из цели и локального фона были правильно отобраны, иначе это может отрицательно сказаться на точно- сти трекеров. Этот класс методов интегрирует процедуру маркировки в сам процесс обуче ния. Примером такой стратегии является структурированное отслеживание вывода с ядрами (structured output tracking with kernels, STR), когда новые обучающие данные выбираются из окружения положения цели\n--- Страница 439 ---\n438  Длительное отслеживание объекта на основе глубокого обучения в предыдущем кадре. Во время обуче ния модель применяет ограничение, связанное с уверенностью в том, что выборка в исходном положении оста- ется максимальной. 10.2.2. Глубокие трекеры Трекеры на основе глубокого обуче ния, именуемые здесь глубокими трекера- ми (deep tracker), имеют много преимуществ по сравнению с их неглубокими, в основном созданными вручную аналогами. Это связано со способностью глубоких трекеров кодировать многоуровневую информацию и демонстри- ровать большую инвариантность и эквивариантность по отношению к из- менениям внешнего вида цели. Существует несколько способов классифика- ции глубоких трекеров. В некоторых публикациях их принято разделять на сиамские и дискриминативные. Далее мы воспользуемся обзорной статьей (Fiaz et al., 2019), чтобы сгруппировать различные трекеры в следующие две основные группы. 10.2.2.1. Отслеживание на основе корреляционного фильтра Методы отслеживания на основе корреляционных фильтров (correlation filter- based tracking, CFT) для ограничения вычислительной стоимости выполня- ют вычисления, связанные с идентификацией цели, в частотной области. Они основаны на парадигме отслеживания путем обнаружения, а пример построения корреляционного фильтра с глубоким обуче нием показан на рис. 10.1. Целевой патч вырезается из изображения шаблона и использует - ся для инициализации корреляционных фильтров в начале отслеживания. Для эффективного представления цели карты объектов строятся с исполь- зованием соответствующих методов извлечения. Первые методы вычис - ляли карту отклика с использованием поэлементного умножения между фильт ром адаптивного обуче ния и извлеченными признаками, а также с ис - пользованием дискретного преобразования Фурье (ДПФ). Глубокое обуче ние позволяет кодировать эти признаки таким образом, что после взаимной корреляции достоверность достигается непосредственно в пространствен- Вес 1 Вес 3 Вес 2CF1 CF3 CF2 Conv3-3Conv4-3Conv5-3 Рис. 10.1  Схематическое представление процесса обуче ния корреляционного фильтра с использованием функции кодирования CNN. Источник: Fiaz et al., 2019\n--- Страница 440 ---\nКраткосрочное визуальное отслеживание объекта  439 ной области. Максимальный показатель достоверности указывает на но- вую позицию цели. Наконец, внешний вид цели в новом предсказанном местоположении обновляется путем извлечения признаков и обновления фильтров корреляции. В публикациях по отслеживанию существуют методы CFT, основанные на различных методах, и их можно описать следующим образом. Простая корреляционная фильтрация (CFT). Основная особенность этого класса трекеров заключается в том, что они в той или иной форме исполь- зуют ядерные корреляционные фильтры. В то время как ранние неглубокие трекеры для изучения этих ядер использовали обычные признаки, такие как HOG, названия цветов и т. д., глубокие трекеры используют рекуррентные или сверточные нейросети. В работе (Ma et al., 2015) предложили первый такой трекер, в котором использовались богатые возможности свертки с ис - пользованием сверточных фильтров, как показано на рис. 10.1. Он вычисляет независимые адаптивные корреляционные фильтры для каждого признака CNN и карты откликов. К улучшенным вариантам этого метода, среди про- чих, относятся трекер на основе иерархических корреляционных признаков (Ma et al., 2015), глубокое отслеживание с хеджированием (Qi et al., 2016) и многозадачный корреляционный фильтр частиц (Zhang et al., 2017). Регуляризованная корреляционная фильтрация (R-CFT). Трекеры на основе корреляционных фильтров сталкиваются с несколькими ограничениями, такими как необходимость в одинаковых размерах фильтра и патча, чувстви- тельность обуче ния к негативным образцам и менее точные карты отклика при удалении от центра кадра. Трекеры R-CFT устраняют эту проблему за счет использования регуляризации процесса обуче ния фильтра. Например, метод пространственно регуляризованного DCF (spatially regularized DCF, SRDCF) (Danelljan et al., 2015) использует пространственную регуляризацию и во время отслеживания компонент регуляризации ослабляет фоновую ин- формацию, тем самым делая трекер менее чувствительным к окружающему шуму. Другим примером является STRCF (Li et al., 2018), который исполь- зует дополнительную временную регуляризацию в SRDCF, чтобы избежать слишком резких скачков прогнозов, и допускает только плавные переходы на траектории отслеживания. Более свежим примером этого класса явля - ется ECO (Danelljan et al., 2017), который регуляризируется путем создания меньшего набора связей для эффективного захвата целевого представления с использованием матричной факторизации. Корреляция на основе сиамской сети. Сиамская сеть объединяет два входа и дает один выход. Благодаря наличию двух подсетей она может изучать глубокие представления шаблона, а также искомого изображения. Этот класс трекеров сочетает в себе сиамские сети с CFT. Сиамские полностью сверточ- ные сети (SiamFC) (Bertinetto et al., 2016) используют сверточное представ- ление и слой корреляции для интеграции глубоких признаков, полученных из шаблона, а также из изображения-кандидата. Другими улучшенными ва- риантами таких методов являются трекеры SiamRPN (Li et al., 2018) и Siam- RPN++ (Li et al., 2019), которые повышают точность отслеживания путем сопо- ставления при помощи сетей предсказания региона. Последней улучшенной версией является трекер Discriminative Model Prediction (DiMP) (Bhat et al.,\n--- Страница 441 ---\n440  Длительное отслеживание объекта на основе глубокого обучения 2019), который постоянно адаптирует представление шаблона для изуче ния улучшенного корреляционного фильтра из предыдущих кадров. Корреляционная фильтрация на основе частей. В отличие от других CFT, эта категория трекеров изучает целевое представление по частям. Такие трекеры отслеживают по отдельности несколько частей изображения, и каждая часть может иметь свой корреляционный фильтр. Карты выходных откликов объ- единяются для создания окончательного отклика, по которому оценивается новое местоположение цели с использованием таких методов, как фильтра- ция частиц. Корреляционная фильтрация на основе слияния. Точность трекеров может быть улучшена в определенных прикладных задачах за счет присоединения информации из дополнительных предметных областей (доменов). Это может быть слияние информации видимой и тепловой частей спектра и информа- ции о глубине фокусировки из изображений или даже слияние низкоуровне- вых и высокоуровневых признаков глубокой сети. Например, метод глубокого слияния признаков (Wang et al., 2017) использует комбинацию локальной обна- руживающей сети (local detection network, LDN) и глобальной обнаруживающей сети (global detection network, GDN). LDN использует VGG-16 и объединяет информацию из разных частей сети для создания карты отклика. Если LDN не удается обнаружить цель, в дело вступает GDN, параметры которой редко обновляются. 10.2.2.2. Отслеживание на основе некорреляционных фильтров В методах отслеживания на основе некорреляционных фильтров (noncorrela- tion filter-based tracking, NCFT) не используются корреляционные фильтры, и они могут базироваться на концепциях изучения патчей, разреженности, суперпикселей, графов, сопоставления на основе частей или сиамского со- поставления. Изучение патчей. Такие трекеры независимо извлекают информацию из разных частей изображения. Большинство подобных трекеров содержат ком - бинации общих слоев и слоев, специфичных для предметной области. В то время как общие слои используют обобщенное целевое представление всех последовательностей, уровень, специфичный для предметной области, от - вечает за идентификацию цели с использованием бинарной классификации. Примерами глубоких трекеров из этой категории являются структурозависи - мые сети (structure aware network, SANet) (Fan, Ling, 2017) и сверточные сети без обуче ния (convolutional networks without training, CNT) (Zhang et al., 2016). SANet объединяет сверточные и рекуррентные признаки, используя страте- гию конкатенации с пропуском для кодирования неразреженной информа- ции. CNT применяет иерархическую структуру с двумя слоями сверточной сети прямого распространения для точного создания представления цели. Нижний уровень извлекает локальные признаки, а глобальное представле- ние цели формируется путем наложения простой ячеистой карты признаков, которая кодирует как локальную информацию, так и данные о геометриче- ском расположении.\n--- Страница 442 ---\nДолгосрочное визуальное отслеживание объекта  441 На основе сиамских сетей. Сиамские сети также использовались для не- корреляционной фильтрации. Их цель состоит в том, чтобы изучить пред- ставления, которые могут привести к сходству между заданными патчами. Как правило, шаблон и области поиска передаются в набор сверточных слоев, которые являются общими для двух подсетей сиамской модели, а глубокие признаки из этих двух подсетей затем объединяются в наборе последова- тельных полностью связанных слоев. Примерами являются SINT (Tao et al., 2016) и GOTURN (Held et al., 2016). Для более точной локализации цели вы- ходные рамки SINT уточняются с использованием четырех регрессий огра- ничивающих рамок, обученных по ограничивающей рамке исходного кадра. Сиамские трекеры, в том числе основанные на корреляции, будут подробно описаны позже, поскольку они особенно хорошо подходят для долгосрочного отслеживания. На основе графов. Методы на основе обуче ния графа, как правило, исполь- зуются для предсказания меток непомеченных вершин в графе. Некоторые современные трекеры, такие как древовидная CNN (tree structure CNN, TCNN) (Nam et al., 2016), строят пространственные или временные графы для опре- деления точных траекторий отслеживания. Существуют методы, которые используют для отслеживания как информацию, так и пространственно- временные графы. Для дальнейшего моделирования сложных отношений более высокого порядка структурозависимый трекер (Du et al., 2016) строит гиперграфы во временном измерении. Гиперграф строится с использованием частей-кандидатов в качестве узлов, а гиперребра обозначают отношения между частями. 10.3. доЛгосро Чное Визуа Льное отсЛежи Вание объе Кта Благодаря наличию стандартных наборов данных (Kristan et al., 2020; Wu et al., 2015; Smeulders et al., 2014) за последние несколько лет технология визуального отслеживания значительно продвинулась вперед. Эти наборы данных в основном были разработаны для решения проблем, возникающих при краткосрочном отслеживании. Например, средняя продолжительность видео в ALOV (Smeulders et al., 2014) и OTB (Wu et al., 2015) составляет всего около 10 и 20 секунд соответственно. Назначение этих наборов данных за- ключалось в том, чтобы представить трудные моменты, такие как изменения условий освещения, резкое движение, беспорядок, большие деформации, внезапные окклюзии и др. Однако при работе с более длинными видео возникают дополнительные проблемы и требования, помимо тривиального условия, что модель должна выполнять прогнозы для более длительного времени. Ранее мы рассмотре- ли различные проблемы с отслеживанием и сгруппировали их в задачи по критериям внешнего вида, обуче ния и технических проблем. Все пробле- мы, которые существуют для краткосрочных трекеров, справедливы и для\n--- Страница 443 ---\n442  Длительное отслеживание объекта на основе глубокого обучения долгосрочных. Среди всех проблем есть две, которые занимают особое место в долгосрочном отслеживании, – это устаревание модели и исчезновение и повторное появление цели. Хотя эти две проблемы не являются уникаль- ными для длительного отслеживания, их последствия гораздо более сильно и нетривиально выражены в трекерах, которые работают с более длинными последовательностями. 10.3.1. Устаревание модели при длительном отслеживании Хорошие результаты отслеживания на тестовых наборах данных часто интер- претируют как решение всех основных проблем отслеживания. На практике, однако, возникают специфические проблемы, когда продолжительность от - слеживания превышает, допустим, полчаса. При практическом применении отслеживания длинные видео встречаются гораздо чаще, чем короткие, на- пример в различных взаимодействиях между людьми, спортивных репорта- жах, документальной съемке и телешоу. Однако слишком продолжительное обновление может в конечном итоге разрушить встроенную модель трекера и привести к потере цели. В то время как устаревание модели может быть незаметным в краткосрочных видео, накопленный эффект очень заметен при длительном отслеживании. Мы продемонстрируем это на примере синтетического эксперимента, изо- браженного на рис. 10.2. Чтобы показать серьезное влияние устаревания модели при обработке длинного видеоряда, мы случайным образом выби- раем видеоролик из набора данных OTB50 (Wu et al., 2015) и искусственно расширяем его в соответствии со следующим периодическим законом: x¢ = [x1, …, xT–1, xT, xT, xT–1, …, x2, x1, x1, x2, …, xT, …]. (10.4) Расширение видео таким способом гарантирует, что любые различия в точности отслеживания, наблюдаемые в более поздних частях длинной последовательности, будут вызваны исключительно увеличением длины видео, а не дополнительными визуальными затруднениями. На рис. 10.2 мы видим прогнозы ECO (Danelljan et al., 2017) – одного из самых успешных несиамских трекеров, который опирается на частые обновления, – для трех разных кадров, наблюдаемых в трех разных повторениях исходного видео. Мы видим, что при увеличении числа повторений фрагментов предсказания трекера со временем становятся все менее точными, хотя кадры абсолют - но идентичны. Причина в устаревании модели, вызванном постепенным, но ошибочным и интенсивным обновлением. Дрейф трекера, вызванный устареванием модели, давно известен (Smeulders et al., 2014), но в контексте краткосрочного отслеживания этот вопрос не очень актуален. При долго- срочном отслеживании устаревание модели чаще всего приводит к ката- строфическим последствиям, даже если при каждом обновлении модели допускаются всего лишь небольшие ошибки, как показано в исследовании (Gavves et al., 2020).\n--- Страница 444 ---\nДолгосрочное визуальное отслеживание объекта  443 Чтобы разработать меры борьбы с этим негативным эффектом длитель- ного отслеживания, необходимо теоретическое обоснование, способное дать математическое определение лежащему в основе данного явления ме- ханизму. Расширение 10Расширение 5Расширение 1 Расширение 10Расширение 5Расширение 1 Расширение 10Расширение 5Расширение 1 Рис. 10.2  Прогнозы трекера ECO (Danelljan et al., 2017) для искусственно расширенного видео, созданного на основе данных OTB50 (красный пря- моугольник: прогноз трекера, желтый прямоугольник: эталонный прогноз). Здесь очевидно преобладает устаревание модели, хотя вариация внешнего вида остается неизменной. Из-за большого количества обновлений устаре- вание модели заметно с самых ранних стадий, даже для четко видимых це- левых объектов, движущихся медленно. Источник: Gavves et al., 2020 Расширяя математическое определение трекеров и предполагая, что мы обновляем параметры модели в каждом кадре, мы получаем следующие уравнения: (10.5) yt+1 = f(xt+1, ϕt+1), (10.6) где f – модель трекера с параметрами ϕ, которая минимизирует потери ℒ трекера по набору данных D = [x1:t, y1:t] на такте t + 1. Набор данных состоит из кадров x1:t = [x1, …, xt], а модель трекера f возвращает в качестве выход- ных данных предсказания ограничивающей рамки y1:t = [y1, , yt]. Чтобы упростить и упорядочить обозначения, мы используем fi,t для обозначения выходных данных модели трекера с параметрами ϕt, примененной к кадру xi. В простейшем случае параметры модели обновляются путем небольших\n--- Страница 445 ---\n444  Длительное отслеживание объекта на основе глубокого обучения шагов в направлении градиента поверхности потерь, а именно с использо- ванием подхода градиентного спуска (или его вариантов): (10.7) ϕt+1 = ϕt – ηÑϕℒt. (10.8) Таким образом, центральное место в задаче обуче ния отслеживающей модели занимает градиент потерь при отслеживании, обусловленный пара- метрами модели. Продолжая на Ñϕℒ и используя математическое ожидание по t временным шагам 𝔼 [·] = имеем: Ñϕℒt = Ñϕ𝔼[(yi – fi,t)2] (10.9) = 2𝔼[ftÑϕft] – 2 𝔼[ytÑϕft]. (10.10) Чтобы перейти от уравнения (10.9)–(10.10), мы исходим из того, что ко- ординаты ограничивающей рамки yi, предсказанные в предыдущих кадрах, становятся входными переменными с постоянными значениями. Таким об- разом, они не зависят от ϕ, а 𝔼[Ñϕyi2] = 0. Это сильное предположение, учи- тывая, что на практике y i определяются моделью с параметрами ϕ . Подставляя уравнение (10.10) в (10.8), обновление параметров модели можно описать как ϕt+1 – ϕt = –2η[𝔼[fi,tÑϕfi,t] – 𝔼[yiÑϕfi,t]]. (10.11) Интересная, но часто упускаемая из виду реальность заключается в том, что хотя отслеживание рассматривается как задача обуче ния с учителем, в наборе обучающих данных есть только одна выборка данных, которая определенно верна. Эта единственная эталонная выборка – пара ( x1, y1*), определенная пользователем в первом кадре, где y1* представляет собой координаты заданной пользователем ограничивающей рамки, описыва- ющей объект. Несмотря на то что все остальные ограничивающие рамки yi > 1 используются для переобучения и тонкой настройки трекера, нет никакой гарантии, что эти рамки действительно верны или хотя бы доста- точно хороши для обуче ния. На самом деле если бы предсказания yi были гарантированно хороши для переобучения трекера, то переобучение не потребовалось бы. На основании вышеупомянутого аргумента разумно ожидать, что прог - нозы, которые также служат будущими обучающими выборками для пере- обучения трекера, являются зашумленными измерениями истинных коор- динат ограничивающей рамки yi*. Предполагая, что имеем дело с гауссовым шумом с дисперсией σ i2, мы можем записать следующее уравнение: yi = yi* + δi и δ i ~ N(0, σ i2). (10.12)\n--- Страница 446 ---\nДолгосрочное визуальное отслеживание объекта  445 Подставив уравнение (10.12) в (10.11), после перестановки членов имеем: ϕt+1 – ϕt = –2η[𝔼[fi,tÑϕ fi,t] – 𝔼[yi* + δi)Ñϕ fi,t]] (10.13) (10.14) Обновление параметров трекера состоит из двух компонентов. Первый член в уравнении (10.14) соответствует компоненту обновления идеальной модели, поскольку он исправляет ошибку, сделанную предсказанием модели fi,t по сравнению с идеальной эталонной рамкой yi*. Второй член представ- ляет собой смещение параметра, так как он напрямую зависит от ошибки, сделанной прошлыми предсказаниями δi. При δi = 0 ошибки бы не было и обновления параметров тоже были бы идеальными. Динамика модели. Вычислив влияние прошлых ошибок на обновления параметров трекера, мы можем затем исследовать влияние на динамику модели с течением времени. В частности, после обновления параметров связь между прошлой моделью f i,t и следующей f i,t+1 имеет вид: (10.15) (10.16) Поскольку комбинируя уравнения (10.16) и (10.14), полу - чаем: (10.17) Из уравнения (10.17) можно сделать следующий вывод. Из-за непрерыв- ных обновлений модель трекера корректирует свои прогнозы на величину, которая линейно пропорциональна прошлым ошибкам. Мы называем эту величину распадом модели. Длительное отслеживание и устаревание модели. Поскольку динами- ка модели в уравнении (10.17) является рекурсивной, подразумевается, что член смещения накапливается и фактически ухудшается со временем. Так как кумулятивное устаревание модели достаточно мало, обычно на ранних итерациях динамика модели является достаточно точной. Ранние ошибки δi малы не только потому, что трекер все еще точен, но и потому, что коли- чество слагаемых t мало. По этой причине устаревание модели не является проблемой и часто остается незамеченным в коротких видеороликах. Однако в более длинных видео, где t и количество слагаемых растут, ошибки δi,t также растут, и кумулятивное устаревание модели становится заметным.\n--- Страница 447 ---\n446  Длительное отслеживание объекта на основе глубокого обучения 10.3.2. Исчезновение и повторное появление цели Предполагая, что цель никогда не исчезает, краткосрочные трекеры могут всегда возвращать свой наиболее вероятный прогноз, независимо от того, является ли вероятность прогноза высокой или низкой. Поэтому обученный классификатор подобного краткосрочного трекера не требует минимальной оценки правдоподобия, прежде чем объявить, что определенное место со- держит целевой объект. В свою очередь, это означает, что обученному клас - сификатору не нужно калибровать свою достоверность. Однако в более длинных видеопоследовательностях цель, скорее всего, ис - чезнет из кадра и снова появится. Часто это случается несколько раз. Значит, любой долгосрочный трекер должен уметь моделировать отсутствие цели в кадре. Хотя это кажется небольшим отличием от краткосрочного трекера, на самом деле оно может иметь важные теоретические и практические по- следствия для моделирования. Прежде всего модель трекера должна уметь различать, почему объект стал невидимым для нее – из-за исчезновения или из-за серьезных изменений внешнего вида. Более того, если модель ис - пользует обновления для учета изменений внешнего вида объекта, функция подобия модели будет динамически изменяться со временем. Это означа- ет, что нельзя зафиксировать заданный минимальный порог обнаружения. Вместо этого порог должен быть либо определен динамически, либо модель должна откалибровать свои прогнозы таким образом, чтобы минимальный порог обнаружения оставался действительным. Наконец, при наличии долго- срочного устаревания модели динамическая адаптация порога может быть затруднена без прямого влияния на точность трекера и дополнительного смещения модели, особенно в случае последовательных обновлений. 10.3.3. Долгосрочные трекеры Долгосрочные трекеры должны не только решать общие проблемы слежения, с которыми сталкиваются краткосрочные трекеры, но и дополнительно обра- батывать долгосрочное затухание, а также исчезновение и повторное появле - ние цели. Теоретически устаревание модели неизбежно, когда к краткосроч- ным трекерам добавляется последовательное обуче ние. Решение проблемы долгосрочного устаревания привлекает наибольшее внимание из-за ее фун- даментального и катастрофического характера. Мы выделяем три семейства подходов долгосрочного отслеживания, сгруппированных по типам обуче ния и обновления модели трекера с учетом долгосрочного устаревания: пред- варительное обуче ние, последовательное обуче ние и гибридное обуче ние. 10.3.3.1. Предварительное обучение и сиамские трекеры В основе всех алгоритмов отслеживания лежит модельная функция fϕ : 𝒴 1 × 𝒳 1 × 𝒳t ® 𝒴t из уравнения (10.1), согласно которой изображение цели сопостав- ляется с поступающими кадрами. Модель трекера возвращает прогнозы y1:t, которые, как мы надеемся, достаточно близки к истинным местоположени-\n--- Страница 448 ---\nДолгосрочное визуальное отслеживание объекта  447 ям y* 1:t. Идеальная функция сопоставления для отслеживания обеспечивает правильное сопоставление, даже если цель на видео частично перекрыта другими предметами, меняет свой масштаб, вращается в плоскости и вне ее или подвергается неравномерному освещению, движению камеры и другим мешающим факторам (Smeulders et al., 2014; Wu et al., 2015). Как мы упоминали ранее, для решения этих проблем с отслеживани- ем модели часто полагаются на последовательные обновления, используя прогнозы модели в качестве псевдоэталона. Это, в свою очередь, приводит к ухудшению модели, которое особенно сильно выражено в случае длин- ных и сложных видео, поскольку мы предполагаем, что прогнозы модели эквивалентны эталонным прогнозам во время обновлений: y1:(t–1) ≡ y* 1:(t–1). Этим предположением мы признаем следующий специфический парадокс, который называем парадоксом отслеживания (tracking paradox). С одной сто- роны, если модель настолько точна, что можно предположить 1:(t–1) ≡ y1:(t–1), то модель не требует дальнейшего переобучения. Другими словами, пере- обучение не дает дополнительных преимуществ, поскольку предсказания модели уже совершенны. С другой стороны, если модель не так точна, как предполагалось, принимая 1:(t–1) ≡ y1:(t–1), мы получаем только временное улучшение точности, но постепенно делаем модель все хуже и хуже и в конце концов доводим ее до полного разрушения. Чтобы разрешить парадокс, мы могли бы взять модель трекера, которая не требует обновления . В этом случае модель должна иметь возможность определять местонахождение цели просто по информации, которая была до- ступна до отслеживания, то есть только по ограничивающей рамке в первом кадре. Это явно затруднительно, так как в сложных видео существуют серьез- ные проблемы, к которым модель трекера должна быть невосприимчивой, как было сказано в разделе 10.1.1. Кроме непрерывного обновления, тради- ционный способ решения этих проблем заключается в явном моделировании каждого из вышеупомянутых искажений путем введения аффинных преоб- разований (Lucas, Kanade, 1981), вероятностного сопоставления (Comaniciu et al., 2000), собственных изображений (Ross et al. al., 2008), инвариантов освещения (Nguyen, Smeulders, 2006), обнаружения окклюзии (Pan and Hu, 2007) и т. д. К сожалению, явное моделирование отдельных проблем – при иг - норировании всех остальных – дает трекеры, которые могут быть оптималь- ными для одного типа искажений, но неоптимальными для многих других, что приводит к ухудшению точности. Вместо того чтобы явно моделировать все возможные искажения с по- мощью модели трекера f, можно представить отслеживание как проблему сопоставления изображений, где искомое изображение всегда является це- лью в первом кадре. Поскольку запрос остается фиксированным и не меня- ется из-за последовательных обновлений с использованием несовершенных прогнозов отслеживания, модель гарантированно будет работать стабильно и надежно в течение любого периода времени. Определение модели трекера приобретает следующий вид: (10.18)\n--- Страница 449 ---\n448  Длительное отслеживание объекта на основе глубокого обучения В этом определении z – участок целевого объекта в первом кадре xt[y] соответствует патчу в t-м кадре, который, в свою очередь, соответствует ко- ординатам ограничивающей рамки y, hϕ – сверточные нейронные сети, вы- числяющие представления из z и xt[y], а f – функция поиска максимального подобия трекера. Каких-либо ограничений по типу сетей hϕ нет, хотя на прак - тике одни сети работают лучше других (Tao et al., 2016; Li et al., 2019). Хотя для простоты мы используем одни и те же параметры ϕ для обеих нейронных сетей, параметры не обязательно должны быть общими (Li et al., 2019). В случае отслеживания путем поиска максимального подобия (сопоставле- ния) целей критическим компонентом модели является функция сопостав- ления, которая должна быть устойчива ко всем нежелательным проблемам отслеживания. Традиционно эта функция сопоставления обучается в после- довательном режиме применительно к конкретной цели z. Альтернативой является внешнее обуче ние функции сопоставления в автономном режиме, в частности путем сравнения появлений объектов, записанных в разные мо- менты времени, то есть (x i, xj, y* ij), где y* ij = 1, если xi и xj представляют тот же объект, и –1 в противном случае. Функция сопоставления f может быть реали- зована с по мощью многослойного персептрона (полностью связанный слой) и обучена для минимизации контрастных потерь (Tao et al., 2016): , (10.19) dij = ||hϕ(xi) – hϕ(xj)||2, (10.20) или с использованием косинусного подобия для минимизации логистиче- ских потерь (Bertinetto et al., 2016): (10.21) По сути, для обеих потерь расстояния, будь то евклидова норма или коси- нусное подобие, являются внутренними произведениями. Учитывая, что при минимизации поиска в уравнении (10.18) мы перебираем местоположения ограничивающей рамки, которые плотно упакованы поверх карт признаков, итерационные внутренние произведения могут быть более компактно за- писаны как свертки, то есть (10.22) Уравнение (10.22) позволяет очень эффективно использовать полностью сверточные сиамские сети (Bertinetto et al., 2016). Визуальные трекеры, которые отслеживают объекты с использованием сиамских глубоких нейронных сетей, называются сиамскими трекерами (рис. 10.3). Сиамские трекеры имеют две ветви сверточных нейронных се- тей. Первая из них – это ветвь шаблона, которая сворачивает целевой патч так, как это определено в первом кадре. Результатом является шаблон, с по- мощью которого каждый будущий кадр может быть дополнительно свернут\n--- Страница 450 ---\nДолгосрочное визуальное отслеживание объекта  449 для определения положения цели. Вторая – это ветвь кандидатов, обраба- тывающая новые кадры в видеопоследовательностях и пытающаяся найти объект, максимально подобный цели. t = 0 z xx[y]hφ hφfφ t Обученные извне h φ, fφ Рис. 10.3  Сиамский трекер состоит из двух ветвей, каждая из которых смо- делирована сверточной нейронной сетью. Первая ветвь всегда содержит патч целевого объекта в момент t = 0. Вторая ветвь анализирует любой другой кадр в видео. Затем представления двух ветвей сравниваются при помощи функции подобия. Функция подобия обучается автономно с использованием отслежива- емых объектов из разных наборов данных. Хотя эта функция не видела будущие цели, она все же может точно оценить подобие их внешнего вида для выпол- нения отслеживания путем поиска максимального подобия. Схема основана на работах Bertinetto et al. (2016); Tao et al. (2016) Область поиска. Как и в случае краткосрочных трекеров, вместо поиска цели по всему кадру можно ограничить модель поиском следующих местопо- ложений цели в пределах заданного радиуса ρ. Ограничение области поиска помогает повысить вычислительную эффективность алгоритма трекера, по- скольку он должен анализировать гораздо меньшую площадь кадра. Огра- ничение поиска определенной областью также может снизить вероятность ложных срабатываний, которые могут случайно возникнуть при просмотре всего изображения. Радиус r0 – гиперпараметр, зависящий от максимальной скорости цели. Как и в большинстве случаев, мы не можем знать максимальную скорость цели. Поэтому если мы решили задать область поиска, то должны делать это осторожно. Если скорость перемещения цели превышает r0 /Dt, где Dt – ин - тервал между любыми двумя кадрами (величина, обратная скорости запи си в кадрах в секунду), то цель окажется вне области поиска и трекер ее по- теряет. Если радиус r0 задать таким, что r0 = max(H , W), где H и W – высота и ширина кадра, то трекер будет просматривать весь кадр. При определении размера области поиска необходимо балансировать между повышением точности и ухудшением полноты отклика. Задав не- большую область поиска, можно повысить точность, избегая избыточных\n--- Страница 451 ---\n450  Длительное отслеживание объекта на основе глубокого обучения ложных срабатываний. Однако небольшая область поиска также может ухуд- шить полноту отклика, поскольку все местоположения за пределами области поиска автоматически помечаются как отрицательные; в случаях, когда цель оказалась за пределами области поиска, это будут ложноотрицательные ре- зультаты. Аналогичным образом можно привести обратные аргументы для больших областей поиска1. Преимущества сиамских трекеров. Сиамские сети имеют определенные преимущества. По большому счету, самым важным преимуществом является возможность избежать устаревания модели из-за отсутствия обновлений модели на протяжении всего видео. Причина в том, что, несмотря на ошибки прогнозирования δi, модель никогда не обновляется, поэтому Ñϕ fi,t = 0 (раз- дел 10.3.1). Разработчику модели не нужно беспокоиться о том, что модель рухнет и больше не восстановится. Это делает сиамские трекеры идеальным инструментом для долгосрочного отслеживания. Если сравнивать сиамские трекеры на сверточных нейронных сетях (Tao et al., 2016) с полностью сверточными сиамскими трекерами (Bertinetto et al., 2016b), то первые, как правило, имеют значительно более высокую точ- ность и лучшую надежность за счет более высоких вычислительных затрат. Причина в том, что сверточные нейронные сети с полностью связанными слоями могут быть предварительно интенсивно обучены на базах данных изображений, таких как ImageNet (Russakovsky et al., 2015), и, таким образом, дополняют сиамскую модель сильными априорными знаниями. Напротив, из-за отсутствия полносвязных слоев полностью сверточные нейронные сети обладают значительно более высокой эффективностью и производи- тельностью в реальном времени, но меньшей дискриминативной способно- стью (Valmadre et al., 2018). Полагаясь исключительно на предварительно обученную сквозным мето- дом функцию подобия, сиамские трекеры требуют только начального обуче- ния и не нуждаются в последовательном обучении во время работы. Это означает, что мы можем заранее выполнить автономное обуче ние, чтобы изучить любой тип инвариантов, которые понадобятся трекеру. Мы можем сделать это во время обуче ния, просто предоставив функции подобия при- меры вариантов, которые хотим сопоставить друг с другом. Более того, по- скольку обуче ние проводится в автономном режиме, мы можем использо- вать очень большие наборы данных и повышать точность без увеличения вычислительных затрат или затрат на память. Еще одним преимуществом сиамских трекеров является то, что функцию подобия можно обучить для оптимального объединения карт признаков из разных слоев. Карты признаков из разных слоев фиксируют различные типы особенностей объекта: более ранние слои фиксируют низкоуровневые гео- метрические паттерны, такие как края или углы, а более поздние фиксируют семантические паттерны высокого уровня, которые идентифицируют лица 1 Точность (precision) вычисляется как отношение числа истинных результатов к сумме истинных и ложных результатов. Полнота отклика (recall) вычисляется как отношение числа истинно положительных результатов к сумме истинно по- ложительных и ложноотрицательных результатов.\n--- Страница 452 ---\nДолгосрочное визуальное отслеживание объекта  451 или типы объектов. Следовательно, при поиске совпадения сиамские тре- керы по своей сути используют как низкоуровневую геометрическую, так и высокоуровневую семантическую информацию, что позволяет выполнять детальный поиск по новым кадрам. Это свойство особенно важно в случае вводящего в заблуждение фона, когда объекты могут выглядеть одинаково, но иметь различную семантику – такая ситуация запутывает модели, кото- рые могут использовать для устранения неоднозначности объектов данные только из одной и той же последовательности. Особенностью сиамских трекеров является то, что при отслеживании они игнорируют время, если не определена область поиска и модель ищет объект по всему кадру. Причина в том, что в алгоритме нет переменной времени: внешний вид целевого объекта задается в первом кадре, модель поиска максимального подобия обучается в автономном режиме и ис - пользуется на протяжении всего процесса отслеживания без изменений на промежуточных кадрах и прогнозах, и область поиска по каждому новому кадру также не зависит от предыдущего местоположения цели. Хотя это свойство может показаться нелогичным, оно не мешает отслеживанию, если функция подобия может почти идеально сопоставлять внешний вид разных представлений одного и того же объекта. Более того, если задать в качестве области поиска весь кадр, то даже если цель упущена в одном кадре, у модели остается возможность повторно найти местоположение цели в последующих кадрах. Ситуации, ведущие к сбою отслеживания. Популярность сиамских трекеров постоянно растет благодаря хорошей точности и замечательной устойчивости к дрейфу модели. Однако в их архитектуре кроются некоторые недостатки, которые дают о себе знать в определенных сценариях. Самый очевидный недостаток базовой архитектуры сиамских трекеров – путаница при наличии множества однотипных объектов. Эта путаница осо- бенно заметна, когда объекты не просто похожи, но идентичны, например при попытке отследить одного человека в марширующем оркестре. В то время как отследить одного конкретного человека в марширующем оркест - ре, пожалуй, сложно даже для человека, сиамский трекер по своей природе не может различать идентичные или почти идентичные объекты. Причина в том, что в простых сиамских трекерах отсутствует компонент моделиро- вания движения. Еще одной проблемой для сиамских трекеров является полное отсутствие обновлений моделей. Даже если мы предположим, что функция подобия иде- альна, бывают случаи, когда целевой объект меняет внешний вид либо сам по себе (например, пешеход меняет одежду), либо под влиянием окружающей среды (например, значительные изменения освещения, которые могут изме- нить внешний вид объекта). В этом случае функция подобия делает больший упор на форму объекта-кандидата, который должен быть в основном похож на форму исходного объекта, а также на семантику объекта, которая не меняется. Это неплохое свойство, учитывая, что сверточные нейронные сети продемон - стрировали большую способность к обобщению при распознавании объектов. Действительно, благодаря этому обобщению сиамские трекеры, такие как (Tao et al., 2016), продемонстрировали устойчивость к обычным проблемам\n--- Страница 453 ---\n452  Длительное отслеживание объекта на основе глубокого обучения отслеживания (Valmadre et al., 2018). Тем не менее это обобщение увеличивает вероятность путаницы при наличии нескольких похожих объектов. Наконец, поскольку сиамские трекеры основаны на сверточных нейрон- ных сетях, они сталкиваются с теми же проблемами, что и базовые сети. В частности, стандартные сверточные нейронные сети не являются стро- го инвариантными или эквивариантными по отношению к изменениям масштаба и поворотам, будь то повороты в плоскости или вне плоскости. Для устранения зависимости от вариаций масштаба и поворота применяют тщательное предварительное обуче ние сиамских сетей, увеличение объема данных или специальные стратегии постобработки, такие как повторение поиска в нескольких масштабах или поворотах. Эти подходы являются до- рогостоящими и работают только до тех пор, пока вариации в достаточной степени представлены в данных и их дополнениях. 10.3.4. Инвариантность и эквивариантность представления На входные данные всегда влияет шум, и, следовательно, нет двух абсолютно одинаковых точек данных. Например, никогда не бывает двух абсолютно идентичных изображений, поскольку объект мог изменить свое местополо- жение, свой внешний вид или ракурс, освещение в сцене могло стать другим и т. д. Некоторые из этих вариаций не имеют отношения к поставленной задаче прогнозирования, то есть идентификации и локализации объекта в случае визуального отслеживания. Например, не имеет значения, как объ- ект освещен и падает ли на него тень; трекер должен иметь возможность локализовать целевой объект в любом случае. Однако некоторые из этих изменений могут иметь значение. Например, изменение масштаба объекта в кадре не имеет отношения к идентификации, но может иметь значение для вывода о том, что объект движется к камере или удаляется от нее. И конечно же, понимание различных вариаций одного и того же объекта на самом деле имеет решающее значение для обобщения. Представления инвариантны к определенным изменениям, если на них не влияет наличие этих изменений. Инвариантность к освещению, например, означает, что представление будет в значительной степени одним и тем же при изменении освещения. Представления эквивариантны к определенным изменениям, когда представления меняются пропорционально изменению объекта или его среды. Говоря упрощенно, эквивариантность к вращению означает, что поворот объекта на π/4 оказывает в два раза большее влияние на его представление, чем поворот на π/8. Далее мы опишем, как современ- ные средства визуального отслеживания объектов включают инвариантность и эквивариантность в свои представления. 10.3.4.1. Инвариантность при отслеживании В сиамских трекерах функция подобия имеет первостепенное значение. При- чина в том, что трекер полагается исключительно на эту функцию, чтобы\n--- Страница 454 ---\nДолгосрочное визуальное отслеживание объекта  453 сравнить два произвольных патча и заключить, изображают ли они один и тот же целевой объект или нет, независимо от любых возможных изме- нений во внешнем виде. Однако ожидается, что во время просмотра видео объект может испытывать серьезные искажения и изменения внешнего вида. Эти помехи могут быть вызваны либо самим объектом (человек снял куртку или автомобиль встал под углом, отличным от того, который наблюдался на первом кадре), либо окружающей средой (например, перекрытие другим объектом, изменение освещения или тень от близлежащего объекта). Функ - ция подобия должна безошибочно определять, что объект остается тем же самым, несмотря на все подобные помехи. То есть функция подобия должна научиться быть инвариантной ко всем возмущениям, обычно встречающим - ся при отслеживании, как мы описали их в разделе 10.1.1. Инвариантность может быть достигнута либо путем жесткого программи- рования в коде алгоритма, либо путем изучения возможных возмущений на основе данных. В первом случае метод жестко настроен на игнорирование определенных изменений визуальных входных данных, например поворота (Gupta et al., 2021) или масштаба объекта (Sosnovik et al., 2021). Во втором случае метод наблюдает за различными вариациями больших наборов данных и учит - ся игнорировать те вариации, которые не имеют отношения к сопоставлению. Преимущество инвариантности с жестким кодированием заключается в том, что можно достичь желаемого с гораздо меньшими наборами данных. Напро- тив, инвариантность на основе обуче ния требует гораздо больших наборов дан- ных. Причина в том, что модель должна улавливать все возможные вариации внешнего вида, относящиеся к этим инвариантностям, и затем обобщать их. Жесткое программирование позволяет уменьшить размер модели, но в об- щем случае результат зависит от математической модели инвариантности. Более того, если математическая модель инвариантности не делает никаких предположений или делает лишь несколько предположений, инвариантно- сти распознаются в данных более точно. С другой стороны, инвариантности на основе обуче ния не требуют явного математического моделирования ука- занных инвариантностей. Это намного удобнее, когда смешивается несколь- ко разных изменений, что часто случается при отслеживании данных. Кроме того, поскольку не требуется явная математическая модель, инвариантные модели на основе обуче ния обычно проще, и нужно сосредоточиться только на сборе достаточно больших и разнообразных данных. Базовые сиамские трекеры (Tao et al., 2016; Bertinetto et al., 2016) исполь- зуют последний вариант и эффективно учатся на данных игнорировать ин- вариантности, которые не имеют отношения к идентификации целевого объекта. Например, после обуче ния на многочисленных образцах объектов, которые претерпели деформацию или изменения освещенности, сиамские трекеры предсказывают, изображают ли какие-либо два патча один и тот же объект или нет, если видеоряд содержит те или иные деформации либо изменения освещенности. Это означает, что для обуче ния инвариантному сопоставлению сиамским трекерам нужны масштабные и разнообразные наборы обучающих данных. Использование больших наборов данных непосредственно во время отсле- живания невозможно. Следовательно, функция сходства сиамского трекера\n--- Страница 455 ---\n454  Длительное отслеживание объекта на основе глубокого обучения должна быть обучена в автономном режиме на внешних данных. Автономный режим означает, что обуче ние не происходит одновременно с отслеживани- ем. Внешние данные означают, что обуче ние не использует целевые данные, которые пользователь определил бы в первом кадре видео, так как алгоритм трекера не может иметь доступа к таким данным. Поэтому функция подобия должна быть обучена на внешних данных и до развертывания трекера. Автономное обуче ние на внешних данных резко отличается от подхода, применяемого в большинстве традиционных трекеров, чья функция подобия обычно изучается последовательно в ходе отслеживания. Последователь- ное обуче ние трекера в рабочем режиме означает, что он использует только внешний вид цели на первом кадре (единичный положительный образец), прогнозы трекера по всему видео (псевдоположительные образцы), а также внешний вид фона (отрицательные образцы) и, возможно, другие появления объектов из разных видео (отрицательные образцы). Чтобы изучить инвариантность на основе данных, требуется большой на- бор видеороликов движущихся объектов из разных категорий. Кроме того, эти отслеживаемые объекты должны быть снабжены аннотациями с указа- нием их местоположения на протяжении всего видео. Чтобы создать набор данных, после этого нужно просто собрать все возможные комбинации пат - чей (x i, xj) в моменты времени i и j. Пары (x i, xj) должны подвергаться измене- ниям, которые нужно смоделировать, чтобы научиться распознавать их или игнорировать. Другими словами, ролики должны быть разноплановыми и не содержать похожих объектов и сценариев, иначе модель не сможет обобщать. Важным моментом является то, что во время обуче ния не должно быть абсолютно никаких совпадений между видео, используемыми для внешнего обуче ния, и любым из видео для рабочего отслеживания. А именно нельзя до- пускать попадания в автономные обучающие данные ни одной из реальных целей отслеживания, так как в этом случае модель по существу превратится в детектор объекта. Вместо этого при автономном обучении модель должна сосредоточиться на изучении общего набора помех и изменений, а не на характерных для объекта шаблонах. Как только формирование функции со- поставления с по мощью внешних данных завершено, она больше не адапти- руется и применяется к ранее не встречавшимся объектам и видео как есть. Сиамское отслеживание напоминает парадигму поиска экземпляров (Tao et al., 2014, 2015; Philbin et al., 2007; Tolias et al., 2015), когда заданный участок изображения-запроса ищут в пакете изображений. Использование обуче ния сопоставлению (Tao et al., 2015) позволяет выполнять точный поиск экземп- ляров объектов, даже если объект поиска представлен совершенно иначе, чем целевое изображение. При отслеживании обуче ние функции сопоставления полностью выполняется на примерах отслеживания. После обуче ния функ - ция сопоставления способна сравнивать патчи новых экземпляров объектов или даже новых типов, которые функция раньше не встречала. 10.3.4.2. Эквивариантность при отслеживании Сначала мы дадим краткое введение в эквивариантные модели. Затем опи- шем популярные виды эквивариантности, применяемые в сиамских треке-\n--- Страница 456 ---\nДолгосрочное визуальное отслеживание объекта  455 рах. За более общим обзором эквивариантности мы отсылаем заинтересо- ванного читателя к публикации (Weiler et al., 2018). Свойство эквивариантности требует, чтобы функция обладала комму - тативностью области определения и области значений. Для любой данной группы преобразований G функция отображения h : X ® Y является эквива- риантной, если она удовлетворяет условию h(ρgX(x)) = ρgY(h(x)) g Î G, x Î X, (10.23) где ρg(·) обозначает групповое действие в соответствующем пространстве. При инвариантности ρ gY будет тождественным отображением. В качестве наглядного примера мы рассмотрим эквивариантность пере- носа (translation equivariance), изображенную на рис. 10.4. В этом примере h обозначает функцию сверточной нейронной сети, а ψg обозначает группу переноса. Примеры действий из этой группы включают, например, переме- щение на один пиксель влево или на один вправо либо сдвиг на несколько пикселей. Таким образом, внутри группы переноса может быть определено бесконечное количество действий. Обеспечение эквивариантности сети по отношению к переносам приводит к уменьшению сложности выборки и об- легчает обобщение модели в отношении вариаций переноса. Важно отметить, что существует несколько других преобразований, поми- мо переноса, которые могут быть встроены в модель для повышения робаст - ности, если эффекты этих преобразований присутствуют в данных и задаче. В качестве примеров можно назвать повороты, отражения и изменение мас - штаба. Для обобщения любого из этих преобразований необходимо приме- нить эквивариантность к соответствующей группе. ρtY(h(x)) = h(ρ tX(x)) h(x)x h hρtX(x) ρtY ρtX Рис. 10.4  Схематическое представление эквивариант - ности переноса по патчам в CNN, возникающей из-за свя- зывания весов переноса, так что перенос ρtX входного изо- бражения x приводит к соответствующему переносу ρtY(f(x)) карт признаков h(x). Здесь h(·) и ρt(·) обозначают функцию кодирования нейронной сети и функцию переноса соответ - ственно. Источник: Worrall et al., 2017\n--- Страница 457 ---\n456  Длительное отслеживание объекта на основе глубокого обучения 10.3.4.3. Эквивариантность переноса При распознавании изображений в целом и визуальном отслеживании объ- ектов в частности варианты переноса объекта не связаны с категорией объ- екта, но имеют отношение к его местоположению. Модель отслеживания должна быть эквивариантна по отношению к переносу (Li et al., 2019a), что- бы она могла точно возвращать местоположение целевого объекта в любом будущем кадре. К счастью, эквивариантность переноса почти идеально интегрирована во все модели трекеров, основанные на сверточных нейронных сетях, благо- даря характеру свертки, которая является эквивариантной по отношению к оператору сдвига (Bronstein et al., 2017). На практике, однако, и особенно в контексте визуального отслеживания объектов, эквивариантность пере- носа не может быть идеально реализована из-за ограничивающих допуще- ний. Как отмечено в (Li et al., 2019), сверточные нейронные сети являются эквивариантными к переносу именно тогда, когда на границах изображения нет отступов. Однако если на границах есть заполнители изображения, вы- ходные данные свертки не будут точно равными при смещении. Это стано- вится особенно актуальным при увеличении глубины сверточной нейронной сети, используемой для реализации сиамской функции сопоставления. Из-за увеличения действующего рецептивного поля (Simonyan, Zisserman, 2014) признаки в более глубоких слоях будут сильно зависеть от входных пиксе- лей вблизи границ изображения, и, таким образом, модель перестает быть действительно эквивариантной к переносу. В результате модель функции сходства пространственно смещена и склонна возвращать наиболее досто- верные участки прогнозов, которые находятся рядом с центром изображе- ния. В качестве примера обратимся к рис. 10.5 (Li et al., 2019), на котором цели размещают в случайных местах, отобранных в диапазоне (0, m), где 0 – центр пятна (то есть центр целевого объекта во время обуче ния сиамской функции подобия), а m = 0, 16, 32 – максимальное смещение цели в патче. При m = 0 цель всегда находится в центре патча, показывая, что трекер будет иметь тенденцию предсказывать центральные местоположения независимо от фактического местоположения цели. Наличие пространственного смещения в модели трекера нежелательно, поскольку цель может находиться в любом месте кадра изображения. Воз- можно, что более важно, самым большим следствием этого пространствен- ного смещения является то, что обычные сиамские трекеры не могут ис - пользовать очень глубокие сверточные нейронные сети. Тем не менее очень глубокие сверточные нейронные сети, такие как нейронные сети ResNet (He et al., 2016), неоднократно показывали, что они имеют решающее значение для повышения точности распознавания объектов. Поскольку эквивариантность переноса не получается точно реализовать в глубоких нейронных сетях из-за несовершенных предположений, в (Li et al., 2019) предлагают практическое решение в виде пространственно-ори- ентированной выборки (spatially aware sampling). В частности, при создании обучающей выборки для обуче ния функции сиамского подобия предлагается добавлять шум к местоположению целевого объекта, чтобы он больше не располагался в центре. При этом пространственное смещение уменьшается\n--- Страница 458 ---\nДолгосрочное визуальное отслеживание объекта  457 (рис. 10.5), и можно использовать более глубокие нейронные сети, такие как ResNet-50. Применение более глубоких сетей, в свою очередь, приво- дит к значительному повышению точности. Для получения дополнительных сведений о точной архитектуре мы отсылаем заинтересованного читателя к оригинальной публикации. Сдвиг: 32 Сдвиг: 16 Сдвиг: 0 Влияние случайного сдвига на VOT Диапазон случайного сдвигаЕАО Рис. 10.5  Вверху: если не добавлять никакого случайного сдвига (сдвиг: 0) в местоположении ограничивающей рамки во время обуче ния, модель склонна предсказывать расположение центра, что, строго говоря, подразумевает отсут - ствие эквивариантности к переносу. Добавление шума к эталонной ограничи- вающей рамке (сдвиг: 16 или 32) помогает более равномерно распределять прогнозы. Внизу: добавление некоторого шума к эталонным предсказаниям восстанавливает строгую эквивариантность переноса, заметно улучшая точ- ность отслеживания. Источник: Li et al., 2019 В заключение важно пояснить, почему более глубокие сети оказались успешными в классификации, но не в визуальном отслеживании объектов. В классификации изображений и объектов строгая эквивариантность пере- носа не обязательно требуется, потому что цель не состоит в том, чтобы пред- сказать точное местоположение объекта. Следовательно, пространственное смещение не приносит вреда, пока модель учится успешно распознавать категорию объекта. Напротив, при визуальном отслеживании объекта задача состоит в том, чтобы точно предсказать местоположение объекта, и про- странственное смещение неуместно.\n--- Страница 459 ---\n458  Длительное отслеживание объекта на основе глубокого обучения 10.3.4.4. Эквивариантность вращения Вращение является одной из наиболее распространенных, но до сих пор не- решенных сложных проблем, возникающих при визуальном отслеживании объектов. Вращение часто встречается в реальных сценариях, особенно когда камера записывает вид сверху, как в дронах, где вращается либо объект, либо сама камера. Еще одним примером являются селфи-видео, в которых объ- екты часто вращаются в плоскости. Алгоритмы отслеживания, основанные на глубоком обучении, применяют глубокие сверточные нейронные сети, которые теоретически являются эк - вивариантными к переносу, но не предназначены для обработки вращений в плоскости. Подразумевается, что модель может хорошо работать с ориен- тациями объекта, представленными в обучающем наборе, но не справляться с незнакомыми ориентациями, как показано на рис. 10.6. ρθ(·) ρθ(·)h(·) h(·) Рис. 10.6  Пример, демонстрирующий отсутствие эквивари- антности вращения в обычных моделях CNN, применяемых для отслеживания объектов, ρθ(h(·)) ≠ h(ρθ(·)). Здесь h(·) и ρθ(·) обозна- чают функцию кодирования нейронной сети и преобразование вращения соответственно. Источник: Gupta et al., 2021 Как и в разделе 10.3.4.3, простой подход к принудительному изучению ва- риантов вращения заключается в использовании обучающих наборов данных, в которых повороты в плоскости происходят естественным образом или по- средством дополнения данных. Однако, как подчеркивают Лаптев и др. (Laptev et al., 2016), существует несколько ограничений стратегий дополнения данных. Во-первых, такие процедуры потребуют изучения отдельных представлений для разных повернутых вариантов данных. Во-вторых, чем больше вариантов учитывается, тем более гибкой должна быть модель трекера, чтобы охватить их все. Это означает значительное увеличение обучающих данных и вычис - лительных расходов. Далее, такой подход сделал бы модель инвариантной к поворотам, но не эквивариантной к ним. Следовательно, прогнозы будут ненадежными, когда цель окружена похожими объектами, совершающими разные вращения, например при отслеживании рыбы в косяке других рыб. Альтернативой является реализация эквивариантности вращения с ис - пользованием группо-эквивариантных CNN (Cohen, Welling, 2016) и управ-\n--- Страница 460 ---\nДолгосрочное визуальное отслеживание объекта  459 ляемых фильтров (Weiler et al., 2018), чтобы сделать сиамские трекеры эк - вивариантными к вращениям. Этот подход к эквивариантности вращения вызывает встроенное разделение весов между различными группами вра- щений и добавляет в модель внутреннее понятие вращения. Управляемые фильтры. Управляемые фильтры позволяют эффективно вычислять отклики для произвольного числа оборотов дискретного фильт - ра Λ. Более того, они также демонстрируют сильные выразительные воз - можности. Фильтр Ψ является вращательно управляемым, если его поворот на произвольный угол θ может быть выражен через фиксированный набор атомарных функций (Freeman et al., 1991; Weiler et al., 2018). В работе (Gupta et al., 2021) определяют базис управляемых функций, используя круговые гармоники ψ jk: ψjk(r, ω) = τj(r)eikω, (10.24) где ω Î (–π, π] и j = 1, 2, …, J позволяют управлять радиальной частью базис - ных функций. Далее, член (r , ω) относится к преобразованной версии (x 1, x2) в полярных координатах, а k Î ℤ обозначает угловую частоту. Преимущество круговых гармоник состоит в том, что можно просто выразить повороты на ψjk как умножение на комплексную экспоненту: ρθψjk(x) = e–ikθψjk(x), (10.25) где θ Î (–π, π]. Для ясности мы выражаем ψjk(·) как ψjk(x). Затем каждый обучен- ный фильтр строится как линейная комбинация элементарных фильтров: (10.26) с весами wjk Î ℂ. Для поворота на θ составным фильтром можно управлять с по мощью фазовой манипуляции элементарных фильтров: (10.27) Единую ориентацию фильтра можно получить, взяв действительную часть Ψ, обозначаемую как Re Ψ (x). Сиамские трекеры имеют две ветви сверточных нейронных сетей. Обе ветви в стандартных сиамских трекерах получают один вход, который яв- ляется либо целевым патчем в первом кадре, либо каждым новым кадром в последовательности. Чтобы иметь вращательно-эквивариантный сиамский трекер, сверточные нейронные сети в обеих ветвях используют вращатель- но-эквивариантные управляемые фильтры. Эквивариантный вход вращения. Сосредоточившись на ветви шабло- нов, Гупта и др. (Gupta et al., 2021) изменяют структуру шаблона, чтобы он содержал несколько повернутых вариантов первого кадра, определенного множеством Z, где Z = {z1, z2, , zΛ}. Каждый повернутый вход I содержит C каналов, где каждый канал представлен посредством Ic и c Î {1, 2, , C}. Этот\n--- Страница 461 ---\n460  Длительное отслеживание объекта на основе глубокого обучения вход свернут с Cˆ повернутыми фильтрами где cˆ Î {1 2 Cˆ}. На основании уравнения (10.27) результирующие признаки, полученные до применения нелинейной активации, будут вычисляться следующим образом: (10.28) где фильтры представляют собой повернутые варианты с равноудаленными ориентациями θ, представленными множеством Затем применяются члены смещения и нелинейность σ, чтобы получить карту признаков на первом слое . Обратите внимание, что необходимо повернуть входные данные только на одной из двух ветвей, так как вращения в свертках в уравнении (10.28) относительны. Имеет смысл выполнять поворот ввода в ветке шаблона, так как это можно сделать один раз на первом кадре. Также отметим, что теоретически, вместо того чтобы брать все возмож - ные версии вращения Z шаблонной цели, также можно сначала вычислить функцию h(z) исходной цели, а затем повернуть h(z). Однако на практике про - странственное разрешение h(z) очень низкое, обычно 6×6 или 7×7 пикселей. В результате из-за грубого преобразования возникнут артефакты по углам и краям. Лучше сначала повернуть весь кадр (а не только цель) вокруг цент - ра вращения цели, затем обрезать и вычислить h(z). Поскольку упомянутые операции выполняются только в ветке цели, этот шаг может быть рассчитан заранее и внесет лишь незначительные дополнительные затраты. Вращательно-эквивариантные свертки. Карты признаков, полученные из уравнения (10.28), обрабатываются далее с использованием групповых сверток, обобщающих пространственные свертки на более широкое мно- жест во групп преобразований. Подобно первому слою, управляемые фильт - ры определяются для группы как (10.29) где hc(l–1) обозначает c-й канал карты признаков на (l – 1)-м слое, который теперь заменяется на h. Дополнительный индекс θ – ω, введенный в урав- нении (10.29) для тензора весов, облегчает операцию групповой свертки по измерению вращения. Он подразумевает преобразование функций в группе путем их пространственного вращения. Вращательно-эквивариантный пулинг. Выходные данные последнего сверточного слоя группы дополнительно обрабатываются путем пулинга по измерению вращения. В отличие от обычных задач классификации, пулинг не выполняется по пространственному измерению. Причина в том, что мы хотим сохранить эквивариантность вращения. Вращательно-эквивариантные сиамские трекеры. Из двух ветвей мы получаем два множества карт признаков, {h (z)} и h(x), где {h (z)} – множество,\n--- Страница 462 ---\nДолгосрочное визуальное отслеживание объекта  461 содержащее карты признаков в Λ ориентациях. Затем {h (z)} и h(x) свертыва- ются для получения {f (z, x)} – множества из Λ карт интенсивности (heatmap), где fi(z, x) = h(zi) ∗ h(x) для всех zi Î Z. Далее { f(z, x)} обрабатывается с по мощью глобальной операции max-пулинга для получения конечной выходной карты интенсивностей f(Z, x), где Z – множество значений z для нескольких ориен- таций шаблона. Глобальная операция max-пулинга находит максимальное значение в {f (z, x)} и выбирает карту признаков, которая его содержит. Вышеупомянутые модули представляют собой необходимый набор компо- нентов для сиамского трекера, эквивариантного вращению. Все сверточные слои и слои пулинга должны быть заменены их аналогами, эквивариантными повороту. Сначала необходимо определить точность трекера с точки зрения различения различных ориентаций в соответствии с вращательными степе- нями свободы. При наличии Λ групп вращения трекер был бы совершенно эквивариантен углам, определяемым множеством Ω = {(i – 1) · 360/Λ }Λ i=1. Для генерации h(z, x) выполняются Λ групповых сверток с целью получения Λ раз- личных карт интенсивности. Наконец, выполняется глобальный max-пулинг карт признаков для генерации h(Z, x), который затем обрабатывается для локализации цели. Окончательный трекер эквивариантен только вращению в плоскости, по - скольку вращение вне плоскости требует знания 3D-сцены. Дополнительным побочным преимуществом сиамских трекеров, эквивариантных вращению, по сравнению с моделями, инвариантными к вращению, является то, что их можно использовать для вычисления изменений относительной ориентации цели путем обуче ния без учителя. Более того, их можно использовать для добавления дополнительных регуляризаций и ограничений для обеспече- ния последовательности вращательного движения. Для получения допол- нительной информации об устройстве сиамских трекеров, эквивариантных вращению, мы отсылаем заинтересованного читателя к (Gupta et al., 2021). 10.3.4.5. Эквивариантность масштаба Другой тип изменений, который часто встречается при отслеживании ви- деообъектов, – это вариации масштаба. Точное измерение масштаба имеет решающее значение, когда камера использует увеличивающий объектив или когда цель перемещается по глубине. Как отмечают Сосновик и др. (Sosnovik et al., 2021), масштаб также важен для дифференциации различных объектов при отслеживании, особенно когда многие объекты на видео имеют схожий внешний вид, например во время трансляции спортивного матча или съемок толпы. В таких обстоятельствах эквивариантность в пространственном мас - штабе обеспечивает более различительное представление, которое необ - ходимо для надежной дифференциации нескольких похожих кандидатов. Важно отметить, что масштабно-пространственная эквивариантность по- могает поддерживать лучшую стабильность размера предсказанных огра- ничивающих рамок, даже если изменения масштаба в видео незначительны. Обычный способ реализации масштаба в трекере – это обуче ние сети на большом наборе данных, где изменения масштаба происходят естественным образом. Как отмечают Лаптев и др. (Laptev et al., 2016) и было сказано в пре-\n--- Страница 463 ---\n462  Длительное отслеживание объекта на основе глубокого обучения дыдущем подразделе, такие процедуры обуче ния могут привести к появле- нию масштабированных дубликатов почти одинаковых фильтров, что делает оценку межмасштабного сходства ненадежной. Масштабно-эквивариантные модели имеют внутреннее понятие масштаба и встроенное распределение веса между различными масштабами фильтров. Таким образом, эквивари- антность масштаба направлена на получение одинакового представления для всех размеров. Масштабно-эквивариантные свертки. Для заданной функции ρs : ℝ ® ℝ масштабное преобразование определяется следующим образом: Ls[f](t) = f(ρs–1t), \"s ³ 0, (10.30) где случаи с ρs > 1 называются укрупняющим масштабированием, или ап- скейлингом (upscaling), а с ρs < 1 – уменьшающим масштабированием, или даунскейлингом (downscaling). Стандартные сверточные слои и сверточные сети являются трансляционно-эквивариантными, но не масштабно-эквива- риантными (Sosnovik et al., 2020). Чтобы построить масштабно-эквивариантные сверточные сети, Сосно- вик и др. (Sosnovik et al., 2020) начинают с выбора полного базиса функций следующего вида, определенных в нескольких масштабах, выбирая центром функции точку (0, 0) в координатах (u , v): (10.31) В отличие от управляемых фильтров, здесь Hn – полином Эрмита n-го по- рядка и A – константа, применяемая для нормализации. Построение базиса из N функций возможно путем итерации по возрастающим парам n и m . Для полного и фиксированного базиса количество функций N равно количеству пикселей в исходном фильтре с выбранным множеством эквидистантных масштабов σ : Ψσ = {ψσ00, ψσ01, ψσ10, ψσ11, …}. (10.32) Наконец, свертки изучаются как взвешенные комбинации ψσi с использо- ванием обучаемых весов w : (10.33) В результате окончательные ядра определяются в нескольких масштабах, и интерполяция изображения не требуется. Для заданной функции масштаба и переноса f (s, t) масштабная свертка с ядром κ σ(s, t) равна (10.34) где «H обозначает масштабно-эквивариантную свертку. Результатом этой свертки является набор признаков, каждый из которых соответствует раз- ным масштабам.\n--- Страница 464 ---\nДолгосрочное визуальное отслеживание объекта  463 Эквивариантные пулинг и паддинг. Чтобы захватить корреляции между различными масштабами и преобразовать трехмерный сигнал в двумерный, необходимо применить глобальный max-пулинг вдоль оси масштаба. Эта операция не исключает масштабную эквивариантность сети. На практике Сос новик и др. (2021) рекомендуют дополнительно включать масштабно-эк - вивариантный пулинг в местах, где обычные CNN содержат пространствен- ный max-пулинг или страйды. Показано, что паддинг снижает способность сверточных трекеров к лока- лизации объектов (Li et al., 2019; Zhang, Peng, 2019), как было сказано также в разделе 10.3.4.3. Однако масштабные эквивариантные свертки полагают - ся на большие рецептивные поля, которые, следовательно, дают меньшие карты признаков. Следовательно, для масштабно-эквивариантных трекеров с очень глубокими моделями необходим паддинг. Чтобы гарантировать, что строгая эквивариантность переноса не будет нарушена при одновременном получении благоприятных результатов, в (Sosnovik et al., 2021) используют циклический паддинг во время обуче ния и нулевой – во время вывода. Масштабно-эквивариантные сиамские трекеры. Операция свертки, в результате которой получается карта интенсивностей трекера, непарамет - рична. И входные данные, и ядро поступают из нейронных сетей. Таким образом, подход, реализованный в уравнении (10.34), для этого случая не подходит. Для двух функций f1, f2 масштаба и переноса непараметрическая масштабная свертка определяется следующим образом: [f1 «H f2](s, t) = Ls–1[Ls[f1] « f2](t). (10.35) Здесь Ls – масштабирование, реализованное как бикубическая интерполя- ция. Хотя это относительно медленная операция, она используется в трекере только один раз и не сильно влияет на время вывода. Вышеупомянутые мо- дули являются необходимыми и достаточными компонентами для построе- ния масштабно-эквивариантного сиамского трекера. А именно необходимо сначала определить, в какой степени объекты изменяются в размерах в этой области, а затем соответственно выбрать набор масштабов σ1, σ2, σN. Это гиперпараметр, специфичный для предметной области, в которой работает сеть. Для сетей, представленных h(x) и h(z), все сверточные слои необходимо заменить масштабно-сверточными. Базисом этих слоев служат выбранные масштабы σ1, σ2, σN. При желании можно включить пулинг по масштабу, чтобы дополнительно извлечь межмасштабные корреляции между всеми масштабами. Параметрическая масштабно-эквивариантная свертка должна быть заменена непараметрической из уравнения (10.35), чтобы получить окончательную карту прогноза. Полученный трекер создает карту интенсивностей f(z, x), определенную для масштаба и переноса. Каждой позиции назначается вектор признаков, который кодирует как меру подобия, так и отношение масштаба между кан- дидатом и шаблоном. Если имеется дополнительный пулинг масштаба, то вся информация о масштабе агрегируется в показателе подобия. Поскольку не меняются ни общая структура трекера, ни процедуры обуче ния и вывода, дополнительные вычислительные затраты за счет введения масштабной эк - вивариантности невелики. За дополнительной информацией об устройстве\n--- Страница 465 ---\n464  Длительное отслеживание объекта на основе глубокого обучения сиамских трекеров, эквивалентных масштабу, мы отсылаем заинтересован- ного читателя к работе (Sosnovik et al., 2021). 10.3.4.6. Эффективность сиамских трекеров Первый сиамский трекер от (Tao et al., 2016) был основан на архитектуре быст рой RCNN (Girshick, 2015) и пулинге области наблюдения (region-of-in- terest, ROI) для выполнения сопоставления с локальным шаблоном. Несмотря на повышение скорости, обеспечиваемое процедурой пулинга ROI, поиск по рамкам по-прежнему является процедурой, требующей значительных вычислительных ресурсов. Бертинетто и др. (Bertinetto et al., 2016) отмеча- ют, что поиск по сверточным картам признаков сам может быть описан как свертка, исходя из принципа работы полностью сверточных нейронных се- тей (Long et al., 2015). Это простое изменение сделало сиамские трекеры на- много более эффективными и сравнимыми с предыдущими альтернативами. Поскольку поиск по всем возможным местам на изображении обходится дорого, в (Li et al., 2018) предлагают ввести в свой сиамский трекер сеть предсказания области (region proposal network) от (Ren et al. (2015). Сеть предсказания области учится регрессии по координатам местоположения и масштабу рамки, которая, вероятно, содержит цель. Поэтому в своем по- иске сиамский трекер может ориентироваться только на нужные регионы. Чтобы еще больше сократить объем вычислений, в (Li et al., 2019) предлага- ют свертки по глубине, а не обычные свертки, получая в десять раз меньше параметров и значительное преимущество в вычислительном отношении. 10.3.4.7. Гибридное обучение с сиамскими трекерами Сиамские трекеры продемонстрировали большие преимущества в точном прогнозировании местоположения целей, особенно в длинных последова- тельностях, благодаря тому, что они не страдают от устаревания модели. Это возможно, если полагаться исключительно на автономное обуче ние и не включать какой-либо компонент последовательного обуче ния в процессе ра- боты. Однако игнорирование всех будущих появлений цели и отсутствие по- следовательного обуче ния противоречат здравому смыслу. Последователь- ное обуче ние необходимо для работы со сценариями, в которых внешний вид цели значительно изменяется в ходе отслеживания, так что полагаться только на первый кадр недостаточно. Например, представьте себе случай, когда пешеход снимает куртку. Последовательная составляющая также имеет решающее значение в случае, если в кадре присутствует несколько похожих объектов и модель должна их различать, что является сложной задачей для простых сиамских трекеров. В этом случае последовательное обуче ние по- могает модели трекера отличить целевой объект от всех других подобных объектов на сцене. Чтобы убедиться, что последовательное обуче ние не оказывает пагубного влияния на модель трекера из-за устаревания модели, обновления необхо- димо применять с осторожностью. При разработке механизмов обновления модели следует учитывать два аспекта. Первый аспект заключается в том,\n--- Страница 466 ---\nДолгосрочное визуальное отслеживание объекта  465 когда и как часто надо выполнять обновление модели. Чем чаще обновля- ются модели, тем больше вероятность того, что модель трекера будет ста- новиться все более и более предвзятой со временем, как показано в (Gavves et al., 2020). Второй аспект заключается в том, какую именно часть модели следует обновить, чтобы гарантировать, что возникшее смещение будет либо небольшим, либо окажет минимальное влияние в долгосрочной перспективе на сопоставление с шаблоном. Обновления могут быть введены либо непо- средственно в функции подобия сиамского трекера (Bhat et al., 2019), либо во вспомогательные сети, дополняющие функцию подобия (Tao et al., 2017). Чтобы ввести компонент последовательного обуче ния, многие подходы предлагают стратегию метаобучения. Согласно этой стратегии модель тре- кера изначально обучается в автономном режиме, чтобы оптимизировать веса параметров на просмотренных данных. Затем во время вывода мета- обучаемая модель предсказывает новые веса параметров, оптимальные для новой точки данных. Бхат и др. (Bhat et al., 2019) предлагают компонент метаобучения, который прогнозирует новые веса параметров, различающиеся для цели и фона. Что касается функции сходства, предлагаемая модель основана на стандартной сиамской архитектуре. Однако, в отличие от стандартных сиамских трекеров, за последним сверточным слоем в ветке шаблона следуют инициализатор мо- дели и модуль оптимизатора модели. Инициализатор модели обеспечивает начальное вычисление весов модели, используя только внешний вид цели. Эти веса затем обрабатываются модулем оптимизатора модели, который ис - пользует как цель, так и фон для получения окончательных параметров веса. Чтобы избежать любого потенциального переобучения, оптимизатор модели содержит очень мало обучаемых параметров. В итоге модель обучается как автономно, так и последовательно в процессе работы. На автономном этапе модель обучается с использованием пар наборов (Mtrain, Mtest). Каждый набор содержит N кадров, M = {Ij, bj}j, где bj – целевые ограничивающие рамки, доступные во время обуче ния. Чтобы построить Mtrain и Mtest, для каждой обучающей последовательности выбирают случай- ный сегмент, а затем делят его на две части. Затем предсказатель модели по- лучает в качестве входных данных сверточные карты признаков, вычислен- ные из Mtrain, на основании которых предсказывает веса параметров. Потом, чтобы обеспечить хорошее обобщение, эти веса параметров используются для прогнозирования отслеживания только на Mtest. На этапе последователь- ного обуче ния первоначальный внешний вид цели искажается с использова- нием методов увеличения данных для создания новых образцов обучающей выборки. Этот набор дополняется новыми патчами цели всякий раз, когда цель прогнозируется с достаточной уверенностью. Последовательное обуче- ние по своей сути аналогично автономному обуче нию, но выполняется через равные промежутки времени каждые 20 кадров. Двигаясь в том же направлении, в работе (Danelljan et al., 2020) предлагают включить вероятностное обуче ние в сеть, предложенную в (Bhat et al., 2019). Чтобы достичь этого, модель учится минимизировать расхождение Куль- бака–Лейблера между своим выходом pθ(y|x) и эталонным распределением p(y|yi). Вероятностный результат модели определяется как энергетическое\n--- Страница 467 ---\n466  Длительное отслеживание объекта на основе глубокого обучения распределение где Эталонное распределение p(y|yi) оценивается эмпирически как гауссово распределение p(y|yi)𝒩(yi, σ2), где σ2 – эмпирическая дисперсия, оцениваемая по небольшой выборке данных. В отличие от вышеупомянутых работ, (Tao et al., 2017; Gavves et al., 2020) иначе подходят к проблеме, сосредоточившись на том, когда трекер должен выполнять обновление. Идея состоит в том, что хотя сиамские трекеры могут извлечь выгоду из обновлений модели, они должны быть осторожны, чтобы не внести необратимые искажения в функцию подобия. Как видно из (10.14), точная оценка смещения модели потребует вычисления члена 𝔼[δiÑϕfi,t]. Од - нако параметры состояния ϕt+1 заранее неизвестны, и повторное обнаруже- ние цели в более ранних кадрах для каждого шага обновления модели (для получения fi,t) было бы слишком сложным с вычислительной точки зрения. В связи с этим было предложено использовать каскадную нейронную сеть для определения необходимости выполнения обновления модели. Сначала сиамский трекер используется для вычисления карты подобия после свертки карты признаков шаблона с картой признаков из каждого нового кадра. За функцией сиамского подобия следует сеть распознавания устаревания (de- cay recognition network), реализованная в виде бинарного классификатора на основе LSTM. Классификатор LSTM получает в качестве входных данных предыдущие K карт подобия, возвращенных сиамским трекером. Чтобы убе- диться в отсутствии предвзятости LSTM, его также обучают в автономном режиме. Когда классификатор LSTM возвращает положительный прогноз, веса модели обновляются. Вдобавок, вместо того чтобы полагаться только на предсказание области для ускорения поиска, модель выполняет глобальный поиск каждые T кадров, так что сиамский трекер не теряет цель, если она оказывается за пределами области поиска. Важно подчеркнуть, что в этой модели глобальный поиск принудительно выполняется через равные про- межутки времени, чтобы отделить обновления модели от прогнозов. Если бы обновления зависели от прогнозов модели, это создало бы зависимость обновлений от поведения модели, что привело бы к самообусловленным обновлениям и в конечном итоге к разрушению модели. Аналогичным образом Дай и др. (Dai et al., 2020) предлагают обучаемый в автономном режиме метаобновитель (metaupdater), который призван ре- шить, следует ли обновлять модель трекера. Метаобновитель опирается на последовательность факторов, состоящую из (а) геометрии ограничивающей рамки, (б) оценки достоверности и (в) изменения внешнего вида с течением времени. Во время обуче ния трекер полагается на метаобновитель, чтобы решить, следует обновлять параметры веса или нет. Затем параметры мета- обновителя оптимизируются, чтобы делать правильные прогнозы отслежи- вания в будущих последовательностях. Разработка гибридных моделей трекеров, которые обучаются как в ав- тономном, так и в последовательном режимах, при этом принципиально ис- ключая или сводя к минимуму распад модели, все еще остается открытым вопросом и предметом исследований.\n--- Страница 468 ---\nДолгосрочное визуальное отслеживание объекта  467 10.3.4.8. Последовательное обучение помимо сиамских трекеров До сиамских трекеров также было предпринято несколько важных попыток моделирования трекеров в длинных видеопоследовательностях. В своей ос - новополагающей работе Калал и др. (Kalal et al., 2012) предлагают разделить длительное отслеживание на задачи моделирования отслеживания, обуче ния и обнаружения. Трекер отвечает за оценку движения объекта от одного кадра к другому. Допущение компонента трекера заключается в том, что движение между кадрами ограничено и объект всегда виден. Детектор обрабатывает каждый кадр независимо, чтобы исправить любые ошибки, допущенные трекером. Ложноположительные и ложноотрицательные результаты, возвра- щаемые трекером и предсказателем, затем отслеживаются и корректируются обучающим компонентом. Обуче ние опирается на пару экспертов. P-эксперт выявляет только ложноотрицательные результаты, а N-эксперт – только лож - ноположительные. Поскольку оба эксперта сами могут ошибаться, они оста- ются независимыми, чтобы была гарантия, что их индивидуальные ошибки взаимно компенсируются. Предлагаемый трекер особенно хорошо подходит для долгосрочного отслеживания благодаря механизму самокоррекции, ис - пользуемому независимым детектором и компонентами обуче ния. В статье (Pernici, Del Bimbo, 2013) также предложен трекер, который хоро- шо подходит для длительного отслеживания. С этой целью трекер использует передискретизацию локальных инвариантных представлений SIFT (Lowe, 2004), которые используются в качестве обучающих выборок, передавае- мых паре дискриминативных классификаторов ближайших соседей. Класси- фикатор целевого объекта пытается смоделировать внешний вид целевого объекта, сравнивая внешний вид и форму с другими соседними патчами. Классификатор контекста пытается смоделировать внешний вид простран- ственно-временного фона. Кроме того, трекер использует случайный поиск, когда объект отсутствует в течение определенного количества последова- тельных кадров. Важным компонентом трекера является геометрическое сопоставление, основанное на голосовании в стиле RANSAC. Когда количест - во совпадений меньше ожидаемого, объект предположительно заслоняют другие объекты. Модель обновляется при каждом успешном обнаружении, если нет окклюзии. По сравнению с сиамскими трекерами, эти более ранние методы не изуча- ли функцию подобия в автономном режиме и должны были полагаться на сложные механизмы, чтобы убедиться, что дрейф модели ограничен. Тем не менее тип сигналов, используемых в этих методах, имеет определенное сходство с сиамскими трекерами. Опираясь на сверточные нейронные ар- хитектуры, подобные (Tao et al., 2016; Bertinetto et al., 2016), они учитывают как внешний вид, так и слабые геометрические признаки при определении сходства целевого объекта с возможными местоположениями в новых кад- рах, как это делают (Kalal et al., 2012; Pernici, Del Bimbo, 2013). Более того, в трекерах (Tao et al., 2017; Kalal et al., 2012) используют поиск по полному изображению, чтобы свести к минимуму ложноотрицательные результаты.\n--- Страница 469 ---\n468  Длительное отслеживание объекта на основе глубокого обучения 10.3.5. Наборы данных и тесты Различные бенчмарки отслеживания (Smeulders et al., 2014; Wu et al., 2015; Kristan et al., 2016; Liang et al., 2015; Li et al., 2016; Mueller et al., 2016; Val- madre et al., 2018) сыграли огромную роль в развитии этой области, позволив провес ти объективное сравнение различных методов и добившись впечат - ляющего прогресса в последние годы. Эти бенчмарки предназначены для тестирования краткосрочного отслеживания в соответствии с определением (Kristan et al., 2016), которое не подразумевает наличия методов для повтор- ного обнаружения. Это означает, что объект всегда присутствует в видеока- дре. Однако существующие бенчмарки также краткосрочны в буквальном смысле, так как средняя продолжительность видео не превышает 20–30 се- кунд. Короткая продолжительность видео имеет несколько последствий для оценки алгоритмов долгосрочного отслеживания. Одним из следствий этого является то, что при использовании коротких видеороликов для отслеживания неблагоприятные последствия устаревания модели трудно заметить просто потому, что выполняется недостаточное количество обновлений модели. Даже на умеренно длинных видеопосле - довательностях краткосрочные трекеры чаще всего становятся настолько смещенными, что полностью упускают цель и, что, возможно, более важно, не могут восстановиться (Gavves et al., 2020). Сверх того, поскольку целевые объекты редко покидают кадр, невозможно оценить, хорошо ли алгоритмы справляются со случаями исчезновения и повторного появления объектов. Наконец, в случае более длинных видеороликов критерии успеха длитель- ного отслеживания могут отличаться от критериев для более коротких по- следовательностей. Например, точная попиксельная локализация целевого объекта в коротких видеороликах может дать очень высокие оценки по не- которым показателям. Однако эта попиксельная локализация становится менее важной, если вскоре после этого трекер полностью теряет цель. По этой причине для длительного отслеживания нужны новые наборы дан - ных, ориентиры и типы оценок (Fan et al., 2019; Valmadre et al., 2018; Mueller et al., 2016; Huang et al., 2019; Mueller et al., 2018), где видео обычно намного длиннее, в диапазоне от нескольких минут до получаса, а целевые объекты часто появляются и исчезают. 10.4. заКЛюЧение Визуальное отслеживание объектов – одна из старейших задач компьютер- ного зрения. Устаревание модели в длинных последовательностях, исчезно- вение и повторное появление цели создают серьезные проблемы для кра- ткосрочных моделей отслеживания. Успех глубокого обуче ния повлиял на визуальное отслеживание объектов, особенно в контексте долгосрочных по- следовательностей. Причина в том, что благодаря сиамской архитектуре глу - бокого трекера можно перевести все сравнения внешнего вида в автономное изучение функции подобия и избежать устаревания модели. Хотя сиамские трекеры невосприимчивы к устареванию модели, они страдают от потери\n--- Страница 470 ---\nЛитературные источники  469 объекта в тех случаях, когда внешний вид цели значительно меняется по сравнению с первым кадром. Для решения этой проблемы предложены си- амские трекеры со встроенными инвариантностями и эквивариантностями, а также гибридные сиамские трекеры, которые полагаются как на автоном- ное, так и на последовательное обуче ние. Эти варианты сиамских трекеров могут учитывать большие различия во внешнем виде целевого объекта, но при этом демонстрируют небольшое устаревание модели. Исходя из данных факторов можно сказать, что сиамские трекеры хорошо себя зарекомендо- вали и рекомендуются для длительного визуального отслеживания объектов. Литературные исто ЧниКи Baker S., Matthews I., 2004. Lucas-Kanade 20 years on: a unifying framework. International Journal of Computer Vision. Bertinetto L., Henriques J. a. F., Valmadre J., Torr P. H. S., Vedaldi A., 2016a. Learning feed-forward one-shot learners. In: Advances in Neural Information Processing Systems. Bertinetto L., Valmadre J., Henriques J. F., Vedaldi A., Torr P. H. S., 2016b. Fully- convolutional Siamese networks for object tracking. In: European Conference on Computer VisionWorkshops. Bhat G., Danelljan M., Gool L. V., Timofte R., 2019. Learning discriminative model prediction for tracking. In: IEEE International Conference on Computer Vision, pp. 6182–6191. Briechle K., Hanebeck U. D., 2001. Template matching using fast normalized cross correlation. In: Optical Pattern Recognition XII, International Society for Op- tics and Photonics, pp. 95–102. Bronstein M. M., Bruna J., LeCun Y., Szlam A., Vandergheynst P., 2017. Geometric deep learning: going beyond Euclidean data. IEEE Signal Processing Magazine. Cohen T., Welling M., 2016. Group equivariant convolutional networks. In: Inter - national Conference on Machine Learning, pp. 2990–2999. Comaniciu D., Ramesh V., Meer P., 2000. Real-time tracking of non-rigid objects us- ing mean shift. In: IEEE Conference on Computer Vision and Pattern Recog nition. Dai K., Zhang Y., Wang D., Li J., Lu H., Yang X., 2020. High-performance long-term tracking with meta-updater. In: IEEE Conference on Computer Vision and Pat - tern Recognition. Danelljan M., Bhat G., Shahbaz Khan F., Felsberg M., 2017. ECO: efficient convolu- tion operators for tracking. In: IEEE Conference on Computer Vision and Pat - tern Recognition. Danelljan M., Hager G., Shahbaz Khan F., Felsberg M., 2015. Learning spatially regularized correlation filters for visual tracking. In: IEEE International Confer - ence on Computer Vision, pp. 4310–4318. Danelljan M., Van Gool L., Timofte R., 2020. Probabilistic regression for visual tracking. In: IEEE Conference on Computer Vision and Pattern Recognition. Du D., Qi H., Li W., Wen L., Huang Q., Lyu S., 2016. Online deformable object tracking based on structure-aware hyper-graph. IEEE Transactions on Image Processing 25, 3572–3584.\n--- Страница 471 ---\n470  Длительное отслеживание объекта на основе глубокого обучения Fan H., Lin L., Yang F., Chu P., Deng G., Yu S., Bai H., Xu Y., Liao C., Ling H., 2019. Lasot: a high-quality benchmark for large-scale single object tracking. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 5374–5383. Fan H., Ling H., 2017. Sanet: structure-aware network for visual tracking. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 42–49. Fiaz M., Mahmood A., Javed S., Jung S. K., 2019. Handcrafted and deep trackers: recent visual object tracking approaches and trends. ACM Computing Surveys (CSUR) 52, 1–44. Freeman W. T., Adelson E. H., et al., 1991. The design and use of steerable filters. IEEE Transactions on Pattern Analysis and Machine Intelligence 13, 891–906. Gavves E., Gupta D., Tao R., Smeulders A., 2020. Model decay in long-term tracking. In: IEEE International Conference on Pattern Recognition. Girshick R., 2015. Fast R-CNN. In: IEEE International Conference on Computer Vision. Godec M., Roth P. M., Bischof H., 2013. Hough-based tracking of non-rigid objects. Computer Vision and Image Understanding 117, 1245–1256. Gupta D., Arya D., Gavves E., 2021. Rotation equivariant Siamese networks for tracking. In: IEEE Conference on Computer Vision and Pattern Recognition. He K., Zhang X., Ren S., Sun J., 2016. Deep residual learning for image recognition. In: IEEE Conference on Computer Vision and Pattern Recognition. Held D., Thrun S., Savarese S., 2016. Learning to track at 100 fps with deep re- gression networks. In: European Conference on Computer Vision. Springer, pp. 749–765. Huang L., Zhao X., Huang K., 2019. Got-10k: a large high-diversity benchmark for generic object tracking in the wild. Kalal Z., Matas J., Mikolajczyk K., 2010. Pn learning: bootstrapping binary clas- sifiers by structural constraints. In: IEEE Conference on Computer Vision and Pattern Recognition. IEEE, pp. 49–56. Kalal Z., Mikolajczyk K., Matas J., 2012. Tracking-learning-detection. IEEE Trans- actions on Pattern Analysis and Machine Intelligence. Kristan M., Leonardis A., Matas J., Felsberg M., Pflugfelder R., Čehovin L., Vojíř T., Hager G., Lukezic A., Eldesokey A., Fernandez G., 2017. The visual object track - ing VOT2017 challenge results. In: IEEE International Conference on Computer VisionWorkshops. Kristan M., Leonardis A., Matas J., Felsberg M., Pflugfelder R., Kamarainen J. K., Čehovin Zajc L., Danelljan M., Lukezic A., Drbohlav O., He L., Zhang Y., Yan S., Yang J., Fernandez G., et al., 2020. The eighth visual object tracking vot2020 challenge results. In: ECCV workshops. Kristan M., Matas J., Leonardis A., Vojíř T., Pflugfelder R., Fernandez G., Nebehay G., Porikli F., Čehovin L., 2016. A novel performance evaluation methodology for single-target trackers. IEEE Transactions on Pattern Analysis and Machine Intelligence. Kwon J., Lee K. M., 2011. Tracking by sampling trackers. In: IEEE International Conference on Computer Vision. IEEE, pp. 1195–1202. Kwon J., Lee K. M., Park F. C., 2009. Visual tracking via geometric particle filtering on the affine group with optimal importance functions. In: IEEE Conference on Computer Vision and Pattern Recognition. IEEE, pp. 991–998.\n--- Страница 472 ---\nЛитературные источники  471 Laptev D., Savinov N., Buhmann J. M., Pollefeys M., 2016. Ti-pooling: transforma- tion-invariant pooling for feature learning in convolutional neural networks. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 289–297. Li A., Lin M., Wu Y., Yang M. H., Yan S., 2016. NUS-PRO: a new visual tracking challenge. IEEE Transactions on Pattern Analysis and Machine Intelligence. Li B., Yan J., Wu W., Zhu Z., Hu X., 2018a. High performance visual tracking with Siamese region proposal network. In: IEEE Conference on Computer Vision and Pattern Recognition. Li F., Tian C., Zuo W., Zhang L., Yang M. H., 2018b. Learning spatial-temporal regu- larized correlation filters for visual tracking. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 4904–4913. Li B., Wu W., Wang Q., Zhang F., Xing J., Yan J., 2019a. Siamrpn++: evolution of Siamese visual tracking with very deep networks. In: IEEE Conference on Com- puter Vision and Pattern Recognition, pp. 4282–4291. Li C., Liang X., Lu Y., Zhao N., Tang J., 2019b. Rgb-t object tracking: benchmark and baseline. Pattern Recognition 96, 106977. Liang P., Blasch E., Ling H., 2015. Encoding color information for visual tracking: algorithms and benchmark. IEEE Transactions on Image Processing. Long J., Shelhamer E., Darrell T., 2015. Fully convolutional networks for semantic segmentation. In: IEEE Conference on Computer Vision and Pattern Recognition. Lowe D. G., 2004. Distinctive image features from scale-invariant keypoints. In- ternational Journal of Computer Vision. Lucas B. D., Kanade T., 1981. An iterative image registration technique with an application to stereo vision. In: International Joint Conferences on Artificial Intelligence. Ma C., Huang J. B., Yang X., Yang M. H., 2015. Hierarchical convolutional features for visual tracking. In: IEEE International Conference on Computer Vision, pp. 3074–3082. Mueller M., Bibi A., Giancola S., Alsubaihi S., Ghanem B., 2018. Trackingnet: a large- scale dataset and benchmark for object tracking in the wild. In: European Con- ference on Computer Vision, pp. 300–317. Mueller M., Smith N., Ghanem B., 2016. A benchmark and simulator for uav track - ing. In: European Conference on Computer Vision. Nam H., Baek M., Han B., 2016. Modeling and propagating cnns in a tree structure for visual tracking. arXiv preprint. arXiv:1608.07242. Nguyen H. T., Smeulders A. W., 2004. Fast occluded object tracking by a robust appearance filter. IEEE Transactions on Pattern Analysis and Machine Intel- ligence. Nguyen H. T., Smeulders A. W., 2006. Robust tracking using foreground-background texture discrimination. International Journal of Computer Vision 69, 277–293. Oron S., Bar-Hillel A., Levi D., Avidan S., 2015. Locally orderless tracking. Interna- tional Journal of Computer Vision 111, 213–228. Pan J., Hu B., 2007. Robust occlusion handling in object tracking. In: IEEE Confer - ence on Computer Vision and Pattern Recognition. Pernici F., Del Bimbo A., 2013. Object tracking by oversampling local features, pp. 2538–2551. Philbin J., Chum O., Isard M., Sivic J., Zisserman A., 2007. Object retrieval with large vocabularies and fast spatial matching. In: IEEE Conference on Computer Vi- sion and Pattern Recognition.\n--- Страница 473 ---\n472  Длительное отслеживание объекта на основе глубокого обучения Qi Y., Zhang S., Qin L., Yao H., Huang Q., Lim J., Yang M. H., 2016. Hedged deep tracking. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 4303–4311. Ren S., He K., Girshick R. B., Sun J., 2015. Faster r-cnn: towards real-time object detection with region proposal networks. In: Advances in Neural Information Processing Systems. Ross D. A., Lim J., Lin R. S., Yang M. H., 2008. Incremental learning for robust visual tracking. International Journal of Computer Vision. Russakovsky O., Deng J., Su H., Krause J., Satheesh S., Ma S., Huang Z., Karpathy A., Khosla A., Bernstein M., Berg A. C., Fei-Fei L., 2015. ImageNet large scale visual recognition challenge. International Journal of Computer Vision. Simonyan K., Zisserman A. , 2014. Very deep convolutional networks for large-scale image recognition. arXiv preprint. arXiv:1409.1556. Smeulders A. W. M., Chu D. M., Cucchiara R., Calderara S., Dehghan A., Shah M., 2014. Visual tracking: an experimental survey. IEEE Transactions on Pattern Analysis and Machine Intelligence. Sosnovik I., Moskalev A., Smeulders A., 2021. Scale equivariance improves Siamese tracking. Sosnovik I., Szmajam M., Smeulders A., 2020. Scale-equivariant steerable networks. Tao R., Gavves E., Smeulders A. W. M., 2016. Siamese instance search for tracking. In: IEEE Conference on Computer Vision and Pattern Recognition. Tao R., Gavves E., Smeulders A. W. M., 2017. Tracking for half an hour. arXiv pre- print. arXiv:1711.10217. Tao R., Gavves E., Snoek C., Smeulders A., 2014. Locality in generic instance search from one example. In: IEEE Conference on Computer Vision and Pattern Recog - nition. Tao R., Smeulders A. W. M., Chang S. F., 2015. Attributes and categories for generic instance search from one example. In: IEEE Conference on Computer Vision and Pattern Recognition. Tolias G., Avrithis Y., Jégou H., 2015. Image search with selective match kernels: aggregation across single and multiple images. International Journal of Com- puter Vision. Valmadre J., Bertinetto L., Henriques J., Tao R., Vedaldi A., Smeulders A., Torr P., Gavves E., 2018. Long-term tracking in the wild: A benchmark. In: European Conference on Computer Vision. Wang G., Wang J., Tang W., Yu N., 2017. Robust visual trackingwith deep feature fusion. In: 2017 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, pp. 1917–1921. Weiler M., Hamprecht F. A., Storath M., 2018. Learning steerable filters for rota- tion equivariant cnns. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 849–858. Worrall D. E., Garbin S. J., Turmukhambetov D., Brostow G. J., 2017. Harmonic networks: deep translation and rotation equivariance. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 5028–5037. Wu Y., Lim J., Yang M. H., 2015. Object tracking benchmark. IEEE Transactions on Pattern Analysis and Machine Intelligence.\n--- Страница 474 ---\nОб авторах главы  473 Zhang K., Liu Q., Wu Y., Yang M. H., 2016. Robust visual tracking via convolu- tional networks without training. IEEE Transactions on Image Processing 25, 1779–1792. Zhang T., Xu C., Yang M. H., 2017. Multi-task correlation particle filter for robust object tracking. In: IEEE Conference on Computer Vision and Pattern Recogni- tion, pp. 4335–4343. Zhang Z., Peng H., 2019. Deeper and wider Siamese networks for real-time visual tracking. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 4591–4600. Zheng W. L., Shen S. C., Lu B. L., 2017. Online depth image-based object tracking with sparse representation and object detection. Neural Processing Letters 45, 745–758. об аВтора Х гЛаВы Доктор Эфстратиос Гаввес – адъюнкт-профессор Амстердамского универ- ситета в Нидерландах, научный руководитель лаборатории глубокого зрения QUVA, научный руководитель лаборатории POP-AART по использованию ИИ для адаптивной лучевой терапии и стипендиат ELLIS. Является получателем гранта ERC Career Starting Grant 2020 и гранта NWO VIDI 2020 для исследо- вания машинного обуче ния темпоральности пространственно-временных последовательностей. Также является соучредителем Ellogon.AI, дочерней компании университета, в сотрудничестве с Голландским институтом рака (NKI) с целью использования ИИ в патологической медицине и геномике. Эфстратиос – автор нескольких статей для ведущих конференций и журна- лов по компьютерному зрению и машинному обуче нию. Ему принадлежат несколько патентов в области компьютерного зрения. Его исследования со- средоточены на машинном обучении и его динамике, эффективном компью- терном зрении и машинном обучении для онкологии. Дипак Гупта в настоящее время работает научным сотрудником в компании Transmute AI Research в Нидерландах, где занимается фундаментальными исследованиями в области компьютерного зрения и глубокого обуче ния. Ранее он в течение двух лет работал постдокторантом в лаборатории QUVA и Институте информатики Амстердамского университета, где в основном занимался улучшением методов визуального отслеживания объектов. Ди- пак защитил докторскую диссертацию в области вычислительной техники в 2017 г., а степень бакалавра и магистра в области геофизики – в 2013 г. Он более года проработал в Royal Dutch Shell научным сотрудником (2017– 2019 гг.), решая проблемы геофизики с использованием ИИ. Его особенно интересует разработка эффективных алгоритмов отслеживания объектов и сегментации видео. Кроме того, он также участвует в исследовательских проектах на стыке физики, математики и машинного обуче ния, ориентиро- ванных на применение в медицинской визуализации и геофизике.",
      "debug": {
        "start_page": 431,
        "end_page": 474
      }
    },
    {
      "name": "Глава 11. Обучение пониманию сцены на основании действий 474",
      "content": "--- Страница 475 --- (продолжение)\nГлава 11 Обучение пониманию сцены на основании действий Авторы главы: Корнелия Фермюллер, Мэрилендский университет, Институт передовых компьютерных исследований, Центр компьютерных наук и технологий Ирибе, Колледж-Парк, Мэриленд, США; Майкл Мейнорд, Мэрилендский университет, факультет информатики, Центр компьютерных наук и технологий Ирибе, Колледж-Парк, Мэриленд, США Краткое содержание главы: основанный на действиях фреймворк интерпретации сцены и деятель- ности; исследование возможностей и функций объектов и их использования в контексте распознавания действий и обуче ния роботов; исследование распознавания деятельности как взаимодействия познания и восприятия; слияние видения и языка через пространства представлений; обсуждение перспектив компьютерного понимания действий и деятель- ности через призму ориентированной на действие структуры. 11.1. В Ведение Целью компьютерного зрения является выработка интерпретаций изображе- ний и видео, которые могут быть полезны людям. Действие следует модели- ровать, потому что оно является основным средством, с по мощью которого люди взаимодействуют с окружающей средой, и в значительной степени благодаря этому взаимодействию окружающая среда становится значимой. Из-за того, что действие занимает центральное место в формировании зна-\nГлава 11 Обучение пониманию сцены на основании действий Авторы главы: Корнелия Фермюллер, Мэрилендский университет, Институт передовых компьютерных исследований, Центр компьютерных наук и технологий Ирибе, Колледж-Парк, Мэриленд, США; Майкл Мейнорд, Мэрилендский университет, факультет информатики, Центр компьютерных наук и технологий Ирибе, Колледж-Парк, Мэриленд, США Краткое содержание главы: основанный на действиях фреймворк интерпретации сцены и деятель- ности; исследование возможностей и функций объектов и их использования в контексте распознавания действий и обуче ния роботов; исследование распознавания деятельности как взаимодействия познания и восприятия; слияние видения и языка через пространства представлений; обсуждение перспектив компьютерного понимания действий и деятель- ности через призму ориентированной на действие структуры. 11.1. В Ведение Целью компьютерного зрения является выработка интерпретаций изображе- ний и видео, которые могут быть полезны людям. Действие следует модели- ровать, потому что оно является основным средством, с по мощью которого люди взаимодействуют с окружающей средой, и в значительной степени благодаря этому взаимодействию окружающая среда становится значимой. Из-за того, что действие занимает центральное место в формировании зна-\n--- Страница 476 ---\nВведение  475 чимости окружения, люди выстраивают свое окружение вокруг действия. Таким образом, для полного понимания окружающей среды с точки зрения человека требуется понимание ее отношения к реальным и возможным дей- ствиям. Большинство современных методов компьютерного зрения не осно- ваны на действии – в противовес им в этой главе мы представляем методы и фреймворки, которые при моделировании наблюдаемой сцены используют основанную на действии (action based) или функциональную интерпретацию. Сосредоточение восприятия на действии согласуется с теориями вопло- щенного познания (embodied cognition) (Varela et al., 1993; Barsalou, 2008), которые утверждают, что многие аспекты познания берут свое начало в дви- гательном поведении и действии. В вычислительном подходе мы можем использовать представление на основе действий в нескольких временных масштабах для иерархического подхода к пониманию сцены. На ранних иерар хических уровнях находятся статические компоненты, объекты, люди и простые движения конечностей. Затем они объединяются во все более сложные понятия, включающие взаимодействие между компонентами сце- ны. Действия во времени объединяются структурированным образом в це- почки, образующие деятельность. Использование представлений, основанных на действиях, в методах вы- числительного восприятия является сложной задачей. Классический подход к компьютерному зрению заключается в распознавании составляющих сце- ны исключительно по их внешнему виду. Однако аспекты сцены, связанные с действием, часто носят семантический и реляционный характер и не связаны напрямую с внешним видом физического объекта. Чтобы лучше моделировать взаимодействия, требуются более сложные архитектуры, которые не только моделируют внешний вид, но и используют более осмысленное понимание промежуточной семантической и реляционной структуры дейст вия на входе. Классические модели со сквозным обуче нием все хуже работают по мере роста пространства входных состояний, как это происходит в случае ви- деороликов и действий при увеличении их продолжительности. Это свя- зано с увеличением изменчивости внешнего вида, что создает проблемы как с данными, так и с моделированием. Для масштабирования задачи не- обходим более когнитивный подход, который моделирует не внешний вид, а структуру действий, составляющих деятельность. Основным преимуществом подхода к интерпретации сцены на основании действий является обобщение, т. е. способность распознавать специфиче- ские характеристики сцены помимо тех, которые визуально наблюдаются в обучаю щей выборке. Например, если мы сможем понять, что делает объ- ект пригодным для резки, это позволит нам распознать новые виды режу - щих инструментов, такие как аляскинский улу, хотя этот объект отсутствует в нашем обучающем наборе. Точно так же, если мы можем интерпретиро- вать наблюдаемую человеческую деятельность, понимая взаимодействие составляющих действий и выделяя основную цель, мы можем построить более робастную модель. Отдельные составляющие сцены может быть труд- но распознать из-за окклюзии, размера, неблагоприятных углов обзора или изменчивости внешнего вида и движений, но рассуждения о когнитивной правдоподобности деятельности помогают исправить ошибки классифика-\n--- Страница 477 ---\n476  Обучение пониманию сцены на основании действий ции. Кроме того, моделирование действий дает возможность предсказывать более отдаленное будущее. В этой главе представлены подходы и концепции, основанные на глубоком обучении и компьютерном зрении, ориентированных на действия. Теперь мы вкратце изложим содержание оставшейся части этой главы. Раздел 11.2 посвящен аффордансам1 – различным описаниям объектов, основанным на действиях. Аффордансы вызвали большой интерес в об- ласти зрения роботов. Но и классическое невоплощенное компьютерное зрение может выиграть от использования аффордансов. Они показывают, как можно использовать различные объекты в сцене, и являются важным компонентом понимания действия. Аффордансы несут информацию о воз- можных совпадениях наблюдаемых объектов, людей и других составляющих сцены. Раздел 11.2 охватывает наиболее известные работы по этой теме, в том числе ранние исследования, объясняющие аффордансы с по мощью гео- метрических измерений, изучающие карты аффордансов с использованием алгоритмов обнаружения объектов и семантической сегментации на картах глубины и геометрических характеристик, а также исследования, в которых аффордансы сочетаются с другими аспектами для распознавания действия. Раздел 11.3 посвящен в первую очередь нашей собственной работе по по- ниманию манипулятивной деятельности. Мы утверждаем, что интерпрета- ция деятельности должна осуществляться как непрерывное взаимодействие между процессами рассуждения и восприятия. Деятельность моделируется иерархически. На нижнем уровне находятся модули объектов, действий, про- странственных отношений и т. д., которые на более высоком уровне объеди- няются посредством грамматической формулы. В этом разделе будут описа- ны грамматика и избранные модули, формирующие понимание, основанное на действиях. Раздел 11.4 посвящен методам, которые могут обеспечить более тесную интеграцию внешнего вида, семантических и реляционных ограничений. Мы рассматриваем интеграцию в контексте задачи обуче ния без ознаком- ления. Мы начнем с рассказа о простых методах, использующих сконструи- рованные атрибуты, и перейдем к более сложным подходам, включающим слияние языка и видения через общие пространства представления, сбор семантической и реляционной информации. Далее следует обсуждение того, как эти концепции могут быть примене- ны к пониманию действия и деятельности в разделе 11.5, и выводы в раз- деле 11.6. 11.2. аффордансы объе КтоВ Психолог Джеймс Гибсон ввел термин аффорданс (Gibson, 1977), обознача- ющий возможности действия, которые объект предоставляет в рамках фи- 1 Аффорданс (affordance) – визуально определяемое свойство предмета или объекта окружающей среды, которое позволяет использовать его определенным образом. Например, дверной проем позволяет войти в комнату, а молоток позволяет забить гвоздь. – Прим. перев.\n--- Страница 478 ---\nАффордансы объектов  477 зических возможностей человека или животного. Например, нож позволяет человеку «резать», «колоть», «тыкать», «метать» и т. д. В последнее время по- нятие аффорданса вызывает большой интерес в литературе по когнитивной науке и нейронауке, поскольку данные визуализации мозга показали, что инструменты наблюдения активируют двигательные области мозга (обзор в Martin, 2007). Эту концепцию исследовали в различных областях, включая психологию развития, промышленный дизайн, науку о спорте и взаимодей- ствие человека с компьютером. Было предложено множество интерпретаций понятия аффорданса и мнений о его значении. Большинство исследовате- лей различают «аффорданс» и «функцию», причем первое означает свойства объектов, а второе относится к роли, которую объект играет в достижении какой-либо цели. Например, у ручки чашки есть аффорданс «взять», а ее внутренняя часть реализует функцию «вмещение налитого», в то время как электрическая вилка реализует функцию «питания кухонных приборов» или «зарядки телефона», а водопроводный кран поддерживает функцию «на - ливания» воды. Однако строгого формального определения не существует, и граница между этими понятиями остается размытой1. В этом разделе мы сначала объясним использование аффордансов в компью терном зрении (раздел 11.2.1). Затем предложим вашему вниманию обзор работ, представленных в различных публикациях: раздел 11.2.2 отно- сится к более ранним подходам, которые использовали геометрические ха- рактеристики, вычисленные из трехмерных данных, для классификации аф- фордансов стульев или предметов повседневного обихода. В разделе 11.2.3 описаны работы по изучению аффордансов объектов и их частей с исполь- зованием алгоритмов распознавания компьютерного зрения, применяемых к данным глубины или картам геометрических признаков. В разделе 11.2.4 представлены методы, использующие аффордансы вместе с другими детек - торами для распознавания сцен и действий, а также подходы, изучающие аффордансы для воплощенных агентов. Раздел 11.2.5 завершает обзор опи- санием перспектив дальнейших исследований. 11.2.1. Зачем аффордансы нужны компьютерному зрению? Взгляд на объекты и сцену с точки зрения аффордансов дает информацию для визуальной интерпретации сцены, которая дополняет классические подсказ- ки и помогает повысить надежность и обобщаемость усвоенных представ- лений. Эта информация касается «действуемости», которую сцена представ- ляет в нескольких пространственных и временных масштабах, относящихся к объектам, группам объектов и всей пространственно-временной сцене. 1 Например, можно сказать, что возможность воткнуть вилку в розетку – это аф- форданс вилки (и розетки тоже), а подача электричества на бытовой прибор – это ее функция (назначение). В самом деле, мы ведь не создавали вилку только ради возможности воткнуть ее в розетку. Но не всегда разница между аффордансом (возможностью) и функцией (назначением) столь очевидна. – Прим. перев.\n--- Страница 479 ---\n478  Обучение пониманию сцены на основании действий Следовательно, аффордансы предоставляют информацию и ограничения для понимания сцены как в настоящем, так и в проекции на будущее, тем самым способствуя распознаванию в дополнение к предсказанию, как подробно описано далее. Модели аффордансов, обученные на наборах объектов, можно перенести на новые категории объектов. Иными словами, если модули распознавания научились узнавать аффорданс, они могут обнаруживать его в объектах, ко- торых раньше не видели, например даже в камне, обладающем нужными свойствами. Это связано с тем, что использование объекта зависит от его физических свойств, таких как его форма, размер, материал и вес (Hermans et al., 2011), и мы можем разработать процессы, которые извлекают эти фи- зические свойства из изображений, карт глубины и других модальностей, не зависящих от ранее встречавшихся категорий объектов. Напротив, клас - сификация объектов на изображениях традиционным способом глубокого обуче ния не дает понимания того, как визуальные характеристики, такие как аффордансы, связаны с объектом. Аффордансы предоставляют ценную информацию для понимания ви- зуальных объектов, например для понимания «действительной функцио- нальности» объектов (Hassanin et al., 2018) – скажем, в перевернутую чашку нельзя налить чай, а на сломанном стуле нельзя сидеть (Grabner et al., 2011). Другим примером является поиск подкатегорий классических категорий визуальных объектов, например сортировка стульев для различных целей (Stark, Bowyer, 1991). Поскольку аффордансы отражают возможные действия, которые можно выполнить с объектом, они несут ценную информацию для прогнозирова- ния будущих действий (Koppula, Saxena, 2015; Qi et al., 2018), так как дей- ствия связаны друг с другом во времени. Например, хлебный нож в целом представляет собой аффордансы «взять в руку» и «резать», позволяющие выполнить действие «нарезка хлеба», а оно, в свою очередь, является ча- стью деятельности «подготовка корзинки с хлебом», состоящей из несколь- ких действий, распределенных во времени в строго определенном поряд- ке. Знание о возможности выполнить действие «нарезка хлеба» позволяет сделать предположение о возможных последующих действиях, например о том, что корзинку с хлебом поставят на стол. Подводя итог, можно ска- зать, что аффордансы и функциональные возможности на уровне объек - та также содержат информацию о возможных взаимодействиях объектов, пространственно-временных отношениях и действиях в более длительных интервалах времени. Моделирование этих отношений для извлечения яв- ных или неявных связей в различных временных масштабах и на разных семантических уровнях абстракции имеет большое значение для задачи понимания деятельности. Концепция аффордансов занимает центральное место в машинном зрении роботов и в исследованиях парадигмы активного видения (Bajcsy, 1988). Автор этой парадигмы выступает за то, чтобы видение систем не считалось пассив- ным процессом. Биологические системы «двигают глазами, чтобы выбрать то, что они видят» в процессе активного зрения. Точно так же искусственные\n--- Страница 480 ---\nАффордансы объектов  479 воплощенные1 системы (embodied systems) должны иметь возможность из- менять точку зрения своих камер, чтобы выбирать, какую информацию со- бирать из окружающей среды, поскольку разные точки зрения представляют разную информацию. Идя дальше, парадигма также предполагает, что вопло- щенные системы должны избегать использования сложных процессов обще- го зрения для всех целей и обрабатывать только информацию, необходимую для решения поставленной задачи (Fermüller, Aloimonos, 1995). Поэтому, когда робот или искусственная система взаимодействует с объектами, часто бывает эффективнее вычислить, для чего может быть использован объект, т. е. вычислить его аффорданс и как его можно использовать, а не класси- фицировать объект в соответствии с нашими языковыми представлениями. Таким образом, хотя преимущества аффордансов, обсуждаемые в этом раз- деле, применимы к классической пассивной формулировке компьютерного зрения, в которой агент не взаимодействует с окружающей средой, большая часть исследований аффордансов посвящена зрению роботов. 11.2.2. Первые исследования на тему аффордансов Аффордансы связаны с действиями. Как следствие они также основаны на физических величинах, связанных с действием. Например, объект, на кото- ром можно сидеть, или объект, в который можно налить воду, имеют опреде - ленные физические характеристики, такие как форма, размер или материал и т. д. Все ранние методы использовали такие явные физически значимые представления в модулях распознавания возможностей. В ранних исследованиях использовали форму и геометрию. Старк и Бойер (Stark, Bowyer, 1991) предложили первый основанный на аффордансах под- ход к распознаванию объектов с использованием 3D-моделей САПР в качест - ве входных данных. Граф знаний, похожий на дерево решений, применялся для классификации стульев и подкатегорий стульев (например, обычный стул, качалка, стульчик для кормления, кресло для отдыха), а листьями графа были процедуры классификации геометрических признаков. Эти признаки включали относительную взаимную ориентацию поверхностей, размер объ- екта, стабильность и близость поверхностей. Грабнер и др. (Grabner et al. 2011) выделили поверхности, соответствующие аффордансу «сидеть», сравнив геометрию трехмерной модели человеческого скелета в сидячей позе с геометрией объекта. В число признаков входят рас - стояние и пересечение сетки сплайнов человека с сеткой объекта. Детектор был оценен на моделях Google Warehouse, а также на реальных 3D-данных, собранных с по мощью времяпролетной камеры. Для лучшей точности метод был объединен с классификатором на основе изображений. Аналогичным об- разом Гупта и др. (Gupta et al., 2011) смоделировали аффордансы в 3D-сценах 1 Термин воплощенные (embodied) в данном контексте можно считать синонимом понятий «очеловеченные», «человекообразные» (в когнитивном смысле). – Прим. перев.\n--- Страница 481 ---\n480  Обучение пониманию сцены на основании действий в помещении, обнаружив области пространства, которые позволяют челове- ку использовать его для одной из трех функций: «лежать», «сидеть прямо» и «сидеть откинувшись». Они также использовали ограничения, основанные на занимаемом трехмерном пространстве и контакте со скелетом человека. Однако их метод может принимать на вход изображения, из которых он сначала получает трехмерную геометрию с по мощью методов регрессии, основанных на обучении, таких как (Hedau et al., 2009; Lee et al., 2010). Германс и др. (Hermans et al., 2011) изучили аффордансы повседневных предметов с по мощью промежуточных представлений, которые кодируют визуальные и физические характеристики. Визуальные характеристики включали цвет, дискретную форму и текстуру, а физические характеристики включали вес и размер. В модели использовались стандартные классифика- торы; метод был продемонстрирован на семи классах аффордансов в области робототехники. 11.2.3. Обнаружение, классификация и сегментация аффордансов Задача распознавания аффордансов, связанных с объектами и поверхностя- ми сцены, концептуально сходна с задачей распознавания объектов. В ряде недавних методов для локализации и распознавания аффордансов приме- няли инструменты обнаружения, классификации, сегментации и семанти- ческой маркировки объектов. Однако эти методы обычно применялись не к изображениям, а либо к данным RGB-D, либо к картам признаков, рас - считанным на основе данных о глубине. В этом разделе мы рассмотрим не- сколько таких подходов. 11.2.3.1. Обнаружение аффордансов по геометрическим признакам В данном разделе мы рассмотрим исследование (Myers et al., 2015) – первый подход, в котором современные инструменты машинного обуче ния приме- нялись к геометрическим элементам. В этом разделе подробно описан метод обнаружения аффорданса и связанная с ним вычислительная нагрузка. В центре внимания исследования были инструменты, которые можно встретить на обычном рабочем месте, в частности обнаружение частей ин- струментов, связанных с различными аффордансами. Был собран набор данных (набор данных о доступности деталей RGB-D) из 105 кухонных, сле- сарных и садовых инструментов. Объекты помещали на поворотный столик и снимали камерой Kinect с круговым обзором 360°; всего было подготовлено около 300 кадров для каждого объекта, из которых 10 000 изображений RGB-D были аннотированы на уровне пикселей. На рис. 11.1 показаны примеры объектов для пяти из семи аффордансов, а также аннотация для одного из объектов. Следует отметить, что аффорданс связан с поверхностями, напри- мер внутренняя поверхность чашки соответствует аффордансу «вмещать», а внешняя – «обхватывать».\n--- Страница 482 ---\nАффордансы объектов  481 Размеченный эталонЧерпать ПоддерживатьУдарять ВмещатьРезать Рис. 11.1  Примеры объектов из набора данных RGB-D Part Affordance Data- set и пример полнокадрового изображения с размеченным вручную эталоном (внизу справа). Эталонные метки включают ранжирование по множеству аф- фордансов (Myers et al., 2015) Из необработанных данных о глубине по фрагментам вычислялись при- знаки формы, в частности нормаль к поверхности, основная кривизна, ин- декс формы и дескриптор HoG-Depth (гистограмма градиентов глубины). Исходя из того, что эти признаки являются входными данными, были пред- ложены два подхода к классификации: во-первых, структурированный слу- чайный лес (structured random forest, SRF), который создает точечную класси- фикацию; и второй алгоритм S-HMP (superpixel hierarchical matching pursuit, иерархическое сопоставление суперпикселей) (Bo et al., 2013). Последний работает, сначала пересегментируя изображение RGB-D в суперпиксели. За- тем, с по мощью метода обуче ния по словарю, признаки формы разреженно кодируются в нескольких масштабах на суперпиксель. Наконец, выполня- ются max-пулинг признаков в суперпиксели и классификация с по мощью SVM. Примеры результатов показаны на рис. 11.2 как для метода S-HMP , так и для метода SRF, где уровень серого отражает вероятность присвоения аффорданса. В упомянутом подходе есть два вычислительных аспекта, которые заслу - живают особого внимания. Во-первых, что иногда упускают из виду, назна- чение аффордансов поверхностям объектов в целом не может быть уникаль- ным. Одна и та же часть объекта может использоваться для разных целей. Таким образом, присвоение аффордансов является задачей многоклассовой разметки. Майерс и др. (Myers et al., 2015) решили эту проблему за счет того, что несколько экспертов-аннотаторов ранжировали, насколько близки дру - гие аффордансы по отношению к рассматриваемым базовым аффордансам, на основании чего была получена порядковая шкала присвоения аффордан- сов при тестировании. Во-вторых, основным преимуществом подхода является его хорошее обоб- щение на новые объекты и поверхности. На рис. 11.2 (внизу) можно увидеть, что дно чашки ассоциируется с аффордансом «ударять», а край шпателя – с аффордансом «резать». Так происходит, потому что форма объектов ука- зывает на эти свойства. Но одной лишь формы было бы недостаточно для классификации аффордансов в реальной прикладной системе. Необходимо\n--- Страница 483 ---\n482  Обучение пониманию сцены на основании действий добавить дополнительные свойства, самое очевидное из которых – материал. Благодаря этому система сможет понять, что бумажный стаканчик нельзя использовать для забивания гвоздей, а предмет с мягким краем нельзя ис - пользовать для резки. Метод S-HMP Метод SRF Вход RGB-D Содержать Содержать Обхватывать-брать Обхватывать-брать Черпать Ударять Резать Рис. 11.2  Вверху: результаты обнаружения аффордансов в трех входных кад рах RGB-D с использованием метода S-HMP и SRF в загроможденной после- довательности для целевых аффордансов «вмещать» и «обхватывать-брать». Более яркие пиксели означают более высокую вероятность целевого аффор- данса (Myers et al., 2015). Внизу: демонстрация обобщения на новые объекты для метода SRF: дну чашки присвоена высокая вероятность аффорданса «уда- рять», а краю шпателя – «резать» 11.2.3.2. Семантическая сегментация и классификация по изображениям Многие из работ, последовавших за (Myers et al., 2015), использовали ней- росетевые подходы, применяя в качестве входных данных карты геометри- ческих объектов. Таким образом, обнаружение аффордансов на уровне пик - селей превратилось в задачу семантической маркировки. Однако, в отличие\n--- Страница 484 ---\nАффордансы объектов  483 от исходного метода, эти подходы часто использовали в качестве входных данных 2D-изображения. На этапе предварительной обработки карты глуби- ны или карты объектов регрессировали с по мощью нейронных сетей. Кроме того, некоторые исследователи рассматривали естественные изображения с несколькими объектами и использовали алгоритмы обнаружения объектов для локализации объектов, прежде чем назначать аффордансы. Например, Нгуен и др. (Nguyen et al., 2017) создали набор данных с деся- тью категориями объектов и девятью категориями аффордансов из области домашнего хозяйства и мастерской. Он состоит как из сканов RGB-D, так и из естественных изображений (подмножество ImageNet (Russakovsky et al., 2015)) – для последних карты глубины были созданы с использованием CNN- подхода Liu et al. (2015). Изображения были аннотированы ограничивающи- ми рамками и аффордансами на уровне пикселей. В методе из упомянутой статьи сначала применялся детектор объектов, затем в каждом регионе вы- числялись аффордансы с использованием модифицированной сети VGG-16, обученной семантической маркировке, и, наконец, значения аффордансов подвергались постобработке с по мощью CRF. Шриканта и Галл (Srikantha, Gall, 2016) использовали набор данных Коп- пулы и Саксены (Koppula, Saxena, 2014), который содержит богатую кон- текстную информацию с точки зрения взаимодействия человека с объектом, и разметили его с по мощью аннотаций аффордансов на уровне пикселей. В работе изучались различные уровни обуче ния семантической сегментации с использованием глубокой сверточной нейронной сети в рамках схемы мак - симизации ожиданий, чтобы использовать в качестве контекста слабо раз- меченные данные, такие как аннотации уровня изображения или аннотации ключевых точек, а также позу человека. Рой и Тодорович (Roy and Todorovic, 2016) работали со сценами в помеще- нии из набора данных Нью-Йоркского университета (Silberman et al., 2012). Их метод сначала выводит карту глубины, нормали поверхности и семанти- ческую сегментацию грубого уровня с использованием многомасштабной CNN в качестве сигналов среднего уровня, которые затем совместно пода- ются в качестве входных данных в другую многомасштабную CNN для прог - нозирования карт аффордансов. Йе и др. (Ye et al., 2017) разработали метод локализации и распознавания функциональных зон в сценах внутри помещений. Для категоризации об- ластей изображения была определена онтология, как показано на рис. 11.3 (слева), в соответствии с их аффордансом или функциональностью. Ка- тегории включают в себя: «открыть сферическим захватом» (например, дверная ручка), «открыть полным захватом или перетащить, чтобы от - крыть» (например, дверца духовки), «включить электричество» (например, выключатель света) и т. д., как показано в предпоследнем столбце рисунка. Набор данных содержит 500 изображений кухонь из набора данных SUN (Xiao et al., 2010), которые были тщательно размечены. Метод сначала за- пускает детектор на основе CCN, обученный обнаруживать область, а затем классификатор на основе архитектуры VGG. На рис. 11.3 (справа) показаны примеры результатов.\n--- Страница 485 ---\n484  Обучение пониманию сцены на основании действий Онтология функциональной областиФункцион. область Небольшая часть мебели/ прибора/ стены Предметы (сосуды и инстру - менты) МебельОсновная функция Открыть Переместить Использова - ние мебелиМанипули- роватьВключить/ выключитьСимвол Цветовой кодКонечная категория Сферическая хват - ка для открывания Две руки поднима - ются и двигаются Сесть, поставить и т. д.Работа с удлинен ны- ми инструментамиЗажать, чтобы двигатьПодцепить для перемещенияЦилиндрический за- хват для перемещенияОбхват для открывания Вкл./выкл. электричество Вкл./выкл. воду Вкл./выкл. огонь Рис. 11.3  Слева: функциональная онтология; справа: пример результатов обнаружения (Ye et al., 2017) 11.2.4. Аффорданс в контексте распознавания действий и обучения роботов В этом разделе мы выделяем несколько подходов, в которых применяют аф- фордансы в сочетании с другими величинами для понимания сцены и дей- ствия. Затем обсудим подходы, направленные на изучение аффордансов роботами. 11.2.4.1. Распознавание действий Аффордансы кодируют признаки возможных взаимодействий человека с окружающей средой. Следовательно, они естественным образом обеспечи- вают связку между различными свойствами сцены в пространстве-времени, например между различными объектами или между объектами и действия- ми. Ряд исследований опирался на эту идею и использовал отношения между аффордансами в качестве контекста для распознавания и прогнозирования активности и действия. В этих методах использовались различные модели для кодирования взаимосвязей между разными вовлеченными объектами, включая CRF, MRF, And-Or-Graphs и вероятностные автоматы состояний. Кьеллстрём и др. (Kjellström et al., 2011) исследовали проблему изучения взаимодействий действие–объект на демонстрационном примере, в кото- ром они задействовали аффордансы. Действия рук были классифицированы в контексте объектов, которыми манипулируют, с использованием модели CRF, получающей в качестве входных данных объект и признаки рук. Объ- екты были смоделированы с использованием созданных вручную признаков, а действия – с по мощью общей скорости руки, ориентации и углов сустава, которые были рассчитаны на основе результатов трехмерной реконструкции руки и метода отслеживания. Коппула и др. (Koppula et al., 2013) рассмотрели проблему изучения после- довательностей субактивностей (subactivty, группы действий), выполняемых\n--- Страница 486 ---\nАффордансы объектов  485 людьми, и их взаимодействия с объектами. Они совместно смоделировали человеческую деятельность и аффордансы объектов в марковском случайном поле, где узлы представляют объекты и субактивности, а ребра – отношения между аффордансами объектов, их отношения с субактивностями и их эво- люцию во времени. Отношения аффорданс–субактивность рассчитывались на основе относительных геометрических характеристик между объектом и суставами скелета человека, а аффордансные отношения между объекта- ми – на основе пространственных отношений. Описанный подход был про- демонстрирован на примере робота PR2 при выполнении вспомогательных задач. Коппула и Саксена (Koppula, Saxena, 2015) добавили в марковскую модель также возможные будущие состояния, чтобы предсказать следующее действие. Ци и др. (Qi et al., 2017) использовали пространственно-временной граф «И-ИЛИ» (spatial-temporal AND-OR Graph, ST-AOG) для представления струк - туры деятельности и прогнозирования будущих действий во входном видео- сигнале RGB-D. Их модель иерархична: субактивности моделируются чело- веческими действиями, объектами и их аффордансами в пространственных графах, а стохастическая грамматика, определенная для субактивностей, кодирует деятельность. Дутта и Зелинска (Dutta, Zielinska, 2017) также рас - смотрели проблему прогнозирования следующего действия на основе аф- фордансов объектов и человеческого взаимодействия. Они использовали пространственно-временные вероятностные автоматы состояния для мо- делирования взаимодействий. В дополнение к классу действия они также вычислили возможную траекторию действия. В зависимости от того, где объ- ект находится относительно человека, он имеет разные аффордансы, и его ориентация и расстояние до возможных траекторий действий кодируются в виде карт интенсивности в зависимости от аффорданса. 11.2.4.2. Изучение аффордансов в зрении роботов Понятие аффорданса было ключевой концепцией в области нейроробототех - ники, целью которой является изучение когнитивных функций роботехниче- ской системы, тело которой помещено в окружающую среду. Речь идет о том, что роботы приобретают все более сложные навыки, используя восприятие и взаимодействие с окружающей средой. Благодаря взаимодействию робо- ты изучают аффордансы и строят на их основе иерархическое понимание действий, деятельности и окружающей среды. Это исследование в области саморазвивающейся робототехники стало возможным благодаря разработке роботизированных платформ, наиболее известной из которых является че- ловекоподобный робот iCub (Metta et al., 2008). В работе (Fitzpatrick et al., 2003) авторы обсудили три основных этапа са- моразвития робота: (1) изучение образа тела, (2) изучение взаимодействия с внешними объектами и (3) изучение интерпретации взаимодействия объ- ект–объект. Аффордансы занимают центральное место на последних двух эта- пах. Робот-гуманоид посредством толкающих и тянущих действий в разных направлениях научился взаимодействовать с окружающей средой, а наблю- дая за движениями затронутых объектов, изучил аффордансы. Например, он\n--- Страница 487 ---\n486  Обучение пониманию сцены на основании действий узнал, что сферический объект может катиться, а прямоугольный – скользить. Наконец, робот также научился повторять наблюдаемое действие. Точно так же авторы Montesano et al. (2008) определили три основных этапа в архитектуре развивающегося робота-гуманоида: сенсорно-мотор- ную координацию, взаимодействие с миром и подражание. Аффордансы играют центральную роль во взаимодействии с миром. При таком подходе система начинала с базовых зрительных и моторных навыков, из которых с по мощью алгоритмов кластеризации приобретались более сложные зри- тельные и моторные навыки. Затем во время взаимодействия наблюдались эффекты с по мощью восприятия, такие как изменения положения объекта, скорости и тактильного восприятия. Байесовская сеть использовалась для изучения аффордансов, которые в данном случае были закодированы как ве- роятностные отношения между действиями и восприятиями (характеристи- ки объекта и эффекты). Было продемонстрировано, что система имитирует действия людей, выполняя движения с аналогичным эффектом. Угур и др. (Ugur et al., 2011) также продемонстрировали возможность обуче - ния робота объектам посредством взаимодействия и самонаблюдения. На первом этапе робот обнаружил общие черты в своих действиях и эффектах, обнаружив категории эффектов. Опираясь на это, на втором этапе были по- лучены предикторы аффордансов для различного поведения путем изучения сопоставления характеристик объекта с категориями эффектов. В следующей работе Угур и Пиатер (Ugur, Piater, 2016) пошли еще дальше и изучили меха- низмы, обеспечивающие иерархическое структурирование задач изучения аффордансов. Руководствуясь внутренними соображениями, робот начал с простых задач и, опираясь на свои знания о взаимодействиях, постепенно осваивал более сложные задачи, выбирая для исследования объект и дей- ствие, наиболее отличающиеся от ранее изученных. В экспериментах робот мог вычислять визуальные характеристики размера объекта, форму участка поверхности и нормали к поверхности, а его действия заключались в том, чтобы тыкать в объекты с трех разных направлений и складывать их друг на друга. На более ранних этапах он исследовал действие тыкания, чтобы наблюдать его влияние на отдельные объекты. Опираясь на полученные зна- ния, на следующем этапе он исследовал размещение одного объекта поверх другого и возникающие в результате эффекты. 11.2.5. Промежуточный итог – изучение аффордансов В этом разделе обсуждались подходы к изучению аффордансов, многие из ко- торых относятся к области зрения роботов и были реализованы с небольшим количеством образцов и ограниченным объемом данных. До сих пор в исследо - ваниях, посвященных аффордансам, относительно мало использовали подходы глубокого обуче ния. Основная причина – отсутствие больших аннотированных наборов данных в этой области, необходимых для глубокого обуче ния. Однако мы ожидаем, что по мере того, как исследования будут продви- гаться от глубокого обуче ния с учителем к методам обуче ния без учителя\n--- Страница 488 ---\nФункциональный анализ манипуляций  487 и самообучения, мы увидим подходы, основанные на концепции аффор - дансов и наблюдаемых взаимодействий между людьми и объектами. Этому будут способствовать новые специализированные наборы данных, такие как набор данных EPIC Kitchens, в котором представлены различные действия по манипулированию объектами в естественных сценах (Damen et al., 2018). Аффордансы и функциональные возможности на уровне объекта также заключают в себе информацию о возможных взаимодействиях объектов, пространственно-временных отношениях и возможных действиях в более длительной перспективе. В разделе 11.2.4 мы обсудили методы, использую- щие аффордансы для моделирования действий. Однако в дальнейшем имеет смысл построить модель отношений, чтобы получить явные или неявные отношения в более длительных масштабах времени для решения задачи по- нимания деятельности, о которой пойдет речь в разделе 11.3. Наконец, мы можем использовать аффордансы при создании отображе- ний от восприятия к действию для обуче ния роботов. Люди могут научиться манипулятивным действиям, используя только свое восприятие. Когда мы видим, что кто-то выполняет действия с незнакомым нам инструментом, мы можем понять возможности этого инструмента и выполнить то же самое действие. Точно так же мы могли бы подойти к обуче нию моторики роботов, используя восприятие и действие в тесной петле, обосновывая их аффордан- сами, чего еще не делалось раньше. Робот будет изучать задачу, наблюдая за действием и аффордансами и выдавая команды (на основе своего существу - ющего набора навыков, ограниченного аффордансами), чтобы генерировать действие, близкое к наблюдаемому, а затем постепенно адаптироваться для улучшения качества. Предложенная исследовательская задача фактически представляет собой разработку методов самообучения и обуче ния с под- креплением, на основании представлений аффордансов. 11.3. фунКциона Льный ана Лиз манипу Ляций В этом разделе описывается работа – в основном нашей исследовательской группы – по интерпретации манипулятивной деятельности. Опираясь на парадигму воплощенного познания (Варела и др., 1993), в этой работе мы рассматриваем понимание человеческой деятельности как процесс, вклю- чающий восприятие, познание и двигательную систему. Основными ком - понентами являются формализованные способы объединения различных модальностей и модули компьютерного зрения для получения семантически значимых дескрипторов действия. 11.3.1. Активное взаимодействие между познанием и восприятием Понимание человеческих действий и деятельности является наиболее слож - ной задачей, изучаемой в настоящее время в области компьютерного зрения.\n--- Страница 489 ---\n488  Обучение пониманию сцены на основании действий Эта задача относится не только к видению. Люди могут понять, что делают другие, потому что у них есть модели действий и деятельностей. Они пони- мают цели действий, и это позволяет им интерпретировать свои наблюдения, несмотря на обширный спектр вариантов действий и условий, в которых они наблюдаются. Знание (в той или иной форме) включается в процесс толко- вания на раннем этапе. Человеческое поведение является активным и исследовательским. Мы по- стоянно перемещаем взгляд в разные места сцены. Мы распознаем объекты и действия, и это, в свою очередь, заставляет нас фиксировать внимание на новых местах. В этом процессе восприятие непрерывно взаимодействует с познанием на разных уровнях абстракции, чтобы направлять внимание, делать прогнозы, ограничивать пространство поиска для распознавания и рассуждать о том, что воспринимается. Мы называем это взаимодействие между непосредственным восприятием и процессами более высокого уровня когнитивным диалогом (Aloimonos, Fermüller, 2015), поскольку оно представ- ляет собой итерацию вопросов и ответов, при этом когнитивные или линг - вистические процессы задают вопросы о том, что и где находится на сцене, а визуальные процессы выполняют локализацию, обнаружение, распозна- вание и реконструкцию. Одним из простых способов выбора следующего вопроса может быть использование теоретико-информационных критериев (Yu et al., 2011). Логические построения могут быть реализованы с по мощью стратегии, основанной на знаниях (Aditya et al., 2018), или с использованием языка. В этом плане компьютерное зрение вызывает особый интерес, поскольку оно позволяет ввести в процесс интерпретации дополнительные знания об отношениях изображений на более высоком уровне. В то время как в одних исследованиях извлекают эту дополнительную информацию из заголовков или сопроводительного текста, в других (как будет сказано в разделе 11.4) используют расширенную обработку естественного языка для получения дополнительной информации высокого уровня. В текущих исследованиях в качестве языкового представления чаще всего используется пространство word2vec (Mikolov et al., 2013) (раздел 11.4.3), которое кодирует сходство лингвистических понятий. В качестве альтернативы можно использовать старые, созданные вручную ресурсы, кодирующие лексическую семантику, например базу данных Word-Net (Miller et al., 1990), которая связывает слова через синонимию (слова, имеющие одинаковое значение, например «бить» и «ударять») и гипернимию (отношения «представляет собой», как, например, между «автомобиль» и «транспортное средство»). В этом отношении особен- но интересна сеть Verbnet (Schuler, 2005), организующая классы глаголов для понимания действия. 11.3.2. Грамматика действий Для кодирования отношений между различными семантическими поня- тиями, то есть между действующими лицами, объектами, глаголами, про- странственно-временными отношениями и атрибутами, традиционно при-\n--- Страница 490 ---\nФункциональный анализ манипуляций  489 меняются различные механизмы. В разделе 11.2 обсуждалось использование графов «И-ИЛИ» и марковских моделей. К альтернативным механизмам от - носятся логические сети Маркова (Tran, Davis, 2008) и средства планирования (Guha et al., 2013). В этом разделе мы описываем применение грамматик (grammar), которые могут фиксировать состав наблюдаемых действий в виде последовательностей, составляющих сцены и их рекурсивную структуру. Основная причина использования грамматик связана с идеей о том, что на- блюдаемые в видео действия имеют синтаксическую структуру. Зная цель дей- ствий, видео можно разбить на осмысленные сегменты, а эти сегменты можно организовать в виде простой грамматики. Иными словами, интерпретация действия, происходящего в видео, подобна пониманию предложения, кото- рое мы читаем или слышим. Чтобы разбить видео на примитивные действия, составляющие сложные задачи, сегменты видео сопоставляются с определен- ными символами, включающими объекты, инструменты, движение и про- странственные отношения. Важно отметить, что грамматика действия при сегментации видео исходит из понятия контакта, то есть момента времени, когда рука касается объекта или отпускает его, или когда объекты сливаются или разделяются. В эти моменты начинается новое поддействие. При при- менении грамматики для анализа видео создается дерево синтаксического анализа, которое мы называем деревом деятельности (activity tree). Эта кон- цепция наглядно представлена на рис. 11.4. Из видеозаписи человека, выпол- Правая рука Правая рука РучкаЛинейкаДоска + рукиЛевая рука Левая рука Левая рука + линейка Ручка + правая рукаЛевая рука + линейка + доска Руки + линейка + доска + ручкаДоска Доскаобхватить обхватить обхватитьвыровнить провести линиюдвигать двигатьотпустить Рис. 11.4  Иллюстрация описания деятельности. Камера следила за тем, как человек отпиливает доску. Четыре параллельных процесса вычисляют основные компоненты: обнаружение руки и классификация типа захвата (слева вверху), грубое определение движения посредством подгонки скелета (справа вверху), сегментация объекта (слева внизу), трехмерное описание сцены (справа внизу)\n--- Страница 491 ---\n490  Обучение пониманию сцены на основании действий няющего действие «отпиливание доски», создается граф, в котором узлы рук, предметов и инструментов сливаются в общий узел, когда они соприкасаются, или узлы расходятся, когда предметы и руки расходятся. Представленные на рисунке различные процессы (показаны в четырех квадрантах видеокадров) извлекают тело человека, руки, объекты и геометрические отношения. Далее мы рассмотрим несколько грамматических методов в разде- ле 11.3.2.1, а затем обсудим в разделе 11.3.2.2, являются ли такие граммати- ческие представления достаточно выразительными, чтобы уловить действие и структуру деятельности, и достаточно ли они экономичны в вычислитель- ном отношении, чтобы их можно было предпочесть другим представлениям. 11.3.2.1. Различные реализации грамматики Описания основаны на контекстно-независимых грамматиках (context- free grammar), первоначально представленных в (Pastra, Aloimonos, 2012). Саммерс-Стей и др. (Summers-Stay et al., 2012) реализовали идею анализа комплекса действий из видео RGB-D с использованием только одного симво - ла для всех действий, а (Yang et al., 2014) расширили описание, включив в него «захват» и разграничив контакт «рука–объект» и контакт «объект–объект». Грамматика описывает действия на уровне абстракции, который полезен как для интерпретации видео, так и для выполнения действий роботом. В работе (Yang et al., 2015) это было продемонстрировано на нескольких примерах. Путем автоматического анализа видео с инструкциями по приготовлению пищи из набора данных Youcook (Das et al., 2013) были проанализированы действия, которые затем были выполнены роботом Baxter, обладающим не- обходимыми двигательными возможностями. Абстрактные описания действий/глаголов необходимы для достижения обобщения и выполнения того, что в современной терминологии называ- ется обуче нием за несколько шагов, или обуче нием без ознакомления (см. раздел 11.4). Базовая грамматика действия сводит описание действий только к последовательности «отношений прикосновения», то есть когда рука касает - ся предмета, соприкасаются два предмета, рука отпускает предмет или когда два предмета или части одного предмета разделяются (Dessalene et al., 2021). Вёргёттер и др. (Wörgötter et al., 2013) уточнили эту концепцию, чтобы сфор- мулировать онтологию с учетом действий одной рукой. На первом уровне действия классифицируются по шести классам в соответствии с последова- тельностью отношений, которые могут иметь рука и один или два объекта: переставить, уничтожить, сломать, опрокинуть, спрятать, создать. Исходя из этих классов, они повторяют возможные действия и придумывают около 30 ос - новных манипуляций. Янг и др. (Yang et al., 2013) предложили родственную концепцию. Они разбили действия на метаклассы в соответствии с послед- ствиями действия для объекта, то есть тем, что происходит с объектом геомет - рически или топологически. Они предложили шесть категорий – разделить объект, объединить две части, перенести объект, деформировать объект, объ- ект появляется, объект исчезает со сцены, – а также предоставили алгоритмы, которые сочетают отслеживание с сегментацией для обнаружения топологи- ческих изменений, свидетельствующих об основных событиях в видео.\n--- Страница 492 ---\nФункциональный анализ манипуляций  491 11.3.2.2. Являются ли грамматики выразительными и лаконичными описаниями? Важный вопрос заключается в том, действительно ли грамматические пред- ставления достаточно богаты, чтобы можно было классифицировать многие виды деятельности. Авторы статьи (Wörgötter et al., 2020) провели психофи- зические и вычислительные эксперименты, чтобы ответить на этот вопрос. Они описывали, как и выше, действия последовательностью контактов, ис - пользуя пять величин: «рука», «земля» и три предмета. Кроме того, они рас - смотрели десять пространственных отношений, то есть «вверху», «внизу», «между» и т. д., чтобы различать в общей сложности 35 различных конфи- гураций или действий. Подмножество из десяти этих действий (положить, встряхнуть, перемешать, взять, открыть, нарезать, разрезать, спрятать, положить и толкнуть) выполнялось в виртуальной среде, но вместо реаль- ных объектов использовались кубы. Эксперименты показали, что исследуе- мые алгоритмы могут распознавать эти действия так же, как и люди. Более того, предложенное описание оказалось очень мощным в предсказательном плане – испытуемым в среднем требовалось только 56 % продолжительно- сти описания, чтобы распознать действие. Таким образом, можно заклю- чить, что описание, основанное только на контактах и пространственных отношениях, очень эффективно для визуального распознавания действий и деятельности. 11.3.3. Модули для понимания действий Для распознавания дискретных компонентов сцены необходимы отдельные процессы зрения, которые затем можно объединить в процессы рассужде- ний более высокого уровня, такие как грамматики из раздела 11.3.2, чтобы реализовать распознавание и предсказание деятельности. Дескрипторы, которые мы обсуждаем в этом разделе, отличаются от широко описанных в литературе (обзор успешных концепций, применяемых в текущих методах, представлен в (Sigurdsson et al., 2017)). В частности, в разделе 11.3.3.1 мы обсуждаем представления захватывания, а в разделе 11.3.3.2 – явное пред- ставление геометрии. 11.3.3.1. Захватывание: важный признак для понимания действий Тип захвата предоставляет важную информацию о действиях. В качестве иллюстративного примера рассмотрим две сцены на рис. 11.5 из задачи VOC (Everingham et al., 2010). Стандартные системы компьютерного зрения имеют детекторы объектов и людей, достаточные для распознавания велосипеда и велосипедиста, а также детекторы позы для подтверждения того, что эти два велосипедиста едут на велосипеде. Но люди могут сказать, что велоси- педист с левой стороны не участвует в гонке (поскольку его руки находятся в положении «отдых или разгибание»), тогда как велосипедист справа явно\n--- Страница 493 ---\n492  Обучение пониманию сцены на основании действий участвует в гонке (поскольку руки крепко держат руль в «сжатом» положении типа «силовой цилиндрический захват»). Рис. 11.5  Упирание разогнутыми руками в руль (слева) в сравнении с силовым цилиндрическим захватом руля (справа) (Yang et al., 2015) Здесь мы рассмотрим две статьи: в первой используется базовая онтология типов захватов в задачах понимания действий, во второй изучаются тонкие изменения в захватах для различения похожих манипуляционных действий, а также разрабатываются подходы к обуче нию для прогнозирования дей- ствий в реальном времени и регрессии связанных усилий пальцев. Распознавание типа захвата дает важную информацию для более под- робного анализа действия (рис. 11.6). Исследователи в нескольких областях, включая робототехнику, медицину и биомеханику, разработали таксономии захвата, которые представляют собой иерархию наиболее распространен- ных поз рук, используемых для захвата объекта, причем каждая таксономия основана на потребностях решаемых задач в предметной области. В работе (Yang et al., 2015) использовалась базовая классификация основных функ - циональных захватов (Cutkosky, 1989) в манипуляционных задачах, затем представленная как полезная функция в двух других задачах: для сегмен- тации действий, связанных с мелкой моторикой, и для характеристики на- мерения действия, т.е. когда задача случайная либо требует навыков или сил. Когнитивные исследования показали, что намерение áктора1 формирует кинематику его движения во время выполнения движения (Ansuini et al., 2015). Например, когда испытуемые брали бутылку, чтобы налить из нее жидкость, средний и безымянный пальцы были более вытянуты, чем когда они брали бутылку с намерением сдвинуть, бросить или передать ее. Вдох - новленные этими выводами, Фермюллер и др. (Fermüller et al. (2018) разрабо- 1 Актор – действующее лицо сцены; субъект, выполняющий интересующее нас дей- ствие. – Прим. перев.\n--- Страница 494 ---\nФункциональный анализ манипуляций  493 тали архитектуру рекуррентной нейронной сети, которая отслеживает руки для прогнозирования действий. В частности, они рассматривали наборы действий с одним и тем же предметом, такие как «отжимание», «перево- рачивание», «умывание», «вытирание» и «царапание» губкой (см. рис. 11.7). Они проанализировали систему, которая в режиме реального времени пред- сказывала текущие действия, чтобы определить, в какой момент времени классификация стала точной, а также провели психофизический экспери - мент, оценивая эффективность человека при выполнении той же задачи. На 10 кадрах после контакта руки с объектом система и люди начали понимать действие (75%-ная точность классификации действий губкой), а на 25 кад- рах оценка была очень хорошей (точность 95 %). Архитектура визуальной сети представляла собой RNN, использующую в качестве входных данных отслеживаемые участки изображения вокруг руки, на основе которых были вычислены признаки VGG-16 (Simonyan, Zisserman, 2014). Силовой Силовой Цилинд- рическийЩипокСфери- ческийТройной КрюкЧерве- образный Рис. 11.6  Базовая классификация активных захватов с приме- рами (Cutkosky, 1989). На самом высоком уровне захваты подраз- деляются на силовые и точные. Силовые захваты используются, когда объект удерживается с силой, и могут быть классифициро- ваны как цилиндрические, сферические и крюкообразные. Точ- ные захваты обеспечивают точное движение и подразделяются на обхватывающие, трехпальцевые и червеобразные Кроме того, в статье также продемонстрирована связь зрения с усилиями. Были зарегистрированы данные об испытуемых, которые выполняли одно и то же действие обеими руками. На пальцах одной руки усилия регист - рировали при помощи датчиков, а другой руки – визуально. Рекуррентная нейронная сеть была обучена регрессии усилия по визуальным данным. За- тем было показано, что, используя только входное видео, когда визуальный классификатор сочетается с регрессией усилия, можно достичь улучшенной точности. Нам этот подход представляется многообещающим. Как показа- но в статье, изучение сопоставления зрительной картины с картой усилий\n--- Страница 495 ---\n494  Обучение пониманию сцены на основании действий формирует бимодальное пространство, которое помогает визуальному рас - познаванию. Кроме того, у этой концепции есть прямое применение в ро- бототехнике. В настоящее время для изучения задач роботы используют тактильные устройства или датчики силы и крутящего момента. Если мы сможем визуально предсказать силы, прилагаемые человеком-демонстра- тором, это позволит нам гораздо эффективнее обучать роботов. Подготовка захватаДействие начинаетсяДействие заканчиваетсяПрикосновение … Задержка предсказания Т predТ0 + Т pred Т0 + Т class Т0 Задержка классификации Т classПроактивный Сенсорный ввод Реактивный Рис. 11.7  Примеры, доказывающие, что начальные движения могут быть на- дежными индикаторами предполагаемых манипуляций. Раннее предсказание действий значительно снижает задержку взаимодействия в реальном времени, что принципиально важно для проактивной системы 11.3.3.2. Геометрические факторы для робастизации Использование геометрических факторов важно, поскольку они предо- ставляют надежную информацию для описания сцены и дополнительную информацию для распознавания. Геометрия объектов сцены вычисляется с использованием процессов реконструкции, которые являются низкоуров- невыми (требуются только признаки изображения и знание положения ка- меры), а обучающие данные или процесс машинного обуче ния не требуются. С появлением доступных по цене сенсоров RGB-D более десяти лет назад воссоздание геометрии сцены стало намного проще и точнее, и поэтому эти сенсоры стали стандартными датчиками зрения в робототехнике. Их исполь- зование облегчает точное и быстрое вычисление расстояний для управления движением робота, а также вычисление геометрии и формы объектов для об- легчения интерпретации сцены. В этом разделе обсуждаются три геометри- ческих метода: точное отслеживание трансформаций нежестких объектов и обнаружение топологических изменений, вычисление попарных простран- ственных отношений объектов во времени и вычисление симметрии объекта и ее использование для лучшей сегментации переднего плана и фона.\n--- Страница 496 ---\nФункциональный анализ манипуляций  495 Опираясь на эффективную библиотеку облаков точек (Zampogiannis et al., 2018), в своей следующей работе (Zampogiannis et al., 2019) авторы предло- жили методику точного отслеживания трансформаций нежестких объектов и обнаружения топологических изменений, то есть контактов и разделений частей тела и объектов, необходимых для грамматического описания (раз- дел 11.3.2). Суть метода заключается в оценке поля деформации, которая учитывает деформации между последовательными кадрами для обнаруже- ния областей деформированной геометрии, которые претерпевают тополо- гические изменения. В описании деятельности также могут пригодиться дескрипторы про - странственных отношений между объектами. В статье (Zampogiannis et al., 2015) авторы ввели представление манипуляционных действий, основанное на эволюции пространственных отношений между объектами в сцене. Ме- тод был реализован путем отслеживания объектов в видео RGB-D и выводов о пространственных отношениях наблюдаемых пар объектов. Результирую- щий дескриптор представляет собой последовательность предикатов про- странственного отношения (например, внутри, слева, справа, впереди, сзади, внизу, вверху, касание). Было показано, что выразительности этого дескрип- тора достаточно для различения четырех различных действий. Другая концепция заключается в использовании общих знаний о свой- ствах формы объекта. Например, обнаружение симметрии может помочь в сегментации как в 2D (Teo et al., 2015), так и в 3D (Ecins et al., 2016). Пред- ставьте, что вы смотрите на загроможденную сцену. Поскольку большинство объектов, с которыми мы работаем, симметричны либо зеркально, либо вра- щательно, мы можем «дополнить» невидимую часть объекта, что существен- но помогает сегментации и распознаванию. 11.3.4. Проблематика понимания деятельности Понимание деятельности – очень сложная задача. Законченные сквозные решения плохо масштабируются из-за больших различий во внешнем виде на высоких уровнях абстракции и временного расширения. В предыдущих разделах мы рассмотрели иерархические подходы и под- робно описали один более высокий уровень – грамматики действия. Грамма- тики действий могут сегментировать действия во время контакта и фикси- ровать рекурсивную структуру последовательностей действий, аналогичную той, что встречается в языке. Мы описали эксперименты, демонстрирующие выразительную силу грамматик действия. Мы также описали процессы ниж - него уровня, которым не уделялось должного внимания в компьютерном зрении, но которые необходимы для реализации методов, основанных на действиях. К ним относятся аффордансы, анализ типа захвата и использова- ние геометрии для облегчения временнóй и пространственной сегментаций и описания пространственных отношений. В этом разделе мы подчеркнули необходимость использования осмыслен- ных представлений, основанных на действиях, на разных уровнях иерархии. Точнее говоря, очень важно, чтобы эти представления были робастными\n--- Страница 497 ---\n496  Обучение пониманию сцены на основании действий из-за многих проблем, связанных с пониманием деятельности. Частично мы можем добиться робастности за счет использования геометрии, поскольку она не требует запоминания и может быть оценена по низкоуровневым из- мерениям. Следовательно, прежде чем начинать распознавание, мы должны по возможности вводить в систему компьютерного зрения геометрию. Поми - мо геометрии, для понимания деятельности имеет значение любое понятие, которое предоставляет универсально верную информацию. Мы можем мо- делировать физические законы или включить модельные онтологии, чтобы облегчить обобщение, например сгруппировав глаголы в зависимости от того, какое влияние они оказывают на объекты (Yang et al., 2013). Мы также можем добавить процессы, моделирующие причинность; действия причинно ограничивают друг друга, некоторые комбинации невозможны физически. Эти представления несут больше знаний и лучше ограничивают интерпре- тацию деятельности. Интеграция зрения и познания или языка сложна. Это происходит из-за семантического разрыва, то есть несоответствия между символическими или языковыми представлениями и визуальными представлениями, основан- ными на сигналах. Мы стремимся добиться устойчивой интеграции между этими представлениями. Поэтому нам нужно избегать слишком ранней на- стройки пороговых значений или преобразования в чисто символическое представление. Это связано с тем, что если зрение не может предоставить точные данные, то неточности усугубляются дальнейшей абстракцией, что приводит к ошибочным рассуждениям. Следующей исследовательской за- дачей является выработка способов обуче ния, которые связывают восприя- тие с рассуждениями более высокого уровня для более глубокой интеграции. В разделе 11.4 рассматриваются подходы к глубокому обуче нию, полезные для такой интеграции. В настоящее время подобные методы в основном огра- ничены распознаванием объектов и, в некоторой степени, распознаванием действий, но они будут полезны и для задачи распознавания деятельности. 11.4. понимание фун Кциона Льной сцены посредст Вом гЛубоКого обу Чения с помощью язы Ка и зрения В этом разделе мы рассматриваем слияние видения и языка и связанных с ними представлений – слияние «сигнала» и «символа». Объединение не- скольких представлений важно из-за пригодности различных представлений для отражения различных характеристик мира. Мы стремимся к тому, чтобы информация из представлений внешнего вида более низкого уровня и ин- формация из представлений отношений и семантики более высокого уровня дополняли друг друга. Системы, включающие символические и непрерывные представления, час то имеют жесткие границы, ниже которых система непрерывна, а выше –\n--- Страница 498 ---\nПонимание функциональной сцены посредством глубокого обучения  497 символична. Где именно устанавливается эта граница, зависит от ситуации, но обычно она не опускается ниже уровня абстракции, отраженного в чело- веческом языке, поскольку язык является основным источником символи- чески представленного знания о мире. Символическое представление более важно для понимания действий и дея тельности, чем для других задач компьютерного зрения, таких как обна- ружение объектов, поскольку природа этой задачи более абстрактна и менее основана на внешнем виде. Действие имеет временную структуру в несколь- ких масштабах и базируется на удовлетворении условий – определяющими характеристиками действия являются семантика и отношения. Многие задачи компьютерного зрения могут выиграть от интеграции зрения и языка. Тем не менее одна задача, которая идеально подходит для изуче ния их интеграции, – это обуче ние без ознакомления (zero shot learning, ZSL, иногда называемое обуче нием без подготовки) – потому что, в отличие от других задач, ее нельзя решить без введения невизуальных знаний, на- пример отраженных в языке. ZSL – это задача с двумя наборами данных: обучающим и тестовым. Кате- гории этих наборов разбиваются на «знакомые» и «незнакомые». Обучающий набор состоит только из «видимых» категорий, в то время как тестовый на- бор содержит «незнакомые» категории, а также, опционально, «знакомые». Например, может быть задача ZSL, которая включает знакомые категории «бегать» и «стоять», а также категорию «ходить», с которой модель не зна- комилась при обучении. Задача обуче ния будет заключаться в том, чтобы модель научилась визуально распознавать и правильно классифицировать ходьбу, хотя она ей ранее никогда не встречалась, но категории «бег» и «стоя- ние» встречались в обучающем наборе. Существует несколько подходов к ZSL. Ранние работы по ZSL сосредото- чены на атрибутах – визуально распознаваемых характеристиках с диф- ференциальными ассоциациями классов (например, классов объектов или классов действий). Атрибуты можно обобщить в том смысле, что детекторы атрибутов, обученные только на видимом наборе, способны обнаруживать атрибуты в выборках как из знакомого, так и из незнакомого набора. Более поздние работы над ZSL, как правило, сосредоточены на семантиче- ских пространствах представления. Это евклидовы векторные пространства, в которых семантические категории (например, отраженные в языке) связа- ны с векторами или точками в пространстве. Эти векторные представления слов имеют значительно более низкую размерность, чем прямое унитар - ное кодирование с одним активным состоянием (one-hot encoding, векторы, в которых каждое измерение соответствует классу, а все измерения, кроме одного, равны нулю), и обладают таким свойством, что слова, сходные по семантике, представлены векторами, которые расположены рядом в про- странстве представления. В семантических пространствах представления символические представ- ления векторизуются таким образом, что сохраняются семантические от - ношения категорий символов. Это позволяет интегрировать символическую семантику в глубокие архитектуры, внутренние представления которых со- стоят из векторов. Интеграция сводится к правильному сопоставлению ви-\n--- Страница 499 ---\n498  Обучение пониманию сцены на основании действий зуальных векторных представлений с векторизованными символическими представлениями. В разных методах ZSL используются разные общие представления: одни встраивают визуальные признаки в семантическое пространство, другие встраивают семантическое пространство в пространство визуальных при- знаков, а некоторые встраивают и то, и другое в третье общее пространство. Поскольку и визуальные, и семантические представления лежат в одном и том же пространстве, категоризация визуального ввода сводится к поиску ближайшей семантической метки в этом пространстве. Современные методы ZSL часто используют CNN для визуальных призна- ков и создают общие пространства представлений с предварительно обучен- ными семантическими пространствами представлений, такими как word2vec (Mandal et al., 2019; Xian et al., 2018). Некоторые методы ZSL, основанные на общем представлении, структурируют и обучают свои модели сквозным способом, что сложнее, но обеспечивает выигрыш в производительности (Zhang et al., 2017). Оставшаяся часть текущего раздела 11.4 построена следующим образом: в разделе 11.4.1 мы подробно описываем простое использование атрибутов для ZSL и определение относительного атрибута с более тонкими нюан- сами; в разделе 11.4.2 представлено использование общих семантических пространств в ZSL; в разделе 11.4.3 мы рассмотрим основные подходы к по- строению семантического векторного пространства; в разделе 11.4.4 пойдет речь о включении знаний в виде графов для классификации действий по методу ZSL. 11.4.1. Атрибуты в обучении без ознакомления Использование для распознавания деятельности атрибутов, в том числе атрибутов, ориентированных на действия, таких как аффордансы, описан- ные в разделе 11.2, позволяет создавать классификаторы, интерпретируемые и определяемые человеком. Атрибуты смягчают проблему непрозрачности модели за счет использования явного предопределенного представления среднего уровня ниже уровня категорий классов. Использование атрибутов делает возможным простой механизм, с по- мощью которого можно изучать визуальные представления из доступных обучающих данных и передавать эти представления в классы, для которых нет доступных обучающих данных. Атрибуты являются общими в том смыс - ле, что они присутствуют в нескольких категориях классов, а использование нескольких атрибутов с различным распределением по классам позволяет представлять конкретные классы. Атрибуты в ZSL применяются следующим образом: детекторы атрибутов обучаются по знакомому набору и связанным с ним меткам атрибутов. Эти детекторы можно обобщить как на знакомый, так и на незнакомый набор. Из-за того, что разные категории атрибутов обладают разным охватом клас - сов (например, класса объектов или действий), разные комбинации атри - бутов могут представлять разные классы. Следовательно, детекторы клас -\n--- Страница 500 ---\nПонимание функциональной сцены посредством глубокого обучения  499 сов могут быть расположены поверх детекторов атрибутов. Эта реализация опирается на спецификацию того, какие атрибуты связаны с классами. При наличии спецификации для незнакомых категорий можно построить соот - ветствующие детекторы, даже если визуальные образцы незнакомых кате- горий не встречались. Традиционное использование атрибутов в компьютерном зрении является бинарным: атрибут либо присутствует, либо отсутствует. Это ограничивает репрезентативную силу представлений атрибутов. Однако бинарные пред- ставления можно обобщить до скалярных представлений, где каждый атри- бут связан со скалярной степенью, а не с бинарной категорией. Это более гибко с точки зрения представления и позволяет использовать атрибуты, которые не так четко подпадают под бинарную категоризацию. Например, в то время как атрибут «в помещении / на улице» обычно явно бинарный, атрибут «двигаться быстро/медленно» имеет более равномерное распреде- ление по градациям визуального ввода. Парих и Грауман (Parikh, Grauman, 2011) предложили один из подходов к обобщению бинарных атрибутов на скалярные. Проблемой при обобщении бинарных атрибутов на скалярные является неоднородность и непоследо- вательность аннотаций, поскольку разные аннотаторы могут по-разному толковать, чему соответствуют разные степени атрибутов в скалярном пред- ставлении. Некоторые исследователи решают эту проблему, требуя, чтобы аннотаторы не присваивали скалярные значения непосредственно атри- бутам, а ранжировали изображения с точки зрения степени атрибута. Пос - ле ранжирования изображений значения скалярных атрибутов могут быть получены из их аннотированных относительных степеней. В случае бинарных атрибутов детекторы можно обучить с по мощью обыч- ных классификаторов, но для создания скалярных атрибутов требуются дру - гие методы. Парих и Грауман (Parikh, Grauman, 2011) обучают функцию ран- жирования изображений на атрибутах знакомого набора и используют эту функцию ранжирования для получения скалярного значения. Относительные представления атрибутов обеспечивают большую гибкость в спецификациях классов. Используя атрибут «быстрое движение / медлен- ное движение», можно указать, что незнакомая категория «бег» быстрее, чем знакомая категория «ходьба», или что незнакомая категория «стояние» мед- леннее, чем знакомая категория «ходьба». Это делается без необходимости определять бинарную спецификацию или интуитивно понятное скалярное значение для описания незнакомых категорий. 11.4.2. Общие пространства для встраивания Обобщение бинарных атрибутов до скалярных увеличивает их репрезента- тивную силу. Однако увеличение репрезентативной способности произошло за счет увеличения сложности аннотирования атрибутов и определения клас - сов. Одним из решений этой проблемы являются относительные атрибуты (Parikh, Grauman, 2011).\n--- Страница 501 ---\n500  Обучение пониманию сцены на основании действий Атрибуты также могут быть абстрактными. Вовсе не обязательно, чтобы визуальные представления сопровождались понятными человеку атрибута- ми. Абстрагирование атрибутов имеет два преимущества: отсутствие неточностей, возникающих при использовании сконструи- рованных, а не изученных представлений; отсутствие накладных расходов и ошибок при аннотировании атри- бутов. Но тогда возникает вопрос, как построить систему, чтобы изучение клас - сификации знакомых классов давало нам классификатор, способный обра- батывать не только знакомые, но и незнакомые классы без использования извлеченного из данных представления промежуточного уровня, которое позволяет специфицировать незнакомые классы с точки зрения этого пред- ставления. Один из подходов состоит в том, чтобы определить незнакомые клас - сы с точки зрения их отношений сходства со знакомыми классами, изучая отношения из корпусов текстов. В области обработки естественного язы- ка (NLP) ведется обширная работа по созданию семантических векторных пространств, которые представляют отношения подобия между словами, – одним из популярных примеров является word2vec (Mikolov et al., 2013). Идея заключается в том, что термины в этих пространствах расположены в непосредственной близости от других терминов, с которыми они имеют семантическое сходство. Обученные семантические пространства общедо- ступны – их можно взять и использовать без необходимости создавать с нуля. В разделе 11.4.3 более подробно рассказано о создании таких пространств. Термины с семантическим сходством часто также имеют сходство в ви- зуальном пространстве – например, «бег трусцой» как семантически, так и визуально находится между «бегом» и «ходьбой». Часто бывает так, что если можно определить визуальное сходство с известными категориями, то можно установить и семантические отношения сходства. Затем из этих семантических отношений мы можем вывести семантические категории визуальной информации. В качестве иллюстрации рассмотрим простой пример. Возьмем набор зна - комых классов, включающий «бег» и «ходьбу», и набор незнакомых классов, включающий «бег трусцой», семантическое векторное пространство, отра- жающее семантическую близость между этими категориями, и архитектуру компьютерного зрения (например, CNN), которая создает визуальные пред- ставления входных данных. Пусть у нас есть визуальные входные данные, относящиеся к незнакомому классу. Внутреннее представление этого входа, созданное CNN, находится на полпути между представлением «бега» и «ходь- бы». Затем мы переходим в семантическое языковое пространство и видим, что метка, расположенная на полпути между «бег» и «ходьба», – это «бег трусцой», и присваиваем эту метку входным данным. Чаще всего сравнение сходства между образцами незнакомого класса и знакомыми классами производится не в визуальном пространстве. Обыч- но входные данные сопоставляются с семантическим пространством и там выполняются сравнения с известными классами. Это требует встраивания одного пространства в другое.\n--- Страница 502 ---\nПонимание функциональной сцены посредством глубокого обучения  501 Механизм встраивания одного пространства в другое может быть таким же простым, как линейное преобразование, применяемое к одному простран- ству, которое обучается на потере сходства между двумя пространствами. Сеть DeViSe (Frome et al., 2013) – хороший пример архитектуры, использую- щей этот метод. Она включает в себя два предварительно обученных пред- ставления – визуальные признаки, взятые, например, из CNN, обученной классификации, и векторы слов в пространстве представлений, которые мо- гут быть созданы с по мощью средств, обсуждаемых в разделе 11.4.3. Один из методов встраивания визуальных признаков в семантическое пространство векторов слов показан на рис. 11.8. Слой узлов добавляется к верхней части предварительно обученных признаков CNN, а затем обуча- ется. Потерей, которая обучает этот слой, является сходство (например, косинусное сходство) между выходными данными этого слоя и векторами в пространстве семантического представления, соответствующими меткам визуального ввода. Таким образом обучается функция простого линейного отображения векторов визуальных признаков на семантические признаки, полученные из текста. Часто используются более сложные отображения, чем линейные. Исполь- зование нескольких слоев нейронов в сочетании с нелинейными активация- ми дает нелинейные отображения (например, Kato et al., 2018 используют такой метод). Кодиров и др. (Kodirov et al., 2017) для создания представления использовали автоэнкодер с семантическими ограничениями и обнаружили, что ограничение визуальной реконструкции приводит к лучшему обобще- нию незнакомых классов в ZSL. Дополнительный слой для линейного преобразования Признаки из предварительно обученной CNNПредварительно обученное семантическое векторное пространствоПотеря подобияМетка: «Бег» Рис. 11.8  Простой подход к встраиванию визуальных представлений в се- мантическое пространство, применяемый такими методами, как DeViSe (Frome et al., 2013). Используются две предварительно обученные модели: 1) предва- рительно обученная модель извлечения визуальных признаков, такая как CNN, и 2) семантическое векторное пространство, созданное с по мощью методов, обсуждаемых в разделе 11.4.3. Простое линейное преобразование произво- дится путем добавления слоя узлов поверх визуальных признаков и их обуче- ния с учетом меры их сходства с семантическим вектором слов меток, соответ - ствующих зрительному вводу. Готовое линейное преобразование представляет собой отображение пространства визуальных признаков в пространство се- мантических векторов\n--- Страница 503 ---\n502  Обучение пониманию сцены на основании действий Как только визуальный ввод и семантическое представление помещены в одно и то же пространство, определить класс нового визуального ввода так же просто, как представить визуальный ввод в этом пространстве, а затем найти ближайшую семантическую метку в том же пространстве. 11.4.3. Построение семантических векторных пространств 11.4.3.1. word2vec Допустим, мы хотим построить векторное пространство, в котором слова представлены таким образом, чтобы их семантика определяла простран- ственное расположение вектора. Конечным результатом является простран- ство, в котором, например, векторы «бег», «трусца» и «ходьба» расположены рядом и «трусца» находится между «бегом» и «ходьбой». Как определить семантику слова? Один из ответов заключается во взаи- модействии слова с другими словами в текстовом корпусе – семантика слов может быть определена по отношению к другим словам. Как мы моделируем отношения слов к другим словам? Одним из простых подходов является со- впадение: если два слова встречаются рядом, они считаются связанными. Чем чаще они встречаются вместе, тем сильнее они связаны. Это принцип, на котором основаны методы представления слов в векторных пространствах, такие как word2vec. Начнем с простейшего векторного представления слов – прямого унитар- ного кодирования, где каждая позиция вектора соответствует одному слову в словаре V. Это многомерное неэффективное представление, в котором нет значимых пространственных отношений между словами. Мы можем размес - тить слова в пространстве меньшей размерности с указанными желаемыми свойствами, решив одну из двух связанных задач: 1) прогнозирование целевого слова на основе контекста; 2) прогнозирование контекста на основе целевого слова. Здесь контекст C определяется как набор терминов «рядом» с целевым тер- мином. Они определяются как другие термины, присутствующие в n-грамме, связанной с целевым термином, без учета порядка слов. Каждая из этих задач может быть решена с использованием простых архи- тектур, и в процессе решения этих задач возникают представления меньшей размерности, которые затем можно взять и использовать для других задач. Метод Continuous Bag Of Words (CBOW) для решения задачи 1 (Mikolov et al., 2013) показан на рис. 11.9a. Входные данные состоят из нескольких слов контекста, каждое из которых представлено как унитарный вектор размер- ности |V |. Эти векторы суммируются для получения вектора размером |V |. Он проходит через один слой из N нейронов, где N – размер пространства представления. Вдобавок к этому у нас есть еще один слой размером |V |, чья задача заключается в том, чтобы предсказать в унитарном коде слово, связанное с контекстом, состоящим из терминов, подаваемых в качестве входных данных для первого слоя.\n--- Страница 504 ---\nПонимание функциональной сцены посредством глубокого обучения  503 Метод Skip Gram для решения задачи 2 (Mikolov et al., 2013) показан на рис. 11.9b. Вход состоит из одного термина, представленного как унитарный вектор размерности |V |. Он подается в один слой размерности N, где N – раз - мерность пространства представления. Выше этого слоя у нас есть выходной слой, состоящий из |C | наборов |V | узлов, каждый из которых связан с одним термином контекста C в n-грамме, связанной с входным термином. Обе архитектуры обучаются путем последовательной подачи n-грамм, из- влеченных из больших текстовых корпусов, и применения потерь softmax к последнему слою для обуче ния соответствию ожидаемым терминам. После того как эти архитектуры обучены, скрытый слой затем перено- сит отображение V из унитарного представления размера |V | во встроенное представление размера N, где термины пространственно расположены ря- дом с терминами с аналогичной семантикой. Входной вектор |C| размера |V| Скрытый слой из N элементовСкрытый слой из N элементовВыходной слой из |V| элементовВыходной слой из |V| элементов|C| слов контекста Поэлементное суммирование (a) (b) Рис. 11.9  (а) Метод Continuous Bag Of Words для решения задачи предска- зания целевого слова на основе контекста этого слова (Mikolov et al., 2013). Входные векторы |C| контекста проходят через два слоя, первый – скрытый слой размера N, второй – выходной слой размера V. Потеря рассчитывается относи- тельно слова W. После обуче ния выходной слой можно отбросить, а скрытый слой использовать для перевода из унитарных кодировок слов во вложенное пространство размера N. (b) Метод Skip Gram для решения задачи предсказа- ния контекста термина (Mikolov et al., 2013). Слово W проходит через два сете- вых слоя, первый – скрытый слой размера N, второй – выходной слой разме- ра V. Потеря рассчитывается относительно |C| слов контекста. После обуче ния выходной слой можно отбросить, а скрытый слой использовать для перевода из унитарных кодировок слов в пространство представления размера N 11.4.4. Общие пространства представления и графовые модели Кроме простого отображения в общее пространство встраивания, ZSL дей- ствия может получить еще одну выгоду от дополнительной структуры, по-\n--- Страница 505 ---\n504  Обучение пониманию сцены на основании действий скольку ее можно представить в виде графов. В нескольких работах (Ghosh et al., 2020a,b; Kato et al., 2018; Yan et al., 2018) для распознавания действий используются графы, которые обрабатываются с по мощью графовой свер- точной сети (graph convolutional network, GCN) для получения векторных представлений категорий действий, подходящих для ZSL. Гош и др. (Ghosh et al., 2020) оценивают три различных графовых пред- ставления, последнее из которых применимо к обуче нию с ограниченным озна комлением (few-shot learning), а не к ZSL, поскольку в нем используются визуальные признаки из небольшого количества образцов. Като и др. (Kato et al., 2018) строят граф на основе триплетов Subject Verb Object, полученных из корпусов знаний. Все они обрабатываются через GCN. Во всех новых исследованиях (Ghosh et al., 2020) применяется sentence2vec (Pagliardini et al., 2017), а не word2vec, поскольку авторы считают, что кате- гории действий лучше представлены фразами, чем отдельными словами, которые могут иметь несколько значений. Первый граф состоит из узлов, принимающих значения представлений sentence2vec для фраз, обозначаю- щих категории действия. Эти узлы связаны друг с другом на основе косинус - ного подобия между векторными представлениями – N ближайших соседей для каждого узла соединены ребрами. Второй граф связывает глаголы и су - ществительные, извлеченные из тегов Part-of-Speech (части речи) фраз, опи- сывающих действия, с каждым классом действий, включая существительные в качестве прочной связи между знакомыми и незнакомыми категориями. Третий граф включает в себя визуальные представления, полученные из не- большого количества образцов незнакомых категорий, – поэтому мы гово- рим, что этот граф применим к обуче нию с ограниченным знакомством, а не к ZSL. Причина добавления визуальных репрезентаций заключается в том, что категории, которые сходны в семантическом пространстве, могут тем не менее иметь различные визуальные проявления – авторы приводят пример «выгула коня» и «конной прогулки», которые имеют схожие представления слов, но разные визуальные проявления. Като и др. (Kato et al., 2018) строят граф, состоящий из трех типов узлов: узлов существительных, узлов объектов и узлов действий. Узлы действий связаны с глаголами и существительными, которые включают в себя связан- ное действие. Узлы графа обычно инициализируют значениями, полученными из се- мантических векторных пространств – это важно, поскольку они задают на- чальные отношения, по которым итерируется GCN. Эта итерация охваты- вает отношения, определяемые ребрами в графе, и позволяет передавать информацию от узла к узлу вдоль ребер. Например, в (Kato et al., 2018) узлы действия, для которых изначально заданы нулевые векторы, приобретают представление, определяемое векторами ближайших узлов существительно- го и глагола, которые были инициализированы семантическими векторами. Как и ранее упомянутые, эти методы изучают отображение визуальных признаков (взятых из CNN, предварительно обученной для отдельной за- дачи) в общее пространство представлений, хотя здесь это пространство используется совместно с представлениями, созданными GCN. У Като и др. (Kato et al., 2018) это отображение производится через два слоя нейронов\n--- Страница 506 ---\nПерспективные направления исследований  505 с сигмовидной активацией, что приводит к нелинейному отображению ви- зуальных признаков в общее семантическое пространство. Как и в преды- дущей работе, эти слои обучаются путем применения потери, измеряющей сходство между векторами визуальных признаков и векторами, ассоцииро- ванными с метками входных данных, созданными GCN. Затем, используя знакомый обучающий набор, можно изучить отображе- ние предварительно обученных визуальных признаков на векторы действия, созданные GCN. Чтобы получить прогнозы сети для новых действий во вре- мя тестирования, можно применить алгоритм поиска ближайших соседей между визуальными признаками и векторами действия. 11.5. перспе КтиВные напра ВЛения иссЛедо Ваний В этом разделе мы обсудим следствия, вытекающие из применения ориенти- рованной на действия структуры сети и перспективы дальнейших исследова- ний. От действия зависят задачи и наборы данных – оно позволяет проводить концептуальное моделирование, способствующее обобщению и долгосроч- ному временному прогнозированию. Пониманию действия способствует моделирование концепций, выходящих за рамки обычного компьютерного зрения. По мере развития компьютерного зрения масштабируемость тра - диционных методов обуче ния с учителем становится все более серьезной проблемой, и методы, основанные на действиях, помогают смягчить эту проблему, используя преимущества парадигм обуче ния с частичным при- влечением учителя или совсем без учителя. Наконец, действие помогает ин- тегрировать познание и символическое моделирование в восприятие, в том числе в нескольких модальностях восприятия. Задачи и наборы данных. Деятельность охватывает длительные проме- жутки времени. Следовательно, при поиске решений для понимания наблю- даемой деятельности мы сталкиваемся с проблемами гораздо более сложны- ми, чем те, с которыми мы сталкиваемся в текущих задачах распознавания действий. Объекты, действия, аффордансы и другие составляющие сцены семантически соотносятся друг с другом в различных временных масштабах, и нам необходимо найти способы моделирования этих отношений. Мы дума- ем, что эта способность не очень хорошо раскрыта в задаче распознавания действий. Нам следует выбирать задачи, которые демонстрируют обобщение и концептуальное понимание действия (в отличие от понимания, основан- ного исключительно на внешнем виде). Такие задачи включают обуче ние без ознакомления и предсказание будущих действий, а также переход с од- ной точки зрения на другую (например, от первого лица к третьему лицу). Сегодняшние исследования компьютерного зрения в значительной степени обусловлены появлением новых наборов данных и определением новых за- дач – существующие наборы данных недостаточно охватывают долгосроч- ное и концептуальное моделирование деятельности. Наборы данных в идеа- ле должны иметь записи с разных точек зрения, потому что это открывает\n--- Страница 507 ---\n506  Обучение пониманию сцены на основании действий возможности для интересных исследований, например для решения задачи передачи знаний между видом от первого и третьего лица. Наконец, боль- шинство наборов данных содержат сцены в помещении. Будет интересно собрать набор сцен на открытом воздухе и проанализировать их, как обсуж - далось выше, рассматривая связи между аффордансами, взаимодействиями и долгосрочными отношениями. Мы также могли бы попытаться провести основанный на действиях анализ данных из области автономного вождения. Концепции понимания длительной деятельности. Понимание дея- тельности требует наличия четкой концепции анализа и распознавания действий в различных временных масштабах. В этой главе мы обсуждали элементы такой концепции применительно к одиночному изображению и в краткосрочных масштабах времени, включая аффордансы, захваты рук, геометрические отношения. Мы отмечали важность использования про- цессов геометрической реконструкции из-за их робастности (раздел 11.3.4). Следующим шагом будет добавление дополнительных ограничений робаст - ности для моделирования временных отношений в более длинных проме- жутках времени. Мы могли бы использовать онтологии для классификации объектов и действий. Сегодня мы можем классифицировать глаголы, исходя из эффектов действия (Yang et al., 2013), принципов эргономики или огра- ничений, связанных с силой и местоположением. Долгосрочные отношения охватывают причинно-следственные связи и ограничения на возможные и невозможные последовательности действий. Мы также можем моделиро- вать физические ограничения и использовать физические движки, но для того, чтобы интегрировать их в глубокие архитектуры, нам нужно встроить эти ограничения в векторные пространства, которые связывают восприятие с познанием (раздел 11.4). Уменьшение потребности в обучении с учителем. Ранние подходы к интеграции языка со зрением (разделы 11.4.1 и 11.4.4) в значительной сте- пени были основаны на обучении с учителем. Например, распознавание ви- зуальных атрибутов или объектов было реализовано посредством обуче ния с учителем. Модели на основе графов, использующие общие представления для ZSL, должны быть заранее готовы распознать категории «незнакомого» набора, с которыми они могут столкнуться во время применения. Естествен- но, в системе, основанной на действиях, найдут воплощение различные ва- рианты концепции развития, такие как обуче ние без учителя и самообуче- ние, перенос знаний, метаобучение и в конечном итоге бесконечное обуче ние (Mitchell et al., 2015). Например, при построении визуальных онтологий нам не следует полностью полагаться на обуче ние с учителем при изучении ви- зуальных представлений классов метаглаголов. Одним из способов такого моделирования является изучение словаря (Zheng et al., 2016), но до сих пор эти подходы ограничивались простыми действиями. Нам потребуются ме- тоды, которые масштабируются на более сложные действия, выполняемые людьми. Генеративно-состязательные сети (GAN) и вариационные автокоди- ровщики (VAE) продемонстрировали свою эффективность в моделировании изображений и видео с атомарными действиями. Мы могли бы, например, использовать VAE для изучения базового распределения данных в дискрет - ном скрытом пространстве, которое кодирует метакатегории.\n--- Страница 508 ---\nВыводы  507 Многомодальное восприятие. Человеческое понимание мира основано на нашем двигательном познании и всех наших чувствах. Точно так же наши модели должны включать другие сенсорные модальности, такие как слухо- вые, тактильные или проприоцептивные1 сигналы, в дополнение к модели- рованию зрительных и когнитивных представлений. Различные модальности предоставляют разную дополнительную информацию и поэтому допускают различные способы организации понятий. В дополнение к вопросам обуче- ния с использованием различных модальностей нам также нужны методы доступа к сохраненным понятиям при восприятии из любой модальности. При изучении интеграции различных модальностей также было бы полезно глубже вникнуть в механизмы памяти. В качестве теоретической модели искусственного интеллекта был предложен фреймворк, известный как век- торные символические архитектуры (vector symbolic architectures, VSA) (Plate, 1995; Eliasmith, 2013), включающий в себя гиперпространственные вычисле - ния (методы, использующие векторные пространства очень высокой размер- ности) (Pentti, 2009). Гиперпространственные вычисления сочетают в себе преимущества подходов искусственного интеллекта на основе нейронных сетей с систематической композиционностью и упорядоченным поведением из области классического символического искусственного интеллекта (Levy, Gayler, 2008). В этом фреймворке концепции (идеи) кодируются и перено- сятся в векторные пространства, а алгебраические операции определяются в векторных пространствах. Эти операции представляют собой добавление родственных понятий и связывание векторов разного происхождения – на- пример, это может быть звук и зрение или зрение и моторика (Mitrokhin et al., 2019). Операции поддерживают отделимость одной модальности от другой. Мы могли бы взять этот фреймворк за основу и объединить его с подходами нейронных сетей. Цель будет состоять в том, чтобы сохранить возможность кодировать в память явные модальности восприятия, сохраняя при этом способность вспоминать информацию из любой модальности. 11.6. В ыВоды Целью компьютерного зрения является создание интерпретаций, полезных для людей. Действие занимает центральное место в нашем понимании мира, но недостаточно используется в современном компьютерном зрении. Эта глава посвящена пониманию сцены и деятельности, в основе которого лежит концепция действия и взаимодействия. Мы рассмотрели основанные на дей- ствиях подходы к пониманию сцены, в том числе моделирование в несколь- ких временных масштабах, начиная с интерпретации объекта с точки зрения аффордансов на уровне текущего момента и переходя к базовым действи- ям, а затем и к деятельности в более длительном временном масштабе. Мы 1 Проприоцепция – это ощущение особого рода, возникающее в результате обработки сигналов от специализированных рецепторов (проприоцепторов), дающих мозгу информацию о положении мышц, сухожилий и суставов и в конечном счете о по- ложении тела и его частей в пространстве. – Прим. перев.\n--- Страница 509 ---\n508  Обучение пониманию сцены на основании действий описали хорошо развитую область аффордансного обуче ния и представили краткий обзор работ по пониманию деятельности, сочетающих когнитивный и лингвистический подходы с интерпретируемыми людьми модулями, не- обходимыми для характеризации деятельности и временной сегментации видео. Мы обсудили методы интеграции визуальных представлений со зна- ниями, как созданными, так и полученными из текстовых корпусов. В гла- ве была рассмотрена интеграция видения, сосредоточенного на действии, с графовыми методами и представлены возможные направления исследова- ний, включая создание новых задач и наборов данных, развитие концепций кодирования долгосрочных отношений, применение методов обуче ния без учителя и добавление памяти в качестве центрального компонента системы, предназначенной для понимания деятельности. бЛагодарности Благодарим за поддержку исследований по грантам BCS 1824198 и OISE 2020624 со стороны Национального фонда науки. Литературные исто ЧниКи Aditya Somak, Yang Yezhou, Baral Chitta, Aloimonos Yiannis, Fermüller Cornelia, 2018. Image understanding using vision and reasoning through scene descrip- tion graph. Computer Vision and Image Understanding 173, 33–45. Aloimonos Yiannis, Fermüller Cornelia, 2015. The cognitive dialogue: a new model for vision implementing common sense reasoning. Image and Vision Compu- ting 34, 42–44. Ansuini Caterina, Cavallo Andrea, Bertone Cesare, Becchio Cristina, 2015. Intentions in the brain: the unveiling of mister Hyde. The Neuroscientist 21 (2), 126–135. Bajcsy Ruzena, 1988. Active perception. Proceedings of the IEEE 76 (8), 966–1005. Barsalou Lawrence W., 2008. Grounded cognition. Annual Review of Psychology 59, 617–645. Bo Liefeng, Ren Xiaofeng, Fox Dieter, 2013. Unsupervised feature learning for rgb-d based object recognition. In: Experimental Robotics. Springer, pp. 387–402. Cutkosky Mark R., 1989. On grasp choice, grasp models, and the design of hands for manufacturing tasks. IEEE Transactions on Robotics and Automation 5 (3), 269–279. Damen Dima, Doughty Hazel, Maria Farinella Giovanni, Fidler Sanja, Furnari An- tonino, Kazakos Evangelos, Moltisanti Davide, Munro Jonathan, Perrett Toby, Price Will, et al., 2018. Scaling egocentric vision: the EPICkitchens dataset. In: Pro- ceedings of the European Conference on Computer Vision (ECCV), pp. 720–736. Das Pradipto, Xu Chenliang, Doell Richard F., Corso Jason J., 2013. A thousand frames in just a few words: lingual description of videos through latent topics and sparse object stitching. In: Proceedings of the IEEE Conference on Com- puter Vision and Pattern Recognition, pp. 2634–2641.\n--- Страница 510 ---\nЛитературные источники  509 Dessalene Eadom, Devaraj Chinmaya, Maynord Michael, Fermüller Cornelia, Aloi monos Yiannis , 2021. Forecasting action through contact representations from first person video. IEEE Transactions on Pattern Analysis and Machine Intelligence. Dutta V., Zielinska T., 2017. Action prediction based on physically grounded object affordances in human-object interactions. In: Proceedings of the 11th Interna- tional Workshop on Robot Motion and Control. Ecins Aleksandrs, Fermüller Cornelia, Aloimonos Yiannis, 2016. Cluttered scene segmentation using the symmetry constraint. In: IEEE International Confer - ence on Robotics and Automation (ICRA), pp. 2271–2278. Eliasmith Chris, 2013. How to Build a Brain: A Neural Architecture for Biological Cognition. Oxford University Press. Everingham M., Van Gool L., Williams C. K. I.,Winn J., Zisserman A., 2010. The Pas- cal visual object classes (VOC) challenge. International Journal of Computer Vision 88 (2), 303–338. Fermüller Cornelia, Aloimonos Yiannis, 1995. Vision and action. Image and Vision Computing 13 (10), 725–744. Fermüller Cornelia, Wang Fang, Yang Yezhou, Zampogiannis Konstantinos, Zhang Yi, Barranco Francisco, Pfeiffer Michael, 2018. Prediction of manipulation actions. International Journal of Computer Vision 126 (2), 358–374. Fitzpatrick Paul, Metta Giorgio, Natale Lorenzo, Rao Sajit, Sandini Giulio, 2003. Learning about objects through action-initial steps towards artificial cogni- tion. In: IEEE International Conference on Robotics and Automation, vol. 3, pp. 3140–3145. Frome Andrea, Corrado Greg, Shlens Jonathon, Bengio Samy, Dean Jeffrey, Ranzato Marc’Aurelio, Devise Tomas Mikolov, 2013. A deep visual-semantic embedding model. Advances in Neural Information Processing Systems 26. Ghosh Pallabi, Saini Nirat, Davis Larry S., Shrivastava Abhinav, 2020a. All about knowledge graphs for actions. arXiv preprint. arXiv:2008.12432. Ghosh Pallabi, Yao Yi, Davis Larry, Divakaran Ajay, 2020b. Stacked spatio-temporal graph convolutional networks for action segmentation. In: Proceedings of the IEEE/CVFWinter Conference onApplications of Computer Vision, pp. 576–585. Gibson James J., 1977. The theory of affordances. In: Bransford John, Shaw Ro bert E. (Eds.), Perceiving, Acting, and Knowing: Toward an Ecological Psycho logy. Law - rence Erlbaum Associates, Hillsdale, NJ, pp. 67–82. Grabner Helmut, Gall Jürgen, Van Gool Luc, 2011. What makes a chair a chair? In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 1529–1536. Guha Anupam, Yang Yezhou, Fermüller Cornelia, Aloimonos Yiannis, 2013. Mini- malist plans for interpreting manipulation actions. In: IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 5908–5914. Gupta Abhinav, Satkin Scott, Efros Alexei A., Hebert Martial, 2011. From 3d scene geometry to human workspace. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 1961–1968. Hassanin Mohammed, Khan Salman, Tahtali Murat, 2018. Visual affordance and function understanding: a survey. arXiv preprint. arXiv:1807.06775. Hedau Varsha, Hoiem Derek, Forsyth David, 2009. Recovering the spatial layout of cluttered rooms. In: IEEE International Conference on Computer Vision, pp. 1849–1856.\n--- Страница 511 ---\n510  Обучение пониманию сцены на основании действий Hermans Tucker, Rehg James M., Bobick Aaron, 2011. Affordance prediction via learned object attributes. In: IEEE International Conference on Robotics and Auto mation (ICRA): Workshop on Semantic Perception, Mapping, and Explora- tion. Pentti Kanerva, 2009. Hyperdimensional computing: an introduction to computing in distributed representation with high-dimensional random vectors. Cognitive Computation 1, 139–159. Kato Keizo, Li Yin, Gupta Abhinav, 2018. Compositional learning for human object interaction. In: Proceedings of the European Conference on Computer Vision (ECCV), pp. 234–251. Kjellström Hedvig, Romero Javier, Kragić Danica, 2011. Visual object-action recogni- tion: inferring object affordances from human demonstration. Computer Vision and Image Understanding 115 (1), 81–90. Kodirov Elyor, Xiang Tao, Gong Shaogang, 2017. Semantic autoencoder for zero- shot learning. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3174–3183. Koppula Hema S., Saxena Ashutosh, 2014. Physically grounded spatio-temporal object affordances. In: European Conference on Computer Vision. Springer, pp. 831–847. Koppula Hema S., Saxena Ashutosh, 2015. Anticipating human activities using object affordances for reactive robotic response. IEEE Transactions on Pattern Analysis and Machine Intelligence 38 (1), 14–29. Koppula Hema Swetha, Gupta Rudhir, Saxena Ashutosh, 2013. Learning human activities and object affordances from rgb-d videos. The International Journal of Robotics Research 32 (8), 951–970. Lee David C., Gupta Abhinav, Hebert Martial, Kanade Takeo, 2010. Estimating spa- tial layout of rooms using volumetric reasoning about objects and surfaces. In: Advances in Neural Information Processing Systems, pp. 1288–1296. Levy S. D., Gayler R., 2008. Vector symbolic architectures: a new building material for artificial general intelligence. In: Proceedings of the First Conference on Artificial General Intelligence (AGI-08). IOS Press. Liu Fayao, Shen Chunhua, Lin Guosheng, 2015. Deep convolutional neural fields for depth estimation from a single image. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5162–5170. Mandal Devraj, Narayan Sanath, Kumar Dwivedi Sai, Gupta Vikram, Ahmed Shuaib, Shahbaz Khan Fahad, Shao Ling, 2019. Out-of-distribution detection for gener - alized zero-shot action recognition. In: Proceedings of the IEEE/CVF Confer - ence on Computer Vision and Pattern Recognition, pp. 9985–9993. Martin A., 2007. The representation of object concepts in the brain. Annual Review of Psychology 58, 25–45. Metta Giorgio, Sandini Giulio, Vernon David, Natale Lorenzo, Nori Francesco, 2008. The iCub humanoid robot: an open platform for research in embodied cogni- tion. In: Proceedings of the 8th Workshop on Performance Metrics for Intel- ligent Systems, pp. 50–56. Mikolov Tomas, Chen Kai, Corrado Greg, Dean Jeffrey, 2013. Efficient estimation of word representations in vector space. arXiv preprint. arXiv:1301.3781.\n--- Страница 512 ---\nЛитературные источники  511 Miller George A., Beckwith Richard, Fellbaum Christiane, Gross Derek, Miller Kather- ine J., 1990. Introduction to wordnet: an on-line lexical database. International Journal of Lexicography 3 (4), 235–244. Mitchell T., Cohen W., Hruschka E., Talukdar P., Betteridge J., Carlson A., Dalvi B., Gardner M., Kisiel B., Krishnamurthy J., Lao N., Mazaitis K., Mohamed T., Na- kashole N., Platanios E., Ritter A., Samadi M., Settles B., Wang R., Wijaya D., Gupta A., Chen X., Saparov A., Greaves M., Welling J., 2015. Never-ending learn- ing. In: Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intel- ligence (AAAI-15). Mitrokhin A., Sutor P., Fermüller C., Aloimonos Y., 2019. Learning sensorimotor control with neuromorphic sensors: toward hyperdimensional active percep- tion. Science Robotics 4 (30), eaaw6736. Montesano Luis, Lopes Manuel, Bernardino Alexandre, Santos-Victor José, 2008. Learning object affordances: from sensory–motor coordination to imitation. IEEE Transactions on Robotics 24 (1), 15–26. Myers Austin, Teo Ching L., Fermüller Cornelia, Aloimonos Yiannis, 2015. Affordance detection of tool parts from geometric features. In: 2015 IEEE International Conference on Robotics and Automation (ICRA), pp. 1374–1381. Nguyen Anh, Kanoulas Dimitrios, Caldwell Darwin G., Tsagarakis Nikos G., 2017. Object-based affordances detection with convolutional neural networks and dense conditional random fields. In: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 5908–5915. Pagliardini Matteo, Gupta Prakhar, Jaggi Martin, 2017. Unsupervised learning of sentence embeddings using compositional n-gram features. arXiv preprint. arXiv:1703.02507. Parikh Devi, Grauman Kristen, 2011. Relative attributes. In: International Confe- rence on Computer Vision, pp. 503–510. Pastra Katerina, Aloimonos Yiannis, 2012. The minimalist grammar of action. Phi- losophical Transactions of the Royal Society B: Biological Sciences 367 (1585), 103–117. Plate Tony A., 1995. Holographic reduced representations. IEEE Transactions on Neural Networks 6 (3), 623–641. Qi Siyuan, Huang Siyuan, Wei Ping, Zhu Song-Chun, 2017. Predicting human ac - tivities using stochastic grammar. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 1164–1172. Qi Siyuan, Wang Wenguan, Jia Baoxiong, Shen Jianbing, Zhu Song-Chun , 2018. Learning human-object interactions by graph parsing neural networks. In: Proceedings of the European Conference on Computer Vision (ECCV), pp. 401– 417. Roy Anirban, Todorovic Sinisa, 2016. A multi-scale cnn for affordance segmenta- tion in rgb images. In: European Conference on Computer Vision. Springer, pp. 186–201. Russakovsky Olga, Deng Jia, Su Hao, Krause Jonathan, Satheesh Sanjeev, Ma Sean, Huang Zhiheng, Karpathy Andrej, Khosla Aditya, Bernstein Michael, et al., 2015. Imagenet large scale visual recognition challenge. International Journal of Computer Vision 115 (3), 211–252.\n--- Страница 513 ---\n512  Обучение пониманию сцены на основании действий Schuler Karin Kipper, 2005. VerbNet: a broad-coverage, comprehensive verb lexi- con. PhD thesis. Computer and Information Science Department, University of Pennsylvania, Philadelphia, PA. Sigurdsson Gunnar A., Russakovsky Olga, Gupta Abhinav, 2017. What actions are needed for understanding human actions in videos? In: Proceedings of the IEEE International Conference on Computer Vision, pp. 2137–2146. Silberman Nathan, Hoiem Derek, Kohli Pushmeet, Fergus Rob, 2012. Indoor segmen- tation and support inference from rgbd images. In: European Conference on Computer Vision. Springer, pp. 746–760. Simonyan Karen, Zisserman Andrew, 2014. Very deep convolutional networks for large-scale image recognition. arXiv preprint. arXiv:1409.1556. Srikantha Abhilash, Gall Jürgen, 2016.Weakly supervised learning of affordances. arXiv preprint. arXiv:1605.02964. Stark Louise, Bowyer Kevin, 1991. Achieving generalized object recognition through reasoning about association of function to structure. IEEE Transactions on Pat - tern Analysis and Machine Intelligence 13 (10), 1097–1104. Summers-Stay Douglas, Teo Ching L., Yang Yezhou, Fermüller Cornelia, Aloimonos Yiannis, 2012. Using a minimal action grammar for activity understanding in the real world. In: IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 4104–4111. Teo Ching Lik, Fermüller Cornelia, Aloimonos Yiannis , 2015. Detection and segmen - tation of 2d curved reflection symmetric structures. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 1644–1652. Tran Son D., Davis Larry S., 2008. Event modeling and recognition using Mar - kov logic networks. In: European Conference on Computer Vision. Springer, pp. 610–623. Ugur Emre, Erhan Oztop, Erol Sahin, 2011. Goal emulation and planning in per - ceptual space using learned affordances. Robotics and Autonomous Systems 59 (7–8), 580–595. Ugur Emre, Piater Justus, 2016. Emergent structuring of interdependent affordance learning tasks using intrinsic motivation and empirical feature selection. IEEE Transactions on Cognitive and Developmental Systems 9 (4), 328–340. Varela Francisco J., Rosch Eleanor, Thompson Evan, 1993. The Embodied Mind: Cognitive Science and Human Experience. MIT Press. Wörgötter Florentin, Erdal Aksoy Eren, Krüger Norbert, Piater Justus, Ude Ales, Ta- mosiunaite Minija, 2013. A simple ontology of manipulation actions based on hand-object relations. IEEE Transactions on Autonomous Mental Development 5 (2), 117–134. Wörgötter Florentin, Ziaeetabar F., Pfeiffer S., Kaya O., Kulvicius T., Tamosiunaite M., 2020. Humans predict action using grammar-like structures. Scientific Reports 10 (1), 1–11. Xian Yongqin, Lorenz Tobias, Schiele Bernt, Akata Zeynep, 2018. Feature generat - ing networks for zero-shot learning. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5542–5551. Xiao Jianxiong, Hays James, Ehinger Krista A., Oliva A., Torralba A., 2010. Sun data- base: large-scale scene recognition from abbey to zoo. IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 3485–3492.\n--- Страница 514 ---\nОб авторах главы  513 Yan Sijie, Xiong Yuanjun, Lin Dahua, 2018. Spatial temporal graph convolutional networks for skeleton-based action recognition. In: Proceedings of the AAAI Conference on Artificial Intelligence, vol. 32. Yang Yezhou, Fermüller Cornelia, Aloimonos Yiannis, 2013. Detection ofmanipula- tion action consequences (MAC). In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2563–2570. Yang Yezhou, Guha Anupam, Fermüller Cornelia, Aloimonos Yiannis, 2014. A cog- nitive system for understanding human manipulation actions. Advances in Cognitive Systems 3, 67–86. Yang Yezhou, Fermüller Cornelia, Li Yi, Aloimonos Yiannis, 2015a. Grasp type revis- ited: a modern perspective on a classical feature for vision. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 400–408. Yang Yezhou, Li Yi, Fermüller Cornelia, Aloimonos Yiannis, 2015b. Robot learning manipulation action plans by “watching” unconstrained videos from the world wide web. In: Proceedings of the AAAI Conference on Artificial Intelligence, vol. 29. Ye Chengxi, Yang Yezhou, Mao Ren, Fermüller Cornelia, Aloimonos Yiannis, 2017. What can I do around here? Deep functional scene understanding for cognitive robots. In: IEEE International Conference on Robotics and Automation (ICRA), pp. 4604–4611. Yu Xiaodong, Fermüller Cornelia, Teo Ching Lik, Yang Yezhou, Aloimonos Yiannis, 2011. Active scene recognition with vision and language. In: 2011 International Conference on Computer Vision, pp. 810–817. Zampogiannis Konstantinos, Fermüller Cornelia, Cilantro Yiannis Aloimonos, 2018. A lean, versatile, and efficient library for point cloud data processing. In: Pro- ceedings of the 26th ACM International Conference onMultimedia, pp. 1364– 1367. Zampogiannis Konstantinos, Fermüller Cornelia, Aloimonos Yiannis, 2019. Topol- ogy-aware non-rigid point cloud registration. IEEE Transactions on Pattern Analysis and Machine Intelligence. Zampogiannis Konstantinos, Yang Yezhou, Fermüller Cornelia, Aloimonos Yiannis, 2015. Learning the spatial semantics of manipulation actions through preposi- tion grounding. In: IEEE International Conference on Robotics and Automation (ICRA), pp. 1389–1396. Zhang Li, Xiang Tao, Gong Shaogang, 2017. Learning a deep embedding model for zero-shot learning. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2021–2030. Zheng J., Jiang Z., Chellappa R., 2016. Cross-view action recognition via trans- ferable dictionary learning. IEEE Transactions on Image Processing 25 (6), 2542–2556. об аВтора Х гЛаВы Корнелия Фермюллер – научный сотрудник Института перспективных компьютерных исследований Мэрилендского университета. Она получила докторскую степень в Венском технологическом университете и степень ма-\n--- Страница 515 ---\n514  Обучение пониманию сцены на основании действий гистра в Технологическом университете Граца, обе по прикладной математи- ке. Ее исследовательский интерес заключался в том, чтобы понять принципы систем активного зрения и разработать методы, основанные на подобии биологическим системам, особенно в области движения. Ее последняя работа была посвящена интерпретации действий человека и разработке алгоритмов трехмерного движения для экстремальных условий с использованием дат - чиков на основе событий. Майкл Мейнорд – докторант кафедры компьютерных наук Колледж-Парка Университета Мэриленда, советниками которого являются Яннис Алоимонос и Корнелия Фермюллер. Область его исследовательских интересов охваты- вает символический искусственный интеллект, когнитивные архитектуры, компьютерное зрение, понимание действий и методы интеграции ИИ и ком- пьютерного зрения.",
      "debug": {
        "start_page": 475,
        "end_page": 515
      }
    },
    {
      "name": "Глава 12. Сегментация событий во времени с использованием когнитивного самообучения 515",
      "content": "--- Страница 516 --- (продолжение)\nГлава 12 Сегментация событий во времени с использованием когнитивного самообучения Авторы главы: Рами Мунир, кафедра вычислительной техники и технологии, Университет Южной Флориды, Тампа, Флорида, США; Сатьянараянан Аакур, факультет информатики, Государственный университет Оклахомы, Стилуотер, Оклахома, США; Судип Саркара Краткое содержание главы: мы можем использовать теории когнитивной науки в области сегментации событий для разработки высокоэффективных алгоритмов компьютерного зрения, которые выполняют пространственно-временную сегментацию со- бытий в видеопотоке, не требуя каких-либо размеченных заранее данных; мы обсудим три современные версии прогнозной модели восприятия: временная сегментация с использованием архитектуры перцептивного предсказания, временная сегментация с рабочими моделями событий, основанными на картах внимания, и, наконец, пространственная и вре- менная локализация событий; вышеупомянутые современные методы могут изучить надежные пред- ставления событий всего лишь из одного прохода через немаркированное потоковое видео; новые методы демонстрируют уникальную точность в задаче времен- ной сегментации и пространственно-временной локализации действий с обуче нием без учителя, предлагая конкурентоспособное качество по сравнению с базовыми моделями обуче ния с учителем, которые требуют большого объема аннотированных данных.\nГлава 12 Сегментация событий во времени с использованием когнитивного самообучения Авторы главы: Рами Мунир, кафедра вычислительной техники и технологии, Университет Южной Флориды, Тампа, Флорида, США; Сатьянараянан Аакур, факультет информатики, Государственный университет Оклахомы, Стилуотер, Оклахома, США; Судип Саркара Краткое содержание главы: мы можем использовать теории когнитивной науки в области сегментации событий для разработки высокоэффективных алгоритмов компьютерного зрения, которые выполняют пространственно-временную сегментацию со- бытий в видеопотоке, не требуя каких-либо размеченных заранее данных; мы обсудим три современные версии прогнозной модели восприятия: временная сегментация с использованием архитектуры перцептивного предсказания, временная сегментация с рабочими моделями событий, основанными на картах внимания, и, наконец, пространственная и вре- менная локализация событий; вышеупомянутые современные методы могут изучить надежные пред- ставления событий всего лишь из одного прохода через немаркированное потоковое видео; новые методы демонстрируют уникальную точность в задаче времен- ной сегментации и пространственно-временной локализации действий с обуче нием без учителя, предлагая конкурентоспособное качество по сравнению с базовыми моделями обуче ния с учителем, которые требуют большого объема аннотированных данных.\n--- Страница 517 ---\n516  Сегментация событий во времени с использованием когнитивного самообучения 12.1. В Ведение Как мы обнаруживаем и сегментируем события? Как мы представляем со- бытия? Как мы воспринимаем события? И что более важно, что такое со- бытие? В исследованиях компьютерного зрения термины действие (action), деятельность (activity) и событие (event) часто смешивают. В большинстве работ эти термины используют вперемежку, чтобы обозначить что-то, что происходит в сцене с участием объектов и действующих персон (áкторов) и может быть аннотировано текстовой меткой, например «прыжки», «наре- зание лука», «замена шин», «приготовление еды» и т. д. В существующей ли- тературе по компьютерному зрению нет четкого различия между распозна- ванием действий, деятельности и событий. Много неясного и в определениях характера событий. С другой стороны, восприятие событий является зрелой областью исследований когнитивной науки (Radvansky, Zacks, 2014; Shipley, Zacks, 2008; Richmond, Zacks, 2017). Мы начнем с обобщения некоторых до- стижений когнитивной науки, которые используем в качестве источника вдохновения для создания решений, изложенных в этой главе. В идеале сле- дует прочитать первоисточники из приведенного в конце главы списка, а не полагаться только на наш обзор, который является лишь кратким введением в гораздо более богатую область знаний. Здесь мы выделим лишь некоторые идеи, которые использовали для создания решений компьютерного зрения в области временной сегментации событий с самообучением. События являются ключевыми компонентами нашего опыта. Мозг полу - чает непрерывный поток сенсорной информации как из внешнего мира, так и из тела, и сегментирует их на дискретные единицы или пакетные пред- ставления, называемые событиями. Каждое событие указывает на ключевые моменты входного сенсорного потока. Следовательно, событие определяется как «отрезок времени в данном месте, который воспринимается наблюдате- лем как имеющий начало и конец» (Zacks, Tversky, 2001). Обратите внимание, что это определение событий отличает их от деятельности. Например, при- готовление пищи как таковое – это деятельность, а приготовление салата – это событие. У приготовления салата есть начало, середина и конец. События могут быть разных типов и продолжительности в зависимости от агента и воздействующей на него среды. Некоторые события короткие, например заправить постель. Некоторые события продолжительные, например матч по крикету. События с участием осмысленных агентов, таких как люди и живот - ные, часто являются целенаправленными. Хотя цель этих событий не всегда сразу видна наблюдателю, она существует как задача, которая направляет событие. Существуют также события, в которых не участвуют осмысленные агенты и которые не имеют целей, например природные явления. Широкой популярностью пользуется идея о том, что человеческое позна- ние использует «структурированные представления событий, называемые мо- делями событий, для сбора информации о пространственно-временной струк - туре, сущностях и объектах, а также других существенных характеристиках ситуации» (Richmond, Zacks, 2017). Эти модели событий являются компози- ционным представлением события и составляющих его элементов и имеют партономии, т. е. иерархии, образованные отношением «часть–целое». На\n--- Страница 518 ---\nВведение  517 рис. 12.1 показаны пример события «сделать бутерброд» и его иерархическая структура. На самом нижнем уровне иерархии находятся элементарные дей- ствия, такие как «принести нож» и «открыть крышку». Эти действия являются частью более длительных блоков действий, таких как «разрезать булочку», которые, в свою очередь, являются частью события «сделать бутерброд». Партономия действий аналогична партономии предметов, которые также могут быть описаны как композиция отдельных частей. Сделать бутерброд После До Разрезать булочкуНамазать маслоПоложить повидло Достать хлебПринести хлебНарезать хлебПринести ножВзять ножОткрыть крышкуНабрать маслаДвигатьсяВзять повидлоОткрыть крышку Рис. 12.1  Иерархия событий состоит из нескольких уровней сегментации. Событие более высокого уровня «Приготовление бутерброда» можно разде- лить на события более низкого уровня «Разрезание булочки», «Намазывание маслом» и «Добавление повидла». Каждое событие более низкого уровня мо- жет быть далее сегментировано на составляющие его события на еще более низком уровне. Событие «Сделать бутерброд» может быть частью события бо- лее высокого уровня «Позавтракать». Это композиционное отношение между событиями образует иерархию событий. Изображения взяты из набора данных «Действия за завтраком» (Kuehne et al., 2014) Так же, как и части физических объектов, которые имеют видимые грани- цы, события имеют границы сегментации в нескольких временных масшта- бах. Сегментация событий и группировка сегментов в иерархию – это непре- рывные процессы, происходящие одновременно в нескольких временных масштабах. Данные нейробиологических экспериментов (Zacks et al., 2001a) указывают на то, что задняя височная область, теменная кора и латеральная лобная кора становятся активными во время достижения границ событий. Некоторые эксперименты (Kurby, Zacks, 2008) показывают, что сегментация событий играет важную роль в основных функциях когнитивного восприятия и кодирования памяти. Однако процесс сегментации событий не требует сознательного внимания. Сегментация событий может быть обработана ис - ключительно восходящими признаками на основе сигналов, извлеченными из движения и внешнего вида. Этот вывод был основан на киноэксперимен-\n--- Страница 519 ---\n518  Сегментация событий во времени с использованием когнитивного самообучения те (Zacks et al., 2001; Zacks, Magliano, 2011). Некоторым участникам были показаны видеоролики о событиях, и их попросили отметить границы со- бытий с по мощью нажатия кнопки во время просмотра. Других участников попросили сделать то же самое, но им показали фильм наоборот! Границы, отмеченные обеими группами участников, были удивительно похожи. Изме - нение направления фильма не позволяет зрителям полагаться на знакомые схемы для интерпретации событий, что затрудняет идентификацию высоко- уровневой информации, такой как достижение цели (Hard et al., 2006). Это свидетельствует в пользу предположения, что высокоуровневая информация о событии не является необходимой для сегментации событий. Следователь- но, мы можем поставить перед собой задачу разработать системы компью- терного зрения, которым не нужны предварительные обучающие метки для сегментации событий, т. е. разработать самообучаемые алгоритмы сегмен- тации событий в непрерывном режиме реального времени. В этой главе мы рассматриваем проблему сегментации событий, т. е. то, каким образом мы отмечаем временные границы (когда одно событие за- канчивается и начинается другое) и локализуем их в пространстве изобра- жения. Построение событийной модели и партономической иерархии – это отдельный процесс, который мы здесь не рассматриваем. Сначала мы рас - смотрим модель теории сегментации событий (event segmentation theory, EST) для вычисления границ событий (Zacks et al. (2014)), основанную на модели перцептивного предсказания. Затем представим наше решение для компьютерного зрения, основанное на модели перцептивного предсказания из EST, в трех последовательных версиях: временная сегментация с исполь- зованием структуры прогнозирования восприятия, временная сегментация вместе с рабочими моделями событий, основанными на картах внимания, и, наконец, пространственная и временная локализация событий. Мы за- кончим главу обсуждением других решений для сегментации событий, пред- ставленных в литературе, и того, как они соотносятся с нашими подходами. 12.2. теория сегментации событий В Когнити Вной науКе Теория сегментации событий (EST), разработанная Заком и др. (Zacks et al., 2007), основана на экспериментах по когнитивной нейробиологии. Она утверж дает, что люди сохраняют стабильное представление о том, «что про- исходит сейчас», которое обновляется на основе проходящего увеличения ошибки перцептивного предсказания (perceptual prediction error). Это пред- ставление текущего события называется моделью события и используется для предсказания следующего сенсорного ввода. Этот процесс предсказания является ключевым элементом данной теории; прогнозы играют централь- ную роль в построении представления событий. Наш мозг постоянно делает прогнозы того, с какими признаками окружа- ющей среды наши органы чувств столкнутся в ближайшем будущем. Когда\n--- Страница 520 ---\nТеория сегментации событий в когнитивной науке  519 мы наблюдаем, как кто-то готовит пищу, мы постоянно делаем прогнозы. Эти прогнозы делаются с разной степенью дискретности. Мы предсказываем траекторию движения в краткосрочном, практически мгновенном масштабе, чтобы предвидеть положение руки в следующий момент времени. И, в более грубом масштабе, пытаемся предвидеть, какая посуда будет использована следующей. Существует определение искусственного интеллекта, согласно которому способность делать прогнозы является ключевой характеристи- кой (Hawkins, Blakeslee, 2004). Степень, в которой агент может считаться разумным, определяется временным окном и пространственной областью, в которой он может делать точные прогнозы. Например, маленькое насе - комое может предсказывать свое ближайшее окружение и свое ближайшее будущее. Люди, вооруженные научными рассуждениями и логикой высоко- го уровня, могут предсказывать события в гораздо большем пространстве и в более длительных временных окнах. Содержание прогноза зависит от поставленной задачи. В нашем случае речь идет о предсказании признаков визуального события. Ошибка в прогнозе приводит к тому, что процесс сегментации группирует события в дискретные интервалы времени. Как показано на рис. 12.2, EST Обнаружение ошибок SN, VTA, LC Прогнозируемые будущие входы ACC, … Сенсорные входы A1, V1, S1, …Перцептивная обработка IT, MT+, pSTS, …Модели событий / Латеральный кортексСхемы событий / Латеральный кортекс Рис. 12.2  Информационный поток в соответствии с теорией сегментации событий (EST), согласно исследованию (Zacks et al., 2007). Буквенные аббревиа- туры относятся к различным областям мозга, в которых происходят эти дей- ствия, как это было обнаружено в экспериментах по когнитивной нейробиоло- гии. Блок перцептивной обработки использует сенсорные входы для извлечения признаков более высокого уровня, имеющих отношение к прогнозирующей за- даче. Извлеченные признаки применяются для предсказания будущих призна- ков восприятия, которые затем сравниваются с фактическими признаками вос - приятия из следующего кадра. Модуль обнаружения ошибок вычисляет ошибку предсказания, которая генерирует сигнал сброса (обозначен символом «) при больших ошибках предсказания. Сигнал сброса обновляет модель событий, принимая входные данные от блоков сенсорного входа и обработки восприятия\n--- Страница 521 ---\n520  Сегментация событий во времени с использованием когнитивного самообучения представляет собой постоянный процесс восприятия, который сегменти- рует непрерывный поток мультимодальных сенсорных входных данных на связную последовательность дискретных событий. Этот набор может быть дополнительно сегментирован для формирования иерархии событий в раз- личных временных масштабах. Важно подчеркнуть, что процесс сегмента- ции событий не требует сознательного внимания. Вместо этого сегмента- ция возникает как побочный эффект непрерывного процесса перцептивного предсказания. По мере восприятия сенсорных входных данных перцептивный процессор получает, фильтрует и кодирует поступающие признаки в полезные представ- ления более высокого уровня. В вычислительном отношении перцептивный процессор может быть представлен стеком глубокого обуче ния для обработ - ки и извлечения признаков. Ключевым аспектом перцептивной обработки в EST является то, что закодированные признаки зависят от представлений из рабочей модели событий. Это условие делает представления признаков устойчивыми к небольшим изменениям от одного момента к другому. Ра- бочая модель события управляет перцептивной обработкой для извлечения соответствующих признаков наблюдаемого события. Рабочие модели собы- тий очень специфичны и ограничены в возможностях; они обновляются на границах событий. Блок обработки восприятия отправляет извлеченные признаки (обу - словленные моделью рабочего события) в блок прогнозирования, чтобы предвидеть будущие признаки восприятия. Любое несоответствие между предсказанными и фактическими признаками для следующего момента времени постоянно отслеживается и называется ошибкой предсказания . Ошибка предсказания является мерой качества прогнозов и, следователь- но, индикатором пригодности рабочей модели событий. Временное рез- кое увеличение ошибки предсказания является индикатором границы со- бытия, т. е. сигналом о том, что текущее событие могло измениться. Для продолжения прогнозирования необходима новая модель событий. Таким образом, ошибка предсказания работает как механизм стробирования для обновления рабочей модели представлением нового события. Это обнов- ление рабочей модели события состоит из сенсорной информации и пред- варительных ожиданий из долговременной памяти о следующем событии. Долговременная память событий представлена схемами событий, которые кодируют более стабильное представление события по сравнению с рабочей моделью событий. Схемы событий хранят последовательную информацию с точки зрения отличительных физических характеристик объектов и дей- ствующих лиц, вероятных следующих событий и целей действующих лиц, причем все эти сведения извлекаются из ранее наблюдавшихся событий. Изменения в схемах событий происходят с меньшей скоростью обуче ния, чем в рабочей памяти событий. Качество предсказания зависит от того, насколько точно рабочая модель события представляет восприятие. Как правило, рабочая модель хорошо на- строена, а ошибка прогнозирования невелика. Однако время от времени те- кущие наблюдения могут становиться менее предсказуемыми, что приводит к увеличению ошибки предсказания и необходимости обновления модели\n--- Страница 522 ---\nВариант 1: однопроходная сегментация во времени с использованием предсказания  521 рабочего события. В структуре EST это обновление опосредуется через ме- ханизм стробирования как функцию сигнала ошибки. Когда сигнал ошибки увеличивается, рабочая модель события обновляется на основе сенсорного сигнала и информации из схемы событий до тех пор, пока ошибка не умень- шится. Таким образом, система в целом работает в основном в стабильном состоянии с низкими ошибками прогнозирования и переходными периода- ми высоких ошибок, сигнализирующих о границах событий. 12.3. В ариант 1: однопро Ходная сегментация Во Времени с испо ЛьзоВанием предс Казания Теория сегментации событий предлагает нам механизм сегментации со- бытий во времени, т. е. разбиения видео на части без необходимости обу - чающих меток и в непрерывном онлайн-режиме. В этом разделе мы демон- стрируем возможности EST, используя простую однопроходную реализацию EST, которая превосходит более сложные современные методы глубокого обуче ния с учителем. В вычислительном отношении мы реализуем структуру EST, используя известные компоненты глубокого обуче ния. Блок перцептивного предска- зания выполнен в виде модуля кодера на основе сверточных нейронных сетей (CNN) (LeCun et al., 1995). Ячейка долгой краткосрочной памяти (long short-term memory, LSTM) (Hochreiter, Schmidhuber, 1997) используется для агрегирования признаков во времени и прогнозирования будущих характе- ристик восприятия. Внутренняя структура ячеек LSTM предлагает идеальную альтернативу реализации для прогнозирования перцептивных признаков по двум причинам. Во-первых, рекуррентный характер LSTM позволяет нам интегрировать прошлые кадры, чтобы предсказать будущие. Во-вторых, скрытое состояние LSTM действует как внутренняя модель событий, которую можно использовать для привязки извлеченных признаков к стабильному представлению событий, построенному из предыдущих кадров. Механизм адаптивного обуче ния обеспечивает простой и практичный метод реали - зации механизма стробирования, используемого для обновления модели событий на основе ошибки перцептивного предсказания. В работе (Aakur, Sarkar, 2019) сосредоточились на построении представ- лений для рабочей модели событий и не реализовывали модуль схем собы- тий. Мы начнем с обсуждения кодирования кадров и извлечения признаков в разделе 12.3.1, после чего представим объяснение того, как мы исполь- зуем рекуррентную ячейку для постоянного вычисления представления предыдущих кадров (раздел 12.3.2). Мы также кратко обсудим роль слоя реконструкции в преобразовании предсказанного представления в буду - щие перцептивные признаки в разделе 12.3.3. В разделах 12.3.5 и 12.3.6 мы представляем механизм вентилей и функции адаптивного обуче ния для обнаружения границ. В алгоритме 1 показан псевдокод структуры перцеп- тивного предсказания.\n--- Страница 523 ---\n522  Сегментация событий во времени с использованием когнитивного самообучения Алгоритм 1. Модель временной сегментации событий. Ввод представляет собой необрезанное/потоковое видео 𝕀 , которое представляет собой множество кадров {I 1, , It, It+1, IT}. На выходе получается множество границ событий {b 1, b2, bT–1} Вход: Видеокадры {I 1, , It , It+1, IT} Î ℝT×C×W×H Выход: Значения границ события 𝔹 = {b1, b2, bT–1} 1: procedure LSTM(h t–1, I¢t) 2: i t ¬ σ(Wi I¢t + Whi ht–1 + bi) Входной вентиль 3: f t ¬ σ(Wf I¢t + Whf ht–1 + bf) Вентиль забывания 4: o t ¬ σ(Wo I¢t + Whoht–1 + bo) Выходной вентиль 5: g t ¬ ϕ(Wg I¢t + Whg ht–1 + bg) 6: m t ¬ ft · m t–1 + it · g t 7: h t ¬ ot · ϕ(mt) 8: return ht 9: end procedure 10: procedure GATE(E P(t)) 11: Скользящее среднее 12: if then 13: P q(t – 1) ¬ Pq(t) 14: return True 15: else 16: P q(t – 1) ¬ Pq(t) 17: return False 18: end if 19: end procedure 20: procedure SEGMENT(I t, It+1, ht–1) Главный слой сегментации 21: I¢t ¬ ENCODER(I ¢t) Базовый кодировщик CNN 22: I¢t+1 ¬ ENCODER(I ¢t+1) Базовый кодировщик CNN 23: h t ¬ LSTM(h t–1, I¢t) 24: y t+1 ¬ DECODER(h t) Одиночный плотный слой 25: 26: b t ¬ GATE(E P(t)) 27: return ht, bt 28: end procedure 29: h t ¬ 0 30: for {It, It+1} Î {I1, I2}, {I 2, I3}, …, { IT–1, IT} do 31: h t, bt ¬ SEGMENT(I t, It+1, ht) 32: 𝔹 .append(b t) 33: end for В основе метода, показанного на рис. 12.3, лежит платформа прогнозиру - ющей обработки, которая кодирует визуальный ввод It в абстракцию более высокого уровня I¢t, используя сеть кодировщика. Абстрактная функция ис - пользуется в качестве априорной для прогнозирования функции I¢t+1 в мо-\n--- Страница 524 ---\nВариант 1: однопроходная сегментация во времени с использованием предсказания  523 мент времени t + 1. Модуль предсказания будущего LSTM объединяет из- влеченные признаки со стабильным представлением (скрытым состоянием) события на основе предыдущих кадров для предсказания будущего пер- цептивного представления. Сеть реконструкции или декодера преобразует предсказанное представление в фактические признаки (той же размерности, что и It+1), которые используются для обнаружения границ событий между последовательными действиями в потоковом входном видео. Предсказанный будущий вход Ячейка LSTM Модели событийОбучающий сигнал Обучающий сигналОбнаружение ошибок Блок кодировщика перцептивной обработки Сенсорный вход Кадры Рис. 12.3  Вариант 1: однопроходная сегментация во времени с использо- ванием перцептивного предсказания. Архитектура модели представляет собой урезанную версию блоков, предложенных для EST. Она состоит из четырех ос - новных компонентов: сети кодировщика, блока предсказания, сети декодиро- вания, блока обнаружения ошибок и определения границ 12.3.1. Извлечение и кодирование признаков Мы кодируем входной кадр на каждом временном шаге в абстрактные ви- зуальные признаки более высокого уровня и используем эти признаки в ка- честве основы для перцептивной обработки вместо «сырого» ввода на уровне пикселей (для снижения сложности сети) или семантики более высокого уровня (которой нужны обучающие данные в виде меток). Оптимизиро- ванный кодировщик извлекает только признаки, относящиеся к решаемой задаче, в данном случае к прогнозированию. Процесс кодирования влечет за собой изучение функции g(I(t), ωe), которая преобразует входной кадр It из пространства пикселей в пространство признаков более высокой размер- ности I¢t.\n--- Страница 525 ---\n524  Сегментация событий во времени с использованием когнитивного самообучения Функция преобразования g(I(t), ωe) извлекает соответствующие простран- ственные признаки в сжатое векторное представление с использованием набора обучаемых параметров ωe. На практике здесь можно использовать предварительно обученную базовую архитектуру для кодирования необра- ботанных пикселей в полезные функции. В этом исследовании в качестве функции преобразования g(·) мы используем модель CNN VGG16 (Simonyan, Zisserman, 2014), предварительно обученную на наборе ImageNet (Russa- kovsky et al., 2015). Предварительно обученные веса используются для обес - печения хороших параметров инициализации, но дополнительно настраи- ваются с применением ошибки прогнозирования. 12.3.2. Рекуррентное прогнозирование для прогнозирования признаков Итак, у нас есть перцептивные признаки в момент t (I¢t), и следующим шагом является предсказание перцептивных признаков в момент t + 1. Прогнозиру - емые признаки являются функцией извлеченных признаков I¢t и внутренней рабочей моделью текущего события. Внутренняя модель обрабатывает вход- ной сенсорный сигнал в каждом кадре, подобно блоку обработки восприятия модели события в разделе 12.2. Формально этот процесс можно описать как генеративную модель P(I¢t+1|ωp, It), где ωp – множество скрытых параметров, характеризующих внутреннее состояние текущего наблюдаемого события. Чтобы извлечь временные зависимости между кадрами внутри событий и кадрами между событиями, мы используем сеть LSTM (Hochreiter, Schmid- huber, 1997). Математическая форма модели LSTM представлена в алгорит - ме 1, где σ – нелинейная функция активации, точечный оператор (·) обо- значает умножение Адамара (поэлементное), ϕ – гиперболическая функция тангенса (tanh), а Wx и bx представляют обученные веса и наклоны для каж - дого из вентилей. В совокупности {W hi, Whf, Who, Whg} и их соответствующие смещения составляют обучаемые параметры ω p. Ячейка LSTM, формально определенная в алгоритме 1, состоит из трех основных вентилей: входного it, забывания ft и выходного ot. Вентили за - бывания и входа (в сочетании со слоем памяти gt) работают вместе, чтобы обновлять внутреннюю модель событий в соответствии с их обучаемыми параметрами. Выходной вентиль обрабатывает покадровый входной сигнал восприятия во внутренней памяти текущего события. Стоит отметить, что можно использовать и другие рекуррентные модели, такие как управляемый рекуррентный блок (gated recurrent unit, GRU). Состояние события ht является представлением события, наблюдаемого в момент времени t, и, следовательно, более чувствительно к наблюдаемому входному сигналу I¢(t), чем слой событий, который более устойчив во всех событиях. Слой событий является стробируемым слоем, который получает входные данные от кодировщика и модели рекуррентных событий. Однако входные данные слоя событий модулируются самообучаемым стробирую- щим сигналом (раздел 12.3.5), что свидетельствует о качестве прогнозов, сде-\n--- Страница 526 ---\nВариант 1: однопроходная сегментация во времени с использованием предсказания  525 ланных рекуррентной моделью. Стробирование позволяет быстро обновлять веса, но также поддерживает согласованное состояние в рамках события. 12.3.3. Реконструкция признаков Цель перцептивного процессора (или, скорее, сети реконструкции) состоит в том, чтобы реконструировать предсказанный признак y¢t+1 по исходному предсказанию h t, что максимизирует вероятность p(y¢t+1|ht) µ p(ht|y¢t+1)p(y¢t+1), (12.1) где первый член – это вероятность, а второй – априорная модель признаков (feature prior model). Однако мы моделируем log p (y¢t+1|ht) как логарифми- чески линейную модель f(·), зависящую от весов рекуррентной модели ωp и наблюдаемого признака I ¢t и характеризуемую уравнением (12.2) где Z(ht) – нормировочная константа, не зависящая от весов ωp и используе- мая для получения более конкретной оценки вероятности с учетом неопре- деленности. На практике ее игнорируют, поскольку предиктивное обуче ние обеспечивает необходимую регуляризацию. Модель реконструкции заверша- ет генеративный процесс для прогнозирования функции в момент времени t + 1 и помогает замкнуть цикл самообучения для определения границ со- бытий. 12.3.4. Функция потерь при самообучении Одно из отличительных свойств признаков одного и того же события заклю- чается в том, что они предсказуемы с учетом предыдущих входных данных восприятия и стабильной модели события. Мы используем это свойство для обнаружения границ событий. Следовательно, можем определить функцию ошибки прогнозирования, которая получает прогноз модели y¢t в качестве входных данных и фактические следующие сенсорные признаки I¢t в качестве целей. Результирующая ошибка, называемая ошибкой перцептивного пред- сказания (perceptual prediction error), рассчитывается, как показано в урав- нении (12.3): (12.3) Ошибка перцептивного предсказания обоснованно указывает на степень релевантности внутреннего состояния рекуррентной модели реальному на- блюдаемому событию. Когда событие изменяется путем пересечения грани- цы события, внутренняя модель становится непригодной для использования,\n--- Страница 527 ---\n526  Сегментация событий во времени с использованием когнитивного самообучения что приводит к неправильным прогнозам. Качество предсказания повыша- ется после обновления внутренней модели более новым представлением, способным предсказывать следующие признаки. На рис. 12.4 представлен пример этого эффекта. Минимизация ошибки предсказания служит целевой функцией для обуче ния сети. Предсказанный признак Ошибка самообучения Предсказанные сегментыНаблюдаемый признакGTВзять миску Разбить яйца Зачерпнуть муку ложкой Рис. 12.4  Здесь показана визуализация процесса прогнозирующего обуче ния в теории сегментации событий. Текущие сенсорные входные данные абстрагируют - ся в признаки меньшей изменчивости, на которых основано предсказание. Строит - ся рабочая модель событий, которая используется для непрерывного предсказания признаков, наблюдаемых на следующем временном шаге. Предсказания постоянно сравниваются с наблюдаемыми признаками, и результирующая ошибка предсказа- ния служит индикатором пригодности модели событий. Механизм стробирования, роль которого играет функция ошибки предсказания, модулирует процесс обуче ния и предоставляет сигналы для сегментации событий. Символ  обозначает на ниж - нем графике предсказанные границы событий. Признаки были визуализированы с использованием T-SNE (van der Maaten, Hinton, 2008) для презентации. Воспроиз- ведено с разрешения Аакура и Саркара (Aakur, Sarkar, 2019) 12.3.5. Механизм стробирования на основе ошибок Согласно теории сегментации событий, перцептивные признаки могут стать крайне непредсказуемыми на границах событий, поскольку для обработки\n--- Страница 528 ---\nВариант 1: однопроходная сегментация во времени с использованием предсказания  527 нового события необходимо будет обновить рабочую модель. Например, на рис. 12.4 мы видим, что визуальное представление признаков, изученных се- тью кодировщика для действий «брать миску» и «разбивать яйца», ближе друг к другу, чем для признаков действий «брать миску» и «брать ложку муки». На границах событий рекуррентная внутренняя модель теряет способность объяснять расходящееся пространство признаков, вызывая временное уве- личение ошибки перцептивного предсказания. Мы видим, что ошибка пред- сказания (второй график снизу) хорошо согласуется с сегментацией эталона (второй сверху) для видео «Выпекание блина». Как показано, частота ошибок выше на границах событий и ниже внутри события. Чтобы смоделировать ошибку предсказания и найти границы событий, мы можем использовать фильтр нижних частот для нахождения скользящего среднего значения ошибки предсказаний, сделанных за последние n входных интервалов времени. Мы используем значение n = 5, исходя из среднего вре- мени отклика человеческого восприятия (200 мс) (Thorpe et al., 1996). Нахо- дим скользящее среднее значение ошибки прогноза, называемое качест вом предсказания и определяемое как (12.4) где Pq – качество предсказания, а EP(t) – ошибка предсказания по уравнению (12.3). Сигнал стробирования модели G(t) вырабатывается, когда текущая ошибка предсказания превышает средний показатель качества предсказа- ния не менее чем на 50 %. Формально мы можем определить стробирующую функцию как (12.5) где EP(t) – ошибка предсказания в момент времени t, G(t) – значение строби- рующего сигнала в момент времени t, Pq(t – 1) – средняя метрика качества предсказания в момент времени t, а Ψe – порог ошибки предсказания для обнаружения границ. Для оптимального прогнозирования ошибка перцеп- тивного предсказания должна быть очень высокой в граничных кадрах собы- тия и очень низкой во всех кадрах внутри события. Ψe – это гиперпараметр, который можно использовать для настройки временной шкалы, в которой мы будем обнаруживать границы событий. 12.3.6. Адаптивное обучение для повышения робастности Изучение робастного представления событий лежит в основе подходов к сег - ментации событий с использованием предиктивного обуче ния. Представ- ление события считается робастным, когда ошибка предсказания низка для\n--- Страница 529 ---\n528  Сегментация событий во времени с использованием когнитивного самообучения кад ров внутри событий и высока для кадров между событиями. Если су - ществует переобучение представления события на наблюдениях внутри со- бытия, то незначительные возмущения в необработанном пространстве пик - селей могут увеличить ошибку прогнозирования. Это опровергло бы лежащее в основе предположение о том, что на изменение наблюдаемого события указывают временные ошибки. Кроме того, представление событий должно быть стабильным для событий с различной временной продолжительно- стью, чтобы избежать катастрофического забывания, т. е. ситуации, когда предсказания перестают отражать внутрисобытийные вариации в длинных последовательностях событий. Следовательно, необходимо гарантировать, что модель не будет переобучаться краткосрочным признакам восприятия, сохраняя при этом робастное представление события целиком. Чтобы обеспечить определенную пластичность и избежать катастрофиче- ского забывания в сети, мы используем адаптивное обуче ние. Адаптивное обуче ние похоже на обуче ние с переменной скоростью, широко используе- мый метод обуче ния глубоких нейронных сетей. Однако вместо использова- ния заранее определенных интервалов для изменения скорости обуче ния мы управляем скоростью, исходя из величины ошибки предсказания. Скорость обуче ния можно настраивать, чтобы управлять распространением ошибки обратно на обучаемые параметры. Например, когда перцептивная скорость предсказания ниже средней ско- рости предсказания, прогнозная модель считается хорошим, стабильным представлением текущего события. Распространение ошибки предсказания при наличии хорошего представления события может привести к пере обуче- нию прогнозной модели для этого конкретного события и не способствует обобщению. Следовательно, более низкие скорости обуче ния используются для временных шагов, когда существует незначительная ошибка прогнози- рования, а относительно более высокие – для более высоких ошибок прог - нозирования. Очевидно, что переменная скорость обуче ния позволяет модели намного быстрее адаптироваться к новым событиям (на границах событий, где ве- роятность ошибок выше) и научиться сохранять внутреннее представление для кадров внутри событий. Скорость обуче ния определяется как результат правила адаптивного обуче ния, описанного как функция ошибки перцептив- ного предсказания, определенной в разделе 12.3.4, и может быть записана в виде: (12.6) где Dt–, Dt+ и λ init обозначают масштабирование скорости обуче ния в отрица- тельном направлении, положительном направлении и начальную скорость обуче ния соответственно, и Скорость обуче ния регули- руется исходя из качества предсказания, характеризуемого ошибкой пред-\n--- Страница 530 ---\nВариант 1: однопроходная сегментация во времени с использованием предсказания  529 сказания на временной последовательности между моментами времени t1 и t2, обычно определяемой стробирующим сигналом. 12.3.7. Промежуточный итог 12.3.7.1. Наборы данных Мы оцениваем и анализируем эффективность системы перцептивного пред - сказания на трех больших общедоступных наборах данных – «Действия за завтраком» (Kuehne et al., 2014), наборе данных INRIA (Alayrac et al., 2016) и наборе данных «50 салатов» (Stein, Маккенна, 2013). Каждый набор данных предлагает разные задачи, что позволяет нам оценить эффективность под- хода в различных сложных условиях. Набор данных о действиях за завтраком представляет собой большую коллекцию из 1712 видеороликов о 10 разновидностях деятельности за завт - раком, выполненных 52 субъектами-актерами. Каждая деятельность состоит из нескольких подвидов деятельности, которые имеют визуальные и вре- менные вариации в зависимости от предпочтений и стиля субъекта. Задачу сегментации во времени усложняют различия в качестве визуальных данных и такие помехи, как окклюзии и переменные ракурсы. Набор обучающих видеороликов INRIA содержит 150 видеороликов о 5 различных видах деятельности, собранных с YouTube. Каждое из видео длится в среднем 2 минуты и содержит около 47 дополнительных подвидов деятельности. «Фоновый» класс обозначает последовательность, в которой не существует четкой деятельности, различимой визуально. Это создает серь езную проблему для методов, которые явно не обучены таким визуаль- ным признакам. Набор данных «50 салатов» представляет собой мультимодальный на- бор данных, собранный в области кулинарии. Набор данных содержит более четырех часов аннотированных данных для 25 человек, каждый из которых готовит по два смешанных салата. Он предоставляет данные в различных мо- дальностях, таких как кадры RGB, карты глубины и данные акселерометров, прикрепленных к различным предметам, таким как ножи, ложки и бутылки (это лишь некоторые из них). Аннотации действий предоставлены на разных уровнях детализации – высоком, низком и оценочном. Мы используем оце- ночный уровень «eval» в соответствии с протоколами оценки в предыдущих работах (Lea et al., 2016, 2017). 12.3.7.2. Метрики оценки Для анализа эффективности рассматриваемого подхода мы используем две широко используемые метрики оценки. Мы применяем тот же протокол оцен- ки и код, что и в (Alayrac et al., 2016; Sener, Yao, 2018). По причине обуче ния без учителя при оценке точности используем венгерский алгоритм сравнения для получения взаимно однозначных сопоставлений между предсказанными сегментами и эталонами. Мы используем среднее значение по кадрам (mean\n--- Страница 531 ---\n530  Сегментация событий во времени с использованием когнитивного самообучения over frames, MoF) для оценки способности сети временно локализовать под- категории деятельности. Оцениваем расхождение предсказанных сегментов с эталонной сегментацией с использованием индекса Жаккара (пересечение поверх объединения, или IoU). Мы также используем показатель F1 для оценки качества сегментации. Для оценки задачи распознавания в разделе 12.3.7.4.1 применяется критерий точности на уровне объектов для 48 классов, как по- казано в табл. 3 в статье (Kuehne et al., 2014) и сравнивается с (Kuehne et al., 2014; Aakur et al., 2019; de Souza et al., 2016; Huang et al., 2016). 12.3.7.3. Вариативные исследования Мы оценивали различные варианты нашей структуры, чтобы сравнить эф- фективность каждого компонента. Мы варьировали историю предсказания n и порог ошибки предсказания Ψ. Увеличение окна кадра приводит к объеди- нению кадров и меньших кластеров вблизи границ событий с предыдущим классом деятельности из-за временного увеличения ошибки. Это приводит к более высокому IoU и более низкому MoF. Низкий порог ошибки приводит к чрезмерной сегментации, поскольку механизм обнаружения границ ста- новится чувствительным к небольшим изменениям. Количество предсказан- ных кластеров уменьшается по мере увеличения размера окна и порога. Мы также обучили четыре модели (рис. 12.5) с разными модулями предикторов. Обучили две рекуррентные нейронные сети (RNN) в качестве предикторов с адаптивным обуче нием (AL) и без него, описанные в разделе 12.3.6, обо- значенные как RNN + No AL и RNN + AL соответственно. Мы также обучи- ли LSTM без адаптивного обуче ния (LSTM + No AL) для сравнения с нашей ЭталонLSTM + ALLSTM + No ALRNN + ALRNN + No AL Затянуть ручной тормозПоднять домкрат Заменить колесо Убрать вещи в багажник Рис. 12.5  Вариативные исследования: сравнение вариантов архитектуры модели с использованием RNN и LSTM с адаптивным обуче нием и без него в наборе учебных видео INRIA и видео с эталонным образцом Change Tire (за- мена покрышки). Можно видеть, что сложные визуальные сцены с действиями меньшей продолжительности создают серьезную проблему для модели и вызы- вают фрагментацию и чрезмерную сегментацию. Однако использование адап- тивного обуче ния помогает в некоторой степени смягчить этот эффект. Приме- чание: шкалы сегментации по времени для лучшей наглядности показаны без фонового класса\n--- Страница 532 ---\nВариант 1: однопроходная сегментация во времени с использованием предсказания  531 основной моделью (LSTM + AL). Мы используем RNN в качестве возможной альтернативы из-за необходимости краткосрочных предсказаний будущего (на 1 кадр вперед). 12.3.7.4. Количественная оценка Набор данных «Действия во время завтрака». Мы оцениваем точность нашей полной модели LSTM + AL в наборе данных о действиях во время завт - рака и сравниваем с подходами, использующими полное обуче ние с учите- лем, частичное обуче ние с учителем и обуче ние без учителя. Мы показываем эффективность подхода SVM (Kuehne et al., 2014), чтобы подчеркнуть важ - ность кратковременного моделирования. Как показано в табл. 12.1, метод перцептивного предсказания превзошел все другие методы с обуче нием без учителя и с частичным привлечением учителя, а также некоторые подходы традиционного обуче ния с учителем. Таблица 12.1. Результаты сегментации набора данных «Действия во время завтрака». MoF обозначает метрику «Среднее значение по кадрам», а IoU – метрику «Пересечение поверх объединения» Разметка Метод MoF, % IoU ПолнаяSVM (Kuehne et al., 2014) 15,8 – HTK(64) (Kuehne et al., 2016) 56,3 – ED-TCN (Lea et al., 2017) 43,3 42,0 TCFPN (Ding, Xu, 2018) 52,0 54,9 GRU (Richard et al., 2017) 60,6 – СлабаяOCDC (Bojanowski et al., 2014) 8,9 23,4 ECTC (Huang et al., 2016) 27,7 – Fine2Coarse (Richard, Gall, 2016) 33,3 47,3 TCFPN + ISBA (Ding, Xu, 2018) 38,4 40,6 НетKNN + GMM (Sener, Yao, 2018) 34,6 47,1 Наш метод (LSTM + AL) 42,9 46,9 Следует отметить, что другой метод с обуче нием без учителя (Sener, Yao, 2018) для достижения заявленной точности требует наличия достаточно боль - шого количества кластеров (из эталона). Напротив, наш подход не требует таких знаний и выполняется в потоковом режиме. Кроме того, методы с час - тичным обуче нием (Huang et al., 2016; Richard, Gall, 2016; Ding, Xu, 2018) требуют в качестве входных данных как большого количества действий, так и упорядоченного списка подвидов деятельности. ECTC (Huang et al., 2016) ос - нован на дискриминативной кластеризации, в то время как OCDC (Bojanowski et al., 2014) и Fine2Coarse (Richard, Gall, 2016) основаны на RNN. Набор данных «50 салатов». Мы также оценили наш метод на наборе данных «50 салатов», используя в качестве входных данных только визуаль- ные признаки. Для объективного сравнения представлен показатель средне- го значения по кадрам (MoF). Как видно из табл. 12.2, наш предсказатель- ный метод значительно превосходит другой метод с обуче нием без учителя,\n--- Страница 533 ---\n532  Сегментация событий во времени с использованием когнитивного самообучения улучшая показатель MoF на 6,6 %. Мы также приводим показатели методов классификации на основе кадров VGG и IDT (Lea et al., 2016), чтобы проде- монстрировать эффективность кратковременного моделирования. Таблица 12.2. Результаты сегментации набора данных «50 салатов» с уровнем детализации «Eval». **Результаты модели были преднамеренно представлены без временных ограничений для вариативного тестирования Разметка Метод MoF, % ПолнаяVGG** (Lea et al., 2016) 7,6 IDT** (Lea et al., 2016) 54,3 S-CNN + LSTM (Lea et al., 2016) 66,6 TDRN (Lei, Todorovic, 2018) 68,1 ST-CNN + Seg (Lea et al., 2016) 72,0 TCN (Lea et al., 2017) 73,4 НетLSTM + KNN (Bhatnagar et al., 2017) 54,0 Наш метод (LSTM + AL) 60,6 Следует отметить, что для методов обуче ния с учителем требуется значи- тельно больше обучающих данных – как в виде меток, так и в виде обучаю- щих эпох. Кроме того, метод TCN (Lea et al., 2017) для достижения точности 73,4 % использует данные акселерометра. Набор учебных видео INRIA. Наконец, мы протестировали наш метод на наборе учебных видео INRIA, который создал серьезную проблему в виде большого количества фоновых (шумовых) данных. Была получена оценка F1 для справедливого сравнения с другими современными методами. Как видно из табл. 12.3, предсказательная модель превосходит другой метод с обуче- нием без учителя (Sener, Yao, 2018) на 7,5 %, с частичным обуче нием (Bo- janowski et al., 2014) на 7,9 % и конкурентоспособна в сравнении с методами, основанными на традиционном обучении с учителем (Malmaud et al., 2015; Alayrac et al., 2016; Sener, Yao, 2018). Мы также оценили качество моделей с адаптивным обуче нием и без него. Как видно из табл. 12.3, эффективность LSTM в извлечении долгосрочных временных зависимостей значительна, в первую очередь из-за большой про - должительности действий в наборе данных. Кроме того, адаптивное обуче- ние значительно улучшило структуру сегментации, повысив точность на 9 % и 11 % для модели на основе RNN и модели на основе LSTM соответственно, что указывает на уменьшение переобучения модели визуальными данными. 12.3.7.4.1. Улучшенные функции распознавания действий Чтобы оценить способность сети изучать признаки с высокой степенью раз- личения для последующего распознавания объектов, мы оценили эффектив- ность предсказательного подхода в задаче распознавания. Мы предваритель - но обучаем модель для сегментации во времени, применяя набор данных «Действия во время завтрака», и используем скрытый слой LSTM в качестве источника входных данных для полностью подключенного слоя, миними- зируя потери кросс-энтропии при обучении. Мы также обучили другую сеть\n--- Страница 534 ---\nВариант 1: однопроходная сегментация во времени с использованием предсказания  533 с такой же структурой – VGG16 LSTM – без предварительной подготовки, чтобы показать полезность изученных признаков при самообучении. Таблица 12.3. Результаты сегментации набора обучающих видео INRIA. Для справедливого сравнения использована оценка F1 Разметка Метод F1, % ПолнаяHMM + Текст (Malmaud et al., 2015) 22,9 Дискриминативная кластеризация (Alayrac et al., 2016) 41,4 KNN + GMM (Sener, Yao, 2018) + GT 69,2 СлабаяOCDC + Текстовые признаки (Bojanowski et al., 2014) 28,9 OCDC (Bojanowski et al., 2014) 31,8 НетKNN + GMM (Sener, Yao, 2018) 32,2 Наш метод (RNN + No AL) 25,9 Наш метод (RNN + AL) 29,4 Наш метод (LSTM + No AL) 36,4 Наш метод (LSTM + AL) 39,7 Как видно из табл. 12.4, использование самообучения для предваритель- ного обуче ния сети перед задачей распознавания повышает точность распо- знавания сети и дает качество работы, сравнимое с другими современными методами. Предложенный нами подход повышает точность распознавания на 4,3 % с сетью, не подвергавшейся предварительному обуче нию предска- зательной задаче. Таблица 12.4. Результаты распознавания действий в наборе данных «Действия за завтраком». HCF и AL обозначают созданные вручную признаки и адаптивное обучение соответственно Метод Точность, % HCF + HMM (Kuehne et al., 2014) 14,90 HCF + CFG + HMM (Kuehne et al., 2014) 31,8 RNN + ECTC (Huang et al., 2016) 35,6 RNN + ECTC (Cosine) (Huang et al., 2016) 36,7 HCF + Теория паттернов (de Souza et al., 2016) 38,6 HCF + Теория паттернов + ConceptNet (Aakur et al., 2019) 42,9 VGG16 + LSTM 33,54 VGG16 + LSTM + Предсказательные признаки (AL) 37,87 12.3.7.5. Качественная оценка Благодаря прогнозной самообучаемой архитектуре мы можем изучить после- довательность визуальных признаков в потоковом видео. Качество сегмен- тации модели на наборе данных Breakfast Actions графически представлено на рис. 12.6. Можно видеть, что предсказательная архитектура демонстриру - ет хорошее совпадение с реальными отрезками времени и не страдает чрез- мерной сегментацией, особенно когда сегменты длинные. Длинные после-\n--- Страница 535 ---\n534  Сегментация событий во времени с использованием когнитивного самообучения довательности действий позволяют модели учиться на основе наблюдения, предоставляя больше выборок «внутри события». Кроме того, методы с час - тичным обуче нием, такие как OCDC (Bojanowski et al., 2014) и ECTC (Huang et al., 2016), страдают чрезмерной сегментацией и фрагментацией внутри клас - са. Вероятно, это можно объяснить тем фактом, что они склонны навязывать семантику в виде упорядочения действий в видео независимо от изменений визуальных признаков. Методы на основе традиционного обуче ния с учите- лем, такие как HTK (Kuehne et al., 2016), работают лучше, особенно благодаря их способности назначать семантику визуальным признакам. Однако на них также влияют несбалансированные данные и смещение наборов данных, как видно на рис. 12.6, где фоновый класс был разбит на другие классы. Наши алгоритмы (LSTM + AL)OCDCECTCHTKBG Взять чашку Насыпать хлопья Налить молокоПеремешать хлопья BG Эталон Рис. 12.6  Графическое представление точности сегментации основной модели в наборе данных «Действия за завтраком» на видео с эталонной ин- формацией «Приготовление хлопьев». Предсказательный подход не склонен к излишней сегментации и обеспечивает логичную последовательную сегмен- тацию. Однако видно, что для определения границ визуально похожих действий ему требуется больше времени Мы также провели качественную оценку влияния адаптивного обуче ния и долговременной временной памяти в тесте, который был представлен на рис. 12.5, а соответствующие альтернативные методы описаны в разде- ле 12.2. Можно видеть, что использование адаптивного обуче ния предотвра- щает переобучение модели на внутрисобытийных кадрах любого отдельного класса и помогает обобщать другие классы независимо от объема обучающих данных. Нельзя сказать, что это решает проблему несбалансированных дан- ных, но адаптивное обуче ние в некоторой степени приносит пользу. 12.4. В ариант 2: сегментация с испо ЛьзоВанием моде Лей событий на осно Ве Внимания Простая архитектура перцептивного предсказания, представленная в разде- ле 12.3, использует для прогнозирования глобальное представление входных видеокадров. Она не сосредоточивается на конкретных пространственных областях как для восприятия, так и для прогнозирования и может вообще не\n--- Страница 536 ---\nВариант 2: сегментация с использованием моделей событий на основе внимания  535 замечать детализированные представления событий как таковые. Если бы модели событий могли влиять на перцептивную обработку текущего сен- сорного ввода, это существенно дополнило бы возможности EST (рис. 12.2). В нашей предыдущей модели эта возможность была косвенно реализована через структуру памяти в LSTM. В этом разделе мы покажем, что инфра- структура модели может быть дополнена идеей пространственного внима- ния (spatial attention), чтобы помочь ей сосредоточиться на ограниченных пространственных областях для более детализованного подхода к сегмен- тации, что позволит обрабатывать очень длинные видеопоследовательно- сти без потребности в значительном обучении. Полная архитектура модели детально изображена на рис. 12.7 и формально выражена в алгоритме 2. Предсказанные будущие входы Ячейка LSTM Модели событий ВниманиеОбучающий сигнал Обучающий сигналОбнаружение пространственно-временных ошибок Блок кодера обработки восприятия Входной сигнал Кадры Рис. 12.7  Вариант 2: сегментация действий во времени с использованием моделей событий, основанных на внимании. Архитектура самообучающегося алгоритма перцептивного предсказания дополнена механизмом внимания, который предлагает более сильный способ воздействия модели события на текущую сенсорную информацию. Входные кадры на каждый момент време- ни кодируются в признаки высокого уровня с использованием стека глубоко- го обуче ния, за которым следует наложение механизма внимания на основе входных данных из предыдущих моментов времени, которые вводятся в LSTM. Потери при обучении вычисляются на основе разницы предсказанных и вы- численных признаков текущего и следующего кадров\n--- Страница 537 ---\n536  Сегментация событий во времени с использованием когнитивного самообучения Механизм пространственного внимания помогает сети изучить функцию внимания между внутренней моделью текущего события в рекуррентной памяти и входными данными на каждом такте времени. Полученную карту внимания можно использовать для пространственной локализации события в каждом обрабатываемом кадре. Алгоритм 2. Модель сегментации событий во времени с пространственной локализацией на основе внимания. Ввод представляет собой необрезанное/ потоковое видео 𝕀 , которое представляет собой множество кадров {I 1, , It, It+1, IT}. На выходе получается множество границ событий {b 1, b2, bT–1} Вход: Видеокадры {I 1, , It , It+1, IT} Î ℝT×C×W×H Выход: Значения границ события 𝔹 = {b1, b2, bT–1} 1: procedure ATTENTION(I ¢t, ht–1) Модуль внимания 2: a t ¬ linear( tanh( linear( ht–1) + linear( I¢t))) 3: A t ¬ softmax( at) 4: I t² ¬ At ʘ I¢t 5: return It² 6: end procedure 7: procedure SEGMENT(I t, It+1, ht–1, yt–1) Главный слой сегментации 8: I¢t ¬ ENCODER(I t) Базовый кодировщик CNN 9: I¢t+1 ¬ ENCODER(I t+1) Базовый кодировщик CNN 10: I t² ¬ ATTENTION(I ¢t, ht–1) 11: h t ¬ LSTM(h t–1, linear( concat( It², yt–1))) 12: y t ¬ DECODER(h t) Одиночный плотный слой 13: e t ¬ ||(I¢t+1 – yt)ʘ2 ʘ (I¢t+1 – I¢t)ʘ2||2 Взвешенная потеря 14: b t ¬ GATE(e t) 15: return ht, bt, yt 16: end procedure 17: h t ¬ 0 18: y t–1 ¬ 0 19: for {It, It+1} Î {I1, I2}, {I 2, I3}, …, { IT–1, IT} do 20: h t, bt, yt ¬ SEGMENT(I t, It+1, ht, yt–1) 21: 𝔹 .append(b t) 22: end for 12.4.1. Извлечение признаков Процесс извлечения признаков в этой архитектуре отличается от рассмот - ренной ранее. Чтобы работал механизм внимания, нам нужно обрабатывать пространственное расположение векторов признаков. В этой архитектуре кодировщик выводит сетку векторов признаков с тем же пространственным разрешением, что и результирующая карта внимания. Другими словами, ме- ханизм внимания диктует значение внимания, присваиваемое каждому из закодированных векторов признаков. В кодировщике мы используем только\n--- Страница 538 ---\nВариант 2: сегментация с использованием моделей событий на основе внимания  537 операции свертки, поскольку ядра (веса) поддерживают пространственную конфигурацию карт признаков. Необработанные входные изображения преобразуются из пространства пикселей в пространство признаков более высокого уровня с использовани- ем модели кодировщика (CNN). Это закодированное представление призна- ков позволяет сети извлекать признаки, более важные для изучаемой задачи. Сеть кодировщика преобразует входное изображение с размерами W×H×D в выходные признаки с размерами N×N×M, где N×N – пространственные раз- меры, а M – длина вектора признаков. 12.4.2. Модуль внимания Модули внимания успешно применяются в задачах, где есть обуче ние с учи- телем, таких как создание подписей к изображениям (Xu et al., 2015), а так - же для различных задач обработки естественного языка, таких как перевод и языковое моделирование (Vaswani et al., 2017; Bahdanau et al., 2014; Luong et al., 2015; Devlin et al., 2018; Ян и др., 2019). В авторегрессионных языковых мо- делях внимание используется для предоставления декодирующей рекуррент - ной ячейке различных временных или пространственных сегментов ввода на каждом временном шаге. Мы используем внимание в несколько иной форме, когда LSTM декодируется только один раз (для каждого входного кадра) для предсказания будущих признаков и использует для этого взвешенный по вниманию ввод. В отличие от (Xu et al., 2015; Vaswani et al., 2017; Bahdanau et al., 2014; Luong et al., 2015; Devlin et al., 2018; Yang et al., 2019), веса внимания обучаются с использованием функций потерь обуче ния без учителя. В рассматриваемой архитектуре мы используем внимание Бахданау (Bahdanau et al., 2014, 2014) для пространственной локализации события в каждом обработанном кадре. Блок внимания получает в качестве входных данных закодированные признаки и выводит набор весов внимания (A t) с размерами N×N×1. Скрытые векторы признаков (h t–1) из слоя предсказания предыдущего временного шага используются для вычисления выходных ве- сов внимания (изображенных на рис. 12.7) как At = γ(FC(tanh( FC(ht–1) + FC(I¢t)))), (12.7) где FC представляет собой один полносвязный слой нейронной сети, а γ – функцию softmax. Затем веса (A t) умножаются на закодированные входные векторы признаков (I ¢t) для создания маскированных векторов признаков (I t²). Некоторая визуализация результирующих масок пространственного внима- ния показана на рис. 12.8. Маска внимания извлекается из At, линейно масшта- бируется, а затем накладывается на необработанное входное изобра жение (I t). 12.4.3. Функция потерь, взвешенная по движению Потери предсказания, которые мы обсуждали в разделе 12.3.4, применяют функцию потерь L2 к предсказанию всего кадра. В этом разделе мы вводим\n--- Страница 539 ---\n538  Сегментация событий во времени с использованием когнитивного самообучения взвешенную по движению функцию потерь (motion weighted loss function), кото- рая извлекает признаки, связанные с движением, из векторов признаков. По- тери, взвешенные по движению, рассматриваются в пространстве признаков закодированных кадров, а не в «сыром» пространстве пикселей, и вычисляют - ся с использованием непрерывной маски, применяемой к потерям предска- зания. Эта модификация обеспечивает увеличение потерь предсказания для движущихся объектов при одновременном снижении потерь статических/ фоновых объектов. На рис. 12.8 показано сравнение предсказания и взвешен- ных потерь движения для событий, когда птица входит в гнездо и выходит из него. Взвешенные потери при движении формально определяются как et ¬ ||(I¢t+1 – yt)ʘ2 ʘ (I¢t+1 – I¢t)ʘ2||2, (12.8) где символ ʘ обозначает операцию Адамара (поэлементно). Обратите вни- мание, что взвешенный по движению вектор (второй член) вычисляется на уровне признаков, а не на уровне пикселей, и, следовательно, более устойчив к незначительным изменениям из-за шума сенсора. Потери предсказания с течением времени Взвешенные потери движения с течением времениНет деятельности Правильное обнаружение Рис. 12.8  Графики предсказания и потерь, взвешенных по движению, до, во время и после деятельности. Вверху: потери при предсказании признаков по кадрам. Внизу: потери при предсказании признаков, взвешенных по движению, по кадрам. Ошибки для некоторых выбранных кадров показаны на обоих гра- фиках с наложением соответствующей карты внимания 12.4.4. Результаты В этом разделе мы рассмотрим результаты обработки видео за несколько дней, с целью отметить пространственное положение и временные границы\n--- Страница 540 ---\nВариант 2: сегментация с использованием моделей событий на основе внимания  539 событий. В отличие от других наборов данных, события в столь продолжи- тельных видеороликах происходят только в нескольких кадрах, в то время как остальная часть видео не содержит значительных событий или движения (фоновых действий). Мы модифицируем фреймворк перцептивного пред- сказания, включив в него механизм внимания для пространственной лока- лизации, а также маскируем функцию потери предсказания для извлечения признаков, связанных с движением. Начнем с описания расширенного на- бора видеоданных о дикой природе, используемого для тестирования моди- фицированного метода, после чего дадим пояснения по поводу показателей, используемых для количественной оценки качества модели. Мы обсудим оцененные варианты модели и в заключение представим количественные и качественные результаты. 12.4.4.1. Набор данных Мы анализируем качество нашей модели на наборе данных мониторинга дикой природы. Набор данных состоит из 10 дней (254 часа) непрерывного наблюдения за гнездом кагу, нелетающей птицы из Новой Каледонии. Метки видео обозначают четыре уникальных вида деятельности птиц: {кормление птенца, инкубация/высиживание, строительство гнезда, сидение в гнезде, достраивание гнезда}. Вместе с метками для каждого экземпляра упомя- нутых видов деятельности предоставляется время начала и окончания. Мы изменили метки, добавив в них события «вход» и «выход», представляющие переходные события от пустого гнезда к инкубации и наоборот. Наш вариант может включать строительство гнезда (начальный садок и достраивание), кормление птенца, вход и выход. Другие события, основанные на климате, времени суток, условиях освещения, игнорируются нашей сетью сегмента- ции. На рис. 12.9 показана выборка изображений из набора данных. Рис. 12.9  Образцы изображений из набора данных мониторинга дикой природы (видеоролик про жизнь птиц кагу) 12.4.4.2. Критерии оценки Количественные результаты представлены в виде графиков рабочих харак - теристик приемника (receiver operating characteristic, ROC) для сегмента- ции событий как на уровне кадра (рис. 12.10), так и на уровне деятельности (рис. 12.11 и 12.12). Размер окна кадра (ϕ ) определяется как максимальный размер окна относительно слияния событий; высокое значение ϕ может при-\n--- Страница 541 ---\n540  Сегментация событий во времени с использованием когнитивного самообучения вести к слиянию отдельных обнаруженных событий, что снижает общий по- казатель качества. 12.4.4.2.1. Уровень кадра Значение полноты отклика в ROC на уровне кадра рассчитывается как от - ношение истинно положительных кадров (наличие события) к количеству положительных кадров в наборе данных, а доля ложных срабатываний вы- ражается как отношение ложноположительных кадров к общему количеству отрицательных кадров (событие отсутствует) в наборе данных. Для построе- ния одной линии ROC мы меняем пороговое значение (ψ ), в то время как из- менение размера окна кадра (ϕ ) при неизменном значении порога приводит к построению другой линии ROC. 12.4.4.2.2 Уровень деятельности Для однозначного сравнения событий, помеченных эталонной разметкой, и обнаруженных событий используется алгоритм венгерского сравнения (на- значение Мункреса). Полнота отклика определяется как отношение коли- чества правильно обнаруженных событий к общему количеству эталонных событий. Для построения графика ROC на уровне деятельности значения полноты отклика наносятся на график в зависимости от частоты ложнопо- ложительных результатов в минуту, определяемой как отношение общего количества обнаруженных ложноположительных событий к общей продол- жительности видео из набора данных в минутах. Метрика оценки частоты ложноположительных результатов в минуту также используется в задаче ActEV TRECVID (ActEV, 2019) для количественной оценки систем обнаруже- ния деятельности. Для построения одной линии ROC мы меняем пороговое значение (ψ ), в то время как изменение размера окна кадра (ϕ ) при неиз- менном значении порога приводит к построению другой линии ROC. 12.4.4.3. Вариативные исследования Для количественной оценки влияния отдельных компонентов на общие по- казатели модели мы исследовали разные варианты нашей архитектуры. В на- ших экспериментах мы протестировали базовую модель, которая обучает систему перцептивного предсказания, включая блок внимания, с исполь- зованием функции потери предсказания для обратного распространения сигнала ошибки. Мы обозначили базовую модель как LSTM + ATTN. Мы также экспериментировали с влиянием удаления модуля внимания из архитек - туры модели на общее качество сегментации; результаты этого варианта представлены под названием LSTM. Дальнейшее тестирование включает ис - пользование взвешенных по движению потерь для обратного распростране- ния сигнала ошибки. Мы обозначили взвешенную по движению модель как LSTM + ATTN + MW. Каждая из моделей была тщательно протестирована; результаты приведены в разделах 12.4.4.4 и 12.4.4.5, а также изображены на рис. 12.10–12.14.\n--- Страница 542 ---\nВариант 2: сегментация с использованием моделей событий на основе внимания  541 Потеря предсказания Взвешенная по движению потеря Частота ложноположительных срабатываний (FPR) Частота ложноположительных срабатываний (FPR)Отклик Отклик Рис. 12.10  ROC сегментации событий на уровне кадра, когда деятельности обнаруживаются на основе простой пороговой обработки сигналов предска- зания и потерь, взвешенных по движению. Графики показаны для различных вариантов тестирования Потеря предсказания Взвешенная по движению потеря Частота ложных срабатываний в минуту (FPR/M) Частота ложных срабатываний в минуту (FPR/M)Отклик Отклик Рис. 12.11  ROC сегментации событий на уровне деятельности, когда дея- тельность обнаруживается на основе простой пороговой обработки сигналов предсказания и потерь, взвешенных по движению. Графики показаны для раз- личных вариантов тестирования Потеря предсказания Взвешенная по движению потеря Потеря предсказания + адаптивный порог Потеря предсказания + адаптивный порогОтклик Отклик Рис. 12.12  ROC сегментации событий на уровне деятельности, когда дея- тельность обнаруживается на основе адаптивной пороговой обработки сигна- лов предсказания и потерь, взвешенных по движению. Графики показаны для различных вариантов тестирования\n--- Страница 543 ---\n542  Сегментация событий во времени с использованием когнитивного самообучения 12.4.4.4. Количественная оценка Мы обучили три разные модели, LSTM, LSTM + ATTN и LSTM + ATTN + MW, для сегментации событий на уровне кадров и на уровне деятельности. Для экспе- риментов на уровне кадров и уровне деятельности к предсказательным и взве- шенным по движению сигналам потерь были применены простые и адаптив- ные функции стробирования (раздел 12.4.3). ROC-кривые для каждой модели, изображенные на рис. 12.10, 12.11 и 12.12, были получены путем изменения таких параметров, как пороговое значение ψ и размер окна кадра ϕ . Следует отметить, что пороговое значение сигнала потерь не обязательно означает, что модель была обучена минимизировать этот конкретный сиг - нал. Другими словами, функции потерь, используемые для обратного рас - пространения ошибки на обучаемые параметры моделей, указаны в имени модели (раздел 12.4.4.3); однако нами были проведены эксперименты по установлению порога для различных типов сигналов потерь, независимо от функции потерь обратного распространения, используемой для обуче ния. Модель с наилучшим качеством сегментации на уровне кадров (LSTM + ATTN, ψ = 1000) способна достичь значения полноты отклика {40 %, 60 %, 80 %} кадров при частоте ложных срабатываний {5 %, 10 %, 20 %} кадров соот - ветственно. Сегментация на уровне деятельности может обеспечить полноту отклика {80 %, 90 %, 95 %} с частотой ложных обнаружений деятельности {0,02, 0,1, 0,2} в минуту соответственно для модели (LSTM + ATTN, ϕ = 0,0021), как показано на рис. 12.12. Частоту ложноположительного обнаружения дея- тельности, равную 0,02 в минуту, также можно интерпретировать как ложное обнаружение одной деятельности каждые 50 минут обуче ния (с полнотой отклика 80 % для эталонной деятельности). Сравнение результатов, изображенных на рис. 12.11 и 12.12, показывает значительное улучшение качества модели при использовании адаптивного порога для формирования стробирующего сигнала потери. Эффективность адаптивного порога очевидна при применении к сегментации событий на уровне активности. Результаты также показали, что модель может эффектив- но генерировать карты внимания (раздел 12.4.4.5) без ухудшения качества сегментации. 12.4.4.5. Качественная оценка Примеры качественной оценки механизма внимания представлены на рис. 12.13 и 12.14. Маска внимания, извлеченная из модели, обучена без учи- теля отслеживать событие во всех обрабатываемых кадрах. Наши результаты показывают, что события отслеживаются и локализуются при различном освещении (тени, день/ночь) и в условиях окклюзии. Механизм внимания также научился бесконечно долго фокусироваться на птице независимо от ее состояния движения (подвижна/неподвижна). Это говорит о том, что модель приобрела высокоуровневое понимание событий в сцене и изучила базовую структуру птицы путем обуче ния без учителя. Дополнительные результаты1 1 Доступны по адресу https://ramyamounir.github.io/projects/EventSegmentation.\n--- Страница 544 ---\nВариант 2: сегментация с использованием моделей событий на основе внимания  543 (а) Кадры днем, когда птица неподвижна (b) Кадры ночью, когда птица неподвижна Рис. 12.13  Примеры весов внимания Бахданау, визуализированные на входных изображениях (а) Кадры в дневное время с движущимися тенями (b) Кадры в дневное время во время движения птицы Рис. 12.14  Примеры весов внимания Бахданау, визуализированные на входных изображениях\n--- Страница 545 ---\n544  Сегментация событий во времени с использованием когнитивного самообучения относятся к взвешенным по вниманию кадрам замедленной съемки во время изменения освещения и движущихся теней. На рис. 12.8 изображены сигнал предсказательной потери, сигнал потери, взвешенной по движению, и маска внимания во время событий входа в гнездо и выхода из него. 12.5. В ариант 3: пространст Венно-Временная ЛоКаЛизация с испо ЛьзоВанием Карты предс Казате Льны Х потерь В заключение мы покажем, что архитектуру системы из предыдущего раз- дела можно дополнительно улучшить, чтобы локализовать событие на изо- бражениях, т. е. отметить с по мощью ограничительной рамки место, где происходит событие. Механизм внимания, рассмотренный в разделе 12.4, генерирует только карту интенсивностей с размером сетки, зависящим от выходного пространственного разрешения кодировщика. Другими словами, карта внимания действует как указатель того, в каком месте кадра проис - ходит действие; однако она не создает точную маску или ограничивающую рамку. Чтобы сформировать ограничивающую рамку, мы используем сеть прогнозирования регионов и карту предсказательных потерь для фильтра- ции этих прогнозов с использованием функции минимизации простран- ственно-временной энергии. Следующее описание взято из (Aakur, Sarkar, 2020). Мы начинаем с извлечения релевантных признаков (раздел 12.5.1) из не- обработанных кадров в пространстве пикселей. Извлеченные признаки будут служить входными данными для сети прогнозирования регионов и модулей предсказания (раздел 12.5.2). Энергетическая функция объединяет предска- зательную потерю и прогнозируемые регионы (ограничивающие рамки) для выделения каналов действия (action tube) (раздел 12.5.4), которые согласу - ются в пространстве и времени. На рис. 12.15 показаны четыре компонента архитектуры: (1) извлечение признаков и прогнозирование пространствен- ной области, (2) самообучаемая модель предсказания будущего, (3) модуль обнаружения пространственно-временных ошибок и (4) процесс локализа- ции действия на основе модуля обнаружения ошибок. 12.5.1. Извлечение признаков Как и в предыдущих методах, для извлечения релевантных признаков ис - пользуется кодировщик CNN. Однако извлеченные признаки в этом под- ходе используются в качестве входных данных для сети прогнозирования пространственной области и стека предсказаний. Прогноз области, по сути, представляет собой набор ограничивающих рамок, определяющих возмож -\n--- Страница 546 ---\nВариант 3: пространственно-временная локализация с использованием карты  545 ные области действия и соответствующие объекты для каждого кадра. Пред- варительно обученная CNN используется для извлечения признаков и гене- рации прогнозов. Прогнозирование пространственных регионов Предсказанные будущие входы Ячейка LSTMЛокализация действий на основе ошибок Обнаружение пространственно-временных ошибок Блок кодера обработки восприятия Сенсорные входы КадрыМодели событийОбучающий сигнал Обучающий сигнал Рис. 12.15  Вариант 3: пространственно-временная локализация с исполь- зованием карты предсказательных потерь. Этот метод представляет собой ва- риант 2 с дополнительным компонентом, который локализует в пространстве кадра доминирующее действие на основе ошибки прогнозирования. Он состо- ит из четырех основных компонентов: (1) извлечение признаков и прогнози- рование пространственной области, (2) самообучаемый фреймворк предска- зания будущего, (3) модуль обнаружения пространственно-временных ошибок и (4) процесс локализации действия на основе модуля обнаружения ошибок Мы используем прогнозы, не зависящие от класса (т. е. категория объекта игнорируется и учитываются только локализации на основе признаков) по двум основным причинам. Во-первых, мы не хотим делать никаких пред- положений о характеристиках áктора, таких как метка, роль и аффорданс. Во-вторых, несмотря на значительный прогресс в обнаружении объектов, может быть много пропущенных обнаружений, особенно когда объект (или актор) выполняет действия, которые могут изменить его внешний вид. Сле- дует отметить, что эти соображения могут привести к большому количеству прогнозов регионов, которые требуют аккуратного и тщательного отбора, но потенциально обеспечивают более высокие шансы на правильную лока- лизацию.\n--- Страница 547 ---\n546  Сегментация событий во времени с использованием когнитивного самообучения 12.5.2. Иерархический стек предсказания Подобно подходам, упомянутым выше, текущая архитектура изучает пред- сказательную функцию на признаках высокого уровня, извлеченных ко- дировщиком. Сеть с LSTM применяется для прогнозирования следующего набора векторов признаков во временной последовательности, исходя из закодированного ввода и внутренней модели текущего события. Внутрен- няя модель эффективно фиксирует пространственно-временную динамику наблюдаемого события. Подобно предыдущей модели внимания, LSTM на каждом временном шаге обрабатывает набор векторов признаков, а не один вектор. Пространственное разрешение карт признаков определяется послед- ним слоем свертки кодировщика. Сеть LSTM выбрана не случайно; хотя другие методы, такие как сверточ- ные декодеры (Jia et al., 2016) и модели смешанных сетей (Vondrick et al., 2016), являются жизнеспособными альтернативами для предсказания буду - щего, мы предлагаем использовать рекуррентные сети по следующим при- чинам. Во-первых, мы хотим моделировать временную динамику во всех кадрах наблюдаемого действия (или события). Во-вторых, LSTM допускают несколько возможных вариантов будущего и, следовательно, не будут ус - реднять результаты этих возможных вариантов будущего, как это может быть в случае с другими прогнозными моделями. Допустим, мы наблюдаем последовательность кадров Ia = (Ia1, Ia2, …, Ian), соответствующих деятельности а. В случае видео со сложной структурой, например учебного видеоролика или спортивного репортажа, следующий набор кадров может представлять деятельность b или c с равными вероятностями, определяемыми как Ib = (Ib1, Ib2, …, Ibm) и Ic = (Ic1, Ic2, …, Ick) соответственно. Использование полностью связанного или сверточного прогнозного модуля, вероятно, приведет к пред- сказанию признаков, которые, как правило, являются средним значением двух действий b и c, т. е. для времени k. Это нежелательный результат, потому что предсказанные признаки могут быть либо малове - роятным результатом, либо, что более вероятно, находиться за пределами правдоподобного многообразия представлений. Рекуррентные сети, такие как RNN и LSTM, допускают одновременное существование нескольких вари- антов предсказанного будущего, которые возможны в момент времени t + 1 при условии наблюдения за кадрами до момента времени t. В-третьих, по- скольку мы работаем с локализацией на основе ошибок, использование LSTM гарантирует, что процесс обуче ния суммирует пространственно-временную ошибку во времени и может давать все более качественные прогнозы, осо- бенно для действий большей продолжительности. В отличие от предыдущих подходов, модуль предсказания здесь состоит из стека сетей LSTM. Выход одной LSTM используется как вход для другой LSTM. Каждая LSTM в стеке имеет свои собственные параметры, определяющие различную внутреннюю модель события в зависимости от его положения в иерархии. Эта архитектура позволяет моделировать как пространственные, так и временные зависимости, поскольку каждый LSTM более высокого уров - ня действует как прогрессивный декодер, который реагирует на временные\n--- Страница 548 ---\nВариант 3: пространственно-временная локализация с использованием карты  547 зависимости, выделенные LSTM более низкого уровня. Первая сеть LSTM выделяет пространственную зависимость, которая распространяется вверх по стеку предсказания. Обновленное скрытое состояние первого (нижнего) слоя LSTM (h t1) зависит от текущего наблюдения ftS, предыдущего скрытого состояния (h1 t–1) и состоя- ния памяти (m1 t–1). Каждая из LSTM более высокого уровня принимает на свой первый слой выходные данные LSTM предшествующего уровня (h tl–1) и со- стояние памяти (m tl–1) и может быть определена как (hl t, ml t) = LSTM(h lt–1, htl–1, mtl–1). Заметим, что это отличается от типичной иерархической модели LSTM (Song et al., 2017) тем, что на более высокие LSTM влияют выходные данные LSTM более низкого уровня на текущем временном шаге, а не на предыдущем. В совокупности модель событий We описывается обучаемыми параметрами и их соответствующими смещениями из иерархического стека LSTM. Следовательно, верхний уровень стека предсказаний действует как де - кодер, целью которого является предсказание следующего признака fS t+1 с учетом всех предыдущих предсказаний fˆ1S, fˆ2S, …, fˆtS, модели событий We и текущего наблюдения ftS. Мы моделируем эту функцию прогнозирования как логарифмически-линейную модель, определяемую уравнением (12.9) где hi t – скрытое состояние LSTM l-го уровня в момент времени t, а Z (ht) – кон- станта нормализации. Стек предсказания LSTM действует как генеративный процесс для прогнозирования будущих признаков. 12.5.3. Потеря предсказания Карта внимания в этой архитектуре извлекается непосредственно из фак - тических предсказательных потерь (рис. 12.7) в верхней части стека пред- сказаний. Потеря предсказания является фактором качества сделанных предсказаний и относительного пространственного распределения ошибок предсказания. Взвешенная потеря движения из уравнения (12.8) использу - ется для вычисления веса αij, связанного с каждым пространственным по- ложением (i, j) в прогнозируемом признаке f ˆS t+1 как (12.10) где eij представляет собой взвешенную ошибку предсказания в точке ( i, j) (12.8). Это уравнение можно рассматривать как функцию a(ftS, hi t–1) состояния самого верхнего LSTM и входного признака ftS в момент времени t. Получен- ная матрица представляет собой карту внимания на основе ошибок, которая позволяет нам локализовать ошибку прогноза в определенном простран- ственном местоположении. А средняя пространственная ошибка во времени E(t) используется для локализации во времени.\n--- Страница 549 ---\n548  Сегментация событий во времени с использованием когнитивного самообучения 12.5.4. Извлечение каналов действий Действия извлекаются в виде каналов с использованием целевой функции энергии, которая подлежит минимизации. Модуль локализации действия получает в качестве входных данных поток прогнозов ограничивающей рамки (несколько прогнозов на кадр) и поток карт предсказательных по- терь (по одной на кадр). Функция энергии предназначена для извлечения когерентных каналов действий. Она фильтрует прогнозы с использованием карты предсказательных потерь и возвращает набор прогнозов с наиболее высокой вероятностью локализации действия. Это достигается путем добав- ления компонента энергии каждому из прогнозов ограничивающей рамки (ℬit) в момент времени t и выбора верхних k ограничивающих рамок с наи- меньшей энергией в качестве наших окончательных прогнозов. Энергия ограничивающей рамки ℬ it определяется уравнением E(ℬit) = wαϕ(αij, ℬit) + wtδ(ℬit, {ℬj,t–1}), (12.11) где ϕ(·) – функция, которая возвращает значение, характеризующее расстоя- ние между центром ограничивающей рамки и положением максимальной ошибки, δ(·) – функция, возвращающая минимальное пространственное рас - стояние между текущей ограничивающей рамкой и ближайшей ограничива- ющей рамкой из предыдущего временного шага. Константы wα и w t являются масштабными коэффициентами. На рис. 12.18 показан пример извлеченных каналов действий для одного действия в потоке кадров. 12.5.5. Результаты 12.5.5.1. Данные Для оценки нашего метода локализации действий мы используем три обще- доступных набора данных. UCF Sports (Rodriguez et al., 2008) – это набор данных, состоящий из 10 классов спортивных действий, таких как катание на коньках и подня- тие тяжестей, собранных из спортивных трансляций. Это интересный на- бор данных, поскольку он имеет высокую концентрацию различных сцен и движений, что затрудняет локализацию и распознавание. Мы используем для оценки так называемые сплиты (103 обучающих и 47 тестовых видеоро- ликов), как предложено в (Lan et al., 2011). JHMDB (Jhuang et al., 2013) состоит из 21 класса действий и 928 обре- занных видео. Все видео аннотированы положением человеческих суставов в каждом кадре. Эталонная ограничивающая рамка для задачи локализации действия выбирается таким образом, чтобы она охватывала все суставы. Этот набор данных предлагает несколько усложнений, таких как увеличение коли- чества фоновых помех, высокое сходство между классами, сложное движение (включая движение камеры) и частично закрытые объекты наблюдения. Мы представляем все результаты как среднее значение по всем трем сплитам.\n--- Страница 550 ---\nВариант 3: пространственно-временная локализация с использованием карты  549 THUMOS’13 (Jiang et al., 2014) – это подмножество набора данных UCF-101 (Soomro et al., 2012), состоящее из 24 классов и 3207 видео. Для каждого из классов задачи локализации действия предусмотрены эталонные ограничи- вающие рамки. Он также известен как набор данных UCF-101-24. Мы прово- дим эксперименты и сообщаем о результатах первого сплита в соответствии с предыдущими работами (Li et al., 2018; Soomro, Shah, 2017). Мы также проанализировали способность метода обобщать видео, сосре- доточенное на персоне (эго-видео), оценивая его в задаче прогнозирования взгляда с обуче нием без учителя. В когнитивной психологии имеется доста- точно доказательств сильной корреляции между точками, на которые на - правлен взгляд, и локализацией действия (Tipper et al., 1992). Поэтому задача предсказания взгляда представляется нам разумной мерой обобщения ло- кализации действия в эго-видео. Мы оцениваем точность на наборе данных GTEA Gaze (Fathi et al., 2012), который состоит из 17 последовательностей задач, выполняемых 14 испытуемыми, причем каждая последовательность длится около 4 минут. Мы используем общепринятые сплиты наборов дан- ных GTEA, определенные в предыдущих работах (Fathi et al., 2012). 12.5.5.2. Показатели и базовые уровни В решении задачи локализации действия мы опирались на предыдущие ис - следования (Li et al., 2018; Soomro, Shah, 2017) и получили значения име- нованной средней точности (mean average precision, mAP) при различных порогах перекрытия, полученной путем вычисления пересечения поверх объединения (IoU) предсказанных и эталонных ограничивающих рамок. Мы также оцениваем качество прогнозов ограничивающей рамки, измеряя среднее значение IoU за кадр и полноту прогнозов рамки при различных коэффициентах перекрытия. Поскольку наш метод основан на обучении без учителя, мы получаем мет - ки классов путем кластеризации изученных представлений с использова - нием алгоритма k-средних. Хотя более сложная кластеризация может дать лучшие результаты распознавания (Soomro, Shah, 2017), алгоритм k-средних позволяет нам оценить робастность изученных признаков. Мы оцениваем наш метод по двум параметрам Kgt и K opt, где первый – это количество класте- ров, равное количеству классов эталонных действий, а второй – оптималь- ное количество, полученное с по мощью метода локтя (Kodinariya, Makwana, 2013) соответственно. Из наших экспериментов следует, что Kopt в три раза превышает количество эталонных классов, что не лишено смысла и было рабочим предположением в других методах кластеризации, основанных на глубоком обучении (Hershey et al., 2016). Оценочное сравнение с эталонны- ми кластерами выполнялось с использованием венгерского метода, как это делалось в предыдущих методах обуче ния без учителя (Ji et al., 2019; Xie et al., 2016). Для оценки эффективности нашего протокола обуче ния мы также провели сравнение с другими подходами – LSTM и на основе внимания (раз- дел 12.5.5.3.3). Для задачи прогнозирования взгляда мы оцениваем разные подходы с ис - пользованием метода площади под кривой (area under curve, AUC), который\n--- Страница 551 ---\n550  Сегментация событий во времени с использованием когнитивного самообучения измеряет площадь под кривой на графиках значимости для истинно положи- тельных показателей по сравнению с ложноположительными при различных пороговых значениях. Мы также определили среднюю угловую ошибку (average angular error, AAE), которая отражает угловое расстояние между прогнози- руемым и реальным положением взгляда. Поскольку выход нашей модели представляет собой график значимости, AUC является более подходящей метрикой, чем средняя угловая ошибка AAE, которая требует знания опре- деленных местоположений. 12.5.5.3. Количественная оценка В этом разделе мы представляем количественную оценку нашего подхода к двум различным задачам, а именно к локализации действия и предсказанию взгляда. Для задачи локализации действия мы оцениваем наш метод по двум аспектам – качество прогнозов и пространственно-временная локализация. 12.5.5.3.1. Качество прогнозов локализации Сначала мы оцениваем качество наших прогнозов локализации, предполагая идеальное предсказание класса. Это позволяет нам независимо оценивать качество локализации, выполненной в режиме самообучения. Полученные оценки представлены в табл. 12.5 и сравниваются с оценками при полном обуче нии с учителем, частичном обучении с учителем и обучении без учи- теля. Как следует из данных в таблице, предсказательный метод превосхо- дит многие альтернативные методы, основанные на полном или частичном обуче нии. Метод APT (Van Gemert et al., 2015) достигает более высокой оцен- ки локализации. Однако он выдает в среднем 1500 прогнозов на видео, тогда как наш подход возвращает примерно 10 прогнозов. Большое количество прогнозов локализации для каждого видео может привести к более высоким значениям полноты отклика и IoU, но усложняет задачу локализации, т. е. затрудняет маркировку действий для каждого видео, и может повлиять на возможность обобщения на другие домены (области деятельности). Кроме того, следует отметить, что наш метод выдает прогнозы в потоко- вом режиме, в отличие от многих других подходов, которые создают каналы действий на основе движения, вычисляемого по всему видео. Во втором случае локализация действий в реальном времени в потоковом видео может быть затруднена. 12.5.5.3.2. Пространственно-временная локализация действия Мы протестировали наш подход к задаче пространственно-временной лока- лизации. Полученная оценка позволяет нам проанализировать робастность признаков, полученных посредством предсказания с самообучением. Мы генерируем метки классов на уровне видео с по мощью кластеризации и ис - пользуем стандартные метрики оценки (раздел 12.5.5.2) для количественной оценки точности. Кривые AUC относительно различных порогов перекрытия представлены на рис. 12.16. Мы сравниваем их с набором базовых значений для полного обуче ния с учителем, частичного обуче ния и обуче ния без учи- теля на всех трех наборах данных.\n--- Страница 552 ---\nВариант 3: пространственно-временная локализация с использованием карты  551 Таблица 12.5. Сравнение с методами полного и частичного обуче ния с учителем на базовом уровне локализации действий, не зависящем от класса, в наборе данных UCF Sports. Представлена средняя точность локализации каждого подхода, т. е. средний IoU Разметка Метод Точность, % ПолнаяSTPD (Tran, Yuan, 2011) 44,6 Поиск макс. пути (Tran, Yuan, 2012) 54,3 СлабаяMa et al. (Ma et al., 2013) 44,6 GBVS (Grundmann et al., 2010) 42,1 Soomro et al. (Soomro, Shah, 2017) 47,7 НетIME Tublets (Jain et al., 2014) 51,5 APT (Van Gemert et al., 2015) 63,7 Предсказательный подход 55,7 AUC AUC AUC Порог перекрытия Порог перекрытия Порог перекрытияS 15 VideoLSTM Наш метод K_optS 17 Наш метод K_opt (a) (b) (c) Рис. 12.16  Кривые AUC для задач локализации действия показаны для сле- дующих наборов данных: (a) UCF Sports, (b) JHMDB и (c) THUMOS13. Мы сравни- ваем показатели нашего метода с базовыми данными при различных уровнях обуче ния, полученными из работ (Lan et al., 2011; Tian et al., 2013; Wang et al., 2014; Gkioxari, Malik, 2015; Jain et al., 2014; Soomro et al., 2015, 2016; Soomro, Shah, 2017; Hou et al., 2017) и VideoLSTM (Li et al., 2018) В наборе данных UCF Sports (рис. 12.16а) наша архитектура превосходит все традиционные методы, включая несколько вариантов обуче ния с учите- лем, за исключением показателей метода (Gkioxari, Malik, 2015) при более высоких порогах перекрытия (σ > 0,4), когда мы устанавливаем число клас - теров k равным числу эталонных классов. Когда допускаем некоторую пере- сегментацию и используем оптимальное количество кластеров, наш метод превосходит все альтернативные подходы до σ > 0,5. Экспериментируя с набором данных JHMDB (рис. 12.16b), мы обнаружили, что хотя наш метод обеспечивает высокую полноту отклика даже при более строгих пороговых значениях (77,8 % при σ > 0,5), большое движение камеры и внутриклассовые вариации оказывают значительное влияние на точность классификации. Следовательно, mAP страдает, когда мы устанавливаем k равным числу эталонных классов. Когда мы выбираем оптимальное коли- чество кластеров, наш метод превосходит альтернативные варианты при\n--- Страница 553 ---\n552  Сегментация событий во времени с использованием когнитивного самообучения более низких порогах (mAP при σ < 0,5). Следует отметить, что другой метод с обуче нием без учителя (Soomro et al. (2017)) использует прогнозы обнару - жения объектов из базовой модели Faster R-CNN для оценки «человечности» прогноза. Это предположение делает подход предвзятым к локализации дей- ствий, ориентированных на человека, и снижает его способность обобщать действия áкторов, не являющихся людьми. В свою очередь, мы не делаем никаких предположений о характеристиках áктора, сцены или динамики движения. В наборе данных THUMOS13 (рис. 12.16c) мы достигаем стабильного пре- имущества по сравнению с исходными примерами обуче ния без учителя и частичного обуче ния с учителем при k = kgt и самых современных показате- лей mAP при k = kopt. Примечательно, что мы конкурируем (когда k = kgt) с мо- делью частичного обуче ния на основе внимания VideoLSTM (Li et al., 2018), которая использует convLSTM для временного моделирования вместе с ме- ханизмом пространственного внимания на основе CNN. Следует отметить, что наш метод демонстрирует на THUMOS13 более высокую полноту отклика (0,47 при σ = 0,4 и 0,33 при σ = 0,5) при более высоких порогах, по сравнению с другими современными методами, и устойчивость алгоритма локализации на основе ошибок к внутриклассовой изменчивости и окклюзии. Качество кластеризации. Поскольку наблюдается значительная раз- ница в оценке mAP , когда мы меняем количество кластеров в k-средних, мы измерили однородность (или чистоту) кластеризации. Оценка однород- ности отражает «качество» кластера, измеряя, насколько хорошо клас тер моделирует данный класс достоверности. Поскольку мы допускаем пере- сегментацию кластеров, когда устанавливаем k равным оптимальному количеству кластеров, это является важной мерой надежности признака. Более высокая однородность указывает на то, что учитываются вариации внутри класса, поскольку все точки данных в определенном кластере при- надлежат к одному и тому же эталонному классу. Мы наблюдаем среднюю оценку однородности 74,56 %, когда k равно количеству эталонных клас - сов, и 78,97 %, когда используем оптимальное количество кластеров. Как следует из результатов, несмотря на чрезмерную сегментацию, каждый из кластеров обычно моделирует один класс действий с высокой степенью совпадения. 12.5.5.3.3. Сравнение с другими подходами на основе LSTM Мы также сравнили нашу модель с другими моделями на основе LSTM и вни- мания, чтобы подчеркнуть важность парадигмы самообучения. Посколь- ку системы на основе LSTM могут иметь очень похожие архитектуры, мы учитываем разные требования и характеристики, такие как уровень анно- тации, необходимый для обуче ния, и количество прогнозов локализации, возвращаемых для каждого видео. Мы сравнили три подхода, схожих по духу с нашим, – ALSTM (Sharma et al., 2015), VideoLSTM (Li et al., 2018) и Actor Su- pervision (Escorcia et al., 2020) – и свели результаты в табл. 12.6. Видно, что наш подход значительно превосходит VideoLSTM и ALSTM на наборе данных THUMOS13 как по полноте отклика, так и по mAP при σ = 0,2.\n--- Страница 554 ---\nВариант 3: пространственно-временная локализация с использованием карты  553 Таблица 12.6. Сравнение нашей архитектуры с другими методами на основе LSTM и внимания на наборе данных THUMOS’13. Представлены средние значения полноты отклика при различных порогах перекрытия, mAP при пороге перекрытия 0,2 и среднем количестве прогнозов на кадр МетодРазметки Число предло- женийСредняя полнота отклика mAP при σ = 0,2Метки Рамки0,1 0,2 0,3 0,4 0,5 ALSTM (Sharma et al., 2015) ✓ ✗ 1 0,46 0,28 0,05 0,02 – 0,06 VideoLSTM (Li et al., 2018) ✓ ✗ 1 0,71 0,52 0,32 0,11 – 0,37 Actor Supervision (Escorcia et al., 2020)✓ ✗ ~1000 0,89 – – – 0,44 0,46 Наш метод ✗ ✗ ~10 0,84 0,72 0,58 0,47 0,33 0,59 Модель Actor Supervision (Escorcia et al., 2020) превосходит наш вариант по отклику, но следует отметить, что прогнозы регионов зависят от двух факторов: (1) прогнозов акторов на основе обнаружения объектов и (2) ме- ханизма фильтрации, ограничивающего прогнозы, основанные на эталон- ных классах действий, которые могут увеличить требования к обуче нию и ограничить обобщаемость. Также следует иметь в виду, что возврат боль- шего количества прогнозов локализации может увеличить отклик ценой ухудшения обобщения. 12.5.5.3.4. Вариативные исследования Наша предсказательная модель имеет три основных компонента, которые больше всего влияют на ее качество: (1) модуль прогнозирования региона, (2) модуль предсказания будущего и (3) модуль локализации действий на основе ошибок. Мы рассматриваем и оцениваем несколько альтернатив всем трем мо- дулям. Мы взяли выборочный поиск (Uijlings et al., 2013) и EdgeBox (Zhu et al., 2015) в качестве альтернативных методов прогнозирования региона для SSD. Чтобы оценить эффективность использования локализации на основе ошибок, мы воспользовались методом локализации на основе внимания для локализации действия в качестве приближения ALSTM (Sharma et al., 2015). Мы также оценили одноуровневый предсказатель LSTM с полносвяз- ной сетью декодеров (Aakur, Sarkar, 2019) для аппроксимации задачи лока- лизации. Оценили эффект прогнозирования на основе внимания, вводя слой внимания Бахданау (Bahdanau et al., 2014) перед предсказанием в качестве альтернативы модулю локализации действий на основе ошибок. Эти вариативные исследования проведены на наборе данных UCF Sports. Результаты представлены на рис. 12.17а. Можно видеть, что использова- ние локализации на основе ошибок прогнозирования дает заметно лучший результат по сравнению с подходом к локализации на основе обученного внимания. Можно также заключить, что выбор методов прогнозирования об- ласти оказывает некоторое влияние на точность модели, при этом выбороч- ный поиск и прогнозы EdgeBox работают немного лучше при более высоких порогах (σ Î (0,4, 0,5)) за счет увеличения времени вывода и дополнительных\n--- Страница 555 ---\n554  Сегментация событий во времени с использованием когнитивного самообучения прогнозов ограничивающей рамки (50 по сравнению с 10 из прогнозиро- вания региона на основе SSD). Использование SSD для генерации прогно- зов позволяет нам распределять веса между задачами кодировщика кадров и прогнозирования регионов и уменьшать объем памяти и вычислительные ресурсы алгоритма. Мы также обнаружили, что использование внимания как части модуля прогнозирования значительно влияет на показатели качества архитектуры. Возможно, это можно отнести на счет целевой функции, ко- торая направлена на минимизацию ошибки прогноза. Обратите внимание, что в данном случае для локализации событий мы используем внимание на основе ошибок, в отличие от изученного вектора внимания из раздела 12.4. Мы обнаружили, что использование внимания Бахданау для кодирования признаков может повлиять на функцию прогнозирования нашей модели. 12.5.5.3.5. Прогнозирование взгляда с обучением без учителя Наконец, мы оцениваем способность обобщать персонализованное видео, количественно определяя точность модели в задаче прогнозирования взгля- да с обуче нием без учителя. Поскольку нам не нужны никакие аннотации или другие вспомогательные данные, мы используем для этой задачи прежнюю архитектуру и стратегию обуче ния. Оцениваем набор данных взгляда GTEA и сравниваем его с другими моделями, обучаемыми без учителя, в табл. 12.7. Как видно из таблицы, нами получены конкурентоспособные результаты в задаче прогнозирования взгляда, превосходящие все сравнительные по- казатели как по AUC, так и по AAE. Следует отметить также, что мы превос - ходим метод смещения центра по показателю AUC. Метод смещения центра (center bias) использует пространственное смещение в персонализованных изображениях и всегда предсказывает центр видеокадра как прогнозируе- мое положение взгляда. Значительное улучшение показателя AUC говорит о том, что наш подход предсказывает фиксации взгляда, которые более близ - ки к эталонным, чем в подходе со смещением центра. Учитывая, что модель не была специально разработана для этой задачи, это замечательный резуль- тат, особенно с учетом показателей моделей, основанных на традиционном обучении с учителем, таких как DFG (Zhang et al., 2017), которые достигают 10,6 и 88,3 для AUC и AAE оответственно. Таблица 12.7. Сравнение задачи прогнозирования взгляда с обуче нием без учителя на наборе данных GTEA с современными моделями Itti, Koch (2000)GBVS (Harel et al., 2007)AWS-D (Leboran et al., 2016)Смещение центраOBDL (Sayed et al., 2015)Наш метод AUC 0,747 0,769 0,770 0,789 0,801 0,861 AAE 18,4 15,3 18,2 10,2 15,6 13,6 12.5.5.4. Качественная оценка Мы обнаружили, что наш подход имеет стабильно высокий уровень полноты отклика для задачи локализации с разными наборами данных и доменами. Мы считаем, что действие правильно локализовано, если средний IoU по всем кадрам выше 0,5, то есть большинство (если не все) кадров в видео пра-\n--- Страница 556 ---\nВариант 3: пространственно-временная локализация с использованием карты  555 вильно локализованы. Значения полноты отклика и последующие значения AUC для каждого класса в наборе спортивных данных UCF представлены на рис. 12.17б и 12.7в. Для большинства классов (7 из 10, если точнее) у нас есть отклик более 80 % при пороге перекрытия 0,5. При визуальном анализе мы обнаруживаем, что пространственно-временная ошибка часто коррелирует с áктором, но обычно не находится в центре наблюдаемой области и, таким образом, снижает качество выбранных прогнозов. Мы демонстрируем этот эффект на рис. 12.18. В первой строке показан входной кадр, во второй – вни- мание на основе ошибок, а в последней строке – окончательные прогнозы по локализации. Если генерируется больше прогнозов (как в случае с вы- борочным поиском и EdgeBox), мы можем получить более высокий отзыв (рис. 12.17б) и более высокий mAP . AUC AUC Отклик Порог перекрытия Порог перекрытия Порог перекрытияДайвинг Бег Гольф Верховая езда Подъем Пинок Прогулка Скейтборд Качели-B Качели-SДайвинг Бег Гольф Верховая езда Подъем Пинок Прогулка Скейтборд Качели-B Качели-SRPN + SSD RPN + Edgebox Выбор внимания RPN + выборочный поиск LSTM + внимание 1-слойная LSTM (a) (b) (c) Рис. 12.17  Качественный анализ нашего метода на наборе данных UCF Sports: (а) абляционные вариации AUC, (b) AUC по классам и (c) полнота отклика ограничивающей рамки по классам при разных порогах перекрытия Успешная локализация Рис. 12.18  Качественные примеры: локализация внимания на основе оши- бок и окончательный прогноз. Зеленая рамка – предсказание; синяя рамка – эталон\n--- Страница 557 ---\n556  Сегментация событий во времени с использованием когнитивного самообучения 12.6. другие под Ходы К сегментации событий В Компьютерном зрении В настоящее время существуют три разных класса подходов к сегментации событий во времени, различаемых по критерию обуче ния: полное обуче ние с учителем, частичное обуче ние и обуче ние без учителя. Хотя традиционные подходы на основе полного обуче ния с учителем имеют более точную лока- лизацию и лучшую точность маркировки, за это приходится платить очень большим количеством аннотаций. Потребность в размеченных обучающих данных плохо масштабируется с увеличением классов меток. Хотя подходы на основе частичного обуче ния (или с так называемой слабой разметкой) не требуют аннотаций на уровне кадра, в их основе лежит предположение о том, что существует большой аннотированный обучающий набор, который по- зволяет эффективно обнаруживать всех возможных акторов (как людей, так и предметы) в наборе классов действий. Подходы с обуче нием без учителя, такие как наш, не делают вышеупомянутых предположений, но могут при- вести к снижению точности локализации. Мы в некоторой степени решаем эту проблему, используя последние достижения в области механизмов прог - нозирования регионов и робастных самообучающихся представлений. Один особый класс подхода с обуче нием без учителя – самообучение – использует для обуче ния только сами данные без аннотаций. 12.6.1. Методы на основе обучения с учителем Методы, основанные на обучении с учителем, традиционно были домини- рующим подходом к сегментации событий во времени. Они исходят из того, что для задачи есть полномасштабный учитель, и используют эталонные аннотации для выбора сегмента с по мощью классификации, т. е. назначают метки семантически согласованным «фрагментам», чтобы сегментировать видео на его составные сегменты, при этом смежные кадры имеют одну и ту же метку. Общим приемом в этих подходах было извлечение призна- ков (либо созданных вручную, либо автоматизированных с использованием глубокого обуче ния) для применения машин опорных векторов на осно- ве кадров (Kuehne et al., 2014) или моделирования временной динамики с использованием скрытых марковских моделей (Kuehne et al. et al., 2014), временных сверточных нейронных сетей (TCN) (Lea et al., 2017), простран- ственно-временных сверточных нейронных сетей (CNN) (Lea et al., 2016), рекуррентных сетей (Richard et al., 2017) и многих других. Хотя подходы на основе полноценного обуче ния с учителем привлекательны из-за их высокой точности, получение крупномасштабных аннотированных наборов данных, особенно с аннотациями на уровне кадра, может стоить довольно дорого и не всегда доступно. Эта проблема становится более заметной по мере увеличе- ния детализации событий. В некоторых подходах задачу локализации действия решают путем одно- временного создания прогнозов ограничивающей рамки и маркировки каж -\n--- Страница 558 ---\nДругие подходы к сегментации событий в компьютерном зрении  557 дой такой рамки прогнозируемым классом действия. Как генерация огра- ничивающей рамки, так и маркировка относятся к обуче нию с учителем, т. е. нужны обучающие эталоны как для ограничивающих рамок, так и для меток классов. В наиболее типичных методах при подготовке прогнозов используют достижения в области обнаружения объектов, чтобы добавить информацию о времени (Gkioxari, Malik, 2015; Hou et al., 2017; Jain et al., 2014; Soomro et al., 2015, 2016; Tian et al., 2013; Tran, Yuan, 2012; Wang et al., 2014). На последнем шаге обычно применяют алгоритм Витерби (Gkioxari, Malik, 2015) для связывания последовательности сгенерированных ограничиваю- щих рамок во времени. 12.6.2. Методы на основе частичного обучения с учителем Основная идея частичного обуче ния заключается в том, чтобы уменьшить потребность в прямой разметке за счет использования сопровождающих текстовых описаний или инструкций в качестве косвенных обучающих дан- ных для изучения резко дискриминативных признаков. В области временной сегментации видео существуют два распространенных подхода к частич- ному обуче нию с учителем: (1) использование описаний или инструкций в качест ве слабой разметки (Bojanowski et al., 2014; Ding, Xu, 2018; Alayrac et al., 2016; Malmaud et al., 2015) и (2) после неполной временной локализации действий для обуче ния и вывода (Huang et al., 2016; Richard et al., 2017). Хотя такие методы моделируют временные переходы с использованием RNN, они по-прежнему полагаются на принудительную семантику для сегментации действий и, следовательно, нуждаются в определенном объеме обучающих данных. Упомянутые подходы применяют для локализации действия, чтобы умень- шить потребность в обширных аннотациях (Escorcia et al., 2020; Lan et al., 2011; Li et al., 2018; Sharma et al., 2015). Обычно им требуются только метки на уровне полного видео, и они используют обнаружение объектов для соз- дания прогнозов ограничительной рамки. Следует отметить, что подходы со слабой разметкой также используют метки и характеристики на уровне объекта для управления процессом выбора ограничивающей рамки. В не- которых моделях (Escorcia et al., 2020) используют трекер на основе подобия для связывания ограничивающих рамок во времени, чтобы обеспечить не- разрывность локализации. 12.6.3. Методы на основе обучения без учителя При обучении без учителя отсутствуют внешние аннотированные обучаю- щие данные, которые можно использовать для определения правильности вывода модели. Такие методы изучены в существенно меньшей степени по сравнению с двумя упомянутыми ранее. Основная идея заключается в ис - пользовании кластеризации и дискриминативных признаков (Bhatnagar et\n--- Страница 559 ---\n558  Сегментация событий во времени с использованием когнитивного самообучения al., 2017; Sener, Yao, 2018). Такие модели используют либо LSTM (Bhatnagar et al., 2017), либо обобщенную модель Маллоу (Sener, Yao, 2018). Гарсия и др. (Garcia et al., 2018) исследуют использование генеративной сети LSTM для сегментации последовательностей, как это делаем мы. Однако они работают только с грубым временным разрешением на протяжении жизни изобра- жений, снятых с интервалом до 30 секунд. Последовательные изображения, снятые с таким промежутком, при изменении событий дают большую вари- ативность, что облегчает их различение. Кроме того, они применяют итера- тивный процесс обуче ния, которого у нас нет. Некоторые модели не нуждаются ни в метках, ни в ограничивающих рамках. Два наиболее распространенных подхода заключаются в создании прогнозов действий с использованием (1) супервокселей (Jain et al., 2014; Soomro, Shah, 2017) и (2) кластеризующих траекторий движения (Van Gemert et al., 2015). Следует отметить, что Соомро и Шах (Soomro, Shah, 2017) также используют характеристики объекта для оценки «человечности» каждого супервокселя при выборе прогнозов ограничивающей рамки. Наш подход, который мы представили в этой главе, относится к классу методов локализации действий с обуче нием без учителя. Наиболее близ- кими подходами (в отношении архитектуры и темы) являются VideoLSTM (Li et al., 2018) и Actor Supervision (Escorcia et al., 2020), которые используют внимание в процессе генерации прогнозов ограничивающей рамки, но тре- буют разметки на уровне видео. Наша модель не требует никаких меток или аннотаций ограничительной рамки для обуче ния. 12.6.4. Методы на основе самообучения Одна из разновидностей обуче ния без учителя, привлекающая внимание исследователей, – это методы на основе самообучения, в которых использу - ются обучающие данные, но без аннотаций. Существует два основных типа методов на основе самообучения: (1) сокрытие подмножества данных и по- пытка предсказать его, т. е. предсказать закрытую часть изображения объекта по видимой части или предсказать цвет из уровня серого (Zhang et al., 2016; Vondrick et al., 2018); (2) изменение входных данных и прогнозирование функции (параметров), вызвавших это изменение (Gidaris et al., 2018; Do- ersch et al., 2015; Misra et al., 2016; Fernando et al., 2017). Предсказание части входных данных или неизмененной версии входных данных заставляет сеть изучать полезные семантические признаки из набора данных. Подходы на основе контрастного обуче ния (Chen et al., 2020; Grill et al., 2020; Caron et al., 2020) подпадают под вторую категорию, когда входные данные изменяются и сеть вынуждена изучать представление, которое максимизирует сходство между исходным и измененным вводами. Было обнаружено, что эти при- емы позволяют изучать довольно надежные представления, которые затем можно применять при решении разных задач, например разметки, оценки движения и т. д. В контексте видео самообучение сводилось в основном к предсказанию следующей пары кадров изображения (Srivastava et al., 2015; Mathieu et al.,\n--- Страница 560 ---\nВыводы  559 2015; Neverova et al., 2017; Lotter et al., 2016; Finn et al., 2016). Прогнозы на уровне признаков было предложено использовать для обнаружения одновре- менно встречающихся пространств визуальных признаков (Wang et al., 2014) и изучения представлений для лучшего распознавания (Liu et al., 2018; Li et al., 2017). Упомянутые подходы предлагают исследование контекста посред- ством совместного появления признаков во временных последовательностях для изучения либо множественной корреляции, такой как моделирование движения и внешнего вида для создания будущих кадров (Li et al., 2017), либо для изучения одновременно встречающихся понятий, таких как носы и глаза на лицах (Wang et al., 2014). Также опубликовано много работ по прогнозированию будущей деятель- ности (Sun et al., 2019; Luc et al., 2017; Ma et al., 2016; Liang et al., 2019; Kitani et al., 2012; Fragkiadaki et al., 2015; Walker et al., 2014; Alahi et al., 2016; Santoro et al., 2017; Hamilton et al., 2017). Однако все эти подходы используют стан- дартную методику глубокого обуче ния на основе аннотированных данных. Наш подход похож на методику прогнозирующего обуче ния по видео, предложенную Вондриком и др. (Vondrick et al., 2016), но для концепций более высокого уровня, а не только для меток действий. Исследования мозга и когнитивных функций убедительно свидетельствуют о том, что прогнозы играют важную роль в процессах усвоения мозгом новых понятий. Осно- вываясь на результатах целого ряда нейробиологических экспериментов, Хоукинс и др. (Hawkins et al., 2016) также предложили повторяющуюся ар- хитектуру слоев прямого распространения, предиктивной памяти и пулинга по времени, на которой они продемонстрировали обнаружение аномалий в одномерных сигналах. Хигер (Heeger, 2017) показал эффективность много- уровневой архитектуры со связями «снизу вверх» и «сверху вниз», но на основе прогнозов временной обработки сигналов. Лоттер и др. (Lotter et al., 2016) реализовали стек предиктивного кодирования, но для прогнозирова- ния на уровне видеокадра. 12.7. В ыВоды Эта глава основана на исследованиях когнитивной науки, направленных на определение задачи сегментации событий и разработку высокоэффективных алгоритмов компьютерного зрения для пространственно-временной сег - ментации событий в видео. Новые подходы не требуют ни аннотированных данных, ни многократных проходов по данным. Они могут обрабатывать потоковые видеоданные, одновременно изучая надежные представления для сегментации событий. Основная идея состоит в том, чтобы использовать прогностическое обуче- ние, в соответствии с теорией сегментации событий (EST) в когнитивной нау - ке, для обнаружения границ событий. Как и в EST, блок обработки восприятия (стек CNN) отправляет извлеченные признаки из текущего кадра (обуслов- ленные рабочей моделью событий) в блок предсказания (LSTM, стек LSTM, модуль прогнозирования ограничивающей рамки), который прогнозирует\n--- Страница 561 ---\n560  Сегментация событий во времени с использованием когнитивного самообучения будущие перцептивные признаки. Несовпадение между предсказанными признаками и фактическими, вычисленное на следующем шаге времени, генерирует сигнал ошибки предсказания. Высокая ошибка сигнализирует о границе события. Начиная с этого момента необходима новая модель со- бытий, чтобы делать прогнозы на будущее. Ошибка предсказания запускает механизм стробирования для обновления рабочей модели событий (скрытых состояний в LSTM). Обширные эксперименты в различных областях демонстрируют, что предсказательное (предвосхищающее) обуче ние может изучать надежные представления событий из немаркированных потоковых видеопоследо- вательностей только с одной эпохой обуче ния (однократное прохождение через видео). На представлениях событий основаны самые современные результаты в области сегментации событий во времени (раздел 12.3) и про- странственно-временной локализации действий (раздел 12.5). При этом новые методы обеспечивают точность, сопоставимую с традиционными методами, которые основаны на обучении с учителем и требуют больших объемов аннотированных обучающих данных. Кроме того, мы показали, что система предсказательного обуче ния может обрабатывать и сегментировать потоковые видеоданные чрезвычайно большой продолжительности (раз- дел 12.4) со скоростью обработки, близкой к обработке в реальном времени. Предсказательное обуче ние помогает преодолеть растущую зависимость от обучающих данных и перейти к визуальному пониманию открытого мира. Мы надеемся, что полученные нами результаты стимулируют дальнейшие исследования в этом многообещающем направлении и избавят отрасль компью терного зрения от постоянно растущей потребности в аннотиро- ванных данных. бЛагодарности Это исследование было частично поддержано грантами Национального на- учного фонда США CNS 1513126, IIS 1956050 и IIS 1955230. Литературные исто ЧниКи Aakur Sathyanarayanan N., Sarkar Sudeep, 2019. A perceptual prediction frame- work for self-supervised event segmentation. In: The IEEE Conference on Com- puter Vision and Pattern Recognition (CVPR). Aakur Sathyanarayanan N., Sarkar Sudeep, 2020. Action localization through con- tinual predictive learning. arXiv preprint. arXiv:2003.12185. Aakur Sathyanarayanan, de Souza Fillipe D. M., Sarkar Sudeep, 2019. Going deeper with semantics: exploiting semantic contextualization for interpretation of human activity in videos. In: IEEE Winter Conference on Applications of Com- puter Vision (WACV). IEEE. ActEV: Activities in Extended Video, 2019. https:// actev.nist.gov/.\n--- Страница 562 ---\nЛитературные источники  561 Alahi Alexandre, Goel Kratarth, Ramanathan Vignesh, Robicquet Alexandre, Fei-Fei Li, Savarese Silvio, 2016. Social lstm: human trajectory prediction in crowded spaces. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 961–971. Alayrac Jean-Baptiste, Bojanowski Piotr, Agrawal Nishant, Sivic Josef, Laptev Ivan, Lacoste-Julien Simon, 2016. Unsupervised learning from narrated instruction videos. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4575–4583. Bahdanau Dzmitry, Cho Kyunghyun, Bengio Yoshua, 2014. Neural machine transla- tion by jointly learning to align and translate. arXiv preprint. arXiv:1409.0473. Bhatnagar Bharat Lal, Singh Suriya, Arora Chetan, Jawahar C. V., CVIT K. C. I. S., 2017. Unsupervised learning of deep feature representation for clustering ego- centric actions. In: International Joint Conference on Artificial Intelligence (IJCAI). AAAI Press, pp. 1447–1453. Bojanowski Piotr, Lajugie R´emi, Bach Francis, Laptev Ivan, Ponce Jean, Schmid Cordelia, Sivic Josef, 2014. Weakly supervised action labeling in videos under ordering constraints. In: European Conference on Computer Vision (ECCV). Springer, pp. 628–643. Caron Mathilde, Misra Ishan, Mairal Julien, Goyal Priya, Bojanowski Piotr, Joulin Armand, 2020. Unsupervised learning of visual features by contrasting cluster assignments. In: Advances in Neural Information Processing Systems, vol. 33. Chen Ting, Kornblith Simon, Norouzi Mohammad, Hinton Geoffrey, 2020. A simple framework for contrastive learning of visual representations. arXiv preprint. arXiv:2002.05709. Devlin Jacob, Chang Ming-Wei, Lee Kenton, Toutanova Kristina, 2018. Bert: pre- training of deep bidirectional transformers for language understanding. arXiv preprint. arXiv:1810.04805. Ding Li, Xu Chenliang, 2018. Weakly-supervised action segmentation with itera- tive soft boundary assignment. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Doersch Carl, Gupta Abhinav, Efros Alexei A., 2015. Unsupervised visual representa- tion learning by context prediction. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 1422–1430. Escorcia Victor, Dao Cuong D., Jain Mihir, Ghanem Bernard, Snoek Cees, 2020. Guess Where? Actor-Supervision for Spatiotemporal Action Localization. Computer Vision and Image Understanding, vol. 192, p. 102886. Fathi Alireza, Li Yin, Rehg James M., 2012. Learning to recognize daily actions us- ing gaze. In: European Conference on Computer Vision. Springer, pp. 314–327. Fernando Basura, Bilen Hakan, Gavves Efstratios, Gould Stephen, 2017. Self-super - vised video representation learning with odd-one-out networks. In: Proceed- ings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3636–3645. Finn Chelsea, Goodfellow Ian J., Levine Sergey, 2016. Unsupervised learning for physical interaction through video prediction. CoRR. arXiv:1605.07157. Fragkiadaki Katerina, Levine Sergey, Felsen Panna, Malik Jitendra, 2015. Recurrent network models for human dynamics. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 4346–4354.\n--- Страница 563 ---\n562  Сегментация событий во времени с использованием когнитивного самообучения Garcia del Molino Ana, Lim Joo-Hwee, Tan Ah-Hwee, 2018. Predicting visual context for unsupervised event segmentation in continuous photo-streams. In: ACM Conference on Multimedia (ACM MM). ACM, pp. 10–17. Gidaris Spyros, Singh Praveer, Komodakis Nikos, 2018. Unsupervised representation learning by predicting image rotations. arXiv:1803.07728 [cs.CV]. Gkioxari Georgia, Malik Jitendra, 2015. Finding action tubes. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 759–768. Grill Jean-Bastien, et al., 2020. Bootstrap your own latent-a new approach to self- supervised learning. In: Advances in Neural Information Processing Systems, vol. 33. Grundmann Matthias, Kwatra Vivek, Han Mei, Essa Irfan, 2010. Efficient hierarchi- cal graph-based video segmentation. In: 2010 IEEE Computer Society Confer - ence on Computer Vision and Pattern Recognition. IEEE, pp. 2141–2148. Hamilton William L., Ying Rex, Leskovec Jure, 2017. Representation learning on graphs: methods and applications. arXiv preprint. arXiv:1709.05584. Hard Bridgette M., Tversky Barbara, Lang David S., 2006. Making sense of abstract events: building event schemas. Memory & Cognition 34 (6), 1221–1235. Harel Jonathan, Koch Christof, Perona Pietro, 2007. Graph-based visual saliency. In: Advances in Neural Information Processing Systems, pp. 545–552. Hawkins Jeff, Ahmad Subutai , 2016. Why neurons have thousands of synapses, a theory of sequence memory in neocortex. Frontiers in Neural Circuits, vol. 10, p. 23. Hawkins Jeff, Blakeslee Sandra, 2004. On Intelligence. Macmillan. Heeger David J., 2017. Theory of cortical function. Proceedings of the National Academy of Sciences 114 (8), 1773–1782. Hershey John R., Chen Zhuo, Le Roux Jonathan, Watanabe Shinji, 2016. Deep cluster - ing: discriminative embeddings for segmentation and separation. In: 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, pp. 31–35. Hochreiter Sepp, Schmidhuber Jürgen, 1997. Long short-term memory. Neural Com- putation 9 (8), 1735–1780. Sayed Hossein Khatoonabadi, Vasconcelos Nuno, Bajic Ivan V., Shan Yufeng, 2015. How many bits does it take for a stimulus to be salient? In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5501–5510. Hou Rui, Chen Chen, Shah Mubarak, 2017. Tube convolutional neural network (T-CNN) for action detection in videos. In: Proceedings of the IEEE Interna- tional Conference on Computer Vision (ICCV), pp. 5822–5831. Huang De-An, Fei-Fei Li, Niebles Juan Carlos, 2016. Connectionist temporal mo- deling for weakly supervised action labeling. In: European Conference on Com- puter Vision (ECCV). Springer, pp. 137–153. Itti Laurent, Koch Christof, 2000. A saliency-based search mechanism for overt and covert shifts of visual attention. Vision Research 40 (10–12), 1489–1506. Jain Mihir, Van Gemert Jan, J´egou, Herv´e Bouthemy, Patrick Snoek, Cees G. M., 2014. Action localization with tubelets from motion. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 740–747. Jhuang Hueihan, Gall Juergen, Zuffi Silvia, Schmid Cordelia, Black Michael J., 2013. Towards understanding action recognition. In: Proceedings of the IEEE Inter - national Conference on Computer Vision, pp. 3192–3199.\n--- Страница 564 ---\nЛитературные источники  563 Ji Xu, Henriques João F., Vedaldi Andrea, 2019. Invariant information clustering for unsupervised image classification and segmentation. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 9865–9874. Jia Xu, De Brabandere Bert, Tuytelaars Tinne, Gool Luc V., 2016. Dynamic filter networks. In: Neural Information Processing Systems, pp. 667–675. Jiang Yu-Gang, Liu Jingen, Roshan Zamir A., Toderici George, Laptev Ivan, 2014. Mubarak Shah, and Rahul Sukthankar. THUMOS challenge: Action recognition with a large number of classes. Kitani Kris M., Ziebart Brian D., Bagnell James Andrew, Hebert Martial, 2012. Ac - tivity forecasting. In: European Conference on Computer Vision. Springer, pp. 201–214. Kodinariya Trupti M., Makwana Prashant R., 2013. Review on determining number of cluster in k-means clustering. International Journal 1 (6), 90–95. Kuehne Hilde, Arslan Ali, Serre Thomas, 2014. The language of actions: recovering the syntax and semantics of goal-directed human activities. In: IEEE Confer - ence on Computer Vision and Pattern Recognition (CVPR), pp. 780–787. Kuehne Hilde, Gall Juergen, Serre Thomas, 2016. An end-to-end generative frame- work for video segmentation and recognition. In: IEEEWinter Conference on Applications of Computer Vision (WACV). IEEE, pp. 1–8. Kurby Christopher A., Zacks Jeffrey M., 2008. Segmentation in the perception and memory of events. Trends in Cognitive Sciences 12 (2), 72–79. Lan Tian, Wang Yang, Mori Greg, 2011. Discriminative figure-centric models for joint action localization and recognition. In: 2011International Conference on Computer Vision. IEEE, pp. 2003–2010. Lea Colin, Reiter Austin, Vidal Ren´e, Hager Gregory D., 2016. Segmental spatiotem- poral cnns for fine-grained action segmentation. In: European Conference on Computer Vision (ECCV). Springer, pp. 36–52. Lea Colin, Flynn Michael D., Ren´e Vidal, Austin Reiter, Hager Gregory D., 2017. Temporal convolutional networks for action segmentation and detection. In: IEEE International Conference on Computer Vision (ICCV). Leboran Victor, Garcia-Diaz Anton, Fdez-Vidal Xose R., Pardo Xose M., 2016. Dy - namic whitening saliency. IEEE Transactions on Pattern Analysis and Machine Intelligence 39 (5), 893–907. LeCun Yann, Bengio Yoshua, et al., 1995. Convolutional networks for images, speech, and time series. Lei Peng, Todorovic Sinisa, 2018. Temporal deformable residual networks for action segmentation in videos. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 6742–6751. Li Ruiyu, Tapaswi Makarand, Liao Renjie, Jia Jiaya, Urtasun Raquel, Fidler Sanja, 2017. Situation recognition with graph neural networks. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 4173–4182. Li Zhenyang, Gavrilyuk Kirill, Gavves Efstratios, Jain Mihir, Snoek Cees GM, 2018. Videolstm convolves, attends and flows for action recognition. Computer Vision and Image Understanding 166, 41–50. Liang Junwei, Jiang Lu, Carlos Niebles Juan, Hauptmann Alexander G., Fei-Fei Li, 2019. Peeking into the future: predicting future person activities and locations in videos. In: Proceedings of the IEEE Conference on Computer Vision and Pat - tern Recognition, pp. 5725–5734.\n--- Страница 565 ---\n564  Сегментация событий во времени с использованием когнитивного самообучения Liu Wenqian, Sharma Abhishek, Camps Octavia, Sznaier Mario, 2018. DYAN: a dy - namical atoms-based network for video prediction. In: Proceedings of the Euro- pean Conference on Computer Vision (ECCV), pp. 170–185. Lotter William, Kreiman Gabriel, Cox David, 2016. Deep predictive coding net - works for video prediction and unsupervised learning. arXiv preprint. arXiv: 1605.08104. Luc Pauline, Neverova Natalia, Couprie Camille, Verbeek Jakob, LeCun Yann, 2017. Pre-dicting deeper into the future of semantic segmentation. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 648–657. Luong Minh-Thang, Pham Hieu, Manning Christopher D., 2015. Effective ap- proaches to attention-based neural machine translation. arXiv preprint. arXiv: 1508.04025. Ma Shugao, Sigal Leonid, Sclaroff Stan, 2016. Learning activity progression in lstms for activity detection and early detection. In: Proceedings of the IEEE Confer - ence on Computer Vision and Pattern Recognition, pp. 1942–1950. Ma Shugao, Zhang Jianming, Ikizler-Cinbis Nazli, Sclaroff Stan, 2013. Action recog- nition and localization by hierarchical space-time segments. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 2744–2751. van der Maaten Laurens, Hinton Geoffrey, 2008. Visualizing data using t-SNE. Jour - nal of Machine Learning Research 9, 2579–2605. Malmaud Jonathan, Huang Jonathan, Rathod Vivek, Johnston Nick, Rabinovich An- drew, Murphy Kevin, 2015. What’s cookin’? Interpreting cooking videos using text, speech and vision. arXiv preprint. arXiv:1503.01558. Mathieu Michaël, Couprie Camille, LeCun Yann, 2015. Deep multi-scale video pre- diction beyond mean square error. CoRR. arXiv:1511.05440 [abs]. Misra Ishan, Zitnick C. Lawrence, Hebert Martial, 2016. Shuffle and learn: unsuper - vised learning using temporal order verification. In: European Conference on Computer Vision. Springer, pp. 527–544. Neverova Natalia, Luc Pauline, Couprie Camille, Verbeek Jakob J., LeCun Yann, 2017. Predicting deeper into the future of semantic segmentation. CoRR abs. arXiv: 1703.07684. Radvansky Gabriel A., Zacks Jeffrey M., 2014. Event Cognition. Oxford University Press. Richard Alexander, Gall Juergen, 2016. Temporal action detection using a statistical language model. In: IEEE Conference on Computer Vision and Pattern Recogni- tion (CVPR), pp. 3131–3140. Richard Alexander, Kuehne Hilde, Gall Juergen, 2017. Weakly Supervised Action Learning with RNN Based Fineto-Coarse Modeling. IEEE Conference on Com- puter Vision and Pattern Recognition (CVPR), vol. 1.2, p. 3. Richmond Lauren L., Zacks Jeffrey M., 2017. Constructing experience: event models from perception to action. Trends in Cognitive Sciences 21 (12), 962–980. Rodriguez Mikel D., Ahmed Javed, Shah Mubarak, 2008. Action Mach a spatio-tem- poral maximum average correlation height filter for action recognition. In: 2008 IEEE Conference on Computer Vision and Pattern Recognition. IEEE, pp. 1–8. Russakovsky Olga, et al., 2015. Imagenet large scale visual recognition challenge. International Journal of Computer Vision (IJCV) 115 (3), 211–252. Santoro Adam, Raposo David, Barrett David G., Malinowski Mateusz, Pascanu Raz - van, Battaglia Peter, Lillicrap Timothy, 2017. A simple neural network module for\n--- Страница 566 ---\nЛитературные источники  565 relational reasoning. In: Advances in Neural Information Processing Systems, pp. 4967–4976. Sener Fadime, Yao Angela, 2018. Unsupervised learning and segmentation of com- plex activities from video. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Sharma Shikhar, Kiros Ryan, Salakhutdinov Ruslan, 2015. Action Recognition Using Visual Attention. Neural Information Processing Systems: Time Series Work - shop. Shipley Thomas F., Zacks Jeffrey M., 2008. Understanding Events: From Perception to Action, vol. 4. Oxford University Press. Simonyan Karen, Zisserman Andrew, 2014. Very deep convolutional networks for large-scale image recognition. arXiv preprint. arXiv:1409.1556. Song Jingkuan, Gao Lianli, Guo Zhao, Liu Wu, Zhang Dongxiang, Tao Shen Heng, 2017. Hierarchical LSTM with adjusted temporal attention for video captioning. In: Proceedings of the 26th International Joint Conference on Artificial Intel- ligence. AAAI Press, pp. 2737–2743. Soomro Khurram, Idrees Haroon, Shah Mubarak, 2015. Action localization in videos through context walk. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 3280–3288. Soomro Khurram, Idrees Haroon, Shah Mubarak, 2016. Predicting the where and what of actors and actions through online action localization. In: Proceed- ings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2648–2657. Soomro Khurram, Shah Mubarak , 2017. Unsupervised action discovery and lo - calization in videos. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 696–705. Soomro Khurram, Zamir Amir Roshan, Shah Mubarak , 2012. UCF101: a dataset of 101 human actions classes from videos in the wild. arXiv preprint. arXiv:1212.0402. de Souza Fillipe D. M., Sarkar Sudeep, Srivastava Anuj, Su Jingyong, 2016. Spatially coherent interpretations of videos using pattern theory. International Journal on Computer Vision (IJCV), 1–21. Srivastava Nitish, Mansimov Elman, Salakhutdinov Ruslan, 2015. Unsupervised learning of video representations using LSTMs. CoRR. arXiv:1502.04681 [abs]. Stein Sebastian, McKenna Stephen J., 2013. Combining embedded accelerometers with computer vision for recognizing food preparation activities. In: ACM In- ternational Joint Conference on Pervasive and Ubiquitous Computing. ACM, pp. 729–738. Sun Chen, Shrivastava Abhinav, Vondrick Carl, Sukthankar Rahul, Murphy Kevin, Schmid Cordelia, 2019. Relational action forecasting. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 273–283. Thorpe Simon, Fize Denis, Marlot Catherine, 1996. Speed of processing in the human visual system. Nature 381 (6582), 520. Tian Yicong, Sukthankar Rahul, Shah Mubarak, 2013. Spatiotemporal deformable part models for action detection. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2642–2649. Tipper Steven P., Lortie Cathy, Baylis Gordon C., 1992. Selective reaching: Evidence for action-centered attention. Journal of Experimental Psychology. Human Perception and Performance 18 (4), 891.\n--- Страница 567 ---\n566  Сегментация событий во времени с использованием когнитивного самообучения Tran Du, Yuan Junsong, 2012. Max-margin structured output regression for spatio- temporal action localization. In: Advances in Neural Information Processing Systems, pp. 350–358. Tran Du, Yuan Junsong, 2011. Optimal spatio-temporal path discovery for video event detection. In: CVPR 2011. IEEE, pp. 3321–3328. Uijlings Jasper R. R., Van De Sande, Koen E. A., Gevers Theo, Smeulders Arnold W. M., 2013. Selective search for object recognition. International Journal of Computer Vision (IJCV) 104 (2), 154–171. Van Gemert Jan C., Jain Mihir, Gati Ella, Snoek Cees G. M., et al., 2015. APT: action localization proposals from dense trajectories. In: BMVC, vol. 2, p. 4. Vaswani Ashish, Shazeer Noam, Parmar Niki, Uszkoreit Jakob, Jones Llion, Gomez Aidan N., Kaiser Łukasz, Polosukhin Illia, 2017. Attention is all you need. In: Advances in Neural Information Processing Systems, pp. 5998–6008. Vondrick Carl, Pirsiavash Hamed, Torralb, Antonio , 2016. Anticipating visual repre- sentations from unlabeled video. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 98–106. Vondrick Carl, Shrivastava Abhinav, Fathi Alireza, Guadarrama Sergio, Murphy Kevin, 2018. Tracking emerges by colorizing videos. In: Proceedings of the European Conference on Computer Vision (ECCV), pp. 391–408. Walker Jacob, Gupta Abhinav, Hebert Martial, 2014. Patch to the future: unsuper - vised visual prediction. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3302–3309. Wang Hongxing, Yuan Junsong, Wu Ying, 2014a. Context-aware discovery of vi- sual co-occurrence patterns. IEEE Transactions on Image Processing 23 (4), 1805–1819. Wang Limin, Qiao Yu, Tang Xiaoou, 2014b. Video action detection with relational dynamic-poselets. In: European Conference on Computer Vision. Springer, pp. 565–580. Xie Junyuan, Girshick Ross, Farhadi Ali, 2016. Unsupervised deep embedding for clustering analysis. In: International Conference on Machine Learning (ICML), pp. 478–487. Xu Kelvin, Ba Jimmy, Kiros Ryan, Cho Kyunghyun, Courville Aaron, Salakhudinov Ruslan, Zemel Rich, Bengio Yoshua, 2015. Show, attend and tell: neural image caption generation with visual attention. In: International Conference on Ma- chine Learning, p. 2048. 2057. Yang Zhilin, Dai Zihang, Yang Yiming, Carbonell Jaime, Salakhutdinov Russ R., Le Quoc V., 2019. Xlnet: generalized autoregressive pretraining for language un- derstanding. In: Advances in Neural Information Processing Systems, pp. 5754– 5764. Zacks Jeffrey M., Braver, Todd S., Sheridan, Margaret A., Donaldson, David I., Snyder, Abraham Z., Ollinger, John M., Buckner, Randy L., Raichle, Marcus E., 2001a. Hu- man brain activity time-locked to perceptual event boundaries. Nature Neuro- science 4 (6), 651–655. Zacks, Jeffrey M., Tversky Barbara, Iyer Gowri, 2001b. Perceiving, remembering, and communicating structure in events. Journal of Experimental Psychology. General 130 (1), 29. Zacks Jeffrey M., Magliano Joseph P., 2011. Film, narrative, and cognitive neurosci- ence. Art and the Senses 435, 454.\n--- Страница 568 ---\nОб авторах главы  567 Zacks Jeffrey M., Speer Nicole K., Swallow Khena M., Braver Todd S., Reynolds Jeremy R., 2007. Event perception: a mind-brain perspective. Psychological Bulletin 133 (2), 273. Zacks Jeffrey M., Tversky Barbara, 2001. Event structure in perception and concep- tion. Psychological Bulletin 127 (1), 3. Zhang Mengmi, Teck Ma Keng, Hwee Lim Joo, Zhao Qi, Feng Jiashi, 2017. Deep future gaze: gaze anticipation on egocentric videos using adversarial networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recogni- tion, pp. 4372–4381. Zhang Richard, Isola Phillip, Efros Alexei A., 2016. Colorful image colorization. arXiv:1603.08511 [cs.CV]. Zhu Gao, Porikli Fatih, Li Hongdong, 2015. Tracking randomly moving objects on edge box proposals. arXiv preprint. arXiv:1507.08085. об аВтора Х гЛаВы Рами Мунир – доктор философии, сотрудник кафедры вычислительной тех - ники и технологии Университета Южной Флориды (USF) в Тампе. Он получил степень бакалавра технических наук и степень магистра в области машино- строения USF в 2015 и 2018 гг. соответственно. Также получил диплом с отли- чием и награду «Выдающийся выпускник» в 2015 г. и сертификат выпускника курсов робототехники от USF в 2018 году. Является лауреатом премии «Ранние инновации» от корпорации Intel. Его исследовательские интересы включают изучение иерархических представлений объектов и событий на основе само- обучения, реализацию перцептивных и когнитивных теорий с использовани- ем вычислительных методов глубокого обуче ния и прогностических моделей. Сатьянараянан Аакур – доцент кафедры информатики в Университете шта- та Оклахома. Получил степень бакалавра в области электроники и техники связи Университета Анны, Ченнаи, в 2013 г., а затем степень магистра в об- ласти информационных систем управления и докторскую степень в области компьютерных наук в Университете Южной Флориды, Тампа, в 2015 и 2019 гг. соответственно. Его исследовательские интересы включают самообучащиеся модели, механизмы визуального понимания сцены и приложения глубокого обуче ния в геномике. Судип Саркар – профессор и заведующий кафедрой вычислительной тех - ники и технологии, а также заместитель вице-президента по специальным программам Университета Южной Флориды в Тампе. Получил степень ба- калавра технических наук Индийского технологического института, Канпур, и степень доктора философии в области электроники Университета штата Огайо. Имеет более чем 25-летний опыт работы в области компьютерного зрения, алгоритмов и систем распознавания образов, десять патентов США, а также публикует высокоцитируемые статьи в журналах и на конференциях. Является членом AAAS, IEEE, IAPR, AIMBE и NAI. Работал во многих журналах и в настоящее время является главным редактором рецензируемого научно- го журнала о распознавании образов.\n--- Страница 569 ---\nГлава 13 Вероятностные методы обнаружения аномалий в данных временных рядов с использованием обученных моделей для мультимедийных самосознательных систем Авторы главы: Карло Регаццони, Али Краяни, Джулия Славик и Лучио Марченаро, DITEN, Генуэзский университет, Генуя, Италия Краткое содержание главы: в этой главе представлена архитектура модели для обнаружения анома- лий и объясняется ее значение для самосознательных систем с инкре- ментным обуче нием; мы кратко рассмотрим современные методы обнаружения аномалий, про- ведем их сравнение и отметим наш вклад; самосознательный агент, работающий с мультимедийными сенсорными данными, может обнаруживать аномалии на иерархическом уровне и об- рабатывать как мало-, так и многомерные данные; обобщенные состояния (generalized state, GS) строятся непосредственно из малоразмерных наблюдений. Напротив, вариационный автоэнкодер ис - пользуется для вывода GS более низкой размерности из данных высокой размерности;",
      "debug": {
        "start_page": 516,
        "end_page": 569
      }
    },
    {
      "name": "Глава 13. Вероятностные методы обнаружения аномалий моделей для мультимедийных самосознательных систем 568",
      "content": "--- Страница 570 ---\nВведение  569 обобщенная динамическая байесовская сеть (generalized dynamic bayes- ian network, GDBN) изучается из GS и используется для прогнозирования динамики системы на нескольких уровнях; прогностические и диагностические сообщения, проходящие внутри GDBN, позволяют вычислять обобщенные ошибки (generalized error) для обнару- жения новых возникающих правил; мы проверяем предложенный подход, используя реальные мультисенсор- ные данные полуавтономного самосознательного автомобиля. 13.1. В Ведение Идентификация аномальных экземпляров данных представляет собой акту - альную задачу в различных областях исследований. Благодаря алгоритмам обнаружения аномалий камеры видеонаблюдения могут распознавать, ког - да происходят потенциально опасные или насильственные события, такие как взлом, нападения, вооруженные ограбления или дорожно-транспортные происшествия; находить подозрительные зоны на медицинских изображе- ниях, таких как маммограммы или томографические снимки, и помогать врачам в диагностике опухолей; обнаруживать мошеннические операции с кредитными картами как отклонения от обычного профиля использования клиентами. В общем, методы обнаружения аномалий составляют необходи- мый компонент во всех приложениях, требующих выявления отклонений от известного набора правил или моделей. Здесь важно отметить, что аномалии связаны с моделью и не являются абсолютными: в случае видеонаблюдения исходная модель может описывать нормальные взаимодействия между по- купателями в магазине; в случае с медицинской визуализацией она может выделять характерные черты здорового органа; в случае с кредитной картой она может отслеживать обычные схемы транзакций пользователя по кредит - ной карте. Аномальные данные соответствуют отклонению от этих изучен- ных моделей и вместо этого подчиняются другим правилам. Поэтому оче- видно, что обнаружение аномалий, обладающее множеством применений, имеет фундаментальное значение и для искусственных самосознательных систем, которые могут постоянно учиться на новых ситуациях, поскольку оно позволяет системе отличать новые ситуации от уже испытанных. Самосознание (self-awareness) можно определить как «способность стано- виться объектом собственного внимания» (Morin, 2006). Оно достигается, когда агент фокусируется не только на внешней среде, но и на эволюции своего собственного состояния. Концепция самосознания обычно приписы- вается биологическим существам и целенаправленно изучается некоторыми учеными, такими как Хайкин и Фустер (Haykin, Fuster, 2014), Фристон и др. (Friston et al., 2014) и Дамасио (Damasio, 1999). В последних исследованиях эту концепцию начали переносить на искусственные агенты, такие как по-\n--- Страница 571 ---\n570  Вероятностные методы обнаружения аномалий в данных временных рядов луавтономные автомобили и дроны или когнитивные радиоканалы1. Чтобы эти агенты одновременно осознавали свое окружение и свое внутреннее состояние, они должны быть снабжены сенсорами двух разных типов: (1) экс- тероцептивными сенсорами для достижения осведомленности о внешней ситуации, такими как внешние камеры; (2) проприоцептивными сенсорами для самосознания, такими как датчик положения рулевого колеса в транс - портном средстве. Благодаря способности сознавать окружающую ситуацию и свое состояние эти агенты могут распознавать опыт, с которым они стал- киваются, исходя из ранее приобретенного опыта; это знание составляет основу для принятия решения и выполнения действия, влияющего на окру - жающую среду через набор исполнительных механизмов. Как недавно предложили в (Regazzoni et al., 2020), чтобы считаться само- сознательным, агент должен обладать шестью основными возможностями: инициализация, вывод, обнаружение аномалий, создание модели и интер- фейс с управлением. Самосознательный агент сначала инициализируется с предопределенной моделью (1) и может запомнить модель (2); далее он использует изученную модель, чтобы делать выводы о своем будущем со- стоянии и будущих изменениях в окружающей среде (3); он обнаруживает новые ситуации, когда они появляются (4), и изучает новую модель для их описания (5); наконец, он использует полученные знания для принятия ре- шений и внесения изменений в окружающую среду (6). Одна функция следует за другой, и они образуют замкнутый цикл, поскольку этап (5) переходит в (2). Обнаружение аномалий – это важнейший навык самосознательных си- стем, поскольку он запускает процессы идентификации неизвестных правил и создания новой модели. В таком контексте важно показать, как мы рас - сматриваем данные временных рядов и как можно определить аномалию путем сравнения прогноза для следующего момента времени с фактическим наблюдением в этот момент времени. В этой главе мы предлагаем метод обнаружения аномалий в данных вре- менных рядах, который следует включить в описанный выше цикл само- сознания. Метод использует обобщенные динамические байесовские сети (GDBN) и их возможности передачи сообщений для определения иерархии различных уровней аномалий. Его можно использовать для данных с низкой и высокой размерностями. В многомерном случае (например, изображения) для преобразования многомерных данных в вероятностное низкоразмер- ное скрытое пространство можно использовать генеративные модели, такие как вариационные автокодировщики (VAE) или генеративно-состязательные сети (GAN). В этой главе мы обсудим в качестве примера использование VAE для уменьшения размерности данных. Остальная часть главы структурирована следующим образом: в разде- ле 13.2 представлены основные понятия о генеративных моделях, GDBN, ва- риационных автоэнкодерах и современные способы обнаружения аномалий в низкоразмерных и многомерных данных; в разделе 13.3 описан предлага- емый нами метод; в разделе 13.4 представлены результаты, полученные на 1 Например, «умная» сеть приемопередатчиков в сетях 6G, способная динамично оценивать окружающую обстановку, абонентскую нагрузку и собственное состоя- ние и оптимально самонастраиваться под обстоятельства. – Прим. перев.\n--- Страница 572 ---\nБазовые понятия и текущее положение дел  571 предлагаемых данных; раздел 13.5 завершает главу и предлагает некоторые идеи для дальнейших исследований. 13.2. базоВые понятия и теКущее поЛожение деЛ 13.2.1. Генеративные модели В контексте машинного обуче ния можно выделить два типа моделей: дискри- минативные и генеративные. Дискриминативные модели изучают условную вероятность метки класса с учетом некоторых наблюдаемых входных дан- ных – это вариант классификации. С другой стороны, генеративные модели могут изучать скрытое распределение данных, на которых они обучаются, и генерировать выборки из того же распределения. Байесовские сети (Bayes- ian networks, BN) представляют собой разновидность генеративной моде- ли, факторизующей совместное распределение данных с учетом условных вероятностей, зависящих от скрытых переменных модели. В свою очередь, динамические байесовские сети (dynamic Bayesian networks, DBN) выполняют эту факторизацию во времени. При работе с многомерными данными, такими как изображения, наибо- лее часто используемыми генеративными моделями являются вариацион- ные автокодировщики (variational autoencoders, VAE) (Kingma, Welling, 2014) и генеративно-состязательные сети (generative adversarial networks, GAN) (Goodfellow et al., 2014). VAE изучают распределение вероятностей данных явно, обычно предполагая распределение Гаусса или гауссовой смешанной модели. VAE, предполагающие гауссово распределение данных, кодируют каждую выборку данных через среднее значение и дисперсию. Делая выбор- ки из изученного распределения, они могут генерировать точки данных, ана- логичные тем, на которых они обучались. И наоборот, GAN изучают распре- деление данных неявно без определения каких-либо параметров. VAE и GAN могут дополнительно использоваться внутри DBN для изучения связи между многомерными данными (например, изображениями) и низкоразмерными латентными состояниями (т. е. так называемой моделью наблюдения) (Slavic et al., 2021). Следовательно, в нашей проблеме определения генеративной модели мы можем различать два случая: в первом дана модель наблюдения (например, случай радиоданных); во втором модель наблюдения должна быть изучена (например, случай видеоданных). В этой главе мы рассказыва- ем о результатах как частичного, так и полного изучения. 13.2.2. Модели динамической байесовской сети (DBN) Байесовские сети (Bayesian network, BN) – это модели направленного ацикли- ческого графа, в которых узлы графа представляют собой набор случайных\n--- Страница 573 ---\n572  Вероятностные методы обнаружения аномалий в данных временных рядов величин, а ребра кодируют конкретную факторизацию совместного распре- деления этого набора в один момент времени. Однако во многих реальных приложениях большинство событий обнаруживаются не на основе одного момента времени, а на основе нескольких наблюдений, которые приводят к определенному событию (Mihajlovic, Petkovic, 2001). Динамическая байесовская сеть (DBN) является расширением BN, кото- рое может моделировать динамические процессы и описывать эволюцию системы во времени на иерархических уровнях. DBN позволяют кодировать вероятностные зависимости и обратные связи между случайными величина- ми в разных временных интервалах. DBN обычно представлена двумя набо- рами параметров. Первый содержит количество узлов в каждом временном интервале и соответствующую топологию, а второй набор состоит из услов- ных распределений вероятностей (conditional probability distributions, CPD), описанных ребрами сети. DBN обобщают линейные динамические системы, представляя скрытые и наблюдаемые состояния в виде случайных пере- менных состояния, образующих графовую структуру, которая определяет соответствующие условные зависимости и компактную параметризацию модели. DBN могут разлагать данные со сложной и нелинейной динамикой на сегменты, которые можно объяснить с по мощью более простых динами- ческих блоков. Для представления динамических блоков и объяснения их поведения при переключении и их зависимости как от наблюдений, так и от непрерывных скрытых состояний можно использовать специфический класс моделей DBN, известных как линейные динамические системы с переключе- нием (switching linear dynamic system, SLDS) (Fox et al., 2011). Обуче ние DBN состоит из изучения параметров и изучения структуры. Первое – это процесс изучения распределений дискретных или непрерывных скрытых перемен- ных в DBN, тогда как второе – это процесс использования данных для изуче- ния связей (т. е. условных вероятностей) между случайными величинами в DBN. Изучение как параметров, так и структуры зависит от рассматривае- мой модели в пространстве состояний. Представление процесса временного ряда в пространстве состояний определяет приор P(Xt), функцию перехода состояния P(Xt|Xt–1) и функцию наблюдения P(Zt|Xt). Скрытые марковские модели (hidden Markov model, HMM) и модели фильтра Калмана (Kalman filter model, KFM) можно рассматривать как возможные способы представления моделей пространства состояний, закодированных в простой DBN, которая содержит одну скрытую переменную и один наблюдаемый узел на срез, как показано на рис. 13.1. Предполагается, что скрытые дискретные переменные в HMM имеют полиномиальное дискретное распределение и эволюциони- руют в соответствии с правилами перехода, параметризованными в моде- ли. Дискретные переменные и соответствующая матрица перехода могут быть изучены с по мощью алгоритма кластеризации наблюдаемых данных временных рядов. В случае KFM эволюция перехода состояния становится линейно-гауссовой, например: Xt = AX t–1 + BU t + wt, (13.1) где Ut – управляющий вход, реализующий родительский узел соответствую- щего Xt. В байесовской архитектуре обуче ние начинается с априорных зна-\n--- Страница 574 ---\nБазовые понятия и текущее положение дел  573 ний о структуре модели (т. е. связях в DBN) и параметрах модели. В случае простой DBN (рис. 13.1) начальные знания о скрытой переменной состояния Xt с учетом распределения вероятностей P(Xt) могут быть обновлены с ис - пользованием данных Zt и использованы для вычисления апостериорной вероятности P (Xt|Zt) в соответствии с правилом Байеса: (13.2) Xt+1 Zt+1Xt ZtXt–1 Zt–1 Рис. 13.1  Простая динамическая байесовская сеть. Сеть является скрытой марковской моделью (HMM), когда X является дискретной пе- ременной, и моделью фильтра Калмана (KFM), когда X – непрерывная переменная Возможная комбинация фильтра частиц (particle filter, PF) и фильтра Кал- мана (Kalman filter, KF), представленная в (Baydoun et al., 2018), может быть реализована на DBN как алгоритм вероятностного вывода. В байесовской архитектуре существуют различные типы вероятностных выводов, а именно нисходящий (или прогнозирующий) вывод и восходящий (или диагностиче- ский) вывод. Каждый из этих выводов основан на разложении требуемых вы- числений на локальные вычисления в каждом узле сети, для чего требуется только передача сообщений с использованием алгоритма передачи сообще- ний (Winn, Bishop, 2005) по ребрам, связанным с этим узлом. В данной главе предлагаемый нами подход обогащен расширенными воз- можностями по сравнению с классическим байесовским выводом, чтобы использовать прогностические и диагностические сообщения, поступающие в общий узел DBN, для расчета измерений аномалий на иерархических уров - нях с использованием соответствующих вероятностных расстояний. Такие аномалии также можно использовать для постепенного изучения новых мо- делей, описывающих вариации на разных уровнях абстракции. 13.2.3. Вариационный автокодировщик Как сказано в разделе 13.2.1, VAE – это генеративная модель. В простейшей базовой версии она состоит из кодировщика Qθ(X|Z) и декодера Pϕ(Z|X), кото - рые можно построить в процессе обуче ния VAE на обучающих данных. Через θ и ϕ мы определяем параметры кодировщика и декодера соответственно. Кодировщик Qθ(X|Z) позволяет представить каждую введенную в него вы- борку Z через два признака «бутылочного горла» – среднее значение μ и дис - персию σ2. С другой стороны, декодер Pϕ(Z|X) синтезирует наблюдение Z из\n--- Страница 575 ---\n574  Вероятностные методы обнаружения аномалий в данных временных рядов скрытого состояния X, выбранного из 𝒩(μ, σ2). Следовательно, кодировщик позволяет уменьшить размерность наблюдений (т. е. данных изображения) и обрабатывать обнаружение аномалий на низкоразмерном уровне состоя- ния; и наоборот, декодер позволяет снова получать многомерные данные и обрабатывать обнаружение аномалий на уровне наблюдения. Заметим, что в архитектуре DBN, описанной в предыдущем разделе, VAE можно рас - сматривать как модель наблюдения P (Zt|Xt). Обуче ние VAE направлено на оптимизацию параметров θ и ϕ путем мак - симизации суммы нижней границы предельной вероятности каждого на - блюдения Z набора данных D , как описано в (Kingma, Welling, 2014, 2019): (13.3) где ℒϕ,θ(Z) определяется как ℒϕ,θ(Z) = –DKL(Qθ(X|Z) || Pϕ(X) + EQθ(X|Z)[logpϕ(Z|X)], (13.4) где член DKL – дивергенция KL. Таким образом, первый член измеряет раз- ницу между распределением кодировщика Qθ(X|Z) и априорным распреде- лением Pϕ(X), которое обычно представляет собой стандартное нормальное распределение 𝒩(0, 1). Второй член представляет собой ожидаемое логариф- мическое правдоподобие наблюдения Z и заставляет VAE восстанавливать входные данные. В данной работе используется способность VAE кодировать входную ин- формацию в пространстве значительно меньшей размерности, проявляю- щем вероятностные свойства. Как отмечалось в разделе 13.2.1, VAE могут быть интегрированы в модель DBN в случае, когда модель наблюдения не задана, но также должна быть изучена. 13.2.4. Типы аномалий и методы обнаружения аномалий Как было отмечено в разделе 13.1, аномалиями являются любые отклоне- ния, проявляющиеся по отношению к эталонной модели. Понятие аномалии весьма обширно и зависит от типа данных, мощности взаимосвязи между задействованными переменными, структуры и распределения данных (Foor - thuis, 2020). Различные типы аномалий – и, следовательно, расстояния до аномалий и алгоритмы обнаружения аномалий – могут быть обнаружены при работе с приложениями, не зависящими или зависящими от времени, с данными низкой размерности, такими как траектории, или многомерными данными, такими как изображения или графовые структуры и т. д. Чтобы оценить сложность и обширность проблематики обнаружения аномалий, мы снова обращаемся к работе (Foorthuis, 2020), в которой посредством обзора публикаций по обнаружению аномалий выделяются три широкие группы аномалий, 9 основных типов и 63 подтипа. Взяв в качестве примера видео- данные, Рамачандра и др. (Ramachandra et al., 2020) выделяют пять основных\n--- Страница 576 ---\nБазовые понятия и текущее положение дел  575 типов аномалий: 1) аномалия внешнего вида; 2) аномалия кратковременно- го движения; 3) аномалия длительного движения; 4) групповая аномалия; 5) аномалия времени суток. Например, автомобиль, движущийся по улице, может либо увидеть аномальный объект в виде дорожного конуса в центре улицы (1), либо обнаружить аномальное движение в виде резкого торможе- ния впереди идущего автомобиля (2), либо выполнить последовательность действий: аномальные движения, например, из-за того, что водитель заснул (3), наблюдение за двумя другими транспортными средствами, взаимодей- ствующими ненормальным образом, как при столкновении (4); наконец, скорость движения, нормальная для светлого времени суток, не разрешена после захода солнца (5). Работа Чандолы и др. (Chandola et al., 2009) формирует основу для клас - сификации методов обнаружения аномалий. В этом разделе мы приводим краткий обзор определенных классов точечных аномалий. Авторы упомя- нутой статьи различают шесть общих методов обнаружения точечных ано- малий; первые пять являются детерминированными методами, а шестой объединяет вероятностные методы. Далее мы кратко рассмотрим пять из шести этих методов. Кроме того, авторы указывают, как можно выделить дополнительные методы для контекстуальных аномалий, таких как аномаль- ные последовательности во временном ряду. Методы на основе классификации (CLA) В методах этого типа изучается классификатор, который может либо от - личать нормальные данные от аномальных на основе дискриминационной границы (одноклассовый классификатор), либо отличать классы нормальных данных друг от друга (многоклассовый классификатор). Во втором случае экземпляр определяется как аномальный, когда его нельзя с достаточной уверенностью связать ни с одним из нормальных классов. Любой алгоритм, обычно используемый для классификации, может быть адаптирован для это- го типа метода, включая нейронные сети, байесовские сети, машины опорных векторов (support vector machines, SVM) и методы классификации на основе правил. Методы на основе расстояния (DB) Методы этого типа основаны на вычислении расстояния от точек данных до их ближайших соседей с использованием допущений о том, что нормальные данные встречаются в плотных окрестностях, тогда как аномалии находятся далеко от своих ближайших соседей. Поэтому выбор метрики расстояния имеет важное значение. В случае окрестностей с различной плотностью зна- чение расстояния часто зависит от расстояний между точками в ближайшей окрестности. Методы на основе кластеризации (CLU) Эти методы основаны на предположениях, зависящих от выбранных методов кластеризации: 1) такие методы, как DBSCAN, ROCK или SNN, предполагают, что аномалии не относятся ни к одному из построенных кластеров; 2) при использовании таких методов, как SOM, предполагается, что аномальные\n--- Страница 577 ---\n576  Вероятностные методы обнаружения аномалий в данных временных рядов данные лежат далеко от центроида кластера; 3) наконец, можно использовать предположение, что нормальные данные относятся к большим кластерам, а аномальные – к малым кластерам. Теоретико-информационные методы (IT) В этих методах теоретико-информационные меры, такие как сложность Кол- могорова, энтропия или относительная энтропия, используются для анализа информационного содержания данных и извлечения наиболее аномального подмножества точек данных (т. е. последовательности, подграфа, области изображения) относительно остальных данных. Статистические/вероятностные методы (STA) Методы, основанные на вероятностях, нацелены на моделирование нормаль- ного распределения признаков выборки, связанных с обучающими данными, тогда как аномалии могут быть обнаружены как статистические выбросы (outlier), т. е. выборки с низкой вероятностью (Rivera et al., 2020). Вероят - ность того, что выборка данных принадлежит определенному распределе- нию, можно оценить с по мощью вероятностных расстояний, таких как рас - хождение Бхаттачарии, Махаланобиса, Хеллингера или Кульбака–Лейблера. Обнаружение аномалий с использованием вероятностных (статистических) моделей можно разделить на две основные группы: параметрические, такие как методы гауссовой модели смешения (Gaussian mixture model, GMM) и ме- тоды регрессии, и непараметрические, такие как методы гистограммы или оценки плотности ядра (kernel density estimation, KDE) (Wang et al., 2019). Существенным преимуществом вероятностного подхода является то, что его можно легко обобщить на различные типы данных и модальности; недоста- ток связан с подгонкой данных к определенному распределению, что может быть неуместным в некоторых случаях (Aggarwal, 2016). Кроме того, в публикации (Chandola et al., 2009) авторы определяют допол- нительный набор методов обнаружения аномалий, а именно методы обнару - жения спектральных аномалий, основанные на предположении, что данные, особенно многомерные, могут быть перенесены в подпространство более низкого измерения, где нормальные и аномальные данные легче разли - чить. Примерами таких методов могут быть использование PCA для данных изобра жения или представление графов как матриц смежности. Эти методы можно использовать в качестве этапа предварительной обработки для других методов, определенных выше. Мы более подробно поговорим о проблеме уменьшения размерности в разделе 13.2.6, поэтому пока проигнорируем эту группу методов. Точно так же при обработке аномальных последователь- ностей данных, таких как данные временных рядов, обнаружение может быть выполнено либо путем адаптации предыдущих методов к контекстным аномалиям, либо с по мощью методов, которые изучают структуру данных, например выполняя прогнозирование последующих моментов времени, ис - ходя из предыдущих (методы предсказания (PRE)). В табл. 13.1 представлена разработанная нами классификация с указанием основных характеристик для каждого метода. Обратите внимание, что все предлагаемые методы применимы к данным временных рядов и использу -\n--- Страница 578 ---\nБазовые понятия и текущее положение дел  577 ют обуче ние без учителя или с частичным привлечением учителя, поэтому не нуждаются в полностью размеченных обучающих данных. Большинство методов также могут быть применены в архитектурах инкрементного обуче- ния с использованием оценок аномалий, но эта проблема редко решается на современном уровне развития технологий. Классификация не дает оценки аномалии с доверительным интервалом, так как обычно в этом классе мето- дов объект описывается только бинарно – как принадлежащий или не при- надлежащий классу; теоретико-информационные методы также не имеют такой возможности. Кроме того, методы, основанные на расстоянии, и теоре- тико-информационные методы трудно распространить на данные высокой размерности. К вероятностным моделям можно применять только методы, основанные на прогнозировании, и статистические методы. Наконец, наш метод обладает всеми вышеупомянутыми характеристиками и дополнитель- но обеспечивает оценку аномалий на разных уровнях абстракции. Таблица 13.1. Сравнение различных методов. * – не требуется для одноклассовой версии, необходим для многоклассовой версии; ** – подходит для большинства методов этой категории, но не для всех CLA DB CLU IT STA PRE Наш Маркировка данных не нужна * ✓ ✓ ✓ ✓ ✓ ✓ Дает оценку аномалии с доверительным интервалом✗** ✓ ✓ ✗ ✓ ✓ ✓ Расширяемость до данных HD ✓ ✗ ✓ ✗ ✓ ✓ ✓ Применимость к вероятностным моделям ✗ ✗ ✗ ✗ ✓ ✓ ✓ Применимость к данным временных рядов✓ ✓ ✓ ✓ ✓ ✓ ✓ Позволяет инкрементное обуче ние ✓ ✓ ✓ ✗ ✓ ✓ ✓ Дает аномалию на разных уровнях абстракции✗ ✗ ✗ ✗ ✗ ✗ ✓ 13.2.5. Обнаружение аномалий в данных низкой размерности В этой главе мы сосредоточимся на вероятностных методах с частичным обуче нием, основанных на представлениях DBN для данных временных ря- дов. В нескольких работах для обнаружения аномалий в различных областях использовались BN и DBN (Mascaro et al., 2014; Bronstein et al., 2001; Salotti, 2018). Этот тип сетей, обеспечивающий иерархическое вероятностное пред- ставление мира, особенно хорошо подходит для автономных систем, которые пытаются отражать человеческие рассуждения. BN дополнительно позволя- ют построить иерархию аномалий. В частности, марковский скачкообразный фильтр частиц (Markov jump par - ticle filter, MJPF) использовался в качестве базового байесовского фильтра, применяемого к DBN для обнаружения аномалий низкоразмерных данных, поступающих от различных типов датчиков мультимодальных физиче-\n--- Страница 579 ---\n578  Вероятностные методы обнаружения аномалий в данных временных рядов ских агентов, таких как полуавтономные транспортные средства, в качест - ве данных одометрии в (Baydoun et al., 2018) и контрольной информации в (Kanapram et al., 2019). 13.2.6. Обнаружение аномалий в многомерных данных Поскольку видеоданные являются многомерными, большинство алгоритмов обнаружения аномалий, разработанных для данных низкой размерности, включая MJPF, не могут выполнить эффективную попиксельную обработку видеопотока. Вместо этого необходимо сначала извлечь признаки из видео- данных, что позволит перенести задачу в пространство меньшей размерно- сти (Chong, Tay, 2015). Процесс извлечения признаков может быть выполнен либо вручную, либо с по мощью методов, основанных на глубоком обучении (deep learning, DL). В первом случае человеческие знания о конкретных проб - лемах, таких как окклюзия, изменения ракурса, масштаба или освещения, используются для разработки экстракторов признаков; одним из наиболее известных примеров является гистограмма ориентированных градиентов (histogram of oriented gradients, HOG) (Dalal and Triggs, 2005). В методах, ос - нованных на DL, нейронные сети обучаются извлекать из данных соответ - ствующие признаки для конкретной задачи путем минимизации функции потерь. Поскольку методы на основе DL в значительной степени превосхо- дят ручные методы (Antipov et al., 2015; Alshazly et al., 2019; Nugroho, 2018), в этой главе мы рассматриваем только первые. После процедуры уменьшения размерности к извлеченным признакам можно применить различные методы обнаружения аномалий, описанные в разделе 13.2.4, как показано в табл. 13.1. Кроме того, при использовании экстрактора признаков, который также позволяет выполнять восстановление исходных кадров из низкоразмерных признаков, обычно также используют - ся методы обнаружения аномалий на основе восстановления. Как показано в (Kiran et al., 2018), методы этого типа учатся восстанавливать нормальные кадры или видеопоследовательности и определять плохо восстановленные образцы как аномалии; они обычно используют такие методы, как анализ основных компонентов или автокодировщики. Генеративные модели, такие как VAE и GAN, можно применять аналогичным образом, дополнительно получая возможность изучения основного распределения данных на уровне наблюдения. Эта способность VAE и GAN соответствует идеям данной главы, поскольку в ней основное внимание уделяется разработке вероятностного метода, ко- торый может быть включен в архитектуру DBN для выявления аномалий и их использования для непрерывного обуче ния моделей на данных временных рядов. Благодаря уменьшению размерности наблюдаемых кадров VAE и GAN можно использовать в качестве нелинейных моделей наблюдения в структу - ре DBN, описанной в разделе 13.2.2. Поскольку VAE могут явно описывать распределение вероятностей базовых данных, в нескольких работах предпринимались попытки использовать их\n--- Страница 580 ---\nАрхитектура вычисления аномалии в самосознательных системах  579 при создании модели линейной коммутации для данных высокой размерно- сти (Watter et al., 2015; Johnson et al., 2016; Fraccaro et al., 2017; Becker-Ehmck et al., 2019). Однако эти работы не рассматривали обнаружение аномалий и непрерывное обуче ние моделей в качестве цели. Кроме того, эксперименты до сих пор проводились на очень простых наборах данных, отображающих только основные движения и наблюдения со статической точки зрения. В другой работе (Ravanbakhsh et al., 2020) вместо этого были объединены GAN и DBN, реализующие одновременно обнаружение аномалий и непре- рывное обуче ние. В этой работе разработана иерархия связанных кросс- модальных сетей GAN. Когда из-за обнаружения аномальных наблюдений или аномальной динамики возникает высокая аномалия, строится новая GAN для изучения новой ситуации. Вместо MJPF разрабатывается модель коммутации, состоящая из иерархии GAN на непрерывном уровне и HMM на дискретном уровне. Однако из-за изучения вероятности данных без явной параметризации – как это свойственно GAN – этот метод имеет ограничения и не предусматривает возможность использования некоторых расстояний до аномалий, обычно применяемых для статистических методов обнаружения аномалий (раздел 13.2.4). Наиболее близкими к идеям данной главы являются работы (Slavic et al., 2021, 2020) и (Campo et al., 2020), в которых изучено сочетание VAE и MJPF, созданное для обнаружения аномалий и непрерывного обуче ния моделей. 13.3. арХитеКтура ВыЧисЛения анома Лии В самосознате Льны Х система Х 13.3.1. Общее описание архитектуры Предлагаемая нами архитектура изображена на рис. 13.2. На вход могут быть поданы данные низкой и высокой размерностей. После выполнения предварительной обработки данных низкой размерности и выделения при- знаков с по мощью кодировщиков VAE из многомерных данных строится вектор обобщенного состояния, включающий отфильтрованные состояния как обобщенные ошибки, полученные из исходной модели, которая активи- руется во время вывода в реальном времени во время начальной итерации. В этом случае исходная модель представляет собой статические правила окружающей среды (т. е. ожидаемые динамические изменения практически равны нулю и на них влияют только случайные возмущения). Путем класте- ризации обобщенных ошибок обучается модель обобщенной динамической байесовской сети (GDBN). При получении новых данных обученная модель используется для выполнения вывода через GDBN и извлекаются различные уровни аномалий (т. е. аномалия кадра, состояния, дискретного уровня). Если обнаруживается высокий уровень аномалии, соответствующие обобщенные состояния и обобщенные ошибки сохраняются, а новая модель строится для использования параллельно с предыдущими в следующем выводе GDBN.\n--- Страница 581 ---\n580  Вероятностные методы обнаружения аномалий в данных временных рядов Высокая размерность Видео/изображениеКадры энкодераВосстановленные изображенияДекодер Исходная модель Изученные моделиОфлайн Онлайн Опт. поток энкодера Предварительная обработка Хранение данных и обобщенных ошибок Нет генерации новой моделиАномалия?Да НетАномалия КЛ Непрерывная аномалия 1 Непрерывная аномалия 2 Аномалия кадра / Опт. потокаКласте- ризацияσ2 σ2μ μ Низкая размерность Позиция МощностьУгол поворота Скорость ротораОбучение VAE (3.2) Обучение GDBN (3.3) Вывод GDBN (3.4) Многоуровневые аномалии и обобщенные ошибки (3.5) Непрерывное обучение Рис. 13.2  Блок-схема предложенной нами архитектуры По рис. 13.2 мы также можем вывести характеристики метода, описанные в табл. 13.1: 1) прежде всего наш метод не нуждается в разметке данных. Вместо этого применяется частичное обуче ние: аномалия обнаруживается относительно обученной модели; 2) в качестве входных данных могут ис - пользоваться данные как низкой, так и высокой размерности. На рис. 13.2 в качестве примеров низкой размерности показаны данные одометрии, угла поворота рулевого колеса, скорости его поворота и мощности транспортно- го средства; видеоданные с камеры представляют собой данные высокой размерности; 3) рассматриваются данные временного ряда; 4) изучается вероятностная модель в форме GDBN; 5) аномалии относительно этой мо- дели обнаруживаются на разных уровнях абстракции, в частности на уров- не кадра, непрерывном и дискретном уровнях; 6) обнаруженные аномалии связаны с доверительным интервалом, как будет показано в разделе 13.3.4; 7) при обнаружении аномалии относительно изученной модели создается новая модель, поддерживающая инкрементное обуче ние и расширение пре- дыдущих знаний. В следующих разделах представлено более подробное описание этой ар- хитектуры. Обуче ние модели GDBN описано в разделе 13.3.2. Разделы 13.3.3 и 13.3.4 описывают алгоритм тестирования MJPF и его многоуровневые из- мерения аномалий соответственно. Наконец, в разделе 13.3.5 рассказано про\n--- Страница 582 ---\nАрхитектура вычисления аномалии в самосознательных системах  581 использование обобщенных ошибок, полученных с по мощью аномалий DBN, в качестве основы для непрерывного обуче ния новых моделей. Номер раз- дела главы, в котором объясняется каждое понятие, также выделен красным цветом на рис. 13.2 рядом с его графическим изображением. 13.3.2. Модель обобщенной динамической байесовской сети (GDBN) Первоначально самосознающий агент начинает воспринимать окружающую среду с по мощью исходной GDBN, т. е. фильтра с нулевым влиянием (null force filter) со статическими предположениями о состояниях среды, путем ин- терпретации полученных обобщенных наблюдений которые со- держат переменную и ее обобщенные координаты движения, поступающие от датчиков агента. В этом случае агент постоянно обнаруживает аномалии и вычисляет обобщенные ошибки GE( X˜t) в виде: (13.5) где Xt – предсказанные скрытые состояния, полученные фильтром с нулевым влиянием в соответствии со следующей динамической моделью: Xt = Xt–1 + vt, (13.6) в то время как – ошибки в производных, рассчитанные как обновления фильтром с нулевым влиянием с использованием текущих обобщенных на- блюдений следующим образом: (13.7) Далее GE, собранные в предыдущем опыте, используются на этапе обуче- ния в качестве входных данных для алгоритма кластеризации без учителя (например, Growing Neural Gas (GNG) (Fritzke, 1994), Self-Organizing Maps (SOMs) (Kohonen, 2001)), который кодирует GE в дискретные компоненты, производящие набор дискретных переменных (S ) или нейронов, которые мы называем сверхсостояниями (superstate), так что: S = {S1, S2, …, SM}, (13.8) где M – общее количество сверхсостояний. Заметим, что рассмотренные выше уравнения относятся к случаю данных малой размерности, когда модель наблюдений известна, является линейной и выражается матрицей H, отображающей наблюдения в скрытые состояния. В случае многомерных данных мы должны сначала понизить размерность с по мощью экстрактора признаков. Следовательно, первая часть GDBN, ко- торую необходимо изучить, – это сама модель наблюдений. Как говорилось в разделе 13.2.6, это может быть выполнено путем обуче ния таких сетей,\n--- Страница 583 ---\n582  Вероятностные методы обнаружения аномалий в данных временных рядов как VAE и GAN. В данной главе мы рассмотрим в качестве примера исполь- зование VAE. Чтобы получить как информацию о содержимом кадра, так и о движении между последовательными кадрами, мы обучаем пару VAE, одну для восстановления кадра в моменты времени t (обозначим ее zt), а дру - гую для восстановления оптического потока (optical flow, OF) между кадрами в моменты времени t и t + 1 (OF t). Соответственно, узкое место архитектуры разделено на две части: одну мы называем Xt – она представляет состояние/ контент (от zt); другую называем – она фиксирует информацию о движе- нии/скорости (из OF t). Кластеризация выполняется по комбинации этих двух переменных. После выполнения процесса уменьшения размерности остальная часть метода остается в основном такой же, с некоторыми поправками и ограни- чениями. После кластеризации матрица перехода (Π ) размерностью M×M, опреде- ляемая как Π (13.9) изучается путем оценки вероятностей перехода πi,j = P(St = i|St–1 = i), i, j Î S за период времени. Таким образом, можно создать набор обобщенных сверх - состояний S ˜t, определенных как (13.10) и включающих в себя текущую дискретную переменную St и событие E(.) пе - рехода к этой переменной, обусловленное нахождением в St–1 в предыдущий момент времени. Этот набор дискретных переменных образует верхний, или дискретный, уровень GDBN. Каждое обобщенное сверхсостояние S˜t(S˜t Î S) связано со статистическими свойствами, такими как среднее значение , ковариационная матрица и набор скрытых обобщенных состояний (GS) X˜t, закодированных внутри него. Скрытые непрерывные обобщенные со- стояния X˜t представляют промежуточный или непрерывный уровень GDBN. Отношение между скрытыми состояниями и сверхсостояниями характери- зуется связью P(X˜t|X˜t) в GDBN. В свою очередь, GDBN представляет скрытые переменные в обобщенных координатах движения, что позволяет самосо- знающему агенту самоорганизовываться путем оптимизации совместного апостериорного распределения по мере поступления новых наблюдений и непрерывно кодировать новые понятия, связанные с возникающей ситуа- цией после обнаружения аномалий. Нижний уровень GDBN соответствует реальным обобщенным наблюдени- ям Z˜t, измеренным датчиками. Путь от S˜t к Z˜t образует цепь причинно-след- ственных связей между случайными величинами на иерархических уровнях. Вероятностные зависимости между переменными, участвующими в цепи причинно-следственных связей, характеризуются связанными ребрами.\n--- Страница 584 ---\nАрхитектура вычисления аномалии в самосознательных системах  583 Учитывая цепное правило, совместную вероятность S˜t, X˜t и Z˜t, P(S˜t, X˜t, Z˜t) можно разложить на множители как произведение условных вероятностей, таких как: P(S˜t, X˜t, Z˜t) = P(S˜t)P(X˜t|S˜t)P(Z˜t|X˜t). (13.11) Это уравнение подразумевает возможность использования модели для создания новых выборок данных с учетом прямой причины (т. е. родитель- ского узла). Кроме того, связи между обобщенными скрытыми переменными в последовательные моменты времени представляют собой соответствую- щие условные временны е вероятности. Π включает в себя динамические правила на дискретном уровне, которые управляют динамическими измене- ниями путем переключения между несколькими динамическими моделями на непрерывном уровне. Такое вероятностное причинно-следственное обо- снование в GDBN позволяет объяснять события, диагностировать причины и делать прогнозы будущих событий, которые улучшают процессы принятия решений/действий. Вероятность перехода P(S˜t|S˜t–1) на дискретном уровне можно разложить следующим образом: S˜t = f(S˜t–1) + wt = f(πij) + wt, (13.12) где f(.) – нелинейная функция, определяющая временную эволюцию сверх - состояний на основе изученной матрицы переходов и подверженная шуму процесса wt, который, как предполагается, получен из нулевого многомер- ного нормального распределения с ковариантой Σ t, такой что w t ~ 𝒩 (0, Σ t). Динамические причинно-следственные модели, описывающие представ- ление в пространстве состояний процесса временных рядов – предполагая, что каждое наблюдение Z˜t генерируется из d-мерного скрытого состояния X˜t, которое, кстати, было порождено дискретным скрытым сверхсостоянием S˜t, – имеют следующий вид: X˜t = g(X˜t–1, S˜t–1) + wt = AX˜t–1 + BU S˜t + wt; (13.13) Z˜t = h(X˜t) + vt = HX˜t + vt. (13.14) Здесь предполагается, что непрерывная функция g(·) в уравнении (13.13) является линейной и определяет эволюцию состояния во времени на непре- рывном уровне, руководствуясь предсказаниями дискретного уровня, и под- вергается влиянию гауссова шума wt. В уравнении (13.13) A и B – матрица динамической модели и матрица модели управления соответственно. С каж - дым сверхсостоянием S˜t связан другой управляющий вектор US˜t, который зависит от средней производной выборок X˜t, закодированных в этом сверх - состоянии. Таким образом, Π кодирует не только переходы между сверх - состояниями, но и переходы между различными линейными моделями на непрерывном уровне. В уравнении (13.14) H – матрица наблюдения, которая отображает скрытое X˜t в наблюдение Z˜t, а vt – гауссов шум измерений с ну - левым средним и ковариацией R t, такой что v t ~ 𝒩 (0, R t). В случае многомерных данных модель наблюдения, описанная в уравне- нии (13.14), связана с нелинейным преобразованием, применяемым VAE при\n--- Страница 585 ---\n584  Вероятностные методы обнаружения аномалий в данных временных рядов извлечении признаков. Следовательно, функция h в этом случае нелинейна. Кроме того, уравнение (13.13) невозможно непосредственно применить для описания эволюции состояния во времени из-за сильной нелинейности, ко- торая может присутствовать в GS. Чтобы сохранить структуру многомерного случая как можно более похожей на маломерную, для каждого найденного сверхсостояния в нашей архитектуре выполняется изучение нейронной сети N(S), описывающей временную эволюцию GS для этого сверхсостояния. По- этому уравнение (13.13) можно заменить следующим выражением: X˜t = g(X˜t–1, S˜t–1) + wt = NS˜t(X˜t–1) + wt, (13.15) где wt – ошибка после сходимости сети, которая может быть аппроксимиро- вана гауссовым шумом. На рис. 13.3 в обобщенном виде изображена предлагаемая GDBN. Красным показаны внутрикадровые соединения, связанные с соответствующим им элементом: P(Z˜t–1|X˜t–1) – модель наблюдения, соответствующая матрице H в малоразмерном случае и декодеру Pϕ(Z˜|X˜) VAE в многомерном случае; связь P(X˜t–1|S˜t–1) коррелирует с кластерной ковариантой ΣS˜t. Зеленым цветом по- казаны межкадровые соединения: прогнозная модель P(X˜t|X˜t–1) выбирается через локальное движение US˜t в маломерном случае и через NSt в многомер- ном; P (S˜t|S˜t–1) кодируется матрицей перехода Π . илиилиДискретный уровень Непрерывный уровень Уровень наблюдения Рис. 13.3  Предлагаемая обобщенная динамическая байесовская сеть 13.3.3. Алгоритм логического вывода в реальном времени Марковский скачкообразный фильтр частиц (MJPF), впервые представленный в работе (Baydoun et al., 2018), здесь используется в процессе реального вре- мени для выполнения выводов на разных иерархических уровнях, начиная с изученной модели GDBN. Алгоритм MJPF реализует коммутирующую модель (switching model), которая использует комбинацию фильтра частиц (PF) для прогнозирования дискретных сверхсостояний и банка фильтров Калмана (KF) для прогнозирования и оценки непрерывных состояний. В случае GS, из- влеченных из многомерных данных, в которых мы применяем нелинейную\n--- Страница 586 ---\nАрхитектура вычисления аномалии в самосознательных системах  585 модель для прогнозирования состояния, вместо этого можно использовать сигма-точечный банк фильтров Калмана (unscented Kalman filters, UKF) (Wan, van der Merwe, 2000), как это сделано в (Slavic et al., 2020). Такая коммутация между динамическими переходами на дискретных/непрерывных уровнях и наблюдениями позволяет обновлять доверие в скрытых переменных, пере- давая локальные сообщения в режимах одновременного вывода, а именно прогнозирующего или причинно-следственного вывода (сверху вниз) и диаг - ностического вывода (снизу вверх). Временные прогностические сообщения π(S˜t), π(X˜t) (рис. 13.3) зависят от динамических правил, хранящихся в моде- ли, в то время как иерархические внутрисрезовые нисходящие сообщения от S˜t к X˜t зависят от статистики кластеризации, включая средние значения и ковариационные матрицы. Причинность «снизу вверх» основана на мо- делях правдоподобия, состоящих из сообщений λ(S˜t), λ(X˜t) (рис. 13.3), пере- даваемых в качестве обратной связи для корректировки ожиданий с учетом последовательности наблюдений. В основе фильтра частиц лежит матрица перехода, закодированная в динамической модели как прогнозное распре- деление для предсказания будущих сверхсостояний (S ˜tn). Первоначально он берет N выборок из этого распределения, которые имеют одинаковый вес и связаны с конкретным сверхсостоянием, таким образом, что 〈S˜tn, Wn〉 ~ 〈π(S˜tn), 1/N〉. (13.16) Затем для каждой частицы (.n) применяется фильтр Калмана для предска- зания непрерывных переменных X˜t, которые зависят от ожидаемого сверх - состояния, как указано в уравнении (13.13), и могут быть выражены через условную вероятность P(X˜t|X˜t–1, S˜tn). Апостериорная вероятность, связанная с прогнозируемым состоянием, определяется как (13.17) Соответственно, как только обнаруживается новое свидетельство Z˜t, MJPF может использовать сообщение, распространяющееся в обратном направле - нии от нижнего уровня к более высоким уровням, для оценки апостериорной вероятности P (X˜t, S˜tn|Zt) следующим образом: P(X˜t, S˜t|Z˜t) = π(X˜t)λ(X˜t). (13.18) Следовательно, веса соответствующей частицы могут быть обновлены в соответствии с выражением Wtn = Wtnλ(S˜t), (13.19) а затем нормализованы в соответствии с методом последовательной повтор- ной выборки коэффициентов (sequential importance resampling, SIR). В урав- нении (13.19) λ(S˜t) – диагностическое сообщение, распространяемое снизу вверх по иерархии для обновления показателя доверия в скрытых пере- менных на этом уровне, которое может быть получено следующим образом:\n--- Страница 587 ---\n586  Вероятностные методы обнаружения аномалий в данных временных рядов λ(S˜t) = λ(X˜t)P(X˜t, S˜t) = P(Z˜t|X˜t)P(X˜t|S˜t), (13.20) где P(X˜t|S˜t) ~ 𝒩(μS˜k, ΣS˜k) обозначает гауссово распределение со средним зна- чением μS˜k и ковариацией ΣS˜k. В свою очередь, λ(X˜t) ~ 𝒩(μZ˜t, R) обозначает гауссово распределение со средним μZ˜t и ковариацией R. Произведение λ(X˜t) и P(X˜t|S˜t) можно найти с по мощью расстояния Бхаттачарии (D B) следующим образом: (13.21) где S˜k Î S˜. Вектор Dλ, содержащий все значения DB между λ(X˜t) и всеми сверх - состояниями в множестве S ˜, здесь вычисляется как (13.22) Следовательно, вектор λ (S˜t) с точки зрения вероятности равен (13.23) В классической байесовской фильтрации для нахождения совместного апостериорного распределения на разных иерархических уровнях исполь- зуются прогностические и диагностические причинные связи. Однако в этом процессе отсутствует необходимый шаг для оценки различий между дву - мя сообщениями, поступающими в данный узел, на основе вероятностной метрики, которая оценивает неожиданность, вызванную наблюдениями, не объяснимыми с точки зрения модели. В следующем разделе показано, как обеспечить самосознающему агенту возможность обнаруживать мультимо- дальные аномалии, которые являются основой для постоянного обновления знаний о воспринимаемой среде и кодирования новых концепций, связан- ных с возникающим аномальным поведением. 13.3.4. Измерения мультимодальных аномалий В предлагаемом подходе классический байесовский вывод (т. е. MJPF) до- полнен расширенными функциями, которые используют вероятностное рас - стояние между нисходящими и восходящими сообщениями, поступающими в общий узел на разных уровнях внутри GDBN, для определения иерархиче- ских измерений аномалий. Такие вероятностные расстояния количествен- но определяют сходство между двумя распределениями вероятностей π(𝒳) и λ(𝒳) в области 𝒳, которые могут быть непрерывными или дискретными. К наиболее важным вероятностным расстояниям относятся следующие: расстояние Бхаттачария ( DB) (Bhattacharyya, 1946): это расстояние было предложено для отражения степени несходства между двумя рас - пределениями вероятностей. Оно основано на коэффициенте Бхатта- чария ℬ𝒞, который аппроксимирует степень перекрытия между двумя\n--- Страница 588 ---\nАрхитектура вычисления аномалии в самосознательных системах  587 распределениями. В случае дискретных вероятностных распределений ℬ𝒞 определяется следующим образом: (13.24) а в случае непрерывных распределений: (13.25) Таким образом, расстояние Бхаттачария DB определяется через ℬ𝒞 сле - дующим образом: DB = –ln[ℬ𝒞( π(𝒳), λ(𝒳))]. (13.26) В любом случае (дискретное и непрерывное распределения) 0 £ ℬ𝒞 £ 1 и 0 £ DB £ ∞; расстояние Хеллингера ( DH) (Beran, 1977): это расстояние также свя- зано с коэффициентом Бхаттачария ℬ𝒞, может быть найдено как (13.27) и удовлетворяет следующему свойству: 0 £ DH £ ∞; дивергенция Кульбака–Лейблера ( DKL) (Kullback, Leibler, 1951): DKL – это способ измерения совпадения между двумя распределениями ве- роятностей. Если два распределения полностью совпадают, то DKL = 0, в противном случае оно находится в диапазоне от 0 до ∞. DKL между двумя дискретными распределениями вероятностей можно найти сле - дующим образом: (13.28) в то время как для непрерывных распределений оно определяется ра- венством (13.29) дивергенция Брегмана ( BD) (Bregman, 1967): BD измеряет расстояние между двумя распределениями, определенными в терминах строго выпуклой функции (φ ). BD = ϕ(π(𝒳)) – ϕ(λ(𝒳)) – Ñϕ(λ(𝒳))(λ(𝒳) – π(𝒳)), (13.30) где Ñϕ(λ(𝒳)) – градиент ϕ при λ (𝒳) и B D ³ 0. Далее мы используем некоторые из вышеупомянутых вероятностных рас - стояний в качестве примеров, чтобы связать показатели аномалий с различ- ными уровнями GDBN.\n--- Страница 589 ---\n588  Вероятностные методы обнаружения аномалий в данных временных рядов 13.3.4.1. Дискретный уровень Индикатор аномалии на дискретном уровне определяется как расстояние между прогностическим π(S˜t) и диагностическим λ(S˜t) сообщениями, посту - пающими в узел S˜t. Такое различие обеспечивает сигнал осведомленности (сознания), указывающий на то, как реальные сенсорные сигналы, полу - ченные из окружающей среды, соотносятся с правилами, закодированными в обобщенной модели. В качестве примера для измерения сходства между двумя дискретными распределениями вероятностей (π (S˜t) и λ(S˜t)) мы ис - пользуем симметричную дивергенцию Кульбака–Лейблера. Аномалия рас - хождения Кульбака–Лейблера (KLDA) согласно определению в (Krayani et al., 2020) имеет следующий вид: KLDA = DKL(π(S˜t) || λ (S˜t)) + DKL(λ(S˜t) || π (S˜t)). (13.31) В каждый момент времени t извлекается гистограмма предсказанных час - тиц, и вероятность появления каждой частицы рассчитывается как: (13.32) где y(.) – частота появления определенного сверхсостояния i, а N – общее ко- личество частиц, проходящих через PF. Стоит отметить, что λ(S˜t) уникально для всех частиц в момент времени t. Определим 𝕊 как множество выигрыш- ных частиц, вероятность появления которых больше нуля, такое что: 𝕊 = {i|p(S˜t = i) i Î S. (13.33) DKL вычисляется между λ(St) и конкретными строками матрицы перехода, относящимися к частицам-победителям в 𝕊. Следовательно, (13.31) прини- мает вид: (13.34) 13.3.4.2. Непрерывный уровень На этом уровне мы сосредоточимся на сообщениях, поступающих в узел X˜t, и рассчитаем соответствующие измерения аномалий, определенные как ста- тистические показатели на основе вероятностного расстояния (например, DB, DH, DKL и т. д.). Сообщение P(X˜t|S˜t), направляемое на промежуточный уровень, описывает вероятность наличия предсказания X˜t в определенном сверхсостоянии. Таким образом, вычисление разницы между прогнозирую- щим сообщением π(X˜t) и P(X˜t|S˜t) позволяет оценить, совпадают ли прогнозы, выполненные на дискретном уровне, с прогнозами, сделанными на непре- рывном уровне. Например, такую разницу можно получить через расстояние DB следующим образом: (13.35)\n--- Страница 590 ---\nАрхитектура вычисления аномалии в самосознательных системах  589 С другой стороны, знание того, насколько реальные наблюдения под- тверждают прогнозы, выполняемые на непрерывном уровне, приводит к об- наружению любого аномального поведения, происходящего в окружающей среде. Вторая аномалия на непрерывном уровне может быть рассчитана как разница между наблюдениями λ(X˜t) и прогнозируемыми обобщенными со- стояниями π(X˜t), которая также основана на вероятностных расстояниях, определенных ранее (например, DB, DH, DKL и т. д.). Например, используя расстояние D B, вторую аномалию на непрерывном уровне можно найти как (13.36) 13.3.4.3. Уровень наблюдения Аномалия на этом уровне особенно информативна в случае многомерных данных. В целом можно выделить два типа аномалий на уровне наблюдения: 1) прямая ошибка реконструкции из-за изучения модели наблюдения, кото- рая не подходит для наблюдаемых данных. Это, например, случай аномалий из-за незнакомого контента и элементов, появляющихся в сцене. Такие ано- малии приводят к большому расхождению между наблюдаемым изображе- нием Xt и его реконструкцией Xˆt через сеть VAE; 2) расстояние между наблю- дением Xt в момент t и прогнозным сообщением π(X˜t), распространяемым вперед от непрерывного уровня к узлу Zt. На практике его можно получить путем расчета среднеквадратической ошибки (MSE) между прогнозируемым изображением Zˆt–1 в момент времени t – 1 и наблюдаемым изображением Xt в момент времени t . 13.3.5. Использование обобщенных ошибок для непрерывного обучения В предыдущих разделах вы видели, как предложенный подход позволяет дополнить архитектуру GDBN и использовать ее концепцию передачи со- общений для расчета аномалий и обобщенных ошибок (GE). Индикаторы аномалий позволяют агенту понять, подходят ли используе- мые им модели для предсказания эволюции мира и его собственного со- стояния в ситуации, которую он ощущает и переживает. Как показано на рис. 13.2, на графике «непрерывное обуче ние», при обнаружении высоких аномалий агент получает предупреждение о том, что ему следует изучить новую модель. Следовательно, он хранит соответствующие GE. С другой стороны, назначением GE является определение того, какие дей- ствия фильтр должен выполнить, чтобы скорректировать сделанные им прог - нозы. Новая модель, извлеченная из GE, минимизирует ошибки на том же типе последовательности, на котором они были найдены. Процесс кластеризации выполняется заново, и новая модель вставляется в словарь изученных моделей. Подводя итог, можно сказать, что аномалии указывают на необходимость создания новой модели, а обобщенные ошибки инструктируют агента о том, как следует создавать новую модель.\n--- Страница 591 ---\n590  Вероятностные методы обнаружения аномалий в данных временных рядов Следует отметить, что в многомерном случае присутствуют некоторые ограничения непрерывного обуче ния через GE. Могут быть обнаружены но- вые наблюдения (например, новые объекты, появившиеся на сцене, новые типы окружающей среды и т. д.). В этом случае необходимо обучить новую модель VAE. В подобной ситуации тестирование требует параллельного ис - пользования нескольких VAE (и, следовательно, нескольких моделей наблю- дения). 13.4. пример : обнаружение анома Лий В муЛьтисенсорны Х данны Х от аВтомоби Ля с самосознанием 13.4.1. Описание условий эксперимента В качестве примера, на котором можно протестировать архитектуру, описан- ную в разделе 13.3, выполняется обнаружение аномалий мультисенсорных данных, получаемых от движущегося автомобиля. Транспортное средство под названием iCab (Marın-Plaza et al., 2016), показанное на рис. 13.4а, управ- ляется человеком при выполнении различных задач в закрытой среде, по- казанной на рис. 13.4b. Автомобиль служит источником различных данных (например, видео с бортовой передней камеры, данные одометрии, сигна- лы рулевого управления и т. д.). Мы решили подробно рассмотреть данные одометрии и видеоданные и предоставить дополнительные примеры, ка- сающиеся управляющих данных (угол поворота руля, скорость вращения рулевого вала, мощность). Поскольку одометрические наблюдения имеют размерность d = 2, они представляют собой пример сенсорных данных ма- лой размерности. С другой стороны, данные изображения имеют начальную размерность d = 640×480 и послужат учебным примером обработки данных высокой размерности. Напомним, что оба этих типа сенсоров мы определили во введении к главе как экстероцептивные сенсоры. Внутренние сенсорыСтереокамера (а) автомобиль iCab (b) Окружение Рис. 13.4  Используемый в эксперименте автомобиль и окружающая среда\n--- Страница 592 ---\nПример: обнаружение аномалий в мультисенсорных данных от автомобиля  591 Для проведения обуче ния на исходной модели, как показано на рис. 13.2, мы берем данные из случая, когда транспортное средство перемещается по окружающей среде без влияния внешних агентов, т. е. осуществляет следо- вание по периметру (PM) двора. Предусмотрены две другие задачи, в кото- рых транспортному средству в его первоначальном мониторинге периметра мешает присутствие пешеходов. Следовательно, поскольку водитель должен выполнять новые движения, чтобы избежать наезда на пешеходов, в потоке данных должны быть обнаружены аномалии относительно исходной модели. Эти две аномальные задачи различаются в зависимости от того, где находит - ся пешеход, и, как следствие, от того, как водитель их избегает: в одном слу - чае (рис. 13.5e) пешехода, находящегося в середине дорожки, избегают путем объезда сбоку (PA); в другом случае (рис. 13.5f), поскольку пешеход находится в углу траектории, его можно избежать за счет U-образного разворота. На рис. 13.5 изображены упомянутые задачи, включая положения, которые транспортное средство занимает с течением времени (рис.13.5а, 13.5c, 13.5e слева), и примеры кадров с фронтальной камеры автомобиля (рис.13.5b, 13.5d, 13.5f справа). (а) позиция на периметре (c) позиция при объезде (e) позиция при развороте(b) задача следования по периметру, вид с передней камеры (d) задача избегания пешехода, вид с передней камеры (f) задача разворота, вид с передней камеры Рис. 13.5  Тестовые задачи, выполняемые самосознающим транспортным средством. Слева: данные одометра транспортного средства изображены синим цветом, а красные точки показывают, где находится пешеход. Справа: несколько изображений с передней камеры автомобиля при выполнении трех задач 13.4.2. Обучение модели DBN В качестве первого шага в рассматриваемой архитектуре необходимо обучить начальную модель. В случае данных одометрии модель наблюдения извест -\n--- Страница 593 ---\n592  Вероятностные методы обнаружения аномалий в данных временных рядов на и задается матрицей H, определенной, как показано в разделе 13.3.2. Компоненты модели, которые необходимо изучить: 1) дискретные сверхсо- стояния, найденные с по мощью алгоритма кластеризации, такого как GNG (Fritzke, 1994), с их статистическими свойствами (т. е. среднее значение μSk, ковариационная матрица ΣSk); 2) матрица перехода Π, описывающая связи между сверхсостояниями. В случае видеоданных необходимо также изучить параметры кодеров и декодеров VAE, что приводит к вычислению модели наблюдения DBN. Кроме того, во втором случае необходимо также обучить нейронные сети, формирующие модель прогнозирования внутри каждого кластера. На этом этапе изучается модель нормальности. В нашем исследовании для получения этой исходной модели использованы данные следования по периметру (PM). На рис. 13.6 показаны результаты кластеризации по данным одометрии (13.6а) и видео (13.6b). В случае одометрии средние значения μSk для каждого кластера можно визуально распознать как среднее значение данных о по- ложении кластеров (показаны голубыми точками) и средние значения клас - теризованных данных скорости (показаны синими стрелками). Кроме того, пунктирные кружки пропорциональны стандартному отклонению положе- ний кластеров, которое можно извлечь из диагонали ΣSk. Обратите внима- ние, что для лучшей наглядности окружность была аппроксимирована через максимальное значение в двух направлениях. В свою очередь, на рис. 13.6а представлена кластеризация данных с видеокамеры. Так как противопо - ложные стороны двора имеют схожий внешний вид и выполняются одни и те же движения, то присутствует симметрия. Теневой области назначается уникальный отдельный кластер (кластер 1). (а) Кластеризация одометрии (b) Кластеризация видеопотокаКластер 1 Кластер 2 Кластер 3 Кластер 4 Кластер 5 Кластер 6 Рис. 13.6  Одометрия и кластеризация видео 13.4.3. Многоуровневое обнаружение аномалий После того как все параметры исходной модели изучены, ее можно использо- вать для вывода, когда имеются данные двух других задач. Аномалии пред- ставляют собой расхождения между прогнозами, выполненными с по мощью\n--- Страница 594 ---\nПример: обнаружение аномалий в мультисенсорных данных от автомобиля  593 модели на основе задачи следования по периметру, и наблюдениями из дан- ных, полученных во время задач объезда пешехода и U-образного разворота. 13.4.3.1. Задача объезда пешеходов На рис. 13.7 и 13.8 показаны аномалии, обнаруженные при фильтрации дан- ных одометрии и видеопотока описанной выше структурой. В первом случае отображаются только аномалии на непрерывном и дискретном уровнях, а во втором также отображаются аномалии на уровне наблюдения. Зеленые обла - сти относятся к зонам прямолинейного движения, желтые области – к зонам криволинейного движения, а синие области – к зонам, отображающим не- нормальные действия (например, маневр уклонения от пешеходов). На рис. 13.7 изображены три графика. Черный график отображает среднее значение обобщенной ошибки, которое мы обозначили за ϵ˜t. Красный гра- фик показывает аномалию Db2 (уравнение (13.35)). Бросается в глаза сход- ство между этими двумя графиками, поскольку они оба представляют собой сравнение между π(Xk) и λ(Xk). Оба графика отображают высокие значения аномалии, соответствующие объезду пешеходов, и ложные срабатывания из-за небольших отклонений во время движения. Однако следует отметить, что Db1 дает лучшие результаты, поскольку учитывает полную информацию о вероятности π(Xk) и λ(Xk), в то время как ϵ˜t отбрасывает информацию о ко- вариации Σ Sk и сохраняет только среднее значение μ Sk. Полная ошибка состояния KLDADb1 Db2 Аномалии непрерывного уровня Аномалии дискретного уровняОбъекты времени (k) Объекты времени (k)Аномалии Аномалии Рис. 13.7  Значения многоуровневой аномалии одометрии в задаче объезда пешеходов Наконец, синий график на рис. 13.7 относится к аномалии Db1 (уравнение (13.36)). Эта аномалия становится особенно актуальной в центре аномаль- ного движения. Например, мы можем наблюдать, что примерно во время t = 600 частицы неравномерно распределяются по кластерам относительно кривой в правом верхнем углу рис. 13.6а из-за неоднородности движения в этой области.\n--- Страница 595 ---\n594  Вероятностные методы обнаружения аномалий в данных временных рядов Второй график на рис. 13.7 относится к аномалии KLDA, описанной уравне- нием (13.34). Зоны избегания пешеходов явно демонстрируют очень высокое значение аномалии, являющееся следствием необычных проходов между кластерами. На рис. 13.8 показаны те же типы аномалий в случае с видеоданными. Кроме того, на первом графике показаны аномалии на уровне наблюдения. Черные и синие линии отражают прямые аномалии восстановления VAE, сиг - нализируя о неподходящей модели наблюдения. Красные и зеленые линии аномалий – это ошибки на уровне изображения из-за несоответствия между наблюдением и прогнозом. Ошибка состоянияОшибка распозн. изображ. Ошибка предсказания изобр. Ошибка предсказания опт. потока Ошибка распозн. опт. потока KLDADb1 Db2Аномалии на непрерывном уровне Аномалии на дискретном уровне Аномалии на уровне обобщенного наблюденияОбъекты времени (k) Объекты времени (k) Объекты времени (k)Аномалии Аномалии Аномалии Рис. 13.8  Значения многоуровневой аномалии видео в задаче объезда пешеходов 13.4.3.2. Задача разворота На рис. 13.9 и рис. 13.10 показаны аномалии одометрии и видео в задаче U-образного разворота. В этом случае синяя область показывает зону, в ко- торой выполняется разворот. В области между этими двумя зонами автомо- биль движется аналогично тому, как он двигался при обучении модели, но в противоположном направлении. Отсюда следует вывод, что: 1) аномалии ϵ˜t и Db2 в случае одометрии (рис. 13.9) имеют высокие значения только в слу - чае аномального разворота и движения в противоположном направлении; 2) аномалия Db1 и KLDA показывают высокое значение на всем протяже- нии разворота и при движении автомобиля в направлении, противополож - ном направлению обуче ния. В обоих случаях это происходит из-за того, что\n--- Страница 596 ---\nПример: обнаружение аномалий в мультисенсорных данных от автомобиля  595 час тицы относятся к кластерам на другой стороне полигона, что приводит к большому расхождению между значениями кластера и прогнозами для CLA и аномальным переходам для KLDA; 3) в случае с видео (рис. 13.10) высокие аномалии появляются только в связи с движением разворота и движением по кривым в направлении, противоположном начальному направлению. Полная ошибка состояния KLDADb1 Db2 Аномалии на непрерывном уровне Аномалии на дискретном уровнеОбъекты времени (k) Объекты времени (k)Аномалии Аномалии Рис. 13.9  Значения многоуровневых аномалий одометрии в задаче избегания пешеходов с по мощью разворота Ошибка состоянияОшибка распозн. изображ. Ошибка предсказания изобр. Ошибка предсказания опт. потока Ошибка распозн. опт. потока KLDADb1 Db2Аномалии на непрерывном уровне Аномалии на дискретном уровне Аномалии на уровне обобщенного наблюденияОбъекты времени (k) Объекты времени (k) Объекты времени (k)Аномалии Аномалии Аномалии Рис. 13.10  Значения многоуровневой аномалии видео в задаче избегания пешеходов с по мощью разворота\n--- Страница 597 ---\n596  Вероятностные методы обнаружения аномалий в данных временных рядов 13.4.3.3. Аномалии на уровне изображения На рис. 13.11 показаны примеры поведения модели на уровне изображе- ния. В двух первых и двух последних столбцах показаны фактические кад- ры и данные оптического потока в последовательные моменты времени; в треть ем и четвертом столбцах показаны результаты прямого восстановле- ния через VAE; в пятом и шестом столбцах показано восстановление пред- сказанного изображения. ℛ{X.ˆ t} Zt Z. t ℛ{Xˆt} ℛ{X. t–1} ℛ{X t–1} Z. t–1 Zt–1 Рис. 13.11  Примеры аномалий на уровне изображения. С помощью записи ℛ{X} кратко обозначено декодирование скрытой переменной X через декодер VAE На рис. 13.11 показаны три примера. 1. В первой строке приводится при- мер нормального прямолинейного движения, взятого из набора данных уклонения от пешехода. 2. Во второй строке мы отображаем момент времени до начала маневра уклонения. Присутствие пешехода вызывает аномалию, строго связанную с моделью наблюдения. Новый VAE должен быть обучен понятию «пешеход». 3. В третьем ряду у нас есть аномалия из-за движения по кривой в противоположном направлении по отношению к направлению при обучении на наборе данных разворота. Нужно заметить, что, несмотря на то что восстановление не является оптимальным, оно является разумным. С другой стороны, прогнозная модель может фиксировать аномалию более очевидным образом. Это связано с тем, что при наблюдении за частью двора, относящейся к траектории, мы могли бы ожидать, что будем двигаться влево (см. красный цвет прогнозируемого оптического потока ), но вместо этого мы выполняем поворот вправо. 13.4.3.4. Оценка обнаружения аномалий Чтобы оценить метод обнаружения аномалий, значение аномалии, получен- ное на разных уровнях абстракции, сравнивается с эталонным (ground truth, GT). Эталоны сценариев уклонения от пешехода и U-образного разворота строятся вручную с учетом движения автомобиля по данным одометрии.\n--- Страница 598 ---\nПример: обнаружение аномалий в мультисенсорных данных от автомобиля  597 В случае одометрии U-образного разворота вся последовательность от нача- ла первого разворота до конца второго считается аномальной, так как транс - портное средство движется в противоположном направлении относительно изученного. В видеоданных 10 кадров до начала аномального маневра добав- ляются к положительному эталону, чтобы отметить присутствие пешехода; кроме того, для учета аномальных теневых зон используется простой метод обнаружения теней. На рис. 13.12 и 13.13 показаны кривые рабочих характеристик приемника (receiver operating characteristic, ROC) для результатов обнаружения анома- лий в одометрии и видеопотоке соответственно. Кривая ROC отображает значения частоты истинных положительных результатов (TPR) и частоты ложных срабатываний (FPR) при различных пороговых значениях аномалии, где и В нашем случае TPR и FPR представляют собой процент случаев, в которых аномалии были правильно и неправильно идентифицированы соответственно. Показатель AUC (area under the curve, площадь под кривой) можно использовать для измерения точности метода. Еще одним показателем является сходимость (accuracy, ACC), определяемая суммой истинно положительных результатов (TP) и истинно отрицательных результатов (TN). В области инкрементных систем с самосознанием мо- гут использоваться дополнительные методы оценки, например насколько хороши аномалии для извлечения ошибок, позволяющих строить лучшие модели. На рис. 13.12 два непрерывных значения аномалии (т. е. Db1 и Db2) нор- мализованы и суммированы для получения единого значения аномалии, демонстрирующего гораздо более высокую точность, чем два его отдельных компонента. Доля истинно положительных прогнозов (TPR) Доля истинно положительных прогнозов (TPR) Доля ложноположительных прогнозов (FPR) Доля ложноположительных прогнозов (FPR)ROC­кривые для данных одометрии при объезде пешеходаROC­кривые для данных одометрии при U­образном развороте Ошибка состояния AUC: 0.67, ACC: 0.81 Db1 AUC: 0.81, ACC: 0.88 Db2 AUC: 0.82, ACC: 0.84 Непрерывность в общем (Db1+Db2) AUC: 0.92, ACC: 0.89 KLDA AUC: 0.81, ACC: 0.87Ошибка состояния AUC: 0.77, ACC: 0.71 Db1 AUC: 0.94, ACC: 0.93 Db2 AUC: 0.74, ACC: 0.7 Непрерывность в общем (Db1+Db2) AUC: 0.98, ACC: 0.95 KLDA AUC: 0.92, ACC: 0.87 Рис. 13.12  ROC-кривые для данных одометрии\n--- Страница 599 ---\n598  Вероятностные методы обнаружения аномалий в данных временных рядов Доля истинно положительных прогнозов (TPR) Доля истинно положительных прогнозов (TPR) Доля ложноположительных прогнозов (FPR) Доля ложноположительных прогнозов (FPR)ROC­кривые для видеоданных при объезде пешеходаROC­кривые для видеоданных при U­образном развороте Ошибки распозн. изобр. AUC: 0.81, ACC: 0.8 Ошибки распозн. опт. потока AUC: 0.66, ACC: 0.79 Ошибки предсказ. изобр. AUC: 0.86, ACC: 0.84 Ошибки предсказ/ опт. потока AUC: 0.7, ACC: 0.78 Ошибки состояния AUC: 0.82, ACC: 0.85 Db1 AUC: 0.77, ACC: 0.83 Db2 AUC: 0.82, ACC: 0.84 KLDA AUC: 0.85, ACC: 0.82Ошибки распозн. изобр. AUC: 0.94, ACC: 0.89 Ошибки распозн. опт. потока AUC: 0.89, ACC: 0.83 Ошибки предсказ. изобр. AUC: 0.87, ACC: 0.83 Ошибки предсказ/ опт. потока AUC: 0.83, ACC: 0.79 Ошибки состояния AUC: 0.84, ACC: 0.81 Db1 AUC: 0.79, ACC: 0.76 Db2 AUC: 0.84, ACC: 0.81 KLDA AUC: 0.83, ACC: 0.82 Рис. 13.13  ROC-кривые для видеоданных 13.4.4. Аномалии проприоцептивных сенсорных данных Подробные описания примеров обуче ния и тестирования с использованием одометрии и видеоданных были представлены в предыдущих разделах. Все они были основаны на данных, поступающих с экстероцептивных сенсоров транспортного средства. Помимо экстероцептивных сенсоров, в архитектуре самосознания следует учитывать и проприоцептивные датчики транспорт - ного средства. К ним относятся, например, угол поворота рулевого колеса (S), скорость вращения рулевого вала (V) и мощность (P). На рис. 13.14 и 13.15 показаны результаты обнаружения аномалии Db2 для случая уклонения от пешеходов и разворота соответственно. Три конт - рольных признака, т. е. S, V и P , можно по-разному комбинировать для фор- мирования рассматриваемых сенсорных данных, на основе которых стро- ится модель GDBN. На рис. 13.14 представлены результаты использования комбинаций SP (угол поворота и мощность) и SV (угол поворота и скорость вращения вала) в задаче уклонения от пешеходов; на рис. 13.14 показаны комбинации SP , SV и VP (скорость вращения вала и мощность) на задаче раз- ворота. В обоих случаях зеленые области соответствуют нормальным зонам, а синие – аномальным, т. е. объезду пешеходов в первом случае и развороту во втором. Результаты, относящиеся к управляющим данным1, можно найти в (Kanapram et al., 2019). 1 Эти данные называются управляющими, потому что свидетельствуют о работе органов управления (угол и скорость поворота руля, а также нажатия на педаль газа, от которого зависит мощность двигателя). Очевидно, что действия водителя, выраженные в управляющих данных, прямо зависят от аномалий окружающей среды. – Прим. перев.\n--- Страница 600 ---\nПример: обнаружение аномалий в мультисенсорных данных от автомобиля  599 Db2 Db2Аномалия Db2 для признаков SP в случае объезда пешехода Аномалия Db2 для признаков SV в случае объезда пешеходаОбъекты времени (k) Объекты времени (k)Аномалии Аномалии Рис. 13.14  Аномалия управляющих данных (SP, SV) на непрерывном уровне для случая уклонения от пешеходов Db2 Db2 Db2Аномалия Db2 для признаков SP в случае объезда пешехода Аномалия Db2 для признаков SP в случае разворота Аномалия Db2 для признаков SV в случае разворотаОбъекты времени (k) Объекты времени (k) Объекты времени (k)Аномалии Аномалии Аномалии Рис. 13.15  Аномалия контрольных данных (SP, SV, VP) на непрерывном уровне для случая разворота 13.4.5. Дополнительные результаты В упомянутом выше примере рассматривались аномалии, которые возни- кают при движении полуавтономного транспортного средства, вырабаты-\n--- Страница 601 ---\n600  Вероятностные методы обнаружения аномалий в данных временных рядов вающего малоразмерные, многомерные, проприоцептивные и экстероцеп- тивные данные. Мы говорили о системе с одним агентом (транспортным средством), но можно было обрабатывать и системы с несколькими агента- ми, а взаимодействие между ними моделировать на более высоком уровне, как это сделано в недавнем исследовании (Kanapram et al., 2020). Важно отметить, что описанный метод можно применять и к данным из других областей, например к радиооборудованию с самосознанием. Резуль- таты в этом направлении можно изучить в работе (Krayani et al., 2020). Во всех упомянутых работах рассматривались аномалии максимум на трех уровнях. Однако могут быть определены более высокие уровни абстракции и, следовательно, более высокие уровни аномалий. Одним из примеров явля- ется работа (Zaal et al., 2019): для каждой задачи получен граф, соединяющий соседние кластеры; там, где на графе обнаруживается высокая аномалия, возникает новый концепт1. 13.5. В ыВоды В этой главе мы представили архитектуру самосознающей системы обнаруже- ния аномалий в данных временных рядов. В рамках самосознания агент, ра- ботающий с мультимедийными данными, включая данные высокой и низкой размерностей, способен обнаруживать аномалии на иерархических уровнях, что считается важным шагом непрерывного обуче ния новой динамической модели, которая кодирует возникающее аномальное поведение. В случае ра- боты с многомерными данными для уменьшения размерности применяется VAE, которая извлекает признаки и включает их в обобщенный вектор со- стояния. В случае малоразмерных данных признаки извлекаются непосред- ственно из наблюдений. Обуче ние динамической модели в форме вероят - ностной графовой модели, структурированной в динамической байесовской сети (DBN), образует мост между данными высокой и низкой размерностей. В главе было показано, как можно использовать сообщения, проходящие внутри DBN, для определения иерархии аномалий на основе вероятностных расстояний. Для практической проверки архитектуры был использован ре- альный набор данных, и результаты показывают, что самосознающий агент способен эффективно обнаруживать мультимодальные аномалии. Литературные исто ЧниКи Aggarwal C. C., 2016. Outlier Analysis, 2nd ed. Springer Publishing Company, Incorporated. Alshazly H., Linse C., Barth E., Martinetz T., 2019. Handcrafted versus cnn features for ear recognition. Symmetry 11, 1493. 1 В робототехнике и ИИ концепт – это элемент представления знаний. В данном случае он требует дополнительного изучения.\n--- Страница 602 ---\nЛитературные источники  601 Antipov G., Berrani S. A., Ruchaud N., Dugelay J. L., 2015. Learned vs. hand-crafted features for pedestrian gender recognition. In: ACM International Conference on Multimedia, pp. 1263–1266. Baydoun M., Campo D., Sanguineti V., Marcenaro L., Cavallaro A., Regazzoni C., 2018. Learning switching models for abnormality detection for autonomous driving. In: 2018 21st International Conference on Information Fusion (FU - SION), pp. 2606–2613. Becker-Ehmck P., Peters J., Smagt P. V. D., 2019. Switching linear dynamics for variational Bayes filtering. In: International Conference on Machine Learning, pp. 553–562. Beran R., 1977. Minimum Hellinger distance estimates for parametric models. The Annals of Statistics 5, 445–463. Bhattacharyya A., 1946. On a measure of divergence between two multinomial populations. Sankhy¯a: The Indian Journal of Statistics (1933–1960) 7, 401– 406. Bregman L., 1967. The relaxation method of finding the common point of convex sets and its application to the solution of problems in convex programming. U.S.S.R. Computational Mathematics and Mathematical Physics 7, 200–217. Bronstein A., Das J., Duro M., Friedrich R., Kleyner G., Mueller M., Singhal S., Co- hen I., 2001. Self-aware services: using Bayesian networks for detecting anoma- lies in Internet-based services. In: 2001 IEEE/IFIP International Symposium on Integrated Network Management Proceedings. Integrated Network Manage - ment VII. Integrated Management Strategies for the New Millennium (Cat. No. 01EX470), pp. 623–638. Campo D., Slavic G., Baydoun M., Marcenaro L., Regazzoni C., 2020. Continual learn- ing of predictive models in video sequences via variational autoencoders. In: IEEE International Conference on Image Processing, pp. 753–757. Chandola V., Banerjee A., Kumar V., 2009. Anomaly detection: a survey. ACM Com- puting Surveys 41, 15:1–15:58. Chong Y. S., Tay Y. H., 2015. Modeling representation of videos for anomaly detec - tion using deep learning: a review. arXiv:1505.00523 [abs]. Dalal N., Triggs B., 2005. Histograms of oriented gradients for human detection. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 886–893. Damasio A. R., 1999. The Feeling of What Happens: Body and Emotion in the Ma- king of Consciousness. Harcourt Brace. Foorthuis R., 2020. On the nature and types of anomalies: a review. arXiv:2007.15634 [abs]. Fox E., Sudderth E. B., Jordan M. I., Willsky A. S., 2011. Bayesian nonparametric inference of switching dynamic linear models. IEEE Transactions on Signal Processing 59, 1569–1585. Fraccaro M., Kamronn S., Paquet U., Winther O., 2017. A disentangled recognition and nonlinear dynamics model for unsupervised learning. In: Conference on Neural Information Processing Systems, pp. 3601–3610. Friston K. J., Sengupta B., Auletta G., 2014. Cognitive dynamics: from attractors to active inference. Proceedings of the IEEE 102, 427–445. Fritzke B., 1994. A growing neural gas network learns topologies. In: Conference on Neural Information Processing Systems, pp. 625–632.\n--- Страница 603 ---\n602  Вероятностные методы обнаружения аномалий в данных временных рядов Goodfellow I. J., Pouget-Abadie J., Mirza M., Xu B., Warde-Farley D., Ozair S., Cour- ville A., Bengio Y., 2014. Generative adversarial nets. In: Conference on Neural Information Processing Systems, pp. 2672–2680. Haykin S., Fuster J. M., 2014. On cognitive dynamic systems: cognitive neurosci- ence and engineering learning from each other. Proceedings of the IEEE 102, 608–628. Johnson M., Duvenaud D., Wiltschko A. B., Adams R., Datta S., 2016. Composing graphical models with neural networks for structured representations and fast inference. In: Conference on Neural Information Processing Systems, pp. 2946– 2954. Kanapram D., Campo D., Baydoun M., Marcenaro L., Bodanese E., Regazzoni C., Mar- chese M., 2019. Dynamic Bayesian approach for decision-making in ego-things. In: 2019 IEEE 5thWorld Forum on Internet of Things (WFIoT), pp. 909–914. Kanapram D., Patrone F., Marín-Plaza P., Marchese M., Bodanese E. L., Marcena- ro L., Gómez D. M., Regazzoni C. S., 2020. Collective awareness for abnormality detection in connected autonomous vehicles. IEEE Internet of Things Journal 7, 3774–3789. Kingma D. P., Welling M., 2014. Auto-encoding variational Bayes. In: International Conference on Learning Representations. Kingma D. P., Welling M. , 2019. An introduction to variational autoencoders. Foun - dations and Trends in Machine Learning 12, 307–392. Kiran B. R., Thomas D., Parakkal R., 2018. An overview of deep learning based methods for unsupervised and semi-supervised anomaly detection in videos. Journal of Imaging 4, 36. Kohonen T., 2001. Self-Organizing Maps. Ser. Physics and Astronomy Online Lib- rary. Springer, Berlin, Heidelberg. Krayani A., Baydoun M., Marcenaro L., Alam A. S., Regazzoni C., 2020. Self-learning Bayesian generative models for jammer detection in cognitive-uav-radios. In: GLOBECOM 2020–2020 IEEE Global Communications Conference, pp. 1–7. Kullback S., Leibler R. A., 1951. On information and sufficiency. The Annals of Mathematical Statistics 22, 79–86. Marın-Plaza P., Beltrán J., Hussein A., Musleh B., Martın D., de la Escalera A., Armin- gol J. M., 2016. Stereo vision-based local occupancy grid map for autonomous navigation in ros. In: International Joint Conference on Computer Vision, Imag- ing and Computer Graphics Theory and Applications, pp. 703–708. Mascaro S., Nicholson A., Korb K., 2014. Anomaly detection in vessel tracks using Bayesian networks. International Journal of Approximate Reasoning 55, 84–98. Mihajlovic V., Petkovic M., 2001. Dynamic Bayesian Networks: a State of the Art. TR-CTIT-34 of CTIT Technical Report Series. University of Twente. Morin A., 2006. Levels of consciousness and self-awareness: a comparison and integration of various neurocognitive views. Consciousness Cognition 15, 358– 371. Nugroho K. A., 2018. A comparison of handcrafted and deep neural network fea- ture extraction for classifying optical coherence tomography (oct) images. In: International Conference on Informatics and Computational Sciences, pp. 1–6. Ramachandra B., Jones M., Vatsavai R. R., 2020. A survey of single-scene video anomaly detection. ArXiv. arXiv: 2004.05993 [abs].\n--- Страница 604 ---\nавторах главы  603 Ravanbakhsh M., Baydoun M., Campo D., Marín P., Martín D., Marcenaro L., Regaz - zoni Carlo, 2020. Learning self-awareness for autonomous vehicles: exploring multisensory incremental models. IEEE Transactions on Intelligent Transpor - tation Systems, 1–15. Regazzoni C. S., Marcenaro L., Campo D., Rinner B., 2020. Multisensorial generative and descriptive self-awareness models for autonomous systems. Proceedings of the IEEE 108, 987–1010. Rivera A. R., Khan A., Bekkouch I. E. I., Sheikh T. S., 2020. Anomaly detection based on zero-shot outlier synthesis and hierarchical feature distillation. IEEE Trans- actions on Neural Networks and Learning Systems, 1–11. Salotti J. M., 2018. Bayesian network for the prediction of situation awareness errors. International Journal of Human Factors Modelling and Simulation 6, 119–126. Slavic G., Baydoun M., Campo D., Marcenaro L., Regazzoni C., 2021. Multilevel anomaly detection through variational autoencoders and Bayesian models for self-aware embodied agents. IEEE Transactions on Multimedia, 1. https://doi. org/10.1109/TMM.2021.3065232. Slavic G., Campo D., Baydoun M., Marín P., Martín D., Marcenaro L., Regazzoni C., 2020. Anomaly detection in video data based on probabilistic latent space mod- els. In: IEEE Conference on Evolving and Adaptive Intelligent Systems, pp. 1–8. Wan E.A., van der Merwe R., 2000. The unscented Kalman filter for nonlinear es- timation. In: IEEE Adaptive Systems for Signal Processing, Communications, and Control Symposium, pp. 153–158. Wang H., Bah M. J., Hammad M., 2019. Progress in outlier detection techniques: a survey. IEEE Access 7, 107964–108000. Watter M., Springenberg J. T., Boedecker J., Riedmiller M., 2015. Embed to control: a locally linear latent dynamics model for control from raw images. In: Confer - ence on Neural Information Processing Systems, pp. 2746–2754. Winn J., Bishop C., 2005. Variational message passing. Journal of Machine Learning Research 6, 661–694. Zaal H., Iqbal H., Campo D., Marcenaro L., Regazzoni C. S., 2019. Incremental learn- ing of abnormalities in autonomous systems. In: 2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS), pp. 1–8. об аВтора Х гЛаВы Карло Регаццони – профессор когнитивных телекоммуникационных систем в DITEN, Университет Генуи, Италия. Он отвечал за несколько национальных и финансируемых ЕС исследовательских проектов. В настоящее время являет - ся координатором международных курсов докторантуры по интерактивным и когнитивным средам с участием нескольких европейских университетов. Был председателем на нескольких конференциях и рецензентом / приглашен- ным редактором в нескольких международных технических журналах. Зани- мал множество должностей в руководящих органах IEEE SPS, а в 2015–2017 гг. был вице-президентом Общества обработки сигналов IEEE.\n--- Страница 605 ---\n604  Вероятностные методы обнаружения аномалий в данных временных рядов Али Краяни получил степень бакалавра в области телекоммуникаций в Ту - ринском политехническом университете в 2014 г. и степень магистра в обла- сти телекоммуникаций в Флорентийском университете в 2017 г. В настоящее время он готовится получить степень доктора философии в рамках Совмест - ной программы докторантуры в области интерактивных и когнитивных сред Университета Генуи и Лондонского университета королевы Марии. Его те- кущие исследовательские интересы включают когнитивное радио, сотовые системы, связь с БПЛА, самосознание, динамические байесовские сети и ис - кусственный интеллект. Джулия Славик получила звание инженера по электронике и информаци- онным технологиям в 2017 г. и магистра интернет- и мультимедийных тех - нологий в 2020 г. в Университете Генуи, Италия. В настоящее время является аспиранткой Университета Генуи. Ее исследовательские интересы включают использование алгоритмов глубокого обуче ния и обработки сигналов для потоковых мультисенсорных данных. Лучио Марченаро имеет более 20 лет опыта в области обработки сигналов и анализа последовательности изображений. Является автором около 160 на- учных работ, связанных с обработкой сигналов для компьютерного зрения и когнитивного радио. Окончил факультет электроники в 1999 г. и получил докторскую степень в области компьютерных наук и электронных техноло- гий в 2003 г. Является адъюнкт-профессором факультета телекоммуникаций Политехнической школы Университета Генуи. Его основные текущие иссле- довательские интересы связаны с обработкой видео для распознавания со- бытий, обнаружением и локализацией объектов в сложных сценах, а также с распределенными гетерогенными сенсорами и когнитивными автоном- ными системами.",
      "debug": {
        "start_page": 570,
        "end_page": 605
      }
    },
    {
      "name": "Глава 14. Методы PnP и глубокой развертки для восстановления изображения 605",
      "content": "--- Страница 606 --- (продолжение)\nГлава 14 Методы PnP и глубокой развертки для восстановления изображения Авторы главы: Кай Чжан и Раду Тимофте, Лаборатория компьютерного зрения, ETH Zürich, Цюрих, Швейцария Краткое содержание главы: обсуждение достоинств и недостатков моделей и методов на основе глу- бокого обуче ния для восстановления изображений; методы plug-and-play (PnP) и развертки на основе глубокого обуче ния могут использовать преимущества как методов, основанных на обучении, так и методов, основанных на моделях; экспериментальные результаты демонстрируют гибкость и эффективность методов PnP и развертки для восстановления изображения. 14.1. В Ведение Задача восстановления изображения (image restoration, IR) давно привлекает пристальное внимание исследователей из-за ее высокой практической зна- чимости в различных приложениях низкоуровневого зрения (Richardson, 1972; Andrews, Hunt, 1977). В этой главе основное внимание уделяется трем репрезентативным и фундаментальным проблемам IR: шумоподавлению (de- noising), удалению размытия (deblurring) и сверхразрешению (superresoution). В общем случае цель IR состоит в том, чтобы восстановить скрытое чистое изображение x из его ухудшенного наблюдения y = (x ⊗ k) ¯s + n, где ⊗ пред-\nГлава 14 Методы PnP и глубокой развертки для восстановления изображения Авторы главы: Кай Чжан и Раду Тимофте, Лаборатория компьютерного зрения, ETH Zürich, Цюрих, Швейцария Краткое содержание главы: обсуждение достоинств и недостатков моделей и методов на основе глу- бокого обуче ния для восстановления изображений; методы plug-and-play (PnP) и развертки на основе глубокого обуче ния могут использовать преимущества как методов, основанных на обучении, так и методов, основанных на моделях; экспериментальные результаты демонстрируют гибкость и эффективность методов PnP и развертки для восстановления изображения. 14.1. В Ведение Задача восстановления изображения (image restoration, IR) давно привлекает пристальное внимание исследователей из-за ее высокой практической зна- чимости в различных приложениях низкоуровневого зрения (Richardson, 1972; Andrews, Hunt, 1977). В этой главе основное внимание уделяется трем репрезентативным и фундаментальным проблемам IR: шумоподавлению (de- noising), удалению размытия (deblurring) и сверхразрешению (superresoution). В общем случае цель IR состоит в том, чтобы восстановить скрытое чистое изображение x из его ухудшенного наблюдения y = (x ⊗ k) ¯s + n, где ⊗ пред-\n--- Страница 607 ---\n606  Методы PnP и глубокой развертки для восстановления изображения ставляет собой двумерную свертку x с ядром размытия k, ¯s обозначает стан- дартную s-кратную понижающую дискретизацию, т. е. сохранение левого верхнего пикселя для каждого отдельного участка размером s×s и отбрасы- вание остальных, а n обычно считается аддитивным белым гауссовым шумом (additive white Gaussian noise, AWGN), определяемым стандартным отклоне- нием (или уровнем шума) σ. Приведенная выше модель ухудшения является общей моделью для сверхразрешения одиночного изображения (single image superresolution, SISR). Однако если масштабный коэффициент s равен 1, она становится моделью деградации изображения (deblurring degradation model) с устранением размытия; дальнейшая фиксация k как дельта-ядра превра- щает ее в модель деградации с шумоподавлением (denoising degradation model). Поскольку IR – это некорректно поставленная обратная задача, для огра- ничения пространства решений необходимо принять априорную оценку, ко - торую также называют регуляризацией (Roth, Black, 2009; Zoran, Weiss, 2011). С байесовской точки зрения решение xˆ может быть получено путем нахож - дения апостериорного максимума (maximum aposteriori, MAP): (14.1) где logp (y|x) представляет собой логарифмическую вероятность наблюдения y, log p(x) – априорное значение чистого изображения x и не зависит от ухуд- шенного изображения y . Более формально (14.1) можно переписать в виде: (14.2) где решение минимизирует энергетическую функцию, состоящую из чле- на данных и члена регуляризации λℛ(x) с параметром регуляризации λ. В частности, член данных гарантирует, что решение соот - ветствует процессу деградации, в то время как член регуляризации смягчает некорректность задачи, навязывая желаемое свойство решению. Как правило, методы решения уравнения (14.2) можно разделить на две основные категории, а именно методы, основанные на моделях, и методы, основанные на обучении. Первые направлены на непосредственное реше- ние уравнения (14.2) с применением алгоритмов оптимизации, в то время как последние в основном изучают предопределенную параметризованную функцию путем оптимизации функции потерь на обучающем наборе, со- держащем N пар ухудшенных/исходных изображений {(y i, xi)}N i=1 (Tappen, 2007; Barbu, 2009; Sun, Tappen, 2013; Schmidt, Roth, 2014; Chen, Pock, 2017). В частности, методы, основанные на обучении, обычно моделируются как следующая задача двухуровневой оптимизации: (14.3a) (14.3б)\n--- Страница 608 ---\nВведение  607 где Θ обозначает обучаемые параметры, ℒ(xˆi, xi) измеряет потерю получен- ного чистого изображения x ˆi по отношению к истинному изображению x i. Основное различие между методами, основанными на модели, и метода- ми, основанными на обучении, заключается в том, что первые проявляют гибкость при решении различных задач IR, просто определяя операции ухуд- шения, и могут напрямую оптимизировать изображение y с ухудшенным ка- чеством, тогда как вторые требуют трудоемкого обуче ния модели перед при - менением и обычно ограничиваются специализированными задачами. Тем не менее методы, основанные на обучении, могут не только обеспечивать высокое быстродействие, но и, как правило, обеспечивают лучшее качество благодаря сквозному обуче нию. В отличие от них, для обеспечения хороше- го качества результата основанные на модели методы обычно нуждаются в больших затратах времени на подбор сложных априорных значений (Gu et al., 2014). Например, методы на основе моделей, такие как NCSR (Dong et al., 2013), гибко решают задачи обработки шумоподавления, суперразрешения и устранения размытия, тогда как методы на основе глубокого обуче ния MLP (Burger et al., 2012), SRCNN (Dong et al., 2016), DCNN (Xu et al., 2014) долж - ны быть настроены только на решение конкретной задачи. И даже в случае конкретной задачи, такой как шумоподавление, методы на основе моделей (например, BM3D (Dabov et al., 2007) и WNNM (Gu et al., 2014)) могут гибко работать с разными уровнями шума, тогда как основанный на обучении ме- тод (Jain, Seung, 2009) отдельно обучает разные модели для каждого уровня. Следовательно, эти две категории методов имеют свои достоинства и недо- статки, и было бы полезно исследовать их интеграцию, чтобы объединить достоинства. Интеграция методов, основанных на моделях и на обучении, привела к созданию метода IR на основе глубокого обуче ния с поддержкой PnP . Он за- меняет подзадачу оптимизации шумоподавляющей модели шумоподавите- лем на основе предварительно обученной CNN. Основная идея глубокого PnP IR заключается в том, что с по мощью алгоритмов переменного разделения, таких как метод переменного направления множителей (alternating direction method of multipliers, ADMM) (Boyd et al., 2011) и полуквадратичное разделение (half-quadratic splitting, HQS) (Geman, Yang, 1995), можно работать с членом данных и априорным членом регуляризации по отдельности (Parikh et al., 2014), когда, в частности, априорный член соответствует только подзадаче шумоподавления (Danielyan et al., 2010; Heide et al., 2014; Venkatakrishnan et al., 2013), которую можно решить с по мощью глубокого шумоподавителя CNN. Следовательно, метод глубокого PnP можно рассматривать как частный случай методов, основанных на моделях. Помимо PnP , интеграцию подходов моделирования и глубокого обуче- ния можно также выполнить с по мощью методов глубокой развертки (deep unfolding). Их основное отличие состоит в том, что последние оптимизиру - ют параметры сквозным путем, минимизируя функцию потерь на большом обучаю щем наборе, и, таким образом, обычно дают лучшие результаты даже при меньшем количестве итераций. Математически метод глубокой разверт - ки можно записать следующим образом:\n--- Страница 609 ---\n608  Методы PnP и глубокой развертки для восстановления изображения Другими словами, метод глубокой развертки направлен на замену предо- пределенной функции из уравнения (14.3б) с разверткой уравнения вывода (14.4б), поэтому его можно рассматривать как частный случай методов, ос - нованных на обучении. Основная идея глубокой развертки применительно к задаче IR состоит в том, чтобы сначала развернуть основанную на моде- ли функцию энергии с по мощью алгоритма полуквадратичного разделения и получить вывод, который итеративно чередуется между решением двух подзадач, одна из которых связана с членом данных, а другая – с априор- ным членом, а затем рассматривать вывод как глубокую нейросеть, заменяя решения двух подзадач нейронными модулями. Поскольку две упомянутые подзадачи соответствуют получению знаний о согласованности деградации и априорных знаний шумоподавителя, метод глубокой развертки основан на явной деградации и априорных ограничениях, что является отличительным преимуществом по сравнению с простыми методами SISR, основанными на обучении. На рис. 14.1 показана иллюстрация связей между методами, основанными на глубоком обучении, методами, основанными на модели, методами глубокого PnP и глубокой развертки. Требуется обучение Быстрый и эффективный Ограниченная гибкость Обучение не требуется Экономия времени Высокая гибкость Явная интерпретацияМетоды IRМетоды глубокой развертки Методы глубокого PnPМетоды на основе обучения Методы на основе моделейПростые методы на основе обучения Традиционные методы на базе моделейКомбинация Рис. 14.1  Иллюстрация связей между методами глубокого обуче ния, моделирования, глубокого PnP и глубокой развертки Остальная часть этой главы организована следующим образом. Поскольку методы глубокого PnP и глубокой развертки тесно связаны с алгоритмами переменного разделения, в разделе 14.2 мы сначала представим один из самых популярных, то есть алгоритм полуквадратичного разделения (half qua- dratic splitting, HQS). Затем в разделе 14.3 представим методы глубокого PnP . В частности, мы предлагаем очень гибкий и эффективный априорный шу -(14.4a) (14.4б)\n--- Страница 610 ---\nАлгоритм полуквадратичного разделения (HQS)  609 моподавитель CNN, а затем подключаем его в качестве модуля к алгоритму HQS для решения различных проблем восстановления изображений. В раз- деле 14.4 мы рассмотрим методы восстановления изображения с глубокой разверткой, которые могут решать задачи устранения размытия и суперраз- решения с различными ядрами размытия и коэффициентами масштабиро- вания с по мощью одной модели. В разделе 14.5 приведены количественные и качественные результаты, а также представлен тщательный анализ на- стройки гиперпараметров и промежуточных результатов, чтобы лучше по- нять механизм работы методов глубокого PnP и глубокой развертки. 14.2. аЛгоритм поЛуКВадрати Чного разде Ления (HQS) Хотя существуют различные алгоритмы разделения переменных для реше- ния уравнения (14.2), алгоритм полуквадратичного разделения (HQS) обязан своей популярностью простоте и быстрой сходимости. Поэтому в данной главе мы используем HQS. Как правило, HQS решает уравнение (14.2) введе- нием вспомогательной переменной z, что дает нам следующее приближенно эквивалентное уравнение: (14.5) где μ – параметр штрафа. Такое уравнение можно решить путем итератив- ного решения промежуточных уравнений для x и z Согласно уравнению (14.6), значение μ должно быть достаточно большим, чтобы x и z были приблизительно равны фиксированной точке. Однако это также приведет к медленной сходимости. Следовательно, хорошее эмпири- ческое правило состоит в том, чтобы итеративно увеличивать μ. Для удобства на k -й итерации μ обозначается как μ k. Можно заметить, что член данных и член регуляризации разделены на уравнения (14.6) и (14.7) соответственно. Для решения уравнения (14.6) мож - но использовать быстрое преобразование Фурье (БПФ), если предположить, что свертка выполняется с круговыми граничными условиями. Примеча - тельно, что преобразование выражено в закрытой форме (Zhao et al., 2016): . (14.8)(14.6) (14.7)\n--- Страница 611 ---\n610  Методы PnP и глубокой развертки для восстановления изображения В свою очередь, d определяется как где αk ≜ μkσ2 и где ℱ(·) и ℱ–1(·)обозначают БПФ и обратное БПФ, обозначает комплексное сопряжение ℱ(·); ʘs – оператор обработки отдельных блоков с поэлементным умножением, т. е. применение поэлементного умножения к s×s различных блоков ; ⇓s обозначает понижение разрешения (downs- ampling) отдельных блоков, т. е. усреднение по s×s блокам; ↑s обозначает стандартную s-кратную повышающую дискретизацию, т. е. повышение про- странственного разрешения путем заполнения новых записей нулями. Для частного случая устранения размытия, когда s = 1, уравнение (14.8) можно кратко записать как (14.9) Другими словами, уравнение (14.8) обобщает уравнение (14.9). Для ре- шения уравнения (14.7) полезно знать, что с байесовской точки зрения оно фактически соответствует задаче шумоподавления с уровнем шума βk ≜ (Chan et al., 2017). 14.3. гЛубоКое Восстано ВЛение изображения по методу PNP Восстановление изображения по методу PnP обычно состоит из двух этапов. Первый шаг заключается в разделении члена данных и члена регуляриза- ции целевой функции с по мощью какого-либо алгоритма разделения пере- менных, что приводит к итеративной схеме, состоящей из поочередного решения подзадачи данных и подзадачи априорного распределения. Второй шаг – решить подзадачу априорного распределения с по мощью любых гото- вых шумоподавителей, таких как K-SVD (Elad, Aharon, 2006), нелокального среднего (Buades et al., 2005), BM3D (Dabov et al., 2007). В результате, в от - личие от традиционных методов, основанных на моделях, которые должны содержать явные и созданные вручную априорные значения, IR PnP может неявно определять их с по мощью шумоподавителя. Такое преимущество дает возможность использовать очень глубокий шумоподавитель CNN для повышения качества результата. IR PnP можно проследить до работ (Danielyan et al., 2010; Zoran, Weiss, 2011; Venkatakrishnan et al., 2013). Даниелян и др. (2012) использовали равнове- сие Нэша для реализации метода итеративного устранения размытия BM3D (IDDBM3D). В (Egiazarian, Katkovnik, 2015) аналогичный метод, предвари- тельно оснащенный шумоподавителем CBM3D, был предложен для решения задачи повышения разрешения одиночного изображения (SISR). Благодаря\n--- Страница 612 ---\nГлубокое восстановление изображения по методу PnP  611 итеративному обновлению шага обратной проекции и шага шумоподавле- ния CBM3D метод демонстрирует обнадеживающие перспективы улучшения показателя PSNR1 по сравнению с SRCNN (Dong et al., 2016). В более ранней работе Даниеляна и др. (2010), в задаче устранения размытия изображения для объединения шумоподавителя BM3D, был применен расширенный метод Лагранжа. В работе (Venkatakrishnan et al, 2013) была предложена итераци- онная схема, аналогичная (Danielyan et al., 2012) – первой работе, в которой шумоподавитель рассматривается как PnP . До этого аналогичная идея PnP упоминается в (Zoran, Weiss, 2011), где алгоритм HQS используется для шу - моподавления, устранения размытия и раскрашивания изображения. Хайде и др. (Heide et al., 2014) использовали альтернативу ADMM и HQS, т. е. пер- вично-двойственный алгоритм (Chambolle, Pock, 2011), чтобы отделить член данных от члена регуляризации. Теодоро и др. (Teodoro et al., 2016) добавили класс-ориентированный шумоподавитель модели гауссовой смеси (GMM) (Zoran, Weiss, 2011) в ADMM для устранения размытости изображения и сжа- тия изображения. Метцлер и др. (Metzler et al., 2016) разработали метод при- ближенной передачи сообщений с шумоподавлением (AMP) для интеграции шумоподавителей, таких как BLS-GSM (Portilla et al., 2003) и BM3D, в схему восстановления сжатых данных. Чан и др. (Chan et al., 2017) предложили ал- горитм ADMM PnP с шумоподавителем BM3D для сверхразрешения одиноч- ного изображения и восстановления квантованного изображения Пуассона. Камилов и др. (Kamilov et al., 2017) предложили пороговый алгоритм быстрой итерационной усадки (FISTA) с шумоподавителями BM3D и WNNM (Gu et al., 2014) для нелинейного обратного рассеяния. Сан и др. (Sun et al., 2019) предложили FISTA, предварительно подключив TV и шумоподавитель BM3D для птихографической микроскопии Фурье. Яир и Михаэли (Yair, Michaeli, 2018) предложили использовать шумоподавитель WNNM в качестве готово- го решения для раскрашивания и удаления размытия. Гаваскар и Чаудхури (Gavaskar, Chaudhury, 2020) исследовали конвергенцию IR PnP на основе ISTA с шумоподавлением по алгоритму нелокального среднего. С развитием методов глубокого обуче ния, таких как современные архитек - туры сети и алгоритм оптимизации на основе градиента, шумоподавитель на основе CNN показал многообещающие характеристики с точки зрения ка- чест ва и экономичности. После его успеха было предложено множество работ по тематике IR PnP на основе шумоподавителя CNN. Романо и др. (Romano et al., 2017) предложили явную регуляризацию с по мощью шумоподавителя TNRD для устранения размытия изображения. В нашей предыдущей работе (Zhang et al., 2017) различные шумоподавители CNN обучены подключаться к алгоритму HQS для устранения размытия и SISR. Тирер и Гириес (Tirer and Giryes, 2018) предложили применять итеративное шумоподавление и обрат - ное проецирование с по мощью шумоподавителей IRCNN для раскрашивания и устранения размытия изображения. Гу и др. (Gu et al., 2018) предложили использовать шумоподавители WNNM и IRCNN для удаления размытия по принципу PnP и SISR. Тирер и Гириес (Tirer, Giryes, 2019) предложили исполь- зовать шумоподавители IRCNN для SISR с поддержкой PnP . Ли и Ву (Li, Wu, 1 Peak signal-to-noise ratio – пиковое отношение сигнала к шуму. – Прим. перев.\n--- Страница 613 ---\n612  Методы PnP и глубокой развертки для восстановления изображения 2019) подключили шумоподавители IRCNN к алгоритму разделенной итера- ции Брегмана, чтобы решить задачу прорисовки глубины изображения. Рю и др. (Ryu et al., 2019) представили теоретический анализ сходимости IR PnP на основе алгоритмов прямого-обратного разделения и ADMM, а также пред- ложили спектральную нормализацию для обуче ния шумоподавителя DnCNN. Сан и др. (Sun et al., 2019) разработали алгоритм регуляризации блочных координат путем шумоподавления (RED) с использованием шумоподавителя DnCNN (Zhang et al., 2017) в качестве явного регуляризатора. Хотя PnP IR может использовать мощные ресурсы шумоподавителя CNN, существующие методы обычно основаны на шумоподавителях DnCNN или IRCNN, которые не в полной мере используют CNN. Как правило, шумопода- витель для PnP IR не должен быть слепым и должен справляться с широким диапазоном уровней шума. Однако шумоподавителю DnCNN необходимо обучить отдельную модель для каждого уровня шума. Чтобы уменьшить ко- личество шумоподавителей, в некоторых работах используется один шу - моподавитель, настроенный на небольшой уровень шума. Однако, по дан- ным (Romano et al., 2017), такая стратегия, как правило, требует большого количества итераций для достижения удовлетворительного качества, что увеличивает вычислительную нагрузку. Хотя шумоподавители IRCNN могут обрабатывать широкий диапазон уровней шума, они состоят из 25 отдельных 7-слойных шумоподавителей, и каждый из них обучается на интервальном уровне шума 2. Такой шумоподавитель страдает от следующих двух недо- статков. Во-первых, у него нет гибкости в обработке разных уровней шума. Во-вторых, он недостаточно эффективен из-за неглубоких слоев. Учитывая вышеизложенное, необходимо разработать гибкий и мощный шумоподави- тель для повышения показателей IR PnP . Предложенный нами шумоподави- тель на основе FFDNet (Zhang et al., 2018a) может обрабатывать широкий диа- пазон уровней шума с по мощью одной модели, используя в качестве входных данных карту уровня шума. Более того, его эффективность повышается за счет использования как ResNet (He et al., 2016), так и U-Net (Ronneberger et al., 2015). Глубокий шумоподавитель дополнительно включен в архитектуру PnP IR на основе HQS, чтобы продемонстрировать преимущества использо- вания мощного глубокого шумоподавителя. В то же время предлагается но- вый периодический геометрический самоансамбль (geometric self-ensemble) для потенциального улучшения производительности без дополнительных вычислительных затрат, а также проводится тщательный анализ настройки параметров и промежуточных результатов, чтобы лучше понять механизм работы предлагаемого глубокого PnP IR. 14.3.1. Предварительное изучение глубокого шумоподавителя CNN Хотя недавно были предложены различные методы шумоподавления на ос - нове CNN, большинство из них не предназначены для IR с поддержкой PnP . В исследованиях (Lehtinen et al., 2018; Krull et al., 2019; Batson, Royer, 2019)\n--- Страница 614 ---\nГлубокое восстановление изображения по методу PnP  613 предлагается новая стратегия обуче ния без реальных данных. В (Guo et al., 2019; Brooks et al., 2019; Abdelhamed et al., 2019; Zamir et al., 2020) предложен метод синтеза реального шума для имитации реальных цифровых фотогра- фий. Однако с байесовской точки зрения шумоподавитель для PnP IR должен быть гауссовым шумоподавителем. Следовательно, для обуче ния с учителем можно добавить синтетический гауссов шум к чистому изображению. В ра- ботах (Lefkimmiatis, 2017; Zhang et al., 2019; Liu et al., 2018; Plötz, Roth, 2018) для лучшего восстановления изображения в структуру сети был включен нелокальный модуль. Однако эти методы изучают отдельную модель для каждого уровня шума. Возможно, наиболее подходящим шумоподавителем для PnP IR является FFDNet (Zhang et al., 2018), который может обрабатывать широкий диапазон уровней шума, используя карту уровня шума в качестве входных данных. Тем не менее FFDNet демонстрирует показатели, сравни- мые только с DnCNN и IRCNN, поэтому ей не хватает внутреннего потенциала для повышения качества PnP IR. По этой причине мы предлагаем улучшить архитектуру FFDNet, воспользовавшись преимуществами широко использу - емых U-Net (Ronneberger et al., 2015) и ResNet (He et al., 2016). 14.3.1.1. Шумоподавляющая сетевая архитектура Хорошо известно, что U-Net (Ronneberger et al., 2015) эффективно и качест - венно преобразовывает изображение в изображение, в то время как ResNet (He et al., 2016) лучше подходит для увеличения качества моделирования за счет стека нескольких обходных блоков (residual block). Продолжая идею FFDNet (Zhang et al., 2018), которая использует карту уровня шума в качест - ве входных данных, предлагаемый шумоподавитель DRUNet дополнитель- но интегрирует обходные блоки в U-Net для эффективного моделирования априорного компонента шумоподавителя. Стоит подчеркнуть, что эта работа не направлена на разработку новой сетевой архитектуры шумоподавления. Схожую идею объединения U-Net и ResNet можно найти и в других работах, таких как (Zhang et al., 2018; Venkatesh et al., 2018). Как и FFDNet, сеть DRUNet может обрабатывать различные уровни шума с по мощью одной модели. Основой DRUNet является U-Net, состоящая из четырех градаций. Каждая градация имеет связь с пропуском идентичности между операциями шаговой свертки 2×2 (ctride convolution, SConv) пониже- ния разрешения и транспонированной свертки 2×2 (transposed convolution, TConv) повышения разрешения. Количество каналов в каждом слое от первой до четвертой градации составляет 64, 128, 256 и 512 соответственно. В каж - дой градации уменьшения и увеличения разрешения задействовано четыре последовательных обходных блока. По аналогии с устройством сетевой ар- хитектуры для сверхразрешения в (Lim et al., 2017) функции активации не следуют за первым и последним сверточными (Conv) слоями, а также слоями SConv и TConv. Кроме того, каждый обходной блок содержит только одну функцию активации ReLU. Стоит отметить, что рассматриваемая DRUNet не имеет смещения, что означает, что смещение не используется во всех слоях Conv, SConv и TConv.\n--- Страница 615 ---\n614  Методы PnP и глубокой развертки для восстановления изображения Причина двоякая. Во-первых, несмещенная сеть с активацией ReLU и про- пуском идентичности естественным образом обеспечивает свойство инвари - антности масштабирования многих задач восстановления изображений, т. е. условие f(ax) = af(x) выполняется для любого скаляра a ³ 0 (см. Mohan et al., 2019 для более подробной информации). Во-вторых, мы эмпирически обна- ружили, что для сети со смещением величина смещения будет намного боль- ше, чем у фильтров, что, в свою очередь, может повредить обобщаемости. 14.3.2. Методика обучения Хорошо известно, что CNN выигрывает от наличия крупномасштабных обучаю щих данных. Чтобы обогатить априорные данные шумоподавителя для PnP IR, вместо обуче ния на небольшом наборе данных, который вклю- чает 400 изображений набора данных сегментации Беркли (BSD) размером 180×180 (Chen, Pock, 2017), мы создаем большой набор данных, состоящий из 400 изобра жений BSD, 4744 изображений из исследовательской базы данных Waterloo (Ma et al., 2017), 900 изображений из набора данных DIV2K (Agusts- son, Timofte, 2017) и 2750 изображений из набора данных Flick2K (Lim et al., 2017). Поскольку такой набор данных охватывает большее пространство изобра жений, обученная модель может немного улучшить показатель PSNR для набора данных BSD68 (Roth, Black, 2009), имея при этом очевидный вы- игрыш в PSNR при обработке наборов данных из другого домена. В соответствии с общепринятой методикой для гауссова шумоподавления зашумленный аналог y чистого изображения x получается путем добавления AWGN с уровнем шума σ. Соответственно, карта уровня шума представляет собой однородную карту, заполненную значениями σ, и имеет тот же про- странственный размер, что и зашумленное изображение. Чтобы справиться с широким диапазоном уровней шума, во время обуче ния уровень шума σ выбирается случайным образом из диапазона [0, 50]. Параметры сети оп - тимизируются путем минимизации потерь L1, а не L2 между изображением после шумоподавления и его истинным образцом с по мощью алгоритма Адама (Kingma, Ba, 2015). Хотя нет прямых доказательств того, какая потеря приведет к повышению качества, широко признано, что потеря L1 более робастна, чем потеря L2 при обработке выбросов (Bishop, 2006). Что касается шумоподавления, во время выборки AWGN могут возникать выбросы. В этом смысле при обучении шумоподавляющей сети потери L1 имеют тенденцию быть более стабильными, чем потери L2. Шаг обуче ния начинается с 1·10–4, затем уменьшается вдвое каждые 100 000 итераций, и, наконец, обуче ние заканчивается, когда шаг становится меньше 5·10–7. На каждой итерации во время обуче ния из обучающих данных случайным образом отбирались 16 патчей размером 128×128. Мы отдельно обучаем модель шумоподавителя для изображений в градациях серого и цветных изображений. Обуче ние мо- дели с по мощью PyTorch и графического процессора Nvidia Titan Xp занимает около четырех дней.\n--- Страница 616 ---\nГлубокое восстановление изображения по методу PnP  615 14.3.3. Результаты удаления шума 14.3.3.1. Удаление шума с изображений в градациях серого Для очистки от шума изображений в градациях серого мы сравнили пред- ложенный нами шумоподавитель DRUNet с несколькими современными ме- тодами удаления шума, включая два репрезентативных метода на основе моделей – BM3D (Dabov et al., 2007) и WNNM (Gu et al., 2014), один метод на основе CNN, который отдельно обучает одну модель для каждого уровня шума (например, DnCNN (Zhang et al., 2017)), и два метода на основе CNN, которые были обучены работать с широким диапазоном уровней шума (на- пример, IRCNN (Zhang et al., 2017) и FFDNet (Zhang et al., 2018)). Значения PSNR различных методов на широко используемых наборах данных Set12 (Zhang et al., 2017) и BSD68 (Martin et al., 2001; Roth, Black, 2009) для уровней шума 15, 25 и 50 представлены в табл. 14.1. Можно видеть, что DRUNet до- стигает наилучших показателей PSNR для всех уровней шума в двух наборах данных. В частности, DRUNet дает среднее увеличение PSNR около 0,9 дБ по сравнению с BM3D и превосходит DnCNN, IRCNN и FFDNet по среднему зна- чению PSNR 0,5 дБ в наборе данных Set12 и 0,25 дБ в наборе данных BSD68. На рис. 14.2 показаны результаты очистки изображения в градациях серого различными методами на примере снимка бабочки Монарх из набора дан- ных Set12 с уровнем шума 50. Видно, что DRUNet может восстанавливать гораздо более четкие края, чем DnCNN и FFDNet. Таблица 14.1. Средние значения PSNR (дБ) для различных методов с уровнями шума 15, 25 и 50 дБ на популярных наборах данных Set12 и BSD68 (Martin et al., 2001; Roth, Black, 2009; Zhang et al., 2017). Лучшие результаты выделены жирным шрифтом Набор Уровень шума BM3D WNNM DnCNN IRCNN FFDNet DRUNet Setl2 15 32,37 32,70 32,86 32,77 32,75 33,25 25 29,97 30,28 30,44 30,38 30,43 30,94 50 26,72 27,05 27,18 27,14 27,32 27,90 BSD68 15 31,08 31,37 31,73 31,63 31,63 31,91 25 28,57 28,83 29,23 29,15 29,19 29,48 50 25,60 25,87 26,23 26,19 26,29 26,59 (a) (b) (c) (d) Рис. 14.2  Результаты очистки от шума изображения в градациях серого различными методами на примере снимка бабочки Монарх из набора данных Set12 с уровнем шума 50. a) Шум (14,78 дБ); b) DnCNN (26,83 дБ); c) FFDNet (26,92 дБ); d) DRUNet (27,31 дБ)\n--- Страница 617 ---\n616  Методы PnP и глубокой развертки для восстановления изображения 14.3.3.2. Удаление шума с цветного изображения Поскольку существующие методы в основном сосредоточены на очистке от шума изображений в градациях серого, при подавлении шумов на цвет - ном изображении мы сравниваем DRUNet только с CBM3D, DnCNN, IRCNN и FFDNet. В табл. 14.2 представлены результаты очистки цветного изобра- жения с использованием различных методов для уровней шума 15, 25 и 50 на CBSD68 (Martin et al., 2001; Roth, Black, 2009; Zhang et al., 2017), Kodak24 (Franzen, 1999) и McMaster (Zhang et al., 2011). Можно видеть, что DRUNet зна- чительно превосходит другие конкурирующие методы. Стоит отметить, что, имея хорошие показатели в наборе данных CBSD68, DnCNN хуже работает с набором данных McMaster. Такое несоответствие подчеркивает важность сокращения разрыва между обуче нием и применением в области подавления шумов на изображении. Примеры применения различных методов к изобра - жению «163085» из набора данных CBSD68 с уровнем шума 50 показаны на рис. 14.3, по которому видно, что DRUNet может восстановить больше мелких деталей и текстур, чем конкурирующие методы. (a) (b) (c) (d) Рис. 14.3  Результаты шумоподавления цветного изображения различными методами на изображении «163085» из набора данных CBSD68 с уровнем шума 50. a) Исходное зашумленное изображение (14,99 дБ); b) DnCNN (28,68 дБ); c) FFDNet (28,75 дБ); d) DRUNet (29,28 дБ) Таблица 14.2. Средние значения PSNR (дБ), полученные различными методами для уровней шума 15, 25 и 50 дБ на наборах CBSD68 (Martin et al., 2001; Roth, Black, 2009; Zhang et al., 2017a), Kodak24 и McMaster. Лучшие результаты выделены жирным шрифтом Набор Уровень шума CBM3D DnCNN IRCNN FFDNet DRUNet CBSD68 15 33,52 33,90 33,86 33,87 34,30 25 30,71 31,24 31,16 31,21 31,69 50 27,38 27,95 27,86 27,96 28,51 Kodak24 15 34,28 34,60 34,69 34,63 35,31 25 32,15 32,14 32,18 32,13 32,89 50 28,46 28,95 28,93 28,98 29,86 McMaster 15 34,06 33,45 34,58 34,66 35,40 25 31,66 31,52 32,18 32,35 33,14 50 28,51 28,62 28,91 29,18 30,08\n--- Страница 618 ---\nГлубокое восстановление изображения по методу PnP  617 14.3.4. Алгоритм HQS для PnP IR Как упоминалось ранее, мы выбрали HQS в качестве алгоритма разделения переменных из-за его простоты и быстрой сходимости. Между тем не вы- зывает сомнений, что настройка параметров всегда является нетривиальной задачей (Romano et al., 2017). Другими словами, для получения хорошего ка- чества обработки изображений необходима тщательная настройка парамет - ров. Чтобы лучше понять принцип PnP IR на основе HQS, мы обсудим общую методологию настройки параметров после краткого обзора алгоритма HQS. Затем рассмотрим стратегию периодического геометрического самосогла- сованного ансамбля, позволяющую улучшить качество. 14.3.4.1. Алгоритм полуквадратичного разделения (HQS) HQS использует следующую итеративную схему для решения уравнения (14.2): В частности, подзадача (14.10б) с байесовской точки зрения соответствует гауссову шумоподавлению на xk с уровнем шума βk ≜ . Следователь- но, любой гауссов шумоподавитель может быть подключен к чередующимся итерациям для решения (14.2). Чтобы решить это уравнение, мы перепишем (14.10б) следующим образом: zk = Шумоподавитель( xk, βk). (14.11) Из уравнения (14.11) можно сделать два вывода. Во-первых, приор ℛ(·) может быть неявно задан шумоподавителем. По этой причине как приор, так и шумоподавитель для IR PnP обычно называют априорным шумопо- давителем. Во-вторых, интересно обучить единственный шумоподавитель CNN, чтобы заменить уравнение (14.11) и использовать преимущества CNN, такие как высокая гибкость проектирования сети, высокая эффективность графических процессоров и мощные возможности моделирования с глубо- кими сетями. 14.3.4.2. Общая методика настройки параметров Из чередующихся итераций между уравнением (14.10а) и уравнением (14.10b) легко видеть, что задействованы три регулируемых параметра, включая па- раметр штрафа μ, параметр регуляризации λ и общее количество итераций K. Как правило, чтобы гарантировать, что xk и zk сходятся к фиксированной точке, требуется большое значение μ, что, однако, требует большого K для сходимости. Общий подход состоит в стратегии постепенного увеличения μ, (14.10a) (14.10б)\n--- Страница 619 ---\n618  Методы PnP и глубокой развертки для восстановления изображения что приводит к последовательности μ1 < ··· < μk < ··· <μK. Тем не менее в та- ком случае необходимо ввести новый параметр для управления размером шага, что усложняет настройку параметров. Согласно уравнению (14.11), мы можем заметить, что μ определяет уровень шума βk = на k-й итерации априорного шумоподавителя. С другой стороны, предполагается, что диа- пазон уровня шума [0, 50] достаточен для βk. Вдохновленные таким знанием о домене, мы можем настроить βk и λ для неявного определения μk. Исхо - дя из того, что значение μk должно монотонно возрастать, мы равномерно выбираем βk от большого уровня шума β1 до малого βK в логарифмическом пространстве. Это означает, что μk легко определяется через μk = λ/βk2. По аналогии с (Zhang et al., 2017) мы фиксируем β1 на уровне 49, а βK опреде- ляется уровнем шума изображения β. Поскольку K задается пользователем, а σK имеет ясный физический смысл, их легко настроить на практике. Факти- чески нам осталось настроить параметр λ. Поскольку λ происходит от члена регуляризации и, следовательно, должен быть фиксированным, мы можем выбрать оптимальное значение λ с по мощью поиска по сетке в проверочном наборе данных. Эмпирически установлено, что λ обеспечивает необходимое качество в диапазоне [0,19, 0,55]. В этой главе мы используем значение 0,23, если не указано иное. Следует отметить, что поскольку λ может быть погло- щен β и играет роль контроля компромисса между членом данных и членом регуляризации, можно неявно настроить λ , умножив β на скаляр. 14.3.4.3. Периодический геометрический самосогласованный ансамбль Геометрический ансамбль, основанный на отражении и вращении, является широко используемой стратегией для повышения качества IR (Timofte et al., 2016). Сначала он преобразует входные данные путем отражения и по- ворота для создания 8 изображений, затем получает соответствующие вос - становленные изображения и, наконец, выдает усредненный результат после обратного преобразования. Хотя использование подобного геометрического ансамбля дает определенный выигрыш в качестве, он достигается за счет увеличения времени вывода. В отличие от описанного выше метода, мы периодически применяем гео- метрический ансамбль для каждых последовательных 8 итераций. На каждой итерации этот процесс включает одно преобразование перед шумоподав- лением и соответствующее обратное преобразование после шумоподавле- ния. Обратите внимание, что мы отказались от шага усреднения, потому что вход априорной модели шумоподавителя варьируется в зависимости от итераций. Мы называем этот метод периодическим геометрическим само- согласованным ансамблем. Его явное преимущество заключается в том, что общее время вывода не увеличивается. Эмпирически мы обнаружили, что предложенный метод обычно может улучшить PSNR на 0,02 ~ 0,2 дБ. Основываясь на вышеизложенном, мы оформили стратегию глубокого PnP IR, а именно DPIR, в виде обобщенного алгоритма 1.\n--- Страница 620 ---\nВосстановление изображения методом глубокой развертки  619 Алгоритм 1. Восстановление изображения по принципу PnP с предварительным глубоким шумоподавлением (DPIR) Вход: априорная модель глубокого шумоподавителя, зашумленное изображение y, модель деградации y = (x ⊗ k) ¯s + n, уровень шума изображения σ , βk априорной модели шумоподавителя на k -й итерации из K итераций, компромиссный параметр λ . Выход: Восстановленное изображение z K. 1. Инициализируем z 0 из y , предварительно вычисляем α k = λσ2/βk2 2. for k = 1, 2, …, K do 3. // Решение подзадачи данных 4. zk = Шумоподавитель( xk, βk); // Шумоподавление с по мощью глубокого шумопо- давителя DRUNet и периодического геометрического ансамбля 5. end 14.4. В осстано ВЛение изображения методом гЛубоКой разВертКи Первые методы глубокой развертки восходят к исследованиям (Barbu, 2009; Samuel, Tappen, 2009; Sun, Tappen, 2011), где для очистки изображения от шума был предложен компактный вывод MAP , основанный на алгоритме градиентного спуска. С тех пор были предложены различные методы глу - бокой развертки, основанные на определенных алгоритмах оптимизации (например, полуквадратичное разделение (Afonso et al., 2010), метод пере- менного направления множителей (Boyd et al., 2011) и прямо-двойственный метод (Chambolle and Pock, 2011)) и предназначенные для решения различ- ных задач восстановления изображений, таких как подавление шумов (Chen, Pock, 2017; Lefkimmiatis, 2017), устранение размытости (Schmidt, Roth, 2014; Kruse et al., 2017) и компрессионное зондирование (Zhang, Ghanem, 2018). По сравнению с простыми методами, основанными на обучении, методы глубокой развертки поддаются интерпретации и могут включать в модель ограничения деградации. Однако большинство из них страдают одним или несколькими из следующих недостатков. (1) Решение подзадачи регуляри- зации без использования глубокой CNN является недостаточно мощным для хорошего качества. (2) Подзадача данных не имеет решения в закрытой форме, что может препятствовать сходимости. (3) Весь вывод обучается по- этапно и с тонкой настройкой, а не полным сквозным способом. Поэтому особый интерес вызывает метод, не страдающий вышеупомянутыми недо- статками.\n--- Страница 621 ---\n620  Методы PnP и глубокой развертки для восстановления изображения 14.4.1. Сеть глубокой развертки После определения оптимизации развертки, т. е. алгоритма HQS, следующим шагом является проектирование сети восстановления изображений с глубокой разверткой (deep unfolding image restoration, DUIR). Поскольку оптимизация развертки в основном состоит из итеративного решения подзадачи данных в виде уравнения (14.6) и подзадачи регуляризации в виде уравнения (14.7), DUIR должен переключаться между модулем данных 𝒟 и модулем приора 𝒫. Кроме того, поскольку решения подзадач также принимают на вход со- ответствующие гиперпараметры αk и βk, в DUIR дополнительно вводится модуль гиперпараметров H. На рис. 14.4 изображена общая архитектура DUIR с K итераций, где значение K эмпирически выбрано равным 8 для достиже- ния компромисса между скоростью и качеством. Далее приводится более подробная информация о 𝒟 , 𝒫 и H. 14.4.1.1. Модуль данных 𝓓 Модуль данных играет роль уравнения (14.8) которое является решением подзадачи данных в закрытой форме. По сути, он предназначен для поиска более четкого изображения с высоким разрешением, которое минимизирует взвешенную комбинацию члена данных ||y – (z ⊗ k) ↓s||2 и члена квадратич- ной регуляризации ||z – xk–1||2 с компромиссным гиперпараметром αk. По - скольку член данных соответствует модели деградации, модуль данных не только имеет то преимущество, что принимает масштабный коэффициент s и ядро размытия k в качестве входных данных, но также накладывает огра- ничение деградации на решение. На самом деле сложно вручную разработать такой простой, но полезный модуль с несколькими входами. Для краткости перепишем уравнение (14.8) следующим образом: zk = 𝒟(xk–1, s, k, y, αk). (14.12) Обратите внимание, что x0 инициализируется путем простой интерполя- ции y по ближайшему соседу с масштабным коэффициентом s. Следует отме - тить, что уравнение (14.12) не содержит обучаемых параметров, что, в свою очередь, приводит к лучшей обобщаемости из-за полного разделения между членом данных и членом регуляризации. Для реализации модуля мы ис - пользуем PyTorch, где основные операторы БПФ и обратного БПФ могут быть реализованы с по мощью torch.fft.fftn и torch.fft.ifftn соответственно. 14.4.1.2. Модуль приора 𝓟 Модуль приора предназначен для получения более чистой оценки xk путем пропускания zk через шумоподавитель, когда уровень шума равен βk. По ана- логии с (Zhang et al., 2018) мы предлагаем использовать глубокий шумопода- витель CNN, который принимает уровень шума в качестве входных данных: xk = 𝒫(zk, βk). (14.13)\n--- Страница 622 ---\nВосстановление изображения методом глубокой развертки  621 Предлагаемый шумоподавитель, а именно ResUNet, объединяет обходные блоки (He et al., 2016) в U-Net (Ronneberger et al., 2015). U-Net широко исполь- зуется для сравнивания изображений, в то время как ResNet обязана своей популярностью быстрому обуче нию и большой емкости со множеством об- ходных блоков. σ k х0 х8y sβ = ℋ(σ, s) z1 = 𝒟(x0, s, k, y, α1) z2 = 𝒟(x1, s, k, y, α2) z8 = 𝒟(x7, s, k, y, α8)x1 = 𝒫(z1, β1) x2 = 𝒫(z2, β2) x8 = 𝒫(z8, β8) α = ℋ(σ, s) Рис. 14.4  Общая архитектура DUIR с K = 8 итерациями. DUIR может гибко обрабатывать выход модели деградации y = ( x ⊗ k) ¯s + n с по мощью одной модели, поскольку в качестве входных данных она принимает искаженное изо- бражение y, масштабный коэффициент s, ядро размытия k и уровень шума σ. В частности, DUIR состоит из трех основных модулей, включая модуль данных 𝒟, который делает изображение высокого разрешения более четким, модуль при- ора 𝒫, который делает изображение более чистым, и модуль гиперпараметров ℋ, управляющий выходными данными 𝒟 и 𝒫 ResUNet принимает объединенную карту zk и уровня шума в качестве вход- ных данных и выводит очищенное от шума изображение xk. Таким образом, ResUNet может обрабатывать различные уровни шума с по мощью одной модели, что значительно сокращает общее количество параметров. Следуя общей структуре U-Net, ResUNet содержит четыре масштабных пути, каждый из которых имеет сквозную связь с пропуском идентичности между опера- циями уменьшения и увеличения масштаба. В частности, количество каналов в слоях с первого по четвертый масштабный путь установлено равным 64, 128, 256 и 512 соответственно. Для операций понижения и повышения раз- решения используются пошаговая свертка 2×2 (SConv) и транспонированная свертка 2×2 (TConv) соответственно. Заметим также, что за слоями SConv и TConv, а также за первым и последним сверточными слоями не следуют функции активации. Ради наследования достоинств ResNet при уменьшении и увеличении разрешения применяется группа из двух обходных блоков. Как было предложено в (Lim et al., 2017), каждый обходной блок состоит из двух сверточных слоев 3×3 с активацией ReLU в середине и сквозным соединени- ем с пропуском идентичности, суммируемым с его выходом. 14.4.1.3. Модуль гиперпараметров 𝓗 Модуль гиперпараметров действует как «ползунковый регулятор» для управ- ления выводом модулей данных и приора. Например, решение zk будет по- степенно приближаться к xk–1 по мере увеличения αk. Согласно определению αk и βk, αk зависит от σ и μk, а βk зависит от λ и μk. Хотя можно найти фикси-\n--- Страница 623 ---\n622  Методы PnP и глубокой развертки для восстановления изображения рованные λ и μ k, мы утверждаем, что возможно улучшение качества резуль- тата, если λ и μk меняются в зависимости от двух ключевых элементов, т. е. масштабного коэффициента s и уровня шума σ, которые влияют на степень некорректности задачи. Пусть α = [α1, α2, …, αK] и β = [β1, β2, , βK]: мы ис - пользуем единственный модуль для предсказания α и β: [α, β] = ℋ(σ, s). (14.14) Модуль гиперпараметров состоит из трех полностью связанных слоев с ReLU в качестве первых двух функций активации и Softplus в качестве по- следней. Количество скрытых узлов в каждом слое равно 64. Учитывая тот факт, что αk и βk должны быть положительными, а уравнению (14.8) следует избегать деления на чрезвычайно малые αk, к выходу слоя Softplus дополни- тельно прибавляют 1×10–6. 14.4.2. Сквозное обучение Сквозное обуче ние направлено на изучение параметров DUIR путем мини- мизации функции потерь на большом наборе обучающих данных. Поэтому в данном разделе в основном описываются обучающие данные, функция по- терь и методика обуче ния. Вслед за (Wang et al., 2018) мы используем DIV2K (Agustsson, Timofte, 2017) и Flickr2K (Timofte et al., 2017). Ухудшенные изо- бражения синтезируются с по мощью модели деградации y = (x ⊗ k) ¯s + n. Масштабные коэффициенты выбираются из множества {1, 2, 3, 4}. В качестве ядер размытия мы используем анизотропные ядра Гаусса, как в (Riegler et al., 2015; Shocher et al., 2018; Zhang et al., 2018), и ядра движения, как в (Bo- racchi, Foi, 2012). Мы также используем фиксированный размер ядра 25×25. Диапазон уровня шума принят равным [0, 25]. Что касается функции потерь, для оценки величины PSNR мы используем потери L1. Для оптимизации параметров DUIR применяем решатель Adam (Kingma, Ba, 2015) с размером мини-пакета 128. Коэффициент обуче ния начинается с 1×10–4, уменьшается в 0,5 раза каждые 4×104 итераций и, наконец, заканчивается на 3×10–6. Стоит отметить, что из-за невозможности параллельных вычислений для разных коэффициентов масштабирования каждый мини-пакет включает только один случайный коэффициент масштабирования. Размер патча чистого об- раза равен 96×96. Мы обучаем модели с по мощью PyTorch на четырех гра- фических процессорах Nvidia Tesla V100 в облаке Amazon AWS. Получение модели DUIR занимает около двух дней. 14.5. Э Ксперименты Чтобы проверить гибкость и эффективность DPIR и DUIR, мы рассматриваем две классические задачи IR – устранение размытия изображения и сверхраз- решение одиночного изображения (SISR). Для каждой задачи мы продемон- стрируем количественные и качественные результаты DPIR и DUIR на трех\n--- Страница 624 ---\nЭксперименты  623 классических тестовых изображениях, которые показаны на рис. 14.5. Мы сравним разработанную вручную и изученную настройку гиперпараметров между DPIR и DUIR. Кроме того, проведем визуальное сравнение xk и zk на промежуточных итерациях для DPIR и DUIR. (а) (b) (c) Рис. 14.5  Три классических тестовых изображения: (а) бабочка; (b) листья; (c) морская звезда 14.5.1. Устранение размытия изображения Мы используем для тестирования два из восьми ядер размытия, предло- женных в (Levin et al., 2009), которые имеют размер 17×17 и 27×27 соответ - ственно. Как показано в табл. 14.3, мы также рассматриваем гауссов шум с различными уровнями шума: 2,55 (1 %) и 7,65 (3 %). Следуя общей стратегии равномерного устранения размытия, мы синтезируем размытые изображе- ния, сначала применяя ядро размытия, а затем добавляя AWGN с уровнем шума σ. Что касается гиперпараметров DPIR, то K и σK устанавливаются рав- ными 8 и σ соответственно, а z 0 инициализируется как y . Таблица 14.3. Значения PSNR (дБ) архитектур DPIR и DUIR в задаче устранения размытия трех тестовых изображений. Лучшие результаты выделены жирным шрифтом Метод σ Бабочка Листья Морская звезда Второе ядро размером 17×17 из (Levin et al., 2009) DPIR2,5534,26 35,19 34,21 DUIR 33,73 34,35 34,02 DPIR7,6529,52 30,11 29,83 DUIR 29,55 30,02 29,84 Четвертое ядро размером 27×27 из (Levin et al., 2009) DPIR2,5534,18 35,12 33,91 DUIR 33,58 34,26 33,73 DPIR7,6529,45 30,27 29,46 DUIR 29,38 29,94 29,43\n--- Страница 625 ---\n624  Методы PnP и глубокой развертки для восстановления изображения 14.5.1.1. Количественные и качественные результаты В табл. 14.3 представлены значения PSNR (дБ) архитектур DPIR и DUIR для трех тестовых изображений. Видно, что DPIR и DUIR достигают схожих ре- зультатов. Обратите внимание, что DPIR имеет более крупный и медленный шумоподавитель, чем DUIR, поэтому DPIR менее эффективен, чем DUIR. Ви- зуальные результаты DPIR и DUIR после обработки тестовых изображений показаны на рис. 14.6. Можно видеть, что и DPIR, и DUIR могут эффективно восстанавливать резкость и естественный вид изображения. (а) (b) (c) Рис. 14.6  Визуальные результаты DPIR и DUIR в задаче устранения размытия изображения. Ядро размытия показано в правом верхнем углу размытого изобра- жения. Уровень шума 7,65 (3 %). (а) Размытое изображение; (b) DPIR; (c) DUIR 14.5.1.2. Сравнение найденных вручную и обученных гиперпараметров Рисунки 14.7 и 14.8 иллюстрируют гиперпараметры, то есть α и β, для DPIR и DUIR соответственно. Можно видеть, что изученные гиперпараметры DUIR\n--- Страница 626 ---\nЭксперименты  625 в целом соответствуют разработанным вручную гиперпараметрам DPIR. По рис. 14.7 и 14.8а видно, что α положительно коррелирует с σ. По рис. 14.7 и 14.8b видно, что β имеет тенденцию к уменьшению с количеством итера- ций и увеличивается с уровнем шума. Это означает, что уровень шума проме- жуточной оценки постепенно снижается на протяжении итераций, а серьез- ное ухудшение требует большого β k, чтобы справиться с некорректностью. Количество итераций Количество итераций (b) (а) Рис. 14.7  Гиперпараметры a) α и b) β DPIR в задаче устранения размытия по отношению к различным уровням шума Количество итераций Количество итераций (b) (а) Рис. 14.8  Гиперпараметры a) α и b) β DUIR в задаче устранения размытия по отношению к различным уровням шума 14.5.1.3. Промежуточные результаты На рис. 14.9 и 14.10 изображены визуальные результаты и PSNR для xk и zk при различных итерациях DPIR и DUIR на изображении морской звезды с (14.12). По рис. 14.9 видно, что хотя решение в замкнутой форме x1 может справиться с искажением размытия, оно также усугубляет шум. Глубокий шумоподавитель удаляет шум, что дает нам zk без шума. По мере увеличения числа итераций x7 содержит меньше структурированного шума, чем x1, а z7 восстанавливает больше деталей и более четкие края, чем z1. По рис. 14.10 видно, что 𝒟 и 𝒫 могут облегчать друг другу итеративное и попеременное удаление размытия. Интересно, что z1 DPIR значительно отличается от z1 DUIR, а это означает, что, в отличие от DPIR, априорный шумоподавитель в DUIR не является априорным гауссовым шумоподавителем.\n--- Страница 627 ---\n626  Методы PnP и глубокой развертки для восстановления изображения (a) (b) (c) (d) (e) (f) Рис. 14.9  Оценки в различных итерациях DPIR для задачи удаления размы- тия изображения морской звезды на рис. 14.6. (а) x1, (b) z1; (c) х2; (d) z6; (e) х7; (f) z7 (a) (b) (c) (d) (e) (f) Рис. 14.10  Оценки в различных итерациях DUIR для задачи удаления размы- тия изображения морской звезды на рис. 14.6. (а) x1, (b) z1; (c) х2; (d) z6; (e) х7; (f) z7\n--- Страница 628 ---\nЭксперименты  627 Мы можем сделать следующие выводы. Во-первых, хотя уравнение (14.10а) может справиться с искажением размытия, оно также усугубляет влияние шума по сравнению с входом zk–1. Во-вторых, априорный глубокий шумо- подавитель успешно удаляет шум, что дает нам очищенный от шума zk. В-третьих, по сравнению с х1 и х2, х8 содержит больше мелких деталей, а это означает, что уравнение (14.10a) может итеративно восстанавливать детали. 14.5.2. Сверхразрешение одиночного изображения (SISR) Хотя мы используем модель деградации y = (x ⊗ k) ¯s + n для SISR, стоит от - метить, что существующие методы SISR в основном предназначены для би- кубической модели деградации с формулой y = x ¯sbicubic, где ¯sbicubic обозначает бикубическую модель даунсэмплинга с понижающим коэффициентом s. Од - нако было обнаружено, что качество этих методов серьезно ухудшается, если реальная модель деградации отклоняется от предполагаемой (Efrat et al., 2013; Zhang et al., 2015). Поскольку бикубическая деградация хорошо изуче- на, интересно исследовать ее связь с классической моделью деградации. На самом деле бикубическую деградацию можно аппроксимировать, устано - вив соответствующее ядро размытия в модели деградации y = (x ⊗ k) ¯s. Чтобы достичь этого, мы используем метод работы с большими данными. Он заключается в решении следующей задачи оценки ядра путем минимизации ошибки реконструкции для большой пары высокое разрешение / бикубиче- ское низкое разрешение {(x , y)}: k×s bicubic = argmin k||(x ⊗ k) ¯s – y||. (14.15) На рис. 14.11 показаны аппроксимированные бикубические ядра для мас - штабных коэффициентов 2, 3 и 4. Следует отметить, что поскольку операция понижающей дискретизации выбирает верхний левый пиксель для каждого отдельного фрагмента s×s, бикубические ядра для масштабных коэффици- ентов 2, 3 и 4 имеют смещение центра на 0,5, 1 и 1,5 пикселя в направлении вверх влево соответственно. Для синтеза соответствующих тестовых изображений низкого разрешения с по мощью модели деградации y = (x ⊗ k) ¯s + n необходимо задать ядра размытия и уровни шума. Для более тщательной оценки было бы полезно ис - пользовать большое количество ядер размытия и уровней шума; однако это также приведет к обременительному процессу оценки. По этой причине мы рассматриваем только 8 репрезентативных и разнообразных ядер размытия, в том числе 4 изотропных ядра Гаусса с разной шириной (т. е. 0,7, 1,2, 1,6 и 2,0) и 4 анизотропных ядра Гаусса из (Zhang et al., 2018б). Мы не рассматриваем ядра размытия в движении, поскольку было указано, что для задачи SISR достаточно ядер Гаусса. Таким образом, для дальнейшего анализа робаст - ности ядра мы будем сообщать результаты PSNR отдельно для каждого ядра размытия, а не для каждого типа ядра. Хотя существует мнение, что правиль- ное ядро размытия должно варьироваться в зависимости от коэффициента\n--- Страница 629 ---\n628  Методы PnP и глубокой развертки для восстановления изображения масштабирования (Zhang et al., 2015), мы утверждаем, что 8 ядер размытия достаточно разнообразны, чтобы покрыть большое пространство ядер. Для уровней шума мы выбираем значения 2,55 (1 %) и 7,65 (3 %). Общие пара- метры K и σK устанавливаются равными 24 и max(σ , s) соответственно. Для инициализации z 0 используется бикубическая интерполяция изображения низкого разрешения. В частности, поскольку классическая модель деграда- ции выбирает верхний левый пиксель для каждого отдельного фрагмента s×s, необходимо надлежащим образом решить проблему сдвига. Чтобы решить эту проблему, мы настраиваем z 0 с по мощью интерполяции сетки. (a) k×2 bicubic (b) k×3 bicubic (c) k×4 bicubic Рис. 14.11 Аппроксимированные бикубические ядра для коэффициентов масштабирования 2, 3 и 4 в рамках модели деградации y = (x ⊗ k) ¯s. Обратите внимание, что эти ядра содержат отрицательные значения 14.5.2.1. Количественное и качественное сравнение В табл. 14.4 представлены средние значения PSNR (дБ) для DPIR и DUIR для трех тестовых изображений. Из табл. 14.4 видно, что значения PSNR разли- чаются для разных ядер размытия, и к наивысшему PSNR для каждого коэф- фициента масштабирования приводят разные ядра. Точнее, больший коэф- фициент масштабирования обычно требует более плавного ядра размытия.\n--- Страница 630 ---\nЭксперименты  629 Кроме того, DUIR значительно превосходит DPIR. Такое явление указывает на то, что сквозное обуче ние более полезно для сверхразрешения, чем для устранения размытия. На рис. 14.12 показаны визуальные результаты работы DPIR и DUIR на трех тестовых изображениях. Можно заметить, что как DPIR, так и DUIR могут значительно улучшить качество изображения. Заметим, что DUIR дает более четкие края, чем DPIR. Возможно, это связано со сквозным обуче нием. (а) (b) (c) Рис. 14.12  Визуальные результаты работы DPIR и DUIR на трех тес - товых изображениях. Ядро размытия показано в правом верхнем углу изображения низкого разрешения. (а) Изображение низкого разреше- ния; (b) DPIR; (c) DUIR\n--- Страница 631 ---\n630  Методы PnP и глубокой развертки для восстановления изображения Таблица 14.4. Средние значения PSNR (дБ) для DPIR и DUIR для различных комбинаций коэффициентов масштабирования, ядер размытия и уровней шума. Лучшие результаты выделены жирным шрифтом Метод Коэффициент масштаба Уровень шумаЯдро размытия DPIR×2 0 31,79 32,10 31,28 29,63 28,72 28,62 29,45 27,77 ×3 0 26,04 26,82 26,97 26,89 26,73 25,89 26,58 26,49 ×3 2,55 25,91 26,49 26,23 25,43 24,81 24,44 25,29 24,13 ×3 7,65 25,53 25,67 24,91 23,68 23,14 22,81 23,56 22,33 ×4 0 22,62 23,50 23,74 23,85 23,76 23,18 23,58 23,88 DUIR×2 0 33,58 34,47 33,49 31,79 31,29 31,29 31,45 30,20 ×3 0 28,05 29,53 29,88 29,87 29,40 29,37 29,43 29,25 ×3 2,55 27,77 28,74 28,47 27,70 27,15 27,20 27,42 26,54 ×3 7,65 26,87 27,13 26,43 25,47 25,15 25,03 25,24 24,47 ×4 0 24,71 26,38 27,02 27,30 27,16 26,76 26,69 27,28 14.5.2.2. Сравнение найденных вручную и изученных гиперпараметров Рисунки 14.13 и 14.14 иллюстрируют гиперпараметры α и β сетей DPIR и DUIR для различных комбинаций масштабного коэффициента s и уровня шума σ соответственно. Можно видеть, что изученные гиперпараметры DUIR со- гласуются с найденными вручную гиперпараметрами DPIR. По рис. 14.13 и 14.14а видно, что α положительно коррелирует с σ и меняется с s. Это фактически согласуется с определением αk. По рис. 14.13 и 14.14б видно, что β имеет тенденцию к уменьшению с ростом количества итераций и увеличи- вается вместе с масштабным коэффициентом и уровнем шума. Это означает, что уровень шума при получении высокого разрешения постепенно сни- жается по мере прохождения итераций, а комплексная деградация требует большого β k для устранения некорректности задачи. Количество итераций Количество итераций (b) (а) Рис. 14.13  Гиперпараметры (a) α и (b) β сети DPIR для задачи сверхразреше- ния при различных комбинациях уровней шума и масштабных коэффициентов\n--- Страница 632 ---\nЭксперименты  631 Количество итераций Количество итераций (b) (а) Рис. 14.14  Гиперпараметры (a) α и (b) β сети DUIR для задачи сверхраз- решения при различных комбинациях уровней шума и масштабных коэффи- циентов 14.5.2.3. Промежуточные результаты На рис. 14.15 и 14.16 представлены визуальные результаты xk и zk при раз- личных итерациях DPIR и DUIR на примере изображения морской звезды с рис. 14.12. По рис. 14.15 видно, что, хотя изображение низкого разрешения не содержит шума, решение в замкнутой форме x1 вносит сильный струк - турированный шум. После прохождения x1 через гауссов шумоподавитель (a) (b) (c) (d) (e) (f) Рис. 14.15  Оценки задачи восстановления высокого разрешения в различ- ных итерациях DPIR на примере изображения морской звезды с рис. 14.12. (а) x 1; (b) z 1; (c) х 2; (d) z 6; (e) х 7; (f) z 7\n--- Страница 633 ---\n632  Методы PnP и глубокой развертки для восстановления изображения такой структурированный шум удаляется, что видно из z1. При этом крошеч- ные текстуры и структуры сглаживаются, а края становятся размытыми. По мере увеличения числа итераций x7 содержит меньше структурированного шума, чем x1, а z7 восстанавливает больше деталей и более четкие края, чем z1. По рис. 14.16 видно, что 𝒟 и 𝒫 могут помогать друг другу в итеративном и попеременном удалении размытия и восстановлении деталей. Интересно, что, в отличие от гауссова шумоподавителя DPIR, 𝒫 также может действовать как усилитель детализации для высокочастотного восстановления, что, воз- можно, является следствием обуче ния для конкретной задачи. Кроме того, это не уменьшает деградацию, вызванную ядром размытия, что подтверж - дает развязку между 𝒟 и 𝒫 . В результате DUIR со сквозным обуче нием имеет определенное преимущество перед DPIR, зависящее от задачи. (a) (b) (c) (d) (e) (f) Рис. 14.16  Оценки задачи восстановления высокого разрешения в различ- ных итерациях DUIR на примере изображения морской звезды с рис. 14.12. (а) x 1; (b) z 1; (c) х 2; (d) z 6; (e) х 7; (f) z 7 14.6. заКЛюЧение В этой главе было рассказано о методах глубокого PnP и глубокой развертки, которые могут интегрировать методы, основанные на моделях и обучении, в задаче восстановления изображений. В частности, с по мощью алгоритма полуквадратичного разделения, который может отделить член данных от\n--- Страница 634 ---\nЛитературные источники  633 члена регуляризации, методы глубокого PnP могут заменить подзадачу ре- гуляризации априорным шумоподавителем на основе глубокого обуче ния, в то время как методы глубокой развертки обучают итеративную сеть решать подзадачу регуляризации с по мощью нейронных модулей. В результате как методы глубокого PnP , так и методы глубокой развертки могут унаследовать гибкость методов, основанных на моделях, сохраняя при этом преимущества методов, основанных на обучении. Для лучшего понимания механизма ра- боты обоих разновидностей метода в главе представлены количественные и качественные результаты, а также сравнительный анализ настройки ги- перпараметров и промежуточные результаты. Результаты показывают, что, хотя методы глубокой развертки изучают гиперпараметры, аналогичные разработанным вручную методам глубокого PnP , обученные априорные мо- дули отличаются от априорных модулей гауссова шумоподавителя. Напри- мер, обученный априорный модуль методов глубокой развертки также может улучшить детализацию изображения, в то время как априорный гауссов шу - моподавитель методов глубокого PnP не имеет такого достоинства. Хотя предложенные методы глубокого PnP и глубокой развертки показали большие перспективы, на практике они также имеют несколько недостатков. Во-первых, это неслепые методы, которые требуют точной оценки парамет - ров деградации, таких как ядро размытия. Если расчетное ядро размытия сильно отклоняется от истинного ядра, качество восстановления серьезно ухудшится. Во-вторых, они созданы на основе идеальной модели деграда- ции, которая редко соответствует реальным изображениям. Если реальный шум не подчиняется аддитивному белому распределению Гаусса, это может привести к снижению качества. бЛагодарности Эта работа была частично поддержана фондом ETH Zürich Fund (OK) и про- ектом Huawei Technologies Oy (Финляндия). Литературные исто ЧниКи Abdelhamed A., Brubaker M. A., Brown M. S., 2019. Noise flow: noise modelingwith conditional normalizing flows. In: IEEE International Conference on Computer Vision, pp. 3165–3173. Afonso M. V., Bioucas-Dias J. M., Figueiredo M. A., 2010. Fast image recovery using variable splitting and constrained optimization. IEEE Transactions on Image Processing 19 (9), 2345–2356. Agustsson E., Timofte R., 2017. NTIRE 2017 challenge on single image super-reso- lution: dataset and study. In: IEEE Conference on Computer Vision and Pattern RecognitionWorkshops, vol. 3, pp. 126–135. Andrews H. C., Hunt B. R., 1977. Digital Image Restoration. Prentice-Hall Signal Processing Series, vol. 1. Prentice-Hall, Englewood Cliffs.\n--- Страница 635 ---\n634  Методы PnP и глубокой развертки для восстановления изображения Barbu A., 2009. Training an active random field for real-time image denoising. IEEE Transactions on Image Processing 18 (11), 2451–2462. Batson J., Royer L., 2019. Noise2self: blind denoising by self-supervision. In: In- ternational Conference on Machine Learning, pp. 524–533. Bishop C. M., 2006. Pattern Recognition and Machine Learning. Springer. Boracchi G., Foi A., 2012. Modeling the performance of image restoration from motion blur. IEEE TIP 21 (8), 3502–3517. Boyd S., Parikh N., Chu E., Peleato B., Eckstein J., 2011. Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends in Machine Learning 3 (1), 1–122. Brooks T., Mildenhall B., Xue T., Chen J., Sharlet D., Barron J. T., 2019. Unprocessing images for learned raw denoising. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 11,036–11,045. Buades A., Coll B., Morel J. M., 2005. A non-local algorithm for image denoising. In: IEEE Conference on Computer Vision and Pattern Recognition, vol. 2, pp. 60–65. Burger H. C., Schuler C. J., Harmeling S., 2012. Image denoising: can plain neural networks compete with BM3D? In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 2392–2399. Chambolle A., Pock T., 2011. A first-order primal-dual algorithm for convex prob- lems with applications to imaging. Journal of Mathematical Imaging and Vision 40 (1), 120–145. Chan S. H., Wang X., Elgendy O. A., 2017. PnP ADMMfor image restoration: fixed- point convergence and applications. IEEE Transactions on Computational Ima- ging 3 (1), 84–98. Chen Y., Pock T., 2017. Trainable nonlinear reaction diffusion: a flexible framework for fast and effective image restoration. IEEE Transactions on Pattern Analysis and Machine Intelligence 39 (6), 1256–1272. Dabov K., Foi A., Katkovnik V., Egiazarian K., 2007. Image denoising by sparse 3-d transform-domain collaborative filtering. IEEE Transactions on Image Pro- cessing 16 (8), 2080–2095. Danielyan A., Katkovnik V., Egiazarian K., 2010. Image deblurring by augmented Lagrangian with BM3D frame prior. In:Workshop on Information Theoretic Methods in Science and Engineering, pp. 16–18. Danielyan A., Katkovnik V., Egiazarian K., 2012. BM3D frames and variational im- age deblurring. IEEE Transactions on Image Processing 21 (4), 1715–1728. Dong C., Loy C. C., He K., Tang X., 2016. Image super-resolution using deep con- volutional networks. IEEE Transactions on Pattern Analysis and Machine Intel- ligence 38 (2), 295–307. Dong W., Zhang L., Shi G., Li X., 2013. Nonlocally centralized sparse represen- tation for image restoration. IEEE Transactions on Image Processing 22 (4), 1620–1630. Efrat N., Glasner D., Apartsin A., Nadler B., Levin A., 2013. Accurate blur models vs. image priors in single image super-resolution. In: IEEE International Confer - ence on Computer Vision, pp. 2832–2839. Egiazarian K., Katkovnik V., 2015. Single image super-resolution via BM3D sparse coding. In: European Signal Processing Conference, pp. 2849–2853.\n--- Страница 636 ---\nЛитературные источники  635 Elad M., Aharon M., 2006. Image denoising via sparse and redundant representa- tions over learned dictionaries. IEEE Transactions on Image Processing 15 (12), 3736–3745. Franzen R., 1999. Kodak lossless true color image suite. source. http://r0k.us/graph- ics/kodak. vol. 4. Gavaskar R. G., Chaudhury K. N., 2020. PnP ista converges with kernel denoisers. IEEE Signal Processing Letters 27, 610–614. Geman D., Yang C., 1995. Nonlinear image recovery with half-quadratic regulariza- tion. IEEE Transactions on Image Processing 4 (7), 932–946. Gu S., Timofte R., Van Gool L., 2018. Integrating local and non-local denoiser priors for image restoration. In: International Conference on Pattern Recognition. Gu S., Zhang L., Zuo W., Feng X., 2014.Weighted nuclear normminimization with application to image denoising. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 2862–2869. Guo S., Yan Z., Zhang K., Zuo W., Zhang L., 2019. Toward convolutional blind de- noising of real photographs. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 1712–1722. He K., Zhang X., Ren S., Sun J., 2016. Deep residual learning for image recognition. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 770–778. Heide F., Steinberger M., Tsai Y. T., Rouf M., Pajak D., Reddy D., Gallo O., Liu J., Heidrich W., Egiazarian K., et al., 2014. Flexisp: a flexible camera image process- ing framework. ACM Transactions on Graphics 33 (6), 231. Jain V., Seung S., 2009. Natural image denoising with convolutional networks. In: Advances in Neural Information Processing Systems, pp. 769–776. Kamilov U. S., Mansour H., Wohlberg B., 2017. A PnP priors approach for solving nonlinear imaging inverse problems. IEEE Signal Processing Letters 24 (12), 1872–1876. Kingma D., Ba J., 2015. Adam: a method for stochastic optimization. In: Interna- tional Conference for Learning Representations. Krull A., Buchholz T. O., Jug F., 2019. Noise2void-learning denoising from single noisy images. In: IEEE Conference on Computer Vision and Pattern Recogni- tion, pp. 2129–2137. Kruse J., Rother C., Schmidt U., 2017. Learning to push the limits of efficient fft-ba sed image deconvolution. In: IEEE International Conference on Computer Vision, pp. 4586–4594. Lefkimmiatis S., 2017. Non-local color image denoising with convolutional neural networks. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 3587–3596. Lehtinen J., Munkberg J., Hasselgren J., Laine S., Karras T., Aittala M., Aila T., 2018. Noise2noise: learning image restoration without clean data. In: International Conference on Machine Learning, pp. 2965–2974. Levin A., Weiss Y., Durand F., Freeman W. T., 2009. Understanding and evaluating blind deconvolution algorithms. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 1964–1971. Li Z., Wu J., 2019. Learning deep cnn denoiser priors for depth image inpainting. Applied Sciences 9 (6), 1103.\n--- Страница 637 ---\n636  Методы PnP и глубокой развертки для восстановления изображения Lim B., Son S., Kim H., Nah S., Lee K. M., 2017. Enhanced deep residual networks for single image superresolution. In: IEEE Conference on Computer Vision and Pattern RecognitionWorkshops, pp. 136–144. Liu D., Wen B., Fan Y., Loy C. C., Huang T. S., 2018. Non-local recurrent network for image restoration. In: Advances in Neural Information Processing Systems, pp. 1673–1682. Ma K., Duanmu Z., Wu Q., Wang Z., Yong H., Li H., Zhang L., 2017. Waterloo ex - ploration database: new challenges for image quality assessment models. IEEE Transactions on Image Processing 26 (2), 1004–1016. Martin D., Fowlkes C., Tal D., Malik J., 2001. A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics. In: IEEE International Conference on Computer Vision, vol. 2, pp. 416–423. Metzler C. A., Maleki A., Baraniuk R. G., 2016. From denoising to compressed sens- ing. IEEE Transactions on Information Theory 62 (9), 5117–5144. Mohan S., Kadkhodaie Z., Simoncelli E. P., Fernandez-Granda C., 2019. Robust and interpretable blind image denoising via bias-free convolutional neural net - works. In: International Conference on Learning Representations. Parikh N., Boyd S. P., et al., 2014. Proximal algorithms. Foundations and Trends in Optimization 1 (3), 127–239. Plötz T., Roth S., 2018. Neural nearest neighbors networks. In: Advances in Neural Information Processing Systems, pp. 1087–1098. Portilla J., Strela V., Wainwright M. J., Simoncelli E. P., 2003. Image denoising using scale mixtures of Gaussians in the wavelet domain. IEEE Transactions on Image Processing 12 (11), 1338–1351. Richardson W. H., 1972. Bayesian-based iterative method of image restoration. JOSA 62 (1), 55–59. Riegler G., Schulter S., Ruther M., Bischof H., 2015. Conditioned regression models for non-blind single image super-resolution. In: IEEE International Conference on Computer Vision, pp. 522–530. Romano Y., Elad M., Milanfar P., 2017. The little engine that could: regularization by denoising (RED). SIAM Journal on Imaging Sciences 10 (4), 1804–1844. Ronneberger O., Fischer P., Brox T., 2015. U-net: convolutional networks for bio- medical image segmentation. In: International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 234–241. Roth S., Black M. J., 2009. Fields of experts. International Journal of Computer Vision 82 (2), 205–229. Ryu E., Liu J., Wang S., Chen X., Wang Z., Yin W., 2019. PnP methods provably con- verge with properly trained denoisers. In: International Conference on Machine Learning, pp. 5546–5557. Samuel K. G., Tappen M. F., 2009. Learning optimizedMAP estimates in continu- ously-valued MRF models. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 477–484. Schmidt U., Roth S., 2014. Shrinkage fields for effective image restoration. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 2774–2781. Shocher A., Cohen N., Irani M., 2018. «zero-shot» super-resolution using deep internal learning. In: IEEE International Conference on Computer Vision, pp. 3118–3126.\n--- Страница 638 ---\nЛитературные источники  637 Sun J., Tappen M. F., 2011. Learning non-local range Markov random field for ima- ge restoration. In: IEEE Conference on Computer Vision and Pattern Recogni- tion, pp. 2745–2752. Sun J., Tappen M. F., 2013. Separable Markov random field model and its ap- plications in low level vision. IEEE Transactions on Image Processing 22 (1), 402–407. Sun Y., Liu J., Kamilov U., 2019a. Block coordinate regularization by denoising. In: Advances in Neural Information Processing Systems, pp. 380–390. Sun Y., Xu S., Li Y., Tian L., Wohlberg B., Kamilov U. S., 2019b. Regularized Fourier ptychography using an online PnP algorithm. In: IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 7665–7669. Tappen M. F., 2007. Utilizing variational optimization to learn Markov random fields. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 1–8. Teodoro A. M., Bioucas-Dias J. M., Figueiredo M. A., 2016. Image restoration and reconstruction using variable splitting and class-adapted image priors. In: IEEE International Conference on Image Processing, pp. 3518–3522. Timofte R., Agustsson E., Van Gool L., Yang M. H., Zhang L., 2017. Ntire 2017 challenge on single image superresolution: methods and results. In: CVPRW, pp. 114–125. Timofte R., Rothe R., Van Gool L., 2016. Seven ways to improve example-based single image super resolution. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 1865–1873. Tirer T., Giryes R., 2018. Image restoration by iterative denoising and backward projections. IEEE Transactions on Image Processing 28 (3), 1220–1234. Tirer T., Giryes R., 2019. Super-resolution via image-adapted denoising cnns: incorporating external and internal learning. IEEE Signal Processing Letters 26 (7), 1080–1084. Venkatakrishnan S. V., Bouman C. A., Wohlberg B., 2013. PnP priors for model based reconstruction. In: IEEE Global Conference on Signal and Information Processing, pp. 945–948. Venkatesh G., Naresh Y., Little S., Oonnor N. E., 2018. A deep residual architecture for skin lesion segmentation. In: Context-Aware Operating Theaters, Computer Assisted Robotic Endoscopy, Clinical Image-Based Procedures, and Skin Image Analysis. Springer, pp. 277–284. Wang X., Yu K., Wu S., Gu J., Liu Y., Dong C., Qiao Y., Loy C. C., 2018. ESRGAN: enhanced super-resolution generative adversarial networks. In: The European Conference on Computer VisionWorkshops. Xu L., Ren J. S., Liu C., Jia J., 2014. Deep convolutional neural network for ima- ge deconvolution. In: Advances in Neural Information Processing Systems, pp. 1790–1798. Yair N., Michaeli T., 2018. Multi-scale weighted nuclear norm image restoration. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 3165– 3174. Zamir S. W., Arora A., Khan S., Hayat M., Khan F. S., Yang M. H., Shao L., 2020. Cycleisp: real image restoration via improved data synthesis. IEEE Conference on Computer Vision and Pattern Recognition.\n--- Страница 639 ---\n638  Методы PnP и глубокой развертки для восстановления изображения Zhang J., Ghanem B., 2018. ISTA-net: interpretable optimization-inspired deep network for image compressive sensing. In: IEEE Conference on Computer Vi- sion and Pattern Recognition, pp. 1828–1837. Zhang K., Zhou X., Zhang H., Zuo W., 2015. Revisiting single image super-resolu- tion under Internet environment: blur kernels and reconstruction algorithms. In: Pacific Rim Conference on Multimedia, pp. 677–687. Zhang K., Zuo W., Chen Y., Meng D., Zhang L., 2017a. Beyond a Gaussian denoiser: residual learning of deep CNN for image denoising. IEEE Transactions on Image Processing, 3142–3155. Zhang K., Zuo W., Gu S., Zhang L., 2017b. Learning deep CNN denoiser prior for image restoration. In: IEEE Conference on Computer Vision and Pattern Rec - ognition, pp. 3929–3938. Zhang K., Zuo W., Zhang L., 2018a. FFDNet: toward a fast and flexible solution for CNN-based image denoising. IEEE TIP 27 (9), 4608–4622. Zhang K., Zuo W., Zhang L., 2018b. Learning a single convolutional super-reso- lution network for multiple degradations. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 3262–3271. Zhang L., Wu X., Buades A., Li X., 2011. Color demosaicking by local directional interpolation and nonlocal adaptive thresholding. Journal of Electronic Imag- ing 20 (2), 1–15. Zhang Y., Li K., Li K., Zhong B., Fu Y., 2019. Residual non-local attention networks for image restoration. In: International Conference on Learning Representa- tions. Zhang Z., Liu Q., Wang Y., 2018. Road extraction by deep residual u-net. IEEE Geoscience and Remote Sensing Letters 15 (5), 749–753. Zhao N., Wei Q., Basarab A., Dobigeon N., Kouamé D., Tourneret J. Y., 2016. Fast single image super-resolution using a new analytical solution for 2-2 problems. IEEE Transactions on Image Processing 25 (8), 3683–3697. Zoran D., Weiss Y., 2011. From learning models of natural image patches to whole image restoration. In: IEEE International Conference on Computer Vision, pp. 479–486. об аВтора Х гЛаВы Кай Чжан получил степень доктора философии в Школе компьютерных наук и технологий Харбинского технологического института, Китай, в 2019 г. С июля 2015 г. по июль 2017 г. и с июля 2018 г. по апрель 2019 г. он работал научным сотрудником в Департаменте вычислительной техники Гонконг - ского политехнического университета. В настоящее время является пост - докторантом в лаборатории Computer Vision Lab, Цюрих, Швейцария, где трудится с профессорами Люком Ван Гулом и профессором Раду Тимофте. Его исследовательские интересы включают машинное обуче ние и обработку изображений. Раду Тимофте получил докторскую степень в области электроники в KU Leuven, Бельгия, в 2013 г. С 2013 по 2016 г. он был постдокторантом в лабо-\n--- Страница 640 ---\nОб авторах главы  639 ратории компьютерного зрения, в Цюрихе, Швейцария. С 2016 г. был руко- водителем группы и преподавателем в той же лаборатории. Также является профессором и заведующим кафедрой компьютерных наук в Вюрцбургском университете, Германия, и лауреатом профессорской премии Александра фон Гумбольдта 2022 г. в области искусственного интеллекта. Член редкол- легии ведущих журналов, таких как IEEE Trans. on Pattern Analysis andMachine Intelligence, Elsevier Neurocomputing, Elsevier Computer Vision and Image Under- standing, SIAM Journal on Imaging Sciences, выступал в качестве председателя на ведущих конференциях, таких как CVPR 2021, IJCAI 2021, ECCV 2020, ACCV 2020, ICCV 2019. Является соучредителем Merantix и соорганизатором меро- приятий NTIRE, CLIC, AIM и PIRM. Его текущие исследовательские интересы включают глубокое обуче ние, неявные модели, сжатие, отслеживание, вос - становление и улучшение изображений.",
      "debug": {
        "start_page": 606,
        "end_page": 640
      }
    },
    {
      "name": "Глава 15. Атаки на визуальные системы и защита от злоумышленников 640",
      "content": "--- Страница 641 --- (продолжение)\nГлава 15 Атаки на визуальные системы и защита от злоумышленников Авторы главы: Чанги О, Алессио Зомперо и Андреа Кавалларо, Центр интеллектуального восприятия, Лондонский университет королевы Марии, Лондон, Соединенное Королевство Краткое содержание главы: постановка проблемы состязательных атак для визуальных задач, исполь- зующих как изображения, так и видео в качестве входных данных; свойства состязательных атак и виды возмущений; описание целевых моделей и наборов данных, используемых в сценариях атаки; обсуждение состязательных атак на системы обработки изображений, классификации изображений, семантической сегментации, обнаружения объектов, отслеживания объектов и классификации видео; обсуждение средств защиты, разработанных против состязательных атак. 15.1. В Ведение Хорошо известно, что глубокие нейронные сети (deep neural networks, DNN) успешно справляются с различными задачами компьютерного зрения, таки- ми как классификация изображений (Krizhevsky et al., 2012; He et al., 2016), обнаружение объектов (Ren et al., 2017; Redmon, Farhadi, 2017), семантиче- ская сегментация (Long et al., 2015; Yu et al., 2017), оценка оптического по- тока (Revaud et al., 2015; Ranjan, Black, 2017) и классификация видео (Carreira, Zisserman, 2017; Jiang et al., 2018; Ng et al., 2015). Однако DNN чувствительны к возмущениям входных данных, которые создают так называемые обманные образцы (adversarial examples), которые мы будем дальше называть обман-\nГлава 15 Атаки на визуальные системы и защита от злоумышленников Авторы главы: Чанги О, Алессио Зомперо и Андреа Кавалларо, Центр интеллектуального восприятия, Лондонский университет королевы Марии, Лондон, Соединенное Королевство Краткое содержание главы: постановка проблемы состязательных атак для визуальных задач, исполь- зующих как изображения, так и видео в качестве входных данных; свойства состязательных атак и виды возмущений; описание целевых моделей и наборов данных, используемых в сценариях атаки; обсуждение состязательных атак на системы обработки изображений, классификации изображений, семантической сегментации, обнаружения объектов, отслеживания объектов и классификации видео; обсуждение средств защиты, разработанных против состязательных атак. 15.1. В Ведение Хорошо известно, что глубокие нейронные сети (deep neural networks, DNN) успешно справляются с различными задачами компьютерного зрения, таки- ми как классификация изображений (Krizhevsky et al., 2012; He et al., 2016), обнаружение объектов (Ren et al., 2017; Redmon, Farhadi, 2017), семантиче- ская сегментация (Long et al., 2015; Yu et al., 2017), оценка оптического по- тока (Revaud et al., 2015; Ranjan, Black, 2017) и классификация видео (Carreira, Zisserman, 2017; Jiang et al., 2018; Ng et al., 2015). Однако DNN чувствительны к возмущениям входных данных, которые создают так называемые обманные образцы (adversarial examples), которые мы будем дальше называть обман-\n--- Страница 642 ---\nОпределение проблемы  641 ными изображениями, побуждающие DNN к ошибочным прогнозам (Szegedy et al., 2014). Исследование изменений данных, предназначенных для обхода классифи- катора, не ново: методы, вводящие классификаторы в заблуждение, обсужда- ются уже более двух десятилетий и включают атаки на системы обнаружения мошенничества (Bolton et al., 2002), спам-фильтры (Meyer, Whateley, 2004) и на конкретные классификаторы, такие как машины опорных векторов (Big- gio et al., 2013). Относительно недавно возрос интерес к обманным образцам для DNN, решающих визуальные задачи (Szegedy et al., 2014). Обманные изображения в области визуальных задач генерируются путем изменения значений пикселей с по мощью тщательно созданного аддитив- ного шума, незаметного для человеческого глаза (Carlini, Wagner, 2017; Jiang et al., 2019); замены полукруглых или прямых областей изображения (Brown et al., 2018; Ranjan et al., 2019) либо границ изображения (Zajac et al., 2019). Обманные изображения помогают исследовать и повышать надежность мо- делей DNN (Tsipras et al., 2019; Allen-Zhu and Li, 2020; Engstrom et al., 2019; Santurkar et al., 2019), а также защищать личную информацию в изображе- ниях (Li et al., 2019; Sanchez-Matilla et al., 2020). Атака противника может быть направленной или ненаправленной. На- правленные атаки модифицируют изображение или видео таким образом, чтобы модель DNN предсказала нужную злоумышленнику метку класса, та- кую как тип объекта (Szegedy et al., 2014), или нужную траекторию объекта в последующих кадрах (Liang et al., 2020). Ненаправленные атаки изменяют исходное изображение или видео, чтобы DNN отнесла его к любому другому классу, отличному от истинного, или сгенерировала неправильные ограни- чивающие рамки, чтобы ввести в заблуждение средство отслеживания (Liang et al., 2020). Наконец, тщательно измененные ключевые признаки могут при- вести к ложному обнаружению или неправильному обнаружению объекта другого типа (Lu et al., 2017). После определения проблемы визуальных состязательных атак (раз - дел 15.2) мы обсудим их основные свойства (раздел 15.3) и типы возмуще- ний, которые они вызывают (раздел 15.4). Затем рассмотрим сценарии атак, модели и наборы данных, используемые для создания состязательных атак (раздел 15.5). В частности, мы рассматриваем состязательные атаки для задач обработки изображений (раздел 15.6), классификации изображений (раз - дел 15.7), семантической сегментации и обнаружения объектов (раздел 15.8), отслеживания объектов (раздел 15.9) и классификации видео (раздел 15.10). Наконец, мы представляем стратегии защиты моделей DNN от этих атак (раздел 15.11) и завершаем главу (раздел 15.12). 15.2. опреде Ление проб Лемы Пусть x – изображение или видео, а y – истинная метка, связанная с x. Метка может быть отдельным классом для классификации изображения или видео, или областью оптического потока для обнаружения либо отслеживания объ- екта.\n--- Страница 643 ---\n642  Атаки на визуальные системы и защита от злоумышленников Пусть f(·) – модель DNN, отображающая x в метку y: y = f(x). Атака модифи- цирует x, чтобы создать обманное изображение x., которое вводит работаю- щую модель в заблуждение, так что f(x) = f(x.) (рис. 15.1). Обманное изображе- ние можно получить, напрямую изменив визуальные данные с возмущением δ таким, что x. = g(x, δ), где g(·) представляет собой процесс добавления воз- мущения к x или замены значений пикселей в x на взятые из δ . f(·) х х х. y.y δf(·) g(·)Обучение ОбучениеЦелевая модель Целевая модель<заяц> <броненосец> Состязательный образец Состязательное возмущение Рис. 15.1  Наглядный пример состязательной атаки на классификатор изо- бражений. Классификатор атакуемой модели присваивает исходному изобра- жению метку «заяц» (вверху), а обманному изображению, полученному с по- мощью атаки базового итеративного метода (Kurakin et al., 2017), та же целевая модель присваивает метку «броненосец» (внизу). Целевая модель представляет собой иллюстративное и абстрактное представление классификатора Inception V3 (Szegedy et al., 2016), обученного в ImageNet (Deng et al., 2009). Стоит от - метить, что в целях наглядности показанное здесь направленное возмущение в 20 раз больше, чем реальное Обманное возмущение может быть создано с по мощью машинного обуче- ния. В таком случае злоумышленник может разработать функцию потерь ℒ(x, y), которая используется для генерации прогноза входного сигнала от - носительно правильного прогноза (Goodfellow et al., 2015; Moosavi-Dezfooli et al., 2016; Jiang et al., 2019; Shamsabadi et al., 2020c; Liang et al., 2020). На- пример, потеря с точки зрения атакующего может максимизировать ошибку классификации для набора обучающих изображений (Szegedy et al., 2014; Moosavi-Dezfooli et al., 2016; Hosseini, Poovendran, 2018) или может опти-\n--- Страница 644 ---\nСвойства состязательной атаки  643 мизировать функцию потерь с по мощью дополнительной цели изменения изобра жения с незаметным возмущением (Szegedy et al., 2014; Goodfellow et al., 2015; Moosavi-Dezfooli et al., 2016; Modas et al., 2019; Shamsabadi et al., 2020). Основываясь на информации о целевой модели f(·) и/или ее прогнозах y, доступных злоумышленнику, атаку можно классифицировать как белый ящик или черный ящик. При атаке белого ящика злоумышленник имеет полный доступ к целевой модели (конкретной архитектуре, ее параметрам и/или обучающим данным) и пользуется им для непосредственного создания воз- мущения. Параметры белого ящика помогают обнаружить ограничения обучен ной модели и оценить их надежность. При атаке методом черного ящика злоумышленник не имеет прямого доступа к архитектуре или пара- метрам целевой модели. Атаки методом черного ящика более реалистичны, поскольку модели (или даже их выходные данные) чаще всего недоступны в реальных ситуациях. При атаке методом черного ящика злоумышленник может не иметь доступа к выходным данным f(·) и, следовательно, никакой информации об y (атака без вывода), или иметь доступ только к метке y (клас - сы), сгенерированной обманными образцами, поданными в классификатор f(·) (атака с выводом метки), или только к значениям нейронов до последнего слоя, а именно к логитам/вероятностям обманных образцов, представленных классификатору (атака с распределением-выводом). 15.3. сВойст Ва состязате Льной атаКи Атаки со стороны противника можно оценить на основе четырех основных характеристик, а именно эффективности, робастности, переносимости и за- метности. Эффективность состязательной атаки – это степень, в которой ей удается ввести в заблуждение модель машинного обуче ния. Эффективность можно измерить как точность модели f(·) на целевом наборе данных. Чем ниже точ- ность, тем выше эффективность атаки противника. Робастность (устойчивость) состязательной атаки – это ее эффективность при наличии защиты, которая устраняет влияние δ до того, как данные будут обработаны моделью f(·). Примеры защиты включают медианную фильтра- цию (Xu et al., 2018), повторное квантование (Xu et al., 2018) и сжатие JPEG (Das et al., 2017; Dziugaite et al., 2016; Guo et al., 2018). Робастность может быть измерена как разница в точности f(·) на целевом наборе данных, когда за- щита используется по отношению к ситуации, когда защита не используется. Чем меньше эта разница, тем выше устойчивость атаки. Переносимость атаки противника – это степень, в которой возмущение δ, созданное для модели f(·), эффективно для введения в заблуждение дру - гой модели f¢(·), не применявшейся для создания δ. Переносимость может быть измерена как разница в точности f(·) и f¢(·) на целевом наборе данных обманных образцов, созданных для f(·). Чем меньше эта разница, тем выше переносимость атаки на классификатор f ¢(·).\n--- Страница 645 ---\n644  Атаки на визуальные системы и защита от злоумышленников Заметность состязательной атаки – это степень, в которой злонамерен- ное возмущение δ может быть замечено как таковое человеком, смотрящим на изображение или видео. Заметность можно измерить с по мощью теста двойного воздействия, в котором сравниваются пары изображений или ви- деоклипов {(x , x.)}; однократного теста на естественность изображения или видеофрагмента {x.}, проверяемого по результатам, полученным с соответ - ствующим {x }; или с (надежной) мерой качества восприятия без эталона. В дополнение к этим четырем основным свойствам при анализе или оценке состязательных атак для конкретных задач или целей могут учи- тываться и другие свойства, такие как обнаруживаемость и обратимость. Обнаруживаемость атаки со стороны – это степень, в которой защитный механизм способен заметить, что возмущение было преднамеренно при- менено для изменения исходного изображения, видео или сцены. Обна- руживаемость, которая связана с робастностью, может быть измерена как доля обманных изображений, которые обнаруживаются как таковые в за- данном наборе данных или заданных сценариях. Обнаруживаемость атаки можно оценить путем сравнения выходных данных f(·) на заданных вход- ных данных и на тех же входных данных, предварительно обработанных защитой, поскольку разные выходные данные предполагают наличие ата- ки. Наконец, обратимость состязательной атаки – это степень, в которой анализ предсказаний или выходных меток f(·) позволяет извлечь исходный класс x Например, анализ частоты сопоставления состязательного и ис - ходного предсказаний показал, что нецелевые атаки более обратимы, чем целевые (Li et al., 2021). 15.4. типы Возмущений Злонамеренное возмущение может быть глобальным или локальным в за- висимости от пространственного распределения δ, а также ограниченным или неограниченным в зависимости от количества изменений, вызванных интенсивностью пикселей. Глобальные возмущения изменяют интенсивность каждого пикселя в от - дельности и, таким образом, генерируют сильный пространственно-частот - ный шум. Природа этих возмущений делает их уязвимыми для средств за- щиты (например, медианной фильтрации или сжатия JPEG) (Dziugaite et al., 2016). Глобальные возмущения могут быть разреженными (Papernot et al., 2016b) или плотными (Goodfellow et al., 2015). Крайним случаем являет - ся однопиксельное возмущение, которое изменяет один пиксель исходного изображения (Su et al., 2019). Возмущения области применяются к областям изображения, таким как рамка вокруг границы изображения, семантическая область или прямо- угольный или круглый патч. Злонамеренные патчи чрезвычайно заметны для целевой модели f(·) (Brown et al., 2018; Ranjan et al., 2019). Выбранными областями также можно манипулировать в зависимости от их ожидаемой значимости для зрительной системы человека (Shamsabadi et al., 2020c).\n--- Страница 646 ---\nСценарии атаки  645 Ограниченные возмущения лимитируют величину изменения значения каждого пикселя (Goodfellow et al., 2015) или изображения (Szegedy et al., 2014), как правило, с ограничением ℓp-нормы. Граница возмущения может быть определена параметром ϵ таким, что ||x – x.||p < ϵ (Carlini, Wagner, 2017; Goodfellow et al., 2015; Moosavi-Dezfooli et al., 2016; Modas et al., 2019). Ис - пользование нормы ℓ2 (||.|| 2) ограничивает максимальное изменение энер- гии (Moosavi-Dezfooli et al., 2016), тогда как использование нормы ℓ∞ (||.||∞) ограничивает максимальное изменение для каждого пикселя (Kurakin et al., 2017; Li et al., 2019). Ограниченные возмущения, как правило, имеют огра- ниченную переносимость (Xie et al., 2019) и ограниченную устойчивость к средствам защиты (Xu et al., 2018). Неограниченные возмущения не ограничивают изменения интенсивности или области атаки, что часто приводит к заметно искаженным обманным образцам (Hosseini, Poovendran, 2018). Чтобы уменьшить (или избежать) ар- тефакты, неограниченные возмущения на основе контента манипулируют низкоуровневыми признаками изображения, такими как цвет, текстура или края, и обеспечивают более высокую переносимость и надежность (Bhattad et al., 2020; Shamsabadi et al., 2020b). 15.5. сценарии атаКи Мы сгруппировали модели, на которые нацелены атаки злоумышленников в задачах обработки изображений и компьютерного зрения, а также соот - ветствующие наборы данных, используемые для создания и оценки этих атак на изображения и видео. В табл. 15.1 и 15.2 приведены основные характерис - тики состязательных атак на изображения или видео. 15.5.1. Целевые модели Целевая модель DNN имеет определенную архитектуру, состоящую из слоев, параметры которых изучаются. Количество слоев определяет глубину модели DNN. Увеличение глубины архитектуры DNN приводит к увеличению коли- чества параметров, и, следовательно, для изучения значений параметров во время обуче ния требуется крупномасштабный набор данных (более миллио- на изображений). Последние слои могут предсказывать логиты, т. е. значения в диапазоне (–∞, +∞), или вероятности (значения в диапазоне [0,1]) предска - занных меток либо конечных меток. Поскольку не все слои (например, слои пулинга) имеют обучаемые параметры, в этой главе мы будем использовать термин «слой» только для тех из них, у которых есть обучаемые параметры (например, сверточные и полносвязные слои). Атакованными (целевыми) моделями являются LeNet, AlexNet, VGGNets, GoogleNet и варианты ResNets и WideResNets, DenseNets и MobileNets для классификации изображений; FCN, HED и Faster R-CNN для семантической сегментации, обнаружения границ и обнаружения объектов соответствен-\n--- Страница 647 ---\n646  Атаки на визуальные системы и защита от злоумышленников Таблица 15.1. Сводка существующих состязательных атак для задач, использующих изображения в качестве входных данных. Обозначения: ○ – белый ящик, ● – черный ящик, T – целевая, T— – нецелевая, B – ограниченная, B— – неограниченная, Opt – на основе оптимизации, Grad – на основе градиента, Bound – граничное приближение, GradE – градиентная оценка, LocS – локальный поиск, RanS – случайный поиск, C – классификация, S – семантическая сегментация, D – обнаружение объектов, IC – подписи к изображениям, E – обнаружение границ Источник Метод Ящик T T—BB—Подход Набор данных Задача (Szegedy et al., 2014) L-BFGS ○ ✓✓ ✓ Opt ImageNet, MNIST, Youtube C (Carlini, Wagner, 2017) CW ○ ✓✓ ✓ Opt MNIST, CIFAR C (Goodfellow et al., 2015) FGSM ○ ✓✓ ✓ Grad MNIST C (Kurakin et al., 2017b) BIM (I-FGSM) ○ ✓✓ ✓ Grad ImageNet C (Madry et al., 2018) PGD ○ ✓✓ ✓ Grad MNIST, CIFAR C (Papemot et al., 2016b) JSMA ○ ✓✓ ✓ Grad MNIST C (Moosavi-Dezfooli et al., 2016)DeepFool ○ ✓ ✓ Grad ImageNet, MNIST, CIFAR C (Modas et al., 2019) SparseFool ○ ✓ ✓ Grad ImageNet, MNIST, CIFAR C (Xie etal., 2019) di2-fgsm ○, ● ✓✓ ✓ Grad ImageNet C (Tramer et al., 2018) E-FGSM ○, ● ✓ ✓ Grad ImageNet C (Li et al., 2019a) P-FGSM ○ ✓ ✓ Grad Places C (Sanchez-Matilla et al., 2020)RP-FGSM ○ ✓✓ ✓ Grad Places C (Moosavi-Dezfooli et al., 2017)DAP ○ ✓ ✓ Opt ImageNet C (Mopuri et al., 2017) Быстрый обман признаков ○ ✓ ✓ Opt ImageNet, Places-205 C (Baluja, Fischer, 2018) ATN ○ ✓✓ ✓ Opt ImageNet, MNIST C (Xiao et al., 2018) AdvGAN ○, ● ✓✓ ✓ Opt ImageNet, MNIST C (Poursaeed et al., 2018) GAP o ✓✓ ✓ Opt ImageNet, Cityscapes C, S (Mopuri et al., 2018) NAG ○, ● ✓ ✓ Opt ImageNet C (Bhattad et al., 2020) Семантическая манипуляция○ ✓ ✓ Opt ImageNet, MSCOCO C, IC (Shamsabadi et al., 2020a) EdgeFool ○ ✓ ✓ Opt ImageNet, Places C\n--- Страница 648 ---\nСценарии атаки  647(Papemot et al., 2016a) SBA ● ✓✓ ✓ Bound MNIST C (Shi et al., 2019) Curls & Whey ● ✓✓ ✓ Bound ImageNet C (Dong et al., 2019) Атака TI ● ✓ ✓ Bound ImageNet C (Chen et al., 2017) ZOO ● ✓✓ ✓ GradE ImageNet, MNIST, CIFAR C (Ilyas et al., 2018) Атака с ограничением запроса● ✓ ✓ GradE ImageNet C (Tu etal., 2019) AutoZOOM ● ✓✓ ✓ GradE ImageNet, MNIST, CIFAR C (Narodytska, KasiViswanathan, 2017)LocSearchAdv ● ✓✓ ✓ GradE ImageNet, MNIST, CIFAR, SVHN, STLC (Brendel et al., 2018) BA ● ✓✓ ✓ LocS ImageNet, MNIST, CIFAR C (Guo et al., 2019) SimBA ● ✓✓ ✓ LocS ImageNet C (Hosseini, Poovendran, 2018)SemanticAdv ● ✓✓ ✓ RanS CIFAR C (Shamsabadi et al., 2020c) ColorFool ● ✓ ✓ RanS ImageNet, CIFAR, Places C (Fischer et al., 2017) SSA ○ ✓ ✓ Grad Citvscapes S (Xie etal., 2017) DAG ○ ✓ ✓ Grad voc S,D (Wei et al., 2019) UEA ○, ● ✓ ✓ Opt ImageNet VID D (Cosgrove, Yuille, 2020) Граничная атака ○ ✓✓ ✓ Grad Cityscapes E Таблица 15.2. Сводка существующих состязательных атак для задач, использующих видео в качестве входных данных. Обозначения: ○ – белый ящик, ● – черный ящик, T – целевая, T— – нецелевая, DD – зависимость ввода данных, U – универсальная, B – неограниченный, B— – ограниченная, R – региональная, Gen – генеративная, Opt – оптимизация, C – классификация видео, ME – оценка движения, OT – отслеживание объектов Источник Метод Ящик T T—DD U B B—R Подход Набор данных Задача (Ranjan et al., 2019) OFA ○, ● ✓ ✓ ✓ ✓ Opt KITTI ME (Liang et al., 2020) FAN ○, ● ✓ ✓ ✓ Gen OTB, VOT OT (Jiang et al., 2018) V-BAD ● ✓ ✓ ✓ Opt DCF, HMDB, Kinetics C (Li et al., 2019) C-DUP ○ ✓ ✓ Gen UCF, JESTER C (Lo, Patel, 2020) MultAV ○ ✓ ✓ ✓ ✓ ✓ ✓ ✓ Direct, Opt UCF C\n--- Страница 649 ---\n648  Атаки на визуальные системы и защита от злоумышленников но; C3D, CNN+LSTM, I3D и 3D ResNet-18 для классификации видео; SiamFC, SiamRPN , SiamRPN+CIR и SiamRPN++ для визуального отслеживания объ- ектов; FlowNet, FlowNet2, SpyNet, PWC-Net и Back2Future для оценки движе- ния. Мы также включили две модели, отличные от DNN, а именно Epic Flow и LDOF, для оценки оптического потока. 15.5.1.1. Модели для задач, связанных с изображениями LeNet – это сверточная нейронная сеть (CNN) с 3 слоями свертки и 2 полно- связными слоями для распознавания изображений (LeCun et al., 1998). AlexNet имеет 8 сверточных слоев и 3 полносвязных слоя, а архитектура модели аналогична LeNet (Krizhevsky et al., 2012). VGGNet имеет более глубокую архитектуру с 16 и 19 уровнями, но ядра сверточных фильтров меньшего размера, поскольку несколько небольших сверточных фильтров с меньшим количеством параметров превосходят один большой фильтр (Simonyan, Zisserman, 2014). GoogLeNet (Inception-v1) имеет 22 слоя (учитываются только слои с па- раметрами), и 9 из этих слоев состоят из сверточных фильтров нескольких размеров (начальный слой/модуль), что снижает вычислительные затраты и ресурсы архитектуры (Szegedy et al., 2015). Inception-v2 и Inception-v3 (Sze- gedy et al., 2016) и Inception-v4 (Szegedy et al., 2017) – это варианты, которые дополнительно повышают точность и снижают вычислительную сложность. Улучшения включают разложение фильтров на стек фильтров меньшего раз- мера, увеличение количества фильтров и их размера в каждой модели (шире, а не глубже), сглаживание меток (член регуляризации для снижения доверия сети к классу), добавление блоков редукции и упрощение различных моду - лей (например, за счет выбора разного количества фильтров и их размера). Блоки редукции представляют собой сверточные слои 1×1, также известные как проекционные слои, которые выполняют объединение карт признаков по измерению канала, что приводит к уменьшению размерности. ResNet может иметь 18, 50, 101 или 150 слоев. Блоки слоев сгруппированы для изучения функции, которая сопоставляет входные данные с выходными в виде остаточного отображения (He et al., 2016). DenseNet имеет архитектуры со 121, 169, 201 и 264 слоями, чьи плотные блоки могут содержать от 12 до 128 сверточных слоев. DenseNet расширяет остаточное отображение ResNet, предоставляя карты признаков всех пре- дыдущих слоев в блоке в качестве входных данных для последующих слоев в том же блоке (плотное соединение), чтобы уменьшить количество парамет - ров, улучшить поток информации и градиенты по всей сети и уменьшить переобучение (Huang et al., 2017). MobileNet имеет 28 уровней и два гиперпараметра, которые регулируют ширину сети на каждом уровне и разрешение входного изображения (Howard et al., 2017). Первые 13 слоев представляют собой разделимые по глубине слои свертки, которые разбивают стандартный слой свертки на два слоя: от - дельный слой для фильтрации и отдельный слой для объединения результи- рующего вывода. Эта факторизация уменьшает объем вычислений и размер модели. Архитектуру можно дополнительно уменьшить, удалив слои.\n--- Страница 650 ---\nСценарии атаки  649 WideResNet имеет более высокую точность, чем ResNet, в задачах клас - сификации изображений с более мелкой архитектурой и большей шириной остаточных блоков (Zagoruyko, Komodakis, 2016). Полностью сверточные сети (fully convolutional networks, FCN) использу - ют модели CNN, такие как AlexNet, VGGNet и GoogleNet, для классификации изображений, но заменяют полносвязные слои сверточными слоями, за ко- торыми следует слой повышающей дискретизации (Long et al., 2015), таким образом создавая выходную карту признаков того же размера, что и входная. Из-за этого FCN можно обучить сквозной (семантической) сегментации. Целостно-вложенный детектор краев (holistically-nested edge detector, HED) – это архитектура на основе FCN, которая использует средний пул для обнаружения краев (Xie, Tu, 2015). Faster R-CNN – это архитектура на основе FCN, которая учится генериро- вать объекты-кандидаты с последующей локализацией и классификацией объектов среди кандидатов (Ren et al., 2017). Faster R-CNN состоит из пред- варительно обученных слоев свертки, таких как 13 слоев свертки VGGNet, где выходные данные подаются в небольшую сеть с двумя слоями свертки, которая выводит признаки более низкой размерности. Эти признаки, каж - дый из которых представляет объект-кандидат, затем передаются в два не- зависимых полносвязных слоя, чтобы найти расположение ограничивающих рамок и классы для объектов-кандидатов. 15.5.1.2. Модели для видеозадач CNN+LSTM – это классификатор видео, который применяет 2D-архитектуры (например, AlexNet или GoogleNet) к каждому кадру независимо, используя общие параметры во времени, а затем учится интегрировать информацию во времени с по мощью рекуррентной нейронной сети, основанной на LSTM, работающей на активациях CNN на уровне кадра (Ng et al., 2015). Комби- нация LSTM с 2D-сетями позволяет классификатору видео поддерживать постоянное количество параметров при извлечении глобального описания временной эволюции видео. C3D – это пространственно-временной класси- фикатор с 8 трехмерными сверточными слоями и 2 полносвязными слоями (Tran et al., 2015). C3D может обрабатывать 16 кадров для распознавания действий. Inflated 3D CNN (I3D) – это пространственно-временная архитектура, по- строенная на основе 2D DNN для классификации изображений (например, InceptionV1), которая объединяет выходные данные двух 3D CNN, одна из которых обрабатывает группу кадров RGB, а другая – группу предсказаний оптического потока среди последовательных кадров RGB (Carreira, Zisserman, 2017). I3D расширяет (inflate) фильтры и операции объединения с 2D на 3D. Модель I3D также может использовать предварительно обученные веса из 2D-моделей в качестве инициализации перед точной настройкой. 3D ResNet – это пространственно-временная архитектура, которая, подоб- но I3D, расширяет модели ResNet на основе изображений во временную об- ласть с использованием 3D CNN (Hara et al., 2018). Дополнительные модели, такие как WideResNet и DenseNet, могут быть расширены с по мощью 3D CNN.\n--- Страница 651 ---\n650  Атаки на визуальные системы и защита от злоумышленников SiamFC использует полностью сверточную сиамскую архитектуру, состо- ящую из двух сверточных нейронных сетей с одинаковыми параметрами. SiamFC обучен прогнозировать карту сходства между целевым шаблоном (или эталонным патчем) и областью поиска в текущем изображении посред- ством взаимной корреляции функций, выдаваемых двумя ветвями. Эталон- ный патч предоставляется или инициализируется в первом кадре (Bertinetto et al., 2016). SiamRPN основана на сиамской архитектуре для извлечения признаков из шаблона и области поиска. В SiamRPN добавлена сеть прогнозов по регионам, состоящая из двух ветвей, одной для классификации переднего и заднего планов, а другой для регрессии, основанной на парной взаимной корреляции (Li et al., 2018). SiamRPN++ – это улучшенная версия SiamRPN, использующая стратегию выборки с учетом пространства, которая обеспечивает строгую трансляци- онную инвариантность, поскольку заполнение, введенное в DNN, наруша- ет инвариантность. Кроме того, в SiamRPN++ добавлен уровень взаимной корреляции по глубине, который прогнозирует многоканальные признаки корреляции между шаблоном и патчами поиска, используя структуру ResNet (Li et al., 2019). SiamRPN+CIR добавляет блоки Cropping-Inside Residual (CIR), чтобы устранить базовое смещение положения, вызванное заполнением нулями. SiamRPN+ CIR применяет блоки CIR к различным глубоким и широким се- тям, таким как ResNet и Inception, при использовании в SiamFC и SiamRPN (Zhang, Peng, 2019). FlowNet – это автокодировщик с 9 сверточными слоями и корреляци- онным слоем, который выполняет мультипликативное сравнение патчей между двумя картами признаков. Пары изображений произвольного размера предоставляются в качестве входных данных для двух ветвей архитектуры и объединяются со слоем корреляции. Часть декодера имеет 4 слоя обратной свертки, которые выполняют расширение карт признаков и объединение с картами признаков из кодировщика для уточнения деталей изображения оптического потока (Dosovitskiy et al., 2015). FlowNet2 объединяет несколько архитектур FlowNet для повышения точ- ности оценки оптического потока как при малых, так и при больших смеще- ниях. Первой сетью является FlowNet, а в стековых сетях используется одна ветвь, вход которой определяется конкатенацией потока, сформированного предыдущей сетью с двумя изображениями – искаженным изображением, основанным на оптическом потоке, и ошибкой яркости. Последний этап FlowNet2 объединяет выходные данные стековых сетей с выходными данны- ми автокодировщика для получения окончательного потока (Ilg et al., 2017). SpyNet (spatial pyramid network, сеть пространственных пирамид) сочетает в себе стратегию «от грубого к точному», основанную на формуле простран- ственной пирамиды, со сверточными нейронными сетями для оценки боль- ших движений внутри пирамиды изображения. Для каждого уровня пирами- ды сверточная нейронная сеть обновляет вычисленный оптический поток, поскольку одно изображение пары переносится вычисленным оптическим потоком на более грубом уровне (Ranjan, Black, 2017).\n--- Страница 652 ---\nСценарии атаки  651 PWC-Net также представляет собой архитектуру «от грубого к точному», которая заменяет пирамиду изображений пирамидой признаков. На каждом уровне пирамиды PWC-Net добавляет слой, который переносит признаки от второго изображения к первому изображению, используя поток с повы- шенной дискретизацией, и слой корреляции между признаками первого и второго изображений для вычисления стоимости ассоциирования пикселя с соответствующими пикселями в следующем кадре (Sun et al., 2018). Back2Future – это архитектура «от грубого к точному», которая использует как изображения, так и пирамиды признаков из трех последовательных кад- ров (прошлого, настоящего и будущего) и обучается без учителя с фотомет - рическими потерями. Формула мультикадра учитывает окклюзии и позво- ляет добавить модель линейного движения в качестве мягкого временного ограничения (Janai et al., 2018). Epic Flow – это классический подход к вычислению оптического потока, который выполняет плотное сопоставление путем интерполяции с сохране- нием границ из разреженного набора совпадений с последующей минимиза- цией вариационной энергии, инициализируемой плотными совпадениями. Интерполяция «от разреженного к плотному» основывается на геодезиче- ском расстоянии с учетом границ, адаптированном для обработки окклюзий и границ движения (Revaud et al., 2015). LDOF – это классический подход к вычислению оптического потока, кото- рый сочетает в себе сопоставление локальных дескрипторов (то есть векто- ров признаков, извлеченных из локальной области вокруг локализованных точек внимания, таких как угловые точки) с вариационными методами, ос - нованными на переносе изображения и минимизации энергии. Этот подход может обрабатывать быстрые движения различных частей тела (Brox, Malik, 2011). 15.5.2. Наборы данных и метки Далее мы опишем основные характеристики наборов данных (и их анно- таций), используемых для создания злонамеренных изображений и видео. К наборам данных изображений относятся MNIST, SVHN, CIFAR-10, STL-10, ImageNet, Places, COCO. В наборы видеоданных входят наборы данных рас - познавания действий, используемые для классификации видео, отслежива- ния визуальных объектов и оценки движения. Это наборы данных KITTI, UCF, JESTER, HMDB, Kinetics и два бенчмарка для отслеживания (и их варианты): Object Tracking Benchmark (OTB) (Wu et al., 2015) и Visual Object Tracking (VOT). 15.5.2.1. Наборы данных изображений MNIST (Modified National Institute of Standards and Technology) содержит 60 000 обучающих и 10 000 тестовых изображений (28×28, оттенки серого) рукописных цифр (LeCun, 1998). SVHN (Street View House Numbers) содержит 600 000 изображений Google Street View с небольшими обрезанными цифрами (Netzer et al., 2011).\n--- Страница 653 ---\n652  Атаки на визуальные системы и защита от злоумышленников CIFAR-10 (Canadian Institute for Advanced Research-10) имеет 50 000 обучаю- щих и 10 000 тестовых изображений 32×32, разбитых на 10 классов, таких как самолет, автомобиль, птица, кошка, олень, собака, лягушка, лошадь, корабль, грузовик (Krizhevsky et al., 2009). STL-10 содержит 500 обучающих изображений, по 800 тестовых изобра- жений на класс, и 100 000 немаркированных изображений в рамках тех же 10 классов, что и CIFAR-10. Цветовое разрешение изображения составляет 96 цветов (Coates et al., 2011). ImageNet содержит 14 197 122 изображения RGB, разбитых на 1000 классов (Deng et al., 2009). Существует миниатюрная версия ImageNet, которая со- держит 120 000 изображений из 200 классов с размером 64. Places имеет две ориентированные на сцены версии: Places-205, которая содержит 2 448 873 изображения и 205 категорий сцен, и Places-365, в кото- рой 1 800 000 изображений и 365 категорий сцен (Zhou et al., 2017). COCO (Common Objects In Context) содержит 330 000 изображений, из ко- торых более 200 000 семантически помечены для обнаружения объектов, се- мантической сегментации, классификации изображений и оценки ключевых точек (Lin et al., 2014). F-MNIST (Fashion MNIST) содержит 60 000 обучающих и 10 000 тестовых изображений глубиной 28 градаций серого с меткой для 10 видов одежды, та- ких как футболка, брюки, пуловер, платье, пальто, сандалии, рубашка, крос - совки, сумка и высокий ботинок (Xiao et al., 2017). VOC (PascalVOC) использовался для нескольких тестов классификации изображений, обнаружения объектов и семантической сегментации, та- ких как VOC2007 и VOC2012 (Everingham et al., 2015). VOC2007 состоит из 9963 изображений с 24 640 аннотированными объектами из 20 классов. VOC2012 состоит из 11 530 обучающих/проверочных изображений, содер- жащих 27 450 аннотированных объектов (ограничивающий прямоугольник) и 6929 сегментов из 20 классов. LFW (Labeled Faces in the Wild) состоит из более чем 13 000 фотографий лиц, помеченных именем изображенного человека (Huang et al., 2008). Набор данных содержит одну или несколько отдельных фотографий для 1680 че- ловек. BSDS500 содержит 500 естественных изображений с аннотациями, нари- сованными людьми для определения границ (Martin et al., 2004). 15.5.2.2. Наборы видеоданных Cityscapes состоит из стереоскопических видеопоследовательностей с улиц 50 городов и включает 5000 изображений с аннотациями высокого качества на уровне пикселей и 20 000 дополнительных изображений с грубыми анно- тациями (Cordts et al., 2016). HAR (Human Activity Recognition, распознавание деятельности человека) содержит 30 субъектов, выполняющих повседневную деятельность с закреп- ленным на талии смартфоном со встроенными инерциальными датчиками (Anguita et al., 2013). Каждому участнику было предложено дважды выпол- нить разработанный протокол действий, включающий 6 действий, а именно\n--- Страница 654 ---\nСценарии атаки  653 ходьбу, подъем по лестнице, спуск по лестнице, сидение, стояние и лежание. Выполнение протокола занимает в общей сложности 192 секунды. UAV содержит 123 последовательности (всего 110 000 кадров), снятые с беспилотных летательных аппаратов на малой высоте для отслеживания объектов (Mueller et al., 2016). KITTI состоит из 389 сцен (пар изображений), разделенных на наборы для обуче ния и тестирования, статической среды, снятой камерой, установлен- ной на движущейся машине (Geiger et al., 2012). Учебный набор включает в себя разреженные аннотации потока между двумя изображениями. UCF содержит 13 320 роликов на YouTube из 101 грубой категории челове- ческих действий, разделенных на 25 групп (по 4–7 клипов в каждой группе) и имеющих общие атрибуты, такие как одинаковый фон или действующие лица (Soomro et al., 2012). В наборе данных есть различные движения камеры, масштабы объектов, условия освещения, фоны и действующие лица. JESTER содержит 148 092 видеоклипа (в среднем продолжительностью 3 секунды) с детализированными человеческими жестами, разделенными на 27 категорий и исполненными в общей сложности 1376 актерами. Примеры жестов: увеличение двумя пальцами, вытягивание руки и смахивание вправо (Materzynska et al., 2019). HMDB содержит 6766 видеоклипов различных действий, разделенных на 51 категорию (около 100 клипов в каждой категории) и 5 типов, таких как об- щие мимические действия (например, улыбка), мимические действия с ма- нипулированием предметами (например, курение), общие движения тела (например, стойка на руках), движения тела при взаимодействии с объектом (например, обливание) и движения тела для взаимодействия с человеком (например, фехтование) (Kuehne et al., 2011). Kinetics содержит 306 245 клипов с 400 человеческими действиями, вклю- чая действия одного человека, взаимодействия человек–человек и человек– объект, изображающие различных действующих лиц и большие вариации фона, освещения, перспективы и выполнения действий (например, скорость и позы). (Кей и др., 2017). Каждая категория действий содержит от 400 до 1000 видеоклипов, продолжительность которых составляет около 10 с. OTB (или OTB-2015) содержит 100 коротких видеороликов с покадровыми аннотациями ограничивающих рамок и 11 атрибутов, таких как изменение освещения и масштаба, окклюзия, деформация нежесткого объекта или от - сутствие его в поле зрения (Wu et al., 2015). OTB-13, первый выпуск, содержал 51 последовательность. VOT1 содержит 60 видеороликов из менее чем 1500 кадров со скоростью 30 кадров в секунду с различными животными, людьми или движущимися объектами, часто снятыми с по мощью движущейся камеры. Примеры сцен включают человека, несущего книгу, гимнастику, движущихся муравьев, ле- тающих птиц, движущиеся дроны, едущую по дороге машину, рыбу в резер- вуаре с водой, людей, играющих в баскетбол, футбол и гандбол. Доступны покадровые аннотации повернутых ограничивающих рамок, масок сегмен- тации и атрибутов. 1 https://www.votchallenge.net.\n--- Страница 655 ---\n654  Атаки на визуальные системы и защита от злоумышленников 15.6. обработ Ка изображений В этом разделе мы обсудим состязательные атаки, направленные на вводя- щие в заблуждение операции обработки изображений, такие как обнаруже- ние границ (Cosgrove, Yuille, 2020) и оценка движения (Ranjan et al., 2019). Граничная атака (edge attack) создает злонамеренные возмущения для модели обнаружения границ на основе CNN – HED (Xie and Tu, 2015). HED обучается на наборе BSDS500 и объединяет карты признаков, извлеченные из каждого слоя свертки, чтобы классифицировать, принадлежит каждый пиксель изображения границе объекта или нет. Граничная атака вычисляет функцию потерь для обнаружения краев и создает возмущения, которые максимизируют градиент функции потерь (Goodfellow et al., 2015). Атака оптического потока (optical flow attack, OFA) (Ranjan et al., 2019) направлена на то, чтобы нарушить две последовательные пары изображений (xk, xk+1) в видео таким образом, чтобы метки, связанные с оптическим по- током, т. е. чтобы векторы смещения (u , v), были предсказаны неправильно (нецелевая атака). Из-за ограниченной доступности наборов данных с плот - ными аннотациями оптического потока OFA использует прогнозирование оптического потока модели f(·) в качестве псевдоаннотации для самоконтро- ля изучения обманного возмущения δ на основе области (например, кругло- го пятна). OFA применяет (например, вставляет на изображение) изученный патч. В дополнение к возмущению небольшого числа пикселей в паре по- следовательных изображений OFA ограничивает возмущение квазинезамет - ностью, так что ||xk – x. k||0 + ||x k+1 – x. k+1||0 < ϵ, (15.1) где ϵ – малая постоянная (ограниченное возмущение), в то время как прог - нозируемый выход модели оптического потока f(·, ·) на возмущенных изо- бражениях существенно меняется, т. е. ||f(xk, xk+1) – f(x. k, x. k+1)|| > E, (15.2) где E – большая константа. Таким образом, обманный патч изучается как (15.3) с (u, v) = f(xk, xk+1), (15.4) (u., v.) = f(g(xk, δ, l, t(δ)), g (xk+1, δ, l, t(δ))), (15.5) где δ – обманный патч, l – местоположение пикселя, выбранное из всех местоположений Ω на изображении, g(·) – оператор, заменяющий пиксели изображения значениями δ в местоположении l, t(δ) – двумерное преоб- разование, выбранное из набора преобразований 𝒯 (или их комбинации)\n--- Страница 656 ---\nКлассификация изображений  655 и примененное к обманному патчу δ, а (u., v.) – оптический поток, возникаю- щий в результате атак изображений с по мощью обманного патча. OFA работает с различными типами моделей оптических потоков, такими как классические (Epic Flow, LDOF), архитектуры на основе автоэнкодера (FlowNet, FlowNet2) и архитектуры на основе изображений-пирамид (SpyNet, PWC-Net, Back2Future) – в сценарии «белого ящика». В таком сценарии OFA изучает конкретный злонамеренный патч для каждой модели независимо и разных размеров, в то время как универсальный злонамеренный патч из- влекается из некоторых моделей и применяется к входным видео в сравне- нии с другими моделями в сценарии черного ящика. В обоих сценариях ата- ка на модели автокодировщика затрагивает большие области изображения даже при небольшом размере патча (0,1 % от разрешения изображения). В то же время некоторые другие типы моделей более устойчивы к такой атаке. 15.7. К Лассифи Кация изображений В этом разделе мы обсудим и систематизируем обманные образцы для за- дачи классификации изображений. 15.7.1. Белый ящик, ограниченные атаки Ограниченные атаки на белый ящик обычно генерируют возмущения с огра- ничением ℓp-нормы, так что искажение полученного состязательного образ- ца незаметно для людей. L-BFGS (Szegedy et al., 2014), чтобы ввести в заблуждение классификатор, использует обманные изображения, которые состоят из незаметных состя- зательных возмущений, добавленных к нормализованному входу x Î [0, 1]. Атака L-BFGS решает задачу оптимизации с ограничениями, целью которой является нахождение x. Î [0, 1] с ограничением по норме ℓ 2: c||x. – x||2 + L(x., y.), (15.6) где c – это гиперпараметр, а ℒ(x., y.) – потеря перекрестной энтропии, которая измеряет разницу между меткой y, предсказанной целевым классификато- ром на основе обманных входных данных, и меткой целевой ошибочной классификации y Эта потеря побуждает атаку генерировать x., способный ввести в заблуждение целевой классификатор. Атака Карлини–Вагнера (CW) (Carlini, Wagner, 2017) генерирует возмущение, ограниченное ℓp-нормой, путем решения задачи оптимизации с ограничениями, аналогичной L-BFGS. Эта атака минимизирует потери в рамках ограничений ℓp-нормы, которые измеряют разницу между логит-значением z. y образца x., принадлежащим тому же классу y предсказания по x, и максимальным логит-значением среди всех остальных классов: (15.7)\n--- Страница 657 ---\n656  Атаки на визуальные системы и защита от злоумышленников где D – общее количество меток p Î {0, 2, ∞}, а c > 0 – константа, определяе- мая с по мощью линейного поиска для нахождения оптимального значения. Минимизация второго члена побуждает атаку находить образец x., который делает z. n ³ z. y, чтобы в результате классификации можно было избежать y. В отличие от L-BFGS, в котором используется кросс-энтропийная потеря, CW-атака основана на маржинальной потере, которая более эффективна при поиске минимально искаженного обманного образца (Carlini, Wagner, 2017). Знаковый метод быстрого градиента (fast gradient sign method, FGSM) (Goodfellow et al., 2015) основан на градиенте и определяет направление возмущения таким образом, что потери в целевой модели увеличиваются. FGSM оценивает возмущения, вычисляя градиент функции потерь, ℒ(x, y) по отношению к заданному входу x, с небольшим ϵ для создания незаметных вредоносных возмущений: x. = x + ϵsgn(Ñ xℒ(x, y)). (15.8) Поскольку возмущения генерируются в направлении Ñxℒ(x, y), обманное изображение может ввести целевую модель в заблуждение таким образом, чтобы она избежала исходную метку y, что приведет к ненаправленной атаке. FGSM также можно использовать для направленной атаки, уменьшив потери целевой модели по отношению к целевой метке y. как x. = x – ϵsgn(Ñ xℒ(x, y.)), (15.9) что создает возмущение, которое вводит классификатор в заблуждение и за- ставляет его выбрать целевую метку y Варианты FGSM, использующие оптимизацию на основе градиента, также могут быть либо ненаправленными, либо направленными аналогичным об- разом, как показано в уравнениях (15.8) и (15.9). Базовый итерационный метод (BIM или I-FGSM) (Kurakin et al., 2017) расширяет FGSM путем агреги- рования обманных возмущений для фиксированного числа итераций: (15.10) где α управляет величиной возмущений на каждом шаге, а операция отсече- ния обрезает интенсивности пикселей обманного изображения на вре- менном шаге i, чтобы они находились в диапазоне исходного изображения. Проецируемый градиентный спуск (PGD) (Madry et al., 2018) обобщает BIM без ограничений на величину возмущения. Вместо этого на каждом шаге PGD проецирует обманные образцы на ℓ∞-соседа, чтобы можно было ограничить возмущение: (15.11) где – оператор проецирования. Атаки на основе якобиановой карты значимости (Jacobian-based saliency map attacks, JSMA) (Papernot et al., 2016) создают карту значимости S(xq, y.), которая определяет каждый пиксель xq Î x в позиции q, чтобы выбрать пиксели, которые наиболее вероятно придется нарушить для достижения желаемых изменений в классификации целевой метки y.:\n--- Страница 658 ---\nКлассификация изображений  657 (15.12) где Py.(x) – предсказанная вероятность softmax для y. до последнего слоя классификации. Алгоритм возмущает пиксель xq с наибольшим значением S(xq, y.), чтобы увеличить (или уменьшить) вероятности softmax целевого класса. Атака итеративно генерирует возмущение до тех пор, пока злона- меренное изображение не будет классифицировано как y. или пока не будет нарушено заданное максимальное количество пикселей. DeepFool (Moosavi-Dezfooli et al., 2016) – это еще один подход, основанный на градиенте, который генерирует возмущения x. i, ограниченные l2, путем оценки расстояния от входа на временном шаге i до ближайшей границы решения целевого классификатора с оригинальным классом y. Этот про- цесс повторяется до тех пор, пока f(x. i) ≠ f(xi). DeepFool производит меньшие возмущения по сравнению с атакой L-BFGS и с меньшими затратами на вы- числения. SparseFool (Modas et al., 2019) использует состязательную атаку, подобную DeepFool, с ограничением возмущений l1-нормой. SparseFool ис - пользует малый средний радиус кривизны границы решения для эффектив- ного вычисления обманных возмущений с по мощью нескольких пикселей. Вышеупомянутые методы обычно сосредоточены на эффективности и заметности атаки со стороны противника, в то время как переносимости уделяется меньше внимания. Некоторые варианты FGSM также допускают дополнительные проблемы со стороны злоумышленников, такие как введе- ние в заблуждение нескольких моделей или незнакомых моделей и защиту частной информации, например исходного класса, из входного изображе- ния. Возмущения, созданные в результате атак на основе FGSM, могут быть адаптированы к целевой модели. Чтобы улучшить возможность переноса на несколько моделей, вариант Diverse Input Iterative FGSM (DI2-FGSM) (Xie et al., 2019) применяет случайное изменение размера и дополнение входных изображений на каждой итерации для создания жестких и разнообразных входных шаблонов. Ансамбль FGSM (E-FGSM) (Tramèr et al., 2018) использует несколько классификаторов одновременно при создании возмущений, по- добных FGSM (уравнение 15.9). E-FGSM может быть применим к нескольким моделям, которые используются для обуче ния, но возмущения, как прави- ло, переопределяются для используемых моделей и плохо подходят для не- знакомых классификаторов. Заметим, что из этих вариантов FGSM можно легко вывести истинный класс изображений, поэтому важно защитить кон- фиденциальность входной метки. Частный FGSM (P-FGSM) (Li et al., 2019) достигает этого, отбрасывая лучшие предсказанные классы из выбора класса, чтобы создать возмущение, подобное уравнению (15.9), но не рассматрива- ет возможность переноса на другие модели или средства защиты, которые могут оценить исходную метку. Чтобы удовлетворить как проблемы перено- симости, так и конфиденциальности, а также обнаруживаемости при состяза- тельной атаке, Robust Private FGSM (RP-FGSM) (Sanchez-Matilla et al., 2020) случайным образом выбирает целевую модель для атаки, а также защиту, от которой нужно уклониться, на основе стратегии P-FGSM для выбора класса.\n--- Страница 659 ---\n658  Атаки на визуальные системы и защита от злоумышленников В отличие от предыдущих атак, которые создают возмущения на конкрет - ном изображении (атаки, зависящие от изображения), универсальное со- стязательное возмущение (universal adversarial perturbation, UAP) (Moosa- vi-Dezfooli et al., 2017) представляет собой единственное возмущение, целью которого является введение модели в заблуждение для большинства изобра- жений в обучающем наборе. UAP накапливает возмущения, зависящие от изображения, итеративно применяя DeepFool до тех пор, пока определенная часть входных изображений не будет классифицирована неправильно. Таким образом, UAP требует обучающих данных, на которых целевая модель может быть обучена создавать единственное универсальное возмущение. Fast Fea- ture Fool (Mopuri et al., 2017) предполагает отсутствие доступа к исходным обучающим данным. Этот метод направлен на создание универсальных воз- мущений, которые могут обмануть признаки целевой модели, оптимизируя произведение средних активаций на нескольких уровнях целевой модели, когда входными данными являются универсальные возмущения. Обсуждаемые до сих пор состязательные атаки генерируют возмущения, решая задачу оптимизации с ограничениями или обновляя обратную связь от градиентов по отношению к входным изображениям. В отличие от выше- упомянутых методов, сети состязательного преобразования (adversarial transformation tetworks ATN) (Baluja, Fischer, 2018) обучают нейронную сеть с прямой связью создавать обманные изображения, похожие на входное изображение. После обуче ния сеть может генерировать их быстрее, чем ал- горитмы на основе оптимизации и алгоритмы на основе градиента с итера- тивными обновлениями. Точно так же обманные генеративно-состяза- тельные сети (AdvGAN) (Xiao et al., 2018) учатся создавать злонамеренные возмущения с использованием нейронных сетей, созданных по принципу генеративно-состязательной архитектуры (Goodfellow et al., 2014), которые состоят из генератора и дискриминатора. Генератор в AdvGAN генерирует возмущения, тогда как дискриминатор, обученный отличать реальное вход- ное изображение от обманных изображений, учит генератор создавать об- манные изображения, максимально похожие на входное изображение. Этот метод можно рассматривать как атаку «серого ящика», поскольку обученная сеть прямого распространения (генератор) может создавать обманные воз- мущения для любых входных данных, не требуя больше доступа к самой мо- дели. В этой архитектуре атака черного ящика также доступна путем замены целевой модели дистиллированной (или замещающей) моделью. Генератив- но-состязательные возмущения (generative adversarial perturbations, GAP) (Poursaed et al., 2018) – это генеративная модель, которая создает зависящие от изображения или универсальные возмущения для ненаправленных или направленных атак. Возмущения, зависящие от изображения, создаются ана- логично AdvGAN (Xiao et al., 2018), где генератор формирует возмущение, исходя из входного изображения. Для выработки универсального возмуще- ния генератор берет фиксированный шаблон, выбранный из равномерного распределения, чтобы создать возмущение, которое добавляется к чистым изображениям и обманывает классификатор. Сеть злонамеренной генера- ции (network for adversary generation, NAG) (Mopuri et al., 2018) создает уни- версальные возмущения, используя GAN-подобную генеративную модель,\n--- Страница 660 ---\nКлассификация изображений  659 которая моделирует неизвестное распределение обманных возмущений для данного классификатора DNN. Основываясь на предполагаемом распределе- нии, NAG может генерировать широкий спектр универсальных возмущений. 15.7.2. Белый ящик, атаки на основе контента Возмущения на основе контента создаются с учетом свойств изображения, таких как структура изображения (Shamsabadi et al., 2020a), текстуры или цвета (Bhattad et al., 2020). В отличие от возмущений, ограниченных нормой (Goodfellow et al., 2014; Szegedy et al., 2014), возмущения, основанные на кон- тенте, являются неограниченными, т. е. не ограничивают величину обман- ных возмущений. Это позволяет состязательным атакам на основе контента улучшить переносимость и снизить обнаруживаемость для средств защиты. Семантическая манипуляция (semantic manipulation) (Bhattad et al., 2020) представляет собой две состязательные атаки, которые манипулиру - ют визуальными дескрипторами, а именно цветами и текстурами входного изображения. Цветовая стратегия использует в качестве направления состя- зательной атаки раскрашивание изображения. Имея входное изображение, преобразованное в оттенки серого, злоумышленник учится раскрашивать его с по мощью исходных цветов исходного изображения таким образом, чтобы ввести в заблуждение целевой классификатор. Текстурная атака переносит текстуру с другого изображения на входное изображение. EdgeFool (Sham- sabadi et al., 2020) создает обманные изображения с улучшенной детализа- цией. EdgeFool обучает нейронную сеть с прямой связью с многозадачными функциями потерь, которые совместно учитывают сглаживание изображения и ненаправленную состязательную атаку (Carlini, Wagner, 2017). Детали изо- бражения, извлеченные из изученного гладкого изображения, обрабатыва- ются с по мощью традиционной техники повышения детализации (Farbman et al., 2008). Выходные данные улучшения детализации затем передаются в функцию потери CW (Carlini, Wagner, 2017), чтобы платформа EdgeFool мог - ла генерировать обманные изображения с улучшенной детализацией. 15.7.3. Атаки методом черного ящика Атаки методом черного ящика предполагают наличие ограниченной ин- формации или отсутствие информации о целевой модели, например только окончательную выходную метку или оценки прогноза. Атаку черного ящика можно выполнить путем обуче ния модели-заменителя, которая способна аппроксимировать целевую модель (аппроксимация границы решения), ге- нерируя возмущение на основе предполагаемого градиента потерь с по- мощью запросов, которые возвращают оценки или вероятности меток из целевой модели (оценка градиента), манипулируя возмущениями текущего шага в правильном направлении, чтобы ввести в заблуждение целевую мо- дель (локальный поиск), или выполняя жадный поиск до тех пор, пока целе- вая модель не будет введена в заблуждение или не достигнет максимальной итерации (случайный поиск).\n--- Страница 661 ---\n660  Атаки на визуальные системы и защита от злоумышленников Методы аппроксимации границы решения обычно учитывают переноси- мость обманных изображений. Атака замещающего черного ящика (substi- tute blackbox attack, SBA) (Papernot et al., 2016) обучает замещающую модель, которая имитирует исходную модель, а затем использует атаки белого ящика на обученной замещающей модели для создания обманных возмущений. Ис - пользуя возможность переноса обманных изображений, SBA получает прог - нозы для синтетического набора данных из целевой модели, а затем обучает замещающую модель, чтобы имитировать прогноз целевой модели. Обучен- ная замещающая модель используется в качестве псевдоцелевой модели, где злоумышленники теперь могут генерировать возмущения с по мощью атаки белого ящика. Поскольку замещающая модель обучается на основе предпо- ложения о переносимости возмущений, важно выбирать атаки, обладающие высокой переносимостью. Атака Curls & Whey (Shi et al., 2019) направлена на улучшение переносимости обманных изображений на другие целевые модели. Во-первых, итерация Curls создает возмущения вдоль направле- ния градиентного подъема и спуска замещающей модели, что позволяет об- манным изображениям иметь лучшую переносимость за счет разнообразия сгенерированных изображений. Второй шаг, оптимизация Whey, уменьша- ет величину возмущений от созданных обманных изображений. Поскольку известно, что хорошая переносимость обманных изображений позволяет проводить атаки черного ящика, в атаке Translation-Invariant (TI) (Dong et al., 2019) используется ансамбль перенесенных обманных изображений, а не оптимизация функции потерь для оценки заменяющей модели. Метод TI выполняет атаку черного ящика путем создания переносимых обманных изображений, которые генерируются для другого классификатора белого ящика со свойством инвариантности к переносу, но имеют высокую пере- носимость для атак черного ящика. Атаки путем оценки градиента принимают форму запроса обратной связи, в которой злоумышленник итеративно генерирует возмущения и спрашива- ет, не ошиблась ли модель-жертва, до тех пор, пока цель не будет достигнута. Оценивая градиент функции потерь из входных запросов, злоумышленник может генерировать возмущение на основе направления этого градиента. Оптимизация нулевого порядка (zeroth order optimization, ZOO) (Chen et al., 2017) оценивает градиенты целевой модели на основе предположения, что злоумышленник имеет доступ к получению оценок вероятности всех классов из целевой модели. Это предположение легче реализует атаку чер- ного ящика, чем предыдущие работы (Papernot et al., 2016), которые могут получить только информацию о метке из классификатора. ZOO генерирует состязательные возмущения, наблюдая за изменениями вероятностей, что позволяет аппроксимировать градиенты. Затем аппроксимированные гра- диенты можно использовать для стохастического спуска по координатам при выполнении состязательной атаки. Одной из проблем атаки методом «черного ящика» является большое количество запросов, которые нужны для прогнозирования неизвестных целевых моделей. Атака с ограничением запросов (Ilyas et al., 2018) генерирует обманные образцы с ограниченным количеством запросов. Метод использует стратегии естественной эволюции (Salimans et al., 2017) в качестве способа оценки градиента при атаке черного\n--- Страница 662 ---\nСемантическая сегментация и обнаружение объектов  661 ящика. Имея предполагаемый градиент, можно вместе с PGD (Madry et al., 2018), используемым для атак белого ящика, создать обманное изображение. Оптимизация нулевого порядка на основе автоэнкодера (autoencoder based zeroth order optimization, AutoZOOM) (Tu et al., 2019) также решает проб- лемы эффективности запросов. AutoZoom уменьшает количество запросов, необходимых для создания успешных обманных изображений, с по мощью стратегии адаптивной оценки случайного градиента, в которой атака может быть ускорена с по мощью автокодировщика, обученного в автономном ре- жиме с немаркированными данными, или билинейной операции изменения размера. Методы случайного поиска создают случайные возмущения до тех пор, пока полученное изображение не введет целевую модель в заблуждение. Semanti- cAdv (Hosseini, Poovendran, 2018) изменяет входное изображение в цветовом пространстве HSV. Оттенок и насыщенность входного изображения иска- жаются случайным возмущением, равномерно выбираемым из диапазона допустимых значений. SemanticAdv вносит новые возмущения до тех пор, пока классификатор не будет введен в заблуждение или не будет достигнуто максимальное количество попыток (например, 1000). Поскольку значения оттенка и насыщенности меняются на одинаковую величину, обманные изо- бражения могут выглядеть неестественно. В отличие от SemanticAdv, модель ColorFool (Shamsabadi et al., 2020) генерирует возмущения, которые, кроме быстродействия, учитывают естественность получаемых обманных изобра- жений. Метод сначала находит нечувствительные и чувствительные области посредством семантической сегментации. Затем возмущения воздействуют на каналы a и b цветового пространства Lab: возмущения нечувствительных областей выбираются случайным образом из всего диапазона возможных значений, тогда как возмущения чувствительных областей выбираются слу - чайным образом из предопределенных диапазонов естественных цветов, ориентированных на человеческое восприятие. Кроме того, SemanticAdv и ColorFool создают неограниченные возмущения, которые обеспечивают лучшую переносимость на другие модели, чем другие атаки черного ящика, которые в основном ограничивают возмущения, уделяя особое внимание разработке методологии атаки. 15.8. семанти ЧесКая сегментация и обнаружение объе КтоВ В этом разделе мы обсудим состязательные атаки, разработанные для мо- делей семантической сегментации и обнаружения объектов. Семантическая сегментация выполняет маркировку сегментов объекта, присваивая метку каждому пикселю изображения. Обнаружение объектов, в отличие от семан- тической сегментации, локализует объекты с по мощью ограничивающих рамок и классифицирует каждый объект. Атака семантической сегментации (semantic segmentation attack, SSA) (Fischer et al., 2017) использует атаку BIM (Kurakin et al., 2017) для каждого\n--- Страница 663 ---\n662  Атаки на визуальные системы и защита от злоумышленников пикселя изображения или области с определенной меткой, чтобы ввести в заблуждение задачу попиксельной семантической сегментации с по мощью FCN. Плотная состязательная генерация (dense adversary generation, DAG) (Xie et al., 2017) создает состязательные возмущения для задач обнаружения объектов и семантической сегментации, выполняемых сетями Faster R-CNN и FCN соответственно. Обратите внимание, что в одном изображении Faster R-CNN выполняет классификацию нескольких объектов-кандидатов, чтобы определить местонахождение объекта в виде ограничивающей рамки, а FCN классифицирует метку каждого пикселя в изображении. Рассматривая объек - ты-кандидаты и пиксели изображения как несколько целей, которые можно ввести в заблуждение, DAG создает возмущения на основе градиента, стре- мящиеся ввести в заблуждение как можно больше пикселей. Универсальная эффективная состязательная сеть (Unified and Efficiency Adversary, UEA) (Wei et al., 2019) ненаправленно генерирует обманные изображения с по- мощью условной генеративно-состязательной сети (cGAN), чтобы вводить в заблуждение детекторы объектов. UEA вместе с состязательной потерей, используемой для атаки на сети Faster R-CNN в DAG, выводит функцию по- терь, которая интегрирует многомасштабную потерю функции внимания, чтобы лучше сконцентрировать возмущения на областях объекта. Изображе- ния, созданные с многомасштабным вниманием, могут ввести в заблужде- ние Faster R-CNN с меньшим количеством возмущений, чем DAG, и улучшить переносимость атаки черного ящика на другой детектор объектов, например SSD. Детектор границы объекта может быть атакован, как показано в Edge At - tack (Cosgrove, Yuille, 2020), в которой используются варианты FGSM (Good- fellow et al., 2015), чтобы ввести в заблуждение детектор HED (Xie, Tu, 2015) (раздел 15.6). Edge Attack передает созданные обманные изображения на последующую классификацию изображений и семантическую сегментацию. 15.9. отсЛежи Вание объе Кта В моделях DNN отслеживание отдельных объектов рассматривается как за- дача метрики подобия на основе шаблона, которая ищет в каждом кадре область, наиболее похожую на эталонный патч, заданный как приор или выбранный из первого кадра. В этой задаче используются сиамские архи- тектуры (Bromley et al., 1994) для сравнения эталонного участка с участком из области поиска в кадре (Bertinetto et al., 2016; Li et al., 2018; Zhang, Peng, 2019; Li et al., 2019). Состязательная атака на систему отслеживания объекта может генерировать возмущения, которые изменяют эталонный патч, об- ласть поиска или и то, и другое. Быстрая атакующая сеть (fast attack network, FAN) (Liang et al., 2020) на сегодняшний день является единственным инструментом состязательной атаки на систему отслеживания объектов. FAN может выполнять ненаправ- ленную или направленную атаку. Ненаправленная FAN возмущает область поиска независимо для каждого кадра последовательности, так что карта отклика максимизируется в случайных областях вне истинной траектории\n--- Страница 664 ---\nОтслеживание объекта  663 объекта. Направленная FAN побуждает трекер следовать по другой, заранее определенной траектории, нарушая как эталонный участок, так и области по- иска. Чтобы избежать преждевременных отказов трекера при целевой атаке, FAN модифицирует области поиска (опорный патч) таким образом, чтобы расстояние в пространстве признаков между обманной областью поиска (или обманным эталонным патчем) и заданными областями траектории было минимальным. FAN использует генеративный подход для получения возмущений, не- заметных для человеческого глаза, а также легко добавляемых к входным видео. Во время обуче ния параметры FAN оптимизируются путем чередо- вания генератора и дискриминатора. Функция потерь для дискриминатора 𝒟(·) основана на PatchGAN (Isola et al., 2017). Генератор 𝒢(·) обучается с по- мощью многокритериальной функции потерь ℒF, которая учитывает рас - стояние между представлениями признаков ℒe (целевая атака); двуцелевой член дрейфа β1ℒd + β2ℒs (ненаправленная атака); расстояние по норме ℓ2 между исходным и обманным изображениями ℒu (незаметность) в допол- нение к стандартному члену генератора ℒ 𝒢 (на основе циклической GAN): ℒF = ℒ𝒢 + α1ℒu + α2ℒe + α3(β1ℒd + β2ℒs), (15.13) где α1, α2, α3, β1 и β2 – гиперпараметры для балансировки влияния каждо- го члена многокритериальной потери. Гиперпараметры для направленной и ненаправленной атак обнуляются при оптимизации любой из атак. Член потерь для генератора определяется как ℒ𝒢 = 𝔼[𝒟(δ + R(xk, bk)) – 1)2], (15.14) где xt – исходный видеокадр в момент времени k, R(·) – экстрактор региона на основе области поиска bk в кадре k. Чтобы создать незаметное возмущение, член подобия в уравнении потерь определяется как ℒu = 𝔼xk~𝒳[||R(x. k, bk) – R(xk, bk)||2], (15.15) где 𝒳 обозначает набор кадров во входном видео. При направленной атаке ℒe стремится минимизировать расстояние в пространстве признаков между обманным опорным патчем и заданной траекторией ℒe = 𝔼xk~𝒳,ε. k~ℰ[||ϕ(R(xk, bk) + δ) – ϕ(ε. k)||2], (15.16) где ε. k – область заданной обманной траектории 𝔼 в кадре k, ϕ(·) – функция, которая отображает область изображения во встроенное пространство при- знаков, а δ генерируется 𝒢(·)и ограничивается до области изображения, вы- бранной с по мощью R(·). Обратите внимание, что R(xk, bk) является опорным патчем, когда k = 0. При ненаправленной атаке член дрейфа нацелен на максимизацию оцен- ки отклика за пределами области, где трекер обычно имеет самый высокий отклик в пределах области поиска для отслеживания объекта: (15.17)\n--- Страница 665 ---\n664  Атаки на визуальные системы и защита от злоумышленников в то же время максимально отдаляя фиктивный центр активации от реального: (15.18) где 𝒮 = 𝒮+1 È 𝒮–1 – карта отклика с положительными и отрицательными мет - ками yq = {–1, +1} для каждого положения пикселя q; q+1 max и q–1 max – располо- жение пикселей с максимальными показателями активации в положитель- ных и отрицательных областях карты откликов соответственно; sq – оценка отклика в точке расположения пикселя q; γ – малая константа для числовой стойкости, а ξ управляет степенью смещения центра активации. 15.10. К Лассифи Кация Видео Атаки на классификатор изображений можно естественным образом рас - пространить на временную область, чтобы ввести в заблуждение целевую модель для классификации видео, работая с каждым кадром независимо. Тем не менее временную информацию можно использовать для создания более надежных злонамеренных возмущений, используя пакет кадров или обрабатывая кадры в режиме реального времени по мере их получения ка- мерой. В этом разделе мы обсудим три состязательные атаки на системы классификации видео: C-DUP , V-BAD и MultAV. Круговые универсальные возмущения двойного назначения (circular universal dual purpose perturbations, C-DUP) – это атака белого ящика, кото- рая вводит в заблуждение классификаторы видео, работающие в реальном времени (Li et al., 2019b). C-DUP направлена на то, чтобы вызвать неправиль- ную классификацию только определенных классов, сохраняя при этом неиз- менным распознавание других классов. C-DUP расширяет работу Mopuri для статичных изображений (Mopuri et al., 2018) и использует модифицирован- ную GAN для изучения в автономном режиме единого набора (универсаль- ных) возмущений, которые можно применить в режиме реального времени к незнакомым входным данным. GAN исправляет дискриминатор с по мощью известного предварительно обученного классификатора и лишь обучает 3D-генератор создавать универсальные возмущения, которые добавляются к входным видео кадрам, стремясь обмануть дискриминатор. Чтобы атаковать только определенные классы, C-DUP использует функцию потерь с векторами вероятности всех классов, выдаваемыми дискриминатором, по всем обучаю- щим данным. Эта функция потерь двойного назначения поддерживает ми- нимизацию кросс-энтропии для целевого класса(ов) y. Î 𝒜Ì 𝒴 (где 𝒴 – набор меток классов) и максимизацию кросс-энтропии для всех других классов 𝒴\\𝒜: (15.19)\n--- Страница 666 ---\nКлассификация видео  665 где λ – весовой параметр, уравновешивающий потери, h – вектор шума из скрытого пространства (например, равномерное распределение в диапазоне [–1, 1]); 𝒢(·) – генератор; Py – вероятность неатакованной метки y; Py. – веро- ятность атакованной метки y.; 𝒳a Ì 𝒳 – подмножество видеоклипов, метка действия которых подвергается атаке; и ρ(G(h), o) = δo – функция переста- новки, которая применяет циклический сдвиг по всем кадрам (o = 1, , W, где W – количество кадров в клипе) сгенерированного возмущения. Функция перестановки заставляет C-DUP быть независимой от временной последо- вательности кадров в клипе. Для создания этих круговых возмущений меж - ду 3D-генератором и дискриминатором используется блок пост обработки. Наконец, 3D-генератор ограничивает возмущения, чтобы они находились в пределах единичного шара, определяемого границей ϵ. Успех C-DUP на грубых (UCF) и детализованных (JESTER) наборах данных распо знавания действий для введения в заблуждение пространственно-временного клас - сификатора C3D (Tran et al., 2015) превышает 80 % для целевых классов при сохранении точности классификации выше 80 % для других классов (ис - ходная точность классификации для C3D составляет 96 % и 90 % для UCF и JESTER соответственно). Существует вариант C-DUP , который генерирует одно квазинезаметное двумерное возмущение, которое применяется к каж - дому кадру клипа. Однако эта атака менее эффективна, чем C-DUP , особенно для детализованной классификации действий, где более важна информация об изменениях по оси времени. V-BAD – это атака методом черного ящика с трехэтапной итеративной схемой для запроса атакуемой модели и получения для каждой итерации метки классификации и соответствующей вероятности (Jiang et al., 2019). Атака V-BAD может быть направленной или ненаправленной. Направленная атака V-BAD нацелена на то, чтобы обмануть модель с по мощью целевого класса, возвращаемого как top-1, и использует образец видео из целевого класса в качестве входных данных, регулируя размер границы возмущения. Ненаправленная атака V-BAD использует исходное видео в качестве входных данных и сохраняет размер возмущения постоянным. Возмущения неза- метны и ограничены ϵ-шаром с центром в исходном видео. Предваритель- ные возмущения генерируются независимо для каждого кадра исходного входного видео (или обманного образца для каждой итерации) с по мощью ансамбля из трех предварительно обученных DNN, а затем их выходные дан- ные усредняются. V-BAD использует равномерные разделы в патчах входных возмущений и ограничивает количество запросов к атакуемой модели рас - познавания видео с по мощью оценки градиента по патчам. Оценщик гра- диента предоставляет вектор весов, основанный на состязательных потерях относительно вероятности, возвращенной атакуемой моделью. Затем патчи возмущений исправляются с использованием вектора весов и применяются к входному видео (или обманному изображению из предыдущей итерации) с по мощью одношагового PGD. V-BAD использовался для атаки на классифи- каторы видео CNN+ LSTM и I3D. MultAV представляет собой набор прямых или итерационных атак на основе градиента (ℓ p-норма, ℓ2-норма PGD), которые создают для каждо -\n--- Страница 667 ---\n666  Атаки на визуальные системы и защита от злоумышленников го кадра видео мультипликативные возмущения (Lo, Patel, 2020). Подобно их аналогу с аддитивным возмущением, атаки MultAV на основе градиента ограничены. В частности, MultAV вводит граничную оценку ϵm (где m озна- чает мультипликативное), которая ограничивает попиксельное соотношение между обманным и исходным изображениями, чтобы сделать искажение незаметным. Если рассматривать в качестве примера ограниченную атаку по норме ℓ2 с аддитивным возмущением (уравнение 15.10), то ее мульти- пликативный аналог, создаваемый итеративным MultAV-ℓ 2, генерируется следующим образом. Обманное изображение на итерации i + 1 получает - ся путем перемножения обманного изображения из предыдущей итерации с размером мультипликативного шага αm, показатель степени которого опре- деляется градиентом потерь (15.20) где – операция отсечения, ϵm – ограниченное отношение, такое что < (ϵm + 1), а ⊙ – произведение Адамара (поэлементное). В качестве альтернативы MultAV применяет тот же мультипликативный принцип к ме- тодам на основе патчей, таким как прямоугольная окклюзия и состязатель- ное кадрирование, или к аддитивному шуму на основе пикселей. Однако эти атаки приводят к ощутимым возмущениям. MultAV был применен на UCF, чтобы ввести в заблуждение классификатор видео 3D ResNet-18. 15.11. защита от состязате Льны Х атаК проти ВниКа Существуют специальные способы защиты моделей машинного обуче ния от атак злоумышленников. Защита может обнаружить обманное изображение (защита путем обнаружения) или исказить градиентную обратную связь от функции потерь в сети, чтобы отключить атаку (защита с по мощью градиент - ной маскировки). В качестве альтернативы целевую модель можно обучить на обманных образцах, чтобы повысить ее устойчивость к атакам (надеж - ность модели). Способы защиты и их свойства перечислены в табл. 15.3 и об- суждаются ниже. 15.11.1. Обнаружение атаки Различные способы защиты путем обнаружения атаки направлены на то, чтобы отличить обманное изображение и отвергнуть его. Эти средства защи - ты могут использовать статистику, полагаться на создание вспомогательной модели или на анализ согласованности прогнозов.\n--- Страница 668 ---\nЗащита от состязательных атак противника  667Таблица 15.3. Сводная информация о средствах защиты от состязательных атак. Обозначения: Dec – метод на основе обнаружения, GradM – маскирование градиента, ModelR – надежность модели, Aux – вспомогательная модель, Stat – статистический подход, CCheck – проверка целостности, NonDiff – недифференцируемый градиент, Van/Exp – исчезающий/взрывающийся градиент, Stoch – стохастический градиент, AdvT Adversarial training, Reg – регуляризация, Cert – сертифицированная защита, Exp – эксперимент, C – классификация изображений, D – обнаружение объектов, S – семантическая сегментация, F – распознавание лиц, T – отслеживание объектов Источник Метод Цель Подход Наборы данных Задача Hendrycks and Gimpel (2016) PCA Dec Stat ImageNet, MNIST, CIFAR C Grosse et al. (2017) Статистический тест Dec Stat MNIST C Gong et al. (2017) Бинарный классификатор Dec Aux MNIST, CIFAR, SVHN C Metzen et al. (2017) Сеть обнаружения обмана Dec Aux ImageNet, CIFAR C Feinman et al. (2017) KDE & BUE Dec CCheck MNIST, CIFAR C Xu et al. (2018) Уплотнение признаков Dec CCheck MNIST, CIFAR C Buckman et al. (2018) Термометрическое кодирование GradM NonDiff MNIST, CIFAR, SVHN C Guo et al. (2018) Преобразования изображения GradM NonDiff ImageNet C Papemot et al. (2016c) Защитная дистилляция GradM Van/Exp MNIST, CIFAR C Song et al. (2018) Пиксельная защита GradM Van/Exp F-MNIST, CIFAR C Samangouei et al. (2018) Защитная GAN GradM Van/Exp F-MNIST C Zhou et al. (2020) A-VAE GradM Van/Exp LFW F Dhillon et al. (2018) Стохастическое отсечение GradM Stoch CIFAR C Xie et al. (2018) Рандомизация GradM Stoch ImageNet C Gu, Rigazio (2014) Глубокая сокращаемая сеть ModelR Reg MNIST C Cisse et al. (2017) Сеть Парсеваля ModelR Reg CIFAR, SVHN C Goodfellow et al. (2015) Базовая AdvTrain ModelR AdvT MNIST C Madry et al. (2018) PGD AdvTrain ModelR AdvT MNIST, CIFAR C Tramer et al. (2018) Ансамблевая AdvTrain ModelR AdvT ImageNet C Zhang, Wang (2019) AROD ModelR AdvT PascalVOC, COCO D Jia et al. (2020) RT ModelR AdvT OTB, VOT, UAV T Raghunathan et al. (2018) Одиночное квазиопределение ModelR Cert MNIST C Wong, Kolter (2018) Глубокая ReLU ModelR Cert F-MNIST, HAR, SVHN C Amab et al. (2018) RSSM ModelR Exp PascalVOC, CityScapes S\n--- Страница 669 ---\n668  Атаки на визуальные системы и защита от злоумышленников Обманные изображения можно обнаружить, найдя различия в статистиче- ских свойствах между обманными и чистыми изображениями. Для обнаруже- ния обманных изображений можно использовать анализ главных компо- нент (principal component analysis, PCA) (Hendrycks, Gimpel, 2016), полагаясь на тот факт, что более поздние главные компоненты обманных изображений имеют большую дисперсию, чем у чистых изображений. Статистический тест (Grosse et al., 2017) использует тот факт, что распределения данных об- манных и чистых изображений различны. С помощью статистического теста, такого как максимальное среднее несоответствие (Gretton et al., 2012), метод проверяет, является группа данных обманной или нет. Метод также содержит расширенную модель, которая является целевой моделью с дополнительным классом, используемым для классификации обманных входных данных. Вспомогательные модели можно научить отличать обманные изображения от чистых. Бинарный классификатор (Gong et al., 2017) – это простой под- ход к созданию классификатора, обнаруживающего обманные изображе- ния. Классификатор принимает изображение в качестве входных данных для классификатора и генерирует двоичную метку, которая указывает, являются входные данные обманными или нет. Сети обнаружения противников (Metzen et al., 2017) образуют бинарный классификатор, на вход которого поступают данные с промежуточного уровня целевой модели. Другие методы обнаруживают обманные изображения, проверяя согла- сованность прогноза относительно входа. Это можно сделать, манипулируя входными данными или целевой моделью до приемлемого предела, а затем проверяя, соответствует ли выходной прогноз ожиданиям. Метод KDE & BUE (Feinman et al., 2017) решает проблему обнаружения, исследуя достоверность модели на состязательных выборках с использованием оценок плотности ядра (kernel density estimates, KDE) обучающих данных и байесовских оценок неопределенности (Bayesian uncertainty estimates, BUE) в слоях отсева. KDE вычисляются с обучающим набором в пространстве признаков последнего скрытого слоя и обнаруживают аномальные точки, которые лежат далеко от множества данных. BUE может обнаруживать обманные изображения, если распределение неопределенности, оцененное случайным отсевом, отличает - ся от чистых данных. Уплотнение признаков (feature squeezing) (Xu et al., 2018) выполняет повторное квантование изображений (уменьшение глубины цвета в битах) и пространственную фильтрацию (медианную фильтрацию) входных изображений. Метод предполагает, что предсказание модели на основе чистых изображений не изменяется при применении повторного квантования или медианной фильтрации. Если после переквантования или медианной фильтрации результат прогнозирования становится другим, ме- тод относит входные данные к обманным изображениям. 15.11.2. Маскировка градиента Большинство обманных атак для создания возмущений используют гради- ент функции потерь целевой модели. Маскировка градиента направлена на то, чтобы сделать информацию о градиенте целевой модели неприменимой\n--- Страница 670 ---\nЗащита от состязательных атак противника  669 для создания обманных возмущений. Примерами маскировки являются не- дифференцируемый градиент, исчезающий/взрывающийся градиент и стохас - тический градиент. Термометрическое кодирование (thermometer encoding) (Buckman et al., 2018) решает проблему линейной экстраполяции моделей DNN путем пред- варительной обработки входных данных с дискретизацией, чтобы сделать защитную модель нелинейной и недифференцируемой. Обычное квантование может быть неэффективным приемом защиты, поскольку возмущения также могут примерно линейно влиять на квантованные входные данные. Поэто- му термометрическое кодирование учится выдавать дискретизированное значение, что позволяет модели сделать вход, эффективный для противо- действия обманным возмущениям. Трансформация изображений (image transformation) (Guo et al., 2018) предлагает несколько подходов к обработ - ке изображений, таких как кадрирование и масштабирование, уменьшение битовой глубины и сжатие JPEG. Также может использоваться минимизация общей дисперсии для упорядочивания каждого небольшого набора пиксе- лей в изображении. Сшивание изображений, синтезирование изображений небольшими патчами – это еще один подход, который заменяет локальные патчи в обманном изображении чистыми патчами ближайшего соседа. Эти недифференцируемые преобразования затрудняют атакующей стороне вы- вод градиента функции потерь из целевой модели. Исчезающий/взрывающийся градиент при обучении защитной модели делает градиенты функции потерь очень маленькими или большими. Такой подход отвлекает противника от атаки на входные изображения. Защитная дистилляция (Papernot et al., 2016) добавляет гибкости процессу класси- фикации, поэтому модель менее уверена в своем прогнозе. Дистиллиро- ванная модель обучается прогнозировать выходные вероятности целевой модели. Эта целевая модель была обучена для достижения высокой точности с изуче нием более мягкого распределения вероятностей с по мощью функции softmax с большой температурой T: Затем дистиллированная модель используется для тестирования с небольшой T, что делает модель более надежной в прогнозировании, чем при использовании большой темпе- ратуры. Это не позволяет противнику оценить градиент, поскольку градиент потерь от других классов становится близким к нулю. По методу PixelDefend (Song et al., 2018) генеративную сеть обучают на чистых данных, чтобы ап- проксимировать их распределение, и, следовательно, побуждают сеть сле- довать исходному распределению, даже когда в качестве входных данных подаются обманные изображения. Эту задачу можно рассматривать как ис - ключение состязательного воздействия. Более того, из-за большого коли- чест ва параметров в генеративной сети градиенты функции потерь могут стать очень маленькими или большими, что сбивает противника с толку и не дает сделать выводы о необходимых возмущениях. Defense-GAN (Saman- gouei et al., 2018) – это структура GAN, которая одновременно обучает гене- ративную сеть для имитации распределения данных и дискриминативную модель для прогнозирования того, являются ли входные данные обманными. Что касается PixelDefend, то генеративная сеть может устранять влияние\n--- Страница 671 ---\n670  Атаки на визуальные системы и защита от злоумышленников обманных возмущений. Состязательный вариационный автокодировщик (adversarial variational autoencoder, A-VAE) (Zhou et al., 2020) – это средство защиты от атак на систему распознавания лиц, которое обучает генератор на основе VAE по исходным изображениям для изучения распределения чистых данных. Во время рабочего вывода входное изображение с пониженной ча- стотой дискретизации подается в обученный VAE, в то время как несколько скрытых кодов выбираются из кодера для создания декодированных изо - бражений с различными деталями. Затем входные данные для модели рас - познавания лиц выбираются путем нахождения ближайшего соседа входных данных в декодированных изображениях. Это позволяет A-VAE выбирать входное изображение, которое, вероятно, позволит предсказать правильную метку и при этом похоже на входное изображение. Стохастический градиент сбивает противника с толку на целевой модели для атаки, применяя рандомизированные операции к входным данным или сети. Стохастическое отсечение (Dhillon et al., 2018) отбрасывает случайное подмножество выходных данных скрытого слоя (или активаций) и увеличи- вает остальные, чтобы компенсировать это. Метод сохраняет узлы с веро- ятностью, пропорциональной величине их активации, и масштабирует вы- жившие узлы, чтобы сохранить динамический диапазон активаций в каждом слое. Этот подход может сделать предварительно обученные модели более устойчивыми к обманным изображениям без тонкой настройки. Рандоми- зация (Xie et al., 2018) использует две операции рандомизации – случай- ное изменение размера и заполнение – на входных изображениях, чтобы смягчить атаки злоумышленников. Хотя добавление случайного изменения размера и случайного заполнения демонстрирует небольшое падение точ- ности на чистых изображениях, прогноз с рандомизацией демонстрирует устойчивость к атакам, ограниченным нормой. 15.11.3. Устойчивость модели Устойчивость целевой модели к атаке со стороны противника может быть повышена за счет регуляризации, состязательного обуче ния или сертифи- цированной защиты. Регуляризация слоев нейронной сети делает обуче ние менее чувствительным к входным искажениям. Состязательное обуче ние переучивает целевую модель на обманных изображениях, созданных в ре- зультате атаки, в дополнение к обуче нию на чистых изображениях. Однако нет гарантии, что переученная модель будет устойчива к другим атакам, не используемым для переучивания. Сертифицированная защита направле- на на предоставление сертификата, гарантирующего устойчивость модели в определенных пределах возмущений. Этот подход отличается от состя- зательного обуче ния и регуляризации, которые смягчают состязательные эффекты в доменах данных/признаков. Глубокая сокращаемая сеть (deep contractive network, Gu, Rigazio, 2014) регуляризует атаки, применяя послойный штраф как потерю, которая огра- ничивает величину частной производной скрытых слоев в целевой модели, в дополнение к потерям, с которыми противник столкнулся при атаке. Это\n--- Страница 672 ---\nЗащита от состязательных атак противника  671 позволяет сети быть менее чувствительной к изменениям входного изо- бражения, таким как возмущения со стороны противника. Сеть Парсеваля (Cisse et al., 2017) контролирует глобальную константу Липшица сети в рам- ках послойной регуляризации. Если рассматривать сеть как комбинацию функций, она может быть устойчивой к небольшим входным возмущениям за счет поддержания небольшой константы Липшица для этих функций. Сеть Парсеваля решает эту проблему с по мощью плотно связанных кадров Пар- севаля, которые определяют спектральную норму весовой матрицы сети. Базовая модель AdvTrain (Goodfellow et al., 2015) переобучает целевой классификатор с по мощью обманных изображений, сгенерированных FGSM, чьи метки совпадают с исходными изображениями. Следовательно, пере- обученный классификатор устойчив к атаке FGSM. Версия PGD AdvTrain (Madry et al., 2018) расширяет базовую AdvTrain, используя атаку PGD, кото- рая создает наихудшее обманное изображение в пределах ℓ∞. Ансамблевая AdvTrain (Tramèr et al., 2018) повторно обучает целевую модель на обман- ных изображениях, созданных из других предварительно обученных клас - сификаторов. Эта стратегия позволяет избежать проблемы переобучения в базовой AdvTrain, а обманные изображения из других классификаторов могут приблизиться к наихудшему обманному изображению. Ансамблевая AdvTrain более эффективна, чем предыдущие методы, поскольку процесс повторного обуче ния и состязательная атака разделены. Устойчивый к ата- кам детектор объектов (adversarially robust object detector, AROD) (Zhang and Wang, 2019) применяет атаку, подобную FGSM, к функциям потери клас - сификации и локализации, которые используются при обнаружении объек - тов, и создает обманные изображения из каждой потери. Результирующий обманный образ – это тот, который максимизирует общую функцию потерь (как классификацию, так и локализацию). Эта же потеря затем используется для подготовки защиты. Робастный трекер (robust tracker, RT) (Jia et al., 2020) оценивает неизвестные обманные возмущения, созданные с учетом движения, происходящего с течением времени во входных видео, и учится устранять их влияние во время отслеживания. Метод сначала определяет потерю со стороны противника, которая включает в себя исходную метку, например ограничивающую рамку и ее класс, с целевой псевдометкой. На входе имеется изображение с неизвестными возмущениями; градиент от состязательных потерь, измеренный с использованием оценочной метки из предыдущего кадра и соответствующей ему псевдометки, вычитается из входного изображения, чтобы уменьшить эффект атаки. Другой подход – обуче ние для оптимизации сертификатов, обеспечива- ющих надежность модели (сертифицированная защита). Исходя из модели и входных данных, верификатор выдает сертификат, если изображение га- рантированно не является обманным. Это можно сделать, проверив, есть ли на расстоянии ℓp какое-либо изображение с меткой, отличной от исходной. Один из подходов заключается в обучении сертификата, который аппрокси- мирует внешние границы состязательных потерь целевой моделью. Метод одиночной полуопределенной релаксации (single semidefinite relaxation) генерирует сертификат, который обеспечивает верхнюю границу, где атака невозможна, учитывая целевую модель и входные данные (Raghunathan et\n--- Страница 673 ---\n672  Атаки на визуальные системы и защита от злоумышленников al., 2018). Аналогично глубокая ReLU (Wong, Kolter, 2018) представляет собой более глубокую сеть для обуче ния доказуемо устойчивых классификаторов, которые гарантированно будут устойчивы к любым ограниченным нормой обманным возмущениям в обучающем наборе. Поскольку обученный серти- фикат приближается к внешним границам состязательных потерь, незнако- мые обманные изображения могут быть обнаружены с нулевым количеством ложноотрицательных результатов, но это не исключает ложноположитель- ные срабатывания. Арнаб и др. (Arnab et al., 2018) исследовали устойчивость к состязатель- ным атакам нескольких модулей, используемых в DNN для семантической сегментации, т. е. робастных моделей семантической сегментации (ro- bust semantic segmentation models, RSSM). Модели для семантической сег - ментации состоят из предварительно обученной модели классификации, используемой в качестве основы, и дополнительных слоев или модулей для лучшей локализации на уровне пикселей, таких как условные случайные поля, расширенные свертки, пропущенные соединения и многомасштаб- ные сети. В ряде работ продемонстрирована атака на модели семантической сегментации с вариантами FGSM (Goodfellow et al., 2015; Kurakin et al., 2017) и показано, что модель, которая является самой точной на чистых изобра- жениях, не обязательно оказывается самой надежной. Условные случайные поля, которые обычно используются в семантической сегментации для обес - печения соблюдения структурных ограничений, содержат вывод, который естественным образом выполняет градиентную маскировку, что приводит к повышению устойчивости к ненаправленным атакам со стороны против- ника. RSSM, основанный на пропущенных соединениях, например ResNet (He et al., 2016), и многомасштабная формулировка более устойчивы к атакам со стороны противника, чем модели, подобные VGG (Simonyan, Zisserman, 2014). 15.12. В ыВоды В данной главе был представлен обширный обзор состязательных атак на модели машинного обуче ния для обработки изображений, классификации изображений, обнаружения объектов, семантической сегментации, отсле- живания объектов и классификации видео, а также средств защиты от этих атак. Мы представили ключевые свойства состязательной атаки, а именно эффективность, надежность, переносимость и заметность, а также обсудили дополнительные свойства, которые необходимо учитывать при оценке ата- ки, такие как обнаруживаемость и обратимость. Затем мы классифицировали методы как ограниченные и неограниченные в зависимости от величины обманного возмущения, а также различали возмущения как глобальные или региональные. Мы сравнили стратегии с учетом конкретной задачи, для которой они предназначены (например, оценка движения, классификация изображений или видео, отслеживание объектов) и различных параметров белого и черного ящиков. Анализ атак позволил нам определить категории стратегий, защищающих DNN от обманных изображений. Средства защиты\n--- Страница 674 ---\nЛитературные источники  673 могут определить, являются ли входные данные обманными, либо предот - вратить атаку с по мощью градиентной маскировки, где градиент исходит из функции потерь. Кроме того, мы обсудили, как сделать модели DNN более надежными с по мощью состязательного обуче ния. Взаимодействие между атаками и защитой станет важным направлением будущих исследований, которые помогут понять ограничения моделей DNN и разработать более надежные глубокие нейросети. Кроме того, еще одной важной областью исследования являются физические атаки, которые изме- няют внешний вид реальных объектов или помещают объекты противника в окружающую среду, и соответствующие средства защиты от таких атак (Eykholt et al., 2018; Sharif et al., 2016; Brown et al., 2018; Kurakin et al., 2017; Athalye et al., 2018; Ranjan, Black, 2017; Chen et al., 2017; Thys et al., 2019; Xu et al., 2020). DNN, как правило, более уязвимы для состязательных атак, чем традиционные модели машинного обуче ния, поскольку сквозные обучае- мые архитектуры DNN упрощают атаку, а некоторые свойства DNN еще не полностью исследованы. Преодоление уязвимости DNN к злонамеренному манипулированию изображениями и видео как непосредственно в цифро- вом пространстве, так и в физическом мире является ключом к их внедрению в реальных приложениях, таких как торговля, безопасность и аутентифика- ция, а также в критических автономных системах безопасности, таких как самоуправляемые транспортные средства (Modas et al., 2020). бЛагодарность Андреа Кавалларо выражает благодарность Институту Алана Тьюринга (грант EP/N510129/1), финансируемому EPSRC, за поддержку в рамках про- екта PRIMULA. Литературные исто ЧниКи Allen-Zhu Z., Li Y., 2020. Feature purification: how adversarial training performs robust deep learning. arXiv:2005. 10190. Anguita D., Ghio A., Oneto L., Parra X., Reyes-Ortiz J., 2013. A public domain da- taset for human activity recognition using smartphones. In: Proceedings of the 21st European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning. Arnab A., Miksik O., Torr P. H. S., 2018. On the robustness of semantic segmenta- tion models to adversarial attacks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Athalye A., Engstrom L., Ilyas A., Kwok K., 2018. Synthesizing robust adversarial examp les. In: Proceedings of the International Conference on Machine Learn- ing. Baluja S., Fischer I., 2018. Learning to attack: adversarial transformation networks. In: Proceedings of the AAAI Conference on Artificial Intelligence.\n--- Страница 675 ---\n674  Атаки на визуальные системы и защита от злоумышленников Bertinetto L., Valmadre J., Henriques J. F., Vedaldi A., Torr P. H., 2016. Fully-convo- lutional Siamese networks for object tracking. In: Proceedings of the European Conference on Computer Vision. Bhattad A., Chong M. J., Liang K., Li B., Forsyth D., 2020. Unrestricted adversarial examples via semantic manipulation. In: Proceedings of the International Con- ference on Learning Representations. Biggio B., Nelson B., Laskov P., 2013. Poisoning attacks against support vector ma- chines. In: Proceedings of the International Conference on Machine Learning. Bolton R. J., Hand D. J., et al., 2002. Statistical fraud detection: a review. Statistical Science 17, 235–255. Brendel W., Rauber J., Bethge M., 2018. Decision-based adversarial attacks: reli- able attacks against black-box machine learning models. In: Proceedings of the International Conference on Learning Representations. Bromley J., Guyon I., LeCun Y., Säckinger E., Shah R., 1994. Signature verification using a Siamese time delay neural network. In: Proceedings of the Advances in Neural Information Processing Systems. Brown T. B., Mané D., Roy A., Abadi M., Gilmer J., 2018. Adversarial patch. arXiv: 1712.09665. Brox T., Malik J., 2011. Large displacement optical flow: descriptor matching in variational motion estimation. IEEE Transactions on Pattern Analysis and Ma- chine Intelligence 33, 500–513. Buckman J., Roy A., Raffel C., Goodfellow I., 2018. Thermometer encoding: one hot way to resist adversarial examples. In: International Conference on Learning Representations. Carlini N., Wagner D., 2017. Towards evaluating the robustness of neural networks. In: Proceedings of the IEEE Symposium on Security and Privacy. Carreira J., Zisserman A., 2017. Quo vadis, action recognition? A new model and the kinetics dataset. In: Proceedings of the IEEE Conference on Computer Vi- sion and Pattern Recognition. Chen P. Y., Zhang H., Sharma Y., Yi J., Hsieh C. J., 2017. Zoo: zeroth order opti- mization based black-box attacks to deep neural networks without training substitutemodels. In: Proceedings of the 10th ACMWorkshop on Artificial In- telligence and Security. Cisse M., Bojanowski P., Grave E., Dauphin Y., Usunier N., 2017. Parseval networks: improving robustness to adversarial examples. In: International Conference on Machine Learning. Coates A., Ng A., Lee H., 2011. An analysis of single-layer networks in unsupervised feature learning. In: Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, JMLRWorkshop and Conference Pro- ceedings. Cordts M., Omran M., Ramos S., Rehfeld T., Enzweiler M., Benenson R., Franke U., Roth S., Schiele B., 2016. The cityscapes dataset for semantic urban scene un- derstanding. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Cosgrove C., Yuille A., 2020. Adversarial examples for edge detection: they exist, and they transfer. In: Proceedings of the IEEE/CVFWinter Conference on App- lications of Computer Vision.\n--- Страница 676 ---\nЛитературные источники  675 Das N., Shanbhogue M., Chen S., Hohman F., Chen L., Kounavis M. E., Chau D. H., 2017. Keeping the bad guys out: protecting and vaccinating deep learning with JPEG compression. arXiv:1705.02900. Deng J., Dong W., Socher R., Li L. J., Li K., Fei-Fei L., 2009. Imagenet: a large-scale hierarchical image database. In: Proceedings of the IEEE Conference on Com- puter Vision and Pattern Recognition. Dhillon G. S., Azizzadenesheli K., Lipton Z. C., Bernstein J. D., Kossaifi J., Khanna A., Anandkumar A., 2018. Stochastic activation pruning for robust adversarial de- fense. In: International Conference on Learning Representations. Dong Y., Pang T., Su H., Zhu J., 2019. Evading defenses to transferable adversarial examples by translationinvariant attacks. In: Proceedings of the IEEE Confer - ence on Computer Vision and Pattern Recognition. Dosovitskiy A., Fischer P., Ilg E., Häusser P., Hazirbas C., Golkov V., Smagt P.v.d., Cre mers, D. Brox T., 2015. FlowNet: learning optical flow with convolutional net - works. In: Proceedings of the IEEE International Conference on Computer Vision. Dziugaite G. K., Ghahramani Z., Roy D. M., 2016. A study of the effect of JPG com- pression on adversarial images. arXiv:1608.00853. Engstrom L., Ilyas A., Santurkar S., Tsipras D., Tran B., Madry A., 2019. Adversarial robustness as a prior for learned representations. arXiv:1906.00945. Everingham M., Eslami S. A., Van Gool L., Williams C. K., Winn J., Zisserman A., 2015. The Pascal visual object classes challenge: a retrospective. International Journal of Computer Vision 111, 98–136. Eykholt K., Evtimov I., Fernandes E., Li B., Rahmati A., Xiao C., Prakash A., Kohno T., Song D., 2018. Robust physical-world attacks on deep learning visual classifica- tion. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Farbman Z., Fattal R., Lischinski D., Szeliski R., 2008. Edge-preserving decompo- sitions for multi-scale tone and detail manipulation. ACM Transactions on Graphics 27, 1–10. Feinman R., Curtin R. R., Shintre S., Gardner A. B., 2017. Detecting adversarial samples from artifacts. arXiv:1703. 00410. Fischer V., Kumar M. C., Metzen J. H., Brox T., 2017. Adversarial examples for se- mantic image segmentation. In: Proceedings of the International Conference on Machine LearningWorkshop. Geiger A., Lenz P., Urtasun R., 2012. Are we ready for autonomous driving? The KITTI vision benchmark suite. In: Proceedings of the Conference on Computer Vision and Pattern Recognition. Gong Z., Wang W., Ku W. S., 2017. Adversarial and clean data are not twins. arXiv: 1704.04960. Goodfellow I., Shlens J., Szegedy C., 2015. Explaining and harnessing adversarial examples. In: Proceedings of the International Conference on Learning Rep- resentations. Goodfellow I. J., Pouget-Abadie J., Mirza M., Xu B., Warde-Farley D., Ozair S., Cour- ville A., Bengio Y., 2014. Generative adversarial nets. In: Proceedings of the International Conference on Neural Information Processing Systems. Gretton A., Borgwardt K. M., Rasch M. J., Schölkopf B., Smola A., 2012. A kernel two- sample test. The Journal of Machine Learning Research 13, 723–773.\n--- Страница 677 ---\n676  Атаки на визуальные системы и защита от злоумышленников Grosse K., Manoharan P., Papernot N., Backes M., McDaniel P., 2017. On the (sta- tistical) detection of adversarial examples. arXiv:1702.06280. Gu S., Rigazio L., 2014. Towards deep neural network architectures robust to ad- versarial examples. arXiv preprint. arXiv:1412.5068. Guo C., Gardner J., You Y., Wilson A. G., Weinberge K., 2019. Simple black-box ad- versarial attacks. In: Proceedings of the International Conference on Machine Learning. Guo C., Rana M., Cisse M., van der Maaten L., 2018. Countering adversarial images using input transformations. In: Proceedings of the International Conference on Learning Representations. Hara K., Kataoka H., Satoh Y. , 2018. Can spatiotemporal 3D CNNs retrace the history of 2D CNNs and ImageNet? In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. He K., Zhang X., Ren S., Sun J., 2016. Deep residual learning for image recognition. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. Hendrycks D., Gimpel K., 2016. Early methods for detecting adversarial images. arXiv:1608.00530. Hosseini H., Poovendran R. , 2018. Semantic adversarial examples. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops. Howard A. G., Zhu M., Chen B., Kalenichenko D., Wang W., Weyand T., Andreetto M., Adam H., 2017. Mobilenets: efficient convolutional neural networks for mobile vision applications. arXiv:1704.04861. Huang G., Liu Z., Van Der Maaten L., Weinberger K. Q., 2017. Densely connected convolutional networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Huang G. B., Mattar M., Berg T., Learned-Miller E., 2008. Labeled faces in the wild: a database for studying face recognition in unconstrained environments. In: Workshop on Faces in ‘Real-Life’ Images: Detection, Alignment, and Recogni- tion. Ilg E., Mayer N., Saikia T., Keuper M., Dosovitskiy A., Brox T., 2017. FlowNet 2.0: evolution of optical flow estimation with deep networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Ilyas A., Engstrom L., Athalye A., Lin J., 2018. Black-box adversarial attacks with limited queries and information. In: Proceedings of the International Confer - ence on Machine Learning. Isola P., Zhu J., Zhou T., Efros A. A., 2017. Image-to-image translation with condi- tional adversarial networks. In: Proceedings of the IEEE Conference on Com- puter Vision and Pattern Recognition. Janai J., Guney F., Ranjan A., Black M., Geiger A., 2018. Unsupervised learning of multi-frame optical flow with occlusions. In: Proceedings of the European Conference on Computer Vision. Jia S., Ma C., Song Y., Yang X., 2020. Robust tracking against adversarial attacks. In: Proceedings of the European Conference on Computer Vision. Jiang L., Ma X., Chen S., Bailey J., Jiang Y., 2019. Black-box adversarial attacks on video recognition models. In: Proceedings of the ACM International Conference on Multimedia.\n--- Страница 678 ---\nЛитературные источники  677 Jiang Y., Wu Z., Wang J., Xue X., Chang S., 2018. Exploiting feature and class rela- tionships in video categorization with regularized deep neural networks. IEEE Transactions on Pattern Analysis and Machine Intelligence 40, 352–364. Kay W., Carreira J., Simonyan K., Zhang B., Hillier C., Vijayanarasimhan S., Viola F., Green T., Back T., Natsev P., Suleyman M., Zisserman A., 2017. The kinetics hu- man action video dataset. arXiv:1705.06950 [cs.CV]. Krizhevsky A., Hinton G., et al., 2009. Learning multiple layers of features from tiny images. Krizhevsky A., Sutskever I., Hinton G. E., 2012. ImageNet classification with deep convolutional neural networks. In: Proceedings of the Advances in Neural In- formation Processing Systems. Kuehne H., Jhuang H., Garrote E., Poggio T., Serre T., 2011. HMDB: a large video database for human motion recognition. In: Proceedings of the International Conference on Computer Vision. Stockholm, Sweden. Kurakin A., Goodfellow I., Bengio S., 2017a. Adversarial examples in the physical world. In: Proceedings of the International Conference on Learning Representa- tions –Workshops. Toulon, France. Kurakin A., Goodfellow I., Bengio S., 2017b. Adversarial machine learning at scale. In: Proceedings of the International Conference on Learning Representations. LeCun Y., 1998. The MNIST database of handwritten digits. LeCun Y., Bottou L., Bengio Y., Haffner P., 1998. Gradient-based learning applied to document recognition. Proceedings of the IEEE 86, 2278–2324. Li B., Wu W., Wang Q., Zhang F., Xing J., Yan J., 2019. SiamRPN++: evolution of Siamese visual tracking with very deep networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Li B., Yan J., Wu W., Zhu Z., Hu X., 2018. High performance visual trackingwith Siamese region proposal network. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Li C. Y., Sanchez-Matilla R., Shahin Shamsabadi A., Mazzon R., Cavallaro A., 2021. On the reversibility of adversarial attacks. Li C. Y., Shahin Shamsabadi A., Sanchez-Matilla R., Mazzon R., Cavallaro A., 2019a. Scene privacy protection. In: Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing. Li S., Neupane A., Paul S., Song C., Krishnamurthy S. V., Chowdhury A. K. R., Swa- mi A., 2019b. Stealthy adversarial perturbations against real-time video clas- sification systems. In: Proceedings of the Network and Distributed Systems Security Symposium. Liang S., Wei X., Yao S., Cao X., 2020. Efficient adversarial attacks for visual object tracking. In: Proceedings of the European Conference on Computer Vision. Lin T. Y., Maire M., Belongie S., Hays J., Perona P., Ramanan D., Dollár P., Zit - nick C. L., 2014. Microsoft COCO: common objects in context. In: Proceedings of the European Conference on Computer Vision. Lo S., Patel V. M., 2020. MultAV: multiplicative adversarial videos. arXiv:2009.08058. Long J., Shelhamer E., Darrell T., 2015. Fully convolutional networks for semantic segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.\n--- Страница 679 ---\n678  Атаки на визуальные системы и защита от злоумышленников Lu J., Sibai H., Fabry E., 2017. Adversarial examples that fool detectors. arXiv: 1712.02494 [cs.CV]. Madry A., Makelov A., Schmidt L., Tsipras D., Vladu A., 2018. Towards deep learn- ing models resistant to adversarial attacks. In: Proceedings of the International Conference on Learning Representations. Martin D. R., Fowlkes C. C., Malik J., 2004. Learning to detect natural image boun- daries using local brightness, color, and texture cues. IEEE Transactions on Pattern Analysis and Machine Intelligence 26, 530–549. Materzynska J., Berger G., Bax I., Memisevic R., 2019. The jester dataset: a large- scale video dataset of human gestures. In: Proceedings of the IEEE/CVF Inter - national Conference on Computer VisionWorkshops. Metzen J. H., Genewein T., Fischer V., Bischoff B., 2017. On detecting adversarial perturbations. arXiv:1702.04267. Meyer T. A., Whateley B., 2004. SpamBayes: effective open-source, Bayesian based, email classification system. In: Proceedings of the Conference on Email and Anti-Spam. Modas A., Moosavi-Dezfooli S. M., Frossard P., 2019. Sparsefool: a few pixels make a big difference. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Modas A., Sanchez-Matilla R., Frossard P., Cavallaro A., 2020. Towards robust sens- ing for autonomous vehicles: an adversarial perspective. IEEE Signal Processing and Magazine 37, 14–23. Moosavi-Dezfooli S. M., Fawzi A., Fawzi O., Frossard P., 2017. Universal adversarial perturbations. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Moosavi-Dezfooli S. M., Fawzi A., Frossard P., 2016. Deepfool: a simple and accurate method to fool deep neural networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Mopuri K. R., Garg U., Babu R. V., 2017. Fast feature fool: a data independent ap- proach to universal adversarial perturbations. In: Proceedings of the British Machine Vision Conference. Mopuri K. R., Ojha U., Garg U., Babu R. V., 2018. NAG: network for adversary generation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Mueller M., Smith N., Ghanem B., 2016. A benchmark and simulator for UAV track - ing. In: Proceedings of the European Conference on Computer Vision. Narodytska N., Kasiviswanathan S. P., 2017. Simple black-box adversarial attacks on deep neural networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern RecognitionWorkshops. Netzer Y., Wang T., Coates A., Bissacco A., Wu B., Ng A. Y., 2011. Reading digits in natural images with unsupervised feature learning. In:Workshop on Deep Learning and Unsupervised Feature Learning (in conjunction with Neural In- formation Processing Systems). Ng Y. H. J., Hausknecht M., Vijayanarasimhan S., Vinyals O., Monga R., Toderici G., 2015. Beyond short snippets: deep networks for video classification. In: Pro- ceedings of the IEEE Conference on Computer Vision and Pattern Recognition.\n--- Страница 680 ---\nЛитературные источники  679 Papernot N., McDaniel P., Goodfellow I., 2016a. Transferability in machine learn- ing: from phenomena to black-box attacks using adversarial samples. arXiv: 1605.07277. Papernot N., McDaniel P., Jha S., Fredrikson M., Celik Z. B., Swami A., 2016b. The limitations of deep learning in adversarial settings. In: Proceedings of the IEEE European Symposium on Security and Privacy. Papernot N., McDaniel P., Wu X., Jha S., Swami A., 2016c. Distillation as a defense to adversarial perturbations against deep neural networks. In: Proceedings of the IEEE Symposium on Security and Privacy. Poursaeed O., Katsman I., Gao B., Belongie S., 2018. Generative adversarial per - turbations. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Raghunathan A., Steinhardt J., Liang P., 2018. Certified defenses against adversarial examples. arXiv:1801.09344. Ranjan A., Black M. J., 2017. Optical flow estimation using a spatial pyramid net - work. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Ranjan A., Janai J., Geiger A., Black M. J., 2019. Attacking optical flow. In: Proceed- ings of the IEEE/CVF International Conference on Computer Vision. Redmon J., Farhadi A., 2017. YOLO9000: better, faster, stronger. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Ren S., He K., Girshick R., Sun J., 2017. Faster R-CNN: towards real-time object de- tection with region proposal networks. IEEE Transactions on Pattern Analysis and Machine Intelligence 39, 1137–1149. Revaud J., Weinzaepfel P., Harchaoui Z., Schmid C., 2015. Epicflow: edge-preserving interpolation of correspondences for optical flow. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Salimans T., Ho J., Chen X., Sidor S., Sutskever I., 2017. Evolution strategies as a scalable alternative to reinforcement learning. arXiv:1703.03864. Samangouei P., Kabkab M., Chellappa R., 2018. Defense-GAN: protecting classifi- ers against adversarial attacks using generative models. In: Proceedings of the International Conference on Learning Representations. Sanchez-Matilla R., Li C. Y., Shamsabadi A. S., Mazzon R., Cavallaro A., 2020. Ex - ploiting vulnerabilities of deep neural networks for privacy protection. IEEE Transactions on Multimedia 22, 1862–1873. Santurkar S., Ilyas A., Tsipras D., Engstrom L., Tran B., Madry A., 2019. Image syn- thesis with a single (robust) classifier. In: Proceedings of the Conference on Neural Information Processing Systems. Shamsabadi A. S., Oh C., Cavallaro A., 2020a. Edgefool: an adversarial image en- hancement filter. In: Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing. Shamsabadi A. S., Oh C., Cavallaro A., 2020b. Semantically adversarial learnable filters. arXiv:2008.06069. Shamsabadi A. S., Sanchez-Matilla R., Cavallaro A., 2020c. ColorFool: semantic adversarial colorization. In: Proceedings of the IEEE/CVF Conference on Com- puter Vision and Pattern Recognition.\n--- Страница 681 ---\n680  Атаки на визуальные системы и защита от злоумышленников Sharif M., Bhagavatula S., Bauer L., Reiter M. K., 2016. Accessorize to a crime: real and stealthy attacks on state-of-the-art face recognition. In: Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security. Shi Y., Wang S., Han Y., 2019. Curls & whey: boosting black-box adversarial at - tacks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Simonyan K., Zisserman A. , 2014. Very deep convolutional networks for large-scale image recognition. arXiv:1409. 1556. Song Y., Kim T., Nowozin S., Ermon S., Kushman N., 2018. Pixeldefend: leveraging generative models to understand and defend against adversarial examples. In: Proceedings of the International Conference on Learning Representations. Soomro K., Zamir A. R., Shah M., 2012. UCF101: a dataset of 101 human actions classes from videos in the wild. arXiv:1212.0402 [cs.CV]. Su J., Vargas D. V., Sakurai K., 2019. One pixel attack for fooling deep neural net - works. IEEE Transactions on Evolutionary Computation 23, 828–841. Sun D., Yang X., Liu M., Kautz J., 2018. PWC-net: CNNs for optical flow using pyramid, warping, and cost volume. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Szegedy C., Ioffe S., Vanhoucke V., Alemi A. A., 2017. Inception-v4, inception-resnet and the impact of residual connections on learning. In: Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence. Szegedy C., Liu W., Jia Y., Sermanet P., Reed S., Anguelov D., Erhan D., Vanhoucke V., Rabinovich A., 2015. Going deeper with convolutions. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Szegedy C., Vanhoucke V., Ioffe S., Shlens J., Wojna Z., 2016. Rethinking the incep- tion architecture for computer vision. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Szegedy C., Zaremba W., Sutskever I., Bruna J., Erhan D., Goodfellow I., Fergus R., 2014. Intriguing properties of neural networks. In: Proceedings of the Interna- tional Conference on Learning Representations. Thys S., Van Ranst W., Goedeme T., 2019. Fooling automated surveillance cameras: adversarial patches to attack person detection. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops. Tramèr F., Kurakin A., Papernot N., Goodfellow I., Boneh D., McDaniel P., 2018. Ensemble adversarial training: attacks and defenses. In: Proceedings of the International Conference on Learning Representations. Tran D., Bourdev L., Fergus R., Torresani L., Paluri M., 2015. Learning spatiotem- poral features with 3d convolutional networks. In: Proceedings of the IEEE International Conference on Computer Vision. Tsipras D., Santurkar S., Engstrom L., Turner A., Madry A., 2019. Robustness may be at odds with accuracy. In: Proceedings of the International Conference on Representation Learning. Tu C. C., Ting P., Chen P. Y., Liu S., Zhang H., Yi J., Hsieh C. J., Cheng S. M., 2019. Autozoom: autoencoder-based zeroth order optimization method for attacking black-box neural networks. In: Proceedings of the AAAI Conference on Artificial Intelligence.\n--- Страница 682 ---\nЛитературные источники  681 Wei X., Liang S., Chen N., Cao X., 2019. Transferable adversarial attacks for image and video object detection. In: Proceedings of the International Joint Confe- rence on Artificial Intelligence. Wong E., Kolter Z., 2018. Provable defenses against adversarial examples via the convex outer adversarial polytope. In: Proceedings of the International Confer - ence on Machine Learning. Wu Y., Lim J., Yang M., 2015. Object tracking benchmark. IEEE Transactions on Pattern Analysis and Machine Intelligence 37, 1834–1848. Xiao C., Li B., Zhu J., He W., Liu M., Song D. , 2018. Generating adversarial examples with adversarial networks. In: Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence. Xiao H., Rasul K., Vollgraf R., 2017. Fashion-MNIST: a novel image dataset for benchmarking machine learning algorithms. arXiv:1708.07747. Xie C., Wang J., Zhang Z., Ren Z., Yuille A., 2018. Mitigating adversarial effects through randomization. In: Proceedings of the International Conference on Learning Representations. Xie C., Wang J., Zhang Z., Zhou Y., Xie L., Yuille A., 2017. Adversarial examples for semantic segmentation and object detection. In: Proceedings of the IEEE International Conference on Computer Vision. Xie C., Zhang Z., Zhou Y., Bai S., Wang J., Ren Z., Yuille A. L., 2019. Improving transferability of adversarial examples with input diversity. In: Proceedings of the Computer Vision and Pattern Recognition. Xie S., Tu Z., 2015. Holistically-nested edge detection. In: Proceedings of the IEEE International Conference on Computer Vision. Xu K., Zhang G., Liu S., Fan Q., Sun M., Chen H., Chen P., Wang Y., Lin X., 2020. Adversarial t-shirt! Evading person detectors in a physical world. In: Procee- dings of the European Conference on Computer Vision. Xu W., Evans D., Qi Y., 2018. Feature squeezing: detecting adversarial examples in deep neural networks. In: Proceedings of the Network and Distributed System Security Symposium. Yu F., Koltun V., Funkhouser T., 2017. Dilated residual networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Zagoruyko S., Komodakis N., 2016. Wide residual networks. In: Proceedings of the British Machine Vision Conference. Zajac M., Zołna K., Rostamzadeh N., Pinheiro P. O., 2019. Adversarial framing for image and video classification. In: Proceedings of the AAAI Conference on Artificial Intelligence. Zhang H., Wang J., 2019. Towards adversarially robust object detection. In: Pro- ceedings of the IEEE/CVF International Conference on Computer Vision. Zhang Z., Peng H., 2019. Deeper and wider Siamese networks for real-time visual tracking. In: Proceedings of the IEEE Conference on Computer Vision and Pat - tern Recognition. Zhou B., Lapedriza A., Khosla A., Oliva A., Torralba A., 2017. Places: a 10 million image database for scene recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence 40, 1452–1464. Zhou J., Liang C., Chen J. , 2020. Manifold projection for adversarial defense on face recognition. In: Proceedings of the European Conference on Computer Vision.\n--- Страница 683 ---\n682  Атаки на визуальные системы и защита от злоумышленников об аВтора Х гЛаВы Чанги О – преподаватель Школы электроники и компьютерных наук и Цент - ра интеллектуального восприятия Лондонского университета королевы Ма- рии, Великобритания. Он получил степень бакалавра, магистра и доктора наук в области электротехники и электроники в Университете Йонсей, Сеул, Южная Корея, в 2011, 2013 и 2018 гг. соответственно. С 2018 по 2019 г. был научным сотрудником в докторантуре Лондонского университета королевы Марии, Великобритания. Алессио Зомперо – научный сотрудник с докторской степенью в области мультимодального восприятия в Школе электронных технологий и компью- терных наук и Центре интеллектуального восприятия Лондонского универси- тета королевы Марии, Великобритания. Получил степень магистра в области телекоммуникаций в Университете Тренто, Италия, в 2015 г. и докторскую степень в области электронных технологий в Лондонском университете ко- ролевы Марии, Великобритания, в 2020 г. Андреа Кавалларо – профессор в области обработки мультимедийных сиг - налов в Лондонском университете королевы Марии (QMUL) и научный со- трудник Института Алана Тьюринга, Британского национального института науки о данных и искусственного интеллекта. Является членом Международ- ной ассоциации распознавания образов; директор Центра интеллектуаль- ного восприятия QMUL; был главным редактором журнала Signal Processing: Image Communication; старшим редактором раздела IEEE Transactions on Image Processing; председателем технического комитета IEEE по обработке изобра- жений, видео и многомерных сигналов и заслуженным лектором Общества обработки сигналов IEEE.\n--- Страница 684 ---\nПредметный указатель A action/behavior recognition, 24 attention map, 25 C cascaded detection and regression, 22 CNN, convolutional neural network, 21 D data augmentation, 22 deep generative model, 23 DNN, deep neural network, 21 F face recognition, 23 face synthesis, 23 K knowledge distillation, 23 L loss function, 22 low-rank factorization, 23 M model decay, 24 multiscale feature representations, 22 multitask losses, 22 P parameter pruning, 23R RANSAC, 51 region-of-interest pooling, 22 region proposal networks, 22 S Siamese tracker, 24 sparse representation, 23 style transfer, 23 А Автокодировщик, 262 вариационный, 263 Адаптация домена, 315, 358 без учителя, 317, 354 с частичным привлечением учителя, 354 Активное видение, 478 Алгоритм 8-точечный, 88 ближайшего соседа, 28 максимизации ожидания, 94, 260 полуквадратичного разделения, 608 Анализ главных компонент, 290 Аномалия расхождения Кульбака–Лейблера, 588 Апостериорный максимум, 606 Атака без вывода, 643 белого ящика, 643 граничная, 654 заметность, 644 замещающего черного ящика, 660 методом случайного поиска, 661\n--- Страница 685 ---\n684  Предметный указатель направленная, 641 ненаправленная, 641 обнаруживаемость, 644 обратимость, 644 оптического потока, 654 переносимость, 643 путем оценки градиента, 660 робастность, 643 с выводом метки, 643 с распределением-выводом, 643 черного ящика, 643 эффективность, 643 Атрибуты классов, 497 Аффорданс, 476 Б Бинокулярное зрение, 61 В Вариационный автокодировщик, 571 Вектор мягкого присвоения, 406 Векторная символическая архитектура, 507 Вергенция, 61 Видимая область, 144 Визуально-языковая генерация, 23 Визуальный паттерн, 254 атомарный, 256 Внутрикластерная сумма квадратов, 221 Возмущения глобальные, 644 неограниченные, 645 области, 644 ограниченные, 645 Восстановление изображения, 605 сверхразрешение, 605 удаление размытия, 605 шумоподавление, 605 Выборка ближайшего соседа, 157 Выравнивание ракурса, 323 Г Гауссова модель смещения, 576 Гауссов шум, 45Генеративное воспроизведение, 381 Геометрический самоансамбль, 612 Гильбертово пространство воспроизводящего ядра, 317 Гиперграф, 441 Гипернимия слов, 488 Гиперпараметр глубина, 293 паддинг, 293 страйд, 293 Гипотеза лотерейного билета, 219 Гистограмма ориентированных градиентов, 139, 406, 578 Глубинная регрессия, 372 Глубокая генеративная модель, 23 Грамматика контекстно- независимая, 490 Грамматика действий, 489 Граф соответствия, 55 Д Двойственность, 395 Действие, 475, 516 Декодер, 262 Дерево деятельности, 489 Детектор Виолы–Джонса, 138 многомасштабный, 154 объектов двухэтапный, 139 одноэтапный, 139 углов, 40 Деятельность, 475, 516 Дискретное преобразование Фурье, 438 Дискриминация с обучением, 367 Дистилляция знаний, 23, 378 Дистрактор, 391 Долгая краткосрочная память, 521 Дополнение данных, 22, 296 Дополненная реальность, 420 З Задача прогнозирования взгляда, 549 Замораживание параметров, 380\n--- Страница 686 ---\nПредметный указатель  685 Знания дистилляция, 216, 225 скрытые, 216 Значимые факторы, 260 Зрение многоракурсное, 83 Зрительная система, 84 Зрительное восприятие, 254 И Извлечение готовых признаков, 296 Инвариантность, 452 Индекс Жаккара, 396 Индуктивная предпосылка, 257 Инициализатор модели, 465 Инициализация весов, 381 К Калибровка камеры, 77 внешняя, 80 внутренняя, 80 Карта внимания, 25 интенсивности, 461 признаков, 293 Каскадное обнаружение, 22 Катастрофическое забывание, 355 Качество предсказания, 527 Квантование без данных, 224 весов, 23, 216 линейное/равномерное, 222 после настройки, 223 сети, 221 Кластеризация k-средних, 221 Клика, 55 Когнитивный диалог, 488 Кодировщик, 262 Коника, 77 Контакт, 489 Косинусное подобие, 301 Коэффициент забывания, 402 расширения, 234 Критерий значимости, 219 остановки, 330М Максимальное среднее расхождение, 337 Марковские случайные поля, 258 Маскировка градиента, 668 Масштабирование укрупняющее (апскейлинг), 462 уменьшающее (даунскейлинг), 462 Масштабное пространство, 406 Матрица совпадений, 100 существенная, 84 фундаментальная, 84 Машина опорных векторов, 575 Метаклассы действий, 490 Метаобновитель, 466 Метаобучение, 465 Метод аппроксимации границы решения, 660 бисекции диаметра, 47 глубокой развертки, 607 жестких шаблонов, 59 локальных бинарных шаблонов, 290 локтя, 549 максимальной клики, 55 машины опорных векторов, 107 оптимальных направлений, 320 пакета признаков, 59 переменного направления множителей, 607 площади под кривой, 549 полуквадратичного разделения, 607 последовательной повторной выборки коэффициентов, 585 стохастического градиентного спуска, 149 фильтрации Габора, 291 хорд и касательных, 47 эпиполярной линии, 62 Минимизация эмпирического риска, 431 Мир закрытый, 392 открытый, 392 Мировая точка, 77\n--- Страница 687 ---\n686  Предметный указатель Многозадачные потери, 22 Многомасштабное представление признаков, 22 Модель бустинг, 96 Гаусса смешанная, 94 генеративная, 571 деградации одиночного изображения, 606 деградации с шумоподавлением, 606 деформируемых частей, 59, 139 дискриминативная, 571 коммутирующая, 584 наблюдения, 571 развертывание, 392 скрытая марковская, 572 события, 516, 518 текстуры, 258 точная настройка, 23 устаревание, 434 фильтра Калмана, 572 Морфинг атрибутов, 282 Н Накопление доказательств, 50 Настройка, 221 с учетом квантования, 224 Нейронная сеть байесовская, 571 восстановления изображений с глубокой разверткой, 620 генеративно-состязательная, 264, 571 глубокая, 21, 108 графовая сверточная, 504 деконволюции, 115 древовидная CNN, 441 искусственная, 106 пирамиды признаков, 156 предсказания области, 464 прогнозирования регионов, 147 распознавания устаревания, 466 сверточная, 21, 108 сверточная без обучения, 440 сиамская, 121с троичными весами, 223 структурозависимая, 440 Низкоранговая факторизация, 216, 220 Нормализованная кросс-корреляция, 398 О Область наблюдения, 464 Обманное изображение, 640 Обнаружение краев, 31 объектов, 137 Обобщенная ошибка, 569 Обобщенное состояние, 568 Обратное распространение ошибки, 108 Обучение бесконечное, 506 непрерывное, 373 однократное, 391 слабое, 354 совмещенное, 375 с переносом, 315 с учителем, 108 трансдуктивное трансферное, 358 Обучение без ознакомления, 497 Объект визуальный состязательный, 26 действия, 24 деятельность, 24 характеристики, 24 Ограничение разреженности, 220 Однородность кластеризации, 552 Однородные координаты, 78 Окклюзия, 45 Окно поиска, 401 Ханна (косинусное), 401 Оператор Боде, 41 Гессе, 41 Кэнни, 33 Лапласа, 41 Собеля, 32 Харриса, 42\n--- Страница 688 ---\nПредметный указатель  687 Оптимизатор модели, 465 Оптимизация чувствительности обнаружения, 35 Оптический поток, 582 Остаточная ошибка, 323 Отношение коэффициентов, 69 сигнал–шум, 35 Отрицательный перенос, 368 Отсечение коэффициентов, 23 Отслеживание объекта, 390 визуальное, 390 длительное, 431 инкрементное, 437 краткосрочное, 431 через обнаружение, 391 Оценка обособленности, 396 Оценка плотности ядра, 576 Ошибка перцептивного предсказания, 518, 525 предсказания, 520 реконструкции, 589 средняя угловая, 550 П Паддинг, 109 Парадокс качественного обнаружения, 149 Параметры камеры внешние, 82 внутренние, 82 Партономия, 516 Передача внимания, 225 Перекрестная энтропия, 161, 309 Перенос обучения, 295 стиля, 23, 267 Пересечение над объединением, 118 Перетасовка каналов, 235 Перспектива полная, 64 слабая, 64 n-точечная, 64 Перспективная проекция, 60Перцептивная обработка, 519 Пирамида изображений, 152 масштаба, 407 Показатель объектности, 148 Поле восприятия (рецептивное), 109 Полилинейная алгебра, 318 Попарная классификация, 300 Порядок тензора, 319 Потеря фокальная (очаговая), 161 Правило равных площадей, 40 Преобразование перспективное, 69 Хафа, 46 обобщенное, 48 Привязка, 22, 148 Признаки Хаара, 139 Приор, 261 Прогрессивное улучшение, 151 Проекция перспективная слабая, 64 полноперспективная, 64 Прореживание гранулярность, 217 итеративное, 220 крупномодульное, 218 мелкомодульное, 217 на ходу, 220 параметров, 216 структурированное, 218 Пространственное внимание, 535 Пространство параметров, 46 Прямое унитарное кодирование, 497 Пулинг, 108 пирамидальный, 143 Р Разделенное представление, 257 Разметка слабая, 354 Разреженное представление, 23 Распад модели, 24 Распознавание действий и поведения, 24 лиц, 23, 289 Расстояние Вассерштейна, 337 Регуляризация, 606\n--- Страница 689 ---\n688  Предметный указатель Рецептивное поле нейрона, 293 Робастная статистика, 45 Робастность, 45 С Самосознание, 569 Свертка глубинная, 232 с разделением по глубине, 233 точечная групповая, 235 Сверхразрешение одиночного изображения, 606 Сверхсостояние, 581 Свойство проективности, 47 Сегментация видеообъектов, 416 семантическая, 116, 354 событий, 24 экземпляров видео, 417 Семантический разрыв, 496 Семантическое пространство представления, 497 Сенсор проприоцептивный, 570 экстероцептивный, 570 Сиамский трекер, 24 Сила угла, 41 Символьное знание, 24 Синономия слов, 488 Синтез лица, 23 Система саморазвивающаяся, 25 Слияние видимых областей, 22 Сложное отношение, 70 Собственное движение, 73 значение, 103, 290 Собственные отображения матрицы Лапласа, 317 Собственный вектор, 103, 290 фильтр, 103 Событие, 516 Стохастический градиент, 670 Страйд, 109 Структурированный случайный лес, 481Субактивность, 484 Сфера Гаусса, 74 Схема событий, 520 Т Тексель, 99 Текстон, 268 Теория воплощенного познания, 475 сегментации событий, 518 Тесселяция, 104 Точка схода, 73 Трансферное обучение. См. Перенос обучения Трекер глубокий, 438 неглубокий, 436 сиамский, 448 Треклет, 124 Триплетные потери, 302 Трудные отрицательные образцы, 160 У Умножение-накопление, 226 Управляемый рекуррентный блок, 524 Уравнение общей точки, 60 Ускоритель граничный, 229 облачный, 229 Условная генерация изображений, 257 Усредненное лицо, 290 Ф Факторизация низкого ранга, 23 Фильтр дискриминативный корреляционный, 403 Калмана, 573 с нулевым влиянием, 581 частиц, 573 чисто фазовый, 395 Фоновые метки, 376\n--- Страница 690 ---\nПредметный указатель  689 Функция потерь, 22 точечной экстраполяции, 49 Функция потерь, взвешенная по движению, 538 Ц Центроидный профиль, 43Э Эквивариантность, 452 вращения, 458 масштаба, 462 переноса, 455 Энергия текстуры, 101 Эпиполюс, 84 Эпиполярная плоскость, 84\n--- Страница 691 ---\nКниги издательства «ДМК ПРЕСС » можно купить оптом и в розницу в книготорговой компании «Галактика» (представляет интересы издательств «ДМК ПРЕСС », «СОЛОН ПРЕСС», «КТК Галактика»). Адрес: г. Москва, пр. Андропова, 38, оф. 10; тел.: (499) 782-38-89, электронная почта: books@alians-kniga.ru. При оформлении заказа следует указать адрес (полностью), по которому должны быть высланы книги; фамилию, имя и отчество получателя. Желательно также указать свой телефон и электронный адрес. Эти книги вы можете заказать и в интернет-магазине: http://www.galaktika-dmk.com/. Редакторы издания Рой Дэвис, Мэтью Терк Компьютерное зрение. Современные методы и перспективы развития Главный редактор Мовчан Д. А. dmkpress@gmail.com Зам. главного редактора Сенченкова Е. А. Перевод Яценков В. С. Корректор Синяева Г. И. Верстка Чаннова А. А. Дизайн обложки Мовчан А. Г. Гарнитура PT Serif. Печать цифровая. Усл. печ. л. 56,06. Тираж 200 экз. Веб-сайт издательства: www.dmkpress.com",
      "debug": {
        "start_page": 641,
        "end_page": 692
      }
    }
  ]
}
{
  "title": "Дообучение готовой модели из Huggingface",
  "chapters": [
    {
      "name": "Дообучение готовой модели из Huggingface",
      "content": "Практические руководства Evolution    \n\n # Дообучение готовой модели из Huggingface   Эта статья полезна?          \nС помощью этого руководства вы запустите процесс дообучения модели mistralai/Ministral-8B-Instruct-2410.\nВы будете использовать следующие сервисы:\n- Secret Management — безопасное хранилище секретов.\n- ML Finetuning — сервис для дообучения моделей.\n- Huggingface — платформа для публикации и использования моделей машинного обучения.\nШаги:\n1. Создайте секрет с токеном Huggingface.\n2. Запустите дообучение модели и проверьте результат.\n\n## Перед началом работы\nЗарегистрируйтесь в личном кабинете Cloud.ru.\nЕсли вы уже зарегистрированы, войдите под своей учетной записью.\n\n## 1. Создайте секрет с токеном Huggingface\n1. Создайте токен Huggingface.\n1. Войдите или зарегистрируйтесь на https://huggingface.co.\n2. Перейдите в раздел Access Tokens.\n3. Нажмите Create new token.\n4. Выберите тип Write.\n5. Введите название токена.\n6. Нажмите Create token.\n7. Скопируйте токен и сохраните его, например в блокнот.\nПосле закрытия страницы он будет недоступен.\n2. Создайте секрет в Secret Management со следующими параметрами:\n\n1. В поле Название укажите название секрета, например hf-token.\n2. В поле Значение вставьте токен, полученный в личном кабинете Huggingface.\n\n## 2. Запустите дообучение модели\n1. Перейдите в AI Factory → ML Finetuning.\n2. Нажмите Дообучить модель.\n1. В поле Репозиторий с моделью укажите название модели mistralai/Ministral-8B-Instruct-2410.\nПримечание Перед началом дообучения убедитесь, что у вас есть доступ к модели, проверив ее карточку на Huggingface.\nДля модели mistralai/Ministral-8B-Instruct-2410 запрашивать специальный доступ не нужно.\n2. В поле Токен доступа выберите секрет hf-token.\n3. В поле Репозиторий модели укажите репозиторий для загрузки дообученной модели my-org/ministral-finetuned.\n4. В поле Датасет укажите репозиторий датасета tatsu-lab/alpaca.\n5. В поле Метод обучения выберите LoRA.\n6. Укажите гиперпараметры обучения:\n- Learning rate — 0.0001.\n- Epoch — 3.\n- Gradient accumulation — 4.\n- Batch size per device — 16.\n- Training precision — bf16.\n- Logging steps — 50.\n- Save steps — 500.\n- Max samples — 100000.\n7. Нажмите Запустить дообучение.\n3. Проверьте результат дообучения в логах:\n1. Перейдите в AI Factory → ML Finetuning.\n2. Нажмите на название модели.\n3. Перейдите на вкладку Логи.\n\n## Что дальше\nВы создали секрет с токеном Huggingface, запустили процесс дообучения модели в сервисе ML Finetuning и проверили модель в Huggingface.\nПолученные навыки помогут интегрировать внешние модели и данные в облачную инфраструктуру Cloud.ru, а также автоматизировать процесс дообучения.\nУзнавайте больше о прикладных сценариях и примерах решения бизнес-задач, получайте навыки управления облаком, выполняя практические руководства.\n\n  [© 2025 Cloud.ru](https://cloud.ru)",
      "debug": {
        "start_page": 1,
        "end_page": 1
      }
    }
  ]
}
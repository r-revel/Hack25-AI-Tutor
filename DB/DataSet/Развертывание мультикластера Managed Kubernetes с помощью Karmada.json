{
  "title": "Развертывание мультикластера Managed Kubernetes с помощью Karmada",
  "chapters": [
    {
      "name": "Развертывание мультикластера Managed Kubernetes с помощью Karmada",
      "content": "Практические руководства Evolution    \n\n # Развертывание мультикластера Managed Kubernetes с помощью Karmada   Эта статья полезна?          \nС помощью этого руководства вы развернете мультикластерное окружение на базе Managed Kubernetes при помощи платформы Karmada.\nВы научитесь создавать и конфигурировать кластеры Kubernetes, управлять доступом и интегрировать несколько кластеров через централизованную платформу.\nВ результате вы получите рабочую мультикластерную инфраструктуру для одновременного и унифицированного управления приложениями в разных кластерах Kubernetes.\nВы будете использовать следующие сервисы:\n- Managed Kubernetes — сервис управления кластерами Kubernetes на вычислительных ресурсах облака.\n- Виртуальные машины — сервис, в рамках которого предоставляется виртуальная машина для подключения и администрирования кластеров Kubernetes.\n- Karmada — Kubernetes-совместимая платформа для централизованного управления и оркестрации приложений в мультикластерной инфраструктуре.\nШаги:\n1. Сгенерируйте ключи доступа для интеграции\n2. Создайте необходимые сети, NAT и виртуальную машину\n3. Подготовьте окружение виртуальной машины\n4. Создайте и настройте кластеры Evolution Managed Kubernetes\n5. Настройте подключение к кластерам Kubernetes\n6. Настройте внешний балансировщик нагрузки для Karmada\n7. Установите Karmada и интегрируйте кластеры-участники\n\n## Перед началом работы\nЗарегистрируйтесь в личном кабинете Cloud.ru.\nЕсли вы уже зарегистрированы, войдите под своей учетной записью.\n\n## 1. Сгенерируйте ключи доступа для интеграции\nПолучите ключи для программного доступа к ресурсам облака Cloud.ru, которые понадобятся для интеграции с Managed Kubernetes.\n1. Сгенерируйте ключи доступа (Key ID и Key Secret) для вашего аккаунта по инструкции.\n2. Сохраните значения Key ID и Key Secret в безопасном месте.\n\n## 2. Разверните ресурсы в облаке\nНа этом шаге вы подготовите подсети, NAT-шлюз и виртуальную машину, которая будет использоваться для управления кластерами.\n1. Создайте три отдельные подсети в одной зоне доступности (например, AZ2) для размещения кластеров Managed Kubernetes.\n2. Создайте NAT-шлюз (SNAT) в этой же зоне.\n3. Создайте виртуальную машину с подсетью и публичным IP.\n\n## 3. Подготовьте окружение виртуальной машины\nНа этом шаге вы настроите окружение для последующей работы с кластерами Kubernetes.\n1. Подключитесь к виртуальной машине по SSH, используя соответствующий клиент.\n2. Установите на виртуальной машине необходимые инструменты для работы с Managed Kubernetes:\n1. Установите kubectl.\n2. Установите cloudlogin.\n3. Установите Git и клонируйте репозиторий Karmada:\n1. Установите Git (команда приведена для ОС на базе Ubuntu/Debian):\n```\nsudo apt update && sudo apt install -y git\n```\n2. Клонируйте официальный репозиторий Karmada:\n```\ngit clone https://github.com/karmada-io/karmada.git\n```\n4. Установите Go версии 1.24.6:\nПримечание Проверьте версию Go в файле go.mod репозитория karmada.\n1. Загрузите и установите Go:\n```\ncurl -fsSLo go1.24.6.linux-amd64.tar.gz https://go.dev/dl/go1.24.6.linux-amd64.tar.gzsudo tar -C /usr/local -xzf go1.24.6.linux-amd64.tar.gzecho 'export GOROOT=/usr/local/go' >> ~/.bashrcecho 'export GOPATH=$HOME/go' >> ~/.bashrcecho 'export PATH=$PATH:$GOROOT/bin:$GOPATH/bin' >> ~/.bashrcsource ~/.bashrc\n```\n2. Проверьте корректность установки:\n```\ngo version\n```\n5. Установите Docker:\n```\ncurl -fsSL https://get.docker.com -o get-docker.shsudo sh ./get-docker.shsudo groupadd dockersudo usermod -aG docker $USERnewgrp docker\n```\n\n## 4. Создайте и настройте кластеры Managed Kubernetes\nНа этом шаге вы создадите основной кластер для control plane Karmada и два кластера-участника.\n1. Создайте три кластера в сервисе Managed Kubernetes: основной (control plane) и два кластера-участника.\nДля каждого выберите ранее созданные подсети и разместите их в одной VPC.\n- Основной кластер:\n- Имя: mk8s-karmada-control-plane\n- Число мастер-узлов: 1\n- Ресурсы мастер-узла: 2 vCPU, 4 ГБ RAM\n- Публичный IP: включен\n- Подсеть сервисов: 10.101.0.0/16\n- Подсеть подов: 10.102.0.0/16\n- Конфигурация группы узлов: 2 vCPU, гарантированная доля vCPU — 30%, 4 ГБ RAM\n- Количество узлов: 3\n- Кластер-участник 1:\n- Имя: mk8s-evo1\n- Число мастер-узлов: 1\n- Ресурсы мастер-узла: 2 vCPU, 4 ГБ RAM\n- Публичный IP: включен\n- Подсеть сервисов: 10.111.0.0/16\n- Подсеть подов: 10.112.0.0/16\n- Конфигурация группы узлов: 2 vCPU, гарантированная доля vCPU — 30%, 4 ГБ RAM\n- Количество узлов: 3\n- Кластер-участник 2:\n- Имя: mk8s-evo2\n- Число мастер-узлов: 1\n- Ресурсы мастер-узла: 2 vCPU, 4 ГБ RAM\n- Публичный IP: включен\n- Подсеть сервисов: 10.121.0.0/16\n- Подсеть подов: 10.122.0.0/16\n- Конфигурация группы узлов: 2 vCPU, гарантированная доля vCPU — 30%, 4 ГБ RAM\n- Количество узлов: 3\n2. Дождитесь окончания создания кластеров.\nУбедитесь, что в личном кабинете статус всех кластеров — «Запущено».\n\n## 5. Настройте подключение к кластерам Kubernetes\nНа этом шаге вы обеспечите конфигурирование доступа к каждому кластеру с управляющей виртуальной машины.\n1. Скачайте файлы kubeconfig для всех кластеров в личном кабинете.\n2. Создайте директорию .kube, которая будет использоваться по умолчанию для основного кластера:\n```\nmkdir -p $HOME/.kube\n```\n3. Создайте директорию для конфигураций кластеров-участников:\n```\nmkdir -p $HOME/join-clusters\n```\n4. Сохраните файлы kubeconfig по следующим путям:\n- mk8s-karmada-control-plane: $HOME/.kube/config (по умолчанию)\n- mk8s-evo1: $HOME/join-clusters/evo1\n- mk8s-evo2: $HOME/join-clusters/evo2\n5. Задайте значения <KEY_ID> и <KEY_SECRET> для параметров CLOUDRU_KEY_ID и CLOUDRU_SECRET_ID с помощью команды:\n```\nsed -i \\  -e '/name: CLOUDRU_KEY_ID/ {n; s/value: \"\"/value: \"<KEY_ID>\"/}' \\  -e '/name: CLOUDRU_SECRET_ID/ {n; s/value: \"\"/value: \"<KEY_SECRET>\"/}' \\  $HOME/.kube/config \\  $HOME/join-clusters/evo1 \\  $HOME/join-clusters/evo2\n```\n\nГде:\n- <KEY_ID> — сгенерированный ранее Key ID.\n- <KEY_SECRET> — сгенерированный ранее Key Secret.\n6. Проверьте доступ к кластерам Kubernetes:\n```\nkubectl cluster-infokubectl --kubeconfig=$HOME/join-clusters/evo1 cluster-infokubectl --kubeconfig=$HOME/join-clusters/evo2 cluster-info\n```\n\nУбедитесь, что каждая команда возвращает информацию о кластере без ошибок аутентификации.\n\n## 6. Настройте внешний балансировщик нагрузки для Karmada\nНа этом шаге вы создадите внешний балансировщик, чтобы организовать доступ к API-серверу Karmada через сервис Load Balancer.\nМы будем устанавливать Karmada на кластер mk8s-karmada-control-plane с помощью скрипта установки из репозитория Karmada.\nПри установке необходимо указать каким образом мы будем обращаться к API-серверу Karmada:\n- через HostNetwork — отправка обращений на порт tcp/5443 непосредственно узла, на котором будет запущен под karmada-apiserver;\n- через LoadBalancer — отправка обращений к API-серверу через балансировщик нагрузки.\nБалансировщик нагрузки слушает порт tcp/5443 и переадресует наши запросы поду karmada-apiserver.\nВ этом сценарии мы будем обращаться к API-серверу через LoadBalancer.\nВажно учесть, что скрипт установки сначала генерирует все необходимые сертификаты, а затем создает все необходимые ресурсы, в том числе сервис LoadBalancer.\nСкрипт создает сертификаты для серверных компонентов с опцией SAN.\nПоскольку скрипт в начале не может знать IP-адрес балансировщика нагрузки, т.к. он еще не создан, то он не добавляет этот IP-адрес как альтернативное имя субъекта.\nИз-за этого вы не сможете подключиться к API-серверу через балансировщик нагрузки.\nЧтобы выйти из ситуации, вы можете перевыпустить сертификаты после установки, но этот путь довольно ресурсозатратный.\nТакже вы можете, узнав IP-адрес балансировщика, переустановить Karmada.\nВ этом случае вы не застрахованы, что IP-адрес балансировщика будет другим.\nМы предлагаем создать заранее namespace karmada-system и сервис типа LoadBalancer.\nКогда вы создадите балансировщик нагрузки в кластере Kubernetes, платформа автоматически создаст балансировщик нагрузки в сервисе Evolution Load Balancer с параметрами сервиса Kubernetes.\n1. Создайте папку karmada-manifests:\n```\nmkdir $HOME/karmada-manifests\n```\n2. Создайте там файл karmada.yaml и скопируйте следующий манифест:\n```\napiVersion: v1kind: Namespacemetadata:   labels:     kubernetes.io/metadata.name: karmada-system   name: karmada-system---apiVersion: v1kind: Servicemetadata:  name: karmada-apiserver  labels:    app: karmada-apiserver  annotations:    loadbalancer.mk8s.cloud.ru/type: \"external\"    loadbalancer.mk8s.cloud.ru/health-check-timeout-seconds: \"5\"    loadbalancer.mk8s.cloud.ru/health-check-interval-seconds: \"5\"    loadbalancer.mk8s.cloud.ru/health-check-unhealthy-threshold-count: \"4\"    loadbalancer.mk8s.cloud.ru/health-check-healthy-threshold-count: \"4\"  namespace: karmada-systemspec:  type: LoadBalancer  selector:    app: karmada-apiserver  ports:   - name: karmada-apiserver-kubectl     port: 5443     protocol: TCP     targetPort: 5443\n```\n3. Примените манифест к основному кластеру Kubernetes:\n```\nkubectl apply -f $HOME/karmada-manifests/karmada.yaml\n```\n4. Убедитесь, что сервис создан:\n```\nkubectl -n karmada-system get svc karmada-apiserver\n```\n\nПроверьте, что сервис отображается, статус внешнего IP — <pending>.\nЭто означает, что Evolution Load Balancer создает ресурс и назначает публичный IP.\nПодождите около 8-10 минут, пока балансировщик нагрузки получит внешний IP-адрес и закончит настройку.\n\n## 7. Установите Karmada и интегрируйте кластеры-участники\nНа этом шаге вы установите Karmada на основной кластер, учитывая внешний IP-адрес балансировщика, и подключите оба кластера-участника.\n1. После назначения публичного IP для балансировщика получите этот IP-адрес:\n```\nkubectl -n karmada-system get svc karmada-apiserver -o jsonpath=\"{range .status.loadBalancer.ingress[*]}{.ip}{'\\n'}{end}\"\n```\n2. Скопируйте полученный IP и вставьте его в установочный скрипт deploy-karmada.sh для корректной генерации сертификатов:\n```\nsed -i \"1iKARMADA_APISERVER_IP=\\\"<IP_BALANCER>\\\"\" $HOME/karmada/hack/deploy-karmada.shsed -i 's#karmada_apiserver_alt_names=(\"karmada-apiserver.karmada-system.svc.cluster.local\" \"karmada-apiserver.karmada-system.svc\" \"localhost\" \"127.0.0.1\" $(util::get_apiserver_ip_from_kubeconfig \"${HOST_CLUSTER_NAME}\"))#karmada_apiserver_alt_names=(\"karmada-apiserver.karmada-system.svc.cluster.local\" \"karmada-apiserver.karmada-system.svc\" \"localhost\" \"127.0.0.1\" \"${KARMADA_APISERVER_IP}\" $(util::get_apiserver_ip_from_kubeconfig \"${HOST_CLUSTER_NAME}\"))#' $HOME/karmada/hack/deploy-karmada.shsed -i 's/HOST_CLUSTER_NAME=${HOST_CLUSTER_NAME:-\"karmada-host\"}/HOST_CLUSTER_NAME=${HOST_CLUSTER_NAME:-\"karmada-apiserver\"}/' $HOME/karmada/hack/deploy-karmada.sh\n```\n\nГде:\n- <IP_BALANCER> — публичный IP-адрес балансировщика нагрузки.\n3. Установите переменную окружения, чтобы скрипт используя сервис Load Balancer:\n```\nexport LOAD_BALANCER=true\n```\n4. Запустите установку Karmada на кластер mk8s-karmada-control-plane:\n```\n$HOME/karmada/hack/remote-up-karmada.sh $HOME/.kube/config <K8S_KARMADA_CONTEXT_NAME>\n```\n\nГде:\n- <K8S_KARMADA_CONTEXT_NAME> — имя контекста кластера из файла конфигурации.\n5. Проверьте, что все компоненты Karmada развернуты корректно:\n```\nkubectl get pods -n karmada-systemkubectl get services -n karmada-system\n```\n6. Установите инструмент CLI karmadactl:\n1. Скачайте и установите утилиту:\n```\ncurl -s https://raw.githubusercontent.com/karmada-io/karmada/master/hack/install-cli.sh | sudo bash\n```\n2. Проверьте, что karmadactl успешно установлена:\n```\nkarmadactl version\n```\n7. Подключите оба кластера-участника к Karmada:\n1. Для кластера mk8s-evo1 выполните комманду:\n```\nkarmadactl join evo1 --karmada-context karmada-apiserver --cluster-kubeconfig $HOME/join-clusters/evo1\n```\n2. Для кластера mk8s-evo2 выполните комманду:\n```\nkarmadactl join evo2 --karmada-context karmada-apiserver --cluster-kubeconfig $HOME/join-clusters/evo2\n```\n8. Проверьте, что оба кластера успешно добавлены и отображаются со статусом «Ready»:\n```\nkarmadactl --karmada-context karmada-apiserver get clusters\n```\n\nВ консоли должны отобразиться оба кластера: evo1 и evo2, статус — «Ready».\n\n## Результат\nВы развернули мультикластерную инфраструктуру Evolution Managed Kubernetes, подготовили внешний балансировщик нагрузки и добавили кластеры-участники control plane Karmada.\nТеперь вы можете централизованно управлять приложениями в распределенной среде Kubernetes, расширять масштабируемость и надежность ваших сервисов.\n\n  [© 2025 Cloud.ru](https://cloud.ru)",
      "debug": {
        "start_page": 1,
        "end_page": 1
      }
    }
  ]
}
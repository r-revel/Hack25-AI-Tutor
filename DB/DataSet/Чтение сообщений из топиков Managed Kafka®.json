{
  "title": "Чтение сообщений из топиков Managed Kafka®",
  "chapters": [
    {
      "name": "Чтение сообщений из топиков Managed Kafka®",
      "content": "Практические руководства Evolution    \n\n # Чтение сообщений из топиков Managed Kafka®   Эта статья полезна?          \nС помощью этого руководства вы настроите чтение сообщений из топика Managed Kafka® и отображение полученных данных в логах задачи Managed Spark.\nВы создадите две задачи Managed Spark c использованием скриптов для разового и для непрерывного чтения данных.\nВ результате вы получите возможность просматривать сообщения из топиков Managed Kafka® в логах задачи Managed Spark.\nВы будете использовать следующие сервисы:\n- Managed Spark — сервис, который позволяет развернуть кластерное вычислительное решение на основе Apache Spark для распределенной обработки данных.\n- Object Storage — сервис для хранения данных любого типа и объема. Будет использоваться в качестве хранилища для скриптов.\n- Managed Kafka® — сервис для развертывания и управления кластерами Kafka® в инфраструктуре платформы Evolution.\nШаги:\n1. Подготовьте скрипты, которые будут обращаться к топику Managed Kafka®.\n2. Cоздайте задачу Managed Spark.\n3. Проверьте информацию в логах.\n4. Запустите непрерывное чтение топика Managed Kafka®.\n\n## Перед началом работы\n1. Зарегистрируйтесь в личном кабинете Cloud.ru. Если вы уже зарегистрированы, войдите под своей учетной записью.\n2. Создайте бакет Object Storage, в котором будут храниться необходимые файлы и логи.\n3. Настройте DNS-сервер и подсеть.\n4. Создайте кластер Data Platform, в котором будет размещен инстанс.\n5. Скачайте и установите root-сертификат на устройство.\n6. Создайте пароль и добавьте его в Secret Manager. Этот секрет станет паролем для доступа к интерфейсу Managed Spark.\n7. Создайте инстанс Managed Spark.\n8. Убедитесь, что в проекте, где будет запускаться задача Managed Spark, доступен сервис Managed Kafka®.\n9. Создайте кластер Managed Kafka®. На шаге Сетевые настройки в списке Подсеть выберите подсеть, указанную при создании инстанса Managed Spark.\n10. Подключитесь к кластеру Managed Kafka® и отправьте несколько сообщений в топик.\n\n## 1. Подготовьте скрипт задачи\nНа этом шаге вы загрузите в хранилище Object Storage файлы, содержащие скрипты для чтения топика Managed Kafka®.\nСкрипт из файла kafka_spark.py выполняет однократное чтение сообщений из топика, а скрипт из файла kafka_spark_streaming.py — непрерывное.\n1. Скопируйте скрипт и назовите файл kafka_spark.py.\n```\nfrom pyspark.sql import SparkSessionimport os\nkafka_user = os.environ[\"KAFKA_USER\"]kafka_pass = os.environ[\"KAFKA_PASS\"]kafka_topic = os.environ[\"KAFKA_TOPIC\"]kafka_server = os.environ[\"KAFKA_SERVER\"]\nspark = SparkSession.builder.appName(\"kafka\").getOrCreate()\ndf = (   spark.read.format(\"kafka\")   .option(\"kafka.bootstrap.servers\", kafka_server)   .option(\"kafka.security.protocol\", \"SASL_PLAINTEXT\")   .option(\"kafka.sasl.mechanism\", \"SCRAM-SHA-512\")   .option(      \"kafka.sasl.jaas.config\",      f'org.apache.kafka.common.security.scram.ScramLoginModule required username=\"{kafka_user}\" password=\"{kafka_pass}\";',      )   .option(\"subscribe\", kafka_topic)   .option(\"startingOffsets\", \"earliest\")   .option(\"endingOffsets\", \"latest\")   .load())\ndf.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")df.show(truncate=False)spark.stop()\n```\n2. Скопируйте скрипт и назовите файл kafka_spark_streaming.py.\n```\nfrom pyspark.sql import SparkSessionimport os\nkafka_user = os.environ[\"KAFKA_USER\"]kafka_pass = os.environ[\"KAFKA_PASS\"]kafka_topic = os.environ[\"KAFKA_TOPIC\"]kafka_server = os.environ[\"KAFKA_SERVER\"]\nspark = (   SparkSession.builder.appName(\"kafka\")   .getOrCreate())\ndf = (   spark   .readStream   .format(\"kafka\")   .option(\"kafka.bootstrap.servers\", kafka_server)   .option(\"kafka.security.protocol\", \"SASL_PLAINTEXT\")   .option(\"kafka.sasl.mechanism\", \"SCRAM-SHA-512\")   .option(      \"kafka.sasl.jaas.config\",      f'org.apache.kafka.common.security.scram.ScramLoginModule required username=\"{kafka_user}\" password=\"{kafka_pass}\";',      )   .option(\"subscribe\", kafka_topic)   .option(\"startingOffsets\", \"earliest\")   .load()   )\ndf.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")сonsole = (df   .writeStream   .outputMode('append')   .format('console')   .start()   )console.awaitTermination()spark.stop()\n```\n3. Откройте ранее созданный бакет Object Storage.\n4. Загрузите файлы со скриптами.\n\n## 2. Создайте задачу Managed Spark\nНа этом шаге вы создадите задачу Managed Spark с использованием подготовленного скрипта.\nСкрипт выполнит чтение сообщений, отправленных в топик Managed Kafka®, и выведет данные из них в логи задачи Managed Spark.\nДля продолжения работы убедитесь, что статус инстанса Managed Spark изменился на «Готов».\n1. Перейдите в сервис Managed Spark.\n2. Откройте созданный ранее инстанс.\n3. Перейдите на вкладку Задачи.\n4. Нажмите Создать задачу.\n5. В блоке Общие параметры введите название задачи, например kafka-spark-streaming.\n6. В блоке Образ выберите базовый образ Spark-3.5.0.\n7. В блоке Скрипт приложения:\n\n- В поле Тип запускаемой задачи выберите Python.\n- В поле Путь к запускаемому файлу укажите путь к файлу kafka_spark.py.\n8. В блоке Настройки активируйте опцию Добавить параметры окружения. Добавьте следующие параметры и их значения:\n Параметр ЗначениеKAFKA_USER Логин для подключения к кластеру Managed Kafka®, например, cloud-admin.KAFKA_PASS Пароль для подключения к кластеру Managed Kafka® с указанным логином.KAFKA_TOPIC Имя топика Managed Kafka®.KAFKA_SERVER Внутренний IP-адрес кластера Managed Kafka®.\nЧтобы узнать внутренний IP-адрес, логин и пароль, откройте сервис Managed Kafka® в отдельной вкладке, в списке кластеров нажмите на название созданного ранее кластера и перейдите в блок Данные для подключения.\n9. В блоке Настройки активируйте опцию Добавить Spark конфигурацию (–conf).\n\n- В поле Аргумент укажите spark.jars.packages.\n- В поле Значение укажите org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0.\n10. Нажмите Создать.\nЗадача Managed Spark начнет выполняться и отобразится на странице инстанса во вкладке Задачи.\nПодробнее о развертывании на официальном сайте.\n\n## 3. Проверьте логи\nНа этом шаге вы проверите логи задачи Managed Spark и отображение в них данных из топика Managed Kafka®.\nДля продолжения работы убедитесь, что статус задачи Managed Spark изменился на «Завершена».\n1. В строке задачи нажмите  и выберите Перейти к логам.\n2. Используйте фильтр, чтобы найти логи, содержащие сообщения из топика Managed Kafka®.\nПример данных, полученных из топика Managed Kafka®:\n\n## 4. Запустите непрерывное чтение топика Managed Kafka®\n\nНа этом шаге вы создадите вторую задачу Managed Spark с использованием скрипта, который будет непрерывно поддерживать соединение с топиком Managed Kafka® и выполнять чтение поступающих в него сообщений.\n\n1. В строке задачи Managed Spark, выполненной ранее, нажмите  и выберите Скопировать задачу.\n2. В блоке Скрипт приложения в поле Путь к запускаемому файлу укажите путь к файлу kafka_spark_streaming.py.\n3. Нажмите Создать.\n4. Дождитесь, пока статус задачи изменится на «Выполняется».\n5. В строке задачи нажмите  и выберите Перейти к логам.\n6. Используйте фильтр, чтобы найти логи, содержащие сообщения из топика Managed Kafka®. Если в топик Managed Kafka® не поступают новые данные, в логах будут только отправленные ранее сообщения и информация об ожидании.\n7. Отправьте новое сообщение в топик Managed Kafka®.\n8. Посмотрите в логах задачи Managed Spark информацию о новом сообщении.\n9. Задача Managed Spark c данными параметрами будет выполняться, пока вы ее не завершите. Чтобы завершить задачу, в строке задачи нажмите  и выберите Остановить.\n\n## Результат\nВы настроили чтение сообщений из топика Managed Kafka® и вывод полученных данных в логи задачи Managed Spark с помощью скриптов.\n\n  [© 2025 Cloud.ru](https://cloud.ru)",
      "debug": {
        "start_page": 1,
        "end_page": 1
      }
    }
  ]
}
{
  "title": "Event-driven масштабирование в Managed Kubernetes с помощью KEDA",
  "chapters": [
    {
      "name": "Event-driven масштабирование в Managed Kubernetes с помощью KEDA",
      "content": "Практические руководства Evolution    \n\n # Event-driven масштабирование в Managed Kubernetes с помощью KEDA   Эта статья полезна?          \nС помощью этого руководства вы развернете инфраструктуру Managed Kubernetes и установите решение KEDA для event-driven автомасштабирования приложений.\nВы настроите масштабирование Kubernetes Job на основе сообщений из очереди RabbitMQ, что позволит реализовать обработку событий и горизонтальное масштабирование без привязки к метрикам потребления ресурсов.\nВ результате вы получите решение для асинхронной обработки задач в Kubernetes с использованием KEDA.\nВы будете использовать следующие сервисы:\n- Managed Kubernetes — сервис управления кластерами Kubernetes на вычислительных ресурсах облака.\n- Artifact Registry для хранения, совместного использования и управления Docker-образами и Helm-чартами.\n- Виртуальные машины — сервис для создания виртуальных машин, используемых для управления кластерами и запуска утилит администрирования.\n- KEDA — платформа для событийного масштабирования приложений в Kubernetes на основе внешних триггеров, таких как очереди сообщений и базы данных.\nШаги:\n1. Сгенерируйте ключи доступа для интеграции.\n2. Разверните ресурсы в облаке.\n3. Подготовьте окружение виртуальной машины.\n4. Создайте кластер Managed Kubernetes и подключитесь к нему.\n5. Создайте репозиторий Artifact Registry.\n6. Установите MongoDB через Helm.\n7. Установите RabbitMQ через Helm.\n8. Установите KEDA.\n9. Загрузите образы контейнеров в приватный реестр Artifact Registry.\n10. Разверните приложение в Kubernetes.\n11. Проверьте работу автомасштабирования KEDA.\n\n## Перед началом работы\nЗарегистрируйтесь в личном кабинете Cloud.ru.\nЕсли вы уже зарегистрированы, войдите под своей учетной записью.\n\n## 1. Сгенерируйте ключи доступа для интеграции\nНа этом этапе получите ключи для программного доступа к ресурсам облачной платформы, которые потребуются для интеграции с Managed Kubernetes и приватным реестром Artifact Registry.\n1. Сгенерируйте ключи доступа Key ID и Key Secret для своего аккаунта.\n2. Сохраните значения Key ID и Key Secret в надежном месте, чтобы использовать их при загрузке образов контейнеров и подключении к кластеру Managed Kubernetes.\n\n## 2. Разверните ресурсы в облаке\nЭтот шаг включает подготовку подсети, NAT-шлюза и виртуальной машины для последующей работы и управления кластером.\n1. Создайте подсеть для размещения кластера Managed Kubernetes.\n2. Создайте SNAT-шлюз в той же зоне доступности, что и подсеть.\n3. Создайте виртуальную машину с подсетью с публичным IP-адресом.\nВыберите ранее созданную подсеть для подключения.\n\n## 3. Подготовьте окружение виртуальной машины\nНа этом этапе настройте окружение для управления облачной инфраструктурой и кластером Kubernetes.\n1. Подключитесь к виртуальной машине по SSH, используя соответствующий SSH-клиент.\n2. Установите необходимые инструменты для работы с Managed Kubernetes:\n1. kubectl\n2. cloudlogin\n3. Установите Git и клонируйте репозиторий демоприложения:\n1. Установите Git для ОС на базе Ubuntu/Debian:\n```\nsudo apt update && sudo apt install -y git\n```\n2. Клонируйте репозиторий демоприложения:\n```\ngit clone https://gitverse.ru/sedg1l/keda-p2\n```\n4. Установите Docker:\n```\ncurl -fsSL https://get.docker.com -o get-docker.shsudo sh ./get-docker.shsudo groupadd dockersudo usermod -aG docker $USERnewgrp docker\n```\n5. Установите Helm:\n```\ncurl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3chmod 700 get_helm.sh./get_helm.sh\n```\n\n## 4. Создайте кластер Managed Kubernetes и подключитесь к нему\nНа этом этапе разверните кластер Kubernetes.\n1. Создайте кластер в сервисе Managed Kubernetes:\n- Название: Cluster-keda.\n- Количество мастер-узлов: 1.\n- Конфигурация мастер-узла: 2 vCPU, 4 ГБ RAM.\n- Публичный IP: включен.\n2. Создайте группу узлов\n- Гарантированная доля vCPU: 10%.\n- vCPU: 2.\n- RAM, ГБ: 4.\n- Количество узлов: 1.\n3. Дождитесь окончания создания кластера.\n4. Убедитесь, что в личном кабинете статус кластера — «Запущено».\n5. Подключитесь к кластеру с управляющей виртуальной машины.\n\n## 5. Создайте репозиторий Artifact Registry\nНа этом шаге создайте приватный реестр в сервисе Artifact Registry.\n\n## 6. Установите MongoDB через Helm\nНа этом шаге вы установите MongoDB в кластер Managed Kubernetes.\n1. Установите MongoDB с помощью Helm:\n```\nhelm install mongodb oci://registry-1.docker.io/bitnamicharts/mongodb --set useStatefulSet=true --set auth.rootPassword=mongo\n```\n2. Проверьте статус развертывания MongoDB:\n```\nkubectl get pods\n```\n3. Дождитесь, пока все поды MongoDB перейдут в состояние «Running».\n\n## 7. Установите RabbitMQ через Helm\nНа этом шаге установите очередь сообщений RabbitMQ с помощью Helm в кластер Managed Kubernetes.\n1. Установите RabbitMQ командой:\n```\nhelm install rabbitmq oci://registry-1.docker.io/bitnamicharts/rabbitmq --set auth.username=user --set auth.password=P@ssw0rd\n```\n2. Проверьте состояние подов RabbitMQ:\n```\nkubectl get pods\n```\n3. Дождитесь, пока все поды очереди RabbitMQ перейдут в состояние «Running».\n\n## 8. Установите KEDA\nНа этом шаге вы установите KEDA для поддержки событийного масштабирования.\n1. В личном кабинете перейдите в созданный кластер Managed Kubernetes.\n2. На панели слева выберите Плагины и нажмите Добавить плагин.\n3. Выберите KEDA и нажмите Установить.\n4. Выберите версию плагина и нажмите Установить.\n5. Чтобы проверить статус подов KEDA, в терминале выполните команду:\n```\nkubectl get pods -n keda\n```\n6. Дождитесь, пока все поды KEDA перейдут в состояние «Running».\n\n## 9. Загрузите образы контейнеров в приватный реестр Artifact Registry\nНа этом этапе соберите и загрузите образы собственного приложения в приватный реестр.\n1. Перейдите в папку репозитория приложения:\n```\ncd $HOME/keda-p2\n```\n2. Откройте файл build.sh в удобном редакторе.\n3. Укажите URI вашего приватного реестра и ключи доступа к облаку в переменных в начале скрипта:\n- <REPO> — адрес реестра Artifact Registry.\n- <LOGIN> — Key ID учетной записи.\n- <PASSWORD> — Secret Key учетной записи.\n4. Сделайте скрипт исполняемым и выполните его:\n```\nchmod +x $HOME/keda-p2/build-images.sh$HOME/keda-p2/build-images.sh\n```\n\nСкрипт выполнит аутентификацию с помощью ключей доступа в Artifact Registry, соберет образы контейнеров через Docker Engine и загрузит их в указанный реестр.\n\n## 10. Разверните приложение в Managed Kubernetes\nНа этом этапе выполните развертывание event-driven приложения, используя подготовленные манифесты.\n1. Примените манифесты:\n```\nkubectl apply -f $HOME/keda-p2/deploy/\n```\n2. Ознакомьтесь со схемой работы приложения:\n\n- При отправке POST-запроса на http://complex-app-service/send?name=<item-name>&content=<content> сервис complex-app отправляет сообщение с параметрами name и content в формате JSON в очередь RabbitMQ.\n- Ресурс ScaledJob периодически опрашивает очередь RabbitMQ.\nКогда в очередь приходит новое сообщение, ScaledJob создает новый Kubernetes Job с именем processor-job.\n- Ресурс processor-job извлекает сообщение, записывает его в MongoDB в формате JSON (name и content), после чего засыпает на 20 секунд.\n- Функция sleep имитирует, что processor-job обрабатывает какой-то «тяжелый» файл.\nНапример, конвертирует видео.\n- Если бы вы масштабировали Deployment с помощью ресурса HPA, то реализовать описанное выше масштабирование было бы невозможно, так как нам необходимо масштабировать ресурс не на основании метрик утилизации ресурсов, а на основании событий.\n3. Проверьте, что все необходимые поды созданы и работают.\n\n## 11. Проверьте работу автомасштабирования KEDA\nНа завершающем этапе вы протестируете работу event-driven масштабирования через отправку сообщений и анализ работы Job.\n1. Создайте тестовый под curl для взаимодействия с приложением:\n```\nkubectl run -it --rm curl-pod --image=curlimages/curl -- /bin/sh\n```\n2. Внутри curl-pod отправьте несколько POST-запросов на сервис для генерации событий:\n```\ncurl -X POST \"http://complex-app-keda-service/send?name=record1&content=content1\"curl -X POST \"http://complex-app-keda-service/send?name=record2&content=content2\"curl -X POST \"http://complex-app-keda-service/send?name=record3&content=content3\"curl -X POST \"http://complex-app-keda-service/send?name=record4&content=content4\"curl -X POST \"http://complex-app-keda-service/send?name=record5&content=content5\"\n```\n3. Проверьте, что данные были добавлены в MongoDB:\n```\ncurl \"http://complex-app-keda-service/data\"\n```\n\nJob-ресурсам потребуется некоторое время на запуск и выполнение, поэтому записи могут появиться в течение минуты.\n4. Выйдите из curl-пода командой:\n```\nexit\n```\n5. Проверьте количество созданных Job:\n```\nkubectl get jobs\n```\n\nУбедитесь, что для каждого события KEDA запустила отдельный Job, реализуя event-driven масштабирование обработки.\n\n## Что дальше\nВ практической работе вы создали кластер Managed Kubernetes, установили KEDA в этом кластере и развернули в нем приложение, в котором реализовано event-driven масштабирование с помощью KEDA.\n\n  [© 2025 Cloud.ru](https://cloud.ru)",
      "debug": {
        "start_page": 1,
        "end_page": 1
      }
    }
  ]
}
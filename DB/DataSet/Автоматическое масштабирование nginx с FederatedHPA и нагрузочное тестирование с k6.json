{
  "title": "Автоматическое масштабирование nginx с FederatedHPA и нагрузочное тестирование с k6",
  "chapters": [
    {
      "name": "Автоматическое масштабирование nginx с FederatedHPA и нагрузочное тестирование с k6",
      "content": "Практические руководства Evolution    \n\n # Автоматическое масштабирование nginx с FederatedHPA и нагрузочное тестирование с k6   Эта статья полезна?          \nС помощью этого руководства вы реализуете автоматическое горизонтальное масштабирование приложения nginx в мультикластерной среде Karmada с помощью FederatedHPA и проведете нагрузочное тестирование с использованием инструмента k6.\nВы получите практические навыки работы с Federated Horizontal Pod Autoscaler, мониторинга метрик, а также анализа масштабирования приложений в Kubernetes кластерах под управлением Karmada.\nВы будете использовать следующие сервисы:\n- Managed Kubernetes — сервис управления кластерами Kubernetes на вычислительных ресурсах облака.\n- Виртуальные машины — сервис, в рамках которого предоставляется виртуальная машина для подключения и управления кластерами Kubernetes.\n- Karmada — Kubernetes-совместимая платформа для централизованного управления и оркестрации приложений в мультикластерной инфраструктуре.\n- k6 — инструмент для проведения нагрузочного тестирования приложений на основе JavaScript-скриптов.\nШаги:\n1. Убедитесь, что Metrics Server установлен в кластерах-участниках\n2. Создайте FederatedHPA для nginx\n3. Разверните генератор нагрузки k6 и выполните нагрузочное тестирование\n4. Проведите мониторинг процессов автомасштабирования\n5. Выполните анализ результатов масштабирования\n\n## Перед началом работы\n1. Зарегистрируйтесь в личном кабинете Cloud.ru.\nЕсли вы уже зарегистрированы, войдите под своей учетной записью.\n2. Разверните Karmada и разверните приложение nginx в кластерах-участниках.\n3. Убедитесь, что Karmada доступна через балансировщик нагрузки, кластеры-участники evo1 и evo2 подключены к Karmada, а приложение nginx запущено в обоих кластерах-участниках.\n\n## 1. Убедитесь, что Metrics Server установлен в кластерах-участниках\nНа этом шаге вы проверите наличие плагина Metrics Server для сбора метрик ресурсов в кластерах-участниках Karmada.\nMetrics Server необходим для работы FederatedHPA, чтобы автоматизировать масштабирование на основе метрик CPU.\n1. Проверьте, что плагин Metrics Server установлен в кластерах mk8s-evo1 и mk8s-evo2.\nПосле создания кластера через сервис Managed Kubernetes, Metrics Server устанавливается по умолчанию.\n2. Выполните команду для каждого кластера:\n```\nkubectl --kubeconfig=$HOME/join-clusters/evo1 get deployment metrics-server -n kube-systemkubectl --kubeconfig=$HOME/join-clusters/evo2 get deployment metrics-server -n kube-system\n```\n3. Если статус ресурса — «AVAILABLE», значит Metrics Server активен.\n\n## 2. Создайте FederatedHPA для nginx\nНа этом шаге вы опишете и примените манифест FederatedHPA, который обеспечит автоматическое масштабирование развернутого nginx в обоих кластерах на основе нагрузки по CPU.\n1. В директории nginx-manifests создайте манифест nginx-fhpa.yaml, который описывает ресурс FederatedHPA со следующими параметрами:\n```\napiVersion: autoscaling.karmada.io/v1alpha1kind: FederatedHPAmetadata:  name: nginx-fhpa  namespace: defaultspec:  scaleTargetRef:    apiVersion: apps/v1    kind: Deployment    name: nginx-deployment  minReplicas: 1  maxReplicas: 10  metrics:  - type: Resource    resource:      name: cpu      target:        type: Utilization        averageUtilization: 30\n```\n\nПояснение по параметрам:\n- scaleTargetRef — целевой ресурс для масштабирования (nginx-deployment).\n- minReplicas / maxReplicas — диапазон реплик от 1 до 10.\n- metrics — отслеживание утилизации CPU: при превышении 50% происходит масштабирование вверх, при меньшей утилизации — вниз.\n2. Примените FederatedHPA к control plane Karmada:\n```\nkarmadactl --karmada-context karmada-apiserver apply -f $HOME/nginx-manifests/nginx-fhpa.yaml\n```\n3. Убедитесь, что ресурс создан и активен, выполнив команду:\n```\nkarmadactl --karmada-context karmada-apiserver get fhpa nginx-fhpa\n```\n\nКоманда выводит актуальный статус FederatedHPA, включая количество реплик и значения метрик.\n4. Получите подробное описание состояния ресурса и истории масштабирования:\n```\nkarmadactl --karmada-context karmada-apiserver describe fhpa nginx-fhpa\n```\n\nВывод содержит историю событий и текущие метрики автомасштабирования.\n\n## 3. Разверните генератор нагрузки k6 и выполните нагрузочное тестирование\nНа этом этапе вы создадите JavaScript-скрипт для k6, развернете его в кластере evo1, опишете необходимые ресурсы и запустите нагрузочный тест для проверки масштабирования nginx.\n1. Создайте директорию для скриптов:\n```\nmkdir -p $HOME/k6-manifests\n```\n2. Создайте JavaScript-скрипт load-test.js для нагрузочного тестирования nginx в директории k6-manifests:\n```\nimport http from 'k6/http';import { check, sleep } from 'k6';export const options = {stages: [    { duration: '1m', target: 100 }, // Наращивание до 100 пользователей за 1 минуту    { duration: '10m', target: 100 },],};export default function () {const response = http.get('http://nginx-service.default.svc.cluster.local');check(response, {    'статус 200': (r) => r.status === 200,    'время ответа < 500ms': (r) => r.timings.duration < 500,});sleep(0.1); // Пауза между запросами}\n```\n\nСкрипт задает:\n- stages — плавное наращивание нагрузки до 100 виртуальных пользователей;\n- target URL — внутренний адрес сервиса nginx;\n- check — проверки успешности ответа и времени отклика;\n- sleep — пауза между запросами для моделирования реального сценария нагрузки.\n3. Создайте ConfigMap с тестовым скриптом:\n```\nkubectl --kubeconfig=$HOME/join-clusters/evo1 create configmap k6-load-test --from-file=$HOME/k6-manifests/load-test.js\n```\n\nConfigMap позволяет подам k6 получать скрипт нагрузочного теста в процессе выполнения.\n4. Создайте в директории k6-manifests манифест k6-deployment.yaml для запуска Job с k6:\n```\napiVersion: batch/v1kind: Jobmetadata:  name: k6-load-test  namespace: defaultspec:  parallelism: 2  template:    metadata:      labels:        app: k6-load-test    spec:      restartPolicy: Never      containers:      - name: k6        image: grafana/k6:latest        command: [\"k6\", \"run\", \"/scripts/load-test.js\"]        volumeMounts:        - mountPath: /scripts          name: k6-script          readOnly: true        resources:          requests:            memory: \"128Mi\"            cpu: \"100m\"          limits:            memory: \"256Mi\"            cpu: \"200m\"      volumes:      - name: k6-script        configMap:          name: k6-load-test\n```\n\nОписание параметров:\n- parallelism: 2 — запуск двух параллельных экземпляров k6 для повышения нагрузки;\n- grafana/k6:latest — официальный контейнер k6;\n- volumeMounts — монтирование скрипта из ConfigMap;\n- resources — ограничения на использование CPU и памяти для стабильной работы тестов.\n5. Примените манифест для запуска генератора нагрузки:\n```\nkubectl --kubeconfig=$HOME/join-clusters/evo1 apply -f $HOME/k6-manifests/k6-deployment.yaml\n```\n6. Проверьте статус k6-load-test и связанных подов:\n```\nkubectl --kubeconfig=$HOME/join-clusters/evo1 get jobs k6-load-testkubectl --kubeconfig=$HOME/join-clusters/evo1 get pods -l app=k6-load-test\n```\n\n## 4. Проведите мониторинг процессов автомасштабирования\nНа этом шаге вы будете отслеживать метрики и состояние масштабирования nginx в кластерах с помощью инструментов мониторинга Kubernetes и командной строки.\n1. Наблюдайте за утилизацией CPU подами nginx в обоих кластерах:\n```\nwatch -n 10 \"echo '=== CPU утилизация подов nginx в evo1 ===' && kubectl --kubeconfig=$HOME/join-clusters/evo1 top pods -l app=nginx && echo '' && echo '=== CPU утилизация подов nginx в evo2 ===' && kubectl --kubeconfig=$HOME/join-clusters/evo2 top pods -l app=nginx\"\n```\n\nКоманда watch обновляет данные по метрикам каждые 10 секунд, позволяя наблюдать динамику использования ресурсов в реальном времени.\n2. Откройте еще одну сессию SSH с ВМ.\nЗапустите отслеживание статус FederatedHPA:\n```\nwatch -n 15 \"karmadactl --karmada-context karmada-apiserver get fhpa nginx-fhpa\"\n```\n\nВы увидите, как FederatedHPA реагирует на изменение нагрузки и корректирует количество реплик в кластерах-участниках.\n3. Откройте еще одну сессию SSH с ВМ. Запустите отслеживание количествf подов nginx:\n```\nwatch -n 10 \"echo '=== Поды nginx в кластере evo1 ===' && kubectl --kubeconfig=$HOME/join-clusters/evo1 get pods -l app=nginx && echo '' && echo '=== Поды nginx в кластере evo2 ===' && kubectl --kubeconfig=$HOME/join-clusters/evo2 get pods -l app=nginx\"\n```\n\nВы увидите, как масштабирование влияет на количество запущенных подов в каждом кластере.\n\n## 5. Выполните анализ результатов масштабирования\nНа завершающем шаге проанализируйте историю событий FederatedHPA, оцените распределение нагрузки между кластерами и отследите влияние масштабирования на использование ресурсов.\n1. Получите подробную информацию о событиях FederatedHPA:\n```\nkarmadactl --karmada-context karmada-apiserver describe fhpa nginx-fhpa\n```\n\nВведите команду, чтобы изучить историю событий масштабирования, включая причины и время изменения числа реплик.\n2. Проверьте текущее распределение подов nginx по кластерам:\n```\necho \"Количество подов nginx в evo1:\"kubectl --kubeconfig=$HOME/join-clusters/evo1 get pods -l app=nginx --no-headers | wc -l\necho \"Количество подов nginx в evo2:\"kubectl --kubeconfig=$HOME/join-clusters/evo2 get pods -l app=nginx --no-headers | wc -l\n```\n\n## Результат\nВы реализовали автоматическое масштабирование nginx с помощью FederatedHPA в мультикластерной среде Karmada, научились генерировать нагрузку с помощью k6, отслеживать метрики и анализировать процессы масштабирования.\n\n  [© 2025 Cloud.ru](https://cloud.ru)",
      "debug": {
        "start_page": 1,
        "end_page": 1
      }
    }
  ]
}